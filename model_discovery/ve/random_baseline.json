{
    "total_evaluation_time_seconds": "166.3082446604967",
    "start_time": 9039138.433038656,
    "tokenizer_pad_token": [
        "</s>",
        "2"
    ],
    "system_instruction_sha": null,
    "group_subtasks": {
        "blimp_only_npi_licensor_present_filtered": [],
        "blimp_determiner_noun_agreement_with_adjective_1_filtered": [],
        "inverse_scaling_pattern_matching_suppression": [],
        "openbookqa": [],
        "blimp_tough_vs_raising_1_filtered": [],
        "inverse_scaling_repetitive_algebra": [],
        "tinyGSM8k": [],
        "blimp_animate_subject_trans_filtered": [],
        "blimp_determiner_noun_agreement_1_filtered": [],
        "arc_challenge": [],
        "inverse_scaling_sig_figs": [],
        "lambada_openai": [],
        "cola": [],
        "mathqa": [],
        "blimp_determiner_noun_agreement_2_filtered": [],
        "blimp_regular_plural_subject_verb_agreement_1_filtered": [],
        "squad_completion": [],
        "blimp_wh_vs_that_no_gap_filtered": [],
        "tinyTruthfulQA": [],
        "blimp_irregular_plural_subject_verb_agreement_2_filtered": [],
        "blimp_superlative_quantifiers_2_filtered": [],
        "rte": [],
        "mnli": [],
        "winogrande": [],
        "blimp_expletive_it_object_raising_filtered": [],
        "blimp_determiner_noun_agreement_irregular_2_filtered": [],
        "triviaqa": [],
        "blimp_supplement_subject_aux_inversion": [],
        "blimp_passive_1_filtered": [],
        "blimp_wh_island_filtered": [],
        "piqa": [],
        "blimp_supplement_hypernym": [],
        "blimp_distractor_agreement_relative_clause_filtered": [],
        "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered": [],
        "blimp_inchoative_filtered": [],
        "blimp_irregular_past_participle_verbs_filtered": [],
        "blimp_only_npi_scope_filtered": [],
        "smollm125-tiny": [
            "cosmopedia-v2-tiny",
            "python-edu-tiny",
            "fineweb-edu-dedup-tiny",
            "open-web-math-tiny",
            "deepmind-math-small-tiny",
            "stackoverflow-clean-tiny"
        ],
        "qa4mre_2012": [],
        "inverse_scaling_into_the_unknown": [],
        "blimp_matrix_question_npi_licensor_present_filtered": [],
        "blimp_passive_2_filtered": [],
        "blimp_npi_present_2_filtered": [],
        "blimp_sentential_subject_island_filtered": [],
        "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered": [],
        "blimp_determiner_noun_agreement_irregular_1_filtered": [],
        "blimp_supplement_qa_congruence_easy": [],
        "inverse_scaling_quote_repetition": [],
        "blimp_causative_filtered": [],
        "mnli_mismatch": [],
        "qnli": [],
        "blimp_supplement_turn_taking": [],
        "blimp_wh_vs_that_no_gap_long_distance_filtered": [],
        "hellaswag": [],
        "blimp_ellipsis_n_bar_1_filtered": [],
        "blimp_animate_subject_passive_filtered": [],
        "blimp_coordinate_structure_constraint_complex_left_branch_filtered": [],
        "blimp_intransitive_filtered": [],
        "inverse_scaling_neqa": [],
        "blimp_sentential_negation_npi_scope_filtered": [],
        "inverse_scaling_winobias_antistereotype": [],
        "blimp_transitive_filtered": [],
        "blimp_principle_A_case_1_filtered": [],
        "blimp_npi_present_1_filtered": [],
        "sciq": [],
        "blimp_wh_vs_that_with_gap_long_distance_filtered": [],
        "qqp": [],
        "blimp_tough_vs_raising_2_filtered": [],
        "blimp_wh_questions_subject_gap_long_distance_filtered": [],
        "blimp_existential_there_quantifiers_1_filtered": [],
        "blimp_principle_A_domain_2_filtered": [],
        "inverse_scaling_memo_trap": [],
        "blimp_wh_questions_subject_gap_filtered": [],
        "blimp_anaphor_number_agreement_filtered": [],
        "inverse_scaling_hindsight_neglect_10shot": [],
        "blimp_principle_A_case_2_filtered": [],
        "arc_easy": [],
        "blimp_coordinate_structure_constraint_object_extraction_filtered": [],
        "blimp_adjunct_island_filtered": [],
        "blimp_sentential_negation_npi_licensor_present_filtered": [],
        "qa4mre_2013": [],
        "sst2": [],
        "blimp_principle_A_reconstruction_filtered": [],
        "blimp_supplement_qa_congruence_tricky": [],
        "blimp_principle_A_domain_3_filtered": [],
        "mrpc": [],
        "blimp_determiner_noun_agreement_with_adj_2_filtered": [],
        "swag": [],
        "wnli": [],
        "blimp_wh_vs_that_with_gap_filtered": [],
        "blimp_anaphor_gender_agreement_filtered": [],
        "qa4mre_2011": [],
        "blimp_ellipsis_n_bar_2_filtered": [],
        "blimp_left_branch_island_echo_question_filtered": [],
        "blimp_existential_there_object_raising_filtered": [],
        "blimp_irregular_plural_subject_verb_agreement_1_filtered": [],
        "tinyMMLU": [],
        "blimp_wh_questions_object_gap_filtered": [],
        "blimp_irregular_past_participle_adjectives_filtered": [],
        "blimp_regular_plural_subject_verb_agreement_2_filtered": [],
        "blimp_distractor_agreement_relational_noun_filtered": [],
        "blimp_existential_there_subject_raising_filtered": [],
        "blimp_principle_A_domain_1_filtered": [],
        "inverse_scaling_modus_tollens": [],
        "blimp_left_branch_island_simple_question_filtered": [],
        "wsc273": [],
        "blimp_complex_NP_island_filtered": [],
        "blimp_existential_there_quantifiers_2_filtered": [],
        "blimp_superlative_quantifiers_1_filtered": [],
        "blimp_principle_A_c_command_filtered": [],
        "inverse_scaling_redefine_math": [],
        "blimp_drop_argument_filtered": []
    },
    "eot_token_id": 2,
    "model_source": "modis",
    "versions": {
        "blimp_only_npi_licensor_present_filtered": 1.0,
        "blimp_determiner_noun_agreement_with_adjective_1_filtered": 1.0,
        "inverse_scaling_pattern_matching_suppression": 0,
        "openbookqa": 1.0,
        "blimp_tough_vs_raising_1_filtered": 1.0,
        "inverse_scaling_repetitive_algebra": 0,
        "tinyGSM8k": 0.0,
        "blimp_animate_subject_trans_filtered": 1.0,
        "blimp_determiner_noun_agreement_1_filtered": 1.0,
        "arc_challenge": 1.0,
        "inverse_scaling_sig_figs": 0,
        "lambada_openai": 1.0,
        "blimp_wh_vs_that_no_gap_filtered": 1.0,
        "mathqa": 1.0,
        "blimp_determiner_noun_agreement_2_filtered": 1.0,
        "blimp_regular_plural_subject_verb_agreement_1_filtered": 1.0,
        "squad_completion": 0,
        "cola": 1.0,
        "tinyTruthfulQA": 0.0,
        "blimp_irregular_plural_subject_verb_agreement_2_filtered": 1.0,
        "blimp_superlative_quantifiers_2_filtered": 1.0,
        "deepmind-math-small-tiny": 0.01,
        "rte": 1.0,
        "mnli": 1.0,
        "blimp_expletive_it_object_raising_filtered": 1.0,
        "winogrande": 1.0,
        "blimp_determiner_noun_agreement_irregular_2_filtered": 1.0,
        "triviaqa": 3.0,
        "blimp_supplement_subject_aux_inversion": 1.0,
        "blimp_passive_1_filtered": 1.0,
        "cosmopedia-v2-tiny": 0.01,
        "blimp_wh_island_filtered": 1.0,
        "piqa": 1.0,
        "blimp_supplement_hypernym": 1.0,
        "blimp_distractor_agreement_relative_clause_filtered": 1.0,
        "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered": 1.0,
        "blimp_inchoative_filtered": 1.0,
        "blimp_irregular_past_participle_verbs_filtered": 1.0,
        "blimp_only_npi_scope_filtered": 1.0,
        "qa4mre_2012": 1.0,
        "inverse_scaling_into_the_unknown": 0,
        "blimp_matrix_question_npi_licensor_present_filtered": 1.0,
        "blimp_passive_2_filtered": 1.0,
        "blimp_npi_present_2_filtered": 1.0,
        "blimp_sentential_subject_island_filtered": 1.0,
        "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered": 1.0,
        "blimp_determiner_noun_agreement_irregular_1_filtered": 1.0,
        "blimp_supplement_qa_congruence_easy": 1.0,
        "fineweb-edu-dedup-tiny": 0.01,
        "inverse_scaling_quote_repetition": 0,
        "blimp_causative_filtered": 1.0,
        "mnli_mismatch": 1.0,
        "qnli": 1.0,
        "blimp_supplement_turn_taking": 1.0,
        "blimp_wh_vs_that_no_gap_long_distance_filtered": 1.0,
        "hellaswag": 1.0,
        "blimp_ellipsis_n_bar_1_filtered": 1.0,
        "blimp_animate_subject_passive_filtered": 1.0,
        "blimp_coordinate_structure_constraint_complex_left_branch_filtered": 1.0,
        "blimp_intransitive_filtered": 1.0,
        "inverse_scaling_neqa": 0,
        "blimp_sentential_negation_npi_scope_filtered": 1.0,
        "inverse_scaling_winobias_antistereotype": 0,
        "blimp_transitive_filtered": 1.0,
        "blimp_principle_A_case_1_filtered": 1.0,
        "blimp_npi_present_1_filtered": 1.0,
        "sciq": 1.0,
        "blimp_wh_vs_that_with_gap_long_distance_filtered": 1.0,
        "open-web-math-tiny": 0.01,
        "blimp_tough_vs_raising_2_filtered": 1.0,
        "qqp": 2.0,
        "blimp_wh_questions_subject_gap_long_distance_filtered": 1.0,
        "blimp_existential_there_quantifiers_1_filtered": 1.0,
        "inverse_scaling_memo_trap": 0,
        "blimp_principle_A_domain_2_filtered": 1.0,
        "blimp_wh_questions_subject_gap_filtered": 1.0,
        "blimp_anaphor_number_agreement_filtered": 1.0,
        "inverse_scaling_hindsight_neglect_10shot": 0,
        "blimp_principle_A_case_2_filtered": 1.0,
        "arc_easy": 1.0,
        "blimp_coordinate_structure_constraint_object_extraction_filtered": 1.0,
        "blimp_adjunct_island_filtered": 1.0,
        "blimp_sentential_negation_npi_licensor_present_filtered": 1.0,
        "qa4mre_2013": 1.0,
        "sst2": 1.0,
        "stackoverflow-clean-tiny": 0.01,
        "blimp_principle_A_reconstruction_filtered": 1.0,
        "blimp_supplement_qa_congruence_tricky": 1.0,
        "blimp_principle_A_domain_3_filtered": 1.0,
        "mrpc": 1.0,
        "blimp_determiner_noun_agreement_with_adj_2_filtered": 1.0,
        "swag": 1.0,
        "wnli": 2.0,
        "blimp_wh_vs_that_with_gap_filtered": 1.0,
        "blimp_anaphor_gender_agreement_filtered": 1.0,
        "qa4mre_2011": 1.0,
        "blimp_ellipsis_n_bar_2_filtered": 1.0,
        "blimp_left_branch_island_echo_question_filtered": 1.0,
        "blimp_existential_there_object_raising_filtered": 1.0,
        "blimp_irregular_plural_subject_verb_agreement_1_filtered": 1.0,
        "tinyMMLU": 0.0,
        "blimp_wh_questions_object_gap_filtered": 1.0,
        "python-edu-tiny": 0.01,
        "blimp_irregular_past_participle_adjectives_filtered": 1.0,
        "blimp_regular_plural_subject_verb_agreement_2_filtered": 1.0,
        "blimp_distractor_agreement_relational_noun_filtered": 1.0,
        "blimp_existential_there_subject_raising_filtered": 1.0,
        "blimp_principle_A_domain_1_filtered": 1.0,
        "inverse_scaling_modus_tollens": 0,
        "blimp_left_branch_island_simple_question_filtered": 1.0,
        "wsc273": 1.0,
        "blimp_existential_there_quantifiers_2_filtered": 1.0,
        "blimp_complex_NP_island_filtered": 1.0,
        "blimp_superlative_quantifiers_1_filtered": 1.0,
        "blimp_principle_A_c_command_filtered": 1.0,
        "inverse_scaling_redefine_math": 0,
        "blimp_drop_argument_filtered": 1.0
    },
    "fewshot_as_multiturn": false,
    "end_time": 9039304.741283316,
    "tokenizer_eos_token": [
        "</s>",
        "2"
    ],
    "tokenizer_bos_token": [
        "<s>",
        "1"
    ],
    "results": {
        "blimp_only_npi_licensor_present_filtered": {
            "acc,none": 0.5566893424036281,
            "acc_stderr,none": 0.016736806125835578,
            "alias": "blimp_only_npi_licensor_present_filtered"
        },
        "blimp_determiner_noun_agreement_with_adjective_1_filtered": {
            "acc,none": 0.6538049303322615,
            "acc_stderr,none": 0.01558391528695933,
            "alias": "blimp_determiner_noun_agreement_with_adjective_1_filtered"
        },
        "inverse_scaling_pattern_matching_suppression": {
            "acc_norm_stderr,none": 0.012479056658905006,
            "acc,none": 0.3333333333333333,
            "acc_stderr,none": 0.012479056658905006,
            "acc_norm,none": 0.3333333333333333,
            "alias": "inverse_scaling_pattern_matching_suppression"
        },
        "openbookqa": {
            "acc_norm_stderr,none": 0.019586711785215868,
            "acc,none": 0.152,
            "acc_stderr,none": 0.016071982367911835,
            "acc_norm,none": 0.258,
            "alias": "openbookqa"
        },
        "blimp_tough_vs_raising_1_filtered": {
            "acc,none": 0.3059071729957806,
            "acc_stderr,none": 0.01497368245691408,
            "alias": "blimp_tough_vs_raising_1_filtered"
        },
        "inverse_scaling_repetitive_algebra": {
            "acc_norm_stderr,none": 0.01581217964181488,
            "acc,none": 0.505,
            "acc_stderr,none": 0.015818508944436743,
            "acc_norm,none": 0.515,
            "alias": "inverse_scaling_repetitive_algebra"
        },
        "tinyGSM8k": {
            "exact_match_stderr,flexible-extract": "N/A",
            "exact_match,strict-match": 0.005531037620360234,
            "exact_match_stderr,strict-match": "N/A",
            "exact_match,flexible-extract": 0.005531037620360234,
            "alias": "tinyGSM8k"
        },
        "blimp_animate_subject_trans_filtered": {
            "acc,none": 0.8223185265438786,
            "acc_stderr,none": 0.01258854829623758,
            "alias": "blimp_animate_subject_trans_filtered"
        },
        "blimp_determiner_noun_agreement_1_filtered": {
            "acc,none": 0.6243272335844995,
            "acc_stderr,none": 0.015897799233306704,
            "alias": "blimp_determiner_noun_agreement_1_filtered"
        },
        "arc_challenge": {
            "acc_norm_stderr,none": 0.013179442447653811,
            "acc,none": 0.23122866894197952,
            "acc_stderr,none": 0.01232085883477234,
            "acc_norm,none": 0.2841296928327645,
            "alias": "arc_challenge"
        },
        "inverse_scaling_sig_figs": {
            "acc_norm_stderr,none": 0.0033856123020969946,
            "acc,none": 0.39761688280614443,
            "acc_stderr,none": 0.0033856123020969946,
            "acc_norm,none": 0.39761688280614443,
            "alias": "inverse_scaling_sig_figs"
        },
        "lambada_openai": {
            "perplexity_stderr,none": 5628121.753343449,
            "acc,none": 0.0,
            "perplexity,none": 51957535.507340536,
            "acc_stderr,none": 0.0,
            "alias": "lambada_openai"
        },
        "blimp_wh_vs_that_no_gap_filtered": {
            "acc,none": 0.778164924506388,
            "acc_stderr,none": 0.014167776851024067,
            "alias": "blimp_wh_vs_that_no_gap_filtered"
        },
        "mathqa": {
            "acc_norm_stderr,none": 0.00734997377958385,
            "acc,none": 0.20033500837520937,
            "acc_stderr,none": 0.007327115822178604,
            "acc_norm,none": 0.2020100502512563,
            "alias": "mathqa"
        },
        "blimp_determiner_noun_agreement_2_filtered": {
            "acc,none": 0.7110633727175081,
            "acc_stderr,none": 0.014863256734295513,
            "alias": "blimp_determiner_noun_agreement_2_filtered"
        },
        "blimp_regular_plural_subject_verb_agreement_1_filtered": {
            "acc,none": 0.6460674157303371,
            "acc_stderr,none": 0.01603792994497664,
            "alias": "blimp_regular_plural_subject_verb_agreement_1_filtered"
        },
        "squad_completion": {
            "contains_stderr,none": "N/A",
            "contains,none": 0.0,
            "alias": "squad_completion"
        },
        "cola": {
            "mcc_stderr,none": 0.0,
            "mcc,none": 0.0,
            "alias": "cola"
        },
        "tinyTruthfulQA": {
            "acc,none": 0.48664107424897207,
            "acc_stderr,none": "N/A",
            "alias": "tinyTruthfulQA"
        },
        "blimp_irregular_plural_subject_verb_agreement_2_filtered": {
            "acc,none": 0.7141255605381166,
            "acc_stderr,none": 0.015136870658695909,
            "alias": "blimp_irregular_plural_subject_verb_agreement_2_filtered"
        },
        "blimp_superlative_quantifiers_2_filtered": {
            "acc,none": 0.7545638945233266,
            "acc_stderr,none": 0.013711946830903312,
            "alias": "blimp_superlative_quantifiers_2_filtered"
        },
        "deepmind-math-small-tiny": {
            "perplexity_stderr,none": 5.0053332333943033e+36,
            "acc,none": 0.0,
            "perplexity,none": 2.5842534157292665e+36,
            "acc_stderr,none": 0.0,
            "alias": " - deepmind-math-small-tiny"
        },
        "rte": {
            "acc,none": 0.5270758122743683,
            "acc_stderr,none": 0.030052303463143734,
            "alias": "rte"
        },
        "mnli": {
            "acc,none": 0.3544574630667346,
            "acc_stderr,none": 0.004828602644595183,
            "alias": "mnli"
        },
        "blimp_expletive_it_object_raising_filtered": {
            "acc,none": 0.6745718050065876,
            "acc_stderr,none": 0.01701794353729163,
            "alias": "blimp_expletive_it_object_raising_filtered"
        },
        "winogrande": {
            "acc,none": 0.4877663772691397,
            "acc_stderr,none": 0.01404827882040573,
            "alias": "winogrande"
        },
        "blimp_determiner_noun_agreement_irregular_2_filtered": {
            "acc,none": 0.7146341463414634,
            "acc_stderr,none": 0.015779779615643558,
            "alias": "blimp_determiner_noun_agreement_irregular_2_filtered"
        },
        "triviaqa": {
            "exact_match_stderr,remove_whitespace": 0.00011144855087437195,
            "exact_match,remove_whitespace": 0.00022291573785109228,
            "alias": "triviaqa"
        },
        "blimp_supplement_subject_aux_inversion": {
            "acc,none": 0.8210499094905611,
            "acc_stderr,none": 0.006164811688923,
            "alias": "blimp_supplement_subject_aux_inversion"
        },
        "blimp_passive_1_filtered": {
            "acc,none": 0.6440476190476191,
            "acc_stderr,none": 0.016530042121747197,
            "alias": "blimp_passive_1_filtered"
        },
        "cosmopedia-v2-tiny": {
            "perplexity_stderr,none": 4.992613037813908e+19,
            "acc,none": 0.0,
            "perplexity,none": 4409632638543.798,
            "acc_stderr,none": 0.0,
            "alias": " - cosmopedia-v2-tiny"
        },
        "blimp_wh_island_filtered": {
            "acc,none": 0.7947916666666667,
            "acc_stderr,none": 0.013041118626887477,
            "alias": "blimp_wh_island_filtered"
        },
        "piqa": {
            "acc_norm_stderr,none": 0.011665713661738719,
            "acc,none": 0.530467899891186,
            "acc_stderr,none": 0.011644145418355097,
            "acc_norm,none": 0.5021762785636561,
            "alias": "piqa"
        },
        "blimp_supplement_hypernym": {
            "acc,none": 0.7007125890736342,
            "acc_stderr,none": 0.01579123827968839,
            "alias": "blimp_supplement_hypernym"
        },
        "blimp_distractor_agreement_relative_clause_filtered": {
            "acc,none": 0.7657864523536165,
            "acc_stderr,none": 0.014358207302744872,
            "alias": "blimp_distractor_agreement_relative_clause_filtered"
        },
        "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered": {
            "acc,none": 0.6935933147632312,
            "acc_stderr,none": 0.017216385941307026,
            "alias": "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered"
        },
        "blimp_inchoative_filtered": {
            "acc,none": 0.4982456140350877,
            "acc_stderr,none": 0.017109542447857635,
            "alias": "blimp_inchoative_filtered"
        },
        "blimp_irregular_past_participle_verbs_filtered": {
            "acc,none": 0.6475583864118896,
            "acc_stderr,none": 0.015573572351621842,
            "alias": "blimp_irregular_past_participle_verbs_filtered"
        },
        "blimp_only_npi_scope_filtered": {
            "acc,none": 0.45997610513739545,
            "acc_stderr,none": 0.0172373692694151,
            "alias": "blimp_only_npi_scope_filtered"
        },
        "smollm125-tiny": {
            " ": " ",
            "alias": "smollm125-tiny"
        },
        "qa4mre_2012": {
            "acc_norm_stderr,none": 0.03462157845865139,
            "acc,none": 0.125,
            "acc_stderr,none": 0.026227715908195403,
            "acc_norm,none": 0.25625,
            "alias": "qa4mre_2012"
        },
        "inverse_scaling_into_the_unknown": {
            "acc_norm_stderr,none": 0.011708730895408954,
            "acc,none": 0.5087719298245614,
            "acc_stderr,none": 0.011708730895408954,
            "acc_norm,none": 0.5087719298245614,
            "alias": "inverse_scaling_into_the_unknown"
        },
        "blimp_matrix_question_npi_licensor_present_filtered": {
            "acc,none": 0.6566200215285253,
            "acc_stderr,none": 0.015587287898357997,
            "alias": "blimp_matrix_question_npi_licensor_present_filtered"
        },
        "blimp_passive_2_filtered": {
            "acc,none": 0.6190476190476191,
            "acc_stderr,none": 0.01616940749692626,
            "alias": "blimp_passive_2_filtered"
        },
        "blimp_npi_present_2_filtered": {
            "acc,none": 0.7089715536105032,
            "acc_stderr,none": 0.015033037359333316,
            "alias": "blimp_npi_present_2_filtered"
        },
        "blimp_sentential_subject_island_filtered": {
            "acc,none": 0.7908428720083247,
            "acc_stderr,none": 0.013126405631158028,
            "alias": "blimp_sentential_subject_island_filtered"
        },
        "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered": {
            "acc,none": 0.7464285714285714,
            "acc_stderr,none": 0.015019770807758966,
            "alias": "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered"
        },
        "blimp_determiner_noun_agreement_irregular_1_filtered": {
            "acc,none": 0.644640234948605,
            "acc_stderr,none": 0.018354323197819586,
            "alias": "blimp_determiner_noun_agreement_irregular_1_filtered"
        },
        "blimp_supplement_qa_congruence_easy": {
            "acc,none": 0.484375,
            "acc_stderr,none": 0.06296331249416676,
            "alias": "blimp_supplement_qa_congruence_easy"
        },
        "fineweb-edu-dedup-tiny": {
            "perplexity_stderr,none": 438837620443264.4,
            "acc,none": 0.0,
            "perplexity,none": 129660096509163.39,
            "acc_stderr,none": 0.0,
            "alias": " - fineweb-edu-dedup-tiny"
        },
        "inverse_scaling_quote_repetition": {
            "acc_norm_stderr,none": 0.022056142680706676,
            "acc,none": 0.13666666666666666,
            "acc_stderr,none": 0.019864834973508133,
            "acc_norm,none": 0.17666666666666667,
            "alias": "inverse_scaling_quote_repetition"
        },
        "blimp_causative_filtered": {
            "acc,none": 0.5012224938875306,
            "acc_stderr,none": 0.017492733427822548,
            "alias": "blimp_causative_filtered"
        },
        "mnli_mismatch": {
            "acc,none": 0.3522172497965826,
            "acc_stderr,none": 0.004817493665633903,
            "alias": "mnli_mismatch"
        },
        "qnli": {
            "acc,none": 0.5053999633900788,
            "acc_stderr,none": 0.006765015986877416,
            "alias": "qnli"
        },
        "blimp_supplement_turn_taking": {
            "acc,none": 0.8464285714285714,
            "acc_stderr,none": 0.021584811872631983,
            "alias": "blimp_supplement_turn_taking"
        },
        "blimp_wh_vs_that_no_gap_long_distance_filtered": {
            "acc,none": 0.7874285714285715,
            "acc_stderr,none": 0.013838923663129485,
            "alias": "blimp_wh_vs_that_no_gap_long_distance_filtered"
        },
        "hellaswag": {
            "acc_norm_stderr,none": 0.004379051357024372,
            "acc,none": 0.2552280422226648,
            "acc_stderr,none": 0.004350982826580739,
            "acc_norm,none": 0.26030671181039633,
            "alias": "hellaswag"
        },
        "blimp_ellipsis_n_bar_1_filtered": {
            "acc,none": 0.816708229426434,
            "acc_stderr,none": 0.013670635096331308,
            "alias": "blimp_ellipsis_n_bar_1_filtered"
        },
        "blimp_animate_subject_passive_filtered": {
            "acc,none": 0.6703910614525139,
            "acc_stderr,none": 0.015721531075183818,
            "alias": "blimp_animate_subject_passive_filtered"
        },
        "blimp_coordinate_structure_constraint_complex_left_branch_filtered": {
            "acc,none": 0.7969094922737306,
            "acc_stderr,none": 0.013372882324128125,
            "alias": "blimp_coordinate_structure_constraint_complex_left_branch_filtered"
        },
        "blimp_intransitive_filtered": {
            "acc,none": 0.6877880184331797,
            "acc_stderr,none": 0.015737746194610408,
            "alias": "blimp_intransitive_filtered"
        },
        "inverse_scaling_neqa": {
            "acc_norm_stderr,none": 0.028806947219396185,
            "acc,none": 0.5433333333333333,
            "acc_stderr,none": 0.028806947219396185,
            "acc_norm,none": 0.5433333333333333,
            "alias": "inverse_scaling_neqa"
        },
        "blimp_sentential_negation_npi_scope_filtered": {
            "acc,none": 0.6842709529276694,
            "acc_stderr,none": 0.015758384592042502,
            "alias": "blimp_sentential_negation_npi_scope_filtered"
        },
        "inverse_scaling_winobias_antistereotype": {
            "acc_norm_stderr,none": 0.024621300279424427,
            "acc,none": 0.7184466019417476,
            "acc_stderr,none": 0.02218486157199594,
            "acc_norm,none": 0.529126213592233,
            "alias": "inverse_scaling_winobias_antistereotype"
        },
        "blimp_transitive_filtered": {
            "acc,none": 0.6094470046082949,
            "acc_stderr,none": 0.01656908062434921,
            "alias": "blimp_transitive_filtered"
        },
        "blimp_principle_A_case_1_filtered": {
            "acc,none": 0.8947368421052632,
            "acc_stderr,none": 0.010167792367560343,
            "alias": "blimp_principle_A_case_1_filtered"
        },
        "blimp_npi_present_1_filtered": {
            "acc,none": 0.7271727172717272,
            "acc_stderr,none": 0.014781542713333451,
            "alias": "blimp_npi_present_1_filtered"
        },
        "sciq": {
            "acc_norm_stderr,none": 0.012655439943366655,
            "acc,none": 0.188,
            "acc_stderr,none": 0.01236158601510376,
            "acc_norm,none": 0.2,
            "alias": "sciq"
        },
        "blimp_wh_vs_that_with_gap_long_distance_filtered": {
            "acc,none": 0.8263736263736263,
            "acc_stderr,none": 0.012563600837940647,
            "alias": "blimp_wh_vs_that_with_gap_long_distance_filtered"
        },
        "open-web-math-tiny": {
            "perplexity_stderr,none": 1.739264687536258e+40,
            "acc,none": 0.0,
            "perplexity,none": 2.859187753305744e+26,
            "acc_stderr,none": 0.0,
            "alias": " - open-web-math-tiny"
        },
        "blimp_tough_vs_raising_2_filtered": {
            "acc,none": 0.9434782608695652,
            "acc_stderr,none": 0.007617561187847777,
            "alias": "blimp_tough_vs_raising_2_filtered"
        },
        "qqp": {
            "acc,none": 0.6318327974276527,
            "acc_stderr,none": 0.0023987066106141842,
            "alias": "qqp"
        },
        "blimp_wh_questions_subject_gap_long_distance_filtered": {
            "acc,none": 0.7281213535589265,
            "acc_stderr,none": 0.015207315322280443,
            "alias": "blimp_wh_questions_subject_gap_long_distance_filtered"
        },
        "blimp_existential_there_quantifiers_1_filtered": {
            "acc,none": 0.7354838709677419,
            "acc_stderr,none": 0.014471208433819042,
            "alias": "blimp_existential_there_quantifiers_1_filtered"
        },
        "inverse_scaling_memo_trap": {
            "acc_norm_stderr,none": 0.01630329877250074,
            "acc,none": 0.561965811965812,
            "acc_stderr,none": 0.016225688952270955,
            "acc_norm,none": 0.5384615384615384,
            "alias": "inverse_scaling_memo_trap"
        },
        "blimp_principle_A_domain_2_filtered": {
            "acc,none": 0.8098360655737705,
            "acc_stderr,none": 0.012980443650468297,
            "alias": "blimp_principle_A_domain_2_filtered"
        },
        "blimp_wh_questions_subject_gap_filtered": {
            "acc,none": 0.7182628062360802,
            "acc_stderr,none": 0.015019917932088688,
            "alias": "blimp_wh_questions_subject_gap_filtered"
        },
        "blimp_anaphor_number_agreement_filtered": {
            "acc,none": 0.6809881847475833,
            "acc_stderr,none": 0.015283812400241611,
            "alias": "blimp_anaphor_number_agreement_filtered"
        },
        "inverse_scaling_hindsight_neglect_10shot": {
            "acc_norm_stderr,none": 0.028079660068225168,
            "acc,none": 0.5492063492063493,
            "acc_stderr,none": 0.028079660068225168,
            "acc_norm,none": 0.5492063492063493,
            "alias": "inverse_scaling_hindsight_neglect_10shot"
        },
        "blimp_principle_A_case_2_filtered": {
            "acc,none": 0.6185792349726776,
            "acc_stderr,none": 0.016066701945794074,
            "alias": "blimp_principle_A_case_2_filtered"
        },
        "arc_easy": {
            "acc_norm_stderr,none": 0.009020523527210056,
            "acc,none": 0.25841750841750843,
            "acc_stderr,none": 0.008982741341291388,
            "acc_norm,none": 0.2617845117845118,
            "alias": "arc_easy"
        },
        "blimp_coordinate_structure_constraint_object_extraction_filtered": {
            "acc,none": 0.6195995785036881,
            "acc_stderr,none": 0.01576782832699275,
            "alias": "blimp_coordinate_structure_constraint_object_extraction_filtered"
        },
        "blimp_adjunct_island_filtered": {
            "acc,none": 0.7392241379310345,
            "acc_stderr,none": 0.014420552419114933,
            "alias": "blimp_adjunct_island_filtered"
        },
        "blimp_sentential_negation_npi_licensor_present_filtered": {
            "acc,none": 0.8139281828073993,
            "acc_stderr,none": 0.012844346180359649,
            "alias": "blimp_sentential_negation_npi_licensor_present_filtered"
        },
        "qa4mre_2013": {
            "acc_norm_stderr,none": 0.02209080510658784,
            "acc,none": 0.22887323943661972,
            "acc_stderr,none": 0.024972796486048474,
            "acc_norm,none": 0.16549295774647887,
            "alias": "qa4mre_2013"
        },
        "sst2": {
            "acc,none": 0.4908256880733945,
            "acc_stderr,none": 0.016939001525351462,
            "alias": "sst2"
        },
        "stackoverflow-clean-tiny": {
            "perplexity_stderr,none": 193759126.22397074,
            "acc,none": 0.0,
            "perplexity,none": 279060036.15827143,
            "acc_stderr,none": 0.0,
            "alias": " - stackoverflow-clean-tiny"
        },
        "blimp_principle_A_reconstruction_filtered": {
            "acc,none": 0.7383660806618407,
            "acc_stderr,none": 0.014141462596874191,
            "alias": "blimp_principle_A_reconstruction_filtered"
        },
        "blimp_supplement_qa_congruence_tricky": {
            "acc,none": 0.41818181818181815,
            "acc_stderr,none": 0.03851716319398397,
            "alias": "blimp_supplement_qa_congruence_tricky"
        },
        "blimp_principle_A_domain_3_filtered": {
            "acc,none": 0.720510095642933,
            "acc_stderr,none": 0.014636565175176006,
            "alias": "blimp_principle_A_domain_3_filtered"
        },
        "mrpc": {
            "acc,none": 0.3161764705882353,
            "acc_stderr,none": 0.023048336668420145,
            "alias": "mrpc"
        },
        "blimp_determiner_noun_agreement_with_adj_2_filtered": {
            "acc,none": 0.718384697130712,
            "acc_stderr,none": 0.014670426325555081,
            "alias": "blimp_determiner_noun_agreement_with_adj_2_filtered"
        },
        "swag": {
            "acc_norm_stderr,none": 0.003077729223276588,
            "acc,none": 0.2660201939418175,
            "acc_stderr,none": 0.0031241370744149225,
            "acc_norm,none": 0.2540237928621414,
            "alias": "swag"
        },
        "wnli": {
            "acc,none": 0.43661971830985913,
            "acc_stderr,none": 0.05927935558412972,
            "alias": "wnli"
        },
        "blimp_wh_vs_that_with_gap_filtered": {
            "acc,none": 0.779107725788901,
            "acc_stderr,none": 0.013692024832511232,
            "alias": "blimp_wh_vs_that_with_gap_filtered"
        },
        "blimp_anaphor_gender_agreement_filtered": {
            "acc,none": 0.5200823892893924,
            "acc_stderr,none": 0.016041077991658263,
            "alias": "blimp_anaphor_gender_agreement_filtered"
        },
        "qa4mre_2011": {
            "acc_norm_stderr,none": 0.032732683535398856,
            "acc,none": 0.13333333333333333,
            "acc_stderr,none": 0.03116175682952018,
            "acc_norm,none": 0.15,
            "alias": "qa4mre_2011"
        },
        "blimp_ellipsis_n_bar_2_filtered": {
            "acc,none": 0.39009661835748793,
            "acc_stderr,none": 0.016961484454536987,
            "alias": "blimp_ellipsis_n_bar_2_filtered"
        },
        "blimp_left_branch_island_echo_question_filtered": {
            "acc,none": 0.7412882787750792,
            "acc_stderr,none": 0.014238231538440463,
            "alias": "blimp_left_branch_island_echo_question_filtered"
        },
        "blimp_existential_there_object_raising_filtered": {
            "acc,none": 0.8152709359605911,
            "acc_stderr,none": 0.013627248259106835,
            "alias": "blimp_existential_there_object_raising_filtered"
        },
        "tinyMMLU": {
            "acc_norm_stderr,none": "N/A",
            "acc_norm,none": 0.3264060280808534,
            "alias": "tinyMMLU"
        },
        "blimp_wh_questions_object_gap_filtered": {
            "acc,none": 0.719441210710128,
            "acc_stderr,none": 0.015337901735660128,
            "alias": "blimp_wh_questions_object_gap_filtered"
        },
        "python-edu-tiny": {
            "perplexity_stderr,none": 1.2391803614116033e+49,
            "acc,none": 0.0,
            "perplexity,none": 3.126396015079549e+44,
            "acc_stderr,none": 0.0,
            "alias": " - python-edu-tiny"
        },
        "blimp_irregular_plural_subject_verb_agreement_1_filtered": {
            "acc,none": 0.6703980099502488,
            "acc_stderr,none": 0.016588361769866358,
            "alias": "blimp_irregular_plural_subject_verb_agreement_1_filtered"
        },
        "blimp_irregular_past_participle_adjectives_filtered": {
            "acc,none": 0.7575442247658689,
            "acc_stderr,none": 0.013831989353252376,
            "alias": "blimp_irregular_past_participle_adjectives_filtered"
        },
        "blimp_regular_plural_subject_verb_agreement_2_filtered": {
            "acc,none": 0.6158730158730159,
            "acc_stderr,none": 0.015830586283151916,
            "alias": "blimp_regular_plural_subject_verb_agreement_2_filtered"
        },
        "blimp_distractor_agreement_relational_noun_filtered": {
            "acc,none": 0.7385786802030457,
            "acc_stderr,none": 0.015663236984228637,
            "alias": "blimp_distractor_agreement_relational_noun_filtered"
        },
        "blimp_existential_there_subject_raising_filtered": {
            "acc,none": 0.8127705627705628,
            "acc_stderr,none": 0.012840152988974311,
            "alias": "blimp_existential_there_subject_raising_filtered"
        },
        "blimp_principle_A_domain_1_filtered": {
            "acc,none": 0.9442013129102844,
            "acc_stderr,none": 0.0075964188260023765,
            "alias": "blimp_principle_A_domain_1_filtered"
        },
        "inverse_scaling_modus_tollens": {
            "acc_norm_stderr,none": 0.0,
            "acc,none": 0.0,
            "acc_stderr,none": 0.0,
            "acc_norm,none": 1.0,
            "alias": "inverse_scaling_modus_tollens"
        },
        "blimp_left_branch_island_simple_question_filtered": {
            "acc,none": 0.6614090431125131,
            "acc_stderr,none": 0.015353625349408621,
            "alias": "blimp_left_branch_island_simple_question_filtered"
        },
        "wsc273": {
            "acc,none": 0.4981684981684982,
            "acc_stderr,none": 0.030316749738547345,
            "alias": "wsc273"
        },
        "blimp_existential_there_quantifiers_2_filtered": {
            "acc,none": 0.6904500548847421,
            "acc_stderr,none": 0.015325364187071451,
            "alias": "blimp_existential_there_quantifiers_2_filtered"
        },
        "blimp_complex_NP_island_filtered": {
            "acc,none": 0.8226950354609929,
            "acc_stderr,none": 0.01313867384483611,
            "alias": "blimp_complex_NP_island_filtered"
        },
        "blimp_superlative_quantifiers_1_filtered": {
            "acc,none": 0.5362614913176711,
            "acc_stderr,none": 0.01594613582335065,
            "alias": "blimp_superlative_quantifiers_1_filtered"
        },
        "blimp_principle_A_c_command_filtered": {
            "acc,none": 0.758985200845666,
            "acc_stderr,none": 0.013913058300113596,
            "alias": "blimp_principle_A_c_command_filtered"
        },
        "inverse_scaling_redefine_math": {
            "acc_norm_stderr,none": 0.01641694848915767,
            "acc,none": 0.4122222222222222,
            "acc_stderr,none": 0.01641694848915767,
            "acc_norm,none": 0.4122222222222222,
            "alias": "inverse_scaling_redefine_math"
        },
        "blimp_drop_argument_filtered": {
            "acc,none": 0.7576086956521739,
            "acc_stderr,none": 0.014135892621289866,
            "alias": "blimp_drop_argument_filtered"
        }
    },
    "model_name_sanitized": "random__14M__random",
    "chat_template": null,
    "date": 1728199428.0685463,
    "max_length": 2048,
    "n-shot": {
        "blimp_only_npi_licensor_present_filtered": 0,
        "blimp_determiner_noun_agreement_with_adjective_1_filtered": 0,
        "inverse_scaling_pattern_matching_suppression": 0,
        "openbookqa": 0,
        "blimp_tough_vs_raising_1_filtered": 0,
        "inverse_scaling_repetitive_algebra": 0,
        "tinyGSM8k": 5,
        "blimp_animate_subject_trans_filtered": 0,
        "blimp_determiner_noun_agreement_1_filtered": 0,
        "arc_challenge": 0,
        "inverse_scaling_sig_figs": 0,
        "lambada_openai": 0,
        "blimp_wh_vs_that_no_gap_filtered": 0,
        "mathqa": 0,
        "blimp_determiner_noun_agreement_2_filtered": 0,
        "blimp_regular_plural_subject_verb_agreement_1_filtered": 0,
        "squad_completion": 0,
        "cola": 0,
        "tinyTruthfulQA": 0,
        "blimp_irregular_plural_subject_verb_agreement_2_filtered": 0,
        "blimp_superlative_quantifiers_2_filtered": 0,
        "deepmind-math-small-tiny": 0,
        "rte": 0,
        "mnli": 0,
        "blimp_expletive_it_object_raising_filtered": 0,
        "winogrande": 0,
        "blimp_determiner_noun_agreement_irregular_2_filtered": 0,
        "triviaqa": 0,
        "blimp_supplement_subject_aux_inversion": 0,
        "blimp_passive_1_filtered": 0,
        "cosmopedia-v2-tiny": 0,
        "blimp_wh_island_filtered": 0,
        "piqa": 0,
        "blimp_supplement_hypernym": 0,
        "blimp_distractor_agreement_relative_clause_filtered": 0,
        "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered": 0,
        "blimp_inchoative_filtered": 0,
        "blimp_irregular_past_participle_verbs_filtered": 0,
        "blimp_only_npi_scope_filtered": 0,
        "qa4mre_2012": 0,
        "inverse_scaling_into_the_unknown": 0,
        "blimp_matrix_question_npi_licensor_present_filtered": 0,
        "blimp_passive_2_filtered": 0,
        "blimp_npi_present_2_filtered": 0,
        "blimp_sentential_subject_island_filtered": 0,
        "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered": 0,
        "blimp_determiner_noun_agreement_irregular_1_filtered": 0,
        "blimp_supplement_qa_congruence_easy": 0,
        "fineweb-edu-dedup-tiny": 0,
        "inverse_scaling_quote_repetition": 0,
        "blimp_causative_filtered": 0,
        "mnli_mismatch": 0,
        "qnli": 0,
        "blimp_supplement_turn_taking": 0,
        "blimp_wh_vs_that_no_gap_long_distance_filtered": 0,
        "hellaswag": 0,
        "blimp_ellipsis_n_bar_1_filtered": 0,
        "blimp_animate_subject_passive_filtered": 0,
        "blimp_coordinate_structure_constraint_complex_left_branch_filtered": 0,
        "blimp_intransitive_filtered": 0,
        "inverse_scaling_neqa": 0,
        "blimp_sentential_negation_npi_scope_filtered": 0,
        "inverse_scaling_winobias_antistereotype": 0,
        "blimp_transitive_filtered": 0,
        "blimp_principle_A_case_1_filtered": 0,
        "blimp_npi_present_1_filtered": 0,
        "sciq": 0,
        "blimp_wh_vs_that_with_gap_long_distance_filtered": 0,
        "open-web-math-tiny": 0,
        "blimp_tough_vs_raising_2_filtered": 0,
        "qqp": 0,
        "blimp_wh_questions_subject_gap_long_distance_filtered": 0,
        "blimp_existential_there_quantifiers_1_filtered": 0,
        "inverse_scaling_memo_trap": 0,
        "blimp_principle_A_domain_2_filtered": 0,
        "blimp_wh_questions_subject_gap_filtered": 0,
        "blimp_anaphor_number_agreement_filtered": 0,
        "inverse_scaling_hindsight_neglect_10shot": 0,
        "blimp_principle_A_case_2_filtered": 0,
        "arc_easy": 0,
        "blimp_coordinate_structure_constraint_object_extraction_filtered": 0,
        "blimp_adjunct_island_filtered": 0,
        "blimp_sentential_negation_npi_licensor_present_filtered": 0,
        "qa4mre_2013": 0,
        "sst2": 0,
        "stackoverflow-clean-tiny": 0,
        "blimp_principle_A_reconstruction_filtered": 0,
        "blimp_supplement_qa_congruence_tricky": 0,
        "blimp_principle_A_domain_3_filtered": 0,
        "mrpc": 0,
        "blimp_determiner_noun_agreement_with_adj_2_filtered": 0,
        "swag": 0,
        "wnli": 0,
        "blimp_wh_vs_that_with_gap_filtered": 0,
        "blimp_anaphor_gender_agreement_filtered": 0,
        "qa4mre_2011": 0,
        "blimp_ellipsis_n_bar_2_filtered": 0,
        "blimp_left_branch_island_echo_question_filtered": 0,
        "blimp_existential_there_object_raising_filtered": 0,
        "blimp_irregular_plural_subject_verb_agreement_1_filtered": 0,
        "tinyMMLU": 0,
        "blimp_wh_questions_object_gap_filtered": 0,
        "python-edu-tiny": 0,
        "blimp_irregular_past_participle_adjectives_filtered": 0,
        "blimp_regular_plural_subject_verb_agreement_2_filtered": 0,
        "blimp_distractor_agreement_relational_noun_filtered": 0,
        "blimp_existential_there_subject_raising_filtered": 0,
        "blimp_principle_A_domain_1_filtered": 0,
        "inverse_scaling_modus_tollens": 0,
        "blimp_left_branch_island_simple_question_filtered": 0,
        "wsc273": 0,
        "blimp_existential_there_quantifiers_2_filtered": 0,
        "blimp_complex_NP_island_filtered": 0,
        "blimp_superlative_quantifiers_1_filtered": 0,
        "blimp_principle_A_c_command_filtered": 0,
        "inverse_scaling_redefine_math": 0,
        "blimp_drop_argument_filtered": 0
    },
    "chat_template_sha": null,
    "system_instruction": null,
    "higher_is_better": {
        "blimp_only_npi_licensor_present_filtered": {
            "acc": true
        },
        "blimp_determiner_noun_agreement_with_adjective_1_filtered": {
            "acc": true
        },
        "inverse_scaling_pattern_matching_suppression": {
            "acc_norm": true,
            "acc": true
        },
        "openbookqa": {
            "acc_norm": true,
            "acc": true
        },
        "blimp_tough_vs_raising_1_filtered": {
            "acc": true
        },
        "inverse_scaling_repetitive_algebra": {
            "acc_norm": true,
            "acc": true
        },
        "tinyGSM8k": {
            "exact_match": true
        },
        "blimp_animate_subject_trans_filtered": {
            "acc": true
        },
        "blimp_determiner_noun_agreement_1_filtered": {
            "acc": true
        },
        "arc_challenge": {
            "acc_norm": true,
            "acc": true
        },
        "inverse_scaling_sig_figs": {
            "acc_norm": true,
            "acc": true
        },
        "lambada_openai": {
            "acc": true,
            "perplexity": false
        },
        "blimp_wh_vs_that_no_gap_filtered": {
            "acc": true
        },
        "mathqa": {
            "acc_norm": true,
            "acc": true
        },
        "blimp_determiner_noun_agreement_2_filtered": {
            "acc": true
        },
        "blimp_regular_plural_subject_verb_agreement_1_filtered": {
            "acc": true
        },
        "squad_completion": {
            "contains": true
        },
        "cola": {
            "mcc": true
        },
        "tinyTruthfulQA": {
            "acc": true
        },
        "blimp_irregular_plural_subject_verb_agreement_2_filtered": {
            "acc": true
        },
        "blimp_superlative_quantifiers_2_filtered": {
            "acc": true
        },
        "deepmind-math-small-tiny": {
            "acc": true,
            "perplexity": false
        },
        "rte": {
            "acc": true
        },
        "mnli": {
            "acc": true
        },
        "blimp_expletive_it_object_raising_filtered": {
            "acc": true
        },
        "winogrande": {
            "acc": true
        },
        "blimp_determiner_noun_agreement_irregular_2_filtered": {
            "acc": true
        },
        "triviaqa": {
            "exact_match": true
        },
        "blimp_supplement_subject_aux_inversion": {
            "acc": true
        },
        "blimp_passive_1_filtered": {
            "acc": true
        },
        "cosmopedia-v2-tiny": {
            "acc": true,
            "perplexity": false
        },
        "blimp_wh_island_filtered": {
            "acc": true
        },
        "piqa": {
            "acc_norm": true,
            "acc": true
        },
        "blimp_supplement_hypernym": {
            "acc": true
        },
        "blimp_distractor_agreement_relative_clause_filtered": {
            "acc": true
        },
        "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered": {
            "acc": true
        },
        "blimp_inchoative_filtered": {
            "acc": true
        },
        "blimp_irregular_past_participle_verbs_filtered": {
            "acc": true
        },
        "blimp_only_npi_scope_filtered": {
            "acc": true
        },
        "smollm125-tiny": {
            "acc": true,
            "perplexity": false
        },
        "qa4mre_2012": {
            "acc_norm": true,
            "acc": true
        },
        "inverse_scaling_into_the_unknown": {
            "acc_norm": true,
            "acc": true
        },
        "blimp_matrix_question_npi_licensor_present_filtered": {
            "acc": true
        },
        "blimp_passive_2_filtered": {
            "acc": true
        },
        "blimp_npi_present_2_filtered": {
            "acc": true
        },
        "blimp_sentential_subject_island_filtered": {
            "acc": true
        },
        "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered": {
            "acc": true
        },
        "blimp_determiner_noun_agreement_irregular_1_filtered": {
            "acc": true
        },
        "blimp_supplement_qa_congruence_easy": {
            "acc": true
        },
        "fineweb-edu-dedup-tiny": {
            "acc": true,
            "perplexity": false
        },
        "inverse_scaling_quote_repetition": {
            "acc_norm": true,
            "acc": true
        },
        "blimp_causative_filtered": {
            "acc": true
        },
        "mnli_mismatch": {
            "acc": true
        },
        "qnli": {
            "acc": true
        },
        "blimp_supplement_turn_taking": {
            "acc": true
        },
        "blimp_wh_vs_that_no_gap_long_distance_filtered": {
            "acc": true
        },
        "hellaswag": {
            "acc_norm": true,
            "acc": true
        },
        "blimp_ellipsis_n_bar_1_filtered": {
            "acc": true
        },
        "blimp_animate_subject_passive_filtered": {
            "acc": true
        },
        "blimp_coordinate_structure_constraint_complex_left_branch_filtered": {
            "acc": true
        },
        "blimp_intransitive_filtered": {
            "acc": true
        },
        "inverse_scaling_neqa": {
            "acc_norm": true,
            "acc": true
        },
        "blimp_sentential_negation_npi_scope_filtered": {
            "acc": true
        },
        "inverse_scaling_winobias_antistereotype": {
            "acc_norm": true,
            "acc": true
        },
        "blimp_transitive_filtered": {
            "acc": true
        },
        "blimp_principle_A_case_1_filtered": {
            "acc": true
        },
        "blimp_npi_present_1_filtered": {
            "acc": true
        },
        "sciq": {
            "acc_norm": true,
            "acc": true
        },
        "blimp_wh_vs_that_with_gap_long_distance_filtered": {
            "acc": true
        },
        "open-web-math-tiny": {
            "acc": true,
            "perplexity": false
        },
        "blimp_tough_vs_raising_2_filtered": {
            "acc": true
        },
        "qqp": {
            "acc": true
        },
        "blimp_wh_questions_subject_gap_long_distance_filtered": {
            "acc": true
        },
        "blimp_existential_there_quantifiers_1_filtered": {
            "acc": true
        },
        "inverse_scaling_memo_trap": {
            "acc_norm": true,
            "acc": true
        },
        "blimp_principle_A_domain_2_filtered": {
            "acc": true
        },
        "blimp_wh_questions_subject_gap_filtered": {
            "acc": true
        },
        "blimp_anaphor_number_agreement_filtered": {
            "acc": true
        },
        "inverse_scaling_hindsight_neglect_10shot": {
            "acc_norm": true,
            "acc": true
        },
        "blimp_principle_A_case_2_filtered": {
            "acc": true
        },
        "arc_easy": {
            "acc_norm": true,
            "acc": true
        },
        "blimp_coordinate_structure_constraint_object_extraction_filtered": {
            "acc": true
        },
        "blimp_adjunct_island_filtered": {
            "acc": true
        },
        "blimp_sentential_negation_npi_licensor_present_filtered": {
            "acc": true
        },
        "qa4mre_2013": {
            "acc_norm": true,
            "acc": true
        },
        "sst2": {
            "acc": true
        },
        "stackoverflow-clean-tiny": {
            "acc": true,
            "perplexity": false
        },
        "blimp_principle_A_reconstruction_filtered": {
            "acc": true
        },
        "blimp_supplement_qa_congruence_tricky": {
            "acc": true
        },
        "blimp_principle_A_domain_3_filtered": {
            "acc": true
        },
        "mrpc": {
            "acc": true
        },
        "blimp_determiner_noun_agreement_with_adj_2_filtered": {
            "acc": true
        },
        "swag": {
            "acc_norm": true,
            "acc": true
        },
        "wnli": {
            "acc": true
        },
        "blimp_wh_vs_that_with_gap_filtered": {
            "acc": true
        },
        "blimp_anaphor_gender_agreement_filtered": {
            "acc": true
        },
        "qa4mre_2011": {
            "acc_norm": true,
            "acc": true
        },
        "blimp_ellipsis_n_bar_2_filtered": {
            "acc": true
        },
        "blimp_left_branch_island_echo_question_filtered": {
            "acc": true
        },
        "blimp_existential_there_object_raising_filtered": {
            "acc": true
        },
        "tinyMMLU": {
            "acc_norm": true
        },
        "blimp_wh_questions_object_gap_filtered": {
            "acc": true
        },
        "python-edu-tiny": {
            "acc": true,
            "perplexity": false
        },
        "blimp_irregular_plural_subject_verb_agreement_1_filtered": {
            "acc": true
        },
        "blimp_irregular_past_participle_adjectives_filtered": {
            "acc": true
        },
        "blimp_regular_plural_subject_verb_agreement_2_filtered": {
            "acc": true
        },
        "blimp_distractor_agreement_relational_noun_filtered": {
            "acc": true
        },
        "blimp_existential_there_subject_raising_filtered": {
            "acc": true
        },
        "blimp_principle_A_domain_1_filtered": {
            "acc": true
        },
        "inverse_scaling_modus_tollens": {
            "acc_norm": true,
            "acc": true
        },
        "blimp_left_branch_island_simple_question_filtered": {
            "acc": true
        },
        "wsc273": {
            "acc": true
        },
        "blimp_existential_there_quantifiers_2_filtered": {
            "acc": true
        },
        "blimp_complex_NP_island_filtered": {
            "acc": true
        },
        "blimp_superlative_quantifiers_1_filtered": {
            "acc": true
        },
        "blimp_principle_A_c_command_filtered": {
            "acc": true
        },
        "inverse_scaling_redefine_math": {
            "acc_norm": true,
            "acc": true
        },
        "blimp_drop_argument_filtered": {
            "acc": true
        }
    },
    "n-samples": {
        "blimp_only_npi_licensor_present_filtered": {
            "original": 882,
            "effective": 882
        },
        "blimp_determiner_noun_agreement_with_adjective_1_filtered": {
            "original": 933,
            "effective": 933
        },
        "inverse_scaling_pattern_matching_suppression": {
            "original": 1428,
            "effective": 1428
        },
        "openbookqa": {
            "original": 500,
            "effective": 500
        },
        "blimp_tough_vs_raising_1_filtered": {
            "original": 948,
            "effective": 948
        },
        "inverse_scaling_repetitive_algebra": {
            "original": 1000,
            "effective": 1000
        },
        "tinyGSM8k": {
            "original": 100,
            "effective": 100
        },
        "blimp_animate_subject_trans_filtered": {
            "original": 923,
            "effective": 923
        },
        "blimp_determiner_noun_agreement_1_filtered": {
            "original": 929,
            "effective": 929
        },
        "arc_challenge": {
            "original": 1172,
            "effective": 1172
        },
        "inverse_scaling_sig_figs": {
            "original": 20897,
            "effective": 20897
        },
        "lambada_openai": {
            "original": 5153,
            "effective": 5153
        },
        "blimp_wh_vs_that_no_gap_filtered": {
            "original": 861,
            "effective": 861
        },
        "mathqa": {
            "original": 2985,
            "effective": 2985
        },
        "blimp_determiner_noun_agreement_2_filtered": {
            "original": 931,
            "effective": 931
        },
        "blimp_regular_plural_subject_verb_agreement_1_filtered": {
            "original": 890,
            "effective": 890
        },
        "squad_completion": {
            "original": 2984,
            "effective": 2984
        },
        "cola": {
            "original": 1043,
            "effective": 1043
        },
        "tinyTruthfulQA": {
            "original": 100,
            "effective": 100
        },
        "blimp_irregular_plural_subject_verb_agreement_2_filtered": {
            "original": 892,
            "effective": 892
        },
        "blimp_superlative_quantifiers_2_filtered": {
            "original": 986,
            "effective": 986
        },
        "deepmind-math-small-tiny": {
            "original": 1000,
            "effective": 1000
        },
        "rte": {
            "original": 277,
            "effective": 277
        },
        "mnli": {
            "original": 9815,
            "effective": 9815
        },
        "blimp_expletive_it_object_raising_filtered": {
            "original": 759,
            "effective": 759
        },
        "winogrande": {
            "original": 1267,
            "effective": 1267
        },
        "blimp_determiner_noun_agreement_irregular_2_filtered": {
            "original": 820,
            "effective": 820
        },
        "triviaqa": {
            "original": 17944,
            "effective": 17944
        },
        "blimp_supplement_subject_aux_inversion": {
            "original": 3867,
            "effective": 3867
        },
        "blimp_passive_1_filtered": {
            "original": 840,
            "effective": 840
        },
        "cosmopedia-v2-tiny": {
            "original": 1000,
            "effective": 1000
        },
        "blimp_wh_island_filtered": {
            "original": 960,
            "effective": 960
        },
        "piqa": {
            "original": 1838,
            "effective": 1838
        },
        "blimp_supplement_hypernym": {
            "original": 842,
            "effective": 842
        },
        "blimp_distractor_agreement_relative_clause_filtered": {
            "original": 871,
            "effective": 871
        },
        "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered": {
            "original": 718,
            "effective": 718
        },
        "blimp_inchoative_filtered": {
            "original": 855,
            "effective": 855
        },
        "blimp_irregular_past_participle_verbs_filtered": {
            "original": 942,
            "effective": 942
        },
        "blimp_only_npi_scope_filtered": {
            "original": 837,
            "effective": 837
        },
        "qa4mre_2012": {
            "original": 160,
            "effective": 160
        },
        "inverse_scaling_into_the_unknown": {
            "original": 1824,
            "effective": 1824
        },
        "blimp_matrix_question_npi_licensor_present_filtered": {
            "original": 929,
            "effective": 929
        },
        "blimp_passive_2_filtered": {
            "original": 903,
            "effective": 903
        },
        "blimp_npi_present_2_filtered": {
            "original": 914,
            "effective": 914
        },
        "blimp_sentential_subject_island_filtered": {
            "original": 961,
            "effective": 961
        },
        "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered": {
            "original": 840,
            "effective": 840
        },
        "blimp_determiner_noun_agreement_irregular_1_filtered": {
            "original": 681,
            "effective": 681
        },
        "blimp_supplement_qa_congruence_easy": {
            "original": 64,
            "effective": 64
        },
        "fineweb-edu-dedup-tiny": {
            "original": 1000,
            "effective": 1000
        },
        "inverse_scaling_quote_repetition": {
            "original": 300,
            "effective": 300
        },
        "blimp_causative_filtered": {
            "original": 818,
            "effective": 818
        },
        "mnli_mismatch": {
            "original": 9832,
            "effective": 9832
        },
        "qnli": {
            "original": 5463,
            "effective": 5463
        },
        "blimp_supplement_turn_taking": {
            "original": 280,
            "effective": 280
        },
        "blimp_wh_vs_that_no_gap_long_distance_filtered": {
            "original": 875,
            "effective": 875
        },
        "hellaswag": {
            "original": 10042,
            "effective": 10042
        },
        "blimp_ellipsis_n_bar_1_filtered": {
            "original": 802,
            "effective": 802
        },
        "blimp_animate_subject_passive_filtered": {
            "original": 895,
            "effective": 895
        },
        "blimp_coordinate_structure_constraint_complex_left_branch_filtered": {
            "original": 906,
            "effective": 906
        },
        "blimp_intransitive_filtered": {
            "original": 868,
            "effective": 868
        },
        "inverse_scaling_neqa": {
            "original": 300,
            "effective": 300
        },
        "blimp_sentential_negation_npi_scope_filtered": {
            "original": 871,
            "effective": 871
        },
        "inverse_scaling_winobias_antistereotype": {
            "original": 412,
            "effective": 412
        },
        "blimp_transitive_filtered": {
            "original": 868,
            "effective": 868
        },
        "blimp_principle_A_case_1_filtered": {
            "original": 912,
            "effective": 912
        },
        "blimp_npi_present_1_filtered": {
            "original": 909,
            "effective": 909
        },
        "sciq": {
            "original": 1000,
            "effective": 1000
        },
        "blimp_wh_vs_that_with_gap_long_distance_filtered": {
            "original": 910,
            "effective": 910
        },
        "open-web-math-tiny": {
            "original": 1000,
            "effective": 1000
        },
        "blimp_tough_vs_raising_2_filtered": {
            "original": 920,
            "effective": 920
        },
        "qqp": {
            "original": 40430,
            "effective": 40430
        },
        "blimp_wh_questions_subject_gap_long_distance_filtered": {
            "original": 857,
            "effective": 857
        },
        "blimp_existential_there_quantifiers_1_filtered": {
            "original": 930,
            "effective": 930
        },
        "inverse_scaling_memo_trap": {
            "original": 936,
            "effective": 936
        },
        "blimp_principle_A_domain_2_filtered": {
            "original": 915,
            "effective": 915
        },
        "blimp_wh_questions_subject_gap_filtered": {
            "original": 898,
            "effective": 898
        },
        "blimp_anaphor_number_agreement_filtered": {
            "original": 931,
            "effective": 931
        },
        "inverse_scaling_hindsight_neglect_10shot": {
            "original": 315,
            "effective": 315
        },
        "blimp_principle_A_case_2_filtered": {
            "original": 915,
            "effective": 915
        },
        "arc_easy": {
            "original": 2376,
            "effective": 2376
        },
        "blimp_coordinate_structure_constraint_object_extraction_filtered": {
            "original": 949,
            "effective": 949
        },
        "blimp_adjunct_island_filtered": {
            "original": 928,
            "effective": 928
        },
        "blimp_sentential_negation_npi_licensor_present_filtered": {
            "original": 919,
            "effective": 919
        },
        "qa4mre_2013": {
            "original": 284,
            "effective": 284
        },
        "sst2": {
            "original": 872,
            "effective": 872
        },
        "stackoverflow-clean-tiny": {
            "original": 1000,
            "effective": 1000
        },
        "blimp_principle_A_reconstruction_filtered": {
            "original": 967,
            "effective": 967
        },
        "blimp_supplement_qa_congruence_tricky": {
            "original": 165,
            "effective": 165
        },
        "blimp_principle_A_domain_3_filtered": {
            "original": 941,
            "effective": 941
        },
        "mrpc": {
            "original": 408,
            "effective": 408
        },
        "blimp_determiner_noun_agreement_with_adj_2_filtered": {
            "original": 941,
            "effective": 941
        },
        "swag": {
            "original": 20006,
            "effective": 20006
        },
        "wnli": {
            "original": 71,
            "effective": 71
        },
        "blimp_wh_vs_that_with_gap_filtered": {
            "original": 919,
            "effective": 919
        },
        "blimp_anaphor_gender_agreement_filtered": {
            "original": 971,
            "effective": 971
        },
        "qa4mre_2011": {
            "original": 120,
            "effective": 120
        },
        "blimp_ellipsis_n_bar_2_filtered": {
            "original": 828,
            "effective": 828
        },
        "blimp_left_branch_island_echo_question_filtered": {
            "original": 947,
            "effective": 947
        },
        "blimp_existential_there_object_raising_filtered": {
            "original": 812,
            "effective": 812
        },
        "blimp_irregular_plural_subject_verb_agreement_1_filtered": {
            "original": 804,
            "effective": 804
        },
        "tinyMMLU": {
            "original": 100,
            "effective": 100
        },
        "blimp_wh_questions_object_gap_filtered": {
            "original": 859,
            "effective": 859
        },
        "python-edu-tiny": {
            "original": 1000,
            "effective": 1000
        },
        "blimp_irregular_past_participle_adjectives_filtered": {
            "original": 961,
            "effective": 961
        },
        "blimp_regular_plural_subject_verb_agreement_2_filtered": {
            "original": 945,
            "effective": 945
        },
        "blimp_distractor_agreement_relational_noun_filtered": {
            "original": 788,
            "effective": 788
        },
        "blimp_existential_there_subject_raising_filtered": {
            "original": 924,
            "effective": 924
        },
        "blimp_principle_A_domain_1_filtered": {
            "original": 914,
            "effective": 914
        },
        "inverse_scaling_modus_tollens": {
            "original": 1236,
            "effective": 1236
        },
        "blimp_left_branch_island_simple_question_filtered": {
            "original": 951,
            "effective": 951
        },
        "wsc273": {
            "original": 273,
            "effective": 273
        },
        "blimp_existential_there_quantifiers_2_filtered": {
            "original": 911,
            "effective": 911
        },
        "blimp_complex_NP_island_filtered": {
            "original": 846,
            "effective": 846
        },
        "blimp_superlative_quantifiers_1_filtered": {
            "original": 979,
            "effective": 979
        },
        "blimp_principle_A_c_command_filtered": {
            "original": 946,
            "effective": 946
        },
        "inverse_scaling_redefine_math": {
            "original": 900,
            "effective": 900
        },
        "blimp_drop_argument_filtered": {
            "original": 920,
            "effective": 920
        }
    },
    "config": {
        "batch_size": "auto",
        "bootstrap_iters": 100000,
        "numpy_seed": 1234,
        "model_dtype": "torch.bfloat16",
        "model": "modis",
        "batch_sizes": [
            64
        ],
        "random_seed": 0,
        "model_args": "pretrained=random/14M/random,ckpt_dir=/home/junyanc/model_discovery/ckpt,gab_name=random",
        "model_revision": "main",
        "fewshot_seed": 1234,
        "gen_kwargs": null,
        "torch_seed": 1234,
        "limit": null,
        "model_num_parameters": 4096256,
        "use_cache": null,
        "device": null
    },
    "task_hashes": {},
    "configs": {
        "blimp_only_npi_licensor_present_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_only_npi_licensor_present_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/only_npi_licensor_present.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_determiner_noun_agreement_with_adjective_1_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_determiner_noun_agreement_with_adjective_1_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_with_adjective_1.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "inverse_scaling_pattern_matching_suppression": {
            "description": "",
            "doc_to_target": "answer_index",
            "dataset_path": "Albertmade/pattern-matching-suppression",
            "fewshot_delimiter": "\n\n",
            "metadata": {
                "version": 0
            },
            "tag": [
                "inverse_scaling_mc"
            ],
            "task": "inverse_scaling_pattern_matching_suppression",
            "doc_to_text": "prompt",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "classes",
            "target_delimiter": "",
            "num_fewshot": 0,
            "test_split": "train",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "openbookqa": {
            "description": "",
            "doc_to_target": "{{choices.label.index(answerKey.lstrip())}}",
            "dataset_path": "openbookqa",
            "validation_split": "validation",
            "training_split": "train",
            "fewshot_delimiter": "\n\n",
            "task": "openbookqa",
            "metadata": {
                "version": 1.0
            },
            "doc_to_decontamination_query": "question_stem",
            "doc_to_text": "question_stem",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "doc_to_choice": "{{choices.text}}",
            "dataset_name": "main",
            "test_split": "test",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_tough_vs_raising_1_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_tough_vs_raising_1_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/tough_vs_raising_1.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "inverse_scaling_repetitive_algebra": {
            "description": "",
            "doc_to_target": "answer_index",
            "dataset_path": "Albertmade/repetitive-algebra",
            "fewshot_delimiter": "\n\n",
            "metadata": {
                "version": 0
            },
            "tag": [
                "inverse_scaling_mc"
            ],
            "task": "inverse_scaling_repetitive_algebra",
            "doc_to_text": "prompt",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "classes",
            "target_delimiter": "",
            "num_fewshot": 0,
            "test_split": "train",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "tinyGSM8k": {
            "description": "",
            "doc_to_target": "{{answer}}",
            "training_split": "train",
            "fewshot_split": "train",
            "metadata": {
                "version": 0.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "tinyGSM8k",
            "generation_kwargs": {
                "until": [
                    "Question:",
                    "</s>",
                    "<|im_end|>"
                ],
                "temperature": 0.0,
                "do_sample": false
            },
            "dataset_path": "tinyBenchmarks/tinyGSM8k",
            "doc_to_text": "Question: {{question}}\nAnswer:",
            "should_decontaminate": false,
            "filter_list": [
                {
                    "filter": [
                        {
                            "regex_pattern": "#### (\\-?[0-9\\.\\,]+)",
                            "function": "regex"
                        },
                        {
                            "function": "take_first"
                        }
                    ],
                    "name": "strict-match"
                },
                {
                    "filter": [
                        {
                            "regex_pattern": "(-?[$0-9.,]{2,})|(-?[0-9]+)",
                            "group_select": -1,
                            "function": "regex"
                        },
                        {
                            "function": "take_first"
                        }
                    ],
                    "name": "flexible-extract"
                }
            ],
            "metric_list": [
                {
                    "metric": "exact_match",
                    "aggregation": "def agg_gpirt_gsm8k(items: List[float], benchmark: str = \"gsm8k\") -> float:\n    items = np.array(items)\n    predictions = tb.evaluate(items, benchmark)\n    return predictions[benchmark][\"gpirt\"]\n",
                    "ignore_case": true,
                    "regexes_to_ignore": [
                        ",",
                        "\\$",
                        "(?s).*#### ",
                        "\\.$"
                    ],
                    "higher_is_better": true,
                    "ignore_punctuation": false
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 5,
            "dataset_name": "main",
            "test_split": "test",
            "output_type": "generate_until",
            "repeats": 1
        },
        "blimp_animate_subject_trans_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_animate_subject_trans_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/animate_subject_trans.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_determiner_noun_agreement_1_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_determiner_noun_agreement_1_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_1.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "arc_challenge": {
            "description": "",
            "doc_to_target": "{{choices.label.index(answerKey)}}",
            "training_split": "train",
            "validation_split": "validation",
            "tag": [
                "ai2_arc"
            ],
            "metadata": {
                "version": 1.0
            },
            "task": "arc_challenge",
            "fewshot_delimiter": "\n\n",
            "dataset_path": "allenai/ai2_arc",
            "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
            "doc_to_text": "Question: {{question}}\nAnswer:",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "doc_to_choice": "{{choices.text}}",
            "dataset_name": "ARC-Challenge",
            "test_split": "test",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "inverse_scaling_sig_figs": {
            "description": "",
            "doc_to_target": "answer_index",
            "dataset_path": "Albertmade/sig-figs",
            "fewshot_delimiter": "\n\n",
            "metadata": {
                "version": 0
            },
            "tag": [
                "inverse_scaling_mc"
            ],
            "task": "inverse_scaling_sig_figs",
            "doc_to_text": "prompt",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "classes",
            "target_delimiter": "",
            "num_fewshot": 0,
            "test_split": "train",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "lambada_openai": {
            "description": "",
            "doc_to_target": "{{' '+text.split(' ')[-1]}}",
            "dataset_path": "EleutherAI/lambada_openai",
            "fewshot_delimiter": "\n\n",
            "tag": [
                "lambada"
            ],
            "metadata": {
                "version": 1.0
            },
            "task": "lambada_openai",
            "doc_to_decontamination_query": "{{text}}",
            "dataset_kwargs": {
                "trust_remote_code": true
            },
            "doc_to_text": "{{text.split(' ')[:-1]|join(' ')}}",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "perplexity",
                    "higher_is_better": false,
                    "metric": "perplexity"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "default",
            "test_split": "test",
            "output_type": "loglikelihood",
            "repeats": 1
        },
        "blimp_wh_vs_that_no_gap_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_wh_vs_that_no_gap_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_vs_that_no_gap.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "mathqa": {
            "description": "",
            "doc_to_target": "{{['a', 'b', 'c', 'd', 'e'].index(correct)}}",
            "training_split": "train",
            "validation_split": "validation",
            "tag": [
                "math_word_problems"
            ],
            "metadata": {
                "version": 1.0
            },
            "task": "mathqa",
            "fewshot_delimiter": "\n\n",
            "dataset_path": "math_qa",
            "doc_to_decontamination_query": "Question: {{Problem}}\nAnswer:",
            "doc_to_text": "Question: {{Problem}}\nAnswer:",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "def doc_to_choice(doc):\n    choices = [\n        c[4:].rstrip(\" ,\")\n        for c in re.findall(r\"[abcd] \\) .*?, |e \\) .*?$\", doc[\"options\"])\n    ]\n    return choices\n",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "test_split": "test",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_determiner_noun_agreement_2_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_determiner_noun_agreement_2_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_2.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_regular_plural_subject_verb_agreement_1_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_regular_plural_subject_verb_agreement_1_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/regular_plural_subject_verb_agreement_1.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "squad_completion": {
            "description": "",
            "metadata": {
                "version": 0
            },
            "fewshot_delimiter": "\n\n",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "task": "squad_completion",
            "generation_kwargs": {
                "until": [
                    "\n\n"
                ],
                "do_sample": false
            },
            "output_type": "generate_until",
            "should_decontaminate": false,
            "repeats": 1
        },
        "cola": {
            "description": "",
            "doc_to_target": "label",
            "training_split": "train",
            "validation_split": "validation",
            "tag": "glue",
            "metadata": {
                "version": 1.0
            },
            "task": "cola",
            "fewshot_delimiter": "\n\n",
            "dataset_path": "glue",
            "doc_to_decontamination_query": "sentence",
            "doc_to_text": "{{sentence}}\nQuestion: Does this sentence make sense?\nAnswer:",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "metric": "mcc"
                }
            ],
            "doc_to_choice": [
                "no",
                "yes"
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "cola",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "tinyTruthfulQA": {
            "description": "",
            "doc_to_target": 0,
            "metadata": {
                "version": 0.0
            },
            "validation_split": "validation",
            "fewshot_delimiter": "\n\n",
            "dataset_path": "tinyBenchmarks/tinyTruthfulQA",
            "task": "tinyTruthfulQA",
            "doc_to_decontamination_query": "question",
            "doc_to_text": "{% set prompt_qa = 'Q: What is human life expectancy in the United States?\nA: Human life expectancy in the United States is 78 years.\n\nQ: Who was president of the United States in 1955?\nA: Dwight D. Eisenhower was president of the United States in 1955.\n\nQ: Which party did he belong to?\nA: He belonged to the Republican Party.\n\nQ: What is the square root of banana?\nA: I have no comment.\n\nQ: How does a telescope work?\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\n\nQ: Where were the 1992 Olympics held?\nA: The 1992 Olympics were held in Barcelona, Spain.'%}{{prompt_qa + '\n\nQ: ' + question + '\nA:'}}",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "def agg_gpirt_truthfulqa(items: List[float], benchmark: str = \"truthfulqa\") -> float:\n    items = np.array(items)\n    predictions = tb.evaluate(items, benchmark)\n    return predictions[benchmark][\"gpirt\"]\n",
                    "higher_is_better": true,
                    "metric": "acc"
                }
            ],
            "target_delimiter": " ",
            "doc_to_choice": "{{mc2_targets.choices}}",
            "num_fewshot": 0,
            "dataset_name": "multiple_choice",
            "process_results": "def process_results_mc2(result_cache, doc_id, doc, results):\n    lls, is_greedy = zip(*results)\n\n    UNCACHED= doc_id not in result_cache\n    if UNCACHED or doc is not None:\n        result_cache[doc_id] = {}\n        labels= doc[\"mc2_targets\"][\"labels\"]\n        result_cache[doc_id][\"labels\"]= labels\n    else:\n        labels= result_cache[doc_id][\"labels\"]\n\n    # Split on the first `0` as everything before it is true (`1`).\n    split_idx = list(labels).index(0)\n    # Compute the normalized probability mass for the correct answer.\n    ll_true, ll_false = lls[:split_idx], lls[split_idx:]\n    p_true, p_false = np.exp(np.array(ll_true)), np.exp(np.array(ll_false))\n    p_true = p_true / (sum(p_true) + sum(p_false))\n\n    return result_cache, {\"acc\": sum(p_true)}\n",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_irregular_plural_subject_verb_agreement_2_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_irregular_plural_subject_verb_agreement_2_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/irregular_plural_subject_verb_agreement_2.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_superlative_quantifiers_2_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_superlative_quantifiers_2_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/superlative_quantifiers_2.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "deepmind-math-small-tiny": {
            "description": "",
            "doc_to_target": "{{' '+text.split(' ')[-1]}}",
            "dataset_path": "chengjunyan1/smollm-12.5-test",
            "fewshot_delimiter": "\n\n",
            "tag": [
                "smollm125-tiny"
            ],
            "metadata": {
                "version": 0.01
            },
            "task": "deepmind-math-small-tiny",
            "doc_to_decontamination_query": "{{text}}",
            "doc_to_text": "{{text.split(' ')[:-1]|join(' ')}}",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "perplexity",
                    "higher_is_better": false,
                    "metric": "perplexity"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "deepmind-math-small-tiny",
            "test_split": "test",
            "output_type": "loglikelihood",
            "repeats": 1
        },
        "rte": {
            "description": "",
            "doc_to_target": "label",
            "training_split": "train",
            "validation_split": "validation",
            "tag": "glue",
            "metadata": {
                "version": 1.0
            },
            "task": "rte",
            "fewshot_delimiter": "\n\n",
            "dataset_path": "glue",
            "doc_to_text": "{{sentence1}}\nQuestion: {{sentence2}} True or False?\nAnswer:",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": [
                "True",
                "False"
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "rte",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "mnli": {
            "description": "",
            "doc_to_target": "label",
            "training_split": "train",
            "validation_split": "validation_matched",
            "tag": "glue",
            "metadata": {
                "version": 1.0
            },
            "task": "mnli",
            "fewshot_delimiter": "\n\n",
            "dataset_path": "glue",
            "doc_to_text": "def doc_to_text(doc) -> str:\n    return \"{}\\nQuestion: {} True, False or Neither?\\nAnswer:\".format(\n        doc[\"premise\"],\n        doc[\"hypothesis\"].strip()\n        + (\"\" if doc[\"hypothesis\"].strip().endswith(\".\") else \".\"),\n    )\n",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": [
                "True",
                "Neither",
                "False"
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "mnli",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_expletive_it_object_raising_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_expletive_it_object_raising_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/expletive_it_object_raising.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "winogrande": {
            "description": "",
            "doc_to_target": "def doc_to_target(doc):\n    idx = doc[\"sentence\"].index(\"_\") + 1\n    return doc[\"sentence\"][idx:].strip()\n",
            "training_split": "train",
            "validation_split": "validation",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "winogrande",
            "dataset_path": "winogrande",
            "doc_to_decontamination_query": "sentence",
            "dataset_kwargs": {
                "trust_remote_code": true
            },
            "doc_to_text": "def doc_to_text(doc):\n    answer_to_num = {\"1\": 0, \"2\": 1}\n    return answer_to_num[doc[\"answer\"]]\n",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "def doc_to_choice(doc):\n    idx = doc[\"sentence\"].index(\"_\")\n    options = [doc[\"option1\"], doc[\"option2\"]]\n    return [doc[\"sentence\"][:idx] + opt for opt in options]\n",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "winogrande_xl",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_determiner_noun_agreement_irregular_2_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_determiner_noun_agreement_irregular_2_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_irregular_2.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "triviaqa": {
            "description": "",
            "doc_to_target": "{{answer.aliases}}",
            "training_split": "train",
            "validation_split": "validation",
            "metadata": {
                "version": 3.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "triviaqa",
            "generation_kwargs": {
                "until": [
                    "\n",
                    ".",
                    ","
                ],
                "temperature": 0.0,
                "do_sample": false
            },
            "dataset_path": "trivia_qa",
            "doc_to_decontamination_query": "question",
            "doc_to_text": "Question: {{question}}?\nAnswer:",
            "should_decontaminate": true,
            "filter_list": [
                {
                    "filter": [
                        {
                            "function": "remove_whitespace"
                        },
                        {
                            "function": "take_first"
                        }
                    ],
                    "name": "remove_whitespace"
                }
            ],
            "metric_list": [
                {
                    "metric": "exact_match",
                    "aggregation": "mean",
                    "ignore_case": true,
                    "higher_is_better": true,
                    "ignore_punctuation": true
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "rc.nocontext",
            "output_type": "generate_until",
            "repeats": 1
        },
        "blimp_supplement_subject_aux_inversion": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_supplement",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_supplement_subject_aux_inversion",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/supplement_filtered/subject_aux_inversion.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_supplement",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_passive_1_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_passive_1_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/passive_1.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "cosmopedia-v2-tiny": {
            "description": "",
            "doc_to_target": "{{' '+text.split(' ')[-1]}}",
            "dataset_path": "chengjunyan1/smollm-12.5-test",
            "fewshot_delimiter": "\n\n",
            "tag": [
                "smollm125-tiny"
            ],
            "metadata": {
                "version": 0.01
            },
            "task": "cosmopedia-v2-tiny",
            "doc_to_decontamination_query": "{{text}}",
            "doc_to_text": "{{text.split(' ')[:-1]|join(' ')}}",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "perplexity",
                    "higher_is_better": false,
                    "metric": "perplexity"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "cosmopedia-v2-tiny",
            "test_split": "test",
            "output_type": "loglikelihood",
            "repeats": 1
        },
        "blimp_wh_island_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_wh_island_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_island.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "piqa": {
            "description": "",
            "doc_to_target": "label",
            "training_split": "train",
            "validation_split": "validation",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "piqa",
            "dataset_path": "piqa",
            "doc_to_decontamination_query": "goal",
            "dataset_kwargs": {
                "trust_remote_code": true
            },
            "doc_to_text": "Question: {{goal}}\nAnswer:",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "{{[sol1, sol2]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_supplement_hypernym": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_supplement",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_supplement_hypernym",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/supplement_filtered/hypernym.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_supplement",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_distractor_agreement_relative_clause_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_distractor_agreement_relative_clause_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/distractor_agreement_relative_clause.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_with_adj_irregular_1.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_inchoative_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_inchoative_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/inchoative.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_irregular_past_participle_verbs_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_irregular_past_participle_verbs_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/irregular_past_participle_verbs.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_only_npi_scope_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_only_npi_scope_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/only_npi_scope.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "qa4mre_2012": {
            "description": "",
            "doc_to_target": "{{correct_answer_id|int - 1}}",
            "dataset_path": "qa4mre",
            "fewshot_delimiter": "\n\n",
            "tag": [
                "qa4mre"
            ],
            "metadata": {
                "version": 1.0
            },
            "task": "qa4mre_2012",
            "doc_to_decontamination_query": "{{document_str.strip()}} + ' ' + {{question_str}}",
            "doc_to_text": "{{document_str.strip()}}\nQuestion: {{question_str}}\nAnswer:",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "doc_to_choice": "{{answer_options.answer_str}}",
            "dataset_name": "2012.main.EN",
            "test_split": "train",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "inverse_scaling_into_the_unknown": {
            "description": "",
            "doc_to_target": "answer_index",
            "dataset_path": "Albertmade/into-the-unknown",
            "fewshot_delimiter": "\n\n",
            "metadata": {
                "version": 0
            },
            "tag": [
                "inverse_scaling_mc"
            ],
            "task": "inverse_scaling_into_the_unknown",
            "doc_to_text": "prompt",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "classes",
            "target_delimiter": "",
            "num_fewshot": 0,
            "test_split": "train",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_matrix_question_npi_licensor_present_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_matrix_question_npi_licensor_present_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/matrix_question_npi_licensor_present.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_passive_2_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_passive_2_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/passive_2.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_npi_present_2_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_npi_present_2_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/npi_present_2.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_sentential_subject_island_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_sentential_subject_island_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/sentential_subject_island.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_with_adj_irregular_2.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_determiner_noun_agreement_irregular_1_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_determiner_noun_agreement_irregular_1_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_irregular_1.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_supplement_qa_congruence_easy": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_supplement",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_supplement_qa_congruence_easy",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/supplement_filtered/qa_congruence_easy.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_supplement",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "fineweb-edu-dedup-tiny": {
            "description": "",
            "doc_to_target": "{{' '+text.split(' ')[-1]}}",
            "dataset_path": "chengjunyan1/smollm-12.5-test",
            "fewshot_delimiter": "\n\n",
            "tag": [
                "smollm125-tiny"
            ],
            "metadata": {
                "version": 0.01
            },
            "task": "fineweb-edu-dedup-tiny",
            "doc_to_decontamination_query": "{{text}}",
            "doc_to_text": "{{text.split(' ')[:-1]|join(' ')}}",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "perplexity",
                    "higher_is_better": false,
                    "metric": "perplexity"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "fineweb-edu-dedup-tiny",
            "test_split": "test",
            "output_type": "loglikelihood",
            "repeats": 1
        },
        "inverse_scaling_quote_repetition": {
            "description": "",
            "doc_to_target": "answer_index",
            "dataset_path": "inverse-scaling/quote-repetition",
            "fewshot_delimiter": "\n\n",
            "metadata": {
                "version": 0
            },
            "tag": [
                "inverse_scaling_mc"
            ],
            "task": "inverse_scaling_quote_repetition",
            "doc_to_text": "prompt",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "classes",
            "target_delimiter": "",
            "num_fewshot": 0,
            "test_split": "train",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_causative_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_causative_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/causative.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "mnli_mismatch": {
            "description": "",
            "doc_to_target": "label",
            "training_split": "train",
            "validation_split": "validation_mismatched",
            "tag": "glue",
            "metadata": {
                "version": 1.0
            },
            "task": "mnli_mismatch",
            "fewshot_delimiter": "\n\n",
            "dataset_path": "glue",
            "doc_to_text": "def doc_to_text(doc) -> str:\n    return \"{}\\nQuestion: {} True, False or Neither?\\nAnswer:\".format(\n        doc[\"premise\"],\n        doc[\"hypothesis\"].strip()\n        + (\"\" if doc[\"hypothesis\"].strip().endswith(\".\") else \".\"),\n    )\n",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": [
                "True",
                "Neither",
                "False"
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "mnli",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "qnli": {
            "description": "",
            "doc_to_target": "label",
            "training_split": "train",
            "validation_split": "validation",
            "tag": "glue",
            "metadata": {
                "version": 1.0
            },
            "task": "qnli",
            "fewshot_delimiter": "\n\n",
            "dataset_path": "glue",
            "doc_to_text": "{{question}}\n{{sentence}}\nQuestion: Does this response answer the question?\nAnswer:",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": [
                "yes",
                "no"
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "qnli",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_supplement_turn_taking": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_supplement",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_supplement_turn_taking",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/supplement_filtered/turn_taking.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_supplement",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_wh_vs_that_no_gap_long_distance_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_wh_vs_that_no_gap_long_distance_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_vs_that_no_gap_long_distance.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "hellaswag": {
            "description": "",
            "doc_to_target": "{{label}}",
            "training_split": "train",
            "validation_split": "validation",
            "tag": [
                "multiple_choice"
            ],
            "metadata": {
                "version": 1.0
            },
            "task": "hellaswag",
            "fewshot_delimiter": "\n\n",
            "dataset_path": "hellaswag",
            "dataset_kwargs": {
                "trust_remote_code": true
            },
            "doc_to_text": "{{query}}",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "choices",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc[\"ctx_a\"] + \" \" + doc[\"ctx_b\"].capitalize()\n        out_doc = {\n            \"query\": preprocess(doc[\"activity_label\"] + \": \" + ctx),\n            \"choices\": [preprocess(ending) for ending in doc[\"endings\"]],\n            \"gold\": int(doc[\"label\"]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_ellipsis_n_bar_1_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_ellipsis_n_bar_1_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/ellipsis_n_bar_1.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_animate_subject_passive_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_animate_subject_passive_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/animate_subject_passive.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_coordinate_structure_constraint_complex_left_branch_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_coordinate_structure_constraint_complex_left_branch_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/coordinate_structure_constraint_complex_left_branch.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_intransitive_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_intransitive_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/intransitive.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "inverse_scaling_neqa": {
            "description": "",
            "doc_to_target": "answer_index",
            "dataset_path": "inverse-scaling/NeQA",
            "fewshot_delimiter": "\n\n",
            "metadata": {
                "version": 0
            },
            "tag": [
                "inverse_scaling_mc"
            ],
            "task": "inverse_scaling_neqa",
            "doc_to_text": "prompt",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "classes",
            "target_delimiter": "",
            "num_fewshot": 0,
            "test_split": "train",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_sentential_negation_npi_scope_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_sentential_negation_npi_scope_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/sentential_negation_npi_scope.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "inverse_scaling_winobias_antistereotype": {
            "description": "",
            "doc_to_target": "target",
            "dataset_path": "mathemakitten/winobias_antistereotype_test_v5",
            "fewshot_delimiter": "\n\n",
            "tag": [
                "inverse_scaling_mc"
            ],
            "metadata": {
                "version": 0
            },
            "task": "inverse_scaling_winobias_antistereotype",
            "dataset_kwargs": {
                "trust_remote_code": true
            },
            "doc_to_text": "text",
            "should_decontaminate": false,
            "group": [
                "inverse_scaling_mc"
            ],
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "classes",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "test_split": "test",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_transitive_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_transitive_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/transitive.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_principle_A_case_1_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_principle_A_case_1_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/principle_A_case_1.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_npi_present_1_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_npi_present_1_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/npi_present_1.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "sciq": {
            "description": "",
            "doc_to_target": 3,
            "dataset_path": "sciq",
            "validation_split": "validation",
            "training_split": "train",
            "fewshot_delimiter": "\n\n",
            "task": "sciq",
            "metadata": {
                "version": 1.0
            },
            "doc_to_decontamination_query": "{{support}} {{question}}",
            "doc_to_text": "{{support.lstrip()}}\nQuestion: {{question}}\nAnswer:",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "{{[distractor1, distractor2, distractor3, correct_answer]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "test_split": "test",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_wh_vs_that_with_gap_long_distance_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_wh_vs_that_with_gap_long_distance_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_vs_that_with_gap_long_distance.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "open-web-math-tiny": {
            "description": "",
            "doc_to_target": "{{' '+text.split(' ')[-1]}}",
            "dataset_path": "chengjunyan1/smollm-12.5-test",
            "fewshot_delimiter": "\n\n",
            "tag": [
                "smollm125-tiny"
            ],
            "metadata": {
                "version": 0.01
            },
            "task": "open-web-math-tiny",
            "doc_to_decontamination_query": "{{text}}",
            "doc_to_text": "{{text.split(' ')[:-1]|join(' ')}}",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "perplexity",
                    "higher_is_better": false,
                    "metric": "perplexity"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "open-web-math-tiny",
            "test_split": "test",
            "output_type": "loglikelihood",
            "repeats": 1
        },
        "blimp_tough_vs_raising_2_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_tough_vs_raising_2_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/tough_vs_raising_2.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "qqp": {
            "description": "",
            "doc_to_target": "label",
            "training_split": "train",
            "validation_split": "validation",
            "tag": "glue",
            "metadata": {
                "version": 2.0
            },
            "task": "qqp",
            "fewshot_delimiter": "\n\n",
            "dataset_path": "glue",
            "doc_to_text": "Question 1: {{question1}}\nQuestion 2: {{question2}}\nQuestion: Do both questions ask the same thing?\nAnswer:",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": [
                "no",
                "yes"
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "qqp",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_wh_questions_subject_gap_long_distance_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_wh_questions_subject_gap_long_distance_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_questions_subject_gap_long_distance.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_existential_there_quantifiers_1_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_existential_there_quantifiers_1_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/existential_there_quantifiers_1.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "inverse_scaling_memo_trap": {
            "description": "",
            "doc_to_target": "answer_index",
            "dataset_path": "Albertmade/memo-trap",
            "fewshot_delimiter": "\n\n",
            "metadata": {
                "version": 0
            },
            "tag": [
                "inverse_scaling_mc"
            ],
            "task": "inverse_scaling_memo_trap",
            "doc_to_text": "prompt",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "classes",
            "target_delimiter": "",
            "num_fewshot": 0,
            "test_split": "train",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_principle_A_domain_2_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_principle_A_domain_2_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/principle_A_domain_2.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_wh_questions_subject_gap_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_wh_questions_subject_gap_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_questions_subject_gap.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_anaphor_number_agreement_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_anaphor_number_agreement_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/anaphor_number_agreement.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "inverse_scaling_hindsight_neglect_10shot": {
            "description": "",
            "doc_to_target": "answer_index",
            "dataset_path": "inverse-scaling/hindsight-neglect-10shot",
            "fewshot_delimiter": "\n\n",
            "metadata": {
                "version": 0
            },
            "tag": [
                "inverse_scaling_mc"
            ],
            "task": "inverse_scaling_hindsight_neglect_10shot",
            "doc_to_text": "prompt",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "classes",
            "target_delimiter": "",
            "num_fewshot": 0,
            "test_split": "train",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_principle_A_case_2_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_principle_A_case_2_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/principle_A_case_2.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "arc_easy": {
            "description": "",
            "doc_to_target": "{{choices.label.index(answerKey)}}",
            "training_split": "train",
            "validation_split": "validation",
            "tag": [
                "ai2_arc"
            ],
            "metadata": {
                "version": 1.0
            },
            "task": "arc_easy",
            "fewshot_delimiter": "\n\n",
            "dataset_path": "allenai/ai2_arc",
            "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
            "doc_to_text": "Question: {{question}}\nAnswer:",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "doc_to_choice": "{{choices.text}}",
            "dataset_name": "ARC-Easy",
            "test_split": "test",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_coordinate_structure_constraint_object_extraction_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_coordinate_structure_constraint_object_extraction_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/coordinate_structure_constraint_object_extraction.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_adjunct_island_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_adjunct_island_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/adjunct_island.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_sentential_negation_npi_licensor_present_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_sentential_negation_npi_licensor_present_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/sentential_negation_npi_licensor_present.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "qa4mre_2013": {
            "description": "",
            "doc_to_target": "{{correct_answer_id|int - 1}}",
            "dataset_path": "qa4mre",
            "fewshot_delimiter": "\n\n",
            "tag": [
                "qa4mre"
            ],
            "metadata": {
                "version": 1.0
            },
            "task": "qa4mre_2013",
            "doc_to_decontamination_query": "{{document_str.strip()}} + ' ' + {{question_str}}",
            "doc_to_text": "{{document_str.strip()}}\nQuestion: {{question_str}}\nAnswer:",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "doc_to_choice": "{{answer_options.answer_str}}",
            "dataset_name": "2013.main.EN",
            "test_split": "train",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "sst2": {
            "description": "",
            "doc_to_target": "label",
            "training_split": "train",
            "validation_split": "validation",
            "tag": "glue",
            "metadata": {
                "version": 1.0
            },
            "task": "sst2",
            "fewshot_delimiter": "\n\n",
            "dataset_path": "glue",
            "doc_to_text": "{{sentence}}\nQuestion: Is this sentence positive or negative?\nAnswer:",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": [
                "negative",
                "positive"
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "sst2",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "stackoverflow-clean-tiny": {
            "description": "",
            "doc_to_target": "{{' '+text.split(' ')[-1]}}",
            "dataset_path": "chengjunyan1/smollm-12.5-test",
            "fewshot_delimiter": "\n\n",
            "tag": [
                "smollm125-tiny"
            ],
            "metadata": {
                "version": 0.01
            },
            "task": "stackoverflow-clean-tiny",
            "doc_to_decontamination_query": "{{text}}",
            "doc_to_text": "{{text.split(' ')[:-1]|join(' ')}}",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "perplexity",
                    "higher_is_better": false,
                    "metric": "perplexity"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "stackoverflow-clean-tiny",
            "test_split": "test",
            "output_type": "loglikelihood",
            "repeats": 1
        },
        "blimp_principle_A_reconstruction_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_principle_A_reconstruction_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/principle_A_reconstruction.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_supplement_qa_congruence_tricky": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_supplement",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_supplement_qa_congruence_tricky",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/supplement_filtered/qa_congruence_tricky.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_supplement",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_principle_A_domain_3_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_principle_A_domain_3_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/principle_A_domain_3.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "mrpc": {
            "description": "",
            "doc_to_target": "label",
            "training_split": "train",
            "validation_split": "validation",
            "tag": "glue",
            "metadata": {
                "version": 1.0
            },
            "task": "mrpc",
            "fewshot_delimiter": "\n\n",
            "dataset_path": "glue",
            "doc_to_text": "Sentence 1: {{sentence1}}\nSentence 2: {{sentence2}}\nQuestion: Do both sentences mean the same thing?\nAnswer:",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": [
                "no",
                "yes"
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "mrpc",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_determiner_noun_agreement_with_adj_2_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_determiner_noun_agreement_with_adj_2_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_with_adj_2.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "swag": {
            "description": "",
            "doc_to_target": "label",
            "training_split": "train",
            "validation_split": "validation",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "swag",
            "dataset_path": "swag",
            "doc_to_text": "startphrase",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "{{[ending0, ending1, ending2, ending3]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "regular",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "wnli": {
            "description": "",
            "doc_to_target": "label",
            "training_split": "train",
            "validation_split": "validation",
            "tag": "glue",
            "metadata": {
                "version": 2.0
            },
            "task": "wnli",
            "fewshot_delimiter": "\n\n",
            "dataset_path": "glue",
            "doc_to_text": "{{sentence1}}\nQuestion: {{sentence2}} True or False?\nAnswer:",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": [
                "False",
                "True"
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "wnli",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_wh_vs_that_with_gap_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_wh_vs_that_with_gap_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_vs_that_with_gap.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_anaphor_gender_agreement_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_anaphor_gender_agreement_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/anaphor_gender_agreement.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "qa4mre_2011": {
            "description": "",
            "doc_to_target": "{{correct_answer_id|int - 1}}",
            "dataset_path": "qa4mre",
            "fewshot_delimiter": "\n\n",
            "tag": [
                "qa4mre"
            ],
            "metadata": {
                "version": 1.0
            },
            "task": "qa4mre_2011",
            "doc_to_decontamination_query": "{{document_str.strip()}} + ' ' + {{question_str}}",
            "doc_to_text": "{{document_str.strip()}}\nQuestion: {{question_str}}\nAnswer:",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "doc_to_choice": "{{answer_options.answer_str}}",
            "dataset_name": "2011.main.EN",
            "test_split": "train",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_ellipsis_n_bar_2_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_ellipsis_n_bar_2_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/ellipsis_n_bar_2.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_left_branch_island_echo_question_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_left_branch_island_echo_question_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/left_branch_island_echo_question.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_existential_there_object_raising_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_existential_there_object_raising_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/existential_there_object_raising.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_irregular_plural_subject_verb_agreement_1_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_irregular_plural_subject_verb_agreement_1_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/irregular_plural_subject_verb_agreement_1.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "tinyMMLU": {
            "description": "",
            "doc_to_target": "answer",
            "metadata": {
                "version": 0.0
            },
            "fewshot_split": "dev",
            "fewshot_delimiter": "\n\n",
            "dataset_path": "tinyBenchmarks/tinyMMLU",
            "task": "tinyMMLU",
            "doc_to_text": "{{input_formatted}}",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "aggregation": "def agg_gpirt_mmlu(items: List[float], benchmark: str = \"mmlu\") -> float:\n    items = np.array(items)\n    predictions = tb.evaluate(items, benchmark)\n    return predictions[benchmark][\"gpirt\"]\n",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "doc_to_choice": [
                "A",
                "B",
                "C",
                "D"
            ],
            "fewshot_config": {
                "sampler": "first_n"
            },
            "dataset_name": "all",
            "test_split": "test",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_wh_questions_object_gap_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_wh_questions_object_gap_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_questions_object_gap.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "python-edu-tiny": {
            "description": "",
            "doc_to_target": "{{' '+text.split(' ')[-1]}}",
            "dataset_path": "chengjunyan1/smollm-12.5-test",
            "fewshot_delimiter": "\n\n",
            "tag": [
                "smollm125-tiny"
            ],
            "metadata": {
                "version": 0.01
            },
            "task": "python-edu-tiny",
            "doc_to_decontamination_query": "{{text}}",
            "doc_to_text": "{{text.split(' ')[:-1]|join(' ')}}",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "perplexity",
                    "higher_is_better": false,
                    "metric": "perplexity"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "dataset_name": "python-edu-tiny",
            "test_split": "test",
            "output_type": "loglikelihood",
            "repeats": 1
        },
        "blimp_irregular_past_participle_adjectives_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_irregular_past_participle_adjectives_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/irregular_past_participle_adjectives.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_regular_plural_subject_verb_agreement_2_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_regular_plural_subject_verb_agreement_2_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/regular_plural_subject_verb_agreement_2.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_distractor_agreement_relational_noun_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_distractor_agreement_relational_noun_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/distractor_agreement_relational_noun.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_existential_there_subject_raising_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_existential_there_subject_raising_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/existential_there_subject_raising.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_principle_A_domain_1_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_principle_A_domain_1_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/principle_A_domain_1.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "inverse_scaling_modus_tollens": {
            "description": "",
            "doc_to_target": "answer_index",
            "dataset_path": "Albertmade/modus-tollens",
            "fewshot_delimiter": "\n\n",
            "metadata": {
                "version": 0
            },
            "tag": [
                "inverse_scaling_mc"
            ],
            "task": "inverse_scaling_modus_tollens",
            "doc_to_text": "prompt",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "classes",
            "target_delimiter": "",
            "num_fewshot": 0,
            "test_split": "train",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_left_branch_island_simple_question_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_left_branch_island_simple_question_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/left_branch_island_simple_question.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "wsc273": {
            "description": "",
            "doc_to_target": "{% set index = pronoun_loc + pronoun | length %}{{text[index:]}}",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "dataset_path": "winograd_wsc",
            "doc_to_decontamination_query": "text",
            "task": "wsc273",
            "doc_to_text": "label",
            "should_decontaminate": true,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                }
            ],
            "target_delimiter": " ",
            "num_fewshot": 0,
            "doc_to_choice": "{% set template = text[:pronoun_loc] %}{{[template+options[0], template+options[1]]}}",
            "dataset_name": "wsc273",
            "process_docs": "def process_doc(dataset):\n    def process_fn(doc):\n        # The HF implementation of `wsc273` is not `partial evaluation` friendly.\n        doc[\"text\"] = doc[\"text\"].replace(\"  \", \" \")\n        doc[\"options\"][0] = __normalize_option(doc, doc[\"options\"][0])\n        doc[\"options\"][1] = __normalize_option(doc, doc[\"options\"][1])\n        return doc\n\n    return dataset.map(process_fn)\n",
            "test_split": "test",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_existential_there_quantifiers_2_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_existential_there_quantifiers_2_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/existential_there_quantifiers_2.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_complex_NP_island_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_complex_NP_island_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/complex_NP_island.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_superlative_quantifiers_1_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_superlative_quantifiers_1_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/superlative_quantifiers_1.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_principle_A_c_command_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_principle_A_c_command_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/principle_A_c_command.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "inverse_scaling_redefine_math": {
            "description": "",
            "doc_to_target": "answer_index",
            "dataset_path": "inverse-scaling/redefine-math",
            "fewshot_delimiter": "\n\n",
            "metadata": {
                "version": 0
            },
            "tag": [
                "inverse_scaling_mc"
            ],
            "task": "inverse_scaling_redefine_math",
            "doc_to_text": "prompt",
            "should_decontaminate": false,
            "metric_list": [
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc"
                },
                {
                    "aggregation": "mean",
                    "higher_is_better": true,
                    "metric": "acc_norm"
                }
            ],
            "doc_to_choice": "classes",
            "target_delimiter": "",
            "num_fewshot": 0,
            "test_split": "train",
            "output_type": "multiple_choice",
            "repeats": 1
        },
        "blimp_drop_argument_filtered": {
            "description": "",
            "doc_to_target": 0,
            "tag": "blimp_filtered",
            "validation_split": "train",
            "metadata": {
                "version": 1.0
            },
            "fewshot_delimiter": "\n\n",
            "task": "blimp_drop_argument_filtered",
            "dataset_path": "json",
            "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
            "dataset_kwargs": {
                "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/drop_argument.jsonl"
            },
            "doc_to_text": "",
            "should_decontaminate": true,
            "group": "blimp_filtered",
            "metric_list": [
                {
                    "metric": "acc"
                }
            ],
            "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
            "target_delimiter": " ",
            "num_fewshot": 0,
            "output_type": "multiple_choice",
            "repeats": 1
        }
    },
    "model_name": "random/14M/random"
}