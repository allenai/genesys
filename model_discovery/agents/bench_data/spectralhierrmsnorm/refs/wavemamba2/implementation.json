{
    "implementation": {
        "review": null,
        "root": "Mamba2",
        "proposal": "While Transformers have been the main architecture behind deep learning's success in language modeling, state-space models (SSMs) such as Mamba have recently been shown to match or outperform Transformers at small to medium scale. We show that these families of models are actually quite closely related, and develop a rich framework of theoretical connections between SSMs and variants of attention, connected through various decompositions of a well-studied class of structured semiseparable matrices. Our state space duality (SSD) framework allows us to design a new architecture (Mamba-2) whose core layer is an a refinement of Mamba's selective SSM that is 2-8X faster, while continuing to be competitive with Transformers on language modeling.\n",
        "proposal_traces": [],
        "rating": null,
        "declares": {
            "SSDMinimalDiscrete": "{\"unitname\":\"SSDMinimalDiscrete\",\"requirements\":\"N/A\",\"inputs\":[\"X\",\"A\",\"B\",\"C\",\"dt\",\"chunk_size\"],\"outputs\":[\"Y\"]}"
        },
        "units": {
            "RMSNorm": {
                "review": null,
                "requirements": null,
                "reuse_from": null,
                "desc": "\n",
                "gautests": {
                    "test_rmsnorm": "@gau_test\ndef test_RMSNorm_test_rmsnorm(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    rmsnorm = RMSNorm(embed_dim, block_loc, kwarg_all, device=device, dtype\n        =dtype, **kwarg_all)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    Z = {}\n    y, Z_ = rmsnorm(x, **Z)\n    assert y.shape == (1, 100, 128)\n"
                },
                "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import Tensor\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RMSNorm(GAUBase):\n    \"\"\"\n    Root Mean Square Layer Normalization (RMSNorm).\n\n    This layer applies a variant of layer normalization that uses only the root mean square\n    statistics, without centering. It's computationally more efficient than standard\n    layer normalization and has been shown to be effective in various NLP tasks.\n\n    Args:\n        embed_dim (int): The size of the input feature dimension.\n        block_loc (tuple): The location of this block in the model architecture.\n        kwarg_all (dict): Additional keyword arguments passed to the parent class.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The dtype of the module's parameters.\n        eps (float, optional): A small constant added to the denominator for numerical stability.\n            Default: 1e-5.\n\n    Attributes:\n        weight (nn.Parameter): Learnable scale parameter of shape (embed_dim,).\n        variance_epsilon (float): The epsilon value used in the normalization formula.\n\n    Shape:\n        - Input: (*, embed_dim)\n        - Output: (*, embed_dim) (same shape as input)\n\n    Examples:\n        >>> rmsnorm = RMSNorm(128, (0, 6), {})\n        >>> x = torch.randn(1, 100, 128)\n        >>> output = rmsnorm(x)\n        >>> print(output.shape)\n        torch.Size([1, 100, 128])\n\n    References:\n        - Paper: \"Root Mean Square Layer Normalization\" by Biao Zhang and Rico Sennrich\n          https://arxiv.org/abs/1910.07467\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, eps=1e-05, **kwargs):\n        \"\"\"If group_size is not None, we do GroupNorm with each group having group_size elements.\n        group_size=None is equivalent to group_size=hidden_size (i.e. there's only 1 group).\n        \"\"\"\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.weight = nn.Parameter(torch.ones(embed_dim, **self.factory_kwargs)\n            )\n        self.variance_epsilon = eps\n\n    def _forward(self, X, **Z):\n        input_dtype = X.dtype\n        X = X.to(torch.float32)\n        variance = X.pow(2).mean(-1, keepdim=True)\n        X = X * torch.rsqrt(variance + self.variance_epsilon)\n        return self.weight * X.to(input_dtype)\n\n\nCHILDREN_DECLARATIONS = []\n",
                "rating": null,
                "spec": "{\"unitname\":\"RMSNorm\",\"document\":\"\\n    Root Mean Square Layer Normalization (RMSNorm).\\n\\n    This layer applies a variant of layer normalization that uses only the root mean square\\n    statistics, without centering. It's computationally more efficient than standard\\n    layer normalization and has been shown to be effective in various NLP tasks.\\n\\n    Args:\\n        embed_dim (int): The size of the input feature dimension.\\n        block_loc (tuple): The location of this block in the model architecture.\\n        kwarg_all (dict): Additional keyword arguments passed to the parent class.\\n        device (torch.device, optional): The device on which to allocate the module's parameters.\\n        dtype (torch.dtype, optional): The dtype of the module's parameters.\\n        eps (float, optional): A small constant added to the denominator for numerical stability.\\n            Default: 1e-5.\\n\\n    Attributes:\\n        weight (nn.Parameter): Learnable scale parameter of shape (embed_dim,).\\n        variance_epsilon (float): The epsilon value used in the normalization formula.\\n\\n    Shape:\\n        - Input: (*, embed_dim)\\n        - Output: (*, embed_dim) (same shape as input)\\n\\n    Examples:\\n        >>> rmsnorm = RMSNorm(128, (0, 6), {})\\n        >>> x = torch.randn(1, 100, 128)\\n        >>> output = rmsnorm(x)\\n        >>> print(output.shape)\\n        torch.Size([1, 100, 128])\\n\\n    References:\\n        - Paper: \\\"Root Mean Square Layer Normalization\\\" by Biao Zhang and Rico Sennrich\\n          https://arxiv.org/abs/1910.07467\\n\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                "children": [],
                "suggestions": null,
                "args": {
                    "eps": 1e-05
                },
                "design_traces": null
            },
            "Mamba2Layer": {
                "review": null,
                "requirements": null,
                "reuse_from": null,
                "desc": "\n",
                "gautests": {
                    "test_mamba2layer": "@gau_test\ndef test_Mamba2Layer_test_mamba2layer(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    mamba2layer = Mamba2Layer(embed_dim, block_loc, kwarg_all, device=\n        device, dtype=dtype, **kwarg_all)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    y, _ = mamba2layer(x)\n    assert y.shape == (1, 100, 128)\n"
                },
                "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nimport math\nfrom einops import rearrange, repeat\n\n\nclass Mamba2Layer(GAUBase):\n    \"\"\"\n    Mamba2Layer: An implementation of the Mamba architecture layer.\n\n    This layer is based on the Mamba architecture, which combines elements of\n    State Space Models (SSMs) and attention mechanisms. It's designed for\n    efficient processing of long sequences.\n\n    Args:\n        embed_dim (int): Dimension of the input embeddings.\n        block_loc (tuple): Location of the block within the model.\n        kwarg_all (dict): Additional keyword arguments.\n        d_state (int, optional): Dimension of the state. Defaults to 64.\n        d_conv (int, optional): Kernel size for the 1D convolution. Defaults to 4.\n        expand (int, optional): Expansion factor for the inner dimension. Defaults to 2.\n        headdim (int, optional): Dimension of each head. Defaults to 128.\n        ngroups (int, optional): Number of groups for group linear operators. Defaults to 1.\n        A_init_range (tuple, optional): Range for initializing the A parameter. Defaults to (1, 16).\n        dt_min (float, optional): Minimum value for dt initialization. Defaults to 0.001.\n        dt_max (float, optional): Maximum value for dt initialization. Defaults to 0.1.\n        dt_init_floor (float, optional): Floor value for dt initialization. Defaults to 1e-4.\n        chunk_size (int, optional): Size of chunks for processing. Defaults to 256.\n        device (torch.device, optional): Device to use for computations.\n        dtype (torch.dtype, optional): Data type to use for computations.\n\n    The Mamba2Layer processes input sequences using a combination of linear projections,\n    1D convolutions, and a selective scan operation (implemented in SSDMinimalDiscrete).\n    It's designed to capture long-range dependencies efficiently.\n\n    The layer includes several components:\n    1. Input projection\n    2. 1D Convolution\n    3. Selective Scan Discrete operation\n    4. Output projection\n\n    The layer also implements a chunking mechanism to process long sequences efficiently.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        d_state=64, d_conv=4, expand=2, headdim=128, ngroups=1,\n        A_init_range=(1, 16), dt_min=0.001, dt_max=0.1, dt_init_floor=\n        0.0001, chunk_size=256, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.d_model = embed_dim\n        self.d_state = d_state\n        self.d_conv = d_conv\n        self.expand = expand\n        self.d_inner = self.expand * self.d_model\n        self.headdim = headdim\n        self.ngroups = ngroups\n        assert self.d_inner % self.headdim == 0\n        self.nheads = self.d_inner // self.headdim\n        self.chunk_size = chunk_size\n        d_in_proj = (2 * self.d_inner + 2 * self.ngroups * self.d_state +\n            self.nheads)\n        self.in_proj = nn.Linear(self.d_model, d_in_proj, bias=True, **self\n            .factory_kwargs)\n        conv_dim = self.d_inner + 2 * self.ngroups * self.d_state\n        self.conv1d = nn.Conv1d(in_channels=conv_dim, out_channels=conv_dim,\n            bias=True, kernel_size=d_conv, groups=conv_dim, padding=d_conv -\n            1, **self.factory_kwargs)\n        self.act = nn.SiLU()\n        dt = torch.exp(torch.rand(self.nheads, **self.factory_kwargs) * (\n            math.log(dt_max) - math.log(dt_min)) + math.log(dt_min))\n        dt = torch.clamp(dt, min=dt_init_floor)\n        inv_dt = dt + torch.log(-torch.expm1(-dt))\n        self.dt_bias = nn.Parameter(inv_dt)\n        self.dt_bias._no_weight_decay = True\n        assert A_init_range[0] > 0 and A_init_range[1] >= A_init_range[0]\n        A = torch.empty(self.nheads, dtype=torch.float32, device=device\n            ).uniform_(*A_init_range)\n        A_log = torch.log(A).to(dtype=dtype)\n        self.A_log = nn.Parameter(A_log)\n        self.A_log._no_weight_decay = True\n        self.norm = nn.LayerNorm(self.d_inner, eps=1e-05, **self.factory_kwargs\n            )\n        self.silu = nn.SiLU()\n        self.out_proj = nn.Linear(self.d_inner, self.d_model, bias=True, **\n            self.factory_kwargs)\n        self.ssd_minimal_discrete = SSDMinimalDiscrete(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n\n    def pad_to_block_length(self, X, block_len):\n        pad_len = (block_len - X.shape[1] % block_len) % block_len\n        if pad_len > 0:\n            padding = torch.zeros(X.shape[0], pad_len, *X.shape[2:], dtype=\n                X.dtype, device=X.device)\n            X = torch.cat([X, padding], dim=1)\n        return X\n\n    def _forward(self, u, **kwargs):\n        \"\"\"\n        u: (B, L, D)\n        Returns: same shape as u\n        \"\"\"\n        batch, _seqlen, dim = u.shape\n        u = self.pad_to_block_length(u, self.chunk_size)\n        seqlen = u.shape[1]\n        zxbcdt = self.in_proj(u)\n        A = -torch.exp(self.A_log)\n        z, xBC, dt = torch.split(zxbcdt, [self.d_inner, self.d_inner + 2 *\n            self.ngroups * self.d_state, self.nheads], dim=-1)\n        dt = F.softplus(dt + self.dt_bias)\n        xBC = self.act(self.conv1d(xBC.transpose(1, 2)).transpose(1, 2))\n        xBC = xBC[:, :seqlen, :]\n        x, B, C = torch.split(xBC, [self.d_inner, self.ngroups * self.\n            d_state, self.ngroups * self.d_state], dim=-1)\n        x = rearrange(x, 'b l (h p) -> b l h p', p=self.headdim)\n        B = rearrange(B, 'b l (g n) -> b l g n', g=self.ngroups)\n        C = rearrange(C, 'b l (g n) -> b l g n', g=self.ngroups)\n        Z = {'x': x, 'A': A, 'B': B, 'C': C, 'dt': dt, 'chunk_size': self.\n            chunk_size}\n        _, Z_ = self.ssd_minimal_discrete(u, **Z)\n        y = Z_.get('y')\n        y = rearrange(y, 'b l h p -> b l (h p)')\n        y = self.norm(y * self.silu(z))\n        out = self.out_proj(y)\n        out = out[:, :_seqlen, :]\n        return out\n\n\nCHILDREN_DECLARATIONS = [UnitDecl(unitname='SSDMinimalDiscrete',\n    requirements='', inputs=['X', 'x', 'A', 'B', 'C', 'dt', 'chunk_size'],\n    outputs=['Y', 'y'])]\n",
                "rating": null,
                "spec": "{\"unitname\":\"Mamba2Layer\",\"document\":\"\\n    Mamba2Layer: An implementation of the Mamba architecture layer.\\n\\n    This layer is based on the Mamba architecture, which combines elements of\\n    State Space Models (SSMs) and attention mechanisms. It's designed for\\n    efficient processing of long sequences.\\n\\n    Args:\\n        embed_dim (int): Dimension of the input embeddings.\\n        block_loc (tuple): Location of the block within the model.\\n        kwarg_all (dict): Additional keyword arguments.\\n        d_state (int, optional): Dimension of the state. Defaults to 64.\\n        d_conv (int, optional): Kernel size for the 1D convolution. Defaults to 4.\\n        expand (int, optional): Expansion factor for the inner dimension. Defaults to 2.\\n        headdim (int, optional): Dimension of each head. Defaults to 128.\\n        ngroups (int, optional): Number of groups for group linear operators. Defaults to 1.\\n        A_init_range (tuple, optional): Range for initializing the A parameter. Defaults to (1, 16).\\n        dt_min (float, optional): Minimum value for dt initialization. Defaults to 0.001.\\n        dt_max (float, optional): Maximum value for dt initialization. Defaults to 0.1.\\n        dt_init_floor (float, optional): Floor value for dt initialization. Defaults to 1e-4.\\n        chunk_size (int, optional): Size of chunks for processing. Defaults to 256.\\n        device (torch.device, optional): Device to use for computations.\\n        dtype (torch.dtype, optional): Data type to use for computations.\\n\\n    The Mamba2Layer processes input sequences using a combination of linear projections,\\n    1D convolutions, and a selective scan operation (implemented in SSDMinimalDiscrete).\\n    It's designed to capture long-range dependencies efficiently.\\n\\n    The layer includes several components:\\n    1. Input projection\\n    2. 1D Convolution\\n    3. Selective Scan Discrete operation\\n    4. Output projection\\n\\n    The layer also implements a chunking mechanism to process long sequences efficiently.\\n    \",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                "children": [
                    "SSDMinimalDiscrete"
                ],
                "suggestions": null,
                "args": {
                    "chunk_size": 256,
                    "dt_init_floor": 0.0001,
                    "d_conv": 4,
                    "A_init_range": [
                        1,
                        16
                    ],
                    "dt_min": 0.001,
                    "headdim": 128,
                    "ngroups": 1,
                    "dt_max": 0.1,
                    "d_state": 64,
                    "expand": 2
                },
                "design_traces": null
            },
            "Mamba2": {
                "review": null,
                "requirements": null,
                "reuse_from": null,
                "desc": "\n",
                "gautests": {
                    "test_mamba2": "@gau_test\ndef test_Mamba2_test_mamba2(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    mamba2 = Mamba2(embed_dim, block_loc, kwarg_all, device=device, dtype=\n        dtype, **kwarg_all)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    Z = {}\n    y, Z_ = mamba2(x, **Z)\n    assert y.shape == (1, 100, 128)\n"
                },
                "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass Mamba2(GAUBase):\n    \"\"\"\n    Mamba2: A Generalized Autoregressive Unit (GAU) implementing a double-layer Mamba architecture.\n\n    This class represents a Mamba2 block, which consists of two Mamba layers with normalization.\n    It's designed to process sequential data in a causal, differentiable, and parallelizable manner.\n\n    Architecture:\n        1. Input Normalization (RMSNorm)\n        2. First Mamba Layer\n        3. Residual Connection\n        4. Second Normalization (RMSNorm)\n        5. Second Mamba Layer\n        6. Final Residual Connection\n\n    Args:\n        embed_dim (int): The dimensionality of the input and output embeddings.\n        block_loc (tuple): The location of this block within the larger model architecture.\n        kwarg_all (dict): Additional keyword arguments to be passed to child components.\n        device (torch.device, optional): The device on which to allocate tensors.\n        dtype (torch.dtype, optional): The default dtype for tensors in this module.\n\n    Inputs:\n        X (torch.Tensor): Input tensor of shape (batch_size, sequence_length, embed_dim).\n        **Z: Additional keyword arguments for potential future extensions.\n\n    Outputs:\n        X (torch.Tensor): Output tensor of shape (batch_size, sequence_length, embed_dim).\n        Z (dict): Updated keyword arguments.\n\n    Note:\n        This implementation adheres to the GAU (Generalized Autoregressive Unit) interface\n        and maintains causal properties for autoregressive processing.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.mamba1 = Mamba2Layer(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.mamba2 = Mamba2Layer(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.norm1 = RMSNorm(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.norm2 = RMSNorm(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, Z = self.norm1(X, **Z)\n        X2, Z = self.mamba1(X1, **Z)\n        X = X + X2\n        X3, Z = self.norm2(X, **Z)\n        X4, Z = self.mamba2(X3, **Z)\n        X = X + X4\n        return X, Z\n\n\nCHILDREN_DECLARATIONS = [UnitDecl(unitname='Mamba2Layer', requirements='',\n    inputs=['X'], outputs=['Y']), UnitDecl(unitname='RMSNorm', requirements\n    ='', inputs=['X'], outputs=['Y'])]\n",
                "rating": null,
                "spec": "{\"unitname\":\"Mamba2\",\"document\":\"\\n    Mamba2: A Generalized Autoregressive Unit (GAU) implementing a double-layer Mamba architecture.\\n\\n    This class represents a Mamba2 block, which consists of two Mamba layers with normalization.\\n    It's designed to process sequential data in a causal, differentiable, and parallelizable manner.\\n\\n    Architecture:\\n        1. Input Normalization (RMSNorm)\\n        2. First Mamba Layer\\n        3. Residual Connection\\n        4. Second Normalization (RMSNorm)\\n        5. Second Mamba Layer\\n        6. Final Residual Connection\\n\\n    Args:\\n        embed_dim (int): The dimensionality of the input and output embeddings.\\n        block_loc (tuple): The location of this block within the larger model architecture.\\n        kwarg_all (dict): Additional keyword arguments to be passed to child components.\\n        device (torch.device, optional): The device on which to allocate tensors.\\n        dtype (torch.dtype, optional): The default dtype for tensors in this module.\\n\\n    Inputs:\\n        X (torch.Tensor): Input tensor of shape (batch_size, sequence_length, embed_dim).\\n        **Z: Additional keyword arguments for potential future extensions.\\n\\n    Outputs:\\n        X (torch.Tensor): Output tensor of shape (batch_size, sequence_length, embed_dim).\\n        Z (dict): Updated keyword arguments.\\n\\n    Note:\\n        This implementation adheres to the GAU (Generalized Autoregressive Unit) interface\\n        and maintains causal properties for autoregressive processing.\\n    \",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                "children": [
                    "Mamba2Layer",
                    "RMSNorm"
                ],
                "suggestions": null,
                "args": {},
                "design_traces": null
            },
            "SSDMinimalDiscrete": {
                "review": "## Feedback Report\n\n### Overall Assessment\n```rating 4.0```\n\n### Strengths of the Implementation\n1. **Successful Functionality**: The implementation has passed all functionality checks, indicating that the code is robust and functions as expected within the larger language model framework.\n2. **Efficient Chunk-Based Processing**: The implementation efficiently processes sequences in chunks, which aligns with the proposal's goal of improving memory usage and computational efficiency.\n3. **Comprehensive Documentation**: The coder has provided detailed docstrings that clearly explain the inputs, outputs, and functionality of the methods, making the code easier to understand and maintain.\n\n### Areas for Improvement and Specific Suggestions\n1. **Code Optimization**:\n   - While the code is functioning correctly, there may still be opportunities to optimize the tensor operations for better performance, especially in the `ssd_minimal_discrete` method. Consider reviewing the use of `einsum` and `rearrange` for potential simplifications or performance improvements.\n   \n2. **Expand Unit Tests**:\n   - Although the functionality checks passed, expanding the unit tests to cover more edge cases and different input scenarios can further ensure robustness. This includes testing with varying batch sizes, sequence lengths, and edge cases like empty inputs or extreme values.\n\n3. **Code Readability**:\n   - Adding inline comments to explain complex operations or decisions in the code can enhance readability and make it easier for future developers to understand the logic.\n\n### Comments on Innovation and Potential Impact\n- The integration of chunk-based processing is a significant innovation that aligns with the proposal's goals of improving efficiency and scalability. This approach can potentially lead to better performance on long sequences, which is a common challenge in language modeling.\n- The current implementation is well-positioned to integrate additional features from the proposal, such as adaptive compression and wavelet-based analysis, which could further enhance the model's capabilities.\n\n### Recommendations for the Coder\n1. **Review and Optimize**: Continue to review the code for potential optimizations, particularly in tensor operations, to ensure maximum efficiency.\n2. **Enhance Testing**: Expand the unit tests to cover a broader range of scenarios, ensuring the implementation remains robust under various conditions.\n3. **Prepare for Future Enhancements**: Consider how the current implementation can be extended to incorporate additional features from the proposal, such as adaptive compression techniques.\n\nBy addressing these areas, the coder can further enhance the implementation's robustness, efficiency, and alignment with the proposal's goals. The successful functionality check is a strong indicator of the implementation's quality, and with continued refinement, it can serve as a solid foundation for future developments.",
                "reuse_from": null,
                "requirements": "N/A",
                "desc": null,
                "gautests": {
                    "test_ssd_minimal_discrete": "@gau_test\ndef test_SSDMinimalDiscrete_test_ssd_minimal_discrete(device=None, dtype=None\n    ) ->None:\n    batch_size = 2\n    L = 16\n    n_heads = 4\n    d_head = 32\n    d_state = 64\n    chunk_size = 4\n    embed_dim = n_heads * d_head\n    X = torch.randn(batch_size, L, n_heads, d_head, device=device, dtype=dtype)\n    x = X.clone()\n    A = torch.randn(batch_size, L, n_heads, device=device, dtype=dtype)\n    B = torch.randn(batch_size, L, n_heads, d_state, device=device, dtype=dtype\n        )\n    C = torch.randn(batch_size, L, n_heads, d_state, device=device, dtype=dtype\n        )\n    dt = torch.abs(torch.randn(batch_size, L, n_heads, device=device, dtype\n        =dtype)) + 0.001\n    model = SSDMinimalDiscrete(embed_dim, (0, 1), {}, device=device, dtype=\n        dtype)\n    X_out, Z_ = model._forward(X, x=x, A=A, B=B, C=C, dt=dt, chunk_size=\n        chunk_size)\n    y = Z_['y']\n    assert y.shape == (batch_size, L, n_heads, d_head\n        ), f'Output shape mismatch. Expected {batch_size, L, n_heads, d_head}, got {y.shape}'\n    assert torch.isfinite(y).all(), 'Output contains NaNs or infinite values'\n",
                    "test_ssdminimaldiscrete": "@gau_test\ndef test_SSDMinimalDiscrete_test_ssdminimaldiscrete(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    chunk_size = 16\n    batch_size = 2\n    seq_len = 32\n    n_heads = 4\n    d_head = 32\n    d_state = 16\n    ssd = SSDMinimalDiscrete(embed_dim, block_loc, kwarg_all, device=device,\n        dtype=dtype)\n    X = torch.randn(batch_size, seq_len, n_heads, d_head, device=device,\n        dtype=dtype)\n    A = torch.randn(batch_size, seq_len, n_heads, device=device, dtype=dtype)\n    B = torch.randn(batch_size, seq_len, n_heads, d_state, device=device,\n        dtype=dtype)\n    C = torch.randn(batch_size, seq_len, n_heads, d_state, device=device,\n        dtype=dtype)\n    dt = torch.rand(batch_size, seq_len, n_heads, device=device, dtype=dtype)\n    Z = {'x': X, 'A': A, 'B': B, 'C': C, 'dt': dt, 'chunk_size': chunk_size}\n    _, Z_ = ssd(X, **Z)\n    assert Z_['y'].shape == (batch_size, seq_len, n_heads, d_head\n        ), f\"Expected output shape {batch_size, seq_len, n_heads, d_head}, but got {Z_['y'].shape}\"\n    assert Z_['y'\n        ].dtype == dtype, f\"Expected output dtype {dtype}, but got {Z_['y'].dtype}\"\n    assert Z_['y'\n        ].device == device, f\"Expected output device {device}, but got {Z_['y'].device}\"\n    print('SSDMinimalDiscrete test passed successfully!')\n"
                },
                "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nimport torch.nn.functional as F\nfrom einops import rearrange, repeat\n\n\nclass SSDMinimalDiscrete(GAUBase):\n    \"\"\"\n    SSDMinimalDiscrete (State Space Discrete Minimal) implements a discrete-time state space model.\n\n    This class provides an efficient implementation of the SSM algorithm, particularly\n    suited for processing sequential data in chunks. It uses a minimal discrete-time\n    formulation that is both memory-efficient and computationally effective.\n\n    Args:\n        embed_dim (int): The embedding dimension of the input.\n        block_loc (tuple): The location of the block within the larger model structure.\n        kwarg_all (dict): Additional keyword arguments.\n        device (torch.device, optional): The device to run the module on.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    Inputs:\n        X (torch.Tensor): The input tensor of shape (batch_size, length, n_heads, d_head).\n        x (torch.Tensor): Input tensor, same as X.\n        A (torch.Tensor): State transition tensor of shape (batch_size, length, n_heads).\n        B (torch.Tensor): Input-to-state tensor of shape (batch_size, length, n_heads, d_state).\n        C (torch.Tensor): State-to-output tensor of shape (batch_size, length, n_heads, d_state).\n        dt (torch.Tensor): Time step tensor of shape (batch_size, length, n_heads).\n        chunk_size (int): Size of chunks for processing.\n\n    Outputs:\n        y (torch.Tensor): The output tensor of shape (batch_size, length, n_heads, d_head).\n\n    The class implements the forward pass of the SSM algorithm, including:\n    1. Intra-chunk computations (diagonal blocks)\n    2. Inter-chunk state propagation\n    3. State-to-output conversion\n\n    This implementation is designed to be efficient for long sequences by processing\n    the input in chunks, which allows for better parallelization and memory usage.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n\n    def _forward(self, X, x, A, B, C, dt, chunk_size):\n        \"\"\"\n        Forward pass of SSDMinimalDiscrete.\n\n        Args:\n            X (torch.Tensor): Input tensor of shape (batch_size, length, n_heads, d_head).\n            x (torch.Tensor): Input tensor, same as X.\n            A (torch.Tensor): State transition tensor of shape (batch_size, length, n_heads).\n            B (torch.Tensor): Input-to-state tensor of shape (batch_size, length, n_heads, d_state).\n            C (torch.Tensor): State-to-output tensor of shape (batch_size, length, n_heads, d_state).\n            dt (torch.Tensor): Time step tensor of shape (batch_size, length, n_heads).\n            chunk_size (int): Size of chunks for processing.\n\n        Returns:\n            X (torch.Tensor): Same as input X.\n            Z_ (dict): Dictionary containing the output 'y' of shape (batch_size, length, n_heads, d_head).\n        \"\"\"\n        x = x * dt.unsqueeze(-1)\n        A = A * dt\n        y, _ = self.ssd_minimal_discrete(x, A, B, C, chunk_size)\n        Z_ = {'y': y}\n        return X, Z_\n\n    def segsum(self, x):\n        \"\"\"More stable segment sum calculation.\"\"\"\n        T = x.size(-1)\n        x = repeat(x, '... d -> ... d e', e=T)\n        mask = torch.tril(torch.ones(T, T, device=x.device, dtype=bool),\n            diagonal=-1)\n        x = x.masked_fill(~mask, 0)\n        x_segsum = torch.cumsum(x, dim=-2)\n        mask = torch.tril(torch.ones(T, T, device=x.device, dtype=bool),\n            diagonal=0)\n        x_segsum = x_segsum.masked_fill(~mask, -torch.inf)\n        return x_segsum\n\n    def ssd_minimal_discrete(self, X, A, B, C, block_len, initial_states=None):\n        \"\"\"\n        Arguments:\n            X: (batch_size, length, n_heads, d_head)\n            A: (batch_size, length, n_heads)\n            B: (batch_size, length, n_heads, d_state)\n            C: (batch_size, length, n_heads, d_state)\n            block_len: int\n\n        Return:\n            y: (batch_size, length, n_heads, d_head)\n            final_state: The final state after processing the sequence.\n        \"\"\"\n        assert X.dtype == A.dtype == B.dtype == C.dtype\n        X, A, B, C = [rearrange(x, 'b (c l) ... -> b c l ...', l=block_len) for\n            x in (X, A, B, C)]\n        A = rearrange(A, 'b c l h -> b h c l')\n        A_cumsum = torch.cumsum(A, dim=-1)\n        L = torch.exp(self.segsum(A))\n        Y_diag = torch.einsum('bclhn,bcshn,bhcls,bcshp->bclhp', C, B, L, X)\n        decay_states = torch.exp(A_cumsum[:, :, :, -1:] - A_cumsum)\n        states = torch.einsum('bclhn,bhcl,bclhp->bchpn', B, decay_states, X)\n        if initial_states is None:\n            initial_states = torch.zeros_like(states[:, :1])\n        states = torch.cat([initial_states, states], dim=1)\n        decay_chunk = torch.exp(self.segsum(F.pad(A_cumsum[:, :, :, -1], (1,\n            0))))\n        new_states = torch.einsum('bhzc,bchpn->bzhpn', decay_chunk, states)\n        states, final_state = new_states[:, :-1], new_states[:, -1]\n        state_decay_out = torch.exp(A_cumsum)\n        Y_off = torch.einsum('bclhn,bchpn,bhcl->bclhp', C, states,\n            state_decay_out)\n        Y = rearrange(Y_diag + Y_off, 'b c l h p -> b (c l) h p')\n        return Y, final_state\n",
                "rating": 4.0,
                "spec": "{\"unitname\":\"SSDMinimalDiscrete\",\"document\":\"SSDMinimalDiscrete (State Space Discrete Minimal) implements a discrete-time state space model.\\n\\nThis class provides an efficient implementation of the SSM algorithm, particularly\\nsuited for processing sequential data in chunks. It uses a minimal discrete-time\\nformulation that is both memory-efficient and computationally effective.\\n\\nArgs:\\n    embed_dim (int): The embedding dimension of the input.\\n    block_loc (tuple): The location of the block within the larger model structure.\\n    kwarg_all (dict): Additional keyword arguments.\\n    device (torch.device, optional): The device to run the module on.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n\\nInputs:\\n    X (torch.Tensor): The input tensor of shape (batch_size, length, n_heads, d_head).\\n    x (torch.Tensor): Input tensor, same as X.\\n    A (torch.Tensor): State transition tensor of shape (batch_size, length, n_heads).\\n    B (torch.Tensor): Input-to-state tensor of shape (batch_size, length, n_heads, d_state).\\n    C (torch.Tensor): State-to-output tensor of shape (batch_size, length, n_heads, d_state).\\n    dt (torch.Tensor): Time step tensor of shape (batch_size, length, n_heads).\\n    chunk_size (int): Size of chunks for processing.\\n\\nOutputs:\\n    y (torch.Tensor): The output tensor of shape (batch_size, length, n_heads, d_head).\\n\\nThe class implements the forward pass of the SSM algorithm, including:\\n1. Intra-chunk computations (diagonal blocks)\\n2. Inter-chunk state propagation\\n3. State-to-output conversion\\n\\nThis implementation is designed to be efficient for long sequences by processing\\nthe input in chunks, which allows for better parallelization and memory usage.\",\"inputs\":[\"X\",\"A\",\"B\",\"C\",\"dt\",\"chunk_size\"],\"outputs\":[\"Y\"]}",
                "children": [],
                "suggestions": null,
                "args": {},
                "design_traces": null
            }
        },
        "suggestions": null,
        "name": "wavemamba2"
    },
    "status": "unfinished",
    "history": [
        {
            "tree": {
                "review": null,
                "root": "Mamba2",
                "proposal": "While Transformers have been the main architecture behind deep learning's success in language modeling, state-space models (SSMs) such as Mamba have recently been shown to match or outperform Transformers at small to medium scale. We show that these families of models are actually quite closely related, and develop a rich framework of theoretical connections between SSMs and variants of attention, connected through various decompositions of a well-studied class of structured semiseparable matrices. Our state space duality (SSD) framework allows us to design a new architecture (Mamba-2) whose core layer is an a refinement of Mamba's selective SSM that is 2-8X faster, while continuing to be competitive with Transformers on language modeling.\n",
                "proposal_traces": [],
                "rating": null,
                "declares": {
                    "SSDMinimalDiscrete": "{\"unitname\":\"SSDMinimalDiscrete\",\"requirements\":\"N/A\",\"inputs\":[\"X\",\"A\",\"B\",\"C\",\"dt\",\"chunk_size\"],\"outputs\":[\"Y\"]}"
                },
                "units": {
                    "RMSNorm": {
                        "review": null,
                        "requirements": null,
                        "reuse_from": null,
                        "desc": "\n",
                        "gautests": {
                            "test_rmsnorm": "@gau_test\ndef test_RMSNorm_test_rmsnorm(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    rmsnorm = RMSNorm(embed_dim, block_loc, kwarg_all, device=device, dtype\n        =dtype, **kwarg_all)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    Z = {}\n    y, Z_ = rmsnorm(x, **Z)\n    assert y.shape == (1, 100, 128)\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import Tensor\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RMSNorm(GAUBase):\n    \"\"\"\n    Root Mean Square Layer Normalization (RMSNorm).\n\n    This layer applies a variant of layer normalization that uses only the root mean square\n    statistics, without centering. It's computationally more efficient than standard\n    layer normalization and has been shown to be effective in various NLP tasks.\n\n    Args:\n        embed_dim (int): The size of the input feature dimension.\n        block_loc (tuple): The location of this block in the model architecture.\n        kwarg_all (dict): Additional keyword arguments passed to the parent class.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The dtype of the module's parameters.\n        eps (float, optional): A small constant added to the denominator for numerical stability.\n            Default: 1e-5.\n\n    Attributes:\n        weight (nn.Parameter): Learnable scale parameter of shape (embed_dim,).\n        variance_epsilon (float): The epsilon value used in the normalization formula.\n\n    Shape:\n        - Input: (*, embed_dim)\n        - Output: (*, embed_dim) (same shape as input)\n\n    Examples:\n        >>> rmsnorm = RMSNorm(128, (0, 6), {})\n        >>> x = torch.randn(1, 100, 128)\n        >>> output = rmsnorm(x)\n        >>> print(output.shape)\n        torch.Size([1, 100, 128])\n\n    References:\n        - Paper: \"Root Mean Square Layer Normalization\" by Biao Zhang and Rico Sennrich\n          https://arxiv.org/abs/1910.07467\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, eps=1e-05, **kwargs):\n        \"\"\"If group_size is not None, we do GroupNorm with each group having group_size elements.\n        group_size=None is equivalent to group_size=hidden_size (i.e. there's only 1 group).\n        \"\"\"\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.weight = nn.Parameter(torch.ones(embed_dim, **self.factory_kwargs)\n            )\n        self.variance_epsilon = eps\n\n    def _forward(self, X, **Z):\n        input_dtype = X.dtype\n        X = X.to(torch.float32)\n        variance = X.pow(2).mean(-1, keepdim=True)\n        X = X * torch.rsqrt(variance + self.variance_epsilon)\n        return self.weight * X.to(input_dtype)\n\n\nCHILDREN_DECLARATIONS = []\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"RMSNorm\",\"document\":\"\\n    Root Mean Square Layer Normalization (RMSNorm).\\n\\n    This layer applies a variant of layer normalization that uses only the root mean square\\n    statistics, without centering. It's computationally more efficient than standard\\n    layer normalization and has been shown to be effective in various NLP tasks.\\n\\n    Args:\\n        embed_dim (int): The size of the input feature dimension.\\n        block_loc (tuple): The location of this block in the model architecture.\\n        kwarg_all (dict): Additional keyword arguments passed to the parent class.\\n        device (torch.device, optional): The device on which to allocate the module's parameters.\\n        dtype (torch.dtype, optional): The dtype of the module's parameters.\\n        eps (float, optional): A small constant added to the denominator for numerical stability.\\n            Default: 1e-5.\\n\\n    Attributes:\\n        weight (nn.Parameter): Learnable scale parameter of shape (embed_dim,).\\n        variance_epsilon (float): The epsilon value used in the normalization formula.\\n\\n    Shape:\\n        - Input: (*, embed_dim)\\n        - Output: (*, embed_dim) (same shape as input)\\n\\n    Examples:\\n        >>> rmsnorm = RMSNorm(128, (0, 6), {})\\n        >>> x = torch.randn(1, 100, 128)\\n        >>> output = rmsnorm(x)\\n        >>> print(output.shape)\\n        torch.Size([1, 100, 128])\\n\\n    References:\\n        - Paper: \\\"Root Mean Square Layer Normalization\\\" by Biao Zhang and Rico Sennrich\\n          https://arxiv.org/abs/1910.07467\\n\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {
                            "eps": 1e-05
                        },
                        "design_traces": null
                    },
                    "Mamba2Layer": {
                        "review": null,
                        "requirements": null,
                        "reuse_from": null,
                        "desc": "\n",
                        "gautests": {
                            "test_mamba2layer": "@gau_test\ndef test_Mamba2Layer_test_mamba2layer(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    mamba2layer = Mamba2Layer(embed_dim, block_loc, kwarg_all, device=\n        device, dtype=dtype, **kwarg_all)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    y, _ = mamba2layer(x)\n    assert y.shape == (1, 100, 128)\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nimport math\nfrom einops import rearrange, repeat\n\n\nclass Mamba2Layer(GAUBase):\n    \"\"\"\n    Mamba2Layer: An implementation of the Mamba architecture layer.\n\n    This layer is based on the Mamba architecture, which combines elements of\n    State Space Models (SSMs) and attention mechanisms. It's designed for\n    efficient processing of long sequences.\n\n    Args:\n        embed_dim (int): Dimension of the input embeddings.\n        block_loc (tuple): Location of the block within the model.\n        kwarg_all (dict): Additional keyword arguments.\n        d_state (int, optional): Dimension of the state. Defaults to 64.\n        d_conv (int, optional): Kernel size for the 1D convolution. Defaults to 4.\n        expand (int, optional): Expansion factor for the inner dimension. Defaults to 2.\n        headdim (int, optional): Dimension of each head. Defaults to 128.\n        ngroups (int, optional): Number of groups for group linear operators. Defaults to 1.\n        A_init_range (tuple, optional): Range for initializing the A parameter. Defaults to (1, 16).\n        dt_min (float, optional): Minimum value for dt initialization. Defaults to 0.001.\n        dt_max (float, optional): Maximum value for dt initialization. Defaults to 0.1.\n        dt_init_floor (float, optional): Floor value for dt initialization. Defaults to 1e-4.\n        chunk_size (int, optional): Size of chunks for processing. Defaults to 256.\n        device (torch.device, optional): Device to use for computations.\n        dtype (torch.dtype, optional): Data type to use for computations.\n\n    The Mamba2Layer processes input sequences using a combination of linear projections,\n    1D convolutions, and a selective scan operation (implemented in SSDMinimalDiscrete).\n    It's designed to capture long-range dependencies efficiently.\n\n    The layer includes several components:\n    1. Input projection\n    2. 1D Convolution\n    3. Selective Scan Discrete operation\n    4. Output projection\n\n    The layer also implements a chunking mechanism to process long sequences efficiently.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        d_state=64, d_conv=4, expand=2, headdim=128, ngroups=1,\n        A_init_range=(1, 16), dt_min=0.001, dt_max=0.1, dt_init_floor=\n        0.0001, chunk_size=256, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.d_model = embed_dim\n        self.d_state = d_state\n        self.d_conv = d_conv\n        self.expand = expand\n        self.d_inner = self.expand * self.d_model\n        self.headdim = headdim\n        self.ngroups = ngroups\n        assert self.d_inner % self.headdim == 0\n        self.nheads = self.d_inner // self.headdim\n        self.chunk_size = chunk_size\n        d_in_proj = (2 * self.d_inner + 2 * self.ngroups * self.d_state +\n            self.nheads)\n        self.in_proj = nn.Linear(self.d_model, d_in_proj, bias=True, **self\n            .factory_kwargs)\n        conv_dim = self.d_inner + 2 * self.ngroups * self.d_state\n        self.conv1d = nn.Conv1d(in_channels=conv_dim, out_channels=conv_dim,\n            bias=True, kernel_size=d_conv, groups=conv_dim, padding=d_conv -\n            1, **self.factory_kwargs)\n        self.act = nn.SiLU()\n        dt = torch.exp(torch.rand(self.nheads, **self.factory_kwargs) * (\n            math.log(dt_max) - math.log(dt_min)) + math.log(dt_min))\n        dt = torch.clamp(dt, min=dt_init_floor)\n        inv_dt = dt + torch.log(-torch.expm1(-dt))\n        self.dt_bias = nn.Parameter(inv_dt)\n        self.dt_bias._no_weight_decay = True\n        assert A_init_range[0] > 0 and A_init_range[1] >= A_init_range[0]\n        A = torch.empty(self.nheads, dtype=torch.float32, device=device\n            ).uniform_(*A_init_range)\n        A_log = torch.log(A).to(dtype=dtype)\n        self.A_log = nn.Parameter(A_log)\n        self.A_log._no_weight_decay = True\n        self.norm = nn.LayerNorm(self.d_inner, eps=1e-05, **self.factory_kwargs\n            )\n        self.silu = nn.SiLU()\n        self.out_proj = nn.Linear(self.d_inner, self.d_model, bias=True, **\n            self.factory_kwargs)\n        self.ssd_minimal_discrete = SSDMinimalDiscrete(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n\n    def pad_to_block_length(self, X, block_len):\n        pad_len = (block_len - X.shape[1] % block_len) % block_len\n        if pad_len > 0:\n            padding = torch.zeros(X.shape[0], pad_len, *X.shape[2:], dtype=\n                X.dtype, device=X.device)\n            X = torch.cat([X, padding], dim=1)\n        return X\n\n    def _forward(self, u, **kwargs):\n        \"\"\"\n        u: (B, L, D)\n        Returns: same shape as u\n        \"\"\"\n        batch, _seqlen, dim = u.shape\n        u = self.pad_to_block_length(u, self.chunk_size)\n        seqlen = u.shape[1]\n        zxbcdt = self.in_proj(u)\n        A = -torch.exp(self.A_log)\n        z, xBC, dt = torch.split(zxbcdt, [self.d_inner, self.d_inner + 2 *\n            self.ngroups * self.d_state, self.nheads], dim=-1)\n        dt = F.softplus(dt + self.dt_bias)\n        xBC = self.act(self.conv1d(xBC.transpose(1, 2)).transpose(1, 2))\n        xBC = xBC[:, :seqlen, :]\n        x, B, C = torch.split(xBC, [self.d_inner, self.ngroups * self.\n            d_state, self.ngroups * self.d_state], dim=-1)\n        x = rearrange(x, 'b l (h p) -> b l h p', p=self.headdim)\n        B = rearrange(B, 'b l (g n) -> b l g n', g=self.ngroups)\n        C = rearrange(C, 'b l (g n) -> b l g n', g=self.ngroups)\n        Z = {'x': x, 'A': A, 'B': B, 'C': C, 'dt': dt, 'chunk_size': self.\n            chunk_size}\n        _, Z_ = self.ssd_minimal_discrete(u, **Z)\n        y = Z_.get('y')\n        y = rearrange(y, 'b l h p -> b l (h p)')\n        y = self.norm(y * self.silu(z))\n        out = self.out_proj(y)\n        out = out[:, :_seqlen, :]\n        return out\n\n\nCHILDREN_DECLARATIONS = [UnitDecl(unitname='SSDMinimalDiscrete',\n    requirements='', inputs=['X', 'x', 'A', 'B', 'C', 'dt', 'chunk_size'],\n    outputs=['Y', 'y'])]\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"Mamba2Layer\",\"document\":\"\\n    Mamba2Layer: An implementation of the Mamba architecture layer.\\n\\n    This layer is based on the Mamba architecture, which combines elements of\\n    State Space Models (SSMs) and attention mechanisms. It's designed for\\n    efficient processing of long sequences.\\n\\n    Args:\\n        embed_dim (int): Dimension of the input embeddings.\\n        block_loc (tuple): Location of the block within the model.\\n        kwarg_all (dict): Additional keyword arguments.\\n        d_state (int, optional): Dimension of the state. Defaults to 64.\\n        d_conv (int, optional): Kernel size for the 1D convolution. Defaults to 4.\\n        expand (int, optional): Expansion factor for the inner dimension. Defaults to 2.\\n        headdim (int, optional): Dimension of each head. Defaults to 128.\\n        ngroups (int, optional): Number of groups for group linear operators. Defaults to 1.\\n        A_init_range (tuple, optional): Range for initializing the A parameter. Defaults to (1, 16).\\n        dt_min (float, optional): Minimum value for dt initialization. Defaults to 0.001.\\n        dt_max (float, optional): Maximum value for dt initialization. Defaults to 0.1.\\n        dt_init_floor (float, optional): Floor value for dt initialization. Defaults to 1e-4.\\n        chunk_size (int, optional): Size of chunks for processing. Defaults to 256.\\n        device (torch.device, optional): Device to use for computations.\\n        dtype (torch.dtype, optional): Data type to use for computations.\\n\\n    The Mamba2Layer processes input sequences using a combination of linear projections,\\n    1D convolutions, and a selective scan operation (implemented in SSDMinimalDiscrete).\\n    It's designed to capture long-range dependencies efficiently.\\n\\n    The layer includes several components:\\n    1. Input projection\\n    2. 1D Convolution\\n    3. Selective Scan Discrete operation\\n    4. Output projection\\n\\n    The layer also implements a chunking mechanism to process long sequences efficiently.\\n    \",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [
                            "SSDMinimalDiscrete"
                        ],
                        "suggestions": null,
                        "args": {
                            "chunk_size": 256,
                            "dt_init_floor": 0.0001,
                            "d_conv": 4,
                            "A_init_range": [
                                1,
                                16
                            ],
                            "dt_min": 0.001,
                            "headdim": 128,
                            "ngroups": 1,
                            "dt_max": 0.1,
                            "d_state": 64,
                            "expand": 2
                        },
                        "design_traces": null
                    },
                    "Mamba2": {
                        "review": null,
                        "requirements": null,
                        "reuse_from": null,
                        "desc": "\n",
                        "gautests": {
                            "test_mamba2": "@gau_test\ndef test_Mamba2_test_mamba2(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    mamba2 = Mamba2(embed_dim, block_loc, kwarg_all, device=device, dtype=\n        dtype, **kwarg_all)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    Z = {}\n    y, Z_ = mamba2(x, **Z)\n    assert y.shape == (1, 100, 128)\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass Mamba2(GAUBase):\n    \"\"\"\n    Mamba2: A Generalized Autoregressive Unit (GAU) implementing a double-layer Mamba architecture.\n\n    This class represents a Mamba2 block, which consists of two Mamba layers with normalization.\n    It's designed to process sequential data in a causal, differentiable, and parallelizable manner.\n\n    Architecture:\n        1. Input Normalization (RMSNorm)\n        2. First Mamba Layer\n        3. Residual Connection\n        4. Second Normalization (RMSNorm)\n        5. Second Mamba Layer\n        6. Final Residual Connection\n\n    Args:\n        embed_dim (int): The dimensionality of the input and output embeddings.\n        block_loc (tuple): The location of this block within the larger model architecture.\n        kwarg_all (dict): Additional keyword arguments to be passed to child components.\n        device (torch.device, optional): The device on which to allocate tensors.\n        dtype (torch.dtype, optional): The default dtype for tensors in this module.\n\n    Inputs:\n        X (torch.Tensor): Input tensor of shape (batch_size, sequence_length, embed_dim).\n        **Z: Additional keyword arguments for potential future extensions.\n\n    Outputs:\n        X (torch.Tensor): Output tensor of shape (batch_size, sequence_length, embed_dim).\n        Z (dict): Updated keyword arguments.\n\n    Note:\n        This implementation adheres to the GAU (Generalized Autoregressive Unit) interface\n        and maintains causal properties for autoregressive processing.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.mamba1 = Mamba2Layer(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.mamba2 = Mamba2Layer(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.norm1 = RMSNorm(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.norm2 = RMSNorm(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, Z = self.norm1(X, **Z)\n        X2, Z = self.mamba1(X1, **Z)\n        X = X + X2\n        X3, Z = self.norm2(X, **Z)\n        X4, Z = self.mamba2(X3, **Z)\n        X = X + X4\n        return X, Z\n\n\nCHILDREN_DECLARATIONS = [UnitDecl(unitname='Mamba2Layer', requirements='',\n    inputs=['X'], outputs=['Y']), UnitDecl(unitname='RMSNorm', requirements\n    ='', inputs=['X'], outputs=['Y'])]\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"Mamba2\",\"document\":\"\\n    Mamba2: A Generalized Autoregressive Unit (GAU) implementing a double-layer Mamba architecture.\\n\\n    This class represents a Mamba2 block, which consists of two Mamba layers with normalization.\\n    It's designed to process sequential data in a causal, differentiable, and parallelizable manner.\\n\\n    Architecture:\\n        1. Input Normalization (RMSNorm)\\n        2. First Mamba Layer\\n        3. Residual Connection\\n        4. Second Normalization (RMSNorm)\\n        5. Second Mamba Layer\\n        6. Final Residual Connection\\n\\n    Args:\\n        embed_dim (int): The dimensionality of the input and output embeddings.\\n        block_loc (tuple): The location of this block within the larger model architecture.\\n        kwarg_all (dict): Additional keyword arguments to be passed to child components.\\n        device (torch.device, optional): The device on which to allocate tensors.\\n        dtype (torch.dtype, optional): The default dtype for tensors in this module.\\n\\n    Inputs:\\n        X (torch.Tensor): Input tensor of shape (batch_size, sequence_length, embed_dim).\\n        **Z: Additional keyword arguments for potential future extensions.\\n\\n    Outputs:\\n        X (torch.Tensor): Output tensor of shape (batch_size, sequence_length, embed_dim).\\n        Z (dict): Updated keyword arguments.\\n\\n    Note:\\n        This implementation adheres to the GAU (Generalized Autoregressive Unit) interface\\n        and maintains causal properties for autoregressive processing.\\n    \",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [
                            "Mamba2Layer",
                            "RMSNorm"
                        ],
                        "suggestions": null,
                        "args": {},
                        "design_traces": null
                    },
                    "SSDMinimalDiscrete": {
                        "review": "## Feedback Report\n\n### Overall Assessment\n```rating 4.0```\n\n### Strengths of the Implementation\n1. **Successful Functionality**: The implementation has passed all functionality checks, indicating that the code is robust and functions as expected within the larger language model framework.\n2. **Efficient Chunk-Based Processing**: The implementation efficiently processes sequences in chunks, which aligns with the proposal's goal of improving memory usage and computational efficiency.\n3. **Comprehensive Documentation**: The coder has provided detailed docstrings that clearly explain the inputs, outputs, and functionality of the methods, making the code easier to understand and maintain.\n\n### Areas for Improvement and Specific Suggestions\n1. **Code Optimization**:\n   - While the code is functioning correctly, there may still be opportunities to optimize the tensor operations for better performance, especially in the `ssd_minimal_discrete` method. Consider reviewing the use of `einsum` and `rearrange` for potential simplifications or performance improvements.\n   \n2. **Expand Unit Tests**:\n   - Although the functionality checks passed, expanding the unit tests to cover more edge cases and different input scenarios can further ensure robustness. This includes testing with varying batch sizes, sequence lengths, and edge cases like empty inputs or extreme values.\n\n3. **Code Readability**:\n   - Adding inline comments to explain complex operations or decisions in the code can enhance readability and make it easier for future developers to understand the logic.\n\n### Comments on Innovation and Potential Impact\n- The integration of chunk-based processing is a significant innovation that aligns with the proposal's goals of improving efficiency and scalability. This approach can potentially lead to better performance on long sequences, which is a common challenge in language modeling.\n- The current implementation is well-positioned to integrate additional features from the proposal, such as adaptive compression and wavelet-based analysis, which could further enhance the model's capabilities.\n\n### Recommendations for the Coder\n1. **Review and Optimize**: Continue to review the code for potential optimizations, particularly in tensor operations, to ensure maximum efficiency.\n2. **Enhance Testing**: Expand the unit tests to cover a broader range of scenarios, ensuring the implementation remains robust under various conditions.\n3. **Prepare for Future Enhancements**: Consider how the current implementation can be extended to incorporate additional features from the proposal, such as adaptive compression techniques.\n\nBy addressing these areas, the coder can further enhance the implementation's robustness, efficiency, and alignment with the proposal's goals. The successful functionality check is a strong indicator of the implementation's quality, and with continued refinement, it can serve as a solid foundation for future developments.",
                        "reuse_from": null,
                        "requirements": "N/A",
                        "desc": null,
                        "gautests": {
                            "test_ssd_minimal_discrete": "@gau_test\ndef test_SSDMinimalDiscrete_test_ssd_minimal_discrete(device=None, dtype=None\n    ) ->None:\n    batch_size = 2\n    L = 16\n    n_heads = 4\n    d_head = 32\n    d_state = 64\n    chunk_size = 4\n    embed_dim = n_heads * d_head\n    X = torch.randn(batch_size, L, n_heads, d_head, device=device, dtype=dtype)\n    x = X.clone()\n    A = torch.randn(batch_size, L, n_heads, device=device, dtype=dtype)\n    B = torch.randn(batch_size, L, n_heads, d_state, device=device, dtype=dtype\n        )\n    C = torch.randn(batch_size, L, n_heads, d_state, device=device, dtype=dtype\n        )\n    dt = torch.abs(torch.randn(batch_size, L, n_heads, device=device, dtype\n        =dtype)) + 0.001\n    model = SSDMinimalDiscrete(embed_dim, (0, 1), {}, device=device, dtype=\n        dtype)\n    X_out, Z_ = model._forward(X, x=x, A=A, B=B, C=C, dt=dt, chunk_size=\n        chunk_size)\n    y = Z_['y']\n    assert y.shape == (batch_size, L, n_heads, d_head\n        ), f'Output shape mismatch. Expected {batch_size, L, n_heads, d_head}, got {y.shape}'\n    assert torch.isfinite(y).all(), 'Output contains NaNs or infinite values'\n",
                            "test_ssdminimaldiscrete": "@gau_test\ndef test_SSDMinimalDiscrete_test_ssdminimaldiscrete(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    chunk_size = 16\n    batch_size = 2\n    seq_len = 32\n    n_heads = 4\n    d_head = 32\n    d_state = 16\n    ssd = SSDMinimalDiscrete(embed_dim, block_loc, kwarg_all, device=device,\n        dtype=dtype)\n    X = torch.randn(batch_size, seq_len, n_heads, d_head, device=device,\n        dtype=dtype)\n    A = torch.randn(batch_size, seq_len, n_heads, device=device, dtype=dtype)\n    B = torch.randn(batch_size, seq_len, n_heads, d_state, device=device,\n        dtype=dtype)\n    C = torch.randn(batch_size, seq_len, n_heads, d_state, device=device,\n        dtype=dtype)\n    dt = torch.rand(batch_size, seq_len, n_heads, device=device, dtype=dtype)\n    Z = {'x': X, 'A': A, 'B': B, 'C': C, 'dt': dt, 'chunk_size': chunk_size}\n    _, Z_ = ssd(X, **Z)\n    assert Z_['y'].shape == (batch_size, seq_len, n_heads, d_head\n        ), f\"Expected output shape {batch_size, seq_len, n_heads, d_head}, but got {Z_['y'].shape}\"\n    assert Z_['y'\n        ].dtype == dtype, f\"Expected output dtype {dtype}, but got {Z_['y'].dtype}\"\n    assert Z_['y'\n        ].device == device, f\"Expected output device {device}, but got {Z_['y'].device}\"\n    print('SSDMinimalDiscrete test passed successfully!')\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nimport torch.nn.functional as F\nfrom einops import rearrange, repeat\n\n\nclass SSDMinimalDiscrete(GAUBase):\n    \"\"\"\n    SSDMinimalDiscrete (State Space Discrete Minimal) implements a discrete-time state space model.\n\n    This class provides an efficient implementation of the SSM algorithm, particularly\n    suited for processing sequential data in chunks. It uses a minimal discrete-time\n    formulation that is both memory-efficient and computationally effective.\n\n    Args:\n        embed_dim (int): The embedding dimension of the input.\n        block_loc (tuple): The location of the block within the larger model structure.\n        kwarg_all (dict): Additional keyword arguments.\n        device (torch.device, optional): The device to run the module on.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    Inputs:\n        X (torch.Tensor): The input tensor of shape (batch_size, length, n_heads, d_head).\n        x (torch.Tensor): Input tensor, same as X.\n        A (torch.Tensor): State transition tensor of shape (batch_size, length, n_heads).\n        B (torch.Tensor): Input-to-state tensor of shape (batch_size, length, n_heads, d_state).\n        C (torch.Tensor): State-to-output tensor of shape (batch_size, length, n_heads, d_state).\n        dt (torch.Tensor): Time step tensor of shape (batch_size, length, n_heads).\n        chunk_size (int): Size of chunks for processing.\n\n    Outputs:\n        y (torch.Tensor): The output tensor of shape (batch_size, length, n_heads, d_head).\n\n    The class implements the forward pass of the SSM algorithm, including:\n    1. Intra-chunk computations (diagonal blocks)\n    2. Inter-chunk state propagation\n    3. State-to-output conversion\n\n    This implementation is designed to be efficient for long sequences by processing\n    the input in chunks, which allows for better parallelization and memory usage.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n\n    def _forward(self, X, x, A, B, C, dt, chunk_size):\n        \"\"\"\n        Forward pass of SSDMinimalDiscrete.\n\n        Args:\n            X (torch.Tensor): Input tensor of shape (batch_size, length, n_heads, d_head).\n            x (torch.Tensor): Input tensor, same as X.\n            A (torch.Tensor): State transition tensor of shape (batch_size, length, n_heads).\n            B (torch.Tensor): Input-to-state tensor of shape (batch_size, length, n_heads, d_state).\n            C (torch.Tensor): State-to-output tensor of shape (batch_size, length, n_heads, d_state).\n            dt (torch.Tensor): Time step tensor of shape (batch_size, length, n_heads).\n            chunk_size (int): Size of chunks for processing.\n\n        Returns:\n            X (torch.Tensor): Same as input X.\n            Z_ (dict): Dictionary containing the output 'y' of shape (batch_size, length, n_heads, d_head).\n        \"\"\"\n        x = x * dt.unsqueeze(-1)\n        A = A * dt\n        y, _ = self.ssd_minimal_discrete(x, A, B, C, chunk_size)\n        Z_ = {'y': y}\n        return X, Z_\n\n    def segsum(self, x):\n        \"\"\"More stable segment sum calculation.\"\"\"\n        T = x.size(-1)\n        x = repeat(x, '... d -> ... d e', e=T)\n        mask = torch.tril(torch.ones(T, T, device=x.device, dtype=bool),\n            diagonal=-1)\n        x = x.masked_fill(~mask, 0)\n        x_segsum = torch.cumsum(x, dim=-2)\n        mask = torch.tril(torch.ones(T, T, device=x.device, dtype=bool),\n            diagonal=0)\n        x_segsum = x_segsum.masked_fill(~mask, -torch.inf)\n        return x_segsum\n\n    def ssd_minimal_discrete(self, X, A, B, C, block_len, initial_states=None):\n        \"\"\"\n        Arguments:\n            X: (batch_size, length, n_heads, d_head)\n            A: (batch_size, length, n_heads)\n            B: (batch_size, length, n_heads, d_state)\n            C: (batch_size, length, n_heads, d_state)\n            block_len: int\n\n        Return:\n            y: (batch_size, length, n_heads, d_head)\n            final_state: The final state after processing the sequence.\n        \"\"\"\n        assert X.dtype == A.dtype == B.dtype == C.dtype\n        X, A, B, C = [rearrange(x, 'b (c l) ... -> b c l ...', l=block_len) for\n            x in (X, A, B, C)]\n        A = rearrange(A, 'b c l h -> b h c l')\n        A_cumsum = torch.cumsum(A, dim=-1)\n        L = torch.exp(self.segsum(A))\n        Y_diag = torch.einsum('bclhn,bcshn,bhcls,bcshp->bclhp', C, B, L, X)\n        decay_states = torch.exp(A_cumsum[:, :, :, -1:] - A_cumsum)\n        states = torch.einsum('bclhn,bhcl,bclhp->bchpn', B, decay_states, X)\n        if initial_states is None:\n            initial_states = torch.zeros_like(states[:, :1])\n        states = torch.cat([initial_states, states], dim=1)\n        decay_chunk = torch.exp(self.segsum(F.pad(A_cumsum[:, :, :, -1], (1,\n            0))))\n        new_states = torch.einsum('bhzc,bchpn->bzhpn', decay_chunk, states)\n        states, final_state = new_states[:, :-1], new_states[:, -1]\n        state_decay_out = torch.exp(A_cumsum)\n        Y_off = torch.einsum('bclhn,bchpn,bhcl->bclhp', C, states,\n            state_decay_out)\n        Y = rearrange(Y_diag + Y_off, 'b c l h p -> b (c l) h p')\n        return Y, final_state\n",
                        "rating": 4.0,
                        "spec": "{\"unitname\":\"SSDMinimalDiscrete\",\"document\":\"SSDMinimalDiscrete (State Space Discrete Minimal) implements a discrete-time state space model.\\n\\nThis class provides an efficient implementation of the SSM algorithm, particularly\\nsuited for processing sequential data in chunks. It uses a minimal discrete-time\\nformulation that is both memory-efficient and computationally effective.\\n\\nArgs:\\n    embed_dim (int): The embedding dimension of the input.\\n    block_loc (tuple): The location of the block within the larger model structure.\\n    kwarg_all (dict): Additional keyword arguments.\\n    device (torch.device, optional): The device to run the module on.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n\\nInputs:\\n    X (torch.Tensor): The input tensor of shape (batch_size, length, n_heads, d_head).\\n    x (torch.Tensor): Input tensor, same as X.\\n    A (torch.Tensor): State transition tensor of shape (batch_size, length, n_heads).\\n    B (torch.Tensor): Input-to-state tensor of shape (batch_size, length, n_heads, d_state).\\n    C (torch.Tensor): State-to-output tensor of shape (batch_size, length, n_heads, d_state).\\n    dt (torch.Tensor): Time step tensor of shape (batch_size, length, n_heads).\\n    chunk_size (int): Size of chunks for processing.\\n\\nOutputs:\\n    y (torch.Tensor): The output tensor of shape (batch_size, length, n_heads, d_head).\\n\\nThe class implements the forward pass of the SSM algorithm, including:\\n1. Intra-chunk computations (diagonal blocks)\\n2. Inter-chunk state propagation\\n3. State-to-output conversion\\n\\nThis implementation is designed to be efficient for long sequences by processing\\nthe input in chunks, which allows for better parallelization and memory usage.\",\"inputs\":[\"X\",\"A\",\"B\",\"C\",\"dt\",\"chunk_size\"],\"outputs\":[\"Y\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {},
                        "design_traces": null
                    }
                },
                "suggestions": null,
                "name": "wavemamba2"
            },
            "costs": {
                "DESIGN_PROPOSER": 0,
                "IMPLEMENTATION_PLANNER": 0,
                "IMPLEMENTATION_CODER": 19.317705,
                "PROPOSAL_REVIEWER": 0,
                "SEARCH_ASSISTANT": 0,
                "IMPLEMENTATION_OBSERVER": 2.579545
            },
            "status": "unfinished",
            "user_input": "",
            "design_cfg": {
                "max_attemps": {
                    "post_refinement": 0,
                    "max_search_rounds": 3,
                    "implementation_debug": 7,
                    "design_proposal": 10
                },
                "threshold": {
                    "proposal_rating": 4.0,
                    "implementation_rating": 3.0
                },
                "use_unlimited_prompt": true,
                "mutation_no_tree": true,
                "agent_types": {
                    "DESIGN_PROPOSER": "hybrid",
                    "IMPLEMENTATION_PLANNER": "hybrid",
                    "IMPLEMENTATION_CODER": "hybrid",
                    "PROPOSAL_REVIEWER": "hybrid",
                    "IMPLEMENTATION_OBSERVER": "hybrid",
                    "SEARCH_ASSISTANT": "None"
                },
                "running_mode": "Proposal + Implementation",
                "unittest_pass_required": false,
                "crossover_no_ref": true,
                "scratch_no_tree": true,
                "agent_weights": {
                    "DESIGN_PROPOSER": [
                        0.05,
                        0.0,
                        0.6000000000000001,
                        0.2,
                        0.15
                    ],
                    "IMPLEMENTATION_PLANNER": [
                        0.05000000000000002,
                        0.0,
                        0.44999999999999996,
                        0.3,
                        0.20000000000000007
                    ],
                    "IMPLEMENTATION_CODER": [
                        0.0,
                        0.0,
                        0.3,
                        0.4999999999999996,
                        0.2
                    ],
                    "PROPOSAL_REVIEWER": [
                        0.10000000000000002,
                        0.0,
                        0.5499999999999999,
                        0.2,
                        0.15000000000000002
                    ],
                    "IMPLEMENTATION_OBSERVER": [
                        0.05,
                        0.0,
                        0.15000000000000002,
                        0.15000000000000002,
                        0.6499999999999999,
                        0.0
                    ]
                },
                "termination": {
                    "max_debug_budget": 0,
                    "max_failed_rounds": 3,
                    "max_total_budget": 0
                },
                "num_samples": {
                    "implementation": 1,
                    "rerank_method": "rating",
                    "proposal": 1
                },
                "_agent_types": {
                    "DESIGN_PROPOSER": "o1_mini",
                    "IMPLEMENTATION_PLANNER": "claude3.5_sonnet",
                    "IMPLEMENTATION_CODER": "o1_preview",
                    "PROPOSAL_REVIEWER": "claude3.5_sonnet",
                    "SEARCH_ASSISTANT": "None",
                    "IMPLEMENTATION_OBSERVER": "gpt4o_0806"
                },
                "search_settings": {
                    "proposal_search": true,
                    "proposal_review_search": true,
                    "search_for_papers_num": 10
                },
                "max_attempts": {
                    "post_refinement": 0,
                    "max_search_rounds": 4,
                    "implementation_debug": 5,
                    "design_proposal": 5
                }
            }
        },
        {
            "tree": {
                "review": null,
                "root": "Mamba2",
                "proposal": "While Transformers have been the main architecture behind deep learning's success in language modeling, state-space models (SSMs) such as Mamba have recently been shown to match or outperform Transformers at small to medium scale. We show that these families of models are actually quite closely related, and develop a rich framework of theoretical connections between SSMs and variants of attention, connected through various decompositions of a well-studied class of structured semiseparable matrices. Our state space duality (SSD) framework allows us to design a new architecture (Mamba-2) whose core layer is an a refinement of Mamba's selective SSM that is 2-8X faster, while continuing to be competitive with Transformers on language modeling.\n",
                "units": {
                    "RMSNorm": {
                        "review": null,
                        "requirements": null,
                        "reuse_from": null,
                        "desc": "\n",
                        "gautests": {
                            "test_rmsnorm": "@gau_test\ndef test_RMSNorm_test_rmsnorm(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    rmsnorm = RMSNorm(embed_dim, block_loc, kwarg_all, device=device, dtype\n        =dtype, **kwarg_all)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    Z = {}\n    y, Z_ = rmsnorm(x, **Z)\n    assert y.shape == (1, 100, 128)\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import Tensor\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RMSNorm(GAUBase):\n    \"\"\"\n    Root Mean Square Layer Normalization (RMSNorm).\n\n    This layer applies a variant of layer normalization that uses only the root mean square\n    statistics, without centering. It's computationally more efficient than standard\n    layer normalization and has been shown to be effective in various NLP tasks.\n\n    Args:\n        embed_dim (int): The size of the input feature dimension.\n        block_loc (tuple): The location of this block in the model architecture.\n        kwarg_all (dict): Additional keyword arguments passed to the parent class.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The dtype of the module's parameters.\n        eps (float, optional): A small constant added to the denominator for numerical stability.\n            Default: 1e-5.\n\n    Attributes:\n        weight (nn.Parameter): Learnable scale parameter of shape (embed_dim,).\n        variance_epsilon (float): The epsilon value used in the normalization formula.\n\n    Shape:\n        - Input: (*, embed_dim)\n        - Output: (*, embed_dim) (same shape as input)\n\n    Examples:\n        >>> rmsnorm = RMSNorm(128, (0, 6), {})\n        >>> x = torch.randn(1, 100, 128)\n        >>> output = rmsnorm(x)\n        >>> print(output.shape)\n        torch.Size([1, 100, 128])\n\n    References:\n        - Paper: \"Root Mean Square Layer Normalization\" by Biao Zhang and Rico Sennrich\n          https://arxiv.org/abs/1910.07467\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, eps=1e-05, **kwargs):\n        \"\"\"If group_size is not None, we do GroupNorm with each group having group_size elements.\n        group_size=None is equivalent to group_size=hidden_size (i.e. there's only 1 group).\n        \"\"\"\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.weight = nn.Parameter(torch.ones(embed_dim, **self.factory_kwargs)\n            )\n        self.variance_epsilon = eps\n\n    def _forward(self, X, **Z):\n        input_dtype = X.dtype\n        X = X.to(torch.float32)\n        variance = X.pow(2).mean(-1, keepdim=True)\n        X = X * torch.rsqrt(variance + self.variance_epsilon)\n        return self.weight * X.to(input_dtype)\n\n\nCHILDREN_DECLARATIONS = []\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"RMSNorm\",\"document\":\"\\n    Root Mean Square Layer Normalization (RMSNorm).\\n\\n    This layer applies a variant of layer normalization that uses only the root mean square\\n    statistics, without centering. It's computationally more efficient than standard\\n    layer normalization and has been shown to be effective in various NLP tasks.\\n\\n    Args:\\n        embed_dim (int): The size of the input feature dimension.\\n        block_loc (tuple): The location of this block in the model architecture.\\n        kwarg_all (dict): Additional keyword arguments passed to the parent class.\\n        device (torch.device, optional): The device on which to allocate the module's parameters.\\n        dtype (torch.dtype, optional): The dtype of the module's parameters.\\n        eps (float, optional): A small constant added to the denominator for numerical stability.\\n            Default: 1e-5.\\n\\n    Attributes:\\n        weight (nn.Parameter): Learnable scale parameter of shape (embed_dim,).\\n        variance_epsilon (float): The epsilon value used in the normalization formula.\\n\\n    Shape:\\n        - Input: (*, embed_dim)\\n        - Output: (*, embed_dim) (same shape as input)\\n\\n    Examples:\\n        >>> rmsnorm = RMSNorm(128, (0, 6), {})\\n        >>> x = torch.randn(1, 100, 128)\\n        >>> output = rmsnorm(x)\\n        >>> print(output.shape)\\n        torch.Size([1, 100, 128])\\n\\n    References:\\n        - Paper: \\\"Root Mean Square Layer Normalization\\\" by Biao Zhang and Rico Sennrich\\n          https://arxiv.org/abs/1910.07467\\n\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {
                            "eps": 1e-05
                        },
                        "design_traces": null
                    },
                    "Mamba2Layer": {
                        "review": null,
                        "requirements": null,
                        "reuse_from": null,
                        "desc": "\n",
                        "gautests": {
                            "test_mamba2layer": "@gau_test\ndef test_Mamba2Layer_test_mamba2layer(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    mamba2layer = Mamba2Layer(embed_dim, block_loc, kwarg_all, device=\n        device, dtype=dtype, **kwarg_all)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    y, _ = mamba2layer(x)\n    assert y.shape == (1, 100, 128)\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nimport math\nfrom einops import rearrange, repeat\n\n\nclass Mamba2Layer(GAUBase):\n    \"\"\"\n    Mamba2Layer: An implementation of the Mamba architecture layer.\n\n    This layer is based on the Mamba architecture, which combines elements of\n    State Space Models (SSMs) and attention mechanisms. It's designed for\n    efficient processing of long sequences.\n\n    Args:\n        embed_dim (int): Dimension of the input embeddings.\n        block_loc (tuple): Location of the block within the model.\n        kwarg_all (dict): Additional keyword arguments.\n        d_state (int, optional): Dimension of the state. Defaults to 64.\n        d_conv (int, optional): Kernel size for the 1D convolution. Defaults to 4.\n        expand (int, optional): Expansion factor for the inner dimension. Defaults to 2.\n        headdim (int, optional): Dimension of each head. Defaults to 128.\n        ngroups (int, optional): Number of groups for group linear operators. Defaults to 1.\n        A_init_range (tuple, optional): Range for initializing the A parameter. Defaults to (1, 16).\n        dt_min (float, optional): Minimum value for dt initialization. Defaults to 0.001.\n        dt_max (float, optional): Maximum value for dt initialization. Defaults to 0.1.\n        dt_init_floor (float, optional): Floor value for dt initialization. Defaults to 1e-4.\n        chunk_size (int, optional): Size of chunks for processing. Defaults to 256.\n        device (torch.device, optional): Device to use for computations.\n        dtype (torch.dtype, optional): Data type to use for computations.\n\n    The Mamba2Layer processes input sequences using a combination of linear projections,\n    1D convolutions, and a selective scan operation (implemented in SSDMinimalDiscrete).\n    It's designed to capture long-range dependencies efficiently.\n\n    The layer includes several components:\n    1. Input projection\n    2. 1D Convolution\n    3. Selective Scan Discrete operation\n    4. Output projection\n\n    The layer also implements a chunking mechanism to process long sequences efficiently.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        d_state=64, d_conv=4, expand=2, headdim=128, ngroups=1,\n        A_init_range=(1, 16), dt_min=0.001, dt_max=0.1, dt_init_floor=\n        0.0001, chunk_size=256, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.d_model = embed_dim\n        self.d_state = d_state\n        self.d_conv = d_conv\n        self.expand = expand\n        self.d_inner = self.expand * self.d_model\n        self.headdim = headdim\n        self.ngroups = ngroups\n        assert self.d_inner % self.headdim == 0\n        self.nheads = self.d_inner // self.headdim\n        self.chunk_size = chunk_size\n        d_in_proj = (2 * self.d_inner + 2 * self.ngroups * self.d_state +\n            self.nheads)\n        self.in_proj = nn.Linear(self.d_model, d_in_proj, bias=True, **self\n            .factory_kwargs)\n        conv_dim = self.d_inner + 2 * self.ngroups * self.d_state\n        self.conv1d = nn.Conv1d(in_channels=conv_dim, out_channels=conv_dim,\n            bias=True, kernel_size=d_conv, groups=conv_dim, padding=d_conv -\n            1, **self.factory_kwargs)\n        self.act = nn.SiLU()\n        dt = torch.exp(torch.rand(self.nheads, **self.factory_kwargs) * (\n            math.log(dt_max) - math.log(dt_min)) + math.log(dt_min))\n        dt = torch.clamp(dt, min=dt_init_floor)\n        inv_dt = dt + torch.log(-torch.expm1(-dt))\n        self.dt_bias = nn.Parameter(inv_dt)\n        self.dt_bias._no_weight_decay = True\n        assert A_init_range[0] > 0 and A_init_range[1] >= A_init_range[0]\n        A = torch.empty(self.nheads, dtype=torch.float32, device=device\n            ).uniform_(*A_init_range)\n        A_log = torch.log(A).to(dtype=dtype)\n        self.A_log = nn.Parameter(A_log)\n        self.A_log._no_weight_decay = True\n        self.norm = nn.LayerNorm(self.d_inner, eps=1e-05, **self.factory_kwargs\n            )\n        self.silu = nn.SiLU()\n        self.out_proj = nn.Linear(self.d_inner, self.d_model, bias=True, **\n            self.factory_kwargs)\n        self.ssd_minimal_discrete = SSDMinimalDiscrete(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n\n    def pad_to_block_length(self, X, block_len):\n        pad_len = (block_len - X.shape[1] % block_len) % block_len\n        if pad_len > 0:\n            padding = torch.zeros(X.shape[0], pad_len, *X.shape[2:], dtype=\n                X.dtype, device=X.device)\n            X = torch.cat([X, padding], dim=1)\n        return X\n\n    def _forward(self, u, **kwargs):\n        \"\"\"\n        u: (B, L, D)\n        Returns: same shape as u\n        \"\"\"\n        batch, _seqlen, dim = u.shape\n        u = self.pad_to_block_length(u, self.chunk_size)\n        seqlen = u.shape[1]\n        zxbcdt = self.in_proj(u)\n        A = -torch.exp(self.A_log)\n        z, xBC, dt = torch.split(zxbcdt, [self.d_inner, self.d_inner + 2 *\n            self.ngroups * self.d_state, self.nheads], dim=-1)\n        dt = F.softplus(dt + self.dt_bias)\n        xBC = self.act(self.conv1d(xBC.transpose(1, 2)).transpose(1, 2))\n        xBC = xBC[:, :seqlen, :]\n        x, B, C = torch.split(xBC, [self.d_inner, self.ngroups * self.\n            d_state, self.ngroups * self.d_state], dim=-1)\n        x = rearrange(x, 'b l (h p) -> b l h p', p=self.headdim)\n        B = rearrange(B, 'b l (g n) -> b l g n', g=self.ngroups)\n        C = rearrange(C, 'b l (g n) -> b l g n', g=self.ngroups)\n        Z = {'x': x, 'A': A, 'B': B, 'C': C, 'dt': dt, 'chunk_size': self.\n            chunk_size}\n        _, Z_ = self.ssd_minimal_discrete(u, **Z)\n        y = Z_.get('y')\n        y = rearrange(y, 'b l h p -> b l (h p)')\n        y = self.norm(y * self.silu(z))\n        out = self.out_proj(y)\n        out = out[:, :_seqlen, :]\n        return out\n\n\nCHILDREN_DECLARATIONS = [UnitDecl(unitname='SSDMinimalDiscrete',\n    requirements='', inputs=['X', 'x', 'A', 'B', 'C', 'dt', 'chunk_size'],\n    outputs=['Y', 'y'])]\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"Mamba2Layer\",\"document\":\"\\n    Mamba2Layer: An implementation of the Mamba architecture layer.\\n\\n    This layer is based on the Mamba architecture, which combines elements of\\n    State Space Models (SSMs) and attention mechanisms. It's designed for\\n    efficient processing of long sequences.\\n\\n    Args:\\n        embed_dim (int): Dimension of the input embeddings.\\n        block_loc (tuple): Location of the block within the model.\\n        kwarg_all (dict): Additional keyword arguments.\\n        d_state (int, optional): Dimension of the state. Defaults to 64.\\n        d_conv (int, optional): Kernel size for the 1D convolution. Defaults to 4.\\n        expand (int, optional): Expansion factor for the inner dimension. Defaults to 2.\\n        headdim (int, optional): Dimension of each head. Defaults to 128.\\n        ngroups (int, optional): Number of groups for group linear operators. Defaults to 1.\\n        A_init_range (tuple, optional): Range for initializing the A parameter. Defaults to (1, 16).\\n        dt_min (float, optional): Minimum value for dt initialization. Defaults to 0.001.\\n        dt_max (float, optional): Maximum value for dt initialization. Defaults to 0.1.\\n        dt_init_floor (float, optional): Floor value for dt initialization. Defaults to 1e-4.\\n        chunk_size (int, optional): Size of chunks for processing. Defaults to 256.\\n        device (torch.device, optional): Device to use for computations.\\n        dtype (torch.dtype, optional): Data type to use for computations.\\n\\n    The Mamba2Layer processes input sequences using a combination of linear projections,\\n    1D convolutions, and a selective scan operation (implemented in SSDMinimalDiscrete).\\n    It's designed to capture long-range dependencies efficiently.\\n\\n    The layer includes several components:\\n    1. Input projection\\n    2. 1D Convolution\\n    3. Selective Scan Discrete operation\\n    4. Output projection\\n\\n    The layer also implements a chunking mechanism to process long sequences efficiently.\\n    \",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [
                            "SSDMinimalDiscrete"
                        ],
                        "suggestions": null,
                        "args": {
                            "chunk_size": 256,
                            "dt_init_floor": 0.0001,
                            "d_conv": 4,
                            "A_init_range": [
                                1,
                                16
                            ],
                            "dt_min": 0.001,
                            "headdim": 128,
                            "ngroups": 1,
                            "dt_max": 0.1,
                            "d_state": 64,
                            "expand": 2
                        },
                        "design_traces": null
                    },
                    "SSDMinimalDiscrete": {
                        "review": "## Feedback Report\n\n### Overall Assessment\n```rating 4.0```\n\n### Strengths of the Implementation\n1. **Successful Functionality**: The implementation has passed all functionality checks, indicating that the code is robust and functions as expected within the larger language model framework.\n2. **Efficient Chunk-Based Processing**: The implementation efficiently processes sequences in chunks, which aligns with the proposal's goal of improving memory usage and computational efficiency.\n3. **Comprehensive Documentation**: The coder has provided detailed docstrings that clearly explain the inputs, outputs, and functionality of the methods, making the code easier to understand and maintain.\n\n### Areas for Improvement and Specific Suggestions\n1. **Code Optimization**:\n   - While the code is functioning correctly, there may still be opportunities to optimize the tensor operations for better performance, especially in the `ssd_minimal_discrete` method. Consider reviewing the use of `einsum` and `rearrange` for potential simplifications or performance improvements.\n   \n2. **Expand Unit Tests**:\n   - Although the functionality checks passed, expanding the unit tests to cover more edge cases and different input scenarios can further ensure robustness. This includes testing with varying batch sizes, sequence lengths, and edge cases like empty inputs or extreme values.\n\n3. **Code Readability**:\n   - Adding inline comments to explain complex operations or decisions in the code can enhance readability and make it easier for future developers to understand the logic.\n\n### Comments on Innovation and Potential Impact\n- The integration of chunk-based processing is a significant innovation that aligns with the proposal's goals of improving efficiency and scalability. This approach can potentially lead to better performance on long sequences, which is a common challenge in language modeling.\n- The current implementation is well-positioned to integrate additional features from the proposal, such as adaptive compression and wavelet-based analysis, which could further enhance the model's capabilities.\n\n### Recommendations for the Coder\n1. **Review and Optimize**: Continue to review the code for potential optimizations, particularly in tensor operations, to ensure maximum efficiency.\n2. **Enhance Testing**: Expand the unit tests to cover a broader range of scenarios, ensuring the implementation remains robust under various conditions.\n3. **Prepare for Future Enhancements**: Consider how the current implementation can be extended to incorporate additional features from the proposal, such as adaptive compression techniques.\n\nBy addressing these areas, the coder can further enhance the implementation's robustness, efficiency, and alignment with the proposal's goals. The successful functionality check is a strong indicator of the implementation's quality, and with continued refinement, it can serve as a solid foundation for future developments.",
                        "requirements": "N/A",
                        "reuse_from": null,
                        "desc": null,
                        "gautests": {
                            "test_ssd_minimal_discrete": "@gau_test\ndef test_SSDMinimalDiscrete_test_ssd_minimal_discrete(device=None, dtype=None\n    ) ->None:\n    batch_size = 2\n    L = 16\n    n_heads = 4\n    d_head = 32\n    d_state = 64\n    chunk_size = 4\n    embed_dim = n_heads * d_head\n    X = torch.randn(batch_size, L, n_heads, d_head, device=device, dtype=dtype)\n    x = X.clone()\n    A = torch.randn(batch_size, L, n_heads, device=device, dtype=dtype)\n    B = torch.randn(batch_size, L, n_heads, d_state, device=device, dtype=dtype\n        )\n    C = torch.randn(batch_size, L, n_heads, d_state, device=device, dtype=dtype\n        )\n    dt = torch.abs(torch.randn(batch_size, L, n_heads, device=device, dtype\n        =dtype)) + 0.001\n    model = SSDMinimalDiscrete(embed_dim, (0, 1), {}, device=device, dtype=\n        dtype)\n    X_out, Z_ = model._forward(X, x=x, A=A, B=B, C=C, dt=dt, chunk_size=\n        chunk_size)\n    y = Z_['y']\n    assert y.shape == (batch_size, L, n_heads, d_head\n        ), f'Output shape mismatch. Expected {batch_size, L, n_heads, d_head}, got {y.shape}'\n    assert torch.isfinite(y).all(), 'Output contains NaNs or infinite values'\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nimport torch.nn.functional as F\nfrom einops import rearrange, repeat\n\n\nclass SSDMinimalDiscrete(GAUBase):\n    \"\"\"\n    SSDMinimalDiscrete (State Space Discrete Minimal) implements a discrete-time state space model.\n\n    This class provides an efficient implementation of the SSM algorithm, particularly\n    suited for processing sequential data in chunks. It uses a minimal discrete-time\n    formulation that is both memory-efficient and computationally effective.\n\n    Args:\n        embed_dim (int): The embedding dimension of the input.\n        block_loc (tuple): The location of the block within the larger model structure.\n        kwarg_all (dict): Additional keyword arguments.\n        device (torch.device, optional): The device to run the module on.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    Inputs:\n        X (torch.Tensor): The input tensor of shape (batch_size, length, n_heads, d_head).\n        x (torch.Tensor): Input tensor, same as X.\n        A (torch.Tensor): State transition tensor of shape (batch_size, length, n_heads).\n        B (torch.Tensor): Input-to-state tensor of shape (batch_size, length, n_heads, d_state).\n        C (torch.Tensor): State-to-output tensor of shape (batch_size, length, n_heads, d_state).\n        dt (torch.Tensor): Time step tensor of shape (batch_size, length, n_heads).\n        chunk_size (int): Size of chunks for processing.\n\n    Outputs:\n        y (torch.Tensor): The output tensor of shape (batch_size, length, n_heads, d_head).\n\n    The class implements the forward pass of the SSM algorithm, including:\n    1. Intra-chunk computations (diagonal blocks)\n    2. Inter-chunk state propagation\n    3. State-to-output conversion\n\n    This implementation is designed to be efficient for long sequences by processing\n    the input in chunks, which allows for better parallelization and memory usage.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n\n    def _forward(self, X, x, A, B, C, dt, chunk_size):\n        \"\"\"\n        Forward pass of SSDMinimalDiscrete.\n\n        Args:\n            X (torch.Tensor): Input tensor of shape (batch_size, length, n_heads, d_head).\n            x (torch.Tensor): Input tensor, same as X.\n            A (torch.Tensor): State transition tensor of shape (batch_size, length, n_heads).\n            B (torch.Tensor): Input-to-state tensor of shape (batch_size, length, n_heads, d_state).\n            C (torch.Tensor): State-to-output tensor of shape (batch_size, length, n_heads, d_state).\n            dt (torch.Tensor): Time step tensor of shape (batch_size, length, n_heads).\n            chunk_size (int): Size of chunks for processing.\n\n        Returns:\n            X (torch.Tensor): Same as input X.\n            Z_ (dict): Dictionary containing the output 'y' of shape (batch_size, length, n_heads, d_head).\n        \"\"\"\n        x = x * dt.unsqueeze(-1)\n        A = A * dt\n        y, _ = self.ssd_minimal_discrete(x, A, B, C, chunk_size)\n        Z_ = {'y': y}\n        return X, Z_\n\n    def segsum(self, x):\n        \"\"\"More stable segment sum calculation.\"\"\"\n        T = x.size(-1)\n        x = repeat(x, '... d -> ... d e', e=T)\n        mask = torch.tril(torch.ones(T, T, device=x.device, dtype=bool),\n            diagonal=-1)\n        x = x.masked_fill(~mask, 0)\n        x_segsum = torch.cumsum(x, dim=-2)\n        mask = torch.tril(torch.ones(T, T, device=x.device, dtype=bool),\n            diagonal=0)\n        x_segsum = x_segsum.masked_fill(~mask, -torch.inf)\n        return x_segsum\n\n    def ssd_minimal_discrete(self, X, A, B, C, block_len, initial_states=None):\n        \"\"\"\n        Arguments:\n            X: (batch_size, length, n_heads, d_head)\n            A: (batch_size, length, n_heads)\n            B: (batch_size, length, n_heads, d_state)\n            C: (batch_size, length, n_heads, d_state)\n            block_len: int\n\n        Return:\n            y: (batch_size, length, n_heads, d_head)\n            final_state: The final state after processing the sequence.\n        \"\"\"\n        assert X.dtype == A.dtype == B.dtype == C.dtype\n        X, A, B, C = [rearrange(x, 'b (c l) ... -> b c l ...', l=block_len) for\n            x in (X, A, B, C)]\n        A = rearrange(A, 'b c l h -> b h c l')\n        A_cumsum = torch.cumsum(A, dim=-1)\n        L = torch.exp(self.segsum(A))\n        Y_diag = torch.einsum('bclhn,bcshn,bhcls,bcshp->bclhp', C, B, L, X)\n        decay_states = torch.exp(A_cumsum[:, :, :, -1:] - A_cumsum)\n        states = torch.einsum('bclhn,bhcl,bclhp->bchpn', B, decay_states, X)\n        if initial_states is None:\n            initial_states = torch.zeros_like(states[:, :1])\n        states = torch.cat([initial_states, states], dim=1)\n        decay_chunk = torch.exp(self.segsum(F.pad(A_cumsum[:, :, :, -1], (1,\n            0))))\n        new_states = torch.einsum('bhzc,bchpn->bzhpn', decay_chunk, states)\n        states, final_state = new_states[:, :-1], new_states[:, -1]\n        state_decay_out = torch.exp(A_cumsum)\n        Y_off = torch.einsum('bclhn,bchpn,bhcl->bclhp', C, states,\n            state_decay_out)\n        Y = rearrange(Y_diag + Y_off, 'b c l h p -> b (c l) h p')\n        return Y, final_state\n",
                        "rating": 4.0,
                        "spec": "{\"unitname\":\"SSDMinimalDiscrete\",\"document\":\"SSDMinimalDiscrete (State Space Discrete Minimal) implements a discrete-time state space model.\\n\\nThis class provides an efficient implementation of the SSM algorithm, particularly\\nsuited for processing sequential data in chunks. It uses a minimal discrete-time\\nformulation that is both memory-efficient and computationally effective.\\n\\nArgs:\\n    embed_dim (int): The embedding dimension of the input.\\n    block_loc (tuple): The location of the block within the larger model structure.\\n    kwarg_all (dict): Additional keyword arguments.\\n    device (torch.device, optional): The device to run the module on.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n\\nInputs:\\n    X (torch.Tensor): The input tensor of shape (batch_size, length, n_heads, d_head).\\n    x (torch.Tensor): Input tensor, same as X.\\n    A (torch.Tensor): State transition tensor of shape (batch_size, length, n_heads).\\n    B (torch.Tensor): Input-to-state tensor of shape (batch_size, length, n_heads, d_state).\\n    C (torch.Tensor): State-to-output tensor of shape (batch_size, length, n_heads, d_state).\\n    dt (torch.Tensor): Time step tensor of shape (batch_size, length, n_heads).\\n    chunk_size (int): Size of chunks for processing.\\n\\nOutputs:\\n    y (torch.Tensor): The output tensor of shape (batch_size, length, n_heads, d_head).\\n\\nThe class implements the forward pass of the SSM algorithm, including:\\n1. Intra-chunk computations (diagonal blocks)\\n2. Inter-chunk state propagation\\n3. State-to-output conversion\\n\\nThis implementation is designed to be efficient for long sequences by processing\\nthe input in chunks, which allows for better parallelization and memory usage.\",\"inputs\":[\"X\",\"A\",\"B\",\"C\",\"dt\",\"chunk_size\"],\"outputs\":[\"Y\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {},
                        "design_traces": null
                    },
                    "Mamba2": {
                        "review": null,
                        "requirements": null,
                        "reuse_from": null,
                        "desc": "\n",
                        "gautests": {
                            "test_mamba2": "@gau_test\ndef test_Mamba2_test_mamba2(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    mamba2 = Mamba2(embed_dim, block_loc, kwarg_all, device=device, dtype=\n        dtype, **kwarg_all)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    Z = {}\n    y, Z_ = mamba2(x, **Z)\n    assert y.shape == (1, 100, 128)\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass Mamba2(GAUBase):\n    \"\"\"\n    Mamba2: A Generalized Autoregressive Unit (GAU) implementing a double-layer Mamba architecture.\n\n    This class represents a Mamba2 block, which consists of two Mamba layers with normalization.\n    It's designed to process sequential data in a causal, differentiable, and parallelizable manner.\n\n    Architecture:\n        1. Input Normalization (RMSNorm)\n        2. First Mamba Layer\n        3. Residual Connection\n        4. Second Normalization (RMSNorm)\n        5. Second Mamba Layer\n        6. Final Residual Connection\n\n    Args:\n        embed_dim (int): The dimensionality of the input and output embeddings.\n        block_loc (tuple): The location of this block within the larger model architecture.\n        kwarg_all (dict): Additional keyword arguments to be passed to child components.\n        device (torch.device, optional): The device on which to allocate tensors.\n        dtype (torch.dtype, optional): The default dtype for tensors in this module.\n\n    Inputs:\n        X (torch.Tensor): Input tensor of shape (batch_size, sequence_length, embed_dim).\n        **Z: Additional keyword arguments for potential future extensions.\n\n    Outputs:\n        X (torch.Tensor): Output tensor of shape (batch_size, sequence_length, embed_dim).\n        Z (dict): Updated keyword arguments.\n\n    Note:\n        This implementation adheres to the GAU (Generalized Autoregressive Unit) interface\n        and maintains causal properties for autoregressive processing.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.mamba1 = Mamba2Layer(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.mamba2 = Mamba2Layer(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.norm1 = RMSNorm(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.norm2 = RMSNorm(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, Z = self.norm1(X, **Z)\n        X2, Z = self.mamba1(X1, **Z)\n        X = X + X2\n        X3, Z = self.norm2(X, **Z)\n        X4, Z = self.mamba2(X3, **Z)\n        X = X + X4\n        return X, Z\n\n\nCHILDREN_DECLARATIONS = [UnitDecl(unitname='Mamba2Layer', requirements='',\n    inputs=['X'], outputs=['Y']), UnitDecl(unitname='RMSNorm', requirements\n    ='', inputs=['X'], outputs=['Y'])]\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"Mamba2\",\"document\":\"\\n    Mamba2: A Generalized Autoregressive Unit (GAU) implementing a double-layer Mamba architecture.\\n\\n    This class represents a Mamba2 block, which consists of two Mamba layers with normalization.\\n    It's designed to process sequential data in a causal, differentiable, and parallelizable manner.\\n\\n    Architecture:\\n        1. Input Normalization (RMSNorm)\\n        2. First Mamba Layer\\n        3. Residual Connection\\n        4. Second Normalization (RMSNorm)\\n        5. Second Mamba Layer\\n        6. Final Residual Connection\\n\\n    Args:\\n        embed_dim (int): The dimensionality of the input and output embeddings.\\n        block_loc (tuple): The location of this block within the larger model architecture.\\n        kwarg_all (dict): Additional keyword arguments to be passed to child components.\\n        device (torch.device, optional): The device on which to allocate tensors.\\n        dtype (torch.dtype, optional): The default dtype for tensors in this module.\\n\\n    Inputs:\\n        X (torch.Tensor): Input tensor of shape (batch_size, sequence_length, embed_dim).\\n        **Z: Additional keyword arguments for potential future extensions.\\n\\n    Outputs:\\n        X (torch.Tensor): Output tensor of shape (batch_size, sequence_length, embed_dim).\\n        Z (dict): Updated keyword arguments.\\n\\n    Note:\\n        This implementation adheres to the GAU (Generalized Autoregressive Unit) interface\\n        and maintains causal properties for autoregressive processing.\\n    \",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [
                            "Mamba2Layer",
                            "RMSNorm"
                        ],
                        "suggestions": null,
                        "args": {},
                        "design_traces": null
                    }
                },
                "rating": null,
                "declares": {
                    "SSDMinimalDiscrete": "{\"unitname\":\"SSDMinimalDiscrete\",\"requirements\":\"N/A\",\"inputs\":[\"X\",\"A\",\"B\",\"C\",\"dt\",\"chunk_size\"],\"outputs\":[\"Y\"]}"
                },
                "proposal_traces": [],
                "suggestions": null,
                "name": "wavemamba2"
            },
            "user_input": "",
            "status": "implemented",
            "design_cfg": {
                "max_attemps": {
                    "post_refinement": 0,
                    "max_search_rounds": 3,
                    "implementation_debug": 7,
                    "design_proposal": 10
                },
                "threshold": {
                    "proposal_rating": 4.0,
                    "implementation_rating": 3.0
                },
                "use_unlimited_prompt": true,
                "mutation_no_tree": true,
                "agent_types": {
                    "DESIGN_PROPOSER": "hybrid",
                    "IMPLEMENTATION_PLANNER": "hybrid",
                    "IMPLEMENTATION_CODER": "hybrid",
                    "PROPOSAL_REVIEWER": "hybrid",
                    "IMPLEMENTATION_OBSERVER": "hybrid",
                    "SEARCH_ASSISTANT": "None"
                },
                "running_mode": "Proposal + Implementation",
                "unittest_pass_required": false,
                "crossover_no_ref": true,
                "scratch_no_tree": true,
                "_agent_types": {
                    "DESIGN_PROPOSER": "o1_mini",
                    "IMPLEMENTATION_PLANNER": "claude3.5_sonnet",
                    "IMPLEMENTATION_CODER": "o1_preview",
                    "PROPOSAL_REVIEWER": "claude3.5_sonnet",
                    "IMPLEMENTATION_OBSERVER": "gpt4o_0806",
                    "SEARCH_ASSISTANT": "None"
                },
                "termination": {
                    "max_debug_budget": 0,
                    "max_failed_rounds": 3,
                    "max_total_budget": 0
                },
                "agent_weights": {
                    "DESIGN_PROPOSER": [
                        0.05,
                        0.0,
                        0.6000000000000001,
                        0.2,
                        0.15
                    ],
                    "IMPLEMENTATION_PLANNER": [
                        0.05000000000000002,
                        0.0,
                        0.44999999999999996,
                        0.3,
                        0.20000000000000007
                    ],
                    "IMPLEMENTATION_CODER": [
                        0.0,
                        0.0,
                        0.3,
                        0.4999999999999996,
                        0.2
                    ],
                    "PROPOSAL_REVIEWER": [
                        0.10000000000000002,
                        0.0,
                        0.5499999999999999,
                        0.2,
                        0.15000000000000002
                    ],
                    "IMPLEMENTATION_OBSERVER": [
                        0.05,
                        0.0,
                        0.15000000000000002,
                        0.15000000000000002,
                        0.6499999999999999,
                        0.0
                    ]
                },
                "num_samples": {
                    "implementation": 1,
                    "rerank_method": "rating",
                    "proposal": 1
                },
                "search_settings": {
                    "proposal_search": true,
                    "proposal_review_search": true,
                    "search_for_papers_num": 10
                },
                "max_attempts": {
                    "post_refinement": 0,
                    "max_search_rounds": 4,
                    "implementation_debug": 5,
                    "design_proposal": 5
                }
            },
            "costs": {
                "DESIGN_PROPOSER": 0,
                "IMPLEMENTATION_PLANNER": 0,
                "IMPLEMENTATION_CODER": 19.317705,
                "PROPOSAL_REVIEWER": 0,
                "IMPLEMENTATION_OBSERVER": 2.579545,
                "SEARCH_ASSISTANT": 0
            }
        }
    ]
}