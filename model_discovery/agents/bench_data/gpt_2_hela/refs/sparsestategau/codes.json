{
    "31M": {
        "31M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = SparseStateBlock(embed_dim=embed_dim, block_loc=\n            block_loc, kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass SparseStateBlock(GAUBase):\n    \"\"\"\n    SparseStateBlock integrates sparse activation, state compression, IO-aware adaptation, and dense processing\n    to efficiently manage state and computation in language modeling tasks.\n\n    **Core Components:**\n\n    - `sparse_activator`: Applies sparse modular activation to selectively activate parts of the input.\n    - `state_compressor`: Compresses and decompresses state representations for efficient storage.\n    - `io_adapter`: Adapts computation in an IO-aware manner to improve hardware efficiency.\n    - `dense_processor`: Processes active states with dense connections to maintain information flow.\n    - `norm`: Applies Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after processing.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ssb = SparseStateBlock(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = ssb(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module integrates multiple components to efficiently process sequences.\n        - It relies on child GAUs for specific functionalities.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.sparse_activator = SparseModularActivator(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n        self.state_compressor = StateCompressor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.io_adapter = IOAwareAdapter(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.dense_processor = DenseStateProcessor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        active_X, Z = self.sparse_activator(X, **Z)\n        mask = Z.get('mask', None)\n        if mask is not None and mask.sum() > 0:\n            processed, Z = self.dense_processor(active_X, **Z)\n            compressed, Z = self.state_compressor(processed, **Z)\n            if self.training:\n                adapted, Z = self.io_adapter(compressed, **Z)\n            else:\n                adapted = compressed\n        else:\n            adapted = X\n        Y = self.norm(adapted)\n        return Y, Z\n\n\nclass StateCompressor(GAUBase):\n    \"\"\"\n    The StateCompressor compresses the state representations for efficient storage and decompresses them when needed.\n\n    **Key Components:**\n\n    - `compress`: Sequential module to compress the state.\n    - `decompress`: Sequential module to decompress the state.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the state to be compressed.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the decompressed state.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> sc = StateCompressor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sc(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The compression reduces the dimension to half, which can be adjusted as needed.\n        - The compressed state could be stored or processed further before decompression.\n\n    **References:**\n\n        - Gu, A., and Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        compressed_dim = embed_dim // 2\n        self.compress = nn.Sequential(nn.Linear(embed_dim, compressed_dim,\n            bias=False, **self.factory_kwargs), nn.GELU(), nn.LayerNorm(\n            compressed_dim, **self.factory_kwargs))\n        self.decompress = nn.Sequential(nn.Linear(compressed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.LayerNorm(embed_dim, **\n            self.factory_kwargs))\n\n    def _forward(self, X, **Z):\n        compressed = self.compress(X)\n        Y = self.decompress(compressed)\n        return Y, Z\n\n\nclass SparseModularActivator(GAUBase):\n    \"\"\"\n    The SparseModularActivator applies sparse activation to the input embeddings.\n    It computes activation scores using a linear layer, applies a sigmoid activation to obtain gating values,\n    and then uses a smooth approximation to thresholding to generate a soft mask.\n    The soft mask is used to selectively activate parts of the input while maintaining gradient flow.\n\n    **Key Attributes:**\n\n    - `gate`: Linear layer to compute activation scores from the input.\n    - `threshold`: Learnable parameter that determines the sparsity level.\n    - `temperature`: A hyperparameter to control the sharpness of the sigmoid function.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        temperature (float, optional): Controls the sharpness of the sigmoid function. Default: 20.0\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables (not used in this GAU).\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after applying sparse activation.\n        - **Z'**: Updated dictionary of intermediate variables, includes `'mask'` key.\n\n    **Example:**\n\n        >>> sma = SparseModularActivator(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sma(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n        >>> print('mask' in Z)\n        True\n\n    **Note:**\n\n        The sparsity of the output depends on the learnable `threshold` parameter and the `temperature`, which can be trained to achieve desired sparsity levels.\n\n    **References:**\n\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, temperature=20.0, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.gate = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.threshold = nn.Parameter(torch.zeros(1, **self.factory_kwargs))\n        self.temperature = temperature\n\n    def _forward(self, X, **Z):\n        scores = torch.sigmoid(self.gate(X))\n        mask = torch.sigmoid((scores - self.threshold) * self.temperature)\n        Y = X * mask\n        Z_ = {'mask': mask}\n        return Y, Z_\n\n\nclass DenseStateProcessor(GAUBase):\n    \"\"\"\n    The DenseStateProcessor processes actively selected states with dense transformations to maintain information flow.\n\n    **Key Components:**\n\n    - `dense_layer`: Linear layer that applies a transformation to the input.\n    - `activation`: Activation function applied after the dense layer.\n    - `norm`: Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the active input tensors.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the processed output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> dsp = DenseStateProcessor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = dsp(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module applies a feed-forward neural network to the input.\n        - It includes residual connections for better gradient flow.\n\n    **References:**\n\n        - Liu, Z., et al. (2024). Short-Long Convolutions Help Hardware-Efficient Linear Attention to Focus on Long Sequences.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.dense_layer = nn.Linear(embed_dim, embed_dim, bias=True, **\n            self.factory_kwargs)\n        self.activation = nn.GELU()\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        residual = X\n        Y = self.dense_layer(X)\n        Y = self.activation(Y)\n        Y = Y + residual\n        Y = self.norm(Y)\n        return Y, Z\n\n\nclass IOAwareAdapter(GAUBase):\n    \"\"\"\n    The IOAwareAdapter processes the input in chunks to optimize for IO efficiency.\n    It adapts computation to be hardware-friendly, improving inference speed and memory access patterns.\n\n    **Key Components:**\n\n    - `adapter`: Linear layer to adapt the input.\n    - `chunk_size`: Integer specifying the size of each chunk.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        chunk_size (int, optional): The size of each chunk for processing.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the input tensor to be adapted.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the adapted output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ioa = IOAwareAdapter(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 1024, 512)\n        >>> Y, Z = ioa(X)\n        >>> print(Y.shape)\n        torch.Size([2, 1024, 512])\n\n    **Note:**\n\n        - Processing in chunks can improve cache utilization and overall computational efficiency.\n        - The chunk size can be adjusted based on hardware specifications.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, chunk_size=256, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.adapter = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.chunk_size = chunk_size\n\n    def _forward(self, X, **Z):\n        B, L, D = X.size()\n        pad_len = (self.chunk_size - L % self.chunk_size) % self.chunk_size\n        if pad_len > 0:\n            padding = torch.zeros(B, pad_len, D, device=X.device, dtype=X.dtype\n                )\n            X_padded = torch.cat([X, padding], dim=1)\n        else:\n            X_padded = X\n        num_chunks = X_padded.size(1) // self.chunk_size\n        X_chunks = X_padded.view(B, num_chunks, self.chunk_size, D).contiguous(\n            )\n        X_chunks = X_chunks.view(-1, self.chunk_size, D)\n        adapted_chunks = self.adapter(X_chunks)\n        adapted_padded = adapted_chunks.view(B, num_chunks * self.chunk_size, D\n            )\n        Y = adapted_padded[:, :L, :]\n        return Y, Z\n\n\ngab_config = {'temperature': 20.0, 'chunk_size': 256}\n\n\n\nautoconfig = {\n    'd_model': 256,\n    'n_block': 9\n}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "760M": {
        "760M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = SparseStateBlock(embed_dim=embed_dim, block_loc=\n            block_loc, kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass SparseStateBlock(GAUBase):\n    \"\"\"\n    SparseStateBlock integrates sparse activation, state compression, IO-aware adaptation, and dense processing\n    to efficiently manage state and computation in language modeling tasks.\n\n    **Core Components:**\n\n    - `sparse_activator`: Applies sparse modular activation to selectively activate parts of the input.\n    - `state_compressor`: Compresses and decompresses state representations for efficient storage.\n    - `io_adapter`: Adapts computation in an IO-aware manner to improve hardware efficiency.\n    - `dense_processor`: Processes active states with dense connections to maintain information flow.\n    - `norm`: Applies Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after processing.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ssb = SparseStateBlock(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = ssb(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module integrates multiple components to efficiently process sequences.\n        - It relies on child GAUs for specific functionalities.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.sparse_activator = SparseModularActivator(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n        self.state_compressor = StateCompressor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.io_adapter = IOAwareAdapter(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.dense_processor = DenseStateProcessor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        active_X, Z = self.sparse_activator(X, **Z)\n        mask = Z.get('mask', None)\n        if mask is not None and mask.sum() > 0:\n            processed, Z = self.dense_processor(active_X, **Z)\n            compressed, Z = self.state_compressor(processed, **Z)\n            if self.training:\n                adapted, Z = self.io_adapter(compressed, **Z)\n            else:\n                adapted = compressed\n        else:\n            adapted = X\n        Y = self.norm(adapted)\n        return Y, Z\n\n\nclass StateCompressor(GAUBase):\n    \"\"\"\n    The StateCompressor compresses the state representations for efficient storage and decompresses them when needed.\n\n    **Key Components:**\n\n    - `compress`: Sequential module to compress the state.\n    - `decompress`: Sequential module to decompress the state.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the state to be compressed.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the decompressed state.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> sc = StateCompressor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sc(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The compression reduces the dimension to half, which can be adjusted as needed.\n        - The compressed state could be stored or processed further before decompression.\n\n    **References:**\n\n        - Gu, A., and Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        compressed_dim = embed_dim // 2\n        self.compress = nn.Sequential(nn.Linear(embed_dim, compressed_dim,\n            bias=False, **self.factory_kwargs), nn.GELU(), nn.LayerNorm(\n            compressed_dim, **self.factory_kwargs))\n        self.decompress = nn.Sequential(nn.Linear(compressed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.LayerNorm(embed_dim, **\n            self.factory_kwargs))\n\n    def _forward(self, X, **Z):\n        compressed = self.compress(X)\n        Y = self.decompress(compressed)\n        return Y, Z\n\n\nclass SparseModularActivator(GAUBase):\n    \"\"\"\n    The SparseModularActivator applies sparse activation to the input embeddings.\n    It computes activation scores using a linear layer, applies a sigmoid activation to obtain gating values,\n    and then uses a smooth approximation to thresholding to generate a soft mask.\n    The soft mask is used to selectively activate parts of the input while maintaining gradient flow.\n\n    **Key Attributes:**\n\n    - `gate`: Linear layer to compute activation scores from the input.\n    - `threshold`: Learnable parameter that determines the sparsity level.\n    - `temperature`: A hyperparameter to control the sharpness of the sigmoid function.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        temperature (float, optional): Controls the sharpness of the sigmoid function. Default: 20.0\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables (not used in this GAU).\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after applying sparse activation.\n        - **Z'**: Updated dictionary of intermediate variables, includes `'mask'` key.\n\n    **Example:**\n\n        >>> sma = SparseModularActivator(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sma(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n        >>> print('mask' in Z)\n        True\n\n    **Note:**\n\n        The sparsity of the output depends on the learnable `threshold` parameter and the `temperature`, which can be trained to achieve desired sparsity levels.\n\n    **References:**\n\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, temperature=20.0, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.gate = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.threshold = nn.Parameter(torch.zeros(1, **self.factory_kwargs))\n        self.temperature = temperature\n\n    def _forward(self, X, **Z):\n        scores = torch.sigmoid(self.gate(X))\n        mask = torch.sigmoid((scores - self.threshold) * self.temperature)\n        Y = X * mask\n        Z_ = {'mask': mask}\n        return Y, Z_\n\n\nclass DenseStateProcessor(GAUBase):\n    \"\"\"\n    The DenseStateProcessor processes actively selected states with dense transformations to maintain information flow.\n\n    **Key Components:**\n\n    - `dense_layer`: Linear layer that applies a transformation to the input.\n    - `activation`: Activation function applied after the dense layer.\n    - `norm`: Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the active input tensors.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the processed output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> dsp = DenseStateProcessor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = dsp(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module applies a feed-forward neural network to the input.\n        - It includes residual connections for better gradient flow.\n\n    **References:**\n\n        - Liu, Z., et al. (2024). Short-Long Convolutions Help Hardware-Efficient Linear Attention to Focus on Long Sequences.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.dense_layer = nn.Linear(embed_dim, embed_dim, bias=True, **\n            self.factory_kwargs)\n        self.activation = nn.GELU()\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        residual = X\n        Y = self.dense_layer(X)\n        Y = self.activation(Y)\n        Y = Y + residual\n        Y = self.norm(Y)\n        return Y, Z\n\n\nclass IOAwareAdapter(GAUBase):\n    \"\"\"\n    The IOAwareAdapter processes the input in chunks to optimize for IO efficiency.\n    It adapts computation to be hardware-friendly, improving inference speed and memory access patterns.\n\n    **Key Components:**\n\n    - `adapter`: Linear layer to adapt the input.\n    - `chunk_size`: Integer specifying the size of each chunk.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        chunk_size (int, optional): The size of each chunk for processing.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the input tensor to be adapted.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the adapted output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ioa = IOAwareAdapter(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 1024, 512)\n        >>> Y, Z = ioa(X)\n        >>> print(Y.shape)\n        torch.Size([2, 1024, 512])\n\n    **Note:**\n\n        - Processing in chunks can improve cache utilization and overall computational efficiency.\n        - The chunk size can be adjusted based on hardware specifications.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, chunk_size=256, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.adapter = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.chunk_size = chunk_size\n\n    def _forward(self, X, **Z):\n        B, L, D = X.size()\n        pad_len = (self.chunk_size - L % self.chunk_size) % self.chunk_size\n        if pad_len > 0:\n            padding = torch.zeros(B, pad_len, D, device=X.device, dtype=X.dtype\n                )\n            X_padded = torch.cat([X, padding], dim=1)\n        else:\n            X_padded = X\n        num_chunks = X_padded.size(1) // self.chunk_size\n        X_chunks = X_padded.view(B, num_chunks, self.chunk_size, D).contiguous(\n            )\n        X_chunks = X_chunks.view(-1, self.chunk_size, D)\n        adapted_chunks = self.adapter(X_chunks)\n        adapted_padded = adapted_chunks.view(B, num_chunks * self.chunk_size, D\n            )\n        Y = adapted_padded[:, :L, :]\n        return Y, Z\n\n\ngab_config = {'temperature': 20.0, 'chunk_size': 256}\n\n\n\nautoconfig = {\n    'd_model': 1536,\n    'n_block': 57\n}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "70M": {
        "70M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = SparseStateBlock(embed_dim=embed_dim, block_loc=\n            block_loc, kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass SparseStateBlock(GAUBase):\n    \"\"\"\n    SparseStateBlock integrates sparse activation, state compression, IO-aware adaptation, and dense processing\n    to efficiently manage state and computation in language modeling tasks.\n\n    **Core Components:**\n\n    - `sparse_activator`: Applies sparse modular activation to selectively activate parts of the input.\n    - `state_compressor`: Compresses and decompresses state representations for efficient storage.\n    - `io_adapter`: Adapts computation in an IO-aware manner to improve hardware efficiency.\n    - `dense_processor`: Processes active states with dense connections to maintain information flow.\n    - `norm`: Applies Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after processing.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ssb = SparseStateBlock(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = ssb(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module integrates multiple components to efficiently process sequences.\n        - It relies on child GAUs for specific functionalities.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.sparse_activator = SparseModularActivator(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n        self.state_compressor = StateCompressor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.io_adapter = IOAwareAdapter(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.dense_processor = DenseStateProcessor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        active_X, Z = self.sparse_activator(X, **Z)\n        mask = Z.get('mask', None)\n        if mask is not None and mask.sum() > 0:\n            processed, Z = self.dense_processor(active_X, **Z)\n            compressed, Z = self.state_compressor(processed, **Z)\n            if self.training:\n                adapted, Z = self.io_adapter(compressed, **Z)\n            else:\n                adapted = compressed\n        else:\n            adapted = X\n        Y = self.norm(adapted)\n        return Y, Z\n\n\nclass StateCompressor(GAUBase):\n    \"\"\"\n    The StateCompressor compresses the state representations for efficient storage and decompresses them when needed.\n\n    **Key Components:**\n\n    - `compress`: Sequential module to compress the state.\n    - `decompress`: Sequential module to decompress the state.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the state to be compressed.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the decompressed state.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> sc = StateCompressor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sc(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The compression reduces the dimension to half, which can be adjusted as needed.\n        - The compressed state could be stored or processed further before decompression.\n\n    **References:**\n\n        - Gu, A., and Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        compressed_dim = embed_dim // 2\n        self.compress = nn.Sequential(nn.Linear(embed_dim, compressed_dim,\n            bias=False, **self.factory_kwargs), nn.GELU(), nn.LayerNorm(\n            compressed_dim, **self.factory_kwargs))\n        self.decompress = nn.Sequential(nn.Linear(compressed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.LayerNorm(embed_dim, **\n            self.factory_kwargs))\n\n    def _forward(self, X, **Z):\n        compressed = self.compress(X)\n        Y = self.decompress(compressed)\n        return Y, Z\n\n\nclass SparseModularActivator(GAUBase):\n    \"\"\"\n    The SparseModularActivator applies sparse activation to the input embeddings.\n    It computes activation scores using a linear layer, applies a sigmoid activation to obtain gating values,\n    and then uses a smooth approximation to thresholding to generate a soft mask.\n    The soft mask is used to selectively activate parts of the input while maintaining gradient flow.\n\n    **Key Attributes:**\n\n    - `gate`: Linear layer to compute activation scores from the input.\n    - `threshold`: Learnable parameter that determines the sparsity level.\n    - `temperature`: A hyperparameter to control the sharpness of the sigmoid function.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        temperature (float, optional): Controls the sharpness of the sigmoid function. Default: 20.0\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables (not used in this GAU).\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after applying sparse activation.\n        - **Z'**: Updated dictionary of intermediate variables, includes `'mask'` key.\n\n    **Example:**\n\n        >>> sma = SparseModularActivator(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sma(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n        >>> print('mask' in Z)\n        True\n\n    **Note:**\n\n        The sparsity of the output depends on the learnable `threshold` parameter and the `temperature`, which can be trained to achieve desired sparsity levels.\n\n    **References:**\n\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, temperature=20.0, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.gate = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.threshold = nn.Parameter(torch.zeros(1, **self.factory_kwargs))\n        self.temperature = temperature\n\n    def _forward(self, X, **Z):\n        scores = torch.sigmoid(self.gate(X))\n        mask = torch.sigmoid((scores - self.threshold) * self.temperature)\n        Y = X * mask\n        Z_ = {'mask': mask}\n        return Y, Z_\n\n\nclass DenseStateProcessor(GAUBase):\n    \"\"\"\n    The DenseStateProcessor processes actively selected states with dense transformations to maintain information flow.\n\n    **Key Components:**\n\n    - `dense_layer`: Linear layer that applies a transformation to the input.\n    - `activation`: Activation function applied after the dense layer.\n    - `norm`: Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the active input tensors.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the processed output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> dsp = DenseStateProcessor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = dsp(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module applies a feed-forward neural network to the input.\n        - It includes residual connections for better gradient flow.\n\n    **References:**\n\n        - Liu, Z., et al. (2024). Short-Long Convolutions Help Hardware-Efficient Linear Attention to Focus on Long Sequences.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.dense_layer = nn.Linear(embed_dim, embed_dim, bias=True, **\n            self.factory_kwargs)\n        self.activation = nn.GELU()\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        residual = X\n        Y = self.dense_layer(X)\n        Y = self.activation(Y)\n        Y = Y + residual\n        Y = self.norm(Y)\n        return Y, Z\n\n\nclass IOAwareAdapter(GAUBase):\n    \"\"\"\n    The IOAwareAdapter processes the input in chunks to optimize for IO efficiency.\n    It adapts computation to be hardware-friendly, improving inference speed and memory access patterns.\n\n    **Key Components:**\n\n    - `adapter`: Linear layer to adapt the input.\n    - `chunk_size`: Integer specifying the size of each chunk.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        chunk_size (int, optional): The size of each chunk for processing.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the input tensor to be adapted.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the adapted output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ioa = IOAwareAdapter(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 1024, 512)\n        >>> Y, Z = ioa(X)\n        >>> print(Y.shape)\n        torch.Size([2, 1024, 512])\n\n    **Note:**\n\n        - Processing in chunks can improve cache utilization and overall computational efficiency.\n        - The chunk size can be adjusted based on hardware specifications.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, chunk_size=256, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.adapter = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.chunk_size = chunk_size\n\n    def _forward(self, X, **Z):\n        B, L, D = X.size()\n        pad_len = (self.chunk_size - L % self.chunk_size) % self.chunk_size\n        if pad_len > 0:\n            padding = torch.zeros(B, pad_len, D, device=X.device, dtype=X.dtype\n                )\n            X_padded = torch.cat([X, padding], dim=1)\n        else:\n            X_padded = X\n        num_chunks = X_padded.size(1) // self.chunk_size\n        X_chunks = X_padded.view(B, num_chunks, self.chunk_size, D).contiguous(\n            )\n        X_chunks = X_chunks.view(-1, self.chunk_size, D)\n        adapted_chunks = self.adapter(X_chunks)\n        adapted_padded = adapted_chunks.view(B, num_chunks * self.chunk_size, D\n            )\n        Y = adapted_padded[:, :L, :]\n        return Y, Z\n\n\ngab_config = {'temperature': 20.0, 'chunk_size': 256}\n\n\n\nautoconfig = {\n    'd_model': 512,\n    'n_block': 12\n}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "1300M": {
        "1300M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = SparseStateBlock(embed_dim=embed_dim, block_loc=\n            block_loc, kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass SparseStateBlock(GAUBase):\n    \"\"\"\n    SparseStateBlock integrates sparse activation, state compression, IO-aware adaptation, and dense processing\n    to efficiently manage state and computation in language modeling tasks.\n\n    **Core Components:**\n\n    - `sparse_activator`: Applies sparse modular activation to selectively activate parts of the input.\n    - `state_compressor`: Compresses and decompresses state representations for efficient storage.\n    - `io_adapter`: Adapts computation in an IO-aware manner to improve hardware efficiency.\n    - `dense_processor`: Processes active states with dense connections to maintain information flow.\n    - `norm`: Applies Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after processing.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ssb = SparseStateBlock(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = ssb(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module integrates multiple components to efficiently process sequences.\n        - It relies on child GAUs for specific functionalities.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.sparse_activator = SparseModularActivator(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n        self.state_compressor = StateCompressor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.io_adapter = IOAwareAdapter(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.dense_processor = DenseStateProcessor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        active_X, Z = self.sparse_activator(X, **Z)\n        mask = Z.get('mask', None)\n        if mask is not None and mask.sum() > 0:\n            processed, Z = self.dense_processor(active_X, **Z)\n            compressed, Z = self.state_compressor(processed, **Z)\n            if self.training:\n                adapted, Z = self.io_adapter(compressed, **Z)\n            else:\n                adapted = compressed\n        else:\n            adapted = X\n        Y = self.norm(adapted)\n        return Y, Z\n\n\nclass StateCompressor(GAUBase):\n    \"\"\"\n    The StateCompressor compresses the state representations for efficient storage and decompresses them when needed.\n\n    **Key Components:**\n\n    - `compress`: Sequential module to compress the state.\n    - `decompress`: Sequential module to decompress the state.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the state to be compressed.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the decompressed state.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> sc = StateCompressor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sc(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The compression reduces the dimension to half, which can be adjusted as needed.\n        - The compressed state could be stored or processed further before decompression.\n\n    **References:**\n\n        - Gu, A., and Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        compressed_dim = embed_dim // 2\n        self.compress = nn.Sequential(nn.Linear(embed_dim, compressed_dim,\n            bias=False, **self.factory_kwargs), nn.GELU(), nn.LayerNorm(\n            compressed_dim, **self.factory_kwargs))\n        self.decompress = nn.Sequential(nn.Linear(compressed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.LayerNorm(embed_dim, **\n            self.factory_kwargs))\n\n    def _forward(self, X, **Z):\n        compressed = self.compress(X)\n        Y = self.decompress(compressed)\n        return Y, Z\n\n\nclass SparseModularActivator(GAUBase):\n    \"\"\"\n    The SparseModularActivator applies sparse activation to the input embeddings.\n    It computes activation scores using a linear layer, applies a sigmoid activation to obtain gating values,\n    and then uses a smooth approximation to thresholding to generate a soft mask.\n    The soft mask is used to selectively activate parts of the input while maintaining gradient flow.\n\n    **Key Attributes:**\n\n    - `gate`: Linear layer to compute activation scores from the input.\n    - `threshold`: Learnable parameter that determines the sparsity level.\n    - `temperature`: A hyperparameter to control the sharpness of the sigmoid function.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        temperature (float, optional): Controls the sharpness of the sigmoid function. Default: 20.0\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables (not used in this GAU).\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after applying sparse activation.\n        - **Z'**: Updated dictionary of intermediate variables, includes `'mask'` key.\n\n    **Example:**\n\n        >>> sma = SparseModularActivator(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sma(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n        >>> print('mask' in Z)\n        True\n\n    **Note:**\n\n        The sparsity of the output depends on the learnable `threshold` parameter and the `temperature`, which can be trained to achieve desired sparsity levels.\n\n    **References:**\n\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, temperature=20.0, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.gate = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.threshold = nn.Parameter(torch.zeros(1, **self.factory_kwargs))\n        self.temperature = temperature\n\n    def _forward(self, X, **Z):\n        scores = torch.sigmoid(self.gate(X))\n        mask = torch.sigmoid((scores - self.threshold) * self.temperature)\n        Y = X * mask\n        Z_ = {'mask': mask}\n        return Y, Z_\n\n\nclass DenseStateProcessor(GAUBase):\n    \"\"\"\n    The DenseStateProcessor processes actively selected states with dense transformations to maintain information flow.\n\n    **Key Components:**\n\n    - `dense_layer`: Linear layer that applies a transformation to the input.\n    - `activation`: Activation function applied after the dense layer.\n    - `norm`: Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the active input tensors.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the processed output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> dsp = DenseStateProcessor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = dsp(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module applies a feed-forward neural network to the input.\n        - It includes residual connections for better gradient flow.\n\n    **References:**\n\n        - Liu, Z., et al. (2024). Short-Long Convolutions Help Hardware-Efficient Linear Attention to Focus on Long Sequences.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.dense_layer = nn.Linear(embed_dim, embed_dim, bias=True, **\n            self.factory_kwargs)\n        self.activation = nn.GELU()\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        residual = X\n        Y = self.dense_layer(X)\n        Y = self.activation(Y)\n        Y = Y + residual\n        Y = self.norm(Y)\n        return Y, Z\n\n\nclass IOAwareAdapter(GAUBase):\n    \"\"\"\n    The IOAwareAdapter processes the input in chunks to optimize for IO efficiency.\n    It adapts computation to be hardware-friendly, improving inference speed and memory access patterns.\n\n    **Key Components:**\n\n    - `adapter`: Linear layer to adapt the input.\n    - `chunk_size`: Integer specifying the size of each chunk.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        chunk_size (int, optional): The size of each chunk for processing.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the input tensor to be adapted.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the adapted output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ioa = IOAwareAdapter(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 1024, 512)\n        >>> Y, Z = ioa(X)\n        >>> print(Y.shape)\n        torch.Size([2, 1024, 512])\n\n    **Note:**\n\n        - Processing in chunks can improve cache utilization and overall computational efficiency.\n        - The chunk size can be adjusted based on hardware specifications.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, chunk_size=256, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.adapter = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.chunk_size = chunk_size\n\n    def _forward(self, X, **Z):\n        B, L, D = X.size()\n        pad_len = (self.chunk_size - L % self.chunk_size) % self.chunk_size\n        if pad_len > 0:\n            padding = torch.zeros(B, pad_len, D, device=X.device, dtype=X.dtype\n                )\n            X_padded = torch.cat([X, padding], dim=1)\n        else:\n            X_padded = X\n        num_chunks = X_padded.size(1) // self.chunk_size\n        X_chunks = X_padded.view(B, num_chunks, self.chunk_size, D).contiguous(\n            )\n        X_chunks = X_chunks.view(-1, self.chunk_size, D)\n        adapted_chunks = self.adapter(X_chunks)\n        adapted_padded = adapted_chunks.view(B, num_chunks * self.chunk_size, D\n            )\n        Y = adapted_padded[:, :L, :]\n        return Y, Z\n\n\ngab_config = {'temperature': 20.0, 'chunk_size': 256}\n\n\n\nautoconfig = {\n    'd_model': 2048,\n    'n_block': 57\n}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "125M": {
        "125M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = SparseStateBlock(embed_dim=embed_dim, block_loc=\n            block_loc, kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass SparseStateBlock(GAUBase):\n    \"\"\"\n    SparseStateBlock integrates sparse activation, state compression, IO-aware adaptation, and dense processing\n    to efficiently manage state and computation in language modeling tasks.\n\n    **Core Components:**\n\n    - `sparse_activator`: Applies sparse modular activation to selectively activate parts of the input.\n    - `state_compressor`: Compresses and decompresses state representations for efficient storage.\n    - `io_adapter`: Adapts computation in an IO-aware manner to improve hardware efficiency.\n    - `dense_processor`: Processes active states with dense connections to maintain information flow.\n    - `norm`: Applies Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after processing.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ssb = SparseStateBlock(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = ssb(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module integrates multiple components to efficiently process sequences.\n        - It relies on child GAUs for specific functionalities.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.sparse_activator = SparseModularActivator(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n        self.state_compressor = StateCompressor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.io_adapter = IOAwareAdapter(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.dense_processor = DenseStateProcessor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        active_X, Z = self.sparse_activator(X, **Z)\n        mask = Z.get('mask', None)\n        if mask is not None and mask.sum() > 0:\n            processed, Z = self.dense_processor(active_X, **Z)\n            compressed, Z = self.state_compressor(processed, **Z)\n            if self.training:\n                adapted, Z = self.io_adapter(compressed, **Z)\n            else:\n                adapted = compressed\n        else:\n            adapted = X\n        Y = self.norm(adapted)\n        return Y, Z\n\n\nclass StateCompressor(GAUBase):\n    \"\"\"\n    The StateCompressor compresses the state representations for efficient storage and decompresses them when needed.\n\n    **Key Components:**\n\n    - `compress`: Sequential module to compress the state.\n    - `decompress`: Sequential module to decompress the state.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the state to be compressed.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the decompressed state.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> sc = StateCompressor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sc(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The compression reduces the dimension to half, which can be adjusted as needed.\n        - The compressed state could be stored or processed further before decompression.\n\n    **References:**\n\n        - Gu, A., and Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        compressed_dim = embed_dim // 2\n        self.compress = nn.Sequential(nn.Linear(embed_dim, compressed_dim,\n            bias=False, **self.factory_kwargs), nn.GELU(), nn.LayerNorm(\n            compressed_dim, **self.factory_kwargs))\n        self.decompress = nn.Sequential(nn.Linear(compressed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.LayerNorm(embed_dim, **\n            self.factory_kwargs))\n\n    def _forward(self, X, **Z):\n        compressed = self.compress(X)\n        Y = self.decompress(compressed)\n        return Y, Z\n\n\nclass SparseModularActivator(GAUBase):\n    \"\"\"\n    The SparseModularActivator applies sparse activation to the input embeddings.\n    It computes activation scores using a linear layer, applies a sigmoid activation to obtain gating values,\n    and then uses a smooth approximation to thresholding to generate a soft mask.\n    The soft mask is used to selectively activate parts of the input while maintaining gradient flow.\n\n    **Key Attributes:**\n\n    - `gate`: Linear layer to compute activation scores from the input.\n    - `threshold`: Learnable parameter that determines the sparsity level.\n    - `temperature`: A hyperparameter to control the sharpness of the sigmoid function.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        temperature (float, optional): Controls the sharpness of the sigmoid function. Default: 20.0\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables (not used in this GAU).\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after applying sparse activation.\n        - **Z'**: Updated dictionary of intermediate variables, includes `'mask'` key.\n\n    **Example:**\n\n        >>> sma = SparseModularActivator(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sma(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n        >>> print('mask' in Z)\n        True\n\n    **Note:**\n\n        The sparsity of the output depends on the learnable `threshold` parameter and the `temperature`, which can be trained to achieve desired sparsity levels.\n\n    **References:**\n\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, temperature=20.0, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.gate = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.threshold = nn.Parameter(torch.zeros(1, **self.factory_kwargs))\n        self.temperature = temperature\n\n    def _forward(self, X, **Z):\n        scores = torch.sigmoid(self.gate(X))\n        mask = torch.sigmoid((scores - self.threshold) * self.temperature)\n        Y = X * mask\n        Z_ = {'mask': mask}\n        return Y, Z_\n\n\nclass DenseStateProcessor(GAUBase):\n    \"\"\"\n    The DenseStateProcessor processes actively selected states with dense transformations to maintain information flow.\n\n    **Key Components:**\n\n    - `dense_layer`: Linear layer that applies a transformation to the input.\n    - `activation`: Activation function applied after the dense layer.\n    - `norm`: Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the active input tensors.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the processed output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> dsp = DenseStateProcessor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = dsp(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module applies a feed-forward neural network to the input.\n        - It includes residual connections for better gradient flow.\n\n    **References:**\n\n        - Liu, Z., et al. (2024). Short-Long Convolutions Help Hardware-Efficient Linear Attention to Focus on Long Sequences.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.dense_layer = nn.Linear(embed_dim, embed_dim, bias=True, **\n            self.factory_kwargs)\n        self.activation = nn.GELU()\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        residual = X\n        Y = self.dense_layer(X)\n        Y = self.activation(Y)\n        Y = Y + residual\n        Y = self.norm(Y)\n        return Y, Z\n\n\nclass IOAwareAdapter(GAUBase):\n    \"\"\"\n    The IOAwareAdapter processes the input in chunks to optimize for IO efficiency.\n    It adapts computation to be hardware-friendly, improving inference speed and memory access patterns.\n\n    **Key Components:**\n\n    - `adapter`: Linear layer to adapt the input.\n    - `chunk_size`: Integer specifying the size of each chunk.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        chunk_size (int, optional): The size of each chunk for processing.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the input tensor to be adapted.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the adapted output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ioa = IOAwareAdapter(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 1024, 512)\n        >>> Y, Z = ioa(X)\n        >>> print(Y.shape)\n        torch.Size([2, 1024, 512])\n\n    **Note:**\n\n        - Processing in chunks can improve cache utilization and overall computational efficiency.\n        - The chunk size can be adjusted based on hardware specifications.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, chunk_size=256, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.adapter = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.chunk_size = chunk_size\n\n    def _forward(self, X, **Z):\n        B, L, D = X.size()\n        pad_len = (self.chunk_size - L % self.chunk_size) % self.chunk_size\n        if pad_len > 0:\n            padding = torch.zeros(B, pad_len, D, device=X.device, dtype=X.dtype\n                )\n            X_padded = torch.cat([X, padding], dim=1)\n        else:\n            X_padded = X\n        num_chunks = X_padded.size(1) // self.chunk_size\n        X_chunks = X_padded.view(B, num_chunks, self.chunk_size, D).contiguous(\n            )\n        X_chunks = X_chunks.view(-1, self.chunk_size, D)\n        adapted_chunks = self.adapter(X_chunks)\n        adapted_padded = adapted_chunks.view(B, num_chunks * self.chunk_size, D\n            )\n        Y = adapted_padded[:, :L, :]\n        return Y, Z\n\n\ngab_config = {'temperature': 20.0, 'chunk_size': 256}\n\n\n\nautoconfig = {\n    'd_model': 768,\n    'n_block': 27\n}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "14M": {
        "14M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = SparseStateBlock(embed_dim=embed_dim, block_loc=\n            block_loc, kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass SparseStateBlock(GAUBase):\n    \"\"\"\n    SparseStateBlock integrates sparse activation, state compression, IO-aware adaptation, and dense processing\n    to efficiently manage state and computation in language modeling tasks.\n\n    **Core Components:**\n\n    - `sparse_activator`: Applies sparse modular activation to selectively activate parts of the input.\n    - `state_compressor`: Compresses and decompresses state representations for efficient storage.\n    - `io_adapter`: Adapts computation in an IO-aware manner to improve hardware efficiency.\n    - `dense_processor`: Processes active states with dense connections to maintain information flow.\n    - `norm`: Applies Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after processing.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ssb = SparseStateBlock(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = ssb(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module integrates multiple components to efficiently process sequences.\n        - It relies on child GAUs for specific functionalities.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.sparse_activator = SparseModularActivator(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n        self.state_compressor = StateCompressor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.io_adapter = IOAwareAdapter(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.dense_processor = DenseStateProcessor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        active_X, Z = self.sparse_activator(X, **Z)\n        mask = Z.get('mask', None)\n        if mask is not None and mask.sum() > 0:\n            processed, Z = self.dense_processor(active_X, **Z)\n            compressed, Z = self.state_compressor(processed, **Z)\n            if self.training:\n                adapted, Z = self.io_adapter(compressed, **Z)\n            else:\n                adapted = compressed\n        else:\n            adapted = X\n        Y = self.norm(adapted)\n        return Y, Z\n\n\nclass StateCompressor(GAUBase):\n    \"\"\"\n    The StateCompressor compresses the state representations for efficient storage and decompresses them when needed.\n\n    **Key Components:**\n\n    - `compress`: Sequential module to compress the state.\n    - `decompress`: Sequential module to decompress the state.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the state to be compressed.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the decompressed state.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> sc = StateCompressor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sc(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The compression reduces the dimension to half, which can be adjusted as needed.\n        - The compressed state could be stored or processed further before decompression.\n\n    **References:**\n\n        - Gu, A., and Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        compressed_dim = embed_dim // 2\n        self.compress = nn.Sequential(nn.Linear(embed_dim, compressed_dim,\n            bias=False, **self.factory_kwargs), nn.GELU(), nn.LayerNorm(\n            compressed_dim, **self.factory_kwargs))\n        self.decompress = nn.Sequential(nn.Linear(compressed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.LayerNorm(embed_dim, **\n            self.factory_kwargs))\n\n    def _forward(self, X, **Z):\n        compressed = self.compress(X)\n        Y = self.decompress(compressed)\n        return Y, Z\n\n\nclass SparseModularActivator(GAUBase):\n    \"\"\"\n    The SparseModularActivator applies sparse activation to the input embeddings.\n    It computes activation scores using a linear layer, applies a sigmoid activation to obtain gating values,\n    and then uses a smooth approximation to thresholding to generate a soft mask.\n    The soft mask is used to selectively activate parts of the input while maintaining gradient flow.\n\n    **Key Attributes:**\n\n    - `gate`: Linear layer to compute activation scores from the input.\n    - `threshold`: Learnable parameter that determines the sparsity level.\n    - `temperature`: A hyperparameter to control the sharpness of the sigmoid function.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        temperature (float, optional): Controls the sharpness of the sigmoid function. Default: 20.0\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables (not used in this GAU).\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after applying sparse activation.\n        - **Z'**: Updated dictionary of intermediate variables, includes `'mask'` key.\n\n    **Example:**\n\n        >>> sma = SparseModularActivator(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sma(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n        >>> print('mask' in Z)\n        True\n\n    **Note:**\n\n        The sparsity of the output depends on the learnable `threshold` parameter and the `temperature`, which can be trained to achieve desired sparsity levels.\n\n    **References:**\n\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, temperature=20.0, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.gate = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.threshold = nn.Parameter(torch.zeros(1, **self.factory_kwargs))\n        self.temperature = temperature\n\n    def _forward(self, X, **Z):\n        scores = torch.sigmoid(self.gate(X))\n        mask = torch.sigmoid((scores - self.threshold) * self.temperature)\n        Y = X * mask\n        Z_ = {'mask': mask}\n        return Y, Z_\n\n\nclass DenseStateProcessor(GAUBase):\n    \"\"\"\n    The DenseStateProcessor processes actively selected states with dense transformations to maintain information flow.\n\n    **Key Components:**\n\n    - `dense_layer`: Linear layer that applies a transformation to the input.\n    - `activation`: Activation function applied after the dense layer.\n    - `norm`: Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the active input tensors.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the processed output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> dsp = DenseStateProcessor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = dsp(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module applies a feed-forward neural network to the input.\n        - It includes residual connections for better gradient flow.\n\n    **References:**\n\n        - Liu, Z., et al. (2024). Short-Long Convolutions Help Hardware-Efficient Linear Attention to Focus on Long Sequences.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.dense_layer = nn.Linear(embed_dim, embed_dim, bias=True, **\n            self.factory_kwargs)\n        self.activation = nn.GELU()\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        residual = X\n        Y = self.dense_layer(X)\n        Y = self.activation(Y)\n        Y = Y + residual\n        Y = self.norm(Y)\n        return Y, Z\n\n\nclass IOAwareAdapter(GAUBase):\n    \"\"\"\n    The IOAwareAdapter processes the input in chunks to optimize for IO efficiency.\n    It adapts computation to be hardware-friendly, improving inference speed and memory access patterns.\n\n    **Key Components:**\n\n    - `adapter`: Linear layer to adapt the input.\n    - `chunk_size`: Integer specifying the size of each chunk.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        chunk_size (int, optional): The size of each chunk for processing.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the input tensor to be adapted.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the adapted output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ioa = IOAwareAdapter(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 1024, 512)\n        >>> Y, Z = ioa(X)\n        >>> print(Y.shape)\n        torch.Size([2, 1024, 512])\n\n    **Note:**\n\n        - Processing in chunks can improve cache utilization and overall computational efficiency.\n        - The chunk size can be adjusted based on hardware specifications.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, chunk_size=256, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.adapter = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.chunk_size = chunk_size\n\n    def _forward(self, X, **Z):\n        B, L, D = X.size()\n        pad_len = (self.chunk_size - L % self.chunk_size) % self.chunk_size\n        if pad_len > 0:\n            padding = torch.zeros(B, pad_len, D, device=X.device, dtype=X.dtype\n                )\n            X_padded = torch.cat([X, padding], dim=1)\n        else:\n            X_padded = X\n        num_chunks = X_padded.size(1) // self.chunk_size\n        X_chunks = X_padded.view(B, num_chunks, self.chunk_size, D).contiguous(\n            )\n        X_chunks = X_chunks.view(-1, self.chunk_size, D)\n        adapted_chunks = self.adapter(X_chunks)\n        adapted_padded = adapted_chunks.view(B, num_chunks * self.chunk_size, D\n            )\n        Y = adapted_padded[:, :L, :]\n        return Y, Z\n\n\ngab_config = {'temperature': 20.0, 'chunk_size': 256}\n\n\n\nautoconfig={}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "350M": {
        "350M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = SparseStateBlock(embed_dim=embed_dim, block_loc=\n            block_loc, kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass SparseStateBlock(GAUBase):\n    \"\"\"\n    SparseStateBlock integrates sparse activation, state compression, IO-aware adaptation, and dense processing\n    to efficiently manage state and computation in language modeling tasks.\n\n    **Core Components:**\n\n    - `sparse_activator`: Applies sparse modular activation to selectively activate parts of the input.\n    - `state_compressor`: Compresses and decompresses state representations for efficient storage.\n    - `io_adapter`: Adapts computation in an IO-aware manner to improve hardware efficiency.\n    - `dense_processor`: Processes active states with dense connections to maintain information flow.\n    - `norm`: Applies Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after processing.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ssb = SparseStateBlock(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = ssb(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module integrates multiple components to efficiently process sequences.\n        - It relies on child GAUs for specific functionalities.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.sparse_activator = SparseModularActivator(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n        self.state_compressor = StateCompressor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.io_adapter = IOAwareAdapter(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.dense_processor = DenseStateProcessor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        active_X, Z = self.sparse_activator(X, **Z)\n        mask = Z.get('mask', None)\n        if mask is not None and mask.sum() > 0:\n            processed, Z = self.dense_processor(active_X, **Z)\n            compressed, Z = self.state_compressor(processed, **Z)\n            if self.training:\n                adapted, Z = self.io_adapter(compressed, **Z)\n            else:\n                adapted = compressed\n        else:\n            adapted = X\n        Y = self.norm(adapted)\n        return Y, Z\n\n\nclass StateCompressor(GAUBase):\n    \"\"\"\n    The StateCompressor compresses the state representations for efficient storage and decompresses them when needed.\n\n    **Key Components:**\n\n    - `compress`: Sequential module to compress the state.\n    - `decompress`: Sequential module to decompress the state.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the state to be compressed.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the decompressed state.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> sc = StateCompressor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sc(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The compression reduces the dimension to half, which can be adjusted as needed.\n        - The compressed state could be stored or processed further before decompression.\n\n    **References:**\n\n        - Gu, A., and Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        compressed_dim = embed_dim // 2\n        self.compress = nn.Sequential(nn.Linear(embed_dim, compressed_dim,\n            bias=False, **self.factory_kwargs), nn.GELU(), nn.LayerNorm(\n            compressed_dim, **self.factory_kwargs))\n        self.decompress = nn.Sequential(nn.Linear(compressed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.LayerNorm(embed_dim, **\n            self.factory_kwargs))\n\n    def _forward(self, X, **Z):\n        compressed = self.compress(X)\n        Y = self.decompress(compressed)\n        return Y, Z\n\n\nclass SparseModularActivator(GAUBase):\n    \"\"\"\n    The SparseModularActivator applies sparse activation to the input embeddings.\n    It computes activation scores using a linear layer, applies a sigmoid activation to obtain gating values,\n    and then uses a smooth approximation to thresholding to generate a soft mask.\n    The soft mask is used to selectively activate parts of the input while maintaining gradient flow.\n\n    **Key Attributes:**\n\n    - `gate`: Linear layer to compute activation scores from the input.\n    - `threshold`: Learnable parameter that determines the sparsity level.\n    - `temperature`: A hyperparameter to control the sharpness of the sigmoid function.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        temperature (float, optional): Controls the sharpness of the sigmoid function. Default: 20.0\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables (not used in this GAU).\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after applying sparse activation.\n        - **Z'**: Updated dictionary of intermediate variables, includes `'mask'` key.\n\n    **Example:**\n\n        >>> sma = SparseModularActivator(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sma(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n        >>> print('mask' in Z)\n        True\n\n    **Note:**\n\n        The sparsity of the output depends on the learnable `threshold` parameter and the `temperature`, which can be trained to achieve desired sparsity levels.\n\n    **References:**\n\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, temperature=20.0, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.gate = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.threshold = nn.Parameter(torch.zeros(1, **self.factory_kwargs))\n        self.temperature = temperature\n\n    def _forward(self, X, **Z):\n        scores = torch.sigmoid(self.gate(X))\n        mask = torch.sigmoid((scores - self.threshold) * self.temperature)\n        Y = X * mask\n        Z_ = {'mask': mask}\n        return Y, Z_\n\n\nclass DenseStateProcessor(GAUBase):\n    \"\"\"\n    The DenseStateProcessor processes actively selected states with dense transformations to maintain information flow.\n\n    **Key Components:**\n\n    - `dense_layer`: Linear layer that applies a transformation to the input.\n    - `activation`: Activation function applied after the dense layer.\n    - `norm`: Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the active input tensors.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the processed output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> dsp = DenseStateProcessor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = dsp(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module applies a feed-forward neural network to the input.\n        - It includes residual connections for better gradient flow.\n\n    **References:**\n\n        - Liu, Z., et al. (2024). Short-Long Convolutions Help Hardware-Efficient Linear Attention to Focus on Long Sequences.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.dense_layer = nn.Linear(embed_dim, embed_dim, bias=True, **\n            self.factory_kwargs)\n        self.activation = nn.GELU()\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        residual = X\n        Y = self.dense_layer(X)\n        Y = self.activation(Y)\n        Y = Y + residual\n        Y = self.norm(Y)\n        return Y, Z\n\n\nclass IOAwareAdapter(GAUBase):\n    \"\"\"\n    The IOAwareAdapter processes the input in chunks to optimize for IO efficiency.\n    It adapts computation to be hardware-friendly, improving inference speed and memory access patterns.\n\n    **Key Components:**\n\n    - `adapter`: Linear layer to adapt the input.\n    - `chunk_size`: Integer specifying the size of each chunk.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        chunk_size (int, optional): The size of each chunk for processing.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the input tensor to be adapted.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the adapted output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ioa = IOAwareAdapter(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 1024, 512)\n        >>> Y, Z = ioa(X)\n        >>> print(Y.shape)\n        torch.Size([2, 1024, 512])\n\n    **Note:**\n\n        - Processing in chunks can improve cache utilization and overall computational efficiency.\n        - The chunk size can be adjusted based on hardware specifications.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, chunk_size=256, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.adapter = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.chunk_size = chunk_size\n\n    def _forward(self, X, **Z):\n        B, L, D = X.size()\n        pad_len = (self.chunk_size - L % self.chunk_size) % self.chunk_size\n        if pad_len > 0:\n            padding = torch.zeros(B, pad_len, D, device=X.device, dtype=X.dtype\n                )\n            X_padded = torch.cat([X, padding], dim=1)\n        else:\n            X_padded = X\n        num_chunks = X_padded.size(1) // self.chunk_size\n        X_chunks = X_padded.view(B, num_chunks, self.chunk_size, D).contiguous(\n            )\n        X_chunks = X_chunks.view(-1, self.chunk_size, D)\n        adapted_chunks = self.adapter(X_chunks)\n        adapted_padded = adapted_chunks.view(B, num_chunks * self.chunk_size, D\n            )\n        Y = adapted_padded[:, :L, :]\n        return Y, Z\n\n\ngab_config = {'temperature': 20.0, 'chunk_size': 256}\n\n\n\nautoconfig = {\n    'd_model': 1024,\n    'n_block': 56\n}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    }
}