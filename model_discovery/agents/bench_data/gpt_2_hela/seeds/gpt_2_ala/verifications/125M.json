{
    "scale": "125M",
    "verification_report": {
        "wandb_ids.json": {
            "evaluate": {
                "name": "evo_exp_full_a_gpt_2_ala_125M_eval_20241030000342"
            },
            "entity": "aristo",
            "pretrain": {
                "id": "ciocaqmx",
                "name": "evo_exp_full_a_gpt_2_ala_125M_20241029205653"
            },
            "project": "model_discovery"
        },
        "trainer_state.json": {},
        "eval_results.json": {
            "total_evaluation_time_seconds": "623.8134512007236",
            "start_time": 11111553.426544324,
            "tokenizer_pad_token": [
                "</s>",
                "2"
            ],
            "system_instruction_sha": null,
            "group_subtasks": {
                "blimp_only_npi_licensor_present_filtered": [],
                "blimp_determiner_noun_agreement_with_adjective_1_filtered": [],
                "openbookqa": [],
                "inverse_scaling_pattern_matching_suppression": [],
                "blimp_tough_vs_raising_1_filtered": [],
                "tinyGSM8k": [],
                "inverse_scaling_repetitive_algebra": [],
                "blimp_animate_subject_trans_filtered": [],
                "blimp_determiner_noun_agreement_1_filtered": [],
                "arc_challenge": [],
                "inverse_scaling_sig_figs": [],
                "lambada_openai": [],
                "cola": [],
                "mathqa": [],
                "blimp_determiner_noun_agreement_2_filtered": [],
                "squad_completion": [],
                "blimp_regular_plural_subject_verb_agreement_1_filtered": [],
                "blimp_wh_vs_that_no_gap_filtered": [],
                "tinyTruthfulQA": [],
                "blimp_irregular_plural_subject_verb_agreement_2_filtered": [],
                "blimp_superlative_quantifiers_2_filtered": [],
                "rte": [],
                "mnli": [],
                "winogrande": [],
                "blimp_expletive_it_object_raising_filtered": [],
                "blimp_determiner_noun_agreement_irregular_2_filtered": [],
                "triviaqa": [],
                "blimp_passive_1_filtered": [],
                "blimp_supplement_subject_aux_inversion": [],
                "blimp_wh_island_filtered": [],
                "piqa": [],
                "blimp_supplement_hypernym": [],
                "blimp_distractor_agreement_relative_clause_filtered": [],
                "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered": [],
                "blimp_inchoative_filtered": [],
                "blimp_irregular_past_participle_verbs_filtered": [],
                "blimp_only_npi_scope_filtered": [],
                "qa4mre_2012": [],
                "inverse_scaling_into_the_unknown": [],
                "blimp_passive_2_filtered": [],
                "blimp_matrix_question_npi_licensor_present_filtered": [],
                "blimp_npi_present_2_filtered": [],
                "blimp_sentential_subject_island_filtered": [],
                "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered": [],
                "blimp_determiner_noun_agreement_irregular_1_filtered": [],
                "blimp_supplement_qa_congruence_easy": [],
                "inverse_scaling_quote_repetition": [],
                "blimp_supplement_turn_taking": [],
                "mnli_mismatch": [],
                "qnli": [],
                "blimp_causative_filtered": [],
                "blimp_wh_vs_that_no_gap_long_distance_filtered": [],
                "hellaswag": [],
                "blimp_ellipsis_n_bar_1_filtered": [],
                "blimp_coordinate_structure_constraint_complex_left_branch_filtered": [],
                "blimp_animate_subject_passive_filtered": [],
                "blimp_intransitive_filtered": [],
                "inverse_scaling_neqa": [],
                "blimp_sentential_negation_npi_scope_filtered": [],
                "sciq": [],
                "blimp_transitive_filtered": [],
                "blimp_principle_A_case_1_filtered": [],
                "blimp_npi_present_1_filtered": [],
                "inverse_scaling_winobias_antistereotype": [],
                "blimp_wh_vs_that_with_gap_long_distance_filtered": [],
                "qqp": [],
                "blimp_tough_vs_raising_2_filtered": [],
                "blimp_wh_questions_subject_gap_long_distance_filtered": [],
                "blimp_existential_there_quantifiers_1_filtered": [],
                "blimp_principle_A_domain_2_filtered": [],
                "inverse_scaling_memo_trap": [],
                "blimp_wh_questions_subject_gap_filtered": [],
                "blimp_anaphor_number_agreement_filtered": [],
                "inverse_scaling_hindsight_neglect_10shot": [],
                "blimp_principle_A_case_2_filtered": [],
                "blimp_sentential_negation_npi_licensor_present_filtered": [],
                "blimp_adjunct_island_filtered": [],
                "blimp_coordinate_structure_constraint_object_extraction_filtered": [],
                "arc_easy": [],
                "qa4mre_2013": [],
                "sst2": [],
                "blimp_principle_A_reconstruction_filtered": [],
                "blimp_supplement_qa_congruence_tricky": [],
                "blimp_principle_A_domain_3_filtered": [],
                "mrpc": [],
                "blimp_determiner_noun_agreement_with_adj_2_filtered": [],
                "wnli": [],
                "swag": [],
                "blimp_wh_vs_that_with_gap_filtered": [],
                "blimp_anaphor_gender_agreement_filtered": [],
                "qa4mre_2011": [],
                "blimp_left_branch_island_echo_question_filtered": [],
                "blimp_ellipsis_n_bar_2_filtered": [],
                "blimp_existential_there_object_raising_filtered": [],
                "tinyMMLU": [],
                "blimp_wh_questions_object_gap_filtered": [],
                "blimp_irregular_plural_subject_verb_agreement_1_filtered": [],
                "blimp_irregular_past_participle_adjectives_filtered": [],
                "blimp_regular_plural_subject_verb_agreement_2_filtered": [],
                "blimp_distractor_agreement_relational_noun_filtered": [],
                "blimp_existential_there_subject_raising_filtered": [],
                "blimp_principle_A_domain_1_filtered": [],
                "inverse_scaling_modus_tollens": [],
                "blimp_left_branch_island_simple_question_filtered": [],
                "wsc273": [],
                "blimp_complex_NP_island_filtered": [],
                "blimp_existential_there_quantifiers_2_filtered": [],
                "blimp_superlative_quantifiers_1_filtered": [],
                "blimp_principle_A_c_command_filtered": [],
                "inverse_scaling_redefine_math": [],
                "blimp_drop_argument_filtered": []
            },
            "eot_token_id": 2,
            "model_source": "modis",
            "versions": {
                "blimp_only_npi_licensor_present_filtered": 1.0,
                "blimp_determiner_noun_agreement_with_adjective_1_filtered": 1.0,
                "openbookqa": 1.0,
                "inverse_scaling_pattern_matching_suppression": 0,
                "blimp_tough_vs_raising_1_filtered": 1.0,
                "tinyGSM8k": 0.0,
                "inverse_scaling_repetitive_algebra": 0,
                "blimp_animate_subject_trans_filtered": 1.0,
                "blimp_determiner_noun_agreement_1_filtered": 1.0,
                "arc_challenge": 1.0,
                "inverse_scaling_sig_figs": 0,
                "lambada_openai": 1.0,
                "cola": 1.0,
                "mathqa": 1.0,
                "blimp_determiner_noun_agreement_2_filtered": 1.0,
                "squad_completion": 0,
                "blimp_regular_plural_subject_verb_agreement_1_filtered": 1.0,
                "blimp_wh_vs_that_no_gap_filtered": 1.0,
                "tinyTruthfulQA": 0.0,
                "blimp_irregular_plural_subject_verb_agreement_2_filtered": 1.0,
                "blimp_superlative_quantifiers_2_filtered": 1.0,
                "rte": 1.0,
                "mnli": 1.0,
                "winogrande": 1.0,
                "blimp_expletive_it_object_raising_filtered": 1.0,
                "blimp_determiner_noun_agreement_irregular_2_filtered": 1.0,
                "triviaqa": 3.0,
                "blimp_passive_1_filtered": 1.0,
                "blimp_supplement_subject_aux_inversion": 1.0,
                "blimp_wh_island_filtered": 1.0,
                "piqa": 1.0,
                "blimp_supplement_hypernym": 1.0,
                "blimp_distractor_agreement_relative_clause_filtered": 1.0,
                "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered": 1.0,
                "blimp_inchoative_filtered": 1.0,
                "blimp_irregular_past_participle_verbs_filtered": 1.0,
                "blimp_only_npi_scope_filtered": 1.0,
                "qa4mre_2012": 1.0,
                "inverse_scaling_into_the_unknown": 0,
                "blimp_passive_2_filtered": 1.0,
                "blimp_matrix_question_npi_licensor_present_filtered": 1.0,
                "blimp_npi_present_2_filtered": 1.0,
                "blimp_sentential_subject_island_filtered": 1.0,
                "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered": 1.0,
                "blimp_determiner_noun_agreement_irregular_1_filtered": 1.0,
                "blimp_supplement_qa_congruence_easy": 1.0,
                "inverse_scaling_quote_repetition": 0,
                "blimp_supplement_turn_taking": 1.0,
                "mnli_mismatch": 1.0,
                "qnli": 1.0,
                "blimp_causative_filtered": 1.0,
                "blimp_wh_vs_that_no_gap_long_distance_filtered": 1.0,
                "hellaswag": 1.0,
                "blimp_ellipsis_n_bar_1_filtered": 1.0,
                "blimp_coordinate_structure_constraint_complex_left_branch_filtered": 1.0,
                "blimp_animate_subject_passive_filtered": 1.0,
                "blimp_intransitive_filtered": 1.0,
                "inverse_scaling_neqa": 0,
                "blimp_sentential_negation_npi_scope_filtered": 1.0,
                "sciq": 1.0,
                "blimp_transitive_filtered": 1.0,
                "blimp_principle_A_case_1_filtered": 1.0,
                "blimp_npi_present_1_filtered": 1.0,
                "inverse_scaling_winobias_antistereotype": 0,
                "blimp_wh_vs_that_with_gap_long_distance_filtered": 1.0,
                "qqp": 2.0,
                "blimp_tough_vs_raising_2_filtered": 1.0,
                "blimp_wh_questions_subject_gap_long_distance_filtered": 1.0,
                "blimp_existential_there_quantifiers_1_filtered": 1.0,
                "blimp_principle_A_domain_2_filtered": 1.0,
                "inverse_scaling_memo_trap": 0,
                "blimp_wh_questions_subject_gap_filtered": 1.0,
                "blimp_anaphor_number_agreement_filtered": 1.0,
                "inverse_scaling_hindsight_neglect_10shot": 0,
                "blimp_principle_A_case_2_filtered": 1.0,
                "blimp_sentential_negation_npi_licensor_present_filtered": 1.0,
                "blimp_adjunct_island_filtered": 1.0,
                "blimp_coordinate_structure_constraint_object_extraction_filtered": 1.0,
                "arc_easy": 1.0,
                "qa4mre_2013": 1.0,
                "sst2": 1.0,
                "blimp_principle_A_reconstruction_filtered": 1.0,
                "blimp_supplement_qa_congruence_tricky": 1.0,
                "blimp_principle_A_domain_3_filtered": 1.0,
                "mrpc": 1.0,
                "blimp_determiner_noun_agreement_with_adj_2_filtered": 1.0,
                "wnli": 2.0,
                "swag": 1.0,
                "blimp_wh_vs_that_with_gap_filtered": 1.0,
                "blimp_anaphor_gender_agreement_filtered": 1.0,
                "qa4mre_2011": 1.0,
                "blimp_left_branch_island_echo_question_filtered": 1.0,
                "blimp_ellipsis_n_bar_2_filtered": 1.0,
                "blimp_existential_there_object_raising_filtered": 1.0,
                "tinyMMLU": 0.0,
                "blimp_wh_questions_object_gap_filtered": 1.0,
                "blimp_irregular_plural_subject_verb_agreement_1_filtered": 1.0,
                "blimp_irregular_past_participle_adjectives_filtered": 1.0,
                "blimp_regular_plural_subject_verb_agreement_2_filtered": 1.0,
                "blimp_distractor_agreement_relational_noun_filtered": 1.0,
                "blimp_existential_there_subject_raising_filtered": 1.0,
                "blimp_principle_A_domain_1_filtered": 1.0,
                "inverse_scaling_modus_tollens": 0,
                "blimp_left_branch_island_simple_question_filtered": 1.0,
                "wsc273": 1.0,
                "blimp_complex_NP_island_filtered": 1.0,
                "blimp_existential_there_quantifiers_2_filtered": 1.0,
                "blimp_superlative_quantifiers_1_filtered": 1.0,
                "blimp_principle_A_c_command_filtered": 1.0,
                "inverse_scaling_redefine_math": 0,
                "blimp_drop_argument_filtered": 1.0
            },
            "fewshot_as_multiturn": false,
            "end_time": 11112177.239995524,
            "max_length": 2048,
            "tokenizer_bos_token": [
                "<s>",
                "1"
            ],
            "results": {
                "blimp_only_npi_licensor_present_filtered": {
                    "acc,none": 0.42970521541950113,
                    "acc_stderr,none": 0.01667811861324945,
                    "alias": "blimp_only_npi_licensor_present_filtered"
                },
                "blimp_determiner_noun_agreement_with_adjective_1_filtered": {
                    "acc,none": 0.5305466237942122,
                    "acc_stderr,none": 0.016347451395869524,
                    "alias": "blimp_determiner_noun_agreement_with_adjective_1_filtered"
                },
                "openbookqa": {
                    "acc_norm_stderr,none": 0.019780559675655396,
                    "acc,none": 0.146,
                    "acc_stderr,none": 0.015807205175834907,
                    "acc_norm,none": 0.266,
                    "alias": "openbookqa"
                },
                "inverse_scaling_pattern_matching_suppression": {
                    "acc_norm_stderr,none": 0.01232001438335283,
                    "acc,none": 0.32563025210084034,
                    "acc_stderr,none": 0.012405075905101948,
                    "acc_norm,none": 0.3172268907563025,
                    "alias": "inverse_scaling_pattern_matching_suppression"
                },
                "blimp_tough_vs_raising_1_filtered": {
                    "acc,none": 0.2858649789029536,
                    "acc_stderr,none": 0.014682352714936207,
                    "alias": "blimp_tough_vs_raising_1_filtered"
                },
                "tinyGSM8k": {
                    "alias": "tinyGSM8k",
                    "exact_match,flexible-extract": 0.005531037620360234,
                    "exact_match_stderr,strict-match": "N/A",
                    "exact_match,strict-match": 0.005531037620360234,
                    "exact_match_stderr,flexible-extract": "N/A"
                },
                "inverse_scaling_repetitive_algebra": {
                    "acc_norm_stderr,none": 0.015749255189977687,
                    "acc,none": 0.533,
                    "acc_stderr,none": 0.015784807891138876,
                    "acc_norm,none": 0.547,
                    "alias": "inverse_scaling_repetitive_algebra"
                },
                "blimp_animate_subject_trans_filtered": {
                    "acc,none": 0.7735644637053087,
                    "acc_stderr,none": 0.013783359618886215,
                    "alias": "blimp_animate_subject_trans_filtered"
                },
                "blimp_determiner_noun_agreement_1_filtered": {
                    "acc,none": 0.5575888051668461,
                    "acc_stderr,none": 0.016304072156327176,
                    "alias": "blimp_determiner_noun_agreement_1_filtered"
                },
                "arc_challenge": {
                    "acc_norm_stderr,none": 0.013106784883601296,
                    "acc,none": 0.22098976109215018,
                    "acc_stderr,none": 0.012124929206818241,
                    "acc_norm,none": 0.2790102389078498,
                    "alias": "arc_challenge"
                },
                "inverse_scaling_sig_figs": {
                    "acc_norm_stderr,none": 0.0033795313072681873,
                    "acc,none": 0.3935014595396468,
                    "acc_stderr,none": 0.0033795313072681873,
                    "acc_norm,none": 0.3935014595396468,
                    "alias": "inverse_scaling_sig_figs"
                },
                "lambada_openai": {
                    "alias": "lambada_openai",
                    "acc,none": 0.0,
                    "perplexity,none": 65473880.32876468,
                    "acc_stderr,none": 0.0,
                    "perplexity_stderr,none": 7226404.873963392
                },
                "cola": {
                    "mcc_stderr,none": 0.0,
                    "mcc,none": 0.0,
                    "alias": "cola"
                },
                "mathqa": {
                    "acc_norm_stderr,none": 0.007082176875410107,
                    "acc,none": 0.17252931323283083,
                    "acc_stderr,none": 0.006916849819851149,
                    "acc_norm,none": 0.183249581239531,
                    "alias": "mathqa"
                },
                "blimp_determiner_noun_agreement_2_filtered": {
                    "acc,none": 0.6036519871106337,
                    "acc_stderr,none": 0.016039476353236718,
                    "alias": "blimp_determiner_noun_agreement_2_filtered"
                },
                "squad_completion": {
                    "contains_stderr,none": "N/A",
                    "contains,none": 0.0,
                    "alias": "squad_completion"
                },
                "blimp_regular_plural_subject_verb_agreement_1_filtered": {
                    "acc,none": 0.597752808988764,
                    "acc_stderr,none": 0.01644585445060793,
                    "alias": "blimp_regular_plural_subject_verb_agreement_1_filtered"
                },
                "blimp_wh_vs_that_no_gap_filtered": {
                    "acc,none": 0.7049941927990708,
                    "acc_stderr,none": 0.015551018097182703,
                    "alias": "blimp_wh_vs_that_no_gap_filtered"
                },
                "tinyTruthfulQA": {
                    "acc,none": 0.5246436303986209,
                    "acc_stderr,none": "N/A",
                    "alias": "tinyTruthfulQA"
                },
                "blimp_irregular_plural_subject_verb_agreement_2_filtered": {
                    "acc,none": 0.5594170403587444,
                    "acc_stderr,none": 0.016631937395962568,
                    "alias": "blimp_irregular_plural_subject_verb_agreement_2_filtered"
                },
                "blimp_superlative_quantifiers_2_filtered": {
                    "acc,none": 0.8367139959432048,
                    "acc_stderr,none": 0.011777276793297703,
                    "alias": "blimp_superlative_quantifiers_2_filtered"
                },
                "rte": {
                    "acc,none": 0.5270758122743683,
                    "acc_stderr,none": 0.030052303463143734,
                    "alias": "rte"
                },
                "mnli": {
                    "acc,none": 0.3544574630667346,
                    "acc_stderr,none": 0.004828602644595183,
                    "alias": "mnli"
                },
                "winogrande": {
                    "acc,none": 0.500394632991318,
                    "acc_stderr,none": 0.01405248130604961,
                    "alias": "winogrande"
                },
                "blimp_expletive_it_object_raising_filtered": {
                    "acc,none": 0.6561264822134387,
                    "acc_stderr,none": 0.017252758624269466,
                    "alias": "blimp_expletive_it_object_raising_filtered"
                },
                "blimp_determiner_noun_agreement_irregular_2_filtered": {
                    "acc,none": 0.5451219512195122,
                    "acc_stderr,none": 0.017400125240526636,
                    "alias": "blimp_determiner_noun_agreement_irregular_2_filtered"
                },
                "triviaqa": {
                    "exact_match_stderr,remove_whitespace": 0.00011144855087437195,
                    "exact_match,remove_whitespace": 0.00022291573785109228,
                    "alias": "triviaqa"
                },
                "blimp_passive_1_filtered": {
                    "acc,none": 0.594047619047619,
                    "acc_stderr,none": 0.01695380547503095,
                    "alias": "blimp_passive_1_filtered"
                },
                "blimp_supplement_subject_aux_inversion": {
                    "acc,none": 0.6904577191621412,
                    "acc_stderr,none": 0.007435284810971782,
                    "alias": "blimp_supplement_subject_aux_inversion"
                },
                "blimp_wh_island_filtered": {
                    "acc,none": 0.6833333333333333,
                    "acc_stderr,none": 0.015021322658116974,
                    "alias": "blimp_wh_island_filtered"
                },
                "piqa": {
                    "acc_norm_stderr,none": 0.011665824165343952,
                    "acc,none": 0.5331882480957563,
                    "acc_stderr,none": 0.011640096923563308,
                    "acc_norm,none": 0.5,
                    "alias": "piqa"
                },
                "blimp_supplement_hypernym": {
                    "acc,none": 0.6057007125890737,
                    "acc_stderr,none": 0.01685171247285365,
                    "alias": "blimp_supplement_hypernym"
                },
                "blimp_distractor_agreement_relative_clause_filtered": {
                    "acc,none": 0.6234213547646383,
                    "acc_stderr,none": 0.01642703019129805,
                    "alias": "blimp_distractor_agreement_relative_clause_filtered"
                },
                "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered": {
                    "acc,none": 0.5738161559888579,
                    "acc_stderr,none": 0.018468231047950593,
                    "alias": "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered"
                },
                "blimp_inchoative_filtered": {
                    "acc,none": 0.4327485380116959,
                    "acc_stderr,none": 0.016954175767314315,
                    "alias": "blimp_inchoative_filtered"
                },
                "blimp_irregular_past_participle_verbs_filtered": {
                    "acc,none": 0.6050955414012739,
                    "acc_stderr,none": 0.015935407850304634,
                    "alias": "blimp_irregular_past_participle_verbs_filtered"
                },
                "blimp_only_npi_scope_filtered": {
                    "acc,none": 0.6344086021505376,
                    "acc_stderr,none": 0.016656332318411574,
                    "alias": "blimp_only_npi_scope_filtered"
                },
                "qa4mre_2012": {
                    "acc_norm_stderr,none": 0.03462157845865139,
                    "acc,none": 0.1625,
                    "acc_stderr,none": 0.029256375964756727,
                    "acc_norm,none": 0.25625,
                    "alias": "qa4mre_2012"
                },
                "inverse_scaling_into_the_unknown": {
                    "acc_norm_stderr,none": 0.011696896320542174,
                    "acc,none": 0.5241228070175439,
                    "acc_stderr,none": 0.011696896320542174,
                    "acc_norm,none": 0.5241228070175439,
                    "alias": "inverse_scaling_into_the_unknown"
                },
                "blimp_passive_2_filtered": {
                    "acc,none": 0.5758582502768549,
                    "acc_stderr,none": 0.016455460475208416,
                    "alias": "blimp_passive_2_filtered"
                },
                "blimp_matrix_question_npi_licensor_present_filtered": {
                    "acc,none": 0.45317545748116256,
                    "acc_stderr,none": 0.01634117202810279,
                    "alias": "blimp_matrix_question_npi_licensor_present_filtered"
                },
                "blimp_npi_present_2_filtered": {
                    "acc,none": 0.5317286652078774,
                    "acc_stderr,none": 0.016514234021162606,
                    "alias": "blimp_npi_present_2_filtered"
                },
                "blimp_sentential_subject_island_filtered": {
                    "acc,none": 0.5972944849115505,
                    "acc_stderr,none": 0.0158289615633087,
                    "alias": "blimp_sentential_subject_island_filtered"
                },
                "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered": {
                    "acc,none": 0.6214285714285714,
                    "acc_stderr,none": 0.016745130829136045,
                    "alias": "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered"
                },
                "blimp_determiner_noun_agreement_irregular_1_filtered": {
                    "acc,none": 0.5624082232011748,
                    "acc_stderr,none": 0.01902418018937356,
                    "alias": "blimp_determiner_noun_agreement_irregular_1_filtered"
                },
                "blimp_supplement_qa_congruence_easy": {
                    "acc,none": 0.4375,
                    "acc_stderr,none": 0.0625,
                    "alias": "blimp_supplement_qa_congruence_easy"
                },
                "inverse_scaling_quote_repetition": {
                    "acc_norm_stderr,none": 0.021723405684078406,
                    "acc,none": 0.14666666666666667,
                    "acc_stderr,none": 0.020459238826580572,
                    "acc_norm,none": 0.17,
                    "alias": "inverse_scaling_quote_repetition"
                },
                "blimp_supplement_turn_taking": {
                    "acc,none": 0.7892857142857143,
                    "acc_stderr,none": 0.024415296890654352,
                    "alias": "blimp_supplement_turn_taking"
                },
                "mnli_mismatch": {
                    "acc,none": 0.3522172497965826,
                    "acc_stderr,none": 0.004817493665633903,
                    "alias": "mnli_mismatch"
                },
                "qnli": {
                    "acc,none": 0.5053999633900788,
                    "acc_stderr,none": 0.006765015986877416,
                    "alias": "qnli"
                },
                "blimp_causative_filtered": {
                    "acc,none": 0.4474327628361858,
                    "acc_stderr,none": 0.017395840946155646,
                    "alias": "blimp_causative_filtered"
                },
                "blimp_wh_vs_that_no_gap_long_distance_filtered": {
                    "acc,none": 0.7405714285714285,
                    "acc_stderr,none": 0.014826432413698371,
                    "alias": "blimp_wh_vs_that_no_gap_long_distance_filtered"
                },
                "hellaswag": {
                    "acc_norm_stderr,none": 0.004375244237044889,
                    "acc,none": 0.25731925911173076,
                    "acc_stderr,none": 0.004362633637374433,
                    "acc_norm,none": 0.25960963951404104,
                    "alias": "hellaswag"
                },
                "blimp_ellipsis_n_bar_1_filtered": {
                    "acc,none": 0.7244389027431422,
                    "acc_stderr,none": 0.015786780723513662,
                    "alias": "blimp_ellipsis_n_bar_1_filtered"
                },
                "blimp_coordinate_structure_constraint_complex_left_branch_filtered": {
                    "acc,none": 0.6181015452538632,
                    "acc_stderr,none": 0.0161502621297732,
                    "alias": "blimp_coordinate_structure_constraint_complex_left_branch_filtered"
                },
                "blimp_animate_subject_passive_filtered": {
                    "acc,none": 0.6446927374301676,
                    "acc_stderr,none": 0.016006989934803203,
                    "alias": "blimp_animate_subject_passive_filtered"
                },
                "blimp_intransitive_filtered": {
                    "acc,none": 0.5691244239631337,
                    "acc_stderr,none": 0.016817831683305293,
                    "alias": "blimp_intransitive_filtered"
                },
                "inverse_scaling_neqa": {
                    "acc_norm_stderr,none": 0.028837890554337213,
                    "acc,none": 0.5366666666666666,
                    "acc_stderr,none": 0.028837890554337213,
                    "acc_norm,none": 0.5366666666666666,
                    "alias": "inverse_scaling_neqa"
                },
                "blimp_sentential_negation_npi_scope_filtered": {
                    "acc,none": 0.49483352468427094,
                    "acc_stderr,none": 0.01695068260697228,
                    "alias": "blimp_sentential_negation_npi_scope_filtered"
                },
                "sciq": {
                    "acc_norm_stderr,none": 0.012559527926707349,
                    "acc,none": 0.187,
                    "acc_stderr,none": 0.012336254828074166,
                    "acc_norm,none": 0.196,
                    "alias": "sciq"
                },
                "blimp_transitive_filtered": {
                    "acc,none": 0.5691244239631337,
                    "acc_stderr,none": 0.016817831683305293,
                    "alias": "blimp_transitive_filtered"
                },
                "blimp_principle_A_case_1_filtered": {
                    "acc,none": 0.5614035087719298,
                    "acc_stderr,none": 0.01644034584737269,
                    "alias": "blimp_principle_A_case_1_filtered"
                },
                "blimp_npi_present_1_filtered": {
                    "acc,none": 0.5335533553355336,
                    "acc_stderr,none": 0.016555678729007577,
                    "alias": "blimp_npi_present_1_filtered"
                },
                "inverse_scaling_winobias_antistereotype": {
                    "acc_norm_stderr,none": 0.024662890588966417,
                    "acc,none": 0.5145631067961165,
                    "acc_stderr,none": 0.02465271762756472,
                    "acc_norm,none": 0.4975728155339806,
                    "alias": "inverse_scaling_winobias_antistereotype"
                },
                "blimp_wh_vs_that_with_gap_long_distance_filtered": {
                    "acc,none": 0.5648351648351648,
                    "acc_stderr,none": 0.016443937540901257,
                    "alias": "blimp_wh_vs_that_with_gap_long_distance_filtered"
                },
                "qqp": {
                    "acc,none": 0.6318327974276527,
                    "acc_stderr,none": 0.0023987066106141842,
                    "alias": "qqp"
                },
                "blimp_tough_vs_raising_2_filtered": {
                    "acc,none": 0.8402173913043478,
                    "acc_stderr,none": 0.01208656331143163,
                    "alias": "blimp_tough_vs_raising_2_filtered"
                },
                "blimp_wh_questions_subject_gap_long_distance_filtered": {
                    "acc,none": 0.5950991831971996,
                    "acc_stderr,none": 0.01677768827976947,
                    "alias": "blimp_wh_questions_subject_gap_long_distance_filtered"
                },
                "blimp_existential_there_quantifiers_1_filtered": {
                    "acc,none": 0.7279569892473118,
                    "acc_stderr,none": 0.01460036756741627,
                    "alias": "blimp_existential_there_quantifiers_1_filtered"
                },
                "blimp_principle_A_domain_2_filtered": {
                    "acc,none": 0.6065573770491803,
                    "acc_stderr,none": 0.016158593292585365,
                    "alias": "blimp_principle_A_domain_2_filtered"
                },
                "inverse_scaling_memo_trap": {
                    "acc_norm_stderr,none": 0.01628887814854385,
                    "acc,none": 0.5651709401709402,
                    "acc_stderr,none": 0.01621225352109748,
                    "acc_norm,none": 0.5438034188034188,
                    "alias": "inverse_scaling_memo_trap"
                },
                "blimp_wh_questions_subject_gap_filtered": {
                    "acc,none": 0.60913140311804,
                    "acc_stderr,none": 0.01629200982095573,
                    "alias": "blimp_wh_questions_subject_gap_filtered"
                },
                "blimp_anaphor_number_agreement_filtered": {
                    "acc,none": 0.5596133190118152,
                    "acc_stderr,none": 0.016278696818346705,
                    "alias": "blimp_anaphor_number_agreement_filtered"
                },
                "inverse_scaling_hindsight_neglect_10shot": {
                    "acc_norm_stderr,none": 0.028079660068225168,
                    "acc,none": 0.4507936507936508,
                    "acc_stderr,none": 0.028079660068225168,
                    "acc_norm,none": 0.4507936507936508,
                    "alias": "inverse_scaling_hindsight_neglect_10shot"
                },
                "blimp_principle_A_case_2_filtered": {
                    "acc,none": 0.5147540983606558,
                    "acc_stderr,none": 0.016531328145805265,
                    "alias": "blimp_principle_A_case_2_filtered"
                },
                "blimp_sentential_negation_npi_licensor_present_filtered": {
                    "acc,none": 0.7290533188248096,
                    "acc_stderr,none": 0.014668990351254824,
                    "alias": "blimp_sentential_negation_npi_licensor_present_filtered"
                },
                "blimp_adjunct_island_filtered": {
                    "acc,none": 0.6002155172413793,
                    "acc_stderr,none": 0.016088913216352606,
                    "alias": "blimp_adjunct_island_filtered"
                },
                "blimp_coordinate_structure_constraint_object_extraction_filtered": {
                    "acc,none": 0.5795574288724974,
                    "acc_stderr,none": 0.01603235834967264,
                    "alias": "blimp_coordinate_structure_constraint_object_extraction_filtered"
                },
                "arc_easy": {
                    "acc_norm_stderr,none": 0.009080463246017426,
                    "acc,none": 0.2638888888888889,
                    "acc_stderr,none": 0.009043789220055392,
                    "acc_norm,none": 0.26725589225589225,
                    "alias": "arc_easy"
                },
                "qa4mre_2013": {
                    "acc_norm_stderr,none": 0.022989742475464956,
                    "acc,none": 0.24295774647887325,
                    "acc_stderr,none": 0.025493661645903932,
                    "acc_norm,none": 0.18309859154929578,
                    "alias": "qa4mre_2013"
                },
                "sst2": {
                    "acc,none": 0.49311926605504586,
                    "acc_stderr,none": 0.0169402494061637,
                    "alias": "sst2"
                },
                "blimp_principle_A_reconstruction_filtered": {
                    "acc,none": 0.6111685625646329,
                    "acc_stderr,none": 0.015684570318101523,
                    "alias": "blimp_principle_A_reconstruction_filtered"
                },
                "blimp_supplement_qa_congruence_tricky": {
                    "acc,none": 0.3939393939393939,
                    "acc_stderr,none": 0.038154943086889305,
                    "alias": "blimp_supplement_qa_congruence_tricky"
                },
                "blimp_principle_A_domain_3_filtered": {
                    "acc,none": 0.5685441020191286,
                    "acc_stderr,none": 0.016154233556115335,
                    "alias": "blimp_principle_A_domain_3_filtered"
                },
                "mrpc": {
                    "acc,none": 0.3161764705882353,
                    "acc_stderr,none": 0.023048336668420145,
                    "alias": "mrpc"
                },
                "blimp_determiner_noun_agreement_with_adj_2_filtered": {
                    "acc,none": 0.6323060573857598,
                    "acc_stderr,none": 0.01572689481122163,
                    "alias": "blimp_determiner_noun_agreement_with_adj_2_filtered"
                },
                "wnli": {
                    "acc,none": 0.43661971830985913,
                    "acc_stderr,none": 0.05927935558412972,
                    "alias": "wnli"
                },
                "swag": {
                    "acc_norm_stderr,none": 0.003076129961422361,
                    "acc,none": 0.2650704788563431,
                    "acc_stderr,none": 0.0031205723051842,
                    "acc_norm,none": 0.25362391282615215,
                    "alias": "swag"
                },
                "blimp_wh_vs_that_with_gap_filtered": {
                    "acc,none": 0.5048966267682263,
                    "acc_stderr,none": 0.016501667673242612,
                    "alias": "blimp_wh_vs_that_with_gap_filtered"
                },
                "blimp_anaphor_gender_agreement_filtered": {
                    "acc,none": 0.446961894953656,
                    "acc_stderr,none": 0.015963455669770074,
                    "alias": "blimp_anaphor_gender_agreement_filtered"
                },
                "qa4mre_2011": {
                    "acc_norm_stderr,none": 0.03196600376689893,
                    "acc,none": 0.11666666666666667,
                    "acc_stderr,none": 0.029428100038830653,
                    "acc_norm,none": 0.14166666666666666,
                    "alias": "qa4mre_2011"
                },
                "blimp_left_branch_island_echo_question_filtered": {
                    "acc,none": 0.5596620908130939,
                    "acc_stderr,none": 0.016140255863004976,
                    "alias": "blimp_left_branch_island_echo_question_filtered"
                },
                "blimp_ellipsis_n_bar_2_filtered": {
                    "acc,none": 0.3695652173913043,
                    "acc_stderr,none": 0.016784672554205557,
                    "alias": "blimp_ellipsis_n_bar_2_filtered"
                },
                "blimp_existential_there_object_raising_filtered": {
                    "acc,none": 0.7376847290640394,
                    "acc_stderr,none": 0.015446737155204992,
                    "alias": "blimp_existential_there_object_raising_filtered"
                },
                "tinyMMLU": {
                    "acc_norm_stderr,none": "N/A",
                    "acc_norm,none": 0.32286021100425377,
                    "alias": "tinyMMLU"
                },
                "blimp_wh_questions_object_gap_filtered": {
                    "acc,none": 0.5552968568102444,
                    "acc_stderr,none": 0.016965007782952814,
                    "alias": "blimp_wh_questions_object_gap_filtered"
                },
                "blimp_irregular_plural_subject_verb_agreement_1_filtered": {
                    "acc,none": 0.5634328358208955,
                    "acc_stderr,none": 0.01750204668123214,
                    "alias": "blimp_irregular_plural_subject_verb_agreement_1_filtered"
                },
                "blimp_irregular_past_participle_adjectives_filtered": {
                    "acc,none": 0.3704474505723205,
                    "acc_stderr,none": 0.015586323362994285,
                    "alias": "blimp_irregular_past_participle_adjectives_filtered"
                },
                "blimp_regular_plural_subject_verb_agreement_2_filtered": {
                    "acc,none": 0.5375661375661376,
                    "acc_stderr,none": 0.016227617744362946,
                    "alias": "blimp_regular_plural_subject_verb_agreement_2_filtered"
                },
                "blimp_distractor_agreement_relational_noun_filtered": {
                    "acc,none": 0.6269035532994924,
                    "acc_stderr,none": 0.017239455947687353,
                    "alias": "blimp_distractor_agreement_relational_noun_filtered"
                },
                "blimp_existential_there_subject_raising_filtered": {
                    "acc,none": 0.7478354978354979,
                    "acc_stderr,none": 0.01429368353374188,
                    "alias": "blimp_existential_there_subject_raising_filtered"
                },
                "blimp_principle_A_domain_1_filtered": {
                    "acc,none": 0.6684901531728665,
                    "acc_stderr,none": 0.015579744632313059,
                    "alias": "blimp_principle_A_domain_1_filtered"
                },
                "inverse_scaling_modus_tollens": {
                    "acc_norm_stderr,none": 0.0,
                    "acc,none": 0.0,
                    "acc_stderr,none": 0.0,
                    "acc_norm,none": 1.0,
                    "alias": "inverse_scaling_modus_tollens"
                },
                "blimp_left_branch_island_simple_question_filtered": {
                    "acc,none": 0.5583596214511041,
                    "acc_stderr,none": 0.016111262964120337,
                    "alias": "blimp_left_branch_island_simple_question_filtered"
                },
                "wsc273": {
                    "acc,none": 0.4945054945054945,
                    "acc_stderr,none": 0.03031512256146765,
                    "alias": "wsc273"
                },
                "blimp_complex_NP_island_filtered": {
                    "acc,none": 0.6583924349881797,
                    "acc_stderr,none": 0.01631465150996901,
                    "alias": "blimp_complex_NP_island_filtered"
                },
                "blimp_existential_there_quantifiers_2_filtered": {
                    "acc,none": 0.40285400658616904,
                    "acc_stderr,none": 0.016258984193147214,
                    "alias": "blimp_existential_there_quantifiers_2_filtered"
                },
                "blimp_superlative_quantifiers_1_filtered": {
                    "acc,none": 0.5045965270684372,
                    "acc_stderr,none": 0.015987561369606745,
                    "alias": "blimp_superlative_quantifiers_1_filtered"
                },
                "blimp_principle_A_c_command_filtered": {
                    "acc,none": 0.572938689217759,
                    "acc_stderr,none": 0.016091009274964048,
                    "alias": "blimp_principle_A_c_command_filtered"
                },
                "inverse_scaling_redefine_math": {
                    "acc_norm_stderr,none": 0.016675768947734156,
                    "acc,none": 0.5022222222222222,
                    "acc_stderr,none": 0.016675768947734156,
                    "acc_norm,none": 0.5022222222222222,
                    "alias": "inverse_scaling_redefine_math"
                },
                "blimp_drop_argument_filtered": {
                    "acc,none": 0.7326086956521739,
                    "acc_stderr,none": 0.014599968500085056,
                    "alias": "blimp_drop_argument_filtered"
                }
            },
            "model_name_sanitized": "evo_exp_full_a__125M__gpt_2_ala_125M",
            "chat_template": null,
            "date": 1730271830.8896978,
            "tokenizer_eos_token": [
                "</s>",
                "2"
            ],
            "model_name": "evo_exp_full_a/125M/gpt_2_ala_125M",
            "chat_template_sha": null,
            "system_instruction": null,
            "configs": {
                "blimp_only_npi_licensor_present_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_only_npi_licensor_present_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/only_npi_licensor_present.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_determiner_noun_agreement_with_adjective_1_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_determiner_noun_agreement_with_adjective_1_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_with_adjective_1.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "openbookqa": {
                    "description": "",
                    "doc_to_decontamination_query": "question_stem",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "openbookqa",
                    "doc_to_target": "{{choices.label.index(answerKey.lstrip())}}",
                    "task": "openbookqa",
                    "training_split": "train",
                    "validation_split": "validation",
                    "doc_to_text": "question_stem",
                    "should_decontaminate": true,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "{{choices.text}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "main",
                    "test_split": "test",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "inverse_scaling_pattern_matching_suppression": {
                    "description": "",
                    "doc_to_target": "answer_index",
                    "dataset_path": "Albertmade/pattern-matching-suppression",
                    "fewshot_delimiter": "\n\n",
                    "metadata": {
                        "version": 0
                    },
                    "tag": [
                        "inverse_scaling_mc"
                    ],
                    "task": "inverse_scaling_pattern_matching_suppression",
                    "doc_to_text": "prompt",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "classes",
                    "num_fewshot": 0,
                    "target_delimiter": "",
                    "test_split": "train",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_tough_vs_raising_1_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_tough_vs_raising_1_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/tough_vs_raising_1.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "tinyGSM8k": {
                    "description": "",
                    "doc_to_target": "{{answer}}",
                    "training_split": "train",
                    "fewshot_split": "train",
                    "metadata": {
                        "version": 0.0
                    },
                    "dataset_path": "tinyBenchmarks/tinyGSM8k",
                    "task": "tinyGSM8k",
                    "generation_kwargs": {
                        "until": [
                            "Question:",
                            "</s>",
                            "<|im_end|>"
                        ],
                        "temperature": 0.0,
                        "do_sample": false
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_text": "Question: {{question}}\nAnswer:",
                    "should_decontaminate": false,
                    "filter_list": [
                        {
                            "filter": [
                                {
                                    "regex_pattern": "#### (\\-?[0-9\\.\\,]+)",
                                    "function": "regex"
                                },
                                {
                                    "function": "take_first"
                                }
                            ],
                            "name": "strict-match"
                        },
                        {
                            "filter": [
                                {
                                    "regex_pattern": "(-?[$0-9.,]{2,})|(-?[0-9]+)",
                                    "group_select": -1,
                                    "function": "regex"
                                },
                                {
                                    "function": "take_first"
                                }
                            ],
                            "name": "flexible-extract"
                        }
                    ],
                    "metric_list": [
                        {
                            "metric": "exact_match",
                            "aggregation": "def agg_gpirt_gsm8k(items: List[float], benchmark: str = \"gsm8k\") -> float:\n    items = np.array(items)\n    predictions = tb.evaluate(items, benchmark)\n    return predictions[benchmark][\"gpirt\"]\n",
                            "ignore_case": true,
                            "regexes_to_ignore": [
                                ",",
                                "\\$",
                                "(?s).*#### ",
                                "\\.$"
                            ],
                            "higher_is_better": true,
                            "ignore_punctuation": false
                        }
                    ],
                    "num_fewshot": 5,
                    "target_delimiter": " ",
                    "dataset_name": "main",
                    "test_split": "test",
                    "output_type": "generate_until",
                    "repeats": 1
                },
                "inverse_scaling_repetitive_algebra": {
                    "description": "",
                    "doc_to_target": "answer_index",
                    "dataset_path": "Albertmade/repetitive-algebra",
                    "fewshot_delimiter": "\n\n",
                    "metadata": {
                        "version": 0
                    },
                    "tag": [
                        "inverse_scaling_mc"
                    ],
                    "task": "inverse_scaling_repetitive_algebra",
                    "doc_to_text": "prompt",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "classes",
                    "num_fewshot": 0,
                    "target_delimiter": "",
                    "test_split": "train",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_animate_subject_trans_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_animate_subject_trans_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/animate_subject_trans.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_determiner_noun_agreement_1_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_determiner_noun_agreement_1_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_1.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "arc_challenge": {
                    "description": "",
                    "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "allenai/ai2_arc",
                    "doc_to_target": "{{choices.label.index(answerKey)}}",
                    "task": "arc_challenge",
                    "training_split": "train",
                    "tag": [
                        "ai2_arc"
                    ],
                    "validation_split": "validation",
                    "doc_to_text": "Question: {{question}}\nAnswer:",
                    "should_decontaminate": true,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "{{choices.text}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "ARC-Challenge",
                    "test_split": "test",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "inverse_scaling_sig_figs": {
                    "description": "",
                    "doc_to_target": "answer_index",
                    "dataset_path": "Albertmade/sig-figs",
                    "fewshot_delimiter": "\n\n",
                    "metadata": {
                        "version": 0
                    },
                    "tag": [
                        "inverse_scaling_mc"
                    ],
                    "task": "inverse_scaling_sig_figs",
                    "doc_to_text": "prompt",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "classes",
                    "num_fewshot": 0,
                    "target_delimiter": "",
                    "test_split": "train",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "lambada_openai": {
                    "description": "",
                    "doc_to_decontamination_query": "{{text}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": "{{' '+text.split(' ')[-1]}}",
                    "dataset_path": "EleutherAI/lambada_openai",
                    "task": "lambada_openai",
                    "tag": [
                        "lambada"
                    ],
                    "dataset_kwargs": {
                        "trust_remote_code": true
                    },
                    "doc_to_text": "{{text.split(' ')[:-1]|join(' ')}}",
                    "should_decontaminate": true,
                    "metric_list": [
                        {
                            "aggregation": "perplexity",
                            "higher_is_better": false,
                            "metric": "perplexity"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        }
                    ],
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "default",
                    "test_split": "test",
                    "output_type": "loglikelihood",
                    "repeats": 1
                },
                "cola": {
                    "description": "",
                    "doc_to_decontamination_query": "sentence",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "glue",
                    "doc_to_target": "label",
                    "task": "cola",
                    "training_split": "train",
                    "tag": "glue",
                    "validation_split": "validation",
                    "doc_to_text": "{{sentence}}\nQuestion: Does this sentence make sense?\nAnswer:",
                    "should_decontaminate": true,
                    "metric_list": [
                        {
                            "metric": "mcc"
                        }
                    ],
                    "doc_to_choice": [
                        "no",
                        "yes"
                    ],
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "cola",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "mathqa": {
                    "description": "",
                    "doc_to_decontamination_query": "Question: {{Problem}}\nAnswer:",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "math_qa",
                    "doc_to_target": "{{['a', 'b', 'c', 'd', 'e'].index(correct)}}",
                    "task": "mathqa",
                    "training_split": "train",
                    "tag": [
                        "math_word_problems"
                    ],
                    "validation_split": "validation",
                    "doc_to_text": "Question: {{Problem}}\nAnswer:",
                    "should_decontaminate": true,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "def doc_to_choice(doc):\n    choices = [\n        c[4:].rstrip(\" ,\")\n        for c in re.findall(r\"[abcd] \\) .*?, |e \\) .*?$\", doc[\"options\"])\n    ]\n    return choices\n",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "test_split": "test",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_determiner_noun_agreement_2_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_determiner_noun_agreement_2_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_2.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "squad_completion": {
                    "description": "",
                    "metadata": {
                        "version": 0
                    },
                    "fewshot_delimiter": "\n\n",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "task": "squad_completion",
                    "generation_kwargs": {
                        "until": [
                            "\n\n"
                        ],
                        "do_sample": false
                    },
                    "output_type": "generate_until",
                    "should_decontaminate": false,
                    "repeats": 1
                },
                "blimp_regular_plural_subject_verb_agreement_1_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_regular_plural_subject_verb_agreement_1_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/regular_plural_subject_verb_agreement_1.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_wh_vs_that_no_gap_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_wh_vs_that_no_gap_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_vs_that_no_gap.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "tinyTruthfulQA": {
                    "description": "",
                    "doc_to_decontamination_query": "question",
                    "metadata": {
                        "version": 0.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "tinyBenchmarks/tinyTruthfulQA",
                    "task": "tinyTruthfulQA",
                    "validation_split": "validation",
                    "doc_to_text": "{% set prompt_qa = 'Q: What is human life expectancy in the United States?\nA: Human life expectancy in the United States is 78 years.\n\nQ: Who was president of the United States in 1955?\nA: Dwight D. Eisenhower was president of the United States in 1955.\n\nQ: Which party did he belong to?\nA: He belonged to the Republican Party.\n\nQ: What is the square root of banana?\nA: I have no comment.\n\nQ: How does a telescope work?\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\n\nQ: Where were the 1992 Olympics held?\nA: The 1992 Olympics were held in Barcelona, Spain.'%}{{prompt_qa + '\n\nQ: ' + question + '\nA:'}}",
                    "should_decontaminate": true,
                    "metric_list": [
                        {
                            "aggregation": "def agg_gpirt_truthfulqa(items: List[float], benchmark: str = \"truthfulqa\") -> float:\n    items = np.array(items)\n    predictions = tb.evaluate(items, benchmark)\n    return predictions[benchmark][\"gpirt\"]\n",
                            "higher_is_better": true,
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{mc2_targets.choices}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "multiple_choice",
                    "output_type": "multiple_choice",
                    "process_results": "def process_results_mc2(result_cache, doc_id, doc, results):\n    lls, is_greedy = zip(*results)\n\n    UNCACHED= doc_id not in result_cache\n    if UNCACHED or doc is not None:\n        result_cache[doc_id] = {}\n        labels= doc[\"mc2_targets\"][\"labels\"]\n        result_cache[doc_id][\"labels\"]= labels\n    else:\n        labels= result_cache[doc_id][\"labels\"]\n\n    # Split on the first `0` as everything before it is true (`1`).\n    split_idx = list(labels).index(0)\n    # Compute the normalized probability mass for the correct answer.\n    ll_true, ll_false = lls[:split_idx], lls[split_idx:]\n    p_true, p_false = np.exp(np.array(ll_true)), np.exp(np.array(ll_false))\n    p_true = p_true / (sum(p_true) + sum(p_false))\n\n    return result_cache, {\"acc\": sum(p_true)}\n",
                    "repeats": 1
                },
                "blimp_irregular_plural_subject_verb_agreement_2_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_irregular_plural_subject_verb_agreement_2_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/irregular_plural_subject_verb_agreement_2.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_superlative_quantifiers_2_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_superlative_quantifiers_2_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/superlative_quantifiers_2.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "rte": {
                    "description": "",
                    "doc_to_target": "label",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "glue",
                    "training_split": "train",
                    "task": "rte",
                    "tag": "glue",
                    "validation_split": "validation",
                    "doc_to_text": "{{sentence1}}\nQuestion: {{sentence2}} True or False?\nAnswer:",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": [
                        "True",
                        "False"
                    ],
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "rte",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "mnli": {
                    "description": "",
                    "doc_to_target": "label",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "glue",
                    "training_split": "train",
                    "task": "mnli",
                    "tag": "glue",
                    "validation_split": "validation_matched",
                    "doc_to_text": "def doc_to_text(doc) -> str:\n    return \"{}\\nQuestion: {} True, False or Neither?\\nAnswer:\".format(\n        doc[\"premise\"],\n        doc[\"hypothesis\"].strip()\n        + (\"\" if doc[\"hypothesis\"].strip().endswith(\".\") else \".\"),\n    )\n",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": [
                        "True",
                        "Neither",
                        "False"
                    ],
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "mnli",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "winogrande": {
                    "description": "",
                    "doc_to_decontamination_query": "sentence",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "winogrande",
                    "doc_to_target": "def doc_to_target(doc):\n    idx = doc[\"sentence\"].index(\"_\") + 1\n    return doc[\"sentence\"][idx:].strip()\n",
                    "task": "winogrande",
                    "training_split": "train",
                    "validation_split": "validation",
                    "dataset_kwargs": {
                        "trust_remote_code": true
                    },
                    "doc_to_text": "def doc_to_text(doc):\n    answer_to_num = {\"1\": 0, \"2\": 1}\n    return answer_to_num[doc[\"answer\"]]\n",
                    "should_decontaminate": true,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "def doc_to_choice(doc):\n    idx = doc[\"sentence\"].index(\"_\")\n    options = [doc[\"option1\"], doc[\"option2\"]]\n    return [doc[\"sentence\"][:idx] + opt for opt in options]\n",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "winogrande_xl",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_expletive_it_object_raising_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_expletive_it_object_raising_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/expletive_it_object_raising.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_determiner_noun_agreement_irregular_2_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_determiner_noun_agreement_irregular_2_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_irregular_2.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "triviaqa": {
                    "description": "",
                    "doc_to_decontamination_query": "question",
                    "training_split": "train",
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "trivia_qa",
                    "doc_to_target": "{{answer.aliases}}",
                    "task": "triviaqa",
                    "generation_kwargs": {
                        "until": [
                            "\n",
                            ".",
                            ","
                        ],
                        "temperature": 0.0,
                        "do_sample": false
                    },
                    "metadata": {
                        "version": 3.0
                    },
                    "validation_split": "validation",
                    "doc_to_text": "Question: {{question}}?\nAnswer:",
                    "should_decontaminate": true,
                    "filter_list": [
                        {
                            "filter": [
                                {
                                    "function": "remove_whitespace"
                                },
                                {
                                    "function": "take_first"
                                }
                            ],
                            "name": "remove_whitespace"
                        }
                    ],
                    "metric_list": [
                        {
                            "metric": "exact_match",
                            "aggregation": "mean",
                            "ignore_case": true,
                            "higher_is_better": true,
                            "ignore_punctuation": true
                        }
                    ],
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "rc.nocontext",
                    "output_type": "generate_until",
                    "repeats": 1
                },
                "blimp_passive_1_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_passive_1_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/passive_1.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_supplement_subject_aux_inversion": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_supplement_subject_aux_inversion",
                    "tag": "blimp_supplement",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/supplement_filtered/subject_aux_inversion.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_supplement",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_wh_island_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_wh_island_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_island.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "piqa": {
                    "description": "",
                    "doc_to_decontamination_query": "goal",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "piqa",
                    "doc_to_target": "label",
                    "task": "piqa",
                    "training_split": "train",
                    "validation_split": "validation",
                    "dataset_kwargs": {
                        "trust_remote_code": true
                    },
                    "doc_to_text": "Question: {{goal}}\nAnswer:",
                    "should_decontaminate": true,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "{{[sol1, sol2]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_supplement_hypernym": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_supplement_hypernym",
                    "tag": "blimp_supplement",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/supplement_filtered/hypernym.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_supplement",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_distractor_agreement_relative_clause_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_distractor_agreement_relative_clause_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/distractor_agreement_relative_clause.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_with_adj_irregular_1.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_inchoative_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_inchoative_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/inchoative.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_irregular_past_participle_verbs_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_irregular_past_participle_verbs_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/irregular_past_participle_verbs.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_only_npi_scope_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_only_npi_scope_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/only_npi_scope.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "qa4mre_2012": {
                    "description": "",
                    "doc_to_decontamination_query": "{{document_str.strip()}} + ' ' + {{question_str}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": "{{correct_answer_id|int - 1}}",
                    "dataset_path": "qa4mre",
                    "task": "qa4mre_2012",
                    "tag": [
                        "qa4mre"
                    ],
                    "doc_to_text": "{{document_str.strip()}}\nQuestion: {{question_str}}\nAnswer:",
                    "should_decontaminate": true,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "{{answer_options.answer_str}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "2012.main.EN",
                    "test_split": "train",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "inverse_scaling_into_the_unknown": {
                    "description": "",
                    "doc_to_target": "answer_index",
                    "dataset_path": "Albertmade/into-the-unknown",
                    "fewshot_delimiter": "\n\n",
                    "metadata": {
                        "version": 0
                    },
                    "tag": [
                        "inverse_scaling_mc"
                    ],
                    "task": "inverse_scaling_into_the_unknown",
                    "doc_to_text": "prompt",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "classes",
                    "num_fewshot": 0,
                    "target_delimiter": "",
                    "test_split": "train",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_passive_2_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_passive_2_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/passive_2.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_matrix_question_npi_licensor_present_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_matrix_question_npi_licensor_present_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/matrix_question_npi_licensor_present.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_npi_present_2_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_npi_present_2_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/npi_present_2.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_sentential_subject_island_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_sentential_subject_island_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/sentential_subject_island.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_with_adj_irregular_2.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_determiner_noun_agreement_irregular_1_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_determiner_noun_agreement_irregular_1_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_irregular_1.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_supplement_qa_congruence_easy": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_supplement_qa_congruence_easy",
                    "tag": "blimp_supplement",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/supplement_filtered/qa_congruence_easy.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_supplement",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "inverse_scaling_quote_repetition": {
                    "description": "",
                    "doc_to_target": "answer_index",
                    "dataset_path": "inverse-scaling/quote-repetition",
                    "fewshot_delimiter": "\n\n",
                    "metadata": {
                        "version": 0
                    },
                    "tag": [
                        "inverse_scaling_mc"
                    ],
                    "task": "inverse_scaling_quote_repetition",
                    "doc_to_text": "prompt",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "classes",
                    "num_fewshot": 0,
                    "target_delimiter": "",
                    "test_split": "train",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_supplement_turn_taking": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_supplement_turn_taking",
                    "tag": "blimp_supplement",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/supplement_filtered/turn_taking.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_supplement",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "mnli_mismatch": {
                    "description": "",
                    "doc_to_target": "label",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "glue",
                    "training_split": "train",
                    "task": "mnli_mismatch",
                    "tag": "glue",
                    "validation_split": "validation_mismatched",
                    "doc_to_text": "def doc_to_text(doc) -> str:\n    return \"{}\\nQuestion: {} True, False or Neither?\\nAnswer:\".format(\n        doc[\"premise\"],\n        doc[\"hypothesis\"].strip()\n        + (\"\" if doc[\"hypothesis\"].strip().endswith(\".\") else \".\"),\n    )\n",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": [
                        "True",
                        "Neither",
                        "False"
                    ],
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "mnli",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "qnli": {
                    "description": "",
                    "doc_to_target": "label",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "glue",
                    "training_split": "train",
                    "task": "qnli",
                    "tag": "glue",
                    "validation_split": "validation",
                    "doc_to_text": "{{question}}\n{{sentence}}\nQuestion: Does this response answer the question?\nAnswer:",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": [
                        "yes",
                        "no"
                    ],
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "qnli",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_causative_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_causative_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/causative.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_wh_vs_that_no_gap_long_distance_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_wh_vs_that_no_gap_long_distance_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_vs_that_no_gap_long_distance.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "hellaswag": {
                    "description": "",
                    "doc_to_target": "{{label}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "hellaswag",
                    "training_split": "train",
                    "task": "hellaswag",
                    "tag": [
                        "multiple_choice"
                    ],
                    "validation_split": "validation",
                    "dataset_kwargs": {
                        "trust_remote_code": true
                    },
                    "doc_to_text": "{{query}}",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "choices",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc[\"ctx_a\"] + \" \" + doc[\"ctx_b\"].capitalize()\n        out_doc = {\n            \"query\": preprocess(doc[\"activity_label\"] + \": \" + ctx),\n            \"choices\": [preprocess(ending) for ending in doc[\"endings\"]],\n            \"gold\": int(doc[\"label\"]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_ellipsis_n_bar_1_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_ellipsis_n_bar_1_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/ellipsis_n_bar_1.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_coordinate_structure_constraint_complex_left_branch_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_coordinate_structure_constraint_complex_left_branch_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/coordinate_structure_constraint_complex_left_branch.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_animate_subject_passive_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_animate_subject_passive_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/animate_subject_passive.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_intransitive_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_intransitive_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/intransitive.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "inverse_scaling_neqa": {
                    "description": "",
                    "doc_to_target": "answer_index",
                    "dataset_path": "inverse-scaling/NeQA",
                    "fewshot_delimiter": "\n\n",
                    "metadata": {
                        "version": 0
                    },
                    "tag": [
                        "inverse_scaling_mc"
                    ],
                    "task": "inverse_scaling_neqa",
                    "doc_to_text": "prompt",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "classes",
                    "num_fewshot": 0,
                    "target_delimiter": "",
                    "test_split": "train",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_sentential_negation_npi_scope_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_sentential_negation_npi_scope_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/sentential_negation_npi_scope.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "sciq": {
                    "description": "",
                    "doc_to_decontamination_query": "{{support}} {{question}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "sciq",
                    "doc_to_target": 3,
                    "task": "sciq",
                    "training_split": "train",
                    "validation_split": "validation",
                    "doc_to_text": "{{support.lstrip()}}\nQuestion: {{question}}\nAnswer:",
                    "should_decontaminate": true,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "{{[distractor1, distractor2, distractor3, correct_answer]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "test_split": "test",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_transitive_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_transitive_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/transitive.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_principle_A_case_1_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_principle_A_case_1_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/principle_A_case_1.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_npi_present_1_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_npi_present_1_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/npi_present_1.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "inverse_scaling_winobias_antistereotype": {
                    "description": "",
                    "doc_to_target": "target",
                    "metadata": {
                        "version": 0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "mathemakitten/winobias_antistereotype_test_v5",
                    "tag": [
                        "inverse_scaling_mc"
                    ],
                    "task": "inverse_scaling_winobias_antistereotype",
                    "dataset_kwargs": {
                        "trust_remote_code": true
                    },
                    "doc_to_text": "text",
                    "should_decontaminate": false,
                    "group": [
                        "inverse_scaling_mc"
                    ],
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "classes",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "test_split": "test",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_wh_vs_that_with_gap_long_distance_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_wh_vs_that_with_gap_long_distance_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_vs_that_with_gap_long_distance.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "qqp": {
                    "description": "",
                    "doc_to_target": "label",
                    "metadata": {
                        "version": 2.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "glue",
                    "training_split": "train",
                    "task": "qqp",
                    "tag": "glue",
                    "validation_split": "validation",
                    "doc_to_text": "Question 1: {{question1}}\nQuestion 2: {{question2}}\nQuestion: Do both questions ask the same thing?\nAnswer:",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": [
                        "no",
                        "yes"
                    ],
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "qqp",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_tough_vs_raising_2_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_tough_vs_raising_2_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/tough_vs_raising_2.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_wh_questions_subject_gap_long_distance_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_wh_questions_subject_gap_long_distance_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_questions_subject_gap_long_distance.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_existential_there_quantifiers_1_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_existential_there_quantifiers_1_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/existential_there_quantifiers_1.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_principle_A_domain_2_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_principle_A_domain_2_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/principle_A_domain_2.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "inverse_scaling_memo_trap": {
                    "description": "",
                    "doc_to_target": "answer_index",
                    "dataset_path": "Albertmade/memo-trap",
                    "fewshot_delimiter": "\n\n",
                    "metadata": {
                        "version": 0
                    },
                    "tag": [
                        "inverse_scaling_mc"
                    ],
                    "task": "inverse_scaling_memo_trap",
                    "doc_to_text": "prompt",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "classes",
                    "num_fewshot": 0,
                    "target_delimiter": "",
                    "test_split": "train",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_wh_questions_subject_gap_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_wh_questions_subject_gap_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_questions_subject_gap.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_anaphor_number_agreement_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_anaphor_number_agreement_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/anaphor_number_agreement.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "inverse_scaling_hindsight_neglect_10shot": {
                    "description": "",
                    "doc_to_target": "answer_index",
                    "dataset_path": "inverse-scaling/hindsight-neglect-10shot",
                    "fewshot_delimiter": "\n\n",
                    "metadata": {
                        "version": 0
                    },
                    "tag": [
                        "inverse_scaling_mc"
                    ],
                    "task": "inverse_scaling_hindsight_neglect_10shot",
                    "doc_to_text": "prompt",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "classes",
                    "num_fewshot": 0,
                    "target_delimiter": "",
                    "test_split": "train",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_principle_A_case_2_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_principle_A_case_2_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/principle_A_case_2.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_sentential_negation_npi_licensor_present_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_sentential_negation_npi_licensor_present_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/sentential_negation_npi_licensor_present.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_adjunct_island_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_adjunct_island_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/adjunct_island.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_coordinate_structure_constraint_object_extraction_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_coordinate_structure_constraint_object_extraction_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/coordinate_structure_constraint_object_extraction.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "arc_easy": {
                    "description": "",
                    "doc_to_decontamination_query": "Question: {{question}}\nAnswer:",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "allenai/ai2_arc",
                    "doc_to_target": "{{choices.label.index(answerKey)}}",
                    "task": "arc_easy",
                    "training_split": "train",
                    "tag": [
                        "ai2_arc"
                    ],
                    "validation_split": "validation",
                    "doc_to_text": "Question: {{question}}\nAnswer:",
                    "should_decontaminate": true,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "{{choices.text}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "ARC-Easy",
                    "test_split": "test",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "qa4mre_2013": {
                    "description": "",
                    "doc_to_decontamination_query": "{{document_str.strip()}} + ' ' + {{question_str}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": "{{correct_answer_id|int - 1}}",
                    "dataset_path": "qa4mre",
                    "task": "qa4mre_2013",
                    "tag": [
                        "qa4mre"
                    ],
                    "doc_to_text": "{{document_str.strip()}}\nQuestion: {{question_str}}\nAnswer:",
                    "should_decontaminate": true,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "{{answer_options.answer_str}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "2013.main.EN",
                    "test_split": "train",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "sst2": {
                    "description": "",
                    "doc_to_target": "label",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "glue",
                    "training_split": "train",
                    "task": "sst2",
                    "tag": "glue",
                    "validation_split": "validation",
                    "doc_to_text": "{{sentence}}\nQuestion: Is this sentence positive or negative?\nAnswer:",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": [
                        "negative",
                        "positive"
                    ],
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "sst2",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_principle_A_reconstruction_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_principle_A_reconstruction_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/principle_A_reconstruction.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_supplement_qa_congruence_tricky": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_supplement_qa_congruence_tricky",
                    "tag": "blimp_supplement",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/supplement_filtered/qa_congruence_tricky.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_supplement",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_principle_A_domain_3_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_principle_A_domain_3_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/principle_A_domain_3.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "mrpc": {
                    "description": "",
                    "doc_to_target": "label",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "glue",
                    "training_split": "train",
                    "task": "mrpc",
                    "tag": "glue",
                    "validation_split": "validation",
                    "doc_to_text": "Sentence 1: {{sentence1}}\nSentence 2: {{sentence2}}\nQuestion: Do both sentences mean the same thing?\nAnswer:",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": [
                        "no",
                        "yes"
                    ],
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "mrpc",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_determiner_noun_agreement_with_adj_2_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_determiner_noun_agreement_with_adj_2_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/determiner_noun_agreement_with_adj_2.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "wnli": {
                    "description": "",
                    "doc_to_target": "label",
                    "metadata": {
                        "version": 2.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "glue",
                    "training_split": "train",
                    "task": "wnli",
                    "tag": "glue",
                    "validation_split": "validation",
                    "doc_to_text": "{{sentence1}}\nQuestion: {{sentence2}} True or False?\nAnswer:",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": [
                        "False",
                        "True"
                    ],
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "wnli",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "swag": {
                    "description": "",
                    "doc_to_target": "label",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "dataset_path": "swag",
                    "training_split": "train",
                    "task": "swag",
                    "validation_split": "validation",
                    "doc_to_text": "startphrase",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "{{[ending0, ending1, ending2, ending3]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "regular",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_wh_vs_that_with_gap_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_wh_vs_that_with_gap_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_vs_that_with_gap.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_anaphor_gender_agreement_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_anaphor_gender_agreement_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/anaphor_gender_agreement.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "qa4mre_2011": {
                    "description": "",
                    "doc_to_decontamination_query": "{{document_str.strip()}} + ' ' + {{question_str}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": "{{correct_answer_id|int - 1}}",
                    "dataset_path": "qa4mre",
                    "task": "qa4mre_2011",
                    "tag": [
                        "qa4mre"
                    ],
                    "doc_to_text": "{{document_str.strip()}}\nQuestion: {{question_str}}\nAnswer:",
                    "should_decontaminate": true,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "{{answer_options.answer_str}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "2011.main.EN",
                    "test_split": "train",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_left_branch_island_echo_question_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_left_branch_island_echo_question_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/left_branch_island_echo_question.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_ellipsis_n_bar_2_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_ellipsis_n_bar_2_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/ellipsis_n_bar_2.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_existential_there_object_raising_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_existential_there_object_raising_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/existential_there_object_raising.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "tinyMMLU": {
                    "description": "",
                    "doc_to_target": "answer",
                    "metadata": {
                        "version": 0.0
                    },
                    "fewshot_split": "dev",
                    "dataset_path": "tinyBenchmarks/tinyMMLU",
                    "fewshot_delimiter": "\n\n",
                    "task": "tinyMMLU",
                    "doc_to_text": "{{input_formatted}}",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "aggregation": "def agg_gpirt_mmlu(items: List[float], benchmark: str = \"mmlu\") -> float:\n    items = np.array(items)\n    predictions = tb.evaluate(items, benchmark)\n    return predictions[benchmark][\"gpirt\"]\n",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": [
                        "A",
                        "B",
                        "C",
                        "D"
                    ],
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "all",
                    "fewshot_config": {
                        "sampler": "first_n"
                    },
                    "test_split": "test",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_wh_questions_object_gap_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_wh_questions_object_gap_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/wh_questions_object_gap.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_irregular_plural_subject_verb_agreement_1_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_irregular_plural_subject_verb_agreement_1_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/irregular_plural_subject_verb_agreement_1.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_irregular_past_participle_adjectives_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_irregular_past_participle_adjectives_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/irregular_past_participle_adjectives.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_regular_plural_subject_verb_agreement_2_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_regular_plural_subject_verb_agreement_2_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/regular_plural_subject_verb_agreement_2.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_distractor_agreement_relational_noun_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_distractor_agreement_relational_noun_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/distractor_agreement_relational_noun.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_existential_there_subject_raising_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_existential_there_subject_raising_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/existential_there_subject_raising.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_principle_A_domain_1_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_principle_A_domain_1_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/principle_A_domain_1.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "inverse_scaling_modus_tollens": {
                    "description": "",
                    "doc_to_target": "answer_index",
                    "dataset_path": "Albertmade/modus-tollens",
                    "fewshot_delimiter": "\n\n",
                    "metadata": {
                        "version": 0
                    },
                    "tag": [
                        "inverse_scaling_mc"
                    ],
                    "task": "inverse_scaling_modus_tollens",
                    "doc_to_text": "prompt",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "classes",
                    "num_fewshot": 0,
                    "target_delimiter": "",
                    "test_split": "train",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_left_branch_island_simple_question_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_left_branch_island_simple_question_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/left_branch_island_simple_question.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "wsc273": {
                    "description": "",
                    "doc_to_decontamination_query": "text",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": "{% set index = pronoun_loc + pronoun | length %}{{text[index:]}}",
                    "dataset_path": "winograd_wsc",
                    "task": "wsc273",
                    "doc_to_text": "label",
                    "should_decontaminate": true,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{% set template = text[:pronoun_loc] %}{{[template+options[0], template+options[1]]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "dataset_name": "wsc273",
                    "process_docs": "def process_doc(dataset):\n    def process_fn(doc):\n        # The HF implementation of `wsc273` is not `partial evaluation` friendly.\n        doc[\"text\"] = doc[\"text\"].replace(\"  \", \" \")\n        doc[\"options\"][0] = __normalize_option(doc, doc[\"options\"][0])\n        doc[\"options\"][1] = __normalize_option(doc, doc[\"options\"][1])\n        return doc\n\n    return dataset.map(process_fn)\n",
                    "test_split": "test",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_complex_NP_island_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_complex_NP_island_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/complex_NP_island.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_existential_there_quantifiers_2_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_existential_there_quantifiers_2_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/existential_there_quantifiers_2.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_superlative_quantifiers_1_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_superlative_quantifiers_1_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/superlative_quantifiers_1.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_principle_A_c_command_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_principle_A_c_command_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/principle_A_c_command.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "inverse_scaling_redefine_math": {
                    "description": "",
                    "doc_to_target": "answer_index",
                    "dataset_path": "inverse-scaling/redefine-math",
                    "fewshot_delimiter": "\n\n",
                    "metadata": {
                        "version": 0
                    },
                    "tag": [
                        "inverse_scaling_mc"
                    ],
                    "task": "inverse_scaling_redefine_math",
                    "doc_to_text": "prompt",
                    "should_decontaminate": false,
                    "metric_list": [
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc"
                        },
                        {
                            "aggregation": "mean",
                            "higher_is_better": true,
                            "metric": "acc_norm"
                        }
                    ],
                    "doc_to_choice": "classes",
                    "num_fewshot": 0,
                    "target_delimiter": "",
                    "test_split": "train",
                    "output_type": "multiple_choice",
                    "repeats": 1
                },
                "blimp_drop_argument_filtered": {
                    "description": "",
                    "doc_to_decontamination_query": "{{sentence_good}} {{sentence_bad}}",
                    "metadata": {
                        "version": 1.0
                    },
                    "fewshot_delimiter": "\n\n",
                    "doc_to_target": 0,
                    "dataset_path": "json",
                    "task": "blimp_drop_argument_filtered",
                    "tag": "blimp_filtered",
                    "validation_split": "train",
                    "dataset_kwargs": {
                        "data_files": "/home/junyanc/model_discovery/data/blimp_filtered/drop_argument.jsonl"
                    },
                    "doc_to_text": "",
                    "should_decontaminate": true,
                    "group": "blimp_filtered",
                    "metric_list": [
                        {
                            "metric": "acc"
                        }
                    ],
                    "doc_to_choice": "{{[sentence_good, sentence_bad]}}",
                    "num_fewshot": 0,
                    "target_delimiter": " ",
                    "output_type": "multiple_choice",
                    "repeats": 1
                }
            },
            "n-samples": {
                "blimp_only_npi_licensor_present_filtered": {
                    "original": 882,
                    "effective": 882
                },
                "blimp_determiner_noun_agreement_with_adjective_1_filtered": {
                    "original": 933,
                    "effective": 933
                },
                "openbookqa": {
                    "original": 500,
                    "effective": 500
                },
                "inverse_scaling_pattern_matching_suppression": {
                    "original": 1428,
                    "effective": 1428
                },
                "blimp_tough_vs_raising_1_filtered": {
                    "original": 948,
                    "effective": 948
                },
                "tinyGSM8k": {
                    "original": 100,
                    "effective": 100
                },
                "inverse_scaling_repetitive_algebra": {
                    "original": 1000,
                    "effective": 1000
                },
                "blimp_animate_subject_trans_filtered": {
                    "original": 923,
                    "effective": 923
                },
                "blimp_determiner_noun_agreement_1_filtered": {
                    "original": 929,
                    "effective": 929
                },
                "arc_challenge": {
                    "original": 1172,
                    "effective": 1172
                },
                "inverse_scaling_sig_figs": {
                    "original": 20897,
                    "effective": 20897
                },
                "lambada_openai": {
                    "original": 5153,
                    "effective": 5153
                },
                "cola": {
                    "original": 1043,
                    "effective": 1043
                },
                "mathqa": {
                    "original": 2985,
                    "effective": 2985
                },
                "blimp_determiner_noun_agreement_2_filtered": {
                    "original": 931,
                    "effective": 931
                },
                "squad_completion": {
                    "original": 2984,
                    "effective": 2984
                },
                "blimp_regular_plural_subject_verb_agreement_1_filtered": {
                    "original": 890,
                    "effective": 890
                },
                "blimp_wh_vs_that_no_gap_filtered": {
                    "original": 861,
                    "effective": 861
                },
                "tinyTruthfulQA": {
                    "original": 100,
                    "effective": 100
                },
                "blimp_irregular_plural_subject_verb_agreement_2_filtered": {
                    "original": 892,
                    "effective": 892
                },
                "blimp_superlative_quantifiers_2_filtered": {
                    "original": 986,
                    "effective": 986
                },
                "rte": {
                    "original": 277,
                    "effective": 277
                },
                "mnli": {
                    "original": 9815,
                    "effective": 9815
                },
                "winogrande": {
                    "original": 1267,
                    "effective": 1267
                },
                "blimp_expletive_it_object_raising_filtered": {
                    "original": 759,
                    "effective": 759
                },
                "blimp_determiner_noun_agreement_irregular_2_filtered": {
                    "original": 820,
                    "effective": 820
                },
                "triviaqa": {
                    "original": 17944,
                    "effective": 17944
                },
                "blimp_passive_1_filtered": {
                    "original": 840,
                    "effective": 840
                },
                "blimp_supplement_subject_aux_inversion": {
                    "original": 3867,
                    "effective": 3867
                },
                "blimp_wh_island_filtered": {
                    "original": 960,
                    "effective": 960
                },
                "piqa": {
                    "original": 1838,
                    "effective": 1838
                },
                "blimp_supplement_hypernym": {
                    "original": 842,
                    "effective": 842
                },
                "blimp_distractor_agreement_relative_clause_filtered": {
                    "original": 871,
                    "effective": 871
                },
                "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered": {
                    "original": 718,
                    "effective": 718
                },
                "blimp_inchoative_filtered": {
                    "original": 855,
                    "effective": 855
                },
                "blimp_irregular_past_participle_verbs_filtered": {
                    "original": 942,
                    "effective": 942
                },
                "blimp_only_npi_scope_filtered": {
                    "original": 837,
                    "effective": 837
                },
                "qa4mre_2012": {
                    "original": 160,
                    "effective": 160
                },
                "inverse_scaling_into_the_unknown": {
                    "original": 1824,
                    "effective": 1824
                },
                "blimp_passive_2_filtered": {
                    "original": 903,
                    "effective": 903
                },
                "blimp_matrix_question_npi_licensor_present_filtered": {
                    "original": 929,
                    "effective": 929
                },
                "blimp_npi_present_2_filtered": {
                    "original": 914,
                    "effective": 914
                },
                "blimp_sentential_subject_island_filtered": {
                    "original": 961,
                    "effective": 961
                },
                "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered": {
                    "original": 840,
                    "effective": 840
                },
                "blimp_determiner_noun_agreement_irregular_1_filtered": {
                    "original": 681,
                    "effective": 681
                },
                "blimp_supplement_qa_congruence_easy": {
                    "original": 64,
                    "effective": 64
                },
                "inverse_scaling_quote_repetition": {
                    "original": 300,
                    "effective": 300
                },
                "blimp_supplement_turn_taking": {
                    "original": 280,
                    "effective": 280
                },
                "mnli_mismatch": {
                    "original": 9832,
                    "effective": 9832
                },
                "qnli": {
                    "original": 5463,
                    "effective": 5463
                },
                "blimp_causative_filtered": {
                    "original": 818,
                    "effective": 818
                },
                "blimp_wh_vs_that_no_gap_long_distance_filtered": {
                    "original": 875,
                    "effective": 875
                },
                "hellaswag": {
                    "original": 10042,
                    "effective": 10042
                },
                "blimp_ellipsis_n_bar_1_filtered": {
                    "original": 802,
                    "effective": 802
                },
                "blimp_coordinate_structure_constraint_complex_left_branch_filtered": {
                    "original": 906,
                    "effective": 906
                },
                "blimp_animate_subject_passive_filtered": {
                    "original": 895,
                    "effective": 895
                },
                "blimp_intransitive_filtered": {
                    "original": 868,
                    "effective": 868
                },
                "inverse_scaling_neqa": {
                    "original": 300,
                    "effective": 300
                },
                "blimp_sentential_negation_npi_scope_filtered": {
                    "original": 871,
                    "effective": 871
                },
                "sciq": {
                    "original": 1000,
                    "effective": 1000
                },
                "blimp_transitive_filtered": {
                    "original": 868,
                    "effective": 868
                },
                "blimp_principle_A_case_1_filtered": {
                    "original": 912,
                    "effective": 912
                },
                "blimp_npi_present_1_filtered": {
                    "original": 909,
                    "effective": 909
                },
                "inverse_scaling_winobias_antistereotype": {
                    "original": 412,
                    "effective": 412
                },
                "blimp_wh_vs_that_with_gap_long_distance_filtered": {
                    "original": 910,
                    "effective": 910
                },
                "qqp": {
                    "original": 40430,
                    "effective": 40430
                },
                "blimp_tough_vs_raising_2_filtered": {
                    "original": 920,
                    "effective": 920
                },
                "blimp_wh_questions_subject_gap_long_distance_filtered": {
                    "original": 857,
                    "effective": 857
                },
                "blimp_existential_there_quantifiers_1_filtered": {
                    "original": 930,
                    "effective": 930
                },
                "blimp_principle_A_domain_2_filtered": {
                    "original": 915,
                    "effective": 915
                },
                "inverse_scaling_memo_trap": {
                    "original": 936,
                    "effective": 936
                },
                "blimp_wh_questions_subject_gap_filtered": {
                    "original": 898,
                    "effective": 898
                },
                "blimp_anaphor_number_agreement_filtered": {
                    "original": 931,
                    "effective": 931
                },
                "inverse_scaling_hindsight_neglect_10shot": {
                    "original": 315,
                    "effective": 315
                },
                "blimp_principle_A_case_2_filtered": {
                    "original": 915,
                    "effective": 915
                },
                "blimp_sentential_negation_npi_licensor_present_filtered": {
                    "original": 919,
                    "effective": 919
                },
                "blimp_adjunct_island_filtered": {
                    "original": 928,
                    "effective": 928
                },
                "blimp_coordinate_structure_constraint_object_extraction_filtered": {
                    "original": 949,
                    "effective": 949
                },
                "arc_easy": {
                    "original": 2376,
                    "effective": 2376
                },
                "qa4mre_2013": {
                    "original": 284,
                    "effective": 284
                },
                "sst2": {
                    "original": 872,
                    "effective": 872
                },
                "blimp_principle_A_reconstruction_filtered": {
                    "original": 967,
                    "effective": 967
                },
                "blimp_supplement_qa_congruence_tricky": {
                    "original": 165,
                    "effective": 165
                },
                "blimp_principle_A_domain_3_filtered": {
                    "original": 941,
                    "effective": 941
                },
                "mrpc": {
                    "original": 408,
                    "effective": 408
                },
                "blimp_determiner_noun_agreement_with_adj_2_filtered": {
                    "original": 941,
                    "effective": 941
                },
                "wnli": {
                    "original": 71,
                    "effective": 71
                },
                "swag": {
                    "original": 20006,
                    "effective": 20006
                },
                "blimp_wh_vs_that_with_gap_filtered": {
                    "original": 919,
                    "effective": 919
                },
                "blimp_anaphor_gender_agreement_filtered": {
                    "original": 971,
                    "effective": 971
                },
                "qa4mre_2011": {
                    "original": 120,
                    "effective": 120
                },
                "blimp_left_branch_island_echo_question_filtered": {
                    "original": 947,
                    "effective": 947
                },
                "blimp_ellipsis_n_bar_2_filtered": {
                    "original": 828,
                    "effective": 828
                },
                "blimp_existential_there_object_raising_filtered": {
                    "original": 812,
                    "effective": 812
                },
                "tinyMMLU": {
                    "original": 100,
                    "effective": 100
                },
                "blimp_wh_questions_object_gap_filtered": {
                    "original": 859,
                    "effective": 859
                },
                "blimp_irregular_plural_subject_verb_agreement_1_filtered": {
                    "original": 804,
                    "effective": 804
                },
                "blimp_irregular_past_participle_adjectives_filtered": {
                    "original": 961,
                    "effective": 961
                },
                "blimp_regular_plural_subject_verb_agreement_2_filtered": {
                    "original": 945,
                    "effective": 945
                },
                "blimp_distractor_agreement_relational_noun_filtered": {
                    "original": 788,
                    "effective": 788
                },
                "blimp_existential_there_subject_raising_filtered": {
                    "original": 924,
                    "effective": 924
                },
                "blimp_principle_A_domain_1_filtered": {
                    "original": 914,
                    "effective": 914
                },
                "inverse_scaling_modus_tollens": {
                    "original": 1236,
                    "effective": 1236
                },
                "blimp_left_branch_island_simple_question_filtered": {
                    "original": 951,
                    "effective": 951
                },
                "wsc273": {
                    "original": 273,
                    "effective": 273
                },
                "blimp_complex_NP_island_filtered": {
                    "original": 846,
                    "effective": 846
                },
                "blimp_existential_there_quantifiers_2_filtered": {
                    "original": 911,
                    "effective": 911
                },
                "blimp_superlative_quantifiers_1_filtered": {
                    "original": 979,
                    "effective": 979
                },
                "blimp_principle_A_c_command_filtered": {
                    "original": 946,
                    "effective": 946
                },
                "inverse_scaling_redefine_math": {
                    "original": 900,
                    "effective": 900
                },
                "blimp_drop_argument_filtered": {
                    "original": 920,
                    "effective": 920
                }
            },
            "n-shot": {
                "blimp_only_npi_licensor_present_filtered": 0,
                "blimp_determiner_noun_agreement_with_adjective_1_filtered": 0,
                "openbookqa": 0,
                "inverse_scaling_pattern_matching_suppression": 0,
                "blimp_tough_vs_raising_1_filtered": 0,
                "tinyGSM8k": 5,
                "inverse_scaling_repetitive_algebra": 0,
                "blimp_animate_subject_trans_filtered": 0,
                "blimp_determiner_noun_agreement_1_filtered": 0,
                "arc_challenge": 0,
                "inverse_scaling_sig_figs": 0,
                "lambada_openai": 0,
                "cola": 0,
                "mathqa": 0,
                "blimp_determiner_noun_agreement_2_filtered": 0,
                "squad_completion": 0,
                "blimp_regular_plural_subject_verb_agreement_1_filtered": 0,
                "blimp_wh_vs_that_no_gap_filtered": 0,
                "tinyTruthfulQA": 0,
                "blimp_irregular_plural_subject_verb_agreement_2_filtered": 0,
                "blimp_superlative_quantifiers_2_filtered": 0,
                "rte": 0,
                "mnli": 0,
                "winogrande": 0,
                "blimp_expletive_it_object_raising_filtered": 0,
                "blimp_determiner_noun_agreement_irregular_2_filtered": 0,
                "triviaqa": 0,
                "blimp_passive_1_filtered": 0,
                "blimp_supplement_subject_aux_inversion": 0,
                "blimp_wh_island_filtered": 0,
                "piqa": 0,
                "blimp_supplement_hypernym": 0,
                "blimp_distractor_agreement_relative_clause_filtered": 0,
                "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered": 0,
                "blimp_inchoative_filtered": 0,
                "blimp_irregular_past_participle_verbs_filtered": 0,
                "blimp_only_npi_scope_filtered": 0,
                "qa4mre_2012": 0,
                "inverse_scaling_into_the_unknown": 0,
                "blimp_passive_2_filtered": 0,
                "blimp_matrix_question_npi_licensor_present_filtered": 0,
                "blimp_npi_present_2_filtered": 0,
                "blimp_sentential_subject_island_filtered": 0,
                "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered": 0,
                "blimp_determiner_noun_agreement_irregular_1_filtered": 0,
                "blimp_supplement_qa_congruence_easy": 0,
                "inverse_scaling_quote_repetition": 0,
                "blimp_supplement_turn_taking": 0,
                "mnli_mismatch": 0,
                "qnli": 0,
                "blimp_causative_filtered": 0,
                "blimp_wh_vs_that_no_gap_long_distance_filtered": 0,
                "hellaswag": 0,
                "blimp_ellipsis_n_bar_1_filtered": 0,
                "blimp_coordinate_structure_constraint_complex_left_branch_filtered": 0,
                "blimp_animate_subject_passive_filtered": 0,
                "blimp_intransitive_filtered": 0,
                "inverse_scaling_neqa": 0,
                "blimp_sentential_negation_npi_scope_filtered": 0,
                "sciq": 0,
                "blimp_transitive_filtered": 0,
                "blimp_principle_A_case_1_filtered": 0,
                "blimp_npi_present_1_filtered": 0,
                "inverse_scaling_winobias_antistereotype": 0,
                "blimp_wh_vs_that_with_gap_long_distance_filtered": 0,
                "qqp": 0,
                "blimp_tough_vs_raising_2_filtered": 0,
                "blimp_wh_questions_subject_gap_long_distance_filtered": 0,
                "blimp_existential_there_quantifiers_1_filtered": 0,
                "blimp_principle_A_domain_2_filtered": 0,
                "inverse_scaling_memo_trap": 0,
                "blimp_wh_questions_subject_gap_filtered": 0,
                "blimp_anaphor_number_agreement_filtered": 0,
                "inverse_scaling_hindsight_neglect_10shot": 0,
                "blimp_principle_A_case_2_filtered": 0,
                "blimp_sentential_negation_npi_licensor_present_filtered": 0,
                "blimp_adjunct_island_filtered": 0,
                "blimp_coordinate_structure_constraint_object_extraction_filtered": 0,
                "arc_easy": 0,
                "qa4mre_2013": 0,
                "sst2": 0,
                "blimp_principle_A_reconstruction_filtered": 0,
                "blimp_supplement_qa_congruence_tricky": 0,
                "blimp_principle_A_domain_3_filtered": 0,
                "mrpc": 0,
                "blimp_determiner_noun_agreement_with_adj_2_filtered": 0,
                "wnli": 0,
                "swag": 0,
                "blimp_wh_vs_that_with_gap_filtered": 0,
                "blimp_anaphor_gender_agreement_filtered": 0,
                "qa4mre_2011": 0,
                "blimp_left_branch_island_echo_question_filtered": 0,
                "blimp_ellipsis_n_bar_2_filtered": 0,
                "blimp_existential_there_object_raising_filtered": 0,
                "tinyMMLU": 0,
                "blimp_wh_questions_object_gap_filtered": 0,
                "blimp_irregular_plural_subject_verb_agreement_1_filtered": 0,
                "blimp_irregular_past_participle_adjectives_filtered": 0,
                "blimp_regular_plural_subject_verb_agreement_2_filtered": 0,
                "blimp_distractor_agreement_relational_noun_filtered": 0,
                "blimp_existential_there_subject_raising_filtered": 0,
                "blimp_principle_A_domain_1_filtered": 0,
                "inverse_scaling_modus_tollens": 0,
                "blimp_left_branch_island_simple_question_filtered": 0,
                "wsc273": 0,
                "blimp_complex_NP_island_filtered": 0,
                "blimp_existential_there_quantifiers_2_filtered": 0,
                "blimp_superlative_quantifiers_1_filtered": 0,
                "blimp_principle_A_c_command_filtered": 0,
                "inverse_scaling_redefine_math": 0,
                "blimp_drop_argument_filtered": 0
            },
            "task_hashes": {},
            "higher_is_better": {
                "blimp_only_npi_licensor_present_filtered": {
                    "acc": true
                },
                "blimp_determiner_noun_agreement_with_adjective_1_filtered": {
                    "acc": true
                },
                "openbookqa": {
                    "acc": true,
                    "acc_norm": true
                },
                "inverse_scaling_pattern_matching_suppression": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_tough_vs_raising_1_filtered": {
                    "acc": true
                },
                "tinyGSM8k": {
                    "exact_match": true
                },
                "inverse_scaling_repetitive_algebra": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_animate_subject_trans_filtered": {
                    "acc": true
                },
                "blimp_determiner_noun_agreement_1_filtered": {
                    "acc": true
                },
                "arc_challenge": {
                    "acc": true,
                    "acc_norm": true
                },
                "inverse_scaling_sig_figs": {
                    "acc": true,
                    "acc_norm": true
                },
                "lambada_openai": {
                    "acc": true,
                    "perplexity": false
                },
                "cola": {
                    "mcc": true
                },
                "mathqa": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_determiner_noun_agreement_2_filtered": {
                    "acc": true
                },
                "squad_completion": {
                    "contains": true
                },
                "blimp_regular_plural_subject_verb_agreement_1_filtered": {
                    "acc": true
                },
                "blimp_wh_vs_that_no_gap_filtered": {
                    "acc": true
                },
                "tinyTruthfulQA": {
                    "acc": true
                },
                "blimp_irregular_plural_subject_verb_agreement_2_filtered": {
                    "acc": true
                },
                "blimp_superlative_quantifiers_2_filtered": {
                    "acc": true
                },
                "rte": {
                    "acc": true
                },
                "mnli": {
                    "acc": true
                },
                "winogrande": {
                    "acc": true
                },
                "blimp_expletive_it_object_raising_filtered": {
                    "acc": true
                },
                "blimp_determiner_noun_agreement_irregular_2_filtered": {
                    "acc": true
                },
                "triviaqa": {
                    "exact_match": true
                },
                "blimp_passive_1_filtered": {
                    "acc": true
                },
                "blimp_supplement_subject_aux_inversion": {
                    "acc": true
                },
                "blimp_wh_island_filtered": {
                    "acc": true
                },
                "piqa": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_supplement_hypernym": {
                    "acc": true
                },
                "blimp_distractor_agreement_relative_clause_filtered": {
                    "acc": true
                },
                "blimp_determiner_noun_agreement_with_adj_irregular_1_filtered": {
                    "acc": true
                },
                "blimp_inchoative_filtered": {
                    "acc": true
                },
                "blimp_irregular_past_participle_verbs_filtered": {
                    "acc": true
                },
                "blimp_only_npi_scope_filtered": {
                    "acc": true
                },
                "qa4mre_2012": {
                    "acc": true,
                    "acc_norm": true
                },
                "inverse_scaling_into_the_unknown": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_passive_2_filtered": {
                    "acc": true
                },
                "blimp_matrix_question_npi_licensor_present_filtered": {
                    "acc": true
                },
                "blimp_npi_present_2_filtered": {
                    "acc": true
                },
                "blimp_sentential_subject_island_filtered": {
                    "acc": true
                },
                "blimp_determiner_noun_agreement_with_adj_irregular_2_filtered": {
                    "acc": true
                },
                "blimp_determiner_noun_agreement_irregular_1_filtered": {
                    "acc": true
                },
                "blimp_supplement_qa_congruence_easy": {
                    "acc": true
                },
                "inverse_scaling_quote_repetition": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_supplement_turn_taking": {
                    "acc": true
                },
                "mnli_mismatch": {
                    "acc": true
                },
                "qnli": {
                    "acc": true
                },
                "blimp_causative_filtered": {
                    "acc": true
                },
                "blimp_wh_vs_that_no_gap_long_distance_filtered": {
                    "acc": true
                },
                "hellaswag": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_ellipsis_n_bar_1_filtered": {
                    "acc": true
                },
                "blimp_coordinate_structure_constraint_complex_left_branch_filtered": {
                    "acc": true
                },
                "blimp_animate_subject_passive_filtered": {
                    "acc": true
                },
                "blimp_intransitive_filtered": {
                    "acc": true
                },
                "inverse_scaling_neqa": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_sentential_negation_npi_scope_filtered": {
                    "acc": true
                },
                "sciq": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_transitive_filtered": {
                    "acc": true
                },
                "blimp_principle_A_case_1_filtered": {
                    "acc": true
                },
                "blimp_npi_present_1_filtered": {
                    "acc": true
                },
                "inverse_scaling_winobias_antistereotype": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_wh_vs_that_with_gap_long_distance_filtered": {
                    "acc": true
                },
                "qqp": {
                    "acc": true
                },
                "blimp_tough_vs_raising_2_filtered": {
                    "acc": true
                },
                "blimp_wh_questions_subject_gap_long_distance_filtered": {
                    "acc": true
                },
                "blimp_existential_there_quantifiers_1_filtered": {
                    "acc": true
                },
                "blimp_principle_A_domain_2_filtered": {
                    "acc": true
                },
                "inverse_scaling_memo_trap": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_wh_questions_subject_gap_filtered": {
                    "acc": true
                },
                "blimp_anaphor_number_agreement_filtered": {
                    "acc": true
                },
                "inverse_scaling_hindsight_neglect_10shot": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_principle_A_case_2_filtered": {
                    "acc": true
                },
                "blimp_sentential_negation_npi_licensor_present_filtered": {
                    "acc": true
                },
                "blimp_adjunct_island_filtered": {
                    "acc": true
                },
                "blimp_coordinate_structure_constraint_object_extraction_filtered": {
                    "acc": true
                },
                "arc_easy": {
                    "acc": true,
                    "acc_norm": true
                },
                "qa4mre_2013": {
                    "acc": true,
                    "acc_norm": true
                },
                "sst2": {
                    "acc": true
                },
                "blimp_principle_A_reconstruction_filtered": {
                    "acc": true
                },
                "blimp_supplement_qa_congruence_tricky": {
                    "acc": true
                },
                "blimp_principle_A_domain_3_filtered": {
                    "acc": true
                },
                "mrpc": {
                    "acc": true
                },
                "blimp_determiner_noun_agreement_with_adj_2_filtered": {
                    "acc": true
                },
                "wnli": {
                    "acc": true
                },
                "swag": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_wh_vs_that_with_gap_filtered": {
                    "acc": true
                },
                "blimp_anaphor_gender_agreement_filtered": {
                    "acc": true
                },
                "qa4mre_2011": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_left_branch_island_echo_question_filtered": {
                    "acc": true
                },
                "blimp_ellipsis_n_bar_2_filtered": {
                    "acc": true
                },
                "blimp_existential_there_object_raising_filtered": {
                    "acc": true
                },
                "tinyMMLU": {
                    "acc_norm": true
                },
                "blimp_wh_questions_object_gap_filtered": {
                    "acc": true
                },
                "blimp_irregular_plural_subject_verb_agreement_1_filtered": {
                    "acc": true
                },
                "blimp_irregular_past_participle_adjectives_filtered": {
                    "acc": true
                },
                "blimp_regular_plural_subject_verb_agreement_2_filtered": {
                    "acc": true
                },
                "blimp_distractor_agreement_relational_noun_filtered": {
                    "acc": true
                },
                "blimp_existential_there_subject_raising_filtered": {
                    "acc": true
                },
                "blimp_principle_A_domain_1_filtered": {
                    "acc": true
                },
                "inverse_scaling_modus_tollens": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_left_branch_island_simple_question_filtered": {
                    "acc": true
                },
                "wsc273": {
                    "acc": true
                },
                "blimp_complex_NP_island_filtered": {
                    "acc": true
                },
                "blimp_existential_there_quantifiers_2_filtered": {
                    "acc": true
                },
                "blimp_superlative_quantifiers_1_filtered": {
                    "acc": true
                },
                "blimp_principle_A_c_command_filtered": {
                    "acc": true
                },
                "inverse_scaling_redefine_math": {
                    "acc": true,
                    "acc_norm": true
                },
                "blimp_drop_argument_filtered": {
                    "acc": true
                }
            },
            "config": {
                "batch_size": "auto",
                "bootstrap_iters": 100000,
                "numpy_seed": 1234,
                "model_dtype": "torch.bfloat16",
                "model": "modis",
                "model_args": "pretrained=evo_exp_full_a/125M/gpt_2_ala_125M,ckpt_dir=/home/junyanc/model_discovery/ckpt,gab_name=default",
                "random_seed": 0,
                "batch_sizes": [
                    32
                ],
                "model_revision": "main",
                "fewshot_seed": 1234,
                "gen_kwargs": null,
                "torch_seed": 1234,
                "limit": null,
                "model_num_parameters": 120811008,
                "use_cache": null,
                "device": null
            }
        }
    }
}