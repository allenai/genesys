{
    "implementation": {
        "review": null,
        "root": "MetaTTT",
        "proposal": "Self-attention performs well in long context but has quadratic complexity. Existing RNN layers have linear complexity, but their performance in long context is limited by the expressive power of their hidden state. We propose a new class of sequence modeling layers with linear complexity and an expressive hidden state. The key idea is to make the hidden state a machine learning model itself, and the update rule a step of self-supervised learning. Since the hidden state is updated by training even on test sequences, our layers are called Test-Time Training (TTT) layers. We consider two instantiations: TTT-Linear and TTT-MLP, whose hidden state is a linear model and a two-layer MLP respectively. We evaluate our instantiations at the scale of 125M to 1.3B parameters, comparing with a strong Transformer and Mamba, a modern RNN. Both TTT-Linear and TTT-MLP match or exceed the baselines. Similar to Transformer, they can keep reducing perplexity by conditioning on more tokens, while Mamba cannot after 16k context. With preliminary systems optimization, TTT-Linear is already faster than Transformer at 8k context and matches Mamba in wall-clock time. TTT-MLP still faces challenges in memory I/O, but shows larger potential in long context, pointing to a promising direction for future research.",
        "units": {
            "TTTLinear": {
                "review": null,
                "requirements": null,
                "reuse_from": null,
                "desc": "\n",
                "gautests": {
                    "test_tttlinear": "@gau_test\ndef test_TTTLinear_test_tttlinear(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    tttlinear = TTTLinear(embed_dim, block_loc, kwarg_all, device=device,\n        dtype=dtype, **kwarg_all)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    Z = {}\n    y, Z_ = tttlinear(x, **Z)\n    assert y.shape == (1, 100, 128)\n"
                },
                "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nfrom typing import Any, Dict, Optional, Tuple, Union\nimport torch.nn.functional as F\nimport torch.utils.checkpoint\nfrom torch.utils._pytree import tree_map\nfrom transformers.utils import logging\nlogger = logging.get_logger(__name__)\n\n\nclass TTTLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, num_attention_heads=4,\n        scan_checkpoint_group_size=4, conv_kernel=4, mini_batch_size=16,\n        rope_theta=10000.0, ttt_base_lr=1.0, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.num_heads = num_attention_heads\n        self.width = embed_dim\n        self.hidden_size = embed_dim\n        self.head_dim = self.width // self.num_heads\n        self.mini_batch_size = mini_batch_size\n        self.rope_theta = rope_theta\n        self.ttt_base_lr = ttt_base_lr\n        token_idx = 1.0 / torch.arange(1, self.mini_batch_size + 1, **self.\n            factory_kwargs)\n        self.register_buffer('token_idx', token_idx, persistent=False)\n        self.learnable_token_idx = nn.Parameter(torch.zeros((self.\n            mini_batch_size,), **self.factory_kwargs))\n        self.conv_kernel = conv_kernel\n        self._init_qkvo_proj()\n        self.rope_theta = self.rope_theta\n        kwargs['dim'] = self.head_dim\n        kwargs['max_position_embeddings'] = self.mini_batch_size\n        kwargs['base'] = self.rope_theta\n        self.rotary_emb = RotaryEmbedding(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self._init_ttt_lr_gate()\n        self._init_ttt_ln()\n        self.post_norm = nn.LayerNorm(self.width, eps=1e-06, **self.\n            factory_kwargs)\n        self.scan_checkpoint_group_size = scan_checkpoint_group_size\n        self.W1 = nn.Parameter(torch.normal(0, 0.02, size=(self.num_heads,\n            self.head_dim, self.head_dim), **self.factory_kwargs))\n        self.b1 = nn.Parameter(torch.zeros(self.num_heads, 1, self.head_dim,\n            **self.factory_kwargs))\n\n    def rotate_half(self, x):\n        \"\"\"Rotates half the hidden dims of the input.\"\"\"\n        x1 = x[..., :x.shape[-1] // 2]\n        x2 = x[..., x.shape[-1] // 2:]\n        return torch.cat((-x2, x1), dim=-1)\n\n    def permute_qk(self, q, k):\n        bsz, num_head, seq_len, head_dim = q.shape\n        q = q.reshape(bsz, num_head, seq_len, head_dim // 2, 2).transpose(3, 4\n            ).reshape(bsz, num_head, seq_len, head_dim)\n        k = k.reshape(bsz, num_head, seq_len, head_dim // 2, 2).transpose(3, 4\n            ).reshape(bsz, num_head, seq_len, head_dim)\n        return q, k\n\n    def undo_permute_qk(self, q, k):\n        bsz, num_head, seq_len, head_dim = q.shape\n        q = q.reshape(bsz, num_head, seq_len, 2, head_dim // 2).transpose(3, 4\n            ).reshape(bsz, num_head, seq_len, head_dim)\n        k = k.reshape(bsz, num_head, seq_len, 2, head_dim // 2).transpose(3, 4\n            ).reshape(bsz, num_head, seq_len, head_dim)\n        return q, k\n\n    def _init_qkvo_proj(self):\n        self.q_proj = nn.Linear(self.width, self.num_heads * self.head_dim,\n            bias=False, **self.factory_kwargs)\n        self.k_proj = nn.Linear(self.width, self.num_heads * self.head_dim,\n            bias=False, **self.factory_kwargs)\n        self.v_proj = nn.Linear(self.width, self.num_heads * self.head_dim,\n            bias=False, **self.factory_kwargs)\n        self.o_proj = nn.Linear(self.width, self.num_heads * self.head_dim,\n            bias=False, **self.factory_kwargs)\n\n    def _init_ttt_lr_gate(self):\n        linear_weight_data = nn.Linear(self.width, 1, bias=True, **self.\n            factory_kwargs).weight.data\n        self.learnable_ttt_lr_weight = nn.Parameter(torch.stack([torch.\n            normal(0, 0.02, size=linear_weight_data.shape, **self.\n            factory_kwargs) for _ in range(self.num_heads)], dim=0))\n        linear_bias_data = nn.Linear(self.width, 1, bias=True, **self.\n            factory_kwargs).bias.data\n        self.learnable_ttt_lr_bias = nn.Parameter(torch.stack([torch.\n            zeros_like(linear_bias_data, **self.factory_kwargs) for _ in\n            range(self.num_heads)], dim=0))\n\n    def ln_fused_l2_bwd(self, x, l2_target, gamma, beta, eps=1e-06):\n        \"\"\"Batch backward for LayerNorm fused with L2 loss.\"\"\"\n        D = x.shape[-1]\n        mu = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, keepdim=True, unbiased=False)\n        std = torch.sqrt(var + eps)\n        x_hat = (x - mu) / std\n        y = gamma * x_hat + beta\n        grad_output = y - l2_target\n        grad_x_hat = grad_output * gamma\n        z = 1.0 / D * (D * grad_x_hat - grad_x_hat.sum(dim=-1, keepdim=True\n            ) - x_hat * (grad_x_hat * x_hat).sum(dim=-1, keepdim=True)) / std\n        return z\n\n    def _init_ttt_ln(self):\n        ln_weight_data = nn.LayerNorm(self.head_dim, **self.factory_kwargs\n            ).weight.data\n        self.ttt_norm_weight = nn.Parameter(torch.tile(ln_weight_data.\n            unsqueeze(0), (self.num_heads, 1)))\n        ln_bias_data = nn.LayerNorm(self.head_dim, **self.factory_kwargs\n            ).bias.data\n        self.ttt_norm_bias = nn.Parameter(torch.tile(ln_bias_data.unsqueeze\n            (0), (self.num_heads, 1)))\n\n    def get_qkv_projections(self, hidden_states):\n        XQ, XK, XV = self.q_proj(hidden_states), self.k_proj(hidden_states\n            ), self.v_proj(hidden_states)\n        return XQ, XK, XV\n\n    def _split_heads(self, hidden_states):\n        return hidden_states.reshape(hidden_states.shape[:2] + (self.\n            num_heads, self.head_dim))\n\n    def get_eta(self, X, mini_batch_size):\n        ttt_lr = torch.einsum('bnkc,hdc->bhnkd', X, self.\n            learnable_ttt_lr_weight) + self.learnable_ttt_lr_bias.reshape(1,\n            -1, 1, 1, 1)\n        ttt_lr = F.sigmoid(ttt_lr)\n        ttt_lr = ttt_lr.permute(0, 1, 2, 4, 3)\n        ttt_lr_eta = self.ttt_base_lr * ttt_lr / self.head_dim\n        token_idx = self.token_idx + self.learnable_token_idx\n        token_idx = token_idx[0:mini_batch_size]\n        token_idx = torch.clamp_min(token_idx, 0.0)\n        token_eta = torch.broadcast_to(token_idx.reshape(1, 1, 1,\n            mini_batch_size, 1), (X.shape[0], self.num_heads, X.shape[1],\n            mini_batch_size, 1))\n        return token_eta, ttt_lr_eta\n\n    def get_ttt_inputs(self, inputs, mini_batch_size):\n        XQ = inputs['XQ']\n        XK = inputs['XK']\n        XV = inputs['XV']\n        X = inputs['X']\n        B, L, C = X.shape\n        num_mini_batch = L // mini_batch_size\n        X = X.reshape(B, num_mini_batch, mini_batch_size, self.width)\n        XQ = XQ.reshape(B, self.num_heads, L // mini_batch_size,\n            mini_batch_size, self.head_dim)\n        XK = XK.reshape(B, self.num_heads, L // mini_batch_size,\n            mini_batch_size, self.head_dim)\n        XV = XV.reshape(B, self.num_heads, L // mini_batch_size,\n            mini_batch_size, self.head_dim)\n        token_eta, ttt_lr_eta = self.get_eta(X, mini_batch_size)\n        eta = token_eta * ttt_lr_eta\n        inputs = {'XQ': XQ, 'XK': XK, 'XV': XV, 'eta': eta, 'token_eta':\n            token_eta, 'ttt_lr_eta': ttt_lr_eta}\n        return inputs\n\n    def ln_fwd(self, x, gamma, beta, eps=1e-06):\n        \"\"\"Batch forward for LayerNorm.\"\"\"\n        mu = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, keepdim=True, unbiased=False)\n        std = torch.sqrt(var + eps)\n        x_hat = (x - mu) / std\n        y = gamma * x_hat + beta\n        return y\n\n    def apply_rotary_pos_emb(self, q, k, cos, sin, unsqueeze_dim=1):\n        \"\"\"Applies Rotary Position Embedding to the query and key tensors.\n\n        Args:\n            q (`torch.Tensor`): The query tensor.\n            k (`torch.Tensor`): The key tensor.\n            cos (`torch.Tensor`): The cosine part of the rotary embedding.\n            sin (`torch.Tensor`): The sine part of the rotary embedding.\n            position_ids (`torch.Tensor`, *optional*):\n                Deprecated and unused.\n            unsqueeze_dim (`int`, *optional*, defaults to 1):\n                The 'unsqueeze_dim' argument specifies the dimension along which to unsqueeze cos[position_ids] and\n                sin[position_ids] so that they can be properly broadcasted to the dimensions of q and k. For example, note\n                that cos[position_ids] and sin[position_ids] have the shape [batch_size, seq_len, head_dim]. Then, if q and\n                k have the shape [batch_size, heads, seq_len, head_dim], then setting unsqueeze_dim=1 makes\n                cos[position_ids] and sin[position_ids] broadcastable to the shapes of q and k. Similarly, if q and k have\n                the shape [batch_size, seq_len, heads, head_dim], then set unsqueeze_dim=2.\n        Returns:\n            `tuple(torch.Tensor)` comprising of the query and key tensors rotated using the Rotary Position Embedding.\n        \"\"\"\n        cos = cos.unsqueeze(unsqueeze_dim)\n        sin = sin.unsqueeze(unsqueeze_dim)\n        q_embed = q * cos + self.rotate_half(q) * sin\n        k_embed = k * cos + self.rotate_half(k) * sin\n        return q_embed, k_embed\n\n    def scan(self, f, init, xs, out, checkpoint_group=0):\n        \"\"\"Minic jax.lax.scan function.\"\"\"\n        carry = init\n        if isinstance(xs, dict):\n            num_items = len(next(iter(xs.values())))\n        else:\n            num_items = len(xs[0])\n\n        def scan_fn(carry, i_start, i_end):\n            for i in range(i_start, i_end):\n                if isinstance(xs, dict):\n                    x = {key: tensor[i] for key, tensor in xs.items()}\n                else:\n                    x = [x[i] for x in xs]\n                carry, y = f(carry, x)\n                out[i] = y\n            return carry\n        if checkpoint_group > 0:\n            ckpt_every_n = num_items // checkpoint_group\n            for k in range(0, num_items, ckpt_every_n):\n                carry = torch.utils.checkpoint.checkpoint(scan_fn, carry, k,\n                    min(k + ckpt_every_n, num_items), use_reentrant=False)\n        else:\n            carry = scan_fn(carry, 0, num_items)\n        return carry, out\n\n    def ttt(self, inputs, mini_batch_size, last_mini_batch_params_dict):\n        if mini_batch_size is None:\n            mini_batch_size = self.mini_batch_size\n        B = inputs['XV'].shape[0]\n        num_mini_batch = inputs['XV'].shape[2]\n        L = inputs['XV'].shape[2] * inputs['XV'].shape[3]\n        device = inputs['XV'].device\n        dtype = inputs['XV'].dtype\n        use_dual_form = True\n\n        def compute_mini_batch(params_dict, inputs):\n            W1_init = params_dict['W1_states']\n            b1_init = params_dict['b1_states']\n            XQ_mini_batch = inputs['XQ']\n            XV_mini_batch = inputs['XV']\n            XK_mini_batch = inputs['XK']\n            eta_mini_batch = inputs['eta']\n            token_eta_mini_batch = inputs['token_eta']\n            ttt_lr_eta_mini_batch = inputs['ttt_lr_eta']\n            X1 = XK_mini_batch\n            Z1 = X1 @ W1_init + b1_init\n            reconstruction_target = XV_mini_batch - XK_mini_batch\n            ln_weight = self.ttt_norm_weight.reshape(self.num_heads, 1,\n                self.head_dim)\n            ln_bias = self.ttt_norm_bias.reshape(self.num_heads, 1, self.\n                head_dim)\n            grad_l_wrt_Z1 = self.ln_fused_l2_bwd(Z1, reconstruction_target,\n                ln_weight, ln_bias)\n            if use_dual_form:\n                Attn1 = torch.tril(XQ_mini_batch @ X1.transpose(-2, -1))\n                b1_bar = b1_init - torch.tril(eta_mini_batch) @ grad_l_wrt_Z1\n                Z1_bar = (XQ_mini_batch @ W1_init - eta_mini_batch * Attn1 @\n                    grad_l_wrt_Z1 + b1_bar)\n                last_eta_mini_batch = eta_mini_batch[:, :, -1, :, None]\n                W1_last = W1_init - (last_eta_mini_batch * X1).transpose(-1, -2\n                    ) @ grad_l_wrt_Z1\n                b1_last = b1_init - torch.sum(last_eta_mini_batch *\n                    grad_l_wrt_Z1, dim=-2, keepdim=True)\n                grad_W1_last = torch.zeros_like(W1_last)\n                grad_b1_last = torch.zeros_like(b1_last)\n            else:\n                ttt_lr_eta_mini_batch = torch.broadcast_to(\n                    ttt_lr_eta_mini_batch, (*ttt_lr_eta_mini_batch.shape[:2\n                    ], mini_batch_size, mini_batch_size))\n                grad_W1 = torch.einsum('bhki,bhkj->bhkij', X1, grad_l_wrt_Z1)\n                grad_W1 = torch.einsum('bhnk,bhkij->bhnij', torch.tril(\n                    ttt_lr_eta_mini_batch), grad_W1)\n                grad_W1 = grad_W1 + params_dict['W1_grad'].unsqueeze(2)\n                grad_b1 = torch.einsum('bhnk,bhki->bhni', torch.tril(\n                    ttt_lr_eta_mini_batch), grad_l_wrt_Z1)\n                grad_b1 = grad_b1 + params_dict['b1_grad']\n                W1_bar = W1_init.unsqueeze(2\n                    ) - grad_W1 * token_eta_mini_batch.unsqueeze(-1)\n                b1_bar = b1_init - grad_b1 * token_eta_mini_batch\n                Z1_bar = (XQ_mini_batch.unsqueeze(3) @ W1_bar).squeeze(3\n                    ) + b1_bar\n                W1_last = W1_bar[:, :, -1]\n                b1_last = b1_bar[:, :, -1:]\n                grad_W1_last = grad_W1[:, :, -1]\n                grad_b1_last = grad_b1[:, :, -1:]\n            Z1_bar = self.ln_fwd(Z1_bar, ln_weight, ln_bias)\n            XQW_mini_batch = XQ_mini_batch + Z1_bar\n            last_param_dict = {'W1_states': W1_last, 'b1_states': b1_last,\n                'W1_grad': grad_W1_last, 'b1_grad': grad_b1_last}\n            return last_param_dict, XQW_mini_batch\n        if last_mini_batch_params_dict is not None:\n            init_params_dict = last_mini_batch_params_dict\n        else:\n            init_params_dict = {'W1_states': torch.tile(self.W1.unsqueeze(0\n                ), dims=(B, 1, 1, 1)), 'b1_states': torch.tile(self.b1.\n                unsqueeze(0), dims=(B, 1, 1, 1))}\n            init_params_dict.update(W1_grad=torch.zeros_like(\n                init_params_dict['W1_states']))\n            init_params_dict.update(b1_grad=torch.zeros_like(\n                init_params_dict['b1_states']))\n        inputs = tree_map(lambda x: x.permute(2, 0, 1, 3, 4), inputs)\n        XQW_batch = torch.empty((num_mini_batch, B, self.num_heads,\n            mini_batch_size, self.head_dim), device=device, dtype=dtype)\n        batch_params_dict, XQW_batch = self.scan(compute_mini_batch,\n            init_params_dict, inputs, XQW_batch, self.\n            scan_checkpoint_group_size if self.training else 0)\n        XQW_batch = XQW_batch.permute(1, 0, 3, 2, 4)\n        XQW_batch = XQW_batch.reshape(B, L, self.width)\n        return XQW_batch, batch_params_dict\n\n    def _forward(self, X, position_ids, **Z):\n        hidden_states = X\n        B, L = hidden_states.shape[:2]\n        reminder_len = L % self.mini_batch_size\n        num_mini_batch = L // self.mini_batch_size\n        last_mini_batch_params_dict = None\n        XQ, XK, XV = self.get_qkv_projections(hidden_states)\n        XQ = XQ.reshape(B, L, self.num_heads, self.head_dim).transpose(1, 2)\n        XK = XK.reshape(B, L, self.num_heads, self.head_dim).transpose(1, 2)\n        XV = XV.reshape(B, L, self.num_heads, self.head_dim).transpose(1, 2)\n        Z['position_ids'] = position_ids % self.mini_batch_size\n        Z['input'] = XV\n        _, Z = self.rotary_emb(X, **Z)\n        cos = Z['cos']\n        sin = Z['sin']\n        XQ, XK = self.permute_qk(XQ, XK)\n        XQ, XK = self.apply_rotary_pos_emb(XQ, XK, cos, sin)\n        XQ, XK = self.undo_permute_qk(XQ, XK)\n        output_hidden_states = []\n        if num_mini_batch > 0:\n            inputs = {'XQ': XQ[:, :, :num_mini_batch * self.mini_batch_size\n                ], 'XK': XK[:, :, :num_mini_batch * self.mini_batch_size],\n                'XV': XV[:, :, :num_mini_batch * self.mini_batch_size], 'X':\n                hidden_states[:, :num_mini_batch * self.mini_batch_size]}\n            output_mod, last_mini_batch_params_dict = self.ttt(self.\n                get_ttt_inputs(inputs, self.mini_batch_size),\n                mini_batch_size=self.mini_batch_size,\n                last_mini_batch_params_dict=last_mini_batch_params_dict)\n            output_hidden_states.append(output_mod)\n        if reminder_len > 0:\n            inputs = {'XQ': XQ[:, :, -reminder_len:], 'XK': XK[:, :, -\n                reminder_len:], 'XV': XV[:, :, -reminder_len:], 'X':\n                hidden_states[:, -reminder_len:]}\n            output_reminder, _ = self.ttt(self.get_ttt_inputs(inputs,\n                reminder_len), mini_batch_size=reminder_len,\n                last_mini_batch_params_dict=last_mini_batch_params_dict)\n            output_hidden_states.append(output_reminder)\n        output_hidden_states = torch.cat(output_hidden_states, dim=1)\n        output_hidden_states = self.post_norm(output_hidden_states)\n        output_hidden_states = self.o_proj(output_hidden_states)\n        return output_hidden_states\n\n\nCHILDREN_DECLARATIONS = [UnitDecl(unitname='RotaryEmbedding', requirements=\n    '', inputs=['X'], outputs=['cos', 'sin'])]\n",
                "rating": null,
                "spec": "{\"unitname\":\"TTTLinear\",\"document\":\"\\nTTTLinear\\n\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                "children": [
                    "RotaryEmbedding"
                ],
                "suggestions": null,
                "args": {
                    "conv_kernel": 4,
                    "rope_theta": 10000.0,
                    "mini_batch_size": 16,
                    "num_attention_heads": 4,
                    "ttt_base_lr": 1.0,
                    "scan_checkpoint_group_size": 4
                },
                "design_traces": null
            },
            "RotaryEmbedding": {
                "review": null,
                "requirements": null,
                "reuse_from": null,
                "desc": "\n",
                "gautests": {
                    "test_rotaryembedding": "@gau_test\ndef test_RotaryEmbedding_test_rotaryembedding(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    rotaryembedding = RotaryEmbedding(embed_dim, block_loc, kwarg_all,\n        device=device, dtype=dtype)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    y = rotaryembedding(x)\n    assert y.shape == (1, 100, 128)\n"
                },
                "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nfrom typing import Any, Dict, Optional, Tuple, Union\nimport torch.nn.functional as F\nfrom transformers.utils import logging\nlogger = logging.get_logger(__name__)\n\n\nclass RotaryEmbedding(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, dim=None, max_position_embeddings=16, base\n        =10000, scaling_factor=1.0, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.scaling_factor = scaling_factor\n        self.dim = dim if dim is not None else embed_dim // 4\n        self.max_position_embeddings = max_position_embeddings\n        self.base = base\n        inv_freq = 1.0 / self.base ** (torch.arange(0, self.dim, 2, dtype=\n            torch.int64).float().to(device) / self.dim)\n        self.register_buffer('inv_freq', inv_freq, persistent=False)\n\n    @torch.no_grad()\n    def _forward(self, X, input, position_ids, **Z):\n        inv_freq_expanded = self.inv_freq[None, :, None].float().expand(\n            position_ids.shape[0], -1, 1)\n        inv_freq_expanded = self.inv_freq[None, :, None].float().expand(\n            position_ids.shape[0], -1, 1)\n        position_ids_expanded = position_ids[:, None, :].float()\n        device_type = input.device.type\n        device_type = device_type if isinstance(device_type, str\n            ) and device_type != 'mps' else 'cpu'\n        with torch.autocast(device_type=device_type, enabled=False):\n            freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()\n                ).transpose(1, 2)\n            emb = torch.cat((freqs, freqs), dim=-1)\n            cos = emb.cos()\n            sin = emb.sin()\n        Z['cos'] = cos.to(**self.factory_kwargs)\n        Z['sin'] = sin.to(**self.factory_kwargs)\n        return X, Z\n\n\nCHILDREN_DECLARATIONS = []\n",
                "rating": null,
                "spec": "{\"unitname\":\"RotaryEmbedding\",\"document\":\"\\nRotaryEmbedding\\n\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                "children": [],
                "suggestions": null,
                "args": {
                    "scaling_factor": 1.0,
                    "dim": null,
                    "base": 10000,
                    "max_position_embeddings": 16
                },
                "design_traces": null
            },
            "RMSNorm": {
                "review": null,
                "requirements": null,
                "reuse_from": null,
                "desc": "\n",
                "gautests": {
                    "test_rmsnorm": "@gau_test\ndef test_RMSNorm_test_rmsnorm(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    rmsnorm = RMSNorm(embed_dim, block_loc, kwarg_all, device=device, dtype\n        =dtype, **kwarg_all)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    Z = {}\n    y, Z_ = rmsnorm(x, **Z)\n    assert y.shape == (1, 100, 128)\n"
                },
                "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import Tensor\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RMSNorm(GAUBase):\n    \"\"\"\n    Root Mean Square Layer Normalization (RMSNorm).\n\n    This layer applies a variant of layer normalization that uses only the root mean square\n    statistics, without centering. It's computationally more efficient than standard\n    layer normalization and has been shown to be effective in various NLP tasks.\n\n    Args:\n        embed_dim (int): The size of the input feature dimension.\n        block_loc (tuple): The location of this block in the model architecture.\n        kwarg_all (dict): Additional keyword arguments passed to the parent class.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The dtype of the module's parameters.\n        eps (float, optional): A small constant added to the denominator for numerical stability.\n            Default: 1e-5.\n\n    Attributes:\n        weight (nn.Parameter): Learnable scale parameter of shape (embed_dim,).\n        variance_epsilon (float): The epsilon value used in the normalization formula.\n\n    Shape:\n        - Input: (*, embed_dim)\n        - Output: (*, embed_dim) (same shape as input)\n\n    Examples:\n        >>> rmsnorm = RMSNorm(128, (0, 6), {})\n        >>> x = torch.randn(1, 100, 128)\n        >>> output = rmsnorm(x)\n        >>> print(output.shape)\n        torch.Size([1, 100, 128])\n\n    References:\n        - Paper: \"Root Mean Square Layer Normalization\" by Biao Zhang and Rico Sennrich\n          https://arxiv.org/abs/1910.07467\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, eps=1e-05, **kwargs):\n        \"\"\"If group_size is not None, we do GroupNorm with each group having group_size elements.\n        group_size=None is equivalent to group_size=hidden_size (i.e. there's only 1 group).\n        \"\"\"\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.weight = nn.Parameter(torch.ones(embed_dim, **self.factory_kwargs)\n            )\n        self.variance_epsilon = eps\n\n    def _forward(self, X, **Z):\n        input_dtype = X.dtype\n        X = X.to(torch.float32)\n        variance = X.pow(2).mean(-1, keepdim=True)\n        X = X * torch.rsqrt(variance + self.variance_epsilon)\n        return self.weight * X.to(input_dtype)\n\n\nCHILDREN_DECLARATIONS = []\n",
                "rating": null,
                "spec": "{\"unitname\":\"RMSNorm\",\"document\":\"\\n    Root Mean Square Layer Normalization (RMSNorm).\\n\\n    This layer applies a variant of layer normalization that uses only the root mean square\\n    statistics, without centering. It's computationally more efficient than standard\\n    layer normalization and has been shown to be effective in various NLP tasks.\\n\\n    Args:\\n        embed_dim (int): The size of the input feature dimension.\\n        block_loc (tuple): The location of this block in the model architecture.\\n        kwarg_all (dict): Additional keyword arguments passed to the parent class.\\n        device (torch.device, optional): The device on which to allocate the module's parameters.\\n        dtype (torch.dtype, optional): The dtype of the module's parameters.\\n        eps (float, optional): A small constant added to the denominator for numerical stability.\\n            Default: 1e-5.\\n\\n    Attributes:\\n        weight (nn.Parameter): Learnable scale parameter of shape (embed_dim,).\\n        variance_epsilon (float): The epsilon value used in the normalization formula.\\n\\n    Shape:\\n        - Input: (*, embed_dim)\\n        - Output: (*, embed_dim) (same shape as input)\\n\\n    Examples:\\n        >>> rmsnorm = RMSNorm(128, (0, 6), {})\\n        >>> x = torch.randn(1, 100, 128)\\n        >>> output = rmsnorm(x)\\n        >>> print(output.shape)\\n        torch.Size([1, 100, 128])\\n\\n    References:\\n        - Paper: \\\"Root Mean Square Layer Normalization\\\" by Biao Zhang and Rico Sennrich\\n          https://arxiv.org/abs/1910.07467\\n    \",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                "children": [],
                "suggestions": null,
                "args": {
                    "eps": 1e-05
                },
                "design_traces": null
            },
            "Conv": {
                "review": null,
                "requirements": null,
                "reuse_from": null,
                "desc": "\n",
                "gautests": {
                    "test_conv": "@gau_test\ndef test_Conv_test_conv(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    conv = Conv(embed_dim, block_loc, kwarg_all, device=device, dtype=dtype)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    y = conv(x)\n    assert y.shape == (1, 100, 128)\n"
                },
                "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nfrom typing import Any, Dict, Optional, Tuple, Union\nimport torch.nn.functional as F\nimport torch.utils.checkpoint\nfrom torch.utils._pytree import tree_map\nfrom transformers.utils import logging\nfrom transformers.activations import ACT2FN\ntry:\n    from causal_conv1d import causal_conv1d_fn, causal_conv1d_update\nexcept:\n    causal_conv1d_update, causal_conv1d_fn = None, None\nlogger = logging.get_logger(__name__)\n\n\nclass Conv(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, conv_kernel=4, rms_norm_eps=1e-06, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        kwarg_all['eps'] = rms_norm_eps\n        self.norm = RMSNorm(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.conv = nn.Conv1d(embed_dim, embed_dim, bias=True, kernel_size=\n            conv_kernel, groups=embed_dim, padding=conv_kernel - 1, **self.\n            factory_kwargs)\n\n    def __call__(self, X, **Z):\n        hidden_states = X\n        seq_len = hidden_states.shape[1]\n        hidden_states = self.norm(hidden_states, **Z)[0]\n        hidden_states = hidden_states.transpose(1, 2)\n        if causal_conv1d_fn is None:\n            hidden_states = self.conv(hidden_states)[..., :seq_len]\n        else:\n            conv_weights = self.conv.weight.view(self.conv.weight.size(0),\n                self.conv.weight.size(2))\n            hidden_states = causal_conv1d_fn(hidden_states, conv_weights,\n                self.conv.bias, activation=None)\n        hidden_states = hidden_states.transpose(1, 2)\n        return hidden_states\n\n\nCHILDREN_DECLARATIONS = [UnitDecl(unitname='RMSNorm', requirements='',\n    inputs=['X'], outputs=['Y'])]\n",
                "rating": null,
                "spec": "{\"unitname\":\"Conv\",\"document\":\"\\nConv\\n\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                "children": [
                    "RMSNorm"
                ],
                "suggestions": null,
                "args": {
                    "conv_kernel": 4,
                    "rms_norm_eps": 1e-06
                },
                "design_traces": null
            },
            "MetaTTT": {
                "review": "**Overall Assessment**:\n\n```rating 4.5```\n\n**Strengths of the Implementation**:\n\n1. **Successful Integration of Meta-Learning and Uncertainty-Aware Mechanisms**: The coder has effectively integrated meta-learning, gated mechanisms, and uncertainty-aware compression into the `MetaTTT` GAU, aligning well with the proposal's objectives. This demonstrates a solid understanding of the underlying concepts and their practical implementation.\n\n2. **Resolution of Previous Issues**: The previously identified issues regarding causality and gradient flow have been successfully addressed. The attention mechanism now includes a causal mask to enforce autoregressive properties, and gradient flow to all parameters is ensured by incorporating `W_compressed` into the computation of the output `Y`.\n\n3. **Clear and Comprehensive Documentation**: The implementation includes detailed docstrings with mathematical formulations, method explanations, and usage examples. This enhances code readability and maintainability, facilitating future development and collaboration.\n\n4. **Passing All Checks**: The implementation passes both the format and functionality checks, indicating robustness and readiness for integration into the larger model. This also reflects adherence to coding standards and best practices.\n\n**Areas for Improvement and Specific Suggestions**:\n\n1. **Optimization of Computational Efficiency**:\n\n   - **Assess Computational Overhead**: While the added components enhance functionality, they may introduce additional computational load.\n\n     **Suggestion**: Profile the model to measure the computational overhead introduced by the meta-learner, gating mechanisms, and uncertainty estimation modules. If significant, consider optimizing these components by:\n\n     - Reducing the `hidden_dim` in the meta-learner and uncertainty modules if it does not adversely affect performance.\n     - Exploring more efficient activation functions or simplifying network architectures.\n     - Utilizing techniques like parameter sharing or low-rank approximations to reduce the number of parameters.\n\n2. **Scalability to Larger Models and Longer Contexts**:\n\n   - **Evaluate Memory Usage and Performance**: Ensure that the implementation scales efficiently with increased model sizes and longer sequences.\n\n     **Suggestion**: Conduct experiments with varying sequence lengths and batch sizes to monitor memory consumption and processing time. Optimize memory usage by:\n\n     - Implementing gradient checkpointing for memory-intensive operations.\n     - Utilizing mixed-precision training if appropriate.\n     - Exploring efficient data structures or parallelization strategies.\n\n3. **Inclusion of Unit Tests and Child Declarations**:\n\n   - **Enhance Test Coverage**: Even though the functionality checks passed, adding unit tests improves robustness.\n\n     **Suggestion**: Implement unit tests for `MetaTTT` to validate its behavior under different scenarios, including edge cases. This ensures reliability and facilitates future modifications.\n\n   - **Child Declarations**:\n\n     **Suggestion**: Explicitly declare any child GAUs or confirm that `CHILDREN_DECLARATIONS` is intentionally left empty for clarity:\n\n     ```python\n     CHILDREN_DECLARATIONS = []\n     ```\n\n4. **Code Readability and Consistency**:\n\n   - **Enhance Readability**: Clear and consistent code aids understanding and future maintenance.\n\n     **Suggestion**:\n\n     - **Inline Comments**: Add comments explaining complex operations, especially in the forward pass where meta-learning and uncertainty computations occur.\n     - **Naming Conventions**: Ensure variable names are descriptive and consistent throughout the code.\n     - **Cleanup**: Remove any unused imports or redundant code to keep the codebase clean.\n\n5. **Validation of Hyperparameters**:\n\n   - **Fine-Tuning Hyperparameters**: The choice of hyperparameters such as `hidden_dim`, learning rates, and layer configurations can significantly impact performance.\n\n     **Suggestion**: Experiment with different hyperparameter settings to find the optimal balance between performance and computational efficiency. Document the rationale behind chosen values.\n\n**Comments on Innovation and Potential Impact**:\n\n- **Innovation**: The `MetaTTT` GAU represents a novel approach by integrating meta-learning and uncertainty-aware compression into the TTT framework. This enhances the model's adaptability during inference and could address challenges in long-context language modeling effectively.\n\n- **Potential Impact**: Successfully implementing these mechanisms may lead to improvements in perplexity, scalability, and efficiency, contributing to advancements in autoregressive language models. This aligns with the team's goals of outperforming existing state-of-the-art models.\n\n**Recommendations for the Coder**:\n\n1. **Performance Profiling and Optimization**:\n\n   - Use profiling tools to identify bottlenecks in computation and memory usage.\n   - Optimize tensor operations to leverage parallelism and minimize overhead.\n   - Consider the trade-off between model complexity and performance benefits.\n\n2. **Extensive Testing and Benchmarking**:\n\n   - Evaluate the model on standard benchmarks for language modeling to assess improvements in perplexity and downstream task performance.\n   - Perform ablation studies to understand the contribution of each component (meta-learning, gating mechanisms, uncertainty-aware compression) to overall performance.\n\n3. **Documentation of Findings**:\n\n   - Keep detailed records of experiments, including configurations and results.\n   - Document any insights or challenges encountered during implementation, which can be valuable for future work.\n\n4. **Future Extensions**:\n\n   - Explore integrating additional techniques such as adaptive learning rates in the meta-learner or alternative uncertainty estimation methods.\n   - Investigate the compatibility of `MetaTTT` with other architectural enhancements or larger-scale models.\n\n5. **Collaboration and Feedback**:\n\n   - Share your implementation with peers or the broader community to gather feedback.\n   - Engage in discussions about potential improvements or alternative approaches.\n\nBy continuing to refine the implementation and addressing the areas for improvement, you can enhance the robustness and scalability of the `MetaTTT` GAU. This will contribute significantly to achieving the team's objectives and advancing the field of language modeling.",
                "requirements": "N/A",
                "reuse_from": null,
                "desc": null,
                "gautests": {
                    "test_meta_ttt": "@gau_test\ndef test_MetaTTT_test_meta_ttt(device=None, dtype=None) ->None:\n    embed_dim = 64\n    batch_size = 4\n    seq_len = 16\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    Z = {}\n    meta_ttt = MetaTTT(embed_dim=embed_dim, block_loc=(0, 1), kwarg_all={},\n        device=device, dtype=dtype)\n    Y, Z_out = meta_ttt(X, **Z)\n    assert Y.shape == X.shape, f'Expected output shape {X.shape}, got {Y.shape}'\n    assert 'hidden_state' in Z_out, 'Hidden state not updated in Z'\n    assert Z_out['hidden_state'].shape == (batch_size, embed_dim\n        ), f\"Expected hidden_state shape {batch_size, embed_dim}, got {Z_out['hidden_state'].shape}\"\n    print('MetaTTT unit test passed.')\n"
                },
                "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nimport torch.nn.functional as F\n\n\nclass MetaTTT(GAUBase):\n    \"\"\"\n    MetaTTT: A Test-Time Training GAU enhanced with meta-learning, gated mechanisms, and uncertainty-aware compression.\n    \n    This class implements the MetaTTT GAU as described in the proposal. MetaTTT enhances the TTT GAU by integrating meta-learning for dynamic hidden state adaptation, gated mechanisms for selective information flow, and uncertainty-aware compression for efficient memory usage.\n    \n    **Methods:**\n    \n    - **__init__**: Initializes the MetaTTT GAU, including the meta-learner, gating mechanisms, uncertainty estimation module, and compression gate.\n    - **_forward**: Implements the forward pass, including hidden state updates, gating mechanisms, uncertainty estimation, and compression.\n    \n    **Mathematical Formulation:**\n    \n    - **Meta-Learned Hidden State Update**:\n      \\\\( W_t = M(W_{t-1}, x_t; \theta_M) \\\\)\n    - **Gated Query and Key Modulation**:\n      \\\\( Q_t' = Q_t \\\\odot \\\\sigma(W_{GQ} W_t + b_{GQ}) \\\\)\n      \\\\( K_t' = K_t \\\\odot \\\\sigma(W_{GK} W_t + b_{GK}) \\\\)\n    - **Uncertainty-Aware Compression**:\n      \\\\( C_t = \\\\sigma(W_U \\\\cdot U(W_t) + b_U) \\\\)\n      \\\\( W_t' = W_t \\\\odot C_t \\\\)\n\n    **Args:**\n        embed_dim (int): The size of the input embeddings.\n        block_loc (tuple): The location of this block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments.\n        device (torch.device, optional): The device to run the model on.\n        dtype (torch.dtype, optional): The data type for model parameters.\n        hidden_dim (int): The dimension of the hidden layer in the meta-learner. Default: 128.\n    \n    **Example:**\n        This is how you can use this function:\n    \n        meta_ttt = MetaTTT(embed_dim=768, block_loc=(0, 1), kwarg_all={})\n        X = torch.randn(32, 128, 768)\n        Y, Z = meta_ttt(X)\n    \n    **References:**\n    - Sun, Y. et al., 2024. Learning to (Learn at Test Time): RNNs with Expressive Hidden States.\n    - Other references as per the proposal.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_dim: int=128, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.meta_learner = nn.Sequential(nn.Linear(embed_dim + embed_dim,\n            hidden_dim, **self.factory_kwargs), nn.ReLU(), nn.Linear(\n            hidden_dim, embed_dim, **self.factory_kwargs))\n        self.gate_q = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.gate_k = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.uncertainty_module = nn.Sequential(nn.Linear(embed_dim,\n            hidden_dim, **self.factory_kwargs), nn.Softplus(), nn.Linear(\n            hidden_dim, 1, **self.factory_kwargs))\n        self.compress_gate = nn.Linear(1, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.q_proj = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        self.k_proj = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        self.v_proj = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        self.o_proj = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n\n    def _forward(self, X, **Z):\n        B, L, D = X.shape\n        W_prev = Z.get('hidden_state', torch.zeros(B, D, device=X.device,\n            dtype=X.dtype))\n        W_prev_expanded = W_prev.unsqueeze(1).expand(-1, L, -1)\n        meta_input = torch.cat([W_prev_expanded, X], dim=-1)\n        W_new = self.meta_learner(meta_input)\n        W_new_last = W_new[:, -1, :]\n        uncertainty = self.uncertainty_module(W_new)\n        compress_factor = torch.sigmoid(self.compress_gate(uncertainty))\n        W_compressed = W_new * compress_factor\n        W_compressed_last = W_compressed[:, -1, :]\n        Z['hidden_state'] = W_compressed_last\n        X_enhanced = X + W_compressed\n        Q = self.q_proj(X_enhanced)\n        K = self.k_proj(X_enhanced)\n        V = self.v_proj(X_enhanced)\n        G_Q = torch.sigmoid(self.gate_q(W_new))\n        G_K = torch.sigmoid(self.gate_k(W_new))\n        Q = Q * G_Q\n        K = K * G_K\n        attn_scores = torch.bmm(Q, K.transpose(1, 2)) / self.embed_dim ** 0.5\n        mask = torch.tril(torch.ones(L, L, device=attn_scores.device)\n            ).unsqueeze(0)\n        attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n        attn_weights = torch.softmax(attn_scores, dim=-1)\n        attn_output = torch.bmm(attn_weights, V)\n        Y = self.o_proj(attn_output)\n        return Y, Z\n",
                "rating": 4.5,
                "spec": "{\"unitname\":\"MetaTTT\",\"document\":\"MetaTTT: A Test-Time Training GAU enhanced with meta-learning, gated mechanisms, and uncertainty-aware compression.\\n\\nThis class implements the MetaTTT GAU as described in the proposal. MetaTTT enhances the TTT GAU by integrating meta-learning for dynamic hidden state adaptation, gated mechanisms for selective information flow, and uncertainty-aware compression for efficient memory usage.\\n\\n**Methods:**\\n\\n- **__init__**: Initializes the MetaTTT GAU, including the meta-learner, gating mechanisms, uncertainty estimation module, and compression gate.\\n- **_forward**: Implements the forward pass, including hidden state updates, gating mechanisms, uncertainty estimation, and compression.\\n\\n**Mathematical Formulation:**\\n\\n- **Meta-Learned Hidden State Update**:\\n  \\\\( W_t = M(W_{t-1}, x_t;  heta_M) \\\\)\\n- **Gated Query and Key Modulation**:\\n  \\\\( Q_t' = Q_t \\\\odot \\\\sigma(W_{GQ} W_t + b_{GQ}) \\\\)\\n  \\\\( K_t' = K_t \\\\odot \\\\sigma(W_{GK} W_t + b_{GK}) \\\\)\\n- **Uncertainty-Aware Compression**:\\n  \\\\( C_t = \\\\sigma(W_U \\\\cdot U(W_t) + b_U) \\\\)\\n  \\\\( W_t' = W_t \\\\odot C_t \\\\)\\n\\n**Args:**\\n    embed_dim (int): The size of the input embeddings.\\n    block_loc (tuple): The location of this block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments.\\n    device (torch.device, optional): The device to run the model on.\\n    dtype (torch.dtype, optional): The data type for model parameters.\\n    hidden_dim (int): The dimension of the hidden layer in the meta-learner. Default: 128.\\n\\n**Example:**\\n    This is how you can use this function:\\n\\n    meta_ttt = MetaTTT(embed_dim=768, block_loc=(0, 1), kwarg_all={})\\n    X = torch.randn(32, 128, 768)\\n    Y, Z = meta_ttt(X)\\n\\n**References:**\\n- Sun, Y. et al., 2024. Learning to (Learn at Test Time): RNNs with Expressive Hidden States.\\n- Other references as per the proposal.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                "children": [],
                "suggestions": null,
                "args": {
                    "hidden_dim": 128
                },
                "design_traces": null
            },
            "SwiGluMLP": {
                "review": null,
                "requirements": null,
                "reuse_from": null,
                "desc": "\n",
                "gautests": {
                    "test_swiglumlp": "@gau_test\ndef test_SwiGluMLP_test_swiglumlp(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    swiglumlp = SwiGluMLP(embed_dim, block_loc, kwarg_all, device=device,\n        dtype=dtype)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    y = swiglumlp(x)\n    assert y.shape == (1, 100, 128)\n"
                },
                "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nfrom typing import Any, Dict, Optional, Tuple, Union\nimport torch.nn.functional as F\nfrom transformers.utils import logging\nfrom transformers.activations import ACT2FN\nlogger = logging.get_logger(__name__)\n\n\nclass SwiGluMLP(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, intermediate_size=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.intermediate_size = (intermediate_size if intermediate_size is not\n            None else int(embed_dim * 2.5))\n        self.gate_proj = nn.Linear(self.hidden_size, self.intermediate_size,\n            bias=False, **self.factory_kwargs)\n        self.up_proj = nn.Linear(self.hidden_size, self.intermediate_size,\n            bias=False, **self.factory_kwargs)\n        self.down_proj = nn.Linear(self.intermediate_size, self.hidden_size,\n            bias=False, **self.factory_kwargs)\n        self.act_fn = ACT2FN['silu']\n\n    def _forward(self, X, **Z):\n        down_proj = self.down_proj(self.act_fn(self.gate_proj(X)) * self.\n            up_proj(X))\n        return down_proj\n\n\nCHILDREN_DECLARATIONS = []\n",
                "rating": null,
                "spec": "{\"unitname\":\"SwiGluMLP\",\"document\":\"\\nSwiGluMLP\\n\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                "children": [],
                "suggestions": null,
                "args": {
                    "intermediate_size": null
                },
                "design_traces": null
            }
        },
        "rating": null,
        "declares": {
            "MetaTTT": "{\"unitname\":\"MetaTTT\",\"requirements\":\"N/A\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}"
        },
        "proposal_traces": [],
        "suggestions": null,
        "name": "metattt"
    },
    "status": "implemented",
    "history": [
        {
            "tree": {
                "review": null,
                "root": "MetaTTT",
                "proposal": "Self-attention performs well in long context but has quadratic complexity. Existing RNN layers have linear complexity, but their performance in long context is limited by the expressive power of their hidden state. We propose a new class of sequence modeling layers with linear complexity and an expressive hidden state. The key idea is to make the hidden state a machine learning model itself, and the update rule a step of self-supervised learning. Since the hidden state is updated by training even on test sequences, our layers are called Test-Time Training (TTT) layers. We consider two instantiations: TTT-Linear and TTT-MLP, whose hidden state is a linear model and a two-layer MLP respectively. We evaluate our instantiations at the scale of 125M to 1.3B parameters, comparing with a strong Transformer and Mamba, a modern RNN. Both TTT-Linear and TTT-MLP match or exceed the baselines. Similar to Transformer, they can keep reducing perplexity by conditioning on more tokens, while Mamba cannot after 16k context. With preliminary systems optimization, TTT-Linear is already faster than Transformer at 8k context and matches Mamba in wall-clock time. TTT-MLP still faces challenges in memory I/O, but shows larger potential in long context, pointing to a promising direction for future research.",
                "units": {
                    "TTTLinear": {
                        "review": null,
                        "requirements": null,
                        "reuse_from": null,
                        "desc": "\n",
                        "gautests": {
                            "test_tttlinear": "@gau_test\ndef test_TTTLinear_test_tttlinear(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    tttlinear = TTTLinear(embed_dim, block_loc, kwarg_all, device=device,\n        dtype=dtype, **kwarg_all)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    Z = {}\n    y, Z_ = tttlinear(x, **Z)\n    assert y.shape == (1, 100, 128)\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nfrom typing import Any, Dict, Optional, Tuple, Union\nimport torch.nn.functional as F\nimport torch.utils.checkpoint\nfrom torch.utils._pytree import tree_map\nfrom transformers.utils import logging\nlogger = logging.get_logger(__name__)\n\n\nclass TTTLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, num_attention_heads=4,\n        scan_checkpoint_group_size=4, conv_kernel=4, mini_batch_size=16,\n        rope_theta=10000.0, ttt_base_lr=1.0, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.num_heads = num_attention_heads\n        self.width = embed_dim\n        self.hidden_size = embed_dim\n        self.head_dim = self.width // self.num_heads\n        self.mini_batch_size = mini_batch_size\n        self.rope_theta = rope_theta\n        self.ttt_base_lr = ttt_base_lr\n        token_idx = 1.0 / torch.arange(1, self.mini_batch_size + 1, **self.\n            factory_kwargs)\n        self.register_buffer('token_idx', token_idx, persistent=False)\n        self.learnable_token_idx = nn.Parameter(torch.zeros((self.\n            mini_batch_size,), **self.factory_kwargs))\n        self.conv_kernel = conv_kernel\n        self._init_qkvo_proj()\n        self.rope_theta = self.rope_theta\n        kwargs['dim'] = self.head_dim\n        kwargs['max_position_embeddings'] = self.mini_batch_size\n        kwargs['base'] = self.rope_theta\n        self.rotary_emb = RotaryEmbedding(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self._init_ttt_lr_gate()\n        self._init_ttt_ln()\n        self.post_norm = nn.LayerNorm(self.width, eps=1e-06, **self.\n            factory_kwargs)\n        self.scan_checkpoint_group_size = scan_checkpoint_group_size\n        self.W1 = nn.Parameter(torch.normal(0, 0.02, size=(self.num_heads,\n            self.head_dim, self.head_dim), **self.factory_kwargs))\n        self.b1 = nn.Parameter(torch.zeros(self.num_heads, 1, self.head_dim,\n            **self.factory_kwargs))\n\n    def rotate_half(self, x):\n        \"\"\"Rotates half the hidden dims of the input.\"\"\"\n        x1 = x[..., :x.shape[-1] // 2]\n        x2 = x[..., x.shape[-1] // 2:]\n        return torch.cat((-x2, x1), dim=-1)\n\n    def permute_qk(self, q, k):\n        bsz, num_head, seq_len, head_dim = q.shape\n        q = q.reshape(bsz, num_head, seq_len, head_dim // 2, 2).transpose(3, 4\n            ).reshape(bsz, num_head, seq_len, head_dim)\n        k = k.reshape(bsz, num_head, seq_len, head_dim // 2, 2).transpose(3, 4\n            ).reshape(bsz, num_head, seq_len, head_dim)\n        return q, k\n\n    def undo_permute_qk(self, q, k):\n        bsz, num_head, seq_len, head_dim = q.shape\n        q = q.reshape(bsz, num_head, seq_len, 2, head_dim // 2).transpose(3, 4\n            ).reshape(bsz, num_head, seq_len, head_dim)\n        k = k.reshape(bsz, num_head, seq_len, 2, head_dim // 2).transpose(3, 4\n            ).reshape(bsz, num_head, seq_len, head_dim)\n        return q, k\n\n    def _init_qkvo_proj(self):\n        self.q_proj = nn.Linear(self.width, self.num_heads * self.head_dim,\n            bias=False, **self.factory_kwargs)\n        self.k_proj = nn.Linear(self.width, self.num_heads * self.head_dim,\n            bias=False, **self.factory_kwargs)\n        self.v_proj = nn.Linear(self.width, self.num_heads * self.head_dim,\n            bias=False, **self.factory_kwargs)\n        self.o_proj = nn.Linear(self.width, self.num_heads * self.head_dim,\n            bias=False, **self.factory_kwargs)\n\n    def _init_ttt_lr_gate(self):\n        linear_weight_data = nn.Linear(self.width, 1, bias=True, **self.\n            factory_kwargs).weight.data\n        self.learnable_ttt_lr_weight = nn.Parameter(torch.stack([torch.\n            normal(0, 0.02, size=linear_weight_data.shape, **self.\n            factory_kwargs) for _ in range(self.num_heads)], dim=0))\n        linear_bias_data = nn.Linear(self.width, 1, bias=True, **self.\n            factory_kwargs).bias.data\n        self.learnable_ttt_lr_bias = nn.Parameter(torch.stack([torch.\n            zeros_like(linear_bias_data, **self.factory_kwargs) for _ in\n            range(self.num_heads)], dim=0))\n\n    def ln_fused_l2_bwd(self, x, l2_target, gamma, beta, eps=1e-06):\n        \"\"\"Batch backward for LayerNorm fused with L2 loss.\"\"\"\n        D = x.shape[-1]\n        mu = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, keepdim=True, unbiased=False)\n        std = torch.sqrt(var + eps)\n        x_hat = (x - mu) / std\n        y = gamma * x_hat + beta\n        grad_output = y - l2_target\n        grad_x_hat = grad_output * gamma\n        z = 1.0 / D * (D * grad_x_hat - grad_x_hat.sum(dim=-1, keepdim=True\n            ) - x_hat * (grad_x_hat * x_hat).sum(dim=-1, keepdim=True)) / std\n        return z\n\n    def _init_ttt_ln(self):\n        ln_weight_data = nn.LayerNorm(self.head_dim, **self.factory_kwargs\n            ).weight.data\n        self.ttt_norm_weight = nn.Parameter(torch.tile(ln_weight_data.\n            unsqueeze(0), (self.num_heads, 1)))\n        ln_bias_data = nn.LayerNorm(self.head_dim, **self.factory_kwargs\n            ).bias.data\n        self.ttt_norm_bias = nn.Parameter(torch.tile(ln_bias_data.unsqueeze\n            (0), (self.num_heads, 1)))\n\n    def get_qkv_projections(self, hidden_states):\n        XQ, XK, XV = self.q_proj(hidden_states), self.k_proj(hidden_states\n            ), self.v_proj(hidden_states)\n        return XQ, XK, XV\n\n    def _split_heads(self, hidden_states):\n        return hidden_states.reshape(hidden_states.shape[:2] + (self.\n            num_heads, self.head_dim))\n\n    def get_eta(self, X, mini_batch_size):\n        ttt_lr = torch.einsum('bnkc,hdc->bhnkd', X, self.\n            learnable_ttt_lr_weight) + self.learnable_ttt_lr_bias.reshape(1,\n            -1, 1, 1, 1)\n        ttt_lr = F.sigmoid(ttt_lr)\n        ttt_lr = ttt_lr.permute(0, 1, 2, 4, 3)\n        ttt_lr_eta = self.ttt_base_lr * ttt_lr / self.head_dim\n        token_idx = self.token_idx + self.learnable_token_idx\n        token_idx = token_idx[0:mini_batch_size]\n        token_idx = torch.clamp_min(token_idx, 0.0)\n        token_eta = torch.broadcast_to(token_idx.reshape(1, 1, 1,\n            mini_batch_size, 1), (X.shape[0], self.num_heads, X.shape[1],\n            mini_batch_size, 1))\n        return token_eta, ttt_lr_eta\n\n    def get_ttt_inputs(self, inputs, mini_batch_size):\n        XQ = inputs['XQ']\n        XK = inputs['XK']\n        XV = inputs['XV']\n        X = inputs['X']\n        B, L, C = X.shape\n        num_mini_batch = L // mini_batch_size\n        X = X.reshape(B, num_mini_batch, mini_batch_size, self.width)\n        XQ = XQ.reshape(B, self.num_heads, L // mini_batch_size,\n            mini_batch_size, self.head_dim)\n        XK = XK.reshape(B, self.num_heads, L // mini_batch_size,\n            mini_batch_size, self.head_dim)\n        XV = XV.reshape(B, self.num_heads, L // mini_batch_size,\n            mini_batch_size, self.head_dim)\n        token_eta, ttt_lr_eta = self.get_eta(X, mini_batch_size)\n        eta = token_eta * ttt_lr_eta\n        inputs = {'XQ': XQ, 'XK': XK, 'XV': XV, 'eta': eta, 'token_eta':\n            token_eta, 'ttt_lr_eta': ttt_lr_eta}\n        return inputs\n\n    def ln_fwd(self, x, gamma, beta, eps=1e-06):\n        \"\"\"Batch forward for LayerNorm.\"\"\"\n        mu = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, keepdim=True, unbiased=False)\n        std = torch.sqrt(var + eps)\n        x_hat = (x - mu) / std\n        y = gamma * x_hat + beta\n        return y\n\n    def apply_rotary_pos_emb(self, q, k, cos, sin, unsqueeze_dim=1):\n        \"\"\"Applies Rotary Position Embedding to the query and key tensors.\n\n        Args:\n            q (`torch.Tensor`): The query tensor.\n            k (`torch.Tensor`): The key tensor.\n            cos (`torch.Tensor`): The cosine part of the rotary embedding.\n            sin (`torch.Tensor`): The sine part of the rotary embedding.\n            position_ids (`torch.Tensor`, *optional*):\n                Deprecated and unused.\n            unsqueeze_dim (`int`, *optional*, defaults to 1):\n                The 'unsqueeze_dim' argument specifies the dimension along which to unsqueeze cos[position_ids] and\n                sin[position_ids] so that they can be properly broadcasted to the dimensions of q and k. For example, note\n                that cos[position_ids] and sin[position_ids] have the shape [batch_size, seq_len, head_dim]. Then, if q and\n                k have the shape [batch_size, heads, seq_len, head_dim], then setting unsqueeze_dim=1 makes\n                cos[position_ids] and sin[position_ids] broadcastable to the shapes of q and k. Similarly, if q and k have\n                the shape [batch_size, seq_len, heads, head_dim], then set unsqueeze_dim=2.\n        Returns:\n            `tuple(torch.Tensor)` comprising of the query and key tensors rotated using the Rotary Position Embedding.\n        \"\"\"\n        cos = cos.unsqueeze(unsqueeze_dim)\n        sin = sin.unsqueeze(unsqueeze_dim)\n        q_embed = q * cos + self.rotate_half(q) * sin\n        k_embed = k * cos + self.rotate_half(k) * sin\n        return q_embed, k_embed\n\n    def scan(self, f, init, xs, out, checkpoint_group=0):\n        \"\"\"Minic jax.lax.scan function.\"\"\"\n        carry = init\n        if isinstance(xs, dict):\n            num_items = len(next(iter(xs.values())))\n        else:\n            num_items = len(xs[0])\n\n        def scan_fn(carry, i_start, i_end):\n            for i in range(i_start, i_end):\n                if isinstance(xs, dict):\n                    x = {key: tensor[i] for key, tensor in xs.items()}\n                else:\n                    x = [x[i] for x in xs]\n                carry, y = f(carry, x)\n                out[i] = y\n            return carry\n        if checkpoint_group > 0:\n            ckpt_every_n = num_items // checkpoint_group\n            for k in range(0, num_items, ckpt_every_n):\n                carry = torch.utils.checkpoint.checkpoint(scan_fn, carry, k,\n                    min(k + ckpt_every_n, num_items), use_reentrant=False)\n        else:\n            carry = scan_fn(carry, 0, num_items)\n        return carry, out\n\n    def ttt(self, inputs, mini_batch_size, last_mini_batch_params_dict):\n        if mini_batch_size is None:\n            mini_batch_size = self.mini_batch_size\n        B = inputs['XV'].shape[0]\n        num_mini_batch = inputs['XV'].shape[2]\n        L = inputs['XV'].shape[2] * inputs['XV'].shape[3]\n        device = inputs['XV'].device\n        dtype = inputs['XV'].dtype\n        use_dual_form = True\n\n        def compute_mini_batch(params_dict, inputs):\n            W1_init = params_dict['W1_states']\n            b1_init = params_dict['b1_states']\n            XQ_mini_batch = inputs['XQ']\n            XV_mini_batch = inputs['XV']\n            XK_mini_batch = inputs['XK']\n            eta_mini_batch = inputs['eta']\n            token_eta_mini_batch = inputs['token_eta']\n            ttt_lr_eta_mini_batch = inputs['ttt_lr_eta']\n            X1 = XK_mini_batch\n            Z1 = X1 @ W1_init + b1_init\n            reconstruction_target = XV_mini_batch - XK_mini_batch\n            ln_weight = self.ttt_norm_weight.reshape(self.num_heads, 1,\n                self.head_dim)\n            ln_bias = self.ttt_norm_bias.reshape(self.num_heads, 1, self.\n                head_dim)\n            grad_l_wrt_Z1 = self.ln_fused_l2_bwd(Z1, reconstruction_target,\n                ln_weight, ln_bias)\n            if use_dual_form:\n                Attn1 = torch.tril(XQ_mini_batch @ X1.transpose(-2, -1))\n                b1_bar = b1_init - torch.tril(eta_mini_batch) @ grad_l_wrt_Z1\n                Z1_bar = (XQ_mini_batch @ W1_init - eta_mini_batch * Attn1 @\n                    grad_l_wrt_Z1 + b1_bar)\n                last_eta_mini_batch = eta_mini_batch[:, :, -1, :, None]\n                W1_last = W1_init - (last_eta_mini_batch * X1).transpose(-1, -2\n                    ) @ grad_l_wrt_Z1\n                b1_last = b1_init - torch.sum(last_eta_mini_batch *\n                    grad_l_wrt_Z1, dim=-2, keepdim=True)\n                grad_W1_last = torch.zeros_like(W1_last)\n                grad_b1_last = torch.zeros_like(b1_last)\n            else:\n                ttt_lr_eta_mini_batch = torch.broadcast_to(\n                    ttt_lr_eta_mini_batch, (*ttt_lr_eta_mini_batch.shape[:2\n                    ], mini_batch_size, mini_batch_size))\n                grad_W1 = torch.einsum('bhki,bhkj->bhkij', X1, grad_l_wrt_Z1)\n                grad_W1 = torch.einsum('bhnk,bhkij->bhnij', torch.tril(\n                    ttt_lr_eta_mini_batch), grad_W1)\n                grad_W1 = grad_W1 + params_dict['W1_grad'].unsqueeze(2)\n                grad_b1 = torch.einsum('bhnk,bhki->bhni', torch.tril(\n                    ttt_lr_eta_mini_batch), grad_l_wrt_Z1)\n                grad_b1 = grad_b1 + params_dict['b1_grad']\n                W1_bar = W1_init.unsqueeze(2\n                    ) - grad_W1 * token_eta_mini_batch.unsqueeze(-1)\n                b1_bar = b1_init - grad_b1 * token_eta_mini_batch\n                Z1_bar = (XQ_mini_batch.unsqueeze(3) @ W1_bar).squeeze(3\n                    ) + b1_bar\n                W1_last = W1_bar[:, :, -1]\n                b1_last = b1_bar[:, :, -1:]\n                grad_W1_last = grad_W1[:, :, -1]\n                grad_b1_last = grad_b1[:, :, -1:]\n            Z1_bar = self.ln_fwd(Z1_bar, ln_weight, ln_bias)\n            XQW_mini_batch = XQ_mini_batch + Z1_bar\n            last_param_dict = {'W1_states': W1_last, 'b1_states': b1_last,\n                'W1_grad': grad_W1_last, 'b1_grad': grad_b1_last}\n            return last_param_dict, XQW_mini_batch\n        if last_mini_batch_params_dict is not None:\n            init_params_dict = last_mini_batch_params_dict\n        else:\n            init_params_dict = {'W1_states': torch.tile(self.W1.unsqueeze(0\n                ), dims=(B, 1, 1, 1)), 'b1_states': torch.tile(self.b1.\n                unsqueeze(0), dims=(B, 1, 1, 1))}\n            init_params_dict.update(W1_grad=torch.zeros_like(\n                init_params_dict['W1_states']))\n            init_params_dict.update(b1_grad=torch.zeros_like(\n                init_params_dict['b1_states']))\n        inputs = tree_map(lambda x: x.permute(2, 0, 1, 3, 4), inputs)\n        XQW_batch = torch.empty((num_mini_batch, B, self.num_heads,\n            mini_batch_size, self.head_dim), device=device, dtype=dtype)\n        batch_params_dict, XQW_batch = self.scan(compute_mini_batch,\n            init_params_dict, inputs, XQW_batch, self.\n            scan_checkpoint_group_size if self.training else 0)\n        XQW_batch = XQW_batch.permute(1, 0, 3, 2, 4)\n        XQW_batch = XQW_batch.reshape(B, L, self.width)\n        return XQW_batch, batch_params_dict\n\n    def _forward(self, X, position_ids, **Z):\n        hidden_states = X\n        B, L = hidden_states.shape[:2]\n        reminder_len = L % self.mini_batch_size\n        num_mini_batch = L // self.mini_batch_size\n        last_mini_batch_params_dict = None\n        XQ, XK, XV = self.get_qkv_projections(hidden_states)\n        XQ = XQ.reshape(B, L, self.num_heads, self.head_dim).transpose(1, 2)\n        XK = XK.reshape(B, L, self.num_heads, self.head_dim).transpose(1, 2)\n        XV = XV.reshape(B, L, self.num_heads, self.head_dim).transpose(1, 2)\n        Z['position_ids'] = position_ids % self.mini_batch_size\n        Z['input'] = XV\n        _, Z = self.rotary_emb(X, **Z)\n        cos = Z['cos']\n        sin = Z['sin']\n        XQ, XK = self.permute_qk(XQ, XK)\n        XQ, XK = self.apply_rotary_pos_emb(XQ, XK, cos, sin)\n        XQ, XK = self.undo_permute_qk(XQ, XK)\n        output_hidden_states = []\n        if num_mini_batch > 0:\n            inputs = {'XQ': XQ[:, :, :num_mini_batch * self.mini_batch_size\n                ], 'XK': XK[:, :, :num_mini_batch * self.mini_batch_size],\n                'XV': XV[:, :, :num_mini_batch * self.mini_batch_size], 'X':\n                hidden_states[:, :num_mini_batch * self.mini_batch_size]}\n            output_mod, last_mini_batch_params_dict = self.ttt(self.\n                get_ttt_inputs(inputs, self.mini_batch_size),\n                mini_batch_size=self.mini_batch_size,\n                last_mini_batch_params_dict=last_mini_batch_params_dict)\n            output_hidden_states.append(output_mod)\n        if reminder_len > 0:\n            inputs = {'XQ': XQ[:, :, -reminder_len:], 'XK': XK[:, :, -\n                reminder_len:], 'XV': XV[:, :, -reminder_len:], 'X':\n                hidden_states[:, -reminder_len:]}\n            output_reminder, _ = self.ttt(self.get_ttt_inputs(inputs,\n                reminder_len), mini_batch_size=reminder_len,\n                last_mini_batch_params_dict=last_mini_batch_params_dict)\n            output_hidden_states.append(output_reminder)\n        output_hidden_states = torch.cat(output_hidden_states, dim=1)\n        output_hidden_states = self.post_norm(output_hidden_states)\n        output_hidden_states = self.o_proj(output_hidden_states)\n        return output_hidden_states\n\n\nCHILDREN_DECLARATIONS = [UnitDecl(unitname='RotaryEmbedding', requirements=\n    '', inputs=['X'], outputs=['cos', 'sin'])]\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"TTTLinear\",\"document\":\"\\nTTTLinear\\n\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [
                            "RotaryEmbedding"
                        ],
                        "suggestions": null,
                        "args": {
                            "conv_kernel": 4,
                            "rope_theta": 10000.0,
                            "mini_batch_size": 16,
                            "num_attention_heads": 4,
                            "ttt_base_lr": 1.0,
                            "scan_checkpoint_group_size": 4
                        },
                        "design_traces": null
                    },
                    "RotaryEmbedding": {
                        "review": null,
                        "requirements": null,
                        "reuse_from": null,
                        "desc": "\n",
                        "gautests": {
                            "test_rotaryembedding": "@gau_test\ndef test_RotaryEmbedding_test_rotaryembedding(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    rotaryembedding = RotaryEmbedding(embed_dim, block_loc, kwarg_all,\n        device=device, dtype=dtype)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    y = rotaryembedding(x)\n    assert y.shape == (1, 100, 128)\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nfrom typing import Any, Dict, Optional, Tuple, Union\nimport torch.nn.functional as F\nfrom transformers.utils import logging\nlogger = logging.get_logger(__name__)\n\n\nclass RotaryEmbedding(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, dim=None, max_position_embeddings=16, base\n        =10000, scaling_factor=1.0, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.scaling_factor = scaling_factor\n        self.dim = dim if dim is not None else embed_dim // 4\n        self.max_position_embeddings = max_position_embeddings\n        self.base = base\n        inv_freq = 1.0 / self.base ** (torch.arange(0, self.dim, 2, dtype=\n            torch.int64).float().to(device) / self.dim)\n        self.register_buffer('inv_freq', inv_freq, persistent=False)\n\n    @torch.no_grad()\n    def _forward(self, X, input, position_ids, **Z):\n        inv_freq_expanded = self.inv_freq[None, :, None].float().expand(\n            position_ids.shape[0], -1, 1)\n        inv_freq_expanded = self.inv_freq[None, :, None].float().expand(\n            position_ids.shape[0], -1, 1)\n        position_ids_expanded = position_ids[:, None, :].float()\n        device_type = input.device.type\n        device_type = device_type if isinstance(device_type, str\n            ) and device_type != 'mps' else 'cpu'\n        with torch.autocast(device_type=device_type, enabled=False):\n            freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()\n                ).transpose(1, 2)\n            emb = torch.cat((freqs, freqs), dim=-1)\n            cos = emb.cos()\n            sin = emb.sin()\n        Z['cos'] = cos.to(**self.factory_kwargs)\n        Z['sin'] = sin.to(**self.factory_kwargs)\n        return X, Z\n\n\nCHILDREN_DECLARATIONS = []\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"RotaryEmbedding\",\"document\":\"\\nRotaryEmbedding\\n\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {
                            "scaling_factor": 1.0,
                            "dim": null,
                            "base": 10000,
                            "max_position_embeddings": 16
                        },
                        "design_traces": null
                    },
                    "RMSNorm": {
                        "review": null,
                        "requirements": null,
                        "reuse_from": null,
                        "desc": "\n",
                        "gautests": {
                            "test_rmsnorm": "@gau_test\ndef test_RMSNorm_test_rmsnorm(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    rmsnorm = RMSNorm(embed_dim, block_loc, kwarg_all, device=device, dtype\n        =dtype, **kwarg_all)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    Z = {}\n    y, Z_ = rmsnorm(x, **Z)\n    assert y.shape == (1, 100, 128)\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import Tensor\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RMSNorm(GAUBase):\n    \"\"\"\n    Root Mean Square Layer Normalization (RMSNorm).\n\n    This layer applies a variant of layer normalization that uses only the root mean square\n    statistics, without centering. It's computationally more efficient than standard\n    layer normalization and has been shown to be effective in various NLP tasks.\n\n    Args:\n        embed_dim (int): The size of the input feature dimension.\n        block_loc (tuple): The location of this block in the model architecture.\n        kwarg_all (dict): Additional keyword arguments passed to the parent class.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The dtype of the module's parameters.\n        eps (float, optional): A small constant added to the denominator for numerical stability.\n            Default: 1e-5.\n\n    Attributes:\n        weight (nn.Parameter): Learnable scale parameter of shape (embed_dim,).\n        variance_epsilon (float): The epsilon value used in the normalization formula.\n\n    Shape:\n        - Input: (*, embed_dim)\n        - Output: (*, embed_dim) (same shape as input)\n\n    Examples:\n        >>> rmsnorm = RMSNorm(128, (0, 6), {})\n        >>> x = torch.randn(1, 100, 128)\n        >>> output = rmsnorm(x)\n        >>> print(output.shape)\n        torch.Size([1, 100, 128])\n\n    References:\n        - Paper: \"Root Mean Square Layer Normalization\" by Biao Zhang and Rico Sennrich\n          https://arxiv.org/abs/1910.07467\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, eps=1e-05, **kwargs):\n        \"\"\"If group_size is not None, we do GroupNorm with each group having group_size elements.\n        group_size=None is equivalent to group_size=hidden_size (i.e. there's only 1 group).\n        \"\"\"\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.weight = nn.Parameter(torch.ones(embed_dim, **self.factory_kwargs)\n            )\n        self.variance_epsilon = eps\n\n    def _forward(self, X, **Z):\n        input_dtype = X.dtype\n        X = X.to(torch.float32)\n        variance = X.pow(2).mean(-1, keepdim=True)\n        X = X * torch.rsqrt(variance + self.variance_epsilon)\n        return self.weight * X.to(input_dtype)\n\n\nCHILDREN_DECLARATIONS = []\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"RMSNorm\",\"document\":\"\\n    Root Mean Square Layer Normalization (RMSNorm).\\n\\n    This layer applies a variant of layer normalization that uses only the root mean square\\n    statistics, without centering. It's computationally more efficient than standard\\n    layer normalization and has been shown to be effective in various NLP tasks.\\n\\n    Args:\\n        embed_dim (int): The size of the input feature dimension.\\n        block_loc (tuple): The location of this block in the model architecture.\\n        kwarg_all (dict): Additional keyword arguments passed to the parent class.\\n        device (torch.device, optional): The device on which to allocate the module's parameters.\\n        dtype (torch.dtype, optional): The dtype of the module's parameters.\\n        eps (float, optional): A small constant added to the denominator for numerical stability.\\n            Default: 1e-5.\\n\\n    Attributes:\\n        weight (nn.Parameter): Learnable scale parameter of shape (embed_dim,).\\n        variance_epsilon (float): The epsilon value used in the normalization formula.\\n\\n    Shape:\\n        - Input: (*, embed_dim)\\n        - Output: (*, embed_dim) (same shape as input)\\n\\n    Examples:\\n        >>> rmsnorm = RMSNorm(128, (0, 6), {})\\n        >>> x = torch.randn(1, 100, 128)\\n        >>> output = rmsnorm(x)\\n        >>> print(output.shape)\\n        torch.Size([1, 100, 128])\\n\\n    References:\\n        - Paper: \\\"Root Mean Square Layer Normalization\\\" by Biao Zhang and Rico Sennrich\\n          https://arxiv.org/abs/1910.07467\\n    \",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {
                            "eps": 1e-05
                        },
                        "design_traces": null
                    },
                    "Conv": {
                        "review": null,
                        "requirements": null,
                        "reuse_from": null,
                        "desc": "\n",
                        "gautests": {
                            "test_conv": "@gau_test\ndef test_Conv_test_conv(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    conv = Conv(embed_dim, block_loc, kwarg_all, device=device, dtype=dtype)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    y = conv(x)\n    assert y.shape == (1, 100, 128)\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nfrom typing import Any, Dict, Optional, Tuple, Union\nimport torch.nn.functional as F\nimport torch.utils.checkpoint\nfrom torch.utils._pytree import tree_map\nfrom transformers.utils import logging\nfrom transformers.activations import ACT2FN\ntry:\n    from causal_conv1d import causal_conv1d_fn, causal_conv1d_update\nexcept:\n    causal_conv1d_update, causal_conv1d_fn = None, None\nlogger = logging.get_logger(__name__)\n\n\nclass Conv(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, conv_kernel=4, rms_norm_eps=1e-06, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        kwarg_all['eps'] = rms_norm_eps\n        self.norm = RMSNorm(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.conv = nn.Conv1d(embed_dim, embed_dim, bias=True, kernel_size=\n            conv_kernel, groups=embed_dim, padding=conv_kernel - 1, **self.\n            factory_kwargs)\n\n    def __call__(self, X, **Z):\n        hidden_states = X\n        seq_len = hidden_states.shape[1]\n        hidden_states = self.norm(hidden_states, **Z)[0]\n        hidden_states = hidden_states.transpose(1, 2)\n        if causal_conv1d_fn is None:\n            hidden_states = self.conv(hidden_states)[..., :seq_len]\n        else:\n            conv_weights = self.conv.weight.view(self.conv.weight.size(0),\n                self.conv.weight.size(2))\n            hidden_states = causal_conv1d_fn(hidden_states, conv_weights,\n                self.conv.bias, activation=None)\n        hidden_states = hidden_states.transpose(1, 2)\n        return hidden_states\n\n\nCHILDREN_DECLARATIONS = [UnitDecl(unitname='RMSNorm', requirements='',\n    inputs=['X'], outputs=['Y'])]\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"Conv\",\"document\":\"\\nConv\\n\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [
                            "RMSNorm"
                        ],
                        "suggestions": null,
                        "args": {
                            "conv_kernel": 4,
                            "rms_norm_eps": 1e-06
                        },
                        "design_traces": null
                    },
                    "MetaTTT": {
                        "review": "**Overall Assessment**:\n\n```rating 4.5```\n\n**Strengths of the Implementation**:\n\n1. **Successful Integration of Meta-Learning and Uncertainty-Aware Mechanisms**: The coder has effectively integrated meta-learning, gated mechanisms, and uncertainty-aware compression into the `MetaTTT` GAU, aligning well with the proposal's objectives. This demonstrates a solid understanding of the underlying concepts and their practical implementation.\n\n2. **Resolution of Previous Issues**: The previously identified issues regarding causality and gradient flow have been successfully addressed. The attention mechanism now includes a causal mask to enforce autoregressive properties, and gradient flow to all parameters is ensured by incorporating `W_compressed` into the computation of the output `Y`.\n\n3. **Clear and Comprehensive Documentation**: The implementation includes detailed docstrings with mathematical formulations, method explanations, and usage examples. This enhances code readability and maintainability, facilitating future development and collaboration.\n\n4. **Passing All Checks**: The implementation passes both the format and functionality checks, indicating robustness and readiness for integration into the larger model. This also reflects adherence to coding standards and best practices.\n\n**Areas for Improvement and Specific Suggestions**:\n\n1. **Optimization of Computational Efficiency**:\n\n   - **Assess Computational Overhead**: While the added components enhance functionality, they may introduce additional computational load.\n\n     **Suggestion**: Profile the model to measure the computational overhead introduced by the meta-learner, gating mechanisms, and uncertainty estimation modules. If significant, consider optimizing these components by:\n\n     - Reducing the `hidden_dim` in the meta-learner and uncertainty modules if it does not adversely affect performance.\n     - Exploring more efficient activation functions or simplifying network architectures.\n     - Utilizing techniques like parameter sharing or low-rank approximations to reduce the number of parameters.\n\n2. **Scalability to Larger Models and Longer Contexts**:\n\n   - **Evaluate Memory Usage and Performance**: Ensure that the implementation scales efficiently with increased model sizes and longer sequences.\n\n     **Suggestion**: Conduct experiments with varying sequence lengths and batch sizes to monitor memory consumption and processing time. Optimize memory usage by:\n\n     - Implementing gradient checkpointing for memory-intensive operations.\n     - Utilizing mixed-precision training if appropriate.\n     - Exploring efficient data structures or parallelization strategies.\n\n3. **Inclusion of Unit Tests and Child Declarations**:\n\n   - **Enhance Test Coverage**: Even though the functionality checks passed, adding unit tests improves robustness.\n\n     **Suggestion**: Implement unit tests for `MetaTTT` to validate its behavior under different scenarios, including edge cases. This ensures reliability and facilitates future modifications.\n\n   - **Child Declarations**:\n\n     **Suggestion**: Explicitly declare any child GAUs or confirm that `CHILDREN_DECLARATIONS` is intentionally left empty for clarity:\n\n     ```python\n     CHILDREN_DECLARATIONS = []\n     ```\n\n4. **Code Readability and Consistency**:\n\n   - **Enhance Readability**: Clear and consistent code aids understanding and future maintenance.\n\n     **Suggestion**:\n\n     - **Inline Comments**: Add comments explaining complex operations, especially in the forward pass where meta-learning and uncertainty computations occur.\n     - **Naming Conventions**: Ensure variable names are descriptive and consistent throughout the code.\n     - **Cleanup**: Remove any unused imports or redundant code to keep the codebase clean.\n\n5. **Validation of Hyperparameters**:\n\n   - **Fine-Tuning Hyperparameters**: The choice of hyperparameters such as `hidden_dim`, learning rates, and layer configurations can significantly impact performance.\n\n     **Suggestion**: Experiment with different hyperparameter settings to find the optimal balance between performance and computational efficiency. Document the rationale behind chosen values.\n\n**Comments on Innovation and Potential Impact**:\n\n- **Innovation**: The `MetaTTT` GAU represents a novel approach by integrating meta-learning and uncertainty-aware compression into the TTT framework. This enhances the model's adaptability during inference and could address challenges in long-context language modeling effectively.\n\n- **Potential Impact**: Successfully implementing these mechanisms may lead to improvements in perplexity, scalability, and efficiency, contributing to advancements in autoregressive language models. This aligns with the team's goals of outperforming existing state-of-the-art models.\n\n**Recommendations for the Coder**:\n\n1. **Performance Profiling and Optimization**:\n\n   - Use profiling tools to identify bottlenecks in computation and memory usage.\n   - Optimize tensor operations to leverage parallelism and minimize overhead.\n   - Consider the trade-off between model complexity and performance benefits.\n\n2. **Extensive Testing and Benchmarking**:\n\n   - Evaluate the model on standard benchmarks for language modeling to assess improvements in perplexity and downstream task performance.\n   - Perform ablation studies to understand the contribution of each component (meta-learning, gating mechanisms, uncertainty-aware compression) to overall performance.\n\n3. **Documentation of Findings**:\n\n   - Keep detailed records of experiments, including configurations and results.\n   - Document any insights or challenges encountered during implementation, which can be valuable for future work.\n\n4. **Future Extensions**:\n\n   - Explore integrating additional techniques such as adaptive learning rates in the meta-learner or alternative uncertainty estimation methods.\n   - Investigate the compatibility of `MetaTTT` with other architectural enhancements or larger-scale models.\n\n5. **Collaboration and Feedback**:\n\n   - Share your implementation with peers or the broader community to gather feedback.\n   - Engage in discussions about potential improvements or alternative approaches.\n\nBy continuing to refine the implementation and addressing the areas for improvement, you can enhance the robustness and scalability of the `MetaTTT` GAU. This will contribute significantly to achieving the team's objectives and advancing the field of language modeling.",
                        "requirements": "N/A",
                        "reuse_from": null,
                        "desc": null,
                        "gautests": {
                            "test_meta_ttt": "@gau_test\ndef test_MetaTTT_test_meta_ttt(device=None, dtype=None) ->None:\n    embed_dim = 64\n    batch_size = 4\n    seq_len = 16\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    Z = {}\n    meta_ttt = MetaTTT(embed_dim=embed_dim, block_loc=(0, 1), kwarg_all={},\n        device=device, dtype=dtype)\n    Y, Z_out = meta_ttt(X, **Z)\n    assert Y.shape == X.shape, f'Expected output shape {X.shape}, got {Y.shape}'\n    assert 'hidden_state' in Z_out, 'Hidden state not updated in Z'\n    assert Z_out['hidden_state'].shape == (batch_size, embed_dim\n        ), f\"Expected hidden_state shape {batch_size, embed_dim}, got {Z_out['hidden_state'].shape}\"\n    print('MetaTTT unit test passed.')\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nimport torch.nn.functional as F\n\n\nclass MetaTTT(GAUBase):\n    \"\"\"\n    MetaTTT: A Test-Time Training GAU enhanced with meta-learning, gated mechanisms, and uncertainty-aware compression.\n    \n    This class implements the MetaTTT GAU as described in the proposal. MetaTTT enhances the TTT GAU by integrating meta-learning for dynamic hidden state adaptation, gated mechanisms for selective information flow, and uncertainty-aware compression for efficient memory usage.\n    \n    **Methods:**\n    \n    - **__init__**: Initializes the MetaTTT GAU, including the meta-learner, gating mechanisms, uncertainty estimation module, and compression gate.\n    - **_forward**: Implements the forward pass, including hidden state updates, gating mechanisms, uncertainty estimation, and compression.\n    \n    **Mathematical Formulation:**\n    \n    - **Meta-Learned Hidden State Update**:\n      \\\\( W_t = M(W_{t-1}, x_t; \theta_M) \\\\)\n    - **Gated Query and Key Modulation**:\n      \\\\( Q_t' = Q_t \\\\odot \\\\sigma(W_{GQ} W_t + b_{GQ}) \\\\)\n      \\\\( K_t' = K_t \\\\odot \\\\sigma(W_{GK} W_t + b_{GK}) \\\\)\n    - **Uncertainty-Aware Compression**:\n      \\\\( C_t = \\\\sigma(W_U \\\\cdot U(W_t) + b_U) \\\\)\n      \\\\( W_t' = W_t \\\\odot C_t \\\\)\n\n    **Args:**\n        embed_dim (int): The size of the input embeddings.\n        block_loc (tuple): The location of this block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments.\n        device (torch.device, optional): The device to run the model on.\n        dtype (torch.dtype, optional): The data type for model parameters.\n        hidden_dim (int): The dimension of the hidden layer in the meta-learner. Default: 128.\n    \n    **Example:**\n        This is how you can use this function:\n    \n        meta_ttt = MetaTTT(embed_dim=768, block_loc=(0, 1), kwarg_all={})\n        X = torch.randn(32, 128, 768)\n        Y, Z = meta_ttt(X)\n    \n    **References:**\n    - Sun, Y. et al., 2024. Learning to (Learn at Test Time): RNNs with Expressive Hidden States.\n    - Other references as per the proposal.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_dim: int=128, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.meta_learner = nn.Sequential(nn.Linear(embed_dim + embed_dim,\n            hidden_dim, **self.factory_kwargs), nn.ReLU(), nn.Linear(\n            hidden_dim, embed_dim, **self.factory_kwargs))\n        self.gate_q = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.gate_k = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.uncertainty_module = nn.Sequential(nn.Linear(embed_dim,\n            hidden_dim, **self.factory_kwargs), nn.Softplus(), nn.Linear(\n            hidden_dim, 1, **self.factory_kwargs))\n        self.compress_gate = nn.Linear(1, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.q_proj = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        self.k_proj = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        self.v_proj = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        self.o_proj = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n\n    def _forward(self, X, **Z):\n        B, L, D = X.shape\n        W_prev = Z.get('hidden_state', torch.zeros(B, D, device=X.device,\n            dtype=X.dtype))\n        W_prev_expanded = W_prev.unsqueeze(1).expand(-1, L, -1)\n        meta_input = torch.cat([W_prev_expanded, X], dim=-1)\n        W_new = self.meta_learner(meta_input)\n        W_new_last = W_new[:, -1, :]\n        uncertainty = self.uncertainty_module(W_new)\n        compress_factor = torch.sigmoid(self.compress_gate(uncertainty))\n        W_compressed = W_new * compress_factor\n        W_compressed_last = W_compressed[:, -1, :]\n        Z['hidden_state'] = W_compressed_last\n        X_enhanced = X + W_compressed\n        Q = self.q_proj(X_enhanced)\n        K = self.k_proj(X_enhanced)\n        V = self.v_proj(X_enhanced)\n        G_Q = torch.sigmoid(self.gate_q(W_new))\n        G_K = torch.sigmoid(self.gate_k(W_new))\n        Q = Q * G_Q\n        K = K * G_K\n        attn_scores = torch.bmm(Q, K.transpose(1, 2)) / self.embed_dim ** 0.5\n        mask = torch.tril(torch.ones(L, L, device=attn_scores.device)\n            ).unsqueeze(0)\n        attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n        attn_weights = torch.softmax(attn_scores, dim=-1)\n        attn_output = torch.bmm(attn_weights, V)\n        Y = self.o_proj(attn_output)\n        return Y, Z\n",
                        "rating": 4.5,
                        "spec": "{\"unitname\":\"MetaTTT\",\"document\":\"MetaTTT: A Test-Time Training GAU enhanced with meta-learning, gated mechanisms, and uncertainty-aware compression.\\n\\nThis class implements the MetaTTT GAU as described in the proposal. MetaTTT enhances the TTT GAU by integrating meta-learning for dynamic hidden state adaptation, gated mechanisms for selective information flow, and uncertainty-aware compression for efficient memory usage.\\n\\n**Methods:**\\n\\n- **__init__**: Initializes the MetaTTT GAU, including the meta-learner, gating mechanisms, uncertainty estimation module, and compression gate.\\n- **_forward**: Implements the forward pass, including hidden state updates, gating mechanisms, uncertainty estimation, and compression.\\n\\n**Mathematical Formulation:**\\n\\n- **Meta-Learned Hidden State Update**:\\n  \\\\( W_t = M(W_{t-1}, x_t;  heta_M) \\\\)\\n- **Gated Query and Key Modulation**:\\n  \\\\( Q_t' = Q_t \\\\odot \\\\sigma(W_{GQ} W_t + b_{GQ}) \\\\)\\n  \\\\( K_t' = K_t \\\\odot \\\\sigma(W_{GK} W_t + b_{GK}) \\\\)\\n- **Uncertainty-Aware Compression**:\\n  \\\\( C_t = \\\\sigma(W_U \\\\cdot U(W_t) + b_U) \\\\)\\n  \\\\( W_t' = W_t \\\\odot C_t \\\\)\\n\\n**Args:**\\n    embed_dim (int): The size of the input embeddings.\\n    block_loc (tuple): The location of this block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments.\\n    device (torch.device, optional): The device to run the model on.\\n    dtype (torch.dtype, optional): The data type for model parameters.\\n    hidden_dim (int): The dimension of the hidden layer in the meta-learner. Default: 128.\\n\\n**Example:**\\n    This is how you can use this function:\\n\\n    meta_ttt = MetaTTT(embed_dim=768, block_loc=(0, 1), kwarg_all={})\\n    X = torch.randn(32, 128, 768)\\n    Y, Z = meta_ttt(X)\\n\\n**References:**\\n- Sun, Y. et al., 2024. Learning to (Learn at Test Time): RNNs with Expressive Hidden States.\\n- Other references as per the proposal.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {
                            "hidden_dim": 128
                        },
                        "design_traces": null
                    },
                    "SwiGluMLP": {
                        "review": null,
                        "requirements": null,
                        "reuse_from": null,
                        "desc": "\n",
                        "gautests": {
                            "test_swiglumlp": "@gau_test\ndef test_SwiGluMLP_test_swiglumlp(device=None, dtype=None):\n    embed_dim = 128\n    block_loc = 0, 6\n    kwarg_all = {}\n    swiglumlp = SwiGluMLP(embed_dim, block_loc, kwarg_all, device=device,\n        dtype=dtype)\n    x = torch.randn(1, 100, 128).to(device=device, dtype=dtype)\n    y = swiglumlp(x)\n    assert y.shape == (1, 100, 128)\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nfrom typing import Any, Dict, Optional, Tuple, Union\nimport torch.nn.functional as F\nfrom transformers.utils import logging\nfrom transformers.activations import ACT2FN\nlogger = logging.get_logger(__name__)\n\n\nclass SwiGluMLP(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, intermediate_size=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.intermediate_size = (intermediate_size if intermediate_size is not\n            None else int(embed_dim * 2.5))\n        self.gate_proj = nn.Linear(self.hidden_size, self.intermediate_size,\n            bias=False, **self.factory_kwargs)\n        self.up_proj = nn.Linear(self.hidden_size, self.intermediate_size,\n            bias=False, **self.factory_kwargs)\n        self.down_proj = nn.Linear(self.intermediate_size, self.hidden_size,\n            bias=False, **self.factory_kwargs)\n        self.act_fn = ACT2FN['silu']\n\n    def _forward(self, X, **Z):\n        down_proj = self.down_proj(self.act_fn(self.gate_proj(X)) * self.\n            up_proj(X))\n        return down_proj\n\n\nCHILDREN_DECLARATIONS = []\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"SwiGluMLP\",\"document\":\"\\nSwiGluMLP\\n\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {
                            "intermediate_size": null
                        },
                        "design_traces": null
                    }
                },
                "rating": null,
                "declares": {
                    "MetaTTT": "{\"unitname\":\"MetaTTT\",\"requirements\":\"N/A\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}"
                },
                "proposal_traces": [],
                "suggestions": null,
                "name": "metattt"
            },
            "user_input": "",
            "status": "unfinished",
            "design_cfg": {
                "max_attemps": {
                    "post_refinement": 0,
                    "max_search_rounds": 3,
                    "implementation_debug": 7,
                    "design_proposal": 10
                },
                "threshold": {
                    "proposal_rating": 4.0,
                    "implementation_rating": 3.0
                },
                "use_unlimited_prompt": true,
                "mutation_no_tree": true,
                "agent_types": {
                    "DESIGN_PROPOSER": "hybrid",
                    "IMPLEMENTATION_PLANNER": "hybrid",
                    "IMPLEMENTATION_CODER": "hybrid",
                    "PROPOSAL_REVIEWER": "hybrid",
                    "IMPLEMENTATION_OBSERVER": "hybrid",
                    "SEARCH_ASSISTANT": "None"
                },
                "running_mode": "Proposal + Implementation",
                "unittest_pass_required": false,
                "crossover_no_ref": true,
                "scratch_no_tree": true,
                "_agent_types": {
                    "DESIGN_PROPOSER": "o1_preview",
                    "IMPLEMENTATION_PLANNER": "o1_mini",
                    "IMPLEMENTATION_CODER": "o1_preview",
                    "PROPOSAL_REVIEWER": "o1_mini",
                    "IMPLEMENTATION_OBSERVER": "o1_preview",
                    "SEARCH_ASSISTANT": "None"
                },
                "termination": {
                    "max_debug_budget": 0,
                    "max_failed_rounds": 3,
                    "max_total_budget": 0
                },
                "agent_weights": {
                    "DESIGN_PROPOSER": [
                        0.05,
                        0.0,
                        0.6000000000000001,
                        0.2,
                        0.15
                    ],
                    "IMPLEMENTATION_PLANNER": [
                        0.05000000000000002,
                        0.0,
                        0.44999999999999996,
                        0.3,
                        0.20000000000000007
                    ],
                    "IMPLEMENTATION_CODER": [
                        0.0,
                        0.0,
                        0.3,
                        0.4999999999999996,
                        0.2
                    ],
                    "PROPOSAL_REVIEWER": [
                        0.10000000000000002,
                        0.0,
                        0.5499999999999999,
                        0.2,
                        0.15000000000000002
                    ],
                    "IMPLEMENTATION_OBSERVER": [
                        0.05,
                        0.0,
                        0.15000000000000002,
                        0.15000000000000002,
                        0.6499999999999999,
                        0.0
                    ]
                },
                "num_samples": {
                    "implementation": 1,
                    "rerank_method": "rating",
                    "proposal": 1
                },
                "search_settings": {
                    "proposal_search": true,
                    "proposal_review_search": true,
                    "search_for_papers_num": 10
                },
                "max_attempts": {
                    "post_refinement": 0,
                    "max_search_rounds": 4,
                    "implementation_debug": 5,
                    "design_proposal": 5
                }
            },
            "costs": {
                "DESIGN_PROPOSER": 0,
                "IMPLEMENTATION_PLANNER": 0.136131,
                "IMPLEMENTATION_CODER": 2.01471,
                "PROPOSAL_REVIEWER": 0,
                "IMPLEMENTATION_OBSERVER": 1.73007,
                "SEARCH_ASSISTANT": 0
            }
        },
        {
            "tree": {
                "review": null,
                "root": "MetaTTT",
                "proposal": "Self-attention performs well in long context but has quadratic complexity. Existing RNN layers have linear complexity, but their performance in long context is limited by the expressive power of their hidden state. We propose a new class of sequence modeling layers with linear complexity and an expressive hidden state. The key idea is to make the hidden state a machine learning model itself, and the update rule a step of self-supervised learning. Since the hidden state is updated by training even on test sequences, our layers are called Test-Time Training (TTT) layers. We consider two instantiations: TTT-Linear and TTT-MLP, whose hidden state is a linear model and a two-layer MLP respectively. We evaluate our instantiations at the scale of 125M to 1.3B parameters, comparing with a strong Transformer and Mamba, a modern RNN. Both TTT-Linear and TTT-MLP match or exceed the baselines. Similar to Transformer, they can keep reducing perplexity by conditioning on more tokens, while Mamba cannot after 16k context. With preliminary systems optimization, TTT-Linear is already faster than Transformer at 8k context and matches Mamba in wall-clock time. TTT-MLP still faces challenges in memory I/O, but shows larger potential in long context, pointing to a promising direction for future research.",
                "units": {
                    "MetaTTT": {
                        "review": "**Overall Assessment**:\n\n```rating 4.5```\n\n**Strengths of the Implementation**:\n\n1. **Successful Integration of Meta-Learning and Uncertainty-Aware Mechanisms**: The coder has effectively integrated meta-learning, gated mechanisms, and uncertainty-aware compression into the `MetaTTT` GAU, aligning well with the proposal's objectives. This demonstrates a solid understanding of the underlying concepts and their practical implementation.\n\n2. **Resolution of Previous Issues**: The previously identified issues regarding causality and gradient flow have been successfully addressed. The attention mechanism now includes a causal mask to enforce autoregressive properties, and gradient flow to all parameters is ensured by incorporating `W_compressed` into the computation of the output `Y`.\n\n3. **Clear and Comprehensive Documentation**: The implementation includes detailed docstrings with mathematical formulations, method explanations, and usage examples. This enhances code readability and maintainability, facilitating future development and collaboration.\n\n4. **Passing All Checks**: The implementation passes both the format and functionality checks, indicating robustness and readiness for integration into the larger model. This also reflects adherence to coding standards and best practices.\n\n**Areas for Improvement and Specific Suggestions**:\n\n1. **Optimization of Computational Efficiency**:\n\n   - **Assess Computational Overhead**: While the added components enhance functionality, they may introduce additional computational load.\n\n     **Suggestion**: Profile the model to measure the computational overhead introduced by the meta-learner, gating mechanisms, and uncertainty estimation modules. If significant, consider optimizing these components by:\n\n     - Reducing the `hidden_dim` in the meta-learner and uncertainty modules if it does not adversely affect performance.\n     - Exploring more efficient activation functions or simplifying network architectures.\n     - Utilizing techniques like parameter sharing or low-rank approximations to reduce the number of parameters.\n\n2. **Scalability to Larger Models and Longer Contexts**:\n\n   - **Evaluate Memory Usage and Performance**: Ensure that the implementation scales efficiently with increased model sizes and longer sequences.\n\n     **Suggestion**: Conduct experiments with varying sequence lengths and batch sizes to monitor memory consumption and processing time. Optimize memory usage by:\n\n     - Implementing gradient checkpointing for memory-intensive operations.\n     - Utilizing mixed-precision training if appropriate.\n     - Exploring efficient data structures or parallelization strategies.\n\n3. **Inclusion of Unit Tests and Child Declarations**:\n\n   - **Enhance Test Coverage**: Even though the functionality checks passed, adding unit tests improves robustness.\n\n     **Suggestion**: Implement unit tests for `MetaTTT` to validate its behavior under different scenarios, including edge cases. This ensures reliability and facilitates future modifications.\n\n   - **Child Declarations**:\n\n     **Suggestion**: Explicitly declare any child GAUs or confirm that `CHILDREN_DECLARATIONS` is intentionally left empty for clarity:\n\n     ```python\n     CHILDREN_DECLARATIONS = []\n     ```\n\n4. **Code Readability and Consistency**:\n\n   - **Enhance Readability**: Clear and consistent code aids understanding and future maintenance.\n\n     **Suggestion**:\n\n     - **Inline Comments**: Add comments explaining complex operations, especially in the forward pass where meta-learning and uncertainty computations occur.\n     - **Naming Conventions**: Ensure variable names are descriptive and consistent throughout the code.\n     - **Cleanup**: Remove any unused imports or redundant code to keep the codebase clean.\n\n5. **Validation of Hyperparameters**:\n\n   - **Fine-Tuning Hyperparameters**: The choice of hyperparameters such as `hidden_dim`, learning rates, and layer configurations can significantly impact performance.\n\n     **Suggestion**: Experiment with different hyperparameter settings to find the optimal balance between performance and computational efficiency. Document the rationale behind chosen values.\n\n**Comments on Innovation and Potential Impact**:\n\n- **Innovation**: The `MetaTTT` GAU represents a novel approach by integrating meta-learning and uncertainty-aware compression into the TTT framework. This enhances the model's adaptability during inference and could address challenges in long-context language modeling effectively.\n\n- **Potential Impact**: Successfully implementing these mechanisms may lead to improvements in perplexity, scalability, and efficiency, contributing to advancements in autoregressive language models. This aligns with the team's goals of outperforming existing state-of-the-art models.\n\n**Recommendations for the Coder**:\n\n1. **Performance Profiling and Optimization**:\n\n   - Use profiling tools to identify bottlenecks in computation and memory usage.\n   - Optimize tensor operations to leverage parallelism and minimize overhead.\n   - Consider the trade-off between model complexity and performance benefits.\n\n2. **Extensive Testing and Benchmarking**:\n\n   - Evaluate the model on standard benchmarks for language modeling to assess improvements in perplexity and downstream task performance.\n   - Perform ablation studies to understand the contribution of each component (meta-learning, gating mechanisms, uncertainty-aware compression) to overall performance.\n\n3. **Documentation of Findings**:\n\n   - Keep detailed records of experiments, including configurations and results.\n   - Document any insights or challenges encountered during implementation, which can be valuable for future work.\n\n4. **Future Extensions**:\n\n   - Explore integrating additional techniques such as adaptive learning rates in the meta-learner or alternative uncertainty estimation methods.\n   - Investigate the compatibility of `MetaTTT` with other architectural enhancements or larger-scale models.\n\n5. **Collaboration and Feedback**:\n\n   - Share your implementation with peers or the broader community to gather feedback.\n   - Engage in discussions about potential improvements or alternative approaches.\n\nBy continuing to refine the implementation and addressing the areas for improvement, you can enhance the robustness and scalability of the `MetaTTT` GAU. This will contribute significantly to achieving the team's objectives and advancing the field of language modeling.",
                        "requirements": "N/A",
                        "reuse_from": null,
                        "desc": null,
                        "gautests": {
                            "test_meta_ttt": "@gau_test\ndef test_MetaTTT_test_meta_ttt(device=None, dtype=None) ->None:\n    embed_dim = 64\n    batch_size = 4\n    seq_len = 16\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    Z = {}\n    meta_ttt = MetaTTT(embed_dim=embed_dim, block_loc=(0, 1), kwarg_all={},\n        device=device, dtype=dtype)\n    Y, Z_out = meta_ttt(X, **Z)\n    assert Y.shape == X.shape, f'Expected output shape {X.shape}, got {Y.shape}'\n    assert 'hidden_state' in Z_out, 'Hidden state not updated in Z'\n    assert Z_out['hidden_state'].shape == (batch_size, embed_dim\n        ), f\"Expected hidden_state shape {batch_size, embed_dim}, got {Z_out['hidden_state'].shape}\"\n    print('MetaTTT unit test passed.')\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nimport torch.nn.functional as F\n\n\nclass MetaTTT(GAUBase):\n    \"\"\"\n    MetaTTT: A Test-Time Training GAU enhanced with meta-learning, gated mechanisms, and uncertainty-aware compression.\n    \n    This class implements the MetaTTT GAU as described in the proposal. MetaTTT enhances the TTT GAU by integrating meta-learning for dynamic hidden state adaptation, gated mechanisms for selective information flow, and uncertainty-aware compression for efficient memory usage.\n    \n    **Methods:**\n    \n    - **__init__**: Initializes the MetaTTT GAU, including the meta-learner, gating mechanisms, uncertainty estimation module, and compression gate.\n    - **_forward**: Implements the forward pass, including hidden state updates, gating mechanisms, uncertainty estimation, and compression.\n    \n    **Mathematical Formulation:**\n    \n    - **Meta-Learned Hidden State Update**:\n      \\\\( W_t = M(W_{t-1}, x_t; \theta_M) \\\\)\n    - **Gated Query and Key Modulation**:\n      \\\\( Q_t' = Q_t \\\\odot \\\\sigma(W_{GQ} W_t + b_{GQ}) \\\\)\n      \\\\( K_t' = K_t \\\\odot \\\\sigma(W_{GK} W_t + b_{GK}) \\\\)\n    - **Uncertainty-Aware Compression**:\n      \\\\( C_t = \\\\sigma(W_U \\\\cdot U(W_t) + b_U) \\\\)\n      \\\\( W_t' = W_t \\\\odot C_t \\\\)\n\n    **Args:**\n        embed_dim (int): The size of the input embeddings.\n        block_loc (tuple): The location of this block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments.\n        device (torch.device, optional): The device to run the model on.\n        dtype (torch.dtype, optional): The data type for model parameters.\n        hidden_dim (int): The dimension of the hidden layer in the meta-learner. Default: 128.\n    \n    **Example:**\n        This is how you can use this function:\n    \n        meta_ttt = MetaTTT(embed_dim=768, block_loc=(0, 1), kwarg_all={})\n        X = torch.randn(32, 128, 768)\n        Y, Z = meta_ttt(X)\n    \n    **References:**\n    - Sun, Y. et al., 2024. Learning to (Learn at Test Time): RNNs with Expressive Hidden States.\n    - Other references as per the proposal.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_dim: int=128, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.meta_learner = nn.Sequential(nn.Linear(embed_dim + embed_dim,\n            hidden_dim, **self.factory_kwargs), nn.ReLU(), nn.Linear(\n            hidden_dim, embed_dim, **self.factory_kwargs))\n        self.gate_q = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.gate_k = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.uncertainty_module = nn.Sequential(nn.Linear(embed_dim,\n            hidden_dim, **self.factory_kwargs), nn.Softplus(), nn.Linear(\n            hidden_dim, 1, **self.factory_kwargs))\n        self.compress_gate = nn.Linear(1, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.q_proj = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        self.k_proj = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        self.v_proj = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        self.o_proj = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n\n    def _forward(self, X, **Z):\n        B, L, D = X.shape\n        W_prev = Z.get('hidden_state', torch.zeros(B, D, device=X.device,\n            dtype=X.dtype))\n        W_prev_expanded = W_prev.unsqueeze(1).expand(-1, L, -1)\n        meta_input = torch.cat([W_prev_expanded, X], dim=-1)\n        W_new = self.meta_learner(meta_input)\n        W_new_last = W_new[:, -1, :]\n        uncertainty = self.uncertainty_module(W_new)\n        compress_factor = torch.sigmoid(self.compress_gate(uncertainty))\n        W_compressed = W_new * compress_factor\n        W_compressed_last = W_compressed[:, -1, :]\n        Z['hidden_state'] = W_compressed_last\n        X_enhanced = X + W_compressed\n        Q = self.q_proj(X_enhanced)\n        K = self.k_proj(X_enhanced)\n        V = self.v_proj(X_enhanced)\n        G_Q = torch.sigmoid(self.gate_q(W_new))\n        G_K = torch.sigmoid(self.gate_k(W_new))\n        Q = Q * G_Q\n        K = K * G_K\n        attn_scores = torch.bmm(Q, K.transpose(1, 2)) / self.embed_dim ** 0.5\n        mask = torch.tril(torch.ones(L, L, device=attn_scores.device)\n            ).unsqueeze(0)\n        attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n        attn_weights = torch.softmax(attn_scores, dim=-1)\n        attn_output = torch.bmm(attn_weights, V)\n        Y = self.o_proj(attn_output)\n        return Y, Z\n",
                        "rating": 4.5,
                        "spec": "{\"unitname\":\"MetaTTT\",\"document\":\"MetaTTT: A Test-Time Training GAU enhanced with meta-learning, gated mechanisms, and uncertainty-aware compression.\\n\\nThis class implements the MetaTTT GAU as described in the proposal. MetaTTT enhances the TTT GAU by integrating meta-learning for dynamic hidden state adaptation, gated mechanisms for selective information flow, and uncertainty-aware compression for efficient memory usage.\\n\\n**Methods:**\\n\\n- **__init__**: Initializes the MetaTTT GAU, including the meta-learner, gating mechanisms, uncertainty estimation module, and compression gate.\\n- **_forward**: Implements the forward pass, including hidden state updates, gating mechanisms, uncertainty estimation, and compression.\\n\\n**Mathematical Formulation:**\\n\\n- **Meta-Learned Hidden State Update**:\\n  \\\\( W_t = M(W_{t-1}, x_t;  heta_M) \\\\)\\n- **Gated Query and Key Modulation**:\\n  \\\\( Q_t' = Q_t \\\\odot \\\\sigma(W_{GQ} W_t + b_{GQ}) \\\\)\\n  \\\\( K_t' = K_t \\\\odot \\\\sigma(W_{GK} W_t + b_{GK}) \\\\)\\n- **Uncertainty-Aware Compression**:\\n  \\\\( C_t = \\\\sigma(W_U \\\\cdot U(W_t) + b_U) \\\\)\\n  \\\\( W_t' = W_t \\\\odot C_t \\\\)\\n\\n**Args:**\\n    embed_dim (int): The size of the input embeddings.\\n    block_loc (tuple): The location of this block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments.\\n    device (torch.device, optional): The device to run the model on.\\n    dtype (torch.dtype, optional): The data type for model parameters.\\n    hidden_dim (int): The dimension of the hidden layer in the meta-learner. Default: 128.\\n\\n**Example:**\\n    This is how you can use this function:\\n\\n    meta_ttt = MetaTTT(embed_dim=768, block_loc=(0, 1), kwarg_all={})\\n    X = torch.randn(32, 128, 768)\\n    Y, Z = meta_ttt(X)\\n\\n**References:**\\n- Sun, Y. et al., 2024. Learning to (Learn at Test Time): RNNs with Expressive Hidden States.\\n- Other references as per the proposal.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {
                            "hidden_dim": 128
                        },
                        "design_traces": null
                    }
                },
                "rating": null,
                "declares": {
                    "MetaTTT": "{\"unitname\":\"MetaTTT\",\"requirements\":\"N/A\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}"
                },
                "proposal_traces": [],
                "suggestions": null,
                "name": "metattt"
            },
            "user_input": "",
            "status": "implemented",
            "design_cfg": {
                "max_attemps": {
                    "post_refinement": 0,
                    "max_search_rounds": 3,
                    "implementation_debug": 7,
                    "design_proposal": 10
                },
                "threshold": {
                    "proposal_rating": 4.0,
                    "implementation_rating": 3.0
                },
                "use_unlimited_prompt": true,
                "mutation_no_tree": true,
                "agent_types": {
                    "DESIGN_PROPOSER": "hybrid",
                    "IMPLEMENTATION_PLANNER": "hybrid",
                    "IMPLEMENTATION_CODER": "hybrid",
                    "PROPOSAL_REVIEWER": "hybrid",
                    "IMPLEMENTATION_OBSERVER": "hybrid",
                    "SEARCH_ASSISTANT": "None"
                },
                "running_mode": "Proposal + Implementation",
                "unittest_pass_required": false,
                "crossover_no_ref": true,
                "scratch_no_tree": true,
                "_agent_types": {
                    "DESIGN_PROPOSER": "o1_preview",
                    "IMPLEMENTATION_PLANNER": "o1_mini",
                    "IMPLEMENTATION_CODER": "o1_preview",
                    "PROPOSAL_REVIEWER": "o1_mini",
                    "IMPLEMENTATION_OBSERVER": "o1_preview",
                    "SEARCH_ASSISTANT": "None"
                },
                "termination": {
                    "max_debug_budget": 0,
                    "max_failed_rounds": 3,
                    "max_total_budget": 0
                },
                "agent_weights": {
                    "DESIGN_PROPOSER": [
                        0.05,
                        0.0,
                        0.6000000000000001,
                        0.2,
                        0.15
                    ],
                    "IMPLEMENTATION_PLANNER": [
                        0.05000000000000002,
                        0.0,
                        0.44999999999999996,
                        0.3,
                        0.20000000000000007
                    ],
                    "IMPLEMENTATION_CODER": [
                        0.0,
                        0.0,
                        0.3,
                        0.4999999999999996,
                        0.2
                    ],
                    "PROPOSAL_REVIEWER": [
                        0.10000000000000002,
                        0.0,
                        0.5499999999999999,
                        0.2,
                        0.15000000000000002
                    ],
                    "IMPLEMENTATION_OBSERVER": [
                        0.05,
                        0.0,
                        0.15000000000000002,
                        0.15000000000000002,
                        0.6499999999999999,
                        0.0
                    ]
                },
                "num_samples": {
                    "implementation": 1,
                    "rerank_method": "rating",
                    "proposal": 1
                },
                "search_settings": {
                    "proposal_search": true,
                    "proposal_review_search": true,
                    "search_for_papers_num": 10
                },
                "max_attempts": {
                    "post_refinement": 0,
                    "max_search_rounds": 4,
                    "implementation_debug": 5,
                    "design_proposal": 5
                }
            },
            "costs": {
                "DESIGN_PROPOSER": 0,
                "IMPLEMENTATION_PLANNER": 0.136131,
                "IMPLEMENTATION_CODER": 2.01471,
                "PROPOSAL_REVIEWER": 0,
                "IMPLEMENTATION_OBSERVER": 1.73007,
                "SEARCH_ASSISTANT": 0
            }
        }
    ]
}