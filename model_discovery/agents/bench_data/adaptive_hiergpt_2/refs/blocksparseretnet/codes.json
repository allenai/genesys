{
    "31M": {
        "31M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RetNet(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nfrom torchtune.modules import RMSNorm\n\n\nclass RetNet(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, norm_eps: float=1e-06, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = RMSNorm(self.hidden_size, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.attn = MultiScaleRetention(embed_dim=self.embed_dim, block_loc\n            =self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.mlp_norm = RMSNorm(self.hidden_size, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.mlp = RetNetMLP(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        hidden_states = self.attn_norm(X)\n        X = self.attn(hidden_states, **Z)[0] + X\n        hidden_states = self.mlp_norm(X)\n        X = self.mlp(hidden_states, **Z)[0] + X\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom transformers.activations import ACT2FN\nfrom einops import rearrange, repeat\nfrom torchtune.modules import RotaryPositionalEmbeddings, RMSNorm\n\n\nclass MultiScaleRetention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_size=None, num_heads: int=8,\n        norm_eps: float=1e-05, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        hidden_size = hidden_size if hidden_size is not None else embed_dim\n        self.hidden_size = hidden_size\n        self.num_heads = num_heads\n        self.num_kv_heads = num_heads\n        self.num_kv_groups = self.num_heads // self.num_kv_heads\n        self.key_dim = hidden_size\n        self.value_dim = hidden_size * 2\n        self.key_dim_per_group = self.key_dim // self.num_kv_groups\n        self.value_dim_per_group = self.value_dim // self.num_kv_groups\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.q_proj = nn.Linear(hidden_size, self.key_dim, bias=False,\n            device=device, dtype=dtype)\n        self.k_proj = nn.Linear(hidden_size, self.key_dim_per_group, bias=\n            False, device=device, dtype=dtype)\n        self.v_proj = nn.Linear(hidden_size, self.value_dim_per_group, bias\n            =False, device=device, dtype=dtype)\n        self.g_proj = nn.Linear(hidden_size, self.value_dim, bias=False,\n            device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, hidden_size, bias=False,\n            device=device, dtype=dtype)\n        self.g_norm = RMSNorm(self.head_v_dim, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.gate_fn = ACT2FN['swish']\n        self.rotary = RotaryPositionalEmbeddings(dim=self.head_qk_dim).to(\n            device=device, dtype=dtype)\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        module._is_hf_initialized = True\n\n    def naive_retention(self, q, k, v):\n        orig_type = q.dtype\n        q, k, v = q.float(), k.float(), v.float()\n        _, n_heads, seq_len, d_head = q.shape\n        s = (1 - q.new_tensor(2.0, dtype=torch.float).pow(-5.0 - q.\n            new_tensor(range(n_heads), dtype=torch.float))).log2()\n        n = q.new_tensor(range(seq_len), dtype=torch.float)\n        n = torch.exp2((n.unsqueeze(-1) - n) * s.view(-1, 1, 1)) * n.unsqueeze(\n            -1).ge(n)\n        s = torch.einsum('bhqd,bhkd,hqk->bhqk', q * d_head ** -0.5, k, n.to\n            (q.dtype))\n        o = torch.einsum('bhqk,bhkd->bhqd', s, v)\n        return o.to(orig_type)\n\n    def _forward(self, X, **Z):\n        q = self.q_proj(X)\n        k = self.k_proj(X)\n        v = self.v_proj(X)\n        q = rearrange(q, '... (h d) -> ... h d', h=self.num_heads)\n        k = rearrange(k, '... (h d) -> ... h d', h=self.num_kv_heads)\n        q = self.rotary(q)\n        k = self.rotary(k)\n        q = q.transpose(1, 2)\n        if self.num_kv_groups > 1:\n            k = repeat(k, 'b t h d -> b (h g) t d', h=self.num_kv_heads, g=\n                self.num_kv_groups)\n            v = repeat(v, 'b t (h d) -> b (h g) t d', h=self.num_kv_heads,\n                g=self.num_kv_groups)\n        else:\n            k, v = rearrange(k, 'b t h d -> b h t d'), rearrange(v,\n                'b t (h d) -> b h t d', h=self.num_kv_heads)\n        o = self.naive_retention(q, k, v)\n        o = rearrange(o, 'b h l d -> b l h d')\n        g = self.g_proj(X)\n        o = rearrange(self.g_norm(o), 'b l h d -> b l (h d)')\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        return o\n\n\nimport torch.nn.functional as F\n\n\nclass RetNetMLP(GAUBase):\n    \"\"\"\n    RetNet MLP with Block Sparse Computation and Adaptive Granularity.\n\n    This GAU implements a Block Sparse MLP that adaptively selects block sizes based on input complexity.\n    It leverages block-based sparse computation for efficient processing, especially for long sequences.\n\n    **Core Components:**\n\n    - **BlockSizeSelector**: Dynamically selects block sizes based on input complexity.\n    - **BlockSparseUnit**: Processes inputs using block-based sparsity patterns with the selected block size.\n\n    Args:\n        embed_dim (int): The embedding dimension of the input.\n        block_loc (tuple): The location of this block within the network (layer_idx, n_block).\n        kwarg_all (dict): Dictionary of all keyword arguments.\n\n    Example:\n\n        >>> mlp = RetNetMLP(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> Y, Z = mlp(X)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_size=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        hidden_size = hidden_size if hidden_size is not None else embed_dim\n        self.hidden_size = hidden_size\n        kwarg_all = kwarg_all.copy()\n        kwarg_all.update(kwargs)\n        self.block_size_selector = BlockSizeSelector(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n        self.block_sparse_unit = BlockSparseUnit(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        _, Z_bs = self.block_size_selector(X, **Z)\n        Z.update(Z_bs)\n        block_size = Z.get('block_size', None)\n        if block_size is None:\n            block_size = 32\n        Z['block_size'] = block_size\n        Y, Z_sbu = self.block_sparse_unit(X, **Z)\n        Z.update(Z_sbu)\n        return Y, Z\n\n\nimport torch.nn.functional as F\n\n\nclass BlockSizeSelector(GAUBase):\n    \"\"\"\n    BlockSizeSelector\n\n    Dynamically selects block sizes based on input complexity using a parameter-free heuristic.\n\n    **Key Components**:\n    - **Selection Heuristic**: Selects the block size based on the complexity of the input sequence without trainable parameters.\n\n    **Inputs**:\n        - X (torch.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n\n    **Outputs**:\n        - Z (dict): Contains 'block_size' (int)\n\n    **Example**:\n\n        >>> selector = BlockSizeSelector(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> _, Z = selector(X)\n        >>> block_size = Z.get('block_size', None)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, block_sizes=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        if block_sizes is None:\n            block_sizes = [16, 32, 64]\n        self.block_sizes = block_sizes\n        self.embed_dim = embed_dim\n\n    def _forward(self, X, **Z):\n        complexity = X.abs().mean(dim=(1, 2))\n        complexity_normalized = (complexity - complexity.min()) / (\n            complexity.max() - complexity.min() + 1e-06)\n        idxs = (complexity_normalized * (len(self.block_sizes) - 1)).long()\n        idxs = idxs.clamp(0, len(self.block_sizes) - 1)\n        selected_block_sizes = [self.block_sizes[idx.item()] for idx in idxs]\n        block_size = max(set(selected_block_sizes), key=\n            selected_block_sizes.count)\n        Z_ = {'block_size': block_size}\n        return X, Z_\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom typing import Optional\n\n\nclass BlockSparseUnit(GAUBase):\n    \"\"\"\n    BlockSparseUnit\n\n    This GAU processes input X using block-based sparsity patterns with a given block_size.\n\n    It utilizes a block-based sparse computation which is hardware-efficient and allows adaptive granularity.\n\n    **Key Components**:\n\n    - **Block Formation**: Splits the input sequence into blocks of size block_size.\n    - **Sparse Computation**: Applies block-wise operations exploiting sparsity.\n\n    **Inputs**:\n        - X (torch.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n        - block_size (int): The size of each block, specifying the granularity of sparsity.\n\n    **Outputs**:\n        - Y (torch.Tensor): Output tensor of the same shape as X.\n\n    **Example**:\n\n        >>> bs_unit = BlockSparseUnit(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> Z = {'block_size': 32}\n        >>> Y, Z = bs_unit(X, **Z)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, min_density: float=0.1, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.min_density = min_density\n        self.ffn = nn.Sequential(nn.Linear(self.hidden_size, self.\n            hidden_size * 4, device=device, dtype=dtype), nn.ReLU(), nn.\n            Linear(self.hidden_size * 4, self.hidden_size, device=device,\n            dtype=dtype))\n\n    def _forward(self, X, **Z):\n        block_size = Z.get('block_size')\n        if block_size is None:\n            block_size = 32\n        batch_size, seq_len, embed_dim = X.shape\n        pad_len = (seq_len + block_size - 1\n            ) // block_size * block_size - seq_len\n        X_padded = F.pad(X, (0, 0, 0, pad_len))\n        seq_len_padded = X_padded.shape[1]\n        num_blocks = seq_len_padded // block_size\n        X_blocks = X_padded.view(batch_size, num_blocks, block_size, embed_dim)\n        block_scores = X_blocks.abs().mean(dim=(2, 3))\n        threshold = block_scores.mean() * self.min_density\n        block_mask = block_scores > threshold\n        Z['block_scores'] = block_scores\n        Z['block_mask'] = block_mask\n        X_blocks_reshaped = X_blocks.view(-1, block_size, embed_dim)\n        block_mask_flat = block_mask.view(-1)\n        Y_blocks = X_blocks_reshaped.clone()\n        if block_mask_flat.any():\n            X_blocks_to_process = X_blocks_reshaped[block_mask_flat]\n            Y_blocks_processed = self.ffn(X_blocks_to_process)\n            Y_blocks[block_mask_flat] = Y_blocks_processed\n        Y_blocks = Y_blocks.view(batch_size, num_blocks, block_size, embed_dim)\n        Y_padded = Y_blocks.reshape(batch_size, seq_len_padded, embed_dim)\n        Y = Y_padded[:, :seq_len, :]\n        return Y, Z\n\n\ngab_config = {'hidden_size': None, 'norm_eps': 1e-06, 'num_heads': 8,\n    'min_density': 0.1, 'block_sizes': None}\n\n\n\nautoconfig={}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "760M": {
        "760M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RetNet(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nfrom torchtune.modules import RMSNorm\n\n\nclass RetNet(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, norm_eps: float=1e-06, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = RMSNorm(self.hidden_size, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.attn = MultiScaleRetention(embed_dim=self.embed_dim, block_loc\n            =self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.mlp_norm = RMSNorm(self.hidden_size, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.mlp = RetNetMLP(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        hidden_states = self.attn_norm(X)\n        X = self.attn(hidden_states, **Z)[0] + X\n        hidden_states = self.mlp_norm(X)\n        X = self.mlp(hidden_states, **Z)[0] + X\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom transformers.activations import ACT2FN\nfrom einops import rearrange, repeat\nfrom torchtune.modules import RotaryPositionalEmbeddings, RMSNorm\n\n\nclass MultiScaleRetention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_size=None, num_heads: int=8,\n        norm_eps: float=1e-05, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        hidden_size = hidden_size if hidden_size is not None else embed_dim\n        self.hidden_size = hidden_size\n        self.num_heads = num_heads\n        self.num_kv_heads = num_heads\n        self.num_kv_groups = self.num_heads // self.num_kv_heads\n        self.key_dim = hidden_size\n        self.value_dim = hidden_size * 2\n        self.key_dim_per_group = self.key_dim // self.num_kv_groups\n        self.value_dim_per_group = self.value_dim // self.num_kv_groups\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.q_proj = nn.Linear(hidden_size, self.key_dim, bias=False,\n            device=device, dtype=dtype)\n        self.k_proj = nn.Linear(hidden_size, self.key_dim_per_group, bias=\n            False, device=device, dtype=dtype)\n        self.v_proj = nn.Linear(hidden_size, self.value_dim_per_group, bias\n            =False, device=device, dtype=dtype)\n        self.g_proj = nn.Linear(hidden_size, self.value_dim, bias=False,\n            device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, hidden_size, bias=False,\n            device=device, dtype=dtype)\n        self.g_norm = RMSNorm(self.head_v_dim, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.gate_fn = ACT2FN['swish']\n        self.rotary = RotaryPositionalEmbeddings(dim=self.head_qk_dim).to(\n            device=device, dtype=dtype)\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        module._is_hf_initialized = True\n\n    def naive_retention(self, q, k, v):\n        orig_type = q.dtype\n        q, k, v = q.float(), k.float(), v.float()\n        _, n_heads, seq_len, d_head = q.shape\n        s = (1 - q.new_tensor(2.0, dtype=torch.float).pow(-5.0 - q.\n            new_tensor(range(n_heads), dtype=torch.float))).log2()\n        n = q.new_tensor(range(seq_len), dtype=torch.float)\n        n = torch.exp2((n.unsqueeze(-1) - n) * s.view(-1, 1, 1)) * n.unsqueeze(\n            -1).ge(n)\n        s = torch.einsum('bhqd,bhkd,hqk->bhqk', q * d_head ** -0.5, k, n.to\n            (q.dtype))\n        o = torch.einsum('bhqk,bhkd->bhqd', s, v)\n        return o.to(orig_type)\n\n    def _forward(self, X, **Z):\n        q = self.q_proj(X)\n        k = self.k_proj(X)\n        v = self.v_proj(X)\n        q = rearrange(q, '... (h d) -> ... h d', h=self.num_heads)\n        k = rearrange(k, '... (h d) -> ... h d', h=self.num_kv_heads)\n        q = self.rotary(q)\n        k = self.rotary(k)\n        q = q.transpose(1, 2)\n        if self.num_kv_groups > 1:\n            k = repeat(k, 'b t h d -> b (h g) t d', h=self.num_kv_heads, g=\n                self.num_kv_groups)\n            v = repeat(v, 'b t (h d) -> b (h g) t d', h=self.num_kv_heads,\n                g=self.num_kv_groups)\n        else:\n            k, v = rearrange(k, 'b t h d -> b h t d'), rearrange(v,\n                'b t (h d) -> b h t d', h=self.num_kv_heads)\n        o = self.naive_retention(q, k, v)\n        o = rearrange(o, 'b h l d -> b l h d')\n        g = self.g_proj(X)\n        o = rearrange(self.g_norm(o), 'b l h d -> b l (h d)')\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        return o\n\n\nimport torch.nn.functional as F\n\n\nclass RetNetMLP(GAUBase):\n    \"\"\"\n    RetNet MLP with Block Sparse Computation and Adaptive Granularity.\n\n    This GAU implements a Block Sparse MLP that adaptively selects block sizes based on input complexity.\n    It leverages block-based sparse computation for efficient processing, especially for long sequences.\n\n    **Core Components:**\n\n    - **BlockSizeSelector**: Dynamically selects block sizes based on input complexity.\n    - **BlockSparseUnit**: Processes inputs using block-based sparsity patterns with the selected block size.\n\n    Args:\n        embed_dim (int): The embedding dimension of the input.\n        block_loc (tuple): The location of this block within the network (layer_idx, n_block).\n        kwarg_all (dict): Dictionary of all keyword arguments.\n\n    Example:\n\n        >>> mlp = RetNetMLP(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> Y, Z = mlp(X)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_size=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        hidden_size = hidden_size if hidden_size is not None else embed_dim\n        self.hidden_size = hidden_size\n        kwarg_all = kwarg_all.copy()\n        kwarg_all.update(kwargs)\n        self.block_size_selector = BlockSizeSelector(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n        self.block_sparse_unit = BlockSparseUnit(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        _, Z_bs = self.block_size_selector(X, **Z)\n        Z.update(Z_bs)\n        block_size = Z.get('block_size', None)\n        if block_size is None:\n            block_size = 32\n        Z['block_size'] = block_size\n        Y, Z_sbu = self.block_sparse_unit(X, **Z)\n        Z.update(Z_sbu)\n        return Y, Z\n\n\nimport torch.nn.functional as F\n\n\nclass BlockSizeSelector(GAUBase):\n    \"\"\"\n    BlockSizeSelector\n\n    Dynamically selects block sizes based on input complexity using a parameter-free heuristic.\n\n    **Key Components**:\n    - **Selection Heuristic**: Selects the block size based on the complexity of the input sequence without trainable parameters.\n\n    **Inputs**:\n        - X (torch.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n\n    **Outputs**:\n        - Z (dict): Contains 'block_size' (int)\n\n    **Example**:\n\n        >>> selector = BlockSizeSelector(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> _, Z = selector(X)\n        >>> block_size = Z.get('block_size', None)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, block_sizes=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        if block_sizes is None:\n            block_sizes = [16, 32, 64]\n        self.block_sizes = block_sizes\n        self.embed_dim = embed_dim\n\n    def _forward(self, X, **Z):\n        complexity = X.abs().mean(dim=(1, 2))\n        complexity_normalized = (complexity - complexity.min()) / (\n            complexity.max() - complexity.min() + 1e-06)\n        idxs = (complexity_normalized * (len(self.block_sizes) - 1)).long()\n        idxs = idxs.clamp(0, len(self.block_sizes) - 1)\n        selected_block_sizes = [self.block_sizes[idx.item()] for idx in idxs]\n        block_size = max(set(selected_block_sizes), key=\n            selected_block_sizes.count)\n        Z_ = {'block_size': block_size}\n        return X, Z_\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom typing import Optional\n\n\nclass BlockSparseUnit(GAUBase):\n    \"\"\"\n    BlockSparseUnit\n\n    This GAU processes input X using block-based sparsity patterns with a given block_size.\n\n    It utilizes a block-based sparse computation which is hardware-efficient and allows adaptive granularity.\n\n    **Key Components**:\n\n    - **Block Formation**: Splits the input sequence into blocks of size block_size.\n    - **Sparse Computation**: Applies block-wise operations exploiting sparsity.\n\n    **Inputs**:\n        - X (torch.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n        - block_size (int): The size of each block, specifying the granularity of sparsity.\n\n    **Outputs**:\n        - Y (torch.Tensor): Output tensor of the same shape as X.\n\n    **Example**:\n\n        >>> bs_unit = BlockSparseUnit(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> Z = {'block_size': 32}\n        >>> Y, Z = bs_unit(X, **Z)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, min_density: float=0.1, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.min_density = min_density\n        self.ffn = nn.Sequential(nn.Linear(self.hidden_size, self.\n            hidden_size * 4, device=device, dtype=dtype), nn.ReLU(), nn.\n            Linear(self.hidden_size * 4, self.hidden_size, device=device,\n            dtype=dtype))\n\n    def _forward(self, X, **Z):\n        block_size = Z.get('block_size')\n        if block_size is None:\n            block_size = 32\n        batch_size, seq_len, embed_dim = X.shape\n        pad_len = (seq_len + block_size - 1\n            ) // block_size * block_size - seq_len\n        X_padded = F.pad(X, (0, 0, 0, pad_len))\n        seq_len_padded = X_padded.shape[1]\n        num_blocks = seq_len_padded // block_size\n        X_blocks = X_padded.view(batch_size, num_blocks, block_size, embed_dim)\n        block_scores = X_blocks.abs().mean(dim=(2, 3))\n        threshold = block_scores.mean() * self.min_density\n        block_mask = block_scores > threshold\n        Z['block_scores'] = block_scores\n        Z['block_mask'] = block_mask\n        X_blocks_reshaped = X_blocks.view(-1, block_size, embed_dim)\n        block_mask_flat = block_mask.view(-1)\n        Y_blocks = X_blocks_reshaped.clone()\n        if block_mask_flat.any():\n            X_blocks_to_process = X_blocks_reshaped[block_mask_flat]\n            Y_blocks_processed = self.ffn(X_blocks_to_process)\n            Y_blocks[block_mask_flat] = Y_blocks_processed\n        Y_blocks = Y_blocks.view(batch_size, num_blocks, block_size, embed_dim)\n        Y_padded = Y_blocks.reshape(batch_size, seq_len_padded, embed_dim)\n        Y = Y_padded[:, :seq_len, :]\n        return Y, Z\n\n\ngab_config = {'hidden_size': None, 'norm_eps': 1e-06, 'num_heads': 8,\n    'min_density': 0.1, 'block_sizes': None}\n\n\n\nautoconfig = {\n    'd_model': 768,\n    'n_block': 60\n}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "70M": {
        "70M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RetNet(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nfrom torchtune.modules import RMSNorm\n\n\nclass RetNet(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, norm_eps: float=1e-06, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = RMSNorm(self.hidden_size, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.attn = MultiScaleRetention(embed_dim=self.embed_dim, block_loc\n            =self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.mlp_norm = RMSNorm(self.hidden_size, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.mlp = RetNetMLP(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        hidden_states = self.attn_norm(X)\n        X = self.attn(hidden_states, **Z)[0] + X\n        hidden_states = self.mlp_norm(X)\n        X = self.mlp(hidden_states, **Z)[0] + X\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom transformers.activations import ACT2FN\nfrom einops import rearrange, repeat\nfrom torchtune.modules import RotaryPositionalEmbeddings, RMSNorm\n\n\nclass MultiScaleRetention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_size=None, num_heads: int=8,\n        norm_eps: float=1e-05, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        hidden_size = hidden_size if hidden_size is not None else embed_dim\n        self.hidden_size = hidden_size\n        self.num_heads = num_heads\n        self.num_kv_heads = num_heads\n        self.num_kv_groups = self.num_heads // self.num_kv_heads\n        self.key_dim = hidden_size\n        self.value_dim = hidden_size * 2\n        self.key_dim_per_group = self.key_dim // self.num_kv_groups\n        self.value_dim_per_group = self.value_dim // self.num_kv_groups\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.q_proj = nn.Linear(hidden_size, self.key_dim, bias=False,\n            device=device, dtype=dtype)\n        self.k_proj = nn.Linear(hidden_size, self.key_dim_per_group, bias=\n            False, device=device, dtype=dtype)\n        self.v_proj = nn.Linear(hidden_size, self.value_dim_per_group, bias\n            =False, device=device, dtype=dtype)\n        self.g_proj = nn.Linear(hidden_size, self.value_dim, bias=False,\n            device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, hidden_size, bias=False,\n            device=device, dtype=dtype)\n        self.g_norm = RMSNorm(self.head_v_dim, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.gate_fn = ACT2FN['swish']\n        self.rotary = RotaryPositionalEmbeddings(dim=self.head_qk_dim).to(\n            device=device, dtype=dtype)\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        module._is_hf_initialized = True\n\n    def naive_retention(self, q, k, v):\n        orig_type = q.dtype\n        q, k, v = q.float(), k.float(), v.float()\n        _, n_heads, seq_len, d_head = q.shape\n        s = (1 - q.new_tensor(2.0, dtype=torch.float).pow(-5.0 - q.\n            new_tensor(range(n_heads), dtype=torch.float))).log2()\n        n = q.new_tensor(range(seq_len), dtype=torch.float)\n        n = torch.exp2((n.unsqueeze(-1) - n) * s.view(-1, 1, 1)) * n.unsqueeze(\n            -1).ge(n)\n        s = torch.einsum('bhqd,bhkd,hqk->bhqk', q * d_head ** -0.5, k, n.to\n            (q.dtype))\n        o = torch.einsum('bhqk,bhkd->bhqd', s, v)\n        return o.to(orig_type)\n\n    def _forward(self, X, **Z):\n        q = self.q_proj(X)\n        k = self.k_proj(X)\n        v = self.v_proj(X)\n        q = rearrange(q, '... (h d) -> ... h d', h=self.num_heads)\n        k = rearrange(k, '... (h d) -> ... h d', h=self.num_kv_heads)\n        q = self.rotary(q)\n        k = self.rotary(k)\n        q = q.transpose(1, 2)\n        if self.num_kv_groups > 1:\n            k = repeat(k, 'b t h d -> b (h g) t d', h=self.num_kv_heads, g=\n                self.num_kv_groups)\n            v = repeat(v, 'b t (h d) -> b (h g) t d', h=self.num_kv_heads,\n                g=self.num_kv_groups)\n        else:\n            k, v = rearrange(k, 'b t h d -> b h t d'), rearrange(v,\n                'b t (h d) -> b h t d', h=self.num_kv_heads)\n        o = self.naive_retention(q, k, v)\n        o = rearrange(o, 'b h l d -> b l h d')\n        g = self.g_proj(X)\n        o = rearrange(self.g_norm(o), 'b l h d -> b l (h d)')\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        return o\n\n\nimport torch.nn.functional as F\n\n\nclass RetNetMLP(GAUBase):\n    \"\"\"\n    RetNet MLP with Block Sparse Computation and Adaptive Granularity.\n\n    This GAU implements a Block Sparse MLP that adaptively selects block sizes based on input complexity.\n    It leverages block-based sparse computation for efficient processing, especially for long sequences.\n\n    **Core Components:**\n\n    - **BlockSizeSelector**: Dynamically selects block sizes based on input complexity.\n    - **BlockSparseUnit**: Processes inputs using block-based sparsity patterns with the selected block size.\n\n    Args:\n        embed_dim (int): The embedding dimension of the input.\n        block_loc (tuple): The location of this block within the network (layer_idx, n_block).\n        kwarg_all (dict): Dictionary of all keyword arguments.\n\n    Example:\n\n        >>> mlp = RetNetMLP(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> Y, Z = mlp(X)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_size=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        hidden_size = hidden_size if hidden_size is not None else embed_dim\n        self.hidden_size = hidden_size\n        kwarg_all = kwarg_all.copy()\n        kwarg_all.update(kwargs)\n        self.block_size_selector = BlockSizeSelector(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n        self.block_sparse_unit = BlockSparseUnit(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        _, Z_bs = self.block_size_selector(X, **Z)\n        Z.update(Z_bs)\n        block_size = Z.get('block_size', None)\n        if block_size is None:\n            block_size = 32\n        Z['block_size'] = block_size\n        Y, Z_sbu = self.block_sparse_unit(X, **Z)\n        Z.update(Z_sbu)\n        return Y, Z\n\n\nimport torch.nn.functional as F\n\n\nclass BlockSizeSelector(GAUBase):\n    \"\"\"\n    BlockSizeSelector\n\n    Dynamically selects block sizes based on input complexity using a parameter-free heuristic.\n\n    **Key Components**:\n    - **Selection Heuristic**: Selects the block size based on the complexity of the input sequence without trainable parameters.\n\n    **Inputs**:\n        - X (torch.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n\n    **Outputs**:\n        - Z (dict): Contains 'block_size' (int)\n\n    **Example**:\n\n        >>> selector = BlockSizeSelector(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> _, Z = selector(X)\n        >>> block_size = Z.get('block_size', None)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, block_sizes=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        if block_sizes is None:\n            block_sizes = [16, 32, 64]\n        self.block_sizes = block_sizes\n        self.embed_dim = embed_dim\n\n    def _forward(self, X, **Z):\n        complexity = X.abs().mean(dim=(1, 2))\n        complexity_normalized = (complexity - complexity.min()) / (\n            complexity.max() - complexity.min() + 1e-06)\n        idxs = (complexity_normalized * (len(self.block_sizes) - 1)).long()\n        idxs = idxs.clamp(0, len(self.block_sizes) - 1)\n        selected_block_sizes = [self.block_sizes[idx.item()] for idx in idxs]\n        block_size = max(set(selected_block_sizes), key=\n            selected_block_sizes.count)\n        Z_ = {'block_size': block_size}\n        return X, Z_\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom typing import Optional\n\n\nclass BlockSparseUnit(GAUBase):\n    \"\"\"\n    BlockSparseUnit\n\n    This GAU processes input X using block-based sparsity patterns with a given block_size.\n\n    It utilizes a block-based sparse computation which is hardware-efficient and allows adaptive granularity.\n\n    **Key Components**:\n\n    - **Block Formation**: Splits the input sequence into blocks of size block_size.\n    - **Sparse Computation**: Applies block-wise operations exploiting sparsity.\n\n    **Inputs**:\n        - X (torch.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n        - block_size (int): The size of each block, specifying the granularity of sparsity.\n\n    **Outputs**:\n        - Y (torch.Tensor): Output tensor of the same shape as X.\n\n    **Example**:\n\n        >>> bs_unit = BlockSparseUnit(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> Z = {'block_size': 32}\n        >>> Y, Z = bs_unit(X, **Z)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, min_density: float=0.1, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.min_density = min_density\n        self.ffn = nn.Sequential(nn.Linear(self.hidden_size, self.\n            hidden_size * 4, device=device, dtype=dtype), nn.ReLU(), nn.\n            Linear(self.hidden_size * 4, self.hidden_size, device=device,\n            dtype=dtype))\n\n    def _forward(self, X, **Z):\n        block_size = Z.get('block_size')\n        if block_size is None:\n            block_size = 32\n        batch_size, seq_len, embed_dim = X.shape\n        pad_len = (seq_len + block_size - 1\n            ) // block_size * block_size - seq_len\n        X_padded = F.pad(X, (0, 0, 0, pad_len))\n        seq_len_padded = X_padded.shape[1]\n        num_blocks = seq_len_padded // block_size\n        X_blocks = X_padded.view(batch_size, num_blocks, block_size, embed_dim)\n        block_scores = X_blocks.abs().mean(dim=(2, 3))\n        threshold = block_scores.mean() * self.min_density\n        block_mask = block_scores > threshold\n        Z['block_scores'] = block_scores\n        Z['block_mask'] = block_mask\n        X_blocks_reshaped = X_blocks.view(-1, block_size, embed_dim)\n        block_mask_flat = block_mask.view(-1)\n        Y_blocks = X_blocks_reshaped.clone()\n        if block_mask_flat.any():\n            X_blocks_to_process = X_blocks_reshaped[block_mask_flat]\n            Y_blocks_processed = self.ffn(X_blocks_to_process)\n            Y_blocks[block_mask_flat] = Y_blocks_processed\n        Y_blocks = Y_blocks.view(batch_size, num_blocks, block_size, embed_dim)\n        Y_padded = Y_blocks.reshape(batch_size, seq_len_padded, embed_dim)\n        Y = Y_padded[:, :seq_len, :]\n        return Y, Z\n\n\ngab_config = {'hidden_size': None, 'norm_eps': 1e-06, 'num_heads': 8,\n    'min_density': 0.1, 'block_sizes': None}\n\n\n\nautoconfig={}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "1300M": {
        "1300M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RetNet(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nfrom torchtune.modules import RMSNorm\n\n\nclass RetNet(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, norm_eps: float=1e-06, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = RMSNorm(self.hidden_size, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.attn = MultiScaleRetention(embed_dim=self.embed_dim, block_loc\n            =self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.mlp_norm = RMSNorm(self.hidden_size, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.mlp = RetNetMLP(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        hidden_states = self.attn_norm(X)\n        X = self.attn(hidden_states, **Z)[0] + X\n        hidden_states = self.mlp_norm(X)\n        X = self.mlp(hidden_states, **Z)[0] + X\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom transformers.activations import ACT2FN\nfrom einops import rearrange, repeat\nfrom torchtune.modules import RotaryPositionalEmbeddings, RMSNorm\n\n\nclass MultiScaleRetention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_size=None, num_heads: int=8,\n        norm_eps: float=1e-05, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        hidden_size = hidden_size if hidden_size is not None else embed_dim\n        self.hidden_size = hidden_size\n        self.num_heads = num_heads\n        self.num_kv_heads = num_heads\n        self.num_kv_groups = self.num_heads // self.num_kv_heads\n        self.key_dim = hidden_size\n        self.value_dim = hidden_size * 2\n        self.key_dim_per_group = self.key_dim // self.num_kv_groups\n        self.value_dim_per_group = self.value_dim // self.num_kv_groups\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.q_proj = nn.Linear(hidden_size, self.key_dim, bias=False,\n            device=device, dtype=dtype)\n        self.k_proj = nn.Linear(hidden_size, self.key_dim_per_group, bias=\n            False, device=device, dtype=dtype)\n        self.v_proj = nn.Linear(hidden_size, self.value_dim_per_group, bias\n            =False, device=device, dtype=dtype)\n        self.g_proj = nn.Linear(hidden_size, self.value_dim, bias=False,\n            device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, hidden_size, bias=False,\n            device=device, dtype=dtype)\n        self.g_norm = RMSNorm(self.head_v_dim, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.gate_fn = ACT2FN['swish']\n        self.rotary = RotaryPositionalEmbeddings(dim=self.head_qk_dim).to(\n            device=device, dtype=dtype)\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        module._is_hf_initialized = True\n\n    def naive_retention(self, q, k, v):\n        orig_type = q.dtype\n        q, k, v = q.float(), k.float(), v.float()\n        _, n_heads, seq_len, d_head = q.shape\n        s = (1 - q.new_tensor(2.0, dtype=torch.float).pow(-5.0 - q.\n            new_tensor(range(n_heads), dtype=torch.float))).log2()\n        n = q.new_tensor(range(seq_len), dtype=torch.float)\n        n = torch.exp2((n.unsqueeze(-1) - n) * s.view(-1, 1, 1)) * n.unsqueeze(\n            -1).ge(n)\n        s = torch.einsum('bhqd,bhkd,hqk->bhqk', q * d_head ** -0.5, k, n.to\n            (q.dtype))\n        o = torch.einsum('bhqk,bhkd->bhqd', s, v)\n        return o.to(orig_type)\n\n    def _forward(self, X, **Z):\n        q = self.q_proj(X)\n        k = self.k_proj(X)\n        v = self.v_proj(X)\n        q = rearrange(q, '... (h d) -> ... h d', h=self.num_heads)\n        k = rearrange(k, '... (h d) -> ... h d', h=self.num_kv_heads)\n        q = self.rotary(q)\n        k = self.rotary(k)\n        q = q.transpose(1, 2)\n        if self.num_kv_groups > 1:\n            k = repeat(k, 'b t h d -> b (h g) t d', h=self.num_kv_heads, g=\n                self.num_kv_groups)\n            v = repeat(v, 'b t (h d) -> b (h g) t d', h=self.num_kv_heads,\n                g=self.num_kv_groups)\n        else:\n            k, v = rearrange(k, 'b t h d -> b h t d'), rearrange(v,\n                'b t (h d) -> b h t d', h=self.num_kv_heads)\n        o = self.naive_retention(q, k, v)\n        o = rearrange(o, 'b h l d -> b l h d')\n        g = self.g_proj(X)\n        o = rearrange(self.g_norm(o), 'b l h d -> b l (h d)')\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        return o\n\n\nimport torch.nn.functional as F\n\n\nclass RetNetMLP(GAUBase):\n    \"\"\"\n    RetNet MLP with Block Sparse Computation and Adaptive Granularity.\n\n    This GAU implements a Block Sparse MLP that adaptively selects block sizes based on input complexity.\n    It leverages block-based sparse computation for efficient processing, especially for long sequences.\n\n    **Core Components:**\n\n    - **BlockSizeSelector**: Dynamically selects block sizes based on input complexity.\n    - **BlockSparseUnit**: Processes inputs using block-based sparsity patterns with the selected block size.\n\n    Args:\n        embed_dim (int): The embedding dimension of the input.\n        block_loc (tuple): The location of this block within the network (layer_idx, n_block).\n        kwarg_all (dict): Dictionary of all keyword arguments.\n\n    Example:\n\n        >>> mlp = RetNetMLP(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> Y, Z = mlp(X)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_size=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        hidden_size = hidden_size if hidden_size is not None else embed_dim\n        self.hidden_size = hidden_size\n        kwarg_all = kwarg_all.copy()\n        kwarg_all.update(kwargs)\n        self.block_size_selector = BlockSizeSelector(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n        self.block_sparse_unit = BlockSparseUnit(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        _, Z_bs = self.block_size_selector(X, **Z)\n        Z.update(Z_bs)\n        block_size = Z.get('block_size', None)\n        if block_size is None:\n            block_size = 32\n        Z['block_size'] = block_size\n        Y, Z_sbu = self.block_sparse_unit(X, **Z)\n        Z.update(Z_sbu)\n        return Y, Z\n\n\nimport torch.nn.functional as F\n\n\nclass BlockSizeSelector(GAUBase):\n    \"\"\"\n    BlockSizeSelector\n\n    Dynamically selects block sizes based on input complexity using a parameter-free heuristic.\n\n    **Key Components**:\n    - **Selection Heuristic**: Selects the block size based on the complexity of the input sequence without trainable parameters.\n\n    **Inputs**:\n        - X (torch.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n\n    **Outputs**:\n        - Z (dict): Contains 'block_size' (int)\n\n    **Example**:\n\n        >>> selector = BlockSizeSelector(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> _, Z = selector(X)\n        >>> block_size = Z.get('block_size', None)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, block_sizes=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        if block_sizes is None:\n            block_sizes = [16, 32, 64]\n        self.block_sizes = block_sizes\n        self.embed_dim = embed_dim\n\n    def _forward(self, X, **Z):\n        complexity = X.abs().mean(dim=(1, 2))\n        complexity_normalized = (complexity - complexity.min()) / (\n            complexity.max() - complexity.min() + 1e-06)\n        idxs = (complexity_normalized * (len(self.block_sizes) - 1)).long()\n        idxs = idxs.clamp(0, len(self.block_sizes) - 1)\n        selected_block_sizes = [self.block_sizes[idx.item()] for idx in idxs]\n        block_size = max(set(selected_block_sizes), key=\n            selected_block_sizes.count)\n        Z_ = {'block_size': block_size}\n        return X, Z_\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom typing import Optional\n\n\nclass BlockSparseUnit(GAUBase):\n    \"\"\"\n    BlockSparseUnit\n\n    This GAU processes input X using block-based sparsity patterns with a given block_size.\n\n    It utilizes a block-based sparse computation which is hardware-efficient and allows adaptive granularity.\n\n    **Key Components**:\n\n    - **Block Formation**: Splits the input sequence into blocks of size block_size.\n    - **Sparse Computation**: Applies block-wise operations exploiting sparsity.\n\n    **Inputs**:\n        - X (torch.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n        - block_size (int): The size of each block, specifying the granularity of sparsity.\n\n    **Outputs**:\n        - Y (torch.Tensor): Output tensor of the same shape as X.\n\n    **Example**:\n\n        >>> bs_unit = BlockSparseUnit(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> Z = {'block_size': 32}\n        >>> Y, Z = bs_unit(X, **Z)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, min_density: float=0.1, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.min_density = min_density\n        self.ffn = nn.Sequential(nn.Linear(self.hidden_size, self.\n            hidden_size * 4, device=device, dtype=dtype), nn.ReLU(), nn.\n            Linear(self.hidden_size * 4, self.hidden_size, device=device,\n            dtype=dtype))\n\n    def _forward(self, X, **Z):\n        block_size = Z.get('block_size')\n        if block_size is None:\n            block_size = 32\n        batch_size, seq_len, embed_dim = X.shape\n        pad_len = (seq_len + block_size - 1\n            ) // block_size * block_size - seq_len\n        X_padded = F.pad(X, (0, 0, 0, pad_len))\n        seq_len_padded = X_padded.shape[1]\n        num_blocks = seq_len_padded // block_size\n        X_blocks = X_padded.view(batch_size, num_blocks, block_size, embed_dim)\n        block_scores = X_blocks.abs().mean(dim=(2, 3))\n        threshold = block_scores.mean() * self.min_density\n        block_mask = block_scores > threshold\n        Z['block_scores'] = block_scores\n        Z['block_mask'] = block_mask\n        X_blocks_reshaped = X_blocks.view(-1, block_size, embed_dim)\n        block_mask_flat = block_mask.view(-1)\n        Y_blocks = X_blocks_reshaped.clone()\n        if block_mask_flat.any():\n            X_blocks_to_process = X_blocks_reshaped[block_mask_flat]\n            Y_blocks_processed = self.ffn(X_blocks_to_process)\n            Y_blocks[block_mask_flat] = Y_blocks_processed\n        Y_blocks = Y_blocks.view(batch_size, num_blocks, block_size, embed_dim)\n        Y_padded = Y_blocks.reshape(batch_size, seq_len_padded, embed_dim)\n        Y = Y_padded[:, :seq_len, :]\n        return Y, Z\n\n\ngab_config = {'hidden_size': None, 'norm_eps': 1e-06, 'num_heads': 8,\n    'min_density': 0.1, 'block_sizes': None}\n\n\n\nautoconfig = {\n    'd_model': 1024,\n    'n_block': 59\n}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "125M": {
        "125M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RetNet(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nfrom torchtune.modules import RMSNorm\n\n\nclass RetNet(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, norm_eps: float=1e-06, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = RMSNorm(self.hidden_size, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.attn = MultiScaleRetention(embed_dim=self.embed_dim, block_loc\n            =self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.mlp_norm = RMSNorm(self.hidden_size, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.mlp = RetNetMLP(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        hidden_states = self.attn_norm(X)\n        X = self.attn(hidden_states, **Z)[0] + X\n        hidden_states = self.mlp_norm(X)\n        X = self.mlp(hidden_states, **Z)[0] + X\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom transformers.activations import ACT2FN\nfrom einops import rearrange, repeat\nfrom torchtune.modules import RotaryPositionalEmbeddings, RMSNorm\n\n\nclass MultiScaleRetention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_size=None, num_heads: int=8,\n        norm_eps: float=1e-05, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        hidden_size = hidden_size if hidden_size is not None else embed_dim\n        self.hidden_size = hidden_size\n        self.num_heads = num_heads\n        self.num_kv_heads = num_heads\n        self.num_kv_groups = self.num_heads // self.num_kv_heads\n        self.key_dim = hidden_size\n        self.value_dim = hidden_size * 2\n        self.key_dim_per_group = self.key_dim // self.num_kv_groups\n        self.value_dim_per_group = self.value_dim // self.num_kv_groups\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.q_proj = nn.Linear(hidden_size, self.key_dim, bias=False,\n            device=device, dtype=dtype)\n        self.k_proj = nn.Linear(hidden_size, self.key_dim_per_group, bias=\n            False, device=device, dtype=dtype)\n        self.v_proj = nn.Linear(hidden_size, self.value_dim_per_group, bias\n            =False, device=device, dtype=dtype)\n        self.g_proj = nn.Linear(hidden_size, self.value_dim, bias=False,\n            device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, hidden_size, bias=False,\n            device=device, dtype=dtype)\n        self.g_norm = RMSNorm(self.head_v_dim, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.gate_fn = ACT2FN['swish']\n        self.rotary = RotaryPositionalEmbeddings(dim=self.head_qk_dim).to(\n            device=device, dtype=dtype)\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        module._is_hf_initialized = True\n\n    def naive_retention(self, q, k, v):\n        orig_type = q.dtype\n        q, k, v = q.float(), k.float(), v.float()\n        _, n_heads, seq_len, d_head = q.shape\n        s = (1 - q.new_tensor(2.0, dtype=torch.float).pow(-5.0 - q.\n            new_tensor(range(n_heads), dtype=torch.float))).log2()\n        n = q.new_tensor(range(seq_len), dtype=torch.float)\n        n = torch.exp2((n.unsqueeze(-1) - n) * s.view(-1, 1, 1)) * n.unsqueeze(\n            -1).ge(n)\n        s = torch.einsum('bhqd,bhkd,hqk->bhqk', q * d_head ** -0.5, k, n.to\n            (q.dtype))\n        o = torch.einsum('bhqk,bhkd->bhqd', s, v)\n        return o.to(orig_type)\n\n    def _forward(self, X, **Z):\n        q = self.q_proj(X)\n        k = self.k_proj(X)\n        v = self.v_proj(X)\n        q = rearrange(q, '... (h d) -> ... h d', h=self.num_heads)\n        k = rearrange(k, '... (h d) -> ... h d', h=self.num_kv_heads)\n        q = self.rotary(q)\n        k = self.rotary(k)\n        q = q.transpose(1, 2)\n        if self.num_kv_groups > 1:\n            k = repeat(k, 'b t h d -> b (h g) t d', h=self.num_kv_heads, g=\n                self.num_kv_groups)\n            v = repeat(v, 'b t (h d) -> b (h g) t d', h=self.num_kv_heads,\n                g=self.num_kv_groups)\n        else:\n            k, v = rearrange(k, 'b t h d -> b h t d'), rearrange(v,\n                'b t (h d) -> b h t d', h=self.num_kv_heads)\n        o = self.naive_retention(q, k, v)\n        o = rearrange(o, 'b h l d -> b l h d')\n        g = self.g_proj(X)\n        o = rearrange(self.g_norm(o), 'b l h d -> b l (h d)')\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        return o\n\n\nimport torch.nn.functional as F\n\n\nclass RetNetMLP(GAUBase):\n    \"\"\"\n    RetNet MLP with Block Sparse Computation and Adaptive Granularity.\n\n    This GAU implements a Block Sparse MLP that adaptively selects block sizes based on input complexity.\n    It leverages block-based sparse computation for efficient processing, especially for long sequences.\n\n    **Core Components:**\n\n    - **BlockSizeSelector**: Dynamically selects block sizes based on input complexity.\n    - **BlockSparseUnit**: Processes inputs using block-based sparsity patterns with the selected block size.\n\n    Args:\n        embed_dim (int): The embedding dimension of the input.\n        block_loc (tuple): The location of this block within the network (layer_idx, n_block).\n        kwarg_all (dict): Dictionary of all keyword arguments.\n\n    Example:\n\n        >>> mlp = RetNetMLP(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> Y, Z = mlp(X)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_size=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        hidden_size = hidden_size if hidden_size is not None else embed_dim\n        self.hidden_size = hidden_size\n        kwarg_all = kwarg_all.copy()\n        kwarg_all.update(kwargs)\n        self.block_size_selector = BlockSizeSelector(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n        self.block_sparse_unit = BlockSparseUnit(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        _, Z_bs = self.block_size_selector(X, **Z)\n        Z.update(Z_bs)\n        block_size = Z.get('block_size', None)\n        if block_size is None:\n            block_size = 32\n        Z['block_size'] = block_size\n        Y, Z_sbu = self.block_sparse_unit(X, **Z)\n        Z.update(Z_sbu)\n        return Y, Z\n\n\nimport torch.nn.functional as F\n\n\nclass BlockSizeSelector(GAUBase):\n    \"\"\"\n    BlockSizeSelector\n\n    Dynamically selects block sizes based on input complexity using a parameter-free heuristic.\n\n    **Key Components**:\n    - **Selection Heuristic**: Selects the block size based on the complexity of the input sequence without trainable parameters.\n\n    **Inputs**:\n        - X (torch.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n\n    **Outputs**:\n        - Z (dict): Contains 'block_size' (int)\n\n    **Example**:\n\n        >>> selector = BlockSizeSelector(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> _, Z = selector(X)\n        >>> block_size = Z.get('block_size', None)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, block_sizes=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        if block_sizes is None:\n            block_sizes = [16, 32, 64]\n        self.block_sizes = block_sizes\n        self.embed_dim = embed_dim\n\n    def _forward(self, X, **Z):\n        complexity = X.abs().mean(dim=(1, 2))\n        complexity_normalized = (complexity - complexity.min()) / (\n            complexity.max() - complexity.min() + 1e-06)\n        idxs = (complexity_normalized * (len(self.block_sizes) - 1)).long()\n        idxs = idxs.clamp(0, len(self.block_sizes) - 1)\n        selected_block_sizes = [self.block_sizes[idx.item()] for idx in idxs]\n        block_size = max(set(selected_block_sizes), key=\n            selected_block_sizes.count)\n        Z_ = {'block_size': block_size}\n        return X, Z_\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom typing import Optional\n\n\nclass BlockSparseUnit(GAUBase):\n    \"\"\"\n    BlockSparseUnit\n\n    This GAU processes input X using block-based sparsity patterns with a given block_size.\n\n    It utilizes a block-based sparse computation which is hardware-efficient and allows adaptive granularity.\n\n    **Key Components**:\n\n    - **Block Formation**: Splits the input sequence into blocks of size block_size.\n    - **Sparse Computation**: Applies block-wise operations exploiting sparsity.\n\n    **Inputs**:\n        - X (torch.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n        - block_size (int): The size of each block, specifying the granularity of sparsity.\n\n    **Outputs**:\n        - Y (torch.Tensor): Output tensor of the same shape as X.\n\n    **Example**:\n\n        >>> bs_unit = BlockSparseUnit(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> Z = {'block_size': 32}\n        >>> Y, Z = bs_unit(X, **Z)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, min_density: float=0.1, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.min_density = min_density\n        self.ffn = nn.Sequential(nn.Linear(self.hidden_size, self.\n            hidden_size * 4, device=device, dtype=dtype), nn.ReLU(), nn.\n            Linear(self.hidden_size * 4, self.hidden_size, device=device,\n            dtype=dtype))\n\n    def _forward(self, X, **Z):\n        block_size = Z.get('block_size')\n        if block_size is None:\n            block_size = 32\n        batch_size, seq_len, embed_dim = X.shape\n        pad_len = (seq_len + block_size - 1\n            ) // block_size * block_size - seq_len\n        X_padded = F.pad(X, (0, 0, 0, pad_len))\n        seq_len_padded = X_padded.shape[1]\n        num_blocks = seq_len_padded // block_size\n        X_blocks = X_padded.view(batch_size, num_blocks, block_size, embed_dim)\n        block_scores = X_blocks.abs().mean(dim=(2, 3))\n        threshold = block_scores.mean() * self.min_density\n        block_mask = block_scores > threshold\n        Z['block_scores'] = block_scores\n        Z['block_mask'] = block_mask\n        X_blocks_reshaped = X_blocks.view(-1, block_size, embed_dim)\n        block_mask_flat = block_mask.view(-1)\n        Y_blocks = X_blocks_reshaped.clone()\n        if block_mask_flat.any():\n            X_blocks_to_process = X_blocks_reshaped[block_mask_flat]\n            Y_blocks_processed = self.ffn(X_blocks_to_process)\n            Y_blocks[block_mask_flat] = Y_blocks_processed\n        Y_blocks = Y_blocks.view(batch_size, num_blocks, block_size, embed_dim)\n        Y_padded = Y_blocks.reshape(batch_size, seq_len_padded, embed_dim)\n        Y = Y_padded[:, :seq_len, :]\n        return Y, Z\n\n\ngab_config = {'hidden_size': None, 'norm_eps': 1e-06, 'num_heads': 8,\n    'min_density': 0.1, 'block_sizes': None}\n\n\n\nautoconfig = {\n    'd_model': 384,\n    'n_block': 32\n}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "14M": {
        "14M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RetNet(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nfrom torchtune.modules import RMSNorm\n\n\nclass RetNet(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, norm_eps: float=1e-06, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = RMSNorm(self.hidden_size, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.attn = MultiScaleRetention(embed_dim=self.embed_dim, block_loc\n            =self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.mlp_norm = RMSNorm(self.hidden_size, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.mlp = RetNetMLP(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        hidden_states = self.attn_norm(X)\n        X = self.attn(hidden_states, **Z)[0] + X\n        hidden_states = self.mlp_norm(X)\n        X = self.mlp(hidden_states, **Z)[0] + X\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom transformers.activations import ACT2FN\nfrom einops import rearrange, repeat\nfrom torchtune.modules import RotaryPositionalEmbeddings, RMSNorm\n\n\nclass MultiScaleRetention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_size=None, num_heads: int=8,\n        norm_eps: float=1e-05, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        hidden_size = hidden_size if hidden_size is not None else embed_dim\n        self.hidden_size = hidden_size\n        self.num_heads = num_heads\n        self.num_kv_heads = num_heads\n        self.num_kv_groups = self.num_heads // self.num_kv_heads\n        self.key_dim = hidden_size\n        self.value_dim = hidden_size * 2\n        self.key_dim_per_group = self.key_dim // self.num_kv_groups\n        self.value_dim_per_group = self.value_dim // self.num_kv_groups\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.q_proj = nn.Linear(hidden_size, self.key_dim, bias=False,\n            device=device, dtype=dtype)\n        self.k_proj = nn.Linear(hidden_size, self.key_dim_per_group, bias=\n            False, device=device, dtype=dtype)\n        self.v_proj = nn.Linear(hidden_size, self.value_dim_per_group, bias\n            =False, device=device, dtype=dtype)\n        self.g_proj = nn.Linear(hidden_size, self.value_dim, bias=False,\n            device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, hidden_size, bias=False,\n            device=device, dtype=dtype)\n        self.g_norm = RMSNorm(self.head_v_dim, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.gate_fn = ACT2FN['swish']\n        self.rotary = RotaryPositionalEmbeddings(dim=self.head_qk_dim).to(\n            device=device, dtype=dtype)\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        module._is_hf_initialized = True\n\n    def naive_retention(self, q, k, v):\n        orig_type = q.dtype\n        q, k, v = q.float(), k.float(), v.float()\n        _, n_heads, seq_len, d_head = q.shape\n        s = (1 - q.new_tensor(2.0, dtype=torch.float).pow(-5.0 - q.\n            new_tensor(range(n_heads), dtype=torch.float))).log2()\n        n = q.new_tensor(range(seq_len), dtype=torch.float)\n        n = torch.exp2((n.unsqueeze(-1) - n) * s.view(-1, 1, 1)) * n.unsqueeze(\n            -1).ge(n)\n        s = torch.einsum('bhqd,bhkd,hqk->bhqk', q * d_head ** -0.5, k, n.to\n            (q.dtype))\n        o = torch.einsum('bhqk,bhkd->bhqd', s, v)\n        return o.to(orig_type)\n\n    def _forward(self, X, **Z):\n        q = self.q_proj(X)\n        k = self.k_proj(X)\n        v = self.v_proj(X)\n        q = rearrange(q, '... (h d) -> ... h d', h=self.num_heads)\n        k = rearrange(k, '... (h d) -> ... h d', h=self.num_kv_heads)\n        q = self.rotary(q)\n        k = self.rotary(k)\n        q = q.transpose(1, 2)\n        if self.num_kv_groups > 1:\n            k = repeat(k, 'b t h d -> b (h g) t d', h=self.num_kv_heads, g=\n                self.num_kv_groups)\n            v = repeat(v, 'b t (h d) -> b (h g) t d', h=self.num_kv_heads,\n                g=self.num_kv_groups)\n        else:\n            k, v = rearrange(k, 'b t h d -> b h t d'), rearrange(v,\n                'b t (h d) -> b h t d', h=self.num_kv_heads)\n        o = self.naive_retention(q, k, v)\n        o = rearrange(o, 'b h l d -> b l h d')\n        g = self.g_proj(X)\n        o = rearrange(self.g_norm(o), 'b l h d -> b l (h d)')\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        return o\n\n\nimport torch.nn.functional as F\n\n\nclass RetNetMLP(GAUBase):\n    \"\"\"\n    RetNet MLP with Block Sparse Computation and Adaptive Granularity.\n\n    This GAU implements a Block Sparse MLP that adaptively selects block sizes based on input complexity.\n    It leverages block-based sparse computation for efficient processing, especially for long sequences.\n\n    **Core Components:**\n\n    - **BlockSizeSelector**: Dynamically selects block sizes based on input complexity.\n    - **BlockSparseUnit**: Processes inputs using block-based sparsity patterns with the selected block size.\n\n    Args:\n        embed_dim (int): The embedding dimension of the input.\n        block_loc (tuple): The location of this block within the network (layer_idx, n_block).\n        kwarg_all (dict): Dictionary of all keyword arguments.\n\n    Example:\n\n        >>> mlp = RetNetMLP(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> Y, Z = mlp(X)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_size=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        hidden_size = hidden_size if hidden_size is not None else embed_dim\n        self.hidden_size = hidden_size\n        kwarg_all = kwarg_all.copy()\n        kwarg_all.update(kwargs)\n        self.block_size_selector = BlockSizeSelector(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n        self.block_sparse_unit = BlockSparseUnit(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        _, Z_bs = self.block_size_selector(X, **Z)\n        Z.update(Z_bs)\n        block_size = Z.get('block_size', None)\n        if block_size is None:\n            block_size = 32\n        Z['block_size'] = block_size\n        Y, Z_sbu = self.block_sparse_unit(X, **Z)\n        Z.update(Z_sbu)\n        return Y, Z\n\n\nimport torch.nn.functional as F\n\n\nclass BlockSizeSelector(GAUBase):\n    \"\"\"\n    BlockSizeSelector\n\n    Dynamically selects block sizes based on input complexity using a parameter-free heuristic.\n\n    **Key Components**:\n    - **Selection Heuristic**: Selects the block size based on the complexity of the input sequence without trainable parameters.\n\n    **Inputs**:\n        - X (torch.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n\n    **Outputs**:\n        - Z (dict): Contains 'block_size' (int)\n\n    **Example**:\n\n        >>> selector = BlockSizeSelector(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> _, Z = selector(X)\n        >>> block_size = Z.get('block_size', None)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, block_sizes=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        if block_sizes is None:\n            block_sizes = [16, 32, 64]\n        self.block_sizes = block_sizes\n        self.embed_dim = embed_dim\n\n    def _forward(self, X, **Z):\n        complexity = X.abs().mean(dim=(1, 2))\n        complexity_normalized = (complexity - complexity.min()) / (\n            complexity.max() - complexity.min() + 1e-06)\n        idxs = (complexity_normalized * (len(self.block_sizes) - 1)).long()\n        idxs = idxs.clamp(0, len(self.block_sizes) - 1)\n        selected_block_sizes = [self.block_sizes[idx.item()] for idx in idxs]\n        block_size = max(set(selected_block_sizes), key=\n            selected_block_sizes.count)\n        Z_ = {'block_size': block_size}\n        return X, Z_\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom typing import Optional\n\n\nclass BlockSparseUnit(GAUBase):\n    \"\"\"\n    BlockSparseUnit\n\n    This GAU processes input X using block-based sparsity patterns with a given block_size.\n\n    It utilizes a block-based sparse computation which is hardware-efficient and allows adaptive granularity.\n\n    **Key Components**:\n\n    - **Block Formation**: Splits the input sequence into blocks of size block_size.\n    - **Sparse Computation**: Applies block-wise operations exploiting sparsity.\n\n    **Inputs**:\n        - X (torch.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n        - block_size (int): The size of each block, specifying the granularity of sparsity.\n\n    **Outputs**:\n        - Y (torch.Tensor): Output tensor of the same shape as X.\n\n    **Example**:\n\n        >>> bs_unit = BlockSparseUnit(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> Z = {'block_size': 32}\n        >>> Y, Z = bs_unit(X, **Z)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, min_density: float=0.1, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.min_density = min_density\n        self.ffn = nn.Sequential(nn.Linear(self.hidden_size, self.\n            hidden_size * 4, device=device, dtype=dtype), nn.ReLU(), nn.\n            Linear(self.hidden_size * 4, self.hidden_size, device=device,\n            dtype=dtype))\n\n    def _forward(self, X, **Z):\n        block_size = Z.get('block_size')\n        if block_size is None:\n            block_size = 32\n        batch_size, seq_len, embed_dim = X.shape\n        pad_len = (seq_len + block_size - 1\n            ) // block_size * block_size - seq_len\n        X_padded = F.pad(X, (0, 0, 0, pad_len))\n        seq_len_padded = X_padded.shape[1]\n        num_blocks = seq_len_padded // block_size\n        X_blocks = X_padded.view(batch_size, num_blocks, block_size, embed_dim)\n        block_scores = X_blocks.abs().mean(dim=(2, 3))\n        threshold = block_scores.mean() * self.min_density\n        block_mask = block_scores > threshold\n        Z['block_scores'] = block_scores\n        Z['block_mask'] = block_mask\n        X_blocks_reshaped = X_blocks.view(-1, block_size, embed_dim)\n        block_mask_flat = block_mask.view(-1)\n        Y_blocks = X_blocks_reshaped.clone()\n        if block_mask_flat.any():\n            X_blocks_to_process = X_blocks_reshaped[block_mask_flat]\n            Y_blocks_processed = self.ffn(X_blocks_to_process)\n            Y_blocks[block_mask_flat] = Y_blocks_processed\n        Y_blocks = Y_blocks.view(batch_size, num_blocks, block_size, embed_dim)\n        Y_padded = Y_blocks.reshape(batch_size, seq_len_padded, embed_dim)\n        Y = Y_padded[:, :seq_len, :]\n        return Y, Z\n\n\ngab_config = {'hidden_size': None, 'norm_eps': 1e-06, 'num_heads': 8,\n    'min_density': 0.1, 'block_sizes': None}\n\n\n\nautoconfig={}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "350M": {
        "350M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RetNet(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\nfrom torchtune.modules import RMSNorm\n\n\nclass RetNet(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, norm_eps: float=1e-06, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = RMSNorm(self.hidden_size, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.attn = MultiScaleRetention(embed_dim=self.embed_dim, block_loc\n            =self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n        self.mlp_norm = RMSNorm(self.hidden_size, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.mlp = RetNetMLP(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        hidden_states = self.attn_norm(X)\n        X = self.attn(hidden_states, **Z)[0] + X\n        hidden_states = self.mlp_norm(X)\n        X = self.mlp(hidden_states, **Z)[0] + X\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom transformers.activations import ACT2FN\nfrom einops import rearrange, repeat\nfrom torchtune.modules import RotaryPositionalEmbeddings, RMSNorm\n\n\nclass MultiScaleRetention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_size=None, num_heads: int=8,\n        norm_eps: float=1e-05, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        hidden_size = hidden_size if hidden_size is not None else embed_dim\n        self.hidden_size = hidden_size\n        self.num_heads = num_heads\n        self.num_kv_heads = num_heads\n        self.num_kv_groups = self.num_heads // self.num_kv_heads\n        self.key_dim = hidden_size\n        self.value_dim = hidden_size * 2\n        self.key_dim_per_group = self.key_dim // self.num_kv_groups\n        self.value_dim_per_group = self.value_dim // self.num_kv_groups\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.q_proj = nn.Linear(hidden_size, self.key_dim, bias=False,\n            device=device, dtype=dtype)\n        self.k_proj = nn.Linear(hidden_size, self.key_dim_per_group, bias=\n            False, device=device, dtype=dtype)\n        self.v_proj = nn.Linear(hidden_size, self.value_dim_per_group, bias\n            =False, device=device, dtype=dtype)\n        self.g_proj = nn.Linear(hidden_size, self.value_dim, bias=False,\n            device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, hidden_size, bias=False,\n            device=device, dtype=dtype)\n        self.g_norm = RMSNorm(self.head_v_dim, eps=norm_eps).to(device=\n            device, dtype=dtype)\n        self.gate_fn = ACT2FN['swish']\n        self.rotary = RotaryPositionalEmbeddings(dim=self.head_qk_dim).to(\n            device=device, dtype=dtype)\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        module._is_hf_initialized = True\n\n    def naive_retention(self, q, k, v):\n        orig_type = q.dtype\n        q, k, v = q.float(), k.float(), v.float()\n        _, n_heads, seq_len, d_head = q.shape\n        s = (1 - q.new_tensor(2.0, dtype=torch.float).pow(-5.0 - q.\n            new_tensor(range(n_heads), dtype=torch.float))).log2()\n        n = q.new_tensor(range(seq_len), dtype=torch.float)\n        n = torch.exp2((n.unsqueeze(-1) - n) * s.view(-1, 1, 1)) * n.unsqueeze(\n            -1).ge(n)\n        s = torch.einsum('bhqd,bhkd,hqk->bhqk', q * d_head ** -0.5, k, n.to\n            (q.dtype))\n        o = torch.einsum('bhqk,bhkd->bhqd', s, v)\n        return o.to(orig_type)\n\n    def _forward(self, X, **Z):\n        q = self.q_proj(X)\n        k = self.k_proj(X)\n        v = self.v_proj(X)\n        q = rearrange(q, '... (h d) -> ... h d', h=self.num_heads)\n        k = rearrange(k, '... (h d) -> ... h d', h=self.num_kv_heads)\n        q = self.rotary(q)\n        k = self.rotary(k)\n        q = q.transpose(1, 2)\n        if self.num_kv_groups > 1:\n            k = repeat(k, 'b t h d -> b (h g) t d', h=self.num_kv_heads, g=\n                self.num_kv_groups)\n            v = repeat(v, 'b t (h d) -> b (h g) t d', h=self.num_kv_heads,\n                g=self.num_kv_groups)\n        else:\n            k, v = rearrange(k, 'b t h d -> b h t d'), rearrange(v,\n                'b t (h d) -> b h t d', h=self.num_kv_heads)\n        o = self.naive_retention(q, k, v)\n        o = rearrange(o, 'b h l d -> b l h d')\n        g = self.g_proj(X)\n        o = rearrange(self.g_norm(o), 'b l h d -> b l (h d)')\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        return o\n\n\nimport torch.nn.functional as F\n\n\nclass RetNetMLP(GAUBase):\n    \"\"\"\n    RetNet MLP with Block Sparse Computation and Adaptive Granularity.\n\n    This GAU implements a Block Sparse MLP that adaptively selects block sizes based on input complexity.\n    It leverages block-based sparse computation for efficient processing, especially for long sequences.\n\n    **Core Components:**\n\n    - **BlockSizeSelector**: Dynamically selects block sizes based on input complexity.\n    - **BlockSparseUnit**: Processes inputs using block-based sparsity patterns with the selected block size.\n\n    Args:\n        embed_dim (int): The embedding dimension of the input.\n        block_loc (tuple): The location of this block within the network (layer_idx, n_block).\n        kwarg_all (dict): Dictionary of all keyword arguments.\n\n    Example:\n\n        >>> mlp = RetNetMLP(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> Y, Z = mlp(X)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, hidden_size=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        hidden_size = hidden_size if hidden_size is not None else embed_dim\n        self.hidden_size = hidden_size\n        kwarg_all = kwarg_all.copy()\n        kwarg_all.update(kwargs)\n        self.block_size_selector = BlockSizeSelector(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all)\n        self.block_sparse_unit = BlockSparseUnit(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        _, Z_bs = self.block_size_selector(X, **Z)\n        Z.update(Z_bs)\n        block_size = Z.get('block_size', None)\n        if block_size is None:\n            block_size = 32\n        Z['block_size'] = block_size\n        Y, Z_sbu = self.block_sparse_unit(X, **Z)\n        Z.update(Z_sbu)\n        return Y, Z\n\n\nimport torch.nn.functional as F\n\n\nclass BlockSizeSelector(GAUBase):\n    \"\"\"\n    BlockSizeSelector\n\n    Dynamically selects block sizes based on input complexity using a parameter-free heuristic.\n\n    **Key Components**:\n    - **Selection Heuristic**: Selects the block size based on the complexity of the input sequence without trainable parameters.\n\n    **Inputs**:\n        - X (torch.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n\n    **Outputs**:\n        - Z (dict): Contains 'block_size' (int)\n\n    **Example**:\n\n        >>> selector = BlockSizeSelector(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> _, Z = selector(X)\n        >>> block_size = Z.get('block_size', None)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, block_sizes=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        if block_sizes is None:\n            block_sizes = [16, 32, 64]\n        self.block_sizes = block_sizes\n        self.embed_dim = embed_dim\n\n    def _forward(self, X, **Z):\n        complexity = X.abs().mean(dim=(1, 2))\n        complexity_normalized = (complexity - complexity.min()) / (\n            complexity.max() - complexity.min() + 1e-06)\n        idxs = (complexity_normalized * (len(self.block_sizes) - 1)).long()\n        idxs = idxs.clamp(0, len(self.block_sizes) - 1)\n        selected_block_sizes = [self.block_sizes[idx.item()] for idx in idxs]\n        block_size = max(set(selected_block_sizes), key=\n            selected_block_sizes.count)\n        Z_ = {'block_size': block_size}\n        return X, Z_\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom typing import Optional\n\n\nclass BlockSparseUnit(GAUBase):\n    \"\"\"\n    BlockSparseUnit\n\n    This GAU processes input X using block-based sparsity patterns with a given block_size.\n\n    It utilizes a block-based sparse computation which is hardware-efficient and allows adaptive granularity.\n\n    **Key Components**:\n\n    - **Block Formation**: Splits the input sequence into blocks of size block_size.\n    - **Sparse Computation**: Applies block-wise operations exploiting sparsity.\n\n    **Inputs**:\n        - X (torch.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n        - block_size (int): The size of each block, specifying the granularity of sparsity.\n\n    **Outputs**:\n        - Y (torch.Tensor): Output tensor of the same shape as X.\n\n    **Example**:\n\n        >>> bs_unit = BlockSparseUnit(embed_dim=512, block_loc=(0, 12), kwarg_all={})\n        >>> X = torch.randn(8, 128, 512)\n        >>> Z = {'block_size': 32}\n        >>> Y, Z = bs_unit(X, **Z)\n\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, min_density: float=0.1, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.min_density = min_density\n        self.ffn = nn.Sequential(nn.Linear(self.hidden_size, self.\n            hidden_size * 4, device=device, dtype=dtype), nn.ReLU(), nn.\n            Linear(self.hidden_size * 4, self.hidden_size, device=device,\n            dtype=dtype))\n\n    def _forward(self, X, **Z):\n        block_size = Z.get('block_size')\n        if block_size is None:\n            block_size = 32\n        batch_size, seq_len, embed_dim = X.shape\n        pad_len = (seq_len + block_size - 1\n            ) // block_size * block_size - seq_len\n        X_padded = F.pad(X, (0, 0, 0, pad_len))\n        seq_len_padded = X_padded.shape[1]\n        num_blocks = seq_len_padded // block_size\n        X_blocks = X_padded.view(batch_size, num_blocks, block_size, embed_dim)\n        block_scores = X_blocks.abs().mean(dim=(2, 3))\n        threshold = block_scores.mean() * self.min_density\n        block_mask = block_scores > threshold\n        Z['block_scores'] = block_scores\n        Z['block_mask'] = block_mask\n        X_blocks_reshaped = X_blocks.view(-1, block_size, embed_dim)\n        block_mask_flat = block_mask.view(-1)\n        Y_blocks = X_blocks_reshaped.clone()\n        if block_mask_flat.any():\n            X_blocks_to_process = X_blocks_reshaped[block_mask_flat]\n            Y_blocks_processed = self.ffn(X_blocks_to_process)\n            Y_blocks[block_mask_flat] = Y_blocks_processed\n        Y_blocks = Y_blocks.view(batch_size, num_blocks, block_size, embed_dim)\n        Y_padded = Y_blocks.reshape(batch_size, seq_len_padded, embed_dim)\n        Y = Y_padded[:, :seq_len, :]\n        return Y, Z\n\n\ngab_config = {'hidden_size': None, 'norm_eps': 1e-06, 'num_heads': 8,\n    'min_density': 0.1, 'block_sizes': None}\n\n\n\nautoconfig = {\n    'd_model': 512,\n    'n_block': 60\n}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    }
}