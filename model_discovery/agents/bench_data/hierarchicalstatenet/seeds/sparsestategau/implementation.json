{
    "implementation": {
        "review": "",
        "root": "SparseStateBlock",
        "proposal": "",
        "units": {
            "DenseStateProcessor": {
                "review": null,
                "requirements": "Processes active states with dense transformations.",
                "reuse_from": null,
                "desc": null,
                "gautests": {
                    "unit_test_DenseStateProcessor": "@gau_test\ndef test_DenseStateProcessor_unit_test_DenseStateProcessor(device=None,\n    dtype=None) ->None:\n    embed_dim = 16\n    batch_size = 2\n    seq_len = 5\n    dsp = DenseStateProcessor(embed_dim=embed_dim, block_loc=(0, 0),\n        kwarg_all={}, device=device, dtype=dtype)\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    X.requires_grad = True\n    Y, Z = dsp(X)\n    assert Y.shape == X.shape, f'Output shape {Y.shape} does not match input shape {X.shape}'\n    loss = Y.sum()\n    loss.backward()\n    for name, param in dsp.named_parameters():\n        if param.requires_grad:\n            assert param.grad is not None, f'Parameter {name} has no gradient'\n    assert X.grad is not None, 'Gradient w.r.t input X should not be None'\n    print('Unit test passed for DenseStateProcessor')\n"
                },
                "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass DenseStateProcessor(GAUBase):\n    \"\"\"\n    The DenseStateProcessor processes actively selected states with dense transformations to maintain information flow.\n\n    **Key Components:**\n\n    - `dense_layer`: Linear layer that applies a transformation to the input.\n    - `activation`: Activation function applied after the dense layer.\n    - `norm`: Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the active input tensors.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the processed output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> dsp = DenseStateProcessor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = dsp(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module applies a feed-forward neural network to the input.\n        - It includes residual connections for better gradient flow.\n\n    **References:**\n\n        - Liu, Z., et al. (2024). Short-Long Convolutions Help Hardware-Efficient Linear Attention to Focus on Long Sequences.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.dense_layer = nn.Linear(embed_dim, embed_dim, bias=True, **\n            self.factory_kwargs)\n        self.activation = nn.GELU()\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        residual = X\n        Y = self.dense_layer(X)\n        Y = self.activation(Y)\n        Y = Y + residual\n        Y = self.norm(Y)\n        return Y, Z\n",
                "rating": null,
                "spec": "{\"unitname\":\"DenseStateProcessor\",\"document\":\"The DenseStateProcessor processes actively selected states with dense transformations to maintain information flow.\\n\\n**Key Components:**\\n\\n- `dense_layer`: Linear layer that applies a transformation to the input.\\n- `activation`: Activation function applied after the dense layer.\\n- `norm`: Layer Normalization to stabilize outputs.\\n\\n**Args:**\\n\\n    embed_dim (int): The dimension of the input embeddings.\\n    block_loc (tuple): The location of the block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments for initialization.\\n    device (torch.device, optional): The device on which to allocate the module's parameters.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n\\n**Inputs:**\\n\\n    - **X**: Tensor of shape `(B, L, D)`, the active input tensors.\\n    - **Z**: Dictionary of intermediate variables.\\n\\n**Outputs:**\\n\\n    - **Y**: Tensor of shape `(B, L, D)`, the processed output tensor.\\n    - **Z'**: Updated dictionary of intermediate variables.\\n\\n**Example:**\\n\\n    >>> dsp = DenseStateProcessor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\\n    >>> X = torch.randn(2, 128, 512)\\n    >>> Y, Z = dsp(X)\\n    >>> print(Y.shape)\\n    torch.Size([2, 128, 512])\\n\\n**Note:**\\n\\n    - The module applies a feed-forward neural network to the input.\\n    - It includes residual connections for better gradient flow.\\n\\n**References:**\\n\\n    - Liu, Z., et al. (2024). Short-Long Convolutions Help Hardware-Efficient Linear Attention to Focus on Long Sequences.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                "children": [],
                "suggestions": null,
                "args": {},
                "design_traces": null
            },
            "SparseModularActivator": {
                "review": null,
                "requirements": "Applies differentiable sparse activation with learnable threshold.",
                "reuse_from": null,
                "desc": null,
                "gautests": {
                    "unit_test_SparseModularActivator": "@gau_test\ndef test_SparseModularActivator_unit_test_SparseModularActivator(device=\n    None, dtype=None) ->None:\n    embed_dim = 16\n    batch_size = 2\n    seq_len = 5\n    sma = SparseModularActivator(embed_dim=embed_dim, block_loc=(0, 0),\n        kwarg_all={}, device=device, dtype=dtype)\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    X.requires_grad = True\n    Y, Z = sma(X)\n    assert Y.shape == X.shape, f'Output shape {Y.shape} does not match input shape {X.shape}'\n    assert 'mask' in Z, \"Intermediate variables Z should contain 'mask'\"\n    mask = Z['mask']\n    assert mask.shape == X.shape, f'Mask shape {mask.shape} does not match input shape {X.shape}'\n    assert torch.all((mask >= 0) & (mask <= 1)\n        ), 'Mask values should be between 0 and 1'\n    expected_Y = X * mask\n    assert torch.allclose(Y, expected_Y\n        ), 'Output Y should be input X multiplied by mask'\n    loss = Y.sum()\n    loss.backward()\n    assert X.grad is not None, 'Gradient w.r.t input X should not be None'\n    assert sma.gate.weight.grad is not None, 'Gradient w.r.t gate weights should not be None'\n    assert sma.threshold.grad is not None, 'Gradient w.r.t threshold should not be None'\n    print('Unit test passed for SparseModularActivator')\n"
                },
                "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass SparseModularActivator(GAUBase):\n    \"\"\"\n    The SparseModularActivator applies sparse activation to the input embeddings.\n    It computes activation scores using a linear layer, applies a sigmoid activation to obtain gating values,\n    and then uses a smooth approximation to thresholding to generate a soft mask.\n    The soft mask is used to selectively activate parts of the input while maintaining gradient flow.\n\n    **Key Attributes:**\n\n    - `gate`: Linear layer to compute activation scores from the input.\n    - `threshold`: Learnable parameter that determines the sparsity level.\n    - `temperature`: A hyperparameter to control the sharpness of the sigmoid function.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        temperature (float, optional): Controls the sharpness of the sigmoid function. Default: 20.0\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables (not used in this GAU).\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after applying sparse activation.\n        - **Z'**: Updated dictionary of intermediate variables, includes `'mask'` key.\n\n    **Example:**\n\n        >>> sma = SparseModularActivator(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sma(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n        >>> print('mask' in Z)\n        True\n\n    **Note:**\n\n        The sparsity of the output depends on the learnable `threshold` parameter and the `temperature`, which can be trained to achieve desired sparsity levels.\n\n    **References:**\n\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, temperature=20.0, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.gate = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.threshold = nn.Parameter(torch.zeros(1, **self.factory_kwargs))\n        self.temperature = temperature\n\n    def _forward(self, X, **Z):\n        scores = torch.sigmoid(self.gate(X))\n        mask = torch.sigmoid((scores - self.threshold) * self.temperature)\n        Y = X * mask\n        Z_ = {'mask': mask}\n        return Y, Z_\n",
                "rating": null,
                "spec": "{\"unitname\":\"SparseModularActivator\",\"document\":\"The SparseModularActivator applies sparse activation to the input embeddings.\\nIt computes activation scores using a linear layer, applies a sigmoid activation to obtain gating values,\\nand then uses a smooth approximation to thresholding to generate a soft mask.\\nThe soft mask is used to selectively activate parts of the input while maintaining gradient flow.\\n\\n**Key Attributes:**\\n\\n- `gate`: Linear layer to compute activation scores from the input.\\n- `threshold`: Learnable parameter that determines the sparsity level.\\n- `temperature`: A hyperparameter to control the sharpness of the sigmoid function.\\n\\n**Args:**\\n\\n    embed_dim (int): The dimension of the input embeddings.\\n    block_loc (tuple): The location of the block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments for initialization.\\n    device (torch.device, optional): The device on which to allocate the module's parameters.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n    temperature (float, optional): Controls the sharpness of the sigmoid function. Default: 20.0\\n\\n**Inputs:**\\n\\n    - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\\n    - **Z**: Dictionary of intermediate variables (not used in this GAU).\\n\\n**Outputs:**\\n\\n    - **Y**: Tensor of shape `(B, L, D)`, the output after applying sparse activation.\\n    - **Z'**: Updated dictionary of intermediate variables, includes `'mask'` key.\\n\\n**Example:**\\n\\n    >>> sma = SparseModularActivator(embed_dim=512, block_loc=(0, 0), kwarg_all={})\\n    >>> X = torch.randn(2, 128, 512)\\n    >>> Y, Z = sma(X)\\n    >>> print(Y.shape)\\n    torch.Size([2, 128, 512])\\n    >>> print('mask' in Z)\\n    True\\n\\n**Note:**\\n\\n    The sparsity of the output depends on the learnable `threshold` parameter and the `temperature`, which can be trained to achieve desired sparsity levels.\\n\\n**References:**\\n\\n    - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\",\"mask\"]}",
                "children": [],
                "suggestions": null,
                "args": {
                    "temperature": 20.0
                },
                "design_traces": null
            },
            "StateCompressor": {
                "review": null,
                "requirements": "Compresses and decompresses state information efficiently.",
                "reuse_from": null,
                "desc": null,
                "gautests": {
                    "unit_test_StateCompressor": "@gau_test\ndef test_StateCompressor_unit_test_StateCompressor(device=None, dtype=None\n    ) ->None:\n    embed_dim = 16\n    batch_size = 2\n    seq_len = 5\n    sc = StateCompressor(embed_dim=embed_dim, block_loc=(0, 0), kwarg_all={\n        }, device=device, dtype=dtype)\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    X.requires_grad = True\n    Y, Z = sc(X)\n    assert Y.shape == X.shape, f'Output shape {Y.shape} does not match input shape {X.shape}'\n    loss = Y.sum()\n    loss.backward()\n    for name, param in sc.named_parameters():\n        if param.requires_grad:\n            assert param.grad is not None, f'Parameter {name} has no gradient'\n    assert X.grad is not None, 'Gradient w.r.t input X should not be None'\n    print('Unit test passed for StateCompressor')\n"
                },
                "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass StateCompressor(GAUBase):\n    \"\"\"\n    The StateCompressor compresses the state representations for efficient storage and decompresses them when needed.\n\n    **Key Components:**\n\n    - `compress`: Sequential module to compress the state.\n    - `decompress`: Sequential module to decompress the state.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the state to be compressed.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the decompressed state.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> sc = StateCompressor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sc(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The compression reduces the dimension to half, which can be adjusted as needed.\n        - The compressed state could be stored or processed further before decompression.\n\n    **References:**\n\n        - Gu, A., and Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        compressed_dim = embed_dim // 2\n        self.compress = nn.Sequential(nn.Linear(embed_dim, compressed_dim,\n            bias=False, **self.factory_kwargs), nn.GELU(), nn.LayerNorm(\n            compressed_dim, **self.factory_kwargs))\n        self.decompress = nn.Sequential(nn.Linear(compressed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.LayerNorm(embed_dim, **\n            self.factory_kwargs))\n\n    def _forward(self, X, **Z):\n        compressed = self.compress(X)\n        Y = self.decompress(compressed)\n        return Y, Z\n",
                "rating": null,
                "spec": "{\"unitname\":\"StateCompressor\",\"document\":\"The StateCompressor compresses the state representations for efficient storage and decompresses them when needed.\\n\\n**Key Components:**\\n\\n- `compress`: Sequential module to compress the state.\\n- `decompress`: Sequential module to decompress the state.\\n\\n**Args:**\\n\\n    embed_dim (int): The dimension of the input embeddings.\\n    block_loc (tuple): The location of the block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments for initialization.\\n    device (torch.device, optional): The device on which to allocate the module's parameters.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n\\n**Inputs:**\\n\\n    - **X**: Tensor of shape `(B, L, D)`, the state to be compressed.\\n    - **Z**: Dictionary of intermediate variables.\\n\\n**Outputs:**\\n\\n    - **Y**: Tensor of shape `(B, L, D)`, the decompressed state.\\n    - **Z'**: Updated dictionary of intermediate variables.\\n\\n**Example:**\\n\\n    >>> sc = StateCompressor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\\n    >>> X = torch.randn(2, 128, 512)\\n    >>> Y, Z = sc(X)\\n    >>> print(Y.shape)\\n    torch.Size([2, 128, 512])\\n\\n**Note:**\\n\\n    - The compression reduces the dimension to half, which can be adjusted as needed.\\n    - The compressed state could be stored or processed further before decompression.\\n\\n**References:**\\n\\n    - Gu, A., and Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                "children": [],
                "suggestions": null,
                "args": {},
                "design_traces": null
            },
            "SparseStateBlock": {
                "review": "# Implementation Review Report for SparseStateBlock\n\n## Overall Assessment\n\n```rating 4.5```\n\nThe implementation shows excellent design and functionality, with only minor improvements needed in unit tests and child declarations.\n\n## Strengths\n\n1. **Architecture Design**:\n   - Clean hierarchical structure with well-defined components\n   - Efficient state management through compression\n   - Smart use of sparse activation for computational efficiency\n   - IO-aware processing for hardware optimization\n\n2. **Code Quality**:\n   - Clear and consistent implementation style\n   - Robust error handling\n   - Well-documented interfaces\n   - Type hints and proper parameter handling\n\n3. **Performance Features**:\n   - Differentiable sparse activation\n   - Efficient chunk-based processing\n   - Adaptive state compression\n   - Residual connections for gradient flow\n\n## Areas for Improvement\n\n1. **Child Declarations**:\nAdd to each leaf GAU:\n```python\nCHILDREN_DECLARATIONS = []  # For leaf nodes\n```\n\nAnd for SparseStateBlock:\n```python\nCHILDREN_DECLARATIONS = [\n    UnitDecl(\n        unitname=\"SparseModularActivator\",\n        requirements=\"Applies differentiable sparse activation with temperature-controlled thresholding\",\n        inputs=[\"X\"],\n        outputs=[\"Y\", \"mask\"]\n    ),\n    UnitDecl(\n        unitname=\"StateCompressor\",\n        requirements=\"Compresses state with nonlinear transformations and normalization\",\n        inputs=[\"X\"],\n        outputs=[\"Y\"]\n    ),\n    UnitDecl(\n        unitname=\"IOAwareAdapter\",\n        requirements=\"Processes input in hardware-efficient chunks with padding handling\",\n        inputs=[\"X\"],\n        outputs=[\"Y\"]\n    ),\n    UnitDecl(\n        unitname=\"DenseStateProcessor\",\n        requirements=\"Processes states with dense connections and residual paths\",\n        inputs=[\"X\"],\n        outputs=[\"Y\"]\n    )\n]\n```\n\n2. **Unit Tests**:\nAdd comprehensive tests:\n```python\n@gau_test\ndef test_sparse_state_block(device=None, dtype=None):\n    model = SparseStateBlock(embed_dim=512, block_loc=(0,0), kwarg_all={}, \n                          device=device, dtype=dtype)\n    \n    # Test basic functionality\n    X = torch.randn(2, 128, 512, device=device, dtype=dtype)\n    Y, Z = model(X)\n    assert Y.shape == X.shape\n    assert 'mask' in Z\n    \n    # Test sparsity levels\n    mask = Z['mask']\n    sparsity = (mask < 0.5).float().mean()\n    print(f\"Activation sparsity: {sparsity.item():.2%}\")\n    assert 0.1 <= sparsity <= 0.9, \"Sparsity should be reasonable\"\n    \n    # Test gradient flow\n    loss = Y.mean()\n    loss.backward()\n    for name, param in model.named_parameters():\n        assert param.grad is not None, f\"No gradient for {name}\"\n    \n    # Test different sequence lengths\n    for seq_len in [64, 256, 1024]:\n        X = torch.randn(2, seq_len, 512, device=device, dtype=dtype)\n        Y, _ = model(X)\n        assert Y.shape == X.shape\n```\n\n3. **Memory Optimization**:\nAdd gradient checkpointing:\n```python\nclass SparseStateBlock(GAUBase):\n    def __init__(self, ...):\n        ...\n        self.use_checkpointing = True\n        \n    def _forward(self, X, **Z):\n        def _run_forward(x):\n            active_x, z = self.sparse_activator(x, **Z)\n            mask = z.get('mask', None)\n            if mask is not None and mask.sum() > 0:\n                processed = self.dense_processor(active_x, **z)[0]\n                compressed = self.state_compressor(processed, **z)[0]\n                if self.training:\n                    adapted = self.io_adapter(compressed, **z)[0]\n                else:\n                    adapted = compressed\n            else:\n                adapted = x\n            return self.norm(adapted)\n            \n        if self.use_checkpointing and self.training:\n            return torch.utils.checkpoint.checkpoint(_run_forward, X), Z\n        return _run_forward(X), Z\n```\n\n## Innovation and Impact\n\n1. **Technical Innovations**:\n   - Smooth differentiable sparse activation\n   - Efficient state compression with nonlinear transformations\n   - IO-aware chunk processing with padding handling\n   - Adaptive processing based on sparsity levels\n\n2. **Scalability Benefits**:\n   - Linear memory complexity through compression\n   - Efficient processing of long sequences\n   - Hardware-friendly computation patterns\n   - Controllable sparsity levels\n\n3. **Integration Advantages**:\n   - Clean interfaces between components\n   - Modular design for easy modifications\n   - Stable gradient flow through careful normalization\n   - Flexible configuration options\n\n## Recommendations\n\n1. **Implementation Priorities**:\n   - Add CHILDREN_DECLARATIONS to all components\n   - Implement comprehensive unit tests\n   - Add gradient checkpointing for memory efficiency\n\n2. **Performance Optimization**:\n```python\nclass IOAwareAdapter(GAUBase):\n    def __init__(self, ..., min_chunk_size=64, max_chunk_size=1024):\n        ...\n        self.min_chunk_size = min_chunk_size\n        self.max_chunk_size = max_chunk_size\n        \n    def _get_optimal_chunk_size(self, seq_len):\n        # Adaptive chunk sizing based on sequence length and hardware\n        base_size = min(seq_len, self.chunk_size)\n        # Round to nearest power of 2 for hardware efficiency\n        return 2 ** int(torch.log2(torch.tensor(\n            max(self.min_chunk_size, min(self.max_chunk_size, base_size))\n        )).ceil().item())\n```\n\n3. **Documentation Additions**:\n   - Add performance benchmarks\n   - Document expected sparsity patterns\n   - Include hardware recommendations\n   - Add integration guidelines\n\n4. **Testing Strategy**:\n   - Add stress tests for long sequences\n   - Test memory usage patterns\n   - Verify gradient flow\n   - Benchmark against baselines\n\nThe implementation is very strong, showing excellent attention to both theoretical soundness and practical efficiency. The main improvements needed are in documentation and testing rather than core functionality.",
                "requirements": "N/A",
                "reuse_from": null,
                "desc": null,
                "gautests": {
                    "unit_test_SparseStateBlock": "@gau_test\ndef test_SparseStateBlock_unit_test_SparseStateBlock(device=None, dtype=None\n    ) ->None:\n    embed_dim = 16\n    batch_size = 2\n    seq_len = 5\n    ssb = SparseStateBlock(embed_dim=embed_dim, block_loc=(0, 0), kwarg_all\n        ={}, device=device, dtype=dtype)\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    X.requires_grad = True\n    Y, Z = ssb(X)\n    assert Y.shape == X.shape, f'Output shape {Y.shape} does not match input shape {X.shape}'\n    assert torch.isfinite(Y).all(), 'Output contains NaNs or Infs'\n    loss = Y.sum()\n    loss.backward()\n    for name, param in ssb.named_parameters():\n        if param.requires_grad:\n            assert param.grad is not None, f'Parameter {name} has no gradient'\n    assert X.grad is not None, 'Gradient w.r.t input X should not be None'\n    print('Unit test passed for SparseStateBlock')\n"
                },
                "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass SparseStateBlock(GAUBase):\n    \"\"\"\n    SparseStateBlock integrates sparse activation, state compression, IO-aware adaptation, and dense processing\n    to efficiently manage state and computation in language modeling tasks.\n\n    **Core Components:**\n\n    - `sparse_activator`: Applies sparse modular activation to selectively activate parts of the input.\n    - `state_compressor`: Compresses and decompresses state representations for efficient storage.\n    - `io_adapter`: Adapts computation in an IO-aware manner to improve hardware efficiency.\n    - `dense_processor`: Processes active states with dense connections to maintain information flow.\n    - `norm`: Applies Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after processing.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ssb = SparseStateBlock(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = ssb(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module integrates multiple components to efficiently process sequences.\n        - It relies on child GAUs for specific functionalities.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.sparse_activator = SparseModularActivator(embed_dim=\n            self.embed_dim, block_loc=self.block_loc, kwarg_all=\n            self.kwarg_all, **self.factory_kwargs, **self.kwarg_all)\n        self.state_compressor = StateCompressor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **\n            self.factory_kwargs, **self.kwarg_all)\n        self.io_adapter = IOAwareAdapter(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **\n            self.factory_kwargs, **self.kwarg_all)\n        self.dense_processor = DenseStateProcessor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **\n            self.factory_kwargs, **self.kwarg_all)\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        active_X, Z = self.sparse_activator(X, **Z)\n        mask = Z.get('mask', None)\n        if mask is not None and mask.sum() > 0:\n            processed, Z = self.dense_processor(active_X, **Z)\n            compressed, Z = self.state_compressor(processed, **Z)\n            if self.training:\n                adapted, Z = self.io_adapter(compressed, **Z)\n            else:\n                adapted = compressed\n        else:\n            adapted = X\n        Y = self.norm(adapted)\n        return Y, Z\n",
                "rating": 4.5,
                "spec": "{\"unitname\":\"SparseStateBlock\",\"document\":\"SparseStateBlock integrates sparse activation, state compression, IO-aware adaptation, and dense processing\\nto efficiently manage state and computation in language modeling tasks.\\n\\n**Core Components:**\\n\\n- `sparse_activator`: Applies sparse modular activation to selectively activate parts of the input.\\n- `state_compressor`: Compresses and decompresses state representations for efficient storage.\\n- `io_adapter`: Adapts computation in an IO-aware manner to improve hardware efficiency.\\n- `dense_processor`: Processes active states with dense connections to maintain information flow.\\n- `norm`: Applies Layer Normalization to stabilize outputs.\\n\\n**Args:**\\n\\n    embed_dim (int): The dimension of the input embeddings.\\n    block_loc (tuple): The location of the block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments for initialization.\\n    device (torch.device, optional): The device on which to allocate the module's parameters.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n\\n**Inputs:**\\n\\n    - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\\n    - **Z**: Dictionary of intermediate variables.\\n\\n**Outputs:**\\n\\n    - **Y**: Tensor of shape `(B, L, D)`, the output after processing.\\n    - **Z'**: Updated dictionary of intermediate variables.\\n\\n**Example:**\\n\\n    >>> ssb = SparseStateBlock(embed_dim=512, block_loc=(0, 0), kwarg_all={})\\n    >>> X = torch.randn(2, 128, 512)\\n    >>> Y, Z = ssb(X)\\n    >>> print(Y.shape)\\n    torch.Size([2, 128, 512])\\n\\n**Note:**\\n\\n    - The module integrates multiple components to efficiently process sequences.\\n    - It relies on child GAUs for specific functionalities.\\n\\n**References:**\\n\\n    - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\\n    - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                "children": [
                    "SparseModularActivator",
                    "StateCompressor",
                    "IOAwareAdapter",
                    "DenseStateProcessor"
                ],
                "suggestions": null,
                "args": {},
                "design_traces": null
            },
            "IOAwareAdapter": {
                "review": null,
                "requirements": "Adapts state management for hardware-efficient IO.",
                "reuse_from": null,
                "desc": null,
                "gautests": {
                    "unit_test_IOAwareAdapter": "@gau_test\ndef test_IOAwareAdapter_unit_test_IOAwareAdapter(device=None, dtype=None\n    ) ->None:\n    embed_dim = 16\n    batch_size = 2\n    seq_len = 1024\n    chunk_size = 128\n    ioa = IOAwareAdapter(embed_dim=embed_dim, block_loc=(0, 0), kwarg_all={\n        }, device=device, dtype=dtype, chunk_size=chunk_size)\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    X.requires_grad = True\n    Y, Z = ioa(X)\n    assert Y.shape == X.shape, f'Output shape {Y.shape} does not match input shape {X.shape}'\n    loss = Y.sum()\n    loss.backward()\n    for name, param in ioa.named_parameters():\n        if param.requires_grad:\n            assert param.grad is not None, f'Parameter {name} has no gradient'\n    assert X.grad is not None, 'Gradient w.r.t input X should not be None'\n    print('Unit test passed for IOAwareAdapter')\n"
                },
                "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass IOAwareAdapter(GAUBase):\n    \"\"\"\n    The IOAwareAdapter processes the input in chunks to optimize for IO efficiency.\n    It adapts computation to be hardware-friendly, improving inference speed and memory access patterns.\n\n    **Key Components:**\n\n    - `adapter`: Linear layer to adapt the input.\n    - `chunk_size`: Integer specifying the size of each chunk.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        chunk_size (int, optional): The size of each chunk for processing.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the input tensor to be adapted.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the adapted output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ioa = IOAwareAdapter(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 1024, 512)\n        >>> Y, Z = ioa(X)\n        >>> print(Y.shape)\n        torch.Size([2, 1024, 512])\n\n    **Note:**\n\n        - Processing in chunks can improve cache utilization and overall computational efficiency.\n        - The chunk size can be adjusted based on hardware specifications.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, chunk_size=256, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.adapter = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.chunk_size = chunk_size\n\n    def _forward(self, X, **Z):\n        B, L, D = X.size()\n        pad_len = (self.chunk_size - L % self.chunk_size) % self.chunk_size\n        if pad_len > 0:\n            padding = torch.zeros(B, pad_len, D, device=X.device, dtype=X.dtype\n                )\n            X_padded = torch.cat([X, padding], dim=1)\n        else:\n            X_padded = X\n        num_chunks = X_padded.size(1) // self.chunk_size\n        X_chunks = X_padded.view(B, num_chunks, self.chunk_size, D).contiguous(\n            )\n        X_chunks = X_chunks.view(-1, self.chunk_size, D)\n        adapted_chunks = self.adapter(X_chunks)\n        adapted_padded = adapted_chunks.view(B, num_chunks * self.chunk_size, D\n            )\n        Y = adapted_padded[:, :L, :]\n        return Y, Z\n",
                "rating": null,
                "spec": "{\"unitname\":\"IOAwareAdapter\",\"document\":\"The IOAwareAdapter processes the input in chunks to optimize for IO efficiency.\\nIt adapts computation to be hardware-friendly, improving inference speed and memory access patterns.\\n\\n**Key Components:**\\n\\n- `adapter`: Linear layer to adapt the input.\\n- `chunk_size`: Integer specifying the size of each chunk.\\n\\n**Args:**\\n\\n    embed_dim (int): The dimension of the input embeddings.\\n    block_loc (tuple): The location of the block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments for initialization.\\n    device (torch.device, optional): The device on which to allocate the module's parameters.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n    chunk_size (int, optional): The size of each chunk for processing.\\n\\n**Inputs:**\\n\\n    - **X**: Tensor of shape `(B, L, D)`, the input tensor to be adapted.\\n    - **Z**: Dictionary of intermediate variables.\\n\\n**Outputs:**\\n\\n    - **Y**: Tensor of shape `(B, L, D)`, the adapted output tensor.\\n    - **Z'**: Updated dictionary of intermediate variables.\\n\\n**Example:**\\n\\n    >>> ioa = IOAwareAdapter(embed_dim=512, block_loc=(0, 0), kwarg_all={})\\n    >>> X = torch.randn(2, 1024, 512)\\n    >>> Y, Z = ioa(X)\\n    >>> print(Y.shape)\\n    torch.Size([2, 1024, 512])\\n\\n**Note:**\\n\\n    - Processing in chunks can improve cache utilization and overall computational efficiency.\\n    - The chunk size can be adjusted based on hardware specifications.\\n\\n**References:**\\n\\n    - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                "children": [],
                "suggestions": null,
                "args": {
                    "chunk_size": 256
                },
                "design_traces": null
            }
        },
        "rating": 0,
        "declares": {
            "DenseStateProcessor": "{\"unitname\":\"DenseStateProcessor\",\"requirements\":\"Processes active states with dense transformations.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
            "SparseModularActivator": "{\"unitname\":\"SparseModularActivator\",\"requirements\":\"Applies differentiable sparse activation with learnable threshold.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\",\"mask\"]}",
            "StateCompressor": "{\"unitname\":\"StateCompressor\",\"requirements\":\"Compresses and decompresses state information efficiently.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
            "SparseStateBlock": "{\"unitname\":\"SparseStateBlock\",\"requirements\":\"N/A\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
            "IOAwareAdapter": "{\"unitname\":\"IOAwareAdapter\",\"requirements\":\"Adapts state management for hardware-efficient IO.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}"
        },
        "proposal_traces": [],
        "suggestions": "",
        "name": "sparsestategau"
    },
    "status": "implemented",
    "history": [
        {
            "tree": {
                "review": "",
                "root": "SparseStateBlock",
                "proposal": "",
                "units": {
                    "DenseStateProcessor": {
                        "review": null,
                        "requirements": "Processes active states with dense transformations.",
                        "reuse_from": null,
                        "desc": null,
                        "gautests": {
                            "unit_test_DenseStateProcessor": "@gau_test\ndef test_DenseStateProcessor_unit_test_DenseStateProcessor(device=None,\n    dtype=None) ->None:\n    embed_dim = 16\n    batch_size = 2\n    seq_len = 5\n    dsp = DenseStateProcessor(embed_dim=embed_dim, block_loc=(0, 0),\n        kwarg_all={}, device=device, dtype=dtype)\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    X.requires_grad = True\n    Y, Z = dsp(X)\n    assert Y.shape == X.shape, f'Output shape {Y.shape} does not match input shape {X.shape}'\n    loss = Y.sum()\n    loss.backward()\n    for name, param in dsp.named_parameters():\n        if param.requires_grad:\n            assert param.grad is not None, f'Parameter {name} has no gradient'\n    assert X.grad is not None, 'Gradient w.r.t input X should not be None'\n    print('Unit test passed for DenseStateProcessor')\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass DenseStateProcessor(GAUBase):\n    \"\"\"\n    The DenseStateProcessor processes actively selected states with dense transformations to maintain information flow.\n\n    **Key Components:**\n\n    - `dense_layer`: Linear layer that applies a transformation to the input.\n    - `activation`: Activation function applied after the dense layer.\n    - `norm`: Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the active input tensors.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the processed output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> dsp = DenseStateProcessor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = dsp(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module applies a feed-forward neural network to the input.\n        - It includes residual connections for better gradient flow.\n\n    **References:**\n\n        - Liu, Z., et al. (2024). Short-Long Convolutions Help Hardware-Efficient Linear Attention to Focus on Long Sequences.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.dense_layer = nn.Linear(embed_dim, embed_dim, bias=True, **\n            self.factory_kwargs)\n        self.activation = nn.GELU()\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        residual = X\n        Y = self.dense_layer(X)\n        Y = self.activation(Y)\n        Y = Y + residual\n        Y = self.norm(Y)\n        return Y, Z\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"DenseStateProcessor\",\"document\":\"The DenseStateProcessor processes actively selected states with dense transformations to maintain information flow.\\n\\n**Key Components:**\\n\\n- `dense_layer`: Linear layer that applies a transformation to the input.\\n- `activation`: Activation function applied after the dense layer.\\n- `norm`: Layer Normalization to stabilize outputs.\\n\\n**Args:**\\n\\n    embed_dim (int): The dimension of the input embeddings.\\n    block_loc (tuple): The location of the block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments for initialization.\\n    device (torch.device, optional): The device on which to allocate the module's parameters.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n\\n**Inputs:**\\n\\n    - **X**: Tensor of shape `(B, L, D)`, the active input tensors.\\n    - **Z**: Dictionary of intermediate variables.\\n\\n**Outputs:**\\n\\n    - **Y**: Tensor of shape `(B, L, D)`, the processed output tensor.\\n    - **Z'**: Updated dictionary of intermediate variables.\\n\\n**Example:**\\n\\n    >>> dsp = DenseStateProcessor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\\n    >>> X = torch.randn(2, 128, 512)\\n    >>> Y, Z = dsp(X)\\n    >>> print(Y.shape)\\n    torch.Size([2, 128, 512])\\n\\n**Note:**\\n\\n    - The module applies a feed-forward neural network to the input.\\n    - It includes residual connections for better gradient flow.\\n\\n**References:**\\n\\n    - Liu, Z., et al. (2024). Short-Long Convolutions Help Hardware-Efficient Linear Attention to Focus on Long Sequences.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {},
                        "design_traces": null
                    },
                    "SparseModularActivator": {
                        "review": null,
                        "requirements": "Applies differentiable sparse activation with learnable threshold.",
                        "reuse_from": null,
                        "desc": null,
                        "gautests": {
                            "unit_test_SparseModularActivator": "@gau_test\ndef test_SparseModularActivator_unit_test_SparseModularActivator(device=\n    None, dtype=None) ->None:\n    embed_dim = 16\n    batch_size = 2\n    seq_len = 5\n    sma = SparseModularActivator(embed_dim=embed_dim, block_loc=(0, 0),\n        kwarg_all={}, device=device, dtype=dtype)\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    X.requires_grad = True\n    Y, Z = sma(X)\n    assert Y.shape == X.shape, f'Output shape {Y.shape} does not match input shape {X.shape}'\n    assert 'mask' in Z, \"Intermediate variables Z should contain 'mask'\"\n    mask = Z['mask']\n    assert mask.shape == X.shape, f'Mask shape {mask.shape} does not match input shape {X.shape}'\n    assert torch.all((mask >= 0) & (mask <= 1)\n        ), 'Mask values should be between 0 and 1'\n    expected_Y = X * mask\n    assert torch.allclose(Y, expected_Y\n        ), 'Output Y should be input X multiplied by mask'\n    loss = Y.sum()\n    loss.backward()\n    assert X.grad is not None, 'Gradient w.r.t input X should not be None'\n    assert sma.gate.weight.grad is not None, 'Gradient w.r.t gate weights should not be None'\n    assert sma.threshold.grad is not None, 'Gradient w.r.t threshold should not be None'\n    print('Unit test passed for SparseModularActivator')\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass SparseModularActivator(GAUBase):\n    \"\"\"\n    The SparseModularActivator applies sparse activation to the input embeddings.\n    It computes activation scores using a linear layer, applies a sigmoid activation to obtain gating values,\n    and then uses a smooth approximation to thresholding to generate a soft mask.\n    The soft mask is used to selectively activate parts of the input while maintaining gradient flow.\n\n    **Key Attributes:**\n\n    - `gate`: Linear layer to compute activation scores from the input.\n    - `threshold`: Learnable parameter that determines the sparsity level.\n    - `temperature`: A hyperparameter to control the sharpness of the sigmoid function.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        temperature (float, optional): Controls the sharpness of the sigmoid function. Default: 20.0\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables (not used in this GAU).\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after applying sparse activation.\n        - **Z'**: Updated dictionary of intermediate variables, includes `'mask'` key.\n\n    **Example:**\n\n        >>> sma = SparseModularActivator(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sma(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n        >>> print('mask' in Z)\n        True\n\n    **Note:**\n\n        The sparsity of the output depends on the learnable `threshold` parameter and the `temperature`, which can be trained to achieve desired sparsity levels.\n\n    **References:**\n\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, temperature=20.0, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.gate = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.threshold = nn.Parameter(torch.zeros(1, **self.factory_kwargs))\n        self.temperature = temperature\n\n    def _forward(self, X, **Z):\n        scores = torch.sigmoid(self.gate(X))\n        mask = torch.sigmoid((scores - self.threshold) * self.temperature)\n        Y = X * mask\n        Z_ = {'mask': mask}\n        return Y, Z_\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"SparseModularActivator\",\"document\":\"The SparseModularActivator applies sparse activation to the input embeddings.\\nIt computes activation scores using a linear layer, applies a sigmoid activation to obtain gating values,\\nand then uses a smooth approximation to thresholding to generate a soft mask.\\nThe soft mask is used to selectively activate parts of the input while maintaining gradient flow.\\n\\n**Key Attributes:**\\n\\n- `gate`: Linear layer to compute activation scores from the input.\\n- `threshold`: Learnable parameter that determines the sparsity level.\\n- `temperature`: A hyperparameter to control the sharpness of the sigmoid function.\\n\\n**Args:**\\n\\n    embed_dim (int): The dimension of the input embeddings.\\n    block_loc (tuple): The location of the block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments for initialization.\\n    device (torch.device, optional): The device on which to allocate the module's parameters.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n    temperature (float, optional): Controls the sharpness of the sigmoid function. Default: 20.0\\n\\n**Inputs:**\\n\\n    - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\\n    - **Z**: Dictionary of intermediate variables (not used in this GAU).\\n\\n**Outputs:**\\n\\n    - **Y**: Tensor of shape `(B, L, D)`, the output after applying sparse activation.\\n    - **Z'**: Updated dictionary of intermediate variables, includes `'mask'` key.\\n\\n**Example:**\\n\\n    >>> sma = SparseModularActivator(embed_dim=512, block_loc=(0, 0), kwarg_all={})\\n    >>> X = torch.randn(2, 128, 512)\\n    >>> Y, Z = sma(X)\\n    >>> print(Y.shape)\\n    torch.Size([2, 128, 512])\\n    >>> print('mask' in Z)\\n    True\\n\\n**Note:**\\n\\n    The sparsity of the output depends on the learnable `threshold` parameter and the `temperature`, which can be trained to achieve desired sparsity levels.\\n\\n**References:**\\n\\n    - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\",\"mask\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {
                            "temperature": 20.0
                        },
                        "design_traces": null
                    },
                    "StateCompressor": {
                        "review": null,
                        "requirements": "Compresses and decompresses state information efficiently.",
                        "reuse_from": null,
                        "desc": null,
                        "gautests": {
                            "unit_test_StateCompressor": "@gau_test\ndef test_StateCompressor_unit_test_StateCompressor(device=None, dtype=None\n    ) ->None:\n    embed_dim = 16\n    batch_size = 2\n    seq_len = 5\n    sc = StateCompressor(embed_dim=embed_dim, block_loc=(0, 0), kwarg_all={\n        }, device=device, dtype=dtype)\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    X.requires_grad = True\n    Y, Z = sc(X)\n    assert Y.shape == X.shape, f'Output shape {Y.shape} does not match input shape {X.shape}'\n    loss = Y.sum()\n    loss.backward()\n    for name, param in sc.named_parameters():\n        if param.requires_grad:\n            assert param.grad is not None, f'Parameter {name} has no gradient'\n    assert X.grad is not None, 'Gradient w.r.t input X should not be None'\n    print('Unit test passed for StateCompressor')\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass StateCompressor(GAUBase):\n    \"\"\"\n    The StateCompressor compresses the state representations for efficient storage and decompresses them when needed.\n\n    **Key Components:**\n\n    - `compress`: Sequential module to compress the state.\n    - `decompress`: Sequential module to decompress the state.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the state to be compressed.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the decompressed state.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> sc = StateCompressor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sc(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The compression reduces the dimension to half, which can be adjusted as needed.\n        - The compressed state could be stored or processed further before decompression.\n\n    **References:**\n\n        - Gu, A., and Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        compressed_dim = embed_dim // 2\n        self.compress = nn.Sequential(nn.Linear(embed_dim, compressed_dim,\n            bias=False, **self.factory_kwargs), nn.GELU(), nn.LayerNorm(\n            compressed_dim, **self.factory_kwargs))\n        self.decompress = nn.Sequential(nn.Linear(compressed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.LayerNorm(embed_dim, **\n            self.factory_kwargs))\n\n    def _forward(self, X, **Z):\n        compressed = self.compress(X)\n        Y = self.decompress(compressed)\n        return Y, Z\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"StateCompressor\",\"document\":\"The StateCompressor compresses the state representations for efficient storage and decompresses them when needed.\\n\\n**Key Components:**\\n\\n- `compress`: Sequential module to compress the state.\\n- `decompress`: Sequential module to decompress the state.\\n\\n**Args:**\\n\\n    embed_dim (int): The dimension of the input embeddings.\\n    block_loc (tuple): The location of the block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments for initialization.\\n    device (torch.device, optional): The device on which to allocate the module's parameters.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n\\n**Inputs:**\\n\\n    - **X**: Tensor of shape `(B, L, D)`, the state to be compressed.\\n    - **Z**: Dictionary of intermediate variables.\\n\\n**Outputs:**\\n\\n    - **Y**: Tensor of shape `(B, L, D)`, the decompressed state.\\n    - **Z'**: Updated dictionary of intermediate variables.\\n\\n**Example:**\\n\\n    >>> sc = StateCompressor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\\n    >>> X = torch.randn(2, 128, 512)\\n    >>> Y, Z = sc(X)\\n    >>> print(Y.shape)\\n    torch.Size([2, 128, 512])\\n\\n**Note:**\\n\\n    - The compression reduces the dimension to half, which can be adjusted as needed.\\n    - The compressed state could be stored or processed further before decompression.\\n\\n**References:**\\n\\n    - Gu, A., and Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {},
                        "design_traces": null
                    },
                    "SparseStateBlock": {
                        "review": "# Implementation Review Report for SparseStateBlock\n\n## Overall Assessment\n\n```rating 4.5```\n\nThe implementation shows excellent design and functionality, with only minor improvements needed in unit tests and child declarations.\n\n## Strengths\n\n1. **Architecture Design**:\n   - Clean hierarchical structure with well-defined components\n   - Efficient state management through compression\n   - Smart use of sparse activation for computational efficiency\n   - IO-aware processing for hardware optimization\n\n2. **Code Quality**:\n   - Clear and consistent implementation style\n   - Robust error handling\n   - Well-documented interfaces\n   - Type hints and proper parameter handling\n\n3. **Performance Features**:\n   - Differentiable sparse activation\n   - Efficient chunk-based processing\n   - Adaptive state compression\n   - Residual connections for gradient flow\n\n## Areas for Improvement\n\n1. **Child Declarations**:\nAdd to each leaf GAU:\n```python\nCHILDREN_DECLARATIONS = []  # For leaf nodes\n```\n\nAnd for SparseStateBlock:\n```python\nCHILDREN_DECLARATIONS = [\n    UnitDecl(\n        unitname=\"SparseModularActivator\",\n        requirements=\"Applies differentiable sparse activation with temperature-controlled thresholding\",\n        inputs=[\"X\"],\n        outputs=[\"Y\", \"mask\"]\n    ),\n    UnitDecl(\n        unitname=\"StateCompressor\",\n        requirements=\"Compresses state with nonlinear transformations and normalization\",\n        inputs=[\"X\"],\n        outputs=[\"Y\"]\n    ),\n    UnitDecl(\n        unitname=\"IOAwareAdapter\",\n        requirements=\"Processes input in hardware-efficient chunks with padding handling\",\n        inputs=[\"X\"],\n        outputs=[\"Y\"]\n    ),\n    UnitDecl(\n        unitname=\"DenseStateProcessor\",\n        requirements=\"Processes states with dense connections and residual paths\",\n        inputs=[\"X\"],\n        outputs=[\"Y\"]\n    )\n]\n```\n\n2. **Unit Tests**:\nAdd comprehensive tests:\n```python\n@gau_test\ndef test_sparse_state_block(device=None, dtype=None):\n    model = SparseStateBlock(embed_dim=512, block_loc=(0,0), kwarg_all={}, \n                          device=device, dtype=dtype)\n    \n    # Test basic functionality\n    X = torch.randn(2, 128, 512, device=device, dtype=dtype)\n    Y, Z = model(X)\n    assert Y.shape == X.shape\n    assert 'mask' in Z\n    \n    # Test sparsity levels\n    mask = Z['mask']\n    sparsity = (mask < 0.5).float().mean()\n    print(f\"Activation sparsity: {sparsity.item():.2%}\")\n    assert 0.1 <= sparsity <= 0.9, \"Sparsity should be reasonable\"\n    \n    # Test gradient flow\n    loss = Y.mean()\n    loss.backward()\n    for name, param in model.named_parameters():\n        assert param.grad is not None, f\"No gradient for {name}\"\n    \n    # Test different sequence lengths\n    for seq_len in [64, 256, 1024]:\n        X = torch.randn(2, seq_len, 512, device=device, dtype=dtype)\n        Y, _ = model(X)\n        assert Y.shape == X.shape\n```\n\n3. **Memory Optimization**:\nAdd gradient checkpointing:\n```python\nclass SparseStateBlock(GAUBase):\n    def __init__(self, ...):\n        ...\n        self.use_checkpointing = True\n        \n    def _forward(self, X, **Z):\n        def _run_forward(x):\n            active_x, z = self.sparse_activator(x, **Z)\n            mask = z.get('mask', None)\n            if mask is not None and mask.sum() > 0:\n                processed = self.dense_processor(active_x, **z)[0]\n                compressed = self.state_compressor(processed, **z)[0]\n                if self.training:\n                    adapted = self.io_adapter(compressed, **z)[0]\n                else:\n                    adapted = compressed\n            else:\n                adapted = x\n            return self.norm(adapted)\n            \n        if self.use_checkpointing and self.training:\n            return torch.utils.checkpoint.checkpoint(_run_forward, X), Z\n        return _run_forward(X), Z\n```\n\n## Innovation and Impact\n\n1. **Technical Innovations**:\n   - Smooth differentiable sparse activation\n   - Efficient state compression with nonlinear transformations\n   - IO-aware chunk processing with padding handling\n   - Adaptive processing based on sparsity levels\n\n2. **Scalability Benefits**:\n   - Linear memory complexity through compression\n   - Efficient processing of long sequences\n   - Hardware-friendly computation patterns\n   - Controllable sparsity levels\n\n3. **Integration Advantages**:\n   - Clean interfaces between components\n   - Modular design for easy modifications\n   - Stable gradient flow through careful normalization\n   - Flexible configuration options\n\n## Recommendations\n\n1. **Implementation Priorities**:\n   - Add CHILDREN_DECLARATIONS to all components\n   - Implement comprehensive unit tests\n   - Add gradient checkpointing for memory efficiency\n\n2. **Performance Optimization**:\n```python\nclass IOAwareAdapter(GAUBase):\n    def __init__(self, ..., min_chunk_size=64, max_chunk_size=1024):\n        ...\n        self.min_chunk_size = min_chunk_size\n        self.max_chunk_size = max_chunk_size\n        \n    def _get_optimal_chunk_size(self, seq_len):\n        # Adaptive chunk sizing based on sequence length and hardware\n        base_size = min(seq_len, self.chunk_size)\n        # Round to nearest power of 2 for hardware efficiency\n        return 2 ** int(torch.log2(torch.tensor(\n            max(self.min_chunk_size, min(self.max_chunk_size, base_size))\n        )).ceil().item())\n```\n\n3. **Documentation Additions**:\n   - Add performance benchmarks\n   - Document expected sparsity patterns\n   - Include hardware recommendations\n   - Add integration guidelines\n\n4. **Testing Strategy**:\n   - Add stress tests for long sequences\n   - Test memory usage patterns\n   - Verify gradient flow\n   - Benchmark against baselines\n\nThe implementation is very strong, showing excellent attention to both theoretical soundness and practical efficiency. The main improvements needed are in documentation and testing rather than core functionality.",
                        "requirements": "N/A",
                        "reuse_from": null,
                        "desc": null,
                        "gautests": {
                            "unit_test_SparseStateBlock": "@gau_test\ndef test_SparseStateBlock_unit_test_SparseStateBlock(device=None, dtype=None\n    ) ->None:\n    embed_dim = 16\n    batch_size = 2\n    seq_len = 5\n    ssb = SparseStateBlock(embed_dim=embed_dim, block_loc=(0, 0), kwarg_all\n        ={}, device=device, dtype=dtype)\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    X.requires_grad = True\n    Y, Z = ssb(X)\n    assert Y.shape == X.shape, f'Output shape {Y.shape} does not match input shape {X.shape}'\n    assert torch.isfinite(Y).all(), 'Output contains NaNs or Infs'\n    loss = Y.sum()\n    loss.backward()\n    for name, param in ssb.named_parameters():\n        if param.requires_grad:\n            assert param.grad is not None, f'Parameter {name} has no gradient'\n    assert X.grad is not None, 'Gradient w.r.t input X should not be None'\n    print('Unit test passed for SparseStateBlock')\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass SparseStateBlock(GAUBase):\n    \"\"\"\n    SparseStateBlock integrates sparse activation, state compression, IO-aware adaptation, and dense processing\n    to efficiently manage state and computation in language modeling tasks.\n\n    **Core Components:**\n\n    - `sparse_activator`: Applies sparse modular activation to selectively activate parts of the input.\n    - `state_compressor`: Compresses and decompresses state representations for efficient storage.\n    - `io_adapter`: Adapts computation in an IO-aware manner to improve hardware efficiency.\n    - `dense_processor`: Processes active states with dense connections to maintain information flow.\n    - `norm`: Applies Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after processing.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ssb = SparseStateBlock(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = ssb(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module integrates multiple components to efficiently process sequences.\n        - It relies on child GAUs for specific functionalities.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.sparse_activator = SparseModularActivator(embed_dim=\n            self.embed_dim, block_loc=self.block_loc, kwarg_all=\n            self.kwarg_all, **self.factory_kwargs, **self.kwarg_all)\n        self.state_compressor = StateCompressor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **\n            self.factory_kwargs, **self.kwarg_all)\n        self.io_adapter = IOAwareAdapter(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **\n            self.factory_kwargs, **self.kwarg_all)\n        self.dense_processor = DenseStateProcessor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **\n            self.factory_kwargs, **self.kwarg_all)\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        active_X, Z = self.sparse_activator(X, **Z)\n        mask = Z.get('mask', None)\n        if mask is not None and mask.sum() > 0:\n            processed, Z = self.dense_processor(active_X, **Z)\n            compressed, Z = self.state_compressor(processed, **Z)\n            if self.training:\n                adapted, Z = self.io_adapter(compressed, **Z)\n            else:\n                adapted = compressed\n        else:\n            adapted = X\n        Y = self.norm(adapted)\n        return Y, Z\n",
                        "rating": 4.5,
                        "spec": "{\"unitname\":\"SparseStateBlock\",\"document\":\"SparseStateBlock integrates sparse activation, state compression, IO-aware adaptation, and dense processing\\nto efficiently manage state and computation in language modeling tasks.\\n\\n**Core Components:**\\n\\n- `sparse_activator`: Applies sparse modular activation to selectively activate parts of the input.\\n- `state_compressor`: Compresses and decompresses state representations for efficient storage.\\n- `io_adapter`: Adapts computation in an IO-aware manner to improve hardware efficiency.\\n- `dense_processor`: Processes active states with dense connections to maintain information flow.\\n- `norm`: Applies Layer Normalization to stabilize outputs.\\n\\n**Args:**\\n\\n    embed_dim (int): The dimension of the input embeddings.\\n    block_loc (tuple): The location of the block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments for initialization.\\n    device (torch.device, optional): The device on which to allocate the module's parameters.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n\\n**Inputs:**\\n\\n    - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\\n    - **Z**: Dictionary of intermediate variables.\\n\\n**Outputs:**\\n\\n    - **Y**: Tensor of shape `(B, L, D)`, the output after processing.\\n    - **Z'**: Updated dictionary of intermediate variables.\\n\\n**Example:**\\n\\n    >>> ssb = SparseStateBlock(embed_dim=512, block_loc=(0, 0), kwarg_all={})\\n    >>> X = torch.randn(2, 128, 512)\\n    >>> Y, Z = ssb(X)\\n    >>> print(Y.shape)\\n    torch.Size([2, 128, 512])\\n\\n**Note:**\\n\\n    - The module integrates multiple components to efficiently process sequences.\\n    - It relies on child GAUs for specific functionalities.\\n\\n**References:**\\n\\n    - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\\n    - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [
                            "SparseModularActivator",
                            "StateCompressor",
                            "IOAwareAdapter",
                            "DenseStateProcessor"
                        ],
                        "suggestions": null,
                        "args": {},
                        "design_traces": null
                    },
                    "IOAwareAdapter": {
                        "review": null,
                        "requirements": "Adapts state management for hardware-efficient IO.",
                        "reuse_from": null,
                        "desc": null,
                        "gautests": {
                            "unit_test_IOAwareAdapter": "@gau_test\ndef test_IOAwareAdapter_unit_test_IOAwareAdapter(device=None, dtype=None\n    ) ->None:\n    embed_dim = 16\n    batch_size = 2\n    seq_len = 1024\n    chunk_size = 128\n    ioa = IOAwareAdapter(embed_dim=embed_dim, block_loc=(0, 0), kwarg_all={\n        }, device=device, dtype=dtype, chunk_size=chunk_size)\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    X.requires_grad = True\n    Y, Z = ioa(X)\n    assert Y.shape == X.shape, f'Output shape {Y.shape} does not match input shape {X.shape}'\n    loss = Y.sum()\n    loss.backward()\n    for name, param in ioa.named_parameters():\n        if param.requires_grad:\n            assert param.grad is not None, f'Parameter {name} has no gradient'\n    assert X.grad is not None, 'Gradient w.r.t input X should not be None'\n    print('Unit test passed for IOAwareAdapter')\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass IOAwareAdapter(GAUBase):\n    \"\"\"\n    The IOAwareAdapter processes the input in chunks to optimize for IO efficiency.\n    It adapts computation to be hardware-friendly, improving inference speed and memory access patterns.\n\n    **Key Components:**\n\n    - `adapter`: Linear layer to adapt the input.\n    - `chunk_size`: Integer specifying the size of each chunk.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        chunk_size (int, optional): The size of each chunk for processing.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the input tensor to be adapted.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the adapted output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ioa = IOAwareAdapter(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 1024, 512)\n        >>> Y, Z = ioa(X)\n        >>> print(Y.shape)\n        torch.Size([2, 1024, 512])\n\n    **Note:**\n\n        - Processing in chunks can improve cache utilization and overall computational efficiency.\n        - The chunk size can be adjusted based on hardware specifications.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, chunk_size=256, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.adapter = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.chunk_size = chunk_size\n\n    def _forward(self, X, **Z):\n        B, L, D = X.size()\n        pad_len = (self.chunk_size - L % self.chunk_size) % self.chunk_size\n        if pad_len > 0:\n            padding = torch.zeros(B, pad_len, D, device=X.device, dtype=X.dtype\n                )\n            X_padded = torch.cat([X, padding], dim=1)\n        else:\n            X_padded = X\n        num_chunks = X_padded.size(1) // self.chunk_size\n        X_chunks = X_padded.view(B, num_chunks, self.chunk_size, D).contiguous(\n            )\n        X_chunks = X_chunks.view(-1, self.chunk_size, D)\n        adapted_chunks = self.adapter(X_chunks)\n        adapted_padded = adapted_chunks.view(B, num_chunks * self.chunk_size, D\n            )\n        Y = adapted_padded[:, :L, :]\n        return Y, Z\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"IOAwareAdapter\",\"document\":\"The IOAwareAdapter processes the input in chunks to optimize for IO efficiency.\\nIt adapts computation to be hardware-friendly, improving inference speed and memory access patterns.\\n\\n**Key Components:**\\n\\n- `adapter`: Linear layer to adapt the input.\\n- `chunk_size`: Integer specifying the size of each chunk.\\n\\n**Args:**\\n\\n    embed_dim (int): The dimension of the input embeddings.\\n    block_loc (tuple): The location of the block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments for initialization.\\n    device (torch.device, optional): The device on which to allocate the module's parameters.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n    chunk_size (int, optional): The size of each chunk for processing.\\n\\n**Inputs:**\\n\\n    - **X**: Tensor of shape `(B, L, D)`, the input tensor to be adapted.\\n    - **Z**: Dictionary of intermediate variables.\\n\\n**Outputs:**\\n\\n    - **Y**: Tensor of shape `(B, L, D)`, the adapted output tensor.\\n    - **Z'**: Updated dictionary of intermediate variables.\\n\\n**Example:**\\n\\n    >>> ioa = IOAwareAdapter(embed_dim=512, block_loc=(0, 0), kwarg_all={})\\n    >>> X = torch.randn(2, 1024, 512)\\n    >>> Y, Z = ioa(X)\\n    >>> print(Y.shape)\\n    torch.Size([2, 1024, 512])\\n\\n**Note:**\\n\\n    - Processing in chunks can improve cache utilization and overall computational efficiency.\\n    - The chunk size can be adjusted based on hardware specifications.\\n\\n**References:**\\n\\n    - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {
                            "chunk_size": 256
                        },
                        "design_traces": null
                    }
                },
                "rating": 0,
                "declares": {
                    "DenseStateProcessor": "{\"unitname\":\"DenseStateProcessor\",\"requirements\":\"Processes active states with dense transformations.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                    "SparseModularActivator": "{\"unitname\":\"SparseModularActivator\",\"requirements\":\"Applies differentiable sparse activation with learnable threshold.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\",\"mask\"]}",
                    "StateCompressor": "{\"unitname\":\"StateCompressor\",\"requirements\":\"Compresses and decompresses state information efficiently.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                    "SparseStateBlock": "{\"unitname\":\"SparseStateBlock\",\"requirements\":\"N/A\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                    "IOAwareAdapter": "{\"unitname\":\"IOAwareAdapter\",\"requirements\":\"Adapts state management for hardware-efficient IO.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}"
                },
                "proposal_traces": [],
                "suggestions": "",
                "name": "sparsestategau"
            },
            "user_input": "",
            "status": "unfinished",
            "design_cfg": {
                "max_attemps": {
                    "post_refinement": 0,
                    "max_search_rounds": 3,
                    "implementation_debug": 7,
                    "design_proposal": 10
                },
                "threshold": {
                    "proposal_rating": 4.0,
                    "implementation_rating": 3.0
                },
                "use_unlimited_prompt": true,
                "mutation_no_tree": true,
                "agent_types": {
                    "DESIGN_PROPOSER": "hybrid",
                    "IMPLEMENTATION_PLANNER": "hybrid",
                    "IMPLEMENTATION_CODER": "hybrid",
                    "PROPOSAL_REVIEWER": "hybrid",
                    "IMPLEMENTATION_OBSERVER": "hybrid",
                    "SEARCH_ASSISTANT": "None"
                },
                "running_mode": "Proposal + Implementation",
                "unittest_pass_required": false,
                "crossover_no_ref": true,
                "scratch_no_tree": true,
                "_agent_types": {
                    "DESIGN_PROPOSER": "claude3.5_sonnet",
                    "IMPLEMENTATION_PLANNER": "o1_mini",
                    "IMPLEMENTATION_CODER": "o1_preview",
                    "PROPOSAL_REVIEWER": "claude3.5_sonnet",
                    "IMPLEMENTATION_OBSERVER": "claude3.5_sonnet",
                    "SEARCH_ASSISTANT": "None"
                },
                "termination": {
                    "max_debug_budget": 0,
                    "max_failed_rounds": 3,
                    "max_total_budget": 0
                },
                "agent_weights": {
                    "DESIGN_PROPOSER": [
                        0.05,
                        0.0,
                        0.6000000000000001,
                        0.2,
                        0.15
                    ],
                    "IMPLEMENTATION_PLANNER": [
                        0.05000000000000002,
                        0.0,
                        0.44999999999999996,
                        0.3,
                        0.20000000000000007
                    ],
                    "IMPLEMENTATION_CODER": [
                        0.0,
                        0.0,
                        0.3,
                        0.4999999999999996,
                        0.2
                    ],
                    "PROPOSAL_REVIEWER": [
                        0.10000000000000002,
                        0.0,
                        0.5499999999999999,
                        0.2,
                        0.15000000000000002
                    ],
                    "IMPLEMENTATION_OBSERVER": [
                        0.05,
                        0.0,
                        0.15000000000000002,
                        0.15000000000000002,
                        0.6499999999999999,
                        0.0
                    ]
                },
                "num_samples": {
                    "implementation": 1,
                    "rerank_method": "rating",
                    "proposal": 1
                },
                "search_settings": {
                    "proposal_search": true,
                    "proposal_review_search": true,
                    "search_for_papers_num": 10
                },
                "max_attempts": {
                    "post_refinement": 0,
                    "max_search_rounds": 4,
                    "implementation_debug": 5,
                    "design_proposal": 5
                }
            },
            "costs": {
                "DESIGN_PROPOSER": 0,
                "IMPLEMENTATION_PLANNER": 0.16581600000000002,
                "IMPLEMENTATION_CODER": 4.6883550000000005,
                "PROPOSAL_REVIEWER": 0,
                "IMPLEMENTATION_OBSERVER": 0.68832,
                "SEARCH_ASSISTANT": 0
            }
        },
        {
            "tree": {
                "review": "",
                "root": "SparseStateBlock",
                "proposal": "",
                "units": {
                    "DenseStateProcessor": {
                        "review": null,
                        "requirements": "Processes active states with dense transformations.",
                        "reuse_from": null,
                        "desc": null,
                        "gautests": {
                            "unit_test_DenseStateProcessor": "@gau_test\ndef test_DenseStateProcessor_unit_test_DenseStateProcessor(device=None,\n    dtype=None) ->None:\n    embed_dim = 16\n    batch_size = 2\n    seq_len = 5\n    dsp = DenseStateProcessor(embed_dim=embed_dim, block_loc=(0, 0),\n        kwarg_all={}, device=device, dtype=dtype)\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    X.requires_grad = True\n    Y, Z = dsp(X)\n    assert Y.shape == X.shape, f'Output shape {Y.shape} does not match input shape {X.shape}'\n    loss = Y.sum()\n    loss.backward()\n    for name, param in dsp.named_parameters():\n        if param.requires_grad:\n            assert param.grad is not None, f'Parameter {name} has no gradient'\n    assert X.grad is not None, 'Gradient w.r.t input X should not be None'\n    print('Unit test passed for DenseStateProcessor')\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass DenseStateProcessor(GAUBase):\n    \"\"\"\n    The DenseStateProcessor processes actively selected states with dense transformations to maintain information flow.\n\n    **Key Components:**\n\n    - `dense_layer`: Linear layer that applies a transformation to the input.\n    - `activation`: Activation function applied after the dense layer.\n    - `norm`: Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the active input tensors.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the processed output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> dsp = DenseStateProcessor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = dsp(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module applies a feed-forward neural network to the input.\n        - It includes residual connections for better gradient flow.\n\n    **References:**\n\n        - Liu, Z., et al. (2024). Short-Long Convolutions Help Hardware-Efficient Linear Attention to Focus on Long Sequences.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.dense_layer = nn.Linear(embed_dim, embed_dim, bias=True, **\n            self.factory_kwargs)\n        self.activation = nn.GELU()\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        residual = X\n        Y = self.dense_layer(X)\n        Y = self.activation(Y)\n        Y = Y + residual\n        Y = self.norm(Y)\n        return Y, Z\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"DenseStateProcessor\",\"document\":\"The DenseStateProcessor processes actively selected states with dense transformations to maintain information flow.\\n\\n**Key Components:**\\n\\n- `dense_layer`: Linear layer that applies a transformation to the input.\\n- `activation`: Activation function applied after the dense layer.\\n- `norm`: Layer Normalization to stabilize outputs.\\n\\n**Args:**\\n\\n    embed_dim (int): The dimension of the input embeddings.\\n    block_loc (tuple): The location of the block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments for initialization.\\n    device (torch.device, optional): The device on which to allocate the module's parameters.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n\\n**Inputs:**\\n\\n    - **X**: Tensor of shape `(B, L, D)`, the active input tensors.\\n    - **Z**: Dictionary of intermediate variables.\\n\\n**Outputs:**\\n\\n    - **Y**: Tensor of shape `(B, L, D)`, the processed output tensor.\\n    - **Z'**: Updated dictionary of intermediate variables.\\n\\n**Example:**\\n\\n    >>> dsp = DenseStateProcessor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\\n    >>> X = torch.randn(2, 128, 512)\\n    >>> Y, Z = dsp(X)\\n    >>> print(Y.shape)\\n    torch.Size([2, 128, 512])\\n\\n**Note:**\\n\\n    - The module applies a feed-forward neural network to the input.\\n    - It includes residual connections for better gradient flow.\\n\\n**References:**\\n\\n    - Liu, Z., et al. (2024). Short-Long Convolutions Help Hardware-Efficient Linear Attention to Focus on Long Sequences.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {},
                        "design_traces": null
                    },
                    "SparseModularActivator": {
                        "review": null,
                        "requirements": "Applies differentiable sparse activation with learnable threshold.",
                        "reuse_from": null,
                        "desc": null,
                        "gautests": {
                            "unit_test_SparseModularActivator": "@gau_test\ndef test_SparseModularActivator_unit_test_SparseModularActivator(device=\n    None, dtype=None) ->None:\n    embed_dim = 16\n    batch_size = 2\n    seq_len = 5\n    sma = SparseModularActivator(embed_dim=embed_dim, block_loc=(0, 0),\n        kwarg_all={}, device=device, dtype=dtype)\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    X.requires_grad = True\n    Y, Z = sma(X)\n    assert Y.shape == X.shape, f'Output shape {Y.shape} does not match input shape {X.shape}'\n    assert 'mask' in Z, \"Intermediate variables Z should contain 'mask'\"\n    mask = Z['mask']\n    assert mask.shape == X.shape, f'Mask shape {mask.shape} does not match input shape {X.shape}'\n    assert torch.all((mask >= 0) & (mask <= 1)\n        ), 'Mask values should be between 0 and 1'\n    expected_Y = X * mask\n    assert torch.allclose(Y, expected_Y\n        ), 'Output Y should be input X multiplied by mask'\n    loss = Y.sum()\n    loss.backward()\n    assert X.grad is not None, 'Gradient w.r.t input X should not be None'\n    assert sma.gate.weight.grad is not None, 'Gradient w.r.t gate weights should not be None'\n    assert sma.threshold.grad is not None, 'Gradient w.r.t threshold should not be None'\n    print('Unit test passed for SparseModularActivator')\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass SparseModularActivator(GAUBase):\n    \"\"\"\n    The SparseModularActivator applies sparse activation to the input embeddings.\n    It computes activation scores using a linear layer, applies a sigmoid activation to obtain gating values,\n    and then uses a smooth approximation to thresholding to generate a soft mask.\n    The soft mask is used to selectively activate parts of the input while maintaining gradient flow.\n\n    **Key Attributes:**\n\n    - `gate`: Linear layer to compute activation scores from the input.\n    - `threshold`: Learnable parameter that determines the sparsity level.\n    - `temperature`: A hyperparameter to control the sharpness of the sigmoid function.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        temperature (float, optional): Controls the sharpness of the sigmoid function. Default: 20.0\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables (not used in this GAU).\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after applying sparse activation.\n        - **Z'**: Updated dictionary of intermediate variables, includes `'mask'` key.\n\n    **Example:**\n\n        >>> sma = SparseModularActivator(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sma(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n        >>> print('mask' in Z)\n        True\n\n    **Note:**\n\n        The sparsity of the output depends on the learnable `threshold` parameter and the `temperature`, which can be trained to achieve desired sparsity levels.\n\n    **References:**\n\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, temperature=20.0, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.gate = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.threshold = nn.Parameter(torch.zeros(1, **self.factory_kwargs))\n        self.temperature = temperature\n\n    def _forward(self, X, **Z):\n        scores = torch.sigmoid(self.gate(X))\n        mask = torch.sigmoid((scores - self.threshold) * self.temperature)\n        Y = X * mask\n        Z_ = {'mask': mask}\n        return Y, Z_\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"SparseModularActivator\",\"document\":\"The SparseModularActivator applies sparse activation to the input embeddings.\\nIt computes activation scores using a linear layer, applies a sigmoid activation to obtain gating values,\\nand then uses a smooth approximation to thresholding to generate a soft mask.\\nThe soft mask is used to selectively activate parts of the input while maintaining gradient flow.\\n\\n**Key Attributes:**\\n\\n- `gate`: Linear layer to compute activation scores from the input.\\n- `threshold`: Learnable parameter that determines the sparsity level.\\n- `temperature`: A hyperparameter to control the sharpness of the sigmoid function.\\n\\n**Args:**\\n\\n    embed_dim (int): The dimension of the input embeddings.\\n    block_loc (tuple): The location of the block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments for initialization.\\n    device (torch.device, optional): The device on which to allocate the module's parameters.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n    temperature (float, optional): Controls the sharpness of the sigmoid function. Default: 20.0\\n\\n**Inputs:**\\n\\n    - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\\n    - **Z**: Dictionary of intermediate variables (not used in this GAU).\\n\\n**Outputs:**\\n\\n    - **Y**: Tensor of shape `(B, L, D)`, the output after applying sparse activation.\\n    - **Z'**: Updated dictionary of intermediate variables, includes `'mask'` key.\\n\\n**Example:**\\n\\n    >>> sma = SparseModularActivator(embed_dim=512, block_loc=(0, 0), kwarg_all={})\\n    >>> X = torch.randn(2, 128, 512)\\n    >>> Y, Z = sma(X)\\n    >>> print(Y.shape)\\n    torch.Size([2, 128, 512])\\n    >>> print('mask' in Z)\\n    True\\n\\n**Note:**\\n\\n    The sparsity of the output depends on the learnable `threshold` parameter and the `temperature`, which can be trained to achieve desired sparsity levels.\\n\\n**References:**\\n\\n    - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\",\"mask\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {
                            "temperature": 20.0
                        },
                        "design_traces": null
                    },
                    "StateCompressor": {
                        "review": null,
                        "requirements": "Compresses and decompresses state information efficiently.",
                        "reuse_from": null,
                        "desc": null,
                        "gautests": {
                            "unit_test_StateCompressor": "@gau_test\ndef test_StateCompressor_unit_test_StateCompressor(device=None, dtype=None\n    ) ->None:\n    embed_dim = 16\n    batch_size = 2\n    seq_len = 5\n    sc = StateCompressor(embed_dim=embed_dim, block_loc=(0, 0), kwarg_all={\n        }, device=device, dtype=dtype)\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    X.requires_grad = True\n    Y, Z = sc(X)\n    assert Y.shape == X.shape, f'Output shape {Y.shape} does not match input shape {X.shape}'\n    loss = Y.sum()\n    loss.backward()\n    for name, param in sc.named_parameters():\n        if param.requires_grad:\n            assert param.grad is not None, f'Parameter {name} has no gradient'\n    assert X.grad is not None, 'Gradient w.r.t input X should not be None'\n    print('Unit test passed for StateCompressor')\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass StateCompressor(GAUBase):\n    \"\"\"\n    The StateCompressor compresses the state representations for efficient storage and decompresses them when needed.\n\n    **Key Components:**\n\n    - `compress`: Sequential module to compress the state.\n    - `decompress`: Sequential module to decompress the state.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the state to be compressed.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the decompressed state.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> sc = StateCompressor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = sc(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The compression reduces the dimension to half, which can be adjusted as needed.\n        - The compressed state could be stored or processed further before decompression.\n\n    **References:**\n\n        - Gu, A., and Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        compressed_dim = embed_dim // 2\n        self.compress = nn.Sequential(nn.Linear(embed_dim, compressed_dim,\n            bias=False, **self.factory_kwargs), nn.GELU(), nn.LayerNorm(\n            compressed_dim, **self.factory_kwargs))\n        self.decompress = nn.Sequential(nn.Linear(compressed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.LayerNorm(embed_dim, **\n            self.factory_kwargs))\n\n    def _forward(self, X, **Z):\n        compressed = self.compress(X)\n        Y = self.decompress(compressed)\n        return Y, Z\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"StateCompressor\",\"document\":\"The StateCompressor compresses the state representations for efficient storage and decompresses them when needed.\\n\\n**Key Components:**\\n\\n- `compress`: Sequential module to compress the state.\\n- `decompress`: Sequential module to decompress the state.\\n\\n**Args:**\\n\\n    embed_dim (int): The dimension of the input embeddings.\\n    block_loc (tuple): The location of the block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments for initialization.\\n    device (torch.device, optional): The device on which to allocate the module's parameters.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n\\n**Inputs:**\\n\\n    - **X**: Tensor of shape `(B, L, D)`, the state to be compressed.\\n    - **Z**: Dictionary of intermediate variables.\\n\\n**Outputs:**\\n\\n    - **Y**: Tensor of shape `(B, L, D)`, the decompressed state.\\n    - **Z'**: Updated dictionary of intermediate variables.\\n\\n**Example:**\\n\\n    >>> sc = StateCompressor(embed_dim=512, block_loc=(0, 0), kwarg_all={})\\n    >>> X = torch.randn(2, 128, 512)\\n    >>> Y, Z = sc(X)\\n    >>> print(Y.shape)\\n    torch.Size([2, 128, 512])\\n\\n**Note:**\\n\\n    - The compression reduces the dimension to half, which can be adjusted as needed.\\n    - The compressed state could be stored or processed further before decompression.\\n\\n**References:**\\n\\n    - Gu, A., and Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {},
                        "design_traces": null
                    },
                    "SparseStateBlock": {
                        "review": "# Implementation Review Report for SparseStateBlock\n\n## Overall Assessment\n\n```rating 4.5```\n\nThe implementation shows excellent design and functionality, with only minor improvements needed in unit tests and child declarations.\n\n## Strengths\n\n1. **Architecture Design**:\n   - Clean hierarchical structure with well-defined components\n   - Efficient state management through compression\n   - Smart use of sparse activation for computational efficiency\n   - IO-aware processing for hardware optimization\n\n2. **Code Quality**:\n   - Clear and consistent implementation style\n   - Robust error handling\n   - Well-documented interfaces\n   - Type hints and proper parameter handling\n\n3. **Performance Features**:\n   - Differentiable sparse activation\n   - Efficient chunk-based processing\n   - Adaptive state compression\n   - Residual connections for gradient flow\n\n## Areas for Improvement\n\n1. **Child Declarations**:\nAdd to each leaf GAU:\n```python\nCHILDREN_DECLARATIONS = []  # For leaf nodes\n```\n\nAnd for SparseStateBlock:\n```python\nCHILDREN_DECLARATIONS = [\n    UnitDecl(\n        unitname=\"SparseModularActivator\",\n        requirements=\"Applies differentiable sparse activation with temperature-controlled thresholding\",\n        inputs=[\"X\"],\n        outputs=[\"Y\", \"mask\"]\n    ),\n    UnitDecl(\n        unitname=\"StateCompressor\",\n        requirements=\"Compresses state with nonlinear transformations and normalization\",\n        inputs=[\"X\"],\n        outputs=[\"Y\"]\n    ),\n    UnitDecl(\n        unitname=\"IOAwareAdapter\",\n        requirements=\"Processes input in hardware-efficient chunks with padding handling\",\n        inputs=[\"X\"],\n        outputs=[\"Y\"]\n    ),\n    UnitDecl(\n        unitname=\"DenseStateProcessor\",\n        requirements=\"Processes states with dense connections and residual paths\",\n        inputs=[\"X\"],\n        outputs=[\"Y\"]\n    )\n]\n```\n\n2. **Unit Tests**:\nAdd comprehensive tests:\n```python\n@gau_test\ndef test_sparse_state_block(device=None, dtype=None):\n    model = SparseStateBlock(embed_dim=512, block_loc=(0,0), kwarg_all={}, \n                          device=device, dtype=dtype)\n    \n    # Test basic functionality\n    X = torch.randn(2, 128, 512, device=device, dtype=dtype)\n    Y, Z = model(X)\n    assert Y.shape == X.shape\n    assert 'mask' in Z\n    \n    # Test sparsity levels\n    mask = Z['mask']\n    sparsity = (mask < 0.5).float().mean()\n    print(f\"Activation sparsity: {sparsity.item():.2%}\")\n    assert 0.1 <= sparsity <= 0.9, \"Sparsity should be reasonable\"\n    \n    # Test gradient flow\n    loss = Y.mean()\n    loss.backward()\n    for name, param in model.named_parameters():\n        assert param.grad is not None, f\"No gradient for {name}\"\n    \n    # Test different sequence lengths\n    for seq_len in [64, 256, 1024]:\n        X = torch.randn(2, seq_len, 512, device=device, dtype=dtype)\n        Y, _ = model(X)\n        assert Y.shape == X.shape\n```\n\n3. **Memory Optimization**:\nAdd gradient checkpointing:\n```python\nclass SparseStateBlock(GAUBase):\n    def __init__(self, ...):\n        ...\n        self.use_checkpointing = True\n        \n    def _forward(self, X, **Z):\n        def _run_forward(x):\n            active_x, z = self.sparse_activator(x, **Z)\n            mask = z.get('mask', None)\n            if mask is not None and mask.sum() > 0:\n                processed = self.dense_processor(active_x, **z)[0]\n                compressed = self.state_compressor(processed, **z)[0]\n                if self.training:\n                    adapted = self.io_adapter(compressed, **z)[0]\n                else:\n                    adapted = compressed\n            else:\n                adapted = x\n            return self.norm(adapted)\n            \n        if self.use_checkpointing and self.training:\n            return torch.utils.checkpoint.checkpoint(_run_forward, X), Z\n        return _run_forward(X), Z\n```\n\n## Innovation and Impact\n\n1. **Technical Innovations**:\n   - Smooth differentiable sparse activation\n   - Efficient state compression with nonlinear transformations\n   - IO-aware chunk processing with padding handling\n   - Adaptive processing based on sparsity levels\n\n2. **Scalability Benefits**:\n   - Linear memory complexity through compression\n   - Efficient processing of long sequences\n   - Hardware-friendly computation patterns\n   - Controllable sparsity levels\n\n3. **Integration Advantages**:\n   - Clean interfaces between components\n   - Modular design for easy modifications\n   - Stable gradient flow through careful normalization\n   - Flexible configuration options\n\n## Recommendations\n\n1. **Implementation Priorities**:\n   - Add CHILDREN_DECLARATIONS to all components\n   - Implement comprehensive unit tests\n   - Add gradient checkpointing for memory efficiency\n\n2. **Performance Optimization**:\n```python\nclass IOAwareAdapter(GAUBase):\n    def __init__(self, ..., min_chunk_size=64, max_chunk_size=1024):\n        ...\n        self.min_chunk_size = min_chunk_size\n        self.max_chunk_size = max_chunk_size\n        \n    def _get_optimal_chunk_size(self, seq_len):\n        # Adaptive chunk sizing based on sequence length and hardware\n        base_size = min(seq_len, self.chunk_size)\n        # Round to nearest power of 2 for hardware efficiency\n        return 2 ** int(torch.log2(torch.tensor(\n            max(self.min_chunk_size, min(self.max_chunk_size, base_size))\n        )).ceil().item())\n```\n\n3. **Documentation Additions**:\n   - Add performance benchmarks\n   - Document expected sparsity patterns\n   - Include hardware recommendations\n   - Add integration guidelines\n\n4. **Testing Strategy**:\n   - Add stress tests for long sequences\n   - Test memory usage patterns\n   - Verify gradient flow\n   - Benchmark against baselines\n\nThe implementation is very strong, showing excellent attention to both theoretical soundness and practical efficiency. The main improvements needed are in documentation and testing rather than core functionality.",
                        "requirements": "N/A",
                        "reuse_from": null,
                        "desc": null,
                        "gautests": {
                            "unit_test_SparseStateBlock": "@gau_test\ndef test_SparseStateBlock_unit_test_SparseStateBlock(device=None, dtype=None\n    ) ->None:\n    embed_dim = 16\n    batch_size = 2\n    seq_len = 5\n    ssb = SparseStateBlock(embed_dim=embed_dim, block_loc=(0, 0), kwarg_all\n        ={}, device=device, dtype=dtype)\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    X.requires_grad = True\n    Y, Z = ssb(X)\n    assert Y.shape == X.shape, f'Output shape {Y.shape} does not match input shape {X.shape}'\n    assert torch.isfinite(Y).all(), 'Output contains NaNs or Infs'\n    loss = Y.sum()\n    loss.backward()\n    for name, param in ssb.named_parameters():\n        if param.requires_grad:\n            assert param.grad is not None, f'Parameter {name} has no gradient'\n    assert X.grad is not None, 'Gradient w.r.t input X should not be None'\n    print('Unit test passed for SparseStateBlock')\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass SparseStateBlock(GAUBase):\n    \"\"\"\n    SparseStateBlock integrates sparse activation, state compression, IO-aware adaptation, and dense processing\n    to efficiently manage state and computation in language modeling tasks.\n\n    **Core Components:**\n\n    - `sparse_activator`: Applies sparse modular activation to selectively activate parts of the input.\n    - `state_compressor`: Compresses and decompresses state representations for efficient storage.\n    - `io_adapter`: Adapts computation in an IO-aware manner to improve hardware efficiency.\n    - `dense_processor`: Processes active states with dense connections to maintain information flow.\n    - `norm`: Applies Layer Normalization to stabilize outputs.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the output after processing.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ssb = SparseStateBlock(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 128, 512)\n        >>> Y, Z = ssb(X)\n        >>> print(Y.shape)\n        torch.Size([2, 128, 512])\n\n    **Note:**\n\n        - The module integrates multiple components to efficiently process sequences.\n        - It relies on child GAUs for specific functionalities.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n        - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.sparse_activator = SparseModularActivator(embed_dim=\n            self.embed_dim, block_loc=self.block_loc, kwarg_all=\n            self.kwarg_all, **self.factory_kwargs, **self.kwarg_all)\n        self.state_compressor = StateCompressor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **\n            self.factory_kwargs, **self.kwarg_all)\n        self.io_adapter = IOAwareAdapter(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **\n            self.factory_kwargs, **self.kwarg_all)\n        self.dense_processor = DenseStateProcessor(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **\n            self.factory_kwargs, **self.kwarg_all)\n        self.norm = nn.LayerNorm(embed_dim, **self.factory_kwargs)\n\n    def _forward(self, X, **Z):\n        active_X, Z = self.sparse_activator(X, **Z)\n        mask = Z.get('mask', None)\n        if mask is not None and mask.sum() > 0:\n            processed, Z = self.dense_processor(active_X, **Z)\n            compressed, Z = self.state_compressor(processed, **Z)\n            if self.training:\n                adapted, Z = self.io_adapter(compressed, **Z)\n            else:\n                adapted = compressed\n        else:\n            adapted = X\n        Y = self.norm(adapted)\n        return Y, Z\n",
                        "rating": 4.5,
                        "spec": "{\"unitname\":\"SparseStateBlock\",\"document\":\"SparseStateBlock integrates sparse activation, state compression, IO-aware adaptation, and dense processing\\nto efficiently manage state and computation in language modeling tasks.\\n\\n**Core Components:**\\n\\n- `sparse_activator`: Applies sparse modular activation to selectively activate parts of the input.\\n- `state_compressor`: Compresses and decompresses state representations for efficient storage.\\n- `io_adapter`: Adapts computation in an IO-aware manner to improve hardware efficiency.\\n- `dense_processor`: Processes active states with dense connections to maintain information flow.\\n- `norm`: Applies Layer Normalization to stabilize outputs.\\n\\n**Args:**\\n\\n    embed_dim (int): The dimension of the input embeddings.\\n    block_loc (tuple): The location of the block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments for initialization.\\n    device (torch.device, optional): The device on which to allocate the module's parameters.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n\\n**Inputs:**\\n\\n    - **X**: Tensor of shape `(B, L, D)`, where `B` is batch size, `L` is sequence length, and `D` is embedding dimension.\\n    - **Z**: Dictionary of intermediate variables.\\n\\n**Outputs:**\\n\\n    - **Y**: Tensor of shape `(B, L, D)`, the output after processing.\\n    - **Z'**: Updated dictionary of intermediate variables.\\n\\n**Example:**\\n\\n    >>> ssb = SparseStateBlock(embed_dim=512, block_loc=(0, 0), kwarg_all={})\\n    >>> X = torch.randn(2, 128, 512)\\n    >>> Y, Z = ssb(X)\\n    >>> print(Y.shape)\\n    torch.Size([2, 128, 512])\\n\\n**Note:**\\n\\n    - The module integrates multiple components to efficiently process sequences.\\n    - It relies on child GAUs for specific functionalities.\\n\\n**References:**\\n\\n    - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\\n    - Ren, L., et al. (2023). Sparse Modular Activation for Efficient Sequence Modeling.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [
                            "SparseModularActivator",
                            "StateCompressor",
                            "IOAwareAdapter",
                            "DenseStateProcessor"
                        ],
                        "suggestions": null,
                        "args": {},
                        "design_traces": null
                    },
                    "IOAwareAdapter": {
                        "review": null,
                        "requirements": "Adapts state management for hardware-efficient IO.",
                        "reuse_from": null,
                        "desc": null,
                        "gautests": {
                            "unit_test_IOAwareAdapter": "@gau_test\ndef test_IOAwareAdapter_unit_test_IOAwareAdapter(device=None, dtype=None\n    ) ->None:\n    embed_dim = 16\n    batch_size = 2\n    seq_len = 1024\n    chunk_size = 128\n    ioa = IOAwareAdapter(embed_dim=embed_dim, block_loc=(0, 0), kwarg_all={\n        }, device=device, dtype=dtype, chunk_size=chunk_size)\n    X = torch.randn(batch_size, seq_len, embed_dim, device=device, dtype=dtype)\n    X.requires_grad = True\n    Y, Z = ioa(X)\n    assert Y.shape == X.shape, f'Output shape {Y.shape} does not match input shape {X.shape}'\n    loss = Y.sum()\n    loss.backward()\n    for name, param in ioa.named_parameters():\n        if param.requires_grad:\n            assert param.grad is not None, f'Parameter {name} has no gradient'\n    assert X.grad is not None, 'Gradient w.r.t input X should not be None'\n    print('Unit test passed for IOAwareAdapter')\n"
                        },
                        "code": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass IOAwareAdapter(GAUBase):\n    \"\"\"\n    The IOAwareAdapter processes the input in chunks to optimize for IO efficiency.\n    It adapts computation to be hardware-friendly, improving inference speed and memory access patterns.\n\n    **Key Components:**\n\n    - `adapter`: Linear layer to adapt the input.\n    - `chunk_size`: Integer specifying the size of each chunk.\n\n    **Args:**\n\n        embed_dim (int): The dimension of the input embeddings.\n        block_loc (tuple): The location of the block within the network.\n        kwarg_all (dict): Dictionary of all keyword arguments for initialization.\n        device (torch.device, optional): The device on which to allocate the module's parameters.\n        dtype (torch.dtype, optional): The data type of the module's parameters.\n        chunk_size (int, optional): The size of each chunk for processing.\n\n    **Inputs:**\n\n        - **X**: Tensor of shape `(B, L, D)`, the input tensor to be adapted.\n        - **Z**: Dictionary of intermediate variables.\n\n    **Outputs:**\n\n        - **Y**: Tensor of shape `(B, L, D)`, the adapted output tensor.\n        - **Z'**: Updated dictionary of intermediate variables.\n\n    **Example:**\n\n        >>> ioa = IOAwareAdapter(embed_dim=512, block_loc=(0, 0), kwarg_all={})\n        >>> X = torch.randn(2, 1024, 512)\n        >>> Y, Z = ioa(X)\n        >>> print(Y.shape)\n        torch.Size([2, 1024, 512])\n\n    **Note:**\n\n        - Processing in chunks can improve cache utilization and overall computational efficiency.\n        - The chunk size can be adjusted based on hardware specifications.\n\n    **References:**\n\n        - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, chunk_size=256, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.adapter = nn.Linear(embed_dim, embed_dim, bias=True, **self.\n            factory_kwargs)\n        self.chunk_size = chunk_size\n\n    def _forward(self, X, **Z):\n        B, L, D = X.size()\n        pad_len = (self.chunk_size - L % self.chunk_size) % self.chunk_size\n        if pad_len > 0:\n            padding = torch.zeros(B, pad_len, D, device=X.device, dtype=X.dtype\n                )\n            X_padded = torch.cat([X, padding], dim=1)\n        else:\n            X_padded = X\n        num_chunks = X_padded.size(1) // self.chunk_size\n        X_chunks = X_padded.view(B, num_chunks, self.chunk_size, D).contiguous(\n            )\n        X_chunks = X_chunks.view(-1, self.chunk_size, D)\n        adapted_chunks = self.adapter(X_chunks)\n        adapted_padded = adapted_chunks.view(B, num_chunks * self.chunk_size, D\n            )\n        Y = adapted_padded[:, :L, :]\n        return Y, Z\n",
                        "rating": null,
                        "spec": "{\"unitname\":\"IOAwareAdapter\",\"document\":\"The IOAwareAdapter processes the input in chunks to optimize for IO efficiency.\\nIt adapts computation to be hardware-friendly, improving inference speed and memory access patterns.\\n\\n**Key Components:**\\n\\n- `adapter`: Linear layer to adapt the input.\\n- `chunk_size`: Integer specifying the size of each chunk.\\n\\n**Args:**\\n\\n    embed_dim (int): The dimension of the input embeddings.\\n    block_loc (tuple): The location of the block within the network.\\n    kwarg_all (dict): Dictionary of all keyword arguments for initialization.\\n    device (torch.device, optional): The device on which to allocate the module's parameters.\\n    dtype (torch.dtype, optional): The data type of the module's parameters.\\n    chunk_size (int, optional): The size of each chunk for processing.\\n\\n**Inputs:**\\n\\n    - **X**: Tensor of shape `(B, L, D)`, the input tensor to be adapted.\\n    - **Z**: Dictionary of intermediate variables.\\n\\n**Outputs:**\\n\\n    - **Y**: Tensor of shape `(B, L, D)`, the adapted output tensor.\\n    - **Z'**: Updated dictionary of intermediate variables.\\n\\n**Example:**\\n\\n    >>> ioa = IOAwareAdapter(embed_dim=512, block_loc=(0, 0), kwarg_all={})\\n    >>> X = torch.randn(2, 1024, 512)\\n    >>> Y, Z = ioa(X)\\n    >>> print(Y.shape)\\n    torch.Size([2, 1024, 512])\\n\\n**Note:**\\n\\n    - Processing in chunks can improve cache utilization and overall computational efficiency.\\n    - The chunk size can be adjusted based on hardware specifications.\\n\\n**References:**\\n\\n    - Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                        "children": [],
                        "suggestions": null,
                        "args": {
                            "chunk_size": 256
                        },
                        "design_traces": null
                    }
                },
                "rating": 0,
                "declares": {
                    "DenseStateProcessor": "{\"unitname\":\"DenseStateProcessor\",\"requirements\":\"Processes active states with dense transformations.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                    "SparseModularActivator": "{\"unitname\":\"SparseModularActivator\",\"requirements\":\"Applies differentiable sparse activation with learnable threshold.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\",\"mask\"]}",
                    "StateCompressor": "{\"unitname\":\"StateCompressor\",\"requirements\":\"Compresses and decompresses state information efficiently.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                    "SparseStateBlock": "{\"unitname\":\"SparseStateBlock\",\"requirements\":\"N/A\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}",
                    "IOAwareAdapter": "{\"unitname\":\"IOAwareAdapter\",\"requirements\":\"Adapts state management for hardware-efficient IO.\",\"inputs\":[\"X\"],\"outputs\":[\"Y\"]}"
                },
                "proposal_traces": [],
                "suggestions": "",
                "name": "sparsestategau"
            },
            "user_input": "",
            "status": "implemented",
            "design_cfg": {
                "max_attemps": {
                    "post_refinement": 0,
                    "max_search_rounds": 3,
                    "implementation_debug": 7,
                    "design_proposal": 10
                },
                "threshold": {
                    "proposal_rating": 4.0,
                    "implementation_rating": 3.0
                },
                "use_unlimited_prompt": true,
                "mutation_no_tree": true,
                "agent_types": {
                    "DESIGN_PROPOSER": "hybrid",
                    "IMPLEMENTATION_PLANNER": "hybrid",
                    "IMPLEMENTATION_CODER": "hybrid",
                    "PROPOSAL_REVIEWER": "hybrid",
                    "IMPLEMENTATION_OBSERVER": "hybrid",
                    "SEARCH_ASSISTANT": "None"
                },
                "running_mode": "Proposal + Implementation",
                "unittest_pass_required": false,
                "crossover_no_ref": true,
                "scratch_no_tree": true,
                "_agent_types": {
                    "DESIGN_PROPOSER": "claude3.5_sonnet",
                    "IMPLEMENTATION_PLANNER": "o1_mini",
                    "IMPLEMENTATION_CODER": "o1_preview",
                    "PROPOSAL_REVIEWER": "claude3.5_sonnet",
                    "IMPLEMENTATION_OBSERVER": "claude3.5_sonnet",
                    "SEARCH_ASSISTANT": "None"
                },
                "termination": {
                    "max_debug_budget": 0,
                    "max_failed_rounds": 3,
                    "max_total_budget": 0
                },
                "agent_weights": {
                    "DESIGN_PROPOSER": [
                        0.05,
                        0.0,
                        0.6000000000000001,
                        0.2,
                        0.15
                    ],
                    "IMPLEMENTATION_PLANNER": [
                        0.05000000000000002,
                        0.0,
                        0.44999999999999996,
                        0.3,
                        0.20000000000000007
                    ],
                    "IMPLEMENTATION_CODER": [
                        0.0,
                        0.0,
                        0.3,
                        0.4999999999999996,
                        0.2
                    ],
                    "PROPOSAL_REVIEWER": [
                        0.10000000000000002,
                        0.0,
                        0.5499999999999999,
                        0.2,
                        0.15000000000000002
                    ],
                    "IMPLEMENTATION_OBSERVER": [
                        0.05,
                        0.0,
                        0.15000000000000002,
                        0.15000000000000002,
                        0.6499999999999999,
                        0.0
                    ]
                },
                "num_samples": {
                    "implementation": 1,
                    "rerank_method": "rating",
                    "proposal": 1
                },
                "search_settings": {
                    "proposal_search": true,
                    "proposal_review_search": true,
                    "search_for_papers_num": 10
                },
                "max_attempts": {
                    "post_refinement": 0,
                    "max_search_rounds": 4,
                    "implementation_debug": 5,
                    "design_proposal": 5
                }
            },
            "costs": {
                "DESIGN_PROPOSER": 0,
                "IMPLEMENTATION_PLANNER": 0.16581600000000002,
                "IMPLEMENTATION_CODER": 4.6883550000000005,
                "PROPOSAL_REVIEWER": 0,
                "IMPLEMENTATION_OBSERVER": 0.68832,
                "SEARCH_ASSISTANT": 0
            }
        }
    ]
}