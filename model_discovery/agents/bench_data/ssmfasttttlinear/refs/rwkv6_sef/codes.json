{
    "31M": {
        "31M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RWKV6(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RWKV6(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        norm_eps: float=1e-05, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.attn = RWKV6Attention(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.ffn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.ffn = RWKV6FeedForwardSEF(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, _ = self.attn(self.attn_norm(X), **Z)\n        X = X1 + X\n        X2, _ = self.ffn(self.ffn_norm(X), **Z)\n        X = X2 + X\n        return X\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass RWKV6FeedForwardSEF(GAUBase):\n    \"\"\"\n    Enhanced RWKV6 Feed Forward block with State Expansion Features (SEF).\n    \n    This implementation enhances the original RWKV6FeedForward by incorporating:\n    1. Parameter-efficient state expansion using Group Linear Transformation (GLT)\n    2. Hierarchical gating with learnable bounds\n    3. Expanded state management\n    \n    Args:\n        embed_dim (int): Input embedding dimension\n        block_loc (tuple): Location of block in network (layer_idx, n_block)\n        kwarg_all (dict): Additional arguments\n        state_expansion_ratio (int): Ratio for state expansion (default: 4)\n        min_gating_bound (float): Minimum value for gating bounds (default: 0.1)\n        device (Optional[torch.device]): Device to place tensors\n        dtype (Optional[torch.dtype]): Data type of tensors\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        state_expansion_ratio: int=4, min_gating_bound: float=0.1, device=\n        None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.state_expansion_ratio = state_expansion_ratio\n        self.min_gating_bound = min_gating_bound\n        self.num_groups = state_expansion_ratio\n        self.group_size = embed_dim // state_expansion_ratio\n        assert embed_dim % state_expansion_ratio == 0, f'embed_dim must be divisible by state_expansion_ratio, got {embed_dim} and {state_expansion_ratio}'\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = self.group_size\n        self.key_groups = nn.ModuleList([LerpLinear(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all) for _ in range(self.\n            num_groups)])\n        self.beta = nn.Parameter(torch.zeros(self.num_groups, device=device,\n            dtype=dtype))\n        self.value = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        kwarg_all['output_dim'] = embed_dim\n        self.receptance = LerpLinear(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n        self.relu = nn.ReLU()\n        self.gelu = nn.GELU()\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        \"\"\"Initialize parameters with appropriate bounds\"\"\"\n        with torch.no_grad():\n            self.beta.data.fill_(self.min_gating_bound)\n\n    def _compute_hierarchical_gates(self, gates: torch.Tensor) ->torch.Tensor:\n        \"\"\"Compute hierarchical gates with learned lower bounds\"\"\"\n        beta_cumsum = torch.cumsum(F.softplus(self.beta), dim=0)\n        beta_norm = beta_cumsum / beta_cumsum[-1].clamp(min=1e-05)\n        batch_size, seq_len, _ = gates.shape\n        gates = gates.view(batch_size, seq_len, self.num_groups, -1)\n        gates = gates * beta_norm.view(1, 1, self.num_groups, 1)\n        return gates.view(batch_size, seq_len, -1)\n\n    def _forward(self, X: torch.Tensor, **Z) ->torch.Tensor:\n        \"\"\"\n        Forward pass with state expansion and hierarchical gating.\n        \n        Args:\n            X: Input tensor of shape (batch_size, seq_len, embed_dim)\n            \n        Returns:\n            Output tensor of shape (batch_size, seq_len, embed_dim)\n        \"\"\"\n        shifted = self.time_shift(X)\n        delta = shifted - X\n        key_expanded = []\n        for group in range(self.num_groups):\n            key_group = self.key_groups[group](X, delta=delta)[1]['o']\n            key_expanded.append(key_group)\n        key_combined = torch.cat(key_expanded, dim=-1)\n        r = self.relu(key_combined)\n        key = r * r\n        key = self.gelu(key)\n        value = self.value(key)\n        receptance = self.receptance(X, delta=delta)[1]['o']\n        receptance = self._compute_hierarchical_gates(receptance)\n        return receptance.sigmoid() * value\n\n    def extra_repr(self) ->str:\n        \"\"\"Return extra representation string\"\"\"\n        return (\n            f'embed_dim={self.hidden_size}, expansion_ratio={self.state_expansion_ratio}'\n            )\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if self.low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n        self.mu = nn.Parameter(torch.zeros(embed_dim, device=device, dtype=\n            dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _forward(self, X: torch.Tensor, delta: Optional[torch.Tensor]=None\n        ) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(X)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - X\n        if self.low_rank_dim is None:\n            o = self.linear(X + delta * self.mu)\n        else:\n            o = self.linear(X + delta * self.mu)[1]['o']\n        return X, {'o': o}\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LoRA(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: int, bias: Optional[bool]=True,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.bias = bias\n        self.lora = nn.Sequential(nn.Linear(embed_dim, low_rank_dim, bias=\n            False, device=device, dtype=dtype), nn.Tanh(), nn.Linear(\n            low_rank_dim, output_dim, bias=bias, device=device, dtype=dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}('\n        s += (\n            f'input_dim={self.input_dim}, low_rank_dim={self.low_rank_dim}, output_dim={self.output_dim}'\n            )\n        if not self.bias:\n            s += f', bias={self.bias}'\n        s += ')'\n        return s\n\n    def _forward(self, X, **Z):\n        return X, {'o': self.lora(X)}\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom transformers.activations import ACT2FN\nfrom typing import Optional\n\n\nclass RWKV6Attention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        num_heads: int=4, gate_fn: str='swish', proj_low_rank_dim: int=32,\n        gate_low_rank_dim: int=64, elementwise_affine: Optional[bool]=True,\n        norm_eps: float=1e-05, chunk_size: int=32, device=None, dtype=None,\n        **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.num_heads = num_heads\n        self.proj_low_rank_dim = proj_low_rank_dim\n        self.gate_low_rank_dim = gate_low_rank_dim\n        self.chunk_size = chunk_size\n        self.key_dim = embed_dim // 2\n        self.value_dim = embed_dim\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = proj_low_rank_dim * 5\n        self.x_proj = nn.Sequential(LerpLinear(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all), nn.Tanh(), nn.Linear(\n            proj_low_rank_dim * 5, embed_dim, bias=False, device=device,\n            dtype=dtype))\n        self.x_bias = nn.Parameter(torch.zeros(5, embed_dim, device=device,\n            dtype=dtype))\n        kwarg_all['output_dim'] = self.key_dim\n        self.r_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.w_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all.pop('low_rank_dim')\n        self.k_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['output_dim'] = self.value_dim\n        self.v_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.g_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.bonus = nn.Parameter(torch.zeros(num_heads, self.head_qk_dim,\n            device=device, dtype=dtype))\n        self.g_norm = nn.LayerNorm(self.value_dim, elementwise_affine=\n            elementwise_affine, eps=norm_eps, device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        self.gate_fn = ACT2FN[gate_fn]\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        if isinstance(module, nn.Parameter):\n            nn.init.xavier_uniform_(module, gain=2 ** -2.5)\n        module._is_hf_initialized = True\n\n    def naive_chunk_rwkv6(self, q: torch.Tensor, k: torch.Tensor, v: torch.\n        Tensor, w: torch.Tensor, u: torch.Tensor, chunk_size: int=32):\n        assert q.shape[-2] % chunk_size == 0\n        orig_dtype = q.dtype\n        num_chunk = q.shape[-2] // chunk_size\n        u = u.unsqueeze(0)\n        q, k, v, w = map(lambda x: rearrange(x, 'b h (n c) d -> b h n c d',\n            c=chunk_size).float(), (q, k, v, w))\n        w_cumsum = w.cumsum(-2)\n        kw = k * (w_cumsum[..., -1, None, :] - w_cumsum).exp()\n        wkv = kw.transpose(-1, -2) @ v\n        wkv_new = torch.zeros_like(wkv)\n        for i in range(num_chunk - 1):\n            wkv_new[:, :, i + 1] = wkv_new[:, :, i].clone() * w_cumsum[:, :,\n                i, -1, :, None].exp() + wkv[:, :, i]\n        o_inter = torch.einsum('b h n d p, b h n c d -> b h n c p', wkv_new,\n            q * (w_cumsum - w).exp())\n        o_intra = torch.zeros_like(o_inter)\n        for i in range(chunk_size):\n            attn = (q[:, :, :, i, None] * k * (w_cumsum[:, :, :, i, None] -\n                w[:, :, :, i, None] - w_cumsum).exp()).sum(-1)\n            mask = (torch.arange(0, chunk_size) < i).to(attn.device)\n            attn.masked_fill_(~mask, 0)\n            intra_inter_o = (attn.unsqueeze(-1) * v).sum(-2)\n            intra_intra_o = (q[:, :, :, i] * u.unsqueeze(2) * k[:, :, :, i]\n                ).sum(-1).unsqueeze(-1) * v[:, :, :, i]\n            o_intra[:, :, :, i] = intra_inter_o + intra_intra_o\n        o = o_inter + o_intra\n        return rearrange(o, 'b h n c d -> b h (n c) d').to(orig_dtype)\n\n    def pad_input(self, X):\n        _seq_len = X.shape[-2]\n        pad_len = (X.shape[-2] + self.chunk_size - 1\n            ) // self.chunk_size * self.chunk_size - X.shape[-2]\n        return F.pad(X, (0, 0, 0, pad_len)), _seq_len\n\n    def _forward(self, X: torch.Tensor):\n        X, _seq_len = self.pad_input(X)\n        batch_size, seq_len, hidden_size = X.shape\n        last_state = None\n        if X.shape[1] == 1 and last_state is not None:\n            shifted = last_state[0].unsqueeze(1)\n        else:\n            shifted = self.time_shift(X)\n            if last_state is not None:\n                shifted[:, 0] = last_state[0]\n        delta = shifted - X\n        x = self.x_proj[0](X, **{'delta': delta})[1]['o'].view(batch_size,\n            seq_len, -1, self.proj_low_rank_dim)\n        x = torch.einsum('b l n r, h n r-> b l n h', self.x_proj[1](x),\n            self.x_proj[2].weight.view(hidden_size, 5, -1))\n        r, w, k, v, g = x.add_(self.x_bias).unbind(-2)\n        r = self.r_proj(X, **{'mu': r, 'delta': delta})[1]['o']\n        w = self.w_proj(X, **{'mu': w, 'delta': delta})[1]['o']\n        k = self.k_proj(X, **{'mu': k, 'delta': delta})[1]['o']\n        v = self.v_proj(X, **{'mu': v, 'delta': delta})[1]['o']\n        g = self.g_proj(X, **{'mu': g, 'delta': delta})[1]['o']\n        r, w, k, v = map(lambda x: rearrange(x, 'b l (h d) -> b h l d', h=\n            self.num_heads), (r, w, k, v))\n        w = -torch.exp(w)\n        u = self.bonus\n        o = self.naive_chunk_rwkv6(r, k, v, w, u, chunk_size=self.chunk_size)\n        o = rearrange(o, 'b h l d -> b l (h d)')\n        o = self.g_norm(o)\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        o = o[:, :_seq_len]\n        return o\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass DDLerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def forward(self, x: torch.Tensor, mu: torch.Tensor, delta: Optional[\n        torch.Tensor]=None) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(x)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - x\n        if self.low_rank_dim is None:\n            o = self.linear(x + delta * mu)\n        else:\n            o = self.linear(x + delta * mu)[1]['o']\n        return x, {'o': o}\n\n\ngab_config = {'num_heads': 4, 'gate_fn': 'swish', 'proj_low_rank_dim': 32,\n    'gate_low_rank_dim': 64, 'elementwise_affine': True, 'chunk_size': 32,\n    'norm_eps': 1e-05, 'state_expansion_ratio': 4, 'min_gating_bound': 0.1}\n\n\n\nautoconfig={}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "760M": {
        "760M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RWKV6(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RWKV6(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        norm_eps: float=1e-05, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.attn = RWKV6Attention(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.ffn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.ffn = RWKV6FeedForwardSEF(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, _ = self.attn(self.attn_norm(X), **Z)\n        X = X1 + X\n        X2, _ = self.ffn(self.ffn_norm(X), **Z)\n        X = X2 + X\n        return X\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass RWKV6FeedForwardSEF(GAUBase):\n    \"\"\"\n    Enhanced RWKV6 Feed Forward block with State Expansion Features (SEF).\n    \n    This implementation enhances the original RWKV6FeedForward by incorporating:\n    1. Parameter-efficient state expansion using Group Linear Transformation (GLT)\n    2. Hierarchical gating with learnable bounds\n    3. Expanded state management\n    \n    Args:\n        embed_dim (int): Input embedding dimension\n        block_loc (tuple): Location of block in network (layer_idx, n_block)\n        kwarg_all (dict): Additional arguments\n        state_expansion_ratio (int): Ratio for state expansion (default: 4)\n        min_gating_bound (float): Minimum value for gating bounds (default: 0.1)\n        device (Optional[torch.device]): Device to place tensors\n        dtype (Optional[torch.dtype]): Data type of tensors\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        state_expansion_ratio: int=4, min_gating_bound: float=0.1, device=\n        None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.state_expansion_ratio = state_expansion_ratio\n        self.min_gating_bound = min_gating_bound\n        self.num_groups = state_expansion_ratio\n        self.group_size = embed_dim // state_expansion_ratio\n        assert embed_dim % state_expansion_ratio == 0, f'embed_dim must be divisible by state_expansion_ratio, got {embed_dim} and {state_expansion_ratio}'\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = self.group_size\n        self.key_groups = nn.ModuleList([LerpLinear(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all) for _ in range(self.\n            num_groups)])\n        self.beta = nn.Parameter(torch.zeros(self.num_groups, device=device,\n            dtype=dtype))\n        self.value = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        kwarg_all['output_dim'] = embed_dim\n        self.receptance = LerpLinear(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n        self.relu = nn.ReLU()\n        self.gelu = nn.GELU()\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        \"\"\"Initialize parameters with appropriate bounds\"\"\"\n        with torch.no_grad():\n            self.beta.data.fill_(self.min_gating_bound)\n\n    def _compute_hierarchical_gates(self, gates: torch.Tensor) ->torch.Tensor:\n        \"\"\"Compute hierarchical gates with learned lower bounds\"\"\"\n        beta_cumsum = torch.cumsum(F.softplus(self.beta), dim=0)\n        beta_norm = beta_cumsum / beta_cumsum[-1].clamp(min=1e-05)\n        batch_size, seq_len, _ = gates.shape\n        gates = gates.view(batch_size, seq_len, self.num_groups, -1)\n        gates = gates * beta_norm.view(1, 1, self.num_groups, 1)\n        return gates.view(batch_size, seq_len, -1)\n\n    def _forward(self, X: torch.Tensor, **Z) ->torch.Tensor:\n        \"\"\"\n        Forward pass with state expansion and hierarchical gating.\n        \n        Args:\n            X: Input tensor of shape (batch_size, seq_len, embed_dim)\n            \n        Returns:\n            Output tensor of shape (batch_size, seq_len, embed_dim)\n        \"\"\"\n        shifted = self.time_shift(X)\n        delta = shifted - X\n        key_expanded = []\n        for group in range(self.num_groups):\n            key_group = self.key_groups[group](X, delta=delta)[1]['o']\n            key_expanded.append(key_group)\n        key_combined = torch.cat(key_expanded, dim=-1)\n        r = self.relu(key_combined)\n        key = r * r\n        key = self.gelu(key)\n        value = self.value(key)\n        receptance = self.receptance(X, delta=delta)[1]['o']\n        receptance = self._compute_hierarchical_gates(receptance)\n        return receptance.sigmoid() * value\n\n    def extra_repr(self) ->str:\n        \"\"\"Return extra representation string\"\"\"\n        return (\n            f'embed_dim={self.hidden_size}, expansion_ratio={self.state_expansion_ratio}'\n            )\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if self.low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n        self.mu = nn.Parameter(torch.zeros(embed_dim, device=device, dtype=\n            dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _forward(self, X: torch.Tensor, delta: Optional[torch.Tensor]=None\n        ) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(X)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - X\n        if self.low_rank_dim is None:\n            o = self.linear(X + delta * self.mu)\n        else:\n            o = self.linear(X + delta * self.mu)[1]['o']\n        return X, {'o': o}\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LoRA(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: int, bias: Optional[bool]=True,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.bias = bias\n        self.lora = nn.Sequential(nn.Linear(embed_dim, low_rank_dim, bias=\n            False, device=device, dtype=dtype), nn.Tanh(), nn.Linear(\n            low_rank_dim, output_dim, bias=bias, device=device, dtype=dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}('\n        s += (\n            f'input_dim={self.input_dim}, low_rank_dim={self.low_rank_dim}, output_dim={self.output_dim}'\n            )\n        if not self.bias:\n            s += f', bias={self.bias}'\n        s += ')'\n        return s\n\n    def _forward(self, X, **Z):\n        return X, {'o': self.lora(X)}\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom transformers.activations import ACT2FN\nfrom typing import Optional\n\n\nclass RWKV6Attention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        num_heads: int=4, gate_fn: str='swish', proj_low_rank_dim: int=32,\n        gate_low_rank_dim: int=64, elementwise_affine: Optional[bool]=True,\n        norm_eps: float=1e-05, chunk_size: int=32, device=None, dtype=None,\n        **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.num_heads = num_heads\n        self.proj_low_rank_dim = proj_low_rank_dim\n        self.gate_low_rank_dim = gate_low_rank_dim\n        self.chunk_size = chunk_size\n        self.key_dim = embed_dim // 2\n        self.value_dim = embed_dim\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = proj_low_rank_dim * 5\n        self.x_proj = nn.Sequential(LerpLinear(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all), nn.Tanh(), nn.Linear(\n            proj_low_rank_dim * 5, embed_dim, bias=False, device=device,\n            dtype=dtype))\n        self.x_bias = nn.Parameter(torch.zeros(5, embed_dim, device=device,\n            dtype=dtype))\n        kwarg_all['output_dim'] = self.key_dim\n        self.r_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.w_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all.pop('low_rank_dim')\n        self.k_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['output_dim'] = self.value_dim\n        self.v_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.g_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.bonus = nn.Parameter(torch.zeros(num_heads, self.head_qk_dim,\n            device=device, dtype=dtype))\n        self.g_norm = nn.LayerNorm(self.value_dim, elementwise_affine=\n            elementwise_affine, eps=norm_eps, device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        self.gate_fn = ACT2FN[gate_fn]\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        if isinstance(module, nn.Parameter):\n            nn.init.xavier_uniform_(module, gain=2 ** -2.5)\n        module._is_hf_initialized = True\n\n    def naive_chunk_rwkv6(self, q: torch.Tensor, k: torch.Tensor, v: torch.\n        Tensor, w: torch.Tensor, u: torch.Tensor, chunk_size: int=32):\n        assert q.shape[-2] % chunk_size == 0\n        orig_dtype = q.dtype\n        num_chunk = q.shape[-2] // chunk_size\n        u = u.unsqueeze(0)\n        q, k, v, w = map(lambda x: rearrange(x, 'b h (n c) d -> b h n c d',\n            c=chunk_size).float(), (q, k, v, w))\n        w_cumsum = w.cumsum(-2)\n        kw = k * (w_cumsum[..., -1, None, :] - w_cumsum).exp()\n        wkv = kw.transpose(-1, -2) @ v\n        wkv_new = torch.zeros_like(wkv)\n        for i in range(num_chunk - 1):\n            wkv_new[:, :, i + 1] = wkv_new[:, :, i].clone() * w_cumsum[:, :,\n                i, -1, :, None].exp() + wkv[:, :, i]\n        o_inter = torch.einsum('b h n d p, b h n c d -> b h n c p', wkv_new,\n            q * (w_cumsum - w).exp())\n        o_intra = torch.zeros_like(o_inter)\n        for i in range(chunk_size):\n            attn = (q[:, :, :, i, None] * k * (w_cumsum[:, :, :, i, None] -\n                w[:, :, :, i, None] - w_cumsum).exp()).sum(-1)\n            mask = (torch.arange(0, chunk_size) < i).to(attn.device)\n            attn.masked_fill_(~mask, 0)\n            intra_inter_o = (attn.unsqueeze(-1) * v).sum(-2)\n            intra_intra_o = (q[:, :, :, i] * u.unsqueeze(2) * k[:, :, :, i]\n                ).sum(-1).unsqueeze(-1) * v[:, :, :, i]\n            o_intra[:, :, :, i] = intra_inter_o + intra_intra_o\n        o = o_inter + o_intra\n        return rearrange(o, 'b h n c d -> b h (n c) d').to(orig_dtype)\n\n    def pad_input(self, X):\n        _seq_len = X.shape[-2]\n        pad_len = (X.shape[-2] + self.chunk_size - 1\n            ) // self.chunk_size * self.chunk_size - X.shape[-2]\n        return F.pad(X, (0, 0, 0, pad_len)), _seq_len\n\n    def _forward(self, X: torch.Tensor):\n        X, _seq_len = self.pad_input(X)\n        batch_size, seq_len, hidden_size = X.shape\n        last_state = None\n        if X.shape[1] == 1 and last_state is not None:\n            shifted = last_state[0].unsqueeze(1)\n        else:\n            shifted = self.time_shift(X)\n            if last_state is not None:\n                shifted[:, 0] = last_state[0]\n        delta = shifted - X\n        x = self.x_proj[0](X, **{'delta': delta})[1]['o'].view(batch_size,\n            seq_len, -1, self.proj_low_rank_dim)\n        x = torch.einsum('b l n r, h n r-> b l n h', self.x_proj[1](x),\n            self.x_proj[2].weight.view(hidden_size, 5, -1))\n        r, w, k, v, g = x.add_(self.x_bias).unbind(-2)\n        r = self.r_proj(X, **{'mu': r, 'delta': delta})[1]['o']\n        w = self.w_proj(X, **{'mu': w, 'delta': delta})[1]['o']\n        k = self.k_proj(X, **{'mu': k, 'delta': delta})[1]['o']\n        v = self.v_proj(X, **{'mu': v, 'delta': delta})[1]['o']\n        g = self.g_proj(X, **{'mu': g, 'delta': delta})[1]['o']\n        r, w, k, v = map(lambda x: rearrange(x, 'b l (h d) -> b h l d', h=\n            self.num_heads), (r, w, k, v))\n        w = -torch.exp(w)\n        u = self.bonus\n        o = self.naive_chunk_rwkv6(r, k, v, w, u, chunk_size=self.chunk_size)\n        o = rearrange(o, 'b h l d -> b l (h d)')\n        o = self.g_norm(o)\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        o = o[:, :_seq_len]\n        return o\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass DDLerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def forward(self, x: torch.Tensor, mu: torch.Tensor, delta: Optional[\n        torch.Tensor]=None) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(x)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - x\n        if self.low_rank_dim is None:\n            o = self.linear(x + delta * mu)\n        else:\n            o = self.linear(x + delta * mu)[1]['o']\n        return x, {'o': o}\n\n\ngab_config = {'num_heads': 4, 'gate_fn': 'swish', 'proj_low_rank_dim': 32,\n    'gate_low_rank_dim': 64, 'elementwise_affine': True, 'chunk_size': 32,\n    'norm_eps': 1e-05, 'state_expansion_ratio': 4, 'min_gating_bound': 0.1}\n\n\n\nautoconfig = {\n    'd_model': 1536,\n    'n_block': 49\n}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "70M": {
        "70M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RWKV6(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RWKV6(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        norm_eps: float=1e-05, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.attn = RWKV6Attention(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.ffn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.ffn = RWKV6FeedForwardSEF(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, _ = self.attn(self.attn_norm(X), **Z)\n        X = X1 + X\n        X2, _ = self.ffn(self.ffn_norm(X), **Z)\n        X = X2 + X\n        return X\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass RWKV6FeedForwardSEF(GAUBase):\n    \"\"\"\n    Enhanced RWKV6 Feed Forward block with State Expansion Features (SEF).\n    \n    This implementation enhances the original RWKV6FeedForward by incorporating:\n    1. Parameter-efficient state expansion using Group Linear Transformation (GLT)\n    2. Hierarchical gating with learnable bounds\n    3. Expanded state management\n    \n    Args:\n        embed_dim (int): Input embedding dimension\n        block_loc (tuple): Location of block in network (layer_idx, n_block)\n        kwarg_all (dict): Additional arguments\n        state_expansion_ratio (int): Ratio for state expansion (default: 4)\n        min_gating_bound (float): Minimum value for gating bounds (default: 0.1)\n        device (Optional[torch.device]): Device to place tensors\n        dtype (Optional[torch.dtype]): Data type of tensors\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        state_expansion_ratio: int=4, min_gating_bound: float=0.1, device=\n        None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.state_expansion_ratio = state_expansion_ratio\n        self.min_gating_bound = min_gating_bound\n        self.num_groups = state_expansion_ratio\n        self.group_size = embed_dim // state_expansion_ratio\n        assert embed_dim % state_expansion_ratio == 0, f'embed_dim must be divisible by state_expansion_ratio, got {embed_dim} and {state_expansion_ratio}'\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = self.group_size\n        self.key_groups = nn.ModuleList([LerpLinear(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all) for _ in range(self.\n            num_groups)])\n        self.beta = nn.Parameter(torch.zeros(self.num_groups, device=device,\n            dtype=dtype))\n        self.value = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        kwarg_all['output_dim'] = embed_dim\n        self.receptance = LerpLinear(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n        self.relu = nn.ReLU()\n        self.gelu = nn.GELU()\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        \"\"\"Initialize parameters with appropriate bounds\"\"\"\n        with torch.no_grad():\n            self.beta.data.fill_(self.min_gating_bound)\n\n    def _compute_hierarchical_gates(self, gates: torch.Tensor) ->torch.Tensor:\n        \"\"\"Compute hierarchical gates with learned lower bounds\"\"\"\n        beta_cumsum = torch.cumsum(F.softplus(self.beta), dim=0)\n        beta_norm = beta_cumsum / beta_cumsum[-1].clamp(min=1e-05)\n        batch_size, seq_len, _ = gates.shape\n        gates = gates.view(batch_size, seq_len, self.num_groups, -1)\n        gates = gates * beta_norm.view(1, 1, self.num_groups, 1)\n        return gates.view(batch_size, seq_len, -1)\n\n    def _forward(self, X: torch.Tensor, **Z) ->torch.Tensor:\n        \"\"\"\n        Forward pass with state expansion and hierarchical gating.\n        \n        Args:\n            X: Input tensor of shape (batch_size, seq_len, embed_dim)\n            \n        Returns:\n            Output tensor of shape (batch_size, seq_len, embed_dim)\n        \"\"\"\n        shifted = self.time_shift(X)\n        delta = shifted - X\n        key_expanded = []\n        for group in range(self.num_groups):\n            key_group = self.key_groups[group](X, delta=delta)[1]['o']\n            key_expanded.append(key_group)\n        key_combined = torch.cat(key_expanded, dim=-1)\n        r = self.relu(key_combined)\n        key = r * r\n        key = self.gelu(key)\n        value = self.value(key)\n        receptance = self.receptance(X, delta=delta)[1]['o']\n        receptance = self._compute_hierarchical_gates(receptance)\n        return receptance.sigmoid() * value\n\n    def extra_repr(self) ->str:\n        \"\"\"Return extra representation string\"\"\"\n        return (\n            f'embed_dim={self.hidden_size}, expansion_ratio={self.state_expansion_ratio}'\n            )\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if self.low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n        self.mu = nn.Parameter(torch.zeros(embed_dim, device=device, dtype=\n            dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _forward(self, X: torch.Tensor, delta: Optional[torch.Tensor]=None\n        ) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(X)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - X\n        if self.low_rank_dim is None:\n            o = self.linear(X + delta * self.mu)\n        else:\n            o = self.linear(X + delta * self.mu)[1]['o']\n        return X, {'o': o}\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LoRA(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: int, bias: Optional[bool]=True,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.bias = bias\n        self.lora = nn.Sequential(nn.Linear(embed_dim, low_rank_dim, bias=\n            False, device=device, dtype=dtype), nn.Tanh(), nn.Linear(\n            low_rank_dim, output_dim, bias=bias, device=device, dtype=dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}('\n        s += (\n            f'input_dim={self.input_dim}, low_rank_dim={self.low_rank_dim}, output_dim={self.output_dim}'\n            )\n        if not self.bias:\n            s += f', bias={self.bias}'\n        s += ')'\n        return s\n\n    def _forward(self, X, **Z):\n        return X, {'o': self.lora(X)}\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom transformers.activations import ACT2FN\nfrom typing import Optional\n\n\nclass RWKV6Attention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        num_heads: int=4, gate_fn: str='swish', proj_low_rank_dim: int=32,\n        gate_low_rank_dim: int=64, elementwise_affine: Optional[bool]=True,\n        norm_eps: float=1e-05, chunk_size: int=32, device=None, dtype=None,\n        **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.num_heads = num_heads\n        self.proj_low_rank_dim = proj_low_rank_dim\n        self.gate_low_rank_dim = gate_low_rank_dim\n        self.chunk_size = chunk_size\n        self.key_dim = embed_dim // 2\n        self.value_dim = embed_dim\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = proj_low_rank_dim * 5\n        self.x_proj = nn.Sequential(LerpLinear(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all), nn.Tanh(), nn.Linear(\n            proj_low_rank_dim * 5, embed_dim, bias=False, device=device,\n            dtype=dtype))\n        self.x_bias = nn.Parameter(torch.zeros(5, embed_dim, device=device,\n            dtype=dtype))\n        kwarg_all['output_dim'] = self.key_dim\n        self.r_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.w_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all.pop('low_rank_dim')\n        self.k_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['output_dim'] = self.value_dim\n        self.v_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.g_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.bonus = nn.Parameter(torch.zeros(num_heads, self.head_qk_dim,\n            device=device, dtype=dtype))\n        self.g_norm = nn.LayerNorm(self.value_dim, elementwise_affine=\n            elementwise_affine, eps=norm_eps, device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        self.gate_fn = ACT2FN[gate_fn]\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        if isinstance(module, nn.Parameter):\n            nn.init.xavier_uniform_(module, gain=2 ** -2.5)\n        module._is_hf_initialized = True\n\n    def naive_chunk_rwkv6(self, q: torch.Tensor, k: torch.Tensor, v: torch.\n        Tensor, w: torch.Tensor, u: torch.Tensor, chunk_size: int=32):\n        assert q.shape[-2] % chunk_size == 0\n        orig_dtype = q.dtype\n        num_chunk = q.shape[-2] // chunk_size\n        u = u.unsqueeze(0)\n        q, k, v, w = map(lambda x: rearrange(x, 'b h (n c) d -> b h n c d',\n            c=chunk_size).float(), (q, k, v, w))\n        w_cumsum = w.cumsum(-2)\n        kw = k * (w_cumsum[..., -1, None, :] - w_cumsum).exp()\n        wkv = kw.transpose(-1, -2) @ v\n        wkv_new = torch.zeros_like(wkv)\n        for i in range(num_chunk - 1):\n            wkv_new[:, :, i + 1] = wkv_new[:, :, i].clone() * w_cumsum[:, :,\n                i, -1, :, None].exp() + wkv[:, :, i]\n        o_inter = torch.einsum('b h n d p, b h n c d -> b h n c p', wkv_new,\n            q * (w_cumsum - w).exp())\n        o_intra = torch.zeros_like(o_inter)\n        for i in range(chunk_size):\n            attn = (q[:, :, :, i, None] * k * (w_cumsum[:, :, :, i, None] -\n                w[:, :, :, i, None] - w_cumsum).exp()).sum(-1)\n            mask = (torch.arange(0, chunk_size) < i).to(attn.device)\n            attn.masked_fill_(~mask, 0)\n            intra_inter_o = (attn.unsqueeze(-1) * v).sum(-2)\n            intra_intra_o = (q[:, :, :, i] * u.unsqueeze(2) * k[:, :, :, i]\n                ).sum(-1).unsqueeze(-1) * v[:, :, :, i]\n            o_intra[:, :, :, i] = intra_inter_o + intra_intra_o\n        o = o_inter + o_intra\n        return rearrange(o, 'b h n c d -> b h (n c) d').to(orig_dtype)\n\n    def pad_input(self, X):\n        _seq_len = X.shape[-2]\n        pad_len = (X.shape[-2] + self.chunk_size - 1\n            ) // self.chunk_size * self.chunk_size - X.shape[-2]\n        return F.pad(X, (0, 0, 0, pad_len)), _seq_len\n\n    def _forward(self, X: torch.Tensor):\n        X, _seq_len = self.pad_input(X)\n        batch_size, seq_len, hidden_size = X.shape\n        last_state = None\n        if X.shape[1] == 1 and last_state is not None:\n            shifted = last_state[0].unsqueeze(1)\n        else:\n            shifted = self.time_shift(X)\n            if last_state is not None:\n                shifted[:, 0] = last_state[0]\n        delta = shifted - X\n        x = self.x_proj[0](X, **{'delta': delta})[1]['o'].view(batch_size,\n            seq_len, -1, self.proj_low_rank_dim)\n        x = torch.einsum('b l n r, h n r-> b l n h', self.x_proj[1](x),\n            self.x_proj[2].weight.view(hidden_size, 5, -1))\n        r, w, k, v, g = x.add_(self.x_bias).unbind(-2)\n        r = self.r_proj(X, **{'mu': r, 'delta': delta})[1]['o']\n        w = self.w_proj(X, **{'mu': w, 'delta': delta})[1]['o']\n        k = self.k_proj(X, **{'mu': k, 'delta': delta})[1]['o']\n        v = self.v_proj(X, **{'mu': v, 'delta': delta})[1]['o']\n        g = self.g_proj(X, **{'mu': g, 'delta': delta})[1]['o']\n        r, w, k, v = map(lambda x: rearrange(x, 'b l (h d) -> b h l d', h=\n            self.num_heads), (r, w, k, v))\n        w = -torch.exp(w)\n        u = self.bonus\n        o = self.naive_chunk_rwkv6(r, k, v, w, u, chunk_size=self.chunk_size)\n        o = rearrange(o, 'b h l d -> b l (h d)')\n        o = self.g_norm(o)\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        o = o[:, :_seq_len]\n        return o\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass DDLerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def forward(self, x: torch.Tensor, mu: torch.Tensor, delta: Optional[\n        torch.Tensor]=None) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(x)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - x\n        if self.low_rank_dim is None:\n            o = self.linear(x + delta * mu)\n        else:\n            o = self.linear(x + delta * mu)[1]['o']\n        return x, {'o': o}\n\n\ngab_config = {'num_heads': 4, 'gate_fn': 'swish', 'proj_low_rank_dim': 32,\n    'gate_low_rank_dim': 64, 'elementwise_affine': True, 'chunk_size': 32,\n    'norm_eps': 1e-05, 'state_expansion_ratio': 4, 'min_gating_bound': 0.1}\n\n\n\nautoconfig = {\n    'd_model': 512,\n    'n_block': 8\n}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "1300M": {
        "1300M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RWKV6(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RWKV6(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        norm_eps: float=1e-05, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.attn = RWKV6Attention(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.ffn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.ffn = RWKV6FeedForwardSEF(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, _ = self.attn(self.attn_norm(X), **Z)\n        X = X1 + X\n        X2, _ = self.ffn(self.ffn_norm(X), **Z)\n        X = X2 + X\n        return X\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass RWKV6FeedForwardSEF(GAUBase):\n    \"\"\"\n    Enhanced RWKV6 Feed Forward block with State Expansion Features (SEF).\n    \n    This implementation enhances the original RWKV6FeedForward by incorporating:\n    1. Parameter-efficient state expansion using Group Linear Transformation (GLT)\n    2. Hierarchical gating with learnable bounds\n    3. Expanded state management\n    \n    Args:\n        embed_dim (int): Input embedding dimension\n        block_loc (tuple): Location of block in network (layer_idx, n_block)\n        kwarg_all (dict): Additional arguments\n        state_expansion_ratio (int): Ratio for state expansion (default: 4)\n        min_gating_bound (float): Minimum value for gating bounds (default: 0.1)\n        device (Optional[torch.device]): Device to place tensors\n        dtype (Optional[torch.dtype]): Data type of tensors\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        state_expansion_ratio: int=4, min_gating_bound: float=0.1, device=\n        None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.state_expansion_ratio = state_expansion_ratio\n        self.min_gating_bound = min_gating_bound\n        self.num_groups = state_expansion_ratio\n        self.group_size = embed_dim // state_expansion_ratio\n        assert embed_dim % state_expansion_ratio == 0, f'embed_dim must be divisible by state_expansion_ratio, got {embed_dim} and {state_expansion_ratio}'\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = self.group_size\n        self.key_groups = nn.ModuleList([LerpLinear(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all) for _ in range(self.\n            num_groups)])\n        self.beta = nn.Parameter(torch.zeros(self.num_groups, device=device,\n            dtype=dtype))\n        self.value = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        kwarg_all['output_dim'] = embed_dim\n        self.receptance = LerpLinear(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n        self.relu = nn.ReLU()\n        self.gelu = nn.GELU()\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        \"\"\"Initialize parameters with appropriate bounds\"\"\"\n        with torch.no_grad():\n            self.beta.data.fill_(self.min_gating_bound)\n\n    def _compute_hierarchical_gates(self, gates: torch.Tensor) ->torch.Tensor:\n        \"\"\"Compute hierarchical gates with learned lower bounds\"\"\"\n        beta_cumsum = torch.cumsum(F.softplus(self.beta), dim=0)\n        beta_norm = beta_cumsum / beta_cumsum[-1].clamp(min=1e-05)\n        batch_size, seq_len, _ = gates.shape\n        gates = gates.view(batch_size, seq_len, self.num_groups, -1)\n        gates = gates * beta_norm.view(1, 1, self.num_groups, 1)\n        return gates.view(batch_size, seq_len, -1)\n\n    def _forward(self, X: torch.Tensor, **Z) ->torch.Tensor:\n        \"\"\"\n        Forward pass with state expansion and hierarchical gating.\n        \n        Args:\n            X: Input tensor of shape (batch_size, seq_len, embed_dim)\n            \n        Returns:\n            Output tensor of shape (batch_size, seq_len, embed_dim)\n        \"\"\"\n        shifted = self.time_shift(X)\n        delta = shifted - X\n        key_expanded = []\n        for group in range(self.num_groups):\n            key_group = self.key_groups[group](X, delta=delta)[1]['o']\n            key_expanded.append(key_group)\n        key_combined = torch.cat(key_expanded, dim=-1)\n        r = self.relu(key_combined)\n        key = r * r\n        key = self.gelu(key)\n        value = self.value(key)\n        receptance = self.receptance(X, delta=delta)[1]['o']\n        receptance = self._compute_hierarchical_gates(receptance)\n        return receptance.sigmoid() * value\n\n    def extra_repr(self) ->str:\n        \"\"\"Return extra representation string\"\"\"\n        return (\n            f'embed_dim={self.hidden_size}, expansion_ratio={self.state_expansion_ratio}'\n            )\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if self.low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n        self.mu = nn.Parameter(torch.zeros(embed_dim, device=device, dtype=\n            dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _forward(self, X: torch.Tensor, delta: Optional[torch.Tensor]=None\n        ) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(X)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - X\n        if self.low_rank_dim is None:\n            o = self.linear(X + delta * self.mu)\n        else:\n            o = self.linear(X + delta * self.mu)[1]['o']\n        return X, {'o': o}\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LoRA(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: int, bias: Optional[bool]=True,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.bias = bias\n        self.lora = nn.Sequential(nn.Linear(embed_dim, low_rank_dim, bias=\n            False, device=device, dtype=dtype), nn.Tanh(), nn.Linear(\n            low_rank_dim, output_dim, bias=bias, device=device, dtype=dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}('\n        s += (\n            f'input_dim={self.input_dim}, low_rank_dim={self.low_rank_dim}, output_dim={self.output_dim}'\n            )\n        if not self.bias:\n            s += f', bias={self.bias}'\n        s += ')'\n        return s\n\n    def _forward(self, X, **Z):\n        return X, {'o': self.lora(X)}\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom transformers.activations import ACT2FN\nfrom typing import Optional\n\n\nclass RWKV6Attention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        num_heads: int=4, gate_fn: str='swish', proj_low_rank_dim: int=32,\n        gate_low_rank_dim: int=64, elementwise_affine: Optional[bool]=True,\n        norm_eps: float=1e-05, chunk_size: int=32, device=None, dtype=None,\n        **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.num_heads = num_heads\n        self.proj_low_rank_dim = proj_low_rank_dim\n        self.gate_low_rank_dim = gate_low_rank_dim\n        self.chunk_size = chunk_size\n        self.key_dim = embed_dim // 2\n        self.value_dim = embed_dim\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = proj_low_rank_dim * 5\n        self.x_proj = nn.Sequential(LerpLinear(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all), nn.Tanh(), nn.Linear(\n            proj_low_rank_dim * 5, embed_dim, bias=False, device=device,\n            dtype=dtype))\n        self.x_bias = nn.Parameter(torch.zeros(5, embed_dim, device=device,\n            dtype=dtype))\n        kwarg_all['output_dim'] = self.key_dim\n        self.r_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.w_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all.pop('low_rank_dim')\n        self.k_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['output_dim'] = self.value_dim\n        self.v_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.g_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.bonus = nn.Parameter(torch.zeros(num_heads, self.head_qk_dim,\n            device=device, dtype=dtype))\n        self.g_norm = nn.LayerNorm(self.value_dim, elementwise_affine=\n            elementwise_affine, eps=norm_eps, device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        self.gate_fn = ACT2FN[gate_fn]\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        if isinstance(module, nn.Parameter):\n            nn.init.xavier_uniform_(module, gain=2 ** -2.5)\n        module._is_hf_initialized = True\n\n    def naive_chunk_rwkv6(self, q: torch.Tensor, k: torch.Tensor, v: torch.\n        Tensor, w: torch.Tensor, u: torch.Tensor, chunk_size: int=32):\n        assert q.shape[-2] % chunk_size == 0\n        orig_dtype = q.dtype\n        num_chunk = q.shape[-2] // chunk_size\n        u = u.unsqueeze(0)\n        q, k, v, w = map(lambda x: rearrange(x, 'b h (n c) d -> b h n c d',\n            c=chunk_size).float(), (q, k, v, w))\n        w_cumsum = w.cumsum(-2)\n        kw = k * (w_cumsum[..., -1, None, :] - w_cumsum).exp()\n        wkv = kw.transpose(-1, -2) @ v\n        wkv_new = torch.zeros_like(wkv)\n        for i in range(num_chunk - 1):\n            wkv_new[:, :, i + 1] = wkv_new[:, :, i].clone() * w_cumsum[:, :,\n                i, -1, :, None].exp() + wkv[:, :, i]\n        o_inter = torch.einsum('b h n d p, b h n c d -> b h n c p', wkv_new,\n            q * (w_cumsum - w).exp())\n        o_intra = torch.zeros_like(o_inter)\n        for i in range(chunk_size):\n            attn = (q[:, :, :, i, None] * k * (w_cumsum[:, :, :, i, None] -\n                w[:, :, :, i, None] - w_cumsum).exp()).sum(-1)\n            mask = (torch.arange(0, chunk_size) < i).to(attn.device)\n            attn.masked_fill_(~mask, 0)\n            intra_inter_o = (attn.unsqueeze(-1) * v).sum(-2)\n            intra_intra_o = (q[:, :, :, i] * u.unsqueeze(2) * k[:, :, :, i]\n                ).sum(-1).unsqueeze(-1) * v[:, :, :, i]\n            o_intra[:, :, :, i] = intra_inter_o + intra_intra_o\n        o = o_inter + o_intra\n        return rearrange(o, 'b h n c d -> b h (n c) d').to(orig_dtype)\n\n    def pad_input(self, X):\n        _seq_len = X.shape[-2]\n        pad_len = (X.shape[-2] + self.chunk_size - 1\n            ) // self.chunk_size * self.chunk_size - X.shape[-2]\n        return F.pad(X, (0, 0, 0, pad_len)), _seq_len\n\n    def _forward(self, X: torch.Tensor):\n        X, _seq_len = self.pad_input(X)\n        batch_size, seq_len, hidden_size = X.shape\n        last_state = None\n        if X.shape[1] == 1 and last_state is not None:\n            shifted = last_state[0].unsqueeze(1)\n        else:\n            shifted = self.time_shift(X)\n            if last_state is not None:\n                shifted[:, 0] = last_state[0]\n        delta = shifted - X\n        x = self.x_proj[0](X, **{'delta': delta})[1]['o'].view(batch_size,\n            seq_len, -1, self.proj_low_rank_dim)\n        x = torch.einsum('b l n r, h n r-> b l n h', self.x_proj[1](x),\n            self.x_proj[2].weight.view(hidden_size, 5, -1))\n        r, w, k, v, g = x.add_(self.x_bias).unbind(-2)\n        r = self.r_proj(X, **{'mu': r, 'delta': delta})[1]['o']\n        w = self.w_proj(X, **{'mu': w, 'delta': delta})[1]['o']\n        k = self.k_proj(X, **{'mu': k, 'delta': delta})[1]['o']\n        v = self.v_proj(X, **{'mu': v, 'delta': delta})[1]['o']\n        g = self.g_proj(X, **{'mu': g, 'delta': delta})[1]['o']\n        r, w, k, v = map(lambda x: rearrange(x, 'b l (h d) -> b h l d', h=\n            self.num_heads), (r, w, k, v))\n        w = -torch.exp(w)\n        u = self.bonus\n        o = self.naive_chunk_rwkv6(r, k, v, w, u, chunk_size=self.chunk_size)\n        o = rearrange(o, 'b h l d -> b l (h d)')\n        o = self.g_norm(o)\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        o = o[:, :_seq_len]\n        return o\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass DDLerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def forward(self, x: torch.Tensor, mu: torch.Tensor, delta: Optional[\n        torch.Tensor]=None) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(x)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - x\n        if self.low_rank_dim is None:\n            o = self.linear(x + delta * mu)\n        else:\n            o = self.linear(x + delta * mu)[1]['o']\n        return x, {'o': o}\n\n\ngab_config = {'num_heads': 4, 'gate_fn': 'swish', 'proj_low_rank_dim': 32,\n    'gate_low_rank_dim': 64, 'elementwise_affine': True, 'chunk_size': 32,\n    'norm_eps': 1e-05, 'state_expansion_ratio': 4, 'min_gating_bound': 0.1}\n\n\n\nautoconfig = {\n    'd_model': 2048,\n    'n_block': 51\n}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "125M": {
        "125M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RWKV6(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RWKV6(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        norm_eps: float=1e-05, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.attn = RWKV6Attention(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.ffn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.ffn = RWKV6FeedForwardSEF(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, _ = self.attn(self.attn_norm(X), **Z)\n        X = X1 + X\n        X2, _ = self.ffn(self.ffn_norm(X), **Z)\n        X = X2 + X\n        return X\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass RWKV6FeedForwardSEF(GAUBase):\n    \"\"\"\n    Enhanced RWKV6 Feed Forward block with State Expansion Features (SEF).\n    \n    This implementation enhances the original RWKV6FeedForward by incorporating:\n    1. Parameter-efficient state expansion using Group Linear Transformation (GLT)\n    2. Hierarchical gating with learnable bounds\n    3. Expanded state management\n    \n    Args:\n        embed_dim (int): Input embedding dimension\n        block_loc (tuple): Location of block in network (layer_idx, n_block)\n        kwarg_all (dict): Additional arguments\n        state_expansion_ratio (int): Ratio for state expansion (default: 4)\n        min_gating_bound (float): Minimum value for gating bounds (default: 0.1)\n        device (Optional[torch.device]): Device to place tensors\n        dtype (Optional[torch.dtype]): Data type of tensors\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        state_expansion_ratio: int=4, min_gating_bound: float=0.1, device=\n        None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.state_expansion_ratio = state_expansion_ratio\n        self.min_gating_bound = min_gating_bound\n        self.num_groups = state_expansion_ratio\n        self.group_size = embed_dim // state_expansion_ratio\n        assert embed_dim % state_expansion_ratio == 0, f'embed_dim must be divisible by state_expansion_ratio, got {embed_dim} and {state_expansion_ratio}'\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = self.group_size\n        self.key_groups = nn.ModuleList([LerpLinear(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all) for _ in range(self.\n            num_groups)])\n        self.beta = nn.Parameter(torch.zeros(self.num_groups, device=device,\n            dtype=dtype))\n        self.value = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        kwarg_all['output_dim'] = embed_dim\n        self.receptance = LerpLinear(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n        self.relu = nn.ReLU()\n        self.gelu = nn.GELU()\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        \"\"\"Initialize parameters with appropriate bounds\"\"\"\n        with torch.no_grad():\n            self.beta.data.fill_(self.min_gating_bound)\n\n    def _compute_hierarchical_gates(self, gates: torch.Tensor) ->torch.Tensor:\n        \"\"\"Compute hierarchical gates with learned lower bounds\"\"\"\n        beta_cumsum = torch.cumsum(F.softplus(self.beta), dim=0)\n        beta_norm = beta_cumsum / beta_cumsum[-1].clamp(min=1e-05)\n        batch_size, seq_len, _ = gates.shape\n        gates = gates.view(batch_size, seq_len, self.num_groups, -1)\n        gates = gates * beta_norm.view(1, 1, self.num_groups, 1)\n        return gates.view(batch_size, seq_len, -1)\n\n    def _forward(self, X: torch.Tensor, **Z) ->torch.Tensor:\n        \"\"\"\n        Forward pass with state expansion and hierarchical gating.\n        \n        Args:\n            X: Input tensor of shape (batch_size, seq_len, embed_dim)\n            \n        Returns:\n            Output tensor of shape (batch_size, seq_len, embed_dim)\n        \"\"\"\n        shifted = self.time_shift(X)\n        delta = shifted - X\n        key_expanded = []\n        for group in range(self.num_groups):\n            key_group = self.key_groups[group](X, delta=delta)[1]['o']\n            key_expanded.append(key_group)\n        key_combined = torch.cat(key_expanded, dim=-1)\n        r = self.relu(key_combined)\n        key = r * r\n        key = self.gelu(key)\n        value = self.value(key)\n        receptance = self.receptance(X, delta=delta)[1]['o']\n        receptance = self._compute_hierarchical_gates(receptance)\n        return receptance.sigmoid() * value\n\n    def extra_repr(self) ->str:\n        \"\"\"Return extra representation string\"\"\"\n        return (\n            f'embed_dim={self.hidden_size}, expansion_ratio={self.state_expansion_ratio}'\n            )\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if self.low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n        self.mu = nn.Parameter(torch.zeros(embed_dim, device=device, dtype=\n            dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _forward(self, X: torch.Tensor, delta: Optional[torch.Tensor]=None\n        ) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(X)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - X\n        if self.low_rank_dim is None:\n            o = self.linear(X + delta * self.mu)\n        else:\n            o = self.linear(X + delta * self.mu)[1]['o']\n        return X, {'o': o}\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LoRA(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: int, bias: Optional[bool]=True,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.bias = bias\n        self.lora = nn.Sequential(nn.Linear(embed_dim, low_rank_dim, bias=\n            False, device=device, dtype=dtype), nn.Tanh(), nn.Linear(\n            low_rank_dim, output_dim, bias=bias, device=device, dtype=dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}('\n        s += (\n            f'input_dim={self.input_dim}, low_rank_dim={self.low_rank_dim}, output_dim={self.output_dim}'\n            )\n        if not self.bias:\n            s += f', bias={self.bias}'\n        s += ')'\n        return s\n\n    def _forward(self, X, **Z):\n        return X, {'o': self.lora(X)}\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom transformers.activations import ACT2FN\nfrom typing import Optional\n\n\nclass RWKV6Attention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        num_heads: int=4, gate_fn: str='swish', proj_low_rank_dim: int=32,\n        gate_low_rank_dim: int=64, elementwise_affine: Optional[bool]=True,\n        norm_eps: float=1e-05, chunk_size: int=32, device=None, dtype=None,\n        **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.num_heads = num_heads\n        self.proj_low_rank_dim = proj_low_rank_dim\n        self.gate_low_rank_dim = gate_low_rank_dim\n        self.chunk_size = chunk_size\n        self.key_dim = embed_dim // 2\n        self.value_dim = embed_dim\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = proj_low_rank_dim * 5\n        self.x_proj = nn.Sequential(LerpLinear(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all), nn.Tanh(), nn.Linear(\n            proj_low_rank_dim * 5, embed_dim, bias=False, device=device,\n            dtype=dtype))\n        self.x_bias = nn.Parameter(torch.zeros(5, embed_dim, device=device,\n            dtype=dtype))\n        kwarg_all['output_dim'] = self.key_dim\n        self.r_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.w_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all.pop('low_rank_dim')\n        self.k_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['output_dim'] = self.value_dim\n        self.v_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.g_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.bonus = nn.Parameter(torch.zeros(num_heads, self.head_qk_dim,\n            device=device, dtype=dtype))\n        self.g_norm = nn.LayerNorm(self.value_dim, elementwise_affine=\n            elementwise_affine, eps=norm_eps, device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        self.gate_fn = ACT2FN[gate_fn]\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        if isinstance(module, nn.Parameter):\n            nn.init.xavier_uniform_(module, gain=2 ** -2.5)\n        module._is_hf_initialized = True\n\n    def naive_chunk_rwkv6(self, q: torch.Tensor, k: torch.Tensor, v: torch.\n        Tensor, w: torch.Tensor, u: torch.Tensor, chunk_size: int=32):\n        assert q.shape[-2] % chunk_size == 0\n        orig_dtype = q.dtype\n        num_chunk = q.shape[-2] // chunk_size\n        u = u.unsqueeze(0)\n        q, k, v, w = map(lambda x: rearrange(x, 'b h (n c) d -> b h n c d',\n            c=chunk_size).float(), (q, k, v, w))\n        w_cumsum = w.cumsum(-2)\n        kw = k * (w_cumsum[..., -1, None, :] - w_cumsum).exp()\n        wkv = kw.transpose(-1, -2) @ v\n        wkv_new = torch.zeros_like(wkv)\n        for i in range(num_chunk - 1):\n            wkv_new[:, :, i + 1] = wkv_new[:, :, i].clone() * w_cumsum[:, :,\n                i, -1, :, None].exp() + wkv[:, :, i]\n        o_inter = torch.einsum('b h n d p, b h n c d -> b h n c p', wkv_new,\n            q * (w_cumsum - w).exp())\n        o_intra = torch.zeros_like(o_inter)\n        for i in range(chunk_size):\n            attn = (q[:, :, :, i, None] * k * (w_cumsum[:, :, :, i, None] -\n                w[:, :, :, i, None] - w_cumsum).exp()).sum(-1)\n            mask = (torch.arange(0, chunk_size) < i).to(attn.device)\n            attn.masked_fill_(~mask, 0)\n            intra_inter_o = (attn.unsqueeze(-1) * v).sum(-2)\n            intra_intra_o = (q[:, :, :, i] * u.unsqueeze(2) * k[:, :, :, i]\n                ).sum(-1).unsqueeze(-1) * v[:, :, :, i]\n            o_intra[:, :, :, i] = intra_inter_o + intra_intra_o\n        o = o_inter + o_intra\n        return rearrange(o, 'b h n c d -> b h (n c) d').to(orig_dtype)\n\n    def pad_input(self, X):\n        _seq_len = X.shape[-2]\n        pad_len = (X.shape[-2] + self.chunk_size - 1\n            ) // self.chunk_size * self.chunk_size - X.shape[-2]\n        return F.pad(X, (0, 0, 0, pad_len)), _seq_len\n\n    def _forward(self, X: torch.Tensor):\n        X, _seq_len = self.pad_input(X)\n        batch_size, seq_len, hidden_size = X.shape\n        last_state = None\n        if X.shape[1] == 1 and last_state is not None:\n            shifted = last_state[0].unsqueeze(1)\n        else:\n            shifted = self.time_shift(X)\n            if last_state is not None:\n                shifted[:, 0] = last_state[0]\n        delta = shifted - X\n        x = self.x_proj[0](X, **{'delta': delta})[1]['o'].view(batch_size,\n            seq_len, -1, self.proj_low_rank_dim)\n        x = torch.einsum('b l n r, h n r-> b l n h', self.x_proj[1](x),\n            self.x_proj[2].weight.view(hidden_size, 5, -1))\n        r, w, k, v, g = x.add_(self.x_bias).unbind(-2)\n        r = self.r_proj(X, **{'mu': r, 'delta': delta})[1]['o']\n        w = self.w_proj(X, **{'mu': w, 'delta': delta})[1]['o']\n        k = self.k_proj(X, **{'mu': k, 'delta': delta})[1]['o']\n        v = self.v_proj(X, **{'mu': v, 'delta': delta})[1]['o']\n        g = self.g_proj(X, **{'mu': g, 'delta': delta})[1]['o']\n        r, w, k, v = map(lambda x: rearrange(x, 'b l (h d) -> b h l d', h=\n            self.num_heads), (r, w, k, v))\n        w = -torch.exp(w)\n        u = self.bonus\n        o = self.naive_chunk_rwkv6(r, k, v, w, u, chunk_size=self.chunk_size)\n        o = rearrange(o, 'b h l d -> b l (h d)')\n        o = self.g_norm(o)\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        o = o[:, :_seq_len]\n        return o\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass DDLerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def forward(self, x: torch.Tensor, mu: torch.Tensor, delta: Optional[\n        torch.Tensor]=None) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(x)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - x\n        if self.low_rank_dim is None:\n            o = self.linear(x + delta * mu)\n        else:\n            o = self.linear(x + delta * mu)[1]['o']\n        return x, {'o': o}\n\n\ngab_config = {'num_heads': 4, 'gate_fn': 'swish', 'proj_low_rank_dim': 32,\n    'gate_low_rank_dim': 64, 'elementwise_affine': True, 'chunk_size': 32,\n    'norm_eps': 1e-05, 'state_expansion_ratio': 4, 'min_gating_bound': 0.1}\n\n\n\nautoconfig = {\n    'd_model': 768,\n    'n_block': 21\n}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "14M": {
        "14M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RWKV6(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RWKV6(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        norm_eps: float=1e-05, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.attn = RWKV6Attention(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.ffn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.ffn = RWKV6FeedForwardSEF(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, _ = self.attn(self.attn_norm(X), **Z)\n        X = X1 + X\n        X2, _ = self.ffn(self.ffn_norm(X), **Z)\n        X = X2 + X\n        return X\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass RWKV6FeedForwardSEF(GAUBase):\n    \"\"\"\n    Enhanced RWKV6 Feed Forward block with State Expansion Features (SEF).\n    \n    This implementation enhances the original RWKV6FeedForward by incorporating:\n    1. Parameter-efficient state expansion using Group Linear Transformation (GLT)\n    2. Hierarchical gating with learnable bounds\n    3. Expanded state management\n    \n    Args:\n        embed_dim (int): Input embedding dimension\n        block_loc (tuple): Location of block in network (layer_idx, n_block)\n        kwarg_all (dict): Additional arguments\n        state_expansion_ratio (int): Ratio for state expansion (default: 4)\n        min_gating_bound (float): Minimum value for gating bounds (default: 0.1)\n        device (Optional[torch.device]): Device to place tensors\n        dtype (Optional[torch.dtype]): Data type of tensors\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        state_expansion_ratio: int=4, min_gating_bound: float=0.1, device=\n        None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.state_expansion_ratio = state_expansion_ratio\n        self.min_gating_bound = min_gating_bound\n        self.num_groups = state_expansion_ratio\n        self.group_size = embed_dim // state_expansion_ratio\n        assert embed_dim % state_expansion_ratio == 0, f'embed_dim must be divisible by state_expansion_ratio, got {embed_dim} and {state_expansion_ratio}'\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = self.group_size\n        self.key_groups = nn.ModuleList([LerpLinear(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all) for _ in range(self.\n            num_groups)])\n        self.beta = nn.Parameter(torch.zeros(self.num_groups, device=device,\n            dtype=dtype))\n        self.value = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        kwarg_all['output_dim'] = embed_dim\n        self.receptance = LerpLinear(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n        self.relu = nn.ReLU()\n        self.gelu = nn.GELU()\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        \"\"\"Initialize parameters with appropriate bounds\"\"\"\n        with torch.no_grad():\n            self.beta.data.fill_(self.min_gating_bound)\n\n    def _compute_hierarchical_gates(self, gates: torch.Tensor) ->torch.Tensor:\n        \"\"\"Compute hierarchical gates with learned lower bounds\"\"\"\n        beta_cumsum = torch.cumsum(F.softplus(self.beta), dim=0)\n        beta_norm = beta_cumsum / beta_cumsum[-1].clamp(min=1e-05)\n        batch_size, seq_len, _ = gates.shape\n        gates = gates.view(batch_size, seq_len, self.num_groups, -1)\n        gates = gates * beta_norm.view(1, 1, self.num_groups, 1)\n        return gates.view(batch_size, seq_len, -1)\n\n    def _forward(self, X: torch.Tensor, **Z) ->torch.Tensor:\n        \"\"\"\n        Forward pass with state expansion and hierarchical gating.\n        \n        Args:\n            X: Input tensor of shape (batch_size, seq_len, embed_dim)\n            \n        Returns:\n            Output tensor of shape (batch_size, seq_len, embed_dim)\n        \"\"\"\n        shifted = self.time_shift(X)\n        delta = shifted - X\n        key_expanded = []\n        for group in range(self.num_groups):\n            key_group = self.key_groups[group](X, delta=delta)[1]['o']\n            key_expanded.append(key_group)\n        key_combined = torch.cat(key_expanded, dim=-1)\n        r = self.relu(key_combined)\n        key = r * r\n        key = self.gelu(key)\n        value = self.value(key)\n        receptance = self.receptance(X, delta=delta)[1]['o']\n        receptance = self._compute_hierarchical_gates(receptance)\n        return receptance.sigmoid() * value\n\n    def extra_repr(self) ->str:\n        \"\"\"Return extra representation string\"\"\"\n        return (\n            f'embed_dim={self.hidden_size}, expansion_ratio={self.state_expansion_ratio}'\n            )\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if self.low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n        self.mu = nn.Parameter(torch.zeros(embed_dim, device=device, dtype=\n            dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _forward(self, X: torch.Tensor, delta: Optional[torch.Tensor]=None\n        ) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(X)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - X\n        if self.low_rank_dim is None:\n            o = self.linear(X + delta * self.mu)\n        else:\n            o = self.linear(X + delta * self.mu)[1]['o']\n        return X, {'o': o}\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LoRA(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: int, bias: Optional[bool]=True,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.bias = bias\n        self.lora = nn.Sequential(nn.Linear(embed_dim, low_rank_dim, bias=\n            False, device=device, dtype=dtype), nn.Tanh(), nn.Linear(\n            low_rank_dim, output_dim, bias=bias, device=device, dtype=dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}('\n        s += (\n            f'input_dim={self.input_dim}, low_rank_dim={self.low_rank_dim}, output_dim={self.output_dim}'\n            )\n        if not self.bias:\n            s += f', bias={self.bias}'\n        s += ')'\n        return s\n\n    def _forward(self, X, **Z):\n        return X, {'o': self.lora(X)}\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom transformers.activations import ACT2FN\nfrom typing import Optional\n\n\nclass RWKV6Attention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        num_heads: int=4, gate_fn: str='swish', proj_low_rank_dim: int=32,\n        gate_low_rank_dim: int=64, elementwise_affine: Optional[bool]=True,\n        norm_eps: float=1e-05, chunk_size: int=32, device=None, dtype=None,\n        **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.num_heads = num_heads\n        self.proj_low_rank_dim = proj_low_rank_dim\n        self.gate_low_rank_dim = gate_low_rank_dim\n        self.chunk_size = chunk_size\n        self.key_dim = embed_dim // 2\n        self.value_dim = embed_dim\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = proj_low_rank_dim * 5\n        self.x_proj = nn.Sequential(LerpLinear(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all), nn.Tanh(), nn.Linear(\n            proj_low_rank_dim * 5, embed_dim, bias=False, device=device,\n            dtype=dtype))\n        self.x_bias = nn.Parameter(torch.zeros(5, embed_dim, device=device,\n            dtype=dtype))\n        kwarg_all['output_dim'] = self.key_dim\n        self.r_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.w_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all.pop('low_rank_dim')\n        self.k_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['output_dim'] = self.value_dim\n        self.v_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.g_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.bonus = nn.Parameter(torch.zeros(num_heads, self.head_qk_dim,\n            device=device, dtype=dtype))\n        self.g_norm = nn.LayerNorm(self.value_dim, elementwise_affine=\n            elementwise_affine, eps=norm_eps, device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        self.gate_fn = ACT2FN[gate_fn]\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        if isinstance(module, nn.Parameter):\n            nn.init.xavier_uniform_(module, gain=2 ** -2.5)\n        module._is_hf_initialized = True\n\n    def naive_chunk_rwkv6(self, q: torch.Tensor, k: torch.Tensor, v: torch.\n        Tensor, w: torch.Tensor, u: torch.Tensor, chunk_size: int=32):\n        assert q.shape[-2] % chunk_size == 0\n        orig_dtype = q.dtype\n        num_chunk = q.shape[-2] // chunk_size\n        u = u.unsqueeze(0)\n        q, k, v, w = map(lambda x: rearrange(x, 'b h (n c) d -> b h n c d',\n            c=chunk_size).float(), (q, k, v, w))\n        w_cumsum = w.cumsum(-2)\n        kw = k * (w_cumsum[..., -1, None, :] - w_cumsum).exp()\n        wkv = kw.transpose(-1, -2) @ v\n        wkv_new = torch.zeros_like(wkv)\n        for i in range(num_chunk - 1):\n            wkv_new[:, :, i + 1] = wkv_new[:, :, i].clone() * w_cumsum[:, :,\n                i, -1, :, None].exp() + wkv[:, :, i]\n        o_inter = torch.einsum('b h n d p, b h n c d -> b h n c p', wkv_new,\n            q * (w_cumsum - w).exp())\n        o_intra = torch.zeros_like(o_inter)\n        for i in range(chunk_size):\n            attn = (q[:, :, :, i, None] * k * (w_cumsum[:, :, :, i, None] -\n                w[:, :, :, i, None] - w_cumsum).exp()).sum(-1)\n            mask = (torch.arange(0, chunk_size) < i).to(attn.device)\n            attn.masked_fill_(~mask, 0)\n            intra_inter_o = (attn.unsqueeze(-1) * v).sum(-2)\n            intra_intra_o = (q[:, :, :, i] * u.unsqueeze(2) * k[:, :, :, i]\n                ).sum(-1).unsqueeze(-1) * v[:, :, :, i]\n            o_intra[:, :, :, i] = intra_inter_o + intra_intra_o\n        o = o_inter + o_intra\n        return rearrange(o, 'b h n c d -> b h (n c) d').to(orig_dtype)\n\n    def pad_input(self, X):\n        _seq_len = X.shape[-2]\n        pad_len = (X.shape[-2] + self.chunk_size - 1\n            ) // self.chunk_size * self.chunk_size - X.shape[-2]\n        return F.pad(X, (0, 0, 0, pad_len)), _seq_len\n\n    def _forward(self, X: torch.Tensor):\n        X, _seq_len = self.pad_input(X)\n        batch_size, seq_len, hidden_size = X.shape\n        last_state = None\n        if X.shape[1] == 1 and last_state is not None:\n            shifted = last_state[0].unsqueeze(1)\n        else:\n            shifted = self.time_shift(X)\n            if last_state is not None:\n                shifted[:, 0] = last_state[0]\n        delta = shifted - X\n        x = self.x_proj[0](X, **{'delta': delta})[1]['o'].view(batch_size,\n            seq_len, -1, self.proj_low_rank_dim)\n        x = torch.einsum('b l n r, h n r-> b l n h', self.x_proj[1](x),\n            self.x_proj[2].weight.view(hidden_size, 5, -1))\n        r, w, k, v, g = x.add_(self.x_bias).unbind(-2)\n        r = self.r_proj(X, **{'mu': r, 'delta': delta})[1]['o']\n        w = self.w_proj(X, **{'mu': w, 'delta': delta})[1]['o']\n        k = self.k_proj(X, **{'mu': k, 'delta': delta})[1]['o']\n        v = self.v_proj(X, **{'mu': v, 'delta': delta})[1]['o']\n        g = self.g_proj(X, **{'mu': g, 'delta': delta})[1]['o']\n        r, w, k, v = map(lambda x: rearrange(x, 'b l (h d) -> b h l d', h=\n            self.num_heads), (r, w, k, v))\n        w = -torch.exp(w)\n        u = self.bonus\n        o = self.naive_chunk_rwkv6(r, k, v, w, u, chunk_size=self.chunk_size)\n        o = rearrange(o, 'b h l d -> b l (h d)')\n        o = self.g_norm(o)\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        o = o[:, :_seq_len]\n        return o\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass DDLerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def forward(self, x: torch.Tensor, mu: torch.Tensor, delta: Optional[\n        torch.Tensor]=None) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(x)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - x\n        if self.low_rank_dim is None:\n            o = self.linear(x + delta * mu)\n        else:\n            o = self.linear(x + delta * mu)[1]['o']\n        return x, {'o': o}\n\n\ngab_config = {'num_heads': 4, 'gate_fn': 'swish', 'proj_low_rank_dim': 32,\n    'gate_low_rank_dim': 64, 'elementwise_affine': True, 'chunk_size': 32,\n    'norm_eps': 1e-05, 'state_expansion_ratio': 4, 'min_gating_bound': 0.1}\n\n\n\nautoconfig={}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "350M": {
        "350M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RWKV6(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RWKV6(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        norm_eps: float=1e-05, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.attn = RWKV6Attention(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.ffn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.ffn = RWKV6FeedForwardSEF(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, _ = self.attn(self.attn_norm(X), **Z)\n        X = X1 + X\n        X2, _ = self.ffn(self.ffn_norm(X), **Z)\n        X = X2 + X\n        return X\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass RWKV6FeedForwardSEF(GAUBase):\n    \"\"\"\n    Enhanced RWKV6 Feed Forward block with State Expansion Features (SEF).\n    \n    This implementation enhances the original RWKV6FeedForward by incorporating:\n    1. Parameter-efficient state expansion using Group Linear Transformation (GLT)\n    2. Hierarchical gating with learnable bounds\n    3. Expanded state management\n    \n    Args:\n        embed_dim (int): Input embedding dimension\n        block_loc (tuple): Location of block in network (layer_idx, n_block)\n        kwarg_all (dict): Additional arguments\n        state_expansion_ratio (int): Ratio for state expansion (default: 4)\n        min_gating_bound (float): Minimum value for gating bounds (default: 0.1)\n        device (Optional[torch.device]): Device to place tensors\n        dtype (Optional[torch.dtype]): Data type of tensors\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        state_expansion_ratio: int=4, min_gating_bound: float=0.1, device=\n        None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.state_expansion_ratio = state_expansion_ratio\n        self.min_gating_bound = min_gating_bound\n        self.num_groups = state_expansion_ratio\n        self.group_size = embed_dim // state_expansion_ratio\n        assert embed_dim % state_expansion_ratio == 0, f'embed_dim must be divisible by state_expansion_ratio, got {embed_dim} and {state_expansion_ratio}'\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = self.group_size\n        self.key_groups = nn.ModuleList([LerpLinear(embed_dim=self.\n            embed_dim, block_loc=self.block_loc, kwarg_all=self.kwarg_all,\n            **self.factory_kwargs, **self.kwarg_all) for _ in range(self.\n            num_groups)])\n        self.beta = nn.Parameter(torch.zeros(self.num_groups, device=device,\n            dtype=dtype))\n        self.value = nn.Linear(embed_dim, embed_dim, bias=False, **self.\n            factory_kwargs)\n        kwarg_all['output_dim'] = embed_dim\n        self.receptance = LerpLinear(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n        self.relu = nn.ReLU()\n        self.gelu = nn.GELU()\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        \"\"\"Initialize parameters with appropriate bounds\"\"\"\n        with torch.no_grad():\n            self.beta.data.fill_(self.min_gating_bound)\n\n    def _compute_hierarchical_gates(self, gates: torch.Tensor) ->torch.Tensor:\n        \"\"\"Compute hierarchical gates with learned lower bounds\"\"\"\n        beta_cumsum = torch.cumsum(F.softplus(self.beta), dim=0)\n        beta_norm = beta_cumsum / beta_cumsum[-1].clamp(min=1e-05)\n        batch_size, seq_len, _ = gates.shape\n        gates = gates.view(batch_size, seq_len, self.num_groups, -1)\n        gates = gates * beta_norm.view(1, 1, self.num_groups, 1)\n        return gates.view(batch_size, seq_len, -1)\n\n    def _forward(self, X: torch.Tensor, **Z) ->torch.Tensor:\n        \"\"\"\n        Forward pass with state expansion and hierarchical gating.\n        \n        Args:\n            X: Input tensor of shape (batch_size, seq_len, embed_dim)\n            \n        Returns:\n            Output tensor of shape (batch_size, seq_len, embed_dim)\n        \"\"\"\n        shifted = self.time_shift(X)\n        delta = shifted - X\n        key_expanded = []\n        for group in range(self.num_groups):\n            key_group = self.key_groups[group](X, delta=delta)[1]['o']\n            key_expanded.append(key_group)\n        key_combined = torch.cat(key_expanded, dim=-1)\n        r = self.relu(key_combined)\n        key = r * r\n        key = self.gelu(key)\n        value = self.value(key)\n        receptance = self.receptance(X, delta=delta)[1]['o']\n        receptance = self._compute_hierarchical_gates(receptance)\n        return receptance.sigmoid() * value\n\n    def extra_repr(self) ->str:\n        \"\"\"Return extra representation string\"\"\"\n        return (\n            f'embed_dim={self.hidden_size}, expansion_ratio={self.state_expansion_ratio}'\n            )\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if self.low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n        self.mu = nn.Parameter(torch.zeros(embed_dim, device=device, dtype=\n            dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _forward(self, X: torch.Tensor, delta: Optional[torch.Tensor]=None\n        ) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(X)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - X\n        if self.low_rank_dim is None:\n            o = self.linear(X + delta * self.mu)\n        else:\n            o = self.linear(X + delta * self.mu)[1]['o']\n        return X, {'o': o}\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LoRA(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: int, bias: Optional[bool]=True,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.bias = bias\n        self.lora = nn.Sequential(nn.Linear(embed_dim, low_rank_dim, bias=\n            False, device=device, dtype=dtype), nn.Tanh(), nn.Linear(\n            low_rank_dim, output_dim, bias=bias, device=device, dtype=dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}('\n        s += (\n            f'input_dim={self.input_dim}, low_rank_dim={self.low_rank_dim}, output_dim={self.output_dim}'\n            )\n        if not self.bias:\n            s += f', bias={self.bias}'\n        s += ')'\n        return s\n\n    def _forward(self, X, **Z):\n        return X, {'o': self.lora(X)}\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom transformers.activations import ACT2FN\nfrom typing import Optional\n\n\nclass RWKV6Attention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        num_heads: int=4, gate_fn: str='swish', proj_low_rank_dim: int=32,\n        gate_low_rank_dim: int=64, elementwise_affine: Optional[bool]=True,\n        norm_eps: float=1e-05, chunk_size: int=32, device=None, dtype=None,\n        **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.num_heads = num_heads\n        self.proj_low_rank_dim = proj_low_rank_dim\n        self.gate_low_rank_dim = gate_low_rank_dim\n        self.chunk_size = chunk_size\n        self.key_dim = embed_dim // 2\n        self.value_dim = embed_dim\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = proj_low_rank_dim * 5\n        self.x_proj = nn.Sequential(LerpLinear(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all), nn.Tanh(), nn.Linear(\n            proj_low_rank_dim * 5, embed_dim, bias=False, device=device,\n            dtype=dtype))\n        self.x_bias = nn.Parameter(torch.zeros(5, embed_dim, device=device,\n            dtype=dtype))\n        kwarg_all['output_dim'] = self.key_dim\n        self.r_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.w_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all.pop('low_rank_dim')\n        self.k_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['output_dim'] = self.value_dim\n        self.v_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.g_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.bonus = nn.Parameter(torch.zeros(num_heads, self.head_qk_dim,\n            device=device, dtype=dtype))\n        self.g_norm = nn.LayerNorm(self.value_dim, elementwise_affine=\n            elementwise_affine, eps=norm_eps, device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        self.gate_fn = ACT2FN[gate_fn]\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        if isinstance(module, nn.Parameter):\n            nn.init.xavier_uniform_(module, gain=2 ** -2.5)\n        module._is_hf_initialized = True\n\n    def naive_chunk_rwkv6(self, q: torch.Tensor, k: torch.Tensor, v: torch.\n        Tensor, w: torch.Tensor, u: torch.Tensor, chunk_size: int=32):\n        assert q.shape[-2] % chunk_size == 0\n        orig_dtype = q.dtype\n        num_chunk = q.shape[-2] // chunk_size\n        u = u.unsqueeze(0)\n        q, k, v, w = map(lambda x: rearrange(x, 'b h (n c) d -> b h n c d',\n            c=chunk_size).float(), (q, k, v, w))\n        w_cumsum = w.cumsum(-2)\n        kw = k * (w_cumsum[..., -1, None, :] - w_cumsum).exp()\n        wkv = kw.transpose(-1, -2) @ v\n        wkv_new = torch.zeros_like(wkv)\n        for i in range(num_chunk - 1):\n            wkv_new[:, :, i + 1] = wkv_new[:, :, i].clone() * w_cumsum[:, :,\n                i, -1, :, None].exp() + wkv[:, :, i]\n        o_inter = torch.einsum('b h n d p, b h n c d -> b h n c p', wkv_new,\n            q * (w_cumsum - w).exp())\n        o_intra = torch.zeros_like(o_inter)\n        for i in range(chunk_size):\n            attn = (q[:, :, :, i, None] * k * (w_cumsum[:, :, :, i, None] -\n                w[:, :, :, i, None] - w_cumsum).exp()).sum(-1)\n            mask = (torch.arange(0, chunk_size) < i).to(attn.device)\n            attn.masked_fill_(~mask, 0)\n            intra_inter_o = (attn.unsqueeze(-1) * v).sum(-2)\n            intra_intra_o = (q[:, :, :, i] * u.unsqueeze(2) * k[:, :, :, i]\n                ).sum(-1).unsqueeze(-1) * v[:, :, :, i]\n            o_intra[:, :, :, i] = intra_inter_o + intra_intra_o\n        o = o_inter + o_intra\n        return rearrange(o, 'b h n c d -> b h (n c) d').to(orig_dtype)\n\n    def pad_input(self, X):\n        _seq_len = X.shape[-2]\n        pad_len = (X.shape[-2] + self.chunk_size - 1\n            ) // self.chunk_size * self.chunk_size - X.shape[-2]\n        return F.pad(X, (0, 0, 0, pad_len)), _seq_len\n\n    def _forward(self, X: torch.Tensor):\n        X, _seq_len = self.pad_input(X)\n        batch_size, seq_len, hidden_size = X.shape\n        last_state = None\n        if X.shape[1] == 1 and last_state is not None:\n            shifted = last_state[0].unsqueeze(1)\n        else:\n            shifted = self.time_shift(X)\n            if last_state is not None:\n                shifted[:, 0] = last_state[0]\n        delta = shifted - X\n        x = self.x_proj[0](X, **{'delta': delta})[1]['o'].view(batch_size,\n            seq_len, -1, self.proj_low_rank_dim)\n        x = torch.einsum('b l n r, h n r-> b l n h', self.x_proj[1](x),\n            self.x_proj[2].weight.view(hidden_size, 5, -1))\n        r, w, k, v, g = x.add_(self.x_bias).unbind(-2)\n        r = self.r_proj(X, **{'mu': r, 'delta': delta})[1]['o']\n        w = self.w_proj(X, **{'mu': w, 'delta': delta})[1]['o']\n        k = self.k_proj(X, **{'mu': k, 'delta': delta})[1]['o']\n        v = self.v_proj(X, **{'mu': v, 'delta': delta})[1]['o']\n        g = self.g_proj(X, **{'mu': g, 'delta': delta})[1]['o']\n        r, w, k, v = map(lambda x: rearrange(x, 'b l (h d) -> b h l d', h=\n            self.num_heads), (r, w, k, v))\n        w = -torch.exp(w)\n        u = self.bonus\n        o = self.naive_chunk_rwkv6(r, k, v, w, u, chunk_size=self.chunk_size)\n        o = rearrange(o, 'b h l d -> b l (h d)')\n        o = self.g_norm(o)\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        o = o[:, :_seq_len]\n        return o\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass DDLerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def forward(self, x: torch.Tensor, mu: torch.Tensor, delta: Optional[\n        torch.Tensor]=None) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(x)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - x\n        if self.low_rank_dim is None:\n            o = self.linear(x + delta * mu)\n        else:\n            o = self.linear(x + delta * mu)[1]['o']\n        return x, {'o': o}\n\n\ngab_config = {'num_heads': 4, 'gate_fn': 'swish', 'proj_low_rank_dim': 32,\n    'gate_low_rank_dim': 64, 'elementwise_affine': True, 'chunk_size': 32,\n    'norm_eps': 1e-05, 'state_expansion_ratio': 4, 'min_gating_bound': 0.1}\n\n\n\nautoconfig = {\n    'd_model': 1024,\n    'n_block': 45\n}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    }
}