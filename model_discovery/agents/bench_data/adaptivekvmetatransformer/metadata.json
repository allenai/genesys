{
    "title": "AdaptiveKVMetaTransformer: Enhancing Efficiency in Autoregressive Language Models through Adaptive Layer-wise KV Cache Management and Sparse Attention",
    "acronym": "adaptivekvmetatransformer",
    "sess_id": "2024-10-30-13-09-10-bd0165",
    "sess_snapshot": {
        "ref_ids": [
            "streamretnet",
            "hierarchicalcompressedlm",
            "s5",
            "hyena",
            "d3pms",
            "assparseattn"
        ],
        "proposed": [],
        "reranked": {},
        "num_samples": {
            "implementation": 1,
            "rerank_method": "rating",
            "proposal": 1
        },
        "instruct": "",
        "mode": "Mutate existing design",
        "seed_ids": [
            "gpt_2_ala"
        ]
    },
    "seed_ids": [
        "gpt_2_ala"
    ]
}