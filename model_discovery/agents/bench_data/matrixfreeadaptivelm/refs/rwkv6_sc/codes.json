{
    "31M": {
        "31M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RWKV6(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RWKV6(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        norm_eps: float=1e-05, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.attn = RWKV6Attention(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.ffn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.ffn = RWKV6FeedForward(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, _ = self.attn(self.attn_norm(X), **Z)\n        X = X1 + X\n        X2, _ = self.ffn(self.ffn_norm(X), **Z)\n        X = X2 + X\n        return X\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom transformers.activations import ACT2FN\nfrom typing import Optional\n\n\nclass RWKV6Attention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        num_heads: int=4, gate_fn: str='swish', proj_low_rank_dim: int=32,\n        gate_low_rank_dim: int=64, elementwise_affine: Optional[bool]=True,\n        norm_eps: float=1e-05, chunk_size: int=32, device=None, dtype=None,\n        **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.num_heads = num_heads\n        self.proj_low_rank_dim = proj_low_rank_dim\n        self.gate_low_rank_dim = gate_low_rank_dim\n        self.chunk_size = chunk_size\n        self.key_dim = embed_dim // 2\n        self.value_dim = embed_dim\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = proj_low_rank_dim * 5\n        self.x_proj = nn.Sequential(LerpLinear(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all), nn.Tanh(), nn.Linear(\n            proj_low_rank_dim * 5, embed_dim, bias=False, device=device,\n            dtype=dtype))\n        self.x_bias = nn.Parameter(torch.zeros(5, embed_dim, device=device,\n            dtype=dtype))\n        kwarg_all['output_dim'] = self.key_dim\n        self.r_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.w_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all.pop('low_rank_dim')\n        self.k_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['output_dim'] = self.value_dim\n        self.v_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.g_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.bonus = nn.Parameter(torch.zeros(num_heads, self.head_qk_dim,\n            device=device, dtype=dtype))\n        self.g_norm = nn.LayerNorm(self.value_dim, elementwise_affine=\n            elementwise_affine, eps=norm_eps, device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        self.gate_fn = ACT2FN[gate_fn]\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        if isinstance(module, nn.Parameter):\n            nn.init.xavier_uniform_(module, gain=2 ** -2.5)\n        module._is_hf_initialized = True\n\n    def naive_chunk_rwkv6(self, q: torch.Tensor, k: torch.Tensor, v: torch.\n        Tensor, w: torch.Tensor, u: torch.Tensor, chunk_size: int=32):\n        assert q.shape[-2] % chunk_size == 0\n        orig_dtype = q.dtype\n        num_chunk = q.shape[-2] // chunk_size\n        u = u.unsqueeze(0)\n        q, k, v, w = map(lambda x: rearrange(x, 'b h (n c) d -> b h n c d',\n            c=chunk_size).float(), (q, k, v, w))\n        w_cumsum = w.cumsum(-2)\n        kw = k * (w_cumsum[..., -1, None, :] - w_cumsum).exp()\n        wkv = kw.transpose(-1, -2) @ v\n        wkv_new = torch.zeros_like(wkv)\n        for i in range(num_chunk - 1):\n            wkv_new[:, :, i + 1] = wkv_new[:, :, i].clone() * w_cumsum[:, :,\n                i, -1, :, None].exp() + wkv[:, :, i]\n        o_inter = torch.einsum('b h n d p, b h n c d -> b h n c p', wkv_new,\n            q * (w_cumsum - w).exp())\n        o_intra = torch.zeros_like(o_inter)\n        for i in range(chunk_size):\n            attn = (q[:, :, :, i, None] * k * (w_cumsum[:, :, :, i, None] -\n                w[:, :, :, i, None] - w_cumsum).exp()).sum(-1)\n            mask = (torch.arange(0, chunk_size) < i).to(attn.device)\n            attn.masked_fill_(~mask, 0)\n            intra_inter_o = (attn.unsqueeze(-1) * v).sum(-2)\n            intra_intra_o = (q[:, :, :, i] * u.unsqueeze(2) * k[:, :, :, i]\n                ).sum(-1).unsqueeze(-1) * v[:, :, :, i]\n            o_intra[:, :, :, i] = intra_inter_o + intra_intra_o\n        o = o_inter + o_intra\n        return rearrange(o, 'b h n c d -> b h (n c) d').to(orig_dtype)\n\n    def pad_input(self, X):\n        _seq_len = X.shape[-2]\n        pad_len = (X.shape[-2] + self.chunk_size - 1\n            ) // self.chunk_size * self.chunk_size - X.shape[-2]\n        return F.pad(X, (0, 0, 0, pad_len)), _seq_len\n\n    def _forward(self, X: torch.Tensor):\n        X, _seq_len = self.pad_input(X)\n        batch_size, seq_len, hidden_size = X.shape\n        last_state = None\n        if X.shape[1] == 1 and last_state is not None:\n            shifted = last_state[0].unsqueeze(1)\n        else:\n            shifted = self.time_shift(X)\n            if last_state is not None:\n                shifted[:, 0] = last_state[0]\n        delta = shifted - X\n        x = self.x_proj[0](X, **{'delta': delta})[1]['o'].view(batch_size,\n            seq_len, -1, self.proj_low_rank_dim)\n        x = torch.einsum('b l n r, h n r-> b l n h', self.x_proj[1](x),\n            self.x_proj[2].weight.view(hidden_size, 5, -1))\n        r, w, k, v, g = x.add_(self.x_bias).unbind(-2)\n        r = self.r_proj(X, **{'mu': r, 'delta': delta})[1]['o']\n        w = self.w_proj(X, **{'mu': w, 'delta': delta})[1]['o']\n        k = self.k_proj(X, **{'mu': k, 'delta': delta})[1]['o']\n        v = self.v_proj(X, **{'mu': v, 'delta': delta})[1]['o']\n        g = self.g_proj(X, **{'mu': g, 'delta': delta})[1]['o']\n        r, w, k, v = map(lambda x: rearrange(x, 'b l (h d) -> b h l d', h=\n            self.num_heads), (r, w, k, v))\n        w = -torch.exp(w)\n        u = self.bonus\n        o = self.naive_chunk_rwkv6(r, k, v, w, u, chunk_size=self.chunk_size)\n        o = rearrange(o, 'b h l d -> b l (h d)')\n        o = self.g_norm(o)\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        o = o[:, :_seq_len]\n        return o\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\nimport torch.utils.checkpoint\n\n\nclass DDLerpLinear(GAUBase):\n    \"\"\"\n    DDLerpLinear with Semantic Compression (DDLerpLinear-SC)\n    \n    This unit enhances the original DDLerpLinear with semantic compression capabilities.\n    It performs dynamic linear interpolation with content-aware state compression.\n    \n    The unit processes input X using the following steps:\n    1. Computes time-shift difference (delta)\n    2. Applies semantic compression to the state (mu)\n    3. Performs linear interpolation with compressed state\n    4. Projects through linear/LoRA layer\n    \n    Args:\n        embed_dim (int): Input embedding dimension\n        block_loc (tuple): Location of block in network (layer_idx, n_block)\n        kwarg_all (dict): Dictionary of all kwargs\n        output_dim (int): Output dimension\n        low_rank_dim (Optional[int]): Dimension for LoRA projection. If None, uses standard linear\n        device (Optional): Device to place tensors on\n        dtype (Optional): Data type for tensors\n        \n    Inputs:\n        X (Tensor): Input tensor of shape (batch_size, seq_len, embed_dim)\n        mu (Tensor): State tensor for interpolation, shape (embed_dim,) or (batch_size, seq_len, embed_dim)\n        delta (Optional[Tensor]): Time difference tensor. If None, computed from X\n        \n    Returns:\n        Tuple[Tensor, Dict]:\n            - X: Input tensor (unchanged)\n            - Dict containing:\n                - 'o': Output tensor after projection\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.gradient_checkpointing = True\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        self.compress_gate = nn.Sequential(nn.Linear(embed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.Sigmoid())\n        if low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False, **\n                self.factory_kwargs)\n        else:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False, **\n                self.factory_kwargs)\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _validate_shapes(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None):\n        \"\"\"Validate input shapes\"\"\"\n        if X.dim() != 3:\n            raise ValueError(\n                f'Expected 3D input (batch, seq, dim), got {X.dim()}D')\n        if mu.dim() not in (1, 3):\n            raise ValueError(f'Expected 1D or 3D mu tensor, got {mu.dim()}D')\n        if delta is not None and delta.shape != X.shape:\n            raise ValueError(\n                f\"Delta shape {delta.shape} doesn't match input shape {X.shape}\"\n                )\n\n    def _process_mu(self, mu: torch.Tensor, batch_size: int, seq_len: int\n        ) ->torch.Tensor:\n        \"\"\"Process mu tensor to handle both 1D and 3D inputs\"\"\"\n        if mu.dim() == 1:\n            return mu.view(1, 1, -1).expand(batch_size, seq_len, -1)\n        return mu\n\n    def _compute_chunk_size(self, seq_len: int, base_chunk_size: int=1024\n        ) ->int:\n        \"\"\"Compute chunk size that evenly divides sequence length\"\"\"\n        if seq_len <= base_chunk_size:\n            return seq_len\n        num_chunks = (seq_len + base_chunk_size - 1) // base_chunk_size\n        return seq_len // num_chunks\n\n    def _forward_chunk(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None) ->tuple:\n        \"\"\"Process a single chunk\"\"\"\n        batch_size, seq_len, _ = X.shape\n        mu = self._process_mu(mu, batch_size, seq_len)\n        if delta is None:\n            shifted = self.time_shift(X)\n            delta = shifted - X\n        compression_mask = self.compress_gate(X)\n        mu_compressed = mu * compression_mask\n        interpolated = X + delta * mu_compressed\n        output = self.linear(interpolated)\n        return X, {'o': output}\n\n    def _process_batch(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None) ->tuple:\n        \"\"\"Process input in chunks\"\"\"\n        chunk_size = self._compute_chunk_size(X.shape[1])\n        outputs = []\n        output_projs = []\n        for i in range(0, X.shape[1], chunk_size):\n            end_idx = min(i + chunk_size, X.shape[1])\n            chunk_X = X[:, i:end_idx]\n            chunk_mu = mu if mu.dim() == 1 else mu[:, i:end_idx]\n            chunk_delta = None if delta is None else delta[:, i:end_idx]\n            X_out, Z_out = self._forward_chunk(chunk_X, chunk_mu, chunk_delta)\n            outputs.append(X_out)\n            output_projs.append(Z_out['o'])\n        return torch.cat(outputs, dim=1), {'o': torch.cat(output_projs, dim=1)}\n\n    def _forward(self, X: torch.Tensor, mu: torch.Tensor, delta: Optional[\n        torch.Tensor]=None) ->tuple:\n        \"\"\"Forward pass with memory optimization\"\"\"\n        self._validate_shapes(X, mu, delta)\n        if X.shape[1] > 1024:\n            if self.gradient_checkpointing and self.training:\n\n                def custom_forward(*inputs):\n                    return self._process_batch(*inputs)\n                return torch.utils.checkpoint.checkpoint(custom_forward, X,\n                    mu, delta, use_reentrant=False, preserve_rng_state=False)\n            return self._process_batch(X, mu, delta)\n        if self.gradient_checkpointing and self.training:\n\n            def custom_forward(*inputs):\n                return self._forward_chunk(*inputs)\n            return torch.utils.checkpoint.checkpoint(custom_forward, X, mu,\n                delta, use_reentrant=False, preserve_rng_state=False)\n        return self._forward_chunk(X, mu, delta)\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if self.low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n        self.mu = nn.Parameter(torch.zeros(embed_dim, device=device, dtype=\n            dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _forward(self, X: torch.Tensor, delta: Optional[torch.Tensor]=None\n        ) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(X)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - X\n        if self.low_rank_dim is None:\n            o = self.linear(X + delta * self.mu)\n        else:\n            o = self.linear(X + delta * self.mu)[1]['o']\n        return X, {'o': o}\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LoRA(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: int, bias: Optional[bool]=True,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.bias = bias\n        self.lora = nn.Sequential(nn.Linear(embed_dim, low_rank_dim, bias=\n            False, device=device, dtype=dtype), nn.Tanh(), nn.Linear(\n            low_rank_dim, output_dim, bias=bias, device=device, dtype=dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}('\n        s += (\n            f'input_dim={self.input_dim}, low_rank_dim={self.low_rank_dim}, output_dim={self.output_dim}'\n            )\n        if not self.bias:\n            s += f', bias={self.bias}'\n        s += ')'\n        return s\n\n    def _forward(self, X, **Z):\n        return X, {'o': self.lora(X)}\n\n\nimport torch.nn.functional as F\n\n\nclass RWKV6FeedForward(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        hidden_ratio = 3.5\n        intermediate_size = int(embed_dim * hidden_ratio)\n        intermediate_size = 32 * ((intermediate_size + 32 - 1) // 32)\n        self.hidden_ratio = hidden_ratio\n        self.intermediate_size = intermediate_size\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = intermediate_size\n        self.key = LerpLinear(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.value = nn.Linear(intermediate_size, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        kwarg_all['output_dim'] = embed_dim\n        self.receptance = LerpLinear(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n        self.relu = nn.ReLU()\n\n    def _forward(self, X, **Z):\n        shifted = self.time_shift(X)\n        delta = shifted - X\n        _key = self.key(X, **{'delta': delta})[1]['o']\n        r = self.relu(_key)\n        key = r * r\n        value = self.value(key)\n        receptance = self.receptance(X, **{'delta': delta})[1]['o']\n        return receptance.sigmoid() * value\n\n\ngab_config = {'num_heads': 4, 'gate_fn': 'swish', 'proj_low_rank_dim': 32,\n    'gate_low_rank_dim': 64, 'elementwise_affine': True, 'chunk_size': 32,\n    'norm_eps': 1e-05, 'output_dim': None, 'low_rank_dim': None}\n\n\n\nautoconfig={}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "760M": {
        "760M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RWKV6(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RWKV6(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        norm_eps: float=1e-05, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.attn = RWKV6Attention(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.ffn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.ffn = RWKV6FeedForward(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, _ = self.attn(self.attn_norm(X), **Z)\n        X = X1 + X\n        X2, _ = self.ffn(self.ffn_norm(X), **Z)\n        X = X2 + X\n        return X\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom transformers.activations import ACT2FN\nfrom typing import Optional\n\n\nclass RWKV6Attention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        num_heads: int=4, gate_fn: str='swish', proj_low_rank_dim: int=32,\n        gate_low_rank_dim: int=64, elementwise_affine: Optional[bool]=True,\n        norm_eps: float=1e-05, chunk_size: int=32, device=None, dtype=None,\n        **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.num_heads = num_heads\n        self.proj_low_rank_dim = proj_low_rank_dim\n        self.gate_low_rank_dim = gate_low_rank_dim\n        self.chunk_size = chunk_size\n        self.key_dim = embed_dim // 2\n        self.value_dim = embed_dim\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = proj_low_rank_dim * 5\n        self.x_proj = nn.Sequential(LerpLinear(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all), nn.Tanh(), nn.Linear(\n            proj_low_rank_dim * 5, embed_dim, bias=False, device=device,\n            dtype=dtype))\n        self.x_bias = nn.Parameter(torch.zeros(5, embed_dim, device=device,\n            dtype=dtype))\n        kwarg_all['output_dim'] = self.key_dim\n        self.r_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.w_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all.pop('low_rank_dim')\n        self.k_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['output_dim'] = self.value_dim\n        self.v_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.g_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.bonus = nn.Parameter(torch.zeros(num_heads, self.head_qk_dim,\n            device=device, dtype=dtype))\n        self.g_norm = nn.LayerNorm(self.value_dim, elementwise_affine=\n            elementwise_affine, eps=norm_eps, device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        self.gate_fn = ACT2FN[gate_fn]\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        if isinstance(module, nn.Parameter):\n            nn.init.xavier_uniform_(module, gain=2 ** -2.5)\n        module._is_hf_initialized = True\n\n    def naive_chunk_rwkv6(self, q: torch.Tensor, k: torch.Tensor, v: torch.\n        Tensor, w: torch.Tensor, u: torch.Tensor, chunk_size: int=32):\n        assert q.shape[-2] % chunk_size == 0\n        orig_dtype = q.dtype\n        num_chunk = q.shape[-2] // chunk_size\n        u = u.unsqueeze(0)\n        q, k, v, w = map(lambda x: rearrange(x, 'b h (n c) d -> b h n c d',\n            c=chunk_size).float(), (q, k, v, w))\n        w_cumsum = w.cumsum(-2)\n        kw = k * (w_cumsum[..., -1, None, :] - w_cumsum).exp()\n        wkv = kw.transpose(-1, -2) @ v\n        wkv_new = torch.zeros_like(wkv)\n        for i in range(num_chunk - 1):\n            wkv_new[:, :, i + 1] = wkv_new[:, :, i].clone() * w_cumsum[:, :,\n                i, -1, :, None].exp() + wkv[:, :, i]\n        o_inter = torch.einsum('b h n d p, b h n c d -> b h n c p', wkv_new,\n            q * (w_cumsum - w).exp())\n        o_intra = torch.zeros_like(o_inter)\n        for i in range(chunk_size):\n            attn = (q[:, :, :, i, None] * k * (w_cumsum[:, :, :, i, None] -\n                w[:, :, :, i, None] - w_cumsum).exp()).sum(-1)\n            mask = (torch.arange(0, chunk_size) < i).to(attn.device)\n            attn.masked_fill_(~mask, 0)\n            intra_inter_o = (attn.unsqueeze(-1) * v).sum(-2)\n            intra_intra_o = (q[:, :, :, i] * u.unsqueeze(2) * k[:, :, :, i]\n                ).sum(-1).unsqueeze(-1) * v[:, :, :, i]\n            o_intra[:, :, :, i] = intra_inter_o + intra_intra_o\n        o = o_inter + o_intra\n        return rearrange(o, 'b h n c d -> b h (n c) d').to(orig_dtype)\n\n    def pad_input(self, X):\n        _seq_len = X.shape[-2]\n        pad_len = (X.shape[-2] + self.chunk_size - 1\n            ) // self.chunk_size * self.chunk_size - X.shape[-2]\n        return F.pad(X, (0, 0, 0, pad_len)), _seq_len\n\n    def _forward(self, X: torch.Tensor):\n        X, _seq_len = self.pad_input(X)\n        batch_size, seq_len, hidden_size = X.shape\n        last_state = None\n        if X.shape[1] == 1 and last_state is not None:\n            shifted = last_state[0].unsqueeze(1)\n        else:\n            shifted = self.time_shift(X)\n            if last_state is not None:\n                shifted[:, 0] = last_state[0]\n        delta = shifted - X\n        x = self.x_proj[0](X, **{'delta': delta})[1]['o'].view(batch_size,\n            seq_len, -1, self.proj_low_rank_dim)\n        x = torch.einsum('b l n r, h n r-> b l n h', self.x_proj[1](x),\n            self.x_proj[2].weight.view(hidden_size, 5, -1))\n        r, w, k, v, g = x.add_(self.x_bias).unbind(-2)\n        r = self.r_proj(X, **{'mu': r, 'delta': delta})[1]['o']\n        w = self.w_proj(X, **{'mu': w, 'delta': delta})[1]['o']\n        k = self.k_proj(X, **{'mu': k, 'delta': delta})[1]['o']\n        v = self.v_proj(X, **{'mu': v, 'delta': delta})[1]['o']\n        g = self.g_proj(X, **{'mu': g, 'delta': delta})[1]['o']\n        r, w, k, v = map(lambda x: rearrange(x, 'b l (h d) -> b h l d', h=\n            self.num_heads), (r, w, k, v))\n        w = -torch.exp(w)\n        u = self.bonus\n        o = self.naive_chunk_rwkv6(r, k, v, w, u, chunk_size=self.chunk_size)\n        o = rearrange(o, 'b h l d -> b l (h d)')\n        o = self.g_norm(o)\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        o = o[:, :_seq_len]\n        return o\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\nimport torch.utils.checkpoint\n\n\nclass DDLerpLinear(GAUBase):\n    \"\"\"\n    DDLerpLinear with Semantic Compression (DDLerpLinear-SC)\n    \n    This unit enhances the original DDLerpLinear with semantic compression capabilities.\n    It performs dynamic linear interpolation with content-aware state compression.\n    \n    The unit processes input X using the following steps:\n    1. Computes time-shift difference (delta)\n    2. Applies semantic compression to the state (mu)\n    3. Performs linear interpolation with compressed state\n    4. Projects through linear/LoRA layer\n    \n    Args:\n        embed_dim (int): Input embedding dimension\n        block_loc (tuple): Location of block in network (layer_idx, n_block)\n        kwarg_all (dict): Dictionary of all kwargs\n        output_dim (int): Output dimension\n        low_rank_dim (Optional[int]): Dimension for LoRA projection. If None, uses standard linear\n        device (Optional): Device to place tensors on\n        dtype (Optional): Data type for tensors\n        \n    Inputs:\n        X (Tensor): Input tensor of shape (batch_size, seq_len, embed_dim)\n        mu (Tensor): State tensor for interpolation, shape (embed_dim,) or (batch_size, seq_len, embed_dim)\n        delta (Optional[Tensor]): Time difference tensor. If None, computed from X\n        \n    Returns:\n        Tuple[Tensor, Dict]:\n            - X: Input tensor (unchanged)\n            - Dict containing:\n                - 'o': Output tensor after projection\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.gradient_checkpointing = True\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        self.compress_gate = nn.Sequential(nn.Linear(embed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.Sigmoid())\n        if low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False, **\n                self.factory_kwargs)\n        else:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False, **\n                self.factory_kwargs)\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _validate_shapes(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None):\n        \"\"\"Validate input shapes\"\"\"\n        if X.dim() != 3:\n            raise ValueError(\n                f'Expected 3D input (batch, seq, dim), got {X.dim()}D')\n        if mu.dim() not in (1, 3):\n            raise ValueError(f'Expected 1D or 3D mu tensor, got {mu.dim()}D')\n        if delta is not None and delta.shape != X.shape:\n            raise ValueError(\n                f\"Delta shape {delta.shape} doesn't match input shape {X.shape}\"\n                )\n\n    def _process_mu(self, mu: torch.Tensor, batch_size: int, seq_len: int\n        ) ->torch.Tensor:\n        \"\"\"Process mu tensor to handle both 1D and 3D inputs\"\"\"\n        if mu.dim() == 1:\n            return mu.view(1, 1, -1).expand(batch_size, seq_len, -1)\n        return mu\n\n    def _compute_chunk_size(self, seq_len: int, base_chunk_size: int=1024\n        ) ->int:\n        \"\"\"Compute chunk size that evenly divides sequence length\"\"\"\n        if seq_len <= base_chunk_size:\n            return seq_len\n        num_chunks = (seq_len + base_chunk_size - 1) // base_chunk_size\n        return seq_len // num_chunks\n\n    def _forward_chunk(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None) ->tuple:\n        \"\"\"Process a single chunk\"\"\"\n        batch_size, seq_len, _ = X.shape\n        mu = self._process_mu(mu, batch_size, seq_len)\n        if delta is None:\n            shifted = self.time_shift(X)\n            delta = shifted - X\n        compression_mask = self.compress_gate(X)\n        mu_compressed = mu * compression_mask\n        interpolated = X + delta * mu_compressed\n        output = self.linear(interpolated)\n        return X, {'o': output}\n\n    def _process_batch(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None) ->tuple:\n        \"\"\"Process input in chunks\"\"\"\n        chunk_size = self._compute_chunk_size(X.shape[1])\n        outputs = []\n        output_projs = []\n        for i in range(0, X.shape[1], chunk_size):\n            end_idx = min(i + chunk_size, X.shape[1])\n            chunk_X = X[:, i:end_idx]\n            chunk_mu = mu if mu.dim() == 1 else mu[:, i:end_idx]\n            chunk_delta = None if delta is None else delta[:, i:end_idx]\n            X_out, Z_out = self._forward_chunk(chunk_X, chunk_mu, chunk_delta)\n            outputs.append(X_out)\n            output_projs.append(Z_out['o'])\n        return torch.cat(outputs, dim=1), {'o': torch.cat(output_projs, dim=1)}\n\n    def _forward(self, X: torch.Tensor, mu: torch.Tensor, delta: Optional[\n        torch.Tensor]=None) ->tuple:\n        \"\"\"Forward pass with memory optimization\"\"\"\n        self._validate_shapes(X, mu, delta)\n        if X.shape[1] > 1024:\n            if self.gradient_checkpointing and self.training:\n\n                def custom_forward(*inputs):\n                    return self._process_batch(*inputs)\n                return torch.utils.checkpoint.checkpoint(custom_forward, X,\n                    mu, delta, use_reentrant=False, preserve_rng_state=False)\n            return self._process_batch(X, mu, delta)\n        if self.gradient_checkpointing and self.training:\n\n            def custom_forward(*inputs):\n                return self._forward_chunk(*inputs)\n            return torch.utils.checkpoint.checkpoint(custom_forward, X, mu,\n                delta, use_reentrant=False, preserve_rng_state=False)\n        return self._forward_chunk(X, mu, delta)\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if self.low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n        self.mu = nn.Parameter(torch.zeros(embed_dim, device=device, dtype=\n            dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _forward(self, X: torch.Tensor, delta: Optional[torch.Tensor]=None\n        ) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(X)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - X\n        if self.low_rank_dim is None:\n            o = self.linear(X + delta * self.mu)\n        else:\n            o = self.linear(X + delta * self.mu)[1]['o']\n        return X, {'o': o}\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LoRA(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: int, bias: Optional[bool]=True,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.bias = bias\n        self.lora = nn.Sequential(nn.Linear(embed_dim, low_rank_dim, bias=\n            False, device=device, dtype=dtype), nn.Tanh(), nn.Linear(\n            low_rank_dim, output_dim, bias=bias, device=device, dtype=dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}('\n        s += (\n            f'input_dim={self.input_dim}, low_rank_dim={self.low_rank_dim}, output_dim={self.output_dim}'\n            )\n        if not self.bias:\n            s += f', bias={self.bias}'\n        s += ')'\n        return s\n\n    def _forward(self, X, **Z):\n        return X, {'o': self.lora(X)}\n\n\nimport torch.nn.functional as F\n\n\nclass RWKV6FeedForward(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        hidden_ratio = 3.5\n        intermediate_size = int(embed_dim * hidden_ratio)\n        intermediate_size = 32 * ((intermediate_size + 32 - 1) // 32)\n        self.hidden_ratio = hidden_ratio\n        self.intermediate_size = intermediate_size\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = intermediate_size\n        self.key = LerpLinear(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.value = nn.Linear(intermediate_size, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        kwarg_all['output_dim'] = embed_dim\n        self.receptance = LerpLinear(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n        self.relu = nn.ReLU()\n\n    def _forward(self, X, **Z):\n        shifted = self.time_shift(X)\n        delta = shifted - X\n        _key = self.key(X, **{'delta': delta})[1]['o']\n        r = self.relu(_key)\n        key = r * r\n        value = self.value(key)\n        receptance = self.receptance(X, **{'delta': delta})[1]['o']\n        return receptance.sigmoid() * value\n\n\ngab_config = {'num_heads': 4, 'gate_fn': 'swish', 'proj_low_rank_dim': 32,\n    'gate_low_rank_dim': 64, 'elementwise_affine': True, 'chunk_size': 32,\n    'norm_eps': 1e-05, 'output_dim': None, 'low_rank_dim': None}\n\n\n\nautoconfig={}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "70M": {
        "70M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RWKV6(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RWKV6(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        norm_eps: float=1e-05, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.attn = RWKV6Attention(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.ffn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.ffn = RWKV6FeedForward(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, _ = self.attn(self.attn_norm(X), **Z)\n        X = X1 + X\n        X2, _ = self.ffn(self.ffn_norm(X), **Z)\n        X = X2 + X\n        return X\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom transformers.activations import ACT2FN\nfrom typing import Optional\n\n\nclass RWKV6Attention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        num_heads: int=4, gate_fn: str='swish', proj_low_rank_dim: int=32,\n        gate_low_rank_dim: int=64, elementwise_affine: Optional[bool]=True,\n        norm_eps: float=1e-05, chunk_size: int=32, device=None, dtype=None,\n        **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.num_heads = num_heads\n        self.proj_low_rank_dim = proj_low_rank_dim\n        self.gate_low_rank_dim = gate_low_rank_dim\n        self.chunk_size = chunk_size\n        self.key_dim = embed_dim // 2\n        self.value_dim = embed_dim\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = proj_low_rank_dim * 5\n        self.x_proj = nn.Sequential(LerpLinear(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all), nn.Tanh(), nn.Linear(\n            proj_low_rank_dim * 5, embed_dim, bias=False, device=device,\n            dtype=dtype))\n        self.x_bias = nn.Parameter(torch.zeros(5, embed_dim, device=device,\n            dtype=dtype))\n        kwarg_all['output_dim'] = self.key_dim\n        self.r_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.w_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all.pop('low_rank_dim')\n        self.k_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['output_dim'] = self.value_dim\n        self.v_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.g_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.bonus = nn.Parameter(torch.zeros(num_heads, self.head_qk_dim,\n            device=device, dtype=dtype))\n        self.g_norm = nn.LayerNorm(self.value_dim, elementwise_affine=\n            elementwise_affine, eps=norm_eps, device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        self.gate_fn = ACT2FN[gate_fn]\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        if isinstance(module, nn.Parameter):\n            nn.init.xavier_uniform_(module, gain=2 ** -2.5)\n        module._is_hf_initialized = True\n\n    def naive_chunk_rwkv6(self, q: torch.Tensor, k: torch.Tensor, v: torch.\n        Tensor, w: torch.Tensor, u: torch.Tensor, chunk_size: int=32):\n        assert q.shape[-2] % chunk_size == 0\n        orig_dtype = q.dtype\n        num_chunk = q.shape[-2] // chunk_size\n        u = u.unsqueeze(0)\n        q, k, v, w = map(lambda x: rearrange(x, 'b h (n c) d -> b h n c d',\n            c=chunk_size).float(), (q, k, v, w))\n        w_cumsum = w.cumsum(-2)\n        kw = k * (w_cumsum[..., -1, None, :] - w_cumsum).exp()\n        wkv = kw.transpose(-1, -2) @ v\n        wkv_new = torch.zeros_like(wkv)\n        for i in range(num_chunk - 1):\n            wkv_new[:, :, i + 1] = wkv_new[:, :, i].clone() * w_cumsum[:, :,\n                i, -1, :, None].exp() + wkv[:, :, i]\n        o_inter = torch.einsum('b h n d p, b h n c d -> b h n c p', wkv_new,\n            q * (w_cumsum - w).exp())\n        o_intra = torch.zeros_like(o_inter)\n        for i in range(chunk_size):\n            attn = (q[:, :, :, i, None] * k * (w_cumsum[:, :, :, i, None] -\n                w[:, :, :, i, None] - w_cumsum).exp()).sum(-1)\n            mask = (torch.arange(0, chunk_size) < i).to(attn.device)\n            attn.masked_fill_(~mask, 0)\n            intra_inter_o = (attn.unsqueeze(-1) * v).sum(-2)\n            intra_intra_o = (q[:, :, :, i] * u.unsqueeze(2) * k[:, :, :, i]\n                ).sum(-1).unsqueeze(-1) * v[:, :, :, i]\n            o_intra[:, :, :, i] = intra_inter_o + intra_intra_o\n        o = o_inter + o_intra\n        return rearrange(o, 'b h n c d -> b h (n c) d').to(orig_dtype)\n\n    def pad_input(self, X):\n        _seq_len = X.shape[-2]\n        pad_len = (X.shape[-2] + self.chunk_size - 1\n            ) // self.chunk_size * self.chunk_size - X.shape[-2]\n        return F.pad(X, (0, 0, 0, pad_len)), _seq_len\n\n    def _forward(self, X: torch.Tensor):\n        X, _seq_len = self.pad_input(X)\n        batch_size, seq_len, hidden_size = X.shape\n        last_state = None\n        if X.shape[1] == 1 and last_state is not None:\n            shifted = last_state[0].unsqueeze(1)\n        else:\n            shifted = self.time_shift(X)\n            if last_state is not None:\n                shifted[:, 0] = last_state[0]\n        delta = shifted - X\n        x = self.x_proj[0](X, **{'delta': delta})[1]['o'].view(batch_size,\n            seq_len, -1, self.proj_low_rank_dim)\n        x = torch.einsum('b l n r, h n r-> b l n h', self.x_proj[1](x),\n            self.x_proj[2].weight.view(hidden_size, 5, -1))\n        r, w, k, v, g = x.add_(self.x_bias).unbind(-2)\n        r = self.r_proj(X, **{'mu': r, 'delta': delta})[1]['o']\n        w = self.w_proj(X, **{'mu': w, 'delta': delta})[1]['o']\n        k = self.k_proj(X, **{'mu': k, 'delta': delta})[1]['o']\n        v = self.v_proj(X, **{'mu': v, 'delta': delta})[1]['o']\n        g = self.g_proj(X, **{'mu': g, 'delta': delta})[1]['o']\n        r, w, k, v = map(lambda x: rearrange(x, 'b l (h d) -> b h l d', h=\n            self.num_heads), (r, w, k, v))\n        w = -torch.exp(w)\n        u = self.bonus\n        o = self.naive_chunk_rwkv6(r, k, v, w, u, chunk_size=self.chunk_size)\n        o = rearrange(o, 'b h l d -> b l (h d)')\n        o = self.g_norm(o)\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        o = o[:, :_seq_len]\n        return o\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\nimport torch.utils.checkpoint\n\n\nclass DDLerpLinear(GAUBase):\n    \"\"\"\n    DDLerpLinear with Semantic Compression (DDLerpLinear-SC)\n    \n    This unit enhances the original DDLerpLinear with semantic compression capabilities.\n    It performs dynamic linear interpolation with content-aware state compression.\n    \n    The unit processes input X using the following steps:\n    1. Computes time-shift difference (delta)\n    2. Applies semantic compression to the state (mu)\n    3. Performs linear interpolation with compressed state\n    4. Projects through linear/LoRA layer\n    \n    Args:\n        embed_dim (int): Input embedding dimension\n        block_loc (tuple): Location of block in network (layer_idx, n_block)\n        kwarg_all (dict): Dictionary of all kwargs\n        output_dim (int): Output dimension\n        low_rank_dim (Optional[int]): Dimension for LoRA projection. If None, uses standard linear\n        device (Optional): Device to place tensors on\n        dtype (Optional): Data type for tensors\n        \n    Inputs:\n        X (Tensor): Input tensor of shape (batch_size, seq_len, embed_dim)\n        mu (Tensor): State tensor for interpolation, shape (embed_dim,) or (batch_size, seq_len, embed_dim)\n        delta (Optional[Tensor]): Time difference tensor. If None, computed from X\n        \n    Returns:\n        Tuple[Tensor, Dict]:\n            - X: Input tensor (unchanged)\n            - Dict containing:\n                - 'o': Output tensor after projection\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.gradient_checkpointing = True\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        self.compress_gate = nn.Sequential(nn.Linear(embed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.Sigmoid())\n        if low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False, **\n                self.factory_kwargs)\n        else:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False, **\n                self.factory_kwargs)\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _validate_shapes(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None):\n        \"\"\"Validate input shapes\"\"\"\n        if X.dim() != 3:\n            raise ValueError(\n                f'Expected 3D input (batch, seq, dim), got {X.dim()}D')\n        if mu.dim() not in (1, 3):\n            raise ValueError(f'Expected 1D or 3D mu tensor, got {mu.dim()}D')\n        if delta is not None and delta.shape != X.shape:\n            raise ValueError(\n                f\"Delta shape {delta.shape} doesn't match input shape {X.shape}\"\n                )\n\n    def _process_mu(self, mu: torch.Tensor, batch_size: int, seq_len: int\n        ) ->torch.Tensor:\n        \"\"\"Process mu tensor to handle both 1D and 3D inputs\"\"\"\n        if mu.dim() == 1:\n            return mu.view(1, 1, -1).expand(batch_size, seq_len, -1)\n        return mu\n\n    def _compute_chunk_size(self, seq_len: int, base_chunk_size: int=1024\n        ) ->int:\n        \"\"\"Compute chunk size that evenly divides sequence length\"\"\"\n        if seq_len <= base_chunk_size:\n            return seq_len\n        num_chunks = (seq_len + base_chunk_size - 1) // base_chunk_size\n        return seq_len // num_chunks\n\n    def _forward_chunk(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None) ->tuple:\n        \"\"\"Process a single chunk\"\"\"\n        batch_size, seq_len, _ = X.shape\n        mu = self._process_mu(mu, batch_size, seq_len)\n        if delta is None:\n            shifted = self.time_shift(X)\n            delta = shifted - X\n        compression_mask = self.compress_gate(X)\n        mu_compressed = mu * compression_mask\n        interpolated = X + delta * mu_compressed\n        output = self.linear(interpolated)\n        return X, {'o': output}\n\n    def _process_batch(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None) ->tuple:\n        \"\"\"Process input in chunks\"\"\"\n        chunk_size = self._compute_chunk_size(X.shape[1])\n        outputs = []\n        output_projs = []\n        for i in range(0, X.shape[1], chunk_size):\n            end_idx = min(i + chunk_size, X.shape[1])\n            chunk_X = X[:, i:end_idx]\n            chunk_mu = mu if mu.dim() == 1 else mu[:, i:end_idx]\n            chunk_delta = None if delta is None else delta[:, i:end_idx]\n            X_out, Z_out = self._forward_chunk(chunk_X, chunk_mu, chunk_delta)\n            outputs.append(X_out)\n            output_projs.append(Z_out['o'])\n        return torch.cat(outputs, dim=1), {'o': torch.cat(output_projs, dim=1)}\n\n    def _forward(self, X: torch.Tensor, mu: torch.Tensor, delta: Optional[\n        torch.Tensor]=None) ->tuple:\n        \"\"\"Forward pass with memory optimization\"\"\"\n        self._validate_shapes(X, mu, delta)\n        if X.shape[1] > 1024:\n            if self.gradient_checkpointing and self.training:\n\n                def custom_forward(*inputs):\n                    return self._process_batch(*inputs)\n                return torch.utils.checkpoint.checkpoint(custom_forward, X,\n                    mu, delta, use_reentrant=False, preserve_rng_state=False)\n            return self._process_batch(X, mu, delta)\n        if self.gradient_checkpointing and self.training:\n\n            def custom_forward(*inputs):\n                return self._forward_chunk(*inputs)\n            return torch.utils.checkpoint.checkpoint(custom_forward, X, mu,\n                delta, use_reentrant=False, preserve_rng_state=False)\n        return self._forward_chunk(X, mu, delta)\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if self.low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n        self.mu = nn.Parameter(torch.zeros(embed_dim, device=device, dtype=\n            dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _forward(self, X: torch.Tensor, delta: Optional[torch.Tensor]=None\n        ) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(X)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - X\n        if self.low_rank_dim is None:\n            o = self.linear(X + delta * self.mu)\n        else:\n            o = self.linear(X + delta * self.mu)[1]['o']\n        return X, {'o': o}\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LoRA(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: int, bias: Optional[bool]=True,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.bias = bias\n        self.lora = nn.Sequential(nn.Linear(embed_dim, low_rank_dim, bias=\n            False, device=device, dtype=dtype), nn.Tanh(), nn.Linear(\n            low_rank_dim, output_dim, bias=bias, device=device, dtype=dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}('\n        s += (\n            f'input_dim={self.input_dim}, low_rank_dim={self.low_rank_dim}, output_dim={self.output_dim}'\n            )\n        if not self.bias:\n            s += f', bias={self.bias}'\n        s += ')'\n        return s\n\n    def _forward(self, X, **Z):\n        return X, {'o': self.lora(X)}\n\n\nimport torch.nn.functional as F\n\n\nclass RWKV6FeedForward(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        hidden_ratio = 3.5\n        intermediate_size = int(embed_dim * hidden_ratio)\n        intermediate_size = 32 * ((intermediate_size + 32 - 1) // 32)\n        self.hidden_ratio = hidden_ratio\n        self.intermediate_size = intermediate_size\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = intermediate_size\n        self.key = LerpLinear(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.value = nn.Linear(intermediate_size, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        kwarg_all['output_dim'] = embed_dim\n        self.receptance = LerpLinear(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n        self.relu = nn.ReLU()\n\n    def _forward(self, X, **Z):\n        shifted = self.time_shift(X)\n        delta = shifted - X\n        _key = self.key(X, **{'delta': delta})[1]['o']\n        r = self.relu(_key)\n        key = r * r\n        value = self.value(key)\n        receptance = self.receptance(X, **{'delta': delta})[1]['o']\n        return receptance.sigmoid() * value\n\n\ngab_config = {'num_heads': 4, 'gate_fn': 'swish', 'proj_low_rank_dim': 32,\n    'gate_low_rank_dim': 64, 'elementwise_affine': True, 'chunk_size': 32,\n    'norm_eps': 1e-05, 'output_dim': None, 'low_rank_dim': None}\n\n\n\nautoconfig={}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "1300M": {
        "1300M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RWKV6(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RWKV6(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        norm_eps: float=1e-05, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.attn = RWKV6Attention(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.ffn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.ffn = RWKV6FeedForward(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, _ = self.attn(self.attn_norm(X), **Z)\n        X = X1 + X\n        X2, _ = self.ffn(self.ffn_norm(X), **Z)\n        X = X2 + X\n        return X\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom transformers.activations import ACT2FN\nfrom typing import Optional\n\n\nclass RWKV6Attention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        num_heads: int=4, gate_fn: str='swish', proj_low_rank_dim: int=32,\n        gate_low_rank_dim: int=64, elementwise_affine: Optional[bool]=True,\n        norm_eps: float=1e-05, chunk_size: int=32, device=None, dtype=None,\n        **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.num_heads = num_heads\n        self.proj_low_rank_dim = proj_low_rank_dim\n        self.gate_low_rank_dim = gate_low_rank_dim\n        self.chunk_size = chunk_size\n        self.key_dim = embed_dim // 2\n        self.value_dim = embed_dim\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = proj_low_rank_dim * 5\n        self.x_proj = nn.Sequential(LerpLinear(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all), nn.Tanh(), nn.Linear(\n            proj_low_rank_dim * 5, embed_dim, bias=False, device=device,\n            dtype=dtype))\n        self.x_bias = nn.Parameter(torch.zeros(5, embed_dim, device=device,\n            dtype=dtype))\n        kwarg_all['output_dim'] = self.key_dim\n        self.r_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.w_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all.pop('low_rank_dim')\n        self.k_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['output_dim'] = self.value_dim\n        self.v_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.g_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.bonus = nn.Parameter(torch.zeros(num_heads, self.head_qk_dim,\n            device=device, dtype=dtype))\n        self.g_norm = nn.LayerNorm(self.value_dim, elementwise_affine=\n            elementwise_affine, eps=norm_eps, device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        self.gate_fn = ACT2FN[gate_fn]\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        if isinstance(module, nn.Parameter):\n            nn.init.xavier_uniform_(module, gain=2 ** -2.5)\n        module._is_hf_initialized = True\n\n    def naive_chunk_rwkv6(self, q: torch.Tensor, k: torch.Tensor, v: torch.\n        Tensor, w: torch.Tensor, u: torch.Tensor, chunk_size: int=32):\n        assert q.shape[-2] % chunk_size == 0\n        orig_dtype = q.dtype\n        num_chunk = q.shape[-2] // chunk_size\n        u = u.unsqueeze(0)\n        q, k, v, w = map(lambda x: rearrange(x, 'b h (n c) d -> b h n c d',\n            c=chunk_size).float(), (q, k, v, w))\n        w_cumsum = w.cumsum(-2)\n        kw = k * (w_cumsum[..., -1, None, :] - w_cumsum).exp()\n        wkv = kw.transpose(-1, -2) @ v\n        wkv_new = torch.zeros_like(wkv)\n        for i in range(num_chunk - 1):\n            wkv_new[:, :, i + 1] = wkv_new[:, :, i].clone() * w_cumsum[:, :,\n                i, -1, :, None].exp() + wkv[:, :, i]\n        o_inter = torch.einsum('b h n d p, b h n c d -> b h n c p', wkv_new,\n            q * (w_cumsum - w).exp())\n        o_intra = torch.zeros_like(o_inter)\n        for i in range(chunk_size):\n            attn = (q[:, :, :, i, None] * k * (w_cumsum[:, :, :, i, None] -\n                w[:, :, :, i, None] - w_cumsum).exp()).sum(-1)\n            mask = (torch.arange(0, chunk_size) < i).to(attn.device)\n            attn.masked_fill_(~mask, 0)\n            intra_inter_o = (attn.unsqueeze(-1) * v).sum(-2)\n            intra_intra_o = (q[:, :, :, i] * u.unsqueeze(2) * k[:, :, :, i]\n                ).sum(-1).unsqueeze(-1) * v[:, :, :, i]\n            o_intra[:, :, :, i] = intra_inter_o + intra_intra_o\n        o = o_inter + o_intra\n        return rearrange(o, 'b h n c d -> b h (n c) d').to(orig_dtype)\n\n    def pad_input(self, X):\n        _seq_len = X.shape[-2]\n        pad_len = (X.shape[-2] + self.chunk_size - 1\n            ) // self.chunk_size * self.chunk_size - X.shape[-2]\n        return F.pad(X, (0, 0, 0, pad_len)), _seq_len\n\n    def _forward(self, X: torch.Tensor):\n        X, _seq_len = self.pad_input(X)\n        batch_size, seq_len, hidden_size = X.shape\n        last_state = None\n        if X.shape[1] == 1 and last_state is not None:\n            shifted = last_state[0].unsqueeze(1)\n        else:\n            shifted = self.time_shift(X)\n            if last_state is not None:\n                shifted[:, 0] = last_state[0]\n        delta = shifted - X\n        x = self.x_proj[0](X, **{'delta': delta})[1]['o'].view(batch_size,\n            seq_len, -1, self.proj_low_rank_dim)\n        x = torch.einsum('b l n r, h n r-> b l n h', self.x_proj[1](x),\n            self.x_proj[2].weight.view(hidden_size, 5, -1))\n        r, w, k, v, g = x.add_(self.x_bias).unbind(-2)\n        r = self.r_proj(X, **{'mu': r, 'delta': delta})[1]['o']\n        w = self.w_proj(X, **{'mu': w, 'delta': delta})[1]['o']\n        k = self.k_proj(X, **{'mu': k, 'delta': delta})[1]['o']\n        v = self.v_proj(X, **{'mu': v, 'delta': delta})[1]['o']\n        g = self.g_proj(X, **{'mu': g, 'delta': delta})[1]['o']\n        r, w, k, v = map(lambda x: rearrange(x, 'b l (h d) -> b h l d', h=\n            self.num_heads), (r, w, k, v))\n        w = -torch.exp(w)\n        u = self.bonus\n        o = self.naive_chunk_rwkv6(r, k, v, w, u, chunk_size=self.chunk_size)\n        o = rearrange(o, 'b h l d -> b l (h d)')\n        o = self.g_norm(o)\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        o = o[:, :_seq_len]\n        return o\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\nimport torch.utils.checkpoint\n\n\nclass DDLerpLinear(GAUBase):\n    \"\"\"\n    DDLerpLinear with Semantic Compression (DDLerpLinear-SC)\n    \n    This unit enhances the original DDLerpLinear with semantic compression capabilities.\n    It performs dynamic linear interpolation with content-aware state compression.\n    \n    The unit processes input X using the following steps:\n    1. Computes time-shift difference (delta)\n    2. Applies semantic compression to the state (mu)\n    3. Performs linear interpolation with compressed state\n    4. Projects through linear/LoRA layer\n    \n    Args:\n        embed_dim (int): Input embedding dimension\n        block_loc (tuple): Location of block in network (layer_idx, n_block)\n        kwarg_all (dict): Dictionary of all kwargs\n        output_dim (int): Output dimension\n        low_rank_dim (Optional[int]): Dimension for LoRA projection. If None, uses standard linear\n        device (Optional): Device to place tensors on\n        dtype (Optional): Data type for tensors\n        \n    Inputs:\n        X (Tensor): Input tensor of shape (batch_size, seq_len, embed_dim)\n        mu (Tensor): State tensor for interpolation, shape (embed_dim,) or (batch_size, seq_len, embed_dim)\n        delta (Optional[Tensor]): Time difference tensor. If None, computed from X\n        \n    Returns:\n        Tuple[Tensor, Dict]:\n            - X: Input tensor (unchanged)\n            - Dict containing:\n                - 'o': Output tensor after projection\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.gradient_checkpointing = True\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        self.compress_gate = nn.Sequential(nn.Linear(embed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.Sigmoid())\n        if low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False, **\n                self.factory_kwargs)\n        else:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False, **\n                self.factory_kwargs)\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _validate_shapes(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None):\n        \"\"\"Validate input shapes\"\"\"\n        if X.dim() != 3:\n            raise ValueError(\n                f'Expected 3D input (batch, seq, dim), got {X.dim()}D')\n        if mu.dim() not in (1, 3):\n            raise ValueError(f'Expected 1D or 3D mu tensor, got {mu.dim()}D')\n        if delta is not None and delta.shape != X.shape:\n            raise ValueError(\n                f\"Delta shape {delta.shape} doesn't match input shape {X.shape}\"\n                )\n\n    def _process_mu(self, mu: torch.Tensor, batch_size: int, seq_len: int\n        ) ->torch.Tensor:\n        \"\"\"Process mu tensor to handle both 1D and 3D inputs\"\"\"\n        if mu.dim() == 1:\n            return mu.view(1, 1, -1).expand(batch_size, seq_len, -1)\n        return mu\n\n    def _compute_chunk_size(self, seq_len: int, base_chunk_size: int=1024\n        ) ->int:\n        \"\"\"Compute chunk size that evenly divides sequence length\"\"\"\n        if seq_len <= base_chunk_size:\n            return seq_len\n        num_chunks = (seq_len + base_chunk_size - 1) // base_chunk_size\n        return seq_len // num_chunks\n\n    def _forward_chunk(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None) ->tuple:\n        \"\"\"Process a single chunk\"\"\"\n        batch_size, seq_len, _ = X.shape\n        mu = self._process_mu(mu, batch_size, seq_len)\n        if delta is None:\n            shifted = self.time_shift(X)\n            delta = shifted - X\n        compression_mask = self.compress_gate(X)\n        mu_compressed = mu * compression_mask\n        interpolated = X + delta * mu_compressed\n        output = self.linear(interpolated)\n        return X, {'o': output}\n\n    def _process_batch(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None) ->tuple:\n        \"\"\"Process input in chunks\"\"\"\n        chunk_size = self._compute_chunk_size(X.shape[1])\n        outputs = []\n        output_projs = []\n        for i in range(0, X.shape[1], chunk_size):\n            end_idx = min(i + chunk_size, X.shape[1])\n            chunk_X = X[:, i:end_idx]\n            chunk_mu = mu if mu.dim() == 1 else mu[:, i:end_idx]\n            chunk_delta = None if delta is None else delta[:, i:end_idx]\n            X_out, Z_out = self._forward_chunk(chunk_X, chunk_mu, chunk_delta)\n            outputs.append(X_out)\n            output_projs.append(Z_out['o'])\n        return torch.cat(outputs, dim=1), {'o': torch.cat(output_projs, dim=1)}\n\n    def _forward(self, X: torch.Tensor, mu: torch.Tensor, delta: Optional[\n        torch.Tensor]=None) ->tuple:\n        \"\"\"Forward pass with memory optimization\"\"\"\n        self._validate_shapes(X, mu, delta)\n        if X.shape[1] > 1024:\n            if self.gradient_checkpointing and self.training:\n\n                def custom_forward(*inputs):\n                    return self._process_batch(*inputs)\n                return torch.utils.checkpoint.checkpoint(custom_forward, X,\n                    mu, delta, use_reentrant=False, preserve_rng_state=False)\n            return self._process_batch(X, mu, delta)\n        if self.gradient_checkpointing and self.training:\n\n            def custom_forward(*inputs):\n                return self._forward_chunk(*inputs)\n            return torch.utils.checkpoint.checkpoint(custom_forward, X, mu,\n                delta, use_reentrant=False, preserve_rng_state=False)\n        return self._forward_chunk(X, mu, delta)\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if self.low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n        self.mu = nn.Parameter(torch.zeros(embed_dim, device=device, dtype=\n            dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _forward(self, X: torch.Tensor, delta: Optional[torch.Tensor]=None\n        ) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(X)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - X\n        if self.low_rank_dim is None:\n            o = self.linear(X + delta * self.mu)\n        else:\n            o = self.linear(X + delta * self.mu)[1]['o']\n        return X, {'o': o}\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LoRA(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: int, bias: Optional[bool]=True,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.bias = bias\n        self.lora = nn.Sequential(nn.Linear(embed_dim, low_rank_dim, bias=\n            False, device=device, dtype=dtype), nn.Tanh(), nn.Linear(\n            low_rank_dim, output_dim, bias=bias, device=device, dtype=dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}('\n        s += (\n            f'input_dim={self.input_dim}, low_rank_dim={self.low_rank_dim}, output_dim={self.output_dim}'\n            )\n        if not self.bias:\n            s += f', bias={self.bias}'\n        s += ')'\n        return s\n\n    def _forward(self, X, **Z):\n        return X, {'o': self.lora(X)}\n\n\nimport torch.nn.functional as F\n\n\nclass RWKV6FeedForward(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        hidden_ratio = 3.5\n        intermediate_size = int(embed_dim * hidden_ratio)\n        intermediate_size = 32 * ((intermediate_size + 32 - 1) // 32)\n        self.hidden_ratio = hidden_ratio\n        self.intermediate_size = intermediate_size\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = intermediate_size\n        self.key = LerpLinear(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.value = nn.Linear(intermediate_size, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        kwarg_all['output_dim'] = embed_dim\n        self.receptance = LerpLinear(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n        self.relu = nn.ReLU()\n\n    def _forward(self, X, **Z):\n        shifted = self.time_shift(X)\n        delta = shifted - X\n        _key = self.key(X, **{'delta': delta})[1]['o']\n        r = self.relu(_key)\n        key = r * r\n        value = self.value(key)\n        receptance = self.receptance(X, **{'delta': delta})[1]['o']\n        return receptance.sigmoid() * value\n\n\ngab_config = {'num_heads': 4, 'gate_fn': 'swish', 'proj_low_rank_dim': 32,\n    'gate_low_rank_dim': 64, 'elementwise_affine': True, 'chunk_size': 32,\n    'norm_eps': 1e-05, 'output_dim': None, 'low_rank_dim': None}\n\n\n\nautoconfig={}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "125M": {
        "125M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RWKV6(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RWKV6(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        norm_eps: float=1e-05, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.attn = RWKV6Attention(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.ffn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.ffn = RWKV6FeedForward(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, _ = self.attn(self.attn_norm(X), **Z)\n        X = X1 + X\n        X2, _ = self.ffn(self.ffn_norm(X), **Z)\n        X = X2 + X\n        return X\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom transformers.activations import ACT2FN\nfrom typing import Optional\n\n\nclass RWKV6Attention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        num_heads: int=4, gate_fn: str='swish', proj_low_rank_dim: int=32,\n        gate_low_rank_dim: int=64, elementwise_affine: Optional[bool]=True,\n        norm_eps: float=1e-05, chunk_size: int=32, device=None, dtype=None,\n        **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.num_heads = num_heads\n        self.proj_low_rank_dim = proj_low_rank_dim\n        self.gate_low_rank_dim = gate_low_rank_dim\n        self.chunk_size = chunk_size\n        self.key_dim = embed_dim // 2\n        self.value_dim = embed_dim\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = proj_low_rank_dim * 5\n        self.x_proj = nn.Sequential(LerpLinear(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all), nn.Tanh(), nn.Linear(\n            proj_low_rank_dim * 5, embed_dim, bias=False, device=device,\n            dtype=dtype))\n        self.x_bias = nn.Parameter(torch.zeros(5, embed_dim, device=device,\n            dtype=dtype))\n        kwarg_all['output_dim'] = self.key_dim\n        self.r_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.w_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all.pop('low_rank_dim')\n        self.k_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['output_dim'] = self.value_dim\n        self.v_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.g_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.bonus = nn.Parameter(torch.zeros(num_heads, self.head_qk_dim,\n            device=device, dtype=dtype))\n        self.g_norm = nn.LayerNorm(self.value_dim, elementwise_affine=\n            elementwise_affine, eps=norm_eps, device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        self.gate_fn = ACT2FN[gate_fn]\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        if isinstance(module, nn.Parameter):\n            nn.init.xavier_uniform_(module, gain=2 ** -2.5)\n        module._is_hf_initialized = True\n\n    def naive_chunk_rwkv6(self, q: torch.Tensor, k: torch.Tensor, v: torch.\n        Tensor, w: torch.Tensor, u: torch.Tensor, chunk_size: int=32):\n        assert q.shape[-2] % chunk_size == 0\n        orig_dtype = q.dtype\n        num_chunk = q.shape[-2] // chunk_size\n        u = u.unsqueeze(0)\n        q, k, v, w = map(lambda x: rearrange(x, 'b h (n c) d -> b h n c d',\n            c=chunk_size).float(), (q, k, v, w))\n        w_cumsum = w.cumsum(-2)\n        kw = k * (w_cumsum[..., -1, None, :] - w_cumsum).exp()\n        wkv = kw.transpose(-1, -2) @ v\n        wkv_new = torch.zeros_like(wkv)\n        for i in range(num_chunk - 1):\n            wkv_new[:, :, i + 1] = wkv_new[:, :, i].clone() * w_cumsum[:, :,\n                i, -1, :, None].exp() + wkv[:, :, i]\n        o_inter = torch.einsum('b h n d p, b h n c d -> b h n c p', wkv_new,\n            q * (w_cumsum - w).exp())\n        o_intra = torch.zeros_like(o_inter)\n        for i in range(chunk_size):\n            attn = (q[:, :, :, i, None] * k * (w_cumsum[:, :, :, i, None] -\n                w[:, :, :, i, None] - w_cumsum).exp()).sum(-1)\n            mask = (torch.arange(0, chunk_size) < i).to(attn.device)\n            attn.masked_fill_(~mask, 0)\n            intra_inter_o = (attn.unsqueeze(-1) * v).sum(-2)\n            intra_intra_o = (q[:, :, :, i] * u.unsqueeze(2) * k[:, :, :, i]\n                ).sum(-1).unsqueeze(-1) * v[:, :, :, i]\n            o_intra[:, :, :, i] = intra_inter_o + intra_intra_o\n        o = o_inter + o_intra\n        return rearrange(o, 'b h n c d -> b h (n c) d').to(orig_dtype)\n\n    def pad_input(self, X):\n        _seq_len = X.shape[-2]\n        pad_len = (X.shape[-2] + self.chunk_size - 1\n            ) // self.chunk_size * self.chunk_size - X.shape[-2]\n        return F.pad(X, (0, 0, 0, pad_len)), _seq_len\n\n    def _forward(self, X: torch.Tensor):\n        X, _seq_len = self.pad_input(X)\n        batch_size, seq_len, hidden_size = X.shape\n        last_state = None\n        if X.shape[1] == 1 and last_state is not None:\n            shifted = last_state[0].unsqueeze(1)\n        else:\n            shifted = self.time_shift(X)\n            if last_state is not None:\n                shifted[:, 0] = last_state[0]\n        delta = shifted - X\n        x = self.x_proj[0](X, **{'delta': delta})[1]['o'].view(batch_size,\n            seq_len, -1, self.proj_low_rank_dim)\n        x = torch.einsum('b l n r, h n r-> b l n h', self.x_proj[1](x),\n            self.x_proj[2].weight.view(hidden_size, 5, -1))\n        r, w, k, v, g = x.add_(self.x_bias).unbind(-2)\n        r = self.r_proj(X, **{'mu': r, 'delta': delta})[1]['o']\n        w = self.w_proj(X, **{'mu': w, 'delta': delta})[1]['o']\n        k = self.k_proj(X, **{'mu': k, 'delta': delta})[1]['o']\n        v = self.v_proj(X, **{'mu': v, 'delta': delta})[1]['o']\n        g = self.g_proj(X, **{'mu': g, 'delta': delta})[1]['o']\n        r, w, k, v = map(lambda x: rearrange(x, 'b l (h d) -> b h l d', h=\n            self.num_heads), (r, w, k, v))\n        w = -torch.exp(w)\n        u = self.bonus\n        o = self.naive_chunk_rwkv6(r, k, v, w, u, chunk_size=self.chunk_size)\n        o = rearrange(o, 'b h l d -> b l (h d)')\n        o = self.g_norm(o)\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        o = o[:, :_seq_len]\n        return o\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\nimport torch.utils.checkpoint\n\n\nclass DDLerpLinear(GAUBase):\n    \"\"\"\n    DDLerpLinear with Semantic Compression (DDLerpLinear-SC)\n    \n    This unit enhances the original DDLerpLinear with semantic compression capabilities.\n    It performs dynamic linear interpolation with content-aware state compression.\n    \n    The unit processes input X using the following steps:\n    1. Computes time-shift difference (delta)\n    2. Applies semantic compression to the state (mu)\n    3. Performs linear interpolation with compressed state\n    4. Projects through linear/LoRA layer\n    \n    Args:\n        embed_dim (int): Input embedding dimension\n        block_loc (tuple): Location of block in network (layer_idx, n_block)\n        kwarg_all (dict): Dictionary of all kwargs\n        output_dim (int): Output dimension\n        low_rank_dim (Optional[int]): Dimension for LoRA projection. If None, uses standard linear\n        device (Optional): Device to place tensors on\n        dtype (Optional): Data type for tensors\n        \n    Inputs:\n        X (Tensor): Input tensor of shape (batch_size, seq_len, embed_dim)\n        mu (Tensor): State tensor for interpolation, shape (embed_dim,) or (batch_size, seq_len, embed_dim)\n        delta (Optional[Tensor]): Time difference tensor. If None, computed from X\n        \n    Returns:\n        Tuple[Tensor, Dict]:\n            - X: Input tensor (unchanged)\n            - Dict containing:\n                - 'o': Output tensor after projection\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.gradient_checkpointing = True\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        self.compress_gate = nn.Sequential(nn.Linear(embed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.Sigmoid())\n        if low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False, **\n                self.factory_kwargs)\n        else:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False, **\n                self.factory_kwargs)\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _validate_shapes(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None):\n        \"\"\"Validate input shapes\"\"\"\n        if X.dim() != 3:\n            raise ValueError(\n                f'Expected 3D input (batch, seq, dim), got {X.dim()}D')\n        if mu.dim() not in (1, 3):\n            raise ValueError(f'Expected 1D or 3D mu tensor, got {mu.dim()}D')\n        if delta is not None and delta.shape != X.shape:\n            raise ValueError(\n                f\"Delta shape {delta.shape} doesn't match input shape {X.shape}\"\n                )\n\n    def _process_mu(self, mu: torch.Tensor, batch_size: int, seq_len: int\n        ) ->torch.Tensor:\n        \"\"\"Process mu tensor to handle both 1D and 3D inputs\"\"\"\n        if mu.dim() == 1:\n            return mu.view(1, 1, -1).expand(batch_size, seq_len, -1)\n        return mu\n\n    def _compute_chunk_size(self, seq_len: int, base_chunk_size: int=1024\n        ) ->int:\n        \"\"\"Compute chunk size that evenly divides sequence length\"\"\"\n        if seq_len <= base_chunk_size:\n            return seq_len\n        num_chunks = (seq_len + base_chunk_size - 1) // base_chunk_size\n        return seq_len // num_chunks\n\n    def _forward_chunk(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None) ->tuple:\n        \"\"\"Process a single chunk\"\"\"\n        batch_size, seq_len, _ = X.shape\n        mu = self._process_mu(mu, batch_size, seq_len)\n        if delta is None:\n            shifted = self.time_shift(X)\n            delta = shifted - X\n        compression_mask = self.compress_gate(X)\n        mu_compressed = mu * compression_mask\n        interpolated = X + delta * mu_compressed\n        output = self.linear(interpolated)\n        return X, {'o': output}\n\n    def _process_batch(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None) ->tuple:\n        \"\"\"Process input in chunks\"\"\"\n        chunk_size = self._compute_chunk_size(X.shape[1])\n        outputs = []\n        output_projs = []\n        for i in range(0, X.shape[1], chunk_size):\n            end_idx = min(i + chunk_size, X.shape[1])\n            chunk_X = X[:, i:end_idx]\n            chunk_mu = mu if mu.dim() == 1 else mu[:, i:end_idx]\n            chunk_delta = None if delta is None else delta[:, i:end_idx]\n            X_out, Z_out = self._forward_chunk(chunk_X, chunk_mu, chunk_delta)\n            outputs.append(X_out)\n            output_projs.append(Z_out['o'])\n        return torch.cat(outputs, dim=1), {'o': torch.cat(output_projs, dim=1)}\n\n    def _forward(self, X: torch.Tensor, mu: torch.Tensor, delta: Optional[\n        torch.Tensor]=None) ->tuple:\n        \"\"\"Forward pass with memory optimization\"\"\"\n        self._validate_shapes(X, mu, delta)\n        if X.shape[1] > 1024:\n            if self.gradient_checkpointing and self.training:\n\n                def custom_forward(*inputs):\n                    return self._process_batch(*inputs)\n                return torch.utils.checkpoint.checkpoint(custom_forward, X,\n                    mu, delta, use_reentrant=False, preserve_rng_state=False)\n            return self._process_batch(X, mu, delta)\n        if self.gradient_checkpointing and self.training:\n\n            def custom_forward(*inputs):\n                return self._forward_chunk(*inputs)\n            return torch.utils.checkpoint.checkpoint(custom_forward, X, mu,\n                delta, use_reentrant=False, preserve_rng_state=False)\n        return self._forward_chunk(X, mu, delta)\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if self.low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n        self.mu = nn.Parameter(torch.zeros(embed_dim, device=device, dtype=\n            dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _forward(self, X: torch.Tensor, delta: Optional[torch.Tensor]=None\n        ) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(X)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - X\n        if self.low_rank_dim is None:\n            o = self.linear(X + delta * self.mu)\n        else:\n            o = self.linear(X + delta * self.mu)[1]['o']\n        return X, {'o': o}\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LoRA(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: int, bias: Optional[bool]=True,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.bias = bias\n        self.lora = nn.Sequential(nn.Linear(embed_dim, low_rank_dim, bias=\n            False, device=device, dtype=dtype), nn.Tanh(), nn.Linear(\n            low_rank_dim, output_dim, bias=bias, device=device, dtype=dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}('\n        s += (\n            f'input_dim={self.input_dim}, low_rank_dim={self.low_rank_dim}, output_dim={self.output_dim}'\n            )\n        if not self.bias:\n            s += f', bias={self.bias}'\n        s += ')'\n        return s\n\n    def _forward(self, X, **Z):\n        return X, {'o': self.lora(X)}\n\n\nimport torch.nn.functional as F\n\n\nclass RWKV6FeedForward(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        hidden_ratio = 3.5\n        intermediate_size = int(embed_dim * hidden_ratio)\n        intermediate_size = 32 * ((intermediate_size + 32 - 1) // 32)\n        self.hidden_ratio = hidden_ratio\n        self.intermediate_size = intermediate_size\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = intermediate_size\n        self.key = LerpLinear(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.value = nn.Linear(intermediate_size, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        kwarg_all['output_dim'] = embed_dim\n        self.receptance = LerpLinear(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n        self.relu = nn.ReLU()\n\n    def _forward(self, X, **Z):\n        shifted = self.time_shift(X)\n        delta = shifted - X\n        _key = self.key(X, **{'delta': delta})[1]['o']\n        r = self.relu(_key)\n        key = r * r\n        value = self.value(key)\n        receptance = self.receptance(X, **{'delta': delta})[1]['o']\n        return receptance.sigmoid() * value\n\n\ngab_config = {'num_heads': 4, 'gate_fn': 'swish', 'proj_low_rank_dim': 32,\n    'gate_low_rank_dim': 64, 'elementwise_affine': True, 'chunk_size': 32,\n    'norm_eps': 1e-05, 'output_dim': None, 'low_rank_dim': None}\n\n\n\nautoconfig={}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "14M": {
        "14M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RWKV6(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RWKV6(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        norm_eps: float=1e-05, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.attn = RWKV6Attention(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.ffn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.ffn = RWKV6FeedForward(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, _ = self.attn(self.attn_norm(X), **Z)\n        X = X1 + X\n        X2, _ = self.ffn(self.ffn_norm(X), **Z)\n        X = X2 + X\n        return X\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom transformers.activations import ACT2FN\nfrom typing import Optional\n\n\nclass RWKV6Attention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        num_heads: int=4, gate_fn: str='swish', proj_low_rank_dim: int=32,\n        gate_low_rank_dim: int=64, elementwise_affine: Optional[bool]=True,\n        norm_eps: float=1e-05, chunk_size: int=32, device=None, dtype=None,\n        **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.num_heads = num_heads\n        self.proj_low_rank_dim = proj_low_rank_dim\n        self.gate_low_rank_dim = gate_low_rank_dim\n        self.chunk_size = chunk_size\n        self.key_dim = embed_dim // 2\n        self.value_dim = embed_dim\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = proj_low_rank_dim * 5\n        self.x_proj = nn.Sequential(LerpLinear(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all), nn.Tanh(), nn.Linear(\n            proj_low_rank_dim * 5, embed_dim, bias=False, device=device,\n            dtype=dtype))\n        self.x_bias = nn.Parameter(torch.zeros(5, embed_dim, device=device,\n            dtype=dtype))\n        kwarg_all['output_dim'] = self.key_dim\n        self.r_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.w_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all.pop('low_rank_dim')\n        self.k_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['output_dim'] = self.value_dim\n        self.v_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.g_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.bonus = nn.Parameter(torch.zeros(num_heads, self.head_qk_dim,\n            device=device, dtype=dtype))\n        self.g_norm = nn.LayerNorm(self.value_dim, elementwise_affine=\n            elementwise_affine, eps=norm_eps, device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        self.gate_fn = ACT2FN[gate_fn]\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        if isinstance(module, nn.Parameter):\n            nn.init.xavier_uniform_(module, gain=2 ** -2.5)\n        module._is_hf_initialized = True\n\n    def naive_chunk_rwkv6(self, q: torch.Tensor, k: torch.Tensor, v: torch.\n        Tensor, w: torch.Tensor, u: torch.Tensor, chunk_size: int=32):\n        assert q.shape[-2] % chunk_size == 0\n        orig_dtype = q.dtype\n        num_chunk = q.shape[-2] // chunk_size\n        u = u.unsqueeze(0)\n        q, k, v, w = map(lambda x: rearrange(x, 'b h (n c) d -> b h n c d',\n            c=chunk_size).float(), (q, k, v, w))\n        w_cumsum = w.cumsum(-2)\n        kw = k * (w_cumsum[..., -1, None, :] - w_cumsum).exp()\n        wkv = kw.transpose(-1, -2) @ v\n        wkv_new = torch.zeros_like(wkv)\n        for i in range(num_chunk - 1):\n            wkv_new[:, :, i + 1] = wkv_new[:, :, i].clone() * w_cumsum[:, :,\n                i, -1, :, None].exp() + wkv[:, :, i]\n        o_inter = torch.einsum('b h n d p, b h n c d -> b h n c p', wkv_new,\n            q * (w_cumsum - w).exp())\n        o_intra = torch.zeros_like(o_inter)\n        for i in range(chunk_size):\n            attn = (q[:, :, :, i, None] * k * (w_cumsum[:, :, :, i, None] -\n                w[:, :, :, i, None] - w_cumsum).exp()).sum(-1)\n            mask = (torch.arange(0, chunk_size) < i).to(attn.device)\n            attn.masked_fill_(~mask, 0)\n            intra_inter_o = (attn.unsqueeze(-1) * v).sum(-2)\n            intra_intra_o = (q[:, :, :, i] * u.unsqueeze(2) * k[:, :, :, i]\n                ).sum(-1).unsqueeze(-1) * v[:, :, :, i]\n            o_intra[:, :, :, i] = intra_inter_o + intra_intra_o\n        o = o_inter + o_intra\n        return rearrange(o, 'b h n c d -> b h (n c) d').to(orig_dtype)\n\n    def pad_input(self, X):\n        _seq_len = X.shape[-2]\n        pad_len = (X.shape[-2] + self.chunk_size - 1\n            ) // self.chunk_size * self.chunk_size - X.shape[-2]\n        return F.pad(X, (0, 0, 0, pad_len)), _seq_len\n\n    def _forward(self, X: torch.Tensor):\n        X, _seq_len = self.pad_input(X)\n        batch_size, seq_len, hidden_size = X.shape\n        last_state = None\n        if X.shape[1] == 1 and last_state is not None:\n            shifted = last_state[0].unsqueeze(1)\n        else:\n            shifted = self.time_shift(X)\n            if last_state is not None:\n                shifted[:, 0] = last_state[0]\n        delta = shifted - X\n        x = self.x_proj[0](X, **{'delta': delta})[1]['o'].view(batch_size,\n            seq_len, -1, self.proj_low_rank_dim)\n        x = torch.einsum('b l n r, h n r-> b l n h', self.x_proj[1](x),\n            self.x_proj[2].weight.view(hidden_size, 5, -1))\n        r, w, k, v, g = x.add_(self.x_bias).unbind(-2)\n        r = self.r_proj(X, **{'mu': r, 'delta': delta})[1]['o']\n        w = self.w_proj(X, **{'mu': w, 'delta': delta})[1]['o']\n        k = self.k_proj(X, **{'mu': k, 'delta': delta})[1]['o']\n        v = self.v_proj(X, **{'mu': v, 'delta': delta})[1]['o']\n        g = self.g_proj(X, **{'mu': g, 'delta': delta})[1]['o']\n        r, w, k, v = map(lambda x: rearrange(x, 'b l (h d) -> b h l d', h=\n            self.num_heads), (r, w, k, v))\n        w = -torch.exp(w)\n        u = self.bonus\n        o = self.naive_chunk_rwkv6(r, k, v, w, u, chunk_size=self.chunk_size)\n        o = rearrange(o, 'b h l d -> b l (h d)')\n        o = self.g_norm(o)\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        o = o[:, :_seq_len]\n        return o\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\nimport torch.utils.checkpoint\n\n\nclass DDLerpLinear(GAUBase):\n    \"\"\"\n    DDLerpLinear with Semantic Compression (DDLerpLinear-SC)\n    \n    This unit enhances the original DDLerpLinear with semantic compression capabilities.\n    It performs dynamic linear interpolation with content-aware state compression.\n    \n    The unit processes input X using the following steps:\n    1. Computes time-shift difference (delta)\n    2. Applies semantic compression to the state (mu)\n    3. Performs linear interpolation with compressed state\n    4. Projects through linear/LoRA layer\n    \n    Args:\n        embed_dim (int): Input embedding dimension\n        block_loc (tuple): Location of block in network (layer_idx, n_block)\n        kwarg_all (dict): Dictionary of all kwargs\n        output_dim (int): Output dimension\n        low_rank_dim (Optional[int]): Dimension for LoRA projection. If None, uses standard linear\n        device (Optional): Device to place tensors on\n        dtype (Optional): Data type for tensors\n        \n    Inputs:\n        X (Tensor): Input tensor of shape (batch_size, seq_len, embed_dim)\n        mu (Tensor): State tensor for interpolation, shape (embed_dim,) or (batch_size, seq_len, embed_dim)\n        delta (Optional[Tensor]): Time difference tensor. If None, computed from X\n        \n    Returns:\n        Tuple[Tensor, Dict]:\n            - X: Input tensor (unchanged)\n            - Dict containing:\n                - 'o': Output tensor after projection\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.gradient_checkpointing = True\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        self.compress_gate = nn.Sequential(nn.Linear(embed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.Sigmoid())\n        if low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False, **\n                self.factory_kwargs)\n        else:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False, **\n                self.factory_kwargs)\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _validate_shapes(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None):\n        \"\"\"Validate input shapes\"\"\"\n        if X.dim() != 3:\n            raise ValueError(\n                f'Expected 3D input (batch, seq, dim), got {X.dim()}D')\n        if mu.dim() not in (1, 3):\n            raise ValueError(f'Expected 1D or 3D mu tensor, got {mu.dim()}D')\n        if delta is not None and delta.shape != X.shape:\n            raise ValueError(\n                f\"Delta shape {delta.shape} doesn't match input shape {X.shape}\"\n                )\n\n    def _process_mu(self, mu: torch.Tensor, batch_size: int, seq_len: int\n        ) ->torch.Tensor:\n        \"\"\"Process mu tensor to handle both 1D and 3D inputs\"\"\"\n        if mu.dim() == 1:\n            return mu.view(1, 1, -1).expand(batch_size, seq_len, -1)\n        return mu\n\n    def _compute_chunk_size(self, seq_len: int, base_chunk_size: int=1024\n        ) ->int:\n        \"\"\"Compute chunk size that evenly divides sequence length\"\"\"\n        if seq_len <= base_chunk_size:\n            return seq_len\n        num_chunks = (seq_len + base_chunk_size - 1) // base_chunk_size\n        return seq_len // num_chunks\n\n    def _forward_chunk(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None) ->tuple:\n        \"\"\"Process a single chunk\"\"\"\n        batch_size, seq_len, _ = X.shape\n        mu = self._process_mu(mu, batch_size, seq_len)\n        if delta is None:\n            shifted = self.time_shift(X)\n            delta = shifted - X\n        compression_mask = self.compress_gate(X)\n        mu_compressed = mu * compression_mask\n        interpolated = X + delta * mu_compressed\n        output = self.linear(interpolated)\n        return X, {'o': output}\n\n    def _process_batch(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None) ->tuple:\n        \"\"\"Process input in chunks\"\"\"\n        chunk_size = self._compute_chunk_size(X.shape[1])\n        outputs = []\n        output_projs = []\n        for i in range(0, X.shape[1], chunk_size):\n            end_idx = min(i + chunk_size, X.shape[1])\n            chunk_X = X[:, i:end_idx]\n            chunk_mu = mu if mu.dim() == 1 else mu[:, i:end_idx]\n            chunk_delta = None if delta is None else delta[:, i:end_idx]\n            X_out, Z_out = self._forward_chunk(chunk_X, chunk_mu, chunk_delta)\n            outputs.append(X_out)\n            output_projs.append(Z_out['o'])\n        return torch.cat(outputs, dim=1), {'o': torch.cat(output_projs, dim=1)}\n\n    def _forward(self, X: torch.Tensor, mu: torch.Tensor, delta: Optional[\n        torch.Tensor]=None) ->tuple:\n        \"\"\"Forward pass with memory optimization\"\"\"\n        self._validate_shapes(X, mu, delta)\n        if X.shape[1] > 1024:\n            if self.gradient_checkpointing and self.training:\n\n                def custom_forward(*inputs):\n                    return self._process_batch(*inputs)\n                return torch.utils.checkpoint.checkpoint(custom_forward, X,\n                    mu, delta, use_reentrant=False, preserve_rng_state=False)\n            return self._process_batch(X, mu, delta)\n        if self.gradient_checkpointing and self.training:\n\n            def custom_forward(*inputs):\n                return self._forward_chunk(*inputs)\n            return torch.utils.checkpoint.checkpoint(custom_forward, X, mu,\n                delta, use_reentrant=False, preserve_rng_state=False)\n        return self._forward_chunk(X, mu, delta)\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if self.low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n        self.mu = nn.Parameter(torch.zeros(embed_dim, device=device, dtype=\n            dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _forward(self, X: torch.Tensor, delta: Optional[torch.Tensor]=None\n        ) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(X)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - X\n        if self.low_rank_dim is None:\n            o = self.linear(X + delta * self.mu)\n        else:\n            o = self.linear(X + delta * self.mu)[1]['o']\n        return X, {'o': o}\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LoRA(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: int, bias: Optional[bool]=True,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.bias = bias\n        self.lora = nn.Sequential(nn.Linear(embed_dim, low_rank_dim, bias=\n            False, device=device, dtype=dtype), nn.Tanh(), nn.Linear(\n            low_rank_dim, output_dim, bias=bias, device=device, dtype=dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}('\n        s += (\n            f'input_dim={self.input_dim}, low_rank_dim={self.low_rank_dim}, output_dim={self.output_dim}'\n            )\n        if not self.bias:\n            s += f', bias={self.bias}'\n        s += ')'\n        return s\n\n    def _forward(self, X, **Z):\n        return X, {'o': self.lora(X)}\n\n\nimport torch.nn.functional as F\n\n\nclass RWKV6FeedForward(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        hidden_ratio = 3.5\n        intermediate_size = int(embed_dim * hidden_ratio)\n        intermediate_size = 32 * ((intermediate_size + 32 - 1) // 32)\n        self.hidden_ratio = hidden_ratio\n        self.intermediate_size = intermediate_size\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = intermediate_size\n        self.key = LerpLinear(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.value = nn.Linear(intermediate_size, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        kwarg_all['output_dim'] = embed_dim\n        self.receptance = LerpLinear(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n        self.relu = nn.ReLU()\n\n    def _forward(self, X, **Z):\n        shifted = self.time_shift(X)\n        delta = shifted - X\n        _key = self.key(X, **{'delta': delta})[1]['o']\n        r = self.relu(_key)\n        key = r * r\n        value = self.value(key)\n        receptance = self.receptance(X, **{'delta': delta})[1]['o']\n        return receptance.sigmoid() * value\n\n\ngab_config = {'num_heads': 4, 'gate_fn': 'swish', 'proj_low_rank_dim': 32,\n    'gate_low_rank_dim': 64, 'elementwise_affine': True, 'chunk_size': 32,\n    'norm_eps': 1e-05, 'output_dim': None, 'low_rank_dim': None}\n\n\n\nautoconfig={}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    },
    "350M": {
        "350M": "import torch\nimport torch.nn as nn\nfrom model_discovery.model.utils.modules import GABBase\n\n\nclass GAB(GABBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, device=None, dtype\n        =None, **kwargs):\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc)\n        self.root = RWKV6(embed_dim=embed_dim, block_loc=block_loc,\n            kwarg_all=kwargs, **factory_kwargs, **kwargs)\n\n    def _forward(self, X, **Z):\n        X, Z = self.root(X, **Z)\n        return X, Z\n\n\nimport torch.nn.functional as F\nfrom model_discovery.model.utils.modules import GAUBase, gau_test, UnitDecl\n\n\nclass RWKV6(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        norm_eps: float=1e-05, device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.attn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.attn = RWKV6Attention(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.ffn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=\n            norm_eps, **self.factory_kwargs)\n        self.ffn = RWKV6FeedForward(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n\n    def _forward(self, X, **Z):\n        X1, _ = self.attn(self.attn_norm(X), **Z)\n        X = X1 + X\n        X2, _ = self.ffn(self.ffn_norm(X), **Z)\n        X = X2 + X\n        return X\n\n\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom transformers.activations import ACT2FN\nfrom typing import Optional\n\n\nclass RWKV6Attention(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        num_heads: int=4, gate_fn: str='swish', proj_low_rank_dim: int=32,\n        gate_low_rank_dim: int=64, elementwise_affine: Optional[bool]=True,\n        norm_eps: float=1e-05, chunk_size: int=32, device=None, dtype=None,\n        **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        self.num_heads = num_heads\n        self.proj_low_rank_dim = proj_low_rank_dim\n        self.gate_low_rank_dim = gate_low_rank_dim\n        self.chunk_size = chunk_size\n        self.key_dim = embed_dim // 2\n        self.value_dim = embed_dim\n        assert self.key_dim % num_heads == 0, f'key dim must be divisible by num_heads of {num_heads}'\n        assert self.value_dim % num_heads == 0, f'value dim must be divisible by num_heads of {num_heads}'\n        self.head_qk_dim = self.key_dim // num_heads\n        self.head_v_dim = self.value_dim // num_heads\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = proj_low_rank_dim * 5\n        self.x_proj = nn.Sequential(LerpLinear(embed_dim=self.embed_dim,\n            block_loc=self.block_loc, kwarg_all=self.kwarg_all, **self.\n            factory_kwargs, **self.kwarg_all), nn.Tanh(), nn.Linear(\n            proj_low_rank_dim * 5, embed_dim, bias=False, device=device,\n            dtype=dtype))\n        self.x_bias = nn.Parameter(torch.zeros(5, embed_dim, device=device,\n            dtype=dtype))\n        kwarg_all['output_dim'] = self.key_dim\n        self.r_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.w_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all.pop('low_rank_dim')\n        self.k_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['output_dim'] = self.value_dim\n        self.v_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        kwarg_all['low_rank_dim'] = gate_low_rank_dim\n        self.g_proj = DDLerpLinear(embed_dim=self.embed_dim, block_loc=self\n            .block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.bonus = nn.Parameter(torch.zeros(num_heads, self.head_qk_dim,\n            device=device, dtype=dtype))\n        self.g_norm = nn.LayerNorm(self.value_dim, elementwise_affine=\n            elementwise_affine, eps=norm_eps, device=device, dtype=dtype)\n        self.o_proj = nn.Linear(self.value_dim, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        self.gate_fn = ACT2FN[gate_fn]\n        self.apply(self._initialize_weights)\n\n    def _initialize_weights(self, module: nn.Module):\n        if getattr(module, '_is_hf_initialized', False):\n            return\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        if isinstance(module, nn.Parameter):\n            nn.init.xavier_uniform_(module, gain=2 ** -2.5)\n        module._is_hf_initialized = True\n\n    def naive_chunk_rwkv6(self, q: torch.Tensor, k: torch.Tensor, v: torch.\n        Tensor, w: torch.Tensor, u: torch.Tensor, chunk_size: int=32):\n        assert q.shape[-2] % chunk_size == 0\n        orig_dtype = q.dtype\n        num_chunk = q.shape[-2] // chunk_size\n        u = u.unsqueeze(0)\n        q, k, v, w = map(lambda x: rearrange(x, 'b h (n c) d -> b h n c d',\n            c=chunk_size).float(), (q, k, v, w))\n        w_cumsum = w.cumsum(-2)\n        kw = k * (w_cumsum[..., -1, None, :] - w_cumsum).exp()\n        wkv = kw.transpose(-1, -2) @ v\n        wkv_new = torch.zeros_like(wkv)\n        for i in range(num_chunk - 1):\n            wkv_new[:, :, i + 1] = wkv_new[:, :, i].clone() * w_cumsum[:, :,\n                i, -1, :, None].exp() + wkv[:, :, i]\n        o_inter = torch.einsum('b h n d p, b h n c d -> b h n c p', wkv_new,\n            q * (w_cumsum - w).exp())\n        o_intra = torch.zeros_like(o_inter)\n        for i in range(chunk_size):\n            attn = (q[:, :, :, i, None] * k * (w_cumsum[:, :, :, i, None] -\n                w[:, :, :, i, None] - w_cumsum).exp()).sum(-1)\n            mask = (torch.arange(0, chunk_size) < i).to(attn.device)\n            attn.masked_fill_(~mask, 0)\n            intra_inter_o = (attn.unsqueeze(-1) * v).sum(-2)\n            intra_intra_o = (q[:, :, :, i] * u.unsqueeze(2) * k[:, :, :, i]\n                ).sum(-1).unsqueeze(-1) * v[:, :, :, i]\n            o_intra[:, :, :, i] = intra_inter_o + intra_intra_o\n        o = o_inter + o_intra\n        return rearrange(o, 'b h n c d -> b h (n c) d').to(orig_dtype)\n\n    def pad_input(self, X):\n        _seq_len = X.shape[-2]\n        pad_len = (X.shape[-2] + self.chunk_size - 1\n            ) // self.chunk_size * self.chunk_size - X.shape[-2]\n        return F.pad(X, (0, 0, 0, pad_len)), _seq_len\n\n    def _forward(self, X: torch.Tensor):\n        X, _seq_len = self.pad_input(X)\n        batch_size, seq_len, hidden_size = X.shape\n        last_state = None\n        if X.shape[1] == 1 and last_state is not None:\n            shifted = last_state[0].unsqueeze(1)\n        else:\n            shifted = self.time_shift(X)\n            if last_state is not None:\n                shifted[:, 0] = last_state[0]\n        delta = shifted - X\n        x = self.x_proj[0](X, **{'delta': delta})[1]['o'].view(batch_size,\n            seq_len, -1, self.proj_low_rank_dim)\n        x = torch.einsum('b l n r, h n r-> b l n h', self.x_proj[1](x),\n            self.x_proj[2].weight.view(hidden_size, 5, -1))\n        r, w, k, v, g = x.add_(self.x_bias).unbind(-2)\n        r = self.r_proj(X, **{'mu': r, 'delta': delta})[1]['o']\n        w = self.w_proj(X, **{'mu': w, 'delta': delta})[1]['o']\n        k = self.k_proj(X, **{'mu': k, 'delta': delta})[1]['o']\n        v = self.v_proj(X, **{'mu': v, 'delta': delta})[1]['o']\n        g = self.g_proj(X, **{'mu': g, 'delta': delta})[1]['o']\n        r, w, k, v = map(lambda x: rearrange(x, 'b l (h d) -> b h l d', h=\n            self.num_heads), (r, w, k, v))\n        w = -torch.exp(w)\n        u = self.bonus\n        o = self.naive_chunk_rwkv6(r, k, v, w, u, chunk_size=self.chunk_size)\n        o = rearrange(o, 'b h l d -> b l (h d)')\n        o = self.g_norm(o)\n        o = o * self.gate_fn(g)\n        o = self.o_proj(o)\n        o = o[:, :_seq_len]\n        return o\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\nimport torch.utils.checkpoint\n\n\nclass DDLerpLinear(GAUBase):\n    \"\"\"\n    DDLerpLinear with Semantic Compression (DDLerpLinear-SC)\n    \n    This unit enhances the original DDLerpLinear with semantic compression capabilities.\n    It performs dynamic linear interpolation with content-aware state compression.\n    \n    The unit processes input X using the following steps:\n    1. Computes time-shift difference (delta)\n    2. Applies semantic compression to the state (mu)\n    3. Performs linear interpolation with compressed state\n    4. Projects through linear/LoRA layer\n    \n    Args:\n        embed_dim (int): Input embedding dimension\n        block_loc (tuple): Location of block in network (layer_idx, n_block)\n        kwarg_all (dict): Dictionary of all kwargs\n        output_dim (int): Output dimension\n        low_rank_dim (Optional[int]): Dimension for LoRA projection. If None, uses standard linear\n        device (Optional): Device to place tensors on\n        dtype (Optional): Data type for tensors\n        \n    Inputs:\n        X (Tensor): Input tensor of shape (batch_size, seq_len, embed_dim)\n        mu (Tensor): State tensor for interpolation, shape (embed_dim,) or (batch_size, seq_len, embed_dim)\n        delta (Optional[Tensor]): Time difference tensor. If None, computed from X\n        \n    Returns:\n        Tuple[Tensor, Dict]:\n            - X: Input tensor (unchanged)\n            - Dict containing:\n                - 'o': Output tensor after projection\n    \"\"\"\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.gradient_checkpointing = True\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        self.compress_gate = nn.Sequential(nn.Linear(embed_dim, embed_dim,\n            bias=False, **self.factory_kwargs), nn.Sigmoid())\n        if low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False, **\n                self.factory_kwargs)\n        else:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False, **\n                self.factory_kwargs)\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _validate_shapes(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None):\n        \"\"\"Validate input shapes\"\"\"\n        if X.dim() != 3:\n            raise ValueError(\n                f'Expected 3D input (batch, seq, dim), got {X.dim()}D')\n        if mu.dim() not in (1, 3):\n            raise ValueError(f'Expected 1D or 3D mu tensor, got {mu.dim()}D')\n        if delta is not None and delta.shape != X.shape:\n            raise ValueError(\n                f\"Delta shape {delta.shape} doesn't match input shape {X.shape}\"\n                )\n\n    def _process_mu(self, mu: torch.Tensor, batch_size: int, seq_len: int\n        ) ->torch.Tensor:\n        \"\"\"Process mu tensor to handle both 1D and 3D inputs\"\"\"\n        if mu.dim() == 1:\n            return mu.view(1, 1, -1).expand(batch_size, seq_len, -1)\n        return mu\n\n    def _compute_chunk_size(self, seq_len: int, base_chunk_size: int=1024\n        ) ->int:\n        \"\"\"Compute chunk size that evenly divides sequence length\"\"\"\n        if seq_len <= base_chunk_size:\n            return seq_len\n        num_chunks = (seq_len + base_chunk_size - 1) // base_chunk_size\n        return seq_len // num_chunks\n\n    def _forward_chunk(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None) ->tuple:\n        \"\"\"Process a single chunk\"\"\"\n        batch_size, seq_len, _ = X.shape\n        mu = self._process_mu(mu, batch_size, seq_len)\n        if delta is None:\n            shifted = self.time_shift(X)\n            delta = shifted - X\n        compression_mask = self.compress_gate(X)\n        mu_compressed = mu * compression_mask\n        interpolated = X + delta * mu_compressed\n        output = self.linear(interpolated)\n        return X, {'o': output}\n\n    def _process_batch(self, X: torch.Tensor, mu: torch.Tensor, delta:\n        Optional[torch.Tensor]=None) ->tuple:\n        \"\"\"Process input in chunks\"\"\"\n        chunk_size = self._compute_chunk_size(X.shape[1])\n        outputs = []\n        output_projs = []\n        for i in range(0, X.shape[1], chunk_size):\n            end_idx = min(i + chunk_size, X.shape[1])\n            chunk_X = X[:, i:end_idx]\n            chunk_mu = mu if mu.dim() == 1 else mu[:, i:end_idx]\n            chunk_delta = None if delta is None else delta[:, i:end_idx]\n            X_out, Z_out = self._forward_chunk(chunk_X, chunk_mu, chunk_delta)\n            outputs.append(X_out)\n            output_projs.append(Z_out['o'])\n        return torch.cat(outputs, dim=1), {'o': torch.cat(output_projs, dim=1)}\n\n    def _forward(self, X: torch.Tensor, mu: torch.Tensor, delta: Optional[\n        torch.Tensor]=None) ->tuple:\n        \"\"\"Forward pass with memory optimization\"\"\"\n        self._validate_shapes(X, mu, delta)\n        if X.shape[1] > 1024:\n            if self.gradient_checkpointing and self.training:\n\n                def custom_forward(*inputs):\n                    return self._process_batch(*inputs)\n                return torch.utils.checkpoint.checkpoint(custom_forward, X,\n                    mu, delta, use_reentrant=False, preserve_rng_state=False)\n            return self._process_batch(X, mu, delta)\n        if self.gradient_checkpointing and self.training:\n\n            def custom_forward(*inputs):\n                return self._forward_chunk(*inputs)\n            return torch.utils.checkpoint.checkpoint(custom_forward, X, mu,\n                delta, use_reentrant=False, preserve_rng_state=False)\n        return self._forward_chunk(X, mu, delta)\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LerpLinear(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: Optional[int]=None, device=None,\n        dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        if self.low_rank_dim is None:\n            self.linear = nn.Linear(embed_dim, output_dim, bias=False,\n                device=device, dtype=dtype)\n        else:\n            kwarg_all['output_dim'] = output_dim\n            kwarg_all['low_rank_dim'] = low_rank_dim\n            self.linear = LoRA(embed_dim=self.embed_dim, block_loc=self.\n                block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n                **self.kwarg_all)\n        self.mu = nn.Parameter(torch.zeros(embed_dim, device=device, dtype=\n            dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}({self.input_dim}, {self.output_dim}'\n        if self.low_rank_dim is not None:\n            s += f', low_rank_dim={self.low_rank_dim}'\n        s += ')'\n        return s\n\n    def _forward(self, X: torch.Tensor, delta: Optional[torch.Tensor]=None\n        ) ->torch.Tensor:\n        if delta is None:\n            shifted = self.time_shift(X)\n            if len(shifted.shape) == 2:\n                shifted = shifted.unsqueeze(1)\n            delta = shifted - X\n        if self.low_rank_dim is None:\n            o = self.linear(X + delta * self.mu)\n        else:\n            o = self.linear(X + delta * self.mu)[1]['o']\n        return X, {'o': o}\n\n\nimport torch.nn.functional as F\nfrom typing import Optional\n\n\nclass LoRA(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        output_dim: int, low_rank_dim: int, bias: Optional[bool]=True,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.input_dim = embed_dim\n        self.output_dim = output_dim\n        self.low_rank_dim = low_rank_dim\n        self.bias = bias\n        self.lora = nn.Sequential(nn.Linear(embed_dim, low_rank_dim, bias=\n            False, device=device, dtype=dtype), nn.Tanh(), nn.Linear(\n            low_rank_dim, output_dim, bias=bias, device=device, dtype=dtype))\n\n    def __repr__(self) ->str:\n        s = f'{self.__class__.__name__}('\n        s += (\n            f'input_dim={self.input_dim}, low_rank_dim={self.low_rank_dim}, output_dim={self.output_dim}'\n            )\n        if not self.bias:\n            s += f', bias={self.bias}'\n        s += ')'\n        return s\n\n    def _forward(self, X, **Z):\n        return X, {'o': self.lora(X)}\n\n\nimport torch.nn.functional as F\n\n\nclass RWKV6FeedForward(GAUBase):\n\n    def __init__(self, embed_dim: int, block_loc: tuple, kwarg_all: dict,\n        device=None, dtype=None, **kwargs):\n        self.factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__(embed_dim, block_loc, kwarg_all)\n        self.hidden_size = embed_dim\n        hidden_ratio = 3.5\n        intermediate_size = int(embed_dim * hidden_ratio)\n        intermediate_size = 32 * ((intermediate_size + 32 - 1) // 32)\n        self.hidden_ratio = hidden_ratio\n        self.intermediate_size = intermediate_size\n        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n        kwarg_all['output_dim'] = intermediate_size\n        self.key = LerpLinear(embed_dim=self.embed_dim, block_loc=self.\n            block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs, **\n            self.kwarg_all)\n        self.value = nn.Linear(intermediate_size, embed_dim, bias=False,\n            device=device, dtype=dtype)\n        kwarg_all['output_dim'] = embed_dim\n        self.receptance = LerpLinear(embed_dim=self.embed_dim, block_loc=\n            self.block_loc, kwarg_all=self.kwarg_all, **self.factory_kwargs,\n            **self.kwarg_all)\n        self.relu = nn.ReLU()\n\n    def _forward(self, X, **Z):\n        shifted = self.time_shift(X)\n        delta = shifted - X\n        _key = self.key(X, **{'delta': delta})[1]['o']\n        r = self.relu(_key)\n        key = r * r\n        value = self.value(key)\n        receptance = self.receptance(X, **{'delta': delta})[1]['o']\n        return receptance.sigmoid() * value\n\n\ngab_config = {'num_heads': 4, 'gate_fn': 'swish', 'proj_low_rank_dim': 32,\n    'gate_low_rank_dim': 64, 'elementwise_affine': True, 'chunk_size': 32,\n    'norm_eps': 1e-05, 'output_dim': None, 'low_rank_dim': None}\n\n\n\nautoconfig={}\nblock_config=gab_config\nblock_config.update(autoconfig)\n\n\nfrom .block_registry import BlockRegister\n\nBlockRegister(\n    name=\"default\",\n    config=block_config\n)(GAB)"
    }
}