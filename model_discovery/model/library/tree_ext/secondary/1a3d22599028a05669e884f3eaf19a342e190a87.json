{
    "paperId": "1a3d22599028a05669e884f3eaf19a342e190a87",
    "externalIds": {
        "MAG": "2150355110",
        "DBLP": "journals/pieee/Werbos90",
        "DOI": "10.1109/5.58337",
        "CorpusId": 18470994
    },
    "title": "Backpropagation Through Time: What It Does and How to Do It",
    "abstract": "Backpropagation is now the most widely used tool in the field of artificial neural networks. At the core of backpropagation is a method for calculating derivatives exactly and efficiently in any large system made up of elementary subsystems or calculations which are represented by known, differentiable functions; thus, backpropagation has many applications which do not involve neural networks as such. This paper first reviews basic backpropagation, a simple method which is now being widely used in areas like pattern recognition and fault diagnosis. Next, it presents the basic equations for backpropagation through time, and discusses applications to areas like pattern recognition involving dynamic systems, systems identification, and control. Finally, i t describes further extensions of this method, to deal with systems other than neural networks, systems involving simultaneous equations or true recurrent networks, and other practical issues which arise with this method. Pseudocode is provided to clarify the algorithms. The chain rule for ordered derivatives-the theorem which underlies backpropagation-is briefly discussed.",
    "venue": "Proceedings of the IEEE",
    "year": 1990,
    "referenceCount": 29,
    "citationCount": 4748,
    "influentialCitationCount": 277,
    "openAccessPdf": {
        "url": "https://zenodo.org/record/1262035/files/article.pdf",
        "status": "GREEN"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper first reviews basic backpropagation, a simple method which is now being widely used in areas like pattern recognition and fault diagnosis, and describes further extensions of this method, to deal with systems other than neural networks, systems involving simultaneous equations or true recurrent networks, and other practical issues which arise with this method."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "47055692",
            "name": "P. Werbos"
        }
    ],
    "references": [
        {
            "paperId": "d656089b7465f6a23dea7f94bd46cfa1020d6d82",
            "title": "Adaptive Control Using Neural Networks"
        },
        {
            "paperId": "8be3f21ab796bd9811382b560507c1c679fae37f",
            "title": "A learning rule for asynchronous perceptrons with feedback in a combinatorial environment"
        },
        {
            "paperId": "25d9530f5a1ae0630d451d754407fc9ab7ceb4b2",
            "title": "Adaptive state representation and estimation using recurrent connectionist networks"
        },
        {
            "paperId": "b1d52187016aa943a854f8df6907d57ee0971713",
            "title": "Recent advances in numerical techniques for large scale optimization"
        },
        {
            "paperId": "590bd948e06e9d07e305fe175c2a86d751ccac2d",
            "title": "Comparing different neural network architectures for classifying handwritten digits"
        },
        {
            "paperId": "34468c0aa95a7aea212d8738ab899a69b2fc14c6",
            "title": "Learning State Space Trajectories in Recurrent Neural Networks"
        },
        {
            "paperId": "c7f9bddb6773be57ab671ebcbffcaaf039ad4cd0",
            "title": "Maximizing long-term gas industry profits in two minutes in Lotus using neural network methods"
        },
        {
            "paperId": "a1b4f13e54d6febdd3281e746af750ea993d4592",
            "title": "Backpropagation: past and future"
        },
        {
            "paperId": "d18b17417128322f86528f60d652a5b998a51409",
            "title": "GENERALIZATION OF BACKPROPAGATION TO RECURRENT AND HIGH-ORDER NETWORKS."
        },
        {
            "paperId": "f1e40283ecd4633c36c70fbc8dbb14e9a4afb37f",
            "title": "Learning Phonetic Features Using Connectionist Networks"
        },
        {
            "paperId": "319f22bd5abfd67ac15988aa5c7f705f018c3ccd",
            "title": "Learning internal representations by error propagation"
        },
        {
            "paperId": "e1053197256c6c3c0631377ec23a3f7dc1cb4781",
            "title": "Numerical methods for unconstrained optimization and nonlinear equations"
        },
        {
            "paperId": "27250b833d10ec7174c841171c5fc5e792c10a63",
            "title": "Conjugate Gradient Methods with Inexact Searches"
        },
        {
            "paperId": "8c393ec4cb7bc630d2bdd324547606daf343b76f",
            "title": "Consistency of HDP applied to a simple reinforcement learning problem"
        },
        {
            "paperId": null,
            "title": "Neural Networks for Robotics and Control"
        },
        {
            "paperId": null,
            "title": "Learning howtheworld works : Specificationsfor predictive networks in robots and brains"
        },
        {
            "paperId": "8798a360b78b97f4ff96f1aaa1176d6157e4bc5e",
            "title": "Parallelism, hierarchy, scaling in time-delay neural networks for spotting Japanese phonemes CV-syllables"
        },
        {
            "paperId": "909226ce00fbb74306da00911d48651383bf1ae8",
            "title": "Generic constraints on underspecified target trajectories"
        },
        {
            "paperId": "3c243f77e85185706abcb6f9a3b25348ad324759",
            "title": "The truck backer-upper: an example of self-learning in neural networks"
        },
        {
            "paperId": "266e07d0dd9a75b61e3632e9469993dbaf063f1c",
            "title": "Generalization of backpropagation with application to a recurrent gas market model"
        },
        {
            "paperId": null,
            "title": "\u201dLearning-logic,\u201dM"
        },
        {
            "paperId": "fa277dfe3645463a25432282563fca4891d846ea",
            "title": "Applications of advances in nonlinear sensitivity analysis"
        },
        {
            "paperId": "56623a496727d5c71491850e04512ddf4152b487",
            "title": "Beyond Regression : \"New Tools for Prediction and Analysis in the Behavioral Sciences"
        },
        {
            "paperId": null,
            "title": "Watrous connectionist recognition"
        },
        {
            "paperId": null,
            "title": "He iscurrently Program Director for Neu-roengineering and Emerging Technology Initiation at the National Science"
        },
        {
            "paperId": null,
            "title": "physics, international political economy, and economics"
        },
        {
            "paperId": null,
            "title": "Glorot , Understanding the difficulty of training deep feedforward neuralnetworks , AISTATS 2010 LeCun , Yann ; Bengio , Yoshua ; Hinton , Geoffrey ( 2015 ) . \" Deep learning \""
        },
        {
            "paperId": null,
            "title": "England, that emphasized mathematical physics, international political economy, and economics. He developed backpropagation for the Ph.D. degree in applied mathematics at Harvard"
        },
        {
            "paperId": null,
            "title": "Une procedure d \u2018 apprentissage pour reseau a seuil assymetrique"
        }
    ]
}