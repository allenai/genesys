{
    "paperId": "642c1b4a9da95ea4239708afc5929a5007a1870d",
    "externalIds": {
        "MAG": "2950159712",
        "ACL": "W18-1819",
        "ArXiv": "1803.07416",
        "DBLP": "journals/corr/abs-1803-07416",
        "CorpusId": 3988816
    },
    "title": "Tensor2Tensor for Neural Machine Translation",
    "abstract": "Tensor2Tensor is a library for deep learning models that is well-suited for neural machine translation and includes the reference implementation of the state-of-the-art Transformer model.",
    "venue": "Conference of the Association for Machine Translation in the Americas",
    "year": 2018,
    "referenceCount": 21,
    "citationCount": 509,
    "influentialCitationCount": 48,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Tensor2Tensor is a library for deep learning models that is well-suited for neural machine translation and includes the reference implementation of the state-of-the-art Transformer model."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "40348417",
            "name": "Ashish Vaswani"
        },
        {
            "authorId": "1751569",
            "name": "Samy Bengio"
        },
        {
            "authorId": "2445241",
            "name": "E. Brevdo"
        },
        {
            "authorId": "1565641737",
            "name": "Fran\u00e7ois Chollet"
        },
        {
            "authorId": "19177000",
            "name": "Aidan N. Gomez"
        },
        {
            "authorId": "2776283",
            "name": "Stephan Gouws"
        },
        {
            "authorId": "145024664",
            "name": "Llion Jones"
        },
        {
            "authorId": "40527594",
            "name": "Lukasz Kaiser"
        },
        {
            "authorId": "2583391",
            "name": "Nal Kalchbrenner"
        },
        {
            "authorId": "3877127",
            "name": "Niki Parmar"
        },
        {
            "authorId": "35474601",
            "name": "Ryan Sepassi"
        },
        {
            "authorId": "1846258",
            "name": "Noam M. Shazeer"
        },
        {
            "authorId": "39328010",
            "name": "Jakob Uszkoreit"
        }
    ],
    "references": [
        {
            "paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329",
            "title": "Image Transformer"
        },
        {
            "paperId": "3a6d4cd0768ae8768e733280d362bdb4d25924e7",
            "title": "The Reversible Residual Network: Backpropagation Without Storing Activations"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "07c4fc48ad7b7d1a417b0bb72d0ae2d4efc5aa83",
            "title": "Depthwise Separable Convolutions for Neural Machine Translation"
        },
        {
            "paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0",
            "title": "Convolutional Sequence to Sequence Learning"
        },
        {
            "paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586",
            "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"
        },
        {
            "paperId": "98445f4172659ec5e891e031d8202c102135c644",
            "title": "Neural Machine Translation in Linear Time"
        },
        {
            "paperId": "735d547fc75e0772d2a78c46a1cc5fad7da1474c",
            "title": "Can Active Memory Replace Attention?"
        },
        {
            "paperId": "5b6ec746d309b165f9f9def873a2375b6fb40f3d",
            "title": "Xception: Deep Learning with Depthwise Separable Convolutions"
        },
        {
            "paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c",
            "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"
        },
        {
            "paperId": "df0402517a7338ae28bc54acaac400de6b456a46",
            "title": "WaveNet: A Generative Model for Raw Audio"
        },
        {
            "paperId": "b60abe57bc195616063be10638c6437358c81d1e",
            "title": "Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation"
        },
        {
            "paperId": "4954fa180728932959997a4768411ff9136aac81",
            "title": "TensorFlow: A system for large-scale machine learning"
        },
        {
            "paperId": "1518039b5001f1836565215eb047526b3ac7f462",
            "title": "Neural Machine Translation of Rare Words with Subword Units"
        },
        {
            "paperId": "eb5eb891061c78f4fcbc9deb3df8bca7fd005acd",
            "title": "Encoding Source Language with Convolutional Neural Network for Machine Translation"
        },
        {
            "paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "title": "Sequence to Sequence Learning with Neural Networks"
        },
        {
            "paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "title": "Neural Machine Translation by Jointly Learning to Align and Translate"
        },
        {
            "paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e",
            "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"
        },
        {
            "paperId": "944a1cfd79dbfb6fef460360a0765ba790f4027a",
            "title": "Recurrent Continuous Translation Models"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": null,
            "title": "Device con\ufb01guration: the type, number, and location of devices. TensorFlow and Ten-sor2Tensor currently support CPU, GPU, and TPU in single and multi-device con\ufb01gu-rations"
        }
    ]
}