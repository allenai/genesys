{
    "paperId": "3d776d7a659795cbc719cf80019cae0dd6bfe69e",
    "externalIds": {
        "ArXiv": "2404.08763",
        "DBLP": "journals/corr/abs-2404-08763",
        "DOI": "10.48550/arXiv.2404.08763",
        "CorpusId": 269148546
    },
    "title": "CATS: Contextually-Aware Thresholding for Sparsity in Large Language Models",
    "abstract": "Large Language Models (LLMs) have dramatically advanced AI applications, yet their deployment remains challenging due to their immense inference costs. Recent studies ameliorate the computational costs of LLMs by increasing their activation sparsity but suffer from significant performance degradation on downstream tasks. In this work, we introduce a new framework for sparsifying the activations of base LLMs and reducing inference costs, dubbed Contextually Aware Thresholding for Sparsity (CATS). CATS is relatively simple, easy to implement, and highly effective. At the heart of our framework is a new non-linear activation function. We demonstrate that CATS can be applied to various base models, including Mistral-7B and Llama2-7B, and outperforms existing sparsification techniques in downstream task performance. More precisely, CATS-based models often achieve downstream task performance within 1-2% of their base models without any fine-tuning and even at activation sparsity levels of 50%. Furthermore, CATS-based models converge faster and display better task performance than competing techniques when fine-tuning is applied. Finally, we develop a custom GPU kernel for efficient implementation of CATS that translates the activation of sparsity of CATS to real wall-clock time speedups. Our custom kernel implementation of CATS results in a ~15% improvement in wall-clock inference latency of token generation on both Llama-7B and Mistral-7B.",
    "venue": "arXiv.org",
    "year": 2024,
    "referenceCount": 62,
    "citationCount": 3,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work introduces a new framework for sparsifying the activations of base LLMs and reducing inference costs, dubbed Contextually Aware Thresholding for Sparsity (CATS), which can be applied to various base models, and outperforms existing sparsification techniques in downstream task performance."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -2.131585121154785,
            -0.4148823022842407,
            0.7447303533554077,
            3.4061121940612793,
            0.3763044774532318,
            0.06621280312538147,
            1.3962360620498657,
            0.0745868980884552,
            -0.8673020005226135,
            -0.27986404299736023,
            -3.8768441677093506,
            4.50331974029541,
            -1.1648120880126953,
            -1.8442903757095337,
            -5.6726179122924805,
            1.4055571556091309,
            -3.362687587738037,
            0.44622674584388733,
            5.414653301239014,
            3.701951503753662,
            -3.6168432235717773,
            0.12328970432281494,
            -4.069516658782959,
            0.5761095881462097,
            -0.6120167374610901,
            -0.4409404695034027,
            1.3148040771484375,
            0.6241689920425415,
            0.17338836193084717,
            1.4020249843597412,
            0.9396356344223022,
            -2.504676580429077,
            7.070631504058838,
            -2.960773229598999,
            3.7149949073791504,
            -4.404186248779297,
            0.1831464171409607,
            9.968976974487305,
            -4.32266902923584,
            -0.29009580612182617,
            -1.2585481405258179,
            -1.3451547622680664,
            2.874220848083496,
            -0.7651715874671936,
            -1.1087201833724976,
            1.0676014423370361,
            1.001111388206482,
            2.5971579551696777,
            -2.6251158714294434,
            2.4266295433044434,
            4.44782018661499,
            2.5825743675231934,
            -0.01972392201423645,
            0.5312092304229736,
            0.03718526288866997,
            -1.7788363695144653,
            2.08323073387146,
            1.7158578634262085,
            3.9790263175964355,
            -5.551701545715332,
            3.59769868850708,
            2.3454153537750244,
            -0.3090287446975708,
            2.272632360458374,
            2.1736817359924316,
            -4.017340183258057,
            -0.2741277813911438,
            7.808659553527832,
            -0.8351669907569885,
            -2.2795650959014893,
            2.532008171081543,
            -3.813443183898926,
            2.901775360107422,
            0.43282070755958557,
            -3.3038313388824463,
            0.7662401795387268,
            0.9947505593299866,
            -8.358864784240723,
            -1.366117000579834,
            -3.0516200065612793,
            0.6655087471008301,
            -0.273576557636261,
            0.12578082084655762,
            1.5610182285308838,
            3.0848140716552734,
            -3.3453803062438965,
            -5.962120056152344,
            1.0082769393920898,
            1.8095678091049194,
            -3.1039557456970215,
            -1.6737487316131592,
            3.299612045288086,
            -0.005849123001098633,
            1.5975677967071533,
            -2.2628352642059326,
            -0.5490204095840454,
            -0.8774821758270264,
            0.355978786945343,
            -3.233804225921631,
            0.1550474762916565,
            3.7720956802368164,
            1.2128353118896484,
            0.6909981369972229,
            1.0528206825256348,
            5.196847915649414,
            -3.1768736839294434,
            -2.214667320251465,
            0.7832044959068298,
            -0.9820241928100586,
            -2.456441879272461,
            -0.7454932332038879,
            2.3243584632873535,
            -0.8571856021881104,
            -1.7939231395721436,
            -0.19267746806144714,
            -4.050668716430664,
            -3.689300298690796,
            0.6972871422767639,
            0.15468084812164307,
            5.378410816192627,
            -1.0433502197265625,
            -0.15029281377792358,
            -4.258060455322266,
            0.8319075703620911,
            -1.0416576862335205,
            1.8803049325942993,
            0.6600584983825684,
            -2.497699499130249,
            -2.2135603427886963,
            -3.240854501724243,
            1.6853740215301514,
            -1.7006571292877197,
            5.503702163696289,
            -0.22781910002231598,
            1.676732063293457,
            3.783900737762451,
            -4.749927043914795,
            3.689110279083252,
            -3.6894452571868896,
            -3.210878372192383,
            0.6205818057060242,
            4.179993629455566,
            1.8751033544540405,
            -1.3908642530441284,
            2.3154220581054688,
            2.483510971069336,
            1.9831454753875732,
            2.7971606254577637,
            2.066530704498291,
            4.250913143157959,
            2.0000498294830322,
            -6.929842472076416,
            3.3053417205810547,
            5.098337650299072,
            -0.5186936855316162,
            4.491058349609375,
            -4.765647888183594,
            2.5864293575286865,
            -1.5619410276412964,
            1.7261240482330322,
            0.7092469334602356,
            -0.1349601447582245,
            -7.939417362213135,
            -1.561423420906067,
            8.870321273803711,
            -3.349247455596924,
            -3.2377843856811523,
            0.16906726360321045,
            0.02325117588043213,
            3.8044159412384033,
            -0.6459651589393616,
            3.65809965133667,
            2.0876572132110596,
            1.6143834590911865,
            3.2946689128875732,
            3.492708206176758,
            3.4009850025177,
            -3.1246137619018555,
            -0.7028452157974243,
            0.6631358861923218,
            -1.9695920944213867,
            -1.5203797817230225,
            -5.425310134887695,
            0.6891397833824158,
            -4.787034511566162,
            -4.300933837890625,
            -3.5429296493530273,
            0.7743849754333496,
            1.494306206703186,
            0.7028464078903198,
            -0.5527931451797485,
            1.1436450481414795,
            4.749772548675537,
            5.2479119300842285,
            2.1033883094787598,
            0.5701368451118469,
            1.933056354522705,
            1.3147239685058594,
            -3.9345145225524902,
            2.593226909637451,
            4.036993980407715,
            2.7350070476531982,
            -0.46993306279182434,
            -1.8594083786010742,
            4.191596031188965,
            2.219123125076294,
            -5.259425640106201,
            3.897721529006958,
            0.24955487251281738,
            1.2040653228759766,
            -0.682872474193573,
            1.6459060907363892,
            -0.6372474431991577,
            1.772343635559082,
            -2.645853281021118,
            -1.6226643323898315,
            -5.440277576446533,
            2.3898613452911377,
            3.7773258686065674,
            3.548931360244751,
            -2.212404251098633,
            -2.175170421600342,
            1.2954157590866089,
            -5.757854461669922,
            1.511297345161438,
            -2.0336999893188477,
            3.009157419204712,
            0.42468324303627014,
            0.5577617883682251,
            1.1768244504928589,
            2.1604702472686768,
            -4.760331153869629,
            -1.686690092086792,
            0.43786072731018066,
            -5.71901273727417,
            -0.691942572593689,
            -5.022140979766846,
            2.280139923095703,
            0.2692408263683319,
            -2.0575098991394043,
            2.4866037368774414,
            1.8846492767333984,
            -3.1002697944641113,
            5.764416694641113,
            4.005524158477783,
            0.10988280177116394,
            -2.2184600830078125,
            3.2853879928588867,
            -0.6355659365653992,
            -4.337871551513672,
            0.34222620725631714,
            -2.57035231590271,
            1.869126319885254,
            -2.0573225021362305,
            2.593449592590332,
            3.3384616374969482,
            -0.4209323227405548,
            1.5903414487838745,
            0.44228416681289673,
            -0.08967532217502594,
            1.165771722793579,
            3.632502317428589,
            2.733827590942383,
            5.466218948364258,
            -1.2531230449676514,
            -2.130967855453491,
            -6.4692888259887695,
            -1.3335926532745361,
            -0.5766972303390503,
            0.8856619000434875,
            2.973529577255249,
            1.2794125080108643,
            -1.2791396379470825,
            -5.845843315124512,
            -2.3203041553497314,
            -6.884449005126953,
            -2.7090494632720947,
            0.805617094039917,
            1.8891605138778687,
            3.804939031600952,
            0.980437159538269,
            -3.625950574874878,
            -2.772303581237793,
            0.2929815649986267,
            -1.6716082096099854,
            -3.0950214862823486,
            -1.547788143157959,
            -2.3767552375793457,
            0.1922484040260315,
            -0.4431154131889343,
            -3.09226393699646,
            4.675347328186035,
            -2.32358455657959,
            -2.342315673828125,
            -6.174171447753906,
            2.9736061096191406,
            4.415480613708496,
            -2.2821619510650635,
            -1.625959038734436,
            0.4136364161968231,
            -1.5601108074188232,
            3.7640304565429688,
            3.0070557594299316,
            -0.2217980921268463,
            0.8383234739303589,
            4.325977802276611,
            0.1417156159877777,
            -1.0449131727218628,
            0.3246566355228424,
            -5.290056228637695,
            -2.3436832427978516,
            -1.9103251695632935,
            1.9231666326522827,
            -1.9919233322143555,
            0.5926973819732666,
            0.5207006335258484,
            3.894406795501709,
            -0.3828044831752777,
            -3.8117973804473877,
            4.47125244140625,
            1.6639175415039062,
            0.8914732933044434,
            -5.4532084465026855,
            -2.7325778007507324,
            -1.971726417541504,
            -0.5643701553344727,
            4.449365615844727,
            1.7408182621002197,
            -2.4505248069763184,
            1.9818108081817627,
            -2.374802589416504,
            5.169571876525879,
            3.8380510807037354,
            3.829449415206909,
            -1.205606460571289,
            -7.079540729522705,
            -1.3650588989257812,
            -0.5780535936355591,
            2.60068941116333,
            0.03667685389518738,
            -1.6178618669509888,
            5.4543914794921875,
            -0.12436197698116302,
            3.5942342281341553,
            -1.6270179748535156,
            -1.5051606893539429,
            0.07886102795600891,
            -3.733839750289917,
            -0.16731253266334534,
            -0.410006046295166,
            0.9602938294410706,
            1.1852298974990845,
            4.302657127380371,
            -4.856832504272461,
            3.5323150157928467,
            4.513012409210205,
            0.8121820092201233,
            1.622767448425293,
            0.9093783497810364,
            1.9657649993896484,
            0.5404067039489746,
            0.01569819450378418,
            -1.402899980545044,
            0.6866819858551025,
            2.7921102046966553,
            -3.8529751300811768,
            9.33237075805664,
            -1.791611909866333,
            -0.3863672614097595,
            -5.76783561706543,
            -1.9992351531982422,
            -1.8581883907318115,
            -4.242520332336426,
            1.117588996887207,
            -4.955958366394043,
            -3.59395170211792,
            -3.049006700515747,
            -3.130037307739258,
            0.9237620830535889,
            4.07378625869751,
            0.8609529733657837,
            2.148747682571411,
            -0.4558565616607666,
            2.940927505493164,
            -1.4450786113739014,
            0.3839857578277588,
            -0.17738574743270874,
            1.495769739151001,
            0.4680221676826477,
            0.12241488695144653,
            -0.9910194873809814,
            2.472433567047119,
            -0.45245781540870667,
            4.960599899291992,
            -2.32456111907959,
            -2.5188217163085938,
            -3.300262928009033,
            -3.478489875793457,
            -1.6422128677368164,
            0.7981610894203186,
            0.3848636746406555,
            1.3080418109893799,
            5.355388641357422,
            5.5988874435424805,
            -3.9807772636413574,
            -0.7962387800216675,
            5.5602521896362305,
            -0.594184398651123,
            -2.5419414043426514,
            0.5910872220993042,
            -2.2213196754455566,
            -1.515859603881836,
            1.7998533248901367,
            -4.70669412612915,
            -0.21766963601112366,
            -1.29227614402771,
            3.2748706340789795,
            0.5042753219604492,
            1.9330217838287354,
            2.510974168777466,
            -2.2031965255737305,
            2.924237012863159,
            3.603415012359619,
            1.907627820968628,
            1.4499542713165283,
            1.3207554817199707,
            4.729814052581787,
            1.7102761268615723,
            -0.8944621086120605,
            4.407712936401367,
            -0.9414637684822083,
            5.077927589416504,
            -4.2211689949035645,
            -0.7962816953659058,
            -1.9803708791732788,
            5.430846691131592,
            3.4521989822387695,
            0.35424157977104187,
            -0.2681777775287628,
            -0.7200872898101807,
            1.6107163429260254,
            2.532057762145996,
            -2.135927200317383,
            5.424052715301514,
            0.5039198398590088,
            -0.09279677271842957,
            0.18471485376358032,
            1.1946513652801514,
            0.8631999492645264,
            -3.161487102508545,
            4.434907913208008,
            -3.2266104221343994,
            -1.2183951139450073,
            -1.2802971601486206,
            0.3888338506221771,
            0.40229061245918274,
            -2.3938653469085693,
            -0.7114567160606384,
            0.7696042060852051,
            -0.07736623287200928,
            -2.6992592811584473,
            4.298908710479736,
            0.0958453118801117,
            -2.0091352462768555,
            0.8983049392700195,
            2.1920576095581055,
            -2.81005859375,
            -5.315243721008301,
            -4.638298034667969,
            2.01601505279541,
            -0.7886930108070374,
            -0.002893209457397461,
            -1.4321942329406738,
            1.6076438426971436,
            -1.2308074235916138,
            -2.3813865184783936,
            6.494259834289551,
            2.114845037460327,
            3.594007968902588,
            -0.7052604556083679,
            -2.5595643520355225,
            -2.6661388874053955,
            1.5953547954559326,
            -1.984778881072998,
            -0.76357102394104,
            4.365583419799805,
            2.0844576358795166,
            2.7325286865234375,
            1.318897008895874,
            1.2431010007858276,
            0.615096390247345,
            2.678123712539673,
            6.388925552368164,
            -0.6665935516357422,
            2.042581081390381,
            0.6776496171951294,
            -4.79958438873291,
            4.706118583679199,
            0.4283919036388397,
            1.52167546749115,
            1.1808503866195679,
            -4.894401550292969,
            -1.247591495513916,
            -2.7231199741363525,
            -5.711811065673828,
            2.643026828765869,
            4.120331287384033,
            -1.0251383781433105,
            -3.0008177757263184,
            -0.08181726932525635,
            0.02018037438392639,
            0.9576328992843628,
            -5.419310569763184,
            1.3163007497787476,
            -0.501929521560669,
            2.225193500518799,
            0.09222233295440674,
            -1.0792961120605469,
            -1.4107918739318848,
            1.9803191423416138,
            -1.6122362613677979,
            0.8921958804130554,
            -1.6050899028778076,
            1.5465867519378662,
            1.3507146835327148,
            2.5021567344665527,
            -4.194607734680176,
            4.373556613922119,
            1.0180132389068604,
            6.562661647796631,
            6.066904067993164,
            5.9897637367248535,
            2.0217416286468506,
            -1.1215916872024536,
            -2.49215030670166,
            -2.153834819793701,
            3.703683853149414,
            3.571732521057129,
            -4.90065860748291,
            -0.4347759485244751,
            -1.012204647064209,
            1.266660213470459,
            -1.1087079048156738,
            1.1895068883895874,
            -2.6159205436706543,
            2.8233423233032227,
            -4.5920305252075195,
            -2.0159454345703125,
            -2.222342014312744,
            2.4932053089141846,
            -0.8631104230880737,
            1.1212382316589355,
            2.9587810039520264,
            0.9726273417472839,
            -4.2238969802856445,
            1.4009206295013428,
            -2.3212032318115234,
            -1.552673101425171,
            1.381151556968689,
            0.8426504731178284,
            -0.20622962713241577,
            -1.0904656648635864,
            0.12778230011463165,
            4.392823219299316,
            -1.0187983512878418,
            0.48679476976394653,
            -3.6729700565338135,
            1.8160662651062012,
            1.6864186525344849,
            -0.3624711036682129,
            0.18742115795612335,
            -2.5581469535827637,
            0.5626028776168823,
            -0.9839421510696411,
            1.5721955299377441,
            1.3483810424804688,
            2.4966254234313965,
            -1.0966472625732422,
            -0.004793643951416016,
            -1.7636346817016602,
            -1.9309202432632446,
            -0.6225475072860718,
            -3.009565830230713,
            -6.260261058807373,
            0.40913599729537964,
            -2.7262015342712402,
            -2.513883590698242,
            3.017096519470215,
            -4.179262161254883,
            -0.459725558757782,
            1.4400169849395752,
            -0.6376789808273315,
            -2.5903947353363037,
            -2.5922961235046387,
            0.5301596522331238,
            -0.2093469649553299,
            3.1758360862731934,
            -2.137758255004883,
            -0.43467843532562256,
            1.6940782070159912,
            1.7604832649230957,
            5.956592082977295,
            3.8359296321868896,
            0.733381986618042,
            -3.2176661491394043,
            -0.9467059969902039,
            2.58969783782959,
            0.8192567825317383,
            -0.9524983763694763,
            1.183881163597107,
            0.809319794178009,
            1.3314845561981201,
            15.518389701843262,
            -2.1386420726776123,
            -0.8959437608718872,
            -0.23335978388786316,
            0.18074311316013336,
            -3.354109287261963,
            -2.915980577468872,
            1.6464945077896118,
            1.7720630168914795,
            1.0155612230300903,
            -3.1488537788391113,
            -4.235496520996094,
            -0.45084047317504883,
            2.7967867851257324,
            -1.0034164190292358,
            2.881422758102417,
            -4.158791542053223,
            0.5644664168357849,
            -1.2429354190826416,
            1.7260241508483887,
            2.1086230278015137,
            2.3342580795288086,
            -3.0229859352111816,
            -0.6043506264686584,
            -0.5350521802902222,
            2.8285915851593018,
            1.5624449253082275,
            4.338667869567871,
            -3.0127906799316406,
            -0.3554459512233734,
            0.09126260876655579,
            3.3865537643432617,
            -3.429546356201172,
            -1.7812241315841675,
            -3.130449056625366,
            3.507476329803467,
            4.389305114746094,
            -0.10733887553215027,
            3.377671480178833,
            0.7669626474380493,
            0.6614958047866821,
            2.433213233947754,
            -3.0940871238708496,
            1.994635820388794,
            -2.5394139289855957,
            -1.859548807144165,
            2.6461143493652344,
            -3.249892234802246,
            -4.249606609344482,
            5.597748756408691,
            0.006586536765098572,
            0.4341127276420593,
            -0.9913625717163086,
            0.6118894219398499,
            1.5051213502883911,
            2.7510128021240234,
            -1.0747056007385254,
            -4.9296770095825195,
            3.4525675773620605,
            -1.9482935667037964,
            -0.5707044005393982,
            0.4786580801010132,
            -3.9839446544647217,
            -2.4450063705444336,
            1.6650046110153198,
            -1.3316847085952759,
            -1.8093297481536865,
            2.557224988937378,
            0.7990742921829224,
            1.5631345510482788,
            3.4685022830963135,
            2.3906216621398926,
            -2.5604248046875,
            -1.7506682872772217,
            1.2140522003173828,
            -2.4551234245300293,
            2.7505879402160645,
            -1.4744248390197754,
            -2.8814711570739746,
            6.242833614349365,
            -3.390411138534546,
            1.9385076761245728,
            -3.0191051959991455,
            -3.563124656677246,
            6.7335028648376465,
            -4.869494438171387,
            4.894057273864746,
            0.37479838728904724,
            -1.425220012664795,
            4.0665082931518555,
            -0.6454472541809082,
            -1.3081421852111816,
            2.0886876583099365,
            3.943028211593628,
            5.191533088684082,
            -6.407562732696533,
            -5.391818046569824,
            -4.959359645843506,
            -2.09991455078125,
            -3.9028875827789307,
            6.574489593505859,
            6.1605753898620605,
            0.02596244215965271,
            -0.8783785700798035,
            -1.415513515472412,
            0.12846916913986206,
            -0.7565155029296875,
            -5.814294338226318,
            -4.086217403411865,
            -1.6542143821716309,
            2.780974864959717,
            -5.357818603515625,
            -1.3203957080841064,
            1.5681190490722656,
            0.699458658695221,
            -0.7476491928100586,
            1.1866031885147095,
            0.332749605178833,
            1.364992380142212,
            4.903672695159912,
            -0.9379733800888062,
            0.6919524669647217,
            -2.5954067707061768,
            -1.7589948177337646,
            -0.008468613028526306,
            3.1996192932128906,
            -1.9527571201324463,
            -0.8287362456321716,
            -1.3018364906311035,
            -1.5372214317321777,
            0.49374592304229736,
            -3.4897515773773193,
            -0.7538132071495056,
            -0.5476169586181641,
            -1.8632242679595947,
            -1.1777496337890625,
            -1.0660769939422607,
            0.009227454662322998,
            -3.00368070602417,
            4.081715106964111,
            2.2692108154296875,
            -4.364777565002441,
            -1.619429588317871,
            7.6241655349731445,
            -0.29296761751174927,
            -1.5556068420410156,
            -1.9240221977233887,
            -2.116259813308716,
            -1.6024155616760254,
            -1.0347998142242432,
            0.9220008850097656,
            -0.3934294879436493,
            5.137462615966797,
            -1.3850549459457397,
            -0.4215628504753113,
            -1.9983019828796387
        ]
    },
    "authors": [
        {
            "authorId": "2196682815",
            "name": "Je-Yong Lee"
        },
        {
            "authorId": "2263095684",
            "name": "Donghyun Lee"
        },
        {
            "authorId": "2296751065",
            "name": "Genghan Zhang"
        },
        {
            "authorId": "2296711088",
            "name": "Mo Tiwari"
        },
        {
            "authorId": "1861312",
            "name": "Azalia Mirhoseini"
        }
    ],
    "references": [
        {
            "paperId": "ed2c3f9fd24a4aa4b05f2c2729c7450da2bfe7e7",
            "title": "ReLU2 Wins: Discovering Efficient Activation Functions for Sparse LLMs"
        },
        {
            "paperId": "411114f989a3d1083d90afd265103132fee94ebe",
            "title": "Mixtral of Experts"
        },
        {
            "paperId": "5c104f905fcacf390270f619f232a2ba4eb873f2",
            "title": "FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores"
        },
        {
            "paperId": "95240dda409e28acccdc5cf619ad0c036cf4292d",
            "title": "Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time"
        },
        {
            "paperId": "188336f606e76fda9e219b954d1750ad26646fdb",
            "title": "ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models"
        },
        {
            "paperId": "aeac7fe0637a172e4ea380fd8d75c93a3302b028",
            "title": "Exploiting Activation Sparsity with Dense to Dynamic-k Mixture-of-Experts Conversion"
        },
        {
            "paperId": "02ad9f3fefe33cb9ca546591bec65dbdf7766c80",
            "title": "Ring Attention with Blockwise Transformers for Near-Infinite Context"
        },
        {
            "paperId": "38939304bb760473141c2aca0305e44fbe04e6e8",
            "title": "RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control"
        },
        {
            "paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0",
            "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"
        },
        {
            "paperId": "7d22ad3573101337bca2091fb0114b377c4f3db6",
            "title": "A Simple and Effective Pruning Approach for Large Language Models"
        },
        {
            "paperId": "7a1e71cb1310c4a873e7a4e54d1a6dab0553adce",
            "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"
        },
        {
            "paperId": "017010b941d902a467f6d329ae5e74fd67e67912",
            "title": "LLM-Pruner: On the Structural Pruning of Large Language Models"
        },
        {
            "paperId": "163b4d6a79a5b19af88b8585456363340d9efd04",
            "title": "GPT-4 Technical Report"
        },
        {
            "paperId": "0a6906bd6f026d3da3031c641ed03081bd0b574e",
            "title": "Full Stack Optimization of Transformer Inference: a Survey"
        },
        {
            "paperId": "fbd49b25bdab98c171af49962a41139c73dacbde",
            "title": "Specializing Smaller Language Models towards Multi-Step Reasoning"
        },
        {
            "paperId": "909ad57ce8caa6b390a65ae09db352d27d8f3996",
            "title": "SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot"
        },
        {
            "paperId": "397e0e0d20f00d8fbfecd2fd36b14f13e2181d0e",
            "title": "Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints"
        },
        {
            "paperId": "43014fc85c4860487336579ec98f509fec1803f7",
            "title": "MegaBlocks: Efficient Sparse Training with Mixture-of-Experts"
        },
        {
            "paperId": "7da0f2501034522e3d50af7e9b8fa7ec9d7b65b6",
            "title": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers"
        },
        {
            "paperId": "e0271cb75087ccfd4a8c3351e0f5189a6de04c03",
            "title": "The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in Transformers"
        },
        {
            "paperId": "3820231d31540ecb05d94c74d959a2f61d3136ea",
            "title": "Mixture of Attention Heads: Selecting Attention Heads Per Token"
        },
        {
            "paperId": "55a8676bb77f3d170bbedffe549636d99feb781b",
            "title": "Sgap: towards efficient sparse tensor algebra compilation for GPU"
        },
        {
            "paperId": "ca086f4c09cf8de705830ac2b70951737fab93ca",
            "title": "A Review of Sparse Expert Models in Deep Learning"
        },
        {
            "paperId": "499d3bb3acbc10730dd6582bd9b8f646bf22ccd5",
            "title": "Multimodal Contrastive Learning with LIMoE: the Language-Image Mixture of Experts"
        },
        {
            "paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336",
            "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"
        },
        {
            "paperId": "9e82736043eebe3f71eb86cbef6e2ac45306ece5",
            "title": "Structured Pruning Learns Compact and Accurate Models"
        },
        {
            "paperId": "6da9a81b75e7ad02867860753d1aa276673a3a77",
            "title": "The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models"
        },
        {
            "paperId": "bbc57e1b3cf90e09b64377f13de455793bc81ad5",
            "title": "Mixture-of-Experts with Expert Choice Routing"
        },
        {
            "paperId": "1bc9865ebf52b59abac7f5ee4456ff2ac37fcff3",
            "title": "ST-MoE: Designing Stable and Transferable Sparse Expert Models"
        },
        {
            "paperId": "7d1e512888a2fa4e838c12a02ae7fce867d322a8",
            "title": "DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale"
        },
        {
            "paperId": "80d0116d77beeded0c23cf48946d9d10d4faee14",
            "title": "GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"
        },
        {
            "paperId": "53c3940f35b8b45d55ed49056282e1961954513d",
            "title": "Self-attention Does Not Need $O(n^2)$ Memory"
        },
        {
            "paperId": "da0d38cf2ac7e2a6908e0d9e1fff07058daab2ed",
            "title": "Sparse is Enough in Scaling Transformers"
        },
        {
            "paperId": "9202a718ce05395b6e17d5301e3a2e8b1021f31b",
            "title": "Prune Once for All: Sparse Pre-Trained Language Models"
        },
        {
            "paperId": "561f9f5abb2c0960a886ab6221c821295f0461a1",
            "title": "MoEfication: Transformer Feed-forward Layers are Mixtures of Experts"
        },
        {
            "paperId": "8ae292cbd9144acbf4b42b7ead82b079faf33192",
            "title": "Beyond Distillation: Task-level Mixture-of-Experts for Efficient Inference"
        },
        {
            "paperId": "ee732f7ec260d1efa3c77e8938a9d38f76342652",
            "title": "Cross-token Modeling with Conditional Computation"
        },
        {
            "paperId": "0611d2f2ea6a3c8fb8534f42758a5a3e9c7bc8fe",
            "title": "Hash Layers For Large Sparse Models"
        },
        {
            "paperId": "36ffa5b1f643f59ccf8396cff9865e5474c8dae7",
            "title": "DSelect-k: Differentiable Selection in the Mixture of Experts with Applications to Multi-Task Learning"
        },
        {
            "paperId": "7a16d9b4e04300d034502dc7dd58428714594e2c",
            "title": "Carbon Emissions and Large Neural Network Training"
        },
        {
            "paperId": "b15ea460c77a4ee8aa159a30ab0331deedfcf392",
            "title": "BASE Layers: Simplifying Training of Large, Sparse Models"
        },
        {
            "paperId": "9d6acac70b2d1fdb861a08b00766ef263109cd7f",
            "title": "Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks"
        },
        {
            "paperId": "fdacf2a732f55befdc410ea927091cad3b791f13",
            "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"
        },
        {
            "paperId": "c375e121926db9551f224ff235018ea38bb159b7",
            "title": "BinaryBERT: Pushing the Limit of BERT Quantization"
        },
        {
            "paperId": "b42c6cfadfaf1209346a41f1cf766f3d0c09aa3c",
            "title": "Meta-KD: A Meta Knowledge Distillation Framework for Language Model Compression across Domains"
        },
        {
            "paperId": "0abb08c4ec5feab4cdd82c471866dd4395c573ce",
            "title": "Contrastive Distillation on Intermediate Representations for Language Model Compression"
        },
        {
            "paperId": "1882f194cb43828852cc052887671e55a80f945a",
            "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "83b8108014e3db4f46354a28ae68193f143c4e7e",
            "title": "Structured Pruning of Large Language Models"
        },
        {
            "paperId": "c95383f251a62c63217586059c67f63507c3e839",
            "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"
        },
        {
            "paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3",
            "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"
        },
        {
            "paperId": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf",
            "title": "Patient Knowledge Distillation for BERT Model Compression"
        },
        {
            "paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583",
            "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"
        },
        {
            "paperId": "6398cb8f2af1c988a097ed1e1cefb380195edfb8",
            "title": "(Preprint)"
        },
        {
            "paperId": "96cf67af95aa27f0fd1da983491b3a66004d30ff",
            "title": "Input-Aware Auto-Tuning of Compute-Bound HPC Kernels"
        },
        {
            "paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586",
            "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"
        },
        {
            "paperId": "092217c2267f6e0673590aa151d811e579ff7760",
            "title": "Roofline: an insightful visual performance model for multicore architectures"
        },
        {
            "paperId": "c2f43eec90d88e5736de431aaa08107be392386e",
            "title": "HyperGef: A Framework Enabling Efficient Fusion for Hypergraph Neural Network on GPUs"
        },
        {
            "paperId": "b8b45b14df9029562b8995c6ab7fd90a8810f312",
            "title": "GPT3.int8(): 8-bit Matrix Multiplication for Transformers at Scale"
        },
        {
            "paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": null,
            "title": ": Open models based on gemini research and technology"
        },
        {
            "paperId": null,
            "title": "A framework for few-shot language model evaluation"
        }
    ]
}