{
    "paperId": "d1869155960e4b1b882b39171dbecd25a7eda3cd",
    "externalIds": {
        "DBLP": "conf/iclr/LiuCCCXWKPMW23",
        "ArXiv": "2207.03620",
        "DOI": "10.48550/arXiv.2207.03620",
        "CorpusId": 250408169
    },
    "title": "More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity",
    "abstract": "Transformers have quickly shined in the computer vision world since the emergence of Vision Transformers (ViTs). The dominant role of convolutional neural networks (CNNs) seems to be challenged by increasingly effective transformer-based models. Very recently, a couple of advanced convolutional models strike back with large kernels motivated by the local-window attention mechanism, showing appealing performance and efficiency. While one of them, i.e. RepLKNet, impressively manages to scale the kernel size to 31x31 with improved performance, the performance starts to saturate as the kernel size continues growing, compared to the scaling trend of advanced ViTs such as Swin Transformer. In this paper, we explore the possibility of training extreme convolutions larger than 31x31 and test whether the performance gap can be eliminated by strategically enlarging convolutions. This study ends up with a recipe for applying extremely large kernels from the perspective of sparsity, which can smoothly scale up kernels to 61x61 with better performance. Built on this recipe, we propose Sparse Large Kernel Network (SLaK), a pure CNN architecture equipped with sparse factorized 51x51 kernels that can perform on par with or better than state-of-the-art hierarchical Transformers and modern ConvNet architectures like ConvNeXt and RepLKNet, on ImageNet classification as well as a wide range of downstream tasks including semantic segmentation on ADE20K, object detection on PASCAL VOC 2007, and object detection/segmentation on MS COCO.",
    "venue": "International Conference on Learning Representations",
    "year": 2022,
    "referenceCount": 124,
    "citationCount": 121,
    "influentialCitationCount": 17,
    "openAccessPdf": {
        "url": "http://arxiv.org/pdf/2207.03620",
        "status": "GREEN"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This study ends up with a recipe for applying extremely large kernels from the perspective of sparsity, which can smoothly scale up kernels to 61x61 with better performance and proposes Sparse Large Kernel Network (SLaK), a pure CNN architecture equipped with sparse factorized 51x51 kernels that can perform on par with or better than state-of-the-art hierarchical Transformers and modern ConvNet architectures."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -5.348985195159912,
            -2.053739547729492,
            0.3769066333770752,
            6.464719772338867,
            2.1220345497131348,
            2.8642449378967285,
            4.441530227661133,
            -1.0043243169784546,
            0.15135052800178528,
            -0.7381669878959656,
            -0.45399218797683716,
            4.348231792449951,
            -0.768467903137207,
            1.5351437330245972,
            -4.8699235916137695,
            -2.5054454803466797,
            -0.5528011322021484,
            -2.013291835784912,
            5.2486772537231445,
            1.8306703567504883,
            -3.0281991958618164,
            -1.7418925762176514,
            -0.4745246171951294,
            0.9309885501861572,
            -3.1388649940490723,
            -0.47975456714630127,
            0.4863964021205902,
            0.22726142406463623,
            -0.48111391067504883,
            1.2838325500488281,
            1.885145902633667,
            -4.75645637512207,
            5.967679023742676,
            -4.870303630828857,
            1.7425384521484375,
            0.04410681128501892,
            0.7991430759429932,
            6.229622840881348,
            -4.725245952606201,
            0.6279111504554749,
            0.7687219977378845,
            -0.6588319540023804,
            0.5868611335754395,
            1.3485476970672607,
            0.06047794222831726,
            1.5343445539474487,
            -1.9630048274993896,
            -1.2722593545913696,
            -0.43812546133995056,
            4.249959945678711,
            2.25752592086792,
            3.040414810180664,
            0.44842034578323364,
            2.6871769428253174,
            -0.838509202003479,
            -0.10238420963287354,
            2.6301968097686768,
            0.31449025869369507,
            -0.01583891361951828,
            -0.9077242612838745,
            2.980281114578247,
            2.9011876583099365,
            -0.07882195711135864,
            2.1743931770324707,
            1.5715652704238892,
            -2.0561563968658447,
            -0.3090583384037018,
            5.198128700256348,
            0.918317437171936,
            -0.6271379590034485,
            -2.889298439025879,
            -4.466075897216797,
            1.350936770439148,
            0.4338511526584625,
            -3.387209892272949,
            -1.973595142364502,
            1.6049044132232666,
            -3.7131807804107666,
            -0.7996149063110352,
            -1.2656347751617432,
            0.27395132184028625,
            4.612993240356445,
            -1.5397318601608276,
            1.7937865257263184,
            3.4145140647888184,
            -3.3270263671875,
            -2.7656168937683105,
            -3.2559361457824707,
            0.2591420114040375,
            -2.559727191925049,
            -1.7703028917312622,
            -0.21656392514705658,
            3.126530647277832,
            2.4297592639923096,
            -6.190679550170898,
            1.300040364265442,
            -0.9756121635437012,
            -4.391272068023682,
            -2.1115760803222656,
            -0.32756656408309937,
            1.5191783905029297,
            -1.883469581604004,
            1.2590042352676392,
            -1.8081650733947754,
            0.41871026158332825,
            -3.868074893951416,
            -1.1319408416748047,
            -0.8132408261299133,
            -1.91903555393219,
            -3.4488067626953125,
            -2.7059519290924072,
            4.997968673706055,
            -1.7451932430267334,
            1.7882349491119385,
            -3.7365431785583496,
            -1.6486026048660278,
            1.8922080993652344,
            0.8474958539009094,
            1.1388579607009888,
            0.8036752939224243,
            -2.7505860328674316,
            -1.449589729309082,
            -5.238285541534424,
            2.7179148197174072,
            1.9676005840301514,
            1.9703805446624756,
            -0.6740893125534058,
            3.447943687438965,
            1.3576903343200684,
            -6.161009311676025,
            1.490051507949829,
            -3.6303293704986572,
            1.6964104175567627,
            0.4603693187236786,
            1.7120048999786377,
            1.0389807224273682,
            -1.7974820137023926,
            -1.497666358947754,
            -2.5482921600341797,
            -0.6975470185279846,
            1.903015375137329,
            3.252077102661133,
            1.1567473411560059,
            0.10556712746620178,
            2.586402416229248,
            2.2655370235443115,
            0.6617472171783447,
            1.929039478302002,
            3.4594240188598633,
            6.114953994750977,
            0.26410073041915894,
            -3.8599283695220947,
            0.2330305576324463,
            4.842815399169922,
            1.8264057636260986,
            2.4005136489868164,
            -5.094480514526367,
            0.9235593676567078,
            -3.0970799922943115,
            0.6690337061882019,
            0.015512540936470032,
            -0.5379042029380798,
            -10.501415252685547,
            -0.7445657849311829,
            3.28448224067688,
            -2.6626291275024414,
            1.1381068229675293,
            0.11214293539524078,
            1.4942172765731812,
            3.746311902999878,
            -0.11566406488418579,
            3.126081943511963,
            2.1533591747283936,
            3.4144206047058105,
            0.655982255935669,
            4.86325740814209,
            5.725397109985352,
            -0.8610504865646362,
            -0.6168829798698425,
            -2.0916340351104736,
            -0.7487912774085999,
            -0.5452147722244263,
            -5.418691158294678,
            4.022364616394043,
            -2.252117872238159,
            -5.6241350173950195,
            -4.01866340637207,
            1.4566419124603271,
            -1.3822160959243774,
            -2.2237002849578857,
            1.9622339010238647,
            1.313458800315857,
            4.756091117858887,
            5.398750305175781,
            2.9987316131591797,
            -1.8967427015304565,
            3.4076554775238037,
            2.2714040279388428,
            -3.2970001697540283,
            4.328331470489502,
            2.94045352935791,
            -0.8137580156326294,
            -0.08852216601371765,
            -0.5739824771881104,
            1.8070118427276611,
            -2.850524425506592,
            -1.1829780340194702,
            0.5854161977767944,
            2.0482077598571777,
            -0.10213492065668106,
            0.3081408143043518,
            -1.650466799736023,
            1.0338785648345947,
            2.3713393211364746,
            -3.8327012062072754,
            -1.9144141674041748,
            -3.0849361419677734,
            0.6256035566329956,
            3.6610891819000244,
            1.9763625860214233,
            -0.3186958432197571,
            -4.84773588180542,
            -2.024482488632202,
            -3.9890522956848145,
            3.5496368408203125,
            -1.9006658792495728,
            1.8480734825134277,
            5.931926727294922,
            0.7321791648864746,
            1.4011919498443604,
            -2.8619165420532227,
            -7.179685592651367,
            0.48412245512008667,
            -1.3183928728103638,
            -5.088840961456299,
            -2.379638433456421,
            -5.301290512084961,
            0.46033114194869995,
            -1.907727837562561,
            -2.0005571842193604,
            6.996500015258789,
            0.6169765591621399,
            1.010125994682312,
            3.1448638439178467,
            0.24969910085201263,
            -4.02808952331543,
            -1.9170725345611572,
            2.2862823009490967,
            2.404449224472046,
            -2.008793830871582,
            1.21523118019104,
            -3.388990879058838,
            3.9649953842163086,
            -2.885594129562378,
            0.41088810563087463,
            -0.38240259885787964,
            2.853863000869751,
            -0.2700287997722626,
            -1.778139352798462,
            -3.3250176906585693,
            -3.422393560409546,
            4.490883827209473,
            2.6830902099609375,
            3.7291574478149414,
            -3.263211965560913,
            0.7916762828826904,
            -2.7512197494506836,
            0.47091299295425415,
            -2.5715436935424805,
            0.43673932552337646,
            0.061911679804325104,
            1.085646629333496,
            -1.72186279296875,
            -5.175514221191406,
            -3.82566499710083,
            -4.1805009841918945,
            -1.14839768409729,
            -1.8430638313293457,
            2.3129801750183105,
            3.5652213096618652,
            0.028952062129974365,
            -2.3799843788146973,
            -4.436946392059326,
            -2.243922233581543,
            -2.6748886108398438,
            -1.0887975692749023,
            -4.3532915115356445,
            -2.7639245986938477,
            0.9407836198806763,
            -0.8730977773666382,
            -4.481939792633057,
            -0.1086692214012146,
            -2.1669414043426514,
            0.7327956557273865,
            -2.3181068897247314,
            1.9554762840270996,
            4.927609443664551,
            1.3420555591583252,
            -1.0525234937667847,
            -0.42859894037246704,
            -3.3411099910736084,
            2.999399423599243,
            4.4871826171875,
            -3.944347381591797,
            2.832853078842163,
            4.807847499847412,
            0.7059604525566101,
            -2.656437873840332,
            -0.20861056447029114,
            -3.8322627544403076,
            -0.3101247251033783,
            -1.1760165691375732,
            2.938425064086914,
            -3.7749009132385254,
            2.79201602935791,
            1.0150392055511475,
            4.830593585968018,
            -1.6416637897491455,
            -1.05617356300354,
            1.46793794631958,
            1.3017146587371826,
            1.3019317388534546,
            -4.869045257568359,
            -5.460277557373047,
            -1.9166390895843506,
            -1.0095665454864502,
            3.2056713104248047,
            3.561589479446411,
            -2.911440849304199,
            0.9627867937088013,
            0.8741304874420166,
            4.477213382720947,
            4.103023052215576,
            3.8186826705932617,
            0.19634999334812164,
            -3.3522770404815674,
            0.24989351630210876,
            1.294952154159546,
            -0.5713589191436768,
            0.8042672872543335,
            -1.1302417516708374,
            1.005873203277588,
            2.664271831512451,
            3.149202823638916,
            2.8721189498901367,
            -0.5756677389144897,
            4.540340423583984,
            -2.2784690856933594,
            1.8384515047073364,
            -2.0007548332214355,
            -3.26774525642395,
            1.8159834146499634,
            4.80720329284668,
            -4.038663387298584,
            -0.3919973373413086,
            2.2439825534820557,
            1.8529661893844604,
            2.5575008392333984,
            2.5188674926757812,
            3.4187233448028564,
            0.6890035271644592,
            -2.2648260593414307,
            2.3119120597839355,
            -3.1751511096954346,
            0.5517199039459229,
            1.2034022808074951,
            10.755073547363281,
            -4.0852580070495605,
            1.5522955656051636,
            -4.493614196777344,
            -2.1491832733154297,
            -1.7278329133987427,
            -1.1318124532699585,
            4.060908317565918,
            -3.2780494689941406,
            -0.6195471882820129,
            0.1613740622997284,
            -5.181357383728027,
            3.354379653930664,
            0.06907516717910767,
            -0.9664477705955505,
            6.541439056396484,
            1.3724875450134277,
            5.358929634094238,
            -0.5622634887695312,
            0.040281251072883606,
            -2.5637331008911133,
            4.686751365661621,
            2.098531484603882,
            -1.3797179460525513,
            -3.208024024963379,
            1.3607556819915771,
            -1.3261854648590088,
            0.4164921045303345,
            -3.7726173400878906,
            -4.868581771850586,
            -6.030428409576416,
            -4.655961990356445,
            1.5352509021759033,
            -1.1051547527313232,
            -2.015094757080078,
            3.692553997039795,
            3.766045093536377,
            -0.6306656002998352,
            -3.448951482772827,
            -2.1130471229553223,
            3.215214729309082,
            3.404862642288208,
            -1.9253652095794678,
            -0.21635746955871582,
            -4.885272026062012,
            -1.6599993705749512,
            0.3903985619544983,
            -4.439667224884033,
            0.18425056338310242,
            0.37241241335868835,
            1.342395544052124,
            4.602970600128174,
            2.944758415222168,
            0.8403709530830383,
            -2.4861392974853516,
            4.264795303344727,
            3.333895683288574,
            3.6304783821105957,
            -1.246464729309082,
            2.9681427478790283,
            2.3843607902526855,
            5.512361526489258,
            -1.1532284021377563,
            1.8357164859771729,
            -1.6109813451766968,
            3.5773167610168457,
            -1.8852354288101196,
            0.061746180057525635,
            -0.5261260271072388,
            4.068515777587891,
            -0.47147148847579956,
            2.906862735748291,
            4.676620960235596,
            0.4558866024017334,
            1.7553765773773193,
            2.1018965244293213,
            -1.2810084819793701,
            4.8291096687316895,
            -0.5661033391952515,
            1.1955312490463257,
            -1.9723684787750244,
            0.16086792945861816,
            -0.5060961246490479,
            -2.4156360626220703,
            2.4479644298553467,
            -3.0658864974975586,
            -3.123812675476074,
            -1.2800912857055664,
            1.9022819995880127,
            -0.2894095480442047,
            -0.5834989547729492,
            -2.271402597427368,
            -0.9463847279548645,
            -0.5214633941650391,
            -2.5276780128479004,
            3.8237810134887695,
            -0.304352343082428,
            0.8024070262908936,
            1.6148709058761597,
            3.2681868076324463,
            0.6980489492416382,
            -3.1896419525146484,
            -3.123659133911133,
            1.093909740447998,
            4.480717658996582,
            -1.6981099843978882,
            0.4779975116252899,
            -0.5486187934875488,
            -1.5791404247283936,
            -2.541055202484131,
            3.131835699081421,
            -0.0007594525814056396,
            -0.4520084261894226,
            -4.3375444412231445,
            -1.8417024612426758,
            0.3364066481590271,
            4.225790977478027,
            -3.621121406555176,
            -2.8910446166992188,
            6.060196876525879,
            2.7776942253112793,
            4.085391998291016,
            3.681795597076416,
            4.672211647033691,
            -0.9307073354721069,
            -0.35565996170043945,
            1.2936863899230957,
            -2.321878433227539,
            1.9349496364593506,
            0.3144931495189667,
            -3.151705741882324,
            0.8475558757781982,
            2.790329933166504,
            -0.39831483364105225,
            -1.5698838233947754,
            -2.77571439743042,
            -3.0289666652679443,
            -2.303363800048828,
            -4.733360290527344,
            6.0124993324279785,
            2.819061756134033,
            1.810990333557129,
            0.998507022857666,
            -0.7726534605026245,
            -2.089104175567627,
            1.1914616823196411,
            -3.5096797943115234,
            1.0115916728973389,
            -1.9979559183120728,
            1.8843075037002563,
            1.778655767440796,
            -2.7425878047943115,
            -0.6736241579055786,
            2.142364978790283,
            -1.9148428440093994,
            0.47134751081466675,
            -0.8360852599143982,
            1.7444496154785156,
            0.6945127844810486,
            1.9163131713867188,
            -2.3732547760009766,
            2.7428340911865234,
            1.0444523096084595,
            3.180420398712158,
            3.0108132362365723,
            2.8052845001220703,
            3.900803565979004,
            -2.5829999446868896,
            -1.6708431243896484,
            -3.2715072631835938,
            0.486503928899765,
            2.0978565216064453,
            -2.693293571472168,
            -3.0533347129821777,
            -1.2592213153839111,
            2.2307910919189453,
            -0.2093508243560791,
            -1.0172326564788818,
            -1.5521740913391113,
            2.6975293159484863,
            -2.363508701324463,
            0.34920734167099,
            -1.4237879514694214,
            2.683450222015381,
            3.006500482559204,
            -0.20753523707389832,
            -0.06778155267238617,
            -2.3365297317504883,
            -4.749562740325928,
            2.0296194553375244,
            -4.345491409301758,
            0.6168886423110962,
            1.9773626327514648,
            -0.24790221452713013,
            -1.140046238899231,
            -1.1199486255645752,
            3.1186869144439697,
            4.94925594329834,
            -3.471015453338623,
            -1.9724104404449463,
            0.1789577305316925,
            2.2369561195373535,
            -0.12343050539493561,
            -4.566022872924805,
            1.0654613971710205,
            -4.429977893829346,
            -2.05473256111145,
            1.2618424892425537,
            2.6430346965789795,
            1.4151217937469482,
            2.808664560317993,
            2.712212324142456,
            -2.714212417602539,
            0.5124217867851257,
            -2.799391269683838,
            -2.468442916870117,
            0.31865912675857544,
            -3.4759490489959717,
            2.5812392234802246,
            -1.9127269983291626,
            -0.7279127836227417,
            1.5944914817810059,
            -3.1060409545898438,
            -0.3831523060798645,
            2.9381980895996094,
            -3.001946449279785,
            -1.0296231508255005,
            -4.695661544799805,
            -4.0216546058654785,
            -2.1592025756835938,
            5.564229965209961,
            1.7750693559646606,
            -3.194401979446411,
            2.298962116241455,
            2.1701955795288086,
            5.3998026847839355,
            5.228435516357422,
            -1.779175043106079,
            -2.6761415004730225,
            0.21920719742774963,
            2.204472064971924,
            0.6084074974060059,
            -3.3200793266296387,
            1.2895017862319946,
            1.2851033210754395,
            2.499544620513916,
            17.18919563293457,
            1.9388461112976074,
            -0.21323204040527344,
            -2.137101650238037,
            0.3509622812271118,
            -3.509518623352051,
            -1.062698245048523,
            0.8982738852500916,
            3.0030291080474854,
            1.7446895837783813,
            -0.26940685510635376,
            -4.694633483886719,
            2.360346794128418,
            1.9543139934539795,
            -0.36201605200767517,
            0.21386033296585083,
            -3.248884677886963,
            1.8195358514785767,
            -2.849821090698242,
            -0.5104368925094604,
            -1.7775828838348389,
            1.6262670755386353,
            -4.266887187957764,
            0.9889712333679199,
            -1.3731131553649902,
            5.035009860992432,
            2.473865032196045,
            2.967423677444458,
            -4.2637104988098145,
            0.6611065864562988,
            3.209118366241455,
            2.70133113861084,
            1.4300131797790527,
            0.35121864080429077,
            -2.19744873046875,
            5.632680892944336,
            3.882963180541992,
            -0.06418091058731079,
            0.5094010829925537,
            1.1479144096374512,
            -1.0115952491760254,
            -0.3041223883628845,
            -4.418934345245361,
            2.334862232208252,
            -1.2477504014968872,
            1.5799099206924438,
            1.0692410469055176,
            -3.1373648643493652,
            -3.1880805492401123,
            4.650942802429199,
            -0.16035518050193787,
            0.7929619550704956,
            -1.158094882965088,
            1.3886592388153076,
            4.352372646331787,
            3.53066349029541,
            0.32424163818359375,
            -2.969599962234497,
            1.2977536916732788,
            0.6180040240287781,
            -0.39455410838127136,
            0.24180763959884644,
            -3.211242198944092,
            -3.1405129432678223,
            0.39238062500953674,
            3.3567867279052734,
            -3.1164255142211914,
            3.9763031005859375,
            0.4743035137653351,
            3.1061851978302,
            5.432961463928223,
            0.8822711110115051,
            -1.245936393737793,
            -1.2128338813781738,
            -1.8835844993591309,
            -5.424867630004883,
            1.1355769634246826,
            -1.2376216650009155,
            1.7097070217132568,
            5.695087432861328,
            -4.201238632202148,
            -0.24927204847335815,
            -1.4676291942596436,
            0.9291067123413086,
            6.968446731567383,
            -2.1321218013763428,
            5.413296699523926,
            0.12141607701778412,
            0.4126724898815155,
            3.04011869430542,
            -1.4804226160049438,
            -1.269456386566162,
            2.190855026245117,
            -2.1222195625305176,
            5.30235481262207,
            -5.039590358734131,
            -5.938545227050781,
            -3.0844759941101074,
            -3.055955648422241,
            -5.714591026306152,
            5.547931671142578,
            4.949300765991211,
            4.873700141906738,
            -0.8866579532623291,
            0.7435038089752197,
            -2.1860344409942627,
            -1.072767972946167,
            -4.183728218078613,
            -4.9117841720581055,
            -0.6198248267173767,
            2.3173725605010986,
            -2.7801170349121094,
            0.4343879222869873,
            -0.13630148768424988,
            -1.5407944917678833,
            -1.4730737209320068,
            -0.7275048494338989,
            4.38771390914917,
            2.3249146938323975,
            5.771517276763916,
            1.9433696269989014,
            -2.4701972007751465,
            -3.3484930992126465,
            -4.154026508331299,
            -0.6697266101837158,
            3.1613786220550537,
            -0.9119864702224731,
            1.9685251712799072,
            0.7088504433631897,
            -3.3486199378967285,
            -0.863722562789917,
            0.5618691444396973,
            -3.6352155208587646,
            0.49983349442481995,
            -2.366041660308838,
            -1.6807358264923096,
            -1.582798957824707,
            1.811436653137207,
            -0.030853793025016785,
            4.515259742736816,
            4.504854202270508,
            -1.3614304065704346,
            -2.1158347129821777,
            7.248398780822754,
            -4.0048909187316895,
            1.0248230695724487,
            -2.0410256385803223,
            0.9522150158882141,
            -1.8475511074066162,
            -1.2816014289855957,
            -0.1492443084716797,
            -1.972512125968933,
            2.8841919898986816,
            -0.42389434576034546,
            -5.882171154022217,
            -1.4951852560043335
        ]
    },
    "authors": [
        {
            "authorId": "47130544",
            "name": "Shiwei Liu"
        },
        {
            "authorId": "2034263179",
            "name": "Tianlong Chen"
        },
        {
            "authorId": "2116298570",
            "name": "Xiaohan Chen"
        },
        {
            "authorId": null,
            "name": "Xuxi Chen"
        },
        {
            "authorId": "2056427852",
            "name": "Q. Xiao"
        },
        {
            "authorId": "46791907",
            "name": "Boqian Wu"
        },
        {
            "authorId": "1691997",
            "name": "Mykola Pechenizkiy"
        },
        {
            "authorId": "2571038",
            "name": "D. Mocanu"
        },
        {
            "authorId": "2969311",
            "name": "Zhangyang Wang"
        }
    ],
    "references": [
        {
            "paperId": "3b2c63b63478d192543bdfb7df7d9a4e1b8d3950",
            "title": "SegNeXt: Rethinking Convolutional Attention Design for Semantic Segmentation"
        },
        {
            "paperId": "6fb05e3483d05f79e59e5ce957708d8ab8932fdc",
            "title": "Peripheral Vision Transformer"
        },
        {
            "paperId": "238e4958773a5d9d3260f05e2532996b8b7dbaea",
            "title": "Towards a General Purpose CNN for Long Range Dependencies in ND"
        },
        {
            "paperId": "a26a7a74f1e5fd562be95c3611a0680759fbdf84",
            "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models"
        },
        {
            "paperId": "2ad12a7be5eaf339a98c4defd8669e11fe726acc",
            "title": "MaxViT: Multi-Axis Vision Transformer"
        },
        {
            "paperId": "9f1b0e4c42a5a85d4c023030557ade4419f82ecf",
            "title": "Scaling Up Your Kernels to 31\u00d731: Revisiting Large Kernel Design in CNNs"
        },
        {
            "paperId": "54020e5fe48ebb250f27d744e20a63cac2988a84",
            "title": "Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time"
        },
        {
            "paperId": "ba637c4f1a170f1e2dadeadb71a63cf2b9a46de2",
            "title": "Visual attention network"
        },
        {
            "paperId": "821b08d595b6482e3d1f5bab6835b72d67ebd894",
            "title": "The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse Training"
        },
        {
            "paperId": "177e957f5cd93229c9794ea652c646d2557b4a69",
            "title": "A ConvNet for the 2020s"
        },
        {
            "paperId": "730a34374384f8abb886e464758b1a145edef938",
            "title": "RepMLPNet: Hierarchical Vision MLP with Re-parameterized Locality"
        },
        {
            "paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2",
            "title": "MetaFormer is Actually What You Need for Vision"
        },
        {
            "paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5",
            "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"
        },
        {
            "paperId": "a8abb45a4b79c7a3ac037aa82fa10b86efc97fa7",
            "title": "Powerpropagation: A sparsity inducing weight reparameterisation"
        },
        {
            "paperId": "c27052d878c81564edfc4f6027b48ad684d94af0",
            "title": "Dead Pixel Test Using Effective Receptive Field"
        },
        {
            "paperId": "260ad39a1dac4b451019e2bf17925f4df8e3b69a",
            "title": "Per-Pixel Classification is Not All You Need for Semantic Segmentation"
        },
        {
            "paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798",
            "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"
        },
        {
            "paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a",
            "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"
        },
        {
            "paperId": "1fb10189c500e4902cd1b5afd406f57323d21be8",
            "title": "VOLO: Vision Outlooker for Visual Recognition"
        },
        {
            "paperId": "a85ba5bb3e97c999f5f6dbc78f277b107af1dba2",
            "title": "Sparse Training via Boosting Pruning Plasticity with Neuroregeneration"
        },
        {
            "paperId": "722ad6ac92286507437b31486f47987d6ece05c9",
            "title": "BEiT: BERT Pre-Training of Image Transformers"
        },
        {
            "paperId": "6b6ffb94626e672caffafc77097491d9ee7a8682",
            "title": "On the Connection between Local Attention and Dynamic Depth-wise Convolution"
        },
        {
            "paperId": "efbe9f591090018f78b42c84613c8afda9292fdb",
            "title": "Chasing Sparsity in Vision Transformers: An End-to-End Exploration"
        },
        {
            "paperId": "9c4dd36ad206ca8be96ae4000568e899f4acfa91",
            "title": "Top-KAST: Top-K Always Sparse Training"
        },
        {
            "paperId": "1ee1160b8c7c70ded02e786c184a6da651e88bed",
            "title": "Dynamic Head: Unifying Object Detection Heads with Attentions"
        },
        {
            "paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60",
            "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"
        },
        {
            "paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de",
            "title": "Pay Attention to MLPs"
        },
        {
            "paperId": "c7650fe09c2b34e43646e785e09aefe290247e52",
            "title": "Are Convolutional Neural Networks or Transformers more like human vision?"
        },
        {
            "paperId": "48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5",
            "title": "ResMLP: Feedforward Networks for Image Classification With Data-Efficient Training"
        },
        {
            "paperId": "67571d29190faea9fbd104acd16274f8c4edf254",
            "title": "MLP-Mixer: An all-MLP Architecture for Vision"
        },
        {
            "paperId": "6709d5583f658f589ae6a2184805933aceb18849",
            "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"
        },
        {
            "paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325",
            "title": "Going deeper with Image Transformers"
        },
        {
            "paperId": "91e8117e7ebc966bc76de2cb52ec717d2acdb1a4",
            "title": "Scaling Local Self-Attention for Parameter Efficient Visual Backbones"
        },
        {
            "paperId": "610b302950a19acef1c45456111dcd495f638c18",
            "title": "ConViT: improving vision transformers with soft convolutional inductive biases"
        },
        {
            "paperId": "fbd730a948a06cd4918c1d632ffdb4572b52d99b",
            "title": "Involution: Inverting the Inherence of Convolution for Visual Recognition"
        },
        {
            "paperId": "0ae67202f0584afccefa770865d14a46655d2975",
            "title": "Transformer in Transformer"
        },
        {
            "paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881",
            "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"
        },
        {
            "paperId": "b4d207a2096aee4a3764933373eef6edb574c952",
            "title": "Accelerated Sparse Neural Training: A Provable and Efficient Method to Find N: M Transposable Masks"
        },
        {
            "paperId": "5e38dc1ccf33ac1df09b8eb6476f110cb3d1966f",
            "title": "Learning N: M Fine-grained Structured Sparse Neural Networks From Scratch"
        },
        {
            "paperId": "1d5c8c6e5a774d2fef8d92bd28670a6345a97f7a",
            "title": "CKConv: Continuous Kernel Convolution For Sequential Data"
        },
        {
            "paperId": "78d17d2ee5ed0a4b3a48e0ed76376491035d47c2",
            "title": "Do We Actually Need Dense Over-Parameterization? In-Time Over-Parameterization in Sparse Training"
        },
        {
            "paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9",
            "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"
        },
        {
            "paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71",
            "title": "Training data-efficient image transformers & distillation through attention"
        },
        {
            "paperId": "787119e3c3f819244c82b7d97779473773e60696",
            "title": "MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers"
        },
        {
            "paperId": "2ac7999cce9f415ee87643f56631b55ed26aa10e",
            "title": "End-to-End Video Instance Segmentation with Transformers"
        },
        {
            "paperId": "6d5f423164cd5ef9324281652987c8a65009e98e",
            "title": "Sparse R-CNN: End-to-End Object Detection with Learnable Proposals"
        },
        {
            "paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
        },
        {
            "paperId": "70e9a09de05aa7ed8a74d56cf2d13ea9e38a6328",
            "title": "Sparse GPU Kernels for Deep Learning"
        },
        {
            "paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e",
            "title": "End-to-End Object Detection with Transformers"
        },
        {
            "paperId": "2e3002f131e1815bda7a10303eff97f79dea01ec",
            "title": "Rigging the Lottery: Making All Tickets Winners"
        },
        {
            "paperId": "db2d3dc613169b519f1a2dd35e0473dc2e848025",
            "title": "Fast Sparse ConvNets"
        },
        {
            "paperId": "150f1260a3b73866865626a0e99b486242d32fc9",
            "title": "Computing Receptive Fields of Convolutional Neural Networks"
        },
        {
            "paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39",
            "title": "Randaugment: Practical automated data augmentation with a reduced search space"
        },
        {
            "paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06",
            "title": "Axial Attention in Multidimensional Transformers"
        },
        {
            "paperId": "f14469790532b5136d283a1b46c6c47a50dbbc79",
            "title": "ACNet: Strengthening the Kernel Skeletons for Powerful CNN via Asymmetric Convolution Blocks"
        },
        {
            "paperId": "60ed82ca3ec8fbfef4d52e98e49ab687ce501a0c",
            "title": "Sparse Networks from Scratch: Faster Training without Losing Performance"
        },
        {
            "paperId": "c2c083df88e88223e1a411e61040b94c233b1b63",
            "title": "MMDetection: Open MMLab Detection Toolbox and Benchmark"
        },
        {
            "paperId": "d6dccb5d71fbb6f5765f89633ba3a8e6809a720d",
            "title": "Stand-Alone Self-Attention in Vision Models"
        },
        {
            "paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9",
            "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"
        },
        {
            "paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c",
            "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"
        },
        {
            "paperId": "8e2c65ff58b28a076883c99b96840e19b5e0b916",
            "title": "Parameter Efficient Training of Deep Convolutional Neural Networks by Dynamic Sparse Reparameterization"
        },
        {
            "paperId": "c37a1110d007a6c6a1e536527504eca5953a51f7",
            "title": "Sparse evolutionary deep learning with over one million artificial neurons on commodity hardware"
        },
        {
            "paperId": "6e3c56010e987b1f7b0ebc64d93d0442948cf389",
            "title": "Random Graphs"
        },
        {
            "paperId": "cf440ccce4a7a8681e238b4f26d5b95109add55d",
            "title": "SNIP: Single-shot Network Pruning based on Connection Sensitivity"
        },
        {
            "paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1",
            "title": "Unified Perceptual Parsing for Scene Understanding"
        },
        {
            "paperId": "b8989afff14fb630ca58b6afa917fb42574228ee",
            "title": "Averaging Weights Leads to Wider Optima and Better Generalization"
        },
        {
            "paperId": "21937ecd9d66567184b83eca3d3e09eb4e6fbd60",
            "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"
        },
        {
            "paperId": "f6195d8dc6aad8231e97b563246f2585842bc68b",
            "title": "Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs"
        },
        {
            "paperId": "04957e40d47ca89d38653e97f728883c0ad26e5d",
            "title": "Cascade R-CNN: Delving Into High Quality Object Detection"
        },
        {
            "paperId": "d07284a6811f1b2745d91bdb06b040b57f226882",
            "title": "Decoupled Weight Decay Regularization"
        },
        {
            "paperId": "ccee800244908d2960830967e70ead7dd8266f7a",
            "title": "Deep Rewiring: Training very sparse deep networks"
        },
        {
            "paperId": "4feef0fd284feb1233399b400eb897f59ec92755",
            "title": "mixup: Beyond Empirical Risk Minimization"
        },
        {
            "paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341",
            "title": "Random Erasing Data Augmentation"
        },
        {
            "paperId": "6dbb9e4b2e3b67dc4e1634989511f67d41373dd0",
            "title": "Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e",
            "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"
        },
        {
            "paperId": "1a0912bb76777469295bb2c059faee907e7f3258",
            "title": "Mask R-CNN"
        },
        {
            "paperId": "3617ccfec4bed2d8ac15d0ad1a35b589d9b270cb",
            "title": "Large Kernel Matters \u2014 Improve Semantic Segmentation by Global Convolutional Network"
        },
        {
            "paperId": "2a94c84383ee3de5e6211d43d16e7de387f68878",
            "title": "Feature Pyramid Networks for Object Detection"
        },
        {
            "paperId": "01a4f33da8ad94ced3cf58548b28dbbb44148571",
            "title": "Understanding the Effective Receptive Field in Deep Convolutional Neural Networks"
        },
        {
            "paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c",
            "title": "Aggregated Residual Transformations for Deep Neural Networks"
        },
        {
            "paperId": "5694e46284460a648fe29117cbc55f6c9be3fa3c",
            "title": "Densely Connected Convolutional Networks"
        },
        {
            "paperId": "88512be44744615f4baa8e14f600f036db4c2433",
            "title": "Semantic Understanding of Scenes Through the ADE20K Dataset"
        },
        {
            "paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111",
            "title": "Deep Networks with Stochastic Depth"
        },
        {
            "paperId": "b5c26ab8767d046cb6e32d959fdf726aee89bb62",
            "title": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning"
        },
        {
            "paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "title": "Deep Residual Learning for Image Recognition"
        },
        {
            "paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58",
            "title": "Rethinking the Inception Architecture for Computer Vision"
        },
        {
            "paperId": "642d0f49b7826adcf986616f4af77e736229990f",
            "title": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"
        },
        {
            "paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
            "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"
        },
        {
            "paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327",
            "title": "Going deeper with convolutions"
        },
        {
            "paperId": "eb42cf88027de515750f230b23b1a057dc782108",
            "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
        },
        {
            "paperId": "71b7178df5d2b112d07e45038cb5637208659ff7",
            "title": "Microsoft COCO: Common Objects in Context"
        },
        {
            "paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "title": "ImageNet classification with deep convolutional neural networks"
        },
        {
            "paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e",
            "title": "ImageNet: A large-scale hierarchical image database"
        },
        {
            "paperId": "bc6dff14a130c57a91d5a21339c23471faf1d46f",
            "title": "Et al"
        },
        {
            "paperId": "99c4904813bc5e23d5bdcfc984adeba151a098da",
            "title": "Cognitive neuroscience: Primary visual cortex and visual awareness"
        },
        {
            "paperId": "409243d8e00d82754933020346c59eae72cf6371",
            "title": "Sparse coding and decorrelation in primary visual cortex during natural vision."
        },
        {
            "paperId": "2805537bec87a6177037b18f9a3a9d3f1038867b",
            "title": "Sparse coding with an overcomplete basis set: A strategy employed by V1?"
        },
        {
            "paperId": "6dc61f37ecc552413606d8c89ffbc46ec98ed887",
            "title": "Acceleration of stochastic approximation by averaging"
        },
        {
            "paperId": "3806035a1b7cda42562453587afdb479dc2f5d7a",
            "title": "On Seeing Sidelong"
        },
        {
            "paperId": "fda9a8f0664456dc4accb4018cfad2e6fde2d460",
            "title": "Revisiting Pruning at Initialization Through the Lens of Ramanujan Graph"
        },
        {
            "paperId": "fcff2246e2b8c143a3262e60dcba8620cc32b61a",
            "title": "Scaling up Kernels in 3D CNNs"
        },
        {
            "paperId": "86ee946179119b65c57171d8a2ddaa1eebc0e7ed",
            "title": "Exposing and Exploiting Fine-Grained Block Structures for Fast and Accurate Sparse Training"
        },
        {
            "paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7",
            "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"
        },
        {
            "paperId": null,
            "title": "grow new weights by randomly sampling following (Mocanu et al., 2018)"
        },
        {
            "paperId": null,
            "title": "Megengine:a fast, scalable and easy-to-use deep learning framework"
        },
        {
            "paperId": null,
            "title": "MMSegmentation Contributors"
        },
        {
            "paperId": null,
            "title": "Nvidia a100 tensor core gpu architecture"
        },
        {
            "paperId": null,
            "title": "GitHub repository: Pytorch image models"
        },
        {
            "paperId": "13ef25201af7f2a7e401ef31a6197f66357f6f01",
            "title": "The PASCAL Visual Object Classes Challenge"
        },
        {
            "paperId": null,
            "title": "The PASCAL visual object classes challenge 2006 (VOC2006) results"
        },
        {
            "paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "title": "Gradient-based learning applied to document recognition"
        },
        {
            "paperId": "5d2ef51c912df93d31314d6827a98bc474374105",
            "title": "Neural mechanisms of selective visual attention."
        },
        {
            "paperId": "f8830ea439ca695e7dd848275e534f1024c2fe8a",
            "title": "Using Relevance to Reduce Network Size Automatically"
        },
        {
            "paperId": "86ab4cae682fbd49c5a5bedb630e5a40fa7529f6",
            "title": "Handwritten Digit Recognition with a Back-Propagation Network"
        },
        {
            "paperId": "9b2541b8d8ca872149b4dabd2ccdc0cacc46ebf5",
            "title": "Neocognitron: A Self-Organizing Neural Network Model for a Mechanism of Visual Pattern Recognition"
        },
        {
            "paperId": "73f36ff3a6d340606e09d2d0091da27a13af7a6f",
            "title": "and as an in"
        },
        {
            "paperId": "12b03af504d0960334c77567dab38791bf0f739a",
            "title": "AND T"
        },
        {
            "paperId": null,
            "title": "A.2 SEMANTIC SEGMENTATION ON ADE20K"
        },
        {
            "paperId": null,
            "title": "Section B. Full details of dynamic sparsity"
        },
        {
            "paperId": null,
            "title": "Comparison between CSwin Transforms and SLaK on ImageNet classification"
        },
        {
            "paperId": null,
            "title": "Details of experimental settings, hyperparameters, and configurations used in this paper"
        },
        {
            "paperId": null,
            "title": "Section D. The sparsity-width trade-off in \"use sparse group, expand more"
        },
        {
            "paperId": null,
            "title": "2018) for 80K/160K iterations, respectively. We report the mean Intersection over Union (mIoU) with a single scale"
        }
    ]
}