{
    "paperId": "38ab111767ade8344d8aa3ab142e42e81428eb3a",
    "externalIds": {
        "DBLP": "conf/eurocolt/KoiranS97",
        "MAG": "2053955420",
        "DOI": "10.1016/S0166-218X(98)00014-6",
        "CorpusId": 8899189
    },
    "title": "Vapnik-Chervonenkis Dimension of Recurrent Neural Networks",
    "abstract": null,
    "venue": "Discrete Applied Mathematics",
    "year": 1997,
    "referenceCount": 23,
    "citationCount": 75,
    "influentialCitationCount": 7,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Lower and upper bounds for the VC dimension of recurrent networks, which are widely used in learning applications, are provided, including threshold, polynomial, piecewise-polynomial and sigmoidal functions."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "1710207",
            "name": "P. Koiran"
        },
        {
            "authorId": "1790264",
            "name": "Eduardo Sontag"
        }
    ],
    "references": [
        {
            "paperId": "fd6d6783eb5ee9728fb945c6376cff53e02844ad",
            "title": "Polynomial Bounds for VC Dimension of Sigmoidal and General Pfaffian Neural Networks"
        },
        {
            "paperId": "37265d17e67a76ca6063bd7e56bb5b7973947c57",
            "title": "VC Dimension of an Integrate-and-Fire Neuron Model"
        },
        {
            "paperId": "7363600ced1e7d64c1fe54f42e0998cfe72a4759",
            "title": "Neural Networks with Quadratic VC Dimension"
        },
        {
            "paperId": "ab0661577396ecc449764619b63bf1618d270ba4",
            "title": "Sample complexity for learning recurrent perceptron mappings"
        },
        {
            "paperId": "39ebcd1e604ae888f8d1b1fb2f0955fbe5f13df4",
            "title": "Polynomial bounds for VC dimension of sigmoidal neural networks"
        },
        {
            "paperId": "94d43b9ba85a57523c9b553dd5ca645aa5716d03",
            "title": "Bounding the Vapnik-Chervonenkis Dimension of Concept Classes Parameterized by Real Numbers"
        },
        {
            "paperId": "93aaf126443643fb0835df896ab07b523f2c9613",
            "title": "Analog computation via neural networks"
        },
        {
            "paperId": "a5c04f0b1962c3ab1075091c2a5798b6a48a3401",
            "title": "Feedforward Nets for Interpolation and Classification"
        },
        {
            "paperId": "17594df98c222217a11510dd454ba52a5a737378",
            "title": "On the computational power of neural nets"
        },
        {
            "paperId": "63de40bad0b400cddb88ec11bb0a875b4f488fe1",
            "title": "The Adaptive Brain"
        },
        {
            "paperId": "e0b8fa3496283d4d808fba9ff62d5f024bcf23be",
            "title": "Learnability and the Vapnik-Chervonenkis dimension"
        },
        {
            "paperId": "98b4d4e24aab57ab4e1124ff8106909050645cfa",
            "title": "Neural networks and physical systems with emergent collective computational abilities."
        },
        {
            "paperId": "a02df6b956612047a9493baba5218f01ed44af00",
            "title": "Neural networks for speech and sequence recognition"
        },
        {
            "paperId": "af4214eff5619705a88e7d6231dd323203282873",
            "title": "NEURAL NETS AS SYSTEMS MODELS AND CONTROLLERS"
        },
        {
            "paperId": null,
            "title": "Neural networks and on-line approximators for adaptive control"
        },
        {
            "paperId": "fac65d27c83dd9645cfb769e74440ed5fcdaee16",
            "title": "Mathematical Control Theory: Deterministic Finite Dimensional Systems"
        },
        {
            "paperId": null,
            "title": "A state-space approach to adaptive nonlinear ltering using re current neural networks,"
        },
        {
            "paperId": "25406e6733a698bfc4ac836f8e74f458e75dad4f",
            "title": "What Size Net Gives Valid Generalization?"
        },
        {
            "paperId": "25c19c8c1d6778a16f8b27beac4d9c6a55357580",
            "title": "Higher Order Recurrent Networks and Grammatical Inference"
        },
        {
            "paperId": null,
            "title": "Cover, \\Capacity problems for linear machines"
        },
        {
            "paperId": null,
            "title": "This article was processed using the L A T E X macro package with LLNCS style"
        },
        {
            "paperId": null,
            "title": "This gap is even bigger for the standard sigmoid: O(k 2 w 4 ) versus (cid:10)(kw)"
        },
        {
            "paperId": null,
            "title": "threshold architectures"
        }
    ]
}