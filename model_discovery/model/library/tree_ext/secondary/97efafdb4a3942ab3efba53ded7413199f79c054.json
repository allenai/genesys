{
    "paperId": "97efafdb4a3942ab3efba53ded7413199f79c054",
    "externalIds": {
        "MAG": "2121863487",
        "DBLP": "journals/tnn/SuttonB98",
        "DOI": "10.1109/TNN.1998.712192",
        "CorpusId": 60035920
    },
    "title": "Reinforcement Learning: An Introduction",
    "abstract": "Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability. The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.",
    "venue": "IEEE Trans. Neural Networks",
    "year": 1998,
    "referenceCount": 455,
    "citationCount": 33474,
    "influentialCitationCount": 5219,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This book provides a clear and simple account of the key ideas and algorithms of reinforcement learning, which ranges from the history of the field's intellectual foundations to the most recent developments and applications."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -1.438429594039917,
            1.206052541732788,
            1.3267934322357178,
            4.63269567489624,
            -0.5946975946426392,
            2.8468706607818604,
            4.483414173126221,
            -4.832252502441406,
            -0.8127360939979553,
            -0.8292290568351746,
            0.16945713758468628,
            3.9212136268615723,
            0.7475770711898804,
            -4.645493030548096,
            -1.9611347913742065,
            0.6368145942687988,
            1.0938117504119873,
            -1.1868104934692383,
            4.721580505371094,
            1.5286214351654053,
            -0.13455648720264435,
            2.674377918243408,
            -3.0757060050964355,
            -4.60455322265625,
            -1.097145915031433,
            1.19342839717865,
            3.5823750495910645,
            -1.5375914573669434,
            -3.743837833404541,
            1.8818656206130981,
            -1.7054288387298584,
            -2.488363742828369,
            5.275186538696289,
            -2.443535089492798,
            3.733464241027832,
            -3.0198891162872314,
            -4.997430801391602,
            3.441925048828125,
            1.7211594581604004,
            0.21294498443603516,
            1.253987431526184,
            2.521991729736328,
            2.6613478660583496,
            -0.17215465009212494,
            2.0609402656555176,
            0.38305211067199707,
            -0.07848438620567322,
            2.443474292755127,
            2.043026924133301,
            0.7734050154685974,
            0.5373871326446533,
            0.7210447788238525,
            -1.9300168752670288,
            2.163710117340088,
            4.433075904846191,
            1.9102625846862793,
            4.293689727783203,
            -1.4415464401245117,
            2.045783519744873,
            -0.7909403443336487,
            2.2134995460510254,
            2.8744168281555176,
            -0.7200255393981934,
            0.32530832290649414,
            2.9544858932495117,
            -3.9316349029541016,
            -0.14525508880615234,
            1.1891086101531982,
            2.7458906173706055,
            4.182613372802734,
            -1.325958013534546,
            -6.388998985290527,
            1.0091605186462402,
            -3.3490047454833984,
            -3.9811830520629883,
            1.0723649263381958,
            -0.28594523668289185,
            -3.9033894538879395,
            0.478196918964386,
            -0.5916274785995483,
            0.24727416038513184,
            0.44834935665130615,
            -0.06268566846847534,
            -2.3304009437561035,
            4.124172210693359,
            1.718061923980713,
            -0.7440450191497803,
            -2.0495479106903076,
            -0.28666287660598755,
            -1.2022349834442139,
            -0.5306429862976074,
            0.37260234355926514,
            1.6552823781967163,
            1.3480340242385864,
            -0.4205141067504883,
            1.1799688339233398,
            0.6980689764022827,
            0.5838102698326111,
            -2.4647774696350098,
            1.9362105131149292,
            1.0061860084533691,
            1.1606810092926025,
            4.656966209411621,
            0.4906176030635834,
            3.970123052597046,
            -1.5624001026153564,
            4.736210823059082,
            3.5379199981689453,
            2.950096607208252,
            -2.7821269035339355,
            -0.5250778198242188,
            3.0634279251098633,
            -1.6218518018722534,
            -2.1079375743865967,
            3.5977015495300293,
            4.092666149139404,
            -0.5196037292480469,
            1.1214340925216675,
            0.4642391502857208,
            3.974285840988159,
            -2.35109281539917,
            -1.9628267288208008,
            -0.6155198812484741,
            1.3315867185592651,
            -2.32086181640625,
            -1.978983759880066,
            -0.33082008361816406,
            -0.6096552610397339,
            0.1790044903755188,
            -1.1938080787658691,
            2.981142282485962,
            0.9173446893692017,
            -0.6203498840332031,
            0.5969623327255249,
            2.5886476039886475,
            3.874048948287964,
            -2.715114116668701,
            -1.1938633918762207,
            -0.2567800283432007,
            2.6301443576812744,
            -4.414247989654541,
            2.4048690795898438,
            -0.17323672771453857,
            -0.820274293422699,
            0.3507441580295563,
            4.343667030334473,
            1.9665765762329102,
            -0.04596138000488281,
            -1.0900671482086182,
            -0.5939050912857056,
            1.507876992225647,
            -0.6268925070762634,
            2.90425181388855,
            -0.42479994893074036,
            5.892727375030518,
            2.009453296661377,
            -4.708928108215332,
            3.19225811958313,
            -1.7806458473205566,
            1.529561996459961,
            1.1770429611206055,
            -0.49977463483810425,
            -6.537458896636963,
            -1.6592661142349243,
            0.3547179400920868,
            -4.541199207305908,
            0.09760922193527222,
            1.516548752784729,
            -1.0844752788543701,
            0.9168100953102112,
            -1.1011059284210205,
            1.4773919582366943,
            2.2241225242614746,
            4.83466100692749,
            4.759765148162842,
            0.916671097278595,
            0.07318377494812012,
            -0.548189103603363,
            3.9773807525634766,
            1.7140920162200928,
            -2.331270694732666,
            -1.2438805103302002,
            -2.2764763832092285,
            -4.709048271179199,
            -5.717070579528809,
            -3.220710277557373,
            -1.165691614151001,
            -0.2386069893836975,
            2.8977773189544678,
            3.2947964668273926,
            -1.3611215353012085,
            1.165687918663025,
            0.7450206279754639,
            3.822953462600708,
            2.708564519882202,
            1.91851806640625,
            0.5455660820007324,
            1.4686834812164307,
            -1.6742148399353027,
            -1.029947280883789,
            2.390209197998047,
            -0.950032114982605,
            1.616713047027588,
            -3.2410106658935547,
            2.3529410362243652,
            -2.6279633045196533,
            -0.23630058765411377,
            3.278104305267334,
            -1.4984830617904663,
            0.977972149848938,
            -0.7444726228713989,
            -0.9657261967658997,
            -1.4446988105773926,
            -1.6837482452392578,
            -4.32888650894165,
            -1.0319676399230957,
            -3.395833969116211,
            -0.5121088027954102,
            4.396744728088379,
            0.37731218338012695,
            0.023947983980178833,
            2.547999858856201,
            -2.4866268634796143,
            2.227994441986084,
            3.7806239128112793,
            -0.17385008931159973,
            1.2955700159072876,
            0.04894459247589111,
            2.3286561965942383,
            0.1359826773405075,
            -4.788349151611328,
            -2.0395843982696533,
            1.4968011379241943,
            0.5049772262573242,
            1.3713552951812744,
            -2.452939987182617,
            -3.9568064212799072,
            -1.1466102600097656,
            2.219496250152588,
            4.608862400054932,
            1.094292402267456,
            -1.3373316526412964,
            -0.3869165778160095,
            2.455233097076416,
            -2.255441188812256,
            0.21538153290748596,
            -0.5583633780479431,
            0.5662260055541992,
            -0.702784538269043,
            -1.7618588209152222,
            0.017719805240631104,
            -1.84706449508667,
            0.6022647619247437,
            2.630333423614502,
            2.627478837966919,
            4.994945049285889,
            -1.149904489517212,
            0.5870553255081177,
            1.1750257015228271,
            3.964876890182495,
            1.373615026473999,
            1.723922610282898,
            -2.635180950164795,
            -0.6940048933029175,
            1.2864588499069214,
            0.33698898553848267,
            -3.007748603820801,
            -1.5671043395996094,
            -4.404783248901367e-05,
            -0.6382385492324829,
            0.17716753482818604,
            0.10498571395874023,
            -1.6662390232086182,
            -6.3795695304870605,
            -1.1284310817718506,
            -2.1502339839935303,
            -0.6531460285186768,
            -2.2816030979156494,
            1.3373432159423828,
            2.6634607315063477,
            1.9664839506149292,
            -2.1126132011413574,
            2.1549134254455566,
            -3.3642539978027344,
            -2.2402162551879883,
            -3.944287061691284,
            0.21760091185569763,
            2.3289029598236084,
            1.259231448173523,
            -0.6907899975776672,
            -2.9481170177459717,
            5.157966136932373,
            -3.3867149353027344,
            3.354398250579834,
            -1.1172890663146973,
            2.482651710510254,
            3.8945155143737793,
            -0.6036251187324524,
            -0.869598388671875,
            -2.403691530227661,
            1.1111724376678467,
            -0.5719040036201477,
            2.847325325012207,
            -0.16993293166160583,
            0.3512902855873108,
            4.646875381469727,
            3.3018388748168945,
            -0.22925567626953125,
            -1.7152941226959229,
            -1.8529150485992432,
            4.218508720397949,
            -0.32838892936706543,
            6.672399997711182,
            -3.1441097259521484,
            -1.6663169860839844,
            -5.603201389312744,
            -3.511249542236328,
            1.3490455150604248,
            -2.48067307472229,
            3.218820333480835,
            -2.358319044113159,
            -2.775609016418457,
            -1.2046873569488525,
            -3.307697057723999,
            -0.19635283946990967,
            2.13700532913208,
            -1.1396945714950562,
            -3.893666982650757,
            2.168776035308838,
            -0.7103822231292725,
            -2.589646816253662,
            3.4856467247009277,
            2.7678654193878174,
            4.932661056518555,
            1.3561644554138184,
            -4.540693283081055,
            -1.4913629293441772,
            -2.607684373855591,
            0.6380801796913147,
            1.259871482849121,
            0.29513439536094666,
            8.968833923339844,
            0.893431544303894,
            0.6865553259849548,
            -2.3301842212677,
            2.476500988006592,
            -0.5770149230957031,
            0.5294941067695618,
            1.0720837116241455,
            0.8195465207099915,
            -0.09961634874343872,
            1.5110037326812744,
            -0.08080123364925385,
            -2.985714912414551,
            4.820061206817627,
            1.9892284870147705,
            3.2280285358428955,
            2.018901824951172,
            -2.421189308166504,
            2.7945139408111572,
            -0.768166720867157,
            2.8408780097961426,
            0.6702308654785156,
            -0.9901365637779236,
            -1.513674020767212,
            -2.4380910396575928,
            7.8422393798828125,
            2.0295937061309814,
            -0.49765336513519287,
            -4.0028767585754395,
            -1.022186040878296,
            -0.5579917430877686,
            -3.179368495941162,
            0.23120126128196716,
            0.43504592776298523,
            -4.80888032913208,
            -0.789068341255188,
            -2.709787368774414,
            3.704918146133423,
            0.34262681007385254,
            -2.21514892578125,
            3.8739571571350098,
            -2.5872139930725098,
            3.318488597869873,
            0.381134033203125,
            -1.078526258468628,
            0.025341123342514038,
            -1.9868409633636475,
            -3.172870635986328,
            1.849259376525879,
            -0.2643700838088989,
            1.1536157131195068,
            1.1428624391555786,
            1.4010072946548462,
            0.8320156931877136,
            -4.062711715698242,
            -1.9470884799957275,
            -0.8016268610954285,
            -2.8439438343048096,
            -0.8627877235412598,
            -4.941191673278809,
            3.648430824279785,
            4.2512431144714355,
            0.5382094383239746,
            -0.8594459295272827,
            -2.2890076637268066,
            2.8248069286346436,
            -0.06725633144378662,
            -2.5040946006774902,
            3.0569887161254883,
            -0.47337228059768677,
            -0.08879852294921875,
            -3.354310989379883,
            -3.8140666484832764,
            -0.2874065637588501,
            -2.162625789642334,
            -0.4649890959262848,
            2.4597253799438477,
            2.191348075866699,
            2.4308741092681885,
            -1.047332525253296,
            -0.15658898651599884,
            8.664498329162598,
            5.577906608581543,
            -1.7461910247802734,
            2.54050350189209,
            -1.8553507328033447,
            -0.4217334985733032,
            -3.875491142272949,
            1.970890998840332,
            -3.589536190032959,
            3.1682276725769043,
            -3.931640386581421,
            3.4511396884918213,
            3.537785291671753,
            -2.0741443634033203,
            2.2024831771850586,
            2.184730291366577,
            1.33522629737854,
            -2.086655616760254,
            -2.2916550636291504,
            0.48624515533447266,
            -2.4856114387512207,
            1.4358246326446533,
            1.3124070167541504,
            -0.8713322877883911,
            -0.9925680756568909,
            0.6335093975067139,
            1.5250842571258545,
            -2.118459701538086,
            0.8797513246536255,
            0.11984947323799133,
            -4.666699409484863,
            -1.503861904144287,
            -0.2553420066833496,
            0.5187968611717224,
            -0.2589080333709717,
            -5.963469505310059,
            1.240789771080017,
            -1.7444067001342773,
            -2.055332660675049,
            0.1471654623746872,
            -0.7546144127845764,
            2.606907844543457,
            -1.3340522050857544,
            1.1262340545654297,
            -0.3272266387939453,
            0.8868730068206787,
            0.33848971128463745,
            0.12530747056007385,
            1.7240630388259888,
            -1.2615097761154175,
            -5.931241989135742,
            -2.389430522918701,
            1.6400028467178345,
            2.1017279624938965,
            0.009061276912689209,
            3.1590237617492676,
            1.4863677024841309,
            -0.5475650429725647,
            -1.5679481029510498,
            -0.7834217548370361,
            3.9899485111236572,
            1.4007713794708252,
            -3.0942745208740234,
            2.446704864501953,
            0.6738842725753784,
            2.1213130950927734,
            1.2350801229476929,
            -0.46091657876968384,
            -0.09485550224781036,
            0.49704697728157043,
            5.980566501617432,
            -0.15631639957427979,
            -3.7901253700256348,
            -0.21701490879058838,
            -1.9057018756866455,
            3.709951162338257,
            4.196605205535889,
            0.38391247391700745,
            2.290940761566162,
            -3.239107131958008,
            4.0125932693481445,
            -1.820902943611145,
            1.0983399152755737,
            1.554471492767334,
            1.6315561532974243,
            0.19929349422454834,
            -1.9075660705566406,
            2.5764949321746826,
            -2.4071621894836426,
            0.3751356303691864,
            -5.768162727355957,
            1.6733179092407227,
            -3.1993768215179443,
            -0.8462994694709778,
            3.2296998500823975,
            -0.4955710172653198,
            -0.49620547890663147,
            -1.3789896965026855,
            3.7079086303710938,
            -5.1554718017578125,
            0.6492832899093628,
            1.751633644104004,
            -0.8654686808586121,
            0.504954993724823,
            -3.897428035736084,
            4.1179046630859375,
            -0.6230573654174805,
            3.9921233654022217,
            5.138706684112549,
            0.6827556490898132,
            2.920003890991211,
            1.0426596403121948,
            -1.365150809288025,
            2.30509877204895,
            2.7704436779022217,
            2.2942867279052734,
            -3.4919071197509766,
            0.32926642894744873,
            1.1024384498596191,
            2.5975232124328613,
            -3.516728401184082,
            -0.8412299752235413,
            2.7104382514953613,
            -3.0208985805511475,
            -4.770516395568848,
            -0.8191899657249451,
            -1.6214467287063599,
            -1.596105933189392,
            1.385887622833252,
            -3.759589672088623,
            5.25519323348999,
            -2.880849599838257,
            -3.155717372894287,
            0.4699528217315674,
            2.2223124504089355,
            -1.8969433307647705,
            -2.053767204284668,
            4.728565216064453,
            -1.101987361907959,
            0.5969144105911255,
            -4.4904680252075195,
            1.4633665084838867,
            -4.183333396911621,
            0.26657184958457947,
            2.4636430740356445,
            1.5658338069915771,
            -3.5948567390441895,
            -1.1148985624313354,
            0.12204644083976746,
            1.3777486085891724,
            0.29687392711639404,
            -1.1224069595336914,
            -0.5922377109527588,
            2.8862850666046143,
            5.539628028869629,
            2.3618860244750977,
            -2.044610023498535,
            3.3738479614257812,
            2.506894111633301,
            -3.480607748031616,
            -2.1827585697174072,
            -2.941786050796509,
            -1.3624416589736938,
            -1.2559459209442139,
            -1.4687278270721436,
            0.16520708799362183,
            -3.5767951011657715,
            -1.0112322568893433,
            0.6176763772964478,
            1.6304988861083984,
            -0.9179402589797974,
            -4.816070556640625,
            -0.7009745836257935,
            -3.891005039215088,
            -0.8395893573760986,
            3.8179068565368652,
            -1.4760375022888184,
            2.789186954498291,
            1.1288284063339233,
            1.7782878875732422,
            -0.7085795402526855,
            0.15517888963222504,
            0.046775057911872864,
            0.7616029977798462,
            0.2218824028968811,
            1.1024962663650513,
            0.8151463866233826,
            2.695138931274414,
            0.29890596866607666,
            0.601058840751648,
            16.04050064086914,
            1.2151312828063965,
            -0.7483922243118286,
            1.0154350996017456,
            -3.571284770965576,
            -4.8024797439575195,
            -3.6775062084198,
            2.186678409576416,
            3.1343541145324707,
            5.01959228515625,
            0.3385399281978607,
            -2.809192657470703,
            -1.3559232950210571,
            -0.6709903478622437,
            -1.313759684562683,
            -2.659435749053955,
            -2.741598129272461,
            3.5931310653686523,
            0.20514419674873352,
            0.3328479528427124,
            -0.46379995346069336,
            -1.214496374130249,
            2.6474812030792236,
            -1.7894890308380127,
            1.685563564300537,
            4.0945587158203125,
            -0.3286726176738739,
            -1.0018115043640137,
            -3.581624746322632,
            3.3658690452575684,
            -0.09427708387374878,
            -0.6739283800125122,
            -0.17198415100574493,
            0.807863712310791,
            -3.4538562297821045,
            0.04752715677022934,
            5.684309959411621,
            -0.8832073211669922,
            1.8064720630645752,
            -1.3210076093673706,
            -0.4317869544029236,
            -3.2752299308776855,
            -1.6434192657470703,
            -0.7360088229179382,
            -0.5262571573257446,
            -1.1648046970367432,
            -0.48922616243362427,
            -0.38528719544410706,
            -2.0084228515625,
            5.135340690612793,
            -1.0451909303665161,
            -3.0226800441741943,
            -3.468043565750122,
            1.1511845588684082,
            0.440130352973938,
            0.30990421772003174,
            2.3961000442504883,
            -2.0344772338867188,
            -1.2594044208526611,
            -0.7826674580574036,
            2.320582389831543,
            -0.027022838592529297,
            -0.8395538330078125,
            -5.668017387390137,
            -2.044837713241577,
            -3.412202835083008,
            -1.812708854675293,
            1.411261796951294,
            1.6949291229248047,
            1.5549638271331787,
            -3.140957832336426,
            1.9949473142623901,
            -1.2977064847946167,
            -4.326331615447998,
            -0.2728291451931,
            -4.966748237609863,
            -0.7857587933540344,
            -2.5904085636138916,
            1.3943941593170166,
            3.0774993896484375,
            -1.1495461463928223,
            0.9230817556381226,
            -1.8256570100784302,
            -1.4673278331756592,
            1.6693036556243896,
            -2.703338623046875,
            2.438711404800415,
            -2.5083746910095215,
            -3.164134979248047,
            1.8381304740905762,
            1.0054750442504883,
            -2.8009350299835205,
            3.6095051765441895,
            1.140080213546753,
            0.12074780464172363,
            -3.2693288326263428,
            -1.887725830078125,
            3.1551389694213867,
            -6.133376121520996,
            -1.7037444114685059,
            1.616782307624817,
            1.7107658386230469,
            1.2606985569000244,
            1.5640047788619995,
            -0.413836807012558,
            1.5679872035980225,
            1.8562264442443848,
            -4.23326301574707,
            -5.928700923919678,
            -2.3306334018707275,
            0.16771124303340912,
            0.6816076636314392,
            -4.452835559844971,
            -0.6699032783508301,
            -0.21540851891040802,
            1.236896276473999,
            -0.32445836067199707,
            5.090890884399414,
            -1.0418709516525269,
            4.201669692993164,
            1.1355533599853516,
            0.36725056171417236,
            0.11728483438491821,
            -3.4722366333007812,
            0.9551519751548767,
            -2.543646812438965,
            2.0388023853302,
            -1.7651779651641846,
            2.480283737182617,
            -0.5721498727798462,
            0.3997954726219177,
            -3.049431324005127,
            -0.21730110049247742,
            -1.3987205028533936,
            -3.229814291000366,
            0.36021921038627625,
            2.9634292125701904,
            -0.8918638229370117,
            -0.5263079404830933,
            5.455836296081543,
            1.017879843711853,
            0.24763157963752747,
            -1.0469169616699219,
            7.177441596984863,
            -3.9043631553649902,
            0.7789189219474792,
            2.843233585357666,
            0.689141571521759,
            -1.8542214632034302,
            1.9222462177276611,
            0.06051844358444214,
            -0.2690465450286865,
            1.6011474132537842,
            1.1884669065475464,
            0.5448197722434998,
            -4.293185234069824
        ]
    },
    "authors": [
        {
            "authorId": "2238176724",
            "name": "R. S. Sutton"
        },
        {
            "authorId": "1730590",
            "name": "A. Barto"
        }
    ],
    "references": [
        {
            "paperId": "78020db7e3d968f6e6cc26d18e31e5b668ca7fee",
            "title": "Eligibility Traces for Off-Policy Policy Evaluation"
        },
        {
            "paperId": "dd6960d576da0d769ca30de6eb6607a66806211f",
            "title": "Algorithms for Inverse Reinforcement Learning"
        },
        {
            "paperId": "6fc241221e6d2b92f752d7d88d2d2313f9c643f3",
            "title": "Observable Operator Models for Discrete Stochastic Time Series"
        },
        {
            "paperId": "2bf5bdb70412b5eac283f6b50b829d12470a98e7",
            "title": "How the Basal Ganglia Use Parallel Excitatory and Inhibitory Learning Pathways to Selectively Respond to Unexpected Rewarding Cues"
        },
        {
            "paperId": "a20f0ce0616def7cc9a87446c228906cd5da093b",
            "title": "Policy Gradient Methods for Reinforcement Learning with Function Approximation"
        },
        {
            "paperId": "b6cbf0863880e89e56f35b778ec2c3619bd280c1",
            "title": "A dynamic channel assignment policy through Q-learning"
        },
        {
            "paperId": "0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d",
            "title": "Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning"
        },
        {
            "paperId": "22dcdc9853f6405ff65ed79fd28f24a09bc6f8cb",
            "title": "A neural network model with dopamine-like reinforcement signal that learns a spatial delayed response task"
        },
        {
            "paperId": "55c7cb8ca85c751f7a418ae06143d9f3473ce526",
            "title": "Least-Squares Temporal Difference Learning"
        },
        {
            "paperId": "94066dc12fe31e96af7557838159bde598cb4f10",
            "title": "Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping"
        },
        {
            "paperId": "18f4e6b5b5b226a47e4aed700ea8b9ae6f121308",
            "title": "Reinforcement Learning Through Gradient Descent"
        },
        {
            "paperId": "cb914e7c6613f33125b73f35356c35972cb2a582",
            "title": "Timing in simple conditioning and occasion setting: a neural network approach"
        },
        {
            "paperId": "2722b9e5ab8da95f03e578bb65879c452c105385",
            "title": "Catastrophic forgetting in connectionist networks"
        },
        {
            "paperId": "812b49a877b98941f258f7c2bfc8e890963142bd",
            "title": "Local Gain Adaptation in Stochastic Gradient Descent"
        },
        {
            "paperId": "f608268033a797a38047575e6b4de65899eedd5f",
            "title": "Simulation-based optimization of Markov reward processes"
        },
        {
            "paperId": "ab2ada3c97ad6f0ae79ca8b7b459f18d77119f9c",
            "title": "Gradient Descent for General Reinforcement Learning"
        },
        {
            "paperId": "50cd666b67505616bee0515a594316e99fbb805d",
            "title": "Dopamine neurons report an error in the temporal prediction of reward during learning"
        },
        {
            "paperId": "2fc73ec66c8e2428b185e60da5c49b842be5283c",
            "title": "Learning of sequential movements by neural network model with dopamine-like reinforcement signal"
        },
        {
            "paperId": "036373f17e5e47bcadc289e6c57d61cf5e08fe3d",
            "title": "Hierarchical Solution of Markov Decision Processes using Macro-actions"
        },
        {
            "paperId": "9d8f6219fbd2da14d8d55562dcedf43fe671d0e3",
            "title": "Learning to Drive a Bicycle Using Reinforcement Learning and Shaping"
        },
        {
            "paperId": "5e4022c0720363c90e6cbecf146a4a5736e891f4",
            "title": "Classical conditioning and brain systems: the role of awareness."
        },
        {
            "paperId": "5a767a341364de1f75bea85e0b12ba7d3586a461",
            "title": "Natural Gradient Works Efficiently in Learning"
        },
        {
            "paperId": "e2a5e8d9b0d0a9657aad850f5747941025f71d29",
            "title": "A neuro-dynamic programming approach to retailer inventory management"
        },
        {
            "paperId": "7bd3ae59740463b9d2730645874dc7aa3bfec1ab",
            "title": "Shaping robot behavior using principles from instrumental conditioning"
        },
        {
            "paperId": "4e76f4b497245eb85fe57146d2b2528d9963f51d",
            "title": "Rollout Algorithms for Combinatorial Optimization"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "f76a76747699db19d469587d6d66ae72e958c43b",
            "title": "Perturbation realization, potentials, and sensitivity analysis of Markov processes"
        },
        {
            "paperId": "a666a97335c9ec87cce86b359bd28e85fecae580",
            "title": "Learning Policies for Partially Observable Environments: Scaling Up"
        },
        {
            "paperId": "f8486d1be0250a83b447d8ee75043359bcef486f",
            "title": "Efficient Locally Weighted Polynomial Regression Predictions"
        },
        {
            "paperId": "9d53a5d317bea1ba62d1c2b5c5e99222f9bf8fbe",
            "title": "The neural basis of associative reward learning in honeybees"
        },
        {
            "paperId": "a6992b208f65b90ae38c39549bce799a8254e8b5",
            "title": "Minimum-time control of the Acrobot"
        },
        {
            "paperId": "ee4bee01b6a0618b7220b4c64ce5cea128c15e5b",
            "title": "On integrating apprentice learning and reinforcement learning TITLE2"
        },
        {
            "paperId": "607135569aedaded773ac3f036f5bff113194dba",
            "title": "Learning the temporal dynamics of behavior."
        },
        {
            "paperId": "12b9019f99a315a137400389ee7c6faa4cceef35",
            "title": "A Neural Substrate of Prediction and Reward"
        },
        {
            "paperId": "c02e20c1682703f85694197af442cead47bd89ba",
            "title": "Synaptic tagging and long-term potentiation"
        },
        {
            "paperId": "679f48306b47634b3ad6b64d8505d36e09dadfe3",
            "title": "Regulation of Synaptic Efficacy by Coincidence of Postsynaptic APs and EPSPs"
        },
        {
            "paperId": "3552fba431aa866bf9de293bebf7eff168e9e19c",
            "title": "On-line Policy Improvement using Monte-Carlo Search"
        },
        {
            "paperId": "54619cf0c09212aee789c6bdab187a94ba3cda0a",
            "title": "Reinforcement Learning for Dynamic Channel Allocation in Cellular Telephone Systems"
        },
        {
            "paperId": "650d4e7c4fbd68b05f87a46985f1da6f2f4f0ed8",
            "title": "Intelligent Machinery, A Heretical Theory*"
        },
        {
            "paperId": "789db4f0277ee25685c414771b4a96fbc8300d69",
            "title": "Optimal control-1950 to 1985"
        },
        {
            "paperId": "12d1d070a53d4084d88a77b8b143bad51c40c38f",
            "title": "Reinforcement Learning: A Survey"
        },
        {
            "paperId": "2811534b332206223188687e214ebbde0f2f294d",
            "title": "A framework for mesencephalic dopamine systems based on predictive Hebbian learning"
        },
        {
            "paperId": "4a5a283e178f187e64d0c1019314d0a6e1d4ca96",
            "title": "Feature-based methods for large scale dynamic programming"
        },
        {
            "paperId": "8597ed8596c08ba2ba7bc8da3e9546749d6f4f7b",
            "title": "Sample mean based index policies by O(log n) regret for the multi-armed bandit problem"
        },
        {
            "paperId": "81a15463a09b9555a78b755e43f9a1c278321ce3",
            "title": "Causal diagrams for empirical research"
        },
        {
            "paperId": "7ca8ac34767d6e6cb389eeebcdabc4225b39edfe",
            "title": "Generalization in Reinforcement Learning: Successful Examples Using Sparse Coarse Coding"
        },
        {
            "paperId": "cc93d7c552b498a4b9ffadf6c07c597ad222dc44",
            "title": "Stable Fitted Reinforcement Learning"
        },
        {
            "paperId": "a7e5a400e63e74f44d07be8b4742472c981ca5b8",
            "title": "Improving Elevator Performance Using Reinforcement Learning"
        },
        {
            "paperId": "25b813ee578fa34be7c13c78f1a35865bbafa519",
            "title": "Temporal Difference Learning in Continuous Time and Space"
        },
        {
            "paperId": "a5a48f3876da907f3be47c146f31af58ec041a86",
            "title": "High-Performance Job-Shop Scheduling With A Time-Delay TD(\u03bb) Network"
        },
        {
            "paperId": "cda1c82b9d48b5cc94ae5bda33e864d95b3053dd",
            "title": "Bee foraging in uncertain environments using predictive hebbian learning"
        },
        {
            "paperId": "b8ff8c7ab23eb70d4179c15a8a6b0efa1a493b8b",
            "title": "Steps toward Artificial Intelligence"
        },
        {
            "paperId": "59b50a775542e87f078db35b868ac10ab43d4c75",
            "title": "Learning from delayed rewards"
        },
        {
            "paperId": "855ce3491013292a31bc0445bc5d57d4819740d3",
            "title": "Local and Global Optimization Algorithms for Generalized Learning Automata"
        },
        {
            "paperId": "6c9e09c754773b13aa9a85c98d01ab30b6ced96f",
            "title": "Approximating Optimal Policies for Partially Observable Stochastic Domains"
        },
        {
            "paperId": "53958cff5f602a73ae8dd2512737e7beb0b60bbb",
            "title": "Decomposition Techniques for Planning in Stochastic Domains"
        },
        {
            "paperId": "d3bfc039f870388491f6d89f8f2a88c0b117ee0c",
            "title": "Exploiting Structure in Policy Construction"
        },
        {
            "paperId": "b550e3e05701cbf6c76a8c71e91beb95f950b080",
            "title": "A Reinforcement Learning Approach to job-shop Scheduling"
        },
        {
            "paperId": "7ae91735c6e5f4ab44bfa95bd144663f057d1935",
            "title": "On the Complexity of Solving Markov Decision Problems"
        },
        {
            "paperId": "f518bffb712a298bff18248c67f6fc0181018ae6",
            "title": "Residual Algorithms: Reinforcement Learning with Function Approximation"
        },
        {
            "paperId": "a24508e65e599b5b20c33af96dbe7017d5caca37",
            "title": "Learning internal representations"
        },
        {
            "paperId": "936fcbdbf013b0308a68d0c35c6f1a89d461184b",
            "title": "Q-Learning for Bandit Problems"
        },
        {
            "paperId": "5ed59f49c1bb7de06cfa2a9467d5efb535103277",
            "title": "Temporal difference learning and TD-Gammon"
        },
        {
            "paperId": "3b5db92ce2f86b2136fe7cf6a415fe1c0632a881",
            "title": "TD Models: Modeling the World at a Mixture of Time Scales"
        },
        {
            "paperId": "adb1612bdcbe9e1c52c126f6058728ebbee8d497",
            "title": "Incremental dynamic programming for on-line adaptive optimal control"
        },
        {
            "paperId": "362891a2110a7cc4e7b378c237c26fbbf5a65860",
            "title": "Swinging up the Acrobot: an example of intelligent control"
        },
        {
            "paperId": "73fb548322b36310483809c5c9dff9f3bee1872a",
            "title": "Robot Shaping: Developing Autonomous Agents Through Learning"
        },
        {
            "paperId": "69e492c7debf575ad1fba8fa0dfa2acc2170a3bf",
            "title": "Truncating Temporal Differences: On the Efficient Implementation of TD(lambda) for Reinforcement Learning"
        },
        {
            "paperId": "43fa730736ede1574abb2f9245a5e3ec5575446f",
            "title": "Incorporating Advice into Agents that Learn from Reinforcements"
        },
        {
            "paperId": "4f48b2ba8c3b8e8f0aa3d61e3f30c5c66997c7ab",
            "title": "Counterfactual Probabilities: Computational Methods, Bounds and Applications"
        },
        {
            "paperId": "563cf7359970015db2f8a05c41e9efef7025dda2",
            "title": "Reward Functions for Accelerated Learning"
        },
        {
            "paperId": "7fbf55baccbc5fdc7ded1ba18330605909aef5e5",
            "title": "Markov Games as a Framework for Multi-Agent Reinforcement Learning"
        },
        {
            "paperId": "c0720cba764469053b3fea2c3f6adb8127106490",
            "title": "Adaptive linear quadratic control using policy iteration"
        },
        {
            "paperId": "00920ddc2a231c54dfbd4f4f57f4ce35d00b6128",
            "title": "Swing up control of the Acrobot"
        },
        {
            "paperId": "56b10282bce1c5943af786544f126aac4437dfaf",
            "title": "Alopex: A Correlation-Based Learning Algorithm for Feedforward and Recurrent Neural Networks"
        },
        {
            "paperId": "68869113833867bf221e3f2131414d27767cc0b0",
            "title": "The predictive brain: temporal coincidence and temporal order in synaptic learning mechanisms."
        },
        {
            "paperId": "c6e7f227db97cc95ef860333cd852832965907cd",
            "title": "Toward a Statistical Theory of Learning."
        },
        {
            "paperId": "89794232987d3973109ba78327a4c989a6e4970b",
            "title": "Value-dependent selection in the brain: Simulation in a synthetic neural model"
        },
        {
            "paperId": "2b11305f69641ecb8bd4a5e59cfebe41ad9ed989",
            "title": "TD-Gammon, a Self-Teaching Backgammon Program, Achieves Master-Level Play"
        },
        {
            "paperId": "82479b544924ee734fb22f9dce78aace0f90cd3c",
            "title": "Robot juggling: implementation of memory-based learning"
        },
        {
            "paperId": "a3f87d045341e713fa62d465531f29f18d4a0559",
            "title": "Training Agents to Perform Sequential Behavior"
        },
        {
            "paperId": "5e5b25e046f120b296b7c0bad24692ceea492427",
            "title": "Monte Carlo Matrix Inversion and Reinforcement Learning"
        },
        {
            "paperId": "fc1a6753de779a5871ee5481e455fa5e00404f1d",
            "title": "Reinforcement Learning With High-Dimensional, Continuous Actions"
        },
        {
            "paperId": "c376317f738fa4795cb47c3b5c8918c9348ca965",
            "title": "Learning to Solve Markovian Decision Processes"
        },
        {
            "paperId": "9840b7a2c9088a8ee4506e0bf49300055352a1ae",
            "title": "Scheduling and rescheduling with iterative repair"
        },
        {
            "paperId": "b6c3243e2f7da9ded57246493e565cd1f7853204",
            "title": "A Survey of Applications of Markov Decision Processes"
        },
        {
            "paperId": "a0b1d1e2a99c4d9c67750c231b3883e5976717d4",
            "title": "Sparse distributed memory and related models"
        },
        {
            "paperId": "171b9d5f0f29388c1e638de55aed3d19c3524df5",
            "title": "Reinforcement learning with hidden states"
        },
        {
            "paperId": "f4c6240b68e97d6f3b9bc67a701f10e49a1b1dab",
            "title": "Hierarchical Learning in Stochastic Domains: Preliminary Results"
        },
        {
            "paperId": "9ae6fbda6080f3ed6ec29a8d62a8c8941d7263d4",
            "title": "Overcoming Incomplete Perception with Utile Distinction Memory"
        },
        {
            "paperId": "99b2fd28dcab3657c5f1271a05223f4740e4b65c",
            "title": "A Reinforcement Learning Method for Maximizing Undiscounted Rewards"
        },
        {
            "paperId": "89a4ddffb62dd31d174d6964a72453b2541c7bc3",
            "title": "Online Learning with Random Representations"
        },
        {
            "paperId": "154e8048e5171b79dcff76c8642afd02a5466768",
            "title": "Learning in embedded systems"
        },
        {
            "paperId": "c980493673bad9bcb888dd18788d2b4b3ecb7a2e",
            "title": "Efficient Learning and Planning Within the Dyna Framework"
        },
        {
            "paperId": "8163c4ccfad54c63aa840b25a3a377f39001d2e4",
            "title": "Responses of monkey dopamine neurons to reward and conditioned stimuli during successive steps of learning a delayed response task"
        },
        {
            "paperId": "1e05ebaa7725ce7da3fbd16d113e71c88822aeaa",
            "title": "Temporal-difference methods and Markov models"
        },
        {
            "paperId": "a4ac3bf8dd1b7aaf8ddc7c7f29d70b1ec62aedee",
            "title": "Reinforcement Learning Applied to Linear Quadratic Regulation"
        },
        {
            "paperId": "1678bd32846b1aded5b1e80a617170812e80f562",
            "title": "Feudal Reinforcement Learning"
        },
        {
            "paperId": "334d339ce1b2f8f19cd71779320b66e44e95fffd",
            "title": "Using Aperiodic Reinforcement for Directed Self-Organization During Development"
        },
        {
            "paperId": "1ca97e1668e305fb719845f84a05a62dfb946a5d",
            "title": "Local Learning Algorithms"
        },
        {
            "paperId": "83ace3ecedcfab917e2af4bda3bbbe198ceacef6",
            "title": "Expectation learning in the brain using diffuse ascending projections"
        },
        {
            "paperId": "f350c2c887c9a78a217dc429297799c5d738b7f5",
            "title": "[Selection by consequences]."
        },
        {
            "paperId": "d5b1239cfb88f6d5f9af62a16969cf9802896027",
            "title": "Shaping as a method for accelerating reinforcement learning"
        },
        {
            "paperId": "b5cc2b2829a1fcf0260a1405f5f931efb21ffd5a",
            "title": "Reinforcement Learning with a Hierarchy of Abstract Models"
        },
        {
            "paperId": "c2dd697bbe99c2ec71c807580a00f7e723cc20ae",
            "title": "Adapting Bias by Gradient Descent: An Incremental Version of Delta-Bar-Delta"
        },
        {
            "paperId": "a1b055577a86141df13f13a3203c76a32bffdc3a",
            "title": "Reinforcement Learning with Perceptual Aliasing: The Perceptual Distinctions Approach"
        },
        {
            "paperId": "d3da3e6a6c76868e0178adf149ef96d4e99a620d",
            "title": "A Teaching Method for Reinforcement Learning"
        },
        {
            "paperId": "6dc61f37ecc552413606d8c89ffbc46ec98ed887",
            "title": "Acceleration of stochastic approximation by averaging"
        },
        {
            "paperId": "66e3294feae7f0dba35c94a7214fc5cba41e9def",
            "title": "Scaling Reinforcement Learning Algorithms by Learning Variable Temporal Resolution Models"
        },
        {
            "paperId": "4b4279db68b16e20fbc56f9d41980a950191d30a",
            "title": "Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence"
        },
        {
            "paperId": "01fc47fbc6665d07d9d97ca185e206c89393f3ba",
            "title": "Theory and development of higher-order CMAC neural networks"
        },
        {
            "paperId": "94db34f4b68189bfcba22beab33ee3b54f10b876",
            "title": "Curious model-building control systems"
        },
        {
            "paperId": "dccf7d93a08366e3970faa5ce5321225b243200f",
            "title": "Second-order conditioning of the rabbit\u2019s nictitating membrane response"
        },
        {
            "paperId": "b7d851e184925792c1065138a56ce5631e491455",
            "title": "CMAC-based adaptive critic self-learning control"
        },
        {
            "paperId": "20bc2fa075a19f0f2638956dcf0bbdb6555ffe9a",
            "title": "Improved Allocation of Weights for Associative Memory Storage in Learning Control Systems"
        },
        {
            "paperId": "45d2bdf5e7072c1d5a91a38efa365715def2f45d",
            "title": "Input Generalization in Delayed Reinforcement Learning: An Algorithm and Performance Comparisons"
        },
        {
            "paperId": "a321926b30f0f0c38ff2d52a0e5b5ff91a752138",
            "title": "An optimal one-way multigrid algorithm for discrete-time stochastic control"
        },
        {
            "paperId": "9d612473d6bba6fb7b611b88d0b5f7fff6c17fdd",
            "title": "Automatic Programming of Behavior-Based Robots Using Reinforcement Learning"
        },
        {
            "paperId": "b631510618b13c32a87ac134f11dcb22cec8c9a1",
            "title": "A survey of algorithmic methods for partially observed Markov decision processes"
        },
        {
            "paperId": "044d1758742d5250a871f4d78f3d9eb1128a6f51",
            "title": "Learning a Cost-Sensitive Internal Representation for Reinforcement Learning"
        },
        {
            "paperId": "2980dfe5c99658dc3e508d9d6e1d7f26e6fc8934",
            "title": "A possibility for implementing curiosity and boredom in model-building neural controllers"
        },
        {
            "paperId": "898c01de58eb3b8e790b60e0fe0db2230d88f15b",
            "title": "Extensions of a Theory of Networks for Approximation and Learning"
        },
        {
            "paperId": "aca7bc48be39efb8671347daa03f5ed60224751c",
            "title": "Toward learning time-varying functions with high input dimensionality"
        },
        {
            "paperId": "241b50e5a6009beaf194f824795ed88c0c6611f4",
            "title": "Explaining Temporal Differences to Create Useful Concepts for Evaluating States"
        },
        {
            "paperId": "704665187c0c9b0064c58b8fbc33a53ab6179d10",
            "title": "What are plans for?"
        },
        {
            "paperId": "dfd2f0963c2b024594bd991a4f09267e17e01862",
            "title": "Dynamic channel assignment in cellular radio"
        },
        {
            "paperId": "591b52d24eb95f5ec3622b814bc91ac872acda9e",
            "title": "Connectionist models of recognition memory: constraints imposed by learning and forgetting functions."
        },
        {
            "paperId": "2fda10f6079156c4621fefc8b7cad72c1829ee94",
            "title": "Real-Time Heuristic Search"
        },
        {
            "paperId": "8991a362622590832faf2f06a23a73296e40a8f8",
            "title": "Dopamine neurons of the monkey midbrain: contingencies of responses to stimuli eliciting immediate behavioral reactions."
        },
        {
            "paperId": "4c3cebe580fd59c6ea01e2d2f695e8880419d3e4",
            "title": "Dopamine neurons of the monkey midbrain: contingencies of responses to active touch during self-initiated arm movements."
        },
        {
            "paperId": "4abd4e51705e74f1739bd3a1e47ac10e45f6468b",
            "title": "Regularization Algorithms for Learning That Are Equivalent to Multilayer Networks"
        },
        {
            "paperId": "fc3577a26c3be6ca5fe1213e8b5cfeb2502a09e1",
            "title": "Expected-Outcome: A General Model of Static Evaluation"
        },
        {
            "paperId": "831edc3d67457db83da40d260e93bfd7559347ae",
            "title": "Dyna, an integrated architecture for learning, planning, and reacting"
        },
        {
            "paperId": "366901eb4a99a6ebb799701614ccd0ac4601f210",
            "title": "A bioreactor benchmark for adaptive network-based process control"
        },
        {
            "paperId": "3764fb7db442dffb6c5e03ac376e8e117f5172e9",
            "title": "Neural networks for control and system identification"
        },
        {
            "paperId": "8da1dda34ecc96263102181448c94ec7d645d085",
            "title": "Approximation by superpositions of a sigmoidal function"
        },
        {
            "paperId": "283471d3a4d1dcc02c9ceea3f1bc674fe573e5f4",
            "title": "IS THERE MORE TO UNCERTAINTY THAN SOME PROBABILITY THEORISTS MIGHT HAVE US BELIEVE"
        },
        {
            "paperId": "884bf8cb17fb159c56a9c1cac8fda478dcc44ffa",
            "title": "Learning and Sequential Decision Making"
        },
        {
            "paperId": "016492fd13554c557e5d10bdbdee85e45255f50b",
            "title": "A colony architecture for an artificial creature"
        },
        {
            "paperId": "c04308d15500b69a9e67bb1ae7ccf67fa19c2d87",
            "title": "Comparisons of channel assignment strategies in cellular mobile telephone systems"
        },
        {
            "paperId": "068005347c90defdb34cfffb7ee73030654c5cfc",
            "title": "Learning Automata: An Introduction"
        },
        {
            "paperId": "8302c2a57c98c08d634aa2212a87cd9009ecc2fe",
            "title": "Learning to control an inverted pendulum using neural networks"
        },
        {
            "paperId": "3b25a530eabd0a39840c81becb980c3dc496975b",
            "title": "Neural dynamics of adaptive timing and temporal discrimination during associative learning"
        },
        {
            "paperId": "20d910897b46b969b3e5cf5a0a18d4c2d0608144",
            "title": "From Chemotaxis to cooperativity: abstract exercises in neuronal learning strategies"
        },
        {
            "paperId": "dcdb9bd64e3d7885c10938291153257b94f3df91",
            "title": "Sparse Distributed Memory"
        },
        {
            "paperId": "88ca1abdb94d6fe559ab9be2ebd948b662698166",
            "title": "The dynamic structure of everyday life"
        },
        {
            "paperId": "000fbd970e7ff72107fdf806027f4ba597637571",
            "title": "Further Real Applications of Markov Decision Processes"
        },
        {
            "paperId": "eb2f539a17487db2c93785214da2fc7a67a57840",
            "title": "Quantitative Results Concerning the Utility of Explanation-based Learning"
        },
        {
            "paperId": "e08da64c0175139d7094a9bfbb3ec38648f8457f",
            "title": "On the use of backpropagation in associative reinforcement learning"
        },
        {
            "paperId": "3c02365d67b65f6ccb840b5f2eda6f892674a502",
            "title": "Optimal path-finding algorithms*"
        },
        {
            "paperId": "8049dc4c4e73f5a8da730a20a9a9820e31818640",
            "title": "A neuronal model of classical conditioning"
        },
        {
            "paperId": "7fa02258b3703ab98cfc57f0885de9e43de06e23",
            "title": "The CDP: A unifying formulation for heuristic search, dynamic programming, and branch-and-bound"
        },
        {
            "paperId": "d5558a34dfd1dbb572895664d38fca04029a99cb",
            "title": "Radial Basis Functions, Multi-Variable Functional Interpolation and Adaptive Networks"
        },
        {
            "paperId": "2991f9bb677b71c33945e89ac0c7dcf7a36fa198",
            "title": "Efficient Estimations from a Slowly Convergent Robbins-Monro Process"
        },
        {
            "paperId": "eac84fd3ff37fdeb793efe1ac5ed31fc77a3c7b1",
            "title": "Temporal primacy overrides prior training in serial compound conditioning of the rabbit\u2019s nictitating membrane response"
        },
        {
            "paperId": "cb7c9fd84a877522ca0f7dc4233ee376e073427c",
            "title": "Increased rates of convergence through learning rate adaptation"
        },
        {
            "paperId": "77808d64daa93b0c1babc58d8dcf5c4ce34c2683",
            "title": "Diversity-Based Inference of Finite Automata (Extended Abstract)"
        },
        {
            "paperId": "52f72a347c92ad10079efc89f6f537affe9d2341",
            "title": "Adaptive treatment allocation and the multi-armed bandit problem"
        },
        {
            "paperId": "d4b025405d3c26a544a1b61d3c746bc3f4d113ed",
            "title": "Dynamic Programming: Deterministic and Stochastic Models"
        },
        {
            "paperId": "003d912198ad1a718a84e430d47f6c513bb4df92",
            "title": "Game-theoretic cooperativity in networks of self-interested units"
        },
        {
            "paperId": "0efeee1a3802701bcb9c49f3d8b267ed0fd2b86d",
            "title": "Learning to control a dynamic physical system"
        },
        {
            "paperId": "6d67a36f5fae72da77cdfa4c69c92b34ce27a9f4",
            "title": "Random Walks and Electric Networks: REFERENCES"
        },
        {
            "paperId": "11463e2a6ed218e87e22cba2c2f24fb5992d0293",
            "title": "Learning and problem-solving with multilayer connectionist systems (adaptive, strategy learning, neural networks, reinforcement learning)"
        },
        {
            "paperId": "123a726f6feb2bce29708b68ab2db5cdf9fcdaf4",
            "title": "Toward memory-based reasoning"
        },
        {
            "paperId": "673a33fd73d1c10ba615c703f51154e419cec034",
            "title": "Recursive estimation and time-series analysis"
        },
        {
            "paperId": "a698fff13d9eea16b7e7a84c9ce023ba0a695d6a",
            "title": "A Unified Theory of Heuristic Evaluation Functions and its Application to Learning"
        },
        {
            "paperId": "b5d16f0d097091d48a15b355b615f89ead4abc85",
            "title": "Simulation of the classically conditioned nictitating membrane response by a neuron-like adaptive element: Response topography, neuronal firing, and interstimulus intervals"
        },
        {
            "paperId": "fda8598e7718b6cb179628d7f31f1967a8d9738c",
            "title": "Learning Control Systems-Review and Outlook"
        },
        {
            "paperId": "3106e66537a0c8f53278e553bcb38f0b0992ec0e",
            "title": "Distributed Representations"
        },
        {
            "paperId": "319f22bd5abfd67ac15988aa5c7f705f018c3ccd",
            "title": "Learning internal representations by error propagation"
        },
        {
            "paperId": "2e6a0730f3bf906e3f4137db4ced6d630d594bca",
            "title": "Decentralized learning in finite Markov chains"
        },
        {
            "paperId": "2cf6ef148f43b4df12acb2abe72af67eae54a09b",
            "title": "Real Applications of Markov Decision Processes"
        },
        {
            "paperId": "4269407105696ae3dafe1fd8bc99ca57f6462d60",
            "title": "Theory and practice of recursive identification"
        },
        {
            "paperId": "dcc3022b37afef00004686e508d305aaee9e12ca",
            "title": "Generalized polynomial approximations in Markovian decision processes"
        },
        {
            "paperId": "3f926f229755a617630ff241789bb4ef09f9209c",
            "title": "Training and Tracking in Robotics"
        },
        {
            "paperId": "0120eefaf05bfad5293e87f56d2e787c05f78cf7",
            "title": "Pattern-recognizing stochastic learning automata"
        },
        {
            "paperId": "9b1a16c102d033765455933f342cd1c19a7bd3e9",
            "title": "A Survey of Some Results in Stochastic Adaptive Control"
        },
        {
            "paperId": "4c9e36a0dbdc3e7b20e38bd288a804c05c77e9fa",
            "title": "Asymptotically efficient adaptive allocation rules"
        },
        {
            "paperId": "1abda55b890345dfffd14ed9f6763077b6109ed1",
            "title": "Actions and habits: the development of behavioural autonomy"
        },
        {
            "paperId": "92c61d5f45a8c0cee1ef2d638d1957a656061e5c",
            "title": "Variations on the Boltzmann Machine Learning Algorithm"
        },
        {
            "paperId": "43369b75cc3ef7df87eb049872428cf5d11d1706",
            "title": "Is there a cell-biological alphabet for simple forms of learning?"
        },
        {
            "paperId": "8096da6600ad034026c78888139fbf020e09461b",
            "title": "Heuristics : intelligent search strategies for computer problem solving"
        },
        {
            "paperId": "ba0c649ff274730ab1f3e21f67ba5aa90080df17",
            "title": "Brains, behavior, and robotics"
        },
        {
            "paperId": "f390b0bf0cc15eddb1dd24b759c425400647782c",
            "title": "An N-player sequential stochastic game with identical payoffs"
        },
        {
            "paperId": "272cc92827d917639a5844bb4f25c8549aaf4813",
            "title": "Meaning and purpose in the intact brain: A philosophical, psychological and biological account of conscious processes R. Miller. Oxford University Press, Oxford, Great Britain, 1982. 239 pp. ISBN 0-19-857579-3. \u00a320.00 (hardback)"
        },
        {
            "paperId": "8a7acaf6469c06ae5876d92f013184db5897bb13",
            "title": "Neuronlike adaptive elements that can solve difficult learning control problems"
        },
        {
            "paperId": "e8bf97dbdb88e60476cd6124ccae6e5accccd0b4",
            "title": "Distributed asynchronous computation of fixed points"
        },
        {
            "paperId": "655135070ffdb6c08d70c74ea7071f8b797764ab",
            "title": "The Hedonistic Neuron: A Theory of Memory, Learning and Intelligence"
        },
        {
            "paperId": "dd5061631a4d11fa394f4421700ebf7e78dcbc59",
            "title": "Optimization by Simulated Annealing"
        },
        {
            "paperId": "397265325909045dbe8706b56c80d2293798ee2f",
            "title": "Temporal contiguity requirements for long-term associative potentiation/depression in the hippocampus"
        },
        {
            "paperId": "ea42c0d1bd38db3da1e2b7276c8e215b23493895",
            "title": "Signature Table Systems and Learning"
        },
        {
            "paperId": "4a26d42bcb505c7294991a0e6c727ec5459290dd",
            "title": "Learning Algorithms for Two-Person Zero-Sum Stochastic Games with Incomplete Information: A Unified Approach"
        },
        {
            "paperId": "90a23d142ad2ae9c2d6cb47c14a6e74c52429b81",
            "title": "Multidimensional Tries Used for Associative Searching"
        },
        {
            "paperId": "3e475fdd47780d48667e58607ba152ad40ed89f2",
            "title": "Variations in the Sensitivity of Instrumental Responding to Reinforcer Devaluation"
        },
        {
            "paperId": "b419910ab2914fcb2cf75bc66708146125ae686c",
            "title": "Simulation of anticipatory responses in classical conditioning by a neuron-like adaptive element"
        },
        {
            "paperId": "d1891df4b672b45433e6ccc2f9be4af2d4a98180",
            "title": "Contemporary Animal Learning Theory"
        },
        {
            "paperId": "0db8e55a0b6ab914e155c55695d839be73c16ded",
            "title": "Instrumental Responding following Reinforcer Devaluation"
        },
        {
            "paperId": "d7ed2b8913c1cbb3b364071ed1bbefc4c92f90da",
            "title": "Conditioning and associative learning."
        },
        {
            "paperId": "a725e66a9975300512852cffa67938b8fecf2702",
            "title": "Goal Seeking Components for Adaptive Intelligence: An Initial Assessment."
        },
        {
            "paperId": "0367b5c4eca7bef6245ec183648f9aec18da91a6",
            "title": "Simulation and the Monte Carlo method"
        },
        {
            "paperId": "60944c5243db70a687a320a2622d3bd1610802a8",
            "title": "Toward a modern theory of adaptive networks: expectation and prediction."
        },
        {
            "paperId": "36303957caa2ebda4d04b6f25334d4fe9bf4b3cf",
            "title": "A model for Pavlovian learning: variations in the effectiveness of conditioned but not of unconditioned stimuli."
        },
        {
            "paperId": "addbcdceadbe8e97e46fe8d8ed121721c7356ae7",
            "title": "Erratum to: Formation of attentional-associative networks in real time: Role of the hippocampus and implications for conditioning"
        },
        {
            "paperId": "b33c0fbfa60c93aa28066563fd2566c26538c498",
            "title": "Approximations of Dynamic Programs, I"
        },
        {
            "paperId": "a7b608eff19a85f85b34cda3ecb66d0a3e572583",
            "title": "Modified Policy Iteration Algorithms for Discounted Markov Decision Problems"
        },
        {
            "paperId": "cab3c73f1b2140231b98944c720100b356d91b28",
            "title": "An Algorithm for Finding Best Matches in Logarithmic Expected Time"
        },
        {
            "paperId": "00c6914dab0fb75c0fe5c8d8ad57d726223b7d9b",
            "title": "Distinctive features, categorical perception, and probability learning: some applications of a neural model"
        },
        {
            "paperId": "0f2d0e9c57d268fc1d05ce657eaf64eaaeb323c7",
            "title": "An Adaptive Optimal Controller for Discrete-Time Markov Environments"
        },
        {
            "paperId": "3d9f746acd675adbddbab4d81ecefdbb59f4bc22",
            "title": "Heuristics for Signature Table Analysis as a Pattern Recognition Technique"
        },
        {
            "paperId": "d20ef4c1d8a10b8ad570c2290923a1dd8d0f8425",
            "title": "Splines and efficiency in dynamic programming"
        },
        {
            "paperId": "821c66f8321580adbafa380f4456f191fbf70628",
            "title": "Why the Law of Effect will not Go Away"
        },
        {
            "paperId": "cc73bacd6a00442570d15e122604ad6862b8663d",
            "title": "Multidimensional binary search trees used for associative searching"
        },
        {
            "paperId": "9219d4cca4af0df78ac8d02ff1cb8fca0c6524a3",
            "title": "A Theory of Attention: Variations in the Associability of Stimuli with Reinforcement"
        },
        {
            "paperId": "a418c03feca1abc2ebaf4d8b2f0ab26839b342ca",
            "title": "A comparison of natural and artificial intelligence"
        },
        {
            "paperId": "bd678d09bfebe5d72900153c2041b57c9f4ea55b",
            "title": "Alopex: a stochastic method for determining visual receptive fields."
        },
        {
            "paperId": "f5884b40f776c85d7689ea2c440f7982cb1bec46",
            "title": "Learning Automata - A Survey"
        },
        {
            "paperId": "77f3a837fce24d23fa64b4725c7fabc3c86ac6c2",
            "title": "A Comparison and Evaluation of Three Machine Learning Procedures as Applied to the Game of Checkers"
        },
        {
            "paperId": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "title": "Pattern classification and scene analysis"
        },
        {
            "paperId": "6587a531da06b9cef73e93b6b7627e466ad51d1b",
            "title": "Punish/Reward: Learning with a Critic in Adaptive Threshold Systems"
        },
        {
            "paperId": "86606ccaf060de44ae8c9db77ea19583a935f941",
            "title": "Behavior, the control of perception"
        },
        {
            "paperId": "72c94dc1d35507df0d0c5f175536a42a2e7abbdc",
            "title": "A Stochastic Learning Model of Economic Behavior"
        },
        {
            "paperId": "0c1accd2ef7218534a1726a8de7d6e7c14271a75",
            "title": "Brain Function and Adaptive Systems: A Heterostatic Theory"
        },
        {
            "paperId": "baa317e95f76f9286c91b1cc8250665d6aaab7fa",
            "title": "A Theory of Cerebellar Function"
        },
        {
            "paperId": "41c627ff4d1a46846515765402fdcdbb7487ff7f",
            "title": "On the law of effect."
        },
        {
            "paperId": "eef94be5d2413d194be31a26ba11112468251f87",
            "title": "Cortical Synapses and Reinforcement: a Hypothesis"
        },
        {
            "paperId": "dd03f2ba2e166143a173aa4dba432df302ae898f",
            "title": "A two-dimensional interpolation function for irregularly-spaced data"
        },
        {
            "paperId": "41cfd316679467086ecbe2408f7ed640790541b1",
            "title": "Predictability, surprise, attention, and conditioning"
        },
        {
            "paperId": "796b26e9145ab22db74e09064877992276fe6592",
            "title": "State Functions and Linear Control Systems"
        },
        {
            "paperId": "e9e6bb5f2a04ae30d8ecc9287f8b702eedd7b772",
            "title": "Some Studies in Machine Learning Using the Game of Checkers"
        },
        {
            "paperId": "de02c70882108516629bb867ba186fab17ef8350",
            "title": "Attention-like processes in classical conditioning"
        },
        {
            "paperId": "c6acd0291ad80a515766c2724357209ff9328270",
            "title": "Applications of artificial intelligence techniques to a spacecraft control problem"
        },
        {
            "paperId": "0f5aa175e63d6fd3c0ddcbf30332b3da006a5477",
            "title": "CONTRACTION MAPPINGS IN THE THEORY UNDERLYING DYNAMIC PROGRAMMING"
        },
        {
            "paperId": "508dd432a33cb7c3d02d8185b6741c139efa0b60",
            "title": "Chemotaxis in Bacteria"
        },
        {
            "paperId": "d946dda40d1eab435416599171657088dcf4310c",
            "title": "Optimal control of systems"
        },
        {
            "paperId": "fc4421a929dd6a5a1005f1a0a6b67e92e63c77e7",
            "title": "A New Machine-Learning Technique Applied to the Game of Checkers"
        },
        {
            "paperId": "28c567f9633871a8aeece63209263ceb1c7a5738",
            "title": "A heuristic approach to reinforcement learning control systems"
        },
        {
            "paperId": "a4da338cff8261a9853bc8007a5257ca33b0cd38",
            "title": "Beat the Dealer: A Winning Strategy for the Game of Twenty-One"
        },
        {
            "paperId": "9b486c647916df9f8be0f8d4fc5c94c493bfaa80",
            "title": "PRINCIPLES OF NEURODYNAMICS. PERCEPTRONS AND THE THEORY OF BRAIN MECHANISMS"
        },
        {
            "paperId": "be1558b852a05bf626e4736d4e12721707065913",
            "title": "STELLA: A scheme for a learning machine"
        },
        {
            "paperId": "20f96bb603df56b569eef7b2d2fc23f9b9cf5fc5",
            "title": "Polynomial approximation\u2014a new computational technique in dynamic programming: Allocation processes"
        },
        {
            "paperId": "0d59aa88409d15487847768bb8055a41858a9fed",
            "title": "Secondary reinforcement in rats as a function of information value and reliability of the stimulus."
        },
        {
            "paperId": "e726f00657c2d82e5ff0ef011910f2d197c4b010",
            "title": "Matrix Iterative Analysis"
        },
        {
            "paperId": "5b2587316b6753979e4da4bae76c3933a9e95884",
            "title": "The misbehavior of organisms."
        },
        {
            "paperId": "c7d3e9a1dd86f9c96f709d0ddb76972862784231",
            "title": "Dynamic Programming and Markov Processes"
        },
        {
            "paperId": "5d7d120409cb3551f191ef32dcbdc4add3eb1ba8",
            "title": "FUNCTIONAL APPROXIMATIONS AND DYNAMIC PROGRAMMING"
        },
        {
            "paperId": "69a6f10d303cdf58f986dccc5677e9baf2d107a0",
            "title": "Stochastic Models for Learning"
        },
        {
            "paperId": "82d7e8efa426f738c86382e9ad2030654800d6fe",
            "title": "On thought: the extrinsic theory."
        },
        {
            "paperId": "616b9f5b957de2249ed1ae433b9be1bf1d45cdef",
            "title": "Generalization of pattern recognition in a self-organizing system"
        },
        {
            "paperId": "874ff0cb6e572381a520104ba73fac1e00595eb7",
            "title": "Positive reinforcement produced by electrical stimulation of septal area and other regions of rat brain."
        },
        {
            "paperId": "910d3158af44ba3fc8a92ec5afd13c9ae930eff9",
            "title": "A PROBLEM IN THE SEQUENTIAL DESIGN OF EXPERIMENTS"
        },
        {
            "paperId": "879650714f3dce59b666346ccf63fd73250259d6",
            "title": "Simulation of self-organizing systems by digital computer"
        },
        {
            "paperId": "a48c43586d4b8b51407a56acd74c0f23d40710de",
            "title": "A Machine with Insight"
        },
        {
            "paperId": "e7097b535108b1e9938d36075a69f6155fdb164b",
            "title": "A new type of behaviour theory."
        },
        {
            "paperId": "a4342e3dab2d6a5c1c22556e45864e984aaab789",
            "title": "On Stochastic Learning Theory"
        },
        {
            "paperId": "b77aa53b45f6aa1873780d0fa7aad50efb422458",
            "title": "Some aspects of the sequential design of experiments"
        },
        {
            "paperId": "885ea2165c9df635712b014093c7f4dd194c37d6",
            "title": "A Machine that Learns"
        },
        {
            "paperId": "487907de7c1c8693374f83851db3308b74175a45",
            "title": "A critical review of latent learning and related experiments."
        },
        {
            "paperId": "b9164335be5808ddd59786869a9f992331af5218",
            "title": "The organization of behavior: A neuropsychological theory"
        },
        {
            "paperId": "2d5673caa9e6af3a7b82a43f19ee920992db07ad",
            "title": "Computing Machinery and Intelligence"
        },
        {
            "paperId": "36dc973d4259acda34a30e91df1b997da083b69b",
            "title": "An Imitation of Life"
        },
        {
            "paperId": "83d4d801ff410961b72bc72b57418600d2ab0454",
            "title": "A chess-playing machine."
        },
        {
            "paperId": "e84d660ebf894e2fb85d7b27985bfbf07b9acd22",
            "title": "Cognitive maps in rats and men."
        },
        {
            "paperId": "ee66f87c06337fb430a90897112de06fb61f6a9f",
            "title": "The Nature of Explanation"
        },
        {
            "paperId": "843976b39e7f1a97bc120e7baa35a9b0f3382650",
            "title": "Behavior of Organisms"
        },
        {
            "paperId": "7b4ab2f136337af4530896925559158987381187",
            "title": "Conditioned Reflexes"
        },
        {
            "paperId": "e02d1d482ea7a51ede5a0babd45ab3d4344a8e13",
            "title": "On the Theory of Apportionment"
        },
        {
            "paperId": "9c3014a83c52355a85323bb5cad4479c362c7df1",
            "title": "Higher Order Conditioning with Constant Motivation"
        },
        {
            "paperId": "ee2cd1d17f833d3c157a1016a778c7c22af555a2",
            "title": "ON THE LIKELIHOOD THAT ONE UNKNOWN PROBABILITY EXCEEDS ANOTHER IN VIEW OF THE EVIDENCE OF TWO SAMPLES"
        },
        {
            "paperId": "093f53afc2f012ea6146194bfc9193e296998149",
            "title": "Machines who think."
        },
        {
            "paperId": "92edf02664b43a5c511fa2c139cb63da2af67cc9",
            "title": "Adaptation"
        },
        {
            "paperId": "6f36fa118e757ce917b7a03664768787d8b9bb62",
            "title": "Reinforcement Learning with Function Approximation Converges to a Region"
        },
        {
            "paperId": "6f6beecacdf52771607f6cf8f05f15a4b58ff275",
            "title": "Temporal abstraction in reinforcement learning"
        },
        {
            "paperId": "774c9d82e4a0c7a8e54d9be971730fb98ec4c084",
            "title": "Numerical Methods for Stochastic Control Problems in Continuous Time"
        },
        {
            "paperId": "b55987b4cfff292dd121ee03c46b41f4f696136e",
            "title": "Intrinsic and Extrinsic Motivations: Classic Definitions and New Directions."
        },
        {
            "paperId": null,
            "title": "Behavior analysis and revaluation"
        },
        {
            "paperId": null,
            "title": "A biologically plausible and locally optimal learning algorithm for spiking neurons"
        },
        {
            "paperId": null,
            "title": "Lecture at the Earthware Symposium, Carnegie Mellon University"
        },
        {
            "paperId": "0729b5a6f11aa863182ac5f1fa1372ac693440b6",
            "title": "Technical Update: Least-squares Temporal Diierence Learning"
        },
        {
            "paperId": "578c9c14f4c3c5ece9caf9b4c1898f8a94461bd9",
            "title": "Approximate solutions to markov decision processes"
        },
        {
            "paperId": "dd5197b78aa4fe2bfccc5772f5a88f742f31e715",
            "title": "Models of Learning"
        },
        {
            "paperId": "ac4af1df88e178386d782705acc159eaa0c3904a",
            "title": "Actor-Critic Algorithms"
        },
        {
            "paperId": "2d6177244636f892c1620e3e5c2870c5e3902b55",
            "title": "Average cost temporal-difference learning"
        },
        {
            "paperId": "eff53c4d30f15e22f2178b5537c4156a8a621557",
            "title": "Least-Squares Temporal Di erence Learning"
        },
        {
            "paperId": "2966ae949d1bc255bad11045fd0ff8eb5848cf5a",
            "title": "Hierarchical control and learning for markov decision processes"
        },
        {
            "paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "title": "Gradient-based learning applied to document recognition"
        },
        {
            "paperId": "547ce5daf623353afa1be87e8c6978fa545dc0a7",
            "title": "A Computational Model of Birdsong Learning by Auditory Experience and Auditory Feedback"
        },
        {
            "paperId": "24da3011dfdefbdcee20d12ca3c2a348ad6f3aad",
            "title": "An Analysis of Temporal-Difference Learning with Function Approximation"
        },
        {
            "paperId": null,
            "title": "What is the role of dopamine in reward: hedonic impact, reward learning, or incentive salience"
        },
        {
            "paperId": null,
            "title": "Predictive timing under temporal uncertainty: The time derivative model of the conditioned response"
        },
        {
            "paperId": "87c6f4ce33794558593a71d90f8587cac33a8226",
            "title": "Partial Solutions Manual Parallel and Distributed Computation : Numerical Methods"
        },
        {
            "paperId": null,
            "title": "LTSM can solve hard time lag problems"
        },
        {
            "paperId": "8bc233c201a3cc09476aa4af02a97d926ada3db7",
            "title": "Reinforcement learning for job shop scheduling"
        },
        {
            "paperId": "8cf7c5d6c731a6d42db9da9ef4c62f7f3e32166e",
            "title": "Large-scale dynamic optimization using teams of reinforcement learning agents"
        },
        {
            "paperId": "f3f149ba4518679bbf2a99acd7947e929f00222d",
            "title": "Scaling Up Average Reward Reinforcement Learning by Approximating the Domain Models and the Value Function"
        },
        {
            "paperId": "2870f60f54d08dd13bf825230859b62e779d0527",
            "title": "Model-Based Reinforcement Learning with an Approximate, Learned Model"
        },
        {
            "paperId": "67de670898ebe2c982dab0429704370cd8d9a327",
            "title": "Numerical dynamic programming in economics"
        },
        {
            "paperId": "b23b75e82a74ef4967b07573e8475bcc6a47a559",
            "title": "An Analysis of Temporal-Di erence Learning with Function Approximation"
        },
        {
            "paperId": "a67a842eb60a082cfb8b99d93d8ab2bb52ecdc5b",
            "title": "UNH_CMAC Version 2.1 The University of New Hampshire Implementation of the Cerebellar Model Arithmetic Computer - CMAC"
        },
        {
            "paperId": "5ee38bf9494a91ca8665f9fbe59830464c223b82",
            "title": "Reinforcement learning with selective perception and hidden state"
        },
        {
            "paperId": null,
            "title": "Special triple issue on reinforcement learning, Machine Learning, 22(1/2/3)"
        },
        {
            "paperId": null,
            "title": "Chattering in SARSA(\u03bb)"
        },
        {
            "paperId": "ae35e9d47cc2db815ccd4346d4df462fce953960",
            "title": "Problem solving with reinforcement learning"
        },
        {
            "paperId": "e5a00e16d536caf3c3ebe50283da202797fc71ed",
            "title": "Truncating Temporal Diierences: on the Eecient Implementation of Td for Reinforcement Learning"
        },
        {
            "paperId": "eaec01700f5ea63af311cfd7a70a3869460ce080",
            "title": "Learning to Act Using Real-Time Dynamic Programming"
        },
        {
            "paperId": "0c4edc609f977cefb305f76a991514a83f8088e3",
            "title": "Stable Function Approximation in Dynamic Programming"
        },
        {
            "paperId": "f923120893ec4c2a1b40a84fe755550327893b58",
            "title": "Cellular models of reinforcement."
        },
        {
            "paperId": "f8271bc1cc4bb42793e45b8adb55fe81d839f0a9",
            "title": "Reward-related signals carried by dopamine neurons."
        },
        {
            "paperId": "bf7e1b6997433dcb2121b07cce1de1c61471ff2d",
            "title": "Pattern Recognition and Neural Networks"
        },
        {
            "paperId": "2e9faeccd0a9ca31bf87372957c45df0978c045e",
            "title": "A Summary Comparison of CMAC Neural Network and Traditional Adaptive Control Systems"
        },
        {
            "paperId": "2547be25e1e07728aa0966a0354e90664816d15e",
            "title": "REINFORCEMENT DRIVEN INFORMATION ACQUISITION IN NON-DETERMINISTIC ENVIRONMENTS"
        },
        {
            "paperId": "0c49199a74a84b67d649a795591ac3b529733453",
            "title": "Without Miracles: Universal Selection Theory and the Second Darwinian Revolution"
        },
        {
            "paperId": "cd4849072ca939e4e6a86a3d2b56b71593eafd18",
            "title": "Efficient Memory-Based Dynamic Programming"
        },
        {
            "paperId": "082b1f5c791cadef18c4920ecc1396615a3fe7cb",
            "title": "Continual learning in reinforcement environments"
        },
        {
            "paperId": "bed8538de3e6e988fdf29afa59fef0fa9bf5bad7",
            "title": "Learning and memory in the honeybee."
        },
        {
            "paperId": null,
            "title": "Ambiguity Aversion and Comparative Ignorance"
        },
        {
            "paperId": null,
            "title": "Elevator dispatchers for down peak traffic"
        },
        {
            "paperId": "7a09464f26e18a25a948baaa736270bfb84b5e12",
            "title": "On-line Q-learning using connectionist systems"
        },
        {
            "paperId": "4e9d797427cd56be90932d6092fc3b6282dfb96f",
            "title": "On the Convergence of Stochastic Iterative Dynamic Programming Algorithms"
        },
        {
            "paperId": "983265d0fe0ba349ec74d6d8e23e7381a9e32e2c",
            "title": "H-Learning: A Reinforcement Learning Method for Optimizing Undiscounted Average Reward"
        },
        {
            "paperId": "188030804d0e5816762cca70e12cea9f18e0a182",
            "title": "A Model of How the Basal Ganglia Generate and Use Neural Signals That Predict Reinforcement"
        },
        {
            "paperId": "0a8f4c3f0d317fd1f0bfe0b2e3e51aac893b8144",
            "title": "Generalization in Reinforcement Learning: Safely Approximating the Value Function"
        },
        {
            "paperId": "96a25df486c7dfa475a93a0ca31d0418f79a8771",
            "title": "Reinforcement Learning Methods for Continuous-Time Markov Decision Problems"
        },
        {
            "paperId": "ea899c8a3806a02a225061a35f802b00d90a0a20",
            "title": "Reinforcement Learning with Soft State Aggregation"
        },
        {
            "paperId": "e7ec6db9093a8b0b4007a1fbc1d4d86cc84f8fc2",
            "title": "Reinforcement-learning control and pattern recognition systems"
        },
        {
            "paperId": "d181a84258bd1249768bfaaa580be5dd1338c596",
            "title": "The Roots of Backpropagation: From Ordered Derivatives to Neural Networks and Political Forecasting"
        },
        {
            "paperId": "a579d06ac278e14948f67748cd651e4eb617ae4e",
            "title": "Learning Without State-Estimation in Partially Observable Markovian Decision Processes"
        },
        {
            "paperId": "9a208167b153e6dfc3327415068ae4a7a6dcd006",
            "title": "Reinforcement Learning Algorithm for Partially Observable Markov Decision Problems"
        },
        {
            "paperId": "5eb4a564d2c116a614b9d35aa1f320bb396ced97",
            "title": "Modular on-line function approximation for scaling up reinforcement learning"
        },
        {
            "paperId": "582b12885316187a33c8f901bf6382cf0a8d4367",
            "title": "A Novel Reinforcement Model of Birdsong Vocalization Learning"
        },
        {
            "paperId": null,
            "title": "Learning and Behavior, 3rd ed"
        },
        {
            "paperId": null,
            "title": "ZCS, A zeroth order classifier system"
        },
        {
            "paperId": "8e989437ab0ce2988bc5f1c2df4cfab58b01d7ac",
            "title": "Adaptive Critics and the Basal Ganglia"
        },
        {
            "paperId": null,
            "title": "Neural network control of dynamic balance for a biped walking robot"
        },
        {
            "paperId": null,
            "title": "Incremental learning of evaluation functions for absorbing Markov chains: New methods and theorems"
        },
        {
            "paperId": null,
            "title": "E cient learning of multiple degree-of-freedom control"
        },
        {
            "paperId": null,
            "title": "Neural networks: A Comprehensive Foundation, Macmillan college publishing"
        },
        {
            "paperId": "d345bb0656e5bfede6bb963d861e592d761d5c55",
            "title": "Neural network learning and expert systems"
        },
        {
            "paperId": "83b6755242f1cff6bacf270f65b4626d4d118f32",
            "title": "Neural Networks for Pattern Recognition"
        },
        {
            "paperId": null,
            "title": "Memory-based approaches to approximating continuous functions"
        },
        {
            "paperId": null,
            "title": "Carbon versus silicon: Matching wits with TD-Gammon"
        },
        {
            "paperId": "5c9bae1a3d1cdd5753a89f2c2355d62d5eafef9b",
            "title": "Responses of monkey dopamine neurons during learning of behavioral reactions."
        },
        {
            "paperId": "b3aa9d4b764b3e4c98d333ab67faf70e4346b289",
            "title": "Genetic Programming: On the Programming of Computers by Means of Natural Selection"
        },
        {
            "paperId": null,
            "title": "Approximate dynamic programming for real-time control and neural modeling"
        },
        {
            "paperId": null,
            "title": "Special issue of Machine Learning on reinforcement learning, 8. Also published as Reinforcement Learning"
        },
        {
            "paperId": null,
            "title": "Gain adaptation beats least squares? Proceedings of the Seventh Yale Workshop on Adaptive and Learning Systems, pp"
        },
        {
            "paperId": null,
            "title": "Applied learning: Optimal control for manufacturing"
        },
        {
            "paperId": null,
            "title": "Development and application of CMAC neural network-based control"
        },
        {
            "paperId": null,
            "title": "Reinforcement Learning. Kluwer Academic Press. Reprinting of a special double issue on reinforcement learning"
        },
        {
            "paperId": "efe838313137a8bf4ea8edfd4ec9562ff675c08a",
            "title": "An improved multi-dimensional CMAC neural network: Receptive field function and placement"
        },
        {
            "paperId": "87bfc4daa478433d8b18a47edf9112a25098cada",
            "title": "Planning by Incremental Dynamic Programming"
        },
        {
            "paperId": "1d8f86d4e674fe735af032a5518b0cf1c4a34ace",
            "title": "On the Computational Economics of Reinforcement Learning"
        },
        {
            "paperId": "3c4b219d75906253512b5b857db7ce8024622cb6",
            "title": "Adaptive Signal Processing"
        },
        {
            "paperId": "8d128edc658d5aceaffbaa38dc2846a2a732a637",
            "title": "Design Improvements in Associative Memories for Cerebellar Model Articulation Controllers (CMAC)"
        },
        {
            "paperId": "290d1e46b71673b35231cb3bcd848912782af6f1",
            "title": "Adaptive confidence and adaptive curiosity"
        },
        {
            "paperId": "428d7dcca59ad16b377b167aa9074f9278852186",
            "title": "Designing Economic Agents that Act Like Human Agents: A Behavioral Approach to Bounded Rationality"
        },
        {
            "paperId": "090c5a5df345ab60c41d6de02b3e366e1a27cf43",
            "title": "A logical calculus of the ideas immanent in nervous activity"
        },
        {
            "paperId": "a892210e032446b9da81177cd2d18b89a7b58f77",
            "title": "Time-Derivative Models of Pavlovian Reinforcement"
        },
        {
            "paperId": "8c393ec4cb7bc630d2bdd324547606daf343b76f",
            "title": "Consistency of HDP applied to a simple reinforcement learning problem"
        },
        {
            "paperId": "00b225d925dfa9ae8fe9ba52cafd4eef2092845a",
            "title": "A MATHEMATICAL ANALYSIS OF ACTOR-CRITIC ARCHITECTURES FOR LEARNING OPTIMAL CONTROLS THROUGH INCREMENTAL DYNAMIC PROGRAMMING (cid:3)"
        },
        {
            "paperId": "874b3a63422eeaf24c14435ee6091ed48247bff3",
            "title": "Efficient memory-based learning for robot control"
        },
        {
            "paperId": "e08d090d1e586610d636a46004876e9f3ded8209",
            "title": "A time-delay neural network architecture for isolated word recognition"
        },
        {
            "paperId": "bc6014884d291555d92b8dbef4635a1a9e192962",
            "title": "Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming"
        },
        {
            "paperId": null,
            "title": "A stochastic reinforcement algorithm for learning real-valued functions"
        },
        {
            "paperId": "360bbd61a6468ad31d7105df966c34dc83fd4a0e",
            "title": "Connectionist Learning for Control: An Overview"
        },
        {
            "paperId": "830ccb44084d9d6cdcb70d623df5012ae4835142",
            "title": "Training Stochastic Model Recognition Algorithms as Networks can Lead to Maximum Mutual Information Estimation of Parameters"
        },
        {
            "paperId": "410af288c634164a88d3a7051a94be677027fba1",
            "title": "Computational Capabilities of Single Neurons: Relationship to Simple Forms of Associative and Nonassociative Learning in Aplysia"
        },
        {
            "paperId": "c213af6582c0d518a6e8e14217611c733eeb1ef1",
            "title": "Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem"
        },
        {
            "paperId": null,
            "title": "Connectionist Problem Solving: Computational Aspects of Biological Learning"
        },
        {
            "paperId": null,
            "title": "Simulation of a classically conditioned response: A cerebellar implementation of the sutton-barto-desmond model"
        },
        {
            "paperId": "b08ba914037af6d88d16e2657a65cd9dc5cf5da1",
            "title": "Multivariable Functional Interpolation and Adaptive Networks"
        },
        {
            "paperId": "2e62d1345b340d5fda3b092c460264b9543bc4b5",
            "title": "Genetic Algorithms in Search Optimization and Machine Learning"
        },
        {
            "paperId": "266e07d0dd9a75b61e3632e9469993dbaf063f1c",
            "title": "Generalization of backpropagation with application to a recurrent gas market model"
        },
        {
            "paperId": null,
            "title": "Learning to predict by the method of temporal di\u21b5erences"
        },
        {
            "paperId": "8a8aea51f5a911e0964d51ac764dc04d5900b7b7",
            "title": "Strategy Learning with Multilayer Connectionist Representations"
        },
        {
            "paperId": "3abac8d1bf1a6c69805e8aa6f0335b66f39ca999",
            "title": "Building and Understanding Adaptive Systems: A Statistical/Numerical Approach to Factory Automation and Brain Research"
        },
        {
            "paperId": "c71ca26b183025b9f39f940f5e730f2c9a64e414",
            "title": "Radial basis functions for multivariable interpolation: a review"
        },
        {
            "paperId": "ff80b7820fbc54926946c245e139c382266489ae",
            "title": "Efficient Algorithms with Neural Network Behavior"
        },
        {
            "paperId": null,
            "title": "Gradient following without back-propagation in layered networks"
        },
        {
            "paperId": "8ae83806465bb89763a6ec4c1f87add1d5ee1841",
            "title": "Stochastic Systems: Estimation, Identification, and Adaptive Control"
        },
        {
            "paperId": "a0a88882d9dc6d77c3ff099f9ca84d24c91e138d",
            "title": "Estimator Algorithms for Learning Automata"
        },
        {
            "paperId": null,
            "title": "Escaping brittleness: The possibility of general-purpose learning algorithms applied to rule-based systems"
        },
        {
            "paperId": null,
            "title": "Reinforcement learning in connectionist networks: A mathematical analysis"
        },
        {
            "paperId": "84cdfa79e6eb9bf9e625e3af38d9f968df18a880",
            "title": "Learning by statistical cooperation of self-interested neuron-like computing elements."
        },
        {
            "paperId": "8c6ebb3ad0ec3839bae24912945e31804edd8bc7",
            "title": "A new approach to the design of reinforcement schemes for learning automata"
        },
        {
            "paperId": "d007ed936c51a700d8c65d1bbfae7acc83783c31",
            "title": "Une procedure d'apprentissage pour reseau a seuil asymmetrique (A learning scheme for asymmetric threshold networks)"
        },
        {
            "paperId": "58cc1683ec449657442b510dbdf05712d97c9657",
            "title": "The Logic of Limax Learning"
        },
        {
            "paperId": "22069cd4504656d3bb85748a4d43be7a4d7d5545",
            "title": "Temporal credit assignment in reinforcement learning"
        },
        {
            "paperId": "ff9da0b0a16634f76422d8533e1996aac9b871bc",
            "title": "Adaptive filtering prediction and control"
        },
        {
            "paperId": "041db552562217841768ef4669d2d7f4430ab1c0",
            "title": "The Role of the Critic in Learning Systems"
        },
        {
            "paperId": "e66422ef02bb1997132d2942109e1c97e662da93",
            "title": "Recursive Estimation and Time Series Analysis"
        },
        {
            "paperId": "e601ad411e21f7545ea26a5edc4d9f0f8b9f5b24",
            "title": "Some Themes and Primitives in Ill-Defined Systems"
        },
        {
            "paperId": "8b68cdf8d5835939abfed55399f4048db331aec3",
            "title": "A neural model of adaptive behavior"
        },
        {
            "paperId": "b1b800aacf850a18e6504c693b4c5d33b8b3ac32",
            "title": "State of the Art\u2014A Survey of Partially Observable Markov Decision Processes: Theory, Models, and Algorithms"
        },
        {
            "paperId": "fa277dfe3645463a25432282563fca4891d846ea",
            "title": "Applications of advances in nonlinear sensitivity analysis"
        },
        {
            "paperId": "b0063d47a1885e841d9aad1f5dd14651f17231df",
            "title": "Intelligent Behavior as an Adaptation to the Task Environment"
        },
        {
            "paperId": null,
            "title": "Conditioning with serial compound stimuli: Theoretical and empirical issues"
        },
        {
            "paperId": null,
            "title": "An adaptive network that constructs and uses an internal model of its world"
        },
        {
            "paperId": "fe9bdf273ff004f4f36eed70200a0ff0fa2ed7c3",
            "title": "Bacterial chemotaxis as a model behavioral system"
        },
        {
            "paperId": "827411d2ebf389a5a8289abd6f17174ed25a278e",
            "title": "Models of Learning Systems."
        },
        {
            "paperId": "287dbe085e815d2e9aad19dca6809dfb2ce33eee",
            "title": "The Art and Theory of Dynamic Programming"
        },
        {
            "paperId": null,
            "title": "Brainstorms, pp"
        },
        {
            "paperId": null,
            "title": "Single channel theory: A neuronal theory of learning"
        },
        {
            "paperId": null,
            "title": "Learning theory support for a single channel theory of the brain"
        },
        {
            "paperId": null,
            "title": "Tracking and trailing: Adaptation in movement strategies"
        },
        {
            "paperId": null,
            "title": "A unified theory of expectation in classical and instrumental conditioning"
        },
        {
            "paperId": "f3a217c11175f2cf904b2f7f6378b7ade176f2d0",
            "title": "Associative memory. A system-theoretical approach"
        },
        {
            "paperId": "10a392190244a4220e1989d22169707af95e82b6",
            "title": "Representation and Approximation of Surfaces"
        },
        {
            "paperId": "9eacc72402165e573a278089eadc65c23b9d18aa",
            "title": "Thinking with the teachable machine"
        },
        {
            "paperId": null,
            "title": "Advanced forecasting methods for global crisis warning and models of intelligence"
        },
        {
            "paperId": "f6a140e441dc62dc9b10fab690e32ae8a609e507",
            "title": "The apparent conflict between estimation and control\u2014a survey of the two-armed bandit problem"
        },
        {
            "paperId": "fe1e895222fb6a5184ee2222b32f8a32e1a48eea",
            "title": "Fitting surfaces to scattered data"
        },
        {
            "paperId": "c2a1a3211d50cfafd47b73c8fdea6ad401132587",
            "title": "A neural model of attention, reinforcement and discrimination learning."
        },
        {
            "paperId": "56623a496727d5c71491850e04512ddf4152b487",
            "title": "Beyond Regression : \"New Tools for Prediction and Analysis in the Behavioral Sciences"
        },
        {
            "paperId": "b32d0557b0bcc0db48902f758be5d97e0e76ca1b",
            "title": "Games of Stochastic Automata"
        },
        {
            "paperId": null,
            "title": "A summary appears"
        },
        {
            "paperId": "d5cb74a2e0ed05d8298f69d7d24600a583932f49",
            "title": "Automaton theory and modeling of biological systems"
        },
        {
            "paperId": "9eed0f983e871f8259c25e05c6184b031b9bda00",
            "title": "Human operators and automatic adaptive controllers: A comparative study on a particular control task"
        },
        {
            "paperId": "afaf65883ff75cc19926f61f181a687927789ad1",
            "title": "A theory of Pavlovian conditioning : Variations in the effectiveness of reinforcement and nonreinforcement"
        },
        {
            "paperId": null,
            "title": "Learned associations over long delays"
        },
        {
            "paperId": "3c6fcb9003001bf6a02328a642a089e2b3737d58",
            "title": "A learning machine with monologue"
        },
        {
            "paperId": "555a7921231b86464a8db34ada9edade765bf8f0",
            "title": "Stochastic Approximation"
        },
        {
            "paperId": null,
            "title": "Learning machines\u2014a unified view"
        },
        {
            "paperId": "1c771595221341d5b0647921b26e229fc7887395",
            "title": "Computation: Finite and Infinite Machines"
        },
        {
            "paperId": "05be5f2e21b49176750287fff0cc1496b0d93984",
            "title": "Foundations of conditioning and learning"
        },
        {
            "paperId": "69022c885504a091680cf2dc9cfc84597332ac69",
            "title": "Artificial Intelligence through Simulated Evolution"
        },
        {
            "paperId": null,
            "title": "Probability problem of pattern recognition learning and potential functions method"
        },
        {
            "paperId": "5673375315295948b44c8f4dde496609819a97af",
            "title": "God and Golem, inc. : a comment on certain points where cybernetics impinges on religion"
        },
        {
            "paperId": null,
            "title": "Experiments on the mechanisation of game learning"
        },
        {
            "paperId": "8db8ced348773ba0a3f6af6ec7ab6c1ac619f29b",
            "title": "Hilgard and Marquis' Conditioning and learning"
        },
        {
            "paperId": null,
            "title": "Blind variation and selective survival as a general strategy in knowledgeprocesses"
        },
        {
            "paperId": "b8ec3ae36f26e78f9a87a4edc5993d1a73a07cb7",
            "title": "Mathematical Games"
        },
        {
            "paperId": "6fd04fb2f6408868a7103b78d4c464478af5a9be",
            "title": "Individual Choice Behavior"
        },
        {
            "paperId": null,
            "title": "Theories of Learning, Second Edition"
        },
        {
            "paperId": null,
            "title": "Theory of Neural-Analog Reinforcement Systems and Its Application to the Brain-Model Problem"
        },
        {
            "paperId": "ef512f15aa1c294c7575aa329a7fecd80be6633b",
            "title": "Exposition of a New Theory on the Measurement of Risk"
        },
        {
            "paperId": null,
            "title": "A theoretical comparison of the e ciencies of two classical methods and a Monte Carlo method for computing one component of the solution of a set of linear algebraic equations"
        },
        {
            "paperId": null,
            "title": "Presentation of a maze-solving machine"
        },
        {
            "paperId": "1a6eacdbf4e881a91cf6b76a9f70f53ccc290ae1",
            "title": "Programming a computer for playing chess"
        },
        {
            "paperId": null,
            "title": "Adjustment of an inverse matrix corresponding to changes in the elements of a given column or a given row of the original matrix (abstract)"
        },
        {
            "paperId": "93f8c9b8483e4915429e4f68eb4b2cceacb68d95",
            "title": "The role of secondary reinforcement in delayed reward learning."
        },
        {
            "paperId": null,
            "title": "Markov processes and the Dirichlet problem"
        },
        {
            "paperId": null,
            "title": "Discriminative conditioning"
        },
        {
            "paperId": "5a6f35e30548fdc0e9f3d7d95bedb96689378498",
            "title": "The goal-gradient hypothesis and maze learning."
        },
        {
            "paperId": "e7b97073af3c395f38f0083f565f0d372fb61f76",
            "title": "Purposive Behavior in Animals and Men"
        },
        {
            "paperId": "69bd34fafbe1cfc12caee013533cba39e15a0c35",
            "title": "The effect of the introduction of reward upon the maze performance of rats"
        },
        {
            "paperId": "e33e131092925466292afaa90a10ac82bf49f006",
            "title": "Animal Intelligence"
        },
        {
            "paperId": "87ead78f0fb0e829a85728ccdb4d58680056afe8",
            "title": "Animal Intelligence: An Experimental Study of the Associative Processes in Animals"
        },
        {
            "paperId": null,
            "title": "The Sorcerers Apprentice"
        },
        {
            "paperId": "e1c2a2fd6a26947e5bbb8df47e30c1199ab1270d",
            "title": "Natural Gradient Works Eciently in Learning"
        },
        {
            "paperId": "d3bc022120f2622b1427807494d3163f40255b6a",
            "title": "Distributed Dynamic Programming"
        },
        {
            "paperId": "572379c1d56e7e19422ae38218ee228c61aefb2f",
            "title": "Asymptotically Efficient Adaptive Allocation Rules"
        },
        {
            "paperId": "f3f3257597b65ce8dcacba31d5957967b867d56d",
            "title": "Opinion TRENDS in Cognitive Sciences Vol.10 No.7 July2006 Special Issue: Probabilistic models of cognition Bayesian theories of conditioning in a changing world"
        },
        {
            "paperId": "8d2f4c7419d0b15ab545df18cefdb0ea4dbe1231",
            "title": "of Experimental Psychology"
        },
        {
            "paperId": "5e35281b59dd49297b36c522f54c0eef9f7fdf5f",
            "title": "Ieee Transactions on Evolutionary Computation Intrinsic Motivation Systems for Autonomous Mental Development"
        },
        {
            "paperId": "145a42e83ec142a125da3ad845ee95027ef702e5",
            "title": "Ieee Transactions on Systems, Man and Cybernetics\u2014part C: Applications and Reviews 1 a Survey of Actor-critic Reinforcement Learning: Standard and Natural Policy Gradients"
        }
    ]
}