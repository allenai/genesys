{
    "paperId": "eb42cf88027de515750f230b23b1a057dc782108",
    "externalIds": {
        "MAG": "2949429431",
        "ArXiv": "1409.1556",
        "DBLP": "journals/corr/SimonyanZ14a",
        "CorpusId": 14124313
    },
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.",
    "venue": "International Conference on Learning Representations",
    "year": 2014,
    "referenceCount": 43,
    "citationCount": 92491,
    "influentialCitationCount": 13572,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work investigates the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting using an architecture with very small convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "34838386",
            "name": "K. Simonyan"
        },
        {
            "authorId": "1688869",
            "name": "Andrew Zisserman"
        }
    ],
    "references": [
        {
            "paperId": "9e46f2b8e00a31d06662b276d46b37852ec725c9",
            "title": "Example Selection For Dictionary Learning"
        },
        {
            "paperId": "48e8cc2d5651053c0bc2fcd20787cca0782f2b94",
            "title": "Actions and Attributes from Wholes and Parts"
        },
        {
            "paperId": "55e022fb7581bb9e1fce678d21fb25ffbb3fbb88",
            "title": "Deep visual-semantic alignments for generating image descriptions"
        },
        {
            "paperId": "0959ef8fefe9e7041f508c2448fc026bc9e08393",
            "title": "Material recognition in the wild with the Materials in Context Database"
        },
        {
            "paperId": "6afd65d1b72e8726f4ae19367a399da1de506edf",
            "title": "Deep convolutional filter banks for texture recognition and segmentation"
        },
        {
            "paperId": "6fc6803df5f9ae505cae5b2f178ade4062c768d0",
            "title": "Fully convolutional networks for semantic segmentation"
        },
        {
            "paperId": "2e36ea91a3c8fbff92be2989325531b4002e2afc",
            "title": "Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models"
        },
        {
            "paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327",
            "title": "Going deeper with convolutions"
        },
        {
            "paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd",
            "title": "ImageNet Large Scale Visual Recognition Challenge"
        },
        {
            "paperId": "616b246e332573af1f4859aa91440280774c183a",
            "title": "The Pascal Visual Object Classes Challenge: A Retrospective"
        },
        {
            "paperId": "c08f5fa876181fc040d76c75fe2433eee3c9b001",
            "title": "Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks"
        },
        {
            "paperId": "cbb19236820a96038d000dc629225d36e0b6294a",
            "title": "Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition"
        },
        {
            "paperId": "67dccc9a856b60bdc4d058d83657a089b8ad4486",
            "title": "Two-Stream Convolutional Networks for Action Recognition in Videos"
        },
        {
            "paperId": "14d9be7962a4ec5a6e55755f4c7588ea00793652",
            "title": "Return of the Devil in the Details: Delving Deep into Convolutional Nets"
        },
        {
            "paperId": "80d800dfadbe2e6c7b2367d9229cc82912d55889",
            "title": "One weird trick for parallelizing convolutional neural networks"
        },
        {
            "paperId": "6270baedeba28001cd1b563a199335720d6e0fe0",
            "title": "CNN Features Off-the-Shelf: An Astounding Baseline for Recognition"
        },
        {
            "paperId": "1109b663453e78a59e4f66446d71720ac58cec25",
            "title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks"
        },
        {
            "paperId": "dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71",
            "title": "Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps"
        },
        {
            "paperId": "99c970348b8f70ce23d6641e201904ea49266b6e",
            "title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks"
        },
        {
            "paperId": "b3d8dffb73bc93de239998548386c84177caa2ad",
            "title": "Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks"
        },
        {
            "paperId": "d67175d17c450ab0ac9c256103828f9e9a0acb85",
            "title": "Some Improvements on Deep Convolutional Neural Network Based Image Classification"
        },
        {
            "paperId": "5e83ab70d0cbc003471e87ec306d27d9c80ecb16",
            "title": "Network In Network"
        },
        {
            "paperId": "1a2a770d23b4a171fa81de62a78a3deb0588f238",
            "title": "Visualizing and Understanding Convolutional Networks"
        },
        {
            "paperId": "2f4df08d9072fc2ac181b7fced6a245315ce05c8",
            "title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation"
        },
        {
            "paperId": "b8de958fead0d8a9619b55c7299df3257c624a96",
            "title": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition"
        },
        {
            "paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "title": "ImageNet classification with deep convolutional neural networks"
        },
        {
            "paperId": "3127190433230b3dc1abd0680bb58dced4bcd90e",
            "title": "Large Scale Distributed Deep Networks"
        },
        {
            "paperId": "398c296d0cc7f9d180f84969f8937e6d3a413796",
            "title": "Multi-column deep neural networks for image classification"
        },
        {
            "paperId": "39f3b1804b8df5be645a1dcb4a876e128385d9be",
            "title": "Improving the Fisher Kernel for Large-Scale Image Classification"
        },
        {
            "paperId": "3a9b175324ba11bc0e16c0633912d897b2fac4e2",
            "title": "The Pascal Visual Object Classes (VOC) Challenge"
        },
        {
            "paperId": "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649",
            "title": "Understanding the difficulty of training deep feedforward neural networks"
        },
        {
            "paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e",
            "title": "ImageNet: A large-scale hierarchical image database"
        },
        {
            "paperId": "5a5effa909cdeafaddbbb7855037e02f8e25d632",
            "title": "Caltech-256 Object Category Dataset"
        },
        {
            "paperId": "ed9db7b20e019cdb1c7db8b7921221ee2d9f36e2",
            "title": "Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories"
        },
        {
            "paperId": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27",
            "title": "Backpropagation Applied to Handwritten Zip Code Recognition"
        },
        {
            "paperId": "75aa1f1a04b5f2bb6bf9afb662711121edde9eda",
            "title": "A and V"
        },
        {
            "paperId": "4423522df1dd92d04e303ae2e2f7fa0d998fe862",
            "title": "Regularized Max Pooling for Image Categorization"
        },
        {
            "paperId": null,
            "title": "class-agnostic single-class regression (SCR), which differs from the findings"
        },
        {
            "paperId": null,
            "title": "CNN: Single-label to multi-label"
        },
        {
            "paperId": null,
            "title": "Caffe: An open source convolutional architecture for fast feature embedding"
        },
        {
            "paperId": "3d2218b17e7898a222e5fc2079a3f1531990708f",
            "title": "I and J"
        },
        {
            "paperId": null,
            "title": "Large scale visual recognition challenge (ILSVRC), 2010. URL http://www.image-net.org/challenges"
        },
        {
            "paperId": "5a47ba057a858f8c024d2518cc3731fc7eb40de1",
            "title": "Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence Flexible, High Performance Convolutional Neural Networks for Image Classification"
        }
    ]
}