{
    "paperId": "5b6ec746d309b165f9f9def873a2375b6fb40f3d",
    "externalIds": {
        "DBLP": "conf/cvpr/Chollet17",
        "ArXiv": "1610.02357",
        "MAG": "2531409750",
        "DOI": "10.1109/CVPR.2017.195",
        "CorpusId": 2375110
    },
    "title": "Xception: Deep Learning with Depthwise Separable Convolutions",
    "abstract": "We present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and significantly outperforms Inception V3 on a larger image classification dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters.",
    "venue": "Computer Vision and Pattern Recognition",
    "year": 2016,
    "referenceCount": 27,
    "citationCount": 12698,
    "influentialCitationCount": 1621,
    "openAccessPdf": {
        "url": "https://arxiv.org/pdf/1610.02357",
        "status": "GREEN"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions, and shows that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset, and significantly outperforms it on a larger image classification dataset."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "1565641737",
            "name": "Fran\u00e7ois Chollet"
        }
    ],
    "references": [
        {
            "paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e",
            "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"
        },
        {
            "paperId": "977bf40fe28f773b95d6802e694505beac78441d",
            "title": "Factorized Convolutional Neural Networks"
        },
        {
            "paperId": "d20da75866f500ee9fbfa859e69556702e1f50a4",
            "title": "Design of Efficient Convolutional Layers using Single Intra-channel Convolution, Topological Subdivisioning and Spatial \"Bottleneck\" Structure"
        },
        {
            "paperId": "b5c26ab8767d046cb6e32d959fdf726aee89bb62",
            "title": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning"
        },
        {
            "paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "title": "Deep Residual Learning for Image Recognition"
        },
        {
            "paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58",
            "title": "Rethinking the Inception Architecture for Computer Vision"
        },
        {
            "paperId": "f63e917638553414526a0cc8550de4ad2d83fe7a",
            "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)"
        },
        {
            "paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19",
            "title": "Distilling the Knowledge in a Neural Network"
        },
        {
            "paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e",
            "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
        },
        {
            "paperId": "30ae2bdef407e7a05b83781907ad7fb257dcd7a1",
            "title": "Flattened Convolutional Neural Networks for Feedforward Acceleration"
        },
        {
            "paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327",
            "title": "Going deeper with convolutions"
        },
        {
            "paperId": "eb42cf88027de515750f230b23b1a057dc782108",
            "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
        },
        {
            "paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd",
            "title": "ImageNet Large Scale Visual Recognition Challenge"
        },
        {
            "paperId": "5e83ab70d0cbc003471e87ec306d27d9c80ecb16",
            "title": "Network In Network"
        },
        {
            "paperId": "1a2a770d23b4a171fa81de62a78a3deb0588f238",
            "title": "Visualizing and Understanding Convolutional Networks"
        },
        {
            "paperId": "528beaa995bf1bd1ae451b18218674af9ecd2b50",
            "title": "Rotation, Scaling and Deformation Invariant Scattering for Texture Discrimination"
        },
        {
            "paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "title": "ImageNet classification with deep convolutional neural networks"
        },
        {
            "paperId": "4dbc68cf2e14155edb6da0def30661aca8c96c22",
            "title": "Simplifying ConvNets for Fast Learning"
        },
        {
            "paperId": "6dc61f37ecc552413606d8c89ffbc46ec98ed887",
            "title": "Acceleration of stochastic approximation by averaging"
        },
        {
            "paperId": null,
            "title": "Tf-slim"
        },
        {
            "paperId": null,
            "title": "Keras"
        },
        {
            "paperId": null,
            "title": "Software available from tensorflow.org"
        },
        {
            "paperId": null,
            "title": "Wicke, Y. Yu, and X. Zheng. Tensor- Flow: Large-scale machine learning on heterogeneous systems"
        },
        {
            "paperId": null,
            "title": "Rigid-motion scattering for image classi\ufb01cation"
        },
        {
            "paperId": null,
            "title": "Learning visual representations at scale"
        },
        {
            "paperId": null,
            "title": "Divide the gradient by a running average of its recent magnitude"
        },
        {
            "paperId": "842dd6d0f4b72ce0e8f3ac8e6861637c1f4645ea",
            "title": "Learning algorithms for classification: A comparison on handwritten digit recognition"
        }
    ]
}