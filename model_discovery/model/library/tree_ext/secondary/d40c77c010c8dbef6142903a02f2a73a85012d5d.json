{
    "paperId": "d40c77c010c8dbef6142903a02f2a73a85012d5d",
    "externalIds": {
        "DBLP": "journals/pami/00020C0GLTXXXYZ23",
        "ArXiv": "2012.12556",
        "DOI": "10.1109/TPAMI.2022.3152247",
        "CorpusId": 236986986,
        "PubMed": "35180075"
    },
    "title": "A Survey on Vision Transformer",
    "abstract": "Transformer, first applied to the field of natural language processing, is a type of deep neural network mainly based on the self-attention mechanism. Thanks to its strong representation capabilities, researchers are looking at ways to apply transformer to computer vision tasks. In a variety of visual benchmarks, transformer-based models perform similar to or better than other types of networks such as convolutional and recurrent neural networks. Given its high performance and less need for vision-specific inductive bias, transformer is receiving more and more attention from the computer vision community. In this paper, we review these vision transformer models by categorizing them in different tasks and analyzing their advantages and disadvantages. The main categories we explore include the backbone network, high/mid-level vision, low-level vision, and video processing. We also include efficient transformer methods for pushing transformer into real device-based applications. Furthermore, we also take a brief look at the self-attention mechanism in computer vision, as it is the base component in transformer. Toward the end of this paper, we discuss the challenges and provide several further research directions for vision transformers.",
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "year": 2020,
    "referenceCount": 326,
    "citationCount": 1331,
    "influentialCitationCount": 29,
    "openAccessPdf": {
        "url": "https://arxiv.org/pdf/2012.12556",
        "status": "GREEN"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper reviews these vision transformer models by categorizing them in different tasks and analyzing their advantages and disadvantages, and takes a brief look at the self-attention mechanism in computer vision, as it is the base component in transformer."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -1.3218327760696411,
            -3.4228944778442383,
            1.1124250888824463,
            5.72465705871582,
            0.5473486185073853,
            0.47200915217399597,
            5.71686315536499,
            -0.9655560255050659,
            1.9659008979797363,
            -2.245025634765625,
            -2.5838875770568848,
            4.351495742797852,
            -0.5506507158279419,
            1.3804631233215332,
            -2.293694496154785,
            -1.912052035331726,
            1.0478752851486206,
            -1.6104979515075684,
            2.0261895656585693,
            0.6886869072914124,
            -0.6963170766830444,
            1.1474661827087402,
            -2.317437171936035,
            0.0949276015162468,
            -2.4183154106140137,
            0.7576791048049927,
            0.888364851474762,
            1.3279796838760376,
            -4.639527320861816,
            -1.414644718170166,
            0.4898715019226074,
            -4.468774795532227,
            2.080550193786621,
            -2.352088212966919,
            1.7727632522583008,
            0.6012029647827148,
            -3.9296350479125977,
            5.553211688995361,
            -2.79854154586792,
            -3.5023033618927,
            2.6262941360473633,
            2.132472038269043,
            3.336573362350464,
            -0.36213624477386475,
            1.7604318857192993,
            -1.0514037609100342,
            -1.1136491298675537,
            2.302050828933716,
            1.5775429010391235,
            3.4215455055236816,
            2.87549090385437,
            1.776768445968628,
            -0.6644829511642456,
            0.5869777798652649,
            -0.0693448930978775,
            0.9430469870567322,
            2.954448938369751,
            2.8008875846862793,
            -0.24627885222434998,
            -0.5608389377593994,
            4.153862953186035,
            6.706479072570801,
            3.3612637519836426,
            1.3209898471832275,
            3.998857021331787,
            -2.996044874191284,
            -1.6717002391815186,
            3.616454601287842,
            1.8824647665023804,
            0.8111670017242432,
            0.02934175729751587,
            -6.3174967765808105,
            3.5499892234802246,
            -3.0725886821746826,
            -4.374736785888672,
            -1.3357709646224976,
            0.8454378843307495,
            -4.4813032150268555,
            0.3042141795158386,
            -1.267292857170105,
            0.028836652636528015,
            3.9175546169281006,
            -0.2909186780452728,
            0.525958240032196,
            5.642671585083008,
            -1.1947239637374878,
            -4.348176002502441,
            -2.956800699234009,
            -1.6650810241699219,
            -2.7249398231506348,
            -3.664231777191162,
            -0.9345818758010864,
            1.6226807832717896,
            0.5159201622009277,
            -2.013943672180176,
            1.0134563446044922,
            3.671703338623047,
            -3.402167797088623,
            -3.4116456508636475,
            1.5365720987319946,
            0.05384469032287598,
            -2.132176399230957,
            -1.8126912117004395,
            0.7845010757446289,
            1.4253226518630981,
            -2.1453683376312256,
            0.8965649604797363,
            -0.5973875522613525,
            0.28300192952156067,
            -1.255759835243225,
            -3.833116292953491,
            4.590097427368164,
            -0.8139756321907043,
            2.716515064239502,
            -2.3435401916503906,
            2.37209153175354,
            0.6892334222793579,
            1.5278488397598267,
            0.07258811593055725,
            1.6292543411254883,
            -0.844171404838562,
            -3.509159803390503,
            -5.981781005859375,
            1.822916030883789,
            1.901523470878601,
            2.6352481842041016,
            -0.9344569444656372,
            6.028979778289795,
            2.979867935180664,
            -5.403779983520508,
            2.4113681316375732,
            -4.923638343811035,
            0.915658712387085,
            -0.6345993876457214,
            3.516852378845215,
            1.8638346195220947,
            0.525523841381073,
            1.2025680541992188,
            -1.646903395652771,
            1.1045554876327515,
            -0.6486861705780029,
            1.4978556632995605,
            2.473568916320801,
            0.6844184398651123,
            -0.13423532247543335,
            1.2512753009796143,
            0.2518486976623535,
            -2.7738327980041504,
            1.0552387237548828,
            5.3490309715271,
            1.7000653743743896,
            -4.628134727478027,
            -2.158952236175537,
            3.4170761108398438,
            1.3762907981872559,
            2.923015832901001,
            -7.329403877258301,
            0.25472140312194824,
            -1.9223597049713135,
            2.006176471710205,
            -2.2142319679260254,
            -0.5822358727455139,
            -9.98643970489502,
            1.0404765605926514,
            0.24957919120788574,
            -6.2352375984191895,
            1.1288189888000488,
            3.7323880195617676,
            -1.1957533359527588,
            5.942389488220215,
            1.6272602081298828,
            -0.25089386105537415,
            0.8727846741676331,
            4.428460121154785,
            2.3014886379241943,
            6.592925548553467,
            0.06447595357894897,
            -0.5893844962120056,
            -1.878579020500183,
            -0.7978652715682983,
            -0.8100581169128418,
            -0.683771014213562,
            -6.913421630859375,
            0.7000740170478821,
            -2.0675978660583496,
            -5.6107892990112305,
            -0.6418574452400208,
            0.5511365532875061,
            -3.0131213665008545,
            -2.3482666015625,
            1.913843035697937,
            1.3535714149475098,
            6.508755683898926,
            5.096395492553711,
            3.130873918533325,
            0.3868144154548645,
            3.1232924461364746,
            5.100661277770996,
            -3.5665245056152344,
            0.18984238803386688,
            0.7123415470123291,
            -2.0725221633911133,
            1.0462162494659424,
            -2.581606149673462,
            2.7190070152282715,
            1.1302785873413086,
            -5.861273765563965,
            0.8141778111457825,
            2.8120927810668945,
            -0.6079789400100708,
            -0.6083996295928955,
            -4.495880126953125,
            -0.9211423397064209,
            5.831879615783691,
            -4.9960784912109375,
            -3.309302806854248,
            -5.396665573120117,
            1.0915443897247314,
            5.510908126831055,
            -0.15861889719963074,
            0.14692986011505127,
            4.169195175170898,
            -3.4077858924865723,
            -5.321747779846191,
            0.38300466537475586,
            -1.7230042219161987,
            1.8258366584777832,
            2.134481191635132,
            0.322107195854187,
            1.9241881370544434,
            -1.060586929321289,
            -4.398498058319092,
            2.4387154579162598,
            -3.8941287994384766,
            -5.181023120880127,
            -2.7271621227264404,
            -4.245901107788086,
            -1.2463277578353882,
            -0.7384077906608582,
            -1.5479005575180054,
            3.4295506477355957,
            2.449090003967285,
            1.6336250305175781,
            4.001946449279785,
            -0.9771555662155151,
            -3.8001723289489746,
            -0.6258059740066528,
            2.04319167137146,
            3.1144397258758545,
            -2.922416925430298,
            1.7075923681259155,
            0.10018479824066162,
            3.7284345626831055,
            -2.4129629135131836,
            -0.3948924243450165,
            0.30547893047332764,
            3.883543014526367,
            -1.1065728664398193,
            -2.326077699661255,
            1.3497157096862793,
            0.16367408633232117,
            4.687605857849121,
            3.1825168132781982,
            4.134458541870117,
            -2.970210552215576,
            0.1582934856414795,
            -1.567749261856079,
            -0.547348141670227,
            -2.330048084259033,
            5.286019802093506,
            3.2668752670288086,
            -0.7350095510482788,
            0.1630166471004486,
            -2.29717755317688,
            -1.949517011642456,
            -1.2215304374694824,
            -3.217805862426758,
            -0.8541170358657837,
            3.722111701965332,
            1.1974856853485107,
            3.1173274517059326,
            0.013421431183815002,
            -1.5775790214538574,
            -2.7647252082824707,
            1.149705171585083,
            -2.7423930168151855,
            -3.8680343627929688,
            -1.8999797105789185,
            -0.8021703362464905,
            -0.851311981678009,
            -5.217373847961426,
            2.5811071395874023,
            -2.254209518432617,
            3.3096835613250732,
            0.16379280388355255,
            2.534513235092163,
            3.0836734771728516,
            2.5942904949188232,
            -0.29462730884552,
            0.13692045211791992,
            -3.5174691677093506,
            0.9711432456970215,
            3.500223159790039,
            -1.7731680870056152,
            3.415853261947632,
            2.7097959518432617,
            2.0642542839050293,
            -3.2717647552490234,
            -0.8738465309143066,
            -1.4922808408737183,
            -2.3022236824035645,
            -1.3990614414215088,
            6.335692882537842,
            -4.26685905456543,
            -0.2811686396598816,
            -1.290511965751648,
            -0.19156038761138916,
            -0.1478118747472763,
            -0.27037692070007324,
            -0.0761338472366333,
            0.9343277812004089,
            2.8154120445251465,
            -1.541539192199707,
            -4.382774829864502,
            -1.9977647066116333,
            -1.9106271266937256,
            2.8536131381988525,
            1.0879939794540405,
            -3.0411529541015625,
            3.9234657287597656,
            4.207683563232422,
            2.6577224731445312,
            1.2681081295013428,
            -0.359866738319397,
            0.5780309438705444,
            -5.338663578033447,
            0.9287262558937073,
            2.268009901046753,
            1.6730756759643555,
            0.07136575877666473,
            -0.8440829515457153,
            5.9537787437438965,
            0.935329258441925,
            2.525794744491577,
            5.2729291915893555,
            1.894891619682312,
            1.387964129447937,
            -1.3437764644622803,
            1.6512055397033691,
            -3.5089938640594482,
            -0.5211618542671204,
            2.768392562866211,
            0.860572874546051,
            -3.4130845069885254,
            1.331462025642395,
            1.6898051500320435,
            2.4399261474609375,
            -0.692578911781311,
            -0.567740797996521,
            1.7000335454940796,
            -1.407623052597046,
            0.25408831238746643,
            2.8340442180633545,
            -2.5864481925964355,
            -1.5245342254638672,
            -3.061974287033081,
            9.943177223205566,
            -0.5590875148773193,
            -1.8749159574508667,
            -2.780472755432129,
            -3.752467155456543,
            -1.4970358610153198,
            -0.26690804958343506,
            7.356105327606201,
            -0.9450051784515381,
            -3.6834726333618164,
            0.8551493883132935,
            -2.441000461578369,
            0.09527869522571564,
            1.1137222051620483,
            1.878125548362732,
            4.133255958557129,
            -1.8783124685287476,
            3.7516214847564697,
            -0.033194154500961304,
            -0.7363108396530151,
            -2.9773707389831543,
            0.0065512508153915405,
            4.9848551750183105,
            1.3967264890670776,
            -0.6096252202987671,
            2.0561306476593018,
            -0.15550607442855835,
            -1.7341033220291138,
            -3.3007614612579346,
            -6.970623016357422,
            -4.32737922668457,
            -5.706730842590332,
            2.0056211948394775,
            -1.0886989831924438,
            -2.230229616165161,
            3.4651260375976562,
            3.0368285179138184,
            3.4420113563537598,
            -4.0290422439575195,
            -1.9628968238830566,
            3.8962502479553223,
            1.0844359397888184,
            -0.6647910475730896,
            1.1448307037353516,
            -2.105215549468994,
            -1.065892219543457,
            1.5323781967163086,
            -0.8336782455444336,
            0.4003888964653015,
            -1.594173550605774,
            2.132272720336914,
            2.2865352630615234,
            4.378274917602539,
            -0.5135696530342102,
            -3.0922226905822754,
            1.6885313987731934,
            4.516479969024658,
            0.990322470664978,
            -1.496129035949707,
            0.20598919689655304,
            2.6350088119506836,
            4.013091087341309,
            -1.9241580963134766,
            1.9840686321258545,
            -3.0805647373199463,
            3.12154483795166,
            -2.062774896621704,
            -0.9930447936058044,
            0.47101080417633057,
            -0.4666348099708557,
            -0.030209466814994812,
            3.5609943866729736,
            3.4535939693450928,
            -1.1432654857635498,
            0.565244197845459,
            2.7150416374206543,
            -1.8181830644607544,
            5.4793572425842285,
            -1.4550058841705322,
            -0.13054990768432617,
            -0.45905014872550964,
            0.5939087867736816,
            0.970263659954071,
            -1.4566435813903809,
            2.5600171089172363,
            -1.830297827720642,
            -2.0014796257019043,
            -2.3503873348236084,
            0.7691880464553833,
            -1.545392632484436,
            -2.3209898471832275,
            -0.6217600107192993,
            1.9639787673950195,
            0.6181297302246094,
            -6.702037334442139,
            4.225074768066406,
            -1.7308465242385864,
            1.9564590454101562,
            2.8132662773132324,
            4.587978363037109,
            1.0447378158569336,
            -1.0768084526062012,
            -0.08846926689147949,
            0.497477263212204,
            7.092036724090576,
            0.3225920498371124,
            -2.8867194652557373,
            -1.1961355209350586,
            0.43504905700683594,
            1.6793256998062134,
            -1.6101536750793457,
            0.6189374923706055,
            -0.05017128586769104,
            -2.2859787940979004,
            -3.0317115783691406,
            -1.609754204750061,
            4.252079486846924,
            -1.386230707168579,
            -4.336021423339844,
            7.47177791595459,
            5.857548236846924,
            3.263014316558838,
            2.124079942703247,
            1.185009479522705,
            0.2745048701763153,
            -0.7532214522361755,
            4.057750701904297,
            -4.677986145019531,
            1.9070075750350952,
            -2.25622296333313,
            -2.9669580459594727,
            3.3212904930114746,
            1.277956247329712,
            -2.716346502304077,
            1.6796698570251465,
            -7.3763041496276855,
            -2.322016716003418,
            0.6404619812965393,
            -0.4446141719818115,
            5.704930782318115,
            3.200376033782959,
            -0.3747714161872864,
            0.4019213318824768,
            -3.1296868324279785,
            -2.7350990772247314,
            -0.17305251955986023,
            -3.1809921264648438,
            -0.006196379661560059,
            -3.962167263031006,
            2.8256258964538574,
            4.192928314208984,
            -3.0261635780334473,
            0.5795542001724243,
            0.12085992097854614,
            0.15488094091415405,
            -0.08861486613750458,
            -0.15472422540187836,
            3.7560038566589355,
            -0.08653641492128372,
            1.0976208448410034,
            -3.422013759613037,
            1.9712510108947754,
            0.1322430968284607,
            4.821786880493164,
            1.2906744480133057,
            1.0209554433822632,
            2.064934253692627,
            -0.960243821144104,
            -3.007455587387085,
            -4.496062278747559,
            -2.444537401199341,
            1.0086278915405273,
            -0.6729310154914856,
            -1.2733280658721924,
            -0.3738430142402649,
            3.2131974697113037,
            -0.5576375722885132,
            3.2362136840820312,
            -1.7260715961456299,
            0.9825650453567505,
            -3.292229652404785,
            -1.0306010246276855,
            -3.189913511276245,
            1.5963069200515747,
            -1.0559464693069458,
            0.9290225505828857,
            0.7131403684616089,
            -1.8131343126296997,
            -1.9279887676239014,
            1.3914278745651245,
            -3.478982925415039,
            -3.206455945968628,
            0.9866199493408203,
            2.1183314323425293,
            3.00044584274292,
            -1.6717734336853027,
            -1.5436276197433472,
            4.633715629577637,
            -4.1809611320495605,
            -1.7995941638946533,
            3.9484105110168457,
            4.5412750244140625,
            -0.730571985244751,
            -3.2073771953582764,
            0.26461726427078247,
            -3.5386829376220703,
            -0.13640129566192627,
            1.4238077402114868,
            1.2343065738677979,
            6.3994927406311035,
            3.010589122772217,
            5.170107841491699,
            -6.4430646896362305,
            1.4879711866378784,
            -2.0816681385040283,
            0.16624155640602112,
            -1.4793446063995361,
            -3.194406509399414,
            2.4458084106445312,
            -1.6926522254943848,
            -4.574620246887207,
            1.3120784759521484,
            -1.6993520259857178,
            -2.5394887924194336,
            2.49676513671875,
            0.5412171483039856,
            1.8100988864898682,
            -5.433443069458008,
            -3.60495662689209,
            -5.065064907073975,
            2.2338829040527344,
            1.7305301427841187,
            -3.7512519359588623,
            4.45543909072876,
            4.039599895477295,
            4.9639692306518555,
            3.908264398574829,
            1.3177822828292847,
            -0.6384843587875366,
            2.8129472732543945,
            0.43629637360572815,
            1.5665264129638672,
            -0.016429513692855835,
            1.3539292812347412,
            -0.963318407535553,
            3.705233097076416,
            16.067720413208008,
            4.175325870513916,
            1.5841026306152344,
            -4.176451206207275,
            -2.0664868354797363,
            -1.8696070909500122,
            1.2797033786773682,
            -0.637549877166748,
            0.22887015342712402,
            1.9998490810394287,
            -1.3641526699066162,
            -2.0144693851470947,
            -1.617541790008545,
            1.3452067375183105,
            -5.064483642578125,
            -0.8415340781211853,
            -3.077983856201172,
            1.4800188541412354,
            -1.9482048749923706,
            -1.5044480562210083,
            -1.7783787250518799,
            0.40534406900405884,
            -1.1783082485198975,
            -1.1008100509643555,
            -3.266033887863159,
            4.211726188659668,
            2.347961664199829,
            0.3583320081233978,
            -6.103440284729004,
            2.9767136573791504,
            1.2359117269515991,
            -0.5701963901519775,
            4.194953918457031,
            -1.3141175508499146,
            -4.8257975578308105,
            5.0439653396606445,
            3.3486781120300293,
            0.2379673719406128,
            3.542240858078003,
            -0.06932884454727173,
            -0.9700033068656921,
            2.0755720138549805,
            -7.416867256164551,
            0.5325685143470764,
            3.525198459625244,
            2.3958330154418945,
            0.12982261180877686,
            -3.238610029220581,
            -2.3274126052856445,
            5.037314414978027,
            2.401655912399292,
            -1.660492181777954,
            1.1198344230651855,
            3.305919647216797,
            4.558727264404297,
            6.097024917602539,
            -0.24256503582000732,
            -3.722188949584961,
            1.86020827293396,
            -0.7148743271827698,
            1.5664589405059814,
            -0.027091383934020996,
            -1.746263861656189,
            -3.5872750282287598,
            0.09075531363487244,
            2.055119514465332,
            -6.7026753425598145,
            3.979045867919922,
            0.5285570621490479,
            3.006072759628296,
            0.8670443296432495,
            2.6221837997436523,
            0.5863275527954102,
            -3.644117832183838,
            -4.385486602783203,
            -2.7896063327789307,
            -0.5360538959503174,
            -1.2317442893981934,
            2.3625354766845703,
            3.5743207931518555,
            -5.369700908660889,
            3.338329553604126,
            -2.8149828910827637,
            0.6255447864532471,
            7.846119403839111,
            -2.5762081146240234,
            4.369877338409424,
            1.3652923107147217,
            1.6087461709976196,
            3.889655828475952,
            0.0044176578521728516,
            -2.696969985961914,
            3.5940964221954346,
            0.16926085948944092,
            2.3275232315063477,
            -5.391900539398193,
            -0.5159251689910889,
            -0.4348403215408325,
            -4.077568054199219,
            -6.161682605743408,
            4.70789909362793,
            3.7220072746276855,
            0.5982658863067627,
            -1.9306385517120361,
            -2.43428897857666,
            -2.303144931793213,
            0.9138305187225342,
            -3.5700135231018066,
            -2.5538573265075684,
            -2.9874045848846436,
            4.6014227867126465,
            -3.2321419715881348,
            0.22870180010795593,
            1.7211194038391113,
            0.06657004356384277,
            0.21365343034267426,
            -3.80473256111145,
            5.647381782531738,
            2.0723557472229004,
            0.9177457094192505,
            1.0779850482940674,
            -1.8355520963668823,
            -1.93992018699646,
            -6.123088836669922,
            -4.542117118835449,
            -0.15025249123573303,
            3.1071267127990723,
            2.2221384048461914,
            1.213172435760498,
            -5.352976322174072,
            0.49651235342025757,
            -0.9113488793373108,
            -2.0802218914031982,
            -1.2071497440338135,
            -3.6799049377441406,
            -1.0489962100982666,
            -1.8562953472137451,
            3.883352041244507,
            -1.9260746240615845,
            3.4513344764709473,
            3.9160003662109375,
            -1.8157260417938232,
            1.733981966972351,
            6.879100799560547,
            -2.737567901611328,
            -1.9787092208862305,
            -3.079475164413452,
            -0.45314985513687134,
            -1.5589287281036377,
            0.34286582469940186,
            -0.7341762781143188,
            3.822206497192383,
            4.0476603507995605,
            -3.9568471908569336,
            -4.853159427642822,
            -3.23753023147583
        ]
    },
    "authors": [
        {
            "authorId": "3826388",
            "name": "Kai Han"
        },
        {
            "authorId": "2108702980",
            "name": "Yunhe Wang"
        },
        {
            "authorId": "2118023932",
            "name": "Hanting Chen"
        },
        {
            "authorId": "1736061",
            "name": "Xinghao Chen"
        },
        {
            "authorId": "2148899357",
            "name": "Jianyuan Guo"
        },
        {
            "authorId": "2125024057",
            "name": "Zhenhua Liu"
        },
        {
            "authorId": "103603255",
            "name": "Yehui Tang"
        },
        {
            "authorId": "1569696821",
            "name": "An Xiao"
        },
        {
            "authorId": "1691522",
            "name": "Chunjing Xu"
        },
        {
            "authorId": "2127897462",
            "name": "Yixing Xu"
        },
        {
            "authorId": "2116369043",
            "name": "Zhaohui Yang"
        },
        {
            "authorId": "2108440680",
            "name": "Yiman Zhang"
        },
        {
            "authorId": "143719920",
            "name": "D. Tao"
        }
    ],
    "references": [
        {
            "paperId": "c57293882b2561e1ba03017902df9fc2f289dea2",
            "title": "Hierarchical Text-Conditional Image Generation with CLIP Latents"
        },
        {
            "paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
            "title": "High-Resolution Image Synthesis with Latent Diffusion Models"
        },
        {
            "paperId": "9c4753ef43d2928866dc5bf6cec53d03373ec2fa",
            "title": "SimMIM: a Simple Framework for Masked Image Modeling"
        },
        {
            "paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7",
            "title": "Masked Autoencoders Are Scalable Vision Learners"
        },
        {
            "paperId": "f829a355de02c08567927154d3045a6eb5425c91",
            "title": "Is Attention Better Than Matrix Decomposition?"
        },
        {
            "paperId": "9933a5af7895354087baf6c96b64dc8a8973eaed",
            "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs"
        },
        {
            "paperId": "a9c214e846188adb645021cd7b1964b8ea1fef6f",
            "title": "Rethinking and Improving Relative Position Encoding for Vision Transformer"
        },
        {
            "paperId": "0b036cd5dfc49d835d0c759c8ca31d89f2410e65",
            "title": "CMT: Convolutional Neural Networks Meet Vision Transformers"
        },
        {
            "paperId": "a143725bccbef904b10348625f5b0dd1eafd7f32",
            "title": "Visual Parser: Representing Part-whole Hierarchies with Transformers"
        },
        {
            "paperId": "bd163f27b409a4d903632009d38df77cfd70a437",
            "title": "ViTGAN: Training GANs with Vision Transformers"
        },
        {
            "paperId": "66775d9f16b3f4ca43dba2b31c7c42ca6dcba72b",
            "title": "GLiT: Neural Architecture Search for Global and Local Image Transformer"
        },
        {
            "paperId": "babfcebd9141cf44e39d04067d22af6f4ef2f93d",
            "title": "Test-Time Personalization with a Transformer for Human Pose Estimation"
        },
        {
            "paperId": "c723187a2230749b1e706df2217e928c8271a660",
            "title": "Learning Efficient Vision Transformers via Fine-Grained Manifold Distillation"
        },
        {
            "paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798",
            "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"
        },
        {
            "paperId": "d645bd08fc19d52164695f9cd5ae863345459a06",
            "title": "AutoFormer: Searching Transformers for Visual Recognition"
        },
        {
            "paperId": "bb6eba6d1c7f09255a9649eb2ed55bbd4f048091",
            "title": "Augmented Shortcuts for Vision Transformers"
        },
        {
            "paperId": "7b664a306b7d2f68dd816ea1d6586cf3472d75c1",
            "title": "Early Convolutions Help Transformers See Better"
        },
        {
            "paperId": "c295391129426d89ec58cebb049d1cd2e976deec",
            "title": "Post-Training Quantization for Vision Transformer"
        },
        {
            "paperId": "ae88babf38716142d630fb6ee4059e46d787cb4e",
            "title": "Vision Transformer Architecture Search"
        },
        {
            "paperId": "1fb10189c500e4902cd1b5afd406f57323d21be8",
            "title": "VOLO: Vision Outlooker for Visual Recognition"
        },
        {
            "paperId": "b70bb1855e217edffb5dfa0632e8216860821870",
            "title": "Efficient Self-supervised Vision Transformers for Representation Learning"
        },
        {
            "paperId": "7fff8018bf625447df837c2fda5c58a705fbc038",
            "title": "XCiT: Cross-Covariance Image Transformers"
        },
        {
            "paperId": "722ad6ac92286507437b31486f47987d6ece05c9",
            "title": "BEiT: BERT Pre-Training of Image Transformers"
        },
        {
            "paperId": "ab70c5e1a338cb470ec39c22a4f10e0f19e61edd",
            "title": "CAT: Cross Attention in Vision Transformer"
        },
        {
            "paperId": "36b9d0f8610a82fd25854889d9327a04da4ff8fd",
            "title": "MST: Masked Self-Supervised Transformer for Visual Representation"
        },
        {
            "paperId": "2a805d0e1b067444a554c5169d189fa1f649f411",
            "title": "Scaling Vision Transformers"
        },
        {
            "paperId": "90bd7648bf2e4dc8644e67c427e374a2bcabbe5e",
            "title": "DETReg: Unsupervised Pretraining with Region Priors for Object Detection"
        },
        {
            "paperId": "fbcbe5a222786f38a1c69c3487b4edf8ca469934",
            "title": "Fully Transformer Networks for Semantic Image Segmentation"
        },
        {
            "paperId": "8602fd5b0ac73bb422f238b265479f363c0ffe61",
            "title": "Refiner: Refining Self-attention for Vision Transformers"
        },
        {
            "paperId": "f43b98fcc2d56c60fc71bce96374c1e6b8e12c66",
            "title": "Shuffle Transformer: Rethinking Spatial Shuffle for Vision Transformer"
        },
        {
            "paperId": "2835951fabf12804e17d5a525b2be2bee70e7910",
            "title": "Uformer: A General U-Shaped Transformer for Image Restoration"
        },
        {
            "paperId": "14179738f12926441901a6c04500dba124b7da67",
            "title": "Oriented Object Detection with Transformer"
        },
        {
            "paperId": "33fd56e5067a1e8a9713378af3e1c1c08d5ce93b",
            "title": "Patch Slimming for Efficient Vision Transformers"
        },
        {
            "paperId": "2e8149dafb864ec3675087c99bf5572fcf4eb170",
            "title": "RegionViT: Regional-to-Local Attention for Vision Transformers"
        },
        {
            "paperId": "3d4b1c580c4df032549a84ee1a5114a09863ce18",
            "title": "SOLQ: Segmenting Objects by Learning Queries"
        },
        {
            "paperId": "ab0ef8e705fa88f079a055842ba20b4f413a69db",
            "title": "Associating Objects with Transformers for Video Object Segmentation"
        },
        {
            "paperId": "9d1934ea1bd69d928d17e05d44495d42edf8601d",
            "title": "You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection"
        },
        {
            "paperId": "07e987364bf0be1949e379f976f8dea675977337",
            "title": "MSG-Transformer: Exchanging Local Spatial Information by Manipulating Messenger Tokens"
        },
        {
            "paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60",
            "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"
        },
        {
            "paperId": "a0964686d80e173529efca6377f47e6a1b2fe69a",
            "title": "Less is More: Pay Less Attention in Vision Transformers"
        },
        {
            "paperId": "fb987ebe5ff5276fbbe6a5c5b16b6bfd759afa37",
            "title": "KVT: k-NN Attention for Boosting Vision Transformers"
        },
        {
            "paperId": "f80775a79d42a1ddfc0df808ea760c57af4949d0",
            "title": "Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding"
        },
        {
            "paperId": "1197ae4a62f0e0e4e3f3fb70396b5ff06ef371aa",
            "title": "CogView: Mastering Text-to-Image Generation via Transformers"
        },
        {
            "paperId": "cad93be77164f1e9c3149098f81524af01cecb3b",
            "title": "OCNet: Object Context for Semantic Segmentation"
        },
        {
            "paperId": "b8cee43a51c44f8f4448e78e41ecf081987707cf",
            "title": "Towards Robust Vision Transformer"
        },
        {
            "paperId": "ea7cfe7f2340584cbe653da6077ee7c213e49b92",
            "title": "Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation"
        },
        {
            "paperId": "68f080e0ac836ea230cb5316fbed273c70422d75",
            "title": "Segmenter: Transformer for Semantic Segmentation"
        },
        {
            "paperId": "039d4956224e7fe280fe61bcbb816fbd96d5745e",
            "title": "CondLaneNet: a Top-to-down Lane Detection Framework Based on Conditional Convolution"
        },
        {
            "paperId": "db33c408174eef1e40661e8279afbbbf6db2352c",
            "title": "Self-Supervised Learning with Swin Transformers"
        },
        {
            "paperId": "f56fa871dade366fd20551e25dd9c9492ab803bc",
            "title": "TrTr: Visual Tracking with Transformer"
        },
        {
            "paperId": "48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5",
            "title": "ResMLP: Feedforward Networks for Image Classification With Data-Efficient Training"
        },
        {
            "paperId": "0768aba7d87ddda3482fd7892b189f84711ede47",
            "title": "Do You Even Need Attention? A Stack of Feed-Forward Layers Does Surprisingly Well on ImageNet"
        },
        {
            "paperId": "fc92009ab34045f9e6d490684c7761f768e88c54",
            "title": "Beyond Self-Attention: External Attention Using Two Linear Layers for Visual Tasks"
        },
        {
            "paperId": "67571d29190faea9fbd104acd16274f8c4edf254",
            "title": "MLP-Mixer: An all-MLP Architecture for Vision"
        },
        {
            "paperId": "816b977342fd291fc4f200a9642fa6df9eb601e9",
            "title": "ISTR: End-to-End Instance Segmentation with Transformers"
        },
        {
            "paperId": "6709d5583f658f589ae6a2184805933aceb18849",
            "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"
        },
        {
            "paperId": "8d3ddc27dce9c6c0fe110e4f9cb45d3b59feb04b",
            "title": "Visformer: The Vision-friendly Transformer"
        },
        {
            "paperId": "82debd146c2351ec37ef2f6b51ca7fb04244d527",
            "title": "Skeletor: Skeletal Transformers for Robust Body-Pose Estimation"
        },
        {
            "paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6",
            "title": "Multiscale Vision Transformers"
        },
        {
            "paperId": "93efaf8c27940aaef145d8bcbca957be634d26e5",
            "title": "Vision Transformer Pruning"
        },
        {
            "paperId": "14c52ffa7ea9c1971d5d82ea369c946c98d056a9",
            "title": "LocalViT: Bringing Locality to Vision Transformers"
        },
        {
            "paperId": "aeeb75fc9354b4693430908c833473204a5f0a24",
            "title": "TokenPose: Learning Keypoint Tokens for Human Pose Estimation"
        },
        {
            "paperId": "16f5ad832b5804a24ca6ea423641082709ae160f",
            "title": "A Video Is Worth Three Views: Trigeminal Transformers for Video-Based Person Re-Identification"
        },
        {
            "paperId": "739ceacfafb1c4eaa17509351b647c773270b3ae",
            "title": "An Empirical Study of Training Self-Supervised Vision Transformers"
        },
        {
            "paperId": "37b66aefc502b205da52a0a811fd9a3bafb399f3",
            "title": "Efficient DETR: Improving End-to-End Object Detector with Dense Prior"
        },
        {
            "paperId": "003326a15fc4a8833785a47a741d7712474fa256",
            "title": "LeViT: a Vision Transformer in ConvNet\u2019s Clothing for Faster Inference"
        },
        {
            "paperId": "43e51c1bfd69df518e2907f7a955e485985ba423",
            "title": "On the Robustness of Vision Transformers to Adversarial Examples"
        },
        {
            "paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325",
            "title": "Going deeper with Image Transformers"
        },
        {
            "paperId": "0216e5538eeb93c3adea7a6e01bd87709b277b0a",
            "title": "Spatiotemporal Transformer for Video-based Person Re-identification"
        },
        {
            "paperId": "40f4d7fe800810288a80f84cdb357a8f4c28e880",
            "title": "Rethinking Spatial Dimensions of Vision Transformers"
        },
        {
            "paperId": "7c3ce1b3ad598a282546e03e2dc8b52c338caed6",
            "title": "Transformer Tracking"
        },
        {
            "paperId": "e775e649d815a02373eac840cf5e33a04ff85c95",
            "title": "CvT: Introducing Convolutions to Vision Transformers"
        },
        {
            "paperId": "c2d3d668228cfce0004b56f5d8e59578a91a7063",
            "title": "TFPose: Direct Human Pose Estimation with Transformers"
        },
        {
            "paperId": "0eff37167876356da2163b2e396df2719adf7de9",
            "title": "CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification"
        },
        {
            "paperId": "421fba3813d04684b42dd667e16ed22a64f50752",
            "title": "BossNAS: Exploring Hybrid CNN-transformers with Block-wisely Self-supervised Neural Architecture Search"
        },
        {
            "paperId": "96da196d6f8c947db03d13759f030642f8234abf",
            "title": "DeepViT: Towards Deeper Vision Transformer"
        },
        {
            "paperId": "2984ab83ade26639c3a82d29628d0d9e4abbebb0",
            "title": "Incorporating Convolution Designs into Visual Transformers"
        },
        {
            "paperId": "75284d5e4dfe1cd8a9ce69085210319e14fcfa3d",
            "title": "Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking"
        },
        {
            "paperId": "81fcd9309e1168fe0664d8df4213771e4ebfa343",
            "title": "Scalable Visual Transformers with Hierarchical Pooling"
        },
        {
            "paperId": "b3bf9fe13195e9aa70e1dac04e01fcff7008e812",
            "title": "Perceiver: General Perception with Iterative Attention"
        },
        {
            "paperId": "0ae67202f0584afccefa770865d14a46655d2975",
            "title": "Transformer in Transformer"
        },
        {
            "paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4",
            "title": "Learning Transferable Visual Models From Natural Language Supervision"
        },
        {
            "paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1",
            "title": "Zero-Shot Text-to-Image Generation"
        },
        {
            "paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881",
            "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"
        },
        {
            "paperId": "63812f583caac3ac32bbfb64f66ba69e57c1e90a",
            "title": "Conditional Positional Encodings for Vision Transformers"
        },
        {
            "paperId": "a87bb9e70d1127b6a9c0e721e48c0b58c997c70e",
            "title": "UniT: Multimodal Multitask Learning with a Unified Transformer"
        },
        {
            "paperId": "367f7f64ded5d18528c1013db9dfa01b075db484",
            "title": "Medical Transformer: Gated Axial-Attention for Medical Image Segmentation"
        },
        {
            "paperId": "b4ce7f92a8b987b5e76d580bf5076e2495f06883",
            "title": "TransReID: Transformer-based Object Re-Identification"
        },
        {
            "paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9",
            "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"
        },
        {
            "paperId": "16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78",
            "title": "Bottleneck Transformers for Visual Recognition"
        },
        {
            "paperId": "69621df0df837d345d764525696899e0570194b6",
            "title": "Fast Convergence of DETR with Spatially Modulated Co-Attention"
        },
        {
            "paperId": "d29430adccb805ab57b349afa8553954347b3197",
            "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"
        },
        {
            "paperId": "1020da59ab3db2b3051fb558559d7fdcd2c7e57b",
            "title": "TransTrack: Multiple-Object Tracking with Transformer"
        },
        {
            "paperId": "6c9710487ffe7161bf5a7b4e436ee6a76fc114cf",
            "title": "TransPose: Keypoint Localization via Transformer"
        },
        {
            "paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71",
            "title": "Training data-efficient image transformers & distillation through attention"
        },
        {
            "paperId": "e374193760d53abd55be0846665dde9e028cc42b",
            "title": "3D Object Detection with Pointformer"
        },
        {
            "paperId": "6102a12b22ec3e44f9bbdae76185ca6e8a358f83",
            "title": "End-to-End Human Pose and Mesh Reconstruction with Transformers"
        },
        {
            "paperId": "ff50b46b4e1cc0fd9beb832fc3468785b635a824",
            "title": "PCT: Point cloud transformer"
        },
        {
            "paperId": "30e77fb57578bf6c7fd8f44d63a9467e6f7804dd",
            "title": "SceneFormer: Indoor Scene Generation with Transformers"
        },
        {
            "paperId": "0acd7ff5817d29839b40197f7a4b600b7fba24e4",
            "title": "Transformer Interpretability Beyond Attention Visualization"
        },
        {
            "paperId": "47f7ec3d0a5e6e83b6768ece35206a94dc81919c",
            "title": "Taming Transformers for High-Resolution Image Synthesis"
        },
        {
            "paperId": "d2e54b3a596a1dce0def9d035dfe1fb7c0c6142a",
            "title": "Toward Transformer-Based Object Detection"
        },
        {
            "paperId": "f76bf23f0c7211a398ada1a789b907137aaf565f",
            "title": "DETR for Pedestrian Detection"
        },
        {
            "paperId": "787119e3c3f819244c82b7d97779473773e60696",
            "title": "MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers"
        },
        {
            "paperId": "6f6f73e69ee0d9d5d7d088bb882db1851d98175a",
            "title": "Pre-Trained Image Processing Transformer"
        },
        {
            "paperId": "2ac7999cce9f415ee87643f56631b55ed26aa10e",
            "title": "End-to-End Video Instance Segmentation with Transformers"
        },
        {
            "paperId": "ddf7dfd1d9096f4a58f33b575bd1b4630309e7b2",
            "title": "Temporal-Channel Transformer for 3D Lidar-Based Video Object Detection for Autonomous Driving"
        },
        {
            "paperId": "234763381de73a18f49430b0238310a6853d184e",
            "title": "Rethinking Transformer-based Set Prediction for Object Detection"
        },
        {
            "paperId": "0e00b46267f10f996bd2d1cb50b3acbe46921b53",
            "title": "ConvTransformer: A Convolutional Transformer Network for Video Frame Synthesis"
        },
        {
            "paperId": "a5661066faa0f28a61f238e860fb14a9057acf6b",
            "title": "Classification by Attention: Scene Graph Classification with Prior Knowledge"
        },
        {
            "paperId": "42aa775a29ff4b3a1cec178301708b8c54266ae7",
            "title": "Attention-Based Transformers for Instance Segmentation of Cells in Microstructures"
        },
        {
            "paperId": "2e1db8cb373f4d4a51d44308b7a457886d855fbb",
            "title": "End-to-End Object Detection with Adaptive Clustering Transformer"
        },
        {
            "paperId": "c13a8f9edb933e60c7a989244aee56283a54ce37",
            "title": "UP-DETR: Unsupervised Pre-training for Object Detection with Transformers"
        },
        {
            "paperId": "566f12bc938fab439ca3a1f6162f54be02abddf2",
            "title": "End-to-end Lane Shape Prediction with Transformers"
        },
        {
            "paperId": "e1d082562981a9f51649c60663aa484ee623dbb0",
            "title": "Point Transformer"
        },
        {
            "paperId": "09155c81f5ed73136c02d59c3f0c79c83c1d86b2",
            "title": "CABiNet: Efficient Context Aggregation Network for Low-Latency Semantic Segmentation"
        },
        {
            "paperId": "35248e4b63c96067ccf1bc3f3fa0f2e27a0e6cee",
            "title": "RelationNet++: Bridging Visual Representations for Object Detection via Transformer Decoder"
        },
        {
            "paperId": "6a3839aba1285f31b9178739470b0dab86b438fe",
            "title": "Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets"
        },
        {
            "paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
        },
        {
            "paperId": "9169f9afdd42aaa60e34f57ff89c882a50e71229",
            "title": "An Investigation on Different Underlying Quantization Schemes for Pre-trained Language Models"
        },
        {
            "paperId": "8e9554c48785af61f81df2d86178a653dcd1d3fc",
            "title": "HOT-Net: Non-Autoregressive Transformer for 3D Hand-Object Pose Estimation"
        },
        {
            "paperId": "907a5239ea4b8d0bed424d18aa229eafdfaf1bd2",
            "title": "End to End Binarized Neural Networks for Text Classification"
        },
        {
            "paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504",
            "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"
        },
        {
            "paperId": "c5b52203898aae655954a79807d00a9cb5145bee",
            "title": "Learning Enhanced Resolution-Wise Features For Human Pose Estimation"
        },
        {
            "paperId": "b0349a32497cf2586d784b639999c38d6a167c9d",
            "title": "Searching for Low-Bit Weights in Quantized Neural Networks"
        },
        {
            "paperId": "460499cd6aa0350754dc4f7e0e1438706e250386",
            "title": "Bidirectional Attention Network for Monocular Depth Estimation"
        },
        {
            "paperId": "d6c7a5882aa3a076261b95c212fd219aace24a1f",
            "title": "PROFIT: A Novel Training Method for sub-4-bit MobileNet Models"
        },
        {
            "paperId": "2a218786f4615b82389f78472e7ff22e6ce57490",
            "title": "ConvBERT: Improving BERT with Span-based Dynamic Convolution"
        },
        {
            "paperId": "8d39bd11f54f7889eca269899e52323f2702c8fa",
            "title": "Temporal Context Aggregation for Video Retrieval with Contrastive Learning"
        },
        {
            "paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3",
            "title": "Big Bird: Transformers for Longer Sequences"
        },
        {
            "paperId": "6871f6c5437a747fae75a19962f418d234ce2dc1",
            "title": "Multi-modal Transformer for Video Retrieval"
        },
        {
            "paperId": "f7f89feee68b6856c0a980a5888b42d18231be07",
            "title": "Learning Joint Spatial-Temporal Transformations for Video Inpainting"
        },
        {
            "paperId": "672aef6f84f240005a09cf4f31ab6880584c1491",
            "title": "Feature Pyramid Transformer"
        },
        {
            "paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8",
            "title": "Generative Pretraining From Pixels"
        },
        {
            "paperId": "93a23cb12c011a1f414c53f151714a47fa85b6a7",
            "title": "Object detection based on an adaptive attention mechanism"
        },
        {
            "paperId": "6f68e1bb253925d8431588555d3010419f322e04",
            "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"
        },
        {
            "paperId": "5c126ae3421f05768d8edd97ecd44b1364e2c99a",
            "title": "Denoising Diffusion Probabilistic Models"
        },
        {
            "paperId": "40ca4fcfffa7ca9aa9b7ff06ecf3cd0436712d78",
            "title": "$O(n)$ Connections are Expressive Enough: Universal Approximability of Sparse Transformers"
        },
        {
            "paperId": "a0185d4f32dde88aa1749f3a8000ed4721787b65",
            "title": "Visual Transformers: Token-based Image Representation and Processing for Computer Vision"
        },
        {
            "paperId": "c209d9c0d49b2377860acad2acbcc13523a40b7f",
            "title": "Learning Texture Transformer Network for Image Super-Resolution"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e",
            "title": "End-to-End Object Detection with Transformers"
        },
        {
            "paperId": "51a36db5ff0df3211994816ae66f20de92a2a3b3",
            "title": "A Survey of Scene Graph: Generation and Application"
        },
        {
            "paperId": "91ac65431b2dc46919e1673fde67671c29446812",
            "title": "When BERT Plays the Lottery, All Tickets Are Winning"
        },
        {
            "paperId": "8af925f4edf45131b5b6fed8aa655089d58692fa",
            "title": "Lite Transformer with Long-Short Range Attention"
        },
        {
            "paperId": "101baf17a9eeb89fc48391d6f8a6c273ecfb7fd4",
            "title": "PolyLaneNet: Lane Estimation via Deep Polynomial Regression"
        },
        {
            "paperId": "90d668b9ff44af25fbe84f888e3c29ec7d86d95a",
            "title": "Self-Supervised Equivariant Attention Mechanism for Weakly Supervised Semantic Segmentation"
        },
        {
            "paperId": "2573af4e13d9a5dddb257d22cd38a600528d9a8b",
            "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"
        },
        {
            "paperId": "9c5a239b75bade55c830b164e2fadc424e879137",
            "title": "XtremeDistil: Multi-stage Distillation for Massive Multilingual Models"
        },
        {
            "paperId": "e401f6b5118279afb7304ab07d18581d286155de",
            "title": "LiDAR-Based Online 3D Video Object Detection With Graph-Based Message Passing and Spatiotemporal Transformer Attention"
        },
        {
            "paperId": "1c332cfa211400fc6f56983fb01a6692046116dd",
            "title": "DynaBERT: Dynamic BERT with Adaptive Width and Depth"
        },
        {
            "paperId": "d177361ddf2765d509882b414a697e94d57dc59e",
            "title": "Self-Supervised Monocular Trained Depth Estimation Using Self-Attention and Discrete Disparity Volume"
        },
        {
            "paperId": "e1e3a36644d71bf1e8a09ad943c7a1bbb65ae73e",
            "title": "SCT: Set Constrained Temporal Transformer for Set Supervised Action Segmentation"
        },
        {
            "paperId": "2c4668668c3b9f0bda4d207b3e6d397034977f0e",
            "title": "Actor-Transformers for Group Activity Recognition"
        },
        {
            "paperId": "3d5dd5c128afa0f11a7cbdf2c3f879c82fca4351",
            "title": "Memory Enhanced Global-Local Aggregation for Video Object Detection"
        },
        {
            "paperId": "3bcb17559ce96eb20fa79af8194f4af0380d194a",
            "title": "Pre-trained models for natural language processing: A survey"
        },
        {
            "paperId": "4076e421d1758fdb68411242044cd45747b7e35b",
            "title": "PowerNorm: Rethinking Batch Normalization in Transformers"
        },
        {
            "paperId": "3e3ccedaec21f9cb2fa6a6b11d29938bc9ca02f6",
            "title": "Rethinking Batch Normalization in Transformers"
        },
        {
            "paperId": "156d11ca27740b591fb827e143cc71e9795a9745",
            "title": "Riptide: Fast End-to-End Binarized Neural Networks"
        },
        {
            "paperId": "e52051204cb1179584f3b008c9d38848b52c1f28",
            "title": "ReZero is All You Need: Fast Convergence at Large Depth"
        },
        {
            "paperId": "a1b8a8df281bbaec148a897927a49ea47ea31515",
            "title": "Improved Baselines with Momentum Contrastive Learning"
        },
        {
            "paperId": "c6c734e16f66fbfcefac7625cc64599e83292c1e",
            "title": "MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers"
        },
        {
            "paperId": "43f2ad297941db230c089ba353efc3f281ab678c",
            "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": "4aadd44e7f58667c149ee9037d97cccb2ebd7815",
            "title": "SpotNet: Self-Attention Multi-Task Network for Object Detection"
        },
        {
            "paperId": "2e27f119e6fcc5477248eb0f4a6abe8d7cf4f6e7",
            "title": "BERT-of-Theseus: Compressing BERT by Progressive Module Replacing"
        },
        {
            "paperId": "bc51622358d8eea83248ef29402fe10640d07ba6",
            "title": "Big Transfer (BiT): General Visual Representation Learning"
        },
        {
            "paperId": "03887d5a9829301f6e5cb2d47655db68430f4d16",
            "title": "One-Shot Object Detection with Co-Attention and Co-Excitation"
        },
        {
            "paperId": "a4cc0701170331a1fd0e58bad962bd7f39f5efc9",
            "title": "GhostNet: More Features From Cheap Operations"
        },
        {
            "paperId": "40922d386116975853a743b1d810c1e0f03e886a",
            "title": "Understanding and Improving Layer Normalization"
        },
        {
            "paperId": "add2f205338d70e10ce5e686df4a690e2851bdfc",
            "title": "Momentum Contrast for Unsupervised Visual Representation Learning"
        },
        {
            "paperId": "59c7f27be8b09596714384f4a35face7cb74ad11",
            "title": "NAT: Neural Architecture Transformer for Accurate and Compact Architectures"
        },
        {
            "paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
            "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"
        },
        {
            "paperId": "2be2f27c079663d3e3a769bcb04b0d341e76a707",
            "title": "SpeechBERT: Cross-Modal Pre-trained Language Model for End-to-end Spoken Question Answering"
        },
        {
            "paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
        },
        {
            "paperId": "132ae47905b1a648c095da54b8533e87cf642897",
            "title": "Fully Quantized Transformer for Machine Translation"
        },
        {
            "paperId": "ce106590145e89ea4b621c99665862967ccf5dac",
            "title": "Q8BERT: Quantized 8Bit BERT"
        },
        {
            "paperId": "83b8108014e3db4f46354a28ae68193f143c4e7e",
            "title": "Structured Pruning of Large Language Models"
        },
        {
            "paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc",
            "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"
        },
        {
            "paperId": "85b9e68eb27069e87181050035f40b79438dd220",
            "title": "A Large-scale Study of Representation Learning with the Visual Task Adaptation Benchmark"
        },
        {
            "paperId": "0be0313db9a4fd54a2e3a4f427772498a1419db8",
            "title": "Video Multitask Transformer Network"
        },
        {
            "paperId": "7c4530882cfcef1d2b4aa2996f494dfac626b5d9",
            "title": "Entangled Transformer for Image Captioning"
        },
        {
            "paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b",
            "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"
        },
        {
            "paperId": "f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1",
            "title": "Reducing Transformer Depth on Demand with Structured Dropout"
        },
        {
            "paperId": "6648b4db5f12c30941ea78c695e77aded19672bb",
            "title": "Unified Vision-Language Pre-Training for Image Captioning and VQA"
        },
        {
            "paperId": "0cbf97173391b0430140117027edcaf1a37968c7",
            "title": "TinyBERT: Distilling BERT for Natural Language Understanding"
        },
        {
            "paperId": "289976cbe82222a30a388b4af380244cb39360d0",
            "title": "ACFNet: Attentional Class Feature Network for Semantic Segmentation"
        },
        {
            "paperId": "4a93ca3250536c587c99c8ddf419b28356b13a5d",
            "title": "The Same Size Dilated Attention Network for Keypoint Detection"
        },
        {
            "paperId": "b480e1ea77d52f62bd86fbf960710b3f4d8cd155",
            "title": "Global Aggregation then Local Distribution in Fully Convolutional Networks"
        },
        {
            "paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d",
            "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"
        },
        {
            "paperId": "bfeb827d06c1a3583b5cc6d25241203a81f6af09",
            "title": "Knowledge Enhanced Contextual Word Representations"
        },
        {
            "paperId": "570e411c174e74e0df4ae15a3b66d7911b6b6a82",
            "title": "Dual Graph Convolutional Network for Semantic Segmentation"
        },
        {
            "paperId": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf",
            "title": "Patient Knowledge Distillation for BERT Model Compression"
        },
        {
            "paperId": "93ad19fbc85360043988fa9ea7932b7fdf1fa948",
            "title": "Well-Read Students Learn Better: The Impact of Student Initialization on Knowledge Distillation"
        },
        {
            "paperId": "4aa6298b606941a282d735fa3143da293199d2ca",
            "title": "VL-BERT: Pre-training of Generic Visual-Linguistic Representations"
        },
        {
            "paperId": "ce177672b00ddf46e4906157a7e997ca9338b8b9",
            "title": "Attention is not not Explanation"
        },
        {
            "paperId": "5aec474c31a2f4b74703c6f786c0a8ff85c450da",
            "title": "VisualBERT: A Simple and Performant Baseline for Vision and Language"
        },
        {
            "paperId": "58d20519b190308d144d4b0110527231179ea100",
            "title": "Few-Shot Object Detection With Attention-RPN and Multi-Relation Detector"
        },
        {
            "paperId": "78b6d0b2a12de2e7c106e8b4a81a6b29cf5c47b7",
            "title": "DaVinci: A Scalable Architecture for Neural Network Computing"
        },
        {
            "paperId": "918ee34e404ba5872d1ceae4d42dedb7f674c9f1",
            "title": "Expectation-Maximization Attention Networks for Semantic Segmentation"
        },
        {
            "paperId": "bae9c127f631f6fd321950c4612ca5c7d0eaea49",
            "title": "Interlaced Sparse Self-Attention for Semantic Segmentation"
        },
        {
            "paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de",
            "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"
        },
        {
            "paperId": "81f5810fbbab9b7203b9556f4ce3c741875407bc",
            "title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans"
        },
        {
            "paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
            "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"
        },
        {
            "paperId": "d6dccb5d71fbb6f5765f89633ba3a8e6809a720d",
            "title": "Stand-Alone Self-Attention in Vision Models"
        },
        {
            "paperId": "e364a32064235297e6bcf7b86aeb73679527222c",
            "title": "Robust Neural Machine Translation with Doubly Adversarial Inputs"
        },
        {
            "paperId": "b2cb203f6b09a3bf734c705c999da706b7a7c031",
            "title": "Attention is all you need for Videos: Self-attention based Video Summarization using Universal Transformers"
        },
        {
            "paperId": "a39398f68ae7e042f2ef5009e31b4e6a20fd5736",
            "title": "Learning Deep Transformer Models for Machine Translation"
        },
        {
            "paperId": "3366e9eb81880d172752d4397cb8e9e6de02b935",
            "title": "Efficient 8-Bit Quantization of Transformer Neural Machine Language Translation Model"
        },
        {
            "paperId": "135112c7ba1762d65f39b1a61777f26ae4dfd8ad",
            "title": "Is Attention Interpretable?"
        },
        {
            "paperId": "60f791a926ed64830736d3d25ae0dbd89e60671d",
            "title": "Adaptive Pyramid Context Network for Semantic Segmentation"
        },
        {
            "paperId": "70d6451f420cb33cbe0dfed5414b4fbfc312a3d0",
            "title": "Temporal Transformer Networks: Joint Learning of Invariant and Discriminative Time Warping"
        },
        {
            "paperId": "6ab21bdffa91fa2460e7f8f8bb8f756abb29484e",
            "title": "Co-Occurrent Features in Semantic Segmentation"
        },
        {
            "paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9",
            "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"
        },
        {
            "paperId": "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "title": "ERNIE: Enhanced Language Representation with Informative Entities"
        },
        {
            "paperId": "1c71771c701aadfd72c5866170a9f5d71464bb88",
            "title": "Unified Language Model Pre-training for Natural Language Understanding and Generation"
        },
        {
            "paperId": "b03c7ff961822183bab66b2e594415e585d3fd09",
            "title": "Are Sixteen Heads Really Better than One?"
        },
        {
            "paperId": "66143960c0325c70329a3869cc8052f0416b87aa",
            "title": "GCNet: Non-Local Networks Meet Squeeze-Excitation Networks and Beyond"
        },
        {
            "paperId": "b3c2c9f53ab130f3eb76eaaab3afa481c5a405eb",
            "title": "ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission"
        },
        {
            "paperId": "c41a11c0e9b8b92b4faaf97749841170b760760a",
            "title": "VideoBERT: A Joint Model for Video and Language Representation Learning"
        },
        {
            "paperId": "e2751a898867ce6687e08a5cc7bdb562e999b841",
            "title": "FCOS: Fully Convolutional One-Stage Object Detection"
        },
        {
            "paperId": "156d217b0a911af97fa1b5a71dc909ccef7a8028",
            "title": "SciBERT: A Pretrained Language Model for Scientific Text"
        },
        {
            "paperId": "bc6dfc6bda2d929fec91042dce1831fd07999b39",
            "title": "Improved Knowledge Distillation via Teacher Assistant"
        },
        {
            "paperId": "16c844fd4d97f3c6eb38b0d6527c87d184efedc3",
            "title": "The Evolved Transformer"
        },
        {
            "paperId": "8d07fc18aa55c775760f721be4ace03de2693289",
            "title": "Attention-based context aggregation network for monocular depth estimation"
        },
        {
            "paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702",
            "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"
        },
        {
            "paperId": "652107ea8161f607e3bdabc89199e9ff2fdfd015",
            "title": "Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey"
        },
        {
            "paperId": "9bd25f99bfc73af7e6d76f83d92f8270eab7be1d",
            "title": "Video Action Transformer Network"
        },
        {
            "paperId": "1eaee16f6395c9602ad1dc17e69a6e235ec9ddd6",
            "title": "Graph-Based Global Reasoning Networks"
        },
        {
            "paperId": "5132500b23d2da47129b3f4f68dd30947a29e502",
            "title": "CCNet: Criss-Cross Attention for Semantic Segmentation"
        },
        {
            "paperId": "d9dc41d3bc92e194c5a881ee9d741f898310ce9e",
            "title": "Two-Stream Transformer Networks for Video-Based Face Alignment"
        },
        {
            "paperId": "157bc9990bfe3df1d1100ea39e405121017fd6b5",
            "title": "Compact Generalized Non-local Network"
        },
        {
            "paperId": "b7339c1deeb617c894cc08c92ed8c2d4ab14b4b5",
            "title": "A2-Nets: Double Attention Networks"
        },
        {
            "paperId": "acf1ab10bb9b20534e5b5cb994ae7546728ae971",
            "title": "Attribute-Aware Attention Model for Fine-grained Representation Learning"
        },
        {
            "paperId": "47d79963ac69111d8dc82a228d26e6a746a4d087",
            "title": "Transformers"
        },
        {
            "paperId": "7c42d7ff616efc45a42b264b0da6c74e8141a9ed",
            "title": "ProxQuant: Quantized Neural Networks via Proximal Operators"
        },
        {
            "paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299",
            "title": "Adaptive Input Representations for Neural Language Modeling"
        },
        {
            "paperId": "ad655c25e052fa4eeed53421344aca6f239c4c9d",
            "title": "Dual Attention Network for Scene Segmentation"
        },
        {
            "paperId": "4eee87d960754f755fdec073a160af3e2e31672f",
            "title": "PSANet: Point-wise Spatial Attention Network for Scene Parsing"
        },
        {
            "paperId": "796a6e78d4c4b63926ee956f202d874a8c4542b0",
            "title": "OCNet: Object Context Network for Scene Parsing"
        },
        {
            "paperId": "1fad7fe0a7a90a8470a0688ad26bab6ceb8a85b7",
            "title": "Graph R-CNN for Scene Graph Generation"
        },
        {
            "paperId": "06ee9741730e4a2c7c8cdf643f5f34bc497a0b7c",
            "title": "Towards Understanding the Role of Over-Parametrization in Generalization of Neural Networks"
        },
        {
            "paperId": "ae1c89817a3a239e5344293138bdd80293983460",
            "title": "Attention U-Net: Learning Where to Look for the Pancreas"
        },
        {
            "paperId": "35ed258aede3df17ee20a6635364cb5fd2461049",
            "title": "End-to-End Dense Video Captioning with Masked Transformer"
        },
        {
            "paperId": "21937ecd9d66567184b83eca3d3e09eb4e6fbd60",
            "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"
        },
        {
            "paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f",
            "title": "Self-Attention with Relative Position Representations"
        },
        {
            "paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329",
            "title": "Image Transformer"
        },
        {
            "paperId": "c70218603f0af1be5d063056cbe629e042141a86",
            "title": "Learn To Pay Attention"
        },
        {
            "paperId": "9f501c7188349c1c18be7a55224f407f18c8b0a4",
            "title": "Diagnose like a Radiologist: Attention Guided Convolutional Neural Network for Thorax Disease Classification"
        },
        {
            "paperId": "04957e40d47ca89d38653e97f728883c0ad26e5d",
            "title": "Cascade R-CNN: Delving Into High Quality Object Detection"
        },
        {
            "paperId": "6a0aaefce8a27a8727d896fa444ba27558b2d381",
            "title": "Relation Networks for Object Detection"
        },
        {
            "paperId": "8899094797e82c5c185a0893896320ef77f60e64",
            "title": "Non-local Neural Networks"
        },
        {
            "paperId": "f466157848d1a7772fb6d02cdac9a7a5e7ef982e",
            "title": "Neural Discrete Representation Learning"
        },
        {
            "paperId": "fb37561499573109fc2cebb6a7b08f44917267dd",
            "title": "Squeeze-and-Excitation Networks"
        },
        {
            "paperId": "90a16f34d109b63d95ab4da2d491cbe3a1c8b656",
            "title": "Learning Efficient Convolutional Networks through Network Slimming"
        },
        {
            "paperId": "79cfb51a51fc093f66aac8e858afe2e14d4a1f20",
            "title": "Focal Loss for Dense Object Detection"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "8674494bd7a076286b905912d26d47f7501c4046",
            "title": "PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space"
        },
        {
            "paperId": "b61a3f8b80bbd44f24544dc915f52fd30bbdf485",
            "title": "Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset"
        },
        {
            "paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0",
            "title": "Convolutional Sequence to Sequence Learning"
        },
        {
            "paperId": "77d30cf9a34fb6b50979c6a68863099da9a060ad",
            "title": "Residual Attention Network for Image Classification"
        },
        {
            "paperId": "2a94c84383ee3de5e6211d43d16e7de387f68878",
            "title": "Feature Pyramid Networks for Object Detection"
        },
        {
            "paperId": "d997beefc0922d97202789d2ac307c55c2c52fba",
            "title": "PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"
        },
        {
            "paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5",
            "title": "Layer Normalization"
        },
        {
            "paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d",
            "title": "Gaussian Error Linear Units (GELUs)"
        },
        {
            "paperId": "0936352b78a52bc5d2b5e3f04233efc56664af51",
            "title": "Conditional Image Generation with PixelCNN Decoders"
        },
        {
            "paperId": "2cd8e8f510c89c7c18268e8ad51c061e459ad321",
            "title": "A Decomposable Attention Model for Natural Language Inference"
        },
        {
            "paperId": "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87",
            "title": "Context Encoders: Feature Learning by Inpainting"
        },
        {
            "paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "title": "Deep Residual Learning for Image Recognition"
        },
        {
            "paperId": "0e6824e137847be0599bb0032e37042ed2ef5045",
            "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"
        },
        {
            "paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
            "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"
        },
        {
            "paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19",
            "title": "Distilling the Knowledge in a Neural Network"
        },
        {
            "paperId": "4d8f2d14af5991d4f0d050d22216825cac3157bd",
            "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"
        },
        {
            "paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e",
            "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
        },
        {
            "paperId": "7845f1d3e796b5704d4bd37a945e0cf3fb8bbf1f",
            "title": "Multiple Object Recognition with Visual Attention"
        },
        {
            "paperId": "ac3ee98020251797c2b401e1389461df88e52e62",
            "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling"
        },
        {
            "paperId": "6fc6803df5f9ae505cae5b2f178ade4062c768d0",
            "title": "Fully convolutional networks for semantic segmentation"
        },
        {
            "paperId": "4c48a4c2f8bbeb6038fa2f8bc7745e8b9a835818",
            "title": "On the Computational Efficiency of Training Neural Networks"
        },
        {
            "paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "title": "Neural Machine Translation by Jointly Learning to Align and Translate"
        },
        {
            "paperId": "8a756d4d25511d92a45d0f4545fa819de993851d",
            "title": "Recurrent Models of Visual Attention"
        },
        {
            "paperId": "71b7178df5d2b112d07e45038cb5637208659ff7",
            "title": "Microsoft COCO: Common Objects in Context"
        },
        {
            "paperId": "22e477a9fdde86ab1f8f4dafdb4d88ea37e31fbd",
            "title": "DianNao: a small-footprint high-throughput accelerator for ubiquitous machine-learning"
        },
        {
            "paperId": "d770060812fb646b3846a7d398a3066145b5e3c8",
            "title": "Do Deep Nets Really Need to be Deep?"
        },
        {
            "paperId": "f8a38c8aa9d2f9f2db64fcc98f5b4770551d70f2",
            "title": "Top-Down Saliency Detection via Contextual Pooling"
        },
        {
            "paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "title": "ImageNet classification with deep convolutional neural networks"
        },
        {
            "paperId": "8d5f8d63a51dbb1554bcab132dd87ac911d9f6ec",
            "title": "What are they doing? : Collective activity classification using spatio-temporal relationship among people"
        },
        {
            "paperId": "53d12a37bc6ea511e9f59fe153df4bc8abf41cfc",
            "title": "Spectral Sparsification of Graphs"
        },
        {
            "paperId": "843959ffdccf31c6694d135fad07425924f785b1",
            "title": "Extracting and composing robust features with denoising autoencoders"
        },
        {
            "paperId": "30c9bb327b7f2b9f1d1e5b69b9d0c97b410948d9",
            "title": "Model compression"
        },
        {
            "paperId": "9c842b2926fd60b9e6ff80fee28c65e7c1ae5f1d",
            "title": "A non-local algorithm for image denoising"
        },
        {
            "paperId": "45949349948c58244017294b6db9d6d445b111ea",
            "title": "Perceptual organization in vision : behavioral and neural perspectives"
        },
        {
            "paperId": "eff3e2a802a63b15ce57498611165eccca0ddbe3",
            "title": "The average distances in random graphs with given expected degrees"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "d00444435757a21a47837040e3ea16a78ea73987",
            "title": "High-Level Vision: Object Recognition and Visual Cognition"
        },
        {
            "paperId": "3dc3a0efe58eaf8564ca1965c0ffd23ec495b83f",
            "title": "Autoencoders, Minimum Description Length and Helmholtz Free Energy"
        },
        {
            "paperId": "319f22bd5abfd67ac15988aa5c7f705f018c3ccd",
            "title": "Learning internal representations by error propagation"
        },
        {
            "paperId": "9b486c647916df9f8be0f8d4fc5c94c493bfaa80",
            "title": "PRINCIPLES OF NEURODYNAMICS. PERCEPTRONS AND THE THEORY OF BRAIN MECHANISMS"
        },
        {
            "paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7",
            "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"
        },
        {
            "paperId": "99c13ed582611b7e19993fdcb45d37ddae72c852",
            "title": "Improving Visual Reasoning by Exploiting The Knowledge in Texts"
        },
        {
            "paperId": "a0269530e9fc45974233e6149d8c6ee856665b3c",
            "title": "HandsFormer: Keypoint Transformer for Monocular 3D Pose Estimation ofHands and Object in Interaction"
        },
        {
            "paperId": "083ca4bd4d5b231a1d7a0715ec55cc57a0f44b13",
            "title": "Aggregating Nested Transformers"
        },
        {
            "paperId": "5366919840236059252c7f8f510dfb36df9e3206",
            "title": "TransGAN: Two Transformers Can Make One Strong GAN"
        },
        {
            "paperId": "c45c7b1da19f0a6644c0f09c231aadb6d1653eb7",
            "title": "Scene Graphs: A Survey of Generations and Applications"
        },
        {
            "paperId": "976a609cf540d1ded373b872d34779f7164d840a",
            "title": "Rethinking the Design Principles of Robust Vision Transformer"
        },
        {
            "paperId": "977424d679d4300a506d31374135413d5d9270b2",
            "title": "Visual Transformer Pruning"
        },
        {
            "paperId": "2f8718cbc567e941b778cc829b35426d25ecabd4",
            "title": "Hand-Transformer: Non-Autoregressive Structured Modeling for 3D Hand Pose Estimation"
        },
        {
            "paperId": "314218aa47999a8ee16599930bed226cbd1c8fd9",
            "title": "Bidirectional Non-local Networks for Object Detection"
        },
        {
            "paperId": "64eba0de822754df1bc1303f96163265dea9ac4f",
            "title": "A Recurrent Transformer Network for Novel View Action Synthesis"
        },
        {
            "paperId": "875880dcce5e0112e65375eeb70b202742a970a0",
            "title": "TransPose: Towards Explainable Human Pose Estimation by Transformer"
        },
        {
            "paperId": null,
            "title": "Electra: Pretraining text encoders as discriminators rather than generators"
        },
        {
            "paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": "61b56f29e4e5123f6d4b510cb85c00b63a6ee470",
            "title": "Quantized Transformer"
        },
        {
            "paperId": "fe82735fe8ae2163a37aa2787eee0db8efc745b6",
            "title": "transformers . zip : Compressing Transformers with Pruning and Quantization"
        },
        {
            "paperId": "9405cc0d6169988371b2755e573cc28650d14dfe",
            "title": "Language Models are Unsupervised Multitask Learners"
        },
        {
            "paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "title": "Improving Language Understanding by Generative Pre-Training"
        },
        {
            "paperId": "bbbbf43dede6962ab42fa79afaa7fc97b00bcb90",
            "title": "Symbolic Graph Reasoning Meets Convolutions"
        },
        {
            "paperId": "531afd8539dd14efbb32a8edddb2674de83beaed",
            "title": "Beyond Grids: Learning Graph Representations for Visual Recognition"
        },
        {
            "paperId": "8d62db434a5fec66c85153a8109509ff786dd29a",
            "title": "Deep Learning on Point Sets for 3 D Classification and Segmentation"
        },
        {
            "paperId": "fbeaa499e10e98515f7e1c4ad89165e8c0677427",
            "title": "Improving the speed of neural networks on CPUs"
        },
        {
            "paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086",
            "title": "Learning Multiple Layers of Features from Tiny Images"
        },
        {
            "paperId": "b37d36d2da2d9b97d535afd6fa83e277ed00d271",
            "title": "A Nonlocal Algorithm for Image Denoising"
        },
        {
            "paperId": "4a082dfea7b8bcc048515071cb4e3d8099be0adf",
            "title": "CVonline : the Evolving, Distributed, Non-Proprietary, On-Line Compendium of Computer Vision"
        },
        {
            "paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "title": "Gradient-based learning applied to document recognition"
        },
        {
            "paperId": "d92bf274d0a28378c3638d18415be4756ffa1c52",
            "title": "A solvable connectionist model of immediate recall of ordered lists"
        },
        {
            "paperId": "cccc0a4817fd5f6d8758c66b4065a23897d49f1d",
            "title": "Principles of neurodynamics"
        },
        {
            "paperId": null,
            "title": "The perceptron, a perceiving and recognizing automaton Project Para"
        },
        {
            "paperId": null,
            "title": "A SUBMISSION TO IEEE TRANSACTION ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE"
        }
    ]
}