{
    "paperId": "df137487e20ba7c6e1e2b9a1e749f2a578b5ad99",
    "externalIds": {
        "MAG": "648786980",
        "DBLP": "conf/nips/BengioVJS15",
        "ArXiv": "1506.03099",
        "CorpusId": 1820089
    },
    "title": "Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks",
    "abstract": "Recurrent Neural Networks can be trained to produce sequences of tokens given some input, as exemplified by recent results in machine translation and image captioning. The current approach to training them consists of maximizing the likelihood of each token in the sequence given the current (recurrent) state and the previous token. At inference, the unknown previous token is then replaced by a token generated by the model itself. This discrepancy between training and inference can yield errors that can accumulate quickly along the generated sequence. We propose a curriculum learning strategy to gently change the training process from a fully guided scheme using the true previous token, towards a less guided scheme which mostly uses the generated token instead. Experiments on several sequence prediction tasks show that this approach yields significant improvements. Moreover, it was used succesfully in our winning entry to the MSCOCO image captioning challenge, 2015.",
    "venue": "Neural Information Processing Systems",
    "year": 2015,
    "referenceCount": 27,
    "citationCount": 1898,
    "influentialCitationCount": 183,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a curriculum learning strategy to gently change the training process from a fully guided scheme using the true previous token, towards a less guided scheme which mostly uses the generated token instead."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "1751569",
            "name": "Samy Bengio"
        },
        {
            "authorId": "1689108",
            "name": "O. Vinyals"
        },
        {
            "authorId": "3111912",
            "name": "N. Jaitly"
        },
        {
            "authorId": "1846258",
            "name": "Noam M. Shazeer"
        }
    ],
    "references": [
        {
            "paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e",
            "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
        },
        {
            "paperId": "d5d46991c7e92352865dbf442be7c74d0d560dd8",
            "title": "Improving Multi-Step Prediction of Learned Time Series Models"
        },
        {
            "paperId": "47570e7f63e296f224a0e7f9a0d08b0de3cbaf40",
            "title": "Grammar as a Foreign Language"
        },
        {
            "paperId": "54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745",
            "title": "Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)"
        },
        {
            "paperId": "55e022fb7581bb9e1fce678d21fb25ffbb3fbb88",
            "title": "Deep visual-semantic alignments for generating image descriptions"
        },
        {
            "paperId": "47d2dc34e1d02a8109f5c04bb6939725de23716d",
            "title": "End-to-end Continuous Speech Recognition using Attention-based Recurrent NN: First Results"
        },
        {
            "paperId": "258986132bf17755fe8263e42429fe73218c1534",
            "title": "CIDEr: Consensus-based image description evaluation"
        },
        {
            "paperId": "15f102c3c9f4d4fe6ba105e221df48c6e8902b3b",
            "title": "From captions to visual concepts and back"
        },
        {
            "paperId": "f01fc808592ea7c473a69a6e7484040a435f36d9",
            "title": "Long-term recurrent convolutional networks for visual recognition and description"
        },
        {
            "paperId": "d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0",
            "title": "Show and tell: A neural image caption generator"
        },
        {
            "paperId": "2e36ea91a3c8fbff92be2989325531b4002e2afc",
            "title": "Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models"
        },
        {
            "paperId": "b04175bb99d6beff0f201ed82971aeb91d2c081d",
            "title": "Exploring Deep Learning Methods for Discovering Features in Speech Signals"
        },
        {
            "paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "title": "Sequence to Sequence Learning with Neural Networks"
        },
        {
            "paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "title": "Neural Machine Translation by Jointly Learning to Align and Translate"
        },
        {
            "paperId": "71b7178df5d2b112d07e45038cb5637208659ff7",
            "title": "Microsoft COCO: Common Objects in Context"
        },
        {
            "paperId": "d4bd0035fe14832626279e6c3c72b73c21c7f5d8",
            "title": "A Dynamic Oracle for Arc-Eager Dependency Parsing"
        },
        {
            "paperId": "79ab3c49903ec8cb339437ccf5cf998607fc313e",
            "title": "A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning"
        },
        {
            "paperId": "8de174ab5419b9d3127695405efd079808e956e8",
            "title": "Curriculum learning"
        },
        {
            "paperId": "526e22c130b18924976553d29ba11bc9d898d58b",
            "title": "Search-based structured prediction"
        },
        {
            "paperId": "e54d8b07ef659f9ee2671441c4355e414e408836",
            "title": "OntoNotes: The 90% Solution"
        },
        {
            "paperId": "41828fc3dab24784f95e6976e8aaa73f68e1840e",
            "title": "Incremental Parsing with the Perceptron Algorithm"
        },
        {
            "paperId": "f4ba954b0412773d047dc41231c733de0c1f4926",
            "title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "d0be39ee052d246ae99c082a565aba25b811be2d",
            "title": "Learning long-term dependencies with gradient descent is difficult"
        },
        {
            "paperId": "b8557627535e1808f9c9de7e5e7b0190262081ac",
            "title": "Challenge!"
        },
        {
            "paperId": "3a1a2cff2b70fb84a7ca7d97f8adcc5855851795",
            "title": "The Kaldi Speech Recognition Toolkit"
        },
        {
            "paperId": "f102536000b7c2db7b8112275e5f264046c3cc21",
            "title": "Search-Based Structured Prediction as Classi\ufb01cation"
        }
    ]
}