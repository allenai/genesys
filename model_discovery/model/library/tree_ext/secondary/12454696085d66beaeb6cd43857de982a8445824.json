{
    "paperId": "12454696085d66beaeb6cd43857de982a8445824",
    "externalIds": {
        "ArXiv": "2303.11607",
        "DBLP": "journals/corr/abs-2303-11607",
        "DOI": "10.48550/arXiv.2303.11607",
        "CorpusId": 257636830
    },
    "title": "Transformers in Speech Processing: A Survey",
    "abstract": "The remarkable success of transformers in the field of natural language processing has sparked the interest of the speech-processing community, leading to an exploration of their potential for modeling long-range dependencies within speech sequences. Recently, transformers have gained prominence across various speech-related domains, including automatic speech recognition, speech synthesis, speech translation, speech para-linguistics, speech enhancement, spoken dialogue systems, and numerous multimodal applications. In this paper, we present a comprehensive survey that aims to bridge research studies from diverse subfields within speech technology. By consolidating findings from across the speech technology landscape, we provide a valuable resource for researchers interested in harnessing the power of transformers to advance the field. We identify the challenges encountered by transformers in speech processing while also offering insights into potential solutions to address these issues.",
    "venue": "arXiv.org",
    "year": 2023,
    "referenceCount": 318,
    "citationCount": 37,
    "influentialCitationCount": 0,
    "openAccessPdf": {
        "url": "http://arxiv.org/pdf/2303.11607",
        "status": "CLOSED"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "By consolidating findings from across the speech technology landscape, this paper provides a valuable resource for researchers interested in harnessing the power of transformers to advance the field."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -2.825497627258301,
            -0.8164657950401306,
            2.3099050521850586,
            4.4842400550842285,
            2.3869566917419434,
            1.0545015335083008,
            6.578588962554932,
            -2.9343202114105225,
            3.6378445625305176,
            -0.549059271812439,
            1.4861044883728027,
            2.110508441925049,
            0.1194525957107544,
            0.4057009220123291,
            1.4910950660705566,
            -2.024225950241089,
            2.2847580909729004,
            -1.2194795608520508,
            4.514312744140625,
            2.7553207874298096,
            -1.0742257833480835,
            1.5402257442474365,
            -6.507641315460205,
            -0.3133566379547119,
            0.5485804080963135,
            -0.04209896922111511,
            1.4985170364379883,
            1.193229079246521,
            -3.939207077026367,
            3.8161094188690186,
            -2.4209189414978027,
            -3.390117645263672,
            3.0582032203674316,
            -4.576056003570557,
            0.7643948793411255,
            2.659951686859131,
            -5.53302526473999,
            6.931584358215332,
            -2.7774646282196045,
            -2.0141000747680664,
            -0.1296655535697937,
            0.3448963165283203,
            -0.7043920755386353,
            0.41137969493865967,
            3.625530958175659,
            -0.08275481313467026,
            2.4183080196380615,
            1.3707389831542969,
            -2.7000885009765625,
            2.541728973388672,
            5.544756889343262,
            -0.1810774803161621,
            -3.2981326580047607,
            -0.17615999281406403,
            0.7104201912879944,
            -0.6884686350822449,
            4.277801513671875,
            -0.7850340604782104,
            -0.28565970063209534,
            -2.881787061691284,
            3.6362597942352295,
            3.350745677947998,
            5.196936130523682,
            1.4367930889129639,
            7.777816295623779,
            -1.8584314584732056,
            -4.561596870422363,
            -0.6372106671333313,
            3.184070587158203,
            3.5466110706329346,
            -2.020009756088257,
            -3.8530263900756836,
            1.5357954502105713,
            -0.6466153264045715,
            -1.5610735416412354,
            -1.0257408618927002,
            -0.8336184620857239,
            -5.407502174377441,
            4.8263258934021,
            -3.0614562034606934,
            0.2956725060939789,
            -2.4609785079956055,
            0.9130294919013977,
            0.1406586766242981,
            5.004437446594238,
            -0.5483244061470032,
            -4.935944080352783,
            -0.2714884281158447,
            -0.5240476131439209,
            -2.1349778175354004,
            -2.606051445007324,
            -0.18281742930412292,
            0.4405793249607086,
            1.0061577558517456,
            1.522812008857727,
            -4.011545658111572,
            0.589920699596405,
            -2.5605533123016357,
            -1.1753044128417969,
            -0.3532424569129944,
            1.6644256114959717,
            -1.6516340970993042,
            -0.05399176478385925,
            0.9330947399139404,
            2.9104695320129395,
            -3.4157845973968506,
            0.44419732689857483,
            0.5768308043479919,
            3.529829978942871,
            -1.440066933631897,
            -1.7810536623001099,
            1.5976049900054932,
            -2.1434905529022217,
            -0.9848014116287231,
            1.9414433240890503,
            -1.5323431491851807,
            -1.024911642074585,
            2.319359064102173,
            -1.6656466722488403,
            2.7029788494110107,
            -0.5988671183586121,
            -2.5916833877563477,
            1.506758451461792,
            0.7710152864456177,
            -0.14999927580356598,
            5.210112571716309,
            1.925086259841919,
            -0.4477657973766327,
            1.4595861434936523,
            2.0746254920959473,
            3.083747148513794,
            2.944364547729492,
            0.06879016757011414,
            -2.9140052795410156,
            1.210213541984558,
            2.117459297180176,
            -1.7096755504608154,
            -0.21184061467647552,
            -0.2786312699317932,
            1.2528674602508545,
            0.7208322286605835,
            0.0996694415807724,
            -1.8658539056777954,
            2.1099157333374023,
            3.1879444122314453,
            0.15261626243591309,
            0.94865483045578,
            -3.418318033218384,
            -1.8202325105667114,
            1.8289482593536377,
            0.5466591715812683,
            0.09682750701904297,
            -3.1966514587402344,
            -1.1002874374389648,
            -3.1768739223480225,
            3.7249574661254883,
            -5.66303825378418,
            2.0087172985076904,
            -1.2494218349456787,
            0.7546960115432739,
            0.09154921770095825,
            2.6378166675567627,
            -11.19232177734375,
            -1.0922973155975342,
            0.5899407267570496,
            -4.029273986816406,
            -0.4478547275066376,
            4.036882400512695,
            1.5616958141326904,
            3.9886574745178223,
            -1.6588631868362427,
            -0.4371688961982727,
            0.4047605097293854,
            -1.6259496212005615,
            1.867444396018982,
            4.323777198791504,
            -1.5326464176177979,
            -1.7603996992111206,
            -1.607738733291626,
            0.2632041871547699,
            -0.8279250860214233,
            -0.12925797700881958,
            -2.5834600925445557,
            -2.027937412261963,
            -5.675268173217773,
            -1.2662440538406372,
            -1.6523871421813965,
            -2.8724751472473145,
            1.9708250761032104,
            0.417791485786438,
            2.222067356109619,
            3.8341219425201416,
            4.671662330627441,
            6.163827419281006,
            0.2372846007347107,
            2.4336650371551514,
            2.47824764251709,
            4.419367790222168,
            -4.00704288482666,
            1.9151277542114258,
            2.4008827209472656,
            -0.1942042112350464,
            -0.053345292806625366,
            -4.562259674072266,
            2.261110305786133,
            0.19277706742286682,
            -6.311888694763184,
            2.2466704845428467,
            2.7646639347076416,
            -1.6842217445373535,
            -0.12166737020015717,
            0.7160052061080933,
            -0.7360242605209351,
            -0.137356236577034,
            2.7016005516052246,
            -2.3901901245117188,
            -4.1303253173828125,
            -0.37475907802581787,
            2.710770606994629,
            1.5431277751922607,
            -0.48157182335853577,
            3.5912461280822754,
            -0.9506625533103943,
            -4.911949157714844,
            -3.140315294265747,
            -2.266017436981201,
            3.988875389099121,
            0.3978670835494995,
            -0.3621854782104492,
            -1.1851493120193481,
            0.7721449136734009,
            -2.160227060317993,
            -0.573040246963501,
            -1.2190966606140137,
            -2.6131389141082764,
            -2.6509857177734375,
            -4.287965297698975,
            0.6745365858078003,
            4.414151191711426,
            -1.6378439664840698,
            7.313163757324219,
            2.6858737468719482,
            -1.087749719619751,
            0.9816587567329407,
            -0.7506392598152161,
            -0.43161651492118835,
            -0.591014564037323,
            -0.343910276889801,
            1.4299030303955078,
            -6.122882843017578,
            -1.8301362991333008,
            -1.2357455492019653,
            0.9253859519958496,
            0.23048990964889526,
            -1.1865274906158447,
            -1.5431976318359375,
            2.6437723636627197,
            -1.8920499086380005,
            -1.6280566453933716,
            4.0035529136657715,
            -1.5971075296401978,
            1.940425992012024,
            -0.08934211730957031,
            3.959524393081665,
            -0.3296959400177002,
            0.03352481126785278,
            -2.0251431465148926,
            -0.1995944082736969,
            -1.8053842782974243,
            1.6611082553863525,
            1.6012187004089355,
            4.039773464202881,
            -1.058911681175232,
            -4.415069580078125,
            -0.9753005504608154,
            -3.7669968605041504,
            -1.804788589477539,
            -2.8586483001708984,
            5.162472248077393,
            1.5928080081939697,
            2.3677709102630615,
            -5.313015460968018,
            -4.618313789367676,
            -1.733795166015625,
            2.013016700744629,
            -3.0062198638916016,
            -2.7586615085601807,
            -2.888901710510254,
            -3.9680685997009277,
            -1.4202425479888916,
            -3.6345643997192383,
            0.8823670148849487,
            -3.061544179916382,
            -1.3295331001281738,
            1.288474202156067,
            1.4182817935943604,
            2.68050217628479,
            -2.432307004928589,
            0.037994980812072754,
            -1.2550886869430542,
            -5.122446537017822,
            2.414121627807617,
            3.4126861095428467,
            -0.04419291019439697,
            1.049501657485962,
            0.6872978806495667,
            1.4312853813171387,
            -1.159794807434082,
            -2.716958522796631,
            -0.8688746690750122,
            1.0979403257369995,
            1.4838169813156128,
            2.768173933029175,
            -2.9718854427337646,
            -1.9114404916763306,
            -1.5735619068145752,
            2.0672366619110107,
            -2.0889885425567627,
            -0.8845908045768738,
            2.93654727935791,
            -5.108865737915039,
            -0.9180353283882141,
            -4.105332851409912,
            -3.5834860801696777,
            -1.4769248962402344,
            -0.7587993144989014,
            3.1684017181396484,
            -3.500974178314209,
            -0.040430426597595215,
            4.963165283203125,
            2.604614734649658,
            -0.22592835128307343,
            1.0681709051132202,
            1.4138879776000977,
            0.8948547840118408,
            -6.326109886169434,
            -3.1876022815704346,
            2.139425754547119,
            -0.10600975155830383,
            -1.3247653245925903,
            3.0760722160339355,
            4.313128471374512,
            1.1572368144989014,
            4.443737506866455,
            -0.3900521397590637,
            2.080097198486328,
            1.8422138690948486,
            1.2255496978759766,
            1.7624611854553223,
            0.9419829845428467,
            -2.3427488803863525,
            -1.4538780450820923,
            3.7349205017089844,
            1.4421535730361938,
            2.8616795539855957,
            -1.0460495948791504,
            0.577972412109375,
            -1.1849100589752197,
            -0.3419646620750427,
            0.9988492727279663,
            1.590850591659546,
            3.243814468383789,
            -0.4293839633464813,
            0.7572061419487,
            0.9357591867446899,
            -5.109497547149658,
            8.27304458618164,
            -6.148766994476318,
            1.0689926147460938,
            -4.680984020233154,
            -3.604532480239868,
            -1.9837344884872437,
            -3.5071120262145996,
            7.450286388397217,
            -2.34464430809021,
            -4.782927513122559,
            -1.4354889392852783,
            -4.104014873504639,
            1.4329123497009277,
            1.7033369541168213,
            -3.469597339630127,
            3.1951966285705566,
            1.9611281156539917,
            0.09719407558441162,
            0.26556670665740967,
            1.1566275358200073,
            -4.359565258026123,
            1.1313294172286987,
            0.7483607530593872,
            -0.6135454177856445,
            -1.484327793121338,
            0.5407271385192871,
            1.148083209991455,
            0.4558072090148926,
            -6.002108573913574,
            -2.856710910797119,
            -2.6707706451416016,
            -2.155115842819214,
            2.6599881649017334,
            3.3585524559020996,
            2.655672550201416,
            -3.5951638221740723,
            3.314023494720459,
            3.3695993423461914,
            -3.798642635345459,
            1.4203568696975708,
            3.783139228820801,
            1.30439293384552,
            -3.0775766372680664,
            -1.4791051149368286,
            -6.265695571899414,
            0.5077223181724548,
            -0.9772846698760986,
            -0.10234013199806213,
            3.487821102142334,
            2.4389374256134033,
            2.090101957321167,
            3.1931800842285156,
            5.558607578277588,
            -0.8759464621543884,
            -6.6599016189575195,
            3.1259148120880127,
            7.077735900878906,
            0.07619410753250122,
            -3.799098014831543,
            1.3351836204528809,
            0.6074660420417786,
            1.1300143003463745,
            -2.9873828887939453,
            2.4304094314575195,
            1.5313340425491333,
            -1.9621697664260864,
            -2.697571277618408,
            -2.141495943069458,
            3.3435850143432617,
            2.3569421768188477,
            -1.2453052997589111,
            3.6611242294311523,
            2.0490758419036865,
            -3.852238893508911,
            1.82028329372406,
            1.9509161710739136,
            -0.5914497375488281,
            -0.06542110443115234,
            -4.742033004760742,
            1.6744105815887451,
            0.6936817169189453,
            -0.7156236171722412,
            -0.8107238411903381,
            -1.311665654182434,
            3.9419126510620117,
            -8.331608772277832,
            -4.309083461761475,
            -1.3238391876220703,
            -0.3311368227005005,
            0.46194931864738464,
            -2.64194393157959,
            -0.8787111639976501,
            2.977607488632202,
            1.949223518371582,
            -0.254411518573761,
            2.329280138015747,
            -2.784294843673706,
            -1.1605796813964844,
            0.6296268701553345,
            2.5527751445770264,
            0.9801312685012817,
            -7.3784871101379395,
            -1.4787859916687012,
            5.433065891265869,
            4.138343811035156,
            -1.5187710523605347,
            -6.415587425231934,
            -2.626716375350952,
            3.2587594985961914,
            2.6979310512542725,
            3.260061740875244,
            -0.19753998517990112,
            -1.3095324039459229,
            -4.666412353515625,
            -4.0096917152404785,
            0.03963810205459595,
            4.015331745147705,
            -4.691169738769531,
            1.4872736930847168,
            6.31997013092041,
            2.543726921081543,
            1.3865821361541748,
            2.03017520904541,
            -3.8275747299194336,
            -0.7178483009338379,
            4.646983623504639,
            3.6343231201171875,
            -0.6253609657287598,
            -0.783506453037262,
            0.7297395467758179,
            -2.6381242275238037,
            0.8149002194404602,
            -0.23031318187713623,
            0.17745891213417053,
            3.5046281814575195,
            -9.943832397460938,
            1.3846601247787476,
            2.9469149112701416,
            -4.395952224731445,
            8.41057014465332,
            6.521521091461182,
            -0.7145061492919922,
            -3.629577159881592,
            -0.20370899140834808,
            -0.4232482314109802,
            3.3956432342529297,
            -6.215169906616211,
            -0.6299604773521423,
            0.5116699934005737,
            0.05133780837059021,
            2.6650075912475586,
            -1.5673567056655884,
            2.291564464569092,
            -1.05272376537323,
            -2.264916181564331,
            -0.9283751249313354,
            0.9616419076919556,
            2.876613140106201,
            -3.6295156478881836,
            0.9141565561294556,
            2.0815484523773193,
            0.7699103355407715,
            -0.6061804890632629,
            5.441674709320068,
            4.502722263336182,
            5.891744136810303,
            2.5622572898864746,
            1.0021440982818604,
            0.05861109495162964,
            -2.0621354579925537,
            -0.05274346470832825,
            5.127101898193359,
            -3.4413044452667236,
            -0.7647726535797119,
            1.1992073059082031,
            3.217790365219116,
            3.984544277191162,
            2.03299617767334,
            -1.5488970279693604,
            -1.1806219816207886,
            -4.713207721710205,
            -1.1616700887680054,
            -0.6944069862365723,
            -2.374467134475708,
            0.4916436970233917,
            -3.64819073677063,
            4.389706134796143,
            1.1134684085845947,
            -1.5390011072158813,
            -1.6985305547714233,
            2.0707907676696777,
            -1.4096394777297974,
            1.315513253211975,
            7.909282207489014,
            4.719604969024658,
            1.2353564500808716,
            -1.042260766029358,
            -1.1635856628417969,
            -0.14706730842590332,
            -5.508492469787598,
            3.585797071456909,
            2.372563123703003,
            -0.10636010766029358,
            -2.925684928894043,
            1.2437293529510498,
            -0.9699863195419312,
            1.7994613647460938,
            1.3986523151397705,
            1.828981876373291,
            4.3714189529418945,
            2.89241886138916,
            1.904935598373413,
            -5.450363636016846,
            0.8528741598129272,
            3.138847827911377,
            1.5003061294555664,
            -2.711498975753784,
            -3.4687986373901367,
            3.1257901191711426,
            -4.245448112487793,
            -4.532687187194824,
            1.103027582168579,
            -1.958135724067688,
            1.6697700023651123,
            2.558077573776245,
            -1.3979084491729736,
            0.3988313674926758,
            -2.2299559116363525,
            0.8112937211990356,
            -4.765959739685059,
            0.7829030752182007,
            2.464432716369629,
            -1.1742725372314453,
            4.006570816040039,
            1.131853461265564,
            1.8562380075454712,
            1.4722230434417725,
            -0.9938138127326965,
            0.5119119882583618,
            0.24760037660598755,
            1.495962142944336,
            2.6574647426605225,
            2.575827121734619,
            -0.46825525164604187,
            -1.7334734201431274,
            3.4484176635742188,
            12.93008041381836,
            5.204812049865723,
            -2.293846607208252,
            1.1996049880981445,
            1.2630068063735962,
            -1.0349290370941162,
            -5.865785121917725,
            2.1029953956604004,
            2.2399251461029053,
            -0.7944506406784058,
            -2.378537178039551,
            3.4653501510620117,
            -0.4002037048339844,
            1.493281602859497,
            -2.090951442718506,
            -1.228737473487854,
            -0.2353699803352356,
            3.605388879776001,
            1.884462594985962,
            0.8200480341911316,
            0.5772033333778381,
            3.804666757583618,
            -1.0773495435714722,
            -1.4098621606826782,
            -1.5109803676605225,
            0.9618878364562988,
            1.9581544399261475,
            1.3908172845840454,
            -3.9572763442993164,
            2.0852832794189453,
            -0.19310057163238525,
            1.1374350786209106,
            2.2555580139160156,
            0.1251133382320404,
            -2.5323522090911865,
            2.450058937072754,
            2.102349042892456,
            -2.9836764335632324,
            0.4042443335056305,
            1.1362333297729492,
            -0.9259414672851562,
            1.770041584968567,
            -1.9282257556915283,
            1.3975117206573486,
            0.8885664939880371,
            -0.4960188865661621,
            0.9340049028396606,
            -1.3206945657730103,
            -2.9989047050476074,
            4.476681709289551,
            0.8570964932441711,
            -2.098177433013916,
            -0.5785346031188965,
            -0.9978965520858765,
            1.942205786705017,
            2.918867588043213,
            0.552014172077179,
            -3.583836555480957,
            3.1006901264190674,
            0.5397977828979492,
            3.0688209533691406,
            -1.555027961730957,
            4.216395378112793,
            -0.04719557613134384,
            -1.1403619050979614,
            -4.342137813568115,
            -4.367304801940918,
            1.8193681240081787,
            -1.5442949533462524,
            -1.3947350978851318,
            -0.028114229440689087,
            1.952561378479004,
            -0.22748328745365143,
            -2.362550973892212,
            -0.30272647738456726,
            -2.443005084991455,
            0.26785558462142944,
            -1.8654956817626953,
            -2.2192554473876953,
            0.32671788334846497,
            -0.249365895986557,
            1.4336940050125122,
            -3.54042911529541,
            3.2889490127563477,
            5.4750895500183105,
            -1.0998016595840454,
            2.861553192138672,
            3.3893046379089355,
            -1.4754924774169922,
            5.172640800476074,
            -2.255943775177002,
            0.0049225687980651855,
            5.290981292724609,
            0.5439146757125854,
            -1.048377513885498,
            -2.3043904304504395,
            -1.109775424003601,
            -2.315438985824585,
            -5.823695182800293,
            0.996572732925415,
            3.7250025272369385,
            3.072341203689575,
            1.0483076572418213,
            -2.803452730178833,
            -1.4671647548675537,
            -0.9437430500984192,
            -0.25131601095199585,
            -4.122788906097412,
            -3.6357522010803223,
            -0.6806739568710327,
            0.568841814994812,
            -1.003840684890747,
            -1.6053776741027832,
            -0.1793743371963501,
            1.004309892654419,
            -0.4546944499015808,
            1.317577600479126,
            5.748744010925293,
            2.1380560398101807,
            1.1150400638580322,
            0.618054211139679,
            -3.549278497695923,
            -5.195401191711426,
            -4.316089630126953,
            -2.0190439224243164,
            0.49967241287231445,
            5.881460666656494,
            -0.7672414183616638,
            0.9120162725448608,
            -2.009373188018799,
            2.9109315872192383,
            -4.578047275543213,
            -0.9249277710914612,
            -0.00040397047996520996,
            0.6130075454711914,
            -1.8318127393722534,
            -0.7668649554252625,
            0.7198712825775146,
            -3.396373748779297,
            4.3405656814575195,
            5.6203389167785645,
            1.0928324460983276,
            -1.806898832321167,
            5.0597615242004395,
            -0.9059264063835144,
            -1.0963313579559326,
            -2.5405192375183105,
            0.43793466687202454,
            -2.671506404876709,
            -0.6829464435577393,
            0.5598053932189941,
            -0.5941492319107056,
            3.484177589416504,
            -1.0417758226394653,
            -2.791107177734375,
            -3.3587841987609863
        ]
    },
    "authors": [
        {
            "authorId": "24040678",
            "name": "S. Latif"
        },
        {
            "authorId": "30692417",
            "name": "Aun Zaidi"
        },
        {
            "authorId": "1806041",
            "name": "H. Cuay\u00e1huitl"
        },
        {
            "authorId": "29434078",
            "name": "Fahad Shamshad"
        },
        {
            "authorId": "2212367091",
            "name": "Moazzam Shoukat"
        },
        {
            "authorId": "1734917",
            "name": "Junaid Qadir"
        }
    ],
    "references": [
        {
            "paperId": "0d86a4a53a842c3ae05162f0475a4eefe807a3d4",
            "title": "Low Complexity Speech Enhancement Network Based on Frame-Level Swin Transformer"
        },
        {
            "paperId": "c40ec51ddd4145402bd95eeb3ce6977778d87881",
            "title": "Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling"
        },
        {
            "paperId": "c483fefb8ebc5f5ae719eef099c3acfb684dbe1a",
            "title": "SpeechFormer++: A Hierarchical Efficient Framework for Paralinguistic Speech Processing"
        },
        {
            "paperId": "64daf0dd3cf9adef433d568627e2c3a784219878",
            "title": "Response-act Guided Reinforced Dialogue Generation for Mental Health Counseling"
        },
        {
            "paperId": "186b603e8b59bf5de4fa999bb4256f62d9a2d629",
            "title": "Response Timing Estimation for Spoken Dialog Systems Based on Syntactic Completeness Prediction"
        },
        {
            "paperId": "638b5c76d96e32f54475a8327a9c68e0167156a9",
            "title": "A Survey on Transformers in Reinforcement Learning"
        },
        {
            "paperId": "c2f91f35df893714418cc29096083dce0b441229",
            "title": "Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers"
        },
        {
            "paperId": "71ddf625e3bbccfdaae528024b73acf8b00ea486",
            "title": "Audio-Visual Efficient Conformer for Robust Speech Recognition"
        },
        {
            "paperId": "d8496775f90ca21735decc238855550c11efd85a",
            "title": "Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language"
        },
        {
            "paperId": "a02fbaf22237a1aedacb1320b6007cd70c1fe6ec",
            "title": "Robust Speech Recognition via Large-Scale Weak Supervision"
        },
        {
            "paperId": "a0fbbf0657480141f209e45a0b276df454235902",
            "title": "HEAT: Hardware-Efficient Automatic Tensor Decomposition for Transformer Compression"
        },
        {
            "paperId": "c0330679312f9e4a2d280dd023aed7984ae32a83",
            "title": "Device Directedness with Contextual Cues for Spoken Dialog Systems"
        },
        {
            "paperId": "7709bdee6f45d0a58d30586a03a78dfe36e35e6e",
            "title": "Compressing Transformer-based self-supervised models for speech processing"
        },
        {
            "paperId": "4e06fa91a71690fddae3d4618e8ee25993d09dd1",
            "title": "Cross-Attention is all you need: Real-Time Streaming Transformers for Personalised Speech Enhancement"
        },
        {
            "paperId": "96a2f16ce9c87db6f647c78666e242cd963d699f",
            "title": "End-to-End Evaluation of a Spoken Dialogue System for Learning Basic Mathematics"
        },
        {
            "paperId": "fa6da2911db479dbb35e5004be920d92242ebb89",
            "title": "Dual-Residual Transformer Network for Speech Recognition"
        },
        {
            "paperId": "782297db7bb951b398512da0041f82f7eaa97f7b",
            "title": "A Transformer-Based User Satisfaction Prediction for Proactive Interaction Mechanism in DuerOS"
        },
        {
            "paperId": "bb1a169b2f5033eccdf06347090e570f10014ced",
            "title": "Multitask learning for multilingual intent detection and slot filling in dialogue systems"
        },
        {
            "paperId": "e5506088b86e7195e3d516d39da434c095e856e0",
            "title": "Adaptive Sparse and Monotonic Attention for Transformer-based Automatic Speech Recognition"
        },
        {
            "paperId": "02f6ad535c5a3362314be2d8c3bd02aa144f8008",
            "title": "Induce Spoken Dialog Intents via Deep Unsupervised Context Contrastive Clustering"
        },
        {
            "paperId": "f9a8155ab033ae533d3e325524a979ac3736ce7e",
            "title": "Improving Spoken Language Understanding with Cross-Modal Contrastive Learning"
        },
        {
            "paperId": "2d5162cb94b844be715a7c44b1c2cd419a1ff633",
            "title": "Vision Transformers for Action Recognition: A Survey"
        },
        {
            "paperId": "744ee04b08e04ad216bd586ac74bbc1fed0dea8f",
            "title": "Transformers in Remote Sensing: A Survey"
        },
        {
            "paperId": "ac40f3197f77397fdf07a73f788056efc99028df",
            "title": "3D Vision with Transformers: A Survey"
        },
        {
            "paperId": "5e82951b021f0d57adca11f1f6f1eb166278a030",
            "title": "Tiny-Sepformer: A Tiny Time-Domain Transformer Network for Speech Separation"
        },
        {
            "paperId": "9c525238d583f86909689846b6d09264dc78e93f",
            "title": "Conformer Based Elderly Speech Recognition System for Alzheimer's Disease Detection"
        },
        {
            "paperId": "ca4f45318c13078005b7e7cb134d79d8fb568f2b",
            "title": "GODEL: Large-Scale Pre-Training for Goal-Directed Dialog"
        },
        {
            "paperId": "c8fd12da59b52ff527e4e54e68edcf9a15ea2bf2",
            "title": "Resource-Efficient Separation Transformer"
        },
        {
            "paperId": "da53910ebcdc41c603526219aad46e0ae9e420bb",
            "title": "Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition"
        },
        {
            "paperId": "622428f5122ad12a40229e1768ecb929fd747ee7",
            "title": "Multimodal Learning With Transformers: A Survey"
        },
        {
            "paperId": "5702438568338a8e353e31ad209deaebfff32604",
            "title": "Duplex Conversation: Towards Human-like Interaction in Spoken Dialogue Systems"
        },
        {
            "paperId": "6b86667bae101cc045f39d3d77a1eaf21a43c12c",
            "title": "TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation"
        },
        {
            "paperId": "790a5da9268e28794d82fa4df648691200445f34",
            "title": "Multiformer: A Head-Configurable Transformer-Based Model for Direct Speech Translation"
        },
        {
            "paperId": "481d773470775eae77361187fae15730948d3639",
            "title": "Gated Multimodal Fusion with Contrastive Learning for Turn-Taking Prediction in Human-Robot Dialogue"
        },
        {
            "paperId": "08f9b6c9c305aa13e92805ab1f0171e10aa786c6",
            "title": "Multimodal Sparse Transformer Network for Audio-Visual Speech Recognition"
        },
        {
            "paperId": "49e628b162d7be2157354953d717dbbfecdea615",
            "title": "Towards End-to-End Integration of Dialog History for Improved Spoken Language Understanding"
        },
        {
            "paperId": "6e685480bc6f348bf45a3871c415d976c58afda7",
            "title": "Robust Speaker Recognition with Transformers Using wav2vec 2.0"
        },
        {
            "paperId": "3e61fa97c97815285601b0d1a6f1eb1c3ce0f52a",
            "title": "Dawn of the Transformer Era in Speech Emotion Recognition: Closing the Valence Gap"
        },
        {
            "paperId": "40eca3f99c70f50501fdae4a0e2dd9a239d5d70d",
            "title": "SpeechFormer: A Hierarchical Efficient Framework Incorporating the Characteristics of Speech"
        },
        {
            "paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
            "title": "Training language models to follow instructions with human feedback"
        },
        {
            "paperId": "65e2fd58ab75025c855b2afdeb05bfaa7d8a5541",
            "title": "Survey of Deep Learning Paradigms for Speech Processing"
        },
        {
            "paperId": "4d35845f81c5afe83c9b101507d2a187ef4d8c3c",
            "title": "TRILLsson: Distilled Universal Paralinguistic Speech Representations"
        },
        {
            "paperId": "8f2bca9d684005675e294b33c26481e36f528cdb",
            "title": "data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language"
        },
        {
            "paperId": "24aa57dae649b6683d8f5bc8deaf2ff549cdacc4",
            "title": "Transformers in Medical Imaging: A Survey"
        },
        {
            "paperId": "145e8a3cad5a1d4767c72b239b776fda7a682eb8",
            "title": "CLIP-TD: CLIP Targeted Distillation for Vision-Language Tasks"
        },
        {
            "paperId": "217aa2a24e5916835d04e384f729c21ad65deadc",
            "title": "Multiview Transformers for Video Recognition"
        },
        {
            "paperId": "80ea0e2882db3347b4fbc83f1a55c6a93e0d9272",
            "title": "Align and Prompt: Video-and-Language Pre-training with Entity Prompts"
        },
        {
            "paperId": "f04291ce23cd5af351a7d77722923c43c9027ffd",
            "title": "Audio Embeddings Help to Learn Better Dialogue Policies"
        },
        {
            "paperId": "1dc1ae646acf5cbee524ef778dccc888d387b9bd",
            "title": "A Conformer-Based ASR Frontend for Joint Acoustic Echo Cancellation, Speech Enhancement and Speech Separation"
        },
        {
            "paperId": "19dbb57ad106137553bff4282149ac2800b5c176",
            "title": "XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale"
        },
        {
            "paperId": "f36cd41386c7e3fd0ee580874f99e6ae1c864bdc",
            "title": "Speech Separation Based on DPTNet with Sparse Attention"
        },
        {
            "paperId": "333212e246fb65f7c9d43862021e78f007c48449",
            "title": "A Survey of Visual Transformers"
        },
        {
            "paperId": "416dab850fda842b13a4f28164514d98f836fff7",
            "title": "WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing"
        },
        {
            "paperId": "50f6dd2aa07074d2904f153a0e489285499436c1",
            "title": "Unifying Multimodal Transformer for Bi-directional Image and Text Generation"
        },
        {
            "paperId": "1067c44e473b6998f89e13f0d4c0de730def43f0",
            "title": "SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing"
        },
        {
            "paperId": "a8fef2707d8cbbb8e16f19e4c6719bd3bc1d44ff",
            "title": "Auxiliary Loss of Transformer with Residual Connection for End-to-End Speaker Diarization"
        },
        {
            "paperId": "ded72c6ba12a1502a65a3be2af971f434e28ec05",
            "title": "Fine-Grained Style Control In Transformer-Based Text-To-Speech Synthesis"
        },
        {
            "paperId": "e871d035824f24f2f82be58f636451214d5b5a71",
            "title": "Unispeech-Sat: Universal Speech Representation Learning With Speaker Aware Pre-Training"
        },
        {
            "paperId": "767923635f2fd4467d848dba9655866e4f9b55c8",
            "title": "Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm"
        },
        {
            "paperId": "1bd84f8c4d1964facca77480dd048223c6443825",
            "title": "Universal Paralinguistic Speech Representations Using self-Supervised Conformers"
        },
        {
            "paperId": "5abf2ddd97bb4428ff88983081edfd13af6fcf24",
            "title": "COOKIE: Contrastive Cross-Modal Knowledge Sharing Pre-training for Vision-Language Representation"
        },
        {
            "paperId": "342a8bd5d9ca7f30ffa976476ac02926f0984b4c",
            "title": "A Comparative Study on Language Models for Task-Oriented Dialogue Systems"
        },
        {
            "paperId": "821ad6c9f0fecb5fabb486a5a87a93b7ea65bcc0",
            "title": "VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding"
        },
        {
            "paperId": "6fe21b01d2202defb8fcd75c40f306a88bd385dc",
            "title": "BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning for Automatic Speech Recognition"
        },
        {
            "paperId": "368e0844bbd3feb5ab17a271ad1663ca5a6fb7e7",
            "title": "Survey of Deep Representation Learning for Speech Emotion Recognition"
        },
        {
            "paperId": "2a641c921bb06d3347ef532010650bce389f6c19",
            "title": "TEASEL: A Transformer-Based Speech-Prefixed Language Model"
        },
        {
            "paperId": "a8e61923b1404eb7ae286e4ec407a3e3f925f788",
            "title": "Speechformer: Reducing Information Loss in Direct Speech Translation"
        },
        {
            "paperId": "ff18115e4ab69c3060d72086cfe1f61f2bf0746f",
            "title": "Causal Confusion Reduction for Robust Multi-Domain Dialogue Policy"
        },
        {
            "paperId": "053ac76f7b6e12f406eaf6e953b3bd5313fd69c2",
            "title": "Ultra Fast Speech Separation Model with Teacher Student Learning"
        },
        {
            "paperId": "aa98a02b83ad8920a9909fae187ce0a96532a95a",
            "title": "Improving Streaming Transformer Based ASR Under a Framework of Self-supervised Learning"
        },
        {
            "paperId": "c64919cf0488149708535824f9da40e842343535",
            "title": "A Unified Transformer-based Framework for Duplex Text Normalization"
        },
        {
            "paperId": "7a27cc0cc37931e85315ed41333f01cb6de18c02",
            "title": "Differentiable Subset Pruning of Transformer Heads"
        },
        {
            "paperId": "18982c55e60d3157e07d0fbdaba0bf7df2fab8bd",
            "title": "Product1M: Towards Weakly Supervised Instance-Level Product Retrieval via Cross-Modal Pretraining"
        },
        {
            "paperId": "67bf3f035a062f8b0a6a409f30bb858e859a8645",
            "title": "Translatotron 2: High-quality direct speech-to-speech translation with voice preservation"
        },
        {
            "paperId": "28d0b2e47bb67d9b6c8f77ee6609c0b36953a88f",
            "title": "GilBERT: Generative Vision-Language Pre-Training for Image-Text Retrieval"
        },
        {
            "paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006",
            "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"
        },
        {
            "paperId": "73d41e90cb85840d860f652a65e5785597d5b698",
            "title": "CLIP-It! Language-Guided Video Summarization"
        },
        {
            "paperId": "f1902f99c53781601061d794d957f77982753352",
            "title": "Attention Bottlenecks for Multimodal Fusion"
        },
        {
            "paperId": "4384ff4ac7459d3045ff660b1772c975512701d9",
            "title": "A Survey on Neural Speech Synthesis"
        },
        {
            "paperId": "11f606fd65df3de5d99c0034d8dd4ec5205090f1",
            "title": "Probing Inter-modality: Visual Parsing with Self-Attention for Vision-Language Pre-training"
        },
        {
            "paperId": "0a03d2c46ba4c3160e4e011eb52cb5a13cde1fbd",
            "title": "DeltaLM: Encoder-Decoder Pre-training for Language Generation and Translation by Augmenting Pretrained Multilingual Encoders"
        },
        {
            "paperId": "c401e01c9ee32fab7d02670d1c754f44fc1ff99e",
            "title": "CLIP2Video: Mastering Video-Text Retrieval via Image CLIP"
        },
        {
            "paperId": "453073c445bbf48bc17c37fc5ffbd91a20c8148d",
            "title": "Domain-independent User Simulation with Transformers for Task-oriented Dialogue Systems"
        },
        {
            "paperId": "4fffa5245d3972077c83614c2a08a47cb578631e",
            "title": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units"
        },
        {
            "paperId": "eb71ca97e37968aaccea3fd85e3f304a92bb1f90",
            "title": "Supervising the Transfer of Reasoning Patterns in VQA"
        },
        {
            "paperId": "69cb92f055d32de55327da24ac38e12db810f280",
            "title": "RealTranS: End-to-End Simultaneous Speech Translation with Convolutional Weighted-Shrinking Transformer"
        },
        {
            "paperId": "d8d2e574965fe733eb1416e03df2b5c2914fc530",
            "title": "A Survey of Transformers"
        },
        {
            "paperId": "6b6ffb94626e672caffafc77097491d9ee7a8682",
            "title": "On the Connection between Local Attention and Dynamic Depth-wise Convolution"
        },
        {
            "paperId": "801a40cc1b18df679612f160b0b97e8e4e208e26",
            "title": "Mixed Precision Quantization of Transformer Language Models for Speech Recognition"
        },
        {
            "paperId": "a0b063097b3e7799f9f1f440296f778b40675178",
            "title": "Patnet : A Phoneme-Level Autoregressive Transformer Network for Speech Synthesis"
        },
        {
            "paperId": "7509c66a666e2e3f14bc8676b969b945ee6e136f",
            "title": "CAPE: Encoding Relative Positions with Continuous Augmented Positional Embeddings"
        },
        {
            "paperId": "90357a6dc817e2f7cec477a51156675fbf545cf1",
            "title": "MERLOT: Multimodal Neural Script Knowledge Models"
        },
        {
            "paperId": "fea02a76f504f6dfefd2497220da913c5274f5ab",
            "title": "E2E-VLP: End-to-End Vision-Language Pre-training Enhanced by Visual Learning"
        },
        {
            "paperId": "e3575ca62373639152adf84ca0b33c52a4f892ef",
            "title": "M3P: Learning Universal Representations via Multitask Multilingual Multimodal Pre-training"
        },
        {
            "paperId": "68f080e0ac836ea230cb5316fbed273c70422d75",
            "title": "Segmenter: Transformer for Semantic Segmentation"
        },
        {
            "paperId": "0beb9f49ecad3f3e583553380d602d4563b231b6",
            "title": "Simulating User Satisfaction for the Evaluation of Task-oriented Dialogue Systems"
        },
        {
            "paperId": "d8e81e80490113434f7ac338c5f8d5a23f05a3de",
            "title": "SUPERB: Speech processing Universal PERformance Benchmark"
        },
        {
            "paperId": "cf9b8da26d9b92e75ba49616ed2a1033f59fce14",
            "title": "Open-vocabulary Object Detection via Vision and Language Knowledge Distillation"
        },
        {
            "paperId": "fdc74c8f69c6888e189f7275b1445b962cf084e6",
            "title": "DPT-FSNet: Dual-Path Transformer Based Full-Band and Sub-Band Fusion Network for Speech Enhancement"
        },
        {
            "paperId": "22299b440277b4bc887168a669408d5547c1461a",
            "title": "Playing Lottery Tickets with Vision and Language"
        },
        {
            "paperId": "f0524b3005720bcff886bcb0227f7f0dd924ff07",
            "title": "VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text"
        },
        {
            "paperId": "281ad83e06d731d5d686acf07cd701576f1188c4",
            "title": "CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip Retrieval"
        },
        {
            "paperId": "458ed347e05945cb500d665311c35c849b3834e3",
            "title": "TalkNet 2: Non-Autoregressive Depth-Wise Separable Convolutional Model for Speech Synthesis with Explicit Pitch and Duration Prediction"
        },
        {
            "paperId": "52a69f1e4bcf5043b51b79fddb6ae0b285e5d7c1",
            "title": "Emotion Recognition from Speech Using Wav2vec 2.0 Embeddings"
        },
        {
            "paperId": "70a79ded7818ba8ae807102b00643e331e344ee8",
            "title": "UC2: Universal Cross-lingual Cross-modal Vision-and-Language Pre-training"
        },
        {
            "paperId": "983d2b3ef5dca83338907da73983b41a5c6adc7c",
            "title": "Thinking Fast and Slow: Efficient Text-to-Visual Retrieval with Transformers"
        },
        {
            "paperId": "809b231e915c35db47cb81abfd8600f4c0f9fa10",
            "title": "Kaleido-BERT: Vision-Language Pre-training on Fashion Domain"
        },
        {
            "paperId": "0eff37167876356da2163b2e396df2719adf7de9",
            "title": "CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification"
        },
        {
            "paperId": "43efa8b1bf77033da9d3b94de512749eacf8176c",
            "title": "TSTNN: Two-Stage Transformer Based Neural Network for Speech Enhancement in the Time Domain"
        },
        {
            "paperId": "e6cf7c8a624d85448745d11f9b01011506db032e",
            "title": "Causal Attention for Vision-Language Tasks"
        },
        {
            "paperId": "98effe02ac4d04e16b71fc06b3aa18f6673ec5bc",
            "title": "Natural Language Understanding for Argumentative Dialogue Systems in the Opinion Building Domain"
        },
        {
            "paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4",
            "title": "Learning Transferable Visual Models From Natural Language Supervision"
        },
        {
            "paperId": "43de8837e4c1a57f3152e3ae4be4d68f3a633e0f",
            "title": "TransMask: A Compact and Fast Speech Separation Model Based on Transformer"
        },
        {
            "paperId": "ba4a4d31d2af23eefadbf19e5efd5a7d4fd89143",
            "title": "Less is More: CLIPBERT for Video-and-Language Learning via Sparse Sampling"
        },
        {
            "paperId": "141a5033d9994242b18bb3b217e79582f1ee9306",
            "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"
        },
        {
            "paperId": "1e5f33695c3529f2a622b7d776d95cee5be778dd",
            "title": "Bayesian Transformer Language Models for Speech Recognition"
        },
        {
            "paperId": "bd66f8a4e883ddf8a337dabdad88bc12b72d7c0e",
            "title": "Transformer models for text-based emotion detection: a review of BERT-based approaches"
        },
        {
            "paperId": "0839722fb5369c0abaff8515bfc08299efc790a1",
            "title": "ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision"
        },
        {
            "paperId": "d46ccff4a72e48c6865599221a71c4dfd3c954ac",
            "title": "SETransformer: Speech Enhancement Transformer"
        },
        {
            "paperId": "81002fbb777f860f9aac2bbc24467a62345af279",
            "title": "Decoupling the Role of Data, Attention, and Losses in Multimodal Transformers"
        },
        {
            "paperId": "b186f1704d3eeea0d979f21e375cb2b170e4c832",
            "title": "Transformer-Based Direct Speech-To-Speech Translation with Transcoder"
        },
        {
            "paperId": "8daf80335bf3693038357fcccbb2a520e8532a15",
            "title": "A New Dataset for Natural Language Understanding of Exercise Logs in a Food and Fitness Spoken Dialogue System"
        },
        {
            "paperId": "05d4c4f3fea5a29b4c6b6f1ef356d94c441d960c",
            "title": "UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data"
        },
        {
            "paperId": "3a906b77fa218adc171fecb28bb81c24c14dcc7b",
            "title": "Transformers in Vision: A Survey"
        },
        {
            "paperId": "80bb30e65c36545f7dcaae8fa9f1e66e550d4731",
            "title": "A survey on deep reinforcement learning for audio-based applications"
        },
        {
            "paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71",
            "title": "Training data-efficient image transformers & distillation through attention"
        },
        {
            "paperId": "2c340d7bc21aa6a9f44b466b7f74ac9150dfcb41",
            "title": "A Closer Look at the Robustness of Vision-and-Language Pre-trained Models"
        },
        {
            "paperId": "8dca64d7cc92dc1f899306772fc0d5f46ed0bc39",
            "title": "DeCoAR 2.0: Deep Contextualized Acoustic Representations with Vector Quantization"
        },
        {
            "paperId": "aed0f85b14e2c52e0c1850c93503bd637ff8119b",
            "title": "Parameter Efficient Multimodal Transformers for Video Representation Learning"
        },
        {
            "paperId": "b3383f4ec36e024f7dda3f1c708f076b8465e307",
            "title": "Just Ask: Learning to Answer Questions from Millions of Narrated Videos"
        },
        {
            "paperId": "ee15b0d8b7de63bdfc31532e866dfeb675442964",
            "title": "s-Transformer: Segment-Transformer for Robust Neural Speech Synthesis"
        },
        {
            "paperId": "4a5356e1935b908371aea251b123057430aafa13",
            "title": "One-Shot Conditional Audio Filtering of Arbitrary Sounds"
        },
        {
            "paperId": "eeb33ad2ede9944918724978bcbfb08b4c8c50a8",
            "title": "Learning Representations from Audio-Visual Spatial Alignment"
        },
        {
            "paperId": "873a3606459fa39d32ba70de2356bf2182bea5b3",
            "title": "Transformer in Action: A Comparative Study of Transformer-Based Acoustic Models for Large Scale Speech Recognition Applications"
        },
        {
            "paperId": "1dbcea281352daf192207d5c414161ecd90c955d",
            "title": "Two-Stage Textual Knowledge Distillation for End-to-End Spoken Language Understanding"
        },
        {
            "paperId": "51c9d4d2f50ac5707c1f889aa97f08350d549132",
            "title": "Attention Is All You Need In Speech Separation"
        },
        {
            "paperId": "77dc3ce653d2beddf6f01f282a86c9cc215b5297",
            "title": "Finnish ASR with Deep Transformer Models"
        },
        {
            "paperId": "5ba51fb6435091db73f1c3f8ada9db8734ff9642",
            "title": "Discriminative Transfer Learning for Optimizing ASR and Semantic Labeling in Task-Oriented Spoken Dialog"
        },
        {
            "paperId": "a835487689424826cb7e2b312710a086d167cc13",
            "title": "End-to-End Task-Oriented Dialog System Through Template Slot Value Generation"
        },
        {
            "paperId": "35570b8c9a79ec53540d48ea5a700232d99ed154",
            "title": "Transformer-Based Long-Context End-to-End Speech Recognition"
        },
        {
            "paperId": "838259c2b061b4025d42e1cfc89b2e0229d39845",
            "title": "Self-Distillation for Improving CTC-Transformer-Based ASR Systems"
        },
        {
            "paperId": "05082bbec600b65e85b04f9fbf7081f4a734d488",
            "title": "Transformer-Based End-to-End Speech Recognition with Local Dense Synthesizer Attention"
        },
        {
            "paperId": "5b032af877e9d4a65fdb37148cba10d1ea206244",
            "title": "Graphspeech: Syntax-Aware Graph Attention Network for Neural Speech Synthesis"
        },
        {
            "paperId": "131ee42e4839d153333e17f46facdb6806e98c73",
            "title": "Developing Real-Time Streaming Transformer Transducer for Speech Recognition on Large-Scale Dataset"
        },
        {
            "paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
        },
        {
            "paperId": "501d54cd4731dba3c7aad5735058be3da2753621",
            "title": "Emformer: Efficient Memory Transformer Based Acoustic Model for Low Latency Streaming Speech Recognition"
        },
        {
            "paperId": "97b0689d937a622c37726a10b911a60a89f146d8",
            "title": "TurnGPT: a Transformer-based Language Model for Predicting Turn-taking in Spoken Dialog"
        },
        {
            "paperId": "9ff525d1ebd389c359ddbf06df3e99c433c2bf9e",
            "title": "Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition"
        },
        {
            "paperId": "de9c16610ed1181710debba81d89a39dbde1fb50",
            "title": "Dual-mode ASR: Unify and Improve Streaming ASR with Full-context Modeling"
        },
        {
            "paperId": "2fb4522a8560c8778c2a4e8a94690a24b9c4450a",
            "title": "Fairseq S2T: Fast Speech-to-Text Modeling with Fairseq"
        },
        {
            "paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
            "title": "Rethinking Attention with Performers"
        },
        {
            "paperId": "0390c5e9556e162b0e514fd9c712c8d81018fb8b",
            "title": "Learning Knowledge Bases with Parameters for Task-Oriented Dialogue Systems"
        },
        {
            "paperId": "7495f9a7f17a2fb63b7776650efe453405aa8933",
            "title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog"
        },
        {
            "paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd",
            "title": "Efficient Transformers: A Survey"
        },
        {
            "paperId": "5c5741492053c3c7be9994510fac378250fcd6f7",
            "title": "VoiceFilter-Lite: Streaming Targeted Voice Separation for On-Device Speech Recognition"
        },
        {
            "paperId": "f0f81bda8974900a46d19ac9882cdeaa3dccf458",
            "title": "Visualizing Transformers for NLP: A Brief Survey"
        },
        {
            "paperId": "902a5f49f6a072c2c4ae7f26c62b89f030db6b6b",
            "title": "Are Neural Open-Domain Dialog Systems Robust to Speech Recognition Errors in the Dialog History? An Empirical Study"
        },
        {
            "paperId": "6871f6c5437a747fae75a19962f418d234ce2dc1",
            "title": "Multi-modal Transformer for Video Retrieval"
        },
        {
            "paperId": "63788711785b1dcbe400af8c2332b8bc48bc42fc",
            "title": "Low Rank Fusion based Transformers for Multimodal Sequences"
        },
        {
            "paperId": "33172567ab1dff9ca32c8d995d88bbff466f3236",
            "title": "Integrating Multimodal Information in Large Pretrained Transformers"
        },
        {
            "paperId": "c9518f55b47d3dc716b85a51d353674ff24a38d0",
            "title": "Multi-Scale Group Transformer for Long Sequence Modeling in Speech Separation"
        },
        {
            "paperId": "49a049dc85e2380dde80501a984878341dd8efdf",
            "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations"
        },
        {
            "paperId": "2e1107db4731714230b25efa9f7a8787e6e115d8",
            "title": "Fastpitch: Parallel Text-to-Speech with Pitch Prediction"
        },
        {
            "paperId": "2f5f81bc516a6d085d39479378af1fc27104f91e",
            "title": "Large-Scale Adversarial Training for Vision-and-Language Representation Learning"
        },
        {
            "paperId": "1623d6ffb6efd94d21537db2b96b91a196842aef",
            "title": "FastSpeech 2: Fast and High-Quality End-to-End Text to Speech"
        },
        {
            "paperId": "e21a4ca2ff3c5761e3cafd727a1cc10f057de814",
            "title": "MultiSpeech: Multi-Speaker Text to Speech with Transformer"
        },
        {
            "paperId": "8cda672bd5487ec2c67d5c217dc84ed8fb786640",
            "title": "ActBERT: Learning Global-Local Video-Text Representations"
        },
        {
            "paperId": "ef8d788a904ed66bd8e30ffa69bc3ea1fe57dda7",
            "title": "HAT: Hardware-Aware Transformers for Efficient Natural Language Processing"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "be934c378c897e5bc3b3767376a59a4679093286",
            "title": "On the Comparison of Popular End-to-End Models for Large Scale Speech Recognition"
        },
        {
            "paperId": "46845759234be49f085e57c694e9b5ec0f79874e",
            "title": "Exploring Transformers for Large-Scale Speech Recognition"
        },
        {
            "paperId": "0170fc76e934ee643f869df18fb617d5357e8b4e",
            "title": "Conformer: Convolution-augmented Transformer for Speech Recognition"
        },
        {
            "paperId": "768e5f9b019c27babbfaf817a5bb20316b9df113",
            "title": "Streaming Transformer-based Acoustic Models Using Self-attention with Augmented Memory"
        },
        {
            "paperId": "2899d16c4c956ad1850d42e9c6ba50d1f14b4e7a",
            "title": "JDI-T: Jointly trained Duration Informed Transformer for Text-To-Speech without Explicit Alignment"
        },
        {
            "paperId": "39206ad9fe0859a0043bd8caea2e3f8202b67533",
            "title": "Improving End-to-End Speech Synthesis with Local Recurrent Neural Network Enhanced Transformer"
        },
        {
            "paperId": "9b539d413393047b28bb7be9b195f142aaf7a80e",
            "title": "Recipes for Building an Open-Domain Chatbot"
        },
        {
            "paperId": "c51b99f18f0ca9e1e2fea7132bf5654299817d6c",
            "title": "DIET: Lightweight Language Understanding for Dialogue Systems"
        },
        {
            "paperId": "8d908042f139575d6688c745e94156c9df6eae07",
            "title": "Understanding the Difficulty of Training Transformers"
        },
        {
            "paperId": "b5ef0f91663f0cbd6910dec9a890c138f7ec10e0",
            "title": "Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks"
        },
        {
            "paperId": "39bb6a13c34e2301373ecd35f5f4d31c8ff6e763",
            "title": "RobuTrans: A Robust Transformer-Based Text-to-Speech Model"
        },
        {
            "paperId": "598a2ee223e2949c3b28389e922c1892b4717d2a",
            "title": "Pixel-BERT: Aligning Image Pixels with Text by Deep Multi-Modal Transformers"
        },
        {
            "paperId": "657329c633709dd1ac34a30d57341b186b1a47c2",
            "title": "Efficient Content-Based Sparse Attention with Routing Transformers"
        },
        {
            "paperId": "086f74fbd570ba2f0d35cb2aeb96001681485c5f",
            "title": "Unsupervised Style and Content Separation by Minimizing Mutual Information for Speech Synthesis"
        },
        {
            "paperId": "1d0d9550ecd2bece6a34fe1ffd12fb7504e7aaa0",
            "title": "XGPT: Cross-modal Generative Pre-Training for Image Captioning"
        },
        {
            "paperId": "441e48ff5a233f243fea1759d9dbfbbbf9598595",
            "title": "Controllable Time-Delay Transformer for Real-Time Punctuation Prediction and Disfluency Detection"
        },
        {
            "paperId": "1042714c5be82d980066fd038105112e601a848e",
            "title": "Towards Learning a Universal Non-Semantic Representation of Speech"
        },
        {
            "paperId": "09e2c7adbed37440d4a339852cfa34e5b660f768",
            "title": "Transformer Transducer: A Streamable Speech Recognition Model with Transformer Encoders and RNN-T Loss"
        },
        {
            "paperId": "18486ffffd6d19ac0521975ce3b5f916212a520c",
            "title": "Learning Robust and Multilingual Speech Representations"
        },
        {
            "paperId": "d08463bd665589d04619f04dbde84183ffcf2e63",
            "title": "Towards a Human-like Open-Domain Chatbot"
        },
        {
            "paperId": "a9fd5511b42206a27748f373e0fdb7eb76a23055",
            "title": "ImageBERT: Cross-modal Pre-training with Large-scale Weak-supervised Image-Text Data"
        },
        {
            "paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500",
            "title": "Reformer: The Efficient Transformer"
        },
        {
            "paperId": "bf03f2ebdace496593bc4a530c6ff6bf6c71149e",
            "title": "Voice Transformer Network: Sequence-to-Sequence Voice Conversion Using Transformer with Text-to-Speech Pretraining"
        },
        {
            "paperId": "a84689ef8eaf38344eb3de24850ec0720c815605",
            "title": "Synchronous Transformers for end-to-end Speech Recognition"
        },
        {
            "paperId": "f9d3ee8569fd73bdcad421e3d0978b8209d46f51",
            "title": "Intention Detection Based On Bert-Bilstm in Taskoriented Dialogue System"
        },
        {
            "paperId": "bc1ab519c225b08332f243269ad6d99284bbf1bf",
            "title": "A Comparison of Transformer and LSTM Encoder Decoder Models for ASR"
        },
        {
            "paperId": "9d296005633ee031b7252ff7a63ecb2303afcb04",
            "title": "Attention-Informed Mixed-Language Training for Zero-shot Cross-lingual Task-oriented Dialogue Systems"
        },
        {
            "paperId": "3f55c542de1e5a19e33cba481dd5460b2a92a266",
            "title": "ConveRT: Efficient and Accurate Conversational Representations from Transformers"
        },
        {
            "paperId": "19a814603289f80c57cc6e7973c115c091f5520a",
            "title": "A Simplified Fully Quantized Transformer for End-to-end Speech Recognition"
        },
        {
            "paperId": "388e2fcdcefbe0834e153ab2a0be127092f9674d",
            "title": "DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation"
        },
        {
            "paperId": "dc28420a0f61113d336cc19c07388ba720f96f2f",
            "title": "Improving Generalization of Transformer for Speech Recognition with Parallel Schedule Sampling and Relative Positional Embedding"
        },
        {
            "paperId": "49e5b09480189fc9b2316a54f9d1e55cf0097c8b",
            "title": "Lightweight and Efficient End-To-End Speech Recognition Using Low-Rank Transformer"
        },
        {
            "paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
            "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"
        },
        {
            "paperId": "fd9649aa3b3151615fffb6bd1b547ee7d82766ee",
            "title": "Transformer-Transducer: End-to-End Speech Recognition with Self-Attention"
        },
        {
            "paperId": "f1e8a99a7e17d449559b26ee0db2e8f1f47ce7ad",
            "title": "SpeechBERT: An Audio-and-Text Jointly Learned Language Model for End-to-End Spoken Question Answering"
        },
        {
            "paperId": "41dd922a7fc5a6df5ef5e8358c1a29e79910d816",
            "title": "Mockingjay: Unsupervised Speech Representation Learning with Deep Bidirectional Transformer Encoders"
        },
        {
            "paperId": "bf0e844f547eec1e161bc5374c0ab13e9d2aa321",
            "title": "Correction of Automatic Speech Recognition with Transformer Sequence-To-Sequence Model"
        },
        {
            "paperId": "18add4d16ace862ecd572b736d848c4d8136ef6f",
            "title": "Speech-XLNet: Unsupervised Acoustic Model Pretraining For Self-Attention Networks"
        },
        {
            "paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
        },
        {
            "paperId": "b72c5236dacf2b958ebcf427d17a100bc54af504",
            "title": "Transformer ASR with Contextual Block Processing"
        },
        {
            "paperId": "29962ae812e7142f56f5f67c2db9d00ab3dfa4c4",
            "title": "T-GSA: Transformer with Gaussian-Weighted Self-Attention for Speech Enhancement"
        },
        {
            "paperId": "84913d6f08942ddf8dd51418820537abfaa5ae19",
            "title": "vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations"
        },
        {
            "paperId": "137918f9613973dd7428fabf464753721fb520ee",
            "title": "Using Bidirectional Transformer-CRF for Spoken Language Understanding"
        },
        {
            "paperId": "c95383f251a62c63217586059c67f63507c3e839",
            "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"
        },
        {
            "paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc",
            "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"
        },
        {
            "paperId": "dfc7b58b67c31932b48586b3e23a43cc94695290",
            "title": "UNITER: UNiversal Image-TExt Representation Learning"
        },
        {
            "paperId": "5bb0bc9676ce9be0d953d8de0e065988cd4fb807",
            "title": "Factorized Multimodal Transformer for Multimodal Sequential Learning"
        },
        {
            "paperId": "ee3a4e09e6d295816d88c0f5594ded7e4922e8b6",
            "title": "Recognition of Intentions of Users' Short Responses for Conversational News Delivery System"
        },
        {
            "paperId": "684597268c6ac614439d4f0d5de1756a668fdb8a",
            "title": "A Comparison of Deep Learning Methods for Language Understanding"
        },
        {
            "paperId": "d0a313a557bd43a7cacb3e5479cd7c491f7faa5c",
            "title": "Adapting Transformer to End-to-End Spoken Language Translation"
        },
        {
            "paperId": "8bfc683672232551c2664233e8e6fae76c2a6260",
            "title": "Improving Transformer-Based Speech Recognition Systems with Compressed Structure and Speech Attributes Augmentation"
        },
        {
            "paperId": "0ce184bd55a4736ec64e5d82a85421298e0373ea",
            "title": "A Comparative Study on Transformer vs RNN in Speech Applications"
        },
        {
            "paperId": "4444e3830f7416449fd2e352c0aa278440e40590",
            "title": "DurIAN: Duration Informed Attention Network For Multimodal Synthesis"
        },
        {
            "paperId": "79c93274429d6355959f1e4374c2147bb81ea649",
            "title": "LXMERT: Learning Cross-Modality Encoder Representations from Transformers"
        },
        {
            "paperId": "3ae3c9de97343bfc5f5f5f17a9419a5db3e5e652",
            "title": "Speech Emotion Recognition Using Deep Learning Techniques: A Review"
        },
        {
            "paperId": "7e87fb8fe78694d42bdc3b4a3b04ffb218148233",
            "title": "Survey on Deep Neural Networks in Speech and Vision Systems"
        },
        {
            "paperId": "2bc1c8bd00bbf7401afcb5460277840fd8bab029",
            "title": "Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training"
        },
        {
            "paperId": "93d63ec754f29fa22572615320afe0521f7ec66d",
            "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"
        },
        {
            "paperId": "5aec474c31a2f4b74703c6f786c0a8ff85c450da",
            "title": "VisualBERT: A Simple and Performant Baseline for Vision and Language"
        },
        {
            "paperId": "a5ed9dfc0725bffb6428a2cc297a15265377906c",
            "title": "Hello, It\u2019s GPT-2 - How Can I Help You? Towards the Use of Pretrained Language Models for Task-Oriented Dialogue Systems"
        },
        {
            "paperId": "6b2704fd8517a9917cfd9d3735930be48717d3de",
            "title": "Sharing Attention Weights for Fast Transformer"
        },
        {
            "paperId": "62dc8ddb4907db4b889c5e93673d9b3c189d1f25",
            "title": "A Tensorized Transformer for Language Modeling"
        },
        {
            "paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
            "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"
        },
        {
            "paperId": "a4d29e912ef6014e355649c1f9f822b9bf3d14e3",
            "title": "Lattice Transformer for Speech Translation"
        },
        {
            "paperId": "a39398f68ae7e042f2ef5009e31b4e6a20fd5736",
            "title": "Learning Deep Transformer Models for Machine Translation"
        },
        {
            "paperId": "d6b0db33bd2952b616960f617a0343a28323fc7e",
            "title": "Improving Long Distance Slot Carryover in Spoken Dialogue Systems"
        },
        {
            "paperId": "949fef650da4c41afe6049a183b504b3cc91f4bd",
            "title": "Multimodal Transformer for Unaligned Multimodal Language Sequences"
        },
        {
            "paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583",
            "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"
        },
        {
            "paperId": "aa50768a67b9f3f578ab5eb300a248ebc33b7da6",
            "title": "The Speechtransformer for Large-scale Mandarin Chinese Speech Recognition"
        },
        {
            "paperId": "606c03a5bb36b77bfc99e33fd7cb6731b13b8eab",
            "title": "Transformers with convolutional context for ASR"
        },
        {
            "paperId": "21da617a0f79aabf94272107184606cefe90ab75",
            "title": "Generating Long Sequences with Sparse Transformers"
        },
        {
            "paperId": "b0fae9fbb4e580d92395eabafe73e317ae6510e3",
            "title": "SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition"
        },
        {
            "paperId": "c41a11c0e9b8b92b4faaf97749841170b760760a",
            "title": "VideoBERT: A Joint Model for Video and Language Representation Learning"
        },
        {
            "paperId": "81dfe45d180d47242838cd8aef809037709df8cb",
            "title": "Deep Text-to-Speech System with Seq2Seq Model"
        },
        {
            "paperId": "e54f6751476ba07928b3f78c097150aa610acffc",
            "title": "Self-attention Aligner: A Latency-control End-to-end Model for ASR Using Self-attention Network and Chunk-hopping"
        },
        {
            "paperId": "29650544fded20dd5b2fc49f60f9a3ad30d0e275",
            "title": "Speech Recognition Using Deep Neural Networks: A Systematic Review"
        },
        {
            "paperId": "e81b50f68265b84d55d03dab3c296b9fd4516857",
            "title": "TransferTransfo: A Transfer Learning Approach for Neural Network Based Conversational Agents"
        },
        {
            "paperId": "ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc",
            "title": "Cross-lingual Language Model Pretraining"
        },
        {
            "paperId": "612a42e2fa4c33b609aade451528d3c11989f88a",
            "title": "Self-attention Networks for Connectionist Temporal Classification in Speech Recognition"
        },
        {
            "paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6",
            "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"
        },
        {
            "paperId": "e9b13731027418ed38103d1dfc8a70f6881bc684",
            "title": "Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question Answering"
        },
        {
            "paperId": "52533e5ffc2f9b635fa21259f9749609b1f9dfa1",
            "title": "End-to-End Speech Translation with the Transformer"
        },
        {
            "paperId": "220d47d9b2872f0f0c33084fb4425424d91fa0ac",
            "title": "Waveglow: A Flow-based Generative Network for Speech Synthesis"
        },
        {
            "paperId": "8c9db2d4588bd774474bc87540bbf561c57a910f",
            "title": "VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking"
        },
        {
            "paperId": "a364a2b6bb97fcb4207468e6500cf3042bbf8d07",
            "title": "Speech Recognition"
        },
        {
            "paperId": "9f2dd5cc190fc713f1339fca838a5537931744f8",
            "title": "Neural Speech Synthesis with Transformer Network"
        },
        {
            "paperId": "5e3a59695261f03aa3f09a8a5ac6166fb63e0a2e",
            "title": "ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech"
        },
        {
            "paperId": "35531573d06fb4a7420615486797885b932ff2a2",
            "title": "Mixed-Precision Training for NLP and Speech Recognition with OpenSeq2Seq"
        },
        {
            "paperId": "f38e047932ddee5614c68214e427215320c22b6c",
            "title": "A Comparison of Modeling Units in Sequence-to-Sequence Speech Recognition with the Transformer on Mandarin Chinese"
        },
        {
            "paperId": "53dcd6068586d50169877d145df550ff3f568221",
            "title": "Syllable-Based Sequence-to-Sequence Speech Recognition with the Transformer in Mandarin Chinese"
        },
        {
            "paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"
        },
        {
            "paperId": "a6e4beb28b345fce7470da122b4e45e2cd0dcd12",
            "title": "A Time-Restricted Self-Attention Layer for ASR"
        },
        {
            "paperId": "41a78e2885b5dc8c719495a33985b5f4880f5b48",
            "title": "Speech-Transformer: A No-Recurrence Sequence-to-Sequence Model for Speech Recognition"
        },
        {
            "paperId": "d198754b61b3d87b015b382d6cc9204a270eb6cb",
            "title": "Fftnet: A Real-Time Speaker-Dependent Neural Vocoder"
        },
        {
            "paperId": "171f8f1090ef0533ff470ed5a4d31ecfefcc74be",
            "title": "Audio-Visual Scene Analysis with Self-Supervised Multisensory Features"
        },
        {
            "paperId": "c52ac453e154953abdb06fc041023e327ea609a4",
            "title": "Self-Attentional Acoustic Models"
        },
        {
            "paperId": "083ec74cc10f96fbb64322ba23450666fd4df6cd",
            "title": "Speech2Vec: A Sequence-to-Sequence Framework for Learning Word Embeddings from Speech"
        },
        {
            "paperId": "642c1b4a9da95ea4239708afc5929a5007a1870d",
            "title": "Tensor2Tensor for Neural Machine Translation"
        },
        {
            "paperId": "4c4fe2bfacc6db6b446401f164a406c48b642e86",
            "title": "End-to-End Automatic Speech Translation of Audiobooks"
        },
        {
            "paperId": "1a2599e467e855f845dcbf9282f8bdbd97b85708",
            "title": "Natural TTS Synthesis by Conditioning Wavenet on MEL Spectrogram Predictions"
        },
        {
            "paperId": "852120feb37d2dc136d1c6916b52b9baabfc2e11",
            "title": "Deep Voice 3: 2000-Speaker Neural Text-to-Speech"
        },
        {
            "paperId": "dab7bb72f29b2b7921b44d4836713f89931b0f22",
            "title": "Toward Expressive Speech Translation: A Unified Sequence-to-Sequence LSTMs Approach for Translating Words and Emphasis"
        },
        {
            "paperId": "ffe28f6bf0e9e6bbca6313319aa1a5409d283d9b",
            "title": "Zero-Shot Learning\u2014A Comprehensive Evaluation of the Good, the Bad and the Ugly"
        },
        {
            "paperId": "5a96f2bfa2deae2bc35b250251d5fbe82ef4932b",
            "title": "Tensor Fusion Network for Multimodal Sentiment Analysis"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "b06f2a7460bef1c1ef48c7c3353dbcc864727cc2",
            "title": "Deep Learning for Environmentally Robust Speech Recognition"
        },
        {
            "paperId": "6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91",
            "title": "Multimodal Machine Learning: A Survey and Taxonomy"
        },
        {
            "paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0",
            "title": "Convolutional Sequence to Sequence Learning"
        },
        {
            "paperId": "a072c2a400f62f720b68dc54a662fb1ae115bf06",
            "title": "Tacotron: Towards End-to-End Speech Synthesis"
        },
        {
            "paperId": "dda047fd87610911c82778243f72f60d1c063383",
            "title": "Sequence-to-Sequence Models Can Directly Translate Foreign Speech"
        },
        {
            "paperId": "63880b57b95de8afd73036e55b9c4bccb7a528b9",
            "title": "Deep Voice: Real-time Neural Text-to-Speech"
        },
        {
            "paperId": "c95a9010bb05d77e334e280fb6dd987aaf053098",
            "title": "Listen and Translate: A Proof of Concept for End-to-End Speech-to-Text Translation"
        },
        {
            "paperId": "df0402517a7338ae28bc54acaac400de6b456a46",
            "title": "WaveNet: A Generative Model for Raw Audio"
        },
        {
            "paperId": "e0b207e96351671453aa8bf05b7225c8a340a0b2",
            "title": "Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks"
        },
        {
            "paperId": "6e795c6e9916174ae12349f5dc3f516570c17ce8",
            "title": "Skip-Thought Vectors"
        },
        {
            "paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19",
            "title": "Distilling the Knowledge in a Neural Network"
        },
        {
            "paperId": "86efe7769f2b8a0e15ca213ab09881e6705caeb0",
            "title": "Convolutional Neural Networks for Speech Recognition"
        },
        {
            "paperId": "f3de86aeb442216a8391befcacb49e58b478f512",
            "title": "Distributed Representations of Sentences and Documents"
        },
        {
            "paperId": "9d748af3521b51648a91a7e807db4d5270d2e240",
            "title": "Automatic Speech Recognition: A Survey"
        },
        {
            "paperId": "7b4f3d0e4e2486a8d5d3f8e00549cf9a117bf88f",
            "title": "Sequence Transduction with Recurrent Neural Networks"
        },
        {
            "paperId": "5a8246be154ca2c9965c6573f14e570e314aebdd",
            "title": "Speech translation: coupling of recognition and translation"
        },
        {
            "paperId": "af4406c6da46ba6c15efdf6c682275cde9dfccb9",
            "title": "Audio-visual integration in multimodal communication"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "1a3d22599028a05669e884f3eaf19a342e190a87",
            "title": "Backpropagation Through Time: What It Does and How to Do It"
        },
        {
            "paperId": "14bc876fae55faf5669beb01667a4f3bd324a4f1",
            "title": "Signal estimation from modified short-time Fourier transform"
        },
        {
            "paperId": "48eeab429c73f2cf525fe727ef949667576ed196",
            "title": "Incorporating BERT With Probability-Aware Gate for Spoken Language Understanding"
        },
        {
            "paperId": "e8242d649eca80018dc01e35b733d332e14d0dce",
            "title": "Audio Embedding-Aware Dialogue Policy Learning"
        },
        {
            "paperId": "a156686a4ba46a7fa3af3daf618e8d470e01ea69",
            "title": "Combining Neural Networks with Knowledge for Spoken Dialogue Systems"
        },
        {
            "paperId": "49f8a31e13998ae431dde8092973e6bd0f8385be",
            "title": "GPT-Critic: Offline Reinforcement Learning for End-to-End Task-Oriented Dialogue Systems"
        },
        {
            "paperId": "36c2b7f37554bc508b7d0a0bebb07b240c56169b",
            "title": "Conditioning Sequence-to-sequence Networks with Learned Activations"
        },
        {
            "paperId": "3cc9516d99f7053f595d1be0347ffd8779026749",
            "title": "TT-ViT: Vision Transformer Compression Using Tensor-Train Decomposition"
        },
        {
            "paperId": "1c939d9726eff12d8cf305c85d875d9fb0caf840",
            "title": "Hypoformer: Hybrid Decomposition Transformer for Edge-friendly Neural Machine Translation"
        },
        {
            "paperId": "5d49c6cd771e1b130b893bbec178f63d6e79e95c",
            "title": "Transfer Learning of Transformers for Spoken Language Understanding"
        },
        {
            "paperId": "4bf6b830c90b78684967a12c3db5f6bb75a86343",
            "title": "Can We Predict How Challenging Spoken Language Understanding Corpora Are Across Sources, Languages, and Domains?"
        },
        {
            "paperId": "3bab3f9dcfe4d0446bb1d093593569d55c5a6ca6",
            "title": "Multilingual Speech Translation from Efficient Finetuning of Pretrained Models"
        },
        {
            "paperId": "34c17bb861b882531402e8a223fba96fbaca82bd",
            "title": "Automatic Speech Recognition: Systematic Literature Review"
        },
        {
            "paperId": "198e1a99bc60b91e5ba3dd2fe306d61802f38732",
            "title": "CTNet: Conversational Transformer Network for Emotion Recognition"
        },
        {
            "paperId": "b76e98a0a023d37c6534aa2ead09c8ff595f0bae",
            "title": "A Robustly Optimized BERT Pre-training Approach with Post-training"
        },
        {
            "paperId": "99cec4179800a4e7e6ac9715261754a4a575a35d",
            "title": "Pretrained Models"
        },
        {
            "paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": null,
            "title": "\u201cBridging commonsense reasoning and probabilistic planning via a differentiable neural logic framework,\u201d"
        },
        {
            "paperId": null,
            "title": "Speech and Signal Processing (ICASSP)"
        },
        {
            "paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "title": "Improving Language Understanding by Generative Pre-Training"
        },
        {
            "paperId": "ab22dbe619750aebfd08b3c8aab49cffe2a5c777",
            "title": "From Speech Recognition to Language and Multimodal Processing"
        },
        {
            "paperId": "b522252d4e370708a5bdd43f4f0bfd9103f808bb",
            "title": "Text-to-speech synthesis"
        },
        {
            "paperId": "343e0f3b1cdbede696e67cf2f77e311899a3cc71",
            "title": "On the integration of speech recognition and statistical machine translation"
        },
        {
            "paperId": "c096c2942b7b6e0f856409dad967bfdf1b94d2f7",
            "title": "Paralinguistic Phonetics in NLP Models & Methods"
        },
        {
            "paperId": null,
            "title": "\u201cSparse transformers and longformers: A comprehensive summary of space and time optimizations on transformer architectures,\u201d"
        },
        {
            "paperId": null,
            "title": "\u201cAccelerated inference for large transformer models using nvidia triton inference server,\u201d"
        }
    ]
}