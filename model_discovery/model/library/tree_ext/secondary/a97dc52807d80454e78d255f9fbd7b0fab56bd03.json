{
    "paperId": "a97dc52807d80454e78d255f9fbd7b0fab56bd03",
    "externalIds": {
        "ArXiv": "1705.00557",
        "MAG": "2610858497",
        "DBLP": "journals/corr/JerniteBS17",
        "CorpusId": 6694822
    },
    "title": "Discourse-Based Objectives for Fast Unsupervised Sentence Representation Learning",
    "abstract": "This work presents a novel objective function for the unsupervised training of neural network sentence encoders. It exploits signals from paragraph-level discourse coherence to train these models to understand text. Our objective is purely discriminative, allowing us to train models many times faster than was possible under prior methods, and it yields models which perform well in extrinsic evaluations.",
    "venue": "arXiv.org",
    "year": 2017,
    "referenceCount": 33,
    "citationCount": 108,
    "influentialCitationCount": 11,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work presents a novel objective function for the unsupervised training of neural network sentence encoders that exploits signals from paragraph-level discourse coherence to train these models to understand text."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "2262249",
            "name": "Yacine Jernite"
        },
        {
            "authorId": "3644767",
            "name": "Samuel R. Bowman"
        },
        {
            "authorId": "1746662",
            "name": "D. Sontag"
        }
    ],
    "references": [
        {
            "paperId": "612598389b4349fef728c80ab4202fee32f3a536",
            "title": "Unsupervised Learning of Sentence Representations using Convolutional Neural Networks"
        },
        {
            "paperId": "85f94d8098322f8130512b4c6c4627548ce4a6cc",
            "title": "Unsupervised Pretraining for Sequence to Sequence Learning"
        },
        {
            "paperId": "c4ea7ea20e3481dd92bb180e59b75c7ac7c41a74",
            "title": "Sentence Ordering using Recurrent Neural Networks"
        },
        {
            "paperId": "6eec608f266de95eb817e9a6086641abc3c91e5f",
            "title": "Embracing data abundance: BookTest Dataset for Reading Comprehension"
        },
        {
            "paperId": "892e53fe5cd39f037cb2a961499f42f3002595dd",
            "title": "Bag of Tricks for Efficient Text Classification"
        },
        {
            "paperId": "455afd748e8834ef521e4b67c7c056d3c33429e2",
            "title": "Hierarchical Attention Networks for Document Classification"
        },
        {
            "paperId": "36a7b1a82390f5291b3bf8ff592f8630b4f33442",
            "title": "Neural Net Models for Open-Domain Discourse Coherence"
        },
        {
            "paperId": "3dfd76e4b5083ee71049099c3105e8af69edb44f",
            "title": "A Latent Variable Recurrent Neural Network for Discourse-Driven Language Models"
        },
        {
            "paperId": "26e743d5bd465f49b9538deaf116c15e61b7951f",
            "title": "Learning Distributed Representations of Sentences from Unlabelled Data"
        },
        {
            "paperId": "961073143d3cfe662e9e820d24c0a88f0ae94c83",
            "title": "Document Context Language Models"
        },
        {
            "paperId": "722e01d5ba05083f7a091f3188cfdfcf183a325d",
            "title": "Larger-Context Language Modelling with Recurrent Neural Network"
        },
        {
            "paperId": "4aa9f5150b46320f534de4747a2dd0cd7f3fe292",
            "title": "Semi-supervised Sequence Learning"
        },
        {
            "paperId": "51a55df1f023571a7e07e338ee45a3e3d66ef73e",
            "title": "Character-level Convolutional Networks for Text Classification"
        },
        {
            "paperId": "1ac30af5522c7a50ec4d1ee43fd2bd8652a9bd52",
            "title": "A Neural Attention Model for Abstractive Sentence Summarization"
        },
        {
            "paperId": "891ce1687e2befddd19f54e4eef1d3f39c8dbaf7",
            "title": "Character-Aware Neural Language Models"
        },
        {
            "paperId": "6e795c6e9916174ae12349f5dc3f516570c17ce8",
            "title": "Skip-Thought Vectors"
        },
        {
            "paperId": "0e6824e137847be0599bb0032e37042ed2ef5045",
            "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"
        },
        {
            "paperId": "e0945081b5b87187a53d4329cf77cd8bff635795",
            "title": "Highway Networks"
        },
        {
            "paperId": "c945743ef99b1c897eaa07ba276dcec0fcdbc0b4",
            "title": "A Model of Coherence Based on Distributed Sentence Representation"
        },
        {
            "paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "title": "Sequence to Sequence Learning with Neural Networks"
        },
        {
            "paperId": "1eb09fecd75eb27825dce4f964b97f4f5cc399d7",
            "title": "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches"
        },
        {
            "paperId": "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba",
            "title": "Convolutional Neural Networks for Sentence Classification"
        },
        {
            "paperId": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
        },
        {
            "paperId": "413c1142de9d91804d6d11c67ff3fed59c9fc279",
            "title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization"
        },
        {
            "paperId": "9d74eca00d4d0c4aa7c7369ae37d67498b37bf2f",
            "title": "Modeling Local Coherence: An Entity-Based Approach"
        },
        {
            "paperId": "7acfdc905f734abf966aed58abb983bc015ff7fe",
            "title": "Unsupervised Construction of Large Paraphrase Corpora: Exploiting Massively Parallel News Sources"
        },
        {
            "paperId": "167e1359943b96b9e92ee73db1df69a1f65d731d",
            "title": "A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts"
        },
        {
            "paperId": "b349b855f47a3000062e1b08ec48651b28ce10f4",
            "title": "The Penn Discourse Treebank"
        },
        {
            "paperId": "9cf7cc817b30170ca36e46c6a2b47f972a8fe998",
            "title": "Literary freedom: project Gutenberg"
        },
        {
            "paperId": "7ec24da49ba4aa33b724c908fb885a401719ced6",
            "title": "Overview of the TREC 2001 Question Answering Track"
        },
        {
            "paperId": "9819b600a828a57e1cde047bbe710d3446b30da5",
            "title": "Recurrent neural network based language model"
        },
        {
            "paperId": "6ed9417eaa7ee16f0563599829a061421a3e0563",
            "title": "NLTK: The Natural Language Toolkit"
        },
        {
            "paperId": "f2e1d62340d111dacb3b1038eb0a8676df045566",
            "title": "Coherence and Coreference"
        }
    ]
}