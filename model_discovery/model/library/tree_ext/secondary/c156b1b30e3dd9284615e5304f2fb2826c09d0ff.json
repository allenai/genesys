{
    "paperId": "c156b1b30e3dd9284615e5304f2fb2826c09d0ff",
    "externalIds": {
        "DBLP": "conf/kdd/KimSTGKHK22",
        "ArXiv": "2107.00910",
        "DOI": "10.1145/3534678.3539260",
        "CorpusId": 235727659
    },
    "title": "Learned Token Pruning for Transformers",
    "abstract": "Efficient deployment of transformer models in practice is challenging due to their inference cost including memory footprint, latency, and power consumption, which scales quadratically with input sequence length. To address this, we present a novel token reduction method dubbed Learned Token Pruning (LTP) which adaptively removes unimportant tokens as an input sequence passes through transformer layers. In particular, LTP prunes tokens with an attention score below a threshold, whose value is learned for each layer during training. Our threshold-based method allows the length of the pruned sequence to vary adaptively based on the input sequence, and avoids algorithmically expensive operations such as top-k token selection. We extensively test the performance of LTP on GLUE and SQuAD tasks and show that our method outperforms the prior state-of-the-art token pruning methods by up to \u223d2.5% higher accuracy with the same amount of FLOPs. In particular, LTP achieves up to 2.1\u00d7 FLOPs reduction with less than 1% accuracy drop, which results in up to 1.9\u00d7 and 2.0\u00d7 throughput improvement on Intel Haswell CPUs and NVIDIA V100 GPUs. Furthermore, we demonstrate that LTP is more robust than prior methods to variations in input sequence lengths. Our code has been developed in PyTorch and open-sourced",
    "venue": "Knowledge Discovery and Data Mining",
    "year": 2021,
    "referenceCount": 80,
    "citationCount": 100,
    "influentialCitationCount": 14,
    "openAccessPdf": {
        "url": "https://dl.acm.org/doi/pdf/10.1145/3534678.3539260",
        "status": "BRONZE"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel token reduction method dubbed Learned Token Pruning (LTP) which adaptively removes unimportant tokens as an input sequence passes through transformer layers, which is more robust than prior methods to variations in input sequence lengths."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -2.280122995376587,
            0.8115869164466858,
            1.146554708480835,
            6.127507209777832,
            -0.2877174913883209,
            2.168077230453491,
            0.3197583556175232,
            -0.47026726603507996,
            1.3756532669067383,
            2.052910566329956,
            -0.5032716393470764,
            4.264042854309082,
            0.5355346202850342,
            -1.4959712028503418,
            -5.4563703536987305,
            -0.42011794447898865,
            -0.015568874776363373,
            -0.7027336955070496,
            5.419630527496338,
            3.629551410675049,
            0.3652929365634918,
            1.786496639251709,
            -3.722679853439331,
            1.5531740188598633,
            -1.8189997673034668,
            2.3187007904052734,
            -0.8308696746826172,
            -2.423492908477783,
            -4.389549255371094,
            0.6071466207504272,
            -1.6341426372528076,
            -7.293324947357178,
            5.4702372550964355,
            -2.307164430618286,
            0.5738511085510254,
            -3.3748421669006348,
            -3.152853488922119,
            7.596128940582275,
            -6.7326812744140625,
            -1.3013664484024048,
            -0.8444925546646118,
            -0.44137877225875854,
            -0.5546411275863647,
            1.0767897367477417,
            1.2950152158737183,
            3.3490915298461914,
            3.181457042694092,
            0.8450045585632324,
            0.011473864316940308,
            4.0926337242126465,
            3.6281561851501465,
            2.723426580429077,
            -2.3852450847625732,
            -0.5556628704071045,
            -1.697006106376648,
            -0.9265792369842529,
            1.7684470415115356,
            0.14102685451507568,
            2.6441032886505127,
            -1.8470864295959473,
            7.348674774169922,
            4.784146785736084,
            1.5722525119781494,
            1.6910004615783691,
            2.9859378337860107,
            -3.08308482170105,
            -0.028478700667619705,
            1.9575183391571045,
            1.714795708656311,
            1.0190558433532715,
            -0.17954301834106445,
            -6.9045000076293945,
            1.6399415731430054,
            -0.11087678372859955,
            -3.332159996032715,
            -2.1219377517700195,
            0.912090003490448,
            -4.679996490478516,
            0.5478419065475464,
            -3.3854174613952637,
            -1.8379368782043457,
            3.9209132194519043,
            -0.22616736590862274,
            2.9217491149902344,
            6.623528480529785,
            -4.455780029296875,
            -0.938073456287384,
            -0.41976043581962585,
            2.5625500679016113,
            -0.3188861906528473,
            0.20284070074558258,
            2.075658082962036,
            -0.7045106291770935,
            1.2818083763122559,
            -5.765032768249512,
            0.027163594961166382,
            0.2352217435836792,
            -0.7465355396270752,
            -2.6724894046783447,
            3.555081844329834,
            0.5427126884460449,
            1.237127423286438,
            2.6757051944732666,
            2.192762851715088,
            1.1485884189605713,
            -0.31402620673179626,
            -3.356067180633545,
            1.7626354694366455,
            -1.8887923955917358,
            -2.050482988357544,
            -0.1996431052684784,
            4.695682048797607,
            -0.18301406502723694,
            -0.9981938004493713,
            -2.3223049640655518,
            -4.434963226318359,
            -1.6864193677902222,
            -1.9398455619812012,
            -1.107051968574524,
            2.175914764404297,
            -0.7474848031997681,
            0.4903198480606079,
            -1.2746108770370483,
            0.9170299172401428,
            -0.2992754578590393,
            3.8678548336029053,
            -1.724555253982544,
            0.7431982755661011,
            -0.9811650514602661,
            -3.721639633178711,
            1.0716346502304077,
            -2.7310922145843506,
            3.0739903450012207,
            -3.495306968688965,
            2.5537166595458984,
            1.5561013221740723,
            -2.0450916290283203,
            1.088134527206421,
            -3.1127970218658447,
            -0.6141222715377808,
            -0.33281999826431274,
            3.713308572769165,
            1.5589702129364014,
            0.5225027203559875,
            1.009749412536621,
            4.796006202697754,
            2.5019428730010986,
            0.2367948740720749,
            -0.6293962001800537,
            5.58322811126709,
            2.958580255508423,
            -3.843806743621826,
            -0.2689993381500244,
            3.1533660888671875,
            0.05469009280204773,
            4.819074630737305,
            -5.95871114730835,
            0.573256254196167,
            -0.8995250463485718,
            -0.8836259245872498,
            -0.19587069749832153,
            -0.2715158462524414,
            -8.554200172424316,
            1.1033737659454346,
            4.094563007354736,
            -4.789461612701416,
            -3.0052883625030518,
            0.18817707896232605,
            0.7123763561248779,
            2.122607946395874,
            -0.42143669724464417,
            2.7902350425720215,
            3.7562079429626465,
            1.7014925479888916,
            7.37354850769043,
            4.3498029708862305,
            3.603853702545166,
            -1.9074727296829224,
            1.7255661487579346,
            -0.8069625496864319,
            -1.0735793113708496,
            1.4626363515853882,
            -3.3188860416412354,
            0.4855557680130005,
            -3.7324233055114746,
            -0.4452727735042572,
            -4.3799943923950195,
            -3.5384461879730225,
            -5.03905725479126,
            1.6827479600906372,
            1.5228530168533325,
            -0.026809077709913254,
            3.1890337467193604,
            3.8758022785186768,
            1.6534959077835083,
            1.804593801498413,
            2.0177414417266846,
            2.3266565799713135,
            -2.725318431854248,
            1.4876885414123535,
            2.451794385910034,
            0.6254487037658691,
            -1.972998023033142,
            -3.486612558364868,
            0.6092050671577454,
            0.7413884401321411,
            -1.34773588180542,
            2.4032468795776367,
            0.18297746777534485,
            -0.32833918929100037,
            -2.016463041305542,
            -1.918833613395691,
            -2.1927497386932373,
            -1.398636817932129,
            -3.922562599182129,
            -6.266804218292236,
            -5.524472236633301,
            0.7263665199279785,
            4.478888988494873,
            2.024096965789795,
            1.2532031536102295,
            2.09820294380188,
            -2.110649347305298,
            -3.3664462566375732,
            0.4114868640899658,
            -1.623088002204895,
            2.686333417892456,
            -0.47541341185569763,
            0.6327864527702332,
            -0.423944890499115,
            -1.9873051643371582,
            -7.238202095031738,
            -2.0975358486175537,
            -2.629833221435547,
            -3.1109507083892822,
            -1.075048565864563,
            -2.4703197479248047,
            -0.07634492218494415,
            -3.029348850250244,
            -0.36800289154052734,
            5.476816654205322,
            1.6827800273895264,
            -2.581040859222412,
            4.870802402496338,
            2.813663959503174,
            -2.226069688796997,
            -2.371739387512207,
            0.1785699874162674,
            1.6369069814682007,
            -3.455472230911255,
            0.21776899695396423,
            -2.942004442214966,
            4.134240627288818,
            -2.2941818237304688,
            2.2657463550567627,
            2.3211233615875244,
            0.07408146560192108,
            -3.317518711090088,
            0.7487435936927795,
            1.7560150623321533,
            -3.6479201316833496,
            3.879885196685791,
            2.305982828140259,
            4.102077484130859,
            -1.9364032745361328,
            -1.2222944498062134,
            -3.185856819152832,
            -3.551286458969116,
            0.729828417301178,
            0.8651437759399414,
            -0.47413167357444763,
            1.0851261615753174,
            -1.3479821681976318,
            -1.3503119945526123,
            0.305979460477829,
            -3.9828197956085205,
            -0.3188847005367279,
            -0.9567780494689941,
            0.6027445793151855,
            4.130564212799072,
            3.2278690338134766,
            -6.064319133758545,
            -4.135260105133057,
            -1.584160566329956,
            -1.2383029460906982,
            -2.6348721981048584,
            -1.310863733291626,
            -0.7563838958740234,
            -2.413254499435425,
            -0.4769923686981201,
            -6.7753777503967285,
            5.341213703155518,
            -4.1655073165893555,
            -3.5435791015625,
            -3.42927622795105,
            3.76785945892334,
            4.987551212310791,
            -0.09829290211200714,
            -0.18208160996437073,
            -0.5241968631744385,
            -0.5775362849235535,
            -0.5046007633209229,
            2.002824306488037,
            2.6040308475494385,
            3.060206651687622,
            1.7338787317276,
            1.3534592390060425,
            -2.6047353744506836,
            -0.8952033519744873,
            -5.756272315979004,
            0.3778194487094879,
            1.2975517511367798,
            1.9477559328079224,
            -1.980629324913025,
            1.6764460802078247,
            -0.48061618208885193,
            2.501502513885498,
            1.317745566368103,
            -2.4915502071380615,
            1.8588436841964722,
            0.8313027620315552,
            -1.2577606439590454,
            -1.5241351127624512,
            -3.0919244289398193,
            -1.8521664142608643,
            -4.023190975189209,
            1.2382347583770752,
            1.7357302904129028,
            -4.63149881362915,
            3.7216956615448,
            -0.07315748929977417,
            3.106689929962158,
            2.7294387817382812,
            0.3312126100063324,
            -1.2312092781066895,
            -5.551464080810547,
            1.8298321962356567,
            -0.6221075654029846,
            -1.0919257402420044,
            1.5684843063354492,
            -1.7063697576522827,
            6.72125244140625,
            0.07008279860019684,
            3.62646746635437,
            -2.883371591567993,
            0.4933319091796875,
            2.874715566635132,
            -1.041899561882019,
            1.1488912105560303,
            0.3983590006828308,
            -1.0839210748672485,
            -0.5023345351219177,
            1.9464502334594727,
            -3.240234613418579,
            1.875998616218567,
            4.01268196105957,
            1.6296560764312744,
            0.021172530949115753,
            1.961572527885437,
            2.93837833404541,
            0.4413614869117737,
            0.7024626731872559,
            -0.7367182374000549,
            -2.467038154602051,
            -0.33090800046920776,
            -3.0419304370880127,
            11.461952209472656,
            -1.753248929977417,
            -0.24647903442382812,
            -4.591674327850342,
            -3.058671712875366,
            -0.21413202583789825,
            -2.0753426551818848,
            2.709616184234619,
            -0.5781476497650146,
            -2.619276285171509,
            2.2768588066101074,
            -1.7900794744491577,
            -1.3788259029388428,
            -2.1775455474853516,
            1.4158977270126343,
            3.128082275390625,
            -0.12330839037895203,
            3.631138324737549,
            1.3230044841766357,
            -0.2801700234413147,
            1.6871447563171387,
            0.0148476492613554,
            4.3765153884887695,
            -0.6250625848770142,
            -1.8914533853530884,
            0.6972987651824951,
            1.2837467193603516,
            3.710050106048584,
            -3.5169224739074707,
            -1.7018985748291016,
            -5.505459785461426,
            -6.535000801086426,
            0.7301016449928284,
            0.41106894612312317,
            -2.26629376411438,
            -0.7196771502494812,
            4.813668251037598,
            6.6151041984558105,
            -1.702216386795044,
            -1.1140718460083008,
            6.234483242034912,
            1.2877247333526611,
            -1.2874760627746582,
            -0.977645218372345,
            -4.279787063598633,
            1.338676929473877,
            -1.0887079238891602,
            -3.0948212146759033,
            1.1987719535827637,
            -2.8293118476867676,
            3.460491895675659,
            2.2107412815093994,
            3.796926975250244,
            1.7992291450500488,
            -1.9794172048568726,
            1.4108970165252686,
            6.350718975067139,
            2.9515373706817627,
            -2.312178134918213,
            -1.7357923984527588,
            1.3570890426635742,
            1.6947021484375,
            -0.07950747013092041,
            1.9811832904815674,
            -3.4044926166534424,
            3.928081750869751,
            -3.676344871520996,
            0.9907324314117432,
            1.3022772073745728,
            2.6676242351531982,
            -1.0444303750991821,
            1.099399447441101,
            0.027245551347732544,
            0.9294355511665344,
            0.2663033604621887,
            3.046809434890747,
            -1.1859080791473389,
            1.3424490690231323,
            3.046380043029785,
            0.9697980284690857,
            2.969093084335327,
            1.684733510017395,
            -0.6629489660263062,
            -2.2427024841308594,
            1.5494678020477295,
            -4.495710849761963,
            0.06841728091239929,
            -0.5675076842308044,
            0.2634998559951782,
            -2.0301403999328613,
            -2.3739895820617676,
            -3.453817129135132,
            -0.5729570388793945,
            3.1496384143829346,
            -3.269602060317993,
            2.2552716732025146,
            -2.1464364528656006,
            2.54451322555542,
            1.9602819681167603,
            2.8809022903442383,
            0.961309015750885,
            -2.7796168327331543,
            -3.2149765491485596,
            1.805909514427185,
            2.085691452026367,
            -2.0063910484313965,
            -0.575798511505127,
            -2.179452896118164,
            -1.036797046661377,
            -2.3335378170013428,
            4.610661506652832,
            2.5824062824249268,
            2.156437635421753,
            -4.305720329284668,
            -4.9520158767700195,
            -1.7356579303741455,
            2.971910238265991,
            1.0421216487884521,
            -0.1672128289937973,
            4.826646327972412,
            3.6496376991271973,
            2.890615701675415,
            2.8067588806152344,
            1.1521117687225342,
            0.8866740465164185,
            1.4130253791809082,
            5.725651264190674,
            -6.083548545837402,
            4.858339309692383,
            1.3529640436172485,
            -2.431190252304077,
            1.3607059717178345,
            5.061720848083496,
            -0.49891573190689087,
            -0.7262533903121948,
            -4.044143199920654,
            -1.6974470615386963,
            -2.0703465938568115,
            -2.833116292953491,
            1.2285072803497314,
            3.2237141132354736,
            0.10794512927532196,
            1.4521313905715942,
            0.17735764384269714,
            1.1832940578460693,
            4.155035495758057,
            -6.018965244293213,
            1.3541010618209839,
            -0.9450005292892456,
            3.715541362762451,
            1.3174968957901,
            0.3395681083202362,
            3.066988468170166,
            1.9762407541275024,
            -0.8908847570419312,
            1.2644457817077637,
            -1.3347431421279907,
            0.9462156891822815,
            1.1126325130462646,
            3.3256447315216064,
            -4.23477029800415,
            4.4421515464782715,
            1.4566740989685059,
            5.1026506423950195,
            6.317197799682617,
            5.324008941650391,
            2.299943685531616,
            0.042527761310338974,
            -0.6641432642936707,
            -2.771069288253784,
            2.0896644592285156,
            2.6297991275787354,
            -5.4813714027404785,
            -0.8357429504394531,
            0.662354588508606,
            0.23567762970924377,
            -3.1649651527404785,
            1.9278455972671509,
            -4.536256790161133,
            3.1752355098724365,
            -1.4468775987625122,
            1.7022629976272583,
            -2.2693941593170166,
            1.951454758644104,
            1.6175016164779663,
            -0.9858613014221191,
            2.0482308864593506,
            -4.5842742919921875,
            -3.2150468826293945,
            -1.7196050882339478,
            -2.1695940494537354,
            -1.4205865859985352,
            0.3491028845310211,
            7.4928879737854,
            0.16988705098628998,
            1.8974967002868652,
            0.359916090965271,
            4.362329006195068,
            -3.9670114517211914,
            -1.5265419483184814,
            -1.1127270460128784,
            3.452256917953491,
            -0.4589143991470337,
            -0.2287502884864807,
            1.8009071350097656,
            -2.462904214859009,
            1.0447336435317993,
            1.3486906290054321,
            0.9948214292526245,
            0.6352105736732483,
            3.369760274887085,
            2.6269309520721436,
            -1.0221654176712036,
            -1.1563938856124878,
            -2.165102005004883,
            -4.582468509674072,
            -3.684403896331787,
            -6.682225704193115,
            0.9360581040382385,
            -3.970360517501831,
            -5.223807334899902,
            2.395296573638916,
            -1.3360440731048584,
            -0.14026471972465515,
            -1.4534785747528076,
            -1.8231688737869263,
            0.7888302803039551,
            -2.635643243789673,
            -1.624742031097412,
            -1.673172116279602,
            2.9347946643829346,
            -1.9899859428405762,
            -0.5344637036323547,
            2.83418345451355,
            2.1544835567474365,
            5.144221305847168,
            2.0318920612335205,
            1.5906590223312378,
            -1.8048763275146484,
            0.6693529486656189,
            1.9614773988723755,
            1.9850986003875732,
            2.314542531967163,
            1.7056195735931396,
            0.8041958212852478,
            2.3850927352905273,
            15.48430347442627,
            -1.1424213647842407,
            1.226773738861084,
            -1.0082186460494995,
            0.5948354005813599,
            -3.9533498287200928,
            -4.2170209884643555,
            2.500624179840088,
            2.847595691680908,
            2.343010663986206,
            -1.959045171737671,
            -4.568114280700684,
            1.378484845161438,
            0.28391164541244507,
            -1.552166223526001,
            -1.6089714765548706,
            -2.4261040687561035,
            1.0516154766082764,
            -1.6735360622406006,
            -0.2698920965194702,
            1.124523639678955,
            1.577336072921753,
            -1.2539606094360352,
            0.9693151712417603,
            -2.7765026092529297,
            4.622997760772705,
            -0.0173272043466568,
            3.9369027614593506,
            -0.7642420530319214,
            -0.12867173552513123,
            2.0879294872283936,
            3.104074716567993,
            -2.2433643341064453,
            2.1238222122192383,
            -4.103794097900391,
            8.09703540802002,
            2.0353879928588867,
            -0.9980100393295288,
            2.9738619327545166,
            1.702158808708191,
            -2.498213052749634,
            -1.031179666519165,
            -2.085447072982788,
            -1.9457403421401978,
            1.6408666372299194,
            2.278747081756592,
            2.262436628341675,
            -1.7455796003341675,
            -2.721299171447754,
            2.371440887451172,
            0.9225292205810547,
            -1.7980718612670898,
            0.5144760012626648,
            2.035327434539795,
            -1.509379506111145,
            3.816437005996704,
            0.3660159409046173,
            -0.47142529487609863,
            2.509732484817505,
            3.0853843688964844,
            0.11662226170301437,
            2.4380173683166504,
            -2.6417698860168457,
            -2.397627830505371,
            -2.016998291015625,
            3.6661858558654785,
            -4.674332618713379,
            2.778832197189331,
            2.6662259101867676,
            3.041426420211792,
            2.140536069869995,
            1.2594109773635864,
            -0.10815063118934631,
            -4.035037517547607,
            -2.1733624935150146,
            -4.782476425170898,
            -0.26774778962135315,
            -2.5765185356140137,
            -1.824276328086853,
            4.494386672973633,
            -5.924367427825928,
            -0.12002266943454742,
            0.18600350618362427,
            -1.545324683189392,
            5.505965709686279,
            -5.591641426086426,
            7.113638877868652,
            1.747572422027588,
            -0.9577716588973999,
            2.864973545074463,
            -3.1050362586975098,
            -2.055753469467163,
            1.4384807348251343,
            4.705931186676025,
            3.2281911373138428,
            -1.233103632926941,
            -0.44938191771507263,
            -2.6028008460998535,
            -1.9395568370819092,
            -5.467808246612549,
            3.560631513595581,
            5.7006330490112305,
            -0.47384732961654663,
            0.5508561730384827,
            -1.950973629951477,
            0.7128426432609558,
            -1.5999988317489624,
            -5.584996700286865,
            -3.215664863586426,
            -4.681767463684082,
            1.2540520429611206,
            -5.348531723022461,
            -1.6950526237487793,
            -3.7352817058563232,
            0.11314709484577179,
            1.5471121072769165,
            -1.1751384735107422,
            1.8589801788330078,
            3.047020673751831,
            2.3294925689697266,
            0.034993961453437805,
            0.11753144860267639,
            -2.7633063793182373,
            -1.8351879119873047,
            -1.8948720693588257,
            0.07642914354801178,
            0.1735033392906189,
            -0.8916730284690857,
            2.3584935665130615,
            0.5361630916595459,
            1.0978856086730957,
            -2.460479974746704,
            -4.578826427459717,
            -0.7721487283706665,
            -2.2183315753936768,
            -3.7484841346740723,
            -1.0790420770645142,
            0.8411635160446167,
            -4.221681118011475,
            2.084496021270752,
            5.125533580780029,
            -1.6264114379882812,
            -2.3607003688812256,
            9.363945007324219,
            -0.8637322187423706,
            1.2416108846664429,
            -0.5231541991233826,
            -1.3815943002700806,
            -1.1768730878829956,
            -0.8830824494361877,
            -1.334852933883667,
            -1.8711875677108765,
            4.32687520980835,
            -1.3819912672042847,
            0.9919127225875854,
            -1.8697229623794556
        ]
    },
    "authors": [
        {
            "authorId": "2109586102",
            "name": "Sehoon Kim"
        },
        {
            "authorId": "2191455",
            "name": "Sheng Shen"
        },
        {
            "authorId": "2214478",
            "name": "D. Thorsley"
        },
        {
            "authorId": "10419477",
            "name": "A. Gholami"
        },
        {
            "authorId": "1491321888",
            "name": "Joseph Hassoun"
        },
        {
            "authorId": "1732330",
            "name": "K. Keutzer"
        }
    ],
    "references": [
        {
            "paperId": "01b1293ddea9bcd6df1185b0b934503de01d6561",
            "title": "Block Pruning For Faster Transformers"
        },
        {
            "paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd",
            "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"
        },
        {
            "paperId": "6da4b231148bf26677233d1f778d08a5d26f4313",
            "title": "TR-BERT: Dynamic Token Reduction for Accelerating BERT Inference"
        },
        {
            "paperId": "04e283adccf66742130bde4a4dedcda8f549dd7e",
            "title": "A Survey of Quantization Methods for Efficient Neural Network Inference"
        },
        {
            "paperId": "de983239063bf87fafc549e651ea133088b1831f",
            "title": "Hessian-Aware Pruning and Optimal Neural Implant"
        },
        {
            "paperId": "7b8f3f65a98340d6e5ab94bd9a4ccb8f75704fd8",
            "title": "I-BERT: Integer-only BERT Quantization"
        },
        {
            "paperId": "c375e121926db9551f224ff235018ea38bb159b7",
            "title": "BinaryBERT: Pushing the Limit of BERT Quantization"
        },
        {
            "paperId": "73e0f38ab49b19b86321016b773e15f1d02e3a72",
            "title": "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning"
        },
        {
            "paperId": "a50d31c082521817a1e74cae584963a63163ca70",
            "title": "Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime with Search"
        },
        {
            "paperId": "8fa19377b9cd6d2e9292522774c3a13108cd2ff5",
            "title": "Pruning Redundant Mappings in Transformer Models via Spectral-Normalized Identity Prior"
        },
        {
            "paperId": "097210dc65924f8ce59523faf444e635523dc714",
            "title": "TernaryBERT: Distillation-aware Ultra-low Bit BERT"
        },
        {
            "paperId": "48745e3485f84cc5a2dab8e1ce41de0a38afb490",
            "title": "Efficient Transformer-based Large Scale Language Representations using Hardware-friendly Block Structured Pruning"
        },
        {
            "paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3",
            "title": "Big Bird: Transformers for Longer Sequences"
        },
        {
            "paperId": "389036b1366b64579725457993c1f63a4f3370ba",
            "title": "The Lottery Ticket Hypothesis for Pre-trained BERT Networks"
        },
        {
            "paperId": "cd4ffe5e014601a3d6b64121355d29a730591490",
            "title": "Fast Transformers with Clustered Attention"
        },
        {
            "paperId": "6f68e1bb253925d8431588555d3010419f322e04",
            "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"
        },
        {
            "paperId": "eb1602ecba96beadeb7d2f05e1b57fa6b339fc69",
            "title": "SqueezeBERT: What can computer vision teach NLP about efficient neural networks?"
        },
        {
            "paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
            "title": "Linformer: Self-Attention with Linear Complexity"
        },
        {
            "paperId": "66f0f35fc78bdf2af9de46093d49a428970cde2e",
            "title": "Movement Pruning: Adaptive Sparsity by Fine-Tuning"
        },
        {
            "paperId": "946a43eb327c5ee2087187720f15c46b2985cb1c",
            "title": "Bayesian Bits: Unifying Quantization and Pruning"
        },
        {
            "paperId": "a81674f480dba239e12c80910528cae5d3a28e97",
            "title": "schuBERT: Optimizing Elements of BERT"
        },
        {
            "paperId": "1b0c8b26affd13e10ace5770e85478d60dcc368e",
            "title": "GOBO: Quantizing Attention-Based NLP Models for Low Latency and Energy Efficient Inference"
        },
        {
            "paperId": "91ac65431b2dc46919e1673fde67671c29446812",
            "title": "When BERT Plays the Lottery, All Tickets Are Winning"
        },
        {
            "paperId": "7fb301ea25f02dc7f4f7ee1360137503ee942c8c",
            "title": "Masking as an Efficient Alternative to Finetuning for Pretrained Language Models"
        },
        {
            "paperId": "0171ad4cc87cc7db25b4ec3169e293eed9a13b39",
            "title": "Training with Quantization Noise for Extreme Model Compression"
        },
        {
            "paperId": "39f8cc684f09ea2b43767f5b9590896774802759",
            "title": "On the effect of dropping layers of pre-trained transformer models"
        },
        {
            "paperId": "2b9955bc08fc5f4ddba73082ddabcfaabdbb4416",
            "title": "Poor Man's BERT: Smaller and Faster Transformer Models"
        },
        {
            "paperId": "2573af4e13d9a5dddb257d22cd38a600528d9a8b",
            "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"
        },
        {
            "paperId": "1c332cfa211400fc6f56983fb01a6692046116dd",
            "title": "DynaBERT: Dynamic BERT with Adaptive Width and Depth"
        },
        {
            "paperId": "657329c633709dd1ac34a30d57341b186b1a47c2",
            "title": "Efficient Content-Based Sparse Attention with Routing Transformers"
        },
        {
            "paperId": "34a4e6818d680875ff0bef9a76de0376118446d1",
            "title": "Sparse Sinkhorn Attention"
        },
        {
            "paperId": "43f2ad297941db230c089ba353efc3f281ab678c",
            "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": "5a6d6640e34e8328a3627200bca9a3d3972a2247",
            "title": "Lookahead: a Far-Sighted Alternative of Magnitude-based Pruning"
        },
        {
            "paperId": "94f94e8892261d0377159379ca5a166ceae19a14",
            "title": "PoWER-BERT: Accelerating BERT Inference via Progressive Word-vector Elimination"
        },
        {
            "paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500",
            "title": "Reformer: The Efficient Transformer"
        },
        {
            "paperId": "ce106590145e89ea4b621c99665862967ccf5dac",
            "title": "Q8BERT: Quantized 8Bit BERT"
        },
        {
            "paperId": "83b8108014e3db4f46354a28ae68193f143c4e7e",
            "title": "Structured Pruning of Large Language Models"
        },
        {
            "paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc",
            "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"
        },
        {
            "paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b",
            "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"
        },
        {
            "paperId": "f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1",
            "title": "Reducing Transformer Depth on Demand with Structured Dropout"
        },
        {
            "paperId": "0cbf97173391b0430140117027edcaf1a37968c7",
            "title": "TinyBERT: Distilling BERT for Natural Language Understanding"
        },
        {
            "paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d",
            "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"
        },
        {
            "paperId": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf",
            "title": "Patient Knowledge Distillation for BERT Model Compression"
        },
        {
            "paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de",
            "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"
        },
        {
            "paperId": "387e0b95d56e9ecec60a1037ddf7cc57b2851835",
            "title": "Playing the lottery with rewards and multiple languages: lottery tickets in RL and NLP"
        },
        {
            "paperId": "3366e9eb81880d172752d4397cb8e9e6de02b935",
            "title": "Efficient 8-Bit Quantization of Transformer Neural Machine Language Translation Model"
        },
        {
            "paperId": "b39eec4d962bb1cae0156af6d7f34c1b6302dc51",
            "title": "Variational Convolutional Neural Network Pruning"
        },
        {
            "paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583",
            "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"
        },
        {
            "paperId": "b03c7ff961822183bab66b2e594415e585d3fd09",
            "title": "Are Sixteen Heads Really Better than One?"
        },
        {
            "paperId": "21da617a0f79aabf94272107184606cefe90ab75",
            "title": "Generating Long Sequences with Sparse Transformers"
        },
        {
            "paperId": "a08293b2c9c5bcddb023cc7eb3354d4d86bfae89",
            "title": "Distilling Task-Specific Knowledge from BERT into Simple Neural Networks"
        },
        {
            "paperId": "dc160709bbe528b506a37ead334f60d258413357",
            "title": "Learned Step Size Quantization"
        },
        {
            "paperId": "0c325138b1ecb7a8ccbd5d6741780dea9461e7ae",
            "title": "Efficient and Effective Sparse LSTM on FPGA with Bank-Balanced Sparsity"
        },
        {
            "paperId": "cf440ccce4a7a8681e238b4f26d5b95109add55d",
            "title": "SNIP: Single-shot Network Pruning based on Connection Sensitivity"
        },
        {
            "paperId": "e8262c9a0a63c765fd0529a6429f3b92cb7ad1b0",
            "title": "Accelerating Convolutional Networks via Global & Dynamic Filter Pruning"
        },
        {
            "paperId": "4d1c856275744c0284312a3a50efb6ca9dc4cd4c",
            "title": "Know What You Don\u2019t Know: Unanswerable Questions for SQuAD"
        },
        {
            "paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"
        },
        {
            "paperId": "21937ecd9d66567184b83eca3d3e09eb4e6fbd60",
            "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"
        },
        {
            "paperId": "1717255b6aea01fe956cef998abbc3c399b5d7cf",
            "title": "AMC: AutoML for Model Compression and Acceleration on Mobile Devices"
        },
        {
            "paperId": "af03709f0893a7ff1c2656b73249d60030bab996",
            "title": "NISP: Pruning Networks Using Neuron Importance Score Propagation"
        },
        {
            "paperId": "56257b0804c9c2418b32337d3af0970f7b67b084",
            "title": "Block-Sparse Recurrent Neural Networks"
        },
        {
            "paperId": "ca1060c50642f9f05735d3007873439347b3bea5",
            "title": "Learning Intrinsic Sparse Structures within Long Short-term Memory"
        },
        {
            "paperId": "a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096",
            "title": "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation"
        },
        {
            "paperId": "2adb616a77fe28b49be2a2d66cccf2d7400e4a04",
            "title": "Data-Driven Sparse Structure Selection for Deep Neural Networks"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "773d5ddc414424a8948446ddaa5275b944f50891",
            "title": "Learning to Prune Deep Neural Networks via Layer-wise Optimal Brain Surgeon"
        },
        {
            "paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e",
            "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"
        },
        {
            "paperId": "05dd7254b632376973f3a1b4d39485da17814df5",
            "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"
        },
        {
            "paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19",
            "title": "Distilling the Knowledge in a Neural Network"
        },
        {
            "paperId": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
        },
        {
            "paperId": "62c76ca0b2790c34e85ba1cce09d47be317c7235",
            "title": "Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "cbde5598c1a78285adfcfd77fb3636f5498987a0",
            "title": "EBERT: Efficient BERT Inference with Dynamic Structured Pruning"
        },
        {
            "paperId": "a74b9cc3b08d2a088d6f0b0c037188ccfd1ceaf4",
            "title": "MLPruning: A Multilevel Structured Pruning Framework for Transformer-based Models"
        },
        {
            "paperId": "ff77078964bcce683e1583d939148881dfa7e1ba",
            "title": "AutoPrune: Automatic Network Pruning by Regularizing Auxiliary Parameters"
        },
        {
            "paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": null,
            "title": "First Quora Dataset Release: Question Pairs"
        },
        {
            "paperId": "475354f10798f110d34792b6d88f31d6d5cb099e",
            "title": "Automatically Constructing a Corpus of Sentential Paraphrases"
        },
        {
            "paperId": "e808f28d411a958c5db81ceb111beb2638698f47",
            "title": "The PASCAL Recognising Textual Entailment Challenge"
        },
        {
            "paperId": null,
            "title": "KDD \u201922, August 14\u201318, 2022, Washington, DC, USA"
        }
    ]
}