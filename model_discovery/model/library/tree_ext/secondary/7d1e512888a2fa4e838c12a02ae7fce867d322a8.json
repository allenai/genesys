{
    "paperId": "7d1e512888a2fa4e838c12a02ae7fce867d322a8",
    "externalIds": {
        "DBLP": "conf/icml/RajbhandariLYZA22",
        "ArXiv": "2201.05596",
        "CorpusId": 245986500
    },
    "title": "DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale",
    "abstract": "As the training of giant dense models hits the boundary on the availability and capability of the hardware resources today, Mixture-of-Experts (MoE) models become one of the most promising model architectures due to their significant training cost reduction compared to a quality-equivalent dense model. Its training cost saving is demonstrated from encoder-decoder models (prior works) to a 5x saving for auto-aggressive language models (this work along with parallel explorations). However, due to the much larger model size and unique architecture, how to provide fast MoE model inference remains challenging and unsolved, limiting its practical usage. To tackle this, we present DeepSpeed-MoE, an end-to-end MoE training and inference solution as part of the DeepSpeed library, including novel MoE architecture designs and model compression techniques that reduce MoE model size by up to 3.7x, and a highly optimized inference system that provides 7.3x better latency and cost compared to existing MoE inference solutions. DeepSpeed-MoE offers an unprecedented scale and efficiency to serve massive MoE models with up to 4.5x faster and 9x cheaper inference compared to quality-equivalent dense models. We hope our innovations and systems help open a promising path to new directions in the large model landscape, a shift from dense to sparse MoE models, where training and deploying higher-quality models with fewer resources becomes more widely possible.",
    "venue": "International Conference on Machine Learning",
    "year": 2022,
    "referenceCount": 53,
    "citationCount": 193,
    "influentialCitationCount": 22,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "DeepSpeed-MoE is presented, an end-to-end MoE training and inference solution as part of the DeepSpeed library, including novel MoE architecture designs and model compression techniques that reduce MoE model size by up to 3.7x, and a highly optimized inference system that provides 7.3x better latency and cost compared to existing MoE inference solutions."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -3.502579689025879,
            -0.3135683536529541,
            0.3685500919818878,
            5.4244704246521,
            -1.7018628120422363,
            3.6258773803710938,
            2.196251153945923,
            -1.486770510673523,
            -0.3207775950431824,
            -0.7588803172111511,
            -2.58744478225708,
            5.02760124206543,
            0.581973671913147,
            1.2927550077438354,
            -2.4163308143615723,
            0.8192803859710693,
            -3.3434667587280273,
            1.615047812461853,
            7.716409683227539,
            1.5418968200683594,
            -5.389889717102051,
            2.0332071781158447,
            -1.9059643745422363,
            0.337704062461853,
            -1.7356350421905518,
            -1.5911318063735962,
            1.9049181938171387,
            1.191107988357544,
            -1.5873082876205444,
            1.2061407566070557,
            2.7363781929016113,
            -4.782921314239502,
            2.8254504203796387,
            -5.378263473510742,
            1.1944396495819092,
            -1.0173935890197754,
            -1.821777582168579,
            9.493170738220215,
            -3.13036847114563,
            0.8288522958755493,
            0.38671717047691345,
            2.181995153427124,
            4.368763446807861,
            -3.232456684112549,
            0.42436838150024414,
            -0.8885053396224976,
            2.3140101432800293,
            0.0006362199783325195,
            2.089130401611328,
            -0.18256819248199463,
            -2.02909517288208,
            2.6950721740722656,
            1.2803157567977905,
            1.1671521663665771,
            -2.774880886077881,
            0.6421276926994324,
            -1.8061527013778687,
            1.5441679954528809,
            3.1424832344055176,
            -0.2020871341228485,
            2.4229698181152344,
            5.228156566619873,
            1.8691564798355103,
            1.0596665143966675,
            2.0237936973571777,
            -2.950047254562378,
            0.05549272894859314,
            6.791001319885254,
            1.562074899673462,
            4.78810977935791,
            -2.8985936641693115,
            -2.8529155254364014,
            2.6646728515625,
            0.368927925825119,
            -5.325128078460693,
            1.230605959892273,
            -1.3428248167037964,
            -4.108532428741455,
            -0.8649107217788696,
            -1.8769457340240479,
            0.8149699568748474,
            4.294287204742432,
            -0.3905627131462097,
            5.213078022003174,
            5.59571647644043,
            -0.5636100769042969,
            -5.410409450531006,
            -1.3773285150527954,
            0.802458643913269,
            -3.3606691360473633,
            1.8004366159439087,
            -1.3462918996810913,
            -1.5969419479370117,
            0.7041822671890259,
            -5.6307220458984375,
            -0.869411289691925,
            0.14655619859695435,
            -0.8599118590354919,
            1.0414470434188843,
            1.9357500076293945,
            3.524224281311035,
            1.4404724836349487,
            3.5768890380859375,
            -1.6627612113952637,
            5.630638122558594,
            -0.718338668346405,
            2.37691593170166,
            0.5244996547698975,
            2.6373865604400635,
            -3.124990463256836,
            -4.4242167472839355,
            3.064021110534668,
            -0.7179471254348755,
            -2.884716272354126,
            -5.320802688598633,
            -2.473107099533081,
            -1.7011560201644897,
            -0.2894447147846222,
            -2.2289340496063232,
            1.6218111515045166,
            1.9186160564422607,
            -2.6479134559631348,
            -2.7372679710388184,
            -0.39611563086509705,
            2.917893171310425,
            1.7347567081451416,
            -2.7477035522460938,
            1.667004942893982,
            0.4873110055923462,
            -3.81040096282959,
            0.37377268075942993,
            -3.6973471641540527,
            1.7124278545379639,
            -1.2969180345535278,
            1.603627324104309,
            3.7657415866851807,
            -6.608523368835449,
            0.4956652522087097,
            -5.012296676635742,
            -0.2245408296585083,
            0.48571258783340454,
            3.819492816925049,
            0.6449407935142517,
            1.7512562274932861,
            1.9908326864242554,
            4.813505172729492,
            2.028001308441162,
            -0.7640990018844604,
            1.495713710784912,
            6.622793197631836,
            5.051018238067627,
            -6.824380874633789,
            2.676522731781006,
            1.311907410621643,
            1.13130784034729,
            3.3359155654907227,
            -6.382400989532471,
            0.9894537925720215,
            -2.6562728881835938,
            -1.685941219329834,
            2.4050862789154053,
            1.2218430042266846,
            -11.03765869140625,
            -0.34765973687171936,
            2.7692270278930664,
            -3.413092613220215,
            -1.8451550006866455,
            1.3839747905731201,
            -3.3517401218414307,
            3.5833611488342285,
            1.340600848197937,
            2.6667070388793945,
            3.6954360008239746,
            6.068600654602051,
            6.289228916168213,
            4.234138488769531,
            0.38502389192581177,
            -0.6213155388832092,
            2.8800830841064453,
            0.16550758481025696,
            -0.42204225063323975,
            -4.233484745025635,
            -6.146332263946533,
            5.372029781341553,
            -1.534225583076477,
            -1.9663397073745728,
            -5.712043285369873,
            -2.6726479530334473,
            -0.6414614319801331,
            1.6474134922027588,
            -2.68660569190979,
            0.6623225808143616,
            4.865797519683838,
            4.350132465362549,
            4.092737674713135,
            -1.5717177391052246,
            0.6691365242004395,
            2.523639678955078,
            -4.109095573425293,
            0.2232702374458313,
            3.7504122257232666,
            1.0938875675201416,
            -2.025723457336426,
            -2.3511173725128174,
            4.7301716804504395,
            3.197936534881592,
            -2.352090835571289,
            2.7420918941497803,
            -2.094784736633301,
            4.3581929206848145,
            -0.8744707107543945,
            -0.6857046484947205,
            0.08892613649368286,
            1.851957082748413,
            -3.624176502227783,
            -0.7799025774002075,
            -5.8992919921875,
            6.6927690505981445,
            8.59471321105957,
            1.0246646404266357,
            -0.9722636342048645,
            1.0616178512573242,
            -0.18553364276885986,
            -1.4538452625274658,
            0.5649335980415344,
            -5.4886393547058105,
            3.6629960536956787,
            -0.3846985101699829,
            2.1738882064819336,
            -0.8178479671478271,
            -3.1612303256988525,
            -6.903210639953613,
            2.228327989578247,
            -0.8695737719535828,
            -7.158555030822754,
            -0.5802698135375977,
            -5.401376247406006,
            2.741152286529541,
            -0.6571568250656128,
            -0.1636359691619873,
            6.369781970977783,
            -0.23094728589057922,
            2.5990426540374756,
            2.5388591289520264,
            4.57148551940918,
            -3.3019726276397705,
            -2.1724441051483154,
            0.6353275775909424,
            -0.6880730390548706,
            -1.6874892711639404,
            -2.5465245246887207,
            -2.428112268447876,
            4.258448600769043,
            -1.9875739812850952,
            3.246950626373291,
            3.0197551250457764,
            -0.7409677505493164,
            -2.249847650527954,
            0.7287477254867554,
            -1.0936102867126465,
            0.4569856524467468,
            5.713151931762695,
            4.2519097328186035,
            5.303287982940674,
            -4.158538818359375,
            -0.7923376560211182,
            -4.658877372741699,
            -2.957818031311035,
            -3.877032518386841,
            3.6353113651275635,
            2.5413129329681396,
            0.6236372590065002,
            -2.771697521209717,
            -4.4465861320495605,
            -0.5490880012512207,
            -7.550076484680176,
            -2.0709142684936523,
            1.2840611934661865,
            0.10010525584220886,
            3.765167713165283,
            2.4136033058166504,
            -3.2099668979644775,
            -1.0346994400024414,
            -1.7701365947723389,
            1.4983398914337158,
            -2.027085542678833,
            -2.2230100631713867,
            2.6946816444396973,
            -2.452634572982788,
            -3.2848904132843018,
            -4.027942657470703,
            3.545947790145874,
            -6.632217884063721,
            -1.3663413524627686,
            -4.006691932678223,
            6.062942981719971,
            5.29561185836792,
            -0.4580986499786377,
            -1.0568568706512451,
            -0.5981738567352295,
            0.41393089294433594,
            1.9709831476211548,
            3.0303866863250732,
            -0.8668517470359802,
            0.8667744398117065,
            4.576667785644531,
            2.0345523357391357,
            -3.551905632019043,
            -1.8971331119537354,
            -1.3006614446640015,
            -2.4842708110809326,
            -0.4855634272098541,
            1.148583173751831,
            -4.075660705566406,
            1.4721169471740723,
            1.948028802871704,
            1.0011671781539917,
            -0.953656792640686,
            -0.9759067296981812,
            4.16671085357666,
            -0.8952735662460327,
            0.8320177793502808,
            -6.515240669250488,
            -2.1995527744293213,
            -4.148867607116699,
            -2.0171732902526855,
            0.25560230016708374,
            3.404128074645996,
            -4.624750137329102,
            0.8763159513473511,
            1.110966682434082,
            4.690685749053955,
            4.844850540161133,
            2.8164093494415283,
            1.2726105451583862,
            -5.555920600891113,
            0.44041234254837036,
            -0.7511998414993286,
            2.575664520263672,
            -0.7677168846130371,
            -1.976007103919983,
            5.8211669921875,
            -1.231244444847107,
            0.9095391035079956,
            -0.5573554039001465,
            -1.6965610980987549,
            3.888841152191162,
            -3.391691207885742,
            -1.6164360046386719,
            -3.869412899017334,
            0.5692673325538635,
            1.9029847383499146,
            2.870892286300659,
            1.1221792697906494,
            1.615121603012085,
            4.3931498527526855,
            0.36742210388183594,
            1.8212039470672607,
            2.343090057373047,
            2.74607515335083,
            -1.039794683456421,
            -0.41486433148384094,
            1.9456597566604614,
            -0.5214341878890991,
            0.5932973027229309,
            -2.041790723800659,
            10.677358627319336,
            -2.103928327560425,
            0.3896999955177307,
            -3.921651840209961,
            1.6708298921585083,
            -4.76423454284668,
            -2.1610796451568604,
            1.3929697275161743,
            -1.2941138744354248,
            -2.256505012512207,
            2.946269989013672,
            -0.8793368339538574,
            0.30231553316116333,
            -0.3111264109611511,
            1.8671655654907227,
            5.2745795249938965,
            -1.6756691932678223,
            4.318357944488525,
            0.22541660070419312,
            -2.5945053100585938,
            -1.7533154487609863,
            4.418806076049805,
            1.0615074634552002,
            -1.6974899768829346,
            -2.9912285804748535,
            2.198138952255249,
            2.0401711463928223,
            4.420876502990723,
            -4.397740364074707,
            -3.5342297554016113,
            -3.8134758472442627,
            -4.5395002365112305,
            0.21000273525714874,
            0.24529194831848145,
            0.9311809539794922,
            -1.454552173614502,
            5.491044044494629,
            5.236973762512207,
            -4.553180694580078,
            -3.582151412963867,
            3.8058080673217773,
            0.5299139618873596,
            -1.299278974533081,
            -0.8344863057136536,
            -2.386345624923706,
            -2.194101333618164,
            -2.4299416542053223,
            -3.7308974266052246,
            -2.276416540145874,
            -0.4843113124370575,
            3.944993734359741,
            1.1690940856933594,
            2.2449686527252197,
            3.658503293991089,
            2.1563711166381836,
            1.152907371520996,
            2.532348871231079,
            4.780920028686523,
            0.21640890836715698,
            1.1900297403335571,
            2.095966100692749,
            0.34178048372268677,
            -3.281576156616211,
            4.6194376945495605,
            -3.0977001190185547,
            5.263064384460449,
            -1.8641847372055054,
            2.959892988204956,
            -1.8613375425338745,
            3.0847349166870117,
            0.9266178607940674,
            -0.23721182346343994,
            0.6281026601791382,
            -3.6782164573669434,
            1.5824882984161377,
            6.147960186004639,
            -3.9987549781799316,
            6.858052730560303,
            1.2436517477035522,
            2.137892723083496,
            -0.6733400821685791,
            2.025822877883911,
            -2.474374532699585,
            -1.3744463920593262,
            2.0411295890808105,
            -4.252532958984375,
            -4.401544570922852,
            -1.294808268547058,
            3.9934000968933105,
            1.0838863849639893,
            -3.732083320617676,
            -1.8614789247512817,
            1.0245435237884521,
            -1.3039486408233643,
            -2.9549481868743896,
            4.536616325378418,
            2.8407182693481445,
            3.681931257247925,
            0.5256791114807129,
            1.7876709699630737,
            -3.7155685424804688,
            -3.0067734718322754,
            0.011187851428985596,
            -0.07637453079223633,
            0.42283663153648376,
            -1.8836923837661743,
            -1.512013554573059,
            0.44750458002090454,
            -2.2829771041870117,
            0.4124767780303955,
            3.5535380840301514,
            2.622466802597046,
            -3.000246524810791,
            -4.090065002441406,
            -1.2767105102539062,
            -2.3432984352111816,
            2.473431348800659,
            -3.368732213973999,
            -3.038058280944824,
            3.921469211578369,
            4.111748695373535,
            4.090167045593262,
            3.502941370010376,
            2.6640894412994385,
            0.05202227830886841,
            2.460704803466797,
            4.106910228729248,
            1.90363347530365,
            2.081308603286743,
            -1.2689194679260254,
            -3.2753405570983887,
            3.099923610687256,
            -0.08711586892604828,
            3.2417256832122803,
            -0.24031053483486176,
            -5.802870750427246,
            -0.6104921102523804,
            -0.741572380065918,
            -3.414703369140625,
            5.372984886169434,
            4.1949920654296875,
            2.1251511573791504,
            -3.4111204147338867,
            -1.5253429412841797,
            -2.887805938720703,
            -0.5437442660331726,
            -6.1163716316223145,
            1.627854347229004,
            -1.724553108215332,
            1.4537434577941895,
            3.3544113636016846,
            -3.036454916000366,
            -0.6120502948760986,
            0.9607812762260437,
            -3.8764123916625977,
            0.3917159140110016,
            -1.1228501796722412,
            0.8498885631561279,
            1.1815043687820435,
            2.55368971824646,
            -3.374563694000244,
            5.308588027954102,
            1.1040798425674438,
            4.880443572998047,
            6.720311164855957,
            3.8645694255828857,
            4.442009925842285,
            -2.9586000442504883,
            -5.460515975952148,
            -2.2113261222839355,
            4.837944030761719,
            2.6935338973999023,
            -4.608095645904541,
            -2.287545680999756,
            -1.9641485214233398,
            1.6339632272720337,
            0.5264198184013367,
            2.5846638679504395,
            -3.262129068374634,
            5.128952980041504,
            -2.766409158706665,
            0.7378206849098206,
            -2.3660192489624023,
            3.422050952911377,
            0.7401754260063171,
            -1.231877088546753,
            3.3989226818084717,
            -0.32055044174194336,
            -6.693586826324463,
            -0.6936752796173096,
            -4.718504905700684,
            -0.8697494864463806,
            -1.1685974597930908,
            4.725536823272705,
            0.6447675824165344,
            0.03323948383331299,
            -1.558359980583191,
            5.912397384643555,
            -4.621894836425781,
            1.5668243169784546,
            -5.325571060180664,
            3.5141549110412598,
            2.5856728553771973,
            0.06425920128822327,
            -1.6855459213256836,
            -4.34204626083374,
            -1.7560889720916748,
            2.593749523162842,
            -2.572913885116577,
            0.8259464502334595,
            3.559288501739502,
            1.7407872676849365,
            -0.1481015533208847,
            -2.1871774196624756,
            -2.490349769592285,
            -2.9142518043518066,
            -4.546974182128906,
            -4.533010482788086,
            -3.215134382247925,
            -4.781015872955322,
            -4.716243267059326,
            2.7159247398376465,
            -2.8851101398468018,
            -0.24762320518493652,
            0.23798605799674988,
            -0.956362247467041,
            0.38124072551727295,
            -3.786661148071289,
            -0.3802523612976074,
            -2.058612585067749,
            2.3389339447021484,
            2.5990090370178223,
            -0.7294987440109253,
            -1.2817609310150146,
            1.3322919607162476,
            5.571744918823242,
            3.3596813678741455,
            1.7092936038970947,
            -2.5776381492614746,
            0.48826801776885986,
            2.4250645637512207,
            0.7754298448562622,
            -1.6344618797302246,
            -4.2363128662109375,
            0.5922921299934387,
            0.8745507597923279,
            15.454620361328125,
            -0.38328850269317627,
            0.8358604311943054,
            -0.03085702657699585,
            -2.2211596965789795,
            -1.380982756614685,
            -3.150359869003296,
            0.16763663291931152,
            -0.7975913286209106,
            4.087175369262695,
            1.549774169921875,
            -1.4619325399398804,
            1.4142723083496094,
            2.336735486984253,
            -1.3767739534378052,
            0.6119142770767212,
            -2.92016339302063,
            -3.109173059463501,
            -2.6626806259155273,
            0.48976364731788635,
            -0.5158488154411316,
            -1.2144477367401123,
            -4.433752059936523,
            -0.33035317063331604,
            -2.1651737689971924,
            4.498233795166016,
            0.5526852607727051,
            1.936532735824585,
            -5.514613628387451,
            1.7541253566741943,
            2.468125581741333,
            1.7531788349151611,
            0.45286503434181213,
            4.192072868347168,
            -5.5893120765686035,
            2.0553553104400635,
            3.3175716400146484,
            -0.5497032403945923,
            4.234130382537842,
            2.7851603031158447,
            -1.6279939413070679,
            -0.7818238735198975,
            -1.8387044668197632,
            1.1095948219299316,
            -2.8202052116394043,
            0.15196727216243744,
            3.8420469760894775,
            -3.9319677352905273,
            0.14723555743694305,
            5.505731582641602,
            -1.9568787813186646,
            -1.1758562326431274,
            -1.3779945373535156,
            -0.5936316251754761,
            -0.5467067360877991,
            4.443172454833984,
            0.03596869856119156,
            -1.2851896286010742,
            2.0151782035827637,
            -1.1349258422851562,
            -0.25731658935546875,
            0.27765703201293945,
            -2.7010841369628906,
            -2.325888156890869,
            -1.912672996520996,
            -0.24448475241661072,
            -1.9289497137069702,
            0.1664041429758072,
            2.854965925216675,
            0.8512047529220581,
            2.8126602172851562,
            1.1215324401855469,
            0.1981121301651001,
            -3.396124839782715,
            0.08704374730587006,
            -0.42039406299591064,
            3.1406662464141846,
            -1.9174798727035522,
            3.90267014503479,
            7.556394100189209,
            -0.5031129121780396,
            4.825595855712891,
            0.31524521112442017,
            -2.8842477798461914,
            4.378042697906494,
            -2.6280384063720703,
            6.126694679260254,
            -1.4577096700668335,
            -3.808885097503662,
            3.6312103271484375,
            0.3509146571159363,
            -1.1156535148620605,
            1.2892506122589111,
            6.13874626159668,
            2.1108837127685547,
            -3.7750701904296875,
            -1.7867618799209595,
            -5.1836161613464355,
            -3.3468198776245117,
            -1.5436012744903564,
            6.765244483947754,
            4.55431604385376,
            0.564674437046051,
            -3.4474501609802246,
            -0.18298839032649994,
            2.0769846439361572,
            -1.8678146600723267,
            -5.703566074371338,
            -3.558717727661133,
            -3.44126558303833,
            3.2027101516723633,
            -2.892615795135498,
            -1.0245897769927979,
            0.14194801449775696,
            0.4281996488571167,
            -2.6925735473632812,
            0.6611160039901733,
            2.0080628395080566,
            0.7497216463088989,
            2.990635395050049,
            0.6427629590034485,
            -1.2970774173736572,
            -1.3232896327972412,
            -3.8049941062927246,
            -0.3348410129547119,
            0.6938976049423218,
            0.46413639187812805,
            -2.8963801860809326,
            -0.5933550596237183,
            -1.0618536472320557,
            -0.31701573729515076,
            -2.5740854740142822,
            -3.7045202255249023,
            -0.003604322671890259,
            -0.5019208192825317,
            -2.2107696533203125,
            0.8384076952934265,
            1.5363917350769043,
            -2.0269219875335693,
            -0.08224695920944214,
            3.354959011077881,
            -4.468369483947754,
            -0.14076665043830872,
            10.01262378692627,
            2.1292707920074463,
            1.7171289920806885,
            -3.39479398727417,
            -1.8576151132583618,
            0.5865152478218079,
            -1.4973039627075195,
            -1.947312355041504,
            0.36646124720573425,
            2.2041141986846924,
            -0.9536111354827881,
            -0.5370945334434509,
            -3.5093255043029785
        ]
    },
    "authors": [
        {
            "authorId": "32817044",
            "name": "Samyam Rajbhandari"
        },
        {
            "authorId": "2609325",
            "name": "Conglong Li"
        },
        {
            "authorId": "9088433",
            "name": "Z. Yao"
        },
        {
            "authorId": "2112111675",
            "name": "Minjia Zhang"
        },
        {
            "authorId": "3394222",
            "name": "Reza Yazdani Aminabadi"
        },
        {
            "authorId": "2942686",
            "name": "A. A. Awan"
        },
        {
            "authorId": "3299496",
            "name": "Jeff Rasley"
        },
        {
            "authorId": "2145020341",
            "name": "Yuxiong He"
        }
    ],
    "references": [
        {
            "paperId": "c022f75b00d795c6297d6a9ea948856ea4d365a1",
            "title": "DeepSpeed- Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale"
        },
        {
            "paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19",
            "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"
        },
        {
            "paperId": "fb01415a0decfa3f3d6339930e95028ae1ff4170",
            "title": "Efficient Large Scale Language Modeling with Mixtures of Experts"
        },
        {
            "paperId": "80d0116d77beeded0c23cf48946d9d10d4faee14",
            "title": "GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"
        },
        {
            "paperId": "0e23cc159fd2fb34550600d60dd9148c93636183",
            "title": "Taming Sparsely Activated Transformer with Stochastic Experts"
        },
        {
            "paperId": "24e775b20adf21e9b5b95c6a9b7a5c164d055849",
            "title": "M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining"
        },
        {
            "paperId": "d52977458284acce166bb1291a9d79143aa59070",
            "title": "Scalable and Efficient MoE Training for Multitask Multilingual Models"
        },
        {
            "paperId": "01b1293ddea9bcd6df1185b0b934503de01d6561",
            "title": "Block Pruning For Faster Transformers"
        },
        {
            "paperId": "238eb420c472bfdb1b4d34f9f53abec51f307a6b",
            "title": "FastMoE: A Fast Mixture-of-Expert Training System"
        },
        {
            "paperId": "fdacf2a732f55befdc410ea927091cad3b791f13",
            "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"
        },
        {
            "paperId": "1882f194cb43828852cc052887671e55a80f945a",
            "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "2573af4e13d9a5dddb257d22cd38a600528d9a8b",
            "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"
        },
        {
            "paperId": "c6c734e16f66fbfcefac7625cc64599e83292c1e",
            "title": "MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers"
        },
        {
            "paperId": "43f2ad297941db230c089ba353efc3f281ab678c",
            "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2",
            "title": "Scaling Laws for Neural Language Models"
        },
        {
            "paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45",
            "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"
        },
        {
            "paperId": "0a5d987ddb5463062babceca90ba974db0cf96e7",
            "title": "HAWQ-V2: Hessian Aware trace-Weighted Quantization of Neural Networks"
        },
        {
            "paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
        },
        {
            "paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3",
            "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"
        },
        {
            "paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc",
            "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"
        },
        {
            "paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b",
            "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"
        },
        {
            "paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a",
            "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"
        },
        {
            "paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d",
            "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"
        },
        {
            "paperId": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf",
            "title": "Patient Knowledge Distillation for BERT Model Compression"
        },
        {
            "paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de",
            "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"
        },
        {
            "paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
            "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"
        },
        {
            "paperId": "d9f6ada77448664b71128bb19df15765336974a6",
            "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"
        },
        {
            "paperId": "1a858b96d2fdfeadf8c0f7126cbd55825223fb9d",
            "title": "HAWQ: Hessian AWare Quantization of Neural Networks With Mixed-Precision"
        },
        {
            "paperId": "21da617a0f79aabf94272107184606cefe90ab75",
            "title": "Generating Long Sequences with Sparse Transformers"
        },
        {
            "paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"
        },
        {
            "paperId": "e326d53dde6864685cdf8ea4a7b30d6631aa2514",
            "title": "Accelerating"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c",
            "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"
        },
        {
            "paperId": "636a79420d838eabe4af7fb25d6437de45ab64e8",
            "title": "RACE: Large-scale ReAding Comprehension Dataset From Examinations"
        },
        {
            "paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586",
            "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"
        },
        {
            "paperId": "5ed791f810da580c78df6a052c6b9f2e258f6b0a",
            "title": "The LAMBADA dataset: Word prediction requiring a broad discourse context"
        },
        {
            "paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19",
            "title": "Distilling the Knowledge in a Neural Network"
        },
        {
            "paperId": "081651b38ff7533550a3adfc1c00da333a8fe86c",
            "title": "How transferable are features in deep neural networks?"
        },
        {
            "paperId": "47990fefbad009186adc7da2f4218815f9d74a02",
            "title": "Mixture of experts: a literature survey"
        },
        {
            "paperId": "1a2a770d23b4a171fa81de62a78a3deb0588f238",
            "title": "Visualizing and Understanding Convolutional Networks"
        },
        {
            "paperId": "b29447ba499507a259ae9d8f685d60cc1597d7d3",
            "title": "Semantic Parsing on Freebase from Question-Answer Pairs"
        },
        {
            "paperId": "4d6e574c76e4a5ebbdb5f6e382d06c058090e4b7",
            "title": "KL-divergence regularized deep neural network adaptation for improved large vocabulary speech recognition"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": null,
            "title": "2021) and this makes our MoE model\u2019s 5x training cost reduction higher than the 4x reduction in (Artetxe et al., 2021)"
        },
        {
            "paperId": null,
            "title": "Tutel: An e\ufb03cient mixture-of-experts implementation for large dnn model training"
        },
        {
            "paperId": null,
            "title": "DeepSpeed: Accelerating large-scale model inference and training via system optimizations and compression"
        },
        {
            "paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": "9405cc0d6169988371b2755e573cc28650d14dfe",
            "title": "Language Models are Unsupervised Multitask Learners"
        },
        {
            "paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "title": "Improving Language Understanding by Generative Pre-Training"
        },
        {
            "paperId": null,
            "title": "A corpus and evaluation framework for deeper understanding of commonsense stories"
        },
        {
            "paperId": null,
            "title": "SCCL: Synthesizing Optimal Collective Algorithms. CoRR, abs"
        },
        {
            "paperId": null,
            "title": "Deepspeed-moe: Advancing mixtureof-experts inference and training to power nextgeneration ai scale. ArXiv"
        }
    ]
}