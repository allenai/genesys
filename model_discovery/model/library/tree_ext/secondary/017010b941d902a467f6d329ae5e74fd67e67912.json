{
    "paperId": "017010b941d902a467f6d329ae5e74fd67e67912",
    "externalIds": {
        "DBLP": "journals/corr/abs-2305-11627",
        "ArXiv": "2305.11627",
        "DOI": "10.48550/arXiv.2305.11627",
        "CorpusId": 258823276
    },
    "title": "LLM-Pruner: On the Structural Pruning of Large Language Models",
    "abstract": "Large language models (LLMs) have shown remarkable capabilities in language understanding and generation. However, such impressive capability typically comes with a substantial model size, which presents significant challenges in both the deployment, inference, and training stages. With LLM being a general-purpose task solver, we explore its compression in a task-agnostic manner, which aims to preserve the multi-task solving and language generation ability of the original LLM. One challenge to achieving this is the enormous size of the training corpus of LLM, which makes both data transfer and model post-training over-burdensome. Thus, we tackle the compression of LLMs within the bound of two constraints: being task-agnostic and minimizing the reliance on the original training dataset. Our method, named LLM-Pruner, adopts structural pruning that selectively removes non-critical coupled structures based on gradient information, maximally preserving the majority of the LLM's functionality. To this end, the performance of pruned models can be efficiently recovered through tuning techniques, LoRA, in merely 3 hours, requiring only 50K data. We validate the LLM-Pruner on three LLMs, including LLaMA, Vicuna, and ChatGLM, and demonstrate that the compressed models still exhibit satisfactory capabilities in zero-shot classification and generation. The code is available at: https://github.com/horseee/LLM-Pruner",
    "venue": "Neural Information Processing Systems",
    "year": 2023,
    "referenceCount": 75,
    "citationCount": 172,
    "influentialCitationCount": 23,
    "openAccessPdf": {
        "url": "https://arxiv.org/pdf/2305.11627",
        "status": "GREEN"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work explores LLM compression in a task-agnostic manner, which aims to preserve the multi-task solving and language generation ability of the original LLM, and adopts structural pruning that selectively removes non-critical coupled structures based on gradient information, maximally preserving the majority of the LLM's functionality."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -1.4612045288085938,
            -0.5414944291114807,
            0.10276836156845093,
            2.7339158058166504,
            0.9761738181114197,
            2.5680065155029297,
            2.9857959747314453,
            -0.1951797604560852,
            -2.9269001483917236,
            2.524810314178467,
            -2.469923496246338,
            4.384628772735596,
            -0.06706991791725159,
            -1.2040952444076538,
            -2.409025192260742,
            1.7947396039962769,
            1.4941332340240479,
            -0.714594841003418,
            4.233754634857178,
            4.203274726867676,
            -2.083730936050415,
            3.8554558753967285,
            -2.6952548027038574,
            -0.8684356808662415,
            -1.0689723491668701,
            -0.3282161355018616,
            5.708301067352295,
            2.1738319396972656,
            -2.7174360752105713,
            1.2651301622390747,
            -0.7010869979858398,
            -5.825442790985107,
            3.118616819381714,
            -3.74452805519104,
            3.250352382659912,
            -2.3024113178253174,
            -2.006958484649658,
            10.330652236938477,
            -2.439049243927002,
            0.6243025064468384,
            -2.394289970397949,
            -0.7322869300842285,
            0.3011391758918762,
            1.165063500404358,
            1.2948729991912842,
            0.9911700487136841,
            4.286055088043213,
            -1.3696677684783936,
            1.3962318897247314,
            1.0065109729766846,
            2.374758243560791,
            0.29708725214004517,
            -0.050201430916786194,
            1.6190557479858398,
            -0.11597037315368652,
            0.2956327795982361,
            -1.7624855041503906,
            1.4521528482437134,
            2.0963289737701416,
            -3.3471298217773438,
            3.4957973957061768,
            7.317336559295654,
            -1.7368555068969727,
            1.352609395980835,
            3.5719285011291504,
            -4.192087173461914,
            -2.754072666168213,
            3.9931092262268066,
            2.324279308319092,
            -0.0822523832321167,
            -0.5658349394798279,
            -4.68626594543457,
            1.1481568813323975,
            2.2858359813690186,
            -3.805751085281372,
            2.4019155502319336,
            -0.5966005921363831,
            -8.772138595581055,
            -1.8377070426940918,
            -2.8756473064422607,
            -0.732111930847168,
            -1.3062858581542969,
            -0.3376835584640503,
            3.3675832748413086,
            3.364593982696533,
            -1.1131826639175415,
            -4.739002704620361,
            1.252315640449524,
            3.6811556816101074,
            -2.6663877964019775,
            0.6491950154304504,
            0.35939717292785645,
            0.06619204580783844,
            6.224851608276367,
            -4.773492336273193,
            -2.4965732097625732,
            0.9725350141525269,
            -1.703190565109253,
            -0.9995774626731873,
            -0.8851509690284729,
            2.4436445236206055,
            -1.175998330116272,
            2.4939467906951904,
            0.8315999507904053,
            5.199639797210693,
            -4.1135454177856445,
            -0.25249284505844116,
            1.0670503377914429,
            0.9770123958587646,
            -1.107699990272522,
            -3.1871399879455566,
            3.4229941368103027,
            -0.8535235524177551,
            -3.906381607055664,
            -2.3074207305908203,
            -3.067955255508423,
            -1.3392586708068848,
            0.12715840339660645,
            -4.226543426513672,
            3.4102258682250977,
            -1.8467450141906738,
            -1.3537070751190186,
            -2.4444124698638916,
            -0.36320143938064575,
            1.781248688697815,
            0.7159679532051086,
            -1.2772762775421143,
            -3.4481470584869385,
            -0.6200438737869263,
            -1.2995171546936035,
            2.49704647064209,
            -1.8928860425949097,
            2.961855173110962,
            -2.5922484397888184,
            0.8976675868034363,
            3.8615922927856445,
            -4.0965681076049805,
            2.212027072906494,
            -2.5378851890563965,
            -2.4396841526031494,
            1.6852052211761475,
            5.103938102722168,
            -1.4459567070007324,
            1.4267277717590332,
            1.4551690816879272,
            2.917369842529297,
            1.0126068592071533,
            -2.7347521781921387,
            -0.5677472352981567,
            6.942602634429932,
            2.6978602409362793,
            -3.6281280517578125,
            -0.7665840983390808,
            0.07931569218635559,
            -0.6284892559051514,
            2.969306468963623,
            -6.781480312347412,
            2.7953875064849854,
            -2.856877088546753,
            0.7563506364822388,
            0.7230280637741089,
            0.8105352520942688,
            -10.46366024017334,
            -1.6199312210083008,
            4.169552803039551,
            -2.070746898651123,
            -1.6685612201690674,
            2.461125373840332,
            1.624778389930725,
            3.768430709838867,
            -2.35746693611145,
            2.330643653869629,
            2.2013893127441406,
            4.549342632293701,
            1.303035855293274,
            2.8823654651641846,
            0.5508542656898499,
            -2.285888195037842,
            -0.9958558082580566,
            -0.3506894111633301,
            -1.6662704944610596,
            0.060397952795028687,
            -5.7098870277404785,
            2.1509974002838135,
            -4.968660354614258,
            -0.3219989538192749,
            -3.727027416229248,
            -5.579722881317139,
            -2.7211008071899414,
            0.42343151569366455,
            -2.3511738777160645,
            0.3933044672012329,
            5.066612720489502,
            6.100870609283447,
            2.9838995933532715,
            1.0920134782791138,
            3.731767177581787,
            4.454745292663574,
            -3.223191738128662,
            2.418661117553711,
            3.102513313293457,
            -0.3349539637565613,
            0.30291086435317993,
            -1.0703459978103638,
            3.779104709625244,
            -1.1548484563827515,
            -2.601285457611084,
            3.5218191146850586,
            0.8314169049263,
            1.3102866411209106,
            1.8864448070526123,
            -0.05255989730358124,
            -3.843217372894287,
            1.4678070545196533,
            -1.682316780090332,
            -1.3319578170776367,
            -7.374607086181641,
            3.19582200050354,
            6.235326290130615,
            1.522249460220337,
            -2.2914299964904785,
            -1.4555315971374512,
            3.0680301189422607,
            -3.0826783180236816,
            2.256826162338257,
            -2.962186813354492,
            1.1127831935882568,
            -3.2013068199157715,
            1.3147947788238525,
            -1.0334745645523071,
            -1.815960168838501,
            -4.231764316558838,
            -0.9743316173553467,
            0.16357149183750153,
            -7.5066938400268555,
            -0.8977500200271606,
            -5.072234153747559,
            2.077070713043213,
            -0.13738331198692322,
            -2.963031768798828,
            3.9144396781921387,
            1.4280343055725098,
            0.20541875064373016,
            4.917881965637207,
            3.2343647480010986,
            -1.318206548690796,
            -2.394798517227173,
            2.834615707397461,
            -1.5008141994476318,
            -0.6497201919555664,
            -2.326066493988037,
            -3.741502523422241,
            3.277500629425049,
            -1.0059007406234741,
            2.5213675498962402,
            2.1021578311920166,
            -0.34251415729522705,
            -0.6730318069458008,
            1.6265838146209717,
            2.851043462753296,
            2.6447715759277344,
            5.712419509887695,
            1.02183198928833,
            5.369124889373779,
            -4.005087852478027,
            0.02978658676147461,
            -4.728582382202148,
            -1.4835608005523682,
            -0.773140013217926,
            4.443600654602051,
            3.6761913299560547,
            -0.9089263677597046,
            0.27678078413009644,
            -4.873643398284912,
            0.9481308460235596,
            -7.542984962463379,
            0.19148367643356323,
            -0.9489169120788574,
            1.8487688302993774,
            3.057711601257324,
            3.484860420227051,
            -2.7200140953063965,
            0.14158841967582703,
            0.01943698525428772,
            -2.084488868713379,
            -2.6703460216522217,
            -0.8018792867660522,
            -0.7213747501373291,
            -1.9899731874465942,
            -2.556112766265869,
            -1.1057976484298706,
            3.0612542629241943,
            -4.409693241119385,
            -6.3628387451171875,
            0.3092518150806427,
            -0.49787068367004395,
            4.610356330871582,
            -0.23205046355724335,
            -2.262275218963623,
            -0.3457830846309662,
            -1.4756278991699219,
            2.0540823936462402,
            3.4474539756774902,
            -2.0943334102630615,
            2.090268850326538,
            2.5985374450683594,
            0.05362270772457123,
            -2.9353485107421875,
            2.3387086391448975,
            -3.47986102104187,
            -2.437025785446167,
            0.33964604139328003,
            4.058619022369385,
            -3.210254669189453,
            0.5898656845092773,
            3.1545844078063965,
            2.2364001274108887,
            1.138803482055664,
            -2.4632256031036377,
            1.610020399093628,
            0.7632922530174255,
            1.1911414861679077,
            -6.0004754066467285,
            -2.6337289810180664,
            -3.73622465133667,
            0.2301797866821289,
            3.2055602073669434,
            2.573401927947998,
            -2.9261369705200195,
            5.700562000274658,
            -0.04834330081939697,
            2.4523508548736572,
            1.8613977432250977,
            2.1005754470825195,
            -1.8686472177505493,
            -4.823182106018066,
            -0.7559460401535034,
            -1.9611263275146484,
            3.4705841541290283,
            0.19897019863128662,
            1.0632705688476562,
            7.283186912536621,
            -0.8548395037651062,
            2.8589611053466797,
            -1.7622934579849243,
            3.2983992099761963,
            2.2625205516815186,
            0.27994588017463684,
            -0.6606037616729736,
            -0.9915397763252258,
            0.7250698804855347,
            1.7588632106781006,
            4.457427501678467,
            1.7407302856445312,
            1.4995986223220825,
            3.0927114486694336,
            0.7131189703941345,
            0.9478583335876465,
            1.9915881156921387,
            -0.1096348762512207,
            0.3164379596710205,
            -0.7034890055656433,
            3.8075547218322754,
            0.16312403976917267,
            4.836127281188965,
            -0.7567089200019836,
            12.608461380004883,
            -3.8103132247924805,
            4.368222713470459,
            -4.438795566558838,
            -1.0199527740478516,
            -3.76448655128479,
            -2.0925216674804688,
            0.7592486143112183,
            -2.945491313934326,
            -2.9375460147857666,
            -0.053564757108688354,
            -5.7045440673828125,
            1.824599027633667,
            1.8093321323394775,
            -1.2948191165924072,
            4.945402145385742,
            -2.1461281776428223,
            2.5635623931884766,
            0.8657147884368896,
            0.46108683943748474,
            -0.968132734298706,
            2.522645950317383,
            -1.0707511901855469,
            -1.1890660524368286,
            -0.6082755923271179,
            1.7714518308639526,
            2.3185856342315674,
            3.3848371505737305,
            -4.4473652839660645,
            -0.33468449115753174,
            -1.7329509258270264,
            -2.220693349838257,
            0.30183881521224976,
            2.2286200523376465,
            -0.24446475505828857,
            -1.1387743949890137,
            4.313810348510742,
            3.3865017890930176,
            -4.480542182922363,
            -0.19843336939811707,
            1.449507236480713,
            -0.836402952671051,
            -2.8507981300354004,
            -0.16786280274391174,
            -4.585715293884277,
            -3.2477073669433594,
            -3.5290536880493164,
            -4.757546424865723,
            -0.6422430276870728,
            -0.290731817483902,
            3.81319260597229,
            1.6545383930206299,
            2.6654462814331055,
            3.706723690032959,
            -0.4609070122241974,
            1.814010739326477,
            4.691908359527588,
            3.9443774223327637,
            0.37393173575401306,
            -0.8629588484764099,
            1.3913946151733398,
            2.723942279815674,
            -2.1338629722595215,
            2.3264968395233154,
            0.24522575736045837,
            5.642590522766113,
            -1.8539116382598877,
            -1.9775359630584717,
            0.6051981449127197,
            1.8534938097000122,
            0.5979875922203064,
            0.477017879486084,
            3.2028608322143555,
            -3.3517355918884277,
            2.348193645477295,
            2.4947235584259033,
            -4.5248942375183105,
            4.87075138092041,
            -0.55723637342453,
            3.343238353729248,
            1.8047266006469727,
            2.1085689067840576,
            -5.272931098937988,
            -1.8305257558822632,
            3.459962844848633,
            -4.436507701873779,
            -1.7103164196014404,
            -0.6764891147613525,
            1.5484768152236938,
            2.8764195442199707,
            -0.981184720993042,
            -1.4556303024291992,
            0.45473527908325195,
            1.7756270170211792,
            -1.4568300247192383,
            5.210262298583984,
            0.06646023690700531,
            0.7075984477996826,
            1.4388810396194458,
            0.49501660466194153,
            -0.8628900051116943,
            -2.622133255004883,
            -0.4820687472820282,
            2.870372772216797,
            2.650678873062134,
            -0.8038656711578369,
            -2.6312663555145264,
            2.779355049133301,
            -2.047457695007324,
            -0.38642632961273193,
            2.722245693206787,
            0.560935914516449,
            2.6963753700256348,
            -4.508059978485107,
            -3.7718746662139893,
            -0.5671840310096741,
            2.336233139038086,
            -1.7994294166564941,
            0.06179409474134445,
            5.089470386505127,
            1.6141124963760376,
            1.3809605836868286,
            4.401991844177246,
            -0.6159780025482178,
            1.0345126390457153,
            3.557300329208374,
            3.403937339782715,
            -0.5216639041900635,
            2.566514253616333,
            -1.1738002300262451,
            -4.27388858795166,
            -0.8759721517562866,
            0.5426210761070251,
            0.916007399559021,
            -0.06840112805366516,
            -3.8262100219726562,
            0.003349810838699341,
            -1.4588948488235474,
            -1.8655543327331543,
            5.106705665588379,
            4.534874439239502,
            -0.3964731693267822,
            -0.19304633140563965,
            0.15909066796302795,
            -0.5578757524490356,
            2.1812005043029785,
            -6.581859588623047,
            1.834197759628296,
            1.306086540222168,
            0.07258366048336029,
            4.728611946105957,
            -1.7443279027938843,
            -0.9145174622535706,
            -0.5317013263702393,
            -1.0032631158828735,
            -0.8110879063606262,
            -2.0506584644317627,
            0.6327642202377319,
            0.17982307076454163,
            -0.02318766713142395,
            -2.175219774246216,
            2.31693959236145,
            -0.4934156835079193,
            6.207056999206543,
            4.86098575592041,
            3.6659324169158936,
            2.8962738513946533,
            -3.3354852199554443,
            -0.22926700115203857,
            -2.375866174697876,
            1.16200590133667,
            2.907144784927368,
            -4.724340438842773,
            -1.5061450004577637,
            -1.8043723106384277,
            -0.5609585046768188,
            0.2743018865585327,
            4.580495357513428,
            -0.7955458164215088,
            6.0596489906311035,
            -4.541072845458984,
            -2.9670238494873047,
            -0.7784874439239502,
            0.7819203734397888,
            0.77776038646698,
            0.4260668158531189,
            0.3454882800579071,
            1.7889456748962402,
            -2.386592149734497,
            -1.1212916374206543,
            -1.4008172750473022,
            -0.7315323948860168,
            -1.369385838508606,
            3.6129777431488037,
            3.2347257137298584,
            0.33269232511520386,
            1.9293915033340454,
            3.423185348510742,
            -0.016318239271640778,
            0.7505800724029541,
            -4.491858005523682,
            3.5919041633605957,
            3.0228042602539062,
            -1.2552471160888672,
            -1.59248685836792,
            -2.760849952697754,
            1.011165738105774,
            0.07301273941993713,
            -1.6785279512405396,
            0.7954690456390381,
            3.391237735748291,
            0.39892882108688354,
            -0.28290069103240967,
            -2.0126500129699707,
            -3.726062059402466,
            -0.651939868927002,
            -2.1308720111846924,
            -4.198372840881348,
            -0.2665752172470093,
            -2.054203987121582,
            -4.2610883712768555,
            -0.2774098813533783,
            -3.4617486000061035,
            2.5956504344940186,
            2.649634838104248,
            -0.10114917159080505,
            0.2251867651939392,
            -2.4634668827056885,
            -0.5114650130271912,
            -4.722946643829346,
            4.319454669952393,
            -0.33319246768951416,
            0.04329705238342285,
            3.4129714965820312,
            1.290928840637207,
            6.888605117797852,
            2.8087573051452637,
            2.616508960723877,
            -3.6939687728881836,
            -1.6356079578399658,
            2.848301410675049,
            0.484102725982666,
            -0.9768323302268982,
            -1.3823964595794678,
            -1.0112751722335815,
            2.3094897270202637,
            18.104217529296875,
            -2.860501766204834,
            -2.9071297645568848,
            2.3864102363586426,
            -0.29199039936065674,
            -2.592709541320801,
            -3.2025442123413086,
            0.8641488552093506,
            0.02074071764945984,
            -0.5674865245819092,
            -0.32448703050613403,
            -2.3120265007019043,
            -0.9673945903778076,
            3.0394675731658936,
            -3.1161999702453613,
            -1.4656678438186646,
            -2.086723566055298,
            0.7560253143310547,
            -3.162465810775757,
            -0.3015351891517639,
            -0.030560463666915894,
            0.18193480372428894,
            -0.02551281452178955,
            -2.5157558917999268,
            -2.081749677658081,
            0.8783971071243286,
            2.619083881378174,
            3.3613569736480713,
            -3.6355671882629395,
            0.5132107138633728,
            1.7059088945388794,
            4.436537742614746,
            1.539259672164917,
            2.267969846725464,
            -3.3987207412719727,
            -0.17383575439453125,
            2.5547165870666504,
            -2.286421775817871,
            -0.09846222400665283,
            1.354477047920227,
            -1.3995180130004883,
            -0.1738957166671753,
            -1.909867763519287,
            1.8538672924041748,
            -1.5190998315811157,
            1.0562520027160645,
            2.9383037090301514,
            -1.3575388193130493,
            -1.0366109609603882,
            3.962059497833252,
            -2.323631763458252,
            -3.7362730503082275,
            -2.4648525714874268,
            0.868449866771698,
            0.07737331092357635,
            0.8307971954345703,
            -2.077854871749878,
            -2.0723862648010254,
            0.46196040511131287,
            -1.907031774520874,
            0.4594138264656067,
            -0.9757009744644165,
            -1.8979928493499756,
            -2.322092294692993,
            -4.215139865875244,
            0.572982907295227,
            -5.108786106109619,
            2.142639398574829,
            4.555882453918457,
            -0.9548792839050293,
            3.9031593799591064,
            1.8901525735855103,
            -0.7872791290283203,
            -0.7341970801353455,
            -0.24050289392471313,
            -2.232100248336792,
            2.7832493782043457,
            -1.6470105648040771,
            -1.0599737167358398,
            7.26629638671875,
            -1.2682361602783203,
            2.4800047874450684,
            -2.8762764930725098,
            -1.2169394493103027,
            3.071918487548828,
            -2.0848424434661865,
            4.693488597869873,
            2.1106698513031006,
            -1.8838701248168945,
            4.370378494262695,
            -3.1994547843933105,
            -0.18027536571025848,
            5.124250888824463,
            6.610487937927246,
            2.140366554260254,
            -4.177545070648193,
            -1.91654634475708,
            -3.1283650398254395,
            -3.264638900756836,
            -1.1680734157562256,
            4.895512104034424,
            4.316197872161865,
            0.6438661813735962,
            -3.7667605876922607,
            0.0680176317691803,
            -0.4834337532520294,
            -3.116243600845337,
            -8.02342414855957,
            -4.858180999755859,
            -3.297780990600586,
            3.1898300647735596,
            -3.0853567123413086,
            -1.7335344552993774,
            0.3691696524620056,
            0.30040842294692993,
            -0.9590730667114258,
            0.6755648851394653,
            1.7270958423614502,
            -0.3401792347431183,
            4.040595531463623,
            0.4344479441642761,
            -2.6144161224365234,
            -3.3182902336120605,
            -2.941873073577881,
            -1.6823992729187012,
            0.08628769218921661,
            -0.4276987910270691,
            -3.1492908000946045,
            -1.689805030822754,
            -2.088840961456299,
            1.660792589187622,
            -2.698647975921631,
            -1.4017555713653564,
            0.5694156885147095,
            -0.8871487975120544,
            -1.870010495185852,
            2.538937568664551,
            -0.7982419729232788,
            -1.7525700330734253,
            3.314333438873291,
            3.005567789077759,
            -1.7326401472091675,
            -2.802022933959961,
            9.201858520507812,
            0.7438820004463196,
            -1.5405364036560059,
            -3.7286605834960938,
            -3.199979066848755,
            -0.15946534276008606,
            0.7225912809371948,
            1.2115185260772705,
            -0.34097978472709656,
            2.856117010116577,
            2.8492767810821533,
            -0.8267252445220947,
            -2.9675045013427734
        ]
    },
    "authors": [
        {
            "authorId": "15532066",
            "name": "Xinyin Ma"
        },
        {
            "authorId": "150110431",
            "name": "Gongfan Fang"
        },
        {
            "authorId": "48631088",
            "name": "Xinchao Wang"
        }
    ],
    "references": [
        {
            "paperId": "1c41acbcdd8a43fc50d24b19b17da84599dcd226",
            "title": "Slimmable Dataset Condensation"
        },
        {
            "paperId": "389ec3e8902a5dcfcde1adec735854e93f845937",
            "title": "LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions"
        },
        {
            "paperId": "57e849d0de13ed5f91d086936296721d4ff75a75",
            "title": "LLaMA: Open and Efficient Foundation Language Models"
        },
        {
            "paperId": "b835345c6168d7b179516700aa4460912a8857e9",
            "title": "HomoDistil: Homotopic Task-Agnostic Distillation of Pre-trained Transformers"
        },
        {
            "paperId": "da075ad0ec2c88335af85602a76a33e034536896",
            "title": "DepGraph: Towards Any Structural Pruning"
        },
        {
            "paperId": "909ad57ce8caa6b390a65ae09db352d27d8f3996",
            "title": "SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot"
        },
        {
            "paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e",
            "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"
        },
        {
            "paperId": "7da0f2501034522e3d50af7e9b8fa7ec9d7b65b6",
            "title": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers"
        },
        {
            "paperId": "07bd1c24b92513c35fc83ae834f5a02f226fbba5",
            "title": "Dataset Distillation via Factorization"
        },
        {
            "paperId": "49e341897e511a70dc3bb88cb5ed39a292d9459e",
            "title": "Deep Model Reassembly"
        },
        {
            "paperId": "1d26c947406173145a4665dd7ab255e03494ea28",
            "title": "GLM-130B: An Open Bilingual Pre-trained Model"
        },
        {
            "paperId": "4be7d1524edb0137599a5cc95f72844b85a52fe1",
            "title": "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale"
        },
        {
            "paperId": "5dca8e6a7d4657bf65a3ecf215fd5dfeb16cd255",
            "title": "Factorizing Knowledge in Neural Networks"
        },
        {
            "paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a",
            "title": "Emergent Abilities of Large Language Models"
        },
        {
            "paperId": "e03609f2587f690867e7ea0bedaf0db25282c548",
            "title": "ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers"
        },
        {
            "paperId": "fb1d85fe28b5e92e22d084eca674d4a2b48cdc5a",
            "title": "Prompting to Distill: Boosting Data-Free Knowledge Distillation via Reinforced Prompt"
        },
        {
            "paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb",
            "title": "PaLM: Scaling Language Modeling with Pathways"
        },
        {
            "paperId": "9e82736043eebe3f71eb86cbef6e2ac45306ece5",
            "title": "Structured Pruning Learns Compact and Accurate Models"
        },
        {
            "paperId": "fb145e1e49d3269d8223c7710e22b45438613ff0",
            "title": "A Fast Post-Training Pruning Framework for Transformers"
        },
        {
            "paperId": "8342b592fe238f3d230e4959b06fd10153c45db1",
            "title": "Training Compute-Optimal Large Language Models"
        },
        {
            "paperId": "6da9a81b75e7ad02867860753d1aa276673a3a77",
            "title": "The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models"
        },
        {
            "paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5",
            "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"
        },
        {
            "paperId": "b3848d32f7294ec708627897833c4097eb4d8778",
            "title": "LaMDA: Language Models for Dialog Applications"
        },
        {
            "paperId": "9202a718ce05395b6e17d5301e3a2e8b1021f31b",
            "title": "Prune Once for All: Sparse Pre-Trained Language Models"
        },
        {
            "paperId": "125e45af77cbec076dcf379b55c682595ac2dd88",
            "title": "RED++ : Data-Free Pruning of Deep Neural Networks via Input Splitting and Output Merging"
        },
        {
            "paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092",
            "title": "LoRA: Low-Rank Adaptation of Large Language Models"
        },
        {
            "paperId": "6da4b231148bf26677233d1f778d08a5d26f4313",
            "title": "TR-BERT: Dynamic Token Reduction for Accelerating BERT Inference"
        },
        {
            "paperId": "40235eded15f44c8c4a7f48468adcc7df4e171fb",
            "title": "Rethinking Network Pruning \u2013 under the Pre-train and Fine-tune Paradigm"
        },
        {
            "paperId": "c375e121926db9551f224ff235018ea38bb159b7",
            "title": "BinaryBERT: Pushing the Limit of BERT Quantization"
        },
        {
            "paperId": "8b28d9e3ca408b8a41d32f8bd4da7fbbd4f12a4b",
            "title": "Towards Zero-Shot Knowledge Distillation for Natural Language Processing"
        },
        {
            "paperId": "b42c6cfadfaf1209346a41f1cf766f3d0c09aa3c",
            "title": "Meta-KD: A Meta Knowledge Distillation Framework for Language Model Compression across Domains"
        },
        {
            "paperId": "8790d0c95f5d12b6fd3f62043515cd1479e57e92",
            "title": "De-biased Court\u2019s View Generation with Causality"
        },
        {
            "paperId": "74276a37bfa50f90dfae37f767b2b67784bd402a",
            "title": "mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer"
        },
        {
            "paperId": "71b769812974c2e04bcd2ffd9554015052f7cfd5",
            "title": "Adversarial Self-Supervised Data Free Distillation for Text Classification"
        },
        {
            "paperId": "0abb08c4ec5feab4cdd82c471866dd4395c573ce",
            "title": "Contrastive Distillation on Intermediate Representations for Language Model Compression"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "90a1491ac32e732c93773354e4e665794ed4d490",
            "title": "DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference"
        },
        {
            "paperId": "2573af4e13d9a5dddb257d22cd38a600528d9a8b",
            "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"
        },
        {
            "paperId": "1c332cfa211400fc6f56983fb01a6692046116dd",
            "title": "DynaBERT: Dynamic BERT with Adaptive Width and Depth"
        },
        {
            "paperId": "1c449fe4bb3ad1f66372d15ce433a2e818299366",
            "title": "Distilling Knowledge From Graph Convolutional Networks"
        },
        {
            "paperId": "c6c734e16f66fbfcefac7625cc64599e83292c1e",
            "title": "MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers"
        },
        {
            "paperId": "43f2ad297941db230c089ba353efc3f281ab678c",
            "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45",
            "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"
        },
        {
            "paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
            "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"
        },
        {
            "paperId": "4d8a4509753cc91832f80ec35795064e79630ef3",
            "title": "Structured Pruning of a BERT-based Question Answering Model"
        },
        {
            "paperId": "ce106590145e89ea4b621c99665862967ccf5dac",
            "title": "Q8BERT: Quantized 8Bit BERT"
        },
        {
            "paperId": "83b8108014e3db4f46354a28ae68193f143c4e7e",
            "title": "Structured Pruning of Large Language Models"
        },
        {
            "paperId": "540f074cb6f16563a357741837e41c44c0a38234",
            "title": "Reweighted Proximal Pruning for Large-Scale Language Representation"
        },
        {
            "paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b",
            "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"
        },
        {
            "paperId": "f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1",
            "title": "Reducing Transformer Depth on Demand with Structured Dropout"
        },
        {
            "paperId": "0cbf97173391b0430140117027edcaf1a37968c7",
            "title": "TinyBERT: Distilling BERT for Natural Language Understanding"
        },
        {
            "paperId": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf",
            "title": "Patient Knowledge Distillation for BERT Model Compression"
        },
        {
            "paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de",
            "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"
        },
        {
            "paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583",
            "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"
        },
        {
            "paperId": "be941015db55266715d897899f7a240b289dacf5",
            "title": "EigenDamage: Structured Pruning in the Kronecker-Factored Eigenbasis"
        },
        {
            "paperId": "9770fff7379a7ab9006b48939462354dda9a2053",
            "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"
        },
        {
            "paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad",
            "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"
        },
        {
            "paperId": "1536e8958697c5364f68b2e2448905dbbeb3a0ca",
            "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering"
        },
        {
            "paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"
        },
        {
            "paperId": "88bb0a28bb58d847183ec505dda89b63771bb495",
            "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"
        },
        {
            "paperId": "3108f96f80d129036f53684344f4058257b37c4b",
            "title": "DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset"
        },
        {
            "paperId": "efbd381493bb9636f489b965a2034d529cd56bcd",
            "title": "Pointer Sentinel Mixture Models"
        },
        {
            "paperId": "c2a1cb1612ba21e067a5c3ba478a8d73b796b77a",
            "title": "Pruning Filters for Efficient ConvNets"
        },
        {
            "paperId": "b0bd441a0cc04cdd0d0e469fe4c5184ee148a97d",
            "title": "Data-free Parameter Pruning for Deep Neural Networks"
        },
        {
            "paperId": "0e6824e137847be0599bb0032e37042ed2ef5045",
            "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"
        },
        {
            "paperId": "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff",
            "title": "Learning both Weights and Connections for Efficient Neural Network"
        },
        {
            "paperId": "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
            "title": "Building a Large Annotated Corpus of English: The Penn Treebank"
        },
        {
            "paperId": null,
            "title": "Stanford alpaca: An instruction-following llama model"
        },
        {
            "paperId": null,
            "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90% chatgpt"
        },
        {
            "paperId": "cbde5598c1a78285adfcfd77fb3636f5498987a0",
            "title": "EBERT: Efficient BERT Inference with Dynamic Structured Pruning"
        },
        {
            "paperId": null,
            "title": "Efficient bert inference with dynamic structured pruning. In Findings of the Association for Computational Linguistics: ACL-IJCNLP"
        },
        {
            "paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28",
            "title": "An Adversarial Winograd Schema Challenge at Scale"
        },
        {
            "paperId": "e7297db245c3feb1897720b173a59fe7e36babb7",
            "title": "Optimal Brain Damage"
        },
        {
            "paperId": null,
            "title": "A framework for few - shot language model evaluation . Version v 0 . 0 . 1"
        }
    ]
}