{
    "paperId": "d9f41589c8e20f570c84fb70b9231233985cfc22",
    "externalIds": {
        "MAG": "2786004705",
        "CorpusId": 35313060
    },
    "title": "GATED FAST WEIGHTS FOR ASSOCIATIVE RETRIEVAL",
    "abstract": "We improve previous end-to-end differentiable neural networks (NNs) with fast weight memories. A gate mechanism updates fast weights at every time step of a sequence through two separate outer-product-based matrices generated by slow parts of the net. The system is trained on a complex sequence to sequence variation of the Associative Retrieval Problem with roughly 70 times more temporal memory (i.e. time-varying variables) than similar-sized standard recurrent NNs (RNNs). In terms of accuracy and number of parameters, our architecture outperforms a variety of RNNs, including Long Short-Term Memory, Hypernetworks, and related fast weight architectures.",
    "venue": "",
    "year": 2018,
    "referenceCount": 18,
    "citationCount": 1,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work improves previous end-to-end differentiable neural networks with fast weight memories by trained on a complex sequence to sequence variation of the Associative Retrieval Problem with roughly 70 times more temporal memory than similar-sized standard recurrent NNs."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "35328044",
            "name": "Imanol Schlag"
        },
        {
            "authorId": "145341374",
            "name": "J. Schmidhuber"
        }
    ],
    "references": [
        {
            "paperId": "c91ae35dbcb6d479580ecd235eabf98374acdb55",
            "title": "Using Fast Weights to Attend to the Recent Past"
        },
        {
            "paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c",
            "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"
        },
        {
            "paperId": "d44efdc542f2cc5e196f04bc76bc783bfd7084af",
            "title": "Incorporating Nesterov Momentum into Adam"
        },
        {
            "paperId": "da398dd57a31a663eb572ec85db7cdfe2f70dc99",
            "title": "Associative Long Short-Term Memory"
        },
        {
            "paperId": "0d0b3ff23fbf1ec7a0dfebd923a3ef224306491a",
            "title": "Learning to Execute"
        },
        {
            "paperId": "193edd20cae92c6759c18ce93eeea96afd9528eb",
            "title": "Deep learning in neural networks: An overview"
        },
        {
            "paperId": "937d3a404b8870fb3ff3e243e6a0c6024eef491b",
            "title": "A Novel Connectionist System for Unconstrained Handwriting Recognition"
        },
        {
            "paperId": "11540131eae85b2e11d53df7f1360eeb6476e7f4",
            "title": "Learning to Forget: Continual Prediction with LSTM"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "61639af1a89c69094bcc0ed40fad752832b037c3",
            "title": "Reducing the Ratio Between Learning Complexity and Number of Time Varying Variables in Fully Recurrent Nets"
        },
        {
            "paperId": "7ee98330fb5969839d88bcabdb44d03848dc9d35",
            "title": "A \u2018Self-Referential\u2019 Weight Matrix"
        },
        {
            "paperId": "ef873b940a5acfeb45796fb6d98163300f8903e6",
            "title": "A Connectionist Symbol Manipulator that Discovers the Structure of Context-Free Languages"
        },
        {
            "paperId": "bc22e87a26d020215afe91c751e5bdaddd8e4922",
            "title": "Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks"
        },
        {
            "paperId": "9fccf16e5205eaa44aa084b785372df1a0b44255",
            "title": "Dynamic connections in neural networks"
        },
        {
            "paperId": "e62f7643f616aaad65ffd47155a53bfa325e455d",
            "title": "The Correlation Theory of Brain Function"
        },
        {
            "paperId": "30110856f45fde473f1903f686aa365cf70ed4c7",
            "title": "Learning Context-free Grammars: Capabilities and Limitations of a Recurrent Neural Network with an External Stack Memory (cid:3)"
        },
        {
            "paperId": "7257eacd80458e70c74494eb1b6759b52ff21399",
            "title": "Using fast weights to deblur old memories"
        },
        {
            "paperId": null,
            "title": "Google voice search: faster and more accurate"
        }
    ]
}