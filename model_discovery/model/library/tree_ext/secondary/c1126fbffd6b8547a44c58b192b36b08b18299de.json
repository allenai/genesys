{
    "paperId": "c1126fbffd6b8547a44c58b192b36b08b18299de",
    "externalIds": {
        "MAG": "2167839676",
        "ArXiv": "1410.5401",
        "DBLP": "journals/corr/GravesWD14",
        "CorpusId": 15299054
    },
    "title": "Neural Turing Machines",
    "abstract": "We extend the capabilities of neural networks by coupling them to external memory resources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-toend, allowing it to be efficiently trained with gradient descent. Preliminary results demonstrate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples.",
    "venue": "arXiv.org",
    "year": 2014,
    "referenceCount": 43,
    "citationCount": 2219,
    "influentialCitationCount": 227,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-toend, allowing it to be efficiently trained with gradient descent."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "1753223",
            "name": "Alex Graves"
        },
        {
            "authorId": "89504302",
            "name": "Greg Wayne"
        },
        {
            "authorId": "1841008",
            "name": "Ivo Danihelka"
        }
    ],
    "references": [
        {
            "paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "title": "Sequence to Sequence Learning with Neural Networks"
        },
        {
            "paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "title": "Neural Machine Translation by Jointly Learning to Align and Translate"
        },
        {
            "paperId": "0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f",
            "title": "Towards End-To-End Speech Recognition with Recurrent Neural Networks"
        },
        {
            "paperId": "6471fd1cbc081fb3b7b5b14d6ab9eaaba02b5c17",
            "title": "Generating Sequences With Recurrent Neural Networks"
        },
        {
            "paperId": "c943afb901840397b72d78d81b65d78e8137121d",
            "title": "The importance of mixed selectivity in complex cognitive tasks"
        },
        {
            "paperId": "03954dcf415daab102fcbfee95d0ec9e4532ec26",
            "title": "How to Build a Brain: A Neural Architecture for Biological Cognition"
        },
        {
            "paperId": "4177ec52d1b80ed57f2e72b0f9a42365f1a8598d",
            "title": "Speech recognition with deep recurrent neural networks"
        },
        {
            "paperId": "27e38351e48fe4b7da2775bf94341738bc4da07e",
            "title": "Semantic Compositionality through Recursive Matrix-Vector Spaces"
        },
        {
            "paperId": "93c20e38c85b69fc2d2eb314b3c1217913f7db11",
            "title": "Generating Text with Recurrent Neural Networks"
        },
        {
            "paperId": "965a6451ba5eca2dc17d0bacac4cabb551edb050",
            "title": "Memory and the Computational Brain: Why Cognitive Science will Transform Neuroscience"
        },
        {
            "paperId": "f1ff2cf822c0dabdf87f426230e9c60074924e04",
            "title": "Memory and the Computational Brain: Why Cognitive Science will Transform Neuroscience"
        },
        {
            "paperId": "5ce004245beab1302dde2c08fc93454c3cbc18d0",
            "title": "The Problem of Rapid Variable Creation"
        },
        {
            "paperId": "425931e434f6b370cc6cdd2db58873843def7d7f",
            "title": "Hyperdimensional Computing: An Introduction to Computing in Distributed Representation with High-Dimensional Random Vectors"
        },
        {
            "paperId": "bdecdb4a23f1381b4ca87ec7e4129e50214ffca7",
            "title": "Simple Substrates for Complex Cognition"
        },
        {
            "paperId": "17452b482179fd45aa958b1b8b440fa4c117be6d",
            "title": "Banishing the homunculus: Making working memory work"
        },
        {
            "paperId": "eda6ad74daa02349feba9c63dc2cf22eece60f90",
            "title": "The evolution of the language faculty: Clarifications and implications"
        },
        {
            "paperId": "de218b3b04ebc223f0740a809f8e1275b182bdc7",
            "title": "The nature of the language faculty and its implications for evolution of language (Reply to Fitch, Hauser, and Chomsky)"
        },
        {
            "paperId": "fd38622d5e7f433d442a41eeedfea0470bdab566",
            "title": "Introduction to real-time ray tracing"
        },
        {
            "paperId": "cf7d7684600d3ebe916ca093eda123a9dad41459",
            "title": "Parallel & distributed processing"
        },
        {
            "paperId": "86c97493c2c7245afefd0336824eb48669923ddd",
            "title": "Time constraints and resource sharing in adults' working memory spans."
        },
        {
            "paperId": "c3577312cb178cc93459bda92e37076e1fa9af88",
            "title": "Holographic Reduced Representation: Distributed Representation for Cognitive Structures"
        },
        {
            "paperId": "1a8cc98ad8f023a9078a5ace98e777a88239854d",
            "title": "The cognitive revolution: a historical perspective"
        },
        {
            "paperId": "8d46fb7cdeab9be071b0bc134aee5ef942d704b2",
            "title": "Synaptic Basis of Cortical Persistent Activity: the Importance of NMDA Receptors to Working Memory"
        },
        {
            "paperId": "d8a56b528822db211a5ad6dbe9e7d36fb77e486a",
            "title": "Continuous attractors and oculomotor control"
        },
        {
            "paperId": "a5eb96540ef53b49eac2246d6b13635fe6e54451",
            "title": "A general framework for adaptive processing of data structures"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "97901b8b7ece99faea15a301186f4a85a5160310",
            "title": "Cellular basis of working memory"
        },
        {
            "paperId": "5f66b5fe5dcb38858fc5cabe23f8681ec3941bbf",
            "title": "First draft of a report on the EDVAC"
        },
        {
            "paperId": "17594df98c222217a11510dd454ba52a5a737378",
            "title": "On the computational power of neural nets"
        },
        {
            "paperId": "6a835df43fdc2f79126319f6fa033bb42147c6f6",
            "title": "Recursive Distributed Representations"
        },
        {
            "paperId": "f70d2ff213a964621cb080f141ceed6359b84199",
            "title": "BoltzCONS: Dynamic Symbol Structures in a Connectionist Network"
        },
        {
            "paperId": "56cbfcbfffd8c54bd8477d10b6e0e17e097b97c7",
            "title": "Connectionism and cognitive architecture: A critical analysis"
        },
        {
            "paperId": "98b4d4e24aab57ab4e1124ff8106909050645cfa",
            "title": "Neural networks and physical systems with emergent collective computational abilities."
        },
        {
            "paperId": "6e785a402a60353e6e22d6883d3998940dcaea96",
            "title": "Three models for the description of language"
        },
        {
            "paperId": "360ca02e6f5a5e1af3dce4866a257aafc2d6d6f5",
            "title": "Machine learning - a probabilistic perspective"
        },
        {
            "paperId": "cef4692d7d5f33b0d819079642c69778497415e6",
            "title": "3 Learning distributed representations of concepts"
        },
        {
            "paperId": "2e5f2b57f4c476dd69dc22ccdf547e48f40a994c",
            "title": "Gradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term Dependencies"
        },
        {
            "paperId": "a6383f155fa9d3e9b15092bfefbf613f982eb263",
            "title": "The Algebraic Mind: Integrating Connectionism and Cognitive Science"
        },
        {
            "paperId": "30110856f45fde473f1903f686aa365cf70ed4c7",
            "title": "Learning Context-free Grammars: Capabilities and Limitations of a Recurrent Neural Network with an External Stack Memory (cid:3)"
        },
        {
            "paperId": "9438172bfbb74a6a4ea4242b180d4335bb1f18b7",
            "title": "Tensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems"
        },
        {
            "paperId": "1c771595221341d5b0647921b26e229fc7887395",
            "title": "Computation: Finite and Infinite Machines"
        },
        {
            "paperId": "a15174ed603bae1b101c4655111bb511787b95b4",
            "title": "The magical number seven plus or minus two: some limits on our capacity for processing information."
        },
        {
            "paperId": "a6bcf0e9b5034c4c9cbea839baadd69a42b05cc1",
            "title": "Learning curves for stochastic gradient descent in linear feedforward networks"
        }
    ]
}