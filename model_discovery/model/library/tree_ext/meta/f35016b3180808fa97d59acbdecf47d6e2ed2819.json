{"paperId": "f35016b3180808fa97d59acbdecf47d6e2ed2819", "title": "Rethinking Vision Transformers for MobileNet Size and Speed", "abstract": "With the success of Vision Transformers (ViTs) in computer vision tasks, recent arts try to optimize the performance and complexity of ViTs to enable efficient deployment on mobile devices. Multiple approaches are proposed to accelerate attention mechanism, improve inefficient designs, or incorporate mobile-friendly lightweight convolutions to form hybrid architectures. However, ViT and its variants still have higher latency or considerably more parameters than lightweight CNNs, even true for the years-old MobileNet. In practice, latency and size are both crucial for efficient deployment on resource-constraint hardware. In this work, we investigate a central question, can transformer models run as fast as MobileNet and maintain a similar size? We revisit the design choices of ViTs and propose a novel supernet with low latency and high parameter efficiency. We further introduce a novel fine-grained joint search strategy for transformer models that can find efficient architectures by optimizing latency and number of parameters simultaneously. The proposed models, EfficientFormerV2, achieve 3.5% higher top-1 accuracy than MobileNetV2 on ImageNet-1K with similar latency and parameters. This work demonstrate that properly designed and optimized vision transformers can achieve high performance even with MobileNet-level size and speed 1.", "venue": "IEEE International Conference on Computer Vision", "year": 2022, "citationCount": 74, "influentialCitationCount": 14, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work revisits the design choices of ViTs and proposes a novel supernet with low latency and high parameter efficiency, and introduces a novel fine-grained joint search strategy for transformer models that can find efficient architectures by optimizing latency and number of parameters simultaneously."}, "embedding": {"model": "specter_v2", "vector": [0.4556003212928772, 0.336713582277298, -0.5276550054550171, 0.4942082464694977, -0.20001336932182312, -0.00851893424987793, 0.5701555013656616, -0.5870770215988159, -0.7741097807884216, -0.7985819578170776, -0.004887801129370928, -0.05165018141269684, 0.6029237508773804, -0.09944214671850204, -0.084168940782547, 0.30712634325027466, -0.4913613796234131, 0.0375591441988945, 0.6074977517127991, -0.3183850944042206, 0.10023733228445053, -0.4346587657928467, -1.5926618576049805, 0.010715956799685955, 0.1994095891714096, 1.5028455257415771, 0.6537374258041382, 1.2147984504699707, -0.1544262021780014, 0.4254061281681061, 0.5637291669845581, -0.5880914926528931, 0.3738352358341217, 0.464357852935791, -0.3958878219127655, -0.21757543087005615, 1.1147547960281372, -0.3353191912174225, -0.48730552196502686, 1.0847171545028687, 0.030098125338554382, 0.11341001838445663, 0.04011685773730278, -0.9269964694976807, -0.06940148025751114, -0.050344809889793396, 0.5713883638381958, 0.87334805727005, -1.0098650455474854, 0.05643731728196144, 1.2736868858337402, -1.1155844926834106, -0.152922123670578, 1.5282293558120728, 0.5955981016159058, 0.17584343254566193, 0.15081417560577393, -0.49124759435653687, 0.8524958491325378, 0.3249945342540741, -0.35865020751953125, -0.6044160723686218, -0.07307738065719604, -0.03754108026623726, 1.8218811750411987, -0.7418750524520874, 0.37398189306259155, 0.5389822721481323, 0.43265190720558167, 1.1083769798278809, -0.18896962702274323, -0.48146477341651917, -0.13505536317825317, -0.5025168657302856, 0.20549096167087555, 0.9564372897148132, 0.12143358588218689, -0.15077170729637146, -0.590617835521698, 0.08569301664829254, 0.7516923546791077, 0.3291095793247223, 0.3577989935874939, -0.08369842171669006, -0.5153824687004089, 0.7222470641136169, 1.0406955480575562, 0.4191390872001648, -0.6191535592079163, 1.3092830181121826, 0.675853967666626, 0.13925713300704956, -0.19186632335186005, 0.36038264632225037, -0.20086787641048431, 0.6857662796974182, -0.7620136141777039, 0.07643590122461319, -0.4015905559062958, 0.8721266984939575, -0.2947814464569092, 0.17062455415725708, -0.4119883179664612, 0.08137111365795135, 1.1421864032745361, 0.5098572373390198, 0.2891819179058075, -0.6837398409843445, 0.36996594071388245, -0.7041866183280945, -0.1278938204050064, -0.7021725177764893, 0.12555520236492157, -0.12870056927204132, -0.9716132283210754, -0.8004246950149536, -0.43724295496940613, 0.5987418293952942, -1.0972177982330322, 0.25978532433509827, -0.40015438199043274, 0.49947693943977356, -0.1421225666999817, 0.34805598855018616, 0.6821409463882446, 0.42906248569488525, 0.20401804149150848, 0.48402947187423706, 1.5228712558746338, -1.4062139987945557, -0.1113356426358223, -1.2607985734939575, -0.009498137049376965, -0.4244201183319092, 0.5477787852287292, -0.13359220325946808, -1.2881075143814087, -1.430525779724121, -0.9884799718856812, -0.045683130621910095, -0.6966416835784912, -0.08259810507297516, 1.1392183303833008, 0.270086407661438, -1.5807589292526245, 0.4168928563594818, -0.4254550337791443, -0.6224397420883179, 0.5100278854370117, 0.29570186138153076, 0.5946958661079407, -0.26358890533447266, -0.7413780689239502, 0.3061986565589905, -0.34938210248947144, -0.5627047419548035, -0.6596531867980957, -0.4844426214694977, -0.8288399577140808, 0.05071726813912392, 0.22078709304332733, -1.0867992639541626, 1.2882753610610962, -0.263007789850235, -0.6176087856292725, 0.7896958589553833, -0.2545093894004822, -0.2389114797115326, -0.08582107722759247, 0.050309982150793076, -0.22239899635314941, 0.08053324371576309, -0.20464101433753967, 0.9017584323883057, 1.146064043045044, 0.20505745708942413, -0.4353492259979248, 0.21539804339408875, 0.08871457725763321, -0.3688468337059021, -0.3739498257637024, 1.0294355154037476, -0.8657698631286621, -0.004815032705664635, 0.4177599549293518, 0.6882577538490295, -0.35661521553993225, 0.2773132622241974, -0.019761105999350548, -0.6814483404159546, 0.7178547382354736, 0.41569069027900696, 0.5445560216903687, -0.734734296798706, -1.0234432220458984, -0.05145024135708809, 0.51507568359375, 0.06248040497303009, -1.1494396924972534, -0.1308496743440628, -0.1856096237897873, 0.19477930665016174, 0.6760432124137878, -0.8004060387611389, -0.12132661044597626, -0.5656318068504333, -0.6100268959999084, -0.1463516354560852, -0.006514031905680895, 1.3956632614135742, -0.6801891326904297, -0.20752085745334625, 0.04985487833619118, 0.36163902282714844, -1.1254680156707764, 0.7991810441017151, -0.38735678791999817, -0.34338030219078064, -0.24328207969665527, 0.37823131680488586, 0.010940265841782093, -0.7888742685317993, 0.4366046190261841, -1.0118292570114136, -0.1531168818473816, 0.5380523204803467, -0.07834871858358383, 1.2793585062026978, -0.3165121078491211, 0.7060496807098389, 0.12173626571893692, -0.8317323327064514, 0.48610830307006836, 0.04826020449399948, -0.2705024778842926, -0.8266667723655701, 0.6079744100570679, 0.29496049880981445, -0.8456016778945923, 0.44054341316223145, 0.9916860461235046, 1.429642915725708, -0.24519775807857513, -0.3243063986301422, 0.5788233280181885, -0.2714386582374573, -0.13096830248832703, 0.2827568054199219, 0.8570485711097717, -0.08856340497732162, 0.11921429634094238, -0.30896541476249695, 0.2269926369190216, -1.024249792098999, -0.10978180915117264, 0.9220921397209167, 0.1383209377527237, 0.7126039862632751, 0.4944385290145874, -1.0790214538574219, -0.3504410684108734, -0.12229222059249878, 0.676458477973938, 1.0969687700271606, 0.1585923582315445, -0.022226257249712944, -0.6388164758682251, -0.3181627690792084, -0.6585584282875061, -0.8903087377548218, -0.0849059596657753, 0.016382664442062378, -0.2213597446680069, -0.8090240955352783, 1.0120643377304077, 0.0681450143456459, 1.5522346496582031, -0.7627728581428528, -1.0504415035247803, -0.5167499780654907, -0.011205879040062428, -1.0808117389678955, -0.6782194972038269, 0.06848728656768799, -0.7294549942016602, -0.39540621638298035, 0.023341502994298935, -0.48325809836387634, -0.13746413588523865, 0.0036728137638419867, 0.8691847324371338, -0.03711225837469101, -0.38664892315864563, 0.39845651388168335, 0.8020070195198059, -0.5109179615974426, 0.031418733298778534, 0.28977885842323303, 0.04286160692572594, -0.17231476306915283, 0.021683521568775177, 0.2118917852640152, -0.5150926113128662, -0.0023814800661057234, -0.21710294485092163, -0.0936625599861145, 0.11955897510051727, -0.11530345678329468, 0.9579497575759888, -0.4651103913784027, -0.1330300271511078, -0.5459566116333008, 0.6353856325149536, 0.5266445875167847, -0.841484785079956, 0.2908323109149933, -0.8625510334968567, -0.2683146595954895, 0.07822983711957932, -0.8077595233917236, 0.29747405648231506, -0.9459616541862488, 0.3823721706867218, -1.0045047998428345, 0.12147636711597443, -0.3299725353717804, 0.2259620577096939, -0.36591145396232605, 0.34540531039237976, 0.3921497166156769, 0.22473017871379852, 0.20455166697502136, 0.21640801429748535, -1.187044382095337, 0.8290532827377319, 0.4011707603931427, 0.00973772257566452, 0.0444183386862278, 0.025464892387390137, -0.8158058524131775, -0.3886641263961792, -0.3179317116737366, 0.11156308650970459, -0.5400059223175049, 0.35185104608535767, -0.7621160745620728, -1.0706018209457397, 0.29099538922309875, -1.148935079574585, -0.2124476581811905, 0.26119229197502136, -0.19326528906822205, -0.1753741353750229, -1.1356298923492432, -0.8699203133583069, -0.37009215354919434, -1.1987000703811646, -1.5605489015579224, 0.33204567432403564, 0.21132618188858032, -0.16072414815425873, -0.3592304289340973, -0.4436374008655548, -0.4499262571334839, 1.252657175064087, -0.5163714289665222, 0.5472592711448669, 0.26264479756355286, -0.8006754517555237, -0.016031766310334206, -0.3899308145046234, 0.14927037060260773, -0.590587854385376, 0.3905845284461975, -1.188044786453247, 0.3497738838195801, -0.45070213079452515, -0.3357733190059662, 0.841655433177948, 0.7699269652366638, 0.7368800640106201, 0.013775275088846684, -0.4738079011440277, 0.919948160648346, 1.6156120300292969, -0.771072506904602, 0.6618079543113708, 0.46204352378845215, 0.984298586845398, -0.33567583560943604, -0.14456084370613098, 0.39837467670440674, 0.48645204305648804, 0.10037563741207123, 0.9004356265068054, -0.4782961905002594, -0.5227656960487366, -0.6596705317497253, 0.23730842769145966, 1.1772396564483643, 0.3004480302333832, -0.06539008021354675, -0.6696056127548218, 0.7046061158180237, -1.1666209697723389, -0.7928551435470581, 0.7021778225898743, 0.7625938653945923, -0.20445516705513, 0.08820412307977676, -0.2183258831501007, -0.27693983912467957, 0.676649272441864, 0.9462332725524902, -0.35771626234054565, -0.8731369376182556, -0.005563952494412661, 0.788217306137085, 0.6895666718482971, 0.47727593779563904, -0.19938889145851135, 1.0892056226730347, 14.29522705078125, 0.9832009077072144, -0.5043882131576538, 0.6597234606742859, 0.62889164686203, 0.37149062752723694, -0.3378759026527405, 0.17310239374637604, -1.2543282508850098, -0.26620054244995117, 0.9880329370498657, 0.5218796730041504, 0.4323098957538605, 0.3772856891155243, -0.15043123066425323, 0.1304113268852234, -0.17719301581382751, 1.0642545223236084, 0.5191246867179871, -1.7641395330429077, 0.43550944328308105, 0.221506267786026, 0.18031160533428192, 0.9140259623527527, 1.07146155834198, 0.5698205828666687, 0.32322731614112854, -0.2544328570365906, 0.6265788674354553, 0.08802742511034012, 1.578752875328064, 0.07592713087797165, 0.29042500257492065, -0.03254147991538048, -1.4517319202423096, 0.2360270470380783, -0.7693990468978882, -1.2207062244415283, -0.16108782589435577, -0.0029386943206191063, -0.2810632288455963, -0.9002113938331604, 0.3690178394317627, 0.9275000691413879, -0.1357063204050064, 0.641804575920105, -0.2524205148220062, 0.19628962874412537, -0.23929065465927124, -0.16411057114601135, 0.508924663066864, 0.746539831161499, -0.12840896844863892, -0.3507038652896881, 0.018862998113036156, -0.4015997052192688, 0.20724719762802124, 0.34595006704330444, -0.5987958312034607, -0.6650350093841553, -0.3686884343624115, 0.08578262478113174, 0.07067369669675827, 1.0349011421203613, -0.2878325879573822, 0.25294560194015503, -0.07731129229068756, 0.2835142910480499, 0.26788604259490967, 0.20786583423614502, -0.7605964541435242, 0.002154396381229162, 0.8123418092727661, -0.5392563343048096, 0.20257475972175598, 0.5246429443359375, -0.33658698201179504, -0.7114145755767822, -0.7618188858032227, -0.4869063198566437, 0.3831610083580017, -1.0520497560501099, -0.008634896017611027, 1.0684819221496582, -0.5947503447532654, -0.2002534121274948, 0.9035491943359375, -0.9600778818130493, -0.5753868818283081, 0.2092367261648178, -1.8260530233383179, -1.007848858833313, -0.06487929821014404, 0.21902653574943542, -0.07848315685987473, -0.018321480602025986, 1.0269191265106201, 0.08143068104982376, -0.025030463933944702, 0.281021386384964, -0.50643390417099, -0.20685778558254242, -0.2733803689479828, -0.1368616819381714, 1.4226720333099365, 0.5720109343528748, -0.02113354206085205, -0.2871333956718445, -0.13771288096904755, 0.5095503330230713, -0.8499981760978699, -0.07097487151622772, 0.7785000801086426, -0.6695528030395508, -0.18987946212291718, -0.5913608074188232, -0.20095178484916687, 0.382582426071167, 0.5950636863708496, 0.08797763288021088, -0.37741363048553467, 0.0030386310536414385, -1.0541903972625732, -0.49100980162620544, -0.6846427917480469, 0.40072330832481384, 0.514695942401886, -0.7998331189155579, 0.022559642791748047, -0.3502039909362793, 0.6195498108863831, -0.7577385902404785, -0.08426758646965027, -0.1657422035932541, 0.5331695675849915, -0.3580157458782196, 1.5233995914459229, -0.03577248007059097, 0.6353163123130798, 1.0076637268066406, -0.21695470809936523, -0.3875059485435486, -0.03578667715191841, -0.8434056639671326, 0.34495431184768677, -0.18016472458839417, 0.3778565526008606, -0.8633092641830444, 0.3053821325302124, 0.37837886810302734, 0.3365602195262909, -0.4799312949180603, -0.44527968764305115, -0.005703460890799761, -0.5534495115280151, -0.8115636110305786, 0.37000393867492676, -0.4090721607208252, -0.25474706292152405, 0.09336480498313904, 0.4327404797077179, 0.42351600527763367, 0.19805221259593964, -0.6998333930969238, 0.35808372497558594, -0.13206417858600616, -0.012383419089019299, -0.7155188322067261, -0.9420754313468933, -1.5480406284332275, -0.3886302411556244, -0.8252529501914978, -0.2630789577960968, -0.8623260855674744, -0.7514038681983948, -0.022574445232748985, -0.4669007956981659, 0.11919273436069489, 0.42173272371292114, 0.11285027861595154, -0.03253300115466118, -0.5177389979362488, -0.9215532541275024, 0.6432679891586304, 1.1870652437210083, -0.8035992980003357, 0.3602515161037445, -0.09476438909769058, -0.03491257131099701, 0.7535148859024048, 0.28600531816482544, -0.13908113539218903, -0.9644192457199097, -1.3267120122909546, 0.4502891004085541, -0.29495668411254883, 0.2310853898525238, -1.073272943496704, 1.2016149759292603, 0.421080082654953, -0.26992878317832947, -0.06910807639360428, 0.49875330924987793, -0.7693450450897217, -0.870602011680603, 0.6166651844978333, -0.3114760220050812, 0.5641088485717773, 0.35702693462371826, -0.6165578961372375, 0.03046080656349659, 1.0028516054153442, 0.19753941893577576, -1.010478138923645, -1.4783951044082642, 0.6015017032623291, -0.46090447902679443, 0.3312906324863434, -0.6088067889213562, -0.31955745816230774, -1.4177004098892212, -0.2302928864955902, 0.2807365953922272, 0.2525657117366791, -0.3778465688228607, 0.7224310040473938, 0.9689956307411194, -0.8296204805374146, 0.4621853828430176, 0.4589780271053314, -0.17422126233577728, -0.15192066133022308, 0.3728298544883728, 0.7542966604232788, -0.6472976207733154, 0.37341535091400146, 0.017395291477441788, 0.10465135425329208, -0.7918927669525146, 0.43854743242263794, 0.7749077081680298, -0.42521172761917114, -0.22298891842365265, 1.2285703420639038, -0.19564849138259888, -0.5289448499679565, 0.36703577637672424, -1.5144703388214111, -0.38608917593955994, -0.15618443489074707, 0.5978459119796753, 0.005242017097771168, 0.2918761968612671, 0.383597195148468, -0.7611761689186096, 0.4891999363899231, 0.040979769080877304, -0.39498239755630493, 0.04806362837553024, 0.09849417954683304, -0.19499742984771729, 0.07159110903739929, 0.7200010418891907, -1.0872925519943237, -0.9158172011375427, -0.9654435515403748, -0.6518367528915405, -0.096701979637146, 0.6116797924041748, 0.005380042362958193, -1.1987793445587158, 0.9026391506195068, 0.7474282383918762, 0.012850511819124222, 0.60123211145401, -0.07426229864358902, 0.3758884072303772, 0.6389109492301941, 0.27557405829429626, -0.3163670003414154, -0.29790985584259033, 1.3288530111312866, 0.7856263518333435, -0.793193519115448, 0.14515739679336548, -0.0662819892168045, -0.44881829619407654, 0.5306909084320068, 0.4665662348270416, -0.6010362505912781, 0.8979895710945129, 0.06547354906797409, -0.14424960315227509, 0.056104663759469986, -1.0196633338928223, -0.6041457653045654, 0.7344644665718079, 1.0353672504425049, 0.2397940307855606, -0.03203863650560379, 0.4900491237640381, 0.6138150691986084, 0.1949903964996338, -0.15894156694412231, 0.07704691588878632, 0.19494977593421936, -0.18484419584274292, 0.5916932821273804, -0.2561717629432678, 0.4979599416255951, -0.6030586361885071, -1.082623839378357, 0.2743043899536133, 0.5933001041412354, 0.2200322151184082, 0.616739809513092, 1.206047534942627, -0.24520352482795715, 0.7726854681968689, -0.40943580865859985, 0.6786960959434509, -0.09543146938085556, -0.29541876912117004, 0.025099974125623703, -0.8512532114982605, -0.3866141140460968, -0.037509046494960785, -0.29304954409599304, 0.020276661962270737, -0.7603474259376526, 0.3718867003917694, -0.3990212678909302, 0.3269813060760498, 0.7215099930763245, 0.4612971246242523, 0.8027774095535278, -0.4854477345943451, -1.0033283233642578, -0.28345775604248047, -0.507698118686676, 0.45970362424850464, -0.8919771313667297, -0.05077890306711197, -0.13751278817653656, -0.12830446660518646, -0.24129125475883484]}, "authors": [{"authorId": "1527091497", "name": "Yanyu Li"}, {"authorId": "2218083176", "name": "Ju Hu"}, {"authorId": "2167854921", "name": "Yang Wen"}, {"authorId": "143998839", "name": "Georgios Evangelidis"}, {"authorId": "151452200", "name": "Kamyar Salahi"}, {"authorId": "2136922252", "name": "Yanzhi Wang"}, {"authorId": "145582202", "name": "S. Tulyakov"}, {"authorId": "2111473627", "name": "Jian Ren"}], "references": [{"paperId": "ec139916edd6feb9b3cb3a0325ca96e21dbb0147", "title": "Hydra Attention: Efficient Attention with Many Heads"}, {"paperId": "a4b728dbbf5afdc231afb95ad4e5c2ececdefc48", "title": "Next-ViT: Next Generation Vision Transformer for Efficient Deployment in Realistic Industrial Scenarios"}, {"paperId": "76d40153acfbb35a7eb8272a4215854cafa10e78", "title": "PLATON: Pruning Large Transformer Models with Upper Confidence Bound of Weight Importance"}, {"paperId": "05b7bd47fa5cbe10497c49004b57eb5ab4fdd0b4", "title": "EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for Mobile Vision Applications"}, {"paperId": "066c143b427571fb5568f2c581ea9066478d2e55", "title": "Separable Self-attention for Mobile Vision Transformers"}, {"paperId": "dd1139cfc609c2f3263d02e97176d5275caebc0a", "title": "EfficientFormer: Vision Transformers at MobileNet Speed"}, {"paperId": "bf6ce546c589fa8054b3972b266532664914bd21", "title": "Fast Vision Transformers with HiLo Attention"}, {"paperId": "dbf6e95cb618f207f029276a6df11f4a9a6313d4", "title": "Inception Transformer"}, {"paperId": "b4da9f3505e22d3e766ba21890285b822dc71599", "title": "EdgeViTs: Competing Light-weight CNNs on Mobile Devices with Vision Transformers"}, {"paperId": "d2f63b56fc6bc373f5c023454c2b253326962865", "title": "DeiT III: Revenge of the ViT"}, {"paperId": "834b5b5b25e99186f900a7eb1c8d641caf024fcb", "title": "Are Multimodal Transformers Robust to Missing Modality?"}, {"paperId": "f634a09747e4ca11754a9bfdccf7485c884f9f86", "title": "TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation"}, {"paperId": "2ad12a7be5eaf339a98c4defd8669e11fe726acc", "title": "MaxViT: Multi-Axis Vision Transformer"}, {"paperId": "dae903091d2c5f82c4595e53e8144ccce93f8fb9", "title": "SepViT: Separable Vision Transformer"}, {"paperId": "28ed0086dd0f51a8965f7e952b6ee933cdf44179", "title": "Training-free Transformer Architecture Search"}, {"paperId": "f0725ad73655513e49c23e757a6a6f5dad6505fa", "title": "Show Me What and Tell Me How: Video Synthesis via Multimodal Conditioning"}, {"paperId": "202967f77c4384bce80eaf2fa5737259008267d3", "title": "Learning to Merge Tokens in Vision Transformers"}, {"paperId": "d31a2a1b1d2378030aed23f6888bce02897e20e7", "title": "F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization"}, {"paperId": "5ab70d95ca49702a3dd49b39d9396d8136b52311", "title": "Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space"}, {"paperId": "e5cb26148791b57bfd36aa26ce2401e231d01b57", "title": "Vision Transformer with Deformable Attention"}, {"paperId": "2a4024163826151303aa0bbb18320b8a67167794", "title": "Pale Transformer: A General Vision Transformer Backbone with Pale-Shaped Attention"}, {"paperId": "164e41a60120917d13fb69e183ee3c996b6c9414", "title": "Vision Transformer for Small-Size Datasets"}, {"paperId": "658a017302d29e4acf4ca789cb5d9f27983717ff", "title": "Masked-attention Mask Transformer for Universal Image Segmentation"}, {"paperId": "9137efc758f80dd22bb56f82cca5c94f78a5db3e", "title": "MViTv2: Improved Multiscale Vision Transformers for Classification and Detection"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "cb99f6f2bdd72b6a23be6af5488ed61e4fdc4fe3", "title": "FBNetV5: Neural Architecture Search for Multiple Tasks in One Run"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "aa8198b922216645c4be46408524f431ad571e78", "title": "Improving Visual Quality of Image Synthesis by A Token-based Generator with Transformers"}, {"paperId": "cbb9446dcb53bb5efda262942f7c7b0f5b3b7195", "title": "UniNet: Unified Architecture Search with Convolution, Transformer, and MLP"}, {"paperId": "da74a10824193be9d3889ce0d6ed4c6f8ee48b9e", "title": "MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer"}, {"paperId": "a66686e60a3eda0c606e036403cf0a07a5962595", "title": "Mobile-Former: Bridging MobileNet and Transformer"}, {"paperId": "a5c41f188b0eb0acb444cb4899bf6af378ee9ede", "title": "CrossFormer: A Versatile Vision Transformer Hinging on Cross-scale Attention"}, {"paperId": "0b036cd5dfc49d835d0c759c8ca31d89f2410e65", "title": "CMT: Convolutional Neural Networks Meet Vision Transformers"}, {"paperId": "bd163f27b409a4d903632009d38df77cfd70a437", "title": "ViTGAN: Training GANs with Vision Transformers"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "d645bd08fc19d52164695f9cd5ae863345459a06", "title": "AutoFormer: Searching Transformers for Visual Recognition"}, {"paperId": "c295391129426d89ec58cebb049d1cd2e976deec", "title": "Post-Training Quantization for Vision Transformer"}, {"paperId": "94eae578e6af3382f6449506965639f18aab3fa0", "title": "Video Swin Transformer"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "6b6ffb94626e672caffafc77097491d9ee7a8682", "title": "On the Connection between Local Attention and Dynamic Depth-wise Convolution"}, {"paperId": "2e8149dafb864ec3675087c99bf5572fcf4eb170", "title": "RegionViT: Regional-to-Local Attention for Vision Transformers"}, {"paperId": "dbdcabd0444ad50b68ee09e30f39b66e9068f5d2", "title": "DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification"}, {"paperId": "74d9586dc0593cddae3223a841213c9ea7038bf6", "title": "FBNetV3: Joint Architecture-Recipe Search using Predictor Pretraining"}, {"paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60", "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"}, {"paperId": "f80775a79d42a1ddfc0df808ea760c57af4949d0", "title": "Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding"}, {"paperId": "48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5", "title": "ResMLP: Feedforward Networks for Image Classification With Data-Efficient Training"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "ad4a0938c48e61b7827869e4ac3baffd0aefab35", "title": "Emerging Properties in Self-Supervised Vision Transformers"}, {"paperId": "14c52ffa7ea9c1971d5d82ea369c946c98d056a9", "title": "LocalViT: Bringing Locality to Vision Transformers"}, {"paperId": "4b06c7e29280b1c6bc05c9df39023b48fef02c93", "title": "Escaping the Big Data Paradigm with Compact Transformers"}, {"paperId": "003326a15fc4a8833785a47a741d7712474fa256", "title": "LeViT: a Vision Transformer in ConvNet\u2019s Clothing for Faster Inference"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "40f4d7fe800810288a80f84cdb357a8f4c28e880", "title": "Rethinking Spatial Dimensions of Vision Transformers"}, {"paperId": "0eff37167876356da2163b2e396df2719adf7de9", "title": "CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification"}, {"paperId": "81cb286b73a69846cf5e02dd7d58d4694453194e", "title": "Teachers Do More Than Teach: Compressing Image-to-Image Models"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "7b8f3f65a98340d6e5ab94bd9a4ccb8f75704fd8", "title": "I-BERT: Integer-only BERT Quantization"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "47f7ec3d0a5e6e83b6768ece35206a94dc81919c", "title": "Taming Transformers for High-Resolution Image Synthesis"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "38a6d0c2f5231b95d626a24435f18134b4254898", "title": "EagleEye: Fast Sub-net Evaluation for Efficient Neural Network Pruning"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "26080498fb851b6239114f0871a4957bea3d3684", "title": "Talking-Heads Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "5e19eba1e6644f7c83f607383d256deea71f87ae", "title": "Searching for MobileNetV3"}, {"paperId": "450a99659e083f5ac2f0fef9abbd9336b3470c3b", "title": "Universally Slimmable Networks and Improved Training Techniques"}, {"paperId": "a84906dbd4d6640f918d0b6ed2a7313dda0d55f1", "title": "Panoptic Feature Pyramid Networks"}, {"paperId": "120ffccea4787b88f78b55b9302891ff96cb4228", "title": "Slimmable Neural Networks"}, {"paperId": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4", "title": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "b8a919f4a2aaa97bef19aa43e01f8bc347693b73", "title": "NASViT: Neural Architecture Search for Efficient Vision Transformers with Gradient Conflict aware Supernet Training"}, {"paperId": "7d2a78a1f713b71c3a337247d042c5c2f0b2da84", "title": "EfficientViT: Enhanced Linear Attention for High-Resolution Low-Computation Visual Recognition"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "f715d91fc59131eb4236ad8630a761d669a0e2ba", "title": "ATS: Adaptive Token Sampling For Efficient Vision Transformers"}, {"paperId": "03ce51e5e854faa614e79afe4dab8baeb5f73980", "title": "Twins: Revisiting Spatial Attention Design in Vision Transformers"}, {"paperId": "9af62668cb87f11fffb53a194588c8158fde6b00", "title": "DynamicViT: Ef\ufb01cient Vision Transformers with Dynamic Token Sparsi\ufb01cation"}, {"paperId": null, "title": "conference on machine learning"}, {"paperId": null, "title": "Pytorch image models. https://github.com/rwightman/ pytorch-image-models, 2019"}, {"paperId": null, "title": "The detailed network architectures for Ef\ufb01cientFormerV2-S0, S1, S2, and L are provided in Tab. 9. We report the stage resolution, width, depth, and per-block expansion ratios"}, {"paperId": null, "title": "Coremltools"}, {"paperId": null, "title": "16852 applicable license agreement with IEEE. Restrictions apply"}]}