{"paperId": "b31a5884a8ebe96b6300839b28608b97f8f8ef76", "title": "LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding", "abstract": "Although large language models (LLMs) demonstrate impressive performance for many language tasks, most of them can only handle texts a few thousand tokens long, limiting their applications on longer sequence inputs, such as books, reports, and codebases. Recent works have proposed methods to improve LLMs' long context capabilities by extending context windows and more sophisticated memory mechanisms. However, comprehensive benchmarks tailored for evaluating long context understanding are lacking. In this paper, we introduce LongBench, the first bilingual, multi-task benchmark for long context understanding, enabling a more rigorous evaluation of long context understanding. LongBench comprises 21 datasets across 6 task categories in both English and Chinese, with an average length of 6,711 words (English) and 13,386 characters (Chinese). These tasks cover key long-text application areas including single-doc QA, multi-doc QA, summarization, few-shot learning, synthetic tasks, and code completion. All datasets in LongBench are standardized into a unified format, allowing for effortless automatic evaluation of LLMs. Upon comprehensive evaluation of 8 LLMs on LongBench, we find that: (1) Commercial model (GPT-3.5-Turbo-16k) outperforms other open-sourced models, but still struggles on longer contexts. (2) Scaled position embedding and fine-tuning on longer sequences lead to substantial improvement on long context understanding. (3) Context compression technique such as retrieval brings improvement for model with weak ability on long contexts, but the performance still lags behind models that have strong long context understanding capability. The code and datasets are available at https://github.com/THUDM/LongBench.", "venue": "arXiv.org", "year": 2023, "citationCount": 168, "influentialCitationCount": 47, "openAccessPdf": {"url": "https://arxiv.org/pdf/2308.14508", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper introduces LongBench, the first bilingual, multi-task benchmark for long context understanding, enabling a more rigorous evaluation of long context understandings of large language models."}, "embedding": {"model": "specter_v2", "vector": [-0.0656030997633934, -0.07245593518018723, -0.2409592717885971, -0.3272181749343872, -0.8553151488304138, -0.5835596919059753, 0.7098983526229858, 0.048690930008888245, -0.3861417770385742, 0.056623585522174835, 1.049802541732788, -0.23953068256378174, 0.4803396463394165, 0.2612001299858093, -0.017982369288802147, -0.1303359866142273, -0.8414646983146667, 0.3835568130016327, -0.5010640025138855, -0.444837361574173, 0.3706856966018677, -1.1285836696624756, -0.3318402171134949, 0.4874339699745178, 0.681330144405365, -0.17213071882724762, 0.517716109752655, 0.9965187907218933, -0.620229959487915, 0.059570323675870895, 0.33394956588745117, -0.4601361155509949, 0.012152302078902721, -0.25293034315109253, -0.3596287965774536, -0.3815467953681946, 0.27904215455055237, -0.4708296060562134, -0.2675270438194275, 0.6154688596725464, 0.24240830540657043, -0.14179161190986633, 0.27051010727882385, -0.11530539393424988, -0.3988513946533203, 1.1096413135528564, 0.6512696146965027, 0.4920322299003601, 0.27094653248786926, -0.39578545093536377, 1.6588735580444336, -1.6034140586853027, 0.47439950704574585, 1.3031774759292603, 0.3986705243587494, 0.6574736833572388, -0.10747741162776947, -0.2202761024236679, 0.3667481243610382, 0.11027106642723083, -0.7816107273101807, -0.46841055154800415, -0.42355841398239136, -0.025826141238212585, 1.8862662315368652, -0.4818541407585144, -0.08475290983915329, 0.6569815874099731, 0.43342822790145874, 1.2003026008605957, -0.11614130437374115, -0.838925838470459, -0.256518691778183, -0.5157973766326904, 0.6654830574989319, 0.34796032309532166, -0.3317222595214844, 0.15812809765338898, -0.7405832409858704, 0.0005811364972032607, -0.09817538410425186, 0.05189337581396103, -0.25933516025543213, 0.16615070402622223, -0.9433797597885132, 0.41648393869400024, -0.03672759607434273, 0.8576456904411316, 0.26350289583206177, 0.4917110800743103, 0.72950279712677, 0.6197655200958252, -0.015133921056985855, 0.3983665108680725, -0.1650286465883255, -0.07074062526226044, -0.9424466490745544, 0.5534841418266296, 0.10566052794456482, 0.9015588164329529, 0.004470853600651026, -0.1113949865102768, -1.1634846925735474, 0.16432209312915802, 1.2307124137878418, 0.19087694585323334, 0.5106992125511169, -0.7299069166183472, 0.3893059492111206, -0.48460832238197327, 0.3856933116912842, -0.07507867366075516, -0.10935506969690323, -0.29943692684173584, -0.2693178057670593, -1.593238353729248, -0.2802066206932068, 0.05228358507156372, -0.3789169192314148, 0.7742071747779846, -0.44020265340805054, 0.09229740500450134, 0.7425943613052368, 0.6987842917442322, 0.7704899907112122, 0.9112127423286438, -0.02991502173244953, -0.3252624571323395, 0.8226333856582642, -1.0758448839187622, -0.9925017952919006, -1.3110015392303467, 1.096479892730713, -0.5868756175041199, 0.5315839052200317, -0.12481903284788132, -1.3163769245147705, -0.8043624758720398, -1.1358221769332886, -0.5468685626983643, -0.4419621527194977, 0.4919867515563965, 0.6167213916778564, 0.5996206402778625, -0.852150022983551, 0.6509187817573547, 0.049945101141929626, -0.3192974030971527, -0.10083283483982086, -0.17610618472099304, 0.32690325379371643, -1.01589834690094, -1.6777794361114502, 0.2880229949951172, 0.1760859489440918, -0.49173974990844727, -0.6949486136436462, -0.3694569170475006, -1.3794933557510376, -0.1636316031217575, 0.6456781029701233, -0.2683866024017334, 1.3248523473739624, 0.06202278286218643, -1.0844810009002686, 0.23573262989521027, -0.5470759868621826, 0.32555949687957764, 0.140590637922287, -0.44014430046081543, -0.7049537301063538, -0.6145432591438293, -0.06379829347133636, 0.20398814976215363, -0.1030460000038147, 0.04899843782186508, -0.19872087240219116, 0.052622076123952866, -0.19694586098194122, 0.2665601372718811, 0.07320770621299744, 1.0068546533584595, -0.7683766484260559, -0.11945889890193939, 0.058877553790807724, 0.8709654211997986, 0.11152240633964539, -0.5172784328460693, -0.19070814549922943, -1.0154640674591064, 0.6325396299362183, -0.22037279605865479, 1.4117521047592163, -0.9065366983413696, -0.600140392780304, -0.6443687081336975, -0.4534948766231537, -0.11085307598114014, -0.948881208896637, 1.2254588603973389, 0.0629848763346672, 0.2803085148334503, -0.2806476652622223, -1.2836791276931763, 0.3291791081428528, 0.019105488434433937, -0.9041436910629272, -0.155914768576622, 0.0072568850591778755, 1.204644799232483, -1.0548877716064453, 0.13655893504619598, -0.47791266441345215, 0.11820532381534576, -0.8622212409973145, 1.0119365453720093, -0.5525099635124207, 0.26552021503448486, -0.04153180867433548, -0.141856849193573, -0.024703262373805046, -0.20202432572841644, 0.8894309997558594, -0.20252199470996857, -0.2879653573036194, 0.4827277660369873, -0.5077495574951172, 2.0866622924804688, -0.14620453119277954, 0.5546830296516418, -0.3230434060096741, -0.3966514766216278, 0.027109341695904732, 0.7754738330841064, -0.46718013286590576, -0.5663762092590332, 0.05250418931245804, 0.5708318948745728, -0.5090673565864563, -0.007366540841758251, 1.082425832748413, 0.8737494945526123, -0.6073368787765503, 0.5496880412101746, 0.5890510678291321, -0.14122256636619568, 1.0002564191818237, 0.8086920976638794, 0.42289936542510986, 0.4672592878341675, 0.45882388949394226, -0.30855855345726013, 0.4335011839866638, -0.6714423894882202, -0.0448477640748024, 0.4220195710659027, 0.5085557103157043, 1.067121148109436, 0.7275639772415161, -0.548088788986206, -0.7695473432540894, 0.17707671225070953, 0.8763400912284851, 1.6858431100845337, 0.30960002541542053, -0.6783297061920166, -0.8982608914375305, -0.2573294937610626, -0.2856074869632721, 0.255927175283432, -0.22193048894405365, -0.010987639427185059, -0.7386622428894043, -0.7568737864494324, 0.6914535760879517, 0.550391435623169, 0.7460225820541382, -0.3265491724014282, -0.11813495308160782, -0.2627949118614197, -0.2590659260749817, -0.7755813598632812, -0.9733942747116089, -0.046423524618148804, -0.4793200194835663, -0.45696327090263367, -0.0898771733045578, -0.05893639475107193, -0.04214800149202347, -0.5090703964233398, 1.2984825372695923, -0.2893431782722473, -0.24789175391197205, 0.3566249907016754, 0.25083890557289124, -0.4197629988193512, -0.7121714949607849, -0.02157234027981758, 0.16151899099349976, -0.5512045621871948, 0.7572152614593506, 0.9596790075302124, -0.004874600097537041, 0.43377432227134705, -0.33592498302459717, 0.4725414514541626, 0.2602428197860718, 0.5232343077659607, 0.6644258499145508, -0.5149551033973694, 0.3382831811904907, -0.9376806020736694, 1.104387879371643, 0.27274778485298157, -0.3675856590270996, 0.8690627217292786, -0.7842783331871033, -0.501179039478302, 0.20257450640201569, -0.4040837585926056, -0.49088823795318604, -1.3535929918289185, 0.38751375675201416, 0.41438356041908264, -0.05750985071063042, 0.5016781091690063, -0.08460327237844467, 0.5968731045722961, 0.3347513973712921, 0.6067076325416565, 0.30171269178390503, -0.24856050312519073, 0.807066798210144, -0.28956010937690735, 0.40776684880256653, 0.19376176595687866, -0.41772907972335815, -0.29702654480934143, -0.48937293887138367, -0.3463604748249054, -0.4321747124195099, -0.583833634853363, -0.5699937343597412, -0.24465982615947723, 0.39132219552993774, -0.8767459392547607, -0.6813875436782837, -0.21728287637233734, -1.0378258228302002, -0.3149196207523346, 0.4661921560764313, -0.3230707049369812, -0.16626055538654327, -0.6719502806663513, -1.0449233055114746, -0.2326534390449524, -0.7371673583984375, -1.147180199623108, 0.6619178652763367, -0.06028762087225914, -0.18403904139995575, -0.5363498330116272, 0.3090464472770691, -0.26891201734542847, 0.636123538017273, -0.8289332985877991, 0.8440873622894287, -0.06704514473676682, -0.19134952127933502, -0.17733295261859894, 0.31307387351989746, 0.4623861014842987, -0.3533462882041931, 0.11407219618558884, -0.5526513457298279, -0.23525121808052063, -0.15504024922847748, -0.45887866616249084, 0.2187366485595703, 0.23062527179718018, 0.09754638373851776, 0.4891328811645508, -0.5029417872428894, -0.0647425651550293, 1.4385015964508057, -0.5250147581100464, 0.11136683821678162, -0.31062081456184387, 0.9810749292373657, 0.4283909201622009, 0.14637185633182526, 0.32663294672966003, 0.14503759145736694, 0.13673219084739685, -0.06260461360216141, 0.3659542500972748, -0.03339622542262077, -0.19040901958942413, 0.9080111980438232, 1.700388789176941, 0.1414528340101242, 0.004319837782531977, -1.4638856649398804, 0.8966755867004395, -1.1873148679733276, -0.46662524342536926, 0.5726391673088074, 0.706677258014679, 0.6213696599006653, -0.5667349696159363, -0.5545342564582825, -0.1273961067199707, 0.46909382939338684, 0.415377140045166, -0.19336654245853424, -0.7364766597747803, -0.10106285661458969, 0.056963276118040085, -0.25044453144073486, 0.636323869228363, -0.3478967547416687, 0.40793806314468384, 14.62117862701416, 1.0102388858795166, 0.18436872959136963, 0.6910544037818909, 0.5163766145706177, 0.004121625795960426, -0.4485633969306946, 0.1185629591345787, -1.3043347597122192, -0.30995428562164307, 1.1980270147323608, -0.1460946947336197, 0.47455692291259766, -0.06251256912946701, 0.19668574631214142, -0.05925332009792328, -0.9553428292274475, 0.5433147549629211, 0.6665869355201721, -1.3322957754135132, 0.3761375844478607, 0.09759698808193207, 0.644311785697937, 0.3921380639076233, 0.6972669363021851, 0.9004233479499817, -0.16013658046722412, -0.3925880789756775, 0.3479078710079193, 0.08044092357158661, 1.0459502935409546, -0.3045930862426758, 0.7032919526100159, 0.4460485279560089, -0.5698405504226685, -0.6928247809410095, -0.8961284756660461, -1.1638845205307007, 0.356964647769928, 0.07254855334758759, -0.4965945780277252, 0.11620823293924332, -0.5017277598381042, 0.9114788174629211, 0.05451483279466629, 0.39002490043640137, -0.23013374209403992, 0.7529014348983765, 0.654375433921814, -0.13788820803165436, 0.5028740763664246, 0.15594825148582458, 0.3567878007888794, 0.08351103961467743, 0.20701155066490173, 0.2284206748008728, 0.23787541687488556, 0.10747610777616501, -0.42305007576942444, 0.23416580259799957, -0.40547481179237366, -0.3768309950828552, -0.3333345055580139, 0.39849379658699036, 0.49128973484039307, 0.03120202198624611, -0.6586666107177734, 0.17500561475753784, 0.3691713809967041, 0.27829647064208984, -0.0954691544175148, -0.20715725421905518, 0.2108851820230484, -0.7535519003868103, -0.13079585134983063, 0.18232391774654388, -0.2269553244113922, -0.6756802201271057, -0.7874774932861328, -0.41029706597328186, 0.18316973745822906, -0.7756309509277344, -0.5783663392066956, 0.7307395339012146, -0.2399834245443344, -0.6479768753051758, 0.1301761418581009, -0.8579882979393005, -0.5227371454238892, 0.47424447536468506, -1.350473403930664, -0.7560898065567017, 0.29999804496765137, -0.41932711005210876, 0.10209272056818008, -0.0005929286126047373, 1.350948452949524, 0.19742241501808167, -0.4249076247215271, -0.16108882427215576, 0.7350831627845764, 0.022992422804236412, 0.4178117513656616, -1.0686523914337158, 0.6818150877952576, 0.5128036737442017, -0.15892337262630463, 0.579866349697113, 0.16342155635356903, -0.2731187343597412, -1.116603136062622, -0.029564788565039635, 0.8217870593070984, -1.1140140295028687, -0.6044771671295166, -1.216468334197998, -0.9604030847549438, 0.048992618918418884, 0.9324678182601929, -0.5355976819992065, 0.5531466007232666, 0.23416808247566223, -0.2912011444568634, -0.3429284989833832, -0.5509200096130371, 0.2514134347438812, 0.40164420008659363, -0.9717192649841309, -0.6684376001358032, 0.10327595472335815, 0.6176331639289856, -1.1218825578689575, -0.4258514940738678, -0.38446488976478577, 0.24628514051437378, -0.030606837943196297, 0.706240713596344, -0.10843122005462646, 0.9723325967788696, 0.8521789908409119, -0.32485994696617126, -0.7301138639450073, 0.48815035820007324, -0.9428386092185974, 0.1544211357831955, 0.15736602246761322, 0.7448164820671082, -0.12423687428236008, -0.2143154740333557, 0.6013979911804199, 0.19434425234794617, -0.6353096961975098, -0.664890468120575, -0.27889057993888855, 0.5306844115257263, -0.3454241454601288, 0.5786896347999573, -0.10262779146432877, 0.17855951189994812, -0.02829429879784584, 0.32083553075790405, 0.6368172764778137, -0.534669816493988, -0.2578771114349365, 0.428457647562027, 0.3988717794418335, 0.11505607515573502, -0.3131501376628876, -0.22882096469402313, -1.5222262144088745, -0.09701444208621979, -0.7956656813621521, 0.18348444998264313, -1.038195013999939, -0.23083630204200745, 0.46812304854393005, -0.21444807946681976, -0.281188040971756, 0.0660930871963501, -0.25390133261680603, -0.5003898739814758, -0.6927220225334167, -0.9779326319694519, 0.922588050365448, 0.9877350926399231, -0.7967351078987122, 0.23842453956604004, -0.33046823740005493, 0.18485741317272186, -0.2979051470756531, 0.17036552727222443, -0.06218573823571205, -0.9269125461578369, -1.5265551805496216, 0.6876845955848694, -0.019380351528525352, -0.36279618740081787, -0.44892486929893494, 0.5893286466598511, 0.5061195492744446, -0.20569030940532684, -0.18627667427062988, 0.12432800978422165, -0.36118873953819275, -0.6491858959197998, 0.2094651311635971, -0.8421049118041992, 0.2385593056678772, 0.08470374345779419, -0.6301623582839966, -0.39653289318084717, 0.5748793482780457, -0.6426218748092651, -1.0835082530975342, -0.7948938608169556, 0.03006410039961338, -0.6191408634185791, 0.08574111014604568, -0.3225034773349762, -0.00016805245832074434, -1.318915843963623, -0.44982999563217163, 0.023493975400924683, 0.7176318764686584, -0.17376211285591125, 0.9362307190895081, 0.4947976768016815, -0.9088820219039917, -0.13652461767196655, 0.23900607228279114, 0.11241669207811356, -0.16020070016384125, 0.7610006928443909, 0.4078637659549713, -0.33664798736572266, 0.7023727297782898, 0.42154771089553833, 0.09625465422868729, -1.034403681755066, 0.06306669861078262, 0.5671371221542358, -0.5131574869155884, 0.01807706616818905, 0.8352761268615723, -0.43395185470581055, -0.898971676826477, -0.01573556661605835, -1.1216732263565063, -0.6937633156776428, -0.43463805317878723, 1.166425108909607, 0.191733255982399, -0.028785547241568565, -0.1043558418750763, -0.31508833169937134, 0.5686944127082825, -0.14333267509937286, -0.7262346744537354, 0.5553717017173767, -0.6312326192855835, -0.6358868479728699, 0.8693934082984924, 0.620278000831604, -0.5232272148132324, -0.6092435121536255, -0.4632529020309448, -0.36107850074768066, -0.2898314595222473, 0.18952004611492157, -0.8788241744041443, 0.059320561587810516, 1.1552902460098267, 0.6633442044258118, 0.3265612721443176, 0.298058420419693, -0.3387407660484314, 0.27143457531929016, 0.9374815225601196, 0.01956895925104618, -0.794829785823822, -0.5607079267501831, 1.4053345918655396, 1.3392881155014038, -1.1922659873962402, 0.35666733980178833, 0.2583092749118805, -0.9811121821403503, 0.9760823845863342, 0.28726425766944885, 0.4167867600917816, 0.5435934066772461, -0.5739502906799316, 0.5250852108001709, 0.2361794114112854, -1.1242256164550781, -0.019839061424136162, 0.9250026345252991, 0.779780924320221, 0.8766575455665588, 0.19178640842437744, -0.4829484224319458, 1.1562798023223877, 0.5709055662155151, -0.1208423376083374, 0.8449163436889648, 0.5782317519187927, -0.13209140300750732, -0.4090729355812073, 0.1419735699892044, 0.21761561930179596, -0.8360400795936584, -0.6099244356155396, 0.22320203483104706, 0.19318504631519318, 0.16601361334323883, 0.8417174220085144, 0.7572636008262634, 0.5090399384498596, 0.18268123269081116, 0.5146936774253845, 0.39125773310661316, -0.7614298462867737, -0.35232338309288025, 0.04337959364056587, -0.5038244724273682, -0.2554300129413605, -0.27227121591567993, -0.4959391951560974, -0.2995308041572571, 0.12542499601840973, 0.18213632702827454, 0.3621807098388672, 0.5462724566459656, 1.4327738285064697, 0.5865439176559448, 0.11632910370826721, -0.4108158051967621, -0.23696665465831757, -0.4406779706478119, -1.051367998123169, -0.1032639816403389, -0.41619136929512024, -0.22046783566474915, -0.018513131886720657, 0.38334858417510986, -0.2666463255882263]}, "authors": [{"authorId": "2141377570", "name": "Yushi Bai"}, {"authorId": "48574888", "name": "Xin Lv"}, {"authorId": "2107983722", "name": "Jiajie Zhang"}, {"authorId": "2220304036", "name": "Hong Lyu"}, {"authorId": "2204826271", "name": "Jiankai Tang"}, {"authorId": "2234629967", "name": "Zhidian Huang"}, {"authorId": "66395694", "name": "Zhengxiao Du"}, {"authorId": "2111312892", "name": "Xiao Liu"}, {"authorId": "2051712753", "name": "Aohan Zeng"}, {"authorId": "2055765060", "name": "Lei Hou"}, {"authorId": "2047998", "name": "Yuxiao Dong"}, {"authorId": "2148911975", "name": "Jie Tang"}, {"authorId": "2133353675", "name": "Juanzi Li"}], "references": [{"paperId": "b0db25e317cf856f1ec1ca3df0e573d850ed4696", "title": "L-Eval: Instituting Standardized Evaluation for Long Context Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "c12db2c60e8989f646a29ad4f4d24475e860ad91", "title": "LongNet: Scaling Transformers to 1, 000, 000, 000 Tokens"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "2a09ebbfcca1a6994eeb472cd4159f5f3858dbf9", "title": "LongCoder: A Long-Range Pre-trained Language Model for Code Completion"}, {"paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787", "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"}, {"paperId": "378a545c3a1cf6c4aada8f9ee8820c0d8008220a", "title": "Benchmarking Foundation Models with Language-Model-as-an-Examiner"}, {"paperId": "f97413a497d47c739d41d237917e6566154647b4", "title": "RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems"}, {"paperId": "60b35c6d68acced19b0c66edcfc0ee0a2c11efed", "title": "Landmark Attention: Random-Access Infinite Context Length for Transformers"}, {"paperId": "eb511ae6b9f04e4936891d26787f274b48b99d57", "title": "ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding"}, {"paperId": "d9964ab436eefd21f923a4bc833c6b66692c7f00", "title": "RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text"}, {"paperId": "61fa56fbdb3b7668a0ac1b895312a9c7bca682e4", "title": "VCSUM: A Versatile Chinese Meeting Summarization Dataset"}, {"paperId": "594d8e1696619f3cebb7c6bffdad8e0a5592f006", "title": "Scaling Transformer to 1M tokens and beyond with RMT"}, {"paperId": "bafe023fb072045dc0cd50316382a61c8dcb9fae", "title": "CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Benchmarking on HumanEval-X"}, {"paperId": "27d391d65ab42c30dc35595213ba6585633afa5d", "title": "CoLT5: Faster Long-Range Transformers with Conditional Computation"}, {"paperId": "f393aff1593c2d370ec0ae004910d18e40524967", "title": "Resurrecting Recurrent Neural Networks for Long Sequences"}, {"paperId": "9575afb5702bc33d7df14c48feeee5901ea00369", "title": "A Length-Extrapolatable Transformer"}, {"paperId": "1d26c947406173145a4665dd7ab255e03494ea28", "title": "GLM-130B: An Open Bilingual Pre-trained Model"}, {"paperId": "398e4061dde8f5c80606869cebfa2031de7b5b74", "title": "Few-shot Learning with Retrieval Augmented Language Models"}, {"paperId": "a8cf0f7a20f886acfb332071c2daaf58ba86a5ca", "title": "Recurrent Memory Transformer"}, {"paperId": "bd1331b233e84bab7eba503abc60b31ac08e7881", "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models"}, {"paperId": "0e802c0739771acf70e60d59c2df51cd7e8c50c0", "title": "Memorizing Transformers"}, {"paperId": "6281c40c66febca1d8003bcc6fdfd2189b30c38f", "title": "SCROLLS: Standardized CompaRison Over Long Language Sequences"}, {"paperId": "4f4a409f701f7552d45c46a5b0fea69dca6f8e84", "title": "Unsupervised Dense Information Retrieval with Contrastive Learning"}, {"paperId": "002c256d30d6be4b23d365a8de8ae0e67e4c9641", "title": "Improving language models by retrieving from trillions of tokens"}, {"paperId": "f75d05e759447c2aedb7097728f29f9a520d9bc1", "title": "Do Long-Range Language Models Actually Use Long-Range Context?"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "ec307b17f193b14292206b65a1bcc95bfd8f02ed", "title": "\u266b MuSiQue: Multihop Questions via Single-hop Question Composition"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "4e3935ef7da6bcbb202ec7f8b285c313cadcd044", "title": "A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers"}, {"paperId": "9dc624d7258d1a56117ca720aea953ce46b66b21", "title": "Efficient Attentions for Long Document Summarization"}, {"paperId": "aa28873534c24e4a8c5deb7bff723cd5fc69a6f0", "title": "QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization"}, {"paperId": "50796b0f3edf9cb5ff1e447c298b33755378aa4f", "title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "9001eb3c3d5a96ad3d804410c2437e6f60feade9", "title": "Constructing A Multi-hop QA Dataset for Comprehensive Evaluation of Reasoning Steps"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "8ee2351221b72fca5eef4c42147ed67071903d93", "title": "IntelliCode compose: code generation using transformer"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f9700e31a1d0ae34d4571ab056dfb268c1543349", "title": "SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "7be8c119dbe065c52125ee7716601751f3116844", "title": "Generalization through Memorization: Nearest Neighbor Language Models"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "cc27ec53160d88c25fc5096c0df65536eb780de4", "title": "Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "22655979df781d222eaf812b0d325fa9adf11594", "title": "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering"}, {"paperId": "d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a", "title": "The NarrativeQA Reading Comprehension Challenge"}, {"paperId": "995b7affd684b910d5a1c520c3af00fd20cc39b0", "title": "DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications"}, {"paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "2c8ac3e1f0edeed1fbd76813e61efdc384c319c7", "title": "Learning Question Classifiers"}, {"paperId": "7806aed0e00bcc8d3d84b15f5dab318b5400b7f0", "title": "Unleashing Infinite-Length Input Capacity for Large-scale Language Models with Self-Controlled Memory System"}, {"paperId": null, "title": "Long sequence modeling with xgen: A 7b llm trained on 8k input sequence length"}, {"paperId": null, "title": "New and improved embedding model"}, {"paperId": null, "title": "Task definition for large scale text categorization at nlpcc"}, {"paperId": null, "title": "2023c. Agent-bench: Evaluating llms as agents"}, {"paperId": null, "title": "llm-as-a-judge"}, {"paperId": null, "title": "LongChat-v1.5-7B-32k"}, {"paperId": null, "title": "2023. How long can open-source llms truly promise on context length?"}, {"paperId": null, "title": "OpenAI"}, {"paperId": null, "title": "2023. Internlm: A multilingual language model with progressively enhanced capabilities"}]}