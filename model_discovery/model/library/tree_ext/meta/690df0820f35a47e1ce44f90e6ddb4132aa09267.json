{"paperId": "690df0820f35a47e1ce44f90e6ddb4132aa09267", "title": "Vision-Language Models for Vision Tasks: A Survey", "abstract": "Most visual recognition studies rely heavily on crowd-labelled data in deep neural networks (DNNs) training, and they usually train a DNN for each single visual recognition task, leading to a laborious and time-consuming visual recognition paradigm. To address the two challenges, Vision-Language Models (VLMs) have been intensively investigated recently, which learns rich vision-language correlation from web-scale image-text pairs that are almost infinitely available on the Internet and enables zero-shot predictions on various visual recognition tasks with a single VLM. This paper provides a systematic review of visual language models for various visual recognition tasks, including: (1) the background that introduces the development of visual recognition paradigms; (2) the foundations of VLM that summarize the widely-adopted network architectures, pre-training objectives, and downstream tasks; (3) the widely-adopted datasets in VLM pre-training and evaluations; (4) the review and categorization of existing VLM pre-training methods, VLM transfer learning methods, and VLM knowledge distillation methods; (5) the benchmarking, analysis and discussion of the reviewed methods; (6) several research challenges and potential research directions that could be pursued in the future VLM studies for visual recognition.", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2023, "citationCount": 126, "influentialCitationCount": 4, "openAccessPdf": {"url": "https://arxiv.org/pdf/2304.00685", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "A systematic review of visual language models for various visual recognition tasks, including the background that introduces the development of visual recognition paradigms, and the foundations of VLM that summarize the widely-adopted network architectures, pre-training objectives, and downstream tasks."}, "embedding": {"model": "specter_v2", "vector": [0.15286020934581757, 0.08953265845775604, -0.19671399891376495, -0.07757259905338287, 0.09900186210870743, 0.13282638788223267, 1.0852714776992798, -0.3522908091545105, -0.9709983468055725, -0.9390029907226562, 0.19257239997386932, 0.17219357192516327, 0.5387857556343079, 0.09169711172580719, -0.0974426418542862, 0.22714047133922577, -0.43297919631004333, -0.09626098722219467, 0.37498900294303894, -0.6723813414573669, 0.002827464370056987, -0.5934244394302368, -1.3502123355865479, 0.31940391659736633, -0.27611634135246277, 0.7724161148071289, 0.7622731328010559, 1.4646527767181396, -0.33749672770500183, 0.7730720043182373, 0.43858635425567627, -0.5169443488121033, 0.2964937686920166, -0.03652903810143471, -0.43273526430130005, 0.23092472553253174, 0.7501299977302551, -0.6311790943145752, -0.8505934476852417, 0.6897469758987427, -0.004055950790643692, 0.6411929726600647, 0.8499963879585266, -0.546946108341217, -0.915342390537262, -0.20134131610393524, 0.3893079161643982, 0.4375811219215393, -0.25821515917778015, 0.01714201457798481, 1.3941948413848877, -1.4204798936843872, 0.2596428692340851, 1.7053552865982056, 0.1858188658952713, 0.574387788772583, 0.27657538652420044, -0.3004046380519867, 0.6420364379882812, -0.11184633523225784, -0.6347029209136963, -0.15430152416229248, -0.19617322087287903, -0.5037760734558105, 1.905813455581665, -0.6777132153511047, -0.030543779954314232, 1.145359754562378, 0.3364349603652954, 1.2163078784942627, -0.1045575886964798, -1.184607982635498, -0.4128471612930298, -0.2078057825565338, 0.03728743642568588, 1.0111690759658813, -0.4166277348995209, 0.5305089354515076, -0.7405062317848206, 0.4459129273891449, 0.7965499758720398, 0.05369885265827179, -0.030685078352689743, -0.16496428847312927, -0.5580147504806519, 0.6932795643806458, 0.7693921327590942, 0.5260292887687683, 0.014246029779314995, 0.45613914728164673, 0.5311295390129089, 0.24979180097579956, -0.4704957604408264, -0.11775988340377808, 0.2595355808734894, 0.913790762424469, -0.7325117588043213, 0.1520187109708786, -0.12210676074028015, 1.063956379890442, -0.46899983286857605, 0.3212640881538391, -0.7947860360145569, 0.46928438544273376, 1.447155475616455, -0.02243746817111969, 0.5918471813201904, -0.501142680644989, 0.368191123008728, -0.9290252923965454, 0.21316459774971008, -0.9519237279891968, 0.06857148557901382, -0.08162551373243332, -0.9020302295684814, -0.8075441718101501, -0.1392698884010315, 0.42536690831184387, -1.275787353515625, 0.533926248550415, -0.724656343460083, -0.2476678490638733, 0.3043082058429718, 0.6689213514328003, 0.9076389074325562, 0.797051191329956, 0.7958700060844421, 0.6709274053573608, 1.293128490447998, -1.2096954584121704, -0.30323565006256104, -1.0429749488830566, 0.13611294329166412, -0.540859043598175, 0.8067489862442017, -0.4555220901966095, -0.8918711543083191, -1.7403160333633423, -0.7030287981033325, -0.5654146075248718, -0.6550047993659973, 0.7734441161155701, 0.8372718691825867, -0.05381070822477341, -1.6132400035858154, 0.4618978202342987, 0.48332303762435913, -0.6845994591712952, 0.26292699575424194, -0.09326422959566116, 0.1123424842953682, -0.6513786315917969, -0.8635342121124268, 0.6744667291641235, -0.12690646946430206, -0.38321778178215027, -0.473969966173172, 0.4592292010784149, -1.6177997589111328, -0.46627846360206604, -0.02498631924390793, -0.8708094954490662, 1.0905357599258423, -0.8022688627243042, -0.7820138931274414, 1.2480417490005493, -0.6656580567359924, -0.0038288794457912445, 0.27876806259155273, -0.16226541996002197, -0.6784110069274902, -0.33511677384376526, -0.20888535678386688, 1.4391742944717407, 0.7130851745605469, -0.5534249544143677, -0.050559524446725845, 0.5768698453903198, -0.2468191534280777, 0.08874449133872986, -0.3914524018764496, 1.27824068069458, -0.9177615642547607, -0.5742530822753906, 0.23639720678329468, 0.5214407444000244, 0.05780426412820816, 0.07142312079668045, -0.2578495144844055, -0.7793375253677368, 0.7339476943016052, 0.0333704873919487, 0.03950325772166252, -0.9286149144172668, -0.9622193574905396, -0.7291364073753357, -0.17795120179653168, 0.13860687613487244, -1.4323498010635376, 0.47571083903312683, 0.07065454870462418, 0.20504504442214966, 0.17569848895072937, -1.6790293455123901, -0.326121062040329, -0.10915125906467438, -0.6026908755302429, -0.23606453835964203, 0.43010926246643066, 1.4299463033676147, -0.8656845688819885, -0.11460021883249283, 0.09734468162059784, 0.2358146756887436, -0.4020730257034302, 1.2222368717193604, -0.5001192092895508, -0.11075771600008011, -0.016622591763734818, -0.11316715180873871, -0.0897044762969017, -0.649614155292511, -0.005180111154913902, -0.4898492693901062, -0.018587611615657806, -0.11184444278478622, 0.21797099709510803, 1.4645671844482422, -0.2331533581018448, 1.3832851648330688, -0.5787461400032043, -0.28433433175086975, 0.4150692820549011, 0.25284385681152344, -0.6726070642471313, -0.46850311756134033, 0.34811824560165405, -0.17212149500846863, -0.5741263628005981, -0.08155028522014618, 0.8314199447631836, 1.070793628692627, -0.08727866411209106, -0.13461509346961975, 0.3845076560974121, -0.19163855910301208, 0.07854630798101425, 0.15826965868473053, 0.23566100001335144, 0.3084590435028076, 0.19229210913181305, 0.28434258699417114, 0.5793734192848206, -0.749276876449585, -0.5350850820541382, 1.0004470348358154, 0.4072042405605316, 1.328850269317627, -0.04212361201643944, -0.8394633531570435, -0.29067233204841614, -0.34985166788101196, 0.981148898601532, 1.343509316444397, 0.2664720118045807, 0.04211869835853577, -0.4942100942134857, -0.14571167528629303, -0.5461387038230896, -0.21814262866973877, -0.4416651427745819, 0.016042636707425117, 0.06981513649225235, -0.6625239253044128, 0.7452542185783386, 0.28391003608703613, 1.3367125988006592, -1.1313937902450562, -0.24141652882099152, -0.8603864908218384, 0.2718638777732849, -1.1525722742080688, -0.9550877809524536, -0.2425425499677658, -0.4088899791240692, -0.15919899940490723, -0.5230545997619629, -0.8633540868759155, 0.4124585688114166, -0.06517187505960464, 0.79673832654953, -0.35771825909614563, -0.5434220433235168, 0.3284691572189331, 0.6468813419342041, -0.6941066980361938, -0.5588105320930481, -0.393466591835022, 0.002201902214437723, 0.1561930626630783, 0.7712255716323853, 0.9551195502281189, -0.14596876502037048, 0.0913422554731369, -0.5696772336959839, 0.17139174044132233, 0.4100838899612427, -0.12608231604099274, 0.762690007686615, -0.40399208664894104, -0.02419046126306057, -0.327403724193573, 0.9025472402572632, 0.4925992786884308, -0.37715062499046326, 0.47637900710105896, -0.5729550719261169, -0.5757998824119568, 0.22824439406394958, -0.8998600244522095, -0.6004514694213867, -0.29609960317611694, 0.7220441699028015, -0.7464184165000916, -0.6924683451652527, -0.14049355685710907, 0.43460801243782043, -0.12180417031049728, 0.37006789445877075, 0.5053821802139282, 0.46580928564071655, 0.2542197108268738, 0.7337213158607483, -0.5733902454376221, 0.8566597104072571, 0.5260443687438965, 0.05831881985068321, 0.12723815441131592, -0.17836704850196838, -0.9228106737136841, -0.523756742477417, -0.608159601688385, -0.2752593159675598, -0.8775491714477539, 0.8671720623970032, -0.9696608781814575, -0.6458881497383118, 0.18080483376979828, -1.3859264850616455, -0.14950037002563477, 0.28849297761917114, -0.0939791277050972, -0.26802074909210205, -0.6571061015129089, -0.838284432888031, -0.4797270596027374, -0.28028813004493713, -0.9013348817825317, 0.14143157005310059, 0.4245818555355072, -0.2354961633682251, -0.553543746471405, -0.24113671481609344, -0.10105589032173157, 0.717781662940979, -0.5565075278282166, 0.6656404733657837, 0.11305292695760727, -0.17758235335350037, -0.3916979134082794, -0.19914455711841583, 1.0479885339736938, -0.130479097366333, 0.4241989254951477, -1.0213067531585693, 0.3204480707645416, -0.20414325594902039, -0.2993508279323578, 0.7457190155982971, 0.46816954016685486, 0.5117760896682739, 0.5731307864189148, -0.17549335956573486, 0.24702297151088715, 1.6085840463638306, -0.6052563190460205, -0.13679347932338715, -0.15656130015850067, 1.0296711921691895, 0.45672711730003357, -0.4781349003314972, 0.19394665956497192, 0.6096224784851074, 0.1960306018590927, 0.1874236762523651, -0.5986281037330627, -0.7784608006477356, -0.811302661895752, 0.7481465935707092, 1.033605694770813, 0.0231382604688406, -0.22106468677520752, -1.231497883796692, 0.8471866250038147, -1.0903518199920654, -0.5103127956390381, 0.42752301692962646, 0.835722029209137, 0.021484943106770515, -0.23351462185382843, -0.25517410039901733, -0.9303070902824402, 0.8671287894248962, 0.6730772256851196, -0.07602068781852722, -0.7360056042671204, -0.5843067169189453, 0.033010613173246384, -0.025696750730276108, 0.35565871000289917, -0.7533167600631714, 0.6963633894920349, 14.035249710083008, 0.30572429299354553, -0.40003591775894165, 0.45411384105682373, 0.9056464433670044, 0.31285378336906433, -0.08842107653617859, -0.15168724954128265, -1.0351741313934326, -0.5421193838119507, 0.6977996230125427, 0.7187638282775879, 0.5760440230369568, 0.2701440155506134, 0.1523619145154953, 0.13019835948944092, -0.744961678981781, 1.5094714164733887, 1.1905972957611084, -1.0518594980239868, 0.9855645895004272, 0.06682206690311432, 0.4491501748561859, 0.7341182231903076, 1.126973271369934, 0.6372607350349426, 0.2027565985918045, -0.5474880337715149, 0.4005195200443268, 0.5192989110946655, 0.8141893744468689, 0.3094049394130707, 0.1320713758468628, 0.5237970948219299, -1.0124225616455078, -0.4523681402206421, -0.9862082004547119, -1.17123544216156, 0.031860437244176865, -0.3281491994857788, -0.1532777100801468, -0.2813189625740051, -0.1918022334575653, 0.8487804532051086, -0.2243148386478424, 0.31707677245140076, -0.24486598372459412, 0.2547346353530884, 0.3565014898777008, -0.3959365785121918, 0.5074536800384521, 0.3395889103412628, 0.3816114664077759, 0.30717718601226807, 0.07405224442481995, -0.019429683685302734, 0.12419520318508148, 0.4748995900154114, -0.6410082578659058, 0.1322493851184845, -0.7024169564247131, -0.1470111906528473, -0.7046111226081848, 0.6773793697357178, 0.14780883491039276, 0.43523311614990234, -0.6864768266677856, 0.5859060287475586, 0.23748187720775604, 0.7776979207992554, -0.10730955749750137, 0.09216908365488052, 0.23857760429382324, -0.48243284225463867, 0.486095130443573, 0.12344785034656525, 0.018525438383221626, -0.7678170800209045, -0.4387502372264862, 0.1018550917506218, 0.28078511357307434, -1.3861054182052612, -1.1905344724655151, 1.2419325113296509, -0.39311209321022034, -0.4795120358467102, 0.16823576390743256, -1.415312647819519, -0.4126031994819641, 0.8930253982543945, -1.5291391611099243, -0.903529703617096, -0.21764037013053894, -0.05067500099539757, 0.30826207995414734, -0.7921630144119263, 0.7395709156990051, -0.25029256939888, 0.04834209755063057, -0.0971563309431076, -0.25840282440185547, 0.41732603311538696, 0.012244008481502533, -0.17047904431819916, 0.7570416331291199, 0.5066430568695068, 0.33744141459465027, -0.11423655599355698, -0.39513012766838074, 0.02689540572464466, -0.5008633136749268, -0.1843247264623642, 1.019428014755249, -0.7990967631340027, -0.6778641939163208, -0.7047132253646851, -0.5080654621124268, -0.1133570522069931, 0.9106677174568176, -0.04503510147333145, -0.11551970988512039, -0.18315526843070984, -0.8544772863388062, 0.12171610444784164, -0.3366345763206482, 0.6771864891052246, 0.24704481661319733, -0.992343544960022, -0.3531942367553711, 0.12437456101179123, 0.025008423253893852, -0.27186697721481323, 0.18174751102924347, -0.418316513299942, 0.11563611775636673, -0.15699733793735504, 1.2347958087921143, -0.823060929775238, 0.9546518921852112, 0.6346527338027954, -0.4265126883983612, -0.5810064673423767, -0.09583579003810883, -0.5217927098274231, 0.35817304253578186, 0.021387862041592598, 0.38403213024139404, -0.23922111093997955, -0.2574636936187744, 0.5568544268608093, 0.8542050123214722, -0.4155350625514984, -0.1778590828180313, -0.5000403523445129, -0.1303485631942749, -0.49957185983657837, -0.2682095170021057, -0.22112521529197693, -0.611564576625824, 0.42685991525650024, 0.15287698805332184, 0.31948015093803406, -0.29280397295951843, -0.846235990524292, 0.5397361516952515, -0.201755553483963, -0.20558638870716095, -0.649836003780365, -0.4353177547454834, -1.7190790176391602, 0.2678965628147125, -1.2128479480743408, -0.02509668841958046, -1.2427020072937012, -0.4211418330669403, 0.8187551498413086, -0.31251031160354614, 0.1578943282365799, 0.6077625155448914, -0.2919517755508423, 0.2131327986717224, -0.03480301797389984, -0.5488570332527161, 0.7136983275413513, 1.185261845588684, -0.8169849514961243, 0.19470909237861633, -0.15496116876602173, 0.15540796518325806, 0.47484704852104187, 0.2284935563802719, -0.1673799455165863, -1.1890193223953247, -1.356660008430481, 0.13699950277805328, -0.2403377890586853, 0.46694496273994446, -1.0373154878616333, 0.789698600769043, 0.3662324547767639, 0.27273526787757874, -0.026815423741936684, 0.692348062992096, -0.5072655081748962, -0.894550621509552, 0.2083231806755066, -1.0235158205032349, 0.26829993724823, 0.13641729950904846, -0.028990592807531357, -0.7215701937675476, 0.7654699087142944, 0.08226045966148376, -1.04301917552948, -1.1433625221252441, 0.6527091860771179, -0.4432298243045807, 0.01988375000655651, -0.043796833604574203, -0.10643314570188522, -0.9983187317848206, -0.8466315269470215, -0.01908942498266697, 0.2446451038122177, -0.5800582766532898, 1.5052120685577393, 1.4455355405807495, -1.0433456897735596, -0.26215165853500366, 0.4015814960002899, 0.12521928548812866, -0.14290055632591248, 0.5567635297775269, 0.20422372221946716, -0.17555440962314606, 0.368949830532074, 0.049799319356679916, 0.18121720850467682, -0.9903150796890259, 0.181838721036911, 1.116012454032898, 0.008168055675923824, -0.04780043289065361, 1.1150177717208862, 0.3033199906349182, -0.8813609480857849, 0.30937880277633667, -0.9672505259513855, -0.7440235018730164, -0.34941455721855164, 0.5595986247062683, -0.5275301933288574, -0.20774224400520325, -0.652281641960144, -0.18896573781967163, 0.47906494140625, -0.03186590224504471, -0.7347971796989441, -0.04703148826956749, -0.1901209056377411, -0.028740692883729935, 0.8327775001525879, 1.2083532810211182, -1.04953932762146, -1.0764720439910889, -0.8217531442642212, -0.5576686859130859, -0.13410000503063202, 0.029846739023923874, -0.40889546275138855, -0.7843299508094788, 0.9237830638885498, 0.6406018733978271, -0.21971876919269562, 0.37398549914360046, -0.03149807080626488, 0.1056799665093422, 1.004878044128418, -0.6268435716629028, -0.6720880270004272, 0.04489920660853386, 1.5460667610168457, 1.3055715560913086, -1.2920656204223633, -0.07326490432024002, -0.35661524534225464, -1.025132179260254, 1.0403882265090942, 0.4535667300224304, -0.15544256567955017, 0.997758686542511, -0.8293907642364502, 0.3109932541847229, 0.4492092728614807, -0.7964073419570923, -0.4591372013092041, 1.4104329347610474, 1.2743921279907227, 0.6516900062561035, 0.1418725550174713, 0.36096876859664917, 0.48793742060661316, 0.16803395748138428, 0.02969907969236374, 0.34792646765708923, 0.0420575849711895, -0.11825183033943176, 0.20268572866916656, 0.08430492132902145, 0.576457679271698, -0.23679226636886597, -0.6147782802581787, 0.07982197403907776, 0.6686415076255798, 0.22284947335720062, 0.819889485836029, 1.0336549282073975, -0.026842210441827774, 0.59675133228302, 0.27358177304267883, 0.45763710141181946, -0.3863176703453064, -0.11211622506380081, -0.19863645732402802, -0.8894852995872498, 0.35977551341056824, -0.5287419557571411, -0.5691103935241699, -0.08122262358665466, 0.30838045477867126, 0.9047647714614868, -1.030242681503296, 0.4397745728492737, 1.170061469078064, 0.44800958037376404, 0.0961909294128418, -0.6629709601402283, -0.1574142575263977, -0.06631410121917725, -0.8077118992805481, 0.2403803914785385, -0.20222890377044678, 0.05422326549887657, -0.5134740471839905, -0.1376742571592331, 0.12834559381008148]}, "authors": [{"authorId": "2108122973", "name": "Jingyi Zhang"}, {"authorId": "144284509", "name": "Jiaxing Huang"}, {"authorId": "145880092", "name": "Sheng Jin"}, {"authorId": "1771189", "name": "Shijian Lu"}], "references": [{"paperId": "aa05929a10a7891a5081b5bfb67fb9ef35041640", "title": "GrowCLIP: Data-aware Automatic Model Growing for Large-scale Contrastive Language-Image Pre-training"}, {"paperId": "d948b1e697aeca03684482003c271536c86c443f", "title": "ALIP: Adaptive Language-Image Pre-training with Synthetic Caption"}, {"paperId": "9f0630ff9d256ab89248f87cf2bdb7cee5740d4c", "title": "Tem-adapter: Adapting Image-Text Pretraining for Video Question Answer"}, {"paperId": "74baedebc3a5b605cc52f6e15160fb6134201177", "title": "ProTeCt: Prompt Tuning for Taxonomic Open Set Classification"}, {"paperId": "913b14f3b6dadf3aa32002501bec144065fde5b7", "title": "Retrieval-Enhanced Visual Prompt Learning for Few-shot Classification"}, {"paperId": "ca5a44251f35897659157f020f212f617c919170", "title": "RA-CLIP: Retrieval Augmented Contrastive Language-Image Pre-Training"}, {"paperId": "d4af12327385260116dfd68ed1ec6d0602d26d1f", "title": "Improving CLIP Training with Language Rewrites"}, {"paperId": "5faee4af70f65e609eafe1f23f26593423f03750", "title": "Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers"}, {"paperId": "362983f6f6b3e0335f1267b7b9d0288cc4d2619f", "title": "FreeSeg: Unified, Universal and Open-Vocabulary Image Segmentation"}, {"paperId": "88779e873b7ec860d6b6a4c2ddfc28dd67c86b67", "title": "Visual-Language Prompt Tuning with Knowledge-Guided Context Optimization"}, {"paperId": "9856e8752b8ae09e2bb7711b9668e086d5ad9feb", "title": "Object-Aware Distillation Pyramid for Open-Vocabulary Object Detection"}, {"paperId": "a935ba7ce7fd44fe372c6860504fbc164f012f03", "title": "HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware Attention"}, {"paperId": "bce29cc829fab288c41ae5678e1bb5b95bf218d4", "title": "Aligning Bag of Regions for Open-Vocabulary Object Detection"}, {"paperId": "641d7866db6691e22aa36de5c8ba05804233c016", "title": "Side Adapter Network for Open-Vocabulary Semantic Segmentation"}, {"paperId": "746bb45433f6b24d3ae64d6cd51c4e9d00a0ffa7", "title": "Large-scale Multi-modal Pre-trained Models: A Comprehensive Survey"}, {"paperId": "7d862911a3355f6ced14e21cf2bc6745de3ae3f7", "title": "Learning to Detect and Segment for Open Vocabulary Object Detection"}, {"paperId": "3a27dfb4b87f74c3c663cc42cec83ccd58f72f23", "title": "CLIP is Also an Efficient Segmenter: A Text-Driven Approach for Weakly Supervised Semantic Segmentation"}, {"paperId": "ec8f75e22ffbb5ad7e2f9cfc20a7780eed45715b", "title": "CLIPPO: Image-and-Language Understanding from Pixels Only"}, {"paperId": "2dd4bdb71e8d1a1bb6f7f2cb500972f082aa91fd", "title": "NLIP: Noise-robust Language-Image Pre-training"}, {"paperId": "16de2006e2960ba410772c6b6d460b83c0a5cc4b", "title": "Reproducible Scaling Laws for Contrastive Language-Image Learning"}, {"paperId": "67db43cb6cc618c873c63fe2c83025c335b7a230", "title": "ZegCLIP: Towards Adapting CLIP for Zero-shot Semantic Segmentation"}, {"paperId": "cc4e6703e2dc989a9dda64af05079f67b0e19ba4", "title": "Improving Zero-Shot Models with Label Distribution Priors"}, {"paperId": "1a45e828c14123bf35ca913f4a6e08d9cd771dec", "title": "SgVA-CLIP: Semantic-Guided Visual Adapting of Vision-Language Models for Few-Shot Image Classification"}, {"paperId": "ffdad9a5493e8d4c6c529b7b6f85eee91ca0bb79", "title": "SuS-X: Training-Free Name-Only Transfer of Vision-Language Models"}, {"paperId": "b2eb28dd5e2340a5e9de8ae82feaca7b6a265b4e", "title": "Learning Object-Language Alignments for Open-Vocabulary Object Detection"}, {"paperId": "4bae689ade260c1624406b5bf2d58d637a0c5aa9", "title": "SegCLIP: Patch Aggregation with Learnable Centers for Open-Vocabulary Semantic Segmentation"}, {"paperId": "813644fa08fe3de617bceaf1372e5f9904c9debd", "title": "Texts as Images in Prompt Tuning for Multi-Label Image Recognition"}, {"paperId": "fd8c1b8741163d8737652fbcd3507bcd7d6225c7", "title": "Multitask Vision-Language Prompt Tuning"}, {"paperId": "e978d2f7e2a04da803d1a224b3ad868ac919dbb8", "title": "Unifying Vision-Language Representation Space with Single-tower Transformer"}, {"paperId": "04acada438826233ad10730a8b4cb4c2acd4e42d", "title": "Task Residual for Tuning Vision-Language Models"}, {"paperId": "4cee5b151e0f309b070525a4252a25bbb10bc0a7", "title": "AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities"}, {"paperId": "39ed60dd84fb70bebd59ba063a8fc0875b6d8345", "title": "Understanding and Mitigating Overfitting in Prompt Tuning for Vision-Language Models"}, {"paperId": "bbc3b23486df1f9cf66beac79886553e46875b3c", "title": "P3OVD: Fine-grained Visual-Text Prompt-Driven Self-Training for Open-Vocabulary Object Detection"}, {"paperId": "3c2b12824b0027edb49b68300cbeab02cfc49ca8", "title": "Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese"}, {"paperId": "df065b3cd3621211320d9900186243aa1d086067", "title": "Open-vocabulary Semantic Segmentation with Frozen Vision-Language Models"}, {"paperId": "7c4be464e68a11c8f254d9608f31280e9bcda85c", "title": "CPL: Counterfactual Prompt Learning for Vision and Language Models"}, {"paperId": "5ac101f4a3d1c2ea664c75e82385fc20f6f48c31", "title": "Non-Contrastive Learning Meets Language-Image Pre-Training"}, {"paperId": "e5c8960eb2ec034ffbd353ef39fd1cb541d3c7c9", "title": "LAION-5B: An open large-scale dataset for training next generation image-text models"}, {"paperId": "a42b091adaf29b06a092b67192ac07cb93312f2a", "title": "Visual Classification via Description from Large Language Models"}, {"paperId": "09b7338021fff3200c2098b19824aecc83a66cb5", "title": "Unified Vision and Language Prompt Learning"}, {"paperId": "29c2d3d77b6d6f24f4356d5ba20c1a6ab4229c76", "title": "Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP"}, {"paperId": "72b63d3082206fbe46c4ce5225c9d2d3312d5688", "title": "SVL-Adapter: Self-Supervised Adapter for Vision-Language Pretrained Models"}, {"paperId": "0d0dbfb1b315a43216020abaf74d289456198219", "title": "MaPLe: Multi-modal Prompt Learning"}, {"paperId": "0d5103378a9f4f6e08bfcd364da207f93b31b8b7", "title": "Prompt Learning with Optimal Transport for Vision-Language Models"}, {"paperId": "d4b8b03d5e301b23de5180e7f630d53fbd45a5b5", "title": "CLIP2Point: Transfer CLIP to Point Cloud Classification with Image-Depth Pre-Training"}, {"paperId": "83aee45f8afc470f5dbaabc05ccca9304599baf2", "title": "F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models"}, {"paperId": "ca26023c4dbde9a54145b68e1a6a40533fcc1a4a", "title": "CALIP: Zero-Shot Enhancement of CLIP with Parameter-free Attention"}, {"paperId": "5343cc3a894e0c119735e67caa9492a7d17252d6", "title": "UniCLIP: Unified Framework for Contrastive Language-Image Pre-training"}, {"paperId": "667bb464a348b2bc85e7a8e8159b948498850ec7", "title": "DetCLIP: Dictionary-Enriched Visual-Concept Paralleled Pre-training for Open-world Detection"}, {"paperId": "12ad6e798487223f4c17aac69c9853bca8bc7830", "title": "Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models"}, {"paperId": "28630034bb29760df01ab033b743e30b37f336ae", "title": "PaLI: A Jointly-Scaled Multilingual Language-Image Model"}, {"paperId": "007fe51fddfae031570f2d69e67dc67e1fe33621", "title": "What does a platypus look like? Generating customized prompts for zero-shot image classification"}, {"paperId": "ad95b096bf012c6446d601612a2e84f872fcc651", "title": "Prompt Tuning with Soft Context Sharing for Vision-Language Models"}, {"paperId": "99630834ca8aabb4cb0cf73ab6fcfad2b661ef59", "title": "Exploiting Unlabeled Data with Vision and Language Models for Object Detection"}, {"paperId": "d3461268e1153b1abec8f999f6375378a33e0061", "title": "Bridging the Gap between Object and Image-level Representations for Open-Vocabulary Detection"}, {"paperId": "b39743039412e40fef6d5b2f86db36320eab30e1", "title": "DualCoOp: Fast Adaptation to Multi-Label Recognition with Limited Annotations"}, {"paperId": "4c559d29e19f1226353f52ffe9f8068db1cef943", "title": "Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone"}, {"paperId": "4b23a0f7ded1e4201dbb9a2d61397d86d2ad7c48", "title": "ReCo: Retrieve and Co-segment for Zero-shot Transfer"}, {"paperId": "622428f5122ad12a40229e1768ecb929fd747ee7", "title": "Multimodal Learning With Transformers: A Survey"}, {"paperId": "42a6ee55b8fc4000c5ae3f4d942f8754ba16362b", "title": "Prompt-aligned Gradient for Prompt Tuning"}, {"paperId": "9dae204dad41633188022002a04c8aa67c79a4e1", "title": "Simple Open-Vocabulary Object Detection with Vision Transformers"}, {"paperId": "3d6849cba47d68a3126eefca04604e13f69b5cfb", "title": "Prompt Distribution Learning"}, {"paperId": "a26a7a74f1e5fd562be95c3611a0680759fbdf84", "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models"}, {"paperId": "d77b4d45741a83e9024beeec0de5663434754038", "title": "PyramidCLIP: Hierarchical Feature Alignment for Vision-language Model Pretraining"}, {"paperId": "00debf63dafa966221c6e572f7705a813d704ff1", "title": "K-LITE: Learning Transferable Visual Models with External Knowledge"}, {"paperId": "aa8611fd47415740470c3947595d25b906d56112", "title": "ELEVATER: A Benchmark and Toolkit for Evaluating Language-Augmented Visual Models"}, {"paperId": "732627c703a9dbc78d9384f1be4c791c3a554391", "title": "Unsupervised Prompt Learning for Vision-Language Models"}, {"paperId": "5e76879aaea118b532fb24a50b721076d4c6ae93", "title": "Unified Contrastive Learning in Image-Text-Label Space"}, {"paperId": "aa8c61c9f6bb21c57e49611ccb995cfda1b53b10", "title": "Exploring Visual Prompts for Adapting Large-Scale Models"}, {"paperId": "2d2396f56cb08051b811e00fa5d09a86503d00cd", "title": "PromptDet: Towards Open-Vocabulary Detection Using Uncurated Images"}, {"paperId": "d6c73f758b05f38529c1a96cab7e908a2047dabd", "title": "Learning to Prompt for Open-Vocabulary Object Detection with Vision-Language Model"}, {"paperId": "42fa4b2519074027bf71ed4569c5183df75539a2", "title": "Large-scale Bilingual Language-Image Contrastive Learning"}, {"paperId": "5c72636582b0a429c8440e31defda76137ef2072", "title": "Image-text Retrieval: A Survey on Recent Research and Development"}, {"paperId": "adb272fbdea3631059cf88ab764bb6c2ce29f965", "title": "Visual Prompt Tuning"}, {"paperId": "403ad5d6e78fcf29f1ac526fbc9ff6cbfea555eb", "title": "Open-Vocabulary DETR with Conditional Matching"}, {"paperId": "15266082d07055ad43d07af4d51116602467f66f", "title": "Open-Vocabulary One-Stage Detection with Hierarchical Visual-Language Knowledge Distillation"}, {"paperId": "b879450f50a6113f44a5baf0bcd5b4331eeb7bbc", "title": "Conditional Prompt Learning for Vision-Language Models"}, {"paperId": "090d128d95c170c4181b4fc3b744ef1df2c98d97", "title": "CLIMS: Cross Language Image Matching for Weakly Supervised Semantic Segmentation"}, {"paperId": "3b239d232ebb0fdb0515f41fd439e54ed4e8f86a", "title": "Vision-Language Intelligence: Tasks, Representation Learning, and Large Models"}, {"paperId": "0b5f27a5766c5d1394a6282ad94fec21d620bd6b", "title": "GroupViT: Semantic Segmentation Emerges from Text Supervision"}, {"paperId": "24ed74ed29c057cba8b52fff4edd2c0d7f408716", "title": "VLP: A Survey on Vision-language Pre-training"}, {"paperId": "04248a087a834af24bfe001c9fc9ea28dab63c26", "title": "A Survey of Vision-Language Pre-Trained Models"}, {"paperId": "cc9826c222ac1e81b4b374dd9e0df130f298b1e8", "title": "Language-driven Semantic Segmentation"}, {"paperId": "86b42cac364985919987789795be7c3a577ee3de", "title": "Detecting Twenty-thousand Classes using Image-level Supervision"}, {"paperId": "ae92c1fd30ba49212e16152646e9f7f1ae385b08", "title": "A Simple Baseline for Open-Vocabulary Semantic Segmentation with Pre-trained Vision-Language Model"}, {"paperId": "e9581d9758062f76e029bd19a58c4ae976cfb414", "title": "SLIP: Self-supervision meets Language-Image Pre-training"}, {"paperId": "8d737dc6a91a7bfde20aed7bb13d100476de5ae3", "title": "Scaling Open-Vocabulary Image Segmentation with Image-Level Labels"}, {"paperId": "e77c484af99fc1eb3d3c36699ac81822e98cb74d", "title": "Image Segmentation Using Text and Image Prompts"}, {"paperId": "38cc96e5a780716dc7e19e037d96d952b3a37940", "title": "Data Efficient Language-supervised Zero-shot Recognition with Optimal Transport Distillation"}, {"paperId": "d4d74b7902cc81b186ad80ba98e28ac38d1662d0", "title": "Contrastive Vision-Language Pre-training with Limited Resources"}, {"paperId": "837173ef1f260adc0d50b76675915776e1cc8ade", "title": "RegionCLIP: Region-based Language-Image Pretraining"}, {"paperId": "8cafa8545ac3d42854e70408d837ef8244d52544", "title": "Decoupling Zero-Shot Semantic Segmentation"}, {"paperId": "2fd6f77540c1cc8e70b96208ccf9971b4251fc02", "title": "FLAVA: A Foundational Language And Vision Alignment Model"}, {"paperId": "5341b412383c43f4a693ad63ec4489e3ec7688c8", "title": "Grounded Language-Image Pre-training"}, {"paperId": "d6fb5948be7b89d71620f25047c193a55d0d77d5", "title": "Semantic Segmentation In-the-Wild Without Seeing Any Segmentation Examples"}, {"paperId": "f3ce9ba3fcec362b70263a7ed63d9404975496a0", "title": "PointCLIP: Point Cloud Understanding by CLIP"}, {"paperId": "fdf8f703710a6237ee29ab794086844bf245ab0e", "title": "VT-CLIP: Enhancing Vision-Language Models with Visual-guided Texts"}, {"paperId": "6d1ef4436904de111c8b1975bbf25d3fe2f165f7", "title": "DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting"}, {"paperId": "0a7e7347e16bf13d710f6f3d30748baabdbb96ad", "title": "Extract Free Dense Labels from CLIP"}, {"paperId": "74f4439c6a0ec7baa17d1829c9dbc7d2010404fd", "title": "Open-Vocabulary Instance Segmentation via Robust Cross-Modal Pseudo-Labeling"}, {"paperId": "21ec90872abd986c12afe39bebe807732ffa70c9", "title": "Florence: A New Foundation Model for Computer Vision"}, {"paperId": "da4261a957eaa96bf626e9641ef68ebed1d5333f", "title": "RedCaps: web-curated image-text data created by the people, for the people"}, {"paperId": "3fcf9580ecd51f73481d45afb6765d81fe3e7696", "title": "Open Vocabulary Object Detection with Pseudo Bounding-Box Labels"}, {"paperId": "197d5867a45a2988f4dd159063cdfbfe90164962", "title": "LiT: Zero-Shot Transfer with Locked-image text Tuning"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "f675c62abfa788ea0be85d3124eba15a14d5e9d6", "title": "FILIP: Fine-grained Interactive Language-Image Pre-Training"}, {"paperId": "e70b7eb3b22f0a49eb5e645be646d5f35d1e693a", "title": "Tip-Adapter: Training-free CLIP-Adapter for Better Vision-Language Modeling"}, {"paperId": "cf7c2e0e4fb2af689aaf4b7a7cddf7b1f4d5e3f0", "title": "VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts"}, {"paperId": "b668ce936cff0b0ca8b635cd5f25a62eaf4eb3df", "title": "LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs"}, {"paperId": "767923635f2fd4467d848dba9655866e4f9b55c8", "title": "Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm"}, {"paperId": "c04067f03fba2df0c14ea51a170f213eb2983708", "title": "CLIP-Adapter: Better Vision-Language Models with Feature Adapters"}, {"paperId": "9289826beb6206eeaf500105f7329d6d5a495d8a", "title": "Robust fine-tuning of zero-shot models"}, {"paperId": "96ea07447d2f9adefe03852a878517a2a6d45b96", "title": "Learning to Prompt for Vision-Language Models"}, {"paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "2a805d0e1b067444a554c5169d189fa1f649f411", "title": "Scaling Vision Transformers"}, {"paperId": "74d9586dc0593cddae3223a841213c9ea7038bf6", "title": "FBNetV3: Joint Architecture-Recipe Search using Predictor Pretraining"}, {"paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60", "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"}, {"paperId": "cf9b8da26d9b92e75ba49616ed2a1033f59fce14", "title": "Open-vocabulary Object Detection via Vision and Language Knowledge Distillation"}, {"paperId": "7ba9c013988eaff5cd186d73704af329d027872d", "title": "MDETR - Modulated Detection for End-to-End Multi-Modal Understanding"}, {"paperId": "98e565fa06f6c7bf7c46833b5106b26dc45130c4", "title": "WIT: Wikipedia-based Image Text Dataset for Multimodal Multilingual Machine Learning"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "394be105b87e9bfe72c20efe6338de10604e1a11", "title": "Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts"}, {"paperId": "141a5033d9994242b18bb3b217e79582f1ee9306", "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"}, {"paperId": "d29430adccb805ab57b349afa8553954347b3197", "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "e508e1b4404f0c2c8fe55877422b69c1004a1e56", "title": "RareAct: A video dataset of unusual interactions"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "3f6570fd55dc5855f93a56150e6d99c7944a1c1e", "title": "The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes"}, {"paperId": "728e0cdfdd5bb14b6eb74e7038ebcf5e975a4743", "title": "Remote Sensing Image Scene Classification Meets Deep Learning: Challenges, Methods, Benchmarks, and Opportunities"}, {"paperId": "38643c2926b10f6f74f122a7037e2cd20d77c0f1", "title": "Supervised Contrastive Learning"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "7af72a461ed7cda180e7eab878efd5f35d79bbf4", "title": "A Simple Framework for Contrastive Learning of Visual Representations"}, {"paperId": "439369de9514e41e0f03fed552d8f6e5aebf51b2", "title": "Connecting Vision and Language with Localized Narratives"}, {"paperId": "460bcc9b52c17ff95b2dc0de831ca6780a33ceaa", "title": "Deep learning-based image recognition for autonomous driving"}, {"paperId": "add2f205338d70e10ce5e686df4a690e2851bdfc", "title": "Momentum Contrast for Unsupervised Visual Representation Learning"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "a595767fa35bcc84362f629fbc4d2d9b05d7342a", "title": "A survey of deep learning techniques for autonomous driving"}, {"paperId": "c5ff974a69fd0c760b4855b819e61e89f31cfffe", "title": "Objects365: A Large-Scale, High-Quality Dataset for Object Detection"}, {"paperId": "7cf64265882f7129b127ce0e27ff7bca9173aa58", "title": "The Context"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "84c0528cb2aa4bdacad989b5b43441161dd4ecda", "title": "A Short Note on the Kinetics-700 Human Action Dataset"}, {"paperId": "f902a64f7d08aaa6bfca7463e8729952ddc6134e", "title": "LVIS: A Dataset for Large Vocabulary Instance Segmentation"}, {"paperId": "ea8d6c2de162e0f9ad89af7b950333cb29e94622", "title": "Semantic Projection Network for Zero- and Few-Label Semantic Segmentation"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "8c92054c26fb4c6dd7435bc99fbb8af3323eae1b", "title": "Making Convolutional Networks Shift-Invariant Again"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "29309743870c825f9645a4803af727402462e513", "title": "Bag of Tricks for Image Classification with Convolutional Neural Networks"}, {"paperId": "cf336d272a30d6ad6141db67faa64deb8791cd61", "title": "A Corpus for Reasoning about Natural Language Grounded in Photographs"}, {"paperId": "b227f3e4c0dc96e5ac5426b85485a70f2175a205", "title": "Representation Learning with Contrastive Predictive Coding"}, {"paperId": "b4df354db88a70183a64dbc9e56cf14e7669a6c0", "title": "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"}, {"paperId": "2a96afaf3261a87f0daa51699b4b3cf169e092c4", "title": "Rotation Equivariant CNNs for Digital Pathology"}, {"paperId": "8e2d8cee2fc474d0c08bfdfa707993d005067823", "title": "Visual Referring Expression Recognition: What Do Systems Actually Learn?"}, {"paperId": "9c88c2357abcd58cc330179c1965fe0a8c067ebc", "title": "EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification"}, {"paperId": "b3d7a7440bb170a935589f6e12aa665fb7516b47", "title": "Deep learning in robotics: a review of recent research"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "179765729fc1e269393617795507607c29a66a8e", "title": "Remote Sensing Image Scene Classification: Benchmark and State of the Art"}, {"paperId": "03eb382e04cca8cca743f7799070869954f1402a", "title": "CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning"}, {"paperId": "cab372bc3824780cce20d9dd1c22d4df39ed081a", "title": "DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs"}, {"paperId": "9979b794d0bd06a1959a6b169f2cf32ba8ba376b", "title": "Going deeper into action recognition: A survey"}, {"paperId": "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "title": "Context Encoders: Feature Learning by Inpainting"}, {"paperId": "c8c494ee5488fe20e0aa01bddf3fc4632086d654", "title": "The Cityscapes Dataset for Semantic Urban Scene Understanding"}, {"paperId": "2ec8f7e0257a07d3914322b36072d1bbcd58a1e0", "title": "Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles"}, {"paperId": "8201e6e687f2de477258e9be53ba7b73ee30d7de", "title": "Colorful Image Colorization"}, {"paperId": "afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d", "title": "Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "97ad70a9fa3f99adf18030e5e38ebe3d90daa2db", "title": "VQA: Visual Question Answering"}, {"paperId": "7ffdbc358b63378f07311e883dddacc9faeeaf4b", "title": "Fast R-CNN"}, {"paperId": "696ca58d93f6404fea0fc75c62d1d7b378f47628", "title": "Microsoft COCO Captions: Data Collection and Evaluation Server"}, {"paperId": "6fc6803df5f9ae505cae5b2f178ade4062c768d0", "title": "Fully convolutional networks for semantic segmentation"}, {"paperId": "8e3f12804882b60ad5f59aad92755c5edb34860e", "title": "Food-101 - Mining Discriminative Components with Random Forests"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "3419ccd5c94d301ee08d716d037f0c3c6a62e78e", "title": "The Role of Context for Object Detection and Semantic Segmentation in the Wild"}, {"paperId": "4965eec4d6fd69e9bff12dce7d9d84897433cc2a", "title": "Birdsnap: Large-Scale Fine-Grained Visual Categorization of Birds"}, {"paperId": "7f1b111f0bb703b0bd97aba505728a9b0d9b2a54", "title": "Deep Fragment Embeddings for Bidirectional Image Sentence Mapping"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "44040913380206991b1991daf1192942e038fe31", "title": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions"}, {"paperId": "18c125ce0f64e85577f7d30132cf0e92ec664bf4", "title": "Describing Textures in the Wild"}, {"paperId": "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation"}, {"paperId": "b8de958fead0d8a9619b55c7299df3257c624a96", "title": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "79b949d9b35c3f51dd20fb5c746cc81fc87147eb", "title": "Vision meets robotics: The KITTI dataset"}, {"paperId": "db8c3cfaae04a14c1209d62953029b6fa53e23c7", "title": "Challenges in representation learning: A report on three machine learning contests"}, {"paperId": "522d65a3db7431015aeaa201a7fc4450a57e40c3", "title": "Fine-Grained Visual Classification of Aircraft"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "da9e411fcf740569b6b356f330a1d0fc077c8d7c", "title": "UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild"}, {"paperId": "84b50ebe85f7a1721800125e7882fce8c45b5c5a", "title": "Cats and dogs"}, {"paperId": "de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42", "title": "Are we ready for autonomous driving? The KITTI vision benchmark suite"}, {"paperId": "8e080b98efbe65c02a116439205ca2344b9f7cd4", "title": "Im2Text: Describing Images Using 1 Million Captioned Photographs"}, {"paperId": "be9a17321537d9289875fe475b71f4821457b435", "title": "An Analysis of Single-Layer Networks in Unsupervised Feature Learning"}, {"paperId": "22fe619996b59c09cb73be40103a123d2e328111", "title": "The German Traffic Sign Recognition Benchmark: A multi-class classification competition"}, {"paperId": "eefcc7bcc05436dac9881acb4ff4e4a0b730e175", "title": "High-dimensional signature compression for large-scale image classification"}, {"paperId": "1aa5a8ad5b7031ba39e1dc0537484694364a1312", "title": "Evaluating Color Descriptors for Object and Scene Recognition"}, {"paperId": "2f7713dcc35e7c05becf3be5522f36c9546b0364", "title": "Locality-constrained Linear Coding for image classification"}, {"paperId": "908091b4a8757c3b2f7d9cfa2c4f616ee12c5157", "title": "SUN database: Large-scale scene recognition from abbey to zoo"}, {"paperId": "3a9b175324ba11bc0e16c0633912d897b2fac4e2", "title": "The Pascal Visual Object Classes (VOC) Challenge"}, {"paperId": "bb5b2df137a4d54c3a9145fa363e66531b491580", "title": "Scene Text Recognition using Higher Order Language Priors"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "0c9633aedafe4ee8cf238fa06c40b84f47e17362", "title": "Linear spatial pyramid matching using sparse coding for image classification"}, {"paperId": "6e0121548ae114b8ed70b5189cbc4800d8b4290d", "title": "K-nearest neighbor"}, {"paperId": "02b28f3b71138a06e40dbd614abf8568420ae183", "title": "Automated Flower Classification over a Large Number of Classes"}, {"paperId": "7c3ed9daaf6c56498f9defefecab215635eb7994", "title": "Multiclass and Binary SVM Classification: Implications for Training and Classification Users"}, {"paperId": "dee20a7ce7745fc367c8bc7ede4f7b8c22efa52d", "title": "Local Features and Kernels for Classification of Texture and Object Categories: A Comprehensive Study"}, {"paperId": "8c04f169203f9e55056a6f7f956695babe622a38", "title": "Distinctive Image Features from Scale-Invariant Keypoints"}, {"paperId": "ae549c5b195ceb0f0f97c5ff3e9b7ed4126def73", "title": "Toward intelligent training of supervised image classifications: directing training data acquisition for SVM classification"}, {"paperId": "ed9db7b20e019cdb1c7db8b7921221ee2d9f36e2", "title": "Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories"}, {"paperId": "52b7bf3ba59b31f362aa07f957f1543a29a4279e", "title": "Support-Vector Networks"}, {"paperId": "ac694e97b1346de82114290d7cfbffd7a1a09c1d", "title": "Wukong: 100 Million Large-scale Chinese Cross-modal Pre-training Dataset and A Foundation Framework"}, {"paperId": "4b361a70a60a51de032c7bf8c37a67dc81340376", "title": "Class-Aware Visual Prompt Tuning for Vision-Language Pre-Trained Model"}, {"paperId": "d7d8c21bb385b701687f220466e519fc898502a7", "title": "Language-Aware Soft Prompting for Vision & Language Foundation Models"}, {"paperId": "e5303b14b8188641f567223e04573d3c4f81945a", "title": "Variational prompt tuning improves generalization of vision-language models"}, {"paperId": "6e83adf8a052c02aa49559add16e4376996602fa", "title": "Masked Unsupervised Self-training for Zero-shot Image Classification"}, {"paperId": "42b2a4868756e24afb7f89d376547fe67f64aa31", "title": "ZSD-YOLO: Zero-Shot YOLO Detection using Vision-Language KnowledgeDistillation"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "9fa62065267bd6566bfd48cb7d3e8b0bafe28187", "title": "MAKING CONVOLUTIONAL NETWORKS SHIFT-INVARIANT AGAIN"}, {"paperId": "fd62a4d907ff9a98cd69926b7dd72cb980713715", "title": "Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources"}, {"paperId": null, "title": "Yfcc100m: The new data in multimedia research"}, {"paperId": "eae500ce89f7cc5cd48a58c4ba7edb2f02826b85", "title": "Collecting a Large-scale Dataset of Fine-grained Cars"}, {"paperId": "02227c94dd41fe0b439e050d377b0beb5d427cda", "title": "Reading Digits in Natural Images with Unsupervised Feature Learning"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "423815a794503aa04a4418015baae83f09556ea3", "title": "Local Features and Kernels for Classication of Texture and Object Categories: A Comprehensive Study"}, {"paperId": "8e0be569ea77b8cb29bb0e8b031887630fe7a96c", "title": "Random Forests"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}, {"paperId": "070874b011f8eb2b18c8aa521ad0a7a932b4d9ad", "title": "Action Recognition with Improved Trajectories"}, {"paperId": null, "title": "VISION-LANGUAGE MODELS FOR VISION TASKS: A SURVEY"}, {"paperId": null, "title": "license agreement with IEEE. Restrictions apply"}]}