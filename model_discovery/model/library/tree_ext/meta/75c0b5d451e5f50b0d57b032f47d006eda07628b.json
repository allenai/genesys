{"paperId": "75c0b5d451e5f50b0d57b032f47d006eda07628b", "title": "MoEUT: Mixture-of-Experts Universal Transformers", "abstract": "Previous work on Universal Transformers (UTs) has demonstrated the importance of parameter sharing across layers. By allowing recurrence in depth, UTs have advantages over standard Transformers in learning compositional generalizations, but layer-sharing comes with a practical limitation of parameter-compute ratio: it drastically reduces the parameter count compared to the non-shared model with the same dimensionality. Naively scaling up the layer size to compensate for the loss of parameters makes its computational resource requirements prohibitive. In practice, no previous work has succeeded in proposing a shared-layer Transformer design that is competitive in parameter count-dominated tasks such as language modeling. Here we propose MoEUT (pronounced\"moot\"), an effective mixture-of-experts (MoE)-based shared-layer Transformer architecture, which combines several recent advances in MoEs for both feedforward and attention layers of standard Transformers together with novel layer-normalization and grouping schemes that are specific and crucial to UTs. The resulting UT model, for the first time, slightly outperforms standard Transformers on language modeling tasks such as BLiMP and PIQA, while using significantly less compute and memory.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The proposed MoEUT (pronounced\"moot\"), an effective mixture-of-experts (MoE)-based shared-layer Transformer architecture, which combines several recent advances in MoEs for both feedforward and attention layers of standard Transformers together with novel layer-normalization and grouping schemes that are specific and crucial to UTs."}, "embedding": {"model": "specter_v2", "vector": [0.5402182340621948, 0.55110764503479, -0.7114898562431335, -0.13056372106075287, -0.3702385425567627, 0.010018100962042809, 0.7316077947616577, -0.23361651599407196, -0.2687508463859558, -0.3515482246875763, 0.7827181220054626, 0.014951716177165508, 0.04847918078303337, 0.3953467011451721, -0.1288221925497055, 0.20964384078979492, -0.8452513217926025, 0.6424537301063538, 0.2739432156085968, -0.583558201789856, -0.5533787608146667, -0.6164924502372742, -1.2624120712280273, 0.49814650416374207, 0.6015141606330872, 0.8092784881591797, 0.16487468779087067, 0.9165533185005188, -0.5062135457992554, 0.6322263479232788, 0.7973768711090088, -0.42391836643218994, 0.20273935794830322, 0.10099440068006516, -0.13913534581661224, 0.28648626804351807, 0.46755412220954895, -0.5157583951950073, -0.28270289301872253, 0.5518941879272461, -0.3533041775226593, 0.18019796907901764, 1.020786166191101, -0.9492016434669495, -0.22607499361038208, 1.4229249954223633, 0.7516385912895203, 0.47460535168647766, -0.7062102556228638, -0.7642735838890076, 1.6111973524093628, -1.3440194129943848, -0.21524935960769653, 1.687461018562317, 0.5644885897636414, 0.6686398983001709, -0.4697725772857666, -0.7846930027008057, 0.8798945546150208, -0.02804209105670452, -0.8647394180297852, -0.4007241427898407, -0.2973664104938507, -0.270656019449234, 1.9657763242721558, -0.3875570297241211, -0.19910430908203125, 0.20898668467998505, -0.14129529893398285, 1.4386730194091797, -0.2469574511051178, -0.14975926280021667, -0.30905821919441223, 0.32077622413635254, 0.027637114748358727, 0.8912501335144043, -0.5092992782592773, 0.2527238130569458, -1.2096771001815796, -0.27647197246551514, 0.5947474241256714, 0.17298203706741333, 0.012946996837854385, -0.3372122049331665, -0.3299404978752136, 0.7223677635192871, 0.5044406056404114, 0.9579119682312012, -0.39893874526023865, 0.5188685655593872, 0.5676608085632324, 0.2923997640609741, 0.08383917063474655, 0.42496922612190247, -0.42619889974594116, 0.9408910274505615, -0.9598447680473328, 0.5627654194831848, -0.17713414132595062, 0.8476125597953796, 0.29471778869628906, 0.15343602001667023, -0.6992715001106262, 0.46364903450012207, 1.5593777894973755, 0.0382937490940094, 0.5373403429985046, -0.8327862024307251, 0.10723261535167694, -0.26105859875679016, -0.012359167449176311, -0.34661224484443665, -0.07387609034776688, -0.15657255053520203, -1.0581978559494019, -1.3447315692901611, -0.947485089302063, 0.7317065000534058, -0.6896350979804993, 0.7926465272903442, -0.39899617433547974, -0.009525165893137455, 0.11899180710315704, 0.361080139875412, 0.35540536046028137, 0.45247113704681396, 0.7747827172279358, 0.09555379301309586, 0.9097362756729126, -1.004379391670227, -0.8589733839035034, -1.147428274154663, 0.46973568201065063, 0.054427240043878555, 0.01403430849313736, -0.07866518199443817, -1.0179327726364136, -0.9935514330863953, -0.9575598835945129, -0.08138088881969452, -0.39441245794296265, 0.18638408184051514, 1.0989753007888794, 0.5506184697151184, -0.9226745367050171, 0.7699499130249023, -0.14868663251399994, -0.010559169575572014, 0.41750672459602356, 0.4576377868652344, 0.19488465785980225, -0.22577141225337982, -1.2555732727050781, 0.24223291873931885, 0.5162271857261658, -0.6930302381515503, -0.6631921529769897, -1.0882296562194824, -0.8949514031410217, -0.09090790897607803, 0.36147812008857727, -1.0129889249801636, 1.6674641370773315, -0.2667589783668518, -1.5241742134094238, 0.28084805607795715, -0.5370282530784607, 0.036766085773706436, 0.07520294189453125, -0.2989051640033722, -0.509355902671814, -0.6076355576515198, -0.250305712223053, 0.5454237461090088, 0.6933145523071289, -0.41262346506118774, -0.35715335607528687, 0.18800108134746552, -0.22453133761882782, 0.010160681791603565, -0.4264260530471802, 0.8653830885887146, -0.12009122222661972, 0.11305323243141174, 0.22867165505886078, 1.0812830924987793, -0.31427374482154846, -0.23854883015155792, -0.1954278200864792, -1.2186565399169922, 0.5419382452964783, -0.007807778660207987, 1.1722450256347656, -0.7764862775802612, -0.29043126106262207, -0.20560577511787415, 0.16016003489494324, -0.2135924994945526, -0.4888874292373657, 0.8297492265701294, -0.34851643443107605, 0.2641478478908539, -0.6286954283714294, -1.49271821975708, 0.4627818465232849, 0.07431020587682724, -0.695826530456543, -0.5149271488189697, -0.0002656119177117944, 1.065768837928772, -0.9640935659408569, 0.01329112146049738, -0.04649761691689491, 0.30661341547966003, -1.009812355041504, 1.4749422073364258, -0.7655280828475952, 0.1524350643157959, 0.23083743453025818, -0.43934834003448486, -0.13719795644283295, -0.3118242621421814, 0.5248602032661438, -0.3309733271598816, -0.07380864769220352, 0.6023313999176025, -0.6164888739585876, 1.4964730739593506, -0.3731539249420166, 0.053512539714574814, -0.1380160003900528, -0.4912862181663513, -0.006335264537483454, 0.9635254144668579, -0.1077495813369751, -0.2999540865421295, 0.41787436604499817, 0.8754776120185852, -0.5906574726104736, 0.5297064185142517, 0.678507387638092, 0.2201787233352661, -0.2811477780342102, 0.28624236583709717, 1.062625527381897, -0.43003755807876587, 0.5481529235839844, 0.6526719927787781, 0.5359870791435242, 0.05711934342980385, 0.4817699193954468, -0.1927836388349533, 0.5376564264297485, -1.1587859392166138, -0.17945964634418488, 0.3064994215965271, 0.8498538136482239, 0.696114718914032, 0.13705386221408844, -0.5106081962585449, -0.37585169076919556, -0.14937043190002441, 0.7716615796089172, 2.0824241638183594, -0.5076018571853638, -0.3254665732383728, -0.620917022228241, -0.18649396300315857, -0.320552259683609, 0.013796167448163033, -0.3450350761413574, -0.05960087850689888, -0.4562126398086548, -0.9542362689971924, 0.7449631094932556, 0.5210626125335693, 0.8298535943031311, -0.3150782287120819, -0.13929711282253265, -0.12593984603881836, 0.3126850128173828, -0.6738986968994141, -0.7015400528907776, 0.4056421220302582, -0.6342269778251648, -0.12001517415046692, -0.11044584959745407, -0.07223068922758102, -0.03551725298166275, -0.7627897262573242, 0.8069694638252258, -0.9166550040245056, 0.0735497772693634, 0.1212814524769783, 0.8703799247741699, -0.5683581233024597, -0.867583692073822, 0.11022044718265533, 0.19171786308288574, 0.25027304887771606, 0.12059571593999863, 0.12574392557144165, 0.17777511477470398, 0.28647497296333313, -0.5442717671394348, 0.24602751433849335, 0.0406070202589035, -0.17569294571876526, 0.5265331864356995, -0.0615137554705143, -0.2619459927082062, -1.469071388244629, 0.8844667077064514, 0.018615884706377983, -0.14819762110710144, 0.36866939067840576, -0.4447593092918396, -0.37260034680366516, 0.35478052496910095, -0.8347533345222473, -0.41449642181396484, -1.077338457107544, 0.6465884447097778, -0.34341469407081604, -0.08492577075958252, 0.03779930621385574, -0.22644837200641632, 0.4918498694896698, 0.2986748218536377, 0.22524310648441315, 0.07202350348234177, -0.3792571723461151, 0.8711619973182678, -0.6864640116691589, 0.5337132811546326, 0.14359953999519348, 0.16753260791301727, -0.4327654540538788, -0.4670518636703491, -0.6004977822303772, -0.30900996923446655, -0.8155991435050964, 0.10339012742042542, -0.040951214730739594, 0.08067912608385086, -0.7770784497261047, -0.8031507730484009, 0.21528586745262146, -1.1562223434448242, -0.23624247312545776, 0.4029088318347931, -0.47149187326431274, -0.10076604783535004, -1.184829592704773, -1.3502339124679565, -0.7285013794898987, -0.6303694248199463, -1.1035631895065308, 0.47361576557159424, -0.14664511382579803, -0.4858647882938385, -0.5951812863349915, 0.10303234308958054, -0.24475620687007904, 1.2511800527572632, -0.9260948896408081, 0.9466640949249268, -0.27676302194595337, -0.395473450422287, 0.2511509358882904, 0.029562933370471, 0.9675943851470947, -0.16758061945438385, 0.05443235859274864, -1.187048077583313, 0.42707559466362, -0.39823117852211, -0.07185418158769608, 0.18103353679180145, 0.08822725713253021, 0.623957097530365, -0.28988003730773926, -0.3725410997867584, 0.19799311459064484, 1.3488452434539795, -0.7184268832206726, -0.14895901083946228, -0.18090815842151642, 1.0666720867156982, 0.3420819938182831, -0.9034755229949951, 0.5224741697311401, 0.7078449130058289, 0.46275442838668823, 0.16482321918010712, -0.07785450667142868, -0.02735678106546402, -0.4015336334705353, 0.5283355712890625, 1.733515739440918, 0.16333790123462677, -0.12589983642101288, -0.8921011090278625, 0.8220644593238831, -1.4686764478683472, -0.2896542549133301, 0.8142155408859253, 0.5131915807723999, 0.3253360092639923, -0.8473474383354187, 0.08879639208316803, -0.006869466509670019, 0.3166143298149109, 0.29866915941238403, -0.23920176923274994, -0.7676405310630798, 0.09810302406549454, 0.5833268165588379, 0.15910612046718597, 0.721729576587677, -0.22983302175998688, 0.33161839842796326, 14.499894142150879, 0.6832051873207092, 0.3052225410938263, 1.1095597743988037, 0.281305730342865, 0.34253254532814026, -0.8332439661026001, -0.2418854534626007, -1.1061789989471436, -0.3599643409252167, 1.3037762641906738, 0.37155988812446594, 0.8445246815681458, -0.16875571012496948, -0.37086784839630127, 0.53305584192276, -0.6576693654060364, 0.39724200963974, 0.2528568506240845, -1.0176810026168823, 0.7340378165245056, -0.06882157921791077, 0.7671656608581543, 0.34230783581733704, 0.7033417224884033, 0.7696572542190552, 0.5866109728813171, -0.6475282311439514, 0.30738624930381775, 0.35711756348609924, 0.6152058243751526, -0.08367612957954407, 0.34275680780410767, 0.6201455593109131, -1.1299020051956177, -0.3672143518924713, -0.4635108411312103, -1.0667755603790283, 0.2687252461910248, 0.11429233849048615, -0.6518781185150146, -0.1864265650510788, -0.03591126948595047, 0.8276774883270264, 0.49545714259147644, 0.16220110654830933, -0.27544593811035156, 0.4375637471675873, -0.16068032383918762, 0.5736607313156128, 0.1917090266942978, 0.6348395347595215, -0.15016122162342072, 0.027634738013148308, -0.0536809004843235, -0.3106370270252228, 0.30175265669822693, 0.33906689286231995, -0.43309953808784485, 0.09407201409339905, -0.11603306233882904, -0.33238768577575684, -0.19420595467090607, 0.6957560777664185, 0.8906484842300415, 0.06228324770927429, -0.4461892247200012, 0.15077246725559235, 0.4105878472328186, 0.40396806597709656, -0.18463638424873352, 0.27504611015319824, 0.5115146040916443, -0.3179129958152771, -0.02952500991523266, 0.9149861931800842, -0.0708940178155899, -0.24251528084278107, -0.9137457013130188, -0.6512608528137207, 0.32814472913742065, -0.2902906537055969, -0.9965905547142029, 0.8096422553062439, 0.1091563031077385, -0.051276154816150665, 0.04364806413650513, -0.5355000495910645, -0.18804931640625, 0.6510778069496155, -1.097983717918396, -1.0677579641342163, 0.40768900513648987, -0.32209309935569763, -0.6971807479858398, -0.3893482983112335, 1.289891004562378, 0.304769903421402, -0.3409539759159088, -0.05629154294729233, -0.24711845815181732, -0.543289840221405, -0.2696923017501831, -0.8620160222053528, 0.7178983688354492, 0.02145182155072689, -0.20498409867286682, 0.5552409887313843, 0.20813751220703125, 0.4280928373336792, -0.3085710406303406, -0.11232610046863556, 1.1422456502914429, -0.7894757986068726, -0.17082247138023376, -0.7771406173706055, -1.0819422006607056, 0.5705146193504333, 0.5658329129219055, -0.2839801609516144, 0.5793580412864685, 0.12441299110651016, -0.9795572757720947, -0.1532585620880127, -0.5657105445861816, -0.2017274796962738, 0.5691925883293152, -1.1020207405090332, -0.3875580132007599, -0.13154444098472595, 0.37775975465774536, -0.8385946750640869, -0.7343271374702454, 0.009844520129263401, 0.34912174940109253, -0.10423033684492111, 1.1139940023422241, -0.27452635765075684, 0.29005059599876404, 0.5593497157096863, -0.3628007173538208, -0.8584412336349487, -0.06126028671860695, -1.0198025703430176, -0.13609185814857483, 0.0513455830514431, 0.5917603373527527, -0.5764757990837097, -0.22187012434005737, 0.37834876775741577, 0.07396198809146881, -0.37486061453819275, -0.4429478943347931, -0.0891692042350769, -0.017452234402298927, -0.709620475769043, 0.796255886554718, -0.2649446725845337, -0.1979077160358429, 0.255527526140213, 0.2911839187145233, 0.7317317724227905, -0.06926781684160233, -1.1232149600982666, 0.2945617139339447, -0.09653870016336441, -0.4109644293785095, -0.9520087838172913, -0.19416643679141998, -1.1346585750579834, -0.09728343784809113, -1.1479805707931519, 0.2526351511478424, -1.0753259658813477, -0.12890441715717316, 0.22168095409870148, -0.5946492552757263, 0.1050449013710022, -0.0007523508975282311, -0.1984972506761551, -0.5666871070861816, -0.5993161201477051, -0.5518076419830322, 0.8528254628181458, 0.9799270629882812, -0.7546656727790833, 0.16534049808979034, -0.13356328010559082, -0.05837690830230713, 0.1289753019809723, 0.4377444088459015, -0.23154623806476593, -1.2163022756576538, -1.1384141445159912, 0.4283907115459442, -0.17124421894550323, 0.017040997743606567, -0.7198010087013245, 0.8774413466453552, 0.44236135482788086, -0.5808898210525513, 0.16325168311595917, 0.47168514132499695, -0.8706037402153015, 0.0061328518204391, 0.18633072078227997, -0.8101243376731873, 0.18218272924423218, 0.19862613081932068, -0.7845082879066467, -0.39998069405555725, 0.9441907405853271, -0.119118832051754, -1.1542057991027832, -0.6427335143089294, 0.6973459124565125, -0.7267639636993408, -0.10836365818977356, -0.7264444828033447, 0.04204411059617996, -0.9569973349571228, -0.06286300718784332, 0.42640945315361023, 0.412248820066452, -0.3427828252315521, 0.65003901720047, 0.3002883493900299, -0.8704290986061096, -0.08276589214801788, 0.626251757144928, 0.2322503626346588, 0.09045178443193436, 0.7392123937606812, 0.5963155627250671, 0.15491485595703125, 0.8582882285118103, 0.3009023070335388, 0.40276241302490234, -0.6494986414909363, -0.19628705084323883, 1.043887734413147, -0.7522348165512085, 0.029856249690055847, 1.3939027786254883, 0.2988549470901489, -1.4955064058303833, -0.0046279896050691605, -1.1625370979309082, -0.5109382271766663, -0.44592028856277466, 0.9748376607894897, 0.33260780572891235, -0.1151924729347229, -0.0778631791472435, -0.5046681761741638, 0.24352259933948517, 0.0020548724569380283, -0.5513666272163391, 0.5739296078681946, 0.08457586914300919, -0.7426895499229431, 1.0714356899261475, 0.583187460899353, -0.8660890460014343, -0.6258735656738281, -0.9360790252685547, -0.42186129093170166, 0.17829765379428864, 0.3483574092388153, -0.3711788058280945, -0.5082013010978699, 0.8047736287117004, 0.27532511949539185, 0.19830851256847382, 0.26941120624542236, -0.08930478990077972, 0.15174010396003723, 0.19738559424877167, -0.0393962599337101, -0.22738687694072723, -0.5839239954948425, 1.1706194877624512, 1.2508360147476196, -0.6631698608398438, 0.25594571232795715, -0.35374715924263, -0.9153135418891907, 0.5772929191589355, 0.09790562838315964, -0.002399167977273464, 0.6278991103172302, -0.26862287521362305, 0.029754942283034325, 0.10893893986940384, -1.5741527080535889, -0.43069809675216675, 1.4535707235336304, 1.1344701051712036, 0.8666414618492126, 0.667994499206543, 0.3723495304584503, 0.9940114617347717, 0.2009507417678833, -0.03746851906180382, -0.010136106051504612, 0.29975736141204834, -0.35164111852645874, -0.30827248096466064, 0.25335079431533813, 0.5174928307533264, -0.3118121027946472, -0.4444293677806854, 0.1348014920949936, 0.2315189391374588, 0.6707342267036438, 0.5834779739379883, 0.5568840503692627, 0.11064916104078293, 0.4733664095401764, 0.30686262249946594, 0.7087427973747253, -0.7488633394241333, -0.5589742064476013, -0.20551736652851105, -0.7889223098754883, -0.12932123243808746, -0.5547347664833069, -0.18712060153484344, -0.16523097455501556, -0.14160875976085663, 0.548417866230011, -0.013075867667794228, 0.4367068111896515, 1.4419854879379272, 0.21651725471019745, 0.7113184928894043, -0.42080146074295044, -0.4664374887943268, -0.45647603273391724, -1.247108817100525, -0.3012080788612366, -0.545489490032196, -0.05436087027192116, -0.3989246189594269, -0.15206198394298553, -0.5063246488571167]}, "authors": [{"authorId": "2303405517", "name": "R'obert Csord'as"}, {"authorId": "2350348", "name": "Kazuki Irie"}, {"authorId": "2260653300", "name": "J\u00fcrgen Schmidhuber"}, {"authorId": "2280333621", "name": "Christopher Potts"}, {"authorId": "2290916250", "name": "Christopher D. Manning"}], "references": [{"paperId": "9548bacc4c7714151b674748dc86e2cc185a4955", "title": "Scaling Laws for Fine-Grained Mixture of Experts"}, {"paperId": "16d6e1ed1cf72212f6154644f3aa59d18bc95fda", "title": "DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models"}, {"paperId": "ab7d320cbae173aef86c31faa087780cba44551f", "title": "SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling"}, {"paperId": "f56fd8eee26d28111ba0e8dd812ee5fc813f666f", "title": "SwitchHead: Accelerating Transformers with Mixture-of-Experts Attention"}, {"paperId": "2fc229bfe561f42aae6f3bb84598cfa5737a8b6a", "title": "Approximating Two-Layer Feedforward Networks for Efficient Transformers"}, {"paperId": "bcd84a2b8f9ae40a908f375425f113c82f8dd739", "title": "Sparse Universal Transformer"}, {"paperId": "8f7f7b48184217c131844d725daefe6734735d8a", "title": "ResiDual: Transformer with Dual Residual Connections"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "f3a6115e5fb2237df938976e005468f0b18da797", "title": "The Stack: 3 TB of permissively licensed source code"}, {"paperId": "3820231d31540ecb05d94c74d959a2f61d3136ea", "title": "Mixture of Attention Heads: Selecting Attention Heads Per Token"}, {"paperId": "c90a99eeb57019732a6cc996bb9eaf13faedf00f", "title": "In-context Learning and Induction Heads"}, {"paperId": "9d125f45b1d2dea01f05281470bc08e12b6c7cba", "title": "Toy Models of Superposition"}, {"paperId": "6edccbd83a9aae204785d4821f97855677c33866", "title": "Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling?"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "c2536182c010c41941e8a031071a1880c34cec60", "title": "Unified Scaling Laws for Routed Language Models"}, {"paperId": "fcf25e1affc2f8ee5bb49d156f174e9769234deb", "title": "Systematic Generalization with Edge Transformers"}, {"paperId": "e528466e2aff981511d4ca6e063211297c0b4175", "title": "The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization"}, {"paperId": "ed535e93d5b5a8b689e861e9c6083a806d1535c2", "title": "The Devil is in the Detail: Simple Tricks Improve Systematic Generalization of Transformers"}, {"paperId": "49e65b12d8d11f2ccb5ddd7be72a8f746b2d1bc2", "title": "Making Transformers Solve Compositional Tasks"}, {"paperId": "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500", "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "3456c1e95d8d2f985a0701232dd55171b3cbd5e0", "title": "Lessons on Parameter Sharing across Layers in Transformers"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "1882f194cb43828852cc052887671e55a80f945a", "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a", "title": "On Layer Normalization in the Transformer Architecture"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "5a2263092f49540fd0e049050a96882ff29b00c3", "title": "BLiMP: The Benchmark of Linguistic Minimal Pairs for English"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "88bb0a28bb58d847183ec505dda89b63771bb495", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586", "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "5ed791f810da580c78df6a052c6b9f2e258f6b0a", "title": "The LAMBADA dataset: Word prediction requiring a broad discourse context"}, {"paperId": "04cca8e341a5da42b29b0bc831cb25a0f784fa01", "title": "Adaptive Computation Time for Recurrent Neural Networks"}, {"paperId": "77f0a39b8e02686fd85b01971f8feb7f60971f80", "title": "Identity Mappings in Deep Residual Networks"}, {"paperId": "35b91b365ceb016fb3e022577cec96fb9b445dc5", "title": "The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations"}, {"paperId": "152d82025f02916019e4cfcc943dceecc159cda4", "title": "Self-Delimiting Neural Networks"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "c8d90974c3f3b40fa05e322df2905fc16204aa56", "title": "Adaptive Mixtures of Local Experts"}, {"paperId": "211b9dacd95a49943f24cb552539e9a2caf416a3", "title": "The Meta-Pi network: connectionist rapid adaptation for high-performance multi-speaker phoneme recognition"}, {"paperId": "668087f0ae7ce1de6e0bd0965dbb480c08103260", "title": "Finding Structure in Time"}, {"paperId": "d76aafbeb54575859441a442376766c597f6bb52", "title": "Attractor dynamics and parallelism in a connectionist sequential machine"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Learning to control fast-weight memories: An alternative to recurrent nets"}, {"paperId": "568ee0b465e1abeda16811b63bbbe348b48e5575", "title": "Local vs. Distributed Coding"}, {"paperId": null, "title": "SlimPajama: A 627B token cleaned and deduplicated version of RedPajama, June 2023"}, {"paperId": null, "title": "peS2o (Pretraining Efficiently on S2ORC) Dataset"}, {"paperId": null, "title": "active experts for the \u03c3 -MoE layer"}, {"paperId": null, "title": "OpenAI"}]}