{"paperId": "592e2a4c8bb3e72b1f6d671d6642907fa81b1782", "title": "Noise Is Not the Main Factor Behind the Gap Between SGD and Adam on Transformers, but Sign Descent Might Be", "abstract": "The success of the Adam optimizer on a wide array of architectures has made it the default in settings where stochastic gradient descent (SGD) performs poorly. However, our theoretical understanding of this discrepancy is lagging, preventing the development of significant improvements on either algorithm. Recent work advances the hypothesis that Adam and other heuristics like gradient clipping outperform SGD on language tasks because the distribution of the error induced by sampling has heavy tails. This suggests that Adam outperform SGD because it uses a more robust gradient estimate. We evaluate this hypothesis by varying the batch size, up to the entire dataset, to control for stochasticity. We present evidence that stochasticity and heavy-tailed noise are not major factors in the performance gap between SGD and Adam. Rather, Adam performs better as the batch size increases, while SGD is less effective at taking advantage of the reduction in noise. This raises the question as to why Adam outperforms SGD in the full-batch setting. Through further investigation of simpler variants of SGD, we find that the behavior of Adam with large batches is similar to sign descent with momentum.", "venue": "International Conference on Learning Representations", "year": 2023, "citationCount": 40, "influentialCitationCount": 8, "openAccessPdf": {"url": "http://arxiv.org/pdf/2304.13960", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "Evidence is presented that stochasticity and heavy-tailed noise are not major factors in the performance gap between SGD and Adam, and that Adam performs better as the batch size increases, while SGD is less effective at taking advantage of the reduction in noise."}, "embedding": {"model": "specter_v2", "vector": [0.14146897196769714, 0.844109296798706, 0.18723055720329285, -0.16037866473197937, -0.2825539708137512, 0.12574957311153412, 0.8559520244598389, -0.562457799911499, -0.5177607536315918, -0.11896149069070816, 0.4524504244327545, -0.1869274526834488, 0.8053594827651978, -0.038173139095306396, -0.43937841057777405, -0.4983847141265869, -0.942201554775238, 0.42380961775779724, 0.07392407208681107, -0.6003722548484802, -0.5486846566200256, -0.7534035444259644, -0.9071468114852905, 0.1701550930738449, 0.35315197706222534, 0.7829456925392151, -0.1688050478696823, 1.040588140487671, -0.244801327586174, 0.8635275363922119, 0.16643330454826355, -0.5980205535888672, 0.6306357979774475, -0.6180926561355591, -0.3071145713329315, -0.12569178640842438, 0.8115264177322388, -0.6268839240074158, -0.46603327989578247, 0.8129594922065735, 0.0006769743631593883, 0.2899341285228729, 0.2666856050491333, -0.5834699273109436, -0.018695935606956482, 0.7729524374008179, 0.834531843662262, 0.6218773722648621, -0.38363784551620483, -0.27605029940605164, 1.5618239641189575, -1.2069605588912964, 0.23317427933216095, 1.3785642385482788, 0.46719005703926086, 0.23580017685890198, -0.10840730369091034, -0.3103671073913574, 1.0925660133361816, -0.024239853024482727, -0.4560019373893738, -0.09707461297512054, 0.08433780074119568, -0.15648284554481506, 1.4828466176986694, -0.29161369800567627, -0.07709526270627975, 0.4687642753124237, -0.025895297527313232, 1.8441401720046997, 0.15281878411769867, -0.4103778898715973, 0.2451138198375702, 0.09250275790691376, 0.17126035690307617, 0.7884182929992676, -0.4476601481437683, 0.21649353206157684, -1.0225510597229004, -0.27768614888191223, -0.10543617606163025, -0.3691067695617676, 0.13654635846614838, -0.013421187177300453, 0.05311158299446106, 0.7178468108177185, -0.0739794671535492, 0.39555227756500244, -0.4659390151500702, 0.7006091475486755, 0.7572889924049377, 0.6631816029548645, 0.4936893880367279, 0.17114871740341187, -0.19664685428142548, 0.06524205207824707, -0.7037734985351562, 0.256727397441864, 0.288054883480072, 0.7241886258125305, -0.4306604862213135, 0.7829136252403259, -0.6805163025856018, 0.2699025869369507, 1.356633186340332, 0.0866670086979866, 0.5323538780212402, -0.36355769634246826, 0.6002431511878967, -0.7467028498649597, -0.06631068885326385, -0.3885071575641632, -0.033390775322914124, -0.33716973662376404, -0.8186996579170227, -0.578291654586792, -0.12956564128398895, -0.23482239246368408, -0.922150194644928, 0.7494052648544312, -0.05396110936999321, 0.08781372755765915, -0.1253276914358139, 0.9631577730178833, 0.47085267305374146, 0.6848853230476379, 0.10050170868635178, 0.16640141606330872, 0.6029155254364014, -0.6630624532699585, -0.6019281148910522, -1.080479383468628, 0.44663646817207336, -0.28964126110076904, 0.3031664788722992, 0.19749784469604492, -1.4652544260025024, -0.537563145160675, -1.0715129375457764, 0.45272132754325867, -0.32051289081573486, 0.18911784887313843, 1.030680775642395, 0.17977745831012726, -0.8940144181251526, 1.1323808431625366, -0.5397546291351318, 0.20704825222492218, 0.5530016422271729, 0.3978409171104431, 0.26448652148246765, -0.09559844434261322, -1.297284483909607, 0.45638078451156616, -0.09134688973426819, -0.6652966141700745, -0.2783677577972412, -0.678390383720398, -1.1029387712478638, -0.4902013838291168, -0.10531231760978699, -0.2955319583415985, 1.4331248998641968, -0.7036482095718384, -1.8403116464614868, 0.5125765800476074, -0.07578978687524796, -0.19065271317958832, 0.929716169834137, -0.04429349675774574, -0.18410412967205048, -0.38701683282852173, -0.6092743873596191, -0.2575733959674835, 0.8297079801559448, 0.07272496819496155, -0.23008465766906738, 0.07318980991840363, -0.2891949415206909, -0.22329701483249664, -0.0611003041267395, 0.8831949234008789, 0.3229009807109833, -0.3797430694103241, 0.21986913681030273, 0.587406575679779, 0.12655603885650635, -0.20975743234157562, 0.048703633248806, -1.1918036937713623, 0.5085157752037048, -0.10233749449253082, 0.8224462866783142, -0.7169632315635681, -0.6460295915603638, -0.010487055405974388, -0.45005446672439575, 0.13424603641033173, -0.4718132019042969, 0.5811225771903992, -0.0847705528140068, -0.09189878404140472, -0.5104362964630127, -1.4497591257095337, 0.08701568841934204, 0.11809743940830231, -0.8955569863319397, 0.5752207636833191, 0.38259127736091614, 0.5017749071121216, -0.902490496635437, 0.026295989751815796, -0.21010038256645203, 0.21134112775325775, -1.0381113290786743, 1.5375823974609375, -0.4057837128639221, 0.1296667605638504, 0.09452211111783981, -0.1810358613729477, 0.26458489894866943, -0.18521559238433838, 0.3113618791103363, 0.009424736723303795, 0.07313340157270432, 0.8664106726646423, -0.888241708278656, 0.9980624914169312, -0.30486080050468445, 0.31424346566200256, 0.517601490020752, -1.0351476669311523, -0.11233749985694885, 0.40628233551979065, -0.1936434954404831, -0.34584182500839233, 0.6622120141983032, 0.3788122832775116, -0.6521185636520386, 0.5763300657272339, 0.37241747975349426, 0.5097966194152832, 0.08751048147678375, 0.5229790806770325, 0.8277153968811035, -0.49721917510032654, 0.37566494941711426, 0.4978254437446594, 0.43157926201820374, 0.39715227484703064, 0.03038075938820839, 0.07638673484325409, 0.32576945424079895, -0.8438588380813599, -0.056609317660331726, 0.6054420471191406, 0.79365074634552, 1.215222716331482, 0.25807520747184753, -0.9966453313827515, -0.12066152691841125, -0.24815161526203156, 0.5979568958282471, 1.882045030593872, -0.36697909235954285, -0.08107373118400574, -0.7420120239257812, -0.4429047107696533, -0.09902828931808472, 0.2206442952156067, -0.39114630222320557, -0.06736703962087631, -0.8562498688697815, -1.793678641319275, 0.5333048105239868, -0.0026819503400474787, 0.5841226577758789, -0.3943333625793457, -0.04523136094212532, -0.0855332762002945, 0.7230676412582397, -0.6076337695121765, -0.6807470917701721, 0.21094626188278198, -0.6330868005752563, 0.1220739334821701, 0.06259440630674362, 0.030881701037287712, 0.531072735786438, -0.9200642108917236, 0.9391946792602539, -0.41778552532196045, -0.12335730344057083, 0.14851237833499908, 0.3682476878166199, -1.0373504161834717, -1.0331916809082031, 0.10795225948095322, 0.33424776792526245, 0.30502060055732727, -0.39226362109184265, 0.056023020297288895, 0.05574561282992363, 0.02150261402130127, -0.34150707721710205, 0.03569438308477402, 0.2623814344406128, 0.1288786232471466, 0.3677157461643219, -0.7010614275932312, 0.04652250558137894, -0.7962217330932617, 1.0233566761016846, -0.13313938677310944, -0.5909340381622314, -0.16015106439590454, -0.8984346389770508, -0.013752447441220284, 0.7814226150512695, -0.8159729242324829, -0.4821084439754486, -0.8095694780349731, -0.1813509464263916, -0.07119481265544891, 0.058889731764793396, -0.2887876331806183, 0.49824756383895874, 0.2281120866537094, 0.2573947012424469, 0.5310568809509277, 0.851885199546814, -0.6080597043037415, 0.5879834294319153, -0.7793411612510681, 0.34536173939704895, 0.16248707473278046, -0.07081074267625809, 0.35546666383743286, -0.3503645658493042, -0.6583902835845947, -0.277413934469223, 0.08784832060337067, 0.2132192850112915, -0.1916813850402832, -0.2465316206216812, -0.613454282283783, -0.5109265446662903, 0.36074450612068176, -0.5001180768013, -0.41743454337120056, 0.02546856552362442, 0.07214134931564331, -0.5878795981407166, -1.1089096069335938, -1.5797189474105835, -0.43177926540374756, -1.1219762563705444, -0.9685013890266418, 0.3659084737300873, -0.12006022781133652, -0.38261500000953674, -0.3301091492176056, -0.12155825644731522, -0.5560858249664307, 1.1372941732406616, -0.9160804152488708, 0.390314519405365, -0.6721660494804382, -0.16336698830127716, -0.6222444772720337, 0.8301135301589966, 1.0992166996002197, -0.46378833055496216, 0.20750023424625397, -0.6209332942962646, -0.2794855833053589, -0.22199846804141998, -0.29225945472717285, 0.005010256078094244, 0.01900346949696541, 0.4206639230251312, -0.4996735453605652, 0.04848853871226311, 0.5737242102622986, 0.8534947037696838, -0.912032961845398, -0.31278350949287415, -0.08075414597988129, 0.6290620565414429, 0.10898524522781372, -0.19011351466178894, 0.93034428358078, 0.15321317315101624, 0.15549634397029877, 0.24294517934322357, 0.014970367774367332, -0.33864977955818176, -0.5966836810112, 0.9486125707626343, 1.7499488592147827, 0.23684781789779663, 0.07883729040622711, -0.7525737881660461, 0.7932737469673157, -1.2853569984436035, -1.0135082006454468, 0.7379673719406128, 0.7185933589935303, 0.6660328507423401, -0.21455532312393188, -0.21625855565071106, -0.26004281640052795, -0.03213496133685112, 0.5198993682861328, -0.24672366678714752, -0.76328444480896, -0.19806213676929474, 0.5658799409866333, 0.3077986538410187, 0.7347559928894043, -0.3005009591579437, 0.34405186772346497, 14.9327974319458, 0.6280903220176697, -0.18356463313102722, 0.6193813681602478, 0.7398016452789307, -0.2147749960422516, -0.017786342650651932, -0.5022610425949097, -1.1309336423873901, 0.4962356686592102, 0.8990550637245178, 0.18743349611759186, 0.6047902703285217, 0.40484362840652466, 0.18021266162395477, 0.25519126653671265, -0.418290376663208, 0.32213595509529114, 0.7039687037467957, -1.1204603910446167, 0.14834795892238617, -0.11341318488121033, 0.7222351431846619, 1.0686346292495728, 0.5663784146308899, 0.5628464818000793, 1.0325428247451782, -0.16485381126403809, 0.8337394595146179, 0.0019077315228059888, 0.2541724741458893, 0.11158479750156403, 0.6807710528373718, 0.4283062815666199, -0.35321033000946045, 0.14333198964595795, -0.11702760308980942, -1.7019546031951904, 0.3319494128227234, 0.40641096234321594, -0.6747483611106873, -0.7352639436721802, -0.0867912620306015, 0.4490811228752136, 0.3699759542942047, 0.1881750077009201, -0.3113309442996979, 1.3433983325958252, -0.41901466250419617, -0.1864069253206253, 0.437550812959671, -0.1073426604270935, 0.4383033812046051, 0.36021798849105835, -0.17024974524974823, -0.17318466305732727, 0.10261188447475433, 0.30090802907943726, -0.5644371509552002, 0.06706493347883224, -0.019159721210598946, -0.039308711886405945, -0.5228959321975708, 0.573002278804779, 0.7841264605522156, -0.2970501780509949, -0.6567451357841492, 0.4636220932006836, 0.46065911650657654, 0.05685914307832718, -0.06408241391181946, -0.10387981683015823, 1.100569486618042, -0.5694983601570129, 0.30248138308525085, 0.4876691699028015, -0.30295121669769287, -0.49246811866760254, -0.2606299817562103, -0.6297375559806824, 0.6078610420227051, -0.1767430454492569, -0.902556836605072, 0.5183099508285522, -0.2642688453197479, -0.23309922218322754, 0.21055500209331512, -0.6295868754386902, -0.5611364841461182, 0.399482786655426, -0.9814369678497314, -0.28713279962539673, 0.6381267309188843, -0.31860366463661194, -0.26855966448783875, 0.060712769627571106, 0.8295590877532959, 0.18868833780288696, -0.4117402136325836, 0.22988516092300415, 0.5244813561439514, 0.26952672004699707, -0.19590391218662262, -0.865935206413269, 1.1161164045333862, 0.3998071849346161, -0.029727648943662643, 0.1221071183681488, 0.40847253799438477, 0.39824941754341125, -0.8990068435668945, 0.14941489696502686, 0.5695598721504211, -0.9064455628395081, -0.1280117779970169, -0.6750273704528809, -0.7733315825462341, 0.1391737014055252, 0.47991225123405457, 0.14114907383918762, 0.1349649280309677, -0.26425793766975403, -0.5194368362426758, -0.46984270215034485, -0.4015995264053345, -0.20776882767677307, 0.693608283996582, -0.5289747714996338, -0.8196819424629211, 0.2723333239555359, 0.11989227682352066, -0.9241840243339539, -0.4515465795993805, -0.2713333070278168, 0.019455913454294205, -0.05537378042936325, 0.9272134900093079, -1.1884112358093262, 0.39953744411468506, 0.6438249349594116, 0.02570507302880287, -1.0985277891159058, 0.343168169260025, -1.1246132850646973, 0.05688166245818138, -0.04941193759441376, 0.7552350759506226, -0.7075908184051514, 0.1264108419418335, 0.8837305307388306, 0.14140069484710693, -0.7131926417350769, -0.7512874603271484, -0.48105961084365845, 0.25728005170822144, -0.5969477891921997, 0.34752821922302246, -0.31759634613990784, 0.12602007389068604, -0.2464933693408966, 0.39376741647720337, 0.4907963275909424, -0.0978441834449768, -0.6247541308403015, 0.26788967847824097, 0.1685277819633484, -0.06345373392105103, -0.7144824862480164, -0.548772931098938, -1.300199270248413, -0.015229607932269573, -1.1013238430023193, 0.07746206223964691, -0.9251587986946106, -0.9716876745223999, 0.30669742822647095, -0.36182525753974915, -0.010810555890202522, 0.13818573951721191, -0.5055969953536987, -0.471689909696579, -0.48509612679481506, -0.5940753817558289, 1.0528559684753418, 0.6146396398544312, -0.7981245517730713, 0.20230090618133545, 0.4016325771808624, 0.3580654561519623, 0.5445130467414856, 0.7761498689651489, -0.4035153090953827, -0.519364058971405, -1.2688226699829102, 0.3508833646774292, -0.5750821828842163, -0.3818387985229492, -0.6857075691223145, 0.5513625741004944, 0.2997717559337616, -0.21758109331130981, 0.4024581015110016, 0.25881925225257874, -0.5716679096221924, -0.6498458385467529, 0.31985077261924744, -0.5164545774459839, 0.12165243923664093, -0.3989620804786682, -0.624346911907196, -0.38027164340019226, 0.8469038605690002, 0.23602844774723053, -1.0242472887039185, -0.16974110901355743, 0.6603796482086182, -0.9839926362037659, 0.7850097417831421, -0.37436485290527344, 0.011772619560360909, -0.8460967540740967, -0.38368460536003113, 0.07707932591438293, 0.29309290647506714, -0.3044373691082001, 0.9801352024078369, 0.16375039517879486, -0.9136735200881958, -0.17022500932216644, 0.5833810567855835, -0.26294997334480286, 0.11323517560958862, -0.017976420000195503, 0.557819664478302, -0.5202147960662842, -0.10736434906721115, 0.509380578994751, 0.3894464075565338, -1.0443875789642334, -0.6321607232093811, 0.7669336199760437, -0.15959542989730835, -0.32030659914016724, 1.4686777591705322, -0.5836249589920044, -0.9251501560211182, 0.42545562982559204, -1.1714520454406738, 0.10625185817480087, -0.24759657680988312, 0.762161135673523, 0.5488618016242981, 0.10481571406126022, -0.08912701159715652, -0.4100724458694458, -0.09803136438131332, -0.04052890092134476, -0.546354353427887, 0.7373858690261841, -0.16970126330852509, -0.3298954367637634, 0.7096929550170898, 0.8459351658821106, -0.5015324950218201, -0.993949830532074, -0.671076238155365, -0.701626181602478, -0.07155092805624008, 0.11862709373235703, -0.23972973227500916, -0.8068441152572632, 0.6508201360702515, 0.3457019627094269, 0.05670712888240814, -0.2715829014778137, 0.16393201053142548, -0.0280225221067667, 0.4960998594760895, 0.28095874190330505, -1.1793999671936035, -0.9267275929450989, 1.2338906526565552, 1.183655023574829, -1.109230637550354, 0.623098611831665, 0.25973933935165405, -0.825995922088623, 0.5044339895248413, 0.22676119208335876, -0.38907355070114136, 0.840767502784729, -0.2964647114276886, 0.25422391295433044, 0.24189262092113495, -0.9555294513702393, -0.41379088163375854, 0.648266613483429, 0.44615283608436584, 0.816752552986145, 0.4624723196029663, -0.28714537620544434, 0.9528152942657471, -0.3271453380584717, -0.2425425499677658, 0.41900894045829773, 0.5989248752593994, -0.06728684157133102, 0.17629463970661163, 0.03504209965467453, 1.0025579929351807, -1.1145508289337158, -0.4109984040260315, -0.2029939591884613, 0.35154756903648376, 0.21664203703403473, 0.4906492233276367, 0.644789457321167, 0.05231410637497902, 0.5840874314308167, 0.23667582869529724, 0.3110261559486389, -0.08250724524259567, -0.6427212953567505, -0.9662320613861084, -0.28938066959381104, -0.30755046010017395, 0.09638690948486328, -0.6843999028205872, -0.35954803228378296, -0.29300621151924133, 0.42552557587623596, -0.07083756476640701, 0.3909555971622467, 1.1069118976593018, 0.5974050164222717, 0.09113909304141998, -0.2571119964122772, -0.6049554944038391, -1.0019291639328003, -1.0379306077957153, 0.015382703393697739, 0.17624478042125702, 0.04501738399267197, 0.07243523746728897, -0.7006593346595764, -0.27202409505844116]}, "authors": [{"authorId": "51894707", "name": "Frederik Kunstner"}, {"authorId": "2155430932", "name": "Jacques Chen"}, {"authorId": "104018453", "name": "J. Lavington"}, {"authorId": "145610994", "name": "Mark W. Schmidt"}], "references": [{"paperId": "a7f59b2162ae0ea2520753b1b9b17277490a9458", "title": "Symbolic Discovery of Optimization Algorithms"}, {"paperId": "5b064570a83231471072b9c03bc068077cefb868", "title": "Robustness to Unbounded Smoothness of Generalized SignSGD"}, {"paperId": "aa6c2814ff94ca098d90f188f95126b5b06ebb69", "title": "Nonlinear Programming"}, {"paperId": "60f9fa6d4f966c316353ee2753021c4587fa0273", "title": "Stochastic Training is Not Necessary for Generalization"}, {"paperId": "026bb8a1066f50ddc8797e1341353603149a8cb8", "title": "Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability"}, {"paperId": "7e3d583d3131161be6e5eac67626d3e53e002cf0", "title": "A Large Batch Optimizer Reality Check: Traditional, Generic Optimizers Suffice Across Batch Sizes"}, {"paperId": "901b546ae60d1e3b6cfe80f19f0786321e701bf4", "title": "Why are Adaptive Methods Good for Attention Models?"}, {"paperId": "88d2c25e50f38d6f466c80c91c0c1ec2456c52df", "title": "Improved Analysis of Clipping Algorithms for Non-convex Optimization"}, {"paperId": "7b5ed479f5caf7b853636060c0a35e516e1f70bb", "title": "On the Generalization Benefit of Noise in Stochastic Gradient Descent"}, {"paperId": "4cd92a56dca741190e453b4229eb9851abf6944c", "title": "Stochastic Optimization with Heavy-Tailed Noise via Accelerated Gradient Clipping"}, {"paperId": "8d908042f139575d6688c745e94156c9df6eae07", "title": "Understanding the Difficulty of Training Transformers"}, {"paperId": "59600463ca4f6b5d02900022b29b6de278154c6b", "title": "A new regret analysis for Adam-type algorithms"}, {"paperId": "05b4436d504d5615801639a120a2c8eca7cbaabd", "title": "A Simple Convergence Proof of Adam and Adagrad"}, {"paperId": "1113a9d2c653fd0008e2c6b25ac1c0c8f794f3c5", "title": "The Geometry of Sign Gradient Descent"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "c2867275ec80f4d5325cf3451291e72628fb69b6", "title": "Which Algorithmic Choices Matter at Which Batch Sizes? Insights From a Noisy Quadratic Model"}, {"paperId": "a14ecc04274f4ef67ed5943aa53fde1bae7b95d0", "title": "Stochastic Sign Descent Methods: New Algorithms and Better Theory"}, {"paperId": "e658741baefd2c4da4742bb43155f69d4cbd79fa", "title": "Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity"}, {"paperId": "bc789aef715498e79a74f857fa090ece9e383bf1", "title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes"}, {"paperId": "e5b2843d3fbb3260a3f84872230ed1437552b131", "title": "Memory-Efficient Adaptive Optimization for Large-Scale Learning"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "15d70874bed0c2cd2ddb2f225fd62f09e9c47617", "title": "Lectures on Convex Optimization"}, {"paperId": "b2c8e834ac5f7be68b9ca3691d39925036dd74a3", "title": "Measuring the Effects of Data Parallelism on Neural Network Training"}, {"paperId": "59ef5569832b2fbb865466b3951ad0957537cd54", "title": "Convergence of Gradient Descent on Separable Data"}, {"paperId": "c983653841b6987d9959318f074a595783838576", "title": "On the Convergence of Adam and Beyond"}, {"paperId": "97884ff15e0a4e83f534b7b13979e519d1c50a54", "title": "signSGD: compressed optimisation for non-convex problems"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "e4da4fb310df2bfa5b9aab217982723634bda4bc", "title": "Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "195043e4c13a635555c28dfab7ac534d10d78c12", "title": "Introduction to Online Convex Optimization"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "3077f050ad950cf4c89c4208816268c2eb20cddb", "title": "From Averaging to Acceleration, There is Only a Step-size"}, {"paperId": "cb4dc7277d1c8c3bc76dd7425eb1cc7cbaf99487", "title": "Optimizing Neural Networks with Kronecker-factored Approximate Curvature"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "84069287da0a6b488b8c933f3cb5be759cb6237e", "title": "On the difficulty of training recurrent neural networks"}, {"paperId": "0b44fcbeea9415d400c5f5789d6b892b6f98daff", "title": "Building a Large Annotated Corpus of English: The Penn Treebank"}, {"paperId": "79ef7842df5174aeac3ddb7f0e0349251a1dba2f", "title": "Understanding Gradient Clipping In Incremental Gradient Methods"}, {"paperId": "88cb4a650a0783c651dca3bdebf1e662ba9742e4", "title": "E FFICIENT E STIMATORS FOR H EAVY -T AILED M ACHINE L EARNING"}, {"paperId": null, "title": "Neural Networks (maybe) Evolved to Make Adam the Best Optimizer"}, {"paperId": null, "title": "RMSPROP: Divide the gradient by a running average of its recent magnitude"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}, {"paperId": null, "title": "A method of solving a convex programming problem with convergence rate O(k 2 )"}, {"paperId": null, "title": "b Normalized GD scales better but plateaus. While normalizaton improves performances and helps scale with batch size, the scaling plateaus earlier than for sign descent"}]}