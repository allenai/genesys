{"paperId": "43112afbeba63e6eb6b70cb9de36506af75804ba", "title": "Grape: Practical and Efficient Graph-based Executions for Dynamic Deep Neural Networks on GPUs", "abstract": "Achieving high performance in machine learning workloads is a crucial yet difficult task. To achieve high runtime performance on hardware platforms such as GPUs, graph-based executions such as CUDA graphs are often used to eliminate CPU runtime overheads by submitting jobs in the granularity of multiple kernels. However, many machine learning workloads, especially dynamic deep neural networks (DNNs) with varying-sized inputs or data-dependent control flows, face challenges when directly using CUDA graphs to achieve optimal performance. We observe that the use of graph-based executions poses three key challenges in terms of efficiency and even practicability: (1) Extra data movements when copying input values to graphs\u2019 placeholders. (2) High GPU memory consumption due to the numerous CUDA graphs created to efficiently support dynamic-shape workloads. (3) Inability to handle data-dependent control flows.To address those challenges, we propose Grape, a new graph compiler that enables practical and efficient graph-based executions for dynamic DNNs on GPUs. Grape comprises three key components: (1) an alias predictor that automatically removes extra data movements by leveraging code positions at the Python frontend, (2) a metadata compressor that efficiently utilizes the data redundancy in CUDA graphs\u2019 memory regions by compressing them, and (3) a predication rewriter that safely replaces control flows with predication contexts while preserving programs\u2019 semantics. The three components improve the efficiency and broaden the optimization scope of graph-based executions while allowing machine learning practitioners to program dynamic DNNs at the Python level with minimal source code changes.We evaluate Grape on state-of-the-art text generation (GPT-2, GPT-J) and speech recognition (Wav2Vec2) workloads, which include both training and inference, using real systems with modern GPUs. Our evaluation shows that Grape achieves up to 36.43\u00d7 less GPU memory consumption and up to 1.26\u00d7 better performance than prior works on graph-based executions that directly use CUDA graphs. Furthermore, Grape can optimize workloads that are impractical for prior works due to the three key challenges, achieving 1.78\u00d7 and 1.82\u00d7 better performance on GPT-J and Wav2Vec2 respectively than the original implementations that do not use graph-based executions.CCS CONCEPTS\u2022 Computing methodologies \u2192 Parallel computing methodologies; Machine learning; Artificial intelligence.", "venue": "Micro", "year": 2023, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3613424.3614248", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "Grape, a new graph compiler that enables practical and efficient graph-based executions for dynamic DNNs on GPUs and allows machine learning practitioners to program dynamic DNNs at the Python level with minimal source code changes is proposed."}, "embedding": {"model": "specter_v2", "vector": [0.0823812335729599, 0.2816294729709625, -0.22659362852573395, 0.16065311431884766, 0.27942121028900146, -0.13493263721466064, 0.630226731300354, -0.06588835269212723, -0.48750197887420654, -0.46146464347839355, 0.4140263795852661, -0.3426419794559479, 0.772982656955719, -0.4123572111129761, -0.1438073217868805, -0.0038058508653193712, -0.6375468373298645, -0.053770240396261215, 0.26310041546821594, -0.10712238401174545, 0.0705799087882042, -0.15404155850410461, -1.9513071775436401, 0.2319541722536087, 0.1451498121023178, 0.390254944562912, -0.1021687388420105, 1.4774624109268188, -0.5870665907859802, 0.34995904564857483, 0.15351133048534393, -0.015249640680849552, 0.0627029612660408, -0.003335891291499138, -0.24207976460456848, -0.0533873550593853, 0.5055197477340698, -0.5532142519950867, -0.6385156512260437, 0.8457517027854919, 0.1972135603427887, 0.5577865839004517, -0.12683168053627014, -0.7677635550498962, -0.13131608068943024, 0.27545061707496643, 0.3591971695423126, 0.6381694674491882, -0.4003462493419647, -0.28098389506340027, 1.0894392728805542, -0.7707331776618958, 0.505807101726532, 1.0032392740249634, 0.3755580484867096, 0.374104380607605, -0.22213944792747498, -0.13170818984508514, 0.5740242600440979, -0.208737313747406, -0.2610301375389099, -0.31687936186790466, -0.10612921416759491, -0.35938069224357605, 2.302006721496582, -0.08448611199855804, 0.22625726461410522, 0.3820677101612091, -0.022977503016591072, 1.0424861907958984, -0.5258497595787048, -0.8100799322128296, 0.08430423587560654, -0.6019570231437683, 0.7707394957542419, 0.9758457541465759, -0.026892710477113724, 0.36496809124946594, -0.8114215731620789, -0.2603098750114441, 0.2821231484413147, 0.18172532320022583, 0.343313992023468, -0.17413567006587982, 0.14126551151275635, 0.7658881545066833, 0.21442502737045288, 0.32847723364830017, -0.333607941865921, 0.9791154265403748, 0.9634705185890198, 0.04526533558964729, 0.0252289529889822, 0.028058672323822975, 0.20475441217422485, 0.09113107621669769, -0.836104691028595, 0.4773222804069519, 0.11703929305076599, 0.9308522939682007, -0.2789260745048523, 0.43944984674453735, -0.7894989252090454, 0.14576812088489532, 0.8177518844604492, -0.07806217670440674, 0.5003361701965332, -0.16812923550605774, 0.3637073040008545, -0.7631549835205078, -0.15691548585891724, -0.6230230331420898, -0.09236903488636017, -0.10613100975751877, -0.8523699641227722, -0.5958652496337891, -0.4543142318725586, -0.3372049629688263, -0.9183743000030518, 0.410468727350235, -0.19099941849708557, 0.33949705958366394, 0.22609910368919373, 0.787117063999176, 0.9565137624740601, 0.7328749299049377, 0.22180265188217163, 0.5929079651832581, 0.6955543160438538, -1.1132168769836426, -0.16847656667232513, -1.063300371170044, 0.7072615623474121, -0.06515659391880035, 0.28270548582077026, -0.49250295758247375, -1.399077296257019, -0.9141303300857544, -0.9390362501144409, 0.021476764231920242, -0.5360168814659119, 0.08350221812725067, 1.192029595375061, 0.39972126483917236, -1.226305365562439, 1.1858816146850586, -0.5520744323730469, -0.4395499527454376, 0.2620669901371002, 0.32224228978157043, 0.6865472793579102, -0.24518918991088867, -1.0075446367263794, -0.512718677520752, 0.20439951121807098, -0.8050978183746338, 0.23441942036151886, -0.4804801642894745, -0.9144513010978699, 0.19671978056430817, 0.0225270614027977, -0.6052738428115845, 1.2113614082336426, 0.15629956126213074, -1.116683840751648, 0.7233064770698547, 0.13461153209209442, -0.03135444223880768, 0.30264759063720703, 0.20870520174503326, -0.3698262870311737, -0.43368643522262573, -0.45186617970466614, 0.5095193386077881, 0.33875033259391785, 0.14207646250724792, -0.08561120927333832, 0.12299445271492004, -0.4198581576347351, -0.05163738504052162, -0.3795885741710663, 1.0321189165115356, -0.8126909136772156, -0.09862512350082397, -0.008679523132741451, 0.47062942385673523, -0.08263588696718216, -0.24795925617218018, -0.7653598189353943, -0.7337376475334167, 0.9421423077583313, 0.1880006641149521, 1.1508351564407349, -0.886971652507782, -0.9816867113113403, -0.1788845807313919, 0.19900749623775482, 0.20277710258960724, -0.3727734088897705, 0.4329739511013031, -0.2915336787700653, 0.4238682687282562, 0.12443166971206665, -0.8442877531051636, 0.30012619495391846, -0.08116338402032852, -0.6075171232223511, -0.43517443537712097, -0.027636779472231865, 0.9314744472503662, -0.6841580867767334, 0.24808357656002045, -0.3526769280433655, 0.0055747125297784805, -1.1490812301635742, 1.1604633331298828, -0.6564158201217651, -0.26012006402015686, -0.08525865525007248, -0.5399552583694458, 0.45464566349983215, -0.429564505815506, 0.899015486240387, -0.22888344526290894, -0.3857409358024597, 0.586898922920227, -0.39611130952835083, 0.9056025147438049, 0.00835038535296917, 0.24645520746707916, -0.05212921276688576, -0.6356684565544128, 0.4636608958244324, 0.09053221344947815, -0.33510175347328186, -0.5984393358230591, 0.1658863127231598, 0.16887591779232025, -0.461207777261734, 0.2473287135362625, 1.2811239957809448, 1.1686371564865112, -0.44756609201431274, 0.5416676998138428, 0.3620571792125702, -0.36700382828712463, 0.9091758131980896, 0.33556312322616577, 1.0351793766021729, 0.3706740140914917, 0.1656653881072998, -0.09067372232675552, 0.19723837077617645, -0.48439323902130127, -0.22046314179897308, 0.6027150750160217, 0.5330880880355835, 0.9119813442230225, 0.9094366431236267, -0.9590057134628296, -0.6582015752792358, 0.2864389717578888, 0.8450735211372375, 1.701241374015808, -0.3442593812942505, 0.1530468463897705, -1.0275765657424927, -0.7909372448921204, 0.0010607695439830422, -0.013860957697033882, -0.13823553919792175, -0.009416577406227589, -0.5783794522285461, -1.3260208368301392, 0.9098672866821289, 0.2910845875740051, 0.8757743239402771, -0.8821221590042114, -0.5311689972877502, -0.5778691172599792, 0.9225756525993347, -0.8489872217178345, -0.7340943217277527, 0.3315444886684418, -0.6653435230255127, -0.04177413508296013, 0.25317850708961487, -0.20490513741970062, 0.34991317987442017, -0.44327428936958313, 1.226963758468628, -0.07172726094722748, -0.3883713483810425, -0.06359512358903885, 0.5792542099952698, -0.40013161301612854, -0.8459913730621338, 0.31423699855804443, -0.29733771085739136, -0.5783560276031494, 0.30636072158813477, 0.20570261776447296, 0.2418229877948761, -0.24036595225334167, -0.4619065523147583, 0.3348304033279419, -0.18308578431606293, 0.1450459212064743, 0.76524418592453, -0.2964276373386383, -0.13511648774147034, -1.3335645198822021, 1.1624336242675781, 0.09220574796199799, -0.7445500493049622, 0.02950953133404255, -0.6599329710006714, 0.08846066892147064, 0.9760705828666687, -0.6467516422271729, -0.2804679870605469, -1.07371187210083, 0.06008892506361008, -0.43908601999282837, -0.5572811365127563, -1.47554947034223e-05, 0.35414132475852966, 0.10875450819730759, 0.4696989059448242, 0.3033844828605652, 0.568429708480835, 0.119780533015728, 0.5000929832458496, -1.0007354021072388, 0.3902473449707031, -0.173514723777771, -0.2219254970550537, -0.28876984119415283, -0.01865156553685665, -0.627548098564148, -0.13227593898773193, 0.02758418396115303, -0.14619795978069305, -0.3739849627017975, 0.1514701247215271, -0.05762476846575737, -0.8463860750198364, 0.055047061294317245, -1.1324244737625122, -0.6089651584625244, 0.3045738935470581, -0.5285260677337646, -0.031576305627822876, -1.110530138015747, -1.240845799446106, -0.03781120851635933, -1.0059497356414795, -1.3303461074829102, 0.2879829704761505, 0.2978803217411041, -0.2589159607887268, -0.8819566965103149, -0.044868212193250656, -1.0182515382766724, 0.7031156420707703, 0.1081080287694931, 0.9358871579170227, -0.08541327714920044, 0.0594189278781414, -0.06733497977256775, -0.20864900946617126, 0.08950001001358032, -0.7458293437957764, 0.7684909701347351, -0.6503046751022339, 0.41158100962638855, -0.8376626372337341, -0.2492380440235138, 0.01947658136487007, 0.34837794303894043, 1.007333517074585, -0.010651777498424053, -0.45778998732566833, 0.664088785648346, 1.541001558303833, -0.6069889068603516, 0.02130020596086979, -0.131846621632576, 1.27910315990448, -0.033494628965854645, -0.5403737425804138, 0.7937126755714417, -0.0801004022359848, 0.37149831652641296, 0.3035312294960022, -0.20195314288139343, -0.5940118432044983, -0.3824264407157898, 0.18129783868789673, 1.6454097032546997, 0.4891239404678345, -0.474740594625473, -0.9852715730667114, 0.49775245785713196, -1.29848051071167, -0.5420820116996765, -0.013500120490789413, 0.5112798810005188, 0.07657036185264587, -0.24945493042469025, -0.19772584736347198, -0.25602206587791443, 0.8615171313285828, 0.8464593291282654, -0.6837864518165588, -1.422513484954834, 0.22502920031547546, 0.704228937625885, 0.5097728967666626, 0.29578641057014465, -0.1870562583208084, 0.3607065975666046, 14.689864158630371, 0.8043844103813171, -0.28315049409866333, 0.20985518395900726, 0.6602121591567993, 0.15487605333328247, -0.3248729705810547, -0.5190373659133911, -1.3020961284637451, -0.11860671639442444, 1.3373233079910278, -0.15471681952476501, 0.3670891523361206, 0.5525397658348083, -0.022993193939328194, 0.29694318771362305, -0.3043750524520874, 0.5705352425575256, 0.3892099857330322, -1.552338719367981, 0.2164444923400879, 0.22082459926605225, 0.5430780649185181, 0.7780471444129944, 0.7134724855422974, 0.6144579648971558, 1.030374526977539, -0.06338320672512054, 0.32124221324920654, 0.02580120973289013, 1.1990340948104858, -0.23197396099567413, 0.41017335653305054, 0.23889312148094177, -0.6117060780525208, 0.20158860087394714, -0.7382495999336243, -1.309909462928772, -0.008114558644592762, 0.2993565499782562, -0.9287488460540771, -0.2640957236289978, -0.3799970746040344, 0.9406324625015259, 0.31188568472862244, 0.16804912686347961, -0.13103479146957397, 0.2907218933105469, 0.23155702650547028, -0.5016600489616394, 0.2898803949356079, 0.37303510308265686, 0.08808409422636032, 0.27408042550086975, 0.43229326605796814, -0.146637961268425, 0.04347098246216774, 0.6079221963882446, -0.8237138390541077, -0.24858799576759338, -0.40107041597366333, -0.3277818262577057, -0.1732284128665924, 0.5706419944763184, 0.10408758372068405, 0.2167757898569107, -0.5490792393684387, 0.5090221762657166, 0.8865875601768494, 0.02609534189105034, -0.3910917639732361, -0.13301301002502441, 0.831394612789154, -0.42017582058906555, 0.2542152404785156, 0.3263125419616699, -0.605690598487854, -0.37845224142074585, -0.9176154136657715, -0.26697593927383423, 0.5595570206642151, -0.6264691352844238, -0.530642569065094, 0.9572727084159851, -0.5202973484992981, -0.22007527947425842, 0.03816457837820053, -1.006555438041687, -0.5159044861793518, 0.5264813899993896, -0.9805389046669006, 0.022713614627718925, 0.22259971499443054, -0.4555487632751465, -0.6037605404853821, -0.011530774645507336, 1.417580485343933, 0.10132663697004318, -0.7903953790664673, 0.06249159201979637, 0.04238872602581978, -0.0552474670112133, -0.47844186425209045, -0.7894551157951355, 1.7702895402908325, 0.6014341115951538, -0.3901149332523346, -0.35380086302757263, -0.08020394295454025, 0.04342179372906685, -0.8809068202972412, -0.5727102756500244, 0.4485631287097931, -0.17559972405433655, -0.19076864421367645, -0.9236802458763123, -0.6818980574607849, 0.2734310030937195, 0.405136376619339, 0.14997020363807678, 0.041506242007017136, 0.21085867285728455, -0.2682410478591919, 0.159458190202713, -0.6242271661758423, 0.37125909328460693, 0.6271175146102905, -0.342171311378479, 0.21277257800102234, 0.010418596677482128, 0.6572615504264832, -1.627415418624878, -0.44263121485710144, -0.6068496108055115, -0.06299737095832825, -0.6821188926696777, 0.8259158134460449, -0.32533785700798035, 1.0734730958938599, 1.0660921335220337, 0.3587736189365387, -0.7603129744529724, 0.19328182935714722, -0.8730192184448242, 0.0806875079870224, -0.06870654225349426, 0.24609802663326263, -0.35263967514038086, 0.8963246941566467, 0.8714439272880554, -0.13026617467403412, -0.3508288562297821, 0.15978191792964935, -0.1178971454501152, -0.14933396875858307, -0.6723891496658325, 0.7345865368843079, 0.13441376388072968, -0.19609874486923218, -0.07744498550891876, 0.6602311134338379, 0.5802126526832581, -0.25391554832458496, -0.301819384098053, 0.48618364334106445, 0.1383253037929535, -0.302481472492218, -0.944115400314331, -0.6964786648750305, -1.2426241636276245, 0.17965836822986603, -1.3332624435424805, -0.24975447356700897, -0.6814523935317993, -0.6815906763076782, 0.1745777726173401, 0.32260820269584656, 0.21220692992210388, 0.23871077597141266, -0.5927043557167053, -0.5871280431747437, -0.7413111925125122, -0.45345523953437805, 0.6153743863105774, 1.025992751121521, -0.2929864227771759, -0.23012393712997437, -0.22363872826099396, 0.322689026594162, 0.058803707361221313, 0.5135288834571838, -0.4071091115474701, -0.7224307060241699, -1.5380935668945312, 0.023852800950407982, 0.06108834594488144, -0.014839518815279007, -0.8928244709968567, 0.8254281282424927, 0.3855383098125458, -0.5207573175430298, -0.013552764430642128, -0.30704811215400696, -0.1401052325963974, -0.5101824402809143, 0.18859882652759552, -0.46641722321510315, 0.42843782901763916, 0.7701202034950256, -0.6080777645111084, -0.39003464579582214, 0.6415560841560364, -0.19366712868213654, -0.6501460671424866, -1.047982931137085, 0.7224589586257935, -0.23254644870758057, 0.38899311423301697, -0.4047236442565918, -0.018220558762550354, -1.3681777715682983, -0.15546080470085144, -0.06662970036268234, -0.007088867947459221, -0.22506126761436462, 0.7197704911231995, 0.11564355343580246, -1.154089093208313, 0.30181506276130676, 0.4936350882053375, -0.4482933580875397, 0.29388338327407837, 0.7782506942749023, 0.030904803425073624, -1.1337335109710693, 0.2628255784511566, -0.02040923573076725, 0.3360406458377838, -0.9481037259101868, 0.06007075682282448, 0.6989679932594299, -0.6510692238807678, -0.4803745448589325, 1.0461245775222778, -0.46857064962387085, -1.2246757745742798, -0.15223580598831177, -1.211492896080017, -0.37789779901504517, -0.5432683229446411, 0.4613669216632843, 0.2007753700017929, 0.5644798874855042, 0.3677273392677307, -0.3125596046447754, -0.18147429823875427, -0.0437566414475441, -0.2168980985879898, 0.5870203375816345, 0.18631264567375183, -0.38030585646629333, -0.028505617752671242, 0.8809736967086792, -0.6659522652626038, -0.9889663457870483, -0.7233421206474304, -0.35397493839263916, -0.05960657447576523, 0.44099828600883484, -0.1354648768901825, -0.9856153726577759, 0.935209333896637, -0.08556503802537918, 0.6163462996482849, 0.29637306928634644, -0.5902569890022278, 0.6286277174949646, 0.35549837350845337, -0.18312010169029236, -0.5413658618927002, -0.736227810382843, 1.5887736082077026, 1.0496301651000977, -0.2674880027770996, 0.5049065947532654, -0.21273621916770935, -0.7986186146736145, 1.1528469324111938, 0.48111942410469055, -0.29652196168899536, 0.8201354742050171, 0.3739742636680603, -0.23007985949516296, -0.043022993952035904, -1.0923850536346436, -0.2860575020313263, 0.528838038444519, 0.774876058101654, 0.6270891427993774, 0.4474877417087555, -0.08749335259199142, 0.8838656544685364, 0.05107470229268074, -0.10278891026973724, 0.5333513617515564, 0.5681202411651611, 0.18440651893615723, -0.3025071620941162, -0.14535988867282867, 0.6943113207817078, -0.7091788053512573, -0.7358205318450928, 0.35666975378990173, 0.7472823858261108, -0.10791762173175812, 0.456587553024292, 1.3225826025009155, -0.23066076636314392, 0.8795626163482666, -0.07749712467193604, 0.3923681974411011, -0.5887100100517273, -0.4303770661354065, -0.3146159052848816, -0.28884321451187134, -0.15491394698619843, 0.3140738308429718, -0.7260284423828125, -0.8241826891899109, -0.9411307573318481, 0.9840638041496277, -0.3151320219039917, 0.5500602722167969, 0.5764817595481873, 1.077010989189148, 1.3072127103805542, -0.2738548517227173, -0.6957994103431702, -0.12747648358345032, -0.42040112614631653, -0.18076840043067932, -0.08986946195363998, -0.600128173828125, 0.06492223590612411, -0.20362478494644165, -0.23176735639572144]}, "authors": [{"authorId": "2112670252", "name": "Bojian Zheng"}, {"authorId": "2271831246", "name": "Cody Hao Yu"}, {"authorId": "2146044942", "name": "Jie Wang"}, {"authorId": "2271595749", "name": "Yaoyao Ding"}, {"authorId": "2136341779", "name": "Yizhi Liu"}, {"authorId": "2270249206", "name": "Yida Wang"}, {"authorId": "3257164", "name": "Gennady Pekhimenko"}], "references": [{"paperId": "7e4937ea9b02cce1db69772beb17ccaf8d2c7ed8", "title": "Graphene: An IR for Optimized Tensor Computations on GPUs"}, {"paperId": "94d23df13520db6d48f72621fc72049e640ca9f2", "title": "Tempo: Accelerating Transformer-Based Model Training through Memory Footprint Reduction"}, {"paperId": "ea9bdd6de80ea298f0a4ec9aaa7be44dc3ebc2ef", "title": "Hidet: Task-Mapping Programming Paradigm for Deep Learning Tensor Programs"}, {"paperId": "003c08471fe579d98e82cf5c0cac03897403fb55", "title": "FP8 Quantization: The Power of the Exponent"}, {"paperId": "c142bfce3b6849ee9d6aa0d5637ab28b170fd507", "title": "SparseTIR: Composable Abstractions for Sparse Compilation in Deep Learning"}, {"paperId": "6d5c5e0df5dc4bd0bcd524d2a22d65d672bd0b74", "title": "TensorIR: An Abstraction for Automatic Tensorized Program Optimization"}, {"paperId": "93f0df3050c2048c08f26765dc387af70f60a362", "title": "AMOS: enabling automatic mapping for tensor computations on spatial accelerators with hardware abstraction"}, {"paperId": "ca46ca04b554fb9a7b1e2ab8345064e603898333", "title": "FreeTensor: a free-form DSL with holistic optimizations for irregular tensor programs"}, {"paperId": "e7e1feff05edf89cac6c2e6de46815a3f89144ef", "title": "Tensor Program Optimization with Probabilistic Programs"}, {"paperId": "7171c5f56543c51ea584ed9edfe8ccd33375167d", "title": "AStitch: enabling a new multi-dimensional optimization space for memory-intensive ML training and inference on modern SIMT architectures"}, {"paperId": "210d8331272eec9b052e68270b9fdcd1267f8d5f", "title": "Bolt: Bridging the Gap between Auto-tuners and Hardware-native Performance"}, {"paperId": "592d8b30525a5ed14d56cb2e72a791f28a0981aa", "title": "The CoRa Tensor Compiler: Compilation for Ragged Tensors with Minimal Padding"}, {"paperId": "a16ada42fa37078ac4287da99fb03ba725993beb", "title": "AKG: automatic kernel generation for neural processing units using polyhedral transformations"}, {"paperId": "72dd63d67588a42fc817bbb8d655b397f67425df", "title": "ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep learning"}, {"paperId": "434aff622d4f4bd1729d1d643bba89c41407ba4d", "title": "DISC: A Dynamic Shape Compiler for Machine Learning Workloads"}, {"paperId": "bc4f195d2f0937dab16bf50a24bf385c10781dd7", "title": "MLIR: Scaling Compiler Infrastructure for Domain Specific Computation"}, {"paperId": "042b0d027790ba21424f59881ff4073e8016fbd6", "title": "RL-Scope: Cross-Stack Profiling for Deep Reinforcement Learning Workloads"}, {"paperId": "213416f5e1e30d86719b6b8d064aebd0fa548d49", "title": "Horizontally Fused Training Array: An Effective Hardware Utilization Squeezer for Training Novel Deep Learning Models"}, {"paperId": "d6ca36b25bcb8c094b584504f734b1bf869d5c1f", "title": "UNIT: Unifying Tensorized Instruction Compilation"}, {"paperId": "12b71736392209b4292471b7da0aed71ba2aa545", "title": "ZeRO-Offload: Democratizing Billion-Scale Model Training"}, {"paperId": "acf31788fa545f5f0467289b16188f2c6cfa8c44", "title": "Cortex: A Compiler for Recursive Deep Learning Models"}, {"paperId": "33d735c2f889b5b6a5851f01e741eae535a91127", "title": "Rammer: Enabling Holistic Deep Learning Compiler Optimizations with rTasks"}, {"paperId": "053b1d7b97eb2c91fc3921d589c160b0923c70b1", "title": "Learning to summarize from human feedback"}, {"paperId": "c435a9e4fdf6fe889f2c3016e2971eaa002695a9", "title": "Skyline: Interactive In-Editor Computational Performance Profiling for Deep Neural Network Training"}, {"paperId": "725264948d7b6946259af5b8d966e996b9570f99", "title": "DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters"}, {"paperId": "ad03bc097eef7a70ebaebd7d392bf87517ace3ac", "title": "Automatic Horizontal Fusion for GPU Kernels"}, {"paperId": "215c7f23c69b745909d6c58ace6d36a141b8c656", "title": "Optimizing DNN computation graph using graph substitutions"}, {"paperId": "49a049dc85e2380dde80501a984878341dd8efdf", "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations"}, {"paperId": "3c55dd7b8da5c7b47e91b2e749c264f50d007cd4", "title": "Dynamic Tensor Rematerialization"}, {"paperId": "09bda461aa4911d0513e8e46dd39a4113947e450", "title": "Ansor : Generating High-Performance Tensor Programs for Deep Learning"}, {"paperId": "86b3e0c9cbdc74b4d0a34345d9f779b6cc38562f", "title": "Nimble: Efficiently Compiling Dynamic Neural Networks for Model Inference"}, {"paperId": "0170fc76e934ee643f869df18fb617d5357e8b4e", "title": "Conformer: Convolution-augmented Transformer for Speech Recognition"}, {"paperId": "d84e056bc71e98424912a43f04471600f12804aa", "title": "FlexTensor: An Automatic Schedule Exploration and Optimization Framework for Tensor Computation on Heterogeneous System"}, {"paperId": "b11c87681ee46ab8c82bf96d97f958bd95b8f0a8", "title": "Capuchin: Tensor-based GPU Memory Management for Deep Learning"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "80b362efee95c1759c6dab9219eb77ca3ee44475", "title": "TASO: optimizing deep learning computation with automatic generation of graph substitutions"}, {"paperId": "fd431005d26100f5453590080683cbae9dc1189f", "title": "Checkmate: Breaking the Memory Wall with Optimal Tensor Rematerialization"}, {"paperId": "3c5f1ab37f70db503636075e15b3173f86eea00b", "title": "Green AI"}, {"paperId": "661d142c23cb2a3207d5f1ba2ac7ff61f2d4fb2f", "title": "Triton: an intermediate language and compiler for tiled neural network computations"}, {"paperId": "6e13e111e85d499d781386b182fd855fbb053771", "title": "Deep Learning Recommendation Model for Personalization and Recommendation Systems"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "68584a2156056718c734fa38cdc08d414cbcfc00", "title": "Buddy Compression: Enabling Larger Memory for Deep Learning and HPC Workloads on GPUs"}, {"paperId": "57642aa16d29bbd9f89f95e3f3dcb8291552db60", "title": "Benchmarking and Analyzing Deep Neural Network Training"}, {"paperId": "c1c8d15520d84ed6d9a701e18627ded4d8f1eb2a", "title": "Differentiable programming for image processing and deep learning in halide"}, {"paperId": "b2c3f631999857d26a9abc4895ca6a9531d54a8e", "title": "Analysis of DAWNBench, a Time-to-Accuracy Machine Learning Performance Benchmark"}, {"paperId": "aa0e749388e10318d9bfab43400e1f303a9e7394", "title": "Gist: Efficient Data Encoding for Deep Neural Network Training"}, {"paperId": "98ecd2ae78afaa48b53f76d9df42935cbfc1d1a7", "title": "Echo: Compiler-based GPU Memory Footprint Reduction for LSTM RNN Training"}, {"paperId": "3e0d101575705c7e24757edb52a0d3b4b1a57f3c", "title": "General-Purpose Graphics Processor Architectures"}, {"paperId": "8c7310477fd027193cd040288f0aa9824c80b91f", "title": "Tiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code"}, {"paperId": "6a06a44dc8538a226df169e5a7ed659e5db3f9e4", "title": "Reversible Architectures for Arbitrarily Deep Residual Neural Networks"}, {"paperId": "3a6d4cd0768ae8768e733280d362bdb4d25924e7", "title": "The Reversible Residual Network: Backpropagation Without Storing Activations"}, {"paperId": "d2e4147eecae6f914e9e1e9aece8fdd2eaed809f", "title": "Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations"}, {"paperId": "5694e46284460a648fe29117cbc55f6c9be3fa3c", "title": "Densely Connected Convolutional Networks"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "642d0f49b7826adcf986616f4af77e736229990f", "title": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"}, {"paperId": "31c36d445367ba204244bb74893c5654e31c3869", "title": "cuDNN: Efficient Primitives for Deep Learning"}, {"paperId": "d9891561707a44a1ce87eb0199f2f5d6524f4d26", "title": "A scalable multi-path microarchitecture for efficient GPU control flow"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "d1de5cf893a9ea1191836782bd740e00e728cb4a", "title": "The dual-path execution model for efficient GPU control flow"}, {"paperId": "afce4d0ba3ab134bdbfb35fd23e17de358acb9a8", "title": "GPUs and the Future of Parallel Computing"}, {"paperId": "8bd6f67ef03b3c138c52f3e9b1716aebe937d244", "title": "Thread block compaction for efficient SIMT control flow"}, {"paperId": "c0546dd48f078225cf4167c6587b6d5e32ab96c3", "title": "Dynamic warp subdivision for integrated branch and memory divergence tolerance"}, {"paperId": "32bc6af9a529d47f81aa9520b9e0b1cb7a8766c2", "title": "Dynamic warp formation: Efficient MIMD control flow on SIMD graphics hardware"}, {"paperId": "4308295a2eaef30be423520918ad224dc2f3ffe2", "title": "Dynamic Warp Formation and Scheduling for Efficient GPU Control Flow"}, {"paperId": "ecc2f6ab799084adab252b5336aab57095129aa1", "title": "Introducing the IA-64 Architecture"}, {"paperId": "0f99496902614aecb72ff70f12d3a2cc9f267ed3", "title": "A comparison of full and partial predicated execution support for ILP processors"}, {"paperId": "89dddec47974ddf33fe8eb16c0232ab255479807", "title": "Compiler transformations for high-performance computing"}, {"paperId": "4a7bbb5718449555f63eb45a1ab2c71fd212a75c", "title": "Advanced compiler optimizations for supercomputers"}, {"paperId": "052b1d8ce63b07fec3de9dbb583772d860b7c769", "title": "Learning representations by back-propagating errors"}, {"paperId": null, "title": ". TorchDynamo Overview"}, {"paperId": "19d89d7156df11fae319252b49c53de5941ed8b9", "title": "Arbitor: A Numerically Accurate Hardware Emulation Tool for DNN Accelerators"}, {"paperId": "9515c79aa5ecb90c17ce03b99543e247e58be978", "title": "Hotline Profiler: Automatic Annotation and A Multi-Scale Timeline for Visualizing Time-Use in DNN Training"}, {"paperId": null, "title": "2023. NVIDIA H100 Tensor Core GPU Architecture"}, {"paperId": "9d7a75601e0e50dd68d40cfb8ef0e891dad797a6", "title": "Orca: A Distributed Serving System for Transformer-Based Generative Models"}, {"paperId": "a33a876dff9bd77eae1bbf0fa7f2b1be1448c2c4", "title": "Apollo: Automatic Partition-based Operator Fusion through Layer by Layer Optimization"}, {"paperId": "7250b2053d05687664029c29c2f1225b48c7ee45", "title": "ROLLER: Fast and Efficient Tensor Compilation for Deep Learning"}, {"paperId": "7d5e427bb8f6374618edf9c380ad22d6249560ab", "title": "DietCode: Automatic Optimization for Dynamic Tensor Programs"}, {"paperId": null, "title": "GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model"}, {"paperId": "e1e18f27e4aec1648f440a526f56b66dba2e1f5c", "title": "PET: Optimizing Tensor Programs with Partially Equivalent Transformations and Automated Corrections"}, {"paperId": null, "title": "Fine-Tune Wav2Vec2 for English ASR with Transform-ers"}, {"paperId": null, "title": "GRAPHICS DOUBLE DATA RATE 6 (GDDR6) SGRAM STAN-DARD"}, {"paperId": null, "title": "EqualitySaturationforTensorGraph Superoptimization"}, {"paperId": null, "title": "HIGH BANDWIDTH MEMORY (HBM) DRAM"}, {"paperId": null, "title": "Transformers:State-of-the-ArtNaturalLanguageProcessing"}, {"paperId": null, "title": "Howtogeneratetext:usingdifferentdecodingmethods for language generation with Transformers"}, {"paperId": null, "title": "ZeRO memoryoptimizationstowardtrainingtrillionparametermodels"}, {"paperId": null, "title": "IntegerQuantizationforDeepLearningInference:PrinciplesandEmpirical Evaluation"}, {"paperId": null, "title": "XLA: Compiling Machine Learning for Peak Performance"}, {"paperId": null, "title": "MLPerfInferenceBenchmark"}, {"paperId": null, "title": "[RFC] Dynamic Shape Support - Graph Dispatching"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "23febd8fbefbabfc5bf3bfccfb377903dd17c1e6", "title": "Python"}, {"paperId": null, "title": "BFloat16:Thesecrettohighperformance on Cloud TPUs"}, {"paperId": null, "title": "Getting Started with CUDA Graphs"}, {"paperId": "ec3071fb918ad69ec80df1ca9cf1fdeb386a9603", "title": "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning"}, {"paperId": null, "title": "MixedPrecisionTraining"}, {"paperId": null, "title": "CompressingDMAEngine:LeveragingActivation SparsityforTrainingDeepNeuralNetworks"}, {"paperId": null, "title": "Systemsanddevicesforcompressingneuralnetworkparameters"}, {"paperId": null, "title": "Main Memory: DDR4 and DDR5 SDRAM"}, {"paperId": null, "title": "Computer Architecture, Sixth Edition: A Quantitative Approach (6th ed.)"}, {"paperId": null, "title": "TensorFlow:ASystemforLarge-ScaleMachineLearning"}, {"paperId": null, "title": "Efficient Inference with TensorRT"}, {"paperId": null, "title": "DeepSpeech2:End-to-EndSpeechRecognitioninEnglishandMandarin"}, {"paperId": null, "title": "TrainingDeep NetswithSublinearMemoryCost"}, {"paperId": null, "title": "vDNN:VirtualizedDeepNeuralNetworksforScalable,Memory-efficientNeuralNetworkDesign"}, {"paperId": "3911933c247f705b2488fdd067330820e8db07bf", "title": "TIMIT Acoustic-Phonetic Continuous Speech Corpus"}, {"paperId": null, "title": "Temporal SIMT execution optimization through elimination of redundant operations"}, {"paperId": null, "title": "PCI Express Base Specification Revision 3.0"}, {"paperId": null, "title": "1-5December2007,Chicago,Illinois,USA"}, {"paperId": null, "title": "Chapter 34. GPU Flow-Control Idioms"}, {"paperId": null, "title": "2022. Enabling Dynamic Control Flow in CUDA Graphs with Device Graph Launch"}, {"paperId": null, "title": "2023. Linux X64 (AMD64/EM64T) Display Driver"}, {"paperId": null, "title": "2023. GPT-4 Technical Report"}, {"paperId": null, "title": "2022. Run Length Encoding and Decoding"}, {"paperId": null, "title": "CentML"}, {"paperId": null, "title": "CPU World. 2023. Intel Xeon 8273CL specifications"}, {"paperId": null, "title": "2022.FP8FormatsforDeepLearning"}, {"paperId": null, "title": "Received 28 April 2023; revised 7 July 2023; accepted 24 July 2023 license agreement with IEEE. Restrictions apply"}, {"paperId": null, "title": "2022. Alpa: Automating Inter-and Intra-Operator Par-allelismforDistributedDeepLearning"}, {"paperId": null, "title": ". 2023. Accelerator-optimized machine family"}, {"paperId": null, "title": "2023. Mixing sparsity compression"}, {"paperId": null, "title": "2022.NeuralNetworkQuantizationwithAIModelEfficiencyToolkit(AIMET). CoRR abs/2201.08442(2022)"}, {"paperId": null, "title": "2022. Introducing nvFuser, a deep learning compiler for PyTorch"}, {"paperId": null, "title": "2023. Graph Management"}, {"paperId": null, "title": "Gregory"}, {"paperId": null, "title": "2022. A Decade of Machine Learning Accelerators: Lessons Learned and Carbon Footprint"}, {"paperId": null, "title": "2022. PyTorch 2.0: Dynamic Shapes Support"}, {"paperId": null, "title": "MICRO \u201923, October 28\u2013November 01, 2023, Toronto, ON, Canada Networks"}, {"paperId": null, "title": "NVIDIA"}]}