{"paperId": "e9fc39f56abbc6b8aed1e05496d985e70345a95a", "title": "An extensive study on pre-trained models for program understanding and generation", "abstract": "Automatic program understanding and generation techniques could significantly advance the productivity of programmers and have been widely studied by academia and industry. Recently, the advent of pre-trained paradigm enlightens researchers to develop general-purpose pre-trained models which can be applied for a broad range of program understanding and generation tasks. Such pre-trained models, derived by self-supervised objectives on large unlabelled corpora, can be fine-tuned in downstream tasks (such as code search and code generation) with minimal adaptations. Although these pre-trained models claim superiority over the prior techniques, they seldom follow equivalent evaluation protocols, e.g., they are hardly evaluated on the identical benchmarks, tasks, or settings. Consequently, there is a pressing need for a comprehensive study of the pre-trained models on their effectiveness, versatility as well as the limitations to provide implications and guidance for the future development in this area. To this end, we first perform an extensive study of eight open-access pre-trained models over a large benchmark on seven representative code tasks to assess their reproducibility. We further compare the pre-trained models and domain-specific state-of-the-art techniques for validating pre-trained effectiveness. At last, we investigate the robustness of the pre-trained models by inspecting their performance variations under adversarial attacks. Through the study, we find that while we can in general replicate the original performance of the pre-trained models on their evaluated tasks and adopted benchmarks, subtle performance fluctuations can refute the findings in their original papers. Moreover, none of the existing pre-trained models can dominate over all other models. We also find that the pre-trained models can significantly outperform non-pre-trained state-of-the-art techniques in program understanding tasks. Furthermore, we perform the first study for natural language-programming language pre-trained model robustness via adversarial attacks and find that a simple random attack approach can easily fool the state-of-the-art pre-trained models and thus incur security issues. At last, we also provide multiple practical guidelines for advancing future research on pre-trained models for program understanding and generation.", "venue": "International Symposium on Software Testing and Analysis", "year": 2022, "citationCount": 93, "influentialCitationCount": 12, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The first study for natural language-programming language pre-trained model robustness via adversarial attacks is performed and it is found that a simple random attack approach can easily fool the state-of-the-art pre- trained models and thus incur security issues."}, "embedding": {"model": "specter_v2", "vector": [0.4767119884490967, 0.4896988868713379, -0.7175079584121704, -0.07980084419250488, -0.42294034361839294, -0.7075973153114319, 0.17180868983268738, -0.1548461616039276, 0.014474675990641117, -0.4127964973449707, -0.057656776160001755, -0.31799325346946716, 0.5804414749145508, 0.021217307075858116, -0.703319251537323, 0.3863815367221832, -0.6364884972572327, -0.05604245141148567, -0.19189535081386566, -0.22263120114803314, 0.32340478897094727, -1.1295905113220215, -0.8008688688278198, 0.4185680150985718, 1.03683340549469, 0.019130630418658257, -0.31573376059532166, 1.2469104528427124, 0.0903681293129921, 0.3473994731903076, 0.5038058757781982, -0.5445948839187622, 0.24845287203788757, 0.1789218634366989, -0.5089793801307678, 0.01140986755490303, 0.19416078925132751, -0.43447017669677734, -0.4103854298591614, 1.0300707817077637, -0.2105141580104828, -0.20935150980949402, 0.058701734989881516, -0.8214108347892761, -0.6371410489082336, 0.9584420323371887, 0.3040163815021515, 0.5756209492683411, 0.06199489161372185, 0.07338059693574905, 1.155569314956665, -0.7252423763275146, 0.12289806455373764, 0.9665703177452087, 0.6175304651260376, 0.825641930103302, -0.40606871247291565, -0.3301115930080414, -0.17240789532661438, -0.4221528172492981, -0.768568754196167, -0.18474562466144562, -0.2073558121919632, -0.6709248423576355, 1.9509708881378174, -0.5766691565513611, -0.6663744449615479, 0.2387974113225937, 0.06938169151544571, 1.0476994514465332, -0.41943359375, -0.6507413983345032, -0.2620055675506592, 0.10591668635606766, 0.6898505091667175, 1.15988290309906, -0.009885896928608418, 0.3852042853832245, -0.6053370833396912, -0.47735899686813354, 0.3409004211425781, -0.02740328200161457, -0.07043413817882538, -0.37785831093788147, -0.08490634709596634, 0.6875623464584351, 0.18214912712574005, 0.8267301321029663, 0.11817523092031479, 0.8031206727027893, 0.8563858270645142, 0.29027944803237915, -0.22565792500972748, 0.9381576180458069, -0.20093879103660583, 0.00995153933763504, -0.8945849537849426, 0.03309057280421257, 0.10628291219472885, 1.115935206413269, 0.21856927871704102, 0.5684850215911865, -0.7250622510910034, -0.23145791888237, 1.0194543600082397, -0.0012754074996337295, 0.35796791315078735, -0.49768945574760437, 0.5197511911392212, -0.16173039376735687, 0.00840541161596775, -0.3661195635795593, 0.1835092008113861, 0.014274911023676395, -0.6288298964500427, -0.788688063621521, -0.5828613042831421, -0.24149379134178162, -1.285799264907837, 0.6738804578781128, -0.6461381316184998, 0.038151152431964874, 0.43650051951408386, 0.5441098213195801, 0.5974581241607666, 0.44713783264160156, 0.1739182472229004, 0.12139221280813217, 0.5871877074241638, -1.0581673383712769, -0.16637679934501648, -1.1955158710479736, 0.934363603591919, -0.43647876381874084, 0.1482255458831787, -0.36593735218048096, -1.2324999570846558, -1.1143790483474731, -1.1114970445632935, 0.1195184513926506, -0.48991432785987854, 0.6211580634117126, 1.2680116891860962, 0.9188533425331116, -1.0586835145950317, 0.9768179655075073, -0.3688506782054901, -0.03067070245742798, 0.5425719022750854, 0.2359759360551834, 0.25319695472717285, -0.315622478723526, -0.7975960373878479, -0.13364215195178986, 0.578277587890625, -0.8970593214035034, -0.9295822978019714, -0.5540054440498352, -1.4361913204193115, 0.06665661931037903, 0.28019851446151733, -0.48459240794181824, 1.4471440315246582, -0.2549336552619934, -0.6115466356277466, 0.9685500860214233, -0.3212794363498688, -0.3494216799736023, 0.022502217441797256, -0.20353485643863678, -0.35392990708351135, -0.4716646671295166, 0.1542639583349228, -0.01572018675506115, 0.5557180643081665, -0.6369659900665283, 0.2873624563217163, 0.720608115196228, 0.3105700612068176, -0.5489012002944946, -0.24545010924339294, 0.999902606010437, -0.3160407543182373, -0.10531770437955856, 0.154034823179245, 0.6434279680252075, 0.034278374165296555, -0.540040135383606, -0.6549667119979858, -0.8492408394813538, 0.9387571811676025, -0.16599996387958527, 1.224440336227417, -1.066988468170166, -0.8957822918891907, 0.005300258751958609, -0.10574033111333847, 0.20086392760276794, -0.5209019184112549, 0.37685394287109375, -0.9156916737556458, 1.0214483737945557, -0.443518728017807, -1.0802392959594727, 0.24357201159000397, -0.532378613948822, -0.9925538897514343, -0.11684513092041016, 0.17733845114707947, 1.0577043294906616, -0.9067898988723755, 0.5289616584777832, -0.2632048428058624, -0.07276450097560883, -1.1250535249710083, 1.3803080320358276, -0.5360848903656006, 0.08000841736793518, -0.19878549873828888, 0.1709079146385193, 0.1526341587305069, -0.2720704674720764, -0.14488071203231812, -0.0661560595035553, -0.07604199647903442, 0.30412739515304565, -0.07708361744880676, 1.6026520729064941, -0.3937402367591858, 0.3710060715675354, -0.08900738507509232, -0.5668819546699524, 0.21219231188297272, 0.7839028835296631, -0.2895641028881073, 0.1692473143339157, 0.24687924981117249, 0.38826629519462585, -0.47430625557899475, -0.028111854568123817, 0.6388824582099915, 0.7900179028511047, -0.4491097033023834, 0.8813115358352661, 0.5749061703681946, -0.5422052145004272, 0.6812863945960999, 0.5658218264579773, 1.0732471942901611, 0.2689149081707001, 0.40650996565818787, 0.18183442950248718, 0.6481480002403259, -0.3508507311344147, 0.02731112390756607, 0.6338433027267456, 0.7286726832389832, 1.3264391422271729, 0.45567378401756287, -0.8819124102592468, -0.3690660893917084, 0.17297641932964325, 1.237319827079773, 1.6308218240737915, -0.13850808143615723, -0.4063730835914612, -1.0619428157806396, -0.898963987827301, -0.5704740285873413, 0.2129983752965927, -0.4042420983314514, -0.5804585814476013, -0.39263272285461426, -1.2450343370437622, 0.9221321940422058, 0.5182853937149048, 1.3769010305404663, -0.4576400816440582, -0.27294087409973145, -0.5841212868690491, 0.39761340618133545, -0.4802236258983612, -0.9545820951461792, 0.16739866137504578, -0.1435825228691101, -0.6488192081451416, 0.5369424223899841, -0.38129785656929016, 0.7716541886329651, -0.3991522192955017, 1.045943260192871, 0.5956596732139587, -0.5825346112251282, 0.5072636604309082, 0.49745598435401917, -0.48663216829299927, -1.1485693454742432, 0.44234499335289, -0.32342851161956787, -0.6039515733718872, 0.5189104676246643, 0.337591290473938, 0.4247584640979767, 0.2839173972606659, -0.6638734340667725, -0.2508458197116852, 0.22342588007450104, 0.2594214379787445, 0.372896283864975, 0.1566062718629837, -0.41612693667411804, -1.6150177717208862, 0.6424174308776855, 0.012834891676902771, -0.45989006757736206, 0.4286878705024719, -0.7413381934165955, -0.16629980504512787, 0.7586642503738403, -0.6802799105644226, -0.47748199105262756, -0.8957958221435547, 0.6002764701843262, -0.21740604937076569, -0.25925523042678833, 0.10846995562314987, 0.2910992205142975, -0.3312414884567261, 0.8256387710571289, 0.5570024251937866, 0.055404551327228546, 0.02873064950108528, 0.1517627090215683, -1.3510257005691528, 0.6244118809700012, -0.16368217766284943, 1.2130411863327026, -0.299763023853302, -0.9614408612251282, 0.05473858118057251, -0.39547300338745117, -0.25733211636543274, 0.09149112552404404, 0.11847031861543655, 0.40797778964042664, -0.5374201536178589, -0.6692966818809509, 0.07654470950365067, -1.4999587535858154, -0.1383710503578186, 0.30107414722442627, -0.6925989985466003, -0.07682253420352936, -0.8206990361213684, -0.7982419729232788, -0.5746281743049622, -0.8120594620704651, -1.3146041631698608, 0.47827476263046265, 0.23451600968837738, -0.3382223844528198, -0.4062064290046692, 0.27559247612953186, -0.06666858494281769, 1.0138487815856934, -0.1628461629152298, 1.070890188217163, -0.20881719887256622, -0.39005547761917114, -0.30104145407676697, 0.08491228520870209, 0.635129988193512, -0.4243035316467285, 0.6845875978469849, -1.062164306640625, -0.25409454107284546, 0.19490645825862885, -0.5331714153289795, 0.3130359947681427, -0.013622395694255829, 0.9224081635475159, 0.08008919656276703, -0.4285346269607544, 0.7538159489631653, 1.675352692604065, -0.5049231052398682, 0.31029191613197327, 0.16460609436035156, 1.2803797721862793, 0.1819998174905777, -0.31985434889793396, 0.25198987126350403, -0.020188970491290092, -0.15014387667179108, 0.28056544065475464, -0.19316332042217255, 0.258671373128891, -0.3456231951713562, 0.6215342879295349, 0.7569904923439026, -0.1132901981472969, -0.1398211568593979, -1.4251214265823364, 1.1297743320465088, -1.2442337274551392, -0.6375824213027954, 0.40520593523979187, 0.6597633957862854, 0.3821159601211548, -0.10676292330026627, -0.5004287362098694, -0.024413827806711197, 0.7580898404121399, 0.21098561584949493, -0.3544943630695343, -1.162367343902588, 0.27852070331573486, 0.6136001944541931, 0.2131349891424179, 0.20665906369686127, -0.8092581033706665, 0.13477636873722076, 14.446162223815918, 0.6679323315620422, 0.34108689427375793, 0.6851343512535095, 0.7644791007041931, 0.9040049314498901, -0.4582193195819855, 0.2550604045391083, -0.9404057264328003, -0.3733048737049103, 0.8362897634506226, -0.3671787977218628, 0.7372148036956787, 0.8922045230865479, -0.4896368682384491, 0.13747632503509521, -0.5856213569641113, 0.499946266412735, 0.5735140442848206, -1.2871079444885254, 0.21153174340724945, 0.06877315789461136, 1.1762186288833618, -0.01015779934823513, 0.9148274660110474, 1.1095830202102661, 0.35105112195014954, -0.7637398838996887, 0.009492422454059124, -0.3249512016773224, 0.9721139073371887, 0.00039198820013552904, 0.8703095316886902, 0.43019983172416687, -0.8304567933082581, -0.3127347528934479, -0.5597214102745056, -1.1870568990707397, 0.117104172706604, 0.12054994702339172, -0.8472618460655212, -0.08572644740343094, -0.31778770685195923, 0.7868627905845642, -0.17562276124954224, 0.45191216468811035, -0.9029905796051025, 0.7791195511817932, 0.230607271194458, 0.638845682144165, -0.23968566954135895, 1.095596432685852, 0.16551189124584198, -0.25224387645721436, -0.18079856038093567, 0.07541424036026001, 0.3737927973270416, 0.8643274307250977, -0.7334843277931213, -0.3961664140224457, -0.27850329875946045, -0.5708155035972595, -0.6385334134101868, 0.7706800699234009, 0.44981905817985535, 0.24343515932559967, -0.4736519157886505, 0.008088039234280586, 0.3711077868938446, 0.09758276492357254, -0.6571804881095886, -0.12089863419532776, 0.07283828407526016, -0.14008037745952606, -0.11269578337669373, 0.3706044852733612, -0.8542404770851135, -0.6830081343650818, -0.5805842280387878, -0.65267014503479, 0.48341137170791626, -0.4658151865005493, -0.4717603027820587, 1.0350186824798584, -0.34724757075309753, -0.47280579805374146, 0.022018909454345703, -0.5453936457633972, -1.2263075113296509, 0.41045525670051575, -1.2064158916473389, -0.7231379747390747, 0.15861493349075317, -0.6843986511230469, -0.45285892486572266, -0.5674521327018738, 1.3375413417816162, -0.0935044214129448, -0.6096372604370117, 0.3357406258583069, -0.07036099582910538, 0.2651864290237427, 0.10812538862228394, -1.0875256061553955, 1.3187047243118286, 1.0051661729812622, -0.5141739249229431, 0.6721287965774536, 0.20148709416389465, -0.3031652867794037, -0.7297399044036865, -0.07916486263275146, 0.5234931111335754, -0.9329699873924255, -0.3413105010986328, -0.6403481364250183, -0.9919241666793823, 0.3397465944290161, 0.803967297077179, -0.6032220721244812, 0.29332679510116577, -0.12432874739170074, -0.8558868169784546, 0.31018736958503723, -1.1569545269012451, -0.5326598286628723, 0.5043280124664307, -1.040397047996521, -0.48840105533599854, 0.2132892608642578, 0.2711290121078491, -1.120774507522583, -0.41556239128112793, -0.06057028844952583, -0.1548120081424713, -0.26061317324638367, 0.7587428092956543, -0.06065812706947327, 1.253385066986084, 0.6351209282875061, 0.5037159323692322, -0.7386777997016907, 0.17333060503005981, -1.1853197813034058, 0.1361522525548935, 0.4401662349700928, 0.970377504825592, -0.4895748496055603, 0.44092369079589844, 1.5131895542144775, 0.08903498947620392, -0.03743632510304451, -0.07823843508958817, 0.050939202308654785, -0.052440766245126724, -0.19921647012233734, 0.2865840792655945, 0.14914441108703613, -0.08179335296154022, -0.45265164971351624, 0.33907777070999146, 1.0723367929458618, -0.2803685963153839, -0.18124084174633026, 0.8726395964622498, 0.1949000358581543, -0.7007158994674683, -0.08806581050157547, -0.26510122418403625, -0.9721008539199829, 0.3706863820552826, -1.0045745372772217, 0.3355146050453186, -0.4484800696372986, -0.10423440486192703, 0.4734065532684326, 0.10441118478775024, 0.3804625868797302, 0.021846022456884384, -0.26302704215049744, -0.6877304315567017, -0.5871454477310181, -0.6088855862617493, 0.3837878704071045, 0.24735412001609802, -0.8015586733818054, 0.051165249198675156, 0.20897047221660614, -0.21791931986808777, 0.406749963760376, 0.6439128518104553, -0.860035240650177, -0.9031970500946045, -1.5626627206802368, 0.22946792840957642, -0.46277034282684326, 0.10874901711940765, -0.8523496389389038, 0.6637368202209473, 0.5252657532691956, -0.5621088743209839, 0.47226351499557495, -0.40416014194488525, -0.565232515335083, -0.5933479070663452, 0.5093640089035034, -0.43014171719551086, 0.33590593934059143, 0.3838741183280945, -0.7153760194778442, -0.41111594438552856, 0.08047430962324142, -0.14074215292930603, -1.1296385526657104, -0.8907393217086792, 0.323496013879776, -0.3632029592990875, 0.1663530170917511, 0.19556474685668945, 0.18527671694755554, -1.4697554111480713, -0.20913510024547577, -0.02428724803030491, 0.5584062933921814, 0.16798429191112518, 0.5926372408866882, 0.2643553614616394, -0.5704841017723083, 0.1266581416130066, 0.5823180675506592, -0.1312231570482254, 0.08127943426370621, 0.7255921959877014, 0.24658794701099396, -0.6236522793769836, 0.20844420790672302, 0.3111293315887451, 0.3521246910095215, -0.899717390537262, 0.1287156194448471, 0.6918870210647583, -0.8287199139595032, 0.48134148120880127, 1.1396851539611816, -0.12201105803251266, -0.8725444078445435, -0.23384138941764832, -0.9323420524597168, -0.1648779660463333, -1.1965601444244385, 0.7593881487846375, 0.05329636484384537, -0.24692198634147644, -0.06305154412984848, -0.46376487612724304, 0.2903827428817749, -0.3111910820007324, 0.023149538785219193, 0.752150297164917, 0.26668107509613037, -0.6284579038619995, -0.12997561693191528, 0.494905561208725, -0.6085150837898254, -0.42492517828941345, -0.22346872091293335, -0.41455161571502686, -0.37127575278282166, 0.10544775426387787, -0.3969554305076599, -0.8994880318641663, 0.80600506067276, 0.2451993227005005, 0.5013889074325562, 0.3486593961715698, -0.5402935147285461, 0.15939514338970184, 0.3562715947628021, 0.15449585020542145, -0.2404995560646057, -0.40299779176712036, 0.9840955138206482, 0.8366771340370178, -1.3349813222885132, 0.32183074951171875, -0.9779506921768188, -0.6239928603172302, 1.2581210136413574, 0.8483275175094604, -0.27593764662742615, 0.40989449620246887, -0.4219433069229126, -0.3767636716365814, 0.1724335253238678, -0.6120411157608032, -0.13252857327461243, 0.7837886214256287, 1.0827925205230713, 0.8507803082466125, -0.12913565337657928, 0.07544741034507751, 1.1445256471633911, 0.15233223140239716, -0.06274758279323578, 1.1359307765960693, 0.7778990268707275, 0.1415119618177414, -0.331958532333374, -0.2850521504878998, 0.5301623940467834, -0.9428300261497498, -0.5429784059524536, 0.02101973444223404, 0.6699218153953552, 0.6379427909851074, 0.689490556716919, -0.10494460165500641, -0.14303068816661835, 0.41390153765678406, 0.4415056109428406, 0.0055723669938743114, -1.3159425258636475, -0.7196505665779114, -0.5644632577896118, -0.524143397808075, -0.21666750311851501, -0.22100773453712463, -0.11561229079961777, -0.23875568807125092, -0.3162294328212738, 0.2328835278749466, 0.1427924782037735, 0.18844759464263916, 1.0241873264312744, 0.6106842160224915, 0.4190520942211151, -0.1399930864572525, -0.5817692875862122, -0.19599635899066925, -0.7136328816413879, 0.26991912722587585, -0.3660354018211365, -0.21060381829738617, -0.20043513178825378, -0.41540956497192383, 0.33673277497291565]}, "authors": [{"authorId": "1557363420", "name": "Zhengran Zeng"}, {"authorId": "2176503078", "name": "Hanzhuo Tan"}, {"authorId": "1557360433", "name": "Haotian Zhang"}, {"authorId": "2174027344", "name": "Jing Li"}, {"authorId": "2108444948", "name": "Yuqun Zhang"}, {"authorId": "2145398332", "name": "Lingming Zhang"}], "references": [{"paperId": "8c8d4698873fc56e0358cfd5c346ca8c669aaf3a", "title": "Free Lunch for Testing: Fuzzing Deep-Learning Libraries from Open Source"}, {"paperId": "801981a7a071e5b76adcd54f4275006073fe4380", "title": "Reinforcement-Learning-Guided Source Code Summarization Using Hierarchical Attention"}, {"paperId": "1067c44e473b6998f89e13f0d4c0de730def43f0", "title": "SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing"}, {"paperId": "b958872bbe8d6cb37ebad96173399403482bf340", "title": "A Strong Baseline for Query Efficient Attacks in a Black Box Setting"}, {"paperId": "a30f912f8c5e2a2bfb06351d4578e1ba3fa37896", "title": "CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation"}, {"paperId": "c9a0bc9fe339d59f99e5a425b11ad74a73421fd3", "title": "Boosting coverage-based fault localization via graph-based representation learning"}, {"paperId": "656676c49163a8753f819a0c22540fcd0884bac2", "title": "Deep just-in-time defect prediction: how far are we?"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "feba0c47bf12a02c3a725174bb53df78658a72a8", "title": "Pre-Trained Models: Past, Present and Future"}, {"paperId": "0b077c9577f4297dcf3da835e253d21965bbc6e0", "title": "CoTexT: Multi-task Learning with Code-Text Transformer"}, {"paperId": "5bfb0cc16b871c75e32a6a9d54dd7db225260e04", "title": "CodeTrans: Towards Cracking the Language of Silicone's Code Through Self-Supervised Deep Learning and High Performance Computing"}, {"paperId": "2e05413a737a7fe823c97e12c2ddc10d4a4c9dc0", "title": "Generating Adversarial Computer Programs using Optimized Obfuscations"}, {"paperId": "0646bb09db4d1ba24150e69b71edcd4aff691b3c", "title": "Unified Pre-training for Program Understanding and Generation"}, {"paperId": "171440398a1c0f43063a7689e3b385280336fb68", "title": "CURE: Code-Aware Neural Machine Translation for Automatic Program Repair"}, {"paperId": "69a72ff5b30642d11c96635e99aadad3140d33a7", "title": "CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation"}, {"paperId": "2ef79342ff22661cd7bc18833049085e6b3501c4", "title": "Generating Natural Language Attacks in a Hard Label Black Box Setting"}, {"paperId": "34757877708898a5a1ab3f0b5f8c975a0f71b2ce", "title": "Cross-domain Retrieval in the Legal and Patent Domains: a Reproducability Study"}, {"paperId": "acd8e24eda17808e3528d2dfd52de1619d13241a", "title": "InferCode: Self-Supervised Learning of Code Representations by Predicting Subtrees"}, {"paperId": "8b4c857311c001f6ed0cd790cce4af4dfcfb6533", "title": "Deep Graph Matching and Searching for Semantic Code Retrieval"}, {"paperId": "4083958684292f6fa2f5c7fd4f9be975e80145b6", "title": "GraphCodeBERT: Pre-training Code Representations with Data Flow"}, {"paperId": "adc9533f3d4c3b41b21c10a948a6118018df2a5a", "title": "Searching for a Search Method: Benchmarking Search Algorithms for Generating NLP Adversarial Examples"}, {"paperId": "bd02bcf2a437217eaac245abe443b2f672b3b36a", "title": "Deep Learning Based Vulnerability Detection: Are We There Yet?"}, {"paperId": "49cf6a22a5dac5bc98b653534af65ffa0bc0e76d", "title": "Multi-task Learning based Pre-trained Language Model for Code Completion"}, {"paperId": "1e5fb8003f866f9beeb1003f0be9a129d480ae75", "title": "Problems and Opportunities in Training Deep Learning Software Systems: An Analysis of Variance"}, {"paperId": "0c70f3d62764600a299b692affd6023922774095", "title": "Functional code clone detection with syntax and semantics fusion learning"}, {"paperId": "e0d4587181a8848e73612e8a32b02bd9cc82b595", "title": "CoCoNuT: combining context-aware neural translation models using ensemble for program repair"}, {"paperId": "eb2963b975277087b956ce83c264f43baa1e5d15", "title": "Can automated program repair refine fault localization? a unified debugging approach"}, {"paperId": "021bbcefc993c389bad6c1daefd8ff92d0fc2441", "title": "Contrastive Code Representation Learning"}, {"paperId": "bd47bb8cdd749a3356149da6155d2dcd7458779f", "title": "Retrieval-based Neural Source Code Summarization"}, {"paperId": "5ca8d485a1c9dc4d1e7904bf14831dcd8d4a621c", "title": "Semantic code search via equational reasoning"}, {"paperId": "df56748cd4f52a58973b4ac52c0bf9156c5f52f0", "title": "Unsupervised Translation of Programming Languages"}, {"paperId": "33ec7eb2168e37e3007d1059aa96b9a63254b4da", "title": "Beyond Accuracy: Behavioral Testing of NLP Models with CheckList"}, {"paperId": "c9b56cb026a38e39bb0228faac57accd6f65e6f7", "title": "TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP"}, {"paperId": "77910e51a40d17157fc798325d06edfa6cff18d6", "title": "Incorporating External Knowledge through Pre-training for Natural Language to Code Generation"}, {"paperId": "06a427e1688f92053a38c73cb4e0da25177c89e7", "title": "BAE: BERT-based Adversarial Examples for Text Classification"}, {"paperId": "dc0ce66f5ab4c5173cdef951649044e4c4c05076", "title": "BERT-ATTACK: Adversarial Attack against BERT Using BERT"}, {"paperId": "0dfe706526e5234338411489e1826b4060acc4e8", "title": "CC2Vec: Distributed Representations of Code Changes"}, {"paperId": "0fe2636446cd686830da3d971b31a004d6094b3c", "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages"}, {"paperId": "17c8d5d173d915d9662ad7b45c593d1ab3b742e1", "title": "Semantic Robustness of Models of Source Code"}, {"paperId": "e38a118f18f1b6e1a4e3d3f6fe4838fcdc0af022", "title": "Learning and Evaluating Contextual Embedding of Source Code"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "2ab44880e1763baf3d8753ccb43ad3bd5f122b70", "title": "Adversarial examples for models of code"}, {"paperId": "fbe25e4f069a19dc63daca27b7c98cff338663b9", "title": "CodeSearchNet Challenge: Evaluating the State of Semantic Code Search"}, {"paperId": "00549af4bc3270e0f688acbf694f912d7ee39cad", "title": "Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks"}, {"paperId": "31ce8dc94f8172875a5ee0ac8e398aa735da4f88", "title": "Neural Code Search Evaluation Dataset"}, {"paperId": "65a9c7b0800c86a196bc14e7621ff895cc6ab287", "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"}, {"paperId": "ae04f3d011511ad8ed7ffdf9fcfb7f11e6899ca2", "title": "Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "81f5810fbbab9b7203b9556f4ce3c741875407bc", "title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans"}, {"paperId": "6fbc0f7544fc9ca7cd29c9811c4cbf6acf5ab981", "title": "DeepFL: integrating multiple fault diagnosis dimensions for deep fault localization"}, {"paperId": "c41a11c0e9b8b92b4faaf97749841170b760760a", "title": "VideoBERT: A Joint Model for Video and Language Representation Learning"}, {"paperId": "87e414c840cb1107719b5f38389f832570cf3288", "title": "DeepBillboard: Systematic Physical-World Testing of Autonomous Driving Systems"}, {"paperId": "516497e7fc39ebb126bed28dcc5c6129e500acb8", "title": "An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation"}, {"paperId": "ea1b62a03ab16c4acca6f7041c6f096bedec244b", "title": "Deep learning type inference"}, {"paperId": "643de4fe3fcd960bea7b2491831308bc0febcef9", "title": "Tree2Tree Neural Translation Model for Learning Source Code Changes"}, {"paperId": "ab758c7d163dba039f1b1badaa9ea72064c887ba", "title": "DeepRoad: GAN-Based Metamorphic Testing and Input Validation Framework for Autonomous Driving Systems"}, {"paperId": "3cac56572497ba51c71da66bd207e7a48b2c758f", "title": "Mapping Language to Code in Programmatic Context"}, {"paperId": "2ea64d4f627efee614578ba2c5ce8e800ae02e7d", "title": "Practical program repair via bytecode mutation"}, {"paperId": "b227f3e4c0dc96e5ac5426b85485a70f2175a205", "title": "Representation Learning with Contrastive Predictive Coding"}, {"paperId": "2403c68b7805342fc2c7dc6815bc29e189fb495a", "title": "code2vec: learning distributed representations of code"}, {"paperId": "dc030c2e55b266c029356a54bb444b7d9b1f2abc", "title": "StaQC: A Systematically Mined Question-Code Dataset from Stack Overflow"}, {"paperId": "ef945d09f35d288e887d9d6ce80377e738a23580", "title": "Public Git Archive: A Big Code Dataset for All"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "e30e29b3bf4bc19194bad081badeb35803ee2118", "title": "Interpretable Learning for Self-Driving Cars by Visualizing Causal Attention"}, {"paperId": "62e176977d439aac2e2d7eca834a7a99016dfcaf", "title": "Probabilistic model for code with decision trees"}, {"paperId": "32aa2517b03c871c11e521c2a3406f457833e2c3", "title": "Summarizing Source Code using a Neural Attention Model"}, {"paperId": "484ed558a5863060b373e8a2cb7cb302b8c36116", "title": "A Convolutional Attention Network for Extreme Summarization of Source Code"}, {"paperId": "9277dc7dd5b348645e8fcf4a987e5b3fc9132c7c", "title": "Towards a Big Data Curated Benchmark of Inter-project Code Clones"}, {"paperId": "49512270b39636375880d611d7b2192d324f4ba6", "title": "Convolutional Neural Networks over Tree Structures for Programming Language Processing"}, {"paperId": "5d833331b0e22ff359db05c62a8bca18c4f04b68", "title": "One billion word benchmark for measuring progress in statistical language modeling"}, {"paperId": "44d0e05de389d81cfc1ae085069c8eb09b2b8c07", "title": "Injecting mechanical faults to localize developer faults for evolving software"}, {"paperId": "f6b51c8753a871dc94ff32152c00c01e94f90f09", "title": "Efficient Estimation of Word Representations in Vector Space"}, {"paperId": "e018415b22c87dc95eefaefa533e30bad824ea97", "title": "A Survey of Data Leakage Detection and Prevention Solutions"}, {"paperId": "3467b97c35d7d9e8d94b0a490751880ccdbcc479", "title": "Neural Code Summarization: How Far Are We?"}, {"paperId": null, "title": "ELECTRA:Pre-trainingTextEncodersasDiscriminatorsRatherThanGenerators"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "90757b62a670e094326e1b65bfb471f1666b5f77", "title": "Google BigQuery"}, {"paperId": null, "title": "ISSTA \u201922, July 18\u201322, 2022, Virtual, South Korea"}, {"paperId": null, "title": "2022. ISSTA\u201922 CodeStudy"}]}