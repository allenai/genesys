{"paperId": "0b0debb710366cdff461938c80763eace1651af6", "title": "Code Llama: Open Foundation Models for Code", "abstract": "We release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B, 34B and 70B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B, 13B and 70B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. Code Llama reaches state-of-the-art performance among open models on several code benchmarks, with scores of up to 67% and 65% on HumanEval and MBPP, respectively. Notably, Code Llama - Python 7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform every other publicly available model on MultiPL-E. We release Code Llama under a permissive license that allows for both research and commercial use.", "venue": "arXiv.org", "year": 2023, "citationCount": 935, "influentialCitationCount": 140, "openAccessPdf": {"url": "https://arxiv.org/pdf/2308.12950", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": null}, "embedding": {"model": "specter_v2", "vector": [-0.05644430220127106, 0.45156586170196533, -0.9729387760162354, 0.19502569735050201, 0.12105551362037659, -0.4050574004650116, 0.5495967864990234, 0.14748717844486237, -0.25770118832588196, -0.4178006649017334, 0.45220959186553955, -0.8553333282470703, 0.9871070384979248, 0.10039537400007248, -0.5642958879470825, 0.3268175423145294, -0.8228538632392883, -0.32043683528900146, 0.04756641387939453, -0.05488435924053192, 0.07049119472503662, -0.6466798186302185, -1.485867977142334, 0.45611777901649475, 0.8614489436149597, 0.055587396025657654, 0.025065550580620766, 1.1120439767837524, -0.621303379535675, 0.8825910687446594, 0.6595636010169983, -0.07957159727811813, 0.0642271488904953, 0.22787193953990936, -0.4507853090763092, -0.2292773276567459, 0.22796480357646942, -0.5429493188858032, -0.29128479957580566, 0.37029096484184265, -0.41336968541145325, 0.07000993192195892, 0.2922993302345276, -0.9275299310684204, -0.14604905247688293, 1.0975120067596436, 0.5093744397163391, 0.794055700302124, -0.26352035999298096, -0.09193993359804153, 1.1412478685379028, -1.266793966293335, 0.09767399728298187, 0.8523549437522888, 0.5924587249755859, 0.41088926792144775, -0.3525218665599823, -0.0626700296998024, 0.23335042595863342, -0.19482865929603577, -0.412077397108078, -0.5452157855033875, -0.48557308316230774, -0.4467017352581024, 2.2314987182617188, -0.5330101847648621, -0.0990571454167366, 0.2796373963356018, 0.10812560468912125, 1.339673399925232, 0.04131276160478592, -1.176894187927246, -0.19462554156780243, 0.13991543650627136, 0.5874303579330444, 1.0204232931137085, -0.1675175279378891, 0.175515815615654, -0.5834687948226929, -0.37280094623565674, 0.5031944513320923, 0.11877807974815369, 0.44549891352653503, -0.42448312044143677, -0.5837463736534119, 0.39881300926208496, 0.05380837991833687, 1.034472942352295, 0.03001539036631584, 0.8151458501815796, 0.8362621665000916, -0.0027176998555660248, -0.4474466145038605, 0.25701913237571716, -0.4108662009239197, -0.02307758294045925, -0.8287554979324341, 0.1526980698108673, 0.38667264580726624, 0.9045223593711853, 0.055123571306467056, 0.3435206413269043, -1.0641131401062012, -0.1753922551870346, 1.0415711402893066, 0.09463527053594589, 0.6920392513275146, -0.9369404315948486, 0.2678012251853943, -0.23542098701000214, 0.22814778983592987, 0.06606511026620865, 0.048899292945861816, -0.0965307205915451, -0.18259067833423615, -0.7249925136566162, -0.3681263327598572, 0.041613783687353134, -0.7524680495262146, 0.6005382537841797, -0.13564547896385193, 0.26650547981262207, 0.39981892704963684, 0.20824414491653442, 0.9996260404586792, 0.4724274277687073, 0.39228352904319763, 0.32730698585510254, 0.6430655121803284, -1.4174607992172241, -0.3235933184623718, -1.2539045810699463, 1.142760992050171, -0.4214671850204468, 0.34560564160346985, -0.5875535011291504, -1.1042590141296387, -0.888863742351532, -0.9329925179481506, -0.14946958422660828, -0.4882640838623047, 0.6167248487472534, 1.4405877590179443, 0.5114297270774841, -0.9696129560470581, 0.7323449850082397, -0.6431992650032043, 0.1661897599697113, 0.09841801971197128, -0.047949668020009995, 0.3554844856262207, -0.1491512954235077, -0.9847137331962585, 0.1540652960538864, 0.32392045855522156, -0.9468500018119812, -0.4290825128555298, -0.45314696431159973, -1.544275164604187, -0.11146730929613113, 0.2557206451892853, 0.12804538011550903, 1.6266077756881714, -0.22143815457820892, -0.9744061827659607, 0.890998899936676, -0.34136199951171875, 0.011506117880344391, 0.07329069077968597, -0.13330164551734924, -0.42445266246795654, -0.39020344614982605, 0.14300355315208435, 0.36032700538635254, 0.529441237449646, -0.49487435817718506, 0.17452138662338257, 0.5155705809593201, 0.14975425601005554, -0.32048264145851135, -0.17708048224449158, 0.9483399987220764, -0.2935854494571686, 0.08693218231201172, -0.056052252650260925, 0.6447498798370361, -0.03703324869275093, 0.11675229668617249, -0.17255479097366333, -0.7422929406166077, 0.5781201720237732, 0.25348037481307983, 1.4901072978973389, -1.2827788591384888, -0.9116405844688416, -0.23710349202156067, -0.18965324759483337, 0.23008127510547638, -0.5476111769676208, 0.3189243972301483, -0.6673725247383118, 0.7179241180419922, -0.5121520161628723, -1.0772061347961426, 0.0006582581554539502, 0.006560200359672308, -0.859704852104187, -0.26411524415016174, 0.04801138862967491, 1.108852505683899, -0.9967451691627502, -0.20110437273979187, -0.0802614688873291, 0.09156721085309982, -1.2402294874191284, 1.1665027141571045, -0.5004928112030029, -0.25423645973205566, -0.11030611395835876, -0.012743382714688778, -0.18882063031196594, -0.4204034209251404, 0.0901232436299324, 0.15686169266700745, -0.5155470967292786, 0.513668417930603, -0.43209773302078247, 1.3740665912628174, -0.849116861820221, 0.1087619736790657, 0.2475632131099701, -0.09900332987308502, -0.07242231070995331, 0.44220438599586487, -0.2755604684352875, 0.00729612959548831, 0.16539201140403748, 0.7890722751617432, -0.37141281366348267, -0.21480058133602142, 0.8750446438789368, 0.9685183763504028, -0.4303494691848755, 0.7870832085609436, 0.3555617332458496, -0.4428980052471161, 0.4414604604244232, 0.6742081046104431, 0.826970636844635, 0.8157278895378113, 0.6174344420433044, -0.07633665949106216, 0.4078352451324463, -0.5619785785675049, -0.3439249098300934, 0.5450447797775269, 0.23442937433719635, 0.7372552752494812, 0.6326664686203003, -0.871176540851593, -0.6041253805160522, 0.17761418223381042, 0.47808748483657837, 1.8325693607330322, -0.09305526316165924, -0.16498252749443054, -0.9038649797439575, -0.49595776200294495, -0.18054501712322235, 0.5189256072044373, -0.3041928708553314, -0.25031420588493347, -0.7103458642959595, -0.696756899356842, 0.9624062776565552, 0.38569188117980957, 1.143169641494751, -1.0708205699920654, -0.9298139810562134, -0.39832261204719543, 0.42265209555625916, -0.6451550126075745, -0.8314099907875061, 0.6311663389205933, -0.6697473526000977, 0.013947802595794201, 0.4089318513870239, -0.5178688764572144, 0.39536476135253906, -0.35862746834754944, 1.101115345954895, 0.4405439496040344, -0.4940780997276306, 0.43882402777671814, 0.40497907996177673, -0.25619521737098694, -1.0931154489517212, 0.47843798995018005, 0.028363173827528954, -0.5783135890960693, 0.32556045055389404, 0.38813522458076477, 0.3469755947589874, -0.045039284974336624, -0.6595939993858337, 0.07211238890886307, 0.16432346403598785, 0.044861551374197006, 0.46386298537254333, -0.5981466770172119, -0.3093631863594055, -1.0115635395050049, 0.4387034773826599, -0.15845198929309845, -0.14373107254505157, 0.10194303840398788, -0.5601422786712646, 0.019504105672240257, 0.5759318470954895, -0.7545590996742249, -0.24767732620239258, -0.803472638130188, 0.5187419652938843, -0.09030568599700928, -0.4370162785053253, -0.0207634586840868, 0.5274083018302917, 0.07095319777727127, 0.5779011845588684, 0.6237941384315491, 0.4674420952796936, -0.05886312574148178, 0.5793525576591492, -0.5868292450904846, 0.5567160844802856, -0.39025893807411194, 0.11864382773637772, -0.23844413459300995, -0.5181484222412109, -0.29851385951042175, -0.35328707098960876, -0.3929482400417328, -0.20220541954040527, -0.26153191924095154, 0.13265439867973328, -0.6482150554656982, -0.7977599501609802, -0.018796933814883232, -1.3034427165985107, -0.6699317693710327, 0.24290119111537933, -0.5867267847061157, -0.27197957038879395, -0.6347630023956299, -0.9824621081352234, -0.388254851102829, -0.6280100345611572, -1.368353009223938, 0.4938224256038666, 0.03693566098809242, -0.4228646755218506, -0.4054802656173706, 0.0773918628692627, -0.4503319263458252, 1.0275733470916748, -0.5983859896659851, 0.7466592788696289, 0.027874330058693886, -0.3207445442676544, -0.0914178192615509, 0.2816274166107178, 0.5792778730392456, -0.5216555595397949, 0.770787239074707, -0.437240332365036, 0.3071618676185608, -0.16521847248077393, -0.791032612323761, 0.08616337925195694, -0.25770655274391174, 0.8231395483016968, -0.09583202749490738, -0.5090867877006531, 0.32612091302871704, 1.2742547988891602, -1.0459140539169312, 0.12982624769210815, 0.41873374581336975, 0.7845603227615356, -0.009548700414597988, -0.30722951889038086, 0.8553677797317505, 0.25747814774513245, -0.07891573756933212, 0.460351824760437, 0.284097820520401, -0.1412440687417984, -0.292239785194397, 0.9871654510498047, 1.0347144603729248, 0.34400880336761475, 0.5561555624008179, -1.441793441772461, 1.0642975568771362, -1.073538899421692, -0.4643156826496124, 0.12009014189243317, 0.9197252988815308, 0.8747150301933289, -0.40857166051864624, -0.47412899136543274, -0.09568240493535995, 0.5645936131477356, 0.4156791567802429, -0.4731062054634094, -1.273220419883728, 0.19313552975654602, 0.39737775921821594, 0.08659158647060394, 0.4678935110569, -0.4958900809288025, 0.31739768385887146, 14.69381332397461, 0.7837693095207214, -0.018724685534834862, 0.621327817440033, 0.6978223323822021, 0.23168198764324188, -0.697912335395813, 0.043236762285232544, -1.259839653968811, -0.24451978504657745, 1.3237154483795166, 0.20688007771968842, 0.6371399164199829, 0.6683482527732849, -0.2849295139312744, -0.09940849244594574, -0.4080643057823181, 0.0862388014793396, 0.503384530544281, -1.0767121315002441, 0.1279360055923462, -0.07236324995756149, 0.7687472105026245, 0.5734965801239014, 0.9128046035766602, 1.096779227256775, 0.6338506937026978, -0.43629974126815796, 0.7697428464889526, -0.16634072363376617, 1.244415044784546, -0.033737462013959885, 0.4217750132083893, 0.6604365110397339, -0.9964125156402588, -0.3807838261127472, -0.2241320013999939, -1.608916997909546, -0.08574468642473221, -0.043609898537397385, -0.6419863104820251, -1.0012093782424927, -0.3228079676628113, 0.7598593235015869, 0.14867129921913147, 0.15749847888946533, -0.4923771023750305, 0.6559873819351196, 0.07818044722080231, -0.11473822593688965, 0.3355661928653717, 0.9821879863739014, 0.06548931449651718, -0.02238520234823227, -0.09721481055021286, 0.09990832209587097, 0.32405176758766174, 0.5539065003395081, -0.44742026925086975, 0.09418150782585144, -0.4483119249343872, -0.24871841073036194, -0.42392435669898987, 0.9548154473304749, 0.3693036437034607, 0.19518224895000458, -0.8334733843803406, 0.15236800909042358, 0.5211319327354431, -0.1523231714963913, -0.5552343130111694, -0.10282457619905472, 0.36445629596710205, -0.049582164734601974, 0.017413543537259102, 0.1701403260231018, -0.44578680396080017, -0.715003252029419, -0.6644847393035889, -0.27201971411705017, 0.05968627333641052, -0.6540493369102478, -0.07593841850757599, 0.6971394419670105, -0.17953820526599884, -0.6783580780029297, 0.19517967104911804, -0.8893280029296875, -0.5877000093460083, 0.29751619696617126, -1.4135651588439941, -0.6455761790275574, 0.5066233277320862, -0.43422698974609375, -0.6097313165664673, 0.0279986634850502, 1.3382956981658936, -0.11970441788434982, -0.14518952369689941, -0.16291821002960205, 0.45063716173171997, 0.08321831375360489, -0.2493545114994049, -0.9995978474617004, 1.07210111618042, 0.46230262517929077, -0.35559001564979553, 0.6031416058540344, 0.13178646564483643, 0.008040940389037132, -0.5696859955787659, -0.15306583046913147, 0.7417322993278503, -1.2719892263412476, 0.08224886655807495, -0.7589387893676758, -0.8312523365020752, 0.3241979479789734, 0.762927770614624, 0.2924814224243164, 0.5020832419395447, -0.19602401554584503, -0.9241034984588623, 0.21154344081878662, -0.7600948810577393, 0.015937507152557373, 0.5875840187072754, -0.7405050992965698, -0.5061948299407959, -0.012403536587953568, 0.5514068603515625, -1.0839048624038696, -0.5870895981788635, -0.4883008301258087, 0.2704256772994995, -0.3628397285938263, 0.6732735633850098, -0.26578038930892944, 1.4889047145843506, 0.847563624382019, -0.039508718997240067, -0.5082889795303345, 0.24765782058238983, -1.0855449438095093, -0.272183895111084, 0.12600629031658173, 0.9855470061302185, -0.4410201609134674, -0.12695057690143585, 1.1241849660873413, 0.15299443900585175, -0.7433236837387085, -0.48389893770217896, -0.3253641426563263, 0.5314822793006897, -0.5966007709503174, 0.6027970910072327, -0.1272556185722351, 0.4480876326560974, -0.4426311254501343, 0.5957865118980408, 0.263264536857605, -0.3024492859840393, -0.40922024846076965, 0.4721323549747467, 0.23006635904312134, -0.4810526371002197, -0.4659634232521057, -0.19294992089271545, -1.0065932273864746, 0.2912319004535675, -1.3834744691848755, 0.47280353307724, -0.35979506373405457, -0.07343137264251709, 0.027139652520418167, -0.05722108483314514, 0.6943248510360718, 0.13828939199447632, -0.3264642059803009, -0.5815353989601135, -0.3477495610713959, -0.7247758507728577, 0.7491376399993896, 0.777165949344635, -0.29817745089530945, 0.20271648466587067, -0.11211823672056198, 0.19522026181221008, 0.29144152998924255, 0.4982151985168457, -0.42133864760398865, -0.37034544348716736, -1.2172210216522217, 0.3724357783794403, -0.3783006966114044, -0.2296741008758545, -0.8359323740005493, 0.20439517498016357, 0.5023394227027893, -0.604661762714386, 0.46777188777923584, -0.3570806086063385, -0.6352919340133667, -0.8208599090576172, 0.6791845560073853, -0.6970701217651367, 0.15585443377494812, 0.5781545042991638, -0.7108447551727295, -0.10499939322471619, 0.07744351029396057, -0.2994290292263031, -1.2394286394119263, -0.7403729557991028, 0.2978716790676117, -0.9316202402114868, 0.08567626774311066, 0.15611808001995087, 0.019381646066904068, -1.0941109657287598, 0.00399760203436017, -0.08096965402364731, 0.25963473320007324, 0.3819425404071808, 1.0765538215637207, -0.10975227504968643, -0.9785510301589966, 0.3761110007762909, 0.4546777904033661, 0.09910809248685837, -0.11017544567584991, 0.21295738220214844, 0.20304127037525177, -0.8667722940444946, 0.3096930682659149, 0.22547292709350586, 0.3218913674354553, -0.9946990013122559, 0.1866869330406189, 0.3156376779079437, -0.48217156529426575, -0.08886446803808212, 0.691607654094696, -0.6454959511756897, -1.1616615056991577, -0.1988600343465805, -1.5091084241867065, -0.4446702003479004, -0.9798616766929626, 0.7828659415245056, -0.0018657406326383352, -0.2532859742641449, -0.4541463553905487, -0.6117982864379883, 0.13470430672168732, -0.08006391674280167, -0.27944374084472656, 0.5572953224182129, 0.1926516890525818, -0.8693654537200928, 0.7524352073669434, 0.6338213086128235, -0.25101950764656067, -0.7992523908615112, -0.3835470378398895, -0.711185872554779, 0.114047572016716, 0.03926834091544151, -0.4239075183868408, -0.18472692370414734, 0.941615879535675, 0.013852613978087902, 0.3723514676094055, -0.17983491718769073, -0.30534371733665466, 0.06622462719678879, 0.6382220387458801, 0.46638044714927673, -0.3262837827205658, -0.3876008689403534, 1.5004756450653076, 0.8583781719207764, -0.9814863801002502, 0.31067755818367004, -0.15035821497440338, -0.6105241179466248, 0.9850936532020569, 0.7895596027374268, 0.01908184587955475, 0.7328190207481384, -0.05114232748746872, -0.16852743923664093, 0.610655665397644, -0.9781337380409241, 0.01578470692038536, 0.09242933988571167, 0.7336229085922241, 1.086277961730957, 0.5025759339332581, -0.04956876114010811, 0.9501934051513672, 0.3929681181907654, 0.16957345604896545, 1.189244270324707, 1.1198216676712036, -0.307474821805954, -0.1623649150133133, -0.16410981118679047, 0.824287474155426, -0.7438398599624634, -0.9161321520805359, 0.4715211093425751, 0.5131803154945374, 0.5963945388793945, 0.3043896555900574, 0.5028271675109863, 0.5791757702827454, 0.046931810677051544, 0.497016966342926, 0.35177987813949585, -1.04684579372406, -0.6325366497039795, -0.7536964416503906, -0.675971269607544, -0.11425521224737167, 0.048283375799655914, -0.48889926075935364, -1.031266689300537, -0.3607368469238281, 0.35650113224983215, -0.07542555779218674, 0.4309844672679901, 1.0615198612213135, 0.9488435387611389, 0.3255566954612732, -0.40895700454711914, -0.6402862071990967, -0.38557395339012146, -0.7819092869758606, 0.06100129336118698, -0.7094378471374512, -0.14732347428798676, -0.24371561408042908, -0.3840692639350891, 0.02341374009847641]}, "authors": [{"authorId": "3361236", "name": "Baptiste Rozi\u00e8re"}, {"authorId": "2401865", "name": "Jonas Gehring"}, {"authorId": "2233293602", "name": "Fabian Gloeckle"}, {"authorId": "31460313", "name": "Sten Sootla"}, {"authorId": "2064713742", "name": "Itai Gat"}, {"authorId": "46879944", "name": "Xiaoqing Tan"}, {"authorId": "2727584", "name": "Yossi Adi"}, {"authorId": "2301500865", "name": "Jingyu Liu"}, {"authorId": "2211633", "name": "Tal Remez"}, {"authorId": "2756187", "name": "J. Rapin"}, {"authorId": "2233293962", "name": "Artyom Kozhevnikov"}, {"authorId": "22229139", "name": "I. Evtimov"}, {"authorId": "1749686057", "name": "Joanna Bitton"}, {"authorId": "50420713", "name": "Manish P Bhatt"}, {"authorId": "66286536", "name": "Cristian Cant\u00f3n Ferrer"}, {"authorId": "2233294011", "name": "Aaron Grattafiori"}, {"authorId": "22253126", "name": "Wenhan Xiong"}, {"authorId": "2233294119", "name": "Alexandre D'efossez"}, {"authorId": "1805998294", "name": "Jade Copet"}, {"authorId": "34672074", "name": "F. Azhar"}, {"authorId": "2113243762", "name": "Hugo Touvron"}, {"authorId": "143792623", "name": "Louis Martin"}, {"authorId": "1746841", "name": "Nicolas Usunier"}, {"authorId": "2073456043", "name": "Thomas Scialom"}, {"authorId": "2282478", "name": "Gabriel Synnaeve"}], "references": [{"paperId": "139a0c7a60667979dcb57eae677f75ff3f0b0196", "title": "LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "a669ea57529f4db630043c8c75d8f840c485d24d", "title": "RLTF: Reinforcement Learning from Unit Test Feedback"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "c12db2c60e8989f646a29ad4f4d24475e860ad91", "title": "LongNet: Scaling Transformers to 1, 000, 000, 000 Tokens"}, {"paperId": "f9acfdf58ccc27ac7d4b815ef8a2b9e03c5b215a", "title": "MultiPL-E: A Scalable and Polyglot Approach to Benchmarking Neural Code Generation"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "2a09ebbfcca1a6994eeb472cd4159f5f3858dbf9", "title": "LongCoder: A Long-Range Pre-trained Language Model for Code Completion"}, {"paperId": "2922768fd451ecdb45f48c1a83eb57f54a91221b", "title": "Textbooks Are All You Need"}, {"paperId": "7a1e71cb1310c4a873e7a4e54d1a6dab0553adce", "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"}, {"paperId": "6f6e2e0311589a9af045f6acd00b7dee6d19fce4", "title": "The Impact of Positional Encoding on Length Generalization in Transformers"}, {"paperId": "412e266cddfd87c79087a88ba1e4d11b89a45a13", "title": "MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers"}, {"paperId": "3e4085e5869f1b7959707a1e1d7d273b6057eb4e", "title": "StarCoder: may the source be with you!"}, {"paperId": "886e0962479ec6dac563666399ca4c96a468fcaa", "title": "CodeGen2: Lessons for Training LLMs on Programming and Natural Languages"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "fbdd496c421e050a47c4fb2e0019635d2f4b97e7", "title": "Meet in the Middle: A New Pre-training Paradigm"}, {"paperId": "407b9e9478ba6bff43ce4b20e8b6cb2b303477d2", "title": "Planning with Large Language Models for Code Generation"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "1bf21dabbdfc81fd4f9e92b1201ecce744cabb6a", "title": "SantaCoder: don't reach for the stars!"}, {"paperId": "9575afb5702bc33d7df14c48feeee5901ea00369", "title": "A Length-Extrapolatable Transformer"}, {"paperId": "bae76e1d13abe54f66dc140be53538b864578ba8", "title": "A Survey on Pretrained Language Models for Neural Code Intelligence"}, {"paperId": "6f4cc536f9ed83d0dbf7e919dc609be12aa0848a", "title": "Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "2a0456b0408cd4c33f2ff4400374e7be2497a362", "title": "Repairing Bugs in Python Assignments Using Large Language Models"}, {"paperId": "780f7eebde16b1ae5843df3a79a7772899ef6a71", "title": "MultiPL-E: A Scalable and Extensible Approach to Benchmarking Neural Code Generation"}, {"paperId": "ec4c8d99eb1c028c43af6d8bbf727392d351cb59", "title": "Efficient Training of Language Models to Fill in the Middle"}, {"paperId": "876eb375cb7b365475040046df669c039ad54202", "title": "CodeT: Code Generation with Generated Tests"}, {"paperId": "6d994b4f5a46cd14e8f09f1e9e49120546b15e31", "title": "CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning"}, {"paperId": "593edb7f66bf6ec3eef943691c18aec9f976bc51", "title": "Code Translation with Compiler Representations"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "6a684417089eb6f07ccb1ac5391c63ebacef821d", "title": "Can OpenAI's Codex Fix Bugs?: An evaluation on QuixBugs"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "5288b9f3a9f575543f44c39e1d3b78b3ca4c99da", "title": "InCoder: A Generative Model for Code Infilling and Synthesis"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "a2fc77f075f666b462d9350e7576f0ba9845c61b", "title": "Transformer Language Models without Positional Encodings Still Learn Positional Information"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "38115e80d805fb0fb8f090dc88ced4b24be07878", "title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis"}, {"paperId": "382ba0c4452aab6ecdaf8a62d567bb3c4684e4f0", "title": "ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "5cbe278b65a81602a864184bbca37de91448a5f5", "title": "Competition-level code generation with AlphaCode"}, {"paperId": "c783e1fb3ce8514f981925ee590c00884660ee4e", "title": "CM3: A Causal Masked Multimodal Model of the Internet"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea", "title": "Training Verifiers to Solve Math Word Problems"}, {"paperId": "1aed58bd07026492194672adec494dc37c894a28", "title": "Leveraging Automated Unit Tests for Unsupervised Code Translation"}, {"paperId": "77d956cdab4508d569ae5741549b78e715fd0749", "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "a30f912f8c5e2a2bfb06351d4578e1ba3fa37896", "title": "CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "a38e0f993e4805ba8a9beae4c275c91ffcec01df", "title": "Program Synthesis with Large Language Models"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "a989f5daa7c438d6b8433efbb1461f1b0af1aa8e", "title": "Break-It-Fix-It: Unsupervised Learning for Program Repair"}, {"paperId": "1ccd031f28dccfb226f6c0c588c93a97a50bf95f", "title": "Measuring Coding Challenge Competence With APPS"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "7e5008713c404445dd8786753526f1a45b93de12", "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow"}, {"paperId": "0646bb09db4d1ba24150e69b71edcd4aff691b3c", "title": "Unified Pre-training for Program Understanding and Generation"}, {"paperId": "3a1efac4a8aa2f40a8128e034c01f18660652dd5", "title": "DOBF: A Deobfuscation Pre-Training Objective for Programming Languages"}, {"paperId": "69a72ff5b30642d11c96635e99aadad3140d33a7", "title": "CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation"}, {"paperId": "ce3b364b7e6358940ce97d8d5887a65e5024ca21", "title": "BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation"}, {"paperId": "4083958684292f6fa2f5c7fd4f9be975e80145b6", "title": "GraphCodeBERT: Pre-training Code Representations with Data Flow"}, {"paperId": "dc3877e3058bc9c854e57770e596acf188d9b57e", "title": "Unit Test Case Generation with Transformers"}, {"paperId": "021bbcefc993c389bad6c1daefd8ff92d0fc2441", "title": "Contrastive Code Representation Learning"}, {"paperId": "df56748cd4f52a58973b4ac52c0bf9156c5f52f0", "title": "Unsupervised Translation of Programming Languages"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "0fe2636446cd686830da3d971b31a004d6094b3c", "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages"}, {"paperId": "78f4de568564b6b5bb9058779ead6b3be8548e53", "title": "Learning to Fix Build Errors with Graph2Diff Neural Networks"}, {"paperId": "37a23c43ddf09ea97b82b38e2827a2229cfae545", "title": "Novel positional encodings to enable tree-based transformers"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "8ace1951c95f9bbbcf83571ff6c0579521507e2e", "title": "The adverse effects of code duplication in machine learning models of code"}, {"paperId": "7365f887c938ca21a6adbef08b5a520ebbd4638f", "title": "Model Cards for Model Reporting"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "bcdc102c04fb0e7d4652e8bcc7edd2983bb9576d", "title": "VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": null, "title": "Falcon-40B: An open large language model with state-of-the-art performance, 2023"}, {"paperId": "ac9d5e5cd77a4f36d9bfd4ee9d4c8089f89990a0", "title": "Impossible Distillation: from Low-Quality Model to High-Quality Dataset & Model for Summarization and Paraphrasing"}, {"paperId": "2a405483796dfedf5d95483aa8880c57626e0e9f", "title": "Integrating Tree Path in Transformer for Code Representation"}, {"paperId": null, "title": "CodeXGLUE docstring generation. Smoothed 4-gram BLEU on the docstring generation infilling benchmark from Fried et al"}, {"paperId": null, "title": "Model card Table 26 presents a model card (Mitchell et al., 2019) for the family of models we release"}, {"paperId": null, "title": "OpenAI FIM90 7B and code-davinci-002, and sampling at temperature 0.2 for InCoder 6B. the original docstrings from the dataset using smoothed 4-gram BLEU Papineni et al"}, {"paperId": null, "title": "Introducing MPT-7B: A New Standard for Open-Source, Commercially Usable LLMs"}, {"paperId": null, "title": "and extensible"}, {"paperId": null, "title": "Acknowledgements We would like to express our gratitude to all the people who helped us carry out this project: \u2022 Participants in the red teaming exercises: Vitor Albiero, Yiannis Douratsos"}, {"paperId": null, "title": "Key Access Control: To ensure that the decryption keys are only accessible to authorized personnel, access control mechanisms need to be put in place"}, {"paperId": null, "title": "All the members of the original Llama team, who did not contribute to Code Llama but provided foundations for this work"}, {"paperId": null, "title": "Other contributors (red teaming, infrastructure, program management, writing): Faisal Azhar"}, {"paperId": null, "title": "Key Recovery: To ensure that the decryption keys can be recovered in case of a disaster or data loss, a key recovery mechanism should be implemented"}, {"paperId": null, "title": "Introducing 100K Context Windows"}]}