{"paperId": "25425e299101b13ec2872417a14f961f4f8aa18e", "title": "VIMA: General Robot Manipulation with Multimodal Prompts", "abstract": "Prompt-based learning has emerged as a successful paradigm in natural language processing, where a single general-purpose language model can be instructed to perform any task specified by input prompts. Yet task specification in robotics comes in various forms, such as imitating one-shot demonstrations, following language instructions, and reaching visual goals. They are often considered different tasks and tackled by specialized models. We show that a wide spectrum of robot manipulation tasks can be expressed with multimodal prompts, interleaving textual and visual tokens. Accordingly, we develop a new simulation benchmark that consists of thousands of procedurally-generated tabletop tasks with multimodal prompts, 600K+ expert trajectories for imitation learning, and a four-level evaluation protocol for systematic generalization. We design a transformer-based robot agent, VIMA, that processes these prompts and outputs motor actions autoregressively. VIMA features a recipe that achieves strong model scalability and data efficiency. It outperforms alternative designs in the hardest zero-shot generalization setting by up to $2.9\\times$ task success rate given the same training data. With $10\\times$ less training data, VIMA still performs $2.7\\times$ better than the best competing variant. Code and video demos are available at https://vimalabs.github.io/", "venue": "arXiv.org", "year": 2022, "citationCount": 212, "influentialCitationCount": 27, "openAccessPdf": {"url": "http://arxiv.org/pdf/2210.03094", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "It is shown that a wide spectrum of robot manipulation tasks can be expressed with multimodal prompts, interleaving textual and visual tokens, and designed a transformer-based robot agent, VIMA, that processes these prompts and outputs motor actions autoregressively."}, "embedding": {"model": "specter_v2", "vector": [0.22507865726947784, 0.31536775827407837, -0.34621185064315796, 0.17863266170024872, -0.4180460274219513, -0.4295341372489929, 0.8057454824447632, -0.3100798726081848, -0.5072284936904907, -0.2991674840450287, 0.0756775289773941, -0.16972176730632782, -0.2645987570285797, 0.3389846980571747, -0.7251324653625488, -0.06794906407594681, -0.8927103877067566, 0.3815324604511261, 0.0026125041767954826, -0.5940375328063965, 0.1711926907300949, -0.6517159342765808, -0.9118620753288269, 0.04653242230415344, 0.43844863772392273, 0.05202191695570946, 0.5086100101470947, 0.9584587216377258, 0.17713795602321625, 0.7338228225708008, 0.495380163192749, 0.33021315932273865, 0.292263388633728, 0.28137537837028503, -0.6352433562278748, -0.19510461390018463, -0.02642020396888256, -0.8482332825660706, -0.7549161314964294, 0.4173584282398224, -0.25311827659606934, 0.3581036925315857, 0.7492387890815735, -0.747223973274231, -0.18573155999183655, 0.5081273913383484, 0.5827282667160034, 0.3379184305667877, 0.5650894641876221, 0.04223306477069855, 0.8384246826171875, -0.9828743934631348, 0.5037978291511536, 1.356960654258728, -0.01635606586933136, 0.766633927822113, 0.2053530365228653, -0.3949447572231293, 0.7102304100990295, -0.35642707347869873, -0.34679079055786133, 0.03203853219747543, -0.23823682963848114, -0.2598092257976532, 1.1176173686981201, -0.4587264955043793, -0.16107456386089325, 1.358784556388855, 0.38707953691482544, 1.4446933269500732, -0.027265800163149834, -0.6732403039932251, 0.05849470943212509, -0.0054765972308814526, 0.2659544348716736, 0.9329624176025391, -0.410049170255661, 1.0375851392745972, -0.9112216234207153, 0.12666603922843933, 1.0789607763290405, 0.06544862687587738, -0.2020094245672226, -0.6004547476768494, -0.6976454257965088, 0.5629439949989319, 0.2817264497280121, 0.5373822450637817, -0.3681877553462982, 0.7469150424003601, 0.5038268566131592, 0.6949799060821533, -0.5800497531890869, 0.49412986636161804, 0.14892332255840302, 0.04322834685444832, 0.05048342049121857, 0.6102368831634521, 0.10309255868196487, 1.2481940984725952, -0.20408375561237335, 0.24381603300571442, -0.9814388751983643, 0.04644837602972984, 1.3832638263702393, 0.1838693618774414, 0.6015163064002991, -1.0638128519058228, 0.37521103024482727, -0.6693943738937378, 0.9668572545051575, -0.437738299369812, -0.42015019059181213, 0.3506253957748413, -0.054496731609106064, -0.5789670348167419, -0.12667953968048096, -0.1258639246225357, -1.1067020893096924, 0.5611151456832886, -0.238856241106987, -0.23889482021331787, 0.311397522687912, 0.6969773769378662, 0.6704566478729248, 0.6280459761619568, 0.462931752204895, 0.3604084849357605, 0.5431148409843445, -0.5209649801254272, -0.702128529548645, -0.9668156504631042, 0.751457154750824, 0.3286835253238678, 0.5013800859451294, -0.08652613312005997, -1.024059772491455, -0.8988977074623108, -1.0073578357696533, 0.10456380248069763, -0.5136758089065552, 0.596520185470581, 1.3284131288528442, 0.1285661906003952, -0.6611900329589844, 0.73109370470047, -0.46532386541366577, -0.2299749255180359, 0.059280894696712494, 0.42365771532058716, -0.16741587221622467, -0.6023098826408386, -0.6817888021469116, 0.651326596736908, 0.5433609485626221, -0.45245885848999023, -1.0305403470993042, -0.27698564529418945, -1.6394972801208496, -0.6520317196846008, 0.7723871469497681, -0.32172802090644836, 1.7238825559616089, 0.25252223014831543, -1.5624912977218628, 0.49131157994270325, -0.20224542915821075, 0.43195679783821106, 0.4415261745452881, -0.3843539357185364, -0.22430671751499176, -0.15490931272506714, 0.036716390401124954, 0.9411460757255554, 0.2837125062942505, -0.9757170677185059, -0.18409346044063568, 0.4429030120372772, 0.39011117815971375, -0.2013748735189438, 0.33328136801719666, 0.7070986032485962, 0.056528061628341675, -0.0711226835846901, 0.021393470466136932, 0.4040547311306, -0.19867907464504242, -0.1798478215932846, -0.5713697671890259, -1.0831226110458374, 0.8639091849327087, 0.17322231829166412, 0.3500169813632965, -0.9957951903343201, -0.35819125175476074, -0.30506524443626404, -0.24651533365249634, -0.2555076777935028, -1.1856180429458618, 0.7157114148139954, -0.4907039999961853, 0.30785077810287476, -0.3601038455963135, -0.8258726596832275, 0.19911839067935944, 0.09057047963142395, -0.48997700214385986, -0.25288692116737366, 0.1582915484905243, 1.4524340629577637, -1.3478503227233887, 0.18354587256908417, 0.5454145073890686, -0.1824471801519394, -0.7273668050765991, 1.6745202541351318, -0.5799852013587952, 0.7739661335945129, -0.2690321207046509, -0.431540310382843, -0.38943248987197876, -0.021717270836234093, 0.3268719017505646, -0.2708522081375122, 0.05839493125677109, 0.3865182101726532, -0.43889492750167847, 1.9506827592849731, -0.35969945788383484, 0.15826039016246796, -0.14201828837394714, -0.5383787751197815, 0.1905759572982788, 0.7076084613800049, -0.22416187822818756, -0.35171061754226685, 0.3895640969276428, 0.4072331190109253, -0.38533681631088257, -0.7998011112213135, 0.39836934208869934, 0.8943484425544739, -0.49420055747032166, 0.1481262594461441, 0.42197051644325256, -0.5736930966377258, 0.42436450719833374, 0.6974121332168579, 0.846210777759552, 0.8889968991279602, 0.3862914741039276, 0.12004952877759933, -0.27530109882354736, -0.5348492860794067, -0.6776241660118103, 0.8590176105499268, 0.9103484153747559, 0.751671552658081, -0.03727404400706291, -0.934908390045166, -0.12807436287403107, -0.4760220944881439, 1.1388967037200928, 1.2699666023254395, 0.3607660233974457, 0.03201565146446228, -0.5946990251541138, -0.37113529443740845, -0.60590660572052, 0.42715010046958923, -0.7270101308822632, -0.387650728225708, -0.7770953178405762, -0.38988375663757324, 0.36181557178497314, 0.35548174381256104, 1.160590648651123, -1.1022473573684692, -0.8003632426261902, -0.254609078168869, 0.29144853353500366, -0.7086578607559204, -0.4633401334285736, 0.3977917730808258, -0.31482139229774475, -0.5676781535148621, -0.22162921726703644, -0.4464799165725708, 0.33144816756248474, -0.21418504416942596, 0.6479301452636719, -0.4155614972114563, -0.32237860560417175, 0.936537504196167, 0.2780176103115082, -0.4550029933452606, -0.8647616505622864, 0.06058197095990181, -0.03903176635503769, -0.5781282782554626, -0.34978652000427246, 0.45859235525131226, 0.22499674558639526, -0.01950005628168583, -0.628350555896759, 0.14992699027061462, 0.24760788679122925, 0.07519117742776871, 0.057606421411037445, -0.9113035202026367, 0.23166655004024506, -0.638426661491394, 1.3709074258804321, 0.19884605705738068, -0.23306873440742493, 0.14803121984004974, -0.17202265560626984, -0.33764663338661194, 0.0899653509259224, -1.0843204259872437, -0.18619363009929657, -0.5893073081970215, 0.41459763050079346, -0.09113563597202301, -0.8885697722434998, 0.42414554953575134, 0.39843010902404785, 0.06442482024431229, 0.4567115604877472, 0.662466824054718, 0.5327848792076111, 0.05188773572444916, 0.7476028800010681, -0.8347378373146057, 0.48623964190483093, -0.11057313531637192, 0.4582512676715851, -0.21391578018665314, -0.2970283329486847, -0.5000029802322388, -0.23810811340808868, 0.027000822126865387, -0.3099566400051117, -0.5718975067138672, 0.13299809396266937, -0.23831720650196075, -1.4202061891555786, 0.05844534933567047, -1.2255473136901855, -1.0277347564697266, 0.09113486856222153, -0.2523283362388611, -0.9413261413574219, -0.7746561169624329, -0.9218501448631287, -0.7050095200538635, -0.0445510596036911, -1.1045541763305664, 0.508288562297821, 0.1090594157576561, -0.7478125095367432, -0.27792632579803467, 0.27911144495010376, -0.6452362537384033, 0.5526724457740784, -0.5798713564872742, 0.6134295463562012, 0.05236645042896271, -0.5021586418151855, -0.2250574827194214, 0.5129989981651306, -0.029861243441700935, 0.4506155252456665, 0.08854801952838898, -0.4411981701850891, 0.11052786558866501, -0.39047327637672424, -0.746262788772583, -0.3862103223800659, 0.15665268898010254, 0.4211520552635193, 0.08264752477407455, -0.6086245179176331, -0.22088971734046936, 1.1424951553344727, 0.21967871487140656, 0.2817719280719757, 0.20294706523418427, 0.9347735643386841, 0.4909394085407257, 0.38905149698257446, 0.3858276605606079, 0.5065335631370544, 0.6511303186416626, 0.5136194229125977, 0.22617851197719574, 0.22911685705184937, -0.5753304958343506, 0.8161191940307617, 0.46812987327575684, 0.1354970633983612, 0.09898951649665833, -0.902376651763916, 0.6474264860153198, -1.1167356967926025, -0.4917984902858734, 0.847923994064331, 0.8187691569328308, 0.2569064795970917, -0.5439260005950928, -0.1391129493713379, -0.21487948298454285, 0.31821408867836, 0.11056429147720337, -0.0670686736702919, -0.38352832198143005, 0.5190280675888062, 0.07849951833486557, -0.43465450406074524, 1.0547693967819214, -0.42099300026893616, 0.5829455256462097, 14.728108406066895, 0.6689907312393188, -0.10575015097856522, 0.2481061816215515, 0.1921999156475067, 0.527154803276062, -0.11426679790019989, -0.469928503036499, -0.6654345989227295, -0.3794742524623871, 0.9440841674804688, 0.34875285625457764, 0.7550477981567383, -0.012024382129311562, 0.3667558431625366, -0.19406244158744812, -0.9319292306900024, 0.715084433555603, 0.321757972240448, -0.8410178422927856, 0.4617029130458832, -0.2456805258989334, 0.01753733493387699, 0.3234792947769165, 0.9692201018333435, 0.9531917572021484, 0.6454841494560242, -0.7749117612838745, 0.6355335116386414, 0.07609912753105164, 1.0387831926345825, 0.045654091984033585, -0.029326409101486206, 0.9940325021743774, -0.844680666923523, -0.24156750738620758, 0.09251698106527328, -0.947268545627594, 0.41751351952552795, -0.8735826015472412, -0.358389288187027, -0.005763150751590729, -0.5370746850967407, 0.6690244078636169, 0.5734065175056458, 0.40329596400260925, -0.42594602704048157, 0.2998656928539276, -0.03027838096022606, -0.37536510825157166, 0.288467139005661, 0.435602068901062, 0.396223783493042, -0.22605527937412262, 0.00021124393970239908, 0.44652673602104187, 0.2607719600200653, 0.5920354723930359, -0.015553897246718407, -0.3099641501903534, -0.9687175750732422, -0.015803972259163857, -0.11423403024673462, 0.32887232303619385, 0.6081897020339966, 0.2629716396331787, 0.15213286876678467, 0.433350533246994, 0.6397651433944702, 0.4673009514808655, -0.3708809018135071, -0.10673792660236359, 0.05542440712451935, -0.6802463531494141, -0.3021763265132904, -0.02117023803293705, -0.12307500094175339, -0.2799621522426605, -0.5278213024139404, -0.5919196605682373, -0.30221277475357056, -0.9190444350242615, -0.48301857709884644, 0.7312654852867126, 0.18819525837898254, -0.8482504487037659, -0.017181208357214928, -0.905431866645813, -0.4099232852458954, -0.117048479616642, -0.9850581884384155, -0.8028534054756165, -0.07141206413507462, -0.17450539767742157, -0.09316036105155945, 0.45739784836769104, 1.2701882123947144, -0.10629890859127045, -0.13309714198112488, -0.17139381170272827, -0.3445832133293152, -0.21246272325515747, -0.27053937315940857, -0.7713436484336853, 0.503797173500061, -0.33538246154785156, -0.26907193660736084, 0.6122643351554871, 0.18813484907150269, -0.062060724943876266, -0.7436274290084839, 0.13635990023612976, -0.1360396295785904, -1.146941900253296, -0.5281732082366943, -0.6575644612312317, -0.840198278427124, 0.4625377357006073, 0.5956902503967285, -0.47876134514808655, -0.15133921802043915, -0.3084273338317871, -0.5133159756660461, 0.05071834474802017, -0.7901283502578735, 0.5519156455993652, 0.7130212187767029, -0.6073934435844421, -0.7339208126068115, 0.1338246613740921, 0.4812357425689697, -1.3835692405700684, -0.3009423315525055, -0.022032545879483223, 0.38308587670326233, 0.11631685495376587, 0.7582198977470398, -0.6831136345863342, 0.7568432092666626, 0.6920021772384644, 0.29537829756736755, -1.0363273620605469, 0.10794751346111298, -1.063010334968567, 0.2926848232746124, -0.01945408806204796, 0.6675791144371033, -0.5518700480461121, -0.145400732755661, 0.9235554933547974, 0.01440183911472559, -0.4149112403392792, -0.6737245321273804, -0.622221052646637, 0.2421388477087021, -0.5548992156982422, -0.03691361844539642, -0.38389796018600464, 0.3400283455848694, 0.059767644852399826, 0.05046816170215607, 0.6803622245788574, -0.43294423818588257, -0.8456565141677856, 0.7856848835945129, 0.3374212086200714, 0.1627994179725647, -0.3505938649177551, -0.0727495551109314, -2.042759895324707, -0.24867019057273865, -0.9690145254135132, 0.8330751061439514, -1.0524132251739502, -0.47350314259529114, 0.2981721758842468, 0.03415357321500778, 0.29186171293258667, 0.38828426599502563, -1.0273300409317017, -0.33129405975341797, -0.6206327080726624, -0.6143026351928711, 0.983681857585907, 1.1924563646316528, -0.9759740233421326, -0.18966057896614075, -0.1772518903017044, 0.13548077642917633, 0.106056347489357, 0.5434317588806152, -0.4562534987926483, -0.7903752326965332, -1.104973316192627, 0.05607648566365242, 0.2502512037754059, 0.4343739151954651, -1.1464182138442993, 0.6387690901756287, 0.35529544949531555, -0.5848782658576965, 0.16247569024562836, 0.5825746655464172, -1.10814368724823, -0.5034785866737366, 0.5389874577522278, -1.1575438976287842, 0.17635121941566467, 0.3430401384830475, -0.31488680839538574, 0.09585250914096832, 0.5069091320037842, -0.4461282193660736, -0.9431122541427612, -0.6191516518592834, 0.21804627776145935, -1.3165855407714844, -0.12118829786777496, 0.06272975355386734, 0.023429129272699356, -1.1163580417633057, -0.4998171925544739, -0.09571505337953568, 0.2930981516838074, -0.47735893726348877, 1.0286979675292969, 0.8722019791603088, -0.9900205135345459, 0.14053498208522797, -0.10404210537672043, -0.007128184195607901, 0.2502720355987549, 0.45929375290870667, 0.45705607533454895, 0.00902518816292286, 0.2596496641635895, 0.16719263792037964, 0.31082049012184143, -0.6310879588127136, 0.11937528848648071, 0.959017813205719, -0.22363682091236115, -0.24363107979297638, 0.5736182332038879, -0.10908009111881256, -1.3876935243606567, 0.31586888432502747, -1.0628553628921509, -0.6325043439865112, -0.9198240041732788, 0.41448482871055603, 0.02837303839623928, -0.6372179388999939, 0.16069622337818146, -0.17591486871242523, 0.8112221360206604, -0.43922632932662964, -0.6670327186584473, 0.07646726816892624, 0.09464432299137115, 0.22144953906536102, 0.7477505803108215, 0.3364644944667816, -0.8919157981872559, -0.8880290389060974, -0.12173575907945633, -0.46963146328926086, 0.27419066429138184, -0.5954630970954895, -0.812224805355072, -0.2327166497707367, 0.6963350176811218, 0.35036247968673706, 0.050125617533922195, -0.47105154395103455, 0.29874613881111145, -0.2734149396419525, 1.0876928567886353, 0.526599109172821, -0.10311988741159439, 0.2549978196620941, 1.316117525100708, 1.869541049003601, -1.2278286218643188, 0.034125085920095444, -0.6447861790657043, -0.6893839836120605, 0.7106824517250061, 0.700424313545227, -0.3848474621772766, 0.3981166481971741, -0.5158368945121765, 0.5435162782669067, -0.22902028262615204, -0.5784918665885925, -0.20159795880317688, 0.5486301779747009, 1.5666775703430176, 0.3535386323928833, 0.4446363151073456, 0.07870596647262573, 0.7024747729301453, 0.331794410943985, 0.45942890644073486, 0.6917166113853455, 0.95573490858078, -0.2720125913619995, 0.036293864250183105, 0.28651970624923706, 0.5745185613632202, -0.15066149830818176, -0.14623472094535828, 0.10758932679891586, 0.8953385949134827, -0.3130396604537964, 1.065773606300354, 0.23754887282848358, -0.16088785231113434, 0.7307817935943604, -0.19429220259189606, 0.8038312792778015, -0.8093347549438477, -0.1103028729557991, -0.40210843086242676, -0.6673570871353149, -0.45096448063850403, -0.21641570329666138, -0.5054807662963867, -0.7688557505607605, 0.39310482144355774, 0.41617774963378906, 0.010863288305699825, -0.017926540225744247, 1.5409148931503296, 0.4162496030330658, 0.2626708447933197, -0.35171985626220703, -1.1584478616714478, -0.48499229550361633, -1.1228545904159546, 0.4558121860027313, -0.5883936882019043, -0.13236816227436066, -1.0130233764648438, -0.19916576147079468, -0.4388044774532318]}, "authors": [{"authorId": "2171112793", "name": "Yunfan Jiang"}, {"authorId": "25445698", "name": "Agrim Gupta"}, {"authorId": "5630943", "name": "Zichen Zhang"}, {"authorId": "96374437", "name": "Guanzhi Wang"}, {"authorId": "1768148923", "name": "Yongqiang Dou"}, {"authorId": "2187067176", "name": "Yanjun Chen"}, {"authorId": "48004138", "name": "Li Fei-Fei"}, {"authorId": "47627049", "name": "Anima Anandkumar"}, {"authorId": "2117748", "name": "Yuke Zhu"}, {"authorId": "3275727", "name": "Linxi (Jim) Fan"}], "references": [{"paperId": "f197bf0fc2f228483f6af3285000d54d8d97f9eb", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models"}, {"paperId": "01706dd038b959e92a93f3141bb98be8f1f048f0", "title": "Hyper-Decision Transformer for Efficient Online Policy Adaptation"}, {"paperId": "7470a1702c8c86e6f28d32cfa315381150102f5b", "title": "Segment Anything"}, {"paperId": "326f6a8011e43322c433751b9cc31fd56564621c", "title": "Where are we in the search for an Artificial Visual Cortex for Embodied Intelligence?"}, {"paperId": "8a863344a241bc58436d1b1a3e5016529e289bab", "title": "When Learning Is Out of Reach, Reset: Generalization in Autonomous Visuomotor Reinforcement Learning"}, {"paperId": "2ebd5df74980a37370b0bcdf16deff958289c041", "title": "Foundation Models for Decision Making: Problems, Methods, and Opportunities"}, {"paperId": "38fe8f324d2162e63a967a9ac6648974fc4c66f3", "title": "PaLM-E: An Embodied Multimodal Language Model"}, {"paperId": "9976672fd95dd1b7579117a01957f5a0c46e9d01", "title": "Open-World Object Manipulation using Pre-trained Vision-Language Models"}, {"paperId": "e701e4c02a32da186d25b08373ada12d83b73b3d", "title": "Scaling Robot Learning with Semantically Imagined Experience"}, {"paperId": "60219c9da45ec42560ade9f4adf792776ecc763a", "title": "Orbit: A Unified Simulation Framework for Interactive Robot Learning Environments"}, {"paperId": "668ef8248bf0ecfaf36cc6a6c65a4f136b976858", "title": "On Pre-Training for Visuo-Motor Control: Revisiting a Learning-from-Scratch Baseline"}, {"paperId": "0703c5c7f737574d708babf48cdc876271415802", "title": "Masked Autoencoding for Scalable and Generalizable Decision Making"}, {"paperId": "95d90f6e0b2b8d2e44726b3389fd201f0df6199f", "title": "VIOLA: Imitation Learning for Vision-Based Manipulation with Object Proposal Priors"}, {"paperId": "9b5f4aab169fba588e214c010345232053f8ae76", "title": "From Play to Policy: Conditional Behavior Generation from Uncurated Robot Data"}, {"paperId": "979810ca765695a481c37126103b8ba256ee2192", "title": "Real-World Robot Learning with Masked Visual Pre-training"}, {"paperId": "3fbe2e8413df0207c26ff393c9aaa8488e3ca4c3", "title": "VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training"}, {"paperId": "60c8d0619481eaafdd1189af610d0e636271fed5", "title": "Perceiver-Actor: A Multi-Task Transformer for Robotic Manipulation"}, {"paperId": "02251886950770e82b3d68564d60cdfe15e73199", "title": "Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks"}, {"paperId": "97e6b89f8f256289b01b9f31799d957db81f2d4e", "title": "LATTE: LAnguage Trajectory TransformEr"}, {"paperId": "f3cf71c51b882fe3111d71c4bf104297d38197f8", "title": "Inner Monologue: Embodied Reasoning through Planning with Language Models"}, {"paperId": "cdf54c147434c83a4a380916b6c1279b0ca19fc2", "title": "LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action"}, {"paperId": "15cbccf71d1cd3f886ae9b0f3cc001d14577d264", "title": "Prompting Decision Transformer for Few-Shot Policy Generalization"}, {"paperId": "65fc1f1c567801fee3788974e753cdbf934f07e9", "title": "Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos"}, {"paperId": "01d4cc6e7c89f42ad1fc27b57439c9b6c2797fb8", "title": "Behavior Transformers: Cloning k modes with one stone"}, {"paperId": "8b5eab31e1c5689312fff3181a75bfbf5c13e51c", "title": "Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks"}, {"paperId": "32c9b3859086d15184989454eb878638659e64c6", "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge"}, {"paperId": "06761cb27e14aa55a6c3d98b949898aa26416698", "title": "A Unified Sequence Interface for Vision Tasks"}, {"paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a", "title": "Emergent Abilities of Large Language Models"}, {"paperId": "d7bca917b753b996074203cc77ba45935b7c62d7", "title": "ProcTHOR: Large-Scale Embodied AI Using Procedural Generation"}, {"paperId": "809822d59203a462bc9f2e0f0e9a8314d6d469d4", "title": "Revisiting the \u201cVideo\u201d in Video-Language Understanding"}, {"paperId": "055cd2faeebc7a9df43923d554a61ae924a4af6b", "title": "UViM: A Unified Modeling Approach for Vision with Learned Guiding Codes"}, {"paperId": "5922f437512158970c417f4413bface021df5f78", "title": "A Generalist Agent"}, {"paperId": "9dae204dad41633188022002a04c8aa67c79a4e1", "title": "Simple Open-Vocabulary Object Detection with Vision Transformers"}, {"paperId": "b60879dda0183160c9d0a611cb7e381e6942cf75", "title": "i-Code: An Integrative and Composable Multimodal Learning Framework"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "9f5120b815fddaaef25c7042035ffe5680507a65", "title": "Google Scanned Objects: A High-Quality Dataset of 3D Scanned Household Items"}, {"paperId": "c57293882b2561e1ba03017902df9fc2f289dea2", "title": "Hierarchical Text-Conditional Image Generation with CLIP Latents"}, {"paperId": "15190e8b459bd85d546286f7d7da61b4f4f3f58a", "title": "What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?"}, {"paperId": "cb5e3f085caefd1f3d5e08637ab55d39e61234fc", "title": "Do As I Can, Not As I Say: Grounding Language in Robotic Affordances"}, {"paperId": "ada81a4de88a6ce474df2e2446ad11fea480616e", "title": "Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language"}, {"paperId": "c9bdc9ad2c3cf3230ba9aac7b5783ab411f0d204", "title": "R3M: A Universal Visual Representation for Robot Manipulation"}, {"paperId": "e97bcb1695b586fdd7b76893bcd57d493f339ca6", "title": "MetaMorph: Learning Universal Controllers with Transformers"}, {"paperId": "523acd658742fb9c978e3f7638c09d7ce78af719", "title": "Masked Visual Pre-training for Motor Control"}, {"paperId": "7b3d26bd1d65ed5937c76043b5cd058260d8469f", "title": "The Unsurprising Effectiveness of Pre-Trained Vision Models for Control"}, {"paperId": "eb92a453cf982126fa2125d4c8915352a52af54d", "title": "Online Decision Transformer"}, {"paperId": "1bfa62ddfa3f6691e0e40c06f8ead594b6449cfa", "title": "OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"}, {"paperId": "b9b220b485d2add79118ffdc2aaa148b67fa53ef", "title": "Pre-Trained Language Models for Interactive Decision-Making"}, {"paperId": "266cc7ff4856b6a2ce9cc0a3e5f6c155ecc448a2", "title": "Can Wikipedia Help Offline Reinforcement Learning?"}, {"paperId": "92a8f7f09f3705cb5a6009a42220a6f01ea084e8", "title": "Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents"}, {"paperId": "400d619cbabeb669115bb7281a889ab869829ef5", "title": "MERLOT RESERVE: Neural Script Knowledge through Vision and Language and Sound"}, {"paperId": "4be02694125b71876552900a53c85c47a2a83614", "title": "CALVIN: A Benchmark for Language-Conditioned Policy Learning for Long-Horizon Robot Manipulation Tasks"}, {"paperId": "47126c012d174d2c66dc99472d8b8f4333248ac7", "title": "Less is More: Generating Grounded Navigation Instructions from Landmarks"}, {"paperId": "ba9d736006b897d06f75586ad46e28e00a5e566e", "title": "VIOLET : End-to-End Video-Language Transformers with Masked Visual-token Modeling"}, {"paperId": "21ec90872abd986c12afe39bebe807732ffa70c9", "title": "Florence: A New Foundation Model for Computer Vision"}, {"paperId": "826383e18568c9c37b5fc5dd7e2913352db22b47", "title": "Simple but Effective: CLIP Embeddings for Embodied AI"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "183984d0426fd0702fbbe8bd890fe32058ecdfff", "title": "A Differentiable Recipe for Learning Visual Non-Prehensile Planar Manipulation"}, {"paperId": "fd399c7068512858b27535f75c8c31d2442dbaac", "title": "Towards More Generalizable One-shot Visual Imitation Learning"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "69ee9b3a915951cc84b74599a3a2699a66d4004f", "title": "CLIPort: What and Where Pathways for Robotic Manipulation"}, {"paperId": "19b3b074d38b250d024920732ae51a8ffa0996dd", "title": "Pix2seq: A Language Modeling Framework for Object Detection"}, {"paperId": "ea29d6ddefa663eedf13fd01999adcca05fea2da", "title": "Multi-Task Learning with Sequence-Conditioned Transporter Networks"}, {"paperId": "12ce370b38cc69403e81980f33b413650900105c", "title": "Multi-Task Self-Training for Learning General Representations"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "d6e783bce3b8e3ad082c2757235c34cb86c4e653", "title": "Safe Learning in Robotics: From Learning-Based Control to Safe Reinforcement Learning"}, {"paperId": "aeae048c7d8d4ea03bb9cb1b75c65903c915909a", "title": "iGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday Household Tasks"}, {"paperId": "c0c9f77cb097f2ce53feb91802bcfbae57fcc42f", "title": "BEHAVIOR: Benchmark for Everyday Household Activities in Virtual, Interactive, and Ecological Environments"}, {"paperId": "3032844d6ac6882ccb03e7a2c22a0026b210ac05", "title": "What Matters in Learning from Offline Human Demonstrations for Robot Manipulation"}, {"paperId": "9933a5af7895354087baf6c96b64dc8a8973eaed", "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs"}, {"paperId": "4aa88c1406414cda3ce9cf76c8af0abaa8391760", "title": "Habitat 2.0: Training Home Assistants to Rearrange their Habitat"}, {"paperId": "01b5412f3d17e90e09226d7c40ad4d4468a1414d", "title": "Multimodal Few-Shot Learning with Frozen Language Models"}, {"paperId": "7ad1b82507b61c7113c4bde17fa3d89bb256cff3", "title": "SECANT: Self-Expert Cloning for Zero-Shot Generalization of Visual Policies"}, {"paperId": "d8d2e574965fe733eb1416e03df2b5c2914fc530", "title": "A Survey of Transformers"}, {"paperId": "90357a6dc817e2f7cec477a51156675fbf545cf1", "title": "MERLOT: Multimodal Neural Script Knowledge Models"}, {"paperId": "f864d4d2267abba15eb43db54f58286aef78292b", "title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem"}, {"paperId": "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500", "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling"}, {"paperId": "982f5f3e9c21f252018bb6fe27930e4e7bda74f8", "title": "AndroidEnv: A Reinforcement Learning Platform for Android"}, {"paperId": "aa262b568c6a4fd24b36fa37dc282bc0c9a46d2e", "title": "OCRTOC: A Cloud-Based Competition and Benchmark for Robotic Grasping and Manipulation"}, {"paperId": "6b45c8d03a20c5ae4fe5d6136cf01748b4bd7489", "title": "ManipulaTHOR: A Framework for Visual Object Manipulation"}, {"paperId": "6500df35e30461d857103b3e3fa72b2913049a56", "title": "Visual Room Rearrangement"}, {"paperId": "69625c4aa0ade91a4b8758e720fb27926835e25a", "title": "The ThreeDWorld Transport Challenge: A Visually Guided Task-and-Motion Planning Benchmark Towards Physically Realistic Embodied AI"}, {"paperId": "9c404d02aefd850ac3d5a8bdc5860738e6cd2b04", "title": "A Survey of Embodied AI: From Simulators to Research Tasks"}, {"paperId": "b3bf9fe13195e9aa70e1dac04e01fcff7008e812", "title": "Perceiver: General Perception with Iterative Attention"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "cb596bffc5c5042c254058b62317a57fa156fea4", "title": "Unifying Vision-and-Language Tasks via Text Generation"}, {"paperId": "3a906b77fa218adc171fecb28bb81c24c14dcc7b", "title": "Transformers in Vision: A Survey"}, {"paperId": "4c5d4601a3a19c31da6588d2a34adfb161f68c0e", "title": "Imitating Interactive Intelligence"}, {"paperId": "806725595f04849b3b4cc9f6c28d4a84744e8d95", "title": "iGibson 1.0: A Simulation Environment for Interactive Tasks in Large Realistic Scenes"}, {"paperId": "8d0eeb8aee3ce93c9c04f0662ee058e8eefee6bf", "title": "Transformers for One-Shot Visual Imitation"}, {"paperId": "b4caa67681cbe4973b21e96e69ad7b213b19f28f", "title": "Rearrangement: A Challenge for Embodied AI"}, {"paperId": "e0acae87ae6d1d14bb2852aad7d645fceee87eb2", "title": "The MAGICAL Benchmark for Robust Imitation"}, {"paperId": "431dc05ac25510de6264084434254cca877f9ab3", "title": "Recovery RL: Safe Reinforcement Learning With Learned Recovery Zones"}, {"paperId": "a334f9897a330abddf99cfec0b5a70f751e9497b", "title": "Conservative Safety Critics for Exploration"}, {"paperId": "3e6a384a13e9e679759c30ab2e0f22fb0bdf7da2", "title": "Transporter Networks: Rearranging the Visual World for Robotic Manipulation"}, {"paperId": "96055d058984b15a9b83024bb2e07292ee7559f5", "title": "Learning to be Safe: Deep RL with a Safety Critic"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "7ca4abace88db259faed67686ed7bba02b46eb82", "title": "Language-Conditioned Imitation Learning for Robot Manipulation Tasks"}, {"paperId": "2342b32e245989103dbc56d6f07f1400f4fd2e06", "title": "CausalWorld: A Robotic Manipulation Benchmark for Causal Structure and Transfer Learning"}, {"paperId": "cf34efc663284da131e747407ac3f389f898e471", "title": "robosuite: A Modular Simulation Framework and Benchmark for Robot Learning"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "1c39625ed65389cfb9d268f93f406455665f201b", "title": "Grounded Language Learning Fast and Slow"}, {"paperId": "932cd7efcaeb7ccd8e969fdb034dcc235f43b7d0", "title": "Self-Supervised Goal-Conditioned Pick and Place"}, {"paperId": "bfdb5ea61a002231dc69015c52add13ee32b56ba", "title": "Self-Supervised Learning for Precise Pick-and-Place Without Object Model"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "1301e9d11b728268ed1ff3f1a9adc155308d5250", "title": "Language Conditioned Imitation Learning Over Unstructured Data"}, {"paperId": "f441e637980a8b427474dbdc0141f38dd78bb831", "title": "Recent Advances in Robot Learning from Demonstration"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "bc51622358d8eea83248ef29402fe10640d07ba6", "title": "Big Transfer (BiT): General Visual Representation Learning"}, {"paperId": "b19729b27a1b4c24b52f87308c907653300afa7f", "title": "Dota 2 with Large Scale Deep Reinforcement Learning"}, {"paperId": "b40f74087b7e069327ca1d29fd20d7065647ee64", "title": "Grasping in the Wild: Learning 6DoF Closed-Loop Grasping From Low-Cost Demonstrations"}, {"paperId": "9915315f5cae822e98c94382ce3b0a6f9a7f8e5e", "title": "12-in-1: Multi-Task Vision and Language Representation Learning"}, {"paperId": "f4cf4246f3882aa6337e9c05d5675a3b8463a32e", "title": "ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "8c54e8575e7c17a4097838305915e6e7b00fd4af", "title": "Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning"}, {"paperId": "0bc855f84668b35cb65618d996d09f6e434d28c9", "title": "Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "a23d21bde1df79dacf9acf723e910771b0ae8f4c", "title": "SURREAL-System: Fully-Integrated Stack for Distributed Deep Reinforcement Learning"}, {"paperId": "a2fdfda785b3a2a0178d174daa515377c531f222", "title": "RLBench: The Robot Learning Benchmark & Learning Environment"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "470dbb7572323a192c5b630d4b51eb59469e9f02", "title": "Self-Supervised Correspondence in Visuomotor Policy Learning"}, {"paperId": "f3f3e2bfe52f2dda91fc68c806e396ab44a7ae8f", "title": "Graph-Structured Visual Imitation"}, {"paperId": "b4a35e548de27b6924e5f2ee41d37238a5c4a1d5", "title": "Habitat: A Platform for Embodied AI Research"}, {"paperId": "d9dcd1e99a91a9662b1f0edf248808ec5e9297ac", "title": "Mid-Level Visual Representations Improve Generalization and Sample Efficiency for Learning Visuomotor Policies"}, {"paperId": "050a89a91b3e828c841972a81f17807f82c79713", "title": "SURREAL: Open-Source Reinforcement Learning Framework and Robot Manipulation Benchmark"}, {"paperId": "776f3d2250285ac03b2019ecf18668fcdd72a9ce", "title": "One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL"}, {"paperId": "9784fbf77295860b2e412137b86356d70b25e3c0", "title": "The Natural Language Decathlon: Multitask Learning as Question Answering"}, {"paperId": "7139a5f730652abbeabf9e140009907d2c7da3e5", "title": "VirtualHome: Simulating Household Activities Via Programs"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "482c0cbfffa77154e3c879c497f50b605297d5bc", "title": "One-Shot Visual Imitation Learning via Meta-Learning"}, {"paperId": "298a55ddc9777e39c5bad92a750827e1cae98ac1", "title": "World of Bits: An Open-Domain Platform for Web-Based Agents"}, {"paperId": "019923afa86036b69c0e423f3c2188bfa7050923", "title": "Grounded Language Learning in a Simulated 3D World"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5c57bb5630835a05eb1c3d0df3e12d6180d75de2", "title": "One-Shot Imitation Learning"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "922197906907dc0a5e1b51fae40d3149333ecacf", "title": "UberNet: Training a Universal Convolutional Neural Network for Low-, Mid-, and High-Level Vision Using Diverse Datasets and Limited Memory"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "bc6dff14a130c57a91d5a21339c23471faf1d46f", "title": "Et al"}, {"paperId": "b0376726958ef70413906aeaad54bb2faf0caaea", "title": "Real-time tracking and pose estimation for industrial objects using geometric features"}, {"paperId": "be960b96d0db9324a66fbc5f3772e4d0bc61bfe8", "title": "Word learning in children: an examination of fast mapping."}, {"paperId": null, "title": "generalization, and understanding of multi-modality"}, {"paperId": "03dc0eefbe231ffa112d576509063936e17225b8", "title": "HighMMT: Towards Modality and Task Generalization for High-Modality Representation Learning"}, {"paperId": "69764fcc646e4c608ac08eeb4c784cf8465268d2", "title": "BEHAVIOR-1K: A Benchmark for Embodied AI with 1, 000 Everyday Activities and Realistic Simulation"}, {"paperId": "1fa589c76e14492dca7a544d58628c2a4dc55264", "title": "Instruction-Following Agents with Jointly Pre-Trained Vision-Language Models"}, {"paperId": null, "title": "Multiple simulation benchmarks are introduced to study the above tasks"}, {"paperId": null, "title": "2022) to encode past actions with a two-layer MLP. It has a hidden dimension of 256. We then map outputs to token dimension and obtain action tokens"}, {"paperId": "ecce44df1956db4ec486539c6543345344809958", "title": "Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"}, {"paperId": null, "title": "M\u00e4ter. Blender online libraries for textures, 2022"}, {"paperId": null, "title": "Scaling language modeling with pathways"}, {"paperId": "e75fb417b54a6eae589ff382874de09d7f58a3de", "title": "Open-Ended Learning Leads to Generally Capable Agents"}, {"paperId": "3e15417de901d4b060bf79754eea308ecd983354", "title": "A Review of Physics Simulators for Robotic Applications"}, {"paperId": "f5e121b9deee45cf1d78539c79297cda553f81d3", "title": "The Task Specification Problem"}, {"paperId": "dff59ec1f1d3c01c3c7046517aa7b0612655764c", "title": "Guiding Multi-Step Rearrangement Tasks with Natural Language Instructions"}, {"paperId": null, "title": "Computer Vision Foundation / IEEE"}, {"paperId": null, "title": "NVISII: Nvidia scene imaging interface, 2020"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "2019) to extract individual objects. Each object representation contains a bounding box and a cropped image. The bounding box is in the format"}, {"paperId": "d43991b2fc2921c4fff5dea8ecb60b32fc0e1512", "title": "Continuous Relaxation of Symbolic Planner for One-Shot Imitation Learning"}, {"paperId": null, "title": "Alphastar: Mastering the real-time strategy game starcraft ii"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "2021) for robotic manipulation. robotic manipulation tasks, such as constraint satisfaction (Bharadhwaj et al., 2021), one-shot imitation"}, {"paperId": null, "title": "2021) is a benchmark for causal structure and transfer learning in manipulation, requiring long-horizon planning and precise low-level motor control. However"}, {"paperId": null, "title": "There are many prior works that are not mentioned in the main paper that study different robotic manipulation tasks, such as instruction following"}, {"paperId": null, "title": "2021) is adopting the large-scale pre-training paradigm, powered by a collection of learning environments"}, {"paperId": null, "title": "2020) leverage a single backbone model with multiple independent heads for different tasks"}, {"paperId": "01bc5be2ca6e648e301b3086c175fb74a57d0132", "title": "A Sino-German \u03bb 6 cm polarization survey of the Galactic plane I . Survey strategy and results for the first survey region"}, {"paperId": null, "title": "2020) to study the effect of prompt encoding. We experiment with three T5 model capacities: t5-small (30M), t5-base (111M), to t5-large (368M). For all T5 variants"}, {"paperId": null, "title": "Extended Related Work In this section, we provide an extended review of related work as complementary to Section 6"}, {"paperId": null, "title": "Configurations for different sized models with causal self-attention prompt conditioning"}, {"paperId": null, "title": "Novel concept grounding"}, {"paperId": null, "title": "Maskvit"}, {"paperId": null, "title": "Pybullet, a python module for physics simulation for games, robotics and machine learning"}, {"paperId": null, "title": "Visual constraint satisfaction"}]}