{"paperId": "e06bfe725a3763500358d8f2c2f014810ea740ab", "title": "A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine", "abstract": "Since the release of ChatGPT and GPT-4, large language models (LLMs) and multimodal large language models (MLLMs) have garnered significant attention due to their powerful and general capabilities in understanding, reasoning, and generation, thereby offering new paradigms for the integration of artificial intelligence with medicine. This survey comprehensively overviews the development background and principles of LLMs and MLLMs, as well as explores their application scenarios, challenges, and future directions in medicine. Specifically, this survey begins by focusing on the paradigm shift, tracing the evolution from traditional models to LLMs and MLLMs, summarizing the model structures to provide detailed foundational knowledge. Subsequently, the survey details the entire process from constructing and evaluating to using LLMs and MLLMs with a clear logic. Following this, to emphasize the significant value of LLMs and MLLMs in healthcare, we survey and summarize 6 promising applications in healthcare. Finally, the survey discusses the challenges faced by medical LLMs and MLLMs and proposes a feasible approach and direction for the subsequent integration of artificial intelligence with medicine. Thus, this survey aims to provide researchers with a valuable and comprehensive reference guide from the perspectives of the background, principles, and clinical applications of LLMs and MLLMs.", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This survey comprehensively overviews the development background and principles of LLMs and MLLMs, as well as explores their application scenarios, challenges, and future directions in medicine and proposes a feasible approach and direction for the subsequent integration of artificial intelligence with medicine."}, "embedding": {"model": "specter_v2", "vector": [-0.12366142868995667, 0.6103823781013489, -0.552627682685852, 0.01331140473484993, -0.4564252495765686, -0.13551990687847137, 0.2517116069793701, 0.01499971840530634, -0.1741907000541687, 0.10452912747859955, 0.5119038224220276, -0.12381788343191147, 0.07587269693613052, 0.16783075034618378, 0.020629974082112312, -0.1733335554599762, -1.232616662979126, 0.6578993201255798, -0.5270776748657227, -0.022598590701818466, -0.7127052545547485, -0.5620828866958618, -0.6671392917633057, 0.23704415559768677, 0.5644350647926331, -0.06801600754261017, 0.11992891877889633, 1.092497706413269, -0.35901564359664917, 0.581611692905426, 0.5975717306137085, -0.4092194736003876, 0.07673362642526627, -0.29105105996131897, -0.03938090056180954, 0.11708424985408783, -0.015440898016095161, -0.7087748050689697, -0.5517897009849548, 0.54715895652771, -0.003222260857000947, 0.049386512488126755, 0.3206893503665924, -0.17150016129016876, -0.3229510486125946, 0.7941190600395203, 0.696266233921051, 0.3797174394130707, 0.17384643852710724, -0.45444852113723755, 0.9172429442405701, -0.9198783040046692, 0.5094278454780579, 1.7082574367523193, 0.2960658669471741, 0.4082109034061432, -0.1542213261127472, -0.5849619507789612, 0.03682446479797363, -0.704392671585083, -0.7793914675712585, -0.055167362093925476, -0.2225693017244339, -0.5635038614273071, 1.1948992013931274, -0.1267891675233841, 0.2761556804180145, 0.4689878821372986, 0.4561362564563751, 1.2128266096115112, 0.1420782059431076, -0.7947370409965515, -0.08908968418836594, 0.4774927496910095, 0.18962721526622772, 0.9752545356750488, -0.28455033898353577, 0.49040186405181885, -0.7076537013053894, -0.7760749459266663, 0.3932889699935913, -0.10873504728078842, -0.062001314014196396, -0.1436539739370346, -0.49076390266418457, 0.9145950078964233, -0.1350400298833847, 0.9918758869171143, -0.02120407111942768, 0.1507965624332428, 0.19763214886188507, 0.29955366253852844, -0.19761250913143158, -0.13031800091266632, -0.09441002458333969, 0.5208898186683655, -0.8134784698486328, 0.17683632671833038, -0.20605051517486572, 0.7958162426948547, -0.6621100306510925, 0.14616739749908447, -1.0134634971618652, 0.3718230128288269, 1.6945571899414062, -0.08739077299833298, 0.8734785318374634, -0.5294458866119385, 0.2552201449871063, -0.42226994037628174, 0.3620511591434479, -0.44593819975852966, -0.6439675688743591, -0.1902589648962021, -0.617570698261261, -1.3284131288528442, -0.4650346040725708, -0.019835013896226883, -0.745999813079834, 0.7777277231216431, -0.28947633504867554, -0.27612364292144775, 0.547965943813324, 0.3248322308063507, 0.7538039088249207, 0.4105162024497986, 0.5630456209182739, -0.3431216776371002, 1.1221307516098022, -0.5172744393348694, -0.6879726052284241, -0.7970958352088928, 0.9526841640472412, -0.04086366668343544, -0.057103175669908524, -0.38989001512527466, -0.9819517731666565, -0.555035412311554, -0.5319713950157166, 0.045307788997888565, -0.07967013865709305, 0.36070096492767334, 1.025080919265747, 0.48630520701408386, -1.1299855709075928, 0.19859232008457184, -0.21754102408885956, -0.5449974536895752, -0.2817773222923279, 0.15297316014766693, 0.2691771388053894, -0.21852517127990723, -1.40875244140625, 0.32305780053138733, 0.5357123613357544, -0.7868034243583679, -0.006020003464072943, 0.18606141209602356, -1.3182148933410645, -0.2316616326570511, -0.20776814222335815, -0.8359825611114502, 0.968558669090271, 0.1276157796382904, -1.0247710943222046, 0.9141680598258972, -0.22497683763504028, -0.016665806993842125, 0.4313705563545227, 0.4983218014240265, -0.8959313035011292, 0.05903157219290733, -0.3804285526275635, 0.6308339238166809, -0.0835164412856102, -0.20547296106815338, -0.07715766131877899, 0.16975072026252747, -0.36299991607666016, -0.2126462459564209, -0.040044452995061874, 1.2355905771255493, -0.29937049746513367, -0.4571034908294678, 0.397942453622818, 0.4189540147781372, -0.6561983227729797, 0.07439753413200378, -0.1392861008644104, -0.46587154269218445, 0.19393004477024078, -0.19433166086673737, 1.2135531902313232, -0.6880453824996948, -0.914005696773529, -0.2687998414039612, 0.04786814749240875, -0.22482113540172577, -0.6588437557220459, 0.5250972509384155, -0.3845416009426117, 0.44308483600616455, -0.5819814205169678, -0.7435206174850464, -0.23993758857250214, -0.03905463218688965, -0.2505159080028534, -0.16989535093307495, -0.23088431358337402, 1.0600074529647827, -0.7464935183525085, -0.13182587921619415, 0.17238998413085938, -0.008546640165150166, -0.4921211898326874, 1.021634578704834, -0.2287341207265854, 0.3872070610523224, -0.19082161784172058, -0.12568944692611694, 0.1369364708662033, -0.3559512794017792, 0.4235641360282898, 0.30411458015441895, -0.07682609558105469, -0.19247420132160187, -0.09528979659080505, 1.4810696840286255, 0.37867075204849243, 0.12675249576568604, -0.011974378488957882, -0.29995501041412354, -0.0600535087287426, 1.0568336248397827, 0.06267482042312622, -0.2142050564289093, 0.5030974745750427, -0.057328224182128906, -0.3027750849723816, -0.23308788239955902, -0.03567446395754814, 0.24921093881130219, -0.24873942136764526, 0.13426002860069275, 0.1880318969488144, -0.08819548040628433, 0.5752869248390198, 0.33639204502105713, 0.022248568013310432, -0.2566438317298889, 0.6926470398902893, 0.07102645933628082, 0.49396812915802, -0.9578863978385925, 0.19482344388961792, 0.7333149909973145, 0.3654382824897766, 0.6363434791564941, 0.21583415567874908, -0.6017214059829712, 0.4121617376804352, -0.006481877528131008, 0.2886650860309601, 0.8024633526802063, -0.5719583034515381, -0.3095363676548004, -0.6111411452293396, 0.019257495179772377, -0.23157855868339539, 0.21842706203460693, -0.24617668986320496, -0.09818357974290848, -0.3102239668369293, -1.3731467723846436, 1.029946208000183, 0.027853256091475487, 0.18597248196601868, -0.6235273480415344, -0.27687278389930725, -0.07086463272571564, 0.17798733711242676, -0.7020204067230225, -0.5516380071640015, -0.037049248814582825, -0.9619215130805969, -0.2059449851512909, -0.6397436857223511, -0.2770809233188629, 0.0426647923886776, -1.1175543069839478, 0.47614261507987976, -0.6964623332023621, -0.6030969619750977, 0.46579641103744507, 0.9042138457298279, -0.6852670907974243, -1.514026165008545, -0.8875084519386292, 0.009924822486937046, -0.2408495843410492, 0.10991104692220688, 0.8843591809272766, 0.19151939451694489, -0.34126198291778564, -0.37608692049980164, 0.16229958832263947, 0.4205312728881836, 0.24809379875659943, 0.4221029579639435, -0.33747580647468567, 0.04605059325695038, -0.8931285738945007, 1.338767647743225, 0.19114013016223907, -0.6226075291633606, 0.6219605803489685, -0.7342299818992615, -0.3044878840446472, 0.1668614149093628, -0.4206463396549225, -0.3157733976840973, -0.9729953408241272, 0.2699252963066101, 0.13741789758205414, -0.5082424283027649, 0.8785130977630615, 0.62408047914505, 0.25256800651550293, -0.08030925691127777, 0.7049912214279175, 0.5602033138275146, 0.15471585094928741, 0.2896113991737366, -0.0857037603855133, -0.016378246247768402, 0.6880733370780945, -0.15321505069732666, -0.021162983030080795, -0.5079859495162964, -0.8651043176651001, 0.12347661703824997, -0.1650419980287552, -0.06084522232413292, -0.2198675274848938, 0.2509717643260956, -0.7898105978965759, -0.40450987219810486, 0.1942521035671234, -0.6823764443397522, 0.1401643604040146, 0.4292543828487396, 0.39652881026268005, -0.06715144962072372, -0.4034444987773895, -1.4205832481384277, -0.7947427034378052, -0.7300079464912415, -1.1612299680709839, 0.37856847047805786, -0.291034460067749, -0.5024016499519348, -0.41810137033462524, 0.17930130660533905, -0.01435056235641241, 0.5232139825820923, -0.5117864012718201, 1.3965927362442017, -0.14708784222602844, 0.12353313714265823, -0.6623945236206055, 0.5547407269477844, 0.2053779661655426, 0.31035810708999634, 0.23249337077140808, -0.23409129679203033, 0.28055599331855774, 0.2071191817522049, -0.06812125444412231, -0.21230046451091766, 0.6610559821128845, 0.5329654216766357, 0.3234238028526306, -0.5066586136817932, -0.1848624050617218, 0.6227086782455444, 0.08128515630960464, -0.2623611390590668, -0.3997466564178467, 0.4345351457595825, 0.4115923047065735, -0.35299110412597656, 0.5752487778663635, 0.20355120301246643, 0.47406005859375, -0.33847659826278687, -0.2885754108428955, 0.1943788379430771, -0.14502468705177307, 0.44442927837371826, 1.2797433137893677, 0.34816890954971313, -0.060926999896764755, -1.007039189338684, 0.2195272147655487, -1.094464898109436, -0.5200964212417603, 0.5493546724319458, 0.8335703611373901, 0.47368496656417847, -0.17716534435749054, -0.18698234856128693, -0.3534700274467468, 0.5495262145996094, -0.030480680987238884, -0.06869707256555557, -0.6315845847129822, -0.3040277063846588, 0.21306127309799194, -0.3231353163719177, 0.5887336134910583, -0.36054402589797974, 0.24806539714336395, 15.555801391601562, 0.3986561894416809, -0.07411276549100876, 0.5870917439460754, 0.6688145399093628, 0.23187032341957092, -0.33335575461387634, -0.26686233282089233, -0.7064425945281982, 0.1516643911600113, 1.5150004625320435, 0.09999243170022964, 0.3195745050907135, 0.09875520318746567, 0.5230017900466919, -0.07036743313074112, -0.3287724256515503, 0.7350682616233826, 0.4574646055698395, -0.9711854457855225, 0.7598896622657776, 0.30085092782974243, 0.1652218997478485, 0.7152425646781921, 0.489413857460022, 0.5288141965866089, 0.10358481854200363, -0.4899226725101471, 0.2938753366470337, 0.28066498041152954, 0.6236668825149536, -0.11810815334320068, 0.6402125358581543, 0.8156920075416565, -0.6822213530540466, -0.2534875273704529, -0.37438973784446716, -0.7741900682449341, 0.23365181684494019, 0.16516311466693878, -0.7443093657493591, -0.37033167481422424, -0.5503620505332947, 0.26812857389450073, 0.28514644503593445, 0.5190838575363159, 0.011342471465468407, 0.5655617117881775, 0.05605355650186539, -0.007438838481903076, 0.10532228648662567, 0.007012628018856049, 0.43306100368499756, -0.027198584750294685, 0.15706950426101685, -0.012231516651809216, 0.22838546335697174, 0.334750771522522, -0.12932521104812622, 0.28640303015708923, -0.4381943643093109, -0.7990119457244873, -0.4311864972114563, 0.42540988326072693, 0.3047912120819092, 0.20849835872650146, -0.8243794441223145, 0.01499276515096426, 0.1762465387582779, 0.314119815826416, -0.11236416548490524, 0.12634611129760742, 0.5127254128456116, -0.5070621371269226, -0.3628477454185486, 0.6106787323951721, 0.006982121616601944, -0.49916261434555054, -0.7467226982116699, -0.35113725066185, 0.784754753112793, -0.6508466601371765, -0.6832427382469177, 0.9395327568054199, -0.3944893777370453, -0.6155292987823486, 0.13959985971450806, -0.6965848207473755, 0.06801508367061615, 0.5223984122276306, -0.813995361328125, -0.73468416929245, 0.651776909828186, -0.22074779868125916, -0.3226514160633087, -0.12660987675189972, 1.6240837574005127, -0.26027408242225647, -0.769906222820282, 0.026517922058701515, 0.2415236383676529, -0.05121418833732605, -0.0958603024482727, -0.28987792134284973, 0.3594091534614563, 0.15788336098194122, -0.2967054843902588, 0.7669867873191833, -0.15126191079616547, -0.21605284512043, -0.71958327293396, -0.053236376494169235, 0.6330981254577637, -0.8106448650360107, -0.2710496187210083, -0.9176619648933411, -0.4604990780353546, 0.25344157218933105, 0.44625476002693176, -0.5386902689933777, 0.6706921458244324, -0.4223448634147644, 0.26520800590515137, 0.07389763742685318, -0.8784524202346802, 0.12905436754226685, 0.17717386782169342, -0.8683449029922485, -0.5529502034187317, 0.5368315577507019, 0.4582962393760681, -0.801801323890686, -0.5378161668777466, -0.02056766487658024, 0.2762718200683594, 0.0823410227894783, 0.8141622543334961, -0.8753030300140381, 0.14172829687595367, 0.8034451007843018, 0.0743689090013504, -0.4886677861213684, -0.06255142390727997, -0.8927383422851562, 0.0008912648190744221, -0.4924301207065582, 0.7937713265419006, -0.7077836394309998, -0.06330150365829468, 1.2604012489318848, 0.40240201354026794, -0.5109982490539551, -0.875571608543396, -0.039730917662382126, 0.05959441140294075, -0.3301311731338501, 0.22288858890533447, -0.42024946212768555, 0.4482901692390442, -0.40237581729888916, 0.13495616614818573, 0.8264414668083191, -0.32180696725845337, -0.32887521386146545, 0.2490575611591339, -0.1686057299375534, -0.0017787335673347116, -0.6524734497070312, -0.5378308892250061, -0.9433181285858154, -0.20266838371753693, -1.13130784034729, -0.08936112374067307, -0.9871423244476318, -0.022412193939089775, 0.36404451727867126, -0.3419340252876282, -0.1661456823348999, 0.433062881231308, -0.8173999190330505, -0.9563800692558289, -0.4188293516635895, 0.075502410531044, 0.45464494824409485, 0.9954392313957214, -0.7054606080055237, -0.17362794280052185, -0.13574518263339996, 0.036544378846883774, 0.3706904947757721, 0.40439409017562866, -0.6811893582344055, -1.025407314300537, -0.790877640247345, 0.03769053891301155, 0.24189938604831696, -0.31130072474479675, -0.4279294013977051, 0.3446904122829437, 0.23039935529232025, -0.056396499276161194, -0.17804645001888275, 0.30815014243125916, -0.6619381308555603, 0.11701246351003647, 0.9408737421035767, -0.7892124056816101, 0.0227062925696373, 0.16800469160079956, -0.7116283774375916, -0.38071078062057495, 0.3420118987560272, -0.1001143604516983, -1.2323341369628906, -0.1828422248363495, 0.6751601099967957, -1.3410942554473877, -0.19568216800689697, 0.15608151257038116, 0.035197075456380844, -0.6041085124015808, -0.2531258463859558, -0.7272104620933533, 0.5576950311660767, -0.7102840542793274, 1.044030785560608, 0.769194483757019, -0.6949001550674438, -0.12741531431674957, 0.5947681069374084, 0.14259538054466248, -0.5940657258033752, 0.5770180225372314, 0.4332345426082611, -0.5776774287223816, 1.0682940483093262, 0.7475810050964355, 0.367811381816864, -1.2313586473464966, 0.07057449221611023, 0.638861894607544, -0.283789724111557, -0.34367698431015015, 1.0326616764068604, 0.15597547590732574, -1.0975725650787354, 0.3688734471797943, -1.176376461982727, -0.7531097531318665, -0.552678644657135, 0.676948606967926, -0.09843059629201889, -0.23682907223701477, -0.26240190863609314, -0.41687530279159546, -0.036421116441488266, 0.06608498096466064, -0.5332542657852173, 0.2078011929988861, -0.49661073088645935, -0.5777009725570679, 0.7644171118736267, 0.5097188353538513, -0.5726374983787537, 0.2215009331703186, 0.027143539860844612, -0.23209969699382782, 0.3111143410205841, 0.047112155705690384, -0.5103980302810669, -0.230677992105484, 0.2933140993118286, 1.1763262748718262, -0.14066298305988312, 0.0442948080599308, 0.04588527977466583, 0.09510525315999985, 0.44839152693748474, 0.5437438488006592, -0.46183380484580994, -1.0382120609283447, 0.6444486975669861, 1.2976808547973633, -1.0021555423736572, 0.023719146847724915, -0.3315141201019287, -0.8748329877853394, 0.894072949886322, -0.06236148253083229, 0.7677819728851318, 0.9732570648193359, -0.1517689973115921, 0.5859162211418152, -0.14075589179992676, -0.9290010929107666, 0.04423673450946808, 0.8765603303909302, 0.5277279615402222, 1.2893187999725342, 0.7831529974937439, -0.6298204064369202, 0.9235085844993591, 0.19459125399589539, 0.6633989810943604, 0.5824387073516846, 0.6801268458366394, -0.12962855398654938, -0.3814437985420227, 0.12537239491939545, 0.7112247943878174, -0.30337005853652954, -0.6206318736076355, -0.2195500135421753, 0.3762188255786896, 0.3311940133571625, 0.7950376272201538, 0.28091901540756226, 0.3372595012187958, 0.26974427700042725, 0.47558125853538513, 0.2242574542760849, -0.55524742603302, -0.09025061130523682, 0.2826479375362396, -0.37402135133743286, 0.04679346829652786, -0.21995191276073456, -0.44205182790756226, -0.5653641223907471, 0.5337886810302734, 0.35956403613090515, 0.16371075809001923, 0.14376816153526306, 1.038614273071289, 0.7075216174125671, -0.007391444407403469, -0.693816065788269, 0.4453229010105133, -0.33516034483909607, -0.9245619177818298, -0.5293533205986023, -0.9656980633735657, -0.002791814738884568, 0.02038162760436535, -0.07950490713119507, -0.6663642525672913]}, "authors": [{"authorId": "2237413487", "name": "Hanguang Xiao"}, {"authorId": "2301416676", "name": "Feizhong Zhou"}, {"authorId": "2264106442", "name": "X. Liu"}, {"authorId": "2261522022", "name": "Tianqi Liu"}, {"authorId": "2297928783", "name": "Zhipeng Li"}, {"authorId": "2301405767", "name": "Xin Liu"}, {"authorId": "2301262715", "name": "Xiaoxuan Huang"}], "references": [{"paperId": "c5e40c7de3ad5cce2bd01fce0f71de313a8ee837", "title": "PMC-LLaMA: toward building open-source language models for medicine."}, {"paperId": "112426cca46a7eeb7c521576fcb9df805841dfbf", "title": "Streamlining Redundant Layers to Compress Large Language Models"}, {"paperId": "e291850b23d1c1ec49bc68e9e9266880898216b2", "title": "The (R)Evolution of Multimodal Large Language Models: A Survey"}, {"paperId": "c59dfbe19a62feeffca03f8a62795425eb1bb8e0", "title": "Text-centric Alignment for Multi-Modality Learning"}, {"paperId": "a091bf215c716a146140f81c751712db628c8e20", "title": "MobileVLM V2: Faster and Stronger Baseline for Vision Language Model"}, {"paperId": "bd0cd89337cc40d39d3a4cbe9c8709e06e877f3e", "title": "Continual Learning for Large Language Models: A Survey"}, {"paperId": "5e17bfb6ccf4f82331aa3732bf94216ae27ae3f4", "title": "Unmasking and Quantifying Racial Bias of Large Language Models in Medical Report Generation"}, {"paperId": "bd7271fd7f595f66c47eaee28d5f556731882a18", "title": "Beyond Anti-Forgetting: Multimodal Continual Instruction Tuning with Positive Forward Transfer"}, {"paperId": "93886752191db25efd096a65af7b09df5c0a64e0", "title": "Data-Centric Foundation Models in Computational Healthcare: A Survey"}, {"paperId": "98ab627dd147db88b5e5cfa9a74f1bd8da110021", "title": "TinyGPT-V: Efficient Multimodal Large Language Model via Small Backbones"}, {"paperId": "13261129251c9e8891cff02c3aee15c4df6a5630", "title": "Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems"}, {"paperId": "0825ef213b4fdeadc8b27fb5a6361bb84d57bc8b", "title": "Tuning LayerNorm in Attention: Towards Efficient Multi-Modal LLM Finetuning"}, {"paperId": "53c3c3984649ca82a2f85629dae01087e9e72991", "title": "OneLLM: One Framework to Align All Modalities with Language"}, {"paperId": "f2e5d96c745b29e5d062a89b6c43810bdcb69969", "title": "A medical multimodal large language model for future pandemics"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "da89cdeb0014666f4024f797d0c67cd45d92a7c9", "title": "FFT: Towards Harmlessness Evaluation and Analysis for LLMs with Factuality, Fairness, Toxicity"}, {"paperId": "bde9da9a39a065588d7f4573936731510d6f4f29", "title": "Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine"}, {"paperId": "bca0bbd01ea917b7a9fe369288ea3ba03d3b1ff3", "title": "A Survey of Large Language Models in Medicine: Progress, Application, and Challenge"}, {"paperId": "3aaa6846d927a14b2aaeddccfef7c5419911fff7", "title": "Benefits and Harms of Large Language Models in Digital Mental Health"}, {"paperId": "6ae4705139494fcb6b790b6dd6c4225b40ee40f8", "title": "GLaMM: Pixel Grounding Large Multimodal Model"}, {"paperId": "96c2824547ff669653e8d058da49dbc8c71ad9c9", "title": "SoulChat: Improving LLMs' Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations"}, {"paperId": "daaa7d4ffb9265226e4baadd2db9a01aa7b2f6fb", "title": "Clinical Text Summarization: Adapting Large Language Models Can Outperform Human Experts"}, {"paperId": "c67a58bb5eb9cb6557a6032bb058a5cab978907f", "title": "Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare"}, {"paperId": "6ba549097ef898a7548c48c0b718b323eec5dbc3", "title": "Performance of Multimodal GPT-4V on USMLE with Image: Potential for Imaging Diagnostic Support with Explanations"}, {"paperId": "c86de166504e73465a64a8ac89335d63cf800b1c", "title": "BianQue: Balancing the Questioning and Suggestion Ability of Health LLMs with Multi-turn Health Conversations Polished by ChatGPT"}, {"paperId": "15a2682ba1b479dea284062dd097a9a349a2eceb", "title": "AlpaCare: Instruction-tuned Large Language Models for Medical Application"}, {"paperId": "68e0e789b5147b1e7d028c7a825650075f4e26bf", "title": "PaLI-3 Vision Language Models: Smaller, Faster, Stronger"}, {"paperId": "c7492913370b5726eaa6ced163a60de6c9d4bb7f", "title": "A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics"}, {"paperId": "124d4d374fbef2016fa9880489871a58a7450644", "title": "Improved Baselines with Visual Instruction Tuning"}, {"paperId": "54814744b42b06c855c97b23de1366e0bcbe775a", "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)"}, {"paperId": "c96297261467b5daa2d01227496a70d444602434", "title": "Baichuan 2: Open Large-scale Language Models"}, {"paperId": "af3ab5da98e0807784b57e321ed887a3666a8ab6", "title": "Multimodal Foundation Models: From Specialists to General-Purpose Assistants"}, {"paperId": "3222702f7be3375008619be6fd6bdc334988d2ba", "title": "R2GenGPT: Radiology Report Generation with Frozen LLMs"}, {"paperId": "b17c9051b22b921d82b3e669f9011538e6d7d2eb", "title": "Transforming healthcare documentation: harnessing the potential of AI to generate discharge summaries"}, {"paperId": "71bc0c97c20fffce796a355b16bd202987260029", "title": "A Survey of Hallucination in Large Foundation Models"}, {"paperId": "2ccdfdbf3bb408a1c74dde2dbb2cf8492b3591db", "title": "Large Language Models in Medicine: The Potentials and Pitfalls"}, {"paperId": "420d6754315ac5db8a040386245cd15b9fe5b459", "title": "Radiology-Llama2: Best-in-Class Large Language Model for Radiology"}, {"paperId": "f0950a3f27c0fefffba60ae1c9a8ee360d5eb55f", "title": "Instruction Tuning for Large Language Models: A Survey"}, {"paperId": "a95ee02fd85a3734bf19bb4bbc6ef3ea22c96cc9", "title": "PMET: Precise Model Editing in a Transformer"}, {"paperId": "0f0024bfef037b97b324b97150ee022c178d6282", "title": "A visual\u2013language foundation model for pathology image analysis using medical Twitter"}, {"paperId": "a50d4fd8f584276c0fd8560255884edd57aa926e", "title": "Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language Model through Expert Feedback and Real-world Multi-turn Dialogue"}, {"paperId": "df0ddb588a200d095743e9d26fc4a9318619766e", "title": "Towards Generalist Foundation Model for Radiology"}, {"paperId": "c9dbdae8146b9f97e254f5d26fd6efde96eaa703", "title": "Med-Flamingo: a Multimodal Medical Few-shot Learner"}, {"paperId": "6eb46737bf0ef916a7f906ec6a8da82a45ffb623", "title": "Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback"}, {"paperId": "3bf7f4a7bf6a7507088f915e271f660e22e89063", "title": "Tell Me, What Are You Most Afraid Of? Exploring the Effects of Agent Representation on Information Disclosure in Human-Chatbot Interaction"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "98f8793a18eaced0ce93f5202065496cc5a84943", "title": "Bootstrapping Vision-Language Learning with Decoupled Language Pre-training"}, {"paperId": "eecb4dbf218d08d43a727c7e79f86a296502f117", "title": "Prompt Engineering as an Important Emerging Skill for Medical Professionals: Tutorial"}, {"paperId": "6651eb8205e3d90c420fbdf8a2740c74e590e545", "title": "Parameter-Efficient Fine-Tuning of LLaMA for the Clinical Domain"}, {"paperId": "514b40032b0b95ed40c7fa2a136dec5a5014ee92", "title": "Transformers in medical image segmentation: A review"}, {"paperId": "0f8d12775a4685575f1489796b5dee9e11fbdfb5", "title": "OphGLM: Training an Ophthalmology Large Language-and-Vision Assistant based on Instructions and Dialogue"}, {"paperId": "ebc502a4d173f6550a8cd6384cb06f2c43c7c1a3", "title": "ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data and Comprehensive Evaluation"}, {"paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787", "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"}, {"paperId": "987f733632ee235d770b7229c567f443ad0abb2f", "title": "The Advent of Generative Language Models in Medical Education"}, {"paperId": "f22d71c7ce9720ba1f717a4f1181488200e78198", "title": "LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day"}, {"paperId": "0d1c76d45afa012ded7ab741194baf142117c495", "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"}, {"paperId": "06091944b864d6dc473cab63321a95fb9c4067cc", "title": "ChatCAD+: Towards a Universal and Reliable Interactive CAD using LLMs"}, {"paperId": "5459cab5dcf3c65c6b4f63b3d9f1e376f722bbcb", "title": "HuatuoGPT, towards Taming Language Model to Be a Doctor"}, {"paperId": "f5c73d9e6641b018b633690102121f5605d34fb0", "title": "Editing Large Language Models: Problems, Methods, and Opportunities"}, {"paperId": "e154dd91de91558f9d671370754eace62a54c911", "title": "A study of generative large language model for medical research and healthcare"}, {"paperId": "546d0624adfc6e18fb87d8cc77e7705bb9ea7445", "title": "LIMA: Less Is More for Alignment"}, {"paperId": "6c9263117c9276b4d373f32491dff0f92564f9e2", "title": "Translating radiology reports into plain language using ChatGPT and GPT-4 with prompt learning: results, limitations, and potential"}, {"paperId": "daf34122a0c38531aeeb55069ba98e564c263d53", "title": "MedBLIP: Bootstrapping Language-Image Pre-training from 3D Medical Images and Texts"}, {"paperId": "2f3822eb380b5e753a6d579f31dfc3ec4c4a0820", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models"}, {"paperId": "8bd6a2a89503be083176f2cc26fabedb79238cbd", "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"}, {"paperId": "1c5bc4f10b95a90d0283d0aacc94332aae508169", "title": "Huatuo-26M, a Large-scale Chinese Medical QA Dataset"}, {"paperId": "ed734578bf467a51b72ea8d0da2b81e1a6364346", "title": "NVIDIA Hopper H100 GPU: Scaling Performance"}, {"paperId": "131c6f328c11706de2c43cd16e0b7c5d5e610b6a", "title": "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond"}, {"paperId": "95430a76264a9be7d64633e56831c60041fb2948", "title": "SurgicalGPT: End-to-End Language-Vision GPT for Visual Question Answering in Surgery"}, {"paperId": "38a9609a5bd874534527df9b00f2897927e57be9", "title": "MedAlpaca - An Open-Source Collection of Medical Conversational AI Models and Training Data"}, {"paperId": "302ee27524a717ddc21f332ca634b9211c6ec6aa", "title": "HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge"}, {"paperId": "281a7a99c16ce8f53bfbfb7aeb460dbd28648d28", "title": "Toxicity in ChatGPT: Analyzing Persona-assigned Language Models"}, {"paperId": "025ca4c125d6ecabc816a56f160e5c992abc76d9", "title": "Multi-step Jailbreaking Privacy Attacks on ChatGPT"}, {"paperId": "16d83e930a4dab2d49f5d276838ddce79df3f787", "title": "Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models"}, {"paperId": "7470a1702c8c86e6f28d32cfa315381150102f5b", "title": "Segment Anything"}, {"paperId": "9faa2b0e5cb93f20df0555c3c350fab0b2eccf3a", "title": "Foundation models for generalist medical artificial intelligence"}, {"paperId": "0b9de138425b4d0374a88e0b0ae9d2faf5231c50", "title": "ChatGPT for healthcare services: An emerging stage for an innovative perspective"}, {"paperId": "72b74bcff8fd76eff6789111a7ce5d0d6c5ac4db", "title": "Benefits, Limits, and Risks of GPT-4 as an AI Chatbot for Medicine."}, {"paperId": "3aaf6a2cbad5850ad81ab5c163599cb3d523436f", "title": "Self-Refine: Iterative Refinement with Self-Feedback"}, {"paperId": "4a7f6c4e71e20311ade4e76e8d0945d499c31fcd", "title": "ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge"}, {"paperId": "348a1efa54376fa39053e5e25d52bd0eb6a0ba68", "title": "Capabilities of GPT-4 on Medical Challenge Problems"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "8f3138f7ee5127faab265793be8ae278bc49d9b1", "title": "PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents"}, {"paperId": "785650a805851c7e945523e495c5a523c60f72a4", "title": "Open-Ended Medical Visual Question Answering Through Prefix Tuning of Language Models"}, {"paperId": "c3e5a20b844c042d2174263d2fd5b30d8cc8f0b0", "title": "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection"}, {"paperId": "bdf7bf9e81a6c12e22323d0402885b2ba62f623e", "title": "Does Synthetic Data Generation of LLMs Help Clinical Text Mining?"}, {"paperId": "8221f1597000543432b7021ca79dbc51a7a63f9c", "title": "Is ChatGPT a Good NLG Evaluator? A Preliminary Study"}, {"paperId": "e9cee216f65e0d82a4f329349c3eb5efe0ddbfb3", "title": "Using ChatGPT to write patient clinic letters."}, {"paperId": "4b3d5da6da9c0b6b61d9672a0374da89b0da1ad3", "title": "The impending impacts of large language models on medical education"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "82ae0e3d614a011e0320887c94d58ba287e106db", "title": "An explorative assessment of ChatGPT as an aid in medical education: Use it with caution"}, {"paperId": "08b85bce712168998004ee80ce4e475390413c74", "title": "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT"}, {"paperId": "3599a236f285af48782fc30b1341d13ec7320735", "title": "A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT"}, {"paperId": "61e721334296ebfbbf6443b5ed9eb8c83b708c95", "title": "Scaling Vision Transformers to 22 Billion Parameters"}, {"paperId": "60f78afe2040f33988c71d585c3f42f06814d0de", "title": "ChatGPT: the future of discharge summaries?"}, {"paperId": "a9be51698e7c2247853b7b6f1f70fc4d6d7ef605", "title": "Transformer-Patcher: One Mistake worth One Neuron"}, {"paperId": "5425de16356015c2f26d2a50684c6c46d6998f51", "title": "MIMIC-IV, a freely accessible electronic health record dataset"}, {"paperId": "6052486bc9144dc1730c12bf35323af3792a1fd0", "title": "Large language models encode clinical knowledge"}, {"paperId": "e65b346d442e9962a4276dc1c1af2956d9d5f1eb", "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions"}, {"paperId": "69c85405cc1986a41f6387d869aa1648a5668d6f", "title": "Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers"}, {"paperId": "3936fd3c6187f606c6e4e2e20b196dbc41cc4654", "title": "Constitutional AI: Harmlessness from AI Feedback"}, {"paperId": "a02fbaf22237a1aedacb1320b6007cd70c1fe6ec", "title": "Robust Speech Recognition via Large-Scale Weak Supervision"}, {"paperId": "325d8e9501af05e594bd668b6cd6d43ed42c8b4d", "title": "InternVideo: General Video Foundation Models via Generative and Discriminative Learning"}, {"paperId": "560b1bc012588731b26748e33236570df777baa0", "title": "Aging with GRACE: Lifelong Model Editing with Discrete Key-Value Adaptors"}, {"paperId": "78281482c1fdad8e167bab39cc9955c73d58ae8f", "title": "EVA: Exploring the Limits of Masked Visual Representation Learning at Scale"}, {"paperId": "2fe1ac0b09cc0f50eb83eef6c7c6b45ac8b12413", "title": "Mass-Editing Memory in a Transformer"}, {"paperId": "1d26c947406173145a4665dd7ab255e03494ea28", "title": "GLM-130B: An Open Bilingual Pre-trained Model"}, {"paperId": "d3135733aa39dec20ce72aa138589dda27c8406d", "title": "Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering"}, {"paperId": "28630034bb29760df01ab033b743e30b37f336ae", "title": "PaLI: A Jointly-Scaled Multilingual Language-Image Model"}, {"paperId": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large Language Models are Zero-Shot Reasoners"}, {"paperId": "b1d2ef3554859c804d9b7993b83c90385717793f", "title": "Mitigating Toxic Degeneration with Empathetic Data: Exploring the Relationship Between Toxicity and Empathy"}, {"paperId": "15190e8b459bd85d546286f7d7da61b4f4f3f58a", "title": "What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "5f19ae1135a9500940978104ec15a5b8751bc7d2", "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "f756e993e6eba8d7c3db74838a348ed3a79bc1cc", "title": "Nvidia Hopper GPU and Grace CPU Highlights"}, {"paperId": "996445d847f06e99b0bd259345408a0cf1bce87e", "title": "Locating and Editing Factual Associations in GPT"}, {"paperId": "c3d208f80d9a6c8793ee3efd3ced8285d92f41d7", "title": "Quantifying and alleviating political bias in language models"}, {"paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d", "title": "High-Resolution Image Synthesis with Latent Diffusion Models"}, {"paperId": "9442019231e11d3e6eb3d4729dcaad7d7871c62c", "title": "MentalBERT: Publicly Available Pretrained Language Models for Mental Healthcare"}, {"paperId": "b15469d0ab3dc3a9dec037d761817b3fe546bed6", "title": "Pre-trained Language Models in Biomedical Domain: A Systematic Survey"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "c7308cd9bb155e1579aff37c053b8ecffa1aff60", "title": "Supervised Learning"}, {"paperId": "b82c5f9efdb2ae56baa084ca41aeddd8a665c1d1", "title": "Align before Fuse: Vision and Language Representation Learning with Momentum Distillation"}, {"paperId": "90357a6dc817e2f7cec477a51156675fbf545cf1", "title": "MERLOT: Multimodal Neural Script Knowledge Models"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "a2a7033a5a859e3a6e6f0a83018326400b4c5faa", "title": "Retrieval Augmentation Reduces Hallucination in Conversation"}, {"paperId": "50796b0f3edf9cb5ff1e447c298b33755378aa4f", "title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling"}, {"paperId": "b3bf9fe13195e9aa70e1dac04e01fcff7008e812", "title": "Perceiver: General Perception with Iterative Attention"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "93b6b79b4ef6c345f31722ce7c829385c6dce0d6", "title": "Slake: A Semantically-Labeled Knowledge-Enhanced Dataset For Medical Visual Question Answering"}, {"paperId": "81002fbb777f860f9aac2bbc24467a62345af279", "title": "Decoupling the Role of Data, Attention, and Losses in Multimodal Transformers"}, {"paperId": "df7d26339adf4eb0c07160947b9d2973c24911ba", "title": "Extracting Training Data from Large Language Models"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "5ba77a5bdeffb62aa0902ae68997bbc38db8a722", "title": "MedICaT: A Dataset of Medical Images, Captions, and Textual References"}, {"paperId": "a2cde1da31a61adab24e702999680108ab58e5ff", "title": "COMETA: A Corpus for Medical Entity Linking in the Social Media"}, {"paperId": "fc97c3f375c7228a1df7caa5c0ce5d2a6a171bd7", "title": "What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams"}, {"paperId": "053b1d7b97eb2c91fc3921d589c160b0923c70b1", "title": "Learning to summarize from human feedback"}, {"paperId": "a2f38d03fd363e920494ad65a5f0ad8bd18cd60b", "title": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing"}, {"paperId": "1d54cbc28ad8561f714c34d82622000b57769441", "title": "Systematic review of artificial intelligence techniques in the detection and classification of COVID-19 medical images in terms of evaluation and benchmarking: Taxonomy analysis, challenges, future solutions and methodological aspects"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "bc411487f305e451d7485e53202ec241fcc97d3b", "title": "CORD-19: The Covid-19 Open Research Dataset"}, {"paperId": "5e52f3b7fd14f151b26309e9f06239ddcd99b39a", "title": "MedDialog: A Large-scale Medical Dialogue Dataset"}, {"paperId": "fc0b46a0f3720e6c29c1a913aaa3de4a0699f713", "title": "PathVQA: 30000+ Questions for Medical Visual Question Answering"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "697aa112f629718e3975217f91cf893f4727ea96", "title": "Self-Supervised Contextual Language Representation of Radiology Reports to Improve the Identification of Communication Urgency"}, {"paperId": "d1f407b16fb8d99487baee37ed0805676c58e7ac", "title": "MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "0c3c4c88c7b07596221ac640c7b7102686e3eae3", "title": "PubMedQA: A Dataset for Biomedical Research Question Answering"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "df6ae7c951a4ae2b548c86768cd94be28adee7f3", "title": "How Should My Chatbot Interact? A Survey on Social Characteristics in Human\u2013Chatbot Interaction Design"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"}, {"paperId": "86c8e5e2979377f87c7fdb2108497d074943d462", "title": "A question-entailment approach to question answering"}, {"paperId": "89a816719613e220a64ab2590c938c23bbfe187e", "title": "CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison"}, {"paperId": "889ad3c713bd7f1b3a8e9b07e136ec4a88651893", "title": "Multi-Scale Attentive Interaction Networks for Chinese Medical Question Answer Selection"}, {"paperId": "a564fabf130ff6e2742cfba90c7a4018937d764d", "title": "Radiology Objects in COntext (ROCO): A Multimodal Image Dataset"}, {"paperId": "51c741acb1cf73eaed1c0e496ccc150bd8926939", "title": "Deep Learning and Medical Diagnosis: A Review of Literature"}, {"paperId": "a6876ea89e677a7cc42dd43f27165ff6fd414de5", "title": "UNet++: A Nested U-Net Architecture for Medical Image Segmentation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "95cd83603a0d2b6918a8e34a5637a8f382da96f5", "title": "MIMIC-III, a freely accessible critical care database"}, {"paperId": "24c86d41b9b81df993b00ce79e6b9618b83de1ea", "title": "No health without mental health."}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "06b919f865d0a0c3adbc10b3c34cbfc35fb98d43", "title": "A Sensitivity Analysis of (and Practitioners\u2019 Guide to) Convolutional Neural Networks for Sentence Classification"}, {"paperId": "651e5bcc14f14605a879303e97572a27ea8c7956", "title": "A Diversity-Promoting Objective Function for Neural Conversation Models"}, {"paperId": "04b9e4192eca063b95ca65db901e1cccfb0ecd6f", "title": "Preparing a collection of radiology examinations for distribution and retrieval"}, {"paperId": "c657ab339517fb8def7ce7f83bb81e746d558218", "title": "Data Resource Profile: Clinical Practice Research Datalink (CPRD)"}, {"paperId": "258986132bf17755fe8263e42429fe73218c1534", "title": "CIDEr: Consensus-based image description evaluation"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "a0fa07523183680555bfb661fae62966a6d52843", "title": "County-level estimates of mental health professional shortage in the United States."}, {"paperId": "955fcf6643c6946f491e70a96db3ffe3bc719a14", "title": "An empirical comparison of supervised learning algorithms"}, {"paperId": "185e7e2d397478d0d81b89c6f712b1fa7d62c979", "title": "Toward integrating feature selection algorithms for classification and clustering"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "77cf2d8a174c5a9a6b41c44203695c1d7f83f391", "title": "Machine learning for medical diagnosis: history, state of the art and perspective"}, {"paperId": "2722b9e5ab8da95f03e578bb65879c452c105385", "title": "Catastrophic forgetting in connectionist networks"}, {"paperId": null, "title": "Introducing the next generation of Claude"}, {"paperId": null, "title": "LargeLanguageModelDistillingMedication Recommendation Model"}, {"paperId": "61b0f5cfd4f951632435707948201474e16e835b", "title": "Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding"}, {"paperId": "53f133dfedf3de823a8ba9e885ef92a9e3811fd1", "title": "ChatGPT and GPT-4 for Professional Translators: Exploring the Potential of Large Language Models in Translation"}, {"paperId": "f02241105c2a72943e24c37ae58a22c46db88720", "title": "PCLmed at ImageCLEFmedical 2023: Customizing General-Purpose Foundation Models for Medical Report Generation"}, {"paperId": null, "title": ". Mobilevlm: A fast, reproducible and strong vision language assistant for mobile devices"}, {"paperId": null, "title": ". Introducing Duolingo Max, a learning experience powered by GPT-4"}, {"paperId": null, "title": ". Harnessing GPT-4 so that all students benefit. A nonprofit approach for equal access"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Preliminarystudyontheconstruction of Chinese medical knowledge graph"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "18f9a6045ba01cb079c4fa49a630d71bbd27cd92", "title": "Descriptor : A dataset of clinically generated visual questions and answers about radiology images"}, {"paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82", "title": "Deep Learning"}, {"paperId": "5bf42fe6806ac76065dea9db434c0f8acb5034ef", "title": "Artificial Intelligence in Medical Diagnosis"}, {"paperId": "cb3dcb13abd096a33780e6268ee4aaa583b198e8", "title": "A Smorgasbord of Features for Statistical Machine Translation"}, {"paperId": "1f1eaf19e38b541eec8a02f099e3090536a4c936", "title": "The Unified Medical Language System (UMLS): integrating biomedical terminology"}, {"paperId": null, "title": "Bleu:amethodforautomaticevaluationofmachinetranslation"}, {"paperId": null, "title": "2023. TCM-GPT: Efficient Pre-training of Large Language Models for Domain Adaptation in Traditional Chinese Medicine"}, {"paperId": null, "title": "2023. Large ai models in health informatics: Applications, challenges, and the future"}, {"paperId": null, "title": "2023. Pathasst: Redefining pathology through generative foundation ai assistant for pathology"}, {"paperId": null, "title": "2023. XrayGLM: The first Chinese Medical Multimodal Model that Chest Radiographs Summarization"}, {"paperId": null, "title": "2023. GPT understands, too"}, {"paperId": null, "title": "2023. Llm-adapters: An adapter family for parameter-efficient fine-tuning of large language models"}, {"paperId": null, "title": "2023. Prompt engineering for healthcare: Methodologies and applications"}, {"paperId": null, "title": "7th Joint International Workshop, CVII-STENT 2018 and Third International Workshop,"}, {"paperId": null, "title": "2024. Towards conversational diagnostic ai"}, {"paperId": null, "title": "2023. Visual med-alpaca: A parameter-efficient biomedical llm with visual capabilities"}, {"paperId": null, "title": "2022. Ul2: Unifying language learning paradigms"}, {"paperId": null, "title": "2023. Global mental health services and the impact of artificial intelligence\u2013powered large language models"}, {"paperId": null, "title": "2023. Qilin-med: Multi-stage knowledge injection advanced medical large language model"}, {"paperId": null, "title": "2023. Perturbation Methods for Protecting Data Privacy: A Review of Techniques and Applications"}, {"paperId": null, "title": "2024. Innovations in Minimally Invasive Surgery: The Rise of Smart Flexible Surgical Robots"}, {"paperId": null, "title": "2023. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing"}, {"paperId": null, "title": "2023. Minigpt-4: Enhancing vision-language understanding with advanced large language models"}, {"paperId": null, "title": "2023. Chatgpt as a factual inconsistency evaluator for abstractive text summarization"}, {"paperId": null, "title": "2024. PeFoMed: Parameter Efficient Fine-tuning on Multimodal Large Language Models for Medical Visual Question Answering"}, {"paperId": null, "title": "2023. Alpagasus: Training a better alpaca with fewer data"}, {"paperId": null, "title": "2023. Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality"}, {"paperId": null, "title": "2023. Baize: An open-source chat model with parameter-efficient tuning on self-chat data"}, {"paperId": null, "title": "Manuscript submitted to ACM"}, {"paperId": null, "title": "2023. Stanford Alpaca: An Instruction-following LLaMA model"}, {"paperId": null, "title": "2023. Instruction mining: High-quality instruction data selection for large language models"}, {"paperId": null, "title": "2023. RadAdapt: Radiology report summarization via lightweight domain adaptation of large language models"}, {"paperId": null, "title": "2023. Videochat: Chat-centric video understanding"}, {"paperId": null, "title": "2023. Xraygpt: Chest radiographs summarization using medical vision-language models"}, {"paperId": null, "title": "2023. Openflamingo: An open-source framework for training large autoregressive vision-language models"}, {"paperId": null, "title": "A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine"}, {"paperId": null, "title": "2023. Halo: Estimation and reduction of hallucinations in open-source weak large language models"}, {"paperId": null, "title": "2023. Performance of ChatGPT on USMLE: potential for AI-assisted medical education using large language models"}, {"paperId": null, "title": "2023. How to bridge the gap between modalities: A comprehensive survey on multimodal large language model"}]}