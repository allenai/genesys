{"paperId": "2f130a320798dba1b13fa2e2822d42273e453038", "title": "An Empirical Analysis of Parameter-Efficient Methods for Debiasing Pre-Trained Language Models", "abstract": "The increasingly large size of modern pre-trained language models not only makes them inherit more human-like biases from the training corpora, but also makes it computationally expensive to mitigate such biases. In this paper, we investigate recent parameter-efficient methods in combination with counterfactual data augmentation (CDA) for bias mitigation. We conduct extensive experiments with prefix tuning, prompt tuning, and adapter tuning on different language models and bias types to evaluate their debiasing performance and abilities to preserve the internal knowledge of a pre-trained model. We find that the parameter-efficient methods (i) are effective in mitigating gender bias, where adapter tuning is consistently the most effective one and prompt tuning is more suitable for GPT-2 than BERT, (ii) areless effective when it comes to racial and religious bias, which may be attributed to the limitations of CDA, and (iii) can perform similarly to or sometimes better than full fine-tuning with improved time and memory efficiency, as well as maintain the internal knowledge in BERT and GPT-2, evaluated via fact retrieval and downstream fine-tuning.", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2023, "citationCount": 6, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2306.04067", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "Recent parameter-efficient methods in combination with counterfactual data augmentation (CDA) for bias mitigation are investigated and find that they are effective in mitigating gender bias and are less effective when it comes to racial and religious bias."}, "embedding": {"model": "specter_v2", "vector": [-0.4047994315624237, 0.7889081835746765, -0.5782166123390198, -0.08126738667488098, -0.064870685338974, -0.16356593370437622, 0.8714564442634583, -0.3908423185348511, -0.6663022041320801, 0.1632554680109024, 0.7265222072601318, -0.36354097723960876, 0.43755412101745605, -0.04067512974143028, -0.29573023319244385, -0.023370632901787758, -0.7963135838508606, 0.6719766855239868, -0.5639702677726746, -0.6811800599098206, -0.26235705614089966, -0.6508762836456299, -0.7159133553504944, -0.41155070066452026, 0.5827324986457825, 0.05578829348087311, -0.4609973132610321, 0.6545053124427795, -0.5449584126472473, -0.05477616935968399, 0.34983471035957336, -0.7713338136672974, 0.41181638836860657, -0.1859816014766693, -0.2514854073524475, 0.08976960927248001, 0.5525940656661987, -0.5923353433609009, -0.548831045627594, 0.5290257930755615, -0.004134157206863165, 0.24215348064899445, 0.4996144473552704, -0.6217319369316101, -0.4732828736305237, 0.531136155128479, 0.6055446863174438, 1.0129597187042236, -0.25000420212745667, -0.5286761522293091, 0.7555449604988098, -1.0665202140808105, 0.21212919056415558, 1.4886561632156372, 0.7164081335067749, 0.8209810853004456, -0.24077196419239044, -1.0502116680145264, 0.5008389949798584, -0.3319237232208252, -0.9230387210845947, -0.1632629632949829, 0.19763126969337463, -0.3384642004966736, 1.32770574092865, -0.2199074625968933, -0.12673987448215485, 0.5466164350509644, -0.3345200717449188, 1.104506254196167, -0.10360724478960037, -0.5609209537506104, -0.44327083230018616, 0.6371027231216431, 0.035978879779577255, 1.0263978242874146, -0.29025208950042725, 0.7562128305435181, -0.8719794154167175, -0.6677101254463196, 0.6599557399749756, -0.4620372951030731, -0.026854105293750763, -0.0179706159979105, -0.22254496812820435, 1.088181495666504, 0.2259630411863327, 0.720786988735199, -0.026274606585502625, 0.36062127351760864, 0.5411921739578247, 0.19027014076709747, 0.17854006588459015, 0.7151627540588379, -0.4689902663230896, 0.375222384929657, -0.9726070761680603, 0.5137643218040466, -0.028295699506998062, 0.5520789623260498, -0.13591647148132324, 0.3001912534236908, -1.0152980089187622, 0.3172522187232971, 1.2712414264678955, 0.14931321144104004, 0.7650102376937866, -0.8837827444076538, 0.3181042969226837, -0.4330168068408966, 0.5879554152488708, -0.7622429132461548, -0.6217107176780701, -0.3713265359401703, -0.9977095127105713, -1.7940565347671509, -0.04685171693563461, -0.10308997333049774, -0.8107338547706604, 0.9704148769378662, 0.1600540280342102, 0.008407115004956722, -0.19182051718235016, 0.6351341605186462, 0.4541943669319153, 0.5840847492218018, 0.46699249744415283, -7.560927770100534e-05, 0.978042483329773, -0.47078749537467957, -0.8028784990310669, -0.973897397518158, 0.9181408882141113, -0.2837604284286499, 0.5757402181625366, -0.42548149824142456, -0.9376323223114014, -0.9255226254463196, -0.7875468730926514, -0.12239331007003784, -0.45114871859550476, 0.5292055010795593, 1.3144265413284302, 1.023508906364441, -0.600594699382782, 0.460954487323761, 0.02419801987707615, -0.42010462284088135, 0.31633949279785156, -0.17444941401481628, 0.3654952943325043, -0.4508029818534851, -1.5372488498687744, 0.19020378589630127, 0.5864474773406982, -0.7929954528808594, 0.056741777807474136, -0.9279615879058838, -0.9840846061706543, -0.3686632215976715, 0.4304859936237335, -0.6104843020439148, 1.1392369270324707, -0.18689315021038055, -0.9615786075592041, 1.2926501035690308, -0.19031323492527008, -0.06274722516536713, 0.7416266798973083, 0.012293958105146885, -0.920158326625824, -0.7210901975631714, -0.24703934788703918, 0.6969489455223083, 0.603839635848999, -0.4079471826553345, -0.008264193311333656, 0.12863436341285706, -0.06461690366268158, 0.01032713521271944, -0.3085848391056061, 0.5040205121040344, -0.4412743151187897, -0.623744010925293, 0.46170270442962646, 0.5558322668075562, 0.06553017348051071, -0.13545183837413788, -0.38459739089012146, -0.5741061568260193, 0.5586709380149841, -0.37893354892730713, 1.2707616090774536, -0.8197675943374634, -0.9959943294525146, 0.11917250603437424, -0.29935771226882935, 0.04033555090427399, -0.6407573223114014, 0.4058416783809662, -0.26354676485061646, 0.6010398268699646, -0.34293434023857117, -1.1688634157180786, 0.019348938018083572, -0.0314045250415802, -0.6882708072662354, -0.13604925572872162, -0.13925519585609436, 0.9814795851707458, -0.6511386036872864, 0.07072475552558899, -0.385159969329834, 0.10623513907194138, -1.5108699798583984, 1.1972121000289917, -0.5222265720367432, 0.3964557945728302, 0.31113195419311523, -0.10988116264343262, 0.5129522085189819, 0.07549955695867538, 0.36737561225891113, -0.3942568004131317, -0.12737706303596497, 0.6835997700691223, -0.7862238883972168, 1.2444342374801636, -0.08323058485984802, 0.030812520533800125, 0.09754513204097748, -0.3979825973510742, 0.06503985822200775, 0.3879677355289459, -0.3210834860801697, -0.44831037521362305, 0.3367578089237213, 0.6176270842552185, -0.6518840789794922, 0.24695302546024323, 1.107604742050171, 0.061445314437150955, -0.29392027854919434, 0.0721435546875, 0.38918840885162354, -0.3729963004589081, 0.47130969166755676, 0.3756925165653229, -0.1157722920179367, 0.2118796706199646, 0.2817628085613251, -0.40571027994155884, 0.4277525544166565, -0.5789744853973389, 0.16190683841705322, 0.257793664932251, 0.609370768070221, 0.6404945850372314, 0.41022786498069763, -0.5706090927124023, -0.44985631108283997, 0.06954489648342133, 0.21439510583877563, 1.8649070262908936, -0.41618892550468445, -0.01232124399393797, -0.5259556770324707, -0.4791199266910553, -0.08015327155590057, 0.39952370524406433, -0.8817330002784729, -0.17496734857559204, -0.7034084796905518, -1.3942276239395142, 1.09208345413208, 0.16074201464653015, 1.3320764303207397, -0.04593147709965706, 0.20457158982753754, -0.25573933124542236, 0.06166002154350281, -0.14571687579154968, -0.9170277714729309, -0.09716314822435379, -0.5857201814651489, -0.05905994772911072, -0.2954818904399872, -0.22493241727352142, 0.0388035885989666, -0.6795022487640381, 1.0842187404632568, 0.18688112497329712, 0.33693909645080566, -0.1052687019109726, 0.73512202501297, -0.4299062490463257, -1.030746340751648, 0.4811764657497406, 0.25001558661460876, -0.16141869127750397, 0.2143774926662445, 0.5541995763778687, -0.11972345411777496, 0.46712496876716614, -0.6133790612220764, 0.05181822553277016, -0.26255518198013306, 0.4717637300491333, 0.25590142607688904, -0.3590797185897827, 0.13457606732845306, -1.627916693687439, 0.7992281317710876, 0.0328797847032547, -0.6713643670082092, -0.009328287094831467, -0.6005935668945312, -0.4357498288154602, -0.04272230342030525, -0.7203933596611023, -0.6871507167816162, -1.3987029790878296, -0.05320451036095619, 0.4443192183971405, 0.012968173250555992, 0.514506459236145, 0.13958580791950226, 0.29045742750167847, 0.561225175857544, 0.20324306190013885, 0.13145868480205536, -0.2572377920150757, 0.6703740358352661, -0.806480884552002, 0.5599424839019775, 0.10107917338609695, 0.505510151386261, -0.01571056991815567, -0.2851341664791107, -0.5716859102249146, -0.5320706367492676, -0.18958663940429688, -0.1386880874633789, 0.19873708486557007, -0.15997779369354248, -0.6548141241073608, -0.48655039072036743, 0.18612967431545258, -0.7013123035430908, -0.30045029520988464, 0.06606045365333557, -0.22660087049007416, 0.03832371160387993, -1.0850564241409302, -1.1267114877700806, -0.7196499109268188, -0.1778046041727066, -0.4013531506061554, 0.34971854090690613, -0.01324794813990593, -0.23299486935138702, -0.6768987774848938, 0.21640987694263458, 0.0634411945939064, 0.9823414087295532, -0.7189103364944458, 1.2463092803955078, 0.09818216413259506, 0.05567153915762901, -0.16920161247253418, 0.16947707533836365, 0.37587639689445496, -0.43717092275619507, 0.1147996112704277, -0.8671374320983887, 0.06111198663711548, -0.29190799593925476, -0.20858493447303772, 0.24024170637130737, 0.3064456880092621, 0.5555558800697327, -0.2237127125263214, -0.4794694185256958, 0.6436809301376343, 1.1023074388504028, -0.8197616338729858, 0.17585055530071259, 0.16801144182682037, 0.7436177730560303, 0.46318319439888, 0.07207514345645905, 0.5678870677947998, 0.6216877102851868, 0.20169293880462646, -0.10220197588205338, -0.4701850414276123, 0.15116189420223236, -0.9014931321144104, 0.11959224194288254, 1.3468399047851562, 0.042473189532756805, -0.06402406096458435, -1.125783920288086, 0.7509783506393433, -0.8294762969017029, -0.4755707383155823, 0.34152817726135254, 0.7060960531234741, 0.7531443238258362, -0.5105443000793457, 0.11902381479740143, -0.0007999302470125258, 0.29992765188217163, 0.49965012073516846, -0.24812184274196625, -0.5305253863334656, -0.17349165678024292, -0.17934063076972961, 0.43640971183776855, 0.5336518287658691, -0.41893240809440613, 0.7477303147315979, 15.052560806274414, 0.6954238414764404, 0.08328799158334732, 0.6578830480575562, 0.84324711561203, 0.25368446111679077, -0.6661221385002136, -0.7148982882499695, -0.7908951640129089, -0.15447695553302765, 0.6711202263832092, 0.4325826168060303, 0.9868365526199341, -0.045726120471954346, -0.05861992761492729, 0.010035574436187744, 0.048646148294210434, 0.7175003886222839, 0.48632726073265076, -1.4007707834243774, 0.1453239470720291, 0.34940123558044434, 0.7895870208740234, 0.3634471893310547, 1.0157228708267212, 1.0994571447372437, 0.16582569479942322, -0.26212647557258606, 0.5363121032714844, -0.01521091628819704, 0.7480520606040955, -0.3070141673088074, 0.5460674166679382, 0.5206937193870544, -0.10181190818548203, -0.19345040619373322, -0.5401243567466736, -1.2158070802688599, 0.012907668016850948, 0.010271153412759304, -0.5511845350265503, -0.4907623827457428, -0.32964423298835754, 0.16380229592323303, -0.08571963012218475, 0.06104988232254982, -0.034273676574230194, 0.8612504601478577, 0.020875675603747368, 0.4277115762233734, 0.2172365039587021, 0.3129754960536957, 0.38293951749801636, -0.18793140351772308, 0.13106884062290192, 0.07351503521203995, -0.31151440739631653, 0.40889421105384827, -0.9764835834503174, -0.021393345668911934, -0.04148462414741516, -0.2759861648082733, 0.15095235407352448, 0.46450650691986084, 0.6950500011444092, 0.14344699680805206, -0.27192115783691406, 0.20791690051555634, 0.39408212900161743, 0.3233163356781006, -0.5078659057617188, 0.547406017780304, 0.6520523428916931, 0.04705306887626648, -0.32474350929260254, 0.25707489252090454, -0.3778823912143707, -0.5806724429130554, -1.024669885635376, -0.48515012860298157, 0.592741072177887, -0.6156229376792908, -0.7255017757415771, 0.37190505862236023, -0.31139039993286133, -0.2635727822780609, 0.29154056310653687, -0.570349931716919, 0.10395462065935135, 0.49651727080345154, -1.3377941846847534, -0.6904897093772888, 0.46231046319007874, -0.3365457355976105, -0.9628094434738159, -0.22583594918251038, 1.227473497390747, 0.3117540776729584, -0.5742539763450623, 0.5385550260543823, 0.42062807083129883, -0.02641480788588524, 0.17504628002643585, -0.699079155921936, 0.9594101905822754, 0.1668926477432251, -0.21092092990875244, 0.4986112415790558, 0.36453959345817566, -0.06562122702598572, -0.5374406576156616, -0.14625030755996704, 0.745679497718811, -0.8203138709068298, -0.6345571875572205, -0.8516571521759033, -0.9748744964599609, 0.3103477358818054, 0.512073814868927, -0.5990111827850342, 0.5998317003250122, 0.481082946062088, -0.5588140487670898, 0.07657952606678009, -1.3800649642944336, 0.2707759737968445, 0.6441742181777954, -0.6000800132751465, -0.3918827176094055, -0.12257232517004013, 0.07565759122371674, -1.4207602739334106, -0.34561973810195923, -0.3682466447353363, -0.18452535569667816, 0.05286067724227905, 0.938600480556488, -0.6862413287162781, 0.17436690628528595, 0.7272951602935791, -0.32281744480133057, -1.0741169452667236, -0.19822075963020325, -0.6611191630363464, 0.24365822970867157, 0.6601678729057312, 0.9325215220451355, -0.6118852496147156, 0.3894553482532501, 1.2256547212600708, 0.49137336015701294, -0.14466004073619843, -0.6123047471046448, -0.2158067673444748, 0.4675526022911072, -0.4362024962902069, 1.015885591506958, 0.38330143690109253, -0.3861430883407593, 0.1239619106054306, -0.009610469453036785, 0.6546066403388977, -0.5730380415916443, -0.6714577674865723, 0.5741546750068665, 0.16565123200416565, 0.04141174629330635, -0.34603986144065857, 0.026062004268169403, -1.1632345914840698, -0.3274524211883545, -0.8950379490852356, -0.2444765418767929, -0.6258469223976135, -0.3262665867805481, -0.1679050177335739, 0.20111845433712006, -0.2426581084728241, 0.047079458832740784, -0.029660256579518318, -0.6545783877372742, -0.5667827129364014, 0.2537500858306885, 1.0673999786376953, 0.8098512291908264, -0.5626322031021118, -0.14748938381671906, -0.09497255086898804, -0.21608737111091614, 0.4259433150291443, 0.6437259316444397, -0.4371502101421356, -0.5013198256492615, -1.1814063787460327, 0.6707844138145447, -0.28773248195648193, 0.031716957688331604, -0.21974623203277588, 0.15467679500579834, 0.18285822868347168, -0.12052209675312042, -0.007950721308588982, 0.39575445652008057, -0.7717612981796265, -0.3907161056995392, 0.09519106149673462, -0.46009713411331177, -0.04649750888347626, 0.49462467432022095, -0.6860595941543579, -0.19854973256587982, 0.7457711696624756, 0.028894318267703056, -0.7366244196891785, -0.4913771152496338, 0.5140732526779175, -0.718043863773346, 0.5898007750511169, -0.6612622141838074, 0.015783553943037987, -1.0275555849075317, -0.34489771723747253, 0.37489503622055054, 0.47127407789230347, -0.22358860075473785, 0.7111417651176453, -0.3648799955844879, -1.5173510313034058, 0.016794029623270035, 0.6841889023780823, -0.1259716898202896, -0.27698183059692383, 0.6685092449188232, 0.47270944714546204, -0.22005702555179596, 0.8464015126228333, 0.4355575144290924, 0.7373722195625305, -0.6048927903175354, 0.07011585682630539, 0.9515118598937988, -0.3744814693927765, 0.3203715980052948, 1.4007748365402222, -0.11742514371871948, -1.5242555141448975, 0.12071803212165833, -1.1597071886062622, -0.4339560270309448, -0.14523079991340637, 0.28818655014038086, 0.31494173407554626, 0.05045638605952263, -0.307575523853302, -0.4094175398349762, -0.1519477516412735, 0.07220155745744705, -0.5667237043380737, 0.21770207583904266, -0.4591977596282959, -0.12189479917287827, 0.4546845853328705, 0.7031465768814087, -0.1755523681640625, -0.6300441026687622, -0.6266414523124695, -0.37221118807792664, -0.48465362191200256, 0.3962722718715668, -0.8976238965988159, -0.6958727240562439, 0.454440712928772, 0.509578287601471, 0.33734434843063354, 0.13730859756469727, -0.2876392602920532, 0.3483732044696808, 0.26184502243995667, -0.020968347787857056, -1.019529938697815, -0.9024581909179688, 1.2125043869018555, 1.2744077444076538, -1.0494976043701172, 0.3009406626224518, -0.1587054282426834, -0.9527103900909424, 0.2408434897661209, 0.377090722322464, 0.2449587732553482, 0.98438560962677, -0.831245481967926, 0.4653092622756958, -0.01469859853386879, -0.49934300780296326, -0.24648460745811462, 0.9586544632911682, 0.8814342021942139, 0.8231750130653381, 0.47650349140167236, -0.1742546111345291, 1.1261231899261475, -0.3450644910335541, -0.03462057560682297, 0.39352676272392273, 0.11457525193691254, 0.025078633800148964, -0.2426549196243286, -0.44053345918655396, 0.7732045650482178, -0.43003660440444946, -0.49448341131210327, -0.053127720952034, 1.2466553449630737, 0.5582817792892456, 0.21464303135871887, 0.5748633742332458, 0.13048487901687622, 0.6578842401504517, 0.6164161562919617, 0.5617312788963318, -0.2399115264415741, -0.386222779750824, -0.09091106057167053, -0.29345273971557617, 0.058266106992959976, -0.16237092018127441, -0.7257280349731445, -0.18869982659816742, -0.5215098857879639, 0.34969645738601685, -0.08409374207258224, 0.24777017533779144, 0.890291690826416, 0.43476834893226624, -0.015936683863401413, -0.43415367603302, -0.2684842646121979, -0.10301872342824936, -1.2056176662445068, -0.3575567305088043, -0.5407806038856506, -0.3711318373680115, -0.42158740758895874, -0.2557538151741028, -0.6245608925819397]}, "authors": [{"authorId": "123639116", "name": "Zhongbin Xie"}, {"authorId": "1690572", "name": "Thomas Lukasiewicz"}], "references": [{"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "8c62277dada489904a63de4dd87336c27c68fb5e", "title": "Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "de6807676d8171472ed6cf421c4e4ed3cbb47699", "title": "An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-trained Language Models"}, {"paperId": "43a87867fe6bf4eb920f97fc753be4b727308923", "title": "Towards a Unified View of Parameter-Efficient Transfer Learning"}, {"paperId": "130ab5c480860e330b65280a3410f17bb2d50fe1", "title": "Sustainable Modular Debiasing of Language Models"}, {"paperId": "ffb56ae86e4abe134c801d3405423b38a589ecb8", "title": "Toward Gender-Inclusive Coreference Resolution: An Analysis of Gender and Bias Throughout the Machine Learning Lifecycle*"}, {"paperId": "7c799b7bd8c069c6feb7235345c97aa1f5330b84", "title": "How Reliable are Model Diagnostics?"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "df157cb42b574c3f46b269504c18375bfa5bc5b1", "title": "FairFil: Contrastive Neural Debiasing Method for Pretrained Text Encoders"}, {"paperId": "ca2f1088d3e581b2c6c75cf0ebc96506d620f64d", "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? \ud83e\udd9c"}, {"paperId": "ce9ca56036307217ea565644d3d3bd74b879e045", "title": "Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP"}, {"paperId": "61ca0040d81c5ed71d3f9b9e5f7b528275048440", "title": "Debiasing Pre-trained Contextualised Embeddings"}, {"paperId": "3d864a8bc5a55ccab9993aa66203d8e70b88148c", "title": "Measuring and Reducing Gendered Correlations in Pre-trained Models"}, {"paperId": "645bd6eadc247989abc5e0b0aa0be79ec8b11ea6", "title": "CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models"}, {"paperId": "063f8b1ecf2394ca776ac61869734de9c1953808", "title": "AdapterHub: A Framework for Adapting Transformers"}, {"paperId": "0d965ed237a3b4592ecefdb618c29f63adedff76", "title": "Towards Debiasing Sentence Representations"}, {"paperId": "d47a682723f710395454687319bb55635e653105", "title": "Language (Technology) is Power: A Critical Survey of \u201cBias\u201d in NLP"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "98ef0db84e62aef969629264c9de1f4d0013f3b9", "title": "AdapterFusion: Non-Destructive Task Composition for Transfer Learning"}, {"paperId": "babeda48b10a4d638252118f2238d05a06f4ec55", "title": "StereoSet: Measuring stereotypical bias in pretrained language models"}, {"paperId": "e969aa3422a49152c22f3faf734e4561a2a3cf42", "title": "Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection"}, {"paperId": "4099c4d272c12081b562392606e6d567e4ae7031", "title": "Masked Language Model Scoring"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "5019dbe8d1da5f128f4f373d6849095cf18fd519", "title": "The Woman Worked as a Babysitter: On Biases in Language Generation"}, {"paperId": "d0086b86103a620a86bc918746df0aa642e2a8a3", "title": "Language Models as Knowledge Bases?"}, {"paperId": "835ac3cbb41f2ec47718c5491211dd33b64f382b", "title": "Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology"}, {"paperId": "25e9ffae12afac2835eabfe9555561adf1536e56", "title": "Are We Consistently Biased? Multidimensional Analysis of Biases in Distributional Word Vectors"}, {"paperId": "e235ad7dcf6e97cd372f09724dc947c5b1efac79", "title": "Gender Bias in Contextualized Word Embeddings"}, {"paperId": "5e9c85235210b59a16bdd84b444a904ae271f7e7", "title": "On Measuring Social Biases in Sentence Encoders"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "b8894e5b2d3afde2142b7ae49d4ba08b77984b29", "title": "Gender Bias."}, {"paperId": "0be19fd9896e5d40222c690cc3ff553adc7c0e27", "title": "Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "ea0afc862128902a991f182741e09ae81d5f5f45", "title": "Permutation Methods: A Basis for Exact Inference"}, {"paperId": "2722b9e5ab8da95f03e578bb65879c452c105385", "title": "Catastrophic forgetting in connectionist networks"}, {"paperId": "b79bb5e86b0836cb1d305bf7d0481383e39b37b4", "title": "Auto-Debias: Debiasing Masked Language Models with Automated Biased Prompts"}, {"paperId": "72128b2da0ffb784861889462070570b21017b9f", "title": "French CrowS-Pairs: Extending a challenge dataset for measuring social bias in masked language models to a language other than English"}, {"paperId": "d4fb836846b79d8692df8bf54d20d1a9d02ffe7d", "title": "Debiasing Pre-Trained Language Models via Efficient Fine-Tuning"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "ea667d3f5df2954c7365b8d1218889e2fc514829", "title": "He is very intelligent, she is very beautiful? On Mitigating Social Biases in Language Modelling and Generation"}, {"paperId": "3e65f572322e192fe36ae52a8a7f025b0685dfc6", "title": "Stereotyping Norwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets"}, {"paperId": null, "title": "We adopt the same bias attribute words as Meade et al. (2022), where the list for gender is from Zhao et al. (2018) and that for religion is from"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "13167f9cd8c7906ca808b01d28dca6dd951da8a5", "title": "of the Association for Computational Linguistics"}, {"paperId": null, "title": ", Sylvain Gugger , Mariama Drame , Quentin Lhoest , and Alexander Rush . 2020 . Transformers : State - ofthe - art natural language processing"}]}