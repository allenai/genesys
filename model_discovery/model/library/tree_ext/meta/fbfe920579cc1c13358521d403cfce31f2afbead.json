{"paperId": "fbfe920579cc1c13358521d403cfce31f2afbead", "title": "KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches", "abstract": "Long context capability is a crucial competency for large language models (LLMs) as it mitigates the human struggle to digest long-form texts. This capability enables complex task-solving scenarios such as book summarization, code assistance, and many more tasks that are traditionally manpower-intensive. However, transformer-based LLMs face significant challenges with long context input due to the growing size of the KV cache and the intrinsic complexity of attending to extended inputs; where multiple schools of efficiency-driven approaches -- such as KV cache quantization, token dropping, prompt compression, linear-time sequence models, and hybrid architectures -- have been proposed to produce efficient yet long context-capable models. Despite these advancements, no existing work has comprehensively benchmarked these methods in a reasonably aligned environment. In this work, we fill this gap by providing a taxonomy of current methods and evaluating 10+ state-of-the-art approaches across seven categories of long context tasks. Our work reveals numerous previously unknown phenomena and offers insights -- as well as a friendly workbench -- for the future development of long context-capable LLMs. The source code will be available at https://github.com/henryzhongsc/longctx_bench", "venue": "", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A taxonomy of current methods and evaluating 10+ state-of-the-art approaches across seven categories of long context tasks is provided, which reveals numerous previously unknown phenomena and offers insights for the future development of long context-capable LLMs."}, "embedding": {"model": "specter_v2", "vector": [0.13299696147441864, 0.34468305110931396, -0.5577450394630432, -0.045545708388090134, -0.768866240978241, -0.4000285863876343, 0.6700318455696106, 0.24549119174480438, -0.5415019392967224, -0.23360610008239746, 0.9692762494087219, -0.10067605972290039, 0.10339797288179398, 0.2887192964553833, 0.11772536486387253, -0.06965288519859314, -0.8177684545516968, 0.2834399938583374, -0.3697393536567688, -0.21642865240573883, 0.20600059628486633, -0.8665967583656311, -0.3387987017631531, 0.1907341182231903, 0.9072967767715454, 0.04766508564352989, 0.31548625230789185, 1.1721971035003662, -0.719880223274231, 0.47065243124961853, 0.48501646518707275, -0.5702027082443237, -0.032159484922885895, -0.21111778914928436, -0.40610721707344055, -0.4989512860774994, 0.39864450693130493, -0.6539304852485657, -0.3582140803337097, 0.6484916806221008, 0.002675288822501898, -0.0585370771586895, 0.36231064796447754, -0.5872228145599365, -0.3919968605041504, 1.227196455001831, 0.7549452781677246, 0.8000874519348145, 0.06470537185668945, -0.49660927057266235, 1.6311805248260498, -1.5422717332839966, 0.32177069783210754, 1.2529997825622559, 0.644100546836853, 0.2373475432395935, 0.017724210396409035, -0.2829285264015198, 0.606883704662323, 0.3441789150238037, -0.7421337366104126, -0.5986686944961548, 0.12258078902959824, 0.17834503948688507, 1.8750532865524292, -0.20764942467212677, 0.2773541510105133, 0.7111921906471252, 0.08514442294836044, 1.5598080158233643, -0.5407876968383789, -0.9028592705726624, -0.10517411679029465, -0.39208099246025085, 0.226282000541687, 0.3565819263458252, -0.5097370743751526, 0.030136967077851295, -0.7903121113777161, -0.22023239731788635, 0.030339490622282028, -0.1424773633480072, -0.14871273934841156, 0.11216510832309723, -0.2378290593624115, 0.7058305144309998, -0.0018457280239090323, 0.7455611824989319, 0.03340910002589226, 0.5874608159065247, 0.7676023840904236, 0.3084450960159302, 0.3427361845970154, 0.412308931350708, -0.2877059578895569, -0.060412533581256866, -1.5553042888641357, 0.7266982197761536, 0.21268026530742645, 1.0522475242614746, -0.7299865484237671, 0.3600302040576935, -0.9535790085792542, 0.31225642561912537, 1.0909427404403687, 0.20813728868961334, 0.6099135279655457, -0.7331164479255676, 0.34870752692222595, -0.7673681378364563, 0.3500923216342926, -0.4872966408729553, -0.26788368821144104, -0.5024022459983826, -0.742780327796936, -1.645374059677124, -0.2830587327480316, 0.25053223967552185, -0.31170547008514404, 0.6258046627044678, -0.5526712536811829, 0.12987294793128967, 0.3972531855106354, 0.5087915658950806, 0.7034284472465515, 0.9121243953704834, 0.47196829319000244, -0.6181818842887878, 0.5884649753570557, -0.8937703967094421, -0.9295071363449097, -1.0177968740463257, 0.9115665555000305, -0.37726029753685, 0.7004969120025635, 0.03315954655408859, -1.6116549968719482, -0.8668686747550964, -0.8772422075271606, -0.3239900767803192, -0.42103832960128784, 0.3643738031387329, 0.6261383295059204, -0.0952029898762703, -0.9674948453903198, 0.7457752227783203, -0.14405210316181183, -0.07169368118047714, 0.14023087918758392, -0.14706122875213623, 0.3990563452243805, -0.5827755331993103, -1.2230145931243896, 0.24289578199386597, 0.06165538728237152, -0.6540062427520752, 0.07329767942428589, -0.5690351128578186, -1.1323728561401367, 0.32505419850349426, 0.5796255469322205, -0.3390956223011017, 1.4408519268035889, 0.06458835303783417, -0.9700489640235901, 0.03382902219891548, -0.44665420055389404, 0.05770339071750641, 0.32507026195526123, -0.5265681147575378, -0.4625592827796936, -0.13806532323360443, -0.08101768791675568, 0.397585928440094, 0.3604746162891388, -0.16574938595294952, -0.6297873258590698, 0.42981597781181335, -0.43404582142829895, 0.14534130692481995, -0.059659749269485474, 0.897712767124176, -0.4841025769710541, -0.22262826561927795, 0.07083643227815628, 0.8549506664276123, -0.032798413187265396, -0.38574182987213135, -0.4040899872779846, -1.1132748126983643, 0.850071907043457, -0.41466760635375977, 1.6840702295303345, -0.658243715763092, -0.7824711203575134, -0.4742075204849243, -0.09054108709096909, 0.12690691649913788, -0.7807728052139282, 1.068466305732727, 0.15004980564117432, 0.5611074566841125, -0.3049861490726471, -1.0737944841384888, 0.36851343512535095, -0.1616218388080597, -0.9504414796829224, -0.2667456567287445, 0.07980731874704361, 1.2007724046707153, -1.1085474491119385, -0.21235671639442444, -0.015750035643577576, 0.12312205880880356, -0.85445636510849, 1.0366710424423218, -0.4509177803993225, -0.028257256373763084, 0.12332537025213242, -0.1522587090730667, 0.0792158991098404, -0.16272175312042236, 0.6648641228675842, -0.4259989261627197, -0.2693127989768982, 0.3246408998966217, -0.4153691232204437, 1.3322144746780396, -0.050088588148355484, 0.6014214158058167, -0.3747817277908325, -0.41894692182540894, -0.3095308244228363, 0.663217306137085, -0.30312982201576233, -0.39525294303894043, 0.13614994287490845, 0.6208139657974243, -0.7670659422874451, 0.12620002031326294, 1.2282665967941284, 0.8286060690879822, -0.6623908281326294, -0.014467813074588776, 0.6217007040977478, -0.18295490741729736, 0.9831493496894836, 0.8440641164779663, 0.3735444247722626, 0.30495715141296387, 0.5890762805938721, -0.15215446054935455, 0.3326948583126068, -0.4620222747325897, -0.05258459597826004, 0.35683611035346985, 0.5061335563659668, 0.9752858877182007, 0.4979126751422882, -0.6281919479370117, -1.0293562412261963, 0.28665676712989807, 0.8363162279129028, 1.464105486869812, 0.06949251890182495, -0.9583969712257385, -0.8726704716682434, -0.16145677864551544, -0.49699074029922485, 0.255955308675766, -0.1162944883108139, -0.10569354891777039, -0.856774628162384, -0.7470627427101135, 0.9042030572891235, 0.536168098449707, 0.6422680616378784, -0.34477102756500244, -0.22490713000297546, 0.13731592893600464, -0.23935753107070923, -0.946901261806488, -0.7267879247665405, 0.19792860746383667, -0.6790238618850708, -0.480895072221756, 0.043984461575746536, -0.026655687019228935, -0.2877528965473175, -0.6177106499671936, 1.0501924753189087, -0.19588717818260193, -0.029071025550365448, 0.23876219987869263, 0.14434148371219635, -0.5679557919502258, -0.7786054015159607, 0.11802058666944504, 0.13716140389442444, -0.8322514891624451, 0.4608877897262573, 0.6523995399475098, -0.01588066667318344, -0.31510964035987854, -0.36600178480148315, 0.3910999894142151, 0.011057477444410324, 0.4022088944911957, 0.9264180660247803, -0.24775628745555878, 0.12515544891357422, -0.9913742542266846, 1.2321195602416992, 0.2551864683628082, -0.30110225081443787, 0.6473255157470703, -1.0452709197998047, -0.48397237062454224, 0.9125325083732605, -0.6557973623275757, -0.21029408276081085, -1.1070908308029175, 0.21563439071178436, -0.047401536256074905, -0.01686384342610836, 0.38689225912094116, 0.0576416552066803, 0.5546601414680481, 0.01143142580986023, 0.7702391147613525, -0.06432453542947769, -0.3237472474575043, 1.0073509216308594, -0.5810340046882629, 0.8763142824172974, 0.36102795600891113, -0.1893797218799591, -0.361796110868454, -0.12731215357780457, -0.4915178120136261, -0.16290517151355743, -0.5530782341957092, -0.5464929342269897, -0.10132154822349548, 0.12314558029174805, -0.6745341420173645, -0.25341126322746277, -0.21471484005451202, -0.8733515739440918, -0.1710381805896759, -0.18367379903793335, -0.5217381715774536, -0.38124826550483704, -0.7719258666038513, -1.5225906372070312, -0.4366903305053711, -1.04451322555542, -0.8396062850952148, 0.6279003024101257, -0.017790310084819794, -0.5243311524391174, -0.6581457257270813, 0.08377255499362946, -0.6697826385498047, 1.0125998258590698, -0.6130520701408386, 1.1112229824066162, -0.22619827091693878, 0.10820309817790985, -0.1440032571554184, 0.4331003427505493, 0.25469744205474854, -0.4995715916156769, 0.467255562543869, -0.6374064683914185, 0.10774832963943481, -0.32680630683898926, -0.14119748771190643, 0.06607727706432343, 0.6110791563987732, 0.22312143445014954, -0.3585900664329529, -0.46838223934173584, 0.4153258204460144, 1.4234340190887451, -0.6191611886024475, -0.06093469262123108, -0.09669259935617447, 1.1236302852630615, -0.007240759674459696, 0.14300082623958588, 0.6474263668060303, 0.06188402324914932, 0.0779794231057167, 0.14153966307640076, -0.17837998270988464, -0.005039943847805262, -0.6737186908721924, 0.5625913739204407, 2.2987301349639893, 0.2170320451259613, -0.31214913725852966, -0.8634742498397827, 0.7242946624755859, -1.2916069030761719, -0.9329777956008911, 0.3831576108932495, 0.43417084217071533, 0.4299819767475128, -0.6214938163757324, -0.14608880877494812, 0.3242681324481964, 0.1502467393875122, 0.33481571078300476, -0.11484739184379578, -0.8161762952804565, -0.13521406054496765, 0.1056654304265976, -0.0453808456659317, 0.5348943471908569, -0.4320126175880432, 0.8636923432350159, 14.74514389038086, 1.303987979888916, 0.09580383449792862, 0.5776289105415344, 0.6549714803695679, -0.1411198526620865, -0.4799528419971466, 0.0784536600112915, -1.1087262630462646, -0.10434924811124802, 1.5633410215377808, -0.2287604659795761, 0.4009357988834381, 0.28591388463974, 0.39155593514442444, 0.1896340250968933, -0.6079474687576294, 0.8148577213287354, 0.4646996259689331, -1.4013983011245728, 0.5530186891555786, 0.18581931293010712, 0.3932034969329834, 0.19037438929080963, 0.6011290550231934, 0.8260090351104736, -0.003971236292272806, -0.37460967898368835, 0.9820995926856995, -0.07130350917577744, 1.233253836631775, -0.5154902935028076, 0.6762295365333557, 0.7101567983627319, -1.016855239868164, -0.5975033044815063, -0.9643611311912537, -1.0377013683319092, 0.35954147577285767, 0.21539518237113953, -0.547467052936554, -0.12240665405988693, -0.5351566076278687, 0.6774219274520874, -0.0736762210726738, 0.5074027180671692, -0.1450492888689041, 1.131178379058838, 0.18332283198833466, 0.16460320353507996, 0.5745503902435303, 0.25021201372146606, 0.4030695855617523, 0.3543778657913208, 0.2600362300872803, 0.26285848021507263, 0.2923429310321808, 0.22932040691375732, -0.24212129414081573, 0.34936457872390747, -0.3218218982219696, -0.21541303396224976, 0.07299893349409103, 0.5697433948516846, 0.28688862919807434, -0.04545518010854721, -0.3787456750869751, 0.44556325674057007, 0.6196826100349426, 0.10597717761993408, -0.06346416473388672, 0.07235087454319, 0.062065839767456055, -0.47644373774528503, -0.021889911964535713, 0.4964364171028137, -0.20363424718379974, -0.666478157043457, -0.6794039011001587, -0.3033173084259033, 0.17377729713916779, -0.6562525629997253, -0.5748963952064514, 0.7692850232124329, 0.19452564418315887, -0.6489185690879822, -0.053147222846746445, -0.4313699007034302, -0.3959551751613617, 0.042821649461984634, -1.398892879486084, -0.9169964790344238, 0.45559775829315186, -0.3026241660118103, 0.17462439835071564, 0.24530252814292908, 1.1359299421310425, -0.06752878427505493, -0.16321305930614471, 0.36439943313598633, 0.7416220307350159, -0.19660653173923492, -0.2570554316043854, -0.9622905850410461, 0.7989712953567505, 0.658665657043457, -0.06726819276809692, 0.30916669964790344, 0.06305797398090363, -0.12918947637081146, -0.9263213872909546, -0.1376437395811081, 1.0041636228561401, -0.8982126116752625, -0.8855485320091248, -0.9789580702781677, -0.9332801699638367, -0.09509553015232086, 0.6048089861869812, -0.3462286591529846, 0.30092892050743103, -0.20826305449008942, -0.08787397295236588, -0.02059815265238285, -0.833770215511322, 0.038910236209630966, 0.546791136264801, -0.5916098356246948, -0.26546892523765564, -0.06867662817239761, 0.5422305464744568, -0.9805119037628174, -0.38078615069389343, -0.2872271239757538, 0.11139704287052155, 0.07292377203702927, 0.7108302712440491, -0.12742631137371063, 0.7940245866775513, 1.0622411966323853, -0.46184834837913513, -0.8343616724014282, -0.19429601728916168, -0.976520299911499, -0.3537975251674652, 0.45882561802864075, 0.42305561900138855, 0.22992561757564545, 0.07026050239801407, 0.8620637655258179, 0.21243421733379364, -0.8979421257972717, -0.7676564455032349, -0.2439037263393402, 0.5048502087593079, -0.595207691192627, 0.5518168807029724, -0.3045476973056793, 0.30378273129463196, -0.10842496156692505, 0.2164471447467804, 0.30109739303588867, -0.4826980531215668, -0.64466392993927, 0.19990995526313782, 0.25861412286758423, 0.24745409190654755, -0.4140680730342865, -0.14156906306743622, -1.2396831512451172, -0.08309156447649002, -0.8500849008560181, 0.0314054973423481, -1.1223163604736328, -0.16370239853858948, 0.2568173408508301, 0.006860217545181513, -0.2456614077091217, 0.10846786946058273, -0.5444833636283875, -0.08225341141223907, -0.38771504163742065, -0.8941668272018433, 0.9865171909332275, 0.7843665480613708, -0.8090854287147522, 0.07562320679426193, -0.3660639226436615, 0.04665901139378548, 0.1688833087682724, 0.30902087688446045, -0.2664845883846283, -1.0738393068313599, -1.2128386497497559, 0.474995493888855, -0.07293441146612167, -0.32881465554237366, -0.7065131664276123, 0.5091727375984192, 0.25404584407806396, 0.04011525213718414, -0.17270077764987946, 0.23864753544330597, -0.6603004932403564, -0.5007508993148804, 0.1844402402639389, -0.8846708536148071, 0.5448689460754395, -0.07949525117874146, -0.6059151291847229, -0.4550773501396179, 0.4822219908237457, -0.26080450415611267, -1.009304165840149, -0.6444798707962036, 0.2620105743408203, -0.6268715858459473, 0.15429002046585083, -0.6180741786956787, -0.18555046617984772, -0.9774117469787598, -0.4053341746330261, 0.3211263418197632, 0.2875201106071472, 0.09041798859834671, 0.6070321798324585, 0.6485797166824341, -1.0070325136184692, -0.11919756978750229, 0.21353554725646973, -0.2519012987613678, 0.10462836921215057, 0.41837015748023987, 0.09061015397310257, -0.21377965807914734, 0.7804791331291199, 0.6210209727287292, 0.21008777618408203, -1.0462133884429932, 0.04153182730078697, 0.36722689867019653, -0.8932738304138184, -0.4810851216316223, 1.0090214014053345, -0.6542695760726929, -0.7466940879821777, 0.06658302992582321, -1.514034390449524, -0.7148849368095398, -0.6306456923484802, 1.0285677909851074, 0.3688465356826782, -0.12900473177433014, -0.26808685064315796, -0.412715882062912, 0.29450723528862, 0.0038372459821403027, -0.5927157402038574, 0.5917602181434631, -0.5339892506599426, -0.15181809663772583, 0.4863400161266327, 0.7562697529792786, -0.6145073771476746, -0.6914392113685608, -0.37650275230407715, -0.11477344483137131, -0.21577641367912292, 0.2838582396507263, -0.6170303821563721, -0.10194088518619537, 0.8625929951667786, 0.5046753883361816, 0.24485664069652557, 0.4881748557090759, -0.24097110331058502, 0.6023268699645996, 0.6232022047042847, 0.08741865307092667, -0.9025269746780396, -0.8278904557228088, 1.2712552547454834, 1.238091230392456, -0.7709701657295227, 0.5343065857887268, 0.04816858470439911, -0.8244574069976807, 0.9903671145439148, 0.08656460046768188, -0.01433466374874115, 0.5193793773651123, -0.17699989676475525, 0.07133231312036514, 0.14780695736408234, -1.409726858139038, 0.12462341040372849, 0.6201369166374207, 1.0340616703033447, 0.6622864007949829, 0.21303299069404602, -0.18053343892097473, 1.358001470565796, 0.03782954812049866, 0.11352159082889557, 0.8111162185668945, 0.6168776750564575, -0.24563202261924744, -0.26772114634513855, 0.12740889191627502, 0.7025673985481262, -0.9224671125411987, -0.9374804496765137, 0.13860951364040375, 0.510476291179657, 0.09703825414180756, 1.0033146142959595, 0.5102378726005554, 0.24438390135765076, 0.25425803661346436, 0.38948482275009155, 0.5892135500907898, -0.37125295400619507, -0.41424211859703064, 0.32297632098197937, -0.5488234758377075, -0.10253347456455231, 0.016180627048015594, -0.5864966511726379, -0.4034607708454132, -0.21402020752429962, -0.0466204471886158, 0.27419498562812805, 0.37116581201553345, 1.1515097618103027, 0.5271973013877869, 0.12175494432449341, -0.5724195837974548, -0.5563417673110962, -0.5375723838806152, -1.0097057819366455, -0.1990603506565094, -0.054924264550209045, -0.19464650750160217, 0.23901726305484772, 0.11922688037157059, 0.05419732257723808]}, "authors": [{"authorId": "2307845512", "name": "Jiayi Yuan"}, {"authorId": "2289776023", "name": "Hongyi Liu"}, {"authorId": "2181946372", "name": "Shaochen Zhong"}, {"authorId": "27615982", "name": "Yu-Neng Chuang"}, {"authorId": "2307516698", "name": "Songchen Li"}, {"authorId": "32780441", "name": "Guanchu Wang"}, {"authorId": "2307476923", "name": "Duy Le"}, {"authorId": "1791983892", "name": "Hongye Jin"}, {"authorId": "2144559840", "name": "V. Chaudhary"}, {"authorId": "2276485344", "name": "Zhaozhuo Xu"}, {"authorId": "2305052067", "name": "Zirui Liu"}, {"authorId": "2282544390", "name": "Xia Hu"}], "references": [{"paperId": "7318a804566baadc9f4b4ca8255f78744e749a32", "title": "QJL: 1-Bit Quantized JL Transform for KV Cache Quantization with Zero Overhead"}, {"paperId": "d7ee15521fcfd8704c8422997614b2b22f5e1148", "title": "Contextual Position Encoding: Learning to Count What's Important"}, {"paperId": "8a3df7b9cb6c323da340a4871ae705d0063f28bf", "title": "KV Cache is 1 Bit Per Channel: Efficient Large Language Model Inference with Coupled Quantization"}, {"paperId": "1784c987e681d60c634765fe64c8d9c26f73d5ff", "title": "SnapKV: LLM Knows What You are Looking for Before Generation"}, {"paperId": "fe33be95849c556ce0bdffaa1d2c7db9bb2e2c61", "title": "RecurrentGemma: Moving Past Transformers for Efficient Open Language Models"}, {"paperId": "46732358e98ce6be0c564ae11f71d556a64b4c35", "title": "HGRN2: Gated Linear RNNs with State Expansion"}, {"paperId": "d8b51d518f2dd62943762ceaa8961d3b1bfbcc1a", "title": "RULER: What's the Real Context Size of Your Long-Context Language Models?"}, {"paperId": "2717e5c7384ec12cfd6cf9c34897c6adad3230ed", "title": "Long-context LLMs Struggle with Long In-context Learning"}, {"paperId": "cbaf689fd9ea9bc939510019d90535d6249b3367", "title": "Jamba: A Hybrid Transformer-Mamba Language Model"}, {"paperId": "41b47f33a24feefd6728bdc1339d0d4ff5fec7be", "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context"}, {"paperId": "7a54aad06171f59149aca5380863c62729c70b41", "title": "GEAR: An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM"}, {"paperId": "a48a3cfde9e9a6f02821ea28698012e4d3e1cd73", "title": "QAQ: Quality Adaptive Quantization for LLM KV Cache"}, {"paperId": "d53fe76bd2795a19ddf52d012917782f6f6f2c1e", "title": "Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models"}, {"paperId": "e19485777bce53f2301f1137133fd9436d9896ea", "title": "Learning to Compress Prompt in Natural Language Formats"}, {"paperId": "89e0fde2dc60f8520c176a57396c6cad3af5dc40", "title": "No Token Left Behind: Reliable KV Cache Compression via Importance-Aware Mixed Precision Quantization"}, {"paperId": "f05e84702562cb693dd68d3d1c88072519a7bd71", "title": "\u221eBench: Extending Long Context Evaluation Beyond 100K Tokens"}, {"paperId": "a3e000e0d7f64c1d094c2a8bf6f43992cbabe91b", "title": "KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache"}, {"paperId": "b085968c4362fb286ad6c5ef71a5db9630da0498", "title": "KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization"}, {"paperId": "9266dc3c65334e36a12fef7e4b231091d346b8a4", "title": "LLM360: Towards Fully Transparent Open-Source LLMs"}, {"paperId": "62b18cc55dcc7ffe52c28e1086aee893b7bc4334", "title": "Gated Linear Attention Transformers with Hardware-Efficient Training"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "9529e50807f36acf3d2e4af994b5803c47e4746a", "title": "Atom: Low-bit Quantization for Efficient and Accurate LLM Serving"}, {"paperId": "6c323c535365e1c7cbfd9703cbec3b5650a3346b", "title": "Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0", "title": "Qwen Technical Report"}, {"paperId": "b31a5884a8ebe96b6300839b28608b97f8f8ef76", "title": "LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding"}, {"paperId": "0b0debb710366cdff461938c80763eace1651af6", "title": "Code Llama: Open Foundation Models for Code"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "240103933ffe3dac2179cc160a2bd91299357a53", "title": "Retentive Network: A Successor to Transformer for Large Language Models"}, {"paperId": "d6eeb2898bd9bd34744194ef543062dda6c4531a", "title": "Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time"}, {"paperId": "60b35c6d68acced19b0c66edcfc0ee0a2c11efed", "title": "Landmark Attention: Random-Access Infinite Context Length for Transformers"}, {"paperId": "2f7364d8e5cf94315bf8905f57de9c5543e9a4bf", "title": "Adapting Language Models to Compress Contexts"}, {"paperId": "b9870e130f61ff900fe00dbcc5782c9b31773d32", "title": "Learning to Compress Prompts with Gist Tokens"}, {"paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8", "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"}, {"paperId": "7bf72a3b5fbac8bc0f461780810fbc781c28ef53", "title": "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society"}, {"paperId": "42a14d824caa3348046eb34c37e2ab7985faa7a3", "title": "High-throughput Generative Inference of Large Language Models with a Single GPU"}, {"paperId": "712573cc74633ec2283724e868328fd2d319c091", "title": "Ten Lessons We Have Learned in the New \"Sparseland\": A Short Handbook for Sparse Neural Network Researchers"}, {"paperId": "2aab6ca1a8dae3f3db6d248231ac3fa4e222b30a", "title": "Re3: Generating Longer Stories With Recursive Reprompting and Revision"}, {"paperId": "4afda39036206dcb3f97829dccb897f1fc80f459", "title": "Prompt Compression and Contrastive Conditioning for Controllability and Toxicity Reduction in Language Models"}, {"paperId": "70e91e16eb321067d9402710e14a40cf28311f73", "title": "Mega: Moving Average Equipped Gated Attention"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "1a4c6856292b8c64d19a812a77f0aa6fd47cb96c", "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework"}, {"paperId": null, "title": "2023a. How long can context length of open-source llms truly promise?"}, {"paperId": null, "title": "2024. Infllm: Unveiling the intrinsic capacity of llms for understanding extremely long sequences with training-free memory"}, {"paperId": null, "title": "2024c. H2o: Heavy-hitter oracle for efficient generative inference of large language models"}, {"paperId": null, "title": "2024. Challenges in deploying long-context transformers: A theoretical peak performance"}, {"paperId": null, "title": "2023. Effi-ciently scaling transformer inference"}, {"paperId": null, "title": "2024. Skvq: Sliding-window key and value cache quantization for large language models"}, {"paperId": null, "title": "2024. Same task, more tokens: the impact of input length on the reasoning performance of large language models"}, {"paperId": null, "title": "2023. Mamba-chat"}]}