{"paperId": "f9bfc6d9ba1665b73af3323d46c7642b852759ef", "title": "VideoLLM: Modeling Video Sequence with Large Language Models", "abstract": "With the exponential growth of video data, there is an urgent need for automated technology to analyze and comprehend video content. However, existing video understanding models are often task-specific and lack a comprehensive capability of handling diverse tasks. The success of large language models (LLMs) like GPT has demonstrated their impressive abilities in sequence causal reasoning. Building upon this insight, we propose a novel framework called VideoLLM that leverages the sequence reasoning capabilities of pre-trained LLMs from natural language processing (NLP) for video sequence understanding. VideoLLM incorporates a carefully designed Modality Encoder and Semantic Translator, which convert inputs from various modalities into a unified token sequence. This token sequence is then fed into a decoder-only LLM. Subsequently, with the aid of a simple task head, our VideoLLM yields an effective unified framework for different kinds of video understanding tasks. To evaluate the efficacy of VideoLLM, we conduct extensive experiments using multiple LLMs and fine-tuning methods. We evaluate our VideoLLM on eight tasks sourced from four different datasets. The experimental results demonstrate that the understanding and reasoning capabilities of LLMs can be effectively transferred to video understanding tasks. We release the code at https://github.com/cg1177/VideoLLM.", "venue": "arXiv.org", "year": 2023, "citationCount": 50, "influentialCitationCount": 2, "openAccessPdf": {"url": "http://arxiv.org/pdf/2305.13292", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes a novel framework called VideoLLM that leverages the sequence reasoning capabilities of pre-trained LLMs from natural language processing (NLP) for video sequence understanding and demonstrates that the understanding and Reasoning capabilities of LLMs can be effectively transferred to video understanding tasks."}, "embedding": {"model": "specter_v2", "vector": [0.12866026163101196, 0.5255593657493591, -0.32479286193847656, -0.27722012996673584, -0.4481452405452728, -0.373201847076416, 0.6229541897773743, -0.02567341923713684, -0.35495737195014954, -0.061117932200431824, 0.801319420337677, 0.010317814536392689, 0.4705336391925812, 0.18556953966617584, -0.24579215049743652, 0.2510325610637665, -0.8900642395019531, 0.012153630144894123, 0.10940846800804138, -0.09935954958200455, -0.019796421751379967, -0.7458726763725281, -0.8145177364349365, 0.6943827867507935, 0.35822951793670654, 0.539681613445282, 0.19419515132904053, 0.9865456819534302, -0.13936877250671387, 1.0247613191604614, 0.6540276408195496, 0.06715037673711777, 0.3515744209289551, 0.09358862042427063, -0.45972514152526855, 0.11502250283956528, 0.14726243913173676, -0.608746349811554, -1.040347933769226, 0.496168851852417, -0.5216075778007507, 0.3640190660953522, 0.6988379955291748, -1.1627159118652344, -0.19667057693004608, 0.8986058831214905, 0.5818458199501038, 0.657960057258606, 0.4085904359817505, -0.49801209568977356, 1.547385334968567, -1.1948636770248413, 0.45957881212234497, 2.050825595855713, 0.274790495634079, 0.5251966118812561, 0.10414581000804901, -0.4789940118789673, 0.8112367987632751, 0.541836142539978, -0.6805747747421265, -0.07148223370313644, -0.7849854230880737, -0.3531499207019806, 1.7460318803787231, -0.6767770648002625, -0.20336927473545074, 1.031234860420227, 0.01594104990363121, 1.7530051469802856, -0.37589991092681885, -0.5251094102859497, -0.2941333055496216, -0.16558603942394257, 0.0768691673874855, 1.0540109872817993, -0.6109049320220947, 0.26223859190940857, -1.1537140607833862, -0.07239380478858948, 0.6441349983215332, 0.004304556641727686, -0.6680796146392822, -0.006274634972214699, -0.647739827632904, 0.8427438735961914, 0.2610078752040863, 0.5390442609786987, -0.11008869856595993, 0.41563814878463745, 0.8051252365112305, 0.4617985188961029, -0.24443306028842926, 0.08601817488670349, -0.31334376335144043, 0.13897919654846191, -0.7101747989654541, 0.2994607388973236, 0.161139577627182, 1.0269120931625366, -0.6162363290786743, 0.1885444074869156, -0.7784065008163452, 0.06664194166660309, 1.654576301574707, 0.11470635235309601, 0.4083453416824341, -0.9661421775817871, 0.5420518517494202, -0.7919908761978149, 0.298248827457428, -0.4747121036052704, -0.30100318789482117, 0.394879013299942, -0.3574901223182678, -1.051776647567749, -0.10897458344697952, 0.0697462186217308, -1.1954565048217773, 0.8062052726745605, -0.6696915626525879, 0.276951402425766, 0.3136051893234253, 0.12497369199991226, 0.8158007264137268, 0.9808675050735474, 0.6500924229621887, -0.23059380054473877, 1.1050610542297363, -0.627231240272522, -0.4667510688304901, -0.8903712630271912, 0.8735649585723877, 0.023303287103772163, -0.10330543667078018, -0.35739490389823914, -1.0323516130447388, -1.1756232976913452, -0.38472768664360046, -0.3211008608341217, -0.14217989146709442, 0.21313075721263885, 0.6742268800735474, 0.08773031830787659, -1.1436522006988525, 0.7581737637519836, -0.11019663512706757, -0.6200456619262695, 0.6261963248252869, -0.20922501385211945, -0.03761133924126625, -0.5406555533409119, -1.3746541738510132, 0.4376721978187561, 0.5078168511390686, -0.4696202874183655, -0.8488093018531799, -0.6304423213005066, -1.7252488136291504, -0.14839819073677063, 0.6256566643714905, -0.697573721408844, 1.3258485794067383, -0.04084385558962822, -0.6386945247650146, 0.5708110332489014, -0.8031827211380005, -0.24830831587314606, 0.6341953277587891, -0.5274964570999146, -0.23817025125026703, 0.11693856120109558, 0.05006833374500275, 0.6992742419242859, 0.3050684630870819, -0.4068310856819153, -0.9546894431114197, 0.21352837979793549, -0.006826870143413544, -0.06250852346420288, 0.26455408334732056, 1.2245421409606934, -0.20208831131458282, -0.1871553659439087, 0.05961846187710762, 0.9572626352310181, -0.016354043036699295, 0.15820954740047455, -0.18594703078269958, -1.107444405555725, 0.8145573139190674, -0.5720481276512146, 0.39002659916877747, -0.8314316868782043, -0.4983956515789032, -0.5262523889541626, 0.21930959820747375, -0.16732685267925262, -1.0515868663787842, 0.7087799310684204, -0.21321165561676025, 0.5674428343772888, -0.20073212683200836, -1.0083564519882202, -0.20765994489192963, -0.1384526491165161, -0.8462750911712646, -0.3270823359489441, 0.18120898306369781, 1.159630298614502, -0.9422728419303894, -0.38349616527557373, 0.2947905361652374, 0.01268981397151947, -0.7418593168258667, 1.4384552240371704, -0.42892229557037354, 0.22386537492275238, -0.6268625259399414, -0.18414726853370667, -0.11220523715019226, -0.14744222164154053, 0.4375501275062561, -0.8850589990615845, -0.08617249876260757, -0.03267722949385643, 0.005339456256479025, 1.5030457973480225, -0.21176080405712128, 0.9168345332145691, -0.5511140823364258, -0.8914424180984497, -0.07251887768507004, 1.1590439081192017, -0.07657025009393692, -0.1027640700340271, 0.4748205840587616, -0.08087980002164841, -0.8942174315452576, -0.8780578970909119, 0.20149900019168854, 0.49992474913597107, -0.1326998472213745, 0.3062274754047394, 0.5438747406005859, -0.14804355800151825, 0.8204821944236755, 0.7823036313056946, 0.9710019826889038, 0.5448595285415649, 0.5845252275466919, 0.3712941110134125, 0.2565484344959259, -0.6549453735351562, 0.11143810302019119, 0.909812867641449, 0.5886278748512268, 0.9437628984451294, 0.6458820700645447, -0.7517707347869873, -0.4797303080558777, -0.08563613891601562, 0.9779792428016663, 1.0004463195800781, 0.05722716078162193, -0.30101102590560913, -0.6250515580177307, -0.533240795135498, -0.2573118507862091, 0.4344196319580078, -0.42584946751594543, -0.07576540112495422, -0.32416728138923645, -0.5102964043617249, 0.8571016192436218, 1.056308388710022, 1.2274222373962402, -0.7693474292755127, -0.05657206103205681, -0.4311331808567047, -0.4417880177497864, -1.3947277069091797, -0.21348822116851807, -0.2548586130142212, -0.5265339612960815, -0.5687455534934998, 0.2908913791179657, -0.003475082805380225, 0.16595585644245148, -0.5393840074539185, 0.7659720182418823, -0.5515075922012329, -0.5518174767494202, 0.4619898796081543, 0.027253132313489914, -0.6305680274963379, -0.7861966490745544, -0.562500536441803, 0.18577654659748077, -0.17584122717380524, 0.4969274699687958, 0.765971839427948, 0.35502538084983826, 0.26567599177360535, -0.44436904788017273, 0.30710288882255554, 0.08384931832551956, -0.09961170703172684, -0.049672309309244156, 0.24282890558242798, -0.05480074882507324, -0.8536350131034851, 0.6619601845741272, -0.0956013947725296, -0.13719061017036438, 0.44706955552101135, 0.052991632372140884, -0.5484251976013184, 0.4282834231853485, -0.5489445328712463, -0.6821098923683167, -0.8067604899406433, 0.5199628472328186, -0.30211564898490906, -0.9979769587516785, 0.4149494171142578, 0.12192582339048386, 0.39708593487739563, 0.02174447663128376, 0.48314234614372253, 0.47268226742744446, -0.10015343874692917, 0.4461861252784729, -0.9341827034950256, 0.4395228624343872, 0.46504074335098267, 0.1907939314842224, 0.33249983191490173, -0.3259734511375427, -0.9096059799194336, -0.7809230089187622, -0.5030277967453003, -0.6209132075309753, -0.4520408511161804, 0.6611093282699585, -0.8697913289070129, -1.0407832860946655, -0.07946919649839401, -1.2694673538208008, -0.3543080687522888, 0.5637449026107788, 0.052044209092855453, -0.47727036476135254, -0.683363139629364, -1.288285255432129, -0.4458732604980469, 0.07099796086549759, -0.7235990166664124, 0.3001738488674164, 0.2026323676109314, -0.718675434589386, -0.8583850264549255, -0.6001515984535217, 0.10439642518758774, 0.3915509581565857, -0.37238967418670654, 1.1659026145935059, -0.06564277410507202, -0.3653099238872528, -0.28507423400878906, -0.10132510215044022, 0.5224968194961548, -0.10322850942611694, 0.1763322651386261, -0.6848774552345276, 0.13693717122077942, -0.06814797222614288, -0.3233988285064697, 0.3559712767601013, 0.800662636756897, 0.6018869280815125, 0.8162710070610046, -0.6659514307975769, -0.06917749345302582, 1.4063410758972168, -0.24196410179138184, -0.17724695801734924, -0.07179870456457138, 1.3492696285247803, 0.5246896147727966, 0.05102502182126045, 0.5189136266708374, 0.32311052083969116, 0.042794518172740936, 0.05887222662568092, -0.2216338813304901, 0.17576636373996735, -0.6528501510620117, 0.7372505068778992, 0.3916545808315277, -0.30006763339042664, -0.48401814699172974, -1.1223068237304688, 0.6034665107727051, -1.8737496137619019, -0.8297869563102722, 0.5108826756477356, 0.32504257559776306, -0.30795010924339294, -0.47344639897346497, -0.2572893798351288, -0.06419678777456284, 0.6916766166687012, 0.04705209285020828, -0.04107958823442459, -0.30356910824775696, 0.0996890589594841, -0.26000168919563293, 0.06812591850757599, 0.5158427953720093, -0.6485403180122375, 0.5371018052101135, 14.369357109069824, 0.6942466497421265, 0.24673908948898315, 0.27911773324012756, 0.3036280870437622, 0.2841850221157074, -0.06504080444574356, -0.10454214364290237, -1.0189882516860962, -0.6999969482421875, 0.9762703776359558, -0.028731947764754295, 0.22399459779262543, -0.2415468990802765, 1.1086347103118896, -0.21156170964241028, -1.0769970417022705, 0.8934351801872253, 0.7385887503623962, -1.0609694719314575, 1.0142631530761719, -0.030369238927960396, -0.23864173889160156, 0.16317632794380188, 0.31867942214012146, 0.9551785588264465, 0.22441472113132477, -0.8586478233337402, 0.8673626780509949, -0.0035295153502374887, 0.5935879945755005, 0.0967407301068306, 0.5932885408401489, 0.6449764966964722, -1.3976130485534668, -0.8469500541687012, -0.5977152585983276, -1.083219051361084, 1.0387667417526245, -0.3832605481147766, -0.4105767011642456, 0.056225329637527466, -0.16822932660579681, 1.3209556341171265, 0.3737460672855377, 0.5786819458007812, -0.6007463932037354, 0.6911477446556091, 0.46816980838775635, 0.40085285902023315, 0.33321166038513184, 0.547795295715332, 0.3991488218307495, -0.3615497648715973, 0.07381122559309006, 0.46596580743789673, 0.4224594831466675, 0.4079895317554474, -0.3722943365573883, -0.30238693952560425, -0.8815997838973999, -0.46699362993240356, -0.2764861285686493, 0.25895416736602783, 0.14110985398292542, 0.06541293859481812, -0.8148563504219055, 0.14593584835529327, 0.12827935814857483, 0.4203178584575653, -0.628910481929779, 0.3139301538467407, 0.37120476365089417, -0.49768826365470886, 0.1571028083562851, 0.5288103818893433, -0.014927887357771397, -0.8725116848945618, -0.7579765915870667, -0.35751256346702576, 0.6634712219238281, -0.9302812814712524, -0.879558801651001, 0.914763331413269, 0.20561201870441437, -0.748777449131012, 0.29405760765075684, -1.0421355962753296, -0.44837865233421326, 0.0740552544593811, -1.2050871849060059, -1.0645108222961426, -0.030638230964541435, 0.28478220105171204, 0.6096102595329285, 0.18629427254199982, 1.16549551486969, -0.22946204245090485, -0.3450784981250763, -0.53545081615448, -0.39045262336730957, 0.17217105627059937, -0.0351627916097641, -0.4820449650287628, 0.37670791149139404, 0.32452794909477234, -0.08389372378587723, 0.0492340512573719, 0.16593371331691742, -0.3497964143753052, -0.5040324330329895, -0.030387792736291885, 0.7298229932785034, -1.0241259336471558, -0.18212765455245972, -0.7626582384109497, -0.9077170491218567, 0.6688564419746399, 0.3660498857498169, -0.48025405406951904, 0.17955787479877472, -0.1306571364402771, -0.7000640034675598, 0.2588863968849182, -0.9332565665245056, 0.005843534134328365, 0.4534524083137512, -0.7889142036437988, -0.8538933396339417, 0.03853096440434456, 0.37600407004356384, -0.4976707100868225, -0.35129162669181824, -0.22371461987495422, -0.011130278930068016, 0.23442353308200836, 0.7336726784706116, -0.769671618938446, 1.1031770706176758, 0.7174420356750488, 0.09005408734083176, -0.7285378575325012, 0.0015267390990629792, -0.6779289245605469, 0.45363110303878784, 0.06824639439582825, 0.6292692422866821, -0.16766653954982758, -0.12119273841381073, 0.9292641878128052, 0.4135719835758209, 0.09150862693786621, -0.2625808119773865, -0.015379424206912518, -0.11386977136135101, -0.7590981721878052, -0.38295841217041016, -0.3760596811771393, 0.11037345975637436, -0.13594229519367218, 0.2443351149559021, 1.1862952709197998, -0.09124835580587387, -0.7039291262626648, 0.17238958179950714, -0.19026437401771545, 0.14679569005966187, -0.17058269679546356, -0.5906822681427002, -1.3382484912872314, 0.4747656285762787, -0.7122858166694641, 0.2744695842266083, -1.3935236930847168, -0.19068847596645355, 0.97980797290802, 0.08742465823888779, 0.2562367916107178, 0.35977423191070557, -0.49259358644485474, -0.16553255915641785, -0.7654865384101868, -0.6017575263977051, 0.37898653745651245, 0.8594903945922852, -0.681276261806488, 0.3680046796798706, -0.15718375146389008, 0.1978060007095337, 0.7070578336715698, 0.19235512614250183, -0.3564569056034088, -1.099556565284729, -1.2802233695983887, 0.06103597581386566, 0.23768649995326996, 0.27860674262046814, -0.347699373960495, 0.4531853199005127, 0.2673902213573456, -0.02300790511071682, 0.06842580437660217, 0.4045397639274597, -0.7304862141609192, -1.0273619890213013, 0.28180935978889465, -1.0845355987548828, -0.16252250969409943, 0.39313292503356934, -0.1011253297328949, -0.6364087462425232, 0.7939955592155457, -0.217116117477417, -1.3569403886795044, -1.2597808837890625, 0.4907338619232178, -1.1947391033172607, -0.09883717447519302, 0.29580554366111755, -0.10569485276937485, -0.9557055234909058, -0.7397269606590271, -0.2910524904727936, 0.9523097276687622, -0.5795089602470398, 1.2754249572753906, 1.0994243621826172, -0.5867925882339478, -0.31955209374427795, 0.018727069720625877, -0.08619869500398636, -0.05335541442036629, 0.7917746305465698, 0.33515220880508423, -0.12722128629684448, 0.48584094643592834, 0.21631087362766266, 0.4118107259273529, -1.2912250757217407, 0.04043984040617943, 0.7039206624031067, 0.13526518642902374, -0.507536768913269, 1.1288529634475708, 0.41340115666389465, -0.4994780421257019, 0.4012615382671356, -1.1296072006225586, -1.0451505184173584, -0.3207014799118042, 1.0793068408966064, 0.10143250972032547, -0.5692123174667358, -0.07520044595003128, -0.2898368835449219, 0.5659096837043762, -0.05232624709606171, -0.6609722971916199, 0.5791332721710205, -0.5892246961593628, -0.34966254234313965, 0.8999274373054504, 0.6253125667572021, -1.2998896837234497, -0.7482569217681885, -0.36039963364601135, -0.3730204701423645, -0.295255184173584, 0.22383397817611694, -0.19396843016147614, -0.5062618851661682, 0.7945380806922913, 0.18244293332099915, 0.3444163501262665, -0.010918204672634602, 0.00021334225311875343, 0.23146064579486847, 0.5572200417518616, 0.11787872761487961, -0.4013363718986511, -0.5395492911338806, 1.0659172534942627, 1.2379344701766968, -1.1265883445739746, 0.02808130346238613, -0.7876765727996826, -1.1218057870864868, 1.3201624155044556, 0.3726738691329956, -0.056684017181396484, 0.7174395322799683, -0.3207980990409851, 0.28439414501190186, 0.17580381035804749, -1.175296664237976, -0.24716967344284058, 0.6436607837677002, 1.2375245094299316, 0.7599939107894897, 0.2586360275745392, 0.16112364828586578, 0.35913729667663574, 0.5524293184280396, 0.8805251717567444, 0.7495020627975464, 0.3390215337276459, -0.1668219417333603, 0.12702476978302002, 0.13290904462337494, 0.6052365303039551, -0.41732296347618103, -0.37629711627960205, 0.3422481417655945, 0.5464165806770325, 0.12479628622531891, 1.0890811681747437, 0.7053049206733704, 0.3191138803958893, 0.5551133155822754, 0.254369854927063, 0.5093823075294495, -0.900377631187439, 0.04428534954786301, -0.21728019416332245, -0.28949615359306335, -0.5548239350318909, -0.5990733504295349, -0.6077545881271362, -0.8545401096343994, 0.05461687967181206, 0.8646553158760071, -0.045157674700021744, -0.02638838440179825, 1.8271312713623047, 0.15281018614768982, 0.3366786241531372, -0.6439237594604492, -0.30123254656791687, -0.10320144891738892, -0.8082964420318604, -0.13666504621505737, -0.4052969515323639, -0.06900174170732498, -0.35780659317970276, -0.3570995032787323, 0.39141738414764404]}, "authors": [{"authorId": "2155229619", "name": "Guo Chen"}, {"authorId": "1391155455", "name": "Yin-Dong Zheng"}, {"authorId": "2110182417", "name": "Jiahao Wang"}, {"authorId": "3259789", "name": "Jilan Xu"}, {"authorId": "48355651", "name": "Yifei Huang"}, {"authorId": "7588865", "name": "Junting Pan"}, {"authorId": "46393411", "name": "Yi Wang"}, {"authorId": "47903936", "name": "Yali Wang"}, {"authorId": "145858545", "name": "Y. Qiao"}, {"authorId": "2113488744", "name": "Tong Lu"}, {"authorId": "2141353278", "name": "Limin Wang"}], "references": [{"paperId": "42a30dc5470f54ec249f25d3c31e05d7c376c8e3", "title": "VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks"}, {"paperId": "d48cb91b9e555194f7494c4d4bb9815021d3ee45", "title": "VideoChat: Chat-Centric Video Understanding"}, {"paperId": "54a8b153ed04a872da878d695239bdc413dc782c", "title": "InternGPT: Solving Vision-Centric Tasks by Interacting with Chatbots Beyond Language"}, {"paperId": "5ff420f47210eb711b99d5b5c7d36cd0fd3c2073", "title": "Boundary-Denoising for Video Activity Localization"}, {"paperId": "9fac3d0728a8c833a593446e3e176e90d856df04", "title": "VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking"}, {"paperId": "c7a9c7302a72301ed79a7c0696d5af2e03ad3ac4", "title": "MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "8ec3b00a5ce99e213af9eb993fcbfad762d2e864", "title": "NaQ: Leveraging Narrations as Queries to Supervise Episodic Memory"}, {"paperId": "933b37b21e9d61139660088adb032ff3fdf56d86", "title": "Learning Video Representations from Large Language Models"}, {"paperId": "325d8e9501af05e594bd668b6cd6d43ed42c8b4d", "title": "InternVideo: General Video Foundation Models via Generative and Discriminative Learning"}, {"paperId": "637d25af0e96915c30fa20f21e3b9ad16e61a764", "title": "InternVideo-Ego4D: A Pack of Champion Solutions to Ego4D Challenges"}, {"paperId": "b2286da2b293b50644e5dc8ddd75eb8651e8b257", "title": "UniFormerV2: Spatiotemporal Learning by Arming Image ViTs with Video UniFormer"}, {"paperId": "78281482c1fdad8e167bab39cc9955c73d58ae8f", "title": "EVA: Exploring the Limits of Masked Visual Representation Learning at Scale"}, {"paperId": "26c80bd65baa90f5b18157de4951f4eb0b62ab69", "title": "InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions"}, {"paperId": "6d751b55fd0579be3135e4b044c9060e3f2dca0d", "title": "Real-time Online Video Detection with Temporal Smoothing Transformers"}, {"paperId": "87fadaab89b05f1b2abadfbdf8176af5f90b73f1", "title": "Egocentric Video-Language Pretraining"}, {"paperId": "004b97aea43f9f62cc49dec20f449abfbae28811", "title": "Masked Autoencoders As Spatiotemporal Learners"}, {"paperId": "17be543e77981a9cf6c6d8f6329805209b981688", "title": "BasicTAD: an Astounding RGB-Only Baseline for Temporal Action Detection"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "4990f7542f0600e0501a7e7a931b32eb7cb804d5", "title": "VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training"}, {"paperId": "92dd395cc99890013946c6293b0417376e936f3e", "title": "UMT: Unified Multi-modal Transformers for Joint Video Moment Retrieval and Highlight Detection"}, {"paperId": "fa717a2e31f0cef4e26921f3b147a98644d2e64c", "title": "Focal Modulation Networks"}, {"paperId": "095ccdb08837a4b44a62638fb8dc391818707e5a", "title": "All in One: Exploring Unified Video-Language Pre-Training"}, {"paperId": "58a3fedc03ab9f5908c077c115eff4c8d2d87660", "title": "ActionFormer: Localizing Moments of Actions with Transformers"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "b3848d32f7294ec708627897833c4097eb4d8778", "title": "LaMDA: Language Models for Dialog Applications"}, {"paperId": "c8831d0629f0eaf7f723317d71bbd60b8eb3c39f", "title": "UniFormer: Unified Transformer for Efficient Spatiotemporal Representation Learning"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "fa85c6c09bec52f11feb6cb5b96e854d87a13ed9", "title": "DCAN: Improving Temporal Action Detection via Dual Context Aggregation"}, {"paperId": "b4713949345551ebb6763f83004f9da68b760b6f", "title": "ASFormer: Transformer for Action Segmentation"}, {"paperId": "848eb8367785910c2fe31372605954ad8f9dfe6c", "title": "Ego4D: Around the World in 3,000 Hours of Egocentric Video"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "b82c5f9efdb2ae56baa084ca41aeddd8a665c1d1", "title": "Align before Fuse: Vision and Language Representation Learning with Momentum Distillation"}, {"paperId": "ab7fff96e2cacb5a183ad23fe4ca50df942c17d2", "title": "Long Short-Term Transformer for Online Action Detection"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "12f9e3261cbf353c56077883f6345e656b6df21b", "title": "OadTR: Online Action Detection with Transformers"}, {"paperId": "2f5f8e60a1c8cea0a0ba669305f0020854549ddd", "title": "End-to-End Temporal Action Detection With Transformer"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "7fff8018bf625447df837c2fda5c58a705fbc038", "title": "XCiT: Cross-Covariance Image Transformers"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "2982181f864209269203eadacbad9a69770fd338", "title": "Anticipative Video Transformer"}, {"paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6", "title": "Multiscale Vision Transformers"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "bac87bdb1cabc35fafb8176a234d332ebcc02864", "title": "Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval"}, {"paperId": "b6382a7351c0c595f91472ac71d3b2d87b3c4844", "title": "ViViT: A Video Vision Transformer"}, {"paperId": "b3bf9fe13195e9aa70e1dac04e01fcff7008e812", "title": "Perceiver: General Perception with Iterative Attention"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "616e0ed02ca024a8c1d4b86167f7486ea92a13d9", "title": "VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning"}, {"paperId": "ba4a4d31d2af23eefadbf19e5efd5a7d4fd89143", "title": "Less is More: CLIPBERT for Video-and-Language Learning via Sparse Sampling"}, {"paperId": "141a5033d9994242b18bb3b217e79582f1ee9306", "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"}, {"paperId": "fa08b41ccdfc5d8771adfbc34c176fa237d4646c", "title": "Is Space-Time Attention All You Need for Video Understanding?"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "2ad2981a53393dc5987419a22cbe1ee3d7fa6e42", "title": "TDN: Temporal Difference Networks for Efficient Action Recognition"}, {"paperId": "9548d5646e3d2900bea9ced28554ec9bc4505b86", "title": "Video Self-Stitching Graph Network for Temporal Action Localization"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "83b4bc669079649690867f4e670c74cd692cf8f2", "title": "Real-Time Deep Learning Approach to Visual Servo Control and Grasp Detection for Autonomous Robotic Manipulation"}, {"paperId": "07c06df8314d3b96423b7512e67b820f575a57e3", "title": "Temporal Aggregate Representations for Long-Range Video Understanding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "f26fb60a6f9ad68b3e10fd809a1414deee808c0e", "title": "Rescaling Egocentric Vision: Collection, Pipeline and Challenges for EPIC-KITCHENS-100"}, {"paperId": "3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb", "title": "TAM: Temporal Adaptive Module for Video Recognition"}, {"paperId": "5a975dcd3dba2a11830e5595d4c4659441cb6836", "title": "Span-based Localizing Network for Natural Language Video Localization"}, {"paperId": "faa84a405a5ce2b7b0eaa7bd90d329894cbb3be4", "title": "Human action recognition using fusion of multiview and deep features: an application to video surveillance"}, {"paperId": "2b3c599cb85369e153acbd39beeac1cc60cb25dd", "title": "G-TAD: Sub-Graph Localization for Temporal Action Detection"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "81f5810fbbab9b7203b9556f4ce3c741875407bc", "title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans"}, {"paperId": "792829f263a523eedf1a8748ec23d25cf664c2b4", "title": "What Would You Expect? Anticipating Egocentric Actions With Rolling-Unrolling LSTMs and Modality Attention"}, {"paperId": "f4852f5385d60e8870e30db5c65392d120e58574", "title": "Video Classification With Channel-Separated Convolutional Networks"}, {"paperId": "b4673e744d0ded47fe6df3b6314f79a41359578b", "title": "MS-TCN: Multi-Stage Temporal Convolutional Network for Action Segmentation"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "8b47b9c3c35b2b2a78bff7822605b3040f87d699", "title": "SlowFast Networks for Video Recognition"}, {"paperId": "49e2b4db35a408e91353578764be9085ac1210da", "title": "BSN: Boundary Sensitive Network for Temporal Action Proposal Generation"}, {"paperId": "89c3050522a0bb9820c32dc7444e003ef0d3e2e4", "title": "A Closer Look at Spatiotemporal Convolutions for Action Recognition"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "b61a3f8b80bbd44f24544dc915f52fd30bbdf485", "title": "Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset"}, {"paperId": "86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6", "title": "The Kinetics Human Action Video Dataset"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "b8d3b24cd4e6477e9dc7979580449db962d50e19", "title": "CUHK & ETHZ & SIAT Submission to ActivityNet Challenge 2016"}, {"paperId": "ea3d7de6c0880e14455b9acb28f1bc1234321456", "title": "Temporal Segment Networks: Towards Good Practices for Deep Action Recognition"}, {"paperId": "fbfb0ede13691804ec5a17babe443c223deb0b9a", "title": "Online Action Detection"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "f8ae17c3ef3754967b62f4a4bc34cfc2f6d93719", "title": "Generating Notifications for Missing Actions: Don't Forget to Turn the Lights Off!"}, {"paperId": "0a28efacb92d16e6e0dd4d87b5aca91b28be8853", "title": "ActivityNet: A large-scale video benchmark for human activity understanding"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "185f078accb52be4faa13e4f470a9909cc6fe814", "title": "The Language of Actions: Recovering the Syntax and Semantics of Goal-Directed Human Activities"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "d1120d67b700e4dfe8b39eb1e48fbdea4e1a0c43", "title": "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face"}, {"paperId": null, "title": "Chatgpt: Optimizing language models for dialogue"}, {"paperId": "18316673291b537b74eee1b369009379688da73a", "title": "Detecting Moments and Highlights in Videos via Natural Language Queries"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "2022. A ConvNet for the 2020s"}, {"paperId": null, "title": "2023. GPT-4 Technical Report"}]}