{"paperId": "2330035c7586a0dc0b1f09e9c00106b295acf543", "title": "Long-Context Language Modeling with Parallel Context Encoding", "abstract": "Extending large language models (LLMs) to process longer inputs is crucial for a wide range of applications. However, the substantial computational cost of transformers and limited generalization of positional encoding restrict the size of their context window. We introduce Context Expansion with Parallel Encoding (CEPE), a framework that can be applied to any existing decoder-only LLMs to extend their context window. CEPE employs a small encoder to process long inputs chunk by chunk, enabling the frozen decoder to utilize additional contexts via cross-attention. CEPE is efficient, generalizable, and versatile: trained with 8K-token documents, it extends the context window of LLAMA-2 to 128K tokens, offering 10x the throughput with only 1/6 of the memory. CEPE yields strong performance on language modeling and in-context learning. CEPE also excels in retrieval-augmented applications, while existing long-context models degenerate with retrieved contexts. We further introduce a CEPE variant that can extend the context window of instruction-tuned models using only unlabeled data, and showcase its effectiveness on LLAMA-2-CHAT, leading to a strong instruction-following model that can leverage very long contexts on downstream tasks.", "venue": "arXiv.org", "year": 2024, "citationCount": 10, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces Context Expansion with Parallel Encoding (CEPE), a framework that can be applied to any existing decoder-only LLMs to extend their context window, and introduces a CEPE variant that can extend the context window of instruction-tuned models using only unlabeled data."}, "embedding": {"model": "specter_v2", "vector": [0.26868996024131775, 0.13666990399360657, -0.5297116041183472, -0.05034874752163887, -0.650843620300293, -0.17877881228923798, 0.5999693274497986, 0.022881221026182175, -0.6566067934036255, -0.03986694663763046, 0.7924548983573914, -0.5068625211715698, 0.6921623945236206, 0.3723360300064087, -0.2135210633277893, 0.08781886845827103, -1.1440186500549316, 0.0811658650636673, 0.03714101389050484, -0.3160720467567444, -0.06341306120157242, -0.7322444319725037, -0.8245095014572144, 0.4545981287956238, 0.37364697456359863, 0.35040855407714844, 0.4555262625217438, 0.8506965637207031, -0.651968240737915, 0.3460383415222168, 0.40588584542274475, -0.19028785824775696, 0.11345253139734268, 0.051371511071920395, -0.3326857388019562, -0.40191125869750977, 0.17532850801944733, -0.5190799236297607, -0.24419410526752472, 0.3004501760005951, -0.28569528460502625, 0.19534306228160858, 0.2621009051799774, -0.37139442563056946, -0.32198983430862427, 1.0002467632293701, 0.6781255602836609, 0.6053946614265442, -0.4121297001838684, -0.9115875363349915, 1.4338973760604858, -1.4843755960464478, 0.12125314772129059, 1.1150251626968384, 0.5266914963722229, 0.6330627202987671, -0.0016731382347643375, -0.42968690395355225, 1.049796462059021, 0.16889427602291107, -0.5579153895378113, -0.3220348656177521, -0.16591434180736542, 0.17928676307201385, 1.893120288848877, -0.2524365782737732, 0.2723291218280792, 0.6661068201065063, 0.015030083246529102, 1.4959958791732788, -0.2249593585729599, -1.0400493144989014, -0.34542474150657654, -0.039789702743291855, 0.4554613530635834, 0.4965379238128662, -0.44958817958831787, 0.35467585921287537, -0.5726549625396729, -0.002838435582816601, 0.23915496468544006, 0.2694781422615051, 0.22643528878688812, 0.016115408390760422, -0.27320078015327454, 0.32376980781555176, 0.2097126543521881, 1.0099210739135742, 0.042915716767311096, 0.7604928016662598, 0.5742400288581848, 0.26693713665008545, 0.14928306639194489, 0.34246957302093506, -0.2141396701335907, 0.018390651792287827, -1.0073273181915283, 0.30158835649490356, -0.42399680614471436, 0.8770207166671753, -0.22480660676956177, -0.04695359990000725, -0.6341384649276733, 0.323677659034729, 1.2472143173217773, 0.15639269351959229, 0.4878169894218445, -0.6435196399688721, 0.40832144021987915, -0.7862626910209656, 0.0759795531630516, -0.08790716528892517, -0.0828947201371193, -0.2553226053714752, -0.20155514776706696, -1.495173692703247, -0.6227021217346191, -0.09336552768945694, -0.3133920133113861, 0.7173239588737488, -0.12715771794319153, 0.5334891080856323, 0.43334513902664185, 0.09032870829105377, 0.246519073843956, 0.7572686672210693, 0.20828668773174286, -0.24005936086177826, 0.8181020617485046, -1.2304798364639282, -0.7086572647094727, -1.2411456108093262, 1.2050237655639648, -0.1583818942308426, 0.35795700550079346, -0.3426297605037689, -0.9934145212173462, -0.6278948783874512, -0.9829474091529846, -0.13170787692070007, -0.7819931507110596, 0.10144240409135818, 0.7503718137741089, 0.40200871229171753, -0.8948294520378113, 0.8177674412727356, -0.30013298988342285, 0.1390802413225174, 0.21480242908000946, 0.040003981441259384, 0.3451171815395355, -0.4442678987979889, -1.422499179840088, 0.21429194509983063, 0.287794828414917, -0.6463776230812073, -0.0620795376598835, -0.7809855341911316, -1.2199878692626953, -0.16849879920482635, 0.5707316398620605, -0.05387866497039795, 1.6308937072753906, -0.058271411806344986, -1.3575032949447632, 0.1925755888223648, -0.4726376533508301, 0.24217911064624786, -0.0725279226899147, -0.38480237126350403, -0.7755634188652039, -0.3571401834487915, -0.3127777576446533, 0.3443661034107208, 0.08003989607095718, -0.27457839250564575, -0.5656592845916748, -0.1073095053434372, -0.3595784604549408, 0.2962830364704132, -0.15904384851455688, 0.8981301188468933, -0.5853008031845093, -0.1924188882112503, -0.1253945380449295, 0.6644638180732727, -0.07221781462430954, -0.5425032377243042, -0.0398724339902401, -0.8577263355255127, 1.2477425336837769, -0.15822122991085052, 1.3603345155715942, -0.8633832931518555, -0.945516049861908, -0.32004231214523315, -0.4189760088920593, 0.2157144546508789, -0.8580759167671204, 0.7428091168403625, -0.18748891353607178, 0.6106078624725342, -0.06565879285335541, -1.3391245603561401, -0.14576788246631622, 0.01166616939008236, -0.7876065969467163, -0.6471837759017944, 0.2175353616476059, 1.0811666250228882, -1.2216778993606567, 0.041185714304447174, -0.34841999411582947, 0.33213651180267334, -1.1126984357833862, 1.0243815183639526, -0.6299887895584106, 0.46457192301750183, -0.1471027433872223, -0.232620969414711, -0.24775704741477966, -0.1476164013147354, 0.7264350056648254, -0.033519238233566284, -0.257535457611084, 0.7459645867347717, -0.2996584177017212, 1.1146647930145264, -0.9245420098304749, 0.5639251470565796, 0.04030044749379158, -0.3569566011428833, -0.24315860867500305, 0.5101516842842102, -0.14170975983142853, -0.45018813014030457, 0.2166341245174408, 0.5586575269699097, -0.7088996767997742, 0.13948549330234528, 1.1702334880828857, 0.8188211917877197, -0.40954601764678955, 0.29797354340553284, 0.4171309173107147, -0.09883204102516174, 0.47405239939689636, 0.471612811088562, 0.5317457318305969, 0.6715460419654846, 0.3621097505092621, 0.17917500436306, 0.2705499827861786, -1.0733191967010498, -0.15191379189491272, 0.18591181933879852, 0.48432594537734985, 0.6081590056419373, 0.3712819218635559, -0.3535534739494324, -0.5905584692955017, 0.4641589820384979, 0.6254338622093201, 1.752596378326416, -0.25750744342803955, -0.3025027811527252, -0.7994020581245422, -0.5791515707969666, -0.30900540947914124, 0.31871476769447327, -0.22766858339309692, 0.02477301098406315, -0.8833191990852356, -0.4873161017894745, 0.822098970413208, 0.7201407551765442, 0.8836773037910461, -0.35561662912368774, -0.2767057418823242, -0.2588105797767639, 0.02509228140115738, -0.9026742577552795, -0.9064789414405823, 0.41388532519340515, -0.725031852722168, -0.014875131659209728, 0.2030535489320755, -0.29578936100006104, -0.10809697955846786, -0.6355917453765869, 0.8621377944946289, -0.0660795271396637, -0.004725481383502483, 0.48234933614730835, 0.2651175260543823, -0.5834548473358154, -0.980845034122467, 0.18466490507125854, 0.2921428084373474, -0.36934125423431396, 0.4619840979576111, 0.5180543065071106, 0.2440354973077774, -0.15606877207756042, -0.2221592664718628, 0.3012619912624359, 0.19142644107341766, 0.25481685996055603, 0.8208591341972351, -0.7130690217018127, 0.3018348217010498, -1.296012043952942, 0.8227488398551941, 0.14157052338123322, -0.3407101035118103, 0.4372985363006592, -0.8546696901321411, -0.5157759189605713, 0.6449026465415955, -0.5383588075637817, -0.4391956925392151, -1.1646554470062256, 0.16572578251361847, -0.18665729463100433, -0.3149050772190094, 0.27697980403900146, 0.15720529854297638, 0.5558652877807617, -0.14665134251117706, 0.5810665488243103, 0.24462886154651642, -0.2524050772190094, 0.6960617899894714, -0.3482799530029297, 0.35623788833618164, 0.028899360448122025, -0.2944149971008301, -0.34307152032852173, -0.14516033232212067, -0.7953994870185852, -0.19429007172584534, -0.6965218186378479, -0.4899156093597412, -0.21391989290714264, 0.052792876958847046, -0.48104551434516907, -0.4610808789730072, -0.2439797967672348, -1.02294921875, -0.4614344537258148, 0.2101111114025116, -0.2950030267238617, -0.21964192390441895, -0.9326164722442627, -1.1538678407669067, -0.6910621523857117, -0.6830766201019287, -1.0566579103469849, 0.47107675671577454, 0.00483438977971673, -0.20700792968273163, -0.7566545605659485, 0.03634835407137871, -0.48026013374328613, 0.7009020447731018, -1.0317022800445557, 0.7857846617698669, -0.25657764077186584, -0.08612976223230362, -0.27019956707954407, 0.41308391094207764, 0.6175183057785034, -0.30408477783203125, 0.35928088426589966, -0.8876261115074158, 0.3215119540691376, -0.46749716997146606, -0.2433585375547409, 0.09034598618745804, 0.08309456706047058, 0.6769654750823975, 0.02075822278857231, -0.8344403505325317, 0.1350679099559784, 1.3042668104171753, -0.190266415476799, 0.06296329945325851, -0.0052618286572396755, 0.8647988438606262, 0.06660906225442886, -0.11545564234256744, 0.2334991991519928, 0.10714126378297806, 0.3213862180709839, 0.06745339930057526, 0.28739625215530396, 0.060057517141103745, -0.656430721282959, 0.6222636699676514, 1.754472255706787, 0.24576865136623383, 0.21174976229667664, -1.0157356262207031, 0.8454009294509888, -0.9826186895370483, -0.7404813766479492, 0.868416428565979, 0.7171903252601624, 0.64409339427948, -0.7599215507507324, -0.4544314444065094, -0.4154173731803894, 0.37940436601638794, 0.3485536575317383, -0.242608904838562, -0.7915017604827881, 0.22183020412921906, 0.23615214228630066, -0.09753305464982986, 0.875485897064209, -0.3512228727340698, 0.6411130428314209, 14.796260833740234, 0.8723622560501099, -0.0513136200606823, 0.745902419090271, 0.6305235624313354, -0.1127735897898674, -0.5069687962532043, -0.11903273314237595, -1.357129454612732, -0.10074138641357422, 1.5602210760116577, 0.4040915369987488, 0.4645461142063141, 0.004384955856949091, 0.15665824711322784, 0.24718603491783142, -0.7561928629875183, 0.39395400881767273, 0.4385972321033478, -1.319355845451355, 0.28124740719795227, 0.17565667629241943, 0.4270900785923004, 0.6384773850440979, 0.8766767382621765, 1.1703523397445679, 0.3619697093963623, -0.08186426013708115, 0.27078089118003845, 0.001654087333008647, 1.1096071004867554, -0.24240213632583618, 0.1853056401014328, 0.6323011517524719, -0.7607728242874146, -0.5479860901832581, -0.2983110845088959, -1.0233083963394165, 0.22387108206748962, -0.1625513732433319, -0.706365168094635, -0.37261009216308594, -0.32473209500312805, 0.6500484347343445, 0.14123369753360748, 0.11218554526567459, -0.12392086535692215, 0.7269498705863953, 0.058194804936647415, -0.2739630937576294, 0.5305365324020386, 0.28450992703437805, 0.27531713247299194, 0.30647480487823486, -0.06812465190887451, 0.271754652261734, 0.047323182225227356, 0.027578985318541527, -0.6115475296974182, 0.20471665263175964, -0.5873053669929504, -0.11417436599731445, 0.13082076609134674, 0.5460418462753296, 0.8427990674972534, -0.13862107694149017, -0.624358594417572, 0.16813313961029053, 0.5806142687797546, 0.2897811233997345, -0.2605615258216858, 0.03891896829009056, 0.4854092001914978, -0.5304486155509949, 0.06804590672254562, 0.492978572845459, 0.02530796453356743, -0.5675578117370605, -0.730647087097168, -0.2990448772907257, 0.09101392328739166, -0.7396877408027649, -0.35666754841804504, 0.8007185459136963, -0.03630554676055908, -0.43935781717300415, 0.013982969336211681, -0.9598526954650879, -0.24501322209835052, 0.356410413980484, -1.335270881652832, -0.5958953499794006, 0.8190121650695801, -0.4224354922771454, -0.39334771037101746, 0.20099730789661407, 1.3782343864440918, 0.35805827379226685, -0.5164899230003357, 0.15224789083003998, 0.7635987997055054, 0.09670620411634445, -0.10405625402927399, -0.8129971027374268, 0.5145794749259949, 0.35215115547180176, -0.05359077826142311, 0.2893896996974945, -0.2885591387748718, 0.03123474307358265, -0.46805474162101746, -0.3428703248500824, 0.8248043060302734, -1.0154374837875366, -0.4394555687904358, -0.8860044479370117, -0.7876666188240051, 0.5934175252914429, 0.8534346222877502, -0.3070835471153259, 0.7359826564788818, 0.3622165322303772, -0.5888539552688599, -0.19457098841667175, -0.5705437064170837, 0.618911623954773, 0.6246894598007202, -0.7849875092506409, -0.33859407901763916, -0.21946078538894653, 0.7538203597068787, -1.1398816108703613, -0.5954602360725403, -0.2924669682979584, 0.22654300928115845, -0.09762024879455566, 0.8294660449028015, -0.37883204221725464, 0.976978063583374, 1.213832139968872, -0.27597689628601074, -0.8382557034492493, 0.1976684033870697, -0.6668201088905334, -0.2881065309047699, 0.20287998020648956, 0.6861921548843384, -0.2651079297065735, -0.1101095899939537, 0.74860680103302, 0.021543946117162704, -1.059119462966919, -0.6191732287406921, -0.3038172125816345, 0.450205534696579, -0.8319374322891235, 0.6344995498657227, 0.017948808148503304, 0.3513217866420746, 0.13278962671756744, 0.6273966431617737, 0.5680177211761475, -0.507190465927124, -0.81133633852005, 0.16948457062244415, 0.3810250461101532, -0.1157158613204956, -0.6869457364082336, -0.36139756441116333, -1.4795308113098145, 0.037205539643764496, -1.0775305032730103, -0.014865663833916187, -0.5397387742996216, -0.42348727583885193, -0.028121767565608025, -0.2560668885707855, 0.07628080248832703, 0.08434434980154037, -0.571483314037323, -0.23246999084949493, -0.7179555892944336, -0.8040087819099426, 0.8511690497398376, 0.8519253134727478, -0.582539975643158, 0.20862863957881927, -0.13342449069023132, 0.2256576269865036, 0.06299275159835815, 0.4056178629398346, -0.08295779675245285, -0.8566536903381348, -1.4640125036239624, 0.20136243104934692, -0.1265571564435959, -0.32931777834892273, -0.49225977063179016, 0.2826414108276367, 0.32162341475486755, -0.2601674795150757, -0.17812204360961914, 0.21483634412288666, -0.9210065007209778, -0.8470557928085327, 0.10503307729959488, -1.0519063472747803, 0.39589259028434753, 0.568271815776825, -0.38536059856414795, -0.25861188769340515, 0.3939407467842102, -0.4591039717197418, -0.9932377934455872, -0.9904871582984924, 0.28162410855293274, -0.8802367448806763, 0.10186193883419037, -0.28666451573371887, 0.06988551467657089, -0.9387921094894409, -0.29900333285331726, 0.039611030369997025, 0.5391830205917358, -0.279069185256958, 0.9772562384605408, 0.3082183003425598, -1.0719401836395264, 0.2093225121498108, 0.3649160861968994, -0.10432006418704987, 0.22010646760463715, 0.6788710951805115, 0.4262319505214691, -0.0812525674700737, 0.8068162202835083, 0.6280114650726318, 0.253591388463974, -1.2213917970657349, 0.12015675753355026, 0.7883444428443909, -0.8619065284729004, 0.062869131565094, 0.9928115010261536, -0.576768696308136, -1.214423418045044, -0.02146817371249199, -1.5535935163497925, -0.7877947688102722, -0.5318008065223694, 1.0963151454925537, 0.0755636915564537, 0.0565514974296093, 0.029049690812826157, -0.4170322120189667, 0.07441560924053192, -0.19014334678649902, -0.597244143486023, 0.412178635597229, -0.45128926634788513, -0.2376404106616974, 0.8214181065559387, 1.0674456357955933, -0.45974206924438477, -0.8015851974487305, -0.725919783115387, -0.46127158403396606, 0.12506917119026184, 0.35678887367248535, -0.6302102208137512, -0.2335744947195053, 0.8734716176986694, 0.43206027150154114, 0.2232288420200348, 0.059660304337739944, -0.26158416271209717, 0.2944088578224182, 0.8515641093254089, 0.2139190286397934, -0.8358874917030334, -0.570428729057312, 1.5089267492294312, 1.2677732706069946, -0.9351504445075989, 0.18105007708072662, 0.15870152413845062, -0.7232999205589294, 0.7258991599082947, 0.3993591368198395, 0.26953431963920593, 0.9954633116722107, -0.10041441768407822, 0.40209537744522095, 0.5105358362197876, -1.3736263513565063, 0.07826325297355652, 0.5000471472740173, 1.0744729042053223, 0.7905129790306091, 0.46316033601760864, 0.1760549247264862, 1.1960461139678955, 0.4456441104412079, -0.07789994776248932, 0.5558676719665527, 0.7187273502349854, -0.022518226876854897, -0.44201865792274475, -0.04575353115797043, 0.6000443696975708, -0.7835490107536316, -0.995377779006958, 0.3328002691268921, 0.5369382500648499, 0.32044166326522827, 0.6638001203536987, 1.1537525653839111, 0.032038364559412, 0.324950635433197, 0.7125607132911682, 0.5586264133453369, -0.6654769778251648, -0.4354398250579834, -0.2030886709690094, -0.5621810555458069, -0.16359445452690125, -0.06415767222642899, -0.5419142842292786, -0.5923028588294983, -0.007030571810901165, 0.19828273355960846, 0.20917491614818573, 0.20513413846492767, 1.3327821493148804, 0.8210651278495789, 0.4261304438114166, -0.3186388313770294, -0.42853114008903503, -0.4508932828903198, -0.9822804927825928, -0.1256280392408371, -0.5847994089126587, -0.02134837582707405, 0.12432748824357986, 0.40571141242980957, -0.29203328490257263]}, "authors": [{"authorId": "2287806228", "name": "Howard Yen"}, {"authorId": "2256993940", "name": "Tianyu Gao"}, {"authorId": "50536468", "name": "Danqi Chen"}], "references": [{"paperId": "1d4c48335d841014d0145256c3c4e7f6c426b8fb", "title": "You Only Cache Once: Decoder-Decoder Architectures for Language Models"}, {"paperId": "f288e2238ac8725baa7ca9874bbc3fed1e89a632", "title": "Data Engineering for Scaling Language Models to 128K Context"}, {"paperId": "189fde3f4dfa105bb51472a8945618f395919560", "title": "Repeat After Me: Transformers are Better than State Space Models at Copying"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "37680e5cb6030e01f1a44a5abe2257972196ae26", "title": "Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2"}, {"paperId": "368fb35a07076eba01c2e4700499323cd4524513", "title": "RA-DIT: Retrieval-Augmented Dual Instruction Tuning"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "5e0cb1c4b91a7486e1c2b15a44a0be56bd74bdc0", "title": "Effective Long-Context Scaling of Foundation Models"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "cbbc2cc774c50b0b19922185b80e9ce90b7cd2f6", "title": "Retrieval-Pretrained Transformer: Long-range Language Modeling with Self-retrieval"}, {"paperId": "2f7364d8e5cf94315bf8905f57de9c5543e9a4bf", "title": "Adapting Language Models to Compress Contexts"}, {"paperId": "e7c97e953849f1a8e5d85ceb4cfcc0a5d54d2365", "title": "Enabling Large Language Models to Generate Text with Citations"}, {"paperId": "eb511ae6b9f04e4936891d26787f274b48b99d57", "title": "ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding"}, {"paperId": "dbc368bc8b49347dd27679894524fa62f88492c9", "title": "Unlimiformer: Long-Range Transformers with Unlimited Length Input"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "3d68522abfadfc8ee6b7ec9edaaf91f1b2f38e5e", "title": "Large Language Models Can Be Easily Distracted by Irrelevant Context"}, {"paperId": "07b14c24833400b79978b0a5f084803337e30a15", "title": "REPLUG: Retrieval-Augmented Black-Box Language Models"}, {"paperId": "980e55d9226cac302d0fae7732da4e67b8bc952c", "title": "Parallel Context Windows for Large Language Models"}, {"paperId": "c6ee979c2da4b55a8486abae4cd720422ab09b26", "title": "When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories"}, {"paperId": "e65b346d442e9962a4276dc1c1af2956d9d5f1eb", "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions"}, {"paperId": "eecb45aa040064cbc0b37fd100706c02e7dc880e", "title": "Structured Prompting: Scaling In-Context Learning to 1, 000 Examples"}, {"paperId": "398e4061dde8f5c80606869cebfa2031de7b5b74", "title": "Few-shot Learning with Retrieval Augmented Language Models"}, {"paperId": "732e3faec4e5be4d144256f2c379b9dc49f0b227", "title": "Efficient Long-Text Understanding with Short-Text Models"}, {"paperId": "6a483cd1cbecd66150c9bbcd01606723950281bc", "title": "Prototypical Calibration for Few-shot Learning of Language Models"}, {"paperId": "0286b2736a114198b25fb5553c671c33aed5d477", "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "6281c40c66febca1d8003bcc6fdfd2189b30c38f", "title": "SCROLLS: Standardized CompaRison Over Long Language Sequences"}, {"paperId": "3c209e0703ffff26231b1145268c935df494631a", "title": "QuALITY: Question Answering with Long Input Texts, Yes!"}, {"paperId": "4f4a409f701f7552d45c46a5b0fea69dca6f8e84", "title": "Unsupervised Dense Information Retrieval with Contrastive Learning"}, {"paperId": "002c256d30d6be4b23d365a8de8ae0e67e4c9641", "title": "Improving language models by retrieving from trillions of tokens"}, {"paperId": "3dc7dc1bea9a4f70c02b6759a0bda7aca0005a9e", "title": "A General Language Assistant as a Laboratory for Alignment"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "a4ffce66918cfb33150a60bf8e26419199e63b01", "title": "BookSum: A Collection of Datasets for Long-form Narrative Summarization"}, {"paperId": "4e3935ef7da6bcbb202ec7f8b285c313cadcd044", "title": "A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "0adec918885dff698acf359988ed79a543157f80", "title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"}, {"paperId": "9d81bc8bebf1beb936427c224afb219b54a64f1e", "title": "Surface Form Competition: Why the Highest Probability Answer Isn\u2019t Always Right"}, {"paperId": "9dc624d7258d1a56117ca720aea953ce46b66b21", "title": "Efficient Attentions for Long Document Summarization"}, {"paperId": "aa28873534c24e4a8c5deb7bff723cd5fc69a6f0", "title": "QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization"}, {"paperId": "56fa0b9cba4d9aee5ccc327365b3b3a721031c69", "title": "Calibrate Before Use: Improving Few-Shot Performance of Language Models"}, {"paperId": null, "title": "Transformers: State-of-the-Art Natural Language Processing"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "54bc3e055d05e44c010febc669e8dea394643efc", "title": "Adding Recurrence to Pretrained Transformers for Improved Efficiency and Context Size"}, {"paperId": "ea8c46e193d5121e440daf96edfd15a47151c293", "title": "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "b26f2037f769d5ffc5f7bdcec2de8da28ec14bee", "title": "Dense Passage Retrieval for Open-Domain Question Answering"}, {"paperId": "5a96a270cbc73e3b448c2404ff31670c21da7b49", "title": "Efficient Intent Detection with Dual Sentence Encoders"}, {"paperId": "832fff14d2ed50eb7969c4c4b976c35776548f56", "title": "REALM: Retrieval-Augmented Language Model Pre-Training"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "499556c6ed1daec62e5a57456213cf4f921460f1", "title": "An Evaluation Dataset for Intent Classification and Out-of-Scope Prediction"}, {"paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0", "title": "Natural Questions: A Benchmark for Question Answering Research"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "a81874b4a651a740fffbfc47ef96515e8c7f782f", "title": "Latent Retrieval for Weakly Supervised Open Domain Question Answering"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "9f1e350a97a4f5f3809c350be6db3e75f0bebf43", "title": "Benchmarking Natural Language Understanding Services for building Conversational Agents"}, {"paperId": "d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a", "title": "The NarrativeQA Reading Comprehension Challenge"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"}, {"paperId": "51a55df1f023571a7e07e338ee45a3e3d66ef73e", "title": "Character-level Convolutional Networks for Text Classification"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "7b36c5602930abf08efd2867f92cdb48a1be757a", "title": "Together"}, {"paperId": "6af58c061f2e4f130c3b795c21ff0c7e3903278f", "title": "Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales"}, {"paperId": "d2161251488dbba08616a9cdd4223a0ac1190cef", "title": "Building a question answering test collection"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "2023. Nonparametric masked language modeling"}, {"paperId": null, "title": "2022. SummScreen: A dataset for abstrac-tive screenplay summarization"}, {"paperId": null, "title": "2020 Conference on Empirical Methods in"}, {"paperId": null, "title": "2022. Ef-ficiently modeling long sequences with structured state spaces"}, {"paperId": null, "title": "Seattle, United States"}, {"paperId": null, "title": "2024. Needle in a haystack - pressure testing"}, {"paperId": null, "title": "Chapter of the Association for Computational Lin-guistics (NAACL)"}, {"paperId": null, "title": "Models Use Long Contexts"}, {"paperId": null, "title": "2023. A dataset of python files from github"}, {"paperId": null, "title": "2023b. Lon-glora: Efficient fine-tuning of long-context large language models"}, {"paperId": null, "title": "2024a. InfLLM: Unveiling the intrinsic capacity of LLMs for understanding extremely long sequences with training-free memory"}, {"paperId": null, "title": "2024. Lost in the Middle: How Language"}, {"paperId": null, "title": "2023. Stanford Alpaca An Instruction-following LLaMA model"}]}