{"paperId": "2b35b946a8ad64e018c24b283bc1c6c65d36fb67", "title": "Retrieval meets Long Context Large Language Models", "abstract": "Extending the context window of large language models (LLMs) is getting popular recently, while the solution of augmenting LLMs with retrieval has existed for years. The natural questions are: i) Retrieval-augmentation versus long context window, which one is better for downstream tasks? ii) Can both methods be combined to get the best of both worlds? In this work, we answer these questions by studying both solutions using two state-of-the-art pretrained LLMs, i.e., a proprietary 43B GPT and Llama2-70B. Perhaps surprisingly, we find that LLM with 4K context window using simple retrieval-augmentation at generation can achieve comparable performance to finetuned LLM with 16K context window via positional interpolation on long context tasks, while taking much less computation. More importantly, we demonstrate that retrieval can significantly improve the performance of LLMs regardless of their extended context window sizes. Our best model, retrieval-augmented Llama2-70B with 32K context window, outperforms GPT-3.5-turbo-16k and Davinci003 in terms of average score on nine long context tasks including question answering, query-based summarization, and in-context few-shot learning tasks. It also outperforms its non-retrieval Llama2-70B-32k baseline by a margin, while being much faster at generation. Our study provides general insights on the choice of retrieval-augmentation versus long context extension of LLM for practitioners.", "venue": "arXiv.org", "year": 2023, "citationCount": 38, "influentialCitationCount": 1, "openAccessPdf": {"url": "https://arxiv.org/pdf/2310.03025", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "It is found that LLM with 4K context window using simple retrieval-augmentation at generation can achieve comparable performance to finetuned LLM with 16K context window via positional interpolation on long context tasks, while taking much less computation."}, "embedding": {"model": "specter_v2", "vector": [-0.0127119654789567, 0.14389005303382874, -0.4961991608142853, -0.12462737411260605, -0.785346508026123, -0.19119298458099365, 0.8344718217849731, -0.13107644021511078, -0.5233795046806335, -0.025399507954716682, 0.974535346031189, 0.11620201915502548, 0.4011155068874359, 0.23267163336277008, -0.09515687823295593, 0.23802559077739716, -1.0729352235794067, 0.20177562534809113, 0.11069279909133911, -0.6505696177482605, -0.06335486471652985, -1.0238298177719116, -0.8255215287208557, 0.2784367799758911, 0.6022167205810547, 0.2738693356513977, 0.32072895765304565, 1.0064411163330078, -0.4121345281600952, 0.23818576335906982, 0.4507325291633606, -0.08351105451583862, 0.009460082277655602, -0.20184266567230225, -0.35832086205482483, -0.08453603088855743, 0.37512046098709106, -0.571269154548645, -0.37080880999565125, 0.14485935866832733, 0.14160116016864777, 0.5752362608909607, 0.40469980239868164, -0.3276938796043396, -0.5366275906562805, 0.6602523922920227, 0.4764255881309509, 0.49042031168937683, -0.12682239711284637, -0.6575836539268494, 1.4535775184631348, -1.4685888290405273, 0.30240869522094727, 1.58366060256958, 0.26913511753082275, 0.42666199803352356, -0.027756812050938606, -0.4129370152950287, 0.7737117409706116, -0.012941330671310425, -0.8859416246414185, -0.404876172542572, -0.27604979276657104, 0.08936323970556259, 1.9366204738616943, -0.19189539551734924, -0.17475467920303345, 0.5356369018554688, -0.21175098419189453, 1.5771691799163818, -0.7688997387886047, -0.7674059271812439, -0.25422996282577515, -0.2548474371433258, 0.4728148281574249, 0.2648336589336395, -0.37615081667900085, 0.02611710876226425, -0.5464784502983093, -0.35646554827690125, -0.05049055069684982, -0.006750803906470537, -0.16133441030979156, 0.11810460686683655, -0.27550482749938965, 0.7958596348762512, 0.2070421427488327, 0.850603461265564, 0.06720447540283203, 0.8770340085029602, 0.5590953230857849, 0.30158984661102295, 0.41807812452316284, 0.69563227891922, -0.21351653337478638, 0.48574426770210266, -1.0195939540863037, 0.7084749937057495, -0.09869256615638733, 0.904493510723114, -0.3510637581348419, -0.12046170979738235, -1.0997668504714966, 0.5462659597396851, 1.277704119682312, 0.06334230303764343, 0.6241848468780518, -0.8799370527267456, 0.34408047795295715, -0.6554310917854309, 0.4282115399837494, -0.45593729615211487, -0.20966459810733795, -0.23489126563072205, -0.47820398211479187, -1.576082706451416, -0.38198399543762207, -0.0673656091094017, -0.148091658949852, 0.7520721554756165, -0.1493467539548874, 0.2198828011751175, 0.39542481303215027, 0.42035263776779175, 0.8313093185424805, 1.2630599737167358, 0.2801697850227356, -0.3547915816307068, 0.84536212682724, -1.131188988685608, -0.8206660151481628, -1.0499131679534912, 1.439884901046753, -0.23299871385097504, 0.41836628317832947, -0.28315380215644836, -1.052728533744812, -0.777626097202301, -1.0025743246078491, -0.3958008587360382, -0.5900404453277588, 0.5673483610153198, 0.6842057704925537, 0.23517127335071564, -0.8178868889808655, 0.6777698993682861, -0.020773429423570633, -0.42425084114074707, -0.022206487134099007, -0.2613675892353058, 0.07893331348896027, -0.671980619430542, -1.4810138940811157, 0.25760263204574585, 0.22919796407222748, -0.4255596101284027, -0.09300645440816879, -0.4435734748840332, -1.2956249713897705, -0.22237549722194672, 0.6406264901161194, -0.5348912477493286, 1.4167671203613281, 0.3162490427494049, -1.2088367938995361, 0.3176010549068451, -0.3629928231239319, -0.04053452983498573, 0.13041748106479645, -0.49300938844680786, -0.49655574560165405, -0.48822617530822754, -0.40593042969703674, 0.627547562122345, 0.13864527642726898, 0.14073652029037476, -0.35143083333969116, 0.12498096376657486, -0.27078303694725037, 0.2656734585762024, -0.2552536427974701, 0.9190239906311035, -0.7067272067070007, -0.1319514960050583, 0.174929678440094, 0.6476360559463501, -0.15608949959278107, -0.4220256507396698, -0.11804673820734024, -1.312690258026123, 1.0353952646255493, -0.07120172679424286, 1.4505161046981812, -0.7555631995201111, -0.8251822590827942, -0.6729809045791626, -0.5132383108139038, 0.10750121623277664, -1.0569512844085693, 0.7900721430778503, 0.30261707305908203, 0.5540525317192078, -0.04872298985719681, -1.485162377357483, 0.05376320704817772, -0.1760663539171219, -0.9096574783325195, -0.259204626083374, 0.21869976818561554, 1.2509362697601318, -0.9942629337310791, 0.15432505309581757, -0.399306982755661, 0.15641357004642487, -1.0303890705108643, 1.111168384552002, -0.9646961688995361, 0.14703448116779327, -0.37473103404045105, -0.11189820617437363, -0.17799656093120575, -0.13550342619419098, 0.5270007252693176, 0.04794255644083023, -0.07378362119197845, 0.5049475431442261, -0.4938620328903198, 1.6014518737792969, -0.29981696605682373, 0.4267268776893616, -0.2099108099937439, -0.4334946572780609, 0.02958746813237667, 0.5325387120246887, -0.48887601494789124, -0.363394558429718, 0.08600956201553345, 0.49979543685913086, -0.9366779923439026, -0.011422106064856052, 1.1535205841064453, 0.9478422403335571, -0.6824137568473816, 0.2741657793521881, 0.4312601089477539, -0.3235822021961212, 0.7421181201934814, 0.3953338861465454, 0.5893673896789551, 0.4795694053173065, 0.25574323534965515, 0.06614705175161362, 0.4441695213317871, -0.850086510181427, -0.07904748618602753, 0.5496376752853394, 0.5771796107292175, 1.1524461507797241, 0.3409252464771271, -0.5768460631370544, -0.4043649137020111, 0.390638530254364, 0.7558419108390808, 1.8680397272109985, -0.14178891479969025, -0.3435085415840149, -0.7513222098350525, -0.18678858876228333, -0.24841207265853882, 0.19857680797576904, -0.433218777179718, 0.007890170440077782, -0.7265799641609192, -1.150094747543335, 0.590260922908783, 0.220789834856987, 0.7571757435798645, -0.6068012118339539, -0.13125325739383698, -0.15995000302791595, -0.09781139343976974, -0.9426980018615723, -0.8842033743858337, -0.2589733898639679, -0.8031474947929382, 0.12445519864559174, -0.16751570999622345, -0.20549045503139496, -0.3122628927230835, -0.528340220451355, 1.0195825099945068, -0.40187087655067444, -0.01366668101400137, 0.252331018447876, 0.14818857610225677, -0.42533445358276367, -0.6617020964622498, 0.28083425760269165, 0.29929882287979126, -0.5171757936477661, 0.26201876997947693, 0.5839905738830566, -0.010701091960072517, 0.012280003167688847, -0.43086203932762146, 0.12116829305887222, 0.20676670968532562, -0.11340881884098053, 0.8031944036483765, -0.6024814248085022, 0.5813230276107788, -1.1405894756317139, 1.1007226705551147, 0.01162825245410204, -0.4825226068496704, 0.6461713910102844, -0.4886634647846222, -0.7145377397537231, 0.25567033886909485, -0.8185122013092041, -0.1858031302690506, -1.064633846282959, 0.5752280950546265, -0.08211760222911835, -0.062126267701387405, 0.5756882429122925, 0.17884722352027893, 0.6425432562828064, 0.30312904715538025, 0.3255413770675659, 0.379320353269577, -0.3839343190193176, 0.851101279258728, -0.5055623054504395, 0.4534061551094055, 0.3171968460083008, -0.249318927526474, -0.2340654730796814, -0.2485629767179489, -0.8136683702468872, -0.3164171278476715, -0.7851648330688477, -0.23659548163414001, -0.008836681954562664, 0.14518123865127563, -0.7190989255905151, -0.09862138330936432, -0.11942433565855026, -0.9625956416130066, -0.106402687728405, 0.25464650988578796, -0.35699543356895447, -0.22672300040721893, -0.87762051820755, -1.184249758720398, -0.5292404890060425, -0.9535102844238281, -0.8694552779197693, 0.6492463946342468, 0.0737299993634224, -0.36966949701309204, -0.3702470064163208, 0.22206026315689087, -0.2596830725669861, 0.958975613117218, -0.5661481022834778, 0.7534813284873962, -0.24016137421131134, -0.16504861414432526, -0.8010692000389099, 0.5242393612861633, 0.574013888835907, -0.4064258635044098, 0.1954059898853302, -0.6603713631629944, 0.12589097023010254, -0.23291729390621185, -0.36444130539894104, 0.31600937247276306, 0.5630831718444824, 0.5074523091316223, 0.23063066601753235, -0.6292335987091064, -0.007728940341621637, 1.224023461341858, -0.755325436592102, 0.020237626507878304, -0.21239739656448364, 0.9754738211631775, 0.4330659806728363, 0.18358761072158813, 0.45273515582084656, 0.21306073665618896, 0.29801738262176514, 0.06420949846506119, 0.2988453805446625, 0.16520193219184875, -0.5423921942710876, 0.687920331954956, 1.7036789655685425, 0.4625293016433716, -0.309392511844635, -0.941744863986969, 0.8869680166244507, -1.4698901176452637, -0.6188675761222839, 0.6744000315666199, 0.8338232040405273, 0.5045908093452454, -0.6899540424346924, -0.3557088375091553, -0.650905430316925, 0.3835776746273041, 0.30133840441703796, -0.1880950629711151, -0.6214507222175598, -0.047998230904340744, -0.020486362278461456, -0.35668203234672546, 0.5198237895965576, -0.5105746388435364, 0.705479621887207, 14.519094467163086, 1.0756028890609741, 0.33693182468414307, 0.587138295173645, 0.7884262800216675, -0.35826024413108826, -0.2726828157901764, -0.07345147430896759, -1.3638336658477783, -0.22662726044654846, 1.536658525466919, 0.03928994759917259, 0.2810197174549103, 0.11059626191854477, 0.38795965909957886, 0.04109280928969383, -0.8114659786224365, 0.48608633875846863, 0.5086153149604797, -1.3328285217285156, 0.7573809623718262, 0.22969305515289307, 0.6253299117088318, 0.6317037343978882, 0.8928621411323547, 1.3276816606521606, -0.12582024931907654, -0.38399821519851685, -0.0036255205050110817, 0.29989898204803467, 0.7367268800735474, -0.2873448133468628, 0.543055534362793, 0.790302038192749, -0.5376320481300354, -0.44156455993652344, -0.791382372379303, -1.0560909509658813, 0.33729222416877747, -0.09115782380104065, -0.4399295151233673, -0.3344002664089203, -0.3270161747932434, 0.6208581924438477, -0.1299499273300171, 0.44901803135871887, -0.02074059657752514, 0.5890105962753296, -0.07234785705804825, -0.2606847286224365, 0.6257022023200989, 0.09514785557985306, 0.4524177014827728, 0.13865934312343597, 0.16361121833324432, 0.28760436177253723, 0.20534542202949524, 0.29869353771209717, -0.8577834367752075, 0.543276846408844, -0.4664292335510254, -0.21988090872764587, 0.10161969810724258, 0.6335238218307495, 0.9279595017433167, -0.11542946845293045, -0.502132773399353, 0.06612095236778259, 0.4527650773525238, 0.31087517738342285, -0.011502744629979134, -0.03686210885643959, 0.29904910922050476, -0.4158344566822052, -0.08682381361722946, 0.5789915323257446, 0.014079421758651733, -0.6639633178710938, -0.5629069209098816, -0.21738509833812714, 0.26064515113830566, -0.8158081769943237, -0.6652628779411316, 0.6446238160133362, -0.05160236358642578, -0.5667851567268372, -0.23739922046661377, -0.31928306818008423, -0.5038908123970032, 0.4359733462333679, -1.5117131471633911, -0.9348059296607971, 0.7030896544456482, -0.7166137099266052, 0.03229356184601784, 0.1397477686405182, 1.287007451057434, -0.0014017436187714338, -0.7657266855239868, 0.04850186035037041, 0.7941771149635315, -0.24078544974327087, 0.04643693566322327, -0.6314091682434082, 0.8009254336357117, 0.28928107023239136, -0.321588397026062, 0.20773346722126007, -0.004254409112036228, 0.3151854872703552, -0.732635498046875, -0.48918986320495605, 0.9018725156784058, -1.1279542446136475, -0.6799852848052979, -0.780333936214447, -1.2684646844863892, 0.18937000632286072, 0.7550511956214905, -0.15690892934799194, 0.5231664776802063, 0.2601049840450287, -0.1629069596529007, -0.15337923169136047, -0.6747158169746399, 0.2502175271511078, 0.339403361082077, -0.6373940706253052, -0.47350969910621643, 0.19569949805736542, 0.8879415988922119, -0.8726218342781067, -0.5497052669525146, 0.014149407856166363, 0.061314184218645096, 0.3396695554256439, 0.9308075308799744, -0.24823914468288422, 0.6908391118049622, 0.9223854541778564, -0.4523652195930481, -0.539662778377533, 0.2531292736530304, -1.0397710800170898, -0.25557637214660645, 0.4095124304294586, 0.7399563789367676, -0.18100163340568542, -0.07120496779680252, 1.0622241497039795, 0.46597734093666077, -0.8930988311767578, -0.7001613974571228, -0.45154228806495667, 0.6030275821685791, -0.5074751973152161, 0.4899124503135681, -0.21918463706970215, 0.13449253141880035, 0.21631202101707458, 0.30919381976127625, 0.6988527178764343, -0.5329264402389526, -0.7308344841003418, 0.6182723045349121, 0.07797829061746597, 0.08271954953670502, -0.5150172710418701, -0.21942998468875885, -1.357435941696167, -0.16464833915233612, -0.878900408744812, -0.0472521148622036, -0.9844257831573486, -0.28045594692230225, 0.3835974335670471, -0.10404900461435318, -0.2441149204969406, 0.138600155711174, -0.44251811504364014, -0.4835342466831207, -0.5661985874176025, -1.0649282932281494, 0.9876176714897156, 0.7629813551902771, -0.5145545601844788, -0.24712421000003815, -0.07088818401098251, 0.05418538674712181, 0.2171657234430313, 0.4577975571155548, -0.04917684569954872, -1.0181187391281128, -1.4228932857513428, 0.34661462903022766, 0.08422691375017166, -0.42150866985321045, -0.5645866394042969, 0.4782159626483917, 0.5647031664848328, -0.24444428086280823, -0.2550419569015503, 0.1832069754600525, -0.47696512937545776, -0.7964708805084229, -0.14810682833194733, -1.1413718461990356, 0.23035308718681335, 0.2832760810852051, -0.41675347089767456, -0.4283078610897064, 0.495547354221344, -0.4272913634777069, -1.0068690776824951, -0.7431139945983887, 0.39963439106941223, -0.7108659148216248, 0.12084449082612991, -0.47322535514831543, 0.283098429441452, -1.0345231294631958, -0.5167885422706604, 0.07182753831148148, 0.8355884552001953, -0.16684794425964355, 0.9967594742774963, 0.4091620445251465, -1.2058552503585815, -0.32496699690818787, -0.1521133929491043, 0.13996253907680511, 0.42048880457878113, 0.8415462374687195, 0.21677549183368683, -0.1335025131702423, 0.602957010269165, 0.884888768196106, 0.15805402398109436, -0.8427239656448364, 0.15955397486686707, 0.5788829922676086, -0.6332216858863831, -0.12250711023807526, 1.150613784790039, -0.3352785110473633, -1.0918912887573242, 0.1494186818599701, -1.511046290397644, -0.9837610125541687, -0.2055385410785675, 1.162480354309082, 0.24615442752838135, -0.13504475355148315, -0.12282931059598923, -0.18702249228954315, 0.11084704101085663, -0.26330235600471497, -0.5291807055473328, 0.6866360902786255, -0.5579206943511963, -0.5458822250366211, 0.8652440905570984, 1.191070556640625, -0.9033129215240479, -0.5854238271713257, -0.8783581852912903, -0.08011779934167862, 0.012260536663234234, 0.37711644172668457, -0.5586115717887878, 0.1206558421254158, 0.6937386989593506, 0.5587803721427917, 0.2255801409482956, 0.20611928403377533, -0.19950531423091888, 0.5264266729354858, 1.0406602621078491, -0.15800559520721436, -0.7515798807144165, -0.5868365168571472, 1.3349720239639282, 1.6346267461776733, -1.1520477533340454, 0.45240485668182373, 0.3372359871864319, -0.8300686478614807, 0.6211724281311035, 0.3874092400074005, 0.07176920771598816, 0.6624380946159363, -0.9288157820701599, 0.16092799603939056, 0.2821221351623535, -1.7165559530258179, 0.023094741627573967, 1.046613335609436, 0.7683318257331848, 0.9083117842674255, 0.2860468029975891, -0.1703629046678543, 0.9953529834747314, 0.36004161834716797, -0.13642065227031708, 0.7591095566749573, 0.42432379722595215, -0.3727571368217468, -0.051776256412267685, 0.1905878633260727, 0.47844135761260986, -0.6484562158584595, -0.472596675157547, 0.3296625316143036, 0.49987390637397766, -0.0496009923517704, 0.902298092842102, 0.7907860279083252, 0.4362944960594177, 0.5307934284210205, 0.40678074955940247, 0.2225870043039322, -0.7696779370307922, -0.16967682540416718, 0.012063735164701939, -0.5317046046257019, -0.13476915657520294, -0.04432784020900726, -0.7569109201431274, -0.13086631894111633, 0.1439046859741211, 0.047650039196014404, 0.05585222318768501, 0.13618400692939758, 1.1951262950897217, 0.8066847920417786, 0.038172584027051926, -0.2871527075767517, -0.5682915449142456, -0.5308798551559448, -1.2051008939743042, -0.20265653729438782, -0.40430527925491333, -0.15680408477783203, 0.16494573652744293, 0.11552087217569351, -0.5669565200805664]}, "authors": [{"authorId": "2254989105", "name": "Peng Xu"}, {"authorId": "2253664013", "name": "Wei Ping"}, {"authorId": "2253618149", "name": "Xianchao Wu"}, {"authorId": "20957879", "name": "Lawrence C. McAfee"}, {"authorId": "2283871700", "name": "Chen Zhu"}, {"authorId": "2256582287", "name": "Zihan Liu"}, {"authorId": "2253531461", "name": "Sandeep Subramanian"}, {"authorId": "32867948", "name": "Evelina Bakhturina"}, {"authorId": "1911755", "name": "M. Shoeybi"}, {"authorId": "2301680", "name": "Bryan Catanzaro"}], "references": [{"paperId": "b31a5884a8ebe96b6300839b28608b97f8f8ef76", "title": "LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding"}, {"paperId": "76c8e90dfd0f1e78e6a94d702a5b14b3e7206003", "title": "RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "b069c32fcd77160f944ab3ba71ab6f0cfb782c68", "title": "Focused Transformer: Contrastive Training for Context Scaling"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "60b35c6d68acced19b0c66edcfc0ee0a2c11efed", "title": "Landmark Attention: Random-Access Infinite Context Length for Transformers"}, {"paperId": "eb511ae6b9f04e4936891d26787f274b48b99d57", "title": "ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding"}, {"paperId": "ae736662f64d56f3ab1894fbd9c45f8f37251843", "title": "OpenAssistant Conversations - Democratizing Large Language Model Alignment"}, {"paperId": "b63e97330154acece935ffa6901e3f36518e5703", "title": "Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "a4867148c2f692efc6c22c3935a59be2d04ea3e9", "title": "How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval"}, {"paperId": "07b14c24833400b79978b0a5f084803337e30a15", "title": "REPLUG: Retrieval-Augmented Black-Box Language Models"}, {"paperId": "980e55d9226cac302d0fae7732da4e67b8bc952c", "title": "Parallel Context Windows for Large Language Models"}, {"paperId": "f78fe02f681a0a9a6867b007bd39e3884de64a91", "title": "SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization"}, {"paperId": "5a3c1afe73d8bcc8288d17cb17be2baec8a98464", "title": "Text Embeddings by Weakly-Supervised Contrastive Pre-training"}, {"paperId": "87126a964ed14d0d2207747fc732b197e2fc9493", "title": "Retrieval as Attention: End-to-end Learning of Retrieval and Reading within a Single Transformer"}, {"paperId": "1d26c947406173145a4665dd7ab255e03494ea28", "title": "GLM-130B: An Open Bilingual Pre-trained Model"}, {"paperId": "398e4061dde8f5c80606869cebfa2031de7b5b74", "title": "Few-shot Learning with Retrieval Augmented Language Models"}, {"paperId": "a8cf0f7a20f886acfb332071c2daaf58ba86a5ca", "title": "Recurrent Memory Transformer"}, {"paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a", "title": "Emergent Abilities of Large Language Models"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "b21670e8061a06ab97e7d6052c9345a326e84ff8", "title": "UL2: Unifying Language Learning Paradigms"}, {"paperId": "6281c40c66febca1d8003bcc6fdfd2189b30c38f", "title": "SCROLLS: Standardized CompaRison Over Long Language Sequences"}, {"paperId": "2f3efe44083af91cef562c1a3451eee2f8601d22", "title": "WebGPT: Browser-assisted question-answering with human feedback"}, {"paperId": "3c209e0703ffff26231b1145268c935df494631a", "title": "QuALITY: Question Answering with Long Input Texts, Yes!"}, {"paperId": "4f4a409f701f7552d45c46a5b0fea69dca6f8e84", "title": "Unsupervised Dense Information Retrieval with Contrastive Learning"}, {"paperId": "002c256d30d6be4b23d365a8de8ae0e67e4c9641", "title": "Improving language models by retrieving from trillions of tokens"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "ec307b17f193b14292206b65a1bcc95bfd8f02ed", "title": "\u266b MuSiQue: Multihop Questions via Single-hop Question Composition"}, {"paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"}, {"paperId": "4e3935ef7da6bcbb202ec7f8b285c313cadcd044", "title": "A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "807600ef43073cd9c59d4208ee710e90cf14efa8", "title": "BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models"}, {"paperId": "aa28873534c24e4a8c5deb7bff723cd5fc69a6f0", "title": "QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "46c585ee9abf76779ea4b863d2da4358efd0d1d3", "title": "Adaptive Semiparametric Language Models"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "ea8c46e193d5121e440daf96edfd15a47151c293", "title": "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "58ed1fbaabe027345f7bb3a6312d41c5aac63e22", "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "b26f2037f769d5ffc5f7bdcec2de8da28ec14bee", "title": "Dense Passage Retrieval for Open-Domain Question Answering"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "832fff14d2ed50eb7969c4c4b976c35776548f56", "title": "REALM: Retrieval-Augmented Language Model Pre-Training"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "add2f205338d70e10ce5e686df4a690e2851bdfc", "title": "Momentum Contrast for Unsupervised Visual Representation Learning"}, {"paperId": "7be8c119dbe065c52125ee7716601751f3116844", "title": "Generalization through Memorization: Nearest Neighbor Language Models"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "ebf59587f8f170ff4241c42263bbfb9da5bd2135", "title": "ELI5: Long Form Question Answering"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "22655979df781d222eaf812b0d325fa9adf11594", "title": "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a", "title": "The NarrativeQA Reading Comprehension Challenge"}, {"paperId": "2cbb8de53759e75411bc528518947a3094fbce3a", "title": "Billion-Scale Similarity Search with GPUs"}, {"paperId": "bd5fc28c7356915ec71abafbe86b7596c60720aa", "title": "The conference paper"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": null, "title": "Function calling and other API updates (longer context"}, {"paperId": "5c5751d45e298cea054f32b392c12c61027d2fe7", "title": "S2ORC: The Semantic Scholar Open Research Corpus"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "OpenAI"}, {"paperId": null, "title": "Introducing 100k context windows"}, {"paperId": null, "title": "We show an example below where the smaller model Llama2-7B fails to incorporate relevant context, while larger models with retrieval could successfully predict the correct answer"}, {"paperId": null, "title": "Long sequence modeling with XGen: A 7b LLM trained on 8k input sequence length"}, {"paperId": null, "title": "Things I\u2019m learning while training SuperHOT"}, {"paperId": null, "title": "Introducing the world\u2019s first truly open instruction-tuned"}]}