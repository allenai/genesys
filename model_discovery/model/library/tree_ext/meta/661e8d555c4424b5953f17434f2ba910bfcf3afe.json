{"paperId": "661e8d555c4424b5953f17434f2ba910bfcf3afe", "title": "Efficient Long Sequence Modeling via State Space Augmented Transformer", "abstract": "Transformer models have achieved superior performance in various natural language processing tasks. However, the quadratic computational cost of the attention mechanism limits its practicality for long sequences. There are existing attention variants that improve the computational efficiency, but they have limited ability to effectively compute global information. In parallel to Transformer models, state space models (SSMs) are tailored for long sequences, but they are not flexible enough to capture complicated local information. We propose SPADE, short for $\\underline{\\textbf{S}}$tate s$\\underline{\\textbf{P}}$ace $\\underline{\\textbf{A}}$ugmente$\\underline{\\textbf{D}}$ Transform$\\underline{\\textbf{E}}$r. Specifically, we augment a SSM into the bottom layer of SPADE, and we employ efficient local attention methods for the other layers. The SSM augments global information, which complements the lack of long-range dependency issue in local attention methods. Experimental results on the Long Range Arena benchmark and language modeling tasks demonstrate the effectiveness of the proposed method. To further demonstrate the scalability of SPADE, we pre-train large encoder-decoder models and present fine-tuning results on natural language understanding and natural language generation tasks.", "venue": "arXiv.org", "year": 2022, "citationCount": 29, "influentialCitationCount": 3, "openAccessPdf": {"url": "http://arxiv.org/pdf/2212.08136", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "The proposed SPADE augments global information, which complements the lack of long-range dependency issue in local attention methods and demonstrates the scalability of the proposed method."}, "embedding": {"model": "specter_v2", "vector": [0.40728259086608887, 0.4379664659500122, -0.07856658101081848, -0.2018628716468811, -0.3770342171192169, -0.39611703157424927, 0.7347503304481506, -0.27838683128356934, -0.37949633598327637, -0.0861281305551529, 0.782133936882019, -0.1011241003870964, 0.4833035171031952, -0.009803635999560356, -0.2877500653266907, 0.10589167475700378, -0.5960386991500854, 0.4042562246322632, 0.08985622227191925, -0.49424314498901367, 0.011433441191911697, -0.4939691722393036, -0.7463769912719727, -0.1785452514886856, 0.612133800983429, 0.38808536529541016, 0.6166964769363403, 0.7790420651435852, -0.7289358973503113, 0.36915385723114014, 0.40312668681144714, -0.451812207698822, 0.24459242820739746, -0.3115847408771515, -0.53327876329422, -0.09056591987609863, 0.08927284926176071, -0.3750358521938324, -0.6211997270584106, 1.0140950679779053, -0.3201354444026947, 0.35621368885040283, 0.12712359428405762, -0.7347851395606995, -0.0371856614947319, 0.9731379747390747, 0.7326771020889282, 0.8900941610336304, -0.2579992711544037, -0.4126763641834259, 1.7617628574371338, -1.0688751935958862, 0.3337778151035309, 1.4164303541183472, 0.19543081521987915, 0.5313535332679749, -0.29908618330955505, -0.8019089102745056, 0.8620668053627014, 0.37885403633117676, -0.7221972346305847, -0.3524564802646637, 0.2327221781015396, 0.06804521381855011, 1.9026401042938232, -0.252895325422287, 0.5182861089706421, 0.7176641225814819, -0.15553951263427734, 1.5051250457763672, -0.18830187618732452, -0.5874661207199097, -0.39256617426872253, -0.4966048300266266, 0.6494237780570984, 1.0962393283843994, -0.38728001713752747, 0.4684998095035553, -1.0805429220199585, 0.2090180367231369, 0.6543030142784119, 0.03499658778309822, 0.19636058807373047, -0.19537369906902313, -0.478355348110199, 0.5100717544555664, 0.1771915704011917, 0.7633681297302246, 0.052985213696956635, 0.554735541343689, 0.551797091960907, 0.037620220333337784, -0.06501970440149307, 0.36513280868530273, -0.09181447327136993, 0.045459236949682236, -0.7569755911827087, 0.21769724786281586, -0.3286902606487274, 1.0167701244354248, -0.43734681606292725, 0.6207886934280396, -0.7431524395942688, 0.1645824909210205, 1.343247652053833, 0.2705802321434021, 0.4993964731693268, -0.8472118377685547, 0.32976341247558594, -0.4130876958370209, 0.22810937464237213, -0.3668646216392517, -0.0023173033259809017, -0.33358752727508545, -0.6101869940757751, -1.2622612714767456, -0.30997201800346375, 0.33680054545402527, -0.6976043581962585, 1.1163774728775024, -0.4817219376564026, 0.5586053133010864, 0.08471482992172241, 0.029836978763341904, 0.16243289411067963, 1.0192763805389404, 0.13333237171173096, 0.031248359009623528, 0.8577137589454651, -1.0188946723937988, -0.8108814358711243, -1.2230565547943115, 0.5707770586013794, 0.1611805260181427, 0.34094229340553284, -0.14806309342384338, -1.4831328392028809, -1.108491063117981, -0.8874337673187256, 0.07133859395980835, -0.5568347573280334, -0.12356320023536682, 0.6219121217727661, 0.3152519762516022, -1.0728219747543335, 0.6279411911964417, -0.8466440439224243, -0.20847700536251068, 0.415073424577713, -0.02512265369296074, 0.39910322427749634, -0.19387055933475494, -1.4966473579406738, 0.4754115343093872, 0.2636731266975403, -0.5083706378936768, -0.2249389886856079, -0.575373649597168, -1.6282780170440674, 0.3325549066066742, 0.41161802411079407, -0.25002482533454895, 1.3327323198318481, 0.3379215896129608, -1.5593867301940918, 0.23826919496059418, -0.6128514409065247, -0.05909314379096031, -0.19011244177818298, -0.35402530431747437, -0.43992069363594055, -0.6325640678405762, -0.2651219964027405, 0.1852293461561203, 0.07383265346288681, 0.14964760839939117, -0.3365227282047272, 0.0477701760828495, -0.4252651631832123, -0.0789257287979126, -0.10185503214597702, 1.405822992324829, -0.17914414405822754, -0.18550890684127808, 0.19191592931747437, 0.5819339752197266, -0.21713991463184357, -0.5076214671134949, -0.5250616073608398, -1.0592142343521118, 0.7189569473266602, -0.16189074516296387, 1.1628564596176147, -0.713231086730957, -0.6463475823402405, -0.4245642423629761, -0.3062551021575928, 0.02926947921514511, -0.8916124701499939, 0.6189678311347961, -0.5687788724899292, 0.2506195604801178, -0.13485342264175415, -0.9205957055091858, 0.09597290307283401, -0.10855108499526978, -0.9605070948600769, -0.17257164418697357, 0.21158656477928162, 1.3272414207458496, -1.1805400848388672, -0.12534475326538086, 0.13512283563613892, -0.09513137489557266, -0.7870180606842041, 1.2504805326461792, -0.2970011830329895, 0.15492723882198334, -0.19870586693286896, -0.3814089000225067, -0.28441470861434937, -0.590472400188446, 0.29070571064949036, -0.2422170639038086, -0.269118070602417, 0.9826240539550781, -0.26947474479675293, 1.6327073574066162, -0.2656680643558502, 0.4289378225803375, -0.4715694189071655, -0.8156699538230896, 0.5467444658279419, 0.23254038393497467, -0.1732388585805893, -0.36907005310058594, 0.2402815967798233, -0.0023136783856898546, -0.5023617148399353, 0.38553038239479065, 0.5507625937461853, 0.673141360282898, -0.4761609733104706, 0.3761891722679138, 0.49752774834632874, -0.2784406244754791, 0.6725185513496399, 0.6837204098701477, 0.6855171918869019, 0.5752324461936951, 0.6912910342216492, -0.15159201622009277, 0.34249967336654663, -0.8427138328552246, 0.07120143622159958, 0.19042642414569855, 0.451322078704834, 0.8252837657928467, 0.37168723344802856, -0.6105730533599854, -0.5637426376342773, -0.03867390751838684, 0.9646595120429993, 1.2381972074508667, 0.14072181284427643, -0.4475489854812622, -0.6658322811126709, -0.2905009686946869, -0.834037184715271, 0.46860024333000183, -0.16302427649497986, -0.3822425901889801, -0.6621988415718079, -0.5040619373321533, 1.023490309715271, 0.7690763473510742, 1.095428228378296, -0.49916860461235046, -0.30807504057884216, -0.12103214859962463, -0.19240932166576385, -0.878799557685852, -1.0542163848876953, 0.18754272162914276, -0.3441106677055359, -0.06584212929010391, 0.24939318001270294, 0.16295745968818665, -0.29381853342056274, -0.8888904452323914, 0.8118524551391602, -0.9023298025131226, -0.1652631163597107, -0.11397707462310791, 0.7745065093040466, -0.6799176335334778, -0.8410852551460266, 0.3096601366996765, 0.03822251781821251, -0.14884917438030243, 0.2749233543872833, 0.520099937915802, 0.2838361859321594, 0.005998861975967884, -0.10170726478099823, 0.3433901071548462, -0.10986601561307907, 0.3563406765460968, 0.47800102829933167, -0.5692580342292786, -0.13354483246803284, -0.9164804816246033, 0.5370128154754639, 0.5955348610877991, -0.8408419489860535, 0.46873173117637634, -0.43859732151031494, 0.10164393484592438, 0.3854444921016693, -0.29946666955947876, -0.5683953166007996, -0.7141083478927612, 0.1959788203239441, -0.37331366539001465, -0.24431060254573822, 0.17786622047424316, -0.038080986589193344, 0.658361554145813, 0.02276136912405491, 0.977282702922821, 0.49089422821998596, -0.059573885053396225, 0.3203229308128357, -0.9492847323417664, 0.5178577303886414, 0.43099305033683777, 0.2438746690750122, -0.26992350816726685, 0.008082283660769463, -0.5552657246589661, -0.7022649645805359, -0.6100360155105591, -0.40105465054512024, -0.12279936671257019, 0.301371306180954, -0.44861727952957153, -0.6334226727485657, 0.10266468673944473, -1.5665254592895508, -0.2658971846103668, -0.0029092002660036087, -0.49624842405319214, -0.3331418037414551, -1.004339337348938, -1.0720200538635254, -0.4956103265285492, -0.31842660903930664, -1.0788085460662842, 0.6674367189407349, 0.03055957518517971, -0.5531392097473145, -0.6507397890090942, 0.19482013583183289, -0.43473145365715027, 0.8507235646247864, -0.5043797492980957, 0.7448405027389526, -0.4246920943260193, -0.4780472218990326, -0.13138708472251892, 0.4799973666667938, 0.3927723169326782, -0.11275339126586914, 0.059202343225479126, -0.49042800068855286, 0.2896195650100708, -0.29154565930366516, -0.01871676743030548, 0.027048340067267418, 0.32158541679382324, 0.6575872898101807, 0.11719862371683121, -0.5731284618377686, 0.25797927379608154, 1.1518899202346802, -0.08582327514886856, 0.21138107776641846, 0.050232138484716415, 1.1124672889709473, 0.04977027699351311, -0.1874663382768631, 0.4377080798149109, 0.23242293298244476, 0.4561341404914856, 0.17275850474834442, 0.02115330658853054, -0.0551789216697216, -0.5875821113586426, 0.8102882504463196, 1.5226178169250488, 0.236441969871521, -0.10115712881088257, -1.2386349439620972, 0.7844570279121399, -1.2281789779663086, -0.9342085123062134, 0.8029148578643799, 0.44143253564834595, 0.4402961730957031, -0.5807409286499023, -0.29080796241760254, -0.04325008764863014, 0.8523496389389038, 0.7726277709007263, -0.2932613790035248, -0.5621629357337952, -0.077260322868824, 0.39376112818717957, -0.02637801319360733, 0.8042750358581543, -0.09273159503936768, 0.7307526469230652, 14.874341011047363, 0.9209008812904358, 0.05839049071073532, 0.47354230284690857, 0.5703064799308777, 0.14184080064296722, -0.21202228963375092, -0.13123388588428497, -1.3810937404632568, -0.10441147536039352, 1.3281888961791992, -0.18766264617443085, 0.574155867099762, -0.15899106860160828, 0.07805706560611725, 0.5581709146499634, -0.6954753994941711, 0.7675719857215881, 0.4766940772533417, -1.3515760898590088, 0.3625841438770294, 0.07290367037057877, 0.12169750034809113, 0.4250675141811371, 0.5472778677940369, 0.6086603403091431, 0.8407686352729797, -0.40588656067848206, 0.5523383021354675, 0.1180446594953537, 0.9612242579460144, -0.10785210877656937, 0.20423048734664917, 0.5920735001564026, -1.0822488069534302, -0.16543667018413544, -0.3471542298793793, -1.1024773120880127, 0.4896352291107178, -0.11901246011257172, -0.22269338369369507, -0.28755244612693787, -0.43464723229408264, 1.076999545097351, 0.39290565252304077, 0.3467150330543518, -0.4831152558326721, 0.7702459692955017, 0.03656337782740593, -0.08152884989976883, 0.5196630954742432, 0.167413592338562, 0.5966588854789734, -0.24980200827121735, 0.3809269964694977, 0.23518149554729462, 0.23403815925121307, 0.6554695963859558, -0.24981871247291565, -0.479286789894104, -0.5237579345703125, -0.3881303668022156, 0.051493775099515915, 0.42408740520477295, 0.42131972312927246, 0.1264408826828003, -0.34731078147888184, 0.15753401815891266, 0.49032944440841675, 0.12210755795240402, -0.43946629762649536, -0.16284966468811035, 0.2924071252346039, -0.47992950677871704, -0.005343833472579718, 0.3317570388317108, -0.30767327547073364, -0.5132318139076233, -1.0384031534194946, -0.27424174547195435, 0.5085616111755371, -0.9592571258544922, -0.4489288032054901, 1.0609266757965088, -0.09922444820404053, -0.2511388957500458, 0.045431967824697495, -0.5184280872344971, -0.4413183629512787, 0.4040975570678711, -1.153710961341858, -0.6722353100776672, 0.19687722623348236, -0.16737043857574463, 0.2499634176492691, -0.15137003362178802, 1.0736110210418701, -0.2688014507293701, -0.6231574416160583, -0.1924755871295929, -0.054350487887859344, 0.12181631475687027, -0.541015625, -0.9647960066795349, 1.1453399658203125, 0.6747971773147583, 0.2668343186378479, 0.2324485182762146, 0.0948408991098404, 0.002889649709686637, -0.6274993419647217, -0.17220696806907654, 0.9502487182617188, -1.2114918231964111, -0.05888974666595459, -1.1423945426940918, -0.8457353115081787, 0.5600979328155518, 0.5755131244659424, -0.24188414216041565, -0.01875985600054264, 0.011684594675898552, -0.4948023557662964, -0.23416109383106232, -0.42216551303863525, 0.1772080957889557, 0.8377062678337097, -0.7887452244758606, -0.4112817347049713, -0.41910022497177124, 0.704811155796051, -0.918073832988739, -0.2414897382259369, -0.21587133407592773, -0.15319572389125824, 0.21269215643405914, 0.9053381681442261, -0.5131190419197083, 0.7758070230484009, 0.8910772800445557, -0.03249632194638252, -1.0435764789581299, -0.33781954646110535, -1.1199626922607422, 0.01583896204829216, 0.26433005928993225, 0.600904643535614, -0.4466477632522583, 0.23380312323570251, 0.7403449416160583, 0.10652769356966019, -0.3917190134525299, -0.6491154432296753, -0.746343195438385, -0.1964816451072693, -0.3773129880428314, 0.6959139704704285, -0.26111072301864624, 0.0778164342045784, 0.4754851162433624, 0.42875999212265015, 0.5832493305206299, -0.23459841310977936, -0.38854309916496277, 0.029407106339931488, -0.13893799483776093, 0.1571773886680603, -0.634262204170227, -0.4830079674720764, -1.6071867942810059, 0.3529037833213806, -1.1059328317642212, 0.19687072932720184, -1.0120856761932373, -0.24647726118564606, 0.40247324109077454, -0.324779748916626, 0.15896177291870117, 0.2826419472694397, -0.6849328279495239, -0.5144850015640259, -0.7288795709609985, -0.6360872983932495, 1.1041702032089233, 0.7444882988929749, -0.6989708542823792, 0.27622830867767334, -0.13031704723834991, 0.08890247344970703, 0.08094906806945801, 0.24048419296741486, -0.22439034283161163, -0.8442670702934265, -1.2693819999694824, 0.12345830351114273, 0.14503616094589233, -0.1717039942741394, -0.5101876258850098, 0.6676716804504395, 0.14696699380874634, -0.5365644097328186, -0.22512611746788025, 0.4740135669708252, -0.802790105342865, -0.5087053179740906, 0.6839978694915771, -0.954391360282898, 0.32149964570999146, 0.1680905818939209, -0.48850008845329285, -0.527129590511322, 0.9032226204872131, 0.13676419854164124, -1.0501412153244019, -0.6558641791343689, 0.6360864043235779, -0.5916696786880493, 0.0594351664185524, -0.20889650285243988, -0.21728602051734924, -1.007496953010559, -0.584877073764801, 0.14388635754585266, 0.36102965474128723, -0.6158952116966248, 0.9252268075942993, 0.43291181325912476, -1.0835769176483154, 0.08435631543397903, 0.40275704860687256, -0.18570610880851746, 0.16841304302215576, 0.2710573077201843, 0.126436248421669, -0.09843870997428894, 0.8361644744873047, 0.1996985226869583, 0.31204429268836975, -1.1486724615097046, 0.1857452690601349, 0.8221193552017212, -0.7736848592758179, -0.17864181101322174, 1.0895782709121704, -0.17642776668071747, -0.7764912247657776, 0.053898293524980545, -1.2282695770263672, -0.6532719135284424, -0.6982406377792358, 0.6710352301597595, 0.39235004782676697, -0.41880854964256287, -0.03393123671412468, -0.4895007610321045, 0.1616274118423462, -0.0001595096691744402, -0.7187190651893616, 0.7977584004402161, -0.28601330518722534, -0.38369473814964294, 0.8624053597450256, 0.5219550132751465, -0.8671056032180786, -0.8424636125564575, -0.7094437479972839, -0.2806885242462158, -0.0853784903883934, 0.1095467358827591, -0.30760276317596436, -0.5285147428512573, 1.0015897750854492, 0.2832067310810089, 0.3962138593196869, 0.054136767983436584, -0.1261787712574005, 0.4126679599285126, 0.5637581944465637, 0.12503871321678162, -0.4260716736316681, -0.5237036347389221, 1.6922792196273804, 1.5523284673690796, -0.619208574295044, -0.1918114721775055, -0.5326923131942749, -0.6633955836296082, 0.4747830033302307, 0.4337663948535919, -0.12587618827819824, 0.6572144627571106, 0.12080199271440506, -0.12774299085140228, 0.18226821720600128, -1.2212104797363281, -0.19379301369190216, 0.623443603515625, 1.0543264150619507, 0.3392009437084198, -0.04728873819112778, 0.3845803439617157, 1.1698576211929321, 0.1978813260793686, -0.05135265365242958, 0.4606150984764099, 0.3462030291557312, -0.08761759102344513, -0.1712033748626709, -0.03186606615781784, 0.5850269794464111, -0.463676780462265, -0.788081705570221, 0.21001899242401123, 0.3962479829788208, -0.358248233795166, 0.4452727735042572, 1.007978081703186, 0.3702887296676636, 0.6106085181236267, 0.5308460593223572, 0.5012274980545044, -0.6335688233375549, -0.024883706122636795, -0.2354818731546402, -0.5518842339515686, -0.4686291515827179, -0.07060220837593079, -0.8653861284255981, -0.40791642665863037, 0.14677979052066803, 0.12480788677930832, -0.0043169488199055195, 0.14724253118038177, 1.267967939376831, 0.493542343378067, 0.6026986837387085, -0.3229750990867615, -0.16195456683635712, -0.5285855531692505, -0.8994036912918091, -0.0444200336933136, -0.3913591206073761, 0.03100523166358471, -0.19739094376564026, 0.3219417333602905, 0.005766564980149269]}, "authors": [{"authorId": "52194893", "name": "Simiao Zuo"}, {"authorId": "46522098", "name": "Xiaodong Liu"}, {"authorId": "49097406", "name": "Jian Jiao"}, {"authorId": "36730993", "name": "Denis Xavier Charles"}, {"authorId": "2690730", "name": "Eren Manavoglu"}, {"authorId": "2153707398", "name": "Tuo Zhao"}, {"authorId": "48441311", "name": "Jianfeng Gao"}], "references": [{"paperId": "70e91e16eb321067d9402710e14a40cf28311f73", "title": "Mega: Moving Average Equipped Gated Attention"}, {"paperId": "dc0102a51a9d33e104a4a3808a18cf17f057228c", "title": "Transformer Quality in Linear Time"}, {"paperId": "3dfb1f50f2a34a699c339dabaa6f9b3a977973de", "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "37abe53ed31caa23ae833b2e67bb4aa1892e8d25", "title": "FMMformer: Efficient and Flexible Transformer via Decomposed Near-field and Far-field Attention"}, {"paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"}, {"paperId": "d8d2e574965fe733eb1416e03df2b5c2914fc530", "title": "A Survey of Transformers"}, {"paperId": "af679d69fcc1d0fcf0f039aba937853bcb50a8de", "title": "Luna: Linear Unified Nested Attention"}, {"paperId": "e32a12b14e212506115cc6804667b3d8297917e1", "title": "Poolingformer: Long Document Modeling with Pooling Attention"}, {"paperId": "1f133158a8973fb33fea188f20517cd7e69bfe7f", "title": "FNet: Mixing Tokens with Fourier Transforms"}, {"paperId": "9dc624d7258d1a56117ca720aea953ce46b66b21", "title": "Efficient Attentions for Long Document Summarization"}, {"paperId": "9623e9e461647a10a8f14419a9abe40482e9eb47", "title": "MediaSum: A Large-scale Media Interview Dataset for Dialogue Summarization"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "0cd82dfae930ac4b57c0e959f744f2d10bf87649", "title": "Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding"}, {"paperId": "0964490205fdc38c2f0980c9d778069089ca92e3", "title": "HiPPO: Recurrent Memory with Optimal Polynomial Projections"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "cd4ffe5e014601a3d6b64121355d29a730591490", "title": "Fast Transformers with Clustered Attention"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "8d908042f139575d6688c745e94156c9df6eae07", "title": "Understanding the Difficulty of Training Transformers"}, {"paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d", "title": "ETC: Encoding Long and Structured Inputs in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "71cd5145c3ec27838bf06a1a09980314f05a17ba", "title": "The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding"}, {"paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a", "title": "On Layer Normalization in the Transformer Architecture"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0", "title": "Natural Questions: A Benchmark for Question Answering Research"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "cc27ec53160d88c25fc5096c0df65536eb780de4", "title": "Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model"}, {"paperId": "f4238bd2385a52413ccbacfd9e409a650235bd13", "title": "Adaptive Attention Span in Transformers"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "658721bc13b0fa97366d38c05a96bf0a9f4bb0ac", "title": "Multi-Task Deep Neural Networks for Natural Language Understanding"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "d7b6753a2d4a2b286c396854063bde3a91b75535", "title": "A Simple Method for Commonsense Reasoning"}, {"paperId": "cb0f3ee1e98faf92429d601cdcd76c69c1e484eb", "title": "Neural Network Acceptability Judgments"}, {"paperId": "0d3c46a3cbfe06cec259fec954b6ff6df6c1a566", "title": "Learning long-range spatial dependencies with horizontal gated-recurrent units"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "8b354d76813bd5375e7e5c8d17f630bec5936a01", "title": "ListOps: A Diagnostic Dataset for Latent Tree Learning"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096", "title": "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "f37076f426023241f19cdc2fb0a0fd733a6fa7fa", "title": "Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "e01eae8dea6fbaa1ae7fc83535053932268df430", "title": "The ACL anthology network corpus"}, {"paperId": "a54ba84e9ea4f46d3614427788d88832aa0f5ed6", "title": "A VIRTUAL EVENT"}, {"paperId": null, "title": "2020b. Linformer: Self-attention with"}, {"paperId": null, "title": "2020a. Cluster-former: Clustering"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "db8885a0037fe47d973ade79d696586453710233", "title": "The Sixth PASCAL Recognizing Textual Entailment Challenge"}, {"paperId": "351ec42df2b60c6042addf96e6b98673bbaf4dfd", "title": "The Fourth PASCAL Recognizing Textual Entailment Challenge"}, {"paperId": "de794d50713ea5f91a7c9da3d72041e2f5ef8452", "title": "The Third PASCAL Recognizing Textual Entailment Challenge"}, {"paperId": "136326377c122560768db674e35f5bcd6de3bc40", "title": "The Second PASCAL Recognising Textual Entailment Challenge"}, {"paperId": "475354f10798f110d34792b6d88f31d6d5cb099e", "title": "Automatically Constructing a Corpus of Sentential Paraphrases"}, {"paperId": "e808f28d411a958c5db81ceb111beb2638698f47", "title": "The PASCAL Recognising Textual Entailment Challenge"}, {"paperId": "68b13366ee7d0e398c2b8736cb8d42052ffbe190", "title": "Empirical Methods in Natural Language Processing"}, {"paperId": null, "title": "(cid:5) SPADE base : We follow the pre-training settings in BERT (Devlin et al., 2019)."}, {"paperId": "13167f9cd8c7906ca808b01d28dca6dd951da8a5", "title": "of the Association for Computational Linguistics"}]}