{"paperId": "539fadfb615ef84c240f4741061c44eeda540091", "title": "Scaling Laws of RoPE-based Extrapolation", "abstract": "The extrapolation capability of Large Language Models (LLMs) based on Rotary Position Embedding is currently a topic of considerable interest. The mainstream approach to addressing extrapolation with LLMs involves modifying RoPE by replacing 10000, the rotary base of $\\theta_n={10000}^{-2n/d}$ in the original RoPE, with a larger value and providing longer fine-tuning text. In this work, we first observe that fine-tuning a RoPE-based LLM with either a smaller or larger base in pre-training context length could significantly enhance its extrapolation performance. After that, we propose \\textbf{\\textit{Scaling Laws of RoPE-based Extrapolation}}, a unified framework from the periodic perspective, to describe the relationship between the extrapolation performance and base value as well as tuning context length. In this process, we also explain the origin of the RoPE-based extrapolation issue by \\textbf{\\textit{critical dimension for extrapolation}}. Besides these observations and analyses, we achieve extrapolation up to 1 million context length within only 16K training length on LLaMA2 7B and 13B.", "venue": "arXiv.org", "year": 2023, "citationCount": 38, "influentialCitationCount": 5, "openAccessPdf": {"url": "https://arxiv.org/pdf/2310.05209", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes a unified framework from the periodic perspective, to describe the relationship between the extrapolation performance and base value as well as tuning context length, and achieves extrapolation up to 1 million context length within only 16K training length on LLaMA2 7B and 13B."}, "embedding": {"model": "specter_v2", "vector": [0.10780155658721924, 0.26108518242836, -1.0450713634490967, -0.1794033646583557, -0.22847585380077362, -0.04598589241504669, 0.6027969121932983, -0.3858772814273834, -0.7188032269477844, -0.15146546065807343, 0.548020601272583, -0.4252086877822876, 0.39309191703796387, 0.27637189626693726, -0.2149655818939209, 0.15763868391513824, -1.1706743240356445, -0.23719894886016846, 0.010640963912010193, -0.7413351535797119, -0.20954664051532745, -0.3806172311306, -0.4584111273288727, 0.14076194167137146, 0.3404525816440582, 0.5679411888122559, 0.039059076458215714, 1.185041904449463, -0.4009206295013428, -0.05995888262987137, 0.4140554666519165, -0.05914376676082611, 0.5190087556838989, 0.1068146601319313, 0.1707916557788849, -0.1329478621482849, 0.1541353017091751, -0.7685259580612183, -0.9248458743095398, 0.6931561827659607, -0.27309444546699524, 0.21358773112297058, 0.10568200796842575, -0.8168913125991821, -0.4650394320487976, 0.4711441099643707, 0.2511622905731201, 0.8660033941268921, -0.4659292995929718, -0.4987894892692566, 0.901399552822113, -1.402818202972412, -0.008529774844646454, 1.0710458755493164, 0.8019620776176453, 0.5065064430236816, -0.03426522761583328, -0.40064114332199097, 0.52267986536026, -0.201918825507164, -0.6949421167373657, -0.4498837888240814, 0.200169175863266, 0.19509203732013702, 1.4572651386260986, -0.3066272735595703, -0.1950434148311615, 0.7122665643692017, 0.07531961053609848, 0.9197052717208862, 0.28548455238342285, -1.0945818424224854, -0.06798525899648666, 0.34655845165252686, 0.34576496481895447, 0.26181575655937195, -0.3599305748939514, 0.27957913279533386, -1.0681934356689453, -0.36273786425590515, 0.08201158791780472, -0.32568246126174927, 0.23221632838249207, 0.02288181520998478, 0.06404733657836914, 0.6103401780128479, 0.47507038712501526, 0.3501971662044525, 0.04861928150057793, 0.947023332118988, 0.6434674859046936, 0.32061952352523804, 0.44615083932876587, -0.34017476439476013, -0.1795617789030075, 0.6064404845237732, -1.1587939262390137, 0.24721558392047882, -0.1385897845029831, 0.9511407613754272, -0.4453507959842682, -0.1225111335515976, -0.5964729189872742, 0.3747311532497406, 1.5313878059387207, -0.07897575199604034, 0.5757917761802673, -0.5250557065010071, 0.6985971331596375, -0.8446878790855408, 0.37530824542045593, -0.2726440727710724, -0.2680007219314575, -0.3844848573207855, -0.965149998664856, -0.8756803870201111, -0.4479330778121948, -0.13904811441898346, -0.40339818596839905, 0.9442839026451111, -0.14909198880195618, -0.02380981296300888, 0.24476279318332672, 0.37551432847976685, 0.04290638118982315, 0.8476666808128357, 0.42750102281570435, -0.30122900009155273, 0.9448882937431335, -1.1991169452667236, -0.645541787147522, -0.9196346998214722, 1.027353048324585, -0.24713045358657837, 0.6092062592506409, -0.315361350774765, -0.7941949963569641, -0.9750227332115173, -1.5938913822174072, 0.009721728973090649, -0.579703152179718, 0.5627002120018005, 0.8043942451477051, 0.6360598206520081, -1.2160719633102417, 0.9276503324508667, -0.40174275636672974, -0.028217140585184097, 0.3041855990886688, 0.30337923765182495, 0.3986146152019501, -0.2855427861213684, -1.6050406694412231, 0.2356182187795639, 0.5864292979240417, -0.45036581158638, 0.337630033493042, -0.5440981984138489, -0.6883053779602051, -0.11226260662078857, 0.35922953486442566, -0.4879147410392761, 1.0711498260498047, 0.3581730127334595, -1.6276423931121826, 0.19480404257774353, -0.09853047132492065, -0.15306122601032257, 0.6006292104721069, -0.4170789420604706, -0.8476661443710327, -0.41346535086631775, -0.5515938997268677, 0.8804827332496643, 0.2780509889125824, 0.047608520835638046, 0.03341072052717209, 0.22969818115234375, -0.4812169671058655, 0.12622042000293732, -0.7967786192893982, 0.7915132641792297, -0.7179951667785645, -0.33583155274391174, 0.22097553312778473, 0.24514073133468628, -0.5115723013877869, 0.034193068742752075, -0.31406253576278687, -0.9187321662902832, 0.932779848575592, -0.2874527871608734, 1.5267916917800903, -0.8551185727119446, -0.9769088625907898, -0.19644729793071747, -0.2960062623023987, 0.07901330292224884, -0.7122793793678284, 0.791790246963501, 0.02822430618107319, 0.6387792825698853, -0.025709088891744614, -1.111919641494751, -0.0272953100502491, -0.4979230761528015, -1.110879898071289, -0.268212229013443, -0.0940701961517334, 1.0270901918411255, -0.7611913681030273, 0.23317621648311615, -0.319540798664093, 0.33501142263412476, -0.7559714913368225, 0.8775923848152161, -0.642068088054657, 0.16933205723762512, 0.18233609199523926, -0.3601408004760742, 0.28374868631362915, -0.3370857536792755, 0.48339101672172546, 0.20442526042461395, 0.016579465940594673, 0.5766161680221558, -0.3155727684497833, 1.3453673124313354, -0.48364585638046265, 0.923783540725708, -0.24220480024814606, 0.0674201101064682, 0.26992419362068176, 0.20940986275672913, -0.6720014810562134, -0.0720253735780716, 0.13016989827156067, 0.6184794902801514, -0.7075085639953613, 0.45361751317977905, 1.2663332223892212, 0.9338827729225159, -0.44285187125205994, -0.04156804457306862, 0.2856746315956116, 0.14607419073581696, 0.3256870210170746, 0.3671695590019226, 0.020846186205744743, 0.5812727212905884, 0.4348593056201935, -0.26608651876449585, 0.644072413444519, -1.0363575220108032, -0.5081098675727844, 0.26268452405929565, 0.5641013979911804, 0.5027016997337341, 0.4647572934627533, -0.558954656124115, -0.7907645106315613, 0.1730712354183197, 0.3740931451320648, 1.5682311058044434, -0.05386201664805412, -0.4757995903491974, -0.8753196597099304, -0.3829420506954193, -0.550910234451294, 0.020506618544459343, -0.18651223182678223, 0.13364364206790924, -0.723183810710907, -1.2989641427993774, 1.1781282424926758, 0.42169442772865295, 0.8361182808876038, -0.11723632365465164, -0.0909186527132988, -0.3090297281742096, 0.42764660716056824, -0.9704098701477051, -0.8961983919143677, 0.17272624373435974, -0.9595029950141907, 0.5837095379829407, 0.00992207508534193, -0.1937391757965088, -0.003074836451560259, -0.7910171151161194, 0.3955627381801605, -0.2470245510339737, 0.24965731799602509, -0.3042944371700287, 0.5927820801734924, -0.4160776436328888, -1.2522292137145996, 0.5416350364685059, 0.6446148157119751, -0.39328548312187195, 0.3337356448173523, 0.4533151388168335, -0.12328449636697769, 0.21126273274421692, -0.3472713232040405, -0.009535854682326317, 0.08231831341981888, -0.07900839298963547, 0.6549496650695801, -0.5126127600669861, 0.4386668801307678, -0.689593493938446, 1.3419036865234375, 0.1280810385942459, -0.7443901896476746, 0.41721412539482117, -0.8538186550140381, -0.2668372690677643, 0.626620352268219, -0.9521807432174683, -0.1750761866569519, -1.271193504333496, -0.010082841850817204, -0.25750651955604553, 0.10705376416444778, 0.04713999480009079, 0.4527583718299866, 0.19580981135368347, 0.4997321665287018, 0.5742837190628052, 0.1776251643896103, -0.39878010749816895, 0.725995659828186, -0.01899586245417595, 0.5018802881240845, 0.3357575535774231, -0.09281077980995178, -0.3940765857696533, 0.19789928197860718, -0.9486778974533081, -0.15581803023815155, -0.42132753133773804, -0.3452720046043396, -0.03326365351676941, -0.1325254589319229, -0.6898845434188843, -0.5131835341453552, -0.20623436570167542, -0.9068468809127808, -0.15831606090068817, 0.24375523626804352, -0.22692951560020447, -0.3277813792228699, -0.815984845161438, -1.5966746807098389, -0.5727064609527588, -0.7942519783973694, -0.9477595090866089, 0.15591590106487274, 0.3275739550590515, -0.21132449805736542, -0.39378389716148376, -0.110107421875, -0.6994533538818359, 0.899054229259491, -0.645773708820343, 0.8602182865142822, -0.12389788776636124, -0.08908003568649292, -0.21595832705497742, 0.30923399329185486, 0.7128660082817078, -0.6374156475067139, 0.19585876166820526, -0.7920010089874268, 0.2301388829946518, -0.0168139711022377, -0.203721284866333, 0.15200263261795044, 0.252955824136734, 0.5059754848480225, -0.2760755121707916, -0.5523675680160522, 0.5461836457252502, 1.5245294570922852, -0.9034196138381958, 0.3192075192928314, 0.15755653381347656, 0.622594952583313, 0.09925709664821625, -0.30356892943382263, 0.5567070245742798, -0.20912712812423706, 0.6224362850189209, -0.16995254158973694, 0.04828675091266632, -0.1360398381948471, -0.9835556745529175, 0.6853784918785095, 2.0707435607910156, 0.603206217288971, -0.3321170210838318, -0.8460990786552429, 0.25143006443977356, -1.0441235303878784, -0.45519736409187317, 0.746181309223175, 0.9255033135414124, 0.513342022895813, -0.00929119624197483, -0.09007130563259125, -0.06507904827594757, 0.5157788395881653, 0.6287435293197632, -0.26993098855018616, -1.0007177591323853, 0.05693104863166809, -0.36501753330230713, 0.5772541165351868, 0.4883614182472229, -0.2546122968196869, 0.5568937659263611, 14.800018310546875, 1.278210997581482, 0.012575834058225155, 0.6081377863883972, 1.0174095630645752, 0.3974437415599823, -0.2712506651878357, -0.2698516249656677, -1.7968945503234863, 0.5022430419921875, 1.728547215461731, 0.17497394979000092, 0.47895339131355286, 0.098847396671772, -0.15076592564582825, 0.3045584261417389, -0.30051255226135254, 0.44773420691490173, 0.4844514727592468, -1.667073369026184, 0.2679365575313568, 0.1521315574645996, 0.7907472848892212, 0.974169135093689, 0.8844720125198364, 0.758933961391449, -0.06069495528936386, -0.21521757543087006, 0.39239636063575745, -0.11821896582841873, 1.3052914142608643, -0.2104935199022293, 0.1549557000398636, 0.845247745513916, -0.5828057527542114, -0.16541296243667603, -0.8303442597389221, -1.0391443967819214, 0.14352639019489288, 0.16601219773292542, -0.7418336868286133, -0.5078606009483337, -0.48949572443962097, 0.23451344668865204, 0.12585784494876862, 0.21626657247543335, -0.33399131894111633, 0.7545934915542603, -0.4541037380695343, -0.1597379595041275, 0.4326384961605072, 0.13729141652584076, 0.2779887616634369, 0.016216859221458435, 0.4082610309123993, -0.3487260937690735, -0.03183899074792862, 0.20352624356746674, -0.9581759572029114, 0.09234259277582169, -0.14666898548603058, -0.07511735707521439, -0.07355646789073944, 0.7738579511642456, 0.4754285216331482, 0.24234820902347565, -0.27004772424697876, 0.3367167115211487, 0.4762304127216339, 0.43272534012794495, -0.516112208366394, -0.183956578373909, 0.3345484733581543, -0.1830420196056366, -0.16268515586853027, 0.08441022783517838, -0.34174489974975586, -0.4601611793041229, -0.3988025486469269, -0.3117784559726715, -0.38706257939338684, -0.6771037578582764, -0.4863382577896118, 1.1960992813110352, 0.013119656592607498, -0.7057374119758606, 0.2954343855381012, -0.7199906706809998, -0.1985277682542801, 0.6561181545257568, -1.410359501838684, -0.6235040426254272, 0.7939121723175049, -0.7685367465019226, -0.1951974779367447, -0.057151708751916885, 1.0016634464263916, -0.07471203804016113, -0.22672845423221588, 0.4388050138950348, 0.5353907942771912, -0.293163001537323, -0.15056893229484558, -0.4731789827346802, 1.332764983177185, 0.3694502115249634, -0.027720607817173004, 0.29724621772766113, -0.04701484739780426, 0.49481216073036194, -0.5089730024337769, -0.07311651110649109, 0.5395561456680298, -0.8734703063964844, -0.2092055380344391, -1.0177687406539917, -0.8231383562088013, 0.18698684871196747, 0.6851984858512878, -0.031495995819568634, 0.30299699306488037, 0.08789388090372086, -0.5969967842102051, 0.07052114605903625, -0.5009004473686218, 0.4655386805534363, 0.3741818964481354, -0.7991501688957214, -0.17712600529193878, -0.05584130063652992, 0.8931119441986084, -1.2065370082855225, -0.6286013722419739, -0.07449673861265182, -0.03388252481818199, -0.07004116475582123, 1.1131560802459717, -0.4026559889316559, 0.9538828134536743, 0.6856304407119751, -0.44685858488082886, -0.48288676142692566, 0.4804961383342743, -1.1000981330871582, -0.2972596287727356, 0.18977420032024384, 0.7301726937294006, -0.24109794199466705, 0.3488893508911133, 0.6218377351760864, 0.49423089623451233, -1.1158279180526733, -0.6205061674118042, -0.6327055096626282, 0.42538052797317505, -0.7506767511367798, 0.29613399505615234, -0.4435105323791504, 0.018806524574756622, 0.23290318250656128, -0.18029731512069702, 0.793261706829071, -0.2789249122142792, -0.9372158050537109, 0.1272682100534439, 0.38065090775489807, -0.3707452714443207, -0.31389638781547546, -0.17442892491817474, -2.0183420181274414, -0.060426946729421616, -1.0805752277374268, -0.1011183112859726, -0.37879499793052673, -0.6511300206184387, -0.15139365196228027, -0.23390722274780273, -0.5565110445022583, 0.48461034893989563, -0.020655207335948944, -0.07774873822927475, -0.2868861258029938, -0.32842642068862915, 0.9801530838012695, 0.593317985534668, -0.3312915861606598, -0.33106034994125366, 0.2156435251235962, 0.3464222848415375, 0.5065748691558838, 0.7379372715950012, -0.3581900894641876, -0.8757951259613037, -1.1954805850982666, 0.7321768999099731, -0.17282947897911072, -0.288675457239151, -0.7385023832321167, 0.6598384380340576, 0.39837831258773804, 0.06427418440580368, 0.06819858402013779, 0.32511216402053833, -0.7441815733909607, -0.6936209797859192, 0.31969472765922546, -1.000126838684082, 0.2043607085943222, 0.545223593711853, -0.1500059962272644, -0.08252065628767014, 0.4619501829147339, -0.1577625870704651, -0.11493825912475586, -0.670428454875946, 0.3600374758243561, -0.40746620297431946, 0.08594552427530289, -0.45690491795539856, -0.07874371111392975, -1.2350821495056152, -0.10355338454246521, -0.15852904319763184, 0.3284458518028259, -0.0934973657131195, 0.9421468377113342, 0.05422823131084442, -1.4754338264465332, 0.29843196272850037, 0.523897647857666, -0.19865475594997406, -0.4194043278694153, 0.5415188074111938, 0.4612341523170471, -0.3132948875427246, 0.7709285616874695, 0.47314444184303284, 0.20874829590320587, -0.8875643610954285, 0.2779858708381653, 0.25340795516967773, -0.5584830045700073, -0.4378414750099182, 1.0071871280670166, -0.559570848941803, -0.8909029364585876, 0.002303437562659383, -1.269010066986084, -0.24402786791324615, -0.5392549633979797, 0.8579829335212708, 0.38146090507507324, -0.23325681686401367, 0.1450694352388382, -0.33332037925720215, 0.2597535252571106, -0.15733222663402557, -0.5190584063529968, 0.03077632002532482, -0.3691173195838928, -0.3161613643169403, 0.59885174036026, 1.019858479499817, -0.22220639884471893, -1.0845654010772705, -0.8301905989646912, -0.2011311650276184, -0.1672438383102417, 0.13943377137184143, -0.17449504137039185, 0.33605048060417175, 0.8392555713653564, 0.587251603603363, 0.23991163074970245, 0.33770403265953064, -0.3203893303871155, 0.3507838845252991, 0.4689357876777649, 0.17616620659828186, -0.6475117206573486, -0.7257887721061707, 1.0794074535369873, 1.5146968364715576, -0.9874101281166077, 0.5712129473686218, -0.34962427616119385, -0.6629210710525513, 0.9416826963424683, 0.13833479583263397, -0.034577060490846634, 1.0162665843963623, -0.013070420362055302, 0.02737092599272728, 0.9854267239570618, -1.2517848014831543, 0.4461838901042938, 0.7846488952636719, 0.4900369346141815, 0.39493992924690247, 0.14282983541488647, -0.2028491050004959, 0.8492105603218079, -0.0072319176979362965, 0.34737294912338257, 0.5508489012718201, 0.242085799574852, -0.311326801776886, -0.36169007420539856, -0.12051631510257721, 0.3334463834762573, -0.7299259305000305, -0.8545024991035461, 0.4448006749153137, 0.6178977489471436, 0.030821798369288445, 0.5109685659408569, 0.7213879823684692, -0.3315703272819519, -0.03819240257143974, 0.25114017724990845, 0.3523457944393158, -0.24910372495651245, -0.19824084639549255, -0.01972244493663311, -0.7430959939956665, 0.4545377790927887, 0.23889432847499847, 0.13328111171722412, -0.18749473989009857, -0.3824751675128937, 0.16849882900714874, -0.19383226335048676, 0.553699791431427, 0.8336991667747498, 0.5759676694869995, 0.20223577320575714, -0.03751746565103531, -0.4736320972442627, -0.970714271068573, -1.0455831289291382, 0.0437946692109108, -0.8942537903785706, -0.1540042608976364, 0.6204680800437927, 0.03539014980196953, -0.43957844376564026]}, "authors": [{"authorId": "2257094943", "name": "Xiaoran Liu"}, {"authorId": "146948229", "name": "Hang Yan"}, {"authorId": "2257086624", "name": "Shuo Zhang"}, {"authorId": "2064164220", "name": "Chen An"}, {"authorId": "2256661980", "name": "Xipeng Qiu"}, {"authorId": "2258618409", "name": "Dahua Lin"}], "references": [{"paperId": "836b9658eb81f321de90423b6259b07a398ca79b", "title": "CoLLiE: Collaborative Training of Large Language Models in an Efficient Way"}, {"paperId": "8511ea96d61593de57cbc2e996910e5cb3dbfe84", "title": "DISTFLASHATTN: Distributed Memory-efficient Attention for Long-context LLMs Training"}, {"paperId": "02ad9f3fefe33cb9ca546591bec65dbdf7766c80", "title": "Ring Attention with Blockwise Transformers for Near-Infinite Context"}, {"paperId": "5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0", "title": "Qwen Technical Report"}, {"paperId": "a51ac7a5e8f6454268ac16ecdc52ecac98ce54d9", "title": "DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models"}, {"paperId": "819bbdc2dac9e13d9ca3e2508a6e063186ce5e40", "title": "YaRN: Efficient Context Window Extension of Large Language Models"}, {"paperId": "0b0debb710366cdff461938c80763eace1651af6", "title": "Code Llama: Open Foundation Models for Code"}, {"paperId": "2dfb9171e180dcb0af23d305e024d43d311708ab", "title": "Giraffe: Adventures in Expanding Context Lengths in LLMs"}, {"paperId": "b0db25e317cf856f1ec1ca3df0e573d850ed4696", "title": "L-Eval: Instituting Standardized Evaluation for Long Context Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "9575afb5702bc33d7df14c48feeee5901ea00369", "title": "A Length-Extrapolatable Transformer"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "bc8b82e8eb0b0714892e4ec7a54ebdf47c4fde96", "title": "Reducing Activation Recomputation in Large Transformer Models"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "38115e80d805fb0fb8f090dc88ced4b24be07878", "title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis"}, {"paperId": "d3dd80269f2542cc173afb3a1df24b582a1e4af2", "title": "Overcoming a Theoretical Limitation of Self-Attention"}, {"paperId": "3c209e0703ffff26231b1145268c935df494631a", "title": "QuALITY: Question Answering with Long Input Texts, Yes!"}, {"paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea", "title": "Training Verifiers to Solve Math Word Problems"}, {"paperId": "77d956cdab4508d569ae5741549b78e715fd0749", "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "16e623059ffccab60f4c35be028a2d4f10933515", "title": "Sequence Parallelism: Long Sequence Training from System Perspective"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3", "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"}, {"paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0", "title": "Natural Questions: A Benchmark for Question Answering Research"}, {"paperId": "d9f6ada77448664b71128bb19df15765336974a6", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"}, {"paperId": "6398cb8f2af1c988a097ed1e1cefb380195edfb8", "title": "(Preprint)"}, {"paperId": "1536e8958697c5364f68b2e2448905dbbeb3a0ca", "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering"}, {"paperId": "88bb0a28bb58d847183ec505dda89b63771bb495", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"}, {"paperId": "21633a4ef076e21ec116856a003efb1bb033a470", "title": "Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine"}, {"paperId": "5ed791f810da580c78df6a052c6b9f2e258f6b0a", "title": "The LAMBADA dataset: Word prediction requiring a broad discourse context"}, {"paperId": "e3aa232577bb427b1f3a34acbdef84bd85734042", "title": "LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models"}, {"paperId": null, "title": "Improving transformer: Length extrapolation ability and position robustness. https://spaces.ac.cn/archives/9444, 2023b"}, {"paperId": "0eedbc38bc215fdbe4e5bcde8aeac08fb3ce9f44", "title": "Parallel Context Windows Improve In-Context Learning of Large Language Models"}, {"paperId": null, "title": "Rethinking attention with per-formers"}, {"paperId": null, "title": "Big bird: Trans-formers for longer sequences"}, {"paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28", "title": "An Adversarial Winograd Schema Challenge at Scale"}, {"paperId": "015ca32bca81dbda1e2e432445eef798582236e1", "title": "Conference Paper"}, {"paperId": null, "title": ". Dynamically scaled rope further increases performance of long context llama with zero fine-tuning, July 2023a"}, {"paperId": null, "title": "primary objective"}, {"paperId": null, "title": "Hugging Face"}, {"paperId": null, "title": "Ntk-aware scaled rope allows llama models to have extended (8k+) context size without any fine-tuning and minimal perplexity degradation"}, {"paperId": null, "title": "How long can open-source llms truly promise on context length?"}, {"paperId": null, "title": "Rerope: Rectified rotary position embeddings, July 2023c"}, {"paperId": null, "title": "Nbce: Naive bayes-based context extension"}, {"paperId": null, "title": "LocalLLaMA"}]}