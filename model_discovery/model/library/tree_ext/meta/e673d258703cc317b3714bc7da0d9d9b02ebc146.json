{"paperId": "e673d258703cc317b3714bc7da0d9d9b02ebc146", "title": "PASS: Pruning Attention Heads with Almost-sure Sparsity Targets", "abstract": "Transformer models have been widely used to obtain high accuracy values in multiple fields including natural language processing (NLP), computer vision, and more. This superior performance typically comes at the expense of substantial computational overhead. Multi-head attention is the key factor in the success of Transformer models that has been found to be computationally expensive. Significant research effort has been devoted to improving attention compute efficiency by pruning redundant attention heads. A widely adopted paradigm is to jointly learn a set of gate variables and apply thresholds on gate values to prune heads. Previous work shows a high level of sensitivity to threshold tuning which can limit subnetwork performance and prevent them from wider adoption in practice. We propose the notion of almost-sure sparsity to overcome this limitation and develop a generic framework for P runing with A lmost-S ure S parsity (PASS) targets over attention heads. To further boost efficiency, we design a novel technique, concentrator , based on which we develop PASSCONC ( PASS with CONC entrator). We also present a simple-yet-effective strategy to further improve subnetwork performance by clipping and selectively reopening learned gates. We investigate PASS and PASSCONC on two widely studied architectures: encoder-decoder (ED) Transformer and encoder-only Transformer (e.g., BERT). Experiments on IWSLT14 German-to-English translation and GLUE benchmark tasks demonstrate that our approaches outperform the SOTA by achieving up to 1 . 33 higher BLEU scores, 1 . 44% higher accuracy, and 60% higher attention speedups.", "venue": "", "year": null, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The notion of almost-sure sparsity is proposed to overcome this limitation and develop a generic framework for P runing with A lmost-S ure S parsity (PASS) targets over attention heads and a simple-yet-effective strategy to further improve subnetwork performance by clipping and selectively reopening learned gates."}, "embedding": {"model": "specter_v2", "vector": [0.30875808000564575, 1.0116121768951416, -0.734373927116394, 0.2478225827217102, -0.7455883622169495, 0.11589628458023071, 0.23102153837680817, -0.37163203954696655, -0.12934447824954987, -0.11468673497438431, 0.7509909868240356, 0.009947706013917923, 0.32909828424453735, -0.00028696347726508975, -0.2789692282676697, 0.16385886073112488, -0.6926955580711365, 0.28072142601013184, -0.03624353185296059, -0.09027286618947983, -0.3760695159435272, -1.0629831552505493, -0.8650079965591431, 0.11571823060512543, 0.5603230595588684, 0.4960483908653259, 0.07432407885789871, 0.5328828692436218, -0.16528210043907166, 0.520189106464386, 0.3741908371448517, -0.6812920570373535, 0.3416663110256195, -0.36303699016571045, -0.1490734964609146, 0.018037224188447, 0.17591869831085205, -0.26338183879852295, -0.20558644831180573, 1.1110981702804565, -0.15285730361938477, 0.05949651077389717, 0.09331894665956497, -0.4892813563346863, -0.3686772882938385, 1.5091075897216797, 0.42631471157073975, 0.7426066398620605, -0.4338862895965576, -0.5145794749259949, 1.7497429847717285, -1.684217095375061, 0.43412384390830994, 1.4086041450500488, 0.38187894225120544, 0.049892012029886246, -0.028509007766842842, -0.2215399444103241, 0.7191740870475769, 0.510443389415741, -0.9552380442619324, -0.7476431727409363, 0.0491161122918129, 0.4820459187030792, 2.1486942768096924, -0.29962438344955444, -0.06071789562702179, -0.11839055269956589, 0.21233855187892914, 1.6687238216400146, -0.1944769024848938, -0.7616159915924072, -0.15575017035007477, -0.27350762486457825, 0.026481561362743378, 0.861882209777832, -0.3726101517677307, 0.14988721907138824, -0.9081006050109863, 0.14439541101455688, 0.002439564559608698, 0.06961968541145325, -0.15583306550979614, 0.12804093956947327, -0.10081817209720612, 0.5233159065246582, 0.6150981187820435, 0.8212519884109497, -0.4340200126171112, 0.7002183794975281, 0.37913596630096436, 0.42227867245674133, 0.10366712510585785, 0.3220660090446472, -0.5375413298606873, 0.47984257340431213, -0.9475848078727722, -0.09014971554279327, 0.1946956366300583, 1.3029097318649292, -0.16502654552459717, 0.29888275265693665, -0.9075192809104919, -0.031159570440649986, 1.0565800666809082, 0.06121918931603432, 0.2892701327800751, -0.2812407612800598, 0.3486037850379944, -0.32307738065719604, -0.4109155535697937, -0.2905224561691284, 0.12676453590393066, -0.49967220425605774, -0.8229256868362427, -1.401585578918457, -0.6819126605987549, 0.043546952307224274, -0.9845448732376099, 0.6335362195968628, -0.5328802466392517, 0.09742966294288635, -0.3130958378314972, 0.6733635663986206, 0.47611352801322937, 0.3099405765533447, 0.5426883101463318, 0.1524490863084793, 1.0279461145401, -0.8663673996925354, -0.5936919450759888, -1.1620376110076904, 0.7785100340843201, -0.4623830318450928, 0.023076364770531654, -0.14016801118850708, -1.5113511085510254, -0.5604243874549866, -0.6617113351821899, 0.11034709215164185, -0.5907176733016968, 0.4076167941093445, 0.774919331073761, 0.4544365704059601, -1.1435256004333496, 0.6562173962593079, -0.3596545457839966, -0.22141830623149872, 0.6650714874267578, 0.7346433401107788, 0.11483864486217499, -0.5065547227859497, -0.9540637135505676, 0.22005826234817505, 0.17130520939826965, -0.5801824927330017, -0.008902528323233128, -0.7876699566841125, -1.0528664588928223, 0.45317450165748596, 0.7140321731567383, -0.5963324308395386, 1.0814721584320068, -0.16499893367290497, -1.1493020057678223, 0.6320716142654419, -0.5491116642951965, 0.018902847543358803, 0.02283019945025444, -0.4124062955379486, -0.1332312971353531, -0.5444144606590271, -0.045003559440374374, 0.269263356924057, 0.5404689311981201, 0.08392483741044998, -0.33292821049690247, 0.0344429574906826, -0.3001771569252014, -0.24186141788959503, -0.01970839686691761, 1.04634428024292, -0.6554805040359497, 0.006141221150755882, 0.5554291009902954, 0.9485803842544556, 0.10946694016456604, -0.27220189571380615, -0.7189017534255981, -1.0476977825164795, 0.6481920480728149, 0.14948619902133942, 0.939480185508728, -0.5811293125152588, -0.19697025418281555, -0.19898968935012817, 0.11392064392566681, -0.0182882659137249, -0.6040438413619995, 0.09777858108282089, -0.5997350215911865, 0.49901852011680603, -0.13902094960212708, -1.2362425327301025, 0.20420803129673004, -0.014178553596138954, -0.5217772722244263, 0.12821237742900848, 0.5480828285217285, 1.4910036325454712, -0.6903631091117859, -0.11582673341035843, -0.00022549735149368644, 0.18416674435138702, -1.380519986152649, 0.9260995388031006, -0.32800665497779846, -0.2267264425754547, -0.25926634669303894, 0.4735688865184784, 0.045033104717731476, -0.20653928816318512, 0.44467490911483765, -0.4808424115180969, -0.0590515099465847, 0.6576098799705505, -0.39733296632766724, 0.7135941982269287, -0.041742824018001556, 0.19659312069416046, 0.1395956426858902, -0.9827257394790649, 0.11674099415540695, 0.3707193434238434, -0.32862308621406555, -0.7167336940765381, 0.8863752484321594, 0.7085825204849243, -0.4757544696331024, 0.34570369124412537, 0.6776280999183655, 0.5619710087776184, -0.43541473150253296, -0.3290121555328369, 1.1611977815628052, -0.25924745202064514, 0.5253971815109253, 0.1740598827600479, 0.7485235333442688, 0.4598335027694702, 0.6245569586753845, -0.11996474117040634, 0.37816014885902405, -0.8217914700508118, 0.3683605492115021, 0.40498286485671997, 0.46528682112693787, 0.7818800806999207, 0.7839446663856506, -0.5675563812255859, -0.39925992488861084, 0.3630158603191376, 0.672234058380127, 1.629602313041687, -0.10145839303731918, -0.20128826797008514, -0.8130280375480652, -0.38962164521217346, -0.7009443044662476, -0.05139224976301193, -0.3041248619556427, -0.4270629286766052, -0.6317213177680969, -1.2002415657043457, 0.6690117120742798, 0.3772866725921631, 1.163240909576416, -0.3472047746181488, -0.15682539343833923, -0.09515757113695145, 0.21873100101947784, -1.0879052877426147, -0.4385251998901367, 0.8738847374916077, -0.3644346594810486, -0.35962045192718506, 0.17781266570091248, -0.2904030680656433, 0.36652472615242004, -0.8966216444969177, 1.2758151292800903, -0.3616009056568146, -0.32259035110473633, -0.048374731093645096, 0.28054994344711304, -0.6467001438140869, -0.17841649055480957, 0.5249611139297485, -0.09144102036952972, -0.24657042324543, 0.946469247341156, 0.534831166267395, 0.17347648739814758, 0.07535720616579056, -0.16682648658752441, -0.022246016189455986, 0.13166223466396332, 0.3134306073188782, 0.9988030791282654, -0.36217182874679565, -0.20644155144691467, -1.0571155548095703, 0.3720269501209259, -0.04668017476797104, -0.2911015450954437, -0.06630977243185043, -0.1500300019979477, -0.5728353261947632, 0.7587246298789978, -0.22599074244499207, -0.08877988904714584, -0.9018678069114685, 0.4265281856060028, -0.5298346281051636, 0.05148569867014885, 0.3643456995487213, -0.1748928427696228, 0.2679383456707001, 0.09792719781398773, 0.20858608186244965, -0.1066131666302681, -0.1276640146970749, 0.5645501017570496, -1.0454171895980835, 0.42543676495552063, 0.09420536458492279, 0.06621100008487701, -0.20149002969264984, -0.05957704782485962, -0.4079892933368683, -0.35929954051971436, -0.44361546635627747, -0.17653843760490417, 0.09961159527301788, -0.007861994206905365, -0.7664228081703186, -0.2750092148780823, -0.3459830582141876, -1.0256435871124268, -0.10029363632202148, -0.11103775352239609, -0.14250673353672028, -0.3024105429649353, -1.547074317932129, -1.0762146711349487, -0.2579498589038849, -0.7555988430976868, -1.1436887979507446, 0.7786474823951721, 0.13463540375232697, -0.4304923713207245, -0.2739432454109192, -0.32124197483062744, -0.5888511538505554, 0.849680483341217, -0.7267689108848572, 0.7067621350288391, -0.43899497389793396, -0.6473156809806824, -0.25778302550315857, 0.10929592698812485, 0.27700841426849365, -0.39715576171875, -0.27852004766464233, -0.7031732201576233, 0.3872484266757965, -0.48952043056488037, -0.06820269674062729, 0.3265554904937744, 0.4813060164451599, 0.5014355182647705, -0.18535855412483215, -0.5612601637840271, 0.6146216988563538, 1.4581354856491089, -0.9442023634910583, 0.4268493950366974, 0.13545507192611694, 0.8017565608024597, 0.02892342396080494, -0.15796639025211334, 0.3206144869327545, 0.19548597931861877, 0.18639615178108215, 0.49457040429115295, -0.18516945838928223, -0.45458388328552246, -0.5743924379348755, 0.4244237244129181, 1.6588951349258423, 0.06282391399145126, -0.03246114030480385, -0.7829897403717041, 1.184417486190796, -1.3119455575942993, -0.5861509442329407, 0.44804736971855164, 0.40712836384773254, 0.18616977334022522, -0.265473872423172, -0.4821533262729645, -0.2673812806606293, 0.5492706298828125, 0.08253659307956696, -0.07201122492551804, -0.5986897945404053, -0.13059493899345398, 1.0160716772079468, 0.7418498992919922, 0.45525553822517395, -0.35786208510398865, 1.03495192527771, 14.98514461517334, 0.8072296380996704, 0.08690880984067917, 0.7468970417976379, 0.6884552836418152, 0.1457233428955078, -0.37945228815078735, 0.2523611783981323, -1.244396686553955, -0.18307599425315857, 0.788105845451355, 0.07596759498119354, 0.32026493549346924, 0.39378422498703003, 0.05521983653306961, 0.2658809423446655, -0.5898659229278564, 0.36346423625946045, 0.6611633896827698, -1.0691524744033813, 0.4903819262981415, 0.20825965702533722, 0.6215776801109314, 0.7566083073616028, 0.6478776931762695, 0.9863972663879395, 0.5728545188903809, -0.47575029730796814, 0.44204163551330566, 0.03581241890788078, 0.814245879650116, -0.05753589794039726, 0.6800984740257263, 0.1312023550271988, -0.8295068144798279, -0.3050376772880554, -0.7615060210227966, -1.2293275594711304, 0.19850710034370422, 0.49401983618736267, -0.29400765895843506, -0.2606298327445984, -0.23045042157173157, 0.8221838474273682, 0.40969783067703247, 0.660115659236908, -0.6116160154342651, 0.7227933406829834, -0.4875440001487732, 0.22280339896678925, 0.31385812163352966, 0.558163583278656, 0.43830496072769165, -0.019942693412303925, 0.25574758648872375, 0.021241186186671257, 0.07414739578962326, 0.7881550788879395, -1.0312974452972412, -0.15148627758026123, -0.12260850518941879, -0.0029443928506225348, -0.043085575103759766, 0.7487178444862366, 0.17130522429943085, 0.15614871680736542, -0.5205079913139343, 0.16322898864746094, 0.4555605351924896, 0.0726986825466156, -0.2554756999015808, -0.39068302512168884, 0.1947648525238037, -0.2890655994415283, 0.4358491003513336, 0.8875254392623901, -0.3247433006763458, -0.5907301306724548, -0.7684112191200256, -0.4610641598701477, 0.40510305762290955, -0.6549930572509766, -0.12295621633529663, 0.4779741168022156, -0.4793774485588074, -0.47632744908332825, 0.35440677404403687, -0.7159497141838074, -0.5433014035224915, 0.39800378680229187, -1.6065977811813354, -0.9575638771057129, 0.4513281285762787, -0.1507922261953354, -0.043410345911979675, -0.0806514322757721, 0.9864851832389832, 0.2447354942560196, -0.45645561814308167, 0.2556487023830414, -0.38887274265289307, -0.11166920512914658, -0.31575900316238403, -0.7959986329078674, 0.6336604952812195, 0.5386963486671448, -0.18017295002937317, 0.41828617453575134, 0.18117055296897888, 0.37503984570503235, -1.0165976285934448, -0.12857088446617126, 1.1696397066116333, -0.6514806747436523, -0.33672311902046204, -0.30865785479545593, -0.49433502554893494, 0.6176143884658813, 0.6096028089523315, -0.03212288022041321, 0.27819085121154785, 0.1888832151889801, -0.4146760404109955, 0.04045393690466881, -0.6605546474456787, -0.0032478338107466698, 0.6673161387443542, -0.7102105617523193, -0.6427174210548401, -0.18508301675319672, 0.22481243312358856, -1.1704879999160767, -0.3281182646751404, -0.17305836081504822, -0.3649022579193115, 0.03086697869002819, 0.6902241110801697, -0.3246026337146759, 0.9739490747451782, 0.650931715965271, -0.22093331813812256, -0.7948250770568848, 0.15484678745269775, -1.2387239933013916, -0.167045459151268, 0.172970712184906, 0.6288818120956421, -0.2083863914012909, 0.09460695087909698, 0.6674477458000183, -0.05855913832783699, -0.4886855185031891, -1.0009535551071167, -0.024199483916163445, 0.07106857746839523, -0.4056929349899292, 0.551659107208252, 0.025664353743195534, 0.2092452049255371, -0.022142980247735977, 0.622808575630188, 0.5858879089355469, -0.015214639715850353, -0.6518042683601379, 0.0760870948433876, 0.004377434495836496, 0.03417746350169182, -0.4324887990951538, -0.759925365447998, -1.4366984367370605, 0.054765429347753525, -1.0770686864852905, 0.03369516134262085, -0.7130730748176575, -0.28690269589424133, 0.27465882897377014, -0.3601248264312744, 0.44447046518325806, 0.20937776565551758, 0.11962467432022095, -0.5319246649742126, -0.5486367344856262, -1.0053775310516357, 1.0006113052368164, 0.7393272519111633, -0.9307314157485962, 0.11612852662801743, -0.45257681608200073, -0.3748238980770111, 0.4206022024154663, 0.3509567677974701, -0.47248348593711853, -0.327341228723526, -1.4603689908981323, 0.4294370114803314, -0.35251033306121826, -0.07431420683860779, -0.6516190767288208, 0.8894405364990234, 0.6182489395141602, -0.2921490967273712, 0.08141360431909561, 0.03843254968523979, -0.9467571973800659, -0.937210738658905, 0.19563403725624084, -0.2717546224594116, -0.24893857538700104, 0.11298692226409912, -0.8688879609107971, -0.5000118017196655, 0.7495619654655457, 0.13677512109279633, -1.3918287754058838, -0.5948076844215393, 0.331008642911911, -0.44456472992897034, 0.3059294521808624, -0.2963925302028656, -0.18718792498111725, -1.0029717683792114, -0.06543508172035217, -0.2579050362110138, 0.34779679775238037, -0.5511000156402588, 0.7290446758270264, 0.22500266134738922, -0.9235123991966248, 0.01063535176217556, 0.3925092816352844, -0.13596892356872559, 0.12972010672092438, -0.08890033513307571, 0.673664927482605, -0.11273887008428574, 0.7889866828918457, 0.5370572805404663, 0.20588819682598114, -0.7743718028068542, -0.22002683579921722, 0.7824084162712097, -0.6329019665718079, -0.3088782727718353, 1.1273220777511597, -0.5364488959312439, -0.9852133989334106, -0.11069190502166748, -1.2528595924377441, -0.2037706971168518, -0.3647238314151764, 0.6526928544044495, 0.20750238001346588, 0.3729519546031952, -0.30862921476364136, -0.7172272801399231, 0.1528787463903427, -0.13450822234153748, 0.06062861531972885, 0.870924711227417, -0.026193294674158096, -0.6326119899749756, -0.18307334184646606, 0.6631466150283813, -0.8119555115699768, -0.27783817052841187, -0.8099114298820496, -0.42619597911834717, 0.05097071826457977, 0.7132464051246643, -0.19568628072738647, -0.8745130896568298, 0.5930843353271484, -0.026684217154979706, 0.023008257150650024, 0.2254907190799713, 0.026123549789190292, -0.05594406649470329, 0.4355272650718689, 0.37128087878227234, -0.7391884922981262, -0.9431700110435486, 1.4365224838256836, 0.9535558223724365, -0.6563354730606079, 0.32821395993232727, -0.5330994129180908, -0.4827568233013153, 0.480664998292923, 0.24672217667102814, -0.28696006536483765, 0.7875544428825378, 0.13150975108146667, -0.39491376280784607, 0.030720675364136696, -0.9295122027397156, -0.8289039134979248, 0.41586291790008545, 1.1739131212234497, 0.8856222033500671, 0.17390219867229462, -0.0493990033864975, 1.2786555290222168, 0.13624325394630432, 0.34893903136253357, 0.416267991065979, 0.3117668628692627, -0.16796110570430756, -0.0003975227882619947, -0.07626470178365707, 0.6391340494155884, -1.1242196559906006, -0.9739565253257751, -0.05343221500515938, 0.5510663390159607, 0.2882538437843323, 0.6596904993057251, 0.6481499075889587, 0.3773043751716614, 0.8267599940299988, 0.11296135932207108, 0.31580281257629395, -0.7533208131790161, -0.2724860608577728, 0.012715509161353111, -0.5041467547416687, -0.30052074790000916, -0.21004553139209747, -0.2770267724990845, -0.19855791330337524, -0.278287410736084, -0.1904309093952179, -0.2545928359031677, 0.0615018829703331, 1.3115313053131104, 0.737358033657074, 0.8614248633384705, -0.49879688024520874, -0.5093725323677063, -0.2423529326915741, -0.7319115996360779, -0.1157931238412857, -0.5566827654838562, -0.1934162825345993, 0.12423716485500336, -0.36217185854911804, -0.1348649561405182]}, "authors": [], "references": [{"paperId": "97b6f4357d1e3ab40a7ee60acb5260a948e3641d", "title": "Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing"}, {"paperId": "ddbd8fe782ac98e9c64dd98710687a962195dd9b", "title": "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection"}, {"paperId": "abdb0f9d1486dbb024c4bc9f8f9dc40464c58715", "title": "Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning"}, {"paperId": "10bd38673951f5d7729568284093cbd80482ab16", "title": "Vision Transformers Need Registers"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "888728745dbb769e29ed475d4f7661eebe1a71cf", "title": "A Survey on Evaluation of Large Language Models"}, {"paperId": "993df7df129f8d18816877d69923d7df7b347d85", "title": "LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion"}, {"paperId": "28c61adcba65ccb1d9c7b8e9ed65815e51bc51d6", "title": "Revisiting Gradient Clipping: Stochastic bias and tight convergence guarantees"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "9e82736043eebe3f71eb86cbef6e2ac45306ece5", "title": "Structured Pruning Learns Compact and Accurate Models"}, {"paperId": "d291149a75d7ac194382bd61e515eb40ed0aa106", "title": "Predicting Attention Sparsity in Transformers"}, {"paperId": "7a27cc0cc37931e85315ed41333f01cb6de18c02", "title": "Differentiable Subset Pruning of Transformer Heads"}, {"paperId": "a93632237958800217341d7bad847200afdd60e3", "title": "Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better"}, {"paperId": "73e0f38ab49b19b86321016b773e15f1d02e3a72", "title": "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning"}, {"paperId": "6346222f4d308dad8e716e0fd33be470f6e94cbb", "title": "Losing Heads in the Lottery: Pruning Transformer Attention in Neural Machine Translation"}, {"paperId": null, "title": "Transformers: State-of-the-Art Natural Language Processing"}, {"paperId": "9baab08fbe37369856688b2abe5b3c90cce1682c", "title": "Compression of Deep Learning Models for Text: A Survey"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "91ac65431b2dc46919e1673fde67671c29446812", "title": "When BERT Plays the Lottery, All Tickets Are Winning"}, {"paperId": "39f8cc684f09ea2b43767f5b9590896774802759", "title": "On the effect of dropping layers of pre-trained transformer models"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "83b8108014e3db4f46354a28ae68193f143c4e7e", "title": "Structured Pruning of Large Language Models"}, {"paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d", "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"}, {"paperId": "f6390beca54411b06f3bde424fb983a451789733", "title": "Adaptively Sparse Transformers"}, {"paperId": "e26e0e5dc6fe766c4ba1c3c14fc9c971f96d405a", "title": "Natural Language Understanding with the Quora Question Pairs Dataset"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "3cee801d10f410f0feb1a2390776a01ba2765001", "title": "Sparse Sequence-to-Sequence Models"}, {"paperId": "b03c7ff961822183bab66b2e594415e585d3fd09", "title": "Are Sixteen Heads Really Better than One?"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "c940cec9b56a5766c316fb6fc1e4195d70d39ecf", "title": "DVAE#: Discrete Variational Autoencoders with Relaxed Boltzmann Priors"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "5e92e2413393d3f90a80c6e79581217d86b7a47d", "title": "DVAE++: Discrete Variational Autoencoders with Overlapping Transformations"}, {"paperId": "2ec7156913117949ab933f27f492d0149bc0031f", "title": "Learning Sparse Neural Networks through L0 Regularization"}, {"paperId": "ee53c9480132fc0d09b1192226cb2c460462fd6d", "title": "Channel Pruning for Accelerating Very Deep Neural Networks"}, {"paperId": "815f535da88e5b6f974527e6ddc72bca8e214fa9", "title": "Visualizing and Understanding Neural Machine Translation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "515a21e90117941150923e559729c59f5fdade1c", "title": "The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "6dab1c6491929d396e9e5463bc2e87af88602aa2", "title": "Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "6ff0ab1e9064dba97bb8e5ae0b0f1110b5565e06", "title": "Tensor-Train Decomposition"}, {"paperId": "8b68bd68d2859c898836f563d571130eab776dc0", "title": "Probability Essentials"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "A method for stochastic optimization"}, {"paperId": "81aace0e90c6a962059b117c24db0d856f340f41", "title": "Report on the 11th IWSLT evaluation campaign"}, {"paperId": "fbc6562814e08e416e28a268ce7beeaa3d0708c8", "title": "Large-Scale Machine Learning with Stochastic Gradient Descent"}, {"paperId": "00cf63a7926a826f7cf73c1d5edb117f98d70c2c", "title": "Variational algorithms for approximate Bayesian inference"}, {"paperId": "e7297db245c3feb1897720b173a59fe7e36babb7", "title": "Optimal Brain Damage"}, {"paperId": "6e103f45ce2f653fd7aafcf67afa80c39130294f", "title": "Statistical Theory of Extreme Values and Some Practical Applications : A Series of Lectures"}]}