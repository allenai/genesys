{"paperId": "8cebc12f731167df440b5cdd746c8ed24c484aa1", "title": "QCQA: Quality and Capacity-aware grouped Query Attention", "abstract": "Excessive memory requirements of key and value features (KV-cache) present significant challenges in the autoregressive inference of large language models (LLMs), restricting both the speed and length of text generation. Approaches such as Multi-Query Attention (MQA) and Grouped Query Attention (GQA) mitigate these challenges by grouping query heads and consequently reducing the number of corresponding key and value heads. However, MQA and GQA decrease the KV-cache size requirements at the expense of LLM accuracy (quality of text generation). These methods do not ensure an optimal tradeoff between KV-cache size and text generation quality due to the absence of quality-aware grouping of query heads. To address this issue, we propose Quality and Capacity-Aware Grouped Query Attention (QCQA), which identifies optimal query head groupings using an evolutionary algorithm with a computationally efficient and inexpensive fitness function. We demonstrate that QCQA achieves a significantly better tradeoff between KV-cache capacity and LLM accuracy compared to GQA. For the Llama2 $7\\,$B model, QCQA achieves $\\mathbf{20}$\\% higher accuracy than GQA with similar KV-cache size requirements in the absence of fine-tuning. After fine-tuning both QCQA and GQA, for a similar KV-cache size, QCQA provides $\\mathbf{10.55}\\,$\\% higher accuracy than GQA. Furthermore, QCQA requires $40\\,$\\% less KV-cache size than GQA to attain similar accuracy. The proposed quality and capacity-aware grouping of query heads can serve as a new paradigm for KV-cache optimization in autoregressive LLM inference.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Quality and Capacity-Aware Grouped Query Attention (QCQA), which identifies optimal query head groupings using an evolutionary algorithm with a computationally efficient and inexpensive fitness function, achieves a significantly better tradeoff between KV-cache capacity and LLM accuracy compared to GQA."}, "embedding": {"model": "specter_v2", "vector": [0.021218953654170036, 0.4861717224121094, -0.1518784463405609, -0.05223574861884117, -0.8922637701034546, -0.1314164251089096, 0.201706200838089, -0.03670712187886238, -0.4490489363670349, -0.2952726185321808, 0.5389895439147949, 0.10254848748445511, -0.19414149224758148, -0.13705198466777802, 0.04913278669118881, -0.2197577953338623, -1.3242608308792114, 0.5996794104576111, -0.25253531336784363, -0.23393025994300842, -0.17503555119037628, -0.63873690366745, -1.3795204162597656, 0.016695484519004822, 0.47575610876083374, 0.7493559718132019, -0.0412660576403141, 1.334710955619812, -0.5392682552337646, -0.0384717732667923, 0.3579454720020294, -0.3952615261077881, 0.13936743140220642, -0.3935292363166809, -0.29373645782470703, -0.15954731404781342, 0.36008816957473755, -0.1561177372932434, -0.23239167034626007, 0.5204157829284668, 0.25297215580940247, 0.4808151125907898, 0.33836236596107483, -0.6057178378105164, -0.34695327281951904, 0.9847089648246765, 0.5687821507453918, 0.8545366525650024, -0.1667226105928421, -0.42775580286979675, 1.3921865224838257, -1.3422598838806152, 0.10932382196187973, 1.55216646194458, 0.29570212960243225, 0.33324310183525085, -0.2065373957157135, -0.2785741686820984, 0.6092032790184021, -0.1687932163476944, -1.1494510173797607, -0.5031092166900635, -0.019362911581993103, -0.2520962655544281, 1.6988240480422974, 0.00039707153337076306, 0.05013284832239151, 0.023372208699584007, 0.0453658327460289, 1.4263538122177124, -0.5937654972076416, -0.975612998008728, 0.3097882866859436, -0.008802774362266064, 0.19280365109443665, 0.7644839882850647, -0.607102632522583, 0.22459180653095245, -1.0217437744140625, -0.7942299246788025, 0.11996620148420334, -0.6444078087806702, 0.22152304649353027, -0.1557336449623108, 0.14453063905239105, 1.1833029985427856, 0.13040223717689514, 0.5382053256034851, -0.37513968348503113, 0.8150072693824768, 0.306392639875412, 0.027272440493106842, 0.3412013053894043, 0.6240923404693604, -0.20412294566631317, 0.2495751529932022, -1.159256100654602, 0.6473931074142456, -0.27438661456108093, 0.9576486349105835, -0.4762423038482666, 0.6924739480018616, -1.0093729496002197, 0.28901436924934387, 1.3858999013900757, 0.29658833146095276, 0.6049960851669312, -0.5433999300003052, 0.1539335697889328, -0.4884272813796997, 0.08672894537448883, -0.3526405990123749, -0.16540725529193878, 0.08723607659339905, -0.5334253311157227, -1.507440447807312, -0.5313442349433899, 0.03368592634797096, -0.4059261083602905, 0.6990679502487183, 0.09492366015911102, 0.05647860839962959, 0.20900709927082062, 0.6407386660575867, 0.3381211459636688, 0.6888620853424072, 0.39652612805366516, 0.07030584663152695, 1.1651878356933594, -0.5929973125457764, -0.38462188839912415, -1.057910442352295, 0.7379990816116333, 0.06955627351999283, 0.08284489810466766, -0.3588237762451172, -1.6649442911148071, -1.0089216232299805, -0.5204983353614807, 0.2194633185863495, -0.32487502694129944, 0.25971540808677673, 1.1876662969589233, 0.5034232139587402, -0.9437915086746216, 0.34775933623313904, 0.1178317666053772, -0.23128506541252136, -0.056319400668144226, 0.3280007243156433, 0.3291056156158447, -0.3663298487663269, -1.3746652603149414, -0.18316622078418732, 0.1301065981388092, -0.6515045166015625, 0.19610513746738434, -0.41696932911872864, -1.1058005094528198, -0.13432790338993073, 0.3095875680446625, -0.776216983795166, 1.3592348098754883, 0.10419271141290665, -1.3898299932479858, 0.32214072346687317, -0.27562016248703003, 0.06792708486318588, 0.10333086550235748, -0.08784528821706772, -0.47009003162384033, -0.3284668028354645, -0.2272060215473175, 0.5833122730255127, 0.5783616900444031, 0.19849471747875214, -0.3525005877017975, 0.025524655357003212, -0.5347999930381775, -0.15146441757678986, -0.2425823211669922, 0.9578324556350708, -0.9870805740356445, -0.36415520310401917, 0.1946398764848709, 0.5619990825653076, -0.48287856578826904, -0.2453724443912506, -0.09115692973136902, -1.1309545040130615, 0.114312082529068, -0.09285178035497665, 1.2849233150482178, -0.6092517971992493, -0.487451434135437, -0.3600282073020935, -0.461765319108963, -0.4142080545425415, -0.8800809383392334, 0.906400740146637, -0.13898366689682007, 0.5017029643058777, -0.2622145116329193, -1.0286988019943237, -0.04179857671260834, -0.353791207075119, -0.7607108354568481, -0.3803473114967346, 0.39493387937545776, 1.0256811380386353, -0.9195482730865479, -0.10208319127559662, -0.2725377082824707, -0.15640711784362793, -1.000027060508728, 1.3139725923538208, -0.49757450819015503, 0.16863520443439484, -0.47257664799690247, -0.23015208542346954, 0.29825422167778015, 0.058086879551410675, 0.2679288685321808, 0.16448429226875305, -0.4390586018562317, 0.16503584384918213, -0.3371695280075073, 1.115949273109436, -0.2056310623884201, 0.018000060692429543, -0.13394132256507874, -0.06373322755098343, 0.28979170322418213, 0.3550829589366913, -0.07451274245977402, -0.5257788300514221, 0.056543558835983276, 0.30589327216148376, -0.5052497982978821, 0.08595056086778641, 0.9104311466217041, 1.0126819610595703, -0.9489772915840149, 0.038893040269613266, 0.557523787021637, -0.3964122235774994, 0.6864433884620667, 0.20616398751735687, 0.45882323384284973, 0.1935213953256607, 0.4718707501888275, -0.1199588030576706, 0.3631151020526886, -0.8221942186355591, -0.05540947616100311, 0.716336190700531, 0.8294283151626587, 0.9610830545425415, 0.23006612062454224, -0.7452927827835083, -0.3980602025985718, 0.5098647475242615, 0.6920354962348938, 1.6226621866226196, -0.5853571891784668, -0.3556438982486725, -0.7459614276885986, -0.15342949330806732, 0.07687865942716599, 0.14044533669948578, -0.4308229088783264, -0.1155533716082573, -0.5092845559120178, -1.145218014717102, 0.951202392578125, 0.38951969146728516, 0.3330336809158325, -0.6679546236991882, -0.38355752825737, -0.15128649771213531, 0.5311667323112488, -0.604684054851532, -0.4462372064590454, 0.26771610975265503, -0.30823490023612976, 0.2552812397480011, -0.1542118638753891, 0.17846952378749847, -0.16599141061306, -0.9382608532905579, 0.8643854856491089, -0.4090786576271057, -0.19822725653648376, 0.20694372057914734, 0.3346370756626129, -0.8224050402641296, -0.8259881138801575, 0.06222838535904884, 0.24788787961006165, -0.11743711680173874, 0.31717491149902344, 0.9239950776100159, 0.27809906005859375, -0.28899189829826355, -0.3035385012626648, 0.18801835179328918, 0.09494031965732574, 0.291145920753479, 0.5701210498809814, -0.47165048122406006, -0.06486640870571136, -0.761599063873291, 0.989309549331665, 0.07711747288703918, -1.139509916305542, 0.18626973032951355, -0.429975301027298, -0.2724716067314148, 0.5103322863578796, -0.2119477093219757, -0.15738649666309357, -0.6508152484893799, 0.08628852665424347, -0.08154970407485962, -0.15056778490543365, 0.5171792507171631, 0.3187861740589142, 0.2120203822851181, -0.07737229764461517, 0.6281787157058716, 0.4211001396179199, -0.3136346638202667, 0.6690139174461365, -0.49753791093826294, 0.20230774581432343, 0.12229043245315552, -0.1535547822713852, -0.40070411562919617, -0.13746099174022675, -0.9971423745155334, -0.06614039838314056, -0.47151198983192444, -0.23195472359657288, -0.21224360167980194, 0.2565529942512512, -0.5206429362297058, -0.6591613292694092, -0.009787176735699177, -0.9568389654159546, -0.02376025915145874, -0.007317706476897001, -0.04565044492483139, -0.20420189201831818, -1.0876444578170776, -1.1533259153366089, -1.0408650636672974, -0.9806975722312927, -0.979714035987854, 0.8451223969459534, -0.056853849440813065, -0.44365495443344116, -0.1496351957321167, 0.20181064307689667, -0.4233582615852356, 0.7264072895050049, -0.9453305602073669, 1.2231179475784302, 0.05469940975308418, -0.17717906832695007, -0.5780614614486694, 0.6250668168067932, -0.12335844337940216, -0.4932396411895752, 0.38706254959106445, -0.5631459951400757, 0.09281187504529953, -0.7561628222465515, -0.437854528427124, 0.19727115333080292, 0.5779845118522644, 0.6951690912246704, -0.027946297079324722, -0.4869908392429352, 0.2740258276462555, 1.1960766315460205, -0.5679852366447449, -0.12545038759708405, -0.14803598821163177, 0.57811039686203, 0.4535401165485382, 0.23520958423614502, 0.9604994654655457, 0.028889944776892662, 0.9013211727142334, 0.16129034757614136, -0.11537310481071472, 0.10307887196540833, -0.37952545285224915, 0.04305419325828552, 2.0553359985351562, 0.4068169891834259, -0.5553404688835144, -0.8463257551193237, 0.7494476437568665, -1.3407586812973022, -0.5134425163269043, 0.3850710690021515, 0.8381914496421814, 0.0819375142455101, -0.7228129506111145, -0.009432591497898102, -0.3856925368309021, 0.08369240909814835, 0.1950034201145172, -0.13962054252624512, -0.7059243321418762, -0.16476310789585114, 0.3471553921699524, 0.02123212069272995, 0.5357212424278259, -0.4041028916835785, 0.6682385206222534, 15.213573455810547, 0.8051543235778809, 0.21954549849033356, 0.39849355816841125, 0.570110559463501, 0.1990751475095749, -0.4846213161945343, -0.24397437274456024, -1.362886905670166, 0.21949690580368042, 1.459619402885437, -0.038397714495658875, 0.2405685931444168, 0.34998464584350586, 0.29982519149780273, -0.01869753561913967, 0.0009404263691976666, 0.2836749851703644, 0.3843064606189728, -1.1581732034683228, 0.6545717120170593, 0.3054402768611908, 0.1636848747730255, 0.2652439475059509, 0.5602203011512756, 0.8310143351554871, 0.5977615118026733, -0.3608781099319458, 0.48595571517944336, 0.5197330713272095, 0.505608081817627, -0.37438344955444336, 0.656711995601654, 0.3587908446788788, -0.8768985271453857, -0.4201849400997162, -0.9399566650390625, -1.0024017095565796, 0.3830915093421936, 0.14652982354164124, -0.7087711691856384, -0.1530812382698059, -0.11276464909315109, -0.09039774537086487, -0.08230336010456085, 0.5130146741867065, -0.0070287976413965225, 0.8459821939468384, -0.07734900712966919, -0.4114760458469391, 0.1898082196712494, 0.4054765999317169, 0.06339413672685623, -0.2587682902812958, 0.505691409111023, 0.060091450810432434, 0.21710272133350372, 0.37496623396873474, -0.3744475245475769, 0.16852352023124695, -0.2843009829521179, -0.4001735746860504, 0.34686270356178284, 0.6999032497406006, 0.6598238348960876, 0.19852399826049805, -0.19425764679908752, 0.24835343658924103, 0.8619388937950134, -0.027814975008368492, -0.017021112143993378, 0.05352660268545151, 0.4722837805747986, -0.6668019890785217, 0.10917115956544876, 0.5596875548362732, 0.13504502177238464, 0.06757287681102753, -1.123671531677246, -0.3962157666683197, 0.6632437705993652, -0.9910908937454224, -0.8500940799713135, 0.8903602361679077, -0.0020268778316676617, -0.12795841693878174, -0.3503730297088623, -0.5718342661857605, -0.2103382647037506, 0.7758170366287231, -0.60650634765625, -0.7725391983985901, 0.4522586464881897, -0.7976686358451843, -0.05463729426264763, -0.053870730102062225, 1.6391918659210205, -0.3944968283176422, -0.61348956823349, 0.11177996546030045, 0.4259093403816223, -0.2761901617050171, -0.37630385160446167, -0.6464217901229858, 1.3011962175369263, 0.5587049126625061, -0.08775027841329575, 0.30907413363456726, -0.19750817120075226, -0.06363144516944885, -1.015776515007019, -0.19476160407066345, 0.8326694965362549, -0.9321102499961853, -0.4890652000904083, -0.9968854784965515, -0.7000607252120972, -0.2572711706161499, 0.3792146146297455, -0.37301865220069885, 0.4730067253112793, 0.19222795963287354, 0.17727018892765045, -0.02635386772453785, -0.22391879558563232, 0.00641085859388113, 0.26543182134628296, -0.39018240571022034, -0.0273809302598238, -0.11414390802383423, 0.6203206181526184, -0.8465490937232971, -0.5106371641159058, -0.40849557518959045, -0.02669799141585827, 0.1682477742433548, 0.8890112042427063, -0.6800599694252014, 0.32956501841545105, 0.8656240105628967, 0.027594085782766342, -0.8275213241577148, -0.6314542889595032, -0.6570550799369812, -0.09041979163885117, 0.2508590519428253, 0.7131163477897644, -0.14034110307693481, 0.2884363532066345, 0.9287216663360596, 0.3516865372657776, -0.41134342551231384, -0.771832287311554, -0.06604012846946716, 0.0564890056848526, -0.5857731103897095, 0.788827121257782, -0.2656756639480591, -0.12688203155994415, -0.04752000421285629, 0.032235804945230484, 0.9695978760719299, -0.5487423539161682, -0.47565165162086487, 0.6115796566009521, -0.04859021306037903, -0.16878999769687653, -0.49135956168174744, -0.40887439250946045, -1.1750479936599731, -0.24534295499324799, -0.8388901352882385, 0.09218627959489822, -0.7567760944366455, -0.4783634543418884, -0.015786057338118553, -0.06533554196357727, -0.09568212926387787, 0.24473236501216888, -0.3878185749053955, -0.6359731554985046, -0.6938666105270386, -0.46154481172561646, 0.8222216367721558, 0.2844810485839844, -0.6551524996757507, 0.050524577498435974, -0.09056180715560913, 0.2751426100730896, -0.019292516633868217, 0.38647618889808655, -0.6333983540534973, -0.6228647828102112, -1.25294029712677, 0.4799536168575287, 0.1964634507894516, -0.10692868381738663, -0.6295433640480042, 0.6926312446594238, 0.30935266613960266, -0.11254682391881943, -0.367754727602005, 0.5507927536964417, -0.4296482801437378, -0.2686016857624054, 0.11654545366764069, -0.7742920517921448, 0.37787172198295593, 0.35405656695365906, -0.5458600521087646, -0.35103660821914673, 0.28968557715415955, -0.3656189739704132, -1.1409331560134888, -0.7473410964012146, 0.46373334527015686, -1.1488913297653198, 0.11392314732074738, -0.3021072447299957, -0.16991010308265686, -0.5793899297714233, -0.391349196434021, 0.3666735887527466, 0.3885327875614166, -0.40918856859207153, 1.0361239910125732, 0.5484139323234558, -0.8125147223472595, -0.11803935468196869, 0.4661850929260254, 0.1583889275789261, -0.08327517658472061, 0.8219263553619385, 0.16229091584682465, -0.05978882312774658, 0.765313982963562, 0.4627719819545746, 0.25343334674835205, -1.0422003269195557, 0.21477890014648438, 0.3425770699977875, -0.45515862107276917, 0.20081429183483124, 1.5748271942138672, -0.46479666233062744, -1.1889289617538452, -0.262087345123291, -0.9337502717971802, -0.5301935076713562, -0.1914863884449005, 0.6699532270431519, 0.2211870551109314, -0.0009628222323954105, -0.22230765223503113, -0.6233281493186951, 0.2979116141796112, 0.01026616245508194, -0.5858784914016724, 0.35133853554725647, -0.007165968418121338, -0.338291198015213, 0.4761594533920288, 0.3401498794555664, -0.19267894327640533, -0.3452135920524597, -0.19743825495243073, -0.13424955308437347, -0.0857122540473938, 0.5403650403022766, -0.10204912722110748, -0.23481693863868713, 0.7270978093147278, 0.60325688123703, 0.27818557620048523, 0.07179780304431915, -0.12002316117286682, 0.004702920559793711, 0.33501136302948, 0.22703689336776733, -0.640782356262207, -0.6396770477294922, 1.047291874885559, 1.2747820615768433, -0.463483601808548, 0.3906592130661011, 0.01281837746500969, -0.9477546215057373, 0.7213519215583801, 0.4946397542953491, 0.5357702970504761, 0.37647610902786255, -0.18982726335525513, 0.25827014446258545, -0.017227500677108765, -1.3019317388534546, -0.6368188261985779, 1.2465784549713135, 0.9146069884300232, 0.6949015855789185, 0.1652008593082428, 0.1455383151769638, 1.0239965915679932, 0.22468188405036926, 0.12217161059379578, 0.2979205250740051, 0.6157800555229187, -0.2796476185321808, -0.04630816727876663, -0.09704206883907318, 0.6611925959587097, -0.5993437767028809, -0.8643191456794739, -0.20215773582458496, 0.636056661605835, 0.08159072697162628, 0.6989932060241699, 0.9345387816429138, 0.14253360033035278, 0.32499808073043823, 0.3961506485939026, 0.13100649416446686, -0.4048290550708771, -0.115972138941288, 0.03949589282274246, -0.2766595482826233, 0.17929187417030334, 0.1541120558977127, -0.36024582386016846, -0.1125265583395958, 0.04841722175478935, -0.13839106261730194, 0.46324294805526733, 0.1008797213435173, 0.532706618309021, 1.0221843719482422, 0.47373974323272705, -0.2781985104084015, -0.29402440786361694, -0.6120695471763611, -0.9838677644729614, -0.15618187189102173, -0.8854951858520508, -0.6237930059432983, 0.037016864866018295, -0.030831776559352875, -0.5961076617240906]}, "authors": [{"authorId": "2284669730", "name": "Vinay Joshi"}, {"authorId": "30769675", "name": "Prashant Laddha"}, {"authorId": "2307006966", "name": "Shambhavi Sinha"}, {"authorId": "123918823", "name": "O. J. Omer"}, {"authorId": "1706165", "name": "S. Subramoney"}], "references": [{"paperId": "8a3df7b9cb6c323da340a4871ae705d0063f28bf", "title": "KV Cache is 1 Bit Per Channel: Efficient Large Language Model Inference with Coupled Quantization"}, {"paperId": "e9576198e9ee767ede4b1ac6a739267aa52a9832", "title": "Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference"}, {"paperId": "58a7cf09d27876c5325aea16dd1e0a9c2940e33c", "title": "GQKVA: Efficient Pre-training of Transformers by Grouping Queries, Keys, and Values"}, {"paperId": "ce9435c82dc9b576f2037aa2f4357a520be9b2aa", "title": "SkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference"}, {"paperId": "d6eeb2898bd9bd34744194ef543062dda6c4531a", "title": "Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time"}, {"paperId": "c193eb176985a81ae64f63c5e50b2f11cfb7c4e6", "title": "Dynamic Context Pruning for Efficient and Interpretable Autoregressive Transformers"}, {"paperId": "5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200", "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints"}, {"paperId": "1ebcdc3cb8975c814c5e6f2f40cd7360e062c323", "title": "A Hardware-Aware Framework for Accelerating Neural Architecture Search Across Modalities"}, {"paperId": "465d1f6a0db8fd981897a251afb1e79b601a9fc6", "title": "A Survey on Evolutionary Neural Architecture Search"}, {"paperId": "ef8d788a904ed66bd8e30ffa69bc3ea1fe57dda7", "title": "HAT: Hardware-Aware Transformers for Efficient Natural Language Processing"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "2ea7e3d2f58a4270f43f22dfc10479506fadf63c", "title": "Neural Architecture Transfer"}, {"paperId": "61e27dbae190b82639c57f180ecf97e4c46fcad9", "title": "Pymoo: Multi-Objective Optimization in Python"}, {"paperId": "dc52b09089704ebd6f471177474bc29741c50023", "title": "Fast Transformer Decoding: One Write-Head is All You Need"}, {"paperId": "7823292e5c4b05c47af91ab6ddf671a0da709e82", "title": "Once for All: Train One Network and Specialize it for Efficient Deployment"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "f48eed915cbb9c6592cdb9df80c1edaeb46959af", "title": "A measure of intelligence"}, {"paperId": "363668677c459ebc0ff494655f993a93a0251009", "title": "OPTQ: Accurate Quantization for Generative Pre-trained Transformers"}, {"paperId": "2c5fdd14e2d560b2ccb17014d50cddb392a85bc2", "title": "What to expect of hardware metric predictors in NAS"}, {"paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28", "title": "An Adversarial Winograd Schema Challenge at Scale"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Pytorch: An imperative style"}, {"paperId": "45042f3b0cdd303f32dacd7f1c16954d492ab288", "title": "Stirling Numbers of the Second Kind"}, {"paperId": null, "title": "Towards joint optimization for dnn architecture and configuration for compute-in-memory"}, {"paperId": null, "title": "torchtune is a pytorch library for easily authoring, fine-tuning and experimenting with llms"}, {"paperId": null, "title": "Scaling rectified flow transformers"}, {"paperId": null, "title": ": Towards 10 million context length"}, {"paperId": null, "title": "Stanford alpaca: An instruction-following llama model"}, {"paperId": null, "title": "A framework for few-shot language model"}, {"paperId": null, "title": "Automated neural architecture construction technology"}, {"paperId": null, "title": "GPT-J-6B: A 6 Billion Parameter Autoregressive Language"}, {"paperId": null, "title": "H 2 o: Heavy-hitter oracle for efficient generative inference of large"}]}