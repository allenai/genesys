{"paperId": "14ada95b263a8a7b4ca3cbc6ce08a15f16b1bae9", "title": "\u03b5-ViLM : Efficient Video-Language Model via Masked Video Modeling with Semantic Vector-Quantized Tokenizer", "abstract": "To build scalable models for the challenging real-world tasks, it is important to learn from diverse, multi-modal data in various forms (e.g., videos, text, images). Amongst the existing works, a plethora of them have been focusing on leveraging large but cumbersome cross-modal architectures. Regardless of their effectiveness, larger architectures unavoidably prevent the models from being extended to real-world applications, so building a lightweight VL architecture and an efficient learning schema is of great practical value. In this paper, we propose an Efficient Video-Language Model (dubbed as E-ViLM) and a masked video modeling (MVM) schema, assisted with a semantic vector-quantized tokenizer: In particular, our E-ViLM learns to reconstruct the semantic labels of masked video regions, produced by the pre-trained vector-quantized tokenizer which discretizes the continuous visual signals into labels. We show that with our simple MVM task and regular VL pre-training modelings, our E-ViLM, despite its compactness, is able to learn expressive representations from Video-Language corpus and generalize well to extensive Video-Language tasks including video question answering, text-to-video retrieval, etc. In particular, our E-ViLM obtains obvious efficiency improvements by reaching competing performances with faster inference speed: i.e., our model reaches 39.3% Top-1 accuracy on the MSRVTT benchmark, retaining 91.4% of the accuracy of state-of-the-art larger VL architecture with only 15% parameters and 94.8% fewer GFLOPs. We also provide extensive ablative studies that validate the effectiveness of our proposed learning schema for E-ViLM.", "venue": "2024 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW)", "year": 2023, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2311.17267", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes an Efficient Video-Language Model (dubbed as E-ViLM) and a masked video modeling (MVM) schema, assisted with a semantic vector-quantized tokenizer: in particular, the E-ViLM learns to reconstruct the semantic labels of masked video regions, produced by the pre-trained vector-quantized tokenizer which discretizes the continuous visual signals into labels."}, "embedding": {"model": "specter_v2", "vector": [0.4761548638343811, 0.4064485430717468, -0.8081234097480774, -0.046567197889089584, -0.8012722134590149, 0.06349010020494461, 0.37321579456329346, -0.17400313913822174, -0.6889129281044006, -0.34744349122047424, 0.7134323716163635, 0.40028321743011475, 0.706790030002594, 0.26286715269088745, -0.16987672448158264, 0.2721957564353943, -1.1475807428359985, -0.05929378792643547, 0.006743878126144409, -0.46686652302742004, -0.3082217276096344, -0.890296459197998, -1.2390542030334473, 0.4668053984642029, 0.17950588464736938, 0.9912521243095398, 0.01409451849758625, 1.199029564857483, -0.35772979259490967, 0.6288613080978394, 0.4329374432563782, -0.061408936977386475, 0.4068687856197357, 0.014336274936795235, -0.3253405690193176, 0.45581531524658203, 0.5762354135513306, -0.9774951338768005, -0.9024943113327026, 0.62464839220047, -0.29615768790245056, 0.3775181174278259, 0.7789851427078247, -0.8316051363945007, -0.4813719093799591, 0.19799184799194336, 0.6703503727912903, 0.36121416091918945, -0.041791390627622604, -0.7830864191055298, 1.6363040208816528, -1.4404648542404175, 0.3006116449832916, 1.59016752243042, 0.012353140860795975, 0.6536825895309448, -0.0431121364235878, -0.47274547815322876, 1.0093704462051392, 0.3880881667137146, -1.0875146389007568, -0.18123170733451843, -0.4764483571052551, -0.4095277190208435, 1.5367292165756226, -0.6869803071022034, 0.05128045752644539, 0.7512569427490234, -0.26957088708877563, 1.5491400957107544, -0.634553849697113, -0.7015712857246399, -0.34549373388290405, 0.15996763110160828, -0.26872971653938293, 1.1855299472808838, -0.6902845501899719, 0.3027055859565735, -0.8679940104484558, 0.1452951282262802, 0.19763438403606415, 0.34175848960876465, -0.28272831439971924, -0.42231494188308716, -0.32863113284111023, 0.7997556924819946, 0.5778274536132812, 0.6113240122795105, 0.041452642530202866, 0.7084828615188599, 1.0325021743774414, 0.4839369058609009, 0.16187722980976105, -0.015228722244501114, -0.11283905804157257, 0.3721904456615448, -1.1995415687561035, 0.442531555891037, -0.3491365611553192, 0.906364917755127, -0.2761062681674957, 0.29481926560401917, -0.9739086031913757, 0.08323098719120026, 1.22357976436615, 0.08876582980155945, 0.42236971855163574, -0.6985534429550171, 0.21656928956508636, -0.9433955550193787, 0.541837215423584, -0.8587475419044495, -0.026406576856970787, 0.2536149322986603, -0.873923659324646, -1.2422713041305542, -0.7577175498008728, 0.6227734684944153, -1.1210259199142456, 0.8237120509147644, -0.5317369699478149, 0.2518572509288788, 0.2593947947025299, 0.45970532298088074, 1.038620114326477, 1.104788899421692, 0.4409124553203583, 0.08785399049520493, 1.2745805978775024, -1.0882943868637085, -0.5835811495780945, -0.7544538974761963, 0.951562762260437, 0.06926453113555908, 0.2774869501590729, -0.23718485236167908, -0.7605904340744019, -1.5216885805130005, -0.6569696664810181, -0.27130216360092163, -0.6915117502212524, 0.41775697469711304, 0.4068254232406616, 0.2724052965641022, -1.4292715787887573, 0.2828296720981598, 0.00577287282794714, -0.4491433799266815, 0.35648953914642334, 0.001321024028584361, -0.05013955757021904, -0.6400979161262512, -1.3021819591522217, 0.39201775193214417, -0.08481641113758087, -0.4878008961677551, -0.7402269840240479, -0.1440085619688034, -1.7671605348587036, -0.3324248492717743, 0.49755021929740906, -0.5687622427940369, 1.054383635520935, -0.24426963925361633, -0.7787163257598877, 0.9419928789138794, -0.9439185857772827, -0.037857264280319214, 0.49982014298439026, -0.5297600626945496, -0.321152001619339, 0.17424307763576508, -0.26399073004722595, 1.1040223836898804, 0.6789203882217407, -0.2583756446838379, -0.2617816925048828, 0.4605430066585541, -0.30057379603385925, 0.05281506106257439, -0.3630838692188263, 1.0338658094406128, -0.6293014883995056, -0.39873838424682617, 0.10343864560127258, 0.9126982092857361, -0.15468013286590576, 0.22844192385673523, -0.12347178906202316, -0.8637815117835999, 1.003178596496582, -0.04604329913854599, 0.580115556716919, -1.1035242080688477, -0.516419529914856, -0.6357438564300537, 0.4253944158554077, -0.13725793361663818, -1.1442549228668213, 0.4224436283111572, -0.031741101294755936, 0.3725101351737976, 0.25138211250305176, -1.5103397369384766, 0.25599780678749084, -0.3268170952796936, -0.8671257495880127, -0.05626701936125755, 0.31694096326828003, 1.4159116744995117, -0.7626230120658875, -0.37242957949638367, -0.02535061538219452, 0.3362143933773041, -1.0724090337753296, 1.3675283193588257, -0.5900137424468994, -0.0419645756483078, -0.41456061601638794, 0.009451000951230526, -0.18598555028438568, -0.33287474513053894, 0.021952131763100624, -0.7914415597915649, 0.09290893375873566, -0.1964101642370224, 0.017306694760918617, 1.5099257230758667, -0.19892451167106628, 0.9609147310256958, -0.3765278458595276, -0.9339244365692139, 0.1546609252691269, 0.8593639731407166, 0.31473901867866516, -0.30560562014579773, 0.601874828338623, -0.13826784491539001, -1.3361451625823975, -0.44926804304122925, 1.1159509420394897, 0.6945669054985046, -0.46038928627967834, -0.030994607135653496, 0.4537504315376282, 0.1442698985338211, 0.4223839044570923, 0.6562554836273193, 0.692703366279602, 0.54851895570755, 0.23524026572704315, 0.5491284728050232, 0.37668824195861816, -0.842366099357605, -0.17061054706573486, 0.8851917386054993, 0.2676153779029846, 0.9877147078514099, 0.15330584347248077, -0.7511378526687622, -0.45938512682914734, -0.1522161215543747, 0.8574345111846924, 1.4305987358093262, 0.301220566034317, -0.35714539885520935, -0.534720778465271, -0.302579402923584, -0.29836317896842957, -0.5694375038146973, -0.3642118573188782, -0.13058362901210785, -0.020948706194758415, -0.3906458020210266, 0.8245328664779663, 0.48540061712265015, 0.8820947408676147, -0.839534342288971, -0.16331987082958221, -0.365265429019928, -0.3903842568397522, -1.2532113790512085, -0.7413297891616821, -0.3048609793186188, -0.1672184020280838, 0.1430884301662445, -0.28018492460250854, -0.2927110493183136, 0.2056782990694046, -0.42648258805274963, 0.7581373453140259, -0.536880373954773, -0.7152650356292725, 0.5690112113952637, -0.04215148091316223, -0.24197708070278168, -0.4770705997943878, -0.3951531648635864, 0.1677713692188263, 0.1548129916191101, 0.4655073881149292, 0.92690509557724, -0.01871858350932598, -0.023742757737636566, -0.5173190236091614, 0.20341721177101135, 0.04981796070933342, -0.10934696346521378, 0.6971113681793213, -0.2940196096897125, -0.01106287445873022, -0.628462553024292, 0.30914485454559326, 0.05581596866250038, -0.24335995316505432, 0.21218788623809814, -0.22616861760616302, -0.7946244478225708, 0.20784036815166473, -0.9140621423721313, 0.10003645718097687, -0.8253516554832458, 0.5166799426078796, -0.9277864098548889, -0.5903038382530212, 0.13596004247665405, 0.2221192568540573, 0.2875373661518097, -0.06377004832029343, 0.5790195465087891, 0.23925358057022095, 0.14594411849975586, 0.7510393261909485, -0.5831533670425415, 0.559072732925415, 0.11923535168170929, 0.24429383873939514, 0.4902940094470978, -0.3188783526420593, -1.0251177549362183, -0.6726785898208618, -0.9055641889572144, -0.22648616135120392, -0.8681178092956543, 0.8446176052093506, -1.1450475454330444, -0.6591554284095764, -0.21735087037086487, -1.2202913761138916, -0.1410917490720749, 0.2535165250301361, -0.12333445996046066, -0.5264232158660889, -0.9989264011383057, -1.1538761854171753, -0.6259943246841431, -0.21226422488689423, -1.0836726427078247, 0.699255108833313, -0.17602507770061493, -0.46331170201301575, -0.5011867880821228, -0.4301636517047882, -0.0909736305475235, 0.9634582996368408, -0.2562442719936371, 0.6312296986579895, 0.09881963580846786, -0.5201250314712524, -0.5972831845283508, -0.2916097342967987, 0.8133038282394409, -0.11357710510492325, 0.10101807862520218, -0.800342321395874, -0.07271645963191986, -0.38084641098976135, -0.36478957533836365, 0.5387524962425232, 0.5125160217285156, 0.7455736398696899, 0.3044920563697815, -0.5344052910804749, 0.36120671033859253, 1.7720879316329956, -0.6589797139167786, -0.24300312995910645, -0.19769272208213806, 1.200499415397644, 0.17089541256427765, -0.08758644014596939, 0.5676571130752563, 0.4649195373058319, 0.3461751639842987, 0.12769131362438202, -0.5555392503738403, 0.10904453694820404, -0.5462140440940857, 0.8631793260574341, 1.4338023662567139, 0.3565269410610199, -0.42075878381729126, -0.6246622800827026, 0.9872323274612427, -1.307416319847107, -0.9023511409759521, 0.8897719383239746, 0.2909630835056305, -0.3939010500907898, -0.4773957133293152, 0.06641823798418045, -0.6464395523071289, 0.563347578048706, 0.49466776847839355, -0.12881255149841309, -0.636701226234436, 0.011471658945083618, 0.004928938578814268, 0.08422306180000305, 0.3571322560310364, -0.8000838756561279, 0.6097572445869446, 14.132957458496094, 0.7777811288833618, -0.24983954429626465, 0.6810246706008911, 0.5037546157836914, 0.11249176412820816, -0.25704774260520935, -0.3930438756942749, -0.9174415469169617, -0.44398367404937744, 1.2362453937530518, 0.18000362813472748, 0.15737475454807281, 0.017361586913466454, 0.5862240791320801, 0.5931963324546814, -0.8819760084152222, 0.9747583270072937, 1.00869619846344, -1.303874135017395, 0.7795159220695496, 0.23758834600448608, 0.23486371338367462, 0.5798388123512268, 0.9766358137130737, 1.0799607038497925, -0.16835583746433258, -0.6088753342628479, 0.8708313703536987, 0.22128859162330627, 1.4339625835418701, 0.32546383142471313, 0.22745709121227264, 0.3812204897403717, -1.534075379371643, -0.45518675446510315, -0.7349604368209839, -0.9590929746627808, 0.6389340162277222, -0.5464228987693787, -0.219655841588974, 0.06086130440235138, -0.03380780667066574, 1.1470941305160522, 0.5530120134353638, 0.19959993660449982, 0.10319533199071884, 0.40158766508102417, 0.325898677110672, 0.06235401704907417, 0.7170495390892029, 0.4810410439968109, 0.2320752590894699, 0.09779530018568039, 0.0684894248843193, -0.04760611057281494, 0.6186755299568176, 0.2939640283584595, -0.6359874606132507, -0.008172191679477692, -0.8098236322402954, -0.16541418433189392, -0.5015383958816528, 0.3255491256713867, 0.46869194507598877, -0.04727138578891754, -0.9962347745895386, 0.41629016399383545, 0.2647656500339508, 0.6999250054359436, -0.6498435139656067, 0.3218507766723633, 0.3728603720664978, -0.296028733253479, 0.43309879302978516, 0.7050625681877136, 0.622942328453064, -0.977675199508667, -0.5818955302238464, -0.20020130276679993, 0.3073999285697937, -0.8696288466453552, -0.8779608011245728, 1.1155849695205688, -0.07018638402223587, -0.8315874338150024, 0.24051393568515778, -0.8229390382766724, 0.047641851007938385, 0.30630210041999817, -1.4854505062103271, -0.6721177101135254, 0.15315420925617218, -0.006410111673176289, -0.0308428592979908, -0.021394312381744385, 1.272871732711792, 0.3906654119491577, 0.062021005898714066, 0.0616215355694294, 0.19595256447792053, 0.3639776408672333, -0.052850447595119476, -0.3827476501464844, 0.44157156348228455, 0.11673054099082947, -0.03348367661237717, -0.4373004138469696, -0.047196630388498306, 0.41484400629997253, -0.583802342414856, -0.5294684171676636, 0.6327931880950928, -0.7134721875190735, -0.3902411162853241, -0.9274780750274658, -0.6847748160362244, 0.35014107823371887, 0.27613621950149536, 0.09560446441173553, 0.33476316928863525, -0.31056055426597595, -0.6507428288459778, -0.02896728180348873, -0.7719117999076843, -0.02381635643541813, 0.20997993648052216, -1.0234767198562622, -0.20045310258865356, 0.07674318552017212, 0.4281890094280243, -0.5343563556671143, -0.17803755402565002, -0.06593475490808487, 0.15014880895614624, 0.16538724303245544, 1.0977087020874023, -0.542447566986084, 0.9723846316337585, 0.6968141198158264, -0.5050954818725586, -0.5258378982543945, 0.05060436949133873, -0.623892068862915, -0.15758639574050903, 0.01664423756301403, 0.10458008199930191, 0.03913693502545357, 0.41585221886634827, 0.39959144592285156, 0.5982852578163147, -0.7085310220718384, -0.5458236336708069, -0.17660978436470032, -0.24439513683319092, -0.5944267511367798, -0.1611538678407669, -0.3335028886795044, -0.11396745592355728, -0.23035787045955658, -0.007081350777298212, 0.598302960395813, -0.1382167488336563, -0.7235129475593567, 0.5400914549827576, 0.17085279524326324, 0.13008280098438263, -0.43912285566329956, -1.0580326318740845, -1.9562864303588867, 0.4326809048652649, -1.0995100736618042, 0.3426377475261688, -0.9123947620391846, -0.25090745091438293, 0.719791054725647, -0.4832831919193268, -0.21495294570922852, 0.4816496670246124, 0.19183313846588135, 0.07501590251922607, -0.8134685158729553, -1.059702754020691, 0.8735746741294861, 0.99428790807724, -1.0616639852523804, 0.41956058144569397, -0.33685341477394104, 0.18886451423168182, 0.39945849776268005, -0.03950124979019165, -0.29205191135406494, -0.9648052453994751, -1.132737398147583, 0.0020161280408501625, 0.15937966108322144, 0.16596901416778564, -0.5644620060920715, 0.30324819684028625, 0.5316721200942993, -0.40188372135162354, -0.1619911640882492, 0.8388383388519287, -0.8196809887886047, -0.9938458204269409, 0.2793642580509186, -1.0771896839141846, 0.09406232088804245, 0.004493336658924818, -0.2461448460817337, -1.0270969867706299, 1.0660759210586548, -0.0936603769659996, -1.0532110929489136, -1.1902376413345337, 1.0321625471115112, -0.6094614267349243, 0.2615150213241577, 0.021488847211003304, -0.17659656703472137, -0.7117319107055664, -0.9009157419204712, -0.32708796858787537, 0.5369688272476196, -0.5879082083702087, 1.2065773010253906, 1.2394864559173584, -1.122448205947876, -0.5217898488044739, 0.28957808017730713, 0.37474575638771057, 0.13102369010448456, 0.9083017110824585, 0.22431153059005737, -0.1388169527053833, 0.44955646991729736, 0.49480095505714417, 0.1359751969575882, -0.9825798273086548, 0.5124778747558594, 0.8181256055831909, -0.1653895378112793, -0.48232439160346985, 1.445692539215088, 0.2433597445487976, -0.5652380585670471, 0.4695613384246826, -1.0204918384552002, -0.7417263984680176, -0.11618182808160782, 0.8268980383872986, -0.28829365968704224, -0.33187687397003174, -0.6605559587478638, -0.5345942378044128, 0.5873854160308838, -0.10373478382825851, -0.5107322335243225, 0.289450466632843, -0.5464479923248291, -0.15108895301818848, 0.9214781522750854, 1.5629972219467163, -1.1547071933746338, -0.6175593733787537, -0.8950183391571045, -0.7334495782852173, -0.10359807312488556, 0.1605723798274994, 0.1264273077249527, -0.565492570400238, 0.6621768474578857, 0.6848438382148743, 0.44839563965797424, 0.3122103810310364, 0.0947197899222374, 0.4983101487159729, 0.47669097781181335, -0.06041670963168144, -0.4337468147277832, -0.3086436092853546, 0.8302470445632935, 0.9568631649017334, -0.8881470561027527, 0.00035842505167238414, -0.12490701675415039, -0.6863171458244324, 0.5158746838569641, 0.23636330664157867, -0.2706761956214905, 0.9972023367881775, -0.42902490496635437, 0.561610758304596, 0.18572379648685455, -1.2145054340362549, -0.35487955808639526, 1.2072087526321411, 0.9816862344741821, 0.45736390352249146, 0.4671601951122284, 0.45563188195228577, 0.32273033261299133, 0.39898741245269775, 0.3367069363594055, 0.5053711533546448, 0.19038888812065125, -0.16364364326000214, 0.2598722577095032, 0.19013983011245728, 0.6293506026268005, -0.6343380808830261, -0.3143310844898224, 0.6291998624801636, 0.3740531802177429, 0.37091052532196045, 0.7046778798103333, 1.0891765356063843, -0.03412977233529091, 0.5355543494224548, 0.04991055279970169, 0.5999448895454407, -0.6738453507423401, 0.4205988645553589, -0.1277976930141449, -0.9928839206695557, -0.328458696603775, -0.5951339602470398, -0.4556938111782074, -0.32902440428733826, -0.053913939744234085, 0.8164037466049194, 0.00659923953935504, -0.061623215675354004, 1.4764076471328735, 0.2947120666503906, 0.5066423416137695, -0.3917187750339508, -0.5722973346710205, -0.12322372943162918, -0.5445550680160522, -0.29131802916526794, -0.14367340505123138, 0.5685091614723206, -0.4174249470233917, -0.2487613409757614, 0.17574623227119446]}, "authors": [{"authorId": "2268721510", "name": "Jacob Zhiyuan Fang"}, {"authorId": "2268855820", "name": "Skyler Zheng"}, {"authorId": "2269064439", "name": "Vasu Sharma"}, {"authorId": "2268494451", "name": "Robinson Piramuthu"}], "references": [{"paperId": "eba51c023f3ae9eeca783893b973db60e7a99a6c", "title": "A Unified View of Masked Image Modeling"}, {"paperId": "8b24e5820617fa6e5b79b4fc51f77a7d175dbbfa", "title": "EfficientVLM: Fast and Accurate Vision-Language Models via Knowledge Distillation and Modal-adaptive Pruning"}, {"paperId": "bac146e4f52df49ded741e4b31102b97c8b5847f", "title": "An Empirical Study of End-to-End Video-Language Transformers with Masked Visual Modeling"}, {"paperId": "599be9043ef3571f65758cf36e184c9dc1781baf", "title": "BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers"}, {"paperId": "ab7214861fc314c796abf9fb7ccbd4c1ff6f7e2c", "title": "MobiVQA"}, {"paperId": "05b7bd47fa5cbe10497c49004b57eb5ab4fdd0b4", "title": "EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for Mobile Vision Applications"}, {"paperId": "8b5eab31e1c5689312fff3181a75bfbf5c13e51c", "title": "Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks"}, {"paperId": "02720ba7a4c0c70506ef63e039387c10b227d8e3", "title": "Transform-Retrieve-Generate: Natural Language-Centric Outside-Knowledge Visual Question Answering"}, {"paperId": "138b11c7ba96ad224b2fd4ade1bac18e8cfd7cb8", "title": "CyCLIP: Cyclic Contrastive Language-Image Pretraining"}, {"paperId": "8f26262437bde0ff8fe5e14d5a6cb4cc05a495ef", "title": "Multimodal Masked Autoencoders Learn Transferable Representations"}, {"paperId": "60ee030773ba1b68eb222a265b052ca028353362", "title": "GIT: A Generative Image-to-text Transformer for Vision and Language"}, {"paperId": "d28fed119d9293af31776205150b3c34f3adc82b", "title": "Uniform Masking: Enabling MAE Pre-training for Pyramid-based Vision Transformers with Locality"}, {"paperId": "004b97aea43f9f62cc49dec20f449abfbae28811", "title": "Masked Autoencoders As Spatiotemporal Learners"}, {"paperId": "c57293882b2561e1ba03017902df9fc2f289dea2", "title": "Hierarchical Text-Conditional Image Generation with CLIP Latents"}, {"paperId": "b1fc7d96d732f99510658c73a8d9da3fd7b25923", "title": "MultiMAE: Multi-modal Multi-task Masked Autoencoders"}, {"paperId": "4990f7542f0600e0501a7e7a931b32eb7cb804d5", "title": "VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training"}, {"paperId": "4259c7706ad1b2f993e33d824f208ffe68313656", "title": "Multi-Modal Masked Pre-Training for Monocular Panoramic Depth Completion"}, {"paperId": "095ccdb08837a4b44a62638fb8dc391818707e5a", "title": "All in One: Exploring Unified Video-Language Pre-Training"}, {"paperId": "ae28b4edea7b3db37ffd0ebba7c54478a9b5e3ab", "title": "LoopITR: Combining Dual and Cross Encoder Architectures for Image-Text Retrieval"}, {"paperId": "e9581d9758062f76e029bd19a58c4ae976cfb414", "title": "SLIP: Self-supervision meets Language-Image Pre-training"}, {"paperId": "96362c3467d70ff1b471f74e0f83085b52afec34", "title": "Distilled Dual-Encoder Model for Vision-Language Understanding"}, {"paperId": "45348358505da4158afb98e0e18ee4e384d8d798", "title": "Injecting Semantic Concepts into End-to-End Image Captioning"}, {"paperId": "2fd6f77540c1cc8e70b96208ccf9971b4251fc02", "title": "FLAVA: A Foundational Language And Vision Alignment Model"}, {"paperId": "9f951b58fc21926f94fc68d9b565d31cc02e8623", "title": "BEVT: BERT Pretraining of Video Transformers"}, {"paperId": "2299c08033af3e2f7d1f6a958aadb15f10ddd0ef", "title": "Object-aware Video-language Pre-training for Retrieval"}, {"paperId": "3e38f4b4055abecbac2e618df2ecb33554073e08", "title": "PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers"}, {"paperId": "ba9d736006b897d06f75586ad46e28e00a5e566e", "title": "VIOLET : End-to-End Video-Language Transformers with Masked Visual-token Modeling"}, {"paperId": "21ec90872abd986c12afe39bebe807732ffa70c9", "title": "Florence: A New Foundation Model for Computer Vision"}, {"paperId": "c05cd00ae61f3c1c39be2603a2f96fdfe0c59dd8", "title": "UFO: A UniFied TransfOrmer for Vision-Language Representation Learning"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "94ff111c4d81bd03f159321728ceec8b4711c89d", "title": "An Empirical Study of Training End-to-End Vision-and-Language Transformers"}, {"paperId": "821ad6c9f0fecb5fabb486a5a87a93b7ea65bcc0", "title": "VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding"}, {"paperId": "e79be3f9ce409f1a9b7084ef880298665e5212d0", "title": "TACo: Token-aware Cascade Contrastive Learning for Video-Text Alignment"}, {"paperId": "94eae578e6af3382f6449506965639f18aab3fa0", "title": "Video Swin Transformer"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "63c74d15940af1af9b386b5762e4445e54c73719", "title": "VinVL: Revisiting Visual Representations in Vision-Language Models"}, {"paperId": "18f37f62d2bf3c2e34e2bde78545b47e92d7b72d", "title": "VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding"}, {"paperId": "889c9c37634766b3543424ac6955811f83f260e0", "title": "Compressing Visual-linguistic Model via Knowledge Distillation"}, {"paperId": "bac87bdb1cabc35fafb8176a234d332ebcc02864", "title": "Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval"}, {"paperId": "0b6f13177a90a02d44a41c62659988561f56c168", "title": "WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Training"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "ba4a4d31d2af23eefadbf19e5efd5a7d4fd89143", "title": "Less is More: CLIPBERT for Video-and-Language Learning via Sparse Sampling"}, {"paperId": "141a5033d9994242b18bb3b217e79582f1ee9306", "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"}, {"paperId": "0839722fb5369c0abaff8515bfc08299efc790a1", "title": "ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision"}, {"paperId": "47f7ec3d0a5e6e83b6768ece35206a94dc81919c", "title": "Taming Transformers for High-Resolution Image Synthesis"}, {"paperId": "188003cf06acbfe2773ce9cfa4bf0517b6d459d8", "title": "MiniVLM: A Smaller and Faster Vision-Language Model"}, {"paperId": "b1f6397717d3cbf84e89081a47205f8ed8395d22", "title": "Look Before you Speak: Visually Contextualized Utterances"}, {"paperId": "1ce28b6d15661e327c5bacd7dd89aae8e6985527", "title": "Just Ask: Learning to Answer Questions from Millions of Narrated Videos"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "34ebd21d136dfcc6c6bee14ae142cc90f6b68110", "title": "Asymmetric Loss For Multi-Label Classification"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "3b0d38302115af1165639d6fb34c4c19187b2a6f", "title": "Behind the Scene: Revealing the Secrets of Pre-trained Vision-and-Language Models"}, {"paperId": "5546e6073f3b82967b12c87d6b90ba722c4b85c6", "title": "Hero: Hierarchical Encoder for Video+Language Omni-representation Pre-training"}, {"paperId": "b5ef0f91663f0cbd6910dec9a890c138f7ec10e0", "title": "Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks"}, {"paperId": "4040449690bb326ca3d5675d6397c2c58952fc11", "title": "The General"}, {"paperId": "777873ef6d23c2cdd7dfd6c4834eb56769a25bb1", "title": "Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning"}, {"paperId": "4243555758433880a67b15b50f752b1e2a8c4609", "title": "UniViLM: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation"}, {"paperId": "c3afcd7e57c3e04b03b0b5001a3854482fa39441", "title": "In Defense of Grid Features for Visual Question Answering"}, {"paperId": "9de403a58395a1b56bfceee6e009788c43db6d08", "title": "End-to-End Learning of Visual Representations From Uncurated Instructional Videos"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "2f9d4887d0022400fc40c774c4c78350c3bc5390", "title": "Small and Practical BERT Models for Sequence Labeling"}, {"paperId": "4aa6298b606941a282d735fa3143da293199d2ca", "title": "VL-BERT: Pre-training of Generic Visual-Linguistic Representations"}, {"paperId": "2bc1c8bd00bbf7401afcb5460277840fd8bab029", "title": "Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training"}, {"paperId": "9311779489e597315488749ee6c386bfa3f3512e", "title": "HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "c41a11c0e9b8b92b4faaf97749841170b760760a", "title": "VideoBERT: A Joint Model for Video and Language Representation Learning"}, {"paperId": "5f4a22ee70ca613d9c0630eafc96364fe365fdf8", "title": "Efficient Attention: Attention with Linear Complexities"}, {"paperId": "b4df354db88a70183a64dbc9e56cf14e7669a6c0", "title": "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "f466157848d1a7772fb6d02cdac9a7a5e7ef982e", "title": "Neural Discrete Representation Learning"}, {"paperId": "ee909ad489244016cf301bb7d7d8eeea423dbf35", "title": "Localizing Moments in Video with Natural Language"}, {"paperId": "a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8", "title": "Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6", "title": "The Kinetics Human Action Video Dataset"}, {"paperId": "b2f521c02c6ed3080c5fe123e938cdf4555e6fd2", "title": "TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering"}, {"paperId": "05f3f8f6f97db00bafa2efd2ac9aac570603c0c6", "title": "TGIF: A New Dataset and Benchmark on Animated GIF Description"}, {"paperId": "afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d", "title": "Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations"}, {"paperId": "b8e2e9f3ba008e28257195ec69a00e07f260131d", "title": "MSR-VTT: A Large Video Description Dataset for Bridging Video and Language"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "62c76ca0b2790c34e85ba1cce09d47be317c7235", "title": "Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation"}, {"paperId": "8b3b8848a311c501e704c45c6d50430ab7068956", "title": "HMDB: A large video database for human motion recognition"}, {"paperId": "72729882f8fa3d9084eaece513f6bf9630be5901", "title": "Collecting Highly Parallel Data for Paraphrase Evaluation"}, {"paperId": "a509f100bf7cf2945c53679faa8726876aaff955", "title": "Voxel-MAE: Masked Autoencoders for Pre-training Large-scale Point Clouds"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Uni\ufb01ed-io: A uni\ufb01ed model license agreement with IEEE"}, {"paperId": null, "title": "General perception with iterative attention"}, {"paperId": null, "title": "Object-aware license agreement with IEEE. Restrictions apply"}, {"paperId": null, "title": "Perceiver"}]}