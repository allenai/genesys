{"paperId": "88dd119dba5ee747851ade8f5d517b381614d918", "title": "Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence", "abstract": "Nowadays, foundation models become one of fundamental infrastructures in artificial intelligence, paving ways to the general intelligence. However, the reality presents two urgent challenges: existing foundation models are dominated by the English-language community; users are often given limited resources and thus cannot always use foundation models. To support the development of the Chinese-language community, we introduce an open-source project, called Fengshenbang, which leads by the research center for Cognitive Computing and Natural Language (CCNL). Our project has comprehensive capabilities, including large pre-trained models, user-friendly APIs, benchmarks, datasets, and others. We wrap all these in three sub-projects: the Fengshenbang Model, the Fengshen Framework, and the Fengshen Benchmark. An open-source roadmap, Fengshenbang, aims to re-evaluate the open-source community of Chinese pre-trained large-scale models, prompting the development of the entire Chinese large-scale model community. We also want to build a user-centered open-source ecosystem to allow individuals to access the desired models to match their computing resources. Furthermore, we invite companies, colleges, and research institutions to collaborate with us to build the large-scale open-source model-based ecosystem. We hope that this project will be the foundation of Chinese cognitive intelligence.", "venue": "arXiv.org", "year": 2022, "citationCount": 76, "influentialCitationCount": 9, "openAccessPdf": {"url": "http://arxiv.org/pdf/2209.02970", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "An open-source project, called Fengshenbang, which aims to re-evaluate the open- source community of Chinese pre-trained large-scale models, prompting the development of the entire Chinese large- scale model community, and to build a user-centeredopen-source ecosystem to allow individuals to access the desired models to match their computing resources."}, "embedding": {"model": "specter_v2", "vector": [-0.1978248506784439, 0.2809993624687195, -0.5688760280609131, -0.1580846905708313, -0.005196633283048868, 0.13435156643390656, 0.8712925314903259, -0.5134894251823425, -0.6194422841072083, 0.11807072907686234, 0.6700387597084045, -0.03462979942560196, 0.2790556848049164, 0.08064978569746017, -0.05884808674454689, 0.011956976726651192, -0.63450688123703, 0.288663387298584, 0.014654652215540409, -0.2345529943704605, 0.11829249560832977, -0.6077973246574402, -1.179376482963562, 0.2727475166320801, 0.45324137806892395, 0.698181688785553, 0.5217995643615723, 1.0830094814300537, -0.35407477617263794, 0.7104530930519104, 0.27653664350509644, -0.21428054571151733, 0.3402218520641327, 0.38020068407058716, -0.41358044743537903, -0.2696371078491211, 0.12332653254270554, -0.6270387172698975, -0.5213414430618286, 1.1924210786819458, -0.4286060333251953, 0.07440037280321121, 0.4091372787952423, -0.8973824381828308, -0.544874370098114, 0.7544842958450317, 1.3311184644699097, 0.467908650636673, -0.37580618262290955, -0.4276469349861145, 1.1683149337768555, -1.0262452363967896, 0.15104149281978607, 1.2395731210708618, 0.40556323528289795, 0.6716141104698181, -0.13816288113594055, -0.9045238494873047, 0.28583016991615295, -0.06385122239589691, -0.5906035304069519, -0.16612806916236877, 0.36032533645629883, -0.3008049726486206, 1.548025131225586, -0.49543747305870056, 0.003154848702251911, 0.44706520438194275, 0.20857122540473938, 1.6863656044006348, 0.31815871596336365, -0.9241380095481873, -0.15221403539180756, 0.060035590082407, 0.40292608737945557, 0.6626911163330078, -0.35247567296028137, 0.4406815767288208, -0.8781166672706604, -0.18615777790546417, 0.478350430727005, 0.07134801149368286, 0.042494215071201324, 0.23498572409152985, -0.8244982361793518, 0.7587049007415771, 0.6882907748222351, 0.7196080684661865, -0.4018080234527588, 0.35465553402900696, 0.3502455949783325, 0.20060408115386963, -0.2554914057254791, 0.3170400857925415, -0.3625849485397339, 0.57111656665802, -0.6459975838661194, 0.5461357831954956, 0.017985522747039795, 1.1441435813903809, 0.062002234160900116, -0.1250336915254593, -0.5127224922180176, 0.1297944039106369, 1.0834201574325562, -0.2855430543422699, 0.8404274582862854, -0.951427698135376, 0.07536670565605164, -0.07141009718179703, 0.2534220218658447, -0.14502960443496704, -0.36510202288627625, -0.1967436671257019, -0.8545926809310913, -0.9869367480278015, -0.5498256087303162, 0.1948493868112564, -0.704797625541687, 0.5854989886283875, -0.8103455305099487, -0.07087782770395279, 0.3766721487045288, 0.5487710237503052, 0.36486348509788513, 0.294633150100708, 0.42707574367523193, 0.3805829584598541, 0.6307492256164551, -1.2579091787338257, -0.7608850002288818, -1.2232030630111694, 0.5315793752670288, -0.04326801747083664, 0.48599472641944885, -0.16107453405857086, -0.9692468047142029, -1.2003730535507202, -0.9378377199172974, -0.07714150100946426, -0.6334443688392639, 0.5653372406959534, 1.5435713529586792, 0.09340600669384003, -1.0160478353500366, 0.6050494909286499, 0.09945308417081833, -0.07532770931720734, 0.22457745671272278, 0.15710291266441345, 0.15741415321826935, -0.4722714126110077, -1.5425570011138916, 0.40787917375564575, 1.0271450281143188, -0.7607806921005249, -0.4765549898147583, -0.08489062637090683, -0.5820590257644653, -0.04643626511096954, 0.10724062472581863, -0.47339338064193726, 1.399966835975647, -0.4124135375022888, -0.7083392143249512, 0.4385225772857666, -0.2663690745830536, 0.0028826757334172726, -0.07925476878881454, 0.039082035422325134, -1.1099979877471924, -0.3692043423652649, 0.1306638866662979, 0.5691953897476196, -0.04010285809636116, -0.3015829026699066, -0.32221177220344543, 0.3784569799900055, 0.0009338532690890133, -0.2789310812950134, -0.7400869727134705, 1.2237896919250488, -0.5269613265991211, -0.3297906219959259, 0.24912644922733307, 0.5990436673164368, -0.14735916256904602, 0.1503223031759262, -0.503143310546875, -1.0601686239242554, 0.5592158436775208, 0.08362723141908646, 1.1164524555206299, -0.9220237731933594, -0.954660177230835, -0.15414144098758698, -0.01366723608225584, -0.09504137188196182, -0.48183467984199524, 0.2577662169933319, 0.0046117003075778484, 0.37423357367515564, -0.27860164642333984, -0.7190716862678528, -0.08566955476999283, -0.02840864472091198, -0.2885739505290985, -0.5580241680145264, 0.10046988725662231, 1.0734431743621826, -0.663435161113739, 0.02868993766605854, -0.42351704835891724, -0.030422361567616463, -1.0415533781051636, 1.2025597095489502, -0.649143397808075, 0.01899734139442444, -0.3777117133140564, -0.19484427571296692, -0.06187940761446953, -0.3094636797904968, 0.12359113246202469, -0.02161399833858013, -0.6808800101280212, 0.2664400339126587, -0.5167896747589111, 1.5992815494537354, 0.1335599273443222, 0.4358305335044861, 0.18088987469673157, -0.27202126383781433, 0.22999554872512817, 0.61883544921875, -0.6193949580192566, -0.17539748549461365, 0.1088644340634346, 0.5096466541290283, -0.3588290810585022, 0.4638463854789734, 0.4476613998413086, 0.6852648258209229, -0.387601763010025, 0.4779125154018402, 0.5129075646400452, -0.36716803908348083, 0.5826959609985352, 0.45227953791618347, -0.020300807431340218, -0.06566386669874191, 0.38002440333366394, -0.7545291185379028, 0.7595397233963013, -0.5635657906532288, 0.09855213761329651, 0.6803637742996216, 0.14668482542037964, 0.567218005657196, 0.31708696484565735, -1.2964136600494385, -0.11015473306179047, 0.32702410221099854, 0.5181485414505005, 1.4440163373947144, -0.07466862350702286, -0.38623782992362976, -0.9317565560340881, -0.116000697016716, -0.24266502261161804, 0.34079521894454956, -0.4244936406612396, -0.11562733352184296, -0.1250709891319275, -0.8489601016044617, 0.991222620010376, 0.5694993734359741, 1.2743809223175049, -0.9518111348152161, -0.3341970145702362, -0.31498152017593384, 0.3332337439060211, -0.6031671762466431, -0.6634412407875061, 0.11228982359170914, -0.5342029333114624, -0.3371524214744568, 0.11293371766805649, -0.35547664761543274, -0.0196145698428154, -0.5594499707221985, 0.6232414245605469, 0.0890812799334526, -0.06954377889633179, -0.07571166753768921, 1.0581583976745605, -1.2872437238693237, -0.7942430377006531, -0.3674471974372864, 0.4902370274066925, -0.16704729199409485, 0.5728508830070496, 0.9332129955291748, 0.24219979345798492, 0.3061300814151764, -0.5555508732795715, 0.7784512042999268, 0.21215970814228058, 0.3402533531188965, 0.6106389760971069, 0.10453759133815765, 0.1620984822511673, -0.9055424332618713, 1.2644654512405396, 0.7548804879188538, -0.5986058115959167, 0.5597058534622192, -0.624465823173523, -0.2562418580055237, 0.583499550819397, -0.6607879400253296, -0.4680628478527069, -0.8175931572914124, 0.6761850118637085, 0.0819980651140213, -0.5541334748268127, 0.5780906677246094, 0.1161077544093132, -0.1627211570739746, 0.46152445673942566, 0.5286002159118652, 0.03798983246088028, -0.2690516710281372, 0.13217079639434814, -0.43170735239982605, 0.6207841634750366, 0.1860855221748352, -0.36796170473098755, -0.1441337913274765, -0.5026004314422607, -0.5541020035743713, -0.5653627514839172, -0.23809251189231873, -0.2762678563594818, -0.36557093262672424, 0.24179865419864655, -0.8032826781272888, -0.6440215110778809, 0.24297669529914856, -1.0695698261260986, -0.2650350332260132, 0.5520051717758179, 0.054722387343645096, -0.041219621896743774, -1.081396222114563, -1.2868002653121948, -0.4404161870479584, -0.7127900123596191, -0.9319813847541809, 0.0417909249663353, 0.1552121937274933, 0.04557165503501892, -0.4272369146347046, -0.28190213441848755, -0.18518508970737457, 1.2279961109161377, -0.8845497965812683, 1.016131043434143, -0.0016160457162186503, -0.01659495197236538, -0.7337336540222168, 0.03876776248216629, 0.9574266076087952, -0.5931781530380249, 0.10755753517150879, -0.9021907448768616, 0.40190234780311584, 0.06864378601312637, -0.488586962223053, 0.351477712392807, 0.3427858352661133, 0.9215312600135803, 0.4706418514251709, -0.15079748630523682, 0.193845734000206, 1.1432554721832275, -0.5333342552185059, -0.16160526871681213, 0.2502706050872803, 0.6976699829101562, 0.05308521166443825, -0.5030034780502319, 0.26893922686576843, 0.4533606171607971, 0.22491846978664398, 0.06820037215948105, -0.31793832778930664, -0.10007710009813309, -0.35138824582099915, 0.30481526255607605, 1.216346263885498, -0.49496060609817505, 0.2722429037094116, -1.4100617170333862, 0.16449277102947235, -1.1157433986663818, -0.718226432800293, 0.7124624848365784, 0.7775253653526306, 0.2539755403995514, -0.04680768400430679, -0.4351937174797058, 0.14441296458244324, 0.6897780299186707, 0.04259691387414932, -0.23881365358829498, -0.31891775131225586, -0.4771950840950012, 0.1118997111916542, -0.05849552899599075, 0.48800426721572876, -0.6039403676986694, 0.8851596713066101, 14.729466438293457, 0.5942787528038025, 0.03195960819721222, 0.8153035640716553, 0.6531892418861389, 0.561453104019165, -0.31761497259140015, -0.01866033300757408, -1.0796923637390137, -0.1352449655532837, 0.9869029521942139, -0.2723875045776367, 1.101501703262329, 0.532800555229187, -0.21880924701690674, 0.21661636233329773, -0.02564302645623684, 0.48584264516830444, 0.5443942546844482, -1.4572665691375732, 0.5091181993484497, 0.2494519054889679, 0.6796532273292542, 1.0142841339111328, 0.13289836049079895, 0.8493931293487549, 0.14051808416843414, -0.3455861806869507, 0.7667286992073059, 0.37571701407432556, 0.6220690608024597, -0.011254888027906418, 0.6290901303291321, 1.0403364896774292, -0.9385114312171936, -0.6501975059509277, -1.126776099205017, -1.7342290878295898, 0.29281601309776306, 0.1766781359910965, -0.004250227008014917, -0.7453562617301941, -0.28460612893104553, 0.6490389704704285, -0.13249579071998596, 0.27720022201538086, -0.6473982930183411, 0.26779547333717346, 0.17613093554973602, -0.14515511691570282, 0.08491551131010056, 0.4175456762313843, -0.15816150605678558, -0.13033133745193481, 0.0434500090777874, 0.12047931551933289, 0.4941784739494324, 0.6576730608940125, -0.6070892810821533, -0.08719274401664734, -0.22058627009391785, -0.42759430408477783, -0.5342368483543396, 0.7960935831069946, 0.4254343509674072, -0.16113339364528656, -0.47791004180908203, -0.05199873447418213, 0.46743419766426086, 0.43794628977775574, -0.06459476053714752, -0.060293395072221756, 0.2983954846858978, -0.5808582305908203, -0.6538520455360413, 0.3915984034538269, -0.5208015441894531, -0.841758668422699, -0.8236747980117798, 0.037288058549165726, 0.21703559160232544, -0.9399632811546326, -0.6653366684913635, 1.423174262046814, -0.2908269464969635, -0.0067296396009624004, 0.3532974421977997, -1.190951943397522, -0.6093003153800964, 0.9520772695541382, -1.4638497829437256, -1.0381685495376587, 0.027122914791107178, 0.45110923051834106, -0.19487684965133667, -0.3969654440879822, 1.7228180170059204, -0.18362130224704742, -0.38807249069213867, -0.5748880505561829, -0.2996015250682831, 0.18629975616931915, -0.3293071985244751, -0.6200303435325623, 0.7006094455718994, 0.4319102168083191, -0.23952236771583557, 0.4000685214996338, -0.43950146436691284, -0.13588711619377136, -0.44244152307510376, 0.17941530048847198, 1.3074268102645874, -0.765531063079834, -0.1758580207824707, -1.0183079242706299, -0.8085690140724182, 0.12252642959356308, 0.5534840226173401, -0.22708505392074585, 0.24348299205303192, 0.12748652696609497, -0.42394301295280457, 0.18655572831630707, -0.6145117282867432, -0.029149429872632027, 0.5530449151992798, -0.9757053852081299, -0.5188412666320801, 0.562523603439331, 0.17399486899375916, -0.28587740659713745, -0.3330373764038086, -0.2384943813085556, 0.3097030222415924, -0.5279983282089233, 0.9305956959724426, -0.4842161238193512, 0.45428118109703064, 0.6645153164863586, -0.23482005298137665, -0.6361503005027771, -0.5798519253730774, -0.7269934415817261, 0.3251006305217743, -0.5789229273796082, 0.7539803385734558, -0.7034782767295837, -0.05714656785130501, 1.3905402421951294, -0.06608148664236069, -0.1741212010383606, -0.4549671411514282, -0.1901209056377411, -0.11530566960573196, -0.7900336980819702, 0.7268494367599487, -0.09367967396974564, 0.0012749547604471445, -0.10040632635354996, 0.39991340041160583, 0.5405808091163635, -0.2585274577140808, -0.4642954468727112, 0.372949481010437, -0.611283540725708, -0.03233351558446884, -0.8148013353347778, -0.30175521969795227, -1.2801657915115356, 0.22864077985286713, -1.1589186191558838, -0.13163305819034576, -1.03371000289917, -0.1800675392150879, 0.10465699434280396, -0.6744102239608765, 0.13619408011436462, 0.30177798867225647, -0.43672576546669006, -0.40271368622779846, 0.02632167562842369, -0.1434365063905716, 0.48796287178993225, 1.2508141994476318, -0.4552144408226013, 0.13149471580982208, 0.032303594052791595, -0.055930253118276596, 0.5468052625656128, 0.5764850974082947, -0.17851482331752777, -0.7817495465278625, -1.3567713499069214, -0.01929752342402935, -0.4620952904224396, -0.04692770540714264, -1.0703102350234985, 1.2770464420318604, 0.2087450921535492, -0.060937728732824326, 0.31083032488822937, 0.3241252899169922, -0.6046789288520813, -0.5655294060707092, 0.688210129737854, -0.8441290259361267, 0.5676714181900024, 0.052628468722105026, -0.8430109024047852, -0.594658613204956, 0.7443506121635437, -0.2600994408130646, -1.0283925533294678, -0.7226176261901855, 0.3464546203613281, -0.693635106086731, -0.3191757798194885, -0.30652445554733276, 0.03131435438990593, -1.0027728080749512, -0.22782646119594574, 0.31597036123275757, 0.1347823143005371, -0.31920117139816284, 0.6798846125602722, 0.5543189644813538, -1.0298775434494019, 0.06498343497514725, 1.303296446800232, 0.22711344063282013, -0.47139325737953186, 0.22492198646068573, 0.23859326541423798, -0.33481186628341675, 1.0585836172103882, -0.0018663678783923388, 0.6298176050186157, -0.42674520611763, 0.09891320765018463, 0.3239504396915436, -0.20319236814975739, -0.2878668010234833, 1.1382218599319458, -0.06317821145057678, -1.2568432092666626, 0.24657753109931946, -1.329766869544983, -0.7472751140594482, -1.1392289400100708, 1.223431944847107, -0.07910420745611191, -0.28581702709198, -0.4474138617515564, -0.07709828019142151, -0.11311689019203186, 0.2044311761856079, -0.4919862151145935, 0.3553112745285034, 0.33877822756767273, -0.5990639328956604, 0.6978439092636108, 0.3435245752334595, -0.9676929116249084, -0.85099196434021, -0.33523029088974, -0.051767390221357346, -0.28860053420066833, 0.5721602439880371, -0.7536502480506897, -0.45915061235427856, 0.7292681932449341, 0.4847361445426941, 0.4364694058895111, 0.41430914402008057, -0.34492647647857666, 0.12054342776536942, 0.7672143578529358, 0.43599823117256165, -1.0365175008773804, -0.8679803013801575, 1.5574040412902832, 1.3724035024642944, -0.9470504522323608, 0.15537430346012115, -0.0007638185052201152, -1.0112261772155762, 1.1067191362380981, 0.204637810587883, -0.06860291957855225, 0.9794741272926331, -0.3192209303379059, 0.25032129883766174, 0.15889863669872284, -0.917190432548523, 0.005399514455348253, 1.0968648195266724, 0.731453537940979, 0.8340991735458374, 0.9385259747505188, -0.10855714231729507, 1.454006314277649, 0.14889538288116455, 0.5829501748085022, 0.33369699120521545, 0.6135467290878296, -0.37745201587677, 0.046855561435222626, -0.04036333039402962, 0.5741686224937439, -0.20946700870990753, -0.8047208189964294, -0.21522624790668488, 0.7743555307388306, 0.4745989143848419, 0.6149855256080627, 0.26641353964805603, 0.005405074916779995, 0.548893392086029, 0.29001185297966003, -0.025032246485352516, -0.3514585793018341, -0.3195693790912628, 0.16833578050136566, -0.5390983819961548, 0.04350709915161133, -0.5330959558486938, 0.07092991471290588, -0.4295605719089508, -0.036008939146995544, 0.095957450568676, 0.027979936450719833, 0.8459805250167847, 1.1127697229385376, 0.5788451433181763, -0.005577086936682463, -0.8771011829376221, -0.6248946785926819, -0.2743961811065674, -1.1096152067184448, -0.13049960136413574, -0.5748788714408875, -0.42815813422203064, -0.46526482701301575, -0.27793923020362854, -0.5905008316040039]}, "authors": [{"authorId": "2143183255", "name": "Junjie Wang"}, {"authorId": "2108080174", "name": "Yuxiang Zhang"}, {"authorId": "2143838327", "name": "Lin Zhang"}, {"authorId": "2170961819", "name": "Ping Yang"}, {"authorId": "2115407333", "name": "Xinyu Gao"}, {"authorId": "2109686406", "name": "Ziwei Wu"}, {"authorId": "46965981", "name": "Xiaoqun Dong"}, {"authorId": "9004440", "name": "Junqing He"}, {"authorId": "2184248816", "name": "Jianheng Zhuo"}, {"authorId": "2116902425", "name": "Qi Yang"}, {"authorId": "2145525387", "name": "Yongfeng Huang"}, {"authorId": "2108571528", "name": "Xiayu Li"}, {"authorId": "50118362", "name": "Yan-Ze Wu"}, {"authorId": "1831370", "name": "Junyu Lu"}, {"authorId": "2116314158", "name": "Xinyu Zhu"}, {"authorId": "2186861609", "name": "Weifeng Chen"}, {"authorId": "2075302579", "name": "Ting-Ting Han"}, {"authorId": "2184245974", "name": "Kunhao Pan"}, {"authorId": "2151036995", "name": "Rui Wang"}, {"authorId": "48016595", "name": "Hao Wang"}, {"authorId": "2108048534", "name": "Xiaojun Wu"}, {"authorId": "2120043041", "name": "Zhong Zeng"}, {"authorId": "1998916322", "name": "Chong-An Chen"}, {"authorId": "94166197", "name": "Ruyi Gan"}, {"authorId": "2144129760", "name": "Jiaxing Zhang"}], "references": [{"paperId": "e14f0ff7054039970b1c924ecc6fc5b8ea3377cb", "title": "Towards No.1 in CLUE Semantic Matching Challenge: Pre-trained Language Model Erlangshen with Propensity-Corrected Loss"}, {"paperId": "fa763f4e71a760f7e21de3f1e611a15d873f783d", "title": "Unified BERT for Few-shot Natural Language Understanding"}, {"paperId": "f1eb0b8788a99f9635a344124bc7211b17bee908", "title": "Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A Vision-Language Framework"}, {"paperId": "0db5207510819b9956849eb84bfe8703f8f3688d", "title": "BioBART: Pretraining and Evaluation of A Biomedical Generative Language Model"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "4237cbebe788a97174f48dc398082739bbffe95b", "title": "FewCLUE: A Chinese Few-shot Learning Evaluation Benchmark"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "1197ae4a62f0e0e4e3f3fb70396b5ff06ef371aa", "title": "CogView: Mastering Text-to-Image Generation via Transformers"}, {"paperId": "0b077c9577f4297dcf3da835e253d21965bbc6e0", "title": "CoTexT: Multi-task Learning with Code-Text Transformer"}, {"paperId": "04b40daa1ca74bdbb578beb314bf662538ecd18e", "title": "ZEN 2.0: Continue Training and Adaption for N-gram Enhanced Text Encoders"}, {"paperId": "6563251e69e4378c189d0a0c94d8d19508d552c8", "title": "MathBERT: A Pre-Trained Model for Mathematical Formula Understanding"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "69a72ff5b30642d11c96635e99aadad3140d33a7", "title": "CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation"}, {"paperId": "0839722fb5369c0abaff8515bfc08299efc790a1", "title": "ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision"}, {"paperId": "74276a37bfa50f90dfae37f767b2b67784bd402a", "title": "mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer"}, {"paperId": "5ad57623099f1fb6045a67fee313fee2573ef5ec", "title": "A Benchmark for Lease Contract Review"}, {"paperId": "4083958684292f6fa2f5c7fd4f9be975e80145b6", "title": "GraphCodeBERT: Pre-training Code Representations with Data Flow"}, {"paperId": "3578a7792904e6af3db8ffefdff86ab6a387c7c3", "title": "FinBERT: A Pretrained Language Model for Financial Communications"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "18318b10e7c2dd4ad292208f4399eb1d4dca5768", "title": "CLUE: A Chinese Language Understanding Evaluation Benchmark"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "0fe2636446cd686830da3d971b31a004d6094b3c", "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages"}, {"paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a", "title": "On Layer Normalization in the Transformer Architecture"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "6007bd2a34385132a7885b934d90b519a1f65bba", "title": "ZEN: Pre-training Chinese Text Encoder Enhanced by N-gram Representations"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3", "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "2ff41a463a374b138bb5a012e5a32bc4beefec20", "title": "Pre-Training with Whole Word Masking for Chinese BERT"}, {"paperId": "d9f6ada77448664b71128bb19df15765336974a6", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"}, {"paperId": "2a567ebd78939d0861d788f0fedff8d40ae62bf2", "title": "Publicly Available Clinical BERT Embeddings"}, {"paperId": "156d217b0a911af97fa1b5a71dc909ccef7a8028", "title": "SciBERT: A Pretrained Language Model for Scientific Text"}, {"paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "ac694e97b1346de82114290d7cfbffd7a1a09c1d", "title": "Wukong: 100 Million Large-scale Chinese Cross-modal Pre-training Dataset and A Foundation Framework"}, {"paperId": null, "title": "Domainspecific language model pretraining for biomedical natural language processing"}, {"paperId": "50068fbea4d1cafcf4c99873ab272c701c08dfcb", "title": "OAG-BERT: Pre-train Heterogeneous Entity-augmented Academic Language Models"}, {"paperId": "b9478e237b58160c65acd2c41894493d27e2c277", "title": "WuDaoCorpora: A super large-scale Chinese corpora for pre-training language models"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "406fd72ed07f9d1f2d13b75f1839f37af4baa3fa", "title": "A Brief History Of Chinese Fiction"}, {"paperId": null, "title": ", Adam Roberts , Mihir Kale , Rami Al - Rfou , Aditya Siddhant , Aditya Barua , and Colin Raffel . 2021 . mt 5 : A massively multilingual pre - trained text - to - text transformer"}, {"paperId": null, "title": "Step 1: Choosing a pre-trained Chinese NLP model from our open-source library of Feng-shenbang Models"}, {"paperId": null, "title": "5B-chinese"}, {"paperId": null, "title": "Step 2: Employing Fengshen Framework to adjust the model by exploring the our tutorial examples"}, {"paperId": null, "title": "From CTO Lab in IDEA"}, {"paperId": null, "title": "Erlangshen-DeBERTa-v2-186M-Chinese-SentencePiece"}, {"paperId": null, "title": "A A List of Fengshenbang Models This list is in alphabetical order"}, {"paperId": null, "title": "Randeng-BART-759M-Chinese-BertTokenizer"}, {"paperId": null, "title": "Taiyi-Roberta-124M-D-v2"}, {"paperId": null, "title": "Erlangshen-MegatronBert-3"}, {"paperId": null, "title": "Randeng-BART-139M-SUMMARY"}, {"paperId": null, "title": "Randeng-T5-784M"}, {"paperId": null, "title": "Randeng-Transformer-1"}, {"paperId": null, "title": "Randeng-Pegasus-523M-Summary-Chinese 30"}, {"paperId": null, "title": "Taiyi-CLIP-Roberta-large-326M-Chinese"}, {"paperId": null, "title": "Erlangshen-ZEN2-668M-Chinese"}, {"paperId": null, "title": "Prodromos Malakasiotis, Nikolaos Aletras, and Ion Androutsopoulos. 2020. LEGAL-BERT: the muppets straight out of law school"}, {"paperId": null, "title": "Zhouwenwang-Unified-110M"}, {"paperId": null, "title": "Yuyuan-Bart-400M"}, {"paperId": null, "title": "Erlangshen-Roberta-110M-NLI"}]}