{"paperId": "161bf3f0705ef8e088f53b383363338daac9af44", "title": "Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings", "abstract": "The use of positional embeddings in transformer language models is widely accepted. However, recent research has called into question the necessity of such embeddings. We further extend this inquiry by demonstrating that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance. To quantify this variance, we derive the underlying distribution of each step within a transformer layer. Through empirical validation using a fully pretrained model, we show that the variance shrinkage effect still persists after extensive gradient updates. Our findings serve to justify the decision to discard positional embeddings and thus facilitate more efficient pretraining of transformer language models.", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2023, "citationCount": 3, "influentialCitationCount": 1, "openAccessPdf": {"url": "http://arxiv.org/pdf/2305.13571", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work demonstrates that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance, and derives the underlying distribution of each step within a transformer layer."}, "embedding": {"model": "specter_v2", "vector": [0.018177980557084084, 1.1646113395690918, -0.34840065240859985, -0.023968476802110672, -0.1652936488389969, -0.12767435610294342, 0.559382975101471, -0.6543881297111511, -0.5157090425491333, -0.4508371651172638, 0.8561270833015442, 0.10169297456741333, 0.057716004550457, -0.18453247845172882, -0.29423201084136963, -0.37815365195274353, -0.5922991633415222, 0.258833646774292, 0.19306963682174683, -0.7045438289642334, -0.2540441155433655, -1.0078188180923462, -0.8367033004760742, 0.0937347412109375, 0.08711171895265579, 0.2941155433654785, 0.17588958144187927, 0.3789620101451874, -0.3232138454914093, 0.5974363684654236, 0.7544386982917786, -0.41405513882637024, 0.1445208340883255, -0.15534242987632751, -0.054291073232889175, -0.1925250142812729, 0.4448421597480774, -0.5523847937583923, -0.7617837190628052, 0.957779586315155, -0.3257845640182495, 0.15632805228233337, 0.1053491085767746, -0.6547778844833374, -0.7730312347412109, 1.373428225517273, 0.9722001552581787, 0.8282365202903748, -0.5356415510177612, -0.8195560574531555, 1.4350756406784058, -1.195436716079712, 0.4684748351573944, 1.340296745300293, 0.7544648051261902, 0.42896363139152527, -0.24885055422782898, -0.45725664496421814, 0.8914217352867126, 0.001294939313083887, -0.9570206999778748, -0.5289506912231445, 0.48265308141708374, -0.06288415938615799, 1.228789210319519, -0.5975064039230347, 0.1459335833787918, 0.4038020968437195, 0.012591765262186527, 1.5032659769058228, 0.22067058086395264, -0.5963654518127441, -0.4212581217288971, 0.742646336555481, 0.5254870057106018, 0.9715827107429504, -0.5809562802314758, 0.609799861907959, -1.0918164253234863, 0.12799058854579926, 0.5882328748703003, -0.4835208058357239, 0.01638825237751007, -0.6586074829101562, -0.040855150669813156, 0.4919763207435608, 0.38550281524658203, 1.0275002717971802, -0.317806601524353, 0.8966565132141113, 0.37046048045158386, 0.3370220363140106, 0.17034989595413208, 0.09896370023488998, 0.019019627943634987, 0.48379379510879517, -0.9455944299697876, -0.0679461658000946, -0.38600239157676697, 0.5613877177238464, 0.16178098320960999, 0.5627062916755676, -0.6868852972984314, -0.02171718142926693, 1.8262920379638672, 0.19844159483909607, 0.8685776591300964, -0.907280683517456, -0.08355159312486649, -0.8250396847724915, 0.15687179565429688, -1.2321652173995972, 0.11313490569591522, -0.6409689784049988, -0.32080984115600586, -1.3788100481033325, -0.2992399334907532, 0.34487348794937134, -0.6963724493980408, 1.2733218669891357, -0.010552913881838322, -0.09934835880994797, -0.0066334097646176815, 0.32496047019958496, 0.32101327180862427, 0.49401602149009705, 0.18727350234985352, 0.22302812337875366, 0.8357082009315491, -0.8046700954437256, -1.0445873737335205, -1.092695951461792, 0.7917105555534363, -0.07001302391290665, 0.21537475287914276, -0.3781510889530182, -1.1125584840774536, -0.971885621547699, -0.8944855332374573, 0.20811615884304047, -0.5170906782150269, 0.4086657166481018, 0.9256609082221985, 0.5250627994537354, -1.7053714990615845, 1.142906904220581, -0.36856821179389954, -0.17806093394756317, 0.5953125953674316, 0.2873474657535553, -0.07261946052312851, 0.023809513077139854, -1.4356932640075684, 0.43865761160850525, 0.2776501774787903, -0.13116803765296936, -0.03613325580954552, -0.7283262014389038, -1.372489333152771, -0.17042897641658783, 0.27312707901000977, -0.2255643904209137, 1.1963450908660889, -0.041759997606277466, -1.5574004650115967, 0.6827412843704224, -0.6746054887771606, 0.04478280618786812, 0.0727635994553566, -0.1314922422170639, -0.21968665719032288, -0.4391901195049286, 0.03553590551018715, 0.4116259813308716, 0.6413752436637878, -0.49470773339271545, -0.12325125932693481, -0.3287646472454071, -0.6090413928031921, 0.09814207255840302, -0.6879286170005798, 0.7473160624504089, -0.4381011426448822, -0.16478502750396729, 0.8598089218139648, 0.5461426377296448, 0.2327479124069214, -0.4477601945400238, -0.3456818163394928, -1.1747956275939941, 0.4602230191230774, 0.0433807410299778, 1.031801700592041, -0.9373135566711426, -0.6466041207313538, 0.02167411707341671, 0.15371635556221008, -0.2746579051017761, -0.8986967206001282, 0.3346792757511139, -0.5787080526351929, 0.46867573261260986, 0.4578288793563843, -1.117371678352356, 0.29096755385398865, -0.389014333486557, -0.7492679357528687, -0.166934534907341, -0.3571570813655853, 1.1455923318862915, -1.1318910121917725, -0.01940605230629444, 0.09490525722503662, 0.6690025329589844, -0.7052334547042847, 0.9695046544075012, 0.16235166788101196, -0.045783188194036484, -0.09124082326889038, -0.6984896063804626, -0.035579655319452286, -0.3340485095977783, 0.22568532824516296, -0.6643298864364624, -0.1657983809709549, 0.7714719772338867, -0.28666242957115173, 1.0297797918319702, -0.20138061046600342, 0.7179746031761169, 0.007499501574784517, -0.38679468631744385, -0.07778452336788177, 0.2338457852602005, -0.02614482492208481, -0.7200443744659424, 0.5171986222267151, 0.07526799291372299, -0.5945477485656738, 0.8345632553100586, 0.6459024548530579, 0.6568973660469055, -0.019801588729023933, 0.35988324880599976, 0.48510855436325073, 0.04005330428481102, 0.19539979100227356, 0.3714393675327301, 0.5622103810310364, 0.7643958330154419, 0.0472603477537632, -0.3924238979816437, 0.2801094949245453, -0.8237369060516357, -0.008938276208937168, 0.4739806354045868, 0.3295293152332306, 0.5503367185592651, 0.356012225151062, -0.4373421370983124, -0.2213403284549713, -0.3313017189502716, 0.5763674378395081, 1.5938410758972168, -0.39595890045166016, -0.5214468240737915, -0.7489489912986755, 0.0899781882762909, -0.5770140886306763, 0.42339086532592773, -0.752983033657074, -0.5252755284309387, -0.7375035285949707, -0.9041262865066528, 0.35334062576293945, 0.40222427248954773, 0.8606017827987671, -0.41036999225616455, -0.27337032556533813, -0.02186274342238903, 0.6484420895576477, -0.5748154520988464, -0.3676804006099701, 0.5485222339630127, -0.6124774813652039, 0.04781195521354675, -0.011948232538998127, -0.1332731544971466, 0.20386150479316711, -0.666746973991394, 0.6321607232093811, -0.7536268830299377, 0.24496294558048248, 0.3098149001598358, 0.5315821170806885, -0.3887370824813843, -0.4644313156604767, 0.3251887559890747, 0.5095885992050171, -0.10082399845123291, 0.35639408230781555, 0.43776053190231323, -0.12356053292751312, 0.08672571927309036, -0.008773060515522957, 0.11931004375219345, 0.007629739120602608, 0.10878068953752518, 0.6191444993019104, 0.18917927145957947, -0.334526002407074, -1.4566388130187988, 0.7082685232162476, 0.47584080696105957, -0.5211307406425476, 0.085879385471344, -0.9070612788200378, -0.11335353553295135, 0.5107669830322266, -0.45715001225471497, -0.4449700117111206, -0.9545365571975708, 0.4328871965408325, -0.2593143582344055, 0.04581231251358986, 0.06034443527460098, 0.33640286326408386, 0.22053863108158112, 0.048094093799591064, 0.6291912198066711, 0.4697059094905853, 0.1079285740852356, 0.6672500371932983, -1.167893648147583, 0.4104096293449402, 0.554421067237854, 0.5933452248573303, -0.07843056321144104, -0.45334896445274353, -0.8655872344970703, -0.7426549792289734, -0.07358196377754211, 0.005997000262141228, -0.25321927666664124, 0.16689755022525787, -0.6878871321678162, -0.8463108539581299, 0.30856409668922424, -0.4851735532283783, -0.4944256544113159, -0.010273932479321957, -0.2993983328342438, -0.16249628365039825, -1.108217477798462, -1.3879731893539429, -0.49021434783935547, -0.618518590927124, -1.019291639328003, 0.1701495200395584, -0.08302713930606842, -0.5121992230415344, -0.7475693225860596, -0.05161457508802414, -0.3360384404659271, 1.4520633220672607, -1.3473432064056396, 0.9053020477294922, -0.1531214863061905, -0.3947148323059082, -0.2172989845275879, 0.40654346346855164, 0.5692591667175293, 0.07261936366558075, 0.23228861391544342, -0.5765747427940369, 0.05956067144870758, -0.13106577098369598, 0.023370200768113136, -0.12015724927186966, 0.596290647983551, 0.4691968262195587, -0.049107857048511505, -0.6206254959106445, 0.4424528181552887, 1.3020459413528442, -0.5150265097618103, 0.31701335310935974, 0.48716840147972107, 1.1600712537765503, 0.4221624732017517, -0.10434001684188843, -0.02494625560939312, 0.7833882570266724, 0.5504160523414612, 0.0916137620806694, 0.020662806928157806, -0.06112615764141083, -1.0687294006347656, 0.5905992984771729, 1.8959357738494873, 0.5812352299690247, 0.13175541162490845, -1.00411057472229, 0.7235497236251831, -1.0257707834243774, -0.9605188965797424, 0.8842066526412964, 0.8349632620811462, 0.2569439709186554, -0.479460209608078, -0.5988855361938477, 0.03473500534892082, 0.4840548038482666, 0.6589215397834778, 0.023717474192380905, -0.19945436716079712, 0.19555604457855225, 0.2854311466217041, 0.39253702759742737, 0.9110128879547119, -0.7415848970413208, 1.447187066078186, 14.797001838684082, 0.37339213490486145, -0.10514823347330093, 0.600334107875824, 0.5611836910247803, 0.5741521716117859, -0.5033812522888184, -0.18424385786056519, -1.4395925998687744, 0.1394515484571457, 1.2093479633331299, 0.17663446068763733, 0.7299972176551819, 0.10569814592599869, -0.05397672951221466, 0.19864721596240997, -0.462356835603714, 0.45254865288734436, 0.659702479839325, -1.0095269680023193, 0.37275978922843933, 0.17329123616218567, -0.017029471695423126, 0.4280683696269989, 1.3313367366790771, 0.664992094039917, 0.7010694146156311, -0.2356467992067337, 0.46018990874290466, 0.27342644333839417, 0.6023997664451599, -0.11939292401075363, 0.2141619324684143, 0.36260753870010376, -0.49393418431282043, 0.0028405243065208197, -0.44728899002075195, -0.9592711925506592, 0.13313442468643188, -0.02206447534263134, -0.06829137355089188, -1.0292741060256958, 0.19165179133415222, 0.6680364012718201, -0.012575936503708363, -0.09279405325651169, -0.4716634154319763, 0.7167081832885742, -0.1962188333272934, 0.015450706705451012, 0.4478831887245178, 0.2293000966310501, 0.19384782016277313, -0.6354735493659973, 0.3290397822856903, 0.02102576568722725, -0.4355580508708954, 0.48163169622421265, -0.1173812747001648, -0.12994013726711273, -0.34644415974617004, -0.3989338278770447, 0.09850362688302994, 0.7080890536308289, 0.45734816789627075, 0.24029377102851868, 0.07923787832260132, 0.34309810400009155, 0.6789938807487488, 0.10369057208299637, -0.17365680634975433, 0.04983467981219292, 0.6487734913825989, -0.02101258933544159, 0.08012749999761581, 0.624660074710846, -0.20494693517684937, -0.20682542026042938, -0.8942919373512268, -0.14307408034801483, -0.1400914043188095, -1.292654037475586, -0.36868682503700256, 1.0993716716766357, -0.5180952548980713, 0.047759994864463806, 0.15173101425170898, -0.8951669931411743, -0.0015848276671022177, 0.18677890300750732, -1.0449224710464478, -0.4165620803833008, 0.3776295483112335, -0.5977159142494202, -0.7129825353622437, -0.1833653450012207, 1.0956952571868896, -0.014213265851140022, -0.6262991428375244, 0.36697718501091003, 0.2870669662952423, -0.02915932424366474, -0.14246197044849396, -0.8516004085540771, 0.4828246235847473, 0.055651672184467316, 0.0020208496134728193, 0.7622612714767456, 0.3830282390117645, 0.2618987262248993, -0.9359813928604126, 0.002579741645604372, 1.0677969455718994, -1.136213779449463, 0.10472115129232407, -0.5752469897270203, -0.6447241306304932, 0.5667902827262878, 0.7567533254623413, -0.2953163981437683, 0.3759327232837677, 0.13492868840694427, -0.47289255261421204, -0.3564048111438751, -0.37838226556777954, 0.20406179130077362, 0.7076684236526489, -0.9817229509353638, -0.5129691958427429, -0.1752854585647583, -0.058085642755031586, -0.8940218091011047, -0.2385692298412323, -0.00821432750672102, -0.18610377609729767, -0.3480706512928009, 1.100415825843811, -0.5031612515449524, 0.4610641598701477, 0.5995120406150818, -0.02788904868066311, -1.0380361080169678, -0.6839392185211182, -0.7120633125305176, 0.3132397532463074, 0.6143280267715454, 0.7079578042030334, -0.4179409444332123, 0.7388482093811035, 0.956586480140686, 0.1716921478509903, -0.23985189199447632, -0.39715683460235596, -0.004950243514031172, 0.09722474962472916, -0.4686546325683594, 0.12554503977298737, -0.09454215317964554, -0.308456152677536, 0.15843836963176727, 0.4496455788612366, 0.5459621548652649, 0.28705093264579773, -1.0310790538787842, -0.04723789915442467, -0.09068933129310608, 0.29725953936576843, -0.5395130515098572, -0.5605257749557495, -1.3149751424789429, 0.26752936840057373, -1.210683822631836, 0.07818581163883209, -1.3538397550582886, -0.5569920539855957, 0.02811022289097309, -0.6071046590805054, 0.014811747707426548, 0.4044959843158722, -0.017743831500411034, -0.7196553349494934, -0.5365034937858582, -0.7583200335502625, 0.8676928877830505, 0.4866006374359131, -0.5523614287376404, 0.07166304439306259, -0.09835497289896011, -0.3060249090194702, 0.5706841945648193, 0.511006236076355, -0.5681924819946289, -1.1523518562316895, -1.6076598167419434, 0.6630039811134338, -0.48365485668182373, -0.347426176071167, -0.3769673705101013, 0.8079572916030884, 0.8125187158584595, -0.12079021334648132, -0.3579665720462799, 0.4541684091091156, -1.0342475175857544, -0.210492804646492, 0.03812872990965843, -0.7078876495361328, 0.22312672436237335, -0.1465504765510559, -0.5404609441757202, -0.3508606553077698, 0.8445225954055786, -0.09926152974367142, -1.195804476737976, -0.7553406357765198, 0.5436950325965881, -0.9145311117172241, 0.12249229848384857, -0.1380789875984192, -0.42447730898857117, -1.072495698928833, -0.40960896015167236, -0.1369352638721466, 0.21325808763504028, -0.1801755577325821, 0.9851351380348206, 0.31677690148353577, -1.4814932346343994, 0.3415178954601288, 0.377710223197937, -0.19161006808280945, -0.337617427110672, 0.6543474793434143, 0.29303446412086487, -0.34617456793785095, 0.6584085822105408, 0.3725185692310333, 0.388026624917984, -0.8510027527809143, -0.073088139295578, 0.7803660035133362, -0.2401246577501297, -0.22542689740657806, 1.251298189163208, -0.13862596452236176, -1.270558476448059, 0.21987846493721008, -0.7544288039207458, -0.7513416409492493, 0.16049177944660187, 0.498409241437912, 0.24093541502952576, -0.5730974078178406, -0.5479671359062195, -0.47907912731170654, 0.4205010235309601, -0.23204094171524048, -0.6350826025009155, 0.6189221739768982, -0.21705636382102966, -0.6751629114151001, 0.7779402732849121, 0.8703116774559021, -0.5977351665496826, -0.6822469234466553, -0.8469114303588867, -0.48209908604621887, -0.06569306552410126, 0.8639964461326599, -0.05896296724677086, -0.8226971626281738, 0.6815637946128845, 0.6601198315620422, 0.04207630455493927, -0.30669164657592773, -0.16785821318626404, -0.23042772710323334, 0.5350236892700195, 0.25824323296546936, -0.8205026388168335, -0.5992494225502014, 1.4516867399215698, 0.7831730842590332, -0.5072705149650574, -0.007202582433819771, -0.3777516186237335, -0.407407283782959, 0.30832400918006897, 0.43307003378868103, -0.031168650835752487, 1.1812642812728882, -0.15373985469341278, 0.6651773452758789, 0.054126959294080734, -0.839526355266571, -0.24597817659378052, 0.6157819032669067, 0.9072285294532776, 0.8725476861000061, 0.07452598959207535, 0.23458419740200043, 0.8054565191268921, -0.3593460023403168, -0.16930080950260162, 0.2577667534351349, 0.24213384091854095, -0.4117838144302368, 0.20826356112957, 0.3765043020248413, 0.4993463456630707, -0.4762342572212219, -0.7955025434494019, 0.061809998005628586, 0.6164730191230774, -0.04287775233387947, 0.22772616147994995, 0.9013310074806213, -0.3999224603176117, 0.28769993782043457, 0.4523966312408447, 0.5036724209785461, -0.12298297882080078, -0.11674921214580536, -0.1465206742286682, -0.5854787826538086, -0.10306217521429062, -0.11544827371835709, -0.580503523349762, -0.2450571060180664, -0.17097286880016327, 0.22539101541042328, -0.0053169624879956245, 0.2738759517669678, 0.9787681698799133, 0.4260316789150238, 0.5468388795852661, -0.2819625735282898, -0.2731400728225708, -0.6483835577964783, -0.6279537081718445, 0.12383389472961426, -0.7181951403617859, -0.32829058170318604, -0.1280229091644287, -0.3340490162372589, -0.7317525148391724]}, "authors": [{"authorId": "27531332", "name": "Ta-Chung Chi"}, {"authorId": "32037089", "name": "Ting-Han Fan"}, {"authorId": "2119257114", "name": "Li-Wei Chen"}, {"authorId": "3156164", "name": "A. Rudnicky"}, {"authorId": "1693135", "name": "P. Ramadge"}], "references": [{"paperId": "bb15f3727f827a3cb88b5d3ca48415c09b40a88f", "title": "What Language Model to Train if You Have One Million GPU Hours?"}, {"paperId": "a2fc77f075f666b462d9350e7576f0ba9845c61b", "title": "Transformer Language Models without Positional Encodings Still Learn Positional Information"}, {"paperId": "4e00843bc5f60d2b9116abc4320af6d184422291", "title": "Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "829580d6fc73fa601c4982e2b1b6832f2796270b", "title": "Positional Artefacts Propagate Through Masked Language Model Embeddings"}, {"paperId": "9be1d1bf82f6ca6a7bf6a7d92f8f37b647e493d0", "title": "Probing Pretrained Language Models for Lexical Semantics"}, {"paperId": "75e17a2dc0a2b2c1cce5ab89d8c703fb8bddbef1", "title": "On the Computational Power of Transformers and Its Implications in Sequence Modeling"}, {"paperId": "a8216d9fc9740772a44570281e7df5770978ad8d", "title": "What\u2019s so special about BERT\u2019s layers? A closer look at the NLP pipeline in monolingual and multilingual models"}, {"paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a", "title": "On Layer Normalization in the Transformer Architecture"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "8cef9900c04d7f661c08f4b5b1ed4337ace042a3", "title": "Transformer Dissection: An Unified Understanding for Transformer\u2019s Attention via the Lens of Kernel"}, {"paperId": "f89d2da991935549b109d780be3351e0dda92a8f", "title": "Assessing the Ability of Self-Attention Networks to Learn Word Order"}, {"paperId": "3928b2177086532775fbf607ae3e05a0375a5061", "title": "Language Modeling with Deep Transformers"}, {"paperId": "512b8ef0002e0bfd0ecb5ab17d533c1762eb9786", "title": "Set Transformer"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "a24508e65e599b5b20c33af96dbe7017d5caca37", "title": "Learning internal representations"}, {"paperId": "319f22bd5abfd67ac15988aa5c7f705f018c3ccd", "title": "Learning internal representations by error propagation"}, {"paperId": null, "title": "GPT-NeoX: Large Scale Autoregressive Language Modeling in PyTorch"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "2014) with learning rate 1e\u2212 3 and 5000 gradient updates. The batch size is set to 32. We implement our model using PyTorch (Paszke"}, {"paperId": "caa5eec3feba1e3f4c421f28daaa6d1906b573ec", "title": "Serial Order: A Parallel Distributed Processing Approach"}]}