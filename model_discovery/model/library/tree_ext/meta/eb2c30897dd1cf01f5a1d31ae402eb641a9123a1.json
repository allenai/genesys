{"paperId": "eb2c30897dd1cf01f5a1d31ae402eb641a9123a1", "title": "Tracking Meets LoRA: Faster Training, Larger Model, Stronger Performance", "abstract": "Motivated by the Parameter-Efficient Fine-Tuning (PEFT) in large language models, we propose LoRAT, a method that unveils the power of large ViT model for tracking within laboratory-level resources. The essence of our work lies in adapting LoRA, a technique that fine-tunes a small subset of model parameters without adding inference latency, to the domain of visual tracking. However, unique challenges and potential domain gaps make this transfer not as easy as the first intuition. Firstly, a transformer-based tracker constructs unshared position embedding for template and search image. This poses a challenge for the transfer of LoRA, usually requiring consistency in the design when applied to the pre-trained backbone, to downstream tasks. Secondly, the inductive bias inherent in convolutional heads diminishes the effectiveness of parameter-efficient fine-tuning in tracking models. To overcome these limitations, we first decouple the position embeddings in transformer-based trackers into shared spatial ones and independent type ones. The shared embeddings, which describe the absolute coordinates of multi-resolution images (namely, the template and search images), are inherited from the pre-trained backbones. In contrast, the independent embeddings indicate the sources of each token and are learned from scratch. Furthermore, we design an anchor-free head solely based on MLP to adapt PETR, enabling better performance with less computational overhead. With our design, 1) it becomes practical to train trackers with the ViT-g backbone on GPUs with only memory of 25.8GB (batch size of 16); 2) we reduce the training time of the L-224 variant from 35.0 to 10.8 GPU hours; 3) we improve the LaSOT SUC score from 0.703 to 0.742 with the L-224 variant; 4) we fast the inference speed of the L-224 variant from 52 to 119 FPS. Code and models are available at https://github.com/LitingLin/LoRAT.", "venue": "arXiv.org", "year": 2024, "citationCount": 2, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "LoRAT is proposed, a method that unveils the power of large ViT model for tracking within laboratory-level resources and designs an anchor-free head solely based on MLP to adapt PETR, enabling better performance with less computational overhead."}, "embedding": {"model": "specter_v2", "vector": [0.42705047130584717, 0.36438313126564026, -0.8507882952690125, 0.3302111327648163, -0.28108009696006775, -0.4485069811344147, 1.2991877794265747, -0.4764270484447479, -0.42187047004699707, -1.0982255935668945, 0.2387246936559677, 0.36173129081726074, 0.6526858806610107, 0.042800381779670715, -0.47355765104293823, 0.31594157218933105, -0.9229635000228882, 0.3157951831817627, 0.4669007956981659, -0.0031811287626624107, -0.4376901090145111, -0.2690499424934387, -0.8472701907157898, -0.1085268035531044, -0.1092364490032196, 0.8133820295333862, 0.4187999367713928, 1.1247479915618896, -0.03434903919696808, 0.2119716852903366, 0.2725571095943451, -0.24623651802539825, 0.348678857088089, -0.1283239871263504, 0.1600058525800705, -0.23476988077163696, 0.962482750415802, -0.2514721751213074, -0.5371000170707703, 0.7208585143089294, -0.15659992396831512, 0.23477433621883392, 0.45464494824409485, -0.8099258542060852, -0.5078340172767639, -0.05406522378325462, 0.15129902958869934, 0.7569243907928467, -0.4507834315299988, -0.5499053597450256, 0.8702870607376099, -0.9431585669517517, 0.4119722545146942, 1.4675178527832031, 0.8286363482475281, 0.28673410415649414, 0.14740295708179474, -0.6549267768859863, 0.7408455610275269, -0.24520280957221985, -0.7076629400253296, -0.39565035700798035, 0.002475663088262081, -0.2924349308013916, 1.2962342500686646, -0.917914867401123, 0.1429915875196457, 1.0229731798171997, -0.07667167484760284, 1.3897953033447266, -0.033795684576034546, -0.7919782400131226, -0.624526858329773, 0.32732248306274414, -0.08867739140987396, 0.8592107892036438, -0.21271051466464996, 0.6273132562637329, -0.9692999720573425, 0.2213163822889328, 0.904351532459259, -0.44682833552360535, 0.38387423753738403, -0.4604717791080475, -0.7718413472175598, 0.5693936944007874, 0.4890037775039673, 0.5712684988975525, 0.2093546986579895, 0.9676278233528137, 0.6195839047431946, 0.03729727491736412, -0.15401802957057953, -0.19217516481876373, 0.21130947768688202, 0.478250116109848, -0.9438108205795288, -0.2391747534275055, -0.3154773712158203, 1.2116729021072388, -0.44553056359291077, 0.1965818554162979, -0.6944493055343628, -0.06669583916664124, 1.546746850013733, 0.5277496576309204, 0.2357339709997177, -0.757737398147583, 0.018547900021076202, -1.0814387798309326, 0.29006198048591614, -0.5359543561935425, 0.038270555436611176, -0.7570874094963074, -0.570895254611969, -0.7066707015037537, 0.13779252767562866, 0.628667950630188, -0.9097453355789185, 0.5322779417037964, -0.16520000994205475, 0.44319087266921997, -0.22713667154312134, 0.3281055986881256, 0.3485654294490814, 0.37877488136291504, 0.36854806542396545, 0.4427526891231537, 1.4788062572479248, -1.0807831287384033, -0.8260740637779236, -1.001888394355774, 0.22760529816150665, -0.4270983338356018, 0.2336963713169098, -0.05042795464396477, -1.1782500743865967, -1.3065170049667358, -1.0964051485061646, -0.027612626552581787, -0.6705570220947266, 0.7614356279373169, 1.1230145692825317, 0.7297084331512451, -0.945496678352356, 0.34812140464782715, -0.5366136431694031, -0.601477861404419, 0.708251416683197, 0.012896341271698475, 0.2471817433834076, 0.06622298806905746, -0.952448308467865, 0.5452139377593994, 0.18121537566184998, -0.42795586585998535, -0.3529340624809265, -0.34069254994392395, -0.9657655954360962, -0.18694688379764557, 0.3158170282840729, -0.513799786567688, 1.062413215637207, 0.1233430802822113, -1.3737943172454834, 0.8918792009353638, -0.6190916895866394, 0.04389728233218193, 0.44357749819755554, -0.19421324133872986, -0.5263036489486694, -0.6961963772773743, -0.43088600039482117, 0.6590412259101868, 1.0728437900543213, -0.0031379491556435823, -0.3225746750831604, 0.1599990576505661, -0.43833309412002563, -0.17006555199623108, -0.1396080106496811, 1.1509976387023926, -0.9792612195014954, -0.08058440685272217, 0.16338713467121124, 0.582808792591095, 0.3673563003540039, 0.11135795712471008, 0.37346726655960083, -1.298424482345581, 1.125582218170166, 0.30728405714035034, 0.3734041154384613, -0.6565659046173096, -0.87856525182724, -0.11598824709653854, -0.10088574141263962, 0.06746581196784973, -0.7752853035926819, 0.20254018902778625, 0.010231777094304562, 0.01361346710473299, 0.7375640273094177, -1.0866860151290894, 0.2908408045768738, -0.6650348901748657, -0.608381986618042, 0.444011390209198, 0.18181081116199493, 1.480536699295044, -0.9637274146080017, -0.16499729454517365, 0.015040750615298748, 0.44501182436943054, -1.030315637588501, 1.1969596147537231, -0.6141719818115234, 0.41569843888282776, -0.11775153130292892, -0.018070373684167862, -0.24541151523590088, -0.6724231839179993, 0.335332989692688, -0.4638991951942444, -0.055257633328437805, 0.4641864597797394, -0.5051003694534302, 1.483199954032898, -0.317221999168396, 0.7901275157928467, -0.12098956853151321, -0.49515020847320557, 0.523626983165741, 0.2555076479911804, -0.33229202032089233, -0.6488660573959351, 0.5237681865692139, 0.13319382071495056, -0.8268214464187622, 0.5709969997406006, 0.5048883557319641, 1.3251643180847168, -0.01378085371106863, -0.15275050699710846, 0.6110062599182129, 0.11073168367147446, -0.013706793077290058, 0.4157393276691437, 0.2988796532154083, 0.8528001308441162, 0.004501561168581247, 0.10345140844583511, 0.08533165603876114, -0.8396797776222229, -0.07128169387578964, 1.0657728910446167, 0.23142723739147186, 0.7554201483726501, 0.16065461933612823, -0.5810306072235107, -0.7062870264053345, -0.25066423416137695, 0.28225210309028625, 1.3983154296875, 0.10675428062677383, -0.27280282974243164, -0.5513578653335571, -0.062461525201797485, -0.5203312635421753, -0.7610558867454529, -0.547728955745697, 0.1653272658586502, -0.7863308191299438, -0.6239740252494812, 1.056854486465454, 0.13331855833530426, 1.0265635251998901, -0.5652347207069397, -0.41081008315086365, -0.26200172305107117, 0.2544647455215454, -1.2002160549163818, -0.7321811318397522, -0.16901208460330963, -0.2248106300830841, 0.13190865516662598, -0.1341475546360016, -0.30600401759147644, -0.3933716416358948, -0.7599806785583496, 0.4862264096736908, -0.46148747205734253, -0.26823362708091736, 0.41846129298210144, 0.5635445713996887, -0.9040024280548096, -0.5629148483276367, 0.3380449712276459, 0.21972166001796722, -0.048038266599178314, 0.2309112250804901, 0.6761707663536072, 0.29435455799102783, 0.23607756197452545, 0.1285843402147293, -0.13358353078365326, 0.1369539350271225, -0.15347374975681305, 0.8239591121673584, -0.7284162044525146, -0.06426829099655151, -0.7546706795692444, 0.3816925585269928, 0.3983137309551239, -0.9989338517189026, 0.1479090452194214, -0.5072982907295227, -0.39362433552742004, 0.15279023349285126, -0.8480600714683533, -0.1956424117088318, -0.5224252343177795, 0.22371776401996613, -0.7834820747375488, -0.2664102017879486, -0.6154534220695496, 0.4314674735069275, -0.15137389302253723, 0.5185995697975159, 0.4220874011516571, 0.3550436794757843, -0.2961614727973938, 0.6144185066223145, -1.1107879877090454, 1.2762084007263184, 0.05409747362136841, 0.6936063170433044, 0.3562350571155548, 0.12796145677566528, -0.5989471077919006, -0.5673702955245972, -0.7732535600662231, -0.7057469487190247, -0.6650845408439636, 0.3557731807231903, -0.8838983178138733, -0.9968538880348206, 0.2186746597290039, -1.1360085010528564, -0.307496041059494, 0.5730208158493042, 0.22186173498630524, -0.5079326629638672, -1.0019158124923706, -0.8273066282272339, -0.3670365512371063, -0.45631125569343567, -1.046769618988037, 0.3487389385700226, 0.2643199861049652, -0.19026342034339905, -0.4171442687511444, 0.49199745059013367, -0.45133212208747864, 0.9537577033042908, -0.273198664188385, 0.016717785969376564, 0.23084449768066406, -0.8494766354560852, -0.32938602566719055, 0.09762208163738251, -0.07039588689804077, -0.51581871509552, 0.3818678557872772, -1.3120546340942383, -0.00782703422009945, -0.7410133481025696, -0.09224428981542587, 0.3396972119808197, 0.3907311260700226, 0.48178592324256897, 0.3722519874572754, -0.7935059070587158, 0.980577826499939, 1.1618022918701172, -0.5341761708259583, 0.2719782888889313, 0.7208889126777649, 1.0651010274887085, -0.135232076048851, -0.06852762401103973, 0.33206284046173096, 0.2428143471479416, 0.7939062118530273, 0.2234799563884735, -0.08954324573278427, -0.8350296020507812, -0.9987908005714417, 0.9061279892921448, 0.9773176908493042, 0.2192956507205963, 0.030113158747553825, -0.6798778772354126, 0.8708556890487671, -1.0169531106948853, -0.9030764102935791, 0.523706316947937, 0.8089578151702881, -0.09870404005050659, -0.19034415483474731, 0.19635434448719025, -1.0664422512054443, 0.6567369103431702, 0.42943471670150757, -0.15389269590377808, -0.45689356327056885, 0.08603285253047943, 0.23928314447402954, 0.22555512189865112, 0.5320862531661987, -0.6587815880775452, 0.8751320838928223, 14.604469299316406, 0.9958308935165405, -0.01935425214469433, 0.6467798352241516, 0.08609966933727264, 0.497344046831131, 0.07713792473077774, -0.157191663980484, -1.7010222673416138, -0.27620524168014526, 1.3354434967041016, 0.611527144908905, 0.5626699924468994, 0.3747375011444092, -0.12597428262233734, 0.6833898425102234, -0.5656313300132751, 0.9081739187240601, 0.6973803043365479, -1.7320048809051514, 0.05131053552031517, 0.1719609946012497, 0.21656154096126556, 1.0386252403259277, 0.9864032864570618, 0.7748644948005676, 0.43792393803596497, -0.3820876479148865, 0.8730730414390564, 0.18759799003601074, 0.949974775314331, 0.3005478084087372, -0.019661104306578636, 0.2687627673149109, -1.3519785404205322, 0.35785526037216187, -0.7505737543106079, -0.8038380742073059, 0.11327560991048813, -0.38210687041282654, -0.4828222095966339, -0.45135435461997986, 0.35106074810028076, 0.9429639577865601, 0.02525351755321026, 0.8034009337425232, -0.2117607444524765, 0.49019044637680054, -0.29838860034942627, -0.043252311646938324, 0.49684879183769226, 0.459110826253891, 0.29098764061927795, 0.4900345802307129, -0.2594600021839142, -0.3566931188106537, 0.061139024794101715, 0.6729440689086914, -0.672787070274353, -0.5230017304420471, -0.432468056678772, 0.023475361987948418, 0.29852497577667236, 1.0345027446746826, 0.23324242234230042, 0.1688537746667862, -0.30016639828681946, 0.23770205676555634, 0.7605682015419006, 0.0021981829777359962, -0.6596865057945251, 0.12487594038248062, 0.5218276381492615, -0.5613201260566711, 0.5150943994522095, 0.28207647800445557, 0.1062430739402771, -0.757249116897583, -0.5119574666023254, -0.17378763854503632, 0.2676432728767395, -0.8626129031181335, -0.47053784132003784, 0.7529116272926331, -0.3550257682800293, -0.4175257086753845, 0.17713479697704315, -0.7962145209312439, -0.42058682441711426, 0.36310771107673645, -1.7875847816467285, -1.2383559942245483, 0.14961452782154083, 0.13282953202724457, -0.29685795307159424, -0.059268657118082047, 0.7633533477783203, 0.13161106407642365, -0.2141464203596115, 0.595457136631012, 0.11617694050073624, 0.533388078212738, 0.27907848358154297, -0.3561267554759979, 1.091362714767456, 0.5202718377113342, 0.18414366245269775, 0.17710387706756592, -0.03369481861591339, 0.2736890912055969, -0.8762431740760803, -0.13275311887264252, 0.367379367351532, -1.5185130834579468, -0.07667317986488342, -1.0490727424621582, -0.7433866858482361, 0.8427579998970032, 0.5563023686408997, 0.11518846452236176, -0.5369239449501038, 0.26633957028388977, -1.001399040222168, -0.055166635662317276, -0.530032753944397, -0.15366549789905548, 0.32656610012054443, -0.87043297290802, -0.41468656063079834, -0.24285729229450226, 0.3609029948711395, -1.2768012285232544, -0.8252462148666382, -0.43200984597206116, 0.5939746499061584, 0.19109730422496796, 1.3660197257995605, 0.1114368885755539, -0.2906743884086609, 0.3865502178668976, 0.21421922743320465, -0.5075502991676331, -0.27809375524520874, -0.8876691460609436, -0.21362218260765076, 0.21785883605480194, 0.1935894787311554, -0.3003169894218445, 0.3292563855648041, -0.06188127025961876, 0.5239282250404358, 0.15093833208084106, -0.37955257296562195, -0.9165458083152771, 0.16819366812705994, -0.5270957946777344, 0.08980956673622131, 0.030010489746928215, -0.2559223175048828, 0.0703844279050827, 0.10816191881895065, 1.0942758321762085, 0.592934250831604, -0.7594875693321228, 0.7163786888122559, -0.2792936861515045, -0.31912368535995483, -0.3979180157184601, -0.7578493356704712, -1.646201729774475, -0.25875410437583923, -1.1942776441574097, -0.1538235992193222, -0.639690637588501, -0.6391719579696655, -0.387337327003479, -0.16439366340637207, -0.06168055906891823, 0.6546922326087952, -0.12832438945770264, 0.12916359305381775, -0.12844416499137878, -0.7819226980209351, 0.6778787970542908, 1.0142621994018555, -0.850017249584198, 0.24247175455093384, 0.0919894352555275, 0.5514627695083618, 0.5528610348701477, 0.18241724371910095, -0.6657773852348328, -0.32484912872314453, -1.2870930433273315, 0.32757681608200073, -0.21326844394207, 0.23112644255161285, -1.0345929861068726, 0.9419894814491272, 0.8134384155273438, 0.3024481534957886, -0.24193818867206573, 0.4401598870754242, -0.6209895014762878, -0.4810737371444702, 0.1764417141675949, -0.5288392305374146, 0.12301532924175262, 0.4605981707572937, -0.3966061770915985, 0.3349708020687103, 0.8669907450675964, 0.17412126064300537, -0.6924735903739929, -1.1590873003005981, 0.3761836290359497, -0.3615919351577759, 0.10880695283412933, -0.6047971844673157, -0.17253364622592926, -1.3333262205123901, -0.24180340766906738, -0.012138075195252895, 0.21364180743694305, -0.3354533910751343, 1.451433777809143, 0.36322060227394104, -1.0417289733886719, -0.07077383995056152, 0.23557458817958832, 0.11400162428617477, -0.1280525177717209, 0.03898987919092178, 0.5478855967521667, 0.017900163307785988, 0.7077674865722656, -0.16707579791545868, -0.22360175848007202, -0.7059307098388672, 0.17754846811294556, 0.815521240234375, -0.40358009934425354, -0.5371585488319397, 0.8818262815475464, -0.17042283713817596, -1.0246965885162354, 0.4776291847229004, -0.8426882028579712, -0.4788745641708374, -0.30195650458335876, 0.8786424994468689, -0.017068857327103615, -0.0746970847249031, -0.1933676302433014, -0.6875476241111755, 0.5639433264732361, -0.2940460741519928, -0.3348615765571594, 0.07647594064474106, -0.15715532004833221, 0.05520586669445038, 0.4240680932998657, 0.8091797828674316, -0.6113985180854797, -1.1563242673873901, -1.0265040397644043, -0.605189859867096, 0.006140352226793766, 0.294958233833313, -0.43359604477882385, -0.49050837755203247, 0.6971506476402283, 1.0157592296600342, -0.3605195879936218, -0.43767133355140686, 0.41113483905792236, 0.034060630947351456, 0.7851004600524902, 0.05862421542406082, -0.3843086063861847, -0.5965813994407654, 1.2100378274917603, 0.5059216022491455, -0.6948851346969604, 0.0863553062081337, -0.0425216481089592, -0.3033139407634735, 0.489666223526001, 0.4259769320487976, -0.2894038259983063, 0.2918214797973633, -0.297335147857666, 0.22479131817817688, 0.215045765042305, -0.6089897155761719, -0.39129313826560974, 0.9186346530914307, 1.3021321296691895, 0.25768405199050903, 0.06594208627939224, 0.7534686326980591, 0.11446822434663773, 0.28514912724494934, 0.06742381304502487, 0.29732829332351685, 0.17555169761180878, -0.26619279384613037, -0.1359422206878662, -0.6983559131622314, 0.5053897500038147, -0.6038936972618103, -0.19539515674114227, 0.3845032751560211, 0.8069775104522705, -0.0162610225379467, 0.16831578314304352, 1.0154896974563599, 0.4866246283054352, 0.667674720287323, -0.0566166453063488, 1.0176546573638916, 0.03452080115675926, -0.2554480731487274, 0.1934969276189804, -1.0403988361358643, -0.291342556476593, -0.4970438480377197, -0.9972138404846191, -0.12355587631464005, -0.2506738603115082, 0.3710145652294159, -0.4347129464149475, 0.1729007363319397, 1.0412191152572632, 0.3663865923881531, 0.6832626461982727, -0.8962710499763489, -0.8344097137451172, 0.06557027995586395, -0.5962463021278381, 0.43115395307540894, -0.5208779573440552, 0.3577826917171478, -0.7074925303459167, 0.20373103022575378, -0.036229610443115234]}, "authors": [{"authorId": "2110865252", "name": "Liting Lin"}, {"authorId": "2290669628", "name": "Heng Fan"}, {"authorId": "2290126457", "name": "Zhipeng Zhang"}, {"authorId": "2290858069", "name": "Yaowei Wang"}, {"authorId": "2269748476", "name": "Yong Xu"}, {"authorId": "2269244565", "name": "Haibin Ling"}], "references": [{"paperId": "241eefc1bb11e693e0fef6977a65a0a822fb8f5e", "title": "LoRA+: Efficient Low Rank Adaptation of Large Models"}, {"paperId": "fcf804ee3f5ce603290e919c91010be5c77b1c0d", "title": "CiteTracker: Correlating Image and Text for Visual Tracking"}, {"paperId": "b4e8984c1d1066adf99f7878345bcfd35dfda88b", "title": "Robust Object Modeling for Visual Tracking"}, {"paperId": "6b8ec9495aa8cb94c6748c5ceae0c94bb1bcf908", "title": "Autoregressive Visual Tracking"}, {"paperId": "cbeee2f7f03acb575f250e7b1857ceb775db98ec", "title": "SeqTrack: Sequence to Sequence Learning for Visual Object Tracking"}, {"paperId": "5a9cb1b3dc4655218b3deeaf4a2417a9a8cd0891", "title": "DINOv2: Learning Robust Visual Features without Supervision"}, {"paperId": "4569040e52aabdc92213d0687eafba0c73c1afdc", "title": "DropMAE: Masked Autoencoders with Spatial-Attention Dropout for Tracking Tasks"}, {"paperId": "5b959cf1e226e19647d2fd2bcb7f65d43e68dbe5", "title": "Generalized Relation Modeling for Transformer Tracking"}, {"paperId": "6007263dd3d14373be5f84fb6ccb0be3f7fce903", "title": "Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning"}, {"paperId": "3049c992adbd56e29c4d957ee0c4e9d05fe3c6d1", "title": "EVA-02: A Visual Representation for Neon Genesis"}, {"paperId": "b612fc6af23cccf2133c2ea40597453ab40dc2c3", "title": "AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning"}, {"paperId": "58842cdca3ea68f7b9e638b288fc247a6f26dafc", "title": "T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models"}, {"paperId": "efbe97d20c4ffe356e8826c01dc550bacc405add", "title": "Adding Conditional Control to Text-to-Image Diffusion Models"}, {"paperId": "827f07e79dad0c1c77c68fa69bc4f098634d3d58", "title": "AiATrack: Attention in Attention for Transformer Visual Tracking"}, {"paperId": "a32887af7eb1fcfd3b3d892ad41f3516a37f11c1", "title": "Tip-Adapter: Training-free Adaption of CLIP for Few-shot Classification"}, {"paperId": "a8fd9c1625011741f74401ff9bdc1c584e25c86d", "title": "Language Models are General-Purpose Interfaces"}, {"paperId": "7cdaa08890895e1ad92afb5fad429690ad7b1dac", "title": "Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning"}, {"paperId": "d2f63b56fc6bc373f5c023454c2b253326962865", "title": "DeiT III: Revenge of the ViT"}, {"paperId": "adb272fbdea3631059cf88ab764bb6c2ce29f965", "title": "Visual Prompt Tuning"}, {"paperId": "c1329f91cfa11011712227c8765fbbe38b9f2b7e", "title": "Joint Feature Learning and Relation Modeling for Tracking: A One-Stream Framework"}, {"paperId": "b6eaec7917439d79ce840fa97bc371552e9b6685", "title": "MixFormer: End-to-End Tracking with Iterative Mixed Attention"}, {"paperId": "8c62277dada489904a63de4dd87336c27c68fb5e", "title": "Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models"}, {"paperId": "04ea6fc31a1196264a15fa9912b1ff06d6f70220", "title": "Backbone is All Your Need: A Simplified Architecture for Visual Object Tracking"}, {"paperId": "0fced9da4d992771c5575081778ff5a13afbbb51", "title": "Correlation-Aware Deep Tracking"}, {"paperId": "2327ce0d6163360bcad09e5c10cab0fd7b54fa77", "title": "Learning Target-aware Representation for Visual Tracking via Informative Interactions"}, {"paperId": "53c3940f35b8b45d55ed49056282e1961954513d", "title": "Self-attention Does Not Need $O(n^2)$ Memory"}, {"paperId": "91a4cbae6553e975ddc3b2f6850ed725ff475307", "title": "SwinTrack: A Simple and Strong Baseline for Transformer Tracking"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "da666d5c6cbc4234fbf0e581284cdca30b719db9", "title": "Learn to Match: Automatic Matching Network Design for Visual Tracking"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "72af9b2e03d3668e09edd0ec413b0b20cbce8f9c", "title": "Learning Spatio-Temporal Transformer for Visual Tracking"}, {"paperId": "8b8ea4bb311f4a46cb654bc4d34cb07f49ed45ca", "title": "Towards More Flexible and Accurate Object Tracking with Natural Language: Algorithms and Benchmark"}, {"paperId": "fb058786bbcb2cead98a3ef55b33d2b73b2119fc", "title": "Learning Target Candidate Association to Keep Track of What Not to Track"}, {"paperId": "7c3ce1b3ad598a282546e03e2dc8b52c338caed6", "title": "Transformer Tracking"}, {"paperId": "75284d5e4dfe1cd8a9ce69085210319e14fcfa3d", "title": "Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking"}, {"paperId": "bc37c6bdb8f39929a58b30464f72d6aa46cddc17", "title": "GPT Understands, Too"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "e284bc13c2b76d0d0c7ad61d976f8a9d3eef8461", "title": "LaSOT: A High-quality Large-scale Single Object Tracking Benchmark"}, {"paperId": "14c3510e4f4b370d5cd0420037406024533f4b6f", "title": "VarifocalNet: An IoU-aware Dense Object Detector"}, {"paperId": "27d52bf3265bea0f9929980f6ffb4c2009eecfee", "title": "Ocean: Object-aware Anchor-free Tracking"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "98ef0db84e62aef969629264c9de1f4d0013f3b9", "title": "AdapterFusion: Non-Destructive Task Composition for Transfer Learning"}, {"paperId": "1187c70c4011f935642084e84186284ac0add3d0", "title": "Exploring Versatile Generative Language Model Via Parameter-Efficient Transfer Learning"}, {"paperId": "6b6d31b022b7984a25fa9ee7fef64086ce7c464d", "title": "Probabilistic Regression for Visual Tracking"}, {"paperId": "2c8315ae713b3e27c6e9f291a158134d9c516166", "title": "Learning Discriminative Model Prediction for Tracking"}, {"paperId": "e2751a898867ce6687e08a5cc7bdb562e999b841", "title": "FCOS: Fully Convolutional One-Stage Object Detection"}, {"paperId": "889c81b4d7b7ed43a3f69f880ea60b0572e02e27", "title": "Generalized Intersection Over Union: A Metric and a Loss for Bounding Box Regression"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "d1a4135a2edd1af8a1e501109bbf7c2c720f10f8", "title": "SiamRPN++: Evolution of Siamese Visual Tracking With Very Deep Networks"}, {"paperId": "f98be9a91dbf00b52a494720bd36be9c73a1210e", "title": "Siamese Cascaded Region Proposal Networks for Real-Time Visual Tracking"}, {"paperId": "9eb3584dc1193ea9192be8df6a3b57aebd3b8548", "title": "GOT-10k: A Large High-Diversity Benchmark for Generic Object Tracking in the Wild"}, {"paperId": "900ab48d25b44c076e31224b7befa503d9550c53", "title": "LaSOT: A High-Quality Benchmark for Large-Scale Single Object Tracking"}, {"paperId": "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b", "title": "TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "7379455504274d7ff46a37bb4a0ccf81b60df86f", "title": "L2 Regularization versus Batch and Weight Normalization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "703505a00579c0aa67712836acc41d94fa6d6edc", "title": "Need for Speed: A Benchmark for Higher Frame Rate Object Tracking"}, {"paperId": "a87cc499cf101b3697cacc65094b4b6590e0d061", "title": "ECO: Efficient Convolution Operators for Tracking"}, {"paperId": "27850781e39df9f750e05409b8072261124068e8", "title": "A Benchmark and Simulator for UAV Tracking"}, {"paperId": "29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "title": "Fully-Convolutional Siamese Networks for Object Tracking"}, {"paperId": "d0156126edbfc524c8d108bdc0cf811cfe3129aa", "title": "FractalNet: Ultra-Deep Neural Networks without Residuals"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "c4c45661501c16064eead6e5d37dcb80d41c7a78", "title": "Object Tracking Benchmark"}, {"paperId": "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac", "title": "A Novel Performance Evaluation Methodology for Single-Target Trackers"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "0407b605b8f55db72e2545586bfe8e946b691b70", "title": "An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks"}, {"paperId": "ec936b808e0fab9281c050ad4010cddec92c8cbe", "title": "P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "65c9b4b1d49f46b3f8f64a5f617acfc14f85d031", "title": "Ieee Transactions on Pattern Analysis and Machine Intelligence High-speed Tracking with Kernelized Correlation Filters"}, {"paperId": null, "title": "QLoRA: Efficient fine-tuning of quantized llms"}, {"paperId": null, "title": "LLaMA-adapter: Efficient fine-tuning of large language models with zero-initialized attention"}]}