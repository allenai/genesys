{"paperId": "8d1187eebe9e1d5631f30629d5bf0c3988e6e3da", "title": "Is BERT Blind? Exploring the Effect of Vision-and-Language Pretraining on Visual Language Understanding", "abstract": "Most humans use visual imagination to understand and reason about language, but models such as BERT reason about language using knowledge acquired during text-only pretraining. In this work, we investigate whether vision-and-language pretraining can improve performance on text-only tasks that involve implicit visual reasoning, focusing primarily on zero-shot probing methods. We propose a suite of visual language understanding (VLU) tasks for probing the visual reasoning abilities of text encoder models, as well as various non-visual natural language understanding (NLU) tasks for comparison. We also contribute a novel zero-shot knowledge probing method, Stroop probing, for applying models such as CLIP to text-only tasks without needing a prediction head such as the masked language modelling head of models like BERT. We show that SOTA multimodally trained text encoders outperform unimodally trained text encoders on the VLU tasks while being under-performed by them on the NLU tasks, lending new context to previously mixed results regarding the NLU capabilities of multimodal models. We conclude that exposure to images during pretraining affords inherent visual reasoning knowledge that is reflected in language-only tasks that require implicit visual reasoning. Our findings bear importance in the broader context of multimodal learning, providing principled guidelines for the choice of text encoders used in such contexts11Our code will be made available at https://isbertblind.github.io/.", "venue": "Computer Vision and Pattern Recognition", "year": 2023, "citationCount": 11, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2303.12513", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "It is concluded that exposure to images during pretraining affords inherent visual reasoning knowledge that is reflected in language-only tasks that require implicit visual reasoning, providing principled guidelines for the choice of text encoders used in such contexts."}, "embedding": {"model": "specter_v2", "vector": [0.38702836632728577, 0.8621745109558105, 0.003287035273388028, -0.1720753163099289, -0.11182370781898499, 0.03716529905796051, 0.6757115125656128, -0.164211705327034, -0.5391164422035217, -0.7601479291915894, 0.4507441818714142, -0.40326371788978577, 0.19814419746398926, -0.041767850518226624, -0.032814715057611465, 0.14755496382713318, -0.7915776968002319, 0.15423110127449036, -0.024557797238230705, -0.562265157699585, 0.024341735988855362, -1.022019624710083, -1.0704705715179443, 0.6239974498748779, 0.028049087151885033, 0.32876482605934143, 0.4455115497112274, 1.525459885597229, -0.06188412383198738, 0.8871580362319946, 0.5224747061729431, -0.468990683555603, -0.03351930156350136, 0.18900877237319946, -0.5461588501930237, 0.025309663265943527, 0.4818289279937744, -0.823522686958313, -0.8406416177749634, 0.6228736042976379, -0.13904206454753876, 0.13282467424869537, 0.6057922840118408, -0.4427701532840729, -0.7735934257507324, 0.5160331130027771, 0.5136004090309143, 0.7897303104400635, 0.15842314064502716, -0.260365754365921, 1.3294641971588135, -1.4096519947052002, 0.4441657066345215, 1.6316889524459839, 0.2605040371417999, 0.6063129901885986, 0.28630805015563965, -0.37984567880630493, 0.623417854309082, 0.23313340544700623, -0.6699016094207764, -0.37063297629356384, -0.36846500635147095, -0.2751806676387787, 1.3290514945983887, -0.6442297697067261, -0.10196930915117264, 0.6150020956993103, 0.3118042051792145, 1.6937823295593262, 0.12699128687381744, -1.1567771434783936, -0.335460364818573, 0.47617635130882263, 0.3325191140174866, 1.1863555908203125, -0.7112849354743958, 0.5463038682937622, -1.0034422874450684, 0.527920126914978, 0.5440963506698608, -0.2259361892938614, -0.7550280690193176, -0.2852710485458374, -0.8942177295684814, 0.5679954290390015, 0.6313651204109192, 0.6191263198852539, 0.21232375502586365, 0.3455008268356323, 0.4863364100456238, 0.7237086892127991, -0.3948332667350769, 0.08267107605934143, 0.13723674416542053, 0.5875647664070129, -0.9524591565132141, -0.054111238569021225, 0.014659009873867035, 0.9723653793334961, -0.20003147423267365, 0.10124795138835907, -1.0198249816894531, -0.018274592235684395, 1.6050176620483398, -0.17348362505435944, 0.5145702362060547, -0.5472073554992676, 0.39658451080322266, -0.9722151756286621, 0.37345650792121887, -0.8565431833267212, -0.3280457854270935, -0.04076462239027023, -0.29482096433639526, -0.9308093190193176, 0.010646405629813671, 0.07320713996887207, -1.5223644971847534, 0.83058762550354, -0.3743409216403961, -0.2874898612499237, 0.1088569313287735, 0.8443343639373779, 1.0937025547027588, 0.5468318462371826, 0.47478213906288147, 0.4782628118991852, 1.5482158660888672, -0.4789353907108307, -0.7163909077644348, -1.0353978872299194, 0.40275508165359497, -0.12959852814674377, 0.8773902058601379, 0.037467196583747864, -1.0376397371292114, -1.3164750337600708, -1.2277530431747437, -0.539417564868927, -0.720511257648468, 0.5030463933944702, 1.1099395751953125, 0.7354366183280945, -1.423887014389038, 0.5979770421981812, 0.21468348801136017, -0.6855396032333374, 0.4031459391117096, -0.030269982293248177, 0.12875521183013916, -0.7236735820770264, -1.1248884201049805, 0.5760159492492676, 0.16838686168193817, -0.45211201906204224, -0.5855135321617126, -0.036380428820848465, -1.7155048847198486, -0.279057115316391, 0.45950499176979065, -0.6375041007995605, 1.1255590915679932, -0.5143595337867737, -0.9627177715301514, 1.2613416910171509, -0.7656322717666626, 0.3237297534942627, 0.30515342950820923, -0.46510186791419983, -0.6470486521720886, 0.3853510618209839, -0.12500399351119995, 1.153075933456421, 0.516838788986206, -0.8336833119392395, 0.1247849240899086, 0.05929023399949074, -0.10815253853797913, -0.06642857193946838, -0.04140381142497063, 0.724357008934021, -0.47769129276275635, -0.49173396825790405, 0.42432087659835815, 0.9482323527336121, 0.5463125705718994, 0.25348106026649475, -0.11613921821117401, -0.8397906422615051, 0.4786982834339142, -0.48717010021209717, 0.40877053141593933, -0.9900730848312378, -0.5329902172088623, -0.464128702878952, 0.2642892897129059, -0.33144357800483704, -1.0762661695480347, 0.528844952583313, -0.24577930569648743, 0.502298891544342, -0.3711206912994385, -1.2386037111282349, 0.10745247453451157, -0.24790839850902557, -0.8981308341026306, -0.20368385314941406, 0.21546898782253265, 1.5226585865020752, -0.8938462734222412, -0.29779794812202454, 0.1321355551481247, 0.2535388469696045, -0.5757342576980591, 1.033801555633545, -0.5588895082473755, 0.2421334683895111, 0.1776207536458969, -0.17308348417282104, 0.18398964405059814, -0.5054140686988831, -0.08581807464361191, -0.6104297041893005, 0.17444513738155365, -0.0638546273112297, 0.04533417895436287, 1.5492181777954102, -0.17868901789188385, 1.4783594608306885, -0.3555738627910614, -0.7296683192253113, -0.21521201729774475, 0.6535604596138, -0.6083540320396423, -0.3945785164833069, 0.6537548899650574, -0.3557572364807129, -0.4204918146133423, -0.3499247133731842, 0.2945086658000946, 0.5405410528182983, 0.08866691589355469, 0.1723843365907669, 0.33863431215286255, -0.44221970438957214, 0.09230266511440277, 0.5987915396690369, 0.370787113904953, 0.38570716977119446, 0.1590217500925064, 0.03176910802721977, 0.2951706647872925, -0.774816632270813, -0.7109257578849792, 0.9258235692977905, 0.6197814345359802, 1.0773359537124634, 0.40600699186325073, -0.8215759992599487, -0.30109328031539917, -0.5416120290756226, 0.40466633439064026, 1.6453667879104614, 0.2626135051250458, -0.18056191504001617, -0.7167644500732422, 0.00012890962534584105, -0.5965842604637146, 0.5351769924163818, -0.9235659837722778, -0.21463589370250702, 0.06289790570735931, -0.40963178873062134, 0.35265299677848816, 0.4249916076660156, 1.5244125127792358, -0.8553065657615662, -0.35246193408966064, -0.740252673625946, 0.5638193488121033, -1.0177266597747803, -0.5661789774894714, -0.29980334639549255, -0.1259571760892868, -0.3948453962802887, -0.5929123759269714, -0.5856176614761353, 0.5568816661834717, -0.37609076499938965, 0.7360097765922546, -0.19292806088924408, -0.4749983251094818, 0.9147423505783081, 0.3812650144100189, -0.49813711643218994, -0.5817006826400757, -0.4054395854473114, -0.39694535732269287, -0.11250726878643036, 0.4382028877735138, 0.8779357671737671, 0.10624565929174423, 0.28215137124061584, -0.5000945329666138, 0.6532353758811951, 0.5826212167739868, -0.30712559819221497, 0.17625315487384796, -0.19703969359397888, -0.01586848683655262, -0.6743336915969849, 0.5045104026794434, 0.2387717068195343, -0.06110749393701553, 0.5179680585861206, -0.17765352129936218, -0.4806661605834961, 0.0466652438044548, -0.8199590444564819, -0.6712265014648438, -0.9056814312934875, 0.5877761840820312, -0.14630310237407684, -0.3436574339866638, 0.36260196566581726, 0.3313386142253876, -0.14269748330116272, 0.35168370604515076, 0.42450636625289917, 0.4718886911869049, 0.45425930619239807, 0.6317905783653259, -0.8500955104827881, 0.651664137840271, 0.4065955579280853, 0.43813055753707886, 0.28495949506759644, -0.3953736424446106, -1.022769808769226, -0.8457792401313782, -0.12795422971248627, -0.38253846764564514, -0.721623957157135, 1.0302705764770508, -0.6340317726135254, -1.056609034538269, -0.07142285257577896, -0.9903894066810608, -0.6829890012741089, 0.3132205605506897, -0.41524365544319153, -0.3387834429740906, -0.6339641213417053, -0.8486713767051697, -0.5916771292686462, 0.003153845202177763, -0.7325958609580994, 0.2269294112920761, 0.07675996422767639, -0.5814911723136902, -0.395411878824234, -0.2964358329772949, 0.1144103929400444, 0.6207531094551086, -0.5430951714515686, 0.9569839239120483, 0.3097359240055084, -0.4615319073200226, -0.08189563453197479, -0.28406837582588196, 0.3375934660434723, -0.3475610315799713, -0.03654514253139496, -0.8873003125190735, -0.06242739409208298, -0.033419981598854065, -0.5240154266357422, 0.5636710524559021, 0.13935570418834686, 0.6919127106666565, 0.3085915446281433, -0.3719777464866638, 0.21403023600578308, 1.3318816423416138, -0.5293622016906738, 0.26443544030189514, -0.35450655221939087, 1.0123193264007568, 0.813132643699646, -0.25532177090644836, 0.25807929039001465, 0.9545795917510986, -0.0472380593419075, -0.1478848159313202, 0.077755868434906, -0.4586375057697296, -0.6319678425788879, 0.8516918420791626, 0.8932285308837891, 0.18156211078166962, -0.005575456190854311, -1.631528615951538, 0.9251616597175598, -0.9653071165084839, -0.35065075755119324, 0.7829520106315613, 0.8853181600570679, 0.2924399971961975, -0.31120461225509644, -0.6254660487174988, -0.3441649377346039, 0.5224077105522156, 0.2826484739780426, -0.282252699136734, -0.3966924548149109, 0.03833622485399246, 0.3307327628135681, -0.11462553590536118, 0.8856677412986755, -0.5832527279853821, 0.533233642578125, 14.36655330657959, 0.1960335671901703, 0.14564163982868195, 0.4202054738998413, 0.5714630484580994, 0.5722522139549255, -0.5106651186943054, -0.22464407980442047, -0.7365512251853943, -0.7876511216163635, 0.6668204069137573, 0.5541052222251892, 0.7079092264175415, -0.27396532893180847, -0.2078072875738144, -0.29562991857528687, -0.5854390859603882, 0.782360315322876, 1.0437626838684082, -0.7231441736221313, 0.6309265494346619, -0.04827605187892914, -0.12430489808320999, 0.16967037320137024, 1.1080619096755981, 0.793552815914154, -0.05107545107603073, -0.6764075756072998, 0.52120041847229, 0.23625275492668152, 1.0440388917922974, 0.21695375442504883, 0.13558775186538696, 0.7222486734390259, -0.7761789560317993, -0.36647242307662964, -0.35746192932128906, -0.9992402195930481, 0.21970915794372559, -0.5549363493919373, -0.38560178875923157, -0.6494136452674866, -0.19810788333415985, 0.36060386896133423, -0.2753327190876007, 0.18853680789470673, -0.4497548043727875, 0.467468798160553, 0.429316908121109, -0.2475580871105194, 0.03916828706860542, 1.0288105010986328, 0.49567732214927673, -0.11834418773651123, -0.15024709701538086, 0.40115106105804443, -0.11355955898761749, 0.5933824777603149, -0.2337397187948227, -0.07580864429473877, -0.3785770535469055, -0.3732197880744934, -0.6907210350036621, 0.21765021979808807, 0.05532427504658699, 0.20819883048534393, -0.5766915678977966, 0.41169631481170654, 0.28501084446907043, 0.4872422516345978, -0.013029119931161404, -0.19570671021938324, -0.12820710241794586, -0.30466362833976746, 0.2758913040161133, 0.1056881994009018, -0.3800012767314911, -0.7257393598556519, -0.5754274725914001, -0.1151522621512413, 0.41868528723716736, -1.4513155221939087, -0.5512131452560425, 0.5480173230171204, -0.13431422412395477, -0.39204174280166626, 0.5067906975746155, -1.3616596460342407, -0.28784850239753723, 0.00339693040587008, -1.526831030845642, -0.8373628258705139, -0.6006568670272827, -0.16639313101768494, 0.33750858902931213, -0.3072035312652588, 0.9526147246360779, -0.34425994753837585, 0.14739128947257996, 0.10516545176506042, -0.5611250996589661, 0.2057037502527237, 0.04059215635061264, -0.811174750328064, 0.5590354204177856, 0.08986156433820724, 0.202166348695755, 0.38947853446006775, 0.19298379123210907, -0.17793121933937073, -0.94392329454422, 0.6656767725944519, 0.5771048665046692, -1.1111693382263184, -0.5617249608039856, -0.8054132461547852, -0.9078704714775085, 0.14930331707000732, 0.937055230140686, -0.4034723937511444, 0.19522956013679504, -0.04165185987949371, -0.6564489603042603, 0.24980518221855164, -0.7589454650878906, 0.4806417226791382, 0.1660570353269577, -0.988323986530304, -1.064807415008545, 0.03346827253699303, 0.10161031782627106, -0.6630291938781738, -0.07178942859172821, -0.08516376465559006, 0.48285171389579773, -0.23904523253440857, 0.7325018048286438, -0.5292630791664124, 0.8610957860946655, 0.5779052376747131, 0.02590027265250683, -0.5790270566940308, 0.04610287398099899, -0.6166582107543945, 0.3730347156524658, -0.09065541625022888, 0.6693350076675415, -0.2567063570022583, -0.12558528780937195, 0.8552988767623901, 0.776841938495636, -0.10747983306646347, -0.3547804355621338, 0.20828281342983246, 0.17957527935504913, -0.5548640489578247, -0.4944429397583008, -0.08528462052345276, -0.051066722720861435, 0.1857597827911377, 0.4550686478614807, 0.9569918513298035, -0.14169247448444366, -0.9243834614753723, 0.5172950625419617, -0.09813656657934189, -0.15291748940944672, -0.38869714736938477, -0.3707573711872101, -1.450982689857483, -0.04501601308584213, -0.9050830006599426, 0.22559992969036102, -1.3335750102996826, -0.6460366249084473, 0.9986717700958252, -0.04181596264243126, 0.08859939873218536, 0.2526889145374298, -0.28983044624328613, -0.07595819979906082, -0.5661129355430603, -0.5599279403686523, 0.6373730897903442, 1.3467673063278198, -0.825739860534668, 0.4514181911945343, -0.3920641839504242, -0.17546634376049042, 0.5243234634399414, 0.2751805782318115, 0.18078823387622833, -1.1776621341705322, -1.4517768621444702, 0.5617050528526306, -0.05628952756524086, 0.2949085533618927, -0.9064510464668274, 0.9440364837646484, 0.8213829398155212, 0.18250256776809692, -0.1850862354040146, 0.5877465605735779, -0.7441830039024353, -1.1273568868637085, 0.03806140646338463, -0.8678900599479675, -0.19945870339870453, 0.5440829992294312, -0.3759401738643646, -0.14559084177017212, 0.5966520309448242, 0.17276401817798615, -1.2328932285308838, -1.1978017091751099, 0.12906672060489655, -0.7064245939254761, 0.1720678210258484, -0.030845321714878082, -0.2548503577709198, -1.1527470350265503, -0.7217312455177307, -0.475911408662796, 0.6349397301673889, -0.5563088059425354, 1.0548943281173706, 1.2663379907608032, -0.8102376461029053, -0.08158133924007416, 0.28130707144737244, 0.3693775236606598, -0.006012172903865576, 0.8172087073326111, 0.17185458540916443, -0.19890956580638885, 0.19309227168560028, 0.397195428609848, 0.4757850170135498, -0.8526628017425537, -0.016724128276109695, 0.8497987389564514, 0.36288538575172424, -0.23904427886009216, 1.0894132852554321, 0.4385465383529663, -0.937840461730957, 0.43823444843292236, -0.7280868887901306, -0.8391189575195312, -0.06778193265199661, 0.8701622486114502, -0.421703040599823, -0.7157917618751526, -0.14890237152576447, -0.21461457014083862, 1.089811086654663, -0.14581426978111267, -1.0144007205963135, -0.10071822255849838, -0.37443748116493225, -0.006962554529309273, 1.0906187295913696, 0.9637120366096497, -0.7338893413543701, -0.9287424683570862, -0.5908896923065186, -0.5463349223136902, -0.2167922407388687, 0.3877602815628052, -0.929616391658783, -0.22862227261066437, 1.1885919570922852, 0.42793601751327515, 0.11982269585132599, 0.00462315883487463, 0.15272670984268188, -0.009762543253600597, 0.880977988243103, -0.292024701833725, -0.45692238211631775, -0.10843890905380249, 1.1000787019729614, 1.3584353923797607, -1.3261045217514038, 0.3869578242301941, -0.4836980402469635, -0.9167628288269043, 0.8093898892402649, 0.3615275025367737, 0.0026209894567728043, 0.7618584632873535, -0.7535766363143921, 0.33888623118400574, -0.031532175838947296, -0.5925489664077759, -0.43640244007110596, 1.3854297399520874, 1.2664605379104614, 0.5384184122085571, -0.030486175790429115, 0.43596214056015015, 0.6707809567451477, -0.2570669651031494, 0.3623187839984894, 0.4276483356952667, 0.13846781849861145, -0.6706554293632507, 0.7309393882751465, 0.27334150671958923, 0.4911953806877136, -0.10041297227144241, -0.6003182530403137, -0.03642046079039574, 0.6732012033462524, -0.04258618503808975, 0.4537412226200104, 0.8103153109550476, 0.3202025294303894, 0.2906626760959625, 0.3596011698246002, 0.7294597625732422, -0.502948522567749, 0.35391321778297424, -0.650195837020874, -0.7052677273750305, 0.3492744266986847, -0.38359761238098145, -0.40786051750183105, -0.4380481243133545, 0.3517044186592102, 0.7749247550964355, -0.6179260611534119, 0.09667971730232239, 1.5741183757781982, 0.33165040612220764, 0.2611824870109558, -0.7973493933677673, -0.30665498971939087, 0.15386328101158142, -0.8254103660583496, 0.5539048910140991, -0.794988214969635, 0.23650240898132324, -0.7202596664428711, -0.5484481453895569, -0.04336479678750038]}, "authors": [{"authorId": "24312899", "name": "Morris Alper"}, {"authorId": "2212461787", "name": "Michael Fiman"}, {"authorId": "1388323535", "name": "Hadar Averbuch-Elor"}], "references": [{"paperId": "16de2006e2960ba410772c6b6d460b83c0a5cc4b", "title": "Reproducible Scaling Laws for Contrastive Language-Image Learning"}, {"paperId": "81d8348378c1df78cb5713d97918a1d3daf894b9", "title": "Weakly Supervised Face Naming with Symmetry-Enhanced Contrastive Loss"}, {"paperId": "b287a2765e5bceb732de39dafdf70594dc9cd664", "title": "Vision-Language Pre-training: Basics, Recent Advances, and Future Trends"}, {"paperId": "e5c8960eb2ec034ffbd353ef39fd1cb541d3c7c9", "title": "LAION-5B: An open large-scale dataset for training next generation image-text models"}, {"paperId": "7e69986581d477f7051bb77ba1ba30e04e38ad8b", "title": "Visual Commonsense in Pretrained Unimodal and Multimodal Models"}, {"paperId": "24ed74ed29c057cba8b52fff4edd2c0d7f408716", "title": "VLP: A Survey on Vision-language Pre-training"}, {"paperId": "2fd6f77540c1cc8e70b96208ccf9971b4251fc02", "title": "FLAVA: A Foundational Language And Vision Alignment Model"}, {"paperId": "1360dc6d21ccbf2c23701c9ddd7c6ab8d04e4531", "title": "The World of an Octopus: How Reporting Bias Influences a Language Model\u2019s Perception of Color"}, {"paperId": "c59bcb6a98d8b3794106a71734746eb6cd0b8c58", "title": "Data Efficient Masked Language Modeling for Vision and Language"}, {"paperId": "5e00596fa946670d894b1bdaeff5a98e3867ef13", "title": "SimVLM: Simple Visual Language Model Pretraining with Weak Supervision"}, {"paperId": "2b9b7b5fb3f4450b6e3a267c4077bca4bf5997c8", "title": "Who\u2019s Waldo? Linking People Across Text and Images"}, {"paperId": "b82c5f9efdb2ae56baa084ca41aeddd8a665c1d1", "title": "Align before Fuse: Vision and Language Representation Learning with Momentum Distillation"}, {"paperId": "b1905ffd714d5e7e14eff99ced51214c2d22a3bd", "title": "Effect of Visual Extensions on Natural Language Understanding in Vision-and-Language Models"}, {"paperId": "8b652c4d7a8d5836925ce0fe28a91dc661778524", "title": "What's the best place for an AI conference, Vancouver or ______: Why completing comparative questions is difficult"}, {"paperId": "7198c33fcbd3561f9491c73529eb19a45ac298cc", "title": "Visual Grounding Strategies for Text-Only Natural Language Processing"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "141a5033d9994242b18bb3b217e79582f1ee9306", "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"}, {"paperId": "e8f7009c107bffa48684f9940ee40d58b71b8c21", "title": "How do blind people know that blue is cold? Distributional semantics encode color-adjective associations"}, {"paperId": "0839722fb5369c0abaff8515bfc08299efc790a1", "title": "ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision"}, {"paperId": "adf44618ffd68df7ab7e77c97eed7d2662efb707", "title": "Seeing colour through language: Colour knowledge in the blind and sighted"}, {"paperId": "7096304d19457833972daec4d3f5107befe30b1c", "title": "Do Neural Language Models Overcome Reporting Bias?"}, {"paperId": "dedcdc1fb3a6def9772dce674d89150923dd75b9", "title": "Vokenization: Improving Language Understanding via Contextualized, Visually-Grounded Supervision"}, {"paperId": "7425780c0ed3616437a2f090c89f3fbdc616cbd0", "title": "Image Colorization: A Survey and Dataset"}, {"paperId": "3b0d38302115af1165639d6fb34c4c19187b2a6f", "title": "Behind the Scene: Revealing the Secrets of Pre-trained Vision-and-Language Models"}, {"paperId": "ff80f56fe0977836fdb232a058fbebc1c2d5bbac", "title": "What is Learned in Visually Grounded Neural Syntax Acquisition"}, {"paperId": "3215c17848f6b0d9d0e8b15ef70c1fcad29a8b90", "title": "Beneath the Tip of the Iceberg: Current Challenges and New Directions in Sentiment Analysis Research"}, {"paperId": "3773952c704b29fc01f2c4fe54a444abbfdf6437", "title": "Clozing the gap: How far do cloze items measure?"}, {"paperId": "bd20069f5cac3e63083ecf6479abc1799db33ce0", "title": "A Primer in BERTology: What We Know About How BERT Works"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "dfc7b58b67c31932b48586b3e23a43cc94695290", "title": "UNITER: UNiversal Image-TExt Representation Learning"}, {"paperId": "d0086b86103a620a86bc918746df0aa642e2a8a3", "title": "Language Models as Knowledge Bases?"}, {"paperId": "093d9253a2fe765ca6577b091d3f99bab3155a7d", "title": "Benchmarking Zero-shot Text Classification: Datasets, Evaluation and Entailment Approach"}, {"paperId": "79c93274429d6355959f1e4374c2147bb81ea649", "title": "LXMERT: Learning Cross-Modality Encoder Representations from Transformers"}, {"paperId": "93d63ec754f29fa22572615320afe0521f7ec66d", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"}, {"paperId": "cc02386375b1262c3a1d5525154eaea24c761d15", "title": "Do Neural Language Representations Learn Physical Commonsense?"}, {"paperId": "80f9f109d1564cb8f82aa440a5f6f3fbe220c9ef", "title": "ERNIE 2.0: A Continual Pre-training Framework for Language Understanding"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "708f8c0eb5032edd6f31663a27febbb0529cbcf3", "title": "Visually Grounded Neural Syntax Acquisition"}, {"paperId": "e75362af676d31ea746de3d7c572c0aec7b9afda", "title": "Predicting Word Concreteness and Imagery"}, {"paperId": "031e4e43aaffd7a479738dcea69a2d5be7957aa3", "title": "ERNIE: Enhanced Representation through Knowledge Integration"}, {"paperId": "4043a936960de8e149dc208178fe1bcb157c7fa4", "title": "Recent Advances in Natural Language Inference: A Survey of Benchmarks, Resources, and Approaches"}, {"paperId": "46b6249adce2ee241f7c496cb58884273bbef4fe", "title": "Learning Concept Abstractness Using Weak Supervision"}, {"paperId": "35ebe95db7ab148e25904604d3b06a9412f6b4a4", "title": "Illustrative Language Understanding: Large-Scale Visual Grounding with Image Search"}, {"paperId": "b3558bda5562bd172d4c1c8d88796a0e3bbe2517", "title": "Colour envisioned: concepts of colour in the blind and sighted"}, {"paperId": "d02bf4082850a667bf0b7b6205df1cf9c1899233", "title": "Quantifying the Visual Concreteness of Words and Topics in Multimodal Datasets"}, {"paperId": "f269968ee8192f3cf663efd6d1dcdff22aabdefe", "title": "Learning Visually Grounded Sentence Representations"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "ce42f2d7595e995993ce9f6b603a1fb2111b2006", "title": "A Practical Guide to Sentiment Analysis"}, {"paperId": "3dd4f855d0c794060a8a2fabe0639f4a4e792b45", "title": "Structured Matching for Phrase Localization"}, {"paperId": "5d083e264cdf20b4407647bfc6107f5d5c732053", "title": "The Shape of Things: The Origin of Young Children\u2019s Knowledge of the Names and Properties of Geometric Forms"}, {"paperId": "0b888196dda951287dddb60bd44798aab16d6fca", "title": "Learning Common Sense through Visual Abstraction"}, {"paperId": "06599d41a3256245aa0cb2e9e56b29459c2e2c69", "title": "VisualWord2Vec (Vis-W2V): Learning Visually Grounded Word Embeddings Using Abstract Scenes"}, {"paperId": "e65142010431ffc089b272a1174214e00693e503", "title": "Generation and Comprehension of Unambiguous Object Descriptions"}, {"paperId": "35b91b365ceb016fb3e022577cec96fb9b445dc5", "title": "The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations"}, {"paperId": "5a4fe661b9ae5c41714b06bd8c7d06046681bf5e", "title": "Reflections on Sentiment/Opinion Analysis"}, {"paperId": "e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd", "title": "Don't just listen, use your imagination: Leveraging visual common sense for non-visual tasks"}, {"paperId": "dfa8790b6463cbd8e50d746e03e4c161e1920cf1", "title": "Combining Language and Vision with a Multimodal Skip-gram Model"}, {"paperId": "5002a020c0aa0d7838bb51c1ab24b23d2385e9d9", "title": "Multi-Modal Models for Concrete and Abstract Concept Meaning"}, {"paperId": "f28bd36d233dba56e23df22e79b1e432d4bdc66b", "title": "Learning Image Embeddings using Convolutional Neural Networks for Improved Multi-Modal Semantics"}, {"paperId": "eb0c26ad12c8bbe2ee02ceaf1033fe6c90f4f7f9", "title": "Learning Abstract Concept Embeddings from Multi-Modal Data: Since You Probably Can\u2019t See What I Mean"}, {"paperId": "8f96d88288385c3dbc681be5adf800bdaab3b35e", "title": "Concreteness ratings for 40 thousand generally known English word lemmas"}, {"paperId": "b843d9637cc7fa7c88dcd859ad323c0353289255", "title": "Decoding the Yellow of a Gray Banana"}, {"paperId": "cceb698cbbb828537f2f195fb70b6fdc586d3327", "title": "Reporting bias and knowledge acquisition"}, {"paperId": "fccebf911153cdefc198ddcd11a94352863aa2a8", "title": "Why are Abstract Concepts Hard to Understand"}, {"paperId": "917fbd64a435cb33e0e5b4cd73fe830db7b166db", "title": "Distributional Semantics in Technicolor"}, {"paperId": "25cd44c468583b9d3b309c03bbd202378454eb7d", "title": "The role of color information on object recognition: a review and meta-analysis."}, {"paperId": "05ff38f0236a3563858fd2560f2131d167b6770a", "title": "Function follows form: activation of shape and function features during object identification."}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "34fd68c23efd89c33e34d755562c6f978566a783", "title": "Is Color an Intrinsic Property of Object Representation?"}, {"paperId": "ac1c030220ab13273f1bcee98b41cbad28ecdec3", "title": "Representation of Colors in the Blind, Color-Blind, and Normally Sighted"}, {"paperId": "217c2da9f9e77834acad4e1dbde9c8ed49a193a1", "title": "Half a century of research on the Stroop effect: an integrative review."}, {"paperId": "193673830c0ef2c4abc7c9b0779383e16b432d0f", "title": "THE CLOZE PROCEDURE AND PROFICIENCY IN ENGLISH AS A FOREIGN LANGUAGE"}, {"paperId": "35cbb681b8fa0dd4fc57cc44d08cc2fee4a6d401", "title": "Age at onset of blindness and the development of the semantics of color names."}, {"paperId": "aebd1d7fc4faddc0b1a9fc2cb89d8b1db90124e8", "title": "The Cloze Test as a Measure of English Proficiency"}, {"paperId": "22d153500a221901496bc7682ab9658f7fbc2532", "title": "Flexible Visual Grounding"}, {"paperId": "a13a180aa995ce2a03d17ea1550813ef4336964b", "title": "Grounded PCFG Induction with Images"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "83a768a0720d0a1f68792827a422395001291614", "title": "Multimodal Distributional Semantics"}, {"paperId": null, "title": "The Psychology of Word Meanings"}, {"paperId": "64ca8e247db5be64d66acef2f0028aebe48d9b9f", "title": "Super vision."}, {"paperId": null, "title": "A standard corpus of present-day edited american english, for use with digital computers"}, {"paperId": null, "title": "\u2022 The movie was"}, {"paperId": null, "title": "\u2022 The following movie review expresses what sentiment"}, {"paperId": null, "title": "No \u2022 Is this a good movie"}, {"paperId": null, "title": "\u2022 Sentiment expressed for the movie is"}, {"paperId": null, "title": "\u2022 Is this review positive"}, {"paperId": null, "title": "\u2022 The overall review of the film is"}, {"paperId": null, "title": "Sentiment Analysis For sentiment analysis, we concatenate the following prompts to the given reviews and use the different options for sentiment prediction"}, {"paperId": null, "title": "Chapter 4. Naive Bayes and Sentiment Classification"}, {"paperId": null, "title": "agreement with IEEE. Restrictions apply"}, {"paperId": null, "title": "\u2022 The basic shape of a w is"}, {"paperId": null, "title": "Bert: Pre-training of deep bidirectional Conference (EMNLP 6786 Authorized licensed use limited to the terms of the applicable license"}, {"paperId": null, "title": "Shape Association Prediction For the shape association prediction, we use the following prompts. For each given"}, {"paperId": null, "title": "Speech and language processing (3rd draft ed.), 2023. Chapter 4"}]}