{"paperId": "936551c6026df296e27a649a34f379357fb57a74", "title": "Mnemosyne: Learning to Train Transformers with Transformers", "abstract": "In this work, we propose a new class of learnable optimizers, called \\textit{Mnemosyne}. It is based on the novel spatio-temporal low-rank implicit attention Transformers that can learn to train entire neural network architectures, including other Transformers, without any task-specific optimizer tuning. We show that Mnemosyne: (a) outperforms popular LSTM optimizers (also with new feature engineering to mitigate catastrophic forgetting of LSTMs), (b) can successfully train Transformers while using simple meta-training strategies that require minimal computational resources, (c) matches accuracy-wise SOTA hand-designed optimizers with carefully tuned hyper-parameters (often producing top performing models). Furthermore, Mnemosyne provides space complexity comparable to that of its hand-designed first-order counterparts, which allows it to scale to training larger sets of parameters. We conduct an extensive empirical evaluation of Mnemosyne on: (a) fine-tuning a wide range of Vision Transformers (ViTs) from medium-size architectures to massive ViT-Hs (36 layers, 16 heads), (b) pre-training BERT models and (c) soft prompt-tuning large 11B+ T5XXL models. We complement our results with a comprehensive theoretical analysis of the compact associative memory used by Mnemosyne which we believe was never done before.", "venue": "Neural Information Processing Systems", "year": 2023, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2302.01128", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "Mnemosyne is a new class of learnable optimizers based on the novel spatio-temporal low-rank implicit attention Transformers that can learn to train entire neural network architectures, including other Transformers, without any task-specific optimizer tuning."}, "embedding": {"model": "specter_v2", "vector": [0.3212386965751648, 0.8795979022979736, -0.3900667726993561, 0.19500109553337097, 0.06556063145399094, -0.023300083354115486, 0.820293128490448, -0.35036909580230713, -0.43521153926849365, -0.6393024921417236, 0.37134411931037903, 0.08738414943218231, 0.4442242681980133, 0.20903627574443817, -0.1326979547739029, 0.13022808730602264, -0.37515825033187866, 0.2481452077627182, 0.3988024890422821, -0.4777955412864685, 0.3124832510948181, -0.5389436483383179, -1.0611042976379395, 0.03735581040382385, 0.06938720494508743, 1.0784790515899658, 0.2126491367816925, 0.9930258393287659, -0.2309524118900299, 0.886338472366333, 0.401285856962204, -0.48811987042427063, 0.20508264005184174, 0.24574880301952362, -0.5661702752113342, 0.005461791530251503, 0.7734501957893372, -0.5020039677619934, -0.6451586484909058, 0.8255410194396973, -0.22280800342559814, 0.26908984780311584, 0.46711236238479614, -0.5719670653343201, -0.3694959878921509, 0.26547080278396606, 0.590781033039093, 0.8138440847396851, -0.9466850161552429, -0.023676026612520218, 1.274861216545105, -1.4314823150634766, 0.03621339425444603, 1.3098310232162476, 0.6450371146202087, 0.4964243769645691, -0.17687292397022247, -0.34015530347824097, 1.0446382761001587, 0.2975308299064636, -0.6322425603866577, -0.425161212682724, 0.0747070387005806, 0.19340047240257263, 1.9311866760253906, -0.7083631753921509, 0.15623575448989868, 0.808718204498291, 0.32381054759025574, 1.4723985195159912, -0.1787175089120865, -0.584287703037262, -0.28470274806022644, 0.36831411719322205, 0.2435590922832489, 0.9153341054916382, -0.5612007975578308, 0.3833485245704651, -0.935295581817627, 0.5172770619392395, 0.6994302272796631, 0.10747470706701279, 0.23510873317718506, -0.20703165233135223, -0.2319466918706894, 0.5274834036827087, 0.9832403063774109, 0.7318591475486755, -0.45165741443634033, 1.052669644355774, 0.5112385153770447, 0.3018837869167328, -0.26545053720474243, 0.5842496752738953, -0.11522218585014343, 0.5472413897514343, -0.8057294487953186, -0.3027827739715576, -0.5595953464508057, 0.7543814182281494, -0.16800688207149506, 0.43036505579948425, -0.5543975830078125, -0.12476731091737747, 1.2806657552719116, -0.19549506902694702, 0.34811994433403015, -0.9880173802375793, 0.24867168068885803, -0.8129327297210693, -0.05012008175253868, -0.6981873512268066, -0.12402090430259705, -0.6011128425598145, -0.873358428478241, -0.797999918460846, -0.5234355330467224, 0.6545378565788269, -1.023819088935852, 0.7267033457756042, -0.4901881217956543, 0.2322583645582199, -0.12694299221038818, 0.651831328868866, 0.666680634021759, 0.573905885219574, 0.2068231701850891, 0.22486388683319092, 0.7715007066726685, -1.277038335800171, -0.7070649862289429, -1.2790806293487549, 0.189530149102211, -0.00754878344014287, 0.4714035987854004, 0.36942750215530396, -1.1575062274932861, -1.111483097076416, -0.9298639297485352, -0.46464622020721436, -0.40682452917099, 0.24088484048843384, 0.9622355103492737, 0.0009897691197693348, -1.3697419166564941, 1.0982390642166138, -0.41610389947891235, -0.11550619453191757, 0.483896940946579, 0.5502029061317444, 0.40276968479156494, 0.10836049914360046, -0.8705049753189087, 0.46469712257385254, 0.28468990325927734, -0.0653986856341362, -0.43761107325553894, -0.5950247645378113, -0.7618498802185059, -0.05827690288424492, 0.38489606976509094, -0.6899442672729492, 1.3559626340866089, -0.510972261428833, -1.279126763343811, 0.7650524377822876, -0.43006056547164917, -0.012929610908031464, 0.21918049454689026, -0.3976737856864929, -0.2226778119802475, -0.18953923881053925, -0.5079870820045471, 1.0208752155303955, 0.9704592227935791, -0.2155633121728897, -0.25031349062919617, 0.16360801458358765, -0.2545914649963379, -0.11649966239929199, -0.5080375075340271, 0.7091753482818604, -0.704332172870636, -0.2211056351661682, 0.4833478331565857, 0.8365620374679565, 0.1778039038181305, -0.06349993497133255, -0.4419400691986084, -0.7963749766349792, 0.5427063703536987, 0.1632126122713089, 0.9540377855300903, -0.9096925258636475, -0.5934872627258301, -0.37069809436798096, 0.3374272882938385, -0.0890858918428421, -0.9814784526824951, 0.02241753600537777, -0.3929443955421448, 0.19985444843769073, 0.08030781894922256, -1.4010727405548096, -0.058645009994506836, -0.24631375074386597, -0.7248606085777283, -0.056223392486572266, 0.33821338415145874, 1.4264123439788818, -0.9450228810310364, -0.11841266602277756, 0.11067409813404083, 0.27240127325057983, -0.9851637482643127, 1.0812965631484985, -0.2862264811992645, 0.0358918160200119, 0.1331656277179718, -0.25515016913414, -0.24724984169006348, -0.8064675331115723, 0.2157878428697586, -0.8639267086982727, -0.060854554176330566, 0.7618774175643921, -0.22345463931560516, 1.3678346872329712, -0.36897504329681396, 1.007104516029358, -0.25861793756484985, -0.49720996618270874, 0.057216521352529526, 0.32636746764183044, -0.34979456663131714, -0.6691399216651917, 0.5107312202453613, 0.2343355417251587, -0.943057656288147, 0.41250884532928467, 0.759363055229187, 0.7145092487335205, 0.016061706468462944, -0.27221065759658813, 0.8360208868980408, -0.22521670162677765, -0.22244901955127716, 0.4582313597202301, 0.5569702386856079, 0.37982288002967834, 0.22661246359348297, -0.05266730487346649, 0.028775004670023918, -0.8739686608314514, -0.07784102857112885, 0.5279733538627625, 0.39504724740982056, 1.1398723125457764, 0.48461103439331055, -1.176599383354187, -0.5040434002876282, -0.39426153898239136, 0.7726746201515198, 1.278336763381958, -0.014626216143369675, -0.09428681433200836, -0.5286772847175598, -0.29239219427108765, -0.761997401714325, 0.0456649586558342, -0.6583370566368103, -0.47268831729888916, -0.36388617753982544, -0.8030033707618713, 0.6586817502975464, 0.22559216618537903, 1.2904812097549438, -0.8410006761550903, -0.3858574330806732, -0.29245567321777344, 0.4420390725135803, -0.7988529801368713, -0.8351247906684875, 0.5213895440101624, -0.7817317843437195, -0.4180774390697479, 0.10326370596885681, -0.2252396047115326, 0.055498115718364716, -0.782983124256134, 0.9633857011795044, -0.4177723228931427, -0.11635177582502365, 0.1673285961151123, 0.932948887348175, -0.34715259075164795, -0.25962916016578674, 0.48380839824676514, 0.22367937862873077, 0.10628137737512589, -0.023363636806607246, 0.24868498742580414, -0.23500996828079224, 0.05532645806670189, -0.32351186871528625, 0.21906998753547668, 0.2416122555732727, -0.10750433057546616, 0.9959738850593567, -0.4876815378665924, 0.05119689181447029, -1.2812737226486206, 0.36639896035194397, 0.538728654384613, -0.573934018611908, 0.280396044254303, -1.0249265432357788, -0.07453238219022751, 0.41518351435661316, -0.6679231524467468, -0.08157142996788025, -0.8659476041793823, 0.41223856806755066, -1.1051113605499268, 0.0505523681640625, -0.37056615948677063, 0.44854629039764404, -0.019794363528490067, 0.5602136850357056, 0.42238160967826843, -0.1105651780962944, 0.06288021802902222, 0.595342755317688, -1.503969430923462, 1.1179704666137695, 0.7462798357009888, 0.3841339349746704, -0.14641650021076202, -0.11513469368219376, -0.5199219584465027, -1.0387226343154907, -0.4216957092285156, -0.16608759760856628, -0.42809388041496277, 0.5620964169502258, -0.47912049293518066, -1.0902409553527832, 0.23384185135364532, -1.1268651485443115, -0.535480260848999, 0.02889614924788475, -0.4719991981983185, -0.294355183839798, -1.25813889503479, -1.1886987686157227, -0.6485419273376465, -0.7018523216247559, -0.977878749370575, 0.14839594066143036, 0.3346697986125946, -0.19743627309799194, -0.6477577090263367, -0.27236780524253845, -0.546894907951355, 1.1682870388031006, -0.5212940573692322, 0.4780212938785553, 0.29322507977485657, -0.48735150694847107, 0.4179258346557617, 0.000489015772473067, 0.6012334823608398, -0.3895360231399536, 0.29052361845970154, -1.3697474002838135, 0.305467814207077, -0.32785263657569885, -0.4200407564640045, 0.5359857678413391, 0.49269288778305054, 0.6117693185806274, -0.41076841950416565, -0.08724365383386612, 0.9256985187530518, 1.5480518341064453, -0.7216213345527649, 0.3995033800601959, 0.5510112643241882, 1.2714488506317139, 0.0353291891515255, -0.25472214818000793, 0.4423190653324127, 0.4834391176700592, 0.10728736966848373, 0.6927263736724854, -0.032203223556280136, -0.3505007326602936, -0.8010445833206177, 0.4496520161628723, 1.2171180248260498, 0.3248944878578186, 0.15506388247013092, -0.8810833096504211, 0.7579830288887024, -0.9961511492729187, -0.5668593049049377, 0.5811513662338257, 0.8260775804519653, 0.20800161361694336, -0.19292740523815155, -0.27334633469581604, -0.22946587204933167, 0.5669700503349304, 0.6319671273231506, -0.4334677457809448, -0.7842939496040344, -0.06764404475688934, 0.5601473450660706, 0.31053227186203003, 0.58559250831604, -0.3372136950492859, 1.071482539176941, 14.559050559997559, 0.5935221314430237, -0.3674246668815613, 0.705614447593689, 0.8565765619277954, -0.060865551233291626, -0.39304739236831665, -0.013904326595366001, -0.8815182447433472, -0.33805033564567566, 1.1157715320587158, 1.0203049182891846, 0.9727414846420288, -0.13449594378471375, -0.13901054859161377, 0.28537195920944214, -0.5534612536430359, 1.0783385038375854, 0.31096208095550537, -1.323146104812622, 0.21683412790298462, 0.06088246405124664, 0.36720767617225647, 0.66994309425354, 1.3493070602416992, 0.7773871421813965, 0.14814844727516174, -0.2999117970466614, 0.764339804649353, 0.48232898116111755, 1.097813606262207, -0.022485362365841866, 0.044439952820539474, 0.06324195861816406, -0.9256124496459961, -0.21117755770683289, -0.38189905881881714, -0.8527083396911621, 0.011833629570901394, -0.21368223428726196, -0.060717299580574036, -0.7793087959289551, 0.17217569053173065, 0.954790472984314, -0.2552524507045746, 0.3499267101287842, -0.4335188865661621, 0.4006681740283966, -0.1794780045747757, 0.3554852604866028, 0.5670210719108582, 0.5599001049995422, 0.11163683980703354, -0.48402881622314453, -0.10213952511548996, 0.07063184678554535, -0.40881630778312683, 0.6742211580276489, -0.4697045087814331, -0.501811683177948, -0.04523675888776779, -0.15084129571914673, -0.09827304631471634, 0.8577463030815125, 0.3322629928588867, 0.4949030876159668, 0.015508903190493584, 0.5892249941825867, 0.4627297520637512, 0.30193036794662476, -0.46797704696655273, -0.055610816925764084, 0.10215252637863159, -0.4266636371612549, 0.032836247235536575, 0.6611392498016357, -0.45955997705459595, -0.5133388042449951, -0.6598285436630249, -0.21963441371917725, 0.3012929856777191, -1.1338516473770142, -0.20344507694244385, 0.979123592376709, -0.6068344712257385, -0.27684757113456726, 0.5642343163490295, -0.8387609124183655, -0.37110915780067444, 0.0726161003112793, -1.5586234331130981, -0.6924480199813843, -0.03180329129099846, -0.20554958283901215, -0.30632734298706055, -0.27169954776763916, 0.6405699253082275, 0.06546657532453537, -0.412546843290329, 0.2921643853187561, -0.320387601852417, -0.36909914016723633, -0.009257163852453232, -0.9318809509277344, 0.9709881544113159, 0.22084853053092957, 0.09719061851501465, 0.08481020480394363, 0.15788821876049042, 0.5722841024398804, -0.5745190382003784, -0.08579051494598389, 0.7446064352989197, -1.0802178382873535, -0.37042781710624695, -0.5551081299781799, -0.6795775890350342, 0.5446994304656982, 0.6625170111656189, -0.01213281974196434, -0.3629222810268402, 0.09452665597200394, -0.7248677611351013, -0.22071237862110138, -0.6215978264808655, -0.06966589391231537, 0.38503584265708923, -0.8894557356834412, -0.38570311665534973, -0.34513553977012634, 0.33774495124816895, -0.7843742966651917, -0.1936287134885788, -0.4016368091106415, 0.05145202577114105, -0.6972035765647888, 1.0073233842849731, -0.2886546850204468, 0.6461853981018066, 0.855579674243927, -0.0441458486020565, -0.6579841375350952, -0.09065740555524826, -0.910145103931427, -0.11642023175954819, 0.15274369716644287, 0.5212975144386292, -0.6192088723182678, 0.4171418845653534, 0.5141725540161133, 0.20690463483333588, -0.4510835111141205, -0.48804986476898193, -0.15688234567642212, -0.31426459550857544, -0.4328323304653168, 0.06115411967039108, -0.3428236246109009, -0.5110009908676147, 0.498310387134552, 0.44227278232574463, 0.568666934967041, -0.0037047951482236385, -1.0219061374664307, -0.07806969434022903, -0.18813347816467285, -0.2721608877182007, -0.7085899114608765, -0.4335840046405792, -1.471766710281372, -0.419647753238678, -0.9762206077575684, -0.19063515961170197, -1.0260592699050903, -0.4998059868812561, 0.03897228091955185, -0.6473936438560486, 0.40022987127304077, 0.3753011226654053, -0.050395213067531586, -0.046179842203855515, -0.2062050700187683, -0.8760928511619568, 1.002099871635437, 0.8865863680839539, -0.8960325121879578, -0.09251394122838974, -0.1544901728630066, -0.12864525616168976, 0.34008586406707764, 0.30062341690063477, -0.4791015684604645, -0.8870512247085571, -1.397506594657898, 0.659295380115509, -0.21715641021728516, 0.1738911271095276, -1.142964243888855, 0.8298790454864502, 0.5639068484306335, -0.06683701276779175, 0.0037565031088888645, 0.5093348622322083, -0.9400796294212341, -0.6349736452102661, 0.28919926285743713, -0.6304375529289246, 0.48912185430526733, 0.4515085816383362, -0.7799583077430725, -0.24064719676971436, 0.8774805665016174, 0.4012807607650757, -0.8750821948051453, -1.1390788555145264, 0.5378244519233704, -0.2720165252685547, 0.04544876515865326, -0.5414666533470154, -0.34455740451812744, -1.2787679433822632, -0.36462804675102234, -0.13516469299793243, 0.5567600131034851, -0.2890390455722809, 0.8187655210494995, 0.8477856516838074, -1.220225214958191, 0.39992061257362366, 0.27805736660957336, -0.14600785076618195, 0.2038566619157791, 0.3742208480834961, 0.8067665100097656, -0.3888334035873413, 0.36818790435791016, 0.13529282808303833, 0.3471184968948364, -0.2382260262966156, 0.25366315245628357, 1.4052317142486572, -0.4983780086040497, -0.18431612849235535, 1.3580223321914673, 0.18520626425743103, -0.9379317760467529, 0.37059417366981506, -1.001961350440979, -0.6558680534362793, -0.13206997513771057, 0.4625610411167145, -0.11478140205144882, 0.08778436481952667, 0.1504715383052826, -0.569426953792572, 0.39084509015083313, -0.05834348872303963, -0.5343278646469116, 0.7134508490562439, -0.07467106729745865, -0.07755514979362488, 0.7041036486625671, 0.9941985607147217, -1.2286889553070068, -1.3317183256149292, -0.8811001181602478, -0.5133606195449829, 0.3442532420158386, 0.5556262731552124, -0.5004755854606628, -1.2503607273101807, 1.0815421342849731, 0.7247226238250732, -0.23804837465286255, 0.6188417077064514, -0.23943863809108734, -0.06450174748897552, 0.8005878925323486, -0.054937511682510376, -0.7550692558288574, 0.09509265422821045, 1.2341418266296387, 1.0291060209274292, -0.7587177753448486, 0.09097133576869965, 0.16141244769096375, -0.7751778960227966, 0.6583981513977051, 0.5029601454734802, -0.3317031264305115, 0.43854954838752747, -0.5987499952316284, -0.059530019760131836, -0.08216284215450287, -1.125465989112854, -0.13736499845981598, 0.9821663498878479, 0.9286092519760132, 0.3754143714904785, -0.24968977272510529, 0.6754635572433472, 0.6769142150878906, 0.16740943491458893, -0.30319416522979736, 0.2819252610206604, 0.06173529848456383, -0.17136196792125702, 0.38199514150619507, 0.04188330098986626, 0.7042785882949829, -0.6671915650367737, -0.8217006921768188, 0.14636000990867615, 0.5630813837051392, 0.16193172335624695, 0.34170007705688477, 0.8555562496185303, -0.019914541393518448, 0.7902610898017883, -0.12315156310796738, 0.7176625728607178, -0.26206427812576294, -0.5247775912284851, -0.23786529898643494, -0.9017377495765686, -0.3039999008178711, 0.11470088362693787, -0.5033808350563049, -0.24849674105644226, -0.19393137097358704, 0.2591269612312317, -0.4010518193244934, 0.16842134296894073, 1.0174790620803833, 0.26743245124816895, 0.9580233693122864, -0.1826312094926834, -0.7959225177764893, -0.3134515583515167, -0.7544166445732117, 0.1855037957429886, -0.6798927783966064, 0.12792102992534637, -0.3668047785758972, -0.057617269456386566, -0.36284419894218445]}, "authors": [{"authorId": "2058985645", "name": "Deepali Jain"}, {"authorId": "1805203", "name": "K. Choromanski"}, {"authorId": "2109040371", "name": "Sumeet Singh"}, {"authorId": "1808676", "name": "Vikas Sindhwani"}, {"authorId": "28292148", "name": "Tingnan Zhang"}, {"authorId": "1739176520", "name": "Jie Tan"}, {"authorId": "89890133", "name": "Kumar Avinava Dubey"}], "references": [{"paperId": "fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d", "title": "RT-1: Robotics Transformer for Real-World Control at Scale"}, {"paperId": "fe60e2ad09a33bee70fb500f055b247a1bf35e0f", "title": "Transformer-Based Learned Optimization"}, {"paperId": "c088b46519c036149a9f6da4ec36383b800a0d2a", "title": "VeLO: Training Versatile Learned Optimizers by Scaling Up"}, {"paperId": "738abb1c50698f75c53f07f86fbc8a26c6b81ffd", "title": "A Memory Transformer Network for Incremental Learning"}, {"paperId": "988e21e7aa6ee5ee7889f785337231cbbcebbed7", "title": "Learning Model Predictive Controllers with Real-Time Attention for Real-World Navigation"}, {"paperId": "dc1b905c0af4dc318b63cd52fbc867c788df4b8c", "title": "Chefs' Random Tables: Non-Trigonometric Random Features"}, {"paperId": "943cd7cf7ba21911561d03228dc2dd3f397168c9", "title": "Towards Learning Universal Hyperparameter Optimizers with Transformers"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "0b0cd862d6820b24fc4e3ca1c42cbe557ca49d9c", "title": "Unbiased Gradient Estimation in Unrolled Computation Graphs with Persistent Evolution Strategies"}, {"paperId": "b64b3880198289fca95e54a001da3dd336502d7a", "title": "CoMPS: Continual Meta Policy Search"}, {"paperId": "fd1b829261ba04bb92e0ab60c4f6e7cea0d99fbf", "title": "Ethical and social risks of harm from Language Models"}, {"paperId": "a25370452533bf47549243e97852b9cdf7a0ee0e", "title": "Learning the Transformer Kernel"}, {"paperId": "988741ccb00fca7d73bf66136662ff5400845f5b", "title": "Optimizing Trajectories with Closed-Loop Dynamic SQP"}, {"paperId": "9058d322a09bfc0c93a070f87cac8fd840e63088", "title": "From block-Toeplitz matrices to differential equations on graphs: towards a general theory for scalable masked Transformers"}, {"paperId": "61f371768cdc093828f432660e22f7a17f22e2af", "title": "Offline Meta-Reinforcement Learning with Online Self-Supervision"}, {"paperId": "0d508600d77d8a7e6a655cdb6d139779732f649f", "title": "Stable, Fast and Accurate: Kernelized Attention with Relative Positional Encoding"}, {"paperId": "781fe7b9957a8b3a316f5ab63cef79e8d78fb88d", "title": "Meta-Learning with Fewer Tasks through Task Interpolation"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "f401a919db41eca28aa1cff062d98cc03b7ab66b", "title": "Learning to Optimize: A Primer and A Benchmark"}, {"paperId": "ca2f1088d3e581b2c6c75cf0ebc96506d620f64d", "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? \ud83e\udd9c"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "3b06c6b02595427fd35a4d98bf9b963380bbb920", "title": "Generalization of Model-Agnostic Meta-Learning Algorithms: Recurring and Unseen Tasks"}, {"paperId": "77706ee4cbdbb23345da22af37bc1b9f5ec8f110", "title": "Sub-Linear Memory: How to Make Performers SLiM"}, {"paperId": "df7d26339adf4eb0c07160947b9d2973c24911ba", "title": "Extracting Training Data from Large Language Models"}, {"paperId": "4509b5cca18dc09489a0df6883ebf7f8cac326ac", "title": "Deep learning can accelerate grasp-optimized motion planning"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "acf24ff124d9359d0404ed77967d292fc2e0a342", "title": "MELD: Meta-Reinforcement Learning from Images via Latent State Models"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3b5bd23386ded50640d285bc95d748272b23ca5c", "title": "Training Stronger Baselines for Learning to Optimize"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "8a858fb857abc06817d245bcb774a3901676f144", "title": "Tasks, stability, architecture, and compute: Training more effective learned optimizers, and using them to train themselves"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "6a8092b98771b8157437e71e351ae1231bdd8259", "title": "Large Associative Memory Problem in Neurobiology and Machine Learning"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "95b927bdb4ce3b9d119ce6a158fc155f573e8148", "title": "Learning Active Task-Oriented Exploration Policies for Bridging the Sim-to-Real Gap"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "8d908042f139575d6688c745e94156c9df6eae07", "title": "Understanding the Difficulty of Training Transformers"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "87a218117317813b5505846b183c1dc7a31225f4", "title": "Learning to Optimize in Swarms"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "eb4fa3f726cf583a5c8ca574ca94543117e7dc97", "title": "Differentially Private Meta-Learning"}, {"paperId": "e29a0a852080ef68248fc0e442627f39846c10b5", "title": "Using learned optimizers to make models robust to input noise"}, {"paperId": "65b226f71faaac9b8a4d63445c85601a16635464", "title": "Stochastic Gradient Descent Escapes Saddle Points Efficiently"}, {"paperId": "c0dccd9be123057ec82a6747d8fec9cc34699a6d", "title": "Sim-To-Real via Sim-To-Sim: Data-Efficient Robotic Grasping via Randomized-To-Canonical Adaptation Networks"}, {"paperId": "27f197e0401b854d14a41829e09209e38fe920b6", "title": "A Sufficient Condition for Convergences of Adam and RMSProp"}, {"paperId": "cb4147fbd0704398c692667078efff935a36bb6d", "title": "Understanding and correcting pathologies in the training of learned optimizers"}, {"paperId": "1f2e020e0b036760f9840e4a649350547db897fc", "title": "Learning to Learn Second-Order Back-Propagation for CNNs Using LSTMs"}, {"paperId": "0e93ee6176197f758dd5e8e9cff8b9610274c402", "title": "Modular meta-learning"}, {"paperId": "bb669de2fce407df2f5cb2f8c51dedee3f467e04", "title": "The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "b8ff7e02ffa1577d125acd3e998e8ce76a9059dc", "title": "Learned Optimizers that Scale and Generalize"}, {"paperId": "822e7515152e74626265c26b7aaccd2c654b5eba", "title": "Learning Gradient Descent: Better Generalization and Longer Horizons"}, {"paperId": "84bad036fbe21a024975cefa71785930fdec758e", "title": "On a Model of Associative Memory with Huge Storage Capacity"}, {"paperId": "519293ddd865118651b4a46041249b95cff74854", "title": "Learning to Learn for Global Optimization of Black Box Functions"}, {"paperId": "29c887794eed2ca9462638ff853e6fe1ab91d5d8", "title": "Optimization as a Model for Few-Shot Learning"}, {"paperId": "3904315e2eca50d0086e4b7273f7fd707c652230", "title": "Meta-Learning with Memory-Augmented Neural Networks"}, {"paperId": "71683e224ab91617950956b5005ed0439a733a71", "title": "Learning to learn by gradient descent by gradient descent"}, {"paperId": "ed332c92664cd64843a7ba9373d992e9547230f6", "title": "Dense Associative Memory for Pattern Recognition"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "3346e72b31399527d037d6ed091a2ab96225e0fd", "title": "Preliminary"}, {"paperId": "c50e547cef9b1119324b7e483bf5503c1afc53be", "title": "Meta-learning with backpropagation"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "04df5041de8c0ba7bdc6edb76ba3e77728b9e93f", "title": "On the search for new learning rules for ANNs"}, {"paperId": "c2dd697bbe99c2ec71c807580a00f7e723cc20ae", "title": "Adapting Bias by Gradient Descent: An Incremental Version of Delta-Bar-Delta"}, {"paperId": "b64e846fe88acaf302248249696c3b7badde41b5", "title": "Meta-neural networks that learn by learning"}, {"paperId": null, "title": "Dawn Song, \u00dalfar Erlingsson, Alina Oprea, and Colin Raffel"}, {"paperId": null, "title": "URL https://proceedings.mlr.press/ v155/zhao21d.html"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "44b6da0cd36c0fa2f7d3485c6dc0b6d2fbe379bb", "title": "Learning how to learn"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "e399090e4dd760e8f09bd3d4de61b13b057c7740", "title": "Compiling machine learning programs via high-level tracing"}, {"paperId": "1de823d71a417950ead15643c67fb6b369027f09", "title": "Hopfield Network"}, {"paperId": "8784f905f4f9fb6fa4a3cc9b0faa5b5479c687ec", "title": "On the Optimization of a Synaptic Learning Rule"}, {"paperId": null, "title": "Hop\ufb01eld"}, {"paperId": "48230ed0c3fa53ef1d43d79e1f6b113f13e83b9b", "title": "Iterative Linear Quadratic Regulator Design for Nonlinear Biological Movement Systems"}, {"paperId": "83519e404690ec4d13650cca62bf58463840beab", "title": "International Joint Conference on Neural Networks"}, {"paperId": "a6bcf0e9b5034c4c9cbea839baadd69a42b05cc1", "title": "Learning curves for stochastic gradient descent in linear feedforward networks"}, {"paperId": null, "title": "32) rest for SQP iteration. A sequence of snapshots during navigation with Mnemosyne-SQP optimizer in a sample environment is shown in Fig"}]}