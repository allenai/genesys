{"paperId": "e25f6a60211aa74ecfde8001a5939ff206102de4", "title": "End-to-End Speech Recognition: A Survey", "abstract": "In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.", "venue": "IEEE/ACM Transactions on Audio Speech and Language Processing", "year": 2023, "citationCount": 66, "influentialCitationCount": 3, "openAccessPdf": {"url": "https://ieeexplore.ieee.org/ielx7/6570655/6633080/10301513.pdf", "status": "BRONZE"}, "tldr": {"model": "tldr@v2.0.0", "text": "A taxonomy of E2E ASR models and corresponding improvements is provided, and their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures are discussed."}, "embedding": {"model": "specter_v2", "vector": [0.20669710636138916, 1.1468716859817505, -0.26026487350463867, -0.25930526852607727, -0.3418806791305542, 0.020852087065577507, 0.1682893931865692, -0.02355184406042099, -0.2916877865791321, -0.599916398525238, 0.637704610824585, -0.1295166015625, 0.8436511158943176, 0.3562140166759491, 0.055083125829696655, 0.37123629450798035, -0.6859661936759949, -0.1460821032524109, -0.16375792026519775, -0.45470938086509705, -0.5547177791595459, -0.8055530190467834, -0.5811769366264343, 0.061285872012376785, -0.18905124068260193, 0.7278743386268616, 0.08974084258079529, 1.2959119081497192, -0.1622159481048584, 0.3827122151851654, 0.059506725519895554, -0.8603551387786865, 0.06556550413370132, -0.18510526418685913, 0.04606315493583679, 0.17340756952762604, 0.054327115416526794, -0.6548386216163635, -0.6149462461471558, 0.6620606184005737, 0.02514238841831684, 0.29680174589157104, 0.14033108949661255, -0.30156630277633667, -0.33626624941825867, 0.9657860994338989, 0.8389695286750793, 0.6078690886497498, -0.2754954695701599, -0.515956461429596, 1.1675809621810913, -1.6384239196777344, -0.22720277309417725, 1.662833333015442, 0.8661065101623535, 0.7498143911361694, -0.23208534717559814, -0.5796127915382385, 0.5583619475364685, -0.25473862886428833, -0.6031233668327332, -1.2059884071350098, 0.1388394683599472, 0.0814419612288475, 1.459963321685791, -0.23516568541526794, 0.07429346442222595, 0.9144991636276245, -0.3494710624217987, 1.1445287466049194, 0.03484906256198883, -0.7150216698646545, -0.03553295135498047, 0.006478163879364729, 0.8241245150566101, 0.49808269739151, -0.7466649413108826, 0.4990612864494324, -1.1585956811904907, 0.03210463002324104, -0.14919480681419373, -0.12370794266462326, -0.058032333850860596, 0.2675746977329254, -0.009910265915095806, 0.7416398525238037, 0.0020082849077880383, 0.5009958744049072, -0.25275930762290955, 0.4637402892112732, 0.6426252126693726, 0.6668487787246704, 0.197452574968338, -0.14998970925807953, -0.1962558627128601, 0.069248728454113, -1.0090564489364624, -0.3160795271396637, -0.11890523880720139, 0.7466216087341309, -0.7009230256080627, 1.0516293048858643, -0.5227064490318298, 0.8896340727806091, 1.5587396621704102, 0.11119574308395386, 0.1293838769197464, -0.47533050179481506, 0.18466618657112122, -1.1001265048980713, 0.09413518756628036, -0.34010857343673706, 0.10157538205385208, -0.6551756858825684, -0.6054537296295166, -0.7942895293235779, -0.6504060626029968, -0.10452663898468018, -1.137014627456665, 0.7047690153121948, -0.5837871432304382, -0.16035421192646027, 0.7084000706672668, 0.09690635651350021, 0.33668115735054016, 0.7254550457000732, 0.07147819548845291, -0.4233025908470154, 1.2129900455474854, -0.8335487246513367, -1.3935375213623047, -0.9981382489204407, 0.5755341649055481, -0.26368290185928345, 0.24439655244350433, -0.17801342904567719, -1.0374209880828857, -0.7043778896331787, -0.6889995336532593, 0.049879997968673706, -0.18011455237865448, 0.6733882427215576, 0.34907612204551697, 0.8459973335266113, -1.3297572135925293, 0.5265390872955322, -0.24342581629753113, -0.199241042137146, 0.011512446217238903, 0.013271410018205643, 0.23874425888061523, 0.12679976224899292, -1.0693799257278442, 0.2134525179862976, 0.1281580626964569, -0.4111120104789734, -0.16255097091197968, -0.07687858492136002, -0.9789536595344543, -0.38621243834495544, 0.07418951392173767, -0.12284710258245468, 1.57154381275177, 0.06361114978790283, -2.0489416122436523, 0.3866502642631531, -0.619189977645874, -0.08886051923036575, 0.08562485873699188, -0.20420482754707336, -1.3399523496627808, -0.38675686717033386, -0.3130209743976593, 0.4736611247062683, 0.4054124355316162, 0.0013228156603872776, -0.07518544793128967, 0.16176722943782806, -0.9227483868598938, -0.4513261914253235, -0.1313205063343048, 1.2926543951034546, -0.3404281735420227, -0.7771071791648865, 0.49899688363075256, 0.4470809996128082, -0.019218992441892624, -0.24112145602703094, -0.7618443965911865, -0.7504512071609497, 1.4732649326324463, -0.7204346656799316, 1.094560980796814, -1.22475266456604, -1.1228082180023193, -0.133154958486557, -0.7137623429298401, 0.2500360906124115, -0.31466564536094666, 0.5240598320960999, -0.23398131132125854, 0.2422059029340744, -0.19363069534301758, -1.2400914430618286, 0.06566658616065979, -0.3613327145576477, -0.8237612843513489, -0.18420661985874176, 0.3108825087547302, 0.8230180144309998, -0.4811420738697052, 0.49422016739845276, 0.017237136140465736, 0.2844923436641693, -0.5886338949203491, 1.535358190536499, -0.1679663509130478, 0.19052010774612427, 0.2709425389766693, -0.12066581845283508, 0.12133995443582535, -0.009517943486571312, 0.27131691575050354, -0.34514573216438293, 0.031997181475162506, 0.8707216382026672, -0.5230602622032166, 1.0402259826660156, -0.2612711191177368, 1.0054724216461182, 0.24924302101135254, -0.32459205389022827, 0.6501054763793945, 1.1559603214263916, -0.5190766453742981, -0.294525682926178, 0.7116522789001465, 0.6630126237869263, -0.31631729006767273, 0.6683384776115417, 0.44708341360092163, 0.8615330457687378, -0.18405842781066895, 0.12903901934623718, 0.6114530563354492, -0.06641019880771637, -0.03476202115416527, 0.09623393416404724, 0.7484771013259888, -0.2714867889881134, 0.48053136467933655, 0.1360761970281601, 0.07803050428628922, -1.1514694690704346, 0.05772159993648529, 0.3503716289997101, 0.48636701703071594, 1.0099133253097534, -0.07259496301412582, -0.20780041813850403, -0.19361819326877594, -0.3809243142604828, 0.7727639675140381, 1.1079320907592773, -0.6085205078125, 0.1203843504190445, -1.1081916093826294, -0.52385413646698, -0.7357250452041626, 0.36982405185699463, 0.14627307653427124, -0.02991761453449726, -0.3865565359592438, -0.7167922258377075, 1.2450224161148071, 0.12252475321292877, 0.7885957360267639, -0.476238876581192, 0.1482098251581192, 0.030949091538786888, 0.20126011967658997, -1.0576133728027344, -1.073287844657898, 0.4226950407028198, -0.8119320869445801, 0.12139635533094406, -0.3021581768989563, -0.05420038476586342, -0.24129940569400787, -0.7659401297569275, 0.6490269899368286, -0.6456007957458496, 0.20119348168373108, 0.07251224666833878, 0.3994654417037964, -0.7647219300270081, -1.3250200748443604, -0.10756088048219681, 0.3016383945941925, 0.39790916442871094, 0.4551790952682495, 0.26587653160095215, 0.3198431134223938, 0.056998468935489655, -0.0493851974606514, -0.44289687275886536, 0.1913611888885498, -0.05627688392996788, 0.4726415276527405, -0.8163771629333496, 0.5210632681846619, -0.7903386950492859, 0.9029470682144165, 0.1324346959590912, -0.015800081193447113, 0.1869109719991684, -0.7601163983345032, -0.14894920587539673, 0.430379718542099, -0.31024447083473206, -0.3502662479877472, -0.6565444469451904, -0.5677107572555542, -0.2577804923057556, -0.42928001284599304, 0.125168114900589, 0.06393067538738251, 0.6561527848243713, 0.037625811994075775, 0.7804884910583496, 0.5414068698883057, -0.467370867729187, 0.4073541462421417, 0.3854416310787201, 0.4903729557991028, 0.9264969229698181, 0.0020663870964199305, -0.40229567885398865, -0.9231830835342407, -1.0137624740600586, -0.10109933465719223, -0.24801163375377655, 0.15717478096485138, -0.41629260778427124, -0.09476667642593384, -0.6517490744590759, -0.5485212802886963, 0.13774600625038147, -1.477875828742981, 0.3983098268508911, 0.046833012253046036, 0.2501106560230255, -0.25595468282699585, -0.9817351698875427, -1.4377598762512207, -1.2042477130889893, -0.7367442846298218, -0.7648058533668518, 0.25099268555641174, -0.11793790012598038, -0.46595853567123413, -0.07153290510177612, 0.010628466494381428, -0.1816701591014862, 0.931065559387207, -1.340364933013916, 0.4780460000038147, -0.5583848357200623, 0.010915949940681458, -0.1830500215291977, 0.7214071750640869, 0.8497607111930847, -0.056095048785209656, 0.3082718253135681, -1.1937247514724731, 0.2837580144405365, 0.0470794253051281, 0.157868891954422, -0.026919331401586533, 0.36656156182289124, 0.05202625319361687, -0.2845379114151001, -0.028331710025668144, 0.15567201375961304, 0.7673845291137695, -0.09961218386888504, 0.09311103820800781, -0.5460978746414185, 0.3635275065898895, 0.3204854130744934, -0.47241151332855225, 0.5001233816146851, 0.029741039499640465, 0.9000047445297241, -0.014645496383309364, -0.006417940370738506, -0.6047354340553284, -0.47686758637428284, 0.8961655497550964, 2.157907724380493, 0.355787068605423, -0.28557732701301575, -0.7839294672012329, 0.9026603698730469, -0.8463671207427979, -0.5932255387306213, 0.38594356179237366, 0.8707900643348694, 0.30430999398231506, -0.33310410380363464, -0.0998096615076065, 0.21868593990802765, 1.11543607711792, 0.5218392014503479, -0.1385391801595688, -1.2065625190734863, 0.25982221961021423, 0.32361412048339844, -0.02211604453623295, 0.5852645635604858, -0.2488844245672226, 0.31048834323883057, 14.616572380065918, 0.6872532367706299, -0.0016790847294032574, 1.0905944108963013, 0.5572572946548462, 0.14054527878761292, 0.0751710757613182, -0.14136148989200592, -1.0651936531066895, 0.1571100652217865, 1.7613606452941895, 0.49936550855636597, 0.45446664094924927, 0.31323477625846863, 0.3955833911895752, 0.8482666611671448, -0.596706748008728, 1.0325437784194946, 0.22434687614440918, -1.0878112316131592, 0.09303446114063263, 0.30782392621040344, 0.18940654397010803, 0.7521559596061707, 0.5122555494308472, 0.9518691301345825, 0.38184860348701477, -0.16867239773273468, 0.7409411072731018, -0.023050107061862946, 0.7158312797546387, -0.05854737013578415, 0.14933905005455017, 0.5609578490257263, -0.9294778108596802, -0.3259390890598297, 0.02301018312573433, -0.7420344352722168, 0.3458667993545532, 0.39731884002685547, -0.19654467701911926, -0.8170278668403625, -0.44216188788414, 0.3970962166786194, 0.2877814769744873, 0.19723913073539734, -0.3941085934638977, 1.1793460845947266, -0.2853611409664154, -0.15771038830280304, -0.04735569655895233, 0.7228906750679016, 0.9231818914413452, 0.13582290709018707, 0.10925883799791336, 0.13081157207489014, -0.3296753764152527, 0.34696632623672485, -0.9215927124023438, -0.018334291875362396, -0.4615408778190613, -0.23081189393997192, -0.006703726481646299, -0.0728726014494896, 0.5092313289642334, 0.4650650918483734, -0.45058467984199524, 0.6671205163002014, 0.15320579707622528, 0.5494303703308105, -0.20652255415916443, -0.5048254132270813, 0.6218051314353943, -0.27972134947776794, 0.10180895030498505, 0.4505525529384613, 0.08238989859819412, -0.4592803418636322, -0.4965725839138031, -0.4243791997432709, 0.028295790776610374, -0.8887031078338623, -0.7522682547569275, 1.172887921333313, -0.8307614326477051, -0.1871776431798935, 0.14018355309963226, -0.6189762949943542, -0.2981451749801636, 0.2304794043302536, -1.0373420715332031, -0.2164156138896942, 0.7083901166915894, -0.2140783816576004, -0.06082568317651749, -0.3482348620891571, 0.9000961780548096, 0.4123241603374481, -0.44724276661872864, 0.2667332887649536, 0.08920570462942123, 0.45832952857017517, -0.5996714234352112, -0.3815595805644989, 0.8238990306854248, 0.6900537610054016, 0.22048628330230713, -0.1949147880077362, 0.04742834344506264, 0.22825612127780914, -0.2921772003173828, -0.37411829829216003, 0.8645417094230652, -0.4110318124294281, -0.729928731918335, -0.8200692534446716, -0.6816079020500183, 0.3443080484867096, 0.5367041230201721, 0.13271985948085785, 0.12567830085754395, 0.1751214563846588, -0.5172252058982849, -0.16717272996902466, -0.43104368448257446, 0.38786208629608154, 0.4053342342376709, -1.2559459209442139, -0.5461022853851318, -0.3555538058280945, 0.6605831980705261, -0.3509296178817749, -0.3547660708427429, -0.24077486991882324, -0.15285761654376984, -0.2292354851961136, 0.5982670187950134, -0.2901308536529541, -0.10815227776765823, 0.8482047915458679, -0.4899233281612396, -0.9126986265182495, 0.45499059557914734, -1.3058607578277588, -0.24921295046806335, 0.3544416129589081, 0.7739233374595642, -0.5947846174240112, 0.28793084621429443, 0.5842516422271729, -0.252814918756485, -0.11168854683637619, -0.9904611110687256, -0.8326855897903442, -0.6209419965744019, -0.7334341406822205, 0.08514708280563354, -0.21096596121788025, -0.19817429780960083, 0.1394631564617157, 0.22933687269687653, 0.8638126850128174, -0.17989473044872284, -1.2470704317092896, 0.25034499168395996, -0.3395601511001587, 0.014652909711003304, -0.396841436624527, -0.5660393834114075, -1.7197388410568237, -0.058895617723464966, -0.9323773980140686, 0.3600689470767975, -0.39932042360305786, -0.6946194767951965, 0.6189279556274414, -0.2281164675951004, -0.20402811467647552, 0.6156057715415955, -0.3651905357837677, 0.006144384387880564, -0.3601362109184265, -0.2177041471004486, 0.9572029113769531, 0.3617349863052368, -0.548502504825592, -0.03200607746839523, 0.3452034890651703, 0.4213888943195343, 0.3775148093700409, 0.545002818107605, -0.9575557112693787, -0.6784663796424866, -1.0968291759490967, -0.34120726585388184, 0.40961983799934387, -0.021807920187711716, -1.1290837526321411, 0.5264459252357483, 0.7487691044807434, -0.7406091094017029, -0.11955571174621582, 0.5946773290634155, -0.8798103928565979, -0.0002429379674140364, 0.2466256469488144, -1.0364999771118164, -0.1972932666540146, -0.1870163530111313, -0.518370509147644, -0.7456017136573792, 0.36875906586647034, 0.24090537428855896, -0.6020265817642212, -0.4473850429058075, 0.4675390422344208, -0.8581645488739014, 0.17705880105495453, -0.2992982864379883, -0.5293965339660645, -0.7596612572669983, -0.5870601534843445, -0.6135416626930237, -0.42353352904319763, -0.7045018076896667, 0.9958183169364929, 0.3876500427722931, -0.9373201727867126, -0.22499561309814453, 0.6685702800750732, 0.03188285604119301, -0.9286274909973145, 0.03285175561904907, 0.4639938175678253, 0.09349626302719116, 0.4989282190799713, 0.6654450297355652, 0.18724839389324188, -1.049787163734436, -0.5265936851501465, 0.8451313376426697, 0.0771649032831192, 0.0034150383435189724, 0.968689501285553, -0.7064279317855835, -1.077195167541504, 0.22166816890239716, -1.0053728818893433, -0.2056552767753601, -0.270174503326416, 0.2911028563976288, 0.3457270562648773, 0.2920916676521301, -0.33198556303977966, -0.4717045724391937, -0.028965186327695847, 0.10619384050369263, -0.8532798290252686, 0.2977539002895355, -0.5467711091041565, 0.2188539057970047, 0.6876193284988403, 1.0025956630706787, -0.20923390984535217, -0.8973358273506165, -0.5627469420433044, -0.11141251027584076, 0.17780765891075134, 0.3421401083469391, -0.1954803615808487, -0.9256538152694702, 1.1939294338226318, 0.9198889136314392, 0.49922412633895874, 0.1952090710401535, -0.2348586618900299, 0.2819044888019562, 0.5194820761680603, 0.07457780092954636, -0.8694549202919006, -0.6650425791740417, 1.5124611854553223, 1.2364259958267212, -1.123012661933899, -0.4548802971839905, -0.4005729854106903, -0.6425272226333618, 0.8805201053619385, -0.211424320936203, 0.33590346574783325, 1.4439024925231934, -0.22948241233825684, 0.518123984336853, 0.520723283290863, -0.9026734232902527, -0.264010488986969, 0.33619338274002075, 0.9158293604850769, 0.8908179402351379, 0.24362893402576447, 0.2990848124027252, 1.0423197746276855, -0.028939062729477882, 0.09098945558071136, 0.6768806576728821, 0.20126572251319885, -0.4828292727470398, -0.1282343715429306, -0.018269652500748634, 0.44022271037101746, -1.0317922830581665, -0.8059939742088318, 0.02961319498717785, 0.3964979648590088, -0.1312226951122284, 1.406449317932129, 0.5700730085372925, -0.015462257899343967, 0.7350000739097595, 0.6691445112228394, -0.07397464662790298, -0.9111233949661255, -0.5121392607688904, -0.1860913336277008, -0.3273894488811493, 0.16441144049167633, 0.2188219577074051, -0.44396141171455383, 0.014210164546966553, -0.08866484463214874, 0.07012011855840683, 0.17789284884929657, 0.7004936337471008, 0.9115210771560669, 0.850188136100769, 0.37804463505744934, 0.13852819800376892, -0.038676679134368896, -0.6421709060668945, -1.2595486640930176, -0.4259430766105652, -0.7445621490478516, 0.42320388555526733, 0.27478358149528503, -0.13263660669326782, -0.16996082663536072]}, "authors": [{"authorId": "2557391", "name": "Rohit Prabhavalkar"}, {"authorId": "145443186", "name": "Takaaki Hori"}, {"authorId": "1784851", "name": "Tara N. Sainath"}, {"authorId": "121979316", "name": "R. Schluter"}, {"authorId": "1746678", "name": "Shinji Watanabe"}], "references": [{"paperId": "b3cbae669ebd495f34913cea7d49d50e3e5923d3", "title": "Label-Synchronous Neural Transducer for End-to-End ASR"}, {"paperId": "3efb81de24eb88017d6dbcf22cb4215084223fd8", "title": "AudioPaLM: A Large Language Model That Can Speak and Listen"}, {"paperId": "42e726e2ea5bbb946001947d1a5b31ccc6b7aef9", "title": "VioLA: Unified Codec Language Models for Speech Recognition, Synthesis, and Translation"}, {"paperId": "33f629cf1a041e0afe0f41b6679a1427a84c1915", "title": "Lattice-Free Sequence Discriminative Training for Phoneme-Based Neural Transducers"}, {"paperId": "a02fbaf22237a1aedacb1320b6007cd70c1fe6ec", "title": "Robust Speech Recognition via Large-Scale Weak Supervision"}, {"paperId": "906148d8c0b9d0e80e1c47d100820a37d85b3fcf", "title": "Monotonic Segmental Attention for Automatic Speech Recognition"}, {"paperId": "db1f0553be8cb3f5235ea5091246b940799f3bd6", "title": "HMM vs. CTC for Automatic Speech Recognition: Comparison Based on Full-Sum Training from Scratch"}, {"paperId": "0fc86eabd4679747664e50e53e02bdee7526d734", "title": "JOIST: A Joint Speech and Text Streaming Model for ASR"}, {"paperId": "fd82a861a0bdb8693a5e3596516f1c0848a3d80a", "title": "E-Branchformer: Branchformer with Enhanced Merging for Speech Recognition"}, {"paperId": "0cd31a2c81f9c14d6f9c0dc810bf98388d8be459", "title": "Branchformer: Parallel MLP-Attention Architectures to Capture Local and Global Context for Speech Recognition and Understanding"}, {"paperId": "cd659542200100189ceec779ec3aa572573fa6f3", "title": "Efficient Training of Neural Transducer for Speech Recognition"}, {"paperId": "3267e6b97790391c15a72e4b5aa4920cfe9756e7", "title": "Unified Speech-Text Pre-training for Speech Translation and Recognition"}, {"paperId": "1a65b38aaa72da05023d7d88fe1b88608b37b5fc", "title": "MAESTRO: Matched Speech Text Representations through Modality Matching"}, {"paperId": "419e714f22c3fa2599abebd630cae5595c70bdef", "title": "End-to-End Integration of Speech Recognition, Speech Enhancement, and Self-Supervised Learning Representation"}, {"paperId": "26f579260f34e65384466d1982e3785320a5f4a6", "title": "Towards Reducing the Need for Speech Training Data to Build Spoken Language Understanding Systems"}, {"paperId": "1ce67b5555c123ae1efb710965567f51bf764423", "title": "mSLAM: Massively multilingual joint pre-training for speech and text"}, {"paperId": "baed0ce3a22bec3823589589d56312b8649d7414", "title": "Recent Advances in End-to-End Automatic Speech Recognition"}, {"paperId": "6f69fcacdf53a811ef18c5e9ac8ec58035dc43fc", "title": "Sequence Transduction with Graph-Based Supervision"}, {"paperId": "9cda754187545c3cc8f9e9f134c08707269d0fae", "title": "SLAM: A Unified Encoder for Speech and Language Modeling via Speech-Text Joint Pre-Training"}, {"paperId": "16675750071ac39f201a28562ab72c7e5b079091", "title": "Efficient Sequence Training of Attention Models Using Approximative Recombination"}, {"paperId": "1067c44e473b6998f89e13f0d4c0de730def43f0", "title": "SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing"}, {"paperId": "70cc759f8350bfe86af4299a494130fc069f3319", "title": "On Language Model Integration for RNN Transducer Based Speech Recognition"}, {"paperId": "7ac4227d0b4d38b16da27ed55bd53ce240a32404", "title": "A Comparative Study on Non-Autoregressive Modelings for Speech-to-Text Generation"}, {"paperId": "aba1b8b76ae1d9c30d0a566e811b27157671905b", "title": "CTC Variations Through New WFST Topologies"}, {"paperId": "6fe21b01d2202defb8fcd75c40f306a88bd385dc", "title": "BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning for Automatic Speech Recognition"}, {"paperId": "55b4f554a7d459eb9c018702b3de6e55ebd1870c", "title": "Factorized Neural Transducer for Efficient Language Model Adaptation"}, {"paperId": "0fc229cfb6f79a6c5778b80ba78dd6584f921ab9", "title": "An Efficient Streaming Non-Recurrent On-Device End-to-End Model with Improvements to Rare-Word Modeling"}, {"paperId": "7f31856eb04f6ea49aff276621de66ca85a1a554", "title": "Tied & Reduced RNN-T Decoder"}, {"paperId": "37074b2b9cebd89e4a92d20f41eec7360e11fe5a", "title": "Streaming End-to-End ASR based on Blockwise Non-Autoregressive Models"}, {"paperId": "4fffa5245d3972077c83614c2a08a47cb578631e", "title": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units"}, {"paperId": "8eda64d93e4d1ce5aef1405f99d15004db9028c5", "title": "SPLAT: Speech-Language Joint Pre-Training for Spoken Language Understanding"}, {"paperId": "46246ceb59c682a16e7796ca81949c09feaad989", "title": "U2++: Unified Two-pass Bidirectional End-to-end Model for Speech Recognition"}, {"paperId": "8c225a7a1612b97ab0f636bf85a9d0fd4e28bcb3", "title": "Why does CTC result in peaky behavior?"}, {"paperId": "2fc885d669263a151e8906f124d3388029b114a1", "title": "On the limit of English conversational speech recognition"}, {"paperId": "a65b7ff72deb358bef29900a53c814771275c37c", "title": "Scaling End-to-End Models for Large-Scale Multilingual ASR"}, {"paperId": "012e96816bc5e0a2b5eeb26aec5175b39cefbfdc", "title": "Acoustic Data-Driven Subword Modeling for End-to-End Speech Recognition"}, {"paperId": "e3ee3bee2f091a5e54061b4aa15082a7510640e1", "title": "Equivalence of Segmental and Neural Transducer Modeling: A Proof of Concept"}, {"paperId": "11d6518dd23a8fd7cfa84ad48526448abbc63f20", "title": "Comparing the Benefit of Synthetic Training Data for Various Automatic Speech Recognition Architectures"}, {"paperId": "3ba5ccc491ebdb61d138db0a85373a35853cb568", "title": "Investigating Methods to Improve Language Model Integration for Attention-based Encoder-Decoder ASR Models"}, {"paperId": "95652905de959dfb8cfb592767c7d331be0af009", "title": "Pushing the Limits of Non-Autoregressive Speech Recognition"}, {"paperId": "07b631a9fd4901d23ad1e7ed35a6c3d6ad1b6307", "title": "Librispeech Transducer Model with Internal Language Model Prior Correction"}, {"paperId": "3603a2d3fd7f34927d7b0501a0077dca2d1779aa", "title": "Towards Consistent Hybrid HMM Acoustic Modeling"}, {"paperId": "ccdafb4eaa0ce58438ea316b56f2a21b6602d0cd", "title": "Relaxing the Conditional Independence Assumption of CTC-based ASR by Conditioning on Intermediate Predictions"}, {"paperId": "a52b677abeb71c6ce16d14ad41d2c1c49b3ae04e", "title": "A study of latent monotonic attention variants"}, {"paperId": "2660dbba723573266edb2a0a4929e6847ae83212", "title": "Advancing RNN Transducer Technology for Speech Recognition"}, {"paperId": "187be9194de4974e428409a8693d1bdba7dd6e7d", "title": "MixSpeech: Data Augmentation for Low-Resource Automatic Speech Recognition"}, {"paperId": "fc912e9af47bf10428396b687b2bfb1e5832fcb1", "title": "Intermediate Loss Regularization for CTC-Based Speech Recognition"}, {"paperId": "08bf462f138c6c4c292d882bb6b760d5aedc4eab", "title": "WeNet: Production Oriented Streaming and Non-Streaming End-to-End Speech Recognition Toolkit"}, {"paperId": "92acaf505a9c738e56ed70759e8d0062f3c520d6", "title": "Toward Streaming ASR with Non-Autoregressive Insertion-Based Model"}, {"paperId": "167c4720d1abba7cbc28ed5dacbfce8fc853311b", "title": "Less is More: Improved RNN-T Decoding Using Limited Label Context and Path Merging"}, {"paperId": "5c5a1a956355e69b6a83bb73cd842e45d039c6f7", "title": "A Better and Faster end-to-end Model for Streaming ASR"}, {"paperId": "f3346b3368099cf398cbd6c9eca6556c493f4d0a", "title": "A systematic comparison of grapheme-based vs. phoneme-based label units for encoder-decoder-attention models."}, {"paperId": "af277b50a4f9dd8c886ddaeb70dde52a0ce3c334", "title": "Internal Language Model Estimation for Domain-Adaptive End-to-End Speech Recognition"}, {"paperId": "1b5753753e54ec680cd3a75925f8694f2236ea41", "title": "Phoneme Based Neural Transducer for Large Vocabulary Speech Recognition"}, {"paperId": "c36a2113c1649565ffd5b9c408f6b38d202accc1", "title": "Cascaded Encoders for Unifying Streaming and Non-Streaming ASR"}, {"paperId": "8809d0732f6147d4ad9218c8f9b20227c837a746", "title": "Recent Developments on Espnet Toolkit Boosted By Conformer"}, {"paperId": "e2e91fcae687655f696926bb88727753a6728a23", "title": "Large-Scale End-to-End Multilingual Speech Recognition and Language Identification with Multi-Task Learning"}, {"paperId": "131ee42e4839d153333e17f46facdb6806e98c73", "title": "Developing Real-Time Streaming Transformer Transducer for Speech Recognition on Large-Scale Dataset"}, {"paperId": "501d54cd4731dba3c7aad5735058be3da2753621", "title": "Emformer: Efficient Memory Transformer Based Acoustic Model for Low Latency Streaming Speech Recognition"}, {"paperId": "f8b168355cbd2348d344e0eb9477d75da15b70f5", "title": "Universal ASR: Unify and Improve Streaming ASR with Full-context Modeling"}, {"paperId": "5944499d410e01040dea78dc6913a3b097988c49", "title": "Transformer Transducer: One Model Unifying Streaming and Non-streaming Speech Recognition"}, {"paperId": "38a2380549d7f8afabc90353956e4511abd48255", "title": "Online Automatic Speech Recognition With Listen, Attend and Spell Model"}, {"paperId": "51db55a30552ab4e2666879d9a28993e6b2acdb5", "title": "Developing RNN-T Models Surpassing High-Performance Hybrid Models with Customization Capability"}, {"paperId": "4affd37c7749b2b6f2e52f49e4dce00f24dc6d8d", "title": "Massively Multilingual ASR: 50 Languages, 1 Model, 1 Billion Parameters"}, {"paperId": "f019a5dcad2306998a2ba06c853ee43d68c9eb31", "title": "Streaming Transformer Asr With Blockwise Synchronous Beam Search"}, {"paperId": "49a049dc85e2380dde80501a984878341dd8efdf", "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations"}, {"paperId": "635932ee917d71e01f07211c0359abf3e0e65e47", "title": "Insertion-Based Modeling for End-to-End Automatic Speech Recognition"}, {"paperId": "4b8d28953c75dcb549148c68e72b4247c5ec7ee7", "title": "Early Stage LM Integration Using Local and Global Log-Linear Combination"}, {"paperId": "2afabb506318ea71f39f28f3ad121bed5358f771", "title": "A New Training Pipeline for an Improved Neural Transducer"}, {"paperId": "8a96d947c98bab4a801ccf7978101b36e79a9d13", "title": "Robust Beam Search for Encoder-Decoder Attention Based Speech Recognition Without Length Bias"}, {"paperId": "4efda60a5db5010e5ba68dc5d8aeb7161df8191d", "title": "Improved Noisy Student Training for Automatic Speech Recognition"}, {"paperId": "46845759234be49f085e57c694e9b5ec0f79874e", "title": "Exploring Transformers for Large-Scale Speech Recognition"}, {"paperId": "1a671afdac8e7b759cf3b5ec7d03d485c76a989c", "title": "Mask CTC: Non-Autoregressive End-to-End ASR with CTC and Mask Predict"}, {"paperId": "0170fc76e934ee643f869df18fb617d5357e8b4e", "title": "Conformer: Convolution-augmented Transformer for Speech Recognition"}, {"paperId": "1bd7d2932de819ed1087b6453ef2c0be9f781ac1", "title": "ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context"}, {"paperId": "c006d720f754069af161e699fa957396b8ea88ba", "title": "Rnn-Transducer with Stateless Prediction Network"}, {"paperId": "2752c502f1c911be67e32ad346be37bec83df5d3", "title": "Exploring A Zero-Order Direct Hmm Based on Latent Attention for Automatic Speech Recognition"}, {"paperId": "102be2d5e0e2074d3c34b787a78a34b4163e4880", "title": "Alignment-Length Synchronous Decoding for RNN Transducer"}, {"paperId": "2369297b14d33f4526e494b56954a65cc65e94f6", "title": "Towards Fast and Accurate Streaming End-To-End ASR"}, {"paperId": "87eece8d39d1e25ba87550be8b01af32738cbf2c", "title": "Improving End-to-End Single-Channel Multi-Talker Speech Recognition"}, {"paperId": "020bb2ba5f3923858cd6882ba5c5a44ea8041ab6", "title": "Meta-Learning in Neural Networks: A Survey"}, {"paperId": "f27b5050cf8fa8258ef3c988c6fd853f3de5c17f", "title": "The Rwth Asr System for Ted-Lium Release 2: Improving Hybrid Hmm With Specaugment"}, {"paperId": "ed75b6104635554a059d614c49bc67d80b4e7b58", "title": "Full-Sum Decoding for Hybrid Hmm Based Speech Recognition Using LSTM Language Model"}, {"paperId": "45df28a07f2061de04633df1bf40104981f0ca1d", "title": "A Streaming On-Device End-To-End Model Surpassing Server-Side Conventional Model Quality and Latency"}, {"paperId": "9c6dccf7e17221adc3b02bfc202a0e0e061fe28a", "title": "Deliberation Model Based Two-Pass End-To-End Speech Recognition"}, {"paperId": "f5dd8b7a0e904369ec0dbcb4306794347b36a62b", "title": "Hybrid Autoregressive Transducer (HAT)"}, {"paperId": "bb2bc99f8220fc681320c541940c99ae30b286d6", "title": "Imputer: Sequence Modelling via Imputation and Dynamic Programming"}, {"paperId": "2683061823326301221f3604b5b071957b54be2c", "title": "Unsupervised Speaker Adaptation Using Attention-Based Speaker Memory for End-to-End ASR"}, {"paperId": "8c09f5dad6d9e4ff1ca901d7ae1bf25d69b093a1", "title": "Accelerating RNN Transducer Inference via Adaptive Expansion Search"}, {"paperId": "09e2c7adbed37440d4a339852cfa34e5b660f768", "title": "Transformer Transducer: A Streamable Speech Recognition Model with Transformer Encoders and RNN-T Loss"}, {"paperId": "22dd93fe1a0b8e9cb83eaff6e2ecca0cd6693294", "title": "End-to-End Automatic Speech Recognition Integrated with CTC-Based Voice Activity Detection"}, {"paperId": "21dc7acda83295748ed4416918e9b6b4ad609491", "title": "Single headed attention based sequence-to-sequence model for state-of-the-art results on Switchboard-300"}, {"paperId": "b27a8968a51c5c1ab30fb8c54ae3a3453db25e1a", "title": "Streaming Automatic Speech Recognition with the Transformer Model"}, {"paperId": "f59c038dee828e0a8c2fc28130d12e39ee4952d6", "title": "Libri-Light: A Benchmark for ASR with Limited or No Supervision"}, {"paperId": "4097148c147f06b54802000a8476d28e525c63cf", "title": "Specaugment on Large Scale Datasets"}, {"paperId": "3da68533095f8401fe5b754d885dc3de704dae5e", "title": "Semantic Mask for Transformer based End-to-End Speech Recognition"}, {"paperId": "a84689ef8eaf38344eb3de24850ec0720c815605", "title": "Synchronous Transformers for end-to-end Speech Recognition"}, {"paperId": "ea415809bf87ef4b99966c6c50de6cb996a02a97", "title": "Deep double descent: where bigger models and more data hurt"}, {"paperId": "17f0ab1aaa2e17d2be5b2a35578aec7df8e0f572", "title": "A Unified Endpointer Using Multitask and Multidomain Training"}, {"paperId": "5f46d8e18138fe572b6fae897475a2ad645a3e1a", "title": "A Density Ratio Approach to Language Model Fusion in End-to-End Automatic Speech Recognition"}, {"paperId": "bc1ab519c225b08332f243269ad6d99284bbf1bf", "title": "A Comparison of Transformer and LSTM Encoder Decoder Models for ASR"}, {"paperId": "9cb71ec73da028bca7f089f5d277e5594d43ee99", "title": "Attention Based On-Device Streaming Speech Recognition with Large Speech Corpus"}, {"paperId": "9439954fc18cb1c5bd154edb6bb4c9a5ac4d5e03", "title": "Monotonic Recurrent Neural Network Transducer and Decoding Strategies"}, {"paperId": "04fea2e8edc678532dbf406346fb8d868712041a", "title": "Minimum Bayes Risk Training of RNN-Transducer for End-to-End Speech Recognition"}, {"paperId": "24472a31618bbc260e2bf45bd72427097875142b", "title": "End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern Architectures"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "6ae51a6908616f2cca16c4cd9bdb816d4f2e7ece", "title": "A Comparison of End-to-End Models for Long-Form Speech Recognition"}, {"paperId": "28867769021768c9daa572ba48ebab49968ff67f", "title": "RNN-T For Latency Controlled ASR With Improved Beam Search"}, {"paperId": "4099c4d272c12081b562392606e6d567e4ae7031", "title": "Masked Language Model Scoring"}, {"paperId": "fd9649aa3b3151615fffb6bd1b547ee7d82766ee", "title": "Transformer-Transducer: End-to-End Speech Recognition with Self-Attention"}, {"paperId": "d9c3bc1c2915ff02d33f66c800ad756cb87821d6", "title": "Transformer-Based Acoustic Modeling for Hybrid Speech Recognition"}, {"paperId": "94f8ef5944ecbdd0350d406bf3a16a7f2dff7349", "title": "MIMO-Speech: End-to-End Multi-Channel Multi-Speaker Speech Recognition"}, {"paperId": "f20f40a28f0e6a18f6008ef333d04a84e7ef32fd", "title": "From Senones to Chenones: Tied Context-Dependent Graphemes for Hybrid Speech Recognition"}, {"paperId": "04d96a75b4383240cb15fb729b29f5775219d724", "title": "Espresso: A Fast End-to-End Neural Speech Recognition Toolkit"}, {"paperId": "42b5438a084c69065acc436a4237f6c6369abb72", "title": "An Analysis of Local Monotonic Attention Variants"}, {"paperId": "ce77b9212751e1afd10c7fccd5271a806dfbb445", "title": "Speaker Adaptation for Attention-Based End-to-End Speech Recognition"}, {"paperId": "b20cadef0c59e80f7dfdf825b07442619d920fd5", "title": "Vectorized Beam Search for CTC-Attention-Based Speech Recognition"}, {"paperId": "d6c70a2ce72ccc11461860c3a738a1f7ca8d7309", "title": "Shallow-Fusion End-to-End Contextual Biasing"}, {"paperId": "26b0f0de64bc3c240c4439201b0fea45be47dff7", "title": "Advancing Sequence-to-Sequence Based Speech Recognition"}, {"paperId": "1ded3d23b5b5a9264fe5e67d07ce217f0adf9765", "title": "Lattice Generation in Attention-Based Speech Recognition Models"}, {"paperId": "d4c47ad1cc9889cdd1b19d7273cb0e66b18e3b28", "title": "Real-Time One-Pass Decoder for Speech Recognition Using LSTM Language Models"}, {"paperId": "0ce184bd55a4736ec64e5d82a85421298e0373ea", "title": "A Comparative Study on Transformer vs RNN in Speech Applications"}, {"paperId": "5cf3e46e6d427a87726c18f22def612519176938", "title": "Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model"}, {"paperId": "91420d80f16430f130cb67402058434eac8c2e38", "title": "Audio Word2vec: Sequence-to-Sequence Autoencoding for Unsupervised Learning of Audio Segmentation and Representation"}, {"paperId": "06183bd57548b74e38acf4733837766c9fdcdef2", "title": "Two-Pass End-to-End Speech Recognition"}, {"paperId": "d3231772937a2182b2377d028417245c49868dd1", "title": "On NMT Search Errors and Model Errors: Cat Got Your Tongue?"}, {"paperId": "e90bd23a26288cb030844894fd6794ac9012b181", "title": "Listen, Attend, Spell and Adapt: Speaker Adapted Sequence-to-Sequence ASR"}, {"paperId": "11f9664eb42cdbe6f434aea3381458d4055328f6", "title": "Comparison of Lattice-Free and Lattice-Based Sequence Discriminative Training Criteria for LVCSR"}, {"paperId": "33c9daa8a6a6a3c16f9670cc0cf357a2832b948b", "title": "LSTM Language Models for LVCSR in First-Pass Decoding and Lattice-Rescoring"}, {"paperId": "efe4cae24065785c6727e815b941613b5d9ac0a0", "title": "Gated Embeddings in End-to-End Speech Recognition for Conversational-Context Fusion"}, {"paperId": "8a568abeba0c2668cbbd58ccc094b8257c9ad4d1", "title": "Cumulative Adaptation for BLSTM Acoustic Models"}, {"paperId": "05b3a6acc8be299cc2a2678e5d81712b71c748e5", "title": "Monotonic Infinite Lookback Attention for Simultaneous Machine Translation"}, {"paperId": "56e3ce0ff4cbd05e404214d19ae264fe6c457a16", "title": "CIF: Continuous Integrate-And-Fire for End-To-End Speech Recognition"}, {"paperId": "80d26b206ee5621169e4175f2f1a6bfff464efbe", "title": "Phoebe: Pronunciation-aware Contextualization for End-to-end Speech Recognition"}, {"paperId": "3928b2177086532775fbf607ae3e05a0375a5061", "title": "Language Modeling with Deep Transformers"}, {"paperId": "744196b6cb5091c0760d05ef068a92a6cd531587", "title": "RWTH ASR Systems for LibriSpeech: Hybrid vs Attention - w/o Data Augmentation"}, {"paperId": "09342a388050fa7138116acea2a1271cf42fa95e", "title": "Subword Regularization and Beam Search Decoding for End-to-end Automatic Speech Recognition"}, {"paperId": "3c730bcb33745fb68fc42756c04df6920d6ddd66", "title": "Sequence Noise Injected Training for End-to-end Speech Recognition"}, {"paperId": "54afa0627f4fe92563fc11d407e64a3d3a5b7a48", "title": "Triggered Attention for End-to-end Speech Recognition"}, {"paperId": "dc92db2149ae862a9c96743bd5ec5bf79a2afa1e", "title": "Component Fusion: Learning Replaceable Language Model Component for End-to-end Speech Recognition System"}, {"paperId": "f2bb7e2f5a1afad5370159c15760c44df93c0438", "title": "Very Deep Self-Attention Networks for End-to-End Speech Recognition"}, {"paperId": "38bac9bb17dc5db753d98baf62941d6e97468d2c", "title": "Semi-Supervised Sequence-to-Sequence ASR Using Unpaired Speech and Text"}, {"paperId": "b0fae9fbb4e580d92395eabafe73e317ae6510e3", "title": "SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition"}, {"paperId": "6249b4b1f2886bf79690b4d9d419ddca87d390ac", "title": "Who Needs Words? Lexicon-Free Speech Recognition"}, {"paperId": "52fc149d40429bcf5090f956b343b779932215ed", "title": "Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions"}, {"paperId": "3426fadf73a5ce418486e640b26b3d2470d932b5", "title": "Massively Multilingual Adversarial Speech Recognition"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "ff413cae44ca5e14281ebe4659b8627c349e8493", "title": "Lingvo: a Modular and Scalable Framework for Sequence-to-Sequence Modeling"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "edbdda5fc458c733215a5ea9ab2750e0b4323ca7", "title": "Fully Convolutional Speech Recognition"}, {"paperId": "3f1431686216c96e0e812d830bf3328a6814fa73", "title": "Improving LF-MMI Using Unconstrained Supervisions for ASR"}, {"paperId": "6dbcb288498657b7d3bb3e59383d0a790123afa3", "title": "Streaming End-to-end Speech Recognition for Mobile Devices"}, {"paperId": "6b98bef930182a848c027dece1bfb58ca706449d", "title": "Improving End-to-end Speech Recognition with Pronunciation-assisted Sub-word Modeling"}, {"paperId": "a30d7a3aa5e50d0b7abb448b6692e419b84018b8", "title": "Promising Accurate Prefix Boosting for Sequence-to-sequence ASR"}, {"paperId": "3c6407554fb4ee599f42501cf5cba8fcefa88783", "title": "Cycle-consistency Training for End-to-end Speech Recognition"}, {"paperId": "6aa83f912110c63f0da5dc8a8464c9dc2c589076", "title": "Flat-Start Single-Stage Discriminatively Trained HMM-Based Models for ASR"}, {"paperId": "6ffe584f5edad5e343a30892ec54f1ef8b8e740e", "title": "Optimal Completion Distillation for Sequence Learning"}, {"paperId": "656aedc681975c3c97b1764466832de537358150", "title": "Auxiliary Feature Based Adaptation of End-to-end ASR Systems"}, {"paperId": "7e05eb04d83b07014e7b2018666358ff5b9432a7", "title": "Compression of End-to-End Models"}, {"paperId": "0d3c436a4236daa236617e0e01d2ff031a8459e1", "title": "Segmental Encoder-Decoder Models for Large Vocabulary Automatic Speech Recognition"}, {"paperId": "da6a90a65e995fe25774a88e581c276418db6546", "title": "Improving Attention Based Sequence-to-Sequence Models for End-to-End English Conversational Speech Recognition"}, {"paperId": "11f592a21ce1e806b264742c761aca0732c2ead1", "title": "Lattice-free State-level Minimum Bayes Risk Training of Acoustic Models"}, {"paperId": "a008575ae2b717024af840905ebbc5a65f18b5c3", "title": "Forward-Backward Attention Decoder"}, {"paperId": "83c54cdaf1979235ec12f1c3f08705ce5ffb9de3", "title": "End-to-end Speech Recognition with Adaptive Computation Steps"}, {"paperId": "fc097d528fd62fe76d73fafbf0c57473b58d1e84", "title": "Correcting Length Bias in Neural Machine Translation"}, {"paperId": "b9de9599d7241459db9213b5cdd7059696f5ef8d", "title": "Character-Level Language Modeling with Deeper Self-Attention"}, {"paperId": "790eb7e93f1d3fce470c0222fd2be83bab55a428", "title": "End-to-end Speech Recognition With Word-Based Rnn Language Models"}, {"paperId": "8829ed626a278c2eba686ff973496f7c0825a2e8", "title": "Deep Context: End-to-end Contextual Speech Recognition"}, {"paperId": "8e73bd32fcad5018ab8bd48df1616a65c288308b", "title": "Dialog-Context Aware end-to-end Speech Recognition"}, {"paperId": "3edfccbe6adf18f5263cd2adf3d977bbc5811e0b", "title": "Back-Translation-Style Data Augmentation for end-to-end ASR"}, {"paperId": "abd91aca4d78799492256b406f5abc199d3802e4", "title": "Multilingual End-to-End Speech Recognition with A Single Transformer on Low-Resource Languages"}, {"paperId": "f0ead45e8c1e4cc390ff6603bc0738b8c57f99ec", "title": "Improved training of end-to-end attention models for speech recognition"}, {"paperId": "26eb7507bff6201a2802236fc3d0a5848a5d906f", "title": "Evaluation of Feature-Space Speaker Adaptation for End-to-End Acoustic Models"}, {"paperId": "1296631b36a3b390466978f4fd80b683bf13573a", "title": "RETURNN as a Generic Flexible Neural Toolkit with Application to Translation and Speech Recognition"}, {"paperId": "41a78e2885b5dc8c719495a33985b5f4880f5b48", "title": "Speech-Transformer: A No-Recurrence Sequence-to-Sequence Model for Speech Recognition"}, {"paperId": "11bfd15381ef914e9ec1e432cef438f92b0e8811", "title": "SEQUENCE TRAINING OF ENCODER-DECODER MODEL USING POLICY GRADIENT FOR END- TO-END SPEECH RECOGNITION"}, {"paperId": "a010b3aa83d7d80e52c84d5f239f940eb33df904", "title": "Multi-Modal Data Augmentation for End-to-end ASR"}, {"paperId": "680aafd3d51e666b297e27b93d9554cc2caf1c4d", "title": "An Analysis of Neural Language Modeling at Multiple Scales"}, {"paperId": "608e4bbe7a2d6f04d68b5747d9d0778d5fce47df", "title": "Learning Longer-term Dependencies in RNNs with Auxiliary Losses"}, {"paperId": "1e077413b25c4d34945cc2707e17e46ed4fe784a", "title": "Universal Language Model Fine-tuning for Text Classification"}, {"paperId": "f0afdccf2903039d202085a771953a171dfd57b1", "title": "Monotonic Chunkwise Attention"}, {"paperId": "478d6102a2df86b0f4e69e398f96619312ecdc8c", "title": "An Analysis of Incorporating an External Language Model into a Sequence-to-Sequence Model"}, {"paperId": "0988c200659858ba6b8a203aea69b0168f5c2660", "title": "Minimum Word Error Rate Training for Attention-Based Sequence-to-Sequence Models"}, {"paperId": "bd62a42eed5991958b30934c557c33d0c6f0f25e", "title": "Improving the Performance of Online Neural Transducer Models"}, {"paperId": "8eff044945bf2543d210adb1e327b8957a219e4d", "title": "No Need for a Lexicon? Evaluating the Value of the Pronunciation Lexica in End-to-End Models"}, {"paperId": "c6b61535f1544835cca3851ceb34222ebc5b4377", "title": "State-of-the-Art Speech Recognition with Sequence-to-Sequence Models"}, {"paperId": "e1a20480e4168d58deec743035b7ff02720672d7", "title": "Multi-level language modeling and decoding for open vocabulary end-to-end speech recognition"}, {"paperId": "af10f3c1c0859aa620623f760c8a29e78f177f7f", "title": "Population Based Training of Neural Networks"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "3299aee7a354877e43339d06abb967af2be8b872", "title": "Don't Decay the Learning Rate, Increase the Batch Size"}, {"paperId": "7b664013c31d8f55a7cc290de9d7b160e35ef5b4", "title": "Sequence-to-Sequence Asr Optimization Via Reinforcement Learning"}, {"paperId": "8fcd012e8ed2ea8190163369c9f222178e70a19d", "title": "Hybrid CTC/Attention Architecture for End-to-End Speech Recognition"}, {"paperId": "33125ec92a0b4b1687ccd153762d6275668e3d09", "title": "Cold Fusion: Training Seq2Seq Models Together with Language Models"}, {"paperId": "7703a2c5468ecbee5b62c048339a03358ed5fe19", "title": "Recurrent Neural Aligner: An Encoder-Decoder Neural Network Model for Sequence to Sequence Mapping"}, {"paperId": "6cc68e8adf34b580f3f37d1bd267ee701974edde", "title": "A Comparison of Sequence-to-Sequence Models for Speech Recognition"}, {"paperId": "2ec4f0035b840b4d90a114b298aaa1f4551a93d1", "title": "CTC in the Context of Generalized Full-Sum HMM Training"}, {"paperId": "6e8b1bd63e0e33fe633d00742560de1a4ea8e30f", "title": "Gaussian Prediction Based Attention for Online End-to-End Speech Recognition"}, {"paperId": "1ca4670e9967fcb91ef1826f52d4d621fa7a950d", "title": "Listening while speaking: Speech chain by deep learning"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "c102ac8c779ee0a53dc8e4ee20b4088ac2c7e186", "title": "Advances in Joint CTC-Attention Based End-to-End Speech Recognition with a Deep CNN Encoder and RNN-LM"}, {"paperId": "106d5e0cf44ea08500adc91c4d5bb3e6c8a4d627", "title": "Six Challenges for Neural Machine Translation"}, {"paperId": "2dfeb5a90abc49ab2a80a492a01a4e2c8e92ec22", "title": "In-datacenter performance analysis of a tensor processing unit"}, {"paperId": "4fc645df0046a6d7bdeaae8cb20f36b2542bac86", "title": "Multitask Learning with Low-Level Auxiliary Tasks for Encoder-Decoder Based Speech Recognition"}, {"paperId": "76faaf292c6d9dc29d3a99300a7fdd7a35d6d107", "title": "Online and Linear-Time Attention by Enforcing Monotonic Alignments"}, {"paperId": "c888022dec626171d243d2a056709b9b053a0ed9", "title": "Multichannel End-to-end Speech Recognition"}, {"paperId": "e10030a7ad71b7954a81de57e5e60de768a905a0", "title": "Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence Labelling"}, {"paperId": "88caa4a0253a8b0076176745ebc072864eab66e1", "title": "Language Modeling with Gated Convolutional Networks"}, {"paperId": "7dbb2d983ab95da04e5d47c87ddd2cd9a8f20786", "title": "Towards Better Decoding and Language Model Integration in Sequence to Sequence Models"}, {"paperId": "b0c5a4f8c833a4bcbe96f17a1e9323a5d46a02f4", "title": "Convolutional Neural Network Language Models"}, {"paperId": "b1cb867270f87f96397cb5f0d76cbb58cdf2c2f2", "title": "Neural Speech Recognizer: Acoustic-to-Word LSTM Model for Large Vocabulary Speech Recognition"}, {"paperId": "8aa3358a34a17abd0a65622aad8c85317b851af4", "title": "Very deep convolutional networks for end-to-end speech recognition"}, {"paperId": "105788dd22393d5a4333c167814ec3d38c7d6612", "title": "Latent Sequence Decompositions"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "9af2264799bdc3490e4650e2f5d126762caf420f", "title": "Joint CTC-attention based end-to-end speech recognition using multi-task learning"}, {"paperId": "f4819c08515a03f086ada34f5babbe3395b3ffe9", "title": "Character-level language modeling with hierarchical recurrent neural networks"}, {"paperId": "81fdda553e8d06e94f98dbb795bd8ff7d2dfc4ad", "title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System"}, {"paperId": "6ce6a9a30cd69bd2842a4b581cf48c6815bdfdd8", "title": "Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI"}, {"paperId": "8292f8f0ffa5b665d57b3fd7fe9be66a6789c804", "title": "GMM-Free Flat Start Sequence-Discriminative DNN Training"}, {"paperId": "ef3164da73e8539598d851a3c069bd78d4b90adf", "title": "Returnn: The RWTH extensible training framework for universal recurrent neural networks"}, {"paperId": "055681baf0722ef6ed3e27ade1e5d7c99efefa6c", "title": "A comprehensive study of deep bidirectional LSTM RNNS for acoustic modeling in speech recognition"}, {"paperId": "4e912f84a498e883d7b15311007e3ac5635af883", "title": "Length bias in Encoder Decoder Models and a Case for Global Conditioning"}, {"paperId": "9f0687bcd0a7d7fc91b8c5d36c003a38b8853105", "title": "Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "b63bd17d4bb28ba90cc6ff66b51ba5b0377467bf", "title": "Minimum word error training of long short-term memory recurrent neural network language models for speech recognition"}, {"paperId": "a5c7e4f9600952996cc3dfeca58ce2176bee6360", "title": "Audio Word2Vec: Unsupervised Learning of Audio Segment Representations Using Sequence-to-Sequence Autoencoder"}, {"paperId": "77854e1a86835065b77b7b15ffabb34f3853f4a2", "title": "On training the recurrent neural network encoder-decoder for large vocabulary end-to-end speech recognition"}, {"paperId": "33108287fbc8d94160787d7b2c7ef249d3ad6437", "title": "Modeling Coverage for Neural Machine Translation"}, {"paperId": "13497bd108d4412d02050e646235f456568cf822", "title": "Deep Speech 2 : End-to-End Speech Recognition in English and Mandarin"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "80c4e5546f5cd5156408b49ed133cdd265fd60cc", "title": "Speaker location and microphone spacing invariant acoustic modeling from raw multichannel waveforms"}, {"paperId": "a546966db50cc8fdef98bb744990f35248932930", "title": "Adding Gradient Noise Improves Learning for Very Deep Networks"}, {"paperId": "a418524a3576afff4dc2178ed169e692915bd46b", "title": "An Online Sequence-to-Sequence Model Using Partial Conditioning"}, {"paperId": "37ac5eaad66955ded22bbb50603f9d1a4f15f3d6", "title": "Multilingual representations for low resource speech recognition and keyword search"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "878ba5458e9e51f0b341fd9117fa0b43ef4096d3", "title": "End-to-end attention-based large vocabulary speech recognition"}, {"paperId": "3056add22b20e3361c38c0472d294a79d4031cb4", "title": "Listen, attend and spell: A neural network for large vocabulary conversational speech recognition"}, {"paperId": "97acdfb3d247f8250d865ef8a9169f06e40f138b", "title": "EESEN: End-to-end speech recognition using deep RNN models and WFST-based decoding"}, {"paperId": "b624504240fa52ab76167acfe3156150ca01cf3b", "title": "Attention-Based Models for Speech Recognition"}, {"paperId": "df137487e20ba7c6e1e2b9a1e749f2a578b5ad99", "title": "Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks"}, {"paperId": "f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6", "title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning"}, {"paperId": "cf61e34f6843be64e7d39bf11670ebd11747be24", "title": "A nonmonotone learning rate strategy for SGD training of deep neural networks"}, {"paperId": "34038d9424ce602d7ac917a4e582d977725d4393", "title": "Librispeech: An ASR corpus based on public domain audio books"}, {"paperId": "f3bca263a92b69c6da872a9a3268f260ba43f690", "title": "Discriminative method for recurrent neural network language models"}, {"paperId": "5fcd41ca42659ff792fc8ee7d535156e8e69f987", "title": "On Using Monolingual Corpora in Neural Machine Translation"}, {"paperId": "8cb72cf5490c2a532d52237f688f915a92afe04c", "title": "From Feedforward to Recurrent LSTM Neural Networks for Language Modeling"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "24741d280869ad9c60321f5ab6e5f01b7852507d", "title": "Deep Speech: Scaling up end-to-end speech recognition"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "79d1e429c241d0aa47a2194246256a5bc79585bc", "title": "First-Pass Large Vocabulary Continuous Speech Recognition using Bi-Directional Recurrent DNNs"}, {"paperId": "0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f", "title": "Towards End-To-End Speech Recognition with Recurrent Neural Networks"}, {"paperId": "31d3686b33a89488f8b0235a3fd7c8112a00f990", "title": "Real-time one-pass decoding with recurrent neural network language model for speech recognition"}, {"paperId": "efbdeb8d4b7b999c19b76b9ddaf49ac668d88c55", "title": "GMM-free DNN acoustic model training"}, {"paperId": "e11274bb4549fbdb9a7ab64d09076976e6f71e75", "title": "Cache based recurrent neural network language model inference for first pass speech recognition"}, {"paperId": "193edd20cae92c6759c18ce93eeea96afd9528eb", "title": "Deep learning in neural networks: An overview"}, {"paperId": "92850166532c28d1dcec87dd0ac2316c9f27eebd", "title": "Elastic spectral distortion for low resource speech recognition with deep neural networks"}, {"paperId": "6471fd1cbc081fb3b7b5b14d6ab9eaaba02b5c17", "title": "Generating Sequences With Recurrent Neural Networks"}, {"paperId": "38f35dd624cd1cf827416e31ac5e0e0454028eca", "title": "Regularization of Neural Networks using DropConnect"}, {"paperId": "aa7bfd2304201afbb19971ebde87b17e40242e91", "title": "On the importance of initialization and momentum in deep learning"}, {"paperId": "777a6fe47b9c961c0f79814b1375b6547bcfde0c", "title": "Investigation on cross- and multilingual MLP features under matched and mismatched acoustical conditions"}, {"paperId": "2f768dda2f047a067aa56a20c9e322b15ef60331", "title": "An empirical study of learning rates in deep neural networks for speech recognition"}, {"paperId": "4177ec52d1b80ed57f2e72b0f9a42365f1a8598d", "title": "Speech recognition with deep recurrent neural networks"}, {"paperId": "452693e033ab33e9e5d357d16d42e56e7c008b23", "title": "Learning Lexicons From Speech Using a Pronunciation Mixture Model"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "7b4f3d0e4e2486a8d5d3f8e00549cf9a117bf88f", "title": "Sequence Transduction with Recurrent Neural Networks"}, {"paperId": "cda3ebb5cfaa9cf1a098512bec07f883d4b026ba", "title": "Discriminative Training for Automatic Speech Recognition: Modeling, Criteria, Optimization, Implementation, and Performance"}, {"paperId": "0060745e006c5f14ec326904119dca19c6545e51", "title": "Improving neural networks by preventing co-adaptation of feature detectors"}, {"paperId": "473f0739666af2791ad6592822118240ed968b70", "title": "Conversational Speech Transcription Using Context-Dependent Deep Neural Networks"}, {"paperId": "522e90b9fccfd3c1c0603359eb04757d770c1ab5", "title": "Practical Recommendations for Gradient-Based Training of Deep Architectures"}, {"paperId": "ed6262b569c0a62c51d941228c54f34e563af022", "title": "Japanese and Korean voice search"}, {"paperId": "5a9ef216bf11f222438fff130c778267d39a9564", "title": "Practical Variational Inference for Neural Networks"}, {"paperId": "bc1022b031dc6c7019696492e8116598097a8c12", "title": "Natural Language Processing (Almost) from Scratch"}, {"paperId": "8de174ab5419b9d3127695405efd079808e956e8", "title": "Curriculum learning"}, {"paperId": "2443dc59cf3d6cc1deba6d3220d61664b1a7eada", "title": "Lattice-based optimization of sequence classification criteria for neural-network acoustic modeling"}, {"paperId": "d63cdc1d1f023c63f8aa3b64cd5e853670680c3e", "title": "Discriminative learning in sequential pattern recognition"}, {"paperId": "355d44f53428b1ac4fb2ab468d593c720640e5bd", "title": "Greedy Layer-Wise Training of Deep Networks"}, {"paperId": "10d21ca7728cb3dd15731accedda9ea711d8a0f4", "title": "An End-to-End Discriminative Approach to Machine Translation"}, {"paperId": "8978cf7574ceb35f4c3096be768c7547b28a35d0", "title": "A Fast Learning Algorithm for Deep Belief Nets"}, {"paperId": "261a056f8b21918e8616a429b2df6e1d5d33be41", "title": "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks"}, {"paperId": "e35a50c251edc9e1ebcd919c09413661420c7ccf", "title": "The IBM 2004 conversational telephony system for rich transcription"}, {"paperId": "6c2b28f9354f667cd5bd07afc0471d8334430da7", "title": "A Neural Probabilistic Language Model"}, {"paperId": "d73d5fdb90fd3abcab3954d2bfd14b8d67473bed", "title": "Testing the correlation of word error rate and perplexity"}, {"paperId": "e41498c05d4c68e4750fb84a380317a112d97b01", "title": "Connectionist language modeling for large vocabulary continuous speech recognition"}, {"paperId": "261bb02e9ad706ef5a4b0cf07bfc9929b988418e", "title": "Context-dependent acoustic modeling using graphemes for large vocabulary speech recognition"}, {"paperId": "a2fa4beb417215d721f0a4aeee72d49347c966e3", "title": "Comparison of discriminative training criteria and optimization methods for speech recognition"}, {"paperId": "067120574d64e37be5fa66591a6d0115d9a6d561", "title": "Improved discriminative training techniques for large vocabulary continuous speech recognition"}, {"paperId": "e653891a9a9ac5585abb3348732d7e5a8f4e686c", "title": "Model-based MCE bound to the true Bayes' error"}, {"paperId": "5e9082caea65c76bfd23b8763872804473ee7872", "title": "Tandem connectionist feature extraction for conventional HMM systems"}, {"paperId": "192f8892ace3162496774c4dec253960c018994e", "title": "Hierarchical search for large-vocabulary conversational speech recognition: working toward a solution to the decoding problem"}, {"paperId": "c9942d4ac23892f7e51ed7a401a6e50faa3aade4", "title": "Single-tree method for grammar-directed search"}, {"paperId": "1c042697ed01051f384fe6dc86ee258796e9f301", "title": "Progress in dynamic programming search for LVCSR"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "4f69c15fc559c5eb893c47f7de727ee4ffad6f5e", "title": "Nonlinear discriminant analysis for improved speech recognition"}, {"paperId": "e931146bf240bd83bb720c3dfdc5ad81951e34bb", "title": "MMIE training of large vocabulary recognition systems"}, {"paperId": "d4e8bed3b50a035e1eabad614fe4218a34b3b178", "title": "An Empirical Study of Smoothing Techniques for Language Modeling"}, {"paperId": "be1c1f5ee7ad3a49206b174201e495488494a85e", "title": "State of the art in continuous speech recognition."}, {"paperId": "67f052a08bc272130d3e4554ca9e00a190a1cb98", "title": "Multiple-pronunciation lexical modeling in a speaker independent speech understanding system"}, {"paperId": "60e66781bf17f8103bbc57fc5daeb6fbc5e4b910", "title": "Enhanced MLP performance and fault tolerance resulting from synaptic weight noise during training"}, {"paperId": "25c7c505653b42da5f59700f987fdd14931684c1", "title": "Improvements in beam search for 10000-word continuous-speech recognition"}, {"paperId": "3d82e058a5c40954b8f5db170a298a889a254c37", "title": "Connectionist Speech Recognition: A Hybrid Approach"}, {"paperId": "f5628a2be47e10b991ee18e24dde7e14580ccf8c", "title": "The use of state tying in continuous speech recognition"}, {"paperId": "5aee00262285c4a26ec77af355ab86cd2d92b403", "title": "Connectionist speech recognition with a global MMI algorithm"}, {"paperId": "d5ddb30bf421bdfdf728b636993dc48b1e879176", "title": "Learning and development in neural networks: the importance of starting small"}, {"paperId": "d80000d84223e177d070a01a734dba56d5f5c069", "title": "SWITCHBOARD: telephone speech corpus for research and development"}, {"paperId": "5a26b1e04cf5090a7026928bfb4e546cd45c6582", "title": "Neural Network - Gaussian Mixture Hybrid for Speech Recognition or Density Estimation"}, {"paperId": "48e1de7d085808004d5f0493d486669a3d2930b5", "title": "A Simple Weight Decay Can Improve Generalization"}, {"paperId": "2ae5a5507253aa3cada113d41d35fada1e84555f", "title": "An Efficient Gradient-Based Algorithm for On-Line Training of Recurrent Network Trajectories"}, {"paperId": "1a3d22599028a05669e884f3eaf19a342e190a87", "title": "Backpropagation Through Time: What It Does and How to Do It"}, {"paperId": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5", "title": "A tutorial on hidden Markov models and selected applications in speech recognition"}, {"paperId": "52f164f715febf097b8756a7308b416539b7c7da", "title": "A study of English word category prediction based on neural networks"}, {"paperId": "f7472c65c41facdc3eb1729706bb0ed97a2ca031", "title": "Accelerating the convergence of the back-propagation method"}, {"paperId": "1e4193d03eb3c5a695a3d8b3506f80704f9dfc19", "title": "The use of a one-stage dynamic programming algorithm for connected word recognition"}, {"paperId": "c4775e2f0d27e8be4aae7b5b5c2560b96ce2eb58", "title": "A Maximum Likelihood Approach to Continuous Speech Recognition"}, {"paperId": "145c0b53514b02bdc3dadfb2e1cea124f2abd99b", "title": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "495364aefa4dfef25e534582c4310ed4785c7dfd", "title": "A comprehensive analysis on attention models"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "7f39f8275ac2dffdfec9c8fb0ea26b5eaeda0bd7", "title": "Hybrid CTC / Attention Architecture for End-to-end Speech Recognition"}, {"paperId": null, "title": "\u201cUniversal language model \ufb01ne-tuning for text classi\ufb01cation,\u201d"}, {"paperId": "4cd66273298128dfb5be290e891870085ecfc455", "title": "Joint CTC/attention decoding for end-to-end speech recognition"}, {"paperId": "66661a68dbf1d98d794fd025113b103683510303", "title": "Audio augmentation for speech recognition"}, {"paperId": "dae891c65f9c555cff233fe4bf6502d283c31ecd", "title": "Acoustic modeling with deep neural networks using raw time signal for LVCSR"}, {"paperId": "f79174a79b0391b6c75035abe1ebc7f5d52445f6", "title": "Vocal Tract Length Perturbation (VTLP) improves speech recognition"}, {"paperId": null, "title": "Speech Recognition Algorithms Using Weighted Finite-State Transducers"}, {"paperId": null, "title": "\u201cEstimating or propagating gradientsthroughstochasticneuronsforconditionalcomputation"}, {"paperId": "84ed475714183a93906baade15c69216e77fa837", "title": "Connectionist Temporal Classification"}, {"paperId": "f9a1b3850dfd837793743565a8af95973d395a4e", "title": "LSTM Neural Networks for Language Modeling"}, {"paperId": "9819b600a828a57e1cde047bbe710d3446b30da5", "title": "Recurrent neural network based language model"}, {"paperId": "f6160beb28fed94ff8a1c46b00c4b50c4f42a3e9", "title": "A discriminative splitting criterion for phonetic decision trees"}, {"paperId": "f2e1c750d4bff9427b20d09a9c320b4f8ab929db", "title": "On the use of a multilingual neural network front-end"}, {"paperId": null, "title": "\u201cQuickNet,\u201d"}, {"paperId": "bc9b8023d0a7f881c0dd29f7e206f3fc6c28669e", "title": "An essay towards solving a problem in the doctrine of chances"}, {"paperId": null, "title": "\u201cOn the relationship between classi\ufb01cation error bounds and training criteria in statistical pattern recognition,\u201d"}, {"paperId": "a80a452e587bd7f06ece1be101d6775fcee0f7af", "title": "Weighted finite-state transducers in speech recognition"}, {"paperId": "231f6de83cfa4d641da1681e97a11b689a48e3aa", "title": "Statistical methods for speech recognition"}, {"paperId": "818d46d3600b0a027fc6af8c74fd37416963ef42", "title": "Connectionist Speech Recognition: Status and Prospects"}, {"paperId": "385622a5862c989653a648ac8abc59ae3fe785f7", "title": "An introduction to hidden Markov models"}, {"paperId": null, "title": "Classication and Regression Trees"}, {"paperId": "8d3a318b62d2e970122da35b2a2e70a5d12cc16f", "title": "A method for solving the convex programming problem with convergence rate O(1/k^2)"}, {"paperId": "539036ab9e8f038c8a948596e77cc0dfcfa91fb3", "title": "An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process"}, {"paperId": "4b53e3f719ff983eef867c6d8deac5dbe38aecb4", "title": "Some methods of speeding up the convergence of iteration methods"}, {"paperId": "2bcf3e6c2b45c052a0bd0183cc29c03acc4b49ac", "title": "Human behavior and the principle of least effort"}, {"paperId": "4954fa180728932959997a4768411ff9136aac81", "title": "This Paper Is Included in the Proceedings of the 12th Usenix Symposium on Operating Systems Design and Implementation (osdi '16). Tensorflow: a System for Large-scale Machine Learning Tensorflow: a System for Large-scale Machine Learning"}, {"paperId": null, "title": "LearningandHumanLanguageTechnology healsojoinedAppTekGmbHAachenasSeniorRe-searcher"}, {"paperId": null, "title": "Takaaki Hori is with Apple Inc., Cambridge, MA 02142 USA"}, {"paperId": null, "title": "hewasaSeniorPrincipalResearchScien-tistwithMitsubishiElectricResearchLaboratories, Cambridge,MA,USA.HeiscurrentlyaMachine LearningResearcherwithApple"}, {"paperId": null, "title": "Themainfocusofher Ph.D.workwasinacousticmodelingfornoiserobustspeechrecognition.AfterherPh.D.,shespent\ufb01ve yearswithSpeechandLanguageAlgorithmsGroup,IBMThomasJ."}, {"paperId": null, "title": "Sainath is with Google LLC., New York, NY 10011 USA"}, {"paperId": null, "title": "\u201cEmformer: Ef\ufb01cient Memory Transformer based Acoustic"}, {"paperId": null, "title": "\u201cCambridge Dictionary,\u201d"}]}