{"paperId": "1f43c1f42dd5505f27c0b36c99e6e6fa01f87ad5", "title": "Transformer-Lite: High-efficiency Deployment of Large Language Models on Mobile Phone GPUs", "abstract": "The Large Language Model (LLM) is widely employed for tasks such as intelligent assistants, text summarization, translation, and multi-modality on mobile phones. However, the current methods for on-device LLM deployment maintain slow inference speed, which causes poor user experience. To facilitate high-efficiency LLM deployment on device GPUs, we propose four optimization techniques: (a) a symbolic expression-based approach to support dynamic shape model inference; (b) operator optimizations and execution priority setting to enhance inference speed and reduce phone lagging; (c) an FP4 quantization method termed M0E4 to reduce dequantization overhead; (d) a sub-tensor-based technique to eliminate the need for copying KV cache after LLM inference. Furthermore, we implement these methods in our mobile inference engine, Transformer-Lite, which is compatible with both Qualcomm and MTK processors. We evaluated Transformer-Lite's performance using LLMs with varied architectures and parameters ranging from 2B to 14B. Specifically, we achieved prefill and decoding speeds of 121 token/s and 14 token/s for ChatGLM2 6B, and 330 token/s and 30 token/s for smaller Gemma 2B, respectively. Compared with CPU-based FastLLM and GPU-based MLC-LLM, our engine attains over 10x speedup for the prefill speed and 2~3x speedup for the decoding speed.", "venue": "arXiv.org", "year": 2024, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "To facilitate high-efficiency LLM deployment on device GPUs, this work proposes four optimization techniques: a symbolic expression-based approach to support dynamic shape model inference, a symbolic expression-based approach to support dynamic shape model inference, an FP4 quantization method termed M0E4 to reduce dequantization overhead, and a sub-tensor-based technique to eliminate the need for copying KV cache after LLM inference."}, "embedding": {"model": "specter_v2", "vector": [0.15718507766723633, 0.32093286514282227, -0.7475324273109436, 0.1559353619813919, -0.6064158082008362, -0.09428533911705017, 0.4458150863647461, -0.19170117378234863, -0.3022977411746979, -0.3698527216911316, 0.795591413974762, -0.2928357422351837, 0.5130314826965332, 0.10924465209245682, 0.21461504697799683, 0.1897398680448532, -0.9201923608779907, 0.3231591284275055, -0.22757771611213684, -0.17579498887062073, 0.05563117563724518, -0.4967108964920044, -0.8847601413726807, 0.5421125888824463, 0.4171496629714966, 0.7941403985023499, -0.09673992544412613, 1.1849944591522217, -0.4866369366645813, 0.4637874662876129, 0.42613279819488525, -0.2219437062740326, -0.027705376967787743, 0.26262781023979187, -0.1418633908033371, -0.08950795233249664, -0.09151367098093033, -0.6882432699203491, -0.02662242390215397, 0.9243981838226318, 0.03219703212380409, 0.11883848160505295, 0.37270820140838623, -0.5850223898887634, -0.16323943436145782, 0.4428379237651825, 0.2968849241733551, 0.5169062614440918, -0.09107895940542221, -0.5463340282440186, 1.0644145011901855, -1.5335348844528198, 0.03217596188187599, 1.540663719177246, 0.48733609914779663, -0.04905884712934494, 0.07177180796861649, -0.23818740248680115, 0.36594656109809875, -0.20941632986068726, -1.039929986000061, -0.8866034150123596, -0.29110121726989746, -0.030879467725753784, 1.8106818199157715, 0.010859266854822636, -0.11341967433691025, 0.1749817430973053, 0.12516333162784576, 1.3603098392486572, -0.10491910576820374, -0.706505298614502, 0.02657981403172016, -0.33450573682785034, 0.10366075485944748, 1.0523332357406616, -0.28294575214385986, -0.25067460536956787, -0.8257045149803162, -0.5523616075515747, 0.4547893702983856, -0.2935587167739868, 0.36439329385757446, 0.14021115005016327, -0.5541832447052002, 0.6531868577003479, -0.2907375693321228, 0.3980537950992584, -0.09849447757005692, 0.6403734087944031, 1.0588806867599487, 0.08892126381397247, 0.15567241609096527, -0.21689707040786743, 0.032957665622234344, -0.2716001570224762, -1.061173915863037, 0.40832582116127014, 0.16845957934856415, 0.8097730278968811, -0.629578709602356, 0.4146890342235565, -1.102380633354187, 0.29903435707092285, 1.3303601741790771, 0.6398265957832336, 0.10365999490022659, -0.8695021867752075, 0.21898095309734344, -0.7734693884849548, 0.5338267683982849, -0.6717230677604675, -0.1950313001871109, 0.08164004981517792, -1.0170903205871582, -1.1794261932373047, -0.38153770565986633, -0.05792874097824097, -0.6245061159133911, 0.18188901245594025, -0.41178563237190247, 0.16527195274829865, 0.28008270263671875, 0.08687293529510498, 0.8363804221153259, 0.6603159308433533, 0.033704306930303574, -0.12361764162778854, 1.3584588766098022, -0.9199034571647644, -0.7420574426651001, -0.9857269525527954, 0.9692572951316833, -0.4625241160392761, -0.025634679943323135, -0.1375064253807068, -1.4809447526931763, -0.860555112361908, -0.568989098072052, -0.2731388807296753, -0.4099913239479065, 0.8185736536979675, 0.9342948198318481, 0.3346925973892212, -1.2201405763626099, 0.16867659986019135, -0.14683903753757477, -0.1570248156785965, 0.22530201077461243, 0.30674049258232117, 0.6586841344833374, -0.31459730863571167, -1.1349116563796997, 0.022127259522676468, 0.1580059975385666, -0.44526511430740356, 0.3150556683540344, -0.22507600486278534, -1.0440301895141602, -0.23560908436775208, 0.2422284185886383, -0.3990457057952881, 1.3348077535629272, 0.5708118081092834, -1.5987952947616577, 0.503526508808136, -0.5845807790756226, 0.26902684569358826, -0.08939353376626968, -0.06072914972901344, -0.5405649542808533, -0.3862324059009552, -0.290398508310318, 0.3069886863231659, 0.5902935862541199, -0.0490499846637249, -0.5437390804290771, 0.26734021306037903, -0.24786315858364105, 0.24014337360858917, 0.13539715111255646, 1.409042477607727, -0.8130581974983215, -0.08209763467311859, 0.0037317571695894003, 0.4006401598453522, -0.2929264307022095, -0.142475426197052, -0.3508654236793518, -0.7203956842422485, 0.9551600217819214, -0.38508930802345276, 1.5524202585220337, -0.7690944075584412, -0.8142817616462708, -0.10013231635093689, 0.008993275463581085, 0.3514855206012726, -0.434186726808548, 0.3607284426689148, 0.15362133085727692, 0.12863552570343018, 0.12795133888721466, -0.820012092590332, 0.2140382081270218, -0.16768628358840942, -0.813328206539154, -0.3994292914867401, -0.13330580294132233, 1.3724912405014038, -0.9376500844955444, -0.021370885893702507, -0.11180641502141953, 0.015470946207642555, -0.9426605701446533, 0.9505648016929626, -0.539502739906311, 0.17403213679790497, -0.4176005721092224, -0.0022553878370672464, 0.3250178396701813, -0.24390384554862976, 0.6079095602035522, -0.7265859842300415, -0.37606626749038696, 0.2179155945777893, -0.5143461227416992, 1.3694021701812744, -0.09511932730674744, 0.2724893093109131, 0.23858696222305298, -0.3538629710674286, 0.3045157790184021, 0.3702285587787628, -0.2494545429944992, -0.3380332887172699, 0.4648323357105255, 0.6521509289741516, -0.5808372497558594, 0.09415540844202042, 1.1740772724151611, 1.1017223596572876, -0.9327383637428284, 0.21122996509075165, -0.09362930804491043, -0.15329094231128693, 0.5261142253875732, 0.33514833450317383, 0.42477330565452576, 0.17828230559825897, 0.353440523147583, -0.1593284159898758, 0.5311341285705566, -0.739942729473114, -0.24558579921722412, 0.7365427017211914, 0.61809903383255, 0.5677412748336792, 0.5162464380264282, -0.6654660105705261, -0.3749329149723053, 0.19237391650676727, 0.9030080437660217, 1.4303498268127441, -0.1303619146347046, -0.4236127436161041, -0.828277051448822, -0.0927882045507431, -0.5115208029747009, -0.12574757635593414, 0.4197152256965637, 0.07673457264900208, -0.6535633206367493, -1.241963267326355, 1.309849739074707, 0.44436511397361755, 1.1669654846191406, -0.48924732208251953, -0.2288338840007782, -0.2906060218811035, -0.014275913126766682, -1.0512186288833618, -0.7465456128120422, -0.14883187413215637, -0.5124227404594421, 0.5054217576980591, -0.016326570883393288, -0.20023104548454285, 0.10784659534692764, -0.7691298723220825, 0.8074976801872253, -0.45257923007011414, -0.0974588692188263, 0.007525590714067221, 0.45053592324256897, -0.4531663656234741, -0.9917930364608765, -0.09457222372293472, 0.16520217061042786, -0.17134656012058258, 0.26616767048835754, 0.6893062591552734, 0.23877105116844177, -0.2119821161031723, -0.01482788659632206, 0.3383658230304718, 0.025342216715216637, -0.26774364709854126, 0.34826573729515076, -0.2371477484703064, -0.28089991211891174, -0.5696200132369995, 1.3180540800094604, 0.5976682901382446, -0.26898348331451416, 0.3077901601791382, -0.3751470744609833, -0.2784755825996399, 0.3892700970172882, -0.5037452578544617, -0.36414167284965515, -1.23664391040802, 0.14176397025585175, 0.1379038244485855, 0.0357792042195797, 0.4038061797618866, 0.002841110108420253, 0.10588601231575012, -0.22481051087379456, 0.75645512342453, 0.5642098784446716, -0.24953565001487732, 0.7465698719024658, -0.1309148073196411, 0.5090042352676392, -0.03472604975104332, -0.32293620705604553, 0.018465202301740646, -0.2743012309074402, -0.9176420569419861, -0.12201324850320816, -0.3557768762111664, -0.11719062179327011, -0.10319406539201736, 0.15533891320228577, -0.5472370982170105, -0.9412441253662109, 0.34328654408454895, -1.5222387313842773, -0.23084090650081635, 0.4752788841724396, -0.44104480743408203, -0.1619063913822174, -0.6114669442176819, -1.4781197309494019, -0.6523563861846924, -0.9383572936058044, -1.3031338453292847, 0.8228878974914551, -0.3052237629890442, -0.5274779796600342, -0.4986254870891571, -0.32110947370529175, -0.46351271867752075, 0.8452379703521729, -0.6005402207374573, 0.8525381684303284, 0.29398322105407715, -0.021017365157604218, -0.1911432445049286, -0.17273612320423126, 0.19714918732643127, -0.20006941258907318, 0.25239717960357666, -0.35083821415901184, 0.21020326018333435, -0.3442949950695038, 0.2109442502260208, -0.099387027323246, 0.5261566638946533, 0.6309080123901367, 0.09355764836072922, -0.6101725697517395, 0.116143137216568, 0.8714371919631958, -0.5712854862213135, 0.4102286696434021, -0.27602821588516235, 1.3315041065216064, -0.12560009956359863, -0.017209427431225777, 0.9624830484390259, 0.25736621022224426, 0.966852068901062, -0.2448170930147171, -0.4810969829559326, 0.0926300585269928, -0.06824112683534622, 1.016865849494934, 2.012815237045288, 0.20284254848957062, -0.233462393283844, -0.6665276288986206, 0.23614588379859924, -1.5340039730072021, -0.5287401676177979, 0.25462737679481506, 0.6273348331451416, 0.12811946868896484, -0.3167056739330292, -0.020344814285635948, -0.18128184974193573, 0.4651244282722473, 0.5484890937805176, -0.051054272800683975, -1.3030216693878174, 0.2410266399383545, -0.013164134696125984, 0.36722320318222046, 0.879918098449707, -0.2535618543624878, 0.7626549601554871, 14.833495140075684, 1.4549449682235718, -0.07246764004230499, 0.4068433940410614, 0.6388594508171082, 0.6235656142234802, -0.12503460049629211, -0.40909022092819214, -1.3468468189239502, -0.07420474290847778, 1.4851435422897339, -0.16410736739635468, 0.46461695432662964, -0.019525356590747833, 0.7260400652885437, 0.1843246966600418, -0.1714613139629364, 0.8639029264450073, 0.5327326655387878, -1.4425983428955078, 0.5854499936103821, 0.44535547494888306, -0.022530490532517433, 0.5271947979927063, 0.6498063802719116, 0.7286956906318665, 0.30560657382011414, -0.35483670234680176, 0.5844517946243286, 0.1608281433582306, 1.2030977010726929, -0.3918202817440033, 0.5633700489997864, 0.6116205453872681, -1.2053898572921753, 0.0019728653132915497, -0.4948115050792694, -1.3502862453460693, 0.562149167060852, 0.33023640513420105, -0.7524577975273132, -0.23629558086395264, -0.614199697971344, 0.7829719185829163, 0.36578822135925293, 0.16481971740722656, 0.133793905377388, 0.5234123468399048, -0.058699700981378555, -0.1096067950129509, 0.12349047511816025, -0.018788063898682594, 0.26875072717666626, 0.3132297396659851, 0.1723884493112564, -0.050469107925891876, 0.5132445693016052, 0.30266785621643066, -0.1575755774974823, -0.18456602096557617, -0.2937772572040558, -0.37396034598350525, -0.1525575816631317, 0.6016675233840942, 0.013489602133631706, -0.2150987684726715, -0.5305562019348145, 0.6205726265907288, 0.25646376609802246, 0.0349329337477684, -0.5065315365791321, 0.22193722426891327, 0.5058386325836182, -0.41657665371894836, 0.1843402087688446, 0.20518718659877777, -0.09118258208036423, -0.689979612827301, -0.6953348517417908, -0.8003824949264526, 0.09602873027324677, -0.48184555768966675, -0.2959444522857666, 0.8054273128509521, -0.14391964673995972, -0.4164864420890808, 0.087406687438488, -0.9268949031829834, -0.24148300290107727, 0.41243499517440796, -1.0263340473175049, -0.7531939148902893, 0.8476848602294922, -0.39303192496299744, -0.3475838303565979, 0.32730603218078613, 1.8935424089431763, 0.2463536411523819, -0.2945217490196228, -0.0539274737238884, 0.49957361817359924, 0.08699806779623032, -0.6811773180961609, -0.4367755055427551, 1.3143939971923828, 0.36140692234039307, -0.32150521874427795, 0.3550591468811035, -0.1844770759344101, -0.08903397619724274, -0.970470666885376, -0.18295910954475403, 0.7683793902397156, -0.8824740648269653, -0.3348056674003601, -1.2851670980453491, -0.5616264939308167, 0.01859593391418457, 0.1792207956314087, -0.14776122570037842, 0.15519821643829346, -0.032402973622083664, -0.07354817539453506, -0.026776598766446114, -0.6560205817222595, 0.43732115626335144, 0.32014891505241394, -0.8811225891113281, 0.3284111022949219, -0.20010705292224884, 0.30405816435813904, -1.3984676599502563, -0.7680104374885559, -0.1196286752820015, 0.30638977885246277, 0.06375952064990997, 0.9775322079658508, 0.14463932812213898, 0.26347869634628296, 0.47668156027793884, -0.22287395596504211, -0.3811987638473511, -0.009671290405094624, -1.2241820096969604, -0.2806706428527832, 0.04514215141534805, 0.6298896074295044, -0.08744748681783676, 0.250052809715271, 0.9053614735603333, 0.3647758364677429, -0.7638141512870789, -0.41506585478782654, -0.1698545217514038, -0.14589618146419525, -0.8299223184585571, 0.3115811347961426, -0.6543887257575989, 0.27341315150260925, 0.19064295291900635, 0.09452751278877258, 0.6234413981437683, -0.31329110264778137, -0.49631351232528687, 0.4385995864868164, 0.1793918013572693, -0.017326928675174713, -0.5207929015159607, -0.5545982122421265, -1.8488229513168335, -0.1171717643737793, -1.0264027118682861, 0.2067929059267044, -0.9025734066963196, -0.2552800178527832, 0.23650000989437103, 0.20288923382759094, -0.08896589279174805, 0.37613585591316223, -0.14672142267227173, -0.6109238862991333, -0.5329181551933289, -1.0916273593902588, 0.5741578936576843, 0.9198870658874512, -0.7398833632469177, 0.06464727967977524, -0.11535761505365372, 0.20202410221099854, 0.48883286118507385, 0.33534276485443115, -0.07267480343580246, -0.8223657011985779, -1.1360187530517578, 0.2655579149723053, -0.0678965151309967, -0.06482306122779846, -0.345163494348526, 0.2831677496433258, 0.33223843574523926, -0.47175681591033936, 0.03280073031783104, 0.11759216338396072, -0.25590038299560547, -0.48148444294929504, 0.5029919743537903, -0.5750643610954285, 0.12036062031984329, 0.5357972383499146, -0.907047688961029, -0.031059931963682175, 0.7091358304023743, -0.4870997667312622, -0.8251111507415771, -0.9488171935081482, 0.3604971766471863, -0.878235936164856, 0.13753961026668549, -0.9207878708839417, -0.015732815489172935, -0.8536645770072937, -0.48561838269233704, 0.14759540557861328, -0.16595789790153503, -0.22180050611495972, 1.0448424816131592, 0.49789392948150635, -1.0947740077972412, 0.0024814866483211517, 0.3358317017555237, -0.219471275806427, -0.3109072148799896, 0.15191109478473663, 0.7400975227355957, -0.4108916223049164, 0.4959569573402405, 0.7814863324165344, 0.09600695967674255, -1.2095025777816772, -0.1265236735343933, 0.3993076682090759, -0.6065344214439392, -0.39339640736579895, 0.8452364802360535, -0.6607795357704163, -0.7782436013221741, -0.1911815106868744, -1.6856383085250854, -0.35087189078330994, -0.7979210615158081, 1.1199955940246582, 0.2258557230234146, 0.2744544446468353, -0.42631614208221436, -0.7529935240745544, 0.01921827904880047, -0.12129075080156326, -0.5978325009346008, 0.00922244880348444, -0.4301144778728485, -0.8194206357002258, 0.35417434573173523, 0.7788990139961243, -0.3228161633014679, -0.22545737028121948, -0.4221446216106415, -0.27304908633232117, 0.20204408466815948, 0.5023113489151001, -0.12428268045186996, -0.0639253631234169, 0.5006159543991089, 0.40480804443359375, 0.20082300901412964, -0.07455771416425705, -0.39571449160575867, 0.8740591406822205, 0.523460328578949, 0.3558957278728485, -0.5855624079704285, -0.9136059284210205, 1.4916160106658936, 1.0350722074508667, -0.8125236630439758, 0.2368435114622116, -0.3409488797187805, -0.6953269243240356, 0.6864480972290039, -0.4536615312099457, 0.28663796186447144, 0.7675337195396423, 0.517105758190155, 0.34079769253730774, 0.1770242154598236, -0.588594377040863, -0.3020842373371124, 0.8795136213302612, 0.8400713801383972, 0.7909939289093018, 0.5620659589767456, 0.09053593873977661, 0.7923192977905273, 0.4436008930206299, 0.6799252033233643, 0.41984590888023376, 0.7630393505096436, -0.20362700521945953, -0.334981769323349, -0.3521333634853363, 0.7634663581848145, -0.5045006275177002, -1.069390058517456, 0.423081636428833, 0.1440194845199585, 0.196769118309021, 0.8137511610984802, 0.82227623462677, 0.06577002257108688, 0.41937386989593506, -0.12786056101322174, 0.7790505886077881, -0.6832383275032043, 0.13840699195861816, 0.27409714460372925, -0.19001977145671844, -0.06125011295080185, -0.05250234156847, -0.3456032872200012, -0.929668128490448, -0.5111469030380249, 0.5416857600212097, 0.10248318314552307, 0.10490473359823227, 1.2300598621368408, 0.9307914972305298, 0.19634056091308594, -0.7128989696502686, -0.5954580903053284, -0.2614901661872864, -0.6969832181930542, -0.2732961177825928, -0.48066821694374084, -0.39272481203079224, 0.054525043815374374, 0.10069979727268219, -0.13214677572250366]}, "authors": [{"authorId": "2294329847", "name": "Luchang Li"}, {"authorId": "2294176487", "name": "Sheng Qian"}, {"authorId": "2294317681", "name": "Jie Lu"}, {"authorId": "2294316787", "name": "Lunxi Yuan"}, {"authorId": "2294212687", "name": "Rui Wang"}, {"authorId": "2294177555", "name": "Qin Xie"}], "references": [{"paperId": "1942fd1ee7e584dbd313492588b13449779d7c6e", "title": "LLM as a System Service on Mobile Devices"}, {"paperId": "a48a3cfde9e9a6f02821ea28698012e4d3e1cd73", "title": "QAQ: Quality Adaptive Quantization for LLM KV Cache"}, {"paperId": "dbf829c977c121c3704d070d7800d29fe5914756", "title": "LLM Inference Unveiled: Survey and Roofline Model Insights"}, {"paperId": "b085968c4362fb286ad6c5ef71a5db9630da0498", "title": "KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization"}, {"paperId": "1b5db3170c195508ff24fee8eda0d4987e806f0b", "title": "EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty"}, {"paperId": "57e7af0b69325fafb371ef5d502e39ef9c90ef7e", "title": "Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads"}, {"paperId": "72f77a393079431e4207b3afe678ee80b420e6f8", "title": "DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving"}, {"paperId": "13261129251c9e8891cff02c3aee15c4df6a5630", "title": "Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "3adca9d49eab1a4db6538a995af3636d10e120c3", "title": "BladeDISC: Optimizing Dynamic Shape Machine Learning Workloads via Compiler Approach"}, {"paperId": "95240dda409e28acccdc5cf619ad0c036cf4292d", "title": "Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time"}, {"paperId": "a8b995f0da78a79447dfb18c2337972b044f4239", "title": "LLM-FP4: 4-Bit Floating-Point Quantized Transformers"}, {"paperId": "6c323c535365e1c7cbfd9703cbec3b5650a3346b", "title": "Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs"}, {"paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05", "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"}, {"paperId": "aeb9454987c3f85563cf7a5d2cb7f3d502d3398d", "title": "ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "db9507cdd3e2d7d9c90ed185bd831e55c62dcec9", "title": "AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "909ad57ce8caa6b390a65ae09db352d27d8f3996", "title": "SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot"}, {"paperId": "53535d38fe259a3aa7c911edd8048d764e09e8e1", "title": "The case for 4-bit precision: k-bit Inference Scaling Laws"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "7da0f2501034522e3d50af7e9b8fa7ec9d7b65b6", "title": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "218c5c69f3cf0c158e9b6af239a2cc62a688c6de", "title": "Speculative Decoding: Exploiting Speculative Execution for Accelerating Seq2seq Generation"}, {"paperId": "434aff622d4f4bd1729d1d643bba89c41407ba4d", "title": "DISC: A Dynamic Shape Compiler for Machine Learning Workloads"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "86b3e0c9cbdc74b4d0a34345d9f779b6cc38562f", "title": "Nimble: Efficiently Compiling Dynamic Neural Networks for Model Inference"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "c5357be80db44a50e205b4c2e68e7df3801d65d2", "title": "MNN: A Universal and Efficient Inference Engine"}, {"paperId": "ad20fb158f09c45e3f1b861da3ccdb0535e88e72", "title": "Deep learning on mobile devices: a review"}, {"paperId": "992983bd9faa6846f143a9080a41ccbb442553e9", "title": "Deep Learning towards Mobile Applications"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "d1a6b3a5efde3783b53f822dc8dd00aaac934b95", "title": "SpecInfer: Accelerating Generative LLM Serving with Speculative Inference and Token Tree Verification"}, {"paperId": "ec3071fb918ad69ec80df1ca9cf1fdeb386a9603", "title": "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning"}, {"paperId": null, "title": "Large Language Models On-Device with MediaPipe and TensorFlow Lite"}, {"paperId": null, "title": "Unlocking on-device"}, {"paperId": null, "title": "MediaTek Demonstrating On-Device Generative AI Using Llama 2 LLM at MWC 2024"}, {"paperId": null, "title": "2023. Flash-llm: Enabling cost-effective and highly-efficient large generative model inference with unstructured sparsity"}, {"paperId": null, "title": "2023. Relu strikes back: Exploiting activation sparsity in large language models"}, {"paperId": null, "title": "2022. Enable deep learning on mobile devices: Methods, systems, and applications"}, {"paperId": null, "title": "cl_khr_priority_hints"}, {"paperId": null, "title": "2023. Flash-decoding for long-context inference"}, {"paperId": null, "title": "export_llama_to_onnx"}, {"paperId": null, "title": "Half-precision floating-point format"}, {"paperId": null, "title": "2024. MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use"}, {"paperId": null, "title": "Democratizing on-device generative AI with sub-10 billion parameter models"}]}