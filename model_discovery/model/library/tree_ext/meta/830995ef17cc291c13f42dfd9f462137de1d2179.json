{"paperId": "830995ef17cc291c13f42dfd9f462137de1d2179", "title": "Augmenting Self-attention with Persistent Memory", "abstract": "Transformer networks have lead to important progress in language modeling and machine translation. These models include two consecutive modules, a feed-forward layer and a self-attention layer. The latter allows the network to capture long term dependencies and are often regarded as the key ingredient in the success of Transformers. Building upon this intuition, we propose a new model that solely consists of attention layers. More precisely, we augment the self-attention layers with persistent memory vectors that play a similar role as the feed-forward layer. Thanks to these vectors, we can remove the feed-forward layer without degrading the performance of a transformer. Our evaluation shows the benefits brought by our model on standard character and word level language modeling benchmarks.", "venue": "arXiv.org", "year": 2019, "citationCount": 116, "influentialCitationCount": 7, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A new model that solely consists of attention layers is proposed that augment the self-attention layers with persistent memory vectors that play a similar role as the feed-forward layer."}, "embedding": {"model": "specter_v2", "vector": [0.03525787964463234, 0.8775927424430847, -0.5915048718452454, 0.04224703460931778, 0.09839210659265518, -0.04437495395541191, 0.8799943923950195, -0.14221256971359253, -0.28909167647361755, -0.25630971789360046, 0.8319863080978394, -0.06352280080318451, 0.591325581073761, -0.1853393018245697, -0.4037622809410095, 0.4554790258407593, -0.45467281341552734, 0.26684051752090454, 0.3754764497280121, -0.27369847893714905, -0.10438623279333115, -0.7210600972175598, -0.5868998765945435, 0.2542736828327179, 0.47098010778427124, -0.06066485494375229, 0.46074557304382324, 0.6329483985900879, -0.6022869348526001, 0.7677051424980164, 0.6302874684333801, -0.437884658575058, -0.1029699444770813, -0.13684575259685516, -0.2701083719730377, -0.13696075975894928, 0.5182345509529114, -0.15839789807796478, -0.5843177437782288, 0.9535602331161499, -0.37348297238349915, -0.00490711722522974, -0.07296237349510193, -0.6328327059745789, -0.46352291107177734, 1.6456729173660278, 0.8392832279205322, 1.2027642726898193, -0.39248067140579224, -0.566656231880188, 1.1561719179153442, -1.5250285863876343, 0.36256831884384155, 1.4626094102859497, 0.5075938105583191, 0.4036122262477875, -0.17669343948364258, -0.5128069519996643, 1.0059765577316284, 0.19791319966316223, -0.753415048122406, -0.8579603433609009, 0.24387572705745697, -0.10458176583051682, 2.2019646167755127, -0.21548216044902802, -0.0916527807712555, 0.4376043975353241, 0.21609413623809814, 1.3429760932922363, -0.08723818510770798, -0.8068640828132629, -0.6602991223335266, 0.28961852192878723, 0.38616490364074707, 1.1619830131530762, -0.5592907071113586, 0.38687220215797424, -0.9475815892219543, -0.015898823738098145, 0.684922993183136, -0.08918013423681259, -0.12645037472248077, -0.5511946082115173, -0.2656051516532898, 0.6003480553627014, 0.0967155322432518, 1.3468490839004517, -0.30068397521972656, 0.6238213777542114, 0.3254230320453644, 0.34235623478889465, 0.16055049002170563, 0.4958299994468689, 0.06729395687580109, 0.5060969591140747, -1.0271079540252686, -0.13516153395175934, -0.23303289711475372, 1.0564303398132324, -0.04265101999044418, 0.6787562966346741, -0.788951575756073, 0.37614038586616516, 1.4397393465042114, 0.2542949914932251, 0.6264318227767944, -0.6638453602790833, 0.07023961842060089, -0.6233808994293213, -0.20973289012908936, -0.9790878295898438, -0.11721590906381607, -0.8422160744667053, -0.5149846076965332, -1.4464313983917236, -0.42707371711730957, 0.4471624493598938, -0.5381497740745544, 0.9441643357276917, -0.3955793082714081, -0.1389084756374359, -0.1358732432126999, -0.14014941453933716, 0.31785354018211365, 0.5073833465576172, 0.43132561445236206, -0.29679468274116516, 0.671070396900177, -1.182668685913086, -0.9452639818191528, -1.3145040273666382, 0.6346355676651001, -0.2275572419166565, 0.07221835851669312, -0.47944459319114685, -1.5092905759811401, -0.8925786018371582, -0.6822291612625122, 0.35296007990837097, -0.3425630033016205, 0.17291569709777832, 0.7806125283241272, 0.40697404742240906, -1.2570478916168213, 0.984778642654419, -0.21914243698120117, -0.2220585197210312, 0.4401688575744629, 0.07760114967823029, 0.08249185234308243, -0.28107619285583496, -1.2623634338378906, 0.32448941469192505, 0.13548046350479126, -0.5284403562545776, -0.11733386665582657, -0.8377414345741272, -1.2735742330551147, -0.08519195020198822, 0.35088908672332764, -0.5322567820549011, 1.168124794960022, -0.3718458116054535, -1.3482803106307983, 0.7494280338287354, -0.6516059637069702, -0.16972562670707703, -0.056392788887023926, -0.2931956946849823, -0.7593829035758972, -0.6900607943534851, 0.07320735603570938, 0.309731662273407, 0.5195258259773254, -0.296050101518631, -0.3774309456348419, -0.1373453289270401, -0.32547327876091003, -0.2911728322505951, -0.4018394351005554, 1.056183099746704, -0.6665359139442444, -0.34133949875831604, 0.3925338089466095, 0.6607330441474915, 0.42866840958595276, -0.7194168567657471, -0.4901561737060547, -1.170927882194519, 0.7210739254951477, 0.20755407214164734, 1.2977973222732544, -0.7598453164100647, -0.6666804552078247, -0.25725677609443665, -0.18280230462551117, 0.026457510888576508, -0.8649534583091736, 0.737505316734314, -0.7021480202674866, 0.3748301565647125, 0.12687796354293823, -0.8894139528274536, -0.21463347971439362, -0.4244922399520874, -0.6687704920768738, -0.2926510274410248, 0.3465767800807953, 1.174095869064331, -1.0424635410308838, -0.12499990314245224, -0.09756584465503693, 0.4105170965194702, -0.699851930141449, 1.3343778848648071, -0.236135333776474, 0.08137626200914383, 0.23769138753414154, -0.40445297956466675, 0.18209438025951385, -0.09934528172016144, 0.6008796691894531, -0.34362658858299255, -0.5129759907722473, 0.693682849407196, 0.1425841599702835, 1.0488672256469727, -0.31238824129104614, 0.6369616985321045, -0.2271556556224823, -0.5296805500984192, 0.21367429196834564, 0.34120529890060425, -0.30372539162635803, -0.9195278286933899, 0.2595353424549103, 0.13662049174308777, -0.525824248790741, 0.594489336013794, 0.864961564540863, 0.7157958149909973, 0.1484449803829193, 0.08257821947336197, 0.7242763638496399, -0.045999981462955475, 0.3861842751502991, 0.3876396417617798, 0.6726638078689575, 0.5791477560997009, 0.28956103324890137, -0.4875484108924866, 0.6483781337738037, -0.531139612197876, 0.2116846740245819, 0.2667801082134247, 0.7518173456192017, 0.6593664884567261, 0.3768172860145569, -0.3211768865585327, -0.28732383251190186, 0.2897900342941284, 0.8855706453323364, 1.758005142211914, -0.5115005373954773, -0.1396598219871521, -0.7310993075370789, -0.13439619541168213, -0.8628789186477661, 0.6296820044517517, -0.2902447581291199, -0.43017226457595825, -1.0396111011505127, -0.5653952360153198, 0.7577150464057922, 0.6298969984054565, 0.9456690549850464, -0.3670986294746399, -0.2382982224225998, 0.05222468823194504, 0.42545393109321594, -0.7710386514663696, -0.9204472899436951, 0.31354060769081116, -0.7898243069648743, -0.18892215192317963, 0.08393829315900803, -0.5190283060073853, -0.15503741800785065, -0.5221927762031555, 1.252340316772461, -0.2721237540245056, 0.21630610525608063, 0.17637327313423157, 0.7337060570716858, -0.48611071705818176, -0.9113137125968933, 0.23674221336841583, 0.3966733515262604, -0.14760632812976837, 0.4371330738067627, 0.6919052004814148, -0.007611847948282957, 0.18810679018497467, -0.11067298799753189, -0.04261651262640953, -0.2190079241991043, 0.155838280916214, 0.5742772221565247, -0.16375839710235596, -0.35472944378852844, -1.789612054824829, 0.4930880665779114, 0.27302053570747375, -0.2790429890155792, 0.2608407735824585, -0.6697695851325989, -0.4174181818962097, 0.39907804131507874, -0.6898714303970337, -0.4942043423652649, -0.9838927984237671, 0.4693196415901184, -0.24221789836883545, 0.1704695224761963, 0.08689426630735397, -0.19130046665668488, 0.3109300434589386, -0.12188374996185303, 0.601875364780426, 0.31915774941444397, -0.05809023603796959, 0.644919753074646, -1.050222396850586, 0.7768095135688782, 0.42750799655914307, 0.2592555582523346, -0.23535798490047455, -0.4182896316051483, -0.6741223335266113, -0.11937591433525085, -0.23417580127716064, -0.01865338906645775, -0.06953319907188416, -0.10940303653478622, -0.5866802930831909, -0.8722363114356995, 0.10766423493623734, -1.1395742893218994, -0.31695565581321716, 0.011327368207275867, -0.4271489381790161, -0.009621226228773594, -0.886150062084198, -1.3141001462936401, -0.6601223349571228, -0.5720940232276917, -0.6598193049430847, -0.19653049111366272, 0.03595145419239998, -0.2524757385253906, -0.6610862612724304, 0.111170195043087, -0.5250598788261414, 1.5620542764663696, -1.2073068618774414, 1.1119235754013062, -0.032798681408166885, -0.5413508415222168, -0.08310531824827194, 0.2170163094997406, 0.35998088121414185, -0.21874494850635529, 0.0356576107442379, -0.704512357711792, 0.40805238485336304, -0.005355491302907467, 0.3277880847454071, 0.1643403023481369, 0.47749653458595276, 0.4289245009422302, -0.09812135994434357, -0.8782474398612976, 0.21771350502967834, 1.331590175628662, -0.39040330052375793, 0.30007314682006836, 0.4579754173755646, 1.0522677898406982, 0.31824448704719543, -0.5190838575363159, -0.1344967633485794, 0.8842999935150146, 0.40279439091682434, 0.405895859003067, -0.18540574610233307, -0.32395800948143005, -0.6667044162750244, 0.4101811349391937, 1.8354934453964233, 0.20143435895442963, -0.3735063672065735, -0.873960018157959, 0.7236721515655518, -1.3443838357925415, -0.8486623764038086, 0.43557390570640564, 0.7293896079063416, 0.34500280022621155, -0.6187322735786438, -0.4718376696109772, -0.18687251210212708, 0.7085071206092834, 0.3323237895965576, -0.1255221962928772, -0.7577629685401917, -0.42360061407089233, 0.31358298659324646, 0.4536106586456299, 1.0158357620239258, -0.3892032206058502, 1.0953576564788818, 14.536637306213379, 0.32745984196662903, -0.12239687144756317, 0.8573866486549377, 0.4819386601448059, 0.4747510850429535, -0.508163332939148, 0.1717042624950409, -1.2715613842010498, -0.28580230474472046, 1.0678406953811646, 0.12980777025222778, 0.38048306107521057, -0.07797078788280487, -0.1416090577840805, 0.22380948066711426, -0.43666791915893555, 0.3928501307964325, 0.7794090509414673, -1.2708121538162231, 0.5233324766159058, 0.0313250795006752, -0.06896590441465378, 0.3243195712566376, 0.7556317448616028, 0.7811288833618164, 0.6376693248748779, -0.13588093221187592, 0.31156718730926514, 0.5971584916114807, 0.7266750931739807, -0.016707368195056915, 0.07874397188425064, 0.436467707157135, -0.4981595277786255, -0.41790571808815, -0.6863607168197632, -0.9318906664848328, 0.21059255301952362, 0.14942628145217896, -0.07203227281570435, -0.8707863688468933, -0.3069098889827728, 0.4233737289905548, 0.09080199897289276, 0.3051058053970337, -0.20271815359592438, 0.7910171151161194, 0.1599704474210739, 0.22721873223781586, 0.00887258816510439, 0.7040497064590454, 0.5055513978004456, 0.22180761396884918, 0.1900119185447693, 0.08100548386573792, -0.27752020955085754, 0.6129633784294128, -0.5483970046043396, 0.017281293869018555, -0.2473716288805008, -0.4716373682022095, 0.012331027537584305, 0.6366007924079895, 0.5904304385185242, 0.03176061809062958, -0.24947123229503632, 0.5824999213218689, 0.5745583772659302, -0.0734637901186943, -0.23327037692070007, 0.10932492464780807, 0.037021055817604065, 0.3199721872806549, 0.06455063074827194, 0.375968337059021, 0.20521514117717743, -0.31434333324432373, -1.133109450340271, -0.37454259395599365, 0.2259649634361267, -0.8914713859558105, -0.36895039677619934, 1.4711471796035767, -0.5560053586959839, -0.10371860861778259, 0.16496776044368744, -0.8252466320991516, -0.4810374081134796, 0.26869335770606995, -1.3613791465759277, -0.7815512418746948, 0.49545761942863464, -0.3445183336734772, -0.3722724914550781, -0.3478897213935852, 1.3698954582214355, -0.016171732917428017, -0.460332989692688, 0.2873651087284088, -0.15464669466018677, 0.04977455735206604, -0.25409388542175293, -0.6636373400688171, 0.686293363571167, 0.31610551476478577, -0.11143574118614197, 0.5160334706306458, 0.28682252764701843, 0.013460390269756317, -1.2160587310791016, -0.08065060526132584, 1.5128642320632935, -0.8856235146522522, -0.30368077754974365, -0.49273252487182617, -1.0169757604599, 0.2841467559337616, 1.0925322771072388, -0.21390071511268616, 0.19796781241893768, 0.18644602596759796, -0.642715573310852, 0.11335974186658859, -0.6411921381950378, 0.006202341057360172, 0.8477246165275574, -0.7959895730018616, -0.408722460269928, -0.1266210377216339, 0.39616045355796814, -0.8924065232276917, -0.2764919400215149, -0.3939148783683777, -0.1441815048456192, -0.06053268164396286, 0.9362155199050903, -0.5242661833763123, 0.623180091381073, 0.7653999328613281, -0.044878508895635605, -0.9598486423492432, -0.6609381437301636, -0.9191761016845703, -0.08585536479949951, 0.8121461272239685, 0.7293345928192139, -0.5264146327972412, -0.0014681884786114097, 1.0127242803573608, 0.11958706378936768, -0.0699806809425354, -0.5229015350341797, -0.5539524555206299, 0.3600299656391144, -0.4703344702720642, 0.4632432460784912, 0.25798970460891724, 0.07872315496206284, 0.5394102334976196, 0.4855748116970062, 0.4809838533401489, -0.017021043226122856, -0.7469237446784973, 0.10276621580123901, -0.22558820247650146, 0.19470927119255066, -0.5099210143089294, -0.33955511450767517, -1.108272910118103, 0.3215881884098053, -1.0239335298538208, -0.10806814581155777, -1.2791434526443481, -0.19860902428627014, 0.033139634877443314, -0.3205339014530182, -0.048808515071868896, 0.4175221025943756, -0.26604971289634705, -0.5128672122955322, -0.5147410035133362, -0.4937193989753723, 0.7268884778022766, 0.4495439827442169, -0.8418019413948059, -0.004556438885629177, -0.0660175159573555, -0.2000257521867752, 0.28556981682777405, 0.5163514018058777, -0.542650043964386, -0.32173091173171997, -1.90261709690094, 0.5007340908050537, -0.1474166214466095, -0.24218632280826569, -0.5158182978630066, 1.0937427282333374, 0.42707279324531555, -0.1425890326499939, -0.11276481300592422, 0.2683888375759125, -0.8214784264564514, -0.4120579957962036, 0.3802953362464905, -0.4640631377696991, 0.6503188014030457, 0.3473758399486542, -0.7007777690887451, -0.3014327585697174, 0.9181274771690369, -0.0840965062379837, -1.464125394821167, -0.6704694628715515, 0.45961108803749084, -0.8593760132789612, 0.19376391172409058, -0.4607557952404022, -0.2819284498691559, -1.1523950099945068, -0.3839668929576874, 0.13515736162662506, 0.29491838812828064, -0.319977730512619, 1.3270102739334106, 0.19898730516433716, -1.1204220056533813, 0.09157814830541611, 0.6081206798553467, -0.03423648700118065, -0.5251348614692688, 0.5968475937843323, 0.3369758129119873, -0.10912806540727615, 0.9111347198486328, 0.19546955823898315, 0.3097752630710602, -1.0112940073013306, 0.26701003313064575, 0.889471173286438, -0.3755095303058624, -0.25614210963249207, 1.036036729812622, -0.3582850694656372, -1.109576940536499, -0.10350844264030457, -1.0534906387329102, -0.8167705535888672, -0.2854470908641815, 0.649941086769104, 0.40143197774887085, -0.3664441406726837, -0.6903508305549622, -0.7314764261245728, 0.24912172555923462, -0.09324482828378677, -0.4063062369823456, 0.7520822286605835, -0.34357333183288574, -0.7406567931175232, 0.4992797076702118, 0.3601400554180145, -0.33720433712005615, -0.45183512568473816, -1.1986924409866333, -0.3749455213546753, -0.07532231509685516, 0.7771775722503662, -0.12990029156208038, -0.8138749599456787, 0.9559019804000854, 0.5916795134544373, 0.21437634527683258, -0.3789064884185791, -0.26923444867134094, -0.01503122877329588, 0.13845202326774597, -0.027674436569213867, -0.8024992942810059, -0.8196519613265991, 1.8351202011108398, 1.2631524801254272, -0.3966021239757538, -0.28851765394210815, -0.4716923236846924, -0.5671725869178772, 0.6812214851379395, 0.33303284645080566, -0.034530751407146454, 0.9892479777336121, -0.07108864933252335, 0.31047937273979187, 0.272002249956131, -1.031342625617981, -0.39432331919670105, 0.5362491607666016, 1.276247501373291, 1.1364821195602417, 0.16149255633354187, 0.2185637652873993, 0.7645139098167419, 0.3780295252799988, 0.18776848912239075, 0.48306983709335327, 0.1964317262172699, -0.35519838333129883, -0.3713048994541168, 0.1964789628982544, 0.24824337661266327, -0.6223711967468262, -1.0210689306259155, 0.13381192088127136, 0.4696378707885742, 0.14056040346622467, 0.6313862800598145, 1.0198206901550293, -0.028251150622963905, 0.6988286375999451, 0.5432244539260864, 0.6797922253608704, -0.6185398697853088, -0.41956064105033875, -0.19479089975357056, -0.5966421365737915, -0.05460929498076439, -0.14478835463523865, -0.49517005681991577, -0.24732154607772827, -0.27862444519996643, -0.28271588683128357, -0.24567672610282898, 0.4008757472038269, 0.8743473291397095, 0.5215885043144226, 0.6854979991912842, -0.25619158148765564, 0.0035849239211529493, -0.22136247158050537, -1.1844191551208496, 0.2188006490468979, -0.8926365375518799, -0.43266215920448303, -0.07298741489648819, 0.1994646191596985, -0.5947467684745789]}, "authors": [{"authorId": "2265067", "name": "Sainbayar Sukhbaatar"}, {"authorId": "3024698", "name": "Edouard Grave"}, {"authorId": "1830914", "name": "Guillaume Lample"}, {"authorId": "1681054", "name": "H. J\u00e9gou"}, {"authorId": "2319608", "name": "Armand Joulin"}], "references": [{"paperId": "f4238bd2385a52413ccbacfd9e409a650235bd13", "title": "Adaptive Attention Span in Transformers"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "fea820b7d953d32069e189af2961c28fd213470b", "title": "Pay Less Attention with Lightweight and Dynamic Convolutions"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "b9de9599d7241459db9213b5cdd7059696f5ef8d", "title": "Character-Level Language Modeling with Deeper Self-Attention"}, {"paperId": "69ac3b35887eb42e8fe554619fc7255e6e95a4cb", "title": "Fast Parametric Learning with Activation Memorization"}, {"paperId": "680aafd3d51e666b297e27b93d9554cc2caf1c4d", "title": "An Analysis of Neural Language Modeling at Multiple Scales"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "87a913817503379547bec61a5f010abac5b0f76b", "title": "Fast-Slow Recurrent Neural Networks"}, {"paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586", "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"}, {"paperId": "88caa4a0253a8b0076176745ebc072864eab66e1", "title": "Language Modeling with Gated Convolutional Networks"}, {"paperId": "424aef7340ee618132cc3314669400e23ad910ba", "title": "Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling"}, {"paperId": "2d7782c225e0fc123d6e227f2cb253e58279ac73", "title": "Improving Neural Language Models with a Continuous Cache"}, {"paperId": "563783de03452683a9206e85fe6d661714436686", "title": "HyperNetworks"}, {"paperId": "55cf59bfbb25d6363cab87cb747648ebe8a096e5", "title": "Multiplicative LSTM for sequence modelling"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "9ec499af9b85f30bdbdd6cdfbb07d484808c526a", "title": "Efficient softmax approximation for GPUs"}, {"paperId": "65eee67dee969fdf8b44c87c560d66ad4d78e233", "title": "Hierarchical Multiscale Recurrent Neural Networks"}, {"paperId": "63e39cdf1ad884da6bc69096bb3413b5b1100559", "title": "Using the Output Embedding to Improve Language Models"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "7dba53e72c182e25e98e8f73a99d75ff69dda0c2", "title": "Recurrent Highway Networks"}, {"paperId": "bba5f2852b1db8a18004eb7328efa5e1d57cc62a", "title": "Key-Value Memory Networks for Directly Reading Documents"}, {"paperId": "2f2d8f8072e5cc9b296fad551f65f183bdbff7aa", "title": "Exploring the Limits of Language Modeling"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "9653d5c2c7844347343d073bbedd96e05d52f69b", "title": "Pointer Networks"}, {"paperId": "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e", "title": "End-To-End Memory Networks"}, {"paperId": "4d8f2d14af5991d4f0d050d22216825cac3157bd", "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"}, {"paperId": "c1126fbffd6b8547a44c58b192b36b08b18299de", "title": "Neural Turing Machines"}, {"paperId": "f264e8b33c0d49a692a6ce2c4bcb28588aeb7d97", "title": "Recurrent Neural Network Regularization"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "84069287da0a6b488b8c933f3cb5be759cb6237e", "title": "On the difficulty of training recurrent neural networks"}, {"paperId": "413c1142de9d91804d6d11c67ff3fed59c9fc279", "title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization"}, {"paperId": "6c2b28f9354f667cd5bd07afc0471d8334430da7", "title": "A Neural Probabilistic Language Model"}, {"paperId": "09c76da2361d46689825c4efc37ad862347ca577", "title": "A bit of progress in language modeling"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "f6d8a7fc2e2d53923832f9404376512068ca2a57", "title": "Hierarchical Mixtures of Experts and the EM Algorithm"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": null, "title": "Large text compression benchmark"}, {"paperId": "9819b600a828a57e1cde047bbe710d3446b30da5", "title": "Recurrent neural network based language model"}, {"paperId": "c19fbefdeead6a4154a22a9c8551a18b1530033a", "title": "Hierarchical Probabilistic Neural Network Language Model"}, {"paperId": "6b388f0151ab37adb3d57738b8f52a3f943f86c8", "title": "Quick Training of Probabilistic Neural Nets by Importance Sampling"}]}