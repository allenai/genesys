{"paperId": "4b56eef2862f7f553686f1dd190c56017122a6a0", "title": "PolySketchFormer: Fast Transformers via Sketches for Polynomial Kernels", "abstract": "The quadratic complexity of attention in transformer architectures remains a big bottleneck in scaling up large foundation models for long context. In fact, recent theoretical results show the hardness of approximating the output of softmax attention mechanism in sub-quadratic time assuming Strong Exponential Time Hypothesis. In this paper, we show how to break this theoretical barrier by replacing softmax with a polynomial function and polynomial sketching. In particular we show that sketches for Polynomial Kernel from the randomized numerical linear algebra literature can be used to approximate the polynomial attention which leads to a significantly faster attention mechanism without assuming any sparse structure for the attention matrix that has been done in many previous works. In addition, we propose an efficient block-based algorithm that lets us apply the causal mask to the attention matrix without explicitly realizing the n \u00d7 n attention matrix and compute the output of the polynomial attention mechanism in time linear in the context length. The block-based algorithm gives significant speedups over the cumulative sum algorithm used by Performer to apply the causal mask to the attention matrix. These observations help us design PolySketchFormer , a practical linear-time transformer architecture for language modeling with provable guarantees. We validate our design empirically by training language models with long context lengths. We first show that the eval perplexities of our models are comparable to that of models trained with softmax attention. We then show that for large context lengths our training times are significantly faster than FlashAttention.", "venue": "arXiv.org", "year": 2023, "citationCount": 16, "influentialCitationCount": 2, "openAccessPdf": {"url": "https://arxiv.org/pdf/2310.01655", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper shows how to break this theoretical barrier by replacing softmax with a polynomial function and polynomial sketching and proposes an efficient block-based algorithm that lets us apply the causal mask to the attention matrix without explicitly realizing the n \u00d7 n attention matrix."}, "embedding": {"model": "specter_v2", "vector": [0.29089638590812683, 0.7178197503089905, -0.43313735723495483, -0.12364138662815094, -0.5250409841537476, -0.3190927803516388, 0.5972471833229065, -0.4066489636898041, -0.3143514394760132, -0.3446195125579834, 0.31053426861763, -0.20372597873210907, 0.29320043325424194, 0.02852308563888073, -0.6053911447525024, -0.11198563873767853, -0.5864349603652954, 0.0572512149810791, -0.06072051450610161, -0.08208432048559189, -0.03397604078054428, -0.5252999067306519, -0.7974663376808167, 0.015872232615947723, -0.044479306787252426, 0.28612053394317627, 0.2193954437971115, 0.9247606992721558, -0.13492320477962494, 0.33716440200805664, 0.5689773559570312, -0.5331299901008606, 0.29611918330192566, 0.3673831522464752, -0.14350618422031403, -0.36198100447654724, 0.14399904012680054, -0.24413101375102997, -0.9721132516860962, 0.8762325644493103, -0.25453153252601624, 0.09782835841178894, 0.0233134962618351, -1.0490403175354004, -0.4726691246032715, 1.073228120803833, 0.5571075677871704, 0.4913330674171448, -0.6422073245048523, -0.39936038851737976, 1.8674416542053223, -1.6850348711013794, -0.06728576868772507, 1.2997394800186157, 0.24559937417507172, 0.28639543056488037, -0.6498034000396729, -0.5355242490768433, 0.8528617024421692, 0.39213836193084717, -1.0521818399429321, -0.60080885887146, -0.1385774463415146, 0.2251930683851242, 1.8730069398880005, -0.18934005498886108, 0.0037185736000537872, 0.3814283609390259, -0.1746387481689453, 1.2748093605041504, 0.1598336100578308, -0.8643989562988281, -0.14923231303691864, 0.08978337049484253, 0.4959064722061157, 0.8886501789093018, -0.06814144551753998, 0.24263904988765717, -0.7468776702880859, -0.4058159291744232, 0.1883803755044937, 0.2302982211112976, 0.1340695172548294, -0.290332555770874, -0.13742782175540924, 0.5545889735221863, 0.3123044967651367, 0.3755902945995331, 0.13736945390701294, 1.2483904361724854, 0.6650423407554626, -0.017024654895067215, -0.3947342336177826, 0.24764668941497803, -0.23362858593463898, 0.4338051676750183, -0.9093440771102905, 0.3167188763618469, 0.10381098091602325, 0.9149256944656372, -0.25580134987831116, 0.5114472508430481, -0.5829436182975769, -0.32254675030708313, 1.195043921470642, 0.8887514472007751, 0.07727163285017014, -0.4954926669597626, 0.050629276782274246, -0.7502024173736572, 0.06604690849781036, -0.6818755269050598, -0.09866706281900406, -0.041475214064121246, -0.7855950593948364, -1.0705084800720215, -0.41936081647872925, 0.3046205937862396, -0.7352214455604553, 0.8853418231010437, -0.48126551508903503, 0.6230030655860901, -0.07254345715045929, 0.4108354449272156, 0.32031935453414917, 0.7740487456321716, 0.27288395166397095, 0.31920602917671204, 0.9879286885261536, -0.8410352468490601, -0.5131822824478149, -0.9472652673721313, 0.5638275742530823, -0.20307767391204834, 0.4043206572532654, 0.04056824371218681, -1.2747615575790405, -0.9135509729385376, -0.7878580093383789, -0.004089838359504938, -0.5384644269943237, 0.4849218428134918, 1.1832304000854492, 0.7076056599617004, -0.9999808073043823, 0.1950257271528244, -0.6534259915351868, 0.320892870426178, 0.4719914197921753, 0.6148633360862732, 0.12443037331104279, -0.48816990852355957, -1.1435918807983398, 0.23875360190868378, 0.01075547281652689, -0.745722770690918, -0.390476256608963, -0.7541231513023376, -1.1624221801757812, 0.7030941247940063, 0.7219465970993042, -0.49346476793289185, 1.2525956630706787, -0.090416818857193, -1.1480151414871216, 0.6278153657913208, -0.5310947895050049, -0.038793858140707016, -0.10067397356033325, -0.4569428861141205, -0.392011821269989, -0.7755522727966309, -0.4051252007484436, 0.07642469555139542, 0.7740671038627625, -0.13754062354564667, 0.009822418913245201, 0.45423221588134766, -0.2032976597547531, -0.502726674079895, 0.04104619100689888, 0.8963456749916077, -0.25281739234924316, -0.07907948642969131, -0.12290889024734497, 0.34485626220703125, -0.6110733151435852, -0.34140875935554504, -0.4304266571998596, -1.0032455921173096, 0.5497525930404663, 0.2490585595369339, 1.2609243392944336, -1.0852373838424683, -0.48625120520591736, 0.17212186753749847, 0.31548064947128296, 0.15982115268707275, -0.6028695106506348, 0.5814827084541321, -0.7702884674072266, 0.07984067499637604, -0.15813763439655304, -1.0324318408966064, 0.39801475405693054, -0.03896269202232361, -0.9894238710403442, -0.03241938352584839, 0.05319052189588547, 1.261146903038025, -0.8421039581298828, 0.2889649271965027, 0.01957099698483944, 0.06857351958751678, -1.1846834421157837, 1.1654413938522339, -0.2049974799156189, -0.41076764464378357, 0.253373384475708, -0.26022854447364807, 0.0879310667514801, -0.7132859826087952, 0.4826030135154724, -0.04509955272078514, 0.29662981629371643, 0.3140236437320709, -0.6913439035415649, 1.1332859992980957, -0.4981292486190796, 0.5480985641479492, 0.24687017500400543, -0.9441220164299011, -0.017244935035705566, 0.41193461418151855, -0.4550066888332367, 0.15053972601890564, -0.11884582787752151, 0.3954552412033081, -0.6227797269821167, 0.05705128610134125, 0.6955140233039856, 0.5757554769515991, -0.36750122904777527, -0.12211354821920395, 0.4731352627277374, -0.17324380576610565, -0.14451882243156433, 0.610766589641571, 0.9690203666687012, 0.06023433431982994, 0.6196838617324829, -0.03779613599181175, 0.4585152864456177, -1.2418571710586548, -0.18471559882164001, 0.6360689401626587, 0.7060621380805969, 0.39034536480903625, 0.6370348930358887, -0.6836591958999634, -0.7322206497192383, 0.024810604751110077, 0.7636619806289673, 1.4788942337036133, -0.22667796909809113, -0.7132229804992676, -0.5478562712669373, -0.14200052618980408, -0.3741699159145355, 0.053148992359638214, -0.06843210756778717, -0.12105794250965118, -0.7042949795722961, -0.9807385206222534, 0.9478023052215576, 0.8534001111984253, 0.45234930515289307, -0.1094784215092659, 0.007860268466174603, -0.4928874671459198, 0.5973713994026184, -1.2749600410461426, -0.5050991773605347, 0.4753309488296509, 0.020328709855675697, 0.17125913500785828, 0.2802886366844177, -0.07123034447431564, 0.2665677070617676, -0.5774306654930115, 0.698826014995575, -0.475625604391098, -0.3014153242111206, 0.3803633749485016, 0.9231300354003906, -0.612373948097229, -0.2746952474117279, 0.27046987414360046, 0.17393364012241364, -0.2074560672044754, 0.5698361992835999, 0.07562749087810516, 0.1279318481683731, -0.09990542382001877, -0.36810103058815, 0.269327849149704, 0.18410234153270721, 0.44977715611457825, 0.30094125866889954, -0.2913903594017029, -0.07471363991498947, -1.1535083055496216, 0.36817264556884766, 0.14621196687221527, -0.8087770938873291, 0.14682380855083466, -0.7471685409545898, -0.37770381569862366, 0.6729665398597717, -0.7420138716697693, 0.13104380667209625, -0.4366067349910736, 0.1729748398065567, -0.453632652759552, -0.1010192260146141, 0.1368715614080429, 0.0656648576259613, 0.18972910940647125, 0.14738139510154724, 0.45821869373321533, -0.017220592126250267, 0.39572107791900635, 0.777307391166687, -1.0928407907485962, 0.37242254614830017, -0.029811164364218712, 0.7128002047538757, -0.08075916022062302, 0.20612631738185883, -0.6873447299003601, -0.3375435471534729, -0.4088943302631378, -0.017235971987247467, 0.06451777368783951, 0.19533461332321167, -0.8357195258140564, -1.3634647130966187, -0.24702082574367523, -1.0986436605453491, -0.3756546676158905, 0.015657683834433556, -0.3908248841762543, -0.11060060560703278, -1.2549158334732056, -1.1109156608581543, -0.858982503414154, -0.3298916816711426, -1.1142029762268066, 0.7300623655319214, -0.0031782998703420162, -0.3719096779823303, -0.4905140697956085, -0.28320804238319397, -0.42756009101867676, 0.9647616147994995, -0.8423817157745361, 0.8476973176002502, -0.07750140875577927, -0.9139016270637512, -0.2656325697898865, -0.06202210113406181, 0.3910019099712372, -1.034460425376892, 0.11604738235473633, -1.273447036743164, 0.24173949658870697, -0.8775326013565063, -0.16902324557304382, 0.17385075986385345, 0.5821762681007385, 1.0604392290115356, -0.21714915335178375, -0.5802834033966064, 0.35856595635414124, 1.4864004850387573, -0.8179211616516113, 0.45556777715682983, -0.2529319226741791, 1.3579329252243042, -0.30500444769859314, -0.6898228526115417, 0.7362945079803467, 0.29168039560317993, 0.4949719309806824, 0.09272526204586029, -0.03266952931880951, 0.36437803506851196, -0.5046017169952393, 0.7903235554695129, 1.214069128036499, 0.25744447112083435, 0.2242671400308609, -0.851430356502533, 0.7078930139541626, -1.4364176988601685, -1.0996546745300293, 0.6570033431053162, 0.5715919137001038, 0.1440105140209198, -0.1540614366531372, -0.38874492049217224, 0.15904977917671204, 0.33052074909210205, 0.2944796085357666, -0.058024812489748, -0.6917255520820618, 0.1264936923980713, 1.1444172859191895, 0.7480868101119995, 0.9084203243255615, -0.2984298765659332, 0.8209526538848877, 14.901449203491211, 1.19581937789917, 0.048459332436323166, 0.7753724455833435, 0.48684975504875183, 0.2346326857805252, -0.487750768661499, 0.6316710114479065, -1.302294135093689, -0.2716710865497589, 1.2494487762451172, -0.02191571518778801, 0.7227911949157715, 0.5237194299697876, -0.19963867962360382, 0.2722257673740387, -0.5407121181488037, 0.9476884603500366, 0.3902240991592407, -1.3499934673309326, -0.17800617218017578, 0.10835457593202591, 0.3665565252304077, 0.3379039466381073, 0.8961554765701294, 0.862058699131012, 0.5859601497650146, -0.8787005543708801, 0.4069836437702179, 0.3465466797351837, 1.0057345628738403, 0.07709966599941254, 0.06487039476633072, 0.4424787759780884, -1.0003371238708496, -0.37426289916038513, -0.5624240040779114, -1.234194040298462, 0.2324194610118866, 0.4714243412017822, -0.5845785140991211, -0.40227359533309937, -0.4810808002948761, 0.626230001449585, 0.4830065071582794, 0.2758276164531708, -0.4053839445114136, 0.8609493374824524, -0.35414716601371765, 0.05117334797978401, -0.15858210623264313, 0.6637516021728516, 0.11563872545957565, 0.07083453238010406, 0.03512532636523247, 0.18934793770313263, 0.5595676898956299, 0.5636964440345764, -0.48821261525154114, -0.2020765095949173, -0.21466945111751556, -0.3407464325428009, -0.12878535687923431, 1.038625717163086, 0.549954354763031, -0.020249484106898308, -0.636899471282959, 0.093314990401268, 0.48708340525627136, 0.3322017192840576, -0.4454639256000519, -0.18568970263004303, 0.31849321722984314, -0.23277662694454193, -0.06598249822854996, 0.30980995297431946, -0.5244545340538025, -0.5732021331787109, -0.7465440034866333, -0.47973185777664185, 0.10718020796775818, -0.7693923711776733, -0.696988582611084, 0.28203466534614563, -0.22749488055706024, 0.0831868052482605, 0.8298681378364563, -1.0635929107666016, -0.12297967821359634, 0.6142905950546265, -0.9558323621749878, -0.7310768961906433, 0.2646108567714691, -0.4171948730945587, -0.30776533484458923, 0.14376980066299438, 1.507591724395752, 0.06043606624007225, -0.2760407626628876, 0.11083973944187164, -0.24951907992362976, -0.02023470029234886, -0.1120239645242691, -1.0648279190063477, 0.9843534231185913, 0.30860331654548645, -0.10776663571596146, 0.571160078048706, 0.21284279227256775, 0.24503715336322784, -0.8863719701766968, 0.33578404784202576, 0.8936939835548401, -1.5342621803283691, 0.13226307928562164, -0.9272325038909912, -0.35861337184906006, 0.4188467264175415, 0.3516448140144348, 0.06559677422046661, 0.3392994701862335, 0.1669846624135971, -0.816530168056488, -0.3539769649505615, -0.17195941507816315, 0.23310916125774384, 0.4511606991291046, -1.1037307977676392, -0.13049450516700745, -0.33183515071868896, 0.39925289154052734, -1.046657919883728, -0.24804271757602692, -0.15963774919509888, 0.2595275640487671, 0.2354578673839569, 1.1364258527755737, -0.5187264680862427, 0.9697469472885132, 0.7700533866882324, -0.3505350649356842, -0.4420819580554962, -0.11722572892904282, -1.3359521627426147, -0.28472137451171875, -0.1410394161939621, 0.4665752053260803, -0.23840878903865814, 0.2158360630273819, 0.8747166991233826, 0.34684473276138306, -0.42173945903778076, -0.4669457972049713, -0.01044082548469305, -0.17345033586025238, -0.7021648287773132, 0.2228698879480362, 0.05624750256538391, 0.09602075815200806, 0.3635229766368866, -0.04843341186642647, 0.9062904119491577, -0.4460974931716919, -0.6444464325904846, 0.6791970729827881, 0.016067031770944595, -0.4311724007129669, -0.5260003209114075, -0.8741784691810608, -1.4339172840118408, 0.41580018401145935, -1.3447048664093018, -0.12409064173698425, -0.4140050411224365, -0.15295545756816864, -0.029297642409801483, -0.17878028750419617, 0.07200397551059723, -0.17169831693172455, -0.5799057483673096, -0.6400325298309326, -1.0761959552764893, -0.38995763659477234, 0.6377192735671997, 0.38407620787620544, -0.5819511413574219, 0.284315824508667, 0.1528991162776947, -0.06909501552581787, 0.32708123326301575, 0.19636404514312744, -0.5050285458564758, -0.8128721117973328, -0.7473581433296204, 0.7195263504981995, 0.16981032490730286, 0.3760871887207031, -0.5534253716468811, 0.6318515539169312, 0.02491012215614319, -0.15836623311042786, 0.4148944616317749, 0.39322543144226074, -1.0515437126159668, -0.420489102602005, 0.25457367300987244, -0.893943190574646, 0.3268677592277527, 0.09657593816518784, -0.34701278805732727, 0.2596980929374695, 0.7269123196601868, -0.2710683345794678, -0.8932370543479919, -0.22097070515155792, 0.43103644251823425, -0.6234910488128662, 0.03471391275525093, -0.5413088798522949, 0.40215539932250977, -1.0340545177459717, -0.4064406156539917, -0.1132858470082283, 0.1431230753660202, -0.4218423068523407, 0.602178692817688, 0.2515117824077606, -1.0136210918426514, 0.359296590089798, 0.19323931634426117, -0.21816158294677734, -0.003042832715436816, 0.4958631098270416, 0.5480930805206299, 0.044909801334142685, 0.5928433537483215, 0.5209477543830872, 0.35355308651924133, -1.2173759937286377, 0.4657239019870758, 0.38215672969818115, -0.5325456261634827, -0.32834282517433167, 1.0903538465499878, 0.18669457733631134, -0.6011652946472168, 0.23264379799365997, -1.421651840209961, -0.0257499311119318, -0.8423053622245789, 0.7505919933319092, 0.02321327105164528, -0.232347309589386, 0.2723299264907837, -0.5217642784118652, 0.1383730173110962, 0.33482304215431213, -0.4930705428123474, 0.6099832653999329, 0.08013172447681427, -0.5314649939537048, 0.4306557774543762, 0.3943367600440979, -0.31605270504951477, -0.13761870563030243, -0.8321546912193298, -0.29740965366363525, -0.14152662456035614, 0.18674439191818237, 0.023672211915254593, -0.2492792159318924, 1.0640932321548462, 0.29073649644851685, 0.12350880354642868, 0.09724053740501404, -0.2377527952194214, 0.11277949810028076, 0.7464231252670288, 0.12224064022302628, -0.33386772871017456, -0.5983651876449585, 1.2176361083984375, 0.7875388264656067, -0.491774320602417, 0.2241969108581543, -0.6386129260063171, -0.5695160031318665, 0.7555840611457825, 0.1788812279701233, -0.3471006751060486, 1.1183546781539917, 0.3458511233329773, -0.2062147706747055, 0.14777326583862305, -1.2682313919067383, -0.43016383051872253, 0.9710131883621216, 0.7196865677833557, 0.37181931734085083, 0.5934875011444092, 0.2362423539161682, 1.36808443069458, 0.08031654357910156, 0.05125363916158676, 0.48605939745903015, 0.5015367865562439, -0.11825121194124222, -0.20382705330848694, -0.3121608793735504, 0.33098524808883667, -1.1004128456115723, -0.8068971633911133, 0.26772767305374146, 0.18293559551239014, 0.02457616850733757, 0.23745644092559814, 0.3866450786590576, 0.049937162548303604, 0.5068302750587463, 0.5145436525344849, 0.7031131982803345, -0.5372530221939087, 0.07509125024080276, -0.17821753025054932, -0.5076224207878113, -0.2649085819721222, -0.021923860535025597, -0.058514732867479324, -0.5220357179641724, -0.37318435311317444, -0.07046753913164139, -0.3216625154018402, 0.23461875319480896, 1.3279674053192139, 0.3529174327850342, 0.527996838092804, -0.16091671586036682, -0.5421795845031738, -0.5571100115776062, -0.4361008107662201, 0.12726260721683502, -0.7458811402320862, -0.11094799637794495, -0.11396321654319763, 0.005988866090774536, 0.1733887493610382]}, "authors": [{"authorId": "1471876925", "name": "Praneeth Kacham"}, {"authorId": "1728881", "name": "V. Mirrokni"}, {"authorId": "2249561001", "name": "Peilin Zhong"}], "references": [{"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "b6d6c33298b852cf63edac233deca70530d69a2a", "title": "PaLM 2 Technical Report"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "39ed1c33af6f0a5fbc16354afcb223a03c9c139b", "title": "Fast Attention Requires Bounded Entries"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "dc0102a51a9d33e104a4a3808a18cf17f057228c", "title": "Transformer Quality in Linear Time"}, {"paperId": "53c3940f35b8b45d55ed49056282e1961954513d", "title": "Self-attention Does Not Need $O(n^2)$ Memory"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "3df83a60f55c64b40e6dbcd99cf9f67894a0736e", "title": "Do Transformers Need Deep Long-Range Memory?"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "01203341a8b5b7df21dec5359afe8cc388786ebf", "title": "Wiki-40B: Multilingual Language Model Dataset"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "8cef9900c04d7f661c08f4b5b1ed4337ace042a3", "title": "Transformer Dissection: An Unified Understanding for Transformer\u2019s Attention via the Lens of Kernel"}, {"paperId": "1bf64f0961da08ea0f9941bd899e916a385e9540", "title": "Adaptive Sampled Softmax with Kernel Based Sampling"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "88caa4a0253a8b0076176745ebc072864eab66e1", "title": "Language Modeling with Gated Convolutional Networks"}, {"paperId": "3e498f3dc80b276defcede984f456f4fef1f2e1f", "title": "An Exploration of Softmax Alternatives Belonging to the Spherical Loss Family"}, {"paperId": null, "title": "Oblivious sketching of high-degree polynomial kernels"}, {"paperId": null, "title": "2020) can be used to show that degree-p polynomial sketch as constructed in Figure 3 with sketch size r = \u03a9(\u03b5\u22122p log(1/\u03b5\u03b4)) satisfies the requirements"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Implementation of FlashAttention in Pallas"}]}