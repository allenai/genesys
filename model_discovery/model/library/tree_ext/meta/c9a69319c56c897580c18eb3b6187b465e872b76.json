{"paperId": "c9a69319c56c897580c18eb3b6187b465e872b76", "title": "Fourier Transformer: Fast Long Range Modeling by Removing Sequence Redundancy with FFT Operator", "abstract": "The transformer model is known to be computationally demanding, and prohibitively costly for long sequences, as the self-attention module uses a quadratic time and space complexity with respect to sequence length. Many researchers have focused on designing new forms of self-attention or introducing new parameters to overcome this limitation, however a large portion of them prohibits the model to inherit weights from large pretrained models. In this work, the transformer's inefficiency has been taken care of from another perspective. We propose Fourier Transformer, a simple yet effective approach by progressively removing redundancies in hidden sequence using the ready-made Fast Fourier Transform (FFT) operator to perform Discrete Cosine Transformation (DCT). Fourier Transformer is able to significantly reduce computational costs while retain the ability to inherit from various large pretrained models. Experiments show that our model achieves state-of-the-art performances among all transformer-based models on the long-range modeling benchmark LRA with significant improvement in both speed and space. For generative seq-to-seq tasks including CNN/DailyMail and ELI5, by inheriting the BART weights our model outperforms the standard BART and other efficient models. \\footnote{Our code is publicly available at \\url{https://github.com/LUMIA-Group/FourierTransformer}}", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2023, "citationCount": 4, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://aclanthology.org/2023.findings-acl.570.pdf", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "Fourier Transformer is able to significantly reduce computational costs while retain the ability to inherit from various large pretrained models, and achieves state-of-the-art performances among all transformer-based models on the long-range modeling benchmark LRA."}, "embedding": {"model": "specter_v2", "vector": [0.5284107327461243, 0.555338978767395, 0.08132226765155792, -0.5685930848121643, 0.03240170702338219, -0.33178889751434326, 0.791130006313324, -0.5509892702102661, -0.16879096627235413, -0.38796278834342957, 0.7635069489479065, 0.27622517943382263, 0.4909907281398773, -0.03140891715884209, -0.2407337725162506, 0.07934200763702393, -0.6032001376152039, 0.21433301270008087, -0.023812513798475266, -0.42727744579315186, -0.036883652210235596, -0.5664901733398438, -0.9125016331672668, 0.017826326191425323, 0.3515150249004364, 0.7726649045944214, 0.5074113607406616, 0.8620696663856506, -0.5687278509140015, 0.5228229761123657, 0.5268867611885071, -0.5646008253097534, 0.2291959673166275, -0.5274347066879272, -0.36972320079803467, -0.06213418394327164, 0.3368486166000366, -0.2860772907733917, -0.49518218636512756, 0.6128472089767456, 0.11207903176546097, 0.27004915475845337, 0.400984525680542, -0.44100964069366455, -0.2358643114566803, 1.0060590505599976, 0.5910950303077698, 0.8365751504898071, -0.4344107210636139, -0.6014305949211121, 1.0338213443756104, -1.225370168685913, 0.1920916736125946, 1.6199162006378174, 0.6032019853591919, 0.5923770070075989, -0.006790397688746452, -0.7079663872718811, 0.38937854766845703, 0.13892963528633118, -0.559717059135437, -0.29945099353790283, 0.18504634499549866, -0.1988605558872223, 1.785762906074524, -0.4990616738796234, 0.03169208765029907, 0.9890569448471069, 0.31523504853248596, 0.8918485641479492, 0.051928404718637466, -0.40053319931030273, -0.4967973530292511, -0.1410255879163742, 0.3492105007171631, 0.7958328127861023, -0.881563663482666, 0.20856589078903198, -0.8817870020866394, 0.015219648368656635, 0.6530857086181641, 0.062501922249794, 0.2945369482040405, 0.15927480161190033, 0.11556541174650192, 0.6557709574699402, 0.426886647939682, 0.9375048279762268, -0.01657688245177269, 0.8348967432975769, 0.6449770331382751, 0.24511867761611938, -0.10791496932506561, 0.04509590566158295, 0.10702895373106003, 0.2959946393966675, -0.7125444412231445, 0.07809329777956009, -0.3219296336174011, 1.1971185207366943, -0.13184092938899994, 0.554510235786438, -0.336560994386673, 0.38163843750953674, 1.3839435577392578, -0.16462892293930054, 1.0087273120880127, -0.6314600110054016, -0.13918781280517578, -0.8724932074546814, -0.3862467408180237, -0.45038166642189026, 0.013872276991605759, -0.8263955116271973, -1.1129932403564453, -1.3895342350006104, -0.6177504062652588, 0.4588199257850647, -0.9756804704666138, 0.7156075239181519, -0.5806779265403748, 0.4217400848865509, -0.25591757893562317, 0.05208409205079079, 0.5315781831741333, 0.7958229184150696, 0.3789120316505432, 0.07200129330158234, 0.8090387582778931, -1.1285595893859863, -0.6365219354629517, -0.8970175981521606, 0.0912730023264885, -0.012973476201295853, 0.18828819692134857, -0.2874138355255127, -1.1237423419952393, -1.4233554601669312, -0.6814327836036682, -0.049379125237464905, -0.4006865620613098, -0.0879659578204155, 0.8501202464103699, 0.25183501839637756, -0.7711097002029419, 1.2429225444793701, -0.3316865861415863, -0.2818959057331085, 0.7254001498222351, -0.022242004051804543, 0.24839338660240173, -0.09788826107978821, -1.382863163948059, 0.310912162065506, 0.13135290145874023, -0.12636175751686096, -0.13467100262641907, -0.7452998161315918, -0.9877719283103943, 0.21921534836292267, 0.12080522626638412, -0.36779141426086426, 1.3046590089797974, -0.39077144861221313, -1.1776940822601318, 0.3895953595638275, -0.3205775320529938, -0.24111413955688477, 0.3116019666194916, -0.2507506012916565, -0.43087252974510193, -0.7778186798095703, -0.1616232991218567, 0.5262327790260315, 0.737586498260498, -0.03702597692608833, 0.06604555994272232, 0.14799277484416962, -0.6048496961593628, -0.4150010943412781, -0.12372222542762756, 0.8992573022842407, -0.44311580061912537, -0.478537917137146, -0.05399090424180031, 0.37172800302505493, 0.18130500614643097, -0.5522637367248535, -0.11257783323526382, -1.069939136505127, 0.996180534362793, 0.058606382459402084, 0.9872095584869385, -0.9872516989707947, -1.1541831493377686, -0.254989892244339, -0.40010499954223633, -0.31747615337371826, -0.8924269676208496, 0.7175400257110596, -0.6511904001235962, 0.31859272718429565, 0.04570276290178299, -1.0530931949615479, -0.11845675855875015, -0.24118606746196747, -0.7937111854553223, -0.11260808259248734, 0.10217656195163727, 1.351665735244751, -0.7998399138450623, -0.022167982533574104, 0.043888866901397705, 0.6101787090301514, -0.7737915515899658, 1.1945534944534302, -0.26814737915992737, -0.14232218265533447, 0.18275322020053864, -0.21240796148777008, -0.055191200226545334, -0.593423068523407, 0.24992989003658295, -0.3532460033893585, 0.050435565412044525, 0.5902360677719116, -0.023004185408353806, 1.5153034925460815, -0.2441031038761139, 0.5542142987251282, -0.6218276619911194, -0.5351547002792358, 0.48907729983329773, 0.09767281264066696, -0.16871905326843262, -0.48767250776290894, 0.44536706805229187, 0.22211308777332306, -0.46014487743377686, 0.32469743490219116, 0.35316017270088196, 0.4704544246196747, -0.34732210636138916, 0.1164817363023758, 0.9830498099327087, 0.005346443969756365, 0.28680410981178284, 0.38223952054977417, 0.6600481271743774, 0.5745996236801147, 0.3327428996562958, -0.30519306659698486, 0.18254594504833221, -1.1771206855773926, -0.0938660055398941, 0.44319412112236023, 0.6368263959884644, 1.1851143836975098, 0.1455506831407547, -0.7469220161437988, -0.4901368021965027, -0.03441467881202698, 0.7545750737190247, 1.3946666717529297, -0.3098475933074951, -0.3088317811489105, -0.6594340801239014, -0.15191130340099335, -0.40545302629470825, 0.03159603849053383, -0.7301166653633118, -0.36460402607917786, -0.6668999195098877, -0.6872967481613159, 0.7853374481201172, 0.5585891008377075, 1.2322003841400146, -0.6271620988845825, -0.49678677320480347, 0.08879345655441284, 0.18656755983829498, -0.6840890645980835, -1.1155163049697876, 0.46134722232818604, -0.5323786735534668, 0.28041598200798035, -0.1553650200366974, 0.17820018529891968, -0.060468707233667374, -0.693140983581543, 0.7178553342819214, -0.760932981967926, -0.620571494102478, 0.09219862520694733, 0.47026076912879944, -0.6789184212684631, -0.7386258244514465, 0.38205134868621826, -0.056121826171875, 0.11456979066133499, 0.14409826695919037, 0.10656528174877167, -0.05898424983024597, 0.21747148036956787, -0.3160747289657593, -0.08826880156993866, 0.10371793061494827, 0.07062242925167084, 0.44092506170272827, -0.04782778024673462, 0.37287384271621704, -1.2292343378067017, 0.6059172749519348, 0.45544546842575073, -0.20527316629886627, 0.030500665307044983, -0.5991511940956116, -0.32503995299339294, 0.4065997302532196, -0.8325637578964233, -0.4384666681289673, -0.6366683840751648, 0.004970885813236237, -0.6485347747802734, -0.12389127910137177, -0.11642922461032867, 0.04802554473280907, 0.40320590138435364, 0.2355705052614212, 0.6928892731666565, 0.45114976167678833, -0.12024451792240143, 0.29873383045196533, -0.8988576531410217, 0.8722608089447021, 0.6419510245323181, 0.25920355319976807, -0.03383014351129532, -0.1094566360116005, -0.654761016368866, -0.5873259902000427, -0.6264566779136658, -0.5409079790115356, -0.5360634922981262, 0.29708898067474365, -0.5551115274429321, -0.9793697595596313, -0.01353075634688139, -0.7718320488929749, -0.0769490972161293, 0.035318177193403244, -0.4897736608982086, -0.4621930420398712, -1.0419422388076782, -1.0978033542633057, -0.7686082720756531, -0.6442964673042297, -0.38791143894195557, 0.2641128599643707, 0.22135858237743378, -0.5292913913726807, -0.7744178771972656, -0.10635103285312653, -0.38513243198394775, 1.264178991317749, -0.31860214471817017, 0.5781679153442383, -0.18129797279834747, -0.31082117557525635, -0.07359034568071365, 0.3370436429977417, 0.7888550162315369, 0.030897231772542, 0.06035177782177925, -1.0104188919067383, 0.2139756679534912, -0.09706686437129974, -0.07289271056652069, 0.5092329382896423, 0.3230944275856018, 0.843254029750824, 0.17863363027572632, -0.3106124699115753, 0.24870388209819794, 1.4608803987503052, -0.3428078293800354, 0.44888341426849365, -0.09447670727968216, 0.84273761510849, 0.18459157645702362, -0.34148579835891724, 0.595916211605072, 0.1619705706834793, -0.05329986661672592, 0.20511406660079956, 0.0360242985188961, -0.10908874869346619, -0.9166867733001709, 0.5477786064147949, 1.3684824705123901, -0.06831015646457672, 0.01913907378911972, -0.8718964457511902, 0.6227046251296997, -1.2410029172897339, -1.370737075805664, 0.8197652101516724, 0.32467272877693176, 0.18279771506786346, -0.3726780414581299, -0.14236696064472198, -0.22084422409534454, 0.614507794380188, 0.4935438930988312, -0.34921449422836304, -0.6305775046348572, -0.1373850256204605, 0.4276955723762512, 0.09791180491447449, 0.5315214991569519, -0.20786747336387634, 0.42917630076408386, 15.112442970275879, 0.6850979328155518, -0.14757049083709717, 0.5904800891876221, 0.8291890025138855, 0.3324674069881439, -0.32326531410217285, -0.32717248797416687, -1.5229215621948242, 0.06073126569390297, 1.2235139608383179, 0.20297688245773315, 0.5199970602989197, 0.26367974281311035, -0.025337334722280502, 0.5284906029701233, -0.5714082717895508, 0.8204154372215271, 0.7369462251663208, -1.308916449546814, 0.05474214628338814, 0.3693089187145233, 0.33338403701782227, 0.5618783235549927, 0.7065861821174622, 0.777362585067749, 0.3663686215877533, -0.48696592450141907, 0.4381752014160156, 0.4947696626186371, 0.7782390117645264, -0.11084257066249847, 0.3878971338272095, 0.4552892744541168, -0.9332498908042908, -0.4424179792404175, -0.6587174534797668, -0.6912152767181396, 0.35949787497520447, 0.2651631534099579, -0.28813260793685913, -0.3418769836425781, 0.05826703831553459, 0.9107236266136169, -0.01644757390022278, 0.24682120978832245, 0.172335684299469, 0.5815756916999817, 0.11339225620031357, 0.216476172208786, 0.4846799075603485, 0.5812736749649048, 0.0874076709151268, 0.167514368891716, 0.30811449885368347, 0.062001749873161316, -0.2670382857322693, 0.5931645631790161, -0.589832603931427, -0.21210747957229614, -0.2719480097293854, -0.5615283846855164, -0.45605042576789856, 0.8313629627227783, 0.33053895831108093, 0.3128295838832855, -0.10048241168260574, 0.542746901512146, 0.367605596780777, 0.023591330274939537, -0.9327148199081421, -0.07677296549081802, 0.17390333116054535, 0.11879424005746841, 0.1589956283569336, 0.44454947113990784, 0.04441811144351959, -0.4801482558250427, -0.8632025718688965, -0.1955719143152237, 0.33328914642333984, -0.9811901450157166, -0.958206295967102, 1.0898233652114868, -0.25836992263793945, -0.1805601865053177, 0.1423047035932541, -0.4990974962711334, -0.35842230916023254, 0.3396233320236206, -1.3401941061019897, -0.7741415500640869, -0.09109103679656982, -0.2888714075088501, 0.17947953939437866, -0.17323768138885498, 0.680763840675354, 0.2656474709510803, 0.2660478353500366, -0.13841374218463898, -0.402477502822876, -0.04125247895717621, -0.30432748794555664, -0.5044141411781311, 0.8426296710968018, 0.06396171450614929, -0.18261578679084778, 0.4128209054470062, 0.020420437678694725, 0.10448098927736282, -0.6501511931419373, -0.28857100009918213, 0.8378991484642029, -0.8725563883781433, -0.42509523034095764, -1.2750585079193115, -0.8709003925323486, 0.2868342101573944, 0.730390191078186, -0.21564987301826477, 0.07669113576412201, -0.16489776968955994, -0.747348964214325, -0.37262552976608276, -0.585435152053833, -0.3036518394947052, 0.7741852402687073, -0.8778439164161682, -0.1506619155406952, -0.38821080327033997, 0.33489686250686646, -0.6813867092132568, -0.39942604303359985, -0.055174753069877625, 0.4561493992805481, -0.4032813608646393, 0.7181293368339539, -0.13073411583900452, 0.7220953702926636, 1.0063403844833374, 0.07093510776758194, -0.523641049861908, -0.19489942491054535, -1.2092441320419312, 0.2869235873222351, 0.7372989654541016, 0.4173172116279602, -0.40330514311790466, 0.27845388650894165, 0.4357258677482605, 0.3095262944698334, -0.5202546715736389, -0.6144582629203796, -0.6141527891159058, -0.15598611533641815, -0.43804606795310974, 0.2346634417772293, -0.15270139276981354, -0.3148379921913147, 0.3090578019618988, 0.08756277710199356, 0.00770331546664238, -0.2573870122432709, -0.5812086462974548, 0.017539259046316147, -0.1940743774175644, -0.27302274107933044, -0.3898876905441284, -0.4037151336669922, -1.4960869550704956, 0.12408857047557831, -1.0972301959991455, 0.0074256109073758125, -0.8421459794044495, -0.10475689172744751, 0.45143428444862366, -0.03572054207324982, -0.1203630119562149, 0.603234052658081, -0.41784393787384033, -0.09786099195480347, -0.6849212050437927, -0.3284466564655304, 0.9219853281974792, 0.9739325046539307, -0.6366629600524902, 0.3031032085418701, 0.04597340151667595, -0.029776711016893387, 0.21816857159137726, 0.2955331802368164, -0.5555649399757385, -0.8270646333694458, -0.8416715860366821, 0.37532082200050354, -0.15072987973690033, -0.02898407354950905, -0.6516456604003906, 0.5195363759994507, 0.4490280747413635, 0.05833033099770546, -0.13003407418727875, 0.4087574779987335, -1.0654138326644897, -0.06792803853750229, 0.3741074800491333, -0.870898962020874, 0.4671216905117035, -0.07218446582555771, -0.46803250908851624, -0.3037717044353485, 0.6829352378845215, 0.5430911183357239, -1.2715028524398804, -0.3134599030017853, 0.580755889415741, -0.5097293853759766, -0.08351253718137741, -0.39494192600250244, -0.13911795616149902, -1.0629264116287231, -0.6969977021217346, -0.1891465038061142, 0.09524756669998169, -0.7233197689056396, 1.3676214218139648, 0.33682018518447876, -1.3635848760604858, 0.22652465105056763, 0.3386634886264801, -0.36644506454467773, -0.19035054743289948, 0.7911331057548523, 0.26575446128845215, -0.0007991995080374181, 0.4413892924785614, 0.11235672235488892, 0.20523601770401, -0.9468528628349304, 0.15458133816719055, 1.1116507053375244, -0.33463311195373535, -0.13700708746910095, 1.0088471174240112, -0.14707988500595093, -1.053023099899292, 0.06777817010879517, -0.8959351778030396, -0.4530828297138214, -0.14724475145339966, 0.5409786105155945, 0.2365180253982544, -0.3468959629535675, -0.2632383406162262, -0.539362907409668, 0.41631844639778137, 0.02273782156407833, -0.6148746609687805, 0.7979187369346619, -0.24417215585708618, -0.1328164041042328, 0.922801673412323, 1.2127152681350708, -0.7605422735214233, -0.5813132524490356, -0.5373623967170715, -0.5460324883460999, -0.31084924936294556, -0.24966682493686676, -0.35355010628700256, -0.48244720697402954, 1.0655603408813477, 0.42615625262260437, 0.35399988293647766, 0.3260909616947174, 0.044915053993463516, 0.13557195663452148, 0.49272027611732483, -0.1521478146314621, -0.6029142737388611, -0.2159934788942337, 1.6386373043060303, 1.503950595855713, -0.6055727005004883, -0.029364177957177162, -0.6283524036407471, -0.8618819117546082, 0.8008204102516174, 0.3886103332042694, -0.3106839060783386, 1.0955910682678223, -0.0002248427044833079, 0.010378575883805752, 0.4645957946777344, -1.444558024406433, -0.24046452343463898, 0.5644849538803101, 0.8962404131889343, 0.7079513669013977, -0.3943863809108734, 0.4126265347003937, 0.8188603520393372, 0.023271266371011734, -0.033748604357242584, 0.4217885732650757, 0.14508384466171265, -0.1168379858136177, 0.06018418073654175, 0.38357147574424744, 0.6360391974449158, -0.7700056433677673, -0.15647920966148376, 0.28449273109436035, 0.40166375041007996, 0.09494791179895401, 0.379562646150589, 0.9384989142417908, 0.10392041504383087, 0.5092940330505371, 0.46829158067703247, 0.6950444579124451, -0.4089268743991852, -0.5924964547157288, 0.40147510170936584, -0.9940921068191528, -0.24460388720035553, -0.30198216438293457, -0.6945227980613708, -0.49742501974105835, -0.00764791714027524, 0.1815534234046936, -0.2318647801876068, 0.40150290727615356, 0.9603825211524963, 0.434908002614975, 0.6636870503425598, -0.05203777551651001, -0.3474818468093872, -0.4565962553024292, -1.039551019668579, -0.047012779861688614, -0.42715582251548767, 0.013529307208955288, 0.1534019261598587, 0.09542196244001389, 0.10571007430553436]}, "authors": [{"authorId": "2165399443", "name": "Ziwei He"}, {"authorId": "3313797", "name": "Meng-Da Yang"}, {"authorId": "2521552", "name": "Minwei Feng"}, {"authorId": "2186332511", "name": "Jingcheng Yin"}, {"authorId": "2107937507", "name": "Xinbing Wang"}, {"authorId": "1831521", "name": "Jingwen Leng"}, {"authorId": "3146592", "name": "Zhouhan Lin"}], "references": [{"paperId": "f7fd184eaa573205dff97d86c836f3038143e87a", "title": "An Efficient Memory-Augmented Transformer for Knowledge-Intensive NLP Tasks"}, {"paperId": "e47da75675b9a3fe02ef1efadca39bc8cdfcdc17", "title": "Designing Effective Sparse Expert Models"}, {"paperId": "706c6b3781374b0b11f98f204a4ddd05b26ed009", "title": "Knowledge Infused Decoding"}, {"paperId": "fdf23f096e4721b18041c5ccc0a984ebfae72f01", "title": "DCT-Former: Efficient Self-Attention with Discrete Cosine Transform"}, {"paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"}, {"paperId": "e79d1206292bc5e67ba19737d87d4b2ea4a37105", "title": "Charformer: Fast Character Transformers via Gradient-based Subword Tokenization"}, {"paperId": "af679d69fcc1d0fcf0f039aba937853bcb50a8de", "title": "Luna: Linear Unified Nested Attention"}, {"paperId": "1f133158a8973fb33fea188f20517cd7e69bfe7f", "title": "FNet: Mixing Tokens with Fourier Transforms"}, {"paperId": "3122a2d7799ba585b993e432b3deb47659b3f3c1", "title": "Hurdles to Progress in Long-form Question Answering"}, {"paperId": "b3bf9fe13195e9aa70e1dac04e01fcff7008e812", "title": "Perceiver: General Perception with Iterative Attention"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "0b09448f7543453cc066416f547292dc1e4471f6", "title": "KILT: a Benchmark for Knowledge Intensive Language Tasks"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8", "title": "Generative Pretraining From Pixels"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "0b991a1a5bcdb13646ac0b6873d09bde4cc36fb5", "title": "Masked Language Modeling for Proteins via Linearly Scalable Long-Context Transformers"}, {"paperId": "4ca3b0ea12f02e2dea01a4aa505956bae5500a09", "title": "Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "49e5b09480189fc9b2316a54f9d1e55cf0097c8b", "title": "Lightweight and Efficient End-To-End Speech Recognition Using Low-Rank Transformer"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "83fac78857c7e65fe10a11a798674dd3cd259c1d", "title": "Using Local Knowledge Graph Construction to Scale Seq2Seq Models to Multi-Document Inputs"}, {"paperId": "f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1", "title": "Reducing Transformer Depth on Demand with Structured Dropout"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "ebf59587f8f170ff4241c42263bbfb9da5bd2135", "title": "ELI5: Long Form Question Answering"}, {"paperId": "f4238bd2385a52413ccbacfd9e409a650235bd13", "title": "Adaptive Attention Span in Transformers"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "fea820b7d953d32069e189af2961c28fd213470b", "title": "Pay Less Attention with Lightweight and Dynamic Convolutions"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "204a4a70428f3938d2c538a4d74c7ae0416306d8", "title": "A Structured Self-attentive Sentence Embedding"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "d1505c6123c102e53eb19dff312cb25cea840b72", "title": "Teaching Machines to Read and Comprehend"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "01d08fa6c229bf3070600e49f8ab05449361817e", "title": "Long-range Sequence Modeling with Predictable Sparse Attention"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values?"}]}