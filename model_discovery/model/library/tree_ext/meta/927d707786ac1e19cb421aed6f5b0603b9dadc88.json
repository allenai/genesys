{"paperId": "927d707786ac1e19cb421aed6f5b0603b9dadc88", "title": "Robustify Transformers with Robust Kernel Density Estimation", "abstract": "Recent advances in Transformer architecture have empowered its empirical success in various tasks across di\ufb00erent domains. However, existing works mainly focus on improving the standard accuracy and computational cost, without considering the robustness of contaminated samples. Existing work [40] has shown that the self-attention mechanism, which is the center of the Transformer architecture, can be viewed as a non-parametric estimator based on the well-known kernel density estimation (KDE). This motivates us to leverage the robust kernel density estimation (RKDE) in the self-attention mechanism, to alleviate the issue of the contamination of data by down-weighting the weight of bad samples in the estimation process. The modi\ufb01ed self-attention mechanism can be incorporated into di\ufb00erent Transformer variants. Empirical results on language modeling and image classi\ufb01cation tasks demonstrate the e\ufb00ectiveness of this approach.", "venue": "arXiv.org", "year": 2022, "citationCount": 5, "influentialCitationCount": 2, "openAccessPdf": {"url": "http://arxiv.org/pdf/2210.05794", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work leverages the robust kernel density estimation (RKDE) in the self-attention mechanism, to alleviate the issue of the contamination of data by down-weighting the weight of bad samples in the estimation process."}, "embedding": {"model": "specter_v2", "vector": [-0.09761196374893188, 0.9115444421768188, -0.48066431283950806, 0.026635702699422836, -0.7344867587089539, 0.4847690463066101, 0.49813926219940186, -0.5411407351493835, -0.15841995179653168, -0.3811590373516083, 0.4256076514720917, 0.5609598755836487, 0.3217018246650696, -0.04693137854337692, -0.3358303904533386, 0.1030375137925148, -0.8546845316886902, 0.38093990087509155, 0.3232661485671997, -0.06618468463420868, -0.5714434385299683, -0.7930763363838196, -1.2742246389389038, -0.10496910661458969, 0.6063321828842163, 1.0085235834121704, 0.097833551466465, 0.47806140780448914, -0.4601231813430786, 0.13694404065608978, 0.5570098757743835, -0.6985430121421814, 0.3809417188167572, 0.04803885146975517, 0.02808057703077793, 0.3168289065361023, 0.5888768434524536, -0.7337947487831116, -0.546095609664917, 1.2183606624603271, -0.19071172177791595, 0.2384621798992157, 0.7934601902961731, -0.8229743242263794, -0.921695351600647, 0.6183241009712219, 0.5443642139434814, 0.9794732928276062, -0.619722306728363, -0.8500667214393616, 1.1184684038162231, -1.7487900257110596, -0.18268723785877228, 1.517358660697937, 0.4627916216850281, 0.13550965487957, -0.5696690678596497, -0.8404958844184875, 0.23807469010353088, 0.23236237466335297, -0.9982291460037231, -0.5859242677688599, 0.0037487815134227276, -0.5141507387161255, 1.229506492614746, -0.7703095078468323, -0.43915560841560364, 0.5445073843002319, 0.12664704024791718, 1.546233892440796, 0.3387911021709442, -0.3598984479904175, -0.18194186687469482, 0.4556516706943512, 0.23756738007068634, 1.1578149795532227, -0.4818209111690521, 0.31377190351486206, -1.2016586065292358, -0.39584439992904663, 0.504035472869873, -0.268520712852478, 0.21795609593391418, -0.7245157361030579, -0.018640004098415375, 0.8918430805206299, 0.18959498405456543, 0.5003365278244019, -0.17370076477527618, 0.5719432234764099, 0.5413086414337158, 0.20139560103416443, 0.638697624206543, 0.04170067235827446, 0.09256410598754883, 0.38945549726486206, -0.9094216227531433, -0.01633094623684883, -0.24543248116970062, 1.0186805725097656, 0.18194878101348877, 0.7972090840339661, -0.7434854507446289, 0.6352064609527588, 1.4814938306808472, 0.6380892395973206, 0.6287259459495544, -0.14222322404384613, -0.12782104313373566, -0.8062891364097595, -0.037555284798145294, -0.9638358354568481, 0.08496768027544022, -0.030113013461232185, -0.9412262439727783, -1.3028818368911743, -0.28916922211647034, 0.6290973424911499, -1.010027289390564, 0.6035447120666504, -0.2586267292499542, 0.0764106884598732, -0.001375845749862492, 0.2694978415966034, 0.2945588231086731, 0.37641769647598267, 0.2748226225376129, 0.38469386100769043, 1.3073844909667969, -0.607771635055542, -0.8035398721694946, -0.6654923558235168, 0.1159825399518013, -0.18675747513771057, 0.18063652515411377, -0.3366200625896454, -0.9041255116462708, -1.254677414894104, -0.7214047908782959, 0.3153602182865143, -0.3187442421913147, 0.46235430240631104, 0.8878864049911499, 0.7434630990028381, -1.0121947526931763, 0.5896974205970764, -0.20627154409885406, -0.2940179705619812, 0.7173081040382385, 0.2521718442440033, -0.09553214907646179, -0.12340527027845383, -1.3078088760375977, 0.5471818447113037, 0.3710715174674988, -0.8623107671737671, -0.4285774528980255, -0.7588207721710205, -1.2534420490264893, -0.08793330192565918, 0.458871066570282, -0.11798515915870667, 1.0340687036514282, -0.2699289321899414, -1.4194555282592773, 0.5874072313308716, -0.27930188179016113, -0.1624673753976822, 0.19618286192417145, -0.42868441343307495, -0.5613377094268799, -0.5582621097564697, 0.2861887216567993, 0.03098718635737896, 1.1831862926483154, -0.120698481798172, -0.27889254689216614, -0.09617305546998978, -0.888897180557251, -0.3948765993118286, -0.2706989049911499, 0.8269249200820923, -0.4075242280960083, -0.6397112011909485, 0.22763821482658386, 0.5477102398872375, 0.2915011942386627, -0.284647136926651, -0.3990589678287506, -1.1145620346069336, 0.807280421257019, -0.058869339525699615, 0.8082838654518127, -1.3253170251846313, -1.1594500541687012, 0.3020193576812744, -0.14044615626335144, -0.19757282733917236, -0.6863173246383667, 0.3610142171382904, -0.6965076923370361, 0.10449618846178055, 0.11466638743877411, -0.7661675214767456, 0.5386664867401123, -0.4387294054031372, -0.7240710854530334, 0.056819140911102295, 0.28864094614982605, 0.9720609784126282, -0.7329685091972351, 0.19741074740886688, 0.0495014414191246, 0.2572917342185974, -0.6457789540290833, 1.4745378494262695, 0.09378399699926376, -0.5198573470115662, 0.027088815346360207, -0.09012439101934433, 0.5579503178596497, -0.20176494121551514, -0.039535339921712875, -0.6837555766105652, 0.2764362692832947, 0.12891840934753418, -0.6292387843132019, 0.9668692350387573, -0.1373436599969864, 0.3809725344181061, -0.13100549578666687, -0.8799319863319397, 0.47649872303009033, 0.4792880415916443, 0.045194488018751144, -0.6750425696372986, 0.1340102255344391, 0.38723108172416687, -0.8340787291526794, 0.22312785685062408, 0.5898902416229248, 0.6776480674743652, -0.20102223753929138, 0.4279704689979553, 1.0206270217895508, -0.2697164714336395, -0.09293628484010696, 0.07535374164581299, 0.6015998721122742, 0.31608089804649353, 0.6113051772117615, -0.5033650994300842, -0.08267609030008316, -1.1752965450286865, -0.26349684596061707, 0.6319887042045593, 0.3963416814804077, 0.738322377204895, 0.17758288979530334, -0.3205213248729706, -0.3911250829696655, -0.8239315152168274, 0.41268259286880493, 1.8301377296447754, -0.6221791505813599, -0.05544411018490791, -0.5336066484451294, -0.4414415955543518, -0.2560252845287323, -0.07136997580528259, -0.565241277217865, -0.4806036651134491, -0.08310865610837936, -1.2617937326431274, 0.6735633015632629, 0.35646483302116394, 1.315524935722351, -0.22904446721076965, 0.0035262585151940584, 0.1065659373998642, 0.4825649559497833, -0.591752290725708, -0.8408944606781006, 0.4034612476825714, -0.17598243057727814, -0.04435916617512703, -0.2586672306060791, 0.15715526044368744, 0.2250787764787674, -0.4369738698005676, 0.6526747941970825, -0.9868921041488647, -0.3472549617290497, 0.6247459053993225, 0.2467411458492279, -0.9348494410514832, -0.5940545797348022, 0.006243439391255379, 0.3874002993106842, 0.20820248126983643, 0.3582945168018341, 0.6083720922470093, 0.16331279277801514, 0.4318569600582123, -0.45255953073501587, -0.4115217626094818, 0.2252318114042282, 0.3953411877155304, 0.4333782196044922, 0.09434069693088531, 0.25243353843688965, -1.0277498960494995, 1.0295518636703491, -0.15710896253585815, -0.4904405176639557, 0.07423099875450134, -0.8290061950683594, -0.1260969489812851, 0.07792045921087265, -0.7249932885169983, -0.3347773551940918, -0.6972863674163818, 0.4126872420310974, -0.39563658833503723, 0.015915149822831154, -0.0837937593460083, 0.2039225548505783, 0.17292416095733643, 0.2675163149833679, 0.5111912488937378, 0.5970005989074707, 0.2580159902572632, 0.652454137802124, -0.7958158254623413, 0.546453595161438, -0.06361866742372513, 0.5593439936637878, 0.04685148224234581, -0.6550740599632263, -0.8934759497642517, -0.5611556172370911, -0.40746769309043884, -0.15357448160648346, -0.16221798956394196, -0.045853931456804276, -0.6478503942489624, -0.5617684721946716, -0.11214479804039001, -0.4096663296222687, 0.052191112190485, -0.37068819999694824, -0.09516001492738724, -0.5005117654800415, -1.221765398979187, -1.056552767753601, -0.9119377732276917, -0.6132697463035583, -0.9145144820213318, 0.5701459050178528, -0.019488904625177383, -0.19297659397125244, -0.3126000165939331, -0.20128615200519562, -0.5058807134628296, 1.3959678411483765, -0.9224646091461182, 0.5996704697608948, -0.4081379175186157, -0.5288292765617371, -0.16187630593776703, -0.18516454100608826, 0.897537350654602, 0.16450057923793793, -0.1546826809644699, -1.0485166311264038, 0.3016207814216614, -0.11928018182516098, -0.12456910312175751, 0.22296679019927979, 0.40990856289863586, 0.6616746783256531, 0.07283162325620651, -0.3415624499320984, -0.12139309197664261, 1.1092159748077393, -0.6637350916862488, 0.03805616870522499, 0.17080315947532654, 0.6969597339630127, 0.218576580286026, -0.2179916650056839, 0.4917590618133545, 0.55908203125, 0.587984025478363, -0.007075768895447254, -0.29127538204193115, 0.01730789989233017, -0.3647362291812897, 0.617225706577301, 1.4266945123672485, 0.5171074271202087, 0.34826841950416565, -0.8362480401992798, 0.8051515817642212, -1.3507683277130127, -0.9904900193214417, 0.8476519584655762, 0.7548530697822571, 0.16951005160808563, -0.6115152835845947, -0.12625755369663239, -0.4379359483718872, 0.5022593140602112, 0.27684009075164795, -0.1357068419456482, -0.10235302895307541, 0.0867941603064537, 0.637117862701416, 0.4878495931625366, 0.32097139954566956, -0.6573241353034973, 0.6332100033760071, 14.942026138305664, 0.8893657326698303, 0.1967560201883316, 0.7214574217796326, 0.4655669331550598, 0.7934777140617371, -0.08478450030088425, -0.27490195631980896, -0.8823205828666687, -0.015116188675165176, 1.0646979808807373, 0.02757928892970085, 0.3920608460903168, 0.5597013831138611, -0.17752335965633392, 0.08406869322061539, -0.4027459919452667, 0.709438681602478, 0.9189252853393555, -0.940375030040741, 0.2674766778945923, 0.36194226145744324, 0.1624143272638321, 0.5730167627334595, 0.9649147987365723, 0.7452062368392944, 0.6390838027000427, -0.23206926882266998, 0.5103123188018799, 0.6781489849090576, 0.6798626184463501, -0.12298762798309326, 0.3962912857532501, 0.15679647028446198, -0.9324597716331482, 0.05116332322359085, -0.7842823266983032, -0.3518572151660919, 0.11486499756574631, 0.45973652601242065, -0.8833223581314087, -0.4629358649253845, 0.16365689039230347, 0.33428844809532166, 0.009196305647492409, 0.3972846269607544, 0.26038649678230286, 0.7797515392303467, 0.0644548237323761, 0.4243505895137787, -0.28256797790527344, 0.3116193413734436, 0.10039176791906357, -0.1135498434305191, 0.3768146336078644, -0.22003385424613953, 0.3411799967288971, 0.4953906238079071, -0.3054249584674835, -0.0007707203039899468, -0.37131911516189575, -0.06417082250118256, -0.4462934732437134, 0.8324072957038879, 0.5058210492134094, -0.061260297894477844, -0.33315613865852356, 0.5863845944404602, 0.5994417667388916, 0.052105844020843506, -0.5255772471427917, 0.23697532713413239, 0.5914862751960754, -0.21467606723308563, 0.06781791895627975, 0.39738574624061584, 0.5246680378913879, -0.5513988137245178, -1.0306905508041382, -0.10044950246810913, 0.3853941857814789, -0.8906822204589844, -1.600247859954834, 0.6237092614173889, -0.05580243840813637, -0.19342558085918427, 0.44764718413352966, -0.803719699382782, 0.16390538215637207, 0.2980777323246002, -1.234448790550232, -0.6898820996284485, 0.30347931385040283, -0.0672210156917572, -0.3601551055908203, -0.36325013637542725, 1.329881191253662, 0.26523324847221375, -0.2019968181848526, 0.015396783128380775, 0.09273611009120941, 0.28325220942497253, 0.34530243277549744, -0.8941729068756104, 0.6731352806091309, 0.09726497530937195, 0.05371992290019989, 0.3360216021537781, -0.056416261941194534, 0.03859161213040352, -0.538907527923584, -0.17684821784496307, 0.0919422134757042, -0.8758734464645386, 0.03203370049595833, -1.025699257850647, -1.1594021320343018, 0.0938134640455246, 0.418860524892807, 0.2172929346561432, 0.4930652379989624, 0.21353362500667572, -0.713238537311554, -0.5091784000396729, -0.707792341709137, -0.20693282783031464, 0.2495398372411728, -1.2083250284194946, -0.30601370334625244, 0.010228156112134457, -0.10024981200695038, -0.9425832629203796, -0.5787681937217712, 0.02077896147966385, 0.16919288039207458, -0.30357006192207336, 1.1650735139846802, -0.06107340008020401, -0.026976728811860085, 0.6692758798599243, -0.28865885734558105, -1.0467791557312012, -0.412614107131958, -0.6120205521583557, -0.03772788494825363, 0.6111222505569458, 0.41714227199554443, -0.48316141963005066, 0.3716874420642853, 0.7747074365615845, 0.30979061126708984, -0.047880325466394424, -0.8754169940948486, -0.4266257584095001, -0.4668595790863037, -0.8217498660087585, 0.21241465210914612, -0.16274361312389374, -0.2915097773075104, -0.08964810520410538, 0.18479891121387482, 0.4898168742656708, 0.0758243203163147, -1.0726873874664307, 0.5413095951080322, -0.3162328004837036, 0.32677415013313293, -0.36184144020080566, -0.5911575555801392, -1.0350500345230103, 0.4747542440891266, -1.159695029258728, 0.2019565999507904, -0.794872522354126, -0.17987078428268433, 0.29208606481552124, -0.41528281569480896, -0.1876012235879898, 0.32635965943336487, -0.24378904700279236, -0.4758281707763672, -0.5142227411270142, -0.29707932472229004, 1.0110890865325928, 0.48232895135879517, -0.8173396587371826, 0.20110896229743958, 0.13004189729690552, -0.10836625099182129, 0.29693087935447693, 0.41042351722717285, -0.5302073359489441, -0.7154794335365295, -0.7127470374107361, -0.20699647068977356, -0.4794016480445862, 0.08219312131404877, -0.7021392583847046, 0.7014606595039368, 0.4129975438117981, 0.16252081096172333, 0.2062995284795761, 0.3675168752670288, -1.2115927934646606, -0.4325578212738037, -0.0036445234436541796, -0.4326622784137726, 0.16923430562019348, 0.04404126852750778, -0.2900896370410919, -0.24204610288143158, 0.8623597025871277, 0.28942787647247314, -1.0382637977600098, -0.6262894868850708, 0.7108851671218872, -0.7974098920822144, 0.3655722141265869, 0.021501680836081505, -0.2868782877922058, -1.03977632522583, -0.28273913264274597, -0.0703377053141594, -0.16910679638385773, -0.6823573112487793, 1.145089030265808, 0.6044902801513672, -1.5707236528396606, 0.3148399889469147, 0.7207937836647034, 0.42042744159698486, -0.3317420780658722, 0.6070963740348816, 0.3585566580295563, 0.4599975645542145, 0.2548624277114868, 0.09188659489154816, 0.2606038749217987, -0.6204614043235779, -0.06564641743898392, 0.8006521463394165, -0.06268388032913208, -0.19706867635250092, 0.8661618232727051, 0.01651924103498459, -0.8887378573417664, -0.0299973301589489, -1.1577767133712769, -0.21552222967147827, -0.10786686092615128, 0.6094326376914978, 0.05413638800382614, -0.30499154329299927, -0.37039315700531006, -0.3776848614215851, 0.06437273323535919, -0.24617412686347961, -0.6617447733879089, 0.2660426199436188, -0.19521349668502808, -0.2573135793209076, 0.7955994009971619, 0.5897964239120483, -0.583755612373352, -0.9732111096382141, -0.8281583189964294, -0.011474152095615864, -0.45746102929115295, 0.14196163415908813, 0.015957459807395935, -0.4198575019836426, 0.36263033747673035, 1.0068365335464478, 0.5277350544929504, -0.04112633690237999, 0.15090544521808624, -0.1992277204990387, 0.31761643290519714, 0.21414150297641754, -0.9317609071731567, -0.1171247810125351, 1.2418292760849, 1.0298078060150146, -1.0482908487319946, 0.2726191580295563, -0.42481160163879395, -0.7451173663139343, 0.7214211225509644, 0.5522906184196472, -0.23360219597816467, 1.2847199440002441, -0.1348372995853424, 0.003819830249994993, 0.007686396595090628, -0.705511748790741, -0.9915369153022766, 1.3668111562728882, 1.5223798751831055, 0.7417872548103333, 0.27276647090911865, 0.8698402047157288, 0.7967119812965393, 0.14474040269851685, -0.0742468386888504, 0.539291501045227, -0.05120525509119034, -0.5488932728767395, 0.04591205716133118, -0.029417412355542183, 0.8893330693244934, -0.5850580334663391, -0.4509265422821045, 0.3369947075843811, 0.9330499768257141, 0.16740255057811737, 0.419007807970047, 0.9268828630447388, -0.03007587417960167, 0.8415305614471436, 0.5258698463439941, 0.3874376714229584, -0.6798570156097412, 0.11409799009561539, -0.02341512218117714, -0.852017879486084, -0.2964895963668823, -0.5255151391029358, -0.5945724248886108, -0.2237117737531662, 0.2384173423051834, 0.054978661239147186, -0.0948622077703476, 0.28266143798828125, 0.8637071251869202, 0.4936724901199341, 0.3535463511943817, -0.4178889989852905, -0.04365004599094391, -0.39824414253234863, -1.078720211982727, -0.42697611451148987, -0.45051103830337524, 0.08549721539020538, -0.6425431370735168, 0.08528083562850952, -0.4331394135951996]}, "authors": [{"authorId": "2110566959", "name": "Xing Han"}, {"authorId": "32453998", "name": "Tongzheng Ren"}, {"authorId": "150322732", "name": "T. Nguyen"}, {"authorId": "145546032", "name": "Khai Nguyen"}, {"authorId": "1379535322", "name": "J. Ghosh"}, {"authorId": "3526349", "name": "Nhat Ho"}], "references": [{"paperId": "6f79b0f2b9fd6213ca04f80c86860148c2465864", "title": "Backdoor Attacks on Vision Transformers"}, {"paperId": "05f6d8319fd30e56e0216a708e1bb74b7d763ac8", "title": "Understanding The Robustness in Vision Transformers"}, {"paperId": "fe9d978f7718474e9613bac114c398614f09be71", "title": "Sinkformers: Transformers with Doubly Stochastic Attention"}, {"paperId": "48af9b314181b04edcc0b7224ffe4689036b755f", "title": "Improving Transformers with Probabilistic Attention Keys"}, {"paperId": "23d11338be48471b3979b13eb172ec67fc22244b", "title": "Modeling Concentrated Cross-Attention for Neural Machine Translation with Gaussian Mixture Model"}, {"paperId": "94eae578e6af3382f6449506965639f18aab3fa0", "title": "Video Swin Transformer"}, {"paperId": "0d46cbaf914da31a06ef2753e00b7f47e055e70d", "title": "Probabilistic Attention for Interactive Segmentation"}, {"paperId": "d8d2e574965fe733eb1416e03df2b5c2914fc530", "title": "A Survey of Transformers"}, {"paperId": "5863d7b35ea317c19f707376978ef1cc53e3534c", "title": "Rethinking Graph Transformers with Spectral Attention"}, {"paperId": "f864d4d2267abba15eb43db54f58286aef78292b", "title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem"}, {"paperId": "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500", "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling"}, {"paperId": "72f207c777e4a17180cc54ccc6a743d5f43227af", "title": "Choose a Transformer: Fourier or Galerkin"}, {"paperId": "5e4f03f68c6867d850f457dc5cc36738e5dff6c1", "title": "Vision Transformers are Robust Learners"}, {"paperId": "b8cee43a51c44f8f4448e78e41ecf081987707cf", "title": "Towards Robust Vision Transformer"}, {"paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6", "title": "Multiscale Vision Transformers"}, {"paperId": "43e51c1bfd69df518e2907f7a955e485985ba423", "title": "On the Robustness of Vision Transformers to Adversarial Examples"}, {"paperId": "d2a3bb6356d439146cd8d8e72dc728a1e3d93e7f", "title": "Understanding Robustness of Transformers for Image Classification"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "3a906b77fa218adc171fecb28bb81c24c14dcc7b", "title": "Transformers in Vision: A Survey"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "c9b56cb026a38e39bb0228faac57accd6f65e6f7", "title": "TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "8cef9900c04d7f661c08f4b5b1ed4337ace042a3", "title": "Transformer Dissection: An Unified Understanding for Transformer\u2019s Attention via the Lens of Kernel"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "81e1d123a85562555befb0243256b1a0d9fca014", "title": "Understanding and Improving Transformer From a Multi-Particle Dynamic System Point of View"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "49b64383fe36268410c430352637ed23b16820c5", "title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "b9de9599d7241459db9213b5cdd7059696f5ef8d", "title": "Character-Level Language Modeling with Deeper Self-Attention"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "f4b434c3ab979ecdd71bbed894b34de77590c6dd", "title": "Adversarial Risk and the Dangers of Evaluating Against Weak Attacks"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "7aa38b85fa8cba64d6a4010543f6695dbf5f1386", "title": "Towards Deep Learning Models Resistant to Adversarial Attacks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "bee044c8e8903fb67523c1f8c105ab4718600cdb", "title": "Explaining and Harnessing Adversarial Examples"}, {"paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd", "title": "ImageNet Large Scale Visual Recognition Challenge"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "64f260cac1a9b2240b748b8106d2339f25b98565", "title": "Robust kernel density estimation"}, {"paperId": "5798b65d3a9318e1847779ff0bdbef44f0ec36a7", "title": "An R and S-PLUS Companion to Applied Regression"}, {"paperId": "ee44540cbffa881162169299e0e79a51dc33ff9c", "title": "Robust Statistics\u2014The Approach Based on Influence Functions"}, {"paperId": "f9b10885e194f619d0c3d4e9c4ff068ac1dba46b", "title": "Robust Non-Linear Regression Using the Dogleg Algorithm"}, {"paperId": "de28c165623adabcdba0fdb18b65eba685aaf31d", "title": "On Estimation of a Probability Density Function and Mode"}, {"paperId": "2c455f0da2bd86a9b9ea432d1485049073d7c63d", "title": "Remarks on Some Nonparametric Estimates of a Density Function"}, {"paperId": "955f90930d48750e7239478b4eed440eb84131cd", "title": "FourierFormer: Transformer Meets Generalized Fourier Integral Theorem"}, {"paperId": "05b22d6ec2cff81bcfbac2a6cf67bc1e9ef0f60a", "title": "Improving Transformer with an Admixture of Attention Heads"}, {"paperId": "ba612bafda906c9e26b8e81d2548a7dde6434183", "title": "Probabilistic Transformer For Time Series Analysis"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "2068b4d5c95ea5c66c8a81e73337fc52466b8b18", "title": "Reinforcement Learning as One Big Sequence Modeling Problem"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "464\u2013468, New Orleans, Louisiana, June"}, {"paperId": "1e1dab377d9174be6a1079f09b96e9fc02bdf5ab", "title": "Robust Regression"}, {"paperId": "4d36e26e8fd958ca6184c283bb6459139590e7ab", "title": "Remarks on Some Nonparametric Estimates of a Density Function"}, {"paperId": null, "title": "An introduction to the \ufb01nite element method , volume 1221"}, {"paperId": "36e07bdcb9f8aa618d6d077238d3de2e7818a0f5", "title": "Robust statistics: the approach based on influence functions"}, {"paperId": "c87d57da3b1f2b467ef4995d30df832ee2281107", "title": "On robust estimation of the location parameter"}, {"paperId": "05175204318c3c01e3301fd864553071039605d2", "title": "On Estimating Regression"}, {"paperId": null, "title": "American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) , pages"}]}