{"paperId": "616e98ba9e60f36c6ee226cc66c787610f0bbb62", "title": "MM-Interleaved: Interleaved Image-Text Generative Modeling via Multi-modal Feature Synchronizer", "abstract": "Developing generative models for interleaved image-text data has both research and practical value. It requires models to understand the interleaved sequences and subsequently generate images and text. However, existing attempts are limited by the issue that the fixed number of visual tokens cannot efficiently capture image details, which is particularly problematic in the multi-image scenarios. To address this, this paper presents MM-Interleaved, an end-to-end generative model for interleaved image-text data. It introduces a multi-scale and multi-image feature synchronizer module, allowing direct access to fine-grained image features in the previous context during the generation process. MM-Interleaved is end-to-end pre-trained on both paired and interleaved image-text corpora. It is further enhanced through a supervised fine-tuning phase, wherein the model improves its ability to follow complex multi-modal instructions. Experiments demonstrate the versatility of MM-Interleaved in recognizing visual details following multi-modal instructions and generating consistent images following both textual and visual conditions. Code and models are available at \\url{https://github.com/OpenGVLab/MM-Interleaved}.", "venue": "arXiv.org", "year": 2024, "citationCount": 22, "influentialCitationCount": 2, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "MM-Interleaved is an end-to-end generative model for interleaved image-text data that introduces a multi-scale and multi-image feature synchronizer module, allowing direct access to fine-grained image features in the previous context during the generation process."}, "embedding": {"model": "specter_v2", "vector": [0.10700801014900208, 0.3581201434135437, 0.06494805961847305, -0.020673448219895363, -0.4438219666481018, -0.43690237402915955, 1.3693946599960327, -0.448849618434906, -0.19937026500701904, -0.774792492389679, 0.5903269648551941, 0.15054525434970856, 0.162300243973732, -0.11236722767353058, -0.383075475692749, -0.027639424428343773, -0.9168000817298889, 0.5468194484710693, -0.17773041129112244, -0.16041462123394012, -0.16132265329360962, -0.719065248966217, -1.3081964254379272, 0.34308433532714844, 0.31053826212882996, 0.23995810747146606, 0.5794188380241394, 1.584323525428772, -0.5516552329063416, 0.0355866402387619, 0.6665188074111938, -0.4959709346294403, 0.2883732318878174, -0.5073836445808411, -0.38906610012054443, 0.759391725063324, 0.33814457058906555, -0.4789137840270996, -0.7015498876571655, 0.08373083919286728, -0.09919106215238571, 0.09161807596683502, 1.053821086883545, -0.4084243178367615, -0.5601932406425476, 0.7729998826980591, 0.46314969658851624, 0.6269582509994507, -0.21323171257972717, -0.6688299775123596, 1.2484582662582397, -1.5069659948349, 0.5535894632339478, 1.315347671508789, 0.07941650599241257, 0.5088393688201904, -0.5625984072685242, -0.5165271162986755, 0.3423590064048767, 0.08616892248392105, -0.6536370515823364, -0.34172117710113525, -0.26353415846824646, -0.34076598286628723, 1.466965913772583, -0.5967645645141602, 0.4293508231639862, 0.8882494568824768, 0.22721606492996216, 1.4071617126464844, -0.27596041560173035, -1.3212615251541138, -0.6093458533287048, 0.0009529597591608763, -0.1090957522392273, 0.9880445003509521, -0.776824951171875, 0.7652952671051025, -1.1955630779266357, 0.4445836842060089, 0.904697597026825, -0.13130949437618256, 0.39193663001060486, 0.03803706914186478, -0.4712308347225189, 0.7351030111312866, 0.3564010262489319, 1.157296895980835, 0.27562955021858215, 0.46006131172180176, -0.003663337556645274, 0.077406145632267, -0.03385009244084358, -0.21752068400382996, 0.6656281352043152, 0.5854999423027039, -0.9004652500152588, 0.4056920111179352, -0.006440023425966501, 0.9189622402191162, 0.1064058467745781, -0.13180485367774963, -0.7189751863479614, 0.05209219828248024, 1.790828824043274, -0.04279044270515442, 0.8073596954345703, -0.29724594950675964, 0.44265371561050415, -1.2382603883743286, 0.19394373893737793, -0.6169554591178894, -0.1691392958164215, -0.1473388969898224, -0.5176950693130493, -1.0620027780532837, -0.13087856769561768, 0.4338110089302063, -1.4174648523330688, 0.4514126479625702, -0.1622311919927597, 0.10092030465602875, 0.022202681750059128, 0.3018483519554138, 0.5045107007026672, 0.6710906624794006, 0.5899765491485596, 0.33175501227378845, 1.1277596950531006, -0.9120009541511536, -0.7049741744995117, -1.2782058715820312, 0.0016031471313908696, -0.5527876019477844, 0.25737127661705017, -0.8455873727798462, -1.3341728448867798, -1.4009733200073242, -0.7034551501274109, 0.06526527553796768, -0.4281723201274872, 0.38809049129486084, 1.019423007965088, 0.12074825167655945, -0.9744977951049805, 0.6455373764038086, -0.31850963830947876, -0.4492943584918976, 0.35042494535446167, -0.3165428638458252, -0.09915255755186081, -0.17278830707073212, -1.0790212154388428, 0.0675060823559761, 0.09325873851776123, -0.633871853351593, -0.4828292429447174, -0.29652950167655945, -1.2548844814300537, -0.3235183358192444, 0.10574372857809067, -0.9190510511398315, 1.1507973670959473, -0.16400998830795288, -0.8978651165962219, 0.854113757610321, -0.6653514504432678, 0.20462851226329803, 0.23210500180721283, -0.1221468597650528, -0.2886205315589905, -0.4453999996185303, 0.1238805428147316, 0.9610487222671509, 0.667510986328125, -0.6078526973724365, -0.060548603534698486, -0.1189190000295639, -0.7558885812759399, 0.4008699357509613, 0.01212507113814354, 0.5863493084907532, -0.7663034200668335, -0.5435189604759216, 0.27851402759552, 0.4801691770553589, -0.1059037297964096, -0.593900203704834, -0.6870957612991333, -0.6535810828208923, 0.5948612093925476, 0.09062950313091278, 0.40536776185035706, -0.7980112433433533, -0.8859249949455261, -0.3585323393344879, -0.0028076081071048975, -0.6909593939781189, -1.0917165279388428, 0.933641791343689, -0.3388060927391052, 0.779118537902832, 0.24661026895046234, -1.6663199663162231, 0.09792014956474304, -0.28437063097953796, -0.4718923270702362, -0.4606914222240448, 0.4327794909477234, 1.5722861289978027, -0.6901105642318726, -0.3342542350292206, 0.05697295069694519, 0.2268877625465393, -0.45576950907707214, 1.2465753555297852, -0.5047485828399658, 0.3511645793914795, -0.18000183999538422, -0.49017244577407837, -0.39271554350852966, -0.46673384308815, -0.14973969757556915, -0.6066832542419434, -0.17613357305526733, 0.046318937093019485, -0.33010271191596985, 1.7586032152175903, -0.11098682880401611, 0.4140506684780121, -0.8875582814216614, -0.43331611156463623, 0.05674700438976288, 0.5251564383506775, -0.3545443117618561, -0.43533724546432495, 0.34679991006851196, -0.010999279096722603, -0.721831738948822, 0.07931707799434662, 0.9374461770057678, 0.38551491498947144, -0.4149233102798462, 0.5243861079216003, 0.8814381957054138, -0.4188697636127472, 0.7044652104377747, 0.6114326119422913, 0.5578955411911011, 0.5198150873184204, 0.10340633988380432, 0.2697348892688751, -0.11107094585895538, -0.9703009128570557, -0.9162032604217529, 0.6046273708343506, 0.7446117401123047, 1.4829599857330322, -0.0947551429271698, -0.7246434688568115, -0.617764949798584, -0.31547629833221436, 0.87042236328125, 1.2867298126220703, 0.05483360216021538, -0.29375073313713074, -0.6754814386367798, -0.07170119136571884, -0.7396092414855957, 0.012152786366641521, -0.9682481288909912, 0.080712229013443, 0.04376133158802986, -0.6172364354133606, 0.46217775344848633, 0.1573588103055954, 1.120587706565857, -0.8996858596801758, -0.33868634700775146, -0.2607211768627167, -0.18222694098949432, -0.5701619386672974, -0.9750178456306458, 0.3334919810295105, -0.0017757491441443563, 0.19576962292194366, -0.31541740894317627, -0.32528379559516907, 0.15940314531326294, -0.36122870445251465, 1.115046501159668, -0.38213446736335754, -0.8493541479110718, 0.5157479047775269, 0.3220040798187256, -0.724854052066803, -1.0505090951919556, -0.03233020752668381, -0.5780678391456604, -0.1865597665309906, -0.16850900650024414, 0.5426976680755615, -0.10470163822174072, 0.21457208693027496, -0.8730254769325256, 0.6571162343025208, 0.2569437026977539, 0.052963972091674805, 0.8898820877075195, -0.21455051004886627, -0.37297293543815613, -0.7602538466453552, 0.6780949234962463, 0.06459178030490875, 0.018226779997348785, 0.40880295634269714, -0.40291106700897217, -0.09661697596311569, 0.0774078518152237, -0.8020849823951721, -0.535117506980896, -0.4892328381538391, 0.583674430847168, -0.2632615864276886, -0.7326273918151855, -0.012900802306830883, 0.24855555593967438, 0.6129418015480042, 0.14946964383125305, 0.7596156001091003, 0.33620020747184753, 0.4121173620223999, 1.0470131635665894, -1.216285228729248, 0.748904287815094, 0.44098904728889465, 0.6118288040161133, 0.1046682745218277, -0.15848909318447113, -0.40859800577163696, -0.49605047702789307, -0.2038354128599167, -0.7322931885719299, -1.20003342628479, 0.9208095669746399, -0.41371244192123413, -0.3137769103050232, 0.2372673749923706, -1.209547519683838, -0.04348888620734215, 0.09851472824811935, -0.389556884765625, -0.6730026602745056, -0.9162604808807373, -0.6728818416595459, -0.435512512922287, -0.24544744193553925, -0.837958812713623, 0.49033480882644653, 0.4670872092247009, -0.3921355903148651, -0.9771525263786316, 0.4114033281803131, -0.15907035768032074, 0.605759859085083, -0.4260023236274719, 0.3851822018623352, -0.05922175198793411, -0.38220512866973877, -0.29850277304649353, 0.41530096530914307, -0.13726863265037537, 0.1662081480026245, 0.45376408100128174, -0.7088603973388672, 0.46335017681121826, -0.5007286071777344, -0.510895848274231, 0.1505543291568756, 0.37164968252182007, 0.20607461035251617, 0.23416098952293396, -0.7341873645782471, 0.1675335168838501, 1.4152143001556396, -0.5176569819450378, 0.22471575438976288, 0.07516050338745117, 0.7368537783622742, 0.516451895236969, -0.3567809462547302, 0.6069367527961731, 0.6000764966011047, 0.41493117809295654, 0.10482602566480637, -0.4163772165775299, -0.4739100933074951, -0.9607889652252197, 0.4733242392539978, 1.1082565784454346, 0.20251792669296265, -0.5574110150337219, -1.0501518249511719, 0.7581424117088318, -1.3179926872253418, -1.171269178390503, 0.6089185476303101, 0.47952449321746826, 0.20162150263786316, -0.8036699295043945, 0.15528759360313416, -0.3951185941696167, 0.6983612179756165, 0.3989052176475525, -0.23846805095672607, -0.10010954737663269, 0.006697318982332945, 0.2542314827442169, -0.21021392941474915, 0.4846464693546295, -0.5994333624839783, 0.3630218803882599, 14.4098539352417, 0.8867217898368835, 0.445068359375, 0.1341739445924759, 1.0654242038726807, 0.3602038025856018, -0.6442509889602661, -0.0936751738190651, -1.2591300010681152, -0.2840813398361206, 1.1656569242477417, 0.2196248471736908, 0.6566935777664185, -0.3618263006210327, 0.0231411661952734, 0.057808324694633484, -0.47630661725997925, 0.6055296063423157, 0.7534530162811279, -1.445212721824646, 0.574157178401947, 0.34770455956459045, 0.40243300795555115, 0.30003657937049866, 1.1319313049316406, 0.3932383358478546, 0.6987095475196838, -0.5884549021720886, 0.9254158139228821, 0.6840431690216064, 0.6399754881858826, -0.265882670879364, -0.144262433052063, 0.4599664807319641, -1.3412867784500122, 0.05135846883058548, -0.37804487347602844, -0.4604840874671936, 0.6537961363792419, -0.28295692801475525, -0.6362664103507996, 0.15687739849090576, 0.12117617577314377, 0.612055242061615, -0.33813661336898804, 0.09130534529685974, 0.04747725650668144, 0.2532554566860199, 0.36193522810935974, 0.2217099368572235, 0.4629564881324768, 0.5195295214653015, 0.2671528160572052, -0.1747359186410904, 0.46216124296188354, 0.06171218305826187, 0.04406767338514328, 0.7345519661903381, -0.1098010316491127, -0.1408918797969818, -0.7660378217697144, -0.351654589176178, -0.18466205894947052, 1.1548490524291992, -0.3308659791946411, 0.5110971927642822, -0.43420037627220154, 0.4199632704257965, 0.6083477735519409, -0.16604503989219666, -0.317134290933609, 0.4947153329849243, -0.387940376996994, -0.34730497002601624, 0.34752988815307617, 0.4621792733669281, 0.07563553005456924, -0.10172443836927414, -1.024499773979187, -0.03192780539393425, 0.22893455624580383, -1.0590800046920776, -1.432361125946045, 1.334429144859314, 0.040928684175014496, -0.6180627942085266, -0.4723951518535614, -0.21441657841205597, -0.5015165209770203, 0.6371004581451416, -1.0073920488357544, -1.2670495510101318, -0.025264030322432518, -0.03271469101309776, 0.0973331555724144, -0.32445281744003296, 1.01652193069458, -0.3071349263191223, 0.2000083029270172, -0.03572210669517517, -0.227913498878479, 0.0950278788805008, 0.1618548184633255, -0.8689094185829163, 1.1439229249954224, 0.2604943513870239, 0.8868433833122253, -0.08956645429134369, 0.2211698442697525, -0.043778106570243835, -0.47399353981018066, 0.07458057999610901, 0.6398173570632935, -1.0255656242370605, -0.454289972782135, -0.7278090715408325, -0.6253381967544556, 0.014197058975696564, 1.2562671899795532, -0.22987212240695953, 0.6320133805274963, -0.19090290367603302, -0.19272078573703766, 0.26224395632743835, -0.5466312766075134, 0.41303855180740356, 0.3551144599914551, -0.5938001871109009, -0.18799956142902374, -0.0006805637967772782, 0.1042034849524498, -1.1711328029632568, -0.2714921236038208, -0.7850148677825928, 0.49265503883361816, -0.5038694739341736, 0.906345546245575, -0.13738207519054413, 1.0445424318313599, 0.935175359249115, 0.2087523490190506, -1.1160787343978882, -0.46963170170783997, -0.7987791895866394, 0.26334819197654724, 0.7153413891792297, 0.677015483379364, 0.2100040763616562, 0.19565019011497498, 0.7193554043769836, 0.45537322759628296, -0.1352733075618744, -0.15443770587444305, -0.03938126191496849, 0.05481644719839096, -0.5370666980743408, 0.14512832462787628, -0.7586545944213867, -0.25142741203308105, 0.3413578271865845, 0.29588788747787476, 0.4546407461166382, -0.21545974910259247, -0.7446869611740112, 0.7259450554847717, 0.2241114228963852, -0.22227545082569122, -0.3619931638240814, -0.3949596881866455, -0.9832546710968018, -0.09536338597536087, -1.2702275514602661, 0.20228908956050873, -1.0923972129821777, 0.14207620918750763, 0.3953717052936554, 0.2464880496263504, 0.08975770324468613, 0.18107040226459503, -0.08031807094812393, 0.10092994570732117, -0.325612336397171, -0.3869650959968567, 0.7419524788856506, 1.3415387868881226, -0.6049956679344177, 0.1876988410949707, -0.2170676440000534, 0.043665289878845215, 0.07094716280698776, 0.07290951162576675, -0.34644243121147156, -1.0215954780578613, -1.0761839151382446, 0.16998131573200226, 0.19872194528579712, 0.31791168451309204, -0.9812734127044678, 0.4783780872821808, 0.7273012399673462, 0.37986254692077637, -0.5606488585472107, 0.1153094470500946, -0.694087564945221, 0.11595775187015533, -0.04918397590517998, -0.9943023324012756, 0.39875856041908264, 0.3715229034423828, -0.12933580577373505, -0.3859352171421051, 0.5313044786453247, -0.15125194191932678, -1.16543447971344, -0.7781473398208618, 0.6138271689414978, -0.5831589102745056, 0.06536435335874557, 0.10363613069057465, -0.21828514337539673, -0.8349822759628296, -0.7288963198661804, -0.3320680558681488, 0.04566280543804169, -0.41619548201560974, 1.244214415550232, 0.6864823698997498, -1.4939920902252197, -0.0668099895119667, 0.4720325469970703, -0.0048475563526153564, 0.04881705343723297, 1.0910547971725464, 0.018233612179756165, 0.3515958786010742, 0.32403677701950073, 0.08685461431741714, 0.1019374206662178, -1.102038860321045, -0.1196618303656578, 0.9019240736961365, -1.0934100151062012, 0.02557694911956787, 0.8472517132759094, 0.012904413975775242, -0.8092765212059021, -0.34646469354629517, -0.39468449354171753, -0.837059736251831, -0.0867471843957901, 0.8605092167854309, -0.1953403800725937, -0.28406456112861633, -0.3302924335002899, -0.13221193850040436, 0.7037174105644226, -0.5182380676269531, -1.221361756324768, 0.4266677498817444, -0.6611799597740173, 0.2921774685382843, 0.7604982256889343, 0.6103944778442383, -0.7353350520133972, -1.168221116065979, -0.41280820965766907, -0.7611795663833618, -0.07293693721294403, 0.20715807378292084, -0.6349352598190308, -0.4969415068626404, 0.4910823404788971, 0.8215042352676392, 0.6369622349739075, -0.01175993587821722, 0.7163408398628235, 0.14235492050647736, 0.20347563922405243, -0.22005006670951843, -0.47104012966156006, 0.18580584228038788, 0.9581239223480225, 1.300315260887146, -0.7052729725837708, 0.2236209511756897, -0.08052738010883331, -1.1175987720489502, 1.2129850387573242, 0.2544563412666321, -0.007346154656261206, 0.7771928906440735, 0.03818221390247345, 0.31941431760787964, 0.03513413295149803, -1.1896611452102661, -0.3624054491519928, 1.1408799886703491, 1.5938711166381836, 0.6547472476959229, 0.017366494983434677, 0.2907924950122833, 0.6285122036933899, 0.20610785484313965, 0.0665365681052208, 0.388540118932724, 0.26911526918411255, -0.05307793617248535, -0.5233417749404907, 0.008147567510604858, 0.6031810641288757, -0.3539595901966095, -0.28397563099861145, 0.23070913553237915, 0.7266075611114502, 0.3039950728416443, 0.8658663034439087, 1.1800251007080078, 0.010568217374384403, 0.15797193348407745, 0.31313198804855347, 0.9617318511009216, -0.34804990887641907, -0.09723642468452454, 0.3332083821296692, -1.0970269441604614, -0.011101576499640942, -0.7385884523391724, -0.8573794960975647, -0.501740574836731, 0.2361663430929184, 0.24502165615558624, -0.38512858748435974, 0.21756550669670105, 1.5807148218154907, 0.6002564430236816, 0.37201419472694397, 0.0500059649348259, -0.9701851606369019, 0.2995578646659851, -0.820892333984375, 0.19700437784194946, -0.3767101466655731, -0.18156132102012634, -0.4843278229236603, -0.1326996088027954, 0.6005542874336243]}, "authors": [{"authorId": "2176398517", "name": "Changyao Tian"}, {"authorId": "2578924", "name": "Xizhou Zhu"}, {"authorId": "2279394155", "name": "Yuwen Xiong"}, {"authorId": "2190474418", "name": "Weiyun Wang"}, {"authorId": "66350249", "name": "Zhe Chen"}, {"authorId": "2257133501", "name": "Wenhai Wang"}, {"authorId": "2279425844", "name": "Yuntao Chen"}, {"authorId": "152309485", "name": "Lewei Lu"}, {"authorId": "2276323159", "name": "Tong Lu"}, {"authorId": "2141009492", "name": "Jie Zhou"}, {"authorId": "2279401774", "name": "Hongsheng Li"}, {"authorId": "2258755556", "name": "Yu Qiao"}, {"authorId": "3304536", "name": "Jifeng Dai"}], "references": [{"paperId": "4b1b5e219fb41a7413599c3b2ca6a7fdf045d1a5", "title": "Generative Multimodal Models are In-Context Learners"}, {"paperId": "ea6982a936a2b263bbf46ff6eb27fc0b63fddaf7", "title": "VL-GPT: A Generative Pre-trained Transformer for Vision and Language Understanding and Generation"}, {"paperId": "154cc4e8a9e8ad24d4f9c9440b187d06b9ba57bd", "title": "SEED-Bench-2: Benchmarking Multimodal Large Language Models"}, {"paperId": "1ddbd08ad8cf22a5c66c4242194c4286328533bf", "title": "MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning"}, {"paperId": "458111ac5a0f73bb35a2acf55298268be25ccfa2", "title": "Ferret: Refer and Ground Anything Anywhere at Any Granularity"}, {"paperId": "124d4d374fbef2016fa9880489871a58a7450644", "title": "Improved Baselines with Visual Instruction Tuning"}, {"paperId": "e7d09b6f2bc878cf2c993acf675f409d0b55f35a", "title": "MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens"}, {"paperId": "5ba1525dc6d382ee0a4a1ca3c64fc5907ca64c67", "title": "Making LLaMA SEE and Draw with SEED Tokenizer"}, {"paperId": "c1e450284e7d6cac1855330a1197df8537df653f", "title": "InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition"}, {"paperId": "7b689adb8c156d6158660f90d1c86888ee281f63", "title": "DreamLLM: Synergistic Multimodal Comprehension and Creation"}, {"paperId": "f34b6b4f75fb4e6f2c5654ee13fb2479c6170b3a", "title": "Kosmos-2.5: A Multimodal Literate Model"}, {"paperId": "3803d1f291e162bdaa4678a2c5a2bbcf63c050f4", "title": "MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning"}, {"paperId": "fa75a55760e6ea49b39b83cb85c99a22e1088254", "title": "NExT-GPT: Any-to-Any Multimodal LLM"}, {"paperId": "bcac614f9774488447221ebb4f16f05e3975ec1e", "title": "Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization"}, {"paperId": "1a735015a1f7ef4f2ba2273ce5fcaaacfa9d1ea2", "title": "Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning"}, {"paperId": "659a12d71d8709c132ccd9ccd235f0024cae0239", "title": "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"}, {"paperId": "7fbc502441d66daf1f53765d5d86a8dfba9ab0ce", "title": "OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models"}, {"paperId": "94053805cd59f2e9a47fe3f080c7e7afefb337cc", "title": "Generative Pretraining in Multimodality"}, {"paperId": "ea566f87f6253bb2d32cf7b61cd3e2535a0c3f42", "title": "mPLUG-DocOwl: Modularized Multimodal Large Language Model for Document Understanding"}, {"paperId": "a9d5d97733ccb15002ff3cfb95b0a7d8ba5236e3", "title": "LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image Understanding"}, {"paperId": "e2a58fd18961c3941102989e3a3d0d27c615e015", "title": "Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic"}, {"paperId": "3b6179c293df29e31d31cea46476f104ab6950f2", "title": "Kosmos-2: Grounding Multimodal Large Language Models to the World"}, {"paperId": "948e8cfae92c2004f2dd5c9316f5972f8baaea21", "title": "OBELISC: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents"}, {"paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787", "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"}, {"paperId": "6fb5c0eff3696ef252aca9638e10176ecce7cecb", "title": "Generating Images with Multimodal Language Models"}, {"paperId": "52337fa31a213efde5f224d81e2108813c50bd3f", "title": "Improved Visual Story Generation with Adaptive Context Modeling"}, {"paperId": "42a30dc5470f54ec249f25d3c31e05d7c376c8e3", "title": "VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks"}, {"paperId": "8bd6a2a89503be083176f2cc26fabedb79238cbd", "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"}, {"paperId": "f9570989919338079088270a9cf1a7afc8db8093", "title": "DataComp: In search of the next generation of multimodal datasets"}, {"paperId": "ca6a2bc279be5a3349a22bfd6866ed633d18734b", "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"}, {"paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8", "title": "Visual Instruction Tuning"}, {"paperId": "df958800014d310b6df34ad83d771314d68fbb2d", "title": "Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved With Text"}, {"paperId": "a08b7123a7158f1a7fbbc18e8b5aaebd47980ecf", "title": "EVA-CLIP: Improved Training Techniques for CLIP at Scale"}, {"paperId": "3049c992adbd56e29c4d957ee0c4e9d05fe3c6d1", "title": "EVA-02: A Visual Representation for Neon Genesis"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "fbfef4723d8c8467d7bd523e1d0b703cce0e0f9c", "title": "Language Is Not All You Need: Aligning Perception with Language Models"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "efbe97d20c4ffe356e8826c01dc550bacc405add", "title": "Adding Conditional Control to Text-to-Image Diffusion Models"}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "cfca7eedc6ede9d363d1662280a74d78dcdc9d4a", "title": "Scaling Language-Image Pre-Training via Masking"}, {"paperId": "33ef78737ba57ecc1ff98c22369a8e17ed90eb98", "title": "Synthesizing Coherent Story with Auto-Regressive Latent Diffusion Models"}, {"paperId": "78281482c1fdad8e167bab39cc9955c73d58ae8f", "title": "EVA: Exploring the Limits of Masked Visual Representation Learning at Scale"}, {"paperId": "6a993404e07687b7edb7fb9a05092213a9419859", "title": "OneFormer: One Transformer to Rule Universal Image Segmentation"}, {"paperId": "e5c8960eb2ec034ffbd353ef39fd1cb541d3c7c9", "title": "LAION-5B: An open large-scale dataset for training next generation image-text models"}, {"paperId": "9f7914c2577626868e6a69f2c9605b38f941055b", "title": "StoryDALL-E: Adapting Pretrained Text-to-Image Transformers for Story Continuation"}, {"paperId": "17d068e78e6f25e65cb08319b19b58279bb8b214", "title": "Understanding Diffusion Models: A Unified Perspective"}, {"paperId": "af9f365ed86614c800f082bd8eb14be76072ad16", "title": "Classifier-Free Diffusion Guidance"}, {"paperId": "1243e13254bb4ea1f71b4be8a3e4e54ffd02d2fe", "title": "Scaling Autoregressive Models for Content-Rich Text-to-Image Generation"}, {"paperId": "a8fd9c1625011741f74401ff9bdc1c584e25c86d", "title": "Language Models are General-Purpose Interfaces"}, {"paperId": "f8d56373df3023f36af2a0c45cd371bf9fe924a8", "title": "Pretraining is All You Need for Image-to-Image Translation"}, {"paperId": "9695824d7a01fad57ba9c01d7d76a519d78d65e7", "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"}, {"paperId": "c431408780586268e8bcf2483b01a80728d10960", "title": "Vision Transformer Adapter for Dense Predictions"}, {"paperId": "a26a7a74f1e5fd562be95c3611a0680759fbdf84", "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models"}, {"paperId": "eed6a734c4f60c5b8dd9cae612da95c5c89d230b", "title": "Sphinx: Enabling Privacy-Preserving Online Learning over the Cloud"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "75bb9eda70751c63fc54dbe63377c673b7dbdb15", "title": "CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers"}, {"paperId": "c57293882b2561e1ba03017902df9fc2f289dea2", "title": "Hierarchical Text-Conditional Image Generation with CLIP Latents"}, {"paperId": "15e234a67f30d6761f1d7670d501095d1697b69c", "title": "Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors"}, {"paperId": "b611c501269224702d1a9942c8600a31ec66ab28", "title": "ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning"}, {"paperId": "1bfa62ddfa3f6691e0e40c06f8ead594b6449cfa", "title": "OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "c783e1fb3ce8514f981925ee590c00884660ee4e", "title": "CM3: A Causal Masked Multimodal Model of the Internet"}, {"paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d", "title": "High-Resolution Image Synthesis with Latent Diffusion Models"}, {"paperId": "7002ae048e4b8c9133a55428441e8066070995cb", "title": "GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models"}, {"paperId": "91dc75f94da13452a54ad5c03fab2c5fda87e9ba", "title": "Uni-Perceiver: Pre-training Unified Architecture for Generic Perception for Zero-shot and Few-shot Tasks"}, {"paperId": "ee1d0e141530190a2b0d834737096c5bfda6b304", "title": "Integrating Visuospatial, Linguistic, and Commonsense Structure into Story Visualization"}, {"paperId": "5e00596fa946670d894b1bdaeff5a98e3867ef13", "title": "SimVLM: Simple Visual Language Model Pretraining with Weak Supervision"}, {"paperId": "b82c5f9efdb2ae56baa084ca41aeddd8a665c1d1", "title": "Align before Fuse: Vision and Language Representation Learning with Momentum Distillation"}, {"paperId": "1197ae4a62f0e0e4e3f3fb70396b5ff06ef371aa", "title": "CogView: Mastering Text-to-Image Generation via Transformers"}, {"paperId": "d5611a92619548e7f2af5adb04070574c0dacac1", "title": "InfographicVQA"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "394be105b87e9bfe72c20efe6338de10604e1a11", "title": "Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts"}, {"paperId": "141a5033d9994242b18bb3b217e79582f1ee9306", "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"}, {"paperId": "47f7ec3d0a5e6e83b6768ece35206a94dc81919c", "title": "Taming Transformers for High-Resolution Image Synthesis"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "33eadd4e666a894306a22ba0839c5e0cef77280e", "title": "TextCaps: a Dataset for Image Captioning with Reading Comprehension"}, {"paperId": "29c3242cce0c78f96d7d90e0123b95cb0840f21a", "title": "On the General Value of Evidence, and Bilingual Scene-Text Visual Question Answering"}, {"paperId": "439369de9514e41e0f03fed552d8f6e5aebf51b2", "title": "Connecting Vision and Language with Localized Narratives"}, {"paperId": "c5ff974a69fd0c760b4855b819e61e89f31cfffe", "title": "Objects365: A Large-Scale, High-Quality Dataset for Object Detection"}, {"paperId": "1097cf8cf5961589ff693b069002e7181e24e631", "title": "OCR-VQA: Visual Question Answering by Reading Text in Images"}, {"paperId": "43ddb69219ce12b0ed213dcae7a16dda40b2c2e6", "title": "Multilingual Universal Sentence Encoder for Semantic Retrieval"}, {"paperId": "28ad018c39d1578bea84e7cedf94459e3dbe1e70", "title": "OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge"}, {"paperId": "af1f7739283bdbd2b7a94903041f6d6afd991907", "title": "Towards VQA Models That Can Read"}, {"paperId": "a7ac99d7cf3f568ab1a741392144b646b856ae0c", "title": "GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering"}, {"paperId": "3b87e795f1f501843f7f99e83e38f125f6af8600", "title": "StoryGAN: A Sequential Conditional GAN for Story Visualization"}, {"paperId": "8de82efafb912de15bde3bf2e40a31c1cf3dc1b7", "title": "Imagine This! Scripts to Compositions to Videos"}, {"paperId": "a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c", "title": "VizWiz Grand Challenge: Answering Visual Questions from Blind People"}, {"paperId": "7289a240c9425bc7cad87b3b835e5f0cac22f488", "title": "DVQA: Understanding Data Visualizations via Question Answering"}, {"paperId": "f466157848d1a7772fb6d02cdac9a7a5e7ef982e", "title": "Neural Discrete Representation Learning"}, {"paperId": "3c78c6df5eb1695b6a399e346dde880af27d1016", "title": "Simple and Effective Multi-Paragraph Reading Comprehension"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "231af7dc01a166cac3b5b01ca05778238f796e41", "title": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium"}, {"paperId": "7e232313a59d735ef7c8a9f4cc7bc980a29deb5e", "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"}, {"paperId": "1b80416cc2b05954941ac7e7dcbcc358c10e5ace", "title": "Visual Dialog"}, {"paperId": "3a7011346ce939e3251915e92ae2f252e4c7f777", "title": "A Hierarchical Approach for Generating Descriptive Image Paragraphs"}, {"paperId": "927987a48c2a519bbc097d8b6c925b64a85b7d8e", "title": "Visual Storytelling"}, {"paperId": "e65142010431ffc089b272a1174214e00693e503", "title": "Generation and Comprehension of Unambiguous Object Descriptions"}, {"paperId": "11c9c31dff70de92ada9160c78ff8bb46b2912d6", "title": "Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models"}, {"paperId": "97ad70a9fa3f99adf18030e5e38ebe3d90daa2db", "title": "VQA: Visual Question Answering"}, {"paperId": "696ca58d93f6404fea0fc75c62d1d7b378f47628", "title": "Microsoft COCO Captions: Data Collection and Evaluation Server"}, {"paperId": "258986132bf17755fe8263e42429fe73218c1534", "title": "CIDEr: Consensus-based image description evaluation"}, {"paperId": "92c141447f51b6732242376164ff961e464731c8", "title": "ReferItGame: Referring to Objects in Photographs of Natural Scenes"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "5ddb51ae85deca14dc7fc8adc07305c22a1ebe0a", "title": "Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities"}, {"paperId": null, "title": "Openllama: An open reproduction of llama"}, {"paperId": "8b55402ffee2734bfc7d5d7595500916e1ef04e8", "title": "nocaps: novel object captioning at scale"}, {"paperId": null, "title": "Chatgpt: Optimizing language models for dialogue"}, {"paperId": null, "title": "Introducing idefics: An open reproduction of state-of-the-art visual language model"}, {"paperId": null, "title": "Laion coco: 600m synthetic captions from laion2b-en"}]}