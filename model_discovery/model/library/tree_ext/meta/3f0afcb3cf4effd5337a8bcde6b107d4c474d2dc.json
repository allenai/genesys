{"paperId": "3f0afcb3cf4effd5337a8bcde6b107d4c474d2dc", "title": "Meta In-Context Learning Makes Large Language Models Better Zero and Few-Shot Relation Extractors", "abstract": "Relation extraction (RE) is an important task that aims to identify the relationships between entities in texts. While large language models (LLMs) have revealed remarkable in-context learning (ICL) capability for general zero and few-shot learning, recent studies indicate that current LLMs still struggle with zero and few-shot RE. Previous studies are mainly dedicated to design prompt formats and select good examples for improving ICL-based RE. Although both factors are vital for ICL, if one can fundamentally boost the ICL capability of LLMs in RE, the zero and few-shot RE performance via ICL would be significantly improved. To this end, we introduce Micre (Meta In-Context learning of LLMs for Relation Extraction), a new meta-training framework for zero and few-shot RE where an LLM is tuned to do ICL on a diverse collection of RE datasets (i.e., learning to learn in context for RE). Through meta-training, the model becomes more effectively to learn a new RE task in context by conditioning on a few training examples with no parameter updates or task-specific templates at inference time, enabling better zero and few-shot task generalization. We experiment Micre on various LLMs with different model scales and 12 public RE datasets, and then evaluate it on unseen RE benchmarks under zero and few-shot settings. Micre delivers comparable or superior performance compared to a range of baselines including supervised fine-tuning and typical in-context learning methods. We find that the gains are particular significant for larger model scales, and using a diverse set of the meta-training RE datasets is key to improvements. Empirically, we show that Micre can transfer the relation semantic knowledge via relation label name during inference on target RE datasets.", "venue": "Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence", "year": 2024, "citationCount": 2, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Micre (Meta In-Context learning of LLMs for Relation Extraction), a new meta-training framework for zero and few-shot RE where an LLM is tuned to do ICL on a diverse collection of RE datasets, delivers comparable or superior performance compared to a range of baselines including supervised fine-tuning and typical in-context learning methods."}, "embedding": {"model": "specter_v2", "vector": [-0.41473522782325745, 0.6748088002204895, -0.6075283288955688, -0.1098640114068985, -0.30729103088378906, -0.5819247364997864, 1.1955139636993408, -0.14771531522274017, -0.6756943464279175, -0.0037425344344228506, 0.8152279853820801, 0.12504956126213074, -0.021005339920520782, 0.14834201335906982, 0.28855183720588684, 0.3344643712043762, -0.8549612760543823, 0.6114290952682495, -0.0862499549984932, -0.8039331436157227, -0.06456264108419418, -0.6480968594551086, -0.2647603154182434, -0.0042919800616800785, 0.13062165677547455, -0.03612672910094261, 0.1055249348282814, 0.4038793742656708, -0.6867837309837341, 0.7549893260002136, 0.32108667492866516, -0.8402127623558044, 0.31091365218162537, 0.19426441192626953, -0.5159441828727722, -0.3034132122993469, 0.05835699662566185, -0.5896542072296143, -0.8268764615058899, 0.551541805267334, -0.20567269623279572, 0.3458786606788635, 0.7401899695396423, -0.44045189023017883, -0.29336389899253845, 1.2472338676452637, 0.8041841983795166, 0.48427897691726685, -0.386456698179245, -1.0674734115600586, 1.582841396331787, -1.738959550857544, 0.935177206993103, 1.0802286863327026, 0.26619821786880493, 0.49842971563339233, 0.10943193733692169, -0.6798251867294312, 0.1942354142665863, 0.24484744668006897, -1.275313138961792, -0.7091951370239258, -0.18351472914218903, -0.019867785274982452, 2.5810129642486572, -0.4249345362186432, -0.5594565868377686, 0.43421587347984314, -0.2982827126979828, 0.8328971862792969, -0.3870460093021393, -0.9112384915351868, -0.6649577021598816, 0.2119106948375702, 0.32375821471214294, 0.7131873965263367, -0.5121600031852722, 0.2646624743938446, -0.5075209140777588, 0.1348446011543274, 0.6907145380973816, -0.19354231655597687, -0.006574769038707018, 0.29701751470565796, -0.26109936833381653, 0.23212440311908722, 0.2601494789123535, 1.1286871433258057, 0.0027702644001692533, 0.24585171043872833, 0.5061776041984558, 0.47062137722969055, 0.028741607442498207, 0.7982736229896545, -0.3300873935222626, 0.2863282561302185, -0.6849435567855835, 0.11211924254894257, 0.42151939868927, 1.10596764087677, -0.2133198082447052, -0.12349166721105576, -0.8176499605178833, 0.5092792510986328, 0.6866425275802612, -0.9459861516952515, 0.47567689418792725, -1.0661686658859253, 0.5811213850975037, -0.28404465317726135, 0.6254515647888184, -0.6216327548027039, -0.4199609160423279, -0.3036748766899109, -0.7473614811897278, -1.4631803035736084, -0.3275592029094696, -0.0331093966960907, -0.12158272415399551, 0.663459837436676, -0.307736337184906, 0.4244600534439087, 0.4397536814212799, 0.4416487216949463, 1.31052827835083, 0.4433416426181793, 0.36474451422691345, -0.37724632024765015, 1.0370739698410034, -0.8643685579299927, -0.8474010229110718, -0.8338708281517029, 1.447156548500061, -0.00873409491032362, 0.03683573752641678, -0.7249521017074585, -0.8614442348480225, -0.5855353474617004, -0.9840870499610901, -0.34192466735839844, -0.8542697429656982, 0.7675060629844666, 0.9750557541847229, 0.15856406092643738, -0.3593255579471588, 0.9913299679756165, 0.07864896953105927, -0.22165192663669586, -0.11227808147668839, 0.058345090597867966, -0.08539760857820511, -0.22915202379226685, -1.668846607208252, 0.6656351685523987, 0.5268958806991577, -0.2763405740261078, 0.014931817539036274, -0.45109233260154724, -1.4931347370147705, 0.05988653376698494, 1.1308542490005493, -0.32342085242271423, 1.1679800748825073, 0.59587562084198, -1.1781543493270874, 1.1851165294647217, -0.30844783782958984, 0.15578505396842957, 0.363742858171463, -0.22982166707515717, -0.9508097171783447, -0.8900955319404602, 0.09234347194433212, 0.2011210322380066, -0.06676995754241943, -0.3920719623565674, -0.20461025834083557, 0.23308007419109344, 0.09582265466451645, 0.1205424889922142, 0.0589764304459095, 1.4072682857513428, -0.4220788776874542, -0.08909813314676285, 0.060396622866392136, 0.950674831867218, 0.2545655071735382, -0.6301859021186829, -0.4504455327987671, -1.7287317514419556, 0.5724779367446899, 0.048306357115507126, 1.2747726440429688, -0.49595367908477783, -0.69142746925354, -0.8477558493614197, 0.16064918041229248, 0.18804769217967987, -0.5978525876998901, 0.9833925366401672, -0.4516586363315582, 0.6972194314002991, 0.031522080302238464, -1.1893177032470703, -0.07675111293792725, 0.024647042155265808, -0.7565520405769348, -0.507643461227417, 0.1756368726491928, 1.361096978187561, -1.0337110757827759, -0.01759701408445835, 0.08093941956758499, -0.06248036399483681, -0.15320546925067902, 1.3201022148132324, -0.21592073142528534, -0.35042914748191833, -0.18439063429832458, -0.3050048053264618, -0.4207983911037445, -0.27114105224609375, 0.7421348690986633, -0.7080308794975281, -0.39512139558792114, 0.7313671708106995, -0.7399513125419617, 0.9877362251281738, -0.5027978420257568, 0.45317670702934265, -0.3989332616329193, -0.5337446928024292, 0.25049489736557007, 0.7522649765014648, -0.027140075340867043, -0.09252927452325821, 0.35220199823379517, 0.28631818294525146, -0.7258473038673401, -0.054388854652643204, 1.0324203968048096, 0.5795726776123047, -0.34082621335983276, 0.22273236513137817, 0.8470343351364136, -0.0053213066421449184, 0.7192092537879944, 0.6349638104438782, 0.6422755718231201, 0.4496345520019531, 0.8385757207870483, 0.3091457486152649, 0.22824780642986298, -0.7070151567459106, 0.2208940088748932, 0.2958230674266815, 1.1552648544311523, 0.4207187294960022, 0.2822834253311157, -0.43574172258377075, -0.5400334000587463, 0.38501062989234924, 0.6627641320228577, 1.5316399335861206, 0.4809923470020294, -1.1813716888427734, -0.5016395449638367, -0.584704577922821, -0.8142520785331726, 0.6556427478790283, -0.38922885060310364, -0.0185092743486166, -0.9942174553871155, -0.6933743357658386, 0.7188988924026489, 0.2024812549352646, 1.1113190650939941, -0.3820590674877167, -0.0833096131682396, 0.12429048120975494, -0.24289992451667786, -1.1513527631759644, -0.3548298180103302, 0.09036589413881302, -0.1685885339975357, -0.3358171284198761, 0.2733570635318756, -0.13261248171329498, -0.14803647994995117, -0.524476945400238, 1.2798373699188232, -0.3961088955402374, -0.32429203391075134, 0.1462164968252182, 0.5189366936683655, -0.1964728981256485, -0.481513649225235, 0.2551797032356262, -0.015201276168227196, -0.8228687047958374, 0.8722175359725952, 0.6094376444816589, 0.40562158823013306, 0.32641008496284485, -0.1348041296005249, 0.21135707199573517, -0.17671166360378265, 0.0013593208277598023, 0.4599621593952179, 0.018351130187511444, 0.42814555764198303, -1.417374610900879, 0.889755129814148, -0.32087278366088867, -0.38897714018821716, 0.9118748307228088, -0.8672387003898621, -0.46739307045936584, 0.6359025835990906, -0.8172057271003723, -0.5867238640785217, -1.159590721130371, 0.8373240232467651, -0.12424241751432419, -0.21842409670352936, 0.24972157180309296, -0.0929168239235878, 0.7188796997070312, 0.509238064289093, 0.17525538802146912, -0.4305047392845154, -0.5554520487785339, 1.0403467416763306, -0.5207897424697876, 0.5643352270126343, 0.012843668460845947, 0.13602541387081146, -0.3910743296146393, 0.03228276968002319, -0.6989665627479553, -0.7214844822883606, -0.9185076355934143, -0.9244254231452942, -0.03779388591647148, 0.20303724706172943, -0.5062397122383118, -0.5300760865211487, -0.3879687786102295, -1.323104977607727, -0.3273489475250244, 0.11324899643659592, -0.43876171112060547, -0.04770289361476898, -1.0022318363189697, -1.1310313940048218, -0.4947253167629242, -0.41412031650543213, -0.3154648244380951, 0.4819799065589905, 0.14600643515586853, -0.3694566488265991, -0.7173153162002563, 0.041770171374082565, -0.5280272364616394, 0.4968842566013336, -0.5129202604293823, 0.7038472890853882, -0.1489439606666565, -0.2491130530834198, 0.005556294694542885, 0.051995061337947845, 0.038708969950675964, 0.4084831774234772, -0.12605993449687958, -0.29691004753112793, 0.5208855867385864, -0.055167056620121, -0.34930315613746643, -0.18937574326992035, -0.2613111734390259, 0.46607428789138794, -0.04650067910552025, -0.8689221739768982, 0.38166508078575134, 1.6974035501480103, -0.48192840814590454, 0.21203182637691498, 0.15786917507648468, 0.9203247427940369, 0.9523612260818481, 0.1903681755065918, 0.2815224230289459, 0.6350523829460144, 0.7200051546096802, -0.24436019361019135, 0.014103997498750687, -0.1352718621492386, -0.5163905024528503, 0.29964780807495117, 1.3355169296264648, -0.3334869146347046, -0.010174796916544437, -0.952449381351471, 0.9131163954734802, -1.482708215713501, -0.9075619578361511, 0.4037819802761078, 0.5401251912117004, 0.7764660716056824, -0.9558737277984619, -0.5247445106506348, -0.8822959661483765, 0.4385948181152344, 0.152889683842659, -0.3160487711429596, -0.08361891657114029, -0.04814764857292175, 0.2657625377178192, 0.15740682184696198, 0.5532890558242798, -0.5203599333763123, 1.2246581315994263, 14.006081581115723, 0.960107147693634, 0.38002097606658936, 0.47026368975639343, 0.3944142460823059, 0.2247144728899002, -0.077094666659832, 0.14423063397407532, -1.7522565126419067, -0.6161519885063171, 0.8759915232658386, -0.21136733889579773, 0.5183142423629761, 0.10379341244697571, -0.13928665220737457, 0.4704520106315613, -0.8371419310569763, 0.8223519325256348, 0.4645884335041046, -1.5071923732757568, 0.3711199164390564, 0.273777037858963, 0.23520341515541077, 0.42631834745407104, 0.18923376500606537, 1.1974921226501465, 0.8370859026908875, -0.9754682779312134, -0.13368071615695953, 0.36335837841033936, 1.3213896751403809, -0.24196936190128326, 0.578372597694397, 0.9601115584373474, -0.8915819525718689, -0.2017700970172882, -0.9146491289138794, -0.5841121673583984, 0.26876300573349, -0.15697528421878815, -0.8280227780342102, 0.11475216597318649, -0.49144455790519714, 0.9516801834106445, 0.19959184527397156, -0.1986718475818634, -0.7162194848060608, 0.3236756920814514, 0.29259926080703735, 0.33246248960494995, 0.14403094351291656, 0.02236044965684414, 0.5924514532089233, 0.21865224838256836, -0.08234760910272598, 0.7901114225387573, -0.14229227602481842, 0.8555167317390442, -0.9161121845245361, 0.18688486516475677, -0.6525647044181824, -0.042057693004608154, 0.2872193455696106, 1.3650139570236206, 0.7610816955566406, -0.07292793691158295, -0.42824608087539673, 0.45003917813301086, 1.2104346752166748, 0.055675946176052094, 0.1426161527633667, -0.3596057593822479, 0.01035486999899149, -0.25567367672920227, -0.3806108236312866, 0.19175800681114197, -0.1027127057313919, -0.9937601089477539, -0.9801932573318481, 0.0953124612569809, 0.49393168091773987, -0.8119651675224304, -1.0133007764816284, 0.9269881844520569, -0.09328898042440414, -0.877842128276825, -0.6669365763664246, -0.684303343296051, -0.20313690602779388, 0.28859516978263855, -1.1116591691970825, -1.0196009874343872, -0.054035380482673645, -0.4253847599029541, -0.17296144366264343, -0.12901301681995392, 1.3521654605865479, 0.00888796802610159, -0.37528350949287415, 0.22086448967456818, 0.30961689352989197, 0.6728925108909607, 0.29542869329452515, -0.9735981822013855, 0.6775362491607666, 0.04708826169371605, 0.36748769879341125, 0.8696326613426208, -0.16609697043895721, -0.25576454401016235, -0.28785353899002075, -0.19846759736537933, 1.105287790298462, -1.3014450073242188, -0.542133092880249, -0.9327585697174072, -1.2343965768814087, 0.7339199781417847, 0.696032702922821, -0.2130378633737564, 0.4919878840446472, 0.45512545108795166, -0.3567480742931366, 0.12154481559991837, -0.9354407787322998, 0.6044343113899231, 1.007447600364685, -0.5899002552032471, -1.012284517288208, -0.11192681640386581, 0.275256872177124, -0.7651606202125549, -1.1784260272979736, -0.10406304895877838, -0.051440589129924774, 0.4336581230163574, 0.8804147243499756, -0.7930324077606201, 1.0160728693008423, 0.8102757930755615, -0.2693813145160675, -0.805664598941803, 0.13969703018665314, -0.9200074672698975, -0.4502277374267578, 0.7517568469047546, 0.8001899123191833, -0.09084196388721466, -0.1621711403131485, 1.4519401788711548, 0.6249293088912964, -0.4632055461406708, -0.26142334938049316, -0.8090095520019531, 0.32227087020874023, -0.10089677572250366, 0.22685855627059937, 0.5783173441886902, -0.04787135496735573, 0.8243523240089417, 0.344839870929718, 0.5202440023422241, -0.172276109457016, -0.7559340596199036, 0.5625682473182678, -0.11889933049678802, -0.19621391594409943, -0.2273602932691574, -0.0701344832777977, -1.3814926147460938, 0.294664204120636, -1.4104464054107666, -0.21094118058681488, -1.0659760236740112, -0.3770335912704468, 0.03726945072412491, -0.02863297611474991, 0.08736950159072876, 0.46282726526260376, -0.6834401488304138, -0.6293280124664307, -0.17669720947742462, -0.6086394786834717, 0.7217308878898621, 0.5534716248512268, -0.40326598286628723, -0.06400080770254135, -0.09778431057929993, -0.14846046268939972, 0.2198360562324524, 0.4251483380794525, -0.7621250748634338, -0.6164389252662659, -1.0812321901321411, 0.2864518165588379, 0.35195958614349365, -0.14856506884098053, 0.24678273499011993, 0.8163692951202393, 0.14838849008083344, -0.2743138074874878, -0.17812314629554749, 0.29299095273017883, -0.8065886497497559, -0.3554936349391937, -0.46946075558662415, -0.8197107911109924, -0.19009359180927277, -0.34716668725013733, -0.9292807579040527, -0.2654617428779602, 0.11847338825464249, -0.18935544788837433, -1.2252764701843262, -1.050346851348877, 0.4306771457195282, -0.16415444016456604, 0.16639867424964905, -0.09841553121805191, 0.029899291694164276, -1.098140001296997, -0.23006661236286163, 0.05900639668107033, 0.3995910882949829, -0.3210252523422241, 1.0417224168777466, 0.2062721997499466, -1.3350229263305664, -0.3063051104545593, -0.39878061413764954, 0.12618494033813477, 0.2276374101638794, 0.3179978132247925, -0.06742508709430695, 0.30945539474487305, 0.35013991594314575, 0.4586504399776459, 0.7253203392028809, -1.1967943906784058, -0.10342246294021606, 1.0838652849197388, -0.9001356959342957, -0.4337790906429291, 0.8603988289833069, -0.36710527539253235, -1.0180981159210205, -0.2395198792219162, -0.7707652449607849, -0.9459409117698669, -0.3973730802536011, 0.9178077578544617, 0.41155776381492615, -0.14898492395877838, -0.34351760149002075, -0.3364979028701782, 0.35904166102409363, -0.1968986690044403, -0.41929197311401367, 1.2562530040740967, -0.37441492080688477, -0.6423953175544739, 0.709926187992096, 0.864295244216919, -0.44493037462234497, -0.6188897490501404, -0.7694985866546631, 0.26597392559051514, -0.08841371536254883, 0.19059385359287262, -0.8707726001739502, 0.06068369001150131, 0.33882418274879456, -0.07113008201122284, 0.2754766047000885, -0.26526013016700745, 0.30996766686439514, 0.28513607382774353, 1.0065093040466309, 0.18795743584632874, -1.074058175086975, -0.7278624773025513, 1.288982629776001, 1.590816855430603, -1.145950436592102, 0.37103158235549927, -0.4947187602519989, -0.5578233599662781, 1.2160855531692505, 0.5400676727294922, -0.014322140254080296, 0.6386730670928955, 0.09267941862344742, -0.0015161604387685657, -0.26861363649368286, -1.2482863664627075, -0.39724284410476685, 0.8068016171455383, 1.0657339096069336, 0.9271665215492249, 0.20594815909862518, -0.045636869966983795, 1.2120099067687988, 0.013941517099738121, 0.14740630984306335, 0.5994313359260559, -0.0592028982937336, -0.14449933171272278, -0.43583643436431885, 0.7143954038619995, 0.5069503784179688, -0.6983609795570374, -0.5233233571052551, -0.535250186920166, 0.7899495959281921, 0.3941113352775574, 0.7744876146316528, 0.5972743034362793, 0.1635892242193222, 0.7459895014762878, 0.3376336097717285, 0.5219728946685791, -0.9110553860664368, -0.4660685658454895, -0.6523680090904236, -0.007493052165955305, -0.019507644698023796, -0.15131165087223053, -0.32308560609817505, -0.7323353886604309, 0.05101408436894417, -0.07113803178071976, -0.20966453850269318, 0.21854360401630402, 1.772235631942749, 0.5837089419364929, 0.03171704709529877, -0.20583480596542358, 0.33747902512550354, -0.2725337743759155, -1.1844779253005981, -0.0036937755066901445, -0.31175702810287476, -0.5363223552703857, -0.44867458939552307, 0.03901280090212822, -0.5572139024734497]}, "authors": [{"authorId": "91119265", "name": "Guozheng Li"}, {"authorId": "2257246692", "name": "Peng Wang"}, {"authorId": "2265716887", "name": "Jiajun Liu"}, {"authorId": "2292241341", "name": "Yikai Guo"}, {"authorId": "2284872859", "name": "Ke Ji"}, {"authorId": "2125194341", "name": "Ziyu Shang"}, {"authorId": "2117883657", "name": "Zijie Xu"}], "references": [{"paperId": "f42d060fb530a11daecd90695211c01a5c264f8d", "title": "Towards Continual Knowledge Graph Embedding via Incremental Distillation"}, {"paperId": "56a246997e51bd81da26a884b84c41c084d8a5fb", "title": "OntoFact: Unveiling Fantastic Fact-Skeleton of LLMs via Ontology-Driven Reinforcement Learning"}, {"paperId": "fca5d378f7858253c4dd1bbb71d09f7bbdc0a537", "title": "Unlocking Instructive In-Context Learning with Tabular Prompting for Relational Triple Extraction"}, {"paperId": "c4382ef185f93db523f805fe8e90ce1b50744563", "title": "Chain of Thought with Explicit Evidence Reasoning for Few-shot Relation Extraction"}, {"paperId": "497acdc02c50073e714838a8d4f16f7482d37e64", "title": "Revisiting Large Language Models as Zero-shot Relation Extractors"}, {"paperId": "574278a1b7955c9a56d65241e40410ff9899a88d", "title": "PasCore: A Chinese Overlapping Relation Extraction Model Based on Global Pointer Annotation Strategy"}, {"paperId": "4eee7b8ccb5ed06a644611a91ba43a0e876086be", "title": "fmLRE: A Low-Resource Relation Extraction Model Based on Feature Mapping Similarity Calculation"}, {"paperId": "0ee00888b34581890397bf31035057a35480f124", "title": "RE-Matching: A Fine-Grained Semantic Matching Method for Zero-Shot Relation Extraction"}, {"paperId": "67bce272a835acc0ce891890bdadc31d055cee77", "title": "Mutually Guided Few-Shot Learning For Relational Triple Extraction"}, {"paperId": "59acd784d30ac2b935e700a7a1c077dc935b2a8a", "title": "Hierarchical Verbalizer for Few-Shot Hierarchical Text Classification"}, {"paperId": "f2cd02c03d0169374442d9bc227c9aed178f4b20", "title": "GPT-RE: In-context Learning for Relation Extraction using Large Language Models"}, {"paperId": "bbb2fc6e95d24fb58ab6c25b216b14ac49a32fbe", "title": "InstructUIE: Multi-task Instruction Tuning for Unified Information Extraction"}, {"paperId": "0100785773b8217c44606ab260e3212f93b0a4fd", "title": "Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "f29e5a78378bd3d8ae8ec7caecf564fe3701c1dd", "title": "Zero-shot Triplet Extraction by Template Infilling"}, {"paperId": "faf73f722cb72f6fd4a0ebf9646f5e3407a72609", "title": "Better Few-Shot Relation Extraction with Label Prompt Dropout"}, {"paperId": "f4c78d817c8ad03659f4d5925ba8a9a3eabef83b", "title": "Relation-Guided Few-Shot Relational Triple Extraction"}, {"paperId": "686d9ee744fa013cc21cdd86acd864c936e9e456", "title": "Large language models are few-shot clinical information extractors"}, {"paperId": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large Language Models are Zero-Shot Reasoners"}, {"paperId": "2f291b0b59483e9c3c4a3391f34e6b29aff848a1", "title": "DeepStruct: Pretraining of Language Models for Structure Prediction"}, {"paperId": "cc128fe365b468cb87aff8d1d195999831e3a473", "title": "FastRE: Towards Fast Relation Extraction with Convolutional Encoder and Improved Cascade Binary Tagging Framework"}, {"paperId": "743dcf234cffd54c4e096a10a284dd81572b16ea", "title": "RelationPrompt: Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extraction"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "47df3fd32d00220c85c2c51a571254fd99b2ecc7", "title": "MetaICL: Learning to Learn In Context"}, {"paperId": "6bd91a3183ddb844641acb9f3fe9faec6a9ff617", "title": "Meta-learning via Language Model In-context Tuning"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "50da4158ab3a604e18f82862aab173d82c2c2714", "title": "Exploring Task Difficulty for Few-Shot Relation Extraction"}, {"paperId": "85061c524fdd5ec75f06a3329352621bb8d05f43", "title": "Label Verbalization and Entailment for Effective Zero and Few-Shot Relation Extraction"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "cbdb45fc16b0885905b91d84281c310e6cb49e9c", "title": "Cross-Task Generalization via Natural Language Crowdsourcing Instructions"}, {"paperId": "93df9dc530b1cf0af6d5eef90d017741a2aab5d8", "title": "ZS-BERT: Towards Zero-Shot Relation Extraction with Attribute Representation Learning"}, {"paperId": "50796b0f3edf9cb5ff1e447c298b33755378aa4f", "title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling"}, {"paperId": "56fa0b9cba4d9aee5ccc327365b3b3a721031c69", "title": "Calibrate Before Use: Improving Few-Shot Performance of Language Models"}, {"paperId": "53bb3924925503986948bd3872efecf77f795a6a", "title": "Few-Shot Event Detection with Prototypical Amortized Conditional Random Field"}, {"paperId": "cc9c7ab614e4e29d201416679d66571e760fa188", "title": "Bridging Text and Knowledge with Multi-Prototype Embedding for Few-Shot Relational Triple Extraction"}, {"paperId": "6dfd1e77584ef916d050063b80e9052d5cc354c6", "title": "Two Are Better than One: Joint Entity and Relation Extraction with Table-Sequence Encoders"}, {"paperId": "6a5608e6fee3ecc65361525906b0d092ad9952bb", "title": "Learning from Context or Names? An Empirical Study on Neural Relation Extraction"}, {"paperId": "725264948d7b6946259af5b8d966e996b9570f99", "title": "DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "76fd100c9776f9d42c61618f31df7a33a6ffda00", "title": "A Novel Cascade Binary Tagging Framework for Relational Triple Extraction"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "887f0c39d8d4e9433f0cf3316f593a0b0758a177", "title": "A Hierarchical Framework for Relation Extraction with Reinforcement Learning"}, {"paperId": "274b4ad4840b0a8a70c5bac3fe4b4861ce5fbb95", "title": "FewRel: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation"}, {"paperId": "b21b927c251c415b601b6d7f785a42cc5c292635", "title": "Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction"}, {"paperId": "ff17100b49e233f38180ad4b978ad35833778692", "title": "Improving Distantly Supervised Relation Extraction using Word and Entity Based Attention"}, {"paperId": "400e746bc8027c4b5f915cae6123cd1775484b4d", "title": "Position-aware Attention and Supervised Data Improve Slot Filling"}, {"paperId": "a4c40532e68728fbeab5d9415f6ad8e9530db360", "title": "The WebNLG Challenge: Generating Text from RDF Data"}, {"paperId": "fa025e5d117929361bcf798437957762eb5bb6d4", "title": "Zero-Shot Relation Extraction via Reading Comprehension"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "c269858a7bb34e8350f2442ccf37797856ae9bca", "title": "Prototypical Networks for Few-shot Learning"}, {"paperId": "c889d6f98e6d79b89c3a6adf8a921f88fa6ba518", "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"}, {"paperId": "0f36511d47596b91b8d3db265e4ca7bafc0b15a4", "title": "Relation Classification via Recurrent Neural Network"}, {"paperId": "14347af6ab135fae319dcbff9fe573fbe757d99f", "title": "Development of a benchmark corpus to support the automatic extraction of drug-related adverse effects from medical case reports"}, {"paperId": "e7e7b9a731678bf0494fe29cbebb42a822224cc6", "title": "Modeling Relations and Their Mentions without Labeled Text"}, {"paperId": "8ea8da551ef6b1c909ca5b37ba94be4cae02e9ac", "title": "SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations Between Pairs of Nominals"}, {"paperId": "5aa70188f70d349580aed96c10a68f57dace2d33", "title": "A Linear Programming Formulation for Global Inference in Natural Language Tasks"}, {"paperId": "fd4134b2fbb169d147ede8d32a40d911742e1495", "title": "HyperNetwork-based Decoupling to Improve Model Generalization for Few-Shot Relation Extraction"}, {"paperId": null, "title": "Simple and effective few-shot named entity recognition with structured nearest neighbor learning"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Ace 2005 multilingual training corpus-linguistic data consortium"}, {"paperId": "0617dd6924df7a3491c299772b70e90507b195dc", "title": "The Automatic Content Extraction (ACE) Program \u2013 Tasks, Data, and Evaluation"}]}