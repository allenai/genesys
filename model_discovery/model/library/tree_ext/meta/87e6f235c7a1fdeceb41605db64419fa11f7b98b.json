{"paperId": "87e6f235c7a1fdeceb41605db64419fa11f7b98b", "title": "Couplformer: Rethinking Vision Transformer with Coupling Attention Map", "abstract": "With the development of the self-attention mechanism, the Transformer model has demonstrated its outstanding performance in the computer vision domain. However, the massive computation brought from the full attention mechanism became a heavy burden for memory consumption. Sequentially, the limitation of memory reduces the possibility of improving the Transformer model. To remedy this problem, we propose a novel memory economy attention mechanism named Couplformer, which decouples the attention map into two sub-matrices and generates the alignment scores from spatial information. A series of different scale image classification tasks are applied to evaluate the effectiveness of our model. The result of experiments shows that on the ImageNet-1k classification task, the Couplformer can significantly decrease 28% memory consumption compared with regular Transformer while accessing sufficient accuracy requirements and outperforming 0.92% on Top-1 accuracy while occupying the same memory footprint. As a result, the Couplformer can serve as an efficient backbone in visual tasks, and provide a novel perspective on the attention mechanism for researchers.", "venue": "arXiv.org", "year": 2021, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A novel memory economy attention mechanism named Couplformer is proposed, which decouples the attention map into two sub-matrices and generates the alignment scores from spatial information and can serve as an efficient backbone in visual tasks, and provide a novel perspective on the attention mechanism for researchers."}, "embedding": {"model": "specter_v2", "vector": [0.337513267993927, 0.519363522529602, 0.037280142307281494, 0.2567810118198395, 0.09249456971883774, 0.5067072510719299, 0.5584058165550232, -0.25647860765457153, -0.48517388105392456, -0.4367468059062958, 0.4400137662887573, 0.5814420580863953, 0.539775013923645, -0.26507726311683655, -0.24554111063480377, -0.16279776394367218, -0.388751745223999, 0.14143551886081696, 0.5555126667022705, -0.4162050187587738, 0.3704606890678406, -0.5784907937049866, -1.4731755256652832, 0.1993218958377838, 0.3396752178668976, 1.1036739349365234, 0.8684111833572388, 0.8208654522895813, -0.19077162444591522, 0.4691280126571655, 0.5554349422454834, -0.4267062842845917, 0.46913495659828186, 0.28500112891197205, -0.41543909907341003, 0.040992096066474915, 1.1354418992996216, -0.12414898723363876, -0.42621561884880066, 1.2126330137252808, -0.1921825110912323, 0.13984082639217377, 0.3282224237918854, -0.8059952855110168, -0.3936702609062195, -0.0299138892441988, 0.24229368567466736, 1.0714832544326782, -0.7068332433700562, -0.40193095803260803, 1.1019538640975952, -1.4120097160339355, -0.18282228708267212, 1.434831976890564, 0.2458622306585312, 0.010391885414719582, 0.06266996264457703, -0.6485620141029358, 0.7158718109130859, 0.361610472202301, -0.6554996371269226, -0.18503034114837646, 0.2500639855861664, -0.12711262702941895, 1.945350170135498, -0.5200021266937256, 0.1421913355588913, 0.3237325847148895, 0.615772545337677, 1.051870584487915, 0.16343683004379272, -0.8440794348716736, -0.2842676043510437, -0.15599218010902405, 0.515998125076294, 1.0724914073944092, -0.2132992148399353, 0.09095063805580139, -1.2226248979568481, -0.0326172299683094, 1.0468542575836182, -0.10333752632141113, 0.49982279539108276, -0.2267732173204422, -0.5251477360725403, 0.5634157657623291, 0.8581355214118958, 0.42827108502388, -0.5252047777175903, 0.8643362522125244, 0.332926481962204, 0.13135892152786255, -0.039595335721969604, 0.25686517357826233, 0.567531943321228, 1.0392348766326904, -0.34140512347221375, 0.0712536945939064, -0.5060232877731323, 1.1752930879592896, 0.1923411339521408, 0.06512172520160675, -0.6284932494163513, 0.16365493834018707, 1.191475749015808, 0.23061193525791168, 0.37545308470726013, -0.6212985515594482, 0.27210214734077454, -0.4856126308441162, -0.174673393368721, -1.2354226112365723, 0.175148144364357, -0.3918357789516449, -1.070553183555603, -0.5677854418754578, -0.3933664560317993, 0.6395538449287415, -0.6751806139945984, 0.4387916326522827, -0.376151442527771, -0.01883254572749138, -0.28307148814201355, 0.5576488375663757, 0.4064265489578247, 0.3324103355407715, 0.4937352240085602, 0.5910906195640564, 1.5467276573181152, -1.4138803482055664, -0.44943320751190186, -1.2425365447998047, -0.2319958359003067, -0.4939177334308624, 0.2656720280647278, -0.301510214805603, -1.2330939769744873, -1.4171364307403564, -0.9031804800033569, -0.10910097509622574, -0.697285532951355, 0.23443499207496643, 1.2278766632080078, -0.2778053283691406, -1.3497916460037231, 0.5598724484443665, -0.05944972485303879, -0.6330221891403198, 0.5042786002159119, 0.2586488723754883, 0.20973390340805054, 0.02980821207165718, -1.076340675354004, 0.5527753829956055, 0.08353729546070099, -0.44199317693710327, -0.16439001262187958, -0.3095783591270447, -0.8499024510383606, 0.07937834411859512, 0.09162772446870804, -1.1621208190917969, 0.8161910176277161, -0.5065839886665344, -0.6990605592727661, 0.653385579586029, -0.29619428515434265, 0.12378742545843124, -0.2637508809566498, -0.12969793379306793, -0.11352171748876572, -0.49765968322753906, -0.01740412414073944, 0.9367656707763672, 0.5747343301773071, 0.010847356170415878, -0.6636677384376526, -0.1476929634809494, -0.21552839875221252, 0.2652468681335449, -0.523647129535675, 1.0041004419326782, -0.7239193320274353, -0.5166430473327637, 0.5014138221740723, 0.49018654227256775, 0.0900697410106659, 0.0392451137304306, 0.045125871896743774, -0.9928985238075256, 0.6199248433113098, 0.3750622570514679, 0.5188952088356018, -0.7276748418807983, -0.5118902325630188, -0.4359683394432068, 0.194219172000885, -0.28890618681907654, -0.9749008417129517, 0.30337977409362793, -0.5078000426292419, -0.13428790867328644, 0.08856157958507538, -0.7178031206130981, -0.27351808547973633, -0.4188370704650879, -0.643490731716156, -0.17411693930625916, 0.40125295519828796, 1.0804108381271362, -0.8599992394447327, -0.16280893981456757, -0.1910688579082489, 0.10425610095262527, -0.7272447347640991, 1.1197316646575928, -0.10851278156042099, -0.2792424261569977, -0.0266597680747509, 0.09690916538238525, 0.21826407313346863, -0.4607822895050049, 0.07455606013536453, -1.044761300086975, -0.07523787021636963, 0.22974462807178497, -0.06480953097343445, 1.5505231618881226, -0.2451462596654892, 0.7900975346565247, -0.20867584645748138, -0.562671422958374, 0.33381423354148865, 0.18607090413570404, -0.3489643931388855, -0.8724433779716492, 0.26922187209129333, -0.1656475067138672, -0.5025255680084229, 0.24747183918952942, 0.6057187914848328, 1.4171968698501587, -0.22971606254577637, 0.07873315364122391, 0.6914829015731812, -0.12809577584266663, -0.04675564169883728, 0.18285855650901794, 0.6331198215484619, 0.16670913994312286, 0.6168969869613647, -0.6718260645866394, 0.3368651270866394, -0.8285883069038391, -0.2494945079088211, 0.5582501292228699, 0.29270726442337036, 0.8614040613174438, 0.11544065922498703, -1.2350705862045288, -0.4987814128398895, 0.014930705539882183, 0.7057876586914062, 1.5880143642425537, 0.18611013889312744, 0.17631332576274872, -0.7445911169052124, -0.2365535944700241, -0.47081872820854187, -0.678435206413269, -0.646452784538269, -0.44547170400619507, -0.24772828817367554, -1.2417149543762207, 0.49177443981170654, 0.4707985520362854, 1.6314244270324707, -0.6913014650344849, -0.7325374484062195, -0.30416062474250793, 0.16407446563243866, -0.7244986891746521, -0.8586533069610596, 0.2586510181427002, -0.3425428569316864, -0.1434648036956787, 0.08004423975944519, -0.4698656499385834, 0.4281429946422577, 0.03501328080892563, 0.9807814359664917, -0.6296020746231079, -0.4872521758079529, 0.16881847381591797, 0.7853018641471863, -0.923470139503479, 0.1266549974679947, 0.2359146624803543, -0.014691438525915146, 0.13348454236984253, 0.6290600895881653, 0.13389530777931213, -0.38479888439178467, 0.31707045435905457, -0.3450939655303955, 0.1758049726486206, 0.48542317748069763, -0.008247053250670433, 0.8180615305900574, -0.4212542772293091, 0.052816249430179596, -0.6727290749549866, 0.9922941327095032, 0.4380180835723877, -0.5015153884887695, 0.21708443760871887, -0.5569865107536316, -0.3598118722438812, -0.013657149858772755, -0.7306579351425171, -0.06492393463850021, -0.3939173221588135, 0.7492424845695496, -0.3916597366333008, -0.016715651378035545, -0.26408621668815613, 0.21351978182792664, -0.6755366921424866, 0.5221036076545715, 0.40194904804229736, 0.35691678524017334, 0.4090973138809204, 0.24169369041919708, -1.0343838930130005, 0.8717856407165527, 0.22581815719604492, -0.12792038917541504, 0.13321688771247864, 0.011233055032789707, -0.6236857771873474, -0.782983660697937, -0.329904705286026, -0.4039801359176636, -0.5629996061325073, 0.6175947189331055, -0.7098298668861389, -0.964606523513794, 0.230826273560524, -1.259788155555725, 0.2032756209373474, 0.11528651416301727, -0.18357320129871368, -0.43633776903152466, -1.2141591310501099, -0.656880259513855, -0.29398584365844727, -0.7776910066604614, -1.1376572847366333, 0.265483021736145, 0.389443039894104, -0.1973240226507187, -0.24268390238285065, -0.1447933316230774, -0.3040437400341034, 1.417235016822815, -0.48805591464042664, 0.48952123522758484, 0.11964160203933716, -0.69007408618927, -0.16655568778514862, -0.40078967809677124, 0.23796609044075012, -0.016937483102083206, -0.15708006918430328, -0.9751437306404114, 0.4676547944545746, 0.024102892726659775, -0.299911767244339, 0.6819837689399719, 0.31326931715011597, 0.8517650365829468, 0.22289781272411346, -0.4600267708301544, 0.3000253736972809, 1.3896770477294922, -0.6966440677642822, 0.29595476388931274, 0.5099396109580994, 1.033004641532898, 0.2763163447380066, -0.12959574162960052, 0.2740890383720398, 0.8281958103179932, 0.47112414240837097, 0.8380258083343506, -0.6176697611808777, -0.6687486171722412, -0.19266772270202637, -0.16961243748664856, 1.2613201141357422, -0.14708960056304932, 0.1280534416437149, -1.0679038763046265, 0.6348233222961426, -1.522592544555664, -0.9709339141845703, 0.8397961258888245, 0.7814227342605591, 0.2285434454679489, -0.3585854470729828, -0.36844462156295776, -0.6100125312805176, 0.8009270429611206, 0.38850462436676025, -0.31403639912605286, -0.39838066697120667, -0.24204248189926147, 0.21677884459495544, 0.46632352471351624, 0.793479859828949, -0.6056418418884277, 0.8236606121063232, 14.716174125671387, 0.46956583857536316, -0.15776796638965607, 0.6399765014648438, 0.8702512979507446, 0.48076197504997253, 0.13027498126029968, 0.06066964566707611, -1.1318738460540771, -0.08683770895004272, 0.4892403483390808, 0.2268942892551422, 0.44627341628074646, 0.2699818015098572, -0.44944703578948975, -0.11526267975568771, -0.4315709173679352, 1.1250852346420288, 0.972323477268219, -1.131834864616394, 0.6128633618354797, 0.2726708948612213, 0.2355533093214035, 0.4383045732975006, 0.7908642292022705, 0.2227054387331009, 0.2437737137079239, -0.3332933783531189, 0.29561394453048706, 0.7151967287063599, 0.6202182769775391, 0.03320574015378952, 0.26244494318962097, 0.1317909061908722, -1.1881457567214966, -0.07980074733495712, -1.129933476448059, -1.2127963304519653, -0.14068269729614258, 0.0457439161837101, -0.041985660791397095, -0.6552343368530273, 0.07459880411624908, 0.600260853767395, -0.31777000427246094, 0.5267786383628845, 0.12853677570819855, -0.11879652738571167, 0.2546539306640625, -0.1516364961862564, 0.14063747227191925, 0.42625170946121216, 0.1972704380750656, -0.009345085360109806, 0.001614296343177557, 0.2438545972108841, 0.10070747137069702, 0.3847754895687103, -0.33592861890792847, -0.35469749569892883, -0.17977815866470337, 0.2950291335582733, -0.09065213799476624, 1.1549590826034546, 0.387530118227005, 0.11933465301990509, -0.19773082435131073, 0.2520553469657898, 0.7671148777008057, 0.1066487580537796, -0.6822199821472168, -0.06975971907377243, 0.3054509460926056, -0.21626129746437073, -0.05958380177617073, 0.5524073243141174, -0.5945978760719299, -0.25678732991218567, -0.7686858177185059, -0.24540533125400543, 0.18977747857570648, -1.0896732807159424, -0.6992093920707703, 1.4765539169311523, -0.3073858916759491, -0.26184579730033875, 0.9706918001174927, -0.8641741275787354, -0.42523762583732605, 0.6450415849685669, -1.2960753440856934, -0.9494214653968811, -0.5280962586402893, -0.24489882588386536, -0.004122341983020306, -0.38755497336387634, 0.9100773334503174, 0.051920086145401, -0.1549060195684433, -0.021609505638480186, -0.9932869672775269, -0.38466641306877136, 0.20964039862155914, -0.5300605893135071, 0.785540759563446, 0.15057790279388428, -0.17249491810798645, 0.057611752301454544, -0.06179141253232956, 0.2523733377456665, -0.6750630140304565, -0.07146088033914566, 0.6133372783660889, -0.7192144393920898, -0.22391939163208008, -0.7093499898910522, -0.9020840525627136, -0.06880663335323334, 1.075591802597046, 0.03660254180431366, -0.04826614260673523, -0.05427337437868118, -0.5820493102073669, -0.4963438808917999, -0.4144946336746216, 0.17269033193588257, 0.5888444185256958, -0.7901194095611572, -0.44338491559028625, 0.11128398776054382, 0.1725669801235199, -0.7889793515205383, -0.3284164071083069, -0.10832074284553528, 0.2910212576389313, -0.45343780517578125, 1.3664275407791138, -0.2889213562011719, 0.6515955924987793, 0.5685117244720459, -0.2619960308074951, -0.6320180296897888, -0.7997555136680603, -0.4658525884151459, 0.34908488392829895, 0.06420765072107315, 0.429969847202301, -0.6542905569076538, 0.06622479856014252, 0.715627133846283, 0.25496572256088257, -0.5364028215408325, -0.5124157071113586, 0.26707571744918823, -0.40997448563575745, -0.07163695245981216, 0.29601097106933594, -0.2314247041940689, -0.016790974885225296, 0.361928254365921, 0.5327463746070862, 0.41378623247146606, 0.23646298050880432, -0.48323333263397217, 0.27065691351890564, -0.37199336290359497, 0.11692541837692261, -0.7936455607414246, -0.7904635071754456, -1.4057680368423462, -0.2214145064353943, -0.8775819540023804, -0.13271887600421906, -0.9973171949386597, 0.021447481587529182, 0.2779444754123688, -0.5188490152359009, 0.18917371332645416, 0.1545339971780777, 0.05873003602027893, -0.3152523934841156, -0.20611409842967987, -0.5827372670173645, 0.6744645833969116, 1.2405234575271606, -0.8333361148834229, 0.40699443221092224, -0.2360256165266037, -0.38844606280326843, 0.5306975245475769, 0.3845144212245941, -0.3285858631134033, -0.740330696105957, -1.358077049255371, 0.3622080683708191, -0.3496609330177307, 0.18371640145778656, -1.286662220954895, 1.6075153350830078, 0.3883293569087982, 0.16271182894706726, -0.22606337070465088, 0.46592530608177185, -1.0582014322280884, -0.6111240983009338, 0.32628822326660156, -0.6281615495681763, 0.7378683090209961, 0.4090440571308136, -0.3590477705001831, -0.4772113561630249, 1.0860074758529663, 0.11249368637800217, -1.2036668062210083, -1.014950156211853, 0.5271757245063782, -0.4387754201889038, -0.04045722633600235, 0.056129518896341324, -0.2093830406665802, -1.5271356105804443, -0.14760546386241913, 0.0033255000598728657, 0.24958515167236328, -0.5687729716300964, 0.9263278245925903, 0.6587137579917908, -1.4585057497024536, 0.2194058746099472, 0.6397876143455505, -0.06570368260145187, -0.08533204346895218, 0.41690561175346375, 0.49687081575393677, -0.08704330772161484, 0.5501688122749329, -0.5150224566459656, 0.2255803793668747, -0.6340864896774292, 0.304544061422348, 0.8427966237068176, -0.15314975380897522, 0.0017097610980272293, 1.111063003540039, 0.34497734904289246, -0.5690298676490784, 0.21340960264205933, -0.7189998626708984, -0.5667902231216431, -0.205267533659935, 0.7280616760253906, 0.18663102388381958, 0.0399472750723362, -0.1640452891588211, -0.5785230994224548, 0.5843501091003418, -0.29994821548461914, -0.4279971420764923, 0.10121225565671921, -0.022850187495350838, -0.5177295804023743, 0.2838686406612396, 0.38518601655960083, -0.9901829361915588, -1.1615420579910278, -0.8754011988639832, -0.5353624224662781, -0.2734907269477844, 0.4090799391269684, -0.115810826420784, -0.9476832747459412, 0.6903047561645508, 0.84694504737854, 0.2837103605270386, 0.45594146847724915, -0.2142091542482376, -0.10068175196647644, 0.5878318548202515, -0.07371643930673599, -0.6394532322883606, -0.1552303433418274, 1.268000841140747, 1.6284304857254028, -0.8653430938720703, 0.11467501521110535, -0.49768534302711487, -0.787153422832489, 0.7103638052940369, 0.8853506445884705, -0.7471380829811096, 0.8919692635536194, -0.02924090065062046, -0.010902952402830124, -0.04737670719623566, -1.1939685344696045, -0.4938821792602539, 1.1186259984970093, 1.2232892513275146, 0.5939514636993408, -0.2609161138534546, 0.240522101521492, 0.36098769307136536, 0.14792200922966003, -0.20656979084014893, 0.1841646432876587, 0.06566695123910904, -0.38500070571899414, 0.4257567226886749, -0.22452987730503082, 0.37095770239830017, -0.03606681525707245, -0.6140934824943542, 0.039047788828611374, 0.5162320733070374, 0.09391380101442337, 0.2616925835609436, 1.2537422180175781, -0.05623438581824303, 0.7862852811813354, -0.09194857627153397, 0.6167406439781189, -0.2551751732826233, -0.12124030292034149, -0.10236956179141998, -1.0338913202285767, -0.1674957275390625, -0.6184801459312439, -0.5052396655082703, 0.1167716309428215, 0.02162105403840542, 0.19033750891685486, -0.3744775056838989, 0.3930547833442688, 0.6123093366622925, 0.779568612575531, 0.9963043928146362, -0.4084373414516449, -0.5798460841178894, -0.05530831962823868, -1.125376582145691, 0.472659707069397, -0.7589863538742065, -0.41830164194107056, -0.544735848903656, 0.046254534274339676, -0.15882277488708496]}, "authors": [{"authorId": "2057697721", "name": "Hai Lan"}, {"authorId": "2108030458", "name": "Xihao Wang"}, {"authorId": "30013158", "name": "Xian Wei"}], "references": [{"paperId": "7b664a306b7d2f68dd816ea1d6586cf3472d75c1", "title": "Early Convolutions Help Transformers See Better"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "4b06c7e29280b1c6bc05c9df39023b48fef02c93", "title": "Escaping the Big Data Paradigm with Compact Transformers"}, {"paperId": "003326a15fc4a8833785a47a741d7712474fa256", "title": "LeViT: a Vision Transformer in ConvNet\u2019s Clothing for Faster Inference"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "2984ab83ade26639c3a82d29628d0d9e4abbebb0", "title": "Incorporating Convolution Designs into Visual Transformers"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "3a906b77fa218adc171fecb28bb81c24c14dcc7b", "title": "Transformers in Vision: A Survey"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "849b88ddc8f8cabc6d4246479b275a1ee65d0647", "title": "A Generalization of Transformer Networks to Graphs"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "d387600e5150b381a306221a5bc9bd92aa99157b", "title": "Memformer: The Memory-Augmented Transformer"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "7f5af01213eb70ccbb787d76a4869e8cd42c1e5d", "title": "Self attention convolutional neural network with time series imaging based feature extraction for transmission line fault detection and classification"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8", "title": "Generative Pretraining From Pixels"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "54c7445f319823c7dcc948c830e75e2fa7460b33", "title": "Exploring Self-Attention for Image Recognition"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "8eba733040b016e9c7ec5c3dc87cc1b28a5c2000", "title": "Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation"}, {"paperId": "b1c39d042fdf8f00a407b0df734764beb6c3b062", "title": "Low-Rank Bottleneck in Multi-head Attention Models"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "bb713d56a39a040b35e4f9e036fb4422f543e614", "title": "On the Relationship between Self-Attention and Convolutional Layers"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "4c163d4942117179d3e97182e1b280027d7d60a9", "title": "Attention on Attention for Image Captioning"}, {"paperId": "d6dccb5d71fbb6f5765f89633ba3a8e6809a720d", "title": "Stand-Alone Self-Attention in Vision Models"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "27ac832ee83d8b5386917998a171a0257e2151e2", "title": "Attention Augmented Convolutional Networks"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "cd8ddaaf56e38dddafdeac3f9643b9b5e9d35d54", "title": "Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks"}, {"paperId": "ad655c25e052fa4eeed53421344aca6f239c4c9d", "title": "Dual Attention Network for Scene Segmentation"}, {"paperId": "de95601d9e3b20ec51aa33e1f27b1880d2c44ef2", "title": "CBAM: Convolutional Block Attention Module"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4", "title": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"}, {"paperId": "6a0aaefce8a27a8727d896fa444ba27558b2d381", "title": "Relation Networks for Object Detection"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "77d30cf9a34fb6b50979c6a68863099da9a060ad", "title": "Residual Attention Network for Image Classification"}, {"paperId": "88513e738a95840de05a62f0e43d30a67b3c542e", "title": "SCA-CNN: Spatial and Channel-Wise Attention in Convolutional Networks for Image Captioning"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "654247d5b184495fca18c6aa7e840e4f4559fef0", "title": "Do We Really Need Explicit Position Encodings for Vision Transformers?"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82", "title": "Deep Learning"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}, {"paperId": "3b5b72dc39b7365357cc25597fcaeea9a692d5c6", "title": "Floating Point Operations in Matrix-Vector Calculus"}]}