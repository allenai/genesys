{"paperId": "d4793bcb3fd92b9da9a62b15e0dc93f64e452578", "title": "Decoder-Only or Encoder-Decoder? Interpreting Language Model as a Regularized Encoder-Decoder", "abstract": "The sequence-to-sequence (seq2seq) task aims at generating the target sequence based on the given input source sequence. Traditionally, most of the seq2seq task is resolved by the Encoder-Decoder framework which requires an encoder to encode the source sequence and a decoder to generate the target text. Recently, a bunch of new approaches have emerged that apply decoder-only language models directly to the seq2seq task. Despite the significant advancements in applying language models to the seq2seq task, there is still a lack of thorough analysis on the effectiveness of the decoder-only language model architecture. This paper aims to address this gap by conducting a detailed comparison between the encoder-decoder architecture and the decoder-only language model framework through the analysis of a regularized encoder-decoder structure. This structure is designed to replicate all behaviors in the classical decoder-only language model but has an encoder and a decoder making it easier to be compared with the classical encoder-decoder structure. Based on the analysis, we unveil the attention degeneration problem in the language model, namely, as the generation step number grows, less and less attention is focused on the source sequence. To give a quantitative understanding of this problem, we conduct a theoretical sensitivity analysis of the attention output with respect to the source input. Grounded on our analysis, we propose a novel partial attention language model to solve the attention degeneration problem. Experimental results on machine translation, summarization, and data-to-text generation tasks support our analysis and demonstrate the effectiveness of our proposed model.", "venue": "arXiv.org", "year": 2023, "citationCount": 22, "influentialCitationCount": 1, "openAccessPdf": {"url": "http://arxiv.org/pdf/2304.04052", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes a novel partial attention language model to solve the attention degeneration problem in the decoder-only language model framework through the analysis of a regularized encoder-decoder structure that has an encoder and a decoder making it easier to be compared with the classical Encoder-Decoder structure."}, "embedding": {"model": "specter_v2", "vector": [0.6840853691101074, 0.9015396237373352, -0.11123932152986526, -0.06623776257038116, -0.6608501076698303, -0.2521524727344513, 0.44432884454727173, -0.06398162245750427, -0.22132472693920135, 0.32725027203559875, 0.8472133874893188, 0.26355689764022827, 0.47870248556137085, 0.13818573951721191, -0.4462932050228119, -0.028998002409934998, -0.7009297609329224, -0.01742723397910595, -0.16487565636634827, -0.35248294472694397, 0.14208553731441498, -1.0181562900543213, -0.6586004495620728, 0.29925957322120667, 0.6677687764167786, 0.008722353726625443, 0.5988969206809998, 1.201850414276123, -0.2645407021045685, 0.5605276823043823, 0.12977026402950287, -0.6895236372947693, 0.18425516784191132, -0.7726979851722717, -0.4559473693370819, -0.06262078881263733, 0.14347423613071442, -0.4019964337348938, -0.2519361674785614, 1.1426364183425903, -0.2049211859703064, 0.034566860646009445, 0.4775989353656769, -0.2117234170436859, -0.3656749129295349, 1.2799932956695557, 0.32600778341293335, 0.8308719396591187, 0.0881296843290329, -0.4899417757987976, 1.1262050867080688, -0.933329701423645, 0.3069022297859192, 1.5164718627929688, 0.11268971115350723, 0.823012113571167, -0.05892115458846092, -0.18353593349456787, 0.49345290660858154, -0.3397411108016968, -0.9785987138748169, -0.4271320402622223, -0.33186739683151245, -0.16562362015247345, 1.636244535446167, -0.30195245146751404, -0.5412846803665161, 0.31579744815826416, 0.11933104693889618, 1.1328452825546265, -0.5008535385131836, -0.5035530924797058, -0.3551388382911682, -0.08855994045734406, 0.48592475056648254, 0.8245664238929749, -0.056299857795238495, 0.03465965762734413, -0.9038225412368774, 0.19749483466148376, 0.30599597096443176, -0.603795051574707, -0.4057995080947876, 0.1764257699251175, -0.39102110266685486, 0.5287137031555176, 0.14010800421237946, 0.6966961622238159, -0.22123178839683533, 0.8231518864631653, 0.6878973841667175, 0.41902369260787964, 0.19641390442848206, 0.5433884859085083, 0.04001328721642494, 0.24373984336853027, -0.55988609790802, 0.1413172334432602, -0.29347124695777893, 1.0687532424926758, -0.2006036788225174, 0.44273337721824646, -0.7953315377235413, 0.2731563448905945, 0.9385555982589722, -0.15549205243587494, 0.4746658205986023, -0.6724585890769958, 0.7079711556434631, -0.7390337586402893, 0.10178036242723465, -0.47190940380096436, -0.041894275695085526, 0.04958869516849518, -0.9696075916290283, -1.4221477508544922, -0.3296913504600525, -0.4009452760219574, -0.48287513852119446, 1.0320268869400024, -0.44740715622901917, -0.4213915467262268, 0.41560453176498413, 0.5883269906044006, 0.5228400230407715, 0.8880046606063843, -0.05781523138284683, -0.5669823288917542, 0.8641262054443359, -0.4506818950176239, -1.1474061012268066, -0.7685599327087402, 0.8661549091339111, -0.2260735034942627, 0.15224504470825195, -0.37953633069992065, -1.447635293006897, -1.0557470321655273, -1.0326862335205078, 0.06720182299613953, 0.1593097448348999, 0.30365148186683655, 0.42245861887931824, 0.2574223279953003, -1.3473312854766846, 0.9401953816413879, -0.07836755365133286, -0.4713349938392639, 0.15596798062324524, 0.13291960954666138, 0.2282317876815796, -0.17473794519901276, -1.0317975282669067, 0.30322182178497314, 0.2994072139263153, -0.7213454246520996, -0.008659405633807182, -0.6297568082809448, -1.2441569566726685, -0.14191961288452148, 0.361505389213562, -0.9585514068603516, 1.4911912679672241, -0.18938174843788147, -1.6942086219787598, 0.19307388365268707, -0.520002007484436, 0.034289855509996414, 0.11320120096206665, -0.47533488273620605, -0.23758475482463837, -0.2638882100582123, -0.04870813712477684, 0.027741266414523125, 0.06029206141829491, -0.12206561863422394, -0.1251422017812729, 0.12564285099506378, -0.7023436427116394, -0.08953177183866501, 0.006504898425191641, 0.9920468926429749, -0.5125126242637634, -0.6114308834075928, 0.153590589761734, 0.7943813800811768, -0.09186375141143799, -0.6315178871154785, -0.873479425907135, -0.8591575622558594, 0.4574064016342163, -0.11718389391899109, 1.2955466508865356, -0.6621770858764648, -0.4149337708950043, -0.6109539270401001, -0.5615546703338623, 0.09401499480009079, -0.8565316796302795, 0.7107598185539246, -0.45201602578163147, 0.8327112793922424, -0.44913867115974426, -0.8473358750343323, -0.43900609016418457, -0.6734596490859985, -0.6724058389663696, -0.04910151660442352, 0.3732956647872925, 0.9349269270896912, -0.9830535054206848, 0.2608713209629059, -0.41180211305618286, -0.19976361095905304, -0.7932810187339783, 1.3693076372146606, -0.35229843854904175, 0.4280957877635956, -0.599624514579773, -0.500247061252594, 0.2763245403766632, -0.18457962572574615, 0.19496244192123413, -0.25024643540382385, -0.2384336143732071, 0.3708169460296631, -0.0731276348233223, 1.6287161111831665, 0.12126922607421875, 0.4619795083999634, -0.030238421633839607, -0.8015454411506653, 0.5079039931297302, 0.4035061001777649, -0.2730678915977478, -0.44759514927864075, 0.3179844915866852, 0.16591933369636536, -0.47562283277511597, -0.12932004034519196, 0.9972517490386963, 0.8306063413619995, -0.5654088854789734, 0.42062807083129883, 0.5095902681350708, -0.2516089081764221, 0.8481643199920654, 0.6563225984573364, 0.8616899847984314, 0.3933209180831909, 0.5452856421470642, -0.09696763753890991, 0.5593596696853638, -0.6349665522575378, 0.052006796002388, 0.519851565361023, 0.998024582862854, 1.4643086194992065, 0.4782905578613281, -0.5290391445159912, -0.27229467034339905, 0.06317967921495438, 0.9842567443847656, 1.1058385372161865, 0.13564521074295044, -0.32995423674583435, -1.2020763158798218, -0.4821910560131073, -0.5334392189979553, 0.42603299021720886, -0.4019499719142914, -0.44537216424942017, -0.719552218914032, -1.263327717781067, 0.9847476482391357, -0.09512003511190414, 0.9214996099472046, -0.39763927459716797, -0.18473100662231445, -0.1324649155139923, -0.04032247141003609, -0.8698456287384033, -1.2451739311218262, -0.052530452609062195, -0.643940806388855, -0.332617849111557, -0.2514254152774811, -0.07203402370214462, 0.3129972517490387, -0.6072297692298889, 0.6999269127845764, -0.3751033544540405, -0.22258342802524567, 0.11727113276720047, 0.15630650520324707, -0.5701186656951904, -1.1464375257492065, 0.09196069836616516, 0.19975225627422333, 0.020341435447335243, -0.10658915340900421, 0.798583447933197, 0.23863160610198975, -0.12850326299667358, -0.4310195744037628, 0.18230566382408142, 0.032046958804130554, -0.054151974618434906, 0.23892730474472046, -0.41275596618652344, 0.1782105565071106, -1.0333917140960693, 1.2542129755020142, 0.1737622767686844, -0.28600823879241943, 0.3584316670894623, -0.14793604612350464, 0.11287128925323486, 0.5750999450683594, -0.3255884647369385, -0.634219765663147, -1.0523428916931152, 0.32576459646224976, 0.19011139869689941, 0.0166011992841959, 0.5234287977218628, 0.15978793799877167, 0.5562014579772949, 0.047401878982782364, 0.6431126594543457, 0.8037087917327881, -0.5070361495018005, 0.3295770585536957, -0.5267069339752197, 0.5186906456947327, 0.603986382484436, 0.028542716056108475, -0.5030583143234253, -0.273394376039505, -0.8082846403121948, -0.15096883475780487, 0.13879451155662537, 0.010844754055142403, -0.11666253209114075, 0.38746753334999084, -0.5409455895423889, -0.6021037101745605, -0.1315290778875351, -1.5507885217666626, -0.09788361936807632, 0.02069811150431633, -0.01155874878168106, -0.42181944847106934, -0.6374051570892334, -0.9368126392364502, -0.558972954750061, -0.6825702786445618, -1.10616934299469, 0.3092002868652344, 0.06646113097667694, -0.6834771633148193, -0.09006315469741821, 0.37511560320854187, -0.49057671427726746, 0.47257426381111145, -0.5048819780349731, 1.0246310234069824, -0.2081064134836197, -0.07450339943170547, 0.028584277257323265, 0.39775073528289795, 0.5144781470298767, 0.2617175281047821, 0.12479718774557114, -0.3601248860359192, 0.12291701883077621, -0.11395779252052307, -0.16793890297412872, 0.21977142989635468, 0.5319191217422485, 0.5106928944587708, -0.12858375906944275, -0.43379345536231995, 0.21131055057048798, 1.3590470552444458, -0.3808003067970276, 0.04644257202744484, -0.2640392482280731, 0.9889079332351685, 0.6519376635551453, 0.02083061821758747, 0.5190796852111816, 0.22861693799495697, 0.6678003668785095, 0.055411212146282196, -0.143302321434021, -0.43080800771713257, -0.4711027443408966, 0.8545664548873901, 1.7093260288238525, 0.11613000184297562, -0.565027117729187, -0.7180672287940979, 0.6543647646903992, -1.4513925313949585, -0.8057317137718201, 0.12530401349067688, 0.8242975473403931, 0.4884274899959564, -0.7021616697311401, -0.2220977246761322, -0.3886934518814087, 1.0651012659072876, 0.11956667900085449, 0.04372386634349823, -0.9286409020423889, 0.11646951735019684, -0.22779211401939392, -0.060671616345644, 0.8398094177246094, -0.05290661379694939, 0.6155790090560913, 14.96462631225586, 0.5492948889732361, 0.08621693402528763, 0.2891632616519928, 0.4000357389450073, -0.056711096316576004, 0.07053713500499725, -0.40834876894950867, -0.9920128583908081, 0.23793192207813263, 1.106920838356018, -0.5844091773033142, 0.44443264603614807, -0.14806367456912994, 0.44577646255493164, -0.04968180134892464, -0.6916703581809998, 0.6437705755233765, 0.5354181528091431, -1.2375627756118774, 1.0507596731185913, 0.4236662983894348, 0.18349243700504303, 0.31179186701774597, 0.45736733078956604, 0.4942589998245239, 0.28318262100219727, -0.28568804264068604, 0.43223607540130615, 0.3399602472782135, 0.782376229763031, -0.23389381170272827, 0.4340815544128418, 0.7213844060897827, -0.7361103296279907, -0.06164766103029251, -0.687569260597229, -1.069482684135437, 0.6750631928443909, 0.2252299189567566, -0.5232247710227966, 0.16310840845108032, -0.43828442692756653, 0.6437751054763794, 0.31038710474967957, 0.2614971995353699, -0.18885774910449982, 0.4881659746170044, 0.355378657579422, -0.280884325504303, -0.18248015642166138, 0.4707757532596588, 0.7906152606010437, 0.3394660949707031, 0.5221004486083984, 0.1636158674955368, -0.23335883021354675, 0.3371354639530182, -0.735571563243866, -0.19158703088760376, -0.7883793711662292, -0.2480507642030716, -0.06826971471309662, 0.213014617562294, 0.8059848546981812, 0.30007871985435486, -0.2981477677822113, 0.25016987323760986, 0.6174163818359375, 0.05619095638394356, 0.024854598566889763, -0.4737407863140106, 0.4517153203487396, -0.06818043440580368, 0.028121788054704666, 0.4657166004180908, -0.27554139494895935, -0.36167392134666443, -0.839124321937561, -0.4311443567276001, 0.22657179832458496, -0.6802269220352173, -0.5942002534866333, 0.980989933013916, -0.06796886771917343, -0.7337141036987305, -0.05297963321208954, -0.2856346070766449, -0.3136306405067444, 0.5978705286979675, -1.1749694347381592, -0.13516348600387573, 0.643778383731842, -0.3419651389122009, 0.018065594136714935, -0.24473662674427032, 0.8785058856010437, -0.3110095262527466, -0.6985487937927246, 0.04975223168730736, 0.04171856865286827, 0.07546492666006088, -0.2747819721698761, -0.6644906997680664, 0.8581850528717041, 0.6946989297866821, -0.541500985622406, 0.3067544400691986, 0.18008166551589966, -0.12796343863010406, -1.1674202680587769, -0.5910197496414185, 0.9549695253372192, -0.7629454135894775, -0.634506344795227, -0.6143407821655273, -1.0288926362991333, 0.052210330963134766, 0.8723348379135132, -0.6891518235206604, 0.23473568260669708, 0.010685866698622704, 0.07594563812017441, -0.2135995328426361, -0.7463901042938232, 0.1600872129201889, 0.558870792388916, -0.5500415563583374, -0.47260263562202454, -0.07581936568021774, 0.547256350517273, -0.8535056710243225, -0.11714626848697662, -0.1632804125547409, -0.38232868909835815, 0.19085241854190826, 0.4458377957344055, -0.3303055465221405, 0.9349793791770935, 0.46770116686820984, 0.14083632826805115, -0.9884902834892273, -0.44881391525268555, -1.3330600261688232, 0.3805025815963745, 0.5956325531005859, 0.5742449760437012, -0.16041842103004456, -0.13889434933662415, 0.6613172888755798, -0.15123918652534485, 0.15842220187187195, -0.7991347312927246, -0.37152257561683655, -0.07407031953334808, -0.11243899166584015, 0.340822696685791, -0.2844693660736084, 0.3836432993412018, 0.012749291025102139, 0.20062898099422455, 0.9049748182296753, -0.20632152259349823, -0.8840690851211548, 0.5471594929695129, 0.20981860160827637, 0.26429396867752075, -0.7658988833427429, -0.27658727765083313, -1.4569436311721802, -0.22829441726207733, -1.2456392049789429, 0.5924874544143677, -1.0727821588516235, -0.18479612469673157, 0.9719579815864563, 0.14042752981185913, -0.2582549452781677, 0.038029786199331284, -0.42925944924354553, -0.2563025653362274, -0.5925576090812683, -0.5546834468841553, 0.9011756777763367, 1.0258102416992188, -0.5788492560386658, -0.08705112338066101, -0.21530316770076752, -0.4644108712673187, 0.18281203508377075, 0.6219770908355713, -0.6600771546363831, -0.6790054440498352, -1.8091130256652832, 0.24628716707229614, 0.2641925811767578, -0.06176399439573288, -0.40435194969177246, 0.662431001663208, 0.6409623622894287, -0.5464982390403748, 0.032537057995796204, -0.20159496366977692, -0.2644352316856384, -0.5049572587013245, 0.3523043990135193, -1.0069888830184937, 0.35407888889312744, 0.17995314300060272, -0.4559840261936188, -0.5789771676063538, 0.499655157327652, -0.2411850541830063, -1.0482983589172363, -0.19673976302146912, 0.35977068543434143, -1.0734405517578125, 0.42923372983932495, 0.0034752055071294308, -0.14558710157871246, -0.9818740487098694, -0.30112603306770325, 0.23443293571472168, 0.20234109461307526, -0.454467236995697, 1.0852707624435425, 0.29315006732940674, -0.8525464534759521, -0.44864964485168457, 0.11765116453170776, -0.2593385875225067, -0.09539423137903214, 0.49359825253486633, 0.3430839776992798, -0.23436975479125977, 0.3640718460083008, 0.6289777755737305, 0.20803490281105042, -0.9687073826789856, 0.020990176126360893, 0.4641692042350769, -0.19031067192554474, -0.15020161867141724, 1.0580803155899048, -0.055733706802129745, -0.9161849021911621, -0.14899969100952148, -1.0327417850494385, -0.3876253664493561, -0.3177688717842102, 0.891922652721405, 0.510761559009552, -0.2222675085067749, -0.24964739382266998, -0.6044107675552368, 0.3683054447174072, -0.16864773631095886, -0.48201045393943787, 0.1946735829114914, -0.6627415418624878, -0.3336974084377289, 0.4842287302017212, 0.7952882647514343, -0.6294379830360413, -0.5144211053848267, -0.40099531412124634, -0.2191551923751831, 0.06610402464866638, 0.14272671937942505, -0.1178797259926796, -0.48265060782432556, 0.7866634130477905, -0.03336941823363304, 0.4867968261241913, 0.09279632568359375, -0.14903296530246735, -0.33492976427078247, 0.17318038642406464, -0.11307911574840546, -0.6747671961784363, -0.6242605447769165, 1.389509677886963, 1.886030673980713, -0.6082110404968262, 0.32888731360435486, -0.3062872886657715, -1.1996855735778809, 0.8673892021179199, 0.37124884128570557, 0.15265420079231262, 0.49916455149650574, -0.1614188402891159, 0.10916078835725784, 0.34531641006469727, -1.1724108457565308, -0.19206790626049042, 0.5168341398239136, 1.0964311361312866, 1.0927330255508423, -0.15103429555892944, -0.43111348152160645, 1.0214563608169556, 0.04518570378422737, 0.30142638087272644, 1.2307884693145752, 0.35762810707092285, -0.15845845639705658, -0.09048532694578171, 0.04816051945090294, 0.3683140277862549, -0.7416852116584778, -0.47745394706726074, -0.1256525069475174, 0.4661768674850464, -0.14213502407073975, 1.0300575494766235, 0.8079861998558044, -0.11344853043556213, 0.6022951006889343, 0.09663873165845871, 0.5002639293670654, -0.9140469431877136, -0.5465373992919922, -0.2683667242527008, -0.36639833450317383, -0.26530683040618896, -0.15749597549438477, -0.7332267165184021, -0.4235036075115204, 0.05769386887550354, 0.37280067801475525, 0.3146369457244873, 0.14377450942993164, 1.0049936771392822, 0.837236762046814, 0.5513493418693542, 0.1234116181731224, -0.49780282378196716, -0.38572928309440613, -1.1760729551315308, -0.09442616999149323, -0.5277522802352905, 0.2470569610595703, 0.4490258991718292, 0.07891339063644409, 0.1948993057012558]}, "authors": [{"authorId": "1646716323", "name": "Z. Fu"}, {"authorId": "1380007189", "name": "W. Lam"}, {"authorId": "144873019", "name": "Qian Yu"}, {"authorId": "1734000", "name": "A. M. So"}, {"authorId": "1576223501", "name": "Shengding Hu"}, {"authorId": null, "name": "Zhiyuan Liu"}, {"authorId": "50638196", "name": "Nigel Collier"}], "references": [{"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "7cfaec8004c6d9f4fb5cf10287d15513c35b0a63", "title": "Towards Safer Generative Language Models: A Survey on Safety Risks, Evaluations, and Improvements"}, {"paperId": "7d645a3fd276918374fd9483fd675c28e46506d1", "title": "Galactica: A Large Language Model for Science"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "c6bf48f25e0a65d64d658b47326de5922ea7dd44", "title": "A Token-level Reference-free Hallucination Detection Benchmark for Free-form Text Generation"}, {"paperId": "dfb37e6216e792bf6bd5a30c0fc7ad55df1cb71e", "title": "Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth"}, {"paperId": "0368a16887369a56d9abb41ae8d697d4691a2021", "title": "Controlling hallucinations at word level in data-to-text generation"}, {"paperId": "7ade458d52d2dfe997b8a617a6b524bda12a619d", "title": "A Theoretical Analysis of the Repetition Problem in Text Generation"}, {"paperId": "0fb276e89b8b39cd9ef0108e6d9624ffae81c17a", "title": "Partially-Aligned Data-to-Text Generation with Distant Supervision"}, {"paperId": "45988d39ab1b0e5199e1f0f31952760bc763e611", "title": "The Lipschitz Constant of Self-Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "dc373d5e108a90a70f55285a852a32706adbeb45", "title": "Incorporating BERT into Neural Machine Translation"}, {"paperId": "6fec3e579c7cd4f13bdabbee2b6ac2e8ff5941c6", "title": "Unsupervised Cross-lingual Representation Learning at Scale"}, {"paperId": "9e1241f017a627beca2542e378a88c642c32098b", "title": "Semantic Noise Matters for Neural Natural Language Generation"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "80c65cac35a43f7e88917cb6d517554c7b175259", "title": "Sticking to the Facts: Confident Decoding for Faithful Data-to-Text Generation"}, {"paperId": "84281e999465fad51945e0fa3b482418f6b70683", "title": "Creating a Corpus for Russian Data-to-Text Generation Using Neural Machine Translation and Post-Editing"}, {"paperId": "3e0b9b1e4d354bb7caef3fc90fa9828b483c6e81", "title": "Tied Transformers: Neural Machine Translation with Shared Encoder and Decoder"}, {"paperId": "8aa12409bc8ca1c18016c77d756ea2eae9ef9968", "title": "A Simple Recipe towards Reducing Hallucination in Neural Surface Realisation"}, {"paperId": "a039ea239e37f53a2cb60c68e0a1967994353166", "title": "Analyzing the Structure of Attention in a Transformer Language Model"}, {"paperId": "1c71771c701aadfd72c5866170a9f5d71464bb88", "title": "Unified Language Model Pre-training for Natural Language Understanding and Generation"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc", "title": "Cross-lingual Language Model Pretraining"}, {"paperId": "dec8fe49a9336149e1268a332ce4ab9ecea7841b", "title": "Enriching the WebNLG corpus"}, {"paperId": "305b2cf37e5dece81e95c92883d5a6e28ac93b22", "title": "Don\u2019t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "642c1b4a9da95ea4239708afc5929a5007a1870d", "title": "Tensor2Tensor for Neural Machine Translation"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "a4c40532e68728fbeab5d9415f6ad8e9530db360", "title": "The WebNLG Challenge: Generating Text from RDF Data"}, {"paperId": "19a632b17b2ee5f64df41bdd23755316a02fb939", "title": "Creating Training Corpora for NLG Micro-Planners"}, {"paperId": "531a7f2c659787165df4fd5b4580590b953448e4", "title": "The E2E Dataset: New Challenges For End-to-End Generation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "106d5e0cf44ea08500adc91c4d5bb3e6c8a4d627", "title": "Six Challenges for Neural Machine Translation"}, {"paperId": "032274e57f7d8b456bd255fe76b909b2c1d7458e", "title": "A Deep Reinforced Model for Abstractive Summarization"}, {"paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0", "title": "Convolutional Sequence to Sequence Learning"}, {"paperId": "6ae02cc5e82e0d50b577717b402607e3aa69a547", "title": "Affect-LM: A Neural Language Model for Customizable Affective Text Generation"}, {"paperId": "263210f256603e3b62476ffb5b9bbbbc6403b646", "title": "What do Neural Machine Translation Models Learn about Morphology?"}, {"paperId": "668db48c6a79826456341680ee1175dfc4cced71", "title": "Get To The Point: Summarization with Pointer-Generator Networks"}, {"paperId": "aab5002a22b9b4244a8329b140bd0a86021aa2d1", "title": "OpenNMT: Open-Source Toolkit for Neural Machine Translation"}, {"paperId": "8cf76f09a63e8195b535edbb0d53e60d93a076aa", "title": "Building RDF Content for Data-to-Text Generation"}, {"paperId": "a486e2839291111bb44fa1f07731ada123539f75", "title": "Google\u2019s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "1a327709cc53ff9e52454e50a643abf4a0ac92af", "title": "Findings of the 2016 Conference on Machine Translation"}, {"paperId": "7a67159fc7bc76d0b37930b55005a69b51241635", "title": "Abstractive Sentence Summarization with Attentive Recurrent Neural Networks"}, {"paperId": "29a294eaec7b485245aa21d994f7300f6b5da8fc", "title": "Neural Summarization by Extracting Sentences and Words"}, {"paperId": "f37076f426023241f19cdc2fb0a0fd733a6fa7fa", "title": "Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond"}, {"paperId": "1ac30af5522c7a50ec4d1ee43fd2bd8652a9bd52", "title": "A Neural Attention Model for Abstractive Sentence Summarization"}, {"paperId": "93499a7c7f699b6630a86fad964536f9423bb6d0", "title": "Effective Approaches to Attention-based Neural Machine Translation"}, {"paperId": "258986132bf17755fe8263e42429fe73218c1534", "title": "CIDEr: Consensus-based image description evaluation"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e", "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"}, {"paperId": "d1275b2a2ab53013310e759e5c6878b96df643d4", "title": "Context dependent recurrent neural network language model"}, {"paperId": "93c20e38c85b69fc2d2eb314b3c1217913f7db11", "title": "Generating Text with Recurrent Neural Networks"}, {"paperId": "07ca885cb5cc4328895bfaec9ab752d5801b14cd", "title": "Extensions of recurrent neural network language model"}, {"paperId": "7533d30329cfdbf04ee8ee82bfef792d08015ee5", "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "6c2b28f9354f667cd5bd07afc0471d8334430da7", "title": "A Neural Probabilistic Language Model"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "3af95af0d1534b24df7ea4d94cbedba0b9663e37", "title": "Automatic evaluation of machine translation quality using n-gram co-occurrence statistics"}, {"paperId": "5665805becad6c87b194b260f2270d86d560bd3f", "title": "On Extractive and Abstractive Neural Document Summarization with Transformer Language Models"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "b12ccd118974839db290f15c989649b2b5188636", "title": "Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "bf0f141bae83bd6d5ca0c37839d53f0d06059b34", "title": "Controlling Politeness in Neural Machine Translation via Side Constraints"}, {"paperId": "81aace0e90c6a962059b117c24db0d856f340f41", "title": "Report on the 11th IWSLT evaluation campaign"}, {"paperId": "9819b600a828a57e1cde047bbe710d3446b30da5", "title": "Recurrent neural network based language model"}, {"paperId": null, "title": "l 1 , W P,l 2 \u2208 R d \u00d7 d , b P,l 1 , b P,l 2 \u2208 R d are trainable parameters, 1 \u2208 R | s |\u00d7 1 is a vector with all elements"}]}