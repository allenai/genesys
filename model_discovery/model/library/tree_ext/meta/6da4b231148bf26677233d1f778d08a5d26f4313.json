{"paperId": "6da4b231148bf26677233d1f778d08a5d26f4313", "title": "TR-BERT: Dynamic Token Reduction for Accelerating BERT Inference", "abstract": "Existing pre-trained language models (PLMs) are often computationally expensive in inference, making them impractical in various resource-limited real-world applications. To address this issue, we propose a dynamic token reduction approach to accelerate PLMs\u2019 inference, named TR-BERT, which could flexibly adapt the layer number of each token in inference to avoid redundant calculation. Specially, TR-BERT formulates the token reduction process as a multi-step token selection problem and automatically learns the selection strategy via reinforcement learning. The experimental results on several downstream NLP tasks show that TR-BERT is able to speed up BERT by 2-5 times to satisfy various performance demands. Moreover, TR-BERT can also achieve better performance with less computation in a suite of long-text tasks since its token-level layer number adaption greatly accelerates the self-attention operation in PLMs. The source code and experiment details of this paper can be obtained from https://github.com/thunlp/TR-BERT.", "venue": "North American Chapter of the Association for Computational Linguistics", "year": 2021, "citationCount": 48, "influentialCitationCount": 10, "openAccessPdf": {"url": "https://aclanthology.org/2021.naacl-main.463.pdf", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "A dynamic token reduction approach to accelerate PLMs\u2019 inference, named TR-BERT, which could flexibly adapt the layer number of each token in inference to avoid redundant calculation and achieve better performance with less computation in a suite of long-text tasks since its token-level layer number adaption greatly accelerates the self-attention operation in PLMs."}, "embedding": {"model": "specter_v2", "vector": [-0.058273687958717346, 0.8424995541572571, -0.3904702663421631, 0.060852497816085815, -0.30336254835128784, -0.23923775553703308, 0.6004877090454102, -0.11111734062433243, -0.7582907676696777, 0.2495933324098587, 0.6101952791213989, -0.14520792663097382, 0.34723934531211853, 0.3154369294643402, -0.0359075590968132, 0.018162118270993233, -0.7258414030075073, 0.704984188079834, -0.3142922520637512, -0.38204309344291687, -0.2966192960739136, -0.8422873616218567, -0.5072022080421448, 0.264649361371994, 0.6552174091339111, 0.0662711039185524, 0.6645929217338562, 0.5783864855766296, -0.8940532207489014, 0.0693591982126236, 0.12842576205730438, -0.6445221900939941, 0.25579267740249634, 0.336519718170166, -0.5958936810493469, -0.06617115437984467, -0.2576836347579956, -0.43632856011390686, -0.365058958530426, 1.018888235092163, -0.19372336566448212, 0.2055368572473526, 0.5589314699172974, -0.5190644264221191, -0.2835790514945984, 1.581821322441101, 0.5026180744171143, 0.75941401720047, -0.22217532992362976, -0.8925700187683105, 1.2844648361206055, -1.4797916412353516, 0.35530608892440796, 1.6296110153198242, 0.22631509602069855, 0.5858865976333618, -0.19974254071712494, -0.9681717753410339, 0.8888236284255981, 0.3459775149822235, -0.946158766746521, -0.39024385809898376, -0.009485386312007904, 0.12552307546138763, 2.1500439643859863, -0.31901511549949646, -0.12545938789844513, 0.5256931781768799, -0.7085942625999451, 1.8078380823135376, -0.4920262098312378, -0.8093644380569458, -0.6974298357963562, 0.20493125915527344, -0.0674801915884018, 0.592099130153656, -0.30885910987854004, 0.00456512114033103, -0.7555181384086609, 0.06760314851999283, 0.25824519991874695, -0.13662797212600708, 0.2699785530567169, 0.4135426878929138, -0.30487701296806335, 0.6570854187011719, 0.18034382164478302, 1.0256807804107666, -0.2322227656841278, 0.46061789989471436, 0.8065557479858398, 0.29556864500045776, 0.15142454206943512, 0.5959951281547546, -0.4124848544597626, 0.2365425080060959, -0.7154462933540344, 0.31683430075645447, -0.1683758795261383, 0.7949230670928955, -0.1887265294790268, 0.3665023148059845, -1.0271309614181519, 0.5732710361480713, 1.3175714015960693, 0.001738424994982779, 0.6808194518089294, -0.4950515925884247, 0.5804046392440796, -0.6977173686027527, 0.3405643403530121, -0.27584409713745117, -0.247827410697937, 0.03559940680861473, -0.8443253636360168, -1.524821400642395, -0.4300135374069214, -0.26857757568359375, -0.5572040677070618, 0.7769359946250916, -0.19482526183128357, 0.06774727255105972, 0.311271071434021, 0.2152801752090454, 0.5443322062492371, 0.7214807868003845, 0.24797575175762177, -0.2091214507818222, 1.1767405271530151, -0.9994451999664307, -1.1023844480514526, -0.9222685098648071, 0.7928423285484314, -0.08195942640304565, -0.16438792645931244, -0.230481818318367, -1.1261820793151855, -0.5608121752738953, -0.5441991686820984, -0.021831627935171127, -0.5006556510925293, 0.5497313141822815, 0.9928675293922424, 0.1588388830423355, -0.6351419687271118, 0.879124104976654, 0.19642344117164612, 0.08284859359264374, 0.19275616109371185, -0.16979753971099854, 0.4640057682991028, -0.40033096075057983, -1.8949750661849976, 0.35878849029541016, 0.7169865369796753, -0.019120793789625168, -0.04433266445994377, -0.738576352596283, -1.090600609779358, 0.048537079244852066, 0.567623496055603, -0.40446043014526367, 1.6659181118011475, -0.05522426590323448, -1.7004681825637817, 0.5800700187683105, -0.5792257785797119, 0.0780787542462349, 0.482166588306427, -0.2348490059375763, -0.6900365352630615, -0.7232053279876709, 0.12001238763332367, 0.5541455745697021, 0.5002787113189697, 0.006555759813636541, -0.6659279465675354, 0.26244261860847473, -0.10049643367528915, 0.26053473353385925, -0.231449693441391, 0.8992084860801697, -0.5255542397499084, -0.3540893793106079, 0.011519732885062695, 0.9423871636390686, -0.12753711640834808, -0.6048901081085205, -0.6473746299743652, -1.5634747743606567, 0.6302542090415955, -0.06398091465234756, 0.7782170176506042, -0.8313788771629333, -0.7228204011917114, -0.45293983817100525, -0.032819557934999466, 0.3589642345905304, -0.820567786693573, 0.6934924125671387, -0.31197962164878845, 0.5043094754219055, 0.146890327334404, -1.3378660678863525, 0.3608396053314209, -0.26642274856567383, -0.6449771523475647, -0.555855929851532, 0.23269031941890717, 1.0567883253097534, -1.2117122411727905, -0.1460389345884323, 0.14527881145477295, 0.19418351352214813, -0.847692608833313, 1.094314455986023, -0.41954997181892395, -0.030661573633551598, -0.2962779402732849, -0.42031922936439514, 0.3142695426940918, 0.06543201208114624, 0.4886956214904785, -0.40606456995010376, -0.4929869472980499, 0.7291740775108337, -0.6811683773994446, 1.257503867149353, -0.4393821358680725, 0.5434495210647583, -0.03139088675379753, -0.6723522543907166, -0.047225795686244965, 0.647803783416748, -0.14494754374027252, -0.4367277920246124, 0.08430618047714233, 0.23271997272968292, -0.5626233220100403, 0.10958751291036606, 0.8551957011222839, 0.7319883704185486, -0.3730257749557495, 0.0007409293903037906, 0.2247224897146225, 0.22202304005622864, 0.9400914311408997, 0.5679519772529602, 0.5557225346565247, 0.18105864524841309, 0.40601104497909546, -0.005736253689974546, 0.4987485706806183, -0.7103731632232666, 0.3738665282726288, 0.585286021232605, 0.7468275427818298, 0.22938668727874756, 0.4148693382740021, -0.5109612345695496, -0.262795090675354, 0.1762382537126541, 0.4864785671234131, 1.5626437664031982, -0.30395370721817017, -0.44316452741622925, -0.6603832840919495, -0.5504825115203857, -0.025342805311083794, 0.31303340196609497, -0.14251916110515594, 0.24099045991897583, -0.3878788352012634, -1.0214499235153198, 1.1377748250961304, -0.06748306751251221, 0.9580351114273071, -0.8593339323997498, 0.3421756327152252, 0.1299690455198288, -0.2679593861103058, -1.0047367811203003, -0.38650697469711304, 0.3564663529396057, -0.37585580348968506, -0.046882838010787964, 0.08320332318544388, -0.015275123529136181, 0.37375736236572266, -0.7544062733650208, 0.6615804433822632, -0.5314573049545288, -0.19309622049331665, -0.4241928160190582, 0.2675982117652893, -0.8664290904998779, -0.6423768997192383, 0.2270650714635849, 0.15350723266601562, -0.31352007389068604, 0.46328476071357727, 0.9649950265884399, 0.31411537528038025, -0.24406854808330536, -0.3476772606372833, 0.3550053834915161, 0.03096626326441765, 0.20373278856277466, 0.4745927155017853, 0.16626881062984467, 0.14491531252861023, -1.6695644855499268, 0.8735125064849854, 0.1669244021177292, -0.6371585130691528, 0.09159205853939056, -0.5925055146217346, -0.21533343195915222, 0.7605803608894348, -0.6462109684944153, -0.8372591137886047, -0.8681920766830444, 0.017251087352633476, -0.11056970804929733, -0.231614351272583, 0.5388475656509399, 0.1930200457572937, 0.6660125255584717, -0.10015998780727386, 0.635502815246582, 0.061978068202733994, -0.4967347979545593, 0.7480434775352478, -0.5171775817871094, 0.33375322818756104, 0.32799750566482544, 0.3908040523529053, -0.36138591170310974, -0.5843620896339417, -0.7900397777557373, -0.8988648653030396, -0.6450932025909424, -0.16427141427993774, -0.08956973254680634, -0.1567368060350418, -0.5125934481620789, -0.8976520299911499, -0.05380530655384064, -1.370478868484497, -0.18636004626750946, 0.17723532021045685, -0.02750927023589611, 0.24680568277835846, -0.8721837401390076, -1.39413583278656, -0.6582345366477966, -0.7035230994224548, -0.6442270874977112, 0.4454370439052582, -0.1682821661233902, 0.02937440015375614, -0.7695976495742798, -0.09043215960264206, -0.17601829767227173, 0.9588608741760254, -1.031674861907959, 0.7909201383590698, 0.1615125834941864, 0.08348190784454346, -0.04277115687727928, -0.03132861480116844, 0.31645363569259644, -0.06179273873567581, 0.17173783481121063, -0.8353763222694397, 0.17293322086334229, -0.4854167401790619, -0.12199202924966812, 0.19899022579193115, 0.38644590973854065, 0.9379234910011292, -0.3115234076976776, -0.8410248160362244, 0.40856367349624634, 1.4254447221755981, -0.8966348767280579, 0.3101217746734619, 0.32865527272224426, 0.966215968132019, 0.07174698263406754, 0.050641220062971115, 0.8078433871269226, 0.3638586103916168, 0.46297672390937805, 0.13884875178337097, -0.5671120882034302, 0.12261726707220078, -0.3644980192184448, 0.5450106263160706, 1.576308012008667, 0.30515730381011963, -0.3086605966091156, -0.8606345653533936, 0.7145298719406128, -1.3550397157669067, -0.9023628234863281, 0.4546070694923401, 0.4211427569389343, 0.6430094242095947, -0.4836694896221161, -0.40443772077560425, -0.06703422963619232, 0.6444384455680847, 0.13566233217716217, -0.35095250606536865, -0.7795456051826477, 0.26562297344207764, -0.2604065239429474, 0.2413310557603836, 0.6441285014152527, -0.20332852005958557, 1.369025707244873, 14.36686897277832, 0.889316201210022, 0.09148070961236954, 0.4014715552330017, 0.3206063210964203, 0.3768877387046814, -0.3763561248779297, -0.3894037902355194, -1.7171392440795898, -0.09953604638576508, 0.6498761177062988, -0.23401504755020142, 0.8149064183235168, 0.014760344289243221, 0.39056581258773804, 0.20952187478542328, -0.3808886408805847, 0.7027185559272766, 0.5752134919166565, -1.2198423147201538, 0.7034130096435547, 0.0510142557322979, 0.11271744221448898, 0.6746223568916321, 0.31287071108818054, 1.3089576959609985, 0.6065865755081177, -0.20623183250427246, 0.5149669647216797, -0.011075805872678757, 0.9321497082710266, -0.14381811022758484, 0.7038172483444214, 0.7921433448791504, -1.080744743347168, -0.29682111740112305, -0.9138351082801819, -1.1426689624786377, 0.1322268396615982, 0.43160468339920044, -1.0968514680862427, -0.22615134716033936, -0.21799176931381226, 0.9219865798950195, 0.43162864446640015, 0.32242414355278015, -0.4133218824863434, 0.7587516903877258, 0.17633837461471558, -0.16451548039913177, 0.2704113721847534, 0.3777922987937927, 0.584421694278717, 0.42420780658721924, -0.17633791267871857, 0.018032142892479897, -0.09376715123653412, 0.5852994918823242, -0.8036226034164429, -0.13486170768737793, -0.1039237454533577, -0.17735731601715088, 0.3926906883716583, 1.1378480195999146, 0.7504395246505737, 0.012268364429473877, -0.10772103816270828, 0.44628533720970154, 1.082767128944397, 0.19655242562294006, -0.5008037090301514, -0.17885905504226685, 0.5380582213401794, -0.5469354391098022, 0.11739011853933334, 0.8009620904922485, 0.07292088866233826, -0.5391305685043335, -0.9378642439842224, -0.20791809260845184, 0.23198869824409485, -0.582678496837616, -0.8837007284164429, 0.8405318260192871, -0.34825748205184937, -0.2723310887813568, -0.07970556616783142, -0.7454673051834106, -0.09393620491027832, 0.5419775247573853, -1.9317293167114258, -0.5091708898544312, 0.7280148267745972, -0.1659431904554367, -0.20112693309783936, 0.17436179518699646, 1.4294620752334595, 0.42207494378089905, -0.804039478302002, 0.10534413158893585, 0.7197466492652893, 0.49338048696517944, -0.1028919667005539, -1.059187650680542, 0.6623569130897522, 0.3023321032524109, -0.3712737262248993, 0.29202359914779663, -0.04148112237453461, 0.17562846839427948, -0.735266387462616, -0.566378653049469, 1.0019816160202026, -0.4751649498939514, -0.5291697978973389, -0.8859530687332153, -0.7143853306770325, 0.25825974345207214, 0.45573368668556213, -0.5696566104888916, 0.25163134932518005, 0.6440325975418091, -0.24560485780239105, -0.13410094380378723, -0.8009625673294067, 0.29228705167770386, 0.4835417568683624, -0.4447075128555298, -0.4164384603500366, 0.2921924591064453, 0.16080085933208466, -1.0649453401565552, -0.48626622557640076, -0.49063509702682495, -0.1901012659072876, 0.672633171081543, 1.0638917684555054, -0.39901381731033325, 0.44841083884239197, 0.7409355640411377, 0.32418596744537354, -1.0805143117904663, -0.45316579937934875, -0.9637928605079651, 0.06794176250696182, 0.41525188088417053, 1.2357791662216187, -0.22748246788978577, 0.04112785682082176, 0.783748209476471, 0.2099754512310028, -0.1508357673883438, -0.6028116941452026, -0.4443868398666382, -0.0976305678486824, -0.3789573907852173, 0.47467806935310364, 0.15137088298797607, 0.36535024642944336, 0.3448096811771393, 0.430801123380661, 0.693295419216156, -0.14163097739219666, -0.7888003587722778, 0.3081020414829254, -0.09426334500312805, 0.10004517436027527, -0.4714171588420868, 0.040811073035001755, -1.402559757232666, 0.35871103405952454, -1.3857282400131226, 0.4506818652153015, -1.348401427268982, -0.318065881729126, -0.03128805384039879, -0.27769461274147034, 0.36199450492858887, 0.1323930025100708, -0.47273918986320496, -0.3782363831996918, -0.4835004210472107, -0.638964831829071, 0.9829105734825134, 1.0218336582183838, -0.8813604116439819, 0.16918149590492249, -0.07800053805112839, -0.04180312156677246, 0.2986617684364319, 0.4564878046512604, -0.6178748607635498, -0.31655243039131165, -1.7449328899383545, 0.43164223432540894, -0.12026619166135788, -0.5426408052444458, -0.03674210608005524, 0.5633753538131714, 0.3756714463233948, -0.2444133162498474, -0.07574222981929779, 0.1367424577474594, -0.7930389642715454, -0.8458858728408813, 0.36472874879837036, -0.766298234462738, 0.05153822898864746, 0.2354314774274826, -0.6389290690422058, -0.250471830368042, 0.34601837396621704, -0.0963582992553711, -1.136457920074463, -0.8535579442977905, 0.606147050857544, -1.0636996030807495, 0.25732332468032837, -0.4919317364692688, -0.0763629674911499, -0.9961794018745422, -0.13254934549331665, 0.2568883001804352, 0.6092076897621155, -0.9476823210716248, 0.9497835636138916, 0.40795576572418213, -1.1337461471557617, -0.43755969405174255, 0.3125767111778259, -0.11836874485015869, 0.18688932061195374, 0.3418518304824829, 0.21562299132347107, -0.032342806458473206, 0.6138615608215332, 0.5000352263450623, 0.4271569550037384, -1.0274944305419922, -0.18238459527492523, 0.9097083210945129, -0.8991901874542236, -0.5230554342269897, 1.0542314052581787, -0.4759618937969208, -1.2188847064971924, 0.36705705523490906, -1.0844848155975342, -0.8511863946914673, -0.41645583510398865, 0.8026546835899353, 0.2744011878967285, -0.0627976655960083, 0.11213032156229019, -0.5013384819030762, -0.36734187602996826, -0.449225515127182, -0.4644424319267273, 0.655533492565155, -0.5075860023498535, -0.3089326024055481, 0.4370001256465912, 0.5470598936080933, -0.6302670240402222, -0.5758697390556335, -0.7446155548095703, -0.2034197300672531, -0.1493302285671234, 0.5736951231956482, -0.5595237612724304, -0.46737372875213623, 0.43900150060653687, 0.022550366818904877, 0.2903138995170593, -0.17031528055667877, -0.3740578293800354, 0.3993900716304779, 0.9326447248458862, -0.08522751182317734, -1.1828073263168335, -0.7714383602142334, 1.7078683376312256, 1.3073010444641113, -1.0348482131958008, 0.00888704415410757, -0.34614625573158264, -0.8652324676513672, 0.707312822341919, 0.33356156945228577, 0.16913564503192902, 0.6996603608131409, -0.18118269741535187, 0.11410347372293472, 0.1786920726299286, -0.9884921908378601, -0.5494409203529358, 0.5275654196739197, 1.068574070930481, 0.9401186108589172, 0.31687554717063904, 0.16535751521587372, 0.9364686012268066, 0.2064623087644577, 0.13361984491348267, 0.5836154818534851, -0.07191047072410583, 0.028281986713409424, -0.4134385883808136, 0.13826675713062286, 0.7693368792533875, -0.7138860821723938, -0.9047912359237671, -0.04017118364572525, 0.5522525906562805, 0.2696572542190552, 0.789511501789093, 0.5451449751853943, 0.4699932336807251, 0.4764830470085144, 0.02254449762403965, 0.3640611469745636, -0.706644594669342, -0.2926080524921417, -0.17236272990703583, -0.5387528538703918, -0.030804064124822617, -0.07446751743555069, -0.6991763114929199, -0.7112572193145752, -0.2515304386615753, -0.16679701209068298, 0.3514118492603302, 0.5673861503601074, 1.3051555156707764, 0.4959318935871124, 0.6928574442863464, -0.18096962571144104, -0.38768187165260315, -0.3961561322212219, -1.3302158117294312, -0.43320247530937195, -0.2758491635322571, -0.39904752373695374, 0.07741893082857132, -0.0842057466506958, -0.5325491428375244]}, "authors": [{"authorId": "50816334", "name": "Deming Ye"}, {"authorId": "2149202150", "name": "Yankai Lin"}, {"authorId": "2115640120", "name": "Yufei Huang"}, {"authorId": "1753344", "name": "Maosong Sun"}], "references": [{"paperId": "a50d31c082521817a1e74cae584963a63163ca70", "title": "Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime with Search"}, {"paperId": "097210dc65924f8ce59523faf444e635523dc714", "title": "TernaryBERT: Distillation-aware Ultra-low Bit BERT"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "389036b1366b64579725457993c1f63a4f3370ba", "title": "The Lottery Ticket Hypothesis for Pre-trained BERT Networks"}, {"paperId": "4ca3b0ea12f02e2dea01a4aa505956bae5500a09", "title": "Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing"}, {"paperId": "851de6751aef4128d7feb7c6ca36b180a0e0835e", "title": "DeFormer: Decomposing Pre-trained Transformers for Faster Question Answering"}, {"paperId": "90a1491ac32e732c93773354e4e665794ed4d490", "title": "DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "2573af4e13d9a5dddb257d22cd38a600528d9a8b", "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"}, {"paperId": "5d34881ff68bd203ff790187e7e5c9e034389cfa", "title": "FastBERT: a Self-distilling BERT with Adaptive Inference Time"}, {"paperId": "1c332cfa211400fc6f56983fb01a6692046116dd", "title": "DynaBERT: Dynamic BERT with Adaptive Width and Depth"}, {"paperId": "bd20069f5cac3e63083ecf6479abc1799db33ce0", "title": "A Primer in BERTology: What We Know About How BERT Works"}, {"paperId": "4510d9ad22f474c30c530ae7f886ec4d42402d68", "title": "PoWER-BERT: Accelerating BERT inference for Classification Tasks"}, {"paperId": "8382402fe166df3de499dac182e42baa51335926", "title": "Transformer-XH: Multi-Evidence Reasoning with eXtra Hop Attention"}, {"paperId": "acf5a74ccb14b01430dab2d200d9aabc5ee9dc16", "title": "MRQA 2019 Shared Task: Evaluating Generalization in Reading Comprehension"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1", "title": "Reducing Transformer Depth on Demand with Structured Dropout"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d", "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"}, {"paperId": "5744f56d3253bd7c4341d36de40a93fceaa266b3", "title": "Semantics-aware BERT for Language Understanding"}, {"paperId": "4bf61dab8ad195e87b6f0496ec7bada5d37c476f", "title": "Revealing the Importance of Semantic Retrieval for Machine Reading at Scale"}, {"paperId": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf", "title": "Patient Knowledge Distillation for BERT Model Compression"}, {"paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0", "title": "Natural Questions: A Benchmark for Question Answering Research"}, {"paperId": "efe4902a39c8ef332058ae7d156a6bffcd3c1341", "title": "Token-level Dynamic Self-Attention Network for Multi-Passage Reading Comprehension"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "165d51a547cd920e6ac55660ad5c404dcb9562ed", "title": "Open Sesame: Getting inside BERT\u2019s Linguistic Knowledge"}, {"paperId": "fc089a09074c84979d1f34e89341318a5bc26d3d", "title": "SemEval-2019 Task 4: Hyperpartisan News Detection"}, {"paperId": "455a8838cde44f288d456d01c76ede95b56dc675", "title": "A Structural Probe for Finding Syntax in Word Representations"}, {"paperId": "636904d91d9dd1a641a595d9578ba7640f35aa74", "title": "MultiQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension"}, {"paperId": "b03c7ff961822183bab66b2e594415e585d3fd09", "title": "Are Sixteen Heads Really Better than One?"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "0de47f354468283efc7765ec0b3588b2ae483c77", "title": "Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence"}, {"paperId": "22655979df781d222eaf812b0d325fa9adf11594", "title": "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "4d1c856275744c0284312a3a50efb6ca9dc4cd4c", "title": "Know What You Don\u2019t Know: Unanswerable Questions for SQuAD"}, {"paperId": "3913d2e0a51657a5fe11305b1bcc8bf3624471c0", "title": "Learning Structured Representation for Text Classification via Reinforcement Learning"}, {"paperId": "3c78c6df5eb1695b6a399e346dde880af27d1016", "title": "Simple and Effective Multi-Paragraph Reading Comprehension"}, {"paperId": "7d5cf22c70484fe217936c66741fb73b2a278bde", "title": "Constructing Datasets for Multi-hop Reading Comprehension Across Documents"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"}, {"paperId": "636a79420d838eabe4af7fb25d6437de45ab64e8", "title": "RACE: Large-scale ReAding Comprehension Dataset From Examinations"}, {"paperId": "3eda43078ae1f4741f09be08c4ecab6229046a5c", "title": "NewsQA: A Machine Comprehension Dataset"}, {"paperId": "6ff2a434578ff2746b9283e45abf296887f48a2d", "title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "51a55df1f023571a7e07e338ee45a3e3d66ef73e", "title": "Character-level Convolutional Networks for Text Classification"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "a20f0ce0616def7cc9a87446c228906cd5da093b", "title": "Policy Gradient Methods for Reinforcement Learning with Function Approximation"}, {"paperId": "38b3a4447a47a6a6ed1869f3da03352c487f8fe3", "title": "NewsWeeder: Learning to Filter Netnews"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "We use the MRQA (Fisch et al., 2019) version of NewsQA and NaturalQA"}, {"paperId": null, "title": "the answer of the unanswerable question as a span of [0 , 0]"}, {"paperId": null, "title": "2018) is an extractive question answering dataset, which requires multihop reasoning over multiple supporting documents for answering 113k questions. We adopt the fullwiki setting for HotpotQA"}, {"paperId": null, "title": "of topics, which can examine the generalization of our token selection"}, {"paperId": "4c915c1eecb217c123a36dc6d3ce52d12c742614", "title": "Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning"}, {"paperId": null, "title": "SQuAD 2"}, {"paperId": null, "title": "multi-hop reasoning over multiple supporting documents for answering 113 k questions. We adopt the full-wiki setting for HotpotQA, which requires models to \ufb01nd answers from a large-scale corpus"}]}