{"paperId": "8fe851f26a929d4c46911067e6ffc62eeac3fdd2", "title": "Take Care of Your Prompt Bias! Investigating and Mitigating Prompt Bias in Factual Knowledge Extraction", "abstract": "Recent research shows that pre-trained language models (PLMs) suffer from \u201cprompt bias\u201d in factual knowledge extraction, i.e., prompts tend to introduce biases toward specific labels. Prompt bias presents a significant challenge in assessing the factual knowledge within PLMs. Therefore, this paper aims to improve the reliability of existing benchmarks by thoroughly investigating and mitigating prompt bias. We show that: 1) all prompts in the experiments exhibit non-negligible bias, with gradient-based prompts like AutoPrompt and OptiPrompt displaying significantly higher levels of bias; 2) prompt bias can amplify benchmark accuracy unreasonably by overfitting the test datasets, especially on imbalanced datasets like LAMA. Based on these findings, we propose a representation-based approach to mitigate the prompt bias during inference time. Specifically, we first estimate the biased representation using prompt-only querying, and then remove it from the model\u2019s internal representations to generate the debiased representations, which are used to produce the final debiased outputs. Experiments across various prompts, PLMs, and benchmarks show that our approach can not only correct the overfitted performance caused by prompt bias, but also significantly improve the prompt retrieval capability (up to 10% absolute performance gain). These results indicate that our approach effectively alleviates prompt bias in knowledge evaluation, thereby enhancing the reliability of benchmark assessments. Hopefully, our plug-and-play approach can be a golden standard to strengthen PLMs toward reliable knowledge bases. Code and data are released in https://github.com/FelliYang/PromptBias.", "venue": "International Conference on Language Resources and Evaluation", "year": 2024, "citationCount": 5, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The approach effectively alleviates prompt bias in knowledge evaluation, thereby enhancing the reliability of benchmark assessments, and can be a golden standard to strengthen PLMs toward reliable knowledge bases."}, "embedding": {"model": "specter_v2", "vector": [-0.2407686561346054, 0.6632593274116516, -0.6671847105026245, -0.1776587814092636, -0.869457483291626, -0.7133845090866089, 1.0549395084381104, -0.24829481542110443, -0.19890405237674713, 0.1927238404750824, 0.4240293502807617, -0.06389781087636948, 0.15514667332172394, 0.016468733549118042, -0.4683947265148163, -0.10345955193042755, -0.5412358045578003, 0.4380536377429962, -0.2702993154525757, -0.13733546435832977, 0.20973218977451324, -0.49277064204216003, -0.8916506767272949, 0.10062994062900543, 0.5273378491401672, 0.6195048689842224, -0.4062601327896118, 0.7441470623016357, -0.7274416089057922, 0.6703794002532959, 0.1729203164577484, -0.3340522050857544, 0.23497478663921356, 0.34065043926239014, -0.7227644920349121, -0.21962331235408783, 0.6391324400901794, -0.691585123538971, -0.6252678632736206, 0.7485176920890808, -0.04866862669587135, 0.12426170706748962, 0.46000251173973083, -0.8851988315582275, -0.6206628680229187, 0.6276281476020813, 0.8409714102745056, 0.8867974281311035, 0.11147642880678177, -0.29431095719337463, 1.1758737564086914, -1.646822214126587, 0.7905985116958618, 1.1540436744689941, 0.2680966556072235, 0.19174328446388245, 0.2154780626296997, -0.642537534236908, 1.019978642463684, 0.2162436842918396, -0.9301522970199585, -0.32578951120376587, -0.11745928972959518, -0.5130689144134521, 1.5776755809783936, -0.4301513731479645, -0.445046991109848, 0.8173254132270813, -0.31754007935523987, 1.4662964344024658, 0.43465498089790344, -0.8483707308769226, -0.19621852040290833, 0.6155728697776794, 0.6891394257545471, 1.0941009521484375, -0.3378017246723175, 0.6680681705474854, -1.0098888874053955, -0.713415265083313, 0.7632442712783813, -0.5891842246055603, -0.372317373752594, 0.2745913565158844, -0.46628135442733765, 0.3443922698497772, 0.3631341755390167, 0.5930302739143372, -0.6538000702857971, 0.32246360182762146, 0.11183450371026993, 0.4258628487586975, -0.2374849170446396, 0.7862553000450134, -0.47818171977996826, 7.578988879686221e-05, -0.8850241303443909, 0.5854637026786804, 0.437211811542511, 0.9421433210372925, 0.08070749044418335, -0.10480094701051712, -1.2276005744934082, -0.09076827019453049, 0.9026496410369873, -0.09525809437036514, 0.6056328415870667, -0.9670006632804871, -0.011890474706888199, -0.06843872368335724, 1.149985909461975, -0.8417506217956543, -0.2499578893184662, 0.05843144282698631, -0.036464061588048935, -1.2380627393722534, -0.06675659120082855, -0.27400097250938416, -0.8827793002128601, 0.7177597880363464, -0.23707427084445953, -0.10819265246391296, 0.1465328335762024, 1.1039494276046753, 1.008743405342102, 0.4568474292755127, 0.2630663216114044, 0.27755311131477356, 0.9349079728126526, -0.6446064114570618, -0.5831201672554016, -0.9225292801856995, 0.9101997017860413, -0.3447715938091278, 0.2749076783657074, -0.3620114326477051, -0.9406113028526306, -0.5223975777626038, -0.9203965663909912, -0.09906145185232162, -0.8534797430038452, 0.5604140162467957, 1.2055115699768066, 0.27569758892059326, -0.7185694575309753, 0.48466023802757263, -0.006375908385962248, -0.4997575879096985, 0.1450400948524475, -0.033385779708623886, 0.3159947395324707, -0.6499022245407104, -1.1343873739242554, 0.43917611241340637, 0.46688464283943176, -0.8324353694915771, -0.23001135885715485, -0.3933354914188385, -0.7254705429077148, -0.2193538099527359, 1.004327654838562, -0.5346604585647583, 1.7518377304077148, -0.09712390601634979, -0.8504824042320251, 0.7186934947967529, -0.4751394987106323, 0.3962847888469696, 0.6452314853668213, -0.2086145281791687, -0.8600241541862488, -0.22522342205047607, 0.023466652259230614, 0.7280384302139282, 0.1423121839761734, -0.6322391033172607, -0.28453493118286133, 0.4830184876918793, 0.10816261172294617, -0.186638742685318, 0.1341932713985443, 0.6170842051506042, 0.057463016360998154, 0.07849232107400894, 0.22723275423049927, 1.0093390941619873, 0.019592151045799255, -0.037289537489414215, -0.3266586363315582, -1.3219928741455078, 0.7005318999290466, -0.25847482681274414, 0.8423069715499878, -0.6870190501213074, -1.2216968536376953, -0.16255789995193481, -0.1390284299850464, -0.1055295541882515, -0.6093997955322266, 0.6234279274940491, -0.14506733417510986, 0.6544937491416931, -0.2670348882675171, -0.019901253283023834, 0.28782060742378235, -0.11618432402610779, -1.1810659170150757, -0.5074998736381531, 0.44744792580604553, 1.3982973098754883, -1.0296064615249634, -0.11885424703359604, -0.241287499666214, -0.14552287757396698, -0.6323853731155396, 1.6133438348770142, -0.783168613910675, 0.19237717986106873, -0.295849084854126, 0.3386155664920807, 0.0619511678814888, -0.5053344368934631, -0.06081617251038551, -0.40401601791381836, -0.323132187128067, 0.4920017421245575, -0.5660005807876587, 1.4008296728134155, -0.1377178281545639, 0.15628913044929504, -0.05516620725393295, -0.2851520776748657, 0.5172653198242188, 0.8721558451652527, -0.13966308534145355, -0.540771484375, 0.04042556509375572, 0.8859285712242126, -1.0246082544326782, -0.42505672574043274, 0.972043514251709, 0.6642159819602966, -0.07403769344091415, 0.1155623346567154, 0.5707977414131165, -0.3035443127155304, 0.6179512739181519, 0.3772628903388977, 0.8043391704559326, 0.34110644459724426, 0.35409751534461975, -0.07191779464483261, 0.0779736191034317, 0.02068101428449154, 0.053990643471479416, 0.6042250990867615, 0.996296226978302, 0.604906439781189, 0.4173780083656311, -0.7338294982910156, 0.16812041401863098, 0.14266811311244965, 0.3414914309978485, 1.3343991041183472, 0.17622257769107819, -0.323356032371521, -0.36170852184295654, -1.0634305477142334, -0.29061052203178406, 0.6581283807754517, -0.22089172899723053, -0.20094355940818787, -0.4083762764930725, -1.105778694152832, 0.6779525279998779, 0.4918881952762604, 0.9886347651481628, -0.5332077741622925, -0.25032633543014526, -0.14549824595451355, -0.1296108216047287, -0.45360472798347473, -0.31261929869651794, 0.4224202632904053, -0.21282236278057098, -0.6745566129684448, -0.06626982241868973, -0.008841357193887234, 0.3734278976917267, -0.7568777799606323, 1.2947659492492676, -0.28669485449790955, -0.1517356038093567, 0.7333663105964661, 0.7508881092071533, -0.47662752866744995, -0.6238752603530884, 0.18421471118927002, -0.18160608410835266, -0.5888282656669617, 0.8101587295532227, 0.6640546917915344, -0.16016864776611328, 0.24263834953308105, -0.7000892162322998, -0.07297451049089432, 0.24014490842819214, 0.36770665645599365, 0.5041404962539673, -0.5126074552536011, 0.4148077368736267, -1.0764670372009277, 1.1167223453521729, -0.4741832911968231, -0.4488748610019684, 0.454222172498703, -1.1465364694595337, -0.43496906757354736, 0.27808964252471924, -0.27977320551872253, -0.5542356967926025, -1.1659395694732666, 0.39611729979515076, 0.467723548412323, -0.6753073334693909, 0.44882732629776, 0.2614453136920929, 0.23133273422718048, 0.5523942708969116, 0.081088125705719, -0.15841194987297058, -0.5312312841415405, 0.8653843402862549, -0.3491218686103821, 0.5298388600349426, -0.4079095125198364, -0.22737808525562286, -0.18102195858955383, -0.23857367038726807, -0.29984164237976074, -0.5048977732658386, -0.3677089810371399, 0.11809885501861572, -0.03143690526485443, -0.5300281047821045, -0.6207159161567688, -0.48667848110198975, -0.24673587083816528, -1.3263486623764038, -0.380594938993454, -0.22809775173664093, -0.5039036870002747, -0.22585448622703552, -1.3554737567901611, -0.6767861843109131, -0.8242119550704956, -0.1040220558643341, -0.5565675497055054, 0.643172025680542, 0.06883454322814941, -0.6854383945465088, -0.5469611883163452, 0.16144216060638428, -0.6477271914482117, 0.8170431852340698, -0.44039037823677063, 1.1250026226043701, -0.23320122063159943, -0.6424666047096252, -0.41690361499786377, -0.2135053277015686, 0.2805994153022766, -0.0648627057671547, 0.017181534320116043, -0.841208279132843, 0.5131633281707764, -0.1355266124010086, -0.6220906972885132, -0.18807029724121094, -0.08791419863700867, 0.2520085573196411, -0.3376132547855377, -0.6837997436523438, 0.057060547173023224, 1.4268463850021362, -0.550484299659729, -0.20250412821769714, 0.24914893507957458, 0.652900218963623, 0.6855401992797852, 0.19990523159503937, 0.12974973022937775, 0.49420276284217834, 0.38193953037261963, -0.15409627556800842, -0.25635701417922974, -0.07946866005659103, -0.7479234337806702, 0.39038947224617004, 1.138522982597351, 0.4573203921318054, 0.29134929180145264, -1.0470266342163086, 0.9061092138290405, -1.413265585899353, 0.14641523361206055, 0.33698582649230957, 0.5844124555587769, 0.7163010835647583, -0.9473275542259216, -0.42850738763809204, -0.5677869319915771, 0.12386015057563782, 0.12540102005004883, -0.42913076281547546, 0.0007702700095251203, -0.10521861165761948, 0.11664367467164993, 0.12216218560934067, 0.5381231307983398, 0.02750924602150917, 0.5154582858085632, 14.798443794250488, 0.7116975784301758, -0.08410812169313431, 0.53975909948349, 0.6375918388366699, 0.5907291173934937, -0.42904147505760193, -0.11076843738555908, -1.0141419172286987, -0.38675060868263245, 0.8269516229629517, -0.3970382511615753, 0.23296035826206207, 0.2927539646625519, -0.5183091163635254, -0.04336204752326012, -0.6157402396202087, 0.6161924600601196, 0.28305530548095703, -1.1210246086120605, 0.2713656723499298, -0.1984335482120514, 0.503128170967102, 0.28405484557151794, 0.4610440731048584, 0.9051215648651123, 0.6020899415016174, -0.6082983613014221, 0.5097590684890747, 0.4429764151573181, 0.8431774377822876, 0.20048630237579346, 0.5970229506492615, 0.40875181555747986, -0.3093279004096985, -0.08019176125526428, -0.4663487672805786, -1.0236997604370117, 0.18071694672107697, 0.4040375351905823, -0.9045803546905518, -0.14911390841007233, -0.5797014832496643, 0.25747057795524597, 0.0473300963640213, 0.4413747191429138, -0.3015213906764984, 0.7135587334632874, -0.045515239238739014, 0.3703784942626953, 0.3108893036842346, 0.6585620641708374, 0.490666002035141, -0.030508074909448624, 0.43142783641815186, -0.01247400976717472, 0.49158304929733276, 0.7739519476890564, -0.71155846118927, 0.24091465771198273, -0.660470187664032, -0.25822603702545166, 0.07750995457172394, 0.7603029012680054, 0.3409809172153473, -0.013034391216933727, -0.3346562087535858, 0.0029964635614305735, 0.6757458448410034, 0.6503983736038208, 0.1928098350763321, 0.15147840976715088, 0.1239251047372818, -0.2340776026248932, -0.5368242263793945, 0.49588602781295776, -0.2048095464706421, -0.340309202671051, -0.31305211782455444, -0.2242976725101471, 0.5806217193603516, -0.7649244666099548, -1.0258173942565918, 0.9575373530387878, -0.07675313204526901, -0.12860022485256195, -0.08469051122665405, -0.8597748875617981, 0.042115047574043274, 0.5128958821296692, -1.4864773750305176, -0.47489699721336365, -0.22974728047847748, -0.3504609167575836, -0.7654273509979248, 0.048486437648534775, 1.6265966892242432, -0.1693546622991562, -0.16913746297359467, -0.3020135760307312, -0.11962135136127472, -0.31542912125587463, 0.41517406702041626, -1.1783387660980225, 0.6860228776931763, -0.0542304702103138, 0.17219574749469757, 0.5692543983459473, 0.027301518246531487, -0.3722876012325287, -0.5739386081695557, -0.09379243105649948, 0.6058838963508606, -1.5033557415008545, -0.551356852054596, -0.2821880280971527, -1.0518982410430908, 0.2099335938692093, 0.5916481018066406, -0.3126923739910126, 0.1709718257188797, 0.17518362402915955, -0.6203891634941101, 0.2549147605895996, -0.9622681736946106, 0.1556759625673294, 0.7786125540733337, -0.5929455757141113, -0.6868666410446167, 0.3723013401031494, 0.24408814311027527, -1.1012952327728271, -0.43715426325798035, -0.04628663882613182, -0.18446384370326996, -0.028660695999860764, 0.4793633222579956, -0.7880195379257202, 0.37770795822143555, 0.5516957640647888, -0.302931547164917, -1.076339602470398, 0.09566807746887207, -0.9154598116874695, -0.43346846103668213, 0.2611164450645447, 1.0388444662094116, -0.5965190529823303, 0.05196768045425415, 1.5441926717758179, 0.5131393074989319, -0.47495219111442566, -0.4989071190357208, -0.47690340876579285, 0.5151687860488892, 0.02973400242626667, 0.6981088519096375, 0.15976405143737793, -0.11037690937519073, 0.007469233125448227, 0.6673178672790527, 0.5823922753334045, -0.6922076940536499, -0.34180739521980286, 0.36861205101013184, -0.3104546070098877, 0.2411152422428131, -0.26516249775886536, -0.018822837620973587, -1.7288872003555298, -0.2325110137462616, -1.246006965637207, 0.24566276371479034, -1.1016570329666138, -0.5528615117073059, 0.027605896815657616, -0.33455362915992737, 0.13347575068473816, 0.06542042642831802, -0.7011480927467346, -1.1540175676345825, -0.4102472960948944, -0.29977211356163025, 0.709180474281311, 0.8550010919570923, -0.36383330821990967, 0.0968964695930481, -0.511468231678009, -0.8318755030632019, 0.24510644376277924, 0.27120935916900635, -0.5060328841209412, -0.3493691086769104, -1.0741277933120728, 0.3032315969467163, -0.0031959847547113895, 0.41545799374580383, -0.11361158639192581, 0.9212763905525208, 0.3870302140712738, -0.3018113374710083, 0.30224916338920593, 0.15603816509246826, -1.118143916130066, -0.6041609644889832, -0.20879465341567993, -0.5984589457511902, 0.01445611659437418, 0.3156259059906006, -0.8534402251243591, -0.3927033841609955, 0.5182384848594666, -0.6293027400970459, -1.0691207647323608, -0.5872768759727478, 0.2517027258872986, -0.5471795201301575, 0.24104838073253632, -0.5197784304618835, 0.22139224410057068, -1.5849957466125488, -0.26503312587738037, 0.28489941358566284, 0.5311774015426636, -0.07240362465381622, 0.9360034465789795, -0.0037043553311377764, -1.33815336227417, 0.07927210628986359, 0.0032089645974338055, 0.27228111028671265, 0.07870970666408539, 0.2267886996269226, 0.37721726298332214, 0.1148538663983345, 0.776150107383728, 0.1896986961364746, 0.45163652300834656, -0.22681812942028046, -0.02643027901649475, 0.3435550630092621, -0.3193092346191406, -0.19808563590049744, 0.9164595603942871, -0.3108046054840088, -1.052800178527832, 0.3209907114505768, -1.0830879211425781, -0.07569451630115509, -0.44232484698295593, 0.5270514488220215, 0.4012787342071533, 0.2429158091545105, 0.09311830252408981, -0.3739171028137207, -0.07021219283342361, -0.47135964035987854, -0.6525870561599731, 0.24327729642391205, 0.11822063475847244, -0.28746935725212097, 0.6268121004104614, 0.5902754068374634, -0.5084215402603149, -0.6760911345481873, -0.45618700981140137, 0.4006361663341522, -0.38054656982421875, 0.3256358206272125, -1.30774986743927, -0.20419485867023468, 0.4153424799442291, 0.5578880906105042, 0.35020872950553894, -0.04770907387137413, -0.1297576129436493, 0.26502150297164917, 0.8856906890869141, 0.25591278076171875, -0.8341276049613953, -0.9020849466323853, 0.8488545417785645, 1.6175730228424072, -1.151496410369873, 0.06986036151647568, -0.5638622045516968, -0.5017135143280029, 0.8527047038078308, 0.8213115930557251, 0.3977106809616089, 0.5334980487823486, -0.3153993487358093, 0.772520124912262, -0.707491934299469, -0.9080761075019836, -0.09879671037197113, 0.7507302761077881, 0.9730495810508728, 0.9159958362579346, 0.2324231117963791, -0.13496629893779755, 1.2809337377548218, 0.0023968564346432686, 0.6438462138175964, 0.3604908585548401, 0.7525091767311096, -0.2729685306549072, -0.158965602517128, -0.24116311967372894, 0.7882601022720337, -0.3470363914966583, -0.5406793355941772, -0.7864804863929749, 0.8252861499786377, 0.1597614735364914, 0.5316548943519592, 0.2739827632904053, 0.3542170822620392, 0.8403684496879578, 0.9177848696708679, 0.32413408160209656, -0.3064386546611786, -0.20694474875926971, -0.5794847011566162, -0.15720053017139435, -0.07636963576078415, -0.22266565263271332, -0.2688997685909271, -0.3352993130683899, 0.1832069456577301, 0.4134773910045624, 0.3934389650821686, 0.22709274291992188, 0.9678987860679626, 0.9012185335159302, 0.19850361347198486, -0.6251500248908997, 0.1515807956457138, -0.34923747181892395, -1.123537302017212, 0.08315384387969971, -0.5303642749786377, -0.43294596672058105, -0.800007700920105, -0.09846572577953339, -0.4435625970363617]}, "authors": [{"authorId": "2291967415", "name": "Ziyang Xu"}, {"authorId": "2065263152", "name": "Keqin Peng"}, {"authorId": "46573238", "name": "Liang Ding"}, {"authorId": "2255502438", "name": "D. Tao"}, {"authorId": "2291987761", "name": "Xiliang Lu"}], "references": [{"paperId": "46b8f29c23b29dc9b62c9292481d54e03939bf3b", "title": "Healthcare Copilot: Eliciting the Power of General LLMs for Medical Consultation"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "28a7ced384549eaae74ea9ad3ee21189a0625afe", "title": "Mitigating Label Biases for In-context Learning"}, {"paperId": "293499319bdd460cb3fca1f0f5eb330e64bf3ff9", "title": "Towards Making the Most of ChatGPT for Machine Translation"}, {"paperId": "8bc313e04cbd39847eb50b22af0a698ff2971a35", "title": "Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models: A Case Study on ChatGPT"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "6839816cd3ab194dfa3ffe3066cc35d099820e00", "title": "Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT"}, {"paperId": "1d4ecc8eabd7d5ac86a53988dcffbf81dd270e23", "title": "Bag of Tricks for Effective Language Model Pretraining and Downstream Adaptation: A Case Study on GLUE"}, {"paperId": "d19bae780d5fe93e4d007e325c278598ec7f9ea4", "title": "Toward Efficient Language Model Pretraining and Downstream Adaptation via Self-Evolution: A Case Study on SuperGLUE"}, {"paperId": "969f45a3adf5e0bcf741447b1c67a0f3a386801a", "title": "BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for Text Generation"}, {"paperId": "39e8c02fbce5fcfaf9c2cb49bd21f697ce54f679", "title": "Should We Rely on Entity Mentions for Relation Extraction? Debiasing Relation Extraction with Counterfactual Analysis"}, {"paperId": "27b6acf6bbb8fcad1f6bf1b90331b49489bd5ff1", "title": "PromptBERT: Improving BERT Sentence Embeddings with Prompts"}, {"paperId": "614dd2ae6db71cd5b2a6069407d3e0705ab2c19c", "title": "OpenPrompt: An Open-source Framework for Prompt-learning"}, {"paperId": "e337ed6543c2e6e7e51c312c7d998798fc79fdde", "title": "Knowledgeable or Educated Guess? Revisiting Language Models as Knowledge Bases"}, {"paperId": "2add974973ab45e46f1f8d3b932d24ba88cbb0b4", "title": "RedditBias: A Real-World Resource for Bias Evaluation and Debiasing of Conversational Language Models"}, {"paperId": "f2885c6a25756cf81aa23b41bc62696a5be5c94d", "title": "Factual Probing Is [MASK]: Learning vs. Learning to Recall"}, {"paperId": "bc37c6bdb8f39929a58b30464f72d6aa46cddc17", "title": "GPT Understands, Too"}, {"paperId": "ce9ca56036307217ea565644d3d3bd74b879e045", "title": "Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP"}, {"paperId": "56fa0b9cba4d9aee5ccc327365b3b3a721031c69", "title": "Calibrate Before Use: Improving Few-Shot Performance of Language Models"}, {"paperId": "fcfc9648561a221750b8085790ad9ba1bebb1800", "title": "Multilingual LAMA: Investigating Knowledge in Multilingual Pretrained Language Models"}, {"paperId": "24a1767f6731abaeb21f8fa745b7e02fd4bbf39f", "title": "Understanding and Improving Lexical Choice in Non-Autoregressive Translation"}, {"paperId": "3d864a8bc5a55ccab9993aa66203d8e70b88148c", "title": "Measuring and Reducing Gendered Correlations in Pre-trained Models"}, {"paperId": "6a3cc30d5d6342d912851deb4362b8c47fa5ede3", "title": "Towards Debiasing NLU Models from Unknown Biases"}, {"paperId": "f30444fbb6ad806168e2564db4815cd27faa7fd9", "title": "It\u2019s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "e969aa3422a49152c22f3faf734e4561a2a3cf42", "title": "Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection"}, {"paperId": "8ae9a17c87a4518b513e860683a0ef7824be994d", "title": "Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference"}, {"paperId": "c7fc1cac162c0e2a934704184c7554fd6b6253f0", "title": "Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language Model"}, {"paperId": "a75649771901a4881b44c0ceafa469fcc6e6f968", "title": "How Can We Know What Language Models Know?"}, {"paperId": "22d3dfd27bfd4ec00ab6d9744cec851982e9b89a", "title": "Queens Are Powerful Too: Mitigating Gender Bias in Dialogue Generation"}, {"paperId": "2bd5b4aed18400bf1a1cc866d9b8d931aa047290", "title": "E-BERT: Efficient-Yet-Effective Entity Embeddings for BERT"}, {"paperId": "68c1bf884f0fc0e86641466a1f1fa67e79f16a17", "title": "Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "72a1d0256b38dea6c3e7d10a63eacc51abdc96da", "title": "End-to-End Bias Mitigation by Modelling Biases in Corpora"}, {"paperId": "d0086b86103a620a86bc918746df0aa642e2a8a3", "title": "Language Models as Knowledge Bases?"}, {"paperId": "0e9b89f034b9a8c2828fe7daaee3894d6bfe3e50", "title": "On Measuring and Mitigating Biased Inferences of Word Embeddings"}, {"paperId": "3caf34532597683c980134579b156cd0d7db2f40", "title": "Universal Adversarial Triggers for Attacking and Analyzing NLP"}, {"paperId": "a2ce1fb96c0b78bee18bb2cb2c3d55dc48d54cbd", "title": "Measuring Bias in Contextualized Word Representations"}, {"paperId": "835ac3cbb41f2ec47718c5491211dd33b64f382b", "title": "Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology"}, {"paperId": "1670a07b70f90cc4ddba71343e6a7ee4b5198595", "title": "Evaluating Gender Bias in Machine Translation"}, {"paperId": "623b1c61aa36048a38485a44551cb3fdcbcc827b", "title": "Reducing Gender Bias in Word-Level Language Models with a Gender-Equalizing Loss Function"}, {"paperId": "d9f6ada77448664b71128bb19df15765336974a6", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"}, {"paperId": "a4e67bcbf912e13cebbb1241d05d1ca0a1df9df8", "title": "Identifying and Reducing Gender Bias in Word-Level Language Models"}, {"paperId": "c590d2c8c2fb6ce5d32ee9165ab24171165f2b70", "title": "Assessing gender bias in machine translation: a case study with Google Translate"}, {"paperId": "11eaa4f1cba9281ecbc1ac44a6b3ba5817bf1a25", "title": "T-REx: A Large Scale Alignment of Natural Language with Knowledge Base Triples"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "0be19fd9896e5d40222c690cc3ff553adc7c0e27", "title": "Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods"}, {"paperId": "45dfef0cc1ed96558c1c650432ce39d6a1050b6a", "title": "Fixing Weight Decay Regularization in Adam"}, {"paperId": "135bafc83e9a73c88e759f98a28edfdb5c02f81d", "title": "Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints"}, {"paperId": "d65ce2b8300541414bfe51d03906fca72e93523c", "title": "On Calibration of Modern Neural Networks"}, {"paperId": "7869471766d5d73adaa37398a2f2fbaff9160221", "title": "Bias Mitigation in Machine Translation Quality Estimation"}, {"paperId": "cea684bfe852e6fccdcb7c4d8676f8cab04dccc2", "title": "Counterfactual Inference for Text Classification Debiasing"}, {"paperId": null, "title": "Au-toPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts"}, {"paperId": null, "title": "Towards debi-asing sentence representations"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Ro{bert}a: A robustly optimized {bert} pre-training approach"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": null, "title": "case sensitive tokens respectively."}, {"paperId": null, "title": "2024. On large language models\u2019 selection bias in multi-choice questions"}, {"paperId": null, "title": "2024. Beyond probabilities: Unveiling the mis-alignment in evaluating large language models"}, {"paperId": null, "title": "prompt\u2019s end. or example"}, {"paperId": null, "title": "2022b. Should we rely on entity mentions for relation extraction?"}, {"paperId": null, "title": "2022. Feature-level debiased natural language understanding"}, {"paperId": null, "title": "on the set for BERT and RoBERTa, following settings in previous work. Finally, optionally, us-ing a common vocabulary filter on the set to compare different PLMs"}, {"paperId": null, "title": "We train the OptiPrompt prompts for 50 epochs with a learning rate of 3e-2 and a batch size of 16. All performance of OptiPrompt we reported is averaged results over 3 random seeds"}, {"paperId": null, "title": "We focus on a typed querying paradigm which needs to construct a candidate set C for each relation"}]}