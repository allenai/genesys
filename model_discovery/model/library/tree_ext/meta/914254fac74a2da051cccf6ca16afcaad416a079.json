{"paperId": "914254fac74a2da051cccf6ca16afcaad416a079", "title": "AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model", "abstract": "In this work, we demonstrate that multilingual large-scale sequence-to-sequence (seq2seq) models, pre-trained on a mixture of denoising and Causal Language Modeling (CLM) tasks, are more efficient few-shot learners than decoder-only models on various tasks. In particular, we train a 20 billion parameter multilingual seq2seq model called Alexa Teacher Model (AlexaTM 20B) and show that it achieves state-of-the-art (SOTA) performance on 1-shot summarization tasks, outperforming a much larger 540B PaLM decoder model. AlexaTM 20B also achieves SOTA in 1-shot machine translation, especially for low-resource languages, across almost all language pairs supported by the model (Arabic, English, French, German, Hindi, Italian, Japanese, Marathi, Portuguese, Spanish, Tamil, and Telugu) on Flores-101 dataset. We also show in zero-shot setting, AlexaTM 20B outperforms GPT3 (175B) on SuperGLUE and SQuADv2 datasets and provides SOTA performance on multilingual tasks such as XNLI, XCOPA, Paws-X, and XWinograd. Overall, our results present a compelling case for seq2seq models as a powerful alternative to decoder-only models for Large-scale Language Model (LLM) training.", "venue": "arXiv.org", "year": 2022, "citationCount": 70, "influentialCitationCount": 12, "openAccessPdf": {"url": "http://arxiv.org/pdf/2208.01448", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "It is demonstrated that multilingual large-scale sequence-to-sequence (seq2seq) models, pre-trained on a mixture of denoising and Causal Language Modeling tasks, are more efficient few-shot learners than decoder-only models on various tasks."}, "embedding": {"model": "specter_v2", "vector": [0.3236214518547058, 0.7121829986572266, -0.28492701053619385, -0.018516898155212402, -0.7873777151107788, -0.3655517101287842, 0.8988685011863708, -0.11882151663303375, -0.22156503796577454, 0.14998099207878113, 1.1856932640075684, 0.09820296615362167, 0.514114499092102, 0.19887660443782806, -0.24505051970481873, 0.1090681180357933, -0.9424763321876526, 0.23628662526607513, 0.012601439841091633, -0.7739726305007935, -0.009775720536708832, -1.2375479936599731, -0.34385091066360474, 0.22603127360343933, 0.5517143607139587, 0.08505676686763763, 0.09221159666776657, 0.9383854269981384, -0.33677756786346436, 0.7339991331100464, 0.3545953333377838, -0.406887948513031, 0.200299933552742, -0.6159968972206116, -0.08741237223148346, -0.2144179791212082, 0.43190059065818787, -0.7869168519973755, -0.2860874533653259, 0.9946613907814026, 0.036779772490262985, 0.017041105777025223, 0.4416602551937103, -0.3503649830818176, -0.3127428889274597, 1.2562830448150635, 0.373931348323822, 0.6098952889442444, -0.02674824185669422, -0.413851797580719, 1.104365587234497, -1.1070916652679443, 0.5746199488639832, 1.6565942764282227, 0.49670520424842834, 0.4781564474105835, 0.04366599768400192, -0.4907606542110443, 0.40312233567237854, 0.2382580041885376, -0.5640087127685547, -0.34886008501052856, -0.2368115931749344, -0.04913867264986038, 1.2985832691192627, -0.5377812385559082, -0.28389033675193787, 0.9491918087005615, 0.23719821870326996, 1.2944449186325073, -0.4655250012874603, -0.41604968905448914, -0.09590237587690353, -0.32299086451530457, 0.34118467569351196, 0.5434952974319458, -0.6728341579437256, -0.026752308011054993, -0.7973880171775818, 0.038662414997816086, -0.031030261889100075, 0.03593621775507927, -0.19668135046958923, 0.37798041105270386, -0.2692875266075134, 0.7846121788024902, 0.044217582792043686, 0.6617075204849243, 0.09310437738895416, 0.6654523015022278, 0.9787118434906006, 0.4724428951740265, 0.37676844000816345, 0.17918749153614044, -0.17008116841316223, 0.3544168770313263, -0.6787179708480835, 0.37257450819015503, -0.09468097239732742, 0.8765861392021179, -0.4205739498138428, 0.4191396236419678, -0.8974707126617432, 0.05660970136523247, 1.1801375150680542, -0.006306888535618782, 0.32696273922920227, -1.053478479385376, 0.01665298268198967, -1.1153208017349243, 0.14987054467201233, -0.5190732479095459, -0.018540088087320328, -0.07392887026071548, -0.7193636298179626, -1.2484691143035889, -0.3406464755535126, 0.03656207025051117, -0.4126109480857849, 0.9130915403366089, -0.3108619451522827, 0.6604984998703003, 0.38377487659454346, 0.366638720035553, 1.0359060764312744, 1.049383521080017, 0.08270937204360962, -0.8483439683914185, 0.7279009819030762, -0.7080631852149963, -1.0428632497787476, -0.9564732909202576, 0.666826605796814, -0.08344253152608871, -0.07121190428733826, 0.07551124691963196, -1.336246132850647, -0.5884130597114563, -0.83675217628479, -0.1657811999320984, -0.1314409375190735, 0.026846617460250854, 0.4521162211894989, 0.26276376843452454, -0.7505757212638855, 0.7694562673568726, -0.16558785736560822, -0.4611952602863312, 0.4042922258377075, -0.5394933819770813, 0.26845189929008484, -0.3725701570510864, -1.471171259880066, 0.3748719394207001, 0.32561174035072327, -0.5741113424301147, -0.5619051456451416, -1.0421046018600464, -1.0977427959442139, -0.2788022756576538, 0.7035501003265381, -0.13195262849330902, 1.328792929649353, -0.00020620178838726133, -1.3350859880447388, 0.464042603969574, -0.5700317025184631, -0.12891598045825958, 0.681821882724762, -0.45328933000564575, -0.2938905358314514, -0.2989359498023987, 0.22609762847423553, 0.11371735483407974, 0.13918544352054596, -0.14582812786102295, -0.031436242163181305, -0.20703165233135223, -0.26729264855384827, -0.40539419651031494, -0.19273655116558075, 1.021532654762268, -0.5914767384529114, -0.3795206844806671, -0.19768555462360382, 0.9400109052658081, 0.08255856484174728, -0.3650883436203003, -0.4886394739151001, -1.081058144569397, 0.7401530146598816, -0.35319122672080994, 0.792298436164856, -0.7534109354019165, -0.4786367118358612, -0.8166669011116028, -0.3191826641559601, 0.22642381489276886, -0.9819328188896179, 0.7792811989784241, -0.08619627356529236, 0.4607044756412506, -0.37413889169692993, -1.1885013580322266, -0.2765505909919739, -0.09524207562208176, -1.0967819690704346, -0.04744419455528259, 0.10888751596212387, 1.1016647815704346, -1.3211536407470703, 0.19882944226264954, -0.03348926827311516, 0.18090882897377014, -1.1982134580612183, 1.0438756942749023, -0.6334176063537598, 0.5869235992431641, -0.2643909752368927, -0.3897832930088043, 0.31528547406196594, 0.1850380152463913, 0.8008794784545898, -0.5542590022087097, -0.21888209879398346, 0.08415775746107101, -0.37764549255371094, 1.858370065689087, 0.0794534906744957, 0.5557711720466614, 0.059456050395965576, -0.8897643089294434, 0.1861104667186737, 0.4635930359363556, -0.290680468082428, -0.5862124562263489, 0.5269284844398499, 0.2937983274459839, -0.965435266494751, -0.2542385458946228, 0.396776020526886, 0.7788162231445312, -0.5990108251571655, 0.189861461520195, 0.8668245077133179, -0.15814436972141266, 0.7757082581520081, 0.9858161211013794, 0.6947311162948608, 0.4222717881202698, 0.5222687721252441, -0.25976964831352234, 0.22863562405109406, -0.6700364351272583, 0.290336936712265, 0.6373692154884338, 0.40608441829681396, 1.1894397735595703, 0.8479845523834229, -0.6306378245353699, -0.5568570494651794, -0.3489755690097809, 0.7524109482765198, 1.2876582145690918, 0.1637287437915802, -0.35467132925987244, -0.8540182113647461, -0.19981737434864044, -0.4790481626987457, 0.5255962014198303, -0.49955689907073975, -0.14642304182052612, -0.6609628796577454, -1.0630130767822266, 0.6491334438323975, 0.055540092289447784, 0.885323703289032, -0.2035861760377884, -0.10385257750749588, -0.32093897461891174, -0.13789013028144836, -0.7506548762321472, -0.7666648626327515, -0.0623323954641819, -0.25950950384140015, -0.09277313947677612, 0.034710150212049484, 0.16726641356945038, -0.24229776859283447, -0.6342321038246155, 0.9144656658172607, -0.8664391040802002, -0.3988417387008667, 0.12907670438289642, 0.1670638918876648, -0.6991070508956909, -1.0663821697235107, -0.1625259816646576, 0.20518708229064941, -0.24988651275634766, 0.2507461607456207, 0.6891835927963257, 0.3941650390625, -0.35966846346855164, -0.3691159188747406, -0.12553811073303223, -0.2607777416706085, 0.06594166904687881, 0.16941554844379425, -0.32371824979782104, 0.499360054731369, -1.1645376682281494, 0.8815658688545227, -0.15210244059562683, -0.370280385017395, 0.26500704884529114, -0.20005783438682556, -0.6412521004676819, 0.5631256103515625, -0.380715936422348, -0.689271867275238, -1.244925618171692, 0.2289593368768692, -0.057806406170129776, -0.2180643528699875, 0.3963516354560852, 0.18766936659812927, 0.8719660043716431, 0.2851896286010742, 0.4381621181964874, 0.6457784175872803, -0.3317035436630249, 0.7756964564323425, -0.6183449029922485, 0.8170442581176758, 0.7746973037719727, -0.07002371549606323, 0.13277898728847504, -0.17814235389232635, -0.9531459808349609, -0.6995438933372498, -0.16058653593063354, -0.4064218997955322, -0.31276562809944153, 0.5712032318115234, -0.8690428733825684, -0.7319871187210083, 0.2824360430240631, -1.329778790473938, -0.12968315184116364, 0.5218021869659424, -0.4610457122325897, -0.35296472907066345, -0.7547302842140198, -1.0824322700500488, -0.4542247951030731, -0.6038328409194946, -0.8314438462257385, 0.5853669047355652, -0.04391861334443092, -0.5427701473236084, -0.5861502289772034, 0.2454252392053604, -0.3428904116153717, 0.47081613540649414, -0.34866732358932495, 0.5811734199523926, -0.13310720026493073, -0.19952349364757538, -0.2198217213153839, 0.6115342974662781, 0.43658724427223206, -0.22191347181797028, 0.2116347849369049, -0.48046356439590454, 0.10480231791734695, -0.3192931115627289, -0.7032658457756042, 0.41446253657341003, 0.5952434539794922, 0.26215729117393494, 0.24233117699623108, -0.20403455197811127, -0.013114988803863525, 1.527702808380127, -0.5082239508628845, 0.16845834255218506, -0.3030952215194702, 0.8948396444320679, 0.48148980736732483, 0.1378335803747177, 0.7629353404045105, 0.3259916305541992, 0.2568414509296417, 0.28857046365737915, 0.25359225273132324, 0.03203114494681358, -0.5439515113830566, 0.8860529661178589, 1.4662892818450928, 0.3150569796562195, -0.2090216875076294, -0.9933978319168091, 0.7930447459220886, -1.3656173944473267, -1.013495683670044, 0.09496142715215683, 0.5106679797172546, 0.45464813709259033, -0.741534411907196, -0.3762257695198059, -0.421592116355896, 0.5295608043670654, 0.3711874485015869, -0.166935533285141, -0.6610901355743408, -0.006854221224784851, 0.18869224190711975, 0.09358822554349899, 0.7971523404121399, -0.3310184180736542, 0.7304949760437012, 14.86774730682373, 0.9379016757011414, 0.032297197729349136, 0.7088030576705933, 0.5254173278808594, -0.17557154595851898, -0.4032275080680847, -0.19187822937965393, -1.1087318658828735, -0.24910970032215118, 1.128588318824768, -0.0053258794359862804, 0.5190005898475647, -0.09112773835659027, 0.6851017475128174, -0.041109807789325714, -0.4737725555896759, 0.3313485085964203, 0.7270922660827637, -1.4657312631607056, 0.6171098351478577, -0.00197978806681931, 0.5876758098602295, 0.8165445327758789, 0.7280514240264893, 0.6584211587905884, 0.37357768416404724, -0.3215606212615967, 0.49831122159957886, 0.3044620752334595, 0.8454278111457825, -0.26146814227104187, 0.5651549696922302, 0.8440992832183838, -0.46346741914749146, -0.4224139451980591, -0.6540201902389526, -1.0428498983383179, 0.610214352607727, -0.14255735278129578, -0.1778835952281952, 0.006179383024573326, -0.12569262087345123, 1.1868857145309448, 0.45840105414390564, -0.03860285133123398, -0.16572245955467224, 0.7244020700454712, 0.44586649537086487, 0.006191133055835962, 0.40452319383621216, 0.13323239982128143, 0.4833959937095642, -0.2750111222267151, 0.1938234120607376, 0.2772902250289917, -0.02526850253343582, 0.4255942702293396, -0.4643137753009796, 0.010628278367221355, -0.6124652028083801, -0.19003969430923462, 0.1049937829375267, 0.41141027212142944, 0.8058403730392456, -0.11583859473466873, -0.6242662072181702, 0.2732551693916321, 0.31690534949302673, -0.09188104420900345, -0.3586500287055969, -0.15531347692012787, 0.34079790115356445, -0.5617892742156982, 0.0921877920627594, 0.6240977644920349, -0.16654089093208313, -0.831640362739563, -1.1144680976867676, -0.46627673506736755, 0.30637168884277344, -0.9516456127166748, -0.542768120765686, 0.4884425401687622, -0.285330593585968, -0.5169445276260376, 0.08952310681343079, -0.5526381731033325, -0.7926616072654724, 0.016505379229784012, -1.0469956398010254, -0.7212382555007935, 0.37787672877311707, -0.4392310380935669, 0.16879786550998688, -0.112494096159935, 1.1014827489852905, -0.09371190518140793, -0.48325636982917786, -0.14588578045368195, 0.6521257162094116, -0.24247297644615173, 0.2624588906764984, -0.6950443983078003, 0.6584311723709106, 0.37553083896636963, -0.564753532409668, 0.19321006536483765, 0.5460348725318909, -0.015537969768047333, -1.2381430864334106, -0.39105576276779175, 0.7665599584579468, -0.870862603187561, -0.29469844698905945, -0.8564050197601318, -0.8931138515472412, 0.2749151885509491, 1.082742691040039, -0.3281264305114746, 0.07607129216194153, -0.13978612422943115, -0.2908499836921692, -0.2928054928779602, -0.7025036215782166, 0.17273341119289398, 0.24705328047275543, -0.5927509069442749, -0.499777227640152, -0.3008527159690857, 0.43914344906806946, -0.527094841003418, -0.5276786088943481, -0.16493603587150574, 0.07131727039813995, -0.1953672468662262, 0.8448179364204407, -0.35926109552383423, 1.0305780172348022, 1.0255829095840454, -0.12979820370674133, -0.915267288684845, 0.3226737380027771, -1.1435097455978394, 0.5008782744407654, 0.6546834707260132, 0.2170037478208542, -0.21167248487472534, -0.3149130344390869, 0.3356294333934784, 0.2735730707645416, 0.009231423027813435, -0.5555605292320251, -0.3622554540634155, 0.7475355863571167, -0.5573800802230835, -0.09310463815927505, 0.0034070652909576893, 0.15148548781871796, 0.10772284120321274, -0.254535436630249, 0.7701717615127563, 0.3265635371208191, -1.2211432456970215, 0.6777785420417786, 0.10549023747444153, 0.09889886528253555, -0.3044111728668213, -0.24546997249126434, -1.164602279663086, 0.06285563111305237, -0.9894182682037354, 0.2213897556066513, -0.758324146270752, -0.21627870202064514, 1.1067941188812256, 0.2546207308769226, -0.19169223308563232, 0.22647053003311157, -0.023201141506433487, -0.41259899735450745, -0.9820826053619385, -0.7106412053108215, 0.8788391947746277, 0.9583826065063477, -0.9900669455528259, 0.26533371210098267, -0.687557578086853, -0.0020492486655712128, 0.39898306131362915, 0.26463204622268677, -0.2635619640350342, -0.872546374797821, -1.4032238721847534, 0.14279711246490479, 0.2546653151512146, 0.16641822457313538, -0.1155768558382988, 0.3451293110847473, 0.5458671450614929, -0.4942045509815216, -0.23818247020244598, 0.03287092223763466, -0.29617786407470703, -0.49572715163230896, 0.3786991834640503, -0.8698362708091736, -0.411736398935318, 0.18020682036876678, -0.3287855386734009, -0.35215112566947937, 0.6762307286262512, 0.05276057869195938, -1.4301828145980835, -0.7270101308822632, 0.32790958881378174, -0.9186012148857117, 0.40207409858703613, -0.0893574208021164, 0.28389447927474976, -0.997454047203064, -0.4394626319408417, -0.061372485011816025, 0.5519553422927856, -0.3505365252494812, 1.0298939943313599, 0.25279396772384644, -0.994205892086029, -0.5245072245597839, -0.021573930978775024, 0.026917852461338043, -0.23782169818878174, 0.6471009850502014, 0.3912506699562073, -0.17585839331150055, 0.36186683177948, 0.4714006185531616, 0.14066091179847717, -0.7640592455863953, 0.07629740238189697, 0.4528975784778595, 0.04270901158452034, -0.25990885496139526, 0.9098951816558838, -0.10335564613342285, -1.0661934614181519, 0.22543743252754211, -0.5171599388122559, -0.6598870754241943, 0.0036554932594299316, 1.1600810289382935, 0.588067889213562, -0.4338572323322296, -0.17959241569042206, -0.6252074837684631, 0.28033819794654846, -0.12080227583646774, -0.4089869558811188, 1.0620002746582031, -0.5111814737319946, -0.7112297415733337, 0.9982068538665771, 1.0678867101669312, -0.6750472784042358, -0.6985614895820618, -0.5117105841636658, -0.649549126625061, -0.08788453787565231, 0.37435951828956604, -0.507073700428009, -0.1679082065820694, 0.9013011455535889, 0.2476864457130432, 0.3629293739795685, 0.10765599459409714, -0.07766694575548172, 0.10834062099456787, 0.3068639934062958, -0.047553740441799164, -0.7398086786270142, -0.4376024901866913, 1.3096835613250732, 1.4332709312438965, -1.0863858461380005, -0.04152180254459381, -0.08083241432905197, -0.942653477191925, 0.9428912401199341, -0.004717612639069557, -0.08831100910902023, 0.553634524345398, -0.24375230073928833, 0.3886229991912842, 0.4571759104728699, -1.3329919576644897, -0.06771498173475266, 0.26157402992248535, 0.9018895626068115, 0.8561084866523743, 0.0772341787815094, -0.40700581669807434, 0.8749547004699707, 0.6066111326217651, 0.21360953152179718, 1.2353174686431885, 0.047396861016750336, -0.12415562570095062, 0.14585977792739868, 0.2685149908065796, 0.316127210855484, -0.7525691390037537, -0.7203852534294128, 0.18083567917346954, 0.04633583873510361, -0.014168959110975266, 0.8903169631958008, 0.9817792177200317, 0.49704480171203613, 0.2045639455318451, -0.09602347016334534, 0.3575667142868042, -0.47546669840812683, -0.01831202395260334, 0.11365506052970886, -0.6440137624740601, -0.3855941891670227, -0.17005567252635956, -0.8164547681808472, -0.4688844382762909, -0.4571692645549774, 0.48225927352905273, -0.15293048322200775, -0.007494733668863773, 1.668774962425232, 0.37369829416275024, 0.35848966240882874, -0.0933326929807663, -0.404854953289032, -0.6838382482528687, -1.0293571949005127, -0.23913031816482544, -0.43874281644821167, 0.020833538845181465, 0.12485195696353912, -0.006343888118863106, 0.005608708597719669]}, "authors": [{"authorId": "2805456", "name": "Saleh Soltan"}, {"authorId": "2773408", "name": "Shankar Ananthakrishnan"}, {"authorId": "120590817", "name": "Jack G. M. FitzGerald"}, {"authorId": "145542597", "name": "Rahul Gupta"}, {"authorId": "1836135", "name": "Wael Hamza"}, {"authorId": "144165565", "name": "Haidar Khan"}, {"authorId": "102648923", "name": "Charith Peris"}, {"authorId": "38696444", "name": "Stephen Rawls"}, {"authorId": "146177177", "name": "Andrew Rosenbaum"}, {"authorId": "1681193", "name": "Anna Rumshisky"}, {"authorId": "1588348842", "name": "Chandan Prakash"}, {"authorId": "1734869335", "name": "Mukund Sridhar"}, {"authorId": "1761263", "name": "Fabian Triefenbach"}, {"authorId": "3363380", "name": "Apurv Verma"}, {"authorId": "5108268", "name": "Gokhan Tur"}, {"authorId": "2104644641", "name": "Premkumar Natarajan"}], "references": [{"paperId": "f2c17758e74707d379b87372528221656d14b697", "title": "Taxonomy of Risks posed by Language Models"}, {"paperId": "daa3af99c6421a60e4dc06cb27fc97a60a1aa54b", "title": "Alexa Teacher Model: Pretraining and Distilling Multi-Billion-Parameter Encoders for Natural Language Understanding Systems"}, {"paperId": "2811559b89a32fdf9facf24f4847f1d37393d158", "title": "Differentially Private Decoding in Large Language Models"}, {"paperId": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large Language Models are Zero-Shot Reasoners"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "15190e8b459bd85d546286f7d7da61b4f4f3f58a", "title": "What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "3c759e2f16bfde8d31189631e4893d3ac8ff05f2", "title": "Mitigating Gender Bias in Distilled Language Models via Counterfactual Role Reversal"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "28c7e583d90ccfc5c3078dfc1d6b80a9ad90248d", "title": "Quantifying Memorization Across Neural Language Models"}, {"paperId": "55c36748f2a7c060c3313349c730b053ed03fbf7", "title": "Deduplicating Training Data Mitigates Privacy Risks in Language Models"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "80d0116d77beeded0c23cf48946d9d10d4faee14", "title": "GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "d64e57b9780f30f5b49bf620fdfb8584651b7f85", "title": "Challenges in Detoxifying Language Models"}, {"paperId": "cddf40e579a596d0110b260313adf43470617c4c", "title": "Datasets: A Community Library for Natural Language Processing"}, {"paperId": "4566c0d22ebf3c31180066ab23b6c445aeec78d5", "title": "Deduplicating Training Data Makes Language Models Better"}, {"paperId": "2ef4ab54d00203f9ac610213ac3abc8e1fe541b4", "title": "Anticipating Safety Issues in E2E Conversational AI: Framework and Tooling"}, {"paperId": "114aa720872462b0ca1b97bfdec0ebd56c36fd0a", "title": "Towards Understanding and Mitigating Social Biases in Language Models"}, {"paperId": "64902a5077ee68011cd467398dbb66511e8e891a", "title": "It\u2019s All in the Heads: Using Attention Heads as a Baseline for Cross-Lingual Transfer in Commonsense Reasoning"}, {"paperId": "789b8487da7188442085983caba3ffaae05531e9", "title": "The Flores-101 Evaluation Benchmark for Low-Resource and Multilingual Machine Translation"}, {"paperId": "76a786b1acd6d1aca56e12a8a1db34569fdf9f3a", "title": "Societal Biases in Language Generation: Progress and Challenges"}, {"paperId": "7a16d9b4e04300d034502dc7dd58428714594e2c", "title": "Carbon Emissions and Large Neural Network Training"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "ce9ca56036307217ea565644d3d3bd74b879e045", "title": "Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP"}, {"paperId": "824cd8db8a68732db04f4d8b7139eb4475e59ff2", "title": "The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"}, {"paperId": "ce3b364b7e6358940ce97d8d5887a65e5024ca21", "title": "BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation"}, {"paperId": "74a501e5d6fe5c727ff76218c4569055364e343e", "title": "Adversary Instantiation: Lower Bounds for Differentially Private Machine Learning"}, {"paperId": "74276a37bfa50f90dfae37f767b2b67784bd402a", "title": "mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer"}, {"paperId": "687b13c44f849d23c2496996b5da83e706094db9", "title": "Beyond English-Centric Multilingual Machine Translation"}, {"paperId": "399e7d8129c60818ee208f236c8dda17e876d21f", "title": "RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models"}, {"paperId": "725264948d7b6946259af5b8d966e996b9570f99", "title": "DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters"}, {"paperId": "ea8c46e193d5121e440daf96edfd15a47151c293", "title": "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering"}, {"paperId": "eec423dd048f942d654d78c1a13dde7ff0d9516e", "title": "Auditing Differentially Private Machine Learning: How Private is Private SGD?"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "d47a682723f710395454687319bb55635e653105", "title": "Language (Technology) is Power: A Critical Survey of \u201cBias\u201d in NLP"}, {"paperId": "d97e7561fa7710213ccd4f8128044ea6849be377", "title": "XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning"}, {"paperId": "24e4d3370dc366d6b353d1d6818a0df266bb31b9", "title": "MLSUM: The Multilingual Summarization Corpus"}, {"paperId": "9b539d413393047b28bb7be9b195f142aaf7a80e", "title": "Recipes for Building an Open-Domain Chatbot"}, {"paperId": "f64e1d6bc13aae99aab5449fc9ae742a9ba7761e", "title": "UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a", "title": "On Layer Normalization in the Transformer Architecture"}, {"paperId": "495da6f19baa09c6db3697d839e10432cdc25934", "title": "Multilingual Denoising Pre-training for Neural Machine Translation"}, {"paperId": "22d3dfd27bfd4ec00ab6d9744cec851982e9b89a", "title": "Queens Are Powerful Too: Mitigating Gender Bias in Dialogue Generation"}, {"paperId": "2aef70dc36ce8c2aba1cc5e823e20a59db3f7326", "title": "Microsoft Research Asia\u2019s Systems for WMT19"}, {"paperId": "6fec3e579c7cd4f13bdabbee2b6ac2e8ff5941c6", "title": "Unsupervised Cross-lingual Representation Learning at Scale"}, {"paperId": "9e1241f017a627beca2542e378a88c642c32098b", "title": "Semantic Noise Matters for Neural Natural Language Generation"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "5334e1857e910e2c7855c909c9495fb0ea28efbb", "title": "Does Gender Matter? Towards Fairness in Dialogue Systems"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "e04a80263d252a3d8a382ba37a249b9345620570", "title": "Plug and Play Language Models: A Simple Approach to Controlled Text Generation"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "5019dbe8d1da5f128f4f373d6849095cf18fd519", "title": "The Woman Worked as a Babysitter: On Biases in Language Generation"}, {"paperId": "0e9b89f034b9a8c2828fe7daaee3894d6bfe3e50", "title": "On Measuring and Mitigating Biased Inferences of Word Embeddings"}, {"paperId": "b91c4edd30b63cd1cb1b86cbeefb33a461535e09", "title": "Build it Break it Fix it for Dialogue Safety: Robustness from Adversarial Human Attack"}, {"paperId": "04a7021fe6be6bddcfae476493fcc7571e7c613c", "title": "PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification"}, {"paperId": "3259d52ae00e65b98391e7e6a2f672dfee721bf8", "title": "Quantifying Social Biases in Contextual Word Representations"}, {"paperId": "1c71771c701aadfd72c5866170a9f5d71464bb88", "title": "Unified Language Model Pre-training for Natural Language Understanding and Generation"}, {"paperId": "145b8b5d99a2beba6029418ca043585b90138d12", "title": "MASS: Masked Sequence to Sequence Pre-training for Language Generation"}, {"paperId": "d9f6ada77448664b71128bb19df15765336974a6", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"}, {"paperId": "8f8542a6aa8c76e8a4441d1ca722e230aa5d6c9e", "title": "Evaluating Differentially Private Machine Learning in Practice"}, {"paperId": "1c3112ef8a346b9817382ed34a8c146c53d5bcf5", "title": "XNLI: Evaluating Cross-lingual Sentence Representations"}, {"paperId": "305b2cf37e5dece81e95c92883d5a6e28ac93b22", "title": "Don\u2019t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "4d1c856275744c0284312a3a50efb6ca9dc4cd4c", "title": "Know What You Don\u2019t Know: Unanswerable Questions for SQuAD"}, {"paperId": "9967cb4fd949039c6f04dd9f2f4c3331dbebe6f7", "title": "Gender Bias in Coreference Resolution"}, {"paperId": "531a7f2c659787165df4fd5b4580590b953448e4", "title": "The E2E Dataset: New Challenges For End-to-End Generation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "4c6fe6179c408e1fbb3871af13d1a8e64f766e54", "title": "Solving General Arithmetic Word Problems"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "f40aeae3e522ada1f6a9f326841b01ef5c8657b6", "title": "Unifying Language Learning Paradigms"}, {"paperId": "1403e6b9adf7712c35ae56327d52fe54603b87e1", "title": "Few-shot Learning with Multilingual Language Models"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "f83618f13fce0e71e9127784f6ecc261dbdbf089", "title": "Structure-to-Text Generation with Self-Training, Acceptability Classifiers and Context-Conditioning for the GEM Shared Task"}, {"paperId": null, "title": "Building an aws ec2 carbon emissions datase"}, {"paperId": "310b8117ae5ce3df8aa6304ad382525b9b46937e", "title": "The 2020 Bilingual, Bi-Directional WebNLG+ Shared Task: Overview and Evaluation Results (WebNLG+ 2020)"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "b8e19d9154f49e951d30d8673585aa654b559cfc", "title": "Using NLG for speech synthesis of mathematical sentences"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing"}, {"paperId": null, "title": "Table A2: Prompts used for AlexaTM 20B 1-shot evaluation on di\ufb00erent generation tasks"}, {"paperId": null, "title": "is a former sailor of the United States Navy, who served as the eleventh Master Chief Petty Officer of the U.S. Navy, right? {Yes"}, {"paperId": null, "title": "St-moe"}, {"paperId": null, "title": "Yandex publishes yalm 100b. it\u2019s the largest gpt-like neural network in open source"}, {"paperId": "13167f9cd8c7906ca808b01d28dca6dd951da8a5", "title": "of the Association for Computational Linguistics"}, {"paperId": null, "title": "Making deepspeed zero run e\ufb03ciently on more-a\ufb00ordable hardware"}]}