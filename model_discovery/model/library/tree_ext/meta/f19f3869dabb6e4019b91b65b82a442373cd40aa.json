{"paperId": "f19f3869dabb6e4019b91b65b82a442373cd40aa", "title": "Various Lengths, Constant Speed: Efficient Language Modeling with Lightning Attention", "abstract": "We present Lightning Attention, the first linear attention implementation that maintains a constant training speed for various sequence lengths under fixed memory consumption. Due to the issue with cumulative summation operations (cumsum), previous linear attention implementations cannot achieve their theoretical advantage in a casual setting. However, this issue can be effectively solved by utilizing different attention calculation strategies to compute the different parts of attention. Specifically, we split the attention calculation into intra-blocks and inter-blocks and use conventional attention computation for intra-blocks and linear attention kernel tricks for inter-blocks. This eliminates the need for cumsum in the linear attention calculation. Furthermore, a tiling technique is adopted through both forward and backward procedures to take full advantage of the GPU hardware. To enhance accuracy while preserving efficacy, we introduce TransNormerLLM (TNL), a new architecture that is tailored to our lightning attention. We conduct rigorous testing on standard and self-collected datasets with varying model sizes and sequence lengths. TNL is notably more efficient than other language models. In addition, benchmark results indicate that TNL performs on par with state-of-the-art LLMs utilizing conventional transformer structures. The source code is released at github.com/OpenNLPLab/TransnormerLLM.", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Lightning Attention is presented, the first linear attention implementation that maintains a constant training speed for various sequence lengths under fixed memory consumption and TransNormerLLM (TNL) is introduced, a new architecture that is tailored to the authors' lightning attention."}, "embedding": {"model": "specter_v2", "vector": [0.4270351827144623, 0.2874368131160736, -0.28030040860176086, -0.17359799146652222, -0.2615821659564972, -0.0957624539732933, 0.6440362930297852, -0.22156578302383423, -0.5723158121109009, -0.35133203864097595, 0.42137569189071655, -0.10602228343486786, 0.6863977313041687, 0.12866801023483276, -0.2435675412416458, 0.11543191969394684, -0.807256817817688, 0.21257100999355316, -0.27680134773254395, -0.26692667603492737, 0.09077752381563187, -0.5619044303894043, -1.2306820154190063, 0.11148522049188614, 0.3568236529827118, 0.4557015001773834, 0.6062273383140564, 0.9943491220474243, -0.4451318085193634, 0.5799216628074646, 0.39160653948783875, -0.24025946855545044, -0.021540088579058647, 0.03840067982673645, -0.3528967797756195, -0.270681232213974, 0.6667492985725403, -0.06927207112312317, -0.40910860896110535, 0.677150309085846, -0.2058628350496292, 0.4084686040878296, 0.4486692547798157, -0.43832913041114807, -0.44365397095680237, 0.6975131034851074, 0.23054420948028564, 0.7323505878448486, -0.2994260787963867, -0.44261083006858826, 1.2502877712249756, -1.6037020683288574, 0.018875962123274803, 1.345314860343933, 0.5961695313453674, 0.37114840745925903, 0.15187132358551025, -0.7184455990791321, 0.9693264961242676, 0.04765715077519417, -0.852618932723999, -0.28948360681533813, -0.19026124477386475, -0.0747976079583168, 2.0946106910705566, -0.22306618094444275, 0.18344387412071228, 0.6034753918647766, 0.1221158429980278, 1.537672519683838, -0.2588948905467987, -1.027591586112976, -0.5509047508239746, -0.20657658576965332, 0.7555464506149292, 0.5711591839790344, -0.5339983105659485, 0.13386240601539612, -0.6851648092269897, 0.055128395557403564, 0.33357590436935425, -0.05693281069397926, 0.15135182440280914, 0.2990216314792633, -0.2456471025943756, 0.7382913827896118, 0.3285718262195587, 0.9379807710647583, -0.1473488211631775, 0.6649816632270813, 0.563869059085846, 0.0011053008493036032, 0.11313994228839874, 0.0673966258764267, 0.18054193258285522, 0.4508143961429596, -1.077009677886963, 0.2501823604106903, -0.25623244047164917, 1.443666696548462, -0.3767881989479065, 0.5472198128700256, -0.9004654288291931, 0.06225384399294853, 0.913536012172699, 0.282683789730072, 0.32291179895401, -0.4909909665584564, 0.18816016614437103, -0.7411884069442749, -0.18072815239429474, -0.6535237431526184, -0.15484356880187988, -0.6097463369369507, -0.8217064738273621, -1.1891907453536987, -0.49808594584465027, 0.3409312963485718, -0.8141453862190247, 0.7378434538841248, -0.4995957612991333, -0.11153240501880646, -0.2129841446876526, 0.04335560277104378, 0.6670944094657898, 0.6484062671661377, 0.6604064106941223, 0.027504928410053253, 1.0744439363479614, -1.0878463983535767, -0.6815146207809448, -1.3367120027542114, 0.7311617136001587, -0.5758296251296997, 0.5681095123291016, -0.2592255473136902, -1.240134596824646, -1.1842632293701172, -0.6340720653533936, -0.37033596634864807, -0.4344089925289154, 0.4996607303619385, 1.0094503164291382, 0.18906579911708832, -0.998950183391571, 0.37016281485557556, -0.07925266027450562, -0.13657884299755096, 0.33475950360298157, -0.21518360078334808, 0.5698663592338562, -0.5597714781761169, -1.477314829826355, 0.448655903339386, 0.1277504414319992, -0.5613530278205872, -0.17060527205467224, -0.6008065342903137, -1.2448837757110596, -0.07876831293106079, -0.012693888507783413, -0.05859069526195526, 1.3190218210220337, -0.48705825209617615, -0.5993902087211609, 0.8280059695243835, -0.7211078405380249, 0.11876662820577621, -0.06314888596534729, -0.4629073739051819, -0.4050293564796448, -0.8678494691848755, -0.16774119436740875, 0.6640851497650146, 0.5009217858314514, 0.13924938440322876, -0.19638074934482574, 0.35353463888168335, -0.3582809865474701, -0.020443158224225044, -0.4383893609046936, 1.1794458627700806, -0.6224324703216553, -0.4214131832122803, -0.08794704079627991, 0.37966588139533997, 0.12598185241222382, -0.49614351987838745, -0.1115746796131134, -1.0196243524551392, 0.8279963731765747, -0.24719566106796265, 1.4372206926345825, -0.7648872137069702, -0.835739254951477, -0.46170008182525635, -0.2663576304912567, -0.005566628184169531, -0.7060947418212891, 0.6282994151115417, -0.4778585731983185, 0.1056925505399704, 0.011370602995157242, -1.2414997816085815, -0.0952351912856102, -0.25453826785087585, -0.5891187787055969, -0.33371275663375854, -0.18619473278522491, 1.2624473571777344, -0.9217501282691956, -0.19132685661315918, -0.16943895816802979, 0.4980611503124237, -0.7817487120628357, 1.2049864530563354, -0.40941351652145386, 0.03207799792289734, 0.10760287195444107, -0.2278449535369873, -0.06063266098499298, -0.5182421803474426, 0.32437974214553833, -0.4352390170097351, -0.42183947563171387, 0.29338979721069336, 0.20961831510066986, 1.2759144306182861, -0.6221546530723572, 0.7299696207046509, -0.3284921646118164, -0.4391191601753235, 0.07428643852472305, 0.2942720651626587, -0.49052876234054565, -0.5782663822174072, 0.42797788977622986, 0.21434517204761505, -0.6359646320343018, 0.20434178411960602, 0.9194067716598511, 1.0778769254684448, -0.4573238492012024, 0.260830283164978, 0.49405741691589355, 0.13597361743450165, 0.41507819294929504, 0.4659862220287323, 0.422419935464859, 0.3435939848423004, 0.5159866213798523, -0.2688722312450409, 0.377948522567749, -0.7819460034370422, -0.4694203734397888, 0.713746964931488, 0.87736576795578, 0.7839071154594421, 0.14882542192935944, -0.9235520958900452, -0.6153958439826965, 0.364973783493042, 0.7765195369720459, 1.7698979377746582, -0.4000585675239563, 0.024215156212449074, -0.7594377398490906, 0.027681272476911545, -0.5431303977966309, 0.3634718358516693, -0.4199135899543762, -0.0279981829226017, -0.8154972791671753, -0.9000610113143921, 0.7441738843917847, 0.4008103907108307, 0.8038445711135864, -0.9115142226219177, -0.6174061894416809, -0.29015862941741943, 0.044178497046232224, -1.000870943069458, -1.0542521476745605, 0.33227649331092834, -0.2966492474079132, 0.1629679799079895, -0.03548400104045868, -0.27521437406539917, 0.2510879337787628, -0.3416515290737152, 1.206560730934143, -0.4364308714866638, -0.5807333588600159, 0.21455463767051697, 0.4732747972011566, -0.7363160252571106, -0.6003872156143188, 0.43221166729927063, 0.09467708319425583, -0.16398507356643677, 0.4453331232070923, 0.6406118273735046, 0.04085320979356766, -0.3406345248222351, -0.3707478642463684, 0.3351778984069824, 0.1406438648700714, -0.3150853216648102, 0.5153636932373047, -0.5820549726486206, -0.10566242784261703, -1.0539759397506714, 0.9088365435600281, 0.22603687644004822, -0.31746646761894226, 0.4179406464099884, -0.3751719892024994, -0.5289075970649719, 0.44740545749664307, -0.7803134918212891, -0.2698054611682892, -0.8562621474266052, 0.288128525018692, -0.39325398206710815, -0.04238180071115494, 0.0676259770989418, 0.27780771255493164, 0.04312315583229065, 0.061936069279909134, 0.7395915985107422, 0.13166460394859314, 0.0010393861448392272, 0.45747944712638855, -0.8424401879310608, 0.4369252324104309, 0.32375138998031616, -0.06713566184043884, -0.24729900062084198, -0.4447377920150757, -1.0263440608978271, -0.8638626933097839, -0.33081650733947754, -0.20632871985435486, -0.4835222065448761, 0.2806140184402466, -0.5188818573951721, -0.8858780264854431, 0.16069617867469788, -1.4733655452728271, 0.055896759033203125, 0.5193064212799072, -0.32103949785232544, 0.030467286705970764, -1.0540454387664795, -1.1209529638290405, -0.7775682806968689, -1.0030475854873657, -0.8124384880065918, 0.4630383551120758, 0.04028739780187607, -0.6372860670089722, -0.6790149211883545, -0.13940444588661194, -0.4883667826652527, 1.323479175567627, -0.5182629823684692, 0.8473966717720032, 0.047589465975761414, -0.2721460163593292, -0.338959276676178, 0.23121502995491028, 0.39168301224708557, -0.058744411915540695, 0.2347039431333542, -0.934592068195343, -0.04360096529126167, -0.10955942422151566, -0.26890531182289124, 0.06461883336305618, 0.4985000491142273, 1.0711266994476318, -0.2571505904197693, -0.565862238407135, 0.1226930096745491, 1.2474050521850586, -0.4184715747833252, 0.11676070094108582, 0.06679020822048187, 1.1024500131607056, 0.17363032698631287, -0.21752721071243286, 0.6602182388305664, 0.4296130836009979, 0.4746224284172058, 0.12065625935792923, -0.2692992389202118, -0.013369827531278133, -0.3133945167064667, 0.5970230102539062, 1.9011330604553223, 0.1945829838514328, -0.1199188083410263, -1.0765504837036133, 0.590410590171814, -0.8556889891624451, -1.038069486618042, 0.6631274819374084, 0.7766180634498596, 0.514738917350769, -0.4709591567516327, -0.39640548825263977, -0.31872323155403137, 0.5882976055145264, 0.6271002292633057, -0.24405956268310547, -1.036197304725647, -0.08720520883798599, 0.3789825439453125, 0.00015212097787298262, 0.8659915924072266, -0.5624564290046692, 0.6107357740402222, 14.780776977539062, 0.9745492339134216, -0.27995622158050537, 0.6162706613540649, 0.8880314230918884, 0.005721962079405785, -0.31273123621940613, -0.46512269973754883, -1.6385469436645508, -0.07799246907234192, 1.0263148546218872, -0.06314675509929657, 0.5900051593780518, 0.16530321538448334, 0.06182629242539406, 0.42846837639808655, -0.3538185954093933, 0.7983850240707397, 1.007907748222351, -1.1687685251235962, 0.6026062965393066, -0.20082375407218933, 0.31826967000961304, 0.3554835617542267, 0.8196884393692017, 0.8510258197784424, 0.3286558985710144, -0.6411808133125305, 0.4409125745296478, 0.4528332054615021, 0.845527172088623, -0.3612523078918457, 0.33798569440841675, 0.6318424344062805, -1.2176966667175293, 0.12620660662651062, -0.43230366706848145, -1.3628607988357544, 0.2069515436887741, 0.18070894479751587, -0.30311715602874756, -0.5138248205184937, -0.266585111618042, 0.6960494518280029, 0.020249702036380768, 0.23646123707294464, -0.021092582494020462, 0.5790905356407166, 0.1594448983669281, -0.1743645966053009, 0.7251384258270264, 0.6335800886154175, 0.05073564872145653, 0.4736676812171936, 0.13816820085048676, 0.06971432268619537, 0.10562849789857864, 0.4413100779056549, -0.4268338680267334, 0.03325686976313591, -0.3505018949508667, -0.30944204330444336, 0.05470633879303932, 0.8626854419708252, 0.4504614770412445, 0.33037179708480835, -0.4047938585281372, 0.19199807941913605, 0.7982274889945984, 0.20655110478401184, -0.7399044632911682, 0.020421268418431282, 0.31959816813468933, -0.44235163927078247, 0.04423399642109871, 0.28210753202438354, -0.1895047426223755, -0.36497482657432556, -0.7485121488571167, -0.6189963817596436, 0.08394551277160645, -0.7702199220657349, -0.6142487525939941, 1.0746456384658813, -0.26359766721725464, -0.21403706073760986, 0.37327566742897034, -0.5617730021476746, -0.4448894262313843, 0.7104284763336182, -1.107187032699585, -0.9384225606918335, 0.07579584419727325, -0.596542477607727, -0.05311867222189903, 0.1179497241973877, 1.1706881523132324, 0.3563005030155182, -0.18959097564220428, 0.2997499704360962, -0.11154890060424805, -0.0889965295791626, -0.5217829346656799, -0.3539225161075592, 1.1528834104537964, 0.2399188131093979, -0.27043071389198303, 0.3900308907032013, 0.20677989721298218, 0.21069809794425964, -0.7006059885025024, -0.4023013710975647, 1.299275517463684, -0.7249142527580261, -0.5310924649238586, -1.0465744733810425, -1.019864797592163, 0.5121790170669556, 0.6933647394180298, -0.45396190881729126, 0.24482785165309906, 0.25927093625068665, -0.608045220375061, 0.06507080793380737, -0.18508997559547424, 0.11411207914352417, 0.41767266392707825, -0.8080623149871826, -0.1293732225894928, -0.0464235283434391, 0.5924457907676697, -1.0586901903152466, -0.17221428453922272, -0.286431223154068, 0.380252480506897, 0.13617490231990814, 0.9371737837791443, -0.46084097027778625, 0.7214189767837524, 1.0669429302215576, -0.035447001457214355, -0.48961716890335083, -0.24184004962444305, -0.5789520740509033, 0.09430848807096481, 0.19271042943000793, 0.6098043322563171, -0.0564374215900898, 0.032423846423625946, 0.5436586141586304, 0.28963708877563477, -0.7679066061973572, -0.43582189083099365, -0.36038580536842346, 0.2064269483089447, -0.7596745491027832, 0.1417553424835205, -0.043262649327516556, -0.1908680945634842, 0.17929673194885254, 0.0429934561252594, 0.27703556418418884, 0.04801619425415993, -0.5401042699813843, 0.06853365153074265, 0.015970293432474136, 0.1019773855805397, -0.6329808235168457, -0.25797632336616516, -1.328956127166748, 0.16994990408420563, -1.068908452987671, -0.12498719990253448, -0.7711380124092102, -0.09320946037769318, 0.0607755184173584, 0.15362301468849182, 0.27726101875305176, 0.17034587264060974, -0.436048686504364, -0.44311729073524475, -0.6860026717185974, -0.6374073028564453, 0.8732736110687256, 0.8805751204490662, -0.6095464825630188, 0.4467628598213196, -0.021348988637328148, 0.377861350774765, 0.28315556049346924, 0.4146568179130554, -0.3552849292755127, -0.7682745456695557, -1.4698371887207031, 0.48684778809547424, -0.3291664123535156, -0.15380126237869263, -0.7785298228263855, 0.7363541722297668, 0.45205214619636536, -0.19577696919441223, -0.236845001578331, 0.22300942242145538, -0.5449115037918091, -0.5512236952781677, 0.378109335899353, -0.8573085069656372, 0.6075854897499084, 0.5779263377189636, -0.9300118088722229, -0.17296196520328522, 0.5969019532203674, 0.12029857933521271, -1.1143617630004883, -0.7283110022544861, 0.6349233388900757, -0.6574422717094421, 0.47937098145484924, -0.18066751956939697, -0.08825478702783585, -1.005454659461975, -0.6556836366653442, 0.09804511815309525, 0.19223348796367645, -0.46459946036338806, 1.2929532527923584, 0.5315708518028259, -1.1711196899414062, -0.0024943675380200148, 0.4646747410297394, -0.1917867809534073, -0.25774773955345154, 0.6049658060073853, 0.33720457553863525, -0.19272743165493011, 0.8786396384239197, 0.29275959730148315, 0.1658383309841156, -1.4621437788009644, 0.15345966815948486, 0.7839211821556091, -0.5145188570022583, -0.022259680554270744, 1.2128220796585083, -0.006838563829660416, -1.06671142578125, 0.27571019530296326, -1.0495589971542358, -0.7249336838722229, -0.2184324860572815, 0.8543431162834167, 0.02991499751806259, 0.04224817827343941, -0.18001927435398102, -0.5718744397163391, 0.3898695409297943, -0.23589301109313965, -0.22147123515605927, 0.24055568873882294, -0.1115105077624321, -0.3695273995399475, 0.7930221557617188, 0.9576881527900696, -0.7336570024490356, -0.44518277049064636, -0.5673582553863525, -0.40232452750205994, 0.25542977452278137, 0.1648026555776596, -0.1549515277147293, -0.6558446288108826, 0.9550151824951172, 0.1710854023694992, 0.17053471505641937, 0.09668079763650894, -0.3257119655609131, 0.22165265679359436, 0.45162367820739746, 0.24444013833999634, -0.5282524228096008, -0.7045514583587646, 1.9699238538742065, 1.3683643341064453, -0.6947629451751709, 0.15144510567188263, -0.012921454384922981, -0.821264386177063, 0.7371153235435486, 0.38985562324523926, 0.059196487069129944, 0.6874890327453613, 0.08668338507413864, -0.0665973573923111, 0.28196802735328674, -1.0933672189712524, -0.021707214415073395, 0.7799654603004456, 0.6337338089942932, 1.3355878591537476, 0.261304646730423, -0.11712788790464401, 0.47811752557754517, 0.11107374727725983, 0.12117637693881989, 0.15891265869140625, 0.5601515173912048, -0.33268457651138306, 0.1302517205476761, 0.05071638152003288, 0.5957694053649902, -0.662969708442688, -1.1056057214736938, 0.45471206307411194, 0.5420403480529785, 0.13627095520496368, 0.2049110382795334, 0.955701470375061, 0.3015555441379547, 0.4374091327190399, 0.3006768226623535, 0.5836988091468811, -0.4301726818084717, -0.412462443113327, -0.4515068829059601, -0.8805627822875977, 0.01938515529036522, -0.06637301295995712, -0.6087188124656677, -0.2356892228126526, -0.36057496070861816, 0.48892834782600403, -0.15031512081623077, 0.08081823587417603, 1.1732279062271118, 0.5456215143203735, 0.6373468041419983, -0.520511269569397, -0.7034661769866943, -0.06510816514492035, -0.9999686479568481, 0.19169262051582336, -0.6973772048950195, -0.209564670920372, -0.05285938084125519, -0.13377200067043304, -0.21783140301704407]}, "authors": [{"authorId": "2171650015", "name": "Zhen Qin"}, {"authorId": "2225238340", "name": "Weigao Sun"}, {"authorId": "2179703418", "name": "Dong Li"}, {"authorId": "2116517206", "name": "Xuyang Shen"}, {"authorId": "8397429", "name": "Weixuan Sun"}, {"authorId": "2266275708", "name": "Yiran Zhong"}], "references": [{"paperId": "434d751d355d7a7c20efa570e785c76286245e77", "title": "Hierarchically Gated Recurrent Neural Network for Sequence Modeling"}, {"paperId": "c96297261467b5daa2d01227496a70d444602434", "title": "Baichuan 2: Open Large-scale Language Models"}, {"paperId": "2f0203386f3dcbffb47c9f7fe2d19d373d9dda2f", "title": "Exploring Transformer Extrapolation"}, {"paperId": "8bc8b9ae855bc0aa19e7223899440ffbdc61f4d8", "title": "Linearized Relative Positional Encoding"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "f35f5aedc30e2c5ded210d9c91ba6e84bd029425", "title": "Toeplitz Neural Network for Sequence Modeling"}, {"paperId": "a0e7c31d723608e03f30fc92ffc2a604a7a039da", "title": "PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel"}, {"paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8", "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"}, {"paperId": "f393aff1593c2d370ec0ae004910d18e40524967", "title": "Resurrecting Recurrent Neural Networks for Long Sequences"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "54155c2977a977bf129849455dcae3a2b79b3f41", "title": "Simple Hardware-Efficient Long Convolutions for Sequence Modeling"}, {"paperId": "ac608a4a6b19b3208e560eee5daadb3cc18638a2", "title": "Efficient Attention via Control Variates"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "62ce88d4e484b5b1f0abbe517807de0a652cd63d", "title": "HIPPO"}, {"paperId": "e3fc46d5f4aae2c7a8a86b6bd21ca8db5d40fcbd", "title": "The Devil in Linear Transformer"}, {"paperId": "1d26c947406173145a4665dd7ab255e03494ea28", "title": "GLM-130B: An Open Bilingual Pre-trained Model"}, {"paperId": "86c8d930b492a4f9cadc6c60aecdaaded49acc86", "title": "Neural Architecture Search on Efficient Transformers and Beyond"}, {"paperId": "eaef083b9d661f42cc0d89d9d8156218f33a91d9", "title": "Long Range Language Modeling via Gated State Spaces"}, {"paperId": "ca444821352a4bd91884413d8070446e2960715a", "title": "On the Parameterization and Initialization of Diagonal State Space Models"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "1944cebf4e41a10ea7bd02ce30404c18c9c4e04f", "title": "Linear Complexity Randomized Self-attention Mechanism"}, {"paperId": "dc0102a51a9d33e104a4a3808a18cf17f057228c", "title": "Transformer Quality in Linear Time"}, {"paperId": "6281c40c66febca1d8003bcc6fdfd2189b30c38f", "title": "SCROLLS: Standardized CompaRison Over Long Language Sequences"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de", "title": "Pay Attention to MLPs"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "661d142c23cb2a3207d5f1ba2ac7ff61f2d4fb2f", "title": "Triton: an intermediate language and compiler for tiled neural network computations"}, {"paperId": "e65c84e2778d7b13b7541e6b14ff790b624a24ec", "title": "A Study of BFLOAT16 for Deep Learning Training"}, {"paperId": "9770fff7379a7ab9006b48939462354dda9a2053", "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "1536e8958697c5364f68b2e2448905dbbeb3a0ca", "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering"}, {"paperId": "88bb0a28bb58d847183ec505dda89b63771bb495", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"}, {"paperId": "e7fd6848cb29ca221a7e17d823e06fb566f1f135", "title": "Mixed Precision Training"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "53839f5d018e063f1c2b6b1bd391352702ca34c1", "title": "A Cheap Linear Attention Mechanism with Fast Lookups and Fixed-Size Representations"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": null, "title": "A framework for few-shot language model evaluation"}, {"paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28", "title": "An Adversarial Winograd Schema Challenge at Scale"}, {"paperId": null, "title": "Commonsense reasoning about social interactions"}, {"paperId": "c8c4ab59ac29973a00df4e5c8df3773a3c59995a", "title": "Searching for Activation Functions"}, {"paperId": null, "title": "TNL with Lightning Attention"}, {"paperId": null, "title": "Falcon-40b: an open large language model with state-of-the-art performance"}, {"paperId": null, "title": "cosformer: Rethink-ing softmax in attention"}, {"paperId": null, "title": "Introducing mpt-7b: A new standard for open-source,"}, {"paperId": null, "title": "Openllama: An open reproduction of llama"}, {"paperId": null, "title": "A multi-level multi-discipline"}, {"paperId": null, "title": "General language model pretraining with autoregressive blank"}]}