{"paperId": "68adb03744692247fb834406798894db9fe77010", "title": "A Survey on Long Text Modeling with Transformers", "abstract": "Modeling long texts has been an essential technique in the field of natural language processing (NLP). With the ever-growing number of long documents, it is important to develop effective modeling methods that can process and analyze such texts. However, long texts pose important research challenges for existing text models, with more complex semantics and special characteristics. In this paper, we provide an overview of the recent advances on long texts modeling based on Transformer models. Firstly, we introduce the formal definition of long text modeling. Then, as the core content, we discuss how to process long input to satisfy the length limitation and design improved Transformer architectures to effectively extend the maximum context length. Following this, we discuss how to adapt Transformer models to capture the special characteristics of long texts. Finally, we describe four typical applications involving long text modeling and conclude this paper with a discussion of future directions. Our survey intends to provide researchers with a synthesis and pointer to related work on long text modeling.", "venue": "arXiv.org", "year": 2023, "citationCount": 37, "influentialCitationCount": 3, "openAccessPdf": {"url": "http://arxiv.org/pdf/2302.14502", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "An overview of the recent advances on long texts modeling based on Transformer models is provided and four typical applications involving long text modeling are described."}, "embedding": {"model": "specter_v2", "vector": [0.1470751166343689, 0.4326994717121124, -0.4996415078639984, -0.1305510252714157, -0.3297680616378784, -0.6573600172996521, 0.9007689356803894, -0.0004594555066432804, -0.24670667946338654, 0.09682386368513107, 1.0693525075912476, -0.1864587664604187, 0.11395781487226486, -0.28271564841270447, -0.09831221401691437, -0.11604230105876923, -0.7434769868850708, 0.37793993949890137, -0.15871790051460266, -0.08312284201383591, -0.2597246766090393, -0.45738184452056885, -0.5097102522850037, 0.3595922887325287, 0.4120277166366577, -0.3561033010482788, 0.35729995369911194, 0.7520445585250854, -0.8358920216560364, 0.6456265449523926, 0.5169650316238403, -0.5455881357192993, 0.09261852502822876, 0.32362210750579834, -0.23392844200134277, -0.22800366580486298, 0.17792539298534393, -0.6771044731140137, -0.703904390335083, 0.7016568779945374, -0.5957874655723572, 0.05322805047035217, 0.21897085011005402, -0.7776256799697876, 0.09644873440265656, 1.7498769760131836, 0.5399680733680725, 0.6954491138458252, -0.08497997373342514, -1.0474014282226562, 1.750146508216858, -1.0860247611999512, 0.5380544066429138, 1.477664589881897, 0.5289732813835144, 0.2813647985458374, -0.3430377244949341, -0.6962202787399292, 0.5518104434013367, -0.023624878376722336, -1.0015968084335327, -0.4639902114868164, -0.07029472291469574, -0.19221670925617218, 1.9652292728424072, -0.15353384613990784, -0.07427120953798294, 0.42406338453292847, 0.3071056306362152, 1.3820257186889648, -0.4921306371688843, -1.1419132947921753, -0.8229604959487915, -0.3955974280834198, 0.4797338545322418, 0.44923657178878784, -0.46780139207839966, 0.18371576070785522, -0.5695045590400696, -0.33278316259384155, 0.30423858761787415, 0.25505897402763367, -0.35535022616386414, 0.3498584032058716, -0.6051974892616272, 0.6327500939369202, -0.3323806822299957, 1.1746463775634766, -0.08595675230026245, 0.28520074486732483, 0.44423428177833557, 0.5865288972854614, -0.048633307218551636, 0.17099979519844055, -0.19545653462409973, 0.3659787178039551, -1.1242862939834595, 0.5228953957557678, 0.033792801201343536, 1.0043435096740723, -0.5577899217605591, 0.11271907389163971, -0.9950034618377686, 0.399926096200943, 1.0384894609451294, 0.09787304699420929, 0.41107892990112305, -0.4960035979747772, 0.22290383279323578, -0.10185687243938446, 0.7575913071632385, -0.44463446736335754, -0.4419056177139282, -0.4198146164417267, -0.2513314187526703, -1.3275023698806763, 0.17792078852653503, -0.00012842187425121665, -0.3773021101951599, 0.6455579400062561, -0.5153533220291138, -0.1982163041830063, 0.45325207710266113, -0.22102923691272736, 0.16690883040428162, 0.878052830696106, 0.3604707419872284, -0.5182347297668457, 0.9821336269378662, -0.5742772221565247, -1.043399453163147, -0.8852353096008301, 0.9705649018287659, -0.3503897190093994, 0.3731496036052704, -0.49463433027267456, -1.0546501874923706, -0.4400743544101715, -0.7973418831825256, -0.06866830587387085, -0.5370424389839172, 0.2340991497039795, 0.6718215346336365, 0.2350984811782837, -0.7751074433326721, 0.665926992893219, -0.5062234401702881, -0.45181357860565186, -0.1941778063774109, -0.15346741676330566, 0.6266974210739136, -0.3111479878425598, -1.6077545881271362, 0.19625858962535858, -0.003469358664005995, -1.0764180421829224, -0.17205128073692322, -0.3723452687263489, -1.2418781518936157, 0.18387678265571594, 0.3862214684486389, 0.0048840963281691074, 1.3517627716064453, 0.15243741869926453, -0.7522387504577637, 0.4284273087978363, -0.5379306077957153, -1.9955021343776025e-05, 0.036003462970256805, -0.37738683819770813, -0.8183066248893738, -0.7319592237472534, 0.22332845628261566, -0.11761729419231415, -0.18209640681743622, -0.14288270473480225, -0.5179794430732727, -0.21790894865989685, 0.07551255822181702, -0.25725993514060974, -0.32682886719703674, 1.4138461351394653, -0.4113632142543793, -0.5068321228027344, 0.0775858536362648, 0.8903752565383911, -0.1749987006187439, -0.12180200219154358, -0.25244781374931335, -0.8297366499900818, 0.7004628777503967, -0.1438259780406952, 1.819192886352539, -0.659472644329071, -0.9959365725517273, -0.4559119939804077, -0.3458099961280823, -0.3086632192134857, -0.8115495443344116, 1.4171055555343628, -0.48403671383857727, 0.4406255781650543, 0.0433509461581707, -0.5664786696434021, 0.07606013864278793, 0.1350633203983307, -1.2058743238449097, -0.30645403265953064, -0.49196213483810425, 1.0593326091766357, -0.7752448916435242, 0.1467265784740448, 0.12108542025089264, -0.21070794761180878, -0.09137635678052902, 0.8974032402038574, -0.5324298143386841, -0.46487095952033997, -0.023178575560450554, -0.2587682902812958, 0.23735283315181732, -0.14903466403484344, 0.5410095453262329, -0.2159867137670517, -0.5685608983039856, 0.3006438910961151, -0.483896404504776, 0.9102611541748047, -0.06782262027263641, 0.34655821323394775, -0.10687890648841858, -0.36394375562667847, -0.3937540352344513, 0.857244074344635, -0.028435418382287025, 0.046313315629959106, 0.10377880930900574, 0.11705455929040909, -0.658649206161499, -0.056629084050655365, 0.8099289536476135, 0.43955907225608826, -0.3160271942615509, 0.7165143489837646, 0.2514485716819763, 0.14015869796276093, 1.0378309488296509, 0.5361230969429016, 0.538848876953125, 0.3143881559371948, 0.3804938495159149, -0.22716361284255981, 0.5876396894454956, -0.5528239607810974, 0.09795273840427399, 0.24284857511520386, 0.9669171571731567, 0.3947114944458008, 0.6265789270401001, -0.5452665090560913, -0.5386130213737488, 0.4133296608924866, 0.6094608306884766, 1.609080195426941, -0.25601473450660706, -1.0297274589538574, -0.9293217062950134, -0.39723628759384155, -0.6079256534576416, 0.6238231062889099, -0.046103231608867645, 0.5195754766464233, -0.6961813569068909, -0.7527130246162415, 1.23158597946167, 0.6919705867767334, 0.11114630848169327, -0.2510054111480713, -0.0838499441742897, 0.12337704747915268, -0.28267818689346313, -0.8069921731948853, -0.6299754977226257, 0.07232783734798431, -0.7867298722267151, -0.5659119486808777, -0.0030082003213465214, -0.3682093918323517, 0.09800150245428085, -0.5763722062110901, 1.0663411617279053, -0.2002774178981781, 0.045584432780742645, -0.03139692172408104, 0.39245131611824036, -0.8363717794418335, -0.7934150695800781, -0.024476084858179092, 0.04534047096967697, -0.6580202579498291, 0.8744922876358032, 0.6642914414405823, 0.6449138522148132, 0.17965930700302124, -0.7125622630119324, 0.2503443956375122, -0.06756508350372314, 0.30520814657211304, 0.5020895600318909, 0.29736003279685974, -0.031628966331481934, -1.2014652490615845, 1.0541808605194092, 0.49207884073257446, -0.8041825294494629, 0.8425161242485046, -0.645254909992218, -0.2983318567276001, 0.6848825216293335, -0.7461043000221252, -0.2734455168247223, -0.9872198104858398, 0.39654216170310974, 0.27455252408981323, 0.07532469183206558, 0.740959644317627, -0.24738076329231262, 0.5440348386764526, 0.19535629451274872, 0.6242921948432922, 0.45991265773773193, -0.07041267305612564, 0.5039322376251221, -0.14825962483882904, -0.020838482305407524, 0.25881505012512207, 0.08323551714420319, -0.11718376725912094, -0.3846528232097626, -0.8986209630966187, -0.4078485667705536, -0.3548226058483124, -0.36362913250923157, -0.005547714419662952, -0.512891948223114, -0.40784966945648193, -0.41302254796028137, 0.21469543874263763, -1.0586128234863281, -0.1146036759018898, 0.0015534518752247095, -0.35808265209198, 0.21622486412525177, -0.6760104894638062, -1.5035046339035034, -0.6821831464767456, -0.5121563673019409, -0.46881982684135437, 0.2954414188861847, -0.15568019449710846, -0.44133415818214417, -0.6962911486625671, -0.04553847387433052, -0.48632562160491943, 0.5871131420135498, -0.5034492611885071, 1.4013900756835938, -0.13332797586917877, -0.015351303853094578, -0.27911150455474854, 0.3128284215927124, -0.14462025463581085, -0.10556990653276443, 0.3021751046180725, -0.2981678247451782, 0.1366179883480072, 0.11833128333091736, 0.23813298344612122, -0.4853403568267822, 0.5554701089859009, 0.45003777742385864, -0.09747868031263351, -1.0377241373062134, -0.179769366979599, 1.3629581928253174, -0.4071688652038574, 0.08774431049823761, -0.11500854045152664, 0.682094395160675, 0.6399375200271606, 0.014693732373416424, 0.3658498227596283, 0.30700600147247314, 0.25859108567237854, -0.01633775793015957, -0.06097954139113426, 0.3675227463245392, -0.3622414767742157, 0.5047442317008972, 1.3675236701965332, 0.2004612237215042, -0.5096901059150696, -1.1673768758773804, 0.9613878726959229, -1.3780423402786255, -0.8875389695167542, 0.4512096047401428, 0.392252117395401, 0.3775565028190613, -0.4542471468448639, -0.5009717345237732, 0.3219545781612396, 0.4473075270652771, 0.48665857315063477, 0.08202266693115234, -0.005898263771086931, -0.16844679415225983, 0.11991118639707565, 0.1989971548318863, 0.9360752105712891, -0.281872034072876, 0.5297015905380249, 14.692835807800293, 0.9570063352584839, 0.1245679035782814, 0.3608528673648834, -0.12256458401679993, 0.42795151472091675, -0.8492770791053772, 0.17065854370594025, -1.345549464225769, -0.35646042227745056, 1.0291969776153564, -0.5167948603630066, 0.6376664042472839, -0.2666301131248474, 0.4718186557292938, -0.013617589138448238, -0.33820968866348267, 0.5516337156295776, 0.561773955821991, -1.0670431852340698, 0.8640700578689575, 0.17018423974514008, -0.021691974252462387, 0.3845197558403015, 0.12080636620521545, 0.5271432399749756, 0.4092961549758911, -0.41633501648902893, 0.43577614426612854, 0.017179179936647415, 0.7658241987228394, -0.28750261664390564, 0.9315157532691956, 1.1733689308166504, -1.1180437803268433, -0.5829825401306152, -0.9811099171638489, -1.2220113277435303, 0.25230005383491516, 0.4555922746658325, -0.3681432008743286, -0.13603568077087402, -0.5662065148353577, 0.9271966218948364, 0.31070995330810547, 0.10060492902994156, -0.36663466691970825, 0.7220193147659302, -0.07267902791500092, 0.06976914405822754, 0.12174728512763977, 0.28588545322418213, 0.4914652407169342, -0.25898614525794983, 0.45076310634613037, 0.46536386013031006, 0.17096491158008575, 0.08977580070495605, -0.3921106159687042, 0.4180755913257599, -0.5817039012908936, -0.8657294511795044, -0.025985663756728172, 0.5845361351966858, 0.21855679154396057, 0.18175183236598969, -0.34755370020866394, -0.0186443068087101, 0.14449656009674072, 0.23762638866901398, -0.07523994892835617, -0.33368080854415894, 0.19296284019947052, 0.48690667748451233, -0.36054909229278564, 0.5049077868461609, -0.4089851379394531, -0.6773471832275391, -0.8938535451889038, -0.13125881552696228, 0.7119817733764648, -0.8294044733047485, -0.8989829421043396, 1.1587154865264893, -0.07562856376171112, -0.886159360408783, 0.2014518678188324, -0.7811940908432007, -0.35047057271003723, 0.44831475615501404, -1.014022946357727, -1.2391573190689087, 0.22861655056476593, 0.06701162457466125, 0.026811039075255394, 0.2723890244960785, 1.5242401361465454, -0.12384731322526932, -0.2145211398601532, -0.14866575598716736, 0.5950922966003418, 0.3421953320503235, -0.3912118673324585, -0.8219999670982361, 0.59723961353302, 0.6488462090492249, 0.03908412158489227, 0.9387466311454773, 0.15657944977283478, -0.2775796949863434, -0.48669350147247314, -0.1179363951086998, 1.457637071609497, -1.027190923690796, -0.15212424099445343, -0.9983044862747192, -1.1430226564407349, 0.5547482967376709, 0.8124857544898987, -0.8520974516868591, 0.48483458161354065, 0.2811393141746521, 0.0844489336013794, -0.18305683135986328, -0.9423345327377319, 0.3674052357673645, 0.4983827471733093, -0.7520116567611694, -0.5578935146331787, 0.038756828755140305, 0.35323092341423035, -0.8979405760765076, -0.687569260597229, -0.2292407900094986, 0.21961919963359833, 0.675039529800415, 0.4591819941997528, -0.1851215958595276, 0.38557538390159607, 0.4787188470363617, -0.27695995569229126, -0.5461031794548035, -0.07721998542547226, -1.0330238342285156, 0.1566620171070099, 0.3482280373573303, 0.982138454914093, -0.20471011102199554, 0.07652043551206589, 0.9565619826316833, 0.4923427700996399, -0.38850316405296326, -0.41819608211517334, -0.31229180097579956, 0.4271279275417328, -0.5321001410484314, 0.7465112209320068, -0.19146624207496643, 0.4361009895801544, 0.1781553030014038, 0.38302144408226013, 0.7426011562347412, -0.28839007019996643, -0.21679842472076416, 0.3847410976886749, -0.2969907224178314, 0.5008732080459595, -0.44597959518432617, -0.065049909055233, -1.5391316413879395, 0.2200118601322174, -0.7878316640853882, 0.02000115066766739, -1.429864764213562, -0.3137815296649933, 0.3875837028026581, 0.2942107319831848, 0.07260297983884811, 0.5922948718070984, -1.0481761693954468, -0.8276840448379517, -0.44178828597068787, -0.05041687935590744, 0.49813154339790344, 0.7994861602783203, -0.778762698173523, 0.12291644513607025, 0.09149444848299026, 0.30670294165611267, 0.26092180609703064, 0.1569347232580185, -0.6483273506164551, -0.993558406829834, -1.1319741010665894, 0.3822924494743347, 0.14148439466953278, -0.6892517805099487, -0.15318240225315094, 0.4887523949146271, -0.1972263604402542, -0.08687718212604523, -0.35070914030075073, 0.09846118092536926, -0.8935859203338623, -0.19040319323539734, 0.08813359588384628, -0.8083109855651855, 0.18111786246299744, -0.07998508214950562, -0.6974783539772034, -0.2537636160850525, 0.18170611560344696, -0.19714581966400146, -1.1714597940444946, -0.15929654240608215, 0.3260968327522278, -1.043758749961853, -0.2647051215171814, 0.14073389768600464, -0.37711548805236816, -0.9290660619735718, -0.4597361981868744, -0.0836491510272026, 0.713790237903595, -0.0019383743638172746, 1.0709772109985352, 0.15334461629390717, -0.8692228198051453, 0.14595790207386017, 0.46399039030075073, -0.16708171367645264, -0.319059818983078, 0.22516955435276031, 0.06366468966007233, -0.1919429451227188, 0.9367086887359619, 0.49328330159187317, 0.3301980793476105, -1.5068107843399048, -0.15114334225654602, 0.47299912571907043, -0.7210262417793274, -0.4331178367137909, 0.6262063980102539, -0.5110098123550415, -0.7866948246955872, 0.20224010944366455, -1.377518892288208, -1.218473196029663, -0.4441875219345093, 1.4537392854690552, 0.29771924018859863, -0.3879847228527069, -0.3362375795841217, -0.12508806586265564, 0.3467675745487213, 0.0113129997625947, -0.5929315090179443, 0.9388185143470764, -0.7152959108352661, -0.6438630819320679, 0.9992520213127136, -0.07770159095525742, -0.18312038481235504, -0.29030466079711914, -0.43751654028892517, -0.04107976704835892, -0.38610461354255676, 0.06506173312664032, -0.5528683066368103, -0.026913657784461975, 0.7436990737915039, 0.24975205957889557, 0.6812639832496643, 0.06065516173839569, -0.29655230045318604, 0.4780232608318329, 0.45525944232940674, 0.443938672542572, -0.8075509071350098, -1.1244248151779175, 1.6763492822647095, 1.6160837411880493, -0.45942598581314087, 0.14199963212013245, -0.19817321002483368, -0.7299045920372009, 1.3544706106185913, 0.2541700005531311, 0.5433160066604614, 0.9768894910812378, 0.3179309666156769, 0.6736018657684326, 0.05188765376806259, -0.8294456601142883, 0.08746234327554703, 0.05966464802622795, 0.9424195885658264, 0.8414586186408997, 0.28089961409568787, -0.252950519323349, 1.4498037099838257, 0.22133132815361023, 0.5913071632385254, 0.8967072367668152, 0.6962352395057678, -0.2667805552482605, -0.8596510291099548, 0.047686733305454254, 0.6620400547981262, -1.0774551630020142, -0.5548316240310669, -0.051593367010354996, 0.5893206596374512, 0.014785370789468288, 0.9686199426651001, 0.40615254640579224, -0.0022497824393212795, 0.4970231056213379, 0.5738566517829895, 0.2976638674736023, -0.7659598588943481, -0.3369438052177429, 0.18744231760501862, -0.23841269314289093, 0.10434811562299728, -0.37703531980514526, -0.43210268020629883, -0.32894039154052734, -0.27889299392700195, -0.24448512494564056, 0.440129816532135, 0.14260992407798767, 1.1630771160125732, 0.2448926568031311, -0.022517994046211243, -0.5648488998413086, 0.30989810824394226, -0.5417101383209229, -1.2864890098571777, -0.5155067443847656, -0.8287217020988464, -0.21139772236347198, 0.19715306162834167, 0.053366780281066895, -0.017754672095179558]}, "authors": [{"authorId": "2198280871", "name": "Zican Dong"}, {"authorId": "1997234792", "name": "Tianyi Tang"}, {"authorId": "2210086300", "name": "Lunyi Li"}, {"authorId": "2542603", "name": "Wayne Xin Zhao"}], "references": [{"paperId": "661e8d555c4424b5953f17434f2ba910bfcf3afe", "title": "Efficient Long Sequence Modeling via State Space Augmented Transformer"}, {"paperId": "3bcea238b0c323d8f891829714bbe6e8a3de894c", "title": "Toward Unifying Text Segmentation and Long Document Summarization"}, {"paperId": "077f3c382d0dce221cf6aaef0e7185a249b71b9f", "title": "Capturing Global Structural Information in Long Document Question Answering with Compressive Graph Selector Network"}, {"paperId": "9166caa474031b62bacad8a920db8308e6a15120", "title": "An Exploration of Hierarchical Attention Transformers for Efficient Long Document Classification"}, {"paperId": "1df0d9c553aee087fe3a7dd1c5f9e03556eb1fe4", "title": "HEGEL: Hypergraph Transformer for Long Document Summarization"}, {"paperId": "3b39efe6c91ae432dd35bb79431edb8a6719f906", "title": "Investigating Efficiently Extending Transformers for Long Input Summarization"}, {"paperId": "732e3faec4e5be4d144256f2c379b9dc49f0b227", "title": "Efficient Long-Text Understanding with Short-Text Models"}, {"paperId": "f8d44802ac8190864c61c9aaf4a8b450261873ab", "title": "An Empirical Survey on Long Document Summarization: Datasets, Models, and Metrics"}, {"paperId": "4eb45f33446018175e266738be22f4d830ed697e", "title": "Semantic Self-Segmentation for Abstractive Summarization of Long Documents in Low-Resource Regimes"}, {"paperId": "85e3cf70079adb1db8b1b50321a5d336edc1c3fa", "title": "Leveraging Locality in Abstractive Text Summarization"}, {"paperId": "3d318019788418b21478e8736d03afadc1607690", "title": "HIBRIDS: Attention with Hierarchical Biases for Structure-aware Long Document Summarization"}, {"paperId": "33d15b2d2a434ab33a2a88585604f4728a324baf", "title": "Efficient Classification of Long Documents Using Transformers"}, {"paperId": "24b951275a7a42ef36aca8352caaf6f4cd6238d2", "title": "HiStruct+: Improving Extractive Text Summarization with Hierarchical Structure Information"}, {"paperId": "e96493b4181de6c60b761dc66492db8e66fd784f", "title": "Long Document Summarization with Top-down and Bottom-up Inference"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "3dfb1f50f2a34a699c339dabaa6f9b3a977973de", "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences"}, {"paperId": "c600b697700c844cbc85009be70f1cdfeef3593e", "title": "Summ^N: A Multi-Stage Summarization Framework for Long Input Dialogues and Documents"}, {"paperId": "0a41cb292242a82b2b09b3bf23b48349b981a640", "title": "DYLE: Dynamic Latent Extraction for Abstractive Long-Input Summarization"}, {"paperId": "365fbeeefe2b219ed36b3f3a603c8d7bae99d48a", "title": "RoR: Read-over-Read for Long Document Machine Reading Comprehension"}, {"paperId": "e4dd6650497ce07d78ea4f57ea1434f4a3e3f771", "title": "Sparsity and Sentence Structure in Encoder-Decoder Attention of Summarization Systems"}, {"paperId": "d8d2e574965fe733eb1416e03df2b5c2914fc530", "title": "A Survey of Transformers"}, {"paperId": "af679d69fcc1d0fcf0f039aba937853bcb50a8de", "title": "Luna: Linear Unified Nested Attention"}, {"paperId": "592dd524b78ff141ef41ed8b784cfe3de32ec974", "title": "Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents"}, {"paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de", "title": "Pay Attention to MLPs"}, {"paperId": "f4566761fe39c4b5273d696d9bc3f4195c9325bb", "title": "Long-Span Summarization via Local Attention and Content Selection"}, {"paperId": "836e9619f779f2d9642561f2b697ba471b866b27", "title": "Hierarchical Learning for Generation with Long Source Sequences"}, {"paperId": "9dc624d7258d1a56117ca720aea953ce46b66b21", "title": "Efficient Attentions for Long Document Summarization"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "8ff620f704a4151fd7abba1db792463fbd32bfe5", "title": "Long Document Summarization in a Low Resource Setting using Pretrained Language Models"}, {"paperId": "afad10da0a3b83a4f2a94e8c16c84ac64338e9fe", "title": "ERNIE-Doc: A Retrospective Long-Document Modeling Transformer"}, {"paperId": "21c3cb93aea616720276ed23d871abc582a0f56c", "title": "Systematically Exploring Redundancy Reduction in Summarizing Long Documents"}, {"paperId": "d387600e5150b381a306221a5bc9bd92aa99157b", "title": "Memformer: The Memory-Augmented Transformer"}, {"paperId": "7e4213efb30cd1ad24b131d1eecd5c8096051a95", "title": "Enhancing Extractive Text Summarization with Topic-Aware Graph Neural Networks"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "e1d89e5a9585a28c9530e2e336876d3dd41c021d", "title": "PARADE: Passage Representation Aggregation forDocument Reranking"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "ea8c46e193d5121e440daf96edfd15a47151c293", "title": "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "0b991a1a5bcdb13646ac0b6873d09bde4cc36fb5", "title": "Masked Language Modeling for Proteins via Linearly Scalable Long-Context Transformers"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "19f1ad5c233e8e17b8defa02dd9cc750af16509a", "title": "Recurrent Chunking Mechanisms for Long-Text Machine Reading Comprehension"}, {"paperId": "17a43e798ede87cadf71793fd29bb12b92ca71d4", "title": "Beyond 512 Tokens: Siamese Multi-depth Transformer-based Hierarchical Encoder for Long-Form Document Matching"}, {"paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d", "title": "ETC: Encoding Long and Structured Inputs in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "86cb79083bfa5dc6329ab1b8c7099af76fefde36", "title": "A Hierarchical Network for Abstractive Meeting Summarization with Cross-Domain Pretraining"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "0e84c135684b62fbaf939a5331ebdb73cd5adb20", "title": "Long-length Legal Document Classification"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "46b3ba0f3cb8340bc94f26e0fdf6dc4e38f68948", "title": "Hierarchical Transformers for Long Document Classification"}, {"paperId": "5cebe6d3f70663d19f0d92154cad86c2d58a649c", "title": "Summary Level Training of Sentence Rewriting for Abstractive Summarization"}, {"paperId": "0cf535110808d33fdf4db3ffa1621dea16e29c0d", "title": "Multi-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering"}, {"paperId": "95a251513853c6032bdecebd4b74e15795662986", "title": "What Does BERT Look at? An Analysis of BERT\u2019s Attention"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "b0da9efe9378efd98551e2416a3af0e4219a90ff", "title": "Semantic Text Matching for Long-Form Documents"}, {"paperId": "203b543bfa1e564bb80ff4229b43174d7c71b0c0", "title": "HIBERT: Document Level Pre-training of Hierarchical Bidirectional Transformers for Document Summarization"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "455afd748e8834ef521e4b67c7c056d3c33429e2", "title": "Hierarchical Attention Networks for Document Classification"}, {"paperId": "bc6dff14a130c57a91d5a21339c23471faf1d46f", "title": "Et al"}, {"paperId": "7b95d389bc6affe6a127d53b04bcfd68138f1a1a", "title": "TextRank: Bringing Order into Text"}, {"paperId": "997dc5d9a058753f034422afe7bd0cc0b8ad808b", "title": "Signature Verification Using A \"Siamese\" Time Delay Neural Network"}, {"paperId": "6cea705be536770d363c56d6db6da51bfb642499", "title": "HeterGraphLongSum: Heterogeneous Graph Neural Network with Passage Aggregation for Extractive Long Document Summarization"}, {"paperId": "0eedbc38bc215fdbe4e5bcde8aeac08fb3ce9f44", "title": "Parallel Context Windows Improve In-Context Learning of Large Language Models"}, {"paperId": "01e19fa9c7d32549b310b0e0b609623ea0ffcc52", "title": "Multi Graph Neural Network for Extractive Long Document Summarization"}, {"paperId": "63b5226b5cea33e7b862f737d5bf1a766ea3281a", "title": "Two-Stage Movie Script Summarization: An Efficient Method For Low-Resource Long Document Summarization"}, {"paperId": "4d244972ed2e0286363bfb054cb269574d21a72c", "title": "Globalizing BERT-based Transformer Architectures for Long Document Summarization"}, {"paperId": "5665805becad6c87b194b260f2270d86d560bd3f", "title": "On Extractive and Abstractive Neural Document Summarization with Transformer Language Models"}, {"paperId": "a5fa6e7565dca654eab9372ace4b1ba7f63655f7", "title": "CogLTX: Applying BERT to Long Texts"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}]}