{"paperId": "31d65e179b1d00484154b3525d93846dd82f23d8", "title": "Inverse Scaling: When Bigger Isn't Better", "abstract": "Work on scaling laws has found that large language models (LMs) show predictable improvements to overall loss with increased scale (model size, training data, and compute). Here, we present evidence for the claim that LMs may show inverse scaling, or worse task performance with increased scale, e.g., due to flaws in the training objective and data. We present empirical evidence of inverse scaling on 11 datasets collected by running a public contest, the Inverse Scaling Prize, with a substantial prize pool. Through analysis of the datasets, along with other examples found in the literature, we identify four potential causes of inverse scaling: (i) preference to repeat memorized sequences over following in-context instructions, (ii) imitation of undesirable patterns in the training data, (iii) tasks containing an easy distractor task which LMs could focus on, rather than the harder real task, and (iv) correct but misleading few-shot demonstrations of the task. We release the winning datasets at https://inversescaling.com/data to allow for further investigation of inverse scaling. Our tasks have helped drive the discovery of U-shaped and inverted-U scaling trends, where an initial trend reverses, suggesting that scaling trends are less reliable at predicting the behavior of larger-scale models than previously understood. Overall, our results suggest that there are tasks for which increased model scale alone may not lead to progress, and that more careful thought needs to go into the data and objectives for training language models.", "venue": "arXiv.org", "year": 2023, "citationCount": 74, "influentialCitationCount": 8, "openAccessPdf": {"url": "http://arxiv.org/pdf/2306.09479", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "Overall, the results suggest that there are tasks for which increased model scale alone may not lead to progress, and that more careful thought needs to go into the data and objectives for training language models."}, "embedding": {"model": "specter_v2", "vector": [0.14230798184871674, 0.3396224081516266, -0.11499405652284622, -0.1542610228061676, -0.22975951433181763, -0.14309895038604736, 0.5384917855262756, -0.46256014704704285, -0.9835545420646667, -0.25994279980659485, 0.21665436029434204, -0.4343952238559723, 0.18993952870368958, 0.38791945576667786, -0.2502073049545288, 0.18202252686023712, -0.9765859842300415, 0.24670007824897766, -0.11599892377853394, -0.5360754728317261, 0.02495289221405983, -0.6295159459114075, -1.0252479314804077, 0.07884779572486877, 0.2642591893672943, 0.256552129983902, 0.3303714990615845, 1.2575258016586304, -0.1857171207666397, 0.35392650961875916, 0.2306056171655655, 0.09641057252883911, 0.34201115369796753, -0.09295868128538132, -0.04347611963748932, -0.19079339504241943, 0.45561331510543823, -0.6493664979934692, -0.5130192041397095, 0.469857394695282, -0.16367825865745544, 0.43233975768089294, 0.2083418369293213, -0.8951898217201233, -0.4033384919166565, 0.48038992285728455, 0.4143820106983185, 1.0343091487884521, -0.1716061681509018, -0.45493626594543457, 0.7988219261169434, -0.9722942113876343, 0.5903293490409851, 1.5337904691696167, 0.687252938747406, 0.6002217531204224, -0.23883916437625885, -1.0523903369903564, 0.4291805028915405, -0.09641478210687637, -0.8949892520904541, -0.3125363886356354, -0.46247798204421997, -0.03303348645567894, 1.4334535598754883, -0.5164206624031067, -0.3458877205848694, 0.3826841115951538, 0.13131451606750488, 1.2864413261413574, 0.3905593454837799, -0.8918399810791016, -0.04737993702292442, 0.2743753492832184, 0.2014838308095932, 0.717808187007904, -0.3967188894748688, 0.619103729724884, -1.1612510681152344, -0.20691505074501038, 0.5052716135978699, -0.5493935346603394, -0.10233522951602936, -0.08010093122720718, -0.27179405093193054, 0.600845217704773, 0.34582823514938354, 0.7807216644287109, 0.23566941916942596, 0.9207730889320374, 0.5887959599494934, 0.9697573781013489, 0.3463379740715027, 0.35801756381988525, -0.29674291610717773, 0.09181179106235504, -0.6888259053230286, -0.16223815083503723, 0.13737477362155914, 1.0230048894882202, -0.11863423138856888, 0.09639956057071686, -0.2828001081943512, -0.013881302438676357, 1.0983914136886597, -0.32218602299690247, 1.116431474685669, -0.683324933052063, 0.5786960124969482, -0.8420181274414062, 0.46693357825279236, -0.10258427262306213, -1.0446511507034302, -0.3455491364002228, -0.3346386253833771, -0.9497085809707642, 0.10645382851362228, 0.2569279074668884, -0.4574136435985565, 1.174810767173767, -0.3060690462589264, 0.019131900742650032, -0.1483532190322876, 0.6365129351615906, 0.2747081220149994, 0.38878530263900757, 0.5842112302780151, 0.054266441613435745, 0.44340747594833374, -0.371578186750412, -0.5588220953941345, -0.7638304829597473, 0.9245933294296265, -0.5736250877380371, 1.0699667930603027, -0.49839329719543457, -1.3033692836761475, -1.342786431312561, -0.969465434551239, 0.14832942187786102, -0.3336222469806671, 0.4540359079837799, 1.0781477689743042, 0.39658430218696594, -1.0447492599487305, 1.1934367418289185, -0.3340884745121002, -0.4084196984767914, 0.1719832867383957, 0.17927172780036926, 0.17091529071331024, -0.4880683422088623, -1.044510006904602, 0.49074044823646545, 0.09515634179115295, -1.0396902561187744, -0.07919517159461975, -0.6692296862602234, -1.1122270822525024, -0.21565867960453033, 0.2331521213054657, -0.1837218552827835, 1.2182952165603638, 0.02172376774251461, -0.9403854012489319, 0.5916260480880737, -0.04730479046702385, 0.5057940483093262, 0.661459743976593, -0.12431488931179047, -0.7879753708839417, -0.5771700143814087, -0.2719147801399231, 0.654215931892395, 0.4951120615005493, -0.2854028642177582, 0.05612070485949516, -0.036981385201215744, -0.21571213006973267, -0.0560770221054554, -0.4340881407260895, 0.6301891207695007, 0.15178239345550537, -0.422834187746048, 0.4701247811317444, 0.261971652507782, 0.13469038903713226, 0.003305710619315505, 0.1229921281337738, -1.0760890245437622, 0.36520150303840637, -0.12182490527629852, 1.1396515369415283, -0.9362403750419617, -0.7784596681594849, -0.3592134416103363, -0.16246353089809418, -0.37344062328338623, -1.1106570959091187, 0.842818021774292, -0.17048250138759613, 0.8623493909835815, -0.0978202298283577, -1.5180283784866333, 0.23949193954467773, -0.19881027936935425, -0.5884155631065369, -0.018749313428997993, -0.36354801058769226, 0.970620334148407, -0.7734895348548889, 0.14237278699874878, -0.20192869007587433, 0.10112058371305466, -0.5382378101348877, 0.9429781436920166, -0.16118168830871582, 0.44126904010772705, 0.5615308284759521, -0.4111570417881012, 0.056863632053136826, -0.48002904653549194, 0.3385976552963257, -0.435122549533844, -0.11172332614660263, 0.1272943615913391, -0.3967032730579376, 1.612295389175415, -0.4595133066177368, 0.5098114013671875, -0.06588766723871231, -0.295680433511734, -0.3079792559146881, 0.19707821309566498, -0.6325559020042419, -0.4430416524410248, 0.29611095786094666, 0.4951574206352234, -0.013792688027024269, 0.13899190723896027, 0.8250046372413635, 0.5234783887863159, -0.2664107382297516, 0.5637866854667664, 0.45057231187820435, -0.7218691110610962, 0.670455813407898, 0.5423351526260376, 0.3866709768772125, 0.6619771122932434, 0.415499210357666, -0.20648959279060364, 0.10143428295850754, -0.8938791751861572, -0.5626678466796875, 0.7463331818580627, 0.35927480459213257, 0.7276787161827087, -0.02850927971303463, -0.9252910017967224, -0.8090289831161499, -0.2891404330730438, 0.5264509916305542, 1.8932260274887085, -0.1918090432882309, -0.035726871341466904, -0.5614892244338989, 0.10550430417060852, -0.35118770599365234, 0.1400201916694641, -0.7674213647842407, -0.24345524609088898, -0.9291568994522095, -0.7106291055679321, 0.48481327295303345, 0.05777216702699661, 0.8210408687591553, -0.4390564262866974, -0.34166407585144043, -0.03926759958267212, 0.5650349259376526, -0.7246391773223877, -0.8487253785133362, -0.11254536360502243, -0.7103620767593384, -0.11185558885335922, 0.01095866970717907, -0.008872833102941513, 0.030216239392757416, -0.0733678787946701, 0.8776348829269409, 0.11539057642221451, -0.6305978894233704, 0.16313962638378143, 0.5707072019577026, -0.6732823252677917, -1.2748063802719116, 0.17358559370040894, 0.5064181685447693, -0.6663640141487122, -0.1945681869983673, 0.5173022747039795, -0.14790506660938263, 0.26476967334747314, -0.7318490743637085, 0.16846293210983276, 0.3915768265724182, 0.04005749523639679, 0.048434071242809296, -0.5962467789649963, 0.653496503829956, -0.861178994178772, 1.6470788717269897, 0.35103729367256165, -0.3225257694721222, 0.660229504108429, -0.8776666522026062, -0.1808227300643921, 0.5803331136703491, -1.099099040031433, 0.012899713590741158, -1.1218701601028442, 0.5383099913597107, 0.0711321160197258, 0.1063307672739029, -0.13413596153259277, 0.7893130779266357, -0.2942714989185333, 0.45614710450172424, 0.48207542300224304, 0.6957891583442688, -0.07363851368427277, 0.47439873218536377, -0.5909319519996643, 0.04962914437055588, 0.33874189853668213, -0.045676592737436295, -0.06380929052829742, -0.1545916050672531, -0.4911207854747772, -0.32692861557006836, 0.06290502101182938, -0.276677668094635, -0.41168540716171265, -0.030227752402424812, -0.4950179159641266, -0.9430657625198364, -0.134237602353096, -0.6169199347496033, -0.7157441973686218, 0.1072397455573082, 0.09627329558134079, -0.5505293607711792, -0.8285761475563049, -1.5297462940216064, -0.37095847725868225, -0.28392359614372253, -0.8985123038291931, 0.33525627851486206, 0.17498207092285156, -0.971550703048706, -0.16942983865737915, 0.02699775993824005, -0.3775791525840759, 1.3488423824310303, -1.1759898662567139, 0.9442222118377686, 0.06173286959528923, 0.090526282787323, -0.22965213656425476, 0.14013752341270447, 0.2299068421125412, -0.21712379157543182, 0.2624538540840149, -0.9106802940368652, -0.3946147859096527, -0.13692094385623932, -0.7876710295677185, -0.0845746397972107, 0.06499456614255905, 0.5086225271224976, 0.2153460830450058, -0.18685436248779297, -0.13442330062389374, 0.9443535804748535, -0.7142549753189087, -0.18738366663455963, 0.06594249606132507, 0.5462466478347778, 0.47672802209854126, -0.23548898100852966, 0.6415323615074158, 0.33887773752212524, 0.28519222140312195, -0.35841885209083557, 0.21361014246940613, -0.5831178426742554, -0.7783536314964294, 0.5110244154930115, 1.6007057428359985, 0.3324951231479645, 0.4085342288017273, -0.9037725925445557, 0.08211765438318253, -0.8945191502571106, -0.41832849383354187, 0.9658622741699219, 1.212157130241394, 0.49496990442276, -0.4156654179096222, -0.4953491985797882, -0.08413216471672058, 0.2758018970489502, 0.17999689280986786, -0.6623556613922119, -0.42179742455482483, 0.17872746288776398, 0.21330739557743073, -0.03837289661169052, 0.5559844374656677, -0.20689818263053894, 0.6077042818069458, 15.097167015075684, 1.0412544012069702, -0.01819591224193573, 1.0194101333618164, 0.6031650900840759, 0.10431517660617828, -0.1296650469303131, -0.4278182089328766, -0.8097742795944214, 0.007967055775225163, 1.0434125661849976, 0.06912567466497421, 1.128179907798767, -0.27742061018943787, 0.12175898253917694, -0.003989178221672773, -0.3261144757270813, 0.4269644618034363, 0.3937924802303314, -1.1078550815582275, 0.14535361528396606, -0.025988364592194557, 0.6677922010421753, 0.6161823868751526, 0.8118810057640076, 1.1183151006698608, 0.3728591203689575, -0.3825029134750366, 0.657063364982605, -0.09408579021692276, 0.9856104850769043, -0.0003966547083109617, -0.06780141592025757, 0.9416122436523438, -0.8573504090309143, -0.16382530331611633, -0.591386616230011, -1.4052292108535767, 0.2377789467573166, -0.24759086966514587, -0.6864829659461975, -0.7921112179756165, -0.24603097140789032, 0.07779352366924286, -0.17239689826965332, 0.2068004459142685, -0.10233379900455475, 0.5558757185935974, -0.02525942586362362, -0.30548882484436035, -0.0396275632083416, 0.6563348770141602, 0.013064449653029442, -0.3604353070259094, 0.010562125593423843, -0.20455524325370789, 0.0745430663228035, 0.3716200590133667, -0.6828320622444153, -0.04528671130537987, -0.17634688317775726, -0.21012380719184875, 0.17044702172279358, 0.6174729466438293, 0.21166326105594635, -0.001971085323020816, -0.1719149947166443, 0.32381606101989746, 0.9565402865409851, 0.36611661314964294, -0.08394411206245422, 0.25238487124443054, 0.20107656717300415, -0.5201525092124939, -0.5801292061805725, -0.033561985939741135, -0.20601071417331696, -0.490549236536026, -0.6264344453811646, -0.21797913312911987, 0.016228124499320984, -0.9404501914978027, -0.9290433526039124, 0.6468782424926758, -0.3128270208835602, -0.6005455851554871, 0.2500143349170685, -0.45195651054382324, -0.024743588641285896, 0.1072051078081131, -1.1870001554489136, -0.5882239937782288, 0.22988328337669373, -0.5558048486709595, -0.03799721226096153, -0.01661902479827404, 1.2403433322906494, -0.01883743144571781, -0.15697185695171356, 0.11241370439529419, 0.2678608000278473, -0.5049174427986145, 0.3625108003616333, -0.586578905582428, 1.0306081771850586, -0.17906908690929413, -0.17001011967658997, 0.4225250780582428, 0.279777467250824, 0.20821060240268707, -0.5464193820953369, 0.46952497959136963, 0.41405123472213745, -0.6754316091537476, 0.0964183509349823, -0.6516233086585999, -0.7866111993789673, 0.10219217836856842, 0.047983262687921524, -0.22743767499923706, 0.479827880859375, -0.14952488243579865, -0.6454840898513794, 0.13063952326774597, -0.8196505904197693, 0.22634005546569824, 0.7735730409622192, -1.0905457735061646, -0.3497488796710968, 0.09076407551765442, 0.5665913224220276, -0.9478726387023926, -0.6865959167480469, -0.022581150755286217, 0.3571416437625885, -0.016398539766669273, 0.5652858018875122, -0.9327748417854309, 0.5780659317970276, 0.9411906599998474, -0.1288154274225235, -0.951285183429718, 0.1361037939786911, -0.700941264629364, 0.2459625005722046, -0.3597411811351776, 0.6469576358795166, -0.356160968542099, 0.14031313359737396, 1.132079839706421, 0.21329858899116516, -0.23665766417980194, -0.8597153425216675, -0.5881139636039734, 0.23237468302249908, -0.5702990293502808, 0.24733667075634003, -0.21211719512939453, 0.08536499738693237, 0.022870587185025215, 0.2449323534965515, 0.30270060896873474, -0.19334442913532257, -0.6059197187423706, 0.3969241976737976, 0.1382443606853485, -0.3506104648113251, -0.786152720451355, -0.29862502217292786, -1.3990364074707031, -0.010820426046848297, -1.1029201745986938, 0.008432768285274506, -0.44502121210098267, -0.6715251207351685, -0.2642399072647095, 0.0317152701318264, -0.6487310528755188, 0.35468533635139465, -0.25403928756713867, -0.0003854651586152613, 0.16714464128017426, -0.5299556851387024, 0.759650707244873, 1.2784115076065063, -0.4142114520072937, -0.085890993475914, 0.00221634260378778, 0.31696686148643494, 0.4854087829589844, 0.7610860466957092, -0.28479698300361633, -0.8110188841819763, -1.4133105278015137, 0.6609528660774231, 0.04849356785416603, -0.46501877903938293, -0.8790197372436523, 0.6992741227149963, 0.4864845871925354, 0.07705137878656387, 0.3953329026699066, 0.5136486291885376, -0.7517549395561218, -0.36421045660972595, 0.7892976999282837, -1.1129134893417358, 0.48488709330558777, 0.4422506093978882, -0.3583134114742279, 0.29434388875961304, 0.2384042590856552, -0.11680837720632553, -0.8842817544937134, -0.7662183046340942, 0.2726331055164337, -0.5311359763145447, 0.09364773333072662, -0.015194802545011044, 0.1535029262304306, -1.0792927742004395, -0.262442946434021, -0.31426751613616943, 0.08986245840787888, -0.12837965786457062, 1.1618950366973877, 0.2144123762845993, -1.0219603776931763, 0.14307977259159088, 0.3737263083457947, 0.09308287501335144, -0.3653019070625305, 0.6314733624458313, 0.18324649333953857, -0.32978299260139465, 0.29975003004074097, 0.32710468769073486, 0.3977261483669281, -0.9626156091690063, -0.25457653403282166, 0.34802669286727905, -0.3865572512149811, 0.27371177077293396, 1.1656503677368164, -0.3123837113380432, -1.2812256813049316, 0.20517078042030334, -1.214724063873291, -0.16375118494033813, -0.42357689142227173, 0.8071512579917908, 0.4611402153968811, -0.0642162635922432, 0.20760168135166168, -0.19736194610595703, 0.3166636526584625, -0.06503066420555115, -0.6260503530502319, 0.2030281275510788, -0.5933587551116943, -0.15991465747356415, 0.9114859700202942, 0.8899089694023132, -0.49309614300727844, -0.998637318611145, -0.5522688627243042, -0.36963605880737305, -0.09119053930044174, -0.35813626646995544, -0.40564143657684326, -0.006395617965608835, 0.7078611850738525, 0.7095226049423218, 0.1210455670952797, -0.40671810507774353, 0.042240843176841736, 0.032241325825452805, 0.5684534907341003, 0.5903016924858093, -0.7912011742591858, -0.3425496518611908, 1.1131917238235474, 1.505623698234558, -1.348676323890686, 0.4839674234390259, 0.1375267207622528, -0.47205066680908203, 0.9176405072212219, 0.5714084506034851, 0.05788758397102356, 0.8727449178695679, -0.23568665981292725, 0.13567838072776794, 0.23382647335529327, -0.8743330836296082, 0.23827041685581207, 0.6141393780708313, 0.5234954357147217, 0.8757542371749878, 0.5900592803955078, -0.35163992643356323, 0.7390470504760742, -0.2560863494873047, 0.7283169627189636, 0.7568094730377197, 0.6481615304946899, -0.37740737199783325, 0.08585677295923233, 0.17570436000823975, 0.6721771955490112, -0.28362399339675903, -0.5875306725502014, 0.46215325593948364, 0.8913464546203613, 0.07844344526529312, 0.4829765260219574, 0.8539239764213562, -0.19020922482013702, 0.2636205554008484, 0.21686914563179016, 0.804428219795227, -0.29595211148262024, -0.1840914785861969, -0.48994961380958557, -0.7336606383323669, -0.016366491094231606, -0.11397858709096909, -0.3382296860218048, -0.5586501955986023, -0.4775991141796112, 0.028842343017458916, -0.4443911612033844, 0.5713030099868774, 0.9950699210166931, 0.6586425304412842, 0.3048347532749176, -0.31061825156211853, -0.8777599930763245, -0.844536304473877, -1.2320245504379272, 0.22732551395893097, -0.3273007571697235, -0.43062424659729004, -0.1697639673948288, -0.4816119074821472, -0.40714558959007263]}, "authors": [{"authorId": "108314449", "name": "I. R. McKenzie"}, {"authorId": "1492181289", "name": "Alexander Lyzhov"}, {"authorId": "15043672", "name": "M. Pieler"}, {"authorId": "119389860", "name": "Alicia Parrish"}, {"authorId": "49355602", "name": "Aaron Mueller"}, {"authorId": "39012223", "name": "Ameya Prabhu"}, {"authorId": "2197779176", "name": "Euan McLean"}, {"authorId": "82311378", "name": "Aaron Kirtland"}, {"authorId": "32739287", "name": "Alexis Ross"}, {"authorId": "94500147", "name": "Alisa Liu"}, {"authorId": "40991104", "name": "Andrew Gritsevskiy"}, {"authorId": "2220218920", "name": "Daniel Wurgaft"}, {"authorId": "2220218708", "name": "Derik Kauffman"}, {"authorId": "34955837", "name": "Gabriel Recchia"}, {"authorId": "2144174497", "name": "Jiacheng Liu"}, {"authorId": "2220218710", "name": "Joe Cavanagh"}, {"authorId": "2196179599", "name": "Max Weiss"}, {"authorId": "50178985", "name": "Sicong Huang"}, {"authorId": "2220218497", "name": "The Floating Droid"}, {"authorId": "2189421715", "name": "Tom Tseng"}, {"authorId": "2237795801", "name": "Tomasz Korbak"}, {"authorId": "2144058688", "name": "Xudong Shen"}, {"authorId": "49889860", "name": "Yuhui Zhang"}, {"authorId": "48741571", "name": "Zhengping Zhou"}, {"authorId": "8756748", "name": "Najoung Kim"}, {"authorId": "1799822", "name": "Sam Bowman"}, {"authorId": "3439053", "name": "Ethan Perez"}], "references": [{"paperId": "dcba37400ad86aaf0d47e5cdfa2fcfa98f089401", "title": "When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets"}, {"paperId": "1a527ac2736239019a9aedd3494443d5a22b57ad", "title": "Beyond Positive Scaling: How Negation Impacts Scaling Trends of Language Models"}, {"paperId": "ce913026f693101e54d3ab9152e107034d81fce1", "title": "Holistic Evaluation of Language Models"}, {"paperId": "4631398b0d61061b9ca9489d76ded4dd05bcf1ec", "title": "The Larger They Are, the Harder They Fail: Language Models do not Recognize Identifier Swaps in Python"}, {"paperId": "c5120b546f1bd99df5bd2e2bf44db5c7c46d1545", "title": "Pretraining Language Models with Human Preferences"}, {"paperId": "6fbf4e4c7872efdc03f7003d2d89b15ad8c4c552", "title": "The Capacity for Moral Self-Correction in Large Language Models"}, {"paperId": "8969ea3d254e149aebcfd1ffc8f46910d7cb160e", "title": "Uncontrolled Lexical Exposure Leads to Overestimation of Compositional Generalization in Pretrained Models"}, {"paperId": "cef330bacf014d60daabbd489647b2006af130ca", "title": "Discovering Language Model Behaviors with Model-Written Evaluations"}, {"paperId": "4809452eb4ed547adaf44a004d47ee910265ba34", "title": "Inverse scaling can become U-shaped"}, {"paperId": "fb3dc5e20e0a71134ca916f0d6d8d41f01225b4b", "title": "Scaling Laws for Reward Model Overoptimization"}, {"paperId": "6fb0b072c4fcdc0c78218bfd1b181fd562f07cd2", "title": "COMPS: Conceptual Minimal Pair Sentences for testing Robust Property Knowledge and its Inheritance in Pre-trained Language Models"}, {"paperId": "7d6f17706cbcfcca55f08485bcbf8c82e00c9279", "title": "Goal Misgeneralization: Why Correct Specifications Aren't Enough For Correct Goals"}, {"paperId": "c90a99eeb57019732a6cc996bb9eaf13faedf00f", "title": "In-context Learning and Induction Heads"}, {"paperId": "eef33138ee3fbef970c74697b46acf60462d690c", "title": "The alignment problem from a deep learning perspective"}, {"paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a", "title": "Emergent Abilities of Large Language Models"}, {"paperId": "bd1331b233e84bab7eba503abc60b31ac08e7881", "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "0286b2736a114198b25fb5553c671c33aed5d477", "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "28c7e583d90ccfc5c3078dfc1d6b80a9ad90248d", "title": "Quantifying Memorization Across Neural Language Models"}, {"paperId": "a6f5b8f114b3eabbcd7f3f62091a481ca6f7f243", "title": "Predictability and Surprise in Large Generative Models"}, {"paperId": "55c36748f2a7c060c3313349c730b053ed03fbf7", "title": "Deduplicating Training Data Mitigates Privacy Risks in Language Models"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "3dc7dc1bea9a4f70c02b6759a0bda7aca0005a9e", "title": "A General Language Assistant as a Laboratory for Alignment"}, {"paperId": "92173d081b15824d22a9ef070e118744ceee8052", "title": "Show Your Work: Scratchpads for Intermediate Computation with Language Models"}, {"paperId": "7d5c661fa9a4255ee087e861f820564ea2e2bd6b", "title": "BBQ: A hand-built bias benchmark for question answering"}, {"paperId": "3ca3ff98405b43fab32dcd7cbd6bd34261386e35", "title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models"}, {"paperId": "77d956cdab4508d569ae5741549b78e715fd0749", "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "d624bc273821c871f899d8256a34be40c09fc3cd", "title": "Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets"}, {"paperId": "b58d8579ece27a60432e667bfbdb750590fa65d9", "title": "True Few-Shot Learning with Language Models"}, {"paperId": "49f905eb03958c7cfae52ac759ea8978b8b2a6ea", "title": "Alignment of Language Agents"}, {"paperId": "ca2f1088d3e581b2c6c75cf0ebc96506d620f64d", "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? \ud83e\udd9c"}, {"paperId": "510a80cc9080e8501187f6b57acf855c182f3b47", "title": "Behavioral Biases in the NFL Gambling Market: Overreaction to News and the Recency Bias"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "053b1d7b97eb2c91fc3921d589c160b0923c70b1", "title": "Learning to summarize from human feedback"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "4d16457cded23bce6eaa91cd17aefd22af2279f0", "title": "Counterfactual Story Reasoning and Generation"}, {"paperId": "7ee12d3bf8e0ce20d281b4550e39a1ee53839452", "title": "Risks from Learned Optimization in Advanced Machine Learning Systems"}, {"paperId": "d9f6ada77448664b71128bb19df15765336974a6", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"}, {"paperId": "1536e8958697c5364f68b2e2448905dbbeb3a0ca", "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "5bbb6f9a8204eb13070b6f033e61c84ef8ee68dd", "title": "Deep Reinforcement Learning from Human Preferences"}, {"paperId": "5ed791f810da580c78df6a052c6b9f2e258f6b0a", "title": "The LAMBADA dataset: Word prediction requiring a broad discourse context"}, {"paperId": "8f71a9729ae782fa0d3b077d8cba97fcc636e70e", "title": "Reasoning about a Rule"}, {"paperId": "4b2137280915ccc0e06e97b604778b05876a34ad", "title": "Evaluating Large Language Models"}, {"paperId": null, "title": "Inverse Scaling Prize"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "a9075f6332542e12b2bf3cdbdb3a6ed44733fb41", "title": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)"}, {"paperId": null, "title": "NeQA: Can Large Language Models Handle Negation in Multi-choice Questions?: Zhengping Zhou and Yuhui Zhang (corresponding author"}, {"paperId": null, "title": "GPT-4, GPT-4 RLHF Unknown No Unknown"}, {"paperId": null, "title": "Hindsight Neglect: The Floating Droid (anonymous)"}, {"paperId": null, "title": "Massachusetts Institute of Technology) and Max Weiss (max_weiss@hms"}, {"paperId": "2f0890baf3a417064c6c5cb4864dea24a127ec65", "title": "University of"}, {"paperId": null, "title": ". . . . . . . . . . . . . . . . . . . . . . . . Mode Collapse in Language Models via Narration Sil Hamilton . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."}, {"paperId": null, "title": "provide financial aid to student presenters"}, {"paperId": null, "title": "Introducing ChatGPT"}, {"paperId": null, "title": "Model index for researchers"}, {"paperId": null, "title": "An important next step on our AI journey, 2023"}, {"paperId": null, "title": "iii) Distractor Task : Examples containing an easy \u201cdistractor\u201d task that can be confused with the harder, real task (\u00a73.3)"}, {"paperId": null, "title": "Claude"}, {"paperId": null, "title": "On the Psychology of Prediction"}]}