{"paperId": "ac994480a05a833b5ac05dd37972a1e5d3b7caa1", "title": "RankMamba, Benchmarking Mamba's Document Ranking Performance in the Era of Transformers", "abstract": "Transformer structure has achieved great success in multiple applied machine learning communities, such as natural language processing (NLP), computer vision (CV) and information retrieval (IR). Transformer architecture\u2019s core mechanism\u2014attention requires O ( n 2 ) time complexity in training and O ( n ) time complexity in inference. Many works have been proposed to improve the attention mechanism\u2019s scalability, such as Flash Attention and Multi-query Attention. A different line of work aims to design new mechanisms to replace attention. Recently, a notable model structure\u2014 Mamba which is based on state space models, has achieved transformer-equivalent performance in multiple sequence modeling tasks. In this work, we examine Mamba \u2019s efficacy through the lens of a classical IR task\u2014document ranking. A reranker model takes a query and a document as input, and predicts a scalar relevance score. This task demands the language model\u2019s ability to comprehend lengthy contextual inputs and to capture the interaction between query and document tokens. We find that (1) Mamba models achieve competitive performance compared to transformer-based models with the same training recipe; (2) but also have a lower training throughput in comparison to efficient transformer implementations such as flash attention. We hope this study can serve as a starting point to explore Mamba models in other classical IR tasks. Our code implementation and trained checkpoints are made public to facilitate reproducibility. 1 .", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Mamba models achieve competitive performance compared to transformer-based models with the same training recipe; but also have a lower training throughput in comparison to efficient transformer implementations such as flash attention."}, "embedding": {"model": "specter_v2", "vector": [0.20130285620689392, 0.20425251126289368, -0.840122640132904, -0.08109060674905777, -0.8942234516143799, -0.058453332632780075, 1.1044808626174927, -0.05867896229028702, -0.43364331126213074, -0.3738286793231964, 0.5778188705444336, -0.20853158831596375, 0.00012740727106574923, 0.43709802627563477, -0.11776784807443619, -0.08212508261203766, -0.7685699462890625, 0.9301931262016296, -0.17088714241981506, -0.672376811504364, 0.28160059452056885, -0.6886482834815979, -1.3575003147125244, 0.43813106417655945, 0.3050525188446045, 0.7139467597007751, 0.11968974024057388, 0.7836103439331055, -0.49749141931533813, 0.4829259216785431, 0.636932373046875, -0.15518473088741302, 0.08815398067235947, 0.140018031001091, -0.9975630640983582, -0.330256849527359, 0.825646162033081, -0.43008047342300415, -0.592943549156189, 0.7613345980644226, -0.3713362216949463, 0.20354999601840973, 0.5801284313201904, -0.6791343688964844, -0.33414793014526367, 0.7668685913085938, 0.535933792591095, 1.0661875009536743, -0.07960723340511322, -0.7474064230918884, 1.6670349836349487, -1.2635680437088013, 0.1330331265926361, 1.2747504711151123, 0.05080346018075943, 0.4879191517829895, -0.2057947963476181, -0.2876207232475281, 0.6539521217346191, 0.5320751667022705, -0.7971234917640686, -0.4176177680492401, -0.21975065767765045, -0.29156988859176636, 1.384361743927002, 0.22124795615673065, -0.26696303486824036, 0.13419246673583984, 0.18774230778217316, 1.5135246515274048, 0.19567108154296875, -0.8419989347457886, -0.18011854588985443, -0.18098574876785278, 0.4165780246257782, 0.7955869436264038, -0.7274476885795593, 0.22187276184558868, -0.9472513794898987, -0.2538391351699829, -0.21003201603889465, -0.03475488722324371, 0.15253950655460358, -0.35089075565338135, -0.22177116572856903, 0.5426314473152161, 0.2158513069152832, 0.7710964679718018, -0.3815805912017822, 0.8793206810951233, 0.013459354639053345, 0.4742010235786438, 0.1429120898246765, 0.5752087235450745, -0.11238094419240952, 0.3568914234638214, -0.7286433577537537, 0.09069332480430603, -0.36212414503097534, 0.31599393486976624, -0.38310912251472473, 0.044252946972846985, -1.2178809642791748, 0.17818664014339447, 1.5304349660873413, -0.04431329295039177, 0.6214451193809509, -0.5472818613052368, -0.027488332241773605, -0.5322927832603455, 0.34595638513565063, -0.49529820680618286, -0.0813852846622467, -0.05144273489713669, -0.767907977104187, -0.9691691398620605, -0.5028899312019348, 1.0693705081939697, -1.0965827703475952, 0.4156959354877472, -0.5372515916824341, -0.03574887290596962, -0.01763933151960373, 0.757615327835083, 0.5509781241416931, 0.6919783353805542, 0.441946804523468, 0.05139017850160599, 1.0904293060302734, -0.5730583667755127, -0.4586777985095978, -0.9832868576049805, 0.5975404381752014, -0.04371561110019684, 0.3891450762748718, 0.19493980705738068, -1.514977216720581, -0.5348259210586548, -0.7301432490348816, 0.2216796576976776, 0.010824845172464848, 0.34413662552833557, 1.0629711151123047, -0.0771932527422905, -1.2298779487609863, 0.7694408893585205, -0.3550887405872345, -0.40619969367980957, 0.23929300904273987, 0.4571286141872406, 0.05487487092614174, -0.590526282787323, -1.2583656311035156, 0.6049672365188599, 0.030893292278051376, -0.2737944722175598, -0.7587116956710815, -0.3185517191886902, -0.5518571734428406, 0.2513391375541687, 0.07736210525035858, -0.27934229373931885, 1.802134394645691, -0.07972696423530579, -1.2220122814178467, 0.4800294041633606, -0.6544798612594604, 0.20506830513477325, 0.22494950890541077, -0.3776150345802307, -0.4512123763561249, -0.5722625851631165, -0.1191064789891243, 0.12942683696746826, 0.3618079721927643, -0.02699793130159378, -0.4142731726169586, 0.3268173038959503, -0.16909392178058624, -0.02783862315118313, -0.3897859454154968, 0.8519566059112549, -0.42719292640686035, 0.21450679004192352, 0.3769918382167816, 0.7978817224502563, -0.402336061000824, -0.5723879933357239, -0.4731728732585907, -1.1762710809707642, 0.2873672544956207, -0.17615212500095367, 1.3163992166519165, -0.5652477145195007, -0.3154907524585724, -0.08642613887786865, -0.06147865951061249, -0.16931648552417755, -0.8802420496940613, 0.6956851482391357, -0.42544904351234436, 0.4977712631225586, -0.20722320675849915, -0.6778686046600342, -0.12123212963342667, -0.510187566280365, -0.5225816965103149, -0.3879508078098297, -0.02795172668993473, 1.2667546272277832, -1.1068058013916016, 0.11768672615289688, 0.08634170889854431, -0.1795334815979004, -0.7281746864318848, 0.8632505536079407, -0.5060279965400696, 0.18717741966247559, -0.21099229156970978, 0.00899029616266489, -0.05783792957663536, -0.894873857498169, 0.7518407702445984, -0.3991895020008087, -0.29010140895843506, 0.6145526766777039, -0.45202627778053284, 1.123456597328186, -0.07375355809926987, 0.4496658742427826, -0.11335821449756622, -0.7486326098442078, -0.0504099540412426, 0.3741644620895386, -0.018407752737402916, -0.8984670042991638, -0.19981269538402557, 0.42542195320129395, -0.7520719170570374, 0.33395278453826904, 0.7258557081222534, 0.9071731567382812, -0.2718830406665802, 0.0667022317647934, 0.44532978534698486, 0.2193620502948761, 0.6174455285072327, 0.5856810808181763, 0.984885573387146, 0.20853032171726227, 0.4206460416316986, -0.5190362334251404, 0.3292792737483978, -0.38431572914123535, -0.4875461161136627, 0.7001118659973145, 0.8211243748664856, 0.3935585021972656, 0.24743805825710297, -1.1610171794891357, -0.19505943357944489, -0.11405541002750397, 0.6982200145721436, 1.8605921268463135, 0.11638631671667099, -0.3629798889160156, -0.19958841800689697, -0.3027224540710449, -0.539331316947937, -0.12085043638944626, -0.2558906674385071, -0.3798176348209381, -0.6403132081031799, -1.265472650527954, 0.26906922459602356, 0.22029933333396912, 0.6641542315483093, -0.4756932854652405, 0.1445205807685852, -0.4873426556587219, -0.196223184466362, -0.12517404556274414, -0.528741717338562, 0.26441076397895813, -0.6675164699554443, -0.371254026889801, 0.432538241147995, -0.16232722997665405, 0.054212357848882675, -0.5154486298561096, 1.270687460899353, -0.08651148527860641, -0.03948911279439926, 0.134749636054039, 0.5214239358901978, -0.6112826466560364, -0.6836124658584595, 0.19791989028453827, 0.2540760934352875, -0.4120078384876251, 0.22211720049381256, 0.5365656614303589, 0.06459534168243408, 0.16925276815891266, -0.6400865912437439, 0.16564562916755676, 0.4900655746459961, 0.310745507478714, 0.7058252692222595, -0.7144271731376648, -0.21009841561317444, -0.8066062331199646, 0.8980507254600525, 0.08634249120950699, -0.9843426942825317, 0.5169287919998169, -1.2122310400009155, 0.0024532771203666925, -0.011655076406896114, -0.6820749044418335, 0.023983629420399666, -0.6976010799407959, 0.517154335975647, -0.10038398951292038, 0.25547221302986145, 0.5292952060699463, 0.3640383780002594, 0.5354968905448914, 0.16465531289577484, 0.3816596269607544, 0.27015775442123413, -0.48656323552131653, 0.8028011322021484, -0.6897907853126526, 0.432115375995636, 0.5516291260719299, 0.19260157644748688, -0.2140018343925476, 0.0538373738527298, -0.5858134627342224, -0.6293967962265015, -0.37541699409484863, 0.19420096278190613, 0.0015803060960024595, 0.09263234585523605, -0.5755065083503723, -1.0393364429473877, -0.17532770335674286, -0.8365198969841003, -0.1406681388616562, 0.22194479405879974, -0.20452362298965454, 0.051524803042411804, -1.4141260385513306, -1.4126349687576294, -0.4208695888519287, -0.7175887227058411, -1.0227634906768799, 0.2754896879196167, -0.11603586375713348, -0.08463407307863235, 0.05457041412591934, 0.4291815757751465, -0.28825077414512634, 1.0515915155410767, -0.8913087248802185, 1.1063085794448853, -0.0781770721077919, -0.5831759572029114, -0.07610894739627838, 0.5286942720413208, 0.22192905843257904, -0.335380494594574, 0.27269211411476135, -0.6422335505485535, 0.3147420883178711, -0.6199014782905579, -0.05994713678956032, 0.43005621433258057, 0.7105255126953125, 0.7119054794311523, -0.20383626222610474, -0.7550643682479858, 0.017162997275590897, 1.1669596433639526, -0.43715372681617737, 0.17183749377727509, 0.5731098055839539, 1.0535883903503418, 0.1006607711315155, 0.12506701052188873, 0.39377936720848083, 0.4180261492729187, 0.6580445170402527, 0.8155178427696228, -0.24714413285255432, 0.41248640418052673, -0.19801096618175507, 0.48217156529426575, 1.4359383583068848, 0.39279791712760925, -0.2951066493988037, -1.2445565462112427, 0.4826011657714844, -1.170671820640564, -1.0561693906784058, 0.4848465621471405, 0.9207836389541626, 0.2368902862071991, -0.9441832900047302, -0.31415683031082153, -0.049836475402116776, 0.2939605712890625, 0.2810223698616028, 0.0140656353905797, -0.439586877822876, 0.3054265081882477, 0.5100605487823486, 0.18304301798343658, 0.8190379738807678, -0.5051189064979553, 0.7571288347244263, 14.952289581298828, 0.7888306379318237, 0.0009591586422175169, 0.3998779356479645, 0.7576557397842407, -0.07209248840808868, -0.4402546286582947, 0.0812271386384964, -1.0349880456924438, -0.11060793697834015, 1.2712920904159546, 0.08536016941070557, 0.6464117169380188, 0.2262381762266159, -0.10334677994251251, 0.27765554189682007, -0.6353911757469177, 0.4662753641605377, 0.4205894470214844, -1.5071271657943726, 0.6234279274940491, 0.23327581584453583, 0.020988259464502335, 0.6837396025657654, 0.851102352142334, 1.0259064435958862, 0.8775334358215332, -0.715527355670929, 0.6217995882034302, 0.6589270234107971, 1.0240492820739746, -0.07464922219514847, 0.49746423959732056, 0.33288630843162537, -0.8256459832191467, -0.5446956753730774, -0.2570156157016754, -1.0504485368728638, 0.10723982751369476, 0.0536244660615921, -0.8035887479782104, -0.38468748331069946, 0.16789455711841583, 0.42862752079963684, 0.10722443461418152, 0.3160274624824524, -0.07996254414319992, 0.6364989280700684, 0.0868496522307396, 0.14090359210968018, -0.09090983867645264, 0.5989155769348145, 0.18723398447036743, -0.4146272540092468, 0.26334235072135925, 0.13800369203090668, 0.40449202060699463, -0.21906737983226776, -0.5449455380439758, -0.19042785465717316, -0.08582548797130585, -0.4120663106441498, -0.04891917482018471, 0.9934027791023254, 0.9058979153633118, 0.1400519609451294, 0.08786947280168533, 0.06860232353210449, 0.5237463712692261, -0.08428893238306046, -0.028735395520925522, 0.30046334862709045, 0.5775246620178223, 0.18791328370571136, -0.19933243095874786, 0.9436163306236267, 0.3665485382080078, -0.2902800142765045, -0.8340380787849426, -0.5543796420097351, 0.4520377814769745, -0.9357011318206787, -0.73408442735672, 1.1303924322128296, 0.09327711164951324, -0.6192741990089417, -0.16483759880065918, -0.6734192371368408, 0.014933153986930847, 0.31668323278427124, -1.3748834133148193, -0.5744369029998779, 0.11376052349805832, -0.4661545157432556, -0.5127497911453247, 0.29121774435043335, 1.2683815956115723, 0.2619050145149231, 0.003144844900816679, -0.27980226278305054, 0.3861497640609741, -0.21598462760448456, -0.3065752387046814, -0.947123646736145, 0.9054923057556152, 0.038298942148685455, 0.41846469044685364, 0.31779661774635315, 0.03134362772107124, 0.32119107246398926, -0.7717080116271973, 0.1312643140554428, 0.8348375558853149, -1.5538123846054077, -0.4236595630645752, -0.6084659695625305, -0.7770834565162659, 0.230504110455513, 0.09584566950798035, -0.25596684217453003, 0.018851565197110176, 0.24746812880039215, -0.5090357065200806, -0.2985061705112457, -0.6275125741958618, 0.0477604977786541, 0.4961174726486206, -0.5884796380996704, -0.20504310727119446, 0.13074147701263428, 0.331205278635025, -0.8215681910514832, -0.2668703496456146, -0.1598207950592041, 0.3253569006919861, 0.12702758610248566, 1.1330442428588867, -0.7567307353019714, 0.6201825737953186, 0.5745932459831238, -0.23595623672008514, -0.660582423210144, -0.6002547740936279, -0.7276144623756409, -0.24938803911209106, 0.0659908577799797, 0.5897727012634277, -0.20771433413028717, 0.24817542731761932, 0.5896407961845398, 0.38330551981925964, -0.4254399836063385, -0.7441425323486328, -0.16523759067058563, -0.2218145728111267, -0.13592638075351715, 0.41164982318878174, -0.12883606553077698, -0.1821388453245163, 0.3996947407722473, 0.014762931503355503, 0.6297823786735535, -0.6038166880607605, -0.559359073638916, 0.28086069226264954, -0.7659791111946106, 0.046516403555870056, -0.3282054364681244, -0.3038839101791382, -1.201735496520996, -0.3224097788333893, -1.2023415565490723, 0.46097850799560547, -1.482922077178955, -0.13435472548007965, 0.06706011295318604, -0.7572021484375, 0.34147489070892334, 0.1924983561038971, -0.4403713643550873, -0.40039846301078796, -0.10540185868740082, -0.9200424551963806, 0.6127068400382996, 0.4630817472934723, -0.9099120497703552, -0.059224240481853485, -0.03786138817667961, -0.23135381937026978, 0.06785930693149567, 0.3553188443183899, -0.6022750735282898, -0.6148830652236938, -1.389980673789978, 0.3933357298374176, 0.16347523033618927, -0.0005726750823669136, -0.5887817740440369, 0.4186770021915436, 0.08177167922258377, -0.2256537824869156, 0.04513787105679512, 0.48417478799819946, -0.6956195831298828, -0.21935036778450012, 0.3538241684436798, -0.9306777119636536, 0.8347005844116211, -0.008151603862643242, -0.5890924334526062, -0.12924660742282867, 0.89141845703125, -0.332022488117218, -0.991134524345398, -0.652104377746582, 0.5201416015625, -0.8181216716766357, -0.07909596711397171, -0.4989035725593567, 0.0817476287484169, -1.1715689897537231, -0.35321488976478577, 0.311086505651474, 0.37594661116600037, -0.1808401197195053, 0.8584158420562744, 0.35736116766929626, -1.1658676862716675, 0.051037173718214035, -0.10527913272380829, 0.040217332541942596, -0.2520764172077179, 0.31980159878730774, 0.5755726099014282, 0.19438134133815765, 0.6620834469795227, 0.2462719827890396, -0.028884151950478554, -0.9865659475326538, -0.024019505828619003, 0.5224939584732056, -0.9578768014907837, 0.20122599601745605, 1.0560047626495361, -0.4851228892803192, -0.9198466539382935, -0.185280442237854, -1.0501832962036133, -0.9556358456611633, -0.48492681980133057, 0.8073627352714539, 0.2544595003128052, 0.04809653386473656, -0.026116786524653435, -0.8498708605766296, -0.025566143915057182, -0.2353883534669876, -0.7560953497886658, 0.3976726830005646, 0.13148266077041626, -0.6476925611495972, 0.4459722638130188, 0.19435341656208038, -0.425231009721756, -0.11145754158496857, -0.6296857595443726, 0.3948434889316559, -0.13653545081615448, 0.4145808815956116, -0.705666720867157, -0.3308129608631134, 0.5686686635017395, 1.1767789125442505, 0.1648108810186386, 0.505342960357666, -0.0024442202411592007, -0.25097036361694336, 0.7551747560501099, 0.19949118793010712, -0.10687477886676788, -0.5172901749610901, 1.0933897495269775, 1.0359147787094116, -0.9239075779914856, 0.4690116047859192, 0.3058999180793762, -0.7788460850715637, 0.36615189909935, 0.38706907629966736, 0.18991486728191376, 0.34512579441070557, -0.4872599244117737, 0.37451985478401184, -0.3127058446407318, -1.310491681098938, -0.48258012533187866, 1.2350125312805176, 0.7628257870674133, 0.6906585097312927, 0.13494069874286652, 0.17342151701450348, 0.7634856700897217, 0.5610334277153015, 0.19400911033153534, 0.36172932386398315, 0.5565293431282043, -0.4298568069934845, -0.2726867198944092, 0.1511377990245819, 1.0261272192001343, -0.9420564770698547, -1.0116177797317505, -0.060586847364902496, 0.7152251601219177, -0.3828650116920471, 0.746377170085907, 0.8813009858131409, -0.37579888105392456, 0.5432029962539673, 0.16541624069213867, 0.2543336749076843, -0.44942915439605713, -0.33922678232192993, -0.42465072870254517, -0.6156643033027649, -0.3768441081047058, -0.04389260709285736, -0.325610488653183, -0.11050871759653091, 0.11104554682970047, 0.22475610673427582, 0.7531581521034241, 0.29439443349838257, 1.1036120653152466, 0.7571619153022766, 0.22165757417678833, -0.5410314202308655, -0.37873804569244385, -0.9726738929748535, -1.2321498394012451, 0.4047788679599762, -0.7677718997001648, 0.15369203686714172, -0.4950031340122223, -0.04839136078953743, -0.5064868330955505]}, "authors": [{"authorId": "2294040252", "name": "Zhichao Xu"}], "references": [{"paperId": "7ed835ecf9f3f6a222ec830e7d8ee40fd809dae5", "title": "Context-aware Decoding Reduces Hallucination in Query-focused Summarization"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "a531e9a328ad1488567fa68c15d5bf30bfb90c78", "title": "Fine-Tuning LLaMA for Multi-Stage Text Retrieval"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "12aaad1dbd3812e9f2791228f20c2d3842165612", "title": "A Lightweight Constrained Generation Alternative for Query-focused Summarization"}, {"paperId": "2c5211cf8433b5e45d0eac70a3cb641fce798bf0", "title": "An In-depth Investigation of User Response Simulation for Conversational Search"}, {"paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8", "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "ef68ac57708ab2745ea71e066868e0d4f1da8d6c", "title": "Zero-shot Clarifying Question Generation for Conversational Search"}, {"paperId": "ead6e2873c776448d38c7596220a5f74b718b60c", "title": "Counterfactual Editing for Search Result Explanation"}, {"paperId": "bb15f3727f827a3cb88b5d3ca48415c09b40a88f", "title": "What Language Model to Train if You Have One Million GPU Hours?"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "4f26132fe5a982f47bba8941dba84cc0d6aa4cbc", "title": "RankT5: Fine-Tuning T5 for Text Ranking with Ranking Losses"}, {"paperId": "6d7d141c75af752ffc0d8a6184cca3f9323d6c74", "title": "Simplified State Space Layers for Sequence Modeling"}, {"paperId": "bae8ea243542daafbdd49831326b0844f464fd2b", "title": "Towards Explainable Search Results: A Listwise Explanation Generator"}, {"paperId": "3f848e8620a1f1ccef544e46b483ceff5cbc7f2a", "title": "Understanding Performance of Long-Document Ranking Models through Comprehensive Evaluation and Leaderboarding"}, {"paperId": "ca444821352a4bd91884413d8070446e2960715a", "title": "On the Parameterization and Initialization of Diagonal State Space Models"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "15190e8b459bd85d546286f7d7da61b4f4f3f58a", "title": "What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?"}, {"paperId": "71e15a9a52dcafca57bff5f310b95e2c7d0cfc87", "title": "Diagonal State Spaces are as Effective as Structured State Spaces"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "ca9047c78d48b606c4e4f0c456b1dda550de28b2", "title": "Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers"}, {"paperId": "dbe87b171bfb789e1d22a047aeeee69105e6fd02", "title": "Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text Models"}, {"paperId": "d69c0ed04ecc852e8c921900d3e7967f74f81263", "title": "Pyserini: A Python Toolkit for Reproducible Information Retrieval Research with Sparse and Dense Representations"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "4aa5d2da9bf906a5c62331ed63f64a23b5eb8f56", "title": "Understanding the Effectiveness of Reviews in E-commerce Top-N Recommendation"}, {"paperId": "ab64ea2c1a9a419b21e8b7ea16f5cf12323a5bc8", "title": "Intra-Document Cascading: Learning to Select Passages for Neural Document Ranking"}, {"paperId": "494e730f73035376736b36cecf2023ea6deb3cbe", "title": "Overview of the TREC 2020 Deep Learning Track"}, {"paperId": "fbda1180145f48d3749c5a6dbef90ce712838e5e", "title": "Rethink Training of BERT Rerankers in Multi-Stage Retrieval Pipeline"}, {"paperId": "1f465b77c7d774da1fa18827e197a6372bbaa63b", "title": "A Zero Attentive Relevance Matching Networkfor Review Modeling in Recommendation System"}, {"paperId": "e1d89e5a9585a28c9530e2e336876d3dd41c021d", "title": "PARADE: Passage Representation Aggregation forDocument Reranking"}, {"paperId": "0964490205fdc38c2f0980c9d778069089ca92e3", "title": "HiPPO: Recurrent Memory with Optimal Polynomial Projections"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "1163d1ffeb57695dafe7084a63dafd5d34004db5", "title": "Overview of the TREC 2019 deep learning track"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "4a75598125bd0be3600d840aec04de40bf03c33b", "title": "Asking Clarifying Questions in Open-Domain Information-Seeking Conversations"}, {"paperId": "7a31e2dcbaa1cf6e9f76084793a02a2a4e4c2d15", "title": "Deeper Text Understanding for IR with Contextual Neural Language Modeling"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "fdfa7dc73dc1fc6772d26f88c72e98b68d1f8498", "title": "Parallelizing Linear Recurrent Neural Nets Over Sequence Length"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "9a68661452f34ad18d40846c365ac332dd34566c", "title": "Efficient Index-Based Snippet Generation"}, {"paperId": "87f40e6f3022adbc1f1905e3e506abad05a9964f", "title": "Distributed Representations of Words and Phrases and their Compositionality"}, {"paperId": "47ced790a563344efae66588b5fb7fe6cca29ed3", "title": "The Probabilistic Relevance Framework: BM25 and Beyond"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "\u201cPre x sums and their applications\u201d"}]}