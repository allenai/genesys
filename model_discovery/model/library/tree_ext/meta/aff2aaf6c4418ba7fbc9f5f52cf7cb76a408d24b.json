{"paperId": "aff2aaf6c4418ba7fbc9f5f52cf7cb76a408d24b", "title": "Modeling Collaborator: Enabling Subjective Vision Classification With Minimal Human Effort via LLM Tool-Use", "abstract": "From content moderation to wildlife conservation, the number of applications that require models to recognize nuanced or subjective visual concepts is growing. Traditionally, developing classifiers for such concepts requires substantial manual effort measured in hours, days, or even months to identify and annotate data needed for training. Even with recently proposed Agile Modeling techniques, which enable rapid bootstrapping of image classifiers, users are still required to spend 30 minutes or more of monotonous, repetitive data labeling just to train a single classifier. Drawing on Fiske's Cognitive Miser theory, we propose a new framework that alleviates manual effort by replacing human labeling with natural language interactions, reducing the total effort required to define a concept by an order of magnitude: from labeling 2,000 images to only 100 plus some natural language interactions. Our framework leverages recent advances in foundation models, both large language models and vision-language models, to carve out the concept space through conversation and by automatically labeling training data points. Most importantly, our framework eliminates the need for crowd-sourced annotations. Moreover, our framework ultimately produces lightweight classification models that are deployable in cost-sensitive scenarios. Across 15 subjective concepts and across 2 public image classification datasets, our trained models outperform traditional Agile Modeling as well as state-of-the-art zero-shot classification models like ALIGN, CLIP, CuPL, and large visual question-answering models like PaLI-X.", "venue": "arXiv.org", "year": 2024, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A new framework is proposed that alleviates manual effort by replacing human labeling with natural language interactions, reducing the total effort required to define a concept by an order of magnitude: from labeling 2,000 images to only 100 plus some natural language interactions."}, "embedding": {"model": "specter_v2", "vector": [0.058373406529426575, 0.4378456771373749, -0.6435472369194031, -0.41948726773262024, -0.1411951184272766, -0.14690354466438293, 0.6859135627746582, -0.27174970507621765, -0.4679909944534302, -0.46446889638900757, 0.12423255294561386, 0.023018134757876396, 0.352934330701828, 0.35329458117485046, -0.05179988965392113, 0.6225429177284241, -0.9716705083847046, 0.26242512464523315, 0.016395114362239838, -0.30647391080856323, -0.03552527353167534, -0.7853342294692993, -1.557498574256897, 0.19811902940273285, 0.38470104336738586, 0.6028683185577393, 0.13432204723358154, 1.0188082456588745, -0.13600404560565948, 0.6272679567337036, 0.24758261442184448, -0.06811213493347168, 0.012663507834076881, 0.3847608268260956, -0.1837834119796753, 0.591217041015625, 0.7075644731521606, -0.24482950568199158, 0.0366513654589653, 0.6037778854370117, -0.349001407623291, 0.22250457108020782, 0.595913290977478, -1.3709449768066406, -0.7635210752487183, 0.24852198362350464, 0.331887811422348, 0.2656713128089905, 0.07740678638219833, -0.46413183212280273, 1.556575059890747, -1.5644546747207642, 0.5713824033737183, 1.589289903640747, 0.6154872179031372, 0.4486218988895416, -0.2932584881782532, -0.3590966761112213, 0.9980103373527527, 0.2954023480415344, -0.8006370663642883, 0.09591635316610336, -0.5252017974853516, -0.6581518054008484, 0.9607789516448975, -0.6306023001670837, -0.12259462475776672, 0.1930379569530487, -0.1712576299905777, 1.4022138118743896, 0.02391936257481575, -0.9680970907211304, 0.1517370194196701, 0.19260571897029877, 0.4202018976211548, 1.2388112545013428, -0.42015552520751953, -0.12719301879405975, -0.9869393706321716, -0.12026652693748474, 0.40421512722969055, -0.03269948810338974, -0.20831461250782013, -0.45674851536750793, -0.19434760510921478, 0.7901812791824341, 0.6330077648162842, 0.32778796553611755, 0.21978192031383514, 0.7041090726852417, 0.25022709369659424, 0.26175379753112793, 0.001916653593070805, 0.13899977505207062, -0.08006738871335983, 0.5658011436462402, -0.3490433096885681, 0.4956827461719513, 0.00223352899774909, 0.9701520800590515, -0.08904899656772614, -0.40300172567367554, -0.5975416898727417, 0.16612164676189423, 1.5613861083984375, -0.0454961396753788, 0.3576095998287201, -1.014280080795288, -0.2324322909116745, -0.5320619344711304, 0.8377010226249695, -0.33897870779037476, -0.30718934535980225, 0.10010121762752533, -0.3437616527080536, -0.5493482351303101, -0.3949802815914154, 0.2644513249397278, -1.1569617986679077, 0.6190750598907471, -0.43833911418914795, -0.320501446723938, -0.3171105980873108, 0.7420571446418762, 0.4748837947845459, 0.38821789622306824, 0.8243662118911743, 0.5107914805412292, 0.9981914162635803, -0.8597005009651184, -0.19510476291179657, -1.1663336753845215, 0.5364795923233032, -0.2393934428691864, 0.8624910116195679, -0.422674298286438, -0.995085597038269, -1.1690289974212646, -0.9887157082557678, -0.13623736798763275, -0.5489123463630676, 0.9582603573799133, 1.2172635793685913, 0.4631817936897278, -1.1508296728134155, 0.07874737679958344, 0.15596389770507812, -0.4495105445384979, 0.4266241490840912, -0.2883656620979309, 0.22717665135860443, -0.8823423385620117, -0.8117176294326782, 0.4827459156513214, -0.2677655518054962, -0.8995047807693481, -0.5560317039489746, -0.34681493043899536, -1.204144835472107, -0.34728243947029114, 0.4674205780029297, -0.5643678903579712, 1.5896449089050293, -0.7800626754760742, -0.29814639687538147, 0.7605843544006348, -0.4421127438545227, 0.21093246340751648, 0.2947257161140442, -0.5563982725143433, -0.4422549903392792, -0.270200252532959, 0.19142980873584747, 1.0283290147781372, 0.6252206563949585, -0.782012939453125, -0.5033884644508362, 0.5383508205413818, 0.5937992930412292, -0.04385002329945564, -0.11226297914981842, 0.9956201910972595, -0.10790206491947174, 0.11297865211963654, 0.12254506349563599, 0.7672253251075745, -0.12768419086933136, 1.0336904525756836, 0.4857707619667053, -1.2302988767623901, 0.8573781251907349, 0.1587577909231186, 0.3556881546974182, -0.9490013122558594, -0.7683823704719543, -0.46842771768569946, 0.36399734020233154, -0.16241207718849182, -0.930370569229126, 0.3526674211025238, -0.011056584306061268, 0.6550586223602295, -0.17041359841823578, -1.3337219953536987, 0.01985597424209118, -0.14354413747787476, -0.30383774638175964, -0.11304410547018051, -0.0035858408082276583, 0.9397426247596741, -0.9506208300590515, -0.14336293935775757, -0.08710997551679611, 0.14929042756557465, -0.6944510340690613, 1.1496347188949585, -0.9717023372650146, -0.2180679738521576, 0.2752816379070282, 0.18683871626853943, 0.3447161316871643, -0.6063571572303772, 0.15754489600658417, -0.507710874080658, -0.18455387651920319, -0.08754531294107437, -0.1859356164932251, 1.5668329000473022, -0.2610156238079071, 0.6225065588951111, 0.027063876390457153, -0.4020416736602783, 0.18569590151309967, 0.34003493189811707, -0.3195219337940216, 0.0212637260556221, -0.13004754483699799, 0.05982736125588417, -0.7888765931129456, -0.1912691742181778, 0.4543299674987793, 0.6873576045036316, -0.30904334783554077, 0.16541987657546997, 0.5629552006721497, -0.34782299399375916, 0.44448322057724, 0.22026392817497253, 0.6055461764335632, 0.5053327679634094, 0.19456548988819122, -0.05866920202970505, 0.3360002636909485, -0.5546478033065796, -0.13859054446220398, 0.6944525837898254, 0.08522346615791321, 0.8926272392272949, 0.31294625997543335, -1.1454685926437378, -0.3461325168609619, -0.12473137676715851, 0.7443484663963318, 1.8364624977111816, 0.2766082286834717, -0.3976753354072571, -0.5860702395439148, -0.6354346871376038, -0.35559186339378357, 0.021887773647904396, -0.6599873304367065, 0.19476304948329926, -0.174751415848732, -0.6304146647453308, 0.35384926199913025, 0.4246011972427368, 1.3266706466674805, -0.29375946521759033, -0.5598906874656677, -0.7244291305541992, 0.0077399881556630135, -0.4597495198249817, -0.6912516355514526, 0.062171511352062225, 0.2777233123779297, -0.08368589729070663, -0.027808308601379395, -0.41865551471710205, 0.4669329822063446, 0.24493564665317535, 1.3108575344085693, -0.01127844862639904, -0.7733879089355469, 0.7295647859573364, 0.04074358940124512, -0.9776808619499207, -0.25230473279953003, -0.3403729796409607, -0.2770083248615265, -0.4634276330471039, 0.42462918162345886, 0.7004193067550659, 0.06740432977676392, 0.7468731999397278, -0.5943936705589294, 0.3237299621105194, 0.014044874347746372, -0.05396021157503128, 0.33346670866012573, -0.40405091643333435, -0.05344986170530319, -0.8101803064346313, 0.6106324195861816, -0.18810206651687622, -0.16812068223953247, 0.6234939098358154, -0.5209996104240417, -0.8640190958976746, 0.09874045103788376, -1.0111618041992188, -0.18657146394252777, -0.7922894954681396, 1.0199551582336426, -0.0259565319865942, -0.4669989347457886, 0.36602073907852173, 0.14546777307987213, -0.16871467232704163, 0.7441835999488831, 8.128576882882044e-05, 0.43556010723114014, 0.27085086703300476, 0.7480568885803223, -0.7193161845207214, 0.4027855098247528, 0.027924519032239914, 0.269195020198822, 0.265464723110199, -0.15018391609191895, -0.5665096640586853, -1.016889214515686, -0.4811124801635742, -0.29092875123023987, -0.8761674761772156, 0.25805070996284485, -0.8601043224334717, -0.6044806838035583, -0.23592600226402283, -1.2453536987304688, -0.13495302200317383, 0.23260745406150818, -0.6395015716552734, -0.17778313159942627, -0.9926495552062988, -0.29694950580596924, -0.7693356871604919, 0.045985981822013855, -0.5998563170433044, 0.3917045593261719, 0.12363315373659134, -0.2968667149543762, -0.2346731722354889, -0.15808914601802826, 0.08805669099092484, 0.7982883453369141, -0.27518966794013977, 0.859970211982727, 0.7098673582077026, -0.4518289268016815, -0.4277288019657135, -0.31830906867980957, 0.43646883964538574, -0.40503254532814026, 0.14425265789031982, -0.6750104427337646, 0.32423168420791626, -0.3720468580722809, -0.8252751231193542, 0.1477721780538559, 0.3654508888721466, 0.8799859881401062, 0.6458877921104431, -0.0751982107758522, -0.14505955576896667, 1.485357403755188, -0.9122762084007263, -0.14837464690208435, -0.08830007910728455, 0.8594691157341003, 0.57831209897995, 0.245530903339386, 0.47809016704559326, 0.9318331480026245, 0.16208961606025696, 0.2584782838821411, -0.43986576795578003, -0.43589845299720764, -0.7296597957611084, 0.48469892144203186, 0.4414679706096649, -0.08653630316257477, -0.18521204590797424, -1.340976595878601, 0.602280855178833, -1.7570490837097168, -0.44498857855796814, 0.5920161008834839, 0.47628188133239746, -0.2501087188720703, -0.6077709197998047, -0.10095126926898956, -0.6721200346946716, 0.681364119052887, 0.2670642137527466, -0.31814002990722656, -0.020725643262267113, -0.0682889074087143, 0.019443044438958168, 0.0966891422867775, 0.4512338936328888, -0.687366247177124, 0.25877270102500916, 14.86294174194336, 0.710113525390625, 0.23475714027881622, 0.9911563396453857, 0.8384625315666199, 0.5212377309799194, -0.6364476084709167, 0.08139753341674805, -1.0196290016174316, -0.6560370326042175, 1.0311273336410522, 0.12406633049249649, 0.3047681748867035, 0.3403335213661194, 0.19106200337409973, -0.2984020411968231, -0.4148978292942047, 0.6230135560035706, 1.129831314086914, -1.184522271156311, 0.462208092212677, -0.08906932175159454, 0.29670602083206177, 0.005148158874362707, 0.8770256638526917, 0.7392235994338989, 0.4736787974834442, -0.8543489575386047, 0.819890558719635, 0.3397279381752014, 1.119832158088684, 0.050100889056921005, 0.440879762172699, 0.8145806193351746, -1.0246310234069824, -0.3112410604953766, -0.8868958950042725, -1.2111643552780151, 0.31721389293670654, -0.28542420268058777, -0.4749435782432556, -0.5259760618209839, -0.25152069330215454, 0.46305325627326965, 0.017219502478837967, 0.40096384286880493, -0.25863298773765564, 0.3772117793560028, 0.35618650913238525, -0.2240416705608368, -0.22147797048091888, 0.946194589138031, -0.026576340198516846, -0.37924250960350037, -0.1275743544101715, -0.08164983987808228, 0.7747703194618225, 0.47773075103759766, -0.5569422841072083, -0.11773528158664703, -0.2571290135383606, -0.08601363748311996, -0.31230953335762024, 0.8343220353126526, 0.41006553173065186, 0.5366121530532837, -0.6465814113616943, -0.02405974268913269, 0.5611165165901184, 0.09263446927070618, -0.40923741459846497, 0.45684918761253357, 0.4227367043495178, 0.008257165551185608, -0.23081724345684052, 0.10681294649839401, -0.23624128103256226, -0.6714456081390381, -0.4832174479961395, 0.01377943530678749, 0.24936677515506744, -1.2650471925735474, -1.0052686929702759, 0.7277690172195435, 0.008836970664560795, -0.8388546705245972, 0.35705533623695374, -0.8537372946739197, -0.3454665243625641, 0.3277829587459564, -1.4743727445602417, -1.732951283454895, -0.4570212960243225, -0.4474228322505951, 0.039124634116888046, 0.07311180979013443, 1.4870586395263672, -0.2645632326602936, 0.33330976963043213, -0.2417885810136795, -0.5069600343704224, -0.4461558163166046, 0.29969483613967896, -0.7865519523620605, 0.4584597051143646, 0.010301237925887108, -0.19713148474693298, -0.00041989542660303414, 0.06279180198907852, 0.11562465131282806, -0.3928440511226654, -0.04155696555972099, 0.5818008184432983, -1.0924427509307861, -0.32763370871543884, -0.8306163549423218, -0.5269052386283875, 0.05524145066738129, 0.3413739502429962, 0.08811639249324799, 0.6469452977180481, 0.3488503694534302, -0.9576403498649597, 0.010562079958617687, -1.1578946113586426, -0.06440754979848862, 0.5194194316864014, -0.6701160073280334, -0.38337573409080505, 0.34451714158058167, 0.17901566624641418, -0.5678268671035767, -0.07023973762989044, -0.22583146393299103, 0.38959652185440063, -0.2991968095302582, 0.8392266631126404, -0.3416343927383423, 0.9413906931877136, 0.2621186375617981, -0.11026903986930847, -0.6589072346687317, -0.3367401659488678, -0.39088526368141174, 0.2558828592300415, 0.03652290627360344, 0.6128404140472412, -0.0689844861626625, 0.15820948779582977, 0.991798996925354, 0.6077256202697754, -0.24587278068065643, -0.3748983144760132, 0.17188449203968048, 0.08984654396772385, -0.6439889073371887, 0.1297946274280548, -0.17850422859191895, -0.12371312826871872, -0.021854829043149948, 0.32441142201423645, 0.753273069858551, -0.1000676155090332, -0.3986750841140747, 0.626422107219696, -0.4126094877719879, -0.1131756529211998, -0.08478055149316788, -0.650477409362793, -1.1904939413070679, -0.02865123748779297, -0.5958704352378845, 0.3843998312950134, -0.8533947467803955, -0.29666832089424133, 0.2247077077627182, 0.054071053862571716, 0.012465192005038261, 0.2565247416496277, -0.057290010154247284, -0.1800059974193573, -0.38933277130126953, -0.7215972542762756, 0.26392897963523865, 0.9899775385856628, -0.6223927140235901, 0.631923258304596, -0.11966226249933243, -0.26366540789604187, 0.7095136642456055, 0.18281137943267822, 0.15138792991638184, -1.0348081588745117, -1.2331430912017822, 0.43895190954208374, -0.42936432361602783, 0.45004570484161377, -0.8442912101745605, 0.4966023862361908, 0.14523720741271973, 0.023986656218767166, 0.028421197086572647, 0.4933153986930847, -0.7752251029014587, -0.7529427409172058, 0.10737569630146027, -1.0211445093154907, 0.05382126197218895, -0.027370212599635124, -0.24483656883239746, -0.04594255983829498, 0.2303576022386551, 0.028714345768094063, -1.3597177267074585, -1.0698037147521973, 0.14937788248062134, -0.6681239008903503, -0.21738466620445251, -0.11174343526363373, 0.29280439019203186, -1.2809641361236572, -0.7759823203086853, 0.045396603643894196, 0.4945774972438812, 0.06054048240184784, 0.8919814825057983, 0.4891597330570221, -1.1228646039962769, -0.009969922713935375, 0.009961188770830631, 0.35770973563194275, -0.02896888181567192, 0.5721724033355713, -0.15148882567882538, -0.09378910064697266, -0.13231150805950165, -0.010477602481842041, 0.31713974475860596, -0.8112685084342957, -0.18916092813014984, 0.4930654764175415, 0.003474043682217598, 0.23727741837501526, 1.2920098304748535, -0.06537003070116043, -0.8735253214836121, 0.2648889720439911, -0.7800714373588562, -0.6514934301376343, -0.4041188359260559, 0.9071605205535889, -0.18674255907535553, -0.4518461525440216, -0.04295053705573082, -0.4288274645805359, 0.36469054222106934, -0.19537898898124695, -0.6897984147071838, 0.38275986909866333, -0.4079251289367676, -0.27119138836860657, 0.8816171288490295, 0.4204384684562683, -0.8241538405418396, -0.9690506458282471, -0.39040592312812805, -0.4509962797164917, -0.5142192840576172, 0.2675938308238983, -0.8192993402481079, 0.1544474959373474, 0.6872435808181763, 0.9086924195289612, 0.2589987516403198, 0.09294053912162781, 0.23447886109352112, -0.12267982959747314, 0.3976769745349884, 0.34303969144821167, -0.6412767171859741, -0.3367176651954651, 0.7448975443840027, 1.420790672302246, -1.167850136756897, 0.6043931245803833, -0.5720376968383789, -0.7838321328163147, 0.9751663208007812, 0.7806390523910522, -0.039926912635564804, 0.9444394707679749, -0.3437477648258209, 0.3054245412349701, 0.05418090149760246, -1.0273123979568481, -0.2771737575531006, 1.0199445486068726, 1.5753796100616455, 0.8703711032867432, 0.6950778961181641, -0.20671460032463074, 0.6839271187782288, 0.28146007657051086, 0.60505610704422, 0.7591274976730347, 0.6950770020484924, -0.4813147485256195, -0.09743025153875351, 0.13744646310806274, 0.4916508197784424, 0.25226229429244995, -0.049564361572265625, 0.14283281564712524, 0.40218397974967957, 0.9247095584869385, 0.681830883026123, 0.8522908091545105, 0.24122846126556396, 0.17104487121105194, 0.23311671614646912, 0.443925142288208, -0.9943451881408691, 0.08525694906711578, -0.4181049168109894, -0.3741972744464874, 0.14838719367980957, -0.9396587014198303, -0.7625460624694824, -0.2684641182422638, 0.0632282942533493, 0.4215092658996582, -0.4276202321052551, 0.3359280228614807, 1.22318434715271, 0.5087641477584839, -0.003236998338252306, -0.5096043348312378, -0.6095666289329529, -0.11574023962020874, -1.062071442604065, 0.2946539521217346, -0.6700562238693237, -0.15646398067474365, -0.9591334462165833, -0.4713734984397888, 0.2151716649532318]}, "authors": [{"authorId": "2091570185", "name": "Imad Eddine Toubal"}, {"authorId": "2209988101", "name": "Aditya Avinash"}, {"authorId": "3016019", "name": "N. Alldrin"}, {"authorId": "16026105", "name": "Jan Dlabal"}, {"authorId": "2439768", "name": "Wenlei Zhou"}, {"authorId": "2270672353", "name": "Enming Luo"}, {"authorId": "3397269", "name": "Otilia Stretcu"}, {"authorId": "2290000812", "name": "Hao Xiong"}, {"authorId": "2270331880", "name": "Chun-Ta Lu"}, {"authorId": "2290352183", "name": "Howard Zhou"}, {"authorId": "2262217505", "name": "Ranjay Krishna"}, {"authorId": "2270670157", "name": "Ariel Fuxman"}, {"authorId": "2066508193", "name": "Tom Duerig"}], "references": [{"paperId": "b844ae48660313c5354b274073336faf9c2fcc34", "title": "Non-Intrusive Adaptation: Input-Centric Parameter-efficient Fine-Tuning for Versatile Multimodal Modeling"}, {"paperId": "68e0e789b5147b1e7d028c7a825650075f4e26bf", "title": "PaLI-3 Vision Language Models: Smaller, Faster, Stronger"}, {"paperId": "bee68767debbdc96d6f75947e544a8be98b869e3", "title": "Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond"}, {"paperId": "f8a2dca1e8fe56e698984c077f7ff58d8ca867e9", "title": "Large Language Models as Optimizers"}, {"paperId": "bcfa73aedf1b2d1ee4f168e21298a37ac55a37f7", "title": "Bias and Fairness in Large Language Models: A Survey"}, {"paperId": "446fb5dead075a1a08862662738f462e9a0e91c8", "title": "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "d98536f24272e258b1d399074b64284d64786099", "title": "AVIS: Autonomous Visual Information Seeking with Large Language Models"}, {"paperId": "7a1e71cb1310c4a873e7a4e54d1a6dab0553adce", "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"}, {"paperId": "3099d6f4965b4d73aa1e2b2880522ec89ed2dc0a", "title": "PaLI-X: On Scaling up a Multilingual Vision and Language Model"}, {"paperId": "7cf64070fd3d7e53d80f260c10e6bd7018d580e1", "title": "IdealGPT: Iteratively Decomposing Vision and Language Reasoning via Large Language Models"}, {"paperId": "b6d6c33298b852cf63edac233deca70530d69a2a", "title": "PaLM 2 Technical Report"}, {"paperId": "20fcc01d12a50f1da2af71d85f0a269b3ba48b77", "title": "LMEye: An Interactive Perception Network for Large Language Models"}, {"paperId": "170c97c7215f42edfb20c2248f954879e91ef86e", "title": "Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models"}, {"paperId": "c7a9c7302a72301ed79a7c0696d5af2e03ad3ac4", "title": "MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action"}, {"paperId": "6e754273d54a91371efbc928cd6b156364d517da", "title": "ViperGPT: Visual Inference via Python Execution for Reasoning"}, {"paperId": "af997821231898a5f8d0fd78dad4eec526acabe5", "title": "Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models"}, {"paperId": "53d128ea815bcc0526856eb5a9c42cc977cb36a7", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools"}, {"paperId": "26590b0c0e22b8c06c31ad51eda4fbab00a85e80", "title": "@ CREPE: Can Vision-Language Foundation Models Reason Compositionally?"}, {"paperId": "3e8251f259dc529b3aa2366fc68c1516b202cfb9", "title": "Reveal: Retrieval-Augmented Visual-Language Pre-Training with Multi-Source Multimodal Knowledge Memory"}, {"paperId": "e5c8960eb2ec034ffbd353ef39fd1cb541d3c7c9", "title": "LAION-5B: An open large-scale dataset for training next generation image-text models"}, {"paperId": "e070ff286709db28312e08b52b05539debe88146", "title": "Measuring and Narrowing the Compositionality Gap in Language Models"}, {"paperId": "28630034bb29760df01ab033b743e30b37f336ae", "title": "PaLI: A Jointly-Scaled Multilingual Language-Image Model"}, {"paperId": "007fe51fddfae031570f2d69e67dc67e1fe33621", "title": "What does a platypus look like? Generating customized prompts for zero-shot image classification"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "8f167ec1149921fac63b1ea855443de109bb013a", "title": "How Much Can CLIP Benefit Vision-and-Language Tasks?"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "141a5033d9994242b18bb3b217e79582f1ee9306", "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "3f6570fd55dc5855f93a56150e6d99c7944a1c1e", "title": "The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes"}, {"paperId": "d1242ba8fdb994b82a0575dc92f30f7b26a75707", "title": "Action Genome: Actions As Compositions of Spatio-Temporal Scene Graphs"}, {"paperId": "79c93274429d6355959f1e4374c2147bb81ea649", "title": "LXMERT: Learning Cross-Modality Encoder Representations from Transformers"}, {"paperId": "f883427cda5d3b02f0087e48985e4d820d0d8038", "title": "Graph-RISE: Graph-Regularized Image Semantic Embedding"}, {"paperId": "5ac18d505ed6d10e8692cbb7d33f6852e6782692", "title": "The Open Images Dataset V4"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "b99432677d0f7857c980271179e7cab88aab2717", "title": "Automated Detection of Substance Use-Related Social Media Posts Based on Image and Text Analysis"}, {"paperId": "79554caf84ce3b7fb5434737505ba6a7549189b2", "title": "Zero-shot image classification"}, {"paperId": "819046fb29e25f37f9ad60f8f4d5116ad8412220", "title": "Smart Content Recognition from Images Using a Mixture of Convolutional Neural Networks"}, {"paperId": "7e232313a59d735ef7c8a9f4cc7bc980a29deb5e", "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"}, {"paperId": "4d9506257186023b78cf19ed4f9e77a4ae4fa0f0", "title": "Visual Relationship Detection with Language Priors"}, {"paperId": "fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b", "title": "Hierarchical Question-Image Co-Attention for Visual Question Answering"}, {"paperId": "afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d", "title": "Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "0e89a45cb30f3e488fa14f74cc8ee7a209199638", "title": "Understanding and Predicting Image Memorability at a Large Scale"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "ea1dcb68622e40e3fa3864540a434b4c8645c0fa", "title": "Begriffsschrift, a formula language, modeled upon that of arithmetic, for pure thought GOTTLOB FREGE(1879)"}, {"paperId": "2bb39b69dd500a06dc4ae7fee468280dd0ed54f4", "title": "Agile Modeling: Image Classification with Domain Experts in the Loop"}, {"paperId": "1a4c6856292b8c64d19a812a77f0aa6fd47cb96c", "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework"}, {"paperId": "7a29f47f6509011fe5b19462abf6607867b68373", "title": "GPT-4V(ision) System Card"}, {"paperId": "d1120d67b700e4dfe8b39eb1e48fbdea4e1a0c43", "title": "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Burr Settles"}, {"paperId": "a15174ed603bae1b101c4655111bb511787b95b4", "title": "The magical number seven plus or minus two: some limits on our capacity for processing information."}, {"paperId": null, "title": "The prompt for generating negative search queries based a visual concept (used to fetch hard negative images from image database)"}, {"paperId": null, "title": "a single sneaker on a white or neutral-colored background (e.g beige)"}, {"paperId": null, "title": ". use positive attributes for questions : Whether to generate positive questions from the attributes or directly from the concept description"}, {"paperId": null, "title": "Your task is to understand the scope of (cid:44) \u2192 a visual concept for image (cid:44) \u2192 classification"}, {"paperId": null, "title": "ear headphones : Any headphones that are worn inside the ear, rather than covering it up. These types of head-phones are inserted into the ear canal"}, {"paperId": null, "title": "B. generate negative questions"}, {"paperId": null, "title": "step3>Provide all the image attributes (cid:44) \u2192 that an image must have in order (cid:44) \u2192 to be in-scope for this visual (cid:44) \u2192 concept."}, {"paperId": null, "title": "house, scented candles, essential oils"}, {"paperId": null, "title": "generate fixed num of questions : Fix the number of questions instead of having the LLM generate as many questions as possible"}, {"paperId": null, "title": "step7>Write your response in following (cid:44) \u2192 user friendly and readable (cid:44) \u2192 format"}, {"paperId": null, "title": "Pie chart : Any image with a pie chart, which is a circular statistical graphic, which is divided into slices to illustrate numerical proportion. Single sneaker on white background : Images depicting"}, {"paperId": null, "title": "step2>Ifthedescriptionprovides (cid:44) \u2192 details on out-of-scope images (cid:44) \u2192 for this visual concept, output (cid:44) \u2192 the list of those carve-outs (cid:44) \u2192 situations mentioned."}, {"paperId": null, "title": "Visual concept definition"}, {"paperId": null, "title": "step2>Provide an concept definition of (cid:44) \u2192 this visual image in a few (cid:44) \u2192 sentences"}, {"paperId": null, "title": "List all the attributes of an (cid:44) \u2192 image that make it in-scope for (cid:44) \u2192 this visual concept"}, {"paperId": null, "title": "Each search query should be 3-4 (cid:44) \u2192 words long, independent, self-(cid:44) \u2192 explanatory and meaningful for (cid:44) \u2192 internet image search"}, {"paperId": null, "title": "Check that attributes you have (cid:44) \u2192 found cover all the positive (cid:44) \u2192 attributes mentioned in the (cid:44) \u2192 description. If not, add the (cid:44) \u2192 missing attributes"}, {"paperId": null, "title": "Hair coloring : Pictures that focus on people during the process of hair coloring or right after, before & after photos Negatives: store front of hairdresser, boxes of dye"}, {"paperId": null, "title": "<Add 2-3 line concept definition of the (cid:44) \u2192 visual concept here"}, {"paperId": null, "title": "Falcon-40B: an open large language model with state-of-the-art performance"}, {"paperId": null, "title": "You are given the name and description (cid:44) \u2192 of a visual concept. We showed (cid:44) \u2192 the image to raters and asked 15"}, {"paperId": null, "title": "Multi-modal dual-tower architectures for entity retrieval from image and text"}, {"paperId": null, "title": "You have to work as an expert linguist. (cid:44) \u2192 You are given a visual concept (cid:44) \u2192 name and its description for the (cid:44) \u2192 purpose of image classification"}, {"paperId": null, "title": "the image has EVEN ONE of (cid:44) \u2192 the out-of-scope attributes, it (cid:44) \u2192 must be classified negative for (cid:44) \u2192 this visual concept"}, {"paperId": null, "title": "Provide the the in-scope (cid:44) \u2192 attributes missing in the image (cid:44) \u2192"}, {"paperId": null, "title": "step2>Each attribute should be (cid:44) \u2192 objective, unambiguous, detailed, (cid:44) \u2192 verbose and self-explanatory.</ (cid:44) \u2192 step2>"}]}