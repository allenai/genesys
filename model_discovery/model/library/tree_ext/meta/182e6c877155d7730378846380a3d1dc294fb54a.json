{"paperId": "182e6c877155d7730378846380a3d1dc294fb54a", "title": "InceptionNeXt: When Inception Meets ConvNeXt", "abstract": "Inspired by the long-range modeling ability of ViTs, large-kernel convolutions are widely studied and adopted recently to enlarge the receptive field and improve model performance, like the remarkable work ConvNeXt which employs 7x7 depthwise convolution. Although such depthwise operator only consumes a few FLOPs, it largely harms the model efficiency on powerful computing devices due to the high memory access costs. For example, ConvNeXt-T has similar FLOPs with ResNet-50 but only achieves 60% throughputs when trained on A100 GPUs with full precision. Although reducing the kernel size of ConvNeXt can improve speed, it results in significant performance degradation. It is still unclear how to speed up large-kernel-based CNN models while preserving their performance. To tackle this issue, inspired by Inceptions, we propose to decompose large-kernel depthwise convolution into four parallel branches along channel dimension, i.e. small square kernel, two orthogonal band kernels, and an identity mapping. With this new Inception depthwise convolution, we build a series of networks, namely IncepitonNeXt, which not only enjoy high throughputs but also maintain competitive performance. For instance, InceptionNeXt-T achieves 1.6x higher training throughputs than ConvNeX-T, as well as attains 0.2% top-1 accuracy improvement on ImageNet-1K. We anticipate InceptionNeXt can serve as an economical baseline for future architecture design to reduce carbon footprint. Code is available at https://github.com/sail-sg/inceptionnext.", "venue": "arXiv.org", "year": 2023, "citationCount": 47, "influentialCitationCount": 5, "openAccessPdf": {"url": "http://arxiv.org/pdf/2303.16900", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes to decompose large-kernel depthwise convolution into four parallel branches along channel dimension, i.e. small square kernel, two orthogonal band kernels, and an identity mapping, and builds a series of networks, namely IncepitonNeXt, which not only enjoy high throughputs but also maintain competitive performance."}, "embedding": {"model": "specter_v2", "vector": [0.4370814263820648, 0.5099602341651917, -0.27795517444610596, 0.1060599759221077, 0.3488590121269226, 0.0020363677758723497, 0.7725011110305786, -0.5833685398101807, -0.7939374446868896, -0.6432564854621887, 0.12822937965393066, -0.07907665520906448, 0.7064304351806641, 0.0114343436434865, -0.30984482169151306, 0.08798107504844666, -0.7297914624214172, -0.5287379026412964, 0.6094852089881897, -0.25279471278190613, 0.15529271960258484, -0.2574193477630615, -1.300628423690796, 0.5574677586555481, 0.08091111481189728, 1.4024580717086792, 0.24523133039474487, 0.908664882183075, -0.17840935289859772, 0.6901283264160156, 0.6382826566696167, -0.662458062171936, 0.49723589420318604, 0.3499186635017395, -0.45472270250320435, -0.3504846394062042, 0.5091186761856079, -0.3029983341693878, -0.4088127315044403, 0.9465044736862183, -0.2602468729019165, 0.44015446305274963, 0.21554118394851685, -0.8797538876533508, -0.07292655110359192, 0.526461124420166, 0.7273954749107361, 0.6621419191360474, -1.4145370721817017, -0.2168734222650528, 0.889771580696106, -1.0185277462005615, 0.2706552743911743, 0.9802758693695068, 0.9600774645805359, 0.24522283673286438, -0.3704264461994171, -0.4557003676891327, 0.4971097707748413, 0.041305627673864365, -0.6896185278892517, -0.10675741732120514, 0.024935809895396233, 0.005256948992609978, 1.9694725275039673, -0.5222690105438232, 0.2232264280319214, 0.7635315656661987, 0.34173622727394104, 1.0431040525436401, 0.036089781671762466, -0.56202232837677, -0.22534742951393127, -0.04654086381196976, 0.4430995583534241, 0.44053348898887634, -0.2280476689338684, 0.3992393910884857, -0.4759255647659302, 0.21126104891300201, 0.8493372201919556, 0.7448009848594666, 0.504830539226532, 0.13669367134571075, -0.4408654570579529, 0.5473592877388, 1.0086627006530762, 0.5838081240653992, -0.6814190149307251, 1.3616310358047485, 0.7287071943283081, 0.1367545872926712, -0.17605847120285034, 0.37259796261787415, -0.05817907303571701, 0.5888921022415161, -0.6343666911125183, -0.0767216607928276, -0.5608212351799011, 0.8446851372718811, 0.09686802327632904, 0.4054397940635681, -0.08904951810836792, 0.10450692474842072, 0.9225195050239563, -0.13520129024982452, 0.5978150963783264, -0.8516209721565247, -0.08111771941184998, -0.43114131689071655, -0.47931551933288574, -0.4640931487083435, 0.21380847692489624, -0.34707188606262207, -1.1450426578521729, -0.5887835025787354, -0.4876987934112549, 0.027068398892879486, -0.9212307929992676, 0.19535104930400848, -0.4462074935436249, 0.37121641635894775, 0.3217591345310211, 0.2341853678226471, 0.5875959396362305, 0.3764090836048126, 0.2618130147457123, 0.6800500750541687, 1.1895568370819092, -1.525032877922058, -0.1687324196100235, -0.8534678220748901, 0.2206297218799591, -0.23779185116291046, -0.49139997363090515, -0.13305392861366272, -0.9618940949440002, -1.4818980693817139, -0.8316550254821777, 0.15763108432292938, -1.1629990339279175, -0.09048070758581161, 1.4297105073928833, 0.12965801358222961, -1.0677874088287354, 1.2574338912963867, -0.6138354539871216, -0.3140186369419098, 0.2804231345653534, 0.19765371084213257, 0.2503435015678406, 0.254548579454422, -1.0743910074234009, 0.08982757478952408, 0.593978226184845, -0.2303006798028946, -0.3058987855911255, -0.5370170474052429, -0.614524245262146, -0.230221226811409, 0.06516876071691513, -0.49277254939079285, 1.3939006328582764, -0.45094916224479675, -0.6829047203063965, 0.398094117641449, 0.10277288407087326, -0.4105443060398102, 0.33237242698669434, -0.00666540814563632, -0.6292529106140137, -0.144449383020401, -0.23779575526714325, 0.8711782097816467, 0.7208402752876282, -0.012794062495231628, -0.07150464504957199, 0.11560667306184769, -0.07172627002000809, -0.5255931615829468, -0.6081787347793579, 0.8226619958877563, -0.7238790988922119, -0.5180256366729736, 0.4145486056804657, 0.633392870426178, -0.2303917407989502, 0.0463113859295845, -0.2851514220237732, -0.8790441751480103, 0.8162849545478821, 0.6626960039138794, 0.6313990354537964, -1.0961899757385254, -1.5562403202056885, -0.09759379923343658, -0.10701620578765869, -0.052188556641340256, -0.6271246075630188, 0.6613668203353882, -0.6663466691970825, 0.5238878130912781, 0.5998246669769287, -0.7033262252807617, -0.20013293623924255, -0.4184526801109314, -0.9041839838027954, -0.3789159059524536, 0.24746458232402802, 1.3550970554351807, -0.4930284917354584, 0.027838388457894325, -0.24696920812129974, 0.6296696662902832, -0.8582730889320374, 0.746404230594635, -0.3607157766819, -0.4800432622432709, -0.09455174952745438, -0.29496750235557556, 0.18000127375125885, -0.6760798096656799, 0.14200140535831451, -0.6434631943702698, -0.5594910383224487, 0.33766674995422363, -0.49110954999923706, 1.2952220439910889, -0.17887096107006073, 0.4926944673061371, -0.14925621449947357, -0.6138260364532471, 0.21199053525924683, 0.08084610849618912, -0.28032800555229187, -0.36765456199645996, 0.4223329424858093, 0.2934384346008301, -0.6480197310447693, 0.5020098090171814, 0.831670880317688, 1.0950126647949219, -0.04205511137843132, 0.24563340842723846, 0.5736307501792908, 0.07319772988557816, -0.11289439350366592, 0.5212398171424866, 0.5370751619338989, 0.2698720097541809, -0.15554262697696686, -0.30013352632522583, 0.01788194291293621, -0.7607118487358093, -0.16839097440242767, 0.8341313004493713, 0.44824448227882385, 0.9987325072288513, 0.5590568780899048, -0.9166959524154663, -0.5060648918151855, 0.18348398804664612, 0.17531514167785645, 1.3002216815948486, -0.0442645326256752, 0.2154502272605896, -0.8129789233207703, -0.4541721045970917, -0.2016235589981079, -0.5004071593284607, -0.5504524111747742, 0.011326027102768421, -0.1618662327528, -0.929862380027771, 1.0722510814666748, 0.34182208776474, 1.5203989744186401, -0.9721506237983704, -0.7761527299880981, -0.4961813986301422, 0.7592560648918152, -1.0207154750823975, -0.5437361001968384, 0.5820423364639282, -0.8308590054512024, -0.22675327956676483, 0.0742117390036583, -0.41690003871917725, 0.24997703731060028, -0.4148179292678833, 0.31878551840782166, -0.1597597450017929, -0.5627615451812744, -0.05513801425695419, 0.6418599486351013, -0.5344854593276978, -0.20639315247535706, 0.2938530743122101, -0.08607641607522964, 0.14722205698490143, -0.07604376971721649, 0.27898019552230835, -0.5852596163749695, -0.08608945459127426, -0.5486530661582947, 0.18897226452827454, 0.1748930811882019, 0.01784314028918743, 0.720598042011261, -0.04830002784729004, 0.36491405963897705, -0.8955503702163696, 0.3814096450805664, 0.4881729483604431, -0.3595312535762787, -0.12977655231952667, -0.8030384182929993, -0.13379856944084167, 0.56983482837677, -0.8776522278785706, -0.32481852173805237, -0.8868277072906494, 0.11933226883411407, -0.8621827960014343, -0.24418844282627106, -0.20672859251499176, 0.7543410658836365, -0.050816312432289124, 0.5195938944816589, 0.4490015208721161, 0.47867926955223083, -0.04244580864906311, 0.36766600608825684, -0.8505966067314148, 0.8801277279853821, 0.5188184380531311, -0.19115372002124786, 0.3298228681087494, 0.034484390169382095, -0.5970326662063599, -0.2591470777988434, -0.6324851512908936, -0.21639128029346466, -0.3225095272064209, 0.2680586278438568, -0.6416690945625305, -1.0867583751678467, 0.5478420257568359, -1.053645133972168, -0.4875687062740326, 0.10090126842260361, -0.16178958117961884, -0.10800626128911972, -1.1820135116577148, -1.0540004968643188, -0.5912256240844727, -1.0938198566436768, -1.0450791120529175, 0.07767856866121292, 0.26794156432151794, 0.18022654950618744, -0.7476521730422974, -0.6195623874664307, -0.8188844323158264, 1.175374984741211, -0.2574188709259033, 0.11684999614953995, -0.22235634922981262, -0.16249722242355347, -0.35011231899261475, -0.5367175936698914, 0.9658693671226501, -0.49236032366752625, 0.3032403588294983, -1.1596077680587769, 0.5416336059570312, -0.5919560790061951, -0.6039268970489502, 0.8756950497627258, 0.1331774741411209, 1.0658185482025146, 0.22098985314369202, -0.5328139066696167, 0.8534001111984253, 1.8347200155258179, -0.7006515264511108, 0.7891368865966797, 0.14896677434444427, 0.57988041639328, -0.41887983679771423, -0.5277497172355652, 0.43273741006851196, -0.04804245010018349, -0.15896303951740265, 0.7771126627922058, -0.437421977519989, -0.3870094120502472, -0.5749157667160034, 0.16461260616779327, 0.7492676973342896, 0.25886261463165283, 0.43007412552833557, -0.6201733350753784, 0.6602323055267334, -1.0086523294448853, -0.8972261548042297, 0.5383815169334412, 0.7176398634910583, 0.15326568484306335, -0.04251570999622345, -0.5854335427284241, -0.5797498822212219, 0.6134908199310303, 0.5611338019371033, -0.5437296628952026, -0.944735050201416, -0.0027638431638479233, 0.5113242268562317, 0.41962045431137085, 0.12207186222076416, -0.23793482780456543, 0.8413612842559814, 14.547951698303223, 0.5608178973197937, -0.34536445140838623, 0.3351343870162964, 1.1310986280441284, 0.5449935793876648, -0.007077298127114773, 0.04839711636304855, -1.491882085800171, -0.19278505444526672, 1.0294420719146729, 0.6688223481178284, 0.4265983998775482, 0.5442354083061218, -0.28782176971435547, 0.14388279616832733, -0.22841082513332367, 0.537874162197113, 0.4209778904914856, -1.7454029321670532, 0.3009503185749054, 0.2706858515739441, 0.7946255207061768, 1.1692304611206055, 0.7820707559585571, 0.8146232962608337, 0.37846267223358154, -0.12414973229169846, 0.16492097079753876, 0.425679475069046, 1.2138898372650146, -0.1217832937836647, 0.5596209764480591, 0.4731646180152893, -0.953153133392334, 0.03714711219072342, -0.7493513822555542, -1.1234254837036133, -0.3599845767021179, 0.025930264964699745, -0.20887914299964905, -0.6338319778442383, 0.31081604957580566, 0.7909372448921204, 0.09479580074548721, 0.21187710762023926, -0.09426479786634445, -0.08172251284122467, -0.16135063767433167, -0.34734323620796204, 0.5562729835510254, 0.5822567343711853, -0.383414626121521, 0.21644140779972076, 0.04293853044509888, 0.0996268168091774, -0.012689325958490372, 0.7581402063369751, -0.8082252740859985, -0.5494325160980225, -0.22836360335350037, -0.10713311284780502, -0.3000757098197937, 1.2879188060760498, 0.13526487350463867, -0.0047315508127212524, -0.36614906787872314, 0.6302335262298584, 0.4228626787662506, 0.326549232006073, -0.6715252995491028, -0.534561276435852, 0.5686318874359131, -0.35977861285209656, 0.3137987554073334, 0.7181279063224792, -0.23779475688934326, -0.38204166293144226, -0.9292609691619873, 0.05087359994649887, -0.006386185064911842, -1.1066354513168335, -0.35252606868743896, 1.1549100875854492, -0.689167320728302, -0.23513250052928925, 0.6054953336715698, -1.3169125318527222, -0.85283362865448, 0.5690868496894836, -1.5720906257629395, -0.7752896547317505, -0.03583627566695213, 0.043651312589645386, -0.46772322058677673, 0.17425167560577393, 0.884765625, -0.21243473887443542, -0.48462724685668945, -0.03415345028042793, -0.21365340054035187, 0.22891771793365479, -0.3365343511104584, -0.6132972240447998, 1.277309536933899, 0.2625120282173157, -0.35213109850883484, 0.18958912789821625, -0.5133198499679565, 0.4233580231666565, -0.6737509369850159, -0.5738683342933655, 0.5047193765640259, -0.49495723843574524, 0.15149247646331787, -0.6952763199806213, -0.39912253618240356, 0.510601818561554, 0.8822392821311951, 0.38303306698799133, -0.21063587069511414, 0.012867264449596405, -0.8546916246414185, -0.363761842250824, -0.20154812932014465, 0.39583906531333923, 0.6476184725761414, -0.5907312631607056, -0.06225559487938881, -0.3457355499267578, 0.4302685856819153, -0.4369025230407715, -0.8736957907676697, 0.1134335845708847, 0.372025728225708, -0.8013887405395508, 1.1831181049346924, -0.34417417645454407, 0.8435379266738892, 1.2602875232696533, -0.04921172931790352, -0.26397815346717834, 0.33548271656036377, -1.1370512247085571, 0.3498457372188568, -0.1051359549164772, 0.5109577178955078, -1.0067962408065796, 0.40937480330467224, 0.6044722199440002, -0.0709196925163269, -0.773861825466156, -0.30877193808555603, -0.5479905009269714, 0.07200910151004791, -1.032607913017273, 0.35467129945755005, -0.05886462330818176, 0.10479151457548141, -0.2513135075569153, 0.83356112241745, 0.23623952269554138, -0.07175451517105103, -0.5529817938804626, 0.2622736692428589, -0.22751399874687195, -0.15502901375293732, -0.616661012172699, -0.778145968914032, -1.4913266897201538, -0.45353493094444275, -1.2649333477020264, -0.28255805373191833, -0.5733733177185059, -0.3515368402004242, 0.09484586119651794, -0.7214422821998596, 0.4157351553440094, 0.5767123103141785, 0.14760778844356537, -0.483033686876297, -0.44341230392456055, -0.616990864276886, 0.6792104244232178, 1.110929250717163, -0.3854784369468689, 0.0333993174135685, -0.15997834503650665, -0.09341271221637726, 0.6114329695701599, 0.461266428232193, -0.022149313241243362, -0.6845957636833191, -1.0137364864349365, 0.279784232378006, -0.28235143423080444, 0.39758816361427307, -1.1821587085723877, 1.0438647270202637, 0.7111979722976685, 0.18844927847385406, -0.21388286352157593, 0.1662900149822235, -0.791738748550415, -0.5443673729896545, 0.4186958968639374, -0.39243993163108826, 0.32568106055259705, 0.4986691176891327, -0.7244957685470581, -0.018769795075058937, 0.617621898651123, 0.08655419200658798, -0.8235357403755188, -1.1112223863601685, 0.588098406791687, -0.539604663848877, 0.14038562774658203, -0.365418940782547, -0.40120914578437805, -1.4904186725616455, 0.25134751200675964, -0.19174692034721375, 0.14666028320789337, -0.4529109597206116, 0.5709202289581299, 0.6026252508163452, -1.151251196861267, 0.37683436274528503, 0.7455719709396362, -0.1484852433204651, -0.0928274467587471, 0.6831105947494507, 0.7797737121582031, -0.4468636214733124, 0.3750975430011749, 0.1318727433681488, 0.3117341101169586, -0.5917865633964539, 0.4297325909137726, 0.9632130861282349, -0.40082302689552307, -0.4222807288169861, 1.0803284645080566, -0.10037244856357574, -0.9356361031532288, 0.27349597215652466, -1.172637701034546, -0.5119123458862305, -0.3499717712402344, 0.6782274842262268, 0.31868883967399597, 0.14097456634044647, 0.16037991642951965, -0.2425832748413086, -0.016197912395000458, -0.39374223351478577, -0.36717551946640015, 0.2738897502422333, 0.33367493748664856, -0.199427992105484, 0.1926025003194809, 1.212745189666748, -1.300850510597229, -1.3081331253051758, -0.8979248404502869, -0.6372340321540833, 0.4744977056980133, 0.3998695909976959, -0.3556467592716217, -0.8616645336151123, 0.7930171489715576, 0.49845895171165466, 0.5741055011749268, 0.4750016927719116, -0.15831159055233002, 0.09825525432825089, 0.7669889330863953, -0.21730533242225647, -0.8538218140602112, 0.019493361935019493, 1.4054908752441406, 1.152757167816162, -0.9089299440383911, 0.3715609908103943, -0.14023391902446747, -0.7311475872993469, 0.7033032178878784, 0.6800423860549927, -0.4595227539539337, 1.125614881515503, -0.2779821753501892, -0.019317463040351868, 0.10283558815717697, -1.164332389831543, -0.4983319044113159, 0.4297620952129364, 0.6984155178070068, 0.28151845932006836, -0.1887408047914505, 0.619093656539917, 0.8445173501968384, 0.24443159997463226, -0.43236634135246277, 0.1800064891576767, 0.29249170422554016, -0.0635996013879776, 0.4915289580821991, 0.06359953433275223, 0.5715306997299194, -0.7541345953941345, -0.9977867007255554, 0.37462469935417175, 0.9027007818222046, 0.391924649477005, 0.5210527181625366, 1.240440011024475, -0.2713419795036316, 0.6201961040496826, 0.07219568639993668, 0.09269637614488602, -0.057833973318338394, -0.6648860573768616, 0.23168104887008667, -0.9993790984153748, -0.194731667637825, 0.1287417858839035, -0.5264067649841309, -0.6397525668144226, -0.30596888065338135, 0.031327709555625916, -0.4037318527698517, 0.6407410502433777, 0.5368101596832275, 0.6748923063278198, 1.077079176902771, 0.04263360798358917, -0.6355928778648376, -0.5815795063972473, -0.8969764709472656, 0.1290292590856552, -0.43716832995414734, -0.16450434923171997, 0.48948216438293457, -0.2467142939567566, -0.19284917414188385]}, "authors": [{"authorId": "23476952", "name": "Weihao Yu"}, {"authorId": "2153245275", "name": "Pan Zhou"}, {"authorId": "2111618103", "name": "Shuicheng Yan"}, {"authorId": "48631088", "name": "Xinchao Wang"}], "references": [{"paperId": "3cb3052825d387a2a0eed29c92f07466d2f4a9ed", "title": "Conv2Former: A Simple Transformer-Style ConvNet for Visual Recognition"}, {"paperId": "26c80bd65baa90f5b18157de4951f4eb0b62ab69", "title": "InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions"}, {"paperId": "fc4cbc7a75f5a3bbca59db5513231555f078fe78", "title": "MetaFormer Baselines for Vision"}, {"paperId": "3e448df5aa191f7a3945d0fd609c8bc5966a2333", "title": "HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions"}, {"paperId": "d1869155960e4b1b882b39171dbecd25a7eda3cd", "title": "More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "fa717a2e31f0cef4e26921f3b147a98644d2e64c", "title": "Focal Modulation Networks"}, {"paperId": "9f1b0e4c42a5a85d4c023030557ade4419f82ecf", "title": "Scaling Up Your Kernels to 31\u00d731: Revisiting Large Kernel Design in CNNs"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "ba637c4f1a170f1e2dadeadb71a63cf2b9a46de2", "title": "Visual attention network"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "9137efc758f80dd22bb56f82cca5c94f78a5db3e", "title": "MViTv2: Improved Multiscale Vision Transformers for Classification and Detection"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "f454f6b5f2ca9749ddf442eb5134612ef7f758c1", "title": "ResNet strikes back: An improved training procedure in timm"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "48418b285a92376a38daafa664a2dd07d42e3fe3", "title": "Focal Self-attention for Local-Global Interactions in Vision Transformers"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "6b6ffb94626e672caffafc77097491d9ee7a8682", "title": "On the Connection between Local Attention and Dynamic Depth-wise Convolution"}, {"paperId": "8f8f73f0f208302546c825ed474432389ed63be4", "title": "EfficientNetV2: Smaller Models and Faster Training"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "2b8088253e2378fce001a090fe923b81e8dedf25", "title": "RepVGG: Making VGG-style ConvNets Great Again"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8", "title": "Generative Pretraining From Pixels"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "54c7445f319823c7dcc948c830e75e2fa7460b33", "title": "Exploring Self-Attention for Image Recognition"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "fb564bacfa790d44ab02a72256d55aa8b2209914", "title": "MixConv: Mixed Depthwise Convolutional Kernels"}, {"paperId": "d6dccb5d71fbb6f5765f89633ba3a8e6809a720d", "title": "Stand-Alone Self-Attention in Vision Models"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "27ac832ee83d8b5386917998a171a0257e2151e2", "title": "Attention Augmented Convolutional Networks"}, {"paperId": "a84906dbd4d6640f918d0b6ed2a7313dda0d55f1", "title": "Panoptic Feature Pyramid Networks"}, {"paperId": "5132500b23d2da47129b3f4f68dd30947a29e502", "title": "CCNet: Criss-Cross Attention for Semantic Segmentation"}, {"paperId": "c02b909a514af6b9255315e2d50112845ca5ed0e", "title": "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "f723eb3e7159f07b97464c8d947d15e78612abe4", "title": "AutoAugment: Learning Augmentation Policies from Data"}, {"paperId": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4", "title": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "9da734397acd7ff7c557960c62fb1b400b27bd89", "title": "ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "edccc38cbd8765c658b3880facec76e9f4a8ee5c", "title": "DiracNets: Training Very Deep Neural Networks Without Skip-Connections"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "5582bebed97947a41e3ddd9bd1f284b73f1648c2", "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"}, {"paperId": "5b6ec746d309b165f9f9def873a2375b6fb40f3d", "title": "Xception: Deep Learning with Depthwise Separable Convolutions"}, {"paperId": "5694e46284460a648fe29117cbc55f6c9be3fa3c", "title": "Densely Connected Convolutional Networks"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "cab372bc3824780cce20d9dd1c22d4df39ed081a", "title": "DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "b5c26ab8767d046cb6e32d959fdf726aee89bb62", "title": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "e0945081b5b87187a53d4329cf77cd8bff635795", "title": "Highway Networks"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327", "title": "Going deeper with convolutions"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd", "title": "ImageNet Large Scale Visual Recognition Challenge"}, {"paperId": "5e83ab70d0cbc003471e87ec306d27d9c80ecb16", "title": "Network In Network"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "4dbc68cf2e14155edb6da0def30661aca8c96c22", "title": "Simplifying ConvNets for Fast Learning"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "25146f22b6be1bc0e7d7c91f7209c82eac5c18c4", "title": "FEATURES"}, {"paperId": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27", "title": "Backpropagation Applied to Handwritten Zip Code Recognition"}, {"paperId": "63f1f2dad0a2e84d37a97258008c5609195487f0", "title": "Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "c25f5efa9e2d6ca04388052959d73e80163556f6", "title": "7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019"}, {"paperId": null, "title": "Pytorch image models"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82", "title": "Deep Learning"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}, {"paperId": null, "title": "MMSegmentation: Openmmlab semantic segmentation toolbox and benchmark"}]}