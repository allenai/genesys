{"paperId": "ed1b378115a43b08ec97a3aa04b09eca8ca868b0", "title": "Expediting Large-Scale Vision Transformer for Dense Prediction Without Fine-Tuning", "abstract": "In a wide range of dense prediction tasks, large-scale Vision Transformers have achieved state-of-the-art performance while requiring expensive computation. In contrast to most existing approaches accelerating Vision Transformers for image classification, we focus on accelerating Vision Transformers for dense prediction without any fine-tuning. We present two non-parametric operators specialized for dense prediction tasks, a token clustering layer to decrease the number of tokens for expediting and a token reconstruction layer to increase the number of tokens for recovering high-resolution. To accomplish this, the following steps are taken: i) token clustering layer is employed to cluster the neighboring tokens and yield low-resolution representations with spatial structures; ii) the following transformer layers are performed only to these clustered low-resolution tokens; and iii) reconstruction of high-resolution representations from refined low-resolution representations is accomplished using token reconstruction layer. The proposed approach shows promising results consistently on 6 dense prediction tasks, including object detection, semantic segmentation, panoptic segmentation, instance segmentation, depth estimation, and video instance segmentation. Additionally, we validate the effectiveness of the proposed approach on the very recent state-of-the-art open-vocabulary recognition methods. Furthermore, a number of recent representative approaches are benchmarked and compared on dense prediction tasks.", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2023, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work presents two non-parametric operators specialized for dense prediction tasks, a token clustering layer to decrease the number of tokens for expediting and a token reconstruction layer to increase the number of tokens for recovering high-resolution."}, "embedding": {"model": "specter_v2", "vector": [0.19741912186145782, 0.5209159255027771, -0.2397676557302475, 0.1566457748413086, -0.3691428005695343, 0.6411125659942627, 0.4519900679588318, 0.06374126672744751, -0.5327878594398499, -0.9629107117652893, 0.5594847202301025, 0.7543922066688538, 0.5292644500732422, -0.2496710866689682, 0.10606352984905243, 0.022407881915569305, -0.8420068025588989, 0.14445218443870544, 0.9901459813117981, -0.046414829790592194, 0.11230666935443878, -0.10266346484422684, -1.7424629926681519, 0.5747211575508118, 0.04726416617631912, 1.5270360708236694, 0.2894531488418579, 0.8414427638053894, -0.5632255673408508, 0.4291746914386749, 0.5861102938652039, 0.024008262902498245, 0.5434930324554443, 0.39918312430381775, -0.5466204285621643, 0.3595227003097534, 0.6626173257827759, -0.6216588020324707, -0.5452572703361511, 0.6880426406860352, -0.23847758769989014, 0.4485253095626831, 0.6106663942337036, -0.605610191822052, -0.03722212836146355, 0.3064098656177521, 0.3546542823314667, 0.582690954208374, -0.4019205570220947, -0.9726245999336243, 1.1458649635314941, -1.5445743799209595, 0.20691058039665222, 1.6880131959915161, 0.7058933973312378, 0.1470896154642105, -0.05436588078737259, -0.6081954836845398, 0.7923032641410828, 0.4688483476638794, -0.7459598779678345, -0.4791087508201599, -0.2107866108417511, -0.5590868592262268, 1.6918493509292603, -0.7901068925857544, 0.3979700207710266, 0.5679643750190735, -0.155496746301651, 1.276536464691162, -0.21143671870231628, -0.5658909678459167, 0.02622203715145588, -0.3865210711956024, 0.0018757417565211654, 1.1168246269226074, -0.3298446834087372, 0.6135678887367249, -1.2150461673736572, 0.3109557628631592, 0.8905709385871887, 0.10398644953966141, 0.6753129363059998, -0.4199540615081787, -0.14717456698417664, 0.41431671380996704, 1.0000007152557373, 0.4127277731895447, -0.44914525747299194, 0.9020846486091614, 0.6783856153488159, -0.2670361399650574, -0.21753257513046265, 0.04926105961203575, 0.19964708387851715, 0.6561889052391052, -0.9672315716743469, -0.03108682855963707, -0.24233320355415344, 0.736577570438385, -0.1418398916721344, 0.17965586483478546, -0.5337130427360535, 0.3739997148513794, 1.313058853149414, -0.08871958404779434, 0.4616970717906952, -0.9838897585868835, -0.19875465333461761, -0.7681488394737244, 0.23558147251605988, -0.5854067206382751, -0.029587656259536743, -0.020593101158738136, -0.7915767431259155, -0.49773892760276794, -0.3184235990047455, 0.5112893581390381, -1.53667151927948, -0.19719800353050232, -0.028746098279953003, 0.8419439792633057, -0.031099583953619003, 0.48917946219444275, 0.5301195383071899, 0.6284700036048889, 0.5519295930862427, 0.46548888087272644, 1.2924811840057373, -1.436659574508667, 0.14429150521755219, -0.46786585450172424, -0.250914067029953, -0.3683062493801117, -0.110310859978199, -0.1623443365097046, -0.9461694955825806, -1.4187750816345215, -0.3539188802242279, -0.13634087145328522, -0.7524997591972351, -0.14469650387763977, 0.9623527526855469, 0.07933013886213303, -1.202481985092163, 0.6044647693634033, -0.2845168113708496, -0.5551326870918274, 0.7903982996940613, -0.1277996003627777, 0.40282005071640015, -0.12449439615011215, -0.7836421132087708, 0.14047390222549438, -0.055115651339292526, -0.4572194218635559, -0.7926766872406006, -0.30547580122947693, -1.05098557472229, 0.2158912569284439, 0.1635899394750595, -0.526479959487915, 1.1866450309753418, -0.15457360446453094, -0.9989100098609924, 0.7070885896682739, -0.3507092297077179, -0.2476091831922531, 0.37977099418640137, -0.23115885257720947, -0.23742042481899261, 0.031820110976696014, 0.08024463057518005, 1.1127557754516602, 1.1364068984985352, -0.25834691524505615, -0.8914404511451721, 0.31003281474113464, -0.44825658202171326, 0.06828571856021881, -0.3672404885292053, 1.1085182428359985, -0.46380504965782166, -0.2910168468952179, 0.5881202816963196, 0.9525013566017151, -0.6426756978034973, 0.10870419442653656, -0.018222445622086525, -0.8800875544548035, 1.1427333354949951, 0.4579373896121979, -0.10709535330533981, -0.8942779898643494, -1.0760838985443115, -0.16887404024600983, 0.1390269249677658, -0.24941179156303406, -1.1343481540679932, -0.052651986479759216, -0.008905031718313694, 0.1914428323507309, 0.6331081390380859, -1.1026018857955933, -0.07743820548057556, -0.354141503572464, -0.8266875743865967, -0.1982431709766388, 0.18063926696777344, 0.9396182894706726, -0.7297772169113159, -0.31607022881507874, 0.32581427693367004, 0.43747732043266296, -0.9294787645339966, 1.139867901802063, -0.6315866112709045, -0.25450924038887024, -0.3546741008758545, 0.4634436368942261, -0.09615340828895569, -0.3321494460105896, 0.1675691306591034, -0.7000339031219482, -0.3374972343444824, 0.47441965341567993, -0.588965117931366, 1.0122636556625366, -0.05619238689541817, 0.4193175435066223, -0.19360192120075226, -0.6062125563621521, 0.30033689737319946, 0.462926983833313, 0.1092621460556984, -0.5685388445854187, 0.37619373202323914, 0.1032366007566452, -1.0397188663482666, 0.11919495463371277, 1.0932060480117798, 0.9996405243873596, -0.2902640402317047, -0.1770644634962082, 0.32296356558799744, -0.1435057818889618, 0.30323702096939087, 0.18693003058433533, 0.618007481098175, 0.40812620520591736, 0.176679790019989, 0.23877625167369843, -0.17582082748413086, -0.781948983669281, 0.19866521656513214, 1.0191396474838257, 0.2019268125295639, 1.3736428022384644, 0.33795568346977234, -0.8278838992118835, -0.9301362037658691, 0.05273574963212013, 0.5227369666099548, 1.4300254583358765, 0.441995769739151, -0.16235481202602386, -0.6626336574554443, -0.4157980978488922, -0.32380443811416626, -0.9352713823318481, -0.4773862659931183, 0.4291316568851471, -0.07848753780126572, -0.5220723152160645, 1.0292441844940186, 0.7949022054672241, 1.4843403100967407, -1.0081244707107544, -0.48633137345314026, -0.38693466782569885, 0.04743105545639992, -1.2123291492462158, -0.22310686111450195, 0.4291362166404724, -0.41720613837242126, -0.28218716382980347, 0.1538093388080597, -0.4351005554199219, 0.3404347002506256, -0.25466302037239075, 0.535387396812439, -0.3519001007080078, -0.9183567762374878, 0.0530654639005661, 0.09632977098226547, -0.5219852924346924, -0.3265168368816376, 0.16251234710216522, 0.022565921768546104, -0.3321147561073303, 0.4542761743068695, 0.3909653127193451, -0.12452981621026993, 0.2496080845594406, -0.25020501017570496, 0.14427171647548676, 0.2661021053791046, -0.18840844929218292, 1.300423502922058, -0.17736934125423431, 0.07078459858894348, -0.6501598358154297, 0.2764267027378082, 0.22396211326122284, -0.4920123517513275, 0.0200948603451252, -0.407545804977417, -0.4617837965488434, 0.35129040479660034, -0.6460709571838379, -0.17672792077064514, -0.12144800275564194, 0.15209965407848358, -1.337336540222168, -1.0896775722503662, -0.3440225124359131, 0.5769931077957153, -0.2558230757713318, 0.39637187123298645, 0.3621827960014343, 0.19223998486995697, -0.23979653418064117, 0.4660269021987915, -0.829521894454956, 0.8764467239379883, -0.03511970862746239, 0.117442287504673, 0.19543597102165222, 0.003668259596452117, -0.9732590913772583, -0.5185586214065552, -1.1471374034881592, -0.9173336029052734, -0.4638424813747406, 0.6809669137001038, -0.6112231016159058, -0.675537645816803, 0.05887474864721298, -1.0382329225540161, -0.3945354223251343, -0.12156008183956146, -0.239336296916008, -0.43052902817726135, -0.9251159429550171, -1.1922043561935425, -0.4759572744369507, -0.5394492745399475, -0.9228843450546265, 0.6283072829246521, 0.25056830048561096, 0.09551849216222763, -0.0011917197844013572, -0.4581829607486725, -0.22942480444908142, 0.7727941870689392, -0.23711399734020233, 0.29542768001556396, -0.1807362586259842, -0.8934212923049927, 0.012657640501856804, -0.4569208323955536, 0.4529414176940918, -0.3200705051422119, 0.3232366442680359, -1.0287604331970215, 0.7174230217933655, -0.5923547148704529, -0.40612274408340454, 0.8159143328666687, 0.23503883183002472, 0.953102171421051, 0.46914392709732056, -0.4593944251537323, 0.542314350605011, 1.3478132486343384, -0.63845294713974, 0.3769240379333496, 0.27049851417541504, 0.9504171013832092, 0.08570880442857742, -0.005644656717777252, 0.6805407404899597, -0.08695442974567413, 0.22032061219215393, 0.44832661747932434, -0.4717748463153839, -0.8792247772216797, -0.5208714604377747, 0.34706005454063416, 0.6633620858192444, 0.1306690126657486, 0.463265061378479, -1.0190387964248657, 1.0290967226028442, -1.2603778839111328, -0.9707893133163452, 0.7578732967376709, 0.4432196617126465, -0.17997030913829803, -0.2581951320171356, 0.0766485184431076, -0.5273054838180542, 0.7144044041633606, 0.437336266040802, -0.2262047678232193, -0.4657314419746399, 0.3433460593223572, 0.5064882040023804, 0.09265964478254318, 0.38796648383140564, -0.7537083029747009, 0.9178580045700073, 14.50770092010498, 0.7695958018302917, -0.34165775775909424, 0.040179572999477386, 0.8609545826911926, 0.49169090390205383, 0.19371341168880463, -0.15102791786193848, -1.4363304376602173, -0.49730485677719116, 0.7460827231407166, 0.359857976436615, 0.2222445160150528, 0.7107763290405273, 0.12791702151298523, 0.24053701758384705, -0.791904091835022, 0.7736608982086182, 0.45586031675338745, -1.4919712543487549, 0.40313270688056946, 0.18198248744010925, 0.23578757047653198, 0.5897694230079651, 0.8499342799186707, 0.7607232332229614, 0.3164962828159332, -0.6002339124679565, 0.6440613865852356, 0.14214003086090088, 1.0883610248565674, 0.12063854932785034, 0.2018083930015564, 0.040074627846479416, -1.4341462850570679, -0.2833179831504822, -0.9511652588844299, -1.0036983489990234, 0.025192808359861374, -0.0735541358590126, -1.1377426385879517, -0.6339332461357117, 0.22272421419620514, 0.9301565885543823, 0.06828518956899643, 0.9495106935501099, -0.11536093056201935, 0.16850662231445312, -0.14972041547298431, 0.22701868414878845, 0.36489546298980713, 0.6760716438293457, 0.16321414709091187, 0.15879298746585846, -0.01226747129112482, 0.3962881565093994, 0.6315063238143921, 0.04067697376012802, -0.5768118500709534, -0.43594834208488464, -0.24507206678390503, 0.23840007185935974, -0.3129231631755829, 1.08544921875, -0.329069584608078, 0.19289298355579376, -0.23055706918239594, 0.20457200706005096, 0.37606242299079895, 0.07534979283809662, -0.525216281414032, -0.11149931699037552, 0.567172646522522, 0.01828746870160103, 0.896239161491394, 0.7229955792427063, -0.4015830159187317, -0.6284309029579163, -0.9945887327194214, 0.04669396951794624, 0.5898379683494568, -0.7628917098045349, -0.72376549243927, 1.1188925504684448, -0.2822657525539398, -0.35273438692092896, 0.20665140450000763, -0.8573130369186401, -0.3302863836288452, 0.07642675936222076, -1.6259607076644897, -0.762967586517334, -0.34237775206565857, -0.009861964732408524, 0.1386362910270691, 0.047068409621715546, 1.150534749031067, 0.07754752039909363, -0.09491423517465591, -0.27590611577033997, -0.3473457992076874, 0.526940107345581, -0.1283884346485138, -0.5586046576499939, 0.6681603193283081, 0.44578975439071655, 0.020315341651439667, -0.3912737965583801, -0.3463316559791565, 0.12461873143911362, 0.21185481548309326, -0.49507588148117065, 0.2450394332408905, -0.27951541543006897, -0.47880756855010986, -0.7329726219177246, -0.8234213590621948, 0.3027985990047455, 0.2311413735151291, 0.3349590003490448, -0.06522101908922195, 0.29626575112342834, -0.8338829278945923, -0.28778108954429626, -0.9212831854820251, 0.16803982853889465, 0.32503679394721985, -0.716718316078186, -0.5085671544075012, -0.17003682255744934, 0.3906061053276062, -0.8954076170921326, -0.64806067943573, -0.06597165763378143, 0.42989620566368103, -0.3751298487186432, 1.5042469501495361, -0.26862019300460815, 1.242096185684204, 0.6762648224830627, -0.3729337751865387, -0.28731217980384827, -0.17282642424106598, -0.3371949791908264, -0.05180640518665314, 0.002625598106533289, 0.15451358258724213, 0.016654813662171364, 0.6662358045578003, 0.5950263738632202, 0.29508915543556213, -0.5358332395553589, -0.3407726585865021, 0.07642769813537598, -0.2355981320142746, -0.4361625909805298, 0.18304398655891418, -0.3323272466659546, -0.07746247202157974, -0.3026564121246338, 0.755638062953949, 0.7583590745925903, 0.05382758006453514, -0.277156800031662, 0.4299618899822235, -0.17189745604991913, -0.015065666288137436, -0.5483733415603638, -0.9439919590950012, -1.5708595514297485, -0.03998212143778801, -0.9422187805175781, 0.37457048892974854, -1.1085294485092163, -0.5125541090965271, -0.1872366964817047, -0.5007778406143188, 0.35698044300079346, 0.6539803743362427, 0.020391089841723442, -0.05242379754781723, -0.37741172313690186, -1.0560877323150635, 0.5044582486152649, 0.935476541519165, -0.57667475938797, 0.2042393535375595, 0.02493121288716793, 0.20159806311130524, 0.7928786277770996, 0.16949231922626495, -0.3939570486545563, -0.47303977608680725, -0.5801111459732056, -0.41054463386535645, 0.058972880244255066, 0.07309293746948242, -1.222548246383667, 0.9118270874023438, 0.14570048451423645, 0.5177955031394958, -0.19139668345451355, 0.5453410148620605, -0.8976070880889893, -0.9753229022026062, 0.2212146520614624, -0.8362909555435181, -0.430616170167923, 0.21957215666770935, -0.40861770510673523, -0.45073676109313965, 0.7652517557144165, 0.4873318076133728, -1.0638651847839355, -1.7681944370269775, 0.6512052416801453, -0.44343698024749756, -0.28368404507637024, -0.04195966199040413, -0.3432733118534088, -1.1711255311965942, 0.010374273173511028, -0.48806288838386536, 0.36849167943000793, -0.367087721824646, 1.028732180595398, 1.2493914365768433, -0.9493355751037598, 0.23440182209014893, 0.2978314757347107, -0.3150656521320343, 0.4165717661380768, 0.5821535587310791, 0.3700963258743286, -0.18011631071567535, 0.2374589592218399, -0.22902606427669525, 0.28705033659935, -1.0055210590362549, 0.24376846849918365, 1.2338018417358398, -0.4146049916744232, -0.6728086471557617, 0.9843210577964783, -0.11240480095148087, -0.39430004358291626, 0.622737467288971, -1.293162226676941, -0.6319454312324524, -0.1306038349866867, 0.783707857131958, 0.07460124045610428, -0.09769763797521591, 0.044189319014549255, -0.5566152334213257, 0.27865827083587646, -0.49335768818855286, -0.5712404847145081, 0.3569265902042389, 0.03537138178944588, -0.18098968267440796, 0.24920979142189026, 0.5999507308006287, -0.9627627730369568, -1.3314324617385864, -0.6492457389831543, -0.42512544989585876, -0.6390721201896667, 0.05486711114645004, -0.09814907610416412, -0.6560001373291016, 0.6555373668670654, 0.6824963688850403, 0.544460117816925, 0.13205982744693756, 0.024973442777991295, 0.5898399949073792, 0.9450427293777466, 0.053982753306627274, -0.8315232992172241, 0.2722094655036926, 1.21364426612854, 0.9654986262321472, -0.7788727283477783, 0.13232335448265076, -0.571535587310791, -0.5398499369621277, 0.8784071207046509, 0.7015403509140015, -0.43591541051864624, 1.0480024814605713, 0.00453570019453764, 0.04148690029978752, 0.18104390799999237, -0.8631273508071899, -0.7150421142578125, 0.664153516292572, 1.6379737854003906, 0.2697965204715729, -0.051992811262607574, 0.9712351560592651, 0.5271654725074768, 0.261856347322464, 0.1511065512895584, 0.5181479454040527, 0.0837242379784584, -0.6159628629684448, 0.23181700706481934, -0.2928546965122223, 0.7862977385520935, -0.7002153992652893, -0.3688454329967499, 0.47191572189331055, 0.5326495170593262, 0.3956582844257355, 0.49687570333480835, 1.3411325216293335, 0.044435542076826096, 0.45099112391471863, 0.105875164270401, 0.38692373037338257, -0.744990885257721, -0.23658668994903564, 0.050808537751436234, -0.8577735424041748, -0.5334819555282593, -0.44602495431900024, -0.7144991755485535, -0.7994916439056396, -0.14071010053157806, 0.7038942575454712, -0.11989490687847137, 0.2265990823507309, 0.803565502166748, 0.5159744620323181, 0.6751566529273987, -0.46422603726387024, -0.9364123344421387, -0.2428850531578064, -0.527561604976654, -0.13142961263656616, -0.4720745086669922, -0.01298863347619772, -0.2785511910915375, 0.2055457979440689, 0.2927112877368927]}, "authors": [{"authorId": "2239404721", "name": "Yuhui Yuan"}, {"authorId": "2186825281", "name": "Weicong Liang"}, {"authorId": "2238396498", "name": "Henghui Ding"}, {"authorId": "2277713299", "name": "Zhanhao Liang"}, {"authorId": "2164073950", "name": "Chao Zhang"}, {"authorId": "2118879491", "name": "Hanhua Hu"}], "references": [{"paperId": "79e07495df577219ec343d68a23e91f9bb4f2e2c", "title": "Dynamic Grained Encoder for Vision Transformers"}, {"paperId": "3d3a76a2fedccea741f34303b06358440dc2a212", "title": "DETRs with Collaborative Hybrid Assignments Training"}, {"paperId": "b6184aa4365008520742a166fc7e6bfd22988029", "title": "Beyond Attentive Tokens: Incorporating Token Importance and Diversity for Efficient Vision Transformers"}, {"paperId": "6a993404e07687b7edb7fb9a05092213a9419859", "title": "OneFormer: One Transformer to Rule Universal Image Segmentation"}, {"paperId": "245445ab41fbd9c96062dba58736dd257f3edc06", "title": "VLT: Vision-Language Transformer and Query Generation for Referring Segmentation"}, {"paperId": "1dff6b1b35e2d45d4db57c8b4e4395486c3e365f", "title": "Token Merging: Your ViT But Faster"}, {"paperId": "29c2d3d77b6d6f24f4356d5ba20c1a6ab4229c76", "title": "Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP"}, {"paperId": "74263c63be360a664e4acfa71db7123caa53bdd9", "title": "Adaptive Sparse ViT: Towards Learnable Adaptive Token Pruning by Fully Exploiting Self-Attention"}, {"paperId": "0d10c6c656c7c28858004284db7f86f46d615a8a", "title": "PatchDropout: Economizing Vision Transformers Using Patch Dropout"}, {"paperId": "af81d2ccfc0a88af6ed619080ef6ff67662b9d0f", "title": "DETRs with Hybrid Matching"}, {"paperId": "fdcad86866ca22d8417599deb41b54fe01487ce8", "title": "ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation"}, {"paperId": "a09cbcaac305884f043810afc4fa4053099b5970", "title": "Exploring Plain Vision Transformer Backbones for Object Detection"}, {"paperId": "9dc481ec44178e797466bbad968071917842156b", "title": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection"}, {"paperId": "3c7f3b153c2b5b4074d95ac9d659a267a2bafa3f", "title": "Auto-scaling Vision Transformers without Training"}, {"paperId": "202967f77c4384bce80eaf2fa5737259008267d3", "title": "Learning to Merge Tokens in Vision Transformers"}, {"paperId": "b7dc007054cf17dea3b22a2d1e71ba4cc8606648", "title": "Revisiting Weakly Supervised Pre-Training of Visual Perception Models"}, {"paperId": "5ab70d95ca49702a3dd49b39d9396d8136b52311", "title": "Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space"}, {"paperId": "722d71a19e4049b30a03d1028158881560432135", "title": "SPViT: Enabling Faster Vision Transformers via Latency-Aware Soft Token Pruning"}, {"paperId": "756b1a89ddcc71ac445af250f4f35f07de8f2318", "title": "SeMask: Semantically Masked Transformers for Semantic Segmentation"}, {"paperId": "5553f9508dd1056ecc20c5b1f367e9a07e2c7e81", "title": "StyleSwin: Transformer-based GAN for High-resolution Image Generation"}, {"paperId": "f427ccb1d97cee3fde8abf0f5442f859531f5bf1", "title": "Mask2Former for Video Instance Segmentation"}, {"paperId": "c2a0c18e810535db52e5ebaf180c64ce70356748", "title": "A-ViT: Adaptive Tokens for Efficient Vision Transformer"}, {"paperId": "5341b412383c43f4a693ad63ec4489e3ec7688c8", "title": "Grounded Language-Image Pre-training"}, {"paperId": "5b34d6c0933f62566e6d1cb9037bcd654af239a6", "title": "SWAT: Spatial Structure Within and Among Tokens"}, {"paperId": "20ee3dc902706d8dffcbc08f8cc89ce749abc8b0", "title": "Benchmarking Detection Transfer Learning with Vision Transformers"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "9c4753ef43d2928866dc5bf6cec53d03373ec2fa", "title": "SimMIM: a Simple Framework for Masked Image Modeling"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "e15fdbde1d56a80743b7d7eafb3409a0a5870094", "title": "HRFormer: High-Resolution Transformer for Dense Prediction"}, {"paperId": "5a060dc5a5bcac0879f17841a5cf70bb4302cc47", "title": "Token Pooling in Vision Transformers"}, {"paperId": "da74a10824193be9d3889ce0d6ed4c6f8ee48b9e", "title": "MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer"}, {"paperId": "f7e449d7695fbbf43081cc820a81fe0ccb11c3db", "title": "PnP-DETR: Towards Efficient Visual Analysis with Transformers"}, {"paperId": "a66686e60a3eda0c606e036403cf0a07a5962595", "title": "Mobile-Former: Bridging MobileNet and Transformer"}, {"paperId": "d045133e6e022684329ff944d67f91888be1bc3b", "title": "Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transformer"}, {"paperId": "48418b285a92376a38daafa664a2dd07d42e3fe3", "title": "Focal Self-attention for Local-Global Interactions in Vision Transformers"}, {"paperId": "94eae578e6af3382f6449506965639f18aab3fa0", "title": "Video Swin Transformer"}, {"paperId": "7fff8018bf625447df837c2fda5c58a705fbc038", "title": "XCiT: Cross-Covariance Image Transformers"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "2a805d0e1b067444a554c5169d189fa1f649f411", "title": "Scaling Vision Transformers"}, {"paperId": "efbe9f591090018f78b42c84613c8afda9292fdb", "title": "Chasing Sparsity in Vision Transformers: An End-to-End Exploration"}, {"paperId": "14b97585f136671742f6ce4151081e487b1fc1fe", "title": "Not All Images are Worth 16x16 Words: Dynamic Transformers for Efficient Image Recognition"}, {"paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60", "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"}, {"paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6", "title": "Multiscale Vision Transformers"}, {"paperId": "8e33914d6051dd031a5e096962b9398fc1d16067", "title": "Vision Transformers for Dense Prediction"}, {"paperId": "610b302950a19acef1c45456111dcd495f638c18", "title": "ConViT: improving vision transformers with soft convolutional inductive biases"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "141a5033d9994242b18bb3b217e79582f1ee9306", "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"}, {"paperId": "9d6acac70b2d1fdb861a08b00766ef263109cd7f", "title": "Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks"}, {"paperId": "2e1db8cb373f4d4a51d44308b7a457886d855fbb", "title": "End-to-End Object Detection with Adaptive Clustering Transformer"}, {"paperId": "6a3839aba1285f31b9178739470b0dab86b438fe", "title": "Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "c0f709acf38eb27702b0fbce1215db0ebaa2de2b", "title": "SMYRF: Efficient Attention using Asymmetric Clustering"}, {"paperId": "945c0d6d164ce7aaf0be5309cf565aad38e62a66", "title": "Accelerate CNNs from Three Dimensions: A Comprehensive Pruning Framework"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "cd4ffe5e014601a3d6b64121355d29a730591490", "title": "Fast Transformers with Clustered Attention"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "de66ada65cd9d36e46f1f8dd2c8be480180038ec", "title": "What is the State of Neural Network Pruning?"}, {"paperId": "a88c914f5a738d38f02790bb5de41453bf17bde1", "title": "Object-Contextual Representations for Semantic Segmentation"}, {"paperId": "f902a64f7d08aaa6bfca7463e8729952ddc6134e", "title": "LVIS: A Dataset for Large Vocabulary Instance Segmentation"}, {"paperId": "24d70dbe19baa72a0c8481d5006d3632712ba688", "title": "Video Instance Segmentation"}, {"paperId": "120ffccea4787b88f78b55b9302891ff96cb4228", "title": "Slimmable Neural Networks"}, {"paperId": "4a1004ecd34118116344633c7cdcc34493c423ee", "title": "Rethinking the Value of Network Pruning"}, {"paperId": "796a6e78d4c4b63926ee956f202d874a8c4542b0", "title": "OCNet: Object Context Network for Scene Parsing"}, {"paperId": "62dccab9ab715f33761a5315746ed02e48eed2a0", "title": "A Short Note about Kinetics-600"}, {"paperId": "ea743597a5f48babef1982259566d76a9bf66bf2", "title": "Context Contrasted Feature and Gated Multi-scale Aggregation for Scene Segmentation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6", "title": "The Kinetics Human Action Video Dataset"}, {"paperId": "88512be44744615f4baa8e14f600f036db4c2433", "title": "Semantic Understanding of Scenes Through the ADE20K Dataset"}, {"paperId": "c8c494ee5488fe20e0aa01bddf3fc4632086d654", "title": "The Cityscapes Dataset for Semantic Urban Scene Understanding"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327", "title": "Going deeper with convolutions"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "3419ccd5c94d301ee08d716d037f0c3c6a62e78e", "title": "The Role of Context for Object Detection and Semantic Segmentation in the Wild"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "c1994ba5946456fc70948c549daf62363f13fa2d", "title": "Indoor Segmentation and Support Inference from RGBD Images"}, {"paperId": "de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42", "title": "Are we ready for autonomous driving? The KITTI vision benchmark suite"}, {"paperId": "293535c2b0ef674e1ed9a7ba227e37cca35e5e4b", "title": "EViT: Expediting Vision Transformers via Token Reorganizations"}, {"paperId": "10a7dfa73ac8f507a9895e6645c622a837f6b09a", "title": "MLSeg: Image and Video Segmentation as Multi-Label Classification and Selected-Label Pixel Classification"}, {"paperId": "32e0057c9a06d23182ff41553c9df1c9a8c4b757", "title": "Efficient Token Mixing for Transformers via Adaptive Fourier Neural Operators"}, {"paperId": "9af62668cb87f11fffb53a194588c8158fde6b00", "title": "DynamicViT: Ef\ufb01cient Vision Transformers with Dynamic Token Sparsi\ufb01cation"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "03b537c948a9711cf2a7b324e02e030874df8f73", "title": "HRViT: Multi-Scale High-Resolution Vision Transformer"}, {"paperId": "a9ae83b112b2218604c9d7b37291a10e0d7e8bcf", "title": "Efficient Self-Ensemble Framework for Semantic Segmentation"}, {"paperId": "eaa09c607780373cc809bce89b6b28b17e301f27", "title": "TokenLearner: Adaptive Space-Time Tokenization for Videos"}, {"paperId": "0d8be19e00af83388523baf86f8cdf682302a0d1", "title": "SPViT: Enabling Faster Vision Transformers via Soft Token Pruning"}, {"paperId": "a2210e99e342bc8e17ad93d4b717ccedeb9cb86a", "title": "A Simple Single-Scale Vision Transformer for Object Localization and Instance Segmentation"}, {"paperId": null, "title": "\u201cOpenclip,\u201d"}, {"paperId": null, "title": "\u201cAutoFormer: Searching trans-formers for visual recognition,\u201d"}, {"paperId": null, "title": "\u201cSwinir: Imagerestorationusingswintransformer"}, {"paperId": null, "title": "\u201cMulti-scalevisionlongformer:Anewvisiontransformer forhigh-resolutionimageencoding,\u201din"}, {"paperId": null, "title": "\u201cSparseDETR:Ef\ufb01cientend-to-endobjectdetectionwithlearnablesparsity,"}, {"paperId": null, "title": "\u201cMulti-dimensionalmodelcompressionofvisiontransformer"}, {"paperId": null, "title": "\u201cEf\ufb01cient transformers: A survey"}, {"paperId": null, "title": "\u201cSegFix:Model-agnosticboundary re\ufb01nementforsegmentation,\u201din"}, {"paperId": null, "title": "\u201cEf\ufb01cientnet: Rethinking model scaling for convolutional neural networks,\u201d"}, {"paperId": null, "title": "\u201cDBP:Discrimina-tionbasedblock-levelpruningfordeepmodelacceleration"}, {"paperId": null, "title": "\u201cSuperpixel samplingnetworks,\u201din"}, {"paperId": null, "title": "\u201cLearningef\ufb01cient convolutionalnetworksthroughnetworkslimming,\u201din"}, {"paperId": null, "title": "received the BS degree from Nanjing University, China, in"}, {"paperId": null, "title": "\u201cModel soups: Averaging weights of multiple \ufb01ne-tunedmodelsimprovesaccuracywithoutincreasinginferencetime,\u201d2022"}, {"paperId": null, "title": "\u201cMaskDINO:Towardsauni\ufb01edtransformer-basedframeworkforobjectdetectionandsegmentation,"}, {"paperId": null, "title": "All the codes"}, {"paperId": null, "title": ". His previous research interests focus on semantic segmentation and object detection while currently focusing more on visual creation. license agreement with IEEE. Restrictions apply"}, {"paperId": null, "title": "\u201cDepthFormer:Depthformer:Exploit-inglong-rangecorrelationandlocalinformationforaccuratemonoculardepthestimation,\u201d2022"}, {"paperId": null, "title": "\u201cEdgeFormer: Improving light-weight convnetsbylearningfromvisiontransformers,\u201d2022"}, {"paperId": null, "title": "Henghui Ding is with the Nanyang Technological University, Singapore 637335"}]}