{"paperId": "1900de2b966ca55ee5ca24ec94d5debe66e80c5b", "title": "Dynamic N:M Fine-Grained Structured Sparse Attention Mechanism", "abstract": "Transformers are becoming the mainstream solutions for various tasks like NLP and Computer vision. Despite their success, the high complexity of the attention mechanism hinders them from being applied to latency-sensitive tasks. One opportunity to accelerate the attention mechanism is leveraging the sparsity in the attention weight matrix. However, due to the dilemma between \"dynamic\" and \"fine-grained\", previous studies fail to achieve speedup on GPUs under moderate sequence lengths. They also require costly retraining to recover accuracy. In this paper, we present DFSS, the first GPU-friendly dynamic fine-grained pruning mechanism, to address this dilemma. DFSS dynamically prunes the full attention score matrix to N:M fine-grained structured sparse pattern. Our key insight is that on the dynamic side, N:M sparsity is friendly to pruning and encoding the sparse matrix on GPU. On the fine-grained side, it always preserves the dominant entries in each row. We develop a dynamic sampled dense-dense matrix multiplication kernel, first of its kind, that multiplies the query and key matrices, prunes the result, and encodes the compressed sparse matrix without overhead. Compared with previous studies, DFSS achieves speedup in arbitrary sequence lengths. It only takes a few fine-tuning epochs to reach on-par accuracy with full attention mechanism. We provide both theoretical and empirical evidence to demonstrate DFSS is a good approximation of the full attention mechanism. We evaluate the 1:2 and 2:4 sparsity under different settings and achieve 1.38 ~ 1.86\u00d7 speedups over the full-attention on A100 GPU. On tasks from various domains with sequence lengths from 384 to 4096, its accuracy is on par with the full attention after only a couple of finetuning epochs from the dense pre-trained model.", "venue": "ACM SIGPLAN Symposium on Principles & Practice of Parallel Programming", "year": 2022, "citationCount": 9, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3572848.3577500", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "DFSS is the first GPU-friendly dynamic fine-grained pruning mechanism, and a dynamic sampled dense-dense matrix multiplication kernel is developed, first of its kind, that multiplies the query and key matrices, prunes the result, and encodes the compressed sparse matrix without overhead."}, "embedding": {"model": "specter_v2", "vector": [0.6194806694984436, 0.5908408164978027, -0.38598430156707764, 0.08840043842792511, -0.36090919375419617, 0.16986335813999176, 0.3809477984905243, 0.009252415038645267, -0.51410311460495, -0.27316468954086304, 0.5210841298103333, 0.16035959124565125, 0.4054115414619446, 0.08308044821023941, -0.2579001784324646, 0.2915645241737366, -0.6940984129905701, 0.3926004469394684, 0.22145909070968628, -0.4935340881347656, 0.14143426716327667, -0.7534486055374146, -1.371062159538269, 0.3915466368198395, 0.6170129776000977, 0.7327193021774292, 0.8362336158752441, 0.7446814179420471, -0.629923939704895, 0.42355167865753174, 0.5424041748046875, -0.2954910397529602, 0.40378493070602417, 0.06877855211496353, -0.35078418254852295, -0.3550572693347931, 0.492485374212265, -0.1848190873861313, -0.40027037262916565, 1.2329000234603882, -0.49344417452812195, 0.4566582441329956, 0.4341723322868347, -0.5699045062065125, -0.6695560812950134, 0.5128520131111145, -0.04561912640929222, 0.8443083167076111, 0.1863389015197754, -0.5921353697776794, 1.5828373432159424, -1.5711805820465088, 0.43242278695106506, 1.5854262113571167, 0.5271971225738525, 0.17572112381458282, -0.11789893358945847, -0.5059652924537659, 0.9003416895866394, 0.7248243689537048, -0.7231464982032776, -0.23645655810832977, -0.3617183268070221, -0.07207205146551132, 2.2880196571350098, -0.4026522636413574, 0.20941691100597382, 0.4943612515926361, -0.04333747178316116, 1.3491432666778564, -0.6830023527145386, -0.8735842108726501, -0.38460084795951843, -0.3353559076786041, 0.35530537366867065, 0.7434190511703491, -0.14561210572719574, 0.08835002779960632, -1.1615852117538452, -0.5197726488113403, 0.09628930687904358, 0.2702920436859131, 0.1930023580789566, -0.2155243456363678, -0.1292472779750824, 0.9135534763336182, 0.5005821585655212, 0.7321652770042419, -0.36383873224258423, 0.5438557267189026, 0.49479252099990845, 0.3543089032173157, -0.1493106186389923, 0.5136436223983765, -0.21117372810840607, 0.20098119974136353, -1.1247475147247314, 0.2426755279302597, 0.14718860387802124, 0.9678605198860168, -0.12047215551137924, -0.11215613037347794, -0.7392180562019348, 0.3766646683216095, 0.8541197180747986, 0.2629000246524811, 0.31410136818885803, -0.4363325238227844, 0.36447298526763916, -0.5446668863296509, -0.0492747537791729, -1.0741703510284424, 0.02865772135555744, 0.09140527248382568, -1.1283700466156006, -1.0950204133987427, -0.3916371762752533, 0.17938758432865143, -0.609958827495575, 0.49758151173591614, -0.23516948521137238, 0.5356113910675049, -0.2898317277431488, 0.5177550315856934, 0.5408563613891602, 0.7805141806602478, 0.16364049911499023, 0.368073970079422, 1.1484485864639282, -1.003496766090393, -0.43134644627571106, -1.238388180732727, 0.3655214011669159, -0.42820611596107483, 0.4125128984451294, -0.23334145545959473, -1.2797622680664062, -0.8711565732955933, -0.6582990884780884, -0.40627044439315796, -0.32451963424682617, 0.24238455295562744, 1.0273252725601196, -0.1196373924612999, -0.7584825754165649, 0.7682018280029297, -0.2681420147418976, -0.4453165829181671, 0.7753849625587463, 0.06107486039400101, 0.24811239540576935, -0.6262198090553284, -1.42597234249115, 0.47828415036201477, -0.08612912893295288, -0.6380265951156616, -0.2592995762825012, -0.6077795624732971, -1.241565465927124, 0.5956335067749023, 0.5661411881446838, -0.6578428149223328, 1.1678664684295654, -0.03665115311741829, -0.9366468191146851, 0.7319252490997314, -0.648934543132782, -0.23071275651454926, -0.11767082661390305, -0.43152695894241333, -0.16999289393424988, -0.396991103887558, 0.06688644737005234, 0.41274794936180115, 0.7669370770454407, 0.5171149373054504, -0.5171152949333191, 0.2925496995449066, -0.21702507138252258, -0.10142792761325836, -0.36088767647743225, 0.8817053437232971, -0.6861557364463806, -0.27876392006874084, 0.3004871904850006, 0.7514380812644958, -0.2320593148469925, -0.09246213734149933, -0.05934889614582062, -0.9034187197685242, 0.7131281495094299, 0.13158179819583893, 0.9280568361282349, -1.057922124862671, -0.4684038460254669, -0.04627078026533127, 0.17358426749706268, 0.019040536135435104, -1.0557631254196167, 0.6437862515449524, -0.18466882407665253, -0.08278868347406387, -0.03234325349330902, -0.7768174409866333, 0.065345399081707, -0.45565128326416016, -0.7400399446487427, -0.10809236764907837, 0.27794134616851807, 1.0402377843856812, -1.1544690132141113, 0.031318046152591705, -0.18694919347763062, 0.1692238599061966, -1.3745571374893188, 0.887624979019165, -0.6942784190177917, -0.3143695294857025, -0.24364972114562988, -0.01026146486401558, 0.062348686158657074, -0.584340512752533, 0.3481960892677307, -0.43854430317878723, 0.14489543437957764, 0.3212032616138458, -0.35791316628456116, 1.4891670942306519, -0.3546588718891144, 0.712943434715271, 0.16297848522663116, -0.48957863450050354, 0.291219025850296, 0.03919660672545433, -0.3763120174407959, -0.6063385009765625, 0.009403976611793041, 0.24516160786151886, -0.5975987315177917, -0.0004770188534166664, 0.9688543677330017, 1.295680284500122, -0.31910446286201477, 0.028164563700556755, 0.3894805312156677, -0.20247212052345276, 0.5882441997528076, 0.8012610077857971, 1.0436809062957764, 0.26776373386383057, 0.9127115607261658, -0.0866301953792572, 0.39143097400665283, -0.6305269002914429, -0.1742776781320572, 1.0575343370437622, 1.0127174854278564, 0.6856935024261475, 0.4410807490348816, -0.7738818526268005, -0.5441797375679016, 0.7056742310523987, 0.740970253944397, 1.8729702234268188, -0.06716228276491165, -0.17556370794773102, -0.41880857944488525, -0.20045138895511627, -0.24170248210430145, -0.3046736717224121, -0.42577439546585083, 0.040880702435970306, -0.4441925585269928, -0.9847480058670044, 0.5745501518249512, -0.0028155415784567595, 0.7563820481300354, -0.8250980377197266, -0.2980373203754425, -0.28522148728370667, 0.0771145150065422, -0.9383367896080017, -0.6917100548744202, 0.36101192235946655, -0.2693421542644501, -0.4534478485584259, 0.2748339772224426, -0.1725827157497406, 0.23160919547080994, -0.3005514442920685, 1.1481486558914185, -0.5480947494506836, -0.4598563015460968, 0.06997929513454437, 0.050566744059324265, -0.6432916522026062, -0.136338010430336, 0.5594986081123352, -0.14405077695846558, -0.21940229833126068, 0.7424314022064209, 0.21428433060646057, 0.020594974979758263, -0.24801091849803925, -0.22975200414657593, -0.16617180407047272, 0.3795838952064514, 0.2610526382923126, 0.8168766498565674, -0.7379815578460693, 0.11262336373329163, -1.3377411365509033, 0.901957094669342, -0.30328652262687683, -0.6563163995742798, -0.09920061379671097, -0.31521573662757874, -0.49230286478996277, 0.5688822269439697, -0.7781623005867004, -0.21057623624801636, -0.39482030272483826, -0.192683145403862, -0.5238707065582275, -0.19266384840011597, 0.27774426341056824, 0.3899903893470764, 0.00855119340121746, 0.735877513885498, 0.6290575861930847, 0.34267452359199524, -0.07202025502920151, 0.5680643916130066, -0.9486081004142761, 0.6452076435089111, 0.10144215822219849, 0.12375593930482864, -0.0007477468461729586, -0.10182269662618637, -0.9383494853973389, -0.7137215733528137, -0.6409760117530823, -0.15259665250778198, 0.4308317303657532, -0.1834515929222107, -0.6284363269805908, -0.8457468748092651, -0.26422059535980225, -1.2962896823883057, -0.09700187295675278, -0.18314631283283234, -0.31808412075042725, -0.02805999293923378, -0.8230027556419373, -1.2237468957901, -0.2618175745010376, -0.8928095698356628, -0.778529703617096, 0.7532766461372375, -0.17269112169742584, -0.554078996181488, -0.17865444719791412, 0.03874506428837776, -0.7368155121803284, 1.103421688079834, -0.4858459234237671, 0.7493456602096558, -0.2531082034111023, -0.305866539478302, -0.3692239224910736, -0.3071802258491516, -0.03269223868846893, -0.359022319316864, -0.13974107801914215, -0.6562030911445618, 0.3149443566799164, -0.0699119046330452, -0.29458290338516235, 0.5754177570343018, 0.5188312530517578, 0.6747863292694092, -0.01704275980591774, -0.8074169158935547, 0.5213778614997864, 1.3318665027618408, -0.7522481083869934, 0.15909916162490845, 0.026472285389900208, 0.8568251729011536, -0.24603046476840973, 0.24062372744083405, 0.8575108647346497, 0.011525221168994904, 0.16677866876125336, 0.5004839301109314, 0.0807797908782959, -0.18832717835903168, -0.4996684789657593, 0.2994769513607025, 1.3884352445602417, 0.46028921008110046, 0.05469350144267082, -0.7434788942337036, 0.7031315565109253, -1.3709349632263184, -1.083507776260376, 0.4588111937046051, 0.3713504672050476, 0.4585070013999939, -0.5039050579071045, -0.5921632051467896, -0.6298678517341614, 0.26773801445961, 0.5806723237037659, -0.5552050471305847, -0.4178365170955658, 0.058222148567438126, 0.5110371112823486, 0.16014958918094635, 0.6464361548423767, -0.23064769804477692, 0.6165315508842468, 14.664118766784668, 1.2731032371520996, 0.15881697833538055, 0.6401371955871582, 0.3919321298599243, -0.10656042397022247, -0.05163057520985603, -0.37791964411735535, -1.6342779397964478, -0.17853423953056335, 0.5877577066421509, -0.07819440215826035, 0.4870302677154541, 0.4471648335456848, -0.12970669567584991, 0.005892833229154348, -0.7826586365699768, 1.0374786853790283, 0.6900477409362793, -1.550376534461975, 0.41831961274147034, -0.051618631929159164, 0.4319249987602234, 0.8078239560127258, 0.6462051868438721, 0.8615171313285828, 0.5030183792114258, -0.524600088596344, 0.0963059812784195, 0.40378063917160034, 1.145084023475647, 0.38023141026496887, 0.42618444561958313, 0.7459074258804321, -1.06924307346344, -0.331827312707901, -0.9910037517547607, -1.3038159608840942, 0.08763150870800018, 0.4208056628704071, -0.46599718928337097, -0.5516064763069153, -0.07553007453680038, 1.0685114860534668, 0.3108401596546173, 0.5330324769020081, 0.1120559349656105, -0.009860369376838207, -0.32328712940216064, -0.19251123070716858, 0.3787219822406769, 0.5786238312721252, 0.33998173475265503, 0.20378534495830536, 0.2467518299818039, 0.09861829876899719, 0.020970487967133522, 0.598020613193512, -0.5977579951286316, -0.14973333477973938, -0.4300450384616852, 0.10124731808900833, 0.13791871070861816, 0.7680224180221558, 0.8234686255455017, 0.2318175733089447, -0.6768482327461243, 0.5092217922210693, 1.0549767017364502, -0.08000119030475616, -0.27661919593811035, -0.14010344445705414, 0.2803782820701599, -0.4655083417892456, 0.5485137104988098, 0.7399802803993225, -0.1600007265806198, -0.7910654544830322, -0.7934998273849487, -0.7758499979972839, 0.6006664037704468, -0.5102763772010803, -0.9934049844741821, 0.8200384378433228, -0.32790055871009827, -0.19510850310325623, 0.3209732174873352, -0.5888341665267944, -0.11617837846279144, 0.5578073859214783, -1.283528447151184, -0.5379158854484558, 0.31047698855400085, -0.20172549784183502, 0.030942223966121674, -0.14605747163295746, 1.383545160293579, 0.3591788709163666, 0.050102751702070236, -0.06753039360046387, -0.020352425053715706, -0.2969801425933838, -0.20499904453754425, -0.4449576139450073, 1.2227420806884766, 0.4199683964252472, -0.03523748740553856, 0.22471438348293304, -0.21851783990859985, 0.026517733931541443, -0.8969067335128784, -0.21816618740558624, 0.7333555221557617, -0.8303492069244385, -0.29266542196273804, -0.7420749068260193, -0.8141120076179504, 0.4192592203617096, 0.2793179452419281, -0.14753441512584686, -0.007458401843905449, 0.3455883860588074, -0.5150547027587891, -0.012603539042174816, -0.7901561260223389, -0.15515902638435364, 0.42818865180015564, -0.6399472951889038, -0.4317892789840698, -0.02750643715262413, 0.4962562918663025, -1.3747819662094116, -0.2358270287513733, -0.20462161302566528, 0.3456628918647766, 0.10908336937427521, 1.32261323928833, -0.3290276825428009, 0.7723122239112854, 0.9499810934066772, -0.15325231850147247, -0.5628426671028137, -0.13229086995124817, -0.6724914908409119, -0.6403634548187256, -0.3850620985031128, 0.5375458002090454, -0.32020604610443115, 0.6397148966789246, 0.6088985204696655, 0.5060053467750549, -0.6530115008354187, -0.40340590476989746, 0.0405634380877018, -0.3718020021915436, -0.44579237699508667, 0.38173431158065796, -0.08162444829940796, 0.014332951977849007, 0.20263589918613434, 0.3122962713241577, 0.7122778296470642, -0.31189799308776855, -0.3183332681655884, 0.49610868096351624, -0.19945505261421204, -0.28355973958969116, -0.3897290527820587, -0.33886203169822693, -1.9240562915802002, -0.18542340397834778, -1.0480228662490845, -0.2248699963092804, -0.7883576154708862, -0.36773401498794556, 0.34187695384025574, -0.016468483954668045, 0.16084343194961548, 0.2328907549381256, -0.17735527455806732, -0.32578250765800476, -0.5296474695205688, -0.6677932143211365, 0.6275838613510132, 0.9114459753036499, -0.7554084658622742, 0.06900981068611145, 0.11207683384418488, -0.18816207349300385, 0.6200717687606812, 0.3047243058681488, -0.6423752307891846, -0.4757300615310669, -1.1938343048095703, 0.7277048826217651, -0.0913391262292862, -0.10975997149944305, -0.5740330815315247, 1.2902677059173584, 0.29796797037124634, -0.2681323289871216, -0.29715496301651, 0.616575300693512, -1.1883182525634766, -0.7109062671661377, 0.37386631965637207, -0.6721327304840088, -0.0943254604935646, 0.38020867109298706, -0.45299404859542847, -0.5479578971862793, 0.4717147946357727, -0.022823520004749298, -1.145025372505188, -0.90952068567276, 0.550193727016449, -0.2841811180114746, 0.5861548185348511, -0.4843960404396057, -0.03140651434659958, -1.1459181308746338, -0.4419821798801422, -0.22797313332557678, 0.41219383478164673, -0.5901498198509216, 0.5648059844970703, 0.6691930890083313, -1.1229281425476074, 0.07119551301002502, 0.38404545187950134, -0.1793174147605896, 0.41183900833129883, 0.6246588826179504, 0.46819761395454407, -0.14283211529254913, 0.4149985611438751, 0.3177756667137146, 0.3027998208999634, -1.014603853225708, 0.25997355580329895, 0.6336464881896973, -0.7014452815055847, -0.6026573181152344, 1.1763676404953003, -0.32296866178512573, -0.6497914791107178, 0.31705641746520996, -1.2974543571472168, -0.44514530897140503, -0.10446023941040039, 0.9012158513069153, 0.13728903234004974, 0.09148469567298889, 0.20537304878234863, -0.7626821994781494, 0.21596145629882812, -0.20432744920253754, -0.0153347197920084, 0.6272873878479004, -0.2396070510149002, -0.6250001192092896, 0.06777416914701462, 0.7296401262283325, -0.48674845695495605, -0.45584356784820557, -1.053375482559204, -0.2633168697357178, -0.4892604351043701, -0.04454657435417175, -0.027883686125278473, -0.5116332769393921, 0.514682948589325, -0.01670786738395691, 0.5822599530220032, 0.2391291707754135, -0.14253678917884827, 0.486135870218277, 1.2382490634918213, -0.071510449051857, -0.2808521091938019, -0.6923714280128479, 1.6750783920288086, 1.5460690259933472, -0.8797106742858887, 0.3355102837085724, -0.5188047289848328, -0.6827489137649536, 0.6992918252944946, 0.4150198996067047, -0.5713458061218262, 0.9399706125259399, 0.12914709746837616, -0.4180259704589844, -0.19879207015037537, -1.1033225059509277, -0.4526802599430084, 0.9323616027832031, 1.073090672492981, 0.2796780467033386, -0.37678083777427673, 0.23821806907653809, 0.8253724575042725, 0.13606461882591248, 0.2161610871553421, 0.11459185183048248, 0.07576815783977509, -0.32732516527175903, 0.15342706441879272, -0.1667899340391159, 1.0779767036437988, -0.7754155993461609, -1.0256869792938232, 0.31356748938560486, 0.5672850608825684, 0.24284641444683075, 0.35922765731811523, 0.696979284286499, 0.33740273118019104, 0.7165483832359314, -0.11733803153038025, 0.5394611954689026, -0.9206625819206238, -0.21165232360363007, -0.38699182868003845, -0.8247620463371277, -0.2908414304256439, -0.10974210500717163, -0.6242589354515076, -0.11177244037389755, -0.29811862111091614, 0.3526732623577118, -0.08223491907119751, -0.09690677374601364, 0.8895461559295654, 0.8859072327613831, 0.450638085603714, -0.7141185998916626, -0.7873441576957703, -0.41878247261047363, -1.1119505167007446, 0.0930902510881424, -0.4613189697265625, -0.12157197296619415, 0.0034160283394157887, -0.07490383088588715, -0.2774539887905121]}, "authors": [{"authorId": "2029325771", "name": "Zhaodong Chen"}, {"authorId": "2156789526", "name": "Yuying Quan"}, {"authorId": "46989001", "name": "Zheng Qu"}, {"authorId": "144117143", "name": "L. Liu"}, {"authorId": "119663869", "name": "Yufei Ding"}, {"authorId": "2154871047", "name": "Yuan Xie"}], "references": [{"paperId": "5679ff44de6c462c6320ab497f80860d2faa14e8", "title": "Efficient Tensor Core-Based GPU Kernels for Structured Sparsity under Reduced Precision"}, {"paperId": "2e644c67a697073d561da4f4dad35e5ad5316cfd", "title": "SOFT: Softmax-free Transformer with Linear Complexity"}, {"paperId": "01b1293ddea9bcd6df1185b0b934503de01d6561", "title": "Block Pruning For Faster Transformers"}, {"paperId": "5af69480a7ae3b571df6782a11ec4437b386a7d9", "title": "ELSA: Hardware-Software Co-design for Efficient, Lightweight Self-Attention Mechanism in Neural Networks"}, {"paperId": "90d5e6f8d3b9f2617b3a3cf00fb02e730eb011cb", "title": "Accelerating Sparse Deep Neural Networks"}, {"paperId": "01217fd88d07b05affa75213672d3d31dbcb6617", "title": "A Unified Lottery Ticket Hypothesis for Graph Neural Networks"}, {"paperId": "5e38dc1ccf33ac1df09b8eb6476f110cb3d1966f", "title": "Learning N: M Fine-grained Structured Sparse Neural Networks From Scratch"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "73e0f38ab49b19b86321016b773e15f1d02e3a72", "title": "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "2573af4e13d9a5dddb257d22cd38a600528d9a8b", "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "d5f79a30b3975e447cede805cb24d9879d6c140a", "title": "Systolic Tensor Array: An Efficient Structured-Sparse GEMM Accelerator for Mobile CNN Inference"}, {"paperId": "b03cf6324ecf7a295a4aeae5970c88d1a1c3f336", "title": "Explicit Sparse Transformer: Concentrated Attention Through Explicit Selection"}, {"paperId": "ce106590145e89ea4b621c99665862967ccf5dac", "title": "Q8BERT: Quantized 8Bit BERT"}, {"paperId": "52d655cadb4ab977b951c1d57e740688f54032dd", "title": "Sparse Tensor Core: Algorithm and Hardware Co-Design for Vector-wise Sparse Neural Networks on Modern GPUs"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "910aea4a020c329afb8b8a948abaafdf9ebcab3f", "title": "DropAttention: A Regularization Method for Fully-Connected Self-Attention Networks"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "bf8fe437f779f2098f9af82b534aa51dc9edb06f", "title": "Scaling Neural Machine Translation"}, {"paperId": "21937ecd9d66567184b83eca3d3e09eb4e6fbd60", "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "121c3860d5e3917c658dfac7e1f56ba297e87a6c", "title": "Channel Permutations for N: M Sparsity"}, {"paperId": "875451d00f6a5e7d44c8222ab1ee95c5eedba296", "title": "Cutlass"}, {"paperId": null, "title": "Developing cuda kernels to push tensor cores to the absolute limit on nvidia a100"}, {"paperId": null, "title": "NVIDIA A100 Tensor Core GPU Architecture"}, {"paperId": null, "title": ", Lukasz Kaiser , and Anselm Levskaya . 2020 . Reformer : The E  cient Transformer"}]}