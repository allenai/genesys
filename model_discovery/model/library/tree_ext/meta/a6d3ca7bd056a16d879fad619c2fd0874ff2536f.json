{"paperId": "a6d3ca7bd056a16d879fad619c2fd0874ff2536f", "title": "Exact Conversion of In-Context Learning to Model Weights in Linearized-Attention Transformers", "abstract": "In-Context Learning (ICL) has been a powerful emergent property of large language models that has attracted increasing attention in recent years. In contrast to regular gradient-based learning, ICL is highly interpretable and does not require parameter updates. In this paper, we show that, for linearized transformer networks, ICL can be made explicit and permanent through the inclusion of bias terms. We mathematically demonstrate the equivalence between a model with ICL demonstration prompts and the same model with the additional bias terms. Our algorithm (ICLCA) allows for exact conversion in an inexpensive manner. Existing methods are not exact and require expensive parameter updates. We demonstrate the efficacy of our approach through experiments that show the exact incorporation of ICL tokens into a linear transformer. We further suggest how our method can be adapted to achieve cheap approximate conversion of ICL tokens, even in regular transformer networks that are not linearized. Our experiments on GPT-2 show that, even though the conversion is only approximate, the model still gains valuable context from the included bias terms.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper shows that, for linearized transformer networks, ICL can be made explicit and permanent through the inclusion of bias terms, and mathematically demonstrates the equivalence between a model with ICL demonstration prompts and the same model with the additional bias terms."}, "embedding": {"model": "specter_v2", "vector": [0.2523392140865326, 0.5780305862426758, -0.5534185171127319, -0.127334326505661, -0.5722278356552124, -0.3781382441520691, 0.8581343293190002, -0.05768350884318352, -0.4059131443500519, 0.0603475421667099, 0.4514465928077698, -0.4744417667388916, 0.29453450441360474, 0.24144482612609863, -0.6000134348869324, -0.006047484930604696, -1.0934743881225586, 0.3520905375480652, 0.032084375619888306, -0.1740541011095047, -0.3520445227622986, -0.5756525993347168, -0.6945448517799377, 0.225627601146698, 0.31651854515075684, 0.42357346415519714, 0.45205289125442505, 0.7408477663993835, -0.6098204851150513, 0.7424100041389465, 0.6640697121620178, -0.429816335439682, 0.23477409780025482, 0.2173677533864975, -0.041443049907684326, -0.19970612227916718, 0.48546102643013, -0.32990196347236633, -0.4153778851032257, 0.6389458775520325, -0.2987534999847412, -0.005677978973835707, 0.17318806052207947, -0.8324307799339294, -0.30792880058288574, 0.9835067987442017, 0.6107839941978455, 0.780704140663147, -0.1885521113872528, -0.5974538326263428, 1.6871343851089478, -1.3441277742385864, 0.037069596350193024, 1.5730448961257935, 0.4390398859977722, 0.5218449831008911, -0.16023290157318115, -0.5298877358436584, 1.4487437009811401, 0.08046834915876389, -0.4334210157394409, -0.058687396347522736, 0.15325748920440674, 0.21119196712970734, 1.892674446105957, -0.34606391191482544, 0.49915826320648193, 0.7899463772773743, -0.13446809351444244, 1.7023940086364746, -0.10161980986595154, -1.2720450162887573, -0.2845474183559418, 0.30746132135391235, 0.17710894346237183, 0.8660486340522766, -0.43181154131889343, 0.7518528699874878, -0.8762118220329285, -0.0770515576004982, 0.6948253512382507, -0.04968966916203499, 0.06396480649709702, -0.16919521987438202, -0.24664507806301117, 0.6846781969070435, 0.6972063779830933, 0.8714151978492737, -0.19874423742294312, 1.1079552173614502, 0.30016234517097473, 0.2219618856906891, 0.03620199114084244, 0.2313440591096878, -0.0820862352848053, 0.17577184736728668, -0.6649165153503418, 0.10937273502349854, -0.2578933835029602, 0.6461262106895447, -0.1464391052722931, 0.170232892036438, -0.5676648616790771, 0.33788710832595825, 1.4477534294128418, 0.2557670474052429, 0.6064056158065796, -0.6730040311813354, 0.3889089524745941, -0.6566435098648071, 0.1382795125246048, -0.6276047229766846, 0.03150279447436333, -0.4499915838241577, -0.012330477125942707, -1.1211450099945068, -0.4209933578968048, 0.23177288472652435, -0.3656820058822632, 1.2202259302139282, 0.012938273139297962, 0.1556980013847351, -0.009997706860303879, 0.4657238721847534, -0.11335863173007965, 0.6367364525794983, 0.35341599583625793, 0.05453004315495491, 0.593523383140564, -0.8076678514480591, -0.6084012389183044, -1.3857417106628418, 0.9300650358200073, 0.014305456541478634, 0.5217582583427429, -0.4740264415740967, -0.8595150113105774, -0.6811023354530334, -0.9330143332481384, 0.14156509935855865, -0.695080578327179, -0.18235082924365997, 1.148391604423523, 0.4482000172138214, -1.3054451942443848, 0.758010983467102, -0.21415027976036072, -0.1414027363061905, 0.24781295657157898, 0.31940144300460815, 0.3386622965335846, -0.5503750443458557, -1.4164445400238037, 0.31861522793769836, 0.20022854208946228, -0.32182469964027405, -0.36603260040283203, -0.7552735805511475, -1.2958705425262451, -0.10270146280527115, 0.4376804530620575, -0.5111257433891296, 1.718733549118042, -0.6247984766960144, -1.1462823152542114, 0.5252049565315247, -0.43353012204170227, 0.04638748988509178, 0.08225246518850327, -0.15986773371696472, -0.4820553660392761, -0.4804655909538269, -0.03694893419742584, 0.8628078699111938, 0.22315244376659393, -0.5238376259803772, -0.654154360294342, -0.18234889209270477, -0.003294129390269518, 0.19787722826004028, -0.12510037422180176, 0.5848848819732666, -0.27603891491889954, -0.09114035218954086, 0.14260409772396088, 0.889858603477478, 0.20281216502189636, -0.10314266383647919, -0.09609293192625046, -1.1252104043960571, 0.9415489435195923, 0.19460023939609528, 0.8095982670783997, -0.7565116286277771, -1.0228641033172607, -0.07133224606513977, -0.06760991364717484, -0.1655375212430954, -0.9723740220069885, 0.6029772758483887, -0.6198952794075012, 0.40583792328834534, -0.011322762817144394, -0.8366901874542236, 0.09948474913835526, 0.1075100377202034, -0.8179382681846619, -0.5985666513442993, 0.21875032782554626, 1.0806970596313477, -1.5904324054718018, -0.1982365995645523, 0.08670686930418015, 0.26070061326026917, -0.811518669128418, 1.2384151220321655, -0.3759379982948303, 0.0023832088336348534, -0.11383389681577682, -0.2859877049922943, -0.44856396317481995, -0.04052611067891121, 0.4710272252559662, -0.09440860897302628, -0.10122992843389511, 0.7621697783470154, 0.08580025285482407, 1.1506993770599365, -0.8287819027900696, 0.757529616355896, -0.01679425686597824, -0.5349133014678955, -0.07531299442052841, 0.6343926191329956, -0.4442839026451111, -0.6423732042312622, 0.09100203216075897, 0.3860982656478882, -0.5738228559494019, 0.306956022977829, 0.5704864859580994, 0.4144169092178345, -0.07652786374092102, 0.1771545708179474, 0.35598599910736084, -0.21499072015285492, 0.2701435089111328, 0.6588577032089233, 0.3627171814441681, 0.599571168422699, 0.3436070382595062, 0.052524384111166, 0.12768572568893433, -0.9190258979797363, -0.06706511229276657, 0.606905460357666, 0.7253997325897217, 0.6160200834274292, 0.5514023303985596, -0.7120997309684753, -0.013534137047827244, 0.11154141277074814, 0.6455539464950562, 1.487303376197815, -0.5494540929794312, -0.21604715287685394, -0.7903878688812256, -0.4549594521522522, -0.4145791828632355, 0.4809613823890686, -0.5500615239143372, -0.14268255233764648, -0.41466259956359863, -0.7989419102668762, 0.7276252508163452, 0.7075199484825134, 0.7384201884269714, -0.5244643092155457, -0.09793643653392792, 0.19355274736881256, 0.35266685485839844, -0.7470946311950684, -0.9148255586624146, 0.6902822256088257, -0.8619018197059631, -0.15563803911209106, 0.2572718560695648, -0.33859407901763916, 0.24040047824382782, -0.7027997970581055, 0.7979386448860168, -0.26743027567863464, -0.2318032830953598, 0.5346890687942505, 0.814877986907959, -0.6307514309883118, -0.4889200031757355, 0.23984496295452118, 0.08802273869514465, -0.21614199876785278, 0.3746453523635864, 0.374770849943161, 0.20770679414272308, -0.31146761775016785, -0.20162275433540344, 0.21826636791229248, -0.1425189971923828, 0.1942588835954666, 0.41238829493522644, -0.6405738592147827, 0.07006532698869705, -1.240677833557129, 0.9022732973098755, 0.2270493358373642, -0.7725028395652771, 0.24955680966377258, -0.8289461731910706, -0.2480173259973526, 0.5648117661476135, -0.5771071910858154, -0.3209300935268402, -0.7501821517944336, 0.4178711473941803, -0.07290957868099213, -0.08858027309179306, 0.35033369064331055, 0.10135110467672348, 0.3469861149787903, 0.10790928453207016, 0.28157106041908264, 0.016738273203372955, -0.06608559191226959, 0.7657636404037476, -0.9495038390159607, 0.4548834562301636, -0.46627724170684814, -0.016521355137228966, -0.41711580753326416, -0.18345007300376892, -0.42358943819999695, -0.5884754061698914, -0.25920358300209045, 0.05375190079212189, -0.5123699903488159, -0.30181655287742615, -0.5537634491920471, -0.9411953091621399, -0.17448726296424866, -0.8655354976654053, -0.8759291768074036, -0.09573297202587128, -0.3621423840522766, -0.04425451159477234, -1.0738236904144287, -1.259626030921936, -0.7045716643333435, -0.3535255789756775, -0.8558555245399475, 0.34667590260505676, 0.17058466374874115, -0.16373310983181, -1.0970394611358643, -0.023525996133685112, -0.7756286263465881, 0.9661910533905029, -0.8404936790466309, 1.0544509887695312, 0.28920382261276245, -0.43864330649375916, -0.19457857310771942, 0.28239706158638, 0.23669536411762238, -0.10187368839979172, 0.15919704735279083, -1.253542423248291, 0.31989026069641113, -0.5230346322059631, -0.3753429651260376, -0.19329889118671417, 0.29755786061286926, 0.5149387121200562, -0.08494473993778229, -0.7937503457069397, 0.10682535916566849, 1.5705569982528687, -0.339077889919281, -0.08170519024133682, 0.18630947172641754, 0.9204942584037781, 0.14176525175571442, -0.16385503113269806, 0.010284417308866978, 0.19227609038352966, 0.5443238019943237, 0.40329042077064514, -0.03997252881526947, 0.015604991465806961, -1.0640473365783691, 0.5546726584434509, 1.1803754568099976, 0.403461754322052, 0.28784018754959106, -0.9412686228752136, 0.7704285979270935, -1.480237364768982, -0.49040231108665466, 0.8823655843734741, 0.9077140092849731, 0.6894935369491577, -0.3439026176929474, -0.5285252332687378, -0.3020693063735962, 0.3920179009437561, 0.2565954923629761, -0.16871365904808044, -0.6372053027153015, 0.0344509482383728, 0.2284674495458603, 0.11951030045747757, 1.3790713548660278, 0.024324029684066772, 0.9882034063339233, 14.741276741027832, 0.6927199959754944, -0.18781587481498718, 0.6756340265274048, 0.6427710056304932, 0.07505281269550323, -0.559210479259491, 0.13458764553070068, -1.1808620691299438, -0.3492448329925537, 1.1151376962661743, 0.29593127965927124, 0.8576618432998657, 0.024436429142951965, 0.0958952084183693, 0.1103605106472969, -1.0189197063446045, 0.7348595261573792, 0.44662949442863464, -0.9387397170066833, 0.5409499406814575, 0.2251751869916916, 0.04996000602841377, 0.5043386816978455, 0.8467894792556763, 0.9207264184951782, 0.7563899755477905, -0.16151511669158936, 0.6402227878570557, 0.09161441028118134, 0.9624398350715637, -0.08936940878629684, 0.06754723936319351, 0.4581800401210785, -0.7106858491897583, -0.36186230182647705, -0.5039073824882507, -1.1589741706848145, -0.06449506431818008, 0.17353394627571106, -0.7854578495025635, -0.7615334987640381, -0.14283190667629242, 0.7163748145103455, 0.15135864913463593, 0.29690033197402954, -0.715679407119751, 0.8647392988204956, -0.33153533935546875, -0.07290320098400116, 0.5694478154182434, 0.4907315671443939, 0.15212684869766235, 0.04069000110030174, 0.07848644256591797, 0.0809749960899353, 0.041819244623184204, 0.500313937664032, -0.5666314363479614, -0.10752169042825699, -0.5196429491043091, 0.09982747584581375, 0.17743605375289917, 0.8484397530555725, 0.7906046509742737, 0.09396060556173325, -0.15400882065296173, 0.04491683095693588, 0.9935226440429688, 0.5020982027053833, -0.0354764461517334, 0.18582572042942047, 0.3437117338180542, -0.42996156215667725, -0.05197415128350258, 0.7757664322853088, 0.20176434516906738, -0.4456945061683655, -0.6038033962249756, -0.21248076856136322, 0.18671326339244843, -1.2074358463287354, -0.8972024321556091, 0.8941777348518372, -0.19262082874774933, -0.1421460658311844, 0.23118652403354645, -0.9261770248413086, -0.4473058879375458, 0.40629661083221436, -1.672694206237793, -0.5339279770851135, 0.4166008234024048, -0.19567732512950897, -0.43830230832099915, 0.30311816930770874, 1.2425384521484375, 0.10019056499004364, -0.5762427449226379, 0.164015993475914, 0.3290874660015106, -0.09189969301223755, -0.09714106470346451, -1.254349708557129, 0.683164119720459, 0.20360524952411652, 0.12059035152196884, 0.369230717420578, -0.20194074511528015, 0.3552556037902832, -0.3169075846672058, -0.007963371463119984, 0.9692474603652954, -1.1001558303833008, -0.28622156381607056, -0.8037775158882141, -0.5434816479682922, 0.7760410308837891, 0.8404849171638489, -0.2823496162891388, 0.3922046422958374, 0.327821284532547, -0.780879020690918, -0.636816143989563, -0.521520733833313, 0.4279247224330902, 0.48816999793052673, -0.7039332985877991, -0.43992140889167786, -0.284324049949646, 0.3671432435512543, -0.944233775138855, -0.15400050580501556, -0.7458480000495911, -0.03250811994075775, 0.08133050799369812, 0.9775115847587585, -0.5304586291313171, 0.4067078232765198, 0.7383734583854675, -0.13107985258102417, -1.0388504266738892, -0.22042721509933472, -0.8707751631736755, 0.1198621317744255, 0.41408684849739075, 0.8791234493255615, -0.80912184715271, -0.010215546935796738, 1.0323294401168823, 0.29661253094673157, -0.5695845484733582, -0.6032537817955017, -0.12126995623111725, 0.061164870858192444, -0.8891488313674927, 0.6268442869186401, -0.08170676976442337, 0.14672315120697021, 0.35235852003097534, 0.7504705190658569, 0.6016033291816711, -0.0031596715562045574, -0.7896294593811035, -0.0372241847217083, 0.03815440461039543, -0.07739035785198212, -0.6250844597816467, -0.4069172441959381, -1.4341410398483276, -0.11433511227369308, -1.3091859817504883, 0.10389550030231476, -1.0240063667297363, -0.4458948075771332, -0.3283251225948334, -0.478275865316391, 0.3469202518463135, 0.12636008858680725, -0.7224111557006836, -0.19401589035987854, -0.685299813747406, -0.5863195657730103, 0.7064217925071716, 0.4967823028564453, -0.8690494298934937, 0.42260703444480896, -0.14691494405269623, -0.09766707569360733, 0.0520312562584877, 0.35483643412590027, -0.7082270979881287, -1.0689774751663208, -1.3519582748413086, 0.5822502970695496, -0.3127947449684143, -0.024549202993512154, -0.48725998401641846, 0.5810589790344238, 0.6947078108787537, 0.08307655155658722, 0.11662289500236511, 0.4275234639644623, -1.2576913833618164, -0.6401945352554321, 0.15750724077224731, -1.0119338035583496, 0.18504559993743896, 0.40329670906066895, -0.24185985326766968, -0.3797384202480316, 0.4884463846683502, -0.38124868273735046, -1.303600788116455, -0.6318318843841553, 0.28734079003334045, -0.7897176146507263, 0.15942373871803284, -0.5901638269424438, -0.07679246366024017, -0.9155697822570801, -0.4327257573604584, 0.23232345283031464, 0.608116865158081, -0.36630934476852417, 0.759806215763092, 0.3718724846839905, -1.2134065628051758, 0.4126450717449188, 0.22411446273326874, 0.021476902067661285, 0.07553958147764206, 0.26612943410873413, 0.1271430253982544, -0.1910470575094223, 0.6710747480392456, 0.46016764640808105, 0.10397950559854507, -0.7859289050102234, 0.12425188720226288, 0.9747097492218018, -0.7317067980766296, -0.08362986147403717, 0.9007803201675415, 0.012122044339776039, -1.2403197288513184, 0.3261091709136963, -1.477518916130066, -0.4941733479499817, -0.7755762338638306, 0.8006583452224731, -0.34740111231803894, -0.07525750249624252, 0.34808269143104553, -0.30199864506721497, 0.2515374422073364, -0.23066888749599457, -0.6060758829116821, 0.3241594433784485, -0.15218958258628845, -0.303279846906662, 0.8111253976821899, 0.7041440010070801, -0.7528467774391174, -0.9326445460319519, -0.9177230000495911, -0.4963511824607849, -0.17939536273479462, 0.46692943572998047, -0.6980448365211487, -0.7409449219703674, 0.982492983341217, 0.7203603982925415, 0.21052630245685577, -0.2650231420993805, -0.2558509111404419, -0.13664966821670532, 0.7187113165855408, 0.2519468665122986, -0.4305507242679596, -0.6948249340057373, 1.1725226640701294, 1.2469223737716675, -0.7024164795875549, -0.11201542615890503, -0.06636884063482285, -0.4909648597240448, 0.9606944918632507, 0.5862434506416321, 0.021404573693871498, 0.7957598567008972, -0.22129689157009125, 0.5405991673469543, -0.0033026409801095724, -1.3104010820388794, 0.04199172183871269, 0.30513644218444824, 1.4047449827194214, 0.9179233312606812, 0.4724453091621399, 0.47811830043792725, 0.8795716762542725, 0.18343931436538696, 0.08115431666374207, 0.36446231603622437, 0.6281751990318298, -0.09023028612136841, -0.2710297703742981, -0.17296254634857178, 0.5529788136482239, -0.544835090637207, -1.0372520685195923, 0.12682364881038666, 0.8068110942840576, 0.10399731993675232, 0.5234889388084412, 0.5829018950462341, 0.3770264983177185, 0.5001392364501953, 0.481381356716156, 0.7751780152320862, -0.4555491805076599, -0.5801241397857666, -0.2048778384923935, -0.714983344078064, -0.06799077242612839, -0.1917811930179596, -0.34260013699531555, -0.43173253536224365, 0.196703240275383, 0.16404156386852264, 0.22503679990768433, 0.20227472484111786, 0.9430451393127441, 0.37064436078071594, 0.47975435853004456, -0.4558797776699066, -0.4362778961658478, -0.2899723947048187, -0.8350551724433899, 0.06267759948968887, -0.8935884237289429, -0.1742001473903656, -0.20619070529937744, -0.13898809254169464, -0.4288374185562134]}, "authors": [{"authorId": "2304901619", "name": "Brian K Chen"}, {"authorId": "2112911801", "name": "Tianyang Hu"}, {"authorId": "2305465742", "name": "Hui Jin"}, {"authorId": "2304808790", "name": "Hwee Kuan Lee"}, {"authorId": "2286306688", "name": "Kenji Kawaguchi"}], "references": [{"paperId": "f4d7cc3f547d065f16ef9f6e6d75902d0bf6f28e", "title": "Towards Understanding How Transformer Perform Multi-step Reasoning with Matching Operation"}, {"paperId": "e35074176fdbfae90772cc69a17f95cbd65d18f1", "title": "On the Expressive Power of a Variant of the Looped Transformer"}, {"paperId": "f4a0c4154203808f362e4678f3741b3d317fdc82", "title": "The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "240103933ffe3dac2179cc160a2bd91299357a53", "title": "Retentive Network: A Successor to Transformer for Large Language Models"}, {"paperId": "70c3d5ab03a54281be91709b19e3f50a2e4be0e3", "title": "Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection"}, {"paperId": "11ae58636a5daf0ea1297f1c4ee94042fcebefa8", "title": "Birth of a Transformer: A Memory Viewpoint"}, {"paperId": "7d97c17a75beb89f938eaac1d3ca60ac2245fb2e", "title": "Faith and Fate: Limits of Transformers on Compositionality"}, {"paperId": "ff2a0fb125e7f03428420230c6ecbeafd4cf07a8", "title": "Can We Edit Factual Knowledge by In-Context Learning?"}, {"paperId": "574beee702be3856d60aa482ec725168fe64fc99", "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4"}, {"paperId": "154493f69d7db3d49da0e51df0192c6ad5f1724a", "title": "Larger language models do in-context learning differently"}, {"paperId": "51879aeb001a8397253755247ccd6507d64d2403", "title": "Role of Bias Terms in Dot-Product Attention"}, {"paperId": "d4c60620570801a231a7756f931dda1740288fb9", "title": "Looped Transformers as Programmable Computers"}, {"paperId": "f8cea2c1638c75ad1bf196ff66e7753120d2c54b", "title": "Generalization on the Unseen, Logic Reasoning and Degree Curriculum"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "7aa801b907b59b8ee4cfb1296d9dac22c5164c5d", "title": "What learning algorithm is in-context learning? Investigations with linear models"}, {"paperId": "2fe1ac0b09cc0f50eb83eef6c7c6b45ac8b12413", "title": "Mass-Editing Memory in a Transformer"}, {"paperId": "8fbd7ddf1ea30c991f3b1152a245df77caa18e16", "title": "Learning by Distilling Context"}, {"paperId": "de32da8f5c6a50a6c311e9357ba16aa7d05a1bc9", "title": "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes"}, {"paperId": "1c475acaa1060c8318a625f24bfd88c12f367516", "title": "Prompt Injection: Parameterization of Fixed Inputs"}, {"paperId": "5437e8adab596d7294124c0e798708e050e25321", "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "663662fbd9be73f99c764a7b85982bf825acfe8a", "title": "The Dual Form of Neural Networks Revisited: Connecting Test Time Predictions to Training Patterns via Spotlights of Attention"}, {"paperId": "996445d847f06e99b0bd259345408a0cf1bce87e", "title": "Locating and Editing Factual Associations in GPT"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "3dc7dc1bea9a4f70c02b6759a0bda7aca0005a9e", "title": "A General Language Assistant as a Laboratory for Alignment"}, {"paperId": "10bd4160b44803ada6a3d2e366c44b7e2a4ffe90", "title": "An Explanation of In-context Learning as Implicit Bayesian Inference"}, {"paperId": "a25370452533bf47549243e97852b9cdf7a0ee0e", "title": "Learning the Transformer Kernel"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "2c871df72c52b58f05447fcb3afc838168d94505", "title": "Knowledge Neurons in Pretrained Transformers"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "1bf64f0961da08ea0f9941bd899e916a385e9540", "title": "Adaptive Sampled Softmax with Kernel Based Sampling"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "93499a7c7f699b6630a86fad964536f9423bb6d0", "title": "Effective Approaches to Attention-based Neural Machine Translation"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "319f22bd5abfd67ac15988aa5c7f705f018c3ccd", "title": "Learning internal representations by error propagation"}, {"paperId": null, "title": "GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model"}, {"paperId": null, "title": "A mathematical framework for transformer circuits"}, {"paperId": null, "title": "(b) In the Performers architecture by Choromanski et al."}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "0c0a778e6fdf7e36b1750c533dcc916f86608607", "title": "A Survey on Context Learning"}]}