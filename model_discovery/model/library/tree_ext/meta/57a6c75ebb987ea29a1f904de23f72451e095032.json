{"paperId": "57a6c75ebb987ea29a1f904de23f72451e095032", "title": "Is Mamba Capable of In-Context Learning?", "abstract": "State of the art foundation models such as GPT-4 perform surprisingly well at in-context learning (ICL), a variant of meta-learning concerning the learned ability to solve tasks during a neural network forward pass, exploiting contextual information provided as input to the model. This useful ability emerges as a side product of the foundation model's massive pretraining. While transformer models are currently the state of the art in ICL, this work provides empirical evidence that Mamba, a newly proposed state space model which scales better than transformers w.r.t. the input sequence length, has similar ICL capabilities. We evaluated Mamba on tasks involving simple function approximation as well as more complex natural language processing problems. Our results demonstrate that, across both categories of tasks, Mamba closely matches the performance of transformer models for ICL. Further analysis reveals that, like transformers, Mamba appears to solve ICL problems by incrementally optimizing its internal representations. Overall, our work suggests that Mamba can be an efficient alternative to transformers for ICL tasks involving long input sequences. This is an exciting finding in meta-learning and may enable generalizations of in-context learned AutoML algorithms (like TabPFN or Optformer) to long input sequences.", "venue": "arXiv.org", "year": 2024, "citationCount": 13, "influentialCitationCount": 2, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work provides empirical evidence that Mamba, a newly proposed state space model which scales better than transformers w.r.t. the input sequence length, has similar ICL capabilities and suggests that Mamba can be an efficient alternative to transformers for ICL tasks involving long input sequences."}, "embedding": {"model": "specter_v2", "vector": [0.34467557072639465, 0.3665933907032013, -0.437831848859787, -0.28892064094543457, -0.42245766520500183, -0.12116406857967377, 0.31112226843833923, -0.007027568761259317, -0.33592018485069275, 0.2666507959365845, 0.2580420970916748, -0.37697353959083557, 0.03465673327445984, 0.06733671575784683, -0.3878127634525299, 0.024720478802919388, -0.8576209545135498, 0.3559798300266266, -0.2527989447116852, -0.3144639730453491, 0.07669093459844589, -0.7415899634361267, -0.9515368342399597, 0.7961474657058716, 0.2643677890300751, 0.7744089961051941, 0.3908955752849579, 0.6938533186912537, -0.6444087028503418, 0.28778478503227234, 0.7012197971343994, -0.5322173237800598, 0.3516293168067932, 0.15487568080425262, -0.6439160704612732, -0.1076267808675766, 0.8431052565574646, -0.16433309018611908, -0.5280466675758362, 0.6034981608390808, -0.5750225782394409, 0.4831470847129822, 0.42281800508499146, -0.5068803429603577, -0.11951159685850143, 1.0512702465057373, 1.109770655632019, 0.7512493133544922, -0.2713311016559601, -0.22806799411773682, 1.9120241403579712, -1.3108179569244385, -0.23569786548614502, 1.4889183044433594, 0.596547544002533, 0.8158701062202454, -0.5617221593856812, -0.35085591673851013, 0.8749769926071167, 0.2917104661464691, -0.31239208579063416, -0.2923848032951355, -0.06445576250553131, 0.05212995037436485, 1.7906638383865356, -0.1604345142841339, 0.12655921280384064, 0.5992303490638733, -0.05443406477570534, 1.5492690801620483, -0.008769621141254902, -0.8618324398994446, -0.1073441356420517, 0.08717351406812668, 0.1541818380355835, 0.8949781060218811, -0.5411994457244873, 0.30276554822921753, -0.8965715169906616, 0.09768340736627579, 0.46378788352012634, -0.10077815502882004, 0.1387941688299179, -0.10316362231969833, -0.4282364249229431, 0.6458607912063599, 0.45519667863845825, 0.9297060370445251, -0.45436328649520874, 1.1749560832977295, 0.24023303389549255, 0.3995445966720581, -0.3895997405052185, 0.9272230267524719, -0.4309067726135254, 0.06382536143064499, -0.6863495111465454, 0.0750194862484932, -0.19241729378700256, 0.5610201954841614, -0.1633080691099167, 0.2580146789550781, -0.6329953670501709, 0.14759591221809387, 1.518064022064209, -0.19423693418502808, 0.3941408693790436, -0.9427573084831238, 0.7871303558349609, -0.2864128351211548, 0.15430870652198792, -0.44499343633651733, -0.2410430759191513, -0.21843840181827545, -0.123011514544487, -1.1358048915863037, -0.09874323010444641, 0.4548106789588928, -0.5929359793663025, 0.9427016377449036, -0.4656883478164673, 0.32669541239738464, -0.01700984500348568, 0.21696560084819794, -0.23639023303985596, 0.8510605096817017, 0.3559737801551819, -0.22289781272411346, 0.6741642951965332, -0.7499910593032837, -0.6196496486663818, -1.2738373279571533, 0.7477383613586426, 0.20582519471645355, 0.40398988127708435, -0.07925242185592651, -1.3765809535980225, -1.0207200050354004, -0.9668309688568115, 0.22599980235099792, -0.6391577124595642, -0.14649097621440887, 1.217734694480896, 0.5449469685554504, -0.9980817437171936, 1.1065852642059326, -0.16637229919433594, -0.01241305097937584, 0.40989938378334045, 0.5443567037582397, 0.03881394490599632, -0.5944111347198486, -1.0135579109191895, 0.37099689245224, 0.7914514541625977, -0.09375149011611938, -0.602922260761261, -0.6874671578407288, -1.0428177118301392, -0.11343368887901306, 0.354687362909317, -0.8331676721572876, 1.5463396310806274, -0.26421427726745605, -1.0537910461425781, 0.20614653825759888, -0.12921997904777527, 0.00672181136906147, 0.158720463514328, -0.0860007181763649, -0.6340926289558411, -0.585921049118042, -0.34655892848968506, 0.7573875188827515, 0.389501690864563, -0.15475712716579437, -0.4737820029258728, -0.028689740225672722, 0.11249059438705444, -0.1456483155488968, -0.31356728076934814, 0.3212391138076782, -0.10472763329744339, -0.21753303706645966, 0.42883795499801636, 0.9313556551933289, -0.0737076997756958, -0.0693339854478836, -0.04635347053408623, -0.8646609783172607, 0.8940441012382507, 0.1378934532403946, 1.272112488746643, -0.7841473817825317, -0.681251585483551, -0.10642953962087631, -0.544303834438324, -0.05774720385670662, -1.1276931762695312, 0.6578526496887207, -0.28277644515037537, 0.33296018838882446, -0.5891792178153992, -1.0826691389083862, -0.08811672776937485, 0.20515580475330353, -0.3899593949317932, -0.42147302627563477, 0.194331556558609, 0.9268016219139099, -1.2221347093582153, -0.026770757511258125, 0.17468875646591187, -0.01102322805672884, -1.2073009014129639, 0.9986529350280762, -0.689365804195404, 0.05756894499063492, 0.06368401646614075, -0.02315988391637802, -0.2692076861858368, -0.07360631972551346, 0.30499109625816345, -0.3438619375228882, -0.042988456785678864, 0.8078107237815857, -0.3643500506877899, 1.8906662464141846, -0.8389285206794739, 0.6563940048217773, 0.020263860002160072, -0.6339240074157715, -0.2325815111398697, 0.6668564677238464, -0.3243210017681122, -0.2685147523880005, 0.22577589750289917, 0.40589624643325806, -0.41135627031326294, 0.25213858485221863, 0.7092484831809998, 0.7185847759246826, -0.03937211260199547, 0.14149092137813568, 0.7539837956428528, -0.35653287172317505, 0.559035062789917, -0.07375269383192062, 0.5880028009414673, 0.34582024812698364, 0.2667146325111389, -0.10283524543046951, 0.6069416403770447, -0.9904259443283081, -0.19076159596443176, 0.6954672932624817, 0.5030698180198669, 0.5345107316970825, 0.24436430633068085, -0.9390687346458435, -0.17615024745464325, 0.033098526298999786, 0.35225626826286316, 1.6018602848052979, -0.4184451699256897, -0.2932303547859192, -0.759244978427887, -0.5627414584159851, -0.28257158398628235, 0.594846248626709, -0.7181326746940613, -0.20000627636909485, -0.4245009422302246, -0.9205812811851501, 0.5776367783546448, 0.7763241529464722, 1.1384001970291138, -0.7089693546295166, 0.012926294468343258, 0.282915860414505, 0.3292999565601349, -0.6174728274345398, -0.704348623752594, 0.5419946908950806, -0.969784140586853, -0.43436187505722046, 0.6481574177742004, -0.0806545540690422, 0.23024950921535492, -0.882445216178894, 0.7408124208450317, -0.5135948061943054, -0.08291155099868774, 0.19802026450634003, 0.873354971408844, -0.3138018846511841, -0.7082144618034363, 0.31250548362731934, -0.10210580378770828, -0.11540178209543228, 0.22966264188289642, 0.26522451639175415, 0.2682657241821289, 0.07701975107192993, -0.3389928936958313, 0.17276984453201294, 0.06014135107398033, 0.3851020634174347, 0.5943768620491028, -0.21537643671035767, 0.08415846526622772, -1.2460824251174927, 0.843060314655304, 0.06774169951677322, -0.5722766518592834, 0.18929091095924377, -0.807425856590271, -0.13503266870975494, 0.4932239353656769, -0.41737890243530273, 0.05655800923705101, -0.5800803899765015, 0.26583537459373474, -0.26455065608024597, -0.3386218249797821, 0.37365075945854187, -0.015488647855818272, 0.21217535436153412, 0.3293290138244629, 0.1975170522928238, 0.25190651416778564, -0.0340278334915638, 0.7129726409912109, -1.2103792428970337, 0.43161359429359436, -0.26125502586364746, 0.10360201448202133, -0.4421854019165039, 0.3454403579235077, -0.4296027719974518, -0.5583717226982117, -0.3419177532196045, -0.015768522396683693, -0.022001223638653755, 0.03534126654267311, -0.36982235312461853, -0.8234084844589233, -0.22759407758712769, -0.8646258115768433, -0.6704130172729492, 0.07668206095695496, -0.43965625762939453, -0.42727169394493103, -1.3432270288467407, -0.9635732173919678, -0.6435854434967041, -0.32716917991638184, -1.0905897617340088, 0.20706261694431305, -0.013444875366985798, -0.3082478940486908, -1.0368911027908325, -0.3185109496116638, -0.32158705592155457, 1.1901240348815918, -0.44617828726768494, 0.8306661248207092, 0.19316771626472473, -0.2975493371486664, 0.012910996563732624, 0.4738713502883911, 0.5678027868270874, -0.027194492518901825, 0.03859276697039604, -1.2747588157653809, 0.5491093397140503, -0.41279155015945435, -0.17745238542556763, 0.20122458040714264, 0.24959057569503784, 0.8583999276161194, -0.24622727930545807, -0.3714054822921753, 0.3623751997947693, 1.298929214477539, -0.33449214696884155, 0.12247294932603836, 0.45816972851753235, 0.7253537178039551, 0.08798106014728546, -0.032281119376420975, 0.16812396049499512, -0.02188696525990963, 0.34089896082878113, 0.7100133299827576, 0.7581445574760437, 0.23423069715499878, -0.6671806573867798, 0.2520145773887634, 0.9646473526954651, 0.15704122185707092, 0.11896808445453644, -1.0768884420394897, 0.7793827056884766, -1.5181752443313599, -0.6266449689865112, 0.9065435528755188, 0.693792462348938, 0.43213382363319397, -0.4886949956417084, -0.19219458103179932, 0.27107152342796326, 0.17577844858169556, 0.141054168343544, -0.03781523555517197, -0.8716979622840881, 0.18144676089286804, 0.3817940354347229, -0.02442220412194729, 0.9493813514709473, -0.6656712293624878, 0.3682146668434143, 14.781956672668457, 0.6083253622055054, 0.09383542090654373, 0.5555074214935303, 0.4597875475883484, 0.3196934163570404, -0.5410292148590088, -0.045935653150081635, -1.0403834581375122, 0.05224264785647392, 1.2233247756958008, 0.8513196706771851, 0.90080326795578, 0.2872270345687866, -0.2844862937927246, 0.2676635682582855, -1.0589925050735474, 0.5463087558746338, 0.1509968638420105, -1.5154552459716797, 0.6403789520263672, 0.26832088828086853, 0.17200060188770294, 0.1399734765291214, 1.003538966178894, 1.0668411254882812, 0.17160283029079437, -0.36343491077423096, 0.6790665984153748, 0.20269103348255157, 0.9475405812263489, -0.3641122281551361, 0.31886690855026245, 0.5958930253982544, -0.8186865448951721, -0.7578985691070557, -0.5963352918624878, -0.9358513951301575, -0.18118132650852203, -0.32385319471359253, -0.6100127696990967, -0.5377420783042908, -0.15063714981079102, 0.5344223380088806, 0.20062242448329926, 0.5212568044662476, -0.42912498116493225, 0.510485827922821, -0.0221104733645916, 0.26474061608314514, 0.43426433205604553, 0.42680829763412476, 0.2106459140777588, -0.006103277672082186, 0.1963217854499817, -0.04214319586753845, 0.04329858347773552, 0.5457710027694702, -0.42777132987976074, -0.18252304196357727, -0.34180429577827454, -0.2960403859615326, 0.08286095410585403, 0.6695491671562195, 0.8763559460639954, 0.6884448528289795, -0.18475927412509918, -0.07526863366365433, 0.3734928071498871, 0.1996747851371765, -0.24678708612918854, 0.17405550181865692, 0.524878740310669, -0.47273585200309753, 0.19562122225761414, 0.59895259141922, -0.3463842272758484, -0.26149117946624756, -0.743635356426239, -0.3400116562843323, 0.6093225479125977, -0.9081867337226868, -0.8604435920715332, 0.8854789137840271, -0.09031012654304504, -0.31658539175987244, 0.1330338418483734, -1.2005771398544312, -0.40591901540756226, 0.3018839955329895, -1.3099673986434937, -0.5515176057815552, 0.2771199345588684, -0.07808234542608261, -0.2557092010974884, -0.32815665006637573, 1.3646528720855713, 0.06881269067525864, -0.46221867203712463, 0.23155561089515686, -0.0052637564949691296, -0.33280715346336365, -0.42818334698677063, -1.3274186849594116, 0.6182976365089417, 0.28119373321533203, 0.09038820117712021, 0.445357084274292, -0.1977025270462036, 0.6607100963592529, -0.7229601740837097, -0.20560593903064728, 0.5755816698074341, -1.2802658081054688, -0.4899080991744995, -0.456136018037796, -0.44447192549705505, 0.4721096158027649, 0.4851650297641754, 0.024513689801096916, 0.44742828607559204, 0.14718784391880035, -0.7211331129074097, -0.45697540044784546, -0.9089006185531616, 0.2347388118505478, 0.6020324230194092, -0.411243200302124, -0.6191542744636536, -0.5832505226135254, 0.43022826313972473, -0.935093343257904, -0.3725263476371765, -0.27830544114112854, -0.039115410298109055, -0.14129586517810822, 1.0729601383209229, -0.6820581555366516, 0.7928088307380676, 0.5954211950302124, -0.5733012557029724, -0.8579080104827881, -0.23641599714756012, -0.96568763256073, -0.3818226158618927, 0.1153632327914238, 0.9734917283058167, -0.6607311367988586, 0.34335857629776, 0.7945202589035034, -0.232660710811615, -0.7177388072013855, -0.8134676218032837, -0.24203544855117798, -0.14067454636096954, -0.8658123016357422, 0.6057968139648438, 0.04488270357251167, -0.21712198853492737, -0.022058889269828796, 0.7450487613677979, 0.5387333035469055, -0.40529385209083557, -0.6703172326087952, 0.03381781280040741, 0.05680745840072632, -0.5039121508598328, -0.5731968879699707, -0.483194500207901, -0.8084259033203125, -0.07081755250692368, -1.298119306564331, 0.007099057547748089, -1.1704556941986084, -0.8697167038917542, -0.15747378766536713, -0.6741368770599365, 0.28309208154678345, 0.22023549675941467, -0.7595751881599426, -0.29937371611595154, -0.8578017950057983, -0.501937747001648, 0.4932396709918976, 0.8568314909934998, -0.8022668361663818, 0.0979657769203186, 0.21114368736743927, -0.11109732836484909, 0.08577720075845718, 0.4954315423965454, -0.3779616355895996, -0.9809795618057251, -1.3409748077392578, 0.37702515721321106, -0.1337847113609314, -0.32111692428588867, -0.917689323425293, 0.6524059772491455, 0.06872765719890594, -0.05560107156634331, 0.2247551828622818, 0.7168530821800232, -1.507210373878479, -0.5963890552520752, 0.31318408250808716, -0.7454497218132019, 0.40483880043029785, 0.6212760806083679, -0.18926061689853668, -0.5097109079360962, 0.3919222354888916, -0.1261613667011261, -1.1533074378967285, -0.7746726274490356, 0.2794295847415924, -0.6789928078651428, -0.01382461842149496, -0.38069289922714233, -0.2685708701610565, -1.1487376689910889, -0.01255552563816309, 0.08526944369077682, 0.5428699851036072, -0.5637432932853699, 0.4283469021320343, 0.48083585500717163, -1.1040010452270508, 0.34182068705558777, 0.514728844165802, 0.0541459396481514, 0.15126384794712067, 0.39166751503944397, 0.49440643191337585, -0.29421380162239075, 0.3925936222076416, -0.08586535602807999, 0.12020609527826309, -0.25077977776527405, 0.0754532739520073, 1.0224648714065552, -0.5752013921737671, 0.17292916774749756, 1.0713320970535278, -0.3819957971572876, -1.0003697872161865, 0.3356294631958008, -1.289750099182129, -0.4058079719543457, -0.5970159769058228, 0.6912051439285278, 0.008195828646421432, -0.16908490657806396, 0.5582475066184998, -0.22178104519844055, -0.01924506016075611, -0.05013008415699005, -0.47327032685279846, 0.6154926419258118, 0.21528248488903046, -0.48282307386398315, 0.7228273153305054, 0.4017232656478882, -0.8799529671669006, -0.7331405878067017, -0.5011721849441528, -0.18549828231334686, -0.3681038022041321, 0.34738367795944214, -0.4974592626094818, -0.7081012725830078, 0.9752242565155029, 0.37353742122650146, 0.12717071175575256, 0.2800385653972626, -0.6382108330726624, -0.003573200898244977, 0.9525482058525085, 0.14186011254787445, -0.4803152084350586, -0.48428407311439514, 1.1683987379074097, 1.2462987899780273, -0.8430612683296204, 0.1614803820848465, -0.09898800402879715, -0.18110932409763336, 1.318394422531128, 0.7541706562042236, -0.14888711273670197, 0.6711023449897766, -0.4313342869281769, -0.254365473985672, 0.3043198585510254, -1.3920468091964722, 0.10233698040246964, 0.9081957340240479, 1.2915310859680176, 0.5623272657394409, 0.16396108269691467, 0.7036474347114563, 1.054123044013977, 0.19442856311798096, -0.17267079651355743, 0.5219076871871948, 0.6150153279304504, -0.3771940767765045, -0.3143438398838043, 0.029132818803191185, 0.513685405254364, -0.6179481148719788, -0.6316844820976257, 0.3250771760940552, 1.0809696912765503, 0.33542364835739136, 0.4776516258716583, 0.835114061832428, -0.017880024388432503, 0.5486475229263306, 0.6175716519355774, 0.7472404837608337, -0.8472004532814026, -0.6312319040298462, -0.6946091651916504, -0.5781548023223877, -0.24670864641666412, -0.13042573630809784, -0.4536752700805664, -0.09612710773944855, 0.14015041291713715, 0.30566608905792236, 0.07897355407476425, 0.3664061427116394, 0.9349261522293091, 0.30896443128585815, 0.5171698331832886, -0.6932299733161926, -0.3190945088863373, -0.42222148180007935, -0.8567472696304321, 0.4858059287071228, -1.0230756998062134, -0.15598095953464508, -0.26731300354003906, -0.25989818572998047, -0.45693907141685486]}, "authors": [{"authorId": "2282540298", "name": "Riccardo Grazzi"}, {"authorId": "81742501", "name": "Julien N. Siems"}, {"authorId": "2061149094", "name": "Simon Schrodi"}, {"authorId": "2239727176", "name": "Thomas Brox"}, {"authorId": "2282539872", "name": "Frank Hutter"}], "references": [{"paperId": "9da427202cc48370fd66359f5d72ff5ff3bc8b57", "title": "Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks"}, {"paperId": "85447eeb6e5276e713957835125a2273f9ac0694", "title": "In-Context Language Learning: Architectures and Algorithms"}, {"paperId": "38c48a1cd296d16dc9c56717495d6e44cc354444", "title": "Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model"}, {"paperId": "c1a04730c83967d0bb904b02263b17893cb50bad", "title": "U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation"}, {"paperId": "62b18cc55dcc7ffe52c28e1086aee893b7bc4334", "title": "Gated Linear Attention Transformers with Hardware-Efficient Training"}, {"paperId": "f483c00cc45dd387364dc485794c27afae9289bb", "title": "The mechanistic basis of data dependence and abrupt learning in an in-context classification task"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "2d2bfb068e3441aaa9743043603d00f860dd0308", "title": "ForecastPFN: Synthetically-Trained Zero-Shot Forecasting"}, {"paperId": "19edd41688c844d4ffd5230b417b99b5fd041cf1", "title": "Efficient Bayesian Learning Curve Extrapolation using Prior-Data Fitted Networks"}, {"paperId": "297211bc86653d9ebbe694a75141c9a1c6c11e69", "title": "In-Context Learning Creates Task Vectors"}, {"paperId": "b13947c7598aa91992cf04048afa19c7cfe69795", "title": "Function Vectors in Large Language Models"}, {"paperId": "e764ad9ccf0b31a0c91a9220290930f083ad062a", "title": "Is attention required for ICL? Exploring the Relationship Between Model Architecture and In-Context Learning Ability"}, {"paperId": "f8a2dca1e8fe56e698984c077f7ff58d8ca867e9", "title": "Large Language Models as Optimizers"}, {"paperId": "70c3d5ab03a54281be91709b19e3f50a2e4be0e3", "title": "Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection"}, {"paperId": "f5e9337477d7a9eb6267d0310549fdefafbb7fe2", "title": "Transformers learn to implement preconditioned gradient descent for in-context learning"}, {"paperId": "fa984cd8632af37ee6a587043619a688ad5c354d", "title": "PFNs4BO: In-Context Learning for Bayesian Optimization"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8", "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"}, {"paperId": "983d8b87693e909eb8b2f2fe74a6244dd65b61ee", "title": "Selective Structured State-Spaces for Long-Form Video Understanding"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "525d93a382f6e7873b5d8a2e0713eb3dff7fb250", "title": "Transformers learn in-context by gradient descent"}, {"paperId": "7aa801b907b59b8ee4cfb1296d9dac22c5164c5d", "title": "What learning algorithm is in-context learning? Investigations with linear models"}, {"paperId": "6d7d141c75af752ffc0d8a6184cca3f9323d6c74", "title": "Simplified State Space Layers for Sequence Modeling"}, {"paperId": "de32da8f5c6a50a6c311e9357ba16aa7d05a1bc9", "title": "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes"}, {"paperId": "4c4f0fcf1ce04f12290d8c876abfbe57817de430", "title": "TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second"}, {"paperId": "eaef083b9d661f42cc0d89d9d8156218f33a91d9", "title": "Long Range Language Modeling via Gated State Spaces"}, {"paperId": "943cd7cf7ba21911561d03228dc2dd3f397168c9", "title": "Towards Learning Universal Hyperparameter Optimizers with Transformers"}, {"paperId": "146e9e1238ff6caf18f0bd936ffcfbe1e65d2afd", "title": "Data Distributional Properties Drive Emergent In-Context Learning in Transformers"}, {"paperId": "71e15a9a52dcafca57bff5f310b95e2c7d0cfc87", "title": "Diagonal State Spaces are as Effective as Structured State Spaces"}, {"paperId": "b55ee75940d24934a54d7f1acfde06e9cb45ac44", "title": "It's Raw! Audio Generation with State-Space Models"}, {"paperId": "d88a5ae1673f2009704186acf2890163e6ddf4ca", "title": "Transformers Can Do Bayesian Inference"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "ca9047c78d48b606c4e4f0c456b1dda550de28b2", "title": "Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "054e307c1edf4b28137ffcbce980fe81f0647d20", "title": "Finetuning Pretrained Transformers into RNNs"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "4a54d58a4b20e4f3af25cea3c188a12082a95e02", "title": "Transformer Feed-Forward Layers Are Key-Value Memories"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "020bb2ba5f3923858cd6882ba5c5a44ea8041ab6", "title": "Meta-Learning in Neural Networks: A Survey"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "7cf64265882f7129b127ce0e27ff7bca9173aa58", "title": "The Context"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "26bc9195c6343e4d7f434dd65b4ad67efe2be27a", "title": "XGBoost: A Scalable Tree Boosting System"}, {"paperId": "5794f07b2ce5a04241198d42e81623380d2c7e2e", "title": "Novel approach to nonlinear/non-Gaussian Bayesian state estimation"}, {"paperId": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5", "title": "A tutorial on hidden Markov models and selected applications in speech recognition"}, {"paperId": "3092a4929bdb3d6a8fe53f162586b7431b5ff8a4", "title": "A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains"}, {"paperId": "a9d460f8eb9001b1bed11b7fb2af555185c70fcf", "title": "Do pretrained Transformers Really Learn In-context by Gradient Descent?"}, {"paperId": "d86ca0894cb4d165eb5ef45b73526ca8b4cdd725", "title": "Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers"}, {"paperId": "cf0f8f585c8822e3c6bcd9527d546eefc8486aea", "title": "S4ND: Modeling Images and Videos as Multidimensional Signals with State Spaces"}, {"paperId": null, "title": "GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "255a77422b1da74da05d1714b7875356187385bd", "title": "A New Approach to Linear Filtering and Prediction Problems"}, {"paperId": null, "title": "1.1 Model parameters"}, {"paperId": null, "title": "1.6 ICL learning curves. The scale and shift were estimated for each layer and each task and are reported in"}, {"paperId": null, "title": "Results for grid search over \ud835\udefe for GD++. We optimized \ud835\udefe in order to have optimal average performance across tasks of GD++ at iteration 24 (the same number of iterations reported in Figure 3d)."}, {"paperId": null, "title": "A.1 ICL for simple function classes We follow the experimental setup of Garg et al. (2022) by building on their MIT-Licensed code"}]}