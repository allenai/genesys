{"paperId": "e9484cf633985ccef70b0ce46866ce232a81ca4b", "title": "Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length", "abstract": "The quadratic complexity and weak length extrapolation of Transformers limits their ability to scale to long sequences, and while sub-quadratic solutions like linear attention and state space models exist, they empirically underperform Transformers in pretraining efficiency and downstream task accuracy. We introduce Megalodon, a neural architecture for efficient sequence modeling with unlimited context length. Megalodon inherits the architecture of Mega (exponential moving average with gated attention), and further introduces multiple technical components to improve its capability and stability, including complex exponential moving average (CEMA), timestep normalization layer, normalized attention mechanism and pre-norm with two-hop residual configuration. In a controlled head-to-head comparison with Llama2, Megalodon achieves better efficiency than Transformer in the scale of 7 billion parameters and 2 trillion training tokens. Megalodon reaches a training loss of 1.70, landing mid-way between Llama2-7B (1.75) and 13B (1.67). Code: https://github.com/XuezheMax/megalodon", "venue": "arXiv.org", "year": 2024, "citationCount": 8, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "In a controlled head-to-head comparison with Llama2, Megalodon achieves better efficiency than Transformer in the scale of 7 billion parameters and 2 trillion training tokens."}, "embedding": {"model": "specter_v2", "vector": [0.3510739803314209, 0.6486929059028625, -0.5451550483703613, -0.050701890140771866, -0.14102229475975037, -0.21014584600925446, 0.7183247208595276, -0.30222266912460327, -0.6699063777923584, -0.13662129640579224, 0.14349865913391113, -0.3820315897464752, 1.0026130676269531, 0.3265317380428314, -0.07317669689655304, -0.14195650815963745, -1.1450401544570923, -0.06141682341694832, -0.07380156219005585, 0.10505867749452591, 0.078037790954113, -0.6590371131896973, -0.7777965664863586, 0.2762366235256195, 0.027682488784193993, 0.9262212514877319, 0.4040473997592926, 1.074709415435791, -0.504526674747467, 0.6230185627937317, 0.28564074635505676, -0.11174976080656052, 0.15149614214897156, -0.1626995950937271, -0.48871830105781555, -0.21245920658111572, 0.6326702833175659, -0.27207157015800476, -0.31205394864082336, 0.6554891467094421, -0.03678160905838013, 0.38130855560302734, 0.32587775588035583, -0.6643313765525818, -0.12652505934238434, 0.9408189654350281, 0.6501981019973755, 0.8628608584403992, -0.6494606733322144, -0.351449579000473, 1.1581306457519531, -1.3542770147323608, 0.05164771527051926, 1.3423315286636353, 0.7617892026901245, 0.4769328236579895, -0.14334328472614288, -0.650026798248291, 0.8857263326644897, 0.44710636138916016, -0.4764460027217865, -0.41517290472984314, -0.17165015637874603, 0.056822873651981354, 1.9906914234161377, -0.5909063220024109, 0.10910245776176453, 0.964957594871521, 0.2354343831539154, 1.3191962242126465, 0.004785585682839155, -0.9015836715698242, -0.0018848254112526774, -0.12387774139642715, 0.4072107970714569, 0.769017219543457, -0.5563085675239563, 0.40113571286201477, -0.7240741848945618, 0.0379890501499176, 0.1697850078344345, -0.11966550350189209, 0.42752769589424133, 0.1122879609465599, -0.3148551881313324, 0.5918357372283936, 0.34819766879081726, 0.982043445110321, -0.2928420305252075, 0.858151912689209, 0.4622367024421692, 0.06116316467523575, 0.10087084770202637, 0.3418601155281067, -0.2463577836751938, -0.025134999305009842, -0.9748286604881287, -0.10485545545816422, -0.4236616790294647, 1.0207682847976685, -0.3148541748523712, 0.6868659257888794, -0.4951368570327759, -0.24239662289619446, 1.1711920499801636, 0.03844553604722023, 0.4637044072151184, -0.9897571802139282, 0.19265130162239075, -0.5994710922241211, 0.04637114703655243, -0.5322268605232239, -0.46621230244636536, -0.298067569732666, -0.7587859034538269, -1.0533391237258911, -0.45331788063049316, -0.03802325204014778, -0.7473310232162476, 0.8092167377471924, -0.4257236421108246, 0.43674176931381226, -0.03765815868973732, 0.01688349060714245, 0.36523503065109253, 0.7908051609992981, 0.3775349259376526, -0.09365371614694595, 0.7213398218154907, -1.1165480613708496, -0.6059302687644958, -1.1511192321777344, 0.5633808374404907, 0.09611029177904129, 0.16072699427604675, -0.03815578296780586, -1.100465178489685, -1.0979053974151611, -1.0491023063659668, -0.027971846982836723, -0.5567029714584351, 0.24722547829151154, 1.2126158475875854, 0.25629016757011414, -0.5405165553092957, 0.7708433866500854, -0.8169557452201843, 0.03835733234882355, 0.46607354283332825, -0.029027903452515602, 0.43600642681121826, -0.14971086382865906, -1.229225754737854, 0.507348358631134, 0.7568420767784119, -0.10314489156007767, -0.19563861191272736, -0.7113281488418579, -1.0945309400558472, -0.041367243975400925, 0.3178809583187103, -0.09120060503482819, 1.3134095668792725, -0.1884792149066925, -1.2347685098648071, 0.5563166737556458, -0.48055821657180786, -0.12967929244041443, 0.4394148588180542, -0.18375849723815918, -0.5503146052360535, -0.40878787636756897, -0.5019865036010742, 0.6586243510246277, 0.5396844744682312, 0.10804427415132523, -0.4198234975337982, 0.13808728754520416, -0.5404337048530579, -0.42097207903862, -0.19064372777938843, 0.7013171911239624, -0.19380487501621246, -0.13402125239372253, 0.2430219054222107, 0.4931650459766388, -0.20539432764053345, -0.38537561893463135, -0.17399320006370544, -1.0874425172805786, 0.6571325659751892, -0.2526065707206726, 1.335645079612732, -0.6459421515464783, -0.8075304627418518, -0.35719287395477295, -0.29335036873817444, 0.10253763943910599, -0.8009483218193054, 0.3547384440898895, -0.3144667148590088, 0.223362997174263, -0.2084622085094452, -1.192916989326477, 0.15253566205501556, -0.18830609321594238, -0.41602733731269836, -0.08400412648916245, 0.13127943873405457, 1.3104747533798218, -1.1466851234436035, -0.22188252210617065, 0.13918578624725342, 0.2347232848405838, -1.0822393894195557, 1.0427730083465576, -0.38353991508483887, 0.13345550000667572, 0.14838090538978577, -0.13540607690811157, -0.21118731796741486, -0.42932313680648804, 0.7556009292602539, -0.3599308431148529, -0.17064671218395233, 0.423748254776001, -0.5360987782478333, 1.5140091180801392, -0.693418562412262, 0.9799138903617859, -0.22877541184425354, -0.5475725531578064, -0.1981477588415146, 0.23960259556770325, -0.13104474544525146, -0.39929771423339844, 0.4265287518501282, 0.06784055382013321, -0.6588094830513, 0.018118899315595627, 0.7533313035964966, 1.0210717916488647, -0.34169095754623413, -0.02721947617828846, 0.8330031633377075, -0.008013879880309105, 0.11638715118169785, 0.28696945309638977, 0.46431708335876465, 0.7243107557296753, 0.5535417199134827, -0.017076831310987473, -0.05472597852349281, -0.938217282295227, 0.21295340359210968, 0.4799334406852722, 0.5406699776649475, 0.5817434191703796, 0.376046746969223, -0.8388373851776123, -0.9022195935249329, 0.4118119180202484, 0.5243517756462097, 1.3150582313537598, -0.2946445941925049, 0.024753769859671593, -0.7135440707206726, -0.1486210823059082, -0.6155123710632324, 0.3932836055755615, -0.2730981111526489, 0.06357622146606445, -0.7104496359825134, -0.868227481842041, 0.7551491260528564, 0.35834094882011414, 1.0325363874435425, -0.9298775792121887, -0.5354907512664795, 0.04989341273903847, 0.19991548359394073, -0.906412661075592, -0.594918966293335, 0.336317241191864, -0.5047845840454102, -0.21929560601711273, 0.4414364993572235, -0.11627587676048279, 0.10333985835313797, -0.993712842464447, 0.965368926525116, -0.6645887494087219, -0.24611923098564148, 0.06758398562669754, 0.41817086935043335, -0.5292308926582336, -0.7515364289283752, 0.3641001582145691, 0.26576483249664307, -0.07906529307365417, 0.4194549024105072, 0.22749149799346924, 0.0751970112323761, -0.3189249634742737, -0.17362356185913086, 0.11242885887622833, 0.42824292182922363, -0.0018818993121385574, 0.5013468861579895, -0.4620283842086792, 0.268584668636322, -1.0252416133880615, 0.37775102257728577, 0.2243858128786087, -0.6891348361968994, 0.20232520997524261, -0.8856080174446106, -0.18432919681072235, 0.36202508211135864, -0.8151406645774841, -0.10350091010332108, -0.7557502388954163, 0.07875289022922516, -0.5140975117683411, -0.33337152004241943, -0.06657316535711288, 0.17082449793815613, 0.44476667046546936, 0.17536184191703796, 0.5373339056968689, -0.06850888580083847, 0.06922828406095505, 0.7676071524620056, -0.6815066337585449, 0.9229184985160828, 0.49638789892196655, -0.3038387894630432, -0.2887769043445587, -0.03573150560259819, -0.7595159411430359, -0.5240485072135925, -0.3761049807071686, -0.611032247543335, -0.2028239518404007, 0.6033831238746643, -0.39380139112472534, -1.241500973701477, 0.16760697960853577, -1.1013460159301758, -0.7197171449661255, 0.4217802584171295, 0.00570383295416832, -0.2663721740245819, -0.885653018951416, -1.0956615209579468, -0.7640621066093445, -0.570269763469696, -0.752903938293457, 0.16046980023384094, -0.105844646692276, -0.4632650315761566, -0.6787664890289307, -0.06119712069630623, -0.6268684267997742, 0.9396867156028748, -0.3794403374195099, 0.4860200583934784, 0.04331296309828758, -0.01427115872502327, -0.38574424386024475, 0.6043775677680969, 0.6583641171455383, -0.24995291233062744, 0.3247537612915039, -0.8893595337867737, 0.22566860914230347, -0.4564107358455658, -0.27709823846817017, 0.1379932314157486, 0.4401075541973114, 0.6000722646713257, -0.22976505756378174, -0.24458889663219452, 0.29885134100914, 1.1289918422698975, -0.4232999384403229, 0.21004131436347961, 0.1178118884563446, 0.7392651438713074, -0.11292783915996552, -0.09478315711021423, 0.5256496071815491, 0.13242919743061066, 0.298381507396698, 0.38486963510513306, 0.3211767375469208, 0.15495359897613525, -0.5147654414176941, 0.8280948996543884, 1.497862696647644, 0.33051395416259766, 0.17117586731910706, -0.82368004322052, 0.6003846526145935, -0.9216375350952148, -1.2841991186141968, 0.6994688510894775, 0.6461167335510254, 0.5142640471458435, -0.3418603837490082, -0.31959453225135803, -0.35010409355163574, 0.4069956839084625, 0.4851890504360199, -0.5806195735931396, -0.6674375534057617, -0.014118678867816925, 0.18413648009300232, 0.19716139137744904, 0.8442127704620361, -0.48229479789733887, 0.6643481254577637, 15.191030502319336, 0.8306589126586914, -0.1862536072731018, 0.6934908628463745, 0.7029849886894226, 0.12179584056138992, -0.005616854876279831, -0.1604812741279602, -1.4544485807418823, 0.15982550382614136, 1.4195431470870972, 0.6426219940185547, 0.4686713218688965, 0.31784844398498535, 0.2235482931137085, 0.26528576016426086, -0.7627741098403931, 0.8171876668930054, 0.47740238904953003, -1.4023324251174927, -0.0975145772099495, 0.02723550610244274, 0.5208386182785034, 0.6086905002593994, 0.665578305721283, 1.031233310699463, 0.5751940011978149, -0.28414151072502136, 0.5592043995857239, 0.3269912004470825, 0.8759582042694092, -0.1369287520647049, 0.4199865758419037, 0.6394045352935791, -0.880586564540863, -0.1528235822916031, -0.4330059885978699, -0.990563690662384, 0.32356834411621094, 0.06550585478544235, -0.48532751202583313, -0.5545811057090759, -0.24009573459625244, 0.6268055438995361, 0.2703329622745514, 0.06838072091341019, -0.267130583524704, 0.9105998873710632, -0.06493358314037323, -0.0005430933670140803, 0.6349663734436035, 0.30811217427253723, -0.07263370603322983, 0.055758699774742126, -0.050239138305187225, 0.10949701815843582, 0.44949740171432495, 0.41973647475242615, -0.4199162423610687, -0.34382516145706177, -0.044878117740154266, -0.4852449595928192, 0.16098251938819885, 0.8908143043518066, 0.635408878326416, 0.045438747853040695, -0.30480557680130005, 0.4044559597969055, 0.5091013312339783, 0.022017501294612885, -0.5894379615783691, -0.11047380417585373, 0.07582781463861465, -0.9749916195869446, 0.06332603842020035, 0.24201606214046478, -0.027179595082998276, -0.5294148921966553, -0.8307769894599915, -0.29835328459739685, 0.24546031653881073, -0.7369523644447327, -0.40956002473831177, 0.8724569082260132, -0.39539191126823425, -0.3834882378578186, -0.09003471583127975, -0.7033431529998779, -0.1814696341753006, 0.3093179762363434, -1.1270396709442139, -0.7276076078414917, 0.10950859636068344, -0.5518698692321777, -0.10848197340965271, 0.08215377479791641, 1.0407432317733765, 0.3254587948322296, -0.4684576988220215, 0.14170454442501068, -0.1934053599834442, 0.02257412113249302, -0.3616214096546173, -0.7794268727302551, 1.1136550903320312, 0.586764395236969, -0.07069052010774612, 0.048033855855464935, -0.146172896027565, 0.2364046722650528, -0.3886032700538635, -0.13936154544353485, 0.4981899857521057, -1.213909387588501, -0.37875789403915405, -0.9639111161231995, -0.6115278005599976, 0.8045440912246704, 0.4618750512599945, -0.07694890350103378, 0.11485785990953445, -0.1618478000164032, -0.3889143168926239, 0.20306988060474396, -0.4483044743537903, 0.08868320286273956, 0.38231974840164185, -0.5392818450927734, -0.45529240369796753, -0.49979647994041443, 0.6771458387374878, -0.765901505947113, -0.7335883975028992, -0.33931323885917664, 0.2735038995742798, -0.04070132598280907, 0.5301713943481445, -0.7947342395782471, 0.4891268312931061, 1.126028299331665, -0.30039888620376587, -0.7006896138191223, 0.0326872393488884, -0.8898239135742188, -0.38842466473579407, 0.2250405251979828, 0.5600051283836365, -0.28041690587997437, 0.4531889259815216, 0.418236643075943, -0.042806725949048996, -0.6327707171440125, -0.6664386987686157, -0.42165470123291016, 0.057513877749443054, -0.8486706614494324, 0.016602812334895134, 0.1698743849992752, -0.11868911981582642, 0.13671782612800598, 0.11441611498594284, 0.6249216794967651, -0.21667800843715668, -0.651361882686615, 0.13979656994342804, 0.17489200830459595, -0.31794893741607666, -0.6429124474525452, -0.7065006494522095, -1.4533040523529053, 0.04420517757534981, -0.9869889616966248, 0.0485885851085186, -0.6309427618980408, -0.6050870418548584, -0.02802891656756401, -0.1801636666059494, 0.25711625814437866, 0.0638423040509224, -0.41770872473716736, -0.4314378499984741, -0.8193449974060059, -0.7609187960624695, 0.7096997499465942, 0.4893284738063812, -0.6700974106788635, -0.016696788370609283, 0.03805938735604286, 0.5574823021888733, 0.23558786511421204, 0.487541526556015, -0.34134843945503235, -0.441702276468277, -1.1053497791290283, 0.4856588840484619, -0.16105222702026367, -0.22600631415843964, -0.8702479600906372, 0.40091726183891296, 0.28062278032302856, -0.1613241583108902, -0.2796488106250763, 0.3418743312358856, -0.8912754654884338, -0.5597288608551025, 0.4506866931915283, -0.8996050953865051, 0.19788047671318054, 0.23851561546325684, -0.6236651539802551, -0.0733131617307663, 0.4792184829711914, 0.05944783613085747, -0.9802655577659607, -1.201897382736206, 0.6056708693504333, -0.676020085811615, 0.1905626803636551, -0.21615847945213318, -0.023140162229537964, -0.9728326797485352, -0.2362171709537506, -0.22479045391082764, 0.5063011646270752, -0.5693989992141724, 1.0344979763031006, 0.17147083580493927, -1.2167818546295166, 0.10528093576431274, 0.11806320399045944, -0.2998709976673126, 0.2504212558269501, 0.5078614950180054, 0.4874195456504822, -0.3238790035247803, 0.6420950293540955, 0.1407313197851181, 0.31717100739479065, -0.8057770133018494, 0.3111184239387512, 0.8255939483642578, -0.381876677274704, -0.06773634254932404, 0.9734273552894592, -0.641701877117157, -1.1468182802200317, 0.5456064343452454, -1.4004567861557007, -0.38242119550704956, -0.030037149786949158, 0.7654869556427002, 0.43544328212738037, -0.12701798975467682, 0.19479894638061523, -0.4491299092769623, 0.13122870028018951, 0.2570507228374481, -0.35665279626846313, 0.8310090899467468, -0.22962486743927002, -0.17215083539485931, 1.1586090326309204, 1.0652141571044922, -0.5699266195297241, -1.0605086088180542, -0.7485799789428711, -0.13629557192325592, 0.37026453018188477, 0.25870785117149353, -0.26597246527671814, -0.43808478116989136, 0.907525360584259, 0.7105397582054138, 0.05383168160915375, -0.08586738258600235, -0.14291472733020782, 0.07766420394182205, 0.9948470592498779, 0.16097848117351532, -0.5827996730804443, -0.35803669691085815, 1.0785623788833618, 0.9094290137290955, -0.9911392331123352, 0.34164753556251526, 0.28036707639694214, -0.6980662941932678, 0.8412681221961975, 0.3977288007736206, -0.07043369114398956, 0.6204250454902649, -0.18958695232868195, 0.1506725549697876, 0.38629859685897827, -1.0860346555709839, -0.07330098003149033, 0.5591080784797668, 0.7172566056251526, 0.5359635949134827, 0.11642486602067947, 0.4374375641345978, 0.5974478125572205, 0.1735987365245819, -0.03363683447241783, 0.3122430145740509, 0.6066973209381104, -0.2861070930957794, 0.1372922658920288, 0.24198661744594574, 0.5729450583457947, -0.8670593500137329, -0.6590553522109985, 0.5111765265464783, 0.5031822919845581, 0.29112765192985535, 0.5127031803131104, 1.1311249732971191, 0.21406938135623932, 0.24042101204395294, 0.4540361762046814, 0.5806371569633484, -0.2972277104854584, -0.037756264209747314, -0.39260146021842957, -0.6728772521018982, -0.322806179523468, -0.16952253878116608, -0.410776823759079, -0.5028800368309021, -0.1971217691898346, 0.13491664826869965, -0.1196688860654831, 0.39491352438926697, 1.1178771257400513, 0.5846501588821411, 0.616447389125824, -0.10376493632793427, -0.9117966890335083, -0.504451334476471, -1.2663697004318237, 0.24339137971401215, -0.679365873336792, -0.06595482677221298, 0.04938802868127823, -0.021829072386026382, -0.1539209634065628]}, "authors": [{"authorId": "2378954", "name": "Xuezhe Ma"}, {"authorId": "2296722524", "name": "Xiaomeng Yang"}, {"authorId": "2296721483", "name": "Wenhan Xiong"}, {"authorId": "2296721324", "name": "Beidi Chen"}, {"authorId": "2296724476", "name": "Lili Yu"}, {"authorId": "2296716359", "name": "Hao Zhang"}, {"authorId": "2296718960", "name": "Jonathan May"}, {"authorId": "2137813791", "name": "Luke Zettlemoyer"}, {"authorId": "2296719126", "name": "Omer Levy"}, {"authorId": "2110714400", "name": "Chunting Zhou"}], "references": [{"paperId": "8f490b938586d8e1b892304dd5209b2295c93ed7", "title": "Transformers Can Achieve Length Generalization But Not Robustly"}, {"paperId": "2e8ca21114ecefac88fd2b3a2daacae352b1907f", "title": "Beyond the Limits: A Survey of Techniques to Extend the Context Length in Large Language Models"}, {"paperId": "db633c6b1c286c0386f0078d8a2e6224e03a6227", "title": "Mistral 7B"}, {"paperId": "02ad9f3fefe33cb9ca546591bec65dbdf7766c80", "title": "Ring Attention with Blockwise Transformers for Near-Infinite Context"}, {"paperId": "5e0cb1c4b91a7486e1c2b15a44a0be56bd74bdc0", "title": "Effective Long-Context Scaling of Foundation Models"}, {"paperId": "819bbdc2dac9e13d9ca3e2508a6e063186ce5e40", "title": "YaRN: Efficient Context Window Extension of Large Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "fbea49896f868a11220ffe9c52c6c03dbdf5f60f", "title": "DropKey for Vision Transformer"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "412e266cddfd87c79087a88ba1e4d11b89a45a13", "title": "MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers"}, {"paperId": "998ac3e945857cf2676ee7efdbaf443a0c6f820a", "title": "Hyena Hierarchy: Towards Larger Convolutional Language Models"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "240300b1da360f22bf0b82c6817eacebba6deed4", "title": "What Makes Convolutional Models Great on Long Sequence Modeling?"}, {"paperId": "70e91e16eb321067d9402710e14a40cf28311f73", "title": "Mega: Moving Average Equipped Gated Attention"}, {"paperId": "6edccbd83a9aae204785d4821f97855677c33866", "title": "Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling?"}, {"paperId": "ca444821352a4bd91884413d8070446e2960715a", "title": "On the Parameterization and Initialization of Diagonal State Space Models"}, {"paperId": "736eb449526fe7128917954ec5532b59e318ec78", "title": "Block-Recurrent Transformers"}, {"paperId": "dc0102a51a9d33e104a4a3808a18cf17f057228c", "title": "Transformer Quality in Linear Time"}, {"paperId": "12809bcb734beafeb47876f42e7b438e27fe99fe", "title": "General-purpose, long-context autoregressive modeling with Perceiver AR"}, {"paperId": "6281c40c66febca1d8003bcc6fdfd2189b30c38f", "title": "SCROLLS: Standardized CompaRison Over Long Language Sequences"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "af679d69fcc1d0fcf0f039aba937853bcb50a8de", "title": "Luna: Linear Unified Nested Attention"}, {"paperId": "4e3935ef7da6bcbb202ec7f8b285c313cadcd044", "title": "A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "aa28873534c24e4a8c5deb7bff723cd5fc69a6f0", "title": "QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "806adbb35ed4a95f51518f5962fd59685ad4706b", "title": "Query-Key Normalization for Transformers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a", "title": "On Layer Normalization in the Transformer Architecture"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "10eda4521c032adabaa8e70d6569e17370b29dcd", "title": "Root Mean Square Layer Normalization"}, {"paperId": "59a916cdc943f0282908e6f3fa0360f4c5fb78d0", "title": "Stabilizing Transformers for Reinforcement Learning"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0", "title": "Natural Questions: A Benchmark for Question Answering Research"}, {"paperId": "9770fff7379a7ab9006b48939462354dda9a2053", "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "d79a26226393f687ddbc375e32055b40b8ad8d38", "title": "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "0d3c46a3cbfe06cec259fec954b6ff6df6c1a566", "title": "Learning long-range spatial dependencies with horizontal gated-recurrent units"}, {"paperId": "da6e404d8911b0e5785019a79dc8607e0b313dc4", "title": "Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition"}, {"paperId": "8b354d76813bd5375e7e5c8d17f630bec5936a01", "title": "ListOps: A Diagnostic Dataset for Latent Tree Learning"}, {"paperId": "d08b35243edc5be07387a9ed218070b31e502901", "title": "Group Normalization"}, {"paperId": "88bb0a28bb58d847183ec505dda89b63771bb495", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"}, {"paperId": "d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a", "title": "The NarrativeQA Reading Comprehension Challenge"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4f57f486adea0bf95c252620a4e8af39232ef8bc", "title": "Swish: a Self-Gated Activation Function"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"}, {"paperId": "e5aabd29682c8b8526833cbe9182e3e35a0c9ae8", "title": "Cosine Normalization: Using Cosine Similarity Instead of Dot Product in Neural Networks"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "c582b1e0189d6dd6682c5450d47fd8d3ff4c096b", "title": "The Exponentially Weighted Moving Average"}, {"paperId": "e01eae8dea6fbaa1ae7fc83535053932268df430", "title": "The ACL anthology network corpus"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "0e6beb95b5150ce99b108acdefabf70ccd3fee30", "title": "An algorithm for the machine calculation of complex Fourier series"}, {"paperId": "946c0b839e5dcca3fcf5a39d07d9f6f7d67887e3", "title": "Note on a Method for Calculating Corrected Sums of Squares and Products"}, {"paperId": null, "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality"}, {"paperId": "5e424004958853f4e366e7a86a1c3a56a76cb2a4", "title": "LightSeq: Sequence Level Parallelism for Distributed Training of Long Context Transformers"}, {"paperId": "0c36366413f08c6f635af6897627a3f113f6115a", "title": "Catformer: Designing Stable Transformers via Sensitivity Analysis"}, {"paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28", "title": "An Adversarial Winograd Schema Challenge at Scale"}, {"paperId": null, "title": "Socialiqa: Commonsense reasoning about social interactions"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "f4ea5a6ff3ffcd11ec2e6ed7828a7d41279fb3ad", "title": "Comparing Biases for Minimal Network Construction with Back-Propagation"}, {"paperId": "672a99813f52aed720d3508d6be7db461328b064", "title": "Pracniques: further remarks on reducing truncation errors"}, {"paperId": null, "title": "Probability = Number of ways the event can occur / Total number of possible outcomes"}, {"paperId": null, "title": "Riemannian geometry and Euclidean geometry are both branches of mathematics that study the properties of space, but they differ in their assumptions and methods"}]}