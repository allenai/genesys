{"paperId": "0dcbf11176db2a55d43b19c1765f1759e13f368b", "title": "A Historical Survey of Advances in Transformer Architectures", "abstract": "In recent times, transformer-based deep learning models have risen in prominence in the field of machine learning for a variety of tasks such as computer vision and text generation. Given this increased interest, a historical outlook at the development and rapid progression of transformer-based models becomes imperative in order to gain an understanding of the rise of this key architecture. This paper presents a survey of key works related to the early development and implementation of transformer models in various domains such as generative deep learning and as backbones of large language models. Previous works are classified based on their historical approaches, followed by key works in the domain of text-based applications, image-based applications, and miscellaneous applications. A quantitative and qualitative analysis of the various approaches is presented. Additionally, recent directions of transformer-related research such as those in the biomedical and timeseries domains are discussed. Finally, future research opportunities, especially regarding the multi-modality and optimization of the transformer training process, are identified.", "venue": "Applied Sciences", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://www.mdpi.com/2076-3417/14/10/4316/pdf?version=1716193415", "status": "GOLD"}, "tldr": {"model": "tldr@v2.0.0", "text": "A survey of key works related to the early development and implementation of transformer models in various domains such as generative deep learning and as backbones of large language models is presented."}, "embedding": {"model": "specter_v2", "vector": [0.46760594844818115, 0.8321613073348999, 0.16526950895786285, 0.08817251771688461, -0.40361109375953674, -0.3277991712093353, 0.9890298843383789, -0.4819447100162506, 0.13581596314907074, -0.5159335732460022, 0.5146365165710449, -0.08863787353038788, 0.3228227496147156, -0.18617169559001923, -0.311355322599411, -0.3542548418045044, -0.40791019797325134, 0.3857738673686981, 0.022335758432745934, -0.155096173286438, -0.3529907763004303, -0.5489936470985413, -0.934633195400238, -0.0148885203525424, 0.10956244170665741, 0.5591137409210205, 0.2184646725654602, 0.6671791672706604, -0.40433940291404724, 0.690833568572998, 0.7584660649299622, -0.741435706615448, 0.15745410323143005, -0.39381086826324463, -0.16549701988697052, 0.4048403203487396, 0.45818156003952026, -0.45856404304504395, -0.9560543894767761, 0.7211061716079712, -0.12801328301429749, 0.007906537503004074, 0.40928414463996887, -0.7839377522468567, -0.1943264752626419, 0.863387942314148, 0.7283632755279541, 0.7449240684509277, -0.5564286112785339, -0.5070764422416687, 1.1865752935409546, -1.15017831325531, 0.04411144554615021, 1.4031548500061035, 0.4062711000442505, 0.5200402736663818, -0.15231502056121826, -0.5438560247421265, 0.11230935156345367, -0.11714235693216324, -0.35426363348960876, -0.3742382228374481, 0.5527127385139465, -0.38090780377388, 1.4454525709152222, -0.393613338470459, 0.2285725474357605, 0.8629921078681946, 0.27357977628707886, 1.4288196563720703, 0.44309893250465393, -0.8649153113365173, -0.3815746009349823, 0.027374137192964554, -0.08179852366447449, 1.2044389247894287, -0.6040306687355042, 0.40364593267440796, -1.0330562591552734, 0.05349835008382797, 0.5752338767051697, -0.15362267196178436, 0.3007017970085144, -0.19717416167259216, -0.30053457617759705, 0.8460990786552429, 0.26628801226615906, 0.9994170665740967, 0.001550884684547782, 0.7676427364349365, 0.4833582043647766, 0.10093554854393005, -0.3434494733810425, 0.02696414850652218, 0.35449618101119995, 0.6511241793632507, -0.8758350014686584, 0.020050261169672012, -0.2902803421020508, 1.0149314403533936, -0.4669874608516693, 0.9203888773918152, -0.8884449005126953, 0.29188036918640137, 1.5476325750350952, 0.1883799284696579, 0.45924094319343567, -0.298799604177475, 0.23062635958194733, -0.9066656827926636, -0.25571209192276, -0.3265534043312073, 0.14290067553520203, -0.6806828379631042, -0.9116334319114685, -1.1877938508987427, -0.2894715368747711, 0.6921862959861755, -1.3419125080108643, 0.6947064399719238, -0.8312828540802002, -0.12351181358098984, 0.11349444836378098, 0.034578125923871994, 0.47795236110687256, 0.45792025327682495, 0.3713933825492859, 0.3827245235443115, 0.9976238012313843, -0.857507586479187, -0.6794818043708801, -0.9195594191551208, 0.09970363229513168, -0.3543606996536255, 0.28081610798835754, 0.020148785784840584, -0.9692772626876831, -0.7818481922149658, -0.6427327394485474, 0.20777550339698792, -0.3457827866077423, 0.30120140314102173, 0.8414492607116699, 0.5339893698692322, -1.410631537437439, 0.4677022397518158, -0.1161423996090889, -0.25416800379753113, 0.3962705433368683, 0.09132534265518188, 0.609385073184967, -0.171522319316864, -1.2891730070114136, 0.30387625098228455, -0.06924862414598465, -0.7673496603965759, -0.7983688116073608, -0.2279278039932251, -1.091055154800415, -0.011000377126038074, -0.31997203826904297, -0.6067189574241638, 1.1249030828475952, -0.05093375965952873, -1.1015371084213257, 0.7767921090126038, -0.23675526678562164, 0.11563832312822342, 0.038703642785549164, 0.1993187516927719, -0.341349720954895, -0.5272274017333984, 0.05171594396233559, 0.44983866810798645, 0.7132452726364136, -0.21324752271175385, 0.046074654906988144, 0.18941336870193481, -0.3315752148628235, -0.3604249656200409, -0.30971768498420715, 0.8658284544944763, -0.5499321818351746, -0.6155006885528564, 0.46656084060668945, 0.5140718221664429, -0.1761002242565155, -0.26042282581329346, -0.6777818202972412, -0.8339155316352844, 0.6983716487884521, -0.12249625474214554, 0.7856319546699524, -1.0594464540481567, -0.9065232276916504, -0.20644305646419525, -0.09701590240001678, -0.5800027251243591, -0.6222397089004517, 0.7144687175750732, -0.7169778347015381, 0.021235942840576172, -0.053490277379751205, -0.942036509513855, 0.13228997588157654, -0.22149260342121124, -1.1085182428359985, -0.11056805402040482, 0.1654696762561798, 1.1232513189315796, -0.6653187274932861, 0.12207741290330887, 0.1832003891468048, 0.5266993045806885, -0.5581430792808533, 1.1150537729263306, -0.033085498958826065, 0.09483274817466736, -0.0638221800327301, 0.13072682917118073, -0.09798438102006912, -0.4945540130138397, 0.3166171908378601, -0.583054780960083, 0.08672890812158585, 0.4749375879764557, 0.1826692372560501, 1.4492096900939941, -0.1409303843975067, 0.6064381003379822, -0.4488857686519623, -0.7765064239501953, 0.4624853730201721, 0.6544381976127625, -0.28144118189811707, -0.6547625660896301, 0.3369429409503937, 0.32390284538269043, -0.5413164496421814, 0.6392303705215454, 0.5156576633453369, 0.1917295753955841, -0.16981104016304016, 0.1084338054060936, 0.8868601322174072, -0.41621658205986023, 0.42852649092674255, 0.6070904731750488, 0.684167206287384, 0.3131310045719147, -0.20025022327899933, -0.1529623419046402, 0.19096943736076355, -1.159912347793579, -0.24756528437137604, 0.414876252412796, 0.6153202056884766, 1.0385395288467407, 0.426107257604599, -0.5533095598220825, -0.5121480226516724, -0.5547454953193665, 0.6990139484405518, 1.0008481740951538, -0.3964061439037323, -0.42472606897354126, -0.5494866371154785, -0.20730683207511902, -0.8122316598892212, 0.17393755912780762, -0.20767976343631744, -0.13113868236541748, -0.2060074359178543, -0.993714451789856, 0.9305686950683594, 0.4108453094959259, 0.7863525152206421, -0.3615805208683014, -0.27006733417510986, -0.21943655610084534, 0.12590596079826355, -0.8308300971984863, -0.5539001226425171, 0.5858765840530396, -0.7685359120368958, 0.10521446913480759, -0.3048509955406189, -0.2672134339809418, 0.34389814734458923, -1.0054749250411987, 0.9218395948410034, -0.7875799536705017, -0.3800133168697357, 0.30574527382850647, 0.7954928278923035, -0.6589936017990112, -0.9895479083061218, -0.24656356871128082, -0.14910587668418884, -0.13253448903560638, 0.03991357609629631, 0.22188930213451385, 0.22904706001281738, -0.1351943016052246, -0.48568665981292725, 0.08430219441652298, 0.02890804037451744, 0.3627818822860718, 0.7343841791152954, 0.026413975283503532, -0.3707878589630127, -0.6684851050376892, 0.7798975110054016, 0.5188391208648682, -0.5863878130912781, 0.3037542700767517, -0.6522426009178162, -0.09501465409994125, 0.6016311645507812, -0.16137617826461792, -0.32966136932373047, -0.5809366106987, 0.2953663170337677, -0.4010353982448578, 0.12957794964313507, -0.002095331670716405, 0.2504574954509735, 0.3293548822402954, -0.01387511845678091, 0.9891383051872253, 0.18961301445960999, 0.1787722259759903, 0.480330228805542, -0.9327288866043091, 0.32001256942749023, 0.21174801886081696, 0.4620026648044586, -0.026713766157627106, -0.08725302666425705, -0.4401019513607025, -0.482479453086853, 0.1101345419883728, -0.026394370943307877, -0.6705345511436462, 0.07087714970111847, -0.8121269941329956, -0.34062620997428894, 0.6378664970397949, -0.859347939491272, 0.17667700350284576, -0.00982710812240839, -0.760413408279419, -0.3201238512992859, -1.020175814628601, -1.2128384113311768, -0.6233758926391602, -0.8544442653656006, -1.0976343154907227, 0.45949727296829224, 0.26348933577537537, 0.14393620193004608, -0.778892993927002, -0.1194259375333786, -0.09057514369487762, 1.0379129648208618, -0.4354942739009857, 1.1883281469345093, -0.1407422572374344, -0.5338987708091736, -0.024538319557905197, 0.47357964515686035, 0.5449578762054443, -0.0017373771406710148, 0.25272175669670105, -1.1799038648605347, 0.14930297434329987, -0.0995410829782486, -0.08580953627824783, 0.01057684700936079, 0.31786710023880005, 0.5371204614639282, 0.3367317020893097, -0.34363770484924316, 0.11117105185985565, 1.3883962631225586, -0.24628698825836182, 0.1111796423792839, 0.0762372761964798, 0.8475334644317627, 0.05175905302166939, -0.6556945443153381, 0.45726919174194336, 0.3136478364467621, 0.21967807412147522, 0.20665307343006134, -0.29106399416923523, -0.39833977818489075, -0.8294267058372498, 0.5423545241355896, 1.49485445022583, 0.4957119822502136, -0.2604176104068756, -1.1142375469207764, 0.9169114232063293, -0.7597697973251343, -0.7284481525421143, 0.7519195079803467, 0.32745662331581116, 0.1776512861251831, -0.08801060914993286, -0.5746505260467529, 0.27720898389816284, 0.7478365898132324, 0.47230958938598633, -0.15144553780555725, -0.5995255708694458, -0.3168863356113434, 0.7943112850189209, 0.03877255693078041, 0.29597747325897217, -0.44698038697242737, 0.31249532103538513, 15.058533668518066, 0.9737987518310547, -0.15976916253566742, 0.5476230382919312, 0.6241418123245239, 0.45318010449409485, -0.7524198293685913, 0.013766651041805744, -0.939946711063385, -0.14755283296108246, 0.9630988240242004, 0.2277304232120514, 0.6781488060951233, 0.218821182847023, -0.3821321427822113, 0.3328574597835541, -0.5382733941078186, 0.8648802042007446, 0.6114431619644165, -1.3458994626998901, 0.6012408137321472, 0.19914358854293823, 0.1909770369529724, 0.5688788890838623, 1.217175841331482, 0.5017833113670349, 0.4344702363014221, -0.4479655623435974, 0.8748453259468079, 0.18027213215827942, 0.6390255093574524, 0.14875470101833344, 0.0935419499874115, 0.2417312115430832, -1.1376773118972778, -0.3136337995529175, -0.3434301018714905, -0.6423061490058899, 0.16309607028961182, 0.4232647120952606, -0.5926413536071777, -0.3094921112060547, -0.15218135714530945, 0.8506255745887756, 0.15833911299705505, 0.1418699026107788, -0.45718955993652344, 0.815217912197113, -0.17333069443702698, 0.29260408878326416, 0.43775293231010437, 0.23767107725143433, 0.40258318185806274, -0.3874821364879608, 0.4176505208015442, -0.33954092860221863, -0.08006210625171661, 0.6969389319419861, -0.3482900559902191, -0.3212434947490692, -0.5936525464057922, -0.714450478553772, -0.4618597626686096, 0.9474148154258728, -0.06185714900493622, 0.4948258101940155, -0.4470004737377167, 0.29848912358283997, 0.08683022111654282, 0.13465169072151184, -0.5909773707389832, -0.18568497896194458, -0.05301370844244957, -0.09621914476156235, 0.4023282825946808, 0.6529777646064758, 0.12106401473283768, -0.5599929094314575, -0.7205187082290649, -0.2184736728668213, 0.3928057849407196, -1.072698950767517, -0.8340116739273071, 1.3792376518249512, -0.46084335446357727, -0.5714060068130493, 0.28137993812561035, -0.8531866073608398, -0.2513238191604614, 0.44338130950927734, -1.3036905527114868, -1.1943600177764893, 0.2558893859386444, -0.036548860371112823, -0.21548989415168762, -0.6661425828933716, 0.9780656099319458, 0.03606017306447029, -0.1699707806110382, -0.0061925966292619705, -0.00263238069601357, 0.25591275095939636, -0.5859507322311401, -0.7428283095359802, 0.8295114040374756, 0.5479214787483215, 0.3531455397605896, 0.17144674062728882, 0.289043128490448, 0.4313950538635254, -0.6617286205291748, -0.07640422135591507, 0.8773836493492126, -0.8044902682304382, -0.24652111530303955, -0.8576622605323792, -0.25739631056785583, 0.3423212170600891, 0.9308057427406311, -0.43269622325897217, 0.11106376349925995, -0.2720705270767212, -0.5713332891464233, -0.3156161308288574, -0.7096289396286011, -0.021107688546180725, 0.4148571789264679, -1.2107449769973755, -0.2757124602794647, 0.0849420502781868, -0.041384875774383545, -0.8557985424995422, -0.37905192375183105, -0.1488565355539322, -0.04684199020266533, -0.29750725626945496, 0.7612158060073853, -0.09400088340044022, 0.6200796365737915, 0.7051336169242859, -0.3581310510635376, -0.6889411211013794, -0.25268882513046265, -1.0455100536346436, 0.2822099030017853, 0.36402273178100586, 0.5318689942359924, -0.3870266079902649, 0.24737967550754547, 0.7193232774734497, 0.1785714328289032, -0.5789764523506165, -0.832504153251648, -0.2575189471244812, 0.1425357460975647, -0.43410611152648926, 0.2819700539112091, -0.42131558060646057, -0.36911678314208984, 0.3094732165336609, 0.3036850392818451, 0.27004098892211914, 0.1370829939842224, -0.48746025562286377, -0.1704934686422348, -0.011339554563164711, -0.07369917631149292, -0.4776928722858429, -0.42458730936050415, -1.338613748550415, 0.11368072032928467, -1.495879888534546, -0.08290424942970276, -1.2360105514526367, -0.06926664710044861, -0.044475264847278595, -0.36562567949295044, 0.3270508944988251, 0.7982546091079712, -0.28979507088661194, -0.374122679233551, -0.6829926371574402, -0.056054167449474335, 1.0556302070617676, 0.8260686993598938, -1.142609715461731, 0.5039918422698975, -0.1783457249403, 0.094596728682518, 0.24738407135009766, 0.18875370919704437, -0.5438092350959778, -1.2911630868911743, -1.3410933017730713, 0.2868439853191376, -0.14452534914016724, 0.017584456130862236, -0.9578525424003601, 0.5014598369598389, 0.7542316913604736, -0.21620874106884003, -0.02806493081152439, 0.39913034439086914, -0.8619955778121948, 0.13523456454277039, 0.4404529929161072, -0.5269243121147156, 0.18596605956554413, 0.21984970569610596, -0.6428141593933105, -0.513989269733429, 0.7582013010978699, 0.21099033951759338, -1.1308015584945679, -0.40321770310401917, 0.5434775352478027, -0.9055579900741577, 0.033635228872299194, -0.08952590078115463, -0.3230542242527008, -0.7038408517837524, -0.41688498854637146, -0.3504906892776489, -0.058717820793390274, -0.5445296168327332, 1.220725417137146, 0.7225135564804077, -1.3281140327453613, 0.16953690350055695, 0.4713154733181, -0.13424989581108093, -0.6463953256607056, 0.2227380871772766, 0.3419468402862549, -0.12139406055212021, 0.766608476638794, 0.09947758167982101, 0.055914364755153656, -0.9146320223808289, -0.3368299901485443, 1.105304479598999, -0.6112675070762634, -0.1668204367160797, 1.3376916646957397, 0.0010487112449482083, -1.0954489707946777, 0.04994155466556549, -0.9521286487579346, -0.5300905108451843, -0.39298492670059204, 0.24478891491889954, -0.2679113447666168, -0.13170114159584045, -0.19519124925136566, -0.48334917426109314, 0.2713322639465332, -0.006837033201009035, -0.7229055166244507, 0.6350045204162598, 0.08516491204500198, -0.3924817442893982, 0.6050515174865723, 0.3310345709323883, -0.8650103807449341, -0.5578820109367371, -0.5548770427703857, -0.5725589990615845, -0.04289248213171959, 0.2677532136440277, -0.3889281749725342, -1.2142844200134277, 1.0725362300872803, 0.8061839938163757, 0.11393963545560837, 0.5104286670684814, 0.12209281325340271, 0.19018656015396118, 0.17234177887439728, 0.4048483669757843, -0.5880365967750549, -0.2635243535041809, 1.4618372917175293, 1.1944386959075928, -0.30704179406166077, -0.10692928731441498, -0.3460199534893036, -0.7124398946762085, 0.983920156955719, 0.09127235412597656, 0.3649294674396515, 1.1384493112564087, 0.13572804629802704, 0.11340484023094177, 0.045872971415519714, -0.9722147583961487, -0.12003184109926224, 0.609079897403717, 1.117102861404419, 0.9951527714729309, 0.04190933331847191, 0.4313580393791199, 0.9223758578300476, 0.09935539960861206, 0.03417060896754265, 0.6075103282928467, 0.6708926558494568, 0.21058553457260132, -0.42724961042404175, 0.0049899728037416935, 0.7107304334640503, -0.6676216721534729, -0.875812292098999, 0.24872605502605438, 0.32028651237487793, 0.21765536069869995, 0.6698047518730164, 0.7138511538505554, -0.23710379004478455, 0.48128387331962585, 0.31652387976646423, 1.015693187713623, -0.4080365002155304, -0.27062714099884033, 0.17669114470481873, -0.7368703484535217, 0.05419142171740532, -0.4427746832370758, -0.5173547863960266, -0.3091301918029785, 0.15676584839820862, 0.13207055628299713, -0.14650817215442657, 0.23607982695102692, 0.9350832104682922, 0.218043714761734, 0.5952888131141663, -0.28884926438331604, 0.1427512913942337, -0.2987285852432251, -0.7330635190010071, -0.13246837258338928, -0.5393214821815491, -0.12980040907859802, -0.1529126614332199, 0.1253824532032013, 0.13488587737083435]}, "authors": [{"authorId": "2047933303", "name": "Ali Reza Sajun"}, {"authorId": "2291253540", "name": "Imran Zualkernan"}, {"authorId": "2003812364", "name": "Donthi Sankalpa"}], "references": [{"paperId": "7f976f21bb571941042906d964c6cb676c29decb", "title": "Foundation and large language models: fundamentals, challenges, opportunities, and social impacts"}, {"paperId": "9c1f6da716514899638089f5939a365255b5531a", "title": "Enhancing fetal electrocardiogram classification: A hybrid approach incorporating multimodal data fusion and advanced deep learning models"}, {"paperId": "e9393a35b37656055d043b494c8f29738a341dec", "title": "Transformers in the Real World: A Survey on NLP Applications"}, {"paperId": "f35016b3180808fa97d59acbdecf47d6e2ed2819", "title": "Rethinking Vision Transformers for MobileNet Size and Speed"}, {"paperId": "379e42895f6d40ab9e9559609f505aba89145a5d", "title": "Efficiently Scaling Transformer Inference"}, {"paperId": "a9c72a0aedd209c2f565d09fd46dd27c78585a91", "title": "Transforming medical imaging with Transformers? A comparative review of key properties, current progresses, and future perspectives"}, {"paperId": "dd1139cfc609c2f3263d02e97176d5275caebc0a", "title": "EfficientFormer: Vision Transformers at MobileNet Speed"}, {"paperId": "d207c175f4d718a6d1881364055447d38a226890", "title": "Investigating the Performance of FixMatch for COVID-19 Detection in Chest X-rays"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "58c486ad4020177f5ed3d9f2883f3fc327b55770", "title": "MiniViT: Compressing Vision Transformers with Weight Multiplexing"}, {"paperId": "0d8730b5af0ac76598530437d920650f3d1d4015", "title": "Towards Data-Efficient Detection Transformers"}, {"paperId": "918646809c7e22c94994fe80c3a2840b4c951a3c", "title": "Unsupervised Semantic Segmentation by Distilling Feature Correspondences"}, {"paperId": "42bad1b72259aa1ff70d7ce2539220a83f1af9a4", "title": "Transformers in Medical Image Analysis: A Review"}, {"paperId": "2f8bb30ba639cb1ca5349fbcbd86b09aea20b082", "title": "TTS-GAN: A Transformer-based Time-Series Generative Adversarial Network"}, {"paperId": "563bac1c5cdd5096e9dbf8d4f3d5b3c4f7284e06", "title": "FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting"}, {"paperId": "24aa57dae649b6683d8f5bc8deaf2ff549cdacc4", "title": "Transformers in Medical Imaging: A Survey"}, {"paperId": "2d57a3f90adf3fc28f0de61fb4b7b34bccb1b92d", "title": "TranAD: Deep Transformer Networks for Anomaly Detection in Multivariate Time Series Data"}, {"paperId": "c2a0c18e810535db52e5ebaf180c64ce70356748", "title": "A-ViT: Adaptive Tokens for Efficient Vision Transformer"}, {"paperId": "42b7427ea72a7998adcb73132743889d1f32ef7a", "title": "A unified pruning framework for vision transformers"}, {"paperId": "38212997a6e8c55141574c329bb58d2eadcb0db5", "title": "AdaViT: Adaptive Vision Transformers for Efficient Image Recognition"}, {"paperId": "a4ad13a961569a328d45e4bef18438de6b1d2b53", "title": "Semi-Supervised Vision Transformers"}, {"paperId": "333212e246fb65f7c9d43862021e78f007c48449", "title": "A Survey of Visual Transformers"}, {"paperId": "089bb1ecce75936eda1890f8e40a56d4c811dd33", "title": "Large Scale Learning on Non-Homophilous Graphs: New Benchmarks and Strong Simple Methods"}, {"paperId": "9933a5af7895354087baf6c96b64dc8a8973eaed", "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs"}, {"paperId": "64d8af9153d68e9b50f616d227663385bece93b9", "title": "Feature Fusion Vision Transformer for Fine-Grained Visual Categorization"}, {"paperId": "2a805d0e1b067444a554c5169d189fa1f649f411", "title": "Scaling Vision Transformers"}, {"paperId": "0e2d8b8d81092037f9866c1ceddcebb87318e38b", "title": "AST: Audio Spectrogram Transformer"}, {"paperId": "bf80051ca9ae1e76e2bdbdcf44df559e7eb73cb1", "title": "A Practical Survey on Faster and Lighter Transformers"}, {"paperId": "f4299e47a76d5d7cf1638ba347d9848903ef5a60", "title": "Gated Transformer Networks for Multivariate Time Series Classification"}, {"paperId": "b3bf9fe13195e9aa70e1dac04e01fcff7008e812", "title": "Perceiver: General Perception with Iterative Attention"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "3a906b77fa218adc171fecb28bb81c24c14dcc7b", "title": "Transformers in Vision: A Survey"}, {"paperId": "d29430adccb805ab57b349afa8553954347b3197", "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"}, {"paperId": "d40c77c010c8dbef6142903a02f2a73a85012d5d", "title": "A Survey on Vision Transformer"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "6f6f73e69ee0d9d5d7d088bb882db1851d98175a", "title": "Pre-Trained Image Processing Transformer"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "f4de50b3dc5d1d850d281ef0cfefb80be2af34f2", "title": "The PRISMA 2020 statement: an updated guideline for reporting systematic reviews"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "0118c8b047587368b71308f67f2b4d28543ce600", "title": "A Transformer-based Audio Captioning Model with Keyword Estimation"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "8af925f4edf45131b5b6fed8aa655089d58692fa", "title": "Lite Transformer with Long-Short Range Attention"}, {"paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d", "title": "ETC: Encoding Long and Structured Inputs in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "bc1ab519c225b08332f243269ad6d99284bbf1bf", "title": "A Comparison of Transformer and LSTM Encoder Decoder Models for ASR"}, {"paperId": "d6b414487787d0b6efd735a3236a690ad13aae70", "title": "TENER: Adapting Transformer Encoder for Named Entity Recognition"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "830995ef17cc291c13f42dfd9f462137de1d2179", "title": "Augmenting Self-attention with Persistent Memory"}, {"paperId": "a39398f68ae7e042f2ef5009e31b4e6a20fd5736", "title": "Learning Deep Transformer Models for Machine Translation"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "d9f6ada77448664b71128bb19df15765336974a6", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"}, {"paperId": "0fe61aaa54ec4e37849330f2cbc4e7bb8ad7eb40", "title": "Parallel Distributed Processing"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "41a78e2885b5dc8c719495a33985b5f4880f5b48", "title": "Speech-Transformer: A No-Recurrence Sequence-to-Sequence Model for Speech Recognition"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "bd414be3d92b7d079b3e3557634471bb27ecbcdc", "title": "Applying named entity recognition and co-reference resolution for segmenting English texts"}, {"paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0", "title": "Convolutional Sequence to Sequence Learning"}, {"paperId": "636a79420d838eabe4af7fb25d6437de45ab64e8", "title": "RACE: Large-scale ReAding Comprehension Dataset From Examinations"}, {"paperId": "a8b21f72bdc251689f636d3d7ff52a6b85ab7ce9", "title": "Neural Question Generation from Text: A Preliminary Study"}, {"paperId": "664ec878de4b7170712baae4a7821fc2602bba25", "title": "Learning to Generate Reviews and Discovering Sentiment"}, {"paperId": "1ecec941252788e09531a8f2e57a2e7af03108e2", "title": "Story Cloze Task: UW NLP System"}, {"paperId": "13d9323a8716131911bfda048a40e2cde1a76a46", "title": "Structured Attention Networks"}, {"paperId": "88caa4a0253a8b0076176745ebc072864eab66e1", "title": "Language Modeling with Gated Convolutional Networks"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "3899f87a2031f3434f89beb68c11a1ca6428328a", "title": "End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "a7976c2bacfbb194ddbe7fd10c2e50a545cf4081", "title": "LSTM: A Search Space Odyssey"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "3419ccd5c94d301ee08d716d037f0c3c6a62e78e", "title": "The Role of Context for Object Detection and Semantic Segmentation in the Wild"}, {"paperId": "5ec85a0d88adcc4344bb5cc81b0d1aef9bcd8dcc", "title": "Findings of the 2014 Workshop on Statistical Machine Translation"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "84069287da0a6b488b8c933f3cb5be759cb6237e", "title": "On the difficulty of training recurrent neural networks"}, {"paperId": "84b50ebe85f7a1721800125e7882fce8c45b5c5a", "title": "Cats and dogs"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "161ffb54a3fdf0715b198bb57bd22f910242eb49", "title": "Multitask Learning"}, {"paperId": "319f22bd5abfd67ac15988aa5c7f705f018c3ccd", "title": "Learning internal representations by error propagation"}, {"paperId": "766ce989b8b8b984f7a4691fd8c9af4bdb2b74cd", "title": "\u201cCloze Procedure\u201d: A New Tool for Measuring Readability"}, {"paperId": "529a5f9931258ae144bf1392e27c201282b1c23f", "title": "Extraction of Fetal Electrocardiogram by Combining Deep Learning and SVD-ICA-NMF Methods"}, {"paperId": "1b173368cc9033eb9966e27f3d69f4b0ae7590d2", "title": "Computer Vision \u2013 ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23\u201327, 2022, Proceedings, Part XIX"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": null, "title": "OpenAI GPT-4 Technical Report 2023"}, {"paperId": null, "title": "DeepNet: Scaling Transformers to 1000 Layers 2022"}]}