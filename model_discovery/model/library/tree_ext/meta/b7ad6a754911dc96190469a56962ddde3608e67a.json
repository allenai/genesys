{"paperId": "b7ad6a754911dc96190469a56962ddde3608e67a", "title": "SemScore: Automated Evaluation of Instruction-Tuned LLMs based on Semantic Textual Similarity", "abstract": "Instruction-tuned Large Language Models (LLMs) have recently showcased remarkable advancements in their ability to generate fitting responses to natural language instructions. However, many current works rely on manual evaluation to judge the quality of generated responses. Since such manual evaluation is time-consuming, it does not easily scale to the evaluation of multiple models and model variants. In this short paper, we propose a straightforward but remarkably effective evaluation metric called SemScore, in which we directly compare model outputs to gold target responses using semantic textual similarity (STS). We conduct a comparative evaluation of the model outputs of 12 prominent instruction-tuned LLMs using 8 widely-used evaluation metrics for text generation. We find that our proposed SemScore metric outperforms all other, in many cases more complex, evaluation metrics in terms of correlation to human evaluation. These findings indicate the utility of our proposed metric for the evaluation of instruction-tuned LLMs.", "venue": "arXiv.org", "year": 2024, "citationCount": 2, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A comparative evaluation of the model outputs of 12 prominent instruction-tuned LLMs using 8 widely-used evaluation metrics for text generation finds that the proposed SemScore metric outperforms all other, in many cases more complex, evaluation metrics in terms of correlation to human evaluation."}, "embedding": {"model": "specter_v2", "vector": [0.23484569787979126, 0.5032252669334412, -0.061822131276130676, -0.2942885458469391, -0.6699525117874146, -0.3681105971336365, 0.46944931149482727, -0.06717907637357712, -0.28347715735435486, -0.07599777728319168, 0.44817227125167847, -0.2840231955051422, 0.23951278626918793, -0.0968087837100029, -0.24645540118217468, 0.3745940327644348, -0.3543395698070526, 0.6693107485771179, -0.24844062328338623, -0.40379974246025085, 0.20237979292869568, -1.2230092287063599, -0.819113552570343, 0.22424957156181335, 1.1464993953704834, 0.08431987464427948, 0.46063727140426636, 1.0430577993392944, -0.5219979286193848, -0.11243859678506851, 0.26245439052581787, -0.4729127287864685, -0.16238944232463837, -0.30209994316101074, -0.05366721749305725, -0.04573284089565277, 0.2545362412929535, -0.6747000217437744, 0.1355951428413391, 0.5637234449386597, -0.10986966639757156, 0.16459158062934875, 0.5840854644775391, -0.41796696186065674, -0.43262311816215515, 1.165945291519165, 0.8130835890769958, 0.3008742332458496, 0.5309726595878601, -0.15761837363243103, 1.2308324575424194, -1.5329328775405884, 0.33214864134788513, 1.4595613479614258, 0.17830274999141693, 0.41407305002212524, -0.3689073324203491, -0.3620396852493286, 0.33565592765808105, -0.6284192800521851, -0.8030647039413452, -0.3323116600513458, -0.45501747727394104, -0.17894995212554932, 1.6259151697158813, -0.19122278690338135, -0.7510601282119751, 0.7592120170593262, 0.029530927538871765, 1.1526743173599243, -0.008731809444725513, -1.0727993249893188, -0.10582634806632996, 0.1574411392211914, -0.08303999900817871, 1.0327068567276, -0.20284929871559143, 0.5855233073234558, -0.7257705330848694, -0.011352229863405228, 0.46629905700683594, -0.7021709680557251, -0.2674129605293274, 0.2340266853570938, -0.7635972499847412, 0.9383296370506287, 0.07605630159378052, 0.8523644208908081, 0.016502123326063156, 0.20832781493663788, 0.2528851628303528, 0.3158458471298218, 0.013416064903140068, 0.555765688419342, -0.42699772119522095, 0.41034868359565735, -0.728828489780426, 0.5574069023132324, 0.4195038974285126, 0.5887411236763, -0.2977006435394287, 0.5530574917793274, -1.2967725992202759, 0.04605410620570183, 1.3093852996826172, 0.4731754660606384, 0.8598051071166992, -0.8875848054885864, 0.5081058144569397, -0.4914703965187073, 0.6161330342292786, -0.6288991570472717, -0.03184434771537781, -0.13891562819480896, -0.13352282345294952, -1.1185142993927002, -0.38219189643859863, -0.20245353877544403, -0.5110677480697632, 0.9704670310020447, -0.15651780366897583, -0.2571588456630707, 0.21460674703121185, 0.5066924095153809, 1.0071921348571777, 0.4040476381778717, 0.41259250044822693, 0.05046411603689194, 0.4899395704269409, -0.4944795072078705, -0.43947839736938477, -1.1675974130630493, 1.1581881046295166, -0.5143098831176758, 0.6313648819923401, -0.4471331834793091, -1.4131568670272827, -1.2022463083267212, -0.533407986164093, 0.3179798424243927, -0.07965845614671707, 1.050733208656311, 0.9219923615455627, 0.4256426692008972, -1.404238224029541, 0.6251897811889648, -0.00761873135343194, -0.4823867976665497, -0.4646356701850891, 0.12353038042783737, 0.24472135305404663, -0.2610454559326172, -1.2321393489837646, -0.06469275802373886, 0.17111836373806, -1.2115907669067383, -0.11072815209627151, -0.1968064308166504, -1.4485663175582886, -0.2713075280189514, 0.3382675349712372, -0.6202054023742676, 1.863674283027649, -0.13748373091220856, -1.17593252658844, 0.671607494354248, -0.39201411604881287, 0.3683713972568512, 0.08496983349323273, 0.09971609711647034, -0.6642546057701111, -0.3870871663093567, 0.2867535650730133, 0.8777715563774109, 0.2067880928516388, -0.28326767683029175, -0.1314726173877716, 0.6088243722915649, -0.11632083356380463, -0.12310202419757843, -0.3520750403404236, 1.1536271572113037, -0.13212493062019348, -0.6529732346534729, 0.1144455298781395, 0.6809986233711243, -0.3167724013328552, -0.2883968651294708, -0.44760262966156006, -0.8972052931785583, 0.4009958803653717, -0.24924910068511963, 1.3023756742477417, -0.35986772179603577, -0.9457573294639587, -0.37347927689552307, -0.44684651494026184, 0.011703160591423512, -1.1116664409637451, 0.7924413681030273, -0.4033168852329254, 0.7135897278785706, -0.25746291875839233, -0.9621730446815491, 0.26118606328964233, -0.6667577624320984, -0.5294236540794373, -0.8645556569099426, 0.017323363572359085, 1.3237833976745605, -0.6033945083618164, 0.0374804250895977, -0.017854953184723854, 0.004982666112482548, -0.8253231644630432, 1.283102035522461, -0.5919272899627686, 0.46291786432266235, -0.43506115674972534, -0.44322681427001953, -0.223394513130188, -0.40618765354156494, -0.06852494925260544, -0.2817736268043518, -0.39213207364082336, 0.5407767295837402, -0.2353031188249588, 1.634592890739441, -0.24655312299728394, -0.0804646760225296, -0.503393292427063, -0.25903600454330444, 0.4641033709049225, 0.5568690896034241, -0.3382700979709625, -0.677778422832489, 0.40162473917007446, 0.9169339537620544, -0.5947410464286804, -0.09131049364805222, 0.6028580069541931, 0.8119460940361023, -0.6357128620147705, 0.7707931399345398, 0.22082959115505219, -0.27370211482048035, 0.8715888261795044, 0.49105706810951233, 0.7308939099311829, 0.6056550741195679, 0.4528610110282898, -0.06876616179943085, 0.5547695755958557, -0.28049543499946594, -0.49522796273231506, 0.5610812306404114, 0.9745705723762512, 0.8261538147926331, -0.1741848587989807, -0.6667464375495911, 0.18198944628238678, -0.1737174540758133, 1.0467263460159302, 1.4132298231124878, -0.14982019364833832, -0.13975712656974792, -1.1438844203948975, -0.5518335700035095, -0.5640836358070374, 0.7860872745513916, -0.16950063407421112, -0.49835872650146484, -0.48269203305244446, -0.5927757024765015, 0.5146424174308777, 0.3998173773288727, 0.6536514759063721, -0.7080128192901611, -0.37659966945648193, -0.12754686176776886, -0.5057926177978516, -0.7803612947463989, -1.0500582456588745, -0.13369561731815338, -0.6736220717430115, -0.19892190396785736, 0.26262181997299194, -0.30197280645370483, 0.17539118230342865, -0.37741124629974365, 1.110970377922058, -0.15422509610652924, -0.31750252842903137, 0.21205607056617737, 0.15169842541217804, -0.4484838545322418, -1.0902072191238403, -0.1944383978843689, 0.176184743642807, -0.5990805625915527, 0.3861757218837738, 0.9830163717269897, 0.061660706996917725, 0.6581728458404541, -0.7075192928314209, 0.19858050346374512, 0.07445624470710754, -0.0761079266667366, 0.5431274175643921, -0.5922859907150269, -0.03243115544319153, -0.7795818448066711, 1.2817972898483276, 0.6359302401542664, -0.35103392601013184, 0.6624182462692261, -0.4834621250629425, -0.15156500041484833, 0.39356714487075806, -0.37165549397468567, -0.5545952916145325, -1.1497516632080078, 0.3813875913619995, 0.6119303703308105, -0.5670052766799927, 0.5149367451667786, 0.2418348342180252, 0.017678918316960335, 0.5569626092910767, 0.3927794396877289, 0.2525331974029541, -0.20719794929027557, 0.30448970198631287, -0.5119901299476624, 0.37894994020462036, 0.05421815812587738, 0.31108516454696655, -0.6182915568351746, -0.7824900150299072, 0.02507256343960762, -0.4472532868385315, 0.3945804238319397, 0.15917934477329254, -0.31406429409980774, 0.4540066719055176, -0.36100828647613525, -0.8814366459846497, -0.3407370448112488, -1.3595181703567505, -0.17889703810214996, 0.15217113494873047, -0.05989406630396843, -0.23386208713054657, -0.8258771300315857, -0.9618011116981506, -0.18935085833072662, -0.6932600140571594, -1.183070182800293, 0.924155592918396, -0.02573404088616371, -0.9869589805603027, -0.5297316908836365, 0.40009820461273193, -0.1517108529806137, 0.923460841178894, -0.6336904764175415, 1.2173808813095093, -0.16994613409042358, -0.028112029656767845, -0.5598142147064209, 0.4866447150707245, 0.06530604511499405, -0.12335678189992905, 0.4086761176586151, -0.2539238929748535, 0.05876605212688446, 0.176218181848526, -0.5262781381607056, -0.23010124266147614, 0.5179592370986938, 0.27475929260253906, -0.015987372025847435, -0.5453731417655945, 0.03710082173347473, 1.399277687072754, -0.4748068153858185, -0.3745512068271637, 0.046012356877326965, 0.55640709400177, 0.9142405986785889, 0.22526346147060394, 0.6006598472595215, 0.546937108039856, 0.8542945384979248, -0.08622069656848907, -0.22790148854255676, -0.165910542011261, -0.6914269924163818, 1.073448896408081, 1.5539742708206177, 0.5015314221382141, -0.5065926909446716, -1.056248426437378, 0.1580093950033188, -1.089435338973999, -0.02703261747956276, 0.1748237907886505, 0.9782339930534363, 0.2144857943058014, -0.6172361373901367, -0.6429067254066467, -0.17243270576000214, 0.6419729590415955, -0.04109157621860504, 0.12132681906223297, -0.8234084248542786, -0.031363606452941895, 0.49996206164360046, -0.33700528740882874, 0.5819054841995239, -0.33274105191230774, 0.8593183159828186, 14.688380241394043, 0.9393552541732788, 0.05337360501289368, 0.308055579662323, 0.7358635663986206, 0.5089414715766907, -0.7805211544036865, -0.11559984087944031, -1.2149523496627808, -0.2254037857055664, 1.4088001251220703, -0.3742118775844574, 0.2990579903125763, 0.004292759578675032, 0.6996818780899048, -0.05285186693072319, -0.472162127494812, 0.3753458261489868, 0.7497158646583557, -1.0341612100601196, 0.978423535823822, 0.12042621523141861, 0.5520241260528564, 0.028755510225892067, 0.6056468486785889, 0.8255921006202698, 0.4775625467300415, -0.5756788849830627, 0.6124140024185181, 0.2156873494386673, 0.9963201284408569, -0.04139482229948044, 0.4757544994354248, 0.5404488444328308, -0.8156229257583618, 0.010419795289635658, -0.3213671147823334, -1.016458511352539, 0.5104771256446838, -0.04351228103041649, -0.5717207193374634, -0.3114261031150818, -0.5403957962989807, 0.34088456630706787, 0.06572074443101883, 0.28043097257614136, -0.5031907558441162, 0.8068355321884155, 0.4447970390319824, -0.05754382535815239, 0.15612222254276276, 0.32993167638778687, 0.3338271379470825, -0.42632654309272766, 0.7064157128334045, -0.16161637008190155, 0.5039442777633667, 0.7089332342147827, -0.2453414350748062, 0.3135940730571747, -0.514668345451355, -0.4072365462779999, -0.13830365240573883, 0.5301917195320129, 0.16277959942817688, 0.45585745573043823, -0.32255080342292786, 0.22921229898929596, 0.3227958679199219, 0.2509601414203644, -0.2866158187389374, 0.048075951635837555, 0.36066389083862305, -0.008593919686973095, -0.34783273935317993, 0.43933436274528503, -0.4797881543636322, -0.20043615996837616, -0.7474929690361023, -0.6727277040481567, -0.02087000571191311, -1.0224435329437256, -0.6161538362503052, 1.0095351934432983, -0.3976702094078064, -0.7667261958122253, -0.2800949513912201, -0.806162416934967, -0.6366622447967529, 0.38156482577323914, -1.0323787927627563, -0.6702238321304321, 0.21486502885818481, -0.5924555063247681, -0.048848655074834824, -0.1719823181629181, 1.5794869661331177, -0.40423211455345154, -0.463264524936676, 0.3181682527065277, -0.13451017439365387, -0.3163636028766632, 0.17957302927970886, -0.5064277052879333, 0.9028209447860718, 0.2654806673526764, -0.047544848173856735, 0.4454856812953949, 0.21103234589099884, -0.36329448223114014, -0.4674072265625, -0.2640712261199951, 1.2772148847579956, -0.9507939219474792, -0.3259751498699188, -0.5253450274467468, -0.760404109954834, -0.2631816267967224, 0.4323611557483673, -0.9271772503852844, 0.6813852190971375, -0.39310601353645325, 0.055252641439437866, 0.23790806531906128, -0.9944612383842468, 0.22456443309783936, 0.5281215906143188, -0.22764952480793, -0.169926255941391, 0.256933331489563, 0.8691460490226746, -0.7718766331672668, -0.21656303107738495, 0.02638780139386654, -0.3328613340854645, 0.0020232275128364563, 0.6137776374816895, -0.5558537840843201, 1.0578526258468628, 0.6976427435874939, -0.15808618068695068, -0.8881114721298218, -0.12144764512777328, -0.8932363986968994, 0.6101185083389282, 0.05490723252296448, 1.1591788530349731, -0.2942799925804138, -0.0997425764799118, 1.2883435487747192, 0.06412464380264282, -0.09032448381185532, -0.07400883734226227, -0.09850256890058517, -0.06433084607124329, -0.28101059794425964, 0.5500027537345886, -0.3397228717803955, -0.09402899444103241, -0.059735823422670364, 0.7080373764038086, 0.43659037351608276, -0.21433673799037933, -0.5027865171432495, 0.3909893333911896, -0.14136341214179993, -0.2361883521080017, -0.6024535298347473, -0.031634870916604996, -1.3716570138931274, 0.1992403119802475, -1.186784029006958, 0.2950921356678009, -1.0765539407730103, -0.3026876747608185, 0.39797264337539673, 0.13077928125858307, -0.04287154600024223, 0.12363730370998383, -0.3932493329048157, -0.9661602973937988, -0.5148264169692993, -0.47029340267181396, 0.8985525965690613, 0.8294609189033508, -0.4159475564956665, 0.03950916603207588, -0.28834784030914307, -0.29073795676231384, 0.2292577177286148, 0.3147633373737335, -0.39042240381240845, -0.6918378472328186, -1.7236566543579102, 0.17803674936294556, 0.20269566774368286, 0.033128347247838974, -0.6607311964035034, 0.435553640127182, 0.31227418780326843, -0.322584331035614, 0.24511303007602692, -0.3336102366447449, -0.3915479779243469, -0.3943819999694824, 0.4840352237224579, -0.8970737457275391, 0.4574286639690399, 0.09843496978282928, -0.7904053926467896, -0.5096970200538635, 0.3153602182865143, -0.45650047063827515, -1.033637523651123, -0.4672493636608124, 0.5150914192199707, -0.8157941699028015, -0.07157198339700699, -0.04035313427448273, -0.505993664264679, -0.8037859797477722, -0.48486196994781494, 0.24915088713169098, 0.21574954688549042, -0.2498531937599182, 1.1187970638275146, 0.6267446875572205, -1.0723804235458374, -0.1836823672056198, 0.5268371105194092, 0.16936646401882172, -0.6909070611000061, 0.3433152437210083, 0.5103392601013184, -0.39422619342803955, 0.7525230050086975, 0.5860971212387085, 0.42312222719192505, -0.9287059903144836, -0.5975537300109863, 0.49982723593711853, -0.38763105869293213, 0.12859413027763367, 1.204040288925171, -0.29073503613471985, -1.3864691257476807, -0.15345938503742218, -0.9667051434516907, -0.5036888122558594, -0.936542809009552, 0.7959849238395691, -0.06383788585662842, 0.050725340843200684, -0.3579702079296112, -0.05828564614057541, 0.364251971244812, 0.043570779263973236, -0.793891191482544, 0.3752988576889038, -0.2552245259284973, -0.49994710087776184, 0.15028123557567596, 0.21704316139221191, -0.7725868225097656, -0.3729274570941925, -0.07265983521938324, -0.06667589396238327, -0.2527329921722412, 0.12162584066390991, -0.6311410069465637, -0.40714165568351746, 0.7172929644584656, 0.3365170657634735, -0.14819882810115814, 0.08848356455564499, -0.23413431644439697, 0.5361890196800232, 0.44160136580467224, 0.5470966100692749, -0.5530920624732971, -0.15427762269973755, 1.201210856437683, 1.2625807523727417, -1.3734254837036133, -0.576480507850647, -0.20082572102546692, -0.9984859824180603, 0.7709455490112305, 0.7285540103912354, 0.5660924911499023, 0.34216630458831787, -0.07949790358543396, 0.4730030298233032, 0.22728395462036133, -1.1088813543319702, 0.016663702204823494, 0.8691487312316895, 1.066904067993164, 1.4230608940124512, 0.5162166953086853, -0.6335079073905945, 1.0963433980941772, -0.10310126841068268, 0.3454183042049408, 0.7017570734024048, 0.4052271544933319, -0.7694166898727417, -0.6571027636528015, 0.05704601854085922, 0.7873117923736572, -0.1633499264717102, -0.6397639513015747, -0.3866831064224243, 0.16564396023750305, 0.030782734975218773, 1.1147407293319702, 0.27298739552497864, -0.21439412236213684, 0.5511495471000671, 0.2984192371368408, 0.24852560460567474, -1.0188783407211304, -0.5008341073989868, -0.22278958559036255, -0.40607142448425293, -0.27899304032325745, 0.19865351915359497, -0.37512168288230896, -0.5522608757019043, -0.06529054045677185, 0.2469760775566101, 0.13502633571624756, 0.48362255096435547, 1.1890487670898438, 0.5041897892951965, 0.06241295486688614, -0.20724831521511078, -0.3075461983680725, -0.570030689239502, -1.0543731451034546, 0.3416094183921814, -0.6720154881477356, -0.9277186989784241, -0.19472303986549377, 0.024219071492552757, -0.1474934071302414]}, "authors": [{"authorId": "74210019", "name": "Ansar Aynetdinov"}, {"authorId": "2273785959", "name": "Alan Akbik"}], "references": [{"paperId": "ce157cea880c9ab64de64f11a531202f5348fa05", "title": "\"Kelly is a Warm Person, Joseph is a Role Model\": Gender Biases in LLM-Generated Reference Letters"}, {"paperId": "a327111002d3d76510970d1eec3f03fb85314f11", "title": "OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs"}, {"paperId": "38d64919ba526868a850a0e5f6239d4c474b7e7e", "title": "Large Language Models are not Fair Evaluators"}, {"paperId": "546d0624adfc6e18fb87d8cc77e7705bb9ea7445", "title": "LIMA: Less Is More for Alignment"}, {"paperId": "381ab7a640f5b46b62f7e08d1af4a8e0d3eadd55", "title": "G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment"}, {"paperId": "e965e93e76a9e6c4e4863d145b5c007b540d575d", "title": "OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization"}, {"paperId": "e65b346d442e9962a4276dc1c1af2956d9d5f1eb", "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions"}, {"paperId": "06d7cb8c8816360feb33c3367073e0ef66d7d0b0", "title": "Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "e6e7d253ace58185acc8b4d8962f7c7b75ab110b", "title": "DiscoScore: Evaluating Text Generation with BERT and Discourse Coherence"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "a6a7724763d8adba466519489b0b9d209e7f2d15", "title": "BARTScore: Evaluating Generated Text as Text Generation"}, {"paperId": "9e67b9758520e49016ab66bafb974d2e1ed762d1", "title": "COMET: A Neural Framework for MT Evaluation"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "270f3bea8ca801870a6cc56b4d36f7f2019c9ed0", "title": "MPNet: Masked and Permuted Pre-training for Language Understanding"}, {"paperId": "4ae52766028e69186052ea8f33a137fbbbdb986a", "title": "BLEURT: Learning Robust Metrics for Text Generation"}, {"paperId": "89e0504b68ace8bd3c71e9113de51a29702dcdb7", "title": "Large-Scale, Diverse, Paraphrastic Bitexts via Sampling and Clustering"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "93d63ec754f29fa22572615320afe0521f7ec66d", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "01e96a94b155be1bfde39aae92ab340b8cb8a0ba", "title": "RUSE: Regressor Using Sentence Embeddings for Automatic Machine Translation Evaluation"}, {"paperId": "b4bfadfca9742bb3ee98a0cd322d5ce4e59a3ceb", "title": "A Call for Clarity in Reporting BLEU Scores"}, {"paperId": "d1505c6123c102e53eb19dff312cb25cea840b72", "title": "Teaching Machines to Read and Comprehend"}, {"paperId": "7533d30329cfdbf04ee8ee82bfef792d08015ee5", "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": null, "title": "Falcon-40B: an open large language model"}, {"paperId": null, "title": "2023. Stanford alpaca: An instruction-following llama model"}, {"paperId": null, "title": "Ex-trinsic Evaluation Measures for Machine Translation and/or Summarization"}, {"paperId": null, "title": "for those instruction groups that have at least 6 instances over the four model variants we evaluated manually ( gpt-3.5-turbo , GPT-4, LLaMA and Alpaca). Evaluation scores for other models"}, {"paperId": null, "title": "Example 3 shows a coding-related in which S EM S CORE scores surprisingly given that"}, {"paperId": null, "title": "Example 1 illustrates a creative task that shows the strengh of embedding-based evaluations"}, {"paperId": null, "title": "2023. Representation biases in sentence transformers"}, {"paperId": null, "title": "2023. Gptscore: Evaluate as you desire"}, {"paperId": null, "title": "We evaluate 8 existing text generation metrics to determine which best correlates to this human-judged ranking. Alpaca-tuned use the same (2023c). For"}, {"paperId": null, "title": "2023. Instructeval: Towards holistic evaluation of instruction-tuned large language models"}, {"paperId": null, "title": "2023. Instruction tuning with gpt-4"}, {"paperId": null, "title": "Based on this extended study, we produce a human-judged ranking of all 12 models"}, {"paperId": null, "title": "ROUGE-L is able to compete with S EM S CORE , while BERTScore is a little too high in this case G-Eval-4 in this case fails to score the response"}, {"paperId": null, "title": "score as well"}, {"paperId": null, "title": "to provide additional understanding of how each metric deals with various types of tasks in our dataset, we provide a further per-task break-down"}, {"paperId": null, "title": "2023. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality"}]}