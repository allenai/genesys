{"paperId": "e92a5332390f0ba94615935541da4da9bed56512", "title": "OliVe: Accelerating Large Language Models via Hardware-friendly Outlier-Victim Pair Quantization", "abstract": "Transformer-based large language models (LLMs) have achieved great success with the growing model size. LLMs' size grows by 240\u00d7 every two years, which outpaces the hardware progress and makes model inference increasingly costly. Model quantization is a promising approach to mitigate the widening gap between LLM size and hardware capacity. However, the existence of outliers, values with significant magnitudes, in LLMs makes existing quantization methods less effective. Prior outlier-aware quantization schemes adopt sparsity encoding techniques to separate outliers from normal values where the process requires global coordination (e.g., a global sparsity coordination list). This incurs complex encoding/decoding hardware logics and an extra orchestration controller for the computation between outlier and normal values. As such, it is not hardware-efficient and hence only achieves sub-optimal quantization benefits. We propose OliVe, an algorithm/architecture co-designed solution that adopts an outlier-victim pair (OVP) quantization and handles outlier values locally with low hardware overheads and high performance gains. The key insight of OliVe is that outliers are important while the normal values next to them are not. Thus those normal values (called victims) can be sacrificed to accommodate outliers. This enables a memory-aligned OVP encoding scheme, which can be efficiently integrated to the existing hardware accelerators like systolic array and tensor core. As a result, OliVe-based accelerator surpasses the existing outlier-aware accelerator, GOBO, by 4.5\u00d7 speedup and 4.0\u00d7 energy reduction, respectively, with a superior model accuracy.", "venue": "International Symposium on Computer Architecture", "year": 2023, "citationCount": 31, "influentialCitationCount": 3, "openAccessPdf": {"url": "https://arxiv.org/pdf/2304.07493", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "The key insight of OliVe is that outliers are important while the normal values next to them are not, which enables a memory-aligned OVP encoding scheme, which can be efficiently integrated to the existing hardware accelerators like systolic array and tensor core."}, "embedding": {"model": "specter_v2", "vector": [0.12835079431533813, 0.2064490020275116, -0.7654935121536255, 0.19220083951950073, -0.35778769850730896, 0.5283932685852051, 0.24884366989135742, 0.47280803322792053, -0.33111369609832764, -0.9919739365577698, 0.490760862827301, 0.12524724006652832, 0.6607140898704529, 0.06830217689275742, -0.05788123980164528, 0.2660587728023529, -1.228819489479065, 0.008678288199007511, -0.10794413089752197, -0.2336142510175705, 0.4605119228363037, -0.47247713804244995, -1.3816399574279785, 0.3387605547904968, 0.5197383165359497, 1.0075827836990356, -0.2547049820423126, 0.6826398968696594, -0.7409964203834534, 0.4985460638999939, 0.6156145334243774, 0.19514690339565277, 0.35463041067123413, 0.09791437536478043, 0.3005555272102356, -0.08729857951402664, 0.34904244542121887, -0.6360034346580505, -0.16746628284454346, 1.048193097114563, -0.2619149684906006, 0.016565103083848953, 0.06810595840215683, -1.29200279712677, -0.2763356864452362, 0.7293740510940552, 0.21090000867843628, 0.5781493782997131, -0.6385875344276428, -0.4780772626399994, 1.3233976364135742, -1.8239372968673706, -0.29704058170318604, 1.2004272937774658, 0.6213104724884033, -0.007706434465944767, 0.026006894186139107, -0.4349672794342041, 0.20029927790164948, -0.04325958341360092, -1.248363971710205, -0.8323473334312439, 0.031114686280488968, -0.013586442917585373, 1.8414039611816406, -0.18185634911060333, -0.24052202701568604, 0.012764769606292248, 0.5040773153305054, 1.1764477491378784, -0.11880854517221451, -0.9498587250709534, 0.29228007793426514, -0.46166157722473145, 0.2837250530719757, 1.0331767797470093, 0.07022455334663391, 0.4030243456363678, -1.5446152687072754, -0.6135603189468384, 0.18964692950248718, 0.16667799651622772, 0.5784419775009155, -0.4549576938152313, -0.28695476055145264, 0.5531523823738098, 0.07720737904310226, 0.7637101411819458, 0.059614114463329315, 1.0543357133865356, 0.9098665714263916, 0.22535377740859985, -0.12195894867181778, 0.13091342151165009, 0.041217733174562454, 0.09416896849870682, -1.4068089723587036, 0.23570136725902557, 0.02737375907599926, 0.9432584047317505, -0.4093078374862671, 0.9059918522834778, -0.6064643263816833, -0.10569791495800018, 1.3611688613891602, 0.33713486790657043, 0.6629365086555481, -0.4229726791381836, 0.07912073284387589, -0.5175963044166565, 0.03718473017215729, -0.6016984581947327, -0.28401970863342285, -0.3838755488395691, -1.0428707599639893, -1.0859856605529785, -0.635678768157959, 1.0435147285461426, -0.9116227626800537, 0.3196105360984802, -0.6570583581924438, 0.5664682388305664, 0.11988671869039536, 0.0012506252387538552, 0.519187867641449, 0.38005778193473816, 0.20496255159378052, 0.08417943120002747, 1.0185472965240479, -1.2175925970077515, -0.2855164706707001, -1.0073449611663818, 0.9692192077636719, -0.6458936333656311, 0.3294089138507843, -0.1741611212491989, -1.2499810457229614, -1.115018367767334, -0.6529261469841003, -0.10075407475233078, -0.3830217123031616, -0.0034618754871189594, 0.7789461016654968, 0.384061723947525, -1.1412681341171265, 0.5223736763000488, -0.7286738753318787, 0.1422668993473053, 0.20323672890663147, 0.38845738768577576, 0.9047320485115051, 0.0018689255230128765, -0.9771962761878967, -0.2576723098754883, 0.09429485350847244, -0.7001352310180664, -0.04435011371970177, -0.7600703835487366, -1.320975422859192, 0.024580994620919228, 0.10746617615222931, -0.026741066947579384, 0.975349485874176, 0.2550366222858429, -0.9372991919517517, 0.4338292181491852, -0.5868813991546631, -0.06326993554830551, -0.21649181842803955, 0.11169639974832535, -0.9049203991889954, -0.5712502002716064, 0.038013558834791183, 0.09463172405958176, 0.7972095608711243, -0.21085187792778015, -0.12203998118638992, -0.019590752199292183, -0.7507502436637878, -0.11340907216072083, -0.28058016300201416, 1.189009189605713, -0.30409783124923706, -0.3152986466884613, 0.6403848528862, 0.7596979737281799, -0.6157039999961853, -0.06904276460409164, -0.33208194375038147, -0.740736186504364, 0.7951646447181702, 0.14926445484161377, 1.5517430305480957, -1.1136878728866577, -1.1349003314971924, 0.22848203778266907, 0.1244339793920517, -0.23723185062408447, -0.39237871766090393, 0.6971226334571838, -0.36315298080444336, 0.32453852891921997, 0.19274432957172394, -0.7441023588180542, 0.20849239826202393, -0.49900540709495544, -1.277633786201477, -0.23222260177135468, -0.19361427426338196, 0.980104923248291, -1.0322020053863525, 0.12269238382577896, -0.346804678440094, -0.15794427692890167, -1.0599853992462158, 1.1578221321105957, -0.19055573642253876, -0.06271185725927353, 0.07273531705141068, 0.4309327006340027, 0.276170015335083, -0.5490074157714844, 0.37360385060310364, -0.5868406891822815, -0.2597513496875763, 0.20464278757572174, -0.4622119665145874, 1.1134308576583862, -0.3480328619480133, -0.11728605628013611, -0.40996402502059937, -0.4093596339225769, 0.40708670020103455, 0.14045991003513336, -0.07731545716524124, -0.7237143516540527, 0.3476179540157318, 1.0421934127807617, -0.2667432427406311, 0.42416003346443176, 1.2416412830352783, 0.8952168822288513, -0.9184501767158508, 0.19223535060882568, 0.3229636251926422, -0.23202763497829437, 0.6723628044128418, 0.15293559432029724, 0.6904547810554504, 0.04967053607106209, 0.6488198637962341, 0.0019070757552981377, 0.5508643388748169, -0.8266026377677917, 0.05891512706875801, 0.8220869898796082, 0.3285309374332428, 0.5788446068763733, 0.4447440207004547, -0.9553965330123901, -0.6555488705635071, 0.012980851344764233, 0.6407625079154968, 1.5681513547897339, -0.0777692124247551, -0.6188551783561707, -0.2579599916934967, 0.031138306483626366, -0.12717711925506592, -0.09687035530805588, 0.3272697329521179, -0.4570714831352234, -0.6023866534233093, -0.9638651013374329, 1.0719135999679565, 0.4601527154445648, 0.6722419261932373, -0.5330116152763367, -0.5690860152244568, -0.2182004302740097, 0.5113641023635864, -0.8471938967704773, -0.6664656400680542, 0.7816085815429688, -0.8258720636367798, 0.4434463679790497, 0.5169593691825867, -0.030891230329871178, 0.45991721749305725, -0.8518170714378357, 1.1015357971191406, -0.1766671985387802, -0.34231725335121155, -0.26245149970054626, 0.5014092922210693, -0.7632377743721008, -1.1553528308868408, -0.298617959022522, 0.34807243943214417, -0.38810643553733826, 0.9591174125671387, 0.4380648732185364, 0.31783390045166016, -0.3416152894496918, -0.5408704876899719, -0.2192559838294983, 0.24042893946170807, 0.1309957057237625, 0.8217140436172485, -0.43880319595336914, -0.5301443338394165, -0.5673797726631165, 0.7523689866065979, 0.150469571352005, -0.6196576952934265, 0.013852955773472786, -0.8485730886459351, -0.20533008873462677, 0.9939776062965393, -0.34354737401008606, 0.45482897758483887, -1.1576476097106934, 0.44519415497779846, -0.5055795311927795, -0.18461410701274872, -0.08173813670873642, 0.44303855299949646, -0.13008317351341248, 0.1133582592010498, 0.8102460503578186, 0.23416142165660858, 0.17193102836608887, 0.2833372950553894, -0.44139260053634644, 0.30104467272758484, -0.355972558259964, 0.07332256436347961, 0.020423710346221924, -0.06044250726699829, -0.7850173115730286, -0.1962944120168686, -0.5344548225402832, -0.27728044986724854, 0.08284410834312439, -0.27881935238838196, -0.9245500564575195, -0.3501744270324707, 0.03585668280720711, -1.0915675163269043, 0.026707831770181656, -0.014619455672800541, -0.3681779205799103, -0.4277258813381195, -0.7543693780899048, -1.3001588582992554, -0.2926943898200989, -0.8538689613342285, -1.4760916233062744, 0.9074434041976929, -0.5397096276283264, -0.4763735830783844, -0.08804240822792053, -0.4131600260734558, -0.5319341421127319, 1.0606716871261597, -0.5291503667831421, 0.9924339056015015, -0.3563036024570465, -0.43615689873695374, -0.005348230246454477, 0.13910682499408722, 0.4217492640018463, -0.5363914370536804, 0.127516970038414, -0.4255087971687317, 0.11869600415229797, -0.17746810615062714, -0.22565239667892456, 0.03549037128686905, -0.17006243765354156, 1.1690359115600586, 0.22850386798381805, -0.469179630279541, 0.2662043869495392, 1.5063207149505615, -0.5785398483276367, 0.07073850184679031, -0.20227256417274475, 1.1054970026016235, -0.302692174911499, -0.2213522493839264, 1.0751314163208008, -0.12689776718616486, 0.5052130818367004, 0.29842624068260193, -0.0142557043582201, 0.1563607156276703, 0.012302471324801445, 0.9672994613647461, 2.421825885772705, 0.5794113874435425, 0.21998140215873718, -1.1799702644348145, 0.7212827205657959, -0.882237434387207, -0.40778347849845886, 0.3853585720062256, 0.9718307852745056, 0.11518172174692154, -0.14900276064872742, -0.41679054498672485, -0.08337511122226715, 0.3296155035495758, 0.5906983017921448, -0.34897947311401367, -1.489009141921997, 0.4862038791179657, 0.6530599594116211, 0.4705972671508789, 0.19328078627586365, -0.16373851895332336, 0.417791485786438, 14.576620101928711, 0.9407956600189209, -0.25391820073127747, 0.5123169422149658, 0.5521026849746704, 0.39932653307914734, -0.2648029029369354, 0.047875989228487015, -1.3898206949234009, 0.237352654337883, 1.9124369621276855, -0.06121046841144562, 0.0479578897356987, 0.45789769291877747, 0.2444336712360382, 0.4047086536884308, -0.4070425033569336, 0.7882270216941833, 0.7609761357307434, -1.3054149150848389, 0.6148289442062378, 0.20965375006198883, 0.36306580901145935, 0.5810840129852295, 0.6969200968742371, 0.6868347525596619, 0.111630380153656, -0.5149354934692383, 0.5941243767738342, 0.17558534443378448, 0.8561592698097229, -0.2674344778060913, 0.44740748405456543, 0.34150779247283936, -1.049615502357483, -0.16282346844673157, -0.9120368957519531, -1.4105558395385742, -0.007231793832033873, 0.712158203125, -0.5780006051063538, -0.5129315853118896, -0.26050814986228943, 0.5792378783226013, 0.1515897810459137, 0.4014722406864166, 0.37352144718170166, 0.3432547450065613, -0.34139856696128845, 0.34864455461502075, 0.18620336055755615, 0.3689609467983246, -0.013824651949107647, -0.3410515785217285, 0.3768327534198761, -0.7288351058959961, 0.882044792175293, 0.42511454224586487, -0.3272377550601959, 0.04751300439238548, -0.4196692109107971, -0.3722926676273346, -0.09957513213157654, 0.421448677778244, 0.2188657969236374, 0.08919093757867813, -0.8852695226669312, 0.33793526887893677, 0.3543151021003723, -0.29952654242515564, -0.4636736810207367, -0.029644377529621124, 0.1623944193124771, -0.46388986706733704, -0.05948084592819214, 0.44983506202697754, -0.38677841424942017, -0.8186652660369873, -0.5702899694442749, -0.6814056634902954, 0.14738065004348755, -0.18371212482452393, -0.435514897108078, 0.6061582565307617, -0.35554301738739014, -0.6367340683937073, 0.1219923198223114, -0.6227367520332336, -0.28202301263809204, 0.1701366901397705, -1.0346282720565796, -0.6974164843559265, 0.37952089309692383, -0.3683260679244995, -0.4789547324180603, 0.07218053936958313, 1.5017694234848022, 0.08257227391004562, -0.23481178283691406, 0.0403599850833416, 0.25470036268234253, -0.0904008224606514, -0.2553168833255768, -0.6636626124382019, 1.2700103521347046, 0.5555501580238342, 0.0436343289911747, 0.5249687433242798, 0.1509043425321579, -0.022369327023625374, -0.880103349685669, -0.3402082920074463, 0.9148616790771484, -0.6257919073104858, 0.1016315296292305, -0.9619792103767395, -0.7585924863815308, 0.3318708837032318, 0.016607897356152534, 0.5279459357261658, 0.5266813039779663, -0.13063420355319977, -0.7265306115150452, -0.17929337918758392, -0.40572425723075867, 0.250412255525589, 0.2996998727321625, -0.7932934761047363, -0.07678079605102539, -0.07441838085651398, 0.29570135474205017, -1.3031840324401855, -0.8740009665489197, -0.12939155101776123, 0.04322725534439087, -0.5150009393692017, 0.9450765252113342, -0.1840810477733612, 0.7528970837593079, 0.5088024139404297, -0.4403369426727295, -0.2790217399597168, 0.5003229975700378, -1.0252760648727417, -0.4307890236377716, -0.26981744170188904, 0.32028260827064514, -0.011487421579658985, 0.43710291385650635, 0.5344418883323669, 0.06325383484363556, -0.550237238407135, -0.6454350352287292, -0.5021055340766907, -0.18426649272441864, -0.8144956231117249, 0.5225081443786621, -0.28414902091026306, 0.08815950155258179, -0.407448947429657, -0.019483745098114014, 0.6281546950340271, 0.10615283995866776, -0.288773775100708, 0.5462117195129395, 0.18930897116661072, -0.14572247862815857, -0.38494840264320374, -0.9950177073478699, -1.1409558057785034, -0.050250161439180374, -1.2922337055206299, -0.05090663954615593, -0.0779493898153305, -0.359544962644577, 0.12591539323329926, -0.5643474459648132, 0.09175930917263031, 0.503075897693634, 0.03715978190302849, -0.5742419362068176, -0.22347310185432434, -0.7214190363883972, 0.7413762211799622, 0.40226978063583374, -0.377142071723938, 0.16319358348846436, -0.5125645995140076, 0.2987338602542877, 0.5609961152076721, 0.19144979119300842, -0.5569741129875183, -0.5230095982551575, -0.9673625230789185, 0.4753458797931671, -0.22097283601760864, 0.11125379055738449, -0.9941436648368835, 0.6104735136032104, 0.20230619609355927, -0.23555505275726318, 0.06704403460025787, -0.08938028663396835, -0.7758620381355286, -0.7047165036201477, 0.8461452722549438, -0.6499709486961365, 0.5542097091674805, 0.2549823224544525, -0.5982975363731384, -0.6823425889015198, 0.6882011890411377, -0.09009640663862228, -0.9074913263320923, -1.3677188158035278, 0.5353901386260986, -0.31776559352874756, 0.3459196388721466, -0.25088298320770264, 0.017168298363685608, -0.7981036305427551, 0.019255954772233963, 0.07935363799333572, -0.0476645790040493, 0.1455271691083908, 1.0584090948104858, 0.6449098587036133, -1.1709682941436768, 0.3271203637123108, 0.9262295961380005, 0.46441778540611267, -0.11652012169361115, 0.14932307600975037, 0.6482459902763367, -0.597343385219574, 0.5753607749938965, 0.31996968388557434, 0.027001027017831802, -0.8021733164787292, 0.12269840389490128, 0.24177631735801697, -0.8512415885925293, -0.12879231572151184, 0.9214714765548706, -0.5394261479377747, -0.8456183671951294, -0.30140170454978943, -1.647926926612854, 0.037958912551403046, -0.7620181441307068, 0.8048058152198792, 0.13138698041439056, 0.38642817735671997, -0.3474266231060028, -0.8337175846099854, -0.022180747240781784, -0.12925957143306732, 0.12760885059833527, 0.12088517844676971, -0.010405178181827068, -1.1938592195510864, 0.8076995015144348, 0.8858709931373596, -0.25392574071884155, 0.12014143913984299, -0.5375731587409973, -0.04506287723779678, -0.12862809002399445, 0.2889752686023712, 0.4653867483139038, -0.2666231393814087, 0.6693676710128784, 0.8042304515838623, 0.07100985199213028, 0.025512447580695152, -0.6087339520454407, 0.8483853340148926, 0.44909510016441345, 0.7032673954963684, -0.6639488339424133, -0.3109152019023895, 1.2565351724624634, 0.8219338655471802, -0.6611413955688477, 0.5219594836235046, -0.10997088253498077, -0.3188793361186981, 1.1456881761550903, 0.39528512954711914, -0.25025540590286255, 0.8708915114402771, 0.3813450336456299, 0.1505873203277588, 0.23053227365016937, -0.891524076461792, -0.05102480202913284, 0.8458003401756287, 0.642273485660553, 1.042729377746582, 0.24926428496837616, -0.028673332184553146, 0.5842465162277222, 0.32711437344551086, 0.39143165946006775, 0.8678545355796814, 0.7469885945320129, -0.4944225251674652, -0.5737568140029907, -0.5481722354888916, 1.0760383605957031, -0.7566264271736145, -1.3326940536499023, 0.7860227227210999, 0.4599502384662628, 0.31298136711120605, 0.3227847218513489, 1.070162057876587, 0.10028668493032455, 0.3312438130378723, 0.3235679268836975, 0.1846916377544403, -0.8280333876609802, -0.14623811841011047, 0.026331141591072083, -0.9713543653488159, -0.46703216433525085, -0.04573648422956467, 0.057465560734272, -0.8218713998794556, -0.20689409971237183, 0.522700309753418, -0.1193518415093422, 0.1554766744375229, 0.7408711910247803, 0.8669776320457458, 0.43237850069999695, -0.33685043454170227, -0.34752029180526733, -0.8847143650054932, -0.2845038175582886, -0.5544474720954895, -0.1907438486814499, -0.2763307988643646, 0.20652267336845398, -0.11751384288072586, -0.2971297800540924]}, "authors": [{"authorId": "2109865181", "name": "Cong Guo"}, {"authorId": "2214687479", "name": "Jiaming Tang"}, {"authorId": "2214664410", "name": "Weiming Hu"}, {"authorId": "1831521", "name": "Jingwen Leng"}, {"authorId": "145107889", "name": "Chen Zhang"}, {"authorId": "145338263", "name": "Fan Yang"}, {"authorId": "2117415805", "name": "Yun-Bo Liu"}, {"authorId": "2151671216", "name": "Minyi Guo"}, {"authorId": "2155860957", "name": "Yuhao Zhu"}], "references": [{"paperId": "4c14b1c41cb0aaa68f5d3f4a432f55e7199657ea", "title": "AI and Memory Wall"}, {"paperId": "9dadfd97013f649fbfa5641ef829cc1d575040e4", "title": "uGrapher: High-Performance Graph Operator Computation via Unified Abstraction for Graph Neural Networks"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "3f6243097a58e386aea1215fed4f372dee07a100", "title": "Outlier Suppression: Pushing the Limit of Low-bit Transformer Language Models"}, {"paperId": "1084825971f3879eeb7e45294bbef24a651fbf81", "title": "Nesting Forward Automatic Differentiation for Memory-Efficient Deep Neural Network Training"}, {"paperId": "90c570a5b1c7d9ceb3c4944a5967435ecec907ca", "title": "ANT: Exploiting Adaptive Numerical Data Type for Low-bit Deep Neural Network Quantization"}, {"paperId": "4be7d1524edb0137599a5cc95f72844b85a52fe1", "title": "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale"}, {"paperId": "81b234a1e6da7bc8131e8585a9455dca5dd68754", "title": "Transkimmer: Transformer Learns to Layer-wise Skim"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "583f353972ed917772f3f1fc62f4b7cadc8f1e81", "title": "SQuant: On-the-Fly Data-Free Quantization via Diagonal Hessian Approximation"}, {"paperId": "bf63b54064968dad3c4c4ebb29e7f4b66a6f5070", "title": "VELTAIR: towards high-performance multi-tenant deep learning services via adaptive compilation and scheduling"}, {"paperId": "f5a3dbc0518df5ca1b6333ae93244dde7f793736", "title": "Block-Skim: Efficient Question Answering for Transformer"}, {"paperId": "2327f7f3f9b1e8b8acf7cde2ff186a3ea2a43657", "title": "Characterizing and Demystifying the Implicit Convolution Algorithm on Commercial Matrix-Multiplication Accelerators"}, {"paperId": "8a0a7170977cf5c94d9079b351562077b78df87a", "title": "A White Paper on Neural Network Quantization"}, {"paperId": "309fb5c6ed6d7ec85281ee315760df342e6c4fcc", "title": "Ten Lessons From Three Generations Shaped Google\u2019s TPUv4i : Industrial Product"}, {"paperId": "ae5e7794aaff65590e265bdf4d65c44f6fa05064", "title": "Dual-side Sparse Tensor Core"}, {"paperId": "1adadbfa95e43a70fcd17e6ce947a0652b86bfc3", "title": "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus"}, {"paperId": "8c8f83ae02a364d6b4bc755bee4b4a115682b3ee", "title": "DeepScaleTool: A Tool for the Accurate Estimation of Technology Scaling in the Deep-Submicron Era"}, {"paperId": "1ab8ec9583db0f1bb28b59c992cd035bc7928f04", "title": "How Far Does BERT Look At: Distance-based Clustering and Analysis of BERT\u2019s Attention"}, {"paperId": "3ccddb9316e82ce76cb70383c6c18a4a01596ad1", "title": "Lazy Batching: An SLA-aware Batching System for Cloud Machine Learning Inference"}, {"paperId": "53439309acd147a51555dfcbe797beab652b25c5", "title": "Accelerating Sparse DNN Models without Hardware-Support via Tile-Wise Sparsity"}, {"paperId": "9ffed10c3d28189783efa51156f451b262d040d4", "title": "Algorithm-Hardware Co-Design of Adaptive Floating-Point Encodings for Resilient Deep Learning Inference"}, {"paperId": "09bda461aa4911d0513e8e46dd39a4113947e450", "title": "Ansor : Generating High-Performance Tensor Programs for Deep Learning"}, {"paperId": "1b0c8b26affd13e10ace5770e85478d60dcc368e", "title": "GOBO: Quantizing Attention-Based NLP Models for Low Latency and Energy Efficient Inference"}, {"paperId": "dff076e78b3f333772be076c65a96e3b7a70ba92", "title": "DRQ: Dynamic Region-based Quantization for Deep Neural Network Acceleration"}, {"paperId": "9088661f7523b744071fc40e2f8e612274854438", "title": "Rethinking Differentiable Search for Mixed-Precision Neural Networks"}, {"paperId": "d84e056bc71e98424912a43f04471600f12804aa", "title": "FlexTensor: An Automatic Schedule Exploration and Optimization Framework for Tensor Computation on Heterogeneous System"}, {"paperId": "0aefe26e6dfa160ec80dbd21a3b150c108288dde", "title": "Balancing Efficiency and Flexibility for DNN Acceleration via Temporal GPU-Systolic Array Integration"}, {"paperId": "fcf1b4473a0af1f3ebc0fd556ee30c9309ff6345", "title": "SIGMA: A Sparse and Irregular GEMM Accelerator with Flexible Interconnects for DNN Training"}, {"paperId": "0acc25f3993bd9431418ae275aa12a536b740b77", "title": "ZeroQ: A Novel Zero Shot Quantization Framework"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "0a5d987ddb5463062babceca90ba974db0cf96e7", "title": "HAWQ-V2: Hessian Aware trace-Weighted Quantization of Neural Networks"}, {"paperId": "12e386d3e993127ecc72bfbc9d35d98de177a513", "title": "Ebird: Elastic Batch for Improving Responsiveness and Throughput of Deep Learning Services"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "80b362efee95c1759c6dab9219eb77ca3ee44475", "title": "TASO: optimizing deep learning computation with automatic generation of graph substitutions"}, {"paperId": "ce106590145e89ea4b621c99665862967ccf5dac", "title": "Q8BERT: Quantized 8Bit BERT"}, {"paperId": "52d655cadb4ab977b951c1d57e740688f54032dd", "title": "Sparse Tensor Core: Algorithm and Hardware Co-Design for Vector-wise Sparse Neural Networks on Modern GPUs"}, {"paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d", "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"}, {"paperId": "f039a499df54321d84b8b214534df6c0b9a9394b", "title": "Effective Training of Convolutional Neural Networks With Low-Bitwidth Weights and Activations"}, {"paperId": "d5c91076338fec5e2d75841c6466cc0aca5d4ff9", "title": "BiScaled-DNN: Quantizing Long-tailed Datastructures with Two Scale Factors for Deep Neural Networks"}, {"paperId": "36eac4877193fe0d137c9fd00962f1c54cca2e2b", "title": "Learning Channel-Wise Interactions for Binary Convolutional Neural Networks"}, {"paperId": "1a858b96d2fdfeadf8c0f7126cbd55825223fb9d", "title": "HAWQ: Hessian AWare Quantization of Neural Networks With Mixed-Precision"}, {"paperId": "81336b3474553bfc861d3c724f79ce52b579a5e3", "title": "Adversarial Defense Through Network Profiling Based Path Extraction"}, {"paperId": "54c4642d017830e1faddbb49f0377228d2b01493", "title": "HAQ: Hardware-Aware Automated Quantization With Mixed Precision"}, {"paperId": "ae64adf6fc9df5a3b24bd2c5152cda68323deb81", "title": "Modeling Deep Learning Accelerator Enabled GPUs"}, {"paperId": "61e67a845becdf37a9e039189a5a831d23039d26", "title": "Accel-Sim: An Extensible Simulation Framework for Validated GPU Modeling"}, {"paperId": "f789425a7af1d012675118d7d10cd50afad09074", "title": "Post training 4-bit quantization of convolutional networks for rapid-deployment"}, {"paperId": "2a84a30a489cd6f59725b80164b24c227d86c160", "title": "Cambricon-S: Addressing Irregularity in Sparse Neural Networks through A Cooperative Software/Hardware Approach"}, {"paperId": "3cd3f1585ced02cbb56a9e1428176a6c2b211da2", "title": "Learning to Quantize Deep Networks by Optimizing Quantization Intervals With Task Loss"}, {"paperId": "a8e1b91b0940a539aca302fb4e5c1f098e4e3860", "title": "LQ-Nets: Learned Quantization for Highly Accurate and Compact Deep Neural Networks"}, {"paperId": "8e64c651b89ea4bad78cf0642876cb12e233e2a5", "title": "Energy-Efficient Neural Network Accelerator Based on Outlier-Aware Low-Precision Computation"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "49e60f82d6ae835c56473464f67ca5c11d3e95ec", "title": "PACT: Parameterized Clipping Activation for Quantized Neural Networks"}, {"paperId": "59d0d7ccec2db66cad20cac5721ce54a8a058294", "title": "Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference"}, {"paperId": "69e220145b5a7886f9c92da8a253b6cc97181f57", "title": "Bit Fusion: Bit-Level Dynamically Composable Architecture for Accelerating Deep Neural Network"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "2dfeb5a90abc49ab2a80a492a01a4e2c8e92ec22", "title": "In-datacenter performance analysis of a tensor processing unit"}, {"paperId": "fdd4cf09259974aa26a40be24cfbda792cf438c3", "title": "Prophet: Precise QoS Prediction on Non-Preemptive Accelerators to Improve Utilization in Warehouse-Scale Computers"}, {"paperId": "bc20f523a6e97800340e57a94d79926fce05572c", "title": "Cambricon-X: An accelerator for sparse neural networks"}, {"paperId": "924d6c44fda59dc9ac1f25d7cc12d669c5f9e557", "title": "From high-level deep neural models to FPGAs"}, {"paperId": "8b053389eb8c18c61b84d7e59a95cb7e13f205b7", "title": "DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "5ec594e9f5ca4b629be28625cd78c882514ea3be", "title": "Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks"}, {"paperId": "b04c9e851ae605592d693aa65f0d753b8af08feb", "title": "Baymax: QoS Awareness and Increased Utilization for Non-Preemptive Accelerators in Warehouse Scale Computers"}, {"paperId": "ffdaa12ef011de9dbf43be46d45a3abcc8288965", "title": "Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "642d0f49b7826adcf986616f4af77e736229990f", "title": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"}, {"paperId": "1dca94518af97b6e84797b4732e25d105e983682", "title": "Heracles: Improving resource efficiency at scale"}, {"paperId": "bd6507b5c9deaf87bda81e59ce15b2309df0bf37", "title": "ShiDianNao: Shifting vision processing closer to the sensor"}, {"paperId": "68837728232463651283edbb7ef0c93b2f502b2b", "title": "PuDianNao: A Polyvalent Machine Learning Accelerator"}, {"paperId": "3468a27c2e3019e1216ee9fe8bbf1ed3a0155ff4", "title": "Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks"}, {"paperId": "b7cf49e30355633af2db19f35189410c8515e91f", "title": "Deep Learning with Limited Numerical Precision"}, {"paperId": "4157ed3db4c656854e69931cb6089b64b08784b9", "title": "DaDianNao: A Machine-Learning Supercomputer"}, {"paperId": "233b1774f28c9972df2dfcf20dfbb0df45792bd0", "title": "A 240 G-ops/s Mobile Coprocessor for Deep Neural Networks"}, {"paperId": "22e477a9fdde86ab1f8f4dafdb4d88ea37e31fbd", "title": "DianNao: a small-footprint high-throughput accelerator for ubiquitous machine-learning"}, {"paperId": "0b71de48a1c7a5d7a7850bbe33a2bb055ea594ef", "title": "Memory-centric accelerator design for Convolutional Neural Networks"}, {"paperId": "62c76ca0b2790c34e85ba1cce09d47be317c7235", "title": "Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation"}, {"paperId": "7ea15c138cc72588fa376ff819f4bb8ca0b324da", "title": "GPUWattch: enabling energy optimizations in GPGPUs"}, {"paperId": "bd9d8d5fe2bdb6e17cf6bf23b5ca24838bbc64bf", "title": "Bubble-up: Increasing utilization in modern warehouse scale computers via sensible co-locations"}, {"paperId": "2d6f002477015469075954c6748a1a85af352c94", "title": "Analyzing CUDA workloads using a detailed GPU simulator"}, {"paperId": "46965d293c72efc9acd9bf50f85afbdacce14c67", "title": "Logic Synthesis Using Synopsys"}, {"paperId": "e6da45c79cf4c0b051b17ec9354927c61ed38776", "title": "RETROSPECTIVE: Cnvlutin: Ineffectual-Neuron-Free Deep Neural Network Computing"}, {"paperId": "5b9f296f00e524bbd270541d1e326b27a2e94e54", "title": "RETROSPECTIVE: Bubble-Flux: Precise Online QoS Management for Increased Utilization in Warehouse Scale Computers"}, {"paperId": "f9cee797aa0f8ea126208f40f35b2b762402bc2a", "title": "Efficient Activation Quantization via Adaptive Rounding Border for Post-Training Quantization"}, {"paperId": "4fab100cd7f4ec9b607b1fc23831bfb96f2edc07", "title": "This paper is included in the Proceedings of the 16th USENIX Symposium on Operating Systems Design and Implementation."}, {"paperId": null, "title": "DVABatch: Diversity-aware Multi-Entry Multi-Exit Batching for Efficient Processing of DNN Services on GPUs"}, {"paperId": null, "title": "NVIDIA A100 tensor core architecture"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "ec3071fb918ad69ec80df1ca9cf1fdeb386a9603", "title": "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning"}, {"paperId": "3364bc50921a9566d61ef8cb73baa82341725e4b", "title": "CACTI 6.0: A Tool to Model Large Caches"}, {"paperId": null, "title": "ModelTC"}, {"paperId": null, "title": "Wikipedia contributors"}, {"paperId": null, "title": "The Free Encyclopedia"}, {"paperId": null, "title": "ISCA \u201923, June 17\u201321, 2023, Orlando, FL, USA"}]}