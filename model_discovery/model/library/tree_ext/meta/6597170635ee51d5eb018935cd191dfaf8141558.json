{"paperId": "6597170635ee51d5eb018935cd191dfaf8141558", "title": "Investigating Automatic Scoring and Feedback using Large Language Models", "abstract": "Automatic grading and feedback have been long studied using traditional machine learning and deep learning techniques using language models. With the recent accessibility to high performing large language models (LLMs) like LLaMA-2, there is an opportunity to investigate the use of these LLMs for automatic grading and feedback generation. Despite the increase in performance, LLMs require significant computational resources for fine-tuning and additional specific adjustments to enhance their performance for such tasks. To address these issues, Parameter Efficient Fine-tuning (PEFT) methods, such as LoRA and QLoRA, have been adopted to decrease memory and computational requirements in model fine-tuning. This paper explores the efficacy of PEFT-based quantized models, employing classification or regression head, to fine-tune LLMs for automatically assigning continuous numerical grades to short answers and essays, as well as generating corresponding feedback. We conducted experiments on both proprietary and open-source datasets for our tasks. The results show that prediction of grade scores via finetuned LLMs are highly accurate, achieving less than 3% error in grade percentage on average. For providing graded feedback fine-tuned 4-bit quantized LLaMA-2 13B models outperform competitive base models and achieve high similarity with subject matter expert feedback in terms of high BLEU and ROUGE scores and qualitatively in terms of feedback. The findings from this study provide important insights into the impacts of the emerging capabilities of using quantization approaches to fine-tune LLMs for various downstream tasks, such as automatic short answer scoring and feedback generation at comparatively lower costs and latency.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper explores the efficacy of PEFT-based quantized models, employing classification or regression head, to fine-tune LLMs for automatically assigning continuous numerical grades to short answers and essays, as well as generating corresponding feedback."}, "embedding": {"model": "specter_v2", "vector": [-0.157627135515213, 0.5034642219543457, -0.31527820229530334, -0.49289533495903015, -0.6590474843978882, -0.38663676381111145, 0.35836732387542725, 0.06614326685667038, -0.31720447540283203, 0.20769722759723663, 0.4612779915332794, -0.2580767273902893, 0.2995409369468689, -0.06487659364938736, 0.10655537247657776, 0.3614974617958069, -0.4958946406841278, 0.5460383892059326, -0.30498436093330383, -0.5545562505722046, 0.16378268599510193, -0.7138078212738037, -0.5718272924423218, 0.05041446536779404, 0.7032830715179443, 0.4390242397785187, -0.2724514305591583, 1.4219502210617065, -0.32625165581703186, 0.23353810608386993, -0.023262636736035347, -0.6379175782203674, 0.012375304475426674, -0.20615944266319275, -0.8334723114967346, 0.0639306977391243, 0.5472805500030518, -0.7779314517974854, -0.237631693482399, 0.597214937210083, -0.07824943214654922, 0.3583686351776123, 0.769446074962616, -0.2524457275867462, -0.7272627353668213, 0.36835458874702454, 0.5195512771606445, 0.4670940339565277, 0.39087018370628357, -0.21162675321102142, 1.265570878982544, -1.2751431465148926, 0.0773136094212532, 1.3982207775115967, 0.18144631385803223, 0.38475582003593445, -0.12363070994615555, -0.5662983655929565, 0.1426800936460495, -0.0035023761447519064, -0.7041751742362976, 0.06004780903458595, -0.31330645084381104, -0.33989134430885315, 1.1358951330184937, -0.21149033308029175, -0.4756953716278076, -0.1647244691848755, -0.2376646101474762, 1.3160219192504883, 0.5299192070960999, -1.129194736480713, -0.14846669137477875, 0.11746244877576828, 0.6083422303199768, 1.0387070178985596, -0.5517805218696594, -0.15060214698314667, -0.8667365908622742, -0.16075608134269714, 0.29090628027915955, -0.5025523900985718, -0.20808903872966766, 0.13482384383678436, -0.3255756199359894, 0.7783674001693726, 0.46477439999580383, -0.05499231070280075, -0.11041030287742615, 0.41763344407081604, 0.35091501474380493, 0.6737072467803955, -0.1864025890827179, 0.5968129634857178, -0.49541449546813965, 0.4309077262878418, -0.7728509306907654, 0.4933207929134369, 0.058169636875391006, 0.32884475588798523, -0.007832647301256657, -0.09358227252960205, -1.402408480644226, 0.28847113251686096, 1.354598045349121, -0.04233284667134285, 0.6356216669082642, -0.8764175176620483, 0.3966127038002014, -0.43881046772003174, 0.6977699398994446, -0.33266422152519226, -0.058927230536937714, -0.0700579434633255, -0.7816287875175476, -0.7445169687271118, -0.2613956332206726, -0.07361850887537003, -0.8281248807907104, 0.7281230688095093, -0.18081030249595642, -0.32372716069221497, 0.05718478560447693, 1.078991174697876, 0.5875184535980225, 0.611527144908905, 0.19693523645401, 0.13506652414798737, 0.9305885434150696, -0.828209638595581, -0.7280056476593018, -0.6092967391014099, 1.036428689956665, -0.5677180886268616, 0.7009609341621399, 0.12468301504850388, -1.2850667238235474, -0.9387570023536682, -0.8452474474906921, -0.20081204175949097, -0.11861767619848251, 0.7559047937393188, 0.9257887005805969, 0.6284673810005188, -1.3376665115356445, 0.6541218161582947, 0.02023245021700859, -0.015579969622194767, 0.16202765703201294, 0.32100242376327515, 0.4524542987346649, -0.6139355897903442, -1.2611480951309204, 0.0020097673404961824, -0.16583654284477234, -0.6785805821418762, 0.18621110916137695, -0.3008474111557007, -0.9056620597839355, 0.05994170531630516, -0.050395578145980835, -0.4816703200340271, 1.826546311378479, 0.05339284986257553, -1.5258108377456665, 0.7286831140518188, -0.12472511827945709, 0.2536812126636505, 0.5926899313926697, -0.24700117111206055, -0.25665080547332764, -0.43959835171699524, -0.3720444142818451, 0.8655097484588623, 0.057128358632326126, 0.4602513611316681, 0.06605256348848343, 0.4126312732696533, 0.2377258837223053, 0.1306965947151184, -0.738494336605072, 0.7924978137016296, -0.16362500190734863, -0.18188171088695526, 0.12521111965179443, 0.704156219959259, -0.09406646341085434, -0.025373565033078194, -0.17118746042251587, -1.340768575668335, 0.4600207507610321, -0.2709665596485138, 1.4130157232284546, -0.42387548089027405, -0.7970466017723083, -0.21690787374973297, -0.06428152322769165, 0.16855983436107635, -0.5755273103713989, -0.05055408552289009, -0.21872559189796448, 0.4843301475048065, -0.12042117118835449, -0.9052336812019348, 0.22927282750606537, -0.5889739990234375, -0.4995683431625366, -0.21533922851085663, 0.14014871418476105, 1.1248369216918945, -0.6032161116600037, 0.2362077534198761, -0.2588430941104889, -0.16578881442546844, -0.9636511206626892, 1.6264734268188477, -0.48572686314582825, 0.11019562929868698, -0.11339990049600601, -0.06603434681892395, -0.08179420977830887, -0.6956062316894531, 0.04357309639453888, 0.22482916712760925, 0.10978080332279205, 0.6669546961784363, -0.9845558404922485, 1.307687520980835, -0.020167939364910126, 0.24642007052898407, -0.14180944859981537, -0.15998370945453644, 0.6114452481269836, 0.5823439955711365, -0.724238932132721, -0.4747602939605713, -0.04331400990486145, 0.762636125087738, -0.8641638159751892, 0.3102915287017822, 0.9874352812767029, 0.857535719871521, -0.6078861355781555, 0.7358701229095459, 0.571141242980957, -0.5296235084533691, 0.7458589673042297, 0.6967726349830627, 0.582095205783844, 0.48168113827705383, 0.5300129652023315, 0.12493458390235901, 0.6793642640113831, -0.6802445650100708, -0.2637975513935089, 0.34569400548934937, 0.29232335090637207, 1.2187529802322388, 0.23927198350429535, -0.7703991532325745, -0.27067384123802185, -0.047367487102746964, 0.9619224667549133, 1.7670435905456543, -0.10723508894443512, -0.1667863130569458, -0.7353242635726929, -0.5161190032958984, -0.33637988567352295, -0.4013683497905731, -0.2718353867530823, 0.01222100481390953, -0.6718569397926331, -1.034691572189331, 0.5788733959197998, 0.36311426758766174, 0.5759517550468445, -0.5255979895591736, -0.13641516864299774, -0.4926265478134155, 0.07140948623418808, -0.1927262395620346, -0.7988216280937195, 0.1814775913953781, -0.44727227091789246, 0.0597555972635746, -0.40257546305656433, -0.09237845987081528, 0.06551901996135712, -0.7898677587509155, 1.1994699239730835, -0.2016586810350418, -0.005106022115796804, -0.06323357671499252, 0.604425847530365, -0.4025779068470001, -0.7694032192230225, 0.3052179217338562, 0.2540800869464874, -0.44830256700515747, 0.34586116671562195, 0.7759367823600769, -0.03634233400225639, 0.30233925580978394, -0.31197017431259155, 0.056543949991464615, 0.2726602256298065, 0.2060806006193161, 0.6379439830780029, -1.0145843029022217, 0.3315429389476776, -1.178308129310608, 1.3450865745544434, 0.37417978048324585, -0.4877834618091583, 0.49951571226119995, -0.8788579702377319, -0.2706560492515564, 0.5535172820091248, -0.3271315395832062, -0.25439736247062683, -1.1475149393081665, 0.5225399136543274, 0.07299468666315079, -0.32330021262168884, 0.28544190526008606, 0.565081000328064, -0.04016261175274849, 0.6900047659873962, -0.1531241238117218, 0.17086242139339447, -0.1165897324681282, 0.3821422755718231, -0.17487843334674835, 0.7055511474609375, 0.04663262143731117, 0.003624277887865901, -0.8706993460655212, -0.41478231549263, 0.08298424631357193, -0.8701881170272827, -0.47582289576530457, -0.36289525032043457, -0.2629880905151367, -0.026673581451177597, -0.5975540280342102, -0.9136298894882202, -0.18790476024150848, -1.1136274337768555, -0.22602875530719757, 0.0918254554271698, -0.23255078494548798, -0.0979524776339531, -1.1121710538864136, -1.5656077861785889, -0.3350720703601837, -0.7913984656333923, -1.2096436023712158, 0.1804914027452469, 0.5448322296142578, -1.0952625274658203, -0.05099176615476608, 0.3612939119338989, 0.09075156599283218, 0.5676654577255249, -0.9693727493286133, 0.8944699764251709, 0.31634530425071716, -0.01958557218313217, -0.33580467104911804, 0.22791245579719543, 0.5420147180557251, -0.5581150650978088, 0.2250613421201706, -0.7148103713989258, 0.019397273659706116, -0.30794140696525574, -1.1967741250991821, 0.10379359126091003, -0.023403430357575417, 0.8066043853759766, 0.02412516064941883, 0.3062313199043274, 0.3508385121822357, 1.043045997619629, -1.2133277654647827, -0.18506652116775513, 0.09223192185163498, 1.042213797569275, 0.6309945583343506, 0.131683349609375, 0.4154079556465149, 0.40083053708076477, 0.40487566590309143, -0.15807922184467316, -0.10424208641052246, -0.6477378010749817, -0.26988711953163147, 0.7929648756980896, 1.8278436660766602, 0.45601513981819153, -0.2615276277065277, -0.9679988026618958, 0.4887053668498993, -0.9469528198242188, -0.05493556335568428, -0.08271051943302155, 0.8681401610374451, 0.7323404550552368, -0.5038731098175049, -0.6130406260490417, 0.19825716316699982, 0.3097565472126007, 0.06102021038532257, -0.14882542192935944, -1.1604048013687134, 0.011012546718120575, 0.6062787175178528, 0.033901702612638474, 0.5358393788337708, -0.41070517897605896, 0.05700766667723656, 14.757728576660156, 0.8454368710517883, -0.1095496118068695, 0.45199155807495117, 1.3035227060317993, 0.4594034254550934, -0.3355005979537964, -0.4569514989852905, -1.152916431427002, -0.31998905539512634, 1.3572239875793457, 0.20872418582439423, 0.41336384415626526, -0.0795295462012291, 0.09781388193368912, 0.24517011642456055, -0.3987278640270233, 0.5222914814949036, 0.4409753978252411, -1.290303111076355, 0.5458212494850159, -0.0021852459758520126, 1.1311320066452026, 0.20407825708389282, 0.9398839473724365, 0.9276368021965027, 0.4533018469810486, -0.6822817325592041, 0.6324499845504761, 0.2193693369626999, 1.1925148963928223, -0.08405670523643494, 0.6609379649162292, 0.2844368517398834, -0.18701250851154327, -0.18656684458255768, -0.4031781554222107, -1.4968079328536987, -0.0796661302447319, -0.04375692829489708, -0.9662214517593384, -0.3444998562335968, -0.4612783193588257, 0.4111005663871765, -0.2765576243400574, 0.6999146342277527, -0.7332522869110107, 0.9465015530586243, 0.1598924994468689, -0.1390693485736847, 0.3054318130016327, 0.3613518476486206, -0.09437041729688644, -0.17040954530239105, 0.14933378994464874, 0.13046406209468842, 0.4825853705406189, 0.3450046181678772, -1.105496883392334, 0.23312389850616455, 0.5212932825088501, 0.024157095700502396, -0.26105859875679016, 0.9740207195281982, 0.5734301209449768, 0.09718061238527298, -0.11328689754009247, 0.22093120217323303, 1.0522907972335815, 0.24681629240512848, 0.14180749654769897, -0.3114979863166809, 0.1470068395137787, -0.16259077191352844, -0.33088821172714233, 0.6320122480392456, -0.9511701464653015, -0.49118906259536743, -0.5760103464126587, -0.3184627890586853, 0.5596438646316528, -1.1890075206756592, -0.5834335684776306, 0.5820341110229492, -0.7611474394798279, -0.5584976673126221, -0.11996807157993317, -0.7921871542930603, -0.258383184671402, 1.086353063583374, -1.4116454124450684, -0.17491325736045837, 0.020873500034213066, -0.6325359344482422, -0.28118428587913513, -0.049548182636499405, 1.536992073059082, -0.09324721246957779, -0.15462695062160492, 0.3734658658504486, 0.09969597309827805, -0.13614611327648163, 0.6833968162536621, -1.1678955554962158, 0.2510438859462738, 0.30474337935447693, -0.28226253390312195, 0.06026078388094902, -0.1363680511713028, 0.4247114062309265, -0.28844910860061646, -0.1821146160364151, 0.9660524129867554, -0.946172297000885, -0.38338321447372437, -0.595113217830658, -0.8900349736213684, -0.1477472484111786, 0.3174666166305542, -0.09577377140522003, 0.4406895935535431, 0.028124231845140457, -0.4142557680606842, 0.12861602008342743, -0.7958614230155945, -0.07947768270969391, -0.18787331879138947, -0.6354194283485413, -0.228920117020607, 0.10663142800331116, 0.3999324440956116, -0.9942807555198669, -0.5218533277511597, -0.19448168575763702, -0.31099557876586914, 0.12791526317596436, 0.6761144399642944, -0.5606688261032104, 1.219235897064209, 0.7188469171524048, 0.061273470520973206, -0.8158072233200073, -0.16581390798091888, -0.9384921789169312, -0.17437966167926788, 0.14111033082008362, 0.8620361685752869, -0.002212730934843421, 0.5231960415840149, 1.068635106086731, 0.4213757812976837, -0.6080589294433594, -0.16565407812595367, 0.5258776545524597, 0.28934526443481445, -0.06637638807296753, 0.3883662521839142, -0.06927470862865448, -0.2885338366031647, 0.2860109210014343, 0.5456312298774719, 0.32380419969558716, -0.4416353404521942, -0.21548239886760712, 0.5368318557739258, -0.38957375288009644, -0.2291060835123062, -0.7280892133712769, -0.2830415368080139, -1.5759409666061401, -0.1943686157464981, -1.1263439655303955, 0.13977928459644318, -0.8405007719993591, -0.1486988216638565, -0.22488000988960266, -0.39772260189056396, 0.0889788568019867, -0.1775737702846527, 0.4489022493362427, -0.6327661871910095, -0.20214369893074036, -0.8873074054718018, 0.7341263294219971, 1.0660483837127686, -0.734915554523468, 0.018969839438796043, 0.02974841743707657, -0.097168929874897, 0.17090317606925964, 0.39649641513824463, -0.1601664423942566, -0.42627373337745667, -1.171166181564331, 0.38190364837646484, 0.1773470789194107, -0.12404847145080566, -0.4084455668926239, 0.5463653802871704, 0.2491561323404312, 0.08842453360557556, 0.1822783201932907, -0.07203946262598038, -0.006730373483151197, -1.0772408246994019, 0.10451287031173706, -1.335739254951477, 0.21782186627388, -0.07797350734472275, -0.7600685358047485, -0.4037405252456665, 0.28411775827407837, -0.236334890127182, -0.8456697463989258, -0.49556711316108704, 0.32847994565963745, -0.3014981150627136, -0.10534299910068512, -0.6356026530265808, 0.08121350407600403, -0.8035084009170532, -0.5315619707107544, 0.07352463155984879, 0.6801543235778809, -0.3292437791824341, 0.6962083578109741, 0.07789090275764465, -1.262314796447754, -0.2294456511735916, 0.3726769685745239, -0.1270732283592224, 0.04761797934770584, 0.33119991421699524, 0.3514763116836548, -0.7398198843002319, 0.6628233194351196, 0.33546754717826843, 0.25131461024284363, -0.9375300407409668, -0.6694403886795044, 0.5643373727798462, -1.0822467803955078, 0.37703683972358704, 1.4012093544006348, -0.6360852718353271, -1.7239818572998047, 0.10987582057714462, -0.8325715661048889, -0.778292179107666, -0.44905415177345276, 0.8811783194541931, 0.06216931715607643, 0.5893077850341797, -0.009727285243570805, -0.08706570416688919, -0.32502418756484985, -0.04302774742245674, -0.44877326488494873, 0.4670557379722595, -0.3100091218948364, -0.5208136439323425, 0.5644761323928833, 0.6775103807449341, -0.6577515006065369, -0.524146556854248, -0.41017472743988037, -0.3073550760746002, -0.0978456661105156, 0.11371834576129913, -1.005883812904358, -0.267182856798172, 1.111090064048767, 0.4140075147151947, 0.048079006373882294, 0.23564180731773376, -0.5696202516555786, 0.26309818029403687, 0.7231738567352295, 0.07406839728355408, -0.429110050201416, -0.2690957188606262, 1.3313374519348145, 0.9004955887794495, -1.1227298974990845, -0.013335657306015491, -0.006383733358234167, -0.4001138210296631, 1.1054432392120361, 0.6859214901924133, 0.1680225431919098, 0.17406059801578522, -0.5936219692230225, 0.4344503879547119, 0.298263281583786, -0.9354982972145081, 0.3796491026878357, 1.0291476249694824, 0.536266565322876, 1.4691357612609863, 0.809770405292511, -0.2792964279651642, 1.052456021308899, -0.5024115443229675, 0.3266507089138031, 1.188817024230957, 0.2976837158203125, -0.1960667073726654, -0.19619010388851166, -0.3892744779586792, 0.681817889213562, -0.7360634803771973, -0.09125819802284241, 0.021693959832191467, -0.12461664527654648, -0.012477836571633816, 0.46653473377227783, 0.4342666268348694, 0.2816590368747711, 0.35448428988456726, 0.39269617199897766, 0.3089621663093567, -0.7522470951080322, -0.556412935256958, -0.5419749021530151, -0.8902626633644104, 0.008213508874177933, -0.01511414721608162, -0.15129338204860687, -0.3796714246273041, -0.3284832239151001, 0.3499460220336914, 0.102525994181633, 0.13515622913837433, 1.1274528503417969, 0.3555135428905487, 0.4900844991207123, -0.31841617822647095, -0.20485448837280273, -0.8493375778198242, -1.2798694372177124, 0.035989049822092056, -0.3690201938152313, -0.15738555788993835, -0.1469118595123291, 0.22944825887680054, -0.176007941365242]}, "authors": [{"authorId": "2089565497", "name": "G. Katuka"}, {"authorId": "2299155239", "name": "Alexander Gain"}, {"authorId": "2299278113", "name": "Yen-Yun Yu"}], "references": [{"paperId": "32ac52069e562d4f900afee70bdca63f53461481", "title": "QLoRA: Efficient Finetuning of Quantized LLMs"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "53535d38fe259a3aa7c911edd8048d764e09e8e1", "title": "The case for 4-bit precision: k-bit Inference Scaling Laws"}, {"paperId": "2c994fadbb84fb960d8306ee138dbeef41a5b323", "title": "SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models"}, {"paperId": "650dfe97ec71e11bad2bfac0a2e8f83df4099bc9", "title": "Automatic Short Math Answer Grading via In-context Meta-learning"}, {"paperId": "7cdaa08890895e1ad92afb5fad429690ad7b1dac", "title": "Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "968e6bb8623b1734bb4b7a60fd03d72d6323f1c5", "title": "Sentence encoding for Dialogue Act classification"}, {"paperId": "f45261b7b53043c316f45f613cb735907b93fb5a", "title": "Raise a Child in Large Language Model: Towards Effective and Generalizable Fine-tuning"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "b0b0dddb8310e01b9407a21674c2d33a23a6e967", "title": "Byte Pair Encoding is Suboptimal for Language Model Pretraining"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "001030b73d105a2acd6a10990fe3e398751d610a", "title": "Automatic Short Answer Grading and Feedback Using Text Mining Methods"}, {"paperId": "e7fd6848cb29ca221a7e17d823e06fb566f1f135", "title": "Mixed Precision Training"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "6404b29ac83a69670f1dd4b887e026bfbd844d83", "title": "The Eras and Trends of Automatic Short Answer Grading"}, {"paperId": "b4829f2e7968be42bead06b1710abee6f5a0afc2", "title": "A Comprehensive Study on Post-Training Quantization for Large Language Models"}, {"paperId": "910fb3b376f5e9cc3087a62eedf4895aa47f7688", "title": "Your Answer is Incorrect... Would you like to know why? Introducing a Bilingual Short Answer Feedback Dataset"}, {"paperId": "b3fb00b0a611190a94c355279be749af93a86d3a", "title": "Toward Better Grade Prediction via A2GP - An Academic Achievement Inspired Predictive Model"}, {"paperId": "cc6095b6272c162544f014a7dea1e9ba2ae95bdb", "title": "Automated Feedback Generation for Student Project Reports: A Data-Driven Approach"}, {"paperId": "79c79938f62e97288010eb2ac2692f3f843681ee", "title": "Improving Automated Scoring of Student Open Responses in Mathematics"}, {"paperId": "bba5b146d2f5442b65c3ff17c47bac6e7cdda492", "title": "Integrating Deep Learning into An Automated Feedback Generation System for Automated Essay Scoring"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "A method for stochastic optimization"}, {"paperId": "1e9441bbad598e181896349757b82af42b6a6902", "title": "Byte Pair Encoding: a Text Compression Scheme That Accelerates Pattern Matching"}, {"paperId": null, "title": "Falcon-40b: an open large language model with state-of-the-art performance"}]}