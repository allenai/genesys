{"paperId": "44b7adbd196e69c8771734aa8c9af5fd69c04370", "title": "BTLM-3B-8K: 7B Parameter Performance in a 3B Parameter Model", "abstract": "We introduce the Bittensor Language Model, called\"BTLM-3B-8K\", a new state-of-the-art 3 billion parameter open-source language model. BTLM-3B-8K was trained on 627B tokens from the SlimPajama dataset with a mixture of 2,048 and 8,192 context lengths. BTLM-3B-8K outperforms all existing 3B parameter models by 2-5.5% across downstream tasks. BTLM-3B-8K is even competitive with some 7B parameter models. Additionally, BTLM-3B-8K provides excellent long context performance, outperforming MPT-7B-8K and XGen-7B-8K on tasks up to 8,192 context length. We trained the model on a cleaned and deduplicated SlimPajama dataset; aggressively tuned the \\textmu P hyperparameters and schedule; used ALiBi position embeddings; and adopted the SwiGLU nonlinearity. On Hugging Face, the most popular models have 7B parameters, indicating that users prefer the quality-size ratio of 7B models. Compacting the 7B parameter model to one with 3B parameters, with little performance impact, is an important milestone. BTLM-3B-8K needs only 3GB of memory with 4-bit precision and takes 2.5x less inference compute than 7B models, helping to open up access to a powerful language model on mobile and edge devices. BTLM-3B-8K is available under an Apache 2.0 license on Hugging Face: https://huggingface.co/cerebras/btlm-3b-8k-base.", "venue": "arXiv.org", "year": 2023, "citationCount": 10, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2309.11568", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "The Bittensor Language Model is introduced, a new state-of-the-art 3 billion parameter open-source language model that needs only 3GB of memory with 4-bit precision and takes 2.5x less inference compute than 7B models, helping to open up access to a powerful language model on mobile and edge devices."}, "embedding": {"model": "specter_v2", "vector": [-0.05162099003791809, -0.00283464090898633, -0.6583265066146851, -0.19957658648490906, -0.254499614238739, -0.19215889275074005, 0.6112288236618042, -0.6156119108200073, -0.45458340644836426, -0.29349035024642944, 0.524966299533844, -0.3049503266811371, 0.5257425904273987, 0.3232281804084778, -0.22914615273475647, -0.06891931593418121, -1.0238507986068726, 0.3541511595249176, -0.3661521077156067, -0.2707257568836212, -0.10846322029829025, -0.7140529751777649, -0.579915463924408, 0.2729463577270508, -0.04195341095328331, 0.6195533871650696, 0.002353895688429475, 1.0893986225128174, -0.7547587156295776, -0.2668721377849579, 0.15855135023593903, -0.23560844361782074, 0.348390132188797, 0.04712338000535965, -0.42762839794158936, -0.16701023280620575, 0.4374145269393921, -0.576677680015564, 0.06208609789609909, 0.30765554308891296, 0.045209914445877075, 0.37365859746932983, 0.6342266201972961, -0.6160081624984741, -0.022435780614614487, 0.9678897261619568, 0.5408169627189636, 0.7968588471412659, -0.4059678316116333, -0.20353546738624573, 1.289622187614441, -1.426683783531189, 0.06602834165096283, 1.568058729171753, 0.4166469871997833, 0.36275410652160645, -0.3705216646194458, -0.5578120350837708, 0.6839199662208557, 0.18280930817127228, -0.8999708890914917, -0.25412556529045105, 0.027366871014237404, -0.002579766558483243, 2.1651933193206787, -0.345840185880661, 0.6062871217727661, 1.1056040525436401, -0.25727379322052, 1.3507765531539917, -0.24050498008728027, -1.0254640579223633, -0.5238497257232666, 0.08297191560268402, 0.4483940303325653, 0.4600980877876282, -0.3711272180080414, 0.27301251888275146, -1.130279541015625, -0.14121006429195404, 0.32275256514549255, -0.16407567262649536, 0.33099883794784546, 0.2232375591993332, -0.7745268940925598, 0.7391487956047058, -0.020168650895357132, 0.7724704146385193, -0.015002571977674961, 0.9575738310813904, 0.5823791027069092, 0.18512308597564697, 0.3297053873538971, -0.16270126402378082, -0.4145696461200714, 0.07968850433826447, -0.9256879091262817, 0.25625860691070557, 0.3542371392250061, 0.7639874815940857, 0.04074354097247124, 0.17447417974472046, -0.6435644626617432, 0.14386585354804993, 1.6485103368759155, 0.4046647250652313, 0.5029898285865784, -0.5561531186103821, 0.23277965188026428, -0.7686874866485596, 0.16858208179473877, -0.5759353041648865, -0.12639254331588745, 0.12042839080095291, -0.39438384771347046, -1.4614248275756836, -0.21072173118591309, 0.061804890632629395, -0.8112099766731262, 0.5369621515274048, 0.012877706438302994, 0.3295738697052002, 0.0023213992826640606, 0.32101568579673767, 0.7889388203620911, 1.1622214317321777, 0.2434721142053604, 0.3528164327144623, 0.7470848560333252, -1.0941946506500244, -0.6805382966995239, -0.7543066740036011, 0.9135918021202087, -0.3739076554775238, 0.6350497007369995, -0.060684796422719955, -0.8493324518203735, -0.7665442824363708, -1.0763235092163086, -0.047412071377038956, -0.9993683695793152, 0.3519781827926636, 0.8992918133735657, 0.6306283473968506, -0.7161476612091064, 0.4089716970920563, -0.21775396168231964, -0.20936115086078644, -0.03560405224561691, -0.031933754682540894, 0.22808891534805298, -0.09395137429237366, -1.5485823154449463, 0.5299787521362305, 0.6195301413536072, -0.3261454701423645, 0.07330399751663208, -0.7107980251312256, -0.8693117499351501, -0.22594290971755981, 0.3190895915031433, -0.5338564515113831, 1.1932423114776611, 0.0016399178421124816, -1.7498103380203247, 0.706842303276062, -0.3075040280818939, 0.16019777953624725, 0.08695214986801147, -0.4532147943973541, -0.6386325359344482, -0.4375873804092407, -0.5982423424720764, 0.7097593545913696, 0.4274429976940155, 0.2960403561592102, 0.19324879348278046, 0.3354564607143402, -0.553475558757782, 0.24032826721668243, -0.27957916259765625, 0.9352526068687439, -0.5212799906730652, -0.2380393147468567, 0.1401791125535965, 0.5383963584899902, 0.25175443291664124, -0.03766883909702301, -0.6963087320327759, -1.013323187828064, 0.7620751261711121, 0.15594319999217987, 1.097978115081787, -0.9993191361427307, -0.6888190507888794, 0.04950326681137085, -0.6442895531654358, 0.11002877354621887, -0.7551742196083069, 0.7077662348747253, -0.21362222731113434, 0.8221323490142822, 0.03648702800273895, -1.3620643615722656, 0.4115627706050873, -0.06646180152893066, -0.5919069647789001, -0.1826394498348236, 0.026280058547854424, 0.8691189289093018, -0.5958536863327026, -0.021773548796772957, 0.17925728857517242, 0.5720810294151306, -1.2048219442367554, 0.8962507247924805, -0.5531007051467896, 0.05268155410885811, 0.05549991875886917, -0.1049155667424202, -0.013304410502314568, -0.17740461230278015, 0.057076308876276016, -0.22500382363796234, 0.0869065672159195, 0.4669596552848816, -0.8523122072219849, 1.6165531873703003, -0.43462350964546204, 0.44571518898010254, 0.005035345442593098, -0.3975882828235626, 0.01618495211005211, 0.36720430850982666, -0.3481963872909546, -0.06737184524536133, 0.09271720796823502, 0.6352542638778687, -0.4449593126773834, 0.3395271897315979, 0.8407143354415894, 1.101992130279541, -0.41203394532203674, 0.08250408619642258, 0.4289112985134125, -0.4299229383468628, 0.3627817630767822, 0.4906778037548065, 0.023510614410042763, 0.3711162805557251, 0.4166766107082367, -0.35139861702919006, 0.14746502041816711, -1.1970354318618774, -0.2203248292207718, 0.44416606426239014, 0.5907274484634399, 0.7012449502944946, 0.3795005679130554, -0.7751595973968506, -0.25787603855133057, -0.05395308509469032, 0.4852460026741028, 1.4116469621658325, -0.22266116738319397, -0.6172553896903992, -0.5521209239959717, -0.2754773199558258, 0.07822578400373459, 0.0014984486624598503, -0.3070875108242035, 0.04184792935848236, -0.7146055698394775, -0.9712060689926147, 0.897975504398346, -0.216949462890625, 0.9048422574996948, -0.8325957655906677, -0.24058179557323456, -0.4048977792263031, -0.018006835132837296, -0.7333357334136963, -0.8861390948295593, 0.19380241632461548, -0.5473653674125671, 0.2512936592102051, 0.0021693971939384937, 0.20110970735549927, -0.2661912143230438, -0.7394574880599976, 0.8951371908187866, -0.31905362010002136, -0.40773552656173706, 0.16991321742534637, 0.3136063516139984, -0.46950602531433105, -0.631138265132904, 0.1766328066587448, 0.18064150214195251, -0.2661571502685547, 0.2575739920139313, 0.6112453937530518, -0.22741645574569702, 0.0468156635761261, -0.6203776597976685, 0.1266103833913803, -0.13737428188323975, 0.20086051523685455, 0.5378693342208862, -0.4534240961074829, 0.01019259449094534, -0.9496419429779053, 0.6044520139694214, 0.0439394935965538, -0.18362776935100555, 0.08832161128520966, -0.5423949956893921, -0.5861995816230774, -0.11835010349750519, -0.7752684354782104, -0.20076274871826172, -0.9957056045532227, 0.19095386564731598, -0.028057165443897247, -0.08309777081012726, 0.15456043183803558, 0.09568871557712555, 0.5575721263885498, 0.20719969272613525, 0.41602617502212524, 0.21974222362041473, -0.37316280603408813, 1.0158747434616089, -0.4424334168434143, 0.07481870800256729, 0.04441722482442856, -0.18720659613609314, -0.07679316401481628, -0.3971727192401886, -1.1037647724151611, -0.30173057317733765, -0.7605182528495789, -0.31335851550102234, -0.17644566297531128, -0.08408165723085403, -0.3203890323638916, -0.5424525737762451, 0.7083942890167236, -1.2217997312545776, -0.37576666474342346, 0.4849471151828766, -0.27316299080848694, -0.35868003964424133, -0.8127743005752563, -1.1468462944030762, -0.3821493983268738, -0.6273675560951233, -0.9071117043495178, 0.5997618436813354, -0.0015725058037787676, -0.4488246440887451, -0.5946205854415894, -0.047722794115543365, -0.410214364528656, 1.0362628698349, -0.617289662361145, 0.6434467434883118, -0.0729256346821785, -0.06811925768852234, -0.28390997648239136, 0.4136870205402374, 0.8207907676696777, -0.32144656777381897, 0.7459214925765991, -0.46436673402786255, 0.4968225061893463, -0.6282092928886414, -0.21413911879062653, 0.5408637523651123, 0.28062111139297485, 0.5270240306854248, -0.3343545198440552, -0.50893634557724, 0.652120053768158, 0.8375480771064758, -0.9096065759658813, 0.10998473316431046, -0.09847447276115417, 0.760713517665863, -0.07577922940254211, -0.3430437743663788, 0.673762321472168, 0.187691792845726, 0.46537306904792786, -0.0663066953420639, -0.03370045870542526, -0.08769012987613678, -0.6757734417915344, 0.6952126622200012, 1.3790836334228516, 0.6503196954727173, -0.21558144688606262, -0.9021196365356445, 0.657730758190155, -1.040937900543213, -0.45504316687583923, 0.6592567563056946, 0.9329859614372253, 0.9271347522735596, -0.46572014689445496, 0.0451548770070076, -0.20316316187381744, 0.2222694754600525, 0.4856824576854706, -0.23293466866016388, -0.9425808787345886, -0.23444031178951263, -0.024197587743401527, -0.18005579710006714, 0.668685257434845, -0.4112749993801117, 0.9135260581970215, 15.031105995178223, 0.9426213502883911, -0.2516591548919678, 0.21611621975898743, 1.0511263608932495, -0.23320958018302917, -0.4109041392803192, -0.12126868218183517, -1.6882387399673462, 0.43742215633392334, 1.4404041767120361, 0.47838854789733887, 0.6061162352561951, -0.11965023726224899, 0.1314007192850113, -0.12184694409370422, -0.6702027320861816, 0.6639904379844666, 0.6984487175941467, -0.9634842872619629, 0.40191787481307983, 0.04741692170500755, 0.14734114706516266, 0.47520849108695984, 0.9285221695899963, 0.760344922542572, 0.13280503451824188, -0.5782004594802856, 0.5016355514526367, 0.26954030990600586, 0.918671727180481, -0.08716943860054016, 0.16992861032485962, 0.5148953795433044, -0.344868928194046, 0.22523994743824005, -0.5054001212120056, -1.1013540029525757, 0.3200284242630005, 0.3981555104255676, -0.7290493249893188, -0.775909423828125, -0.008874318562448025, 0.5314126014709473, 0.3310262858867645, 0.319556325674057, -0.005394879262894392, 0.9890112280845642, -0.6457916498184204, -0.5132463574409485, 0.4305574893951416, 0.17411112785339355, 0.7758334279060364, 0.45019373297691345, 0.148479163646698, 0.004897255450487137, -0.01896561123430729, 0.47622188925743103, -0.16068610548973083, 0.24372504651546478, -0.31943216919898987, -0.4881993234157562, 0.1270778775215149, 0.8648308515548706, 0.5349091291427612, 0.14518265426158905, -0.1992388218641281, 0.39359015226364136, 0.39579859375953674, 0.3912815749645233, -0.387358158826828, 0.08785485476255417, 0.6035946011543274, -0.6945088505744934, 0.17817384004592896, 0.029449619352817535, 0.03957459703087807, -0.5485115051269531, -0.5878483057022095, -0.35438022017478943, 0.5056086182594299, -0.6159471273422241, -0.6989210844039917, 0.5415964722633362, 0.009768901392817497, -0.02922687493264675, -0.04601946845650673, -1.0382080078125, -0.26483845710754395, 0.6451529860496521, -1.5009734630584717, -0.697526752948761, 0.6595417261123657, -0.2598173916339874, -0.386694073677063, 0.19642946124076843, 1.4383964538574219, -0.04010694473981857, -0.5617536306381226, 0.2291404753923416, 0.4489904046058655, -0.18305625021457672, 0.09570451825857162, -0.8480307459831238, 0.9255303144454956, -0.07230749726295471, 0.08191640675067902, 0.4850093722343445, -0.2351801097393036, 0.3197527229785919, -0.8247488737106323, 0.2630252540111542, 0.689820408821106, -1.0571565628051758, -0.3392930030822754, -0.9954748749732971, -0.3680589497089386, 0.2471316158771515, 0.559655487537384, -0.26832062005996704, 0.5632843375205994, 0.5419830679893494, -0.8557059168815613, -0.38632795214653015, -0.5586537718772888, 0.2692534625530243, 0.585365891456604, -0.4317374527454376, 0.06071000546216965, -0.05072607100009918, 0.35134217143058777, -1.0019201040267944, -0.4202411472797394, -0.15159070491790771, 0.2837267816066742, -0.2329726368188858, 1.1252774000167847, -0.3003101348876953, 0.5291763544082642, 1.0870091915130615, -0.44156739115715027, -1.0176572799682617, 0.44257652759552, -1.1639620065689087, -0.17047205567359924, 0.03381772339344025, 0.9030667543411255, -0.49682819843292236, -0.07919240742921829, 0.5652223229408264, 0.4210328459739685, -0.8282886147499084, -0.9669843912124634, -0.5965597629547119, 0.40711861848831177, -0.649787187576294, 0.548173189163208, -0.26118817925453186, 0.2631831467151642, 0.12269757688045502, 0.26087021827697754, -0.02760898694396019, -0.4941384494304657, -0.7640894055366516, 0.5108529329299927, 0.16938431560993195, -0.3139924705028534, -0.7932730317115784, -0.5191453695297241, -1.6568284034729004, -0.10831321775913239, -1.1010760068893433, -0.03938966989517212, -0.22393761575222015, -0.1453215777873993, -0.0011019621742889285, -0.37357616424560547, 0.21545244753360748, 0.27547115087509155, -0.02555452659726143, -0.5382842421531677, -0.7852952480316162, -0.37698888778686523, 0.8686618804931641, 0.7196950912475586, -0.66948401927948, 0.1663135290145874, -0.058725565671920776, 0.288316935300827, 0.19697004556655884, 0.489277184009552, 0.07788801193237305, -0.6025201678276062, -1.484142541885376, 0.5599068403244019, -0.45676469802856445, -0.006235223729163408, -0.22192654013633728, 0.20766377449035645, 0.37154555320739746, -0.11415927112102509, -0.15055795013904572, 0.6580907702445984, -0.6917620301246643, -0.6123222708702087, -0.040598951280117035, -0.4395318329334259, 0.044271934777498245, 0.4101445972919464, -0.4788704514503479, 0.048029739409685135, 0.5963073968887329, -0.35927268862724304, -0.7543066740036011, -0.6956813335418701, 0.3110736310482025, -0.6138034462928772, -0.013393957167863846, -0.4657244086265564, -0.3117796778678894, -1.0172547101974487, -0.36800646781921387, 0.08403746038675308, 0.109764464199543, -0.44892120361328125, 0.9610356092453003, 0.2783772349357605, -1.1402546167373657, -0.12806017696857452, 0.5835917592048645, -0.0029344584327191114, 0.11535271257162094, 0.3678436279296875, 0.25211262702941895, -0.424757719039917, 0.4640469551086426, 0.5502786040306091, -0.13159354031085968, -0.9080259203910828, -0.28493016958236694, 0.7499105334281921, -0.08053013682365417, -0.33548668026924133, 1.386228084564209, -0.7566426396369934, -1.0851439237594604, 0.43400779366493225, -1.1768730878829956, -0.12545771896839142, -0.42909303307533264, 0.5257436037063599, 0.2637097239494324, 0.06816620379686356, -0.13278141617774963, -0.4624132812023163, 0.22679249942302704, -0.23923437297344208, -0.7313548922538757, 0.1729738712310791, -0.1082957535982132, -0.3028841018676758, 0.8822858929634094, 1.2577855587005615, -0.7007428407669067, -0.4874611794948578, -0.7289391756057739, -0.38973549008369446, 0.1463717371225357, 0.3054063320159912, -0.8002573847770691, -0.19884103536605835, 0.861515462398529, 0.21368710696697235, 0.21148625016212463, -0.1926170438528061, -0.2876250743865967, 0.3645886182785034, 1.0175831317901611, 0.00553304934874177, -0.6835265159606934, -0.43928349018096924, 1.6297589540481567, 1.270504355430603, -0.9927799105644226, 0.18974603712558746, -0.2779361605644226, -0.45963871479034424, 0.6862538456916809, 0.17377302050590515, 0.192485973238945, 1.293763279914856, -0.36504650115966797, 0.3506677746772766, 0.31379061937332153, -0.7949633598327637, 0.18192033469676971, 0.8596530556678772, 0.3718544542789459, 0.6251108050346375, 0.649880051612854, -0.06797731667757034, 0.843289315700531, -0.06773208826780319, -0.650348961353302, 0.32099923491477966, 0.23232440650463104, 0.10420382767915726, -0.25112661719322205, 0.18589897453784943, 0.4109618365764618, -0.507646381855011, -0.9479054808616638, -0.2714531719684601, 0.6394549012184143, 0.026185577735304832, 0.7094530463218689, 0.871795117855072, 0.38951417803764343, 0.1189429759979248, 0.7243854999542236, 0.5545154809951782, -0.49056562781333923, -0.1931234449148178, -0.06828773766756058, -0.47202765941619873, -0.16884201765060425, -0.049794651567935944, -0.5494901537895203, -0.1975155621767044, -0.3877098262310028, 0.031079620122909546, -0.025466496124863625, 0.5578422546386719, 1.1262948513031006, 0.7896550297737122, -0.10275611281394958, -0.3234312832355499, -0.6384038925170898, -0.45855626463890076, -1.2050338983535767, -0.26889169216156006, -0.566487729549408, -0.3211711347103119, 0.054530009627342224, -0.4000701308250427, -0.45143744349479675]}, "authors": [{"authorId": "1564139903", "name": "Nolan Dey"}, {"authorId": "2243228174", "name": "Daria Soboleva"}, {"authorId": "2243335766", "name": "Faisal Al-Khateeb"}, {"authorId": "2243383177", "name": "Bowen Yang"}, {"authorId": "2213728244", "name": "Ribhu Pathria"}, {"authorId": "2213732240", "name": "Hemant Khachane"}, {"authorId": "2243337041", "name": "Shaheer Muhammad"}, {"authorId": "2243372487", "name": "Zhiming Chen"}, {"authorId": "2243336038", "name": "Robert Myers"}, {"authorId": "2243336766", "name": "Jacob Robert Steeves"}, {"authorId": "2243228182", "name": "Natalia Vassilieva"}, {"authorId": "2243336770", "name": "Marvin Tom"}, {"authorId": "3130228", "name": "Joel Hestness"}], "references": [{"paperId": "2dfb9171e180dcb0af23d305e024d43d311708ab", "title": "Giraffe: Adventures in Expanding Context Lengths in LLMs"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "7a1e71cb1310c4a873e7a4e54d1a6dab0553adce", "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"}, {"paperId": "ece77610adfb0fb162dd22ef694f2777393c319a", "title": "Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "9575afb5702bc33d7df14c48feeee5901ea00369", "title": "A Length-Extrapolatable Transformer"}, {"paperId": "bb15f3727f827a3cb88b5d3ca48415c09b40a88f", "title": "What Language Model to Train if You Have One Million GPU Hours?"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "382ba0c4452aab6ecdaf8a62d567bb3c4684e4f0", "title": "ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection"}, {"paperId": "77d956cdab4508d569ae5741549b78e715fd0749", "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "9dc624d7258d1a56117ca720aea953ce46b66b21", "title": "Efficient Attentions for Long Document Summarization"}, {"paperId": "aa28873534c24e4a8c5deb7bff723cd5fc69a6f0", "title": "QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "645bd6eadc247989abc5e0b0aa0be79ec8b11ea6", "title": "CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models"}, {"paperId": "399e7d8129c60818ee208f236c8dda17e876d21f", "title": "RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "5019dbe8d1da5f128f4f373d6849095cf18fd519", "title": "The Woman Worked as a Babysitter: On Biases in Language Generation"}, {"paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0", "title": "Natural Questions: A Benchmark for Question Answering Research"}, {"paperId": "a2ce1fb96c0b78bee18bb2cb2c3d55dc48d54cbd", "title": "Measuring Bias in Contextualized Word Representations"}, {"paperId": "9770fff7379a7ab9006b48939462354dda9a2053", "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "eefa0df7c5678fa6004f8b48dbbc1c2696702fee", "title": "An Empirical Model of Large-Batch Training"}, {"paperId": "7365f887c938ca21a6adbef08b5a520ebbd4638f", "title": "Model Cards for Model Reporting"}, {"paperId": "1536e8958697c5364f68b2e2448905dbbeb3a0ca", "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering"}, {"paperId": "9967cb4fd949039c6f04dd9f2f4c3331dbebe6f7", "title": "Gender Bias in Coreference Resolution"}, {"paperId": "88bb0a28bb58d847183ec505dda89b63771bb495", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"}, {"paperId": "636a79420d838eabe4af7fb25d6437de45ab64e8", "title": "RACE: Large-scale ReAding Comprehension Dataset From Examinations"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "7b36c5602930abf08efd2867f92cdb48a1be757a", "title": "Together"}, {"paperId": null, "title": "Falcon-40B: an open large language model with state-of-the-art performance, 2023"}, {"paperId": null, "title": "Openllama: An open reproduction of llama"}, {"paperId": null, "title": "StableLM Alpha v2 Models"}, {"paperId": null, "title": "Redpajama Models V1"}, {"paperId": null, "title": "RedPajama: An Open Source Recipe to Reproduce LLaMA training dataset"}, {"paperId": null, "title": "Introducing mpt-7b: A new standard for open-source, commercially usable llms"}, {"paperId": null, "title": "How Long Can Open-Source LLMs Truly Promise on Context Length?"}, {"paperId": null, "title": "SlimPajama: A 627B token cleaned and deduplicated version of RedPajama"}, {"paperId": "bb0656031cb17adf6bac5fd0fe8d53dd9c291508", "title": "An empirical analysis of compute-optimal large language model training"}, {"paperId": "4b2137280915ccc0e06e97b604778b05876a34ad", "title": "Evaluating Large Language Models"}, {"paperId": "a6b6eedb0559cb44bd3fcab64151529019bae42a", "title": "Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer"}, {"paperId": null, "title": "A framework for few-shot language model evaluation"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28", "title": "An Adversarial Winograd Schema Challenge at Scale"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "SocialIQA: Commonsense Reasoning about Social Interactions, 2019"}, {"paperId": null, "title": "Announcing MPT-7B-8K: 8K Context Length for Document Understanding"}, {"paperId": null, "title": "Long Sequence Modeling with XGen: A 7B LLM Trained on 8K Input Sequence Length"}, {"paperId": null, "title": "TriviaQA is a realistic text-based question answering dataset based on documents collected from Wikipedia and the web. Question: Which US Olympic swimmer is nicknamed the \u2018Baltimore Bullet\u2019? Answers"}, {"paperId": null, "title": "GovReports is a dataset for summarization of longer documents and summaries written by government research agencies. The example format is similar to QMSum"}, {"paperId": null, "title": "MMLU is a dataset to test the model\u2019s understanding the world and problem-solving skills"}, {"paperId": null, "title": "ToxiGen is a dataset that includes sentences mentioning 13 minority groups, some of which contain implicit toxicity while others are benign."}, {"paperId": null, "title": "BTLM-3B-8K: 7B Parameter Performance in a 3B Parameter Model"}, {"paperId": null, "title": "models with sentences containing two subjects and a pronoun that requires models to correctly guess which subject the pronoun refers to"}, {"paperId": null, "title": "NaturalQuestions contains short questions from Google search engine users"}, {"paperId": null, "title": "LongEval-Topics tests models\u2019 ability to perform coarse-grained conversation with multiple topics"}, {"paperId": null, "title": "GPTQ: Accurate Post-training Compression for Generative Pretrained Transformers"}, {"paperId": null, "title": "\u00a92023 Cerebras Systems Inc. All Rights Reserved"}]}