{"paperId": "73b222c2808a95878c8a3aa762b9ba1d4dd9ecd4", "title": "Parameter-Efficient Legal Domain Adaptation", "abstract": "Seeking legal advice is often expensive. Recent advancements in machine learning for solving complex problems can be leveraged to help make legal services more accessible to the public. However, real-life applications encounter significant challenges. State-of-the-art language models are growing increasingly large, making parameter-efficient learning increasingly important. Unfortunately, parameter-efficient methods perform poorly with small amounts of data, which are common in the legal domain (where data labelling costs are high). To address these challenges, we propose parameter-efficient legal domain adaptation, which uses vast unsupervised legal data from public legal forums to perform legal pre-training. This method exceeds or matches the fewshot performance of existing models such as LEGAL-BERT on various legal tasks while tuning only approximately 0.1% of model parameters. Additionally, we show that our method can achieve calibration comparable to existing methods across several tasks. To the best of our knowledge, this work is among the first to explore parameter-efficient methods of tuning language models in the legal domain.", "venue": "NLLP", "year": 2022, "citationCount": 4, "influentialCitationCount": 1, "openAccessPdf": {"url": "http://arxiv.org/pdf/2210.13712", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes parameter-efficient legal domain adaptation, which uses vast unsupervised legal data from public legal forums to perform legal pre-training and is among the first to explore parameter- efficient methods of tuning language models in the legal domain."}, "embedding": {"model": "specter_v2", "vector": [-0.3994854986667633, 0.4980981945991516, -0.6334584951400757, -0.31977325677871704, -0.5230834484100342, -0.3805522620677948, 0.6973305940628052, -0.7239329218864441, -0.7698729038238525, 0.013469776138663292, 0.307081401348114, -0.18916936218738556, 0.06368651241064072, 0.13519951701164246, -0.4725879728794098, 0.24815057218074799, -0.6901741623878479, 0.6394002437591553, 0.002363616367802024, -0.5838506817817688, -0.5875023007392883, -0.5339616537094116, -0.3515893816947937, -0.029168788343667984, 0.592402994632721, 0.16934387385845184, -0.4746421277523041, 0.5294565558433533, -0.34048664569854736, -0.35504859685897827, 0.3718733489513397, -1.0274755954742432, 1.0226422548294067, -0.026400737464427948, -0.09972669184207916, -0.08848918974399567, 0.1753527671098709, -0.8288403749465942, -0.6146848797798157, 0.6227265000343323, -0.204412579536438, 0.4426465630531311, 1.0073223114013672, -0.5044244527816772, -0.7419180870056152, 0.6334889531135559, 0.8106937408447266, 0.9652500748634338, -0.20051585137844086, -0.6113299131393433, 1.4221899509429932, -0.8302723169326782, 0.9415152668952942, 1.494195818901062, 0.25401267409324646, 0.984555184841156, -0.060385674238204956, -0.7494292259216309, 0.19818761944770813, 0.13445807993412018, -0.9479398727416992, 0.04575148597359657, -0.044764645397663116, -0.3895866572856903, 1.5122278928756714, -0.8198150396347046, -0.10647173970937729, 0.6833024621009827, -0.299548476934433, 1.0083348751068115, -0.3568708300590515, -0.6399729251861572, -0.24287980794906616, 0.21758437156677246, -0.3706234395503998, 0.505232036113739, -0.6300851106643677, 0.3648291826248169, -0.7100932002067566, -0.4967614710330963, 0.4967115521430969, -0.34940454363822937, 0.28999343514442444, -0.14384329319000244, 0.45475107431411743, 1.0878628492355347, 0.0784212052822113, 0.6791296601295471, 0.1978490948677063, 0.2624562978744507, 0.4724694490432739, 0.5921517014503479, 0.18147966265678406, 0.5060737133026123, -0.03678044676780701, 0.185127854347229, -0.5481441617012024, 0.496086984872818, 0.20742329955101013, 0.642314076423645, 0.05207351595163345, -0.0908023789525032, -0.6868101358413696, 0.8541623950004578, 1.345991849899292, -0.08074541389942169, 0.4238622784614563, -1.0172845125198364, 0.550290048122406, -0.3589262366294861, 0.5554496645927429, -0.15034225583076477, 0.06038166955113411, 0.2219628244638443, -0.5645243525505066, -1.0572723150253296, -0.16340331733226776, -0.1393316388130188, -0.6162024140357971, 0.5568005442619324, -0.09728953242301941, -0.0186088215559721, 0.045162517577409744, 0.7388558387756348, 0.21300187706947327, 0.7441099882125854, 0.28526636958122253, 0.10768908262252808, 0.3855655789375305, -0.3901464641094208, -0.7735108733177185, -0.8894193172454834, 0.796245276927948, -0.12239061295986176, 0.4631959795951843, -0.34062376618385315, -1.1962586641311646, -0.6093851327896118, -0.9391125440597534, -0.027515199035406113, -0.49696701765060425, 0.25422510504722595, 0.9207131266593933, 0.5580362677574158, -0.2549237012863159, 0.7831137776374817, 0.32635030150413513, -0.223744198679924, 0.45267167687416077, -0.019802197813987732, -0.20716486871242523, -0.6098710894584656, -1.9522349834442139, 0.4229377210140228, 0.3269284963607788, -0.7325114607810974, 0.150459885597229, -0.42476701736450195, -1.1782859563827515, -0.36851227283477783, 0.5584474205970764, -0.2541363537311554, 1.3336471319198608, -0.23492571711540222, -1.4138621091842651, 0.8051314353942871, -0.0170765183866024, -0.2604076564311981, 0.9716429710388184, -0.1272413283586502, -1.0749021768569946, -0.681825578212738, 0.01566287875175476, 0.42250916361808777, 0.6323127150535583, 0.03804635629057884, -0.3007074296474457, 0.971962571144104, 0.28794729709625244, 0.0467945896089077, -0.36809268593788147, 0.8375363349914551, -0.7946757674217224, -0.16159754991531372, -0.2068299949169159, 0.5337719321250916, -0.09808734804391861, 0.09302746504545212, 0.002848722506314516, -1.353615164756775, 0.6547755002975464, -0.10524826496839523, 1.1770185232162476, -1.0017515420913696, -0.6252487301826477, 0.1908138394355774, -0.7579877972602844, 0.16035118699073792, -0.6677754521369934, 0.6819969415664673, -0.0855313241481781, 0.6622785329818726, -0.49980437755584717, -1.2445096969604492, 0.4606848955154419, 0.19165661931037903, -0.49812453985214233, 0.16237132251262665, 0.16483059525489807, 1.0216946601867676, -0.48461630940437317, -0.08636624366044998, -0.11441940069198608, 0.04725906625390053, -1.2418099641799927, 1.2715680599212646, -0.5790420770645142, 0.13818617165088654, 0.09189220517873764, -0.2305971384048462, 0.1856873780488968, 0.110743947327137, 0.2863946855068207, -0.10335920751094818, 0.09226620197296143, 0.21889036893844604, -0.6229163408279419, 1.498320460319519, -0.23659177124500275, 0.36447957158088684, 0.1788979470729828, -0.5198207497596741, -0.07992751896381378, 0.5280407071113586, 0.04281340166926384, -0.643109917640686, 0.3196962773799896, 0.5833137631416321, -0.43560078740119934, -0.2067030370235443, 0.3670235872268677, 0.4214305579662323, -0.4865334630012512, 0.4568445384502411, 0.37450528144836426, -0.28615841269493103, 1.1980924606323242, 0.3791830837726593, 0.41849440336227417, 0.385475754737854, 0.5577791929244995, 0.3545732796192169, 0.31546834111213684, -1.0617200136184692, 0.10045797377824783, 0.1296665221452713, 0.44760748744010925, 0.5221260786056519, 0.3872165381908417, -0.6813318133354187, -0.8365674018859863, -0.25807854533195496, 0.3344992995262146, 1.62196946144104, -0.15360094606876373, -0.34875527024269104, -0.6059938669204712, -0.7021690011024475, 0.3854317367076874, 0.24353648722171783, -0.7791101336479187, -0.09057217091321945, -0.8600295782089233, -0.7330847978591919, 0.8809065222740173, 0.010335957631468773, 0.8949081301689148, -0.3765171468257904, 0.22331276535987854, -0.24731497466564178, -0.04616905003786087, -0.6074479222297668, -0.844142735004425, -0.3799285888671875, 0.04515872150659561, -0.16362421214580536, -0.015232601203024387, 0.34298792481422424, 0.19255399703979492, -1.1175616979599, 0.5550347566604614, -0.2247246652841568, -0.11593188345432281, 0.02777356654405594, 0.468110591173172, -0.2936520278453827, -1.4368113279342651, 0.1893318146467209, 0.259302020072937, -0.017322978004813194, 0.207142636179924, 0.46243956685066223, 0.25696495175361633, 0.5508716702461243, -0.9308145046234131, -0.363826721906662, 0.20203694701194763, 0.17910972237586975, 0.2850983738899231, -0.30329492688179016, 0.07434213906526566, -1.7750427722930908, 1.3498802185058594, -0.15548096597194672, -0.7722530364990234, 0.2804053723812103, -0.716698408126831, -0.37583422660827637, 0.4901474416255951, -0.8112544417381287, -0.7650277614593506, -1.0166724920272827, -0.19918906688690186, 0.08491786569356918, -0.2308940589427948, 0.4585663378238678, 0.16391442716121674, 0.32785454392433167, 1.0677521228790283, -0.11543934047222137, 0.05406222119927406, -0.3243887424468994, 0.9433985948562622, -0.43205726146698, 0.5064744353294373, -0.0729902908205986, 0.726088285446167, 0.1957809180021286, -0.44360384345054626, -0.2282232791185379, -0.44130438566207886, -0.6778654456138611, -0.656807541847229, -0.41811949014663696, 0.02175864949822426, -0.3566390872001648, -0.43252384662628174, -0.4920946955680847, -0.7935681939125061, -0.30586251616477966, 0.07984259724617004, -0.28225767612457275, -0.18748648464679718, -0.6006868481636047, -1.2012579441070557, -0.4806881844997406, -0.10542022436857224, -0.5693260431289673, 0.2967988848686218, -0.05243561416864395, -0.1870516538619995, -0.4863814115524292, 0.10300039499998093, 0.1013508215546608, 0.7471628785133362, -0.6561766266822815, 0.7735287547111511, 0.0773855447769165, -0.03000911884009838, -0.584206759929657, 0.17453978955745697, 0.8548310399055481, -0.36228397488594055, 0.22432871162891388, -0.5898762941360474, 0.21204346418380737, -0.7551841735839844, -0.31982704997062683, 0.03351427987217903, 0.09785784035921097, 0.2187233418226242, -0.13655295968055725, -0.3794029951095581, 0.5393553376197815, 0.9164594411849976, -0.7976630926132202, 0.03650504723191261, 0.5355829000473022, 0.4473978877067566, 0.276289701461792, 0.042987510561943054, 0.696853756904602, 0.0622759684920311, 0.7573754787445068, -0.085642509162426, -0.1311017870903015, 0.06893093883991241, -0.7345104813575745, 0.507462203502655, 0.7220681309700012, 0.08519183844327927, -0.18664231896400452, -0.8730034232139587, 0.5376154184341431, -1.4141359329223633, -0.966159999370575, 0.8787067532539368, 0.5454691052436829, 0.5165740251541138, -0.24025774002075195, 0.1647486388683319, -0.5799830555915833, 0.37067851424217224, 0.2031872421503067, -0.646442174911499, -0.6844730377197266, -0.13644543290138245, -0.1964765042066574, 0.29063472151756287, 0.5811589956283569, -0.7995141744613647, 0.7161012291908264, 14.784431457519531, 1.082809329032898, 0.37014177441596985, 1.00691819190979, 0.26897621154785156, 0.07426798343658447, -0.5546285510063171, -0.29580533504486084, -1.0849469900131226, 0.04584912210702896, 1.0403794050216675, -0.08499521017074585, 0.9498395323753357, 0.25566908717155457, 0.11613893508911133, 0.28026026487350464, -0.11521399766206741, 0.48280778527259827, 0.6647169589996338, -1.4571599960327148, 0.2464047074317932, 0.42587366700172424, 0.6622105240821838, 0.517474889755249, 0.8233222365379333, 0.9835153818130493, 0.4817326068878174, -0.48757705092430115, 0.5053458213806152, 0.057834282517433167, 1.1623272895812988, -0.1354057639837265, 0.6111054420471191, 0.7043229341506958, -0.5786618590354919, -0.6899341940879822, -1.0955374240875244, -0.6808709502220154, 0.9434195160865784, -0.12681010365486145, -0.7676552534103394, -0.31367310881614685, -0.06825824081897736, 0.7200208902359009, 0.3065345585346222, 0.3893664479255676, -0.5391638278961182, 0.9106277823448181, -0.2575264871120453, 0.6519506573677063, 0.3075047433376312, -0.003818836994469166, 0.3543127179145813, 0.17242823541164398, 0.027538470923900604, 0.1347171813249588, -0.19633911550045013, 0.44191592931747437, -0.7807368636131287, 0.2449973225593567, -0.4149348735809326, -0.06976279616355896, -0.16373632848262787, 0.6626935601234436, 1.0054630041122437, 0.45769017934799194, -0.529757022857666, 0.4646656811237335, 0.8867568373680115, 0.3812311887741089, -0.4618575870990753, 0.4529946744441986, 0.5329940319061279, 0.05974771827459335, -0.2960713803768158, 0.33406496047973633, 0.31812039017677307, -0.582172155380249, -0.6624607443809509, -0.09271014481782913, 0.8692660331726074, -0.5959396958351135, -1.3643593788146973, 0.4968548119068146, 0.10025337338447571, -0.8871698379516602, -0.2604740858078003, -0.7697429060935974, 0.07911590486764908, 0.3483703136444092, -1.6299723386764526, -0.7244848012924194, 0.8939282298088074, -0.17824800312519073, -0.5476737022399902, -0.42465078830718994, 1.0997471809387207, 0.5781952738761902, -0.31207701563835144, 0.43647292256355286, 0.5821771025657654, 0.23173370957374573, 0.6523199081420898, -0.6971411108970642, 0.7939105033874512, 0.41090354323387146, -0.20784522593021393, 0.621444046497345, 0.0036139257717877626, -0.20688258111476898, -0.042790692299604416, -0.0493704229593277, 0.42789483070373535, -1.0399478673934937, -0.3880193829536438, -0.9614568948745728, -0.9519428610801697, 0.14772087335586548, 0.6550837159156799, -0.49541816115379333, 0.7869318723678589, 0.22405411303043365, -0.8066125512123108, -0.18525756895542145, -1.0914899110794067, 0.24543508887290955, 0.663156270980835, -0.6185072064399719, -0.42366135120391846, 0.3143121898174286, -0.23432233929634094, -1.3121029138565063, -0.4538901150226593, -0.35045599937438965, 0.11013293266296387, -0.20202241837978363, 0.9204550385475159, -0.5144956111907959, 0.12404227256774902, 0.6980770826339722, 0.2023771107196808, -0.6810542941093445, -0.21565347909927368, -0.975471556186676, 0.4958058297634125, 0.041958533227443695, 1.0658382177352905, -0.38890212774276733, 0.3832032382488251, 1.4535821676254272, 0.3522469401359558, -0.28598374128341675, -1.1060744524002075, -0.5274674892425537, 0.43821316957473755, -0.4214858114719391, 0.3130471110343933, -0.026803001761436462, -0.13350650668144226, -0.14480161666870117, -0.12056632339954376, 0.6616425514221191, -0.5297499299049377, -0.840347945690155, 0.595694899559021, -0.10201513022184372, -0.19901593029499054, -0.5648542642593384, 0.03902854025363922, -1.4210580587387085, 0.5246255397796631, -1.1045845746994019, -0.017096884548664093, -1.1667083501815796, -0.6372560262680054, 0.1403934806585312, 0.15914319455623627, -0.0016198528464883566, 0.6693739891052246, -0.2804955244064331, -0.43271762132644653, -0.18695718050003052, -0.25943806767463684, 0.8257492184638977, 0.8285591006278992, -0.910192608833313, 0.32600608468055725, 0.35943806171417236, 0.4032527506351471, 0.1796715259552002, 0.35117799043655396, -0.40820956230163574, -0.7515356540679932, -1.2436543703079224, 0.5905715227127075, -0.5808656215667725, -0.30794307589530945, -0.09320840984582901, 0.5944812297821045, -0.06929212808609009, -0.32758909463882446, 0.4087486267089844, 0.67948317527771, -1.1009351015090942, -0.48216649889945984, -0.19078117609024048, -0.5899488925933838, 0.027649281546473503, -0.06432721018791199, -0.22760775685310364, -0.3250483572483063, 0.4166450798511505, 0.1690244972705841, -0.8427751660346985, -0.6491016745567322, 0.626971960067749, -0.7778241634368896, 0.28833526372909546, -0.0667433962225914, -0.10772117972373962, -1.0646730661392212, -0.8008151650428772, 0.11311597377061844, 0.5168710350990295, -0.11822855472564697, 0.695116400718689, 0.08528505265712738, -1.2603504657745361, -0.2444165199995041, 0.4672328531742096, 0.16153517365455627, -0.3717918395996094, 0.6841596364974976, -0.11039134860038757, -0.25916603207588196, 0.6271255612373352, 0.15667645633220673, 0.7301281690597534, -0.7070028185844421, -0.34672847390174866, 1.1343525648117065, -0.3365533649921417, -0.04385705664753914, 1.3312681913375854, -0.579515278339386, -1.3985750675201416, -0.009939913637936115, -0.7500116229057312, -0.6859054565429688, -0.5765870213508606, 0.20721286535263062, -0.0985361859202385, -0.381891131401062, -0.48496538400650024, -0.20446741580963135, 0.3093697726726532, 0.19311341643333435, -0.7539857625961304, 0.42905130982398987, -0.05121658742427826, -0.24080218374729156, 0.3439313769340515, 0.5727937817573547, -0.11632251739501953, -0.8173975348472595, -0.4380124509334564, -0.4069124758243561, -0.46342724561691284, -0.4095693528652191, -0.7217512130737305, -0.2849827706813812, 0.4456586241722107, 0.39409562945365906, 0.33280307054519653, -0.11176939308643341, 0.257102906703949, 0.32403331995010376, 0.8438085317611694, -0.38580530881881714, -1.4302911758422852, -0.5721983909606934, 1.0976837873458862, 1.2110788822174072, -0.8992342352867126, 0.38643214106559753, -0.3116142749786377, -0.8832138776779175, 0.8241878151893616, 0.4935756027698517, 0.040136683732271194, 1.0916727781295776, -0.41891396045684814, 0.5383399724960327, 0.3183959424495697, -0.6113054752349854, -0.2639957070350647, 1.3583483695983887, 0.8402025103569031, 0.44352126121520996, 0.36261647939682007, -0.34501686692237854, 0.8870735168457031, 0.03149479255080223, 0.055762000381946564, 0.5718599557876587, -0.006373640615493059, -0.008656919002532959, -1.1322060823440552, 0.18317541480064392, 0.7325297594070435, -0.5735988020896912, 0.010032248683273792, -0.34606102108955383, 0.8949846029281616, 0.7671800851821899, 0.46069571375846863, 0.20179583132266998, 0.29884758591651917, 1.002724289894104, 0.4248450696468353, -0.10844015330076218, -0.785200297832489, -0.08489856123924255, -0.04314246401190758, -0.37724751234054565, -0.23916418850421906, -0.33235055208206177, -0.7192848920822144, -0.501369833946228, -0.06264369934797287, 0.33771851658821106, 0.3012887239456177, 0.13671664893627167, 1.3520833253860474, 0.5874955058097839, -0.3490973711013794, -0.6583397388458252, -0.18055129051208496, -0.46749070286750793, -1.0886037349700928, -0.3411848247051239, 0.13957130908966064, -0.5187400579452515, -0.5383461713790894, -0.30016788840293884, -0.5305241942405701]}, "authors": [{"authorId": "2124950910", "name": "Jonathan Li"}, {"authorId": "2008160154", "name": "R. Bhambhoria"}, {"authorId": "1854999", "name": "Xiao-Dan Zhu"}], "references": [{"paperId": "759b5f58e58a76f79a7d845acd3169dc899d0ac2", "title": "Domain Adaptation via Prompt Learning"}, {"paperId": "59365dd313523a04d327912ece23529e25623bb0", "title": "Interpretable Low-Resource Legal Decision Making"}, {"paperId": "007088458d6d508e8a1ffc4dce24750461453d61", "title": "Unsupervised Domain Adaptation with Adapter"}, {"paperId": "c28b7dfe341f1e13a5a98efbce7946ef795cf9b8", "title": "SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer"}, {"paperId": "fd33e77884e69f6bc099990fc2790248af2749d9", "title": "LexGLUE: A Benchmark Dataset for Legal Language Understanding in English"}, {"paperId": "e553407be283d018e275f472d4d2fd709a6c9248", "title": "PPT: Pre-trained Prompt Tuning for Few-shot Learning"}, {"paperId": "b58d8579ece27a60432e667bfbdb750590fa65d9", "title": "True Few-Shot Learning with Language Models"}, {"paperId": "529edafa160a77901bec123cf8858e6c08f6cd06", "title": "When does pretraining help?: assessing self-supervised learning for law and the CaseHOLD dataset of 53,000+ legal holdings"}, {"paperId": "8a0f00731de478df520b09db65e17404494f90e3", "title": "Dank or not? Analyzing and predicting the popularity of memes on Reddit"}, {"paperId": "062c4ef3bf914186cd4b6f9c952ab28cdbe708b1", "title": "Large Scale Legal Text Classification Using Transformer Models"}, {"paperId": "a2cde1da31a61adab24e702999680108ab58e5ff", "title": "COMETA: A Corpus for Medical Entity Linking in the Social Media"}, {"paperId": "090648f65354977762a4624559e7f7b52ae17f58", "title": "Scruples: A Corpus of Community Ethical Judgments on 32, 000 Real-Life Anecdotes"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "1a6f4495474f75ae1e8bbf407f70d9a874e5b4d6", "title": "The Pushshift Reddit Dataset"}, {"paperId": "cb1141b240e3611ca698b3beeafc74b2399b77ed", "title": "Duplicate Question Detection With Deep Learning in Stack Overflow"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "e26e0e5dc6fe766c4ba1c3c14fc9c971f96d405a", "title": "Natural Language Understanding with the Quora Question Pairs Dataset"}, {"paperId": "aca16f64ddbf187f8944118c8f72777c3d682521", "title": "Neural Legal Judgment Prediction in English"}, {"paperId": "9538c57bab1a45e794d34229d1524652bb91d4cf", "title": "Legal Area Classification: A Comparative Study of Text Classifiers on Singapore Supreme Court Judgments"}, {"paperId": "156d217b0a911af97fa1b5a71dc909ccef7a8028", "title": "SciBERT: A Pretrained Language Model for Scientific Text"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"}, {"paperId": "d65ce2b8300541414bfe51d03906fca72e93523c", "title": "On Calibration of Modern Neural Networks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "8d115c3b2ee80e0754360a154a9369bc1658b607", "title": "Obtaining Well Calibrated Probabilities Using Bayesian Binning"}, {"paperId": "ec936b808e0fab9281c050ad4010cddec92c8cbe", "title": "P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks"}, {"paperId": null, "title": "For all of our experiments, we truncate the sequence to a length of 500 tokens (as opposed to 512 tokens) to allow space for a tuned"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Learning rates searched for each configuration. The suffix \"PT\" means for prompt tuning based methods, and \"FT\" for finetuning based methods"}, {"paperId": null, "title": "A Additional Training Details We use the AdamW optimizer and a of learning rates"}, {"paperId": null, "title": "experiments on roberta-base, and due to memory constraints, an effective batch size of 24 for experiments on roberta-large. As the number of samples is low, we train for 100 epochs"}, {"paperId": null, "title": "deep pre\ufb01x prompt. We report the calibration and general results using the checkpoint with the best validation macro F1, for each fewshot size and"}]}