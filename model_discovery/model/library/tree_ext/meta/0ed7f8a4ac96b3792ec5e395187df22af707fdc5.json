{"paperId": "0ed7f8a4ac96b3792ec5e395187df22af707fdc5", "title": "RNNs, CNNs and Transformers in Human Action Recognition: A Survey and A Hybrid Model", "abstract": "Human Action Recognition (HAR) encompasses the task of monitoring human activities across various domains, including but not limited to medical, educational, entertainment, visual surveillance, video retrieval, and the identification of anomalous activities. Over the past decade, the field of HAR has witnessed substantial progress by leveraging Convolutional Neural Networks (CNNs) to effectively extract and comprehend intricate information, thereby enhancing the overall performance of HAR systems. Recently, the domain of computer vision has witnessed the emergence of Vision Transformers (ViTs) as a potent solution. The efficacy of transformer architecture has been validated beyond the confines of image analysis, extending their applicability to diverse video-related tasks. Notably, within this landscape, the research community has shown keen interest in HAR, acknowledging its manifold utility and widespread adoption across various domains. This article aims to present an encompassing survey that focuses on CNNs and the evolution of Recurrent Neural Networks (RNNs) to ViTs given their importance in the domain of HAR. By conducting a thorough examination of existing literature and exploring emerging trends, this study undertakes a critical analysis and synthesis of the accumulated knowledge in this field. Additionally, it investigates the ongoing efforts to develop hybrid approaches. Following this direction, this article presents a novel hybrid model that seeks to integrate the inherent strengths of CNNs and ViTs.", "venue": "", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A novel hybrid model that seeks to integrate the inherent strengths of CNNs and ViTs is presented that seeks to integrate the inherent strengths of CNNs and ViTs in Human Action Recognition systems."}, "embedding": {"model": "specter_v2", "vector": [0.4288773536682129, 0.8115337491035461, -0.16008061170578003, 0.19196708500385284, -0.005296073853969574, 0.35092318058013916, 0.5438030958175659, -0.4930427670478821, -0.23752465844154358, -0.4446496367454529, 0.8513808846473694, 0.8577749729156494, 0.5459096431732178, -0.1272985190153122, 0.2462093085050583, 0.04397984594106674, -0.6094428896903992, -0.3310536742210388, 0.24813365936279297, -0.6128180027008057, -0.1726832389831543, -0.41455113887786865, -1.0770663022994995, -0.08092756569385529, -0.3844980001449585, 0.9897348284721375, -0.36841273307800293, 1.0470123291015625, 0.47661715745925903, 1.4305721521377563, 0.5447306632995605, -0.1618797928094864, 0.49695640802383423, -0.32444074749946594, -0.5039529204368591, 0.3590010404586792, 0.5050224661827087, -0.6163318753242493, -1.1509279012680054, 0.5537736415863037, -0.387045681476593, 0.40815916657447815, 0.26134493947029114, -0.8168026804924011, -0.06521076709032059, 0.11741021275520325, 1.0498017072677612, 0.7703908085823059, 0.0857723206281662, 0.01549453940242529, 1.3912862539291382, -0.7033198475837708, 0.04455079138278961, 1.6721423864364624, 0.9454036951065063, 0.5062231421470642, 0.20814469456672668, -0.4808632433414459, 0.3091180622577667, -0.09799344092607498, -0.2175690233707428, -0.1944645345211029, 0.36755380034446716, -0.2688714265823364, 1.3352444171905518, -0.5493406653404236, 0.418621689081192, 0.9403539896011353, 0.15285833179950714, 1.5705760717391968, -0.4043091833591461, -0.6707448959350586, -0.11704442650079727, -0.17909586429595947, 0.04569375887513161, 0.7509655952453613, -0.5298994779586792, 0.22706401348114014, -0.8333449363708496, 0.09465913474559784, 1.0273027420043945, 0.6925738453865051, 0.10065408051013947, -0.20848295092582703, -0.3398267924785614, 0.8558463454246521, 0.7670005559921265, 0.8239319920539856, -0.8738941550254822, 0.8166150450706482, 0.5730943083763123, 0.11959561705589294, -0.6077191233634949, 0.5240753293037415, 0.505959153175354, 0.4672392010688782, -0.3748082220554352, 0.040679462254047394, -0.5281410217285156, 0.6490002870559692, -0.5068643093109131, 0.5895090699195862, -0.77000492811203, 0.3991420269012451, 1.0167039632797241, -0.18972426652908325, 0.19920790195465088, -0.9546442627906799, -0.03401621803641319, -0.14400343596935272, 0.0028270878829061985, -0.9686535000801086, -0.11820543557405472, -0.12389969825744629, -0.8270508646965027, -0.7830204367637634, -0.5503162741661072, 0.5778169631958008, -1.1696748733520508, 0.18765462934970856, -0.7904161214828491, -0.36711686849594116, 0.1349720060825348, 0.10412544012069702, 0.3316757082939148, -0.04393472522497177, 0.546309769153595, 0.5153511166572571, 1.0526584386825562, -0.9534634351730347, -0.683331310749054, -0.9286043643951416, -0.0176714938133955, 0.28059121966362, -0.21409249305725098, -0.07218239456415176, -1.1120189428329468, -1.2221852540969849, -0.9846212863922119, -0.05777142941951752, -0.3726224899291992, 0.37815892696380615, 0.8615086674690247, -0.04786680266261101, -1.012316107749939, 0.7658702731132507, -0.1959855556488037, -0.8411647081375122, 0.5481981635093689, 0.11994882673025131, 0.18738536536693573, 0.12271317094564438, -0.8131529092788696, 0.40585559606552124, -0.1112309992313385, -0.2061460018157959, -0.5527597665786743, 0.40584394335746765, -1.340185523033142, -0.08635519444942474, 0.032711636275053024, -0.4926430583000183, 1.3745840787887573, -0.5520031452178955, -0.7524516582489014, 0.4993841350078583, 0.02803470939397812, -0.21565233170986176, 0.558987021446228, -0.24516873061656952, -0.8055179715156555, 0.10367872565984726, -0.12286242097616196, 0.6409704685211182, 0.5112138986587524, 0.34125983715057373, -0.3856882154941559, 0.2209528684616089, 0.18427135050296783, -0.18737757205963135, -0.47975999116897583, 1.1635316610336304, -0.037348415702581406, -0.24198414385318756, 0.5003852248191833, 0.5990233421325684, -0.20795020461082458, 0.0528055839240551, -0.10302353650331497, -1.0050023794174194, 0.9226422309875488, 0.0899801254272461, 0.7113488912582397, -0.8140321373939514, -0.8087694644927979, -0.2161436825990677, 0.19558623433113098, -0.20196567475795746, -0.7816921472549438, 0.41244035959243774, -0.6506213545799255, -0.26375049352645874, 0.16492874920368195, -0.7382017970085144, -0.5935096144676208, -0.10932959616184235, -0.14001493155956268, 0.14527225494384766, 0.10149993002414703, 1.2870707511901855, -0.8637775778770447, -0.15037477016448975, 0.2540512681007385, 0.177278071641922, -0.5133669376373291, 1.6094290018081665, 0.07600695639848709, -0.20610816776752472, -0.29386329650878906, 0.4159373641014099, -0.42216962575912476, -0.31788474321365356, 0.4994265139102936, -0.7643216848373413, 0.016201423481106758, 0.35700446367263794, -0.24460811913013458, 0.960825502872467, 0.36028921604156494, 0.9970605969429016, -0.6784867644309998, -1.1202434301376343, 0.29723137617111206, 0.827022910118103, 0.10962408035993576, -0.6691251397132874, 0.6282541155815125, -0.010555117391049862, -1.0348378419876099, -0.009938064962625504, 0.6142331957817078, 0.9161311388015747, -0.48225724697113037, -0.13683339953422546, 0.9098729491233826, 0.28454723954200745, 0.08645278215408325, 0.3330768346786499, 0.9259682893753052, 0.08455383777618408, 0.6256922483444214, 0.3669488728046417, 0.2599693238735199, -0.8873984813690186, 0.20401298999786377, 0.6214358806610107, 0.10886134952306747, 1.0517691373825073, 0.4646623730659485, -1.193034052848816, -0.07031573355197906, -0.02407771535217762, 1.1299151182174683, 0.9272135496139526, -0.04978134483098984, -0.014819023199379444, -0.7313490509986877, -0.6118356585502625, -0.7754616141319275, -0.3919543921947479, -0.8505010008811951, -0.4124408960342407, -0.41771379113197327, -0.6033457517623901, 1.2107079029083252, 0.9384316802024841, 1.4563658237457275, -1.497889757156372, -0.9226197600364685, -0.23398588597774506, -0.2169739007949829, -0.9176436066627502, -0.6253984570503235, 0.04991214722394943, -0.710791826248169, -0.8013933300971985, -0.09452040493488312, -0.04851905629038811, 0.18429383635520935, -0.3815847933292389, 0.6981315016746521, -0.3834337890148163, -0.49644041061401367, 0.8383969068527222, 0.5041556358337402, -0.7054191827774048, -0.5627298355102539, -0.44183963537216187, 0.060280587524175644, 0.17819452285766602, 0.41865089535713196, 0.3981788158416748, -0.28191739320755005, 0.229853555560112, -0.2041347324848175, -0.44394978880882263, 0.277188241481781, 0.12053049355745316, 0.39540013670921326, -0.5745762586593628, 0.10664742439985275, -0.5119155645370483, 0.8406432271003723, 0.22467568516731262, 0.015253452584147453, 0.2873176634311676, -0.5614521503448486, -0.34250345826148987, 0.09223970770835876, -0.5406320691108704, -0.2305312156677246, -0.4488915801048279, 0.627157986164093, -0.6623842120170593, -0.7147408127784729, 0.04384700953960419, 0.4254816472530365, 0.21629495918750763, 0.6366572976112366, 0.5462319254875183, 0.3149685263633728, 0.11319483071565628, -0.20573697984218597, -0.5416057705879211, 1.0967525243759155, 0.8505001664161682, -0.015929577872157097, -0.009716711938381195, -0.11779889464378357, -0.9279510974884033, -0.5512226223945618, -0.8043287992477417, -0.4990161061286926, -0.8323747515678406, 0.713807225227356, -0.8519142866134644, -0.8416735529899597, 0.2760082185268402, -1.0469365119934082, 0.0676296278834343, -0.22744841873645782, -0.11936133354902267, -0.5214597582817078, -0.8478063344955444, -0.7542029619216919, -1.0430420637130737, -0.5230273604393005, -0.6574394106864929, -0.051204122602939606, 0.48986953496932983, -0.46802034974098206, -0.20069867372512817, 0.05591799318790436, 0.14050109684467316, 0.6010932326316833, 0.13205794990062714, 0.24222432076931, -0.14111356437206268, -0.12035750597715378, -0.4694748818874359, 0.3779788315296173, 0.9460738897323608, 0.10457848012447357, -0.24942487478256226, -0.7950461506843567, 0.4750416874885559, -0.21245193481445312, -0.2583834230899811, 0.16086158156394958, 0.009157536551356316, 0.42281588912010193, 0.28904762864112854, 0.02678779512643814, -0.1618962436914444, 0.9688528180122375, -0.10933596640825272, 0.5073361396789551, 0.16996051371097565, 0.7265634536743164, -0.11474748700857162, -0.25220394134521484, 0.6441954970359802, 0.3018146753311157, 0.28265342116355896, 0.6342784762382507, -0.6736301183700562, -0.5116989612579346, -0.6903688311576843, 0.49549034237861633, 0.49306681752204895, -0.701583981513977, 0.17886784672737122, -0.8539928197860718, 0.7864159345626831, -1.5481191873550415, -1.3538289070129395, 0.7671574950218201, 0.4440237879753113, -0.3173964321613312, -0.3522191345691681, 0.16142989695072174, 0.06001346930861473, 0.4936535358428955, 0.28864654898643494, -0.26895326375961304, -0.4513242542743683, 0.07010038197040558, 0.4059199094772339, 0.06334228068590164, -0.014853263273835182, -1.0435659885406494, 0.4071682393550873, 14.701995849609375, -0.0483468621969223, -0.05317787081003189, 0.3527388572692871, 0.28169408440589905, 0.4217429757118225, 0.4492180347442627, -0.12837740778923035, -0.6651195883750916, -0.3998926281929016, 0.8721016049385071, 0.6347533464431763, 0.5239251852035522, 0.5553634762763977, 0.043886035680770874, 0.18244393169879913, -0.7637057304382324, 1.2601509094238281, 0.7362545728683472, -1.124029517173767, 0.33460813760757446, 0.12825213372707367, -0.045466918498277664, 0.42251303791999817, 0.45980027318000793, 0.8714937567710876, 0.4264150559902191, -0.4434906840324402, 0.5929861068725586, 0.44437357783317566, 0.562751829624176, 0.08367935568094254, 0.5496577024459839, 0.07820237427949905, -1.491332769393921, -0.7659685611724854, -0.25976479053497314, -1.0791714191436768, 0.1440250724554062, -0.7450941205024719, -0.11403413116931915, -0.49652376770973206, 0.36385786533355713, 1.339424729347229, -0.14908960461616516, 0.216964453458786, -0.6170691847801208, 0.1785459667444229, 0.3466385304927826, 0.1805403083562851, 0.3873033821582794, 0.6707526445388794, 0.3336016833782196, 0.07743321359157562, -0.2916853725910187, 0.5605342388153076, 0.08164849132299423, 0.3187639117240906, -0.5078508853912354, -0.722428023815155, -0.4841804504394531, -0.3474338948726654, -0.6859810948371887, 0.7706348896026611, 0.24930311739444733, 0.128958061337471, -0.16951248049736023, 0.4141365587711334, 0.05516532436013222, 0.3848324418067932, -0.5259169340133667, -0.3241156339645386, 0.5370173454284668, -0.07904333621263504, 0.49304914474487305, 0.615534782409668, -0.0058129592798650265, -0.8441669940948486, -0.643959641456604, -0.33792558312416077, 0.8300449252128601, -1.0327274799346924, -0.507477879524231, 1.2515791654586792, -0.3446596562862396, -0.8726780414581299, 0.17947863042354584, -0.651717483997345, -0.5286548137664795, -0.08847136795520782, -1.095274567604065, -0.7331549525260925, -0.7488119602203369, 0.6027460098266602, 0.07413110136985779, -0.32705456018447876, 0.957272469997406, 0.0074338060803711414, -0.3542764484882355, 0.13927675783634186, -1.134170413017273, 0.7185503840446472, -0.4913688600063324, -0.35235345363616943, 0.2516659200191498, 0.639171302318573, -0.11966468393802643, -0.09396542608737946, 0.07416501641273499, 0.15352779626846313, -0.04019041731953621, 0.09428241103887558, 0.5959036350250244, -0.7268765568733215, -0.7410151362419128, -0.5490015745162964, -0.412735253572464, 0.765899121761322, 0.597906231880188, 0.09398104250431061, -0.0725228488445282, -0.13452601432800293, -0.5110828280448914, 0.00877167284488678, -0.8478925824165344, 0.047559645026922226, 0.43310609459877014, -0.8661614060401917, -1.0039488077163696, -0.3028072714805603, -0.23925858736038208, -0.4874253273010254, -0.0935683622956276, -0.049948498606681824, 0.5104050636291504, -0.6488748788833618, 1.1173038482666016, -0.8862897753715515, 0.42903047800064087, 0.7059280872344971, -0.24915573000907898, -0.34801697731018066, -0.30800044536590576, -0.6881037950515747, 0.17266637086868286, -0.2619490921497345, 0.0216742604970932, -0.37988772988319397, 0.4196822941303253, 0.9460670351982117, 0.25324076414108276, -0.20181803405284882, -0.5118206739425659, -0.14042295515537262, -0.8434761762619019, -0.43815168738365173, -0.04872768372297287, -0.44188350439071655, -0.13012054562568665, 0.09392134100198746, -0.09316633641719818, 0.29906007647514343, -0.1446683406829834, -0.8764118552207947, 0.3148229420185089, -0.6129355430603027, 0.14892807602882385, -0.15082816779613495, -1.0090959072113037, -1.2586569786071777, -0.5045356750488281, -0.5987658500671387, 0.033068712800741196, -0.8789076209068298, -0.3273206949234009, 0.8428432941436768, -0.750133752822876, 0.6884228587150574, 0.8918004631996155, -0.2997303307056427, 0.05541125684976578, -0.19480927288532257, -0.7973563075065613, 0.8588911890983582, 0.7389494180679321, -0.7905229330062866, -0.028201520442962646, 0.1688382625579834, 0.051669642329216, 0.8404500484466553, 0.3060913383960724, -0.52461177110672, -0.6355247497558594, -0.36316195130348206, -0.03349761664867401, 0.20731760561466217, 0.5100576877593994, -1.6120655536651611, 0.8542783856391907, 0.2749903202056885, 0.40432265400886536, -0.0018484846223145723, 0.6956983804702759, -1.057434320449829, -0.476260781288147, 0.35306820273399353, -0.8772304058074951, 0.20382709801197052, -0.44760966300964355, -0.47402769327163696, -0.6544355750083923, 1.0720933675765991, 0.3609553277492523, -1.1825308799743652, -1.0301421880722046, 0.5399022698402405, -0.7934556007385254, -0.10569053143262863, 0.04468365013599396, -0.626948893070221, -0.6090648770332336, -0.49369749426841736, -0.43172216415405273, 0.1688930094242096, -1.0140477418899536, 1.0880756378173828, 1.1445497274398804, -1.224513053894043, 0.28135743737220764, 0.5217841267585754, 0.10597718507051468, -0.3932461142539978, 0.3616701364517212, 0.5939923524856567, 0.05996087193489075, 0.2626558542251587, -0.37307992577552795, 0.3737417161464691, -0.9426661133766174, -0.05563405528664589, 1.5953398942947388, -0.3236139714717865, -0.2148592472076416, 0.6609570384025574, -0.25077781081199646, -0.8443868160247803, 0.4042127728462219, -0.9688836932182312, -0.9944833517074585, -0.0065664793364703655, 0.5771656632423401, 0.49117133021354675, -0.2780963182449341, -0.4933304488658905, -0.3934729993343353, 0.2408357411623001, 0.057150717824697495, -0.2585936486721039, 0.4123099148273468, -0.009488069452345371, 0.18665504455566406, 0.3135019838809967, 0.5680986046791077, -1.281680941581726, -1.0258010625839233, -0.4894979000091553, -0.44751283526420593, -0.04364814981818199, -0.1769879311323166, -0.08352925628423691, -1.2260353565216064, 0.574178159236908, 1.149056315422058, 0.07862966507673264, 0.4765509366989136, 0.24452540278434753, 0.12609019875526428, 0.8486591577529907, 0.006936144083738327, -0.9372992515563965, 0.36823397874832153, 0.9999340772628784, 1.4466776847839355, -0.9378142356872559, 0.13200029730796814, -0.07424114644527435, -0.6966062188148499, 1.297702431678772, 0.45960918068885803, -0.4333125352859497, 0.8366071581840515, -0.7889044284820557, 0.15630774199962616, -0.1588945984840393, -0.5585975646972656, -0.2964802384376526, 0.6551099419593811, 0.9987620115280151, 0.5043566226959229, 0.35705479979515076, 0.3114442825317383, 0.6740896105766296, 0.39199820160865784, 0.6692823171615601, 0.7801223993301392, 0.5764042735099792, -0.07599830627441406, 0.4825817346572876, 0.2858861982822418, 0.38547173142433167, -0.35864463448524475, 0.22212448716163635, -0.03886204585433006, 0.6706975102424622, 0.3026464581489563, 0.9210212230682373, 0.7667232751846313, -0.49944326281547546, 1.4514352083206177, 0.014385087415575981, 0.2610336244106293, -0.41315415501594543, -0.6225107312202454, -0.3131873309612274, -0.7462534308433533, -0.6481285095214844, -0.8184902667999268, -1.1171053647994995, -0.1660842001438141, 0.27616024017333984, 0.8291550278663635, -0.35710498690605164, -0.28553274273872375, 0.957885205745697, 0.3319230079650879, 0.5248199701309204, -0.3445059359073639, -0.4409671425819397, -0.3332301378250122, -0.9057928919792175, -0.150588721036911, -0.47647687792778015, 0.43918219208717346, -0.4994887113571167, -0.3203367292881012, -0.10525660216808319]}, "authors": [{"authorId": "2292280120", "name": "Khaled Alomar"}, {"authorId": "2160733660", "name": "Halil Ibrahim Aysel"}, {"authorId": "2292742904", "name": "Xiaohao Cai"}], "references": [{"paperId": "d76937ff6d110c09d3823167c7b6c0d4cda8d669", "title": "Distilling Knowledge from CNN-Transformer Models for Enhanced Human Action Recognition"}, {"paperId": "6a32a7447b751062ebefb59ef2de82010369fe05", "title": "A Lightweight Skeleton-Based 3D-CNN for Real-Time Fall Detection and Action Recognition"}, {"paperId": "356f045aec87a2e5605168c9f80eb4f2b0b37cfb", "title": "A Hybrid Visual Transformer for Efficient Deep Human Activity Recognition"}, {"paperId": "4efb2c9b983b8e0a7876e544a47e627e93f3b977", "title": "TransNet: A Transfer Learning-Based Network for Human Action Recognition"}, {"paperId": "c4c6c51edb6890505da5e12caa049af824575a29", "title": "3D-ShuffleViT: An Efficient Video Action Recognition Network with Deep Integration of Self-Attention and Convolution"}, {"paperId": "52239e2338cd9f0e0e690203af8f0f1260ef7abf", "title": "Swin-Fusion: Swin-Transformer with Feature Fusion for Human Action Recognition"}, {"paperId": "948fa6c5710f460c7e732e2059d75d70de972bbb", "title": "Actor-agnostic Multi-label Action Recognition with Multi-modal Query"}, {"paperId": "d612bdfefe3340bfa13fd814d51a6b8992df5b1d", "title": "Video-Based Human Activity Recognition Using Deep Learning Approaches"}, {"paperId": "8c06bfc34df02d1e05abb2db339bb3f93c74eb1f", "title": "Spatial and temporal saliency based four-stream network with multi-task learning for action recognition"}, {"paperId": "672a8c7fe6d079c82758a45c7fdefa741bdc6ef5", "title": "SVFormer: Semi-supervised Video Transformer for Action Recognition"}, {"paperId": "027b2285c29142cd7d7ec0ed6014ae2024998a33", "title": "STAR-Transformer: A Spatio-temporal Cross Attention Transformer for Human Action Recognition"}, {"paperId": "8b19a8525dc3b18ba0b98c6a8c32700036d8f128", "title": "A unified model for continuous conditional video prediction"}, {"paperId": "2d5162cb94b844be715a7c44b1c2cd419a1ff633", "title": "Vision Transformers for Action Recognition: A Survey"}, {"paperId": "c7fa5c2172a4624d6baa91e66344e4520d3028ad", "title": "Analyzing Transformers in Embedding Space"}, {"paperId": "16fa1a8575ff56781b6b83726906754ed4e5f3a7", "title": "ViT-ReT: Vision and Recurrent Transformer Neural Networks for Human Activity Recognition in Videos"}, {"paperId": "ced875786cd1777e138987e406ee8e8f0f1f1667", "title": "Multimodal Transformer for Nursing Activity Recognition"}, {"paperId": "5a71bf38cf409b55b14b2d5159c0b06bef9ad603", "title": "A General Survey on Attention Mechanisms in Deep Learning"}, {"paperId": "793ca4a75d120ca2f09a6f70e649a59725e59ec8", "title": "Human action recognition based on spatial\u2013temporal relational model and LSTM-CNN framework"}, {"paperId": "4d4255335acdb246c5b0f85c21a0a43c9b53f54b", "title": "Evaluating Transformers for Lightweight Action Recognition"}, {"paperId": "faba70f66c734a6b3ca9c87e29d0acb0ccbbe584", "title": "HAR-Depth: A Novel Framework for Human Action Recognition Using Sequential Learning and Depth Estimated History Images"}, {"paperId": "dc05240a06326b5b1664f7e8c95c330b08cd0349", "title": "ActionCLIP: A New Paradigm for Video Action Recognition"}, {"paperId": "464511c173f6a7b6e594131e18d516bfdee2b6dd", "title": "MM-ViT: Multi-Modal Video Transformer for Compressed Video Action Recognition"}, {"paperId": "94eae578e6af3382f6449506965639f18aab3fa0", "title": "Video Swin Transformer"}, {"paperId": "2f5f8e60a1c8cea0a0ba669305f0020854549ddd", "title": "End-to-End Temporal Action Detection With Transformer"}, {"paperId": "d8d2e574965fe733eb1416e03df2b5c2914fc530", "title": "A Survey of Transformers"}, {"paperId": "025f060ffc3a30d616fb8a35eb3c8b0697f88595", "title": "Spatiotemporal Multimodal Learning With 3D CNNs for Video Action Recognition"}, {"paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6", "title": "Multiscale Vision Transformers"}, {"paperId": "df37e254a5e2d966680d9c4ef70b44d43a073eb9", "title": "Video Prediction Recalling Long-term Motion Context via Memory Alignment Learning"}, {"paperId": "b6382a7351c0c595f91472ac71d3b2d87b3c4844", "title": "ViViT: A Video Vision Transformer"}, {"paperId": "63e838bb935f5ebe3498107e753f07f08a8b5689", "title": "An Image is Worth 16x16 Words, What is a Video Worth?"}, {"paperId": "fa19b03899100a3765d27377c9f90996c19cdf66", "title": "ACTION-Net: Multipath Excitation for Action Recognition"}, {"paperId": "fa08b41ccdfc5d8771adfbc34c176fa237d4646c", "title": "Is Space-Time Attention All You Need for Video Understanding?"}, {"paperId": "94b69cf199fa0b6c842e17fe5d6174a9d161c3df", "title": "Video Transformer Network"}, {"paperId": "3a906b77fa218adc171fecb28bb81c24c14dcc7b", "title": "Transformers in Vision: A Survey"}, {"paperId": "d40c77c010c8dbef6142903a02f2a73a85012d5d", "title": "A Survey on Vision Transformer"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "ebc5dc2961d12cbbbd45264889dfc3ef9731fc6a", "title": "Human Action Recognition From Various Data Modalities: A Review"}, {"paperId": "2ad2981a53393dc5987419a22cbe1ee3d7fa6e42", "title": "TDN: Temporal Difference Networks for Efficient Action Recognition"}, {"paperId": "a9b3a9dd494576f54c946aa030fe491eba239b7e", "title": "A comprehensive review on deep learning-based methods for video anomaly detection"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "dfa12484c45830c5711a3f8aa5790a98fe65105d", "title": "Pose and Joint-Aware Action Recognition"}, {"paperId": "d11a704eeae83031e6141f87412cfe9b5b1585e2", "title": "A survey on video-based Human Action Recognition: recent updates, datasets, challenges, and applications"}, {"paperId": "594033435ed9b8db1d193d1f053b803e712ce4b1", "title": "Construction and evaluation of the human behavior recognition model in kinematics under deep learning"}, {"paperId": "6f613f166ec26e3e01e996f7f04ed1d747081d9c", "title": "3DFCNN: real-time action recognition using 3D deep neural networks with raw depth information"}, {"paperId": "6429d6188ed346c62792ff13cf36c1cb1a3e1205", "title": "Improved human action recognition approach based on two-stream convolutional neural network model"}, {"paperId": "d2301072587dadf9e18552f35abfc26dac3f4b8e", "title": "Learning Temporal Co-Attention Models for Unsupervised Video Action Localization"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "1b7e4a6fccd81fbf07cf0f51c8771b21a01d7338", "title": "Transferable two-stream convolutional neural network for human action recognition"}, {"paperId": "51bcb7de98bedf65215910fcfd08555d5eed682a", "title": "Dynamic Motion Representation for Human Action Recognition"}, {"paperId": "42bf5be4b315c0eb68dd8d7fd4a6519304217c25", "title": "An information-rich sampling technique over spatio-temporal CNN for classification of human actions in videos"}, {"paperId": "7834932066cbfb0e9af41637834157e3011ff250", "title": "Human Action Recognition based on Simple Deep Convolution Network PCANet"}, {"paperId": "448529da2bf004cf79084401ad3cbd6b511e4969", "title": "Bridging the Gap Between Anchor-Based and Anchor-Free Detection via Adaptive Training Sample Selection"}, {"paperId": "9a454eddbb459c2f810468cd80a4aead6f201901", "title": "Gate-Shift Networks for Video Action Recognition"}, {"paperId": "b812b20192ffac37b03bde0261934a2a8c7fdf47", "title": "STM: SpatioTemporal and Motion Encoding for Action Recognition"}, {"paperId": "6e93bd99350bf03acf870f83bb9c7ab1a7d17147", "title": "MARS: Motion-Augmented RGB Stream for Action Recognition"}, {"paperId": "9662b48d9b8a8f2118487a7f3be2d76283848627", "title": "CenterNet: Keypoint Triplets for Object Detection"}, {"paperId": "756532d707209f13c44b96e6306ac0c96e6733a5", "title": "Time-Asymmetric 3d Convolutional Neural Networks for Action Recognition"}, {"paperId": "50fec8e60b63e355241f153d6f5c17d4116b2a9e", "title": "Timeception for Complex Action Recognition"}, {"paperId": "94d67304c6c0d23c7dfcf008cbf799b54b8d20b9", "title": "StNet: Local and Global Spatial-Temporal Modeling for Action Recognition"}, {"paperId": "2096d98995f48de87697cfbd3e58f378d00a840e", "title": "A novel attention-based hybrid CNN-RNN architecture for sEMG-based gesture recognition"}, {"paperId": "396520344fb4894849a826b3de56fc86d4d79100", "title": "Compound Memory Networks for Few-Shot Video Classification"}, {"paperId": "baa733992a236258adf36a41413b96707c8e9f4c", "title": "Multi-stream CNN: Learning representations based on human-related regions for action recognition"}, {"paperId": "025a44bf059aef8b9ee2e6ca598bebefc59a4a61", "title": "Human Action Recognition and Prediction: A Survey"}, {"paperId": "3d708e4ecabc50d3f3e387a21a73f6ae2b52ddfc", "title": "T-C3D: Temporal Convolutional 3D Network for Real-Time Action Recognition"}, {"paperId": "aa63893b34f523973d0692dc74ff22512daac322", "title": "ECO: Efficient Convolutional Network for Online Video Understanding"}, {"paperId": "12ffd26b3f88c721bef2a97323f17e38b99e86d3", "title": "Region-sequence based six-stream CNN features for general and fine-grained human action recognition in videos"}, {"paperId": "7d7b036ed01765c9473d695f029142128d442aaa", "title": "Real-Time Action Recognition With Deeply Transferred Motion Vector CNNs"}, {"paperId": "289fd6808097aa5091dd2b20ce88443faf0f7449", "title": "Recognition"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "b9da2a1cd00c7a26e34c72bb18cd4ca7d69d8cdd", "title": "Skeleton based action recognition using translation-scale invariant image mapping and multi-scale deep CNN"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "1ba76761f551a044d3d1bebefc5cb3faccf77b27", "title": "Two-stream RNN/CNN for action recognition in 3D videos"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "1031a69923b80ad01cf3fbb703d10757a80e699b", "title": "Pyramid Scene Parsing Network"}, {"paperId": "0d6f20680b33ffcc4d83a01dc908df5cb856eb9b", "title": "3D Action Recognition from Novel Viewpoints"}, {"paperId": "3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c", "title": "Real-Time Action Recognition with Enhanced Motion Vector CNNs"}, {"paperId": "179462c2a03b1a5c3f98fac86c992c116e152b82", "title": "Long-Term Temporal Convolutions for Action Recognition"}, {"paperId": "5aff9c4118b15c7fa8d9afdc1527bb608c667bd2", "title": "ARCH: Adaptive recurrent-convolutional hybrid networks for long-term action recognition"}, {"paperId": "08d6eea549dab5701c54d5e8674cc8d4b0882998", "title": "Human Action Recognition based on Convolutional Neural Networks with a Convolutional Auto-Encoder"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0", "title": "SSD: Single Shot MultiBox Detector"}, {"paperId": "3a8e4a921cddf7cc7ec6c4b7f1971c0f1f371faa", "title": "Skeleton based action recognition with convolutional neural network"}, {"paperId": "93499a7c7f699b6630a86fad964536f9423bb6d0", "title": "Effective Approaches to Attention-based Neural Machine Translation"}, {"paperId": "c4697681079de557cc04e209762b1a4c1eaae709", "title": "P-CNN: Pose-Based CNN Features for Action Recognition"}, {"paperId": "f8e79ac0ea341056ef20f2616628b3e964764cfd", "title": "You Only Look Once: Unified, Real-Time Object Detection"}, {"paperId": "0a28efacb92d16e6e0dd4d87b5aca91b28be8853", "title": "ActivityNet: A large-scale video benchmark for human activity understanding"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "6364fdaa0a0eccd823a779fcdd489173f938e91a", "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation"}, {"paperId": "1ab237d7eb9dec8416947fce0b0cbf6c688a7229", "title": "Contextual Action Recognition with R*CNN"}, {"paperId": "ac3ee98020251797c2b401e1389461df88e52e62", "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling"}, {"paperId": "c216c58f63f5f31c04b329b8eebf72bcd12ed6c4", "title": "Human Action Recognition Based on Recognition of Linear Patterns in Action Bank Features Using Convolutional Neural Networks"}, {"paperId": "6fc6803df5f9ae505cae5b2f178ade4062c768d0", "title": "Fully convolutional networks for semantic segmentation"}, {"paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327", "title": "Going deeper with convolutions"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "c1b0296ed47cf3f906f6e24683d9f5444406be53", "title": "DL-SFA: Deeply-Learned Slow Feature Analysis for Action Recognition"}, {"paperId": "6d4c9c923e9f145d1c01a2de2afc38ec23c44253", "title": "Large-Scale Video Classification with Convolutional Neural Networks"}, {"paperId": "67dccc9a856b60bdc4d058d83657a089b8ad4486", "title": "Two-Stream Convolutional Networks for Action Recognition in Videos"}, {"paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e", "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"}, {"paperId": "7ae18514a4a5a67026a02d4893bf86f38e438359", "title": "Multi-modal gesture recognition challenge 2013: dataset and results"}, {"paperId": "1d7ad548f1abe3ef69c742e7a878cb9dcc888c20", "title": "Recognition of human walking/running actions based on neural network"}, {"paperId": "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation"}, {"paperId": "944a1cfd79dbfb6fef460360a0765ba790f4027a", "title": "Recurrent Continuous Translation Models"}, {"paperId": "6471fd1cbc081fb3b7b5b14d6ab9eaaba02b5c17", "title": "Generating Sequences With Recurrent Neural Networks"}, {"paperId": "4177ec52d1b80ed57f2e72b0f9a42365f1a8598d", "title": "Speech recognition with deep recurrent neural networks"}, {"paperId": "8ab709dcffad8abdc73f264993a88f4ca4f5299b", "title": "Berkeley MHAD: A comprehensive Multimodal Human Action Database"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "da9e411fcf740569b6b356f330a1d0fc077c8d7c", "title": "UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild"}, {"paperId": "8b3b8848a311c501e704c45c6d50430ab7068956", "title": "HMDB: A large video database for human motion recognition"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "e8b12467bdc20bde976750b8a28decdb33246d1d", "title": "Histograms of oriented gradients for human detection"}, {"paperId": "b480f6a3750b4cebaf1db205692c8321d45926a2", "title": "Recognizing human actions: a local SVM approach"}, {"paperId": "dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63", "title": "Rapid object detection using a boosted cascade of simple features"}, {"paperId": "11540131eae85b2e11d53df7f1360eeb6476e7f4", "title": "Learning to Forget: Continual Prediction with LSTM"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "52b7bf3ba59b31f362aa07f957f1543a29a4279e", "title": "Support-Vector Networks"}, {"paperId": "d0be39ee052d246ae99c082a565aba25b811be2d", "title": "Learning long-term dependencies with gradient descent is difficult"}, {"paperId": "1181acaf0bb0541830b80d8dc49fae430f035e4c", "title": "Performance of optical flow techniques"}, {"paperId": "319f22bd5abfd67ac15988aa5c7f705f018c3ccd", "title": "Learning internal representations by error propagation"}, {"paperId": "69e68bfaadf2dccff800158749f5a50fe82d173b", "title": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position"}, {"paperId": "a07c9824180897e04cc84598c38cd051cdc64c7e", "title": "Vision Transformer with Cross-attention by Temporal Shift for Efficient Action Recognition"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "34fdca6e6d0efd1dc0612b119194700a9ba0877a", "title": "Human Action Recognition using 3D Convolutional Neural Networks with 3D Motion Cuboids in Surveillance Videos"}, {"paperId": "b5979489e11edd76607c219a8bdc83ba4a88ab38", "title": "Action Recognition in Video Sequences using Deep Bi-Directional LSTM With CNN Features"}, {"paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82", "title": "Deep Learning"}, {"paperId": "326ef4abc7ee723bc400922774ce6d59125c6413", "title": "UvA-DARE (Digital Academic Repository) Dynamic Image Networks for Action Recognition"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}, {"paperId": "caa5eec3feba1e3f4c421f28daaa6d1906b573ec", "title": "Serial Order: A Parallel Distributed Processing Approach"}, {"paperId": null, "title": "A new hybrid deep learning model for human action 43"}]}