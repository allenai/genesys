{"paperId": "9f52317ea9c5a6804b978987ff2a6557f98b5b2c", "title": "SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks", "abstract": "As the size of large language models continue to scale, so does the computational resources required to run it. Spiking Neural Networks (SNNs) have emerged as an energy-efficient approach to deep learning that leverage sparse and event-driven activations to reduce the computational overhead associated with model inference. While they have become competitive with non-spiking models on many computer vision tasks, SNNs have also proven to be more challenging to train. As a result, their performance lags behind modern deep learning, and we are yet to see the effectiveness of SNNs in language generation. In this paper, inspired by the Receptance Weighted Key Value (RWKV) language model, we successfully implement `SpikeGPT', a generative language model with binary, event-driven spiking activation units. We train the proposed model on two model variants: 45M and 216M parameters. To the best of our knowledge, SpikeGPT is the largest backpropagation-trained SNN model to date, rendering it suitable for both the generation and comprehension of natural language. We achieve this by modifying the transformer block to replace multi-head self attention to reduce quadratic computational complexity O(N^2) to linear complexity O(N) with increasing sequence length. Input tokens are instead streamed in sequentially to our attention mechanism (as with typical SNNs). Our preliminary experiments show that SpikeGPT remains competitive with non-spiking models on tested benchmarks, while maintaining 20x fewer operations when processed on neuromorphic hardware that can leverage sparse, event-driven activations. Our code implementation is available at https://github.com/ridgerchu/SpikeGPT.", "venue": "arXiv.org", "year": 2023, "citationCount": 54, "influentialCitationCount": 2, "openAccessPdf": {"url": "http://arxiv.org/pdf/2302.13939", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper successfully implements `SpikeGPT', a generative language model with binary, event-driven spiking activation units, and is the largest backpropagation-trained SNN model to date, rendering it suitable for both the generation and comprehension of natural language."}, "embedding": {"model": "specter_v2", "vector": [0.774475634098053, 0.5654326677322388, 0.5194164514541626, -0.28511539101600647, -0.10538119822740555, -0.26314419507980347, 0.8253964185714722, -0.22871582210063934, -0.5074517130851746, -0.3326876163482666, 0.4247072637081146, 0.062253668904304504, 0.7181101441383362, -0.3036384880542755, -0.5767684578895569, -0.049454789608716965, -0.719873309135437, -0.06937944144010544, 0.1334630399942398, -0.13820913434028625, 0.4178512990474701, -0.8335838317871094, -1.1812269687652588, 0.09238388389348984, -0.256268173456192, 0.6912776231765747, 0.3993403911590576, 1.0385148525238037, -0.6148005723953247, 0.2565789818763733, 0.49169665575027466, -0.12553207576274872, 0.10552126169204712, -0.042895663529634476, -0.22110573947429657, -0.25624337792396545, 0.007006686646491289, 0.054790861904621124, -0.5557511448860168, 0.887915849685669, -0.04727596789598465, 0.09735232591629028, 0.26488029956817627, -0.7362194061279297, -0.34094780683517456, 1.3868603706359863, 0.5974486470222473, 0.6988964676856995, -0.44073858857154846, 0.014469494111835957, 0.8619024157524109, -1.0963813066482544, 0.20795026421546936, 1.3035649061203003, 0.14133748412132263, 0.895377516746521, -0.22507642209529877, -0.9579541087150574, 0.8259884119033813, -0.6880239248275757, -0.6428837180137634, -0.21352021396160126, 0.05392685532569885, 0.081937275826931, 1.8866539001464844, -0.4433801472187042, 0.6652867197990417, 1.4396328926086426, 0.31170377135276794, 1.0001475811004639, 0.30462703108787537, -0.5387826561927795, 0.1300077587366104, 0.018012670800089836, 0.2943470776081085, 0.5171344876289368, -0.17002169787883759, 0.26316386461257935, -0.9150574803352356, -0.057610854506492615, 0.7863848209381104, -0.052642278373241425, 0.46935176849365234, 0.016790447756648064, -0.5237025618553162, 0.8323569297790527, 0.3868975043296814, 0.9714207649230957, -0.10937478393316269, 1.022493839263916, 0.4028968811035156, -0.17640355229377747, -0.3441134989261627, 0.41811302304267883, 0.09799803048372269, 0.29674431681632996, -0.8641716241836548, 0.24571183323860168, -0.11398494243621826, 0.8565503358840942, -0.31463557481765747, 0.8679545521736145, -0.7873111367225647, -0.2181643396615982, 1.5878986120224, 0.2859398424625397, 0.4336391091346741, -0.7026323080062866, -0.1314600706100464, -0.9500611424446106, -0.2180166095495224, -0.5640597343444824, -0.04755686968564987, -0.39902442693710327, -0.7711229920387268, -1.373957872390747, -0.44561949372291565, 0.08650139719247818, -1.160064697265625, 1.2756587266921997, -0.8312457203865051, 0.431338906288147, 0.27991655468940735, 0.03875689581036568, 0.8793617486953735, 0.8419606685638428, 0.5796450972557068, 0.4703969359397888, 0.9372029304504395, -0.26505905389785767, -0.37482577562332153, -1.3661912679672241, 0.005093581974506378, 0.10724176466464996, -0.025674641132354736, -0.15402980148792267, -1.192158818244934, -0.8690280914306641, -0.5697081089019775, 0.2586188018321991, -0.49775034189224243, -0.0841275155544281, 1.5693386793136597, 0.5440292954444885, -1.391445517539978, 0.7102186679840088, -0.354078471660614, -0.48137813806533813, 0.6698171496391296, 0.33423861861228943, 0.4769749939441681, 0.22692270576953888, -1.358565330505371, 0.08372613787651062, 0.20717640221118927, -0.3859483301639557, -0.30529770255088806, -0.21819822490215302, -1.1283339262008667, 0.018862679600715637, -0.05256301537156105, -0.5806927680969238, 1.1573429107666016, -0.055568404495716095, -1.0673060417175293, 1.2436554431915283, -0.418393075466156, -0.25179532170295715, -0.10558182001113892, 0.3313910961151123, -0.4385283589363098, -0.7622641921043396, -0.2635457217693329, 0.8788976669311523, 0.563238799571991, -0.22975504398345947, 0.21367163956165314, 0.3673313856124878, -0.7633124589920044, -0.6648766994476318, -0.1465180367231369, 1.1399786472320557, -0.21558566391468048, -0.3679908514022827, 0.34491482377052307, 0.42023566365242004, -0.05232127755880356, -0.28440573811531067, -0.6053827404975891, -1.0002691745758057, 0.41890767216682434, 0.3612014651298523, 0.473508358001709, -1.008863925933838, -1.124344825744629, 0.11839595437049866, -0.1817198544740677, -0.16844254732131958, -0.8074113130569458, 0.4157598316669464, -0.5230332612991333, 0.4042872190475464, -0.31037575006484985, -0.7192599177360535, 0.0014494439819827676, -0.17758622765541077, -0.8589368462562561, -0.33769434690475464, 0.6624539494514465, 1.3296915292739868, -0.8976801037788391, 0.24269041419029236, -0.006069011054933071, 0.5386331081390381, -1.0817772150039673, 1.0170514583587646, -0.13246797025203705, 0.30051225423812866, -0.32553231716156006, -0.5433439016342163, -0.01870879903435707, -0.5207660794258118, 0.08153919130563736, -0.08383611589670181, -0.028895186260342598, 0.5654914975166321, -0.4223306477069855, 1.641484022140503, -0.15249300003051758, 0.43079471588134766, -0.2686227560043335, -0.7098057270050049, 0.8216598629951477, 0.02940456196665764, -0.41155731678009033, -0.5267461538314819, 0.5874218940734863, 0.4232841730117798, -0.5016708970069885, 0.2929932177066803, 0.2484411597251892, 0.9812117218971252, -0.5204424262046814, 0.11890065670013428, 0.7775528430938721, -0.5684640407562256, 0.27776554226875305, 0.7314099669456482, 0.7706447243690491, 0.23050299286842346, 0.5065907835960388, -0.4068829417228699, 0.018694385886192322, -1.3000632524490356, -0.10303148627281189, 0.866813063621521, 0.683051347732544, 1.1012766361236572, 0.4662526845932007, -0.7282251715660095, -0.1509914994239807, -0.4329957962036133, 0.6080910563468933, 0.9492001533508301, -0.31803858280181885, 0.20535695552825928, -0.8912058472633362, 0.46918827295303345, -0.5676008462905884, 0.1813051402568817, -0.34484633803367615, -0.3785691261291504, -0.40254852175712585, -1.1824262142181396, 0.662824809551239, 0.280610054731369, 0.47638368606567383, -1.390492558479309, -0.4590201675891876, -0.08924316614866257, 0.42015334963798523, -0.9442992806434631, -0.5788257718086243, 0.6773266792297363, -0.4056733548641205, 0.476182758808136, -0.15646137297153473, -0.2688872516155243, 0.2451212853193283, -1.0306793451309204, 0.8444239497184753, -0.8399584889411926, -0.7058937549591064, 0.04007446765899658, 1.0425041913986206, -0.8117919564247131, -0.7555992603302002, 0.01812571845948696, -0.030577972531318665, -0.020363638177514076, 0.3181943893432617, 0.0770326778292656, -0.19545453786849976, -0.586012065410614, -0.41859444975852966, 0.278185099363327, 0.10656347125768661, -0.22994570434093475, 0.5526379346847534, -0.8516673445701599, 0.03320924565196037, -1.0086177587509155, 0.681721568107605, 0.17462429404258728, -0.3417210876941681, -0.041734129190444946, -0.26699039340019226, 0.066363126039505, 0.1511661559343338, -0.616060733795166, -0.09618183225393295, -0.447931706905365, 0.10420731455087662, 0.03938070684671402, -0.23861274123191833, -0.2116098552942276, 0.6624717116355896, 0.07891877740621567, 0.1097060963511467, 1.0819658041000366, 0.18195071816444397, 0.7104436755180359, 0.30939891934394836, -1.0516886711120605, 0.7034686803817749, 0.18323545157909393, 0.17928101122379303, -0.03066641092300415, -0.30512478947639465, -0.5712183117866516, -0.32948869466781616, 0.10397723317146301, 0.44152554869651794, -0.4014422595500946, 0.32955196499824524, -0.7586599588394165, -1.372423529624939, 0.6137121319770813, -1.0810133218765259, -0.24442267417907715, -0.038326866924762726, -0.3649078607559204, -0.3930562436580658, -1.0387307405471802, -1.1387085914611816, -0.972173810005188, -0.6390660405158997, -0.6396232843399048, 0.27310436964035034, 0.5388296246528625, -0.49370548129081726, -0.24984294176101685, -0.1775842308998108, -0.803510844707489, 1.4150761365890503, -0.47679394483566284, 0.47784876823425293, -0.2677716016769409, -0.3834969103336334, -0.13373161852359772, 0.23322175443172455, 0.2513298988342285, -0.44616320729255676, 0.556892991065979, -0.9065954685211182, 0.242863267660141, -0.49384361505508423, -0.41875165700912476, 0.4938024878501892, 0.8006159067153931, 1.1519814729690552, 0.33069971203804016, -0.3630046546459198, 0.38994961977005005, 1.598021149635315, -0.3090741038322449, 0.1782752424478531, -0.14783501625061035, 0.5611947178840637, 0.14569690823554993, -1.010313868522644, 0.7159765362739563, 0.5755277276039124, 0.05160660296678543, 0.25527721643447876, 0.20329724252223969, 0.19943426549434662, -0.7351745963096619, 0.32213807106018066, 1.3712189197540283, 0.28379565477371216, -0.1203978881239891, -0.9913646578788757, 0.7742363214492798, -0.728410542011261, -0.7013653516769409, 0.7436435222625732, 0.7242779731750488, 0.36137837171554565, 0.04179499298334122, -0.7049298286437988, -0.14588062465190887, 0.7520140409469604, 0.30391448736190796, -0.3313353955745697, -1.1938846111297607, -0.441976398229599, 0.914777398109436, 0.07154008746147156, 0.1928950846195221, -0.23090197145938873, 0.4616687595844269, 14.630552291870117, 0.3278481960296631, -0.38072776794433594, 0.18744365870952606, 0.7684500813484192, 0.30063000321388245, -0.7624775171279907, -0.18638232350349426, -1.564846158027649, 0.06109360232949257, 1.2532157897949219, 0.298349529504776, 0.7761650085449219, 0.0398208424448967, -0.07183422148227692, 0.26424673199653625, -0.20153097808361053, 0.8318281769752502, 0.45709851384162903, -1.285049557685852, 0.1954689621925354, -0.06221978738903999, 0.3387044072151184, 0.6420207023620605, 1.0234220027923584, 0.8385634422302246, 0.6385678648948669, -0.3119072914123535, 0.7131810188293457, 0.43098634481430054, 0.5430265665054321, 0.4052864611148834, -0.062045853585004807, 0.22494493424892426, -0.9825710654258728, -0.1998356729745865, -0.43095284700393677, -1.121584415435791, 0.19293422996997833, 0.16947300732135773, 0.11178096383810043, -0.8210932016372681, 0.0493692122399807, 0.6235817670822144, 0.27981775999069214, 0.2527059316635132, 0.011537869460880756, 0.7171148061752319, -0.37328481674194336, -0.686870276927948, 0.3504851460456848, 0.5512787103652954, 0.08824920654296875, -0.007593885064125061, 0.45129382610321045, 0.07707997411489487, -0.22151055932044983, 1.301108717918396, -0.38271260261535645, -0.23443721234798431, -0.3265000283718109, -0.5911697745323181, 0.07726267725229263, 0.8135247230529785, -0.17028175294399261, 0.398078978061676, -0.26919907331466675, 0.2478528469800949, 0.09150201827287674, 0.2657490670681, -0.39185553789138794, -0.052453670650720596, 0.15124188363552094, -0.5469352602958679, 0.3135303258895874, 0.6321778893470764, -0.2727985084056854, -0.5103811025619507, -0.6170333027839661, 0.05077943205833435, -0.006638487800955772, -1.0346249341964722, -0.7456547617912292, 1.1072931289672852, -0.552045464515686, 0.018736431375145912, 0.24885162711143494, -0.6949848532676697, -0.5878552198410034, 0.5501166582107544, -1.2635960578918457, -0.6992328763008118, 0.12292353808879852, -0.28912243247032166, -0.5347475409507751, -0.04089680686593056, 1.2552610635757446, -0.45999303460121155, -0.3760705292224884, -0.28315791487693787, -0.3795160949230194, -0.004355010576546192, -0.607502818107605, -0.7137824892997742, 1.4298820495605469, 0.2500697076320648, 0.023433828726410866, 0.5678576231002808, 0.29159075021743774, 0.2992924451828003, -0.6833786368370056, 0.03447164595127106, 1.123073935508728, -0.7570757865905762, -0.3788743019104004, -1.2298582792282104, -0.6844329237937927, 0.22963760793209076, 0.6279681324958801, 0.10884737968444824, -0.09442582726478577, -0.2421005666255951, -0.6977099776268005, 0.007383515127003193, -0.6585862636566162, 0.05855431780219078, 0.5544060468673706, -0.7234454154968262, -0.2341829538345337, -0.4890913963317871, 0.09516578912734985, -0.6582871079444885, 0.008665601722896099, -0.22735212743282318, 0.2556636333465576, -0.08760043233633041, 0.9556912779808044, -0.3525336682796478, 0.5648966431617737, 0.8770766258239746, 0.058730464428663254, -0.554110050201416, -0.21383939683437347, -1.198367714881897, 0.30195197463035583, 0.21044279634952545, 0.5523527264595032, -0.7329534888267517, 0.3940916657447815, 0.523565411567688, 0.34409448504447937, -0.4351034164428711, -0.5912591218948364, -0.25577011704444885, 0.050080470740795135, -0.7257499694824219, 0.3330613672733307, -0.21120667457580566, -0.37137335538864136, -0.03195122629404068, 0.3650294244289398, 0.2367062121629715, -0.10344725847244263, -0.78017258644104, -0.104429230093956, -0.23902955651283264, -0.27767661213874817, -0.6842537522315979, -0.707590639591217, -1.0609657764434814, -0.12313212454319, -1.3241864442825317, 0.10457465797662735, -0.8801383376121521, 0.033972494304180145, 0.27281224727630615, -0.6304184794425964, 0.2880588471889496, 0.405712366104126, -0.15513677895069122, -0.5468974709510803, -1.1768404245376587, -0.23048563301563263, 0.47713392972946167, 0.47942766547203064, -0.6337484121322632, 0.12858544290065765, -0.0473080649971962, -0.28939175605773926, 0.008146936073899269, 0.45521479845046997, -0.7729997634887695, -0.619297981262207, -1.2073230743408203, 0.7207668423652649, -0.22076594829559326, 0.4062650799751282, -1.1765788793563843, 0.7146780490875244, 0.7273459434509277, -0.17042572796344757, 0.15691034495830536, 0.36256611347198486, -0.3178083896636963, -0.25195321440696716, 0.6413655877113342, -0.8212695121765137, -0.05933106690645218, 0.3974801003932953, -0.5056673884391785, 0.007610904518514872, 0.8931618332862854, -0.0228588730096817, -1.2276983261108398, -0.7631333470344543, 0.7069177627563477, -0.9794405102729797, 0.37303370237350464, -0.15801143646240234, -0.4920613765716553, -0.8762778043746948, -0.3801547884941101, -0.2835584282875061, 0.06744915246963501, -0.7691419720649719, 1.2977330684661865, 0.7804306149482727, -0.7589671611785889, -0.15955790877342224, 0.7892588376998901, 0.10014624893665314, -0.24474526941776276, 0.5249735116958618, 0.10232333093881607, -0.10124516487121582, 0.6296699643135071, -0.07785577327013016, 0.12458007037639618, -0.49342888593673706, -0.23745214939117432, 0.7035819888114929, -0.011003867723047733, -0.10948215425014496, 1.3738133907318115, -0.13565778732299805, -1.1733677387237549, 0.100979283452034, -1.6331186294555664, -0.6212753653526306, -0.5442081093788147, 0.27105990052223206, -0.7103089094161987, -0.2481001913547516, 0.15970928966999054, -0.4022047221660614, 0.5511705875396729, 0.2887752652168274, -0.4376741051673889, 0.6446146965026855, 0.18562504649162292, -0.18188130855560303, 0.7609047889709473, 0.6465332508087158, -1.015785574913025, -0.7951222658157349, -0.7228142619132996, -0.5166547298431396, 0.3882707953453064, 0.23934988677501678, -0.08908837288618088, -1.0034135580062866, 1.0724257230758667, 0.5758779048919678, 0.23181350529193878, -0.015520144253969193, 0.03962605819106102, 0.11133749783039093, 0.41160666942596436, 0.3566579222679138, -0.332530677318573, -0.3305472135543823, 1.4651352167129517, 0.8663789629936218, -0.6900920271873474, -0.4621630907058716, -0.4672534465789795, -0.7725663185119629, 0.7356314659118652, 0.17782799899578094, -0.3189180791378021, 0.9889695644378662, 0.08904679864645004, -0.16207945346832275, 0.17338445782661438, -1.1926183700561523, 0.057391125708818436, 0.34338781237602234, 0.9298177361488342, 0.8677629232406616, 0.3305504024028778, 0.08942387253046036, 1.0507781505584717, 0.05316852405667305, 0.3925749659538269, 0.5588307976722717, 0.6511461138725281, -0.17078079283237457, 0.23604048788547516, 0.28123053908348083, 0.8905580639839172, -0.8321365714073181, -0.85145503282547, 0.44731730222702026, -0.09313143789768219, -0.12010001391172409, 0.3606905937194824, 1.1284773349761963, 0.20026002824306488, 0.4758940041065216, 0.05387883260846138, 0.8038395047187805, -0.6395019292831421, -0.33225885033607483, -0.1798890382051468, -0.889726996421814, -0.11722155660390854, -0.1633332371711731, -0.6870868802070618, -0.6143678426742554, 0.1666191667318344, 0.4067095220088959, -0.2772805392742157, 0.5824425220489502, 0.9253553748130798, 0.3437565267086029, 0.599527895450592, -0.11809943616390228, -0.5825079679489136, -0.21679845452308655, -0.5413090586662292, -0.06087743863463402, -0.5143532156944275, -0.346570760011673, 0.07943537831306458, -0.1192963719367981, -0.226228266954422]}, "authors": [{"authorId": "144649570", "name": "Rui Zhu"}, {"authorId": "2110483969", "name": "Qihang Zhao"}, {"authorId": "3444950", "name": "J. Eshraghian"}], "references": [{"paperId": "21fd0499167799a9d7365280ea3e168584e8db48", "title": "Spiking Convolutional Neural Networks for Text Classification"}, {"paperId": "401c4147375b016d4758cf2dd859232a8271fdcd", "title": "Scalable MatMul-free Language Modeling"}, {"paperId": "07e7b418a24891a7335075748c429cfb6af50884", "title": "SQUAT: Stateful Quantization-Aware Training in Recurrent Spiking Neural Networks"}, {"paperId": "8723dc63469c56d6a3c038d54ea3407228da4c44", "title": "Optically Tunable Electrical Oscillations in Oxide\u2010Based Memristors for Neuromorphic Computing"}, {"paperId": "7af0b5ba28bd386fb2141207498e168df7e98ccb", "title": "Is Conventional SNN Really Efficient? A Perspective from Network Quantization"}, {"paperId": "12dfca34cdd2662f4ae8fee9e9f1cb785bb6fa8e", "title": "Tensor Decomposition Based Attention Module for Spiking Neural Networks"}, {"paperId": "c96297261467b5daa2d01227496a70d444602434", "title": "Baichuan 2: Open Large-scale Language Models"}, {"paperId": "60a1bd9e010e341e101892a3d29d72ac5d8d35fa", "title": "SpikeBERT: A Language Spikformer Learned from BERT with Knowledge Distillation"}, {"paperId": "cd1c724ad7a01186711add767cea2811af720dd1", "title": "SpikingBERT: Distilling BERT to Train Spiking Language Models Using Implicit Differentiation"}, {"paperId": "b9a6a6dee5803d9d4c6a6d4bb3da59fe512459ca", "title": "Gated Attention Coding for Training High-performance and Efficient Spiking Neural Networks"}, {"paperId": "7a47444ce5842e03b7bf23e74ea8a80e1755cd8a", "title": "Implementing and Benchmarking the Locally Competitive Algorithm on the Loihi 2 Neuromorphic Processor"}, {"paperId": "6bd3ee1ca608bc66a490f63f2fb107d79b44f3e2", "title": "LLM-QAT: Data-Free Quantization Aware Training for Large Language Models"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "78f599fbd62dcc4a8dbab9d2f6056815dfc5b84c", "title": "The MiniPile Challenge for Data-Efficient Language Models"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "65679db595cda4870fedeb6272cf4a74ad634b9b", "title": "OpenSpike: An OpenRAM SNN Accelerator"}, {"paperId": "b89f19883d160778fc5b72f017cf537173361eec", "title": "Intelligence Processing Units Accelerate Neuromorphic Learning"}, {"paperId": "fd5953a89731b91fab564525a21af819912a5b27", "title": "Spikeformer: A Novel Architecture for Training High-Performance Low-Latency Spiking Neural Network"}, {"paperId": "2c994fadbb84fb960d8306ee138dbeef41a5b323", "title": "SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models"}, {"paperId": "ffd91f85d6d19e75309ececfd190afa6bb562284", "title": "Spikformer: When Spiking Neural Network Meets Transformer"}, {"paperId": "9c5cd94bbe92b831b12149b9504c25afc8d00d3d", "title": "Attention Spiking Neural Networks"}, {"paperId": "3f6243097a58e386aea1215fed4f372dee07a100", "title": "Outlier Suppression: Pushing the Limit of Low-bit Transformer Language Models"}, {"paperId": "c90a99eeb57019732a6cc996bb9eaf13faedf00f", "title": "In-context Learning and Induction Heads"}, {"paperId": "4be7d1524edb0137599a5cc95f72844b85a52fe1", "title": "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale"}, {"paperId": "2307cc54494e7738bf5082ebb447ec41b548b9fc", "title": "TCJA-SNN: Temporal-Channel Joint Attention for Spiking Neural Networks"}, {"paperId": "03c028d84606ba2de0e8b777585ca61d0bca8633", "title": "Spiking Neural Networks for Frame-based and Event-based Single Object Localization"}, {"paperId": "9a5fe0ac9d16df142fdad4b2f129ecd480b2ea7d", "title": "Object Detection with Spiking Neural Networks on Automotive Event Data"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "d1369954af4a700f0061c58863c6d8935da0bf53", "title": "Memristor-Based Binarized Spiking Neural Networks: Challenges and applications"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "b45c0940059ab45c15c7eec16d295b841cc1b913", "title": "The fine line between dead neurons and sparsity in binarized spiking neural networks"}, {"paperId": "1921489a2801f053d0906079f0015ba6e68dd505", "title": "DIET-SNN: A Low-Latency Spiking Neural Network With Direct Input Encoding and Leakage and Threshold Optimization"}, {"paperId": "e3695e70c01ecea526ecf30f4d2c4e71d7930e24", "title": "Efficient Neuromorphic Signal Processing with Loihi 2"}, {"paperId": "2ace8667f2b331001136391cae237d50c0db6383", "title": "Training Spiking Neural Networks Using Lessons From Deep Learning"}, {"paperId": "62d1464cc4c0b98df3d835a4cf46eb63dd038ae7", "title": "Sparsity provides a competitive advantage"}, {"paperId": "238c2c55bf23dd516e6c1de6aa2f0c25516440c1", "title": "Temporal-wise Attention Spiking Neural Networks for Event Streams Classification"}, {"paperId": "d5e999aae76d5270ef272076979c809817458212", "title": "An Attention Free Transformer"}, {"paperId": "35fcc65db264d9c73ed19d0f3f9d53a43991bdbf", "title": "Deep Residual Learning in Spiking Neural Networks"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "4a54d58a4b20e4f3af25cea3c188a12082a95e02", "title": "Transformer Feed-Forward Layers Are Key-Value Memories"}, {"paperId": "0fdcb620b4ca0f17f9ba8ed79c1cea210c753478", "title": "RANC: Reconfigurable Architecture for Neuromorphic Computing"}, {"paperId": "b6c5f9d87df735b436884a4286f0ecdbee4a73c6", "title": "A system hierarchy for brain-inspired computing"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "805d950d6df9bdabd6b87d06de213909192341db", "title": "The carbon impact of artificial intelligence"}, {"paperId": "de5157a3d62ab114813379a6568f716b483feece", "title": "Carbontracker: Tracking and Predicting the Carbon Footprint of Training Deep Learning Models"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "a238109c3969ae681eee0d4f1bf2012f28850593", "title": "Synthesizer: Rethinking Self-Attention in Transformer Models"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "b9ed2fd3237539b0ad539dad8bdee15efbe0a26e", "title": "Single Headed Attention RNN: Stop Thinking With Your Head"}, {"paperId": "0ebca477733c79e13900d1b4e00b67a9b7bf8abd", "title": "Towards spike-based machine intelligence with neuromorphic computing"}, {"paperId": "71b411d47ae7b9cf8f6ff26dc2eda8e5038ef94c", "title": "Spiking-YOLO: Spiking Neural Network for Energy-Efficient Object Detection"}, {"paperId": "409e5a3b7c25cd0cfcf0ff37cc47f7625c09f2fb", "title": "Surrogate Gradient Learning in Spiking Neural Networks: Bringing the Power of Gradient-based optimization to spiking neural networks"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "f7d8783648ef685eb020bda8a41b8bc5ced5c2a1", "title": "Deep Learning With Spiking Neurons: Opportunities and Challenges"}, {"paperId": "a67b7966cd8cdff0c9195cf719ac8ebf38c40b8e", "title": "Loihi: A Neuromorphic Manycore Processor with On-Chip Learning"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "1d1802480eeb320d2f48bccee669c02804dbaa99", "title": "Spatio-Temporal Backpropagation for Training High-Performance Spiking Neural Networks"}, {"paperId": "88caa4a0253a8b0076176745ebc072864eab66e1", "title": "Language Modeling with Gated Convolutional Networks"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "e457aabc35b6a7bd07ea8efc2d9d2700ff27c2ee", "title": "Conversion of artificial recurrent neural networks to spiking neural networks for low-power neuromorphic hardware"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "32de44f01a96d4473d21099d15e25bc2b9f08e2f", "title": "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks"}, {"paperId": "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba", "title": "Convolutional Neural Networks for Sentence Classification"}, {"paperId": "680a38e8f025685b192e9e0cf755c6b664963551", "title": "A million spiking-neuron integrated circuit with a scalable communication network and interface"}, {"paperId": "947620a1854655ed91a86b90d12695e05be85983", "title": "1.1 Computing's energy problem (and what we can do about it)"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "6471fd1cbc081fb3b7b5b14d6ab9eaaba02b5c17", "title": "Generating Sequences With Recurrent Neural Networks"}, {"paperId": "56a1b9015adc0bf0118b7cda4f4727075520bbc8", "title": "Lapicque\u2019s 1907 paper: from frogs to integrate-and-fire"}, {"paperId": "6af58c061f2e4f130c3b795c21ff0c7e3903278f", "title": "Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales"}, {"paperId": "167e1359943b96b9e92ee73db1df69a1f65d731d", "title": "A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "4aa95dc3682d664b333a868ce350d1567abc47cd", "title": "Contributors"}, {"paperId": "5d11aad09f65431b5d3cb1d85328743c9e53ba96", "title": "The perceptron: a probabilistic model for information storage and organization in the brain."}, {"paperId": "0d499ac0de809d38210140ab6e21c2e399838987", "title": "A quantitative description of membrane current and its application to conduction and excitation in nerve"}, {"paperId": "4b483e210881b8949fb784f7c8e5e2a68603e63b", "title": "Towards Energy-Preserving Natural Language Understanding With Spiking Neural Networks"}, {"paperId": "b8b45b14df9029562b8995c6ab7fd90a8810f312", "title": "GPT3.int8(): 8-bit Matrix Multiplication for Transformers at Scale"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Large text compression benchmark"}, {"paperId": "9ef2c863159e9f9a79000e3c35cb3f41536897fd", "title": "Networks of Spiking Neurons: The Third Generation of Neural Network Models"}, {"paperId": null, "title": "Recherches quantitatives sur l\u2019excitation electrique des nerfs traitee comme une polarization"}, {"paperId": null, "title": "Optimizing language models for dialogue"}]}