{"paperId": "722ae1415e102ff258d5cbf31cfaacd6fd31d99f", "title": "Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers", "abstract": "Sora unveils the potential of scaling Diffusion Transformer for generating photorealistic images and videos at arbitrary resolutions, aspect ratios, and durations, yet it still lacks sufficient implementation details. In this technical report, we introduce the Lumina-T2X family - a series of Flow-based Large Diffusion Transformers (Flag-DiT) equipped with zero-initialized attention, as a unified framework designed to transform noise into images, videos, multi-view 3D objects, and audio clips conditioned on text instructions. By tokenizing the latent spatial-temporal space and incorporating learnable placeholders such as [nextline] and [nextframe] tokens, Lumina-T2X seamlessly unifies the representations of different modalities across various spatial-temporal resolutions. This unified approach enables training within a single framework for different modalities and allows for flexible generation of multimodal data at any resolution, aspect ratio, and length during inference. Advanced techniques like RoPE, RMSNorm, and flow matching enhance the stability, flexibility, and scalability of Flag-DiT, enabling models of Lumina-T2X to scale up to 7 billion parameters and extend the context window to 128K tokens. This is particularly beneficial for creating ultra-high-definition images with our Lumina-T2I model and long 720p videos with our Lumina-T2V model. Remarkably, Lumina-T2I, powered by a 5-billion-parameter Flag-DiT, requires only 35% of the training computational costs of a 600-million-parameter naive DiT. Our further comprehensive analysis underscores Lumina-T2X's preliminary capability in resolution extrapolation, high-resolution editing, generating consistent 3D views, and synthesizing videos with seamless transitions. We expect that the open-sourcing of Lumina-T2X will further foster creativity, transparency, and diversity in the generative AI community.", "venue": "arXiv.org", "year": 2024, "citationCount": 13, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This technical report introduces the Lumina-T2X family - a series of Flow-based Large Diffusion Transformers (Flag-DiT) equipped with zero-initialized attention, as a unified framework designed to transform noise into images, videos, multi-view 3D objects, and audio clips conditioned on text instructions."}, "embedding": {"model": "specter_v2", "vector": [0.512316882610321, 0.44617629051208496, 0.011073957197368145, 0.19038881361484528, -0.2631751000881195, -0.4417749047279358, 0.9658811688423157, -0.47500738501548767, -0.02408234030008316, -0.7496031522750854, 0.7529709935188293, 0.579485297203064, -0.05198833718895912, -0.16793397068977356, -0.10226152092218399, 0.08963678777217865, -0.9836184978485107, 0.3424801528453827, 0.06440999358892441, -0.3223111033439636, 0.0723792016506195, -0.10483511537313461, -1.1574695110321045, 0.3985951244831085, 0.12471146881580353, 0.9611718058586121, -0.05988470837473869, 1.266273856163025, -0.3586050570011139, 0.4121548533439636, 0.11666668951511383, -0.12003665417432785, 0.5669042468070984, 0.003432708326727152, -0.3310631811618805, 0.16661779582500458, 0.5693843960762024, -0.4270908534526825, -0.9116268157958984, 0.411702424287796, 0.033005524426698685, 0.29254254698753357, 0.8791553378105164, -0.4765355885028839, -0.7150949239730835, 0.32464367151260376, 0.2697668969631195, 0.7793281078338623, 0.23184096813201904, -0.42096176743507385, 1.078586220741272, -1.3068290948867798, 0.6673957705497742, 1.808739423751831, 0.0736996978521347, 0.4382055103778839, -0.319260835647583, -0.2760566473007202, 0.6612620949745178, 0.15210281312465668, -0.6233071684837341, -0.3330674469470978, -0.034083444625139236, -0.5763656497001648, 1.2064571380615234, -0.4114901125431061, 0.5374609231948853, 1.2444422245025635, -0.14601844549179077, 1.6780614852905273, -0.08043234050273895, -0.943037211894989, -0.11852989345788956, -0.07341307401657104, -0.3070329427719116, 0.7172302603721619, -1.0468961000442505, 0.5207056999206543, -0.9325161576271057, 0.3108842372894287, 1.003377079963684, -0.27381420135498047, 0.0825175866484642, -0.08565066009759903, -0.3985356390476227, 0.513699471950531, 0.5644766688346863, 0.9664924740791321, -0.1469125747680664, 0.7684547901153564, 0.5005500912666321, 0.10609155893325806, 0.17086739838123322, 0.05075891688466072, 0.27809783816337585, 0.14084123075008392, -0.8400974273681641, 0.41741129755973816, -0.2809281051158905, 0.7920549511909485, -0.29814717173576355, 0.31115081906318665, -1.066619634628296, 0.33796608448028564, 0.9540258049964905, 0.19890253245830536, 0.43207353353500366, -1.081206202507019, 0.005479445215314627, -0.7939112186431885, 0.3376767039299011, -0.9122025966644287, -0.01304343156516552, 0.18553271889686584, -0.8872606158256531, -0.8253105878829956, -0.20897679030895233, 0.3444339632987976, -1.2765995264053345, 0.5745302438735962, -0.04229491204023361, 0.07521790266036987, -0.1463753879070282, 0.7896287441253662, 0.5766565203666687, 0.7470976114273071, 0.08791018277406693, 0.35656028985977173, 0.8970018625259399, -0.9057604670524597, -0.8235284686088562, -0.8702315092086792, 0.22701050341129303, -0.009815414436161518, 0.529889702796936, 0.10374438762664795, -1.416702389717102, -0.9909440875053406, -0.7041537761688232, -0.24267537891864777, -0.5895256400108337, 0.2577756643295288, 1.4006950855255127, 0.38670626282691956, -0.6615278124809265, 0.496297687292099, -0.2951042950153351, -0.34521499276161194, 0.7991330623626709, -0.30952852964401245, -0.05962817370891571, -0.5544634461402893, -0.835418701171875, 0.1462087780237198, -0.03273360803723335, -0.06946680694818497, -0.36121174693107605, -0.5821577906608582, -1.2858490943908691, -0.2422877848148346, 0.35396328568458557, -0.6406186819076538, 0.9241865277290344, -0.3313756287097931, -1.2043864727020264, 0.7691526412963867, -0.3102755546569824, 0.41626131534576416, 0.743669867515564, -0.44163453578948975, -0.3305029273033142, -0.09919654577970505, -0.1638742834329605, 1.1136926412582397, 0.8050273656845093, -0.22216296195983887, -0.26559141278266907, 0.03540366142988205, -0.09322070330381393, 0.006123851984739304, -0.061961330473423004, 0.8784116506576538, -0.5585586428642273, -0.2861924171447754, 0.11139045655727386, 0.668242335319519, 0.11382865905761719, -0.024516791105270386, -0.2455751895904541, -0.9346269965171814, 1.0462807416915894, 0.37954404950141907, 0.516616940498352, -1.123164415359497, -0.12021056562662125, -0.46498361229896545, 0.23331446945667267, -0.753460705280304, -1.010669469833374, 0.5286595821380615, -0.18556873500347137, 0.4547175168991089, 0.04917462170124054, -0.9877280592918396, 0.2542354464530945, -0.1934645026922226, -0.6131249070167542, -0.024548478424549103, 0.3302516043186188, 1.2861838340759277, -0.6455793976783752, -0.15692982077598572, 0.2005482316017151, 0.4589577913284302, -0.8640061020851135, 1.0553785562515259, -0.6338333487510681, 0.47823211550712585, -0.23520460724830627, -0.03284389153122902, -0.05459574609994888, -0.16196919977664948, 0.01986013539135456, -0.5390730500221252, 0.02203705534338951, 0.10783611238002777, -0.4692016839981079, 1.9173877239227295, -0.19282935559749603, 0.8731409311294556, -0.26804012060165405, -0.4878346621990204, 0.21877355873584747, 0.4274049699306488, 0.17396695911884308, -0.5600000023841858, 0.20869213342666626, 0.11545703560113907, -0.8482873439788818, -0.314797043800354, 0.7159671783447266, 0.5520948767662048, -0.459100604057312, -0.2398717999458313, 0.3649538457393646, -0.6186003088951111, 0.6320971846580505, 0.7223570346832275, 0.8079324960708618, 0.8196008801460266, -0.32203206419944763, 0.041371770203113556, -0.20744553208351135, -0.9991697072982788, -0.2547367215156555, 0.6471695899963379, 0.528340756893158, 1.353774070739746, 0.489934504032135, -1.032936453819275, -0.640447735786438, -0.1599939614534378, 0.6762895584106445, 1.104355812072754, 0.010143782012164593, -0.5196333527565002, -0.3913743793964386, -0.22084282338619232, -0.41681382060050964, -0.47102653980255127, -1.0632238388061523, 0.0022602786775678396, -0.3611145615577698, -0.4442901611328125, 0.654116153717041, 0.4540860056877136, 0.994352400302887, -0.9873373508453369, -0.5056097507476807, -0.4903360903263092, 0.02035251073539257, -0.8579813241958618, -0.5842801928520203, -0.23786704242229462, 0.13391150534152985, 0.20576737821102142, -0.4467882513999939, -0.18571944534778595, 0.09974195808172226, -0.8616276979446411, 0.5893368124961853, -0.7476622462272644, -0.9363556504249573, 0.6004308462142944, 0.4414873421192169, -0.3174712657928467, -0.5655504465103149, -0.09846056252717972, -0.05239237844944, -0.09685607254505157, -0.18947885930538177, 0.18493670225143433, -0.22032839059829712, 0.09007735550403595, -0.9178138971328735, 0.23732680082321167, -0.13447341322898865, -0.3598872125148773, 0.34051376581192017, -0.22273759543895721, -0.09213820099830627, -0.733887255191803, 0.7430146336555481, 0.34707292914390564, -0.22021149098873138, -0.032867494970560074, -0.15635588765144348, -0.6390798687934875, 0.08154396712779999, -1.1341420412063599, -0.44485795497894287, -0.7209261655807495, 0.5606780648231506, -0.6096154451370239, -0.6794531345367432, -0.07767662405967712, 0.29052406549453735, 0.4367316961288452, 0.6828437447547913, 0.07304491847753525, -0.1601742058992386, 0.10946700721979141, 1.1445773839950562, -1.0579818487167358, 0.8463665246963501, -0.11821666359901428, 0.45064646005630493, 0.35670530796051025, -0.09020020812749863, -0.90866619348526, -0.5740749835968018, -0.2911357879638672, -0.6152274012565613, -0.8434465527534485, 0.6355202794075012, -0.2695242166519165, -1.1519403457641602, 0.216598778963089, -1.1249635219573975, -0.3831298351287842, -0.17666351795196533, -0.6769007444381714, -0.5777041912078857, -0.8619140386581421, -1.1535944938659668, -0.7740180492401123, -0.17243261635303497, -0.8980475068092346, 0.6806238889694214, 0.2065589278936386, -0.5845482349395752, -0.5603342056274414, 0.09666623175144196, -0.21883945167064667, 0.6375548839569092, -0.26160091161727905, 0.4707224667072296, 0.6507483720779419, -0.5261520743370056, -0.20440219342708588, 0.11858914792537689, 0.00959013495594263, 0.012429539114236832, 0.7695017457008362, -0.8330133557319641, 0.41405537724494934, -0.6604002714157104, -0.7289696931838989, 0.1389036327600479, 0.4803850054740906, 0.38985735177993774, 0.1297426074743271, -0.3643451929092407, 0.37442025542259216, 0.991007924079895, -0.3330656886100769, 0.4081960916519165, 0.1374702900648117, 0.8670240640640259, 0.5048240423202515, -0.36413007974624634, 0.8240472674369812, 0.2006833851337433, 0.1851748377084732, -0.03993628919124603, -0.1383618712425232, -0.46935325860977173, -0.9240508079528809, 0.6108155846595764, 0.8251563906669617, 0.2589392364025116, -0.23879429697990417, -0.6157853603363037, 0.7778405547142029, -1.2023450136184692, -1.0149036645889282, 1.0384552478790283, 0.43612030148506165, -0.09482007473707199, -0.42964109778404236, -0.03711182251572609, -0.33341318368911743, 0.3091598451137543, 0.3687291443347931, -0.42246946692466736, -0.271043986082077, -0.5193983912467957, 0.24615129828453064, -0.4227941632270813, 0.5986182689666748, -0.2574077844619751, 0.5979788303375244, 14.991703033447266, 0.9541352391242981, -0.17248739302158356, 0.03479119762778282, 0.7066993117332458, 0.12951886653900146, -0.7238304615020752, 0.07440108805894852, -0.6894282102584839, -0.4413852095603943, 0.5625098347663879, 0.3531349301338196, 0.5608214139938354, -0.2222125381231308, 0.08177778869867325, 0.13654635846614838, -0.5675819516181946, 0.842999279499054, 0.5424151420593262, -1.143129825592041, 0.3406773805618286, -0.013676222413778305, 0.2150188684463501, 0.09639599174261093, 1.1525237560272217, 0.6464258432388306, 0.2616260349750519, -0.45886749029159546, 0.8233457803726196, 0.3753339350223541, 1.3262197971343994, 0.37099769711494446, -0.4935538172721863, 0.28562813997268677, -0.9209280610084534, -0.3422695994377136, -0.38861045241355896, -0.8109280467033386, 0.5987692475318909, -0.2337430715560913, -0.40255093574523926, -0.5258811712265015, 0.3484753966331482, 0.8389743566513062, 0.17668700218200684, 0.16343146562576294, 0.037524595856666565, 0.19522832334041595, -0.3524429500102997, 0.36620983481407166, 0.2606011927127838, 0.2974489629268646, 0.25268375873565674, -0.12460534274578094, 0.19293959438800812, 0.14077241718769073, 0.0010880170157179236, 0.8808735013008118, -0.3523012697696686, -0.09017990529537201, -0.49495649337768555, -0.48547059297561646, -0.2811781167984009, 0.9800688028335571, 0.04962405189871788, 0.28070151805877686, -0.04075988009572029, 0.7252891063690186, 0.5079216361045837, 0.3092171251773834, -0.29255059361457825, -0.04771309345960617, -0.16231869161128998, -0.23830991983413696, 0.259738028049469, 0.30380043387413025, 0.18222661316394806, -0.5893568396568298, -0.5050536394119263, -0.09268015623092651, 0.26412439346313477, -1.2193008661270142, -0.9117798209190369, 1.0654715299606323, -0.06978625804185867, -0.20126380026340485, 0.31126511096954346, -0.6526359915733337, -0.0397069975733757, 0.14309492707252502, -0.989008903503418, -0.9140732884407043, 0.03722820058465004, -0.15110859274864197, 0.08138630539178848, 0.24504771828651428, 1.0338122844696045, 0.11880860477685928, -0.12423501908779144, -0.11195524781942368, -0.2876697778701782, -0.1020655706524849, 0.03482898697257042, -0.740053653717041, 0.7791377902030945, -0.0870208814740181, 0.027767440304160118, -0.07639564573764801, 0.1657641977071762, 0.059914302080869675, -0.7622982263565063, 0.715451180934906, 0.021545011550188065, -0.8993640542030334, -0.4849029779434204, -0.8916084170341492, -0.5724654197692871, 0.39538270235061646, 0.5305313467979431, -0.02706814929842949, -0.030954644083976746, 0.1130719855427742, -0.8104126453399658, 0.012074395082890987, -0.6674478054046631, 0.22560487687587738, 0.5219534635543823, -0.6799449324607849, -0.09447994828224182, 0.00783945620059967, 0.29530924558639526, -1.1277440786361694, -0.6060166954994202, -0.19707952439785004, 0.6121509671211243, -0.6776466965675354, 0.8064597845077515, -0.4046657383441925, 0.8176636099815369, 0.8930210471153259, -0.020748641341924667, -0.639410674571991, -0.13140302896499634, -1.3554319143295288, 0.24032855033874512, 0.37067604064941406, 0.4391763210296631, 0.09317648410797119, 0.473667174577713, 0.9831752777099609, 0.4925732910633087, -0.07979519665241241, -0.4352249801158905, 0.053460486233234406, 0.29519256949424744, -0.682582437992096, -0.11297757178544998, -0.228153795003891, 0.09314596652984619, 0.5251991152763367, 0.11100004613399506, 0.3504573106765747, -0.3084232807159424, -0.7945178151130676, 0.5524473190307617, 0.02474023960530758, 0.04734121263027191, -0.6298855543136597, -0.6354666948318481, -1.8814241886138916, -0.44301900267601013, -0.8425863981246948, -0.08606233447790146, -1.0777394771575928, -0.5540311336517334, 0.11369679868221283, 0.27881404757499695, -0.045001521706581116, 0.6550164222717285, -0.3391576409339905, -0.1502160131931305, -0.5744036436080933, -0.5587544441223145, 1.099411964416504, 1.4532333612442017, -1.0873515605926514, -0.07056301087141037, -0.2817690670490265, 0.2456922084093094, 0.32552090287208557, -0.025429101660847664, -0.2033960372209549, -0.8726245760917664, -1.1878745555877686, 0.5193161964416504, 0.18839219212532043, -0.04421175643801689, -0.9581445455551147, 0.2520782947540283, 0.44059836864471436, 0.11650703102350235, -0.0025998884811997414, 0.9598038196563721, -0.9049393534660339, -0.4114340543746948, -0.2480437159538269, -1.0636253356933594, 0.0887208878993988, 0.33823516964912415, -0.5178416967391968, 0.03623305261135101, 0.9075707197189331, -0.21929220855236053, -1.1088416576385498, -0.5338048338890076, 0.5460634827613831, -0.7117196917533875, 0.048597291111946106, -0.40501868724823, -0.3480549454689026, -1.1164469718933105, -0.5856472253799438, -0.4848390221595764, 0.13958007097244263, -0.4224475920200348, 1.31256902217865, 0.8631712198257446, -1.2306246757507324, -0.12311920523643494, 0.21046410501003265, -0.050872597843408585, 0.49863606691360474, 1.1426547765731812, 0.01055246964097023, 0.00023443528334610164, 0.091300368309021, 0.08516045659780502, 0.09133370220661163, -0.6055948138237, 0.34498918056488037, 0.7448788285255432, -0.04078265279531479, -0.44251731038093567, 1.0942366123199463, 0.28120356798171997, -0.7907611727714539, 0.2372807413339615, -0.7050976753234863, -0.4041694700717926, -0.3055620491504669, 0.6820555329322815, 0.04839501157402992, -0.6099225282669067, -0.011811206117272377, -0.2593681514263153, 0.6261255741119385, -0.2365344613790512, -1.058605432510376, 0.4774056077003479, -0.23026834428310394, 0.0446896031498909, 0.6685433983802795, 0.681911289691925, -0.3905653655529022, -1.037628412246704, -0.529167652130127, -0.8880250453948975, -0.3409058153629303, -0.024583125486969948, -0.6498062014579773, -0.6810720562934875, 1.054629921913147, 0.5850496292114258, 0.5150017738342285, 0.30610132217407227, 0.34856459498405457, 0.2474304586648941, 0.3525683283805847, -0.517331063747406, -0.5585130453109741, 0.10839468240737915, 0.7219638824462891, 1.3403948545455933, -0.298406720161438, -0.018826646730303764, -0.1337946653366089, -0.8100679516792297, 0.8616121411323547, 0.4806762933731079, 0.050913356244564056, 0.6498667597770691, -0.01204796601086855, 0.3450154960155487, -0.11459363996982574, -0.9182217121124268, -0.19639085233211517, 0.8933281302452087, 1.5129464864730835, 0.44539937376976013, -0.09566248208284378, 0.44400882720947266, 0.28858625888824463, 0.17825056612491608, 0.3495428264141083, 0.5106567740440369, 0.4045218527317047, 0.021500462666153908, 0.19517895579338074, 0.023236259818077087, 0.15861059725284576, -0.3435751497745514, -0.18799608945846558, 0.09658438712358475, 0.16410556435585022, 0.1944536566734314, 0.5852495431900024, 0.9485297799110413, 0.2580317258834839, 0.7076156735420227, -0.13043071329593658, 1.272684931755066, 0.0015419642440974712, 0.24032826721668243, 0.407349556684494, -0.9745380282402039, -0.02513061836361885, -0.5510976910591125, -0.5693559050559998, -0.36037322878837585, -0.16064555943012238, 0.35515114665031433, -0.1753554344177246, 0.052680566906929016, 0.8651863932609558, 0.7480062246322632, 0.429671972990036, -0.34609827399253845, -0.8641428351402283, 0.26439547538757324, -1.0241408348083496, 0.06903406977653503, 0.04381949454545975, -0.010386276058852673, -0.5878257751464844, -0.13172222673892975, 0.048427339643239975]}, "authors": [{"authorId": "144740494", "name": "Peng Gao"}, {"authorId": "2300371391", "name": "Le Zhuo"}, {"authorId": "2112305433", "name": "Ziyi Lin"}, {"authorId": "2238219059", "name": "Chris Liu"}, {"authorId": "2212250873", "name": "Junsong Chen"}, {"authorId": "2300371542", "name": "Ruoyi Du"}, {"authorId": "2300371174", "name": "Enze Xie"}, {"authorId": "2300428221", "name": "Xu Luo"}, {"authorId": "2150467916", "name": "Longtian Qiu"}, {"authorId": "2300451668", "name": "Yuhang Zhang"}, {"authorId": "2266583076", "name": "Chen Lin"}, {"authorId": "2300852396", "name": "Rongjie Huang"}, {"authorId": "1947101", "name": "Shijie Geng"}, {"authorId": "2274929565", "name": "Renrui Zhang"}, {"authorId": "2300371501", "name": "Junlin Xi"}, {"authorId": "2283133523", "name": "Wenqi Shao"}, {"authorId": "2268849435", "name": "Zhengkai Jiang"}, {"authorId": "2300491960", "name": "Tianshuo Yang"}, {"authorId": "2300420528", "name": "Weicai Ye"}, {"authorId": "2300370603", "name": "He Tong"}, {"authorId": "50774681", "name": "Jingwen He"}, {"authorId": "2059129841", "name": "Y. Qiao"}, {"authorId": "2266421952", "name": "Hongsheng Li"}], "references": [{"paperId": "ea7d472879de137bbb763eb9fb0ce6de187a90c3", "title": "Upsample Guidance: Scale Up Diffusion Models without Training"}, {"paperId": "6d017adda6b2b1ea627dde2f0e85401ebb9fe566", "title": "MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?"}, {"paperId": "5c80f5947fed7c5c2b58a4aebfb7c3be4b3ce35d", "title": "FouriScale: A Frequency Perspective on Training-Free High-Resolution Image Synthesis"}, {"paperId": "03e2cfa44b64489fb98f09dfbd940043fbef90ad", "title": "SV3D: Novel Multi-view Synthesis and 3D Generation from a Single Image using Latent Video Diffusion"}, {"paperId": "77b3af0bc3b3967529ecea7f72c53941ae4ba357", "title": "VFusion3D: Learning Scalable 3D Generative Models from Video Diffusion Models"}, {"paperId": "e9af07e09bc4804c3d6305d51b9588d08b2f2ba8", "title": "VideoMV: Consistent Multi-View Generation Based on Large Video Generative Model"}, {"paperId": "9db25ca30dcc8aa75c034ccaee0f6ee2ca934956", "title": "V3D: Video Diffusion Models are Effective 3D Generators"}, {"paperId": "65e8a4cca1a80f517bab8b4c3a39cc63d7527e66", "title": "CogView3: Finer and Faster Text-to-Image Generation via Relay Diffusion"}, {"paperId": "41b47f33a24feefd6728bdc1339d0d4ff5fec7be", "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context"}, {"paperId": "f6632f0c4633ea981684a16a05f5d7d46d1d586c", "title": "PixArt-\u03a3: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation"}, {"paperId": "41a66997ce0a366bba3becf7c3f37c9aebb13fbd", "title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis"}, {"paperId": "df5b72f541fdd0328563ec93896d217c3b3660e3", "title": "ResAdapter: Domain Consistent Resolution Adapter for Diffusion Models"}, {"paperId": "8eae862d9669e7001eeee17b49fba793df9672c4", "title": "Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers"}, {"paperId": "888e36b348b786538e3a74c459fe884a3457a36f", "title": "MVDiffusion++: A Dense High-resolution Multi-view Diffusion Model for Single or Sparse-view 3D Object Reconstruction"}, {"paperId": "93556757bf63230df3293456f5a7a2a261aedeb7", "title": "Make a Cheap Scaling: A Self-Cascade Diffusion Model for Higher-Resolution Adaptation"}, {"paperId": "ec8e2b45c4601730015608a58e33409224a81228", "title": "SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models"}, {"paperId": "39ba6d541d94132b816938e7e16b1e8fd49c2fd9", "title": "Training-Free Consistent Text-to-Image Generation"}, {"paperId": "140cfda71bfff852c3e205b7ad61854b78c76982", "title": "Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs"}, {"paperId": "492bc8339d8aac442c4ec13f8c1d59e980a3af2f", "title": "VideoCrafter2: Overcoming Data Limitations for High-Quality Video Diffusion Models"}, {"paperId": "1eac5d12f30697aa74d66f4026fb662c5d51bd43", "title": "SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers"}, {"paperId": "6c64ddd2190909de2c680dd18abc9b92e80c39f9", "title": "Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision, Language, Audio, and Action"}, {"paperId": "831425c9cd30c61a333528e6678d73370aff84b1", "title": "FreeControl: Training-Free Spatial Control of Any Text-to-Image Diffusion Model with Any Condition"}, {"paperId": "905ba940236b00bebb2fd348d4d932e7887b0c0a", "title": "Photorealistic Video Generation with Diffusion Models"}, {"paperId": "95a1305f252f53d5d7bed8cf9d9091d6dbdeb0ab", "title": "Upscale-A-Video: Temporal-Consistent Diffusion Model for Real-World Video Super-Resolution"}, {"paperId": "457828497f66d3c4abb1f0ee0d0dc58ab74d01cd", "title": "GenTron: Diffusion Transformers for Image and Video Generation"}, {"paperId": "c320eb9255940cec341af7aef9c8c38a7a167d6a", "title": "Style Aligned Image Generation via Shared Attention"}, {"paperId": "4c8608124dd92b84effedb7dd1965aeb13420e9c", "title": "ImageDream: Image-Prompt Multi-view Diffusion for 3D Generation"}, {"paperId": "d759a0543d3112361ff9f124ae40142aa4949093", "title": "VideoBooth: Diffusion-based Video Generation with Image Prompts"}, {"paperId": "31245344a6eb6cd897a71928dc4b174ab75e4070", "title": "Diffusion Models Without Attention"}, {"paperId": "fa5b841a69a1262aaf4ca346989368526c90f2bd", "title": "ElasticDiffusion: Training-free Arbitrary Size Image Generation"}, {"paperId": "c8dc4af5c61f95cc79b7f83e8339efa62af8f811", "title": "Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation"}, {"paperId": "1206b05eae5a06ba662ae79fb291b50e359c4f42", "title": "Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets"}, {"paperId": "af908ee2d0580b15a3814a3b302af4b61bbfdb2e", "title": "DemoFusion: Democratising High-Resolution Image Generation With No $$$"}, {"paperId": "5bcb0153dd0840113eb27d4d6f753414ef656a03", "title": "Emu Edit: Precise Image Editing via Recognition and Generation Tasks"}, {"paperId": "05782b157d5468c08de9dbde9635ee9902f40b60", "title": "One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion"}, {"paperId": "76a3f4a79ae9a00db2f2b5f6877021d8deb96ada", "title": "SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for Multi-modal Large Language Models"}, {"paperId": "3af134a559a618b3185390646d49d1d4e7ffab45", "title": "Instant3D: Fast Text-to-3D with Sparse-View Generation and Large Reconstruction Model"}, {"paperId": "9b86ce1bde87b304141641b49299f4d0f1f7ba1d", "title": "I2VGen-XL: High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models"}, {"paperId": "1891c3756f870d902a0b793a1dcd5cc34c778612", "title": "VideoCrafter1: Open Diffusion Models for High-Quality Video Generation"}, {"paperId": "186c2b2386799fa599e2d77bc6945f7da66e5fab", "title": "Zero123++: a Single Image to Consistent Multi-view Diffusion Base Model"}, {"paperId": "d2c5565a039f464b778e0f2263da418ef42e98b0", "title": "Wonder3D: Single Image to 3D using Cross-Domain Diffusion"}, {"paperId": "083bab4a967c2221d9f4da9110fe37d8ca679078", "title": "DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors"}, {"paperId": "b02d8250bf26701f0e300bb6d6c3cff7558b2754", "title": "ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models"}, {"paperId": "02ad9f3fefe33cb9ca546591bec65dbdf7766c80", "title": "Ring Attention with Blockwise Transformers for Near-Infinite Context"}, {"paperId": "8fafd95a6ffbecf9c1b5f4542ac4b78a00602551", "title": "PixArt-\u03b1: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis"}, {"paperId": "ed4603ea341acc26cab24f41aa40524fb7779917", "title": "LAVIE: High-Quality Video Generation with Cascaded Latent Diffusion Models"}, {"paperId": "a51ac7a5e8f6454268ac16ecdc52ecac98ce54d9", "title": "DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models"}, {"paperId": "169fd6c457d99a21c32b6f23bbfd1e09a2513684", "title": "Relay Diffusion: Unifying diffusion process across resolutions for image synthesis"}, {"paperId": "7d7d2b9137080248c9881fb85a100bb5ba30f2ac", "title": "Any-Size-Diffusion: Toward Efficient Text-Driven Synthesis for Any-Size HD Images"}, {"paperId": "819bbdc2dac9e13d9ca3e2508a6e063186ce5e40", "title": "YaRN: Efficient Context Window Extension of Large Language Models"}, {"paperId": "9aa01997226b5c4d705ae2e2f52c32681006654b", "title": "MVDream: Multi-view Diffusion for 3D Generation"}, {"paperId": "84f0a99d0f0015a6145c94468870d43ab1d166fd", "title": "ModelScope Text-to-Video Technical Report"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "c1caa303549764d220ff17dc1785985dd1ba6047", "title": "AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning"}, {"paperId": "d7890d1906d95c4ae4c430b350455156d6d8aed9", "title": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "166b8c2ee52794c46615c5c52d0390d896b79794", "title": "Training-free Diffusion Model Adaptation for Variable-Sized Text-to-Image Synthesis"}, {"paperId": "4279a38a098d1d359881b73c6a88a112fe93443a", "title": "Scalable 3D Captioning with Pretrained Models"}, {"paperId": "02dde8e9fefafae8e0b9ee2eef0ddc74c511f7cd", "title": "Wuerstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models"}, {"paperId": "0b3d3b58077ebe719930e75764d18ba296cd269b", "title": "RAPHAEL: Text-to-Image Generation via Large Mixture of Diffusion Paths"}, {"paperId": "a483ff9557f29d21fe780b3dd969a037a3ffc3ed", "title": "Uni-ControlNet: All-in-One Control to Text-to-Image Diffusion Models"}, {"paperId": "b6d6c33298b852cf63edac233deca70530d69a2a", "title": "PaLM 2 Technical Report"}, {"paperId": "570079bbdd8758dfe865097e05719313c9c1301a", "title": "LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model"}, {"paperId": "f51bc74814a3452009ea5ca262d9768d08149ee6", "title": "Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model"}, {"paperId": "a0e7c31d723608e03f30fc92ffc2a604a7a039da", "title": "PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel"}, {"paperId": "f5a0c57f90c6abe31482e9f320ccac5ee789b135", "title": "Align Your Latents: High-Resolution Video Synthesis with Latent Diffusion Models"}, {"paperId": "7470a1702c8c86e6f28d32cfa315381150102f5b", "title": "Segment Anything"}, {"paperId": "a757999ed260d7bc45484dc6b4456bf33fe6f679", "title": "LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention"}, {"paperId": "cd7427ba511c126ed0cf32ba9404b6aa53da0153", "title": "Stochastic Interpolants: A Unifying Framework for Flows and Diffusions"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "58842cdca3ea68f7b9e638b288fc247a6f26dafc", "title": "T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models"}, {"paperId": "9ced6e814457eae83f5415364e266143defc81d1", "title": "MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation"}, {"paperId": "61e721334296ebfbbf6443b5ed9eb8c83b708c95", "title": "Scaling Vision Transformers to 22 Billion Parameters"}, {"paperId": "efbe97d20c4ffe356e8826c01dc550bacc405add", "title": "Adding Conditional Control to Text-to-Image Diffusion Models"}, {"paperId": "e6376edb31bf224c0223b48442b3fef4bb1a30f4", "title": "Mixture of Diffusers for scene composition and high resolution image generation"}, {"paperId": "6d1433f3342fbee85ad1e2809e62734aec5c3853", "title": "Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models"}, {"paperId": "fa0f3d8aa20e8987dbc7a516d5399cfa3dc97b1b", "title": "AudioLDM: Text-to-Audio Generation with Latent Diffusion Models"}, {"paperId": "6e3a3b7a8a0376d867cad72eedf2f9b746f29a33", "title": "simple diffusion: End-to-end diffusion for high resolution images"}, {"paperId": "c2f91f35df893714418cc29096083dce0b441229", "title": "Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers"}, {"paperId": "1367dcff4ccb927a5e95c452041288b3f0dd0eff", "title": "Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation"}, {"paperId": "736973165f98105fec3729b7db414ae4d80fcbeb", "title": "Scalable Diffusion Models with Transformers"}, {"paperId": "1b31dbf44e68b698120552366df03e6e35a1e428", "title": "Objaverse: A Universe of Annotated 3D Objects"}, {"paperId": "a02fbaf22237a1aedacb1320b6007cd70c1fe6ec", "title": "Robust Speech Recognition via Large-Scale Weak Supervision"}, {"paperId": "a2d2bbe4c542173662a444b33b76c66992697830", "title": "InstructPix2Pix: Learning to Follow Image Editing Instructions"}, {"paperId": "baa4f95081e9663fb045d145acc70049ace16ac9", "title": "DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models"}, {"paperId": "23e261a20a315059b4de5492ed071c97a20c12e7", "title": "Imagic: Text-Based Real Image Editing with Diffusion Models"}, {"paperId": "e5c8960eb2ec034ffbd353ef39fd1cb541d3c7c9", "title": "LAION-5B: An open large-scale dataset for training next generation image-text models"}, {"paperId": "37d626720f5003373336098ce7c01a1a38e6b63d", "title": "What the DAAM: Interpreting Stable Diffusion Using Cross Attention"}, {"paperId": "af68f10ab5078bfc519caae377c90ee6d9c504e9", "title": "Flow Matching for Generative Modeling"}, {"paperId": "498ac9b2e494601d20a3d0211c16acf2b7954a54", "title": "Imagen Video: High Definition Video Generation with Diffusion Models"}, {"paperId": "4e6244baf4236f4635e85f7dfb941a9a0a6c4a11", "title": "Building Normalizing Flows with Stochastic Interpolants"}, {"paperId": "897f3bb5eacaa80359e81ff33378e1110e20ae95", "title": "All are Worth Words: A ViT Backbone for Diffusion Models"}, {"paperId": "244054a4254a2147e43a3dad9c124b9b7eb4a04a", "title": "Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow"}, {"paperId": "04e541391e8dce14d099d00fb2c21dbbd8afe87f", "title": "Prompt-to-Prompt Image Editing with Cross Attention Control"}, {"paperId": "af9f365ed86614c800f082bd8eb14be76072ad16", "title": "Classifier-Free Diffusion Guidance"}, {"paperId": "c036f75da24ba64a583e0b6d41c5b792347bffa6", "title": "Diffsound: Discrete Diffusion Model for Text-to-Sound Generation"}, {"paperId": "4530c25da949bb2185c50663158ef19d52e3c6b5", "title": "DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps"}, {"paperId": "2f4c451922e227cbbd4f090b74298445bbd900d0", "title": "Elucidating the Design Space of Diffusion-Based Generative Models"}, {"paperId": "c539f6ab5818bde96f61298856cb0c38f6268369", "title": "On Aliased Resizing and Surprising Subtleties in GAN Evaluation"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "7c597874535c1537d7ddff3b3723015b4dc79d30", "title": "MaskGIT: Masked Generative Image Transformer"}, {"paperId": "82ba96443173da0b8b3e870c5ab8f41109a67203", "title": "StyleGAN-XL: Scaling StyleGAN to Large Diverse Datasets"}, {"paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d", "title": "High-Resolution Image Synthesis with Latent Diffusion Models"}, {"paperId": "b668ce936cff0b0ca8b635cd5f25a62eaf4eb3df", "title": "LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs"}, {"paperId": "416dab850fda842b13a4f28164514d98f836fff7", "title": "WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing"}, {"paperId": "155a3210bbc715b04a455b2d396f9fbb585540aa", "title": "Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation"}, {"paperId": "0f183bcfe65781c06b1a48a6f56e0f3c63e8e4a4", "title": "Cascaded Diffusion Models for High Fidelity Image Generation"}, {"paperId": "64ea8f180d0682e6c18d1eb688afdb2027c02794", "title": "Diffusion Models Beat GANs on Image Synthesis"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "79a79a4c1a43038973c49b0cbc6085e2c6caeeb1", "title": "Generating Images with Sparse Representations"}, {"paperId": "4c055698c68b21c4e8f25a5c1b3439f9f7f3be62", "title": "AdaSpeech: Adaptive Text to Speech for Custom Voice"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "de18baa4964804cf471d85a5a090498242d2e79f", "title": "Improved Denoising Diffusion Probabilistic Models"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "633e2fbfc0b21e959a244100937c5853afca4853", "title": "Score-Based Generative Modeling through Stochastic Differential Equations"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "4e468d3da1797d791db8d514d695b183acb027ee", "title": "HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis"}, {"paperId": "806adbb35ed4a95f51518f5962fd59685ad4706b", "title": "Query-Key Normalization for Transformers"}, {"paperId": "014576b866078524286802b1d0e18628520aa886", "title": "Denoising Diffusion Implicit Models"}, {"paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8", "title": "Generative Pretraining From Pixels"}, {"paperId": "f6d32ed0eee5fb3f6ac518f3aebc8ceff2aae397", "title": "NVAE: A Deep Hierarchical Variational Autoencoder"}, {"paperId": "725264948d7b6946259af5b8d966e996b9570f99", "title": "DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters"}, {"paperId": "5c126ae3421f05768d8edd97ecd44b1364e2c99a", "title": "Denoising Diffusion Probabilistic Models"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "79f13cd8b7fc3e154b5b6ce66a3f49d038715011", "title": "ControlVAE: Controllable Variational Autoencoder"}, {"paperId": "e52051204cb1179584f3b008c9d38848b52c1f28", "title": "ReZero is All You Need: Fast Convergence at Large Depth"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "10eda4521c032adabaa8e70d6569e17370b29dcd", "title": "Root Mean Square Layer Normalization"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "d383dd8ced85d7898d8b1546c514a34fb626ea16", "title": "Improved Precision and Recall Metric for Assessing Generative Models"}, {"paperId": "04265022434f6c0ea2782952830ea344bff5705a", "title": "Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion"}, {"paperId": "ceb2ebef0b41e31c1a21b28c2734123900c005e2", "title": "A Style-Based Generator Architecture for Generative Adversarial Networks"}, {"paperId": "22aab110058ebbd198edb1f1e7b4f69fb13c0613", "title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis"}, {"paperId": "1bdd30a8acc75c58a1bdd4daa4545d5f3971a826", "title": "ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks"}, {"paperId": "e7fd6848cb29ca221a7e17d823e06fb566f1f135", "title": "Mixed Precision Training"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "be0ef77fb0345c5851bb5d297f3ed84ae3c581ee", "title": "Arbitrary Style Transfer in Real-Time with Adaptive Instance Normalization"}, {"paperId": "222928303a72d1389b0add8032a31abccbba41b3", "title": "Grammar Variational Autoencoder"}, {"paperId": "8acbe90d5b852dadea7810345451a99608ee54c7", "title": "Image-to-Image Translation with Conditional Adversarial Networks"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "0936352b78a52bc5d2b5e3f04233efc56664af51", "title": "Conditional Image Generation with PixelCNN Decoders"}, {"paperId": "571b0750085ae3d939525e62af510ee2cee9d5ea", "title": "Improved Techniques for Training GANs"}, {"paperId": "09879f7956dddc2a9328f5c1472feeb8402bcbcf", "title": "Density estimation using Real NVP"}, {"paperId": "41f1d50c85d3180476c4c7b3eea121278b0d8474", "title": "Pixel Recurrent Neural Networks"}, {"paperId": "2dcef55a07f8607a819c21fe84131ea269cc2e3c", "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"}, {"paperId": "dc8301b67f98accbb331190dd7bd987952a692af", "title": "NICE: Non-linear Independent Components Estimation"}, {"paperId": "5a61035df1c7ae84a2db92c41b63b84f812ba3fd", "title": "CROWDMOS: An approach for crowdsourcing mean opinion score studies"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "90428f3a8caa5082f825ebf3138514ddf273dae3", "title": "Supplementary Materials for: NULL-text Inversion for Editing Real Images using Guided Diffusion Models"}, {"paperId": "adc8b62fd2bd644c140c7c42275a9d2d913ad8a8", "title": "Blockwise Parallel Transformers for Large Context Models"}, {"paperId": "ef4f5a50837a7c1b3e87b9300ffc7ba00d461a0f", "title": "AUTO-ENCODING VARIATIONAL BAYES"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "c68796f833a7151f0a63d1d1608dc902b4fdc9b6", "title": "GENERATIVE ADVERSARIAL NETS"}, {"paperId": "061146b1d7938d7a8dae70e3531a00fceb3c78e8", "title": "Variational Autoencoder based Anomaly Detection using Reconstruction Probability"}, {"paperId": null, "title": "Ntk-aware Scaled Rope Allows Llama Models to Have Extended (8k+) Con-text Size Without Any Fine-tuning and Minimal Perplexity Degradation"}, {"paperId": "cfee1826dd4743eab44c6e27a0cc5970effa4d80", "title": "Improving Image Generation with Better Captions"}, {"paperId": null, "title": "World model on million-length video and language with ringattention"}, {"paperId": null, "title": "Runway: Creative tools for the next generation"}, {"paperId": null, "title": "OpenAI"}, {"paperId": null, "title": "Anthropic"}, {"paperId": null, "title": "Gemini: a family of highly capable multimodal models"}, {"paperId": null, "title": "Midjourney"}]}