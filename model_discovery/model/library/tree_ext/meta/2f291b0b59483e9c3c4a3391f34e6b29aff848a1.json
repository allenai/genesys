{"paperId": "2f291b0b59483e9c3c4a3391f34e6b29aff848a1", "title": "DeepStruct: Pretraining of Language Models for Structure Prediction", "abstract": "We introduce a method for improving the structural understanding abilities of language models. Unlike previous approaches that finetune the models with task-specific augmentation, we pretrain language models to generate structures from the text on a collection of task-agnostic corpora. Our structure pretraining enables zero-shot transfer of the learned knowledge that models have about the structure tasks. We study the performance of this approach on 28 datasets, spanning 10 structure prediction tasks including open information extraction, joint entity and relation extraction, named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, factual probe, intent detection, and dialogue state tracking. We further enhance the pretraining with the task-specific training sets. We show that a 10B parameter language model transfers non-trivially to most tasks and obtains state-of-the-art performance on 21 of 28 datasets that we evaluate. Our code and datasets will be made publicly available.", "venue": "Findings", "year": 2022, "citationCount": 51, "influentialCitationCount": 11, "openAccessPdf": {"url": "http://arxiv.org/pdf/2205.10475", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "It is shown that a 10B parameter language model transfers non-trivially to most tasks and obtains state-of-the-art performance on 21 of 28 datasets that are evaluated."}, "embedding": {"model": "specter_v2", "vector": [-0.016385402530431747, 1.229296326637268, -0.4428892731666565, -0.42279723286628723, -0.0829567238688469, -0.8328191637992859, 0.7213352918624878, -0.12583260238170624, -0.44095519185066223, 0.08978015184402466, 1.3698567152023315, -0.026334095746278763, 0.47604092955589294, 0.22603806853294373, 0.31528323888778687, 0.4801125228404999, -0.6684413552284241, 0.7833109498023987, -0.06752220541238785, -0.6099988222122192, -0.13277333974838257, -0.8255708813667297, 0.10043670982122421, -0.08025173097848892, -0.019223058596253395, 0.40791425108909607, 0.22290103137493134, 0.19482524693012238, -0.5559609532356262, 0.6052384972572327, 0.2752895951271057, -0.5564814209938049, -0.01930631697177887, -0.037122830748558044, -0.9429485201835632, -0.3177952468395233, -0.013763489201664925, -0.2978930175304413, -0.3080041706562042, 0.9168357849121094, -0.6640564203262329, 0.0850590243935585, 0.7070527076721191, -0.41345104575157166, 0.16423802077770233, 1.3320484161376953, 0.6761046648025513, 0.5573379397392273, -0.012881334871053696, -1.2930763959884644, 1.665026307106018, -1.2312079668045044, 1.0770995616912842, 1.3595038652420044, 0.6844379305839539, 0.7600051760673523, -0.4647587239742279, -0.694519579410553, 0.4364064633846283, 0.25509411096572876, -0.8834206461906433, -0.6842723488807678, 0.08326438069343567, -0.13177599012851715, 1.8440358638763428, -0.4530402719974518, -0.2233864963054657, 0.5335330367088318, -0.12782971560955048, 1.0053504705429077, -0.35352471470832825, -0.32537901401519775, -0.7335805296897888, 0.14001145958900452, 0.6906558275222778, 1.08610200881958, -0.4622589349746704, 0.1744348555803299, -0.5753098726272583, -0.07498107105493546, 0.28958234190940857, -0.40291646122932434, -0.16961783170700073, -0.03982248902320862, -0.46089601516723633, 0.4956957995891571, 0.5774067044258118, 0.8755872845649719, 0.010333842597901821, 0.023297686129808426, 0.6267754435539246, 0.26938602328300476, -0.5393881797790527, 0.867065966129303, -0.4262255132198334, 0.3607599139213562, -0.3941913843154907, -0.2700809836387634, 0.6242746114730835, 0.6524142622947693, -0.16104485094547272, 0.12895986437797546, -0.784450352191925, 0.040596652776002884, 1.2400197982788086, -0.6680731177330017, 0.2529315650463104, -1.1065669059753418, 0.28148844838142395, -0.31068339943885803, 0.40211039781570435, -0.478304386138916, -0.6832919716835022, -0.19754743576049805, -0.7603172659873962, -1.3505357503890991, -0.3421425521373749, -0.48082223534584045, -0.6797877550125122, 0.7575469017028809, -0.09247756749391556, 0.15864336490631104, 0.04421953111886978, 0.2592583894729614, 0.9539815783500671, 0.6682091355323792, 0.2686496376991272, -0.12423104792833328, 1.20260488986969, -0.6927613019943237, -1.0345516204833984, -0.8642643690109253, 0.8018445372581482, -0.04899359121918678, -0.43906107544898987, -0.36756864190101624, -0.6704088449478149, -0.7255247235298157, -0.7936878800392151, -0.3293438255786896, -0.2869899272918701, 0.3277090787887573, 0.6345821619033813, 0.5053154826164246, -0.5338085889816284, 0.7446383237838745, -0.0416446253657341, 0.10310259461402893, 0.11884409189224243, 0.04293856397271156, -0.04786642640829086, 0.058659352362155914, -1.174262523651123, 0.5428765416145325, 0.7738350629806519, -0.3782308101654053, -0.3743886649608612, -0.7535862922668457, -1.4569487571716309, 0.15485340356826782, 0.8112483620643616, -0.3102662265300751, 1.2654906511306763, 0.221453458070755, -1.3784618377685547, 0.8740166425704956, -0.6350142955780029, -0.08733662962913513, -0.12023264169692993, -0.2838652729988098, -0.3609829545021057, -0.8357397317886353, -0.20638372004032135, 0.37027356028556824, 0.11408612877130508, -0.3188028037548065, 0.03600678965449333, 0.17577077448368073, -0.12831096351146698, -0.1734493523836136, -0.04896245151758194, 1.2787833213806152, -0.10527636110782623, -0.07602681964635849, 0.030849898234009743, 0.8125023245811462, 0.002194043016061187, -0.5321106314659119, -0.949360728263855, -1.2129837274551392, 0.7196460366249084, -0.09281294047832489, 0.951298713684082, -0.6298859119415283, -0.349036306142807, -0.5170748233795166, 0.3492198884487152, 0.14890484511852264, -0.8411504626274109, 0.4571882486343384, -0.7745286226272583, 0.3956689238548279, -0.13242438435554504, -1.2766153812408447, 0.044394925236701965, -0.11648554354906082, -0.4183259606361389, -0.3046538829803467, -0.02916775271296501, 1.200122594833374, -0.6411886811256409, -0.16197900474071503, 0.17247512936592102, 0.12208343297243118, -0.794843316078186, 1.3193018436431885, -0.33166682720184326, 0.2371598184108734, -0.3157140910625458, -0.4182736873626709, -0.16600899398326874, -0.2196538746356964, 0.9792043566703796, -0.7631662487983704, -0.25071945786476135, 0.9450081586837769, -0.46728405356407166, 1.210455298423767, -0.15077190101146698, 0.15121157467365265, 0.5449851751327515, -0.7345618605613708, 0.4490739703178406, 0.3306482136249542, -0.15162590146064758, -0.060196444392204285, 0.40990471839904785, 0.07947571575641632, -0.4354510009288788, 0.2961081266403198, 0.872815728187561, 0.37252599000930786, -0.5092517733573914, 0.26561248302459717, 0.6790036559104919, -0.030448952689766884, 0.2730218470096588, 0.5313512682914734, 0.7598990797996521, 0.2498917430639267, 0.6667810678482056, -0.09275762736797333, 0.4818967878818512, -0.5154131650924683, 0.3869509696960449, -0.2154107689857483, 0.6209322214126587, 0.420291006565094, 0.7314680218696594, -0.5409021377563477, -0.4353184700012207, -0.08384335041046143, 0.6163008809089661, 1.44855797290802, -0.0007018165779300034, -0.8216941952705383, -0.8762568831443787, -0.814016580581665, -0.8364822864532471, 0.5728769302368164, -0.4903877079486847, 0.0758853629231453, -0.870486319065094, -0.463313490152359, 0.644270122051239, 0.3766298294067383, 1.2355538606643677, -0.17363838851451874, 0.2554207146167755, -0.3038685917854309, -0.26615607738494873, -1.2271350622177124, -0.7981051206588745, 0.393411248922348, -0.31466060876846313, -0.46298277378082275, 0.4927014112472534, -0.3336673080921173, 0.07570606470108032, -0.903286337852478, 1.2545439004898071, -0.5051459670066833, -0.17789438366889954, 0.2226693332195282, 0.6343896389007568, -0.43399497866630554, -0.8265493512153625, 0.5439452528953552, -0.10246863961219788, -0.0374772772192955, 0.45419836044311523, 0.5361953973770142, 0.37668508291244507, 0.3483584225177765, -0.10512921214103699, 0.20835570991039276, -0.25423988699913025, 0.27757012844085693, 0.3994469940662384, -0.3193711042404175, -0.12048336863517761, -1.4471633434295654, 0.7716124653816223, -0.07686203718185425, -0.5013530850410461, 0.4924178123474121, -0.17546644806861877, 0.012524577789008617, 0.49539804458618164, -0.03143884614109993, -0.7344255447387695, -0.617742121219635, -0.1347474455833435, -0.1295609474182129, -0.5322220921516418, 0.5721870064735413, 0.06924435496330261, 0.7681713104248047, 0.3225557208061218, 0.44286108016967773, 0.37935522198677063, -0.5238553881645203, 0.4953064024448395, -0.7166106104850769, 0.652279257774353, 0.4098930060863495, 0.43560153245925903, -0.27428239583969116, 0.017853466793894768, -0.8017873764038086, -0.9998869895935059, -0.6729959845542908, -0.7930707335472107, 0.15026280283927917, 0.49280524253845215, -0.22603651881217957, -0.8024860620498657, -0.5121549367904663, -1.3922932147979736, -0.16986079514026642, 0.229946568608284, -0.46997523307800293, 0.09146352112293243, -0.7578765749931335, -0.9116814136505127, -0.5444141030311584, -0.6718576550483704, -0.4676094055175781, 0.3882503807544708, 0.09931211173534393, -0.5668171048164368, -0.7724590301513672, 0.18977206945419312, 0.032914113253355026, 0.2484665811061859, -0.32675623893737793, 0.8033451437950134, -0.24058780074119568, -0.1859329491853714, 0.28314438462257385, 0.13645559549331665, 0.35655874013900757, 0.015376899391412735, -0.21988585591316223, -0.2968105673789978, 0.3575274646282196, -0.2687411308288574, -0.25942108035087585, 0.09970281273126602, -0.021826863288879395, 0.4386748969554901, 0.17778915166854858, -0.531227171421051, 0.2686500549316406, 1.1255022287368774, -0.6272841691970825, 0.3047550618648529, -0.00027667550602927804, 0.7979038953781128, 0.7109645009040833, -0.15740537643432617, 0.27548062801361084, 0.5766984820365906, 0.567180871963501, 0.07854015380144119, 0.17415867745876312, -0.201111301779747, -0.6633955240249634, 0.5528664588928223, 0.8465607166290283, 0.03104453906416893, 0.22418628633022308, -1.2231602668762207, 0.76259845495224, -1.0195542573928833, -0.5614967346191406, 0.22362737357616425, 0.36028534173965454, 0.617068886756897, -0.7286136150360107, -0.2306329309940338, -0.5818446278572083, 0.6478835344314575, 0.13711634278297424, -0.3037859797477722, -0.3566402494907379, 0.4679724872112274, 0.4406704008579254, -0.14418096840381622, 0.7268255352973938, -0.5058774948120117, 0.723617672920227, 14.602477073669434, 0.37665900588035583, 0.17825429141521454, 0.40642300248146057, 0.5091708302497864, 0.5443006157875061, -0.11729555577039719, -0.2919984459877014, -1.6787588596343994, -0.565658688545227, 1.1563791036605835, -0.06859494745731354, 0.45414528250694275, -0.04808348789811134, 0.02398049645125866, 0.49821898341178894, -0.8407204151153564, 0.8536661863327026, 0.18488749861717224, -1.4359451532363892, -0.025138845667243004, 0.5170277953147888, -0.2766932249069214, 0.6741399765014648, 0.43604815006256104, 0.9438326358795166, 0.8259674906730652, -0.8357111811637878, 0.38117215037345886, 0.21910883486270905, 0.59087073802948, 0.1541835367679596, 0.4403131604194641, 0.9321144223213196, -0.8792049288749695, -0.38312941789627075, -0.5478883981704712, -0.6413120031356812, 0.5868685245513916, -0.14643308520317078, -0.9819686412811279, -0.12433259189128876, -0.38976994156837463, 0.7889178991317749, 0.33069750666618347, 0.2470865249633789, -0.7702444195747375, 0.6363160014152527, -0.04494045302271843, -0.007899491116404533, 0.08397568017244339, 0.3367273211479187, 0.8204862475395203, -0.03869752958416939, -0.3420352041721344, 0.2646457552909851, 0.19612760841846466, 0.8705782294273376, -0.8908106088638306, -0.212119460105896, -0.2901524603366852, -0.21553397178649902, -0.004575191996991634, 1.185521125793457, 0.8579946160316467, 0.36358165740966797, -0.27912238240242004, 0.14466841518878937, 0.5977602601051331, -0.34529808163642883, -0.008599719032645226, -0.17841848731040955, 0.19164201617240906, -0.09964071959257126, -0.07989417761564255, 0.01779462955892086, -0.04887862876057625, -0.8556509613990784, -1.137195348739624, 0.04135952517390251, 0.8448567390441895, -0.6200382113456726, -0.7313106060028076, 0.9093344807624817, -0.18098002672195435, -0.2772687077522278, -0.3550954759120941, -0.8511388897895813, -0.1791841983795166, 0.3068435490131378, -1.3614568710327148, -0.8797072172164917, 0.07968250662088394, -0.0038081768434494734, -0.4655151069164276, 0.07024937123060226, 1.6196483373641968, 0.04038169980049133, -0.4280792474746704, -0.030061766505241394, -0.16553907096385956, 0.8850657939910889, -0.2060558795928955, -1.0202809572219849, 0.38290831446647644, -0.19925613701343536, 0.24171032011508942, 0.3364892899990082, 0.05682038888335228, -0.051375847309827805, -0.4213658571243286, -0.2770400643348694, 0.9183072447776794, -1.2121518850326538, -0.23754280805587769, -1.0531563758850098, -0.9716850519180298, 0.7554354667663574, 0.9057953953742981, -0.4912976920604706, 0.7397087812423706, 0.7627644538879395, -0.7338239550590515, 0.23782803118228912, -1.162043809890747, -0.1452389508485794, 0.8028033971786499, -0.6761137843132019, -1.2664788961410522, -0.5818840861320496, 0.1812155842781067, -0.8609764575958252, -0.9045789241790771, -0.27403947710990906, 0.0008123620646074414, 0.2489822953939438, 0.6086446642875671, -0.7652328610420227, 0.6829793453216553, 0.7765835523605347, 0.07935936748981476, -0.7536356449127197, -0.055145248770713806, -1.0013893842697144, -0.0969458594918251, 0.3369637727737427, 0.9738090634346008, -0.2724415063858032, 0.5130589008331299, 1.0773329734802246, 0.06097785383462906, -0.03467710316181183, -0.6109017133712769, -0.22663992643356323, 0.252037912607193, 0.16859805583953857, 0.02279619872570038, 0.3327312171459198, -0.20850622653961182, 1.1047285795211792, 0.5237923264503479, 0.5420056581497192, -0.10450300574302673, -0.5294988751411438, 0.3584652245044708, -0.6410170793533325, -0.2441926747560501, -0.16067259013652802, -0.21118758618831635, -1.6325474977493286, 0.3640688955783844, -1.1827332973480225, -0.1305457055568695, -1.063136339187622, -0.11179981380701065, 0.36161792278289795, 0.023863868787884712, 0.46069100499153137, 0.5651815533638, -0.6582592129707336, -0.5646957755088806, -0.7024236917495728, -0.6046578884124756, 0.9123241305351257, 0.6330491304397583, -0.6941310167312622, 0.11994769424200058, -0.11624439805746078, -0.47369709610939026, 0.48855113983154297, 0.30845311284065247, -0.380864679813385, -0.5407505631446838, -1.259281039237976, 0.14781005680561066, 0.14981786906719208, -0.126897394657135, 0.047998152673244476, 0.6375611424446106, 0.44369322061538696, -0.19512683153152466, -0.19752338528633118, 0.43140995502471924, -0.9645254611968994, -0.422656774520874, 0.08741015195846558, -0.7006499171257019, -0.4597908854484558, 0.08487457782030106, -0.7610540986061096, -0.262783020734787, 0.1663089394569397, 0.04883859306573868, -1.1305831670761108, -0.7955523729324341, 0.11277543008327484, -0.5073270797729492, -0.02202281728386879, -0.12314282357692719, -0.05288819223642349, -0.9996349811553955, -0.3839286267757416, -0.39820030331611633, 0.6726379990577698, -0.7120845913887024, 0.6715507507324219, 0.20444677770137787, -0.8519993424415588, -0.1294170767068863, -0.2613834738731384, -0.3014715015888214, -0.02182123437523842, 0.3777855634689331, 0.6151190996170044, 0.2904324233531952, 0.5054142475128174, 0.1029578447341919, 0.6300688982009888, -1.3652406930923462, -0.23263196647167206, 1.322623372077942, -0.9252796173095703, -0.09820820391178131, 0.8502570390701294, -0.16482096910476685, -1.3150297403335571, 0.08119010925292969, -0.9532405734062195, -0.9819374084472656, -0.01167047955095768, 0.7759789228439331, -0.1948605626821518, -0.24265122413635254, -0.37926390767097473, -0.2286437749862671, 0.1239437535405159, -0.16919007897377014, -0.21033404767513275, 1.1624394655227661, 0.03791918233036995, -0.759705126285553, 0.28102463483810425, 0.6569952368736267, -0.46741387248039246, -0.26376718282699585, -0.6433113217353821, 0.152985081076622, 0.39614138007164, 0.37230780720710754, -0.7445328235626221, -0.41531166434288025, 0.6767627000808716, 0.00042206482612527907, 0.45604875683784485, -0.05449845269322395, 0.08084917068481445, 0.35780444741249084, 1.0003376007080078, 0.31887125968933105, -0.41304290294647217, -0.3156105577945709, 1.9262418746948242, 1.5905226469039917, -0.8464767932891846, -0.06646129488945007, -0.90371173620224, -0.5265210270881653, 1.05268132686615, 0.24150757491588593, 0.169755220413208, 1.2618062496185303, 0.003699457971379161, -0.13699382543563843, -0.06816350668668747, -0.8970036506652832, -0.3168164789676666, 0.6566176414489746, 1.3698298931121826, 0.8399984240531921, 0.09318352490663528, 0.3023408353328705, 1.4577457904815674, -0.05623035505414009, -0.11205580085515976, 0.7201271653175354, 0.14098335802555084, -0.1034114733338356, -0.7109060287475586, 0.23338229954242706, 0.4743090271949768, -0.8855522274971008, -0.23426932096481323, -0.8722108006477356, 0.4756718575954437, 0.028876328840851784, 0.4210340976715088, 0.4912019371986389, 0.08113330602645874, 0.8094377517700195, 0.4316265285015106, 0.49089503288269043, -1.0555676221847534, -0.6377241611480713, -0.4765562117099762, 0.24556781351566315, -0.06327399611473083, -0.3008384704589844, -0.5732163786888123, -0.7637344598770142, -0.07632088661193848, 0.2574734687805176, 0.24116367101669312, 0.16595116257667542, 1.228816270828247, 0.6595363020896912, 0.20330114662647247, -0.21390073001384735, 0.123543381690979, -0.43797004222869873, -1.3221979141235352, 0.001260422053746879, -0.7692357897758484, -0.35055410861968994, -0.41239479184150696, 0.44637203216552734, -0.31759530305862427]}, "authors": [{"authorId": "2108755854", "name": "Chenguang Wang"}, {"authorId": "2111312892", "name": "Xiao Liu"}, {"authorId": "48354042", "name": "Zui Chen"}, {"authorId": "2113253456", "name": "Haoyun Hong"}, {"authorId": "2218289739", "name": "Jie Tang"}, {"authorId": "2112739650", "name": "Dawn Song"}], "references": [{"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "f3a332ff1b73acda482e5d83696b2c701f487819", "title": "P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"}, {"paperId": "baa8b6fc12a2b410c69c2621dada73339b96da48", "title": "Zero-Shot Information Extraction as a Unified Text-to-Triple Translation"}, {"paperId": "85061c524fdd5ec75f06a3329352621bb8d05f43", "title": "Label Verbalization and Entailment for Effective Zero and Few-Shot Relation Extraction"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "ead441f3e9db042ffdeaf469f70bbe4b127d9060", "title": "Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with Language Models"}, {"paperId": "e337ed6543c2e6e7e51c312c7d998798fc79fdde", "title": "Knowledgeable or Educated Guess? Revisiting Language Models as Knowledge Bases"}, {"paperId": "c09ff6965322ece56bce383266c75159234f59c4", "title": "A Unified Generative Framework for Various NER Subtasks"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "1cb3f6d545b68db3e7fc6055dcf44099c3ac4672", "title": "Structured Prediction as Translation between Augmented Natural Languages"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "b360427d0991143013da6a208ccf28bcc8028fab", "title": "Large Scale Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training"}, {"paperId": "3ee955bfb656e30a337b22a1149b5ecc91a91217", "title": "Language Models are Open Knowledge Graphs"}, {"paperId": "f30444fbb6ad806168e2564db4815cd27faa7fd9", "title": "It\u2019s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners"}, {"paperId": "15f002dde348b82817fa2a59e7ed56e6e3ec6972", "title": "Augmented Natural Language for Generative Sequence Labeling"}, {"paperId": "77c42a438b320aed8e1fd6be69f7e14347e2f78e", "title": "MultiWOZ 2.2 : A Dialogue Dataset with Additional Annotation Corrections and State Tracking Baselines"}, {"paperId": "5919449af919cc6d9bdf3e5025bbf04feba823bb", "title": "Neural Machine Translation with Error Correction"}, {"paperId": "0fc2b08409def9f7ef6beff8ff2155c0dcff2345", "title": "A Relation-Specific Attention Network for Joint Entity and Relation Extraction"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "84286c4a614c198593d0e19623cdce318416f212", "title": "Named Entity Recognition as Dependency Parsing"}, {"paperId": "01ec011977fc6cda03e8b447e1b5eb0551f1c961", "title": "A Simple Language Model for Task-Oriented Dialogue"}, {"paperId": "3db2a48d44f7cfca152df85492a5e417466ab1be", "title": "Efficient long-distance relation extraction with DG-SpanBERT"}, {"paperId": "71cd5145c3ec27838bf06a1a09980314f05a17ba", "title": "The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding"}, {"paperId": "c44120f765fc43994c5cfb4e12e4f62999efeae6", "title": "How Context Affects Language Models' Factual Predictions"}, {"paperId": "0bce17fdfd4872b16c97a89516a24a092cdc3616", "title": "Blank Language Models"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "5487dadb5b4b8b240ab4ae28705acc0b9f138db0", "title": "Dice Loss for Data-imbalanced NLP Tasks"}, {"paperId": "dab8424eec426ed3996e469f657371dd53e20127", "title": "CorefQA: Coreference Resolution as Query-based Span Prediction"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "73a5605ce482bd639078ebbb19baac7b903017e2", "title": "A Unified MRC Framework for Named Entity Recognition"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "2873f78efd7adcb118a70f8ea3ca7fa1501e320a", "title": "FewRel 2.0: Towards More Challenging Few-Shot Relation Classification"}, {"paperId": "360d36899dbd44109f5040251cee35822900edb9", "title": "Span-based Joint Entity and Relation Extraction with Transformer Pre-training"}, {"paperId": "0e1772e6f3c0c5c890ff2feb6adc0a035a4822a7", "title": "Joint Extraction of Entities and Relations Based on a Novel Decomposition Strategy"}, {"paperId": "fac2368c2ec81ef82fd168d49a0def2f8d1ec7d8", "title": "Entity, Relation, and Event Extraction with Contextualized Span Representations"}, {"paperId": "d0086b86103a620a86bc918746df0aa642e2a8a3", "title": "Language Models as Knowledge Bases?"}, {"paperId": "127ffe6d21b75bd41dd808e3313bc392b9428346", "title": "BERT for Coreference Resolution: Baselines and Analysis"}, {"paperId": "52919d9a881eee8645a1ff796d75137d5d8d9383", "title": "A Novel Bi-directional Interrelated Model for Joint Intent Detection and Slot Filling"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "4af09143735210777281b66997ec12994dbb43d4", "title": "Matching the Blanks: Distributional Similarity for Relation Learning"}, {"paperId": "f13981668a98173bf6b49310f171a2093167a027", "title": "Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems"}, {"paperId": "3c1e46a8e262af64492f71c25e40d2fe86589c88", "title": "OPIEC: An Open Information Extraction Corpus"}, {"paperId": "fddbcabe0fc9be0684855ae3dd059fb525a69e5b", "title": "Simple BERT Models for Relation Extraction and Semantic Role Labeling"}, {"paperId": "f262ef2f50dfcaf07dc6598f22fb9b2470b37cf1", "title": "A general framework for information extraction using dynamic span graphs"}, {"paperId": "9f1c5777a193b2c3bb2b25e248a156348e5ba56d", "title": "Cloze-driven Pretraining of Self-attention Networks"}, {"paperId": "ca13f33970bc70d44a6159db5e14f65841abcf5a", "title": "Dependency or Span, End-to-End Uniform Semantic Role Labeling"}, {"paperId": "d449657cad3dee1ef2181870bdb2309c80ef6d2b", "title": "Text Infilling"}, {"paperId": "c0c9ccba8319477c72151b5a28eec864407175fd", "title": "One for All: Neural Joint Modeling of Entities and Events"}, {"paperId": "274b4ad4840b0a8a70c5bac3fe4b4861ce5fbb95", "title": "FewRel: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation"}, {"paperId": "f4a5503783487eba5c5e34b1d02c09016b244b1d", "title": "MultiWOZ - A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling"}, {"paperId": "45f146bdf91198ea93858d0619c2acc5761e540d", "title": "Open Information Extraction from Conjunctive Sentences"}, {"paperId": "323e2fd5b3bd334aeb7c9ff3a836f2f6eb49769b", "title": "Large-Scale Multi-Domain Belief Tracking with Knowledge Sharing"}, {"paperId": "6fc991dbc1714b425d11b4de3d9d247d21d77c0b", "title": "Supervised Open Information Extraction"}, {"paperId": "15c10b24ef645d83ff4059affd86945c33e00328", "title": "Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces"}, {"paperId": "11eaa4f1cba9281ecbc1ac44a6b3ba5817bf1a25", "title": "T-REx: A Large Scale Alignment of Natural Language with Knowledge Base Triples"}, {"paperId": "e6566ece21f6637c515fe9969f9d1ec6cca6d36c", "title": "Higher-Order Coreference Resolution with Coarse-to-Fine Inference"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "a4c40532e68728fbeab5d9415f6ad8e9530db360", "title": "The WebNLG Challenge: Generating Text from RDF Data"}, {"paperId": "400e746bc8027c4b5f915cae6123cd1775484b4d", "title": "Position-aware Attention and Supervised Data Improve Slot Filling"}, {"paperId": "6d431f835c06afdea45dff6b24486bf301ebdef0", "title": "An Overview of Multi-Task Learning in Deep Neural Networks"}, {"paperId": "f6767e9260623dfb6cc7628ef0333c0dcd7f3e63", "title": "Table Filling Multi-Task Recurrent Neural Network for Joint Entity and Relation Extraction"}, {"paperId": "a32d7aba28ce9f130934b8e892df5bf2cad97e21", "title": "Creating a Large Benchmark for Open Information Extraction"}, {"paperId": "fba28688404c090661d29cd8b90acf1cb74d959c", "title": "Which Coreference Evaluation Metric Do You Trust? A Proposal for a Link-based Entity Aware Metric"}, {"paperId": "38ee5f3b088770ddf8bfb04dbc3012e1413a5039", "title": "Demonyms and Compound Relational Nouns in Nominal Open IE"}, {"paperId": "48e8e8085907192d501eb2bcc582035e90431a2f", "title": "Multi-Task Cross-Lingual Sequence Tagging from Scratch"}, {"paperId": "027ced58a1fb3600f438c856b9cc4e1ac24cb0a6", "title": "Getting More Out Of Syntax with PropS"}, {"paperId": "7daf69424feafdce1c896ff19f9a08a5b31ad5d8", "title": "Question-Answer Driven Semantic Role Labeling: Using Natural Language to Annotate Natural Language"}, {"paperId": "3171ec184b5fec0bc7b47356ad74d8598e858ddc", "title": "Leveraging Linguistic Structure For Open Domain Information Extraction"}, {"paperId": "a4c9384b9cffcf75213858a4b003b65e48a9331f", "title": "Effectiveness and Efficiency of Open Relation Extraction"}, {"paperId": "c92970286c535992a86539b761357761e97a37ee", "title": "Towards Robust Linguistic Analysis using OntoNotes"}, {"paperId": "b04e3d829cec0d98224b73560b2bf27586523e48", "title": "Open Information Extraction with Tree Kernels"}, {"paperId": "14347af6ab135fae319dcbff9fe573fbe757d99f", "title": "Development of a benchmark corpus to support the automatic extraction of drug-related adverse effects from medical case reports"}, {"paperId": "1b97b4623cf2f183340e548e0aa53abf0f2963d8", "title": "Representing General Relational Knowledge in ConceptNet 5"}, {"paperId": "30d226088c4f00b24ded6367757ad88320cc40aa", "title": "An analysis of open information extraction based on semantic role labeling"}, {"paperId": "e7e7b9a731678bf0494fe29cbebb42a822224cc6", "title": "Modeling Relations and Their Mentions without Labeled Text"}, {"paperId": "57458bc1cffe5caa45a885af986d70f723f406b4", "title": "A unified architecture for natural language processing: deep neural networks with multitask learning"}, {"paperId": "25e7efa59a5cf68e0fc9401e4c6fa7b2bfe3f1ae", "title": "Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling"}, {"paperId": "5aa70188f70d349580aed96c10a68f57dace2d33", "title": "A Linear Programming Formulation for Global Inference in Natural Language Tasks"}, {"paperId": "10f97f1fb4f5c2c8e6c44d4a33da46d331dd4aeb", "title": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition"}, {"paperId": "fd268d35d3e3e4d368e94050163fba9ede42ffe2", "title": "The GENIA corpus: an annotated research abstract corpus in molecular biology domain"}, {"paperId": "161ffb54a3fdf0715b198bb57bd22f910242eb49", "title": "Multitask Learning"}, {"paperId": "1d19708290ef3cc3f43c2c95b07acdd4f52f5cda", "title": "The ATIS Spoken Language Systems Pilot Corpus"}, {"paperId": "da5d78b3e3a1544fde98fba86088e1215e97cbe8", "title": "All NLP Tasks Are Generation Tasks: A General Pretraining Framework"}, {"paperId": null, "title": "different scales: 110M, 220M, 2B, and 10B 2 . The 110M model is pretrained over English Wikipedia and BookCorpus, and the others are pretrained over the Pile corpora (Gao et al.,"}, {"paperId": null, "title": "as our base language model pretrained on autoregressive blank in\ufb01lling objectives. GLM follows an adaptive encoder-decoder architecture"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "22d64e6d55c34f1a1a5884305c940526d826deab", "title": "MultiWOZ 2."}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "2018) is used in the factual probe"}, {"paperId": null, "title": "Linguistic Data Consortium, Philadel"}, {"paperId": null, "title": "Ontonotes release 5.0 ldc2013t19"}, {"paperId": null, "title": "The CoNLL04 dataset: CoNLL04 consists of annotated named entities and relations on sentences taken from WSJ, AP"}, {"paperId": null, "title": "Glauber; instance of; human ) ( Robert R. Glauber; company; NASD ) ACE2005 jer ace2005: The Davao Medical Center"}, {"paperId": null, "title": "ACE 2005 Multilingual Training Corpus"}, {"paperId": "a3705f24c62170829997818137d3455e27c3ef66", "title": "PropBank: the Next Level of TreeBank"}, {"paperId": null, "title": "DeepStruct: train LM to produce triples from text"}, {"paperId": null, "title": "DeepStruct 10B zero-shot model largely outperforms GPT-3 175B"}, {"paperId": null, "title": "State-of-the-art on 21 of 28 datasets over 10 tasks"}, {"paperId": null, "title": "the pretrain-\ufb01netune consistency via cloze-style \ufb01netuning. GLM adopts the Byte Pair Encoding Radford et al., 2019b), covering 50,257 tokens."}, {"paperId": null, "title": "bidirectional model and is able to perform autoregressive generation. Structure Pretraining Procedure"}, {"paperId": null, "title": "GPT-3. GLM outperforms T5 on text summarization, which shares a similar nature with structure prediction tasks"}, {"paperId": null, "title": "A.1 Implementation Details Model Architecture We leverage"}, {"paperId": null, "title": "pre-training on 8 NVIDIA DGX-A100 machines using an Adam optimizer with a 5e-6 learning rate and"}]}