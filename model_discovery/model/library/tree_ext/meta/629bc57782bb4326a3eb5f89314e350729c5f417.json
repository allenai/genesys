{"paperId": "629bc57782bb4326a3eb5f89314e350729c5f417", "title": "AdapterSoup: Weight Averaging to Improve Generalization of Pretrained Language Models", "abstract": "Pretrained language models (PLMs) are trained on massive corpora, but often need to specialize to specific domains. A parameter-efficient adaptation method suggests training an adapter for each domain on the task of language modeling. This leads to good in-domain scores but can be impractical for domain- or resource-restricted settings. A solution is to use a related-domain adapter for the novel domain at test time. In this paper, we introduce AdapterSoup, an approach that performs weight-space averaging of adapters trained on different domains. Our approach is embarrassingly parallel: first, we train a set of domain-specific adapters; then, for each novel domain, we determine which adapters should be averaged at test time. We present extensive experiments showing that AdapterSoup consistently improves performance to new domains without extra training. We also explore weight averaging of adapters trained on the same domain with different hyper-parameters, and show that it preserves the performance of a PLM on new domains while obtaining strong in-domain results. We explore various approaches for choosing which adapters to combine, such as text clustering and semantic similarity. We find that using clustering leads to the most competitive results on novel domains.", "venue": "Findings", "year": 2023, "citationCount": 38, "influentialCitationCount": 5, "openAccessPdf": {"url": "http://arxiv.org/pdf/2302.07027", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper introduces AdapterSoup, an approach that performs weight-space averaging of adapters trained on different domains, and explores various approaches for choosing which adapters to combine, such as text clustering and semantic similarity."}, "embedding": {"model": "specter_v2", "vector": [-0.07303069531917572, 0.15610480308532715, -0.27122431993484497, -0.4750463664531708, -0.7544874548912048, -0.20684459805488586, 0.6172963380813599, -0.3616027235984802, -0.6299577355384827, -0.2486211359500885, 0.8322023749351501, 0.014028084464371204, 0.149752676486969, 0.21971110999584198, -0.20797529816627502, 0.13659970462322235, -0.57138592004776, 0.6983113288879395, 0.027970775961875916, -0.4720105230808258, -0.6398636698722839, -0.7131536602973938, -0.5137730240821838, 0.060960326343774796, 0.640311598777771, 0.3186328411102295, 0.3739617168903351, 0.6847381591796875, -0.37358665466308594, -0.2585085332393646, 0.46874895691871643, -0.4703323543071747, 0.3229599893093109, -0.3834276497364044, -0.057357124984264374, 0.14094389975070953, 0.2830986976623535, -0.292570561170578, -0.26282283663749695, 0.6696669459342957, -0.2629926800727844, 0.3750038146972656, 0.6390038132667542, -0.5170034170150757, -0.21461252868175507, 0.8302377462387085, 0.9481770396232605, 0.6573445200920105, -0.37467196583747864, -0.7656936049461365, 1.1891511678695679, -1.2673444747924805, 0.4303378462791443, 1.305529236793518, 0.5842664837837219, 0.6982153058052063, -0.6681437492370605, -0.9542900323867798, 0.5708848834037781, -0.04722573608160019, -0.975353479385376, -0.3822716772556305, 0.10099861770868301, -0.2303665578365326, 1.9918556213378906, -0.44438645243644714, -0.1685074269771576, 0.47906097769737244, -0.29045337438583374, 1.1743814945220947, -0.6113341450691223, -0.3866640627384186, -0.4379335045814514, 0.37469714879989624, 0.08059111982584, 0.6385904550552368, -0.7071144580841064, 0.18829184770584106, -0.6449015140533447, -0.22089974582195282, -0.028501570224761963, -0.06791143864393234, 0.036438170820474625, -0.10368940234184265, -0.33656027913093567, 0.8432521224021912, 0.38546091318130493, 1.08413565158844, -0.10424676537513733, 0.5760170817375183, 0.5461694002151489, 0.5201911330223083, 0.4363653063774109, 0.8790650963783264, -0.45166072249412537, 0.6350442171096802, -0.9207789301872253, 0.5119163393974304, -0.14025932550430298, 1.106059193611145, 0.1965898722410202, 0.023025859147310257, -0.12545470893383026, 0.639488697052002, 1.3622936010360718, -0.14869213104248047, 0.8416383862495422, -0.7775156497955322, 0.39273685216903687, -0.3983798027038574, -0.11806533485651016, -0.3627006709575653, -0.7654580473899841, -0.333376407623291, -0.6710354685783386, -1.6299104690551758, -0.3876603841781616, 0.025189267471432686, -0.4920453131198883, 0.9961034655570984, -0.41426971554756165, 0.6544066667556763, 0.013691426254808903, 0.26260489225387573, 0.46643853187561035, 0.6252518892288208, 0.4832770526409149, 0.1554901897907257, 0.46854567527770996, -1.0125062465667725, -0.5081358551979065, -1.2404171228408813, 1.0059601068496704, -0.4447413682937622, 0.47291433811187744, -0.6497716307640076, -1.1805150508880615, -0.8756399750709534, -0.9806808233261108, 0.022496474906802177, -0.771567165851593, 0.12689617276191711, 0.9471105933189392, 0.3498117923736572, -0.4173678159713745, 0.9030801057815552, -0.17390216886997223, -0.6242409944534302, 0.1923610270023346, 0.10185816138982773, 0.11145302653312683, -0.5103136897087097, -1.1891276836395264, 0.5102136731147766, 0.6031175255775452, -1.3362672328948975, -0.33196622133255005, -1.1330050230026245, -0.8519912958145142, -0.40908655524253845, 0.06662510335445404, -0.8289345502853394, 1.391350507736206, -0.48650431632995605, -1.1198376417160034, 0.6142600178718567, -0.5290762186050415, -0.10925783216953278, -0.010485279373824596, 0.01897275261580944, -1.1454726457595825, -0.8083675503730774, -0.12529627978801727, 0.2423887550830841, 0.15354342758655548, -0.059520624577999115, 0.022047603502869606, 0.11230070143938065, -0.2268880158662796, 0.06855475157499313, -0.6801532506942749, 0.7271303534507751, -0.193444162607193, -0.5893557071685791, 0.11080963909626007, 0.8233754634857178, -0.21159091591835022, -0.37475571036338806, 0.23291394114494324, -0.8767399787902832, 0.863091230392456, -0.18562310934066772, 0.9814553260803223, -1.1873836517333984, -0.12256079912185669, -0.29442647099494934, -0.2622511386871338, -0.24788133800029755, -1.1535933017730713, 0.8225630521774292, -0.23831596970558167, 0.3228159546852112, -0.3344658613204956, -1.3759907484054565, 0.21851211786270142, 0.008822936564683914, -0.5516855120658875, -0.5805894136428833, 0.4996495246887207, 0.9597845673561096, -1.0536211729049683, 0.2518531382083893, -0.5255118012428284, 0.15695907175540924, -1.418885350227356, 1.3563379049301147, -0.5867061614990234, 0.3057264983654022, 0.11573965102434158, -0.10187365859746933, 0.09593790024518967, -0.16627870500087738, 0.2448771446943283, -0.35894423723220825, 0.029053786769509315, 0.5649429559707642, -0.17402715981006622, 1.8009614944458008, -0.7252978682518005, -0.104111447930336, -0.10182549804449081, -0.7115265130996704, 0.14045633375644684, 0.3991727828979492, 0.06434705853462219, -0.2091251015663147, 0.33438602089881897, 0.7167894244194031, -0.6429362297058105, 0.14512307941913605, 0.746771514415741, 0.13295316696166992, -0.29583853483200073, 0.0325603112578392, 1.3054122924804688, -0.47832363843917847, 0.7026255130767822, 0.3480881154537201, 0.9344020485877991, -0.026534847915172577, 0.22167429327964783, -0.02294440008699894, 0.5749450922012329, -0.5852454304695129, -0.07722114026546478, -0.1489899903535843, 0.7006323933601379, 0.7052116394042969, -0.2735401690006256, -0.5293055772781372, -0.5871558785438538, -0.6356514096260071, 0.7042480111122131, 1.8237841129302979, -0.42888036370277405, -0.33123740553855896, -0.5838972330093384, -0.4631011188030243, -0.15715117752552032, 0.453966349363327, -0.3874931335449219, -0.41435596346855164, -0.44359272718429565, -1.0028223991394043, 0.8010075092315674, 0.4879698157310486, 1.1404931545257568, 0.18456429243087769, 0.3131403923034668, -0.10901103913784027, -0.21593882143497467, -0.5509184002876282, -1.095118522644043, 0.2509097754955292, -0.605141282081604, 0.07364308089017868, -0.168028324842453, -0.13325262069702148, 0.04820169508457184, -0.5445144176483154, 1.1930896043777466, -0.49598729610443115, 0.010440710932016373, 0.29979366064071655, 0.4614197313785553, -0.7858677506446838, -0.9936717748641968, 0.4282197952270508, 0.5450413227081299, 0.025570478290319443, 0.5530580878257751, 0.2685462534427643, 0.18256251513957977, 0.4751812219619751, -0.5491030812263489, 0.09028147906064987, -0.2352236658334732, 0.4214169979095459, 0.5735241770744324, -0.26730698347091675, 0.22956685721874237, -1.2371011972427368, 0.9967200756072998, -0.27073004841804504, -0.12166643142700195, 0.3756650984287262, -0.1600130796432495, -0.5964635610580444, 0.35624557733535767, -1.0028201341629028, -0.36577144265174866, -0.9329276084899902, 0.1266653686761856, 0.07682478427886963, -0.034201912581920624, 0.5200643539428711, -0.02277262881398201, 0.40949398279190063, 0.719248354434967, 0.11452128738164902, 0.2825723886489868, -0.4636421799659729, 0.5432223081588745, -0.9388649463653564, 0.16456535458564758, 0.3410656452178955, 0.5875533223152161, -0.23772402107715607, -0.3936326801776886, -0.604297935962677, -0.3463118076324463, -0.714805006980896, -0.5258985757827759, -0.1612725406885147, 0.21375198662281036, -0.5985850095748901, -0.04172714427113533, -0.17652487754821777, -0.9713590741157532, -0.3352462947368622, 0.04081927612423897, -0.09542381018400192, -0.3200942575931549, -1.4882431030273438, -0.7985178232192993, -0.22587725520133972, -0.3131757974624634, -0.7712063789367676, 0.3597696125507355, 0.0006515522836707532, -0.4878607988357544, -0.9633239507675171, 0.13136301934719086, -0.29587894678115845, 1.4715826511383057, -0.7129641771316528, 0.7842493057250977, -0.11272783577442169, 0.07954607903957367, -0.39749541878700256, 0.08357620239257812, 0.6640021800994873, -0.4084702134132385, -0.2634432315826416, -0.9007734656333923, 0.13733983039855957, -0.5045021772384644, -0.13560758531093597, 0.2827228903770447, -0.09976468980312347, 0.6342753767967224, 0.20009943842887878, -0.662114143371582, 0.47850582003593445, 1.3850947618484497, -0.6299989223480225, -0.2657913267612457, -0.1346384435892105, 0.5500354170799255, 0.2594149708747864, -0.6015177965164185, 0.27768218517303467, 0.5664045214653015, 0.5747731924057007, -0.3460346758365631, -0.051774244755506516, -0.16808322072029114, -0.7338002920150757, 0.6074008345603943, 2.201408863067627, 0.11870209127664566, 0.16939973831176758, -1.1008923053741455, 0.84180748462677, -1.2170814275741577, -0.48915863037109375, 0.9896463751792908, 0.4234696328639984, 0.45627567172050476, -1.1703134775161743, 0.008162736892700195, -0.558743953704834, 0.025262724608182907, -0.040786925703287125, -0.46680134534835815, -0.47333332896232605, -0.15884451568126678, 0.45689529180526733, 0.21920718252658844, 0.511046290397644, -0.26757490634918213, 0.6754924654960632, 14.369348526000977, 1.11232590675354, 0.32761088013648987, 1.3027563095092773, 0.12731477618217468, 0.20451872050762177, -0.4928385317325592, -0.21249838173389435, -1.0694794654846191, -0.23749282956123352, 1.2885537147521973, -0.33524879813194275, 1.0772148370742798, -0.007836790755391121, -0.08069705218076706, 0.569956362247467, -0.4204898178577423, 0.4149647653102875, 0.6072084307670593, -1.3362923860549927, 0.49226778745651245, 0.07862680405378342, 0.5231111645698547, 0.9350680708885193, 0.6039190888404846, 1.001138687133789, 0.3631118834018707, -0.251475065946579, -0.02147073671221733, 0.3138277530670166, 0.5602947473526001, 0.010844841599464417, 0.5020135045051575, 0.3763384521007538, -0.8104878067970276, -0.3002995252609253, -0.8571403622627258, -0.9282280802726746, 0.613753616809845, -0.05401107296347618, -0.5929092764854431, -0.42246243357658386, -0.10805497318506241, 1.0997684001922607, -0.021634787321090698, 0.40477943420410156, 0.2619849145412445, 0.6652323603630066, -0.12740027904510498, 0.29036158323287964, 0.27486637234687805, 0.3746151030063629, 0.3174467384815216, 0.23260262608528137, 0.2091776579618454, -0.18142932653427124, 0.1974230408668518, 0.5919102430343628, -0.7253357768058777, 0.2852182984352112, -0.7060781717300415, -0.32102665305137634, -0.3794999122619629, 0.6241234540939331, 0.9784826636314392, -0.2686088979244232, -0.7346171140670776, 0.3740897476673126, 0.5247035622596741, 0.34133076667785645, -0.42902395129203796, -0.08615031093358994, 0.6121643781661987, 0.025625593960285187, -0.4398806691169739, 0.24583016335964203, -0.16256670653820038, -0.4722338318824768, -1.0139307975769043, -0.026629095897078514, 0.6510446071624756, -0.7555663585662842, -1.3483401536941528, 0.9465242624282837, 0.09429516643285751, -0.6625323295593262, 0.1840074062347412, -0.8388710618019104, -0.30012595653533936, 0.5210579633712769, -1.2771892547607422, -0.7598756551742554, 0.1836908459663391, -0.0882088765501976, -0.2936828136444092, -0.7879079580307007, 1.6742427349090576, 0.6050722599029541, -0.18901272118091583, 0.26892533898353577, 0.33844244480133057, -0.11104677617549896, 0.25294366478919983, -0.7031832933425903, 0.7924037575721741, -0.1328711360692978, -0.022241348400712013, 0.3011619448661804, -0.11000208556652069, 0.16366367042064667, -0.5929571986198425, -0.4991597831249237, 0.9702087044715881, -0.9616607427597046, -0.0018407338066026568, -0.6612842082977295, -0.8878366351127625, 0.3465796411037445, 0.8179519772529602, -0.6407253742218018, 0.9445877075195312, 0.5816195607185364, -1.1543457508087158, -0.24728798866271973, -1.1276421546936035, 0.30175265669822693, 0.8490471839904785, -0.5942118167877197, -0.5840676426887512, 0.3451879024505615, 0.621284544467926, -0.8619211912155151, -0.8616474866867065, -0.07061484456062317, -0.007866146042943, 0.22843331098556519, 0.9548457860946655, -0.5593866109848022, 0.49904459714889526, 0.7726643085479736, -0.3662019371986389, -1.2708511352539062, -0.10730253905057907, -0.4970720112323761, 0.4141741394996643, 0.13357402384281158, 1.0091156959533691, -0.5265554785728455, -0.15005667507648468, 0.7911623120307922, 0.10178761929273605, -0.00018092220125254244, -0.6265438795089722, -0.6818731427192688, 0.3240349590778351, -0.45111986994743347, 0.6437293291091919, 0.3850324749946594, 0.02546815201640129, 0.19807031750679016, 0.8103631734848022, 0.5561432838439941, -0.31550440192222595, -1.3191297054290771, 0.7427800893783569, 0.0482168011367321, -0.3827226459980011, -0.5777785181999207, -0.6064370274543762, -1.0957670211791992, 0.43678444623947144, -1.583717942237854, -0.3990688621997833, -0.6083205938339233, -0.3621615767478943, 0.19455596804618835, -0.24870972335338593, -0.2275959998369217, 0.5669147968292236, -0.030047809705138206, -0.34685924649238586, -0.8879558444023132, -0.3384404182434082, 0.7768518924713135, 0.8215753436088562, -1.1208348274230957, -0.03992113098502159, -0.29198628664016724, 0.24782796204090118, 0.6771239638328552, 0.7372111678123474, -0.2722926735877991, -0.7080860733985901, -1.8206274509429932, 0.13307775557041168, -0.5259478688240051, -0.05656003579497337, -0.601952314376831, 0.6516953706741333, 0.44005128741264343, -0.16104832291603088, 0.2701621651649475, 0.3985130190849304, -0.9400163292884827, -0.09768625348806381, 0.0031049521639943123, -0.4191826581954956, 0.7064841389656067, 0.3962453603744507, -0.47779616713523865, -0.41097861528396606, 0.6952855587005615, 0.1092858761548996, -1.1308138370513916, -0.5521497130393982, 0.13329152762889862, -0.701912522315979, 0.30240797996520996, -0.45892611145973206, 0.18159134685993195, -0.7551290392875671, -0.3833805024623871, 0.09570424258708954, 0.36481955647468567, -0.3142469525337219, 0.983916699886322, 0.2740534245967865, -1.4928655624389648, -0.0477386899292469, 0.3543282151222229, 0.558830976486206, -0.4262630343437195, 0.8378506302833557, 0.41359761357307434, 0.00868743471801281, 0.2006533294916153, 0.3168673515319824, 0.444023460149765, -0.8482590913772583, -0.21075047552585602, 0.9823524951934814, -0.3356891870498657, 0.1310017704963684, 1.4056812524795532, -0.2841297388076782, -1.5644242763519287, -0.022622035816311836, -1.1098297834396362, 0.12892967462539673, -0.34263941645622253, 0.7984428405761719, 0.23231442272663116, -0.012915726751089096, -0.16337370872497559, -0.1709972620010376, 0.4050135910511017, -0.1757727861404419, -0.6113156676292419, 0.7018541097640991, -0.2391844093799591, -0.4350273311138153, 1.0198878049850464, 0.8856645226478577, -0.8388551473617554, -0.22941260039806366, -0.8446053862571716, -0.12281516939401627, -0.09736613929271698, 0.2574321925640106, -0.7018887996673584, -0.49510374665260315, 0.7051160931587219, 0.529165506362915, -0.1515992134809494, 0.3572668731212616, 0.008732364512979984, 0.5385807752609253, 0.5384939312934875, 0.048099663108587265, -1.0019577741622925, -0.600783109664917, 1.4258439540863037, 1.3907153606414795, -0.9146454930305481, 0.21511320769786835, 0.16541635990142822, -0.8318016529083252, 0.6283102631568909, 0.15479817986488342, -0.118840791285038, 1.2878104448318481, -0.33224520087242126, 0.30872517824172974, 0.282723993062973, -0.989779531955719, -0.46108731627464294, 1.2349568605422974, 1.1507326364517212, 0.9335584044456482, 0.5860909223556519, -0.25891536474227905, 1.0557637214660645, 0.24212200939655304, -0.142289936542511, 0.20087780058383942, -0.1325361281633377, -0.03202638402581215, -0.5520092844963074, 0.18379078805446625, 0.6306604743003845, -0.21783702075481415, -0.2781534194946289, -0.30655404925346375, 0.6243141889572144, 0.6062142848968506, 0.5917719006538391, 0.6665160059928894, -0.32818976044654846, 0.740233838558197, 0.6623649597167969, 0.3649364709854126, -0.6387500166893005, -0.3930601179599762, -0.3482195734977722, -0.4550014138221741, -0.04178663715720177, -0.5029691457748413, -0.4687507450580597, -0.23312033712863922, -0.16119325160980225, 0.1574222296476364, -0.07420051097869873, 0.5951780676841736, 1.1592817306518555, 0.6932216882705688, 0.5022099018096924, -0.421901136636734, -0.5802976489067078, -0.1397116482257843, -1.2299973964691162, -0.012573223561048508, -0.11210554093122482, -0.5242170095443726, -0.42292895913124084, -0.07278650254011154, -0.288775235414505]}, "authors": [{"authorId": "3379701", "name": "Alexandra Chronopoulou"}, {"authorId": "39139825", "name": "Matthew E. Peters"}, {"authorId": "2277248", "name": "Alexander M. Fraser"}, {"authorId": "34176020", "name": "Jesse Dodge"}], "references": [{"paperId": "7c3a735c7567b5b54581ba09612db4d18a5dacac", "title": "M2D2: A Massively Multi-Domain Language Modeling Dataset"}, {"paperId": "8b3a67c7e5289eed160d2acfd04d71cfb552c67d", "title": "Branch-Train-Merge: Embarrassingly Parallel Training of Expert Language Models"}, {"paperId": "00df5cf0d83c48657d453ab8083d8805a67f744f", "title": "Measuring the Carbon Intensity of AI in Cloud Instances"}, {"paperId": "54020e5fe48ebb250f27d744e20a63cac2988a84", "title": "Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time"}, {"paperId": "fb01415a0decfa3f3d6339930e95028ae1ff4170", "title": "Efficient Large Scale Language Modeling with Mixtures of Experts"}, {"paperId": "5b0cfef3ebb8f709a4cf2e4718e8440cc5890bab", "title": "Efficient Hierarchical Domain Adaptation for Pretrained Language Models"}, {"paperId": "06b20a1c6883464fcb2855adc146874fe7937c41", "title": "Merging Models with Fisher-Weighted Averaging"}, {"paperId": "51d62830c1112ea7443398990b850a988ed7c86c", "title": "Multilingual Domain Adaptation for NMT: Decoupling Language and Domain Information with Adapters"}, {"paperId": "7b5b15279e5a52439614f886b79fa33f4b88bfb2", "title": "Efficient Test Time Adapter Ensembling for Low-resource Language Varieties"}, {"paperId": "9289826beb6206eeaf500105f7329d6d5a495d8a", "title": "Robust fine-tuning of zero-shot models"}, {"paperId": "917c63f2186119166b3379f5d2816bb1a2f39b09", "title": "DEMix Layers: Disentangling Domains for Modular Language Modeling"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "1adadbfa95e43a70fcd17e6ce947a0652b86bfc3", "title": "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "26299d5fdc5137291dc6a091573b3d18aba1d1c2", "title": "MAD-X: An Adapter-based Framework for Multi-task Cross-lingual Transfer"}, {"paperId": "e816f788767eec6a8ef0ea9eddd0e902435d4271", "title": "Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks"}, {"paperId": "95856e0789481eedc2cedc413581a0a819ef8fc8", "title": "Unsupervised Domain Clusters in Pretrained Language Models"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "48530f3d6425f2f150f07ccdd61ba951951a0a7d", "title": "Simple, Scalable Adaptation for Neural Machine Translation"}, {"paperId": "93d63ec754f29fa22572615320afe0521f7ec66d", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "title": "Energy and Policy Considerations for Deep Learning in NLP"}, {"paperId": "c39e409d6b7744200c4fd12a6b81e51f6145cfae", "title": "Unsupervised Domain Adaptation of Contextualized Embeddings for Sequence Labeling"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "d89ee98810039d2061ed42ee8026da49c503d16b", "title": "Learning multiple visual domains with residual adapters"}, {"paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586", "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"}, {"paperId": "5aa26299435bdf7db874ef1640a6c3b5a4a2c394", "title": "FaceNet: A unified embedding for face recognition and clustering"}, {"paperId": "56010a55d49ac1f42355538f494427fd22402be1", "title": "Exploring the Limits"}, {"paperId": null, "title": "2022a. Model soups: averaging weights of multi"}, {"paperId": "7e2530784eeae241e997627795819cf42ba8562f", "title": "AdaMix: Mixture-of-Adapter for Parameter-efficient Tuning of Large Language Models"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Dhabi, United Arab Emirates"}, {"paperId": null, "title": "for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)"}, {"paperId": null, "title": "United Arab Emirates. Association for Computational Linguistics"}]}