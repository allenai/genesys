{"paperId": "86552c4a5ee38ecbad1b2d41b8031b01b92237ea", "title": "Couplformer: Rethinking Vision Transformer with Coupling Attention", "abstract": "With the development of the self-attention mechanism, the Transformer model has demonstrated its outstanding performance in the computer vision domain. However, the massive computation brought from the full attention mechanism became a heavy burden for memory consumption. Sequentially, the limitation of memory consumption hinders the deployment of the Transformer model on the embedded system where the computing resources are limited. To remedy this problem, we propose a novel memory economy attention mechanism named Couplformer, which decouples the attention map into two sub-matrices and generates the alignment scores from spatial information. Our method enables the Transformer model to improve time and memory efficiency while maintaining expressive power. A series of different scale image classification tasks are applied to evaluate the effectiveness of our model. The result of experiments shows that on the ImageNet-1K classification task, the Couplformer can significantly decrease 42% memory consumption compared with the regular Transformer. Meanwhile, it accesses sufficient accuracy requirements, which outperforms 0.56% on Top-1 accuracy and occupies the same memory footprint. Besides, the Couplformer achieves state-of-art performance in MS COCO 2017 object detection and instance segmentation tasks. As a result, the Couplformer can serve as an efficient backbone in visual tasks and provide a novel perspective on deploying attention mechanisms for researchers.", "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision", "year": 2023, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A novel memory economy attention mechanism named Couplformer is proposed, which decouples the attention map into two sub-matrices and generates the alignment scores from spatial information and can serve as an efficient backbone in visual tasks and provide a novel perspective on deploying attention mechanisms for researchers."}, "embedding": {"model": "specter_v2", "vector": [0.29280227422714233, 0.4646047353744507, -0.18909554183483124, 0.256803035736084, -0.2125518023967743, 0.2976244390010834, 0.408689945936203, -0.20363064110279083, -0.45072123408317566, -0.5350033640861511, 0.22916771471500397, 0.7135301232337952, 0.6842532157897949, -0.20543329417705536, -0.24160215258598328, -0.03826093673706055, -0.5028765201568604, 0.2775736153125763, 0.6047332882881165, -0.15521858632564545, 0.3800600469112396, -0.6912257075309753, -1.463175892829895, 0.24585270881652832, 0.44639265537261963, 1.1658309698104858, 0.6400256156921387, 0.9683160185813904, -0.004632635973393917, 0.3979106843471527, 0.36290764808654785, -0.38283824920654297, 0.44684329628944397, 0.3549853563308716, -0.33207258582115173, 0.18870678544044495, 1.0798858404159546, -0.08883412182331085, -0.3182673156261444, 1.1825040578842163, -0.20748752355575562, 0.07256954163312912, 0.18326695263385773, -0.9203165769577026, -0.32502231001853943, 0.06421647220849991, 0.3309863805770874, 1.0601650476455688, -0.6505149006843567, -0.4306090176105499, 1.0950993299484253, -1.4376659393310547, -0.19177360832691193, 1.3988795280456543, 0.32623058557510376, 0.046631623059511185, 0.05887189880013466, -0.6036457419395447, 0.7605524063110352, 0.3294053375720978, -0.5347479581832886, -0.2915150821208954, 0.13571298122406006, -0.13663162291049957, 1.9198294878005981, -0.411095529794693, 0.1624828279018402, 0.31058603525161743, 0.313476026058197, 1.1364593505859375, 0.08560468256473541, -0.7037265300750732, -0.19980429112911224, -0.12193214148283005, 0.584047257900238, 0.9756917357444763, 0.022109568119049072, 0.013015374541282654, -1.0803139209747314, -0.03412558138370514, 0.8081815838813782, 0.01686534658074379, 0.6079769730567932, -0.2226707935333252, -0.3792928159236908, 0.5700953006744385, 0.78083735704422, 0.5425547957420349, -0.1777285486459732, 0.9599446654319763, 0.5816117525100708, -0.04046231135725975, 0.14195403456687927, 0.2577364444732666, 0.48681211471557617, 0.9282652139663696, -0.5251579880714417, -0.008113394491374493, -0.2539670765399933, 1.3113856315612793, -0.0431811697781086, 0.14419831335544586, -0.5126972794532776, 0.13507606089115143, 1.3170661926269531, 0.32603490352630615, 0.37176987528800964, -0.6420889496803284, 0.28050926327705383, -0.4593060612678528, -0.17538176476955414, -1.2139146327972412, 0.11385137587785721, -0.48555758595466614, -0.9965574145317078, -0.8149489760398865, -0.33752700686454773, 0.6753911972045898, -0.8947070240974426, 0.29710230231285095, -0.37710708379745483, 0.18688982725143433, -0.06484552472829819, 0.49444299936294556, 0.5246509313583374, 0.29881152510643005, 0.45986855030059814, 0.5131004452705383, 1.4937349557876587, -1.368219256401062, -0.4440820515155792, -1.3077244758605957, -0.12913855910301208, -0.5326106548309326, 0.12600713968276978, -0.36986374855041504, -1.1966702938079834, -1.3490688800811768, -1.0109745264053345, 0.11496894806623459, -0.7889202833175659, 0.38821327686309814, 1.014830231666565, 0.08712181448936462, -1.2349387407302856, 0.4054926633834839, -0.3303750455379486, -0.6170005202293396, 0.621849000453949, 0.27511316537857056, 0.4128953218460083, 0.07961901277303696, -0.9886196255683899, 0.4596448540687561, 0.15819591283798218, -0.4551500976085663, -0.19857200980186462, -0.28709253668785095, -0.8844886422157288, 0.07963840663433075, 0.30652549862861633, -0.8749032020568848, 0.8487561941146851, -0.4965478181838989, -0.6117778420448303, 0.7218968868255615, -0.17254844307899475, -0.08135121315717697, -0.11820578575134277, -0.1895846128463745, -0.14937548339366913, -0.32532864809036255, 0.11801973730325699, 0.5903621315956116, 0.6821818351745605, -0.02747616358101368, -0.5992642045021057, -0.15627965331077576, -0.2337644100189209, 0.09282563626766205, -0.3044356107711792, 0.8832553625106812, -0.8259108662605286, -0.4428924322128296, 0.481756329536438, 0.5004847645759583, 0.0020188470371067524, -0.05740310996770859, -0.06308630108833313, -0.9779059290885925, 0.9399699568748474, 0.39141276478767395, 0.5701583623886108, -0.8337692022323608, -0.7552589178085327, -0.2104422152042389, 0.05145301669836044, -0.08254853636026382, -0.9251848459243774, 0.16521099209785461, -0.4670918583869934, -0.002517579821869731, 0.2174651026725769, -0.6440283060073853, -0.21563825011253357, -0.4474899470806122, -0.565133273601532, -0.034568771719932556, 0.493590772151947, 1.0604361295700073, -0.8785676956176758, -0.07469112426042557, -0.19837121665477753, 0.1869051605463028, -0.9850851893424988, 1.076175332069397, -0.22995951771736145, -0.36365747451782227, -0.15911142528057098, 0.2904561460018158, 0.21421879529953003, -0.5856027603149414, 0.39086857438087463, -1.0242199897766113, 0.04758443683385849, 0.32436633110046387, -0.26950880885124207, 1.2695786952972412, -0.08921797573566437, 0.5705439448356628, -0.09662330150604248, -0.8134640455245972, 0.42578133940696716, 0.3056434988975525, -0.2928331792354584, -0.9094858169555664, 0.37587636709213257, 0.010771793313324451, -0.5522281527519226, 0.1952340006828308, 0.7000013589859009, 1.4268310070037842, -0.2844821810722351, 0.020014535635709763, 0.8005141019821167, -0.14394479990005493, 0.11194679141044617, 0.1807103306055069, 0.601493239402771, 0.19345851242542267, 0.4984520375728607, -0.5299039483070374, 0.2813069224357605, -0.8562983274459839, -0.0729832574725151, 0.5330784320831299, 0.14293323457241058, 0.8922688364982605, 0.2830141484737396, -1.053856611251831, -0.5765151977539062, 0.07522094249725342, 0.7595651745796204, 1.4295287132263184, 0.21018745005130768, 0.1758081316947937, -0.8986822366714478, -0.3152536153793335, -0.5703827738761902, -0.8264541029930115, -0.46344640851020813, -0.2977299094200134, -0.28581956028938293, -1.4012608528137207, 0.6220879554748535, 0.6545968651771545, 1.6402909755706787, -0.623694896697998, -0.9013681411743164, -0.309623658657074, 0.018465353175997734, -0.8807888031005859, -0.868669867515564, 0.24348245561122894, -0.30719268321990967, -0.25827673077583313, 0.09213478863239288, -0.5159580707550049, 0.47009414434432983, -0.06806816905736923, 0.9390698075294495, -0.466675728559494, -0.548004150390625, 0.49844419956207275, 0.6330568194389343, -0.824691653251648, 0.06249319761991501, 0.2544551491737366, -0.06551502645015717, 0.1469498723745346, 0.4693847596645355, 0.2238706797361374, -0.258878231048584, 0.2554684579372406, -0.3374617099761963, -0.011819221079349518, 0.2824976444244385, 0.0547613687813282, 0.8056256771087646, -0.5148594379425049, 0.06715918332338333, -0.8504279851913452, 0.7087514400482178, 0.32152268290519714, -0.530481219291687, 0.13421913981437683, -0.42741623520851135, -0.5624573230743408, -0.11200466006994247, -0.8521039485931396, 0.018001671880483627, -0.3382735848426819, 0.774591863155365, -0.47203490138053894, 0.0971815213561058, -0.23429203033447266, 0.1026766300201416, -0.534680962562561, 0.43650418519973755, 0.2897472381591797, 0.28768542408943176, 0.3919132649898529, 0.36944782733917236, -1.120023488998413, 0.8023927807807922, 0.1086907684803009, -0.12172707170248032, 0.15887147188186646, -0.08552868664264679, -0.5910207033157349, -0.7844657897949219, -0.39528122544288635, -0.31813350319862366, -0.5501790046691895, 0.5065188407897949, -0.7443575263023376, -1.0991936922073364, 0.22198624908924103, -1.2569161653518677, 0.09420249611139297, 0.16591231524944305, -0.3497089743614197, -0.54143887758255, -1.1878125667572021, -0.7472460269927979, -0.43865934014320374, -0.7615728378295898, -1.2076337337493896, 0.23553898930549622, 0.3499072790145874, -0.07562859356403351, -0.12265170365571976, -0.2023494839668274, -0.1689053326845169, 1.3126479387283325, -0.26400306820869446, 0.2918094992637634, -0.22014957666397095, -0.8060422539710999, -0.19677914679050446, -0.45323511958122253, 0.3278038799762726, -0.11591066420078278, -0.07190091162919998, -0.9839362502098083, 0.33024120330810547, -0.01428446639329195, -0.30617159605026245, 0.6288126111030579, 0.2133253663778305, 0.8605630397796631, 0.05082080140709877, -0.5413693189620972, 0.24402813613414764, 1.4760797023773193, -0.5404016971588135, 0.3694987893104553, 0.47719237208366394, 0.9953356385231018, 0.10115388035774231, -0.08478164672851562, 0.22549393773078918, 0.7260058522224426, 0.35431671142578125, 0.8107293248176575, -0.5497010350227356, -0.5035649538040161, -0.09933923184871674, -0.15982992947101593, 1.3060824871063232, -0.16984449326992035, 0.17595994472503662, -1.0509023666381836, 0.7281448841094971, -1.5424073934555054, -0.9886248707771301, 0.9376176595687866, 0.634501039981842, 0.08506134897470474, -0.3251684606075287, -0.2887224555015564, -0.3847307860851288, 0.8646389842033386, 0.38267895579338074, -0.35157182812690735, -0.31674548983573914, -0.042641982436180115, 0.30207833647727966, 0.4751465320587158, 0.5822657346725464, -0.7663129568099976, 0.7344720363616943, 14.926600456237793, 0.6529451012611389, -0.14371736347675323, 0.7179754376411438, 0.9040829539299011, 0.4959862530231476, 0.286668598651886, 0.04327167570590973, -1.100345492362976, -0.15398797392845154, 0.5555647611618042, 0.2954614460468292, 0.25703004002571106, 0.49795958399772644, -0.4956649839878082, -0.047028832137584686, -0.4324784278869629, 0.894301176071167, 0.990658164024353, -1.1820131540298462, 0.3953618109226227, 0.12314718961715698, 0.2776906192302704, 0.3828512728214264, 0.8753623366355896, 0.32532811164855957, 0.17726875841617584, -0.3418276906013489, 0.396014004945755, 0.4109537899494171, 0.7285642623901367, -0.021428760141134262, 0.2770461142063141, -0.024073893204331398, -1.2936546802520752, -0.06938620656728745, -0.8691322207450867, -1.0592052936553955, -0.2769467830657959, 0.10595239698886871, -0.04945197328925133, -0.6154884696006775, 0.19952215254306793, 0.6428096294403076, -0.2550463378429413, 0.5988135933876038, 0.18590664863586426, -0.03846128284931183, 0.32442858815193176, -0.15773175656795502, 0.011305682361125946, 0.5591526627540588, 0.36550742387771606, 0.10524503886699677, -0.08567677438259125, 0.2815706431865692, 0.2620546817779541, 0.4576829969882965, -0.456604927778244, -0.505573034286499, -0.17688219249248505, 0.16528938710689545, -0.12321681529283524, 1.1556591987609863, 0.01056871097534895, -0.0736292377114296, -0.27668359875679016, 0.18952669203281403, 0.6322118639945984, 0.1464909315109253, -0.8586513996124268, -0.09062279015779495, 0.19098398089408875, -0.204762801527977, 0.10134417563676834, 0.420395165681839, -0.496402382850647, -0.5348950028419495, -0.6330760717391968, -0.3654816448688507, 0.2223997265100479, -0.7936590909957886, -0.665149450302124, 1.3845434188842773, -0.30509814620018005, -0.3733917474746704, 1.034252643585205, -0.8167268633842468, -0.4292808473110199, 0.2303004264831543, -1.2285646200180054, -0.9085446000099182, -0.35263603925704956, -0.39581388235092163, 0.016637898981571198, -0.1864270269870758, 0.8411072492599487, 0.1523142158985138, -0.2808419167995453, 0.01762467250227928, -0.9545514583587646, -0.10332353413105011, 0.09494459629058838, -0.5248531103134155, 0.7793199419975281, 0.1540084332227707, -0.16568845510482788, 0.00407241890206933, -0.13056698441505432, 0.3065391182899475, -0.6409571766853333, -0.18785272538661957, 0.4445609450340271, -0.6617217063903809, -0.31440508365631104, -0.7409175634384155, -0.8031710982322693, 0.0791611298918724, 0.9036434292793274, 0.1609317809343338, -0.12151602655649185, -0.08598329871892929, -0.6890058517456055, -0.5002024173736572, -0.6216954588890076, 0.008137463591992855, 0.48546624183654785, -0.8107705116271973, -0.3001805543899536, 0.04169579595327377, 0.2657470405101776, -1.0288147926330566, -0.2941877245903015, -0.030278438702225685, 0.29223722219467163, -0.41049033403396606, 1.4165923595428467, -0.09857155382633209, 0.5680694580078125, 0.618812620639801, -0.27439942955970764, -0.43176761269569397, -0.4599492847919464, -0.5220662355422974, 0.32996663451194763, 0.232760950922966, 0.4510970711708069, -0.7198484539985657, 0.13358639180660248, 0.7754688858985901, 0.3302105665206909, -0.4760051965713501, -0.6627320647239685, 0.09220287948846817, -0.45236527919769287, -0.19268089532852173, 0.19429649412631989, -0.144489586353302, 0.02858045883476734, 0.042691901326179504, 0.6950666308403015, 0.5202127695083618, 0.2770344018936157, -0.3950828015804291, 0.26185142993927, -0.18483777344226837, 0.1324237585067749, -0.593222975730896, -0.9212083220481873, -1.2099449634552002, -0.2653942406177521, -0.9354891180992126, 0.02666269801557064, -0.6395367980003357, 0.093355692923069, 0.20336322486400604, -0.5125896334648132, 0.12347671389579773, 0.14461106061935425, 0.24031810462474823, -0.10561179369688034, -0.4156433343887329, -0.8093962073326111, 0.5544975996017456, 1.050496220588684, -0.9484038352966309, 0.3847389817237854, -0.05977112427353859, -0.24528054893016815, 0.657617449760437, 0.3411191701889038, -0.33735737204551697, -0.5219367742538452, -1.1074262857437134, 0.2758275270462036, -0.2225690335035324, 0.29418328404426575, -1.3448561429977417, 1.507089376449585, 0.49572518467903137, 0.14410239458084106, -0.1356302946805954, 0.32499974966049194, -0.9740222096443176, -0.7233067154884338, 0.4338112771511078, -0.6255801320075989, 0.5153056383132935, 0.4513925611972809, -0.41224053502082825, -0.40161532163619995, 1.0462881326675415, 0.21497701108455658, -1.2013124227523804, -1.0435154438018799, 0.37604206800460815, -0.5256852507591248, 0.23747214674949646, 0.03574680536985397, -0.12007932364940643, -1.5398848056793213, -0.07835780829191208, -0.1933649778366089, 0.2594796121120453, -0.6042700409889221, 0.931395947933197, 0.5195852518081665, -1.358418583869934, 0.35385647416114807, 0.5296993255615234, -0.13184544444084167, -0.05187491700053215, 0.33767014741897583, 0.501561164855957, -0.17805300652980804, 0.36246567964553833, -0.3383813202381134, 0.12375406175851822, -0.7041100859642029, 0.2801126539707184, 0.870248556137085, -0.2574220597743988, 0.03225705772638321, 0.8881748914718628, 0.12077154219150543, -0.6127674579620361, 0.21879757940769196, -0.8541696667671204, -0.45016953349113464, -0.17467428743839264, 0.5981793999671936, 0.3765687644481659, -0.014614756219089031, -0.02655015140771866, -0.7180331945419312, 0.5480957627296448, -0.1977347880601883, -0.3424340784549713, 0.11926620453596115, 0.06657236069440842, -0.4460154175758362, 0.1753099113702774, 0.30973586440086365, -0.9812060594558716, -1.0249499082565308, -0.7666133642196655, -0.4891761541366577, -0.22778916358947754, 0.1823417842388153, -0.10861393809318542, -1.0623623132705688, 0.623845636844635, 0.8477107882499695, 0.44336751103401184, 0.3169945478439331, -0.25822097063064575, -0.09700077772140503, 0.4576846659183502, 0.05569963529706001, -0.852311372756958, 0.01604267582297325, 1.2795789241790771, 1.4225382804870605, -0.8500354290008545, 0.12104717642068863, -0.6174496412277222, -0.6950612664222717, 0.6974462866783142, 0.896722674369812, -0.8823239207267761, 0.9059205651283264, 0.09869998693466187, 0.0052685849368572235, 0.05196351930499077, -1.0384997129440308, -0.5837385654449463, 1.0244196653366089, 1.282584309577942, 0.570826530456543, -0.1479858011007309, 0.1954897940158844, 0.5593542456626892, 0.4182090759277344, -0.20640981197357178, 0.35944172739982605, 0.09783738106489182, -0.29355931282043457, 0.3377539813518524, -0.29115626215934753, 0.3905200660228729, -0.25108304619789124, -0.5036735534667969, 0.16937516629695892, 0.5395511388778687, 0.17888256907463074, 0.44738462567329407, 1.2598893642425537, 0.029097488150000572, 0.7535465955734253, -0.103755421936512, 0.5512088537216187, -0.3683807849884033, -0.22754868865013123, 0.007421327754855156, -1.0281994342803955, -0.3391026258468628, -0.655583381652832, -0.5314919948577881, 0.0013482627691701055, 0.06267669796943665, 0.0437639020383358, -0.3601173758506775, 0.3185206651687622, 0.698681652545929, 0.6936469674110413, 1.1148585081100464, -0.48934483528137207, -0.8298525214195251, -0.03822440281510353, -0.9947752356529236, 0.38445040583610535, -0.7248902916908264, -0.31391674280166626, -0.4001714587211609, 0.05001546069979668, -0.04598357528448105]}, "authors": [{"authorId": "2057697721", "name": "Hai Lan"}, {"authorId": "2108030458", "name": "Xihao Wang"}, {"authorId": "2185468201", "name": "Hao Shen"}, {"authorId": "153616403", "name": "Peidong Liang"}, {"authorId": "2115493929", "name": "Xian Wei"}], "references": [{"paperId": "a66686e60a3eda0c606e036403cf0a07a5962595", "title": "Mobile-Former: Bridging MobileNet and Transformer"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "4b06c7e29280b1c6bc05c9df39023b48fef02c93", "title": "Escaping the Big Data Paradigm with Compact Transformers"}, {"paperId": "003326a15fc4a8833785a47a741d7712474fa256", "title": "LeViT: a Vision Transformer in ConvNet\u2019s Clothing for Faster Inference"}, {"paperId": "a56bf7ee9a56d8f84079684339a953c2df9ce76b", "title": "A review on the attention mechanism of deep learning"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "2984ab83ade26639c3a82d29628d0d9e4abbebb0", "title": "Incorporating Convolution Designs into Visual Transformers"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "3a906b77fa218adc171fecb28bb81c24c14dcc7b", "title": "Transformers in Vision: A Survey"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "849b88ddc8f8cabc6d4246479b275a1ee65d0647", "title": "A Generalization of Transformer Networks to Graphs"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "441555b5cd09703e55c03e70bd2c9f82c0ffcf9b", "title": "Deep High-Resolution Representation Learning for Visual Recognition"}, {"paperId": "9c4e3248e8c3b981b0e20a47b542d066299ddc08", "title": "Densely connected attentional pyramid residual network for human pose estimation"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "24522165803afefd43f95d5c79a0449f248e7718", "title": "Boosting image sentiment analysis with visual attention"}, {"paperId": "f723eb3e7159f07b97464c8d947d15e78612abe4", "title": "AutoAugment: Learning Augmentation Policies from Data"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4", "title": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"}, {"paperId": "33998aff64ce51df8dee45989cdca4b6b1329ec4", "title": "Graph Attention Networks"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "9f4d7d622d1f7319cc511bfef661cd973e881a4c", "title": "Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning"}, {"paperId": "addb41821f0e6c3f89289061a5598e9a70b637a4", "title": "An End-to-End Spatio-Temporal Attention Model for Human Action Recognition from Skeleton Data"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "4d8f2d14af5991d4f0d050d22216825cac3157bd", "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "654247d5b184495fca18c6aa7e840e4f4559fef0", "title": "Do We Really Need Explicit Position Encodings for Vision Transformers?"}, {"paperId": null, "title": "Visual hierarchy: Organizing content to follow natural eye movement patterns"}, {"paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82", "title": "Deep Learning"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": null, "title": "Fujian Science & Technology Innovation Laboratory for Optoelec-tronic Information of China * Equal technical contribution \u2020 Corresponding author"}]}