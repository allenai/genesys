{"paperId": "687f0af2b6b6eb9dde326d7c6759dedf4b9e917a", "title": "Efficient Multi-order Gated Aggregation Network", "abstract": "Since the recent success of Vision Transformers (ViTs), explorations toward transformer-style architectures have triggered the resurgence of modern ConvNets. In this work, we explore the representation ability of DNNs through the lens of interaction complexities. We empirically show that interaction complexity is an overlooked but essential indi-cator for visual recognition. Accordingly, a new family of ef\ufb01cient ConvNets, named MogaNet, is presented to pursue informative context mining in pure ConvNet-based models, with preferable complexity-performance trade-offs. In MogaNet, interactions across multiple complexities are facil-itated and contextualized by leveraging two specially designed aggregation blocks in both spatial and channel interaction spaces. Extensive studies are conducted on ImageNet classi\ufb01cation, COCO object detection, and ADE20K semantic segmentation tasks. The results demonstrate that our MogaNet establishes new state-of-the-art over other popular methods in mainstream scenarios and all model scales. Typically, the lightweight MogaNet-T achieves 80.0% top-1 accuracy with only 1.44G FLOPs using re\ufb01ned training setup on ImageNet-1K, surpassing ParC-Net-S by 1.4% accuracy but saving 59% (2.04G) FLOPs.", "venue": "arXiv.org", "year": 2022, "citationCount": 14, "influentialCitationCount": 2, "openAccessPdf": {"url": "http://arxiv.org/pdf/2211.03295", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work empirically show that interaction complexity is an overlooked but essential indi-cator for visual recognition, and presents a new family of pure ConvNet-based models, named MogaNet, to pursue informative context mining in pure ConvNet-based models, with preferable complexity-performance trade-offs."}, "embedding": {"model": "specter_v2", "vector": [0.4018886685371399, 0.22788959741592407, -0.2747592329978943, -0.15773256123065948, -0.08840809017419815, 0.25893107056617737, 0.4472005069255829, -0.17865164577960968, -0.6710437536239624, -0.40508219599723816, 0.3326368033885956, 0.3447454273700714, 0.8085297346115112, -0.04617740958929062, 0.3324558436870575, 0.15773074328899384, -1.0842933654785156, 0.04459180310368538, 0.5463276505470276, -0.20025566220283508, -0.20063792169094086, -0.33908507227897644, -1.165060043334961, 0.05606969818472862, 0.09466980397701263, 1.4586457014083862, 0.43967726826667786, 1.0073118209838867, -0.15395209193229675, 0.39174798130989075, 0.29973334074020386, -0.37989190220832825, 0.35702988505363464, -0.13403087854385376, -0.18688400089740753, 0.11886687576770782, 0.7056168913841248, -0.5239835381507874, -0.46037060022354126, 1.0285181999206543, 0.09859059751033783, 0.3222188949584961, 0.13596706092357635, -0.752608597278595, -0.11173952370882034, 0.44002705812454224, 0.8927105665206909, 0.8255782127380371, -0.8841001987457275, -0.5638901591300964, 1.5993616580963135, -1.3063442707061768, 0.04042147099971771, 1.5562535524368286, 0.42579323053359985, 0.3007826805114746, -0.21493494510650635, -0.5563802123069763, 1.0629690885543823, 0.39160025119781494, -0.24275723099708557, -0.22452065348625183, 0.16991181671619415, -0.13835939764976501, 1.9346469640731812, -0.5013603568077087, 0.633939266204834, 0.6656105518341064, 0.1663360744714737, 1.249210238456726, 0.02937440760433674, -0.49787577986717224, 0.18355122208595276, -0.6553480625152588, 0.5008910298347473, 0.7080515027046204, 0.1452183872461319, 0.3775835335254669, -0.7237053513526917, 0.11915566027164459, 0.43192893266677856, 0.6014779210090637, 0.7186352014541626, -0.04334249719977379, 0.1496792584657669, 0.7337321043014526, 0.792815625667572, 0.5202281475067139, -0.34761014580726624, 1.282882571220398, 0.6765385866165161, -0.029824987053871155, -0.19611980020999908, 0.0864984393119812, -0.1092238575220108, 0.6872120499610901, -0.5083786249160767, 0.14424018561840057, -0.20055356621742249, 0.8785006403923035, -0.13715630769729614, 0.4245592951774597, -0.43855947256088257, 0.015024315565824509, 1.4400780200958252, -0.10987105965614319, -0.033045198768377304, -0.5387040376663208, -0.05213697999715805, -0.4459579288959503, -0.1950756311416626, -0.601919412612915, 0.14430475234985352, -0.5837925672531128, -0.9084861278533936, -1.021318793296814, -0.5664335489273071, 0.39793652296066284, -1.5364785194396973, 0.3996511399745941, -0.6757640242576599, 0.5310420393943787, -0.01238738652318716, 0.4001886546611786, 0.3177005648612976, 0.16877715289592743, 0.7221959233283997, 0.28546902537345886, 1.1388136148452759, -1.164973497390747, -0.3881847560405731, -1.1597235202789307, 0.30582916736602783, -0.14473693072795868, -0.12875646352767944, -0.37422072887420654, -0.940671443939209, -1.2006398439407349, -0.8916534781455994, 0.031038936227560043, -0.7558907866477966, 0.1122836247086525, 1.0686759948730469, 0.34357884526252747, -1.2487568855285645, 0.5176889300346375, -0.5454322695732117, -0.31040072441101074, 1.0540024042129517, 0.31330788135528564, 0.7190872430801392, 0.025563716888427734, -0.9501360654830933, 0.23441040515899658, 0.19156813621520996, -0.021624650806188583, -0.9632042646408081, -0.06017841026186943, -1.0503660440444946, 0.05483884736895561, 0.2490336149930954, -0.6798021197319031, 0.9726743102073669, -0.20760881900787354, -0.5234033465385437, 0.3421098291873932, -0.2630872428417206, -0.37927910685539246, 0.38693976402282715, -0.39652329683303833, -0.3774414658546448, -0.21658676862716675, -0.09634450078010559, 0.6743316054344177, 0.6830470561981201, -0.1824214607477188, -0.48319509625434875, 0.05920959264039993, -0.09104259312152863, 0.09409771114587784, -0.26467442512512207, 1.063660740852356, -0.33713898062705994, -0.43995100259780884, 0.6578143239021301, 0.7321633696556091, -0.7687169313430786, -0.1734127700328827, -0.315729558467865, -0.9564725756645203, 1.2290701866149902, 0.29174259305000305, 0.7418442368507385, -0.7653385996818542, -1.1530611515045166, -0.015062185004353523, 0.21013662219047546, -0.033520761877298355, -0.7679103016853333, 0.11824138462543488, -0.18482857942581177, 0.34604305028915405, 0.14806613326072693, -0.9329863786697388, 0.1091448962688446, -0.026500031352043152, -0.479511559009552, -0.2560480237007141, 0.31283921003341675, 1.2387163639068604, -0.7553008794784546, -0.13793067634105682, 0.15517857670783997, 0.4089842438697815, -0.9387059211730957, 0.963114321231842, -0.5485578179359436, -0.047616615891456604, -0.4432024657726288, 0.3848760426044464, -0.007159911096096039, -0.376558780670166, 0.6321285367012024, -0.675901472568512, 0.044270724058151245, 0.6147382855415344, -0.45266780257225037, 1.1465601921081543, 0.15947289764881134, 0.7098343372344971, -0.36163854598999023, -0.8825886845588684, 0.42251333594322205, 0.05832303687930107, -0.17088498175144196, -0.5612278580665588, 0.697034478187561, 0.14945495128631592, -0.5505379438400269, 0.5882628560066223, 0.9517722129821777, 1.3131303787231445, -0.62446129322052, -0.38446280360221863, 0.8258822560310364, -0.05691127851605415, 0.3404116928577423, 0.1969921588897705, 0.6064766645431519, 0.03970814123749733, 0.18841871619224548, -0.39478743076324463, -0.10213892161846161, -1.2639789581298828, 0.36780431866645813, 0.8993242979049683, -0.16806700825691223, 0.7459398508071899, 0.5617480278015137, -0.9912322163581848, -0.3901918828487396, 0.20248302817344666, 0.611454963684082, 1.5431872606277466, 0.24325041472911835, -0.027874650433659554, -0.7840734124183655, -0.5707042217254639, -0.7307131290435791, -0.6755645871162415, -0.21524932980537415, 0.15748319029808044, -0.39113590121269226, -1.2081552743911743, 0.9156676530838013, 0.9435327053070068, 1.5782629251480103, -0.8903008699417114, -0.6651317477226257, -0.157499298453331, 0.21162456274032593, -1.157332181930542, -0.348728209733963, 0.6560054421424866, -0.5539183616638184, -0.1970575749874115, 0.3856058716773987, -0.41592177748680115, 0.11751561611890793, -0.8571270704269409, 1.0781728029251099, -0.3237217962741852, -0.4611547291278839, 0.06376668810844421, 0.3445417881011963, -0.6537683010101318, -0.030127527192234993, 0.10754650086164474, -0.22538933157920837, -0.19102299213409424, 0.7285816073417664, 0.31904399394989014, -0.45733511447906494, 0.5485165119171143, -0.17318426072597504, -0.09986753016710281, 0.22249417006969452, 0.07703427225351334, 1.1778755187988281, -0.370942622423172, 0.47951409220695496, -0.7350139617919922, 0.5896092653274536, 0.4510617256164551, -0.4754936695098877, 0.16875667870044708, -0.6738998889923096, -0.5726934671401978, 0.26907798647880554, -0.3446362614631653, -0.022121919319033623, -0.46562522649765015, 0.35287365317344666, -0.6124799847602844, -0.48943185806274414, -0.23439304530620575, -0.04230973497033119, -0.03946729749441147, 0.39374303817749023, 0.3740425109863281, -0.32587432861328125, 0.16335874795913696, 0.3571935296058655, -1.1574863195419312, 0.5351458191871643, 0.20129860937595367, -0.44931748509407043, 0.165400892496109, -0.014967410825192928, -0.7692987322807312, -0.23195190727710724, -0.6308099627494812, -0.41814637184143066, -0.3541041910648346, 0.7175746560096741, -0.5967697501182556, -0.7321717143058777, 0.14167505502700806, -0.9121623039245605, -0.11593125015497208, -0.024303140118718147, -0.12008076161146164, -0.15652577579021454, -1.3680598735809326, -1.168084979057312, -0.552479088306427, -0.6121219396591187, -1.3122669458389282, 0.12043851613998413, 0.38091322779655457, 0.14093175530433655, -0.4985589385032654, -0.5573451519012451, -0.6775363683700562, 0.949526309967041, 0.016905544325709343, 0.36410361528396606, -0.519372820854187, -0.7960718274116516, -0.13164204359054565, -0.36105525493621826, 0.7274770736694336, -0.4847205877304077, 0.0402316153049469, -1.0719703435897827, 0.3632637858390808, -0.29820042848587036, -0.1408252865076065, 0.8458345532417297, 0.7335855960845947, 0.8569256663322449, 0.302909255027771, -0.374042272567749, 0.3944019675254822, 1.419445514678955, -0.464893639087677, 0.39060747623443604, -0.1717127114534378, 1.1355891227722168, -0.23899908363819122, -0.32926902174949646, 0.4172056317329407, 0.16432903707027435, -0.17305511236190796, 0.9047263860702515, -0.3252209722995758, -0.39289677143096924, -0.36650171875953674, -0.016507048159837723, 1.1103413105010986, -0.15607108175754547, -0.04535476863384247, -0.827528715133667, 1.033834457397461, -1.3550686836242676, -0.7771931290626526, 0.6748288869857788, 0.2721479833126068, -0.3787812888622284, -0.026252100244164467, -0.07640046626329422, -0.3969575762748718, 1.0047078132629395, 0.7956461310386658, -0.37127289175987244, -0.5880855917930603, -0.2626378536224365, 0.5830557346343994, 0.42638278007507324, 0.32097017765045166, -0.7641391754150391, 0.7713196873664856, 14.557196617126465, 0.6567124128341675, -0.185035839676857, 0.38008198142051697, 1.185373306274414, 0.7431066632270813, -0.14349012076854706, 0.37134021520614624, -1.35857093334198, -0.14425210654735565, 0.7731776833534241, 0.5944982767105103, 0.14036385715007782, 0.47653457522392273, -0.15919864177703857, 0.23851627111434937, -0.7318958640098572, 0.830452024936676, 0.4099218547344208, -1.4834895133972168, 0.3406592309474945, 0.20635974407196045, 0.4622170329093933, 0.7677301168441772, 0.6147643327713013, 0.6324849724769592, 0.5460777282714844, -0.5236909985542297, 0.4597574770450592, -0.18551278114318848, 0.9663140177726746, 0.16694635152816772, 0.44688260555267334, -0.3312673270702362, -1.6684019565582275, -0.3263630270957947, -0.5722702741622925, -1.2627403736114502, 0.270670622587204, 0.10378590226173401, -0.19019794464111328, -0.482227087020874, 0.19120725989341736, 1.0412706136703491, 0.0010909936390817165, 0.5550498366355896, -0.36685261130332947, 0.49005386233329773, -0.16701538860797882, -0.0274040624499321, 0.6531984806060791, 0.40051594376564026, 0.25202512741088867, 0.11144959181547165, -0.2862083315849304, 0.2288556694984436, 0.6500696539878845, 0.1902591437101364, -0.7469090223312378, -0.5850698351860046, -0.20020583271980286, 0.008069089613854885, -0.24876169860363007, 0.9475880861282349, -0.4329083561897278, -0.10942336916923523, -0.19521164894104004, 0.10514453798532486, 0.025895612314343452, 0.39310985803604126, -0.6054437160491943, 0.041625890880823135, 0.3607107698917389, -0.7674979567527771, 0.5112619400024414, 0.5152351260185242, -0.4811694920063019, -0.4601384103298187, -0.6684495806694031, 0.07684214413166046, 0.6424435973167419, -0.5037782788276672, -0.4978698492050171, 1.297440528869629, -0.2685687243938446, -0.2320956140756607, 0.6673219203948975, -0.8495312929153442, -0.5128673315048218, 0.18231099843978882, -1.4567666053771973, -0.9327200651168823, -0.14719700813293457, -0.1197107583284378, -0.08600141108036041, 0.05964226275682449, 0.9720795750617981, 0.3986981213092804, -0.2588244080543518, -0.08443525433540344, -0.6721819043159485, 0.44550350308418274, -0.5843198299407959, -0.7698103785514832, 0.8517746329307556, 0.6131588220596313, 0.0549933947622776, -0.5073421597480774, -0.23775573074817657, 0.3075738847255707, 0.1083267331123352, -0.4624057412147522, 0.5130533576011658, -0.4480886459350586, -0.6723269820213318, -0.8609839081764221, -0.43218809366226196, 0.5399009585380554, 0.6256220936775208, 0.5026121139526367, 0.05144919455051422, 0.01126207783818245, -0.40691155195236206, -0.2783440053462982, -0.6439981460571289, 0.107515849173069, 0.772969126701355, -0.7258679270744324, -0.24891069531440735, -0.4972476065158844, 0.3319263160228729, -0.8555901646614075, -0.059610702097415924, 0.00012141456682002172, 0.2144276350736618, -0.5231017470359802, 1.15402090549469, -0.4409972131252289, 0.4818675220012665, 0.8433939218521118, -0.6774352192878723, -0.3513014018535614, -0.011107397265732288, -0.8722642660140991, 0.0842059850692749, -0.0007315222756005824, 0.19092047214508057, -0.5559211373329163, 0.6292712092399597, 0.46155446767807007, 0.0009399962145835161, -0.7039875388145447, -0.5892422795295715, -0.07454060018062592, -0.5383691787719727, -0.9361273646354675, 0.4879385530948639, -0.3409019410610199, -0.6305140256881714, -0.036419596523046494, 0.7748243808746338, 0.5677949786186218, 0.03697208687663078, -0.5410733222961426, -0.1400994509458542, -0.20324298739433289, 0.1485108882188797, -0.45674946904182434, -1.2768446207046509, -1.7260968685150146, -0.2503982484340668, -0.7357196807861328, 0.023315856233239174, -0.8904968500137329, -0.6060608625411987, -0.09716376662254333, -0.8280788064002991, 0.0799843966960907, 0.38282763957977295, 0.16571788489818573, 0.007615679409354925, -0.6551188826560974, -1.0674662590026855, 0.7035728693008423, 0.9002068042755127, -0.6453403830528259, 0.11516039818525314, -0.06758993119001389, 0.014911051839590073, 0.9492441415786743, 0.2958269417285919, -0.2736905813217163, -0.7478112578392029, -1.0524870157241821, 0.12387426942586899, -0.38971349596977234, 0.37166839838027954, -1.2227003574371338, 0.9462570548057556, 0.47296658158302307, 0.055236201733350754, -0.26713109016418457, 0.3123205900192261, -1.0123649835586548, -0.7295314073562622, 0.46505266427993774, -0.6585531234741211, 0.03856173902750015, 0.1124410480260849, -0.2750980854034424, -0.48152267932891846, 1.1488378047943115, 0.05063789337873459, -0.9929516315460205, -1.551041841506958, 0.5435808897018433, -0.43488508462905884, 0.257036030292511, -0.13183394074440002, -0.378071129322052, -1.228994369506836, -0.10650318115949631, -0.657993733882904, 0.15634894371032715, -0.6502945423126221, 0.6010019183158875, 0.9616665244102478, -1.0903733968734741, 0.21715456247329712, 0.4461190104484558, -0.42071831226348877, 0.47489655017852783, 0.23561398684978485, 0.5149040818214417, -0.3319319784641266, 0.2297421544790268, -0.03715901076793671, -0.07744133472442627, -0.6989921927452087, -0.10469521582126617, 1.173804759979248, -0.5113457441329956, -0.1976921260356903, 1.1641240119934082, 0.1000077947974205, -0.3008189797401428, 0.3317130208015442, -1.5566097497940063, -0.5367359519004822, -0.05269470065832138, 0.3950307071208954, 0.28790202736854553, 0.15969093143939972, -0.006915649399161339, -0.6451658010482788, 0.09386344254016876, -0.25720006227493286, -0.3831656277179718, 0.2916203439235687, -0.0706416517496109, -0.15265852212905884, 0.08844354003667831, 0.6966671347618103, -1.3286614418029785, -1.535031795501709, -0.6586188077926636, -0.46805837750434875, -0.3554425537586212, 0.14435918629169464, -0.23874413967132568, -0.9143690466880798, 0.7479851245880127, 0.8933737874031067, 0.7368243932723999, 0.5399712324142456, -0.10919422656297684, 0.19054847955703735, 0.6072995066642761, -0.0773673802614212, -0.726902425289154, -0.13019733130931854, 1.2198807001113892, 0.9683089852333069, -0.9245497584342957, 0.1243569552898407, -0.35519641637802124, -0.6437936425209045, 0.4533964991569519, 0.5607843399047852, -0.6910179257392883, 1.1461832523345947, -0.06369610130786896, -0.04867871105670929, 0.03634730726480484, -0.914007842540741, -0.8395797610282898, 0.6143823862075806, 1.2327349185943604, 0.29443758726119995, 0.1721285730600357, 0.12001516669988632, 0.9934356212615967, 0.607072114944458, -0.31553328037261963, 0.1611398309469223, 0.4559989869594574, -0.12293869256973267, 0.38619425892829895, 0.1741800159215927, 0.8178342580795288, -0.9745257496833801, -0.5642420649528503, 0.20164404809474945, 0.48366233706474304, 0.4789873957633972, 0.6979804635047913, 1.1679165363311768, 0.0959446057677269, 0.5107910633087158, -0.15182475745677948, 0.26808393001556396, -0.4041344225406647, -0.31444430351257324, 0.36694884300231934, -0.7754588723182678, -0.3628489673137665, -0.5651020407676697, -0.3170737326145172, -0.3321881890296936, 0.02475579082965851, 0.21086011826992035, -0.23237042129039764, 0.2451271414756775, 0.9328266978263855, 0.6787127256393433, 1.0769497156143188, -0.3062387704849243, -0.8692358732223511, -0.030415048822760582, -0.7365695238113403, 0.23769281804561615, -0.364219069480896, -0.005052520893514156, -0.23987977206707, 0.08836552500724792, 0.06860151886940002]}, "authors": [{"authorId": "2118155623", "name": "Siyuan Li"}, {"authorId": "2184760529", "name": "Zedong Wang"}, {"authorId": "2200082418", "name": "Zicheng Liu"}, {"authorId": "2256967775", "name": "Cheng Tan"}, {"authorId": "2260201864", "name": "Haitao Lin"}, {"authorId": "2256655094", "name": "Di Wu"}, {"authorId": "2174997552", "name": "Zhiyuan Chen"}, {"authorId": "2256349675", "name": "Jiangbin Zheng"}, {"authorId": "2253952904", "name": "Stan Z. Li"}], "references": [{"paperId": "3e448df5aa191f7a3945d0fd609c8bc5966a2333", "title": "HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions"}, {"paperId": "6f48988fd4237f599bf158a5210c70b3c15f1a16", "title": "An Impartial Take to the CNN vs Transformer Robustness Contest"}, {"paperId": "2fe71acc2c3f1e75b6149dea72838f0b594ad013", "title": "TinyViT: Fast Pretraining Distillation for Small Vision Transformers"}, {"paperId": "d1869155960e4b1b882b39171dbecd25a7eda3cd", "title": "More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity"}, {"paperId": "dd1139cfc609c2f3263d02e97176d5275caebc0a", "title": "EfficientFormer: Vision Transformers at MobileNet Speed"}, {"paperId": "07d3837fff7bc872def43f34a62864e753c10a7f", "title": "SimVP: Simpler yet Better Video Prediction"}, {"paperId": "4331838d6a6bf1baf7e6c740f8fa3ff86a64eb8d", "title": "Architecture-Agnostic Masked Image Modeling - From ViT back to CNN"}, {"paperId": "bf6ce546c589fa8054b3972b266532664914bd21", "title": "Fast Vision Transformers with HiLo Attention"}, {"paperId": "dbf6e95cb618f207f029276a6df11f4a9a6313d4", "title": "Inception Transformer"}, {"paperId": "05f6d8319fd30e56e0216a708e1bb74b7d763ac8", "title": "Understanding The Robustness in Vision Transformers"}, {"paperId": "d2f63b56fc6bc373f5c023454c2b253326962865", "title": "DeiT III: Revenge of the ViT"}, {"paperId": "fa717a2e31f0cef4e26921f3b147a98644d2e64c", "title": "Focal Modulation Networks"}, {"paperId": "b9225c672a5078409d890393780a5eb90f2ec3ca", "title": "Anti-Oversmoothing in Deep Vision Transformers via the Fourier Domain Analysis: From Theory to Practice"}, {"paperId": "ed00842931ebb0db2c634330a77c8dee6f77e547", "title": "CF-ViT: A General Coarse-to-Fine Method for Vision Transformer"}, {"paperId": "dc0102a51a9d33e104a4a3808a18cf17f057228c", "title": "Transformer Quality in Linear Time"}, {"paperId": "ba637c4f1a170f1e2dadeadb71a63cf2b9a46de2", "title": "Visual attention network"}, {"paperId": "c49ac1f916d6d2edeb187e6619c8d23acd95eb21", "title": "cosFormer: Rethinking Softmax in Attention"}, {"paperId": "430bab3890e1e52c4c1f74900b0e408e47a1cb8f", "title": "How Do Vision Transformers Work?"}, {"paperId": "9b61adb6f0d1e8831ab2f5481a12e2125b13c50a", "title": "Flowformer: Linearizing Transformers with Conservation Flows"}, {"paperId": "b52844a746dafd8a5051cef49abbbda64a312605", "title": "When Shift Operation Meets Vision Transformer: An Extremely Simple Alternative to Attention Mechanism"}, {"paperId": "f4b11a696aa5a03fed1bfc47e65fdb7eb0e529c1", "title": "UniFormer: Unifying Convolution and Self-Attention for Visual Recognition"}, {"paperId": "3425495ee3b6ead009f35aeb70edeac4e6eb2d10", "title": "Patches Are All You Need?"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "c78ffe94ad3d5b41595ab6474a924c429f1420a6", "title": "Augmenting Convolutional networks with attention-based aggregation"}, {"paperId": "c2a0c18e810535db52e5ebaf180c64ce70356748", "title": "A-ViT: Adaptive Tokens for Efficient Vision Transformer"}, {"paperId": "8a04d8e60e6d5cb7ea2064797e6ab6ef92484742", "title": "Boosting Discriminative Visual Representation Learning with Scenario-Agnostic Mixup"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "9653c070724e44f023e8cc3ec79f0b9e6d59480d", "title": "iBOT: Image BERT Pre-Training with Online Tokenizer"}, {"paperId": "9f97b49e2fe4e06a998d19537eb292552018db7d", "title": "Discovering and Explaining the Representation Bottleneck of DNNs"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "70a10d95e968158c2a862af217186c74c44b5e25", "title": "Sliced Recursive Transformer"}, {"paperId": "2e644c67a697073d561da4f4dad35e5ad5316cfd", "title": "SOFT: Softmax-free Transformer with Linear Complexity"}, {"paperId": "e15fdbde1d56a80743b7d7eafb3409a0a5870094", "title": "HRFormer: High-Resolution Transformer for Dense Prediction"}, {"paperId": "da74a10824193be9d3889ce0d6ed4c6f8ee48b9e", "title": "MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer"}, {"paperId": "f454f6b5f2ca9749ddf442eb5134612ef7f758c1", "title": "ResNet strikes back: An improved training procedure in timm"}, {"paperId": "39b492db00faead70bc3f4fb4b0364d94398ffdb", "title": "Do Vision Transformers See Like Convolutional Neural Networks?"}, {"paperId": "a66686e60a3eda0c606e036403cf0a07a5962595", "title": "Mobile-Former: Bridging MobileNet and Transformer"}, {"paperId": "b541c0cadd747b4f630d2ccfca4a6db2858d524a", "title": "MicroNet: Improving Image Recognition with Extremely Low FLOPs"}, {"paperId": "a9c214e846188adb645021cd7b1964b8ea1fef6f", "title": "Rethinking and Improving Relative Position Encoding for Vision Transformer"}, {"paperId": "0b036cd5dfc49d835d0c759c8ca31d89f2410e65", "title": "CMT: Convolutional Neural Networks Meet Vision Transformers"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "48418b285a92376a38daafa664a2dd07d42e3fe3", "title": "Focal Self-attention for Local-Global Interactions in Vision Transformers"}, {"paperId": "7b664a306b7d2f68dd816ea1d6586cf3472d75c1", "title": "Early Convolutions Help Transformers See Better"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "94eae578e6af3382f6449506965639f18aab3fa0", "title": "Video Swin Transformer"}, {"paperId": "68ae532807289219b672e6c617c577e668d8d21d", "title": "A Game-Theoretic Taxonomy of Visual Concepts in DNNs"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "0e100c06d9fbdf32c434fd40469939a4aaab6c24", "title": "Partial success in closing the gap between human and machine vision"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "576c462dbc1f3d732b919ef1daac37a817123e52", "title": "ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias"}, {"paperId": "a0964686d80e173529efca6377f47e6a1b2fe69a", "title": "Less is More: Pay Less Attention in Vision Transformers"}, {"paperId": "03db529f0bfae6d0b64b0feef565196327fe8d50", "title": "Intriguing Properties of Vision Transformers"}, {"paperId": "c7650fe09c2b34e43646e785e09aefe290247e52", "title": "Are Convolutional Neural Networks or Transformers more like human vision?"}, {"paperId": "5faf75b5c5a4d83bd6407b4aba8fb0bccd7fa31d", "title": "Conformer: Local Features Coupling Global Representations for Visual Recognition"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "ad4a0938c48e61b7827869e4ac3baffd0aefab35", "title": "Emerging Properties in Self-Supervised Vision Transformers"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "cc9f3a61ea4eaabf43cbb30cd1dd718074932679", "title": "All Tokens Matter: Token Labeling for Training Better Vision Transformers"}, {"paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6", "title": "Multiscale Vision Transformers"}, {"paperId": "003326a15fc4a8833785a47a741d7712474fa256", "title": "LeViT: a Vision Transformer in ConvNet\u2019s Clothing for Faster Inference"}, {"paperId": "8f8f73f0f208302546c825ed474432389ed63be4", "title": "EfficientNetV2: Smaller Models and Faster Training"}, {"paperId": "40f4d7fe800810288a80f84cdb357a8f4c28e880", "title": "Rethinking Spatial Dimensions of Vision Transformers"}, {"paperId": "b6382a7351c0c595f91472ac71d3b2d87b3c4844", "title": "ViViT: A Video Vision Transformer"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "08695fdaa5544e22742a8aea1ddeb9808ab20ab2", "title": "AutoMix: Unveiling the Power of Mixup for Stronger Classifiers"}, {"paperId": "610b302950a19acef1c45456111dcd495f638c18", "title": "ConViT: improving vision transformers with soft convolutional inductive biases"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "6e8f35c6d54acb14109c9b792a62609eac8a7b5e", "title": "TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up"}, {"paperId": "c16835c8e535ebd9c10a550ca9455fe384a14449", "title": "High-Performance Large-Scale Image Recognition Without Normalization"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78", "title": "Bottleneck Transformers for Visual Recognition"}, {"paperId": "feeae38fd404fdc17cad19d80461843059216fde", "title": "Characterizing signal propagation to close the performance gap in unnormalized ResNets"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "6f6f73e69ee0d9d5d7d088bb882db1851d98175a", "title": "Pre-Trained Image Processing Transformer"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "9017fba9c4268dabc15e4bd8a99c6992625f9585", "title": "Interpreting and Boosting Dropout from a Game-Theoretic View"}, {"paperId": "12fd70787218583118d807390585a895aabef428", "title": "Monocular Expressive Body Regression through Body-Driven Attention"}, {"paperId": "38f93092ece8eee9771e61c1edaf11b1293cae1b", "title": "Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "13da774fe604027bff2951ba82f4c3d9be7e415e", "title": "Augment Your Batch: Improving Generalization Through Instance Repetition"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "fb93ca1e004cbdcb93c8ffc57357189fa4eb6770", "title": "ResNeSt: Split-Attention Networks"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "3b7eca55735a22147e40bc0852bb329227df9a37", "title": "Learning Delicate Local Representations for Multi-Person Pose Estimation"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "f0bfcf4152276b055455dcb86d3f03e29009d051", "title": "mechanism"}, {"paperId": "96382611e8a8139df8771ea5c6b25d553cf3e9a5", "title": "Orthogonal Convolutional Neural Networks"}, {"paperId": "a15591db63cc736f36770806dfc5a0f199eefe87", "title": "The Origins and Prevalence of Texture Bias in Convolutional Neural Networks"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "28e1db22e72be9d4fbfa830f31c471a69eab2d86", "title": "FreiHAND: A Dataset for Markerless Capture of Hand Pose and Shape From Single RGB Images"}, {"paperId": "bc626a52664e948a0ffb2b95d0e1e6377a01171a", "title": "Cascade R-CNN: High Quality Object Detection and Instance Segmentation"}, {"paperId": "c2c083df88e88223e1a411e61040b94c233b1b63", "title": "MMDetection: Open MMLab Detection Toolbox and Benchmark"}, {"paperId": "a39398f68ae7e042f2ef5009e31b4e6a20fd5736", "title": "Learning Deep Transformer Models for Machine Translation"}, {"paperId": "21de3a36cb51adc205fad8a1d3d69118891dc3dd", "title": "AutoAugment: Learning Augmentation Strategies From Data"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "5e19eba1e6644f7c83f607383d256deea71f87ae", "title": "Searching for MobileNetV3"}, {"paperId": "66143960c0325c70329a3869cc8052f0416b87aa", "title": "GCNet: Non-Local Networks Meet Squeeze-Excitation Networks and Beyond"}, {"paperId": "bc789aef715498e79a74f857fa090ece9e383bf1", "title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes"}, {"paperId": "efe1edde4918c603a1191cbcfb669c11b3c6e7c6", "title": "Explaining Deep Neural Networks with a Polynomial Time Algorithm for Shapley Values Approximation"}, {"paperId": "6303bac53abd725c3b458190a6abe389a4a1e72d", "title": "Deep High-Resolution Representation Learning for Human Pose Estimation"}, {"paperId": "a84906dbd4d6640f918d0b6ed2a7313dda0d55f1", "title": "Panoptic Feature Pyramid Networks"}, {"paperId": "ceb2ebef0b41e31c1a21b28c2734123900c005e2", "title": "A Style-Based Generator Architecture for Generative Adversarial Networks"}, {"paperId": "23cfb692c55ab178a818d4a86d5d417981358086", "title": "Deep convolutional networks do not classify based on global object shape"}, {"paperId": "0f50b7483f1b200ebf88c4dd7698de986399a0f3", "title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness"}, {"paperId": "c02b909a514af6b9255315e2d50112845ca5ed0e", "title": "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "de95601d9e3b20ec51aa33e1f27b1880d2c44ef2", "title": "CBAM: Convolutional Block Attention Module"}, {"paperId": "dc9187434a1c27306c61a3317aa942d3402d97c3", "title": "Simple Baselines for Human Pose Estimation and Tracking"}, {"paperId": "2d2e1d1f50645fe20c051339e9a0fca7b176422a", "title": "Evaluation of Dense 3D Reconstruction from 2D Face Images in the Wild"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4", "title": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "79cfb51a51fc093f66aac8e858afe2e14d4a1f20", "title": "Focal Loss for Dense Object Detection"}, {"paperId": "ee53c9480132fc0d09b1192226cb2c460462fd6d", "title": "Channel Pruning for Accelerating Very Deep Neural Networks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "8501e330d78391f4e690886a8eb8fac867704ea6", "title": "Train longer, generalize better: closing the generalization gap in large batch training of neural networks"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "4a73a1840945e87583d89ca0216a2c449d50a4a3", "title": "Deformable Convolutional Networks"}, {"paperId": "b587ee7c802a5bd222a69090f59285e0dfdb29f1", "title": "Sigmoid-Weighted Linear Units for Neural Network Function Approximation in Reinforcement Learning"}, {"paperId": "88caa4a0253a8b0076176745ebc072864eab66e1", "title": "Language Modeling with Gated Convolutional Networks"}, {"paperId": "2a94c84383ee3de5e6211d43d16e7de387f68878", "title": "Feature Pyramid Networks for Object Detection"}, {"paperId": "01a4f33da8ad94ced3cf58548b28dbbb44148571", "title": "Understanding the Effective Receptive Field in Deep Convolutional Neural Networks"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "5582bebed97947a41e3ddd9bd1f284b73f1648c2", "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"}, {"paperId": "5b6ec746d309b165f9f9def873a2375b6fb40f3d", "title": "Xception: Deep Learning with Depthwise Separable Convolutions"}, {"paperId": "88512be44744615f4baa8e14f600f036db4c2433", "title": "Semantic Understanding of Scenes Through the ADE20K Dataset"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "4361e64f2d12d63476fdc88faf72a0f70d9a2ffb", "title": "Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units"}, {"paperId": "1c4e9156ca07705531e45960b7a919dc473abb51", "title": "Wide Residual Networks"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "7f5fc84819c0cf94b771fe15141f65b123f7b8ec", "title": "Multi-Scale Context Aggregation by Dilated Convolutions"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "829510ad6f975c939d589eeb01a3cf6fc6c8ce4d", "title": "Unsupervised Learning of Video Representations using LSTMs"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327", "title": "Going deeper with convolutions"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "2bd2b120ccd5aa88a5927889a973b2204732e435", "title": "Performance-optimized hierarchical models predict neural responses in higher visual cortex"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "bc90c96263679a51021a63884b36f3e6ed8444a0", "title": "Rigid-Motion Scattering for Texture Classification"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "6dc61f37ecc552413606d8c89ffbc46ec98ed887", "title": "Acceleration of stochastic approximation by averaging"}, {"paperId": "76361a44e145732a39dbc68d9418871038c83be2", "title": "A feature-integration theory of attention"}, {"paperId": "c70cd5ee9c96252b8a5325d429dbce7291429a8d", "title": "EdgeFormer: Improving Light-weight ConvNets by Learning from Vision Transformers"}, {"paperId": "9b54ce3cf87d326d12e6349d2f82922acebb19ef", "title": "OpenMixup: Open Mixup Toolbox and Benchmark for Visual Representation Learning"}, {"paperId": "63f1f2dad0a2e84d37a97258008c5609195487f0", "title": "Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs"}, {"paperId": "fd830773da098dbb475307ac669919214f7c5bff", "title": "Discovering the Representation Bottleneck of Graph Neural Networks from Multi-order Interactions"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "7dee2bc2be709c0009b7623b7af78246f32e0a60", "title": "Demystifying Local Vision Transformer: Sparse Connectivity, Weight Sharing, and Dynamic Weight"}, {"paperId": null, "title": "Rethinking \"batch\" in batchnorm. ArXiv, abs/2105.07576"}, {"paperId": null, "title": "MMSegmentation Contributors"}, {"paperId": null, "title": "MMSegmentation: Openmmlab semantic segmentation toolbox and benchmark. ht tps://github.com/open-mmlab/mmsegmenta tion"}, {"paperId": null, "title": "Recognition (CVPR)"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}, {"paperId": null, "title": "Video prediction with SimVP on Moving MNIST. The FLOPs and FPS are measured at the input tensor of 10 \u00d7 1 \u00d7 64 \u00d7 64 on an NVIDIA Tesla V100 GPU"}, {"paperId": null, "title": "Model Input Learning Warmup Rand 3-Augment EMA Top-1"}, {"paperId": null, "title": "Decoupled mixup for data-ef\ufb01cient learning"}, {"paperId": null, "title": ": Fast pretraining"}, {"paperId": null, "title": "Architecture Data Param. 100-epoch 300-epoch"}]}