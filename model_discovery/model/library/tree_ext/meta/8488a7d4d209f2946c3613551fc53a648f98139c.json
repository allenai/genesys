{"paperId": "8488a7d4d209f2946c3613551fc53a648f98139c", "title": "B I XT: P ERCEIVING L ONGER S EQUENCES W ITH B I -D IRECTIONAL C ROSS -A TTENTION T RANSFORMERS", "abstract": null, "venue": "", "year": null, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": null, "embedding": null, "authors": [], "references": [{"paperId": "5a9cb1b3dc4655218b3deeaf4a2417a9a8cd0891", "title": "DINOv2: Learning Robust Visual Features without Supervision"}, {"paperId": "2f4d8f3c016ec53380b376ae7ac516f9c0f07a0d", "title": "BiFormer: Vision Transformer with Bi-Level Routing Attention"}, {"paperId": "d2f63b56fc6bc373f5c023454c2b253326962865", "title": "DeiT III: Revenge of the ViT"}, {"paperId": "2ad12a7be5eaf339a98c4defd8669e11fe726acc", "title": "MaxViT: Multi-Axis Vision Transformer"}, {"paperId": "a7cc9851d78bd718e17f6fca05efa16710344952", "title": "Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual MLP Framework"}, {"paperId": "9933a5af7895354087baf6c96b64dc8a8973eaed", "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "7fff8018bf625447df837c2fda5c58a705fbc038", "title": "XCiT: Cross-Covariance Image Transformers"}, {"paperId": "40f4d7fe800810288a80f84cdb357a8f4c28e880", "title": "Rethinking Spatial Dimensions of Vision Transformers"}, {"paperId": "3cbe314cc5407a6c3249815b5173f22ea15173c2", "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"}, {"paperId": "b3bf9fe13195e9aa70e1dac04e01fcff7008e812", "title": "Perceiver: General Perception with Iterative Attention"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "a32ed7f632e087c92ecd8f7a1080cba23aa6ea99", "title": "Implicit Kernel Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "c877932f3935679d21005a41958735809a13ca16", "title": "TESA: Tensor Element Self-Attention via Matricization"}, {"paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d", "title": "ETC: Encoding Long and Structured Inputs in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "10c2250aeab4d4cbdba07293da95a513dcdf85ee", "title": "Asymmetric Non-Local Neural Networks for Semantic Segmentation"}, {"paperId": "918ee34e404ba5872d1ceae4d42dedb7f674c9f1", "title": "Expectation-Maximization Attention Networks for Semantic Segmentation"}, {"paperId": "62dc8ddb4907db4b889c5e93673d9b3c189d1f25", "title": "A Tensorized Transformer for Language Modeling"}, {"paperId": "a84906dbd4d6640f918d0b6ed2a7313dda0d55f1", "title": "Panoptic Feature Pyramid Networks"}, {"paperId": "5f4a22ee70ca613d9c0630eafc96364fe365fdf8", "title": "Efficient Attention: Attention with Linear Complexities"}, {"paperId": "b7339c1deeb617c894cc08c92ed8c2d4ab14b4b5", "title": "A2-Nets: Double Attention Networks"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "8674494bd7a076286b905912d26d47f7501c4046", "title": "PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space"}, {"paperId": "d997beefc0922d97202789d2ac307c55c2c52fba", "title": "PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"}, {"paperId": "729d5c7dc6bfb32e47b5bd24cdb01ccaaf62bba5", "title": "A scalable active framework for region annotation in 3D shape collections"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd", "title": "ImageNet Large Scale Visual Recognition Challenge"}, {"paperId": "7c8a51d04522496c43db68f2582efd45eaf59fea", "title": "3D ShapeNets: A deep representation for volumetric shapes"}, {"paperId": null, "title": "MMSegmentation Contributors"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Set trans-former: A framework for attention-based permutation-invariant neural networks"}, {"paperId": "be0dd2e91bb104494feeb5da2761cf930564f650", "title": "Under review as a conference paper at ICLR 2016"}, {"paperId": null, "title": "Figure A2 The attention maps of all latent vectors (64 in this case) for the final layer of our BiXT tiny architecture"}]}