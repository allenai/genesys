{"paperId": "e2ee883fca5f8f32a1dfa2dc06c742d57f2c38b9", "title": "Linearizing Transformer with Key-Value Memory", "abstract": "Efficient transformer variants with linear time complexity have been developed to mitigate the quadratic computational overhead of the vanilla transformer. Among them are low-rank projection methods such as Linformer and kernel-based Transformers. Despite their unique merits, they usually suffer from a performance drop comparing with the vanilla transformer on many sequence generation tasks, and often fail to obtain computation gain when the generation is short. We propose Memsizer, an approach towards closing the performance gap while improving the efficiency even with short generation. It projects the source sequences into lower dimension representations like Linformer, while enjoying efficient recurrent-style incremental computation similar to kernel-based transformers. This yields linear computation time and constant memory complexity at inference time. Memsizer also employs a lightweight multi-head mechanism which renders the computation as light as a single-head model. We demonstrate that Memsizer provides an improved balance between efficiency and accuracy over the vanilla transformer and other efficient transformer variants in three typical sequence generation tasks, including machine translation, abstractive text summarization, and language modeling.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2022, "citationCount": 4, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://aclanthology.org/2022.emnlp-main.24.pdf", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "It is demonstrated that Memsizer provides an improved balance between efficiency and accuracy over the vanilla transformer and other efficient transformer variants in three typical sequence generation tasks, including machine translation, abstractive text summarization, and language modeling."}, "embedding": {"model": "specter_v2", "vector": [0.3147406578063965, 0.508792519569397, -0.36807915568351746, 0.05165613442659378, -0.695795476436615, -0.3281916677951813, 0.9367969036102295, -0.09863805770874023, -0.19953754544258118, -0.13998129963874817, 0.9698236584663391, -0.08066853880882263, 0.2720048129558563, -0.13004131615161896, -0.46980440616607666, 0.007778814062476158, -0.5448964238166809, 0.33363649249076843, -0.26378634572029114, -0.19718188047409058, 0.2463533878326416, -0.7840940952301025, -0.7208048105239868, 0.20500816404819489, 0.6457659602165222, 0.37762975692749023, 0.08209031820297241, 1.0106582641601562, -0.6482575535774231, 0.6071820855140686, 0.4516245424747467, -0.41877785325050354, 0.2721276581287384, -0.4515552222728729, -0.3414576053619385, -0.11375316232442856, 0.14511074125766754, -0.5755029320716858, -0.2447224259376526, 0.7467169165611267, -0.0862063467502594, 0.1406337469816208, 0.6060857176780701, -0.47433367371559143, -0.34279677271842957, 1.1686922311782837, 0.43143442273139954, 0.3605288863182068, 0.29226210713386536, -0.6840887665748596, 1.3239977359771729, -1.9058935642242432, 0.3990742564201355, 1.3309370279312134, 0.5496125817298889, 0.2086067497730255, -0.15405890345573425, -0.35966601967811584, 0.6101000905036926, 0.40603017807006836, -1.0131230354309082, -0.5359792709350586, -0.07727362960577011, -0.17300289869308472, 1.619654893875122, -0.16984835267066956, 0.1764773279428482, 0.2884630858898163, -0.05391515791416168, 1.541629672050476, -0.3204908072948456, -0.4447326362133026, -0.21579404175281525, -0.13704392313957214, 0.11099668592214584, 0.8792000412940979, -0.2957034111022949, 0.0010937731713056564, -1.156964659690857, -0.3826424479484558, -0.03451061248779297, -0.09299261122941971, -0.34171295166015625, -0.23364153504371643, -0.4857705235481262, 0.5600296854972839, 0.19768305122852325, 0.48519980907440186, -0.390966534614563, 0.7919068932533264, 0.5868015289306641, 0.21421444416046143, 0.39537471532821655, 0.2664732336997986, 0.07784712314605713, 0.2197829633951187, -1.3028080463409424, 0.5755622982978821, 0.20779970288276672, 0.587662935256958, -0.16966001689434052, 0.31274887919425964, -1.037976861000061, 0.11849766969680786, 1.1775768995285034, 0.33426305651664734, 0.7230757474899292, -0.6072009801864624, 0.182231605052948, -0.7165645956993103, 0.023070035502314568, -0.7802436351776123, 0.06258642673492432, -0.12832029163837433, -0.9977445602416992, -1.5771816968917847, -0.648371160030365, 0.22422155737876892, -0.6321130394935608, 0.7406830787658691, -0.26606687903404236, 0.6199080348014832, 0.144830584526062, 0.3705189824104309, 0.6809864640235901, 1.1611400842666626, -0.2807100713253021, -0.55517578125, 0.6923093795776367, -0.7713599801063538, -0.6617960929870605, -0.8131994605064392, 0.9745128154754639, -0.2505335509777069, 0.01887967251241207, -0.11396974325180054, -1.4029927253723145, -0.7376614809036255, -0.7245026230812073, 0.05900076776742935, -0.27519503235816956, 0.29710930585861206, 0.8112212419509888, 0.24058407545089722, -1.051473617553711, 0.7259491682052612, -0.06238443776965141, -0.13140073418617249, 0.26722079515457153, 0.1800333708524704, 0.13308560848236084, -0.5987572073936462, -1.0283763408660889, 0.3807165026664734, 0.11559029668569565, -0.5582753419876099, -0.11570101976394653, -0.9262610077857971, -0.9405468106269836, -0.00874322559684515, 0.3236270248889923, -0.7707789540290833, 1.256182312965393, 0.4684455096721649, -1.7450404167175293, 0.02244631201028824, -0.5878134369850159, 0.02256494201719761, 0.23883773386478424, -0.5570710897445679, 0.23297856748104095, -0.552253007888794, 0.02128821611404419, -0.04040248692035675, 0.5581994652748108, 0.2191254049539566, -0.18062332272529602, 0.23905149102210999, -0.806296169757843, 0.08231528848409653, -0.09414912760257721, 0.7269385457038879, -0.44187480211257935, -0.12790775299072266, 0.36522912979125977, 0.6161929965019226, -0.2591703236103058, -0.7457563877105713, -0.6529793739318848, -1.0408920049667358, 0.5440765023231506, -0.2030159831047058, 1.0399304628372192, -0.45331302285194397, -0.12639166414737701, -0.3240930438041687, -0.0372711680829525, -0.2400740087032318, -0.7676439881324768, 0.8862272500991821, -0.44700974225997925, 0.19761762022972107, -0.2850854694843292, -0.8419796824455261, 0.05475490540266037, -0.5675868391990662, -1.1580414772033691, 0.059673938900232315, 0.08311127126216888, 1.3142646551132202, -0.9930384159088135, 0.23261447250843048, 0.027531998232007027, -0.09456925094127655, -0.9083588123321533, 1.2403101921081543, -0.0947737917304039, 0.13207943737506866, -0.1653139740228653, -0.545904815196991, 0.15941061079502106, -0.41203007102012634, 0.5150347948074341, -0.49504220485687256, 0.03637492284178734, 0.39090725779533386, -0.7253385186195374, 1.4622716903686523, -0.10854680091142654, 0.4115871489048004, -0.5944689512252808, -0.8986706137657166, 0.21795254945755005, 0.30553048849105835, 0.047382652759552, -0.22281000018119812, -0.038011979311704636, 0.60152667760849, -0.8392246961593628, 0.4788022041320801, 0.6079283952713013, 0.5352644324302673, -0.5372315645217896, 0.2979835867881775, 0.6775879859924316, -0.3260628581047058, 0.899986982345581, 0.7185742259025574, 0.8124751448631287, 0.393161803483963, 0.6651251912117004, 0.21573284268379211, 0.5267996788024902, -0.7354190349578857, -0.0029000071808695793, 0.5978585481643677, 1.2648882865905762, 0.9435688257217407, 0.3056454658508301, -0.6381183862686157, -0.41606926918029785, -0.26273313164711, 1.1109334230422974, 1.180993914604187, -0.37553074955940247, -0.7324857115745544, -0.6309786438941956, 0.0772378072142601, -0.4982856810092926, 0.30690136551856995, -0.11452733725309372, -0.45216262340545654, -0.5414041876792908, -1.4019025564193726, 0.7809703350067139, 0.34146544337272644, 0.8999438881874084, 0.0490785650908947, -0.00563030457124114, -0.18886058032512665, -0.24187664687633514, -0.7990521788597107, -0.5646458268165588, -0.1525944173336029, -0.6209721565246582, 0.014660262502729893, -0.3167816400527954, 0.3351297974586487, 0.07383940368890762, -0.6533130407333374, 0.882592499256134, -0.8042616248130798, -0.0960906520485878, 0.07873246818780899, 0.40607750415802, -0.6699973940849304, -0.6190436482429504, 0.17378251254558563, 0.41059309244155884, -0.20178277790546417, -0.013292900286614895, 0.36978664994239807, 0.1415456235408783, -0.4126676619052887, -0.148044154047966, 0.6236127614974976, 0.07821357250213623, 0.17127476632595062, 0.341085284948349, -0.38224369287490845, -0.21986979246139526, -1.0054430961608887, 1.2215101718902588, 0.1712096482515335, -0.45235055685043335, 0.21130557358264923, -0.6918626427650452, -0.4215376675128937, 0.4406525790691376, -0.5828494429588318, -0.10164890438318253, -0.9850670695304871, 0.3786138892173767, -0.06473242491483688, 0.2856009006500244, 0.5141985416412354, 0.36473700404167175, 0.606990396976471, -0.004403853788971901, 0.9726837277412415, 0.3717103600502014, -0.2281852513551712, 1.0526533126831055, -0.9301391839981079, 0.6074088215827942, 0.5384859442710876, 0.6276443004608154, -0.09497284144163132, -0.05548914149403572, -0.5863077044487, -0.3035832941532135, -0.3497246503829956, -0.12166613340377808, -0.2941019535064697, -0.029337450861930847, -0.886435329914093, -0.7013537287712097, 0.030035199597477913, -1.4346623420715332, 0.06499163061380386, 0.05492393672466278, -0.2703028917312622, -0.32098516821861267, -0.9161313772201538, -1.4951413869857788, -0.3081132769584656, -1.150115728378296, -0.8716166019439697, 0.5629070401191711, -0.31852805614471436, -0.5459758639335632, -0.10154721885919571, 0.2996935546398163, -0.5715538263320923, 0.7406569719314575, -0.7011980414390564, 0.8488615155220032, -0.016499988734722137, -0.5211908221244812, -0.307472825050354, 0.22546932101249695, 0.45660197734832764, -0.3845769464969635, -0.010319378226995468, -0.31468716263771057, 0.024901026859879494, -0.45797258615493774, 0.14588576555252075, 0.25714197754859924, 0.6999942660331726, 0.1320464164018631, -0.30587655305862427, -0.7017990946769714, 0.47129392623901367, 1.2519745826721191, -0.6719998717308044, 0.029515549540519714, -0.01193788181990385, 1.2938083410263062, 0.21730518341064453, -0.22489207983016968, 0.8900063037872314, 0.36600610613822937, 0.43300899863243103, -0.23482996225357056, -0.050538212060928345, 0.1250140517950058, -0.7140566110610962, 1.0942543745040894, 2.141065835952759, 0.28894180059432983, -0.21524499356746674, -0.7589486241340637, 0.5029577016830444, -1.664065957069397, -0.9837514758110046, 0.2702980935573578, 0.6387929320335388, 0.1013188511133194, -0.9311079978942871, -0.17773286998271942, -0.2001977562904358, 0.10777901113033295, 0.38142916560173035, -0.22343774139881134, -0.5114166140556335, 0.15662966668605804, 0.38183024525642395, 0.37405821681022644, 0.3804251551628113, 0.2296789139509201, 0.6812575459480286, 14.899173736572266, 0.7395852208137512, 0.09297487884759903, 0.7710856199264526, 0.3739936053752899, -0.2683993875980377, -0.36697036027908325, 0.08173546940088272, -1.0896327495574951, 0.03317748382687569, 1.2474758625030518, -0.5929446816444397, 0.26141977310180664, 0.08815134316682816, 0.36536097526550293, 0.3469003736972809, -0.5861884355545044, 0.9785639643669128, 0.6163371801376343, -1.7794612646102905, 0.7370805144309998, 0.2808716297149658, 0.44892674684524536, 0.5995422005653381, 0.6906879544258118, 0.8146229386329651, 0.24199311435222626, -0.39217251539230347, 0.40699705481529236, 0.4846164882183075, 0.7351953983306885, -0.1769828498363495, 0.5351011753082275, 0.4820639491081238, -1.0347529649734497, -0.3693018853664398, -0.6812270283699036, -1.2981752157211304, 0.7889519929885864, 0.6449777483940125, -0.7890096306800842, -0.04035633057355881, -0.28706037998199463, 1.096167802810669, 0.2566719651222229, 0.3332262337207794, -0.11957364529371262, 0.7034531235694885, -0.1025606319308281, 0.17668212950229645, 0.11759337782859802, -0.1696871817111969, 0.22376003861427307, -0.10667341947555542, 0.8902512192726135, -0.04233337566256523, 0.1970454752445221, 0.3733144700527191, -0.4946150481700897, 0.17799077928066254, -0.751218855381012, -0.35036325454711914, 0.02035738155245781, 0.537205159664154, 0.653647243976593, -0.19502393901348114, -0.39661380648612976, 0.5175435543060303, 0.48227134346961975, 0.04171484336256981, -0.22457252442836761, 0.027187228202819824, 0.4115382432937622, -0.0022891140542924404, 0.027617275714874268, 0.42627066373825073, -0.09157869964838028, -0.7029997706413269, -0.6398360729217529, -0.38515496253967285, 0.1451486051082611, -0.7390109896659851, -0.37052252888679504, 0.4628838300704956, 0.08332878351211548, -0.5477899312973022, -0.3592281937599182, -0.47514474391937256, -0.5000727772712708, 0.4442792534828186, -0.9577508568763733, -0.5686699151992798, 0.5294210910797119, -0.5265665054321289, -0.1454063057899475, -0.07142526656389236, 1.046887993812561, -0.06653637439012527, -0.5402708649635315, -0.14975570142269135, 0.3674885034561157, -0.2518405318260193, -0.4368666112422943, -0.6966671347618103, 1.1348551511764526, 0.6552169919013977, -0.06018201634287834, 0.5018503069877625, 0.19137617945671082, -0.038379184901714325, -1.3279155492782593, -0.1112055853009224, 0.8373252153396606, -1.0231996774673462, -0.5509220361709595, -0.7922380566596985, -0.6602373719215393, 0.04597480967640877, 0.40122708678245544, -0.6498925089836121, 0.42038998007774353, -0.04340854287147522, -0.2566956579685211, -0.24110449850559235, -0.21624135971069336, 0.1551136076450348, 0.5289578437805176, -0.6149300932884216, -0.1814567744731903, 0.12159501016139984, 0.4694157838821411, -0.7448535561561584, -0.2520098090171814, -0.08949567377567291, 0.03849106654524803, 0.07382652908563614, 1.1565093994140625, -0.14325791597366333, 0.7209808230400085, 0.4398971199989319, 0.02926136739552021, -0.9175139665603638, -0.4496080279350281, -0.9919242858886719, -0.16198697686195374, 0.267024964094162, 0.42307132482528687, -0.031213080510497093, 0.36250317096710205, 0.43940070271492004, 0.5643869042396545, -0.3636227250099182, -0.3920822739601135, -0.13959120213985443, 0.032255128026008606, -0.5962784886360168, 0.2568001449108124, -0.5072362422943115, 0.021099748089909554, 0.5577470660209656, -0.1005953848361969, 0.40480923652648926, -0.0888286754488945, -0.7014154195785522, 0.9227765798568726, 0.05011240392923355, 0.23919405043125153, -0.5045982003211975, -0.38524723052978516, -1.4287563562393188, -0.0021168002858757973, -1.3509787321090698, 0.025676453486084938, -1.5689808130264282, 0.14781776070594788, 0.8930231928825378, 0.056899815797805786, -0.24201111495494843, 0.05704842507839203, -0.21702000498771667, -0.22659452259540558, -0.55609130859375, -0.5690433382987976, 0.9739921689033508, 0.5761708617210388, -0.9080418944358826, -0.006535990629345179, -0.24263809621334076, 0.07285702973604202, 0.10812315344810486, 0.12774963676929474, -0.41281574964523315, -1.000279188156128, -1.058647871017456, 0.632437527179718, 0.06399266421794891, -0.07668523490428925, -0.5203864574432373, 0.7260178327560425, 0.438205361366272, -0.04853767529129982, -0.3343357741832733, 0.30545416474342346, -0.12284840643405914, 0.05079071596264839, 0.48409122228622437, -0.6675771474838257, 0.43601512908935547, -0.28099325299263, -0.5760661959648132, -0.12430662661790848, 0.8651437759399414, -0.3326610326766968, -1.2047561407089233, -0.47007766366004944, 0.48045629262924194, -0.7901498079299927, -0.061106618493795395, -0.5607317686080933, -0.20793141424655914, -0.7731220126152039, -0.6805933713912964, 0.5806952118873596, 0.04223434254527092, -0.11244585365056992, 0.8211879134178162, 0.8615650534629822, -1.1409947872161865, -0.3203774690628052, 0.17604941129684448, -0.14817504584789276, -0.2532421052455902, 0.4275834560394287, 0.5101037621498108, 0.03904244303703308, 0.4618435204029083, 0.7519283890724182, 0.19701425731182098, -0.7595171332359314, -0.0649067759513855, 0.24757744371891022, -0.8092253804206848, -0.39889174699783325, 1.0332331657409668, -0.2418384701013565, -1.1467747688293457, -0.4529374837875366, -0.953909695148468, -0.3271203935146332, -0.21583347022533417, 1.0074331760406494, 0.4839537441730499, -0.18159666657447815, -0.04685501381754875, -0.6931788325309753, 0.18946397304534912, -0.10349097102880478, -0.8080427050590515, 0.7142791748046875, -0.22664767503738403, -0.8481665849685669, 0.6303483843803406, 1.035319447517395, -0.7104740142822266, 0.18276874721050262, -0.7020576000213623, -0.2947685122489929, -0.16271409392356873, 0.35909003019332886, 0.008162838406860828, -0.16020968556404114, 0.4796738624572754, 0.47094377875328064, -0.09248275309801102, 0.26840296387672424, -0.26894885301589966, 0.44727835059165955, 0.7646451592445374, 0.06701850146055222, -0.5300987362861633, -0.5325268507003784, 1.2740570306777954, 1.1543270349502563, -0.414014995098114, 0.735483705997467, -0.044162165373563766, -0.7448359727859497, 0.6829426884651184, -0.2523828148841858, -0.09182292222976685, 0.5864630341529846, -0.07492288947105408, -0.024143829941749573, 0.16981250047683716, -1.415830135345459, -0.3693620562553406, 0.9381522536277771, 1.0282835960388184, 0.8222010731697083, 0.06398642063140869, -0.18878817558288574, 0.6625650525093079, 0.10260165482759476, 0.4337919056415558, 0.7338071465492249, 0.283816933631897, -0.07067029178142548, -0.1264706254005432, -0.15577809512615204, 1.01554536819458, -0.6406403183937073, -0.8684148192405701, 0.23942804336547852, -0.006418020464479923, -0.2303193360567093, 0.6925222873687744, 0.5932038426399231, -0.010265005752444267, 0.581244945526123, 0.12251503020524979, 0.4457453489303589, -0.609326183795929, 0.06635930389165878, -0.11299145966768265, -0.6177927255630493, -0.2513259947299957, 0.013510935008525848, -0.5267964601516724, -0.31737008690834045, -0.37215131521224976, 0.11431676894426346, 0.23425151407718658, 0.23793117702007294, 1.2390589714050293, 0.6230469942092896, 0.3354577422142029, -0.07751290500164032, -0.8003459572792053, -0.6312223076820374, -1.0282986164093018, 0.07377567887306213, -0.11209544539451599, -0.5178865194320679, -0.09455366432666779, 0.07952740043401718, -0.06510460376739502]}, "authors": [{"authorId": "2120312196", "name": "Yizhe Zhang"}, {"authorId": "2053327987", "name": "Deng Cai"}], "references": [{"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"}, {"paperId": "7fff8018bf625447df837c2fda5c58a705fbc038", "title": "XCiT: Cross-Covariance Image Transformers"}, {"paperId": "af679d69fcc1d0fcf0f039aba937853bcb50a8de", "title": "Luna: Linear Unified Nested Attention"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "054e307c1edf4b28137ffcbce980fe81f0647d20", "title": "Finetuning Pretrained Transformers into RNNs"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "0822f8d7e6a72a65e65f147d3a8d8fccd485da40", "title": "Shortformer: Better Language Modeling using Shorter Inputs"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "168fc3525f7b97695a97b04e257ee9bd1e832acb", "title": "Memory Transformer"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "a238109c3969ae681eee0d4f1bf2012f28850593", "title": "Synthesizer: Rethinking Self-Attention in Transformer Models"}, {"paperId": "8905f3dcd215fbc3d56839b6f52a43d77ac59fe8", "title": "Augmenting Transformers with KNN-Based Composite Memory for Dialog"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "ce106590145e89ea4b621c99665862967ccf5dac", "title": "Q8BERT: Quantized 8Bit BERT"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1", "title": "Reducing Transformer Depth on Demand with Structured Dropout"}, {"paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d", "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"}, {"paperId": "3c5f1ab37f70db503636075e15b3173f86eea00b", "title": "Green AI"}, {"paperId": "bf442ab269074665a68e4dbbe19e4efc97862541", "title": "Large Memory Layers with Product Keys"}, {"paperId": "d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "title": "Energy and Policy Considerations for Deep Learning in NLP"}, {"paperId": "f4238bd2385a52413ccbacfd9e409a650235bd13", "title": "Adaptive Attention Span in Transformers"}, {"paperId": "b03c7ff961822183bab66b2e594415e585d3fd09", "title": "Are Sixteen Heads Really Better than One?"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "305b2cf37e5dece81e95c92883d5a6e28ac93b22", "title": "Don\u2019t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "bf8fe437f779f2098f9af82b534aa51dc9edb06f", "title": "Scaling Neural Machine Translation"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "424aef7340ee618132cc3314669400e23ad910ba", "title": "Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling"}, {"paperId": "32e934094c4d17fe4d734b2e169ba5e3cd0ee05e", "title": "Orthogonal Random Features"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "63e39cdf1ad884da6bc69096bb3413b5b1100559", "title": "Using the Output Embedding to Improve Language Models"}, {"paperId": "1a327709cc53ff9e52454e50a643abf4a0ac92af", "title": "Findings of the 2016 Conference on Machine Translation"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "f37076f426023241f19cdc2fb0a0fd733a6fa7fa", "title": "Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "d1505c6123c102e53eb19dff312cb25cea840b72", "title": "Teaching Machines to Read and Comprehend"}, {"paperId": "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e", "title": "End-To-End Memory Networks"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "c1126fbffd6b8547a44c58b192b36b08b18299de", "title": "Neural Turing Machines"}, {"paperId": "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649", "title": "Understanding the difficulty of training deep feedforward neural networks"}, {"paperId": "7a59fde27461a3ef4a21a249cc403d0d96e4a0d7", "title": "Random Features for Large-Scale Kernel Machines"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": null, "title": "Lucia Specia, Marco Turchi, Karin Verspoor, and Marcos Zampieri"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}]}