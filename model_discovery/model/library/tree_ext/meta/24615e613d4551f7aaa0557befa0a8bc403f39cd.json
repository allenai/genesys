{"paperId": "24615e613d4551f7aaa0557befa0a8bc403f39cd", "title": "Stateful Memory-Augmented Transformers for Dialogue Modeling", "abstract": "Transformer encoder-decoder models have shown impressive performance in dialogue modeling. However, as Transformers are in-ef\ufb01cient in processing long sequences, dialogue history length often needs to be truncated. To address this problem, we propose a new memory-augmented Transformer that is compatible with existing pre-trained encoder-decoder models and enables ef\ufb01cient preservation of history information. It incorporates a separate memory module alongside the pre-trained Transformer to effectively interchange information between the memory states and the current input context. We evaluate our model on three dialogue datasets and two language modeling datasets. Experimental results show that our method has achieved superior ef\ufb01ciency and performance compared to other pre-trained Transformer baselines.", "venue": "arXiv.org", "year": 2022, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2209.07634", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "A new memory-augmented Transformer is proposed that is compatible with existing pre-trained encoder-decoder models and enables ef\ufb01cient preservation of history information and incorporates a separate memory module alongside the pre-trained Transformer to effectively interchange information between the memory states and the current input context."}, "embedding": {"model": "specter_v2", "vector": [0.1198626235127449, 0.8954910635948181, -0.3935548961162567, -0.29733219742774963, -0.3514184057712555, -0.494251012802124, 1.0677876472473145, -0.19545400142669678, -0.2840263545513153, 0.018657928332686424, 1.2494738101959229, -0.5584213733673096, 0.4775088429450989, -0.012437191791832447, 0.1375405490398407, 0.12511944770812988, -0.8672566413879395, 0.35023626685142517, -0.12282067537307739, -0.5907083749771118, -0.362252414226532, -0.6629602313041687, -0.3748578429222107, 0.19379645586013794, 0.23350462317466736, 0.10755839943885803, 0.04966053366661072, 0.6169159412384033, -0.4425021708011627, 0.7073349356651306, 0.8333492875099182, -0.4756675958633423, 0.022496934980154037, -0.3116772472858429, -0.6342456340789795, 0.27805501222610474, 0.061780571937561035, -0.7236671447753906, -0.77924644947052, 0.4627295434474945, -0.35031911730766296, 0.3770526349544525, 0.0245521143078804, -0.29386472702026367, 0.010039151646196842, 1.0307557582855225, 1.1759605407714844, 0.7123478055000305, 0.003039037575945258, -0.7419919967651367, 1.2387398481369019, -1.5212544202804565, 0.2601394057273865, 1.5700947046279907, 0.43474850058555603, 0.4768085479736328, -0.3922373950481415, -0.5768961906433105, 0.6876055598258972, -0.009605923667550087, -0.5882688760757446, -0.669111967086792, 0.0042062485590577126, -0.2655048668384552, 1.469937801361084, 1.40174552143435e-05, 0.6319217681884766, 0.6171994805335999, -0.21793895959854126, 1.5059455633163452, -0.1115151196718216, -0.4636569023132324, -0.5489287972450256, 0.6148220300674438, 0.28468751907348633, 1.2786840200424194, -1.13184654712677, 0.27764657139778137, -0.9155294299125671, -0.12185785174369812, 0.6527765393257141, -0.15435317158699036, -0.3058581054210663, -0.32387039065361023, -0.35100021958351135, 0.93094801902771, -0.2261454313993454, 0.9485469460487366, 0.12588441371917725, -0.3015279769897461, 0.7153109908103943, 0.30983078479766846, 0.06913688033819199, 0.29010313749313354, 0.4661799371242523, -0.03128473833203316, -0.5681453347206116, 0.24047696590423584, 0.07809782773256302, 0.6120060682296753, -0.3296361565589905, 0.3490488529205322, -1.1011041402816772, 0.5968028903007507, 1.530285120010376, -0.3053445816040039, 0.3099392354488373, -0.9890732765197754, 0.21508175134658813, -0.5123927593231201, 0.5230122804641724, -0.4733552634716034, 0.058917779475450516, 0.11764069646596909, -0.3985053598880768, -1.4868948459625244, -0.34087446331977844, 0.33475369215011597, -0.7762749195098877, 0.6493127346038818, -0.3764662742614746, -0.10028041899204254, 0.21373815834522247, 0.006289709825068712, 0.6981542706489563, 0.8738608360290527, 0.21250388026237488, -0.5596941709518433, 0.7799443602561951, -0.9155757427215576, -1.4478074312210083, -1.144120216369629, 0.6218785643577576, -0.058623407036066055, 0.3104207515716553, -0.2715153992176056, -1.1418137550354004, -0.6127904057502747, -0.8955878615379333, -0.11174625903367996, -0.08659598976373672, 0.08519124984741211, 1.1540364027023315, 0.5696045756340027, -1.2171610593795776, 0.7054463028907776, -0.021754320710897446, -0.16108576953411102, -0.03764265030622482, -0.2203664481639862, 0.1090540736913681, -0.018676824867725372, -1.387243628501892, 0.5470792055130005, 0.08903761208057404, -0.15832959115505219, -0.7347754836082458, -0.5164756178855896, -1.5461457967758179, -0.47821271419525146, 0.39994972944259644, 0.11211708933115005, 1.67476224899292, 0.5681345462799072, -1.7815958261489868, 0.4481561481952667, -0.5119057297706604, 0.28739261627197266, 0.1874137818813324, -0.31219667196273804, -0.4643169939517975, -0.6263136267662048, 0.018285244703292847, 0.031667958945035934, -0.238743394613266, -0.22591756284236908, -0.2126326560974121, -0.04691145196557045, 0.07577844709157944, 0.3059540092945099, -0.33255645632743835, 1.0735211372375488, -0.5339610576629639, 0.17546337842941284, 0.08906162530183792, 0.6286418437957764, -0.09075240790843964, -0.2034059315919876, -0.5538326501846313, -0.6084592938423157, 1.0229439735412598, -0.14128224551677704, 1.7988606691360474, -0.8594193458557129, -0.637016773223877, -0.5415973663330078, -0.26408353447914124, 0.20015309751033783, -0.4669550955295563, 0.9126994609832764, -0.305081307888031, 0.11316971480846405, -0.07945530861616135, -1.4412202835083008, 0.11142192780971527, 0.14054308831691742, -0.9560796022415161, -0.41162970662117004, -0.29418161511421204, 0.9316737651824951, -1.183576226234436, -0.1857970654964447, 0.5371163487434387, 0.3534764349460602, -0.4542410969734192, 1.8793094158172607, 0.03249426186084747, 0.5471188426017761, 0.11927984654903412, -0.32353150844573975, -0.19007670879364014, -0.08009547740221024, 0.8442696332931519, -0.6747714877128601, -0.5008373260498047, 0.8229663968086243, -0.22910013794898987, 1.4389615058898926, -0.3506539463996887, 0.45456627011299133, 0.09676782041788101, -0.23858065903186798, 0.4551795721054077, 0.7577702403068542, -0.24942271411418915, -0.2392561435699463, 0.2197166383266449, 0.3133588433265686, -0.7620999217033386, 0.48122426867485046, 0.9923466444015503, 0.22643209993839264, -0.2898082137107849, 0.23834963142871857, 0.5972512364387512, -0.4194285571575165, 0.6408597230911255, 0.4625440239906311, 0.7005665302276611, 0.16546322405338287, 0.3268095552921295, 0.21756425499916077, 0.38983577489852905, -0.8999002575874329, -0.07422436028718948, 0.1391577124595642, 0.3700862228870392, 0.6115916967391968, 0.4659094214439392, -0.4912427067756653, -0.10182436555624008, -0.3475779592990875, 0.8903632760047913, 1.5207836627960205, -0.33684757351875305, -0.6368495225906372, -0.5661307573318481, -0.27073296904563904, -0.921486496925354, 0.5820454359054565, -0.5009214878082275, -0.4091518819332123, -0.6279946565628052, -0.6604844331741333, 1.1704448461532593, 0.4546835720539093, 1.2964121103286743, -0.256174236536026, -0.2469409704208374, 0.06763839721679688, -0.12997496128082275, -0.5803495645523071, -0.7116102576255798, 0.40388035774230957, -0.853436291217804, -0.27414897084236145, 0.2016204595565796, -0.04960301145911217, -0.42681968212127686, -0.6498316526412964, 0.9424751400947571, -0.7592095136642456, 0.08780401200056076, 0.39585819840431213, 0.8758528232574463, -0.3242328464984894, -1.1608268022537231, -0.4970574975013733, 0.029619649052619934, -0.15445658564567566, 0.06488946825265884, 0.4980410933494568, 0.2699296772480011, 0.20318835973739624, -0.1629248708486557, 0.40376749634742737, -0.2422967255115509, 0.2624186873435974, 0.11590985208749771, -0.6061593294143677, -0.5319448113441467, -1.130635142326355, 1.3935853242874146, 0.47866061329841614, -0.1189897283911705, 0.6263870596885681, -0.671963632106781, -0.38107001781463623, 0.010063892230391502, -0.4897541105747223, -0.8200676441192627, -0.9419584274291992, 0.28605398535728455, -0.019036130979657173, 0.15824827551841736, 0.3999265134334564, -0.11962121725082397, 0.6193420886993408, -0.200433149933815, 0.8291530609130859, 0.6533318161964417, -0.3896756172180176, 0.58409184217453, -0.5335460305213928, 0.3925133943557739, 0.42099639773368835, 0.08529721200466156, -0.2801927626132965, -0.5086528062820435, -0.8593385815620422, -0.4965575635433197, -0.21636775135993958, -0.1890445500612259, -0.5852428078651428, 0.17551937699317932, -0.3158523142337799, -0.6536358594894409, -0.12154200673103333, -1.3811180591583252, -0.19995160400867462, -0.11198946833610535, -0.4321732223033905, -0.10643187910318375, -0.7916107177734375, -1.401790976524353, -1.1131694316864014, -0.5252333283424377, -1.0932385921478271, 0.10042939335107803, -0.012737530283629894, -0.4251415431499481, -0.9025799632072449, 0.5465607643127441, -0.15274281799793243, 0.8716103434562683, -0.8244683742523193, 0.8552907109260559, -0.017787490040063858, 0.03288637101650238, -0.04393377527594566, 0.5355554223060608, 0.7136908769607544, 0.27174898982048035, -0.047598741948604584, -0.7174292206764221, 0.41411900520324707, 0.07408121228218079, 0.012148099951446056, -0.24952933192253113, -0.18537701666355133, 0.16074472665786743, -0.04064066335558891, -0.3463149666786194, -0.2573617696762085, 0.5278503894805908, 0.023056643083691597, 0.014450045302510262, 0.042628366500139236, 0.8308566808700562, 0.31854483485221863, 0.15974795818328857, 0.6848751902580261, 0.5735862851142883, 0.7962548136711121, 0.09254039078950882, -0.011811449192464352, 0.24858789145946503, -0.7752476334571838, 0.7441865801811218, 1.472348928451538, 0.07974863052368164, 0.01666872762143612, -0.9227469563484192, 0.7515700459480286, -1.4375256299972534, -0.7576541900634766, 0.7752169966697693, 0.8776962161064148, 0.7821688055992126, -0.7459917664527893, -0.061606988310813904, -0.147309809923172, 0.5332205891609192, 0.7930278778076172, -0.0745379775762558, -0.9501221179962158, 0.5349360108375549, 0.20960424840450287, -0.4634672999382019, 1.0472822189331055, -0.5627065896987915, 0.2896327078342438, 14.36113166809082, 0.2704535722732544, 0.07383593171834946, 0.7104547619819641, 0.4281669557094574, 0.30319368839263916, -0.4005211889743805, -0.2177990823984146, -1.0127063989639282, -0.24705810844898224, 1.1857911348342896, -0.28217682242393494, 0.6366193294525146, -0.13575315475463867, 0.2506045401096344, 0.15758490562438965, -0.7007097601890564, 0.5494481325149536, 0.17845338582992554, -1.1764754056930542, 0.5634208917617798, 0.25075289607048035, -0.5114220380783081, -0.1644195318222046, 0.9811766147613525, 0.9451109766960144, 0.5931698083877563, -0.41956639289855957, 0.3718770146369934, 0.1620882749557495, 0.817168116569519, -0.3172309398651123, 0.28208106756210327, 0.43094518780708313, -1.0205495357513428, -0.3482230305671692, -0.23263856768608093, -0.9115093946456909, 0.9307886958122253, -0.3256374001502991, -0.8732732534408569, -0.8142186403274536, -0.4032011926174164, 0.5932029485702515, 0.17708900570869446, -0.1309075951576233, -0.19910533726215363, 0.9182305335998535, 0.23074771463871002, 0.3123479187488556, 0.5178173184394836, 0.003360494039952755, 0.27993178367614746, 0.15286323428153992, 0.021110808476805687, 0.2719433009624481, 0.13890902698040009, 0.4154009521007538, -0.07150459289550781, -0.34029415249824524, -0.9029740691184998, -0.6990951299667358, 0.0040655010379850864, 0.822228193283081, 0.8260140419006348, 0.31463125348091125, -0.21133127808570862, 0.4329974353313446, 0.25695306062698364, -0.2919834852218628, -0.23226229846477509, 0.28760629892349243, 0.43691694736480713, 0.0850343257188797, -0.3153185546398163, 0.20375563204288483, 0.32979798316955566, -0.2839238941669464, -1.2766169309616089, -0.32672104239463806, 0.46297287940979004, -0.4209557771682739, -0.4014839231967926, 1.147864580154419, 0.13846294581890106, -0.454326868057251, -0.2790760099887848, -0.47707802057266235, -0.5231356024742126, 0.24996210634708405, -0.7856536507606506, -0.9184783101081848, 0.22770580649375916, -0.026373716071248055, -0.3245483338832855, 0.18140748143196106, 1.5502837896347046, 0.275024950504303, -0.35257256031036377, -0.060578394681215286, -0.08138866722583771, 0.26448965072631836, -0.34963518381118774, -1.0107421875, 0.48041415214538574, -0.04156121239066124, -0.05773976072669029, 0.6829139590263367, 0.28472021222114563, -0.05624803155660629, -0.8854987621307373, -0.06264818459749222, 0.8639849424362183, -0.9023133516311646, -0.24271978437900543, -1.0419247150421143, -1.1276628971099854, 0.545150101184845, 0.770840048789978, -0.26133155822753906, 0.9366391897201538, 0.32740136981010437, -0.274141788482666, 0.1044553741812706, -0.8252806067466736, 0.15006965398788452, 0.7186994552612305, -1.0684763193130493, -0.6460000872612, -0.24765336513519287, 0.33256930112838745, -1.2419095039367676, -0.42694392800331116, -0.35530027747154236, 0.10766811668872833, -0.3773359954357147, 0.7645294666290283, -0.20620013773441315, 0.006975154858082533, 0.9910106658935547, -0.025588728487491608, -1.0657964944839478, -0.060479018837213516, -0.9373798370361328, 0.009238533675670624, 0.39921480417251587, 0.5873903036117554, -0.01860535889863968, 0.01385622750967741, 1.4017677307128906, 0.16056592762470245, -0.22328521311283112, -0.8206623196601868, -0.010439596138894558, -0.025756023824214935, -0.27913156151771545, -0.0060110255144536495, -0.2866670787334442, 0.3820723295211792, 0.8267022967338562, -0.13498228788375854, 0.09208884090185165, -0.1698087453842163, -0.9335883855819702, 0.1214287057518959, -0.07123354822397232, 0.1677202433347702, -0.11700186133384705, 0.07995868474245071, -1.470237374305725, -0.05133335292339325, -0.7980776429176331, 0.26996442675590515, -1.1513304710388184, -0.12699083983898163, 0.472063273191452, 0.06589668244123459, 0.13581207394599915, 0.5413306951522827, -0.4766470193862915, -0.27410537004470825, -0.7007342576980591, -0.7937061190605164, 1.1030288934707642, 1.0835007429122925, -0.7439329028129578, -0.06531554460525513, -0.06410855054855347, -0.03657710552215576, 0.1971869021654129, 0.2178688496351242, 0.008248545229434967, -1.1661279201507568, -0.8636991381645203, -0.18078693747520447, 0.12732838094234467, -0.23932242393493652, -0.09516111016273499, 0.4456646144390106, 0.254766583442688, -0.48965194821357727, -0.023975789546966553, 0.8959440588951111, -0.7329010367393494, 0.010751323774456978, 0.13662134110927582, -0.8574227690696716, 0.035167913883924484, 0.18963712453842163, -0.6709139943122864, -0.4262774884700775, 0.8121594190597534, -0.062432318925857544, -1.255915641784668, -0.7415981292724609, 0.40572938323020935, -1.3263871669769287, -0.19258283078670502, -0.27747485041618347, -0.2192593514919281, -0.7006388902664185, -0.6839033365249634, -0.08282256126403809, 0.16586416959762573, -0.6780388951301575, 1.034597635269165, 0.7117537260055542, -1.2342631816864014, 0.38016435503959656, 0.24110008776187897, -0.184696227312088, -0.47894486784935, 0.3512449562549591, 0.45362499356269836, 0.4191112220287323, 0.49319157004356384, 0.1751619428396225, 0.5692310333251953, -1.3651050329208374, -0.4628702700138092, 1.091274380683899, -0.8540010452270508, -0.14369134604930878, 1.1319063901901245, -0.45612633228302, -1.3172333240509033, 0.40150558948516846, -1.07011878490448, -0.984825849533081, -0.16223405301570892, 1.0340417623519897, 0.30502498149871826, -0.3391002118587494, -0.36267614364624023, -0.3019784688949585, -0.14484329521656036, -0.21076369285583496, -0.8930633068084717, 0.6021820902824402, -0.4091486930847168, -0.47966089844703674, 1.4052973985671997, 0.5678367614746094, -0.6441797614097595, -0.6452437043190002, -0.5144754648208618, -0.4423017203807831, -0.30884850025177, 0.371662974357605, -0.7737223505973816, -0.1955786645412445, 1.0643562078475952, 0.7347491979598999, 0.3162876069545746, -0.09315529465675354, -0.21446216106414795, 0.23273688554763794, 0.6532751321792603, 0.3783327341079712, -0.6884839534759521, -0.39307305216789246, 1.5430794954299927, 1.572243332862854, -0.696428656578064, 0.025085698813199997, -0.11560705304145813, -1.0549544095993042, 1.0060467720031738, 0.36263352632522583, 0.6794500350952148, 1.0945292711257935, -0.10189726203680038, 0.509638786315918, 0.006435725837945938, -1.0729150772094727, 0.05686596781015396, 0.4917874038219452, 1.1891615390777588, 1.15288507938385, 0.3724251687526703, 0.08349446207284927, 0.9951571226119995, 0.4144172668457031, 0.2956545352935791, 0.5661396980285645, 0.7239657044410706, -0.28677698969841003, -0.6409251093864441, 0.44818994402885437, 0.3827817440032959, -0.14921161532402039, -0.4688240885734558, -0.25927653908729553, 0.5088326930999756, 0.02790614403784275, 0.9132764935493469, 0.4912509322166443, -0.4986717998981476, 0.9266483187675476, 0.4938458800315857, 0.42492684721946716, -0.935606837272644, -0.7090121507644653, -0.16314968466758728, 0.002612039679661393, -0.3041590750217438, -0.32663148641586304, -0.47863060235977173, -0.2396615594625473, -0.23757413029670715, 0.3727841377258301, 0.4650695025920868, -0.1858634650707245, 1.055899977684021, 0.3942148685455322, -0.013872395269572735, -0.24025528132915497, -0.22800388932228088, -0.6003444790840149, -1.3042500019073486, -0.33095329999923706, -1.1013329029083252, -0.28723081946372986, -0.44976747035980225, -0.04674874246120453, -0.7755817174911499]}, "authors": [{"authorId": "31060482", "name": "Qingyang Wu"}, {"authorId": "144007938", "name": "Zhou Yu"}], "references": [{"paperId": "b21670e8061a06ab97e7d6052c9345a326e84ff8", "title": "UL2: Unifying Language Learning Paradigms"}, {"paperId": "0e802c0739771acf70e60d59c2df51cd7e8c50c0", "title": "Memorizing Transformers"}, {"paperId": "736eb449526fe7128917954ec5532b59e318ec78", "title": "Block-Recurrent Transformers"}, {"paperId": "dc0102a51a9d33e104a4a3808a18cf17f057228c", "title": "Transformer Quality in Linear Time"}, {"paperId": "c49ac1f916d6d2edeb187e6619c8d23acd95eb21", "title": "cosFormer: Rethinking Softmax in Attention"}, {"paperId": "88064de690af282dbdf222774f03ff070b9df22b", "title": "Beyond Goldfish Memory: Long-Term Open-Domain Conversation"}, {"paperId": "d387600e5150b381a306221a5bc9bd92aa99157b", "title": "Memformer: The Memory-Augmented Transformer"}, {"paperId": "4fa24cc5b17e8ff1eb5a01fd37a9d267a57ac563", "title": "Recipes for Safety in Open-domain Chatbots"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "9b539d413393047b28bb7be9b195f142aaf7a80e", "title": "Recipes for Building an Open-Domain Chatbot"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "e52051204cb1179584f3b008c9d38848b52c1f28", "title": "ReZero is All You Need: Fast Convergence at Large Depth"}, {"paperId": "d08463bd665589d04619f04dbde84183ffcf2e63", "title": "Towards a Human-like Open-Domain Chatbot"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "388e2fcdcefbe0834e153ab2a0be127092f9674d", "title": "DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "3d52d429b4d83d096dd354e8470bf3655e8b67bc", "title": "Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "6c7046195f64cccac1ed3275d88d77655534b5a4", "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "784ee73d5363c711118f784428d1ab89f019daa5", "title": "Hybrid computing using a neural network with dynamic external memory"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "f5f323e62acb75f785e00b4c90ace16f1690076f", "title": "Deep Recurrent Q-Learning for Partially Observable MDPs"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e", "title": "End-To-End Memory Networks"}, {"paperId": "ac3ee98020251797c2b401e1389461df88e52e62", "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling"}, {"paperId": "71ae756c75ac89e2d731c9c79649562b5768ff39", "title": "Memory Networks"}, {"paperId": "56010a55d49ac1f42355538f494427fd22402be1", "title": "Exploring the Limits"}, {"paperId": "5db74a28bb57faa7a4614b49a0c172a858b4a571", "title": "FX trading via recurrent reinforcement learning"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "2ae5a5507253aa3cada113d41d35fada1e84555f", "title": "An Efficient Gradient-Based Algorithm for On-Line Training of Recurrent Network Trajectories"}, {"paperId": "f40aeae3e522ada1f6a9f326841b01ef5c8657b6", "title": "Unifying Language Learning Paradigms"}, {"paperId": null, "title": "MLP(H ) Memformer + ReZero uses ReZero (Bachlechner et al., 2021) by adding a zero-initialized trainable weight \u03b1 when adding the memory crossattention layer, and therefore the model\u2019s output"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Openwebtext corpus"}, {"paperId": null, "title": "A Different Model Variants We evaluate different model variants to select the model with best memory effectiveness. We choose the text recall task for evaluation"}]}