{"paperId": "154cc4e8a9e8ad24d4f9c9440b187d06b9ba57bd", "title": "SEED-Bench-2: Benchmarking Multimodal Large Language Models", "abstract": "Multimodal large language models (MLLMs), building upon the foundation of powerful large language models (LLMs), have recently demonstrated exceptional capabilities in generating not only texts but also images given interleaved multimodal inputs (acting like a combination of GPT-4V and DALL-E 3). However, existing MLLM benchmarks remain limited to assessing only models' comprehension ability of single image-text inputs, failing to keep up with the strides made in MLLMs. A comprehensive benchmark is imperative for investigating the progress and uncovering the limitations of current MLLMs. In this work, we categorize the capabilities of MLLMs into hierarchical levels from $L_0$ to $L_4$ based on the modalities they can accept and generate, and propose SEED-Bench-2, a comprehensive benchmark that evaluates the \\textbf{hierarchical} capabilities of MLLMs. Specifically, SEED-Bench-2 comprises 24K multiple-choice questions with accurate human annotations, which spans 27 dimensions, including the evaluation of both text and image generation. Multiple-choice questions with groundtruth options derived from human annotation enables an objective and efficient assessment of model performance, eliminating the need for human or GPT intervention during evaluation. We further evaluate the performance of 23 prominent open-source MLLMs and summarize valuable observations. By revealing the limitations of existing MLLMs through extensive evaluations, we aim for SEED-Bench-2 to provide insights that will motivate future research towards the goal of General Artificial Intelligence. Dataset and evaluation code are available at \\href{https://github.com/AILab-CVC/SEED-Bench}", "venue": "arXiv.org", "year": 2023, "citationCount": 33, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work categorizes the capabilities of MLLMs into hierarchical levels from $L_0 to $L-4 based on the modalities they can accept and generate, and proposes SEED-Bench-2, a comprehensive benchmark that evaluates the hierarchical capabilities ofMLLMs."}, "embedding": {"model": "specter_v2", "vector": [0.33267122507095337, 0.6387352347373962, -0.08909188956022263, -0.1450335532426834, -0.7235726118087769, -0.35788896679878235, 0.8678430914878845, -0.1693045049905777, -0.4888553023338318, -0.10514078289270401, 0.16458648443222046, -0.18991349637508392, 0.3511975109577179, -0.06575886160135269, -0.10964799672365189, 0.25501736998558044, -0.9516065120697021, 0.6062349081039429, -0.46851909160614014, -0.375581830739975, -0.2527569532394409, -0.9048863053321838, -0.9204272627830505, 0.31318551301956177, 0.3158808946609497, 0.3993007242679596, 0.2000199407339096, 1.2594947814941406, -0.19985492527484894, 0.15811000764369965, 0.33501502871513367, -0.4801291823387146, 0.16803893446922302, -0.22543472051620483, -0.3947767913341522, 0.21975837647914886, 0.30288445949554443, -0.6743307709693909, -0.3942452371120453, 0.4010021686553955, 0.16571779549121857, 0.250760018825531, 0.5841684341430664, -0.5661296844482422, -0.542202889919281, 0.7803492546081543, 0.6110337972640991, 0.24802438914775848, 0.4141649007797241, 0.010812767781317234, 1.3557792901992798, -1.4960429668426514, 0.37707042694091797, 1.8622618913650513, 0.001328920479863882, 0.6039386987686157, -0.5865322947502136, -0.4887474477291107, 0.3632972240447998, -0.36798152327537537, -0.8514769673347473, -0.20107437670230865, -0.2938385307788849, -0.04772740975022316, 1.3315227031707764, -0.2902497351169586, -0.31411832571029663, 0.8732457756996155, -0.11644908785820007, 1.702004075050354, -0.0037406908813863993, -1.1213778257369995, -0.37021881341934204, 0.1309354454278946, 0.0018758578225970268, 0.8130083680152893, -0.7542566061019897, 0.44795942306518555, -0.7506921887397766, -0.0015467576449736953, 0.4859960079193115, -0.5783246159553528, -0.503821849822998, 0.29996007680892944, -0.8569341897964478, 0.8704147934913635, 0.09268217533826828, 0.6947641968727112, 0.2581954300403595, 0.28093916177749634, -0.00043288193410262465, 0.7058880925178528, -0.10756561160087585, 0.3380110561847687, -0.13971832394599915, 0.6747077107429504, -0.7950827479362488, 0.6251955628395081, 0.15890367329120636, 0.9801909923553467, -0.22842177748680115, -0.07228118926286697, -1.2875927686691284, 0.15054216980934143, 1.4156352281570435, 0.1829301118850708, 0.7751985788345337, -0.7237595319747925, 0.4881615936756134, -0.5623381733894348, 0.4651203453540802, -0.5295718908309937, -0.37728458642959595, 0.02087320387363434, -0.5749498605728149, -1.2153427600860596, 0.004194074310362339, -0.08970482647418976, -0.8532713651657104, 0.8706148862838745, -0.4610825777053833, -0.5430142879486084, 0.31840747594833374, 0.48669832944869995, 1.1022312641143799, 1.0089619159698486, 0.45422619581222534, 0.258398175239563, 0.9842532277107239, -0.6741743683815002, -0.4146265387535095, -1.1754952669143677, 0.8698671460151672, -0.36997950077056885, 0.7036705613136292, -0.19283872842788696, -1.3671170473098755, -1.090008020401001, -0.6581737995147705, -0.2284131795167923, -0.46954113245010376, 1.042683720588684, 0.6309373378753662, 0.42586714029312134, -1.294132113456726, 0.2911261022090912, 0.3356086313724518, -0.3639051020145416, -0.12410034239292145, 0.16816683113574982, -0.10560496151447296, -0.7514088153839111, -1.3558753728866577, 0.1716350018978119, 0.2232508510351181, -0.5000703930854797, -0.3264484405517578, 0.4274914264678955, -1.4761383533477783, -0.45988625288009644, 0.2451171875, -0.47065481543540955, 1.416905164718628, -0.18939875066280365, -1.0969738960266113, 1.000148057937622, -0.42023566365242004, 0.2726535499095917, 0.3791550099849701, 0.10065768659114838, -0.6567253470420837, -0.26189857721328735, -0.2635361850261688, 1.532383680343628, 0.1643669307231903, -0.2622227966785431, 0.15087057650089264, 0.4731787145137787, -0.13405467569828033, -0.028085192665457726, -0.20362959802150726, 0.9075492024421692, -0.5199754238128662, -0.36774834990501404, 0.008824655786156654, 0.5697552561759949, -0.15840069949626923, 0.06289642304182053, -0.6770715117454529, -0.9731271266937256, 0.3946024477481842, 0.17791174352169037, 0.7480961084365845, -0.8875440955162048, -0.6495099067687988, -0.6477888822555542, -0.22215189039707184, -0.6590092182159424, -1.3712282180786133, 0.7697503566741943, -0.1028682217001915, 0.8954198956489563, -0.42312854528427124, -1.6878981590270996, 0.04869695380330086, -0.33383291959762573, -0.31279146671295166, -0.36267632246017456, 0.5570784211158752, 1.5077992677688599, -0.578059196472168, -0.3231492340564728, -0.1410996913909912, -0.029256237670779228, -0.5730804204940796, 1.156057357788086, -0.8077792525291443, 0.46151503920555115, -0.19771237671375275, -0.1544404923915863, -0.16929371654987335, -0.5797829627990723, -0.07115710526704788, -0.2256391942501068, -0.15015718340873718, -0.06586449593305588, -0.20718452334403992, 1.6705988645553589, 0.15782862901687622, 0.330207496881485, -0.5350725054740906, -0.2912708818912506, 0.028207741677761078, 0.7139633893966675, -0.5595428943634033, -0.260614812374115, 0.48706233501434326, 0.3881567716598511, -0.5694072842597961, -0.09813281893730164, 0.5848674178123474, 0.5838868021965027, -0.5853090286254883, 0.3805690109729767, 0.3760523200035095, -0.5837271213531494, 0.7056286334991455, 0.30951857566833496, 0.5549538731575012, 0.2857074439525604, 0.17443880438804626, -0.024969546124339104, 0.5215772986412048, -0.6183445453643799, -0.7812783718109131, 0.7507112622261047, 0.6734611988067627, 1.1587491035461426, 0.2003684788942337, -0.7780094146728516, 0.06446274369955063, -0.12896393239498138, 0.7862949967384338, 1.240028977394104, -0.04553583264350891, -0.047960713505744934, -0.642388105392456, 0.00014747319801244885, -0.5102768540382385, 0.24890512228012085, -0.5899385809898376, 0.13306273519992828, -0.3304307460784912, -0.9637255668640137, 0.7484237551689148, 0.09211191534996033, 0.7356885671615601, -0.8341817855834961, -0.3682425916194916, -0.36999472975730896, -0.1859525740146637, -0.8866011500358582, -0.6938678622245789, -0.17698350548744202, -0.42081838846206665, 0.06362680345773697, -0.4803771674633026, -0.4164070785045624, 0.2831416726112366, -0.7596803307533264, 0.9176865220069885, -0.5384671688079834, -0.5623294115066528, 0.5373438596725464, 0.5133833885192871, -0.5193434357643127, -0.9445004463195801, -0.2808294892311096, -0.27742379903793335, -0.21810771524906158, -0.09126327186822891, 1.0952879190444946, 0.08342500776052475, 0.38607215881347656, -0.8126230835914612, 0.6363390684127808, 0.4205423593521118, 0.06627807021141052, 0.667901337146759, -0.36290502548217773, 0.05187812075018883, -0.655306339263916, 1.3416239023208618, 0.13727474212646484, -0.30082643032073975, 0.7032926678657532, -0.18198342621326447, -0.4681832790374756, 0.2385426014661789, -0.984992504119873, -0.1702778935432434, -0.8474310040473938, 0.5374034643173218, 0.15569151937961578, -0.6431836485862732, 0.5838876962661743, 0.31226927042007446, 0.3388476073741913, 0.3140501081943512, 0.42824599146842957, 0.5532076954841614, 0.09530871361494064, 0.8019760251045227, -0.7579041123390198, 0.48266875743865967, 0.13764514029026031, 0.3171203136444092, -0.03301957994699478, -0.3192196488380432, -0.6873064637184143, -0.32886365056037903, 0.12816183269023895, -0.13895352184772491, -0.649422287940979, 0.6003297567367554, -0.5815172791481018, -0.6246180534362793, 0.2448691874742508, -1.197265625, -0.10411716997623444, 0.09235766530036926, -0.4088776707649231, -0.1511079967021942, -0.8579120635986328, -1.100843906402588, -0.6290432810783386, -0.3775104880332947, -1.232325553894043, 0.7882148027420044, 0.07842298597097397, -0.6099853515625, -0.47606518864631653, 0.06990963220596313, -0.01756652444601059, 0.7604693174362183, -0.3204759955406189, 1.1641967296600342, 0.04162478819489479, -0.3092516362667084, -0.9238157868385315, 0.33819669485092163, 0.24319353699684143, -0.24119050800800323, 0.31267425417900085, -0.7359494566917419, 0.03743651136755943, -0.0285132247954607, -0.8318027853965759, -0.06704125553369522, 0.3544718027114868, 0.2432129681110382, 0.3713081181049347, -0.4018203318119049, -0.3317706882953644, 1.2484391927719116, -0.5536128878593445, -0.22102119028568268, -0.20689985156059265, 0.4565359652042389, 0.8870802521705627, -0.4958377480506897, 0.5105536580085754, 0.6072773337364197, 0.07706212997436523, -0.05077076703310013, -0.19607903063297272, 0.034559011459350586, -0.5708171129226685, 0.8349436521530151, 1.1440074443817139, 0.530716061592102, -0.8072454333305359, -1.1307827234268188, 0.49080878496170044, -0.9838694334030151, -0.25420081615448, 0.6221172213554382, 0.8282346725463867, 0.19609420001506805, -0.5219293236732483, -0.3763498067855835, -0.2890399992465973, 0.5137128829956055, 0.18492355942726135, 0.006175980903208256, -0.27513039112091064, -0.6550368666648865, 0.22499634325504303, -0.4195040762424469, 0.45764705538749695, -0.6312583684921265, 0.3605654835700989, 14.67453670501709, 0.7151868343353271, 0.2189481258392334, 0.43928074836730957, 1.1678024530410767, 0.2579209804534912, -0.761040210723877, -0.23557543754577637, -1.0955545902252197, -0.4049505591392517, 1.2768034934997559, 0.2726840078830719, 0.45816418528556824, -0.3406446874141693, 0.2709551751613617, -0.12998539209365845, -0.7304200530052185, 0.6694819331169128, 0.7232357859611511, -0.7878205180168152, 0.8666864633560181, 0.04272983968257904, 0.20158299803733826, 0.47169482707977295, 1.0312937498092651, 0.7006332278251648, 0.20045031607151031, -0.8062368035316467, 0.7475695013999939, 0.2723850607872009, 1.0265871286392212, 0.29407599568367004, 0.20211447775363922, 0.9240347743034363, -0.7785419821739197, -0.3848074674606323, -0.3116810619831085, -1.0541703701019287, 0.5346103310585022, -0.3460095524787903, -0.3210582733154297, -0.3787854313850403, -0.5580340027809143, 0.21235395967960358, -0.18023809790611267, 0.1781640350818634, -0.1442670375108719, 0.5948009490966797, -0.02541656605899334, -0.24712210893630981, 0.378330796957016, 0.47307851910591125, 0.32855746150016785, -0.3307565152645111, 0.4036514163017273, 0.03596814349293709, 0.34406396746635437, 0.6804848909378052, -0.5090810060501099, 0.3893851041793823, -0.6073458790779114, -0.6111964583396912, -0.4919198453426361, 0.5574595332145691, 0.2307652086019516, 0.46686744689941406, -0.6777152419090271, 0.16203485429286957, 0.46233585476875305, 0.2694999575614929, 0.08108629286289215, 0.2756400406360626, -0.2942678928375244, -0.29005157947540283, -0.17552244663238525, 0.39490070939064026, 0.1674554944038391, -0.47506099939346313, -0.5560333728790283, -0.4978512227535248, 0.3671206533908844, -0.9781739115715027, -1.1056088209152222, 1.125037431716919, -0.08967015892267227, -0.608221709728241, 0.014002765528857708, -0.8139774203300476, -0.31536614894866943, 0.6817494034767151, -1.3490772247314453, -1.170639991760254, 0.29326918721199036, -0.26607221364974976, 0.045643530786037445, -0.09616894274950027, 1.5307725667953491, -0.25349676609039307, -0.3907378613948822, 0.10141158103942871, -0.08573748916387558, 0.028384601697325706, -0.25487321615219116, -0.40337300300598145, 0.7994368076324463, 0.09831026196479797, -0.013173558749258518, 0.06026454642415047, -0.10264955461025238, -0.030625533312559128, -0.9770598411560059, 0.18413564562797546, 0.8675218820571899, -1.0555663108825684, -0.5711756348609924, -0.7544776797294617, -0.5155229568481445, -0.08005574345588684, 0.7913327813148499, -0.5289224982261658, 0.47699159383773804, -0.4282117784023285, -0.2512194514274597, 0.3456815779209137, -0.8603852391242981, 0.2952338457107544, 0.12080548703670502, -0.6664493083953857, -0.17156586050987244, 0.40239614248275757, 0.5060892105102539, -0.7901559472084045, -0.20327918231487274, 0.024347370490431786, 0.1860734522342682, 0.13472047448158264, 0.5467237234115601, -0.5768119096755981, 0.9757240414619446, 0.7759499549865723, -0.3315849304199219, -0.5764083862304688, 0.2534300684928894, -1.0023128986358643, 0.45089972019195557, -0.22581881284713745, 1.1472331285476685, -0.2570687234401703, -0.11099611967802048, 1.0216153860092163, 0.7776724696159363, -0.5552110075950623, -0.648883044719696, -0.08982688188552856, 0.293359637260437, -0.6236023306846619, 0.1763906329870224, -0.48402687907218933, 0.01278048288077116, 0.17867343127727509, 0.20458970963954926, 0.6233881115913391, -0.28521397709846497, -0.4885036051273346, 0.5534031391143799, -0.11527036875486374, -0.26500409841537476, -0.6144282221794128, -0.28306111693382263, -1.6332054138183594, 0.0035192626528441906, -1.1162326335906982, 0.2013470083475113, -1.032131552696228, -0.2748105823993683, 0.5722325444221497, 0.15428650379180908, 0.10932830721139908, 0.581616222858429, -0.3157767057418823, -0.49105510115623474, -0.5179982781410217, -0.2643035352230072, 0.8253856897354126, 1.2966758012771606, -0.8969699740409851, 0.21294082701206207, -0.13271291553974152, 0.11339332908391953, 0.06820449233055115, 0.11185313761234283, -0.0656958743929863, -1.0435729026794434, -1.6504048109054565, 0.2147897183895111, 0.239995077252388, 0.15941107273101807, -0.7756763100624084, 0.5625226497650146, 0.6124513149261475, -0.19956189393997192, -0.03682222589850426, 0.6447546482086182, -0.529377281665802, -0.6093056797981262, 0.2067013680934906, -1.200535535812378, 0.5137699246406555, 0.377169668674469, -0.6154235601425171, -0.5034778714179993, 0.4319485127925873, -0.3061527609825134, -1.2112312316894531, -0.10189452022314072, 0.45002222061157227, -0.8352000713348389, 0.03143686428666115, -0.12264488637447357, -0.21945559978485107, -1.058459758758545, -0.7292376756668091, -0.22806374728679657, 0.5804823637008667, -0.5616740584373474, 1.0688737630844116, 0.9329492449760437, -0.8970614075660706, -0.35196349024772644, 0.32694393396377563, 0.3208898603916168, -0.0013931806897744536, 0.67850261926651, 0.14797382056713104, -0.177837073802948, 0.5064588189125061, 0.5653750896453857, 0.2966887652873993, -0.9158030152320862, -0.2793973386287689, 0.7155390381813049, -0.38234007358551025, 0.19783294200897217, 1.5523345470428467, -0.12320058047771454, -1.2891050577163696, 0.15858227014541626, -1.0036557912826538, -0.6620582342147827, -0.40886008739471436, 0.5539392828941345, -0.2460400015115738, -0.5929184556007385, -0.4099080264568329, 0.042995426803827286, 0.386604368686676, -0.025275180116295815, -1.027026653289795, 0.061759356409311295, -0.25706958770751953, -0.22041893005371094, 0.6853219866752625, 0.7403650879859924, -0.9197189211845398, -0.22175782918930054, -0.3926987648010254, -0.3984922766685486, 0.2235318124294281, 0.035804539918899536, -0.6885511875152588, -0.2157030552625656, 0.9400575160980225, 0.5415164828300476, 0.31297650933265686, 0.24661360681056976, 0.1573847532272339, 0.38109758496284485, 0.7642805576324463, 0.1710929572582245, -0.2984885573387146, -0.325082927942276, 0.9650872349739075, 1.5124555826187134, -1.293850302696228, -0.10147736966609955, -0.14049473404884338, -0.8619822859764099, 0.9290537238121033, 0.38623926043510437, 0.7121420502662659, 0.8619323968887329, -0.4151281714439392, 0.3298620879650116, -0.004474902059882879, -1.1244231462478638, 0.034132033586502075, 1.313299298286438, 0.5510615706443787, 1.000315546989441, 0.6421486139297485, -0.2854922115802765, 0.6895899176597595, 0.11246570199728012, 0.29833734035491943, 0.537268877029419, 0.5775890946388245, -0.16441673040390015, -0.37022048234939575, 0.3000923693180084, 0.47523537278175354, -0.09409044682979584, -0.5363619327545166, -0.18358059227466583, 0.4308225214481354, 0.246504008769989, 1.0017285346984863, 0.505710780620575, 0.15094254910945892, 0.5122480988502502, 0.34792789816856384, 0.5092977285385132, -0.5648766160011292, 0.03713592141866684, -0.19191640615463257, -0.7102375030517578, 0.4149325489997864, -0.2882078289985657, -0.5676344037055969, 0.005271185655146837, 0.36011964082717896, 0.2653816342353821, -0.23640176653862, 0.15482239425182343, 1.170708179473877, 0.40203186869621277, -0.199968159198761, -0.4669969379901886, -0.3773667812347412, -0.5224661231040955, -0.8919171094894409, 0.20221495628356934, -0.45254722237586975, -0.3287254571914673, -0.09568377584218979, -0.29162701964378357, -0.18127721548080444]}, "authors": [{"authorId": "1491798621", "name": "Bohao Li"}, {"authorId": "51123495", "name": "Yuying Ge"}, {"authorId": "2245532356", "name": "Yixiao Ge"}, {"authorId": "2243452799", "name": "Guangzhi Wang"}, {"authorId": "2151036422", "name": "Rui Wang"}, {"authorId": "2268726753", "name": "Ruimao Zhang"}, {"authorId": "2265579883", "name": "Ying Shan"}], "references": [{"paperId": "124d4d374fbef2016fa9880489871a58a7450644", "title": "Improved Baselines with Visual Instruction Tuning"}, {"paperId": "5ba1525dc6d382ee0a4a1ca3c64fc5907ca64c67", "title": "Making LLaMA SEE and Draw with SEED Tokenizer"}, {"paperId": "c1e450284e7d6cac1855330a1197df8537df653f", "title": "InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition"}, {"paperId": "7b689adb8c156d6158660f90d1c86888ee281f63", "title": "DreamLLM: Synergistic Multimodal Comprehension and Creation"}, {"paperId": "fa75a55760e6ea49b39b83cb85c99a22e1088254", "title": "NExT-GPT: Any-to-Any Multimodal LLM"}, {"paperId": "1a735015a1f7ef4f2ba2273ce5fcaaacfa9d1ea2", "title": "Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning"}, {"paperId": "2928e5a5ee488104c5d7b636f577baef2d470310", "title": "TouchStone: Evaluating Vision-Language Models by Language Models"}, {"paperId": "d6c2523ab97416c2692cbbeab082ed1790e8e55e", "title": "VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use"}, {"paperId": "2bd1b8990db73b6495c11082bea2d5f925c5226f", "title": "SciGraphQA: A Large-Scale Synthetic Multi-Turn Question-Answering Dataset for Scientific Graphs"}, {"paperId": "94972e30504017156ef5b5debc419bf6edc67384", "title": "MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities"}, {"paperId": "7fbc502441d66daf1f53765d5d86a8dfba9ab0ce", "title": "OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models"}, {"paperId": "4309d572a37d655779f9dce6a2c98c66334132de", "title": "SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension"}, {"paperId": "40298b8d50109c52fc10763eddc64a07cf8acb31", "title": "Planting a SEED of Vision in Large Language Model"}, {"paperId": "b37b1dc72b1882858f5120f2cd6883134089a6ed", "title": "MMBench: Is Your Multi-modal Model an All-around Player?"}, {"paperId": "94053805cd59f2e9a47fe3f080c7e7afefb337cc", "title": "Generative Pretraining in Multimodality"}, {"paperId": "d7890d1906d95c4ae4c430b350455156d6d8aed9", "title": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"}, {"paperId": "3b6179c293df29e31d31cea46476f104ab6950f2", "title": "Kosmos-2: Grounding Multimodal Large Language Models to the World"}, {"paperId": "697e0add95e880bd42e00bef838181e105f91981", "title": "MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models"}, {"paperId": "a8d02ff6d075c3cc48f0b97801cc52765c8f9ac9", "title": "LVLM-eHub: A Comprehensive Evaluation Benchmark for Large Vision-Language Models"}, {"paperId": "4c4d176c6e28f48041f215d563f6ee8633534cff", "title": "Valley: Video Assistant with Large Language model Enhanced abilitY"}, {"paperId": "fd755dc7b5b206c17fd953db04e1c888d45b6e4e", "title": "LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset, Framework, and Benchmark"}, {"paperId": "bf7025a2e5dbb3c09deae02a1aa98a256ca559e2", "title": "Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models"}, {"paperId": "d47524cd5c3c4b57af2e5a29f6f91c420310f236", "title": "MIMIC-IT: Multi-Modal In-Context Instruction Tuning"}, {"paperId": "89689059d0cdcb52d7fbb6007ab953db22936a90", "title": "M3Exam: A Multilingual, Multimodal, Multilevel Benchmark for Examining Large Language Models"}, {"paperId": "d3f79210b54e168c76b8c311488f42d7d1048b81", "title": "PandaGPT: One Model To Instruction-Follow Them All"}, {"paperId": "6a5525c316b9be7909c433a79e090ed731425083", "title": "What Makes for Good Visual Tokenizers for Large Language Models?"}, {"paperId": "848e690a62c327e1210532d58a6b914097cac763", "title": "On the Hidden Mystery of OCR in Large Multimodal Models"}, {"paperId": "8bd6a2a89503be083176f2cc26fabedb79238cbd", "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"}, {"paperId": "d48cb91b9e555194f7494c4d4bb9815021d3ee45", "title": "VideoChat: Chat-Centric Video Understanding"}, {"paperId": "81e7e82245c2f230eeb8aaaa1a2b2604c143754a", "title": "MultiModal-GPT: A Vision and Language Model for Dialogue with Humans"}, {"paperId": "d6d3604f369bb0415cbe814e43ca3131323b03e2", "title": "Otter: A Multi-Modal Model with In-Context Instruction Tuning"}, {"paperId": "0046306876ff2d5600699327e52bc29fa5e9ec91", "title": "Transfer Visual Prompt Generator across LLMs"}, {"paperId": "570079bbdd8758dfe865097e05719313c9c1301a", "title": "LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model"}, {"paperId": "7e32aac43e9f1df49e116add03327ee6f365dbf3", "title": "mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality"}, {"paperId": "ca6a2bc279be5a3349a22bfd6866ed633d18734b", "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"}, {"paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8", "title": "Visual Instruction Tuning"}, {"paperId": "7470a1702c8c86e6f28d32cfa315381150102f5b", "title": "Segment Anything"}, {"paperId": "6721b137c216ae15bbeba641292a63e32ab159a8", "title": "Tag2Text: Guiding Vision-Language Model via Image Tagging"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "25de00096c45121a06668bc501f91adec5d0aff9", "title": "Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis"}, {"paperId": "33b1dbf1ad913047b919cd090907ffc4199b4178", "title": "GRiT: A Generative Region-to-text Transformer for Object Understanding"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "d3135733aa39dec20ce72aa138589dda27c8406d", "title": "Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "77d956cdab4508d569ae5741549b78e715fd0749", "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods"}, {"paperId": "63c74d15940af1af9b386b5762e4445e54c73719", "title": "VinVL: Revisiting Visual Representations in Vision-Language Models"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "f3f5db6241f37b6302469c4b712a2260146bf84b", "title": "Google Landmarks Dataset v2 \u2013 A Large-Scale Benchmark for Instance-Level Recognition and Retrieval"}, {"paperId": "c496f00f2b85b496abdc36e4dc4105541248fd3c", "title": "PlotQA: Reasoning over Scientific Plots"}, {"paperId": "6dfc2ff03534a4325d06c6f88c3144831996629b", "title": "From Recognition to Cognition: Visual Commonsense Reasoning"}, {"paperId": "b4df354db88a70183a64dbc9e56cf14e7669a6c0", "title": "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"}, {"paperId": "b68811a9b5cafe4795a11c1048541750068b7ad0", "title": "The \u201cSomething Something\u201d Video Database for Learning and Evaluating Visual Common Sense"}, {"paperId": "21334d1aac5422da88780f8e24e181bfa15ef0e1", "title": "Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding"}, {"paperId": "185f078accb52be4faa13e4f470a9909cc6fe814", "title": "The Language of Actions: Recovering the Syntax and Semantics of Goal-Directed Human Activities"}, {"paperId": "fcd7b547bf0a6646a282f521db880e74974aa838", "title": "ICDAR 2013 Robust Reading Competition"}, {"paperId": "32b8f58a038df83138435b12a499c8bf0de13811", "title": "End-to-end scene text recognition"}, {"paperId": "bb5b2df137a4d54c3a9145fa363e66531b491580", "title": "Scene Text Recognition using Higher Order Language Priors"}, {"paperId": "5ddb51ae85deca14dc7fc8adc07305c22a1ebe0a", "title": "Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities"}, {"paperId": null, "title": "Challenges in representation learning: Facial expression recognition challenge"}, {"paperId": "e2ee104b00d45161f48d8760ec9955452944f2cf", "title": "Digital Object Identifier (DOI) 10.1007/s10032-004-0134-3 ICDAR 2003 robust reading competitions: entries, results, and future directions"}, {"paperId": "cfee1826dd4743eab44c6e27a0cc5970effa4d80", "title": "Improving Image Generation with Better Captions"}, {"paperId": null, "title": "the leaderboards for each task, sub-part, part are displayed"}, {"paperId": null, "title": "Rescaling egocentric vision"}, {"paperId": null, "title": "Obelics"}]}