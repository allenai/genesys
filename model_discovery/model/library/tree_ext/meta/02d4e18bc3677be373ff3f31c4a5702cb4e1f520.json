{"paperId": "02d4e18bc3677be373ff3f31c4a5702cb4e1f520", "title": "Pre-trained Language Models in Biomedical Domain: A Survey from Multiscale Perspective", "abstract": "Pre-trained language models have been the de facto paradigm for most natural language processing (NLP) tasks. In the biomedical domain, which also benefits from NLP techniques, various pre-trained language models were proposed by leveraging domain datasets including biomedical literature, biomedical social medial, electronic health records, and other biological sequences. Large amounts of efforts have been explored on applying these biomedical pre-trained language models to downstream biomedical tasks, from informatics, medicine, and computer science (CS) communities. However, it seems that the vast majority of existing works are isolated from each other probably because of the cross-discipline characteristics. It is expected to propose a survey that not only systematically reviews recent advances of biomedical pre-trained language models and their applications but also standardizes terminology, taxonomy, and benchmarks. Therefore, this paper summarizes the recent progress of pre-trained language models used in the biomedical domain. Particularly, an overview and taxonomy of existing biomedical pre-trained language models as well as their applications in biomedical downstream tasks are exhaustively discussed. At last, we illustrate various limitations and future trends, which we hope can provide inspiration for the future research.", "venue": "", "year": 2021, "citationCount": 5, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The recent progress of pre-trained language models used in the biomedical domain is summarized and an overview and taxonomy of existing biomedical pre-trained language models as well as their applications in biomedical downstream tasks are exhaustively discussed."}, "embedding": {"model": "specter_v2", "vector": [0.4638230800628662, 0.7449303269386292, -0.28159892559051514, -0.4250270426273346, -0.401089608669281, 0.03529591113328934, 0.19435365498065948, -0.005851402413100004, -0.9562142491340637, 0.1161574274301529, 0.7610073685646057, 0.07189439237117767, 0.07924593240022659, 0.5410416722297668, 0.02605181746184826, 0.08816707879304886, -0.9951446652412415, 0.28569579124450684, -0.6733128428459167, 0.08823634684085846, -0.7346681952476501, -0.6629408001899719, -0.007791687734425068, 0.2064274400472641, 0.19256247580051422, -0.48365238308906555, 0.3333338499069214, 0.9592660665512085, -0.2236393690109253, 0.38340550661087036, 0.6410902738571167, -0.6841187477111816, 0.08242566138505936, -0.2989233434200287, -0.17316827178001404, 0.029689643532037735, 0.0559423491358757, -0.52632075548172, -0.7113261222839355, 0.7168346643447876, -0.027984818443655968, -0.024101214483380318, 0.696262776851654, -0.231608048081398, -0.47533005475997925, 1.3892604112625122, 0.8366672396659851, 0.7036320567131042, -0.15810108184814453, -0.43744778633117676, 1.1475577354431152, -1.084118127822876, 0.5006585121154785, 1.5928174257278442, 0.6270283460617065, 0.790111243724823, -0.12101027369499207, -0.8538447022438049, -0.02775660529732704, -0.47046589851379395, -0.7377495169639587, -0.29609382152557373, -0.12339083105325699, -0.6152500510215759, 1.4615464210510254, -0.39285799860954285, -0.24987542629241943, 0.6081957817077637, 0.5415526032447815, 0.7963433861732483, -0.07144796848297119, -0.792000412940979, -0.3952881097793579, 0.20954686403274536, 0.16164129972457886, 1.0820376873016357, -0.4943734109401703, 0.3724420964717865, -0.8490137457847595, -0.4100368916988373, 0.1928066462278366, 0.1571069210767746, -0.06945431977510452, 0.373113214969635, -0.6463075876235962, 0.479238361120224, 0.23471243679523468, 1.256762146949768, -0.2150617092847824, -0.03338569402694702, 0.3940254747867584, 0.3770538568496704, -0.06642194837331772, 0.3956564664840698, -0.471187561750412, 1.0572775602340698, -1.159503698348999, -0.1884629875421524, 0.013677611015737057, 0.8440815806388855, -0.37164533138275146, -0.11407296359539032, -1.1856969594955444, 0.2501850724220276, 1.450231909751892, -0.11174333840608597, 0.6532881259918213, -0.39993223547935486, -0.00048469510511495173, -0.4180450439453125, 0.20422875881195068, -0.7324326038360596, -0.5927886366844177, -0.4987587034702301, -1.0255399942398071, -1.9295997619628906, -0.39931169152259827, 0.003366780001670122, -1.2625285387039185, 1.0373841524124146, -0.6457327008247375, 0.13478140532970428, 0.6030110716819763, 0.18760040402412415, 0.7320480942726135, 0.4668208658695221, 1.026923418045044, -0.15065105259418488, 1.3648780584335327, -0.5130565762519836, -0.8209203481674194, -1.12153959274292, 0.6265586614608765, -0.25832465291023254, -0.04592469334602356, -0.6232030391693115, -0.6433579325675964, -0.780527651309967, -0.44699111580848694, -0.320394903421402, -0.4603833854198456, 0.5649210810661316, 0.758778989315033, 0.29084694385528564, -1.1850645542144775, 0.7273700833320618, 0.10920936614274979, -0.5476092100143433, -0.04352220520377159, 0.08532976359128952, 0.1269557923078537, -0.3773745000362396, -1.5793744325637817, 0.3747182786464691, 0.23489727079868317, -0.45334872603416443, -0.6097521185874939, -0.0824790969491005, -1.0298346281051636, -0.15135231614112854, 0.10005103796720505, -0.9947028160095215, 1.1519321203231812, 0.023221107199788094, -0.955047070980072, 1.4195934534072876, -0.5505226254463196, -0.23505645990371704, 0.13420291244983673, -0.09849890321493149, -0.9878879189491272, -0.1690349131822586, 0.15115857124328613, 0.5213706493377686, 0.01553947664797306, -0.07318542897701263, 0.20814311504364014, 0.13354891538619995, -0.38103827834129333, -0.405087411403656, -0.30285415053367615, 1.0466251373291016, -0.5165184736251831, -0.6573590636253357, 0.2212914228439331, 0.44088324904441833, -0.7274981141090393, -0.1138923242688179, -0.4559841752052307, -0.6337370276451111, 0.0385054312646389, -0.15141764283180237, 0.8436722755432129, -0.9491324424743652, -0.8773600459098816, -0.10931303352117538, -0.08500491082668304, -0.08499892055988312, -0.8497263789176941, 0.6736849546432495, -0.6280509829521179, 0.5478081107139587, -0.5375986695289612, -1.0677745342254639, -0.4031114876270294, -0.11213607341051102, -0.40239083766937256, -0.13018754124641418, 0.12309873849153519, 0.946899950504303, -0.9576342105865479, -0.26141804456710815, -0.0760134905576706, 0.1804240494966507, -0.8564785122871399, 1.030903935432434, -0.06928567588329315, 0.3655667304992676, -0.18137498199939728, -0.04801049828529358, -0.012784005142748356, -0.4851994514465332, 0.25839129090309143, -0.47631925344467163, -0.256639689207077, -0.05471199005842209, 0.3133600652217865, 1.412037968635559, -0.0674259141087532, 0.055309735238552094, 0.1967976689338684, -0.5992271304130554, -0.2937738597393036, 1.071454405784607, 0.3517092764377594, 0.21470648050308228, 0.7319594025611877, 0.19654464721679688, -0.4526926279067993, -0.23340190947055817, 0.11561919003725052, 0.11636030673980713, -0.15084700286388397, -0.19770585000514984, 0.660686194896698, -0.09565944224596024, 0.3997519314289093, 0.522635281085968, 0.502101719379425, -0.21701553463935852, 0.9224956631660461, -0.2746956944465637, 0.8907451629638672, -0.7925217151641846, 0.36774003505706787, 0.5619076490402222, 0.4519651234149933, 0.35246047377586365, 0.007579658646136522, -0.3478769361972809, 0.17683959007263184, 0.1636984944343567, 0.4010232985019684, 1.4477319717407227, -0.5270280241966248, -0.18183112144470215, -0.5714460611343384, -0.1842062622308731, -0.44967368245124817, -0.011022012680768967, -0.4268961250782013, -0.06363703310489655, -0.5728777647018433, -1.0178841352462769, 0.9954309463500977, 0.031116213649511337, 0.3617652654647827, -0.5067220330238342, 0.37544286251068115, -0.11465337872505188, 0.1477229744195938, -0.9236834645271301, -0.8952242732048035, 0.3987804353237152, -0.8672733306884766, -0.3096029758453369, -0.4293985068798065, -0.649160623550415, 0.4202459752559662, -1.1233506202697754, 0.7349292039871216, -0.6523791551589966, -0.6131304502487183, 0.24488607048988342, 0.9306288361549377, -0.7967774271965027, -1.1755293607711792, -0.5913515686988831, 0.12132208049297333, -0.1979367583990097, 0.48899662494659424, 0.6634076833724976, 0.060549575835466385, -0.17259685695171356, -0.6208401918411255, 0.05042598769068718, 0.5818237662315369, 0.449664443731308, 0.5686132311820984, -0.15723609924316406, 0.3426986038684845, -1.4306479692459106, 0.9804415106773376, 0.19248972833156586, -0.08057336509227753, 0.36082640290260315, -0.29193997383117676, -0.23393861949443817, 0.7486259937286377, -0.5256767868995667, -0.4210524260997772, -0.4980784058570862, -0.12333906441926956, 0.1601121425628662, -0.1429622918367386, 1.1067062616348267, 0.4849945306777954, 0.49101758003234863, 0.3631967604160309, 0.5654069185256958, 0.17117539048194885, -0.17339244484901428, 0.31964802742004395, -0.12567199766635895, 0.32317179441452026, 0.5247611403465271, 0.26819291710853577, -0.12097854912281036, -0.375634104013443, -0.8574708104133606, -0.537480890750885, -0.6076399087905884, -0.30896684527397156, -0.11276385933160782, 0.31442925333976746, -0.8753457069396973, -0.28665316104888916, -0.09419025480747223, -0.7018217444419861, 0.2931075096130371, 0.48931947350502014, 0.26018616557121277, 0.3056689202785492, -0.6675681471824646, -1.5638781785964966, -0.45303505659103394, -0.7518318295478821, -0.7242118716239929, 0.5415208339691162, -0.02181762084364891, -0.2114967405796051, -0.3794335424900055, -0.0644802674651146, 0.016809146851301193, 0.6271703243255615, -0.5370350480079651, 1.4311414957046509, -0.23429720103740692, 0.5833274722099304, -0.5504443645477295, 0.4306010901927948, 0.6794767379760742, 0.3572084605693817, 0.20762605965137482, -0.5579200387001038, 0.14077073335647583, 0.2888323664665222, 0.06789840757846832, 0.17059849202632904, 0.5617178082466125, 0.6393691301345825, 0.47250133752822876, -0.8557524681091309, -0.0458538755774498, 0.9439870119094849, -0.40480953454971313, -0.5802159309387207, -0.7214926481246948, 0.2796996831893921, 0.223269984126091, -0.2771907150745392, 0.3189871907234192, -0.10645370930433273, -0.011557668447494507, -0.47674164175987244, -0.3034847378730774, 0.18486899137496948, -0.2941650152206421, 0.42991653084754944, 1.5372203588485718, 0.466157466173172, -0.34858429431915283, -1.367403507232666, 0.7035287618637085, -0.7578758597373962, -0.3952871263027191, 0.6424209475517273, 0.18604490160942078, 0.8369230628013611, -0.12062744051218033, -0.7144283056259155, -0.36848416924476624, 0.4825766384601593, -0.17461664974689484, -0.10069634020328522, -0.18012504279613495, -0.1842871606349945, 0.44968369603157043, 0.153008833527565, 0.3712122440338135, -0.8146235942840576, 0.4794491231441498, 14.664203643798828, -0.008186702616512775, -0.11663543432950974, 0.42187440395355225, 0.5433613657951355, 0.7068445682525635, -0.0664166584610939, -0.3885754644870758, -1.011411428451538, -0.1745603382587433, 1.1488531827926636, -0.15708281099796295, 0.2042596936225891, 0.3953745663166046, 0.4023979902267456, 0.18129582703113556, -0.835169792175293, 0.7305017709732056, 0.6264622211456299, -0.9539506435394287, 0.6020684838294983, 0.27991747856140137, 0.13354183733463287, 0.6934810876846313, 0.6088175177574158, 0.8930933475494385, 0.12275698035955429, -0.5637486577033997, -0.1906495988368988, 0.4564798176288605, 0.45450079441070557, 0.3847932815551758, 0.9212832450866699, 0.8897956609725952, -0.6570123434066772, -0.610092043876648, -0.5608405470848083, -0.6325552463531494, 0.23374606668949127, 0.5080195069313049, -1.1043431758880615, 0.0009644354577176273, -0.5399333238601685, 0.7647165060043335, 0.0924917608499527, 0.3396880328655243, -0.06934481114149094, 0.7009553909301758, 0.1973751038312912, 0.02189231477677822, 0.22410763800144196, 0.6425567269325256, 0.5698463320732117, 0.3036746382713318, 0.07911548018455505, 0.2630719542503357, 0.4409964382648468, 0.10780185461044312, -0.6956631541252136, 0.4626803994178772, -0.32912003993988037, -0.8632456064224243, -0.6919223666191101, 0.5599743127822876, 0.40938475728034973, -0.016686851158738136, -0.6125208735466003, 0.06221882998943329, 0.10711552947759628, 0.22058451175689697, -0.16699154675006866, -0.0009535382851026952, 0.2284422218799591, -0.36359670758247375, -0.6507630944252014, 0.4213505983352661, -0.011803274042904377, -0.6504422426223755, -1.006801724433899, -0.10158556699752808, 0.8111488223075867, -0.7151073217391968, -1.450197458267212, 1.252213716506958, -0.4912894368171692, -0.6225447654724121, 0.27608081698417664, -1.2221617698669434, 0.5100175142288208, 0.7439811825752258, -1.1888911724090576, -0.5557540059089661, 0.5688820481300354, -0.0472349189221859, -0.5595491528511047, -0.23832406103610992, 1.6250749826431274, 0.4289986491203308, -0.5094512104988098, -0.1511755734682083, 0.23960882425308228, 0.6726574897766113, 0.33803001046180725, -0.28021085262298584, 0.061490025371313095, 0.3531983494758606, -0.3437134027481079, 1.1320661306381226, 0.1112956628203392, -0.41525861620903015, -0.7662862539291382, -0.39775073528289795, 1.2378009557724, -0.7041389346122742, -0.5304132103919983, -0.7460375428199768, -0.6117996573448181, 0.3014726936817169, 0.6386004090309143, -0.6861997842788696, 0.9765635132789612, -0.1255144327878952, 0.24616621434688568, 0.04515615478157997, -1.0706244707107544, 0.30770936608314514, 0.7971107363700867, -0.905501663684845, -0.8092017769813538, 0.6212682723999023, 0.14016155898571014, -0.40526655316352844, -0.6139786243438721, 0.29017773270606995, -0.2744465172290802, 0.7980291247367859, 0.9303591847419739, -0.9990659952163696, 0.4729451835155487, 0.7311308979988098, 0.0930800810456276, -0.7020598649978638, -0.3706040382385254, -0.4628622829914093, 0.25338155031204224, -0.3376797139644623, 0.8296478986740112, -0.19553695619106293, 0.10126156359910965, 0.8804681897163391, 0.03633401170372963, -0.5045069456100464, -0.6067190766334534, -0.2681947350502014, -0.13356906175613403, -0.06235293671488762, -0.06422755122184753, 0.008685409091413021, 0.0981702134013176, 0.20698246359825134, 0.13132916390895844, 0.9691216945648193, -0.38553231954574585, -0.4869265854358673, 0.11867454648017883, -0.2051238864660263, -0.055183034390211105, -0.15649347007274628, -0.3491845726966858, -1.32041335105896, 0.2948850393295288, -1.5058993101119995, 0.3567992150783539, -0.9199804067611694, -0.016191838309168816, 0.46530938148498535, -0.5138832330703735, 0.3570092022418976, 0.10648906230926514, -0.45659899711608887, -1.0631135702133179, -0.6893237233161926, 0.40925025939941406, 0.33582189679145813, 1.0730507373809814, -0.7591589689254761, -0.06054995581507683, -0.10202407091856003, -0.09660869091749191, 0.4440010190010071, 0.42923757433891296, -0.7859693169593811, -0.9138621091842651, -1.3300981521606445, -0.11875942349433899, 0.14306797087192535, -0.15954504907131195, -0.4815668761730194, 0.905467689037323, 0.23981177806854248, -0.087398961186409, -0.1304241120815277, 0.5237262845039368, -0.8483120799064636, -0.09456802904605865, 0.7208700180053711, -1.0501530170440674, -0.08436748385429382, -0.13089320063591003, -0.36795544624328613, -0.5189701914787292, 0.5430235266685486, 0.13452556729316711, -1.2221958637237549, -0.10033592581748962, 0.646038830280304, -1.1068781614303589, -0.12239063531160355, -0.08347270637750626, 0.26407870650291443, -0.3133453130722046, -0.1264636218547821, -0.7282188534736633, 0.4721534252166748, -1.0798438787460327, 0.784636378288269, 0.7340517640113831, -0.4915975034236908, -0.3722646236419678, 0.29563993215560913, -0.04528854787349701, -0.7728145718574524, 0.6328060626983643, 0.4811393916606903, -0.31608128547668457, 1.134274959564209, 0.5841336846351624, 0.353130966424942, -1.3807429075241089, -0.07777738571166992, 0.8283007740974426, -0.4525544345378876, -0.3040711581707001, 1.3923521041870117, -0.18874384462833405, -1.056106448173523, 0.30987006425857544, -1.417195439338684, -0.7157551050186157, -0.5440677404403687, 0.3963007926940918, -0.37258708477020264, -0.1531950831413269, -0.5811705589294434, -0.9479601383209229, 0.006323857232928276, 0.15102237462997437, -0.33237895369529724, 0.8183669447898865, -0.09154586493968964, -0.4667080342769623, 0.3653643727302551, 0.8073815107345581, -0.48941367864608765, 0.30046650767326355, -0.621963381767273, 0.1559387445449829, 0.1782282441854477, 0.16167199611663818, -0.618815004825592, -0.5087520480155945, 0.39018136262893677, 0.4720952808856964, -0.26241183280944824, 0.3145475387573242, -0.30398261547088623, 0.14105232059955597, 0.6321037411689758, 0.18578533828258514, -0.545612096786499, -0.7588878273963928, 1.3806613683700562, 1.2193150520324707, -0.9143847227096558, 0.21037140488624573, -0.8306660652160645, -0.6661094427108765, 0.9460852742195129, 0.04357597976922989, 0.2407587319612503, 1.7245945930480957, -0.21943794190883636, 0.47742030024528503, -0.0014179123099893332, -0.6026741862297058, 0.19679683446884155, 1.061727523803711, 0.3328395485877991, 1.3777389526367188, 0.4887619614601135, -0.43924492597579956, 1.371808648109436, 0.07099013775587082, 0.674687922000885, 0.4184178113937378, 0.6062453985214233, 0.09955603629350662, -0.4708891212940216, 0.3903661072254181, 0.9359787702560425, -1.0755789279937744, -0.7389934659004211, -0.2832131087779999, 0.30360594391822815, 0.5247024893760681, 0.714378833770752, -0.15041163563728333, -0.03206544369459152, 0.4452310800552368, 0.6983321309089661, -0.07261400669813156, -1.1292351484298706, -0.438800185918808, -0.007151564583182335, -0.4380079507827759, 0.2530425786972046, -0.6034716963768005, -0.2548149824142456, -0.3057401478290558, 0.5957232713699341, 0.5738767385482788, 0.1299392282962799, 0.2936386466026306, 1.2421939373016357, 0.48467662930488586, 0.2967924475669861, -0.6601501703262329, 0.5566266775131226, -0.24424301087856293, -1.185178279876709, -0.026760298758745193, -0.65702885389328, 0.12965185940265656, 0.16200534999370575, -0.121695376932621, 0.20093227922916412]}, "authors": [{"authorId": "2894465", "name": "Benyou Wang"}], "references": [{"paperId": "b42d20ec9580ebd76860890a1d7a7fdcc742677e", "title": "Modeling Protein Using Large-scale Pretrain Language Model"}, {"paperId": "55c8521e976b54bfe48e24b5a3ce519932069143", "title": "Protein language model embeddings for fast, accurate, alignment-free protein structure prediction"}, {"paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"}, {"paperId": "dc32a984b651256a8ec282be52310e6bd33d9815", "title": "Highly accurate protein structure prediction with AlphaFold"}, {"paperId": "d8e375017de9fd2c875b6925cbd6c64519a9c558", "title": "MedGPT: Medical Concept Prediction from Clinical Narratives"}, {"paperId": "cb2a38002e2f346b084e7dd6c9fcf2bb45de5a9e", "title": "CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark"}, {"paperId": "896c76bf99de9c1ba6fc3dfb695dfa66e73e1eb3", "title": "Probing Pre-Trained Language Models for Disease Knowledge"}, {"paperId": "feba0c47bf12a02c3a725174bb53df78658a72a8", "title": "Pre-Trained Models: Past, Present and Future"}, {"paperId": "4a53a4ab7afa19c64a0721f4bcc3e643acfa681e", "title": "A GPT-2 Language Model for Biomedical Texts in Portuguese"}, {"paperId": "6003d268e9b5230dbc3e320497b50329d6186816", "title": "SciFive: a text-to-text transformer model for biomedical literature"}, {"paperId": "b58d8579ece27a60432e667bfbdb750590fa65d9", "title": "True Few-Shot Learning with Language Models"}, {"paperId": "54738ed18575f40e9ff3ad0181aaccc527fc4f95", "title": "Semi-Supervised Variational Reasoning for Medical Dialogue Generation"}, {"paperId": "1dd525b5af40e613ae1665cf15a193b5ef23431b", "title": "Improving BERT Model Using Contrastive Learning for Biomedical Relation Extraction"}, {"paperId": "a76c11fd3119c44520f7487b4141ff7e833bc5d0", "title": "Prediction of RNA\u2013protein interactions using a nucleotide language model"}, {"paperId": "58fe64beb45b18f63cbc001849a0dee3e4e60482", "title": "Improving Biomedical Pretrained Language Models with Knowledge"}, {"paperId": "4afa7d8e2de43b0b67366b1bce8768f5a246d153", "title": "Bayesian Optimization is Superior to Random Search for Machine Learning Hyperparameter Tuning: Analysis of the Black-Box Optimization Challenge 2020"}, {"paperId": "1991ea2ec85113cadf38faea840f4b5cf73ae0c7", "title": "ELECTRAMed: a new pre-trained language representation model for biomedical NLP"}, {"paperId": "4fe19d28d91fb42047ca4bc7602f647c007b32c2", "title": "Attention-based clinical note summarization"}, {"paperId": "420c897bc67e6f438db522d919d925df1a10aa8c", "title": "AMMU: A survey of transformer-based biomedical pretrained language models"}, {"paperId": "c464563311ded1ebe16cf68dc894f0d9c744d597", "title": "Sequence tagging for biomedical extractive question answering"}, {"paperId": "1d5c07e7415a7e9be078717197ddf9f3c70a2875", "title": "Does BERT Pretrained on Clinical Notes Reveal Sensitive Data?"}, {"paperId": "49a77a36a0a60d29aa7838ac49a055a69658b195", "title": "K-PLUG: Knowledge-injected Pre-trained Language Model for Natural Language Understanding and Generation in E-Commerce"}, {"paperId": "d25121da56c9050137800c69520111b30201d1ed", "title": "MS\u02c62: Multi-Document Summarization of Medical Studies"}, {"paperId": "a978fcb10817abe8bc91ab2ba0c0bb4605add1d9", "title": "Discourse Probing of Pretrained Language Models"}, {"paperId": "8994bce4b85a8b4087584661c49f8776f868f7dd", "title": "Interpretable Bias Mitigation for Textual Data: Reducing Genderization in Patient Notes While Maintaining Classification Performance"}, {"paperId": "beb6a2d33b1979d9d2010fc5721fd307e015c342", "title": "Bidirectional Representation Learning From Transformers Using Multimodal Electronic Health Record Data to Predict Depression"}, {"paperId": "c0e6cd2ec3bc9eb46c7d45bb708854da3327339e", "title": "A Survey on Bias in Deep NLP"}, {"paperId": "474c63c4238e830ae395cad69bb4533e69731ff3", "title": "Limitations of Transformers on Clinical Text Classification"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "60c4ea58eb7fccbf189837a94760b2605bb54dde", "title": "A Cooperative Memory Network for Personalized Task-oriented Dialogue Systems with Incomplete User Profiles"}, {"paperId": "deee48c5e0ac0407a1e002905caaf2b174bdb0e6", "title": "MSA Transformer"}, {"paperId": "89d0505974747c21d28309b26257bfe56c4eaeda", "title": "Unsupervised Extractive Summarization using Pointwise Mutual Information"}, {"paperId": "6f412cbe1bc515c8c9fb0d6cd2e96c58d18e7951", "title": "A pre-training and self-training approach for biomedical named entity recognition"}, {"paperId": "75f1c7dadb4ed733fb4d3a4cc47b9cbde9ad98cc", "title": "Combining pre-trained language models and structured knowledge"}, {"paperId": "feecf3e9ff390ccd0101e9c2590dea32bcb4070f", "title": "Transformer-Based Models for Question Answering on COVID19"}, {"paperId": "c375e121926db9551f224ff235018ea38bb159b7", "title": "BinaryBERT: Pushing the Limit of BERT Quantization"}, {"paperId": "5b4376a0b97a474a4e063768cc4faf20691b7887", "title": "Automated Lay Language Summarization of Biomedical Scientific Reviews"}, {"paperId": "2ad565fb0ce9cda15a9e5ce37b5678ec09b134b9", "title": "Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue Generation"}, {"paperId": "f9327f5b4493bea71833d0bf6c5d039f331c069e", "title": "Cross2Self-attentive Bidirectional Recurrent Neural Network with BERT for Biomedical Semantic Text Similarity"}, {"paperId": "c6ba01a86927c3abb891ed268353c14f9faa8097", "title": "End-to-End QA on COVID-19: Domain Adaptation with Synthetic Training"}, {"paperId": "9eaceb2b21876a39f948c6841deee2c2767fba2f", "title": "LBERT: Lexically-aware Transformers based Bidirectional Encoder Representation model for learning Universal Bio-Entity Relations"}, {"paperId": "c7c201d81538bf68ff373238597fd2991a0dca44", "title": "Profile Prediction: An Alignment-Based Pre-Training Task for Protein Sequence Models"}, {"paperId": "06af86469540794522169e80361aff89d6d9535e", "title": "Summarizing Medical Conversations via Identifying Important Utterances"}, {"paperId": "903ad24a5e924086869f6f9f0ae2992ae2971048", "title": "BioMedBERT: A Pre-trained Biomedical Language Model for QA and IR"}, {"paperId": "c7dd71e6a24acbd9174cefdc68fa23baf5abcab9", "title": "Experiments on transfer learning architectures for biomedical relation extraction"}, {"paperId": "70b0c85638d195dbde56cbedc94ae4363b272b58", "title": "A Pre-Training Technique to Localize Medical BERT and to Enhance Biomedical BERT"}, {"paperId": "a9f104cf0c1584d4d6df46d2e551fcdffa4e4b84", "title": "Medical Knowledge-enriched Textual Entailment Framework"}, {"paperId": "a79b520571f7373cbeb8c6ffc02f6a719b3bce38", "title": "CODER: Knowledge-infused cross-lingual medical term embedding for term normalization"}, {"paperId": "604959267cef4b1495df9b0bc03303c4f1b2f715", "title": "BioBERTpt - A Portuguese Neural Language Model for Clinical Named Entity Recognition"}, {"paperId": "76ad0d37bd3845431b3ca9d07f8db74c82752298", "title": "Pretrained Language Models for Biomedical and Clinical Tasks: Understanding and Extending the State-of-the-Art"}, {"paperId": "fefa0bd805beef371a1679a74a1b9f9f8a1baacd", "title": "FedED: Federated Learning via Ensemble Distillation for Medical Relation Extraction"}, {"paperId": "59da4f7d85967d922b5d674779ffcee06f186c73", "title": "Investigation of BERT Model on Biomedical Relation Extraction Based on Revised Fine-tuning Mechanism"}, {"paperId": "2fcee0b96353e81595325ff77c47bfdb82d03fff", "title": "Biomedical Event Extraction as Sequence Labeling"}, {"paperId": "24bdcb3d033f25f4dd593cc028ba32d18822c9ab", "title": "Biomedical Event Extraction as Multi-turn Question Answering"}, {"paperId": "2739deec362784909563db9411c4b9d9e62a1ed5", "title": "Modern Clinical Text Mining: A Guide and Review."}, {"paperId": "4b6da028739a126b0df08e9b5d4f01c288c210f3", "title": "A BERT-Based Named Entity Recognition in Chinese Electronic Medical Record"}, {"paperId": "b9868f59ed09866143261e43e7596d1c71326399", "title": "Clinical concept extraction using transformers"}, {"paperId": "03935e520c612ac9f137d9e9ef388e0c08568b60", "title": "UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus"}, {"paperId": "c7b5bed0141ed30f1aadbf4b2cba786679015835", "title": "MedDG: A Large-scale Medical Consultation Dataset for Building Medical Dialogue System"}, {"paperId": "6d6595766a35f12a6ad671d05634b5e2159d4f3e", "title": "Bio-Megatron: Larger Biomedical Domain Language Model"}, {"paperId": "9be1d1bf82f6ca6a7bf6a7d92f8f37b647e493d0", "title": "Probing Pretrained Language Models for Lexical Semantics"}, {"paperId": "e39a4b182c3bae017b08df20b37b9d1d97c9a4bf", "title": "Multi-Stage Pretraining for Low-Resource Domain Adaptation"}, {"paperId": "ef26dad0f2fa7c06c54c0b8c3fa1274354f7e6e5", "title": "Crosslingual named entity recognition for clinical de-identification applied to a COVID-19 Italian data set"}, {"paperId": "3b2664a15b46e95eecb9573f21c36892037b0264", "title": "Infusing Disease Knowledge into BERT for Health Question Answering, Medical Inference and Disease Name Recognition"}, {"paperId": "a2cde1da31a61adab24e702999680108ab58e5ff", "title": "COMETA: A Corpus for Medical Entity Linking in the Social Media"}, {"paperId": "697a19567dbb8f31c10b6b33b490b5522987f47d", "title": "Unsupervised Pre-training for Biomedical Question Answering"}, {"paperId": "097210dc65924f8ce59523faf444e635523dc714", "title": "TernaryBERT: Distillation-aware Ultra-low Bit BERT"}, {"paperId": "f2861a7c7155c50e2efab3bdec1a491a1b786b03", "title": "BioALBERT: A Simple and Effective Pre-trained Language Model for Biomedical Named Entity Recognition"}, {"paperId": "c43d9cade31600400a0f62beb5bbcc1b548e009e", "title": "DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "065c60b4a8f69bccfbbf9b0ac3b3615b984b51bd", "title": "Improving fine-tuned question answering models for electronic health records"}, {"paperId": "1cad933afc55f1a562e27ebd4f65c5d0f5a6c26a", "title": "Task-specific Objectives of Pre-trained Language Models for Dialogue Adaptation"}, {"paperId": "850f298337728fea2e19ad48975ddee89a34c088", "title": "Biomedical named entity recognition using BERT in the machine reading comprehension framework"}, {"paperId": "4535f00f4116082d93e35448048e116aa46e795d", "title": "Korean clinical entity recognition from diagnosis text using BERT"}, {"paperId": "44f02e037fd78116f921c8c57bc9ee3f7b2e64fd", "title": "Generating (Factual?) Narrative Summaries of RCTs: Experiments with Neural Multi-Document Summarization"}, {"paperId": "2b01b3334ce950c76c9c3c2c9146a7f0ce79cc50", "title": "Conceptualized Representation Learning for Chinese Biomedical Text Mining"}, {"paperId": "3d09912d7630b11dcb36af59eff64474ea281d80", "title": "The 2019 n2c2/OHNLP Track on Clinical Semantic Textual Similarity: Overview"}, {"paperId": "a2f38d03fd363e920494ad65a5f0ad8bd18cd60b", "title": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing"}, {"paperId": "eba8c42f158f0333b77c2c4c017e6a5fd47e806a", "title": "Ethics of Artificial Intelligence in Surgery"}, {"paperId": "7c462df4adefcf90af3c27ce7f7a8d83efbff2b0", "title": "Measurement of Semantic Textual Similarity in Clinical Texts: Comparison of Transformer-Based Models"}, {"paperId": "b01b962620a1627dbdd0d202eda9e7185fa8f2e0", "title": "Highly accurate classification of chest radiographic reports using a deep learning natural language model pre-trained on 3.8 million text reports"}, {"paperId": "ca9b4fc03ad3ea4680ab2204ecf215f333c616a4", "title": "ProtTrans: Towards Cracking the Language of Life\u2019s Code Through Self-Supervised Deep Learning and High Performance Computing"}, {"paperId": "18b0f8b819e15a6a91b3f6c0555209fd507630a3", "title": "A clinical specific BERT developed with huge size of Japanese clinical narrative"}, {"paperId": "790dd0db272b948806432db374b6d89717b54838", "title": "Biomedical-domain pre-trained language model for extractive summarization"}, {"paperId": "dc7975f6a57bc5991dd5145be490445425c593c4", "title": "A BERT-based One-Pass Multi-Task Model for Clinical Temporal Relation Extraction"}, {"paperId": "1a308d3793363f47eae2ca1429e3078a01bb5e26", "title": "MIE: A Medical Information Extractor towards Medical Dialogues"}, {"paperId": "c0091585ae4f9cccd4c1dba5aa7409c0886553fa", "title": "Transferability of Natural Language Inference to Biomedical Question Answering"}, {"paperId": "a562a6f14283f176a80a7254048db0efe0ee830c", "title": "Answering Questions on COVID-19 in Real-Time"}, {"paperId": "e23cb51f50f749320b9122fb5f75113b4d192c0a", "title": "Evaluation of Text Generation: A Survey"}, {"paperId": "2b364917b0c51e91fcf2ab9c1d66a14ed4b44c03", "title": "BERTology Meets Biology: Interpreting Attention in Protein Language Models"}, {"paperId": "4cd1eacb7d0e3657ac01a4f687638832546cd072", "title": "DeepEventMine: end-to-end neural nested event extraction from biomedical texts"}, {"paperId": "27f0246890395d743252fd93282544c7efdec443", "title": "CO-Search: COVID-19 Information Retrieval with Semantic Search, Question Answering, and Abstractive Summarization"}, {"paperId": "7a23a2948fa3a9d48e3c3bd071b522f417e59955", "title": "Results of the Seventh Edition of the BioASQ Challenge"}, {"paperId": "85bb1317013141d5e5f41d18376cd7257c46264a", "title": "Document Classification for COVID-19 Literature"}, {"paperId": "8b9d77d5e52a70af37451d3db3d32781b83ea054", "title": "On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines"}, {"paperId": "762baed866a8f23e19ea52f265c9ba7f353896ce", "title": "Automatic Text Summarization of COVID-19 Medical Research Articles using BERT and GPT-2"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "d47a682723f710395454687319bb55635e653105", "title": "Language (Technology) is Power: A Critical Survey of \u201cBias\u201d in NLP"}, {"paperId": "5b0b876a815f8a07876052c03c4a733d595f72fb", "title": "On the effectiveness of small, discriminatively pre-trained language representation models for biomedical text mining"}, {"paperId": "5d4de0fa45aeddc31142e6a24666d06ed7923f1e", "title": "Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction"}, {"paperId": "126fb7df6bcab2b70000dfe5b940ada63ae1ba6a", "title": "COVID-Twitter-BERT: A natural language processing model to analyse COVID-19 content on Twitter"}, {"paperId": "18629f4edead8bcf07e5ef694914ba83dd1e9666", "title": "Entity-Enriched Neural Models for Clinical Question Answering"}, {"paperId": "57fd722e2bbfffdb5b36a12ded59a303dbad95c5", "title": "On the Generation of Medical Dialogues for COVID-19"}, {"paperId": "8500552bb21127e6957f2b6fa1cede0b918000a1", "title": "Comparative Analysis of Text Classification Approaches in Electronic Health Records"}, {"paperId": "1d77bf9273392156b309b7ed871449776f9a1618", "title": "CAiRE-COVID: A Question Answering and Query-focused Multi-Document Summarization System for COVID-19 Scholarly Information Management"}, {"paperId": "016760dc4a05489ddf5dbb48aecbb49e214e1b71", "title": "Birds Have Four Legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-trained Language Models"}, {"paperId": "cebf0335d051b95a1810c0dd237b8bd5a36346a0", "title": "Evaluation of Dataset Selection for Pre-Training and Fine-Tuning Transformer Language Models for Clinical Question Answering"}, {"paperId": "4c3b5f8db4f44ed4d24e15227a0da30f7c20a665", "title": "Attend to Medical Ontologies: Content Selection for Clinical Abstractive Summarization"}, {"paperId": "3aaa8aaad5ef36550a6b47d6ee000f0b346a5a1f", "title": "Perturbed Masking: Parameter-free Probing for Analyzing and Interpreting BERT"}, {"paperId": "e0fe2936aa9c5142b75a382f29d3398f4b810c73", "title": "Towards Chinese clinical named entity recognition by dynamic embedding using domain-specific knowledge"}, {"paperId": "e014af8ae8d7dbd3c1c908dfba334a6d2181b8e1", "title": "Task-oriented Dialogue System for Automatic Disease Diagnosis via Hierarchical Reinforcement Learning"}, {"paperId": "636e89ca198156cd8b7a799f460004da7eb4c3ad", "title": "Chinese clinical named entity recognition with variant neural structures based on BERT methods"}, {"paperId": "e816f788767eec6a8ef0ea9eddd0e902435d4271", "title": "Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks"}, {"paperId": "0f995b05821b58b02e914422b56fba615d0e8d7f", "title": "Rapidly Bootstrapping a Question Answering Dataset for COVID-19"}, {"paperId": "bc411487f305e451d7485e53202ec241fcc97d3b", "title": "CORD-19: The Covid-19 Open Research Dataset"}, {"paperId": "dbcea4cfd482a0b7b366077d75b858ef38f37f8f", "title": "Robustly Pre-Trained Neural Model for Direct Temporal Relation Extraction"}, {"paperId": "9afed5a68ec147ddf221c9ae6c7ff8f0ceef2ef8", "title": "The Russian Drug Reaction Corpus and Neural Models for Drug Reactions and Effectiveness Detection in User Reviews"}, {"paperId": "5e52f3b7fd14f151b26309e9f06239ddcd99b39a", "title": "MedDialog: A Large-scale Medical Dialogue Dataset"}, {"paperId": "25a49187e0d1e3ebebda71c7e77f31bc49358044", "title": "Inexpensive Domain Adaptation of Pretrained Language Models: Case Studies on Biomedical NER and Covid-19 QA"}, {"paperId": "c2d80269e20ba8fa41fe49313253faf3f18c48a6", "title": "Generative Adversarial Regularized Mutual Information Policy Gradient Framework for Automatic Diagnosis"}, {"paperId": "6c62f9617830d2b5246a05a1a5d3664660dc7985", "title": "Understanding Medical Conversations with Scattered Keyword Attention and Weak Supervision from Responses"}, {"paperId": "e1b188b33a8ddc314679551a74bb561bef30af06", "title": "Named Entity Recognition in Spanish Biomedical Literature: Short Review and Bert Model"}, {"paperId": "b2fd96a52ded7a64f60c1e54f5bb488c787629c0", "title": "What Happens To BERT Embeddings During Fine-tuning?"}, {"paperId": "1c332cfa211400fc6f56983fb01a6692046116dd", "title": "DynaBERT: Dynamic BERT with Adaptive Width and Depth"}, {"paperId": "e06f6d79b57ddf9e8fecc0b24a8e3045ea66ad9a", "title": "On Biomedical Named Entity Recognition: Experiments in Interlingual Transfer for Clinical and Social Media Texts"}, {"paperId": "3bcb17559ce96eb20fa79af8194f4af0380d194a", "title": "Pre-trained models for natural language processing: A survey"}, {"paperId": "e092ecf56fcca38d0cd6fe9e1e6b11c380f6c286", "title": "A Survey on Contextual Embeddings"}, {"paperId": "d505eb794676927e919bcfeafdd1680a4bf10229", "title": "Hurtful words: quantifying biases in clinical contextual word embeddings"}, {"paperId": "c5f7074a264356c9a022a8dff24df79d1db8c3d3", "title": "ProGen: Language Modeling for Protein Generation"}, {"paperId": "0134bdb3cce9f9d5784adb40438a366a0e1f0ffd", "title": "Pre-trained language model augmented adversarial training network for Chinese clinical event detection."}, {"paperId": "0fe2636446cd686830da3d971b31a004d6094b3c", "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages"}, {"paperId": "f57954e72bf805b0717a0fc5b59156ac58f51648", "title": "Deep Scaled Dot-Product Attention Based Domain Adaptation Model For Biomedical Question Answering."}, {"paperId": "616e0f73229c118e1e50a1d9e868a198915cecd8", "title": "Testing Contextualized Word Embeddings to Improve NER in Spanish Clinical Case Narratives"}, {"paperId": "1359d2ef45f1550941e22bf046026c89f6edf315", "title": "AraBERT: Transformer-based Model for Arabic Language Understanding"}, {"paperId": "dc5da5ac3aff86e4b0156c52d9641d05dc1eeace", "title": "MT-BioNER: Multi-task Learning for Biomedical Named Entity Recognition using Deep Bidirectional Transformers"}, {"paperId": "28263e06835ae078fed27faffc82986f32e3070e", "title": "Deep learning for electronic health records: A comparative review of multiple deep neural architectures"}, {"paperId": "4c72d6e102408889a6b3179d08b55b75a115bb90", "title": "Document-Level Biomedical Relation Extraction Leveraging Pretrained Self-Attention Structure and Entity Replacement: Algorithm and Pretreatment Method Validation Study"}, {"paperId": "42f0bae2dacba44e9b5d8f050da3cbe41b9fc437", "title": "Clinical XLNet: Modeling Sequential Clinical Notes and Predicting Prolonged Mechanical Ventilation"}, {"paperId": "d0e28f5dc1feae19e41087a92a87992977fd85af", "title": "Encoding word order in complex embeddings"}, {"paperId": "697aa112f629718e3975217f91cf893f4727ea96", "title": "Self-Supervised Contextual Language Representation of Radiology Reports to Improve the Identification of Communication Urgency"}, {"paperId": "a2d2a482ccd62a705c8fafeb5f93bca33a4d796d", "title": "Deep learning in clinical natural language processing: a methodical review"}, {"paperId": "797a9b822bc5159e93108a434fd28d4cb2635879", "title": "A survey of word embeddings for clinical text"}, {"paperId": "0cd8ab37c3f6e3ec1e570dcb2f73fc0bc3a4f541", "title": "Modeling aspects of the language of life through transfer-learning protein sequences"}, {"paperId": "3f55c542de1e5a19e33cba481dd5460b2a92a266", "title": "ConveRT: Efficient and Accurate Conversational Representations from Transformers"}, {"paperId": "388e2fcdcefbe0834e153ab2a0be127092f9674d", "title": "DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation"}, {"paperId": "953ad57d381b866dcb16890bd1a568729bc6b7ca", "title": "PharmaCoNER: Pharmacological Substances, Compounds and proteins Named Entity Recognition track"}, {"paperId": "9c800a101fdbc95d76494e74cfec4f533bc1adab", "title": "Enhancing Dialogue Symptom Diagnosis with Global Attention and Symptom Graph"}, {"paperId": "20b847537d3b7b9661733c1770c5faab3c0e2215", "title": "Biomedical Named Entity Recognition with Multilingual BERT"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "fa5eeae07c683533c907d3417eb098084a994456", "title": "Critical assessment of methods of protein structure prediction (CASP)\u2014Round XIII"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "bd01b18df9a39cdd5c66f44051d62f176e9c8e7e", "title": "A BERT-BiLSTM-CRF Model for Chinese Electronic Medical Records Named Entity Recognition"}, {"paperId": "63de7c5f4bbdfffb54ebcdbee3ba0fc289e3d29b", "title": "Named Entity Recognition Using BERT BiLSTM CRF for Chinese Electronic Health Records"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "a9885472e5c40ca4045a229ced1cc439a431387e", "title": "Biomedical relation extraction with pre-trained language representations and minimal task-specific architecture"}, {"paperId": "23c26e6ed3de8ec90fbffb3f4c90f8d24432682a", "title": "End-to-end Named Entity Recognition and Relation Extraction using Pre-trained Language Models"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "4267112ddb9959252cf25bb4b7692858434393a7", "title": "Representation Learning for Electronic Health Records"}, {"paperId": "1f4ab7875649852babc851090fc8e0ce73d0e323", "title": "How to Pre-Train Your Model? Comparison of Different Pre-Training Models for Biomedical Question Answering"}, {"paperId": "1a00229c25dcc740fd0388ac1e98c42eaa52912e", "title": "Pre-trained Language Model for Biomedical Question Answering"}, {"paperId": "c33b69855e03958f1d9d3cff7abd2eb2184ecd52", "title": "Fine-Tuning Bidirectional Encoder Representations From Transformers (BERT)\u2013Based Models on Large-Scale Electronic Health Record Notes: An Empirical Study"}, {"paperId": "fac2368c2ec81ef82fd168d49a0def2f8d1ec7d8", "title": "Entity, Relation, and Event Extraction with Contextualized Span Representations"}, {"paperId": "16dc153aaeef8f8e62bd7010f9ab2032ba671a11", "title": "Deep learning with sentence embeddings pre-trained on biomedical corpora improves the performance of finding similar sentences in electronic medical records"}, {"paperId": "5b1aac9b91e626d6da47600ae8b1eab2a48707c9", "title": "Evaluation of Five Sentence Similarity Models on Electronic Medical Records"}, {"paperId": "d0086b86103a620a86bc918746df0aa642e2a8a3", "title": "Language Models as Knowledge Bases?"}, {"paperId": "0c3c4c88c7b07596221ac640c7b7102686e3eae3", "title": "PubMedQA: A Dataset for Biomedical Research Question Answering"}, {"paperId": "d97b04b3399b404581c5caa9e96331413cb432dc", "title": "Incorporating Domain Knowledge into Medical NLI using Knowledge Graphs"}, {"paperId": "ac1869e5648e4e6d68dd2b7632079107b49d316b", "title": "Learning to Infer Entities, Properties and their Relations from Clinical Conversations"}, {"paperId": "0090023afc66cd2741568599057f4e82b566137c", "title": "A Survey on Bias and Fairness in Machine Learning"}, {"paperId": "49bdeb07b045dd77f0bfe2b44436608770235a23", "title": "Federated Learning: Challenges, Methods, and Future Directions"}, {"paperId": "be16e643ed6cead716df162c4ac0806a2cdf52b0", "title": "Fine-tuning BERT for Joint Entity and Relation Extraction in Chinese Medical Text"}, {"paperId": "5c456e1cbc2756f790023e26632aa44427385b9d", "title": "An Effective Domain Adaptive Post-Training Method for BERT in Response Selection"}, {"paperId": "7ee67d8b002c111d21a3ec204d531476464924c4", "title": "BioFLAIR: Pretrained Pooled Contextualized Embeddings for Biomedical Sequence Labeling Tasks"}, {"paperId": "27ef74894b08899684909b5746beb1bf5b5a99d8", "title": "Clustering of Deep Contextualized Representations for Summarization of Biomedical Texts"}, {"paperId": "e66e64066606b17f6513a2c1ca4cb249c9c95489", "title": "Overview of the MEDIQA 2019 Shared Task on Textual Inference, Question Entailment and Question Answering"}, {"paperId": "1dd4f07cd25f29464cfd8b0a94d089e37265ebe2", "title": "BioBERT Based Named Entity Recognition in Electronic Medical Record"}, {"paperId": "79313c298988d2f3b3c68004bedbf4754c8a1605", "title": "DUT-NLP at MEDIQA 2019: An Adversarial Multi-Task Network to Jointly Model Recognizing Question Entailment and Question Answering"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "57633ff5c6f0708be25e651f51eef29d2fbfe48b", "title": "BEHRT: Transformer for Electronic Health Records"}, {"paperId": "493fac37cea49afb98c52c2f5dd75c303a325b25", "title": "Mitigating Gender Bias in Natural Language Processing: Literature Review"}, {"paperId": "ec7c9b201fc1ce18b4e0131691c9418f519a71c5", "title": "Evaluating Protein Transfer Learning with TAPE"}, {"paperId": "2ff41a463a374b138bb5a012e5a32bc4beefec20", "title": "Pre-Training with Whole Word Masking for Chinese BERT"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "1b7942148cba547a56013ccc6e292cdeb008be71", "title": "SEntNet: Source-aware Recurrent Entity Network for Dialogue Response Selection"}, {"paperId": "347bac45298f37cd83c3e79d99b826dc65a70c46", "title": "Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets"}, {"paperId": "9929e732e938c9be0a4e431c7cb785ac03938ff6", "title": "Extracting Symptoms and their Status from Clinical Conversations"}, {"paperId": "c3229debfda1b015c88404cf98f1074237d80809", "title": "Pre-training of Graph Augmented Transformers for Medication Recommendation"}, {"paperId": "a022bda79947d1f656a1164003c1b3ae9a843df9", "title": "How to Fine-Tune BERT for Text Classification?"}, {"paperId": "637514b892ac71c7c1379d3e9d0217e6f53a7d3c", "title": "Classification of Traditional Chinese Medicine Cases based on Character-level Bert and Deep Learning"}, {"paperId": "18a93dc1558bf9d7534d0b416633cebaf75c1145", "title": "Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences"}, {"paperId": "5ffa8e4778c430412d804bf53c3ee9e77f0dacea", "title": "Modeling the language of life \u2013 Deep Learning Protein Sequences"}, {"paperId": "b3c2c9f53ab130f3eb76eaaab3afa481c5a405eb", "title": "ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission"}, {"paperId": "2a567ebd78939d0861d788f0fedff8d40ae62bf2", "title": "Publicly Available Clinical BERT Embeddings"}, {"paperId": "5df0b8b80aecda1efdebac5d1ab7bcf94a88c68f", "title": "Probing Biomedical Embeddings from Language Models"}, {"paperId": "79af328616d2440c77449d038f72d053c64d8f1f", "title": "Unified rational protein engineering with sequence-only deep representation learning"}, {"paperId": "db9ff3080be1acac2f403d0c79c9ec776a3d3b5f", "title": "SECNLP: A Survey of Embeddings in Clinical Natural Language Processing"}, {"paperId": "156d217b0a911af97fa1b5a71dc909ccef7a8028", "title": "SciBERT: A Pretrained Language Model for Scientific Text"}, {"paperId": "06b36e744dca445863c9f9aefe76aea95ba95999", "title": "Enhancing Clinical Concept Extraction with Contextual Embedding"}, {"paperId": "3637fcccc758786ae1c6529ab22fe85ea98e9c36", "title": "Learning protein sequence embeddings using information from structure"}, {"paperId": "e14fdf566f9fe9e605e047e8688c75ad4277bc17", "title": "End-to-End Knowledge-Routed Relational Dialogue System for Automatic Diagnosis"}, {"paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"}, {"paperId": "66617d894e4cefc86efbf9ab984caada733f549e", "title": "A general approach for improving deep learning-based medical relation extraction using a pre-trained model and fine-tuning"}, {"paperId": "889ad3c713bd7f1b3a8e9b07e136ec4a88651893", "title": "Multi-Scale Attentive Interaction Networks for Chinese Medical Question Answer Selection"}, {"paperId": "e9aba084dc100209bfc6ca2433d6cadb75fa44df", "title": "CAS: French Corpus with Clinical Cases"}, {"paperId": "fc33b11d0cbc6ec891aa5faa88e471bfa3dee361", "title": "Clinical Concept Extraction with Contextual Word Embedding"}, {"paperId": "5dc8f1af682c4a148bfa0a08d07f5a30f0de2217", "title": "BioSentVec: creating sentence embeddings for biomedical texts"}, {"paperId": "f8b901c330e7f946ef93453b24682f294b8764a1", "title": "In-domain Context-aware Token Embeddings Improve Biomedical Named Entity Recognition"}, {"paperId": "6cbdeb96380e028fb204f9802694e77bb772ed60", "title": "emrQA: A Large Corpus for Question Answering on Electronic Medical Records"}, {"paperId": "7304afb491930d520e194f4ca8b91a9652f0e658", "title": "MedSTS: a resource for clinical semantic textual similarity"}, {"paperId": "f2588de5173fb047192dbb93d62ce6636bdf46bd", "title": "Lessons from Natural Language Inference in the Clinical Domain"}, {"paperId": "1abcc5349eeec3608f87caa32fcdb9baa24a3265", "title": "Conversational agents in healthcare: a systematic review"}, {"paperId": "3b821dbfa024027d8c009d8854c958c0e470837a", "title": "Task-oriented Dialogue System for Automatic Diagnosis"}, {"paperId": "0a78873e41615798d09391d9f40d41666b8c9beb", "title": "A Corpus with Multi-Level Annotations of Patients, Interventions and Outcomes to Support Language Processing for Medical Literature"}, {"paperId": "7d4a2515e9239ab03339a92075802f07461e8084", "title": "Crowdbreaks: Tracking Health Trends Using Public Social Media Data and Crowdsourcing"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "cd36768795c696c990ff5c89be8d8b3b205858bd", "title": "CliCR: a Dataset of Clinical Case Reports for Machine Reading Comprehension"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "9223c95f0e600aee2dcf476094a5102adc386e0f", "title": "Effective Use of Bidirectional Language Modeling for Transfer Learning in Biomedical Named Entity Recognition"}, {"paperId": "20de699c041ffc9e242cfdb03d4938ec5f849785", "title": "Capturing the Patient\u2019s Perspective: a Review of Advances in Natural Language Processing of Health-Related Text"}, {"paperId": "aa4148c4c5735fb7f5008a71f7ed5cf4d8eeebab", "title": "BioCreative VI Precision Medicine Track: creating a training corpus for mining protein-protein interactions affected by mutations"}, {"paperId": "135bafc83e9a73c88e759f98a28edfdb5c02f81d", "title": "Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints"}, {"paperId": "e8808581cda898f83dadcc79403064a584ac8bd0", "title": "MatchZoo: A Toolkit for Deep Text Matching"}, {"paperId": "d01450f9f0f7603e599f4e3ed4aa3eee1468af84", "title": "BIOSSES: a semantic sentence similarity estimation system for the biomedical domain"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "61322ec6cfc54fe9723d4637239b8fb9938dc501", "title": "BioCreative V CDR task corpus: a resource for chemical disease relation extraction"}, {"paperId": "95cd83603a0d2b6918a8e34a5637a8f382da96f5", "title": "MIMIC-III, a freely accessible critical care database"}, {"paperId": "995bbef8ff7bbbb7d994e3bfeed1ac169356db5f", "title": "Survey of Natural Language Processing Techniques in Bioinformatics"}, {"paperId": "1bd9760237b03f4995f5e205e18d3d7e7ccf5f87", "title": "Overview of the Cancer Genetics and Pathway Curation tasks of BioNLP Shared Task 2013"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "c657ab339517fb8def7ce7f83bb81e746d558218", "title": "Data Resource Profile: Clinical Practice Research Datalink (CPRD)"}, {"paperId": "d755a7e943009af26e0a5b617ef60c29c1d4f4e0", "title": "CHEMDNER: The drugs and chemical names extraction challenge"}, {"paperId": "be4e25eeef837f272aea6aaf1aa62bd108f1924c", "title": "Text summarization in the biomedical domain: A systematic review of recent research"}, {"paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5", "title": "GloVe: Global Vectors for Word Representation"}, {"paperId": "cfb4edb7541fafcf593b466320c63ae32d27f57e", "title": "Extraction of relations between genes and diseases from text and large-scale data analysis: implications for translational research"}, {"paperId": "696753d59185436ec95ecf3021c413f353be4874", "title": "NCBI disease corpus: A resource for disease name recognition and concept normalization"}, {"paperId": "6ea353ada2b89763f58d8068a74b2e6def526948", "title": "The DDI corpus: An annotated corpus with pharmacological substances and drug-drug interactions"}, {"paperId": "3598e8b4664477cb82b9887c78e4d178a2437f5c", "title": "The Genia Event Extraction Shared Task, 2013 Edition - Overview"}, {"paperId": "c83d05b15797ade0f8dffb9a311a859682d43a27", "title": "The SPECIES and ORGANISMS Resources for Fast and Accurate Identification of Taxonomic Names in Text"}, {"paperId": "8a867967998066584ed87a6adec7c68389d308f2", "title": "BioCause: Annotating and analysing causality in the biomedical domain"}, {"paperId": "f6b51c8753a871dc94ff32152c00c01e94f90f09", "title": "Efficient Estimation of Word Representations in Vector Space"}, {"paperId": "574aa45e8868844e31e047c8a9227a2cea706ed6", "title": "BioASQ: A Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering"}, {"paperId": "506c7e333efa0b31823c1b1914b1180c346773ee", "title": "The EU-ADR corpus: Annotated drugs, diseases, targets, and their relationships"}, {"paperId": "a8dff94485a16320e1ef980420bc74b2882babee", "title": "Event extraction across multiple levels of biological organization"}, {"paperId": "1470722bd776c4c5b1bc7a6cbcf9ff93c952461f", "title": "The hallmarks of cancer"}, {"paperId": "b33e9e49df030509be2a9063565e6e90d05c7c2d", "title": "A review of causal inference for biomedical informatics"}, {"paperId": "5e095981ebf4d389e9356bd56e59e0ade1b42e88", "title": "2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text"}, {"paperId": "b8472b394125768bb53615cc53cb2ef1ae38b112", "title": "Overview of the Infectious Diseases (ID) task of BioNLP Shared Task 2011"}, {"paperId": "88a38c33d2207524e3c42203f46c2fd2e77edd49", "title": "Overview of the Epigenetics and Post-translational Modifications (EPI) task of BioNLP Shared Task 2011"}, {"paperId": "00248a60f905f49c451e106ee6647823e9359e6c", "title": "Overview of Genia Event Task in BioNLP Shared Task 2011"}, {"paperId": "cd5a26b89f0799db1cbc1dff5607cb6815739fe7", "title": "A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning"}, {"paperId": "f2f6fb25311ada4afb830ec084e604a397b8a0e0", "title": "Event extraction for systems biology by text mining the literature."}, {"paperId": "e1039346942874c59d89028bb934b72524827b8c", "title": "LINNAEUS: A species name identification system for biomedical literature"}, {"paperId": "f5a0c6593ba95d23c025608ce9280848da8b929f", "title": "Overview of BioCreative II gene mention recognition"}, {"paperId": "a5a1e9ff53a230f6ede07ae9c75a5d9b84bda2e1", "title": "A survey and analysis of Electronic Healthcare Record standards"}, {"paperId": "acfc8d0d536e71cb7b3d2ae1364ee3fc6eb6b963", "title": "A survey of current work in biomedical text mining"}, {"paperId": "3bd4d2de49d8a092abb295b845dba14874f8787d", "title": "Introduction to the Bio-entity Recognition Task at JNLPBA"}, {"paperId": "e995078660f734127ba0e310c3e290ce29c554cb", "title": "Bioinformatics\u2014an introduction for computer scientists"}, {"paperId": "10f97f1fb4f5c2c8e6c44d4a33da46d331dd4aeb", "title": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition"}, {"paperId": "6c2b28f9354f667cd5bd07afc0471d8334430da7", "title": "A Neural Probabilistic Language Model"}, {"paperId": "84aae91c8f7a19e174c75f64e40ffe38b678eee9", "title": "Computational biology"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "2f00d047edd943d56389678c55175bbbf257cde0", "title": "Natural Language Processing in Medicine: An Overview"}, {"paperId": "752cefd84b78253a510b9b4530b6eb963824ec9b", "title": "A large\u2010scale experiment to assess protein structure prediction methods"}, {"paperId": "36e091c47b2330acf77f16205ad0d599cb190e82", "title": "Principles that govern the folding of protein chains."}, {"paperId": "dc35daba3fb34b2e6a5b12530badb7b799262bbf", "title": "On Position Embeddings in BERT"}, {"paperId": "50920f95cee87913dea19656e83ae06b51f9ba4a", "title": "Discovering Better Model Architectures for Medical Query Understanding"}, {"paperId": "19164116fed967ca4dfd0905221f8c5f192a6999", "title": "Overview of the MEDIQA 2021 Shared Task on Summarization in the Medical Domain"}, {"paperId": "30037743378708483e028896edef084b5b2f990d", "title": "Pre-trained language models to extract information from radiological reports"}, {"paperId": "5322e5936e4a46195b1a92001467a2350fe72782", "title": "KART: Privacy Leakage Framework of Language Models Pre-trained with Clinical Records"}, {"paperId": "1636928dc20917834a1824ec2cccd4232a11bc3f", "title": "ABioNER: A BERT-Based Model for Arabic Biomedical Named-Entity Recognition"}, {"paperId": "5134bc9d01cba38b18387e921872cc8d5cd9ae37", "title": "M 2 -MedDialog: A Dataset and Benchmarks for Multi-domain Multi-service Medical Dialogues"}, {"paperId": "4ab55fd59a5dc012e512925afdd78233280c54ff", "title": "Benchmarking of Transformer-Based Pre-Trained Models on Social Media Text Classification Datasets"}, {"paperId": "2fc12f2f3378e0aeab24df396f78ee8b59956973", "title": "Contextualized French Language Models for Biomedical Named Entity Recognition"}, {"paperId": "18396dd27d5b455d5fd062a1d0b7066a398bb8e4", "title": "Named Entity Recognition, Concept Normalization and Clinical Coding: Overview of the Cantemist Track for Cancer Text Mining in Spanish, Corpus, Guidelines, Methods and Results"}, {"paperId": "89a1c2f9b79db889b372041025a2b2f095a59bcd", "title": "Transfer Learning for Biomedical Question Answering"}, {"paperId": null, "title": "Electra: pre-training text encoders as discriminators rather than generators"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "a792d9c05008e56142acae588a9018ff9b3ba7a9", "title": "Relation Extraction from Clinical Narratives Using Pre-trained Language Models"}, {"paperId": "afc317b098cd6744611049ff16f351032ab14f83", "title": "A BERT-based Universal Model for Both Within- and Cross-sentence Clinical Temporal Relation Extraction"}, {"paperId": null, "title": "Federated machine learning: concept and applications"}, {"paperId": null, "title": "Proceedings of the 5th workshop on bionlp open shared tasks"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "f84fc762a3229f436f2a472bd90ef5070b5d31fb", "title": "Clinical information extraction applications: A literature review"}, {"paperId": null, "title": "Mining electronic health records (ehrs) a survey"}, {"paperId": null, "title": "The mythos of model interpretability: in machine learning, the concept of interpretability is both important and slippery"}, {"paperId": "eed781f498b563df5a9e8a241c67d63dd1d92ad5", "title": "Overview of the BioCreative VI chemical-protein interaction Track"}, {"paperId": "f697762b2b8cdf6df65e9246b96db4c4824ded5b", "title": "Recognizing Question Entailment for Medical Question Answering"}, {"paperId": "1f1eaf19e38b541eec8a02f099e3090536a4c936", "title": "The Unified Medical Language System (UMLS): integrating biomedical terminology"}]}