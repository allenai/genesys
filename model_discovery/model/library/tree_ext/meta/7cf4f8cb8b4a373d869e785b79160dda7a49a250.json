{"paperId": "7cf4f8cb8b4a373d869e785b79160dda7a49a250", "title": "Exploring The Landscape of Distributional Robustness for Question Answering Models", "abstract": "We conduct a large empirical evaluation to investigate the landscape of distributional robustness in question answering. Our investigation spans over 350 models and 16 question answering datasets, including a diverse set of architectures, model sizes, and adaptation methods (e.g., fine-tuning, adapter tuning, in-context learning, etc.). We find that, in many cases, model variations do not affect robustness and in-distribution performance alone determines out-of-distribution performance. Moreover, our findings indicate that i) zero-shot and in-context learning methods are more robust to distribution shifts than fully fine-tuned models; ii) few-shot prompt fine-tuned models exhibit better robustness than few-shot fine-tuned span prediction models; iii) parameter-efficient and robustness enhancing training methods provide no significant robustness improvements. In addition, we publicly release all evaluations to encourage researchers to further analyze robustness trends for question answering models.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2022, "citationCount": 13, "influentialCitationCount": 1, "openAccessPdf": {"url": "http://arxiv.org/pdf/2210.12517", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This investigation spans over 350 models and 16 question answering datasets, including a diverse set of architectures, model sizes, and adaptation methods, and indicates that zero-shot and in-context learning methods are more robust to distribution shifts than fully fine-tuned models."}, "embedding": {"model": "specter_v2", "vector": [-0.05952613800764084, 0.6031413078308105, -0.5503753423690796, -0.4052217900753021, -0.5283318758010864, -0.39157795906066895, 0.6599422693252563, -0.3296043574810028, -0.5868764519691467, -0.2351369857788086, 0.5348458290100098, 0.09570476412773132, 0.10720430314540863, 0.18287481367588043, -0.21231015026569366, 0.778518795967102, -0.2539025843143463, 0.6012123823165894, 0.39678213000297546, -0.7085002064704895, -0.3744993209838867, -0.9012395739555359, -1.1396043300628662, 0.2568795382976532, 0.5613459348678589, 0.6328210234642029, -0.24588866531848907, 1.2285525798797607, -0.41816195845603943, 0.17941312491893768, 0.3222319185733795, -0.37614646553993225, 0.14233335852622986, -0.06265727430582047, -0.15316912531852722, -0.051464520394802094, 0.6863621473312378, -0.3236410915851593, -0.4062299132347107, 0.36632993817329407, 0.25714313983917236, 0.43158239126205444, 0.634267270565033, -0.397769957780838, -0.9288510680198669, 0.39795219898223877, 0.7183310985565186, 0.6340472102165222, 0.2940949499607086, -0.4316421449184418, 1.075961709022522, -1.3026013374328613, 0.20254985988140106, 1.5752534866333008, 0.47024673223495483, 0.6997435688972473, -0.3006936013698578, -0.3524756133556366, 0.40198755264282227, -0.031906384974718094, -0.5548568367958069, -0.5800727009773254, -0.09918957948684692, -0.05351743474602699, 1.2166601419448853, -0.23889775574207306, -0.7207900881767273, 0.31601372361183167, -0.2425479292869568, 1.0916345119476318, -0.21485242247581482, -0.9870796799659729, -0.08273914456367493, 0.15333291888237, 0.4562857449054718, 0.6358162760734558, -0.6017318367958069, -0.12380906939506531, -0.6731513738632202, -0.291716992855072, 0.1299755871295929, -0.21201051771640778, -0.32355618476867676, -0.08366876095533371, -0.34643006324768066, 0.5964515209197998, 0.49285978078842163, 0.7788090109825134, -0.14505887031555176, 0.46143507957458496, 0.43681779503822327, 0.6594740748405457, -0.2951586842536926, 0.5240955948829651, -0.5386226773262024, 0.3937303423881531, -0.7177737951278687, 0.38775789737701416, 0.45456552505493164, 1.0471880435943604, -0.2839134633541107, -0.4244532883167267, -1.208045244216919, 0.7294695377349854, 1.1367961168289185, -0.06926658004522324, 0.8259580135345459, -1.0621644258499146, 0.06917282193899155, -0.43801677227020264, 0.4749515652656555, -0.5489504337310791, -0.3361341655254364, 0.08092008531093597, -0.5194926261901855, -1.432578682899475, -0.10611534118652344, 0.27038469910621643, -0.6553866267204285, 0.9975298047065735, 0.06576038151979446, -0.4362945556640625, -0.3689998388290405, 0.5914362072944641, 0.7795165181159973, 0.24391940236091614, 0.47066378593444824, 0.08530766516923904, 1.1009485721588135, -0.7210617065429688, -0.5572347044944763, -0.7669982314109802, 0.8822113871574402, -0.5198383927345276, 1.164631724357605, -0.6681540012359619, -1.091199517250061, -1.1824653148651123, -0.7197957038879395, -0.2109495997428894, -0.3526498079299927, 0.09193262457847595, 0.45858004689216614, 0.6074703931808472, -0.9939268827438354, 0.2858436405658722, 0.08738040924072266, -0.7333515286445618, -0.1379532366991043, -0.20135515928268433, 0.11389543861150742, -1.0203436613082886, -1.1103023290634155, 0.26324334740638733, 0.020877065137028694, -0.9990686774253845, 0.06986695528030396, -0.5354491472244263, -1.0624154806137085, -0.22473978996276855, 0.5478005409240723, -0.9825006723403931, 1.6975152492523193, -0.5184177756309509, -1.2018624544143677, 0.5424582362174988, -0.37844982743263245, 0.37762850522994995, 0.4272928237915039, 0.07867822051048279, -0.8999652862548828, -0.31077447533607483, -0.30497074127197266, 0.9119948148727417, 0.5585476160049438, 0.05240019038319588, 0.376010537147522, 0.12588119506835938, -0.0221595149487257, -0.02644941210746765, -0.00961401779204607, 0.6045185923576355, -0.489095538854599, -0.1831570565700531, 0.6264421939849854, 0.5467467904090881, 0.3174106180667877, 0.16973794996738434, 0.15964946150779724, -1.349534034729004, 0.9844679236412048, 0.11538419127464294, 1.0828484296798706, -0.9831103086471558, -0.9762587547302246, -0.46562692523002625, -0.3415396809577942, -0.3178722560405731, -1.1340796947479248, 0.657045304775238, -0.10734312981367111, 0.5472933053970337, -0.34228551387786865, -1.2314481735229492, 0.5445460677146912, -0.320425808429718, -0.6079689264297485, -0.5384300351142883, 0.10164954513311386, 1.4410772323608398, -0.5478760004043579, 0.04522407427430153, -0.24459557235240936, -0.04463345929980278, -1.122432827949524, 1.2682911157608032, -1.2636553049087524, 0.311292827129364, 0.15576133131980896, 0.31490057706832886, -0.062291648238897324, -0.4233580231666565, -0.01938222162425518, -0.46550726890563965, 0.3516419529914856, 0.41540202498435974, -0.3657490015029907, 1.621503472328186, -0.36851951479911804, -0.16424113512039185, 0.08374114334583282, -0.19234202802181244, 0.24130257964134216, 0.4715428054332733, -0.2626706063747406, -0.8013066649436951, -0.06710925698280334, 0.6274127960205078, -0.6516652703285217, -0.254224568605423, 1.0174028873443604, 0.4524199962615967, -0.4592420756816864, 0.48756399750709534, 0.6544316411018372, -0.4956686496734619, 0.5873590707778931, 0.2938242554664612, 0.9601545929908752, 0.3566508889198303, 0.07407034933567047, -0.05416373163461685, 0.22330370545387268, -0.912993848323822, -0.5172860622406006, 0.44560861587524414, 0.027230216190218925, 1.0372138023376465, 0.17335455119609833, -0.4805503189563751, -0.3152725398540497, -0.3810208737850189, 0.7446970343589783, 2.2830755710601807, -0.20092934370040894, 0.19982703030109406, -0.6513614058494568, -0.7940077185630798, -0.256079763174057, 0.5166880488395691, -0.692075252532959, -0.19090811908245087, -0.2990375757217407, -0.7504920959472656, 0.664958655834198, -0.01958928070962429, 0.9451921582221985, -0.5031068921089172, -0.04336727410554886, -0.18962828814983368, -0.13687023520469666, -0.43536829948425293, -0.9403818845748901, -0.24521997570991516, -0.5081169009208679, -0.30949676036834717, -0.075230173766613, 0.08686637878417969, -0.2958969175815582, -0.23265205323696136, 1.521236777305603, -0.5157783031463623, 0.07774387300014496, 0.9595112800598145, 0.3705260455608368, -0.4851246178150177, -0.792881429195404, 0.45210832357406616, -0.02227986790239811, -0.45068061351776123, 0.4465000033378601, 0.487537682056427, -0.3849545121192932, 0.9151866436004639, -1.0697195529937744, -0.5158907175064087, 0.1413065493106842, -0.2961733639240265, 0.8084250092506409, -0.8342942595481873, 0.9044474363327026, -1.2654576301574707, 1.072044014930725, -0.694461464881897, -0.031173519790172577, 0.7260839939117432, -0.7610806822776794, -0.4800620973110199, 0.2737870514392853, -0.7796714305877686, -0.2864360511302948, -1.3485159873962402, 0.38287055492401123, -0.123186394572258, -0.30203309655189514, 0.12516745924949646, 0.051723334938287735, 0.4638196527957916, 0.8656182885169983, -0.08327122777700424, 0.6697449088096619, -0.07749496400356293, 0.868644118309021, -0.6566563248634338, 0.16514329612255096, 0.024171076714992523, -0.292328417301178, -0.2066916674375534, -0.4888627231121063, -0.5687450766563416, -0.6541385650634766, -0.3703877031803131, 0.22154094278812408, -0.47593238949775696, -0.0044313836842775345, -0.44690456986427307, -0.6136248111724854, -0.48228219151496887, -0.5403488874435425, -0.15265315771102905, -0.25368940830230713, -0.6451884508132935, -0.39140602946281433, -1.054580807685852, -0.8770542740821838, -0.21511976420879364, -0.3613034784793854, -0.5756245255470276, 0.5923685431480408, 0.25406211614608765, -0.7840971350669861, -0.43251845240592957, 0.5830453634262085, 0.06488832831382751, 1.1650182008743286, -0.7020805478096008, 0.9500313997268677, 0.005828368477523327, -0.16544698178768158, -0.6251576542854309, 0.12607528269290924, 0.31237056851387024, -0.1444156914949417, 0.25202202796936035, -1.0097856521606445, 0.044409554451704025, 0.1956939697265625, -0.5849703550338745, 0.14083552360534668, 0.1756201684474945, 0.7639819383621216, 0.0028488696552813053, -0.23178312182426453, 0.10268879681825638, 1.2689309120178223, -0.9736135005950928, -0.12240664660930634, 0.037077777087688446, 0.5124117136001587, 0.880875825881958, -0.15141597390174866, 0.34011396765708923, 0.7112744450569153, 0.4551856815814972, 0.07436108589172363, 0.48440566658973694, -0.44275081157684326, -0.8505461812019348, 0.4706387221813202, 1.3888990879058838, 0.8160437941551208, -0.39750680327415466, -0.9522812962532043, 0.516785204410553, -1.31526780128479, -0.5013778805732727, 0.5237465500831604, 0.9142919182777405, 0.3170897960662842, -0.8841562867164612, 0.05945092439651489, -0.5424469709396362, 0.21978247165679932, 0.28927525877952576, -0.6779628396034241, -0.38542667031288147, -0.12503911554813385, 0.039999257773160934, -0.14445972442626953, 0.21320201456546783, -0.18537673354148865, 0.025038735941052437, 14.566064834594727, 0.6865503191947937, 0.12499591708183289, 1.0450694561004639, 0.7576074600219727, 0.16426721215248108, -0.6687864661216736, -0.3099479079246521, -0.6130528450012207, 0.006809004116803408, 1.362571358680725, 0.38336023688316345, 0.41623467206954956, 0.11920012533664703, -0.1000082939863205, 0.23614384233951569, -0.6223268508911133, 0.32881808280944824, 0.7157474160194397, -0.9280091524124146, 0.3527587950229645, -0.31126654148101807, 0.8287041187286377, 0.6113674640655518, 1.0041379928588867, 1.2284115552902222, 0.197029247879982, -0.49498993158340454, 0.2037508338689804, 0.7802754044532776, 1.1189556121826172, 0.07511039078235626, 0.3541633188724518, 0.6039802432060242, -0.3044394254684448, -0.2609587609767914, -0.5589231848716736, -0.9352243542671204, 0.1765683889389038, -0.12385409325361252, -0.6892943382263184, -0.708351194858551, -0.14820392429828644, 0.06177878379821777, -0.21402114629745483, 0.22935011982917786, -0.09442393481731415, 0.8800116777420044, -0.16123296320438385, -0.03934665024280548, -0.15485669672489166, 0.8694933652877808, 0.25715896487236023, -0.08640259504318237, 0.14149974286556244, 0.004209845792502165, -0.013760058209300041, 0.3896128535270691, -1.1889533996582031, 0.35831284523010254, -0.40662524104118347, 0.1755618304014206, 0.011306929402053356, 0.5149828195571899, 0.9134547114372253, 0.335433691740036, -0.39520174264907837, 0.1687525510787964, 0.8051791787147522, 0.3814783990383148, -0.19125083088874817, 0.3427880108356476, 0.08592703938484192, 0.16633059084415436, -0.21141164004802704, 0.6847190856933594, -0.16456960141658783, -0.4771798253059387, -0.3399859070777893, -0.347531795501709, 0.7711697220802307, -0.9936599731445312, -1.385597586631775, 0.38695600628852844, -0.4580300450325012, -0.36750686168670654, 0.06799077242612839, -0.1907169669866562, -0.4462830722332001, 0.2801283597946167, -1.428389549255371, -0.8074172735214233, 0.13111211359500885, -0.34843721985816956, -0.2309357076883316, 0.06373706459999084, 1.3595517873764038, 0.04831300675868988, -0.33371269702911377, 0.43424758315086365, 0.35108840465545654, -0.497868150472641, 0.6701744198799133, -0.8092912435531616, 0.3968625068664551, -0.1491086632013321, -0.2971024513244629, 0.23323756456375122, 0.07226540893316269, 0.5431883335113525, -0.717547595500946, -0.4032820761203766, 0.6672061681747437, -1.226979374885559, -0.6258754730224609, -0.02545454353094101, -1.1247904300689697, 0.34593650698661804, 0.6704357266426086, -0.21910281479358673, 0.8286057114601135, 0.30906441807746887, -1.0192265510559082, -0.10679974406957626, -1.2738232612609863, 0.29506343603134155, 0.24657289683818817, -0.7221609950065613, -0.585224449634552, 0.07672158628702164, 0.8168362975120544, -0.7037950754165649, -0.5562011003494263, 0.06808807700872421, -0.0859646424651146, -0.12971897423267365, 0.5468544363975525, -0.5670751333236694, 0.5010702610015869, 0.5835601091384888, -0.6352711915969849, -0.4634120762348175, -0.10964463651180267, -0.7345024943351746, -0.21161296963691711, 0.3214365839958191, 0.8984983563423157, -0.5826605558395386, -0.007492066361010075, 1.5081068277359009, 0.2956126630306244, -0.3673267364501953, -0.6726700663566589, 0.017757635563611984, 0.43667760491371155, -0.3070503771305084, 0.5757817625999451, -0.13622520864009857, -0.35931912064552307, 0.3258732855319977, 0.9956820011138916, 0.4614475667476654, -0.35956594347953796, -0.7490283250808716, 0.6694763898849487, -0.18107885122299194, -0.3318347632884979, -0.7666036486625671, 0.12286312133073807, -1.5316895246505737, -0.22691196203231812, -1.0475165843963623, -0.004131389781832695, -0.9990264177322388, -0.601535439491272, -0.06647993624210358, -0.2064276486635208, -0.3539072275161743, 0.028043972328305244, -0.3253217935562134, -0.42210131883621216, -0.10946939885616302, -0.9474327564239502, 0.9008101224899292, 0.9437616467475891, -0.5822789669036865, 0.1727163940668106, 0.07087670266628265, -0.25454193353652954, 0.2884358763694763, 0.6853620409965515, -0.12888452410697937, -0.6666415333747864, -1.3139728307724, 0.2976951599121094, 0.016745856031775475, -0.11404956877231598, -0.6330081820487976, 0.482369989156723, 0.5720834732055664, -0.25739148259162903, 0.11433792859315872, 0.1894787698984146, -0.9691531658172607, -0.5358254909515381, -0.18258851766586304, -0.985182523727417, 0.4722609519958496, 0.27876144647598267, -0.23201684653759003, -0.33501943945884705, 0.4753309190273285, 0.11532177031040192, -0.8319478034973145, -0.48827773332595825, 0.5593287348747253, -0.1771511286497116, 0.6089643239974976, -0.1878088116645813, 0.22349904477596283, -1.1890029907226562, -0.7562016248703003, 0.05575349181890488, 0.4341331720352173, 0.14589524269104004, 0.7744991183280945, 0.12307081371545792, -1.2224186658859253, -0.00047159710084088147, 0.08368011564016342, 0.4810669422149658, -0.052992936223745346, 1.022452712059021, 0.46400660276412964, -0.20525886118412018, 0.3299546539783478, 0.5371323823928833, 0.09193490445613861, -0.40953943133354187, 0.27958011627197266, 0.7691141366958618, -0.3431139588356018, 0.7143251895904541, 1.2279417514801025, -0.4441719055175781, -1.8035684823989868, -0.18984995782375336, -1.0228551626205444, -0.2560634911060333, -0.36299484968185425, 0.5473934412002563, 0.3512650430202484, 0.04237380251288414, 0.17412236332893372, -0.11386608332395554, -0.0019486991222947836, 0.06329774111509323, -0.9191429018974304, 0.03179742395877838, -0.47010907530784607, -0.4808695316314697, 1.0155445337295532, 0.8785292506217957, -0.36051809787750244, -0.5326154828071594, -0.7352294921875, -0.08058181405067444, 0.1098213866353035, -0.41033968329429626, -0.8897778987884521, 0.024356985464692116, 0.4397151470184326, 0.370708703994751, 0.5078648924827576, 0.41027334332466125, 0.08922556787729263, 0.09479420632123947, 0.7095933556556702, -0.10247557610273361, -0.518335223197937, -0.35782763361930847, 1.1531238555908203, 1.5419732332229614, -1.3114378452301025, -0.18835949897766113, 0.2996567189693451, -0.5585651993751526, 0.7478330135345459, 0.7074258923530579, 0.22922730445861816, 1.0641244649887085, -0.9702286720275879, 0.3707297146320343, 0.26260069012641907, -1.3211873769760132, 0.21356351673603058, 1.0144233703613281, 0.8530632257461548, 1.1542292833328247, 0.48132312297821045, -0.10633676499128342, 0.7171420454978943, 0.025666072964668274, 0.1130606010556221, 0.5420143604278564, 0.11963122338056564, -0.5130865573883057, -0.008487784303724766, 0.06559503823518753, 0.725875735282898, -0.27949586510658264, -0.07487446069717407, -0.11795426905155182, 0.6114179491996765, 0.28243309259414673, 0.7544411420822144, 0.6052753329277039, 0.2665567696094513, 0.9804724454879761, 0.8007494211196899, 0.37438514828681946, -0.7973644733428955, -0.14285774528980255, -0.7901557087898254, -0.7675697207450867, -0.11917483061552048, -0.1915527582168579, -0.652769148349762, -0.05723237246274948, -0.051625367254018784, 0.30210912227630615, -0.09384756535291672, 0.3314346671104431, 0.7117977738380432, 1.1422227621078491, 0.1756584197282791, -0.3818539083003998, 0.06507313251495361, -0.7509501576423645, -1.6927491426467896, 0.4747920036315918, -0.3219014108181, -0.27537980675697327, -0.11039066314697266, -0.07573086023330688, -0.6247724294662476]}, "authors": [{"authorId": "2135149490", "name": "Anas Awadalla"}, {"authorId": "52193502", "name": "Mitchell Wortsman"}, {"authorId": "1387994137", "name": "Gabriel Ilharco"}, {"authorId": "48872685", "name": "Sewon Min"}, {"authorId": "2124977543", "name": "Ian H. Magnusson"}, {"authorId": "2548384", "name": "Hannaneh Hajishirzi"}, {"authorId": "152772922", "name": "Ludwig Schmidt"}], "references": [{"paperId": "a1762b22d9222c52ba607b28c09977d76f709ba8", "title": "Are Sample-Efficient NLP Models More Robust?"}, {"paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a", "title": "Emergent Abilities of Large Language Models"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "d257547d681f3a153f4bbf85f5955b5a0189e500", "title": "Combined Scaling for Zero-shot Transfer Learning"}, {"paperId": "17d7fd18123e12efbb9c255c8b986a5e84578b07", "title": "Time Waits for No One! Analysis and Challenges of Temporal Misalignment"}, {"paperId": "8331f4363d65235a8344e6a0c9b21fa3ab4c1d5e", "title": "Types of Out-of-Distribution Texts and How to Detect Them"}, {"paperId": "9289826beb6206eeaf500105f7329d6d5a495d8a", "title": "Robust fine-tuning of zero-shot models"}, {"paperId": "9c81394363178ce94b1eac111df4e3ad11bdb7c2", "title": "FewshotQA: A simple framework for few-shot learning of question answering tasks using pre-trained text-to-text models"}, {"paperId": "106cc848e51ad0938e73c1b3b2ebb90d4bdea143", "title": "Accuracy on the Line: on the Strong Correlation Between Out-of-Distribution and In-Distribution Generalization"}, {"paperId": "4b1db6ebbdfcfe8ef67c5db511b6ad169fcc8f7f", "title": "The Evolution of Out-of-Distribution Robustness Throughout Fine-Tuning"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "6aecc93c2d61da073b70dec19795172ca1ff3405", "title": "Counterfactual Invariance to Spurious Correlations: Why and How to Pass Stress Tests"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "7e5008713c404445dd8786753526f1a45b93de12", "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "9b54941de1e21826ecc28b32730ac3f69991ede4", "title": "Robustness Gym: Unifying the NLP Evaluation Landscape"}, {"paperId": "06047017f7a2b4dee6d8078786a21c8f67590a22", "title": "Few-Shot Question Answering by Pretraining Span Selection"}, {"paperId": "40848b41ed8c9c255ecd8a920006877691b52d03", "title": "WILDS: A Benchmark of in-the-Wild Distribution Shifts"}, {"paperId": "b88c11922cac84e5ea902f82d27ae21c3dda2e04", "title": "Better Fine-Tuning by Reducing Representational Collapse"}, {"paperId": "063f8b1ecf2394ca776ac61869734de9c1953808", "title": "AdapterHub: A Framework for Adapting Transformers"}, {"paperId": "04422085a52050516b9741e0fd1fda964b73dd53", "title": "An Empirical Study on Robustness to Spurious Correlations using Pre-trained Language Models"}, {"paperId": "e609165fac8e4923423f754fb82292a614395c92", "title": "Measuring Robustness to Natural Distribution Shifts in Image Classification"}, {"paperId": "02eaaf87f9cae34cca398fed146079e6eeb1f868", "title": "Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "33ec7eb2168e37e3007d1059aa96b9a63254b4da", "title": "Beyond Accuracy: Behavioral Testing of NLP Models with CheckList"}, {"paperId": "98ef0db84e62aef969629264c9de1f4d0013f3b9", "title": "AdapterFusion: Non-Destructive Task Composition for Transfer Learning"}, {"paperId": "2fe6759b0e9757df70ca3db1e1dd9bd1c5a5bda5", "title": "The Effect of Natural Distribution Shift on Question Answering Models"}, {"paperId": "97f08c1ae8ca5ddf5948c66bfbbc0546ac154807", "title": "Pretrained Transformers Improve Out-of-Distribution Robustness"}, {"paperId": "3f9514630194a9fba9505b594ec921b247fecb48", "title": "Evaluating Models\u2019 Local Decision Boundaries via Contrast Sets"}, {"paperId": "122b75042daae44f93153dedda15b0fb11b3f279", "title": "What Do Models Learn from Question Answering Datasets?"}, {"paperId": "58c143069444c7dff4be53531a47efefc40be497", "title": "On Adaptive Attacks to Adversarial Example Defenses"}, {"paperId": "baf60d13c98916b77b09bc525ede1cd610ed1db5", "title": "Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping"}, {"paperId": "ab70853cd5912c470f6ff95e95481980f0a2a41b", "title": "SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "acf5a74ccb14b01430dab2d200d9aabc5ee9dc16", "title": "MRQA 2019 Shared Task: Evaluating Generalization in Reading Comprehension"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "d01fa0311e8e15b8b874b376123530c815f52852", "title": "FreeLB: Enhanced Adversarial Training for Natural Language Understanding"}, {"paperId": "52fa450740913a6cdcb4d9395b45e203f46cab79", "title": "Giving BERT a Calculator: Finding Operations and Arguments with Reading Comprehension"}, {"paperId": "3caf34532597683c980134579b156cd0d7db2f40", "title": "Universal Adversarial Triggers for Attacking and Analyzing NLP"}, {"paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0", "title": "Natural Questions: A Benchmark for Question Answering Research"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "81f5810fbbab9b7203b9556f4ce3c741875407bc", "title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans"}, {"paperId": "636904d91d9dd1a641a595d9578ba7640f35aa74", "title": "MultiQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension"}, {"paperId": "d9f6ada77448664b71128bb19df15765336974a6", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"}, {"paperId": "dda6fb309f62e2557a071522354d8c2c897a2805", "title": "DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs"}, {"paperId": "4e0bb8c1c683b43357c5d5216f6b74ff2cb32434", "title": "Do ImageNet Classifiers Generalize to ImageNet?"}, {"paperId": "14475c32c703a0c2146a3ba39d16e435fcb6ee13", "title": "Towards a Robust Deep Neural Network in Texts: A Survey"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "19281b9ecdb5c07a93423a506627ab9d9b0cf039", "title": "Learning and Evaluating General Linguistic Intelligence"}, {"paperId": "b47381e04739ea3f392ba6c8faaf64105493c196", "title": "Sentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data Tasks"}, {"paperId": "22655979df781d222eaf812b0d325fa9adf11594", "title": "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering"}, {"paperId": "634c083444e11c89f30c93a2986cb43db35ca304", "title": "Trick Me If You Can: Human-in-the-Loop Generation of Adversarial Examples for Question Answering"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "a7bbb084f5de4f318c811776afeba2b05439c234", "title": "DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension"}, {"paperId": "2c20e7220269b28fb1935a83d0e7f2db330aa691", "title": "Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning"}, {"paperId": "ffb949d3493c3b2f3c9acf9c75cb03938933ddf0", "title": "Adversarial Examples for Evaluating Reading Comprehension Systems"}, {"paperId": "c071a1ad68310fed7f0876b6f01cb7b135043bc3", "title": "Are You Smarter Than a Sixth Grader? Textbook Question Answering for Multimodal Machine Comprehension"}, {"paperId": "fa025e5d117929361bcf798437957762eb5bb6d4", "title": "Zero-Shot Relation Extraction via Reading Comprehension"}, {"paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"}, {"paperId": "3adff57fd09965224506a1bacc0579d9d3c8c11e", "title": "SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine"}, {"paperId": "636a79420d838eabe4af7fb25d6437de45ab64e8", "title": "RACE: Large-scale ReAding Comprehension Dataset From Examinations"}, {"paperId": "3eda43078ae1f4741f09be08c4ecab6229046a5c", "title": "NewsQA: A Machine Comprehension Dataset"}, {"paperId": "df40ce107a71b770c9d0354b78fdd8989da80d2f", "title": "Towards Evaluating the Robustness of Neural Networks"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "c4dd9a19d822c965ce8cde55ab23b8a0b628278a", "title": "An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition"}, {"paperId": "d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad", "title": "Intriguing properties of neural networks"}, {"paperId": "b9124861e4e874bbc477b4b726adf94f7d2ecdc4", "title": "Learning"}, {"paperId": "be7cb8f79bc018e57467168fc0c7f8ad59bba04f", "title": "Adaptive Testing and Debugging of NLP Models"}, {"paperId": null, "title": "GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "5e9faa7316250e6d8ee367a2abce418e9e3269dc", "title": "Evaluating Neural Model Robustness for Machine Comprehension"}, {"paperId": "f01457a49d4e2c62c91ca29b239eec6b5e71798c", "title": "Robustness and Adversarial Examples in Natural Language Processing"}, {"paperId": "5505d608a1d482fdc083796db812379ec1cb8723", "title": "Can Small and Synthetic Benchmarks Drive Modeling Innovation? A Retrospective Study of Question Answering Modeling Approaches"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Vancouver, Canada. Association for Computational Linguistics"}, {"paperId": null, "title": "2020b. Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901"}, {"paperId": null, "title": "Processing (Volume 1:"}]}