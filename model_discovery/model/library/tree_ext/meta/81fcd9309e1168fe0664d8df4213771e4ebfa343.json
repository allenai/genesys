{"paperId": "81fcd9309e1168fe0664d8df4213771e4ebfa343", "title": "Scalable Visual Transformers with Hierarchical Pooling", "abstract": "The recently proposed Visual image Transformers (ViT) with pure attention have achieved promising performance on image recognition tasks, such as image classification. However, the routine of the current ViT model is to maintain a full-length patch sequence during inference, which is redundant and lacks hierarchical representation. To this end, we propose a Hierarchical Visual Transformer (HVT) which progressively pools visual tokens to shrink the sequence length and hence reduces the computational cost, analogous to the feature maps downsampling in Convolutional Neural Networks (CNNs). It brings a great benefit that we can increase the model capacity by scaling dimensions of depth/width/resolution/patch size without introducing extra computational complexity due to the reduced sequence length. Moreover, we empirically find that the average pooled visual tokens contain more discriminative information than the single class token. To demonstrate the improved scalability of our HVT, we conduct extensive experiments on the image classification task. With comparable FLOPs, our HVT outperforms the competitive baselines on ImageNet and CIFAR-100 datasets.", "venue": "arXiv.org", "year": 2021, "citationCount": 27, "influentialCitationCount": 2, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A Hierarchical Visual Transformer (HVT) is proposed which progressively pools visual tokens to shrink the sequence length and hence reduces the computational cost, analogous to the feature maps downsampling in Convolutional Neural Networks (CNNs)."}, "embedding": {"model": "specter_v2", "vector": [0.5562605857849121, 0.3310348391532898, -0.3623292148113251, 0.22301575541496277, -0.24165143072605133, 0.18951605260372162, 1.0292352437973022, -0.2669019401073456, -0.2500659227371216, -0.5449533462524414, 0.9151664972305298, 0.711520791053772, 0.48348718881607056, 0.24663898348808289, -0.11018010973930359, -0.12534895539283752, -0.7510231733322144, -0.47192373871803284, 0.7712154984474182, -0.3053242266178131, 0.36530056595802307, -0.6233296990394592, -1.710553765296936, 0.4751219153404236, 0.2671618163585663, 1.5317693948745728, 0.655969500541687, 0.9248343706130981, -0.040023379027843475, 0.5501355528831482, 0.3310384154319763, -0.10375537723302841, 0.697504460811615, -0.18368558585643768, -0.3805079758167267, 0.04722508043050766, 0.8582572937011719, -0.6315606236457825, -0.6774577498435974, 0.8025646209716797, -0.05253559350967407, 0.366568922996521, 0.4391428232192993, -1.019119381904602, -0.32999834418296814, 0.38408297300338745, 0.47448429465293884, 0.9652785658836365, -0.6213635206222534, -0.6847621202468872, 1.4892489910125732, -1.1080623865127563, 0.32520291209220886, 1.4108390808105469, 0.1693391650915146, 0.16553150117397308, -0.0793561190366745, -0.48760128021240234, 1.1521657705307007, 0.5997449159622192, -0.7094710469245911, 0.12852680683135986, 0.29256555438041687, -0.18831750750541687, 2.19048810005188, -0.7544373273849487, 0.4624251425266266, 0.6253029108047485, 0.27208438515663147, 1.4837335348129272, -0.12594132125377655, -0.6622830629348755, -0.3301137685775757, -0.07151234894990921, 0.49979591369628906, 0.8114293813705444, -0.3326603174209595, 0.3662012815475464, -1.3368715047836304, 0.1130165308713913, 0.5528733134269714, 0.42370155453681946, 0.37330102920532227, -0.10750188678503036, -0.35277095437049866, 0.6435653567314148, 1.1634352207183838, 0.6776904463768005, -0.6936084032058716, 0.7937054634094238, 0.7042657136917114, -0.13120676577091217, -0.20027568936347961, 0.2147206962108612, 0.16396014392375946, 1.0785775184631348, -0.6946023106575012, 0.3815906047821045, -0.8806568384170532, 1.1129485368728638, 0.09677551686763763, 0.19155184924602509, -0.8958653211593628, 0.23103067278862, 1.0900641679763794, -0.0013143167598173022, 0.5735238790512085, -0.6166684627532959, -0.11017830669879913, -0.750683069229126, -0.30292415618896484, -0.7966138124465942, 0.35480237007141113, -0.18721932172775269, -0.8032888174057007, -0.6910654306411743, -0.7363189458847046, 0.747800350189209, -1.0217700004577637, 0.601120114326477, -0.29912546277046204, 0.14911583065986633, -0.4915720820426941, 0.13383127748966217, 0.42100322246551514, 0.6514294743537903, 0.2815185785293579, 0.3831559717655182, 1.3907829523086548, -1.1623075008392334, -0.43707722425460815, -0.9474242925643921, -0.4968002736568451, 0.029782097786664963, -0.020623350515961647, 0.06833326816558838, -1.1094963550567627, -1.5964242219924927, -1.1855597496032715, -0.3975163698196411, -0.9273196458816528, -0.380339115858078, 0.8928113579750061, 0.06812677532434464, -1.4380159378051758, 0.7680624723434448, -0.21906007826328278, -0.14261852204799652, 0.8277831077575684, -0.006377084646373987, 0.42815303802490234, -0.24820661544799805, -1.0000910758972168, -0.02514944225549698, 0.019095925614237785, -0.5893704891204834, -0.7220482230186462, -0.6101484298706055, -1.1671003103256226, 0.23153908550739288, -0.15498633682727814, -0.7590416073799133, 1.068770408630371, -0.29098567366600037, -0.5760377645492554, 0.30513638257980347, -0.6845937967300415, 0.15283697843551636, -0.061737313866615295, -0.3122814893722534, 0.3329285979270935, 0.0647244080901146, -0.047983866184949875, 1.1043057441711426, 0.9169022440910339, -0.13940739631652832, -0.3784323036670685, -0.0178013164550066, -0.5726466774940491, -0.07923523336648941, -0.6992563605308533, 0.8507281541824341, -0.44981348514556885, -0.33269447088241577, 0.17320185899734497, 1.0485942363739014, -0.0034489952959120274, -0.2759770452976227, -0.10829376429319382, -0.9435214996337891, 0.6704747080802917, 0.026804622262716293, 0.3020474910736084, -0.7729628682136536, -0.63963383436203, -0.37590256333351135, 0.3078867495059967, -0.3161807656288147, -1.0033270120620728, 0.6120896935462952, -0.20278935134410858, 0.27621448040008545, 0.49823081493377686, -0.9817081093788147, 0.19952963292598724, -0.33384695649147034, -0.7969520688056946, -0.39721494913101196, 0.19338645040988922, 1.433975338935852, -0.6462352275848389, -0.2676379680633545, 0.00604686513543129, 0.3891303241252899, -1.141769289970398, 1.1446303129196167, -0.33818140625953674, -0.04506878927350044, -0.23541325330734253, -0.0852803885936737, 0.038162749260663986, -0.405211478471756, 0.41026854515075684, -0.5594233870506287, -0.05854365974664688, 0.6461350917816162, 0.11512266099452972, 0.9841989874839783, 0.18168267607688904, 0.7696667909622192, -0.5147340893745422, -1.019068956375122, 0.21291911602020264, 0.30051541328430176, -0.1277150809764862, -0.9471771121025085, 0.4411216676235199, -0.43553081154823303, -1.156982421875, 0.31006529927253723, 0.9857157468795776, 0.9681380987167358, -0.3045353591442108, -0.16539959609508514, 1.0533782243728638, -0.14666706323623657, -0.0016193118644878268, 0.7639098167419434, 0.4303572177886963, 0.13004693388938904, 0.48800772428512573, -0.029058000072836876, -0.21537812054157257, -0.9966790080070496, -0.04660941660404205, 0.9777852296829224, 0.3561922311782837, 1.140101671218872, 0.7822659015655518, -0.8935860395431519, -0.7343462109565735, -0.06943968683481216, 0.6006060838699341, 1.4171262979507446, 0.009392062202095985, -0.15925703942775726, -0.5787041187286377, -0.3601486384868622, -0.5701779127120972, -1.0263522863388062, -0.8096345067024231, -0.34684187173843384, 0.057966168969869614, -0.6277235150337219, 0.4750533401966095, 0.5950243473052979, 1.535597801208496, -0.8322895169258118, -0.399833083152771, -0.6000419855117798, 0.18907687067985535, -0.9455522298812866, -0.6136474609375, 0.29736313223838806, -0.22490163147449493, -0.16080352663993835, -0.22633308172225952, -0.4792521893978119, 0.07374250888824463, -0.27542299032211304, 0.7584262490272522, -0.3179471492767334, -0.8078693151473999, 0.16518162190914154, 0.14428256452083588, -0.7810144424438477, 0.04328054562211037, -0.09239554405212402, -0.056735891848802567, -0.05662543699145317, -0.030293872579932213, 0.3441895842552185, -0.5203850269317627, 0.2907555401325226, -0.6903338432312012, -0.10334020853042603, 0.07203845679759979, 0.3398774564266205, 1.0737172365188599, -0.4861909747123718, 0.17852936685085297, -0.5763747096061707, 0.4683995842933655, 0.4451581537723541, -0.4498264193534851, 0.21100421249866486, -0.2567208707332611, -0.36948633193969727, 0.3279877305030823, -0.5747446417808533, -0.18633325397968292, -0.8061751127243042, 0.5009382367134094, -0.7687554955482483, -0.3359225392341614, -0.12190746515989304, 0.19244465231895447, -0.11517225205898285, 0.36056050658226013, 0.5525621175765991, 0.06117923557758331, 0.2685554027557373, 0.2651944160461426, -0.8840245008468628, 0.6085951328277588, 0.5229372978210449, -0.2706211507320404, -0.05669780820608139, -0.06329702585935593, -0.8483499884605408, -0.5264478325843811, -0.6681880950927734, -0.4880463480949402, -0.6750626564025879, 0.6174653768539429, -0.5765702724456787, -1.0806115865707397, 0.4229060411453247, -0.9879892468452454, -0.32619044184684753, 0.228006049990654, -0.26881104707717896, -0.28888458013534546, -0.625098705291748, -0.9519667625427246, -0.2132703959941864, -0.6092720031738281, -1.197096824645996, 0.1649644374847412, 0.5466883778572083, -0.13020358979701996, -0.2505059540271759, -0.2670529782772064, -0.3030914068222046, 0.9961109161376953, -0.16284573078155518, 0.5155739784240723, 0.11667153984308243, -0.6579798460006714, -0.340030312538147, -0.2843061089515686, 0.8395901918411255, -0.34053653478622437, -0.09222540259361267, -1.1795620918273926, 0.3421875536441803, -0.3766828775405884, -0.5568313002586365, 0.811635434627533, 0.45603007078170776, 0.777942419052124, -0.04007720574736595, -0.4396754801273346, 0.3557135760784149, 1.5328173637390137, -0.5838035941123962, 0.2988389730453491, -0.005970807280391455, 0.906822919845581, 0.01969858631491661, -0.2794802188873291, 0.7028771638870239, 0.2791785001754761, 0.34773147106170654, 0.7087996006011963, -0.4543304145336151, -0.8459224700927734, -0.6499588489532471, 0.17197492718696594, 0.7321588397026062, 0.3300521969795227, -0.0005988304619677365, -0.6587715744972229, 1.047556757926941, -1.0773639678955078, -0.9643123149871826, 1.1021625995635986, 0.6506839394569397, -0.06062149256467819, -0.7310852408409119, -0.13645170629024506, -0.18284395337104797, 0.7294957041740417, 0.8070496320724487, -0.38476842641830444, -0.4797256886959076, 0.22456766664981842, 0.7027338743209839, 0.26229625940322876, 0.8098669648170471, -0.19042985141277313, 0.6408193707466125, 14.42446517944336, 0.6348664164543152, -0.17294372618198395, 0.3948248326778412, 0.5042256116867065, 0.20877200365066528, -0.12582063674926758, -0.017822716385126114, -1.1743998527526855, -0.4337424337863922, 0.4960293769836426, 0.45676106214523315, 0.6556171178817749, 0.1346498280763626, -0.33176830410957336, 0.1382990926504135, -0.3645622432231903, 0.7629972696304321, 0.7689253687858582, -1.3235952854156494, 0.5338535308837891, 0.3897923529148102, 0.5041143894195557, 0.7696899175643921, 0.9544275403022766, 0.6162392497062683, 0.15825852751731873, -0.3254322409629822, 0.7413219809532166, 0.17262302339076996, 0.6610568165779114, 0.0785689651966095, 0.21597008407115936, -0.07335095852613449, -1.4648475646972656, -0.17836077511310577, -0.970354437828064, -1.0707699060440063, 0.11025561392307281, -0.3350076377391815, -0.40004172921180725, -0.11824418604373932, 0.423282653093338, 1.2680875062942505, -0.20133161544799805, 0.6136338710784912, -0.31600746512413025, 0.047560010105371475, 0.22702735662460327, -0.41556140780448914, 0.481216162443161, 1.1241204738616943, -0.11958398669958115, -0.08133808523416519, -0.23289038240909576, 0.05147912725806236, 0.056647829711437225, 0.21557022631168365, -0.4825694262981415, -0.3976958692073822, -0.3120689392089844, 0.06196342781186104, -0.003760013496503234, 0.8571160435676575, 0.1775800585746765, -0.1875132918357849, -0.09732655435800552, 0.24757243692874908, 0.35907599329948425, 0.2940937280654907, -0.2903141975402832, -0.3036405146121979, 0.36569538712501526, -0.5393643379211426, 0.6901748776435852, 0.6752773523330688, -0.3424670994281769, -0.5125296711921692, -0.7129610776901245, -0.06108761951327324, 0.6441041827201843, -1.0979669094085693, -0.5618472099304199, 1.3207941055297852, 0.1212543472647667, -0.34294062852859497, 0.4111684262752533, -0.811363935470581, -0.3671894967556, 0.3505786657333374, -1.6194010972976685, -0.7399569153785706, -0.4534253478050232, 0.17585064470767975, -0.33939310908317566, 0.07524781674146652, 0.6886225342750549, -0.2531662583351135, 0.11228194832801819, 0.31095513701438904, -0.743973433971405, -0.050527509301900864, -0.37336254119873047, -0.5486711263656616, 0.6302495002746582, 0.48964330554008484, -0.0635363757610321, -0.1551618129014969, -0.06781211495399475, 0.3124576807022095, -0.3485367000102997, 0.07528377324342728, 0.552781343460083, -0.34114959836006165, -0.5518869161605835, -0.7767286896705627, -0.9462138414382935, 0.3945813775062561, 1.0159791707992554, 0.22903867065906525, 0.18990011513233185, 0.15887434780597687, -1.1197099685668945, -0.33556652069091797, -0.7296447157859802, -0.0020248382352292538, 0.0604667067527771, -0.8222654461860657, -0.3678301274776459, -0.3827269971370697, 0.3013834059238434, -0.4357307553291321, -0.469279408454895, -0.486592173576355, 0.5096257925033569, -0.6011237502098083, 1.4513710737228394, -0.3019345700740814, 0.5702131390571594, 0.9033257365226746, -0.2609129548072815, -0.49893227219581604, -0.3324712812900543, -0.7311729192733765, 0.7463330626487732, 0.29401957988739014, 0.06308009475469589, -0.6819025278091431, -0.010000000707805157, 0.2866920828819275, 0.1404462605714798, -0.30857202410697937, -0.47546279430389404, -0.0916203111410141, -0.20723585784435272, -0.476528525352478, 0.21706952154636383, -0.23845304548740387, 0.29754939675331116, 0.04509882256388664, 0.37180474400520325, 0.6927152276039124, 0.11502989381551743, -0.7418888807296753, 0.23059657216072083, 0.026392078027129173, -0.06538596004247665, -0.8316718339920044, -0.9679171442985535, -1.4710700511932373, -0.35861140489578247, -1.0944489240646362, 0.14897474646568298, -1.085378646850586, -0.11655426025390625, 0.6222600340843201, -0.6112757325172424, 0.7604654431343079, 0.029661720618605614, 0.26532283425331116, -0.11779730021953583, -0.7760564088821411, -0.7006092667579651, 0.8433724641799927, 1.0787508487701416, -0.802316427230835, 0.23238056898117065, -0.7398117184638977, -0.16374410688877106, 0.01878844015300274, 0.3005913197994232, -0.1634758561849594, -0.7781273722648621, -1.0409053564071655, 0.12805335223674774, -0.16646915674209595, 0.2932320535182953, -0.9233194589614868, 0.8020309209823608, 0.7090986967086792, 0.3188401460647583, -0.3330361545085907, 0.47648900747299194, -0.44377076625823975, -0.9178888201713562, 0.31724369525909424, -0.768956184387207, 0.09172716736793518, 0.48289015889167786, -0.4505593180656433, -0.5752544403076172, 0.9543069005012512, 0.3039214015007019, -1.1871020793914795, -1.1031827926635742, 0.5939732193946838, -0.4518916606903076, -0.09940189868211746, -0.2735278904438019, -0.2173517793416977, -1.5240775346755981, -0.38716039061546326, 0.24515163898468018, 0.46004989743232727, -0.4573388993740082, 0.7590191960334778, 0.8969193696975708, -0.915809154510498, 0.2980659008026123, 0.5670339465141296, 0.07595854252576828, 0.0061471303924918175, 0.8817920088768005, 0.5146761536598206, -0.0576644092798233, 0.3196932375431061, -0.3258615732192993, 0.13539472222328186, -0.9180635213851929, 0.6184747219085693, 0.7429355978965759, -0.09339795261621475, -0.17820650339126587, 1.1493842601776123, 0.35500219464302063, -0.17986539006233215, 0.23045887053012848, -1.0998286008834839, -0.7229735851287842, 0.2688421905040741, 1.0893958806991577, -0.16021573543548584, 0.13104456663131714, 0.170182004570961, -0.46038901805877686, 0.5722177028656006, -0.3980429768562317, -0.6406346559524536, 0.5765225291252136, 0.0782291367650032, -0.3133545219898224, 0.15357622504234314, 0.9279088377952576, -1.2185275554656982, -1.3430086374282837, -0.9635076522827148, -0.8778855204582214, -0.3187173306941986, 0.418070524930954, -0.16314613819122314, -0.868671178817749, 0.904106080532074, 0.517676591873169, 0.7693726420402527, 0.47244980931282043, 0.3927758038043976, -0.05434247851371765, 0.3042634427547455, -0.15384210646152496, -0.16315501928329468, 0.272854208946228, 1.2227089405059814, 1.279646873474121, -0.5060673356056213, 0.19114907085895538, 0.13977333903312683, -0.8803741931915283, 0.40815362334251404, 0.09515310823917389, -0.6588624119758606, 0.9184131622314453, -0.3661733567714691, -0.05961204320192337, 0.08339159935712814, -1.2027580738067627, -0.5142563581466675, 1.170543909072876, 1.5514723062515259, 0.21000134944915771, -0.1604531705379486, 0.38768354058265686, 0.5740856528282166, 0.2386404126882553, -0.23851798474788666, 0.3741273283958435, 0.4311826229095459, -0.4511069655418396, 0.20260925590991974, 0.13742059469223022, 0.1699829250574112, -0.7160764932632446, -0.5874047875404358, -0.05719254910945892, 0.55860835313797, 0.05609387159347534, 0.539557933807373, 0.9694274067878723, -0.00888461247086525, 0.5025157928466797, -0.06361149996519089, 0.7404575943946838, -0.25391680002212524, -0.362409383058548, 0.1069817766547203, -1.3689219951629639, -0.44417691230773926, -0.45608583092689514, -0.8517605066299438, 0.11989966034889221, 0.24043188989162445, 0.5292486548423767, -0.2898716330528259, 0.15083450078964233, 0.9188927412033081, 0.42457807064056396, 0.9127534031867981, 0.0486268550157547, -1.2157856225967407, 0.0702069029211998, -0.9773979783058167, 0.1209767535328865, -0.5027855634689331, 0.362640380859375, -0.4678787589073181, -0.10217161476612091, -0.0020295463036745787]}, "authors": [{"authorId": "1840579673", "name": "Zizheng Pan"}, {"authorId": "3194022", "name": "Bohan Zhuang"}, {"authorId": "49270464", "name": "Jing Liu"}, {"authorId": "2257471849", "name": "Haoyu He"}, {"authorId": "2249720327", "name": "Jianfei Cai"}], "references": [{"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78", "title": "Bottleneck Transformers for Visual Recognition"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "787119e3c3f819244c82b7d97779473773e60696", "title": "MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers"}, {"paperId": "2ac7999cce9f415ee87643f56631b55ed26aa10e", "title": "End-to-End Video Instance Segmentation with Transformers"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "097210dc65924f8ce59523faf444e635523dc714", "title": "TernaryBERT: Distillation-aware Ultra-low Bit BERT"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "4ca3b0ea12f02e2dea01a4aa505956bae5500a09", "title": "Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing"}, {"paperId": "ef8d788a904ed66bd8e30ffa69bc3ea1fe57dda7", "title": "HAT: Hardware-Aware Transformers for Efficient Natural Language Processing"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "8eba733040b016e9c7ec5c3dc87cc1b28a5c2000", "title": "Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation"}, {"paperId": "d9b824dbecbe3a1f0b1489f9e4521a532a63818d", "title": "Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning"}, {"paperId": "94f94e8892261d0377159379ca5a166ceae19a14", "title": "PoWER-BERT: Accelerating BERT Inference via Progressive Word-vector Elimination"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "bb713d56a39a040b35e4f9e036fb4422f543e614", "title": "On the Relationship between Self-Attention and Convolutional Layers"}, {"paperId": "132ae47905b1a648c095da54b8533e87cf642897", "title": "Fully Quantized Transformer for Machine Translation"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "d6dccb5d71fbb6f5765f89633ba3a8e6809a720d", "title": "Stand-Alone Self-Attention in Vision Models"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "b03c7ff961822183bab66b2e594415e585d3fd09", "title": "Are Sixteen Heads Really Better than One?"}, {"paperId": "061d6d5f3df0db70b12f9e90bec327e19b7259c1", "title": "Local Relation Networks for Image Recognition"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "5132500b23d2da47129b3f4f68dd30947a29e502", "title": "CCNet: Criss-Cross Attention for Semantic Segmentation"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "2a94c84383ee3de5e6211d43d16e7de387f68878", "title": "Feature Pyramid Networks for Object Detection"}, {"paperId": "3070a1bd503c3767def898bbd50c7eea2bbf29c9", "title": "Wider or Deeper: Revisiting the ResNet Model for Visual Recognition"}, {"paperId": "c2a1cb1612ba21e067a5c3ba478a8d73b796b77a", "title": "Pruning Filters for Efficient ConvNets"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "1c4e9156ca07705531e45960b7a919dc473abb51", "title": "Wide Residual Networks"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd", "title": "ImageNet Large Scale Visual Recognition Challenge"}, {"paperId": "405aed4b8ecdd869b2e83095dde51c396334115f", "title": "A Theoretical Analysis of Feature Pooling in Visual Recognition"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}]}