{"paperId": "94e46e18d2628343a926acf6c3d0817e11d35d58", "title": "ERNIE-SPARSE: Learning Hierarchical Efficient Transformer Through Regularized Self-Attention", "abstract": "Sparse Transformer has recently attracted a lot of attention since the ability for reducing the quadratic dependency on the sequence length. We argue that two factors, information bottleneck sensitivity and inconsistency between different attention topologies, could affect the performance of the Sparse Transformer. This paper proposes a well-designed model named ERNIE-Sparse. It consists of two distinctive parts: (i) Hierarchical Sparse Transformer (HST) to sequentially unify local and global information. (ii) Self-Attention Regularization (SAR) method, a novel regularization designed to minimize the distance for transformers with different attention topologies. To evaluate the effectiveness of ERNIE-Sparse, we perform extensive evaluations. Firstly, we perform experiments on a multi-modal long sequence modeling task benchmark, Long Range Arena (LRA). Experimental results demonstrate that ERNIE-Sparse significantly outperforms a variety of strong baseline methods including the dense attention and other efficient sparse attention methods and achieves improvements by 2.77% (57.78% vs. 55.01%). Secondly, to further show the effectiveness of our method, we pretrain ERNIE-Sparse and verified it on 3 text classification and 2 QA downstream tasks, achieve improvements on classification benchmark by 0.83% (92.46% vs. 91.63%), on QA benchmark by 3.24% (74.67% vs. 71.43%). Experimental results continue to demonstrate its superior performance.", "venue": "arXiv.org", "year": 2022, "citationCount": 9, "influentialCitationCount": 1, "openAccessPdf": {"url": "http://arxiv.org/pdf/2203.12276", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "Experimental results demonstrate that ERNIE-Sparse significantly outperforms a variety of strong baseline methods including the dense attention and other efficient sparse attention methods and achieves improvements on classification benchmark and on QA downstream tasks."}, "embedding": {"model": "specter_v2", "vector": [0.43635958433151245, 0.5710840225219727, -0.19195227324962616, -0.16820776462554932, -0.5246682167053223, -0.24654318392276764, 0.1762651801109314, -0.061479128897190094, -0.06160033494234085, 0.10087903589010239, 0.7028256058692932, 0.2554067373275757, 0.4143887460231781, 0.15827125310897827, -0.189723938703537, 0.058924201875925064, -0.8907366394996643, 0.5191829800605774, -0.17485454678535461, -0.5577362179756165, 0.1533515751361847, -0.8821431994438171, -0.7669597864151001, -0.04516620188951492, 0.7077083587646484, 0.5721808075904846, 0.6691338419914246, 0.41615304350852966, -0.6624746918678284, 0.564431369304657, 0.5161125063896179, -0.39705103635787964, 0.16546493768692017, -0.2557060718536377, -0.5338603854179382, -0.0360872857272625, 0.297504723072052, -0.03800118342041969, -0.5574560761451721, 0.6927216649055481, -0.09108579158782959, 0.27325382828712463, 0.7076361775398254, -0.6319476366043091, -0.34308066964149475, 0.9447144865989685, 0.48641103506088257, 0.8779674172401428, -0.1694546341896057, -0.5619685649871826, 1.8422456979751587, -1.1459362506866455, 0.13789807260036469, 1.1699018478393555, 0.5481359958648682, 0.43192046880722046, -0.17681731283664703, -0.8658177256584167, 0.5492718815803528, 0.4650737941265106, -0.771379828453064, -0.3151727020740509, -0.11357313394546509, -0.2415517270565033, 1.8585071563720703, -0.4463967978954315, -0.17420360445976257, 0.8531835079193115, 0.19286629557609558, 1.2857295274734497, -0.22101932764053345, -0.3004121780395508, -0.3955284357070923, -0.43884822726249695, 0.4158342182636261, 0.9393841028213501, -0.7576761245727539, 0.4300359785556793, -0.9429037570953369, 0.04970374330878258, 0.25541865825653076, -0.04166913777589798, 0.133694127202034, -0.0922972559928894, -0.07822111994028091, 0.8590939044952393, 0.37604495882987976, 1.1284124851226807, -0.17114156484603882, 0.29592165350914, 0.7318843007087708, 0.39289596676826477, -0.20933176577091217, 0.6137284636497498, 0.011873029172420502, -0.022299733012914658, -0.6927095651626587, 0.07956641912460327, -0.2385505586862564, 1.2660958766937256, -0.1622702032327652, 0.6147142052650452, -0.5921834111213684, 0.23020100593566895, 1.2775229215621948, -0.04413697123527527, 0.7877897620201111, -0.5942347645759583, 0.2607676386833191, -0.44845324754714966, -0.14651533961296082, -0.7869997024536133, -0.3859521448612213, -0.35236138105392456, -1.185793161392212, -1.4525285959243774, -0.4129163324832916, 0.536395788192749, -0.4737566411495209, 0.7049104571342468, -0.6272393465042114, 0.22697171568870544, -0.01253054291009903, 0.1659819632768631, 0.8270208835601807, 0.6802124381065369, 0.34508198499679565, 0.08896512538194656, 0.7289770245552063, -1.103011131286621, -0.8602467775344849, -1.2044260501861572, 0.7101555466651917, -0.23960436880588531, 0.10309038311243057, -0.28649473190307617, -0.9576799869537354, -0.9168288707733154, -0.701569676399231, -0.10995502024888992, -0.02193620428442955, -0.0414389930665493, 0.6085053086280823, -0.02978278510272503, -0.6871724724769592, 0.83684903383255, -0.22082355618476868, -0.32759442925453186, 0.5077505111694336, -0.17352275550365448, 0.08978193998336792, -0.34990444779396057, -1.4384639263153076, 0.4959262013435364, 0.13326211273670197, -0.5176509618759155, -0.5172757506370544, -0.5485590100288391, -1.692941665649414, 0.24833248555660248, 0.444121390581131, -0.26542559266090393, 1.0512803792953491, -0.10341984033584595, -1.174617886543274, 0.49910908937454224, -0.49926483631134033, -0.19844795763492584, -0.05320359393954277, -0.035143814980983734, -0.18776291608810425, -0.5747990012168884, 0.35446348786354065, 0.24913090467453003, 0.2627292573451996, 0.00930545013397932, -0.06491157412528992, 0.07708588242530823, -0.610060453414917, -0.1157410517334938, -0.08090569823980331, 0.8037779331207275, -0.026756154373288155, -0.350578248500824, -0.11767135560512543, 0.6507344841957092, -0.16471657156944275, -0.3848687410354614, -0.3023761808872223, -1.1581906080245972, 0.7250860929489136, -0.1714087873697281, 1.0711902379989624, -0.8778932690620422, -0.4979400038719177, -0.35486894845962524, -0.0008398047066293657, -0.22754178941249847, -1.1726140975952148, 0.7571742534637451, -0.6112834811210632, 0.08480512350797653, -0.3762122690677643, -0.9712850451469421, -0.06734318286180496, -0.01108935009688139, -0.5954219698905945, -0.13489246368408203, -0.024915888905525208, 1.1073979139328003, -1.1112762689590454, -0.2114192545413971, -0.012177995406091213, 0.06455282121896744, -0.6379983425140381, 1.3410371541976929, -0.2598671019077301, 0.15218938887119293, -0.27036184072494507, -0.18724270164966583, -0.30840378999710083, -0.8753507137298584, 0.13880406320095062, -0.5733750462532043, 0.1079932153224945, 0.490546315908432, -0.04711458459496498, 1.6761178970336914, -0.301210880279541, 0.5184544920921326, -0.28864601254463196, -0.9457131028175354, 0.5277217626571655, 0.2808595597743988, 0.1804836392402649, -0.8323802947998047, 0.3994038701057434, -0.03796866908669472, -0.5926650762557983, 0.06003565713763237, 0.5750018358230591, 0.7080327272415161, -0.20491690933704376, 0.12323502451181412, 0.6033182740211487, -0.12230609357357025, 0.7205076813697815, 0.6784029603004456, 1.1075940132141113, 0.3514929711818695, 0.7546600103378296, -0.17268477380275726, 0.17928314208984375, -0.7755625247955322, 0.07698065042495728, 0.3169501721858978, 0.4670158624649048, 0.906930685043335, 0.20591452717781067, -0.5224689841270447, -0.7182977795600891, 0.28932809829711914, 0.8736643195152283, 1.3515115976333618, -0.008663770742714405, -0.6586102247238159, -0.4341351389884949, -0.3843291103839874, -0.6571105122566223, 0.2504970133304596, -0.5016039609909058, -0.36306658387184143, -0.24497643113136292, -0.7840186953544617, 0.7122188806533813, 0.43681249022483826, 0.9247273206710815, -0.5405346155166626, -0.2384340614080429, -0.0499916598200798, -0.35505226254463196, -0.7267917990684509, -0.9493535161018372, 0.5274306535720825, -0.359762042760849, -0.2709207534790039, 0.08480938524007797, 0.1645180583000183, -0.2227311134338379, -0.5073436498641968, 1.1676901578903198, -0.7342095971107483, -0.2534690499305725, 0.2926316261291504, 0.08207418769598007, -0.46507778763771057, -0.6966185569763184, 0.349688857793808, -0.18797935545444489, -0.2597673833370209, 0.3260212540626526, 0.3605688214302063, 0.2252221256494522, 0.24814273416996002, -0.19968225061893463, -0.036505382508039474, 0.27513575553894043, 0.4340295195579529, 0.4698563516139984, -0.11501695960760117, 0.018902795389294624, -0.8830525279045105, 0.6060669422149658, -0.04812118783593178, -0.39667776226997375, 0.20896349847316742, -0.6073437333106995, -0.19027310609817505, 0.5039410591125488, -0.3641814589500427, -0.23335875570774078, -0.6433548331260681, 0.15568828582763672, -0.2902241349220276, -0.22937260568141937, 0.33559325337409973, 0.15311360359191895, 0.2959592938423157, 0.5348895788192749, 0.8323565721511841, 0.5810160636901855, 0.07495441287755966, 0.3461710214614868, -0.7936089038848877, 0.3118542730808258, 0.3378489315509796, 0.13522520661354065, -0.2547750771045685, -0.16559337079524994, -0.8197228312492371, -0.9370576739311218, -0.5890527367591858, -0.15632793307304382, -0.033589497208595276, 0.3827332556247711, -0.6446080803871155, -0.9204223155975342, -0.1437421441078186, -0.9077760577201843, -0.29941993951797485, -0.0586402490735054, -0.6277539730072021, -0.4968877136707306, -0.7504052519798279, -1.1142019033432007, -0.512170135974884, -0.6902409195899963, -1.0582995414733887, 0.7055133581161499, -0.1250486671924591, -0.6117962598800659, -0.4826122224330902, 0.010683940723538399, -0.1963779181241989, 1.1028504371643066, -0.4294009506702423, 0.5007193088531494, -0.41828009486198425, -0.19841386377811432, 0.00024827016750350595, 0.11164851486682892, 0.276817262172699, 0.19626402854919434, -0.15399929881095886, -0.5191164612770081, 0.12995225191116333, -0.1642635017633438, -0.3946399390697479, -0.07919453084468842, 0.37863853573799133, 0.7888973951339722, 0.03585370257496834, -0.5319505929946899, 0.042654938995838165, 1.3613309860229492, -0.2809593379497528, 0.17949406802654266, 0.3021765649318695, 1.0921322107315063, 0.24278046190738678, -0.08187392354011536, 0.5062874555587769, 0.6262897253036499, 0.4778312146663666, 0.31955698132514954, 0.15298424661159515, 0.07850407809019089, -0.3998737633228302, 0.587158203125, 1.6874659061431885, 0.3187650144100189, 0.01793021894991398, -0.9954245090484619, 0.80254727602005, -1.2603996992111206, -1.2655709981918335, 0.5973969101905823, 0.2888317406177521, 0.5611166954040527, -0.7494279742240906, -0.10758254677057266, -0.21295982599258423, 0.3367258906364441, 0.33435767889022827, -0.3628046214580536, -0.20569276809692383, -0.193612203001976, 0.32021576166152954, 0.16687798500061035, 0.42837411165237427, -0.2894567847251892, 0.39630362391471863, 15.12414836883545, 1.1529030799865723, 0.18333163857460022, 0.6881594061851501, 0.7235155701637268, 0.5075189471244812, -0.10068206489086151, -0.32037001848220825, -1.130285620689392, 0.1074119284749031, 1.1595427989959717, -0.0956542119383812, 0.4731164574623108, 0.1750132292509079, 0.010084479115903378, 0.39268237352371216, -0.6413957476615906, 0.6851686835289001, 0.5526412725448608, -1.1309518814086914, 0.36669909954071045, -0.07936032861471176, 0.08523959666490555, 0.379472941160202, 0.6383493542671204, 0.7085204124450684, 0.7678292393684387, -0.7351402640342712, 0.1768508404493332, 0.3410443663597107, 0.9999845027923584, -0.049172986298799515, 0.5379319190979004, 0.532946765422821, -1.0836256742477417, -0.41957858204841614, -0.5500680208206177, -0.9648346900939941, 0.38444098830223083, 0.03696705400943756, -0.17893339693546295, -0.1428338885307312, 0.005620182957500219, 1.372169852256775, 0.29597964882850647, 0.5198185443878174, 0.004186156205832958, 0.6169582009315491, 0.3920077979564667, 0.17668884992599487, 0.5025232434272766, 0.44442218542099, 0.2935413122177124, -0.11494206637144089, 0.26346537470817566, 0.08653611689805984, 0.14245346188545227, 0.39335912466049194, -0.13185815513134003, 0.013591261580586433, -0.6474847197532654, -0.425791472196579, -0.15473966300487518, 0.7308756113052368, 0.6958491206169128, 0.38764652609825134, -0.48315978050231934, 0.2314767986536026, 0.6546550393104553, -0.2262014001607895, -0.34109848737716675, -0.20758265256881714, 0.01299657765775919, -0.48383358120918274, -0.1697479784488678, 0.6466385126113892, -0.2791900336742401, -0.5550525188446045, -1.1493500471115112, -0.8545699119567871, 0.531853437423706, -1.0174040794372559, -1.4491304159164429, 1.1684857606887817, -0.4149892330169678, -0.5300906300544739, 0.18450216948986053, -0.42973485589027405, 0.01715424470603466, 0.3228623867034912, -1.1104865074157715, -0.5619757175445557, -0.08540584146976471, -0.2677491307258606, 0.11858608573675156, -0.42145875096321106, 1.1692231893539429, 0.22649571299552917, -0.12668532133102417, 0.04382789134979248, 0.09034008532762527, -0.037445370107889175, -0.09541482478380203, -0.7807092070579529, 0.5782088041305542, 0.072725310921669, -0.04760697856545448, 0.13424038887023926, 0.23420202732086182, 0.0907571092247963, -0.47819283604621887, -0.20639151334762573, 0.7246241569519043, -1.060585856437683, 0.059078607708215714, -0.8461018800735474, -1.0297679901123047, 0.47806596755981445, 0.6117764711380005, -0.531671941280365, 0.39983069896698, 0.014635293744504452, -0.48808932304382324, -0.08574008196592331, -0.6277652382850647, -0.1421220749616623, 0.7626072764396667, -0.7331444025039673, -0.5495262145996094, -0.051486510783433914, 0.4829768240451813, -0.9441865682601929, -0.5412473678588867, -0.14484776556491852, 0.06619028002023697, -0.013337226584553719, 0.6908680200576782, -0.171648770570755, 0.922322154045105, 0.9409321546554565, 0.036949556320905685, -1.0130010843276978, -0.33523857593536377, -0.9048107862472534, 0.19104325771331787, 0.13528123497962952, 0.49913108348846436, -0.23438802361488342, 0.287239134311676, 0.5919964909553528, 0.1810331493616104, -0.3592913746833801, -0.7412588596343994, -0.36367377638816833, -0.31197845935821533, -0.11976917088031769, 0.0892796590924263, -0.0015983560588210821, 0.01568341627717018, 0.6699995994567871, 0.05476327985525131, 0.12675030529499054, -0.0778995230793953, -0.6521450281143188, 0.039719998836517334, -0.26149314641952515, 0.1248590499162674, -0.5076702237129211, -0.48520976305007935, -1.5516245365142822, 0.20623597502708435, -1.1226171255111694, 0.21790389716625214, -0.8111799955368042, -0.07041069120168686, 0.24975311756134033, -0.09271564334630966, 0.1906326860189438, 0.3565691113471985, -0.49589478969573975, -0.43472081422805786, -0.6200850605964661, -0.8351614475250244, 1.2181764841079712, 0.8767357468605042, -1.1167349815368652, 0.2695753574371338, -0.2598021328449249, -0.30377116799354553, 0.010307565331459045, 0.33465278148651123, -0.677276074886322, -0.5943343043327332, -0.9459081888198853, 0.26997458934783936, 0.11435461044311523, -0.35136622190475464, -0.4358152747154236, 0.6527018547058105, 0.4814411401748657, -0.3757380247116089, -0.05985208973288536, 0.1339299976825714, -1.2870410680770874, -0.27768367528915405, 0.3421190679073334, -0.9619139432907104, 0.47622793912887573, 0.16410326957702637, -0.3142091631889343, -0.5432931184768677, 0.5471240878105164, 0.31177687644958496, -1.2521089315414429, -0.49487730860710144, 0.7840269207954407, -0.7382961511611938, 0.35299617052078247, -0.08636455982923508, 0.017480431124567986, -1.0262246131896973, -0.47991853952407837, -0.2455814927816391, 0.5964274406433105, -0.6003450155258179, 1.0052013397216797, 0.39659640192985535, -1.3252551555633545, 0.018899451941251755, 0.020823700353503227, 0.24147650599479675, 0.030384743586182594, 0.6708230376243591, 0.23097524046897888, 0.16181863844394684, 0.38565632700920105, 0.017367159947752953, 0.3007504343986511, -1.0165244340896606, 0.14390116930007935, 0.9468675255775452, -0.7219040989875793, -0.14803282916545868, 0.935234546661377, -0.07896912842988968, -0.9280440211296082, 0.15122172236442566, -0.7668594121932983, -0.870296835899353, -0.23958370089530945, 0.6111624836921692, 0.38555747270584106, -0.4985347092151642, -0.4759368598461151, -0.45451560616493225, 0.4330052435398102, -0.10683982819318771, -0.11793447285890579, 0.8893883228302002, -0.40445688366889954, -0.45105066895484924, 0.8679912090301514, 0.8344936370849609, -0.8051266074180603, -0.520764172077179, -0.6944859623908997, -0.2932458221912384, -0.03153233975172043, -0.0708397850394249, -0.35750728845596313, -0.5808910131454468, 0.6957228183746338, 0.46733301877975464, 0.4760974049568176, 0.06848320364952087, -0.17311032116413116, 0.26721295714378357, 0.6034636497497559, -0.013885892927646637, -0.3387381434440613, -0.11924771219491959, 1.4936996698379517, 1.6106358766555786, -0.8469513654708862, -0.06274256855249405, -0.21099434792995453, -0.8638724684715271, 0.7014515399932861, 0.47377628087997437, -0.07892047613859177, 0.5838048458099365, 0.02964850701391697, -0.052131809294223785, -0.13976459205150604, -1.1309961080551147, -0.45490989089012146, 0.8216579556465149, 1.2601678371429443, 0.7547554969787598, -0.32580122351646423, 0.09322763234376907, 0.7138321399688721, 0.18651853501796722, 0.09681171923875809, 0.558487594127655, 0.014066003262996674, -0.1508462280035019, 0.062056269496679306, 0.40901893377304077, 0.8101627230644226, -0.6384851336479187, -0.6935395002365112, 0.37847959995269775, 0.21341225504875183, -0.16144004464149475, 0.6240305304527283, 0.6573207974433899, 0.10456248372793198, 0.4830721616744995, 0.18612197041511536, 0.28658872842788696, -0.5445289611816406, -0.05350105091929436, -0.20855103433132172, -0.7513121366500854, -0.3939741849899292, -0.49475741386413574, -0.6055183410644531, -0.24443747103214264, 0.13793876767158508, 0.15128487348556519, 0.3023700714111328, -0.011706478893756866, 1.252961277961731, 0.7019751071929932, 0.6016989350318909, -0.3172495365142822, -0.2977326512336731, -0.515058696269989, -1.1103359460830688, -0.15203417837619781, -0.396476149559021, -0.08085181564092636, -0.31017109751701355, -0.18236640095710754, -0.17584043741226196]}, "authors": [{"authorId": "2152798427", "name": "Yang Liu"}, {"authorId": "2144130913", "name": "Jiaxiang Liu"}, {"authorId": "47817922", "name": "L. Chen"}, {"authorId": "2140025135", "name": "Yuxiang Lu"}, {"authorId": "144588144", "name": "Shi Feng"}, {"authorId": null, "name": "Zhida Feng"}, {"authorId": "2117103617", "name": "Yu Sun"}, {"authorId": "50007795", "name": "Hao Tian"}, {"authorId": "51336296", "name": "Huancheng Wu"}, {"authorId": "2108969274", "name": "Hai-feng Wang"}], "references": [{"paperId": "520bd2331cca8d5a9c032c186a2a0f7704ead6ff", "title": "R-Drop: Regularized Dropout for Neural Networks"}, {"paperId": "84daddd294fa3cc12596b5785f81c2a153d2fb1d", "title": "Hi-Transformer: Hierarchical Interactive Transformer for Efficient and Effective Long Document Modeling"}, {"paperId": "836e9619f779f2d9642561f2b697ba471b866b27", "title": "Hierarchical Learning for Generation with Long Source Sequences"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "3bfa808ce20b2736708c3fc0b9443635e3f133a7", "title": "On the Bottleneck of Graph Neural Networks and its Practical Implications"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "2ffcf8352223c95ae8cef4daaec995525ecc926b", "title": "Adversarial Training for Large Neural Language Models"}, {"paperId": "baed71eed57ad462f3ab138d4b1700a738cd5414", "title": "ETC: Encoding Long and Structured Data in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "efe638a32c6bd9ad24a233784008bfe5b33cfc83", "title": "Adv-BERT: BERT is not robust on misspellings! Generating nature adversarial samples on BERT"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "80f9f109d1564cb8f82aa440a5f6f3fbe220c9ef", "title": "ERNIE 2.0: A Continual Pre-training Framework for Language Understanding"}, {"paperId": "ae04f3d011511ad8ed7ffdf9fcfb7f11e6899ca2", "title": "Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "fc089a09074c84979d1f34e89341318a5bc26d3d", "title": "SemEval-2019 Task 4: Hyperpartisan News Detection"}, {"paperId": "7cc730da554003dda77796d2cb4f06da5dfd5592", "title": "Hierarchical Transformers for Multi-Document Summarization"}, {"paperId": "ad7129af0644dbcafa9aa2f111cb76526ea444a1", "title": "Defending Against Neural Fake News"}, {"paperId": "203b543bfa1e564bb80ff4229b43174d7c71b0c0", "title": "HIBERT: Document Level Pre-training of Hierarchical Bidirectional Transformers for Document Summarization"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "db9b452f34e5dd6522acaad64e1d0d11868aa5d3", "title": "Long Document Classification From Local Word Glimpses via Recurrent Attention Learning"}, {"paperId": "d7b6753a2d4a2b286c396854063bde3a91b75535", "title": "A Simple Method for Commonsense Reasoning"}, {"paperId": "0d3c46a3cbfe06cec259fec954b6ff6df6c1a566", "title": "Learning long-range spatial dependencies with horizontal gated-recurrent units"}, {"paperId": "8b354d76813bd5375e7e5c8d17f630bec5936a01", "title": "ListOps: A Diagnostic Dataset for Latent Tree Learning"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "514e7fb769950dbe96eb519c88ca17e04dc829f6", "title": "HotFlip: White-Box Adversarial Examples for Text Classification"}, {"paperId": "7d5cf22c70484fe217936c66741fb73b2a278bde", "title": "Constructing Datasets for Multi-hop Reading Comprehension Across Documents"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"}, {"paperId": "4b1c6f6521da545892f3f5dc39461584d4a27ec0", "title": "Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "bee044c8e8903fb67523c1f8c105ab4718600cdb", "title": "Explaining and Harnessing Adversarial Examples"}, {"paperId": "d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad", "title": "Intriguing properties of neural networks"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "56010a55d49ac1f42355538f494427fd22402be1", "title": "Exploring the Limits"}, {"paperId": "e01eae8dea6fbaa1ae7fc83535053932268df430", "title": "The ACL anthology network corpus"}, {"paperId": "9ca9f28676ad788d04ba24a51141a9a0a0df4d67", "title": "A new model for learning in graph domains"}, {"paperId": "a89d59f39e805e71b554a962d07449c5d39b7df3", "title": "Combining labeled and unlabeled data with co-training"}, {"paperId": null, "title": "ELECTRA: pre-training text encoders as discriminators rather than generators"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}]}