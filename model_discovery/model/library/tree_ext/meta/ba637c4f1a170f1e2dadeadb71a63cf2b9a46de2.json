{"paperId": "ba637c4f1a170f1e2dadeadb71a63cf2b9a46de2", "title": "Visual attention network", "abstract": null, "venue": "Computational Visual Media", "year": 2022, "citationCount": 354, "influentialCitationCount": 47, "openAccessPdf": {"url": "https://link.springer.com/content/pdf/10.1007/s41095-023-0364-2.pdf", "status": "GOLD"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes a novel linear attention named large kernel attention (LKA) to enable self-adaptive and long-range correlations in self-attention while avoiding its shortcomings, and presents a neural network based on LKA, namely Visual Attention Network (VAN)."}, "embedding": {"model": "specter_v2", "vector": [0.15349231660366058, 0.6112030744552612, -0.21538423001766205, 0.011718297377228737, 0.10584276914596558, 0.19807499647140503, 0.4160497486591339, -0.4047921597957611, -0.3219614028930664, -0.7259796261787415, 0.40470534563064575, 1.0779833793640137, 0.6122645735740662, -0.1852157711982727, -0.1522374153137207, 0.16562983393669128, -0.7195888161659241, -0.20064030587673187, 1.041472315788269, -0.1946001499891281, 0.177420973777771, -0.7820730209350586, -1.2142137289047241, 0.1461089551448822, -0.024088427424430847, 0.951571524143219, 0.640358567237854, 1.0537680387496948, -0.08124270290136337, 0.069997139275074, 0.31370481848716736, -0.016779860481619835, 0.2061738222837448, 0.06400400400161743, -0.5814489722251892, 0.11535172164440155, 0.898507297039032, -0.12997961044311523, -0.84914630651474, 0.9991530776023865, -0.0988449975848198, 0.46680518984794617, 0.5897886157035828, -0.5432413220405579, -0.36772242188453674, 0.1653546690940857, 0.271544873714447, 0.9462838172912598, -0.31678497791290283, -0.5017402768135071, 1.2743505239486694, -0.923471212387085, 0.40054160356521606, 1.8875219821929932, 0.35665327310562134, 0.37495729327201843, -0.13378311693668365, -0.38595491647720337, 0.6271920204162598, 0.3335763216018677, -0.6255787014961243, 0.025041209533810616, 0.17386586964130402, -0.2900213599205017, 1.5636323690414429, -0.6990247964859009, 0.48168158531188965, 0.8270448446273804, 0.3186366558074951, 1.312685251235962, -0.17417868971824646, -0.5460137724876404, -0.2857857644557953, -0.10224319994449615, 0.39020776748657227, 0.746418297290802, -0.17929577827453613, 0.3192943334579468, -0.6460698843002319, 0.2571848928928375, 0.9315938949584961, 0.021255681291222572, 0.5097784399986267, -0.6298760771751404, -0.15868140757083893, 0.6661295294761658, 0.9631399512290955, 0.5149901509284973, -0.27046850323677063, 1.1822344064712524, 0.5638291239738464, -0.3373347222805023, -0.32023289799690247, 0.3684612512588501, 0.3476911187171936, 1.0304359197616577, -0.652737021446228, 0.0718989446759224, -0.28067952394485474, 1.0391209125518799, 0.039991967380046844, 0.45768502354621887, -0.47530338168144226, 0.09344402700662613, 1.2466661930084229, 0.25297629833221436, 0.28276142477989197, -0.7852181792259216, -0.3039562702178955, -0.7112406492233276, -0.269795298576355, -1.4558380842208862, -0.07092508673667908, -0.39132213592529297, -0.7154731750488281, -0.6317086815834045, -0.2458767145872116, 0.6234830617904663, -0.9962667226791382, 0.34799328446388245, -0.08127778023481369, -0.036219168454408646, -0.14303095638751984, 0.5860012173652649, 0.7226203680038452, 0.450772225856781, 0.22426411509513855, 0.6433702707290649, 1.5817582607269287, -1.2392064332962036, -0.5147035717964172, -0.9794338941574097, -0.5082278847694397, -0.3401310443878174, -0.009042460471391678, -0.3117136061191559, -0.8883373141288757, -1.4759916067123413, -0.8511924147605896, 0.01931261271238327, -0.6693649888038635, 0.04592764750123024, 0.9913834929466248, 0.06510249525308609, -0.842833399772644, 0.8749471306800842, -0.2325057089328766, -0.8486171364784241, 0.759032130241394, -0.022275788709521294, 0.3285449743270874, 0.02996121533215046, -1.0215569734573364, 0.35563787817955017, 0.16526539623737335, -0.32577282190322876, -0.6046327352523804, 0.1494389772415161, -1.3083138465881348, -0.040657445788383484, 0.476900577545166, -0.46453413367271423, 1.0056966543197632, -0.46108847856521606, -0.8137831687927246, 0.6481464505195618, -0.17843419313430786, -0.22720922529697418, 0.1264030784368515, -0.5176947116851807, -0.1801302284002304, -0.013254866003990173, 0.10361013561487198, 0.8476455211639404, 0.8971452116966248, -0.3164860010147095, -0.15404389798641205, -0.012237845920026302, -0.44862663745880127, -0.18625669181346893, -0.3829740881919861, 1.019221544265747, -1.0162321329116821, -0.5569418668746948, 0.3653689920902252, 0.22487397491931915, -0.1677941381931305, -0.24012112617492676, -0.2683349847793579, -1.2155306339263916, 1.0381203889846802, 0.31819120049476624, 0.5000851154327393, -0.8431271314620972, -0.9945610761642456, -0.3560636341571808, -0.03567245602607727, -0.13006770610809326, -1.0135186910629272, 0.28536006808280945, -0.25312262773513794, 0.13543838262557983, 0.3003787398338318, -0.585515558719635, -0.25599342584609985, -0.3122279942035675, -0.5058817267417908, 0.19957201182842255, 0.45611771941185, 1.2438100576400757, -1.0768882036209106, -0.47870951890945435, 0.22187334299087524, 0.11753567308187485, -0.7630001902580261, 1.0130614042282104, -0.6346225142478943, -0.0434127040207386, -0.31723394989967346, 0.12542442977428436, 0.16175585985183716, -0.31902894377708435, 0.11812826991081238, -0.7143130302429199, 0.007332881446927786, 0.1313735693693161, -0.22663313150405884, 1.1537082195281982, -0.033482637256383896, 1.0010852813720703, -0.3193383514881134, -0.5758973956108093, 0.3091728091239929, 0.15895071625709534, -0.14826907217502594, -0.6461995840072632, 0.49311670660972595, -0.4693513512611389, -0.874301016330719, -0.20036780834197998, 0.6217946410179138, 1.6576159000396729, -0.47165852785110474, -0.030743258073925972, 0.8160480856895447, -0.355598509311676, -0.12932638823986053, 0.5175043940544128, 0.3703634738922119, 0.4897984266281128, 0.48677700757980347, -0.34064510464668274, -0.07865475863218307, -0.6948406100273132, 0.12732400000095367, 0.8908781409263611, 0.18290425837039948, 1.178754448890686, 0.350929319858551, -1.054596185684204, -0.764542281627655, 0.21047037839889526, 0.49772578477859497, 1.4705513715744019, 0.34247398376464844, -0.0827578529715538, -0.7677332758903503, -0.5611736178398132, -0.2884593605995178, -0.4928622245788574, -1.093052625656128, -0.01263720914721489, -0.31127581000328064, -0.9233929514884949, 0.7074791193008423, 0.6614215970039368, 1.341369390487671, -0.9571487903594971, -0.7437338829040527, -0.1516762673854828, 0.5410447716712952, -1.0471763610839844, -0.7841825485229492, 0.2360943704843521, -0.025655101984739304, -0.4167342782020569, -0.03034861572086811, -0.29259127378463745, 0.19605255126953125, -0.18969477713108063, 0.5893150568008423, -0.8438679575920105, -0.5047888159751892, 0.3438326418399811, 0.3336540758609772, -1.0094993114471436, -0.1725313365459442, 0.29015976190567017, 0.2149609923362732, -0.061324480921030045, 0.17619015276432037, 0.4204094111919403, -0.48345065116882324, 0.5292866826057434, -0.3515627086162567, -0.3252972960472107, 0.33343929052352905, -0.1089799702167511, 0.7216299772262573, -0.28398391604423523, 0.2954108417034149, -1.0835516452789307, 0.3294914960861206, 0.3033580780029297, -0.4549393653869629, 0.09520629793405533, -0.37243348360061646, -0.34705808758735657, -0.03723200038075447, -0.7008056640625, -0.255060076713562, -0.063491590321064, 0.5492997169494629, -0.8175165057182312, -0.40815263986587524, -0.43234315514564514, 0.3032459616661072, -0.46256160736083984, 0.7071370482444763, 0.21604493260383606, 0.3670726716518402, 0.2217678278684616, 0.46455076336860657, -0.9469956159591675, 1.1304829120635986, 0.4002489149570465, 0.24889975786209106, 0.2939191162586212, 0.038351330906152725, -0.910587728023529, -0.7678017616271973, -0.866711437702179, -0.6779085993766785, -0.6710246801376343, 0.9618331789970398, -0.45620983839035034, -0.9496178030967712, 0.04145171865820885, -0.944595456123352, -0.18180924654006958, 0.19007174670696259, -0.2083311378955841, -0.4575296640396118, -0.7703094482421875, -0.6205003261566162, -0.5545943975448608, -0.6702081561088562, -0.8399044871330261, 0.21551911532878876, 0.5390796065330505, -0.39878761768341064, -0.3497423231601715, -0.2218131422996521, -0.5004953742027283, 1.100823163986206, 0.07785449922084808, 0.10376019030809402, -0.11223887652158737, -0.5011079907417297, -0.4650944173336029, -0.44282156229019165, 0.45549899339675903, -0.15646442770957947, 0.16222567856311798, -0.9487793445587158, 0.4362808167934418, -0.3547567129135132, -0.3283635079860687, 0.7815989851951599, 0.603144645690918, 0.8089193105697632, 0.4390675723552704, -0.5874322056770325, 0.25482237339019775, 1.445291519165039, -0.7694593667984009, 0.2535974681377411, 0.14432476460933685, 0.9808229804039001, 0.2902824580669403, -0.17414970695972443, 0.18786685168743134, 0.6000543832778931, 0.44850966334342957, 0.8263505101203918, -0.33577612042427063, -0.6691026091575623, -0.46290159225463867, 0.048821479082107544, 0.8192765116691589, 0.034416086971759796, 0.4514935314655304, -0.8105349540710449, 1.2091209888458252, -1.1510342359542847, -0.9116809964179993, 0.6405856013298035, 0.6315063834190369, -0.24094930291175842, -0.34846824407577515, -0.04752294719219208, -0.9654431939125061, 0.8846086263656616, 0.5868122577667236, -0.6772595643997192, -0.37250861525535583, -0.1702532023191452, 0.18186146020889282, 0.35862433910369873, 0.4952758252620697, -1.1547625064849854, 0.962847113609314, 14.789841651916504, 0.6192481517791748, -0.1141897514462471, 0.2966477572917938, 0.6218934059143066, 0.8711605072021484, 0.2214202880859375, 0.08202797919511795, -1.1695504188537598, -0.22743676602840424, 0.244406059384346, 0.41699403524398804, 0.230425626039505, 0.693191647529602, -0.21349309384822845, 0.12020949274301529, -0.3407261371612549, 0.829505443572998, 0.8977271318435669, -1.0104718208312988, 0.010671164840459824, 0.19487880170345306, 0.2991924583911896, 0.5464869141578674, 0.6327100396156311, 0.46313560009002686, 0.4737221300601959, -0.23657499253749847, 0.19343923032283783, 0.3362102210521698, 0.9076876640319824, 0.16099128127098083, 0.21187953650951385, -0.10046910494565964, -1.2264167070388794, -0.2594413757324219, -0.9028491377830505, -0.6229906678199768, 0.12714995443820953, -0.317341148853302, -0.14335958659648895, -0.6453234553337097, 0.3752484917640686, 0.417375773191452, -0.2352386862039566, 0.7095767855644226, -0.16524599492549896, -0.02879619598388672, 0.14302539825439453, -0.30640608072280884, 0.5535962581634521, 0.8998490571975708, 0.36695295572280884, 0.4466802477836609, -0.2797590494155884, 0.6140761375427246, 0.2591779828071594, 0.35969433188438416, -0.18133527040481567, -0.22784769535064697, -0.20798230171203613, 0.026237020269036293, -0.43938979506492615, 0.9988524913787842, -0.0037187840789556503, -0.01835647039115429, -0.13476435840129852, 0.4424281120300293, 0.11299557238817215, 0.07777915149927139, -0.46691009402275085, -0.42156368494033813, 0.24231965839862823, -0.288994699716568, 0.5533448457717896, 0.3477873206138611, -0.17964908480644226, -0.4564806818962097, -1.0046449899673462, 0.06890348345041275, 0.6065661311149597, -1.0000700950622559, -0.8404837846755981, 1.388551115989685, -0.27198994159698486, -0.11956354975700378, 0.571418285369873, -0.8337467908859253, -0.4302815794944763, 0.05618686601519585, -1.016738772392273, -0.6297215819358826, -0.41190335154533386, -0.46259593963623047, 0.021990863606333733, -0.05960119143128395, 0.6102317571640015, -0.12731194496154785, -0.16514892876148224, 0.12539632618427277, -0.6858269572257996, 0.3762383460998535, 0.0710797980427742, -0.611563503742218, 0.9017929434776306, 0.3327997326850891, -0.3805391490459442, -0.20452852547168732, 0.03576931729912758, -0.10748253762722015, -0.41657230257987976, -0.20515887439250946, 0.2709297835826874, -0.7975315451622009, -0.5887942314147949, -0.7395491003990173, -1.0836454629898071, 0.0020557409152388573, 1.0415399074554443, 0.21141502261161804, -0.36236777901649475, -0.0879335105419159, -0.5960517525672913, -0.17252634465694427, -0.5930634140968323, -0.09082125127315521, 0.162775918841362, -0.5071372389793396, -0.4436447322368622, -0.31601014733314514, 0.45066747069358826, -0.7776394486427307, -0.2516041100025177, 0.009489670395851135, 0.4925365447998047, -0.06567685306072235, 1.3392890691757202, -0.4460603892803192, 0.5444690585136414, 0.5259373784065247, -0.23381824791431427, -0.3639584481716156, -0.5383380055427551, -0.704921305179596, 0.2140561044216156, 0.1558024138212204, -0.06735437363386154, -0.008411508053541183, 0.4573853611946106, 0.6454692482948303, 0.3853589594364166, -0.6460769772529602, -0.19020715355873108, -0.23726209998130798, -0.25489482283592224, -0.594094455242157, -0.11072319746017456, -0.01641080528497696, -0.1939622163772583, 0.19331128895282745, 0.3135433495044708, 0.596583902835846, 0.3410034775733948, -0.44856083393096924, 0.6328723430633545, -0.2394285798072815, -0.0403064601123333, -0.5574349761009216, -0.9492949843406677, -1.6065363883972168, -0.22414036095142365, -0.9429728984832764, -0.026956049725413322, -1.041243314743042, -0.28683826327323914, 0.41740334033966064, -0.32608717679977417, -0.006448985077440739, 0.3464016318321228, 0.016961922869086266, -0.010408199392259121, -0.5718383193016052, -0.9570668339729309, 0.7185764312744141, 1.2792631387710571, -0.808998703956604, -0.010251255705952644, 0.17344827950000763, -0.12017332762479782, 0.7581787109375, 0.2187877893447876, -0.531179666519165, -0.2853168249130249, -0.8994752764701843, 0.09017129242420197, -0.3308025598526001, 0.18553614616394043, -1.2552770376205444, 1.2086279392242432, 0.408976674079895, 0.3723425269126892, -0.49063995480537415, 0.44413572549819946, -0.646399199962616, -0.9271371960639954, 0.32218846678733826, -0.5450776219367981, 0.04535587131977081, 0.1346219927072525, 0.08236321061849594, -0.34055668115615845, 0.9779399037361145, 0.40995338559150696, -1.3594187498092651, -1.2864466905593872, 0.5214465260505676, -0.5387185215950012, 0.1188357025384903, 0.06279885023832321, -0.2693139612674713, -1.0697665214538574, -0.5031506419181824, -0.49276673793792725, 0.42206522822380066, -0.6886365413665771, 1.0951472520828247, 0.7484752535820007, -1.2590034008026123, 0.0860217809677124, 0.46832025051116943, -0.039181362837553024, 0.2677123546600342, 0.8220174312591553, 0.28597357869148254, -0.28487783670425415, 0.46466007828712463, -0.0805051177740097, -0.026047509163618088, -0.7565298080444336, 0.5264788269996643, 1.0202544927597046, 0.1714756041765213, -0.1391884833574295, 0.9675049185752869, 0.3768235146999359, -0.7615739107131958, 0.35107892751693726, -0.7839720249176025, -0.7403025031089783, 0.20067085325717926, 0.499683678150177, 0.17636987566947937, -0.39807140827178955, -0.361416220664978, -0.6545162200927734, 0.6833993792533875, -0.09910661727190018, -0.48832008242607117, 0.4638110399246216, -0.16697941720485687, -0.09660216420888901, 0.3145112991333008, 0.8843492865562439, -0.7894485592842102, -1.1806784868240356, -1.096299648284912, -0.5713734030723572, -0.3937588632106781, -0.07807160168886185, -0.022550644353032112, -0.8803679943084717, 0.7642426490783691, 0.7175543904304504, 0.5746029615402222, 0.14925727248191833, 0.46895673871040344, 0.02959614247083664, 0.5864136815071106, -0.4065433740615845, -0.7210535407066345, 0.3397490084171295, 1.4090244770050049, 1.4018115997314453, -0.63667893409729, 0.28163576126098633, -0.5480808615684509, -0.9284666180610657, 1.0208204984664917, 0.6491327881813049, -0.8259763717651367, 1.0280747413635254, -0.60614413022995, 0.17423376441001892, 0.0714954361319542, -0.7863836884498596, -0.7975094318389893, 1.1393626928329468, 1.1317894458770752, 0.07936440408229828, 0.054575737565755844, 0.45418962836265564, 0.4990164041519165, 0.2645663321018219, -0.29799163341522217, 0.5531497001647949, -0.2437848001718521, -0.36537405848503113, 0.41181471943855286, -0.15801182389259338, 0.3795818090438843, -0.6100096702575684, -0.03188705071806908, 0.11234768480062485, 0.5460130572319031, 0.14901211857795715, 0.25241681933403015, 1.3236110210418701, -0.1515788435935974, 0.4967251718044281, -0.15528929233551025, 0.46519801020622253, -0.46426162123680115, 0.009635784663259983, 0.31119459867477417, -0.9055101275444031, -0.36997562646865845, -0.5230889320373535, -1.1240723133087158, -0.00028271955670788884, 0.42116883397102356, -0.03248262405395508, -0.503654956817627, 0.3973071575164795, 0.6446501016616821, 0.6097057461738586, 0.7346804141998291, -0.28390365839004517, -0.7398073077201843, -0.03374314308166504, -0.9604548811912537, 0.3139995336532593, -0.440498024225235, -0.06096351146697998, -0.4869198501110077, 0.23556439578533173, -0.33803343772888184]}, "authors": [{"authorId": "2088775481", "name": "Meng-Hao Guo"}, {"authorId": "51211520", "name": "Chengrou Lu"}, {"authorId": "79305819", "name": "Zheng-Ning Liu"}, {"authorId": "2149615771", "name": "Ming-Ming Cheng"}, {"authorId": "51265060", "name": "Shiyong Hu"}], "references": [{"paperId": "1504ab3e1ae7af39bbf3dba62b132ec027611c38", "title": "MixFormer: Mixing Features across Windows and Dimensions"}, {"paperId": "fa717a2e31f0cef4e26921f3b147a98644d2e64c", "title": "Focal Modulation Networks"}, {"paperId": "9f1b0e4c42a5a85d4c023030557ade4419f82ecf", "title": "Scaling Up Your Kernels to 31\u00d731: Revisiting Large Kernel Design in CNNs"}, {"paperId": "004f1d2b1b7d7dcecafdd94daee9c1b0aa3e65cf", "title": "DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "15b0e710a9b8069d898ae6a0963d627e0fb86bd8", "title": "MPViT: Multi-Path Vision Transformer for Dense Prediction"}, {"paperId": "658a017302d29e4acf4ca789cb5d9f27983717ff", "title": "Masked-attention Mask Transformer for Universal Image Segmentation"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "45f686be3b96302ede327645227134e1c304dbab", "title": "Attention mechanisms in computer vision: A survey"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "f8a287be26c30b4362f9504ba01e4e7269790c60", "title": "Are we ready for a new paradigm shift? A survey on visual deep MLP"}, {"paperId": "5e2180e4ce9d218cccb1c78a93a863d5f967d907", "title": "Transformers in computational visual media: A survey"}, {"paperId": "f829a355de02c08567927154d3045a6eb5425c91", "title": "Is Attention Better Than Matrix Decomposition?"}, {"paperId": "7809f2f509b5bd1ce3d8b9a89ef25a755dd729a2", "title": "FuseFormer: Fusing Fine-Grained Information in Transformers for Video Inpainting"}, {"paperId": "60439bf4e0f8178cb230b7685bf01d703f3ec0bf", "title": "Query2Label: A Simple Transformer Way to Multi-Label Classification"}, {"paperId": "0b036cd5dfc49d835d0c759c8ca31d89f2410e65", "title": "CMT: Convolutional Neural Networks Meet Vision Transformers"}, {"paperId": "48418b285a92376a38daafa664a2dd07d42e3fe3", "title": "Focal Self-attention for Local-Global Interactions in Vision Transformers"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "ba1b51e872cdf7744a50b1b2e76ee8b85a0d0dfd", "title": "P2T: Pyramid Pooling Transformer for Scene Understanding"}, {"paperId": "7fff8018bf625447df837c2fda5c58a705fbc038", "title": "XCiT: Cross-Covariance Image Transformers"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "576c462dbc1f3d732b919ef1daac37a817123e52", "title": "ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias"}, {"paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60", "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"}, {"paperId": "ba80068a716c231f0839e4e1b5b3d5181903f1a2", "title": "Can attention enable MLPs to catch up with CNNs?"}, {"paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de", "title": "Pay Attention to MLPs"}, {"paperId": "48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5", "title": "ResMLP: Feedforward Networks for Image Classification With Data-Efficient Training"}, {"paperId": "fc92009ab34045f9e6d490684c7761f768e88c54", "title": "Beyond Self-Attention: External Attention Using Two Linear Layers for Visual Tasks"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "cc3432e6e231955f156f5051091c353c7209f464", "title": "Decoupled Spatial-Temporal Transformer for Video Inpainting"}, {"paperId": "5b68522f58b61e7235b852677337ef3725075fd9", "title": "Co-Scale Conv-Attentional Image Transformers"}, {"paperId": "8f8f73f0f208302546c825ed474432389ed63be4", "title": "EfficientNetV2: Smaller Models and Faster Training"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "9efe8dbde586d6248ecfc69f08b918012e2ac478", "title": "Revisiting ResNets: Improved Training and Scaling Strategies"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "cec7872b194aadf54140578b9be52939eb1112e9", "title": "LambdaNetworks: Modeling Long-Range Interactions Without Attention"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78", "title": "Bottleneck Transformers for Visual Recognition"}, {"paperId": "ec8557caf54e71425624a73de5c607feb742693d", "title": "EDN: Salient Object Detection via Extremely-Downsampled Network"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "1834a1ff37052895c42906ceb163d9306badc00b", "title": "FcaNet: Frequency Channel Attention Networks"}, {"paperId": "ff50b46b4e1cc0fd9beb832fc3468785b635a824", "title": "PCT: Point cloud transformer"}, {"paperId": "6d5f423164cd5ef9324281652987c8a65009e98e", "title": "Sparse R-CNN: End-to-End Object Detection with Learnable Proposals"}, {"paperId": "7b760f0468a520bc25a813b3f29664a92beb200a", "title": "Jittor: a novel deep learning framework with meta-operators and unified graph execution"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "da60e046aac895b5775ed34bde45beb86aad0fe8", "title": "Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection"}, {"paperId": "a9d93e3b418039f4423fbcb5db99fcef050c1e0b", "title": "D2Det: Towards High Quality Object Detection and Instance Segmentation"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "448529da2bf004cf79084401ad3cbd6b511e4969", "title": "Bridging the Gap Between Anchor-Based and Anchor-Free Detection via Adaptive Training Sample Selection"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "8cb34cbdcf65c23ef98430441b14a648c4e8d992", "title": "ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks"}, {"paperId": "a88c914f5a738d38f02790bb5de41453bf17bde1", "title": "Object-Contextual Representations for Semantic Segmentation"}, {"paperId": "441555b5cd09703e55c03e70bd2c9f82c0ffcf9b", "title": "Deep High-Resolution Representation Learning for Visual Recognition"}, {"paperId": "bc626a52664e948a0ffb2b95d0e1e6377a01171a", "title": "Cascade R-CNN: High Quality Object Detection and Instance Segmentation"}, {"paperId": "c2c083df88e88223e1a411e61040b94c233b1b63", "title": "MMDetection: Open MMLab Detection Toolbox and Benchmark"}, {"paperId": "d6dccb5d71fbb6f5765f89633ba3a8e6809a720d", "title": "Stand-Alone Self-Attention in Vision Models"}, {"paperId": "f8de25118af2abc4c48afb947d6ec298e05ef1e5", "title": "When Does Label Smoothing Help?"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "27ac832ee83d8b5386917998a171a0257e2151e2", "title": "Attention Augmented Convolutional Networks"}, {"paperId": "2a69ddbafb23c63e5e22401664bea229daaeb7d6", "title": "Res2Net: A New Multi-Scale Backbone Architecture"}, {"paperId": "a84906dbd4d6640f918d0b6ed2a7313dda0d55f1", "title": "Panoptic Feature Pyramid Networks"}, {"paperId": "5132500b23d2da47129b3f4f68dd30947a29e502", "title": "CCNet: Criss-Cross Attention for Semantic Segmentation"}, {"paperId": "cd8ddaaf56e38dddafdeac3f9643b9b5e9d35d54", "title": "Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks"}, {"paperId": "ad655c25e052fa4eeed53421344aca6f239c4c9d", "title": "Dual Attention Network for Scene Segmentation"}, {"paperId": "796a6e78d4c4b63926ee956f202d874a8c4542b0", "title": "OCNet: Object Context Network for Scene Parsing"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "de95601d9e3b20ec51aa33e1f27b1880d2c44ef2", "title": "CBAM: Convolutional Block Attention Module"}, {"paperId": "10bb4ef7a6719ea132e00f0ab5680919a4131d99", "title": "BAM: Bottleneck Attention Module"}, {"paperId": "36777066966899fb48c1850d5776af97f1c81942", "title": "Attentional ShapeContextNet for Point Cloud Recognition"}, {"paperId": "a8f3dc53e321fbb2565f5925def4365b9f68d1af", "title": "Self-Attention Generative Adversarial Networks"}, {"paperId": "dc9187434a1c27306c61a3317aa942d3402d97c3", "title": "Simple Baselines for Human Pose Estimation and Tracking"}, {"paperId": "921196c32213a229245a9705ee4768bc941e7a26", "title": "An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling"}, {"paperId": "9217e28b2273eb3b26e4e9b7b498b4661e6e09f5", "title": "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation"}, {"paperId": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4", "title": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"}, {"paperId": "6a0aaefce8a27a8727d896fa444ba27558b2d381", "title": "Relation Networks for Object Detection"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "79cfb51a51fc093f66aac8e858afe2e14d4a1f20", "title": "Focal Loss for Dense Object Detection"}, {"paperId": "bf9aee2857c39cfcc8f468aa93c81f48e2453d89", "title": "Learning to Detect Salient Objects with Image-Level Supervision"}, {"paperId": "9da734397acd7ff7c557960c62fb1b400b27bd89", "title": "ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "77d30cf9a34fb6b50979c6a68863099da9a060ad", "title": "Residual Attention Network for Image Classification"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "4a73a1840945e87583d89ca0216a2c449d50a4a3", "title": "Deformable Convolutional Networks"}, {"paperId": "01a4f33da8ad94ced3cf58548b28dbbb44148571", "title": "Understanding the Effective Receptive Field in Deep Convolutional Neural Networks"}, {"paperId": "88513e738a95840de05a62f0e43d30a67b3c542e", "title": "SCA-CNN: Spatial and Channel-Wise Attention in Convolutional Networks for Image Captioning"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "5582bebed97947a41e3ddd9bd1f284b73f1648c2", "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"}, {"paperId": "5694e46284460a648fe29117cbc55f6c9be3fa3c", "title": "Densely Connected Convolutional Networks"}, {"paperId": "88512be44744615f4baa8e14f600f036db4c2433", "title": "Semantic Understanding of Scenes Through the ADE20K Dataset"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "31f9eb39d840821979e5df9f34a6e92dd9c879f2", "title": "Learning Deep Features for Discriminative Localization"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "7f5fc84819c0cf94b771fe15141f65b123f7b8ec", "title": "Multi-Scale Context Aggregation by Dilated Convolutions"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "39ad6c911f3351a3b390130a6e4265355b4d593b", "title": "Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs"}, {"paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327", "title": "Going deeper with convolutions"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "8a756d4d25511d92a45d0f4545fa819de993851d", "title": "Recurrent Models of Visual Attention"}, {"paperId": "40e71c10edc2afc68d079546e8f4952cd52dc671", "title": "The Secrets of Salient Object Segmentation"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "1109b663453e78a59e4f66446d71720ac58cec25", "title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks"}, {"paperId": "5e83ab70d0cbc003471e87ec306d27d9c80ecb16", "title": "Network In Network"}, {"paperId": "699d4d8c8b91b1a34dd6f47d28e3fe1236f25944", "title": "Saliency Detection via Graph-Based Manifold Ranking"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "a48a56b0727d09f599676524fe190308d9e88bf1", "title": "Caltech-UCSD Birds 200"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "74bd3bfd66c49d22bb1094ad4f7eb57d0f902523", "title": "What attributes guide the deployment of visual attention and how do they do it?"}, {"paperId": "839e0a5e15fec789181285d57c9fad2b26bd0042", "title": "The representation of visual salience in monkey parietal cortex"}, {"paperId": "8930f62a4b5eb1cbabf224cf84aa009ea798cfee", "title": "Modeling Visual Attention via Selective Tuning"}, {"paperId": "6dc61f37ecc552413606d8c89ffbc46ec98ed887", "title": "Acceleration of stochastic approximation by averaging"}, {"paperId": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27", "title": "Backpropagation Applied to Handwritten Zip Code Recognition"}, {"paperId": "319f22bd5abfd67ac15988aa5c7f705f018c3ccd", "title": "Learning internal representations by error propagation"}, {"paperId": "76361a44e145732a39dbc68d9418871038c83be2", "title": "A feature-integration theory of attention"}, {"paperId": "5d11aad09f65431b5d3cb1d85328743c9e53ba96", "title": "The perceptron: a probabilistic model for information storage and organization in the brain."}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "7dee2bc2be709c0009b7623b7af78246f32e0a60", "title": "Demystifying Local Vision Transformer: Sparse Connectivity, Weight Sharing, and Dynamic Weight"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Layer normalization (2016"}, {"paperId": "7d76a09aa363685bc0f04a502ed853dc09a574e2", "title": "Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}, {"paperId": null, "title": "\u201cResmlp: Feed-forward"}]}