{"paperId": "fcf839ee33de3e2df9e6002d6298650b74e37067", "title": "ShareBERT: Embeddings Are Capable of Learning Hidden Layers", "abstract": "The deployment of Pre-trained Language Models in memory-limited devices is hindered by their massive number of parameters, which motivated the interest in developing smaller architectures.\nEstablished works in the model compression literature showcased that small models often present a noticeable performance degradation and need to be paired with transfer learning methods, such as Knowledge Distillation. \nIn this work, we propose a parameter-sharing method that consists of sharing parameters between embeddings and the hidden layers, enabling the design of near-zero parameter encoders. To demonstrate its effectiveness, we present an architecture design called ShareBERT, which can preserve up to 95.5%\nof BERT Base performances, using only 5M parameters (21.9\u00d7 fewer parameters) without the help of Knowledge Distillation. We demonstrate empirically that our proposal does not negatively affect the model learning capabilities and that it is even beneficial for representation learning. Code will be available at https://github.com/jchenghu/sharebert.", "venue": "AAAI Conference on Artificial Intelligence", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://ojs.aaai.org/index.php/AAAI/article/download/29781/31348", "status": "GOLD"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes a parameter-sharing method that consists of sharing parameters between embeddings and the hidden layers, enabling the design of near-zero parameter encoders, and presents an architecture design called ShareBERT, which can preserve up to 95.5% of BERT Base performances, using only 5M parameters."}, "embedding": {"model": "specter_v2", "vector": [-0.05410205200314522, 0.7200379967689514, -0.8709843754768372, 0.33109021186828613, -0.1470911204814911, 0.10242989659309387, 0.5161822438240051, -0.37253493070602417, -0.6442392468452454, -0.3170170783996582, 0.5884695649147034, -0.08465584367513657, 0.48990392684936523, 0.16295300424098969, -0.23292431235313416, 0.12113878130912781, -0.7590025663375854, 0.3733516037464142, 0.05649389699101448, -0.3004704713821411, -0.271893173456192, -0.598491907119751, -0.7639793157577515, 0.02819477953016758, 0.17204463481903076, 0.9467960000038147, 0.16528384387493134, 0.8726312518119812, -0.4929964244365692, 0.16964764893054962, 0.7121753096580505, -0.328747421503067, 0.19589348137378693, 0.06434423476457596, -0.027572331950068474, -0.26604199409484863, 0.1504538506269455, -0.5764369964599609, -0.5422164797782898, 0.7338754534721375, -0.1804903745651245, 0.30266454815864563, 0.5023084878921509, -0.6390073299407959, -0.08707600086927414, 0.527057409286499, 0.6752704381942749, 0.5080772638320923, -0.7191477417945862, -0.4161936044692993, 0.775985836982727, -1.4614368677139282, 0.009562383405864239, 1.2434508800506592, 0.8116337060928345, 0.21893630921840668, -0.20570218563079834, -0.5569895505905151, 0.37924283742904663, 0.10594472289085388, -1.0741664171218872, -0.35060277581214905, 0.04244548827409744, 0.1565641611814499, 1.8525437116622925, -0.22749535739421844, 0.19677531719207764, 0.6379097104072571, -0.44704365730285645, 0.8758680820465088, -0.020082887262105942, -0.7937667965888977, -0.2515003979206085, 0.5247278809547424, 0.2462916076183319, 1.0237352848052979, -0.08956820517778397, 0.34212467074394226, -0.878449022769928, -0.11757293343544006, 0.24006669223308563, -0.14442646503448486, 0.14705903828144073, -0.25432536005973816, -0.03246951475739479, 0.8104161024093628, 0.4387250542640686, 0.47860127687454224, 0.11771421134471893, 1.1318832635879517, 0.5593776702880859, 0.31402063369750977, 0.33914902806282043, 0.2941552400588989, -0.10401663929224014, 0.23831021785736084, -0.8133755326271057, 0.012184572406113148, 0.3182293474674225, 0.8753519058227539, 0.05413183569908142, 0.5010728240013123, -0.28199678659439087, 0.10124809294939041, 1.4386078119277954, 0.07513651251792908, 0.9088656902313232, -0.708838701248169, 0.47642162442207336, -1.025403618812561, -0.1568363904953003, -0.7715457081794739, 0.22076867520809174, -0.25322386622428894, -0.8470088839530945, -1.4748870134353638, -1.1571818590164185, 0.00829185638576746, -0.7032655477523804, 0.573076069355011, -0.6884364485740662, 0.7284268736839294, 0.13687853515148163, 0.38341018557548523, 0.6146668791770935, 0.8172189593315125, 0.2630341947078705, 0.14034579694271088, 0.8205991387367249, -1.2013416290283203, -0.8390960693359375, -0.9604747891426086, 0.5787913799285889, -0.26698023080825806, 0.27788135409355164, -0.4002953767776489, -1.271051049232483, -0.9859078526496887, -1.2224040031433105, -0.03606441617012024, -0.8583747744560242, 0.43180277943611145, 0.7696607112884521, 0.7328386902809143, -0.9513376355171204, 1.0760736465454102, -0.47446581721305847, 0.05250691622495651, 0.5298497080802917, 0.38826239109039307, 0.22105836868286133, -0.1618512123823166, -1.0410408973693848, 0.6570472121238708, 0.8951507210731506, -0.6599643230438232, 0.052790846675634384, -0.8601702451705933, -0.9781886339187622, 0.22954212129116058, 0.3804081380367279, -0.5918685793876648, 0.9097851514816284, 0.2674890458583832, -1.5441237688064575, 0.40924832224845886, -0.3176926076412201, -0.09246555715799332, 0.4380083978176117, -0.5916605591773987, -0.5381022095680237, -0.14527133107185364, -0.9618404507637024, 0.521716833114624, 0.8392258286476135, -0.3389316499233246, 0.5221119523048401, 0.6687710285186768, -0.5886067748069763, 0.121330626308918, -0.681813657283783, 0.6935172080993652, -0.6611072421073914, -0.3335200250148773, 0.3078204393386841, 0.2966523766517639, 0.10090592503547668, -0.028666408732533455, -0.6916732788085938, -0.34424448013305664, 1.0843077898025513, -0.10377223044633865, 1.0999966859817505, -0.9725696444511414, -0.7268258333206177, 0.26545318961143494, -0.16355371475219727, 0.3625229299068451, -0.8829821348190308, 0.36106812953948975, -0.37071311473846436, 0.7108825445175171, -0.3726038932800293, -1.6601946353912354, 0.5080975890159607, -0.0015155505388975143, -0.9400901794433594, -0.24136140942573547, 0.03252829238772392, 1.2101390361785889, -0.4667254686355591, 0.09115149825811386, 0.22368189692497253, 0.8733619451522827, -1.3448898792266846, 1.21415376663208, -0.20964747667312622, -0.1418417990207672, 0.28534749150276184, -0.42344701290130615, 0.11658335477113724, -0.19328992068767548, 0.391068696975708, -0.4964791536331177, 0.13863208889961243, 0.5871628522872925, -0.36286264657974243, 1.4007599353790283, -0.6171887516975403, 0.5238886475563049, -0.24409326910972595, -0.5567639470100403, 0.5249804854393005, 0.4263933300971985, -0.23675782978534698, -0.008899913169443607, 0.3491953909397125, 0.8358774185180664, -0.6317583322525024, 0.30429723858833313, 0.9287523031234741, 0.6086916327476501, -0.10504898428916931, 0.12872596085071564, 0.6762466430664062, -0.8027859330177307, 0.33480265736579895, 0.355686753988266, 0.33532825112342834, 0.11033404618501663, 0.2801934778690338, 0.4115680158138275, 0.12245112657546997, -1.1955828666687012, -0.3639061748981476, 0.15645308792591095, 0.7375805974006653, 1.1350140571594238, 0.2690698504447937, -0.5250065326690674, -0.6412339806556702, -0.3017832636833191, 0.9112873077392578, 0.8268728852272034, -0.29795587062835693, -0.39274415373802185, -0.5008202791213989, -0.1779160052537918, -0.099237821996212, 0.2303568720817566, -0.14222794771194458, -0.6408964991569519, -0.7580360174179077, -1.1575509309768677, 0.7436840534210205, -0.20488010346889496, 1.297897458076477, -0.28357625007629395, -0.30035099387168884, -0.5887965559959412, 0.433161199092865, -0.9398761987686157, -0.49041715264320374, 0.37233713269233704, -0.5591580867767334, -0.16185666620731354, 0.013141109608113766, 0.20077189803123474, 0.06007326394319534, -0.7072755098342896, 0.7643378973007202, -0.30877742171287537, -0.21322375535964966, 0.14710944890975952, 0.44831162691116333, -0.5788140296936035, -0.8552547693252563, 0.6089663505554199, 0.026571815833449364, -0.4977215528488159, 0.05573016777634621, 0.13203519582748413, -0.08034929633140564, -0.3431496024131775, -0.36010074615478516, 0.07436767220497131, -0.02803327888250351, -0.1972818523645401, 0.5435097813606262, -0.5472581386566162, -0.10167152434587479, -1.0276179313659668, 0.8659971356391907, -0.1569524109363556, -0.06708110868930817, 0.01756245829164982, -0.7743844985961914, -0.23305457830429077, 0.33609524369239807, -0.5736691355705261, -0.04921771585941315, -1.115492343902588, 0.08876974880695343, -0.8350808024406433, 0.030668335035443306, 0.08199873566627502, 0.611454427242279, 0.09488508850336075, -0.1997135877609253, 0.38068708777427673, 0.6204009652137756, -0.48985180258750916, 0.779316246509552, -1.0961155891418457, 0.5119969844818115, 0.7280675768852234, 0.45268747210502625, -0.229001984000206, 0.03014765866100788, -0.36702072620391846, -0.2736506462097168, -0.3245580494403839, -0.29009997844696045, 0.051725175231695175, 0.03904065489768982, -0.6505628228187561, -0.4100721776485443, -0.4485796391963959, -0.9061501622200012, -0.07284928858280182, -0.1885976642370224, 0.08210663497447968, -0.6001940965652466, -0.9452047944068909, -1.2229807376861572, -0.2535655200481415, -0.6278820633888245, -1.1813654899597168, 0.08536400645971298, -0.14413638412952423, -0.37544989585876465, -0.8903375864028931, 0.01959119737148285, -0.5846965909004211, 1.4442349672317505, -0.7708802223205566, 0.9407044649124146, -0.07891613990068436, -0.1686801016330719, -0.053860340267419815, 0.05437465012073517, 0.8901873826980591, -0.40091219544410706, 0.16463910043239594, -1.0868699550628662, 0.024608153849840164, -0.5486369132995605, -0.4152708649635315, 0.6805791854858398, -0.02108028531074524, 0.8494510650634766, -0.46457117795944214, -0.30355724692344666, 1.0249354839324951, 1.4808933734893799, -1.0406187772750854, 0.5211381912231445, 0.10034165531396866, 0.997519314289093, -0.21541988849639893, -1.031241774559021, 0.6083334684371948, 0.08553879708051682, 0.5572205781936646, 0.12637421488761902, -0.06060967966914177, -0.6634357571601868, -0.8384304046630859, 0.3842350244522095, 2.1609630584716797, 0.5462756156921387, 0.004017127212136984, -0.6579517126083374, 0.13530150055885315, -0.8180894255638123, -0.4510418474674225, 0.9421827793121338, 0.7771024107933044, 0.5252341032028198, -0.5407389402389526, -0.554052472114563, -0.05191740393638611, 0.33383527398109436, 0.6664940118789673, -0.3417360782623291, -0.9822478294372559, 0.004203428979963064, 0.572443425655365, 0.3190464675426483, 0.7753333449363708, -0.3096718490123749, 0.4114476144313812, 14.661039352416992, 0.9032106399536133, -0.20391471683979034, 0.6914277076721191, 0.7555118799209595, -0.09635239094495773, -0.36057642102241516, -0.2805212438106537, -0.9811220169067383, 0.26462170481681824, 1.5505671501159668, 0.20631606876850128, 0.5964533090591431, 0.04426002502441406, -0.1055721864104271, 0.427165150642395, -0.1366143375635147, 0.9525764584541321, 0.6776541471481323, -1.4820502996444702, 0.18539020419120789, 0.04813672602176666, 0.5226828455924988, 0.4181673228740692, 1.2750778198242188, 1.06428062915802, 0.11140181124210358, -0.6542144417762756, 0.3165852129459381, 0.5100536346435547, 1.1357508897781372, -0.284322589635849, 0.27305322885513306, 0.32949286699295044, -0.7304651737213135, 0.08178970962762833, -0.7309572100639343, -0.942991316318512, 0.4470537304878235, 0.2824954092502594, -0.795958399772644, -0.46336162090301514, -0.49078333377838135, 0.6978800892829895, -0.10299631953239441, 0.5035439133644104, -0.1775241494178772, 0.8442397117614746, -0.4745025634765625, 0.3637624680995941, 0.20533207058906555, 0.26957765221595764, 0.15988285839557648, 0.17206811904907227, 0.44527795910835266, -0.3984866738319397, 0.02786274254322052, 0.5365641713142395, -0.8532916307449341, -0.26920247077941895, -0.1757744997739792, -0.2994278073310852, 0.07109405100345612, 0.48663076758384705, 0.6398679614067078, 0.06106613948941231, -0.2835268974304199, 0.4595913290977478, 0.6902487874031067, 0.32797157764434814, -0.2495197057723999, 0.1333271712064743, 0.2256471812725067, -0.3716687560081482, 0.13559919595718384, 0.41634345054626465, -0.269036203622818, -0.4738645851612091, -0.6060583591461182, -0.1431025117635727, -0.10704294592142105, -0.7397504448890686, -0.2777372896671295, 0.6065022349357605, -0.03608781099319458, -0.1304212361574173, 0.00994031596928835, -0.5720078349113464, -0.19223441183567047, 0.3828854560852051, -1.8615435361862183, -0.4158411920070648, 0.4229055941104889, -0.6025392413139343, -0.6947587132453918, -0.33147913217544556, 1.6002185344696045, 0.35685452818870544, -0.4231753647327423, 0.14704932272434235, 0.30137330293655396, -0.40874186158180237, -0.24690011143684387, -0.48548394441604614, 0.8323269486427307, -0.23446349799633026, -0.24381829798221588, 0.19087688624858856, -0.12042439728975296, 0.33231139183044434, -0.6336249709129333, -0.3785572350025177, 0.7141730189323425, -0.39024463295936584, -0.40359818935394287, -0.5614445805549622, -0.7242385149002075, 0.2923292815685272, 0.4566507935523987, -0.09415661543607712, 0.622381865978241, -0.12562042474746704, -0.9233106970787048, 0.1477546989917755, -0.8171082735061646, -0.03930191323161125, 0.15145368874073029, -1.0629525184631348, -0.17690180242061615, -0.08107020705938339, 0.5345582365989685, -0.7726966738700867, -0.39711663126945496, 0.019602393731474876, -0.02778622880578041, -0.337880402803421, 1.2318284511566162, -0.23034873604774475, 0.832073986530304, 1.2145023345947266, -0.33968815207481384, -1.0021239519119263, 0.4551439583301544, -0.8427183628082275, -0.5240952968597412, -0.10618986189365387, 0.5257532596588135, -0.3442975878715515, 0.4975334107875824, 0.7263786792755127, -0.013944054953753948, -0.5573420524597168, -0.6899059414863586, -0.5364089608192444, 0.1227717250585556, -0.47018948197364807, 0.19633261859416962, -0.10323476791381836, -0.014192014001309872, -0.13759765028953552, 0.27339017391204834, -0.017245516180992126, -0.37496417760849, -1.309300422668457, 0.08833124488592148, 0.20726130902767181, -0.35490450263023376, -0.5709116458892822, -0.4738771617412567, -1.253071904182434, 0.27215147018432617, -1.4433859586715698, -0.36522507667541504, -0.44999247789382935, -0.2690577507019043, -0.13439950346946716, -0.2713364064693451, -0.17443133890628815, 0.34744691848754883, 0.09449674189090729, 0.08755416423082352, -0.18506211042404175, -0.4159809648990631, 1.2960361242294312, 0.6867049932479858, -0.5065221190452576, 0.12381623685359955, -0.4096781313419342, 0.285115122795105, 0.48566317558288574, 0.7298460602760315, -0.16206640005111694, -0.9896140098571777, -1.4203873872756958, 0.3762860894203186, -0.5320417881011963, -0.0418158695101738, -0.9087458252906799, 0.4992469549179077, 0.7742012739181519, -0.3168303370475769, 0.33891400694847107, 0.8846146464347839, -1.1129157543182373, -0.4281114637851715, 0.8311266899108887, -0.7433322668075562, 0.31494179368019104, 0.4645761251449585, -0.5853790640830994, -0.27873846888542175, 0.287007600069046, 0.13255290687084198, -0.6881101131439209, -0.839022159576416, 0.3630448281764984, -0.1837688833475113, -0.11881305277347565, -0.31286370754241943, 0.007671271450817585, -1.3656394481658936, -0.36316561698913574, -0.11732146143913269, -0.2844797670841217, -0.27475646138191223, 0.6371884942054749, 0.6642341613769531, -1.2395025491714478, 0.22734035551548004, 0.6857323050498962, -0.21640177071094513, -0.3193436563014984, 0.3812606632709503, 0.35479626059532166, -0.7028748393058777, 0.5727692246437073, 0.3304487466812134, 0.6408413648605347, -0.5886243581771851, -0.12666969001293182, 0.6394864916801453, -0.627813458442688, -0.14346610009670258, 1.1352180242538452, -0.8286272287368774, -1.0226503610610962, 0.09224463999271393, -1.0454528331756592, -0.21160957217216492, -0.3464919328689575, 0.4764581322669983, 0.4242646396160126, 0.1324339658021927, 0.09201883524656296, -0.13308842480182648, 0.08291412144899368, -0.013131877407431602, -0.5568251013755798, 0.36166784167289734, -0.1135154440999031, -0.1860179901123047, 0.7462236881256104, 1.75306236743927, -0.9101312160491943, -0.665447473526001, -0.7443819642066956, -0.6297869682312012, -0.29280543327331543, 0.4626343548297882, -0.35055315494537354, -0.8041244149208069, 0.8335107564926147, 0.7022167444229126, -0.19408078491687775, -0.028381330892443657, -0.3136383593082428, 0.32700029015541077, 0.7973840236663818, -0.14769436419010162, -0.5856383442878723, -0.1457347273826599, 1.648324728012085, 1.3069367408752441, -0.8761940002441406, 0.6200118660926819, -0.6323100924491882, -0.5416454672813416, 0.5273951292037964, -0.0714070126414299, -0.17585954070091248, 1.2226593494415283, -0.26459282636642456, -0.21206806600093842, 0.3584807217121124, -1.0765355825424194, -0.14788922667503357, 0.7677074670791626, 0.9666246175765991, 0.7329438328742981, 0.40633854269981384, 0.2836736738681793, 0.6606407761573792, -0.35546359419822693, -0.027425499632954597, 0.4343251585960388, 0.27821093797683716, -0.3519496023654938, -0.06649382412433624, -0.008316642604768276, 0.7237793803215027, -0.37897491455078125, -0.9159359335899353, 0.33508598804473877, 0.631739616394043, 0.3481528162956238, 0.31598782539367676, 1.146518349647522, -0.0026637970004230738, 0.3882221281528473, 0.33967480063438416, 0.44815322756767273, -0.4961578845977783, -0.28428590297698975, -0.41234350204467773, -0.5035884380340576, 0.0061352248303592205, 0.06970945000648499, 0.01870862953364849, -0.24586789309978485, -0.5986916422843933, 0.6501474380493164, -0.19443413615226746, 0.6617465019226074, 0.774872362613678, 0.6501578688621521, 0.626884400844574, -0.21517689526081085, -0.5066573619842529, -0.50301593542099, -0.9577633142471313, -0.2927832305431366, -0.20319153368473053, -0.339481920003891, -0.11000079661607742, -0.19775493443012238, -0.2613197863101959]}, "authors": [{"authorId": "2134575790", "name": "J. Hu"}, {"authorId": "2273098089", "name": "Roberto Cavicchioli"}, {"authorId": "2271383850", "name": "Giulia Berardinelli"}, {"authorId": "2780990", "name": "Alessandro Capotondi"}], "references": [{"paperId": "9b4f46bd74b659505a50d11a86c615f17002a0db", "title": "A request for clarity over the End of Sequence token in the Self-Critical Sequence Training"}, {"paperId": "b835345c6168d7b179516700aa4460912a8857e9", "title": "HomoDistil: Homotopic Task-Agnostic Distillation of Pre-trained Transformers"}, {"paperId": "eda43b5766e00a0cb70e02e0f50c9b9e6e62d214", "title": "LAD: Layer-Wise Adaptive Distillation for BERT Model Compression"}, {"paperId": "bf459cca52f336de2afe61e6e6348571c73943c1", "title": "Improving the Efficiency of Transformers for Resource-Constrained Devices"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "1f133158a8973fb33fea188f20517cd7e69bfe7f", "title": "FNet: Mixing Tokens with Fourier Transforms"}, {"paperId": "d1870f667cbd309df45a244c170d1d4ba36bac03", "title": "Subformer: Exploring Weight Sharing for Parameter Efficiency in Generative Transformers"}, {"paperId": "c375e121926db9551f224ff235018ea38bb159b7", "title": "BinaryBERT: Pushing the Limit of BERT Quantization"}, {"paperId": "097210dc65924f8ce59523faf444e635523dc714", "title": "TernaryBERT: Distillation-aware Ultra-low Bit BERT"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "821fde6dc36d1264c765d249d4247ea66daff55f", "title": "Edge Machine Learning for AI-Enabled IoT Devices: A Review"}, {"paperId": "2b9955bc08fc5f4ddba73082ddabcfaabdbb4416", "title": "Poor Man's BERT: Smaller and Faster Transformer Models"}, {"paperId": "2573af4e13d9a5dddb257d22cd38a600528d9a8b", "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"}, {"paperId": "2e27f119e6fcc5477248eb0f4a6abe8d7cf4f6e7", "title": "BERT-of-Theseus: Compressing BERT by Progressive Module Replacing"}, {"paperId": "54d4ff8d536b292149a4fa017c22349cf4e54ce4", "title": "AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural Architecture Search"}, {"paperId": "555fceb16c3bb3196948b43f25e39ef633f3314d", "title": "Resource-Efficient Neural Networks for Embedded Systems"}, {"paperId": "4d8a4509753cc91832f80ec35795064e79630ef3", "title": "Structured Pruning of a BERT-based Question Answering Model"}, {"paperId": "ce106590145e89ea4b621c99665862967ccf5dac", "title": "Q8BERT: Quantized 8Bit BERT"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1", "title": "Reducing Transformer Depth on Demand with Structured Dropout"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d", "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"}, {"paperId": "9a618cca0d2fc78db1be1aed70517401cb3f3859", "title": "Deep Equilibrium Models"}, {"paperId": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf", "title": "Patient Knowledge Distillation for BERT Model Compression"}, {"paperId": "97906df07855b029b7aae7c2a1c6c5e8df1d531c", "title": "BERT Rediscovers the Classical NLP Pipeline"}, {"paperId": "528b5f5356bc7ad91edc4dc074b0273e1e55fb03", "title": "Modeling Recurrence for Transformer"}, {"paperId": "799bd97bd86b760244d178fc6cccb0b55323bf0e", "title": "A Review of Low-End, Middle-End, and High-End Iot Devices"}, {"paperId": "7cdee781985dce1f6f9a373254244df2b79f2843", "title": "Parameter Sharing Methods for Multilingual Self-Attentional Translation Models"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "b4bfadfca9742bb3ee98a0cd322d5ce4e59a3ceb", "title": "A Call for Clarity in Reporting BLEU Scores"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "21937ecd9d66567184b83eca3d3e09eb4e6fbd60", "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"}, {"paperId": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4", "title": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"}, {"paperId": "67355b7f4edede98a3d568c9d8951bd738e280c5", "title": "FFT-based deep learning deployment in embedded systems"}, {"paperId": "ee53c9480132fc0d09b1192226cb2c460462fd6d", "title": "Channel Pruning for Accelerating Very Deep Neural Networks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "6c8353697cdbb98dfba4f493875778c4286d3e3a", "title": "Self-Critical Sequence Training for Image Captioning"}, {"paperId": "86052e869a0b458b9bfba4deaf42672f3a731432", "title": "Learning Compact Neural Word Embeddings by Parameter Space Sharing"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "258986132bf17755fe8263e42429fe73218c1534", "title": "CIDEr: Consensus-based image description evaluation"}, {"paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5", "title": "GloVe: Global Vectors for Word Representation"}, {"paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e", "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"}, {"paperId": "d770060812fb646b3846a7d398a3066145b5e3c8", "title": "Do Deep Nets Really Need to be Deep?"}, {"paperId": "eff61216e0136886e1158625b1e5a88ed1a7cbce", "title": "Predicting Parameters in Deep Learning"}, {"paperId": "f6b51c8753a871dc94ff32152c00c01e94f90f09", "title": "Efficient Estimation of Word Representations in Vector Space"}, {"paperId": "2b669398c4cf2ebe04375c8b1beae20f4ac802fa", "title": "Improving Word Representations via Global Context and Multiple Word Prototypes"}, {"paperId": "7533d30329cfdbf04ee8ee82bfef792d08015ee5", "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "e0c01df98a6b633b25c96c1a99b713ac96f1c5be", "title": "Placing search in context: the concept revisited"}, {"paperId": null, "title": "2022. Exploring extreme parameter compression for pre-trained language models"}, {"paperId": null, "title": "2022. SDBERT: SparseDis-tilBERT, a faster and smaller BERT model"}, {"paperId": null, "title": "trained quantization and huffman coding"}, {"paperId": null, "title": "2023. Exploring Challenges of Deploying BERT-based NLP Models in Resource-Constrained Embed-ded Devices"}, {"paperId": null, "title": "2022. Expan-sionNet v2: Block Static Expansion in fast end to end training for Image Captioning"}, {"paperId": null, "title": "2022. The optimal BERT surgeon: Scalable and accurate second-order pruning for large language models"}]}