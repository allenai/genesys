{"paperId": "35c991b167708b7a76bc8bb2ed1eea2cb1a4f11b", "title": "On the Role of Attention Masks and LayerNorm in Transformers", "abstract": "Self-attention is the key mechanism of transformers, which are the essential building blocks of modern foundation models. Recent studies have shown that pure self-attention suffers from an increasing degree of rank collapse as depth increases, limiting model expressivity and further utilization of model depth. The existing literature on rank collapse, however, has mostly overlooked other critical components in transformers that may alleviate the rank collapse issue. In this paper, we provide a general analysis of rank collapse under self-attention, taking into account the effects of attention masks and layer normalization (LayerNorm). In particular, we find that although pure masked attention still suffers from exponential collapse to a rank one subspace, local masked attention can provably slow down the collapse rate. In the case of self-attention with LayerNorm, we first show that for certain classes of value matrices, collapse to a rank one subspace still happens exponentially. However, through construction of nontrivial counterexamples, we then establish that with proper choice of value matrices, a general class of sequences may not converge to a rank one subspace, and the self-attention dynamics with LayerNorm can simultaneously possess a rich set of equilibria with any possible rank between one and full. Our result refutes the previous hypothesis that LayerNorm plays no role in the rank collapse of self-attention and suggests that self-attention with LayerNorm constitutes a much more expressive, versatile nonlinear dynamical system than what was originally thought.", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper provides a general analysis of rank collapse under self-attention, taking into account the effects of attention masks and layer normalization (LayerNorm), and suggests that self-attention with LayerNorm constitutes a much more expressive, versatile nonlinear dynamical system than what was originally thought."}, "embedding": {"model": "specter_v2", "vector": [-0.03916694596409798, 0.6333379149436951, -0.43072593212127686, 0.3170207738876343, -0.13995303213596344, -0.3427104651927948, 0.3541620373725891, -0.46119004487991333, -0.0012917235726490617, -0.06446731835603714, 0.3192872703075409, 0.05001802369952202, 0.10145509988069534, -0.05830587074160576, -0.18338768184185028, -0.14000843465328217, -0.9762968420982361, 0.11403157562017441, -0.012785224243998528, -0.5316460728645325, 0.020526902750134468, -0.5062285661697388, -1.4610215425491333, 0.2563211917877197, 0.6516411304473877, 1.0470566749572754, -0.2089984118938446, 0.508722722530365, -0.49110886454582214, 0.9402820467948914, 0.6719080209732056, -0.3407553434371948, 0.7144307494163513, 0.1690583974123001, -0.2375028431415558, -0.333894819021225, 0.43620622158050537, -0.4917074739933014, -0.7271475195884705, 1.2358829975128174, -0.3324325382709503, -0.06156870722770691, 0.1795264184474945, -0.9763097763061523, 0.1422286480665207, 0.9692814946174622, 0.8656818270683289, 0.8196792006492615, -0.47047966718673706, -0.41213279962539673, 1.4741857051849365, -1.3909813165664673, -0.05191658437252045, 0.92432701587677, 0.49151501059532166, 0.4387749433517456, -0.4334715008735657, -0.988466739654541, 0.4363093674182892, 0.2071014940738678, -1.0320507287979126, -0.4633970856666565, 0.37431296706199646, -0.5294051170349121, 1.0854755640029907, -0.029171016067266464, 0.10138716548681259, 0.02241824008524418, 0.29291993379592896, 0.930454671382904, 0.5646871328353882, -0.4074851870536804, 0.16308288276195526, 0.63841313123703, 0.3766149580478668, 0.7470735311508179, -0.10192117094993591, 0.4299595355987549, -1.1124283075332642, -0.30549848079681396, 0.6812486052513123, -0.27462735772132874, -0.13068613409996033, -0.918963611125946, 0.23013009130954742, 0.2661758363246918, 0.03155776485800743, 0.6309881210327148, -0.21579384803771973, 0.7874631881713867, 0.42105481028556824, 0.620049238204956, 0.029014410451054573, 0.5065858364105225, 0.17674466967582703, 0.38046514987945557, -0.7137302160263062, 0.03534715995192528, -0.2020689845085144, 0.5979825854301453, 0.37175101041793823, 0.6601963639259338, -0.26235058903694153, -0.03307421877980232, 1.2381616830825806, -0.10186538845300674, 0.5804052948951721, -0.8398329019546509, 0.1659712791442871, 0.09093782305717468, 0.6375669836997986, -0.7928394675254822, 0.13279449939727783, -0.735061526298523, -0.8942818641662598, -0.7806660532951355, -0.34333693981170654, 0.45797738432884216, -0.39790695905685425, 0.9338677525520325, -0.5184189081192017, -0.06812068074941635, 0.015214483253657818, 0.5190185308456421, 0.20667985081672668, 0.29566657543182373, -0.021942246705293655, -0.47036370635032654, 0.9137895703315735, -0.4103745222091675, -1.0280159711837769, -0.8774919509887695, 0.5627066493034363, 0.17241793870925903, 0.44710105657577515, -0.15655477344989777, -1.6004753112792969, -0.7686647176742554, -1.267439365386963, 0.8028214573860168, -0.26689159870147705, -0.23648077249526978, 0.9528422355651855, 0.1300773173570633, -1.097300410270691, 0.9677366614341736, -0.35424473881721497, 0.01868894137442112, 0.3785465657711029, 0.7207910418510437, 0.0003298220981378108, -0.02594638057053089, -1.2838683128356934, 0.7352707982063293, 0.13010306656360626, -0.39469507336616516, -0.5070351362228394, -0.7346627712249756, -1.0816532373428345, 0.060850873589515686, 0.5203760862350464, -0.3153555393218994, 1.0117746591567993, 0.14070774614810944, -1.0366796255111694, 0.5749788880348206, -0.13958100974559784, -0.015437434427440166, 0.47929447889328003, 0.09174931049346924, -0.4748024046421051, -0.2510818541049957, 0.24765314161777496, -0.3625999093055725, 0.4293912649154663, -0.9923571944236755, 0.15260529518127441, 0.14815592765808105, -0.3886253237724304, -0.3522482216358185, -0.5620337724685669, 0.692703127861023, -0.03041083738207817, 0.17857538163661957, 0.5615857839584351, 1.0353046655654907, 0.03916032239794731, -0.2698955833911896, -0.4485618770122528, -0.7956570386886597, 0.464322030544281, 0.46037980914115906, 1.6279700994491577, -0.7826985716819763, -0.8361813426017761, -0.10314492881298065, 0.1338806301355362, -0.2640111744403839, -0.1177833303809166, 0.9558272361755371, -1.0237294435501099, 0.7150306105613708, -0.25643521547317505, -0.506415843963623, -0.18059834837913513, -0.4102109670639038, -1.1809755563735962, -0.14637507498264313, 0.02060069516301155, 0.8630633354187012, -0.6182200312614441, 0.020400062203407288, 0.0955393835902214, -0.10671629756689072, -0.797378659248352, 1.1072027683258057, 0.06174703687429428, 0.05022791028022766, -0.17832481861114502, -0.3894999623298645, 0.11249340325593948, -0.6636168360710144, 0.2359739989042282, -0.7084101438522339, -0.269509881734848, 0.25261080265045166, -0.7271329760551453, 0.5873156189918518, 0.02509121410548687, 0.5645849704742432, 0.12067185342311859, -0.7080162167549133, -0.07804518193006516, 0.41905054450035095, 0.2820315361022949, -0.2780882716178894, 0.38804176449775696, 0.10906706750392914, -0.3668852150440216, 0.14214371144771576, 0.47211527824401855, 0.6849119663238525, -0.4527266323566437, 0.1461121141910553, 0.5009016394615173, -0.35214442014694214, 0.22714947164058685, 0.30174487829208374, 0.5846176147460938, 0.04302554205060005, 0.44079816341400146, -0.863092839717865, 0.2814285457134247, -0.621722936630249, -0.17163151502609253, 0.3059479594230652, 0.40164053440093994, 0.29595598578453064, 0.3916104733943939, -0.7526013851165771, -0.4331205487251282, -0.12087398022413254, 0.48225873708724976, 1.1918818950653076, 0.011447126977145672, -0.8155008554458618, -0.7300648093223572, 0.08414915204048157, -0.47340983152389526, 0.04729514196515083, -0.3560743033885956, -0.64899742603302, -0.39153793454170227, -0.6991750001907349, 0.5287110805511475, 0.3128530979156494, 1.326910376548767, -0.12088440358638763, -0.29072868824005127, 0.09885839372873306, 0.4481726288795471, -0.5853986740112305, -0.20519936084747314, 0.38305965065956116, -0.6542692184448242, -0.25698724389076233, 0.08653096854686737, -0.25750288367271423, 0.150840625166893, -0.9926504492759705, 0.39975908398628235, -0.4916156232357025, 0.026135945692658424, 0.3311265707015991, 1.4650681018829346, -0.37218159437179565, -0.49049538373947144, -0.06920434534549713, 0.557994544506073, -0.005950704216957092, 0.06834337115287781, 0.20637471973896027, 0.12081127613782883, 0.33868297934532166, -0.20683997869491577, -0.07625515013933182, -0.16620232164859772, 0.0658564642071724, 0.22704793512821198, 0.23304203152656555, 0.09663743525743484, -0.8496080040931702, 0.8859150409698486, 0.5272748470306396, -0.9148744344711304, 0.0017245402559638023, -0.9675713777542114, -0.21025951206684113, 0.4120270311832428, -0.6851034760475159, 0.11213740706443787, -1.0082249641418457, 0.9585398435592651, -0.46122029423713684, 0.3760555684566498, 0.2522864043712616, -0.013668911531567574, -0.23363646864891052, 0.25231802463531494, 0.6792564392089844, 0.4399805963039398, 0.23658695816993713, 0.25931328535079956, -0.8147971034049988, 0.6683597564697266, 0.17989614605903625, 0.5455689430236816, 0.0712135061621666, -0.1958642601966858, -0.576623260974884, -0.37071681022644043, 0.1645859330892563, 0.33916667103767395, -0.42032742500305176, -0.19957087934017181, -0.8470720052719116, -1.492058277130127, 0.28812745213508606, -0.2388373762369156, -0.5369190573692322, -0.2791721224784851, -0.5991448760032654, -0.46043267846107483, -1.0220599174499512, -1.3868248462677002, -1.351198434829712, -0.3215234577655792, -0.8251142501831055, -0.07007735967636108, -0.13830670714378357, -0.2670254707336426, -0.019743086770176888, -0.45529380440711975, -0.6383373141288757, 1.2355902194976807, -0.7603718638420105, 0.8724098205566406, -0.09255830198526382, -0.824363648891449, -0.1416161209344864, 0.43938690423965454, 0.395274817943573, -0.011043736711144447, 0.0037400415167212486, -0.5916147232055664, 0.11950904130935669, 0.3549802601337433, 0.011786491610109806, -0.2952372431755066, 0.12608228623867035, 0.6863277554512024, -0.8283539414405823, -0.7077631950378418, -0.08914364874362946, 1.7233197689056396, -0.37197455763816833, 0.243727445602417, 0.5058811902999878, 0.8443934321403503, 0.6297938823699951, -0.3670821487903595, 0.566993236541748, 0.3737468421459198, 0.20743979513645172, 0.646409273147583, 0.027669301256537437, 0.4919707775115967, -0.4210669696331024, 0.32997259497642517, 1.7873337268829346, 0.43996644020080566, 0.46241295337677, -1.1226743459701538, 0.8899734616279602, -1.248363971710205, -0.75152188539505, 0.859005868434906, 0.9536291360855103, 0.3326723575592041, -0.18577711284160614, -0.4340762495994568, 0.27352339029312134, 0.7126218676567078, -0.1358267217874527, -0.49597877264022827, -0.12401299923658371, 0.008429700508713722, 0.338241308927536, 0.47574490308761597, 0.6188644170761108, -0.06497688591480255, 0.808943510055542, 15.20179271697998, 0.3024408221244812, -0.04619384557008743, 0.4776032269001007, 0.6889320611953735, 0.5514670014381409, -0.42084047198295593, 0.3376408815383911, -0.7761134505271912, 0.08735276013612747, 0.8900849223136902, -0.19249555468559265, 0.5577917695045471, 0.1634804755449295, -0.19770605862140656, 0.46003520488739014, -0.19479502737522125, 0.5054571628570557, 0.24586838483810425, -1.2018688917160034, 0.47772812843322754, 0.2925660312175751, 0.3600829541683197, -0.04829643294215202, 0.7886243462562561, 0.308929443359375, 0.7623711824417114, -0.42975255846977234, 0.2884998321533203, 0.3066968321800232, 1.2974679470062256, -0.09382854402065277, 0.15774333477020264, 0.5611717700958252, -0.8325603604316711, -0.4012427031993866, -0.27472934126853943, -1.3708652257919312, 0.03735736757516861, 0.06411058455705643, -0.059655219316482544, -0.8982405662536621, 0.18799597024917603, 0.2151634246110916, 0.3942148685455322, 0.2069171816110611, -0.1829545944929123, 0.5940305590629578, -0.15152330696582794, 0.38715824484825134, -0.44844305515289307, 0.7575780749320984, 0.149694561958313, -0.9258726835250854, 0.2741125524044037, 0.08107782900333405, 0.039891958236694336, 0.6573297381401062, -0.10858163237571716, -0.3435521125793457, -0.33945202827453613, -0.34555891156196594, 0.0321238674223423, 0.9216636419296265, 0.9924535155296326, -0.19631998240947723, 0.2957748770713806, -0.1864297091960907, 0.30731701850891113, 0.2564181983470917, 0.06286872923374176, -0.19461287558078766, 0.8075234889984131, 0.30109983682632446, -0.44820645451545715, 0.5349869132041931, -0.6045328974723816, -0.4455333948135376, -0.8850957751274109, -0.46326807141304016, 0.033682581037282944, -1.2569503784179688, -0.8190262317657471, 1.0217946767807007, -0.08954008668661118, -0.5178718566894531, 0.3148711621761322, -0.7607693076133728, -0.2771624028682709, 0.01696292869746685, -0.672096848487854, -0.2950682044029236, -0.06860218197107315, -0.2508160173892975, -0.6470231413841248, -0.262783944606781, 0.8778371810913086, -0.0821896493434906, -0.6106160879135132, -0.0419253446161747, -0.20625516772270203, -0.10819636285305023, -0.33400341868400574, -0.8386206030845642, 0.6130805015563965, 0.061539389193058014, -0.5726139545440674, 0.8053092956542969, 0.48094481229782104, 0.2055024951696396, -0.8773958086967468, 0.14843609929084778, 0.383927583694458, -1.1599746942520142, 0.28101006150245667, -0.980431318283081, -1.2774375677108765, 0.3245868682861328, 0.6272885203361511, -0.0829131156206131, -0.1546967625617981, -0.4774315357208252, -0.21224482357501984, -0.35181382298469543, -0.7249276638031006, 0.5469714999198914, 0.6740294098854065, -1.1747139692306519, -0.3934217095375061, -0.365480899810791, 0.10528790950775146, -0.6349193453788757, -0.6378864049911499, 0.21071375906467438, 0.001457377802580595, -0.2888320982456207, 0.8780658841133118, -0.3476913571357727, 0.5184565186500549, 0.3832436203956604, -0.1543610692024231, -0.403430312871933, -0.3551750183105469, -1.2755922079086304, -0.060056280344724655, 0.5938040018081665, 0.40728121995925903, -0.9168485999107361, 0.6470279097557068, 1.0211992263793945, 0.13779470324516296, -0.1774793118238449, -0.8889652490615845, -0.007914147339761257, 0.030171029269695282, -0.5072858333587646, 0.5574191808700562, 0.23193342983722687, 0.32847821712493896, -0.0350198857486248, 0.30757462978363037, 0.5969010591506958, 0.06091452017426491, -0.8262282013893127, 0.10084453970193863, -0.27009958028793335, 0.520240306854248, -0.6835249066352844, -0.4942009747028351, -0.9639840126037598, -0.17357298731803894, -0.9965667128562927, -0.016515618190169334, -1.2646151781082153, -0.46281132102012634, 0.41768795251846313, -0.6155173182487488, -0.041392937302589417, 0.8139779567718506, -0.1770051121711731, -0.6785860061645508, 0.08510780334472656, -0.2741723358631134, 0.6081162691116333, 0.6335372924804688, -0.8909653425216675, 0.112106092274189, -0.12314099818468094, -0.5033168196678162, 0.25648123025894165, 0.5880739688873291, -0.5241658687591553, -0.5298398733139038, -0.3346045911312103, 0.594325840473175, -0.12240684777498245, -0.10791664570569992, -0.7466639280319214, 1.0283374786376953, 0.522364616394043, -0.13637806475162506, -0.05123206600546837, 0.48033013939857483, -1.090214490890503, -0.10990510135889053, 0.30846622586250305, -0.6224835515022278, 0.33720964193344116, 0.37331536412239075, -0.7535891532897949, -0.1285867691040039, 0.9158477187156677, -0.12796346843242645, -1.2247182130813599, -0.25126779079437256, 0.28824034333229065, -1.237466812133789, 0.13386492431163788, -0.15443871915340424, -0.43044164776802063, -1.2923834323883057, -0.4010620415210724, -0.2029261291027069, 0.3930985927581787, -0.04142511636018753, 0.8165313005447388, 0.03436913713812828, -1.3781238794326782, 0.5993891358375549, 0.7867314219474792, 0.2026241570711136, -0.3186333477497101, 0.5915161967277527, 0.12276993691921234, 0.01813906989991665, 0.16399675607681274, 0.07860758155584335, -0.048298776149749756, -0.4135190546512604, -0.09789370745420456, 0.7499156594276428, -0.37898924946784973, 0.23549170792102814, 0.6844568848609924, 0.3611162304878235, -0.771338939666748, -0.04002184048295021, -1.049090027809143, -0.7090904116630554, -0.2859145998954773, 0.33924537897109985, 0.3767927587032318, -0.6607063412666321, -0.23031653463840485, -0.5644757151603699, 0.6647399067878723, -0.13125693798065186, -0.5313720703125, 0.21357129514217377, -0.1807580441236496, -0.3320084810256958, 0.8771272897720337, 0.06401047110557556, -0.6020836234092712, -0.827229917049408, -0.3237372040748596, -0.2634444236755371, -0.12294521182775497, 0.24517107009887695, -0.13505952060222626, -0.37354689836502075, 0.7600574493408203, 0.9445470571517944, 0.7485756874084473, 0.1157907173037529, -0.21868042647838593, -0.5947153568267822, 0.1439123898744583, 0.45111364126205444, -0.680530309677124, -0.31053534150123596, 0.7091199159622192, 1.2545182704925537, -0.25112485885620117, 0.19900862872600555, -0.4184788763523102, -0.4015456736087799, 0.374528169631958, 0.8363502025604248, -0.27008920907974243, 0.8015169501304626, -0.08601072430610657, 0.19505779445171356, -0.11043795943260193, -1.3354748487472534, -0.460336297750473, 0.5676193237304688, 0.8839418292045593, 0.27364999055862427, -0.26606813073158264, 0.5512319803237915, 1.0923537015914917, -0.15145570039749146, 0.26685941219329834, 0.9539587497711182, 0.25820139050483704, -0.5410144329071045, 0.4787842631340027, 0.17728380858898163, 0.6180552840232849, -0.8650566339492798, -0.580105721950531, 0.16343899071216583, 0.9392624497413635, -0.16881722211837769, 0.4046517610549927, 0.7251874208450317, -0.6464967727661133, 0.7294701337814331, 0.3594420552253723, 0.03356890380382538, -0.3287285268306732, -0.20091448724269867, 0.11279325187206268, -0.7101104259490967, -0.01171659491956234, 0.1159214973449707, -0.17941506206989288, -0.03590428829193115, 0.05640323832631111, -0.5069295763969421, 0.22050820291042328, 0.16228684782981873, 0.7366867661476135, 0.5345601439476013, 0.39413517713546753, 0.09606964886188507, -0.19030089676380157, -0.8155792951583862, -0.7140882611274719, 0.08430738747119904, -0.8352036476135254, 0.03879159688949585, -0.3894800543785095, -0.5488095879554749, -0.9362135529518127]}, "authors": [{"authorId": "2303845787", "name": "Xinyi Wu"}, {"authorId": "2468364", "name": "A. Ajorlou"}, {"authorId": "2303611770", "name": "Yifei Wang"}, {"authorId": "2242248678", "name": "Stefanie Jegelka"}, {"authorId": "1688304", "name": "A. Jadbabaie"}], "references": [{"paperId": "89d786457591d39091cf6ef4831f2bbd72698caf", "title": "TransformerFAM: Feedback attention is working memory"}, {"paperId": "96c88b196e3e432710debab39f49ee72f2b96a10", "title": "Anisotropy Is Inherent to Self-Attention in Transformers"}, {"paperId": "54c7bdf63719bb366987bb6e9e857335a479f4d9", "title": "A mathematical perspective on Transformers"}, {"paperId": "f9e1cf92a56898e9378b9019669e6de62bb7066a", "title": "On the impact of activation and normalization in obtaining isometric embeddings at initialization"}, {"paperId": "8b9f01585a679dffe92261ecdec56425db9ef97f", "title": "Demystifying Oversmoothing in Attention-Based Graph Neural Networks"}, {"paperId": "50eb97f832ffcd2114f79957c977215176384e3d", "title": "Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer"}, {"paperId": "e5526fcee23b6dc7b7bf0d83607d88d12cf6baf2", "title": "The emergence of clusters in self-attention dynamics"}, {"paperId": "d078b6e88bc4749f4eb83f289537a88b4aaf54e6", "title": "On the Expressivity Role of LayerNorm in Transformers' Attention"}, {"paperId": "39ed1c33af6f0a5fbc16354afcb223a03c9c139b", "title": "Fast Attention Requires Bounded Entries"}, {"paperId": "b8c236dc5963dac36b0d8e419beb5876e3a18f96", "title": "Deep Transformers without Shortcuts: Modifying Self-attention for Faithful Signal Propagation"}, {"paperId": "5eeb80dc67590422db64ca95ec0aded24799cfb6", "title": "Signal Propagation in Transformers: Theoretical Perspectives and the Role of Rank Collapse"}, {"paperId": "383116b2685d0c7ae9669ac929b628b9af0af5f3", "title": "Revisiting Over-smoothing in BERT from the Perspective of Graph"}, {"paperId": "dfb37e6216e792bf6bd5a30c0fc7ad55df1cb71e", "title": "Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth"}, {"paperId": null, "title": "Transformers: State-of-the-Art Natural Language Processing"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "40ca4fcfffa7ca9aa9b7ff06ecf3cd0436712d78", "title": "$O(n)$ Connections are Expressive Enough: Universal Approximability of Sparse Transformers"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a", "title": "On Layer Normalization in the Transformer Architecture"}, {"paperId": "509b4661ed74a24c2ffdbf131f9e1c6a1783752d", "title": "Are Transformers universal approximators of sequence-to-sequence functions?"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "9d7902e834d5d1d35179962c7a5b9d16623b0d39", "title": "How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings"}, {"paperId": "55e960535f643637161b2e99a8c21a92c0d13757", "title": "Representation Degeneration Problem in Training Natural Language Generation Models"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "4b4274ef53fd1163e1b75ccee63e6736d98d0b50", "title": "Is Anisotropy Truly Harmful? A Case Study on Text Clustering"}, {"paperId": "2a8bb26654c015f663670d1e0745f870071d5507", "title": "Isotropy in the Contextual Embedding Space: Clusters and Manifolds"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "48e9ac3f80c3fa697d577d5c68c56c77c0e899d9", "title": "Nonhomogeneous Matrix Products"}]}