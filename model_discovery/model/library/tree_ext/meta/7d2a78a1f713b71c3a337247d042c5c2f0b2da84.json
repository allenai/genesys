{"paperId": "7d2a78a1f713b71c3a337247d042c5c2f0b2da84", "title": "EfficientViT: Enhanced Linear Attention for High-Resolution Low-Computation Visual Recognition", "abstract": "Vision Transformer (ViT) has achieved remarkable performance in many vision tasks. However, ViT is inferior to convolutional neural networks (CNNs) when targeting high-resolution mobile vision applications. The key computational bottle-neck of ViT is the softmax attention module which has quadratic computational complexity with the input resolution. It is essential to reduce the cost of ViT to deploy it on edge devices. Existing methods (e.g., Swin, PVT) restrict the softmax attention within local windows or reduce the resolution of key/value tensors to reduce the cost, which sacri\ufb01ces ViT\u2019s core advantages on global feature extractions. In this work, we present Ef\ufb01cientViT , an ef\ufb01cient ViT architecture for high-resolution low-computation visual recognition. Instead of restricting the softmax attention, we propose to replace softmax attention with linear attention while enhancing its local feature extraction ability with depthwise convolution. Ef\ufb01cientViT maintains global and local feature extraction capability while enjoying linear computational complexity. Extensive experiments on COCO object detection and Cityscapes semantic segmentation demonstrate the effectiveness of our method. On the COCO dataset, Ef\ufb01cientViT achieves 42.6 AP with 4.4G MACs, surpassing Ef\ufb01cientDet-D1 by 2.4 AP while having 27.9% fewer MACs. On Cityscapes, Ef\ufb01cientViT reaches 78.7 mIoU with 19.1G MACs, outperforming SegFormer by 2.5 mIoU while requiring less than 1/3 the computational cost. On Qualcomm Snapdragon 855 CPU, Ef\ufb01cientViT is 3 \u00d7 faster than Ef\ufb01cientNet while achieving higher ImageNet accuracy.", "venue": "arXiv.org", "year": 2022, "citationCount": 51, "influentialCitationCount": 8, "openAccessPdf": {"url": "https://arxiv.org/pdf/2205.14756", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "Ef\ufb01cientViT, an ef\ufb01cient ViT architecture for high-resolution low-computation visual recognition, proposes to replace softmax attention with linear attention while enhancing its local feature extraction ability with depthwise convolution."}, "embedding": {"model": "specter_v2", "vector": [0.39093661308288574, 0.5007985830307007, -0.3875257670879364, 0.419869989156723, -0.1283532679080963, 0.17275330424308777, 0.5722692608833313, -0.3003107011318207, -0.34436336159706116, -0.9639512300491333, 0.42285221815109253, 0.8608901500701904, 0.7494062185287476, -0.4270836114883423, 0.09971050173044205, 0.2694929540157318, -0.6938472986221313, -0.2600781321525574, 0.7724272012710571, -0.4652739465236664, -0.054137494415044785, -0.2917449176311493, -1.3166019916534424, 0.5670786499977112, 0.08526989072561264, 1.5384635925292969, 0.3525629937648773, 1.2763742208480835, -0.1593133509159088, 0.6567757725715637, 0.5936527848243713, -0.501854419708252, 0.3208969831466675, 0.05058147385716438, -0.37602850794792175, 0.158731609582901, 0.6110696792602539, -0.47869789600372314, -0.37616053223609924, 0.8858073949813843, -0.008112234063446522, 0.1698893904685974, 0.7075074911117554, -0.6311054825782776, -0.3603613078594208, 0.0398278683423996, 0.40737780928611755, 0.8657007813453674, -0.3457220494747162, -0.6169147491455078, 1.1314904689788818, -1.554761290550232, 0.19763615727424622, 1.6430048942565918, 0.8388092517852783, -0.1470603197813034, 0.15226905047893524, -0.10008712112903595, 0.6129313707351685, 0.271919310092926, -0.695122480392456, -0.41939687728881836, 0.0740012526512146, -0.16567404568195343, 1.7812399864196777, -0.692626953125, 0.12180618941783905, 0.8027007579803467, 0.2255343347787857, 1.1292039155960083, -0.05052284523844719, -0.5347893238067627, -0.13317345082759857, -0.10992696136236191, -0.14543086290359497, 0.9368987679481506, -0.013853737153112888, 0.08675847947597504, -0.7948401570320129, 0.4308694303035736, 0.6831369400024414, 0.26875969767570496, 0.4924277663230896, -0.45193585753440857, 0.053274497389793396, 0.5986962914466858, 1.081461787223816, 0.43348103761672974, -0.31305110454559326, 0.8580687642097473, 0.49443647265434265, -0.25829342007637024, -0.12534306943416595, 0.10041090846061707, -0.037207841873168945, 0.5522052645683289, -0.807973325252533, -0.3103249669075012, -0.404915988445282, 1.0508512258529663, -0.4332619607448578, 0.4222172200679779, -0.386626273393631, 0.32533130049705505, 1.0004541873931885, 0.4050619602203369, 0.04596083238720894, -0.543860137462616, -0.17383861541748047, -0.6019285917282104, 0.08330528438091278, -1.2055304050445557, 0.09195398539304733, -0.5890705585479736, -1.0550782680511475, -0.48603489995002747, -0.4944455623626709, 0.271495521068573, -1.4457346200942993, -0.1590718775987625, -0.5037119388580322, 0.06235126405954361, -0.08760498464107513, 0.4797356128692627, 0.6889341473579407, 0.6200695633888245, 0.13049007952213287, 0.6983864307403564, 1.6180306673049927, -1.1544959545135498, -0.373933345079422, -0.9889976978302002, -0.38414567708969116, -0.3621508479118347, 0.06291592866182327, -0.09324685484170914, -1.055019497871399, -1.1960760354995728, -0.8386773467063904, -0.439011812210083, -0.9564598798751831, 0.2693755030632019, 0.9919759631156921, 0.562105655670166, -1.0009726285934448, 0.25865674018859863, -0.41344016790390015, -0.6673187613487244, 1.0077579021453857, -0.1647392362356186, 0.6849921941757202, -0.31298890709877014, -0.6228506565093994, 0.4236409664154053, -0.20901843905448914, -0.3944135904312134, -0.24422217905521393, 0.22133329510688782, -1.2261472940444946, 0.43601733446121216, 0.342722624540329, -0.47811904549598694, 0.926477313041687, -0.5488408803939819, -0.9047197103500366, 0.4033460319042206, -0.39700379967689514, -0.00734699284657836, 0.02934103086590767, -0.17253905534744263, -0.2824324369430542, 0.07078350335359573, -0.04867043346166611, 0.6706414818763733, 1.3519619703292847, 0.17810967564582825, -0.5035061836242676, 0.5347161889076233, -0.38826146721839905, -0.08711161464452744, -0.41566202044487, 1.0814086198806763, -1.0198493003845215, -0.4217931926250458, 0.5193191170692444, 0.7163658142089844, -0.08146815001964569, -0.0675131157040596, 0.19161295890808105, -0.8458348512649536, 1.1500364542007446, 0.3527408242225647, 0.22765275835990906, -0.854245126247406, -0.8545849323272705, -0.11277280002832413, -0.06432168185710907, -0.02107221446931362, -0.7214975953102112, -0.2911616861820221, 0.07337991893291473, 0.13147562742233276, 0.2698496878147125, -0.9173656105995178, -0.06829171627759933, -0.4932941198348999, -0.4694726765155792, 0.049874354153871536, 0.7473134994506836, 1.5651851892471313, -0.5946192145347595, -0.37549731135368347, 0.3124343156814575, 0.5205346941947937, -0.9581010937690735, 0.9441222548484802, -0.45094916224479675, -0.5340803265571594, -0.3479156792163849, 0.917630672454834, 0.08092235773801804, -0.6304399967193604, 0.5440570116043091, -0.7084200382232666, 0.036927465349435806, 0.15995065867900848, -0.6875349879264832, 0.7304098010063171, -0.04707021266222, 1.097006916999817, -0.07899652421474457, -0.7078225612640381, 0.29592299461364746, 0.06657086312770844, -0.20182906091213226, -0.6981112957000732, 0.8402196764945984, -0.028718072921037674, -1.1859378814697266, 0.27310624718666077, 0.7880823612213135, 1.5056642293930054, -0.5280038714408875, -0.5223913788795471, 0.8745346069335938, -0.3652466833591461, -0.2339266687631607, 0.18653830885887146, 0.11392457038164139, 0.4710782766342163, 0.4243023693561554, -0.08508968353271484, -0.06199612841010094, -0.7652831673622131, 0.1691575050354004, 0.9704843759536743, 0.1892930269241333, 1.46369206905365, 0.6090139746665955, -0.6863872408866882, -0.7037743926048279, -0.1627458930015564, 0.36762678623199463, 1.422964334487915, 0.41844791173934937, -0.14927013218402863, -0.682235062122345, -0.4115649163722992, -0.8299940228462219, -1.2018898725509644, -0.2658120095729828, 0.19334961473941803, -0.15410830080509186, -1.0179617404937744, 0.8113455772399902, 0.6958619356155396, 1.524763822555542, -0.5739942789077759, -0.6577211022377014, -0.47111260890960693, 0.055925726890563965, -1.3395795822143555, -0.7042940855026245, 0.2846702039241791, -0.18609806895256042, -0.014918109402060509, -0.13918231427669525, -0.6101749539375305, 0.18183840811252594, -0.42330440878868103, 0.5779204368591309, -0.8528385758399963, -0.6814393997192383, 0.2967929244041443, 0.15567323565483093, -0.8361336588859558, 0.27496814727783203, 0.14423798024654388, 0.0524093359708786, 0.1883241981267929, 0.1694278120994568, 0.45356470346450806, -0.05146303400397301, 0.17658281326293945, -0.1952083557844162, -0.14901834726333618, 0.3682924211025238, -0.03840845450758934, 0.8880462646484375, -0.334708571434021, 0.23753215372562408, -0.4681888520717621, 0.17634309828281403, 0.36846011877059937, -0.3978845775127411, -0.12349855899810791, -0.5552061796188354, -0.1752900332212448, 0.2941865622997284, -0.6804987788200378, -0.28918299078941345, -0.2981944978237152, 0.1769637167453766, -0.65519118309021, -0.3345315158367157, -0.343513160943985, 0.2193039208650589, -0.4399072825908661, 0.3891027867794037, 0.11742815375328064, -0.13181442022323608, 0.02536606229841709, 0.5040174126625061, -0.6015284657478333, 1.1028645038604736, 0.2759138345718384, 0.07579430192708969, 0.2936086654663086, 0.029724683612585068, -0.7519508600234985, -0.25399094820022583, -0.5593686103820801, -0.5773086547851562, -0.48584631085395813, 0.7964916825294495, -0.662354052066803, -0.6746768355369568, 0.12142503261566162, -0.856503427028656, -0.09408573061227798, -0.021349282935261726, -0.0952046662569046, -0.4200635850429535, -1.053293228149414, -0.8851335644721985, -0.4931236207485199, -0.7920632362365723, -1.1833504438400269, 0.45277199149131775, 0.7313240170478821, 0.024256177246570587, -0.021089233458042145, -0.6447163820266724, -0.6051483750343323, 1.2104440927505493, 0.009244600310921669, 0.05875956639647484, 0.1608087420463562, -0.8080155849456787, -0.21526949107646942, -0.38596856594085693, 0.46313172578811646, -0.4265660345554352, 0.13312126696109772, -1.0034611225128174, 0.5091482400894165, -0.3580222725868225, -0.17500731348991394, 0.666784405708313, 0.5887560248374939, 0.28849026560783386, 0.42485564947128296, -0.2831066846847534, 0.8320833444595337, 1.4962676763534546, -0.7300078272819519, 0.3027961254119873, 0.12003391236066818, 1.0671120882034302, -0.13594381511211395, -0.22451040148735046, 0.456013560295105, 0.23654063045978546, 0.33529630303382874, 0.5192933678627014, -0.7744092345237732, -1.0410889387130737, -0.5065426230430603, 0.35314545035362244, 0.6746663451194763, -0.014858141541481018, 0.329051673412323, -0.8448158502578735, 1.132224440574646, -1.026557207107544, -0.8635907769203186, 0.5197257995605469, 0.4181238114833832, -0.4436476230621338, -0.01785663329064846, -0.47765079140663147, -0.6606759428977966, 0.6676373481750488, 0.6516671776771545, -0.19091829657554626, -0.7149585485458374, -0.3935467600822449, 0.74671870470047, 0.4713914692401886, 0.7190052270889282, -0.6780247688293457, 0.7705317139625549, 14.537076950073242, 0.7797788977622986, -0.39722222089767456, 0.49106186628341675, 0.7793549299240112, 0.3872188329696655, 0.31984734535217285, 0.051413293927907944, -0.9294525384902954, -0.48820197582244873, 0.4875042736530304, 0.5067970156669617, 0.1713511049747467, 0.6745069622993469, -0.3307643532752991, 0.29390379786491394, -0.343262642621994, 1.1672629117965698, 0.9499236941337585, -1.461046576499939, -0.10605690628290176, 0.18794584274291992, 0.7375708222389221, 0.7056882977485657, 0.7500644326210022, 0.7503085732460022, 0.10464545339345932, -0.5504947304725647, 0.6191797256469727, 0.23685024678707123, 1.2066655158996582, -0.22238948941230774, 0.3934386968612671, -0.2039877325296402, -1.6969192028045654, -0.18345887959003448, -0.5972937941551208, -0.9596960544586182, -0.16520154476165771, -0.20774532854557037, -0.20597469806671143, -0.5296300649642944, 0.7163913249969482, 0.8109055757522583, -0.2770881950855255, 0.5776280760765076, -0.12426166236400604, 0.013391602784395218, -0.2763471007347107, -0.21242786943912506, 0.5188356637954712, 0.6682000160217285, 0.2168649435043335, 0.37918853759765625, -0.377468466758728, 0.30607202649116516, 0.22701512277126312, 0.3859385848045349, -0.595061182975769, -0.4287266731262207, -0.35840147733688354, 0.22739925980567932, -0.5264338254928589, 0.998925507068634, -0.418935626745224, -0.004966337233781815, -0.25356554985046387, 0.6775121092796326, 0.136037215590477, 0.18746376037597656, -0.44924888014793396, -0.59888756275177, 0.29914602637290955, -0.3251088261604309, 0.9042911529541016, 0.2126830518245697, -0.5193718671798706, -0.8996176719665527, -0.601455807685852, -0.14036567509174347, 0.5787344574928284, -0.995442807674408, -0.3273788094520569, 1.0753214359283447, -0.37791359424591064, -0.1237674206495285, 0.40472084283828735, -1.0180386304855347, -0.2458312064409256, 0.32811516523361206, -1.3550728559494019, -0.8151964545249939, -0.2171105295419693, -0.31861674785614014, 0.1338767111301422, 0.06724529713392258, 0.638348400592804, 0.010298829525709152, 0.002498892368748784, 0.04831528291106224, -0.3792356848716736, 0.6323782801628113, -0.2778686583042145, -0.24962276220321655, 0.7674203515052795, 1.1358728408813477, -0.14536052942276, -0.5888171792030334, -0.3500843048095703, 0.18895979225635529, -0.5293111205101013, -0.04735880345106125, 0.533930242061615, -0.6994102001190186, -0.8121957778930664, -1.031463623046875, -0.7028555274009705, 0.2863942086696625, 0.5782638788223267, 0.421353280544281, -0.7357948422431946, 0.016090719029307365, -0.612356960773468, -0.19822631776332855, -0.7987236976623535, 0.1613684594631195, 0.12546074390411377, -0.8425239324569702, -0.32020729780197144, -0.44932711124420166, 0.20270639657974243, -0.9553184509277344, -0.41691118478775024, 0.1217261254787445, 0.5101000666618347, -0.13699109852313995, 1.4354952573776245, -0.02842293493449688, 0.3862738609313965, 0.6168907284736633, -0.37866702675819397, -0.15034089982509613, -0.28047338128089905, -0.6378450393676758, -0.030763952061533928, 0.2615278363227844, 0.10366076231002808, -0.15133413672447205, 0.1323501616716385, 0.29534003138542175, 0.5052430033683777, -0.6759973764419556, -0.48409414291381836, 0.20822235941886902, -0.5838221907615662, -0.7981640696525574, -0.15586824715137482, -0.06992590427398682, -0.14098727703094482, 0.04246807470917702, 0.3618566691875458, 0.7721437215805054, 0.12380543351173401, -0.42170852422714233, 0.17922595143318176, -0.12051334232091904, -0.03750040382146835, -0.5388627052307129, -1.1346592903137207, -1.5455247163772583, -0.6059827208518982, -0.8390473127365112, -0.08276380598545074, -1.0699948072433472, -0.7871939539909363, 0.39322561025619507, -0.17731788754463196, 0.16625992953777313, 0.362162321805954, 0.4552925229072571, -0.014260664582252502, -0.6683831214904785, -0.8693004250526428, 0.5926443338394165, 0.750231146812439, -0.7320000529289246, -0.0658726617693901, -0.17009031772613525, -0.06793991476297379, 0.8094624876976013, 0.17403750121593475, -0.46644407510757446, -0.26095110177993774, -0.8568896651268005, 0.11557574570178986, -0.26274269819259644, -0.06435249000787735, -1.3475513458251953, 1.0625956058502197, 0.209845632314682, 0.5718812942504883, -0.15411688387393951, 0.4970881938934326, -0.7639975547790527, -1.0388883352279663, 0.3789244592189789, -0.3708456754684448, -0.2972346842288971, 0.2508644759654999, -0.5225850343704224, -0.020308824256062508, 1.034037709236145, 0.7549165487289429, -0.8438029289245605, -1.421507477760315, 0.4194297194480896, -0.6447445154190063, 0.10617346316576004, -0.3200148642063141, -0.25393229722976685, -1.304893970489502, -0.36047860980033875, -0.29866695404052734, 0.06992759555578232, -0.5610235333442688, 1.2156695127487183, 1.054076075553894, -1.0145195722579956, 0.05141656473278999, 0.5652154088020325, -0.24076859652996063, 0.13889864087104797, 0.42116594314575195, 0.5780006051063538, -0.44647133350372314, 0.3005312979221344, -0.14377060532569885, -0.12090566009283066, -0.6518686413764954, 0.2671393156051636, 1.2355105876922607, 0.16227692365646362, -0.4147120714187622, 0.7515093684196472, -0.32979488372802734, -0.3340487778186798, 0.2846777141094208, -1.5149248838424683, -0.45730477571487427, 0.0792730301618576, 0.4952657222747803, 0.0805942490696907, 0.12215178459882736, -0.183902770280838, -0.8595335483551025, 0.6347359418869019, 0.06537674367427826, -0.7113851308822632, 0.19612503051757812, -0.1504291594028473, 0.09999725967645645, 0.08291392773389816, 0.8506343364715576, -0.706599235534668, -1.0711511373519897, -0.9966839551925659, -0.7229614853858948, -0.35929346084594727, 0.34315693378448486, -0.24250303208827972, -0.7089216113090515, 0.6266672015190125, 1.0849515199661255, 0.29607728123664856, 0.5224800109863281, 0.29225316643714905, 0.01386281754821539, 0.6685695648193359, -0.13085472583770752, -0.7162203788757324, -0.05493205040693283, 1.446255087852478, 0.9611878991127014, -0.7655476927757263, 0.04523041844367981, -0.4457949697971344, -0.42861342430114746, 0.6599907875061035, 0.3630804121494293, -0.36976414918899536, 0.9223763942718506, 0.03163234516978264, -0.04535367339849472, 0.4850122034549713, -0.45394623279571533, -1.0695197582244873, 1.2080714702606201, 1.4874236583709717, 0.19863295555114746, 0.06911364197731018, 0.6126543283462524, 0.7968955039978027, 0.37769603729248047, -0.1267671287059784, 0.5210614800453186, 0.33017975091934204, -0.49599727988243103, 0.607258141040802, -0.5277618765830994, 0.5914400815963745, -0.8558735847473145, -0.39973515272140503, 0.16697783768177032, 0.28659334778785706, 0.5499652028083801, 0.8565460443496704, 1.0981943607330322, -0.007139866705983877, 0.817879855632782, -0.1514347344636917, 0.4875897467136383, -0.28351014852523804, -0.14162644743919373, 0.24990585446357727, -0.9073659777641296, -0.4605990946292877, 0.0017983177676796913, -0.7349693179130554, -0.13157342374324799, -0.1611214280128479, 0.5741486549377441, -0.7470402121543884, 0.35253986716270447, 0.7427255511283875, 0.5706100463867188, 1.0360051393508911, -0.5021000504493713, -1.0509647130966187, 0.20881137251853943, -0.7644110918045044, 0.2112985998392105, -0.5739326477050781, 0.25959110260009766, -0.2717486619949341, 0.1732511818408966, 0.14359666407108307]}, "authors": [{"authorId": "2114069742", "name": "Han Cai"}, {"authorId": "144158271", "name": "Chuang Gan"}, {"authorId": "2143833459", "name": "Song Han"}], "references": [{"paperId": "6409ca7fe8858f9c430f260969309ef8f12d24b8", "title": "Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation"}, {"paperId": "a09cbcaac305884f043810afc4fa4053099b5970", "title": "Exploring Plain Vision Transformer Backbones for Object Detection"}, {"paperId": "9f1b0e4c42a5a85d4c023030557ade4419f82ecf", "title": "Scaling Up Your Kernels to 31\u00d731: Revisiting Large Kernel Design in CNNs"}, {"paperId": "c49ac1f916d6d2edeb187e6619c8d23acd95eb21", "title": "cosFormer: Rethinking Softmax in Attention"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "0d9b8ccb1135b8e380dd8015b080158c6aae3ae5", "title": "QuadTree Attention for Vision Transformers"}, {"paperId": "e5cb26148791b57bfd36aa26ce2401e231d01b57", "title": "Vision Transformer with Deformable Attention"}, {"paperId": "9137efc758f80dd22bb56f82cca5c94f78a5db3e", "title": "MViTv2: Improved Multiscale Vision Transformers for Classification and Detection"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "e5c32ac6cb785832d5fe186cca654c6e41828f1c", "title": "PP-PicoDet: A Better Real-Time Object Detector on Mobile Devices"}, {"paperId": "8beae209c88558c8a8ad9ec66912dbb981949f66", "title": "MCUNetV2: Memory-Efficient Patch-based Inference for Tiny Deep Learning"}, {"paperId": "da74a10824193be9d3889ce0d6ed4c6f8ee48b9e", "title": "MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer"}, {"paperId": "a66686e60a3eda0c606e036403cf0a07a5962595", "title": "Mobile-Former: Bridging MobileNet and Transformer"}, {"paperId": "c01b385205e488a731c8c8c11c0c494d426beb03", "title": "YOLOX: Exceeding YOLO Series in 2021"}, {"paperId": "260ad39a1dac4b451019e2bf17925f4df8e3b69a", "title": "Per-Pixel Classification is Not All You Need for Semantic Segmentation"}, {"paperId": "5d032bd2632b6f5847767f39ce247098c6bbc563", "title": "Combiner: Full Attention Transformer with Sparse Computation Cost"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "48418b285a92376a38daafa664a2dd07d42e3fe3", "title": "Focal Self-attention for Local-Global Interactions in Vision Transformers"}, {"paperId": "bb6eba6d1c7f09255a9649eb2ed55bbd4f048091", "title": "Augmented Shortcuts for Vision Transformers"}, {"paperId": "7b664a306b7d2f68dd816ea1d6586cf3472d75c1", "title": "Early Convolutions Help Transformers See Better"}, {"paperId": "1fb10189c500e4902cd1b5afd406f57323d21be8", "title": "VOLO: Vision Outlooker for Visual Recognition"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "af679d69fcc1d0fcf0f039aba937853bcb50a8de", "title": "Luna: Linear Unified Nested Attention"}, {"paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60", "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"}, {"paperId": "2c9fdba6bf846e0986cbbf30d56b467d9e334333", "title": "ConTNet: Why not use convolution and transformer at the same time?"}, {"paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6", "title": "Multiscale Vision Transformers"}, {"paperId": "5b68522f58b61e7235b852677337ef3725075fd9", "title": "Co-Scale Conv-Attentional Image Transformers"}, {"paperId": "003326a15fc4a8833785a47a741d7712474fa256", "title": "LeViT: a Vision Transformer in ConvNet\u2019s Clothing for Faster Inference"}, {"paperId": "8f8f73f0f208302546c825ed474432389ed63be4", "title": "EfficientNetV2: Smaller Models and Faster Training"}, {"paperId": "40f4d7fe800810288a80f84cdb357a8f4c28e880", "title": "Rethinking Spatial Dimensions of Vision Transformers"}, {"paperId": "3cbe314cc5407a6c3249815b5173f22ea15173c2", "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "2984ab83ade26639c3a82d29628d0d9e4abbebb0", "title": "Incorporating Convolution Designs into Visual Transformers"}, {"paperId": "ac591dbf261777e05d89c27f9a7bcb06f88aab5a", "title": "Scalable Vision Transformers with Hierarchical Pooling"}, {"paperId": "610b302950a19acef1c45456111dcd495f638c18", "title": "ConViT: improving vision transformers with soft convolutional inductive biases"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "d29430adccb805ab57b349afa8553954347b3197", "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "0449c88867dec952945fc99749cc656df25c38b2", "title": "MobileDets: Searching for Object Detection Architectures for Mobile Accelerators"}, {"paperId": "2a6f7f0d659c5f7dcd665064b71e7b751592c80e", "title": "YOLOv4: Optimal Speed and Accuracy of Object Detection"}, {"paperId": "41c67d04be2d1632c0d3b0880c21c9fe797cdab8", "title": "EfficientDet: Scalable and Efficient Object Detection"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "7823292e5c4b05c47af91ab6ddf671a0da709e82", "title": "Once for All: Train One Network and Specialize it for Efficient Deployment"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "5e19eba1e6644f7c83f607383d256deea71f87ae", "title": "Searching for MobileNetV3"}, {"paperId": "b2324651155468c9b6bef8a2e006272126d17608", "title": "Fast-SCNN: Fast Semantic Segmentation Network"}, {"paperId": "0ba8182fa99559257e99a56d790bf2c705c42537", "title": "Bag of Freebies for Training Object Detection Neural Networks"}, {"paperId": "45532bffbfbb5553da0b2d0844e95a1b37e59147", "title": "FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search"}, {"paperId": "f323407464c4cd492d3fc1afd7170eab08f44d9b", "title": "ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware"}, {"paperId": "693c97ecedb0a84539b7162c95e89fa3cd84ca73", "title": "MnasNet: Platform-Aware Neural Architecture Search for Mobile"}, {"paperId": "c02b909a514af6b9255315e2d50112845ca5ed0e", "title": "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"}, {"paperId": "9217e28b2273eb3b26e4e9b7b498b4661e6e09f5", "title": "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation"}, {"paperId": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4", "title": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "1a857da1a8ce47b2aa185b91b5cb215ddef24de7", "title": "Focal Loss for Dense Object Detection"}, {"paperId": "1071b2435e0afa04c797dc09bf4ed9a630767b0c", "title": "On the Properties of the Softmax Function with Application in Game Theory and Reinforcement Learning"}, {"paperId": "1031a69923b80ad01cf3fbb703d10757a80e699b", "title": "Pyramid Scene Parsing Network"}, {"paperId": "67d968c7450878190e45ac7886746de867bf673d", "title": "Neural Architecture Search with Reinforcement Learning"}, {"paperId": "29e944711a354c396fad71936f536e83025b6ce0", "title": "Categorical Reparameterization with Gumbel-Softmax"}, {"paperId": "5b6ec746d309b165f9f9def873a2375b6fb40f3d", "title": "Xception: Deep Learning with Depthwise Separable Convolutions"}, {"paperId": "01434a4153d5340c00d9e2f910f462a841a7bca3", "title": "One-vs-Each Approximation to Softmax for Scalable Estimation of Probabilities"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "c8c494ee5488fe20e0aa01bddf3fc4632086d654", "title": "The Cityscapes Dataset for Semantic Urban Scene Understanding"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "6fc6803df5f9ae505cae5b2f178ade4062c768d0", "title": "Fully convolutional networks for semantic segmentation"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "b8a919f4a2aaa97bef19aa43e01f8bc347693b73", "title": "NASViT: Neural Architecture Search for Efficient Vision Transformers with Gradient Conflict aware Supernet Training"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "2a23ffef0b4f5f8689ffffb4cd9f515cb28336bd", "title": "HRFormer: High-Resolution Vision Transformer for Dense Predict"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Pytorch image models"}, {"paperId": null, "title": "Visual correspondence"}]}