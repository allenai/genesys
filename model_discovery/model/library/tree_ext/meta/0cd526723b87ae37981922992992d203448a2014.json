{"paperId": "0cd526723b87ae37981922992992d203448a2014", "title": "DilateFormer: Multi-Scale Dilated Transformer for Visual Recognition", "abstract": "As a de facto solution, the vanilla Vision Transformers (ViTs) are encouraged to model long-range dependencies between arbitrary image patches while the global attended receptive field leads to quadratic computational cost. Another branch of Vision Transformers exploits local attention inspired by CNNs, which only models the interactions between patches in small neighborhoods. Although such a solution reduces the computational cost, it naturally suffers from small attended receptive fields, which may limit the performance. In this work, we explore effective Vision Transformers to pursue a preferable trade-off between the computational complexity and size of the attended receptive field. By analyzing the patch interaction of global attention in ViTs, we observe two key properties in the shallow layers, namely locality and sparsity, indicating the redundancy of global dependency modeling in shallow layers of ViTs. Accordingly, we propose Multi-Scale Dilated Attention (MSDA) to model local and sparse patch interaction within the sliding window. With a pyramid architecture, we construct a Multi-Scale Dilated Transformer (DilateFormer) by stacking MSDA blocks at low-level stages and global multi-head self-attention blocks at high-level stages. Our experiment results show that our DilateFormer achieves state-of-the-art performance on various vision tasks. On ImageNet-1 K classification task, DilateFormer achieves comparable performance with 70% fewer FLOPs compared with existing state-of-the-art models. Our DilateFormer-Base achieves 85.6% top-1 accuracy on ImageNet-1 K classification task, 53.5% box mAP/46.1% mask mAP on COCO object detection/instance segmentation task and 51.1% MS mIoU on ADE20 K semantic segmentation task. The code is available at https://isee-ai.cn/~jiaojiayu/DilteFormer.html.", "venue": "IEEE transactions on multimedia", "year": 2023, "citationCount": 35, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2302.01791", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work analyzes the patch interaction of global attention in ViTs and proposes Multi-Scale Dilated Attention (MSDA) to model local and sparse patch interaction within the sliding window, indicating the redundancy of global dependency modeling in shallow layers of ViTs."}, "embedding": {"model": "specter_v2", "vector": [0.1974879801273346, 0.43681296706199646, 0.016861429437994957, 0.2054116427898407, -0.10637456923723221, 0.08778273314237595, 0.5075661540031433, -0.15551164746284485, -0.25173255801200867, -0.6736739277839661, 0.5028082132339478, 0.9490309953689575, 0.5918548703193665, -0.17054593563079834, -0.06227036938071251, -0.00014064541028346866, -0.6357739567756653, -0.11630029231309891, 0.8698139190673828, -0.35624754428863525, 0.07791952788829803, -0.39284732937812805, -0.9449232816696167, 0.3042733371257782, 0.21281178295612335, 1.3145802021026611, 0.6886844038963318, 0.9395430684089661, 0.1652108132839203, 0.28549283742904663, 0.2704724073410034, -0.22287583351135254, 0.5595733523368835, -0.25004833936691284, -0.256429523229599, 0.12071184813976288, 0.899040699005127, -0.31889429688453674, -0.6794304847717285, 1.015425682067871, 0.12857666611671448, 0.28426581621170044, 0.4046080410480499, -0.5201048254966736, -0.4740397036075592, 0.44046682119369507, 0.4532894492149353, 1.1131502389907837, -0.8276544809341431, -0.7774015665054321, 1.2252057790756226, -1.30259370803833, 0.1205286905169487, 1.6301064491271973, 0.388132780790329, 0.17271946370601654, -0.21048885583877563, -0.3706229627132416, 0.8290792107582092, 0.33972758054733276, -0.5941655039787292, -0.1649458408355713, 0.277717262506485, -0.029413120821118355, 1.9168784618377686, -0.6878986954689026, 0.08989302814006805, 0.3247184157371521, 0.3307352066040039, 1.285772681236267, -0.21238668262958527, -0.703449547290802, -0.15969392657279968, -0.18988558650016785, 0.40740981698036194, 0.5423808097839355, -0.162239670753479, 0.1330774426460266, -0.8990156054496765, 0.288939893245697, 0.9179990887641907, 0.12213596701622009, 0.5301551818847656, -0.1823825240135193, 0.13634833693504333, 0.6569759249687195, 1.1656277179718018, 0.7873881459236145, -0.2999407649040222, 0.7604888677597046, 0.5173096060752869, -0.09758670628070831, -0.1793997883796692, 0.3925471901893616, -0.10002721846103668, 1.2421367168426514, -0.5189647078514099, 0.10862165689468384, -0.3991564214229584, 0.950674295425415, -0.08118132501840591, 0.3444853127002716, -0.5177077054977417, 0.3223089575767517, 1.0707288980484009, 0.17689141631126404, 0.16848157346248627, -0.4762963652610779, -0.23480021953582764, -0.61802738904953, -0.3942526578903198, -1.0629258155822754, -0.025073274970054626, -0.5237821340560913, -1.0675710439682007, -0.9297316670417786, -0.30788615345954895, 0.7241337895393372, -1.066292643547058, 0.36537307500839233, -0.3695395290851593, 0.14003898203372955, -0.24618780612945557, 0.6828970909118652, 0.548778772354126, 0.29885801672935486, 0.49027711153030396, 0.4121272563934326, 1.248946189880371, -1.3632409572601318, -0.20885786414146423, -0.78340744972229, -0.6151761412620544, -0.41191256046295166, -0.20794853568077087, -0.2589917480945587, -1.2442227602005005, -1.772406816482544, -0.7559404373168945, -0.12505313754081726, -0.7251021862030029, 0.03719822317361832, 0.7590106129646301, -0.012346800416707993, -1.1149868965148926, 0.8165491223335266, -0.4714704751968384, -0.5239936113357544, 0.8842737078666687, 0.15703009068965912, 0.7211175560951233, 0.16174957156181335, -1.1052299737930298, 0.2991397976875305, -0.20828889310359955, -0.36013278365135193, -0.5151579976081848, -0.27720290422439575, -0.9355087876319885, 0.3009018003940582, 0.08728667348623276, -0.5641217231750488, 1.0545872449874878, -0.4571506381034851, -0.5871440768241882, 0.2583948075771332, -0.14044806361198425, -0.08331752568483353, -0.08307790011167526, -0.14865240454673767, -0.02109575644135475, -0.2453170120716095, -0.10190082341432571, 0.7169855833053589, 1.1009505987167358, -0.009755202569067478, -0.29243311285972595, -0.134608194231987, -0.30865153670310974, 0.026470480486750603, -0.6097334623336792, 0.9532657861709595, -0.6715881824493408, -0.795006513595581, 0.35442543029785156, 0.8331307172775269, -0.15771019458770752, -0.42790520191192627, 0.10938262194395065, -1.1960601806640625, 0.9750226736068726, 0.3834289610385895, 0.6238993406295776, -0.9287776350975037, -0.5606021881103516, -0.3343052268028259, 0.09258823841810226, 0.03245391324162483, -1.072773814201355, 0.18252438306808472, -0.2964087426662445, -0.012358340434730053, 0.3728379011154175, -0.8037500977516174, -0.03263961523771286, -0.536673903465271, -0.7057822942733765, 0.0244430098682642, 0.4407098591327667, 1.389990210533142, -0.7417992353439331, -0.20713402330875397, -0.030004957690835, 0.4324612319469452, -0.9723994135856628, 1.1342586278915405, -0.2408556193113327, 0.0205319132655859, -0.43308037519454956, 0.41946911811828613, -0.019345249980688095, -0.30809736251831055, 0.34380394220352173, -0.8614984750747681, 0.04890544340014458, 0.1260603368282318, -0.3969149589538574, 1.1683732271194458, 0.17478537559509277, 0.7324028611183167, -0.17280156910419464, -0.9234803915023804, 0.4176834225654602, 0.17361882328987122, -0.1888621300458908, -0.8917278051376343, 0.590605616569519, 0.06578585505485535, -0.8801456093788147, 0.35054659843444824, 0.5591714978218079, 1.3138651847839355, -0.5153370499610901, -0.29658764600753784, 0.8860262632369995, -0.4109461307525635, 0.0745200514793396, 0.4998015761375427, 0.5555737614631653, 0.27745842933654785, 0.5088083744049072, -0.33413165807724, 0.2027376890182495, -0.8937520980834961, 0.06504775583744049, 0.9343445301055908, 0.086177758872509, 1.2945623397827148, 0.5138516426086426, -0.9056926965713501, -0.7268134951591492, 0.010692841373383999, 0.31356045603752136, 1.3476051092147827, 0.2773127555847168, 0.03529917076230049, -0.8125551342964172, -0.27390021085739136, -0.5351454615592957, -1.0850080251693726, -0.42347344756126404, -0.05087549611926079, -0.31979814171791077, -0.8653938174247742, 0.5066928863525391, 0.5433834195137024, 1.2988618612289429, -0.8768041729927063, -0.5181241631507874, -0.23591427505016327, 0.5256019234657288, -0.9612078666687012, -0.939915657043457, 0.38129204511642456, -0.25073888897895813, -0.17590078711509705, -0.1534351110458374, -0.6788813471794128, 0.39735400676727295, -0.49714651703834534, 0.8270373344421387, -0.8648661971092224, -0.8605594635009766, 0.3275006413459778, 0.19636714458465576, -0.8466570973396301, -0.04948003590106964, 0.16704797744750977, -0.000614177028182894, -0.03444864973425865, 0.28152647614479065, 0.22653138637542725, -0.5043202042579651, 0.2962610721588135, -0.4497162103652954, -0.26592764258384705, 0.23179426789283752, 0.27224159240722656, 0.9814653992652893, -0.2500198781490326, 0.4629899263381958, -0.7858185172080994, 0.6042503118515015, 0.5285246968269348, -0.521453320980072, 0.017130432650446892, -0.3031143844127655, -0.49684029817581177, 0.39566534757614136, -0.6932527422904968, -0.1647263467311859, -0.35432931780815125, 0.5927232503890991, -0.7052652835845947, -0.14455917477607727, -0.18837183713912964, 0.3145691454410553, -0.2806091606616974, 0.7029622793197632, 0.12643659114837646, -0.044206541031599045, 0.1448451280593872, 0.20475023984909058, -0.8207428455352783, 0.7777012586593628, 0.30650749802589417, -0.011027048341929913, 0.06701802462339401, -0.1497291475534439, -0.854105532169342, -0.3901180028915405, -0.7249563336372375, -0.4890228807926178, -0.3031270503997803, 0.5276700258255005, -0.6625766754150391, -0.8336982727050781, 0.5623934864997864, -0.9826111197471619, -0.09229109436273575, -0.05115286633372307, -0.34645259380340576, -0.18392789363861084, -1.2118765115737915, -1.060396432876587, -0.14766602218151093, -0.711372435092926, -1.0515263080596924, 0.2759602665901184, 0.7215465903282166, -0.18857623636722565, -0.2357989400625229, -0.19855327904224396, -0.5883309245109558, 1.2728983163833618, -0.26526981592178345, 0.37889403104782104, -0.14933663606643677, -0.6598955392837524, -0.27392274141311646, -0.3720979392528534, 0.8321285247802734, -0.24955013394355774, -0.11190611124038696, -0.9186195731163025, 0.07185063511133194, -0.17011509835720062, -0.39033326506614685, 0.7356627583503723, 0.7621196508407593, 0.7864080667495728, 0.33055660128593445, -0.3002263605594635, 0.3033999502658844, 1.6618826389312744, -0.5503717660903931, 0.1776224821805954, -0.22884239256381989, 0.9110469818115234, -0.07190253585577011, -0.3413606286048889, 0.6375331282615662, 0.4006771147251129, 0.11607824265956879, 0.4677180051803589, -0.5565851330757141, -1.0422236919403076, -0.439889520406723, -0.1840154528617859, 0.9472777247428894, 0.1788649559020996, 0.29561731219291687, -0.7843204736709595, 1.0808426141738892, -1.2871556282043457, -0.6683793067932129, 0.869959831237793, 0.4004531502723694, -0.10042492300271988, -0.3373367190361023, -0.37250545620918274, -0.5378349423408508, 0.8086915016174316, 0.6498830914497375, -0.6187318563461304, -0.5481317639350891, -0.2130618393421173, 0.9711446166038513, 0.29605206847190857, 0.5038111209869385, -0.6486014723777771, 0.8705554008483887, 14.627225875854492, 0.6025304198265076, -0.11683697253465652, 0.6224405169487, 0.9911289215087891, 0.6594644784927368, 0.07939552515745163, 0.10918910801410675, -1.1611772775650024, -0.4581301510334015, 0.2003576010465622, 0.47812163829803467, 0.42405250668525696, 0.4114464521408081, -0.35586559772491455, 0.15645526349544525, -0.5209241509437561, 0.8219701051712036, 0.6666088700294495, -1.34920072555542, 0.08862052857875824, 0.005356167908757925, 0.8649164438247681, 0.7200537323951721, 0.7798997163772583, 0.5364729762077332, 0.04774250462651253, -0.1989898383617401, 0.4316830635070801, 0.11231248825788498, 0.6073167324066162, 0.24596676230430603, 0.08633652329444885, -0.3268469572067261, -1.496140718460083, -0.35015878081321716, -0.9060600996017456, -1.0637351274490356, -0.25489309430122375, -0.11051587760448456, 0.05397564172744751, -0.6700882315635681, 0.49779218435287476, 0.9782941341400146, -0.2238147109746933, 0.4779421091079712, -0.16495341062545776, -0.04902509227395058, -0.031036000698804855, -0.3163049519062042, 0.1951340138912201, 0.8535109758377075, 0.32179832458496094, 0.018459295853972435, -0.31708860397338867, 0.5771610736846924, 0.21648938953876495, 0.57231205701828, -0.5896509885787964, -0.4318665862083435, 0.13599908351898193, 0.026710685342550278, -0.13617180287837982, 1.1863330602645874, -0.20176805555820465, -0.017232846468687057, -0.3742887079715729, 0.3894677758216858, 0.3753857910633087, 0.42264944314956665, -0.5126379132270813, -0.4177928566932678, 0.12749584019184113, -0.46442532539367676, 0.721240222454071, 0.4969734251499176, -0.45352086424827576, -0.6263014078140259, -0.731639564037323, -0.20672354102134705, 0.6156128644943237, -0.7109513878822327, -0.6955090761184692, 1.2450852394104004, -0.2821500301361084, -0.007499368395656347, 0.8473062515258789, -0.8364431262016296, -0.40151816606521606, 0.471462607383728, -1.2746131420135498, -0.7859412431716919, 0.016473975032567978, -0.0751105323433876, 0.004986307583749294, -0.05039813742041588, 0.7867304086685181, 0.042631421238183975, -0.1782843917608261, -0.036186832934617996, -0.7646587491035461, 0.17961595952510834, -0.14726023375988007, -0.5838301181793213, 0.8308702111244202, 0.6587977409362793, -0.19301000237464905, -0.2968021333217621, -0.1562405824661255, 0.252525269985199, -0.4279913306236267, 0.06899785250425339, 0.6038674712181091, -0.4578211009502411, -0.3494334816932678, -0.6895155310630798, -0.6254367232322693, 0.029052358120679855, 0.8575096130371094, 0.5324839949607849, -0.3958393633365631, 0.06922297179698944, -0.6564939022064209, -0.5967532992362976, -0.5258083343505859, -0.26501452922821045, 0.285261869430542, -0.8311940431594849, -0.47928014397621155, -0.29909005761146545, 0.07291898131370544, -0.9799616932868958, -0.4796437621116638, 0.03677069768309593, 0.2079491913318634, -0.3687000274658203, 1.1907323598861694, -0.36851176619529724, 0.4271717667579651, 0.8236041069030762, -0.32195228338241577, -0.42560887336730957, -0.36591944098472595, -0.7602022886276245, 0.306066632270813, 0.2206120491027832, 0.11556264013051987, -0.328960657119751, 0.010656836442649364, 0.7198267579078674, 0.3155934512615204, -0.6632018685340881, -0.41663026809692383, 0.299262136220932, -0.2195024937391281, -0.3945426642894745, 0.041104719042778015, -0.30836981534957886, 0.0544612891972065, 0.12174639105796814, 0.6769686341285706, 0.7634310126304626, 0.14703789353370667, -0.3155369460582733, 0.1866965889930725, 0.017257554456591606, -0.18808811902999878, -0.7157498598098755, -1.1341097354888916, -1.624252438545227, -0.4899537265300751, -0.8584645390510559, -0.16504144668579102, -0.7937602400779724, -0.1988176852464676, 0.21916420757770538, -0.799247682094574, 0.31676724553108215, 0.2882172763347626, 0.3540588915348053, -0.10125008970499039, -0.4376205503940582, -0.7068997621536255, 0.7075926661491394, 1.3117551803588867, -0.8212719559669495, -0.21821534633636475, -0.30260705947875977, -0.09542929381132126, 0.5030015707015991, 0.093085378408432, -0.2677744925022125, -0.4909033477306366, -1.058638095855713, 0.12095242738723755, -0.2149955779314041, 0.1874997615814209, -1.2432191371917725, 1.3060381412506104, 0.6768638491630554, 0.3257182538509369, 0.027449151501059532, 0.14604923129081726, -0.6679953336715698, -0.9095267057418823, 0.5048707127571106, -0.6892732977867126, -0.2829815745353699, 0.1101919561624527, -0.6393402218818665, -0.6327312588691711, 1.1409189701080322, 0.4667910039424896, -1.1915359497070312, -1.2197284698486328, 0.715506374835968, -0.20590056478977203, 0.22058416903018951, -0.18948215246200562, 0.0518689900636673, -1.2670072317123413, -0.12642741203308105, -0.4316524863243103, 0.20729106664657593, -0.9252846837043762, 1.010123610496521, 0.8350401520729065, -1.1506353616714478, 0.08333347737789154, 0.6681123971939087, -0.42713457345962524, 0.32460129261016846, 0.5643747448921204, 0.44291234016418457, -0.23741254210472107, 0.4314010441303253, -0.20313379168510437, 0.010124904103577137, -0.6153725385665894, 0.2253970205783844, 1.0893913507461548, -0.15899468958377838, 0.035509560257196426, 1.3128886222839355, 0.2234252244234085, -0.3257101774215698, 0.31895729899406433, -1.0865814685821533, -0.4843313992023468, 0.11423759907484055, 0.546460747718811, 0.11656124889850616, -0.06810541450977325, -0.16721273958683014, -0.6374226808547974, 0.5568530559539795, -0.30100128054618835, -0.21946988999843597, 0.5040121674537659, -0.005929609760642052, -0.41022971272468567, -0.06624015420675278, 0.8037044405937195, -1.0223408937454224, -1.2618800401687622, -1.1585975885391235, -0.9049874544143677, -0.21423441171646118, 0.1765126734972, -0.014441541396081448, -1.1408491134643555, 0.4660172462463379, 0.7196155786514282, 0.6261905431747437, 0.7432135939598083, 0.26069432497024536, 0.0566837377846241, 0.3679734468460083, -0.07063914090394974, -0.6857223510742188, 0.04987410455942154, 1.2577940225601196, 1.481041669845581, -0.7491763234138489, -0.011819813400506973, -0.23294082283973694, -0.5750131607055664, 0.7308526039123535, 0.6862576007843018, -0.9249230623245239, 1.2330583333969116, -0.25979119539260864, 0.10969195514917374, 0.04796113446354866, -0.6066436171531677, -0.706485390663147, 0.9940696358680725, 1.174920678138733, 0.31602078676223755, -0.03958120569586754, 0.06794165819883347, 0.8049253821372986, 0.46041029691696167, -0.49625164270401, 0.12694387137889862, 0.1152777448296547, -0.12158460915088654, 0.189194917678833, -0.10615211725234985, 0.40315818786621094, -0.6061223149299622, -0.33616259694099426, 0.14463838934898376, 0.3135316073894501, 0.32623228430747986, 0.6166456937789917, 1.0258525609970093, 0.047418903559446335, 0.8899781703948975, -0.463290274143219, 0.6858629584312439, -0.3723640739917755, -0.25692832469940186, 0.5711773037910461, -1.2872076034545898, -0.37953394651412964, -0.5904538035392761, -0.6343750953674316, -0.17980389297008514, 0.30577343702316284, 0.1320801079273224, -0.48357853293418884, 0.2894100844860077, 0.7856639623641968, 0.49920374155044556, 1.1749908924102783, 0.02709205076098442, -0.9760181307792664, -0.293818861246109, -1.0287436246871948, 0.1913113296031952, -0.20235475897789001, 0.09452888369560242, -0.0555928573012352, 0.18704363703727722, -0.04874702915549278]}, "authors": [{"authorId": "2204464639", "name": "Jiayu Jiao"}, {"authorId": "2119309865", "name": "Yuyao Tang"}, {"authorId": "151478390", "name": "Kun-Li Channing Lin"}, {"authorId": "2118544431", "name": "Yipeng Gao"}, {"authorId": "2204468299", "name": "Jinhua Ma"}, {"authorId": "2119050330", "name": "Yaowei Wang"}, {"authorId": "2152975603", "name": "Wei-Shi Zheng"}], "references": [{"paperId": "a883336e5c2e9f46f5012343227a6be4671c9ca0", "title": "Dilated Neighborhood Attention Transformer"}, {"paperId": "a4b728dbbf5afdc231afb95ad4e5c2ececdefc48", "title": "Next-ViT: Next Generation Vision Transformer for Efficient Deployment in Realistic Industrial Scenarios"}, {"paperId": "0594eaa8dfe580678a2382aaf77ac3582c872a97", "title": "TRT-ViT: TensorRT-oriented Vision Transformer"}, {"paperId": "ad7bcec33f5206d4f28687a6a5a950de67010651", "title": "Neighborhood Attention Transformer"}, {"paperId": "2ad12a7be5eaf339a98c4defd8669e11fe726acc", "title": "MaxViT: Multi-Axis Vision Transformer"}, {"paperId": "e4ed352c7db8cb0b4b5ee4107659a85f1f8aebf4", "title": "Template-Aware Transformer for Person Reidentification"}, {"paperId": "27a1165c29a08fb885674bd4421089e8a5aa6358", "title": "ResT-ReID: Transformer block-based residual learning for person re-identification"}, {"paperId": "f4b11a696aa5a03fed1bfc47e65fdb7eb0e529c1", "title": "UniFormer: Unifying Convolution and Self-Attention for Visual Recognition"}, {"paperId": "41396b28fb56f5699f24ac0a85902165b88c696f", "title": "SimViT: Exploring a Simple Vision Transformer with Sliding Windows"}, {"paperId": "15b0e710a9b8069d898ae6a0963d627e0fb86bd8", "title": "MPViT: Multi-Path Vision Transformer for Dense Prediction"}, {"paperId": "e0e6ae2ef8ef9f02e0c65ada61eadd82b7ce8a9c", "title": "Shunted Self-Attention via Multi-Scale Token Aggregation"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "9c4753ef43d2928866dc5bf6cec53d03373ec2fa", "title": "SimMIM: a Simple Framework for Masked Image Modeling"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "21dbc2998779c602185a95e326364001ec6d87ea", "title": "SOTR: Segmenting Objects with Transformers"}, {"paperId": "a66686e60a3eda0c606e036403cf0a07a5962595", "title": "Mobile-Former: Bridging MobileNet and Transformer"}, {"paperId": "c945efdeefaacb8ca679298720f4b0b054dc84bd", "title": "Vision Transformer with Progressive Sampling"}, {"paperId": "a9c214e846188adb645021cd7b1964b8ea1fef6f", "title": "Rethinking and Improving Relative Position Encoding for Vision Transformer"}, {"paperId": "e3b56d3515b5fa19c3bd4764400754079932f718", "title": "A Unified Efficient Pyramid Transformer for Semantic Segmentation"}, {"paperId": "87e823d2cb58e741230c0fa3b83f3459c7e32241", "title": "PiSLTRc: Position-Informed Sign Language Transformer With Content-Aware Convolution"}, {"paperId": "dfa8694c3329c31205cd2454fa59c9e607b43695", "title": "Contextual Transformer Networks for Visual Recognition"}, {"paperId": "0b036cd5dfc49d835d0c759c8ca31d89f2410e65", "title": "CMT: Convolutional Neural Networks Meet Vision Transformers"}, {"paperId": "aebc74ff69a84fb35060738a5da77cb8a2e7bd47", "title": "Crowd Counting Via Perspective-Guided Fractional-Dilation Convolution"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "48418b285a92376a38daafa664a2dd07d42e3fe3", "title": "Focal Self-attention for Local-Global Interactions in Vision Transformers"}, {"paperId": "7b664a306b7d2f68dd816ea1d6586cf3472d75c1", "title": "Early Convolutions Help Transformers See Better"}, {"paperId": "1fb10189c500e4902cd1b5afd406f57323d21be8", "title": "VOLO: Vision Outlooker for Visual Recognition"}, {"paperId": "39ce4484cf44cf7a9f545cd4ffdfd6feac6c4a0b", "title": "Multi-Scale Grid Network for Image Deblurring With High-Frequency Guidance"}, {"paperId": "c7b2e98390bf634ca50cee9e5d3a9319cb3b127d", "title": "Learning Scale-Consistent Attention Part Network for Fine-Grained Image Recognition"}, {"paperId": "7fff8018bf625447df837c2fda5c58a705fbc038", "title": "XCiT: Cross-Covariance Image Transformers"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "6b6ffb94626e672caffafc77097491d9ee7a8682", "title": "On the Connection between Local Attention and Dynamic Depth-wise Convolution"}, {"paperId": "f43b98fcc2d56c60fc71bce96374c1e6b8e12c66", "title": "Shuffle Transformer: Rethinking Spatial Shuffle for Vision Transformer"}, {"paperId": "576c462dbc1f3d732b919ef1daac37a817123e52", "title": "ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias"}, {"paperId": "ac74a160e0ca53d3ffb15f79f0b9d3911df2fc28", "title": "Glance-and-Gaze Vision Transformer"}, {"paperId": "1ee1160b8c7c70ded02e786c184a6da651e88bed", "title": "Dynamic Head: Unifying Object Detection Heads with Attentions"}, {"paperId": "f80775a79d42a1ddfc0df808ea760c57af4949d0", "title": "Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding"}, {"paperId": "5faf75b5c5a4d83bd6407b4aba8fb0bccd7fa31d", "title": "Conformer: Local Features Coupling Global Representations for Visual Recognition"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "cc9f3a61ea4eaabf43cbb30cd1dd718074932679", "title": "All Tokens Matter: Token Labeling for Training Better Vision Transformers"}, {"paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6", "title": "Multiscale Vision Transformers"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "3cbe314cc5407a6c3249815b5173f22ea15173c2", "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "0eff37167876356da2163b2e396df2719adf7de9", "title": "CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification"}, {"paperId": "2984ab83ade26639c3a82d29628d0d9e4abbebb0", "title": "Incorporating Convolution Designs into Visual Transformers"}, {"paperId": "96da196d6f8c947db03d13759f030642f8234abf", "title": "DeepViT: Towards Deeper Vision Transformer"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "63812f583caac3ac32bbfb64f66ba69e57c1e90a", "title": "Conditional Positional Encodings for Vision Transformers"}, {"paperId": "b4ce7f92a8b987b5e76d580bf5076e2495f06883", "title": "TransReID: Transformer-based Object Re-Identification"}, {"paperId": "3c667245c074e51e5d0c17ad0772fc202f264d89", "title": "Spatiotemporal Dilated Convolution With Uncertain Matching for Video-Based Crowd Estimation"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78", "title": "Bottleneck Transformers for Visual Recognition"}, {"paperId": "69621df0df837d345d764525696899e0570194b6", "title": "Fast Convergence of DETR with Spatially Modulated Co-Attention"}, {"paperId": "71d7e1ea7e8fdd9e8aa0a69a1e29b911c91f105a", "title": "LAG-Net: Multi-Granularity Network for Person Re-Identification via Local Attention System"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "135d2e3c59f9c5df971e88b1a082557ee8010bf6", "title": "Dual Attention on Pyramid Feature Maps for Image Captioning"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "13da774fe604027bff2951ba82f4c3d9be7e415e", "title": "Augment Your Batch: Improving Generalization Through Instance Repetition"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "f5c89f880165f974bba359ed5e67e89da792c643", "title": "SAL:Selection and Attention Losses for Weakly Supervised Semantic Segmentation"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "fb7972f30812c7dd056d7943c3e3f00af022d607", "title": "Dynamic Convolution: Attention Over Convolution Kernels"}, {"paperId": "bc626a52664e948a0ffb2b95d0e1e6377a01171a", "title": "Cascade R-CNN: High Quality Object Detection and Instance Segmentation"}, {"paperId": "c2c083df88e88223e1a411e61040b94c233b1b63", "title": "MMDetection: Open MMLab Detection Toolbox and Benchmark"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "a84906dbd4d6640f918d0b6ed2a7313dda0d55f1", "title": "Panoptic Feature Pyramid Networks"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "ebc96892b9bcbf007be9a1d7844e4b09fde9d961", "title": "YOLOv3: An Incremental Improvement"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "79cfb51a51fc093f66aac8e858afe2e14d4a1f20", "title": "Focal Loss for Dense Object Detection"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "ee4a012a4b12d11d7ab8c0e79c61e807927a163c", "title": "Rethinking Atrous Convolution for Semantic Image Segmentation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "fafcaf5ca3fab8dc4fad15c2391c0fdb4a7dc005", "title": "Group Equivariant Convolutional Networks"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0", "title": "SSD: Single Shot MultiBox Detector"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "7f5fc84819c0cf94b771fe15141f65b123f7b8ec", "title": "Multi-Scale Context Aggregation by Dilated Convolutions"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "6364fdaa0a0eccd823a779fcdd489173f938e91a", "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation"}, {"paperId": "6fc6803df5f9ae505cae5b2f178ade4062c768d0", "title": "Fully convolutional networks for semantic segmentation"}, {"paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327", "title": "Going deeper with convolutions"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "c4846423e5e51b3a0d16630afd7fd2a20b1e5fc5", "title": "Consistent Discrepancy Learning for Intra-Camera Supervised Person Re-Identification"}, {"paperId": null, "title": "\u201cA ConvNet for the 2020 s,\u201d"}, {"paperId": "cf978901174e9d492fe6a0d86ea2e4f1ba344937", "title": "Self-Attention-Based Multiscale Feature Learning Optical Flow With Occlusion Feature Map Prediction"}, {"paperId": "04084461a7e10b84ca71134f4c45eb92cdff7f51", "title": "Multi-Focus Image Fusion Based on Multi-Scale Gradients and Image Matting"}, {"paperId": "fddb1966a1deaf8203ffdd4a2fc205c1c16426bf", "title": "MIG-Net: Multi-Scale Network Alternatively Guided by Intensity and Gradient Features for Depth Map Super-Resolution"}, {"paperId": "3ef7464a5fadc948399c056ac9879b5ed64c0f5b", "title": "Structured Attention Network for Referring Image Segmentation"}, {"paperId": "22840652f0ed5f81377a956b372bba88cdd60d1c", "title": "LAGA-Net: Local-and-Global Attention Network for Skeleton Based Action Recognition"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "add8b5d665de42d2575a321fd90e8624d3eb59b5", "title": "Spatial Pyramid Attention for Deep Convolutional Neural Networks"}, {"paperId": "9f7f81b1c82828a45a52df8f0c6a92636af76c7e", "title": "CrossFormer: A Versatile Vision Transformer Based on Cross-scale Attention"}, {"paperId": "654247d5b184495fca18c6aa7e840e4f4559fef0", "title": "Do We Really Need Explicit Position Encodings for Vision Transformers?"}, {"paperId": "1dc37521adde97f839ee8384080702d8762e3df0", "title": "COMO: Efficient Deep Neural Networks Expansion With COnvolutional MaxOut"}, {"paperId": "083ca4bd4d5b231a1d7a0715ec55cc57a0f44b13", "title": "Aggregating Nested Transformers"}, {"paperId": "3889cb8c459eeedc249c4724f72b6bfba63fd9b8", "title": "Stacked U-Shape Network With Channel-Wise Attention for Salient Object Detection"}, {"paperId": null, "title": "Pytorch library for cam methods"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "ACTIONS ON P ATTERN A NALYSIS AND M ACHINE I N - TELLIGENCE"}, {"paperId": null, "title": "Brunswick,"}, {"paperId": null, "title": "license agreement with IEEE. Restrictions apply"}]}