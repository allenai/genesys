{"paperId": "203af8a5076910b4e9581ca750328f1bd98d3587", "title": "Evaluation of Few-Shot Learning for Classification Tasks in the Polish Language", "abstract": "We introduce a few-shot benchmark consisting of 7 different classification tasks native to the Polish language. We conducted an empirical comparison with 0 and 16 shots between fine-tuning, linear probing, SetFit, and in-context learning (ICL) using various pre-trained commercial and open-source models. Our findings reveal that ICL achieves the best performance, with commercial models like GPT-3.5 and GPT-4 attaining the best performance. However, there remains a significant 14 percentage points gap between our best few-shot learning score and the performance of HerBERT-large fine-tuned on the entire training dataset. Among the techniques, SetFit emerges as the second-best approach, closely followed by linear probing. We observed the worst and most unstable performance with non-linear head fine-tuning. Results for ICL indicate that continual pre-training of models like Mistral-7b or Llama-2-13b on Polish corpora is beneficial. This is confirmed by the improved performances of Bielik-7b and Trurl-13b, respectively. To further support experiments in few-shot learning for Polish, we are releasing handcrafted templates for the ICL.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "An empirical comparison with 0 and 16 shots between fine-tuning, linear probing, SetFit, and in-context learning (ICL) using various pre-trained commercial and open-source models reveals that ICL achieves the best performance, with commercial models like GPT-3.5 and GPT-4 attaining the best performance."}, "embedding": {"model": "specter_v2", "vector": [0.23368382453918457, 0.7077268362045288, -0.662298858165741, -0.04550168290734291, -0.30593734979629517, -0.07265029847621918, 0.8867796659469604, -0.4704384207725525, -0.37185725569725037, 0.05061560869216919, 0.4346453845500946, 0.19831742346286774, 0.18309395015239716, -0.15488089621067047, 0.2049327790737152, -0.07411502301692963, -0.5644533038139343, 0.374205082654953, 0.36698436737060547, -0.513195276260376, -0.06877993047237396, -1.0308051109313965, -0.780381441116333, 0.04770911484956741, -0.10171310603618622, 0.2555425763130188, 0.11647456884384155, 0.616129994392395, -0.5708253383636475, 0.43529218435287476, 0.5116446018218994, -0.7117671966552734, 0.4906599819660187, 0.16451048851013184, -0.7086637020111084, 0.0984092727303505, 0.3793655335903168, -0.40576454997062683, -0.371926486492157, 0.49689456820487976, -0.1254001408815384, 0.44443294405937195, 0.34964069724082947, -0.6743892431259155, -0.31866490840911865, 0.709269642829895, 0.7535071969032288, 0.28589823842048645, -0.23423665761947632, -0.09940161556005478, 1.4162670373916626, -1.3285088539123535, 0.5806944370269775, 1.2873867750167847, 0.6248177289962769, 0.9389470219612122, -0.37084710597991943, -0.5464609861373901, 0.32153141498565674, 0.3292678892612457, -0.6367962956428528, -0.37794098258018494, 0.10202392935752869, -0.21578550338745117, 1.6288988590240479, -0.5678725242614746, -0.3231792151927948, 0.6817716956138611, 0.02091732807457447, 1.192196011543274, -0.34288614988327026, -0.9291612505912781, -0.3362995386123657, 0.2343750298023224, 0.815541684627533, 0.7208453416824341, -0.8062565326690674, 0.23831436038017273, -0.6244545578956604, -0.10316181927919388, 0.2516203820705414, 0.2946724593639374, -0.027949638664722443, -0.19182533025741577, -0.19344939291477203, 0.7541341781616211, -0.029651574790477753, 1.015773057937622, 0.059392303228378296, 0.6983430981636047, 0.9347326755523682, 0.6616643071174622, 0.04184715449810028, 0.44718316197395325, -0.24084746837615967, 0.44021448493003845, -0.48360350728034973, 0.3081500232219696, 0.08858247101306915, 1.024657130241394, 0.11576105654239655, -0.1123969778418541, -1.3118751049041748, 0.48610547184944153, 0.7949919104576111, -0.7408886551856995, 0.3926793932914734, -1.1258488893508911, 0.05265810713171959, -0.5118704438209534, 0.07425501942634583, -0.293633371591568, -0.1335257738828659, 0.08524768054485321, -0.7038968801498413, -0.9357773661613464, 0.0307026207447052, 0.291677862405777, -0.5709019899368286, 0.5868006348609924, -0.5079824328422546, 0.4216025471687317, 0.3143008053302765, 0.2979445457458496, 1.0540971755981445, 0.5281546115875244, 0.44204115867614746, -0.26775941252708435, 0.9738141298294067, -1.1442888975143433, -0.620532751083374, -0.8466137051582336, 1.0438908338546753, -0.12850457429885864, 0.7202305793762207, -0.08582159131765366, -0.9259611368179321, -0.6934493780136108, -0.7782721519470215, -0.155744269490242, -0.48238253593444824, 0.20668670535087585, 1.076419711112976, 0.7842957973480225, -0.21191532909870148, 0.8598591089248657, 0.2906564474105835, -0.4267231225967407, 0.38025781512260437, -0.31217023730278015, 0.09787337481975555, -0.7195923924446106, -1.607641339302063, 0.5614975094795227, 0.19104933738708496, -1.1342759132385254, -0.24298003315925598, -0.8873201012611389, -0.902277946472168, -0.33459916710853577, 0.9582930207252502, -0.14795775711536407, 1.4939911365509033, -0.06150452420115471, -1.4665014743804932, 1.1502076387405396, -0.17605037987232208, -0.0044970326125621796, 0.6120008826255798, 0.20594976842403412, -0.5630238652229309, -0.5661100745201111, -0.14711067080497742, 0.5395355224609375, 0.3231199085712433, 0.09314314275979996, 0.09029148519039154, 0.36673152446746826, 0.19481860101222992, -0.28865042328834534, -0.24348671734333038, 0.8022127747535706, -0.7720460891723633, -0.17818588018417358, 0.1733320951461792, 0.8769844174385071, 0.11140873283147812, -0.21918216347694397, 0.03965986147522926, -1.4793734550476074, 0.8336926102638245, 0.5095235705375671, 0.8863363862037659, -0.8614534139633179, -1.0607948303222656, -0.6006886959075928, -0.558215320110321, 0.18025848269462585, -0.8115208148956299, 0.6971548795700073, -0.08953534811735153, 0.2846457064151764, 0.013949830085039139, -1.1989418268203735, 0.1735132932662964, 0.06902332603931427, -0.7073187232017517, -0.2599984407424927, -0.09144537150859833, 1.2256033420562744, -1.0226171016693115, 0.20211246609687805, 0.09307762235403061, -0.0033837328664958477, -1.1129399538040161, 0.7258577346801758, -0.5020005702972412, 0.061726294457912445, 0.14785075187683105, -0.1708720177412033, -0.12381589412689209, -0.051551107317209244, 0.038237836211919785, -0.2626568377017975, -0.030496012419462204, 0.5821138620376587, -0.5603182911872864, 1.715009331703186, -0.49606671929359436, 0.36123138666152954, -0.07546449452638626, -0.6251038908958435, 0.1061372235417366, 0.8434457182884216, -0.4781736135482788, -0.22663722932338715, 0.21121257543563843, 0.23386026918888092, -0.9298331141471863, 0.189952090382576, 0.7153067588806152, 0.616704523563385, -0.5972554087638855, 0.3059060871601105, 1.1375691890716553, -0.47875410318374634, 0.5646083354949951, 0.11630785465240479, 0.5548020005226135, 0.33919641375541687, 0.5572755932807922, -0.20483896136283875, 0.4308897852897644, -0.6889193654060364, 0.11587207019329071, 0.6851195693016052, 0.18402554094791412, 0.9906383156776428, 0.4056316018104553, -1.0153371095657349, -0.10384067893028259, 0.014952994883060455, 0.6451641321182251, 2.100677967071533, -0.05711407959461212, -0.5690616965293884, -0.7433193922042847, -0.4392433166503906, -0.7316561341285706, 0.5734182000160217, -0.6146815419197083, -0.24544036388397217, -0.37775394320487976, -0.7453096508979797, 0.766288161277771, -0.2774851322174072, 1.0826232433319092, -0.8129624724388123, -0.4661029279232025, 0.0010007396340370178, 0.31156837940216064, -0.624638557434082, -0.5656571984291077, 0.43619614839553833, -0.19122998416423798, -0.27336183190345764, 0.0045861778780817986, -0.3573465645313263, -0.32837504148483276, -0.33838069438934326, 1.0716445446014404, -0.5257394313812256, -0.5736076235771179, 0.39888906478881836, 0.5539833903312683, -0.735450029373169, -0.6001145243644714, 0.39406633377075195, -0.16805367171764374, -0.4105222523212433, 0.8336707949638367, 0.5708418488502502, 0.5737656354904175, 0.43652698397636414, -0.2207518368959427, 0.00021059883874841034, -0.35915541648864746, 0.1934845894575119, 0.670860767364502, -0.30041244626045227, 0.3013322651386261, -1.4229905605316162, 0.9821516275405884, 0.31299662590026855, -0.48185911774635315, 0.34474337100982666, -0.4251995086669922, -0.7775526642799377, 0.31531041860580444, -0.8733794689178467, -0.48091909289360046, -0.9058138728141785, 0.42150750756263733, -0.46698299050331116, -0.47234222292900085, -0.12874968349933624, 0.1755923479795456, 0.014800218865275383, 0.8187466859817505, 0.2534213662147522, 0.26876574754714966, 0.07488467544317245, 0.822895348072052, -0.8846477270126343, 0.4397890269756317, 0.0462278388440609, -0.12209950387477875, -0.14780905842781067, -0.007891703397035599, -0.6736094355583191, -0.5846958160400391, -0.5683248043060303, -0.32871001958847046, -0.20109836757183075, 0.09950445592403412, -0.5315731167793274, -0.5772327184677124, 0.1894935667514801, -0.8786348104476929, -0.5387185215950012, -0.31016165018081665, -0.7156226634979248, -0.6483237147331238, -0.9497829079627991, -0.8965196013450623, -0.411081999540329, -0.7542886734008789, -0.9608697891235352, 0.23103925585746765, -0.02615472488105297, -0.5725519061088562, -0.40090617537498474, 0.15578827261924744, -0.3352125585079193, 0.8058467507362366, -0.6240150928497314, 0.5004395246505737, -0.40584003925323486, -0.11095912754535675, -0.33715954422950745, 0.4650082290172577, 0.4045845866203308, 0.042782992124557495, -0.11795278638601303, -0.9335796236991882, 0.45972469449043274, 0.08946536481380463, -0.7513340711593628, 0.31301015615463257, 0.023837178945541382, 0.7235683798789978, 0.14041709899902344, -0.32482799887657166, 0.19669483602046967, 1.2116243839263916, -0.5089189410209656, 0.3018267750740051, 0.15825548768043518, 0.6287654638290405, 0.6816114187240601, 0.11845926940441132, 0.2664872705936432, 0.13961642980575562, 0.40767523646354675, -0.15186086297035217, 0.693779468536377, -0.09235083311796188, -0.17511065304279327, 0.2798842787742615, 0.8783426284790039, 0.17951320111751556, 0.41812917590141296, -1.1759846210479736, 0.8808702230453491, -1.429131031036377, -0.9822649359703064, 0.826354444026947, 0.6037969589233398, 0.6531766653060913, -0.2836749851703644, -0.4725731611251831, -0.05302268639206886, 0.4432283341884613, 0.24495045840740204, -0.09362344443798065, -0.6745800971984863, 0.1947622299194336, 0.6284230947494507, -0.11624464392662048, 0.6431339979171753, -0.5692279934883118, 0.9210534691810608, 14.6982421875, 1.479170799255371, 0.16051185131072998, 0.7074205279350281, 0.6386462450027466, 0.10483305156230927, -0.12474799156188965, -0.23134984076023102, -1.2873198986053467, -0.5553940534591675, 0.7730227708816528, 0.11439597606658936, 0.8282986283302307, 0.452720046043396, -0.1585203856229782, 0.06534522026777267, -0.5828900933265686, 0.5223634839057922, 0.4871738851070404, -1.4696667194366455, 0.3503873348236084, -0.14074335992336273, 0.48859354853630066, 0.4717905819416046, 0.6279541850090027, 1.2882782220840454, 0.18702097237110138, -0.1755104959011078, 0.05226188525557518, 0.3223172128200531, 0.835348904132843, -0.5512155294418335, 0.4234873950481415, 0.8229990005493164, -0.436481237411499, -0.3617236912250519, -0.9638037085533142, -1.298877477645874, 0.03069346956908703, -0.09239000827074051, -0.49748748540878296, -0.6052499413490295, -0.3297836184501648, 0.536185085773468, 0.4128478169441223, 0.113795205950737, -0.23107610642910004, 0.2802368700504303, 0.4856318533420563, 0.04856907203793526, 0.6008263826370239, 0.10616283863782883, 0.32387223839759827, 0.2542116045951843, -0.10065388679504395, 0.4621884524822235, 0.1584106981754303, 0.5459262728691101, -0.49363625049591064, 0.1631840318441391, -0.541027843952179, -0.052751049399375916, -0.39882946014404297, 1.0490727424621582, 0.8864952921867371, 0.14884716272354126, -0.4210449159145355, -0.06730525940656662, 0.44307470321655273, -0.09818720817565918, 0.02521040476858616, -0.4988067150115967, 0.42197030782699585, -0.45986685156822205, -0.15165382623672485, 0.7087844014167786, -0.3762983977794647, -0.6126338839530945, -1.1359158754348755, -0.1871161311864853, 0.2754412591457367, -0.7684556841850281, -0.9850532412528992, 0.3965062201023102, -0.18873658776283264, -0.30433815717697144, -0.011795183643698692, -0.6088898777961731, -1.0115230083465576, 0.41693738102912903, -1.1280869245529175, -0.9629175662994385, -0.025058554485440254, -0.3005041480064392, 0.12409976124763489, -0.36033523082733154, 1.5662428140640259, -0.11103781312704086, -0.26130619645118713, 0.1081768348813057, -0.02002631686627865, -0.12753577530384064, 0.1316356509923935, -0.5999165177345276, 0.8951156735420227, 0.006556401029229164, -0.35305315256118774, -0.05826247110962868, 0.06874999403953552, 0.6351808905601501, -0.3221684992313385, -0.5461500287055969, 0.9304258823394775, -0.793562650680542, -0.5173176527023315, -0.8691582083702087, -1.2114492654800415, 0.23143517971038818, 0.7713519334793091, -0.017391888424754143, 0.4360697567462921, 0.025944264605641365, -0.6625968813896179, -0.02952759899199009, -1.1495689153671265, 0.38917794823646545, 0.5206485390663147, -0.8677819967269897, -0.9033470749855042, 0.10519105195999146, 0.6056466102600098, -0.7022765874862671, -0.5501759648323059, -0.40702012181282043, 0.09910725057125092, -0.10180363059043884, 1.042739987373352, -0.2830560803413391, 0.5930998921394348, 1.130236268043518, -0.21815349161624908, -0.8883542418479919, -0.1244887039065361, -0.991908848285675, 0.4975064992904663, 0.49326685070991516, 0.513411819934845, -0.5541062951087952, 0.34931430220603943, 0.9481930136680603, 0.44387805461883545, -0.4667913317680359, -0.6550069451332092, -0.5307514667510986, 0.5883368253707886, -0.7484768033027649, 0.5036997199058533, 0.24669525027275085, 0.3601948618888855, 0.2761182487010956, 0.414756715297699, -0.0008426335407420993, 0.04369204863905907, -0.8385375738143921, 0.6046393513679504, -0.17526698112487793, -0.12186246365308762, -0.696575939655304, -0.1316368132829666, -0.7587147355079651, 0.179584801197052, -1.2020219564437866, 0.032342519611120224, -0.5718934535980225, -0.5617745518684387, 0.3183833658695221, -0.13843224942684174, 0.31967562437057495, 0.451086163520813, -0.19277910888195038, -0.3761734366416931, -0.6518304944038391, -0.6197412610054016, 0.25209543108940125, 0.9561424255371094, -0.9440755844116211, -0.21759043633937836, 0.0812663659453392, 0.1370256543159485, 0.6075388193130493, 0.8087584376335144, -0.24314482510089874, -0.838156521320343, -0.7909755110740662, -0.05134515091776848, -0.2129131406545639, -0.20780733227729797, -0.7157776355743408, 0.7004943490028381, 0.21552683413028717, -0.4437875747680664, -0.016270801424980164, 0.32887065410614014, -0.749226987361908, -0.5002607107162476, 0.1325569450855255, -0.6768501996994019, -0.6563454270362854, 0.0748191699385643, -0.6708745360374451, -0.13674132525920868, -0.08348681032657623, 0.3951483964920044, -1.397135853767395, -1.0134296417236328, 0.415485143661499, -0.6677692532539368, 0.24254965782165527, -0.011187922209501266, -0.03695518150925636, -0.9367928504943848, -0.14417144656181335, -0.27724313735961914, 0.3208875060081482, -0.38847386837005615, 0.9812470078468323, -0.008081015199422836, -1.428375482559204, 0.3728647828102112, 0.3054650127887726, 0.6499562859535217, -0.23555035889148712, 0.42128098011016846, 0.24937503039836884, 0.0686245709657669, 0.3761913776397705, 0.009123159572482109, 0.3153359591960907, -0.8036837577819824, 0.16788700222969055, 0.5880314111709595, -0.6285478472709656, -0.22815924882888794, 0.8189879059791565, -0.26718395948410034, -1.3593807220458984, 0.5735948085784912, -1.1965008974075317, -0.7206416130065918, 0.013939707539975643, 1.0440081357955933, 0.49585607647895813, 0.074414923787117, 0.07053636759519577, -0.12717053294181824, 0.2474828064441681, -0.036258939653635025, -0.5141746401786804, 0.7054954767227173, -0.10247138887643814, -0.39366036653518677, 1.0195950269699097, 0.7785274982452393, -1.052716612815857, -0.8033239841461182, -0.9031424522399902, -0.37398990988731384, -0.15945234894752502, 0.03612399473786354, -0.6608027815818787, -0.10859301686286926, 0.9650598168373108, 0.23835669457912445, 0.28932902216911316, -0.06013866513967514, -0.41394853591918945, 0.007569553330540657, 1.171454668045044, 0.45245790481567383, -0.9502593874931335, -0.3910387456417084, 1.6505935192108154, 1.256448745727539, -1.1265935897827148, -0.057553473860025406, -0.42683741450309753, -0.6971297860145569, 1.003713846206665, 0.3892682194709778, -0.24037115275859833, 0.936927080154419, -0.6975221037864685, 0.20779462158679962, 0.3260860741138458, -1.3625181913375854, -0.1766381412744522, 0.7422970533370972, 1.1278811693191528, 0.47019603848457336, 0.31782782077789307, 0.0010622348636388779, 1.219716191291809, 0.3414197564125061, 0.34307754039764404, 0.8415733575820923, 0.25595977902412415, -0.5642580986022949, -0.07922821491956711, 0.2545156478881836, 0.42450183629989624, -0.7439117431640625, -0.27568259835243225, 0.05035218223929405, 0.7342228889465332, 0.5014092922210693, 0.5634092092514038, 0.5236021280288696, 0.20963208377361298, 0.6655164957046509, 0.7988028526306152, 0.5848109722137451, -0.7605237364768982, -0.5591258406639099, -0.43473026156425476, -0.691558837890625, -0.10992303490638733, -0.06220155581831932, -0.43619832396507263, 0.06571180373430252, 0.0033976840786635876, 0.27375075221061707, -0.27891433238983154, 0.05434884503483772, 1.4344700574874878, 0.34572502970695496, 0.01582185924053192, -0.8018218874931335, -0.7045294046401978, -0.5637931227684021, -0.8954070210456848, 0.02520296350121498, -0.6069005727767944, -0.532564640045166, -0.23743706941604614, -0.22197307646274567, -0.49063682556152344]}, "authors": [{"authorId": "2149558640", "name": "Tsimur Hadeliya"}, {"authorId": "102712558", "name": "D. Kajtoch"}], "references": [{"paperId": "1cff5549753a518ed9d6a3517b5050968d710b27", "title": "LLaMA Beyond English: An Empirical Study on Language Capability Transfer"}, {"paperId": "cf1fd110df9fec1d820032a5264514d88a56b06b", "title": "LLaMAntino: LLaMA 2 Models for Effective Text Generation in Italian Language"}, {"paperId": "7fe071ea76e49bc3e573beb53f07721630954247", "title": "Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution"}, {"paperId": "cd7c9fbb2acab241b0b4c7837877a19335c7284c", "title": "Monolingual or Multilingual Instruction Tuning: Which Makes a Better Alpaca"}, {"paperId": "8d17234680db76f99efd22fbcb169f45d2d79d93", "title": "Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers"}, {"paperId": "fe6670cfc0d0dfe184afc8e003df51333d3a750e", "title": "The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants"}, {"paperId": "9fec5cf2f06e6fd8c5e6f6028226082d1ecec5b7", "title": "Extrapolating Large Language Models to Non-English by Aligning Languages"}, {"paperId": "1b28cfd31c05451a39894ec2c380c54e370b9cce", "title": "Do Multilingual Language Models Think Better in English?"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "0d1c76d45afa012ded7ab741194baf142117c495", "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"}, {"paperId": "7eb044170c11b7e2193b8df35f606edcfc7f2585", "title": "Don't Trust ChatGPT when your Question is not in English: A Study of Multilingual Abilities and Types of LLMs"}, {"paperId": "2f1555f7f601c3826165fa5f9db1dd5c717d1c60", "title": "Automated Few-shot Classification with Instruction-Finetuned Language Models"}, {"paperId": "c76dd4a70361c3afd2e19d046343e2dedd16ecc3", "title": "Automatic Prompt Optimization with \"Gradient Descent\" and Beam Search"}, {"paperId": "dfbfa21a93c3164ae8a033398c8de42b03b1b84d", "title": "ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning"}, {"paperId": "62ad7ea9467bbcdbfe325b9ee561cab3908e4583", "title": "MEGA: Multilingual Evaluation of Generative AI"}, {"paperId": "6e0e04c29b8f151ae8aeca853710db9ee6401ffa", "title": "Improving Few-Shot Generalization by Exploring and Exploiting Auxiliary Data"}, {"paperId": "4f0bfeadd39e64456d15d400fda8ecc2197c3265", "title": "Direct Preference-based Policy Optimization without Reward Modeling"}, {"paperId": "e7dfa8ef33f961315837dcd808856a45fc9e97c1", "title": "This is the way: designing and compiling LEPISZCZE, a comprehensive NLP benchmark for Polish"}, {"paperId": "4610ffb1b016acaa82a2065ffd1a3adbae1ce722", "title": "Large Language Models Are Human-Level Prompt Engineers"}, {"paperId": "07759a84f27e43cfa5bc8d579f8227c96e6ae1dc", "title": "RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning"}, {"paperId": "7cdaa08890895e1ad92afb5fad429690ad7b1dac", "title": "Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning"}, {"paperId": "06d7cb8c8816360feb33c3367073e0ef66d7d0b0", "title": "Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks"}, {"paperId": "6197d4e544ec34e6f2e873830ec066895bf1a830", "title": "Prompt-free and Efficient Few-shot Learning with Language Models"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "9b1f4492a663c7f56f2b43ae1ed167d3857aacca", "title": "PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "e1227daa4877599e13de41a5207a222e1b197456", "title": "RAFT: A Real-World Few-Shot Text Classification Benchmark"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "2ee03e28208a9310a9be4032c2b04ebdddb83cc7", "title": "FLEX: Unifying Evaluation for Few-Shot NLP"}, {"paperId": "ead441f3e9db042ffdeaf469f70bbe4b127d9060", "title": "Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with Language Models"}, {"paperId": "b58d8579ece27a60432e667bfbdb750590fa65d9", "title": "True Few-Shot Learning with Language Models"}, {"paperId": "cbdb45fc16b0885905b91d84281c310e6cb49e9c", "title": "Cross-Task Generalization via Natural Language Crowdsourcing Instructions"}, {"paperId": "7fa273f450251523e6b7fcc2eb3fdbdfd4a30493", "title": "CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in NLP"}, {"paperId": "f30444fbb6ad806168e2564db4815cd27faa7fd9", "title": "It\u2019s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "f527bcef68aeda601aae314fe5c75185c716e579", "title": "KLEJ: Comprehensive Benchmark for Polish Language Understanding"}, {"paperId": "d97e7561fa7710213ccd4f8128044ea6849be377", "title": "XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning"}, {"paperId": "085b360d3c08aaf997f45a78e27f2629f5625205", "title": "Translation Artifacts in Cross-lingual Transfer Learning"}, {"paperId": "8ae9a17c87a4518b513e860683a0ef7824be994d", "title": "Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference"}, {"paperId": "79cfb51a51fc093f66aac8e858afe2e14d4a1f20", "title": "Focal Loss for Dense Object Detection"}, {"paperId": "5bbb6f9a8204eb13070b6f033e61c84ef8ee68dd", "title": "Deep Reinforcement Learning from Human Preferences"}, {"paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586", "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"}, {"paperId": "26bc9195c6343e4d7f434dd65b4ad67efe2be27a", "title": "XGBoost: A Scalable Tree Boosting System"}, {"paperId": "29c7f009df21d0112c48dec254ff80cc45fac3af", "title": "Are Emergent Abilities of Large Language Models a Mirage?"}, {"paperId": "27b2bff2dce12c0edc1ff56109335f494424a87d", "title": "Multi-Domain Multilingual Question Answering"}, {"paperId": null, "title": "Improving and"}, {"paperId": null, "title": "AutoPrompt: Elic-iting Knowledge from Language Models with Auto-matically Generated Prompts"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "spaCy 2: Natural language understanding with Bloom embed-dings, convolutional neural networks and incremental parsing"}, {"paperId": null, "title": "2023. Bu ff et: Benchmarking large language models for few-shot cross-lingual transfer"}, {"paperId": null, "title": "f1cc2961-3a7b-4cc6-887e-c661089dd994 : instruction :"}, {"paperId": null, "title": "2022 Switch transformers: Scaling to trillion parameter models with simple and e ffi cient sparsity"}, {"paperId": null, "title": "3ad789e3-6a21-4db9-8fba-c051c37cf449 : instruction :"}, {"paperId": null, "title": "2022. FewNLU: Benchmarking state-of-the-art methods for few-shot natural language understanding"}, {"paperId": null, "title": "simplifying pattern exploiting training"}, {"paperId": null, "title": "2022. Lamda:"}, {"paperId": null, "title": "2023. Crosslingual generalization through multitask finetuning"}, {"paperId": null, "title": "0d817d40-b514-4a40-b76a-dbdd5902bc3e : instruction :"}, {"paperId": null, "title": "2024. Persianmind: A cross-lingual persian-english large language model"}, {"paperId": null, "title": "62f33ae1-a7bf-4ab3-9192-afe3b5bc8e20 : instruction : 'Czy zdanie jest obra\u017aliwe?"}, {"paperId": null, "title": "2022. Multi-task prompted training enables zero-shot task generalization"}, {"paperId": null, "title": "871270fa-33aa-4677-b6ce-1869632a694c"}, {"paperId": null, "title": "ceb5e55e-cb6f-47ab-b4f0-059192837c26 : instruction :"}, {"paperId": null, "title": "2023. GrIPS: Gradient-free, edit-based instruction search for prompting large language models"}, {"paperId": null, "title": "2023. Ul2: Unifying language learning paradigms"}, {"paperId": null, "title": "2023. E ffi - cient memory management for large language model serving with pagedattention"}]}