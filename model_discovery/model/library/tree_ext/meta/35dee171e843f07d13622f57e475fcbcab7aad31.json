{"paperId": "35dee171e843f07d13622f57e475fcbcab7aad31", "title": "Multi-Document Summarization Using Selective Attention Span and Reinforcement Learning", "abstract": "Abstractive text summarization systems using recently improved RNN-based sequence-to-sequence architecture have shown great promise for single-document summarization. However, such neural models fail to perpetuate the performance in the multi-document summarization setting owing to the long-range dependencies within the documents, overlapping/contradicting facts and extrinsic model hallucinations. These shortcomings augment the model to generate inconsistent, repetitive and non-factual summaries. In this work, we introduce <monospace>REISA</monospace>, a sequence-to-sequence model with a novel <italic>reinforced selective attention span</italic> that attends over the input and recalibrates the local attention weights to focus on important segments while generating output at each time step. <monospace>REISA</monospace> utilizes a reinforcement learning-based policy gradient algorithm to reward the model and formulate attention distributions over the encoder input. We further benchmark <monospace>REISA</monospace> on two widely-used multi-document summarization corpora \u2013 Multinews and CQASumm, and observe an improvement of <inline-formula><tex-math notation=\"LaTeX\">$+2.91$</tex-math></inline-formula> and <inline-formula><tex-math notation=\"LaTeX\">$+6.64$</tex-math></inline-formula> ROUGE-L scores, respectively. The qualitative analyses on semantic similarity by BERTScore, faithfulness by question-answer evaluation and human evaluation show significant improvement over the baseline-generated summaries.", "venue": "IEEE/ACM Transactions on Audio Speech and Language Processing", "year": 2023, "citationCount": 2, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces <monospace>REISA</monospace>, a sequence-to-sequence model with a novel Reinforced selective attention span that attends over the input and recalibrates the local attention weights to focus on important segments while generating output at each time step."}, "embedding": {"model": "specter_v2", "vector": [0.028127282857894897, 0.25814515352249146, -0.4353034794330597, -0.23462146520614624, -0.6019226908683777, -0.4273056089878082, 0.463680624961853, 0.1807665377855301, -0.35832923650741577, 0.6275181770324707, 1.034897804260254, 0.3975719213485718, -0.28498774766921997, 0.2345832735300064, 0.15124201774597168, 0.16891364753246307, -0.6489792466163635, 0.02020386792719364, -0.33998337388038635, -0.3722940683364868, 0.4731939435005188, -0.9357184767723083, -0.6253402829170227, 0.2837054133415222, 0.8264696002006531, -0.09919941425323486, 0.042755529284477234, 1.548936367034912, -0.18882320821285248, 0.5908767580986023, -0.01672763004899025, -0.18513090908527374, -0.31925955414772034, -0.6415449976921082, -0.707850992679596, -0.0778937116265297, 0.5453904271125793, -0.5449600219726562, -0.42760246992111206, 0.5086441040039062, -0.0019216836662963033, 0.312396764755249, 0.6484752893447876, 0.08850035816431046, -0.11362186074256897, 0.8256234526634216, 0.4876948297023773, 0.9380444288253784, 0.6003201603889465, -0.5774497389793396, 1.5967785120010376, -0.9644144773483276, 0.1523527055978775, 1.4902411699295044, 0.2190752476453781, 0.5632896423339844, -0.15129923820495605, -0.017849307507276535, 0.8496477007865906, 0.4129893481731415, -0.4819922149181366, -0.02503221482038498, -0.11662202328443527, 0.024043578654527664, 1.6322726011276245, 0.03945479169487953, -0.2607046961784363, 0.30773741006851196, -0.007361466996371746, 1.76633882522583, -0.6121394634246826, -0.5023059844970703, -0.28845083713531494, -0.33049944043159485, 0.8138401508331299, 0.3747822940349579, -0.1639767438173294, -0.09981474280357361, -0.8901100754737854, 0.04749768227338791, 0.11426350474357605, 0.18879525363445282, -0.4315628111362457, 0.2765284478664398, -0.42780378460884094, 0.5545821189880371, 0.21959231793880463, 0.7621684074401855, -0.835865318775177, 0.6302242875099182, 0.51470547914505, 0.4264707565307617, -0.020652450621128082, 0.7957404851913452, 0.176566943526268, 0.136820450425148, -1.0788109302520752, 0.6047787070274353, -0.09073127061128616, 0.5240598320960999, -0.037034958600997925, 0.48206958174705505, -1.0772114992141724, 0.27032849192619324, 0.8660491108894348, 0.03401906415820122, 0.4435422420501709, -0.8796312808990479, 0.1380130499601364, -0.4877879321575165, 0.7173425555229187, -0.9406994581222534, -0.48051193356513977, -0.3659849464893341, -0.6738678812980652, -1.0891199111938477, -0.7470489740371704, 0.029803622514009476, -0.2283805012702942, 0.564177930355072, -0.39322590827941895, -0.17121334373950958, 0.25679314136505127, 0.584382951259613, 0.8718151450157166, 0.6688303351402283, 0.13315841555595398, -0.3769163191318512, 0.644917368888855, -0.8562368750572205, -1.0230451822280884, -0.7896112203598022, 0.5187621712684631, -0.13117671012878418, -0.3175792694091797, -0.0568186491727829, -1.629023551940918, -1.0347567796707153, -1.0762377977371216, 0.4646715521812439, 0.053657304495573044, 0.13807354867458344, 0.4003753364086151, -0.15338878333568573, -0.8766958713531494, 1.2113653421401978, -0.06475279480218887, -0.5640754103660583, 0.08403907716274261, -0.1869034469127655, 0.3657650351524353, -0.6142717599868774, -1.007737398147583, 0.4264586567878723, 0.29046157002449036, -0.7022427916526794, -0.1402747929096222, -0.40092429518699646, -1.0423991680145264, -0.03643133118748665, 0.43690025806427, -1.0686200857162476, 1.402766227722168, 0.14796465635299683, -1.0548433065414429, -0.16326148808002472, -0.39188751578330994, 0.013928369618952274, 0.4404012858867645, -0.8278020024299622, -0.4818757474422455, 0.4159959852695465, -0.08111293613910675, 0.26283201575279236, 0.030514264479279518, -0.2543918788433075, -0.44511374831199646, 0.20432327687740326, -0.1843186616897583, 0.03583749756217003, -0.3058766722679138, 0.9042701721191406, -0.11390049010515213, -0.29582664370536804, 0.12488666921854019, 1.2823058366775513, 0.017398297786712646, -0.8685272932052612, -0.6841133832931519, -1.123140573501587, 0.4588550925254822, -0.16974636912345886, 1.5100066661834717, -0.4549988806247711, -0.4728839695453644, -0.6085811257362366, -0.06452438980340958, 0.38909944891929626, -0.9319483041763306, 0.8619087934494019, -0.1649520844221115, 0.3818821907043457, -0.39145442843437195, -1.0534073114395142, -0.10314499586820602, -0.1942102611064911, -0.44116905331611633, -0.35183531045913696, 0.3594420850276947, 1.2738500833511353, -1.2015305757522583, -0.048496074974536896, -0.030799372121691704, -0.1510600447654724, -0.7516399621963501, 1.2066391706466675, -0.7860758304595947, 0.3010312616825104, -0.4133874773979187, -0.306087464094162, 0.16253183782100677, -0.29536399245262146, 0.08084587007761002, -0.22271516919136047, -0.2030399739742279, 0.4185775816440582, -0.7569279074668884, 1.360463261604309, 0.4297514259815216, 0.2748211622238159, -0.3820083737373352, -0.7047525644302368, 0.20298872888088226, 0.4797186851501465, 0.06002577766776085, -0.35864025354385376, -0.0013595180353149772, 0.01397952064871788, -1.148898959159851, -0.447531521320343, 1.106071949005127, 1.1111387014389038, -0.57393878698349, 0.6613638401031494, 0.5951343178749084, -0.028187328949570656, 1.2991944551467896, 0.8815594911575317, 0.9801084995269775, 0.4275989830493927, 0.6869000792503357, 0.014641374349594116, 0.6055189967155457, -0.3824128806591034, 0.12631146609783173, 0.7594194412231445, 0.734279990196228, 1.1961462497711182, 0.30943700671195984, -0.7527117133140564, -0.3140808343887329, 0.0378686785697937, 1.2714004516601562, 0.9627552628517151, 0.09112661331892014, -0.36006397008895874, -0.6859686970710754, -0.6930084228515625, -0.44478660821914673, 0.5613133311271667, -0.38573354482650757, -0.22544975578784943, -0.7735955715179443, -0.9529697299003601, 0.7673117518424988, 0.4389035701751709, 1.1031274795532227, -0.7623315453529358, -0.3445534110069275, 0.07916922122240067, -0.2592712938785553, -0.4095553159713745, -0.806785523891449, 0.006023557391017675, -0.4579434096813202, -0.6359112858772278, -0.09837287664413452, 0.2141856849193573, -0.18273699283599854, -0.12436679005622864, 1.3721890449523926, -0.3127540647983551, 0.0017367304535582662, 0.47531071305274963, 0.3115798830986023, -0.6557367444038391, -0.5162497162818909, -0.10714465379714966, 0.006092604715377092, -0.31357383728027344, 0.24332144856452942, 0.5029130578041077, -0.35009291768074036, 0.28305965662002563, -0.838375449180603, -0.14021241664886475, -0.03927059471607208, 0.18761178851127625, 0.14754359424114227, -0.2235112190246582, 0.7778443098068237, -0.9318297505378723, 1.2120367288589478, 0.09461024403572083, 0.19954831898212433, 0.3704493045806885, -0.4264201521873474, -0.33290669322013855, 0.36643943190574646, -0.2626982033252716, -0.4687268137931824, -1.4720609188079834, 0.7108580470085144, 0.16402475535869598, -0.39278098940849304, 0.5415430068969727, 0.38355740904808044, 0.859139084815979, 0.421721875667572, 0.5427508354187012, 0.5225277543067932, -0.08220194280147552, 0.4183928370475769, -0.5938537120819092, 0.9259800314903259, 0.7772080898284912, -0.14398112893104553, -0.31234079599380493, -0.2769455015659332, -0.7151810526847839, -0.6683440208435059, -0.6805111169815063, 0.04688127711415291, -0.4630047082901001, 0.24712535738945007, -0.380613774061203, -0.9221718311309814, -0.13065338134765625, -1.5284082889556885, 0.2835293114185333, -0.056211963295936584, 0.010447501204907894, -0.25706520676612854, -0.5700331330299377, -0.952446460723877, -0.5771970748901367, -0.7894523739814758, -0.297771155834198, 0.026720695197582245, 0.46181267499923706, -1.2026511430740356, -0.5183335542678833, 0.617213249206543, -0.5683631896972656, 0.669839084148407, -0.1480933129787445, 0.5302521586418152, -0.029288850724697113, 0.042048439383506775, -0.3093412518501282, 0.4124593138694763, 0.5873012542724609, 0.06937000900506973, 0.10913421958684921, -0.19737301766872406, -0.022529300302267075, 0.05077884718775749, -0.3161972761154175, 0.44834718108177185, 0.5594918131828308, 0.2994629144668579, -0.09114155173301697, -0.3293098211288452, -0.4014280438423157, 1.448832631111145, -0.6884422302246094, -0.02346494048833847, -0.15731245279312134, 0.8470798134803772, 0.6992340087890625, 0.25981268286705017, 0.7986707091331482, 0.27747029066085815, 0.20401526987552643, 0.2227364331483841, -0.30951592326164246, -0.2667571008205414, -0.2095664143562317, 0.5356637835502625, 1.5889521837234497, 0.27539968490600586, -0.664685845375061, -0.6128238439559937, 0.7513172626495361, -1.749154806137085, -1.128616452217102, 0.3240868151187897, 0.4739299714565277, -0.01424633152782917, -0.8351141214370728, 0.03779352828860283, 0.2042675018310547, 0.6502942442893982, 0.3211512565612793, -0.42903515696525574, -0.47199952602386475, -0.08053034543991089, -0.11528859287500381, -0.26081615686416626, 0.8249261379241943, -0.19299595057964325, 0.12115392833948135, 14.64322566986084, 0.5305517911911011, 0.42312198877334595, -0.23513780534267426, 0.41480782628059387, -0.2795400023460388, -0.432635635137558, -0.2855958938598633, -0.8690821528434753, -0.2360725998878479, 1.1213501691818237, -0.2788555324077606, 0.1377418339252472, -0.2900364398956299, 0.6450278759002686, -0.1387193500995636, -0.6839002370834351, 0.6012046933174133, 0.7453904747962952, -1.464589238166809, 0.6620961427688599, -0.02313469536602497, 0.4684249758720398, 0.26800867915153503, 0.34843122959136963, 0.7039219737052917, 0.5673467516899109, -0.1969432830810547, 0.30549827218055725, 0.819021999835968, 0.5985368490219116, -0.42810600996017456, 0.6179237961769104, 0.5587449073791504, -0.49978822469711304, -0.5004676580429077, -0.5616521835327148, -1.0382095575332642, 0.5733493566513062, -0.10539668798446655, -0.5485489964485168, 0.655121922492981, -0.30360764265060425, 1.015424370765686, 0.0745721086859703, 0.6527953743934631, -0.3735612630844116, 0.5483958721160889, 0.3780183494091034, -0.48651811480522156, 0.3294428586959839, 0.42976781725883484, 0.7086692452430725, 0.2612936794757843, 0.08167091012001038, 0.34813618659973145, -0.0713304728269577, 0.3076200485229492, -0.39438897371292114, -0.16907601058483124, -0.33728185296058655, -0.007845557294785976, 0.12584926187992096, 0.6372395753860474, 0.8873371481895447, -0.03550605848431587, -0.21104255318641663, 0.20780885219573975, 0.5561803579330444, 0.2483314424753189, -0.027386581525206566, -0.5547776818275452, 0.12510548532009125, -0.39784660935401917, 0.13216160237789154, 0.6059686541557312, -0.5222747921943665, -0.33294737339019775, -0.803139328956604, -0.3798956573009491, 0.5130473971366882, -1.0434542894363403, -0.5596295595169067, 1.0792508125305176, -0.12821586430072784, -0.7952952980995178, -0.41989046335220337, -0.20421507954597473, -0.7558310627937317, 0.18380513787269592, -1.2594709396362305, -0.1319548338651657, 0.12626248598098755, -0.5953671336174011, -0.2763325273990631, -0.14838334918022156, 1.3266620635986328, -0.25221753120422363, -0.4959582984447479, -0.2731921672821045, 0.31370747089385986, -0.47659412026405334, 0.18360388278961182, -1.1165233850479126, 0.2971101701259613, 0.41795989871025085, -0.37579092383384705, 0.23107007145881653, 0.4230726659297943, 0.0557866133749485, -0.45174726843833923, -0.34644025564193726, 0.7497173547744751, -0.7803089022636414, -0.7867224216461182, -0.06545978039503098, -1.0204733610153198, -0.17829596996307373, 1.0517855882644653, -0.6287927627563477, 0.3217940330505371, -0.16192150115966797, 0.25509408116340637, -0.09231453388929367, -1.0136730670928955, 0.1180797889828682, 0.09334935992956161, -0.15993764996528625, -0.7060107588768005, -0.2422417551279068, 0.46533337235450745, -0.35089442133903503, -0.1894368827342987, -0.33085381984710693, -0.2858472168445587, -0.08806899935007095, 0.768521785736084, -0.6470299363136292, 1.0771031379699707, 0.5181338787078857, 0.03198939561843872, -1.033058524131775, -0.33946362137794495, -1.0778536796569824, 0.06471066921949387, 0.6018362641334534, 0.3876050114631653, -0.10846665501594543, 0.2564610540866852, 0.6364755034446716, 0.1259920448064804, -0.44527193903923035, -0.344207763671875, -0.0367857851088047, 0.1295645385980606, -0.0014352597063407302, 0.310412734746933, -0.4164441227912903, 0.22314567863941193, 0.4030638039112091, 0.32628700137138367, 0.534464955329895, -0.17880861461162567, -0.5555904507637024, 0.6479794383049011, -0.08333441615104675, 0.2819003164768219, -0.8041049838066101, -0.2783813774585724, -1.6552411317825317, -0.40625840425491333, -0.5995497703552246, 0.00011772029392886907, -1.665548324584961, -0.3771275281906128, 1.1260247230529785, -0.3171330988407135, -0.4030941128730774, -0.06526678800582886, -0.51602703332901, -0.3756711184978485, -0.5887625813484192, -1.4399445056915283, 1.0105139017105103, 1.122523546218872, -0.8657057881355286, -0.12136436998844147, -0.23955696821212769, -0.5919851064682007, 0.23361994326114655, 0.6802240014076233, -0.41755378246307373, -0.5797680616378784, -1.2633792161941528, 0.2169971466064453, 0.3770636320114136, 0.07238743454217911, -0.8047632575035095, 0.7810078263282776, 0.7249515652656555, 0.09147153794765472, -0.8844525218009949, -0.03583737462759018, -0.2693464457988739, -0.6740290522575378, 0.31751877069473267, -1.0303456783294678, 0.37250158190727234, 0.10652963072061539, -0.2675011157989502, -0.6928935050964355, 0.5609980225563049, -0.15291860699653625, -1.0785746574401855, -0.31524261832237244, 0.34049513936042786, -0.8270326256752014, 0.3017028272151947, -0.32171717286109924, -0.35418328642845154, -1.0479705333709717, -0.6612229347229004, 0.07194335013628006, 0.954889714717865, -0.5852167010307312, 0.8028738498687744, 0.6985903382301331, -1.2337416410446167, -0.7522053122520447, -0.1394241750240326, -0.14047667384147644, 0.050891175866127014, 0.9935151934623718, 0.1424422711133957, -0.02088327333331108, 0.6030315160751343, 0.41386422514915466, -0.016016237437725067, -0.7482004761695862, -0.11620134860277176, 0.6967453360557556, -0.7794074416160583, 0.14141349494457245, 0.7193076014518738, -0.5998350381851196, -0.812151312828064, 0.12964412569999695, -0.5704346895217896, -1.2181473970413208, -0.02181966044008732, 1.269700288772583, 1.0476504564285278, -0.31705743074417114, 0.05740944296121597, -0.38959985971450806, 0.27203696966171265, -0.49674633145332336, -0.4392969012260437, 0.8684784173965454, -0.6707086563110352, -0.2709465026855469, 0.5038708448410034, 0.4924803078174591, -0.8083201050758362, -0.6757543683052063, -0.7034837603569031, 0.013945333659648895, 0.08962071686983109, 0.02210187539458275, -0.7067321538925171, 0.022556953132152557, 0.41480302810668945, 0.18453514575958252, 0.6466451287269592, 0.16033773124217987, -0.40613096952438354, 0.08797908574342728, 0.46752896904945374, -0.5815348029136658, -0.6839191913604736, -0.14592322707176208, 1.258984088897705, 1.8703153133392334, -0.7912200093269348, 0.5405418872833252, 0.48008662462234497, -0.8252397775650024, 1.043048620223999, 0.27131417393684387, -0.3158700466156006, 0.2677326798439026, -0.7863600254058838, 0.26153403520584106, -0.00482273381203413, -1.082505702972412, 0.03449000045657158, 0.8021935224533081, 0.683325469493866, 0.5805884599685669, 0.10497009009122849, -0.3158058226108551, 0.9580656290054321, 0.4732080101966858, 0.2454632818698883, 0.8807341456413269, 0.28283578157424927, -0.28187671303749084, 0.10885011404752731, 0.00798097439110279, 0.3621259331703186, -0.6527517437934875, -0.013530866242945194, 0.040169380605220795, 0.370108962059021, -0.3053322732448578, 1.5001379251480103, 0.4350053071975708, 0.021232610568404198, 0.7510306239128113, -0.0902647152543068, 0.40251290798187256, -0.6562951803207397, -0.6093626618385315, -0.18820640444755554, -0.29538801312446594, -0.08902750164270401, -0.6515340209007263, -0.8877513408660889, -0.3409664034843445, -0.31583693623542786, 0.1907927542924881, 0.39083534479141235, -0.02139480598270893, 1.3066543340682983, 0.7357410788536072, 0.8177505731582642, -0.003229188732802868, -0.4814409613609314, -0.8892211318016052, -1.419454574584961, -0.06262201815843582, -0.1527988612651825, 0.3197251558303833, -0.05171891301870346, -0.11337240785360336, -0.49904394149780273]}, "authors": [{"authorId": "1986291522", "name": "Yash Kumar Atri"}, {"authorId": "1744939", "name": "Vikram Goyal"}, {"authorId": "144054829", "name": "Tanmoy Chakraborty"}], "references": [{"paperId": "e17042941940568d71483b81c44e4fff48a5095a", "title": "Fusing Multimodal Signals on Hyper-complex Space for Extreme Abstractive Text Summarization (TL;DR) of Scientific Contents"}, {"paperId": "3dfb1f50f2a34a699c339dabaa6f9b3a977973de", "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences"}, {"paperId": "e7216f9e67904157ff5265921956fee5eb32f103", "title": "Topic-Guided Abstractive Multi-Document Summarization"}, {"paperId": "45f7c0caf0f1f88a568279de52d7a8c29aa8e28f", "title": "Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization"}, {"paperId": "42e41ab2211b8ba78e36326ea21e05bd25d92c42", "title": "Efficiently Summarizing Text and Graph Encodings of Multi-Document Clusters"}, {"paperId": "a62209a3f90a5bb23054b0a126f5f5f23b9e4b53", "title": "BASS: Boosting Abstractive Summarization with Unified Semantic Graph"}, {"paperId": "f4566761fe39c4b5273d696d9bc3f4195c9325bb", "title": "Long-Span Summarization via Local Attention and Content Selection"}, {"paperId": "9dc624d7258d1a56117ca720aea953ce46b66b21", "title": "Efficient Attentions for Long Document Summarization"}, {"paperId": "b4eb84ca50148be183b6ef235613d6d4b5f2970b", "title": "Meta-Transfer Learning for Low-Resource Abstractive Summarization"}, {"paperId": "6ac8b209447c36d27b5b700d661202830d7c31e7", "title": "Attention Actor-Critic algorithm for Multi-Agent Constrained Co-operative Reinforcement Learning"}, {"paperId": "a0e7d24f91da6a1be5f8856963e3b160d47ca7b7", "title": "Towards Zero Shot Conditional Summarization with Adaptive Multi-task Fine-Tuning"}, {"paperId": "7ba0dc20800195c6350995695c8bf86be6227c49", "title": "Improving Zero and Few-Shot Abstractive Summarization with Intermediate Fine-tuning and Data Augmentation"}, {"paperId": "5d502c4ecf060440636e487875102bb81f2d7505", "title": "Unsupervised Extractive Summarization by Pre-training Hierarchical Transformers"}, {"paperId": "587a83a209a82e753b7df25e90fc2c46e4b59fde", "title": "A Cascade Approach to Neural Abstractive Summarization with Content Selection and Fusion"}, {"paperId": "46e7383e6fb8da77479d0a828c7a24d924302169", "title": "Stepwise Extractive Summarization and Planning with Structured Transformers"}, {"paperId": "53c283cc281deb515c4b4b539dbcd636c5842e62", "title": "Towards Question-Answering as an Automatic Metric for Evaluating the Content Quality of a Summary"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "dbeeca8466e0c177ec67c60d529899232415ca87", "title": "On Faithfulness and Factuality in Abstractive Summarization"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "65b9c5b3e2c27ddd4ebb6f8ed33ab82fa67f1dc6", "title": "Neural Abstractive Summarization with Structural Attention"}, {"paperId": "76037594f29a663fbd2799de2e5c7463c02a8a1d", "title": "Discourse-Aware Neural Extractive Text Summarization"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "af93e1accba69994cdc36254ef93584af307fd8a", "title": "Neural Text Summarization: A Critical Evaluation"}, {"paperId": "90d8f96e2cd71a50b40992020cb65bc75f352ea1", "title": "Better Rewards Yield Better Summaries: Learning to Summarise Without References"}, {"paperId": "d2803635b4ab094f230481c74e7d680f333e1d14", "title": "Deep Reinforcement Learning with Distributional Semantic Rewards for Abstractive Summarization"}, {"paperId": "63748e59f4e106cbda6b65939b77589f40e48fcb", "title": "Text Summarization with Pretrained Encoders"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "cc27ec53160d88c25fc5096c0df65536eb780de4", "title": "Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "e5ae1e458a5d5de95dfecabead30ce8217398538", "title": "Modelling the Dynamic Joint Policy of Teammates with Attention Multi-agent DDPG"}, {"paperId": "3a94167d2cc39282d55cade641ec887e9eaf6b01", "title": "CQASUMM: Building References for Community Question Answering Summarization Corpora"}, {"paperId": "63f81ec1a331f66f8ced0c189bf30829fe017c1c", "title": "BanditSum: Extractive Summarization as a Contextual Bandit"}, {"paperId": "682660c7a014e806b924fdf1a2a3d999a9ac13cf", "title": "Guided Neural Language Generation for Abstractive Summarization using Abstract Meaning Representation"}, {"paperId": "7af89df3691d8c33aaf1858f7cc51da1bc9549a9", "title": "Bottom-Up Abstractive Summarization"}, {"paperId": "d524bd471d631d302cfd98316839c52f11a69a88", "title": "Learning When to Concentrate or Divert Attention: Self-Adaptive Attention Temperature for Neural Machine Translation"}, {"paperId": "2fdf58255aa7d15635cd562ee0244fc802438d34", "title": "Adapting the Neural Encoder-Decoder Framework from Single to Multi-Document Summarization"}, {"paperId": "1e8feffa2280e41ceb864b940869c5408db89285", "title": "Entity-aware Image Caption Generation"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "59562be2cf8e01e8b7bb7560cef56158ea171227", "title": "Ranking Sentences for Extractive Summarization with Reinforcement Learning"}, {"paperId": "453aa72c327e3886059582e90c461e0581a78a49", "title": "Automatic Text Summarization Using Reinforcement Learning with Embedding Features"}, {"paperId": "c624c38e53f321a6df2d16bd707499ce744ca114", "title": "Abstractive Document Summarization with a Graph-Based Attentional Neural Model"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "032274e57f7d8b456bd255fe76b909b2c1d7458e", "title": "A Deep Reinforced Model for Abstractive Summarization"}, {"paperId": "1298dae5751fb06184f6b067d1503bde8037bdb7", "title": "Deep Reinforcement Learning for Dialogue Generation"}, {"paperId": "7a67159fc7bc76d0b37930b55005a69b51241635", "title": "Abstractive Sentence Summarization with Attentive Recurrent Neural Networks"}, {"paperId": "02534853626c18c9a097c2712f1ddf3613257d35", "title": "Incorporating Copying Mechanism in Sequence-to-Sequence Learning"}, {"paperId": "33108287fbc8d94160787d7b2c7ef249d3ad6437", "title": "Modeling Coverage for Neural Machine Translation"}, {"paperId": "d1505c6123c102e53eb19dff312cb25cea840b72", "title": "Teaching Machines to Read and Comprehend"}, {"paperId": "9653d5c2c7844347343d073bbedd96e05d52f69b", "title": "Pointer Networks"}, {"paperId": "4d8f2d14af5991d4f0d050d22216825cac3157bd", "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "9065d03256bcc962938f81eb795e70db214c459c", "title": "Exploring Content Models for Multi-Document Summarization"}, {"paperId": "3827c54958e653b5ce23e19a347f1f52e25592b8", "title": "Beyond SumBasic: Task-focused summarization with sentence simplification and lexical expansion"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "44fca068eecce2203d111213e3691647914a3945", "title": "LexRank: Graph-based Lexical Centrality as Salience in Text Summarization"}, {"paperId": "7b95d389bc6affe6a127d53b04bcfd68138f1a1a", "title": "TextRank: Bringing Order into Text"}, {"paperId": "10ce81dadc2e07d69c8a4f0bbdf7d14b3f37882e", "title": "The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries"}, {"paperId": null, "title": "\u201cFEQA:Aquestionansweringevaluation frameworkforfaithfulnessassessmentinabstractivesummarization,\u201din"}, {"paperId": null, "title": "\u201cGenerating di-verseandconsistentQApairsfromcontextswithinformation-maximizing hierarchicalconditionalVAEs,\u201din"}, {"paperId": null, "title": "\u201cThesummaryloop:Learningtowriteabstractivesummarieswithoutexamples,\u201din"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "\u201cRankinggeneratedsummariesbycorrectness:Aninterestingbutchallengingappli-cationfornaturallanguageinference,\u201din"}, {"paperId": null, "title": "\u201cMulti-rewardreinforcedsummarizationwith saliencyandentailment,\u201din"}, {"paperId": null, "title": "\u201cAutomatic dialogue generationwithexpressedemotions,\u201din"}, {"paperId": null, "title": "\u201cA reinforced topic-awareconvolutionalsequence-to-sequencemodelforabstractivetextsummarization,\u201din"}, {"paperId": null, "title": "\u201cEnumerationofextractiveoraclesummaries,\u201din"}, {"paperId": null, "title": "\u201cQuestiongenerationforquestion answering,\u201din"}, {"paperId": null, "title": "\u201cGettothepoint:Summarizationwithpointer-generatornetworks,\u201din"}, {"paperId": null, "title": "\u201cAbstractive textsummarizationusingsequence-to-sequenceRNNsandbeyond,\u201din"}, {"paperId": null, "title": "\u201cEffectiveapproachestoattention-basedneuralmachinetranslation,\u201din"}, {"paperId": null, "title": "\u201cAlargeannotated corpusforlearningnaturallanguageinference,\u201din"}, {"paperId": "d3329b8e7106069cf537795d19ba97bcf8252b25", "title": "The ICSI Summarization System at TAC 2008"}, {"paperId": "4c915c1eecb217c123a36dc6d3ce52d12c742614", "title": "Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning"}, {"paperId": null, "title": "\u201cTheanatomyofalarge-scalehypertextualwebsearchengine,\u201d"}, {"paperId": null, "title": "RL-ConvS2S"}, {"paperId": null, "title": "LongT5 BASE [33] scales the T5 [59] architecture over the input length and the model size while combining the Pegasus pretraining objective and TGlobal attention"}, {"paperId": null, "title": "is an RL-based baseline that uses the greedily decoded sentences and the sampled distribution sentences as a combined RL reward"}, {"paperId": null, "title": "extends the work of PG by incorporating structural attention in a hierarchical encoder setting to capture the long-range contextual dependencies"}, {"paperId": null, "title": "applicable license agreement with IEEE. Restrictions apply"}]}