{"paperId": "27f8c420f0967eba781f0e1c03db7363570b66af", "title": "Private Fine-tuning of Large Language Models with Zeroth-order Optimization", "abstract": "Fine-tuning large pretrained models on private datasets may run the risk of violating privacy. Differential privacy is a framework for mitigating privacy risks by enforcing algorithmic stability. DP-SGD enables training models with private data in a privacy-preserving manner, but raises new obstacles in the form of performance loss and significant engineering challenges. We introduce DP-ZO, a new method for fine-tuning large language models that preserves the privacy of training data by privatizing zeroth-order optimization. A key insight into the design of our method is that the direction of the gradient in SPSA, the zeroth-order algorithm we use, is always random and the only information that depends on private data is the step size, i.e., a scalar. Therefore, we only need to privatize the scalar step size, which is memory-efficient. DP-ZO, which can be instantiated with either Laplace or Gaussian noise, provides a strong privacy-utility trade-off across different tasks, and model sizes, under conservative privacy budgets. One noteworthy result is that DP-ZO exhibits just $1.86\\%$ performance degradation due to privacy at $(1,10^{-5})$-DP when fine-tuning OPT-66B on 1000 training samples from SQuAD.", "venue": "arXiv.org", "year": 2024, "citationCount": 7, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces DP-ZO, a new method for fine-tuning large language models that preserves the privacy of training data by privatizing zeroth-order optimization, and provides a strong privacy-utility trade-off across different tasks, and model sizes, under conservative privacy budgets."}, "embedding": {"model": "specter_v2", "vector": [0.39195191860198975, 0.7247354388237, -0.5228981375694275, -0.08181688189506531, -0.7108945250511169, -0.08866481482982635, 0.6424337029457092, -0.15144020318984985, -0.8710913062095642, -0.35062944889068604, 0.025212906301021576, 0.11266416311264038, 0.35397472977638245, -0.025337830185890198, -0.5684765577316284, -0.10476583242416382, -0.9172669053077698, 0.3177473843097687, -0.07380419969558716, -0.08977945148944855, -0.5977511405944824, -0.44459766149520874, -0.7746368050575256, 0.240029975771904, 0.23424921929836273, 0.937804102897644, -0.19081327319145203, 1.096569299697876, 0.06996571272611618, -0.23907046020030975, 0.558441698551178, -0.4016525149345398, 0.8340874910354614, 0.26002949476242065, -0.07284542918205261, 0.06526152044534683, 0.025544391945004463, -0.5226068496704102, -0.7956430912017822, 1.3750404119491577, -0.07131578773260117, 0.3965153396129608, 0.31900453567504883, -0.7613528966903687, -0.5313733220100403, 0.23867368698120117, 0.1210891529917717, 0.6481383442878723, -0.43574148416519165, -0.4566181004047394, 1.3760805130004883, -0.8114296197891235, 0.19398491084575653, 1.5953119993209839, 0.15236487984657288, 0.45340797305107117, -0.5089160799980164, -0.7183451056480408, 0.511708676815033, -0.3822380006313324, -1.0814870595932007, -0.06413585692644119, -0.5404488444328308, 0.0214389655739069, 1.217604160308838, -0.11381622403860092, -0.5858902931213379, 0.5491827726364136, 0.04626339301466942, 1.2667118310928345, 0.4352762699127197, -0.5111483931541443, -0.19155801832675934, 0.4611327350139618, 0.3150148093700409, 0.6452447175979614, -0.016675598919391632, 0.6087145805358887, -1.0529534816741943, -0.8837112784385681, -0.11696061491966248, -0.1791081726551056, 0.07950948923826218, -0.4965302348136902, 0.17537087202072144, 0.5682814717292786, 0.0033105588518083096, 0.1571124792098999, 0.3015557527542114, 0.8694397211074829, 0.5238762497901917, 0.5837540626525879, 0.563647985458374, 0.13519595563411713, -0.17457236349582672, 0.1602642983198166, -0.8423911333084106, 0.31537970900535583, 0.34263280034065247, 0.7500085234642029, -0.2428663671016693, -0.29010552167892456, -0.888910174369812, 0.02806798554956913, 1.3711817264556885, 0.16759353876113892, 0.3551260828971863, -0.5490707159042358, 0.5631297826766968, -0.9638272523880005, 0.1595185399055481, -0.7506945133209229, -0.05776554346084595, -0.07994940131902695, -1.0472480058670044, -0.9879196882247925, -0.5056928396224976, 0.08988369256258011, -0.8051663637161255, 0.7210885286331177, -0.0784200131893158, 0.12185578048229218, 0.027958422899246216, 0.6224319338798523, 0.20718662440776825, 0.6937653422355652, -0.06620347499847412, 0.16882571578025818, 1.2761653661727905, -0.5683997273445129, -0.32777702808380127, -0.7826801538467407, 0.6142081022262573, 0.08770554512739182, 0.6703711152076721, 0.1223149225115776, -0.9449841976165771, -0.35071924328804016, -0.890299916267395, -0.26612529158592224, -0.3771061897277832, 0.35481369495391846, 0.7678507566452026, 0.953892707824707, -0.9362611770629883, 0.7550293803215027, -0.6953909397125244, -0.1397734135389328, 0.7733340859413147, 0.6549543738365173, 0.2214614897966385, -0.007185367867350578, -1.4076564311981201, -0.03572548180818558, 0.557256281375885, -0.870173454284668, -0.05278374254703522, -0.8565980195999146, -0.7786023616790771, 0.12184032052755356, 0.5111608505249023, -0.6207613348960876, 1.0128309726715088, 0.29546457529067993, -1.365053653717041, 1.3477329015731812, -0.17217345535755157, -0.2905525267124176, 1.1983100175857544, -0.15162740647792816, -0.6075614094734192, -0.45878809690475464, -0.46843111515045166, 0.20599550008773804, 0.556545615196228, -0.16538746654987335, -0.1721760630607605, 0.07441385090351105, -0.3854617178440094, -0.10727270692586899, -0.3405759930610657, 0.6867825984954834, -0.6018801927566528, -0.4551922082901001, 0.17352817952632904, 0.13071578741073608, -0.2757563889026642, 0.2084389626979828, -0.7498977184295654, -0.8406077027320862, 0.7431135177612305, 0.12841995060443878, 0.9817603230476379, -1.3171923160552979, -0.9759351015090942, 0.621421217918396, 0.1531822830438614, 0.05399983376264572, -0.22756925225257874, 0.2224951982498169, -0.14160004258155823, 0.7207989692687988, -0.4317292869091034, -1.4181820154190063, 0.4465034008026123, -0.1536564975976944, -0.5500723123550415, 0.32051581144332886, -0.18650776147842407, 1.0449793338775635, -0.741590678691864, 0.49676042795181274, -0.3960750102996826, 0.10825932770967484, -1.327979326248169, 1.2114745378494263, -0.7250904440879822, 0.4213670492172241, -0.15309718251228333, -0.539067268371582, 0.6644055843353271, -0.7257686257362366, 0.26689285039901733, 0.21160468459129333, 0.4675239622592926, 0.45610302686691284, -0.679623007774353, 1.1008180379867554, -0.0314684621989727, 0.35084959864616394, 0.33390843868255615, -0.48364540934562683, -0.21459712088108063, 0.10252100229263306, -0.08358418941497803, -0.11844831705093384, 0.49369552731513977, 0.1489732265472412, -0.9447159171104431, 0.16749462485313416, 0.40034323930740356, 0.7318768501281738, -0.12853190302848816, 0.5329237580299377, -0.031169332563877106, -0.09271441400051117, 0.07920638471841812, 0.3480280935764313, 0.36587265133857727, -0.026067905128002167, 0.5041957497596741, -0.012966684065759182, 0.12474380433559418, -1.4799507856369019, -0.21531502902507782, 0.7943338751792908, 0.719927191734314, 0.962697446346283, 0.6835657954216003, -0.5250164866447449, -0.4010153114795685, -0.3698814809322357, 0.35264477133750916, 1.5080373287200928, -0.055099256336688995, -0.31874218583106995, -0.7182261347770691, -0.34429824352264404, 0.2615930140018463, -0.19284258782863617, -0.5557847619056702, -0.029172729700803757, -0.2313869297504425, -1.6091184616088867, 0.8852106928825378, -0.4056769609451294, 0.7781501412391663, 0.01148266438394785, 0.16853033006191254, -0.858604371547699, 0.7724441289901733, -0.9169114232063293, -0.9358624815940857, -0.018118856474757195, 0.020600993186235428, 0.31948816776275635, 0.08645737916231155, 0.235511913895607, 0.32424595952033997, -0.8351859450340271, 0.5549795627593994, -0.5346522331237793, -0.07661070674657822, 0.26155880093574524, 0.5693246722221375, -0.4338289797306061, -1.0265330076217651, 0.5310664176940918, 0.2797744572162628, 0.4577573239803314, 0.06097659096121788, 0.03309960663318634, 0.1285107582807541, -0.2580302655696869, -0.5842105746269226, -0.23259028792381287, 0.18631888926029205, -0.010943947359919548, 0.42323076725006104, -0.17937541007995605, -0.3401644229888916, -1.7375397682189941, 1.2282140254974365, -0.04824497178196907, -0.8123500347137451, 0.28067004680633545, -1.081101655960083, 0.1302264928817749, 0.4610411524772644, -0.8326834440231323, -0.2851356565952301, -0.9279282093048096, -0.100627601146698, -0.5945022702217102, -0.053322941064834595, -0.2128962278366089, 0.14611029624938965, 0.06608156114816666, 0.552043080329895, 0.5952574014663696, 0.4730163812637329, -0.26306474208831787, 0.551932156085968, -0.7452982068061829, 0.34545913338661194, -0.23025597631931305, 0.5142195820808411, 0.32982906699180603, -0.08013105392456055, -0.9911019206047058, -0.31690189242362976, -0.3856827914714813, 0.12776437401771545, 0.47847452759742737, 0.23381543159484863, -0.617709219455719, -1.3022068738937378, 0.1523611694574356, -0.5589092373847961, -0.2471398562192917, 0.013050897978246212, -0.29257822036743164, -0.29291751980781555, -0.541840136051178, -1.4222500324249268, -0.5710344910621643, -0.8591625094413757, -1.0628751516342163, 0.49064019322395325, -0.17346130311489105, -0.39380812644958496, -0.4067663848400116, -0.641691267490387, -0.3447415232658386, 0.43830606341362, -0.6065234541893005, 0.6031798720359802, -0.11385446786880493, -0.5374839305877686, -0.37875160574913025, -0.07714082300662994, 0.47975262999534607, -0.5424198508262634, 0.013800401240587234, -1.1658897399902344, -0.31167951226234436, -0.4612075388431549, -0.18120786547660828, 0.4887423515319824, 0.12237578630447388, 1.401582956314087, -0.5182704925537109, -0.5839928984642029, 1.2037408351898193, 1.262690782546997, -1.0165011882781982, -0.019942233338952065, 0.06654037535190582, 1.0161763429641724, -0.3103938698768616, -0.20480383932590485, 1.0288629531860352, 0.22193610668182373, 0.27997320890426636, -0.2552356719970703, 0.13791607320308685, 0.4691459536552429, -0.877960205078125, 0.43383556604385376, 0.6377937197685242, 0.9250529408454895, -0.1365499645471573, -0.567486584186554, 0.48897072672843933, -1.1272670030593872, -0.7008771896362305, 0.5473741888999939, 1.2571169137954712, 0.1992303431034088, 0.048847880214452744, -0.026159899309277534, -0.5989767909049988, 0.24621956050395966, 0.6989426612854004, -0.45001113414764404, -0.8654350638389587, -0.039445798844099045, 0.2760370671749115, 0.9713404774665833, 0.4632454216480255, -0.5935943126678467, 0.421618789434433, 14.589134216308594, 1.1372770071029663, 0.09197051078081131, 1.05551016330719, 0.9523349404335022, -0.19499854743480682, -0.6025453209877014, -0.24650777876377106, -1.1855701208114624, 0.4502331018447876, 1.0512654781341553, 0.030823854729533195, 0.8623945116996765, 0.07014280557632446, -0.03300575539469719, 0.19703255593776703, -0.31544938683509827, 0.9480332732200623, 0.18608024716377258, -1.2324328422546387, -0.08377935737371445, 0.4998950660228729, 0.8600338697433472, 0.882706344127655, 1.1802849769592285, 0.05589573457837105, 0.9027394652366638, -0.45823073387145996, 0.30395957827568054, 0.2948421835899353, 1.1495968103408813, -0.2059299349784851, -0.3297247588634491, 1.0140533447265625, -0.3983422815799713, -0.124898262321949, -0.5107579827308655, -0.8402060270309448, 0.06412988156080246, 0.36869269609451294, -0.52607262134552, -0.4965096414089203, 0.14703704416751862, 0.48151251673698425, 0.4143080413341522, -0.02226640097796917, -0.12874992191791534, 0.5455173254013062, -0.771140992641449, 0.08908101916313171, 0.06942898780107498, 0.228985995054245, 0.4357163906097412, -0.2471981942653656, 0.049025293439626694, 0.056810446083545685, 0.15453307330608368, 0.6456790566444397, -0.7527917623519897, -0.25363290309906006, 0.02851138822734356, -0.13291680812835693, -0.08709455281496048, 0.36934638023376465, 0.995607316493988, 0.42694005370140076, -0.26259908080101013, 0.7597384452819824, 0.585192859172821, 0.1507672220468521, 0.12325944006443024, 0.4667513072490692, 0.8724865913391113, -0.27749183773994446, -0.22254975140094757, 0.422161728143692, -0.42298489809036255, -0.7020424604415894, -0.2714158296585083, -0.5773882269859314, 0.7025593519210815, -0.219705268740654, -0.9795442223548889, 0.3175875246524811, -0.37743034958839417, -0.23541279137134552, 0.6229730248451233, -0.4636662006378174, 0.27719050645828247, 0.7802124619483948, -1.0688670873641968, -0.5845027565956116, 1.0443750619888306, -0.6426685452461243, -0.8649826049804688, 0.14755800366401672, 1.0391091108322144, 0.09916829317808151, -0.20750242471694946, 1.0449327230453491, 0.7586372494697571, -0.09706875681877136, -0.08541492372751236, -0.6780830025672913, 1.465503215789795, 0.42271125316619873, -0.2717120051383972, 0.2950674295425415, 0.04003656283020973, 0.24210579693317413, -0.6090441942214966, -0.014131988398730755, 0.5398358106613159, -1.0309723615646362, -0.0707932710647583, -1.016236662864685, -0.6626570224761963, 0.4044150412082672, 0.051804035902023315, 0.16794012486934662, 0.23740114271640778, -0.052862949669361115, -0.5913554430007935, -0.1305183619260788, -0.8869730830192566, 0.07628253102302551, 0.6930792927742004, -1.1457234621047974, 0.1556905061006546, -0.06212456896901131, 0.4104469120502472, -1.4848240613937378, -0.6900967359542847, -0.04029077664017677, 0.22739753127098083, 0.01907411962747574, 0.9735613465309143, -0.6277556419372559, 0.3006185293197632, 0.881295919418335, -0.015456460416316986, -0.5427762866020203, 0.2646772861480713, -1.4321218729019165, -0.23649190366268158, -0.023518458008766174, 0.6258516907691956, -0.8113974928855896, 0.6468175053596497, 1.1462856531143188, 0.9737705588340759, -0.5028996467590332, -0.6107944846153259, -0.34654533863067627, 0.11025446653366089, -0.5320701003074646, 0.31919175386428833, 0.00348452921025455, -0.5151587724685669, -0.4658340513706207, -0.2053116410970688, 1.4083608388900757, 0.22408470511436462, -0.776154637336731, 0.640181839466095, -0.02705259621143341, -0.6322248578071594, -0.40872374176979065, -0.5136968493461609, -1.9047999382019043, -0.00739702396094799, -1.3394380807876587, -0.40619805455207825, -0.20576681196689606, -0.4956424832344055, 0.03545013442635536, -0.13492487370967865, -0.5876109600067139, 0.23697982728481293, -0.32068362832069397, -0.29539063572883606, -0.5803312063217163, -0.22449465095996857, 0.6700592637062073, 0.69701087474823, -0.661302924156189, 0.05943828821182251, 0.7734189033508301, -0.031730376183986664, 0.18963004648685455, 0.41773587465286255, -0.7675564885139465, -0.7916733026504517, -0.9545854926109314, 0.43061378598213196, -0.5066896677017212, 0.07931378483772278, -0.5858849883079529, 0.7202149033546448, 0.15391677618026733, -0.3243299722671509, 0.20020121335983276, 0.371216356754303, -1.1569325923919678, -0.3845832943916321, 0.39761215448379517, -1.081511378288269, -0.059535469859838486, -0.14623533189296722, -0.170196533203125, 0.22136901319026947, 0.8647064566612244, 0.26914161443710327, -0.8340244293212891, -0.2392224371433258, 0.9653061628341675, -0.2822239398956299, 0.5416719913482666, -0.32926201820373535, 0.2179166078567505, -0.9031025171279907, -0.3807622194290161, -0.5062857866287231, 0.6773476004600525, -0.12408674508333206, 0.9480379819869995, -0.04591444507241249, -0.9274283647537231, 0.15965425968170166, 0.8001703023910522, -0.06096181273460388, 0.41751113533973694, 0.5898116827011108, 0.2740391790866852, -0.37581807374954224, 0.3409351408481598, 0.9018513560295105, 0.5264496207237244, -1.0722030401229858, 0.0952068641781807, 0.7853481769561768, -0.7199522852897644, -0.4139966368675232, 1.4906771183013916, 0.13347457349300385, -1.2030671834945679, 0.15527760982513428, -1.0920813083648682, 0.3291144371032715, -0.48142606019973755, 0.4234960973262787, 0.21440434455871582, -0.012366500683128834, 0.11058717221021652, -0.5976894497871399, -0.13966412842273712, 0.0011321513447910547, -0.5060389637947083, 0.35229259729385376, -0.5686887502670288, -0.5319992899894714, 0.3873571455478668, 1.5160213708877563, -0.3872387409210205, -1.0477991104125977, -1.1326097249984741, -0.2775859236717224, -0.5267776846885681, 0.1665264368057251, -0.15311996638774872, -0.45949622988700867, 0.4577261507511139, 0.607261598110199, 0.1661750227212906, 0.07755731791257858, -0.12930630147457123, 0.37531334161758423, 0.6501666307449341, 0.04033726453781128, -0.7786838412284851, -0.9975622296333313, 0.8013219833374023, 0.8084515333175659, -1.0459840297698975, 0.4679032862186432, -0.5186209678649902, -0.6476286053657532, 0.16222573816776276, 0.09775569289922714, -0.06927375495433807, 1.3002979755401611, -0.16697338223457336, -0.04907155781984329, 0.347339391708374, -1.0187110900878906, -0.18023967742919922, 1.3534140586853027, 0.46950510144233704, 0.061782218515872955, 0.7019038796424866, 0.012801208533346653, 0.8747783303260803, -0.22338144481182098, -0.09421935677528381, 0.209415465593338, 0.2171279489994049, -0.0104293841868639, -0.2543337345123291, -0.07293727993965149, 1.18430495262146, -1.306182622909546, -0.46913012862205505, -0.05911235138773918, 0.1474139392375946, 0.10196033120155334, 0.2672681510448456, 0.6221866607666016, -0.031876105815172195, 0.35229799151420593, -0.1679450124502182, 0.11449480056762695, -0.4790070056915283, 0.020259229466319084, -0.4850602149963379, -0.6517957448959351, -0.17449887096881866, 0.3862702548503876, -0.5122747421264648, -0.3839755952358246, -0.7204110026359558, 0.8293704986572266, -0.12999461591243744, -0.3267785310745239, 1.2137283086776733, 0.6769933104515076, -0.009237520396709442, 0.2017734944820404, -0.09681183099746704, -1.0422345399856567, -0.20015686750411987, -0.47884994745254517, -0.5216732025146484, 0.12557800114154816, 0.439435750246048, -0.1810998171567917, -0.6578616499900818]}, "authors": [{"authorId": "2243940153", "name": "Xinyu Tang"}, {"authorId": "1816755705", "name": "Ashwinee Panda"}, {"authorId": "3490923", "name": "Milad Nasr"}, {"authorId": "28122602", "name": "Saeed Mahloujifar"}, {"authorId": "2254282852", "name": "Prateek Mittal"}], "references": [{"paperId": "00426e1197194a204886fdcfb3894fcbb90d4e31", "title": "DPZero: Private Fine-Tuning of Language Models without Backpropagation"}, {"paperId": "f0676c081f12c9395cd0e920d137a90a9ceb2c4a", "title": "Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation"}, {"paperId": "385c2ee0bf829676d1a5aacfc697fc6a9d245ed5", "title": "DP-Forward: Fine-tuning and Inference on Language Models with Differential Privacy in Forward Pass"}, {"paperId": "b40b72ccfa4eb12ecf97ad9a65543dec02bceab2", "title": "Differentially Private Image Classification by Learning Priors from Random Processes"}, {"paperId": "ad4b365630f1c13d74d78f0f5d8cee87ef356d41", "title": "Fine-Tuning Language Models with Just Forward Passes"}, {"paperId": "2f2a430ba6c93bcfaf4818316ff8a27b1e034b1a", "title": "Flocks of Stochastic Parrots: Differentially Private Prompt Learning for Large Language Models"}, {"paperId": "6e41a4cbb34c4d403efb73d74f5be5556b1f13d6", "title": "Privacy-Preserving In-Context Learning for Large Language Models"}, {"paperId": "e231843966472fa60117403f49f2ac5f252ed1d9", "title": "A Randomized Approach for Tight Privacy Accounting"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "75e852a362b8c4fd5115590ab174a2185128d7c0", "title": "Why Is Public Pretraining Necessary for Private Model Training?"}, {"paperId": "1d589e172084a1451398f0d6c30592baa8224732", "title": "A New Linear Scaling Rule for Private Adaptive Hyperparameter Optimization"}, {"paperId": "0ba0091c60c0346493b9ffb46ac682eee5453a53", "title": "Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping"}, {"paperId": "ba2b6a94d4fb018c9eab252a34d80787ae962f46", "title": "Differentially Private Optimization on Large Model at Small Cost"}, {"paperId": "051c2cfb399d71dfc91459cad5be404ee4568f9d", "title": "When Does Differentially Private Learning Not Suffer in High Dimensions?"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "2a60bebcb0d01aa1d27ab0f4e6d2210df093042c", "title": "Unlocking High-Accuracy Differentially Private Image Classification through Scale"}, {"paperId": "56874f9aef515902c5a49d84d10f629f8dcd5f40", "title": "Differentially Private Fine-tuning of Language Models"}, {"paperId": "6a758ada5c48a2ae48d1392d12ce4f4e1977e0dd", "title": "Large Language Models Can Be Strong Differentially Private Learners"}, {"paperId": "bea1187a1f8a68f1a93f0c2fa10d31f93a30f84e", "title": "Opacus: User-Friendly Differential Privacy Library in PyTorch"}, {"paperId": "5229800fdbe094ba62f64715b0ec4a7a270cb943", "title": "Christine P. Chai's contribution to the Discussion of \u2018Gaussian Differential Privacy\u2019 by Dong et al."}, {"paperId": "8f435293ddeaa91819e4c9c5c0e0180750fe44cc", "title": "Large Scale Private Learning via Low-rank Reparametrization"}, {"paperId": "fe6f8b49e73ca96f24c83cc933f3072c57a3e0c7", "title": "Optimal Accounting of Differential Privacy via Characteristic Function"}, {"paperId": "a7d7db2320436a90dac4fb10a50dc0500952e7a6", "title": "On the Convergence and Calibration of Deep Learning with Differential Privacy."}, {"paperId": "08c43944c22a3e10cecd5936f04f3e07b0e636c1", "title": "Numerical Composition of Differential Privacy"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "ee500b621cc59f76b3396c6c5f136be8e9c44726", "title": "Do Not Let Privacy Overbill Utility: Gradient Embedding Perturbation for Private Learning"}, {"paperId": "85e7d63f75c0916bd350a229e040c5fbb1472e7a", "title": "Making Pre-trained Language Models Better Few-shot Learners"}, {"paperId": "5c8c2a2c725f2f9da095045e35cf0f7322c360d5", "title": "Differentially Private Learning Needs Better Features (or Much More Data)"}, {"paperId": "50e571b2b90966ee1f6560681e679646324fc06b", "title": "Stability of Stochastic Gradient Descent on Nonsmooth Convex Losses"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "dda6fb309f62e2557a071522354d8c2c897a2805", "title": "DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs"}, {"paperId": "c489ced6b820e8609eec130a7484477ff27cfff4", "title": "DP-ADMM: ADMM-Based Distributed Learning With Differential Privacy"}, {"paperId": "597f72e80555f2072274bcc4b2a6d6999457ec3e", "title": "Privacy Amplification by Subsampling: Tight Analyses via Couplings and Divergences"}, {"paperId": "65f0e9db55f498bb196de3950393f5ded14bcc72", "title": "Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization"}, {"paperId": "d660e89055644fa122f2b4b4cdd32c85a5e33648", "title": "R\u00e9nyi Differential Privacy"}, {"paperId": "e9a986c8ff6c2f381d026fe014f6aaa865f34da7", "title": "Deep Learning with Differential Privacy"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "21a0b0fbdde1aee56fe10e69e897decaf21f43a6", "title": "Random Gradient-Free Minimization of Convex Functions"}, {"paperId": "65926b61d0308954bd6cc4f6cbe46eef64147635", "title": "Private Empirical Risk Minimization: Efficient Algorithms and Tight Error Bounds"}, {"paperId": "0023582fde36430c7e3ae81611a14e558c8f4bae", "title": "The Algorithmic Foundations of Differential Privacy"}, {"paperId": "d7440b0840c9a1aace59884e73d21250bec096e5", "title": "Optimal Rates for Zero-Order Convex Optimization: The Power of Two Function Evaluations"}, {"paperId": "fae3819ea63c7ae9eef2398fa938e84fe0c10317", "title": "Stochastic gradient descent with differentially private updates"}, {"paperId": "88dda59076c3b96a6f8866d8da395165b65955c6", "title": "The Composition Theorem for Differential Privacy"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "8424a9e5a4456a2c45a42e392b9c01cd0c5c9467", "title": "Stochastic First- and Zeroth-Order Methods for Nonconvex Stochastic Programming"}, {"paperId": "be6858f60ecf83ffaf952d24ecd522f9883c80d8", "title": "On the Complexity of Bandit and Derivative-Free Stochastic Convex Optimization"}, {"paperId": "e4ce10063cd25447dcde75c2d9ce327446ced952", "title": "Calibrating Noise to Sensitivity in Private Data Analysis"}, {"paperId": "f7410cd1afeba276f4479e8b5f04f12530b48d83", "title": "Multivariate stochastic approximation using a simultaneous perturbation gradient approximation"}, {"paperId": "5ef99a3d8770a675f60eb0f8cf1f4a1e6ab27a98", "title": "Privacy-Preserved Distributed Learning With Zeroth-Order Optimization"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "98892662e66e612c77a9a8e687841dff4982f1df", "title": "The Complexity of Differential Privacy"}, {"paperId": null, "title": "fp16 support"}, {"paperId": null, "title": "Private Fine-tuning of Large Language Models with deep learning made easier and stronger"}, {"paperId": null, "title": "OpenAI"}, {"paperId": null, "title": "How to DP-fy"}, {"paperId": null, "title": "parameter sharing support"}]}