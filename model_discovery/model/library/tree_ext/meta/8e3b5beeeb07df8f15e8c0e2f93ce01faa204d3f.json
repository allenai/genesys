{"paperId": "8e3b5beeeb07df8f15e8c0e2f93ce01faa204d3f", "title": "Structural Pruning of Pre-trained Language Models via Neural Architecture Search", "abstract": "Pre-trained language models (PLM), for example BERT or RoBERTa, mark the state-of-the-art for natural language understanding task when fine-tuned on labeled data. However, their large size poses challenges in deploying them for inference in real-world applications, due to significant GPU memory requirements and high inference latency. This paper explores neural architecture search (NAS) for structural pruning to find sub-parts of the fine-tuned network that optimally trade-off efficiency, for example in terms of model size or latency, and generalization performance. We also show how we can utilize more recently developed two-stage weight-sharing NAS approaches in this setting to accelerate the search process. Unlike traditional pruning methods with fixed thresholds, we propose to adopt a multi-objective approach that identifies the Pareto optimal set of sub-networks, allowing for a more flexible and automated compression process.", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper explores neural architecture search (NAS) for structural pruning to find sub-parts of the fine-tuned network that optimally trade-off efficiency, for example in terms of model size or latency, and generalization performance."}, "embedding": {"model": "specter_v2", "vector": [0.09248135983943939, 0.5085843801498413, -0.4753912687301636, -0.22830629348754883, -0.4627174735069275, -0.04867754876613617, 0.04006382077932358, -0.29798832535743713, -0.7832420468330383, -0.22343088686466217, 0.4739638864994049, -0.25465449690818787, 0.08577191829681396, 0.13987033069133759, 0.01183753740042448, 0.4961862564086914, -0.4467078149318695, 0.5130758285522461, -0.09565234184265137, -0.3694079518318176, -0.05750594660639763, -0.6433291435241699, -1.0725359916687012, -0.0015751828905194998, 0.49772289395332336, 0.945970892906189, 0.12105043977499008, 0.9674254655838013, -0.449019193649292, 0.115816131234169, 0.47473663091659546, -0.3897647261619568, 0.05962042883038521, 0.11939217150211334, -0.33782416582107544, -0.27521151304244995, 0.4726989269256592, -0.3906528055667877, -0.5160761475563049, 0.995760977268219, -0.45868319272994995, 0.3512977957725525, 0.31618210673332214, -0.5402283072471619, -0.2686338424682617, 0.8165341019630432, 0.4680842161178589, 0.740210235118866, -0.4702058732509613, -0.5548588633537292, 1.425372838973999, -1.1929856538772583, 0.05900241807103157, 1.6769969463348389, 0.6144424080848694, 0.6895925998687744, -0.3064654767513275, -0.802921712398529, 0.7103189826011658, 0.2147836834192276, -0.8073439598083496, -0.4980250895023346, 0.15402215719223022, 0.08890700340270996, 1.9609071016311646, -0.25553932785987854, -0.124626524746418, 0.25137028098106384, -0.13451719284057617, 1.4110230207443237, -0.4865085482597351, -0.7696570158004761, 0.038741279393434525, -0.03216442093253136, 0.6229315400123596, 0.9789912700653076, -0.09530006349086761, 0.3637540936470032, -0.8791097402572632, -0.3639465570449829, -0.05699756741523743, -0.08965618163347244, 0.1935170739889145, 0.04603629931807518, 0.5592736601829529, 1.0471018552780151, 0.3858441710472107, 0.5683080554008484, -0.008643265813589096, 0.9738672971725464, 0.6799172759056091, 0.5225762128829956, 0.10437674820423126, 0.5970187187194824, -0.1984950304031372, 0.4281821846961975, -1.071511149406433, 0.00291075580753386, -0.11212099343538284, 0.670100748538971, -0.316012442111969, 0.5447688698768616, -0.4857177734375, 0.49988672137260437, 1.4095485210418701, -0.26843297481536865, 0.4916050136089325, -0.8249258399009705, 0.5455150008201599, -0.5921438932418823, -0.245733842253685, -0.11412584036588669, -0.17778266966342926, -0.3483904004096985, -0.7430669665336609, -1.0521705150604248, -0.6000221371650696, -0.06312679499387741, -0.8078587055206299, 0.667671799659729, -0.6199098825454712, 0.32415738701820374, 0.11511844396591187, 0.37116938829421997, 0.30199387669563293, 0.5799323320388794, 0.48030737042427063, 0.1394800990819931, 0.9533841609954834, -1.04744291305542, -0.2684938609600067, -1.038488745689392, 0.5275505185127258, -0.011668783612549305, 0.0740140900015831, -0.11158691346645355, -1.4106029272079468, -1.0002199411392212, -0.789146363735199, -0.3540503978729248, -0.33221057057380676, 0.29073771834373474, 0.8777471780776978, 0.45058679580688477, -1.1090373992919922, 0.8083677291870117, -0.21216121315956116, -0.15960507094860077, 0.7169538140296936, 0.48162466287612915, 0.6798890233039856, -0.39118221402168274, -1.0983997583389282, 0.20783765614032745, 0.2924848198890686, -0.5282351970672607, -0.20710405707359314, -0.656731903553009, -1.0178364515304565, 0.3454379737377167, 0.2556796371936798, -0.979649007320404, 1.241575002670288, -0.19351249933242798, -1.4890457391738892, 0.3340226411819458, -0.31648144125938416, -0.3160668611526489, 0.0919380933046341, -0.45742902159690857, -0.5182809829711914, -0.3423152267932892, -0.7836361527442932, 0.7995678782463074, 0.6820952296257019, -0.1538580060005188, -0.19552242755889893, 0.260381281375885, -0.04283343628048897, -0.019267955794930458, -0.48411062359809875, 0.8739230036735535, -0.6264172792434692, -0.27627700567245483, 0.46831023693084717, 0.6736679077148438, -0.15604452788829803, -0.33604052662849426, -0.6309191584587097, -1.1679284572601318, 0.613636314868927, -0.29154103994369507, 1.1128978729248047, -0.7239195108413696, -0.5954362154006958, 0.1671595573425293, 0.06197626516222954, -0.058933112770318985, -1.2441383600234985, 0.07157249003648758, -0.23496589064598083, 0.5308908224105835, -0.04675908014178276, -1.4494285583496094, -0.09953974187374115, -0.3864803612232208, -0.8060651421546936, -0.4156423807144165, -0.031616419553756714, 1.1030923128128052, -0.6695736050605774, 0.1966402530670166, -0.23250427842140198, 0.4947676956653595, -1.3145480155944824, 0.9776826500892639, -0.6133331656455994, 0.0719490796327591, -0.21343958377838135, -0.03435588628053665, -0.16867689788341522, 0.010545549914240837, 0.384736031293869, -0.40665099024772644, -0.06161550059914589, 0.6527342200279236, 0.1343407928943634, 1.4124336242675781, -0.6681522130966187, 0.4193907678127289, -0.008969811722636223, -0.4734075665473938, 0.3362584412097931, 0.2782324254512787, -0.440110981464386, -0.3686366081237793, 0.5619909167289734, 0.49696019291877747, -0.4092435836791992, 0.6136382818222046, 0.8601645231246948, 0.8585489988327026, -0.26722970604896545, 0.1711658537387848, 0.7649927139282227, -0.38004472851753235, 0.7306567430496216, 0.22547614574432373, 0.7962281107902527, 0.13931678235530853, 0.03880976885557175, 0.014160041697323322, 0.7604075074195862, -0.6393453478813171, 0.07650608569383621, 0.42360174655914307, 0.8363436460494995, 0.8676422834396362, 0.29286301136016846, -0.8314805030822754, -0.5807576775550842, 0.13364489376544952, 0.7806046009063721, 1.5812848806381226, -0.43587300181388855, -0.003419693559408188, -0.8177358508110046, -0.4373445510864258, -0.3143583834171295, 0.28179433941841125, -0.11265486478805542, -0.10783589631319046, -0.5824407935142517, -1.0235352516174316, 1.0982035398483276, 0.25923481583595276, 1.00567626953125, -0.2690245807170868, -0.11001870781183243, -0.4244113862514496, 0.45611056685447693, -0.6298862099647522, -0.5626343488693237, 0.2695242762565613, -0.9258778691291809, -0.2514222264289856, 0.21352334320545197, 0.1731346845626831, 0.18889659643173218, -0.6082552075386047, 0.910775899887085, -0.06083009019494057, -0.443878173828125, 0.00029777950840070844, 0.9001744389533997, -0.54062819480896, -0.7927277088165283, 0.4358431100845337, -0.07482011616230011, -0.4242453873157501, 0.4403786361217499, 0.5714691281318665, 0.054992254823446274, -0.31789764761924744, -0.0984976664185524, 0.0778949037194252, -0.0471821129322052, 0.04222789779305458, 0.8292959928512573, -0.16795901954174042, 0.06215756759047508, -1.3088635206222534, 1.1819747686386108, 0.21251316368579865, -0.762850821018219, 0.4891055226325989, -0.5678897500038147, -0.015542365610599518, 0.6750848889350891, -0.35135769844055176, -0.5256094336509705, -0.8715177178382874, -0.017862558364868164, -0.8279702663421631, -0.22307553887367249, 0.20695404708385468, 0.5574319958686829, 0.08261991292238235, 0.10834376513957977, 0.2708510458469391, 0.31513741612434387, -0.5651999711990356, 0.6219965815544128, -1.257290005683899, 0.5533621907234192, 0.20243974030017853, 0.2632128894329071, -0.224086731672287, -0.25711748003959656, -0.6165289282798767, -0.6039972305297852, -0.3517417013645172, -0.04030025750398636, 0.055752478539943695, 0.18684694170951843, -0.563490092754364, -0.5016318559646606, -0.4699748158454895, -1.0367251634597778, -0.10001253336668015, 0.01081738993525505, -0.1415010392665863, -0.11851182579994202, -1.3226242065429688, -1.415554165840149, -0.7025957107543945, -1.149630069732666, -1.1649093627929688, 0.3852519094944, 0.12944914400577545, -0.49510428309440613, -0.6214459538459778, 0.040878552943468094, -0.17218032479286194, 1.0690926313400269, -0.9632282853126526, 1.3668664693832397, -0.1298513561487198, -0.12324103713035583, -0.061573319137096405, -0.022442985326051712, 0.6361058950424194, -0.6819506883621216, 0.33661797642707825, -0.9667086005210876, -0.019235365092754364, -0.2361614853143692, -0.40637513995170593, 0.7091191411018372, 0.5619982481002808, 1.131666660308838, -0.021498288959264755, -0.3980693519115448, 0.6353156566619873, 1.625388264656067, -0.5650573372840881, 0.15579092502593994, -0.11879540234804153, 1.1332793235778809, 0.04642825946211815, -0.58687824010849, 0.21069562435150146, 0.13639307022094727, 0.2840028405189514, 0.11914754658937454, 0.09128664433956146, -0.5443708300590515, -0.4420429766178131, 0.35264524817466736, 1.9359372854232788, 0.18784816563129425, -0.18265089392662048, -0.7939755320549011, 0.3558352291584015, -1.0245877504348755, -0.422769695520401, 0.7834271788597107, 0.7066108584403992, 0.22156158089637756, -0.2082856297492981, -0.37671613693237305, -0.1659730225801468, 0.5701067447662354, 0.3505652844905853, -0.4308043420314789, -1.1155725717544556, 0.23136624693870544, 0.6538935899734497, 0.25265181064605713, 0.7910060882568359, -0.3481401205062866, 0.6038827300071716, 14.64695930480957, 1.0778436660766602, -0.04237509146332741, 0.7886290550231934, 1.0684000253677368, 0.1771417260169983, -0.40573909878730774, -0.3296035826206207, -1.4377727508544922, -0.21013624966144562, 1.298900842666626, 0.34959033131599426, 0.9523184895515442, 0.3379705250263214, 0.021787729114294052, 0.30180808901786804, -0.3820779323577881, 0.5782797932624817, 0.4065870940685272, -1.5359395742416382, 0.5574405789375305, 0.11578419804573059, 0.5376266241073608, 0.7790285348892212, 0.6535537838935852, 1.0001765489578247, 0.43912366032600403, -0.5843436121940613, 0.3451825976371765, 0.19428695738315582, 1.0642800331115723, -0.20275336503982544, 0.3712984621524811, 0.2972104847431183, -0.8454472422599792, -0.5181699991226196, -0.7456192970275879, -0.9264041185379028, 0.06868039816617966, -0.0006193795707076788, -0.17681917548179626, -0.4697644114494324, -0.32164132595062256, 0.440667062997818, -0.10618481785058975, 0.48904967308044434, -0.28565990924835205, 0.7878116965293884, -0.3681960999965668, 0.15590140223503113, 0.285960853099823, 0.3419502079486847, 0.1767278015613556, -0.1610398143529892, 0.18070052564144135, -0.08559545129537582, 0.03598206490278244, 0.5521661043167114, -1.0055795907974243, -0.40044963359832764, -0.19459468126296997, -0.25773587822914124, -0.08063782006502151, 0.6113236546516418, 0.5081967711448669, 0.3198656141757965, -0.3194271922111511, 0.0522543340921402, 1.0038254261016846, 0.34056517481803894, -0.24194416403770447, 0.08180301636457443, 0.28272125124931335, -0.8955100178718567, 0.02874108776450157, 0.6049789786338806, -0.7895889282226562, -0.6677815318107605, -0.9783868193626404, -0.36440229415893555, 0.6503611207008362, -0.7117191553115845, -0.6002212166786194, 1.0413260459899902, -0.3457849621772766, 0.13607142865657806, 0.3369850218296051, -0.7366664409637451, -0.47577330470085144, 0.23944391310214996, -1.4454467296600342, -0.579684853553772, 0.5325413346290588, -0.43209201097488403, 0.035420313477516174, -0.42113983631134033, 1.202402949333191, 0.3631523549556732, -0.7105516195297241, 0.2741546332836151, 0.22839303314685822, -0.23932874202728271, -0.505728542804718, -0.5584398508071899, 0.7208185195922852, 0.35904717445373535, 0.08639495074748993, 0.1547372043132782, -0.18876957893371582, 0.33714917302131653, -0.6972236633300781, -0.18200042843818665, 0.8678690195083618, -0.39394620060920715, -0.3110540509223938, -0.6702845096588135, -0.7268571257591248, 0.27735063433647156, 0.507376492023468, -0.5548995733261108, 0.28238505125045776, 0.2391393780708313, -0.7629241943359375, -0.11653362959623337, -0.9396852850914001, 0.047215141355991364, 0.5515937805175781, -0.8705641627311707, -0.43111303448677063, -0.19519037008285522, 0.38508591055870056, -0.7824319005012512, -0.29982990026474, 0.020701048895716667, 0.10131269693374634, 0.23133723437786102, 1.1411162614822388, -0.49050208926200867, 1.0191150903701782, 0.9496712684631348, 0.11702180653810501, -0.6799872517585754, -0.03893952816724777, -0.5566205978393555, -0.26124635338783264, -0.047926343977451324, 0.6551617383956909, -0.32366710901260376, 0.6387630105018616, 1.0754363536834717, 0.16947734355926514, -0.48376595973968506, -0.8378741145133972, -0.22346965968608856, -0.15585370361804962, -0.5658589601516724, 0.3549765348434448, -0.38165363669395447, -0.432450532913208, 0.28603488206863403, 0.6002241969108582, 0.4995712637901306, -0.22897940874099731, -0.606878936290741, -0.0582822822034359, -0.08072216063737869, -0.14301860332489014, -0.8817997574806213, -0.09673169255256653, -1.309212327003479, 0.24854475259780884, -1.1513900756835938, -0.13945773243904114, -0.7657610774040222, -0.5708926320075989, -0.16301150619983673, -0.3524143397808075, 0.015626372769474983, 0.7108896970748901, -0.04943795129656792, -0.37760013341903687, -0.5094365477561951, -0.5076308250427246, 0.7754448652267456, 0.3090779781341553, -0.9300336837768555, -0.07700891047716141, 0.11974284797906876, 0.10585103929042816, 0.7641887068748474, 0.6895772814750671, -0.3110716640949249, -1.1365660429000854, -1.7274229526519775, 0.12170252203941345, -0.18548642098903656, -0.21741917729377747, -0.7058040499687195, 1.0733534097671509, 0.5476331114768982, -0.4218252897262573, 0.10100649297237396, 0.3429025113582611, -0.8804271221160889, -0.6239003539085388, 0.6480638980865479, -1.0261693000793457, 0.4833885729312897, 0.28863900899887085, -0.47219616174697876, -0.43868693709373474, 0.2003486305475235, 0.1663150191307068, -0.8149349093437195, -0.9889863133430481, 0.24226690828800201, -0.4222871661186218, 0.19761411845684052, -0.7724736928939819, 0.10605824738740921, -1.150175929069519, -0.20619194209575653, -0.006616886239498854, 0.48047780990600586, -0.8551572561264038, 0.7211615443229675, 0.8126850724220276, -0.8664286136627197, -0.04457421228289604, 0.20581677556037903, -0.3575018048286438, 0.12944044172763824, 0.5797079205513, 0.41237205266952515, -0.5838706493377686, 0.6096985340118408, 0.3221256136894226, 0.5722858309745789, -0.9483911991119385, -0.3335167169570923, 0.8392736911773682, -0.8530489206314087, -0.12930522859096527, 1.3320256471633911, -0.33949968218803406, -0.9885339736938477, 0.24624258279800415, -1.2749712467193604, -0.50475013256073, -0.5177302360534668, 0.6939454674720764, 0.3928028643131256, 0.06756505370140076, 0.2759801149368286, -0.3210916817188263, 0.09291683882474899, -0.10233046859502792, -0.5263307690620422, 0.5330429077148438, -0.19214653968811035, -0.38532212376594543, 0.33584704995155334, 0.8536940217018127, -0.7245885729789734, -0.7554730772972107, -0.6868388056755066, -0.11557360738515854, -0.04339008405804634, 0.6523705720901489, -0.5029137134552002, -1.2299878597259521, 0.8699848055839539, 0.28142377734184265, -0.019653331488370895, 0.16031065583229065, -0.31196051836013794, 0.40236184000968933, 0.7852713465690613, -0.1140771135687828, -0.7328394055366516, -0.5563927888870239, 1.539548635482788, 1.3833825588226318, -0.7542784810066223, 0.5226665735244751, -0.41164568066596985, -0.44699493050575256, 1.060451626777649, 0.36904576420783997, -0.49286967515945435, 0.7947529554367065, -0.24108543992042542, -0.20231863856315613, 0.06640033423900604, -1.13352632522583, -0.20522932708263397, 1.075622797012329, 0.7593342065811157, 0.5920848846435547, 0.07235123217105865, 0.08569997549057007, 0.9208981394767761, 0.031775593757629395, -0.10467167943716049, 0.1772783100605011, 0.00462219025939703, -0.018051965162158012, 0.02355094812810421, 0.06364376842975616, 0.7543100714683533, -0.7665275931358337, -0.7925600409507751, 0.2056063413619995, 0.7761194705963135, 0.26778849959373474, 0.530886173248291, 0.9718236327171326, 0.004259344190359116, 0.35244178771972656, 0.28267261385917664, 0.4377932846546173, -0.5439799427986145, -0.5512651205062866, -0.03271310031414032, -0.31881073117256165, 0.0677514299750328, 0.18577615916728973, -0.302135169506073, -0.3517410457134247, -0.23031000792980194, 0.4253508746623993, -0.277769535779953, 0.4756503999233246, 1.0681402683258057, 0.5345029830932617, 0.6514673233032227, -0.577449381351471, -0.3789612054824829, -0.36981308460235596, -0.6406949758529663, 0.24979832768440247, -0.658515453338623, -0.49727800488471985, -0.1016300842165947, 0.0089213065803051, -0.5173386335372925]}, "authors": [{"authorId": "2238461878", "name": "Aaron Klein"}, {"authorId": "2238481381", "name": "Jacek Golebiowski"}, {"authorId": "2238532717", "name": "Xingchen Ma"}, {"authorId": "2299943113", "name": "Valerio Perrone"}, {"authorId": "2262457089", "name": "C\u00e9dric Archambeau"}], "references": [{"paperId": "53535d38fe259a3aa7c911edd8048d764e09e8e1", "title": "The case for 4-bit precision: k-bit Inference Scaling Laws"}, {"paperId": "4be7d1524edb0137599a5cc95f72844b85a52fe1", "title": "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale"}, {"paperId": "fb145e1e49d3269d8223c7710e22b45438613ff0", "title": "A Fast Post-Training Pruning Framework for Transformers"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "316a40ad51725c41524f7e8ef78b91a7886167ad", "title": "Multi-objective Asynchronous Successive Halving"}, {"paperId": "dd0a27aa2285bc64798fa76944400ab6d9ce3025", "title": "NAS-BERT: Task-Agnostic and Adaptive-Size BERT Compression with Neural Architecture Search"}, {"paperId": "c13f5dbf6fd48ae339dd3f3394e0cbe9661756d3", "title": "How Powerful are Performance Predictors in Neural Architecture Search?"}, {"paperId": "a34a77bd53e752c4ecfe8c5ddbf1c218e2e8ac31", "title": "AttentiveNAS: Improving Neural Architecture Search via Attentive Sampling"}, {"paperId": "8b9d77d5e52a70af37451d3db3d32781b83ea054", "title": "On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines"}, {"paperId": "1c55f470a8273788d82f05500d507b408a5722b8", "title": "Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization"}, {"paperId": "6f51319f22c3c02ab15cb26f5b332667ed1b7cd8", "title": "Exploring the loss landscape in neural architecture search"}, {"paperId": "39f8cc684f09ea2b43767f5b9590896774802759", "title": "On the effect of dropping layers of pre-trained transformer models"}, {"paperId": "a8c0ac6588012d91c81b83b6cbd16c40e2e5edd2", "title": "BigNAS: Scaling Up Neural Architecture Search with Big Single-Stage Models"}, {"paperId": "ca49bd49356148fa5f64e43bda07fe736a24fa34", "title": "Model-based Asynchronous Hyperparameter Optimization"}, {"paperId": "de66ada65cd9d36e46f1f8dd2c8be480180038ec", "title": "What is the State of Neural Network Pruning?"}, {"paperId": "54d4ff8d536b292149a4fa017c22349cf4e54ce4", "title": "AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural Architecture Search"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "7823292e5c4b05c47af91ab6ddf671a0da709e82", "title": "Once for All: Train One Network and Specialize it for Efficient Deployment"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "b03c7ff961822183bab66b2e594415e585d3fd09", "title": "Are Sixteen Heads Really Better than One?"}, {"paperId": "35a59bd09974c7fc78cf681f77f7301e180fd23c", "title": "Random Search and Reproducibility for Neural Architecture Search"}, {"paperId": "120ffccea4787b88f78b55b9302891ff96cb4228", "title": "Slimmable Neural Networks"}, {"paperId": "93436a26d744e0417e21df10abdfce2cc74b1e58", "title": "BOHB: Robust and Efficient Hyperparameter Optimization at Scale"}, {"paperId": "45b7b5514a65126d39a51d5a68da53e7aa244c1f", "title": "Understanding and Simplifying One-Shot Architecture Search"}, {"paperId": "c1f457e31b611da727f9aef76c283a18157dfa83", "title": "DARTS: Differentiable Architecture Search"}, {"paperId": "09b72a1299a6856bc33ada5bfd482810a3f9b292", "title": "Massively Parallel Hyperparameter Tuning"}, {"paperId": "fe9b8aac9fa3bfd9724db5a881a578e471e612d7", "title": "Efficient Neural Architecture Search via Parameter Sharing"}, {"paperId": "50bdda28de3dcf82a0e10f9ec13eea248b19edb5", "title": "Regularized Evolution for Image Classifier Architecture Search"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "f108b65fe0003e387e1cd7e50f537af0531818e4", "title": "Large-Scale Evolution of Image Classifiers"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "c6c745d7fae9aad4294549d829f7e7415ffb1709", "title": "Non-stochastic Best Arm Identification and Hyperparameter Optimization"}, {"paperId": "9be7e7579fbec5d45e3e6ea1c4465258225a183d", "title": "Initializing Bayesian Hyperparameter Optimization via Meta-Learning"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "29935173af73aef20336db72d608e0ef5b0e0c16", "title": "Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures"}, {"paperId": "188e247506ad992b8bc62d6c74789e89891a984f", "title": "Random Search for Hyper-Parameter Optimization"}, {"paperId": "e839b9802348606a71a35b6354c6d9def58d7d49", "title": "Performance assessment of multiobjective optimizers: an analysis and review"}, {"paperId": "08f14bc8734253ba886b91531c68ff88393a5a84", "title": "Syne Tune: A Library for Large Scale Hyperparameter Tuning and Reproducible Research"}, {"paperId": null, "title": "NAS valuation is frustratingly hard"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}]}