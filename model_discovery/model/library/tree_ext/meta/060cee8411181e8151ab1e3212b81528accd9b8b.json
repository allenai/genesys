{"paperId": "060cee8411181e8151ab1e3212b81528accd9b8b", "title": "On Transforming Reinforcement Learning With Transformers: The Development Trajectory.", "abstract": "Transformers, originally devised for natural language processing (NLP), have also produced significant successes in computer vision (CV). Due to their strong expression power, researchers are investigating ways to deploy transformers for reinforcement learning (RL), and transformer-based models have manifested their potential in representative RL benchmarks. In this paper, we collect and dissect recent advances concerning the transformation of RL with transformers (transformer-based RL (TRL)) to explore the development trajectory and future trends of this field. We group the existing developments into two categories: architecture enhancements and trajectory optimizations, and examine the main applications of TRL in robotic manipulation, text-based games (TBGs), navigation, and autonomous driving. Architecture enhancement methods consider how to apply the powerful transformer structure to RL problems under the traditional RL framework, facilitating more precise modeling of agents and environments compared to traditional deep RL techniques. However, these methods are still limited by the inherent defects of traditional RL algorithms, such as bootstrapping and the \"deadly triad\". Trajectory optimization methods treat RL problems as sequence modeling problems and train a joint state-action model over entire trajectories under the behavior cloning framework; such approaches are able to extract policies from static datasets and fully use the long-sequence modeling capabilities of transformers. Given these advancements, the limitations and challenges in TRL are reviewed and proposals regarding future research directions are discussed. We hope that this survey can provide a detailed introduction to TRL and motivate future research in this rapidly developing field.", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2022, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This survey collects and dissects recent advances concerning the transformation of RL with transformers (transformer-based RL (TRL), and examines the main applications of TRL in robotic manipulation, text-based games (TBGs), navigation, and autonomous driving."}, "embedding": {"model": "specter_v2", "vector": [0.1327904313802719, 0.544706404209137, -0.44416651129722595, 0.3625253438949585, -0.40545785427093506, -0.46620047092437744, 0.7039378881454468, -0.08856905251741409, -0.5947031378746033, 0.03199096396565437, 0.3129017949104309, -0.3781298100948334, -0.08386307954788208, -0.12409350275993347, -0.7669594883918762, -0.2219499945640564, -0.6809411644935608, 0.3215447664260864, 0.06843535602092743, -0.6181603074073792, -0.22961373627185822, -0.20412030816078186, -0.9328681826591492, -0.2427058070898056, 0.3529466688632965, 0.4218161404132843, -0.06746269762516022, 0.7783270478248596, -0.0574541799724102, 1.0219802856445312, 0.7040422558784485, -0.02417856454849243, 0.5636290907859802, 0.25000080466270447, -0.5042389035224915, -0.19821159541606903, 0.0941145047545433, -0.5377082228660583, -0.9914863109588623, 0.9263061881065369, -0.5479907393455505, 0.28994715213775635, 0.1651732474565506, -1.1724146604537964, 0.09562855958938599, 0.639078676700592, 0.6007832884788513, 0.5270761847496033, -0.1773321032524109, -0.1113094612956047, 1.3461134433746338, -0.5184703469276428, 0.26363682746887207, 1.2326014041900635, 0.4891686737537384, 0.5524448752403259, -0.2122710943222046, -0.8822418451309204, 0.9981539249420166, 0.037671465426683426, -0.16741380095481873, 0.11786007881164551, -0.09633730351924896, -0.18048639595508575, 1.2908737659454346, -0.6406154036521912, 0.6534367203712463, 0.7505177855491638, 0.22476428747177124, 1.5543770790100098, 0.22718805074691772, -0.3728393614292145, 0.11622140556573868, 0.14141009747982025, 0.06167628616094589, 1.1749829053878784, -0.3386336863040924, 0.8135212659835815, -0.8073135614395142, -0.051686208695173264, 0.4584679901599884, 0.09654513746500015, 0.002415047027170658, -0.9385489225387573, -0.13259181380271912, 0.9553219079971313, 0.48438823223114014, 0.3740546703338623, -0.44030657410621643, 1.06724214553833, 0.6009429693222046, 0.5153616666793823, -0.25632885098457336, 0.6735805869102478, 0.3513187766075134, 0.06595925986766815, -0.05220210924744606, 0.5373730659484863, -0.40006765723228455, 0.5807123780250549, -0.15722431242465973, 0.435665100812912, -0.7726259231567383, -0.13639794290065765, 1.4069465398788452, 0.13664083182811737, 0.09713026881217957, -0.9625415205955505, 0.3778711259365082, -0.40712252259254456, 0.6748148202896118, -0.32570788264274597, -0.14812345802783966, -0.23498499393463135, -0.3022672235965729, -0.5242334604263306, -0.09932827949523926, 0.35330504179000854, -0.6144952178001404, 0.9816851019859314, -0.333441823720932, -0.0008454872877337039, 0.2583563029766083, 0.3615727722644806, -0.22744496166706085, 0.5838435292243958, 0.04076087474822998, 0.0954289510846138, 0.4441511034965515, -0.7783023118972778, -0.779506504535675, -1.0049338340759277, 0.356332927942276, 0.7252601981163025, 0.4026961326599121, 0.20530661940574646, -1.0911412239074707, -0.8307510018348694, -1.0597577095031738, 0.6694177389144897, -0.4697641134262085, -0.007796980440616608, 1.0785768032073975, 0.38779735565185547, -1.0040630102157593, 0.699232816696167, -0.48205628991127014, -0.25989586114883423, 0.5239237546920776, 0.5472660660743713, 0.16113802790641785, -0.2890041172504425, -1.028001308441162, 0.6954326033592224, 0.41939815878868103, -0.42357659339904785, -1.1689461469650269, -0.2789309024810791, -1.4445593357086182, -0.15476931631565094, 0.5749146342277527, -0.3145274817943573, 1.3568706512451172, 0.1253395974636078, -1.526890754699707, 0.005339910741895437, 0.1759798228740692, -0.27440717816352844, 0.6977449655532837, -0.4476071000099182, -0.06985709071159363, -0.531586766242981, -0.19103078544139862, 0.12314029037952423, 0.36444875597953796, -0.46993449330329895, -0.719545841217041, 0.044750310480594635, 0.41502127051353455, -0.17381839454174042, -0.29912853240966797, 0.5487650632858276, 0.09514351189136505, 0.36158284544944763, -0.29146382212638855, 0.5644211769104004, -0.47571998834609985, -0.23323190212249756, -0.054189518094062805, -1.2150440216064453, 0.7024880051612854, 0.18191060423851013, 0.6186728477478027, -0.6097041368484497, -0.42787331342697144, -0.0890040248632431, 0.1718519628047943, -0.19045297801494598, -1.1171139478683472, 0.6915230751037598, -0.4512389004230499, -0.1458449363708496, 0.12787504494190216, -0.6826208233833313, 0.13476860523223877, 0.1472424417734146, -0.8833642601966858, 0.2981083393096924, -0.07038675993680954, 0.9623801112174988, -1.512704610824585, 0.3269229531288147, 0.455435186624527, -0.36835920810699463, -0.874008297920227, 1.4511500597000122, -0.3595965802669525, 0.40669694542884827, -0.5460237264633179, -0.56514972448349, -0.07408910244703293, -0.17239345610141754, 0.7171756029129028, -0.264822393655777, -0.10802216827869415, 0.49924516677856445, -0.17976167798042297, 1.30170738697052, -0.35618749260902405, 0.3015846908092499, -0.12860101461410522, -0.9684180021286011, 0.26995864510536194, 0.364900678396225, 0.2419479787349701, -0.5181881785392761, 0.4466760456562042, -0.10373622924089432, -0.517586886882782, -0.0029641170985996723, 0.42744460701942444, 0.6651222109794617, -0.37975627183914185, 0.44231781363487244, 0.6105427742004395, -0.37413856387138367, 0.6457206606864929, 0.36266520619392395, 1.1055214405059814, 0.909311830997467, 0.28951695561408997, 0.3700287938117981, 0.056415580213069916, -0.6273015737533569, 0.2656998336315155, 0.6389175057411194, 0.3274291157722473, 0.24757800996303558, 0.3391501009464264, -1.1093162298202515, -0.35951635241508484, -0.4934864640235901, 1.1266756057739258, 1.1911282539367676, -0.05122621729969978, -0.62419593334198, -0.7431850433349609, -0.9050721526145935, -0.30850619077682495, 0.4632376730442047, -0.8058290481567383, -0.5827465653419495, -0.6494247913360596, -0.9218523502349854, 0.9197531342506409, 0.4829789698123932, 1.0645328760147095, -0.6292385458946228, -0.3387127220630646, -0.18434464931488037, 0.10980606824159622, -0.781018078327179, -0.20685094594955444, 0.3345208168029785, -0.3375706970691681, -0.5622717142105103, 0.2089041918516159, 0.12472819536924362, 0.18194831907749176, -0.7299870252609253, 0.38977548480033875, -0.7468769550323486, 0.08819835633039474, 0.39575687050819397, 0.6273733973503113, -0.7487755417823792, -0.914898693561554, -0.011676892638206482, 0.33575376868247986, -0.26967155933380127, -0.2138286679983139, 0.45148995518684387, 0.5319567322731018, -0.097755566239357, -0.17396315932273865, -0.05975273624062538, 0.15319588780403137, 0.27340608835220337, 0.19418802857398987, -0.39556705951690674, -0.017705688253045082, -0.8353762030601501, 1.4541893005371094, 0.4839586913585663, -0.9928345084190369, 0.4604257643222809, -0.8331698775291443, 0.047193869948387146, 0.6609311699867249, -0.661569356918335, 0.0012490885565057397, -0.6384261846542358, 0.28521886467933655, -0.7268481254577637, -0.14789336919784546, -0.08954635262489319, 0.5023137331008911, 0.15599477291107178, 0.289926677942276, 0.9053298830986023, 0.6898613572120667, 0.15033148229122162, 0.8391320705413818, -0.9905416369438171, 0.29996269941329956, 0.04167785868048668, 0.49000218510627747, -0.24227537214756012, -0.18176943063735962, -0.2370847910642624, -0.6640099883079529, 0.01405659131705761, 0.15916918218135834, -0.7769624590873718, 0.00906500406563282, -0.1896923929452896, -1.5742530822753906, -0.0331454873085022, -0.6981230974197388, -0.5782108306884766, -0.35461828112602234, -0.2725062072277069, -0.78611159324646, -1.1077066659927368, -1.0655908584594727, -0.8035818338394165, -0.10031992197036743, -1.3878533840179443, -0.11421935260295868, 0.07959996163845062, -0.17604781687259674, -0.40003570914268494, 0.5787543654441833, -0.07531733065843582, 0.6863269805908203, -0.7245987057685852, 0.768275797367096, 0.1435067355632782, -0.2990473806858063, 0.09803050756454468, 0.5828046798706055, 0.35115981101989746, 0.06909096240997314, -0.08759645372629166, -0.5318902134895325, -0.23600497841835022, -0.6271259784698486, -0.8742583990097046, -0.294473797082901, 0.09527331590652466, 0.7105879187583923, -0.0971434935927391, -0.49185118079185486, 0.16487008333206177, 1.1035652160644531, 0.06740123778581619, 0.11822762340307236, 0.8748872876167297, 0.8996214270591736, 0.3212305009365082, 0.40066567063331604, 0.3713968098163605, 0.5531301498413086, 0.4724731147289276, 0.5681266784667969, 0.007537664845585823, 0.28081345558166504, -1.100911021232605, 0.7796656489372253, 0.6508373618125916, 0.12732826173305511, 0.14810334146022797, -0.810869574546814, 0.4471401572227478, -1.7163323163986206, -0.7806702256202698, 1.2277926206588745, 0.5700104236602783, 0.25988492369651794, -0.41999122500419617, 0.09303707629442215, 0.051163192838430405, 0.3332299590110779, 0.4032117426395416, -0.5056561827659607, -0.4490726590156555, 0.5687483549118042, 0.2509846091270447, 0.24020636081695557, 0.8713377118110657, -0.4337216019630432, 0.7255985736846924, 14.728519439697266, 0.9926995635032654, -0.08543410152196884, 0.3758034408092499, 0.12217620760202408, 0.3986258804798126, -0.19285912811756134, -0.27651411294937134, -0.9513577222824097, -0.3862704634666443, 0.908935546875, 0.14043864607810974, 1.137887716293335, 0.15331362187862396, 0.21407735347747803, 0.09510669857263565, -0.46841058135032654, 0.5746573805809021, 0.2450035661458969, -1.2207783460617065, 0.5550900101661682, 0.2640478014945984, -0.1810753494501114, 0.5709317922592163, 0.9723049402236938, 0.9567142128944397, 1.255716323852539, -0.5760698318481445, 1.1293706893920898, -0.10923053324222565, 0.9023324847221375, -0.26015806198120117, 0.3026450276374817, 0.8120262026786804, -1.049330234527588, -0.6558732986450195, -0.2045941799879074, -1.0094060897827148, 0.16896788775920868, -0.7539371848106384, -0.6087915897369385, -0.2160821408033371, -0.08077706396579742, 1.2234927415847778, 0.5017142295837402, -0.0018371264450252056, -0.7088831067085266, 0.42351850867271423, -0.2408509999513626, -0.1580691635608673, 0.5249134302139282, 0.006998973898589611, 0.09573796391487122, -0.7255819439888, -0.08724433183670044, -0.0633803978562355, 0.24805594980716705, 0.39966610074043274, -0.07387682050466537, -0.6088137626647949, -0.9518558979034424, -0.20507778227329254, -0.10353950411081314, 0.6901671886444092, 0.6482958793640137, 0.6128682494163513, 0.16270732879638672, -0.33270207047462463, 0.8805162906646729, 0.10489536821842194, -0.47109830379486084, 0.14641055464744568, 0.7262759804725647, -0.4144611656665802, -0.2157660722732544, 0.5927116274833679, -0.03954217582941055, -0.48616039752960205, -1.0266647338867188, -0.7686475515365601, 0.05910061299800873, -0.63265061378479, -0.3168357312679291, 1.043312430381775, -0.10293512046337128, -0.8974640965461731, 0.16824224591255188, -0.5589169263839722, 0.06175735220313072, -0.2026936560869217, -1.2195957899093628, -0.8789001703262329, 0.2827707529067993, 0.25708428025245667, -0.5408846139907837, -0.25432369112968445, 0.9762526154518127, -0.10898247361183167, -0.3684714436531067, -0.1542271077632904, 0.08755720406770706, 0.09357373416423798, -0.600983738899231, -0.8841850757598877, 0.6200143098831177, 0.10605373233556747, 0.03388383984565735, 0.048994626849889755, 0.32188084721565247, 0.25835809111595154, -0.6000639200210571, -0.23953883349895477, -0.2644687592983246, -0.9846150875091553, -0.09790539741516113, -0.9556009769439697, -0.5184613466262817, 0.760115385055542, 0.4021310806274414, -0.3264951705932617, -0.17941585183143616, -0.15869784355163574, -0.39889785647392273, -0.49253034591674805, -0.8573361039161682, 0.43863674998283386, 0.48408281803131104, -0.5102313160896301, -0.5107365846633911, -0.47781771421432495, 0.19821150600910187, -1.0676158666610718, -0.1650356650352478, -0.2615373432636261, 0.38040030002593994, 0.008892348036170006, 1.0699090957641602, -0.7330225706100464, 0.1996389925479889, 0.46499133110046387, 0.3306194245815277, -1.116018295288086, -0.3779045641422272, -0.9575596451759338, 0.6437293887138367, -0.0315706767141819, 0.434509813785553, -0.9054600596427917, 0.7230244278907776, 0.46722471714019775, 0.5097332000732422, -0.21785405278205872, -0.724354088306427, -0.2755417823791504, 0.1572815477848053, -0.5993385314941406, 0.3834914565086365, -0.4671386480331421, -0.0009393433574587107, 0.06624998897314072, 0.09234916418790817, 0.6081260442733765, 0.04027609899640083, -0.7372217178344727, 0.4729737937450409, 0.33745598793029785, 0.10162606835365295, -0.39828160405158997, -0.2724612057209015, -1.3840447664260864, 0.04654340073466301, -1.088424563407898, 0.5255924463272095, -1.1468124389648438, -0.6549153923988342, -0.08211368322372437, -0.2826082408428192, 0.34968289732933044, 0.747105062007904, -1.0357357263565063, 0.04006943106651306, -0.7310650944709778, -0.8461432456970215, 1.2698841094970703, 0.9973757266998291, -1.0408083200454712, 0.22829169034957886, 0.07497043162584305, 0.2751785218715668, 0.4223881661891937, 0.5743734836578369, -0.6860496997833252, -1.1810353994369507, -0.7461050152778625, 0.47465550899505615, 0.1215505599975586, -0.2623586356639862, -0.770628035068512, 0.5342722535133362, -0.19416378438472748, -0.2769528925418854, 0.33373576402664185, 0.6738222241401672, -1.2596776485443115, -0.4091993272304535, 0.6402360796928406, -0.9880690574645996, 0.27008992433547974, 0.2834542691707611, -0.24408593773841858, -0.11337988823652267, 0.7948086857795715, 0.15858256816864014, -1.0242661237716675, -0.5041890144348145, 0.5304965972900391, -1.3067787885665894, 0.12163607031106949, 0.3636360764503479, -0.22038748860359192, -1.019582748413086, -0.4431891143321991, -0.0176383126527071, 0.7428789138793945, -0.2985294759273529, 0.9643132090568542, 0.7862197160720825, -1.0547951459884644, 0.2283601313829422, 0.24771733582019806, -0.03291475027799606, -0.10320073366165161, 0.0675109475851059, 0.24545012414455414, -0.26608195900917053, 0.30161362886428833, -0.42610591650009155, 0.588689923286438, -0.709205150604248, 0.09161730855703354, 1.3020379543304443, -1.1296663284301758, -0.15274998545646667, 0.8042712807655334, -0.20339439809322357, -1.642275333404541, 0.4690304696559906, -1.1025108098983765, -1.105519413948059, -0.734423041343689, 0.4949582517147064, 0.16694900393486023, -0.6763561964035034, 0.41191431879997253, -0.4270785450935364, 0.5036552548408508, -0.2013840228319168, -0.5907272696495056, 0.6774579286575317, 0.021719055250287056, -0.15091635286808014, 0.5358438491821289, 0.016017816960811615, -0.752291202545166, -1.268319845199585, -0.38647374510765076, -0.5021361708641052, -0.24945108592510223, -0.04580321162939072, -0.3867701590061188, -0.7640154361724854, 0.8571708798408508, 0.6636977195739746, 0.11894518882036209, 0.011708472855389118, -0.10564292967319489, -0.1942662000656128, 0.6598070859909058, 0.7936041355133057, -0.5029947757720947, -0.03137344494462013, 1.2637873888015747, 1.4137239456176758, -0.47948747873306274, 0.18805301189422607, -0.14076410233974457, -0.6355863213539124, 0.8633222579956055, 0.7392430901527405, -0.49456197023391724, 0.6048306822776794, 0.07159510999917984, 0.14522886276245117, 0.07135854661464691, -0.9773305654525757, -0.19308577477931976, 0.18792657554149628, 1.6180363893508911, -0.12924255430698395, 0.20760267972946167, 0.6094328165054321, 0.7248873114585876, 0.34725508093833923, 0.6645236015319824, 0.7876487374305725, 0.7687324285507202, -0.017160041257739067, -0.23401792347431183, 0.15990838408470154, 0.4517451226711273, -0.36989274621009827, -0.06895608454942703, 0.18617233633995056, 0.7421573400497437, -0.009725186042487621, 0.45171868801116943, 0.4807402491569519, -0.41192826628685, 0.7598521709442139, -0.5333124995231628, 0.8191637992858887, -0.28161731362342834, -0.4317057430744171, -0.41126927733421326, -0.5874064564704895, -0.5774925351142883, -0.18041692674160004, -0.6832009553909302, -0.38546422123908997, -0.18493042886257172, 0.5136605501174927, 0.5840643644332886, -0.3304525911808014, 0.9594201445579529, 0.1143970862030983, 0.58663409948349, -0.29455268383026123, -0.4493175148963928, -0.8963302373886108, -0.7567382454872131, 0.07602406293153763, -0.8573577404022217, 0.06291335821151733, -0.681625485420227, -0.12763723731040955, -0.562929630279541]}, "authors": [{"authorId": "2176837980", "name": "Shengchao Hu"}, {"authorId": "2144035454", "name": "Li Shen"}, {"authorId": "2910574", "name": "Ya Zhang"}, {"authorId": "2223152252", "name": "Yixin Chen"}, {"authorId": "2135519749", "name": "Dacheng Tao"}], "references": [{"paperId": "00852625e613dc68e573fe54e4be47ae4255e5e2", "title": "Offline Pre-trained Multi-agent Decision Transformer"}, {"paperId": "3cbdcec97acef3cb32f9759eb3b49ee6dafd9892", "title": "Transformer in Transformer as Backbone for Deep Reinforcement Learning"}, {"paperId": "5412a55e4d2ee2169cb23b186a43d98b927fd485", "title": "How Crucial is Transformer in Decision Transformer?"}, {"paperId": "0703c5c7f737574d708babf48cdc876271415802", "title": "Masked Autoencoding for Scalable and Generalizable Decision Making"}, {"paperId": "78f1ca609cd6f789749365c2870e2c2efd8f1fdf", "title": "UniMASK: Unified Inference in Sequential Decision Problems"}, {"paperId": "160821fa1cfd66f90d145f144e0b81e3e62fbcb5", "title": "On the Effect of Pre-training for Transformer in Different Modality on Offline Reinforcement Learning"}, {"paperId": "2b915e1fc2f5551ac1f0f3278a7a7f898c5bae09", "title": "Learning to Follow Instructions in Text-Based Games"}, {"paperId": "860bc4f071f35d6d8529a52c2c1858d030779a6a", "title": "In-context Reinforcement Learning with Algorithm Distillation"}, {"paperId": "c0ca3ec9cf42c067a0123990137f6ee57980ab85", "title": "AVLEN: Audio-Visual-Language Embodied Navigation in 3D Environments"}, {"paperId": "60c8d0619481eaafdd1189af610d0e636271fed5", "title": "Perceiver-Actor: A Multi-Task Transformer for Robotic Manipulation"}, {"paperId": "682649e54113007724168c3920efe9a919f2d3d8", "title": "Instruction-driven history-aware policies for robotic manipulations"}, {"paperId": "fbb15aa7303586d25dc73f84c23f9b5447b0c06b", "title": "Q-learning Decision Transformer: Leveraging Dynamic Programming for Conditional Sequence Modelling in Offline RL"}, {"paperId": "235303a8bc1e4892efd525a38ead657422d8a519", "title": "Transformers are Sample Efficient World Models"}, {"paperId": "97e6b89f8f256289b01b9f31799d957db81f2d4e", "title": "LATTE: LAnguage Trajectory TransformEr"}, {"paperId": "a3335ad0d5e4061edda2b66567e517022642ea96", "title": "Safety-Enhanced Autonomous Driving Using Interpretable Sensor Fusion Transformer"}, {"paperId": "7b604cd12bfd735f16d2097357b3d6ca584d53a1", "title": "Addressing Optimism Bias in Sequence Modeling for Reinforcement Learning"}, {"paperId": "6caa7cce613702a2b204642e2324c61598921e56", "title": "ST-P3: End-to-end Vision-based Autonomous Driving via Spatial-Temporal Feature Learning"}, {"paperId": "c2366e759a97c2b21e9fc35c5e2f6b377eca38ab", "title": "Transformers are Adaptable Task Planners"}, {"paperId": "15cbccf71d1cd3f886ae9b0f3cc001d14577d264", "title": "Prompting Decision Transformer for Few-Shot Policy Generalization"}, {"paperId": "a94aaf192fc1d46d697e4d7eb3e999021ec88b46", "title": "Phasic Self-Imitative Reduction for Sparse-Reward Goal-Conditioned Reinforcement Learning"}, {"paperId": "01d4cc6e7c89f42ad1fc27b57439c9b6c2797fb8", "title": "Behavior Transformers: Cloning k modes with one stone"}, {"paperId": "32c9b3859086d15184989454eb878638659e64c6", "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge"}, {"paperId": "b7d27c5af2d314f6ec45b6d88984fb45220eb379", "title": "Bootstrapped Transformer for Offline Reinforcement Learning"}, {"paperId": "e1e9a7d86fec57148d7eb4029ed0ce42ab7224fe", "title": "AnyMorph: Learning Transferable Polices By Inferring Agent Morphology"}, {"paperId": "511e6559df79b5b7cc3fa69ae31ef1c3badce048", "title": "When does return-conditioned supervised learning work for offline reinforcement learning?"}, {"paperId": "3cadc8dfbeda7cc79dc83855b76a17eebda3ddcc", "title": "You Can't Count on Luck: Why Decision Transformers Fail in Stochastic Environments"}, {"paperId": "1be5064847c7a5e9a7e516e4c21aa8f4f8ab2eb5", "title": "Multi-Game Decision Transformers"}, {"paperId": "fe26607ca95c0d1d9005810b4ad12845ee69e9cf", "title": "Multi-Agent Reinforcement Learning is a Sequence Modeling Problem"}, {"paperId": "5922f437512158970c417f4413bface021df5f78", "title": "A Generalist Agent"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "56bc06be82c087348e638506174fa99956ef666c", "title": "Towards Flexible Inference in Sequential Decision Problems via Bidirectional Transformers"}, {"paperId": "a58b3f2ab75fdbda082e684d027ab4f552b0b5d3", "title": "Correcting Robot Plans with Natural Language Feedback"}, {"paperId": "4a3553941825e7c46eb052e7c3c9fc3e6de895b1", "title": "Reshaping Robot Trajectories Using Natural Language Commands: A Study of Multi-Modal Data Alignment Using Transformers"}, {"paperId": "96ba2f6c3c7b090cfd5c16e0840d3ae3d88cad83", "title": "Switch Trajectory Transformer with Distributional Value Approximation for Multi-Task Reinforcement Learning"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "61e7a3d5606043594a8ce377870479f77a6b58c2", "title": "A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems"}, {"paperId": "2fec20377bc947ec1df003b4aedcb4d7f25ac934", "title": "TransDreamer: Reinforcement Learning with Transformer World Models"}, {"paperId": "eb92a453cf982126fa2125d4c8915352a52af54d", "title": "Online Decision Transformer"}, {"paperId": "1d803f07e4591bd67c358eef715bcd443e821894", "title": "BC-Z: Zero-Shot Task Generalization with Robotic Imitation Learning"}, {"paperId": "b9b220b485d2add79118ffdc2aaa148b67fa53ef", "title": "Pre-Trained Language Models for Interactive Decision-Making"}, {"paperId": "266cc7ff4856b6a2ce9cc0a3e5f6c155ecc448a2", "title": "Can Wikipedia Help Offline Reinforcement Learning?"}, {"paperId": "2b3ee35b370e9b08ec11cbf681b20540d4b0f8bf", "title": "Look Closer: Bridging Egocentric and Third-Person Views With Transformers for Robotic Manipulation"}, {"paperId": "47d9133629a7dee1664483944547658e8cea83f2", "title": "Diaformer: Automatic Diagnosis via Symptoms Sequence Generation"}, {"paperId": "27eba26d43b43a31fcbc5138fe88131362000ed5", "title": "Learning Generalizable Vision-Tactile Robotic Grasping Strategy for Deformable Objects via Transformer"}, {"paperId": "387a17823d7c47c0bd3390a124708933032989e0", "title": "Generalized Decision Transformer for Offline Hindsight Information Matching"}, {"paperId": "3b3d7adb9047d01af6dfa2975ad8addd69715e96", "title": "Mastering Atari Games with Limited Data"}, {"paperId": "f9a8aa74110c0100e023406c4c48dce8a1ac4cdc", "title": "Transfer learning with causal counterfactual reasoning in Decision Transformers"}, {"paperId": "fd399c7068512858b27535f75c8c31d2442dbaac", "title": "Towards More Generalizable One-shot Visual Imitation Learning"}, {"paperId": "6f681faaa985ed38bc9b30777d57d9e1e3765861", "title": "History Aware Multimodal Transformer for Vision-and-Language Navigation"}, {"paperId": "5a4d66d6383c3132cbd07dd3fa4ec4f9c74bdd70", "title": "Measuring the Non-Transitivity in Chess"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "3b03753bff6d934c6d403d1039ecaca0c98e9a69", "title": "StARformer: Transformer with State-Action-Reward Representations for Visual Reinforcement Learning"}, {"paperId": "348a855fe01f3f4273bf0ecf851ca688686dbfcc", "title": "Offline Reinforcement Learning with Implicit Q-Learning"}, {"paperId": "d0114ee6700df40f8e49c25176a3719a8d9434eb", "title": "An Offline Deep Reinforcement Learning for Maintenance Decision-Making"}, {"paperId": "69ee9b3a915951cc84b74599a3a2699a66d4004f", "title": "CLIPort: What and Where Pathways for Robotic Manipulation"}, {"paperId": "27302766f8d0eb6c052eb400e234c5be0e7a767e", "title": "Trust Region Policy Optimisation in Multi-Agent Reinforcement Learning"}, {"paperId": "d6a1e9699d4e3571ab1eb74ab9eaba75095b809c", "title": "PlaTe: Visually-Grounded Planning With Transformers in Procedural Tasks"}, {"paperId": "9c8e0d514f9cc0991371f0e796ae2971163fccb8", "title": "NEAT: Neural Attention Fields for End-to-End Autonomous Driving"}, {"paperId": "15cdd86ff69bb5c0d89f9bd066874530f8ab0c0d", "title": "The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "2b605238c599259159bf006d8c64fb9af57cfd23", "title": "Settling the Variance of Multi-Agent Policy Gradients"}, {"paperId": "010ac9acd45c0073e79130e855aad3b65c51a5e1", "title": "End-to-End Urban Driving by Imitating a Reinforcement Learning Coach"}, {"paperId": "05c01bb3f9c1ab23ff56f8e4b53f89300298b82b", "title": "Transformer-based deep imitation learning for dual-arm robot manipulation"}, {"paperId": "9933a5af7895354087baf6c96b64dc8a8973eaed", "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs"}, {"paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"}, {"paperId": "83906fb0cae96d01385f1fd6469bad3da8fc91fd", "title": "Reinforcement Learning for Education: Opportunities and Challenges"}, {"paperId": "f908112125aaf7505237737b2f08e40dbdd9a110", "title": "CoBERL: Contrastive BERT for Reinforcement Learning"}, {"paperId": "065dc8e953d5e5da138c33a8c3f4f7181b19cd54", "title": "Learning Vision-Guided Quadrupedal Locomotion End-to-End with Cross-Modal Transformers"}, {"paperId": "806aac1f7bf886988ea2bce8461f45a09db575b6", "title": "Scene Transformer: A unified architecture for predicting multiple agent trajectories"}, {"paperId": "86589b6286ef3c55b8b4fccfb41a3b30b7afdf61", "title": "Going Beyond Linear Transformers with Recurrent Fast Weight Programmers"}, {"paperId": "db6965ab7ae91e7c81d5dc606861159f83bfd3a4", "title": "Vector Quantized Models for Planning"}, {"paperId": "f864d4d2267abba15eb43db54f58286aef78292b", "title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem"}, {"paperId": "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500", "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling"}, {"paperId": "0d1d2b3d455429147e8cd0003c85f77dff4d74b5", "title": "Predicting Vehicles Trajectories in Urban Scenarios with Transformer Networks and Augmented Information"}, {"paperId": "25ddddbd0bd1cfebf1548b2ee91bb1bbd05fdff1", "title": "Episodic Transformer for Vision-and-Language Navigation"}, {"paperId": "ea02c7bde9c64e7cd643e96db648f0b1171f5e6c", "title": "Augmenting Sequential Recommendation with Pseudo-Prior Items via Reversely Pre-training Transformer"}, {"paperId": "e0642272d01afd867c090c7beddd37218616fcfd", "title": "Reinforcement learning in robotic applications: a comprehensive survey"}, {"paperId": "c0559fc7e7d6ea0f783ba791ddd5deaa74cf58a9", "title": "Multi-Modal Fusion Transformer for End-to-End Autonomous Driving"}, {"paperId": "dfea422a6e4a251a0404eacd7929ed234adf9ba0", "title": "Imperfect also Deserves Reward: Multi-Level and Sequential Reward Modeling for Better Dialog Management"}, {"paperId": "cd37fee4da0d4483322d6fa3cc67af9ed8c07be6", "title": "Efficient Transformers in Reinforcement Learning using Actor-Learner Distillation"}, {"paperId": "b6382a7351c0c595f91472ac71d3b2d87b3c4844", "title": "ViViT: A Video Vision Transformer"}, {"paperId": "44121878a5f390f178e241310a65afef1ccac33c", "title": "AgentFormer: Agent-Aware Transformers for Socio-Temporal Multi-Agent Forecasting"}, {"paperId": "f936302f7ab29313db752b7b6275d5bdff8a9191", "title": "The interplay of a conversational ontology and AI planning for health dialogue management"}, {"paperId": "22ad3545d78f2acfe7de1b2c38ec72efc9faa0d6", "title": "Multimodal Motion Prediction with Stacked Transformers"}, {"paperId": "3a315c81a98851f0614c09fef6a14c30d6a1e63c", "title": "The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "0c9ea8f25c4f29a28e1c04c0c7121b22b6daa3bf", "title": "The Uncanny Similarity of Recurrence and Depth"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "245682e8b3fa76f4a3e2991b5497577af95cbb3f", "title": "COMBO: Conservative Offline Model-Based Policy Optimization"}, {"paperId": "7d79bac55be79502ab70e8fe46e92e649a6670da", "title": "Representation Matters: Offline Pretraining for Sequential Decision Making"}, {"paperId": "841f8e46c359b86ed1da7dafa3062ef9f351b5a4", "title": "NeoRL: A Near Real-World Benchmark for Offline Reinforcement Learning"}, {"paperId": "d5250c59351e5cc7ef842a3c4c89c1a62bd45180", "title": "UPDeT: Universal Multi-agent Reinforcement Learning via Policy Decoupling with Transformers"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "1941a6e2d4fd61b63d1df518a40cb47cab19c0e6", "title": "Semantic Audio-Visual Navigation"}, {"paperId": "604e0c54580a0530392f86b48a6183581a47b66d", "title": "VLN\u21bbBERT: A Recurrent Vision-and-Language BERT for Navigation"}, {"paperId": "8d0eeb8aee3ce93c9c04f0662ee058e8eefee6bf", "title": "Transformers for One-Shot Visual Imitation"}, {"paperId": "c3662e9176a7ad90020bdd025c179c5925d0b5b0", "title": "An Overview of Multi-Agent Reinforcement Learning from Game Theoretical Perspective"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "57835c5ad5424f94ee75901c3113730f3900e656", "title": "Representation Learning via Invariant Causal Mechanisms"}, {"paperId": "b44bb1762640ed72091fd5f5fdc20719a6dc24af", "title": "Mastering Atari with Discrete World Models"}, {"paperId": "cf34efc663284da131e747407ac3f389f898e471", "title": "robosuite: A Modular Simulation Framework and Benchmark for Robot Learning"}, {"paperId": "07bcda1dff9bb696ea9cbc69303eee8bd3d85bd6", "title": "GeDi: Generative Discriminator Guided Sequence Generation"}, {"paperId": "17908c7db26985704c00dd4521932f25c43dbe17", "title": "Offline Meta-Reinforcement Learning with Advantage Weighting"}, {"paperId": "82237bb3b2b359c4e0b3c3bfb79135e42cea31f5", "title": "End-to-end Contextual Perception and Prediction with Interaction Transformer"}, {"paperId": "052c100d45f949c06e8419b504e319b442cb3f0a", "title": "QPLEX: Duplex Dueling Multi-Agent Q-Learning"}, {"paperId": "47a218b3e05b12fd97b2e9fae1e545849ac192fc", "title": "BabyAI 1.1"}, {"paperId": "7c4356ec0dca6e6df0af7a882e2cd1571c8bf3dc", "title": "Data-Efficient Reinforcement Learning with Self-Predictive Representations"}, {"paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8", "title": "Generative Pretraining From Pixels"}, {"paperId": "0272b14dd471fe7b81df703af1b71d7600b77215", "title": "Accelerating Online Reinforcement Learning with Offline Datasets"}, {"paperId": "3b2ec1d8e56131d2644b1de89733262adc720716", "title": "How to Avoid Being Eaten by a Grue: Structured Exploration Strategies for Textual Worlds"}, {"paperId": "28db20a81eec74a50204686c3cf796c42a020d2e", "title": "Conservative Q-Learning for Offline Reinforcement Learning"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "dea0f1c5949f8d898b9b6ff68226a781558e413c", "title": "MOPO: Model-based Offline Policy Optimization"}, {"paperId": "309c2c5ee60e725244da09180f913cd8d4b8d4e9", "title": "MOReL : Model-Based Offline Reinforcement Learning"}, {"paperId": "5e7bc93622416f14e6948a500278bfbe58cd3890", "title": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems"}, {"paperId": "d1ac487f21829ef56c8ffdcd37ea414bce68c809", "title": "Improving Vision-and-Language Navigation with Image-Text Pairs from the Web"}, {"paperId": "e014af8ae8d7dbd3c1c908dfba334a6d2181b8e1", "title": "Task-oriented Dialogue System for Automatic Disease Diagnosis via Hierarchical Reinforcement Learning"}, {"paperId": "6568423cfaca7e24c88ea208cb0e67129e43aa9b", "title": "Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels"}, {"paperId": "a326d9f2d2d351001fece788165dbcbb524da2e4", "title": "D4RL: Datasets for Deep Data-Driven Reinforcement Learning"}, {"paperId": "3e3ccedaec21f9cb2fa6a6b11d29938bc9ca02f6", "title": "Rethinking Batch Normalization in Transformers"}, {"paperId": "85eb9d305dc5fc5cb3f1553f4595a1e3d2913a90", "title": "Deep Multi-Agent Reinforcement Learning for Decentralized Continuous Cooperative Control"}, {"paperId": "bc563a24bfab97d1737699db9c4eb5910746180b", "title": "Diverse and Admissible Trajectory Forecasting through Multimodal Context Understanding"}, {"paperId": "5f48e7be390a61846e38976df2aeade9a6502e6c", "title": "Reinforcement Learning for Clinical Decision Support in Critical Care: Comprehensive Review"}, {"paperId": "6fa25c94e41a0c90e3aabe80cf60f59ec9ff0a52", "title": "Towards Learning a Generic Agent for Vision-and-Language Navigation via Pre-Training"}, {"paperId": "55999400a3eed52ea9dd2f4b9f1b71ccb5c51238", "title": "Rewriting History with Inverse RL: Hindsight Inference for Policy Improvement"}, {"paperId": "15b91292ba80adaa87361a0e8894e47899f02f1d", "title": "Learning Dynamic Belief Graphs to Generalize on Text-Based Games"}, {"paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a", "title": "On Layer Normalization in the Transformer Architecture"}, {"paperId": "129983331ca874142a3e8eb2d93d820bdf1f9aca", "title": "Deep Reinforcement Learning for Autonomous Driving: A Survey"}, {"paperId": "7b0871c783e721bfbf9b5d16e575130a07a672cd", "title": "Generalized Hindsight for Reinforcement Learning"}, {"paperId": "028c1a07ac62bbdb681d11cacf4c7485f9aa3ef7", "title": "Graph Constrained Reinforcement Learning for Natural Language Action Spaces"}, {"paperId": "24e0cec8c71421fdb5d002a7776d2b17c5dc975b", "title": "Reward-Conditioned Policies"}, {"paperId": "21522b397f477a4a4e2253042d3c25cd03af9820", "title": "SoundSpaces: Audio-Visual Navigation in 3D Environments"}, {"paperId": "3fa432268bfdf6aa75f563a3f0e7f90e270740c5", "title": "SAM: Squeeze-and-Mimic Networks for Conditional Visual Driving Policy Learning"}, {"paperId": "7a7a7847041e7b25febb1491d65d842a6c65927e", "title": "Training Agents using Upside-Down Reinforcement Learning"}, {"paperId": "f4cf4246f3882aa6337e9c05d5675a3b8463a32e", "title": "ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks"}, {"paperId": "0cc956565c7d249d4197eeb1dbab6523c648b2c9", "title": "Dream to Control: Learning Behaviors by Latent Imagination"}, {"paperId": "8d814620a1ca77e745bc8a33b96b86148f2804fe", "title": "Leveraging Procedural Generation to Benchmark Reinforcement Learning"}, {"paperId": "42d0b94c8cf71541e5b52f45ab845b6d47dc4efe", "title": "End-to-End Model-Free Reinforcement Learning for Urban Driving Using Implicit Affordances"}, {"paperId": "0e58395ec5677ac3e6876c51cd1dba0cf299261e", "title": "Working Memory Graphs"}, {"paperId": "40922d386116975853a743b1d810c1e0f03e886a", "title": "Understanding and Improving Layer Normalization"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "add2f205338d70e10ce5e686df4a690e2851bdfc", "title": "Momentum Contrast for Unsupervised Visual Representation Learning"}, {"paperId": "1928a851f7454223803d13e7260fa5f26979ffab", "title": "Multiple Futures Prediction"}, {"paperId": "0bc855f84668b35cb65618d996d09f6e434d28c9", "title": "Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning"}, {"paperId": "703685e969fed715e13937c11d7ecc5cc7c4dfd0", "title": "Transformers without Tears: Improving the Normalization of Self-Attention"}, {"paperId": "59a916cdc943f0282908e6f3fa0360f4c5fb78d0", "title": "Stabilizing Transformers for Reinforcement Learning"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "e7bb4419a88d15fa8e52c1f4f9cfd65ed58c7379", "title": "V-MPO: On-Policy Maximum a Posteriori Policy Optimization for Discrete and Continuous Control"}, {"paperId": "a2fdfda785b3a2a0178d174daa515377c531f222", "title": "RLBench: The Robot Learning Benchmark & Learning Environment"}, {"paperId": "dfc7b58b67c31932b48586b3e23a43cc94695290", "title": "UNITER: UNiversal Image-TExt Representation Learning"}, {"paperId": "9be492858863c8c7c24be1ecb75724de5086bd8e", "title": "Behavior Regularized Offline Reinforcement Learning"}, {"paperId": "221d453c165aca6bc1a054289eb510e558a23dca", "title": "Interactive Fiction Games: A Colossal Adventure"}, {"paperId": "104f75283ae9027eb478e7984bd26b680277ce6f", "title": "Robust Navigation with Language Pretraining and Stochastic Sampling"}, {"paperId": "79bc6e1fe465aec49d7f0252f295c0ad9cdaf389", "title": "Help, Anna! Visual Navigation with Natural Multimodal Assistance via Retrospective Curiosity-Encouraging Imitation Learning"}, {"paperId": "9f4ceac35abe4b92b43128925d55e42c7f7ab702", "title": "Interactive Language Learning by Question Answering"}, {"paperId": "4aa6298b606941a282d735fa3143da293199d2ca", "title": "VL-BERT: Pre-training of Generic Visual-Linguistic Representations"}, {"paperId": "79c93274429d6355959f1e4374c2147bb81ea649", "title": "LXMERT: Learning Cross-Modality Encoder Representations from Transformers"}, {"paperId": "2bc1c8bd00bbf7401afcb5460277840fd8bab029", "title": "Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training"}, {"paperId": "65a9c7b0800c86a196bc14e7621ff895cc6ab287", "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"}, {"paperId": "abb0460b839a7cae30245c9690d54462f8275e47", "title": "Google Research Football: A Novel Reinforcement Learning Environment"}, {"paperId": "4012d4ab621f3f5f04b0f91849a60c6eaabe64b4", "title": "An Optimistic Perspective on Offline Reinforcement Learning"}, {"paperId": "1b9ce27801c077433245ad0f9e43e3c38441cecd", "title": "Vision-and-Dialog Navigation"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "b668ba0900ddcdacd0a07ff9983172f525c3c4d6", "title": "Goal-conditioned Imitation Learning"}, {"paperId": "9508e13a39475c23765360e75401f045b064e93e", "title": "PRECOG: PREdiction Conditioned on Goals in Visual Multi-Agent Settings"}, {"paperId": "1bdd8f6d3900e6e7fe492ea21fcdd87f3d8c857f", "title": "REVERIE: Remote Embodied Visual Referring Expression in Real Indoor Environments"}, {"paperId": "fcfc344628c7604232804317eb90db268dfc85e8", "title": "Exploring the Limitations of Behavior Cloning for Autonomous Driving"}, {"paperId": "e3d5a020ae3e8c16c4e321878984898db800ee1a", "title": "Remaining Useful Life Estimation Using Functional Data Analysis"}, {"paperId": "74b327b9f58c6bcc49114dafe95441e992ce2593", "title": "Holistic Reinforcement Learning: The Role of Structure and Attention"}, {"paperId": "505e3315b7c5d4094c3160d00956a7d1596c0956", "title": "Scene Memory Transformer for Embodied Agents in Long-Horizon Tasks"}, {"paperId": "1fd4694e7c2d9c872a427d50e81b5475056de6bc", "title": "Model-Based Reinforcement Learning for Atari"}, {"paperId": "f7c455cc5a40d2a31b63ac2657c9d2d6c53b1be5", "title": "Learning to Speak and Act in a Fantasy Text Adventure Game"}, {"paperId": "d35f9c78fc6d656d530aac2ed9f2aae6137b9041", "title": "Preferences Implicit in the State of the World"}, {"paperId": "82055eed2ba0d7156a54c586249742c848e5d565", "title": "The StarCraft Multi-Agent Challenge"}, {"paperId": "e14fdf566f9fe9e605e047e8688c75ad4277bc17", "title": "End-to-End Knowledge-Routed Relational Dialogue System for Automatic Diagnosis"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "12c0751b4f51ed833172a713b7e32390032ead93", "title": "Soft Actor-Critic Algorithms and Applications"}, {"paperId": "03fdf3abf8d6bb3ff35dc87742ad66722997caeb", "title": "Vision-Based Navigation With Language-Based Assistance via Imitation Learning With Indirect Intervention"}, {"paperId": "5285cb8faada5de8a92a47622950f6cfd476ac1d", "title": "Off-Policy Deep Reinforcement Learning without Exploration"}, {"paperId": "f3caa43a7016fbbf309d45112b31b20230eaf8da", "title": "Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning"}, {"paperId": "f75f0750a00f6f85107985c70eca9c275b5e0962", "title": "TOUCHDOWN: Natural Language Navigation and Spatial Reasoning in Visual Street Environments"}, {"paperId": "8ede7ddf99986d69562455bc8d69222fc3e27350", "title": "Recurrent Experience Replay in Distributed Reinforcement Learning"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "b227f3e4c0dc96e5ac5426b85485a70f2175a205", "title": "Representation Learning with Contrastive Predictive Coding"}, {"paperId": "3b821dbfa024027d8c009d8854c958c0e470837a", "title": "Task-oriented Dialogue System for Automatic Diagnosis"}, {"paperId": "89daae27e7df4a418b9610d307ce3df0e30fc8a2", "title": "TextWorld: A Learning Environment for Text-based Games"}, {"paperId": "6201fdf649a54892cce3786dc88ad0d074661243", "title": "Playing Atari with Six Neurons"}, {"paperId": "7139a5f730652abbeabf9e140009907d2c7da3e5", "title": "VirtualHome: Simulating Household Activities Via Programs"}, {"paperId": "6ecc4b1ab05f3ec12484a0ea36abfd6271c5c5ba", "title": "Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review"}, {"paperId": "9a8e6feb271bf1cce8b1393cf41e70692a7f6625", "title": "Verifiable Reinforcement Learning via Policy Extraction"}, {"paperId": "ffc211476f2e40e79466ffc198c919a97da3bb76", "title": "QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning"}, {"paperId": "ff332c21562c87cab5891d495b7d0956f2d9228b", "title": "World Models"}, {"paperId": "b79e5e4622a95417deec313cd543617b19611bea", "title": "Deep Learning using Rectified Linear Units (ReLU)"}, {"paperId": "368131eaf906d7b29517066e1b2759a44c8105d4", "title": "Look Before You Leap: Bridging Model-Free and Model-Based Reinforcement Learning for Planned-Ahead Vision-and-Language Navigation"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "8c1b00128e74f1cd92aede3959690615695d5101", "title": "QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension"}, {"paperId": "80196cdfcd0c6ce2953bf65a7f019971e2026386", "title": "IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures"}, {"paperId": "f4eff7c0127a2ef92c441f028c3bb15b64cabcc8", "title": "One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning"}, {"paperId": "a9a3ed69c94a3e1c08ef1f833d9199f57736238b", "title": "DeepMind Control Suite"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "c37c23b12e00168833eccff8025a830ce27c5abc", "title": "Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments"}, {"paperId": "ebf0615fc4d98cf1dbe527c79146ce1e50dce9af", "title": "CARLA: An Open Urban Driving Simulator"}, {"paperId": "0ab3f7ecbdc5a33565a234215604a6ca9d155a33", "title": "Rainbow: Combining Improvements in Deep Reinforcement Learning"}, {"paperId": "79cfb51a51fc093f66aac8e858afe2e14d4a1f20", "title": "Focal Loss for Dense Object Detection"}, {"paperId": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b", "title": "Proximal Policy Optimization Algorithms"}, {"paperId": "7e9c1e0d247b20a0683f4797d9ea248c3b53d424", "title": "A Simple Neural Attentive Meta-Learner"}, {"paperId": "e66afb33d246dbe3199fd57bcfc1b611136d96c2", "title": "Long Short-Term Memory Network for Remaining Useful Life estimation"}, {"paperId": "250bf5e1d40a619080dec553914c2905db6008c7", "title": "Value-Decomposition Networks For Cooperative Multi-Agent Learning"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0", "title": "Convolutional Sequence to Sequence Learning"}, {"paperId": "bc9f3c466c6f6b386f4ef1195853d498cf3c182e", "title": "Mapping Instructions and Visual Observations to Actions with Reinforcement Learning"}, {"paperId": "cd8a9914d50b0ac63315872530274d158d6aff09", "title": "Modeling Relational Data with Graph Convolutional Networks"}, {"paperId": "b68673a166f9c620e13152f63d358fb8fce7850d", "title": "Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability"}, {"paperId": "204a4a70428f3938d2c538a4d74c7ae0416306d8", "title": "A Structured Self-attentive Sentence Embedding"}, {"paperId": "c889d6f98e6d79b89c3a6adf8a921f88fa6ba518", "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"}, {"paperId": "2e77b99e8bd10b9e4551a780c0bde9dd10fdbe9b", "title": "PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications"}, {"paperId": "a5c68d0d01ace4a7a5f4d3e0a3fccc42a7d1f354", "title": "DeepMind Lab"}, {"paperId": "3a7b63b50c64f4ec3358477790e84cbd6be2a0b4", "title": "Bidirectional Attention Flow for Machine Comprehension"}, {"paperId": "3ed67ded2b4d3614b38798b3f17a8e69803d0980", "title": "Transfer from Simulation to Real World through Learning Deep Inverse Dynamics Model"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "2218e2e1df2c3adfb70e0def2e326a39928aacfc", "title": "Complex Embeddings for Simple Link Prediction"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "0936352b78a52bc5d2b5e3f04233efc56664af51", "title": "Conditional Image Generation with PixelCNN Decoders"}, {"paperId": "2cd8e8f510c89c7c18268e8ad51c061e459ad321", "title": "A Decomposable Attention Model for Natural Language Inference"}, {"paperId": "69e76e16740ed69f4dc55361a3d319ac2f1293dd", "title": "Asynchronous Methods for Deep Reinforcement Learning"}, {"paperId": "f88a6f6fd6611543220482e6b3a5f379b7bf5049", "title": "Increasing the Action Gap: New Operators for Reinforcement Learning"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "4c05d7caa357148f0bbd61720bdd35f0bc05eb81", "title": "Dueling Network Architectures for Deep Reinforcement Learning"}, {"paperId": "1def5d3711ebd1d86787b1ed57c91832c5ddc90b", "title": "Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning"}, {"paperId": "1c4927af526d5c28f7c2cfa492ece192d80a61d4", "title": "Policy Distillation"}, {"paperId": "3b9732bb07dc99bde5e1f9f75251c6ea5039373e", "title": "Deep Reinforcement Learning with Double Q-Learning"}, {"paperId": "024006d4c2a89f7acacc6e4438d156525b60a98f", "title": "Continuous control with deep reinforcement learning"}, {"paperId": "f5f323e62acb75f785e00b4c90ace16f1690076f", "title": "Deep Recurrent Q-Learning for Partially Observable MDPs"}, {"paperId": "e0945081b5b87187a53d4329cf77cd8bff635795", "title": "Highway Networks"}, {"paperId": "7ffdbc358b63378f07311e883dddacc9faeeaf4b", "title": "Fast R-CNN"}, {"paperId": "340f48901f72278f6bf78a04ee5b01df208cc508", "title": "Human-level control through deep reinforcement learning"}, {"paperId": "ac3ee98020251797c2b401e1389461df88e52e62", "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "2319a491378867c7049b3da055c5df60e1671158", "title": "Playing Atari with Deep Reinforcement Learning"}, {"paperId": "b354ee518bfc1ac0d8ac447eece9edb69e92eae1", "title": "MuJoCo: A physics engine for model-based control"}, {"paperId": "f82e4ff4f003581330338aaae71f60316e58dd26", "title": "The Arcade Learning Environment: An Evaluation Platform for General Agents"}, {"paperId": "abd0d4ed53a86f7af4674b838d590edff6edf9a4", "title": "Natural language processing: an introduction"}, {"paperId": "7a7a23f2c39f9b1526bc8853c6c71a5b7f89e68c", "title": "Robot trajectory optimization using approximate inference"}, {"paperId": "25fd7e9ed8d1a669c7a8d28a8b620479899e6b53", "title": "An object-oriented representation for efficient reinforcement learning"}, {"paperId": "02cc6a5944d57d2353a55639c7b77336b94f29b6", "title": "Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search"}, {"paperId": "9d59f87b881017e6ef0198636a77ad04b7ebea7a", "title": "Symbolic Dynamic Programming for First-Order MDPs"}, {"paperId": "b18833db0de9393d614d511e60821a1504fc6cd1", "title": "A Natural Policy Gradient"}, {"paperId": "a20f0ce0616def7cc9a87446c228906cd5da093b", "title": "Policy Gradient Methods for Reinforcement Learning with Function Approximation"}, {"paperId": "116d7798c1123cf7fad4176e98f58fd49de4f8f1", "title": "Planning and Acting in Partially Observable Stochastic Domains"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "bc22e87a26d020215afe91c751e5bdaddd8e4922", "title": "Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks"}, {"paperId": "8d652a1980e743c7c85ff6066409ea1e3be4d685", "title": "Efficient Training of Artificial Neural Networks for Autonomous Navigation"}, {"paperId": "1eb1583c2d2f7f075075cc54b0ef1640d2b7da4b", "title": "Probabilistic Inference and Influence Diagrams"}, {"paperId": "a2b5b7691e67fd488ec008e8e850d4403abccf8d", "title": "Spatial Localization Does Not Require the Presence of Local Cues"}, {"paperId": "07cf239db20908b18227648df28cefda640806c5", "title": "Learning Object-Oriented Dynamics for Planning from Text"}, {"paperId": "20ac9c25a3fdac1146f499d32f6389fc9af397a6", "title": "Transformer-based Working Memory for Multiagent Reinforcement Learning with Action Parsing"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "f25a69a981384a71f16d3312784e80a3a6369538", "title": "DCRAC: Deep Conditioned Recurrent Actor-Critic for Multi-Objective Partially Observable Environments"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "\u201cMinimalistic gridworld environment for openai gym,"}, {"paperId": null, "title": "Artificial intelligence a modern approach"}, {"paperId": "4c915c1eecb217c123a36dc6d3ce52d12c742614", "title": "Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning"}, {"paperId": "97efafdb4a3942ab3efba53ded7413199f79c054", "title": "Reinforcement Learning: An Introduction"}, {"paperId": "53e5d573f977bd59416b0bf870bfd4d917c9b79a", "title": "Temporal Logic of Programs"}, {"paperId": null, "title": "Speech understanding systems. summary of results of the five-year research effort at carnegie-mellon university"}, {"paperId": "777010281e4ad7feef46bcbd8c1e3fcdf467ec57", "title": "Some methods for classi cation and analysis of multivariate observations"}, {"paperId": "ac8ab51a86f1a9ae74dd0e4576d1a019f5e654ed", "title": "Some methods for classification and analysis of multivariate observations"}, {"paperId": null, "title": "TEX CLASS FILES, VOL. 14,"}]}