{"paperId": "2d88b671af49e477e3a0e85014fb853b6d3bd363", "title": "On the Validity of Self-Attention as Explanation in Transformer Models", "abstract": "Explainability of deep learning systems is a vital requirement for many applications. However, it is still an unsolved problem. Recent self-attention based models for natural language processing, such as the Transformer or BERT, offer hope of greater explainability by providing attention maps that can be directly inspected. Nevertheless, by just looking at the attention maps one often overlooks that the attention is not over words but over hidden embeddings, which themselves can be mixed representations of multiple embeddings. We investigate to what extent the implicit assumption made in many recent papers - that hidden embeddings at all layers still correspond to the underlying words - is justified. We quantify how much embeddings are mixed based on a gradient based attribution method and find that already after the first layer less than 50% of the embedding is attributed to the underlying word, declining thereafter to a median contribution of 7.5% in the last layer. While throughout the layers the underlying word remains as the one contributing most to the embedding, we argue that attention visualizations are misleading and should be treated with care when explaining the underlying deep learning system.", "venue": "arXiv.org", "year": 2019, "citationCount": 18, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "It is argued that attention visualizations are misleading and should be treated with care when explaining the underlying deep learning system."}, "embedding": {"model": "specter_v2", "vector": [-0.21310077607631683, 1.030189037322998, -0.15245676040649414, 0.06888218224048615, 0.017443284392356873, -0.055005382746458054, 0.7201493978500366, -0.19353696703910828, -0.1406850516796112, -0.26763784885406494, 0.8681954741477966, -0.15985643863677979, 0.3399348855018616, 0.00512330885976553, -0.08665812760591507, -0.1459132730960846, -0.4545625150203705, 0.29136309027671814, -0.1425194889307022, -0.41450485587120056, -0.16707268357276917, -0.9874852895736694, -0.9207636117935181, 0.04336729645729065, 0.16961629688739777, 0.17787057161331177, 0.36413612961769104, 1.0771015882492065, -0.7119089365005493, 0.4720290005207062, 0.627362847328186, -0.6711537837982178, -0.02678144909441471, 0.009055652655661106, -0.34035685658454895, -0.13736183941364288, 0.4495188593864441, -0.27865245938301086, -0.5598651170730591, 1.0037661790847778, -0.3317125737667084, -0.3217962980270386, 0.5213138461112976, -0.9694941639900208, -0.6930398344993591, 1.0496958494186401, 0.8078065514564514, 0.8947995901107788, -0.09378153830766678, -0.37001752853393555, 1.9294812679290771, -1.3075181245803833, 0.30862683057785034, 1.3536344766616821, 0.05245989188551903, 0.2987331748008728, -0.5899197459220886, -0.6693983674049377, 0.6435310244560242, 0.35938915610313416, -0.6995508074760437, -0.07814834266901016, 0.2874007821083069, -0.2725376486778259, 1.8976025581359863, -0.48356595635414124, -0.1754307746887207, 0.5032089948654175, 0.1682625263929367, 1.632387399673462, 0.5523717999458313, -0.8570095896720886, -0.4414364695549011, 0.6563149094581604, 0.8639764189720154, 0.9954326152801514, -0.2529318332672119, 0.45810848474502563, -1.007713794708252, -0.09957350790500641, 0.5316664576530457, -0.3036783039569855, -0.26768073439598083, -0.2690490484237671, -0.42513105273246765, 0.8339683413505554, 0.6804468035697937, 0.7326887249946594, -0.37201231718063354, 1.0918750762939453, 0.4771415889263153, 0.33250606060028076, 0.018565939739346504, 0.34674757719039917, 0.03969065845012665, 0.5600936412811279, -0.8014776706695557, 0.17184942960739136, 0.04740659520030022, 0.643341064453125, 0.5176867246627808, 0.49217092990875244, -0.2434629648923874, -0.05332396924495697, 1.5890289545059204, -0.005556129384785891, 1.0259506702423096, -0.49517902731895447, -0.06812859326601028, -0.6614023447036743, 0.019866282120347023, -1.1149027347564697, 0.06630469858646393, -0.46956872940063477, -0.3389451205730438, -0.8550430536270142, -0.44083794951438904, 0.2699972093105316, -0.7456694841384888, 0.9748141765594482, -0.46117815375328064, -0.3331953287124634, 0.03277858346700668, 0.5337955951690674, 0.47290343046188354, 0.39966508746147156, 0.3333503305912018, 0.6916002035140991, 1.111193299293518, -0.6847888231277466, -0.984260082244873, -1.1439260244369507, 0.4559449851512909, -0.00319293444044888, 0.44219082593917847, -0.2925718426704407, -0.8354308009147644, -1.0273969173431396, -0.8856623768806458, 0.36874625086784363, -0.5187930464744568, 0.3928908109664917, 0.8982554078102112, 0.41685980558395386, -1.0834479331970215, 0.9661365747451782, -0.33826056122779846, -0.35463401675224304, 0.21746177971363068, 0.23980678617954254, 0.08114501088857651, 0.05910684913396835, -1.3295934200286865, 0.58548903465271, 0.31546950340270996, -0.6523237824440002, -0.262576162815094, -0.37542036175727844, -1.3451290130615234, 0.0892113596200943, 0.1127825602889061, -0.5692932605743408, 1.0067819356918335, -0.245289146900177, -0.7443219423294067, 0.8622018694877625, -0.6744726300239563, 0.2282254546880722, 0.011019399389624596, -0.21425825357437134, -0.6272383332252502, -0.5007136464118958, 0.4369582533836365, 0.6314336061477661, 0.43982475996017456, -0.5213279724121094, -0.16955623030662537, -0.003801451763138175, -0.3180208206176758, -0.25667300820350647, -0.5580111145973206, 0.44820019602775574, -0.03313310071825981, -0.36917391419410706, 0.3371921479701996, 0.8651716709136963, 0.47241905331611633, -0.5191686153411865, -0.7688087821006775, -1.261201024055481, 0.5815666317939758, -0.10769573599100113, 0.664132297039032, -0.9605835676193237, -0.7871439456939697, -0.21214978396892548, 0.3155001103878021, -0.5295224785804749, -0.8094790577888489, 0.5081346035003662, -0.9996485710144043, 0.8417159914970398, -0.04223344847559929, -1.187793254852295, 0.4874247908592224, -0.1486302763223648, -0.8560757040977478, -0.3686933219432831, 0.32450658082962036, 1.0612038373947144, -0.8104501962661743, 0.05333847925066948, 0.07781779766082764, 0.29876193404197693, -0.4380805790424347, 1.2740058898925781, 0.008346880786120892, -0.43105408549308777, 0.33445218205451965, -0.4977193772792816, 0.1433313935995102, -0.19131159782409668, -0.3210722804069519, -0.5482318997383118, -0.06207936629652977, 0.701707124710083, -0.12001524120569229, 0.8672384023666382, -0.28352370858192444, 1.0296696424484253, -0.1894184648990631, -0.45359525084495544, 0.07324989885091782, 0.4078201949596405, -0.5552002787590027, -0.3435096740722656, 0.07652078568935394, 0.3184071183204651, -0.4431489408016205, 0.2007254660129547, 0.5203786492347717, 0.4542508125305176, -0.06935475766658783, 0.5742661952972412, 0.6808762550354004, -0.0775420144200325, 0.2197299301624298, 0.5340843200683594, 0.7151733636856079, 0.6416079998016357, 0.3902067244052887, -0.4570518434047699, 0.02560338005423546, -0.2767297923564911, -0.34305521845817566, 0.24929192662239075, 0.7012295722961426, 0.9262819886207581, 0.360484778881073, -0.7732133865356445, -0.12516145408153534, 0.01653813011944294, 0.7994259595870972, 1.3229660987854004, -0.24288742244243622, -0.4909170866012573, -0.6331662535667419, -0.31674957275390625, -0.392020046710968, 0.6470970511436462, -0.7301150560379028, -0.3779243230819702, -0.15701651573181152, -1.0493987798690796, 0.6328197717666626, 0.48319223523139954, 0.7764202356338501, -0.5843630433082581, -0.47671207785606384, 0.10498504340648651, 0.4513566493988037, -0.4880439043045044, -0.4760246276855469, 0.8756148219108582, -0.24075208604335785, -0.13939087092876434, -0.1913139969110489, 0.14895980060100555, -0.12039811909198761, -0.4501432478427887, 0.8514471054077148, -0.4345623552799225, -0.43767932057380676, 0.3035743236541748, 0.6994820833206177, -0.7765828371047974, -0.588194727897644, 0.14744819700717926, 0.22953791916370392, -0.32027506828308105, 0.6272409558296204, 0.7158809304237366, 0.0016249525360763073, 0.08225525915622711, -0.3974030911922455, -0.08856569975614548, 0.015572941862046719, 0.1258915662765503, 0.10481379181146622, 0.08914738148450851, -0.42329561710357666, -0.8993237614631653, 0.9402845501899719, -0.10112500190734863, 0.21674224734306335, 0.03079005517065525, -1.0829565525054932, 0.13362498581409454, 0.3282187283039093, -0.5925154089927673, 0.05377467721700668, -1.0209530591964722, 0.6376349329948425, -0.2990690767765045, -0.4193931519985199, 0.3951016962528229, 0.05322718620300293, 0.3277153968811035, 0.12550944089889526, 0.40856727957725525, 0.4313180446624756, 0.09667907655239105, 0.4804806411266327, -1.21387779712677, 0.413237065076828, 0.5899367332458496, 0.3555904030799866, -0.28264397382736206, -0.39477765560150146, -0.7570676803588867, -0.4877554774284363, -0.18116451799869537, 0.022140637040138245, -0.22813142836093903, 0.35536524653434753, -0.4043274223804474, -0.8485432863235474, -0.2756369113922119, -1.1199781894683838, -0.2218407690525055, 0.02288011647760868, -0.3716111183166504, -0.15047451853752136, -0.9887551665306091, -0.9239292740821838, -0.7687526941299438, -0.12087255716323853, -0.7671818137168884, 0.15301202237606049, -0.004845476243644953, -0.7713444232940674, -0.9752993583679199, -0.008977405726909637, -0.3042186200618744, 1.2943227291107178, -0.6285731792449951, 1.0292702913284302, -0.26387712359428406, -0.21291200816631317, -0.07194273173809052, -0.07856764644384384, 0.35613107681274414, 0.2149031162261963, 0.05615176260471344, -1.074300765991211, 0.37980806827545166, 0.15455950796604156, -0.11209643632173538, 0.36913377046585083, 0.24267899990081787, 0.27700310945510864, -0.4874110519886017, -0.5589417815208435, -0.027660442516207695, 1.7189407348632812, -1.008204460144043, 0.054532818496227264, 0.5127856731414795, 1.2850502729415894, 0.8873960971832275, -0.6142603754997253, -0.15191973745822906, 0.8895375728607178, 0.2108353078365326, 0.502535343170166, -0.43187761306762695, -0.36056360602378845, -0.8489523530006409, 0.5450013875961304, 1.3345495462417603, 0.4035987854003906, 0.054314762353897095, -1.2593250274658203, 0.9197983741760254, -1.3481967449188232, -0.6448659896850586, 0.3437511622905731, 0.41479870676994324, -0.001007664599455893, -0.4290319085121155, -0.5372224450111389, 0.1761447787284851, 0.5469517111778259, 0.10603044927120209, -0.2520151436328888, -0.5515870451927185, -0.08076339960098267, 0.42150187492370605, 0.5604395270347595, 0.975152313709259, -0.29532694816589355, 0.5701005458831787, 14.770838737487793, 0.28999000787734985, 0.014127982780337334, 0.4327450692653656, 0.6120547652244568, 0.6054025888442993, -0.746534526348114, 0.18515171110630035, -1.1171756982803345, -0.23628613352775574, 1.2546848058700562, -0.005593793001025915, 0.22546054422855377, -0.042334165424108505, -0.20500272512435913, 0.41921404004096985, -0.2704210877418518, 0.5309614539146423, 0.8813896179199219, -0.83634352684021, 0.5011688470840454, 0.46974146366119385, -0.21101465821266174, 0.35594427585601807, 0.6578401923179626, 0.5024268627166748, 0.6878931522369385, -0.4022451639175415, 0.5629114508628845, 0.11307325214147568, 0.6451237797737122, 0.06029561534523964, 0.31344184279441833, 0.46519649028778076, -0.663854718208313, -0.11066224426031113, -0.7082624435424805, -1.1282240152359009, 0.08394162356853485, 0.2924213707447052, -0.5606595277786255, -0.756019651889801, -0.1922816038131714, 0.4801103174686432, -0.24905137717723846, -0.08685500174760818, -0.40699708461761475, 0.8056281805038452, 0.07385911792516708, -0.19809994101524353, 0.40719667077064514, 1.0465998649597168, 0.7095009684562683, 0.09808515757322311, 0.24772149324417114, -0.20189596712589264, -0.18095186352729797, 0.9829216599464417, -0.0281553715467453, -0.006186320446431637, -0.2772092819213867, -0.5715413689613342, -0.59076327085495, 0.905655026435852, 0.36957409977912903, 0.23441056907176971, 0.10256876051425934, 0.5566785335540771, 0.5704867839813232, 0.30681267380714417, 0.040421079844236374, -0.4353039860725403, 0.6026660799980164, 0.21760325133800507, 0.04877489060163498, 0.5009912252426147, -0.17106246948242188, -0.408782958984375, -0.7589696645736694, 0.031864672899246216, 0.07438915967941284, -1.1614789962768555, -0.9971035718917847, 1.4272979497909546, -0.3167637288570404, -0.08158031851053238, 0.17937715351581573, -1.2841829061508179, -0.5200597643852234, 0.417939692735672, -1.5079724788665771, -0.5435830950737, -0.11316216737031937, -0.45951247215270996, -0.3855774998664856, -0.32276201248168945, 1.2511184215545654, -0.5368064045906067, -0.29895254969596863, -0.3020715117454529, -0.5018835663795471, -0.13896630704402924, -0.07346904277801514, -1.693285346031189, 0.7074535489082336, -0.08315512537956238, 0.2769019603729248, 0.5500208735466003, 0.5437014698982239, 0.16920611262321472, -0.5019669532775879, 0.2393416166305542, 1.0185272693634033, -1.1051346063613892, 0.0699121281504631, -0.5226401090621948, -0.8976814150810242, -0.13053981959819794, 1.1849732398986816, -0.501542866230011, 0.42922407388687134, 0.08375240862369537, -0.689150333404541, 0.19191625714302063, -0.48974671959877014, 0.08034925907850266, 0.10707419365644455, -0.8520171642303467, -0.7529870867729187, -0.16473528742790222, 0.08083465695381165, -0.3958267867565155, 0.1393427550792694, -0.4528084695339203, -0.13176864385604858, -0.223172128200531, 0.5076543688774109, -0.6221252083778381, 0.9793378114700317, 0.5017799139022827, -0.24877478182315826, -1.1742192506790161, -0.5359426736831665, -0.746404767036438, 0.17811135947704315, 0.6286036968231201, 0.9086357355117798, -0.5392780303955078, 0.4688889682292938, 1.3747862577438354, 0.39815396070480347, -0.1510549634695053, -0.3980523645877838, -0.20558184385299683, -0.1480916291475296, -0.46318474411964417, 0.36181992292404175, 0.2072439044713974, 0.08259283751249313, 0.47993507981300354, 0.745084285736084, 0.4276379346847534, 0.440685510635376, -0.8987748622894287, 0.053653571754693985, -0.3428381383419037, 0.1386667639017105, -0.6910460591316223, -0.6231545209884644, -1.1389801502227783, 0.3628758490085602, -1.3012853860855103, -0.034630775451660156, -1.5396513938903809, -0.5552912354469299, 0.3384034335613251, -0.5024570226669312, 0.21463973820209503, 0.06391603499650955, -0.008128714747726917, -0.5534310340881348, -0.3102458715438843, -0.14250119030475616, 0.47770413756370544, 0.46490228176116943, -0.8362404704093933, 0.3746059238910675, -0.3255685567855835, -0.681074857711792, 0.3146587908267975, 0.4630771279335022, -0.7046003937721252, -0.6341387629508972, -1.4666600227355957, 0.554794192314148, -0.42825254797935486, 0.27709314227104187, -0.36934518814086914, 0.7682379484176636, 0.7753379940986633, -0.05883205682039261, 0.28606200218200684, 0.2705554664134979, -1.1252522468566895, -0.42822667956352234, 0.3780597448348999, -0.9435839056968689, 0.5632432103157043, 0.11933118104934692, -0.2570696771144867, -0.424969881772995, 0.5552250742912292, -0.36448386311531067, -1.35958731174469, -0.517132043838501, 0.18209736049175262, -0.5624850392341614, -0.08756358921527863, -0.32172852754592896, -0.4888698160648346, -1.061409831047058, -0.39493927359580994, -0.23881472647190094, 0.3018604815006256, -0.35015055537223816, 1.0783299207687378, 0.4478816092014313, -1.344603419303894, 0.023551683872938156, 0.36412081122398376, 0.32783451676368713, -0.6860498785972595, 0.34171441197395325, -0.30678901076316833, -0.05311836302280426, 0.4595160186290741, 0.1266557276248932, 0.12844257056713104, -0.7255992293357849, -0.1309807002544403, 0.5302583575248718, -0.09414606541395187, -0.4308842420578003, 0.7724905610084534, 0.04563242197036743, -0.8211661577224731, -0.09043316543102264, -0.9886460304260254, -0.6852885484695435, -0.03846798092126846, 0.6924664974212646, 0.1327401101589203, -0.4244047701358795, -0.30829909443855286, -0.46044909954071045, 0.23295797407627106, -0.265865296125412, -0.8708395957946777, 0.43535566329956055, -0.3368428945541382, -0.31703701615333557, 0.8858556151390076, 0.8165251016616821, -0.8623439073562622, -0.6042275428771973, -0.6246495246887207, -0.3774736225605011, -0.2676973044872284, 0.6333098411560059, -0.3101540803909302, -0.4959557056427002, 1.2243529558181763, 0.7388373613357544, 0.719839870929718, -0.3700788617134094, 0.00044654050725512207, -0.09428717195987701, 0.2590540647506714, -0.12385787814855576, -0.2254207581281662, -0.5522647500038147, 1.3294793367385864, 1.2742046117782593, -0.5374683141708374, -0.040833842009305954, -0.2335924357175827, -0.8724415898323059, 1.0150753259658813, 0.3866581618785858, -0.19845689833164215, 0.9547245502471924, -0.10825683921575546, 0.4988466799259186, -0.29172050952911377, -1.2400363683700562, -0.46091562509536743, 0.8341512680053711, 1.0677233934402466, 0.9091086387634277, 0.21702837944030762, 0.4871915280818939, 0.9718775749206543, -0.4350084364414215, -0.15803664922714233, 0.8620473742485046, -0.06723413616418839, -0.28153783082962036, 0.3638787269592285, 0.16830305755138397, 0.36072033643722534, -0.5472404956817627, -0.6647023558616638, -0.19073523581027985, 0.9432867169380188, -0.06676346808671951, 0.3070003092288971, 0.5927819609642029, -0.1738816201686859, 0.3976907730102539, 0.4958041310310364, 0.1192278191447258, -0.5396558046340942, -0.2856665253639221, -0.24652309715747833, -0.7157872915267944, 0.09066881984472275, -0.349883109331131, -0.27607226371765137, -0.46942681074142456, 0.14402766525745392, -0.016609033569693565, -0.04552800580859184, 0.6123776435852051, 0.9437394142150879, 0.3381495177745819, 0.589413583278656, -0.3593766391277313, -0.30532777309417725, -0.27216535806655884, -0.9228953123092651, 0.013500487431883812, -0.7646165490150452, 0.12836229801177979, -0.4986035227775574, -0.8666728138923645, -0.40682005882263184]}, "authors": [{"authorId": "38094934", "name": "Gino Brunner"}, {"authorId": "40457423", "name": "Yang Liu"}, {"authorId": "150973452", "name": "Damian Pascual"}, {"authorId": "143944934", "name": "Oliver Richter"}, {"authorId": "1716440", "name": "Roger Wattenhofer"}], "references": [{"paperId": "1a4e8e6baa0fa0ed11cf4db92d84a7e6d8eac02a", "title": "Do Transformer Attention Heads Provide Transparency in Abstractive Summarization?"}, {"paperId": "95a251513853c6032bdecebd4b74e15795662986", "title": "What Does BERT Look at? An Analysis of BERT\u2019s Attention"}, {"paperId": "a4a2d99d1c237d0818971ec9205e89128c57fb02", "title": "Towards Interpretable Reinforcement Learning Using Attention Augmented Agents"}, {"paperId": "afd110eace912c2b273e64851c6b4df2658622eb", "title": "Visualizing and Measuring the Geometry of BERT"}, {"paperId": "165d51a547cd920e6ac55660ad5c404dcb9562ed", "title": "Open Sesame: Getting inside BERT\u2019s Linguistic Knowledge"}, {"paperId": "8e82dd83df5023df86868c59a03fd7872fb5931e", "title": "Attention Is (not) All You Need for Commonsense Reasoning"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "e2587eddd57bc4ba286d91b27c185083f16f40ee", "title": "What do you learn from context? Probing for sentence structure in contextualized word representations"}, {"paperId": "1219fe1ddb3fb19eb7e31dece3418e420fef376b", "title": "Investigating the Successes and Failures of BERT for Passage Re-Ranking"}, {"paperId": "beb051c652f02c2d5829d783fbc4f3acce99bc3c", "title": "Visualizing Attention in Transformer-Based Language Representation Models"}, {"paperId": "1e83c20def5c84efa6d4a0d80aa3159f55cb9c3f", "title": "Attention is not Explanation"}, {"paperId": "8b3b5d1138fa9ff20e9b12c0f53c22838039efff", "title": "Adding Interpretable Attention to Neural Translation Models Improves Word Alignment"}, {"paperId": "f9717d29840f4d8f1cc19d1b1e80c5d12ec40608", "title": "A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play"}, {"paperId": "537a9ca1b98c58fc77cb175e049433b700c3404a", "title": "Attending to Mathematical Language with Transformers"}, {"paperId": "49400b3a3ea01772e321e3e010b7b891c3d6cb88", "title": "Extracting Syntactic Trees from Transformer Encoder Self-Attentions"}, {"paperId": "7b8b182d0fdf4ea465a700ef9943b15eca910e49", "title": "An Analysis of Attention Mechanisms: The Case of Word Sense Disambiguation in Neural Machine Translation"}, {"paperId": "ac11062f1f368d97f4c826c317bf50dcc13fdb59", "title": "Dissecting Contextual Word Embeddings: Architecture and Representation"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "1a9977f0d02fad288ad0c9c99fa871ac88f6688c", "title": "Evaluating neural network explanation methods using hybrid documents and morphosyntactic agreement"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "0a255e716a89b787336ab956f0aa74424629c950", "title": "On the information bottleneck theory of deep learning"}, {"paperId": "744fe47157477235032f7bb3777800f9f2f45e52", "title": "Progressive Growing of GANs for Improved Quality, Stability, and Variation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "c43d954cf8133e6254499f3d68e45218067e4941", "title": "Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks"}, {"paperId": "267980e417f1d01a897e87fa409f64e2a76b96cd", "title": "Opening the Black Box of Deep Neural Networks via Information"}, {"paperId": "b5c26ab8767d046cb6e32d959fdf726aee89bb62", "title": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "340f48901f72278f6bf78a04ee5b01df208cc508", "title": "Human-level control through deep reinforcement learning"}, {"paperId": "4d8f2d14af5991d4f0d050d22216825cac3157bd", "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"}, {"paperId": "dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71", "title": "Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "eb42a490cf4f186d3383c92963817d100afd81e2", "title": "Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network"}, {"paperId": "0b44fcbeea9415d400c5f5789d6b892b6f98daff", "title": "Building a Large Annotated Corpus of English: The Penn Treebank"}, {"paperId": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27", "title": "Backpropagation Applied to Handwritten Zip Code Recognition"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "94238dead40b12735d79ed63e29ead70730261a2", "title": "An Analysis of Encoder Representations in Transformer-Based Machine Translation"}, {"paperId": "475354f10798f110d34792b6d88f31d6d5cb099e", "title": "Automatically Constructing a Corpus of Sentential Paraphrases"}]}