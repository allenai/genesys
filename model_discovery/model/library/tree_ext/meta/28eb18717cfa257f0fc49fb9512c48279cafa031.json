{"paperId": "28eb18717cfa257f0fc49fb9512c48279cafa031", "title": "Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling", "abstract": "Efficiently modeling sequences with infinite context length has been a long-standing problem. Past works suffer from either the quadratic computation complexity or the limited extrapolation ability on length generalization. In this work, we present Samba, a simple hybrid architecture that layer-wise combines Mamba, a selective State Space Model (SSM), with Sliding Window Attention (SWA). Samba selectively compresses a given sequence into recurrent hidden states while still maintaining the ability to precisely recall memories with the attention mechanism. We scale Samba up to 3.8B parameters with 3.2T training tokens and show that Samba substantially outperforms the state-of-the-art models based on pure attention or SSMs on a wide range of benchmarks. When trained on 4K length sequences, Samba can be efficiently extrapolated to 256K context length with perfect memory recall and show improved token predictions up to 1M context length. As a linear-time sequence model, Samba enjoys a 3.73x higher throughput compared to Transformers with grouped-query attention when processing user prompts of 128K length, and 3.64x speedup when generating 64K tokens with unlimited streaming. A sample implementation of Samba is publicly available in https://github.com/microsoft/Samba.", "venue": "arXiv.org", "year": 2024, "citationCount": 5, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Samba is presented, a simple hybrid architecture that layer-wise combines Mamba, a selective State Space Model (SSM), with Sliding Window Attention (SWA), which selectively compresses a given sequence into recurrent hidden states while still maintaining the ability to precisely recall memories with the attention mechanism."}, "embedding": {"model": "specter_v2", "vector": [0.5163679718971252, 0.24800491333007812, -0.5723499655723572, -0.1584429293870926, -0.19093817472457886, -0.1391296535730362, 0.7661631107330322, 0.1214713305234909, -0.46633240580558777, -0.29652824997901917, 0.43172547221183777, -0.300597220659256, 0.8802321553230286, 0.2211880087852478, -0.23259735107421875, 0.5038034915924072, -0.9970598220825195, -0.022798767313361168, 0.32404521107673645, -0.6016944050788879, 0.1257832944393158, -0.5541479587554932, -1.2311393022537231, 0.23490454256534576, 0.23678405582904816, 0.5683444142341614, 0.37147173285484314, 1.1008607149124146, -0.761951208114624, 0.5702391862869263, 0.18498171865940094, 0.356506884098053, 0.004387896507978439, -0.10129359364509583, -0.5395239591598511, -0.4487972557544708, 0.3533298671245575, -0.4810202419757843, -0.440692275762558, 0.2360115796327591, -0.28924861550331116, 0.4113663136959076, -0.010673831216990948, -0.5698294639587402, 0.19268126785755157, 0.8314916491508484, 0.8501366376876831, 0.765026867389679, -0.03731454163789749, -0.5967629551887512, 1.3351316452026367, -1.0771002769470215, 0.15502941608428955, 1.2857621908187866, 0.1087406799197197, 0.6795094609260559, 0.011315309442579746, -0.6243459582328796, 1.1734338998794556, 0.3531639575958252, -0.6890638470649719, -0.390227735042572, 0.10067842155694962, 0.1752941906452179, 2.090174674987793, 0.3094240128993988, 0.48455241322517395, 0.7053402662277222, -0.34706762433052063, 1.6661186218261719, -0.379307359457016, -1.088363528251648, 0.06328119337558746, -0.04890919849276543, 0.7992304563522339, 0.545030415058136, -0.42988064885139465, 0.01737586408853531, -1.0287501811981201, -0.1510908603668213, 0.5212934017181396, 0.20856018364429474, 0.4855964183807373, -0.05747197940945625, -0.38718342781066895, 0.5700433254241943, 0.18064652383327484, 0.9315474629402161, -0.03038383647799492, 0.4491044878959656, 0.4836815297603607, 0.1457773745059967, -0.10664130747318268, 0.4121387004852295, -0.041191138327121735, 0.09634572267532349, -1.096185564994812, 0.4420943558216095, -0.2814878225326538, 1.1705691814422607, -0.4661615788936615, 0.4652356207370758, -0.8536338210105896, 0.17091107368469238, 1.0401768684387207, 0.14542770385742188, 0.4565644860267639, -0.6663267016410828, 0.2458306849002838, -0.613877534866333, 0.4293191730976105, 0.0489286445081234, -0.2927809953689575, -0.07649850845336914, -0.4103071391582489, -1.1890332698822021, -0.5691104531288147, 0.2542632222175598, -0.7309562563896179, 0.5338929891586304, -0.2660282850265503, 0.42209291458129883, -0.117707759141922, 0.2524806261062622, 0.3471810519695282, 0.9551323056221008, 0.3094176948070526, -0.2497880458831787, 0.8052502274513245, -0.8812545537948608, -0.712181568145752, -1.300562858581543, 0.4971076548099518, 0.05659901350736618, 0.46477532386779785, -0.1587781310081482, -1.4427809715270996, -0.8385592699050903, -1.1676206588745117, 0.020225243642926216, -0.5465720295906067, -0.08594513684511185, 1.0121244192123413, 0.36496788263320923, -0.9144418835639954, 0.6031985282897949, -0.8677993416786194, -0.2651694715023041, 0.3337908685207367, 0.032645899802446365, 0.6754366159439087, -0.3336295485496521, -1.4155253171920776, 0.214729905128479, 0.1700955033302307, -0.7461541891098022, 0.07503364235162735, -0.46991342306137085, -1.1146055459976196, 0.19418281316757202, 0.562321662902832, -0.1522129327058792, 1.4510208368301392, -0.037149786949157715, -1.418660283088684, 0.00531273428350687, -0.6351297497749329, -0.0007307673222385347, -0.007420755457133055, -0.2189583033323288, -0.7481467723846436, -0.2625892758369446, -0.46912574768066406, 0.28739938139915466, 0.2881418466567993, 0.20639118552207947, -0.30606773495674133, 0.208235964179039, -0.4534491300582886, -0.30010637640953064, -0.279554158449173, 1.3117895126342773, -0.2961921989917755, 0.054772455245256424, 0.37265127897262573, 0.6791995167732239, -0.30485790967941284, -0.43002963066101074, -0.4989680349826813, -0.9088289141654968, 0.7051419019699097, -0.07961435616016388, 1.4529409408569336, -0.8440292477607727, -1.0354387760162354, -0.241914302110672, -0.6513639688491821, 0.2697044909000397, -0.821047842502594, 0.6932347416877747, -0.10035501420497894, 0.3285502791404724, -0.24081569910049438, -1.0394519567489624, -0.06828586012125015, -0.34205901622772217, -0.7598690986633301, -0.6028155088424683, 0.19135195016860962, 0.9991012811660767, -1.2143086194992065, -0.3434082269668579, 0.08796584606170654, 0.1691824197769165, -1.0872455835342407, 1.510809302330017, -0.6929987072944641, 0.18688565492630005, -0.29977667331695557, -0.11457221955060959, -0.2546572685241699, -0.4291697144508362, 0.5510882139205933, 0.2178419977426529, -0.3595244288444519, 0.8242460489273071, -0.5458162426948547, 1.6396173238754272, -0.5778629183769226, 0.598884642124176, -0.240828275680542, -0.3325234353542328, 0.050337646156549454, 0.3310724198818207, -0.14540717005729675, -0.46744903922080994, -0.01663108728826046, 0.24812878668308258, -0.9046233296394348, 0.09426450729370117, 1.0161179304122925, 1.2503845691680908, -0.4556737542152405, 0.11732450872659683, 0.3646107316017151, -0.04127931594848633, 0.3313581645488739, 0.798397958278656, 0.8607949614524841, 0.2059890329837799, 0.5509637594223022, 0.2198401391506195, -0.025766493752598763, -0.8072802424430847, -0.14918066561222076, 0.6238738894462585, 0.5791729092597961, 0.9225507974624634, 0.2195332646369934, -0.7019141912460327, -0.5487899780273438, 0.18434523046016693, 0.764988362789154, 1.6295928955078125, -0.0371834859251976, -0.21783797442913055, -0.7581540942192078, -0.060774777084589005, -0.6083509922027588, 0.5260530114173889, 0.05714723467826843, 0.2332674264907837, -0.8381223678588867, -0.39935654401779175, 0.6735267639160156, 0.3732999563217163, 0.8047466278076172, -0.9359537363052368, -0.6059176325798035, -0.01090130116790533, 0.0974530279636383, -0.7874084115028381, -0.659184455871582, 0.036052022129297256, -0.56299889087677, 0.0680457204580307, 0.3090377151966095, 0.10621987283229828, -0.34996166825294495, -0.3867814540863037, 0.8451157212257385, -0.32079461216926575, -0.3060572147369385, 0.20174704492092133, 0.3980574607849121, -0.7489631175994873, -0.7585487961769104, 0.555571973323822, -0.009254544042050838, -0.3622160851955414, 0.21438626945018768, 0.4899299442768097, -0.10798876732587814, -0.288552463054657, -0.5712484121322632, 0.2999832034111023, 0.15876294672489166, 0.012999982573091984, 0.3162573277950287, -0.9656689763069153, 0.2110711932182312, -1.1020172834396362, 0.4309627413749695, 0.051532547920942307, -0.4038007855415344, 0.2776682376861572, -0.7258031368255615, -0.2796824276447296, 0.10606252402067184, -0.8601841926574707, -0.2913717031478882, -0.7037482261657715, 0.07822433114051819, -0.2624913454055786, -0.5252097249031067, -0.034199029207229614, 0.3150887191295624, 0.6194004416465759, 0.0987408384680748, 0.9089608192443848, 0.40519097447395325, -0.13590671122074127, 0.41503846645355225, -0.30824196338653564, 0.36121243238449097, 0.5822577476501465, -0.29210641980171204, 0.04162439703941345, -0.05638855695724487, -1.1141302585601807, -0.28654736280441284, -0.7119735479354858, -0.3713648319244385, -0.05877070128917694, -0.02155458740890026, -0.3570793867111206, -0.7889658212661743, -0.2601553201675415, -1.2770178318023682, -0.5698952078819275, 0.23025014996528625, -0.36617714166641235, -0.2749045491218567, -0.7925081253051758, -1.0806459188461304, -1.0789780616760254, -0.46854278445243835, -0.4511977434158325, 0.28846272826194763, -0.08599071949720383, -0.7063197493553162, -0.33263102173805237, -0.019322233274579048, -0.5433610677719116, 1.1180572509765625, -0.5031430125236511, 0.4671322703361511, -0.23211541771888733, -0.6497520804405212, -0.6187010407447815, 0.7077047824859619, 0.2824940085411072, -0.2757209241390228, 0.23815633356571198, -0.7993645668029785, 0.12718234956264496, -0.5305564403533936, 0.0017586592584848404, 0.36936408281326294, 0.34655341506004333, 0.6101368069648743, -0.2847326993942261, -0.45143112540245056, 0.03035789728164673, 1.1069144010543823, -0.4202042818069458, -0.012960555031895638, -0.06326781213283539, 0.8260157704353333, -0.03438618779182434, 0.08862224966287613, 0.8528844714164734, 0.202224999666214, 0.6465160250663757, 0.3465742766857147, 0.03896382451057434, 0.16206911206245422, -0.4083162248134613, 0.6298047304153442, 1.429894208908081, 0.31878453493118286, -0.12003086507320404, -0.6596004366874695, 0.8940941095352173, -1.0989516973495483, -0.9534608125686646, 0.6705771088600159, 0.8518434762954712, 0.21486076712608337, -0.5021430850028992, 0.17226925492286682, -0.02399866282939911, 0.3661498427391052, 0.6780457496643066, -0.41211652755737305, -0.9514277577400208, 0.09433864802122116, 0.3571336567401886, 0.018964046612381935, 0.6995286345481873, -0.21308188140392303, 0.7358362078666687, 14.890120506286621, 0.7710349559783936, -0.34890368580818176, 0.4678528308868408, 0.47378110885620117, -0.5819225907325745, -0.18866463005542755, -0.13891546428203583, -1.1186902523040771, 0.06403493881225586, 1.755774974822998, 0.27971339225769043, 0.7181119918823242, 0.042788077145814896, 0.045173726975917816, 0.4511328339576721, -0.5958706140518188, 0.2766190469264984, 0.1746327131986618, -1.3890403509140015, 0.08934097737073898, -0.12150447070598602, 0.02698768861591816, 0.6358775496482849, 0.9345252513885498, 0.9017263054847717, 0.3003735840320587, -0.25820448994636536, 0.6113646030426025, 0.2755346894264221, 1.1689444780349731, -0.060693059116601944, -0.2056875377893448, 0.8825201988220215, -0.8157850503921509, -0.29698455333709717, -0.36166518926620483, -1.2512402534484863, 0.25828805565834045, -0.34613269567489624, -0.6582018136978149, -0.525139570236206, -0.5323220491409302, 0.3713108003139496, 0.2582677900791168, 0.20191062986850739, 0.1328476369380951, 1.0601977109909058, -0.15299147367477417, -0.4598096013069153, 0.35673996806144714, 0.7772390842437744, 0.23796580731868744, 0.3068178594112396, 0.007771926466375589, 0.33053839206695557, -0.020550670102238655, 0.3940832316875458, 0.07021224498748779, 0.12785236537456512, -0.3368608355522156, -0.23579838871955872, 0.2825104594230652, 0.4956033229827881, 0.8145163655281067, -0.12010519206523895, -0.6061296463012695, 0.2005125880241394, 0.25284379720687866, 0.42103061079978943, -0.18005713820457458, -0.049697134643793106, 0.4543663263320923, -0.23930005729198456, 0.10386264324188232, 0.37721776962280273, -0.2814164459705353, -0.5300198197364807, -0.6729590892791748, -0.17026104032993317, 0.4629998207092285, -0.5306841135025024, -0.033585116267204285, 0.8718900084495544, -0.014251583255827427, -0.4989212155342102, -0.34076541662216187, -0.40915536880493164, -0.35230642557144165, 0.4016752541065216, -1.256896734237671, -0.7627446055412292, 0.4444451928138733, -0.46566978096961975, -0.019029412418603897, 0.22950895130634308, 1.3764156103134155, -0.07361416518688202, -0.4668373763561249, 0.14891910552978516, 0.18459343910217285, -0.2694832682609558, -0.5066620707511902, -0.6665903329849243, 1.2263789176940918, 0.36623018980026245, -0.030600838363170624, 0.3498745560646057, 0.03673703968524933, 0.19703249633312225, -0.7856473326683044, -0.264475017786026, 0.8276716470718384, -1.0895335674285889, -0.5825544595718384, -1.0404502153396606, -1.0215325355529785, 0.5109643936157227, 0.427492618560791, -0.10423964262008667, 0.18843849003314972, 0.1442948430776596, -0.4987500309944153, 0.11907030642032623, -0.5712006688117981, 0.13418173789978027, 0.4406827986240387, -0.6327342987060547, -0.12793494760990143, -0.44717660546302795, 1.0099890232086182, -0.9550237655639648, -0.3571540117263794, -0.5382366180419922, 0.4676256477832794, -0.10835656523704529, 0.9945934414863586, -0.588663637638092, 0.6109893321990967, 1.266480803489685, -0.054566461592912674, -0.3823786973953247, -0.06905604153871536, -0.8442466855049133, -0.496055006980896, 0.02508966065943241, 0.5663160085678101, -0.4130650758743286, 0.34104669094085693, 0.9032347202301025, 0.1803196221590042, -0.6562891006469727, -0.6741863489151001, -0.6154091954231262, 0.10779915004968643, -0.7163114547729492, 1.0061267614364624, -0.0464010052382946, 0.31399983167648315, 0.04838380217552185, 0.42305660247802734, 0.5859318375587463, -0.3000921905040741, -0.6283992528915405, 0.22478923201560974, 0.10571109503507614, -0.058548763394355774, -0.6529141664505005, -0.3772580623626709, -1.4915019273757935, -0.18514522910118103, -0.7262228727340698, -0.06324859708547592, -0.7495251893997192, -0.5347855687141418, 0.10624657571315765, -0.679521918296814, -0.016412245109677315, 0.15480764210224152, -0.7137088775634766, -0.3809261620044708, -0.6515587568283081, -0.8869203329086304, 0.4623323678970337, 0.7268655896186829, -0.6715388298034668, -0.12900878489017487, 0.274641215801239, 0.2662060558795929, -0.2443809062242508, 0.5174724459648132, -0.13519245386123657, -0.5264363884925842, -0.940246045589447, 0.09368449449539185, 0.4375981390476227, -0.19587932527065277, -0.6529476642608643, 0.5208605527877808, -0.23605218529701233, -0.5060556530952454, -0.38894084095954895, 0.6850592494010925, -0.659187912940979, -0.6897900104522705, 0.35154885053634644, -1.2235358953475952, -0.19502346217632294, 0.3523646295070648, -0.5505461096763611, -0.12191018462181091, 0.7128482460975647, -0.22819717228412628, -0.9848288893699646, -0.7378117442131042, 0.4095405042171478, -0.6725762486457825, -0.17055746912956238, -0.4365171194076538, 0.011574897915124893, -0.9113497734069824, -0.4579658508300781, 0.10931947827339172, 0.24078959226608276, -0.2211005836725235, 1.0016422271728516, 0.4738357663154602, -0.9520279765129089, 0.0400410071015358, 0.3877299427986145, 0.0368385873734951, 0.2814565598964691, 0.6864729523658752, 0.06927897781133652, -0.08760842680931091, 0.9588077068328857, 0.3721402883529663, 0.18654830753803253, -1.0414892435073853, 0.3389491140842438, 0.23894286155700684, -0.3125317096710205, 0.1049097403883934, 0.9629939198493958, -0.7525440454483032, -0.4492500126361847, -0.01594802923500538, -1.6683259010314941, -0.5771639943122864, -0.724032461643219, 0.7639569044113159, 0.4045623540878296, -0.10918577760457993, 0.1463846117258072, -0.539373517036438, -0.21923404932022095, 0.027686847373843193, -0.7561925649642944, 0.4113599359989166, -0.06159790977835655, -0.04032476246356964, 1.1482048034667969, 0.8257085680961609, -0.7652989029884338, -0.7636072039604187, -0.7231670618057251, -0.35327333211898804, -0.09134497493505478, 0.25425589084625244, -0.3627278208732605, -0.0013278387486934662, 0.8851040005683899, 0.556110143661499, 0.807077169418335, 0.030765265226364136, -0.15738429129123688, 0.4401598870754242, 0.5271145105361938, 0.24674183130264282, -0.42423945665359497, -0.6292535662651062, 1.0744712352752686, 1.197738766670227, -0.9743280410766602, 0.18639619648456573, 0.0064932177774608135, -0.6671779751777649, 0.42296266555786133, 0.22313277423381805, 0.01485116221010685, 0.5961251258850098, -0.442553848028183, 0.26766279339790344, 0.42386582493782043, -1.4894320964813232, 0.06296785175800323, 0.5985386967658997, 0.6569252610206604, 0.7276917695999146, 0.6594271659851074, 0.2443210631608963, 0.8594558238983154, 0.23447024822235107, 0.12872542440891266, 0.5596368312835693, 0.7760570645332336, -0.41620030999183655, 0.0018602610798552632, 0.029253503307700157, 0.686363935470581, -0.4576084017753601, -0.6493033170700073, 0.37283945083618164, 0.41229671239852905, -0.27251169085502625, 0.6429439187049866, 1.3176677227020264, 0.28268545866012573, 0.5390210747718811, 0.4292050898075104, 0.5524911284446716, -0.9084910154342651, -0.2701977789402008, -0.3534587025642395, -0.6726648807525635, -0.36691683530807495, 0.3333115577697754, -0.9022058248519897, -0.470899760723114, 0.03128087520599365, 0.20619931817054749, 0.008327577263116837, 0.460685670375824, 1.0274927616119385, 0.7625955939292908, 0.3261790871620178, -0.013322677463293076, -0.44617369771003723, -0.5932068228721619, -1.1838078498840332, -0.12648633122444153, -0.5674508213996887, 0.3100920617580414, 0.19438129663467407, 0.22639033198356628, -0.525489091873169]}, "authors": [{"authorId": "2305659894", "name": "Liliang Ren"}, {"authorId": "2305678436", "name": "Yang Liu"}, {"authorId": "2238052953", "name": "Yadong Lu"}, {"authorId": "2237948786", "name": "Yelong Shen"}, {"authorId": "2305745249", "name": "Chen Liang"}, {"authorId": "2249538838", "name": "Weizhu Chen"}], "references": [{"paperId": "abdceff7d7983cdede9a5aabe6a476d4c72e41a3", "title": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"}, {"paperId": "917479a7a72ee7c1fb320c14d770e30ef322ef28", "title": "The Illusion of State in State-Space Models"}, {"paperId": "fe33be95849c556ce0bdffaa1d2c7db9bb2e2c61", "title": "RecurrentGemma: Moving Past Transformers for Efficient Open Language Models"}, {"paperId": "46732358e98ce6be0c564ae11f71d556a64b4c35", "title": "HGRN2: Gated Linear RNNs with State Expansion"}, {"paperId": "cbaf689fd9ea9bc939510019d90535d6249b3367", "title": "Jamba: A Hybrid Transformer-Mamba Language Model"}, {"paperId": "cde66097f4123a62bf3e28d48c764648e8c69f72", "title": "Simple linear attention language models balance the recall-throughput tradeoff"}, {"paperId": "ffea74c90f92eca449356b7bf83dc38cb11c6131", "title": "RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval"}, {"paperId": "a9468d8bfa6bd016dfd3128c4e8408e30eb8549b", "title": "LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning"}, {"paperId": "62b18cc55dcc7ffe52c28e1086aee893b7bc4334", "title": "Gated Linear Attention Transformers with Hardware-Efficient Training"}, {"paperId": "1be73fa3e856c33d0aed1d9e46693523e7fa3c60", "title": "Zoology: Measuring and Improving Recall in Efficient Language Models"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "434d751d355d7a7c20efa570e785c76286245e77", "title": "Hierarchically Gated Recurrent Neural Network for Sequence Modeling"}, {"paperId": "d7f64f2bdd80ea15f21ef7d867e102ac9ecdc797", "title": "GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "e26888285436bc7998e5c95102a9beb60144be5e", "title": "Textbooks Are All You Need II: phi-1.5 technical report"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "240103933ffe3dac2179cc160a2bd91299357a53", "title": "Retentive Network: A Successor to Transformer for Large Language Models"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "d2d0371158803df93a249c9f7237ffd79b875816", "title": "Sparse Modular Activation for Efficient Sequence Modeling"}, {"paperId": "60b35c6d68acced19b0c66edcfc0ee0a2c11efed", "title": "Landmark Attention: Random-Access Infinite Context Length for Transformers"}, {"paperId": "5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200", "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints"}, {"paperId": "574beee702be3856d60aa482ec725168fe64fc99", "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4"}, {"paperId": "f393aff1593c2d370ec0ae004910d18e40524967", "title": "Resurrecting Recurrent Neural Networks for Long Sequences"}, {"paperId": "998ac3e945857cf2676ee7efdbaf443a0c6f820a", "title": "Hyena Hierarchy: Towards Larger Convolutional Language Models"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "661e8d555c4424b5953f17434f2ba910bfcf3afe", "title": "Efficient Long Sequence Modeling via State Space Augmented Transformer"}, {"paperId": "70e91e16eb321067d9402710e14a40cf28311f73", "title": "Mega: Moving Average Equipped Gated Attention"}, {"paperId": "6d7d141c75af752ffc0d8a6184cca3f9323d6c74", "title": "Simplified State Space Layers for Sequence Modeling"}, {"paperId": "ca444821352a4bd91884413d8070446e2960715a", "title": "On the Parameterization and Initialization of Diagonal State Space Models"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "b7422b7a7830cd899b47b03e514d8151ffb74c03", "title": "SQuALITY: Building a Long-Document Summarization Dataset the Hard Way"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea", "title": "Training Verifiers to Solve Math Word Problems"}, {"paperId": "77d956cdab4508d569ae5741549b78e715fd0749", "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "a38e0f993e4805ba8a9beae4c275c91ffcec01df", "title": "Program Synthesis with Large Language Models"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "2c871df72c52b58f05447fcb3afc838168d94505", "title": "Knowledge Neurons in Pretrained Transformers"}, {"paperId": "9dc624d7258d1a56117ca720aea953ce46b66b21", "title": "Efficient Attentions for Long Document Summarization"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a", "title": "On Layer Normalization in the Transformer Architecture"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "dc52b09089704ebd6f471177474bc29741c50023", "title": "Fast Transformer Decoding: One Write-Head is All You Need"}, {"paperId": "941c39670d2e747170de4efdab7e8ef332860976", "title": "Depth-wise Decomposition for Accelerating Separable Convolutions in Efficient Convolutional Neural Networks"}, {"paperId": "10eda4521c032adabaa8e70d6569e17370b29dcd", "title": "Root Mean Square Layer Normalization"}, {"paperId": "9770fff7379a7ab9006b48939462354dda9a2053", "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "1536e8958697c5364f68b2e2448905dbbeb3a0ca", "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering"}, {"paperId": "88bb0a28bb58d847183ec505dda89b63771bb495", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "b587ee7c802a5bd222a69090f59285e0dfdb29f1", "title": "Sigmoid-Weighted Linear Units for Neural Network Function Approximation in Reinforcement Learning"}, {"paperId": "88caa4a0253a8b0076176745ebc072864eab66e1", "title": "Language Modeling with Gated Convolutional Networks"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "e3aa232577bb427b1f3a34acbdef84bd85734042", "title": "LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models"}, {"paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28", "title": "An Adversarial Winograd Schema Challenge at Scale"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Introducing meta"}, {"paperId": null, "title": "Slimpajama: A 627b token cleaned and dedupli-cated version of redpajama"}, {"paperId": null, "title": "Socialiqa: Common-sense reasoning about social interactions"}, {"paperId": null, "title": "Open models based on gemini research and technology"}]}