{"paperId": "6baf554c223cb4eea666efa2d1eb507a60823808", "title": "Eliminating Position Bias of Language Models: A Mechanistic Approach", "abstract": "Position bias has proven to be a prevalent issue of modern language models (LMs), where the models prioritize content based on its position within the given context. This bias often leads to unexpected model failures and hurts performance, robustness, and reliability across various applications. Our mechanistic analysis attributes the position bias to two components employed in nearly all state-of-the-art LMs: causal attention and relative positional encodings. Specifically, we find that causal attention generally causes models to favor distant content, while relative positional encodings like RoPE prefer nearby ones based on the analysis of retrieval-augmented question answering (QA). Further, our empirical study on object detection reveals that position bias is also present in vision-language models (VLMs). Based on the above analyses, we propose to ELIMINATE position bias caused by different input segment orders (e.g., options in LM-as-a-judge, retrieved documents in QA) in a TRAINING-FREE ZERO-SHOT manner. Our method changes the causal attention to bidirectional attention between segments and utilizes model attention values to decide the relative orders of segments instead of using the order provided in input prompts, therefore enabling Position-INvariant inferencE (PINE) at the segment level. By eliminating position bias, models achieve better performance and reliability in downstream tasks where position bias widely exists, such as LM-as-a-judge and retrieval-augmented QA. Notably, PINE is especially useful when adapting LMs for evaluating reasoning pairs: it consistently provides 8 to 10 percentage points performance gains in most cases, and makes Llama-3-70B-Instruct perform even better than GPT-4-0125-preview on the RewardBench reasoning subset.", "venue": "", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "By eliminating position bias, models achieve better performance and reliability in downstream tasks where position bias widely exists, such as LM-as-a-judge and retrieval-augmented QA."}, "embedding": {"model": "specter_v2", "vector": [0.09278153628110886, 0.518945038318634, -0.7636894583702087, -0.32731786370277405, -0.7022923231124878, -0.3399438261985779, 0.5592758059501648, -0.14430221915245056, -0.604170560836792, -0.3604738414287567, 0.19468502700328827, -0.5259701013565063, -0.024372387677431107, 0.1813066303730011, -0.376324862241745, 0.39755451679229736, -0.8834574818611145, 0.5722957849502563, 0.5063620805740356, -0.4937697947025299, 0.19155597686767578, -0.708686888217926, -0.9946707487106323, 0.5924522280693054, 0.31507810950279236, 0.293865442276001, 0.13045988976955414, 1.2464231252670288, -0.17486301064491272, 0.8673527240753174, 0.29882943630218506, -0.31839612126350403, -0.0328245535492897, -0.11021465063095093, -0.30285048484802246, -0.38583463430404663, 0.40958768129348755, -0.8017553091049194, -0.6758641004562378, 0.4833815097808838, 0.13810616731643677, -0.12636788189411163, 0.5739524364471436, -0.7949234843254089, -0.5477433204650879, 0.7194457054138184, 0.4812385141849518, 0.9001680016517639, 0.12140488624572754, -0.49209877848625183, 1.6391277313232422, -1.3121492862701416, 0.4860815703868866, 1.8648185729980469, 0.45537856221199036, 0.4046986401081085, 0.1458604335784912, 0.11474479734897614, 0.9983816742897034, 0.43711036443710327, -0.7461178302764893, -0.5025588274002075, -0.3946133255958557, 0.002585688605904579, 1.3981246948242188, -0.26748961210250854, -0.6072604656219482, 0.33635687828063965, -0.157737135887146, 1.750771403312683, -0.12532825767993927, -1.1156330108642578, 0.151724174618721, 0.1305849552154541, 0.5066999793052673, 0.9455505609512329, -0.29415759444236755, 0.17171384394168854, -0.7959874272346497, -0.36068880558013916, 0.5879982113838196, -0.5025031566619873, -0.3342583179473877, -0.4648018777370453, -0.38310834765434265, 0.36943551898002625, 0.41150379180908203, 0.5056856274604797, -0.07685625553131104, 0.5380319356918335, -0.11975494772195816, 0.3915327489376068, -0.16550284624099731, 0.4099222421646118, -0.28885605931282043, 0.438296377658844, -0.8811628818511963, 0.30080780386924744, 0.20564334094524384, 0.6348567605018616, -0.722821831703186, -0.2121828943490982, -1.1051387786865234, 0.22701922059059143, 1.8331165313720703, 0.008193200454115868, 0.39183923602104187, -0.924504280090332, 0.3617459833621979, -0.5381280779838562, 0.7437581419944763, -0.7226930856704712, -0.16347898542881012, -0.2725209593772888, 0.1772828996181488, -1.0768963098526, -0.12597490847110748, 0.3176029920578003, -0.5271883010864258, 0.8448436856269836, -0.16506946086883545, -0.06456306576728821, 0.027269041165709496, 0.616035521030426, 0.6772047281265259, 0.6134538650512695, 0.463325560092926, 0.3165014088153839, 0.7653377652168274, -0.5302945375442505, -0.36156120896339417, -1.1884205341339111, 0.8495705723762512, -0.2997625768184662, 0.3136971890926361, -0.468400776386261, -1.0930054187774658, -1.1321790218353271, -1.150717854499817, -0.04642178863286972, -0.2164098024368286, 0.762771487236023, 0.4964648187160492, -0.2662200927734375, -1.2820329666137695, 0.7585736513137817, 0.14390066266059875, -0.3178759813308716, 0.09024044126272202, 0.02640458568930626, 0.48337116837501526, -0.6699612736701965, -1.2849235534667969, 0.43507859110832214, 0.07115377485752106, -0.36197778582572937, -0.1736639440059662, -0.14296609163284302, -1.1191288232803345, -0.3037225008010864, 0.61420077085495, -0.850511372089386, 1.6331509351730347, 0.27661317586898804, -0.9892681241035461, 0.42376628518104553, -0.6710973978042603, 0.07103758305311203, 0.5331960320472717, -0.128900945186615, -0.5669336318969727, -0.021280139684677124, -0.18709558248519897, 0.8139365911483765, 0.5150934457778931, -0.6773983836174011, -0.6033183336257935, 0.19034309685230255, 0.15104876458644867, 0.07580646127462387, 0.33187252283096313, 0.555735170841217, -0.5501273274421692, 0.17153747379779816, 0.9239935874938965, 0.774483323097229, 0.2328348159790039, 0.2391831874847412, -0.16460002958774567, -1.3160574436187744, 0.4747788906097412, -0.10859667509794235, 0.8537853956222534, -0.6277561187744141, -0.6250481009483337, -0.6105673909187317, -0.06262601166963577, -0.22518303990364075, -0.8959919214248657, 0.3801141679286957, 0.10175424069166183, 0.5377299189567566, -0.1944214403629303, -1.0918442010879517, 0.15269210934638977, -0.25766798853874207, -0.8769589066505432, -0.13273626565933228, 0.17267394065856934, 1.3708795309066772, -1.0404613018035889, -0.37578344345092773, -0.02280374988913536, 0.03417236730456352, -0.6513682007789612, 1.1445502042770386, -0.7947285175323486, 0.20204715430736542, -0.36815211176872253, -0.031134886667132378, -0.09549843519926071, -0.21107453107833862, 0.036866266280412674, -0.2040320485830307, -0.009941422380506992, 0.47111591696739197, -0.1631016880273819, 1.144085168838501, -0.046189941465854645, 0.6586644649505615, -0.1547039896249771, -0.26693832874298096, -0.16288429498672485, 0.4218860864639282, -0.447605699300766, -0.6235449910163879, 0.2529478073120117, 0.27227747440338135, -0.31468528509140015, -0.3270050883293152, 0.7059518098831177, 1.0161833763122559, -0.2219824194908142, 0.18948012590408325, 0.4004546105861664, -0.27486035227775574, 0.4764033854007721, 0.4440762996673584, 0.6119715571403503, 0.5932543277740479, 0.13012583553791046, 0.25039607286453247, 0.3073342442512512, -0.4450696110725403, -0.17585837841033936, 1.0183731317520142, 0.4626300036907196, 1.0822076797485352, 0.37223049998283386, -0.6083647012710571, -0.30039286613464355, -0.09932500123977661, 0.3938952684402466, 1.6530919075012207, 0.42803165316581726, -0.055427435785532, -0.6289228200912476, -0.4773917496204376, -0.21249209344387054, 0.6685872077941895, -0.41036561131477356, -0.23089830577373505, -0.3987002670764923, -0.7976601719856262, 0.8235501646995544, 0.5295328497886658, 0.9460386037826538, -0.6347198486328125, -0.2961106300354004, -0.11418256908655167, 0.1830739974975586, -0.5538215637207031, -0.05906714126467705, -0.24360863864421844, -0.5624906420707703, -0.42481735348701477, 0.19453276693820953, -0.21787789463996887, 0.24370525777339935, -0.4413495361804962, 1.138784646987915, -0.36941957473754883, -0.10770215094089508, 0.6746795177459717, 0.43209344148635864, -0.7170520424842834, -0.8128126263618469, 0.03780488669872284, -0.23762980103492737, -0.386391818523407, 0.447887659072876, 1.108002781867981, -0.13633808493614197, 0.43689823150634766, -0.3771928548812866, 0.12224297225475311, 0.4439249634742737, -0.13351041078567505, 0.5627450346946716, -0.6368225812911987, 0.00686216726899147, -1.011695146560669, 0.7928135991096497, -0.09883268922567368, -0.48690104484558105, 0.7720863223075867, -0.8396568298339844, -0.5011429190635681, -0.08584040403366089, -0.4323905408382416, -0.08786746114492416, -1.5109729766845703, 0.6515580415725708, -0.16269023716449738, -0.30500879883766174, 0.17993353307247162, 0.26290470361709595, 0.7343623042106628, 0.3570948839187622, 0.19107304513454437, 0.5181466341018677, -0.27228447794914246, 0.7982098460197449, -0.7305784821510315, 0.6155741810798645, 0.17252317070960999, -0.35522088408470154, -0.0866110622882843, -0.11406277865171432, -0.45218855142593384, -0.401294082403183, -0.5489185452461243, -0.17710651457309723, -0.33404436707496643, -0.0146017512306571, -0.5406302809715271, -0.6089310050010681, -0.19361363351345062, -1.2112661600112915, -0.18324105441570282, 0.36324742436408997, -0.34579217433929443, -0.09554161876440048, -1.2112232446670532, -1.313881754875183, -0.5440271496772766, 0.0541595034301281, -0.7778515219688416, 0.6122224926948547, -0.29625070095062256, -0.741477370262146, -0.19852519035339355, -0.018093639984726906, 0.06617546081542969, 0.8168208599090576, -0.9404216408729553, 1.3099863529205322, -0.07212972640991211, -0.5253399014472961, -0.6863830089569092, 0.24797295033931732, 0.21704497933387756, -0.35008448362350464, 0.26951444149017334, -0.831279456615448, 0.11839564889669418, 0.15193015336990356, -0.041062455624341965, 0.11783859133720398, 0.37495967745780945, 0.3457922041416168, -0.01503894291818142, -0.7638558745384216, -0.3353101313114166, 1.2241531610488892, -0.402791827917099, 0.026662832126021385, 0.17288100719451904, 1.1583819389343262, 0.9234278202056885, 0.24768675863742828, 0.2486782819032669, 0.43399205803871155, 0.27804383635520935, 0.2853490114212036, -0.10145056992769241, 0.09175979346036911, -0.6505638957023621, 0.3917030692100525, 1.0251362323760986, 0.288199245929718, -0.16803275048732758, -1.114219307899475, 0.3573964536190033, -1.6704553365707397, -0.5806723833084106, 0.5833104848861694, 0.7511855363845825, 0.06953312456607819, -0.5478377938270569, -0.6311324834823608, -0.30269259214401245, 0.7476137280464172, 0.15187862515449524, -0.44329121708869934, 0.038947694003582, 0.16568230092525482, -0.3472216725349426, -0.18711361289024353, 0.8036343455314636, -0.5242239832878113, 0.4298391342163086, 14.88487720489502, 0.6361367106437683, -0.04824293777346611, 0.6211727261543274, 0.9456188678741455, 0.30330827832221985, -0.1975872665643692, 0.030693290755152702, -1.2067877054214478, -0.34267887473106384, 1.3044078350067139, 0.30679091811180115, -0.14744095504283905, 0.3644816279411316, 0.21040204167366028, -0.13414910435676575, -0.8836082220077515, 0.33614209294319153, 0.7261209487915039, -1.0264358520507812, 0.5870790481567383, 0.06916259229183197, 0.1591038852930069, 0.24036231637001038, 1.0116444826126099, 0.9296185374259949, 0.052329953759908676, -0.5450773239135742, 1.0283854007720947, 0.28391072154045105, 0.6468569040298462, 0.05929659679532051, 0.5269330143928528, 0.6276744604110718, -0.45750513672828674, -0.3743627071380615, -0.6846204400062561, -0.8886248469352722, 0.1018829271197319, -0.32932960987091064, -0.7591904997825623, -0.7092610597610474, -0.31379085779190063, 0.20056399703025818, -0.20097970962524414, 0.4694424569606781, -0.4011581242084503, 0.7145587205886841, 0.43178269267082214, -0.008189261890947819, -0.024401407688856125, 0.6519556641578674, 0.46267974376678467, -0.3858223855495453, 0.026750482618808746, -0.06267810612916946, 0.034715332090854645, 0.5669152736663818, -0.6001198887825012, -0.13837729394435883, -0.5644446015357971, 0.1854240894317627, 0.06935206800699234, 0.2546197474002838, 0.39852529764175415, 0.11465012282133102, -0.13449130952358246, 0.2329866588115692, 0.5163307189941406, 0.3364025056362152, -0.22982008755207062, 0.372860312461853, 0.10051930695772171, -0.13351507484912872, 0.10106753557920456, 0.7075754404067993, 0.07849057763814926, -0.3680099844932556, -0.3596321940422058, -0.2640986442565918, 0.4042693078517914, -1.0322067737579346, -0.5230553150177002, 0.736669659614563, -0.13661526143550873, -0.7268725037574768, -0.15155993402004242, -0.7629387378692627, -0.1179434210062027, 0.1398877501487732, -1.4148205518722534, -0.6687571406364441, 0.3984682559967041, -0.6791824698448181, -0.025873899459838867, 0.31357234716415405, 1.1862691640853882, -0.2979661524295807, -0.3567570745944977, -0.22908028960227966, 0.1207902804017067, -0.06683582812547684, 0.20739863812923431, -1.0811126232147217, 0.46489110589027405, 0.19897405803203583, 0.11480213701725006, 0.5019563436508179, 0.002356062177568674, 0.2431475669145584, -0.5922400951385498, -0.1721324473619461, 0.7435963153839111, -1.5785397291183472, -0.7814515829086304, -0.4275414049625397, -0.9413682222366333, 0.22283272445201874, 0.3245382606983185, -0.2815875709056854, 0.0700068324804306, 0.05814339220523834, -0.4981797933578491, 0.0042394353076815605, -0.7204428315162659, 0.2634221315383911, 0.45632413029670715, -0.7495931386947632, -0.9738677740097046, -0.038756389170885086, 0.3827378749847412, -1.0850262641906738, 0.1053835079073906, 0.026750028133392334, -0.02159462682902813, 0.028896551579236984, 1.0740822553634644, -0.6903553605079651, 0.8375982046127319, 0.3555159568786621, -0.20412777364253998, -0.562928318977356, -0.36404895782470703, -0.37253454327583313, -0.07682990282773972, 0.27006033062934875, 1.1576225757598877, -0.3417571187019348, -0.07621774822473526, 1.1706563234329224, 0.35797616839408875, -0.5037234425544739, -0.5093764066696167, -0.029846934601664543, 0.1817425787448883, -0.6165591478347778, 0.3019808828830719, -0.3449193239212036, -0.300579696893692, 0.2206888198852539, 0.8597611784934998, 1.365200161933899, -0.4202283024787903, -0.30006301403045654, 0.11626967042684555, -0.25197267532348633, -0.31070584058761597, -0.45048433542251587, -0.31866753101348877, -1.5179959535598755, -0.2261667549610138, -0.57710200548172, 0.5556676983833313, -1.464216947555542, -0.6920555233955383, 0.18982259929180145, -0.5520185232162476, -0.2723867893218994, 0.17749595642089844, -0.5118586421012878, -0.5837884545326233, -0.06692676246166229, -1.0629901885986328, 0.4267441928386688, 0.6763625741004944, -0.7595604062080383, 0.29885372519493103, 0.1946643441915512, -0.13920871913433075, 0.5243329405784607, 0.39520424604415894, -0.3383898437023163, -1.0486435890197754, -1.6714451313018799, 0.5361804366111755, 0.14464230835437775, 0.1950269341468811, -0.5179458260536194, 0.8892537355422974, 0.7418023943901062, -0.0055464282631874084, -0.054723549634218216, 0.4429560899734497, -0.6896097660064697, -0.9599210619926453, 0.24004395306110382, -1.3285679817199707, 0.14842747151851654, 0.08104871958494186, -0.3854982852935791, -0.338304340839386, 0.30030402541160583, -0.4144953787326813, -1.1568151712417603, -1.0292764902114868, 0.1602489948272705, -0.5610986351966858, 0.09682363271713257, -0.41675862669944763, 0.10954190790653229, -1.1331861019134521, -0.4601806700229645, 0.055514492094516754, 0.45231378078460693, -0.12442789226770401, 1.006206750869751, 0.538236677646637, -0.7991767525672913, -0.09810453653335571, -0.1269010603427887, 0.17221753299236298, 0.2772924602031708, 0.48463818430900574, 0.14414766430854797, -0.24946090579032898, 0.6806358098983765, 0.6052864193916321, -0.13038113713264465, -0.9161268472671509, 0.048746898770332336, 0.5747891068458557, -0.05497356504201889, 0.2319069504737854, 1.2981505393981934, -0.48340943455696106, -0.9886740446090698, 0.18216492235660553, -1.3177298307418823, -0.6934144496917725, -0.24546942114830017, 0.5260857939720154, 0.38320648670196533, -0.06265170127153397, -0.022338991984725, -0.4633708596229553, 0.24801695346832275, -0.1272120177745819, -0.9225903153419495, 0.04015526548027992, -0.25447511672973633, -0.5814573764801025, 0.9549511671066284, 0.45253294706344604, -0.561690092086792, -0.8950278162956238, -0.49675261974334717, -0.20874696969985962, -0.13769787549972534, 0.24797916412353516, -0.5521939396858215, 0.2185211181640625, 0.779914140701294, 0.4792161285877228, 0.26388806104660034, -0.4266378581523895, 0.19961683452129364, -0.23935618996620178, 0.5326937437057495, 0.31730952858924866, -0.3726067543029785, -0.6513994336128235, 0.7954485416412354, 1.6366636753082275, -1.1647439002990723, 0.13802751898765564, -0.01199376117438078, -0.48770803213119507, 0.7620683908462524, 0.6696144342422485, 0.29196488857269287, 0.33152472972869873, -0.6368255019187927, 0.4546663165092468, 0.04458334296941757, -0.9584150314331055, -0.0009437110857106745, 1.1295552253723145, 0.8454869985580444, 0.6760797500610352, 0.2691733241081238, 0.2810072600841522, 0.6326223611831665, 0.3801293969154358, 0.20789875090122223, 0.3810882568359375, 0.9305156469345093, -0.42512282729148865, 0.041141338646411896, -0.0726645216345787, 0.6123123168945312, -0.24247772991657257, -0.6650047302246094, -0.19153529405593872, 0.6941526532173157, 0.21448741853237152, 1.0369585752487183, 0.8636602759361267, 0.40808552503585815, 0.49274805188179016, 0.45863083004951477, 0.4472655951976776, -0.7544282674789429, 0.367218941450119, -0.4352746605873108, -0.5647179484367371, 0.038255542516708374, -0.15026001632213593, -0.5755020976066589, -0.5362616181373596, 0.1175260916352272, 0.2433975487947464, -0.009448548778891563, 0.16254279017448425, 1.0849990844726562, 0.944768488407135, 0.5158188939094543, -0.4012939929962158, -0.20430518686771393, -0.7382516264915466, -1.240049123764038, 0.4517490267753601, -0.5487945079803467, -0.27452412247657776, -0.35613787174224854, -0.39805054664611816, -0.44494664669036865]}, "authors": [{"authorId": "2255392818", "name": "Ziqi Wang"}, {"authorId": "2119078297", "name": "Hanlin Zhang"}, {"authorId": "2118053386", "name": "Xiner Li"}, {"authorId": "2295786180", "name": "Kuan-Hao Huang"}, {"authorId": "2310233116", "name": "Chi Han"}, {"authorId": "2279225650", "name": "Shuiwang Ji"}, {"authorId": "144695232", "name": "S. Kakade"}, {"authorId": "2288239343", "name": "Hao Peng"}, {"authorId": "2290907632", "name": "Heng Ji"}], "references": [{"paperId": "1ebaca653dde0d67d1dc088368d22f7f9e284ac0", "title": "Attention Instruction: Amplifying Attention in the Middle via Prompting"}, {"paperId": "9f3c17e20dff7321ddc849f8bf5194ba94370c46", "title": "Found in the Middle: Calibrating Positional Attention Bias Improves Long Context Utilization"}, {"paperId": "7d755929690577dbd4b8c187238ed44c3e3a247a", "title": "3D-RPE: Enhancing Long-Context Modeling Through 3D Rotary Position Encoding"}, {"paperId": "83990fc5ccef2c1b932b426c6d715f80dfb82f53", "title": "Judging the Judges: A Systematic Investigation of Position Bias in Pairwise Comparative Assessments by LLMs"}, {"paperId": "7a4478d86d7e968ea5340f8e9615715d41e3b47e", "title": "Mitigate Position Bias in Large Language Models via Scaling a Single Dimension"}, {"paperId": "d7ee15521fcfd8704c8422997614b2b22f5e1148", "title": "Contextual Position Encoding: Learning to Count What's Important"}, {"paperId": "59cf4f0391430523cff7d7ca1819389476ff87a6", "title": "Transformers Can Do Arithmetic with the Right Embeddings"}, {"paperId": "a509670659e8b054e2b7d1b6f8a0bc722398fa62", "title": "PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation"}, {"paperId": "8e9088c102b3714ae4e5cac7ced93a59804bfc7c", "title": "RewardBench: Evaluating Reward Models for Language Modeling"}, {"paperId": "07f4d937c2b852994d7c8cb5808910e34dc9519a", "title": "In-Context Example Ordering Guided by Label Distributions"}, {"paperId": "2208e506f72518a16ea86dfa604995c12fa8e4ca", "title": "Premise Order Matters in Reasoning with Large Language Models"}, {"paperId": "d99a32f5191ba4192e30b933278d40956e3292c9", "title": "Batch-ICL: Effective, Efficient, and Order-Agnostic In-Context Learning"}, {"paperId": "c672ec79f55cef8f7a32cd8dddfa981b893f1567", "title": "V*: Guided Visual Search as a Core Mechanism in Multimodal LLMs"}, {"paperId": "c2b833283099f6fbcbe89229c703e4945b1f7ebf", "title": "Never Lost in the Middle: Improving Large Language Models via Attention Strengthening Question Answering"}, {"paperId": "69ecf88a0d9752db7dc32b4917ee24b4974cea18", "title": "JudgeLM: Fine-tuned Large Language Models are Scalable Judges"}, {"paperId": "7c3c9f90e3acc5a0e780b121456a45df8ebed1a0", "title": "Primacy Effect of ChatGPT"}, {"paperId": "ff01d3dab60dd4b7426c884b009dda83540c0c1e", "title": "Attention Sorting Combats Recency Bias In Long Context Language Models"}, {"paperId": "5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0", "title": "Qwen Technical Report"}, {"paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05", "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"}, {"paperId": "570e4fec8c8f1c96b76accbb07d40e0528aafb4a", "title": "Large Language Models Are Not Robust Multiple Choice Selectors"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "e89b4ef0f0282327085078058557c04812aa4d35", "title": "Scaling In-Context Demonstrations with Structured Attention"}, {"paperId": "d908dbdecadb766b4e993e0cba02f18a1fba2788", "title": "Open-Domain Hierarchical Event Schema Induction by Incremental Prompting and Verification"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "980e55d9226cac302d0fae7732da4e67b8bc952c", "title": "Parallel Context Windows for Large Language Models"}, {"paperId": "eecb45aa040064cbc0b37fd100706c02e7dc880e", "title": "Structured Prompting: Scaling In-Context Learning to 1, 000 Examples"}, {"paperId": "b21670e8061a06ab97e7d6052c9345a326e84ff8", "title": "UL2: Unifying Language Learning Paradigms"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "5f19ae1135a9500940978104ec15a5b8751bc7d2", "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models"}, {"paperId": "b3848d32f7294ec708627897833c4097eb4d8778", "title": "LaMDA: Language Models for Dialog Applications"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": null, "title": "Transformers: State-of-the-Art Natural Language Processing"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": null, "title": "Build the future of ai with meta"}, {"paperId": "7a29f47f6509011fe5b19462abf6607867b68373", "title": "GPT-4V(ision) System Card"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Pearls are found in the Indian Ocean, specifically in the Gulf of Mannar and the Laccadive Sea, off the coast of India"}, {"paperId": null, "title": "Introducing our multimodal models"}]}