{"paperId": "a3c8c57075dfebf7f5a57952afafb7407762cc46", "title": "Discourse-Aware Soft Prompting for Text Generation", "abstract": "Current efficient fine-tuning methods(e.g., adapters, prefix-tuning, etc.) have optimized conditional text generation via training a small set of extra parameters of the neural language model, while freezing the rest for efficiency. While showing strong performance on some generation tasks, they don\u2019t generalize across all generation tasks. We show that soft-prompt based conditional text generation can be improved with simple and efficient methods that simulate modeling the discourse structure of human written text.We investigate two design choices: First, we apply hierarchical blocking on the prefix parameters to simulate a higher-level discourse structure of human written text. Second, we apply attention sparsity on the prefix parameters at different layers of the network and learn sparse transformations on the softmax-function. We show that structured design of prefix parameters yields more coherent, faithful and relevant generations than the baseline prefix-tuning on all generation tasks.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2021, "citationCount": 4, "influentialCitationCount": 1, "openAccessPdf": {"url": "https://aclanthology.org/2022.emnlp-main.303.pdf", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work investigates two design choices and shows that structured design of prefix parameters yields more coherent, faithful and relevant generations than the baseline prefix-tuning on all generation tasks."}, "embedding": {"model": "specter_v2", "vector": [0.5771693587303162, 1.4630534648895264, -0.07094522565603256, 0.028914928436279297, -0.3021430969238281, -0.43554800748825073, 1.1360632181167603, -0.060711659491062164, 0.010767130181193352, -0.03705994039773941, 0.834507167339325, -0.3555566966533661, 0.04713054373860359, -0.13189014792442322, -0.271628201007843, -0.13117492198944092, -0.3723300099372864, 0.27457523345947266, -0.08778268098831177, -0.47155332565307617, -0.015903403982520103, -1.3601300716400146, -0.6880754232406616, 0.23298180103302002, 0.6557343006134033, 0.1595316231250763, 0.2661576569080353, 1.1038072109222412, -0.2872484028339386, 0.15013708174228668, -0.29877930879592896, -0.5644861459732056, 0.14062532782554626, -0.49698758125305176, -0.40298739075660706, 0.18216508626937866, 0.206189826130867, -0.33835333585739136, -0.15975260734558105, 0.5688468813896179, -0.07853012531995773, 0.15132275223731995, 0.49729499220848083, -0.22865499556064606, -0.7172206044197083, 1.3974136114120483, 0.6231221556663513, 0.6198393702507019, 0.3609127700328827, -0.27932342886924744, 1.234548568725586, -0.7350078225135803, 0.5800178050994873, 1.416943907737732, -0.08261602371931076, 0.8382880091667175, -0.25959450006484985, -0.05753073841333389, 1.158440351486206, -0.06791992485523224, -0.5274536609649658, -0.11339892446994781, 0.04497753828763962, -0.2738337218761444, 1.7382276058197021, -0.14916259050369263, -0.06327595561742783, 1.1259585618972778, -0.4524325728416443, 1.213010549545288, -0.5368977189064026, -1.0895196199417114, -0.47880318760871887, 0.12731508910655975, 0.06523913145065308, 0.4625253975391388, -0.41340672969818115, 0.7522410154342651, -0.9943479895591736, 0.19825893640518188, 0.41959789395332336, -0.7479884028434753, -0.2727394700050354, 0.5720811486244202, -0.6353555917739868, 0.4103357493877411, 0.04546944797039032, 0.9229309558868408, 0.004739776719361544, 0.4774050712585449, 0.3991643786430359, 0.13462211191654205, -0.004219728987663984, 0.4310658872127533, 0.05873842537403107, 0.2689043879508972, -0.9178246259689331, 0.4587531089782715, 0.24381737411022186, 0.8984830379486084, -0.3454182744026184, 0.42215219140052795, -1.6957520246505737, 0.0757390558719635, 1.2124561071395874, -0.0038204584270715714, 0.6996421217918396, -0.912232518196106, 0.72785884141922, -0.6966087818145752, 0.18918389081954956, -0.6665687561035156, 0.029257258400321007, 0.08092248439788818, -0.5964094400405884, -1.2080048322677612, -0.1112855076789856, -0.5701849460601807, -1.0346969366073608, 0.9383955001831055, 0.08582604676485062, -0.3500661253929138, -0.08185643702745438, 0.7169064879417419, 0.49608486890792847, 0.9027316570281982, 0.14102904498577118, 0.15280881524085999, 0.5625437498092651, -0.5745912194252014, -0.6949620842933655, -1.022754430770874, 0.5766048431396484, -0.2700050473213196, 0.3390325605869293, -0.058583781123161316, -1.5754131078720093, -0.8419895172119141, -1.0175012350082397, 0.0873785987496376, -0.31480205059051514, 0.35395705699920654, 1.1197391748428345, 0.7641336917877197, -0.8477270603179932, 0.8378161787986755, -0.3142845332622528, -0.29133903980255127, 0.11182726174592972, -0.1603296399116516, 0.4508873224258423, -0.26176702976226807, -1.360842227935791, -0.10587862133979797, 0.4364229440689087, -0.8265109062194824, -0.07189851254224777, -0.7107856273651123, -1.0943260192871094, -0.13682794570922852, 0.5489782691001892, -0.7796722650527954, 1.594765067100525, -0.4755977392196655, -1.6319575309753418, 0.7385717630386353, -0.03356267139315605, 0.18208619952201843, 0.3053203821182251, -0.016320429742336273, -0.2721320688724518, -0.17279919981956482, -0.0728493481874466, 0.7793850898742676, 0.5479899048805237, -0.024567212909460068, -0.0426776148378849, 0.5269964337348938, -0.1428183615207672, -0.33846038579940796, -0.2327737957239151, 0.8799936175346375, -0.07924927771091461, -0.5192338824272156, -0.024839753285050392, 0.9395745396614075, 0.18472614884376526, -0.6403868794441223, -0.9770016074180603, -1.2374509572982788, 0.4100080728530884, -0.049768511205911636, 1.1386133432388306, -0.7464949488639832, -0.581838846206665, -0.310976505279541, -0.4399053454399109, 0.08126279711723328, -0.872024416923523, 0.6278717517852783, -0.6977264285087585, 0.4233727753162384, -0.12016236782073975, -0.9634572267532349, 0.40501996874809265, -0.5318917632102966, -0.611004650592804, -0.504767119884491, 0.40934276580810547, 1.0488537549972534, -0.5770222544670105, -0.13587987422943115, -0.027528071776032448, 0.10397451370954514, -0.9775985479354858, 1.3539142608642578, -0.91607266664505, 0.36432886123657227, 0.002334951190277934, -0.30471712350845337, -0.18269917368888855, -0.41630616784095764, 0.25143399834632874, -0.11045947670936584, 0.08900696784257889, 0.6237990856170654, -0.4909287393093109, 1.2902216911315918, 0.1098979040980339, 0.5390357971191406, -0.0835941955447197, -0.8878708481788635, 0.48334577679634094, 0.6492173075675964, -0.5671568512916565, -0.49281808733940125, 0.21584530174732208, 0.3019031584262848, -0.4640734791755676, -0.025456298142671585, 0.7839565873146057, 0.6420426368713379, -0.13264299929141998, 0.15208259224891663, 0.5824649333953857, -0.21926209330558777, 1.1802085638046265, 0.568443775177002, 0.6265838742256165, 0.510042667388916, 0.1278822124004364, 0.13128378987312317, 0.24542264640331268, -0.6415458917617798, -0.14346295595169067, 0.29065456986427307, 1.1638835668563843, 1.2623451948165894, 0.820441484451294, -0.34146952629089355, -0.3800126612186432, -0.018233122304081917, 0.7575786709785461, 1.4119659662246704, -0.24144446849822998, -0.2944575548171997, -1.1609342098236084, -0.3998439908027649, -0.5412899255752563, 0.5485374331474304, -0.4500562250614166, -0.2713252902030945, -0.8252992630004883, -1.0496879816055298, 0.5631324052810669, 0.2390025109052658, 0.4616025984287262, -0.6652761697769165, -0.19099634885787964, -0.20679357647895813, -0.04981245845556259, -0.7746295928955078, -0.936895489692688, 0.007123051676899195, -0.12523800134658813, -0.09533495455980301, -0.4453152120113373, -0.07371154427528381, 0.38474005460739136, -1.0820571184158325, 1.0687583684921265, -0.16519175469875336, -0.4666571319103241, 0.37382546067237854, 0.19068899750709534, -0.2820407748222351, -0.9333932399749756, 0.3817528486251831, -0.3136926591396332, -0.16297662258148193, -0.013589664362370968, 0.4428580403327942, -0.15654191374778748, -0.09647805988788605, -0.6357901096343994, 0.32179972529411316, -0.25502896308898926, 0.08514966815710068, 0.22111450135707855, -0.6102828979492188, -0.07540050894021988, -1.1329560279846191, 0.995771586894989, 0.3175472319126129, -0.6455764770507812, 0.21327050030231476, -0.5160270929336548, -0.42941349744796753, 0.3526644706726074, -0.7685754299163818, -0.8869615197181702, -1.1174360513687134, 0.229671910405159, 0.5334811210632324, -0.514882504940033, 0.27316683530807495, 0.16542455554008484, 0.5615345239639282, 0.8060458302497864, 0.18563289940357208, -0.04302602633833885, 0.08039546012878418, 0.6947878003120422, -0.9028975963592529, 0.5912805795669556, -0.1113218143582344, 0.24801845848560333, -0.5325825214385986, -0.3477928936481476, -0.59110426902771, -0.5058543682098389, 0.4206558167934418, 0.10006017982959747, -0.42644375562667847, 0.47243839502334595, -0.2953766882419586, -1.1222373247146606, -0.2367231249809265, -1.4558993577957153, -0.6000897884368896, -0.2602244019508362, -0.6597577929496765, -0.23624837398529053, -0.6595520973205566, -1.0534155368804932, -0.5080884099006653, -0.42042508721351624, -0.6201601624488831, 0.6423240900039673, 0.180707648396492, -0.920673668384552, -0.6659603118896484, 0.272815078496933, -0.185113787651062, 0.554364800453186, -0.4011346995830536, 0.8718912601470947, 0.013921814039349556, -0.6804390549659729, -0.1912417858839035, 0.41458624601364136, 0.41566529870033264, -0.49847593903541565, 0.5934461355209351, -0.4774188697338104, 0.32677024602890015, -0.655032753944397, -0.4294751286506653, 0.07750353217124939, 0.5316989421844482, 0.46956461668014526, -0.2106754034757614, -0.627345621585846, 0.43689092993736267, 0.9892668724060059, -0.6529562473297119, 0.07203052937984467, 0.20757974684238434, 0.7377161979675293, 0.7702128291130066, -0.04756161943078041, 0.8343448638916016, 0.2938743233680725, 0.44591182470321655, 0.19600948691368103, -0.24701985716819763, -0.5014399886131287, -0.8233709335327148, 0.6247788667678833, 1.3788305521011353, 0.4288767874240875, -0.5827895998954773, -1.128942847251892, 0.8915883302688599, -1.2488244771957397, -0.37970006465911865, 0.26857876777648926, 0.4004054665565491, 0.7736899256706238, -0.5267872214317322, -0.3239709734916687, -0.09136857837438583, 0.6622147560119629, 0.2634226083755493, 0.06890551000833511, -0.5625778436660767, -0.09215212613344193, 0.2231685370206833, -0.3422791659832001, 0.9706152081489563, -0.0654112845659256, 0.46468886733055115, 14.71080493927002, 0.7453670501708984, 0.17060212790966034, 0.31285521388053894, 0.7619739770889282, -0.020115366205573082, -0.6717338562011719, -0.06479644030332565, -1.4587149620056152, 0.0516381673514843, 0.9426968097686768, -0.02913999930024147, 0.47166457772254944, -0.26191598176956177, -0.1250017285346985, -0.026256680488586426, -0.6304563283920288, 0.4287664592266083, 0.5481995344161987, -1.521381139755249, 0.2630729079246521, -0.045192133635282516, 0.7231636047363281, -0.03338423743844032, 0.8923190236091614, 0.4706217050552368, 0.37483784556388855, -0.18150360882282257, 0.7874690890312195, 0.3089396357536316, 0.8133228421211243, 0.1576113998889923, 0.08729622513055801, 0.5828455686569214, -0.26825782656669617, -0.21027490496635437, -0.40644532442092896, -0.9204210638999939, 0.6488969922065735, 0.4838886559009552, -0.46849745512008667, -0.3596348464488983, -0.5103194117546082, 0.419091135263443, 0.17327624559402466, 0.13359293341636658, -0.6910574436187744, 0.9593221545219421, -0.04077588766813278, -0.19326041638851166, 0.14317531883716583, 0.5554514527320862, 0.4247904419898987, 0.13752445578575134, 0.4717034101486206, 0.1606454700231552, -0.032982733100652695, 1.0535736083984375, -0.266167551279068, -0.2596309781074524, -0.11305871605873108, -0.45936283469200134, 0.13165216147899628, 0.5894794464111328, 0.4128662645816803, 0.37307193875312805, -0.18322956562042236, 0.1393033266067505, 0.5340533256530762, 0.5028519630432129, 0.05102994292974472, -0.40644654631614685, 0.0220064427703619, -0.09726691991090775, 0.03782862424850464, 0.5462950468063354, -0.4675835967063904, -0.2910202741622925, -0.5620445013046265, -0.4678490459918976, 0.3960132598876953, -0.769869863986969, -0.6560401320457458, 0.7146681547164917, -0.1200585663318634, -0.23985432088375092, -0.3854627311229706, -0.728929340839386, -0.5546178221702576, 0.4382481575012207, -1.2269940376281738, -0.47895604372024536, 0.1453341543674469, -0.45281365513801575, -0.5765775442123413, -0.23318339884281158, 1.0816259384155273, -0.21824266016483307, -0.4381588399410248, 0.44163650274276733, -0.15128673613071442, -0.17141464352607727, 0.06656654924154282, -1.026607871055603, 0.864741325378418, 0.4277726709842682, -0.2328420877456665, 0.1653178185224533, 0.2283591330051422, -0.10491900146007538, -0.342591792345047, 0.2699890434741974, 0.9666715264320374, -0.9754697680473328, -0.5873217582702637, -0.7614911198616028, -0.6800075173377991, 0.1109880581498146, 1.228116750717163, -0.6632900238037109, 0.4024827778339386, 0.3043416142463684, -0.1927480548620224, -0.18211215734481812, -0.5906379222869873, 0.2932437062263489, 0.3007950782775879, -0.09429021924734116, -0.33799391984939575, 0.3099486231803894, 0.9524986147880554, -1.2893390655517578, -0.33887189626693726, -0.5526075959205627, -0.3461814820766449, -0.09177051484584808, 0.7609980702400208, -0.18175078928470612, 1.0226788520812988, 0.8300386667251587, 0.2723914682865143, -0.7595795392990112, -0.10113942623138428, -1.6512919664382935, 0.22674918174743652, 0.8940821886062622, 0.9961175322532654, -0.4135802686214447, 0.43554478883743286, 1.1979336738586426, 0.14867813885211945, -0.12594391405582428, -0.4933364689350128, -0.1573249250650406, 0.393655002117157, -0.2918069064617157, 0.5706871747970581, -0.1639871895313263, 0.4629487991333008, 0.30501213669776917, 0.5394399166107178, 0.38742178678512573, -0.21005292236804962, -0.656291127204895, 0.4016549289226532, 0.3782269358634949, -0.23546777665615082, -0.6231867074966431, -0.1190330758690834, -1.7404240369796753, -0.2489185780286789, -1.1030917167663574, 0.15886199474334717, -0.9766270518302917, -0.5809646844863892, 0.5336823463439941, 0.3359968662261963, 0.02806185558438301, -0.10755572468042374, -0.7245883345603943, -0.3468351364135742, -1.2811851501464844, -0.3623110055923462, 1.0194693803787231, 1.0489040613174438, -0.8972283601760864, 0.11091526597738266, -0.21923330426216125, -0.37525323033332825, -0.009274287149310112, 0.3422664403915405, -0.4607393741607666, -0.6420394778251648, -1.4925299882888794, 0.604282021522522, 0.22996066510677338, 0.19950436055660248, -0.5404346585273743, 0.6045134663581848, 0.42368245124816895, -0.13277855515480042, 0.07681333273649216, -0.017963794991374016, -0.24770689010620117, -0.6441762447357178, -0.10534379631280899, -0.9579442739486694, -0.2699386775493622, -0.06867395341396332, -0.6905352473258972, -0.3483189046382904, 0.4114404022693634, -0.27084654569625854, -1.0038279294967651, -0.058667562901973724, 0.26894092559814453, -0.7090309262275696, 0.45747241377830505, -0.4160417914390564, -0.4459433853626251, -1.4174305200576782, -0.24271471798419952, 0.04256061092019081, 0.40753528475761414, -0.63038170337677, 0.9141998291015625, 0.18595758080482483, -1.1050336360931396, -0.11614824086427689, 0.21759337186813354, -0.3098578453063965, 0.17745965719223022, 0.5647031664848328, 0.22778081893920898, -0.20532527565956116, 0.697790265083313, 0.6223515868186951, 0.27577465772628784, -0.7018020749092102, -0.23478549718856812, 0.6717750430107117, -0.3601955473423004, -0.11032078415155411, 1.4343838691711426, -0.4033246636390686, -1.0878688097000122, 0.3638668656349182, -1.0910589694976807, -0.24713659286499023, -0.5036377906799316, 0.7207802534103394, 0.1340848207473755, -0.3439752459526062, 0.4240433871746063, -0.11945600807666779, 0.24373017251491547, 0.013513876125216484, -0.8434010744094849, 0.35260188579559326, -0.11201132833957672, -0.3016200363636017, 0.11589474231004715, 0.30147650837898254, -0.9426880478858948, -0.834842324256897, -0.2578236162662506, -0.34662529826164246, 0.045144714415073395, 0.05441423878073692, -0.8005759716033936, -0.566061794757843, 1.0012093782424927, -0.008253282867372036, 0.613198459148407, 0.13940364122390747, 0.1404867321252823, 0.14288310706615448, 0.38585877418518066, -0.3678473234176636, -0.9834124445915222, -0.1596878170967102, 1.1478136777877808, 1.3232556581497192, -0.7682197093963623, 0.04065820574760437, -0.36866259574890137, -0.7549066543579102, 1.0255604982376099, 0.6059980988502502, 0.3232196271419525, 0.5587502121925354, -0.32463353872299194, 0.15310892462730408, 0.1903611272573471, -1.230001449584961, -0.02871847338974476, 0.7880738377571106, 1.6288436651229858, 0.9453067183494568, 0.1369187831878662, -0.10770221799612045, 1.4292560815811157, -0.16224516928195953, -0.11011258512735367, 0.448289692401886, 0.031935419887304306, -0.05281604453921318, -0.5524014234542847, -0.3160783648490906, 0.1812238097190857, -0.7078251838684082, -0.4135337471961975, -0.11036136746406555, 0.35639050602912903, 0.31271442770957947, 0.8800421953201294, 0.349539577960968, 0.31824690103530884, 0.7065452933311462, 0.09648063778877258, 0.6999236345291138, -0.5737233757972717, -0.4078878164291382, -0.13456672430038452, -0.22460009157657623, -0.14263391494750977, 0.17346522212028503, -0.8306028842926025, -0.13502848148345947, -0.1881343573331833, 0.3121616542339325, -0.24495774507522583, 0.14251866936683655, 1.2053815126419067, 0.49306681752204895, 0.7343984842300415, -0.3263026773929596, -0.7469842433929443, -0.31974032521247864, -0.9747803211212158, 0.23230336606502533, -0.49273309111595154, -0.09210949391126633, -0.001198699465021491, -0.09636574983596802, 0.38582655787467957]}, "authors": [{"authorId": "2320509", "name": "Marjan Ghazvininejad"}, {"authorId": "2067091563", "name": "Vladimir Karpukhin"}, {"authorId": "89992516", "name": "Vera Gor"}, {"authorId": "1709797", "name": "Asli Celikyilmaz"}], "references": [{"paperId": "3d318019788418b21478e8736d03afadc1607690", "title": "HIBRIDS: Attention with Hierarchical Biases for Structure-aware Long Document Summarization"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "3c8a620170eed8cc8cb418db429c9e444a20ead6", "title": "Protum: A New Method For Prompt Tuning Based on \"[MASK]\""}, {"paperId": "e64e194f64ccccb037ee6f6f5a38ca0c6bb26262", "title": "Response Generation with Context-Aware Prompt Learning"}, {"paperId": "ad471be93216ddbf8544721d50ee5aed14f07cae", "title": "UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning"}, {"paperId": "34042e2680e475510a1030b54165a81534ad88d3", "title": "HETFORMER: Heterogeneous Transformer with Sparse Attention for Long-Text Extractive Summarization"}, {"paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"}, {"paperId": "ce498651107588db67adcfbb5479bdb416f4de2f", "title": "Template-Based Named Entity Recognition Using BART"}, {"paperId": "45f7c0caf0f1f88a568279de52d7a8c29aa8e28f", "title": "Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization"}, {"paperId": "da454295392cf4caaa39cc465734237ffe55392f", "title": "PTR: Prompt Tuning with Rules for Text Classification"}, {"paperId": "64a29bee2e1ad29547d590a3cc26274f4c537145", "title": "Not All Memories are Created Equal: Learning to Forget by Expiring"}, {"paperId": "f4566761fe39c4b5273d696d9bc3f4195c9325bb", "title": "Long-Span Summarization via Local Attention and Content Selection"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "4d59c17aa86bbbfafd07fe04f86b1b4ec9c942e3", "title": "Multimodal End-to-End Sparse Model for Emotion Recognition"}, {"paperId": "161321ef451d658d66b762cba5c202b12260220e", "title": "Data Augmentation for Abstractive Query-Focused Multi-Document Summarization"}, {"paperId": "4badd753be64c5c5b57dd2bb2e515fbe0c0720d8", "title": "SparseBERT: Rethinking the Importance Analysis in Self-attention"}, {"paperId": "1d7f3297924a9dd90cfc0df522ebe9138c28b46f", "title": "Amnesic Probing: Behavioral Explanation with Amnesic Counterfactuals"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "2c953a3c378b40dadf2e3fb486713c8608b8e282", "title": "Pretrained Transformers for Text Ranking: BERT and Beyond"}, {"paperId": "0ac7c7279f52e8cc98171254534276d9644cf92c", "title": "Multi-View Sequence-to-Sequence Models with Conversational Structure for Abstractive Dialogue Summarization"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6e3f8187f8fef3e11578a73f32da07d33dbf8235", "title": "DART: Open-Domain Structured Data Record to Text Generation"}, {"paperId": "94e586cd3342940422c0bd01ad7f252db9327394", "title": "Understanding Attention for Text Classification"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "3a5f479d15a3300a2fbfb868f80339431b452a5b", "title": "Sparse Text Generation"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "f9700e31a1d0ae34d4571ab056dfb268c1543349", "title": "SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization"}, {"paperId": "9e1241f017a627beca2542e378a88c642c32098b", "title": "Semantic Noise Matters for Neural Natural Language Generation"}, {"paperId": "a3ef6ee560e93e6f58be2b28f27aed0eb86dc463", "title": "Fine-tune BERT with Sparse Self-Attention Mechanism"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "d0086b86103a620a86bc918746df0aa642e2a8a3", "title": "Language Models as Knowledge Bases?"}, {"paperId": "af93e1accba69994cdc36254ef93584af307fd8a", "title": "Neural Text Summarization: A Critical Evaluation"}, {"paperId": "635cb6fb865e86c108c5d1d895aeac0e759eb199", "title": "MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance"}, {"paperId": "53a77e8f73f2ca422d6e38fa9ecc490231ac044c", "title": "Neural Text Generation with Unlikelihood Training"}, {"paperId": "335613303ebc5eac98de757ed02a56377d99e03a", "title": "What Does BERT Learn about the Structure of Language?"}, {"paperId": "cc27ec53160d88c25fc5096c0df65536eb780de4", "title": "Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model"}, {"paperId": "7cc730da554003dda77796d2cb4f06da5dfd5592", "title": "Hierarchical Transformers for Multi-Document Summarization"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "0a77aefc43614afd0f89829d87d582525ffc06c7", "title": "On Controllable Sparse Alternatives to Softmax"}, {"paperId": "c0199a7a37c22797c899571e51dba9690e606fa2", "title": "WikiHow: A Large Scale Text Summarization Dataset"}, {"paperId": "305b2cf37e5dece81e95c92883d5a6e28ac93b22", "title": "Don\u2019t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"}, {"paperId": "29de7c0fb3c09eaf55b20619bceaeafe72fd87a6", "title": "Hierarchical Neural Story Generation"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "531a7f2c659787165df4fd5b4580590b953448e4", "title": "The E2E Dataset: New Challenges For End-to-End Generation"}, {"paperId": "668db48c6a79826456341680ee1175dfc4cced71", "title": "Get To The Point: Summarization with Pointer-Generator Networks"}, {"paperId": "29e944711a354c396fad71936f536e83025b6ce0", "title": "Categorical Reparameterization with Gumbel-Softmax"}, {"paperId": "d1505c6123c102e53eb19dff312cb25cea840b72", "title": "Teaching Machines to Read and Comprehend"}, {"paperId": "c945743ef99b1c897eaa07ba276dcec0fcdbc0b4", "title": "A Model of Coherence Based on Distributed Sentence Representation"}, {"paperId": "34d7a07c493ca6336c92156806a2947e115caadc", "title": "METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments"}, {"paperId": "9d74eca00d4d0c4aa7c7369ae37d67498b37bf2f", "title": "Modeling Local Coherence: An Entity-Based Approach"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "984efc8932edb635d09ec1a5fd8fc1d1ceccad45", "title": "Catching the Drift: Probabilistic Content Models, with Applications to Generation and Summarization"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "ec936b808e0fab9281c050ad4010cddec92c8cbe", "title": "P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "250bc04cae3e973880bb9151c135e6a62de28384", "title": "EASE: Extractive-Abstractive Summarization End-to-End using the Information Bottleneck Principle"}, {"paperId": "b9a21c2bf389ba693cd4692a028c7f2821b1804e", "title": "Discourse-Aware Unsupervised Summarization for Long Scientific Documents"}, {"paperId": "2a7023e7d1dbd6ea0d98efd09a1f18d8599fe78f", "title": "PRIMER: Pyramid-based Masked Sentence Pre-training for Multi-document Summarization"}, {"paperId": null, "title": "2020)) we plot the attention matrix"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "86e60b61a0f481876b5d44cedfee11c16456d788", "title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations"}, {"paperId": null, "title": "2018), and commonly used CNN/DM (Hermann et al., 2015; See et al., 2017) news article summarization dataset with an \u201dInverted Pyramid\u201d (PurdueOWL, 2019) document structure (Kryscinski et al., 2019)"}, {"paperId": null, "title": "Journalism and journalistic writing: The inverted pyramid structure"}, {"paperId": "a70e48c119742cb69b1cdbd62e58a8a8d0d28a8e", "title": "Comparing Automatic and Human Evaluation of NLG Systems"}, {"paperId": "3d07b5087e53c6f7c228b3c7e769494527be228e", "title": "A Study of Translation Edit Rate with Targeted Human Annotation"}, {"paperId": "1daf375141571501ca8c30b62d7c14269d566762", "title": "From discourse structures to text summaries"}, {"paperId": null, "title": "Both models outperform Finetuned models (green) on ROUGE-1 and ROUGE-2 metrics (Figure 8-(a)&(b)). While the HierBlock models show consistent performance"}, {"paperId": "13167f9cd8c7906ca808b01d28dca6dd951da8a5", "title": "of the Association for Computational Linguistics"}]}