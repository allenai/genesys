{"paperId": "5ebcf1ed7765441dcc719c9f877d20a35224f340", "title": "Holmes: Benchmark the Linguistic Competence of Language Models", "abstract": "We introduce Holmes, a benchmark to assess the linguistic competence of language models (LMs) - their ability to grasp linguistic phenomena. Unlike prior prompting-based evaluations, Holmes assesses the linguistic competence of LMs via their internal representations using classifier-based probing. In doing so, we disentangle specific phenomena (e.g., part-of-speech of words) from other cognitive abilities, like following textual instructions, and meet recent calls to assess LMs' linguistic competence in isolation. Composing Holmes, we review over 250 probing studies and feature more than 200 datasets to assess syntax, morphology, semantics, reasoning, and discourse phenomena. Analyzing over 50 LMs reveals that, aligned with known trends, their linguistic competence correlates with model size. However, surprisingly, model architecture and instruction tuning also significantly influence performance, particularly in morphology and syntax. Finally, we propose FlashHolmes, a streamlined version of Holmes designed to lower the high computation load while maintaining high-ranking precision.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Holmes, a benchmark to assess the linguistic competence of language models (LMs) - their ability to grasp linguistic phenomena, is introduced and it is revealed that, aligned with known trends, their linguistic competence correlates with model size."}, "embedding": {"model": "specter_v2", "vector": [-0.0838519036769867, 0.8702201247215271, -0.3729887306690216, -0.3119775950908661, -0.28208398818969727, -0.2882823050022125, 0.5462660193443298, 0.11956150829792023, -0.5471324324607849, -0.38015615940093994, 0.5135157108306885, -0.612762987613678, 0.3473529517650604, 0.2658073604106903, 0.21466274559497833, 0.5441131591796875, -0.5464785099029541, 0.49126332998275757, -0.131515771150589, -0.329286128282547, 0.023011058568954468, -0.5036720633506775, -0.8816218376159668, 0.4422619640827179, 0.7182567119598389, 0.25948429107666016, 0.021409891545772552, 0.8063469529151917, -0.32544395327568054, 0.706123948097229, 0.34172630310058594, -0.42535150051116943, -0.14673848450183868, 0.3622187376022339, -0.31508156657218933, -0.34828171133995056, 0.6258306503295898, -0.5356894731521606, -0.2719935178756714, 0.793245255947113, -0.3791487514972687, 0.09095854312181473, 0.7920416593551636, -0.6391451358795166, -0.39632806181907654, 0.9190645217895508, 1.1651232242584229, 0.659187912940979, -0.040142763406038284, -0.11485548317432404, 1.3833943605422974, -1.464066743850708, 0.45533427596092224, 1.5978267192840576, 0.6531850099563599, 0.3926756978034973, -0.28442448377609253, -0.6781793832778931, 0.638268768787384, -0.10232024639844894, -0.6792792081832886, -0.858711302280426, -0.2544485032558441, -0.25923895835876465, 1.9130582809448242, -0.2966459393501282, -0.4107445776462555, 0.30493196845054626, -0.1560652256011963, 1.660062313079834, 0.5210327506065369, -0.8310044407844543, -0.1500556915998459, 0.3328621983528137, 0.7182900905609131, 0.9712111353874207, -0.28812485933303833, 0.5501232743263245, -1.0334758758544922, -0.24418896436691284, 0.23186710476875305, -0.5542553663253784, -0.5013742446899414, 0.15926457941532135, -0.9698818325996399, 0.7725912928581238, 0.187857523560524, 0.8380454778671265, -0.319705069065094, 0.32259106636047363, 0.438606858253479, 0.5543643832206726, -0.26343125104904175, 0.6233381628990173, -0.6223128437995911, 0.5011865496635437, -0.9071750640869141, 0.4373966157436371, 0.527099072933197, 0.8388184905052185, -0.32913315296173096, 0.4166664481163025, -1.0401155948638916, 0.05100657418370247, 1.6466869115829468, 0.33778148889541626, 0.5300045609474182, -1.147410273551941, 0.28130584955215454, -0.22908110916614532, 0.3618618845939636, -0.5904155373573303, -0.511979877948761, -0.20306912064552307, -0.2246679812669754, -1.3049335479736328, 0.1303531676530838, -0.010065795853734016, -0.46238529682159424, 0.8204717040061951, -0.09504842758178711, -0.28190645575523376, 0.3614548444747925, 0.3509645462036133, 1.0947691202163696, 0.49685823917388916, 0.5771970748901367, 0.029162902384996414, 0.9776424169540405, -0.48498159646987915, -0.5678733587265015, -1.1863763332366943, 1.2954108715057373, -0.4217716157436371, 0.38063207268714905, -0.16199460625648499, -1.194665789604187, -1.1902867555618286, -0.6072477102279663, 0.01302141509950161, -0.36699384450912476, 0.7926155924797058, 0.9458658695220947, 0.5458553433418274, -1.3550677299499512, 0.493179053068161, 0.04371532052755356, -0.11742718517780304, -0.1398596167564392, 0.10451070219278336, 0.11580754071474075, -0.5055385828018188, -1.1824536323547363, 0.4750173091888428, 0.4296859800815582, -0.737371563911438, -0.2472548484802246, -0.3738263249397278, -1.6307520866394043, -0.30894607305526733, 0.06331784278154373, -0.33550387620925903, 1.5711016654968262, 0.297482967376709, -1.2102454900741577, 0.7304196953773499, -0.6851667761802673, 0.32168424129486084, 0.03562066704034805, 0.053335029631853104, -0.7765166163444519, -0.4806954562664032, -0.14005577564239502, 0.930010199546814, 0.21883733570575714, -0.4786520302295685, -0.21437130868434906, 0.3635806143283844, -0.29705196619033813, -0.2412395179271698, 0.013340974226593971, 1.039106845855713, 0.2979446351528168, -0.19934412837028503, 0.4351285398006439, 0.7529404163360596, 0.06400784850120544, -0.18208613991737366, -0.33932918310165405, -1.1363716125488281, 0.4138707220554352, -0.3208431005477905, 1.2709356546401978, -0.7181198596954346, -0.8392045497894287, -0.4312911033630371, 0.057645611464977264, -0.008175707422196865, -0.7790678143501282, 0.5883569121360779, 0.0722300335764885, 0.6525099277496338, -0.30246883630752563, -1.057869791984558, 0.2793515622615814, -0.18180949985980988, -0.6194919347763062, -0.23666110634803772, 0.11149325966835022, 1.260783314704895, -0.7190555334091187, -0.29392769932746887, 0.17533926665782928, 0.18830034136772156, -0.8305109739303589, 1.0402873754501343, -0.48556673526763916, 0.15675601363182068, 0.21954524517059326, -0.15497536957263947, -0.22474683821201324, -0.295415461063385, 0.33193618059158325, -0.38027694821357727, -0.3254169821739197, 0.5944865345954895, -0.5417667031288147, 0.8955870866775513, -0.19350565969944, 0.277871310710907, -0.020719127729535103, -0.02299085259437561, 0.11875534802675247, 0.5605634450912476, -0.8668736815452576, -0.5214808583259583, 0.344730943441391, 0.8782703280448914, -0.25333938002586365, 0.24454621970653534, 0.6657676696777344, 0.7101973295211792, -0.23725908994674683, 0.2788558602333069, 0.5532636046409607, -0.5866312980651855, 0.48511916399002075, 0.13473035395145416, 0.5701435804367065, 0.29195284843444824, 0.7244125008583069, -0.4449670910835266, 0.5615761876106262, -0.26363906264305115, -0.13468307256698608, 0.5062803030014038, 0.5410173535346985, 0.4039568603038788, 0.13633549213409424, -0.6840746402740479, 0.07851987332105637, 0.08955496549606323, 0.4777866303920746, 1.8273087739944458, -0.08844345062971115, -0.2098073810338974, -0.7826939225196838, -0.31520938873291016, -0.23390692472457886, 0.7759608626365662, -0.3654877841472626, 0.012873819097876549, -0.8282487392425537, -0.47679898142814636, 0.9195910096168518, 0.4494000971317291, 0.707024872303009, -0.954035222530365, -0.477568656206131, -0.20129023492336273, 0.30975431203842163, -0.7783136963844299, -0.5122237205505371, 0.16119857132434845, -0.7890222668647766, -0.6067433953285217, 0.3524780571460724, -0.48213326930999756, -0.04763852804899216, -0.5694687366485596, 1.0567127466201782, 0.009480324573814869, 0.31895315647125244, 0.17203502357006073, 0.7812424302101135, -0.5836082100868225, -1.1841644048690796, -0.08518091589212418, 0.10580919682979584, -0.4304938018321991, 0.18363764882087708, 0.9829133749008179, 0.22958727180957794, 0.3050670921802521, -0.3902265131473541, 0.2683883011341095, 0.15870386362075806, 0.02363627403974533, 0.5486207008361816, -0.515379011631012, -0.055071745067834854, -1.2232272624969482, 1.1034109592437744, 0.3744584321975708, -0.3214819133281708, 0.7633479237556458, -0.6652966141700745, -0.23372051119804382, 0.539154589176178, -0.4509676992893219, -0.28897765278816223, -1.1055655479431152, 0.6738591194152832, 0.31934869289398193, -0.5160024166107178, 0.4538695216178894, 0.22884535789489746, 0.22853820025920868, 0.37984442710876465, 0.3453997075557709, 0.35229751467704773, -0.26406848430633545, 0.6611769795417786, -0.4799862802028656, 0.524811327457428, 0.19439703226089478, -0.07004948705434799, -0.4964555501937866, -0.5879958868026733, -0.7165500521659851, -0.33762866258621216, -0.17299112677574158, -0.013085777871310711, -0.19311025738716125, -0.0012321318499743938, -0.34303727746009827, -0.9291115999221802, -0.05149465054273605, -1.545046329498291, -0.4302349388599396, 0.23945647478103638, -0.2547692358493805, 0.0963834747672081, -0.8947365880012512, -1.4369699954986572, -0.4649253189563751, -0.3891313672065735, -1.2106503248214722, 0.7787781357765198, -0.32934999465942383, -0.8185797333717346, -0.4739402234554291, 0.17642928659915924, -0.25422024726867676, 1.0074875354766846, -0.7334833145141602, 1.3763904571533203, -0.3910125494003296, 0.24598585069179535, 0.028503384441137314, 0.12237733602523804, 0.45403853058815, -0.47596773505210876, 0.47487953305244446, -0.8579003214836121, 0.21573106944561005, 0.1530977189540863, -0.3239571452140808, -0.10214315354824066, 0.24186676740646362, 0.10536397993564606, -0.3167010545730591, -0.34282299876213074, -0.03302397578954697, 0.9713876247406006, -0.46839627623558044, -0.4002091586589813, -0.060500532388687134, 0.755723237991333, 1.0012197494506836, -0.3387629985809326, 0.2649291455745697, 0.680377185344696, 0.19722896814346313, 0.04218260571360588, 0.289889931678772, -0.14343419671058655, -0.42691734433174133, 0.8369264006614685, 1.735418677330017, 0.6221089959144592, -0.22850145399570465, -1.4068188667297363, 0.0783964991569519, -0.9991142153739929, 0.18317550420761108, 0.09969089180231094, 0.6937822699546814, 0.39849579334259033, -0.6228049993515015, -0.6176536083221436, 0.014554853551089764, 0.46724602580070496, 0.3875419497489929, -0.13101138174533844, -0.6289320588111877, -0.08661473542451859, 0.27779585123062134, -0.3604465425014496, 0.7503568530082703, -0.5941150188446045, 0.8167825937271118, 14.685972213745117, 0.7660154700279236, -0.10452622920274734, 0.5034623146057129, 0.7053003311157227, 0.8845995664596558, -0.505091667175293, -0.2520129382610321, -1.277832269668579, -0.3609580099582672, 1.344117522239685, 0.4096136689186096, 0.452320396900177, 0.13907262682914734, 0.05482717230916023, 0.10203888267278671, -0.7110342383384705, 0.5307388305664062, 0.49194544553756714, -1.167388916015625, 0.7599008679389954, 0.002702272729948163, 0.05150110647082329, 0.4444934129714966, 0.5642680525779724, 0.9755234122276306, 0.3577255308628082, -0.7139875888824463, 1.1065669059753418, 0.10335744172334671, 0.8168473839759827, 0.17372146248817444, 0.7751682996749878, 0.7966193556785583, -0.8310699462890625, 0.056979380548000336, -0.4008200168609619, -1.3046464920043945, 0.24150477349758148, -0.28762754797935486, -0.7369238138198853, -0.9012006521224976, -0.7292450666427612, 0.23698268830776215, -0.2215590924024582, 0.15217553079128265, -0.4545165002346039, 1.0294113159179688, 0.04701482504606247, -0.28816691040992737, -0.008302704431116581, 0.7382301688194275, 0.3264811635017395, 0.06671369075775146, -0.0313740000128746, -0.06490501761436462, 0.425278902053833, 0.34435465931892395, -0.5403732061386108, 0.42279329895973206, -0.46626585721969604, -0.3580113649368286, 0.18249516189098358, 0.5031206011772156, 0.3106308877468109, 0.18853937089443207, -0.19635088741779327, -0.2879656255245209, 0.6628480553627014, -0.09537464380264282, 0.29172080755233765, 0.35695192217826843, 0.2689880132675171, -0.4414127469062805, -0.4877470135688782, 0.29994213581085205, -0.28624963760375977, -0.3344947397708893, -0.543723464012146, -0.6780707836151123, 0.23594732582569122, -0.7654967308044434, -0.7390137314796448, 0.8306606411933899, -0.4120568335056305, -0.1858668327331543, 0.024997295811772346, -1.0915250778198242, -0.14649096131324768, 0.11113937199115753, -1.455607295036316, -0.9075703024864197, 0.1656343787908554, -0.40926268696784973, -0.19028343260288239, -0.026535382494330406, 1.5272767543792725, -0.34314966201782227, -0.2976227402687073, -0.13644471764564514, -0.1964348405599594, 0.18321046233177185, -0.2944689691066742, -0.9201062917709351, 0.7496359944343567, 0.10168641060590744, 0.18786610662937164, 0.4631076753139496, 0.03295427933335304, -0.1322818547487259, -0.6907225847244263, -0.03631577268242836, 1.205552101135254, -0.956926703453064, -0.3430211842060089, -0.4176468551158905, -1.047709584236145, 0.04482745751738548, 0.35087811946868896, -0.3506861627101898, 0.37879160046577454, -0.00673691974952817, -0.697006106376648, 0.32018744945526123, -0.8928504586219788, 0.12884633243083954, 0.6297307014465332, -0.8052874803543091, -0.8323687314987183, 0.011808239854872227, 0.45227211713790894, -0.8542057871818542, -0.3322526812553406, 0.03183501958847046, 0.08822093904018402, -0.0374605730175972, 0.29858335852622986, -0.8041832447052002, 0.464086651802063, 0.5876066088676453, -0.3860318660736084, -0.8671650886535645, -0.0020084576681256294, -0.8484786152839661, 0.10935380309820175, -0.27224496006965637, 1.3042863607406616, -0.6476428508758545, -0.16275650262832642, 1.2036089897155762, -0.07337947189807892, -0.3882538974285126, -0.6638017892837524, -0.09988140314817429, 0.21075589954853058, -0.5895509123802185, 0.4458821415901184, 0.03224356472492218, 0.011557620950043201, 0.2693274915218353, 0.9832155108451843, 0.5924162268638611, -0.3617009222507477, -0.6058080196380615, 0.22042886912822723, -0.5515401363372803, -0.0773656964302063, -0.851185142993927, -0.3015177547931671, -1.0751187801361084, 0.3348919749259949, -1.2642333507537842, 0.21408933401107788, -1.0817915201187134, -0.5856155753135681, 0.11914478987455368, -0.060875408351421356, 0.23310597240924835, 0.29652246832847595, -0.5857857465744019, -0.7076870203018188, -0.21505889296531677, -0.5636143088340759, 0.562412440776825, 0.7995854020118713, -0.5837788581848145, 0.21582630276679993, -0.2828086018562317, 0.03339419141411781, 0.4869843125343323, 0.38548287749290466, -0.2964080572128296, -0.4150793254375458, -1.4746315479278564, 0.15180572867393494, 0.18070408701896667, -0.22656573355197906, -0.5880993604660034, 0.8402055501937866, 0.5130664110183716, -0.40588071942329407, 0.23625631630420685, 0.04858233407139778, -0.3461550772190094, -0.4426117241382599, 0.5936978459358215, -0.9568535089492798, 0.45363274216651917, 0.3478440046310425, -0.9162968397140503, -0.4797297418117523, 0.40696030855178833, -0.2519853413105011, -0.8613863587379456, -0.7696165442466736, 0.09348156303167343, -0.8214979767799377, 0.4621409475803375, -0.307552307844162, -0.3578051030635834, -1.2399582862854004, -0.06454020738601685, 0.03516556695103645, 0.30418410897254944, -0.12255483120679855, 0.7774024605751038, 0.537032425403595, -0.5709556341171265, 0.012525733560323715, 0.48633256554603577, 0.16826732456684113, -0.2732609510421753, 0.08514507114887238, 0.5227455496788025, -0.6171831488609314, 0.675544798374176, 0.4920949339866638, 0.28159070014953613, -0.8666253089904785, -0.41580119729042053, 0.5269651412963867, -0.35443970561027527, 0.0017089508473873138, 1.1994857788085938, -0.21659474074840546, -1.5136297941207886, 0.20576409995555878, -1.5122625827789307, -0.6992086172103882, -0.4168344736099243, 0.5374543070793152, 0.25860103964805603, 0.14783479273319244, -0.4476459324359894, -0.40764495730400085, -0.03653934970498085, 0.05597876012325287, -0.6025887727737427, 0.17678982019424438, 0.2000335305929184, -0.5302609801292419, 0.47681596875190735, 0.5122199058532715, -0.478007048368454, -0.34552523493766785, -0.5082201361656189, 0.289632648229599, 0.31935620307922363, 0.33482280373573303, -0.4685090482234955, -0.3674200773239136, 0.7038992047309875, 0.07723857462406158, 0.1469287872314453, -0.5218003392219543, -0.2688777446746826, 0.30750876665115356, 0.9055461287498474, 0.6138596534729004, -0.3986023962497711, -0.7335755825042725, 1.486910104751587, 1.2918075323104858, -1.27878999710083, -0.1290387511253357, -0.18005944788455963, -0.7236998081207275, 0.9551722407341003, 0.22121089696884155, 0.21875835955142975, 1.0745368003845215, -0.3019563555717468, 0.5183983445167542, -0.2277454286813736, -0.8389958143234253, 0.1463792473077774, 1.0693439245224, 0.8513033986091614, 1.1151950359344482, 0.7340987324714661, -0.10858207941055298, 0.9548083543777466, -0.22523538768291473, 0.12240641564130783, 0.37167999148368835, 0.7296896576881409, -0.6019493341445923, -0.03704033046960831, 0.20536744594573975, 0.6591328382492065, -0.1694665104150772, -0.9254247546195984, -0.24082712829113007, 0.8174740076065063, 0.20323297381401062, 0.7926126718521118, 0.2617023289203644, 0.37718838453292847, 0.5828941464424133, 0.6405876278877258, 0.14661531150341034, -0.9125272631645203, -0.532624363899231, -0.5811893343925476, -0.11616671085357666, -0.17277440428733826, -0.19189979135990143, -0.5041788220405579, -0.4317326247692108, -0.04905809834599495, 0.2316775918006897, -0.010569402016699314, 0.26023727655410767, 1.0797308683395386, 0.5205355286598206, -0.2156018167734146, -0.8165422677993774, -0.41404545307159424, -0.6956333518028259, -1.1788064241409302, 0.12901371717453003, -0.794309139251709, -0.3372609317302704, -0.47451260685920715, -0.5100263357162476, -0.6004591584205627]}, "authors": [{"authorId": "3470765", "name": "Andreas Waldis"}, {"authorId": "102376484", "name": "Yotam Perlitz"}, {"authorId": "41019330", "name": "Leshem Choshen"}, {"authorId": "2282504397", "name": "Yufang Hou"}, {"authorId": "69033154", "name": "Iryna Gurevych"}], "references": [{"paperId": "af0d10afb526eb8e2418a1da796fe8d81a14a687", "title": "Lossless and Near-Lossless Compression for Foundation Models"}, {"paperId": "7f94b69cac02fdd113385950297fcdbfbe3413ee", "title": "Robust Pronoun Fidelity with English LLMs: Are they Reasoning, Repeating, or Just Biased?"}, {"paperId": "ca757b42595d40dd0683d508e2485e030bc4eb54", "title": "LAB: Large-Scale Alignment for ChatBots"}, {"paperId": "a073a5b5b97416b19ae70e4183d43296aa164c52", "title": "Large Language Models for Psycholinguistic Plausibility Pretesting"}, {"paperId": "798feda076ad710df65d509a7884bd15937c8056", "title": "Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs"}, {"paperId": "163ffbc1b347432638d71c5e1f14710213fe5f88", "title": "Dive into the Chasm: Probing the Gap between In- and Cross-Topic Generalization"}, {"paperId": "8dce168f723158b771b526401113064c36fc875e", "title": "State of What Art? A Call for Multi-Prompt LLM Evaluation"}, {"paperId": "5c7a21e9262b62f0a27fefdc8b1270dfdcbd3912", "title": "The Truth is in There: Improving Reasoning in Language Models with Layer-Selective Rank Reduction"}, {"paperId": "dac7158541d30f9a1eb663bc8dc21f5475d47043", "title": "Instruction-tuning Aligns LLMs to the Human Brain"}, {"paperId": "dff9b29918369f2ce7c06d13258ffad5c644788a", "title": "ComPEFT: Compression for Communicating Parameter Efficient Updates via Sparsification and Quantization"}, {"paperId": "d2ea161e6b2114529d875d16cfaad4c824e17a8c", "title": "Orca 2: Teaching Small Language Models How to Reason"}, {"paperId": "aa41cb578ddef7658a92cb9d6dd60529720fcc74", "title": "How to Handle Different Types of Out-of-Distribution Scenarios in Computational Argumentation? A Comprehensive and Fine-Grained Field Study"}, {"paperId": "3e4afde5a9de2c1801da99b8aff5ae05923f256b", "title": "Are Emergent Abilities in Large Language Models just In-Context Learning?"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787", "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"}, {"paperId": "fbd2c8089870814449f9254a711041bbae145a82", "title": "How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources"}, {"paperId": "ce913026f693101e54d3ab9152e107034d81fce1", "title": "Holistic Evaluation of Language Models"}, {"paperId": "de7fcd50cf893d96f039f21f990c3174715c3767", "title": "What about \u201cem\u201d? How Commercial Machine Translation Fails to Handle (Neo-)Pronouns"}, {"paperId": "546d0624adfc6e18fb87d8cc77e7705bb9ea7445", "title": "LIMA: Less Is More for Alignment"}, {"paperId": "131f499e4d3503da93022d07fcf804a18483bea9", "title": "WizardLM: Empowering Large Language Models to Follow Complex Instructions"}, {"paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8", "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"}, {"paperId": "478ec7a8001d46cde90395c4a9d9ffdec59d5ce3", "title": "Prompting Language Models for Linguistic Structure"}, {"paperId": "d15091e73f7295ba8c0bdbabe0b7188307c96039", "title": "GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-distribution Generalization Perspective"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "157ff71fb4818aab80ef4b54187251bff23449c6", "title": "Predicting Fine-Tuning Performance with Probing"}, {"paperId": "bd1331b233e84bab7eba503abc60b31ac08e7881", "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models"}, {"paperId": "06d7cb8c8816360feb33c3367073e0ef66d7d0b0", "title": "Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks"}, {"paperId": "df2113c867c4836a12dad9c697d11654539ae35e", "title": "Metaphors in Pre-Trained Language Models: Probing and Generalization Across Datasets and Languages"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "7bebb48d34c219b119ca2d4ffc97d7fd4940c35c", "title": "On the data requirements of probing"}, {"paperId": "f4df78183261538e718066331898ee5cad7cad05", "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"}, {"paperId": "972706306f85b1bfb40c7d35c796ad5174eb0c9c", "title": "DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing"}, {"paperId": "8436897e713c2242d6291df9a6a33c1544d4dd39", "title": "Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models"}, {"paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea", "title": "Training Verifiers to Solve Math Word Problems"}, {"paperId": "95c20f35d352f23b19c378c0758b8dc1d7622872", "title": "On Aspects of the Theory of Syntax"}, {"paperId": "c4a24f0a480b15254b84b1f5620a6c1fc34f4c72", "title": "Probing Multilingual Language Models for Discourse"}, {"paperId": "1c0f8a6b8e6f4cc6fc81c4019fc07a2e5ec17107", "title": "Probing for Bridging Inference in Transformer Language Models"}, {"paperId": "b4ab9b198ed140928751143af68c6b45adf396ca", "title": "A multilabel approach to morphosyntactic probing"}, {"paperId": "807600ef43073cd9c59d4208ee710e90cf14efa8", "title": "BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models"}, {"paperId": "a978fcb10817abe8bc91ab2ba0c0bb4605add1d9", "title": "Discourse Probing of Pretrained Language Models"}, {"paperId": "3dcfa05a1c162e6cab927c5b08d0444f7b6691f4", "title": "Probing Classifiers: Promises, Shortcomings, and Advances"}, {"paperId": "1d7f3297924a9dd90cfc0df522ebe9138c28b46f", "title": "Amnesic Probing: Behavioral Explanation with Amnesic Counterfactuals"}, {"paperId": "31392ad8722d9c66181b621936e2013199e02edc", "title": "When Do You Need Billions of Words of Pretraining Data?"}, {"paperId": "b042444e4e9501ab2fcae6b1f6b9d834146b3fc9", "title": "Do Language Embeddings capture Scales?"}, {"paperId": "1c6f94fb3d888167355afb580f04d55cd517ebc6", "title": "On the Interplay Between Fine-tuning and Sentence-Level Probing for Linguistic Knowledge in Pre-Trained Transformers"}, {"paperId": "3c4d3b7085ad5f02bc732b489ace590a7bbd58c9", "title": "Intrinsic Probing through Dimension Selection"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "cae24695391e7ef8e7d351a8c922b4016fbfbd02", "title": "Spying on Your Neighbors: Fine-grained Probing of Contextual Embeddings for Information about Surrounding Words"}, {"paperId": "3aaa8aaad5ef36550a6b47d6ee000f0b346a5a1f", "title": "Perturbed Masking: Parameter-free Probing for Analyzing and Interpreting BERT"}, {"paperId": "175d5bd966e874ec36e93c880a74164af8da6c84", "title": "Bridging Anaphora Resolution as Question Answering"}, {"paperId": "738c6d664aa6c3854e1aa894957bd595f621fc42", "title": "Information-Theoretic Probing for Linguistic Structure"}, {"paperId": "f4b585c9a79dfce0807b445a09036ea0f9cbcdce", "title": "Information-Theoretic Probing with Minimum Description Length"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "c44120f765fc43994c5cfb4e12e4f62999efeae6", "title": "How Context Affects Language Models' Factual Predictions"}, {"paperId": "5e0cffc51e8b64a8f11326f955fa4b4f1803e3be", "title": "oLMpics-On What Language Model Pre-training Captures"}, {"paperId": "5a2263092f49540fd0e049050a96882ff29b00c3", "title": "BLiMP: The Benchmark of Linguistic Minimal Pairs for English"}, {"paperId": "207da6d2c07289bf72a2b5974bb3f011ebb5dd0d", "title": "Adversarial NLI: A New Benchmark for Natural Language Understanding"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "199ff73d2f728e997f860b62a2322823d3e3d9e8", "title": "Designing and Interpreting Probes with Control Tasks"}, {"paperId": "d0086b86103a620a86bc918746df0aa642e2a8a3", "title": "Language Models as Knowledge Bases?"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "0c4f8dd922530471410e43ae13d9f2a3e572cb1a", "title": "Empirical Linguistic Study of Sentence Embeddings"}, {"paperId": "eaea866271ce0bdf1b9bf8e11581a66ec58806c6", "title": "DisSent: Learning Sentence Representations from Explicit Discourse Relations"}, {"paperId": "455a8838cde44f288d456d01c76ede95b56dc675", "title": "A Structural Probe for Finding Syntax in Word Representations"}, {"paperId": "97906df07855b029b7aae7c2a1c6c5e8df1d531c", "title": "BERT Rediscovers the Classical NLP Pipeline"}, {"paperId": "e2587eddd57bc4ba286d91b27c185083f16f40ee", "title": "What do you learn from context? Probing for sentence structure in contextualized word representations"}, {"paperId": "d9f6ada77448664b71128bb19df15765336974a6", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"}, {"paperId": "1c3e6aeacb4d30c4e94ad3cd981fa5f38f1a5a79", "title": "Fine-Grained Temporal Relation Extraction"}, {"paperId": "e71aae34bdbb193952b8d20fea0c7da98fa39ac6", "title": "Decomposing Generalization: Models of Generic, Habitual, and Episodic Statements"}, {"paperId": "c5489d244bfc1e9b0d8c94bf6dd774ee1aca2def", "title": "Identifying and Controlling Important Neurons in Neural Machine Translation"}, {"paperId": "305b2cf37e5dece81e95c92883d5a6e28ac93b22", "title": "Don\u2019t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"}, {"paperId": "7fedd981f2769bd009f749a3dff7044d8378c9b4", "title": "Under the Hood: Using Diagnostic Classifiers to Investigate and Improve how Language Models Track Agreement Information"}, {"paperId": "c41516420ddbd0f29e010ca259a74c1fc2da0466", "title": "What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties"}, {"paperId": "c8f4ddc811f96aa21697347fa422cc52b22c0ef0", "title": "Neural-Davidsonian Semantic Proto-role Labeling"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "642c4615b2cedff69db871ddda138761c44b88dc", "title": "Neural Models of Factuality"}, {"paperId": "3a8dbf4e89dacfde96da118534401d6971e56dba", "title": "Enhanced Word Representations for Bridging Anaphora Resolution"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "263210f256603e3b62476ffb5b9bbbbc6403b646", "title": "What do Neural Machine Translation Models Learn about Morphology?"}, {"paperId": "3aa52436575cf6768a0a1a476601825f6a62e58f", "title": "Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies"}, {"paperId": "d821ce08da6c0084d5eacbdf65e25556bc1b9bc3", "title": "Does String-Based Neural MT Learn Source Syntax?"}, {"paperId": "00dc74ca39fc6630bef824a4768dd214bbd81927", "title": "Universal Decompositional Semantics on Universal Dependencies"}, {"paperId": "e44da7d8c71edcc6e575fa7faadd5e75785a7901", "title": "Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks"}, {"paperId": "8f8c0588a7126a03a366b6f30000543ae1211b79", "title": "N-gram language models for massively parallel devices"}, {"paperId": "3183f4e1144b21c248fd1716880e55ea9c1b2c18", "title": "SemEval 2016 Task 11: Complex Word Identification"}, {"paperId": "edf9b7367660d7f8255633717bf050f000a7c8fd", "title": "Introducing the LCC Metaphor Datasets"}, {"paperId": "178cc2fc3062b1aa789418448d197440349fdaa0", "title": "The GUM corpus: creating multilayer resources in the classroom"}, {"paperId": "d15e9a0aa68aeb1cdb8429d9db0d343178f2d377", "title": "What\u2019s in an Embedding? Analyzing Word Embeddings through Multilingual Evaluation"}, {"paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5", "title": "GloVe: Global Vectors for Word Representation"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "08994baceec0965f2f5009ecc701fc0e7a442965", "title": "Processing"}, {"paperId": "d1d1004488231e2d26922016f252a85a3dc41388", "title": "*SEM 2012 Shared Task: Resolving the Scope and Focus of Negation"}, {"paperId": "417a7adad2ff42090b41884c26d9d4a0a12aa127", "title": "A review corpus annotated for negation, speculation and their scope"}, {"paperId": "c33fe3ea3ee2b8241c972b74661f52dcab7bbbf3", "title": "A method for linguistic metaphor identification : from MIP to MIPVU"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "8ea8da551ef6b1c909ca5b37ba94be4cae02e9ac", "title": "SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations Between Pairs of Nominals"}, {"paperId": "4571ca5cd6ed29bebfdaf44cf4c0ca1ab79b9a28", "title": "The BioScope corpus: annotation for negation, uncertainty and their scope in biomedical texts"}, {"paperId": "626517aded5ce3f90c51023f255546aaaf678b89", "title": "A Clustering Approach for Nearly Unsupervised Recognition of Nonliteral Language"}, {"paperId": "07a78850c0c2ff11acf21fccca40bfcb79da282b", "title": "Building a Discourse-Tagged Corpus in the Framework of Rhetorical Structure Theory"}, {"paperId": "68c03788224000794d5491ab459be0b2a2c38677", "title": "WordNet: A Lexical Database for English"}, {"paperId": "c8c09d729ca002fdee9341ba884035954a97c955", "title": "A new readability yardstick."}, {"paperId": null, "title": "Free dolly: Introducing the world\u2019s first truly open instruction-tuned llm"}, {"paperId": "5f58a1c84a4c251ae85f9beab39992c3d76f94c9", "title": "It Is Not Easy To Detect Paraphrases: Analysing Semantic Similarity With Antonyms and Negation Using the New SemAntoNeg Benchmark"}, {"paperId": "30f233eecca2239ee1dd754914324092e53f8f19", "title": "Evaluation Examples are not Equally Informative: How should that change NLP Leaderboards?"}, {"paperId": "b122dabd76d5578dad1bacd69ce749730ffd6021", "title": "Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)"}, {"paperId": "4e38f52fdcbb3341b9c07d29016cab1a0b84912f", "title": "BabyBERTa: Learning More Grammar With Small-Scale Child-Directed Language"}, {"paperId": null, "title": "ELECTRA: pre-training text encoders as discriminators rather than generators"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "c25f5efa9e2d6ca04388052959d73e80163556f6", "title": "7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "753ac88f46fe056db5b6a7d37014f95160873f42", "title": "Diagnostic Classifiers Revealing how Neural Networks Process Hierarchical Structure"}, {"paperId": "82cf69e48ede65b9d1f419da786c0349342d449d", "title": "A Gold Standard Dependency Corpus for English"}, {"paperId": null, "title": "Ontonotes release 5.0"}, {"paperId": "531b5f071c0c7e75108684d9896dba49f5917a7a", "title": "The Penn Discourse Treebank 2.0 Annotation Manual"}, {"paperId": "decd9bc0385612bdf936928206d83730718e737e", "title": "Distributional Structure"}, {"paperId": null, "title": "2023. UL2: unifying language learning paradigms"}, {"paperId": null, "title": "2022. Probing as quantifying inductive bias"}, {"paperId": null, "title": "2024. Dissociating language and thought in large language models"}, {"paperId": null, "title": "task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval 2012) , pages 265\u2013274, Montr\u00e9al, Canada"}, {"paperId": null, "title": "2022. Decomposing and recomposing event structure"}, {"paperId": null, "title": "2023. MTEB: Massive text embedding benchmark"}, {"paperId": null, "title": "Workshop on Semantic Evaluation"}, {"paperId": null, "title": "Re-nard"}, {"paperId": null, "title": "Pro-ceedings of the 2018 Conference on Empirical Meth-ods"}, {"paperId": null, "title": "Lacroix"}, {"paperId": null, "title": "2023. Prompting is not a substitute for probability measurements in large language models"}, {"paperId": null, "title": "Linguistics (Volume 1: Long Papers)"}, {"paperId": null, "title": "5085\u20135109, Abu Dhabi, United Arab Emirates"}, {"paperId": null, "title": ". Mix-tral of experts"}]}