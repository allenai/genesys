{"paperId": "97f7a0c4be425f0019f7fca603d3dfd522da025a", "title": "PrE-Text: Training Language Models on Private Federated Data in the Age of LLMs", "abstract": "On-device training is currently the most common approach for training machine learning (ML) models on private, distributed user data. Despite this, on-device training has several drawbacks: (1) most user devices are too small to train large models on-device, (2) on-device training is communication- and computation-intensive, and (3) on-device training can be difficult to debug and deploy. To address these problems, we propose Private Evolution-Text (PrE-Text), a method for generating differentially private (DP) synthetic textual data. First, we show that across multiple datasets, training small models (models that fit on user devices) with PrE-Text synthetic data outperforms small models trained on-device under practical privacy regimes ($\\epsilon=1.29$, $\\epsilon=7.58$). We achieve these results while using 9$\\times$ fewer rounds, 6$\\times$ less client computation per round, and 100$\\times$ less communication per round. Second, finetuning large models on PrE-Text's DP synthetic data improves large language model (LLM) performance on private data across the same range of privacy budgets. Altogether, these results suggest that training on DP synthetic data can be a better option than training a model on-device on private distributed data. Code is available at https://github.com/houcharlie/PrE-Text.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Across multiple datasets, training small models with PrE-Text synthetic data outperforms small models trained on-device under practical privacy regimes and suggests that training on DP synthetic data can be a better option than training a model on-device on private distributed data."}, "embedding": {"model": "specter_v2", "vector": [0.43801411986351013, 0.6008837223052979, -0.9267412424087524, 0.20320160686969757, -0.7678740620613098, -0.40800657868385315, 0.902824342250824, -0.14390285313129425, -0.5013310313224792, -0.16817371547222137, 0.16697412729263306, -0.632596492767334, 0.3537731468677521, 0.1835297793149948, -0.6214787364006042, 0.23893071711063385, -1.0226378440856934, 0.044788628816604614, -0.5783653855323792, 0.09884503483772278, -0.45822253823280334, -0.45308157801628113, -0.6687347888946533, 0.2711213529109955, 0.33262181282043457, 0.5353437066078186, -0.4994966983795166, 1.307233214378357, 0.27264609932899475, 0.13862477242946625, 0.27650201320648193, -0.3990214169025421, 0.7899956107139587, 0.33745402097702026, -0.4750029444694519, 0.2516777217388153, -0.249642476439476, -0.619687557220459, -1.0071614980697632, 0.6835486888885498, 0.1680484265089035, 0.1293376237154007, 0.05599205195903778, -0.8029971122741699, -0.4774840176105499, 0.5054435133934021, 0.04915972426533699, 0.531825065612793, 0.06857898086309433, -0.1911444514989853, 0.9985173940658569, -1.0132852792739868, 0.3998963534832001, 1.2978596687316895, 0.23950058221817017, 0.4873347878456116, -0.5891101360321045, -0.6220000386238098, -0.058068301528692245, -0.2175324559211731, -0.8985152244567871, -0.3712448477745056, -0.5433914661407471, -0.008010913617908955, 1.0636515617370605, -0.13566580414772034, -0.45794081687927246, 0.9668318629264832, -0.4049280285835266, 1.440109133720398, 0.389751136302948, -0.7088376879692078, -0.27509424090385437, 0.5085755586624146, -0.24883927404880524, 0.5670896768569946, -0.1891692727804184, 0.40155985951423645, -1.0627537965774536, -0.7192003726959229, -0.33940374851226807, 0.04064510762691498, -0.09092477709054947, -0.5055426955223083, 0.05994705483317375, 0.6802961230278015, -0.26418358087539673, 0.23806676268577576, 0.07045905292034149, 0.5139510631561279, 0.5801402926445007, 0.5240172743797302, 0.5097750425338745, -0.2149331271648407, -0.13926956057548523, -0.4161756634712219, -0.8564912676811218, 0.39663636684417725, 0.3531075716018677, 0.5615500211715698, -0.3125441372394562, -0.5141682624816895, -0.7121821641921997, -0.035089947283267975, 1.1995594501495361, 0.20489604771137238, 0.5355643033981323, -0.4831233620643616, 0.7625938057899475, -1.1254751682281494, 0.35278835892677307, -0.38802361488342285, 0.3932880759239197, 0.11606179922819138, -0.835874080657959, -1.335116982460022, -0.5709350109100342, -0.5434672236442566, -0.5954086184501648, 0.5735176205635071, -0.3291425406932831, 0.19796310365200043, 0.3533540964126587, 0.12041238695383072, 0.35990920662879944, 0.764477014541626, -0.006581912748515606, 0.2380901277065277, 0.7102359533309937, -0.6356939077377319, -0.2574196457862854, -0.8597995638847351, 0.8871222734451294, -0.18059749901294708, 0.6063395738601685, -0.15157698094844818, -1.3391048908233643, -0.5224155783653259, -0.7641101479530334, 0.1992066353559494, -0.5020413398742676, 0.3358830213546753, 0.9607053995132446, 1.2326768636703491, -0.7936093807220459, 0.9716218113899231, -0.4878380000591278, -0.5216293931007385, 0.7734558582305908, 0.40136662125587463, -0.07788529992103577, -0.5831941962242126, -1.2072193622589111, 0.06843915581703186, 0.16281971335411072, -1.1454720497131348, -0.008529155515134335, -0.5352271199226379, -0.8007134199142456, -0.2314448058605194, 0.2329535186290741, -0.11130651086568832, 1.4284613132476807, 0.42466485500335693, -1.249222993850708, 1.3150724172592163, -0.13471709191799164, -0.1216946542263031, 1.3065072298049927, -0.14600518345832825, -0.8427571654319763, -0.3230573534965515, -0.5016255378723145, 0.03454398363828659, 0.4193417429924011, -0.19228054583072662, 0.07722006738185883, 0.2145044058561325, -0.23331370949745178, -0.38239631056785583, -0.4281037747859955, 0.7470272779464722, -0.6316789984703064, -0.4286532700061798, -0.3026866018772125, 0.15638959407806396, -0.14156442880630493, 0.07247783988714218, -0.9267972707748413, -0.695375382900238, 1.360107183456421, -0.18970409035682678, 0.9208889007568359, -1.1650030612945557, -0.9721086621284485, 0.39453715085983276, -0.04895451292395592, 0.28010013699531555, -0.4573797881603241, 1.0356048345565796, -0.3131953477859497, 0.8732871413230896, -0.22374503314495087, -1.574123740196228, 0.3549021780490875, -0.29735058546066284, -0.7307978868484497, 0.26813337206840515, -0.3008806109428406, 0.9960542917251587, -0.30325791239738464, 0.3319864273071289, -0.3946961462497711, -0.006456231698393822, -1.2739143371582031, 1.2492108345031738, -0.4764864146709442, 0.5021243691444397, -0.12244647741317749, -0.48155784606933594, 0.7512339949607849, -0.4460337460041046, 0.3987376093864441, 0.07270091027021408, 0.24427205324172974, 0.3255405128002167, -0.6095526218414307, 1.2511379718780518, -0.4466984272003174, 0.4047938585281372, 0.27249014377593994, -0.5883672833442688, -0.1701842099428177, 0.5080880522727966, 0.1581990122795105, 0.08592437952756882, 0.40110546350479126, 0.25161150097846985, -0.6636998057365417, -0.1813424527645111, 0.5431276559829712, 0.970328152179718, -0.13830730319023132, 1.0717631578445435, -0.047137241810560226, -0.04519302397966385, 0.241294726729393, 0.46167075634002686, 0.6404591202735901, 0.11279670149087906, 0.02763935551047325, 0.24063120782375336, 0.24797508120536804, -1.4082224369049072, -0.4955124855041504, 0.8586615920066833, 0.6299796104431152, 0.6060876250267029, 0.36633235216140747, -0.518399715423584, -0.3687468469142914, -0.12084158509969711, 0.45149946212768555, 1.1882838010787964, 0.14459609985351562, -0.5590275526046753, -0.670641303062439, -0.589514434337616, 0.5634028315544128, -0.1635507196187973, -0.5243887305259705, -0.05887073278427124, -0.27665236592292786, -1.472057819366455, 1.1198451519012451, -0.2681342661380768, 0.8900599479675293, -0.19034674763679504, 0.14566829800605774, -0.9440954327583313, 0.33384981751441956, -0.8997822999954224, -0.6592127084732056, -0.07145103067159653, 0.1713288575410843, 0.21457761526107788, -0.05595584586262703, 0.26676028966903687, 0.31911328434944153, -0.6123524308204651, 0.27696073055267334, -0.16451263427734375, -0.40601933002471924, 0.48802879452705383, 0.3943444788455963, -0.38116681575775146, -1.2754085063934326, 0.33931031823158264, 0.17346030473709106, 0.28639674186706543, 0.013067725114524364, 0.055685050785541534, -0.04823991656303406, -0.12444586306810379, -0.6591194868087769, -0.05651650205254555, 0.20369473099708557, -0.11426488310098648, -0.17983807623386383, -0.2640032470226288, -0.4087679088115692, -1.671286702156067, 1.3446353673934937, -0.3408636450767517, -0.0371481291949749, 0.2981412708759308, -0.8380985260009766, -0.21071134507656097, 0.48780199885368347, -1.1142299175262451, -0.21320189535617828, -1.3580007553100586, -0.08432745933532715, -0.22945037484169006, -0.07870519161224365, -0.0012464983155950904, 0.437926709651947, -0.03977373242378235, 0.4123949706554413, 0.6972143650054932, 0.6291416883468628, -0.236668661236763, 0.7489902377128601, -0.22648575901985168, 0.13517148792743683, -0.4612795114517212, 0.7751244902610779, 0.07286864519119263, -0.2545734643936157, -0.4744328260421753, -0.09790398925542831, 0.1370617002248764, -0.03904574364423752, 0.17719049751758575, -0.13185739517211914, -0.6018136143684387, -1.2885239124298096, -0.04782751947641373, -0.7748902440071106, -0.5962307453155518, 0.013575851917266846, -0.187620148062706, -0.5095060467720032, -0.489837646484375, -1.3676365613937378, -0.4976118803024292, -0.6665617227554321, -0.8966197371482849, 0.38180312514305115, -0.1686047613620758, -0.5815795063972473, -0.47211161255836487, -0.23426233232021332, -0.14991724491119385, 0.7887788414955139, -0.6075531840324402, 0.7578313946723938, 0.08189620077610016, -0.18660785257816315, -0.6255275011062622, -0.12642623484134674, 0.2753674387931824, -0.4193874001502991, 0.40596339106559753, -1.101780652999878, -0.36587971448898315, -0.8371178507804871, -0.6439585089683533, -0.049541037529706955, 0.11460117250680923, 1.4963184595108032, -0.21447688341140747, -0.7582221627235413, 0.8609947562217712, 1.1718437671661377, -0.7842467427253723, 0.0299067385494709, -0.2245142012834549, 0.6586818099021912, 0.16645725071430206, -0.43536263704299927, 1.3920965194702148, -0.023996638134121895, 0.2909378707408905, -0.555582582950592, -0.309055358171463, 0.37464287877082825, -0.9923747777938843, 0.5568068623542786, 0.5468862652778625, 0.7341362833976746, -0.43834948539733887, -0.8012206554412842, 0.4098650813102722, -1.0657395124435425, -0.7330314517021179, 0.6288607120513916, 0.9838022589683533, 0.29430481791496277, -0.037022463977336884, 0.08448057621717453, -0.24621380865573883, 0.23760434985160828, 0.6724992394447327, -0.37337982654571533, -0.9522513747215271, 0.09315992891788483, 0.7444664835929871, 0.7409840822219849, 0.12337411940097809, -0.3886904716491699, 0.1102176234126091, 14.62431812286377, 1.1145492792129517, -0.030888186767697334, 0.9438140988349915, 0.8305002450942993, 0.07004807144403458, -0.5404698848724365, -0.263918936252594, -0.7715715169906616, 0.41602450609207153, 1.4040427207946777, -0.44077882170677185, 0.8422157764434814, 0.1404762715101242, -0.01869562268257141, -0.011654917150735855, -0.3418937623500824, 0.8765759468078613, 0.18522371351718903, -1.3142565488815308, -0.12608155608177185, 0.7125234603881836, 0.6439124345779419, 0.74895179271698, 1.51470148563385, 0.5661861300468445, 0.7674140334129333, -0.5194586515426636, 0.5592032074928284, -0.048604678362607956, 1.6286678314208984, -0.20822863280773163, 0.11618039011955261, 1.1605520248413086, -0.35953986644744873, -0.27295276522636414, -0.46539339423179626, -0.7858487367630005, 0.09660867601633072, 0.07898528128862381, -0.7590280771255493, -0.2943806052207947, -0.2293013334274292, 0.5722379684448242, 0.3700142502784729, -0.18890981376171112, 0.17606773972511292, 0.7262662649154663, -0.23528358340263367, 0.11203698068857193, -0.12409242242574692, 0.7176706790924072, 0.014500977471470833, -0.07743972539901733, 0.18623024225234985, -0.4397103190422058, -0.04546327888965607, 0.4911397099494934, -1.0412899255752563, 0.05878309905529022, -0.5936614274978638, -0.4877256155014038, 0.076801598072052, 0.4433836042881012, 1.0768499374389648, 0.39431750774383545, -0.5973385572433472, 0.9076733589172363, 0.26204344630241394, 0.0018151308177039027, -0.00928954966366291, 0.35025110840797424, 0.6074820756912231, -0.12114714086055756, -0.2911800742149353, 0.4066305160522461, -0.10675127059221268, -0.6460737586021423, -0.5658875703811646, -0.49586737155914307, 0.47449567914009094, -0.3648737668991089, -0.853417158126831, 0.5723809599876404, -0.42015722393989563, -0.5431959629058838, 0.10901381075382233, -0.3151662349700928, -0.13157418370246887, 1.0109589099884033, -1.0372322797775269, -0.762591540813446, 0.8313281536102295, -0.225469172000885, -0.8866665959358215, 0.08507516980171204, 1.4487032890319824, 0.2311064749956131, -0.34298738837242126, 0.669775664806366, 0.7600308060646057, 0.0049171107821166515, -0.053618818521499634, -0.40668389201164246, 1.5513626337051392, 0.35974693298339844, -0.1973162442445755, 0.25190725922584534, -0.2053336799144745, 0.008119543083012104, -1.03761887550354, -0.15303245186805725, 0.5417908430099487, -1.1150543689727783, -0.21471260488033295, -1.230338215827942, -0.3142666518688202, 0.38846278190612793, 0.2639923095703125, 0.17865972220897675, 0.6034759879112244, -0.048891209065914154, -0.5012205839157104, 0.05737829953432083, -1.1042226552963257, 0.3297417461872101, 0.5660344958305359, -1.2566944360733032, 0.45107656717300415, 0.26661384105682373, 0.10968723148107529, -0.9892241954803467, -0.6912317276000977, -0.030792729929089546, 0.19063878059387207, -0.12790337204933167, 0.6223597526550293, -0.4437793791294098, 0.6701102256774902, 1.299054503440857, -0.07178950309753418, -0.6459770202636719, 0.7634825110435486, -1.6097979545593262, -0.26703378558158875, 0.018139032647013664, 0.5779998898506165, -0.4809008240699768, 0.9171207547187805, 0.9264641404151917, 1.1888128519058228, -0.5347470045089722, -0.2652477025985718, -0.1668746918439865, 0.09129661321640015, -0.7303842902183533, 0.45916667580604553, 0.14689990878105164, -0.1068602129817009, -0.6930181384086609, -0.14117345213890076, 0.5615440607070923, -0.04634064808487892, -0.7993668913841248, 1.1313072443008423, 0.050479911267757416, -0.649326741695404, -0.043371982872486115, 0.004221945069730282, -1.6160833835601807, 0.08742743730545044, -1.4147555828094482, -0.4496147632598877, -0.016317786648869514, -0.44492825865745544, -0.16632767021656036, 0.3110945224761963, -0.40626636147499084, 0.6644929051399231, -0.26897406578063965, -0.12306366860866547, -0.5979823470115662, 0.010447201319038868, 0.742152750492096, 0.7353994846343994, -0.42804819345474243, 0.17576803267002106, 0.5236090421676636, 0.05323686823248863, -0.18327473104000092, 0.5193827152252197, -0.514032781124115, -0.8732082843780518, -0.7223866581916809, 0.0038079519290477037, -0.023802246898412704, -0.040226083248853683, -0.544249415397644, 0.28635504841804504, 0.08307943493127823, -0.46434319019317627, 0.2821342647075653, 0.10318906605243683, -0.8785195350646973, -0.3737502098083496, 0.4696849286556244, -0.8784537315368652, 0.12248057126998901, -0.18368111550807953, -0.4195755124092102, 0.2707345485687256, 0.8246976733207703, 0.045930441468954086, -0.6695082783699036, -0.20131134986877441, 1.1090469360351562, -0.4009816348552704, 0.18976782262325287, -0.14730225503444672, -0.05345560982823372, -1.163330316543579, -0.7762383222579956, -0.3479204475879669, 0.1843387335538864, -0.06380653381347656, 0.94017094373703, -0.1553918421268463, -0.8235303163528442, -0.007349277380853891, 0.7689975500106812, 0.039543017745018005, -0.2697363793849945, 0.8526346683502197, 0.29421281814575195, -0.35669201612472534, 0.22236216068267822, 0.5670040249824524, 0.5891898274421692, -1.0488172769546509, 0.08325918018817902, 0.629810631275177, -0.7052310109138489, -0.2855106592178345, 1.253400206565857, -0.6300177574157715, -1.1593985557556152, 0.11866024136543274, -0.555518627166748, 0.1326444149017334, -0.7463904023170471, 0.364326149225235, 0.0171019546687603, 0.13847459852695465, 0.09743703901767731, -0.3315880000591278, -0.0933728963136673, 0.12648852169513702, -0.5574015974998474, 0.5614442229270935, -0.5005664229393005, -0.1388864815235138, 0.3280380368232727, 1.4659743309020996, 0.2956775724887848, -0.751110851764679, -1.0917327404022217, -0.5589478015899658, -0.5177144408226013, -0.07983016967773438, -0.2652328610420227, -0.32288679480552673, 0.6971713304519653, 0.5838497281074524, 0.448866605758667, -0.07108712196350098, 0.002394094131886959, 0.8224328756332397, 0.3185533881187439, 0.058192409574985504, -0.5632590651512146, -0.5176962614059448, 0.6953274607658386, 0.6724132895469666, -0.9241606593132019, 0.34643083810806274, -0.5189563035964966, -0.5341841578483582, 0.5899458527565002, 0.00131341558881104, 0.4210983216762543, 1.3302083015441895, 0.08755998313426971, 0.08405875414609909, 0.4674210548400879, -0.9970352053642273, -0.01186953391879797, 0.6699129343032837, 0.6292375922203064, 0.36821115016937256, 0.8621054291725159, 0.057035524398088455, 0.5864684581756592, 0.012948419898748398, 0.28130483627319336, 0.5056310892105103, 0.7089666128158569, 0.39623093605041504, -0.9236800074577332, -0.002172039821743965, 0.8648487329483032, -1.1177104711532593, -0.28396284580230713, 0.09986389428377151, 0.24790959060192108, 0.5820837616920471, 0.5402235388755798, 0.6839883923530579, -0.4408923387527466, 0.3215727210044861, 0.0609835647046566, 0.32449817657470703, -0.7494822144508362, -0.010094384662806988, -0.7975228428840637, -0.46143484115600586, 0.06259890645742416, 0.26542049646377563, -0.37422192096710205, -0.21991285681724548, -1.125429391860962, 0.9040119647979736, 0.058065369725227356, 0.18652166426181793, 1.1861056089401245, 0.8448470830917358, -0.3191473186016083, 0.5833477973937988, -0.21844640374183655, -0.7459744811058044, -0.5316054224967957, -0.6859187483787537, -0.1338767111301422, -0.2171647548675537, 0.34141814708709717, -0.1856536865234375, -0.4777313470840454]}, "authors": [{"authorId": "1443436264", "name": "Charlie Hou"}, {"authorId": "1519979046", "name": "Akshat Shrivastava"}, {"authorId": "2304748832", "name": "Hongyuan Zhan"}, {"authorId": "2304748670", "name": "Rylan Conway"}, {"authorId": "2241614580", "name": "Trang Le"}, {"authorId": "2063995456", "name": "Adithya Sagar"}, {"authorId": "2288256947", "name": "Giulia Fanti"}, {"authorId": "2178345339", "name": "Daniel Lazar"}], "references": [{"paperId": "be6c26ba4a0e1e821e260fe05f7c9366099f1d7f", "title": "Delving into Differentially Private Transformer"}, {"paperId": "6a28f9390a2fa99e593b2b3efeccce4abec52631", "title": "Prompt Public Large Language Models to Synthesize Data for Private On-device Applications"}, {"paperId": "a27d2f743dab4ae009beec52f2d61e0be885a7bd", "title": "Differentially Private Synthetic Data via Foundation Model APIs 2: Text"}, {"paperId": "ec072b1382e8da7480737a8cc5b9ca98dda30c9a", "title": "Machine Unlearning of Pre-trained Large Language Models"}, {"paperId": "f648d5bff46b180c633c812c71aa1cfafd7576dc", "title": "Privacy-Preserving Instructions for Aligning Large Language Models"}, {"paperId": "27f8c420f0967eba781f0e1c03db7363570b66af", "title": "Private Fine-tuning of Large Language Models with Zeroth-order Optimization"}, {"paperId": "0399533de2d1d21f456663d1bd5355c8b3c32a58", "title": "Unlearn What You Want to Forget: Efficient Unlearning for LLMs"}, {"paperId": "836e3069a83f455f916114e7265e00187e511838", "title": "Locally Differentially Private Document Generation Using Zero Shot Prompting"}, {"paperId": "57fdfe4bcc5fa6f0af8d2fe176620f8b05fd0d0b", "title": "Little is Enough: Improving Privacy by Sharing Labels in Federated Semi-Supervised Learning"}, {"paperId": "61f46dbe000930877c5da4d8628c63ce1ce2df82", "title": "Profit: Benchmarking Personalization and Robustness Trade-off in Federated Prompt Tuning"}, {"paperId": "f0676c081f12c9395cd0e920d137a90a9ceb2c4a", "title": "Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation"}, {"paperId": "385c2ee0bf829676d1a5aacfc697fc6a9d245ed5", "title": "DP-Forward: Fine-tuning and Inference on Language Models with Differential Privacy in Forward Pass"}, {"paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05", "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"}, {"paperId": "0b0debb710366cdff461938c80763eace1651af6", "title": "Code Llama: Open Foundation Models for Code"}, {"paperId": "187c849426586dbc3fdc56fef7d61c81ed14ca9b", "title": "ACCESS: Advancing Innovation: NSF\u2019s Advanced Cyberinfrastructure Coordination Ecosystem: Services & Support"}, {"paperId": "f5e670c22d1125de557aaa79f721fcfb557fcb36", "title": "Towards Federated Foundation Models: Scalable Dataset Pipelines for Group-Structured Learning"}, {"paperId": "2922768fd451ecdb45f48c1a83eb57f54a91221b", "title": "Textbooks Are All You Need"}, {"paperId": "edd348b6e78e1114b8f00328c4770bf74950c77d", "title": "GPT-FL: Generative Pre-trained Model-Assisted Federated Learning"}, {"paperId": "cd0db1266961a9cd3e61aeab6456d35c32d77a39", "title": "Harnessing large-language models to generate private synthetic text"}, {"paperId": "1d2967d96b5e2daa172cb052b22c094beeec3068", "title": "Federated Learning of Gboard Language Models with Differential Privacy"}, {"paperId": "322351e6efc401114f308047f34580d5b8cf5490", "title": "Differentially Private Synthetic Data via Foundation Model APIs 1: Images"}, {"paperId": "2f2a430ba6c93bcfaf4818316ff8a27b1e034b1a", "title": "Flocks of Stochastic Parrots: Differentially Private Prompt Learning for Large Language Models"}, {"paperId": "865662f736e0b9cd5ddbabc23294f68ff3484138", "title": "Can Public Large Language Models Help Private Cross-device Federated Learning?"}, {"paperId": "4c4722d3767dae6bc00b7de3e3fa160caaffe483", "title": "Privacy-Preserving Prompt Tuning for Large Language Model Services"}, {"paperId": "5db3257a61d86f302767ae1f21d6fd30567f12e5", "title": "Towards Building the Federated GPT: Federated Instruction Tuning"}, {"paperId": "6e41a4cbb34c4d403efb73d74f5be5556b1f13d6", "title": "Privacy-Preserving In-Context Learning for Large Language Models"}, {"paperId": "be6acb6f594b52a6b4d81c96fe84a14b654e148c", "title": "Choosing Public Datasets for Private Machine Learning via Gradient Subspace Distance"}, {"paperId": "5b0f2ff37a977fd4b0c845b27726b65682bf8ac6", "title": "How to DP-fy ML: A Practical Guide to Machine Learning with Differential Privacy"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "75e852a362b8c4fd5115590ab174a2185128d7c0", "title": "Why Is Public Pretraining Necessary for Private Model Training?"}, {"paperId": "6d3c136719c49e922d462d3b9fa63ceb074dbae5", "title": "Privately Customizing Prefinetuning to Better Match User Data in Federated Learning"}, {"paperId": "4d86e6724f969769517c8f64589eb28d463118ae", "title": "Can 5th Generation Local Training Methods Support Client Sampling? Yes!"}, {"paperId": "e65b346d442e9962a4276dc1c1af2956d9d5f1eb", "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions"}, {"paperId": "6f4cc536f9ed83d0dbf7e919dc609be12aa0848a", "title": "Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor"}, {"paperId": "ccbb76dc7996f370043b34e32844b1b18a586227", "title": "Privacy Adhering Machine Un-learning in NLP"}, {"paperId": "7932b714e2ae1def5828df52b97f1decb9bebd32", "title": "Considerations for Differentially Private Learning with Large-Scale Public Pretraining"}, {"paperId": "ade1259366e35a55f13e5588b4291085552f5821", "title": "Learning to Generate Image Embeddings with User-Level Differential Privacy"}, {"paperId": "4aa6ae7d867ee9a08d3f81adfb851e115e23b8b0", "title": "FedTune: A Deep Dive into Efficient Federated Fine-Tuning with Pre-trained Transformers"}, {"paperId": "58996964dbcd15045b66201c2b850b5570ba74cb", "title": "Synthetic Text Generation with Differential Privacy: A Simple and Practical Recipe"}, {"paperId": "af710ada8965f274e810053f716f966627a136d9", "title": "Differentially Private Language Models for Secure Data Sharing"}, {"paperId": "9dea2c15a044a3c83d0d66b9c3daa91d457d905f", "title": "Differentially Private Diffusion Models"}, {"paperId": "91fb2254c5942048425e642c8a6c8d400006150e", "title": "Knowledge Unlearning for Mitigating Privacy Risks in Language Models"}, {"paperId": "ba2b6a94d4fb018c9eab252a34d80787ae962f46", "title": "Differentially Private Optimization on Large Model at Small Cost"}, {"paperId": "8319aa06ed1bdc7e455bbc29c07a409f76250a6d", "title": "PromptFL: Let Federated Participants Cooperatively Learn Prompts Instead of Models \u2013 Federated Learning in Age of Foundation Model"}, {"paperId": "29fca3f4ae956ebe4ef43284a7916c729ce54fb9", "title": "Federated Learning via Decentralized Dataset Distillation in Resource-Constrained Edge Environments"}, {"paperId": "acba7ea5905901944027b1bab14d5c6059edf062", "title": "Federated Select: A Primitive for Communication- and Memory-Efficient Federated Learning"}, {"paperId": "20d0509531baed437aa08202a3bbc60181fdb6b3", "title": "Training Large-Vocabulary Neural Language Models by Private Federated Learning for Resource-Constrained Devices"}, {"paperId": "a78b3d5e72d70c78bbe0ad9cc3f8899edb6a0a35", "title": "Communication Acceleration of Local Gradient Methods via an Accelerated Primal-Dual Algorithm with Inexact Prox"}, {"paperId": "051c2cfb399d71dfc91459cad5be404ee4568f9d", "title": "When Does Differentially Private Learning Not Suffer in High Dimensions?"}, {"paperId": "e73d51188ca5d71e183be4a828796d0a98ff7520", "title": "Automatic Clipping: Differentially Private Deep Learning Made Easier and Stronger"}, {"paperId": "e437ed4992d2bf70ed5372897a54c4b937bdd607", "title": "Algorithms for bounding contribution for histogram estimation under user-level privacy"}, {"paperId": "750331fa07beb042acb462283e18d05d756824e3", "title": "Individual Privacy Accounting for Differentially Private Stochastic Gradient Descent"}, {"paperId": "69218bdd534e334cbc45aa25dbe125c3c5db44f2", "title": "Pretrained Models for Multilingual Federated Learning"}, {"paperId": "6233582e55c20598c738e94ee99c66c219eb796b", "title": "On the Privacy Properties of GAN-generated Samples"}, {"paperId": "d96aa291c0c56b9522cd7c901f1acd43818f1db3", "title": "FedAdapter: Efficient Federated Learning for Modern NLP"}, {"paperId": "6fcbb819920ce206269105d1524489a33518d06d", "title": "Recovering Private Text in Federated Learning of Language Models"}, {"paperId": "c21d3ac8a235e2ee5f783c4c8a146f6fd3ae12e5", "title": "Provably Confidential Language Modelling"}, {"paperId": "11154b89486fd7b41bfab5f8b0e19756c488523e", "title": "Dataset Distillation by Matching Training Trajectories"}, {"paperId": "e2c9a43281daed4543f299564fd46dde10b5e57c", "title": "ProxSkip: Yes! Local Gradient Steps Provably Lead to Communication Acceleration! Finally!"}, {"paperId": "62d17b6f6ad77fd71ef9954c7784700d5e316f1f", "title": "What Does it Mean for a Language Model to Preserve Privacy?"}, {"paperId": "7164b7d3972e9066759db79b75cb64408d262b47", "title": "Towards Sparse Federated Analytics: Location Heatmaps under Distributed Differential Privacy with Secure Aggregation"}, {"paperId": "ac67e66ae50de8f8e5da84654f7e6de0e94503c7", "title": "Don't Generate Me: Training Differentially Private Generative Models with Sinkhorn Divergence"}, {"paperId": "56874f9aef515902c5a49d84d10f629f8dcd5f40", "title": "Differentially Private Fine-tuning of Language Models"}, {"paperId": "6a758ada5c48a2ae48d1392d12ce4f4e1977e0dd", "title": "Large Language Models Can Be Strong Differentially Private Learners"}, {"paperId": "1a522f304731611fccbb76c9e323a4a8e458335c", "title": "The Skellam Mechanism for Differentially Private Federated Learning"}, {"paperId": "bea1187a1f8a68f1a93f0c2fa10d31f93a30f84e", "title": "Opacus: User-Friendly Differential Privacy Library in PyTorch"}, {"paperId": "a55005bc10fadb264fb0d1e3b04aac64ac8eeebf", "title": "Personalized Federated Learning for Heterogeneous Clients with Clustered Knowledge Transfer"}, {"paperId": "56708004ada46632aa25d1d7a3f2d5b92b54166f", "title": "Communication-efficient federated learning via knowledge distillation"}, {"paperId": "5c0e39934e1b57937e8702a47888b2404ae1345e", "title": "FedChain: Chained Algorithms for Near-optimal Communication Cost in Federated Learning"}, {"paperId": "2cbf8688cbaddb28eac94fafb01251178f664dc7", "title": "Large-Scale Differentially Private BERT"}, {"paperId": "412569269f13540080faa81620ea67eeb72f76b2", "title": "A Field Guide to Federated Optimization"}, {"paperId": "8f435293ddeaa91819e4c9c5c0e0180750fe44cc", "title": "Large Scale Private Learning via Low-rank Reparametrization"}, {"paperId": "38fca90fef15b226dbae8db408c5efe8066dde1c", "title": "Federated Learning with Buffered Asynchronous Aggregation"}, {"paperId": "dfd8fc9966ca8ec5c8bdc2dfc94099285f0e07a9", "title": "On a Utilitarian Approach to Privacy Preserving Text Generation"}, {"paperId": "425a4a9c0598e4101ca2f2b930f5c6986ce40a99", "title": "Privacy Regularization: Joint Privacy-Utility Optimization in LanguageModels"}, {"paperId": "373a183de7c4ffad1375e3db5f1bb1c33e64a755", "title": "Shuffled Model of Federated Learning: Privacy, Accuracy and Communication Trade-Offs"}, {"paperId": "234904518b6bc3db7fbbef2dd481332ed71a009e", "title": "Practical and Private (Deep) Learning without Sampling or Shuffling"}, {"paperId": "d8dc171b192edda57ec67ceac3062bf91ad00320", "title": "Efficient Algorithms for Federated Saddle Point Optimization"}, {"paperId": "23099e2bf6e6675caf021fd1337e0988f8ed7d40", "title": "The Distributed Discrete Gaussian Mechanism for Federated Learning with Secure Aggregation"}, {"paperId": "5c8c2a2c725f2f9da095045e35cf0f7322c360d5", "title": "Differentially Private Learning Needs Better Features (or Much More Data)"}, {"paperId": "2695fae0a6650d08766397955371c460d7b7a168", "title": "Training Production Language Models without Memorizing User Data"}, {"paperId": "8e990e779cd70b70e316b129f334edfb8aa89af1", "title": "Differentially Private Language Models Benefit from Public Pre-training"}, {"paperId": "ca68bd8927f84c7fd204e6d5f9f465c5da479ef3", "title": "Dimension Independence in Unconstrained Private ERM via Adaptive Preconditioning"}, {"paperId": "34ceeaef8f0569ca107b72622c14cbec15bf778f", "title": "Private Post-GAN Boosting"}, {"paperId": "4b6661347d5b58250130b89145dbd34ce310f2a0", "title": "Tackling the Objective Inconsistency Problem in Heterogeneous Federated Optimization"}, {"paperId": "465c52d9aa7b451a6ced3fafb377bac1b7da1ca1", "title": "Bypassing the Ambient Dimension: Private SGD with Gradient Subspace Identification"}, {"paperId": "053f4d6715a4dba6f8103456fc1bb5fd6a5266c4", "title": "Ensemble Distillation for Robust Model Fusion in Federated Learning"}, {"paperId": "5a94bcc168330318d3020aa4d41bd73cf68ab285", "title": "Dataset Condensation with Gradient Matching"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "07912741c6c96e6ad5b2c2d6c6c3b2de5c8a271b", "title": "Advances and Open Problems in Federated Learning"}, {"paperId": "7306c2579f49d3ac3a5377d9b594788711cb3f57", "title": "Generative Models for Effective ML on Private, Decentralized Datasets"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "fc7b1823bd8b59a590d0bc33bd7a145518fd71c5", "title": "SCAFFOLD: Stochastic Controlled Averaging for Federated Learning"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "93d63ec754f29fa22572615320afe0521f7ec66d", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "cd24b3d31f1fd9f77e3a90eab832361fceded8f9", "title": "DP-CGAN: Differentially Private Synthetic Data and Label Generation"}, {"paperId": "1284ed4bf6a043ecf8cebca09e4811f1e3b83b65", "title": "Federated Optimization in Heterogeneous Networks"}, {"paperId": "90d1be1c16e0df7d7a0e8839ec34171c13265678", "title": "cpSGD: Communication-efficient and differentially-private distributed SGD"}, {"paperId": "44058a625cb64c311043145655645d8206e272c2", "title": "Scalable Private Learning with PATE"}, {"paperId": "ed46493d568030b42f0154d9e5bf39bbd07962b3", "title": "Learning Differentially Private Recurrent Language Models"}, {"paperId": "231af7dc01a166cac3b5b01ca05778238f796e41", "title": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium"}, {"paperId": "a97dc4eba33a2756d73178cd945f465fb4e193b1", "title": "Practical Secure Aggregation for Federated Learning on User-Held Data"}, {"paperId": "e70b9a38fcf8373865dd6e7b45e45cca7ff2eaa9", "title": "Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data"}, {"paperId": "e9a986c8ff6c2f381d026fe014f6aaa865f34da7", "title": "Deep Learning with Differential Privacy"}, {"paperId": "d1dbf643447405984eeef098b1b320dee0b3b8a7", "title": "Communication-Efficient Learning of Deep Networks from Decentralized Data"}, {"paperId": "a90b92746d08f596f46cab8f5b772bf60740f23e", "title": "Analyze gauss: optimal bounds for privacy-preserving principal component analysis"}, {"paperId": "2618dbd8bc6bc401fbc202342c00cd2ffefcbe4f", "title": "Differential Privacy"}, {"paperId": "2370e2ba6ab1c40d5879f0ebb0a53946f85dc06b", "title": "Effectively Using Public Data in Privacy Preserving Machine Learning"}, {"paperId": "db34d89d0e3a45096eab417c979aaafe62696682", "title": "A Unified Fast Gradient Clipping Framework for DP-SGD"}, {"paperId": "3954e59506fd6a1e199f69e254fc2d1c25e7450d", "title": "Reduce Communication Costs and Preserve Privacy: Prompt Tuning Method in Federated Learning"}, {"paperId": "d668f12be54174141e6197fad737006b7b0c0571", "title": "PyTorch"}, {"paperId": "798f537bef58a80514c397c17eb37af56765944b", "title": "Distributed Distillation for On-Device Learning"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "We could run out of data to train ai language programs"}, {"paperId": null, "title": "Stanford al-paca: An instruction-following llama model"}, {"paperId": null, "title": "Reddit to give openai access to its data in licensing deal"}, {"paperId": null, "title": "PrE-Text: Training Language Models on Private Federated Data in the Age of LLMs"}, {"paperId": null, "title": "speedtest.net. United states median country speeds october 2023"}, {"paperId": null, "title": "Exclusive: Reddit in ai content licensing deal with google"}, {"paperId": null, "title": "OpenAI"}, {"paperId": null, "title": "Private overparameterized linear regression without suffering in high dimensions"}, {"paperId": null, "title": "For data-guzzling ai companies, the internet is too small"}, {"paperId": null, "title": "Dpzero: Dimension-independent and differentially private zeroth-order optimization"}, {"paperId": null, "title": "Tensorflow"}]}