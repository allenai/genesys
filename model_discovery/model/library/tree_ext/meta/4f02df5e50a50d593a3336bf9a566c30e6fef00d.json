{"paperId": "4f02df5e50a50d593a3336bf9a566c30e6fef00d", "title": "A Unified Implicit Attention Formulation for Gated-Linear Recurrent Sequence Models", "abstract": "Recent advances in efficient sequence modeling have led to attention-free layers, such as Mamba, RWKV, and various gated RNNs, all featuring sub-quadratic complexity in sequence length and excellent scaling properties, enabling the construction of a new type of foundation models. In this paper, we present a unified view of these models, formulating such layers as implicit causal self-attention layers. The formulation includes most of their sub-components and is not limited to a specific part of the architecture. The framework compares the underlying mechanisms on similar grounds for different layers and provides a direct means for applying explainability methods. Our experiments show that our attention matrices and attribution method outperform an alternative and a more limited formulation that was recently proposed for Mamba. For the other architectures for which our method is the first to provide such a view, our method is effective and competitive in the relevant metrics compared to the results obtained by state-of-the-art transformer explainability methods. Our code is publicly available.", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A unified view of attention-free layers of Mamba, RWKV, and various gated RNNs is presented, formulating such layers as implicit causal self-attention layers and providing a direct means for applying explainability methods."}, "embedding": {"model": "specter_v2", "vector": [0.40469154715538025, 0.8542776107788086, -0.2540039122104645, -0.05436829850077629, 0.3176482915878296, 0.177205890417099, 0.7476204633712769, -0.30208921432495117, -0.27714109420776367, -0.16108128428459167, 0.6418209671974182, -0.16521918773651123, 0.4348750114440918, 0.0016925856471061707, -0.039091892540454865, -0.05359182506799698, -0.9322789311408997, 0.19308699667453766, 0.07298869639635086, -0.37568092346191406, 0.23052553832530975, -0.696213960647583, -0.8672952651977539, 0.010301873087882996, -0.3645448088645935, 0.6208080053329468, 0.7354190349578857, 1.1507872343063354, -0.4041607975959778, 1.0356354713439941, 0.6069525480270386, -0.23749162256717682, -0.11913509666919708, -0.6560537219047546, -0.42684534192085266, -0.2283317595720291, 0.3163186311721802, -0.5420326590538025, -0.8713287115097046, 0.42023539543151855, -0.40520545840263367, 0.007786528207361698, 0.36256253719329834, -0.8526228666305542, -0.15741439163684845, 1.2069401741027832, 0.8382426500320435, 1.1649948358535767, -0.47375354170799255, -0.6754119992256165, 1.6395405530929565, -1.084306240081787, 0.020662985742092133, 1.4852991104125977, 0.4529297351837158, 0.5295150279998779, -0.2917880713939667, -0.5605123043060303, 1.2226191759109497, 0.4487747848033905, -0.4816509187221527, -0.21156549453735352, 0.1641600877046585, -0.09501372277736664, 1.8300446271896362, -0.30616897344589233, 0.052351564168930054, 1.0076440572738647, 0.04053445905447006, 1.0044338703155518, 0.013635254465043545, -0.7942414283752441, -0.31534144282341003, 0.005570136476308107, 0.5263883471488953, 0.7131286263465881, -0.28704968094825745, 0.475744366645813, -0.8683801889419556, -0.10066954046487808, 0.9502655267715454, 0.04980676248669624, -0.2245863825082779, 0.0462174192070961, -0.1209602952003479, 1.0315815210342407, 0.39355841279029846, 0.8055363893508911, -0.41852399706840515, 0.9999104738235474, 0.4540679454803467, 0.17406906187534332, -0.38655394315719604, 0.10069544613361359, -0.2092972844839096, 0.5898122787475586, -0.6584893465042114, 0.08821950852870941, -0.13391424715518951, 0.6664788126945496, -0.03152807801961899, 0.9667574763298035, -0.013097891584038734, 0.00905888807028532, 1.7172738313674927, -0.2457665354013443, 0.7641027569770813, -0.5283893346786499, -0.27841347455978394, -0.7613147497177124, -0.08170845359563828, -1.0799704790115356, -0.09230386465787888, -0.38440367579460144, -0.8456302285194397, -1.2854809761047363, -0.7164128422737122, 0.8359936475753784, -1.0124619007110596, 0.8496170043945312, -0.7647059559822083, 0.3243248164653778, -0.33636605739593506, 0.16296106576919556, 0.6071218252182007, 0.5045713782310486, 0.6561071276664734, -0.11091554909944534, 0.8375102281570435, -0.6933392286300659, -1.0037018060684204, -1.01859712600708, 0.1607876867055893, 0.24820925295352936, -0.15815573930740356, -0.3890702426433563, -1.0055756568908691, -1.3392457962036133, -0.8828184008598328, 0.3043697774410248, -0.06263371556997299, -0.09230628609657288, 1.1007269620895386, -0.03050212934613228, -1.0651434659957886, 0.8836713433265686, -0.4941082298755646, -0.141244038939476, 0.1944870501756668, 0.16182227432727814, 0.44950640201568604, 0.22133924067020416, -1.3473330736160278, 0.5992323756217957, 0.21745094656944275, -0.19453586637973785, -0.7482646107673645, -0.5896733999252319, -1.1404978036880493, -0.2035549134016037, -0.17679785192012787, -0.5901893377304077, 1.3221161365509033, -0.5624357461929321, -0.8744266033172607, 0.7081561088562012, -0.5040804743766785, -0.4681051969528198, -0.03470887243747711, -0.08467301726341248, -0.46083760261535645, -0.26093152165412903, -0.07510783523321152, 0.4322705566883087, 0.6845626831054688, -0.37771230936050415, -0.19201378524303436, 0.1556604951620102, -0.5071943402290344, -0.48038744926452637, -0.23822973668575287, 0.7935706377029419, -0.20689710974693298, -0.3505582809448242, 0.39442703127861023, 0.7869685292243958, -0.08216356486082077, -0.5426205992698669, -0.21978795528411865, -0.757763683795929, 0.580548107624054, -0.3056391477584839, 1.2106362581253052, -0.5817556381225586, -0.6802566051483154, -0.20681604743003845, 0.04422719404101372, -0.3024606704711914, -0.714526355266571, 0.42114904522895813, -1.0756185054779053, 0.501635730266571, -0.14071384072303772, -0.8311201333999634, -0.4694864749908447, -0.0960935726761818, -1.1246601343154907, -0.1077473983168602, 0.23801018297672272, 0.8673045635223389, -0.9311562776565552, 0.03545477241277695, 0.18905992805957794, 0.27823373675346375, -0.7067888975143433, 1.5790205001831055, 0.15281373262405396, -0.050365984439849854, -0.1132655069231987, -0.5121286511421204, -0.09267736226320267, -0.49195143580436707, 0.4353158175945282, -0.4225079119205475, -0.07434787601232529, 0.7797821760177612, -0.14720399677753448, 1.0125250816345215, -0.3505004644393921, 1.0204004049301147, -0.35191893577575684, -0.9844845533370972, 0.49617576599121094, 0.4979358911514282, -0.3645011782646179, -0.6746971607208252, 0.48500704765319824, 0.18611189723014832, -0.44604459404945374, 0.414625883102417, 0.44296911358833313, 0.6990801095962524, -0.12198477983474731, 0.012448337860405445, 0.8900868892669678, 0.053828127682209015, 0.11515069752931595, 0.6371617913246155, 0.9396434426307678, 0.5533486008644104, 0.5206400752067566, -0.025113947689533234, 0.11630593240261078, -0.8946939706802368, 0.1254263073205948, 0.6236480474472046, 0.6735295057296753, 0.9925019145011902, 0.1451544165611267, -0.8528313636779785, -0.54801344871521, 0.26435452699661255, 0.6415499448776245, 1.0909297466278076, -0.2615601122379303, -0.04705739766359329, -0.4056819975376129, 0.32527682185173035, -0.35878995060920715, 0.24410903453826904, -0.7028443813323975, -0.320993572473526, -0.5631807446479797, -0.9633257389068604, 0.7193677425384521, 0.7165300846099854, 0.6521066427230835, -1.004406452178955, -0.4555928111076355, 0.2352653592824936, 0.1384248286485672, -0.8774189352989197, -0.053899090737104416, 0.7295783162117004, -0.78350430727005, -0.10882273316383362, 0.31188255548477173, 0.06750112771987915, -0.060241665691137314, -0.5102663040161133, 1.044854998588562, -0.19708071649074554, -0.5380317568778992, 0.18904739618301392, 0.5532126426696777, -0.7249354720115662, -0.5963813662528992, -0.013645905070006847, 0.178567036986351, -0.13881021738052368, 0.30680587887763977, 0.18669326603412628, -0.12712615728378296, 0.045410312712192535, -0.2238450050354004, 0.1731465607881546, -0.15014994144439697, 0.09900728613138199, 0.42126598954200745, -0.3988445997238159, 0.3037814795970917, -0.925209105014801, 0.35054102540016174, 0.027512427419424057, -0.31112927198410034, -0.22996509075164795, -0.6600103378295898, -0.37875962257385254, 0.09450243413448334, -0.4991828501224518, -0.1403460055589676, -1.0189893245697021, 0.4896721839904785, -0.6860664486885071, -0.4145289957523346, 0.21727119386196136, 0.27842244505882263, 0.3990062177181244, -0.08128537982702255, 0.3715503215789795, 0.040110982954502106, 0.06473397463560104, 0.3504684865474701, -1.1324090957641602, 0.6680524349212646, 0.8331555128097534, 0.22900740802288055, -0.05303088575601578, -0.06780339032411575, -0.8305907249450684, -0.6683343052864075, -0.38832685351371765, -0.2663135826587677, -0.31805887818336487, 0.4274621903896332, -0.8540973663330078, -0.9107269048690796, -0.0054599810391664505, -0.9742262959480286, -0.3450811803340912, 0.4789133369922638, -0.1753566414117813, -0.3870190978050232, -1.0012104511260986, -1.2450623512268066, -1.030603051185608, -0.4072684645652771, -0.16115769743919373, -0.3217082917690277, 0.227433979511261, -0.5591527819633484, -0.8751236796379089, -0.004294259008020163, -0.4004982113838196, 1.1096888780593872, -0.2823997735977173, 0.7616220116615295, -0.06296420097351074, -0.4077504277229309, 0.11855142563581467, 0.351239949464798, 0.5439954996109009, -0.03470812737941742, 0.2904428243637085, -0.9855965971946716, 0.270428866147995, 0.11761903762817383, -0.08603189140558243, 0.5358102321624756, 0.5845066905021667, 0.6509668231010437, 0.24371644854545593, -0.401531845331192, 0.24991877377033234, 1.3902645111083984, -0.43734607100486755, 0.18475425243377686, 0.524665355682373, 0.9764281511306763, 0.22773203253746033, -0.24077434837818146, 0.4942774474620819, 0.33818644285202026, 0.25104793906211853, 0.8269500136375427, -0.4598926305770874, 0.03787954896688461, -0.6443396210670471, 0.3316044807434082, 1.4759043455123901, -0.2287329137325287, 0.16135020554065704, -0.8727465271949768, 1.0467610359191895, -1.260818362236023, -1.1509917974472046, 0.3418371081352234, 0.6121776700019836, 0.03027998097240925, -0.3031093180179596, -0.4361512362957001, 0.16729597747325897, 0.7613270878791809, 0.08579952269792557, -0.30326977372169495, -0.821552574634552, -0.21030190587043762, 0.5778512954711914, 0.27567407488822937, 0.5713672637939453, -0.35641488432884216, 0.3585938513278961, 14.96920108795166, -0.048361167311668396, 0.019309254363179207, 0.3983365595340729, 0.870098352432251, 0.31600868701934814, -0.3074508011341095, 0.3367606997489929, -1.29259192943573, -0.25107961893081665, 1.6704574823379517, 0.290043443441391, 0.38322776556015015, 0.05294756963849068, 0.2676345407962799, 0.6626984477043152, -0.45131394267082214, 0.44800806045532227, 0.568121612071991, -1.1061139106750488, 0.46180954575538635, 0.12473319470882416, -0.22813120484352112, 0.5315526723861694, 0.5915589928627014, 0.7711300253868103, 0.4011586010456085, -0.45520636439323425, 0.45890966057777405, 0.38738110661506653, 0.6332199573516846, -0.11711540818214417, 0.3184675872325897, 0.2499428540468216, -1.0344210863113403, -0.3458353281021118, -0.797645092010498, -1.3223239183425903, 0.16032522916793823, -0.2695654332637787, -0.31525954604148865, -0.4683813750743866, 0.021225037053227425, 0.7418373823165894, 0.3528178632259369, 0.06143799424171448, -0.35734960436820984, 1.071946144104004, 0.33803123235702515, 0.48415932059288025, 0.2950108051300049, 0.5856015086174011, 0.0676790103316307, 0.0560976080596447, 0.07661180198192596, 0.2563868761062622, -0.2758524715900421, 0.5618146657943726, -0.19327527284622192, -0.39291542768478394, -0.1465958058834076, -0.5743873715400696, -0.26162347197532654, 1.0174953937530518, 0.511595606803894, 0.2713223993778229, -0.19248245656490326, 0.2833154797554016, 0.4151935279369354, 0.15813595056533813, -0.7486563324928284, -0.20603124797344208, 0.40401551127433777, -0.1743655800819397, 0.45550107955932617, 0.6628761887550354, 0.11767648160457611, -0.41597995162010193, -1.2876275777816772, -0.19979192316532135, 0.2870696485042572, -1.1213715076446533, -0.8625158667564392, 1.2214056253433228, -0.40771618485450745, 0.009283853694796562, 0.08965205401182175, -0.7682514190673828, -0.44023993611335754, 0.5376311540603638, -1.6084628105163574, -0.5106966495513916, -0.34411901235580444, -0.028979359194636345, -0.2791883945465088, -0.013415017165243626, 1.153873324394226, -0.04997510462999344, -0.3752291202545166, -0.22689682245254517, -0.5166230201721191, -0.11814168840646744, -0.3813153803348541, -0.6835759878158569, 0.8971980810165405, 0.06783369183540344, 0.09896025061607361, 0.4400995373725891, 0.33486661314964294, 0.41098326444625854, -0.4119984805583954, -0.21254883706569672, 0.8310529589653015, -0.8927096128463745, -0.007021906785666943, -0.6159685254096985, -1.1565183401107788, 0.6461555361747742, 0.6038374304771423, -0.1729479432106018, 0.18538424372673035, 0.06535004079341888, -0.5908224582672119, 0.003626416437327862, -0.19356662034988403, -0.3000270426273346, 0.28197744488716125, -0.7245069742202759, -0.815916121006012, -0.622336208820343, 0.47049227356910706, -0.3211650848388672, -0.04212329909205437, -0.1314835548400879, -0.21047385036945343, -0.22496293485164642, 0.8385440111160278, -0.7728206515312195, 0.5834252834320068, 0.6768836379051208, -0.08304131031036377, -0.47583872079849243, -0.6384343504905701, -0.7955538034439087, -0.14046530425548553, 0.548953115940094, 0.4453020393848419, -0.4418397843837738, 0.10592959821224213, 0.3456770181655884, 0.09286537021398544, -0.1519337147474289, -0.6154314875602722, 0.005908470135182142, -0.45974230766296387, -0.6330602169036865, 0.1361987143754959, 0.15044055879116058, -0.32385390996932983, 0.2507317364215851, 0.12358678877353668, 0.6954838633537292, -0.13503363728523254, -0.8010865449905396, -0.027688417583703995, -0.19604793190956116, -0.05929466709494591, -0.49195995926856995, -0.7754325866699219, -1.2031339406967163, -0.0830463171005249, -0.9447469711303711, -0.11121845990419388, -1.2273918390274048, -0.18410134315490723, 0.27065974473953247, -1.0757313966751099, 0.13209222257137299, 0.14353618025779724, -0.16233381628990173, -0.33724650740623474, -0.4864332675933838, -0.15851858258247375, 0.6284363269805908, 0.33510157465934753, -0.3405453562736511, 0.2075502723455429, -0.2082405537366867, -0.04857092350721359, 0.4332422912120819, 0.5052432417869568, -0.7224462628364563, -0.6623399257659912, -1.0533332824707031, 0.4817327558994293, 0.08320675790309906, 0.15793927013874054, -0.5697935819625854, 0.2651880979537964, 0.4760013222694397, -0.017693335190415382, -0.033854372799396515, 0.48216667771339417, -0.6759251952171326, -0.3237054944038391, 0.5398204326629639, -0.7363031506538391, 0.372260183095932, 0.35676854848861694, -0.14997869729995728, -0.4061918556690216, 0.8906177878379822, -0.018155699595808983, -1.164237380027771, -0.532002866268158, 0.5197346806526184, -0.9769511818885803, -0.22101472318172455, -0.47652214765548706, -0.21544790267944336, -0.7781805992126465, -0.4298672676086426, -0.19391942024230957, 0.10206758975982666, -0.7487120628356934, 1.2100509405136108, 0.7728750109672546, -1.1829174757003784, -0.12290604412555695, 0.2769707441329956, -0.17380641400814056, -0.6262113451957703, 0.30337104201316833, 0.1954134702682495, 0.09483028948307037, 0.6761972904205322, -0.07874760031700134, 0.21766217052936554, -0.823121964931488, -0.006547559984028339, 0.8825693130493164, -0.20726710557937622, -0.2535247206687927, 1.0608971118927002, 0.17231620848178864, -0.6822868585586548, -0.011340219527482986, -1.145540714263916, -0.9055290222167969, -0.08521634340286255, 0.6879799962043762, 0.09213930368423462, -0.32666969299316406, -0.3196221888065338, -0.38541439175605774, 0.10508262366056442, -0.13612188398838043, -0.29598572850227356, 0.6196630001068115, -0.279212087392807, -0.2816697955131531, 1.2066363096237183, 0.45589467883110046, -1.272330403327942, -0.5757589936256409, -0.4845162332057953, -0.355821818113327, 0.10499338805675507, 0.5377373695373535, -0.09415427595376968, -0.7283035516738892, 1.0125473737716675, 0.6867568492889404, 0.4059329330921173, 0.1833609789609909, -0.2696344256401062, -0.26490893959999084, 0.2793303430080414, -0.018881337717175484, -0.11278311163187027, -0.3830934166908264, 1.2958542108535767, 1.417264699935913, -0.6320441365242004, 0.12379337102174759, -0.1258888691663742, -0.6413723826408386, 0.9559804797172546, 0.26390787959098816, -0.3937142491340637, 0.7087519764900208, -0.5443865060806274, 0.25076013803482056, 0.2038334608078003, -1.6801531314849854, -0.24021968245506287, 0.39228442311286926, 0.9195172786712646, 0.9817661643028259, 0.1273811161518097, 0.28327032923698425, 0.7505263090133667, 0.1270742416381836, -0.05557680130004883, 0.6974791884422302, 0.2814170718193054, -0.26420772075653076, 0.38255003094673157, 0.35491085052490234, 0.36473244428634644, -0.783988356590271, -0.6013950109481812, 0.37448903918266296, 0.8475104570388794, -0.2228163629770279, 0.727796733379364, 1.1174739599227905, 0.20470736920833588, 0.4145340621471405, -0.012575767002999783, 0.526421844959259, -0.45751655101776123, -0.3717806935310364, -0.007183422800153494, -0.615813672542572, -0.29120486974716187, -0.37113216519355774, -0.4607127904891968, -0.6897876262664795, 0.10879907757043839, -0.007481532637029886, -0.12975434958934784, 0.5950489640235901, 1.0584592819213867, 0.3171883821487427, 0.7851662635803223, -0.0490170419216156, -0.4161023497581482, -0.22352826595306396, -1.1444660425186157, 0.06714987009763718, -0.6463496088981628, 0.2512754499912262, -0.3092746138572693, -0.5706945657730103, 0.037330131977796555]}, "authors": [{"authorId": "2215803905", "name": "Itamar Zimerman"}, {"authorId": "2112239702", "name": "Ameen Ali"}, {"authorId": "2266750992", "name": "Lior Wolf"}], "references": [{"paperId": "47741d9e57f7a986a350f5cb20de287b1b1b8ff8", "title": "Visual Mamba: A Survey and New Outlooks"}, {"paperId": "ba4c5a116d07b37dea1046b6d16a60cb2d01cd47", "title": "Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges"}, {"paperId": "f5cea4651c32d2ba95171fb264cc6680262c17d7", "title": "A Survey on Visual Mamba"}, {"paperId": "46732358e98ce6be0c564ae11f71d556a64b4c35", "title": "HGRN2: Gated Linear RNNs with State Expansion"}, {"paperId": "157ed5647da39a7f5d33a84a90414b2a9e97e301", "title": "Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence"}, {"paperId": "cbaf689fd9ea9bc939510019d90535d6249b3367", "title": "Jamba: A Hybrid Transformer-Mamba Language Model"}, {"paperId": "05c1dc502ed51162580ccd320d5668d2fec94a7a", "title": "Mechanistic Design and Scaling of Hybrid Architectures"}, {"paperId": "51f38bd957fa863022feb5878fa1ba3bea6657cf", "title": "Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like Architectures"}, {"paperId": "26e6cd121c5fdb147df83cb848e4813c926737c8", "title": "The Hidden Attention of Mamba Models"}, {"paperId": "d53fe76bd2795a19ddf52d012917782f6f6f2c1e", "title": "Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models"}, {"paperId": "40438187c1037ebce7b477a400853ba1b47ef772", "title": "HyenaPixel: Global Image Context with Convolutions"}, {"paperId": "2dda6da7375bf5e8bcf60f87b17ba10757f3bc57", "title": "Graph Mamba: Towards Learning on Graphs with State Space Models"}, {"paperId": "906d0688e1c683d5fec70e88e71ea1291c666b78", "title": "Mamba-ND: Selective State Space Modeling for Multi-Dimensional Data"}, {"paperId": "1df04f33a8ef313cc2067147dbb79c3ca7c5c99f", "title": "Graph-Mamba: Towards Long-Range Graph Sequence Modeling with Selective State Spaces"}, {"paperId": "3169a2478154e26fd7f63fdf43cf3a24f1007962", "title": "BlackMamba: Mixture of Experts for State-Space Models"}, {"paperId": "a6e2dca754f3dc625a9da5f10f9b7a57079bfd27", "title": "MambaByte: Token-free Selective State Space Model"}, {"paperId": "b24e899ec0f77eef2fc87a9b8e50516367aa1f97", "title": "VMamba: Visual State Space Model"}, {"paperId": "38c48a1cd296d16dc9c56717495d6e44cc354444", "title": "Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model"}, {"paperId": "745594bd0dc3e9dc86f74e100cd2c98ed36256c0", "title": "MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts"}, {"paperId": "62b18cc55dcc7ffe52c28e1086aee893b7bc4334", "title": "Gated Linear Attention Transformers with Hardware-Efficient Training"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "8420fddf489bd7c5b822bd904aa11ff3742bfb78", "title": "On the Long Range Abilities of Transformers"}, {"paperId": "434d751d355d7a7c20efa570e785c76286245e77", "title": "Hierarchically Gated Recurrent Neural Network for Sequence Modeling"}, {"paperId": "d7f64f2bdd80ea15f21ef7d867e102ac9ecdc797", "title": "GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling"}, {"paperId": "e6917b14918f90e8fb89ad4debebd3937e57a123", "title": "Multi-Dimensional Hyena for Spatial Inductive Bias"}, {"paperId": "59708496c88f173276a40d779a1f83bcfe2e7842", "title": "RMT: Retentive Networks Meet Vision Transformers"}, {"paperId": "22a0bfac8cc0cb9c01123d8a898e3235ddcab269", "title": "Weigh Your Own Words: Improving Hate Speech Counter Narrative Generation via Attention Regularization"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "240103933ffe3dac2179cc160a2bd91299357a53", "title": "Retentive Network: A Successor to Transformer for Large Language Models"}, {"paperId": "debbb47abc9fb757857f7c06aa86ca558d37c2d7", "title": "2-D SSM: A General Spatial Layer for Visual Transformers"}, {"paperId": "2d01b6afbc86cba1cb895dbcd9396b13952bf0e5", "title": "Focus Your Attention (with Adaptive IIR Filters)"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8", "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"}, {"paperId": "f393aff1593c2d370ec0ae004910d18e40524967", "title": "Resurrecting Recurrent Neural Networks for Long Sequences"}, {"paperId": "f14b28b2bfbaf5febf7076994052f727d36f31b7", "title": "Token Contrast for Weakly-Supervised Semantic Segmentation"}, {"paperId": "998ac3e945857cf2676ee7efdbaf443a0c6f820a", "title": "Hyena Hierarchy: Towards Larger Convolutional Language Models"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "a128b1c47e6842605fb95bceae930d2135fc38fc", "title": "Pretraining Without Attention"}, {"paperId": "70e91e16eb321067d9402710e14a40cf28311f73", "title": "Mega: Moving Average Equipped Gated Attention"}, {"paperId": "6d7d141c75af752ffc0d8a6184cca3f9323d6c74", "title": "Simplified State Space Layers for Sequence Modeling"}, {"paperId": "eaef083b9d661f42cc0d89d9d8156218f33a91d9", "title": "Long Range Language Modeling via Gated State Spaces"}, {"paperId": "257f9f3dbe2bac1ae242728827f8a861bd8469fd", "title": "Optimizing Relevance Maps of Vision Transformers Improves Robustness"}, {"paperId": "71e15a9a52dcafca57bff5f310b95e2c7d0cfc87", "title": "Diagonal State Spaces are as Effective as Structured State Spaces"}, {"paperId": "5a5b5bd6c644eb43943144410efba704ebb4c083", "title": "Entropy-based Attention Regularization Frees Unintended Bias Mitigation from Lists"}, {"paperId": "1da81334febeff16d13f618b02c855a51fd751a7", "title": "Learning Affinity from Attention: End-to-End Weakly-Supervised Semantic Segmentation with Transformers"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "ca9047c78d48b606c4e4f0c456b1dda550de28b2", "title": "Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers"}, {"paperId": "d5e999aae76d5270ef272076979c809817458212", "title": "An Attention Free Transformer"}, {"paperId": "7ec5f207263100ea2d45db595712f611a74bafd9", "title": "Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers"}, {"paperId": "0acd7ff5817d29839b40197f7a4b600b7fba24e4", "title": "Transformer Interpretability Beyond Attention Visualization"}, {"paperId": "c92ccde8efe40d1696dc7acdadaddc923c9d945d", "title": "Visualization of Supervised and Self-Supervised Neural Networks via Attribution Guided Factorization"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "76a9f336481b39515d6cea2920696f11fb686451", "title": "Quantifying Attention Flow in Transformers"}, {"paperId": "90d668b9ff44af25fbe84f888e3c29ec7d86d95a", "title": "Self-Supervised Equivariant Attention Mechanism for Weakly Supervised Semantic Segmentation"}, {"paperId": "79c93274429d6355959f1e4374c2147bb81ea649", "title": "LXMERT: Learning Cross-Modality Encoder Representations from Transformers"}, {"paperId": "65a9c7b0800c86a196bc14e7621ff895cc6ab287", "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"}, {"paperId": "7e9b21ef739d35ded550daaabae2d65934ebb9a1", "title": "Relative Attributing Propagation: Interpreting the Comparative Contributions of Individual Units in Deep Neural Networks"}, {"paperId": "1e83c20def5c84efa6d4a0d80aa3159f55cb9c3f", "title": "Attention is not Explanation"}, {"paperId": "fdbdd4e0461d23905104460a02a176907d945f44", "title": "Multi-Head Attention with Disagreement Regularization"}, {"paperId": "fdfa7dc73dc1fc6772d26f88c72e98b68d1f8498", "title": "Parallelizing Linear Recurrent Neural Nets Over Sequence Length"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "ac3ee98020251797c2b401e1389461df88e52e62", "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling"}, {"paperId": "10fda03f3ea1735795f747863d3d1662e14449b0", "title": "ImageNet Auto-Annotation with Segmentation Propagation"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": null, "title": "Prefix sums and their applications. Technical Report"}, {"paperId": null, "title": "Edinburgh Research Explorer The PASCAL Visual Object Classes (VOC) Challenge"}]}