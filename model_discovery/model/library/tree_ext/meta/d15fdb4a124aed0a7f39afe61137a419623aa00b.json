{"paperId": "d15fdb4a124aed0a7f39afe61137a419623aa00b", "title": "SPARO: Selective Attention for Robust and Compositional Transformer Encodings for Vision", "abstract": "Selective attention helps us focus on task-relevant aspects in the constant flood of our sensory input. This constraint in our perception allows us to robustly generalize under distractions and to new compositions of perceivable concepts. Transformers employ a similar notion of attention in their architecture, but representation learning models with transformer backbones like CLIP and DINO often fail to demonstrate robustness and compositionality. We highlight a missing architectural prior: unlike human perception, transformer encodings do not separately attend over individual concepts. In response, we propose SPARO, a read-out mechanism that partitions encodings into separately-attended slots, each produced by a single attention head. Using SPARO with CLIP imparts an inductive bias that the vision and text modalities are different views of a shared compositional world with the same corresponding concepts. Using SPARO, we demonstrate improvements on downstream recognition, robustness, retrieval, and compositionality benchmarks with CLIP (up to +14% for ImageNet, +4% for SugarCrepe), and on nearest neighbors and linear probe for ImageNet with DINO (+3% each). We also showcase a powerful ability to intervene and select individual SPARO concepts to further improve downstream task performance (up from +4% to +9% for SugarCrepe) and use this ability to study the robustness of SPARO's representation structure. Finally, we provide insights through ablation experiments and visualization of learned concepts.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "SPARO is proposed, a read-out mechanism that partitions encodings into separately-attended slots, each produced by a single attention head, that demonstrates improvements on downstream recognition, robustness, retrieval, and compositionality benchmarks with CLIP and DINO and provides insights through ablation experiments and visualization of learned concepts."}, "embedding": {"model": "specter_v2", "vector": [0.5485767126083374, 0.4069859981536865, -0.11796854436397552, 0.19910435378551483, -0.43743565678596497, -0.059971388429403305, 0.9356954097747803, -0.0005723116337321699, -0.40977948904037476, -0.5070475935935974, 0.6113476157188416, 0.4562044143676758, -0.021109525114297867, 0.035224899649620056, -0.10871587693691254, 0.17799003422260284, -0.7469150424003601, 0.47417256236076355, 0.39412426948547363, -0.729852020740509, 0.058905474841594696, -0.5141250491142273, -1.8294973373413086, 0.40534138679504395, 0.19847719371318817, 1.0080499649047852, 0.10783074796199799, 0.8895675539970398, -0.03779013827443123, 0.7866178750991821, 0.5074463486671448, 0.010923843830823898, 0.20337067544460297, -0.008059386163949966, -0.3733550012111664, -0.1249639242887497, 0.764307975769043, -0.37059226632118225, -0.4691482186317444, 0.7488740682601929, 0.0010685814777389169, 0.31826311349868774, 0.7277837991714478, -0.7836430072784424, -0.7715721726417542, 0.5203733444213867, 1.086572527885437, 0.4766061007976532, -0.05338802933692932, -0.5552908778190613, 1.7218875885009766, -1.6425657272338867, 0.43832069635391235, 1.5018082857131958, 0.4787972867488861, 0.5565181374549866, -0.4808548092842102, -0.38982194662094116, 0.9885145425796509, 0.2041952759027481, -0.7335139513015747, -0.4683145582675934, -0.2806529700756073, 0.037765104323625565, 1.4002572298049927, -0.6102097034454346, -0.004429963417351246, 0.5903956890106201, -0.07161229103803635, 1.5567238330841064, 0.11742968112230301, -0.6044948697090149, 0.02155272662639618, 0.07254856079816818, 0.24095790088176727, 0.8142302632331848, -0.3843226730823517, 0.19979959726333618, -1.04324471950531, 0.2805415093898773, 0.6955581903457642, 0.18983742594718933, -0.19380410015583038, -0.3780722916126251, -0.4223402142524719, 0.32645487785339355, 0.8825042843818665, 0.7237809896469116, -0.5468927621841431, 0.8140857219696045, 0.3469609320163727, 0.44166821241378784, -0.3194339871406555, 0.5781225562095642, 0.080296091735363, 0.7289162874221802, -0.5401368737220764, 0.29231008887290955, -0.08082249760627747, 1.130911946296692, -0.04866870120167732, 0.05752626806497574, -0.7929871678352356, 0.057563476264476776, 1.1723719835281372, 0.1692991703748703, 0.6325798630714417, -0.6636538505554199, -0.09032296389341354, -0.5893969535827637, 0.10899634659290314, -0.8754427433013916, 0.162385955452919, -0.1763324737548828, -0.3253328502178192, -0.9228008985519409, -0.5447962284088135, 0.6840988993644714, -1.129253625869751, 0.6173551678657532, -0.7286671996116638, -0.0978366956114769, -0.06679978221654892, 0.8361279964447021, 0.6534668207168579, 0.29667502641677856, 0.6352390646934509, 0.7646965384483337, 1.0103375911712646, -0.7147152423858643, -0.25849390029907227, -1.0472460985183716, 0.3482039272785187, -0.07634179294109344, 0.3922163248062134, -0.01912613958120346, -0.9972037076950073, -1.2117422819137573, -0.9128412008285522, -0.0974518433213234, -1.0060943365097046, -0.04915936291217804, 0.8738924860954285, 0.034482717514038086, -1.2680007219314575, 0.8350364565849304, 0.1786828637123108, -0.5322173237800598, 0.691193699836731, 0.3416604697704315, 0.021592704579234123, -0.8643389940261841, -1.170669674873352, 0.2950802743434906, 0.36983227729797363, -0.5787713527679443, -0.8806992173194885, -0.45369288325309753, -1.2600836753845215, -0.023494480177760124, 0.3285992443561554, -0.8556047677993774, 1.0180187225341797, -0.5251997709274292, -0.5890184640884399, 0.6054577827453613, -0.45371872186660767, 0.2779792547225952, 0.0449901819229126, -0.3254511058330536, -0.4237530827522278, 0.050879012793302536, -0.03428114578127861, 0.8355362415313721, 0.7893463969230652, -0.6882875561714172, -0.22762076556682587, 0.1725529134273529, -0.3586902320384979, 0.07572673261165619, -0.23791316151618958, 0.8191646337509155, -0.10057518631219864, -0.0774054154753685, 0.7312758564949036, 0.9250640273094177, 0.17600063979625702, 0.19433461129665375, 0.06882111728191376, -1.0814555883407593, 0.5940744876861572, 0.31003499031066895, 0.2625613510608673, -1.0694609880447388, -0.34102746844291687, -0.17729167640209198, 0.1454072892665863, -0.3872634172439575, -1.230049967765808, 0.5582513213157654, -0.34740766882896423, 0.5277208685874939, -0.14260022342205048, -1.2154901027679443, 0.33436423540115356, -0.13322380185127258, -0.7813480496406555, -0.21322473883628845, 0.3290460407733917, 1.330236792564392, -1.0855296850204468, -0.15274721384048462, 0.08954189717769623, 0.3596297800540924, -0.704590380191803, 1.018897533416748, -0.5092030763626099, -0.25652819871902466, -0.11443537473678589, 0.29346421360969543, -0.24022768437862396, -0.19474990665912628, 0.048571985214948654, -0.7021357417106628, 0.2781151831150055, 0.4137050211429596, -0.39226049184799194, 1.343209147453308, -0.31275060772895813, 0.4967280328273773, -0.23323285579681396, -0.5824548602104187, 0.2970951497554779, 0.4128663241863251, -0.3134917616844177, -0.85493403673172, 0.30795571208000183, 0.41640958189964294, -0.7733997702598572, 0.12079323828220367, 0.7455176115036011, 0.5353159308433533, -0.29360684752464294, -0.0791957899928093, 0.7640484571456909, -0.5809624791145325, 0.29961922764778137, 0.33647698163986206, 0.7779796719551086, 0.5538906455039978, 0.17835651338100433, -0.08826760202646255, 0.027779456228017807, -0.819112241268158, -0.20506039261817932, 0.7857885956764221, 0.5409364104270935, 1.4679737091064453, 0.29288363456726074, -0.8147985935211182, -0.30358123779296875, -0.3715730607509613, 0.697888970375061, 1.7059434652328491, 0.2337312400341034, -0.33636534214019775, -0.217694491147995, -0.3403555452823639, -0.48072513937950134, -0.05085121467709541, -0.6874592304229736, -0.4657854735851288, -0.15261059999465942, -0.6356695294380188, 0.36422300338745117, 0.6881352663040161, 1.1219022274017334, -1.0516002178192139, -0.4350992739200592, -0.31182661652565, 0.32704344391822815, -0.6948385834693909, -0.4759220480918884, 0.37873151898384094, -0.24387288093566895, -0.20753878355026245, 0.06731008738279343, -0.385810911655426, 0.3210037052631378, -0.4131193161010742, 1.1310374736785889, -0.5499114394187927, -0.4519656002521515, 0.5890680551528931, 0.33467450737953186, -0.6558666825294495, -0.21840783953666687, -0.021249571815133095, -0.08332692086696625, -0.036522358655929565, 0.37343695759773254, 0.3365767002105713, -0.24937312304973602, 0.3966189920902252, -0.8099945783615112, -0.2948959469795227, 0.31524425745010376, -0.11476203799247742, 0.911639392375946, -0.28301963210105896, -0.04356558620929718, -0.891804575920105, 0.7978960871696472, -0.14115969836711884, -0.04741963744163513, 0.07177413254976273, -0.6953396797180176, -0.30808284878730774, 0.40949854254722595, -0.5764254331588745, 0.026052886620163918, -0.8398016095161438, 0.8269349932670593, -0.48787644505500793, -0.44488829374313354, 0.2553562521934509, 0.19454056024551392, 0.28288817405700684, 0.6059624552726746, 0.49700087308883667, 0.2870407998561859, 0.041419994086027145, 0.6819853186607361, -1.0747480392456055, 0.47229644656181335, 0.014575444161891937, 0.04498331993818283, 0.1443769335746765, -0.13331012427806854, -0.6558408737182617, -0.45155924558639526, -0.4516807496547699, -0.09530206769704819, -0.2883692681789398, 0.21756164729595184, -0.7526505589485168, -0.8189079761505127, -0.2458125501871109, -0.9082674980163574, -0.2728162407875061, -0.3566528260707855, -0.5803239345550537, -0.2539537847042084, -1.3539135456085205, -0.6938331127166748, -0.3063138723373413, -0.13187193870544434, -0.8558669090270996, 0.5707458853721619, 0.0032548680901527405, -0.5912930369377136, -0.42044779658317566, -0.1656886339187622, -0.5856082439422607, 1.0651497840881348, -0.23466834425926208, 0.605231523513794, -0.2247185856103897, -0.5619218349456787, -0.42637255787849426, -0.29462140798568726, 0.6465657949447632, -0.16370496153831482, -0.03591177240014076, -1.1678727865219116, 0.14460411667823792, -0.30317971110343933, -0.668885350227356, 0.7632946372032166, -0.14809055626392365, 0.6136766076087952, 0.1476716250181198, -0.36101165413856506, 0.22069290280342102, 1.6673420667648315, -0.5479258298873901, 0.4082966446876526, 0.261738657951355, 0.9355272650718689, 0.5580553412437439, -0.3473389148712158, 0.31663674116134644, 0.4120147228240967, -0.12550291419029236, 0.5139285922050476, -0.03520492836833, -0.6200430393218994, -0.8287417888641357, 0.4877060055732727, 0.7995020151138306, 0.07253441959619522, -0.040478553622961044, -1.1496367454528809, 0.9089113473892212, -1.267730474472046, -0.60443514585495, 1.046015739440918, 0.8273538947105408, 0.07105948030948639, -0.4939333200454712, -0.4811153709888458, -0.40213531255722046, 0.3594632148742676, 0.18814128637313843, -0.26594236493110657, -0.21684937179088593, -0.15474958717823029, 0.7787922620773315, 0.15456369519233704, 0.6041985154151917, -0.40089547634124756, 0.46747252345085144, 14.800686836242676, 0.4637730121612549, 0.031036674976348877, 0.35772812366485596, 0.3937084674835205, 0.34584033489227295, -0.5957208871841431, 0.007430680561810732, -0.9445284008979797, -0.43743929266929626, 0.8444911241531372, 0.5051255822181702, 0.2742486000061035, 0.05038364231586456, -0.5435157418251038, 0.2735534906387329, -1.0517258644104004, 0.6056604385375977, 0.9825201630592346, -0.8460338711738586, 0.6127822995185852, 0.055321693420410156, 0.26276347041130066, 0.32113486528396606, 1.1366225481033325, 0.7085996866226196, 0.6164743900299072, -0.8966628313064575, 0.5729698538780212, 0.5641674399375916, 1.0499194860458374, 0.285749614238739, 0.27589958906173706, 0.011882968246936798, -0.9275782704353333, -0.4522625207901001, -0.5644710659980774, -0.9819418787956238, -0.15638215839862823, -0.36989983916282654, -0.4671127200126648, -0.5949224233627319, -0.15087884664535522, 0.9282757043838501, -0.16443544626235962, 0.41493889689445496, -0.4438338279724121, 0.17026638984680176, -0.10712307691574097, -0.03334822505712509, 0.17215323448181152, 0.9992947578430176, 0.275449275970459, -0.19805406033992767, 0.01574523188173771, -0.11185841262340546, 0.30262768268585205, 0.5973657965660095, -0.5848373174667358, -0.15475745499134064, -0.45865684747695923, 0.0445714145898819, -0.037520937621593475, 0.5548630356788635, 0.2588362991809845, 0.4077165126800537, -0.1135987639427185, 0.31330227851867676, 0.2555233836174011, 0.45029330253601074, 0.0971568375825882, -0.32423117756843567, 0.23154543340206146, -0.13603894412517548, 0.15404580533504486, 0.7405924797058105, 0.016712604090571404, -0.2330947071313858, -0.6277405023574829, -0.14291265606880188, 0.5588952898979187, -0.9293336868286133, -0.8185940980911255, 0.922288715839386, -0.24740299582481384, -0.516789436340332, 0.4597892165184021, -1.0493190288543701, -0.1482798010110855, 0.34788778424263, -1.6879603862762451, -0.9840561151504517, -0.36330506205558777, -0.07810252904891968, -0.21005307137966156, -0.10835592448711395, 1.4639275074005127, -0.13132022321224213, 0.08596727252006531, -0.2640438377857208, -0.4660552442073822, -0.19484378397464752, 0.15715375542640686, -1.0958143472671509, 0.4892382323741913, -0.05185141786932945, -0.012013183906674385, 0.42704570293426514, 0.15704038739204407, 0.32095712423324585, -0.3466455638408661, 0.025110621005296707, 0.7102940082550049, -1.0680197477340698, -0.5669995546340942, -0.6231687068939209, -0.5948933959007263, 0.4495692253112793, 0.5470397472381592, 0.19353234767913818, 0.3418497145175934, 0.21627983450889587, -1.1814765930175781, -0.36779582500457764, -0.8480369448661804, 0.15938371419906616, 0.5082910060882568, -0.9240186810493469, -0.7776729464530945, -0.10391969978809357, 0.2769041955471039, -0.5433757305145264, -0.17906498908996582, -0.337683767080307, 0.4190692901611328, -0.2809598743915558, 1.1461238861083984, -0.656773030757904, 0.810845673084259, 0.45812535285949707, -0.5318639278411865, -0.8525574207305908, -0.37614256143569946, -0.6152562499046326, 0.15562233328819275, 0.050551917403936386, 0.530817449092865, -0.5298715233802795, -0.13864466547966003, 0.8591988682746887, 0.3670559823513031, -0.18219661712646484, -0.2943989634513855, -0.08549284934997559, -0.052697423845529556, -0.42678365111351013, 0.23429585993289948, -0.36556994915008545, -0.2126651108264923, 0.31850898265838623, 0.8487855792045593, 0.44829317927360535, -0.11446762830018997, -0.7503515481948853, -0.010505905374884605, -0.35349178314208984, 0.1081368625164032, -0.49592918157577515, -0.8500442504882812, -1.267237663269043, -0.20900508761405945, -1.1337419748306274, 0.23765137791633606, -1.3310636281967163, -0.7805593609809875, 0.2199951708316803, -0.8820462226867676, 0.29122287034988403, 0.5122848749160767, 0.04321593418717384, -0.09517155587673187, -0.3497909903526306, -0.8036701679229736, 0.624505341053009, 1.0153987407684326, -0.8024057745933533, 0.24205729365348816, -0.4103033244609833, -0.6195195913314819, 0.2066105455160141, 0.3395020067691803, -0.31932225823402405, -0.9449071288108826, -1.2190642356872559, 0.5850272178649902, -0.6307673454284668, 0.35073837637901306, -1.0366837978363037, 1.0393575429916382, 0.9379987120628357, 0.17441074550151825, 0.3028104603290558, 0.6545584201812744, -1.2753716707229614, -0.897731363773346, 0.17409645020961761, -1.0016164779663086, 0.055398691445589066, 0.19883781671524048, -0.3469318449497223, -0.5295386910438538, 0.7607452869415283, -0.09985186159610748, -1.3645092248916626, -1.1507130861282349, 0.4721382260322571, -0.4636514186859131, 0.1427132934331894, -0.2325497716665268, -0.3496728837490082, -1.3564279079437256, -0.2970708906650543, -0.16765347123146057, 0.4918082058429718, -0.5544223189353943, 0.9326918721199036, 1.1442127227783203, -1.1505438089370728, 0.040908049792051315, 0.3450712561607361, 0.3910696506500244, 0.2189079076051712, 0.29081571102142334, 0.154558002948761, -0.20157748460769653, 0.1857198029756546, 0.06339824944734573, 0.3709513545036316, -0.5180178284645081, 0.30747583508491516, 0.8264663815498352, 0.21708187460899353, -0.06415728479623795, 1.133235216140747, -0.10745606571435928, -0.7883878946304321, 0.1630946844816208, -1.0503422021865845, -0.6141128540039062, 0.24745513498783112, 0.704239547252655, -0.04559047147631645, -0.25932547450065613, -0.04685583338141441, -0.4671595096588135, 0.5712396502494812, -0.25547218322753906, -0.5870456695556641, 0.42340603470802307, 0.059326279908418655, -0.49347802996635437, 0.6517891883850098, 0.8627814650535583, -1.0139596462249756, -0.6725286841392517, -0.848982572555542, -0.5397491455078125, -0.05221700668334961, 0.16601893305778503, -0.4130617082118988, -0.2525942027568817, 0.6872037053108215, 0.5850175619125366, 0.31117454171180725, 0.2696944773197174, 0.06413546949625015, -0.13866348564624786, 0.7463568449020386, -0.12335577607154846, -0.3789557218551636, 0.02673659473657608, 1.0982894897460938, 1.5739086866378784, -0.6777653098106384, 0.0347130224108696, -0.19576013088226318, -0.5019605159759521, 0.8516710996627808, 0.3327220380306244, -0.3806942105293274, 0.7961551547050476, -0.5463307499885559, -0.20581962168216705, -0.12101895362138748, -0.9977048635482788, -0.6153181195259094, 0.9818621873855591, 1.5722790956497192, 0.5257439613342285, 0.08872261643409729, 0.47262680530548096, 0.5243561863899231, 0.2428266555070877, 0.0825960785150528, 0.2600833773612976, 0.377573698759079, -0.4349097013473511, 0.3303483724594116, 0.1798522025346756, 0.38081783056259155, -0.20610573887825012, -0.6184520721435547, -0.121421217918396, 0.4972725808620453, 0.4139367640018463, 0.44079798460006714, 0.8568270802497864, 0.3063002824783325, 0.9093444347381592, 0.48363378643989563, 0.5668243169784546, -0.7790711522102356, 0.009079715237021446, -0.49531257152557373, -0.764603316783905, -0.205093115568161, -0.5821908712387085, -0.6507863402366638, -0.24782173335552216, 0.15119142830371857, 0.6747238636016846, -0.3318576514720917, 0.08739659935235977, 0.8591339588165283, 0.5075417160987854, 0.7509155869483948, -0.5051741003990173, -0.5163427591323853, -0.236024871468544, -0.7596578598022461, 0.2135590761899948, -0.18065716326236725, 0.22576381266117096, -0.5536082983016968, -0.37463292479515076, -0.17619003355503082]}, "authors": [{"authorId": "34360821", "name": "Ankit Vani"}, {"authorId": "2298043382", "name": "Bac Nguyen"}, {"authorId": "2122697679", "name": "Samuel Lavoie"}, {"authorId": "2257273968", "name": "Ranjay Krishna"}, {"authorId": "2262443562", "name": "Aaron Courville"}], "references": [{"paperId": "dce93d147731495d0ec3eec8713f82cc67545056", "title": "Self-supervised Object-Centric Learning for Videos"}, {"paperId": "0ee4fad1e29b82f0fba73cc657c5f41baa07e354", "title": "Semantics Meets Temporal Correspondence: Self-supervised Object-centric Learning in Videos"}, {"paperId": "dedbac319177d04ce63fe00d2fec24bdaab90d6d", "title": "SugarCrepe: Fixing Hackable Benchmarks for Vision-Language Compositionality"}, {"paperId": "29e916644308908e1c592e0fdb935bb4f723a475", "title": "Provably Learning Object-Centric Representations"}, {"paperId": "d23b11cc2c87017914c7b4c95262da01810aa743", "title": "Cola: A Benchmark for Compositional Text-to-image Retrieval"}, {"paperId": "d7adb2e6c8e381ca6c7a9a74ec5c54061573f9e1", "title": "Revisiting Multimodal Representation in Contrastive Learning: From Patch and Token Embeddings to Finite Discrete Tokens"}, {"paperId": "26590b0c0e22b8c06c31ad51eda4fbab00a85e80", "title": "@ CREPE: Can Vision-Language Foundation Models Reason Compositionally?"}, {"paperId": "abdd13184f276533dfe4fd7ffb6d99b1b762a43d", "title": "Multi-CLS BERT: An Efficient Alternative to Traditional Ensembling"}, {"paperId": "10667c1ae4b49808772b5a377c5b52196701267f", "title": "When and why vision-language models behave like bags-of-words, and what to do about it?"}, {"paperId": "6174d6498562f066526c7371edf8f548918d988c", "title": "Bridging the Gap to Real-World Object-Centric Learning"}, {"paperId": "c399b8d44dac36982b0d0b2b037c74740fa3dca7", "title": "Unsupervised Semantic Segmentation with Self-supervised Object-centric Representations"}, {"paperId": "0b0c87602818160e75ff54b48ef154d0ca27dd45", "title": "VL-CheckList: Evaluating Pre-trained Vision-Language Models with Objects, Attributes and Relations"}, {"paperId": "a26a7a74f1e5fd562be95c3611a0680759fbdf84", "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models"}, {"paperId": "c435ecd0321dcec1f25e458bf930311f9e1d04b6", "title": "Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality"}, {"paperId": "f005116ddb524a4cc3df83b24a1d15bb3b4ef87a", "title": "Simplicial Embeddings in Self-Supervised Learning and Downstream Classification"}, {"paperId": "772f9f21511de7bc1077b877a0ea0bd6e50f4e76", "title": "Multi-class Token Transformer for Weakly Supervised Semantic Segmentation"}, {"paperId": "b668ce936cff0b0ca8b635cd5f25a62eaf4eb3df", "title": "LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs"}, {"paperId": "ad4a0938c48e61b7827869e4ac3baffd0aefab35", "title": "Emerging Properties in Self-Supervised Vision Transformers"}, {"paperId": "739ceacfafb1c4eaa17509351b647c773270b3ae", "title": "An Empirical Study of Training Self-Supervised Vision Transformers"}, {"paperId": "57fb3190887d837fca47a0ca176abc782b1f42d3", "title": "Neural Production Systems"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "394be105b87e9bfe72c20efe6338de10604e1a11", "title": "Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "022622e024890d6e044ac50e2da6b44c59bdf418", "title": "The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization"}, {"paperId": "5156381d63bb3e873533b08f203cb56c2d79b6c9", "title": "Object-Centric Learning with Slot Attention"}, {"paperId": "0fd6fe2f3e0e78550934be980de4062ac54a87b4", "title": "Diabetic Retinopathy Detection"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "dc52b09089704ebd6f471177474bc29741c50023", "title": "Fast Transformer Decoding: One Write-Head is All You Need"}, {"paperId": "85b9e68eb27069e87181050035f40b79438dd220", "title": "A Large-scale Study of Representation Learning with the Visual Task Adaptation Benchmark"}, {"paperId": "67a9dde04f367efc903b6d06097df9bdd9887ae7", "title": "Recurrent Independent Mechanisms"}, {"paperId": "a50b7a45f704f30d7f97dd229d4d53433d5df3b1", "title": "GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations"}, {"paperId": "45557cc70cd6989ab6b03e5aeb787e34299099f7", "title": "Natural Adversarial Examples"}, {"paperId": "c91907248cd832ba4f766394cd86a27946047a9e", "title": "Deep Set Prediction Networks"}, {"paperId": "4ae0c4a511697e960c477ea3e37b3e11bf3e0e02", "title": "Learning Robust Global Representations by Penalizing Local Predictive Power"}, {"paperId": "9b8327b04667269fdae78cd34064eb2ee05ddee8", "title": "Multi-Object Representation Learning with Iterative Variational Inference"}, {"paperId": "4e0bb8c1c683b43357c5d5216f6b74ff2cb32434", "title": "Do ImageNet Classifiers Generalize to ImageNet?"}, {"paperId": "d25b1edda507cba944938ec8784d8b124c2381a5", "title": "MONet: Unsupervised Scene Decomposition and Representation"}, {"paperId": "b4df354db88a70183a64dbc9e56cf14e7669a6c0", "title": "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"}, {"paperId": "2a96afaf3261a87f0daa51699b4b3cf169e092c4", "title": "Rotation Equivariant CNNs for Digital Pathology"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "9c88c2357abcd58cc330179c1965fe0a8c067ebc", "title": "EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "179765729fc1e269393617795507607c29a66a8e", "title": "Remote Sensing Image Scene Classification: Benchmark and State of the Art"}, {"paperId": "03eb382e04cca8cca743f7799070869954f1402a", "title": "CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning"}, {"paperId": "a5c68d0d01ace4a7a5f4d3e0a3fccc42a7d1f354", "title": "DeepMind Lab"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "2b5f51588f1c4cdca0865de20c1e2e1ff3570fd1", "title": "Attend, Infer, Repeat: Fast Scene Understanding with Generative Models"}, {"paperId": "c1e3a26fb88c6720f4e84b7118e6f2df7dc8efa3", "title": "From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "44040913380206991b1991daf1192942e038fe31", "title": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions"}, {"paperId": "18c125ce0f64e85577f7d30132cf0e92ec664bf4", "title": "Describing Textures in the Wild"}, {"paperId": "79b949d9b35c3f51dd20fb5c746cc81fc87147eb", "title": "Vision meets robotics: The KITTI dataset"}, {"paperId": "9814df8bd00ba999c4d1e305a7e9bca579dc7c75", "title": "Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics"}, {"paperId": "84b50ebe85f7a1721800125e7882fce8c45b5c5a", "title": "Cats and dogs"}, {"paperId": "908091b4a8757c3b2f7d9cfa2c4f616ee12c5157", "title": "SUN database: Large-scale scene recognition from abbey to zoo"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "02b28f3b71138a06e40dbd614abf8568420ae183", "title": "Automated Flower Classification over a Large Number of Classes"}, {"paperId": "812355cec91fa30bb50e9e992a3549af39e4f6eb", "title": "One-shot learning of object categories"}, {"paperId": "f354310098e09c1e1dc88758fca36767fd9d084d", "title": "Learning methods for generic object recognition with invariance to pose and lighting"}, {"paperId": "0ccd456631d1ab297a96ca9df2ee759ccd0981b5", "title": "Attention modulates responses in the human lateral geniculate nucleus"}, {"paperId": "56a8b0f08ae276808996470f24ce7406042c884f", "title": "Putting spatial attention on the map: timing and localization of stimulus selection processes in striate and extrastriate visual areas"}, {"paperId": "3e7f895ad75d417da9f7f224abbfe8c9087826b7", "title": "Handbook of perception and human performance. Vol 1: Sensory processes and perception. Vol 2: Cognitive processes and performance."}, {"paperId": "76361a44e145732a39dbc68d9418871038c83be2", "title": "A feature-integration theory of attention"}, {"paperId": "f71bdb23973525b4ef8db0ab5323adea61d78c43", "title": "Cognitive Complexity and Cognitive Flexibility"}, {"paperId": "336f5ebe4a0e03697e87df9c5cb519fa4db39aa5", "title": "Factorizing Declarative and Procedural Knowledge in Structured, Dynamical Environments"}, {"paperId": null, "title": "Meta Research: DINO open-source repository"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "639174f32a71ecfe9041ad05ff30eb39bd4977bf", "title": "ObjectNet: A large-scale bias-controlled dataset for pushing the limits of object recognition models"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Set transformer: A framework for attention-based permutation-invariant neural networks"}, {"paperId": null, "title": "dsprites: Disentanglement testing sprites"}, {"paperId": "02227c94dd41fe0b439e050d377b0beb5d427cda", "title": "Reading Digits in Natural Images with Unsupervised Feature Learning"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "cebaf23fd90935847883d92627b554208bb7ca85", "title": "Space and attention in parietal cortex."}, {"paperId": null, "title": "CLIP_benchmark open-source project"}, {"paperId": null, "title": "Selective Attention in Transformer Encodings for Vision 16"}]}