{"paperId": "29168348f4729d418df5acc8a5fce4f1c428a7e3", "title": "Sparsifying Transformer Models with Trainable Representation Pooling", "abstract": "We propose a novel method to sparsify attention in the Transformer model by learning to select the most-informative token representations during the training process, thus focusing on the task-specific parts of an input. A reduction of quadratic time and memory complexity to sublinear was achieved due to a robust trainable top-k operator.Our experiments on a challenging long document summarization task show that even our simple baseline performs comparably to the current SOTA, and with trainable pooling we can retain its top quality, while being 1.8\\times faster during training, 4.5\\times faster during inference, and up to 13\\times more computationally efficient in the decoder.", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2020, "citationCount": 8, "influentialCitationCount": 2, "openAccessPdf": {"url": "https://aclanthology.org/2022.acl-long.590.pdf", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "A novel method to sparsify attention in the Transformer model by learning to select the most-informative token representations during the training process, thus focusing on the task-specific parts of an input."}, "embedding": {"model": "specter_v2", "vector": [0.25077852606773376, 0.6832966208457947, -0.5769678950309753, 0.03731990605592728, -0.8461282253265381, -0.35023826360702515, 0.8672153353691101, -0.013393566943705082, -0.1886461079120636, -0.07580424845218658, 1.1167861223220825, 0.6571914553642273, -0.030652571469545364, 0.24163340032100677, -0.058429863303899765, 0.16483274102210999, -0.6377474069595337, 0.5527655482292175, 0.1052049994468689, -0.2990129590034485, 0.15659211575984955, -0.9310345649719238, -0.565799355506897, 0.278887540102005, 0.5674331784248352, 0.45384031534194946, 0.16764013469219208, 0.8271365761756897, -0.428411602973938, 0.4184376001358032, -0.027711909264326096, -0.3162262737751007, 0.23581917583942413, -0.10155443102121353, -0.5955438613891602, -0.13208240270614624, 0.6590082049369812, -0.19834880530834198, -0.5141401290893555, 0.5237855315208435, -0.19509169459342957, 0.17552706599235535, 0.4045485556125641, -0.6383398771286011, -0.22469855844974518, 1.3038396835327148, 0.5872540473937988, 0.9085057377815247, -0.2794231176376343, -0.917590320110321, 1.658703327178955, -1.2630409002304077, 0.08203528076410294, 1.4268217086791992, 0.2831712067127228, 0.2996450662612915, -0.10018816590309143, -0.38711127638816833, 0.9418876767158508, 0.41068097949028015, -0.626869261264801, -0.5167539119720459, 0.05284009128808975, 0.09893440455198288, 2.015794515609741, -0.16394224762916565, 0.0184604711830616, 0.11988185346126556, -0.3153017461299896, 1.7358208894729614, -0.3729158341884613, -0.28083088994026184, -0.5853800177574158, -0.1819477081298828, 0.7672490477561951, 0.7669179439544678, -0.17615766823291779, -0.22374533116817474, -1.2017039060592651, -0.131253182888031, 0.10187165439128876, -0.009006071835756302, -0.006486145779490471, 0.16082675755023956, -0.3950403034687042, 0.44248390197753906, 0.48670268058776855, 0.9062219262123108, -0.49834081530570984, 0.8958197832107544, 0.8083332777023315, 0.26422420144081116, 0.23419831693172455, 0.6981229782104492, -0.016734657809138298, 0.565798819065094, -1.1500625610351562, 0.3380744159221649, -0.19713038206100464, 0.6635257005691528, -0.13707205653190613, 0.5351935029029846, -1.3490146398544312, 0.24368181824684143, 0.8586212992668152, 0.24089618027210236, 0.28291046619415283, -0.7107760906219482, 0.24749372899532318, -0.5321764945983887, 0.08464626222848892, -0.7672603726387024, -0.19508297741413116, -0.2851441204547882, -0.7226701974868774, -1.5393743515014648, -0.6578712463378906, 0.40363046526908875, -0.860788881778717, 0.6346655488014221, -0.6930335760116577, 0.1586386263370514, -0.11178863048553467, 0.27859780192375183, 0.6567283272743225, 0.9426330924034119, 0.1960645318031311, -0.3084573745727539, 1.0213254690170288, -1.0647947788238525, -0.8300700187683105, -0.8594980239868164, 0.5235469341278076, -0.2868208587169647, -0.13858523964881897, 0.2117377370595932, -1.4116716384887695, -1.0454968214035034, -0.7149598002433777, -0.28527456521987915, -0.35553544759750366, 0.34347328543663025, 0.7442559599876404, 0.3182196021080017, -1.1279221773147583, 0.6338896751403809, -0.30885016918182373, -0.1074407771229744, 0.5662132501602173, 0.22578299045562744, 0.1066475585103035, -0.15955063700675964, -1.1278107166290283, 0.486391544342041, 0.24635444581508636, -0.600420355796814, -0.30849170684814453, -0.8508907556533813, -1.0533666610717773, 0.3006754517555237, 0.375066876411438, -0.8380265831947327, 1.1633527278900146, 0.16753019392490387, -1.3979545831680298, 0.378997802734375, -0.8803579807281494, -0.1319180428981781, -0.008915378712117672, -0.6865463256835938, 0.04751782491803169, -0.20188669860363007, 0.04312759265303612, 0.01046130433678627, 0.20130041241645813, -0.05796542391180992, -0.16306644678115845, 0.17125505208969116, -0.34530505537986755, -0.19253747165203094, -0.26018381118774414, 1.220908761024475, -0.3511204421520233, -0.10970247536897659, 0.3210791349411011, 0.9544586539268494, 0.057630475610494614, -0.8442283272743225, -0.8965939879417419, -1.4336663484573364, 0.6712738275527954, -0.18529018759727478, 1.2316206693649292, -0.6919940114021301, -0.27645909786224365, -0.32437387108802795, -0.12427075952291489, 0.3281937539577484, -0.6579622030258179, 0.7147417664527893, -0.37302732467651367, 0.4144693911075592, -0.1731918603181839, -1.2624198198318481, 0.33918312191963196, -0.4610889256000519, -0.9336194396018982, -0.2745698094367981, 0.5726774334907532, 1.2225333452224731, -0.9219646453857422, 0.12349709123373032, 0.12654784321784973, 0.08660654723644257, -1.0211472511291504, 1.1943670511245728, -0.2023094743490219, -0.022178897634148598, -0.5409175753593445, -0.2690781354904175, 0.15633060038089752, -0.1773519217967987, 0.13676179945468903, -0.5794125199317932, -0.24735192954540253, 0.893444299697876, -0.592034637928009, 1.3223388195037842, -0.11515238881111145, 0.4692254662513733, -0.10489074140787125, -1.2128026485443115, 0.29339107871055603, 0.44554847478866577, -0.1324617862701416, -0.3583660125732422, 0.0915626510977745, 0.3236587941646576, -1.1457610130310059, 0.18758459389209747, 1.1017687320709229, 0.7152872085571289, -0.7078619003295898, 0.10850386321544647, 0.7088208198547363, -0.2591135501861572, 0.8587157130241394, 0.7953711748123169, 0.711361825466156, 0.09835390001535416, 0.5125961303710938, -0.1067761778831482, 0.4543268382549286, -0.3769022822380066, 0.12229116261005402, 0.5422690510749817, 0.8585613369941711, 1.0328580141067505, 0.6620160937309265, -0.6159308552742004, -0.3431084454059601, -0.10860587656497955, 0.8921313881874084, 1.4604581594467163, -0.3592628836631775, -0.46992227435112, -0.49563005566596985, -0.18602533638477325, -0.6247896552085876, -0.0208680909126997, -0.32856497168540955, -0.35733532905578613, -0.8738264441490173, -0.9840207695960999, 0.9761516451835632, 0.4323505759239197, 1.089096188545227, -0.1825188547372818, 0.06403403729200363, -0.2918091118335724, -0.22596526145935059, -0.7561566829681396, -0.7082960605621338, 0.4150676429271698, -0.32572799921035767, -0.3856724798679352, -0.02836013399064541, -0.13451284170150757, 0.01963648945093155, -0.41349905729293823, 1.1670136451721191, -0.4092191457748413, 0.05145633593201637, 0.053474247455596924, 0.48284807801246643, -0.7396184206008911, -0.46350979804992676, 0.22059649229049683, 0.17097705602645874, -0.2709536552429199, 0.24957513809204102, 0.7111220359802246, 0.2907039225101471, 0.11453723162412643, -0.4456910192966461, 0.048228129744529724, -0.21260234713554382, 0.3042408525943756, 0.5997334718704224, -0.12705132365226746, 0.13742034137248993, -1.1512963771820068, 0.6156516075134277, 0.3390565514564514, -0.20727457106113434, 0.3813895583152771, -0.2090691775083542, -0.2603868842124939, 0.5453072786331177, -0.26363226771354675, -0.2693037986755371, -1.0057207345962524, 0.6197159290313721, -0.07489030063152313, 0.20881469547748566, 0.4627373516559601, 0.06375793367624283, 0.5745036602020264, 0.034534893929958344, 0.5469092130661011, 0.07194594293832779, -0.24448268115520477, 0.3434036076068878, -0.8439148664474487, 0.6037280559539795, 0.4513552188873291, 0.3784020245075226, -0.06951037794351578, -0.2271130383014679, -0.6805434226989746, -0.7517407536506653, -0.5569341778755188, -0.09551603347063065, 0.027528224512934685, 0.20598995685577393, -0.5935455560684204, -0.5150577425956726, 0.07915311306715012, -1.252612829208374, 0.0387556329369545, -0.12668386101722717, -0.4263613522052765, -0.14962150156497955, -0.9854578971862793, -1.1433478593826294, -0.4857266843318939, -0.8225128650665283, -0.7179092764854431, 0.6014063954353333, 0.26765769720077515, -0.36521419882774353, -0.4461558759212494, 0.1477040946483612, -0.14820335805416107, 1.0480408668518066, -0.27116334438323975, 0.6099111437797546, -0.37003010511398315, -0.5417924523353577, -0.5472900867462158, 0.1171814426779747, 0.7981134057044983, -0.3588256537914276, 0.24835443496704102, -0.7705071568489075, 0.28374263644218445, -0.3589004576206207, -0.1786309778690338, 0.8893745541572571, 0.7917200326919556, 0.41573426127433777, -0.0582868866622448, -0.6477953791618347, 0.15077543258666992, 1.1248579025268555, -0.9972112774848938, 0.10371894389390945, 0.15468105673789978, 1.115450382232666, 0.2824389934539795, -0.07700612396001816, 0.49620288610458374, 0.3722364604473114, 0.46094533801078796, -0.03589988499879837, -0.42763635516166687, -0.20568841695785522, -0.5667552947998047, 0.7702747583389282, 1.7154011726379395, 0.1290862113237381, -0.39191964268684387, -0.695737898349762, 0.8703092336654663, -1.4064925909042358, -1.1618096828460693, 0.5153918862342834, 0.7139886617660522, -0.03280347213149071, -0.5943629145622253, -0.05750930309295654, 0.1712327003479004, 0.7218589782714844, 0.38862305879592896, -0.1756194829940796, -0.7513195276260376, -0.08519742637872696, 0.6856369376182556, 0.4569583237171173, 0.5291141867637634, -0.20214581489562988, 0.7272842526435852, 14.778680801391602, 0.7016172409057617, 0.06131710484623909, 0.42617931962013245, 0.3947845697402954, -0.10558252781629562, -0.368020623922348, 0.04077744483947754, -1.163764476776123, -0.2869377136230469, 0.977771520614624, -0.4938930869102478, 0.36751043796539307, -0.08115211874246597, 0.30463531613349915, 0.202600359916687, -0.6182541251182556, 0.433425635099411, 0.6816917061805725, -1.273090124130249, 0.6645320653915405, 0.15250292420387268, 0.35026857256889343, 0.5357005000114441, 0.6856268048286438, 0.8715540766716003, 0.25175008177757263, -0.49959442019462585, 0.3013834059238434, 0.258640855550766, 0.4478404223918915, -0.16076375544071198, 0.6760810017585754, 0.21215590834617615, -1.019783854484558, -0.32789406180381775, -0.6379393339157104, -1.2025552988052368, 0.528520941734314, 0.35975345969200134, -0.634397566318512, 0.1961691975593567, -0.41122543811798096, 1.2728453874588013, 0.18042156100273132, 0.6089697480201721, -0.319486141204834, 0.8055216670036316, -0.22196565568447113, 0.17046549916267395, 0.20457124710083008, 0.775172233581543, 0.5748207569122314, 0.27118217945098877, 0.21033790707588196, 0.08299508690834045, 0.3569871783256531, 0.2566280961036682, -0.5360057353973389, -0.15507714450359344, -0.19722236692905426, -0.34204432368278503, 0.03541332855820656, 0.8687896132469177, 0.65312659740448, -0.18734373152256012, -0.17207977175712585, 0.086947001516819, 0.3237476646900177, 0.004855110310018063, -0.3249059319496155, -0.2873595356941223, 0.11066235601902008, -0.1816883236169815, 0.0780397430062294, 0.6082687973976135, -0.08424031734466553, -0.6786370873451233, -0.6555007100105286, -0.04876962676644325, 0.664760947227478, -0.577030599117279, -0.6880455017089844, 0.6568924784660339, 0.21826918423175812, -0.5469900369644165, 0.28563153743743896, -0.4931139349937439, -0.7042209506034851, 0.3132649064064026, -1.752037763595581, -0.7977208495140076, 0.3152434229850769, -0.20689783990383148, -0.23121461272239685, 0.11976411193609238, 1.0642716884613037, 0.06844385713338852, -0.4765836298465729, 0.03346127271652222, -0.0574677512049675, -0.21374143660068512, -0.08305947482585907, -1.021158218383789, 0.5754708647727966, 0.36551904678344727, -0.13911761343479156, 0.35364028811454773, 0.27008965611457825, 0.4771018624305725, -0.7699323296546936, 0.08478128910064697, 1.163794994354248, -0.888066291809082, -0.6174042820930481, -0.36770087480545044, -0.836321234703064, 0.41251540184020996, 0.6858005523681641, -0.25472360849380493, 0.4086311161518097, 0.32868513464927673, -0.47157183289527893, -0.20839178562164307, -0.8170303106307983, -0.512388288974762, 0.31833648681640625, -0.5500507950782776, -0.5212820172309875, 0.11739419400691986, 0.18237346410751343, -0.7616287469863892, -0.10425197333097458, -0.43792396783828735, -0.309700071811676, 0.0825066938996315, 1.0378260612487793, -0.3332832157611847, 0.5387934446334839, 0.47851285338401794, 0.03198876976966858, -1.1056373119354248, -0.48531320691108704, -0.9745232462882996, 0.06840666383504868, 0.5523514747619629, 0.3537302613258362, -0.22718384861946106, 0.08930624276399612, 0.6637808680534363, -0.10430037975311279, 0.019335731863975525, -0.6212158799171448, -0.1923263967037201, 0.10482221841812134, -0.1809413731098175, 0.13332606852054596, -0.2882745862007141, 0.22286343574523926, 0.11409863084554672, 0.3053310811519623, 0.661865234375, -0.2848655581474304, -0.9696633815765381, 0.6352384090423584, -0.2330973595380783, 0.4673539102077484, -0.7504207491874695, -0.6457992792129517, -1.2787710428237915, 0.07269779592752457, -1.2451785802841187, -0.012557756155729294, -1.682436466217041, 0.0035898948553949594, 0.7010747194290161, -0.5630401372909546, 0.41045770049095154, -0.01834762655198574, -0.29974350333213806, -0.36487123370170593, -0.7395740747451782, -1.0257278680801392, 0.6671101450920105, 0.6924346089363098, -0.9754104018211365, 0.09215247631072998, -0.2849491238594055, -0.532684326171875, 0.19797074794769287, 0.42898836731910706, -0.5420562028884888, -0.5480735301971436, -1.3802167177200317, 0.21211804449558258, -0.12355536967515945, 0.06524379551410675, -0.5452492237091064, 0.8175669312477112, 0.6496814489364624, -0.16390351951122284, -0.12941160798072815, 0.20461326837539673, -0.4197342097759247, -0.583724856376648, 0.21607936918735504, -0.8461900353431702, 0.12915076315402985, 0.2844451367855072, -0.7419455051422119, -0.6074732542037964, 0.9410760998725891, -0.22088627517223358, -1.1074553728103638, -0.5358467102050781, 0.24955075979232788, -0.5306980013847351, 0.2891463339328766, -0.48595738410949707, -0.245598703622818, -1.1067321300506592, -0.21662726998329163, 0.3844606280326843, 0.7222316861152649, -0.42404085397720337, 0.7630786895751953, 0.19646649062633514, -1.10063898563385, -0.3585088849067688, 0.023103954270482063, -0.13912923634052277, 0.04722011461853981, 0.5447043776512146, 0.31055864691734314, 0.09636303037405014, 0.674768328666687, 0.3236468732357025, 0.3201095461845398, -0.877005934715271, -0.3144643008708954, 0.5098598003387451, -1.0366939306259155, -0.21391183137893677, 1.1351959705352783, -0.4216051399707794, -0.5461002588272095, -0.034132231026887894, -1.2157139778137207, -0.7974625825881958, 0.030735012143850327, 1.2336387634277344, 0.5632656812667847, -0.04808821156620979, -0.1456241011619568, -0.7140797972679138, 0.2707909643650055, -0.3602137267589569, -0.2775569260120392, 0.8859317898750305, -0.05773644894361496, -0.6559026837348938, 0.5306585431098938, 0.7201929688453674, -0.7895593643188477, -0.38571298122406006, -0.8654433488845825, -0.21575097739696503, -0.15543819963932037, 0.5250445604324341, -0.30280572175979614, -0.6611225605010986, 0.7335445284843445, 0.12376637756824493, 0.697512149810791, 0.2398044317960739, -0.14751775562763214, 0.2788928747177124, 0.6512508988380432, -0.07629205286502838, -0.6129841804504395, -0.41140565276145935, 1.4240788221359253, 1.2625054121017456, -0.7234815359115601, 0.449810266494751, -0.03772992640733719, -1.0292279720306396, 0.7916350364685059, -0.07554513961076736, -0.4262932538986206, 0.43347305059432983, -0.4244942367076874, -0.1707054227590561, 0.08626434206962585, -1.1463505029678345, -0.2906232178211212, 0.8819206953048706, 1.0354160070419312, 0.8692334890365601, 0.09586269408464432, 0.06606314331293106, 1.1030335426330566, 0.08973687142133713, 0.1058405190706253, 0.6819661259651184, 0.2865998446941376, -0.28001394867897034, -0.018759189173579216, 0.12787282466888428, 0.5118045806884766, -0.9303597211837769, -0.352290540933609, 0.03241420537233353, 0.34764549136161804, -0.21200916171073914, 0.9629011750221252, 0.6252454519271851, 0.3143548369407654, 0.9789035320281982, 0.20039168000221252, 0.4979187548160553, -0.7702497243881226, -0.6277821063995361, -0.3411191701889038, -0.41830572485923767, -0.26415765285491943, -0.46882522106170654, -0.6802430748939514, -0.5258538126945496, -0.1616426259279251, 0.0708688497543335, 0.3953239619731903, 0.15473432838916779, 1.161280870437622, 0.6520501375198364, 0.7465695738792419, -0.14416223764419556, -0.7696453332901001, -0.33643701672554016, -1.192330002784729, -0.12317877262830734, -0.38551315665245056, 0.13546603918075562, -0.26417994499206543, -0.19892346858978271, -0.17773061990737915]}, "authors": [{"authorId": "1749652564", "name": "Michal Pietruszka"}, {"authorId": "3448729", "name": "\u0141ukasz Borchmann"}, {"authorId": "79665491", "name": "Lukasz Garncarek"}], "references": [{"paperId": "717d65440e1a21feb35640210dd0a6c767591b99", "title": "Doc2Dict: Information Extraction as Text Generation"}, {"paperId": "e32a12b14e212506115cc6804667b3d8297917e1", "title": "Poolingformer: Long Document Modeling with Pooling Attention"}, {"paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6", "title": "Multiscale Vision Transformers"}, {"paperId": "836e9619f779f2d9642561f2b697ba471b866b27", "title": "Hierarchical Learning for Generation with Long Source Sequences"}, {"paperId": "ba0548f16bdbf98a2671798946c28f1a6559e582", "title": "Successive Halving Top-k Operator"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "3df83a60f55c64b40e6dbcd99cf9f67894a0736e", "title": "Do Transformers Need Deep Long-Range Memory?"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "4ca3b0ea12f02e2dea01a4aa505956bae5500a09", "title": "Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "01b15017ac59b8d6f2ce3598c4a7d6358c211426", "title": "A Divide-and-Conquer Approach to the Summarization of Long Documents"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "e1678aece552737a99e46b3e4ddb854347466e1e", "title": "Differentiable Top-k Operator with Optimal Transport"}, {"paperId": "94f94e8892261d0377159379ca5a166ceae19a14", "title": "PoWER-BERT: Accelerating BERT Inference via Progressive Word-vector Elimination"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "d5ba83cc43fbfc515d31985759099d1f2bff9a6f", "title": "Reparameterizable Subset Sampling via Continuous Relaxations"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "5f4a22ee70ca613d9c0630eafc96364fe365fdf8", "title": "Efficient Attention: Attention with Linear Complexities"}, {"paperId": "cfadc984973aa0ee446157310c9045627de7d7d1", "title": "Neural Nearest Neighbors Networks"}, {"paperId": "7af89df3691d8c33aaf1858f7cc51da1bc9549a9", "title": "Bottom-Up Abstractive Summarization"}, {"paperId": "41b3180745068934bd9f7f2fbc2efc00c64d534b", "title": "Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting"}, {"paperId": "d381709212dccf397284eee54a1e3010a4ef777f", "title": "A Unified Model for Extractive and Abstractive Summarization using Inconsistency Loss"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a", "title": "The NarrativeQA Reading Comprehension Challenge"}, {"paperId": "5903924863200f85d850e7bc6e503381e3723f02", "title": "Temporal dynamics of eye\u2010tracking and EEG during reading and relevance decisions"}, {"paperId": "fee62123e1d2ac56065675983475b079e1e9106f", "title": "A Continuous Relaxation of Beam Search for End-to-end Training of Neural Sequence Models"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "c14f416bab5a4936deded9797883e14ac0b55fff", "title": "Differentiable Scheduled Sampling for Credit Assignment"}, {"paperId": "5256b6d0ffe5b0dbcd979e2a8404326732b5ed51", "title": "Coarse-to-Fine Question Answering for Long Documents"}, {"paperId": "99f9718faf84e017ead656f62aebe1ab9b289a2c", "title": "Making do with what we have: use your bootstraps."}, {"paperId": "8543e96a026471ab92a59ce27621f262c16fcab0", "title": "Understanding the strategies of document literacy and their conditions of use."}, {"paperId": "5665805becad6c87b194b260f2270d86d560bd3f", "title": "On Extractive and Abstractive Neural Document Summarization with Transformer Language Models"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "02e48745f2cb95bdd358c0622c9ce23d3366e4a1", "title": "Types of Document Knowledge: From Structures to Strategies (Document Strategies)."}, {"paperId": null, "title": "# ROUGE-1 (CI) ROUGE-2 (CI)"}, {"paperId": null, "title": "2020) parametrized the top-k operator in terms of an optimal transport problem. Employing such an algorithm instead of softmax may induce numerous zero weights in the attention matrix"}, {"paperId": null, "title": "We assumed a fixed length of 256 or 512 tokens to decode to discount for lower processing time of models predicting the end of sequence token earlier"}, {"paperId": null, "title": "pooling). PoWER-BERT. As it comes to the PoWER-based models, we finetune Vanilla transformers with a progressive elimination of word vectors on the encoder side, following the approach"}, {"paperId": null, "title": "Without local attention, their results were several points lower. We assumed an LSH bucket size of 64 and four parallel hashes. Bucket size follows the authors"}]}