{"paperId": "6be32b4321f95b79bb2e37feeab0c3c7f902195e", "title": "Vicinity Vision Transformer", "abstract": "Vision transformers have shown great success on numerous computer vision tasks. However, their central component, softmax attention, prohibits vision transformers from scaling up to high-resolution images, due to both the computational complexity and memory footprint being quadratic. Linear attention was introduced in natural language processing (NLP) which reorders the self-attention mechanism to mitigate a similar issue, but directly applying existing linear attention to vision may not lead to satisfactory results. We investigate this problem and point out that existing linear attention methods ignore an inductive bias in vision tasks, i.e., 2D locality. In this article, we propose Vicinity Attention, which is a type of linear attention that integrates 2D locality. Specifically, for each image patch, we adjust its attention weight based on its 2D Manhattan distance from its neighbouring patches. In this case, we achieve 2D locality in a linear complexity where the neighbouring image patches receive stronger attention than far away patches. In addition, we propose a novel Vicinity Attention Block that is comprised of Feature Reduction Attention (FRA) and Feature Preserving Connection (FPC) in order to address the computational bottleneck of linear attention approaches, including our Vicinity Attention, whose complexity grows quadratically with respect to the feature dimension. The Vicinity Attention Block computes attention in a compressed feature space with an extra skip connection to retrieve the original feature distribution. We experimentally validate that the block further reduces computation without degenerating the accuracy. Finally, to validate the proposed methods, we build a linear vision transformer backbone named Vicinity Vision Transformer (VVT). Targeting general vision tasks, we build VVT in a pyramid structure with progressively reduced sequence length. We perform extensive experiments on CIFAR-100, ImageNet-1 k, and ADE20 K datasets to validate the effectiveness of our method. Our method has a slower growth rate in terms of computational overhead than previous transformer-based and convolution-based networks when the input resolution increases. In particular, our approach achieves state-of-the-art image classification accuracy with 50% fewer parameters than previous approaches.", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2022, "citationCount": 18, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2206.10552", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "Vicinity Attention, which is a type of linear attention that integrates 2D locality that achieves state-of-the-art image classification accuracy with 50% fewer parameters than previous approaches, is proposed."}, "embedding": {"model": "specter_v2", "vector": [0.42280739545822144, 0.47477826476097107, 0.17601443827152252, 0.18191410601139069, -0.2785457670688629, 0.21068090200424194, 0.9547972083091736, -0.16666041314601898, -0.548347532749176, -0.9596756100654602, 0.5626058578491211, 0.4179442524909973, 0.3802741467952728, -0.04424431174993515, -0.3143894374370575, -0.042840320616960526, -0.6178941130638123, -0.27621468901634216, 0.6559938788414001, -0.561855673789978, 0.235014870762825, -0.4103744626045227, -1.4007408618927002, 0.5124236941337585, 0.052220262587070465, 0.9433480501174927, 0.7900155782699585, 0.9571549296379089, -0.19179005920886993, 0.47112420201301575, 0.5974112749099731, -0.04203725606203079, 0.4212837219238281, 0.13152296841144562, -0.31042981147766113, 0.08911265432834625, 0.9014662504196167, -0.1758367419242859, -0.6452410817146301, 1.197872519493103, -0.08777020871639252, 0.20659981667995453, 0.4070596694946289, -0.49768149852752686, -0.7136938571929932, 0.4743845462799072, 0.2987250089645386, 0.9686353206634521, -0.47635310888290405, -0.47054529190063477, 1.211776852607727, -1.4608503580093384, -0.09486241638660431, 1.661371111869812, 0.41960424184799194, 0.1338050365447998, 0.03613075986504555, -0.13941632211208344, 0.9247620701789856, 0.28679391741752625, -0.8646206855773926, -0.25536400079727173, 0.07636811584234238, -0.023763099685311317, 2.0078303813934326, -0.708134651184082, 0.08473759889602661, 0.21658365428447723, 0.3375934660434723, 1.135012149810791, -0.1451292335987091, -1.030164361000061, -0.45078903436660767, -0.22556695342063904, 0.3625372350215912, 0.8069821000099182, -0.5306717157363892, 0.0684863030910492, -0.954293966293335, 0.011038638651371002, 0.8174259662628174, 0.1492605060338974, 0.18726155161857605, -0.13094176352024078, -0.18960025906562805, 0.5499956607818604, 1.1147043704986572, 0.644173800945282, -0.600935161113739, 0.8780831694602966, 0.28288474678993225, -0.11484623700380325, -0.18692760169506073, 0.3337738811969757, 0.42738276720046997, 1.1344395875930786, -0.47249969840049744, -0.027665965259075165, -0.5154880285263062, 1.1621628999710083, 0.07587108761072159, 0.08552377671003342, -0.5769574046134949, 0.19248181581497192, 1.271968960762024, 0.199980229139328, 0.3262854814529419, -0.49021801352500916, -0.0028911756817251444, -0.8697099089622498, -0.29290494322776794, -0.8777368068695068, 0.2039247751235962, -0.3478909134864807, -0.6650314927101135, -0.49841073155403137, -0.22999180853366852, 0.6425189971923828, -0.8679111003875732, 0.33414018154144287, -0.546662449836731, -0.06320290267467499, -0.062053266912698746, 0.608148455619812, 0.4120769500732422, 0.40250054001808167, 0.3106338083744049, 0.6318936944007874, 1.6093683242797852, -1.1449799537658691, -0.19366726279258728, -0.8750383257865906, -0.24429334700107574, -0.550958514213562, 0.49033790826797485, -0.25821587443351746, -1.1000447273254395, -1.3105592727661133, -0.7456678748130798, -0.22509802877902985, -0.8742213249206543, 0.0690649226307869, 0.8733007311820984, -0.23288963735103607, -1.394734501838684, 0.7740452289581299, -0.02450736239552498, -0.5010406970977783, 0.7745938897132874, 0.2096175104379654, 0.41707053780555725, -0.3328472673892975, -1.2474339008331299, 0.37128475308418274, 0.00955397542566061, -0.4697408676147461, -0.3040402829647064, -0.41766494512557983, -1.0703867673873901, 0.3654661178588867, 0.04776393994688988, -0.7064025402069092, 1.007926344871521, -0.4641824960708618, -0.5082497000694275, 0.6471514105796814, -0.35140910744667053, -0.17611482739448547, -0.2529293894767761, -0.38357090950012207, -0.13930866122245789, -0.1967780739068985, 0.0007923031225800514, 0.9058473110198975, 1.0633511543273926, -0.10991781204938889, -0.5601486563682556, 0.12502746284008026, -0.24148622155189514, 0.22817693650722504, -0.6671437621116638, 0.9682974219322205, -0.7302100658416748, -0.14146029949188232, 0.13539119064807892, 0.7362802624702454, 0.09996640682220459, -0.16742676496505737, 0.15047761797904968, -1.113142728805542, 0.7910670638084412, 0.3948841691017151, 0.2837388813495636, -0.9536635279655457, -1.014862298965454, -0.2768886983394623, 0.22615525126457214, -0.15415838360786438, -1.1067960262298584, 0.4825288653373718, -0.43384265899658203, 0.007245906163007021, 0.3856523931026459, -0.6326717734336853, -0.1479208618402481, -0.6095151901245117, -0.7682363390922546, -0.07041333615779877, 0.4164567291736603, 1.2344452142715454, -1.0469586849212646, -0.12925197184085846, 0.009187821298837662, 0.523227870464325, -0.6999770998954773, 0.9671388268470764, -0.33910825848579407, -0.3939914405345917, -0.12665587663650513, -0.04839465022087097, 0.023376736789941788, -0.48728999495506287, 0.1915978342294693, -0.7934748530387878, -0.16555644571781158, 0.38359335064888, 0.3213791251182556, 1.1621973514556885, -0.2994804382324219, 0.8414146304130554, -0.18108496069908142, -0.6496394276618958, 0.41497522592544556, 0.07893789559602737, -0.5063062906265259, -0.7399564385414124, 0.21052274107933044, -0.22770777344703674, -0.6470583081245422, 0.2461610585451126, 0.5954686999320984, 1.2574180364608765, -0.21208584308624268, -0.18143099546432495, 0.7477172613143921, -0.10735726356506348, -0.06318958103656769, 0.4887329339981079, 0.7339203357696533, 0.3333791196346283, 0.5573897361755371, -0.45534518361091614, 0.09491948783397675, -0.8170755505561829, -0.37911027669906616, 0.8514047861099243, 0.44378840923309326, 1.2197762727737427, 0.4422871172428131, -1.0427117347717285, -0.7984265685081482, 0.07694117724895477, 0.6091912388801575, 1.5877017974853516, 0.05675794184207916, 0.043560586869716644, -0.6991113424301147, -0.1596250683069229, -0.6015034317970276, -0.6568408608436584, -0.5346364974975586, -0.26978442072868347, -0.2516859769821167, -0.9077574610710144, 0.6747220158576965, 0.4677095115184784, 1.340240716934204, -0.9022826552391052, -0.49015212059020996, -0.4086504280567169, 0.48683521151542664, -1.026023507118225, -1.0249227285385132, 0.3497263789176941, -0.12598943710327148, -0.0638168677687645, 0.025304216891527176, -0.5522506833076477, 0.5277597904205322, -0.11702209711074829, 0.8997598886489868, -0.5706230998039246, -0.592584490776062, 0.3622358739376068, 0.42682626843452454, -0.8296443223953247, -0.07651565968990326, 0.33359435200691223, 0.004434152040630579, -0.07744116336107254, 0.7296914458274841, 0.25700584053993225, -0.23200999200344086, -0.11674191057682037, -0.5346220135688782, -0.19745264947414398, 0.5856854319572449, 0.10944024473428726, 0.8657323718070984, -0.19463422894477844, 0.03676411136984825, -0.8392387628555298, 0.925268292427063, 0.30175116658210754, -0.4600497782230377, 0.1338888555765152, -0.5367688536643982, -0.2812190055847168, 0.6483441591262817, -0.6539514064788818, -0.13374434411525726, -0.10068042576313019, 0.5783202648162842, -1.0400757789611816, -0.5096127986907959, -0.0993419662117958, 0.21704892814159393, -0.2123613953590393, 0.7088282108306885, 0.6168984174728394, 0.40145251154899597, 0.22738969326019287, 0.3747578263282776, -0.9901695847511292, 0.9285545945167542, 0.3948386311531067, 0.11050894111394882, 0.15147832036018372, 0.09382274746894836, -0.9125479459762573, -0.8327928781509399, -0.6954997777938843, -0.4962804317474365, -0.41164934635162354, 0.3561851978302002, -0.5454974174499512, -1.0309576988220215, 0.023375635966658592, -0.998801052570343, -0.0077875396236777306, -0.01118962187319994, -0.29227957129478455, -0.2331439107656479, -0.9136236310005188, -0.7988449335098267, -0.32577913999557495, -0.6422141194343567, -0.8538880944252014, 0.3110021948814392, 0.36597684025764465, -0.017532404512166977, -0.48423629999160767, -0.45841386914253235, -0.5360397100448608, 1.1401561498641968, -0.4241335093975067, 0.5233649611473083, 0.1398284137248993, -0.4054306149482727, -0.27164313197135925, -0.24826207756996155, 0.38947105407714844, -0.0873308926820755, -0.08742491900920868, -1.221842885017395, 0.5650928020477295, -0.2832527756690979, -0.25156015157699585, 0.6891732811927795, 0.4643683433532715, 0.6782353520393372, 0.19243380427360535, -0.39446184039115906, 0.3102247714996338, 1.574719786643982, -0.8848257660865784, 0.29027819633483887, 0.26538488268852234, 0.8804228901863098, 0.18111847341060638, -0.1279534101486206, 0.41488227248191833, 0.36703890562057495, 0.21494421362876892, 0.7607516646385193, -0.6417888402938843, -0.7986054420471191, -0.6627805829048157, 0.2038184553384781, 0.696876049041748, 0.14511623978614807, 0.3705407381057739, -0.9566922783851624, 1.0287691354751587, -1.313535451889038, -0.991671085357666, 0.8324657082557678, 0.6350257992744446, 0.12717470526695251, -0.4324262738227844, -0.25724470615386963, -0.7245191931724548, 0.8620124459266663, 0.34145882725715637, -0.26368582248687744, -0.5244196057319641, -0.18647852540016174, 0.2928183078765869, 0.35576221346855164, 0.805558979511261, -0.8394662141799927, 0.8492513298988342, 14.654203414916992, 0.7894812226295471, -0.15965597331523895, 0.23971320688724518, 0.5545678734779358, 0.37866559624671936, -0.007094003725796938, 0.002778437687084079, -1.318739414215088, -0.47842535376548767, 0.421707421541214, 0.462228924036026, 0.7505955696105957, 0.27777475118637085, -0.20462147891521454, 0.2705058157444, -0.43477845191955566, 0.9070775508880615, 1.0482720136642456, -1.2785588502883911, 0.5011246800422668, 0.22218859195709229, 0.2037687599658966, 0.5362746715545654, 1.1078401803970337, 0.32992035150527954, 0.26135754585266113, -0.5930454730987549, 0.3098359704017639, 0.6318433880805969, 0.8389867544174194, 0.0007849016110412776, 0.2594253718852997, 0.18114404380321503, -1.1981797218322754, -0.24687987565994263, -1.1195290088653564, -1.0547147989273071, -0.30291548371315, 0.07072263211011887, -0.5507868528366089, -0.7633846402168274, 0.2478596568107605, 0.6740138530731201, -0.15651243925094604, 0.43629080057144165, -0.18749676644802094, -0.08661603182554245, -0.10335841029882431, -0.29582223296165466, 0.6128443479537964, 0.8017012476921082, 0.11160898208618164, 0.11384786665439606, -0.18137575685977936, 0.26936888694763184, 0.15788796544075012, 0.586122989654541, -0.42594268918037415, -0.33120226860046387, -0.40850502252578735, 0.18794302642345428, -0.16996890306472778, 1.2382738590240479, 0.24059252440929413, 0.36119455099105835, -0.4713462293148041, 0.24998022615909576, 0.6694909930229187, 0.19607140123844147, -0.35051679611206055, -0.3361626863479614, 0.22704945504665375, -0.16881607472896576, 0.5601294040679932, 0.6742030382156372, -0.2917711138725281, -0.29893916845321655, -0.7222589254379272, 0.02061724290251732, 0.26401516795158386, -0.9301093220710754, -0.7799096703529358, 1.3337185382843018, -0.37546226382255554, -0.3181407153606415, 0.6644918918609619, -0.9225351214408875, -0.4489670395851135, 0.5346805453300476, -1.5758863687515259, -0.9866167306900024, -0.1591615080833435, -0.026754673570394516, -0.2586452066898346, -0.34407421946525574, 0.9013649225234985, -0.17450304329395294, 0.31333839893341064, 0.0392894372344017, -0.6299918293952942, 0.06989897787570953, -0.047717079520225525, -0.6654775738716125, 0.7088563442230225, 0.4748397767543793, -0.03898192569613457, 0.1588641256093979, -0.04948323965072632, 0.39067211747169495, -0.5577143430709839, -0.1635720282793045, 0.7357981204986572, -0.6177394986152649, -0.4330310821533203, -0.7646794319152832, -0.7121613025665283, 0.04111163690686226, 0.8359370827674866, 0.26103273034095764, -0.20390774309635162, 0.2034798115491867, -0.8979307413101196, -0.25983816385269165, -0.47502756118774414, 0.18072472512722015, 0.2508001923561096, -0.8795110583305359, -0.45666804909706116, -0.07493393868207932, 0.3235912621021271, -0.7415550947189331, -0.4863443672657013, -0.3759511113166809, 0.281077116727829, -0.3118475675582886, 1.383437156677246, -0.2670079469680786, 0.6559751629829407, 0.5247255563735962, -0.19679726660251617, -0.44185250997543335, -0.7114483714103699, -0.6679118275642395, 0.33315059542655945, 0.246148481965065, 0.39492541551589966, -0.4100894033908844, -0.04794757068157196, 0.5879791378974915, 0.2517346143722534, -0.405843585729599, -0.28040823340415955, 0.006094909273087978, -0.1289573460817337, -0.31602713465690613, 0.05266854539513588, -0.13767656683921814, 0.18489772081375122, 0.46114546060562134, 0.6184729933738708, 0.7171420454978943, 0.09804312884807587, -0.42529597878456116, -0.03754902631044388, 0.00024445250164717436, -0.029100626707077026, -0.6949499249458313, -0.7018961310386658, -1.5459333658218384, -0.13716121017932892, -1.0410629510879517, 0.039935316890478134, -0.908178448677063, -0.3488142490386963, 0.44065046310424805, -0.37555432319641113, 0.4182279109954834, 0.19308799505233765, -0.03226248174905777, -0.14237724244594574, -0.4226970672607422, -0.7747693061828613, 0.6810624003410339, 0.9690088629722595, -0.728315532207489, 0.27922293543815613, -0.19150961935520172, -0.3717714846134186, 0.5882378220558167, 0.29591861367225647, -0.3243381083011627, -0.7651947140693665, -1.20216703414917, 0.2401413768529892, -0.4279778301715851, 0.19756463170051575, -0.9867327213287354, 1.3633695840835571, 0.7691783905029297, 0.2027401179075241, -0.00967851560562849, 0.5232939720153809, -0.8860591650009155, -1.1942452192306519, 0.09113036096096039, -0.841454267501831, -0.0033084210008382797, 0.3267623484134674, -0.4353710114955902, -0.4516010880470276, 0.8494182825088501, 0.3358818292617798, -1.2486653327941895, -1.1041395664215088, 0.4967125952243805, -0.5043240189552307, -0.08507738262414932, -0.3207251727581024, -0.12024043500423431, -1.3960720300674438, -0.49157029390335083, -0.08750554174184799, 0.2560136914253235, -0.5372887849807739, 0.8349546790122986, 0.9474180936813354, -1.2479445934295654, 0.007138487882912159, 0.35912927985191345, -0.0882241278886795, 0.0877922996878624, 0.39204373955726624, 0.4310435652732849, -0.15778768062591553, 0.6002328991889954, -0.05525388568639755, 0.15154238045215607, -0.9771201610565186, 0.5000849366188049, 0.9392868280410767, -0.04827515408396721, -0.36371827125549316, 0.9704769849777222, 0.2884683907032013, -0.6789469122886658, 0.1762346625328064, -0.9341443777084351, -0.7875344157218933, -0.30943113565444946, 0.8271611928939819, -0.2506706416606903, -0.05965716391801834, 0.03412972763180733, -0.5750516653060913, 0.5539489388465881, -0.16349051892757416, -0.2950429916381836, 0.3354366421699524, -0.08863936364650726, -0.44800713658332825, 0.08863063901662827, 0.6198317408561707, -0.9709563255310059, -1.0896837711334229, -1.2613565921783447, -0.49630436301231384, -0.06668251752853394, 0.4634365737438202, 0.020192811265587807, -0.6682760715484619, 0.8050836324691772, 0.5609011054039001, 0.4110693335533142, 0.6119978427886963, 0.19367733597755432, -0.2239828109741211, 0.9049707651138306, -0.3465839922428131, -0.5140936970710754, -0.27679190039634705, 1.4874905347824097, 1.4594364166259766, -0.5397112965583801, 0.10684823244810104, -0.4416571855545044, -0.6674091219902039, 0.9099849462509155, 0.5033295750617981, -0.7119463086128235, 1.0628345012664795, 0.19877177476882935, 0.048125430941581726, 0.028792910277843475, -1.0156710147857666, -0.719964861869812, 0.920887291431427, 1.44683039188385, 0.44603273272514343, -0.222483292222023, 0.5236505270004272, 0.5768067836761475, 0.24552960693836212, -0.304874449968338, 0.22816477715969086, 0.1178349107503891, -0.49160146713256836, 0.32824406027793884, -0.44167622923851013, 0.4080270230770111, -0.5954905152320862, -0.9900642037391663, 0.07479129731655121, 0.4152715504169464, 0.21817870438098907, 0.4938012957572937, 1.2383027076721191, 0.08781389892101288, 0.6163715124130249, -0.07511437684297562, 0.5931736826896667, -0.3889685869216919, -0.2640639841556549, 0.27640488743782043, -1.0227488279342651, -0.05974139645695686, -0.3703133463859558, -0.8565798401832581, -0.30136948823928833, 0.13116495311260223, 0.2751295268535614, -0.36022093892097473, 0.2111043483018875, 0.6690089702606201, 0.5896915793418884, 0.8347018957138062, -0.37485769391059875, -0.6667253971099854, -0.1903110146522522, -1.0064690113067627, 0.21910952031612396, -0.5717456936836243, -0.012139477767050266, -0.0023468623403459787, 0.1338575780391693, 0.1027098298072815]}, "authors": [{"authorId": "8397429", "name": "Weixuan Sun"}, {"authorId": "2171650015", "name": "Zhen Qin"}, {"authorId": "2072971413", "name": "Huiyuan Deng"}, {"authorId": "1832343458", "name": "Jianyuan Wang"}, {"authorId": "2153910607", "name": "Yi Zhang"}, {"authorId": "3397429", "name": "Kaihao Zhang"}, {"authorId": "1712576", "name": "Nick Barnes"}, {"authorId": "2238841", "name": "Stan Birchfield"}, {"authorId": "47648549", "name": "Lingpeng Kong"}, {"authorId": "2015152", "name": "Yiran Zhong"}], "references": [{"paperId": "ad7bcec33f5206d4f28687a6a5a950de67010651", "title": "Neighborhood Attention Transformer"}, {"paperId": "a54e8b88566bd7ac4c420fd0c2bf1dcf5dc21fa9", "title": "Implicit Motion Handling for Video Camouflaged Object Detection"}, {"paperId": "c49ac1f916d6d2edeb187e6619c8d23acd95eb21", "title": "cosFormer: Rethinking Softmax in Attention"}, {"paperId": "0d9b8ccb1135b8e380dd8015b080158c6aae3ae5", "title": "QuadTree Attention for Vision Transformers"}, {"paperId": "e5cb26148791b57bfd36aa26ce2401e231d01b57", "title": "Vision Transformer with Deformable Attention"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "3a71cc0a377e9f22a2d435f0a650efabf9d025f2", "title": "Neighborhood"}, {"paperId": "ff0a9d1cb358370eca9fa704f09835d28a659f75", "title": "Inferring the Class Conditional Response Map for Weakly Supervised Semantic Segmentation"}, {"paperId": "2e644c67a697073d561da4f4dad35e5ad5316cfd", "title": "SOFT: Softmax-free Transformer with Linear Complexity"}, {"paperId": "48418b285a92376a38daafa664a2dd07d42e3fe3", "title": "Focal Self-attention for Local-Global Interactions in Vision Transformers"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "7fff8018bf625447df837c2fda5c58a705fbc038", "title": "XCiT: Cross-Covariance Image Transformers"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "640667e929b2ce4fe4cce4f060c4e710c817365e", "title": "Deep Two-View Structure-from-Motion Revisited"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "3cbe314cc5407a6c3249815b5173f22ea15173c2", "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"}, {"paperId": "8e33914d6051dd031a5e096962b9398fc1d16067", "title": "Vision Transformers for Dense Prediction"}, {"paperId": "91e8117e7ebc966bc76de2cb52ec717d2acdb1a4", "title": "Scaling Local Self-Attention for Parameter Efficient Visual Backbones"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78", "title": "Bottleneck Transformers for Visual Recognition"}, {"paperId": "cdfb41e5d1b3c7c69c7eef17d6baa38363c13691", "title": "RegNet: Self-Regulated Network for Image Classification"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "c0f709acf38eb27702b0fbce1215db0ebaa2de2b", "title": "SMYRF: Efficient Attention using Asymmetric Clustering"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "54c7445f319823c7dcc948c830e75e2fa7460b33", "title": "Exploring Self-Attention for Image Recognition"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "d78aed1dac6656affa4a04cbf225ced11a83d103", "title": "Revealing the Dark Secrets of BERT"}, {"paperId": "d6dccb5d71fbb6f5765f89633ba3a8e6809a720d", "title": "Stand-Alone Self-Attention in Vision Models"}, {"paperId": "95a251513853c6032bdecebd4b74e15795662986", "title": "What Does BERT Look at? An Analysis of BERT\u2019s Attention"}, {"paperId": "66143960c0325c70329a3869cc8052f0416b87aa", "title": "GCNet: Non-Local Networks Meet Squeeze-Excitation Networks and Beyond"}, {"paperId": "061d6d5f3df0db70b12f9e90bec327e19b7259c1", "title": "Local Relation Networks for Image Recognition"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "0ac7fe3a033baa5062ebffee94a3054f3b9d6592", "title": "Noise-Aware Unsupervised Deep Lidar-Stereo Fusion"}, {"paperId": "697dd316d0b99ba1e108a102ce57fbea1ca8eda8", "title": "Unsupervised Deep Epipolar Flow for Stationary or Dynamic Scenes"}, {"paperId": "a84906dbd4d6640f918d0b6ed2a7313dda0d55f1", "title": "Panoptic Feature Pyramid Networks"}, {"paperId": "5f4a22ee70ca613d9c0630eafc96364fe365fdf8", "title": "Efficient Attention: Attention with Linear Complexities"}, {"paperId": "27979bf3f159296f02e5c4bb876a84ca39a392c1", "title": "Stereo Computation for a Single Mixture Image"}, {"paperId": "1c5fd26994a5f3a685b8e9b2ddb19dae20712f8f", "title": "Open-World Stereo Video Matching with Deep RNN"}, {"paperId": "6509b5e896c4891fd7f7a793359dfaaefe8c335b", "title": "3D Geometry-Aware Semantic Labeling of Outdoor Street Scenes"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "4183c1c6853d3748b8232fcdb149329a8e38aa92", "title": "Self-Supervised Learning for Stereo Matching with Self-Improving Ability"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "2a94c84383ee3de5e6211d43d16e7de387f68878", "title": "Feature Pyramid Networks for Object Detection"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "5582bebed97947a41e3ddd9bd1f284b73f1648c2", "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "654247d5b184495fca18c6aa7e840e4f4559fef0", "title": "Do We Really Need Explicit Position Encodings for Vision Transformers?"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "b8134f373de0aacf72cc6c8ffc6a5703d700ce01", "title": "Representation and Shape Matching of 3-D Objects"}, {"paperId": null, "title": "Geometrie Der Zahlen , vol. 40. Rome, Germany"}, {"paperId": null, "title": "non-rigid structure from motion and depth estimation"}]}