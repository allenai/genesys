{"paperId": "275b005c33a315ad603f236cd5766efe07ef6a54", "title": "Found in the Middle: How Language Models Use Long Contexts Better via Plug-and-Play Positional Encoding", "abstract": "This paper aims to overcome the\"lost-in-the-middle\"challenge of large language models (LLMs). While recent advancements have successfully enabled LLMs to perform stable language modeling with up to 4 million tokens, the persistent difficulty faced by most LLMs in identifying relevant information situated in the middle of the context has not been adequately tackled. To address this problem, this paper introduces Multi-scale Positional Encoding (Ms-PoE) which is a simple yet effective plug-and-play approach to enhance the capacity of LLMs to handle the relevant information located in the middle of the context, without fine-tuning or introducing any additional overhead. Ms-PoE leverages the position indice rescaling to relieve the long-term decay effect introduced by RoPE, while meticulously assigning distinct scaling ratios to different attention heads to preserve essential knowledge learned during the pre-training step, forming a multi-scale context fusion from short to long distance. Extensive experiments with a wide range of LLMs demonstrate the efficacy of our approach. Notably, Ms-PoE achieves an average accuracy gain of up to 3.8 on the Zero-SCROLLS benchmark over the original LLMs. Code are available at https://github.com/VITA-Group/Ms-PoE.", "venue": "arXiv.org", "year": 2024, "citationCount": 8, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Ms-PoE leverages the position indice rescaling to relieve the long-term decay effect introduced by RoPE, while meticulously assigning distinct scaling ratios to different attention heads to preserve essential knowledge learned during the pre-training step, forming a multi-scale context fusion from short to long distance."}, "embedding": {"model": "specter_v2", "vector": [0.1609119474887848, 0.4469263553619385, -0.6978408694267273, -0.3019821345806122, -0.5786231160163879, -0.16734926402568817, 0.45926982164382935, -0.12061706930398941, -0.6373112201690674, -0.35492363572120667, 0.5917414426803589, -0.011105873622000217, 0.340327650308609, 0.2678360044956207, -0.43498870730400085, 0.17614561319351196, -0.9954044818878174, 0.38287490606307983, 0.032292794436216354, -0.38267025351524353, -0.377450555562973, -0.6511052846908569, -1.053084373474121, 0.15731091797351837, 0.3894312381744385, 0.43358683586120605, 0.5205890536308289, 0.8876235485076904, -0.5754039287567139, 0.48503708839416504, 0.6590360999107361, -0.2237922102212906, 0.325432151556015, 0.04783416911959648, -0.056682415306568146, -0.5192069411277771, 0.306745707988739, -0.44048216938972473, -0.5384071469306946, 0.8051409721374512, -0.04488345608115196, 0.3227258026599884, -0.030749056488275528, -0.76852947473526, -0.44026461243629456, 1.2084295749664307, 0.507106363773346, 0.589798092842102, -0.23065301775932312, -0.7000430822372437, 1.5405354499816895, -1.5368499755859375, 0.08459950983524323, 1.6453042030334473, 0.761245846748352, 0.3964275121688843, -0.10412824153900146, -0.39029261469841003, 1.0905097723007202, 0.05671032518148422, -0.7380324602127075, -0.6134288907051086, -0.016077641397714615, 0.13036490976810455, 1.6536388397216797, -0.18976880609989166, 0.14028598368167877, 0.76886385679245, -0.1289868801832199, 1.5000066757202148, -0.2053261399269104, -0.8920052647590637, -0.1622915267944336, 0.09843189269304276, 0.4490838050842285, 0.5456544160842896, -0.5271969437599182, 0.304119348526001, -0.9632545709609985, -0.18813201785087585, 0.26715606451034546, -0.02999989502131939, 0.3360831141471863, -0.14748524129390717, -0.25813376903533936, 0.3169398307800293, 0.293521910905838, 0.7750330567359924, -0.3165903687477112, 0.9423044919967651, 0.43244796991348267, 0.17464548349380493, 0.31450673937797546, 0.18011823296546936, -0.32888221740722656, -0.2333473265171051, -1.0657920837402344, 0.3232925534248352, -0.22517524659633636, 0.7272396087646484, -0.4612114727497101, -0.1217665821313858, -0.46493497490882874, 0.32244351506233215, 1.5538846254348755, 0.05756275728344917, 0.3090254068374634, -0.8631163835525513, 0.29913127422332764, -1.00200355052948, 0.22389425337314606, -0.5201929807662964, 0.05521329864859581, -0.2988233268260956, -0.34401917457580566, -1.4173438549041748, -0.35927045345306396, 0.24578766524791718, -0.3718029856681824, 1.2037774324417114, -0.27213403582572937, 0.5550993084907532, 0.024949505925178528, 0.14937295019626617, 0.46524477005004883, 0.9066444635391235, 0.30026957392692566, 0.1995953917503357, 0.6812212467193604, -1.2313519716262817, -0.7090744376182556, -1.6942319869995117, 0.6920210123062134, -0.2153395116329193, 0.7216261625289917, -0.3117661476135254, -1.3203051090240479, -1.0688179731369019, -1.1596161127090454, 0.037007641047239304, -0.7657955884933472, 0.28690671920776367, 0.8710658550262451, 0.18560615181922913, -1.1009360551834106, 0.9183303713798523, -0.408446729183197, -0.11074258387088776, 0.23978134989738464, -0.006148366257548332, 0.12174798548221588, -0.5676094889640808, -1.6528481245040894, 0.36424893140792847, 0.2976510226726532, -0.2006082534790039, 0.049595195800065994, -0.6580832600593567, -1.115981101989746, -0.18765826523303986, 0.41387349367141724, -0.3343653082847595, 1.1973739862442017, 0.13114488124847412, -1.280443787574768, 0.2686139941215515, -0.48749756813049316, 0.2598016560077667, 0.521422266960144, -0.3834024667739868, -0.5078994631767273, -0.5481030344963074, -0.2480761706829071, 0.5494821071624756, 0.13773544132709503, -0.18748925626277924, -0.25532689690589905, 0.137192964553833, -0.32625502347946167, -0.019934626296162605, 0.06937096267938614, 1.0254155397415161, -0.6340047717094421, -0.03845154494047165, 0.6031500101089478, 0.6108492612838745, -0.12689925730228424, -0.23932790756225586, -0.11516845226287842, -1.063862681388855, 0.5534437894821167, -0.18863730132579803, 1.0151927471160889, -0.8225551247596741, -0.7111572027206421, -0.24669377505779266, -0.10822033137083054, -0.15024688839912415, -0.8679850697517395, 0.5537536144256592, -0.0023849986027926207, 0.3468872010707855, 0.1503126472234726, -1.5031530857086182, 0.37881845235824585, -0.01999998837709427, -0.6362431645393372, -0.2823764979839325, -0.08095531165599823, 1.1510452032089233, -1.30487859249115, -0.021566731855273247, -0.043723128736019135, 0.5079977512359619, -0.8886964321136475, 1.0598810911178589, -0.23164275288581848, 0.1295073926448822, 0.16118007898330688, -0.23579701781272888, -0.0029641801957041025, -0.06651260703802109, 0.40636178851127625, -0.3101964592933655, -0.015128260478377342, 0.6137139201164246, -0.5724294781684875, 1.2366275787353516, -0.45656299591064453, 0.6228172183036804, 0.11548230051994324, -0.16149288415908813, -0.005413931328803301, 0.22141368687152863, -0.1170806959271431, -0.2709002196788788, 0.38436123728752136, 0.5808976888656616, -0.5857672095298767, 0.371650367975235, 1.0684614181518555, 0.7837113738059998, -0.5301883816719055, -0.1604059636592865, 0.42490652203559875, -0.08173264563083649, 0.5051233172416687, 0.4196251630783081, 0.39888641238212585, 0.747184693813324, 0.37056195735931396, -0.017131850123405457, 0.17573222517967224, -1.171074628829956, 0.10458220541477203, 0.6250342726707458, 0.13013695180416107, 0.7982545495033264, 0.550990641117096, -0.4788702428340912, -0.3383413851261139, 0.25155219435691833, 0.6408307552337646, 2.0063469409942627, 0.0567140206694603, -0.3933054208755493, -0.6906892657279968, -0.038246411830186844, -0.23630766570568085, 0.011688683182001114, -0.6582710146903992, -0.08740242570638657, -0.5850418210029602, -0.8167680501937866, 0.8446347117424011, 0.6237170696258545, 0.5057977437973022, -0.5385539531707764, -0.09009043127298355, 0.022166253998875618, 0.25894153118133545, -0.8183146715164185, -0.4898304045200348, 0.5669088363647461, -0.35485121607780457, 0.022601822391152382, 0.1707034409046173, -0.0831710547208786, -0.14455798268318176, -0.823909342288971, 0.7052546143531799, -0.7796636819839478, 0.2069263905286789, 0.005947434809058905, 0.3341748118400574, -0.5283298492431641, -1.1945991516113281, 0.19728171825408936, 0.2401757538318634, -0.3581835627555847, 0.2155957818031311, 0.5143822431564331, 0.17758002877235413, -0.06705647706985474, 0.0027436139062047005, 0.5013762712478638, 0.08829263597726822, -0.2219984531402588, 0.9951955676078796, -0.6754679679870605, 0.3128940761089325, -1.2320669889450073, 0.9539498686790466, 0.13000230491161346, -0.34631529450416565, 0.46514710783958435, -0.6945233345031738, -0.48833128809928894, 0.5058692693710327, -0.6038599610328674, -0.050829723477363586, -1.001359462738037, 0.14607484638690948, -0.4219946265220642, 0.010730613023042679, 0.25599274039268494, 0.024619603529572487, 0.5607778429985046, 0.005189834628254175, 0.45619097352027893, 0.12111444026231766, -0.5077923536300659, 0.8566333055496216, -0.7511973977088928, 0.7897210121154785, 0.14640644192695618, -0.35458311438560486, -0.4550056755542755, -0.22073495388031006, -0.45576176047325134, -0.2096274495124817, -0.5828710794448853, -0.5455141067504883, -0.3565078377723694, 0.024387242272496223, -0.6603405475616455, -0.523439884185791, -0.14037922024726868, -0.9322939515113831, -0.2663222849369049, 0.04595286026597023, -0.4403459429740906, -0.16711685061454773, -1.0529124736785889, -1.3976848125457764, -0.5550159215927124, -0.4659411907196045, -1.2739133834838867, 0.3689354658126831, -0.08502763509750366, -0.4160546064376831, -0.5817614793777466, 0.01640244387090206, -0.40417400002479553, 1.1302138566970825, -0.7630981206893921, 0.7004964351654053, -0.12851236760616302, 0.13864900171756744, -0.6400320529937744, 0.24885186553001404, 0.5480293035507202, -0.23777958750724792, 0.4374414384365082, -1.0555689334869385, 0.16982609033584595, -0.5770263671875, 0.037961091846227646, 0.13000905513763428, 0.3815467655658722, 0.3783416748046875, -0.010722650215029716, -0.6165202260017395, 0.22190633416175842, 1.2030856609344482, -0.48628273606300354, 0.0862615555524826, 0.05364079773426056, 1.2632700204849243, 0.1980564296245575, -0.14329546689987183, 0.4275740087032318, 0.35303443670272827, 0.26479214429855347, 0.18026630580425262, 0.06394243985414505, -0.16414713859558105, -0.9451450109481812, 0.6270978450775146, 2.2239530086517334, 0.3410763144493103, 0.03319242596626282, -1.041197419166565, 0.4227893054485321, -1.4637930393218994, -0.7270426750183105, 0.8258954882621765, 0.7245332598686218, 0.3917251229286194, -0.46645602583885193, -0.35539111495018005, -0.399397075176239, 0.46512898802757263, 0.8041794896125793, -0.4080790877342224, -0.5611913800239563, -0.09626809507608414, -0.08822227269411087, -0.10602115094661713, 0.883342444896698, -0.40196412801742554, 0.8311580419540405, 14.750669479370117, 0.9833205938339233, -0.08015765994787216, 0.8631507158279419, 0.8326025605201721, 0.1635855734348297, -0.3607254922389984, -0.06660879403352737, -1.3328700065612793, 0.17754192650318146, 1.543345332145691, 0.23310622572898865, 0.5468636751174927, 0.34394893050193787, 0.3963399827480316, 0.37532415986061096, -0.7534230351448059, 0.7312695384025574, 0.38655346632003784, -1.09514319896698, 0.025839034467935562, -0.06845654547214508, 0.4840836226940155, 0.8768620491027832, 0.7350503206253052, 1.0583467483520508, 0.424518346786499, -0.402084082365036, 1.0099830627441406, 0.2593817412853241, 0.9601366519927979, -0.012324954383075237, 0.43820804357528687, 0.36899688839912415, -1.0702506303787231, -0.2453051656484604, -0.7719574570655823, -1.101387858390808, 0.33161449432373047, -0.19029709696769714, -0.34959787130355835, -0.7633060812950134, -0.35327932238578796, 0.7402347922325134, -0.34689486026763916, 0.3438898026943207, -0.04406178370118141, 0.6107677221298218, -0.050415415316820145, 0.0402253121137619, 0.4071434736251831, 0.25942614674568176, 0.13792401552200317, 0.042812079191207886, 0.1714533418416977, -0.41770467162132263, 0.10748469084501266, 0.49500471353530884, -0.619232177734375, 0.15110868215560913, -0.15125466883182526, -0.06655444949865341, 0.3729315400123596, 0.4895358383655548, 0.494592547416687, -0.0906246230006218, -0.2617550194263458, 0.1989394575357437, 0.6925150752067566, 0.11271697282791138, -0.31691861152648926, 0.15410178899765015, 0.42327824234962463, -0.4381723403930664, -0.32993263006210327, 0.7710641622543335, -0.04828817769885063, -0.4709770381450653, -0.502025306224823, -0.19705361127853394, -0.004634812939912081, -0.8574652671813965, -0.5771548748016357, 1.0063745975494385, -0.09379684925079346, -0.1770395189523697, 0.011572124436497688, -0.48788735270500183, -0.2689414918422699, 0.22437997162342072, -1.1389394998550415, -0.9111112952232361, 0.45067816972732544, -0.7046694755554199, -0.30393868684768677, 0.28280046582221985, 1.0577430725097656, 0.4432530701160431, -0.6404809355735779, 0.20240257680416107, 0.712128758430481, -0.035701118409633636, -0.08344901353120804, -0.8328302502632141, 1.1192948818206787, 0.4221701920032501, -0.0478278212249279, 0.4102106988430023, 0.08145198225975037, 0.2847418785095215, -0.599101185798645, -0.08057931810617447, 0.8720331788063049, -0.8138644099235535, -0.43334439396858215, -1.016112208366394, -0.7501794099807739, 0.4541592299938202, 0.46187081933021545, 0.09582925587892532, 0.33505773544311523, 0.32108715176582336, -0.6174796223640442, -0.3227189779281616, -0.5304014086723328, 0.07073942571878433, 0.4163946211338043, -0.8983420729637146, -0.3362544775009155, -0.2880467176437378, 0.6686298847198486, -1.0896533727645874, -0.33589422702789307, -0.18230290710926056, 0.3541010022163391, -0.022997254505753517, 1.0463505983352661, -0.4378553628921509, 0.49910181760787964, 0.9928309917449951, -0.4878947138786316, -0.8909516334533691, 0.019849922508001328, -0.8698495030403137, 0.009110181592404842, 0.37339165806770325, 0.7292912006378174, -0.2844623327255249, 0.14487695693969727, 0.9007264971733093, 0.29007211327552795, -0.8975951671600342, -0.7226966619491577, -0.2715144157409668, 0.251111775636673, -1.175539493560791, 0.6938216090202332, -0.17126931250095367, 0.15748602151870728, -0.0015052976086735725, 0.2592626214027405, 0.5566057562828064, -0.3380110263824463, -0.989608883857727, 0.1246432363986969, 0.08739205449819565, -0.24522341787815094, -0.6287211179733276, -0.4391644299030304, -1.4856258630752563, -0.03420715034008026, -1.1468271017074585, 0.24258239567279816, -1.0221431255340576, -0.4902372360229492, -0.33781394362449646, -0.8604594469070435, -0.11595149338245392, 0.11809927970170975, -0.29865002632141113, 0.016312943771481514, -0.5777884721755981, -0.8448501229286194, 0.7683490514755249, 0.7931300401687622, -0.6268947720527649, 0.04632687196135521, 0.07306870073080063, 0.21615168452262878, 0.39344513416290283, 0.32404419779777527, -0.23892462253570557, -0.7706793546676636, -1.4012560844421387, 0.8719125986099243, 0.029244961217045784, -0.27501797676086426, -0.6370456218719482, 0.6741058230400085, 0.35100483894348145, -0.327825665473938, -0.04956798255443573, 0.6275801062583923, -0.7806340456008911, -0.35474976897239685, 0.06446027755737305, -0.9843279123306274, 0.46893051266670227, 0.23889102041721344, -0.52252197265625, -0.3548251986503601, 0.6028359532356262, -0.12858501076698303, -0.7956969141960144, -0.9743022918701172, 0.352792352437973, -0.4236321747303009, 0.10027816891670227, -0.4955233633518219, 0.012902467511594296, -0.9820665121078491, -0.42088383436203003, -0.07594046741724014, 0.09571430087089539, -0.18552491068840027, 1.220731258392334, 0.291449636220932, -1.1762980222702026, 0.04613533243536949, 0.4063465893268585, -0.03176959231495857, 0.03688659891486168, 0.5640288591384888, 0.3798842430114746, -0.32076096534729004, 0.3787088394165039, 0.4675818979740143, 0.22611328959465027, -0.9419973492622375, 0.05279413238167763, 0.7745015621185303, -0.3933343291282654, -0.01490428764373064, 1.5022152662277222, -0.39347749948501587, -1.242392659187317, 0.2947775423526764, -1.4686284065246582, -0.4454467296600342, -0.2893145978450775, 0.7020968794822693, 0.3387261629104614, -0.15041373670101166, -0.4659671485424042, -0.6492757201194763, 0.19658756256103516, 0.06764250993728638, -0.514585018157959, 0.607648491859436, -0.35501807928085327, -0.48885706067085266, 0.9243918061256409, 1.0752114057540894, -0.27961573004722595, -1.1029573678970337, -0.771648645401001, -0.6311625242233276, -0.2530103027820587, 0.3503960967063904, -0.4313782751560211, -0.2856810688972473, 0.9818071126937866, 0.505577027797699, 0.20356442034244537, -0.2780008018016815, 0.14938555657863617, 0.1903388947248459, 0.40607985854148865, 0.24185451865196228, -0.6999595165252686, -0.9303716421127319, 1.133758544921875, 1.2171727418899536, -0.7928999066352844, 0.09998127073049545, 0.06333915889263153, -0.5594515204429626, 0.5398151278495789, 0.1906251609325409, 0.16347557306289673, 0.866414487361908, -0.06653144210577011, 0.2684538960456848, 0.4872472286224365, -1.0997525453567505, 0.1544732302427292, 0.6858463287353516, 0.8860337138175964, 0.6003727316856384, 0.5880091190338135, 0.31787219643592834, 1.2793126106262207, 0.06578031927347183, -0.08588320761919022, 0.3199441134929657, 0.38734766840934753, -0.21938946843147278, -0.14803722500801086, 0.15009136497974396, 0.44554829597473145, -0.6925665140151978, -0.8662204742431641, 0.22746042907238007, 0.29210901260375977, 0.4688868820667267, 0.7216739654541016, 0.8211827874183655, 0.06275554746389389, 0.24983255565166473, 0.4541553258895874, 0.3757031559944153, -0.24874481558799744, -0.19963105022907257, -0.0067487056367099285, -0.7318702340126038, -0.007269012741744518, 0.04614011570811272, -0.45221179723739624, -0.4720224440097809, -0.3485559821128845, 0.29153895378112793, -0.05192744359374046, 0.38898664712905884, 1.0070992708206177, 0.6623227596282959, 0.7076566815376282, -0.49151670932769775, -0.6172031164169312, -0.4916761815547943, -1.021918535232544, -0.10425663739442825, -0.3024546205997467, -0.2912057042121887, 0.020071743056178093, 0.06386137008666992, -0.5754127502441406]}, "authors": [{"authorId": "2109338656", "name": "Zhenyu (Allen) Zhang"}, {"authorId": "2284222685", "name": "Runjin Chen"}, {"authorId": "2255081092", "name": "Shiwei Liu"}, {"authorId": "2262242352", "name": "Zhewei Yao"}, {"authorId": "2537545", "name": "Olatunji Ruwase"}, {"authorId": "2249538643", "name": "Beidi Chen"}, {"authorId": "2129511744", "name": "Xiaoxia Wu"}, {"authorId": "2284563898", "name": "Zhangyang Wang"}], "references": [{"paperId": "3e8d4062ec4353ff2701c7769336dbdb97f8814c", "title": "Transformers are Multi-State RNNs"}, {"paperId": "411114f989a3d1083d90afd265103132fee94ebe", "title": "Mixtral of Experts"}, {"paperId": "2b8439f319dfa73df62ca8957ff6d0c1f3c7a73c", "title": "Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon"}, {"paperId": "a9468d8bfa6bd016dfd3128c4e8408e30eb8549b", "title": "LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning"}, {"paperId": "36697944858ab17ca23b23ae2043aa6c0b2e3d5d", "title": "Zebra: Extending Context Window with Layerwise Grouped Local-Global Attention"}, {"paperId": "3597c2eff349260c59e7cb2bff31a31db5cf50fc", "title": "Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool Use"}, {"paperId": "c2b833283099f6fbcbe89229c703e4945b1f7ebf", "title": "Never Lost in the Middle: Improving Large Language Models via Attention Strengthening Question Answering"}, {"paperId": "0484f05b6b3c11a9344cb623649ae867f172046f", "title": "LooGLE: Can Long-Context Language Models Understand Long Contexts?"}, {"paperId": "a54761081c2b001c057fb6e1ea9a48058d5aa5e0", "title": "CLEX: Continuous Length Extrapolation for Large Language Models"}, {"paperId": "db633c6b1c286c0386f0078d8a2e6224e03a6227", "title": "Mistral 7B"}, {"paperId": "4c0428917aeee6aa7bd434f337d039f35996b736", "title": "LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression"}, {"paperId": "faab24bc6cd4a4dea6e82420d145f08445c05fc7", "title": "Outlier Weighed Layerwise Sparsity (OWL): A Missing Secret Sauce for Pruning LLMs to High Sparsity"}, {"paperId": "1266477120913d274346b044b4cc72ea893b1382", "title": "Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading"}, {"paperId": "6c9f65d94b3a5c985cb16045eb64e5f4f00d48db", "title": "DeepSpeed4Science Initiative: Enabling Large-Scale Scientific Discovery through Sophisticated AI System Technologies"}, {"paperId": "2b35b946a8ad64e018c24b283bc1c6c65d36fb67", "title": "Retrieval meets Long Context Large Language Models"}, {"paperId": "6c323c535365e1c7cbfd9703cbec3b5650a3346b", "title": "Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs"}, {"paperId": "97ad7960bdd20442093bc8e31391e235b943eecf", "title": "JoMA: Demystifying Multilayer Transformers via JOint Dynamics of MLP and Attention"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "ff01d3dab60dd4b7426c884b009dda83540c0c1e", "title": "Attention Sorting Combats Recency Bias In Long Context Language Models"}, {"paperId": "a51ac7a5e8f6454268ac16ecdc52ecac98ce54d9", "title": "DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models"}, {"paperId": "819bbdc2dac9e13d9ca3e2508a6e063186ce5e40", "title": "YaRN: Efficient Context Window Extension of Large Language Models"}, {"paperId": "e539218e2f6054ed002da6d6efc96d73221c22dc", "title": "ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "80980cd10d19f021c14a6b7eee871b6a5d328024", "title": "Augmenting Language Models with Long-Term Memory"}, {"paperId": "db9507cdd3e2d7d9c90ed185bd831e55c62dcec9", "title": "AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration"}, {"paperId": "7a1e71cb1310c4a873e7a4e54d1a6dab0553adce", "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"}, {"paperId": "eb511ae6b9f04e4936891d26787f274b48b99d57", "title": "ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding"}, {"paperId": "bafe023fb072045dc0cd50316382a61c8dcb9fae", "title": "CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Benchmarking on HumanEval-X"}, {"paperId": "3b2c63b63478d192543bdfb7df7d9a4e1b8d3950", "title": "SegNeXt: Rethinking Convolutional Attention Design for Semantic Segmentation"}, {"paperId": "732e3faec4e5be4d144256f2c379b9dc49f0b227", "title": "Efficient Long-Text Understanding with Short-Text Models"}, {"paperId": "86c048c4d91066610beba9099b7d23bdae29caab", "title": "AlphaFold Protein Structure Database: massively expanding the structural coverage of protein-sequence space with high-accuracy models"}, {"paperId": "1cbb3d96242c3f47c3f40aada33616d0f5c07737", "title": "Inductive Biases and Variable Creation in Self-Attention Mechanisms"}, {"paperId": "c600b697700c844cbc85009be70f1cdfeef3593e", "title": "Summ^N: A Multi-Stage Summarization Framework for Long Input Dialogues and Documents"}, {"paperId": "ac95a18762133d4065ac8af518c33084d83c5582", "title": "DialogLM: Pre-trained Model for Long Dialogue Understanding and Summarization"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "148011adfae37b821407aae84fcbbf7fb4619eb6", "title": "On the Expressive Power of Self-Attention Matrices"}, {"paperId": "a4ffce66918cfb33150a60bf8e26419199e63b01", "title": "BookSum: A Collection of Datasets for Long-form Narrative Summarization"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327", "title": "Going deeper with convolutions"}, {"paperId": "e3aa232577bb427b1f3a34acbdef84bd85734042", "title": "LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models"}, {"paperId": null, "title": "Elec-tra: Pre-training text encoders as discriminators rather than generators"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Stable beluga models"}, {"paperId": null, "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality"}, {"paperId": null, "title": "Introducing mpt-7b: A new standard for open-source, commercially usable llms"}, {"paperId": null, "title": "Can longer sequences help take the next leap in ai?, June 2022"}, {"paperId": null, "title": "the Middle: How Language Models Use Long Contexts Better via Plug-and-Play Positional Encoding"}]}