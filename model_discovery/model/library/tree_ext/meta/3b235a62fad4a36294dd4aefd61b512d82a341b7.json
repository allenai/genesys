{"paperId": "3b235a62fad4a36294dd4aefd61b512d82a341b7", "title": "MINOTAUR: Multi-task Video Grounding From Multimodal Queries", "abstract": "Video understanding tasks take many forms, from action detection to visual query localization and spatio-temporal grounding of sentences. These tasks differ in the type of inputs (only video, or video-query pair where query is an image region or sentence) and outputs (temporal segments or spatio-temporal tubes). However, at their core they require the same fundamental understanding of the video, i.e., the actors and objects in it, their actions and interactions. So far these tasks have been tackled in isolation with individual, highly specialized architectures, which do not exploit the interplay between tasks. In contrast, in this paper, we present a single, unified model for tackling query-based video understanding in long-form videos. In particular, our model can address all three tasks of the Ego4D Episodic Memory benchmark which entail queries of three different forms: given an egocentric video and a visual, textual or activity query, the goal is to determine when and where the answer can be seen within the video. Our model design is inspired by recent query-based approaches to spatio-temporal grounding, and contains modality-specific query encoders and task-specific sliding window inference that allow multi-task training with diverse input modalities and different structured outputs. We exhaustively analyze relationships among the tasks and illustrate that cross-task learning leads to improved performance on each individual task, as well as the ability to generalize to unseen tasks, such as zero-shot spatial localization of language queries.", "venue": "arXiv.org", "year": 2023, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2302.08063", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper exhaustively analyze relationships among the tasks and illustrates that cross-task learning leads to improved performance on each individual task, as well as the ability to generalize to unseen tasks, such as zero-shot spatial localization of language queries."}, "embedding": {"model": "specter_v2", "vector": [-0.08908357471227646, 0.16673250496387482, -0.6122434735298157, -0.4172290861606598, -0.6092593669891357, 0.01101749949157238, 0.4119769334793091, 0.03293558582663536, -0.48469632863998413, -0.5359572172164917, 0.8589218854904175, 0.7644845247268677, 0.10862316191196442, -0.011072891764342785, -0.22474510967731476, 0.5477952361106873, -0.967792809009552, 0.24562771618366241, 0.5758875608444214, -0.32809358835220337, -0.009700225666165352, -0.9516693949699402, -1.2505290508270264, 0.79704749584198, -0.007215042598545551, 0.7526006102561951, 0.08208801597356796, 1.0119822025299072, 0.3337863087654114, 0.8497899770736694, 0.5335748195648193, 0.32885897159576416, 0.01016274280846119, -0.06998955458402634, -0.8398174047470093, 0.054129526019096375, 0.2397657334804535, -0.904693067073822, -0.9989930391311646, 0.21934860944747925, -0.13310876488685608, 0.46664801239967346, 0.5051853060722351, -0.508467435836792, -0.13832978904247284, 0.38768771290779114, 1.0552459955215454, 0.580680787563324, 0.5778242945671082, -0.9947854280471802, 1.8083900213241577, -1.4512414932250977, 0.9808094501495361, 1.7650185823440552, 0.12178994715213776, 0.45353347063064575, -0.051264841109514236, -0.054498426616191864, 0.8798297643661499, 0.6703580021858215, -0.9882804155349731, -0.3155992329120636, -0.8392203450202942, -0.25099748373031616, 1.6498860120773315, -0.5821728706359863, 0.23633289337158203, 0.8169810771942139, 0.10529948770999908, 2.0232274532318115, -0.7210072875022888, -0.6528624296188354, -0.17165452241897583, -0.32813188433647156, 0.11300261318683624, 0.8132703304290771, -0.7646224498748779, 0.15649928152561188, -1.4028348922729492, 0.15065743029117584, 0.4952789843082428, 0.3959938883781433, -0.4144485890865326, -0.5186107158660889, -0.7299500107765198, 0.5588618516921997, 0.5455204248428345, 0.8958936929702759, -0.2130146473646164, 0.8845087289810181, 0.6181155443191528, 0.5088508129119873, -0.042985618114471436, 0.1930874139070511, 0.23321443796157837, -0.07669482380151749, -1.0004633665084839, 0.6601553559303284, 0.24425038695335388, 0.9929655194282532, -0.20306071639060974, -0.31672796607017517, -0.7663946151733398, 0.0627545416355133, 1.4644254446029663, -0.1011708527803421, 0.38344791531562805, -0.9166254997253418, 0.3288987874984741, -0.5760073661804199, 0.8264440894126892, -0.8261204957962036, -0.043454013764858246, 0.1657976657152176, 0.1827975958585739, -1.463369369506836, -0.2290925234556198, 0.5812373757362366, -0.8217161297798157, 0.47395196557044983, -0.13031607866287231, 0.24457864463329315, 0.22005915641784668, 0.6547300815582275, 0.7830053567886353, 0.607380747795105, 0.44344502687454224, 0.5880694389343262, 0.9653557538986206, -0.7620657086372375, -0.2907453775405884, -1.078729510307312, 1.1195814609527588, 0.0829581767320633, 0.0947364792227745, -0.5111737847328186, -0.9495866894721985, -1.1951079368591309, -0.9863205552101135, -0.37612882256507874, -0.866452693939209, 0.17840352654457092, 0.6724130511283875, 0.05340828374028206, -0.7662022709846497, 0.9001896381378174, -0.35422778129577637, -0.8785439729690552, 0.2656838297843933, -0.11326726526021957, -0.309245228767395, -0.8330487608909607, -1.18854558467865, 0.24651925265789032, 0.11173774302005768, -0.5103015303611755, -0.940466582775116, -0.30462804436683655, -1.6567007303237915, -0.6388793587684631, 0.5335797667503357, -0.5883630514144897, 1.2694091796875, -0.009550340473651886, -0.5020564794540405, 0.959223747253418, -0.6789832711219788, -0.23049408197402954, 0.4954353868961334, -0.7678236365318298, -0.5650594234466553, 0.22099849581718445, 0.29633983969688416, 0.7706221342086792, 0.42089444398880005, -0.027416758239269257, -0.5615017414093018, -0.4535975456237793, -0.08713723719120026, 0.1263030469417572, 0.38444793224334717, 1.0172922611236572, -0.6745851039886475, -0.2239530235528946, 0.7085514068603516, 0.9142727255821228, 0.23989246785640717, -0.16143953800201416, 0.2283884584903717, -1.0899853706359863, 1.0789177417755127, 0.11277879029512405, 0.8735992908477783, -0.9297746419906616, -0.3262314200401306, -0.5154520869255066, -0.15037739276885986, -0.8327894806861877, -0.9667907953262329, 0.8104472756385803, 0.07145668566226959, 0.26510849595069885, 0.1735130101442337, -1.3245840072631836, 0.01612377166748047, -0.12209097295999527, -0.7888298034667969, -0.057750552892684937, -0.1217719241976738, 1.1861721277236938, -1.2169466018676758, -0.2458651065826416, -0.1340874582529068, -0.12343588471412659, -0.7894506454467773, 1.2204561233520508, -0.6292737126350403, -0.09878316521644592, -0.8038004040718079, 0.27320972084999084, -0.585521399974823, 0.017186589539051056, 0.23361584544181824, -0.7045066356658936, 0.041792985051870346, 0.1376553326845169, -0.14018766582012177, 1.8296836614608765, -0.18765932321548462, 0.6394079327583313, -0.3282952606678009, -0.43982037901878357, -0.08087122440338135, 0.8749507665634155, 0.06069059669971466, -0.52585768699646, 0.3507745563983917, 0.4458799958229065, -1.1388797760009766, -0.7718532085418701, 0.9298897981643677, 1.1135984659194946, -0.5530352592468262, 0.23990565538406372, 0.5031887292861938, -0.26273706555366516, 0.4914732873439789, 0.6243227124214172, 0.5552195906639099, 0.8954770565032959, -0.06518096476793289, 0.20680969953536987, -0.07868887484073639, -0.7664411067962646, -0.2513193190097809, 0.9750140309333801, 0.45646989345550537, 1.0631098747253418, 0.29972705245018005, -0.9988776445388794, -0.5123901963233948, 0.24624866247177124, 0.7353380918502808, 1.7102335691452026, 0.5881211161613464, -0.5170658826828003, -0.7599867582321167, -0.5118825435638428, -0.22097565233707428, -0.05111320689320564, -0.9683756828308105, 0.01487714797258377, -0.25409626960754395, -0.3397265374660492, 0.5727184414863586, 0.9577153325080872, 1.2579553127288818, -0.8482801914215088, -0.7236378192901611, -0.11046744883060455, -0.3647538423538208, -0.972641110420227, -0.6754406690597534, -0.29630717635154724, -0.3881017863750458, -0.5687255859375, 0.0596386082470417, -0.12515434622764587, 0.06405296176671982, -0.3459961712360382, 0.9104887843132019, -0.2804509997367859, -0.5119932889938354, 1.0809141397476196, 0.11154427379369736, -0.46629729866981506, -0.3604351282119751, 0.022702323272824287, 0.1284504383802414, 0.10698734223842621, 0.7682452201843262, 0.5785110592842102, -0.38603296875953674, 0.7116297483444214, -0.5556402802467346, 0.0027670422568917274, -0.10207079350948334, -0.2091529369354248, 0.7904084920883179, -0.5804864168167114, 0.450980544090271, -0.7491952180862427, 0.206724151968956, -0.3200846016407013, 0.0534730888903141, 0.26293110847473145, -0.20320463180541992, -0.8204583525657654, -0.3530128598213196, -0.5479925870895386, -0.06784889101982117, -0.7388226389884949, 0.6645073890686035, -0.5082516074180603, -0.5288130044937134, 0.5421125888824463, 0.15519636869430542, 0.5782405138015747, 0.5009453892707825, 0.5284343361854553, 0.24368716776371002, -0.07503529638051987, 0.5889000296592712, -0.7560878396034241, 0.6696158051490784, 0.10776756703853607, -0.5890036821365356, 0.6581334471702576, -0.27490103244781494, -1.0136226415634155, -0.8159316182136536, -1.165319800376892, -0.5733428001403809, -0.7146610617637634, 0.8502824306488037, -0.7347649335861206, -0.8102700114250183, -0.16523946821689606, -1.2147986888885498, -0.4329555928707123, 0.5485325455665588, -0.12240105867385864, -0.9031103849411011, -0.9421647191047668, -0.8670021891593933, -0.5808541178703308, -0.09645648300647736, -0.6455885767936707, 0.5104738473892212, -0.23630039393901825, -0.7224093079566956, -0.31380102038383484, -0.12488465011119843, -0.1874612718820572, 0.5870407223701477, -0.18116913735866547, 0.2907600700855255, -0.06234845519065857, -0.7258605360984802, -0.6574203372001648, 0.0884663388133049, -0.013262370601296425, -0.21178968250751495, -0.3332439661026001, -0.625983476638794, 0.022763144224882126, -0.13420435786247253, -0.4348348081111908, 0.49237650632858276, 0.22843743860721588, 0.35678544640541077, 0.48527222871780396, -0.754438579082489, -0.10990116745233536, 1.351235032081604, -0.29951804876327515, 0.07111363857984543, 0.016081687062978745, 0.6759363412857056, 0.6736570000648499, 0.41633710265159607, 0.6372997760772705, 0.5098022222518921, 0.37084636092185974, 0.507358193397522, 0.30652865767478943, 0.11084531992673874, -0.782609760761261, 0.5510591268539429, 0.45308688282966614, -0.05799315869808197, 0.0649554654955864, -0.9450772404670715, 1.413000464439392, -1.9301514625549316, -1.0220400094985962, 0.9222169518470764, 0.6930727958679199, -0.41527336835861206, -0.7538377642631531, 0.3929133117198944, -0.7112880349159241, 0.23267413675785065, 0.4101722538471222, -0.3202008903026581, 0.22944752871990204, -0.019549278542399406, -0.2396683692932129, -0.26976534724235535, 0.4929080307483673, -0.8981111645698547, 0.4877341389656067, 14.160321235656738, 0.5285239815711975, 0.3507808744907379, 0.5691956877708435, 0.45756781101226807, 0.06821439415216446, -0.07377409189939499, -0.21500526368618011, -1.0389713048934937, -0.6331084966659546, 1.074035882949829, 0.10007230937480927, 0.13054601848125458, 0.234226793050766, 0.5401124954223633, -0.030817795544862747, -1.3967559337615967, 0.8591393828392029, 0.802196204662323, -1.1878591775894165, 0.33656057715415955, -0.15845158696174622, -0.06551746279001236, 0.6413843631744385, 0.5959614515304565, 0.9141536951065063, -0.06779946386814117, -0.7339728474617004, 0.9574436545372009, 0.4342009127140045, 0.6821809411048889, 0.10933210700750351, 0.3880082070827484, 0.22680404782295227, -1.1790823936462402, -0.6625722050666809, -0.6757519841194153, -0.6362256407737732, 0.47558706998825073, -0.884416937828064, -0.3112158477306366, -0.2309703677892685, 0.06274554133415222, 1.090906023979187, 0.2939535975456238, 0.4189473092556, 0.08519356697797775, -0.007546470034867525, 0.08739388734102249, 0.09356523305177689, 0.4680180847644806, 0.6703230738639832, 0.3965752422809601, -0.14464689791202545, 0.1749902069568634, 0.32793697714805603, 0.10279321670532227, 0.4243992567062378, -0.4698435366153717, 0.15908785164356232, -0.9372020959854126, 0.003811013186350465, -0.1825658529996872, 0.05780128762125969, 0.3621613681316376, -0.036596208810806274, -0.34904107451438904, 0.5848246812820435, 0.24784469604492188, 0.47169095277786255, -0.27578434348106384, -0.15375933051109314, 0.020416749641299248, 0.07624664902687073, 0.37456992268562317, 0.4576990306377411, 0.5617898106575012, -0.567376971244812, -0.6351388692855835, 0.028590228408575058, 0.8603808283805847, -0.9068670272827148, -0.38760867714881897, 1.0478041172027588, 0.12185689806938171, -0.7104228138923645, -0.2584027051925659, -0.5333256721496582, -0.2807011008262634, -0.15345874428749084, -0.9983697533607483, -0.9504055380821228, -0.2977345287799835, 0.1888604611158371, 0.4180695712566376, 0.33532387018203735, 1.1654014587402344, 0.2356603741645813, -0.07484258711338043, -0.3058382272720337, -0.12895825505256653, -0.08306941390037537, 0.22784024477005005, -0.6347398161888123, 0.19293923676013947, -0.18499623239040375, 0.033515483140945435, 0.09056928008794785, 0.06566718965768814, -0.14106737077236176, -0.5550271272659302, -0.23379403352737427, 0.5829787254333496, -1.2971042394638062, -0.5342552661895752, -0.5957908630371094, -0.9146295785903931, 0.5809077620506287, 0.4608554244041443, -0.19596490263938904, 0.25811031460762024, 0.04909941181540489, -0.7161068916320801, -0.07905465364456177, -0.8091484904289246, 0.02780359983444214, 0.3933861553668976, -1.0580546855926514, -0.7364324331283569, 0.061243727803230286, 0.4820924401283264, -0.7774543762207031, -0.5263662338256836, -0.4242030084133148, 0.4359092712402344, -0.2057075947523117, 0.8305844068527222, -0.9082157611846924, 0.8360707759857178, 0.6431019306182861, -0.5317301154136658, -0.3728589713573456, 0.5337507128715515, -0.7045073509216309, -0.2513574957847595, -0.19191470742225647, 0.653840184211731, 0.10883459448814392, 0.3888310194015503, 0.7919837236404419, 0.49010348320007324, -0.5809568762779236, -0.4304075241088867, -0.33911454677581787, -0.20627638697624207, -0.699569821357727, 0.1168326810002327, -0.3332389295101166, 0.10578256845474243, -0.07758204638957977, 0.4337225556373596, 0.9329313039779663, -0.292305588722229, -0.5217489004135132, 0.5628339052200317, 0.18675923347473145, 0.02850433997809887, -0.024066057056188583, -0.6994266510009766, -1.8982131481170654, -0.3325389623641968, -0.60129714012146, 0.08684895932674408, -1.272760272026062, -0.6642859578132629, 0.6627135872840881, -0.19288726150989532, -0.21132895350456238, 0.7800713777542114, -0.29177212715148926, -0.03449797257781029, -0.4678725004196167, -1.4462883472442627, 0.7116232514381409, 0.960328221321106, -0.8263769149780273, 0.1199299544095993, 0.030663011595606804, 0.46200045943260193, 0.3922000825405121, 0.1662326455116272, -0.1828872412443161, -0.8288440108299255, -1.2406127452850342, 0.33145245909690857, 0.0847536250948906, 0.2794269919395447, -0.9325746297836304, 0.7126237154006958, 0.6204124093055725, -0.15271078050136566, -0.597385585308075, 0.8659927248954773, -0.7567439675331116, -0.7252374887466431, -0.02916618622839451, -0.825597882270813, 0.007250973489135504, -0.11283004283905029, 0.08284497261047363, -0.9121114611625671, 0.8706775903701782, -0.15714633464813232, -1.0944117307662964, -1.2329742908477783, 0.5075002312660217, -0.5897155404090881, -0.019740378484129906, 0.039814334362745285, -0.3074148893356323, -0.7101318836212158, -1.0256074666976929, -0.9276360869407654, 0.7616678476333618, -0.49679452180862427, 1.2539780139923096, 1.0497519969940186, -1.1945490837097168, -0.1437355875968933, -0.23954667150974274, 0.48742398619651794, 0.3851427733898163, 1.2635393142700195, 0.5375135540962219, -0.028484877198934555, 0.6000625491142273, 0.434998095035553, 0.18512991070747375, -0.8888964653015137, 0.19692164659500122, 1.1085385084152222, 0.12371775507926941, -0.039536818861961365, 0.9294948577880859, 0.14732639491558075, -0.4693131744861603, 0.29377174377441406, -0.9890450239181519, -0.6480416655540466, 0.1273074746131897, 0.8968017101287842, 0.1898464560508728, -0.26522961258888245, -0.3903176486492157, -0.32807931303977966, 0.5666519999504089, -0.31960558891296387, -0.6602015495300293, 0.629346489906311, -0.37902507185935974, -0.1945183128118515, 0.7446351051330566, 1.0922003984451294, -0.9345132112503052, -0.5196549296379089, -0.6758184432983398, -0.2663660943508148, -0.12960101664066315, 0.07427405565977097, -0.042188603430986404, -0.13744759559631348, 0.6444802284240723, 0.5503712296485901, 0.5261548757553101, -0.21933533251285553, 0.6274646520614624, 0.25438496470451355, 0.9577385783195496, -0.1585622876882553, -0.7810729742050171, 0.10051759332418442, 0.9235098361968994, 1.7045366764068604, -0.8930768370628357, 0.0029070107266306877, -0.046837180852890015, -0.4677445888519287, 0.9355600476264954, 0.45386573672294617, -0.19531205296516418, 0.8775843977928162, -1.0964553356170654, 0.12830673158168793, -0.19594019651412964, -1.0438804626464844, -0.16614586114883423, 0.7533392906188965, 1.0917102098464966, 0.3005973696708679, 0.18807323276996613, 0.34249988198280334, 0.6705227494239807, 0.640049934387207, 0.3497432768344879, 0.35064178705215454, 0.37340638041496277, -0.5227267742156982, 0.2428402155637741, 0.3252331614494324, 0.3627306818962097, -0.5517029166221619, 0.0930829867720604, 0.3172655701637268, 0.5720853209495544, -0.06059322506189346, 0.6331738829612732, 1.0530297756195068, 0.18770244717597961, 0.7038643956184387, 0.1734418421983719, 0.49750256538391113, -0.8197224736213684, 0.21224930882453918, -0.3048492670059204, -0.2973406910896301, -0.49003636837005615, -0.6683600544929504, -0.88178950548172, -0.44186145067214966, 0.3482263684272766, 0.7885708808898926, -0.0644051805138588, -0.15168529748916626, 1.2844500541687012, 0.8908565044403076, 0.026032578200101852, -0.7302218079566956, -0.3758634924888611, -0.08797313272953033, -0.9076148867607117, 0.0748562291264534, -0.25074881315231323, -0.019028354436159134, -0.3917650580406189, -0.16092295944690704, -0.13223443925380707]}, "authors": [{"authorId": "38962424", "name": "Raghav Goyal"}, {"authorId": "2065610871", "name": "E. Mavroudi"}, {"authorId": "3042242", "name": "Xitong Yang"}, {"authorId": "2265067", "name": "Sainbayar Sukhbaatar"}, {"authorId": "144398147", "name": "L. Sigal"}, {"authorId": "3429328", "name": "Matt Feiszli"}, {"authorId": "1732879", "name": "L. Torresani"}, {"authorId": "1687325", "name": "Du Tran"}], "references": [{"paperId": "19bf7f2346786c2e17840be5be04844b4531268a", "title": "Where is my Wallet? Modeling Object Proposal Sets for Egocentric Visual Query Localization"}, {"paperId": "637d25af0e96915c30fa20f21e3b9ad16e61a764", "title": "InternVideo-Ego4D: A Pack of Champion Solutions to Ego4D Challenges"}, {"paperId": "07ab0c7ec1385fe92987fe1458a5a9a5b5bd1698", "title": "Where a Strong Backbone Meets Strong Features - ActionFormer for Ego4D Moment Queries Challenge"}, {"paperId": "8c0469d102e02e942a74fd319f0ac20fa9702111", "title": "EPIC-KITCHENS VISOR Benchmark: VIdeo Segmentations and Object Relations"}, {"paperId": "ef2d9bfe192ed144defbff9a65e3912d923612b5", "title": "CONE: An Efficient COarse-to-fiNE Alignment Framework for Long Video Temporal Grounding"}, {"paperId": "a6a57c444e73d8154f8f91e1c67b532c6c5c2825", "title": "Negative Frames Matter in Egocentric Visual Query 2D Localization"}, {"paperId": "4d8986746e9ae313e7086f770486c19f99d2e6f4", "title": "ReLER@ZJU-Alibaba Submission to the Ego4D Natural Language Queries Challenge 2022"}, {"paperId": "8b5eab31e1c5689312fff3181a75bfbf5c13e51c", "title": "Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks"}, {"paperId": "87fadaab89b05f1b2abadfbdf8176af5f90b73f1", "title": "Egocentric Video-Language Pretraining"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "9d4eb3a74c3b3cd196834e7cb04b6a0871cdf13d", "title": "TubeDETR: Spatio-Temporal Video Grounding with Transformers"}, {"paperId": "92dd395cc99890013946c6293b0417376e936f3e", "title": "UMT: Unified Multi-modal Transformers for Joint Video Moment Retrieval and Highlight Detection"}, {"paperId": "4990f7542f0600e0501a7e7a931b32eb7cb804d5", "title": "VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training"}, {"paperId": "58a3fedc03ab9f5908c077c115eff4c8d2d87660", "title": "ActionFormer: Localizing Moments of Actions with Transformers"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "80ea0e2882db3347b4fbc83f1a55c6a93e0d9272", "title": "Align and Prompt: Video-and-Language Pre-training with Entity Prompts"}, {"paperId": "91dc75f94da13452a54ad5c03fab2c5fda87e9ba", "title": "Uni-Perceiver: Pre-training Unified Architecture for Generic Perception for Zero-shot and Few-shot Tasks"}, {"paperId": "6f681faaa985ed38bc9b30777d57d9e1e3765861", "title": "History Aware Multimodal Transformer for Vision-and-Language Navigation"}, {"paperId": "848eb8367785910c2fe31372605954ad8f9dfe6c", "title": "Ego4D: Around the World in 3,000 Hours of Egocentric Video"}, {"paperId": "5d3ce91825d8bf6288610ef4d4eee463db2408cf", "title": "Joint Visual and Audio Learning for Video Highlight Detection"}, {"paperId": "068ff8c9c5cea92c4a14ac1036cc9033e4bf695d", "title": "Watch Only Once: An End-to-End Video Action Detection Framework"}, {"paperId": "7f315575220d7efd67e2707cc8aaf176c82257ec", "title": "Temporal Cue Guided Video Highlight Detection with Low-Rank Audio-Visual Fusion"}, {"paperId": "23e0731c87eaf87115177ecdd337edf80c4e222f", "title": "Class Semantics-based Attention for Action Detection"}, {"paperId": "9933a5af7895354087baf6c96b64dc8a8973eaed", "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs"}, {"paperId": "f9faec7204aeaa9601dea6168bbe18d1f3d3bd1a", "title": "QVHighlights: Detecting Moments and Highlights in Videos via Natural Language Queries"}, {"paperId": "2f5f8e60a1c8cea0a0ba669305f0020854549ddd", "title": "End-to-End Temporal Action Detection With Transformer"}, {"paperId": "7ba9c013988eaff5cd186d73704af329d027872d", "title": "MDETR - Modulated Detection for End-to-End Multi-Modal Understanding"}, {"paperId": "e36c35f3b3d898898a1b63817ce70397555cef76", "title": "TubeR: Tubelet Transformer for Video Action Detection"}, {"paperId": "582b732602654e5b4a574c4e57d1bf524670cdf7", "title": "Towards General Purpose Vision Systems: An End-to-End Task-Agnostic Vision-Language Architecture"}, {"paperId": "bac87bdb1cabc35fafb8176a234d332ebcc02864", "title": "Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval"}, {"paperId": "d9a447690ba5845cc466f42e96962ee3aee732eb", "title": "Learning Salient Boundary Feature for Anchor-free Temporal Action Localization"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "0839722fb5369c0abaff8515bfc08299efc790a1", "title": "ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision"}, {"paperId": "bfb1961040e04f0afe7a06a14f73dda28ba75f71", "title": "Relaxed Transformer Decoders for Direct Action Proposal Generation"}, {"paperId": "9548d5646e3d2900bea9ced28554ec9bc4505b86", "title": "Video Self-Stitching Graph Network for Temporal Action Localization"}, {"paperId": "af00b934e0a036b2e5897711d2dd443e34c5b038", "title": "VLG-Net: Video-Language Graph Matching Network for Video Grounding"}, {"paperId": "086057656b94de8bfd0d50ebe935e3d433f593d3", "title": "Revisiting Anchor Mechanisms for Temporal Action Localization"}, {"paperId": "ab87795177c3d53913cc91771162420ef75671e3", "title": "Boundary Content Graph Neural Network for Temporal Action Proposal Generation"}, {"paperId": "12a1598a2861c647f0551454f8cbb2b1d55917b8", "title": "Actor-Context-Actor Relation Network for Spatio-Temporal Action Localization"}, {"paperId": "3e86f5a0e2a97894de1cf1f1587799ac79bad0f2", "title": "VirTex: Learning Visual Representations from Textual Annotations"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "c659e0e8e50b2a4b2aeec5c2087ff2f1c1032b8d", "title": "Asynchronous Interaction Aggregation for Action Detection"}, {"paperId": "b5ef0f91663f0cbd6910dec9a890c138f7ec10e0", "title": "Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks"}, {"paperId": "5a975dcd3dba2a11830e5595d4c4659441cb6836", "title": "Span-based Localizing Network for Natural Language Video Localization"}, {"paperId": "d1e61fa7824709cae37fb59483dd0772e3101c08", "title": "Know Your Surroundings: Exploiting Scene Information for Object Tracking"}, {"paperId": "3b44345d670d816fb5a3e53262e2d35413a163ec", "title": "Where Does It Exist: Spatio-Temporal Video Grounding for Multi-Form Sentences"}, {"paperId": "a89b352a5c5de11749ba1da506b62aa22b134cdf", "title": "Actions as Moving Points"}, {"paperId": "959ca81466ce27a8670e21a352440a44e9eb79b2", "title": "Learning 2D Temporal Adjacent Networks for Moment Localization with Natural Language"}, {"paperId": "9915315f5cae822e98c94382ce3b0a6f9a7f8e5e", "title": "12-in-1: Multi-Task Vision and Language Representation Learning"}, {"paperId": "2b3c599cb85369e153acbd39beeac1cc60cb25dd", "title": "G-TAD: Sub-Graph Localization for Temporal Action Detection"}, {"paperId": "8feaebbe8c3e4617d65efdf00eda01bfddd10546", "title": "Weakly-Supervised Video Moment Retrieval via Semantic Completion Network"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "dfc7b58b67c31932b48586b3e23a43cc94695290", "title": "UNITER: UNiversal Image-TExt Representation Learning"}, {"paperId": "687ae817f0e35ee82a0b0b74cdfb4165c379296f", "title": "Temporally Grounding Language Queries in Videos by Contextual Boundary-aware Prediction"}, {"paperId": "fd8e725159159ca2169d302f6cb510e3b1cc1a4b", "title": "Graph Convolutional Networks for Temporal Action Localization"}, {"paperId": "4aa6298b606941a282d735fa3143da293199d2ca", "title": "VL-BERT: Pre-training of Generic Visual-Linguistic Representations"}, {"paperId": "03df26255781ebb71d9430e1b2aaabf8e1af9990", "title": "Proposal-free Temporal Moment Localization of a Natural-Language Query in Video using Guided Attention"}, {"paperId": "79c93274429d6355959f1e4374c2147bb81ea649", "title": "LXMERT: Learning Cross-Modality Encoder Representations from Transformers"}, {"paperId": "2bc1c8bd00bbf7401afcb5460277840fd8bab029", "title": "Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training"}, {"paperId": "65a9c7b0800c86a196bc14e7621ff895cc6ab287", "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "8548d5a93869a5a4c808f5e81742f59f848c718c", "title": "Semantic Proposal for Activity Localization in Videos via Sentence Query"}, {"paperId": "d85117bc69847b64f90424f4858ffc55c4fa3963", "title": "Localizing Natural Language in Videos"}, {"paperId": "3fc815cebbd8948dfed0592a254d5d4bf82d3fcf", "title": "OmniNet: A unified architecture for multi-modal multi-task learning"}, {"paperId": "0fa68cde4db12779adacb70a24961cf09b1adf73", "title": "Language-Driven Temporal Activity Localization: A Semantic Matching Reinforcement Learning Model"}, {"paperId": "c2cc82c2948c0513628a61d4ff829110750fdf9a", "title": "STEP: Spatio-Temporal Progressive Learning for Video Action Detection"}, {"paperId": "ca4d965ab8fd07fd236a2ec5b5c7a520077a3085", "title": "Weakly Supervised Video Moment Retrieval From Text Queries"}, {"paperId": "ddf69a6ef015a1b0668ca48a486c4cc7e22a7d9c", "title": "ExCL: Extractive Clip Localization Using Natural Language Descriptions"}, {"paperId": "213a37f44d28799ebff6b20aa53867d4d7a08cc4", "title": "Dance With Flow: Two-In-One Stream Action Detection"}, {"paperId": "842b24b04ef2b142d655c7b50cd6ab0835d89330", "title": "Video Object Segmentation Using Space-Time Memory Networks"}, {"paperId": "575fffa523c150e4e1f899a0d4db322a099afea9", "title": "Many Task Learning With Task Routing"}, {"paperId": "658721bc13b0fa97366d38c05a96bf0a9f4bb0ac", "title": "Multi-Task Deep Neural Networks for Natural Language Understanding"}, {"paperId": "6fd7e8aa1a031923e3580752e4ab9163e45fe41c", "title": "Read, Watch, and Move: Reinforcement Learning for Temporally Grounding Natural Language Descriptions in Videos"}, {"paperId": "8b47b9c3c35b2b2a78bff7822605b3040f87d699", "title": "SlowFast Networks for Video Recognition"}, {"paperId": "ac359aac85ba5d05c8249bd7dfb5d71aa205db79", "title": "Multi-Task Learning of Hierarchical Vision-Language Representation"}, {"paperId": "57eedf785fd9e3ea28b4cd30539cb0fa374f9e74", "title": "Characterizing and Avoiding Negative Transfer"}, {"paperId": "b6d977251b551471f5dddfb0a2e8f9c542e684d2", "title": "Recurrent Tubelet Proposal and Recognition Networks for Action Detection"}, {"paperId": "b4df354db88a70183a64dbc9e56cf14e7669a6c0", "title": "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"}, {"paperId": "9784fbf77295860b2e412137b86356d70b25e3c0", "title": "The Natural Language Decathlon: Multitask Learning as Question Answering"}, {"paperId": "49e2b4db35a408e91353578764be9085ac1210da", "title": "BSN: Boundary Sensitive Network for Temporal Action Proposal Generation"}, {"paperId": "31bb920739f22b4865161f75692785decfea470c", "title": "To Find Where You Talk: Temporal Sentence Localization in Video with Attention Based Location Regression"}, {"paperId": "83b2a55aecd5f917dbedbc0c5ef3ff3b61013958", "title": "Multilevel Language and Vision Integration for Text-to-Clip Retrieval"}, {"paperId": "fc50c9392fd23b6c88915177c6ae904a498aacea", "title": "Scaling Egocentric Vision: The EPIC-KITCHENS Dataset"}, {"paperId": "b4fdbe0c627eb374fa9f347157ae94c5a2fcad67", "title": "Single Shot Temporal Action Detection"}, {"paperId": "ee909ad489244016cf301bb7d7d8eeea423dbf35", "title": "Localizing Moments in Video with Natural Language"}, {"paperId": "cf90552b5d2e992e93ab838fd615e1c36618e31c", "title": "Distral: Robust multitask reinforcement learning"}, {"paperId": "54c7c3909c7e1e827befdbe8d2595a3b196ba1b8", "title": "AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions"}, {"paperId": "86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6", "title": "The Kinetics Human Action Video Dataset"}, {"paperId": "e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff", "title": "TALL: Temporal Activity Localization via Language Query"}, {"paperId": "9c643f3d4d7d52ab9b64911bb085438ca096275a", "title": "Temporal Action Detection with Structured Segment Networks"}, {"paperId": "49e8fec24cce8b73706bc5fcd2c3f681addb9982", "title": "The 2017 DAVIS Challenge on Video Object Segmentation"}, {"paperId": "065f55d40d473b63becccc890fe8a57c2f840548", "title": "Tube Convolutional Neural Network (T-CNN) for Action Detection in Videos"}, {"paperId": "7f8324dda6261ec293e9705c13a0e96b9ab63474", "title": "R-C3D: Region Convolutional 3D Network for Temporal Activity Detection"}, {"paperId": "df990d13fbe2e0a982061fc449e9c7e0aa9f357f", "title": "Online Real-Time Multiple Spatiotemporal Action Localisation and Prediction"}, {"paperId": "ddbd24a73ba3d74028596f393bb07a6b87a469c0", "title": "Multi-region Two-Stream R-CNN for Action Detection"}, {"paperId": "6b0983e11312938381bb9d11ef42612aaf78f5f4", "title": "Deep Learning for Detecting Multiple Space-Time Action Tubes in Videos"}, {"paperId": "2976605dc3b73377696537291d45f09f1ab1fbf5", "title": "Cross-Stitch Networks for Multi-task Learning"}, {"paperId": "21334d1aac5422da88780f8e24e181bfa15ef0e1", "title": "Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding"}, {"paperId": "afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d", "title": "Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "1def5d3711ebd1d86787b1ed57c91832c5ddc90b", "title": "Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning"}, {"paperId": "0a28efacb92d16e6e0dd4d87b5aca91b28be8853", "title": "ActivityNet: A large-scale video benchmark for human activity understanding"}, {"paperId": "2f488a8139630e3b2499ea2d3ff192e33387f7de", "title": "Learning to Track for Spatio-Temporal Action Localization"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "11c9c31dff70de92ada9160c78ff8bb46b2912d6", "title": "Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models"}, {"paperId": "696ca58d93f6404fea0fc75c62d1d7b378f47628", "title": "Microsoft COCO Captions: Data Collection and Evaluation Server"}, {"paperId": "377ad65969b98823dc5f28815d8a01b74fc1b79a", "title": "Action Localization with Tubelets from Motion"}, {"paperId": "21b3007f967d39e1346bc91e0fc8b3f16121300c", "title": "Grounding Action Descriptions in Videos"}, {"paperId": "5da64a24a3a0a07b1b21db2fb2a64ded1340fc57", "title": "Max-Margin Structured Output Regression for Spatio-Temporal Action Localization"}, {"paperId": "57458bc1cffe5caa45a885af986d70f723f406b4", "title": "A unified architecture for natural language processing: deep neural networks with multitask learning"}, {"paperId": "647bef8880324a06b3219cf78cca099790698011", "title": "Stochastic Gravity"}, {"paperId": "b9124861e4e874bbc477b4b726adf94f7d2ecdc4", "title": "Learning"}, {"paperId": "e13bde06aa3a53f307216838232b2da560746251", "title": "Dropped Scheduled Task: Mitigating Negative Transfer in Multi-task Learning using Dynamic Task Dropping"}, {"paperId": null, "title": "groups for multi-task cnns: Learning specialist and gener-alist convolution kernels"}, {"paperId": "452aca244ef62a533d8b46a54c6212fe9fa3ce9a", "title": "Temporally Grounding Natural Sentence in Video"}, {"paperId": "c39f634edc2318a4b288bd29cf3880505e4ae711", "title": "Robust Visual Tracking via Structured Multi-Task Sparse Learning"}]}