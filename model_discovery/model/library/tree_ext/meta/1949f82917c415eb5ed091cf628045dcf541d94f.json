{"paperId": "1949f82917c415eb5ed091cf628045dcf541d94f", "title": "PELMS: Pre-training for Effective Low-Shot Multi-Document Summarization", "abstract": "We investigate pre-training techniques for abstractive multi-document summarization (MDS), which is much less studied than summarizing single documents. Though recent work has demonstrated the effectiveness of highlighting information salience for pre-training strategy design, they struggle to generate abstractive and reflective summaries, which are critical properties for MDS. To this end, we present **PELMS**, a pre-trained model that uses pre-training objectives based on semantic coherence heuristics and faithfulness constraints together with unlabeled multi-document inputs, to promote the generation of concise, fluent, and faithful summaries. To support the training of PELMS, we compile **MultiPT**, a multi-document pre-training corpus containing over 93 million documents to form more than 3million unlabeled topic-centric document clusters, covering diverse genres such as product reviews, news, and general knowledge. We perform extensive evaluation of PELMS in low-shot settings on a wide range of MDS datasets. Our approach consistently outperforms competitive comparisons with respect to overall informativeness, abstractiveness, coherence, and faithfulness, and with minimal fine-tuning can match performance of language models at a much larger scale (e.g., GPT-4).", "venue": "North American Chapter of the Association for Computational Linguistics", "year": 2023, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work presents PELMS, a pre-trained model that uses pre-training objectives based on semantic coherence heuristics and faithfulness constraints together with unlabeled multi-document inputs, to promote the generation of concise, fluent, and faithful summaries for MDS."}, "embedding": {"model": "specter_v2", "vector": [-0.005410308949649334, 0.5126262307167053, -0.9153484106063843, -0.20209866762161255, -0.523956298828125, -0.3017294704914093, 0.8404443264007568, 0.26886487007141113, -0.18397121131420135, -0.20589718222618103, 1.1486378908157349, 0.3981779217720032, -0.028235584497451782, 0.3335758447647095, -0.04212331026792526, 0.12181377410888672, -0.60672527551651, 0.29743123054504395, -0.2513969838619232, -0.3879833221435547, 0.31427812576293945, -1.1282758712768555, -0.9742370843887329, 0.3703440725803375, 0.6860726475715637, -0.1021256148815155, -0.24410665035247803, 0.8276224732398987, -0.24986986815929413, 0.5157439708709717, 0.08021356910467148, -0.11975724995136261, -0.037674155086278915, -0.43960264325141907, -0.419820636510849, 0.36707189679145813, 0.20505090057849884, -0.6173886060714722, -0.28878673911094666, 0.4242824614048004, -0.16773924231529236, 0.43561071157455444, 0.7020612359046936, -0.1253565549850464, -0.349217027425766, 0.9211894273757935, 0.5115603804588318, 0.5922341346740723, 0.18060055375099182, -0.5581130981445312, 1.7631776332855225, -1.4085806608200073, 0.603752076625824, 1.4535808563232422, 0.3183009922504425, 0.47225743532180786, -0.21666297316551208, 0.03728097677230835, 1.0882431268692017, -0.06028859689831734, -0.6438769698143005, -0.48878246545791626, -0.13956871628761292, -0.2141551971435547, 1.9360978603363037, -0.1962757259607315, -0.004025167319923639, 0.4910481870174408, -0.08030780404806137, 1.7627887725830078, -0.5233039855957031, -0.592292308807373, -0.053756359964609146, -0.0335935540497303, 0.914767324924469, 0.5937393307685852, -0.2514584958553314, -0.05478733777999878, -0.7916455268859863, 0.14028127491474152, -0.08160103112459183, 0.24389955401420593, -0.3884519338607788, 0.23968406021595, -0.005626035388559103, 0.7306281924247742, 0.22103123366832733, 0.9194772243499756, -0.5352675318717957, 0.3640524446964264, 0.3750966787338257, 0.34984010457992554, 0.5585147738456726, 0.45840758085250854, 0.2640992999076843, 0.3949781060218811, -0.856472373008728, 0.4734640419483185, 0.30263614654541016, 0.6726356744766235, -0.2501915991306305, 0.034220919013023376, -1.3488227128982544, 0.3702227771282196, 1.0679901838302612, -0.4866752326488495, 0.36910486221313477, -0.9322187304496765, 0.11506175994873047, -0.3451766073703766, 0.690595805644989, -0.9289475679397583, -0.2355603724718094, -0.17444197833538055, -0.5279247164726257, -1.4419740438461304, -0.7676024436950684, 0.1143500804901123, -0.5594141483306885, 0.5919445157051086, -0.3519248366355896, -0.14872297644615173, 0.31102392077445984, 0.7925076484680176, 0.9628830552101135, 1.177879810333252, 0.24028320610523224, -0.6367359757423401, 0.5871866941452026, -1.1331634521484375, -1.0268486738204956, -1.2277061939239502, 0.9297088980674744, -0.019969938322901726, -0.044175781309604645, -0.0872359648346901, -1.3381354808807373, -0.730667769908905, -1.249286413192749, -0.06556534767150879, -0.23143380880355835, 0.6064999103546143, 0.7866670489311218, 0.17112639546394348, -0.6308922171592712, 0.9461766481399536, -0.10642737150192261, -0.4397357404232025, 0.2055048793554306, -0.01618077978491783, 0.29715192317962646, -0.8584843873977661, -0.9004667401313782, 0.35163408517837524, 0.0715327337384224, -0.8388296365737915, -0.2787874937057495, -0.6595649123191833, -1.0781766176223755, -0.03972938656806946, 0.7313212156295776, -0.899888277053833, 1.423734426498413, -0.05143730342388153, -1.4234962463378906, 0.1599883735179901, -0.3109707534313202, 0.15182889997959137, 0.1374623030424118, -0.7502923011779785, -0.27436718344688416, 0.031703975051641464, 0.033858414739370346, 0.4739849865436554, 0.12468694895505905, -0.3326905071735382, -0.15542711317539215, 0.204182967543602, -0.2765899896621704, 0.3195722699165344, -0.38723984360694885, 0.7808100581169128, -0.6397885084152222, -0.08972018212080002, 0.18840374052524567, 1.147966980934143, -0.0053837476298213005, -0.7407110333442688, -0.618246853351593, -1.2996220588684082, 0.501417875289917, 0.12341175228357315, 1.46397066116333, -0.6607147455215454, -0.5555839538574219, -0.6337913274765015, -0.16846412420272827, 0.24767714738845825, -0.7714797854423523, 0.7811189889907837, -0.026528513059020042, 0.6029801964759827, -0.12932023406028748, -1.5065374374389648, 0.2361118644475937, -0.23211044073104858, -0.5820890665054321, -0.2061271369457245, 0.19974836707115173, 1.069865107536316, -0.9651212692260742, 0.20172809064388275, -0.019231829792261124, -0.16594964265823364, -0.9049305319786072, 0.9472828507423401, -0.6867094039916992, -0.07847226411104202, -0.5537012815475464, -0.37293386459350586, 0.10624069720506668, -0.3588159680366516, 0.28763502836227417, -0.3848745822906494, -0.3819355368614197, 0.5075586438179016, -0.7359397411346436, 1.3418675661087036, 0.23178809881210327, 0.29600822925567627, -0.33740362524986267, -0.6124951839447021, 0.09058737009763718, 0.3554343581199646, 0.11119960993528366, -0.44904825091362, 0.3109830319881439, 0.1336546391248703, -1.2668074369430542, -0.006116619799286127, 0.9557761549949646, 0.7181836366653442, -0.8070585131645203, 0.6224628686904907, 0.7015812993049622, -0.21790148317813873, 1.1681742668151855, 0.8965656757354736, 0.7893441319465637, 0.2969462275505066, 0.44999822974205017, -0.17695125937461853, 0.1993197202682495, -0.31019383668899536, 0.15466903150081635, 0.5819458365440369, 1.0428507328033447, 1.1030625104904175, 0.4131893515586853, -0.6232848167419434, -0.2716808617115021, 0.26702451705932617, 1.1722290515899658, 1.4744582176208496, 0.12648341059684753, -0.8250319957733154, -0.7901058197021484, -0.5224838256835938, -0.579339325428009, 0.554488480091095, -0.29866865277290344, -0.398189514875412, -0.4524140954017639, -1.1599863767623901, 0.35944581031799316, 0.2486945539712906, 1.0075596570968628, -0.03665135055780411, -0.2107243835926056, -0.056338127702474594, -0.0496729277074337, -0.4499131441116333, -0.8461820483207703, 0.1353791505098343, -0.20023185014724731, -0.26203015446662903, -0.20751123130321503, -0.015307306312024593, 0.14484968781471252, -0.1132793128490448, 1.369071364402771, -0.0760231465101242, -0.07357306778430939, 0.36584579944610596, 0.27552899718284607, -0.5260481238365173, -0.5099864602088928, -0.2592085897922516, 0.10745526850223541, -0.49632692337036133, 0.6238535642623901, 0.8427992463111877, -0.13397681713104248, 0.360387921333313, -0.6044318079948425, 0.2683803141117096, 0.0513363741338253, -0.03195740655064583, 0.5042167901992798, 0.11309915781021118, 0.2813863456249237, -1.0833340883255005, 1.182074785232544, -0.016361532732844353, -0.011329871602356434, 0.33531641960144043, -0.4594417214393616, -0.507645308971405, 0.3614272177219391, -0.5413485169410706, -0.7667592167854309, -1.1934741735458374, 0.6402751803398132, 0.3226267695426941, -0.08151999115943909, 0.7433334589004517, 0.28083544969558716, 0.765408456325531, 0.6110223531723022, 0.20629429817199707, 0.24015799164772034, -0.20756760239601135, 0.5949465036392212, -0.5990399718284607, 0.5766712427139282, 0.5414870977401733, -0.30745869874954224, -0.2030669003725052, -0.6564497351646423, -0.8594257831573486, -1.0337640047073364, -0.6518362164497375, 0.1287897527217865, -0.24402053654193878, 0.025379721075296402, -0.6575750708580017, -0.3869676887989044, -0.21697679162025452, -1.174269676208496, 0.04168812558054924, -0.22161950170993805, -0.32367485761642456, -0.034345731139183044, -0.7889999151229858, -1.153414011001587, -0.46007075905799866, -0.7450181245803833, -0.5104395151138306, 0.3213917016983032, 0.3084752559661865, -0.7068269848823547, -0.27869734168052673, 0.45161914825439453, -0.6000512838363647, 0.4552333652973175, -0.09920690208673477, 0.574325680732727, -0.3206275403499603, -0.18678121268749237, -0.4141734540462494, 0.5431914329528809, 0.4781327545642853, -0.1854802668094635, 0.5079454779624939, -0.3392089009284973, 0.1392519623041153, 0.07132026553153992, -0.30087265372276306, 0.4767698049545288, 0.9509433507919312, -0.11463688313961029, -0.21903665363788605, -0.6657994985580444, -0.39329594373703003, 1.3426742553710938, -0.7593436241149902, -0.13626527786254883, -0.14266355335712433, 0.704841136932373, 0.8870469331741333, 0.461570680141449, 0.8196982741355896, 0.3596877157688141, 0.21416093409061432, -0.14951080083847046, -0.20262208580970764, -0.0663057416677475, -0.41300803422927856, 0.7733383178710938, 1.6384308338165283, 0.3715514838695526, -0.7278349995613098, -0.6277259588241577, 0.7700696587562561, -1.6493496894836426, -0.7322484850883484, 0.3317246735095978, 0.4796310067176819, 0.19441327452659607, -0.5794198513031006, 0.051167845726013184, -0.2972823679447174, 0.5076331496238708, 0.46423643827438354, -0.3046610653400421, -0.4384133219718933, 0.018040277063846588, -0.09077142924070358, -0.2505858540534973, 0.5957016348838806, -0.2679663300514221, 0.495019793510437, 14.627345085144043, 0.6887296438217163, 0.5340942144393921, 0.33971014618873596, 0.9138334393501282, -0.1557779610157013, -0.6701241731643677, -0.21888792514801025, -1.0465493202209473, -0.2005976289510727, 1.2650041580200195, -0.4808254539966583, 0.04079221189022064, -0.04064754769206047, 0.3542967140674591, -0.46531379222869873, -0.7445336580276489, 0.13645371794700623, 0.6561734676361084, -1.6098259687423706, 0.46721991896629333, 0.07480228692293167, 0.7202544212341309, 0.11218327283859253, 0.8056904673576355, 1.0385818481445312, 0.547602117061615, -0.2560611069202423, 0.305758535861969, 0.21825534105300903, 0.44083479046821594, -0.730756402015686, 0.6186429858207703, 0.9177303314208984, -0.39178866147994995, -0.4480322003364563, -0.6311569213867188, -1.0799078941345215, 0.5587078332901001, 0.1250941902399063, -0.38712647557258606, 0.06969814002513885, -0.40154704451560974, 1.1313725709915161, 0.1800440400838852, 0.25787749886512756, -0.210161954164505, 0.3566107749938965, 0.0010835379362106323, -0.19645848870277405, 0.5829446911811829, 0.24943512678146362, 0.4107779562473297, 0.12986186146736145, 0.1679726243019104, 0.6348878741264343, 0.2712024450302124, 0.44341063499450684, -0.4190619885921478, -0.031718138605356216, -0.6161045432090759, -0.38930773735046387, 0.14340440928936005, 0.526874303817749, 0.6180631518363953, -0.0784485787153244, -0.3158610463142395, 0.04475343972444534, -0.0012893498642370105, -0.011435057036578655, 0.012538383714854717, -0.06515154242515564, -0.06373107433319092, -0.3147934377193451, -0.125557079911232, 0.6941617131233215, -0.2872006595134735, -0.28713908791542053, -0.9837619662284851, -0.2807924151420593, 0.42419809103012085, -0.8102517127990723, -0.5997211337089539, 0.6386300921440125, 0.16195878386497498, -0.7244220972061157, -0.3410038650035858, -0.14264194667339325, -0.7634291052818298, 0.07046911865472794, -0.7433076500892639, -0.568760871887207, 0.20380331575870514, -0.8596700429916382, 0.013514107093214989, -0.006832627113908529, 1.1889296770095825, -0.12044943124055862, -0.6303508281707764, -0.409351646900177, 0.33869823813438416, -0.7171417474746704, -0.04400679096579552, -0.7906810641288757, 0.6137484908103943, 0.5247216820716858, -0.34565192461013794, 0.48507875204086304, 0.45858561992645264, -0.017802713438868523, -0.8787177801132202, -0.11620623618364334, 0.7002108693122864, -0.7880104780197144, -1.0622597932815552, -0.44119247794151306, -0.9971511363983154, 0.11476956307888031, 0.992160439491272, -0.6951467990875244, 0.6736528277397156, 0.10755479335784912, 0.4121703803539276, 0.17797774076461792, -1.017222285270691, 0.10625890642404556, 0.2750951051712036, -0.2828833758831024, -0.6104837656021118, 0.2969362437725067, 0.5322170257568359, -0.8343905210494995, -0.4349301755428314, -0.5100658535957336, -0.4559216797351837, -0.17857494950294495, 0.7472668886184692, 0.05448596179485321, 1.0151946544647217, 0.6001835465431213, 0.19295789301395416, -1.1676911115646362, -0.07245258241891861, -1.0024996995925903, -0.1179998591542244, 0.6745923757553101, 0.5191126465797424, 0.18933996558189392, 0.3030753433704376, 0.9735705852508545, 0.08166605979204178, -0.39896833896636963, -0.21476298570632935, -0.08343520015478134, 0.003433214733377099, 0.021694837138056755, -0.021698875352740288, -0.1977253407239914, 0.2774515450000763, 0.43191853165626526, 0.4733777642250061, 0.45806071162223816, -0.325592577457428, -0.6569694876670837, 0.5105903744697571, -0.11835041642189026, 0.3113929331302643, -0.4752454459667206, 0.2421458661556244, -1.7529257535934448, -0.2525117099285126, -0.4996403157711029, 0.25829461216926575, -1.5770152807235718, -0.26287388801574707, 0.8856152296066284, 0.07440844923257828, -0.1854734569787979, 0.3712847828865051, -0.56675785779953, -0.6370649933815002, -0.5379558801651001, -1.3704807758331299, 0.7568318843841553, 0.9891518354415894, -0.974510669708252, -0.46693187952041626, -0.21944878995418549, -0.6553767323493958, 0.30524036288261414, 0.44914233684539795, -0.46093085408210754, -0.948065996170044, -1.0804234743118286, 0.26485586166381836, -0.0450027771294117, -0.28025564551353455, -0.38698312640190125, 0.8712308406829834, 0.5479802489280701, -0.3678373098373413, -0.668281614780426, 0.24272921681404114, -0.43176671862602234, -0.2331560105085373, 0.12615007162094116, -0.7827633619308472, -0.18508543074131012, 0.03311022371053696, -0.4713631272315979, -0.6619484424591064, 0.32832300662994385, -0.20788857340812683, -1.3232792615890503, -0.6333461403846741, 0.23930829763412476, -0.8414746522903442, 0.09116673469543457, -0.2844679355621338, -0.31000593304634094, -1.2643340826034546, -0.4054250717163086, 0.1694677770137787, 0.7972216606140137, -0.23347774147987366, 0.7722687125205994, 0.4749130606651306, -1.303615689277649, -0.17859622836112976, -0.13360129296779633, -0.19037288427352905, 0.2553066909313202, 0.9670883417129517, 0.34403231739997864, 0.14513225853443146, 0.53291255235672, 0.4872795641422272, 0.1155695915222168, -0.6215350031852722, -0.23113176226615906, 0.4017666280269623, -0.595108687877655, -0.09568624198436737, 0.9774854779243469, -0.3335452377796173, -0.5546702146530151, 0.160421222448349, -0.891734778881073, -0.9670242667198181, 0.1371833086013794, 1.228419303894043, 0.6016103625297546, -0.1068662777543068, 0.006925783585757017, -0.47318586707115173, 0.29324573278427124, -0.5641873478889465, -0.46054813265800476, 1.1267709732055664, -0.39372938871383667, -0.1165429875254631, 0.46177127957344055, 0.915664792060852, -0.9138584136962891, -0.8619524836540222, -0.5530565977096558, -0.04550663381814957, -0.15647684037685394, 0.6537918448448181, -0.6306867003440857, -0.08880208432674408, 0.4320925176143646, 0.17179971933364868, 0.6298423409461975, 0.12828965485095978, -0.21084576845169067, -0.002762687159702182, 0.694694995880127, -0.35848143696784973, -1.1668509244918823, -0.04943045601248741, 0.7831392288208008, 1.4106560945510864, -0.8400522470474243, 0.9147332310676575, 0.04934275895357132, -1.2491103410720825, 0.8257063031196594, 0.2583211660385132, -0.04348500818014145, 0.42349740862846375, -0.5428357124328613, -0.06729134917259216, -0.14300213754177094, -1.1959517002105713, -0.19760312139987946, 0.9625267386436462, 0.9308310151100159, 0.5385981202125549, -0.07672937214374542, -0.16851384937763214, 1.2403039932250977, 0.717788815498352, 0.2939679026603699, 0.7982073426246643, 0.45842206478118896, -0.6222219467163086, 0.24221937358379364, 0.46366843581199646, 0.4479740262031555, -0.7182605862617493, -0.0605635866522789, -0.11600827425718307, 0.6696277260780334, -0.10388888418674469, 1.0682889223098755, 0.6254320740699768, 0.18808463215827942, 0.6542736887931824, -0.1053808182477951, 0.2561679780483246, -1.0473850965499878, -0.4943709671497345, 0.35474127531051636, -0.05694516375660896, -0.049947965890169144, -0.4971736967563629, -0.708979606628418, -0.19441694021224976, -0.17672650516033173, 0.14070357382297516, 0.21281127631664276, -0.07010147720575333, 1.3553099632263184, 0.8214647173881531, 0.5030055046081543, -0.06150253117084503, -0.6861307621002197, -0.5755857825279236, -0.993800699710846, -0.10244371742010117, -0.6020305752754211, -0.21060891449451447, -0.19133254885673523, -0.2892706096172333, -0.3670593500137329]}, "authors": [{"authorId": "79548673", "name": "Joseph Peper"}, {"authorId": "2266840869", "name": "Wenzhao Qiu"}, {"authorId": "2267224906", "name": "Lu Wang"}], "references": [{"paperId": "f3ca1504ab4cc14f491f07e5a8b38d93890551e1", "title": "Peek Across: Improving Multi-Document Modeling via Cross-Document Question-Answering"}, {"paperId": "7a6a20f705dfd5d1f8cfd24743b0977f34cdad1e", "title": "Do Multi-Document Summarization Models Synthesize?"}, {"paperId": "f6b171486d0240fff7a464c0fbbfd84483945924", "title": "DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "fe02e806f7591a7ff39b5a22f01bfc6663e44e08", "title": "LED down the rabbit hole: exploring the potential of global attention for biomedical multi-document summarisation"}, {"paperId": "3b39efe6c91ae432dd35bb79431edb8a6719f906", "title": "Investigating Efficiently Extending Transformers for Long Input Summarization"}, {"paperId": "64f42b62c9795c66074b4dd72511b4b04ea3ec7b", "title": "Multi-Document Summarization with Centroid-Based Pretraining"}, {"paperId": "5f50a876e1f323598df423475a9cb4c01bd4b44f", "title": "FactPEGASUS: Factuality-Aware Pre-training and Fine-tuning for Abstractive Summarization"}, {"paperId": "0f5b18f7b54517fa6d54a311e08a81d5fa07c695", "title": "Efficient Few-Shot Fine-Tuning for Opinion Summarization"}, {"paperId": "182e296d349662376d91f2b2ee1f05c5d577ea6e", "title": "POLITICS: Pretraining with Same-story Article Comparison for Ideology Prediction and Stance Detection"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "3dfb1f50f2a34a699c339dabaa6f9b3a977973de", "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences"}, {"paperId": "ee1ef7b70dc34adcc90c42cc28168165ea56501f", "title": "SummaC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization"}, {"paperId": "3cf51f5f36bac0cbafdb7581d8713979e0d1c17e", "title": "CLIFF: Contrastive Learning for Improving Faithfulness and Factuality in Abstractive Summarization"}, {"paperId": "b6bf7706a4773e452bb09cf43d7686ac8fd06403", "title": "Faithful or Extractive? On Mitigating the Faithfulness-Abstractiveness Trade-off in Abstractive Summarization"}, {"paperId": "42e41ab2211b8ba78e36326ea21e05bd25d92c42", "title": "Efficiently Summarizing Text and Graph Encodings of Multi-Document Clusters"}, {"paperId": "eebc1811c55c2e5e8b3b78d0b0382ad50f22e32a", "title": "Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence"}, {"paperId": "6aaec722a90eee0185d4bbfebbcd4f228ed1577f", "title": "Cross-Document Language Modeling"}, {"paperId": "d164fc8d71ca304bbd7833de5d03ad0a5ca32afa", "title": "Multi-document Summarization via Deep Learning Techniques: A Survey"}, {"paperId": "56214030211d3c0212fc0da9b97735ead9021cc5", "title": "Multi-XScience: A Large-scale Dataset for Extreme Multi-document Summarization of Scientific Articles"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "4eff0c1f82cf09753400bb7cffedac7e44ebd903", "title": "Few-Shot Learning for Opinion Summarization"}, {"paperId": "270f3bea8ca801870a6cc56b4d36f7f2019c9ed0", "title": "MPNet: Masked and Permuted Pre-training for Language Understanding"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "ef57ad148ec2eeef5eb3467f3e37e30042b2c7bd", "title": "Generating Representative Headlines for News Stories"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "41d49ec6f73ab5621ab8e8cb5ddb677a886ccc76", "title": "Justifying Recommendations using Distantly-Labeled Reviews and Fine-Grained Aspects"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "0c5598424cc96d8fb500eb553cb7969f86a0ede0", "title": "Evaluating the Factual Consistency of Abstractive Text Summarization"}, {"paperId": "93d63ec754f29fa22572615320afe0521f7ec66d", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"}, {"paperId": "cc27ec53160d88c25fc5096c0df65536eb780de4", "title": "Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "a002b45d7b844b0d4e2c4b56564a008b96c98f75", "title": "Exploring Text Links for Coherent Multi-Document Summarization"}, {"paperId": "e8b7225037dfa77623824f28f58927212bc3949e", "title": "Neural Network-Based Abstract Generation for Opinions and Arguments"}, {"paperId": "3d4a123b8036f3bd81ad2659af69865cde404909", "title": "Towards Coherent Multi-Document Summarization"}, {"paperId": "e6066edec51ddb44b4b989cb21d60dbb0f1e5a88", "title": "The original Borda count and partial voting"}, {"paperId": "6d396187ba065f0c316623778ceb90d982d39d2b", "title": "Reducing Redundancy in Multi-document Summarization Using Lexical Semantic Similarity"}, {"paperId": "284def0393e733c747f4caf32adf52693a36cfed", "title": "The Pyramid Method: Incorporating human content selection variation in summarization evaluation"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "7d567a104ed5e206229c6d98e4190135f336448d", "title": "A Common Theory of Information Fusion from Multiple Text Sources Step One: Cross-Document Structure"}, {"paperId": "8eb180e37164d43029f627b1388279bdac47acce", "title": "Human Language Technologies"}, {"paperId": "dc954000617ae982f83b7f1ed4bd72b95e38aa88", "title": "Overview of DUC 2005"}, {"paperId": null, "title": "2022. PRIMERA: Pyramid-based masked sentence pre-training for multi-document summarization"}, {"paperId": null, "title": "Ranking cluster sentences by summary-worthiness (\u00a73.2). We score each cluster element based on a) distance to the cluster centroid and b) entailment-based intra-cluster consistency"}, {"paperId": null, "title": "using the default sliding-window local attention configuration supplemented by inserting <doc-sep> tokens with full attention added after"}, {"paperId": null, "title": "warmup steps"}, {"paperId": null, "title": "Pre-processing of the 3-million+ pre-training examples with the PELMS technique takes approximately 14 hours using the same computing environment"}, {"paperId": null, "title": "only consider clusters with at least 2 elements"}]}