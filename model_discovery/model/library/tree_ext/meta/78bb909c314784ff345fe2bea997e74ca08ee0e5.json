{"paperId": "78bb909c314784ff345fe2bea997e74ca08ee0e5", "title": "A Framework for Accelerating Transformer-Based Language Model on ReRAM-Based Architecture", "abstract": "Transformer-based language models have become the de-facto standard model for various natural language processing (NLP) applications given the superior algorithmic performances. Processing a transformer-based language model on a conventional accelerator induces the memory wall problem, and the ReRAM-based accelerator is a promising solution to this problem. However, due to the characteristics of the self-attention mechanism and the ReRAM-based accelerator, the pipeline hazard arises when processing the transformer-based language model on the ReRAM-based accelerator. This hazard issue greatly increases the overall execution time. In this article, we propose a framework to resolve the hazard issue. First, we propose the concept of window self-attention to reduce the attention computation scope by analyzing the properties of the self-attention mechanism. After that, we present a window-size search algorithm, which finds an optimal window size set according to the target application/algorithmic performance. We also suggest a hardware design that exploits the advantages of the proposed algorithm optimization on the general ReRAM-based accelerator. The proposed work successfully alleviates the hazard issue while maintaining the algorithmic performance, leading to a $5.8\\times $ speedup over the provisioned baseline. It also delivers up to $39.2\\times /643.2\\times $ speedup/higher energy efficiency over GPU, respectively.", "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems", "year": 2021, "citationCount": 9, "influentialCitationCount": 2, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This article proposes the concept of window self-attention to reduce the attention computation scope by analyzing the properties of the self-ATTention mechanism, and presents a window-size search algorithm, which finds an optimal window size set according to the target application/algorithmic performance."}, "embedding": {"model": "specter_v2", "vector": [0.23108725249767303, 0.38638436794281006, -0.25504738092422485, 0.19170668721199036, -0.5100895762443542, 0.052974551916122437, 0.1817539930343628, 0.09253299236297607, -0.8267921805381775, -0.4584348201751709, 0.8940436244010925, -0.3080475330352783, 0.7296201586723328, -0.6052888631820679, 0.04007658362388611, -0.1995450258255005, -0.5238608717918396, -0.36814823746681213, 0.06234785541892052, -0.24411848187446594, 0.015931230038404465, -0.3714335262775421, -1.2869915962219238, 0.46279484033584595, 0.580308198928833, 0.4215056896209717, 0.26917311549186707, 1.0605946779251099, -0.37948134541511536, 0.33361342549324036, 0.6039726734161377, 0.18835188448429108, 0.17871218919754028, 0.18790876865386963, -0.21563750505447388, -0.4133221209049225, 0.18374407291412354, -0.417468786239624, -0.6404914855957031, 0.8041409254074097, -0.11769357323646545, 0.4178105294704437, 0.0996227115392685, -0.5653239488601685, -0.15450169146060944, 0.9173659682273865, 0.4795306921005249, 1.1161779165267944, -0.6808758974075317, -0.3858468532562256, 1.140134334564209, -1.4372793436050415, -0.04593106731772423, 0.83961021900177, 0.15156826376914978, 0.3989347517490387, 0.1412215232849121, -0.5878879427909851, 0.016214078292250633, -0.11056835204362869, -0.6700976490974426, -0.7941576838493347, 0.05574289336800575, -0.22512146830558777, 2.1077027320861816, -0.07640577852725983, 0.024299604818224907, -0.030398843809962273, 0.5448145270347595, 1.1390652656555176, -0.22174225747585297, -1.0028719902038574, -0.10987546294927597, -0.4236936569213867, 0.8239066004753113, 0.9064131379127502, -0.26902031898498535, 0.23319336771965027, -1.1271471977233887, -0.3772415816783905, 0.4338885247707367, -0.05137421190738678, 0.1251564621925354, 0.09484346210956573, -0.3649807274341583, 0.8093006014823914, 0.18076170980930328, 1.018135905265808, -0.029679574072360992, 0.5590201020240784, 0.9787493944168091, 0.06766559928655624, 0.08606023341417313, 0.11395169794559479, 0.38790228962898254, 0.3505352735519409, -1.1674164533615112, 0.10574939101934433, -0.4356426000595093, 0.9631460905075073, -0.4250219166278839, 0.7120459079742432, -1.0904388427734375, -0.17739935219287872, 1.192101001739502, 0.22187086939811707, 0.7787693738937378, -0.05665476620197296, 0.13335616886615753, -0.5687136054039001, -0.09809798747301102, -0.06936553120613098, -0.25268593430519104, -0.31221023201942444, -1.2541892528533936, -1.0820064544677734, -0.4257349669933319, 0.341665118932724, -1.0808848142623901, 0.3773967921733856, -0.4138306975364685, -0.22561414539813995, 0.5270193219184875, -0.011774708516895771, 0.9341356158256531, 0.7151656746864319, 0.45252278447151184, -0.15249289572238922, 1.7820554971694946, -1.461542010307312, -0.837256669998169, -0.8809453248977661, 0.6415121555328369, -0.40368929505348206, 0.3092712163925171, -0.7848907709121704, -1.3437020778656006, -0.7943109273910522, -0.8492093682289124, -0.23375548422336578, -0.22319190204143524, 0.11666747182607651, 0.9185188412666321, 0.16827072203159332, -1.4311422109603882, 0.50942462682724, -0.4006774127483368, -0.23177418112754822, -0.0066999695263803005, 0.12452332675457001, 0.5799030065536499, 0.26299524307250977, -1.3274732828140259, -0.06395864486694336, 0.22425739467144012, -0.6341420412063599, -0.18457148969173431, -0.7031727433204651, -1.0444480180740356, 0.2987433671951294, -0.2666809856891632, -0.4703703820705414, 1.4662721157073975, 0.29858675599098206, -1.1912734508514404, 0.6728610396385193, -0.6121648550033569, -0.009704524651169777, -0.25909677147865295, 0.13961833715438843, -0.7410953044891357, -0.45407620072364807, -0.02704203873872757, 0.17475458979606628, 0.4706481397151947, 0.028467899188399315, -0.32556796073913574, -0.13359001278877258, -0.48373696208000183, 0.033288758248090744, -0.5233191847801208, 1.1686183214187622, -0.5363300442695618, -0.4843980073928833, 0.4230041205883026, 0.6997441649436951, -0.4017839729785919, -0.3023202419281006, -0.4353589713573456, -0.9098343253135681, 0.6873611807823181, 0.2632407248020172, 1.6158504486083984, -1.1134480237960815, -1.4595943689346313, -0.14453701674938202, -0.10995621234178543, -0.061214640736579895, -0.3945530652999878, 0.5554237961769104, -0.8065093755722046, 0.053692206740379333, 0.12063343077898026, -0.2306157499551773, -0.4573855400085449, -0.8578009605407715, -1.2809600830078125, -0.41718947887420654, -0.23069418966770172, 1.137894630432129, -0.8238029479980469, 0.1810784637928009, -0.5002554059028625, 0.2708621025085449, -0.7488989233970642, 1.2801405191421509, 0.007640998810529709, -0.0028272720519453287, -0.04575377702713013, -0.020940998569130898, 0.33110490441322327, -0.2494068443775177, -0.012770363129675388, -1.0255132913589478, -0.8452625870704651, 0.23451150953769684, 0.2495909333229065, 1.1765494346618652, -0.27032384276390076, 0.49422261118888855, 0.029141580685973167, -0.25317394733428955, 0.1003030315041542, 0.4712600111961365, -0.44155582785606384, -0.5759381055831909, 0.6036958694458008, 0.01556672714650631, -0.11287739127874374, 0.2546827495098114, 1.541365623474121, 1.0288795232772827, -0.504636287689209, 0.5934967994689941, 0.2383052557706833, -0.037190135568380356, 0.4284268319606781, 0.21746422350406647, 0.857199490070343, -0.2347557097673416, 0.4976806044578552, -0.5258142352104187, 0.634782612323761, -0.677294135093689, -0.21849630773067474, 0.5179219841957092, 0.24893616139888763, 0.31549549102783203, 0.04392627626657486, -0.6857651472091675, -0.4505421817302704, 0.1488877534866333, 0.5970585346221924, 1.7281619310379028, -0.6520000100135803, -0.13323110342025757, -0.6931761503219604, -0.1394791156053543, -0.7108814120292664, 0.1386011242866516, 0.2685503661632538, -0.24820703268051147, -0.6534168124198914, -1.3588337898254395, 1.0152298212051392, 0.417140930891037, 1.0594751834869385, -0.8187304139137268, -0.9737906455993652, -0.3092477321624756, 0.5443288087844849, -0.8651819229125977, -0.8719947338104248, 0.6647316217422485, -0.899480938911438, 0.22075150907039642, 0.10186629742383957, -0.26562225818634033, 0.3944949805736542, -0.22772595286369324, 0.6998658180236816, -0.5159211158752441, -0.41338682174682617, -0.00047471115249209106, 0.5282878875732422, -0.48178791999816895, -0.9714345335960388, -0.015607770532369614, -0.043981119990348816, -0.46510225534439087, 0.6977503895759583, 0.4338272213935852, -0.04057595878839493, -0.38880982995033264, -0.37759917974472046, -0.34292492270469666, 0.07982978969812393, 0.06715825200080872, 0.42980024218559265, 0.09055045247077942, -0.46300381422042847, -1.0858701467514038, 1.368789792060852, 0.6379265189170837, -0.5267894268035889, 0.10380454361438751, -0.5888085961341858, 0.0678553506731987, 0.5816072821617126, -0.6050604581832886, -0.3844490051269531, -0.7770026326179504, 0.19578023254871368, 0.16177059710025787, 0.20122164487838745, -0.04185211658477783, -0.03790440037846565, -0.15154455602169037, 0.0712398961186409, 0.7764735817909241, 0.46090734004974365, 0.6331074237823486, 0.3662039041519165, -0.19669608771800995, 0.18711312115192413, 0.18025077879428864, 0.11073670536279678, 0.09310363978147507, -0.4198971390724182, -0.9176045656204224, -0.22912423312664032, -0.2743702530860901, 0.22867617011070251, -0.16039647161960602, 0.10247348994016647, -0.8512709140777588, -0.9313338994979858, 0.10865099728107452, -1.1916289329528809, -0.062367040663957596, 0.03037194348871708, -0.38880455493927, -0.09983715415000916, -1.0204464197158813, -1.4769973754882812, -0.6968638300895691, -1.6554317474365234, -1.2756885290145874, 0.48866790533065796, 0.07622957974672318, -0.23767216503620148, -0.30018553137779236, -0.30988040566444397, -0.37238869071006775, 1.3226639032363892, -1.0229076147079468, 1.2057909965515137, -0.12594439089298248, -0.5122268795967102, 0.07117690145969391, -0.06927400827407837, 0.020299619063735008, -0.2600630819797516, 0.12535840272903442, -0.7504087090492249, 0.3622003495693207, 0.4238068461418152, 0.2960997521877289, 0.43764984607696533, 0.36552831530570984, 0.9333111643791199, 0.29428356885910034, -0.9029690623283386, 0.1421322077512741, 1.4826805591583252, 0.0036283170338720083, 0.46444299817085266, -0.027833247557282448, 0.7341179251670837, -0.2991333305835724, -0.01354273408651352, 0.4729633033275604, 0.11686840653419495, 0.3414735794067383, 0.07296508550643921, -0.46827733516693115, 0.372809499502182, 0.12291015684604645, 0.5742665529251099, 2.007368803024292, 0.3708510994911194, -0.014182878658175468, -1.0180537700653076, 0.5227978825569153, -1.0493690967559814, -0.7202685475349426, 0.4680175185203552, 0.7449958324432373, 0.20887181162834167, -0.24117860198020935, -0.46836379170417786, 0.23351415991783142, 0.6224378943443298, 0.5876113176345825, -0.42065301537513733, -1.159138798713684, 0.3387952744960785, 0.5843268632888794, 0.6221393346786499, 0.8080474734306335, -0.4273248016834259, 0.8462076783180237, 14.487358093261719, 0.782562255859375, 0.040862083435058594, 0.6823088526725769, 0.5747237801551819, 0.7322666645050049, -0.26252713799476624, -0.2454044371843338, -1.5402767658233643, -0.25206267833709717, 1.271349310874939, -0.26002171635627747, 0.09705524146556854, 0.3234633207321167, 0.12771478295326233, -0.06495959311723709, -0.14997687935829163, 0.49687567353248596, 0.7714030742645264, -1.2464098930358887, 0.6617567539215088, 0.36492249369621277, -0.45808613300323486, 0.33599188923835754, 0.6019411683082581, 0.4974319338798523, 0.35696670413017273, -0.2601813077926636, -0.0872882604598999, -0.02759145200252533, 0.8547760844230652, -0.4613053798675537, 0.4133830964565277, 0.5368097424507141, -1.1725741624832153, -0.13434550166130066, -0.6931618452072144, -1.1035833358764648, 0.07938115298748016, 0.6971237063407898, -0.4281013011932373, -0.7432203888893127, -0.33751344680786133, -0.04221491515636444, 0.6287491917610168, 0.20220310986042023, -0.0470133051276207, 0.28158193826675415, 0.33748334646224976, -0.059111133217811584, -0.09865547716617584, 0.5620725154876709, 0.29332125186920166, -0.11668898165225983, 0.3454890549182892, 0.4433107376098633, -0.20256729423999786, 0.1352158635854721, -0.1498841643333435, -0.13458368182182312, -0.2990420162677765, -0.35054898262023926, -0.3334008753299713, 1.1668018102645874, -0.05979297682642937, 0.3758262097835541, -0.3281298875808716, 0.3725889027118683, 0.5595558881759644, -0.1622898429632187, -0.6699295043945312, -0.36453911662101746, 0.2181221842765808, -0.2333269715309143, -0.11483974754810333, 0.20854535698890686, -0.17946411669254303, -0.5989872813224792, -0.9172770380973816, -0.38221612572669983, 0.17017002403736115, -0.4814196527004242, -0.4827667772769928, 1.635867714881897, -0.429019957780838, -0.4492804706096649, 0.7170806527137756, -0.8887821435928345, -0.5888279676437378, 0.3207741379737854, -1.249066948890686, -0.6591883301734924, 0.26077187061309814, -0.20903468132019043, -0.4629204273223877, -0.02998359315097332, 1.4122318029403687, -0.033298149704933167, -0.26055359840393066, 0.18779462575912476, -0.10913009941577911, 0.18443505465984344, -0.36309483647346497, -0.1608230620622635, 1.0249261856079102, 0.4633883535861969, -0.613842248916626, 0.42322811484336853, 0.1792011708021164, -0.04645945504307747, -1.2132564783096313, -0.31460607051849365, 0.8553012013435364, -0.46665605902671814, 0.05580873787403107, -1.338548183441162, -0.8731024861335754, -0.012445853091776371, 0.8055933117866516, -0.07548992335796356, 0.6313665509223938, -0.041820917278528214, -0.15955506265163422, -0.21433572471141815, -0.7620419263839722, 0.4138777554035187, 0.625741720199585, -1.0268566608428955, -0.16254185140132904, 0.1429217904806137, 0.6391447186470032, -1.3141285181045532, -0.4193516671657562, -0.11244124919176102, -0.0986524373292923, -0.0962439626455307, 1.0073370933532715, 0.09624055027961731, 0.6651031374931335, 0.6532701849937439, -0.1692107617855072, -0.4632290005683899, -0.07336131483316422, -0.6997411847114563, 0.03008260391652584, 0.2979823350906372, 0.6150065064430237, -0.26930734515190125, 0.6900243163108826, 1.233324646949768, 0.2490706741809845, -0.32030418515205383, -0.7664440274238586, -0.00524686835706234, -0.25123172998428345, -0.5358242392539978, 0.4152185320854187, -0.31671544909477234, 0.5686478018760681, 0.17978046834468842, 0.5489643812179565, 0.7449257373809814, -0.20280584692955017, -0.2939336895942688, 0.0580504946410656, 0.1725994348526001, 0.296189546585083, -0.33678138256073, -0.44110774993896484, -0.9472646117210388, 0.06688859313726425, -1.4049760103225708, 0.11234547197818756, -0.5931025743484497, -0.1688220053911209, 0.40865156054496765, -0.12472137063741684, 0.010643929243087769, 0.26389080286026, -0.32625049352645874, -0.5496186017990112, -0.5527306795120239, -0.19677817821502686, 0.7970584630966187, 0.7229648232460022, -0.6522477269172668, -0.22133074700832367, -0.07596457749605179, -0.08873903751373291, 0.34838417172431946, 0.4173516035079956, -0.5082198977470398, -0.6772974729537964, -1.055080771446228, 0.03086681291460991, -0.04911051690578461, -0.4058881103992462, -0.7370699048042297, 1.3505877256393433, 0.5350217223167419, -0.3214520812034607, -0.2423395812511444, -0.15552501380443573, -0.8885722756385803, -0.734343409538269, 0.636306643486023, -0.4897940754890442, 0.8604202270507812, 0.589381217956543, -0.8178586363792419, -0.4500482678413391, 0.4339074492454529, -0.10931529849767685, -1.14767324924469, -0.7458776831626892, 0.5778284072875977, -1.0758209228515625, 0.29399797320365906, 0.11932220309972763, -0.018502069637179375, -0.9477586150169373, 0.066261425614357, 0.10142797976732254, 0.1732439547777176, -0.44016313552856445, 0.7763318419456482, 0.599958062171936, -1.0035825967788696, 0.40922507643699646, 0.8341055512428284, -0.15490756928920746, -0.10865866392850876, 0.77494215965271, 0.018992584198713303, -0.3858976364135742, 0.8195407390594482, 0.3137224614620209, 0.23949192464351654, -1.3627804517745972, 0.05900544673204422, 0.3687710464000702, -0.920455276966095, -0.06609625369310379, 0.8968082666397095, -0.19506090879440308, -0.8198972344398499, -0.23486807942390442, -1.2968500852584839, -0.6654000282287598, -0.24952971935272217, 1.0874080657958984, 0.14955022931098938, 0.16738353669643402, -0.23737184703350067, -0.6053808927536011, 0.11923637241125107, -0.46729350090026855, -0.5332711338996887, 0.29597216844558716, 0.2816908657550812, -0.8084509968757629, 0.23800158500671387, 0.10928574949502945, -0.141701340675354, -0.05257662013173103, -0.46919944882392883, -0.23776710033416748, 0.0466262511909008, 0.6884944438934326, 0.32615479826927185, -0.5265254974365234, 0.6806514263153076, 0.680696964263916, 0.24090613424777985, 0.43739327788352966, -0.5299324989318848, 0.4853304922580719, 0.10961633175611496, 0.2094191163778305, -0.6571943759918213, -0.8258975148200989, 1.7981544733047485, 0.9838658571243286, -0.4116063117980957, 0.3413945138454437, -0.5547252893447876, -0.5422876477241516, 1.2124149799346924, 0.6252034902572632, 0.09678575396537781, 1.257718801498413, 0.7056287527084351, 0.29460614919662476, 0.28993189334869385, -1.0839284658432007, -0.3804294168949127, 0.3574938178062439, 0.8062362670898438, 1.1996320486068726, -0.00018156196165364236, -0.12885431945323944, 0.975279688835144, 0.3022388219833374, 0.43508458137512207, 0.8079027533531189, 0.532112181186676, -0.32014185190200806, -0.35718777775764465, -0.1255122572183609, 0.538759171962738, -0.6355034112930298, -1.3166276216506958, 0.9240026473999023, 0.9100180864334106, -0.272905170917511, 0.40551286935806274, 1.1617685556411743, -0.12397553771734238, 0.45866110920906067, 0.18984383344650269, 0.2965088486671448, -0.6506156921386719, -0.5337191224098206, -0.05901806056499481, -0.6511027812957764, 0.10364960879087448, -0.06977365165948868, 0.001305680605582893, -0.8481482267379761, 0.13207903504371643, 0.22677072882652283, 0.22909636795520782, 0.4785557687282562, 0.7301114797592163, 0.8064939379692078, 0.6980136632919312, -0.5418328046798706, -0.35549667477607727, -0.2916281521320343, -0.6542381048202515, 0.09878795593976974, -1.1767340898513794, -0.0848277136683464, 0.43099403381347656, -0.08076928555965424, -0.6838161945343018]}, "authors": [{"authorId": "41184118", "name": "Myeonggu Kang"}, {"authorId": "2115353051", "name": "Hyein Shin"}, {"authorId": "144843517", "name": "L. Kim"}], "references": [{"paperId": "b431938300a5e2baa9c88b83d8fec13c087cb85b", "title": "AttentionLite: Towards Efficient Self-Attention Models for Vision"}, {"paperId": "097210dc65924f8ce59523faf444e635523dc714", "title": "TernaryBERT: Distillation-aware Ultra-low Bit BERT"}, {"paperId": "6048cbb88d9a6691bfade0d46b41650533ac42bd", "title": "Real-Time Execution of Large-scale Language Models on Mobile."}, {"paperId": "268b4c0cbbce656a582b6903fb85e3c517bd137c", "title": "Fixed-Point Optimization of Transformer Neural Network"}, {"paperId": "7b9b756ab509cb9f52dbac95e3e901d571f0784f", "title": "A Survey of the Usages of Deep Learning for Natural Language Processing"}, {"paperId": "2573af4e13d9a5dddb257d22cd38a600528d9a8b", "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"}, {"paperId": "d3c6c635b9cfd8890c7244d3db4be53d45944963", "title": "A^3: Accelerating Attention Mechanisms in Neural Networks with Approximation"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "a3ef6ee560e93e6f58be2b28f27aed0eb86dc463", "title": "Fine-tune BERT with Sparse Self-Attention Mechanism"}, {"paperId": "ce106590145e89ea4b621c99665862967ccf5dac", "title": "Q8BERT: Quantized 8Bit BERT"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d", "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "d6dccb5d71fbb6f5765f89633ba3a8e6809a720d", "title": "Stand-Alone Self-Attention in Vision Models"}, {"paperId": "4af09143735210777281b66997ec12994dbb43d4", "title": "Matching the Blanks: Distributional Similarity for Relation Learning"}, {"paperId": "a81874b4a651a740fffbfc47ef96515e8c7f782f", "title": "Latent Retrieval for Weakly Supervised Open Domain Question Answering"}, {"paperId": "7edacd94dc1509803d9bbcc1d92fea780d71cb3e", "title": "MnnFast: A Fast and Scalable System Architecture for Memory-Augmented Neural Networks"}, {"paperId": "ef16cfb732304eac420ccb344859dd660ace0b6a", "title": "Performance Analysis of Deep Learning Workloads on Leading-edge Systems"}, {"paperId": "a98041dc8b935f9c5ff2b1fd2ad1e772be03c6a7", "title": "Tiered-ReRAM: A Low Latency and Energy Efficient TLC Crossbar ReRAM Architecture"}, {"paperId": "f4238bd2385a52413ccbacfd9e409a650235bd13", "title": "Adaptive Attention Span in Transformers"}, {"paperId": "b03c7ff961822183bab66b2e594415e585d3fd09", "title": "Are Sixteen Heads Really Better than One?"}, {"paperId": "a43cf0f32f8ae254544f46073c04f286716daf19", "title": "Optimizing Weight Mapping and Data Flow for Convolutional Neural Networks on RRAM Based Processing-In-Memory Architecture"}, {"paperId": "668f42a4d4094f0a66d402a16087e14269b31a1f", "title": "Analysis Methods in Neural Language Processing: A Survey"}, {"paperId": "577df7f48ecdc44271a51c4d049563565f51e398", "title": "ReRAM-Based Processing-in-Memory Architecture for Recurrent Neural Network Acceleration"}, {"paperId": "4d1c856275744c0284312a3a50efb6ca9dc4cd4c", "title": "Know What You Don\u2019t Know: Unanswerable Questions for SQuAD"}, {"paperId": "07f978f0e7829f2df60d98cfe859553c976d5ab4", "title": "MNSIM: Simulation Platform for Memristor-Based Neuromorphic Computing System"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "401e226c0bde2ecc09e290050a8f2e6a15a19933", "title": "A fixed point exponential function accelerator for a neuromorphic many-core system"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "6b3c06f148deba3926eff3c22ddf4dfd1195ac8a", "title": "PipeLayer: A Pipelined ReRAM-Based Accelerator for Deep Learning"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "9071775ebcfebddd54d879fe7e6c627673e4d305", "title": "ISAAC: A Convolutional Neural Network Accelerator with In-Situ Analog Arithmetic in Crossbars"}, {"paperId": "fd5a2bd2e68e8ad5223ee1cf5c717ffcc4d0983c", "title": "Multilevel Cell Storage and Resistance Variability in Resistive Random Access Memory"}, {"paperId": "43e054ff899206aa9c820574750053252dc6e6b2", "title": "LUT Optimization In Implementation Of Combinational Karatsuba Ofman On Virtex-6 FPGA"}, {"paperId": "5a7e2b2b06a32edd03bab00d46988a4afbb48512", "title": "MNSIM: Simulation platform for memristor-based neuromorphic computing system"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "5a2b26a9c19906e0c742d5d2e453236a8be91e23", "title": "Skype Translator: Breaking down language and hearing barriers. A behind the scenes look at near real-time speech translation"}, {"paperId": "c32c76490c506722ede871dc3b92725908000bbd", "title": "Scaling with Design Constraints: Predicting the Future of Big Chips"}, {"paperId": "4cdde0eafec8bdbf043dd27686234bee57687aba", "title": "Hitting the memory wall: implications of the obvious"}, {"paperId": "35a8c483ed0641ebbb56da1bd2d0f188b000a8ca", "title": "RETROSPECTIVE:PRIME: A Novel Processing-in-memory Architecture for Neural Network Computation in ReRAM-based Main Memory"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "\u201cScale-sim: Systolic CNN accelerator simulator,\u201d"}, {"paperId": null, "title": "and the M.S. degree in electrical engineering from the Korea Advanced Institute of Science and Technology, Daejeon, South Korea"}, {"paperId": null, "title": "\u201cNvidia GPU\u2014Titan XP.\u201d"}, {"paperId": "18546138cc81939664e5615cda732ab3f06462ce", "title": "A real-world system for simultaneous translation of German lectures"}, {"paperId": null, "title": "FRAMEWORK FOR ACCELERATING TRANSFORMER-BASED LANGUAGE MODEL"}, {"paperId": null, "title": "High-Performance Computer Architecture and the Best Paper Award"}]}