{"paperId": "a0ed652bb0b65f8171c76654cb3ce03e0d907585", "title": "Towards Cheaper Inference in Deep Networks with Lower Bit-Width Accumulators", "abstract": "The majority of the research on the quantization of Deep Neural Networks (DNNs) is focused on reducing the precision of tensors visible by high-level frameworks (e.g., weights, activations, and gradients). However, current hardware still relies on high-accuracy core operations. Most significant is the operation of accumulating products. This high-precision accumulation operation is gradually becoming the main computational bottleneck. This is because, so far, the usage of low-precision accumulators led to a significant degradation in performance. In this work, we present a simple method to train and fine-tune high-end DNNs, to allow, for the first time, utilization of cheaper, $12$-bits accumulators, with no significant degradation in accuracy. Lastly, we show that as we decrease the accumulation precision further, using fine-grained gradient approximations can improve the DNN accuracy.", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work presents a simple method to train and fine-tune high-end DNNs, to allow, for the first time, utilization of cheaper, $12$-bits accumulators, with no significant degradation in accuracy."}, "embedding": {"model": "specter_v2", "vector": [-0.08365640789270401, 0.6148934364318848, -0.32437804341316223, -0.06522836536169052, 0.10755591839551926, 0.37539032101631165, 0.474643349647522, -0.1884511560201645, -0.8660755157470703, -0.18438473343849182, 0.6639019250869751, 0.33482012152671814, 0.5206223726272583, -0.16624587774276733, 0.04904007539153099, -0.24110117554664612, -1.2470186948776245, -0.3956905007362366, 0.26690614223480225, -0.31852594017982483, 0.02933196723461151, -0.13728442788124084, -1.2291269302368164, 0.1549990475177765, -0.2778949737548828, 1.850309133529663, -0.4176630973815918, 0.8715070486068726, -0.32991376519203186, 0.7625720500946045, 0.54683917760849, -0.8783133625984192, 0.8304694890975952, 0.23923256993293762, 0.021594615653157234, -0.25813034176826477, 0.6630403399467468, -1.0542258024215698, -0.28945809602737427, 1.3933098316192627, -0.2907000482082367, 0.26232144236564636, -0.04729914665222168, -0.5095586776733398, -0.06595901399850845, 0.8549821972846985, 0.5158593058586121, 0.6822343468666077, -0.8404196500778198, -0.3010256588459015, 0.9641830325126648, -1.142884373664856, 0.06560622155666351, 1.5182148218154907, 0.8886072039604187, 0.15006861090660095, -0.10675322264432907, -0.22561107575893402, 0.24959821999073029, 0.005909265018999577, -0.7469514012336731, -0.3272888958454132, 0.5605838894844055, -0.02138085477054119, 1.4220794439315796, -0.25902029871940613, -0.06244294345378876, 0.5812147259712219, 0.015818536281585693, 0.9826443195343018, 0.22976084053516388, -0.7225382924079895, 0.20731815695762634, -0.13992716372013092, 0.44262826442718506, 0.8525426387786865, 0.14631007611751556, 0.38296112418174744, -1.4663856029510498, 0.04577767476439476, 0.9747858643531799, 0.39393150806427, 0.40493044257164, -0.1913614124059677, -0.23978455364704132, 0.829824686050415, 0.7491520047187805, 0.2240857630968094, -0.971457302570343, 1.3652406930923462, 0.6796172857284546, -0.009716426022350788, -0.025799822062253952, -0.11727401614189148, -0.058744002133607864, 0.11204598098993301, -0.9478955864906311, -0.04741216450929642, -0.16917183995246887, 0.6375347971916199, 0.11876078695058823, 0.5816408395767212, -0.4431012272834778, 0.11218701303005219, 1.3602073192596436, -0.20632502436637878, 0.4100024104118347, -0.7992467880249023, 0.3479515612125397, -0.8429776430130005, -0.06494280695915222, -0.6918137669563293, -0.08854608982801437, -0.599527895450592, -1.335197925567627, -0.572248101234436, -0.4660019874572754, -0.1633445918560028, -0.9274075627326965, 0.4052679240703583, -0.37807631492614746, 0.27851244807243347, -0.054359227418899536, 1.0276986360549927, -0.2988281846046448, 0.5270262956619263, 0.18136581778526306, 0.19924487173557281, 1.1837470531463623, -0.7759559750556946, -0.4980349540710449, -0.5661786198616028, 0.08576588332653046, -0.0852556899189949, -0.21577246487140656, 0.09087628126144409, -1.567997694015503, -1.2203313112258911, -1.0835059881210327, -0.13504233956336975, -0.626456081867218, -0.0481494702398777, 1.3807852268218994, 0.5247179269790649, -1.424257516860962, 1.4113692045211792, -0.60939621925354, 0.2309584766626358, 0.8448442220687866, 0.23711822926998138, 0.6544287204742432, 0.3099481165409088, -0.7524538636207581, 0.18531690537929535, 0.38053107261657715, -0.01036895252764225, 0.1765688806772232, -0.644833505153656, -0.7526124119758606, 0.139179989695549, -0.20531490445137024, -0.7812561392784119, 1.1361581087112427, 0.2725948691368103, -1.4544955492019653, 0.34450897574424744, 0.24244831502437592, -0.38177797198295593, 0.2387416660785675, 0.06473630666732788, -0.4527444839477539, 0.20462165772914886, -0.6342113018035889, 0.9150050282478333, 0.8216739892959595, -0.13579756021499634, 0.09653010964393616, -0.4052709639072418, -0.20386826992034912, -0.6069244742393494, -0.7720738053321838, 0.8278205394744873, -0.3065338134765625, -0.7124174237251282, 0.8855078816413879, 0.7222615480422974, -0.3451633155345917, 0.20105107128620148, -0.28243789076805115, -0.8062708377838135, 0.3961411714553833, 0.3475944995880127, 0.6903193593025208, -0.8196620345115662, -1.25309157371521, 0.3809557855129242, 0.16575290262699127, 0.003345040837302804, -0.6563894152641296, -0.10775559395551682, -0.33573588728904724, 0.43349021673202515, 0.35825464129447937, -0.9934732913970947, 0.25151124596595764, -0.1558866798877716, -0.8753324747085571, -0.3133471608161926, 0.2807956039905548, 0.8715004324913025, -0.6982327103614807, 0.01479855366051197, -0.15079081058502197, 0.6198399066925049, -0.902351975440979, 0.7604658007621765, -0.1636524349451065, -0.4783764183521271, 0.37080416083335876, 0.00790991261601448, 0.3921985924243927, -0.35525885224342346, 0.345203161239624, -1.0720595121383667, -0.2497091144323349, 0.8564156889915466, -0.8695058822631836, 1.3815183639526367, 0.11124179512262344, 0.5152980089187622, 0.13129784166812897, -0.42173686623573303, 0.3622662127017975, 0.06085936352610588, -0.210113987326622, -0.4386311173439026, 0.48773321509361267, 0.3354218900203705, -0.6415666341781616, 0.8711673021316528, 1.2036354541778564, 0.991052508354187, -0.22860418260097504, -0.011539957486093044, 0.8321164846420288, -0.41640421748161316, 0.790844738483429, 0.17654307186603546, 0.08363310992717743, -0.08524781465530396, -0.13913770020008087, 0.02737514115869999, 0.04267873987555504, -1.1534132957458496, -0.008989434689283371, 0.655113160610199, 0.24480201303958893, 0.9160867929458618, 0.6531615257263184, -0.8294602036476135, -0.6254432797431946, 0.040599558502435684, 0.2775401473045349, 1.2489765882492065, -0.5000991821289062, 0.10935189574956894, -0.5476232767105103, -0.13928696513175964, -0.2861362397670746, -0.7879538536071777, 0.0686403140425682, 0.11332665383815765, -0.393789142370224, -1.3013266324996948, 1.0076580047607422, 0.6142421364784241, 1.3944189548492432, -0.06944083422422409, -0.4845908582210541, -0.3244040310382843, 1.0780503749847412, -0.6528577208518982, -0.17210686206817627, 0.5258738994598389, -1.1856797933578491, 0.2835826873779297, 0.011021329089999199, 0.20158976316452026, 0.18937447667121887, -1.1063847541809082, 0.7518854737281799, -0.34892600774765015, -0.05300166830420494, -0.5974783301353455, 0.8132046461105347, -0.6128057241439819, -0.08375275135040283, -0.23690342903137207, 0.09353882819414139, -0.22586797177791595, 0.29246944189071655, 0.1597767472267151, -0.4898523688316345, -0.43340998888015747, -0.5361922979354858, -0.2685532569885254, 0.1986025869846344, -0.10358905792236328, 0.7795370817184448, -0.444730281829834, 0.12833406031131744, -0.5753508806228638, 1.0611629486083984, 0.5200802087783813, -0.7250009775161743, -0.39419326186180115, -0.8331403136253357, 0.38200274109840393, 0.5216131806373596, -0.3196522295475006, -0.00529421865940094, -1.0597522258758545, -0.07312989979982376, -0.8289449214935303, -0.16478295624256134, -0.20171862840652466, 0.8052656650543213, -0.34777575731277466, 0.20707078278064728, -0.3134223520755768, 0.20905637741088867, -0.1437755674123764, 0.4899293780326843, -0.852230966091156, 0.8991993069648743, 0.11780763417482376, -0.19464027881622314, -0.050771716982126236, 0.4932979345321655, -0.27098652720451355, -0.35416048765182495, -0.23550541698932648, -0.2141820639371872, -0.35155150294303894, -0.0020276098512113094, -0.3594636917114258, -0.8169874548912048, 0.1794685274362564, -1.136997938156128, 0.05906085669994354, -0.22097568213939667, 0.1769450604915619, 0.0032657866831868887, -0.7969058752059937, -1.8918899297714233, -0.5690031051635742, -1.1299097537994385, -1.1462570428848267, 0.2830849587917328, 0.2665542662143707, -0.14453770220279694, -0.3675084412097931, -0.42936936020851135, -0.6906628012657166, 1.1454156637191772, -0.5865503549575806, 0.5038813948631287, 0.1040031760931015, -0.4731455445289612, -0.09993931651115417, -0.2768237888813019, 1.0256450176239014, -0.6718689799308777, 0.35830652713775635, -0.9357204437255859, 0.7869806885719299, -0.1459103673696518, -0.5085964798927307, 0.47432854771614075, 0.04604781046509743, 1.0362592935562134, -0.27660003304481506, 0.3794862926006317, 0.6513426303863525, 1.4210662841796875, -0.9467266201972961, 0.5282427668571472, -0.21092651784420013, 0.7286719083786011, -0.41361698508262634, -0.34721338748931885, 0.843565821647644, -0.2807363271713257, 0.019813893362879753, 0.5888990759849548, -0.1715427041053772, -0.6805471777915955, -0.28945547342300415, 0.06054547801613808, 1.7572638988494873, 0.16023634374141693, 0.34960830211639404, -0.4441007673740387, 0.3644426763057709, -0.8411313891410828, -0.7006821632385254, 0.502872884273529, 0.7091580033302307, 0.6077850461006165, 0.085280641913414, -0.5436848998069763, 0.3163726329803467, 0.2796001434326172, 0.8667889833450317, -0.19770176708698273, -1.19326913356781, 0.02776268683373928, 0.6456505060195923, 0.8708539605140686, 0.29625844955444336, -0.3077482581138611, 0.10578811168670654, 14.387118339538574, 0.3176352381706238, -0.5526106953620911, 0.14697086811065674, 0.8532022833824158, 0.2746870815753937, 0.07720072567462921, -0.2761264145374298, -1.5468175411224365, 0.4135499596595764, 1.2321134805679321, 1.037353515625, 0.23491360247135162, 0.5354970097541809, -0.04745405912399292, 0.1929979771375656, -0.532664954662323, 1.0606920719146729, 0.4087192118167877, -1.850704312324524, 0.3014134168624878, 0.06969194859266281, 0.6605296730995178, 0.5516077280044556, 0.7325714230537415, 0.490474134683609, 0.24127264320850372, 0.11218702793121338, 0.672330379486084, 0.6209308505058289, 0.8086408376693726, -0.1719728261232376, 0.9221104383468628, -0.05574376508593559, -0.44157874584198, 0.2934184670448303, -0.6783043146133423, -1.451136827468872, -0.24372360110282898, 0.8411787152290344, -0.6849180459976196, -0.684197187423706, 0.18686644732952118, 0.4436117112636566, 0.05599858611822128, 0.6289681792259216, -0.27511680126190186, 0.41208428144454956, -0.32005614042282104, -0.4276845157146454, 0.4094333052635193, -0.11809299141168594, -0.23492635786533356, -0.0023271976970136166, -0.06855684518814087, -0.3197314739227295, -0.14554531872272491, 0.6486175656318665, -1.0709127187728882, -0.7289174795150757, 0.29289498925209045, -0.16961853206157684, -0.21020692586898804, 1.0424480438232422, 0.38496237993240356, -0.2305605560541153, 0.056805286556482315, 0.4058762192726135, 0.6231187582015991, 0.0006231833249330521, -0.13820822536945343, -0.5219299793243408, 0.8635032773017883, -0.8979069590568542, 0.25414711236953735, 0.10812156647443771, -0.9668061137199402, -0.33303308486938477, -0.503563404083252, -0.16029928624629974, 0.37413671612739563, -1.109928011894226, -0.5861363410949707, 0.7063477039337158, -0.549631655216217, -0.1207040324807167, 0.16117608547210693, -1.6203064918518066, -0.08172313123941422, 0.42466461658477783, -1.4167335033416748, 0.16791486740112305, 0.10658273100852966, -0.3813651502132416, -0.5523291826248169, 0.33930790424346924, 1.0062847137451172, 0.4100700914859772, -0.6696129441261292, -0.08609376102685928, -0.23546616733074188, 0.24066412448883057, -0.3140055239200592, -0.718235433101654, 0.5771750211715698, 0.8084171414375305, -0.05946210399270058, 0.4905471205711365, -0.37802278995513916, 0.5932106375694275, -0.7596822381019592, -0.06434918195009232, 0.23126305639743805, -0.014112824574112892, 0.17533566057682037, -0.5160225629806519, -0.5658999085426331, 0.257796049118042, 0.38504165410995483, 0.3191644549369812, -0.07604621350765228, -0.13934335112571716, -0.5501176714897156, -0.6319609880447388, -0.6752709150314331, 0.3998507857322693, 0.17102959752082825, -0.8601949214935303, -0.09180977940559387, -0.3710332214832306, 0.00658287713304162, -1.0425931215286255, -1.1935068368911743, 0.19703896343708038, -0.09822743386030197, -0.5925849676132202, 1.5024796724319458, -0.38335272669792175, 0.8912721276283264, 0.6396733522415161, -0.17634069919586182, -0.3721871078014374, 0.2230328470468521, -0.7415408492088318, -0.3132030665874481, 0.16848322749137878, 0.24343407154083252, -0.3053697347640991, 0.6572311520576477, 1.001986026763916, -0.12878724932670593, -0.3931470513343811, -0.4192648231983185, 0.02884119562804699, -0.6543869972229004, -0.8701654076576233, 0.38691607117652893, -0.47658202052116394, -0.23119045794010162, -0.120899997651577, 0.7023515701293945, 0.6022792458534241, 0.1438933163881302, -0.6029149293899536, -0.3118058145046234, -0.031798649579286575, 0.17242684960365295, -0.8709186315536499, -1.2820391654968262, -1.7375192642211914, -0.38242509961128235, -0.9376402497291565, -0.2019244134426117, -0.6091693639755249, -0.9819558262825012, -0.08135605603456497, -0.5219404101371765, 0.0698062926530838, 0.531629741191864, 0.5088427066802979, -0.563041090965271, -0.3862406313419342, -0.5013672709465027, 0.5515099763870239, 0.5336996912956238, -0.3803853392601013, 0.3706035017967224, -0.41584739089012146, 0.2993040084838867, 0.7677121758460999, 0.500736653804779, -0.09193143248558044, -0.41563543677330017, -1.2856645584106445, 0.23350250720977783, -0.309203565120697, 0.29614242911338806, -1.1478067636489868, 0.9449763894081116, 0.7176865935325623, 0.3656209409236908, -0.6283585429191589, 0.5944597721099854, -0.7569512724876404, -0.6998786926269531, 0.49464333057403564, -0.6112723350524902, 0.07668486982584, 0.2885880768299103, -0.7082251906394958, -0.158269464969635, 0.30435046553611755, 0.12403746694326401, -0.41100743412971497, -1.3745428323745728, 0.3501216173171997, -0.07483553141355515, -0.23543138802051544, -0.6623753309249878, -0.24592842161655426, -1.3853347301483154, 0.28143060207366943, 0.07601818442344666, -0.22609756886959076, -0.4191353917121887, 0.2938774526119232, 0.6248393058776855, -1.07108736038208, 0.5296400785446167, 0.5615488886833191, -0.5761436223983765, -0.05652706325054169, 0.06261423975229263, 0.4774264991283417, -0.7561483979225159, 0.368183434009552, -0.12385836988687515, 0.0199190154671669, -0.36265867948532104, -0.14033767580986023, 0.6240838170051575, -0.4090357720851898, -0.09138141572475433, 1.3168390989303589, -1.1404865980148315, -0.34360483288764954, 0.35144609212875366, -2.0059049129486084, 0.003056504298001528, -0.17314085364341736, 0.686994731426239, 0.6450485587120056, 0.9692673087120056, 0.47135695815086365, -0.39256536960601807, -0.13395671546459198, -0.01394004374742508, -0.4800328016281128, 0.12049620598554611, 0.2162809818983078, -0.6238393783569336, 0.24509356915950775, 0.9984554052352905, -0.7403309345245361, -1.2208528518676758, -0.6664011478424072, -0.24869494140148163, -0.34456169605255127, 0.7403279542922974, -0.030471330508589745, -1.1607083082199097, 0.7771499156951904, 0.7999597787857056, 0.41359415650367737, 0.21721366047859192, -0.47029682993888855, 0.31691670417785645, 0.7286046743392944, 0.17324458062648773, -0.8511523604393005, -0.26206424832344055, 1.0118224620819092, 1.0616446733474731, -0.6248762607574463, 0.6106157302856445, -0.4715339243412018, -0.3374156653881073, 1.0744165182113647, 0.15964025259017944, -0.21767757833003998, 0.9140447378158569, 0.17257820069789886, -0.09252819418907166, 0.14684464037418365, -0.636695921421051, -0.2859402894973755, 0.6447721719741821, 0.8501777052879333, 0.6631757020950317, 0.05580409988760948, 0.18525294959545135, 1.0777451992034912, -0.2577217221260071, -0.0030224816873669624, 0.3424341380596161, 0.41286933422088623, -0.05973733961582184, 0.3292345404624939, -0.33182376623153687, 0.6353254914283752, -0.8305773138999939, -0.8910083770751953, 0.6249879002571106, 0.5321598052978516, 0.5440170168876648, 0.5348311066627502, 1.3723032474517822, 0.08402954041957855, 0.5016981363296509, 0.048904214054346085, 0.4650430679321289, 0.043898556381464005, -0.35602399706840515, -0.19657643139362335, -0.4516488015651703, -0.41102489829063416, -0.3228412866592407, -0.30978628993034363, -0.439464271068573, -0.42861297726631165, 0.48980578780174255, -0.36062389612197876, 1.0715051889419556, 0.31735047698020935, 0.5926820039749146, 0.9606297612190247, -0.1499631404876709, -0.7706060409545898, -0.9241666197776794, -0.8206239938735962, 0.08665473014116287, -0.21478170156478882, -0.23217011988162994, 0.1342252790927887, -0.190438374876976, -0.17849300801753998]}, "authors": [{"authorId": "2266390386", "name": "Yaniv Blumenfeld"}, {"authorId": "2477463", "name": "Itay Hubara"}, {"authorId": "2266392841", "name": "Daniel Soudry"}], "references": [{"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "32ac52069e562d4f900afee70bdca63f53461481", "title": "QLoRA: Efficient Finetuning of Quantized LLMs"}, {"paperId": "ae736662f64d56f3ab1894fbd9c45f8f37251843", "title": "OpenAssistant Conversations - Democratizing Large Language Model Alignment"}, {"paperId": "3f2a55671ea1993893143811c3aa0b23323c0a52", "title": "FP8 versus INT8 for efficient deep learning inference"}, {"paperId": "003c08471fe579d98e82cf5c0cac03897403fb55", "title": "FP8 Quantization: The Power of the Exponent"}, {"paperId": "7a7a4f41f9ca5682b1444140799ca4dde44352f5", "title": "Overcoming Oscillations in Quantization-Aware Training"}, {"paperId": "92b4ae3f83c4e28dae668c1698105f91d2c5185c", "title": "A 7nm 4-Core AI Chip with 25.6TFLOPS Hybrid FP8 Training, 102.4TOPS INT4 Inference and Workload-Aware Throttling"}, {"paperId": "949c0941d4c57482318afa28f2c8eb82569fb401", "title": "Pruning and Quantization for Deep Neural Network Acceleration: A Survey"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "0708626d48d23a85aceca9e58963332079ff55b8", "title": "WrapNet: Neural Net Inference with Ultra-Low-Resolution Arithmetic"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "76df2eba276123657d8ba72fe70ae83fb8a85e3a", "title": "QPyTorch: A Low-Precision Arithmetic Simulation Framework"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "e931f4444f634695bfab5a6e57c817da52fc512b", "title": "Accumulation Bit-Width Scaling For Ultra-Low Precision Training Of Deep Networks"}, {"paperId": "9a1093af92d315def21b90918faf08665157051a", "title": "Training Deep Neural Networks with 8-bit Floating Point Numbers"}, {"paperId": "fae2a5101789afd51c1ececb28c75537c88734ec", "title": "Scalable Methods for 8-bit Training of Neural Networks"}, {"paperId": "6baca6351dc55baac44f0416e74a7e0ba2bfd03e", "title": "Visualizing the Loss Landscape of Neural Nets"}, {"paperId": "d2e4147eecae6f914e9e1e9aece8fdd2eaed809f", "title": "Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "b7cf49e30355633af2db19f35189410c8515e91f", "title": "Deep Learning with Limited Numerical Precision"}, {"paperId": "62c76ca0b2790c34e85ba1cce09d47be317c7235", "title": "Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation"}, {"paperId": "9cabb9887efe4f5ef375ff364785579d501cea31", "title": "High-precision floating-point arithmetic in scientific computation"}, {"paperId": "5c179d447a27c40a54b2bf8b1b2d6819e63c1a69", "title": "The Accuracy of Floating Point Summation"}, {"paperId": "90747985e1d9d24c20e55a3b041b52627c629ef0", "title": "A floating-point technique for extending the available precision"}, {"paperId": "9fae65e8c1af810dbdecfd9a8c6302d1145c3666", "title": "Logarithmic Unbiased Quantization: Practical 4-bit Training in Deep Learning"}, {"paperId": "3c61e6b55597cf37b19d2e4b38fc66b9c85c97b9", "title": "Ultra-Low Precision 4-bit Training of Deep Neural Networks"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "e6cc6a7bd4db3e7604bae6a654ec29aa8542dafc", "title": "Hybrid 8-bit Floating Point (HFP8) Training and Inference for Deep Neural Networks"}, {"paperId": "28135fd3e80dda50a673cd556f10b9b972005d27", "title": "Binarized Neural Networks"}]}