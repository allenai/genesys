{"paperId": "260b9388c90b497218b591a9a0e2742b7e0951e5", "title": "Momentum Transformer: Closing the Performance Gap Between Self-attention and Its Linearization", "abstract": "Transformers have achieved remarkable success in sequence modeling and beyond but suffer from quadratic computational and memory complexities with respect to the length of the input sequence. Leveraging techniques include sparse and linear attention and hashing tricks; efficient transformers have been proposed to reduce the quadratic complexity of transformers but significantly degrade the accuracy. In response, we first interpret the linear attention and residual connections in computing the attention map as gradient descent steps. We then introduce momentum into these components and propose the \\emph{momentum transformer}, which utilizes momentum to improve the accuracy of linear transformers while maintaining linear memory and computational complexities. Furthermore, we develop an adaptive strategy to compute the momentum value for our model based on the optimal momentum for quadratic optimization. This adaptive momentum eliminates the need to search for the optimal momentum value and further enhances the performance of the momentum transformer. A range of experiments on both autoregressive and non-autoregressive tasks, including image generation and machine translation, demonstrate that the momentum transformer outperforms popular linear transformers in training efficiency and accuracy.", "venue": "Mathematical and Scientific Machine Learning", "year": 2022, "citationCount": 6, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2208.00579", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "The momentum transformer is proposed, which utilizes momentum to improve the accuracy of linear transformers while maintaining linear memory and computational complexities and an adaptive strategy to compute the momentum value for the model based on the optimal momentum for quadratic optimization is developed."}, "embedding": {"model": "specter_v2", "vector": [0.327093243598938, 0.7642649412155151, -0.3798682391643524, 0.1394483894109726, -0.06791549921035767, 0.05852634832262993, 0.736973226070404, -0.3118141293525696, -0.2017785608768463, -0.5018376111984253, 0.5776656866073608, 0.11189664155244827, 0.834659218788147, -0.022433524951338768, -0.4186801314353943, 0.03609523922204971, -0.7583512663841248, 0.25350409746170044, 0.12004885822534561, -0.2654198706150055, 0.09097301959991455, -0.7960086464881897, -1.203344464302063, 0.13143284618854523, 0.3485052287578583, 0.7447640895843506, 0.43691444396972656, 0.9194396734237671, -0.40888386964797974, 0.649540901184082, 0.5855768918991089, -0.4251641631126404, 0.3979533612728119, -0.4753779470920563, -0.5178021788597107, -0.021469365805387497, 0.5384669303894043, -0.17134132981300354, -0.3925037086009979, 0.8177441954612732, -0.133268803358078, 0.24600602686405182, 0.4266013503074646, -0.7645136117935181, -0.2870810925960541, 0.5994395613670349, 0.37021005153656006, 1.1674784421920776, -0.4702223539352417, -0.5877954959869385, 1.250382661819458, -1.4665100574493408, 0.07441599667072296, 1.3659415245056152, 0.5713229179382324, 0.28549668192863464, 0.0031821629963815212, -0.43548908829689026, 0.8328565359115601, 0.48135167360305786, -0.6715788841247559, -0.4547184705734253, 0.040741898119449615, -0.26029151678085327, 1.772781491279602, -0.41401758790016174, 0.3157210350036621, 0.4328412413597107, 0.2699858546257019, 1.4320297241210938, -0.1205131784081459, -0.8499705195426941, -0.2939768135547638, 0.017802804708480835, -0.09772281348705292, 1.066286563873291, -0.6969860196113586, 0.19690118730068207, -1.1858799457550049, 0.02515612356364727, 0.7010583281517029, -0.3451862335205078, 0.14527174830436707, -0.4452201724052429, -0.1155736893415451, 0.7643684148788452, 0.4416945278644562, 0.8000078201293945, -0.44494912028312683, 0.7767263650894165, 0.540775716304779, 0.010147200897336006, 0.17307746410369873, 0.22756893932819366, 0.1925317347049713, 0.08544806391000748, -0.9360082745552063, 0.10735145211219788, -0.08907358348369598, 1.0926563739776611, -0.1050720065832138, 0.5629420876502991, -0.6007208228111267, 0.15414875745773315, 1.2886652946472168, 0.0690935030579567, 0.887944221496582, -0.6093853116035461, 0.00678672781214118, -0.9512490630149841, -0.008955678902566433, -1.1176546812057495, 0.18628515303134918, -0.3194790184497833, -0.9928585290908813, -1.0207622051239014, -0.7940540313720703, 0.24429647624492645, -0.7850466370582581, 0.5952118039131165, -0.12796494364738464, 0.3915840685367584, -0.3584919273853302, 0.5373179316520691, 0.3096025586128235, 0.6237313151359558, 0.3005565404891968, 0.11774656176567078, 0.8983160853385925, -1.3194128274917603, -0.749937891960144, -1.1171637773513794, 0.10097897797822952, -0.3978556990623474, 0.28701719641685486, -0.388793408870697, -1.3901671171188354, -1.1888978481292725, -0.8045865297317505, 0.015438380651175976, -0.1147238090634346, 0.25584083795547485, 1.0468864440917969, 0.19995459914207458, -1.079444408416748, 0.9672665596008301, -0.47305330634117126, -0.26109886169433594, 0.48845577239990234, -0.053584638983011246, 0.3548083007335663, 0.040289219468832016, -1.1260260343551636, 0.49282726645469666, -0.04821530729532242, -0.41609466075897217, -0.22242535650730133, -0.675184965133667, -1.0040385723114014, 0.09794648736715317, 0.2764940559864044, -0.6402477622032166, 1.3778791427612305, -0.4399356544017792, -1.6042048931121826, 0.507922351360321, -0.6139951348304749, -0.2693329155445099, 0.1787719428539276, -0.6072978973388672, -0.10843636840581894, -0.3334670960903168, -0.09096714854240417, 0.6330986022949219, 0.8745777606964111, 0.19768309593200684, -0.3647055923938751, 0.3113926649093628, -0.581445574760437, 0.17128176987171173, -0.12906037271022797, 0.7318040132522583, -0.5669428706169128, -0.31495651602745056, 0.33275309205055237, 0.4105221927165985, 0.008138872683048248, -0.5725988745689392, -0.12767863273620605, -0.966494083404541, 0.7045281529426575, 0.00938221625983715, 0.7805587649345398, -0.7649624943733215, -0.5551685690879822, -0.35420578718185425, -0.2939540445804596, -0.30236315727233887, -0.817724347114563, 0.5246256589889526, -0.44754528999328613, 0.2541576325893402, 0.07618828117847443, -0.9896228909492493, -0.10281811654567719, -0.5542018413543701, -0.8211434483528137, -0.2001044750213623, 0.3790161609649658, 1.1847964525222778, -0.9028502106666565, -0.2641255259513855, -0.011643880046904087, 0.32156363129615784, -1.0209569931030273, 1.5108048915863037, -0.2928328216075897, 0.08253683149814606, 0.021004140377044678, -0.44579336047172546, -0.2308601289987564, -0.5696021318435669, 0.3228277266025543, -0.5403818488121033, 0.07114095985889435, 0.5827682614326477, -0.05077570304274559, 1.3274821043014526, -0.258293092250824, 0.6335726380348206, -0.5574305653572083, -0.7251503467559814, 0.29836681485176086, 0.4108317494392395, 0.06245165318250656, -0.5369008779525757, 0.2003929764032364, -0.03981281444430351, -0.7099311947822571, 0.33763155341148376, 0.8024144768714905, 0.8164955973625183, 0.06643623113632202, 0.16400262713432312, 0.6623102426528931, -0.32292771339416504, 0.0584707036614418, 0.6120438575744629, 0.6264023780822754, 0.5783146619796753, 0.5375478863716125, -0.03187515586614609, 0.2513538897037506, -0.8706397414207458, -0.034310150891542435, 0.6123090982437134, 0.5841111540794373, 1.1306248903274536, 0.17023704946041107, -0.7523283958435059, -0.6266531348228455, 0.0701514482498169, 1.0375878810882568, 1.577143669128418, -0.07363631576299667, -0.3759707510471344, -0.7708801031112671, -0.22122587263584137, -0.6024983525276184, -0.0033483407460153103, -0.41623273491859436, -0.46558839082717896, -0.406794935464859, -1.0141487121582031, 0.5228506326675415, 0.24857912957668304, 1.3661630153656006, -0.7015912532806396, -0.48271602392196655, -0.03160571679472923, 0.09888652712106705, -0.9080049991607666, -0.8928059935569763, -0.05539398267865181, -0.4436764717102051, -0.01594436727464199, 0.025138860568404198, 0.048384249210357666, -0.06475845724344254, -0.40957751870155334, 1.0194157361984253, -0.40253838896751404, -0.3364413380622864, 0.38970714807510376, 0.31857380270957947, -0.7939221858978271, -0.43855020403862, 0.4034428894519806, 0.14809100329875946, -0.03751073405146599, 0.15542569756507874, 0.15047289431095123, -0.15482716262340546, -0.02733667939901352, -0.013662290759384632, 0.25641781091690063, 0.29930636286735535, 0.013013205491006374, 0.6219107508659363, -0.18011870980262756, -0.15897029638290405, -0.9870779514312744, 0.5626212358474731, 0.22053706645965576, -0.15780678391456604, 0.0905555784702301, -0.6549466848373413, -0.4267733693122864, 0.09970475733280182, -0.6581069827079773, -0.2771588861942291, -0.6440525054931641, 0.26234862208366394, -0.4350902736186981, 0.016981545835733414, -0.025033799931406975, 0.4173697233200073, 0.01368697639554739, 0.12220921367406845, 0.7642533779144287, 0.5898497700691223, 0.005240911152213812, 0.6728402376174927, -1.2669926881790161, 0.7681943774223328, 0.39585429430007935, 0.1124550923705101, -0.16602973639965057, -0.18091323971748352, -0.5260006189346313, -0.8715370297431946, -0.38393381237983704, -0.23618356883525848, -0.46136921644210815, 0.2940978705883026, -0.6299251914024353, -0.9902064204216003, -0.05109657347202301, -0.9794582724571228, -0.2976780831813812, -0.07964002341032028, -0.30389630794525146, -0.6992461085319519, -0.8907504081726074, -1.0458698272705078, -0.6382330060005188, -0.9884787201881409, -0.8197277784347534, 0.27884241938591003, 0.06160057708621025, -0.33400699496269226, -0.3373928368091583, 0.07408609241247177, -0.5483078360557556, 1.2917969226837158, -0.9330482482910156, 0.49331095814704895, 0.1386745721101761, -0.5812103152275085, -0.028412776067852974, 0.35926443338394165, 0.5952357053756714, -0.0950578898191452, 0.013123192824423313, -0.755958080291748, 0.1362917572259903, -0.03691750764846802, -0.14429490268230438, 0.12554724514484406, 0.39122292399406433, 0.6197309494018555, -0.28473034501075745, -0.3970535695552826, 0.2782576382160187, 1.1712019443511963, -0.5205727219581604, 0.3006129562854767, 0.43021389842033386, 1.060001015663147, -0.05725909397006035, -0.0833556279540062, 0.5216678977012634, 0.5528151392936707, 0.43567782640457153, 0.22729358077049255, -0.17339597642421722, -0.23731327056884766, -0.7643344402313232, 0.5676095485687256, 1.9260574579238892, 0.10651547461748123, 0.11641047894954681, -0.8976617455482483, 0.5767815709114075, -1.2374473810195923, -1.2939937114715576, 0.8472425937652588, 0.642220675945282, 0.5109995603561401, -0.5081549286842346, 0.0827675461769104, -0.4846948981285095, 0.5679136514663696, 0.43108251690864563, -0.2646043002605438, -0.5526071786880493, 0.1341589242219925, 0.22990085184574127, 0.19360119104385376, 0.666359007358551, -0.512228786945343, 0.8560023307800293, 15.107033729553223, 0.5997476577758789, -0.2799055278301239, 0.7719354629516602, 0.7197847962379456, 0.23659439384937286, -0.013537239283323288, -0.16227658092975616, -1.0974351167678833, 0.03251524642109871, 0.9793057441711426, -0.25926610827445984, 0.43884214758872986, 0.5109261870384216, -0.157509446144104, 0.329634428024292, -0.3705042898654938, 0.7569376826286316, 0.732460618019104, -1.379530668258667, 0.5709124803543091, 0.08861295878887177, 0.1991918385028839, 0.4473559260368347, 0.8298665285110474, 0.7357863783836365, 0.4383445084095001, -0.2927168607711792, 0.5560690760612488, 0.3778132498264313, 0.792758584022522, 0.1510671228170395, 0.21522217988967896, 0.413533478975296, -0.8910951018333435, 0.06682124733924866, -0.7309665679931641, -1.174475073814392, 0.5620312690734863, 0.18342076241970062, -0.706927478313446, -0.3242013454437256, 0.103534996509552, 0.7854171395301819, 0.05122612789273262, 0.5913715362548828, -0.21700544655323029, 0.90455162525177, 0.17027750611305237, 0.20095592737197876, 0.22104746103286743, 0.3794758915901184, 0.2548213601112366, 0.18652386963367462, 0.36238497495651245, 0.24530336260795593, 0.05872800201177597, 0.11225588619709015, -0.24625547230243683, -0.00866550300270319, -0.11811283230781555, -0.17523512244224548, -0.12080986797809601, 0.7334562540054321, 0.5678156614303589, 0.042109403759241104, -0.11175159364938736, 0.365652471780777, 0.5641745328903198, -0.05652950331568718, -0.5195473432540894, 0.09191963076591492, 0.131987065076828, -0.3382577896118164, 0.436278373003006, 0.43382352590560913, -0.16688288748264313, -0.49884146451950073, -0.9024430513381958, -0.5838847756385803, 0.17860934138298035, -1.070188045501709, -0.6556581258773804, 1.0286296606063843, -0.4451853036880493, -0.23368780314922333, 0.1960100382566452, -0.14663076400756836, -0.18499405682086945, 0.2899666726589203, -1.052242636680603, -0.37680238485336304, 0.045821867883205414, -0.54299396276474, -0.10705625265836716, -0.1456574946641922, 0.9932264089584351, -0.008561414666473866, -0.016900964081287384, 0.1335657238960266, -0.3803316354751587, -0.2900644540786743, -0.3258843719959259, -0.7445400953292847, 1.0962611436843872, 0.3206268548965454, 0.02592991478741169, 0.2130955159664154, 0.3366241455078125, 0.14611901342868805, -0.7729539275169373, -0.052539438009262085, 0.6665447354316711, -0.8310601115226746, -0.30243822932243347, -0.6809255480766296, -1.055298089981079, 0.33313363790512085, 0.7881032228469849, -0.3958601653575897, -0.04619056358933449, 0.07638058811426163, -0.48102492094039917, -0.2260863035917282, -0.3986554741859436, -0.0129811130464077, 0.5874564051628113, -0.8129408359527588, -0.4983639717102051, 0.03488866239786148, 0.5498335957527161, -1.0944546461105347, -0.24108141660690308, -0.1646665632724762, 0.1419239640235901, -0.3879171907901764, 0.9801939725875854, -0.29705971479415894, 0.6740123629570007, 0.8783355355262756, 0.23134435713291168, -0.7789251208305359, -0.5575146675109863, -1.0965036153793335, 0.123336061835289, 0.4488421380519867, 0.3056754469871521, -0.3377078175544739, 0.4210769236087799, 0.5432206988334656, 0.28903818130493164, -0.4659557044506073, -0.6479671001434326, -0.2381036877632141, -0.254679799079895, -0.40787622332572937, 0.2808076739311218, -0.21927273273468018, -0.12839244306087494, 0.28773775696754456, 0.11895927786827087, 0.39532333612442017, -0.14214776456356049, -0.7190089225769043, 0.4466373026371002, 0.2615107297897339, 0.07888448238372803, -0.5027602910995483, -0.6837700009346008, -1.506025791168213, -0.14242683351039886, -0.9643955826759338, 0.21375875174999237, -0.8748165965080261, -0.22687457501888275, 0.08165848255157471, -0.35663530230522156, 0.0551057904958725, 0.16681955754756927, -0.22896808385849, -0.1671612411737442, -0.34862229228019714, -0.6669606566429138, 1.1162235736846924, 0.88345867395401, -0.6536219120025635, 0.11576205492019653, -0.014841316267848015, 0.008067185059189796, 0.22924835979938507, 0.555036187171936, -0.5114268064498901, -0.7172234058380127, -1.1074713468551636, 0.26958319544792175, -0.10896632820367813, -0.027623934671282768, -0.9386292695999146, 0.8845363259315491, 0.41924336552619934, -0.09194233268499374, -0.21966688334941864, 0.4161202609539032, -0.7727450132369995, -0.2247151881456375, 0.26477301120758057, -0.8417542576789856, 0.5768001675605774, 0.10807882249355316, -0.5593364238739014, -0.29208940267562866, 0.8230478167533875, 0.01720990054309368, -1.1877882480621338, -0.6330485939979553, 0.5013286471366882, -0.6060968637466431, 0.29318737983703613, -0.42062944173812866, 0.00987185351550579, -1.094087839126587, -0.610901951789856, -0.0035203273873776197, -0.04230337217450142, -0.32428693771362305, 1.0886006355285645, 0.4627246558666229, -1.2260524034500122, 0.246817484498024, 0.2659732699394226, -0.35199564695358276, -0.1524677276611328, 0.7218394875526428, 0.4367642402648926, 0.0489719994366169, 0.3857811689376831, 0.1027841791510582, 0.18577934801578522, -0.7128273248672485, 0.14007747173309326, 0.8077182769775391, -0.2647744119167328, -0.36424535512924194, 1.1161020994186401, -0.2456669956445694, -0.7259308099746704, -0.05965827405452728, -0.62946617603302, -0.5223919749259949, -0.37971001863479614, 0.5994721055030823, 0.14572536945343018, -0.33203062415122986, -0.23502270877361298, -0.5779416561126709, 0.2137083113193512, -0.2344503253698349, -0.7667759656906128, 0.4732838273048401, -0.3284790813922882, -0.4424929916858673, 0.8196321725845337, 0.6733319759368896, -0.7131897807121277, -0.7551835179328918, -0.779523491859436, -0.4563792943954468, -0.4010221064090729, 0.18000592291355133, -0.24252423644065857, -0.6802045702934265, 0.9032233953475952, 0.6859492659568787, 0.3150388300418854, 0.10722929239273071, -0.09847044199705124, 0.1566770225763321, 0.3509165942668915, -0.06550799310207367, -0.41488778591156006, -0.20479199290275574, 1.4352091550827026, 1.461716651916504, -0.4995369613170624, 0.4150649309158325, -0.4217367172241211, -1.0129650831222534, 0.5425751805305481, 0.4949604272842407, -0.2577704191207886, 0.7390372157096863, -0.4270898103713989, 0.13165822625160217, 0.19231672585010529, -1.2184494733810425, -0.23084324598312378, 1.0940496921539307, 1.110539436340332, 0.583005428314209, -0.13419289886951447, 0.30127206444740295, 0.41610193252563477, -0.22914274036884308, 0.3961891233921051, 0.44539520144462585, 0.262949138879776, -0.3003464937210083, 0.2802540361881256, 0.2474128007888794, 0.6950555443763733, -0.6794061064720154, -0.6579314470291138, 0.4683457612991333, 0.3612786531448364, -0.028445079922676086, 0.1863422989845276, 1.0425584316253662, 0.029225675389170647, 0.42418086528778076, 0.1220538541674614, 0.5320667028427124, -0.4832019507884979, -0.1881057322025299, -0.1628957986831665, -0.9650505185127258, -0.297493040561676, -0.3759377598762512, -0.8880870938301086, -0.08142589032649994, 0.04857102036476135, 0.2040230929851532, 0.2285093069076538, 0.36886659264564514, 0.9254467487335205, 0.9644519686698914, 0.5229306221008301, -0.15505555272102356, -0.7794102430343628, -0.2458232194185257, -0.8895989656448364, 0.3805357813835144, -0.48176267743110657, -0.32912570238113403, -0.225497305393219, -0.07124013453722, 0.12675896286964417]}, "authors": [{"authorId": "150322732", "name": "T. Nguyen"}, {"authorId": "144908066", "name": "Richard Baraniuk"}, {"authorId": "152534535", "name": "Robert M. Kirby"}, {"authorId": "103583159", "name": "S. Osher"}, {"authorId": "70994653", "name": "Bao Wang"}], "references": [{"paperId": "b16e208978328629e04595df825f5f6251025e2d", "title": "Training Deep Neural Networks with Adaptive Momentum Inspired by the Quadratic Optimization"}, {"paperId": "c4d8e0e72ae5bf2394041d0188f35755d6ea7456", "title": "How does momentum benefit deep neural networks architecture design? A few case studies"}, {"paperId": "4c1d1114a15b501a90924653d263dd2222aa127e", "title": "Heavy Ball Neural Ordinary Differential Equations"}, {"paperId": "37abe53ed31caa23ae833b2e67bb4aa1892e8d25", "title": "FMMformer: Efficient and Flexible Transformer via Decomposed Near-field and Far-field Attention"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "372cce47fa16c538946972e6a7ac8420e64000b0", "title": "Challenges in Information-Seeking QA: Unanswerable Questions and Paragraph Retrieval"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "cd4ffe5e014601a3d6b64121355d29a730591490", "title": "Fast Transformers with Clustered Attention"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "a32ed7f632e087c92ecd8f7a1080cba23aa6ea99", "title": "Implicit Kernel Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "1c7e57ac925953dd1e48b5d175726ccf7b4f42f2", "title": "MomentumRNN: Integrating Momentum into Recurrent Neural Networks"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "a238109c3969ae681eee0d4f1bf2012f28850593", "title": "Synthesizer: Rethinking Self-Attention in Transformer Models"}, {"paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d", "title": "ETC: Encoding Long and Structured Inputs in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "177fa110bdb2d4dc12a958be4f1cd78a6cfd750e", "title": "Scheduled Restart Momentum for Accelerated Stochastic Gradient Descent"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "42b0d32a7e644b657e34ce056c84d215d9f62187", "title": "Universal"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "add2f205338d70e10ce5e686df4a690e2851bdfc", "title": "Momentum Contrast for Unsupervised Visual Representation Learning"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "8cef9900c04d7f661c08f4b5b1ed4337ace042a3", "title": "Transformer Dissection: An Unified Understanding for Transformer\u2019s Attention via the Lens of Kernel"}, {"paperId": "2a687609ac1cecb9b20ba52d4f5d72ba14e0eaf2", "title": "Sampled Softmax with Random Fourier Features"}, {"paperId": "830995ef17cc291c13f42dfd9f462137de1d2179", "title": "Augmenting Self-attention with Persistent Memory"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "16c844fd4d97f3c6eb38b0d6527c87d184efedc3", "title": "The Evolved Transformer"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "5f4a22ee70ca613d9c0630eafc96364fe365fdf8", "title": "Efficient Attention: Attention with Linear Complexities"}, {"paperId": "9634946080bcc7c5b5e8cf09aa5e79d5d8751dcc", "title": "Optimization Algorithm Inspired Deep Neural Network Structure Design"}, {"paperId": "fb507ada871d1e8c29e376dbf7b7879689aa89f9", "title": "Music Transformer: Generating Music with Long-Term Structure"}, {"paperId": "b9de9599d7241459db9213b5cdd7059696f5ef8d", "title": "Character-Level Language Modeling with Deeper Self-Attention"}, {"paperId": "9c5c89199114858eafbe50b46d77d38ffd03b28a", "title": "Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "1e077413b25c4d34945cc2707e17e46ed4fe784a", "title": "Universal Language Model Fine-tuning for Text Classification"}, {"paperId": "1bf64f0961da08ea0f9941bd899e916a385e9540", "title": "Adaptive Sampled Softmax with Kernel Based Sampling"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "170d74a6f55d737c7348c888266af7a3bee3a780", "title": "Understanding the Learned Iterative Soft Thresholding Algorithm with matrix factorization"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "3e8ccf9d3d843c9855c5d76ab66d3e775384da72", "title": "Why Momentum Really Works"}, {"paperId": "13d9323a8716131911bfda048a40e2cde1a76a46", "title": "Structured Attention Networks"}, {"paperId": "2e77b99e8bd10b9e4551a780c0bde9dd10fdbe9b", "title": "PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications"}, {"paperId": "59b3ebd49ef620b3051d9777dfc59076d846949f", "title": "A Conceptual Introduction to Hamiltonian Monte Carlo"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "9a471f962b3b2cbac5e84e876cd11f4921f339ec", "title": "Stochastic Gradient Hamiltonian Monte Carlo"}, {"paperId": "aa7bfd2304201afbb19971ebde87b17e40242e91", "title": "On the importance of initialization and momentum in deep learning"}, {"paperId": "b716f735fb9b229c8227495e596e2d52f2981c33", "title": "Perfection within Reach: Exact MCMC Sampling"}, {"paperId": "4ee2eab4c298c1824a9fb8799ad8eed21be38d21", "title": "Moses: Open Source Toolkit for Statistical Machine Translation"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "75f063c9b32912f4b1b1f08dbcf6b0575ce16bf1", "title": "Hybrid Monte Carlo"}, {"paperId": "99bb7bf9cb5fc4ac6e6d0d6185afb5c9ca7de4bd", "title": "Optimal methods of smooth convex minimization"}, {"paperId": "2ff74d426e712522030057624510c03713fa77ba", "title": "Linear Transformers Are Secretly Fast Weight Memory Systems"}, {"paperId": "850d753aed56ed1a0facc3e87734aa1dfd197e82", "title": "DALL-E: CREATING IMAGES FROM TEXT"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Set transformer: A framework for attention-based permutation-invariant neural networks"}, {"paperId": "b0b36cd24cbb45bc11140def9245af79c313e609", "title": "Open Source Toolkit for Statistical Machine Translation: Factored Translation Models and Lattice Decoding"}, {"paperId": "8d3a318b62d2e970122da35b2a2e70a5d12cc16f", "title": "A method for solving the convex programming problem with convergence rate O(1/k^2)"}, {"paperId": "4b53e3f719ff983eef867c6d8deac5dbe38aecb4", "title": "Some methods of speeding up the convergence of iteration methods"}]}