{"paperId": "d931f84abfc4550c10ceb113b142c8eb3e07571e", "title": "Curriculum Learning: A Regularization Method for Efficient and Stable Billion-Scale GPT Model Pre-Training", "abstract": "Recent works have demonstrated great success in training large autoregressive language models (e.g., GPT-3) on unlabeled text corpus for text generation. To reduce their expensive training cost, practitioners attempt to increase the batch sizes and learning rates. However, increasing them often cause training instabilities and poor generalization. On the other side, using smaller batch sizes or learning rates would reduce the training ef\ufb01ciency, signi\ufb01cantly increasing training time and cost. We investigate this stability-ef\ufb01ciency dilemma and identify that long sequence length is one of the main causes of training instability in large-scale GPT model pre-training. Based on our analysis, we present a novel sequence length warmup method that simultaneously improves training stability and ef\ufb01ciency. As a kind of curriculum learning approach, our method improves the training convergence speed of autoregressive models. More importantly, our in-depth analysis shows that our method exerts a gradient variance reduction effect and regular-izes early stages of training where the amount of training data is much smaller than the model capacity. This enables stable training with much larger batch sizes and learning rates, further improving the training speed. Evaluations show that our approach enables stable GPT-2 (117M and 1.5B) pre-training with 8x larger batch size and 4x larger learning rate, whereas the baseline approach struggles with training instability. To achieve the same or better zero-shot WikiText-103/LAMBADA evaluation results, our approach reduces the required number of pre-training to-kens and wall clock time by up to 55% and 73%, respectively.", "venue": "arXiv.org", "year": 2021, "citationCount": 25, "influentialCitationCount": 3, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work presents a novel sequence length warmup method that simultaneously improves training stability and ef\ufb01ciency and improves the training convergence speed of autoregressive models."}, "embedding": {"model": "specter_v2", "vector": [0.09323230385780334, 0.6410982608795166, 0.055589135736227036, -0.01229814812541008, -0.1796960085630417, -0.2721498906612396, 0.48576727509498596, -0.4421375095844269, -0.10076718032360077, -0.4231683015823364, 0.34413641691207886, -0.337159126996994, 0.579474151134491, -0.07801970839500427, -0.31084874272346497, -0.3458545207977295, -1.0193884372711182, 0.39669492840766907, -0.2685224115848541, -0.49996325373649597, -0.4147436022758484, -1.0255334377288818, -1.1020773649215698, -0.14108462631702423, 0.4599747359752655, 0.3909248411655426, 0.1532062292098999, 0.8072481751441956, -0.6348116397857666, 0.19494342803955078, 0.3021726906299591, -0.3982997536659241, 0.5192111730575562, -0.2591336965560913, -0.3597928583621979, 0.41245928406715393, 0.3295225501060486, 0.007953297346830368, -0.20477114617824554, 0.6055586338043213, -0.12069854140281677, 0.48345598578453064, 0.1846095323562622, -0.5828539729118347, -0.41514652967453003, 0.666084885597229, 0.24346022307872772, 0.5474730134010315, -0.5308235883712769, -0.3735181987285614, 0.9722465872764587, -1.0371618270874023, 0.2167654037475586, 1.3607386350631714, 0.7504942417144775, 0.6573380827903748, -0.22888940572738647, -0.7267904281616211, 1.071415901184082, -0.4281497895717621, -0.4289911091327667, 0.06977429240942001, 0.11687276512384415, -0.4193613827228546, 1.7154600620269775, -0.4907781183719635, 0.2835943400859833, 1.136614441871643, 0.04926425963640213, 0.983024537563324, -0.29067644476890564, -0.719840943813324, -0.14019687473773956, 0.11881068348884583, 0.1094660833477974, 0.8337512016296387, -0.6021575331687927, 0.44149619340896606, -0.6927098035812378, -0.029099764302372932, 0.4240325391292572, -0.5066556930541992, 0.14840790629386902, 0.13082848489284515, 0.4209462106227875, 1.0948742628097534, 0.08330559730529785, 0.6007972359657288, -0.19415055215358734, 0.743340253829956, 0.605314314365387, 0.5747625231742859, 0.47974252700805664, 0.32327404618263245, -0.09772218763828278, 0.3597185015678406, -0.5956598520278931, 0.3246932029724121, -0.14278678596019745, 0.9907488822937012, -0.2084304839372635, 0.8426446914672852, -0.823314905166626, 0.4517171382904053, 1.3033100366592407, -0.15756931900978088, 0.9289994239807129, -0.6568886637687683, 0.541434109210968, -0.7015697360038757, -0.042111556977033615, -0.6815478801727295, -0.12213575094938278, -0.34645193815231323, -1.0810500383377075, -1.298235297203064, -0.34678176045417786, -0.4568530023097992, -1.1241581439971924, 0.9717350602149963, 0.06902027875185013, 0.3897636830806732, 0.2677786946296692, 0.5172422528266907, 0.3436005413532257, 1.1258583068847656, 0.40748077630996704, -0.000740724615752697, 0.7363408207893372, -0.9439709782600403, -0.5088746547698975, -1.1424983739852905, 0.7789685130119324, -0.037117261439561844, 0.36432600021362305, -0.30407437682151794, -1.3742421865463257, -0.9477327466011047, -0.7094852924346924, 0.3648808002471924, -0.29796668887138367, 0.2086845338344574, 1.2431601285934448, 0.8050220608711243, -0.8096984028816223, 0.7267342805862427, -0.1250917911529541, -0.15196211636066437, 0.24509909749031067, -0.05223623663187027, 0.35515549778938293, -0.20793598890304565, -1.4142491817474365, 0.16419628262519836, 0.1448371410369873, -0.288053035736084, -0.0808391198515892, -0.9655632376670837, -0.9747427701950073, -0.0716538205742836, 0.3176041841506958, -0.62444669008255, 1.4378927946090698, -0.26086360216140747, -1.8630350828170776, 0.5336290597915649, -0.08754047751426697, -0.08283862471580505, 0.3568655848503113, 0.0887356698513031, -0.34141403436660767, -0.6849291324615479, -0.26792800426483154, 0.5313176512718201, 0.5824921727180481, 0.12822507321834564, 0.009200646542012691, 0.28232407569885254, -0.4120376408100128, -0.08230394124984741, -0.2229732722043991, 0.6904038190841675, -0.4778023064136505, -0.25304731726646423, 0.40737101435661316, 0.3983391523361206, -0.5821041464805603, -0.7880338430404663, -0.03180042654275894, -1.2401920557022095, 0.4811555743217468, -0.015891319140791893, 0.9026631116867065, -0.7736994028091431, -0.7243438959121704, -0.12485559284687042, -0.4818539619445801, -0.07861659675836563, -1.0504049062728882, 0.7012573480606079, -0.38727858662605286, 0.5426033139228821, -0.0412667877972126, -1.256268858909607, 0.05465896800160408, -0.19963295757770538, -1.0260878801345825, -0.48726361989974976, 0.4316626191139221, 0.7519882321357727, -0.912144124507904, 0.11612646281719208, -0.09553807228803635, 0.31321999430656433, -1.1200470924377441, 1.06793212890625, -0.6034497618675232, 0.4505082368850708, -0.11405172199010849, -0.3936646580696106, 0.015887785702943802, -0.3212661147117615, 0.41665568947792053, 0.2669413387775421, -0.018215002492070198, 0.3649525046348572, -0.6296103596687317, 1.3512250185012817, -0.41748225688934326, 0.33148109912872314, -0.17430181801319122, -0.6413397192955017, 0.5707767605781555, 0.7455102801322937, 0.11056413501501083, -0.36099475622177124, 0.2841685116291046, 0.3545275330543518, -0.7401291728019714, 0.2540183663368225, 0.8821943998336792, 0.6900214552879333, -0.48124364018440247, 0.00730971759185195, 0.7036100625991821, -0.35945916175842285, 1.012235164642334, 0.11473461240530014, 0.4845503270626068, 0.32796165347099304, -0.24005241692066193, -0.04899376630783081, 0.2037011682987213, -0.8237186670303345, 0.3058355152606964, 0.5796538591384888, 0.8239510655403137, 0.7722064852714539, 0.44713932275772095, -0.7918243408203125, -0.4024731516838074, 0.17777088284492493, 0.8895615339279175, 1.6192702054977417, -0.6701973080635071, -0.2531833052635193, -0.587547242641449, -0.03736478462815285, -0.43440353870391846, 0.060809530317783356, -0.3118751645088196, -0.0033706563990563154, -0.6642552614212036, -1.3832628726959229, 0.5182282328605652, -0.08450008928775787, 0.7479068040847778, -0.4921708405017853, -0.19874092936515808, -0.13547426462173462, 0.3888380825519562, -0.7419140338897705, -0.3969535529613495, 0.18853387236595154, -0.6982102394104004, 0.19997473061084747, -0.327990859746933, -0.14334096014499664, 0.1722869724035263, -0.6584168672561646, 0.8959630727767944, -0.34088602662086487, -0.05559975653886795, 0.16619886457920074, 0.4011308550834656, -0.8675505518913269, -0.8469690680503845, 0.4144831597805023, 0.08886073529720306, -0.4476710855960846, 0.04335907846689224, 0.17848964035511017, 0.27895382046699524, -0.022594362497329712, -0.05940099060535431, 0.20649798214435577, -0.054571524262428284, 0.04428402706980705, 0.5212108492851257, -0.014416337944567204, -0.0643773227930069, -1.2186847925186157, 1.2533652782440186, 0.17987236380577087, -1.0795981884002686, 0.2450082004070282, -0.6406253576278687, -0.4722370207309723, 0.4926726222038269, -0.9545566439628601, -0.399819552898407, -0.961315929889679, 0.19675388932228088, -0.2842293977737427, 0.007389947306364775, 0.39439958333969116, 0.8484860062599182, 0.2402125895023346, 0.334735631942749, 0.283110648393631, 0.2312757819890976, 0.0008319601183757186, 0.6216995120048523, -1.3316423892974854, 0.2557006776332855, 0.008205235935747623, 0.306203693151474, -0.5307008624076843, -0.11714868992567062, -0.6172486543655396, -0.7135353684425354, -0.09083139151334763, 0.02559870481491089, -0.3593434691429138, 0.012175210751593113, -0.7608454823493958, -0.676286518573761, 0.018015585839748383, -0.8678927421569824, -0.5578948855400085, -0.15391282737255096, -0.28841644525527954, -0.15473856031894684, -1.126135230064392, -1.2886358499526978, -0.7560501098632812, -0.9565004110336304, -0.9026951789855957, 0.551442563533783, 0.16125239431858063, -0.24955284595489502, -0.6453394293785095, 0.4754562973976135, -0.6680382490158081, 0.9631792902946472, -0.656744122505188, 0.6781507134437561, 0.3190809488296509, -0.055823251605033875, -0.16930432617664337, 0.650035560131073, 0.39702123403549194, -0.5643147826194763, 0.5208597183227539, -0.811458945274353, 0.08007719367742538, -0.26164302229881287, -0.5827819108963013, 0.13188165426254272, 0.5959497690200806, 0.5324053764343262, 0.10766774415969849, -0.21965540945529938, 0.4067498445510864, 1.2746350765228271, -0.6137793660163879, 0.17783929407596588, 0.008101660758256912, 0.8073725700378418, 0.4697735607624054, -0.3784792423248291, 0.44344961643218994, 0.1105143204331398, 0.2586795687675476, -0.16314075887203217, -0.040048401802778244, 0.25685322284698486, -0.6107737421989441, 0.4127432703971863, 2.041368007659912, 0.27637556195259094, -0.21501092612743378, -0.9681878089904785, 0.5765154361724854, -1.2824581861495972, -0.7051728963851929, 0.369179904460907, 0.6989115476608276, 0.5912487506866455, -0.5133041739463806, -0.31055939197540283, -0.3383379280567169, 0.43555471301078796, 0.4100561738014221, 0.06371157616376877, -0.8255119323730469, 0.18481004238128662, 0.3918198049068451, 0.018802518025040627, 0.5383905172348022, -0.24615751206874847, 0.751674234867096, 14.819424629211426, 0.7834064364433289, -0.060252681374549866, 0.5109030604362488, 0.6917628645896912, 0.33296191692352295, -0.1626136153936386, -0.28796935081481934, -1.2716374397277832, 0.017009301111102104, 1.346167802810669, -0.08035808801651001, 0.5195366144180298, 0.36702778935432434, 0.11174187809228897, 0.21529321372509003, 0.03909553587436676, 0.35060015320777893, 0.1615929901599884, -1.3202235698699951, 0.4220542311668396, 0.11841073632240295, 0.9263650178909302, 0.6258825063705444, 0.7859236598014832, 1.3343372344970703, 0.8248255848884583, -0.09015843272209167, 0.3172907829284668, 0.05102263763546944, 0.35831987857818604, -0.07183603942394257, 0.4199444651603699, 0.35470259189605713, -0.8100332617759705, -0.15293806791305542, -0.9407864809036255, -1.0466777086257935, 0.48779526352882385, 0.226431205868721, -0.49877476692199707, -0.20948202908039093, -0.1801362931728363, 0.42025578022003174, -0.05906037613749504, 0.4242875277996063, -0.37062180042266846, 0.9599902033805847, -0.21317079663276672, 0.12339406460523605, 0.5945472121238708, -0.2520144581794739, 0.06883233040571213, -0.22471767663955688, 0.6875139474868774, -0.08653312921524048, 0.2783448100090027, 0.3841853439807892, -0.5243349671363831, 0.03572222962975502, -0.36550402641296387, -0.41400301456451416, -0.11903326213359833, 0.7650102376937866, 0.5841432809829712, 0.2569591999053955, -0.22126631438732147, -0.04094301909208298, 0.8314127326011658, 0.27326592803001404, -0.3808395266532898, 0.2893024981021881, 0.21746063232421875, -0.7640669345855713, 0.017325857654213905, 0.3614700436592102, -0.17408202588558197, -0.38457196950912476, -0.5723907351493835, -0.455243855714798, 0.25329020619392395, -0.9423036575317383, -0.7634428143501282, 0.9183626770973206, -0.308309406042099, -0.22390860319137573, -0.15576815605163574, -0.5498341917991638, -0.6512919068336487, 0.619662344455719, -1.1434478759765625, -0.6473283767700195, 0.3229169547557831, -0.5460308790206909, -0.17877604067325592, -0.27860063314437866, 1.4120532274246216, -0.005216789897531271, -1.0762085914611816, -0.06257720291614532, 0.22761252522468567, -0.22906191647052765, -0.42995402216911316, -0.7147196531295776, 1.296064019203186, 0.5250204801559448, -0.10648399591445923, 0.0931638553738594, 0.17904780805110931, 0.13742387294769287, -0.738271951675415, -0.42374905943870544, 0.6284077763557434, -0.8475537896156311, -0.1468323916196823, -0.9500313401222229, -1.0241332054138184, 0.3049095571041107, 0.5853371620178223, -0.7549289464950562, 0.17304059863090515, 0.7308996319770813, -0.3708772361278534, -0.13159538805484772, -0.36296361684799194, 0.39507293701171875, 0.32664692401885986, -0.36567407846450806, -0.13402745127677917, 0.26436105370521545, 0.7453070282936096, -1.4367328882217407, -0.5374736785888672, -0.2625240981578827, -0.16515976190567017, 0.1375824213027954, 0.8516325354576111, -0.2720556855201721, 0.6242014169692993, 1.2714390754699707, 0.46992912888526917, -0.9588431715965271, -0.15715059638023376, -1.1979249715805054, 0.47445568442344666, 0.5159648656845093, 0.6674863696098328, -0.430297315120697, 0.5426371693611145, 0.9579324722290039, 0.07467302680015564, -0.29033562541007996, -0.6265835762023926, -0.45140907168388367, 0.29585394263267517, -0.6113600730895996, 0.3003012239933014, 0.012105854228138924, -0.10110479593276978, 0.35054725408554077, 0.10898074507713318, 0.7124621868133545, -0.5264641642570496, -0.7273452877998352, 0.5779427886009216, 0.01857021078467369, -0.021670406684279442, -0.5447381734848022, -0.008519426919519901, -1.1795706748962402, -0.0016042998759076, -1.0206345319747925, 0.045018091797828674, -0.7546541690826416, -0.8265629410743713, 0.0029662251472473145, 0.12253643572330475, -0.11657585948705673, 0.26759839057922363, -0.7481607794761658, -0.5490422248840332, -0.777263343334198, -0.22859439253807068, 1.061037540435791, 0.8718580007553101, -0.6367459297180176, -0.443164199590683, 0.16025620698928833, 0.20221810042858124, 0.1107698529958725, 0.8549155592918396, -0.556153416633606, -1.1013572216033936, -1.53633713722229, 0.3954070210456848, -0.23789548873901367, -0.21723942458629608, -0.7482763528823853, 0.4976016581058502, 0.26588496565818787, -0.45968911051750183, 0.024028977379202843, 0.29351791739463806, -0.7651466131210327, -0.10436900705099106, -0.04632022976875305, -0.5073842406272888, 0.3667008876800537, 0.5554549694061279, -0.40581369400024414, -0.19599543511867523, 0.369499534368515, -0.22790031135082245, -1.110988736152649, -0.5988168120384216, 0.5743106007575989, -0.8568242192268372, 0.3417551815509796, -0.5471267104148865, 0.14027950167655945, -1.0750725269317627, -0.20053105056285858, 0.18039202690124512, 0.6600251793861389, -0.5621040463447571, 1.090633511543274, 0.13882452249526978, -1.0898759365081787, 0.05311975255608559, 0.41921335458755493, -0.2612208127975464, 0.0681396946310997, 0.9000221490859985, 0.3554677367210388, -0.040868256241083145, 0.30587315559387207, 0.3375456631183624, 0.17761358618736267, -0.6845660209655762, -0.1692090481519699, 0.7735723853111267, -0.9129645824432373, -0.3243919312953949, 1.2687321901321411, -0.3000073730945587, -1.4156670570373535, 0.3037136495113373, -1.151727318763733, -0.5298396348953247, -0.524142861366272, 0.37085771560668945, 0.028906282037496567, -0.3038165867328644, 0.2528616189956665, 0.09697652608156204, 0.29987722635269165, -0.14135748147964478, -0.5862608551979065, 0.5788419246673584, -0.17988868057727814, -0.0038872736040502787, 0.8096005320549011, 0.5101861357688904, -0.9841456413269043, -0.7343635559082031, -0.4467131197452545, -0.38526540994644165, -0.14499807357788086, 0.31710174679756165, -0.18785005807876587, -0.606883704662323, 0.9043275117874146, 0.5644422173500061, 0.4446178376674652, -0.014245106838643551, -0.6128243803977966, -0.022339174523949623, 0.6587548851966858, 0.027833430096507072, -1.0444711446762085, -0.40336641669273376, 1.4891459941864014, 1.2888835668563843, -0.8767479658126831, 0.27585890889167786, -0.2572966516017914, -1.1047303676605225, 0.7813096642494202, 0.6177243590354919, 0.04772501438856125, 0.6930263042449951, -0.7239527702331543, 0.35118526220321655, -0.0972415953874588, -1.3992578983306885, -0.37171587347984314, 0.660203754901886, 0.9481467008590698, 0.7921861410140991, -0.08981598168611526, 0.10517130047082901, 0.7191872000694275, -0.27357974648475647, -0.08326464146375656, 0.5814103484153748, 0.3298751711845398, -0.07999006658792496, -0.07901059091091156, 0.21378932893276215, 0.5233134031295776, -0.5516785979270935, -0.4985763728618622, 0.3873645067214966, 0.5528761744499207, -0.0073499055579304695, 0.813975989818573, 0.8743318915367126, 0.14006057381629944, 0.538964569568634, 0.3945361375808716, 0.4778311550617218, -0.39701926708221436, -0.5018707513809204, 0.3127627372741699, -0.5623611807823181, -0.01492496207356453, -0.181319922208786, -0.44830965995788574, 0.13180358707904816, -0.18767915666103363, 0.19501234591007233, 0.28973472118377686, 0.288593053817749, 0.9175395965576172, 0.5783337354660034, 0.6827433705329895, -0.13868126273155212, -0.39133545756340027, -0.46074721217155457, -0.995905876159668, 0.11297861486673355, -0.568652868270874, -0.8442007899284363, 0.013573035597801208, -0.02513519860804081, -0.050825465470552444]}, "authors": [{"authorId": "2609325", "name": "Conglong Li"}, {"authorId": "2112111675", "name": "Minjia Zhang"}, {"authorId": "2145020341", "name": "Yuxiong He"}], "references": [{"paperId": "1081df12b1500f48718ad9cdf3b0b90f44a31fc9", "title": "Curriculum learning for language modeling"}, {"paperId": "5d21acef02a2035d0c5e3b8f70d4d3c9a164855f", "title": "1-bit LAMB: Communication Efficient Large-Scale Large-Batch Training with LAMB\u2019s Convergence Speed"}, {"paperId": "ad9b8672d48eaefa67a5f7a7e7f14e3a2a7b5d72", "title": "Reducing BERT Computation by Padding Removal and Curriculum Learning"}, {"paperId": "4066d78b637c2b8e57de5ffd53950134a551de85", "title": "1-bit Adam: Communication Efficient Large-Scale Training with Adam's Convergence Speed"}, {"paperId": "24b471802eda460d4cc17e591804ef04c0cd18ef", "title": "Curriculum Learning: A Survey"}, {"paperId": "0822f8d7e6a72a65e65f147d3a8d8fccd485da40", "title": "Shortformer: Better Language Modeling using Shorter Inputs"}, {"paperId": "3bf8538d70e912d6e0cbd334a74a8172cf7ad602", "title": "A Comprehensive Survey on Curriculum Learning"}, {"paperId": "2d315208dd88eed245dc4ae1ae398af75aa291f8", "title": "Curriculum Learning for Natural Language Understanding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "ad7129af0644dbcafa9aa2f111cb76526ea444a1", "title": "Defending Against Neural Fake News"}, {"paperId": "e1f037f47d96d10af5c1ab390a246238dd8e1057", "title": "Simple and Effective Curriculum Pointer-Generator Networks for Reading Comprehension over Long Narratives"}, {"paperId": "ec9984003962eb70a73bf0882ab49ef38cd6c239", "title": "Curriculum Learning for Domain Adaptation in Neural Machine Translation"}, {"paperId": "a62158491e3c88712277a8947a736ed8f17bbd4c", "title": "Control Regularization for Reduced Variance Reinforcement Learning"}, {"paperId": "1c71771c701aadfd72c5866170a9f5d71464bb88", "title": "Unified Language Model Pre-training for Natural Language Understanding and Generation"}, {"paperId": "bc789aef715498e79a74f857fa090ece9e383bf1", "title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes"}, {"paperId": "7225c2a42990f850f692f8d82e7f3bfaf312145c", "title": "Competence-based Curriculum Learning for Neural Machine Translation"}, {"paperId": "b43ffb0d4f8d1c66632b78ad74d92ab1218a6976", "title": "An Empirical Exploration of Curriculum Learning for Neural Machine Translation"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "c470f1d1e7d377b4e0d01890ae418a918c0e7093", "title": "Variance Reduction for Reinforcement Learning in Input-Driven Environments"}, {"paperId": "d7b6753a2d4a2b286c396854063bde3a91b75535", "title": "A Simple Method for Commonsense Reasoning"}, {"paperId": "a1e79bc3717486b311488bc67b319b3f6a44da14", "title": "Self-Training for Jointly Learning to Ask and Answer Questions"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "6a6e4c66a0ac349a149d05da9a4718f2dbb926d8", "title": "Results of the WMT17 Neural MT Training Task"}, {"paperId": "48bdeb305a9e3fd34932e2382d246ba364dfa4d0", "title": "Curriculum Learning and Minibatch Bucketing in Neural Machine Translation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "6ecb8a743f92db6c6b8691ab8e8aebbb06fb1b48", "title": "Averaged-DQN: Variance Reduction and Stabilization for Deep Reinforcement Learning"}, {"paperId": "992018dd6d98f37352437c19f16c5bc87c3b6f22", "title": "Easy Questions First? A Case Study on Curriculum Learning for Question Answering"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "5fb8a9271af105a5065a5a855e71a7d25c7a6f1b", "title": "Variance Reduction for Stochastic Gradient Optimization"}, {"paperId": "8de174ab5419b9d3127695405efd079808e956e8", "title": "Curriculum learning"}, {"paperId": "1af453015162bc2ce1c5b58afbcc153b158192cd", "title": "Neural network learning control of robot manipulators using gradually increasing task difficulty"}, {"paperId": "d5ddb30bf421bdfdf728b636993dc48b1e879176", "title": "Learning and development in neural networks: the importance of starting small"}, {"paperId": null, "title": "The engineering group in @bigsciencew \ufb01ghting training instabilities over +100b parameters"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Better language models and their implications"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, the World\u2019s Largest and Most Powerful Generative Language Model"}]}