{"paperId": "ff7391dff405fc6f5aebd5d5f14257af19a0c26c", "title": "Farewell to Length Extrapolation, a Training-Free Infinite Context with Finite Attention Scope", "abstract": "The maximum supported context length is a critical bottleneck limiting the practical application of the Large Language Model (LLM). Although existing length extrapolation methods can extend the context of LLMs to millions of tokens, these methods all have an explicit upper bound. In this work, we propose LongCache, a training-free approach that enables LLM to support an infinite context with finite context scope, through full-context cache selection and training-free integration. This effectively frees LLMs from the length extrapolation issue. We validate LongCache on the LongBench and L-Eval and demonstrate its performance is on par with traditional full-attention mechanisms. Furthermore, we have applied LongCache on mainstream LLMs, including LLaMA3 and Mistral-v0.3, enabling them to support context lengths of at least 400K in Needle-In-A-Haystack tests. We will improve the efficiency of LongCache by GPU-aware optimization soon.", "venue": "", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes LongCache, a training-free approach that enables LLM to support an infinite context with finite context scope, through full-context cache selection and training-free integration, which effectively frees LLMs from the length extrapolation issue."}, "embedding": {"model": "specter_v2", "vector": [0.21247395873069763, 0.10875309258699417, -0.42154064774513245, -0.024599645286798477, -0.37244758009910583, -0.2857665419578552, 0.40737536549568176, -0.04775718227028847, -0.8174976706504822, -0.02803877554833889, 0.6853874325752258, -0.46887582540512085, 1.1394065618515015, 0.24339856207370758, -0.19496935606002808, 0.10000324249267578, -0.8888339400291443, -0.17575767636299133, 0.23804984986782074, -0.2336859554052353, -0.040033116936683655, -0.5967693328857422, -1.2639745473861694, 0.3554729223251343, 0.5828863382339478, 0.4116918444633484, 0.3053886294364929, 1.1473686695098877, -0.6882954239845276, 0.2413671761751175, 0.2297867089509964, 0.053673554211854935, -0.1414724439382553, 0.27140161395072937, -0.45645642280578613, -0.552963376045227, 0.3817198872566223, -0.6729478240013123, -0.2175501585006714, 0.5729153156280518, 0.06936009228229523, 0.2511848211288452, -0.023840108886361122, -0.5852773785591125, -0.1543346643447876, 0.9411041736602783, 0.3513040840625763, 0.8362036347389221, -0.36685213446617126, -0.36265692114830017, 1.1131622791290283, -1.5498579740524292, 0.2687722444534302, 1.093292236328125, 0.37932202219963074, 0.5353448390960693, -0.1399860978126526, -0.16594019532203674, 0.8871908783912659, -0.05707461014389992, -0.7037813067436218, -0.5177704691886902, -0.27674561738967896, 0.14180320501327515, 2.5085763931274414, -0.19271767139434814, 0.20944668352603912, 0.5027558207511902, 0.1028197780251503, 1.349862813949585, -0.2432948499917984, -1.06782066822052, -0.04234245419502258, -0.27160170674324036, 0.6812343597412109, 0.3301580250263214, -0.24233214557170868, 0.1718643754720688, -0.673980176448822, -0.3945477604866028, 0.29927605390548706, -0.08450865000486374, 0.39729130268096924, -0.023497167974710464, -0.47458502650260925, 0.5080283284187317, 0.056078698486089706, 1.0338855981826782, 0.06162479892373085, 0.9260703921318054, 0.9612371921539307, 0.017815537750720978, 0.2548055648803711, 0.1825648695230484, -0.13453976809978485, -0.07843863219022751, -1.178783655166626, 0.3382839262485504, -0.12967953085899353, 1.1001981496810913, -0.4816969931125641, 0.3793264329433441, -0.7481526732444763, 0.09163859486579895, 0.7966437935829163, 0.34846949577331543, 0.46337223052978516, -0.7477729916572571, 0.3180491030216217, -0.78504878282547, 0.17488044500350952, 0.2469143569469452, -0.12057184427976608, -0.3162427246570587, -0.5783198475837708, -0.9294463396072388, -0.19992302358150482, -0.3040928840637207, -0.23799782991409302, 0.6642218828201294, 0.2516980767250061, 0.26436400413513184, 0.31335148215293884, 0.4890477955341339, 0.779686450958252, 0.6008031368255615, 0.055570509284734726, -0.01520601287484169, 0.9570480585098267, -1.2001500129699707, -0.5291378498077393, -1.1956912279129028, 1.2419512271881104, -0.42875662446022034, 0.6450706124305725, -0.1458878368139267, -1.1388580799102783, -0.7270495891571045, -1.031846523284912, -0.19651459157466888, -0.6303855180740356, -0.0602274015545845, 0.9297495484352112, 0.4089151620864868, -0.8656246662139893, 0.6697010397911072, -0.33805137872695923, -0.010974948294460773, 0.04258475825190544, -0.05962817743420601, 0.5030490159988403, -0.4648357927799225, -1.6200381517410278, -0.14538244903087616, 0.1859847605228424, -0.7513465285301208, 0.06896840035915375, -0.49196332693099976, -1.2053990364074707, -0.1264733523130417, 0.5453884601593018, -0.09408982843160629, 1.4935537576675415, -0.13508689403533936, -0.9416444301605225, 0.3715916574001312, -0.4994032680988312, 0.11312805861234665, 0.13468654453754425, -0.4380883574485779, -0.7038924098014832, -0.6812291741371155, -0.36683133244514465, 0.5406413078308105, 0.4758915305137634, -0.01633836328983307, -0.12609246373176575, 0.13872487843036652, -0.22311891615390778, 0.10007646679878235, -0.1969083845615387, 0.8981938362121582, -0.46225783228874207, -0.1711580455303192, 0.0658404603600502, 0.5292803645133972, -0.12759901583194733, -0.4497259557247162, -0.29389211535453796, -0.9703592658042908, 0.8687817454338074, 0.21141013503074646, 1.515882134437561, -0.9150525331497192, -0.9749550223350525, -0.2882697284221649, -0.3780938684940338, -0.05756073817610741, -0.6025657653808594, 0.4828471839427948, -0.01131343748420477, 0.32056087255477905, -0.18654148280620575, -0.9670352339744568, 0.008420571684837341, -0.2014649361371994, -0.7619276642799377, -0.3071882426738739, -0.08144057542085648, 1.0317631959915161, -1.1028425693511963, -0.29781943559646606, -0.22039176523685455, 0.364160418510437, -1.155626654624939, 1.1145284175872803, -0.7643847465515137, 0.23445530235767365, -0.05092401057481766, -0.07629361748695374, -0.10175193101167679, -0.24697120487689972, 0.45310482382774353, 0.03266005963087082, -0.43496429920196533, 0.36658424139022827, -0.32625266909599304, 1.5727968215942383, -0.7938997745513916, 0.348483145236969, 0.08280688524246216, 0.10787758231163025, -0.2119733691215515, 0.2896658480167389, -0.4016644060611725, -0.2549002766609192, 0.2249782830476761, 0.6454889178276062, -0.4356052279472351, 0.15263234078884125, 1.406205177307129, 1.3496583700180054, -0.7732763886451721, 0.38001880049705505, 0.13838942348957062, -0.08170876652002335, 0.30104970932006836, 0.6199592351913452, 0.6191076040267944, 0.8162211179733276, 0.19836503267288208, -0.21164865791797638, 0.5250371098518372, -0.762241780757904, -0.29140129685401917, 0.5929466485977173, 0.5550515651702881, 0.6649959683418274, 0.36460381746292114, -0.7602035403251648, -0.6631227135658264, 0.5564858913421631, 0.41744083166122437, 1.9890096187591553, -0.1906048059463501, -0.20783449709415436, -1.2707182168960571, -0.3724856674671173, -0.365924209356308, 0.5471397042274475, -0.10150020569562912, 0.30070146918296814, -0.8206157684326172, -0.6269486546516418, 0.9773435592651367, 0.36516261100769043, 0.6781185269355774, -0.9604113101959229, -0.7424700260162354, -0.2984684407711029, 0.25549304485321045, -0.9632454514503479, -1.044689655303955, 0.2210809588432312, -0.7032052874565125, 0.28506019711494446, 0.1005912646651268, -0.21460063755512238, 0.10599740594625473, -0.6026064157485962, 0.9858295917510986, -0.16650182008743286, -0.1328604519367218, 0.10496225953102112, 0.5353862047195435, -0.24109995365142822, -0.9687978029251099, 0.5495465397834778, 0.13026587665081024, -0.44269034266471863, 0.27440139651298523, 0.5325115323066711, -0.14332838356494904, -0.1206001490354538, -0.479830801486969, 0.27387139201164246, 0.03201739490032196, -0.025887001305818558, 1.0236066579818726, -0.7550215125083923, 0.1529518961906433, -1.376715064048767, 0.7544577717781067, 0.17352195084095, -0.4605807960033417, 0.3159419894218445, -0.6320937871932983, -0.21457694470882416, 0.628192126750946, -1.05433189868927, -0.27865034341812134, -0.9810619950294495, -0.08050767332315445, -0.3029072880744934, -0.299446165561676, -0.034198928624391556, 0.07662490755319595, 0.3210833966732025, 0.049412716180086136, 0.6172375082969666, -0.037836797535419464, -0.23990735411643982, 0.8298910856246948, -0.6241492033004761, 0.5686973929405212, -0.03673446178436279, -0.6256468296051025, -0.2787780463695526, -0.21047696471214294, -0.8751885294914246, -0.005853968672454357, -0.27966704964637756, -0.5200526714324951, -0.33860281109809875, 0.04526691138744354, -0.3988850712776184, -0.6991693377494812, 0.0737229660153389, -1.2427992820739746, -0.5650386214256287, 0.2870301902294159, -0.3834395706653595, -0.04291722923517227, -0.765961766242981, -1.3235613107681274, -0.46099191904067993, -1.0491584539413452, -1.266029715538025, 0.6604527235031128, -0.2686797082424164, -0.560518205165863, -0.6037483811378479, -0.1530769169330597, -0.6234574317932129, 1.0586473941802979, -0.7617687582969666, 0.716589093208313, -0.07002124190330505, -0.21944618225097656, -0.28767505288124084, 0.40839773416519165, 0.2555977404117584, -0.7016086578369141, 0.0691976249217987, -1.0568311214447021, 0.030411358922719955, -0.25446856021881104, -0.3629109859466553, 0.2632703483104706, 0.25306111574172974, 0.9460296630859375, -0.1652507334947586, -0.6011329293251038, 0.244915172457695, 1.3701207637786865, -0.7690321207046509, 0.15717996656894684, -0.24515852332115173, 1.075755000114441, -0.23921120166778564, -0.06992628425359726, 0.6576147079467773, -0.07187588512897491, 0.22539891302585602, 0.30587783455848694, 0.08871887624263763, 0.09352143108844757, -0.1652182787656784, 0.7331061959266663, 1.8667534589767456, 0.5440146327018738, -0.1769312024116516, -0.8844520449638367, 0.6324131488800049, -1.1761527061462402, -0.6258395910263062, 0.5164145231246948, 1.010014533996582, 0.4766116738319397, -0.11987663805484772, -0.30545297265052795, -0.4278140068054199, 0.4539186656475067, 0.5834437012672424, -0.6169121861457825, -1.3048319816589355, -0.023618148639798164, 0.08889412134885788, 0.09769588708877563, 0.8263907432556152, -0.1001502200961113, 0.8079617619514465, 14.577434539794922, 1.3693567514419556, -0.12192551791667938, 0.7263931632041931, 0.8437016010284424, -0.15528300404548645, -0.6133692264556885, -0.22192639112472534, -1.4444830417633057, -0.018757985904812813, 1.4315435886383057, 0.3251507580280304, 0.6288995146751404, 0.2813994586467743, -0.03242632746696472, -0.06528263539075851, -0.5428863167762756, 0.555144190788269, 0.4874136447906494, -1.2073906660079956, 0.27450674772262573, 0.0950353667140007, 0.46933549642562866, 0.7720645070075989, 0.6359547972679138, 0.9205648899078369, 0.11536499857902527, -0.30578741431236267, 0.6705681681632996, 0.015911424532532692, 1.28019118309021, -0.47613516449928284, 0.5283921360969543, 0.6004396677017212, -0.9713069200515747, 0.05636029317975044, -0.5282973051071167, -1.1964898109436035, 0.12130331993103027, 0.19946636259555817, -0.5226255655288696, -0.7684459090232849, -0.4346669316291809, 0.41166263818740845, 0.2711629569530487, 0.04203224927186966, 0.19930903613567352, 0.6370704174041748, 0.000950958754401654, -0.2579488456249237, 0.5447556972503662, 0.528305172920227, 0.407233864068985, 0.22346748411655426, 0.018773969262838364, -0.05877501517534256, 0.0669809952378273, 0.43198734521865845, -0.44075480103492737, 0.20198167860507965, -0.3888182044029236, 0.14397475123405457, 0.1227802038192749, 0.8243625164031982, 0.3876765966415405, 0.09542014449834824, -0.7469092607498169, 0.3421398401260376, 0.5236480236053467, 0.10126818716526031, -0.3431108593940735, -0.08021502941846848, 0.27712008357048035, -0.5983574986457825, -0.11041881889104843, 0.5257869958877563, -0.2945062220096588, -0.6250276565551758, -0.5613383650779724, -0.38694673776626587, 0.07844846695661545, -0.5858057737350464, -0.26530638337135315, 1.1073263883590698, -0.1536676436662674, -0.40964144468307495, 0.08053484559059143, -0.4479050934314728, -0.4029654860496521, 0.5395771861076355, -1.021004319190979, -0.6445302367210388, 0.7226491570472717, -0.5696876645088196, -0.1490216702222824, 0.3204537630081177, 1.3213210105895996, 0.05869254469871521, -0.38257965445518494, 0.3432130515575409, 0.5872054696083069, 0.0047769625671207905, -0.23491045832633972, -0.7729957103729248, 1.3941717147827148, 0.3979021906852722, -0.39972683787345886, 0.07065808773040771, -0.008649872615933418, 0.1295459121465683, -0.9168078899383545, -0.3183750510215759, 0.6962798237800598, -1.0250217914581299, -0.4318041205406189, -1.2350214719772339, -1.1835622787475586, 0.31292468309402466, 0.7436395883560181, -0.014044273644685745, 0.32495367527008057, 0.20934395492076874, -0.25354719161987305, -0.006338376551866531, -0.5705022215843201, 0.3202645182609558, 0.7803969979286194, -0.6830242872238159, 0.024865401908755302, -0.2834317088127136, 0.9921756386756897, -1.3946833610534668, -0.7708299160003662, -0.4948800802230835, 0.38885489106178284, -0.13446006178855896, 0.7020981311798096, -0.12524409592151642, 0.6559166312217712, 1.2741191387176514, -0.19914133846759796, -0.5247963666915894, 0.32203757762908936, -0.8363490104675293, -0.24354296922683716, 0.3436868190765381, 0.7568893432617188, -0.35325953364372253, 0.19334089756011963, 0.8361242413520813, 0.21625672280788422, -0.9781339168548584, -0.7971863150596619, -0.2595910429954529, 0.7391613125801086, -0.8441614508628845, 0.9437432289123535, -0.2632654309272766, 0.31617817282676697, 0.08091290295124054, 0.4186636507511139, 0.536044716835022, -0.18617919087409973, -0.48786336183547974, 0.3494725227355957, 0.3974836468696594, -0.13379347324371338, -0.5865438580513, -0.07295077294111252, -1.4969242811203003, -0.024244533851742744, -1.0544147491455078, 0.02713419683277607, -0.4251972436904907, -0.3136932849884033, -0.07570870220661163, -0.09769818931818008, -0.13384655117988586, 0.2443597912788391, -0.4831921458244324, -0.7326518893241882, -0.7368462085723877, -0.9257988333702087, 0.5722677111625671, 0.9441804885864258, -0.4006836414337158, 0.1112133041024208, -0.1278015673160553, 0.4752427637577057, 0.1821325570344925, 0.49292388558387756, -0.16641029715538025, -0.6812697649002075, -1.4253654479980469, 0.4546653628349304, 0.05836382135748863, -0.3890884518623352, -0.6107362508773804, 0.3243122398853302, 0.24505960941314697, -0.1702108234167099, -0.29795441031455994, 0.0860733911395073, -0.5853551626205444, -0.775117039680481, 0.2635481655597687, -0.8816830515861511, 0.39469945430755615, 0.6412829756736755, -0.7484409809112549, 0.08381545543670654, 0.5125587582588196, -0.40530043840408325, -0.9077931642532349, -1.040010929107666, 0.2555318772792816, -0.8517889380455017, 0.5356718301773071, -0.6494414806365967, -0.03219227120280266, -1.1180576086044312, -0.06771210581064224, -0.11465512216091156, 0.4270431399345398, 0.13220009207725525, 1.0502064228057861, 0.39600616693496704, -1.018139362335205, 0.11233461648225784, 0.4717145264148712, -0.032288748770952225, 0.2094697505235672, 0.8409785032272339, 0.29808133840560913, -0.34668105840682983, 0.6145498752593994, 0.6323053240776062, 0.03701825812458992, -1.359312653541565, 0.37018704414367676, 0.4580409526824951, -0.48175811767578125, -0.4022189676761627, 0.952465295791626, -0.3343439996242523, -0.9250455498695374, 0.02395487017929554, -1.613783359527588, -0.3661727011203766, -0.9540454149246216, 1.0731360912322998, 0.2330876588821411, 0.1552770435810089, -0.2637764513492584, -0.6495590209960938, 0.003510142210870981, -0.16732099652290344, -0.7039754390716553, 0.20855526626110077, -0.22195766866207123, -0.4672032296657562, 0.7536712288856506, 0.8088491559028625, -0.16202521324157715, -0.6052461266517639, -0.6157850027084351, -0.47550898790359497, 0.055624909698963165, 0.3999222218990326, -0.3170984983444214, -0.1314462125301361, 0.8658007979393005, 0.40076351165771484, 0.3753545880317688, -0.10738025605678558, -0.23854199051856995, 0.6367942094802856, 0.5938896536827087, 0.30413058400154114, -0.6576240062713623, -0.78525710105896, 1.4796935319900513, 1.0670993328094482, -0.9456260204315186, 0.19242128729820251, 0.2955728769302368, -0.6670430302619934, 0.6189020872116089, 0.6656233072280884, 0.17372772097587585, 0.7294785380363464, 0.24030983448028564, 0.008239827118813992, 0.4895993173122406, -1.3282381296157837, 0.15323364734649658, 0.640063464641571, 0.49340254068374634, 0.888099730014801, 0.30393174290657043, 0.041723161935806274, 0.9415900111198425, 0.27061861753463745, 0.013048922643065453, 0.45217180252075195, 0.8064805865287781, -0.32485973834991455, -0.16299653053283691, -0.18233856558799744, 0.5919370651245117, -0.8628067970275879, -1.142850399017334, 0.3657044470310211, 0.49143287539482117, 0.2974666953086853, 0.48889318108558655, 1.0288938283920288, 0.36844393610954285, 0.05287877842783928, 0.3157414197921753, 0.7233245968818665, -0.5195505619049072, -0.5052366256713867, 0.04918316751718521, -0.6597781777381897, -0.09456963837146759, 0.426692932844162, -0.4106229245662689, -0.8163563013076782, -0.6091948747634888, 0.17332282662391663, 0.07818587869405746, 0.18643346428871155, 0.9958476424217224, 0.7165965437889099, 0.43320828676223755, -0.4439702332019806, -0.6250589489936829, -0.24350492656230927, -0.948401153087616, -0.08821804821491241, -0.4630276560783386, -0.1274847537279129, 0.4682369828224182, 0.23082689940929413, -0.5896439552307129]}, "authors": [{"authorId": "2257094943", "name": "Xiaoran Liu"}, {"authorId": "3187768", "name": "Qipeng Guo"}, {"authorId": "2312411082", "name": "Yuerong Song"}, {"authorId": "2284732560", "name": "Zhigeng Liu"}, {"authorId": "2055634356", "name": "Kai Lv"}, {"authorId": "146948229", "name": "Hang Yan"}, {"authorId": "2312337531", "name": "Linlin Li"}, {"authorId": "2312345527", "name": "Qun Liu"}, {"authorId": "2256661980", "name": "Xipeng Qiu"}], "references": [{"paperId": "9803d83bbb28d02fb01f00e0e05aa3c192a87255", "title": "MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention"}, {"paperId": "37b1ce339678f63315c82841c6824dd739269636", "title": "Length Generalization of Causal Transformers without Position Encoding"}, {"paperId": "41b47f33a24feefd6728bdc1339d0d4ff5fec7be", "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context"}, {"paperId": "cf7ab5df804575bad88a9fcf0fbf7707bf500944", "title": "Training-Free Long-Context Scaling of Large Language Models"}, {"paperId": "c9603ec967879c24973b5bd48861df2e5555932e", "title": "LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens"}, {"paperId": "ba233fd52bb840d138c5a2aa46c715ed858cda9d", "title": "BGE Landmark Embedding: A Chunking-Free Embedding Method For Retrieval Augmented Long-Context Large Language Models"}, {"paperId": "f6440a16ccc5c13d2a86af91b76e078685abfd16", "title": "LongHeads: Multi-Head Attention is Secretly a Long Context Processor"}, {"paperId": "ef1b02dc1b82f9955fc4760fcefd92c0fff9f227", "title": "Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference"}, {"paperId": "2b8439f319dfa73df62ca8957ff6d0c1f3c7a73c", "title": "Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon"}, {"paperId": "a9468d8bfa6bd016dfd3128c4e8408e30eb8549b", "title": "LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning"}, {"paperId": "713806165610c237f551a7b68e6b09b3ded75502", "title": "SparQ Attention: Bandwidth-Efficient LLM Inference"}, {"paperId": "539fadfb615ef84c240f4741061c44eeda540091", "title": "Scaling Laws of RoPE-based Extrapolation"}, {"paperId": "6c323c535365e1c7cbfd9703cbec3b5650a3346b", "title": "Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "5e0cb1c4b91a7486e1c2b15a44a0be56bd74bdc0", "title": "Effective Long-Context Scaling of Foundation Models"}, {"paperId": "819bbdc2dac9e13d9ca3e2508a6e063186ce5e40", "title": "YaRN: Efficient Context Window Extension of Large Language Models"}, {"paperId": "b31a5884a8ebe96b6300839b28608b97f8f8ef76", "title": "LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding"}, {"paperId": "0b0debb710366cdff461938c80763eace1651af6", "title": "Code Llama: Open Foundation Models for Code"}, {"paperId": "b0db25e317cf856f1ec1ca3df0e573d850ed4696", "title": "L-Eval: Instituting Standardized Evaluation for Long Context Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "e586a4591ba0303b769f2c07cbddaf1899cb72e4", "title": "H2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "9575afb5702bc33d7df14c48feeee5901ea00369", "title": "A Length-Extrapolatable Transformer"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": null, "title": "Transformers: State-of-the-Art Natural Language Processing"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "4aa95dc3682d664b333a868ce350d1567abc47cd", "title": "Contributors"}, {"paperId": "5c3391bde2bb1b3d737913ee8caa01492a782732", "title": "WHO Technical Report"}, {"paperId": null, "title": "mistralai"}, {"paperId": null, "title": "Internlm2.5-7b"}, {"paperId": "e3aa232577bb427b1f3a34acbdef84bd85734042", "title": "LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models"}, {"paperId": "0eedbc38bc215fdbe4e5bcde8aeac08fb3ce9f44", "title": "Parallel Context Windows Improve In-Context Learning of Large Language Models"}, {"paperId": null, "title": "Introducing meta llama 3: The most capable openly available llm to date"}, {"paperId": null, "title": "Infllm: Unveiling the intrinsic capacity of llms for understanding extremely long sequences with training-free memory"}, {"paperId": null, "title": "Dynamically scaled rope further increases performance of long context llama with zero fine-tuning,"}, {"paperId": null, "title": "Rerope: Rectified rotary position embeddings, July 2023"}, {"paperId": null, "title": "Nbce: Naive bayes-based context extension, May 2023"}, {"paperId": null, "title": ". Ntk-aware scaled rope allows llama models to have extended (8k+) context size without any fine-tuning and minimal perplexity degradation"}]}