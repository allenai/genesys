{"paperId": "b50815251c948f00baedccaf5f56c281ffa7650f", "title": "Staircase Attention for Recurrent Processing of Sequences", "abstract": "Attention mechanisms have become a standard tool for sequence modeling tasks, in particular by stacking self-attention layers over the entire input sequence as in the Transformer architecture. In this work we introduce a novel attention procedure called staircase attention that, unlike self-attention, operates across the sequence (in time) recurrently processing the input by adding another step of processing. A step in the staircase comprises of backward tokens (encoding the sequence so far seen) and forward tokens (ingesting a new part of the sequence), or an extreme Ladder version with a forward step of zero that simply repeats the Transformer on each step of the ladder, sharing the weights. We thus describe a family of such models that can trade off performance and compute, by either increasing the amount of recurrence through time, the amount of sequential processing via recurrence in depth, or both. Staircase attention is shown to be able to solve tasks that involve tracking that conventional Transformers cannot, due to this recurrence. Further, it is shown to provide improved modeling power for the same size model (number of parameters) compared to self-attentive Transformers on large language modeling and dialogue tasks, yielding significant perplexity gains.", "venue": "Neural Information Processing Systems", "year": 2021, "citationCount": 10, "influentialCitationCount": 2, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Staircase attention is shown to be able to solve tasks that involve tracking that conventional Transformers cannot, and to provide improved modeling power compared to self-attentive Transformers on large language modeling and dialogue tasks, yielding significant perplexity gains."}, "embedding": {"model": "specter_v2", "vector": [0.5341459512710571, 0.5944818258285522, -0.03367951139807701, -0.16176077723503113, 0.04479179531335831, -0.04596332460641861, 0.6753339171409607, -0.185885488986969, -0.3212565779685974, -0.5419041514396667, 0.8031006455421448, 0.14866016805171967, 0.2233514040708542, 0.1407996118068695, 0.0017892483156174421, 0.3541838228702545, -0.9033477306365967, 0.2292748987674713, 0.46344560384750366, -0.34886783361434937, 0.2021390050649643, -0.6869713068008423, -1.3977737426757812, 0.47960665822029114, 0.3071460723876953, 0.5806326270103455, 0.37709805369377136, 0.9121254682540894, -0.3965849280357361, 1.0239977836608887, 0.4039471745491028, -0.3763911724090576, -0.008250851184129715, -0.37457454204559326, -0.5980430245399475, -0.12336128205060959, 0.5449663400650024, -0.031116772443056107, -0.4359041154384613, 0.5890739560127258, -0.48029381036758423, 0.12786798179149628, 0.19525457918643951, -0.3795735538005829, 0.12808090448379517, 1.285516381263733, 0.5668482780456543, 0.9515933394432068, 0.09039747714996338, -0.9999799728393555, 1.3797152042388916, -1.2730753421783447, 0.17256329953670502, 1.574759602546692, 0.7453052997589111, 0.4538835287094116, -0.04480506107211113, -0.5904154777526855, 1.1676428318023682, 0.3586098849773407, -0.6267583966255188, -0.5405475497245789, -0.007062668912112713, -0.13822758197784424, 1.6241679191589355, -0.15249888598918915, 0.11569301784038544, 0.29154354333877563, -0.014010239392518997, 1.627916693687439, -0.14470580220222473, -0.7309775352478027, -0.2732383906841278, 0.18807420134544373, 0.7589285373687744, 0.8466419577598572, -0.5694586634635925, 0.2130504995584488, -1.1755478382110596, -0.07544593513011932, 0.7247986197471619, 0.020706642419099808, -0.03010018914937973, -0.2944808304309845, -0.05111971125006676, 0.2541484534740448, 0.41027724742889404, 0.9586862325668335, -0.4107770323753357, 0.8364014029502869, 0.5477147698402405, 0.3462660312652588, 0.1250312179327011, 0.2255709320306778, 0.28716135025024414, 0.3415287435054779, -0.6063481569290161, -0.009039288386702538, -0.1426982283592224, 1.1010386943817139, 0.023012422025203705, 0.4841761887073517, -0.6346842646598816, 0.3002358078956604, 1.4512332677841187, -0.6287549734115601, 0.5446007251739502, -0.6482976078987122, -0.0831829234957695, -0.5153382420539856, 0.4069114923477173, -0.5776376724243164, -0.1756390929222107, -0.5150014162063599, -0.6116493940353394, -1.117051601409912, -0.33571165800094604, 0.4770956337451935, -0.7220416069030762, 0.6266064047813416, -0.3422209918498993, 0.18893016874790192, -0.18770819902420044, 0.08980930596590042, 0.11100230365991592, 0.41201579570770264, 0.5876389145851135, -0.11053555458784103, 1.2218519449234009, -0.7560200095176697, -0.6196076273918152, -1.0250738859176636, 0.4995817542076111, 0.061809565871953964, -0.15263167023658752, -0.3644687235355377, -1.487186312675476, -0.9514656662940979, -0.7011706829071045, 0.21455702185630798, -0.18241414427757263, -0.09682068228721619, 1.0524725914001465, 0.254457950592041, -1.1853361129760742, 1.0621885061264038, -0.4783133566379547, -0.2892729341983795, 0.3797708749771118, -0.04432903602719307, 0.4020249545574188, -0.026163693517446518, -1.2324762344360352, 0.32961568236351013, 0.11872968077659607, 0.09851384907960892, -0.23383237421512604, -0.9995102882385254, -1.0644299983978271, 0.0802367702126503, 0.21581214666366577, -0.5836514830589294, 1.5266214609146118, -0.32974904775619507, -1.2197740077972412, 0.7967932224273682, -0.6726215481758118, -0.05954361334443092, 0.3122732937335968, -0.24514250457286835, -0.4430904984474182, -0.572776198387146, -0.1403525322675705, -0.04311348497867584, 0.21055108308792114, -0.19925831258296967, -0.6821281313896179, -0.29511094093322754, -0.583899199962616, -0.2944681942462921, 0.10669919103384018, 1.110557198524475, -0.34976497292518616, -0.1988067775964737, 0.5927923917770386, 0.8360303044319153, -0.04477934166789055, -0.6326720714569092, -0.26864001154899597, -1.3275563716888428, 0.4860698878765106, 0.1358484923839569, 1.172318696975708, -0.6589618921279907, -0.7385455965995789, -0.2784939408302307, -0.217220738530159, -0.22606605291366577, -0.5450905561447144, 0.7057348489761353, -0.6012576222419739, 0.560509443283081, -0.17211854457855225, -0.98736572265625, -0.2095736563205719, -0.5569429397583008, -0.7159428596496582, -0.43178924918174744, 0.07571108639240265, 0.9300779700279236, -1.2625716924667358, 0.05788015201687813, -0.1942438781261444, 0.20476025342941284, -0.7622859477996826, 1.3384605646133423, -0.07994450628757477, -0.02456602081656456, -0.13780577480793, -0.4876399338245392, -0.08735648542642593, -0.23969392478466034, 0.4007575809955597, -0.44732144474983215, -0.4300224483013153, 0.6883870363235474, -0.028130561113357544, 0.9864142537117004, -0.4036811888217926, 0.5908048152923584, -0.17544113099575043, -0.32297033071517944, 0.12357383221387863, 0.2724453806877136, -0.3994782269001007, -0.6080738306045532, 0.008957520127296448, 0.003399299457669258, -0.5927791595458984, 0.3208942711353302, 0.7058385610580444, 0.940717875957489, -0.3749271631240845, 0.11614620685577393, 0.5997158288955688, -0.018944265320897102, 0.3434598445892334, 0.5068010687828064, 0.8655259013175964, 0.5293325781822205, 0.3753857910633087, 0.009717167355120182, 0.3015649616718292, -0.5999741554260254, 0.2348044514656067, 0.6492727398872375, 0.7346504926681519, 0.6203092336654663, 0.2859860062599182, -0.8079855442047119, -0.5612568259239197, 0.30757322907447815, 0.7212257385253906, 1.663797378540039, -0.3653688430786133, -0.11086663603782654, -0.8708931803703308, -0.05356772616505623, -0.5056623816490173, 0.4319067895412445, -0.6255964040756226, -0.31205639243125916, -0.7064409852027893, -0.7123293876647949, 0.7038701176643372, 0.5268497467041016, 1.0638974905014038, -1.0096445083618164, -0.628153383731842, 0.1908467561006546, 0.46290749311447144, -0.7654920816421509, -0.6764493584632874, 0.37399306893348694, -0.6446594595909119, -0.16527678072452545, 0.11942390352487564, -0.15989720821380615, -0.0498444065451622, -0.3773342967033386, 0.8417560458183289, -0.4408138394355774, -0.32601651549339294, 0.38165414333343506, 0.515527069568634, -0.588304877281189, -0.7025125026702881, 0.04031414911150932, 0.11594782024621964, 0.21644991636276245, 0.07105591148138046, 0.49802500009536743, -0.10208965837955475, 0.18858285248279572, 0.048660095781087875, -0.0040251584723591805, -0.05266638845205307, -0.10020312666893005, 0.22625038027763367, -0.18990057706832886, -0.016917703673243523, -1.5321239233016968, 0.76278156042099, 0.10159029811620712, -0.23406840860843658, 0.3597317636013031, -0.4990931749343872, -0.42476797103881836, 0.2658337652683258, -0.33953025937080383, -0.5199397802352905, -0.8963605165481567, 0.6458032131195068, -0.5123039484024048, -0.10219208151102066, 0.1306600123643875, 0.2824310064315796, 0.4193418323993683, 0.004344159737229347, 0.6711934208869934, 0.2905520796775818, -0.16411946713924408, 0.17969024181365967, -0.8286194801330566, 0.7121122479438782, 0.7491692900657654, -0.1252754032611847, -0.24135279655456543, -0.20821847021579742, -0.8908211588859558, -0.6996430158615112, -0.5825352072715759, -0.26765766739845276, -0.39908313751220703, 0.05589999631047249, -0.34518179297447205, -1.3066248893737793, 0.29666194319725037, -1.218146562576294, -0.3826793432235718, 0.2802650034427643, -0.6067399382591248, -0.4587404131889343, -0.8761302828788757, -1.114856243133545, -1.165871500968933, -0.4867124855518341, -0.21839025616645813, -0.09436656534671783, 0.31473517417907715, -0.5450047254562378, -0.5547282099723816, -0.041740782558918, -0.46916744112968445, 0.9739630818367004, -0.7903366684913635, 0.44624972343444824, -0.09688807278871536, -0.606685996055603, -0.18823470175266266, 0.2075096070766449, 0.12900863587856293, 0.26718541979789734, 0.004195791203528643, -0.7471844553947449, 0.277591347694397, -0.010295449756085873, 0.1701688915491104, 0.29754334688186646, -0.034737300127744675, 0.6541901230812073, -0.23862609267234802, -0.6444276571273804, -0.0923096165060997, 1.1201720237731934, -0.12793174386024475, 0.290994256734848, 0.3283131718635559, 0.8223896622657776, 0.568146288394928, -0.11690601706504822, 0.45693036913871765, 0.7171962261199951, 0.46311232447624207, 0.1917686015367508, 0.004030250478535891, -0.102218858897686, -0.6827139854431152, 0.46213871240615845, 1.1731442213058472, 0.04296812787652016, 0.17026564478874207, -1.1135265827178955, 0.7978662252426147, -1.3015118837356567, -1.3796688318252563, 0.5226601362228394, 0.9197638034820557, 0.08734872192144394, -0.6287857890129089, -0.08670146763324738, -0.30910253524780273, 0.6742637157440186, -0.04709110036492348, -0.42075181007385254, -0.623133659362793, 0.2692183554172516, 0.03215427324175835, 0.03669093921780586, 0.9127366542816162, -0.3263811469078064, 0.832584798336029, 15.121511459350586, 0.08091151714324951, 0.14367786049842834, 0.5152665972709656, 0.5777315497398376, 0.3483138978481293, -0.2946159243583679, -0.02997797355055809, -1.3219172954559326, -0.09106998145580292, 1.190839171409607, -0.06252750009298325, 0.4767776131629944, -0.1367749273777008, 0.26647666096687317, 0.34582313895225525, -0.6869438886642456, 0.463515043258667, 0.4392060339450836, -0.9915325045585632, 0.48839694261550903, -0.025133483111858368, -0.3138399124145508, 0.3522246778011322, 0.5907765626907349, 0.6557720303535461, 1.0060495138168335, -0.19955311715602875, 0.4519875943660736, 0.7943950295448303, 0.4208260178565979, -0.06534978002309799, 0.04497404024004936, 0.360544890165329, -0.857631266117096, -0.24739177525043488, -0.3512565791606903, -0.7921349406242371, 0.2670857906341553, -0.29195743799209595, -0.6064807772636414, -0.4512982666492462, 0.04139000549912453, 0.48106199502944946, 0.12442682683467865, 0.5447008609771729, -0.09869174659252167, 0.550329327583313, 0.16937094926834106, -0.11796995252370834, 0.13603366911411285, 0.7220708131790161, 0.14343588054180145, 0.3325462341308594, -0.11517670005559921, 0.40047913789749146, -0.23801878094673157, 0.45307621359825134, -0.0917125940322876, -0.2958258390426636, -0.43953901529312134, -0.08067623525857925, 0.31856852769851685, 0.7477651238441467, 0.7834812998771667, 0.16257016360759735, 0.10715392231941223, 0.4840758740901947, 0.7208375930786133, 0.22144851088523865, -0.026182547211647034, -0.2976389229297638, 0.35302722454071045, -0.0990346372127533, 0.2188611924648285, 0.695298433303833, -0.062151048332452774, -0.21400569379329681, -1.0073738098144531, -0.1500752568244934, 0.6302141547203064, -1.0680863857269287, -0.5238661766052246, 1.2650253772735596, -0.3949972987174988, -0.30147409439086914, -0.2065591961145401, -0.4007665514945984, -0.5395239591598511, 0.3976413607597351, -1.1219396591186523, -0.5429807901382446, -0.22679917514324188, -0.4058719873428345, -0.1106720045208931, -0.004492749460041523, 0.8858882188796997, -0.2982781231403351, -0.39851778745651245, 0.02470555528998375, -0.32785913348197937, -0.10356274992227554, -0.5555569529533386, -0.8675801753997803, 0.8959330320358276, 0.07998078316450119, -0.17556129395961761, 0.5845975279808044, 0.26491299271583557, 0.19105085730552673, -0.6631214022636414, -0.04720735177397728, 0.9474053382873535, -0.9033776521682739, -0.07228869944810867, -0.7383859753608704, -1.206130862236023, 0.696143388748169, 0.552891731262207, -0.22935254871845245, 0.12488552182912827, 0.3239140510559082, -0.6305942535400391, -0.1425328552722931, -0.5043333768844604, 0.13074679672718048, 0.8466061949729919, -0.891808032989502, -0.3968343734741211, -0.5715510249137878, 0.3885763883590698, -0.6897552609443665, -0.3867894113063812, -0.3243056535720825, 0.18194353580474854, -0.24643468856811523, 0.6142791509628296, -0.6894172430038452, 0.366347074508667, 0.7198671698570251, 0.26149240136146545, -0.6212338209152222, -0.6829397678375244, -1.0527902841567993, 0.112629733979702, 0.6289609670639038, 0.4459259808063507, -0.3717300593852997, 0.47469979524612427, 0.9086927771568298, -0.025650853291153908, -0.13492459058761597, -0.5806484222412109, -0.12591122090816498, -0.4364780783653259, -0.3912487328052521, 0.1457519680261612, 0.043897323310375214, 0.14749743044376373, 0.1796722114086151, 0.455911785364151, 0.5879611968994141, 0.18848933279514313, -0.867992639541626, 0.13510456681251526, -0.3485701084136963, 0.5848672389984131, -0.8160708546638489, -0.40938326716423035, -1.211477518081665, -0.010179651901125908, -0.9226299524307251, 0.1851302683353424, -1.2242836952209473, -0.5546802878379822, 0.059921666979789734, -0.5710233449935913, 0.022898178547620773, 0.3042004406452179, -0.6223517060279846, -0.33754149079322815, -0.4022389054298401, -0.7503977417945862, 0.5673141479492188, 0.6209831237792969, -0.5416147112846375, -0.04312241077423096, 0.2005091905593872, -0.2878871560096741, 0.3017752468585968, 0.4275455176830292, -0.38057124614715576, -0.4415709674358368, -1.140411376953125, 0.34909629821777344, 0.11297180503606796, -0.022877532988786697, -0.6250751614570618, 1.3648979663848877, 0.5058327913284302, -0.18388661742210388, -0.27974894642829895, 0.2569904923439026, -0.7753036022186279, -0.2465633749961853, 0.3102838099002838, -0.8942214250564575, 0.37731367349624634, 0.2515753507614136, -0.4795469045639038, -0.2669033110141754, 0.7005331516265869, -0.18991361558437347, -1.274802803993225, -0.8698673844337463, 0.29234156012535095, -0.8764852285385132, -0.23453660309314728, -0.27614831924438477, -0.5000068545341492, -0.6992929577827454, -0.174570694565773, -0.049024224281311035, 0.6928373575210571, -0.5897844433784485, 1.2444684505462646, 0.36532390117645264, -1.0466406345367432, -0.028049377724528313, 0.2708303928375244, -0.16027623414993286, -0.11010286957025528, 0.8503946661949158, 0.17833849787712097, 0.07637684792280197, 0.5025596022605896, 0.2072862982749939, 0.12993092834949493, -1.0374287366867065, 0.04583467170596123, 1.0411186218261719, -0.30244559049606323, -0.24165888130664825, 0.7640231251716614, -0.11060167849063873, -0.7417480945587158, 0.1861559897661209, -0.9216119647026062, -0.8560643792152405, 0.30611148476600647, 0.8284404277801514, 0.46362826228141785, -0.33229300379753113, -0.08651837706565857, -0.5921286940574646, 0.3128631114959717, -0.7330688834190369, -0.41902515292167664, 0.4463413655757904, -0.2760500907897949, -0.48065778613090515, 1.0272175073623657, 0.24504916369915009, -0.7495860457420349, -0.7453481554985046, -0.8227723836898804, 0.17260973155498505, 0.02167060226202011, 0.2635490894317627, -0.15931321680545807, -0.22267058491706848, 0.7140014171600342, 0.3643524646759033, 0.6123112440109253, -0.21647264063358307, -0.10337864607572556, -0.5674421787261963, 0.31226837635040283, 0.28777840733528137, -0.3046320974826813, -0.5029241442680359, 1.514394998550415, 1.628648042678833, -0.24132315814495087, -0.14571526646614075, -0.43245983123779297, -0.7874709367752075, 0.6872678995132446, 0.45406413078308105, -0.26364776492118835, 0.6927788853645325, -0.3754701614379883, 0.26602688431739807, 0.13872861862182617, -1.4685559272766113, -0.3790016770362854, 0.5243512392044067, 1.076195478439331, 0.8531898260116577, -0.05896124988794327, 0.5297342538833618, 0.679686963558197, 0.10779471695423126, 0.2276238054037094, 0.6123464107513428, 0.06095384806394577, -0.36059439182281494, 0.34204044938087463, 0.3268158435821533, 0.25908994674682617, -0.6176409721374512, -0.4371064305305481, 0.07569828629493713, 0.4620778262615204, -0.33219146728515625, 0.477167546749115, 1.3915082216262817, 0.04617943614721298, 0.9604333639144897, 0.2775411903858185, 0.4473852813243866, -0.5492430925369263, -0.611023485660553, -0.3049507737159729, -0.42355942726135254, -0.2406313121318817, -0.2492600530385971, -1.0082019567489624, -0.25046539306640625, 0.14225910604000092, 0.1308213472366333, 0.17385880649089813, 0.21084599196910858, 0.7455376386642456, 0.7237248420715332, 0.613135814666748, 0.14097967743873596, -0.4859042763710022, -0.36087432503700256, -1.0917550325393677, 0.23564517498016357, -0.6598075032234192, 0.132085382938385, -0.11690611392259598, -0.10164943337440491, -0.5516220331192017]}, "authors": [{"authorId": "3092435", "name": "Da Ju"}, {"authorId": "3849208", "name": "Stephen Roller"}, {"authorId": "2265067", "name": "Sainbayar Sukhbaatar"}, {"authorId": "145183709", "name": "J. Weston"}], "references": [{"paperId": "86589b6286ef3c55b8b4fccfb41a3b30b7afdf61", "title": "Going Beyond Linear Transformers with Recurrent Fast Weight Programmers"}, {"paperId": "b15ea460c77a4ee8aa159a30ab0331deedfcf392", "title": "BASE Layers: Simplifying Training of Large, Sparse Models"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "9b539d413393047b28bb7be9b195f142aaf7a80e", "title": "Recipes for Building an Open-Domain Chatbot"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "42b0d32a7e644b657e34ce056c84d215d9f62187", "title": "Universal"}, {"paperId": "1a6f4495474f75ae1e8bbf407f70d9a874e5b4d6", "title": "The Pushshift Reddit Dataset"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "3ff8d265f4351e4b1fdac5b586466bee0b5d6fff", "title": "Improving Transformer Models by Reordering their Sublayers"}, {"paperId": "11abce981e90585c142078b5c64b2cb8331b8794", "title": "The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded Conversational Agents"}, {"paperId": "6fec3e579c7cd4f13bdabbee2b6ac2e8ff5941c6", "title": "Unsupervised Cross-lingual Representation Learning at Scale"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "75acc731bdd2b626edc74672a30da3bc51010ae8", "title": "CTRL: A Conditional Transformer Language Model for Controllable Generation"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "81e1d123a85562555befb0243256b1a0d9fca014", "title": "Understanding and Improving Transformer From a Multi-Particle Dynamic System Point of View"}, {"paperId": "f4238bd2385a52413ccbacfd9e409a650235bd13", "title": "Adaptive Attention Span in Transformers"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "301e13f3df8f9dfb79ea782da3693e2942392279", "title": "Poly-encoders: Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring"}, {"paperId": "528b5f5356bc7ad91edc4dc074b0273e1e55fb03", "title": "Modeling Recurrence for Transformer"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "dde89e64a7f375b90e1cc594142940f4161e1592", "title": "Training Millions of Personalized Dialogue Agents"}, {"paperId": "b9de9599d7241459db9213b5cdd7059696f5ef8d", "title": "Character-Level Language Modeling with Deeper Self-Attention"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "bb669de2fce407df2f5cb2f8c51dedee3f467e04", "title": "The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation"}, {"paperId": "245b03b60cb4bf0235109af4e48f958fbab03b34", "title": "Learning Semantic Textual Similarity from Conversations"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e", "title": "End-To-End Memory Networks"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "6c2b28f9354f667cd5bd07afc0471d8334430da7", "title": "A Neural Probabilistic Language Model"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "668087f0ae7ce1de6e0bd0965dbb480c08103260", "title": "Finding Structure in Time"}, {"paperId": null, "title": "Addressing some limitations of transformers with feedback memory"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Large text compression benchmark"}, {"paperId": "9819b600a828a57e1cde047bbe710d3446b30da5", "title": "Recurrent neural network based language model"}]}