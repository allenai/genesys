{"paperId": "0938d0ccc1c633fa0f8c067d914358b1ef53a44b", "title": "Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense Video Captioning", "abstract": "In this work, we introduce Vid2Seq, a multi-modal single-stage dense event captioning model pretrained on narrated videos which are readily-available at scale. The Vid2Seq architecture augments a language model with special time tokens, allowing it to seamlessly predict event boundaries and textual descriptions in the same output sequence. Such a unified model requires large-scale training data, which is not available in current annotated datasets. We show that it is possible to leverage unlabeled narrated videos for dense video captioning, by reformulating sentence boundaries of transcribed speech as pseudo event boundaries, and using the transcribed speech sentences as pseudo event captions. The resulting Vid2Seq model pretrained on the YT-Temporal-1B dataset improves the state of the art on a variety of dense video captioning benchmarks including YouCook2, ViTT and ActivityNet Captions. Vid2Seq also generalizes well to the tasks of video paragraph captioning and video clip captioning, and to few-shot settings. Our code is publicly available at [1].", "venue": "Computer Vision and Pattern Recognition", "year": 2023, "citationCount": 109, "influentialCitationCount": 13, "openAccessPdf": {"url": "https://arxiv.org/pdf/2302.14115", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "Vid2Seq is introduced, a multi-modal single-stage dense event captioning model pretrained on narrated videos which are readily-available at scale and improves the state of the art on a variety of dense video captioning benchmarks including YouCook2, ViTT and ActivityNet Captions."}, "embedding": {"model": "specter_v2", "vector": [0.21539847552776337, 0.8529314398765564, -0.19567888975143433, -0.1821863204240799, -0.47402244806289673, -0.45038166642189026, 1.2361723184585571, -0.19587048888206482, -0.22866962850093842, -0.07132100313901901, 1.4234265089035034, 0.5252464413642883, 0.878329873085022, 0.4313380718231201, -0.13493120670318604, 0.27829599380493164, -1.0833138227462769, 0.23316718637943268, 0.23706360161304474, -0.35120025277137756, -0.3723962903022766, -0.9663142561912537, -0.9069868326187134, 0.5742405652999878, -0.030715961009263992, 0.5173230767250061, 0.13327369093894958, 1.1225401163101196, -0.4100762903690338, 0.6160975694656372, -0.08576898276805878, -0.03634520247578621, 0.04211556538939476, -0.47596311569213867, -0.3148137629032135, 0.060418739914894104, 0.3154526650905609, -0.7583547234535217, -0.8239977955818176, 0.2745279371738434, -0.2399359494447708, 0.31589794158935547, 0.7165456414222717, -0.7024155259132385, -0.07670510560274124, 0.794253945350647, 0.5895615816116333, 0.604439377784729, 0.19903555512428284, -0.9950495958328247, 1.4152183532714844, -1.2414586544036865, 0.7217621803283691, 1.4264401197433472, 0.1656504124403, 0.6324366927146912, 0.10571490228176117, -0.30319851636886597, 1.1088933944702148, 0.1792934238910675, -0.48903030157089233, -0.08518332988023758, -0.025245577096939087, -0.44849923253059387, 1.1654465198516846, -0.345403254032135, 0.29608091711997986, 1.4896906614303589, -0.5062075257301331, 1.5352901220321655, -0.671924889087677, -0.45679301023483276, -0.24974873661994934, 0.07220616936683655, 0.05091806873679161, 0.3522856533527374, -0.7906206846237183, 0.3765234053134918, -0.8267216086387634, 0.2600727379322052, 0.2668834924697876, 0.07695486396551132, -0.47631651163101196, -0.09130274504423141, -0.42915257811546326, 0.6962341070175171, 0.457363486289978, 0.9072349667549133, 0.03706171363592148, 0.6196755170822144, 0.8716965317726135, -0.07398762553930283, 0.11350325495004654, -0.006409839261323214, 0.2214144766330719, 0.021912159398198128, -0.9165536165237427, 0.23785339295864105, 0.08361030369997025, 1.091203212738037, -0.7890391945838928, 0.09494384378194809, -1.2493828535079956, 0.13265682756900787, 1.0472157001495361, -0.254142701625824, 0.15603138506412506, -0.9003321528434753, 0.2196611613035202, -1.136081576347351, 0.5641814470291138, -0.7832792401313782, -0.003858741605654359, 0.10603845119476318, -0.5440513491630554, -1.2831307649612427, -0.3664875626564026, -0.043685637414455414, -1.073102355003357, 0.8014543652534485, -0.34917351603507996, 0.45766496658325195, 0.16596779227256775, 0.4734213054180145, 1.1498388051986694, 1.2142854928970337, 0.13951273262500763, -0.22910316288471222, 0.9579079747200012, -1.1029325723648071, -1.1506249904632568, -1.1500294208526611, 0.3332836925983429, 0.17520791292190552, -0.15278564393520355, -0.29003795981407166, -0.9430155158042908, -0.8675689697265625, -0.9718151092529297, -0.12588456273078918, -0.2733140289783478, 0.18350128829479218, 0.7325422763824463, 0.03652409836649895, -1.0737640857696533, 0.5552843809127808, -0.1559731513261795, -0.48776334524154663, 0.44993606209754944, -0.6109238266944885, 0.027483796700835228, -0.2850130796432495, -1.225376844406128, 0.20877844095230103, -0.1083676889538765, -0.4970760941505432, -0.526972770690918, -0.45254287123680115, -1.535394549369812, -0.4347599446773529, 0.21775110065937042, 0.0925913080573082, 1.5941798686981201, -0.5465529561042786, -0.8527348041534424, 0.9033320546150208, -0.6675696969032288, -0.2627016007900238, 0.7337424159049988, -0.3772982954978943, -0.6218035817146301, 0.3256998360157013, -0.0843968465924263, 0.9537785649299622, 0.3543080687522888, -0.23554553091526031, -0.09633397310972214, 0.32097527384757996, -0.3527078926563263, 0.0009104140335693955, -0.19743216037750244, 1.0339409112930298, -0.7832309007644653, -0.3259928822517395, -0.2687312960624695, 0.8605675101280212, 0.4379105269908905, 0.12591935694217682, -0.05902852863073349, -0.7611238360404968, 1.1694718599319458, -0.20186971127986908, 0.6104564666748047, -1.2269254922866821, -0.5432485938072205, -0.8281868696212769, -0.026930030435323715, -0.1086767166852951, -0.9512709975242615, 0.6291701197624207, -0.21793194115161896, 0.17244134843349457, 0.03855239972472191, -1.4722040891647339, -0.12764470279216766, -0.1100807934999466, -0.6698881983757019, -0.1652994006872177, 0.35951998829841614, 1.1980856657028198, -0.9008469581604004, -0.39044255018234253, -0.044530585408210754, 0.313017874956131, -0.7999277114868164, 1.4815759658813477, -0.8054969906806946, 0.28044259548187256, -0.3535461723804474, -0.332742840051651, -0.1010209247469902, -0.10500381141901016, 0.6305394768714905, -0.5058656334877014, -0.16241472959518433, 0.23906297981739044, -0.23781314492225647, 1.4766541719436646, 0.2925673723220825, 1.0865031480789185, 0.06322672963142395, -0.9120209813117981, 0.45437756180763245, 0.8452154994010925, -0.030890218913555145, -0.43382760882377625, 0.44359350204467773, -0.07651135325431824, -1.4082584381103516, -0.3880014419555664, 0.641269326210022, 0.7711479663848877, -0.46799805760383606, -0.22584213316440582, 0.45948341488838196, -0.1375947892665863, 0.3625114858150482, 1.001137375831604, 0.8210535645484924, 0.6622319221496582, 0.12277067452669144, 0.49404177069664, -0.09874995797872543, -0.6117607355117798, 0.02350478433072567, 0.35613706707954407, 0.1636364758014679, 1.5483498573303223, 1.005813717842102, -0.6228329539299011, -0.6540000438690186, 0.05064985901117325, 0.9273782968521118, 0.9469684362411499, 0.10096848756074905, -0.12008191645145416, -0.7586601376533508, -0.33062243461608887, -0.3927559554576874, -0.07594408839941025, -0.8298407196998596, 0.11149422079324722, -0.5427147746086121, -0.18501588702201843, 0.7055442929267883, 0.6976261734962463, 0.8859725594520569, -0.8537783622741699, -0.06087099760770798, -0.402089387178421, -0.3125331699848175, -1.1893298625946045, -0.9396399259567261, 0.19123370945453644, -0.03182420879602432, -0.17712673544883728, -0.41166630387306213, -0.5528067946434021, 0.04616750776767731, -0.6641169786453247, 1.057256817817688, -0.6358128190040588, -0.35981497168540955, 0.3576478064060211, -0.05603057146072388, -0.4144722819328308, -0.7508209943771362, -0.3685567378997803, 0.08269192278385162, -0.07653333246707916, 0.17804402112960815, 0.5024808049201965, 0.1814473569393158, -0.022531019523739815, -0.5417245030403137, 0.607842743396759, -0.28946229815483093, -0.029666315764188766, 0.5428729057312012, -0.7725172638893127, 0.4097047746181488, -0.6807975172996521, 0.383573979139328, -0.114320769906044, -0.2099556177854538, -0.012881199829280376, 0.20750702917575836, -0.6419135928153992, 0.26240307092666626, -0.6416000127792358, -0.41850578784942627, -0.6932544112205505, 0.5312978625297546, -0.6075001358985901, -0.5963186025619507, 0.2145083248615265, 0.35182812809944153, 1.0086381435394287, 0.24585776031017303, 0.08545523881912231, 0.3405589163303375, -0.007942008785903454, 0.6710399985313416, -0.5603904724121094, 1.1044265031814575, 0.6388856768608093, 0.16188256442546844, 0.10568743199110031, -0.44120004773139954, -0.8056215047836304, -0.7638004422187805, -0.6438118815422058, -0.5135436058044434, -0.949546754360199, 0.9312968254089355, -0.9457086324691772, -0.5356817841529846, -0.2220291942358017, -1.4832513332366943, -0.2210748791694641, 0.1630169153213501, -0.27625322341918945, -0.2979307770729065, -0.703521192073822, -0.8888869881629944, -0.70583575963974, -0.3251548409461975, -0.3325275480747223, 0.3572666645050049, 0.44607123732566833, -0.5825679898262024, -0.5205655097961426, 0.17788748443126678, -0.19794537127017975, 0.316067636013031, 0.3262355327606201, 0.24338309466838837, -0.2133464217185974, -0.07888493686914444, -0.6242676973342896, 0.29581621289253235, 0.5312595367431641, -0.32067835330963135, 0.3589939475059509, -0.6483974456787109, 0.33210429549217224, -0.588786780834198, -0.43877115845680237, 0.3362914025783539, 0.46698084473609924, 0.22644060850143433, 0.40632790327072144, -0.5177534818649292, 0.2655129134654999, 1.0243040323257446, -0.3312073051929474, -0.027639953419566154, -0.17878955602645874, 0.56410151720047, 0.38332217931747437, 0.15085366368293762, 0.8216877579689026, 0.2995450496673584, 0.4903189539909363, 0.4368569850921631, -0.2969699800014496, -0.24265165627002716, -0.9053223729133606, 0.7640700936317444, 0.9221751689910889, 0.45880210399627686, -0.3287580609321594, -0.8712270855903625, 1.280771255493164, -1.3319423198699951, -1.1293067932128906, 0.47931212186813354, 0.29278331995010376, 0.0016633633058518171, -0.5942319631576538, 0.0989750325679779, -0.38737425208091736, 0.8991004824638367, 0.6314548254013062, -0.281474769115448, -0.588685929775238, -0.15635527670383453, -0.08143370598554611, -0.4540991187095642, 0.48793521523475647, -0.7035699486732483, 0.24009796977043152, 14.480380058288574, 0.110155388712883, 0.23894533514976501, 0.25754469633102417, 0.6873858571052551, -0.20027737319469452, -0.3607674539089203, -0.5411117672920227, -0.9000508785247803, -0.25078532099723816, 1.29214608669281, 0.3538995683193207, 0.3065461218357086, -0.030747190117836, 0.6494901180267334, 0.16973784565925598, -0.8534063696861267, 0.8246818780899048, 0.8845728039741516, -1.4439749717712402, 0.06048029288649559, -0.032148391008377075, 0.2117377072572708, 0.5253764390945435, 0.7109171152114868, 0.9523094296455383, -0.036631952971220016, -0.26140838861465454, 0.8617981672286987, 0.05795465409755707, 1.0901540517807007, 0.039397768676280975, 0.3610323667526245, 0.2824988067150116, -0.9720984697341919, -0.2732384502887726, -0.23292410373687744, -1.0116784572601318, 0.8417675495147705, -0.4825085997581482, -0.49110400676727295, -0.22145915031433105, 0.03934156522154808, 1.1179214715957642, 0.42591777443885803, 0.22576478123664856, -0.15123026072978973, 0.6780959367752075, 0.28037893772125244, -0.3672768175601959, 0.7626991271972656, 0.3970160484313965, 0.509888768196106, 0.10923312604427338, 0.05549918860197067, 0.6382640600204468, -0.11765933781862259, 0.6027334332466125, -0.4860159754753113, -0.24245907366275787, -0.7881426215171814, -0.5892688035964966, -0.19611462950706482, 0.6245496273040771, 0.3755303621292114, 0.1551760584115982, -0.8144687414169312, 0.6931769251823425, 0.1993323117494583, 0.23791992664337158, -0.6730050444602966, 0.15901197493076324, 0.2957458794116974, -0.0010773296235129237, 0.4298831820487976, 0.44575783610343933, 0.3140011429786682, -0.637649655342102, -0.5777782201766968, 0.09477085620164871, 0.5039817094802856, -1.245571494102478, -0.7008756399154663, 1.0143991708755493, -0.00905761681497097, -0.8743635416030884, -0.22773957252502441, -0.504114031791687, -0.6550270915031433, 0.0929127186536789, -1.143048882484436, -0.38929858803749084, -0.5806087255477905, -0.09557490795850754, -0.1291579008102417, 0.2095279097557068, 1.1929423809051514, 0.10772495716810226, -0.16194723546504974, -0.10365083068609238, 0.16460993885993958, 0.3995108902454376, 0.09416638314723969, -0.754920482635498, 0.6075047850608826, 0.14048786461353302, -0.08110605180263519, -0.9087428450584412, 0.3417157232761383, -0.07319439202547073, -0.48442068696022034, -0.33888232707977295, 0.5608277320861816, -0.7511290907859802, -0.3977240324020386, -0.9694914817810059, -0.7879117727279663, 0.33203744888305664, 0.7157320976257324, 0.05908525362610817, 0.3037186563014984, -0.12607230246067047, -0.5048238039016724, 0.14282019436359406, -0.8553078770637512, -0.029419315978884697, 0.23676836490631104, -0.4911938011646271, -0.7046541571617126, 0.10782880336046219, 0.928722620010376, -0.8044557571411133, -0.13965997099876404, -0.507112979888916, -0.09545494616031647, -0.2039732038974762, 0.6884476542472839, -0.3803211748600006, 0.8512210845947266, 0.8474891781806946, -0.19911663234233856, -0.7040578722953796, 0.18947891891002655, -0.9484214782714844, -0.17571833729743958, 0.4837357699871063, 0.30459290742874146, 0.46518802642822266, 0.42125293612480164, 0.5329337120056152, 0.04981282725930214, -0.20714391767978668, -0.45889222621917725, -0.19618062674999237, 0.011814549565315247, -0.40731093287467957, -0.29903116822242737, -0.14507029950618744, 0.20200209319591522, 0.21471242606639862, 0.0055442382581532, 0.49790769815444946, -0.43675127625465393, -0.9263125061988831, 0.42636510729789734, -0.09741822630167007, 0.09748738259077072, -0.16033492982387543, -0.6670305728912354, -1.4214446544647217, -0.1132199689745903, -0.8827327489852905, 0.22149792313575745, -1.3682386875152588, -0.18531553447246552, 1.016795039176941, 0.07353327423334122, 0.07736573368310928, 0.6030856966972351, -0.22398707270622253, -0.03830539435148239, -0.8352482318878174, -0.898956298828125, 1.0512117147445679, 1.096281886100769, -0.7839860320091248, -0.08614504337310791, -0.5361034274101257, 0.15338030457496643, 0.17529498040676117, 0.08515498787164688, -0.013194293715059757, -0.6104660034179688, -1.0330793857574463, -0.02470691315829754, 0.37874072790145874, 0.13538242876529694, -0.9192315936088562, 0.05422522872686386, 0.7445264458656311, 0.02118133008480072, -0.6527715921401978, 0.8278465867042542, -0.664395272731781, -0.5999394655227661, -0.1686515063047409, -0.9496468901634216, -0.19833336770534515, 0.3723257780075073, -0.0063064200803637505, -0.8012511730194092, 0.9550673365592957, -0.033150605857372284, -0.7271394729614258, -0.8989931344985962, 0.5611010789871216, -0.589048445224762, 0.24344530701637268, 0.43093517422676086, -0.23460732400417328, -1.0107778310775757, -0.9943990707397461, -0.47297292947769165, 0.6688056588172913, -0.6486800312995911, 1.4890300035476685, 0.5405862927436829, -1.3282291889190674, -0.35578131675720215, -0.0676368921995163, 0.2109915167093277, 0.20088785886764526, 0.6073724031448364, 0.15054193139076233, -0.19338463246822357, 0.5237318873405457, 0.2511839270591736, 0.26359161734580994, -0.8982309103012085, 0.25872987508773804, 0.9427025318145752, 0.05904119089245796, -0.6381158232688904, 1.1939537525177002, -0.0731457844376564, -0.4328717887401581, 0.8158957958221436, -0.8845096826553345, -1.133969783782959, 0.3374035358428955, 1.1032768487930298, -0.39940208196640015, -0.4286419153213501, -0.38039571046829224, -0.43931448459625244, 0.10471760481595993, -0.05067542567849159, -0.7589285969734192, 0.8165530562400818, -0.18292073905467987, 0.26966041326522827, 0.8448821902275085, 1.2363777160644531, -1.0978342294692993, -1.25368070602417, -0.5160726308822632, -0.7010404467582703, 0.28646066784858704, 0.08850055932998657, -0.6682719588279724, -0.5623415112495422, 0.8156324028968811, 0.5374311208724976, 0.47978973388671875, 0.22823145985603333, 0.4473094046115875, 0.20455223321914673, 0.2333287000656128, -0.35149145126342773, -0.7308829426765442, 0.02531101368367672, 1.2810901403427124, 1.5328798294067383, -0.7062796950340271, -0.12804213166236877, -0.010461616329848766, -1.0297726392745972, 0.654135525226593, 0.2819295823574066, 0.005468904506415129, 0.8799086809158325, -0.316483736038208, 0.1328287422657013, 0.30982616543769836, -1.2305163145065308, 0.03874608129262924, 0.5376878380775452, 1.405881404876709, 0.672187864780426, 0.3519235849380493, -0.008007961325347424, 1.0461820363998413, 0.4611654281616211, 0.0832889974117279, 0.7124000787734985, 0.1745387464761734, -0.15530240535736084, 0.14437124133110046, 0.17036765813827515, 0.3976445496082306, -0.37206393480300903, -0.06998224556446075, -0.21449914574623108, 0.2804977297782898, 0.05437371879816055, 0.8480143547058105, 1.2827636003494263, 0.15082338452339172, 0.6159974932670593, 0.20854303240776062, 0.34843549132347107, -0.6492501497268677, -0.14993615448474884, -0.0817471593618393, -0.3264673054218292, -0.30623337626457214, -0.3883726894855499, -1.118041753768921, -0.7199370265007019, 0.052659764885902405, 0.8962149024009705, 0.051880545914173126, 0.12593844532966614, 1.3117685317993164, 0.5475830435752869, 0.557405948638916, -0.39241278171539307, -0.6414580345153809, 0.1675475686788559, -1.1084502935409546, -0.17344459891319275, -0.5069082975387573, 0.19459562003612518, -0.30470961332321167, -0.27536913752555847, -0.03167455270886421]}, "authors": [{"authorId": "2064599701", "name": "Antoine Yang"}, {"authorId": "19263506", "name": "Arsha Nagrani"}, {"authorId": "14454974", "name": "P. H. Seo"}, {"authorId": "19200186", "name": "Antoine Miech"}, {"authorId": "1403171438", "name": "J. Pont-Tuset"}, {"authorId": "143991676", "name": "I. Laptev"}, {"authorId": "1782755", "name": "Josef Sivic"}, {"authorId": "2462253", "name": "C. Schmid"}], "references": [{"paperId": "6ac5e4c7d148634ae994c7854e18c04a4da6bcf0", "title": "Long-Form Video-Language Pre-Training with Multimodal Temporal Contrastive Learning"}, {"paperId": "46cb539b7480a909954e62a706b5a2afcb612915", "title": "Contrastive Video-Language Learning with Fine-grained Frame Sampling"}, {"paperId": "dd53d8ad6dfc9df7af899c0b36b62feff64b8eb8", "title": "Obj2Seq: Formatting Objects as Sequences with Class Prompt for Visual Tasks"}, {"paperId": "28630034bb29760df01ab033b743e30b37f336ae", "title": "PaLI: A Jointly-Scaled Multilingual Language-Image Model"}, {"paperId": "31ec2df38b42d7f3999936572726461dfc1a1657", "title": "LocVTP: Video-Text Pre-training for Temporal Localization"}, {"paperId": "1cc80b8e01b129a25face308bbf1f6741bad1e4d", "title": "Unifying Event Detection and Captioning as Sequence Generation via Pre-Training"}, {"paperId": "2c0dd871b67bad56b35e227286f755be6d7735a4", "title": "Label2Label: A Language Modeling Framework for Multi-Attribute Learning"}, {"paperId": "a970c8fadef8497576660b288c52c0ec8eebdc12", "title": "Zero-Shot Video Question Answering via Frozen Bidirectional Language Models"}, {"paperId": "4c559d29e19f1226353f52ffe9f8068db1cef943", "title": "Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone"}, {"paperId": "06761cb27e14aa55a6c3d98b949898aa26416698", "title": "A Unified Sequence Interface for Vision Tasks"}, {"paperId": "49b5ffebdbcbd683010a2558a19eaa9b21cd8c34", "title": "GLIPv2: Unifying Localization and Vision-Language Understanding"}, {"paperId": "87fadaab89b05f1b2abadfbdf8176af5f90b73f1", "title": "Egocentric Video-Language Pretraining"}, {"paperId": "055cd2faeebc7a9df43923d554a61ae924a4af6b", "title": "UViM: A Unified Modeling Approach for Vision with Learned Guiding Codes"}, {"paperId": "fd415ecea64cd56f818a18fd4660e65c2dc10f53", "title": "Learning to Answer Visual Questions from Web Videos"}, {"paperId": "a26a7a74f1e5fd562be95c3611a0680759fbdf84", "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "3463596216795978c520707ad9a9ff5d19a5236f", "title": "Contrastive Language-Action Pre-training for Temporal Localization"}, {"paperId": "751b7e1d3c94ad8afaed5668f1bcc72a1406f42a", "title": "End-to-end Dense Video Captioning as Sequence Generation"}, {"paperId": "0e76cf252fcc119ad87d336d439e667a9200a05c", "title": "Temporal Alignment Networks for Long-term Video"}, {"paperId": "020edd629773e27936b37934ef237ac879f23207", "title": "TALLFormer: Temporal Action Localization with Long-memory Transformer"}, {"paperId": "aa1b722485106c84e52c5e35b2d4b2f8c7fb3135", "title": "Learning Audio-Video Modalities from Image Captions"}, {"paperId": "74adce30fb1812a4a2c7e65f06ed99ad36159d6d", "title": "Video-Text Representation Learning via Differentiable Weak Temporal Alignment"}, {"paperId": "add12473900be92c3ff36d07585011ec33e0a736", "title": "SeqTR: A Simple yet Universal Network for Visual Grounding"}, {"paperId": "9d4eb3a74c3b3cd196834e7cb04b6a0871cdf13d", "title": "TubeDETR: Spatio-Temporal Video Grounding with Transformers"}, {"paperId": "095ccdb08837a4b44a62638fb8dc391818707e5a", "title": "All in One: Exploring Unified Video-Language Pre-Training"}, {"paperId": "58a3fedc03ab9f5908c077c115eff4c8d2d87660", "title": "ActionFormer: Localizing Moments of Actions with Transformers"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "e8a72d29771d1a33b4a0e43c74adcee6c73d74c7", "title": "End-to-end Generative Pretraining for Multimodal Video Captioning"}, {"paperId": "2711962702dc65deb0b75bac37f971c64364b125", "title": "Bridging Video-text Retrieval with Multiple Choice Questions"}, {"paperId": "400d619cbabeb669115bb7281a889ab869829ef5", "title": "MERLOT RESERVE: Neural Script Knowledge through Vision and Language and Sound"}, {"paperId": "80ea0e2882db3347b4fbc83f1a55c6a93e0d9272", "title": "Align and Prompt: Video-and-Language Pre-training with Entity Prompts"}, {"paperId": "2fd6f77540c1cc8e70b96208ccf9971b4251fc02", "title": "FLAVA: A Foundational Language And Vision Alignment Model"}, {"paperId": "5341b412383c43f4a693ad63ec4489e3ec7688c8", "title": "Grounded Language-Image Pre-training"}, {"paperId": "2299c08033af3e2f7d1f6a958aadb15f10ddd0ef", "title": "Object-aware Video-language Pre-training for Retrieval"}, {"paperId": "cbdd3e2fcfd85d546f3ab18f644434097baa7590", "title": "SwinBERT: End-to-End Transformers with Sparse Attention for Video Captioning"}, {"paperId": "3ea60cbce6c9065661d207fccf021c5d58a83f01", "title": "Scaling Up Vision-Language Pretraining for Image Captioning"}, {"paperId": "ba9d736006b897d06f75586ad46e28e00a5e566e", "title": "VIOLET : End-to-End Video-Language Transformers with Masked Visual-token Modeling"}, {"paperId": "21ec90872abd986c12afe39bebe807732ffa70c9", "title": "Florence: A New Foundation Model for Computer Vision"}, {"paperId": "da4261a957eaa96bf626e9641ef68ebed1d5333f", "title": "RedCaps: web-curated image-text data created by the people, for the people"}, {"paperId": "e1a3e6856b6ac6af3600b5954392e5368603fd1b", "title": "Advancing High-Resolution Video-Language Representation with Large-Scale Video Transcriptions"}, {"paperId": "c05cd00ae61f3c1c39be2603a2f96fdfe0c59dd8", "title": "UFO: A UniFied TransfOrmer for Vision-Language Representation Learning"}, {"paperId": "94ff111c4d81bd03f159321728ceec8b4711c89d", "title": "An Empirical Study of Training End-to-End Vision-and-Language Transformers"}, {"paperId": "b8cb9c0b02da96a9908665ae67692a6da4dd25a4", "title": "SCENIC: A JAX Library for Computer Vision Research and Beyond"}, {"paperId": "821ad6c9f0fecb5fabb486a5a87a93b7ea65bcc0", "title": "VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding"}, {"paperId": "19b3b074d38b250d024920732ae51a8ffa0996dd", "title": "Pix2seq: A Language Modeling Framework for Object Detection"}, {"paperId": "5e00596fa946670d894b1bdaeff5a98e3867ef13", "title": "SimVLM: Simple Visual Language Model Pretraining with Weak Supervision"}, {"paperId": "e79be3f9ce409f1a9b7084ef880298665e5212d0", "title": "TACo: Token-aware Cascade Contrastive Learning for Video-Text Alignment"}, {"paperId": "76e64bb7cd283d448740dc1dafb9be69cc34765b", "title": "End-to-End Dense Video Captioning with Parallel Decoding"}, {"paperId": "b82c5f9efdb2ae56baa084ca41aeddd8a665c1d1", "title": "Align before Fuse: Vision and Language Representation Learning with Momentum Distillation"}, {"paperId": "01b5412f3d17e90e09226d7c40ad4d4468a1414d", "title": "Multimodal Few-Shot Learning with Frozen Language Models"}, {"paperId": "cf5e6e3c50a798d87033e0e108e88b3647738bbe", "title": "How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers"}, {"paperId": "2f5f8e60a1c8cea0a0ba669305f0020854549ddd", "title": "End-to-End Temporal Action Detection With Transformer"}, {"paperId": "70b4c724a0f22198f9a04f504b1b298299e4cc37", "title": "VALUE: A Multi-Task Benchmark for Video-and-Language Understanding Evaluation"}, {"paperId": "90357a6dc817e2f7cec477a51156675fbf545cf1", "title": "MERLOT: Multimodal Neural Script Knowledge Models"}, {"paperId": "bc320788232352b9b245b4e8271e492964cb1620", "title": "Sketch, Ground, and Refine: Top-Down Dense Video Captioning"}, {"paperId": "1704633966c5400edc3e085102538c01d2eff9d2", "title": "Towards Bridging Event Captioner and Sentence Localizer for Weakly Supervised Dense Event Captioning"}, {"paperId": "7ba9c013988eaff5cd186d73704af329d027872d", "title": "MDETR - Modulated Detection for End-to-End Multi-Modal Understanding"}, {"paperId": "f0524b3005720bcff886bcb0227f7f0dd924ff07", "title": "VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text"}, {"paperId": "2fa4938001b18f464c62aa38a5a469bb92569d57", "title": "Seeing Out of tHe bOx: End-to-End Pre-training for Vision-Language Representation Learning"}, {"paperId": "bac87bdb1cabc35fafb8176a234d332ebcc02864", "title": "Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "141a5033d9994242b18bb3b217e79582f1ee9306", "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"}, {"paperId": "ba4a4d31d2af23eefadbf19e5efd5a7d4fd89143", "title": "Less is More: CLIPBERT for Video-and-Language Learning via Sparse Sampling"}, {"paperId": "cb596bffc5c5042c254058b62317a57fa156fea4", "title": "Unifying Vision-and-Language Tasks via Text Generation"}, {"paperId": "0839722fb5369c0abaff8515bfc08299efc790a1", "title": "ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision"}, {"paperId": "b1f6397717d3cbf84e89081a47205f8ed8395d22", "title": "Look Before you Speak: Visually Contextualized Utterances"}, {"paperId": "1ce28b6d15661e327c5bacd7dd89aae8e6985527", "title": "Just Ask: Learning to Answer Questions from Millions of Narrated Videos"}, {"paperId": "bcffc406b4cc5b179ed973cd7f974c656e129c4f", "title": "iPerceive: Applying Common-Sense Reasoning to Multi-Modal Dense Video Captioning and Video Question Answering"}, {"paperId": "2bacd2f2a70d756f108ad889b6bcddc79cc1ce51", "title": "Multimodal Pretraining for Dense Video Captioning"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "2f4075ddceceab5284ff8ae0bc7b230046b108cb", "title": "Formatting"}, {"paperId": "ec7cdb1ab0a9a4aefbee9e10c9c011d4cb764416", "title": "Event-Centric Hierarchical Representation for Dense Video Captioning"}, {"paperId": "bc996a4dbf9d4234eacdd0b930a94de1d158e256", "title": "ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through Scene Graph"}, {"paperId": "2f5f81bc516a6d085d39479378af1fc27104f91e", "title": "Large-Scale Adversarial Training for Vision-and-Language Representation Learning"}, {"paperId": "d87489d2facf197caafd24d0796523d55d47fb62", "title": "A Better Use of Audio-Visual Cues: Dense Video Captioning with Bi-modal Transformer"}, {"paperId": "70557ea6b65846fc30729ceed224acd4ac64ca5d", "title": "MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning"}, {"paperId": "5546e6073f3b82967b12c87d6b90ba722c4b85c6", "title": "Hero: Hierarchical Encoder for Video+Language Omni-representation Pre-training"}, {"paperId": "b5ef0f91663f0cbd6910dec9a890c138f7ec10e0", "title": "Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks"}, {"paperId": "3ba94f4dd7db8c697401aa54e63ad318423fc83d", "title": "Multi-modal Dense Video Captioning"}, {"paperId": "f1dd557a8839733a5ee06d19989a265e61f603c1", "title": "Object Relational Graph With Teacher-Recommended Learning for Video Captioning"}, {"paperId": "4243555758433880a67b15b50f752b1e2a8c4609", "title": "UniViLM: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation"}, {"paperId": "9de403a58395a1b56bfceee6e009788c43db6d08", "title": "End-to-End Learning of Visual Representations From Uncurated Instructional Videos"}, {"paperId": "9915315f5cae822e98c94382ce3b0a6f9a7f8e5e", "title": "12-in-1: Multi-Task Vision and Language Representation Learning"}, {"paperId": "e2534a3c894c93053341d514967c45c78657969c", "title": "Fast Learning of Temporal Action Proposal via Dense Boundary Generator"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "dfc7b58b67c31932b48586b3e23a43cc94695290", "title": "UNITER: UNiversal Image-TExt Representation Learning"}, {"paperId": "6648b4db5f12c30941ea78c695e77aded19672bb", "title": "Unified Vision-Language Pre-Training for Image Captioning and VQA"}, {"paperId": "7a2de516a4e628a30036193d71faac7240d553ef", "title": "Watch, Listen and Tell: Multi-Modal Weakly Supervised Dense Event Captioning"}, {"paperId": "4aa6298b606941a282d735fa3143da293199d2ca", "title": "VL-BERT: Pre-training of Generic Visual-Linguistic Representations"}, {"paperId": "79c93274429d6355959f1e4374c2147bb81ea649", "title": "LXMERT: Learning Cross-Modality Encoder Representations from Transformers"}, {"paperId": "2bc1c8bd00bbf7401afcb5460277840fd8bab029", "title": "Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training"}, {"paperId": "65a9c7b0800c86a196bc14e7621ff895cc6ab287", "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"}, {"paperId": "faf5651d82885243f5d310ced0e39e0703add073", "title": "BMN: Boundary-Matching Network for Temporal Action Proposal Generation"}, {"paperId": "ea57ffa3e13400cad53dc061887a6fbbd45e7f12", "title": "Dense Procedure Captioning in Narrated Instructional Videos"}, {"paperId": "9311779489e597315488749ee6c386bfa3f3512e", "title": "HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips"}, {"paperId": "c5a757427132fda0c66e18a0d059eca8e2472d13", "title": "Streamlined Dense Video Captioning"}, {"paperId": "c41a11c0e9b8b92b4faaf97749841170b760760a", "title": "VideoBERT: A Joint Model for Video and Language Representation Learning"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "171a027fc6c7f4194569170accc48187c8bb5aaa", "title": "Grounded Video Description"}, {"paperId": "6aa6932c22b9bd407e615ec2bfffc20cd88a9069", "title": "Adversarial Inference for Multi-Sentence Video Description"}, {"paperId": "c0199a7a37c22797c899571e51dba9690e606fa2", "title": "WikiHow: A Large Scale Text Summarization Dataset"}, {"paperId": "e7e1313061b0d56364bd2c41f017deb954bb05db", "title": "TVQA: Localized, Compositional Video Question Answering"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "b74a094b6e35fab07e1a4694afd12cad9696f1c1", "title": "Move Forward and Tell: A Progressive Generator of Video Descriptions"}, {"paperId": "49e2b4db35a408e91353578764be9085ac1210da", "title": "BSN: Boundary Sensitive Network for Temporal Action Proposal Generation"}, {"paperId": "19d7f83c3d7147f0eed1e1471438066eb4fe51fb", "title": "Jointly Localizing and Describing Events for Dense Video Captioning"}, {"paperId": "35ed258aede3df17ee20a6635364cb5fd2461049", "title": "End-to-End Dense Video Captioning with Masked Transformer"}, {"paperId": "bb4e2d6a6e3e1067f21a4cad087fc91c671e495d", "title": "Bidirectional Attentive Fusion with Context Gating for Dense Video Captioning"}, {"paperId": "ba7405516e1408f0ee6e0d0a8c6d511ce33c0551", "title": "Reconstruction Network for Video Captioning"}, {"paperId": "74b284a66e75b65f5970d05bac000fe91243ee49", "title": "Video Captioning via Hierarchical Reinforcement Learning"}, {"paperId": "51b2c1e750b1d3b893072829d012f2352d6bd373", "title": "Video Captioning With Attention-Based LSTM and Semantic Consistency"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "96dd1fc39a368d23291816d57763bc6eb4f7b8d6", "title": "Dense-Captioning Events in Videos"}, {"paperId": "9c643f3d4d7d52ab9b64911bb085438ca096275a", "title": "Temporal Action Detection with Structured Segment Networks"}, {"paperId": "6979be4e3acbb6a5455946dc332565ccb10cf8de", "title": "Weakly Supervised Dense Video Captioning"}, {"paperId": "f94841ec597dcf6d1c23e7f40ba35e121f6a81c1", "title": "TURN TAP: Temporal Unit Regression Network for Temporal Action Proposals"}, {"paperId": "e10a5e0baf2aa87d804795af071808a9377cc80a", "title": "Towards Automatic Learning of Procedures From Web Instructional Videos"}, {"paperId": "0d3b5ffff118326fea73341a86a7c29423eb95f0", "title": "Video Captioning with Transferred Semantic Attributes"}, {"paperId": "c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc", "title": "DAPs: Deep Action Proposals for Action Understanding"}, {"paperId": "c9a1e8e1ba2913ef0bdf1c5eaaa1ac0a79be3716", "title": "YouTube-8M: A Large-Scale Video Classification Benchmark"}, {"paperId": "bac994dda1385cd709e08e24170c711d8c573676", "title": "Fast Temporal Activity Proposals for Efficient Detection of Human Actions in Untrimmed Videos"}, {"paperId": "317eaf94573857bec786bbf030605ccdb0fd624d", "title": "Temporal Action Localization in Untrimmed Videos via Multi-stage CNNs"}, {"paperId": "b8e2e9f3ba008e28257195ec69a00e07f260131d", "title": "MSR-VTT: A Large Video Description Dataset for Bridging Video and Language"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "258986132bf17755fe8263e42429fe73218c1534", "title": "CIDEr: Consensus-based image description evaluation"}, {"paperId": "72729882f8fa3d9084eaece513f6bf9630be5901", "title": "Collecting Highly Parallel Data for Paraphrase Evaluation"}, {"paperId": "7533d30329cfdbf04ee8ee82bfef792d08015ee5", "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"}, {"paperId": "ecce44df1956db4ec486539c6543345344809958", "title": "Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"}, {"paperId": "d5f3cb388933db53d5391d6cd462e8499facee78", "title": "Crossing the Format Boundary of Text and Boxes: Towards Unified Vision-Language Modeling"}, {"paperId": "18316673291b537b74eee1b369009379688da73a", "title": "Detecting Moments and Highlights in Videos via Natural Language Queries"}, {"paperId": "5a4c5fa5a25cff3c65e74f64504819683353ef1e", "title": "SODA: Story Oriented Dense Video Captioning Evaluation Framework"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": "4774432f02ef4c5285952dd8c7daff0852c3a601", "title": "Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization"}, {"paperId": null, "title": "Swin-10723 license agreement with IEEE. Restrictions apply"}]}