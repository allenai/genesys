{"paperId": "38b55849585083df18e24e87859313395be8a1c6", "title": "LongVQ: Long Sequence Modeling with Vector Quantization on Structured Memory", "abstract": "Transformer models have been successful in various sequence processing tasks, but the self-attention mechanism's computational cost limits its practicality for long sequences. Although there are existing attention variants that improve computational efficiency, they have a limited ability to abstract global information effectively based on their hand-crafted mixing strategies. On the other hand, state-space models (SSMs) are tailored for long sequences but cannot capture complicated local information. Therefore, the combination of them as a unified token mixer is a trend in recent long-sequence models. However, the linearized attention degrades performance significantly even when equipped with SSMs. To address the issue, we propose a new method called LongVQ. LongVQ uses the vector quantization (VQ) technique to compress the global abstraction as a length-fixed codebook, enabling the linear-time computation of the attention matrix. This technique effectively maintains dynamic global and local patterns, which helps to complement the lack of long-range dependency issues. Our experiments on the Long Range Arena benchmark, autoregressive language modeling, and image and speech classification demonstrate the effectiveness of LongVQ. Our model achieves significant improvements over other sequence models, including variants of Transformers, Convolutions, and recent State Space Models.", "venue": "Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A new method called LongVQ, which uses the vector quantization (VQ) technique to compress the global abstraction as a length-fixed codebook, enabling the linear-time computation of the attention matrix, and effectively maintains dynamic global and local patterns."}, "embedding": {"model": "specter_v2", "vector": [0.07389866560697556, 0.28451836109161377, -0.26592695713043213, -0.09737636893987656, -0.4328162968158722, -0.2208658903837204, 0.46149471402168274, 0.22480134665966034, -0.44166284799575806, -0.24476152658462524, 0.821357011795044, 0.20796680450439453, 0.48392733931541443, 0.0648159384727478, 0.09959806501865387, -0.1946750432252884, -0.917172908782959, 0.1342625766992569, 0.36496391892433167, -0.23763805627822876, 0.36353799700737, -0.548349916934967, -1.0401828289031982, -0.10213181376457214, 0.22313298285007477, 0.8092809319496155, 0.4133908450603485, 0.9637485146522522, -0.9330286383628845, 0.41636180877685547, 0.22838836908340454, -0.5171392560005188, 0.33045414090156555, -0.28973644971847534, -0.5516561269760132, -0.15914905071258545, 0.4988028407096863, -0.10514233261346817, -0.6054307818412781, 0.8080649375915527, 0.004927382804453373, 0.35568490624427795, 0.3118613660335541, -0.5863028764724731, 0.10290432721376419, 0.6947298049926758, 0.6505562663078308, 0.8338363170623779, -0.4252503216266632, -0.42038896679878235, 1.7226659059524536, -1.3111063241958618, 0.09761341661214828, 1.3602144718170166, 0.2999228835105896, 0.29646334052085876, -0.24769511818885803, -0.846187174320221, 0.6890044212341309, 0.6822435259819031, -0.830689013004303, -0.4173010587692261, 0.3057812452316284, -0.3213260769844055, 1.740018606185913, -0.26097849011421204, 0.48384320735931396, 0.5569459795951843, 0.3175942599773407, 1.039883017539978, -0.4932757019996643, -0.542880654335022, 0.24127686023712158, -0.5668841004371643, 1.0687068700790405, 0.7390507459640503, -0.6395288705825806, 0.38755765557289124, -1.0676429271697998, 0.07349765300750732, 0.5674117803573608, 0.061440885066986084, 0.44495028257369995, -0.49116814136505127, -0.12795542180538177, 1.0254943370819092, 0.1756862998008728, 0.5045957565307617, -0.24674302339553833, 0.745233416557312, 0.882928729057312, 0.00997189711779356, -0.022498564794659615, 0.339840829372406, 0.31796905398368835, -0.24241012334823608, -0.7343161106109619, 0.1406906694173813, -0.635770857334137, 1.0904158353805542, -0.1313927173614502, 0.8344483375549316, -0.7835131883621216, 0.5898979306221008, 1.1002824306488037, 0.11499982327222824, 0.5619844198226929, -0.9324265122413635, 0.013561069965362549, -0.7362181544303894, 0.07827147096395493, -0.5694952011108398, 0.03916715458035469, -0.5171351432800293, -0.8263468146324158, -0.9980266094207764, -0.5291545391082764, 0.6634178757667542, -0.5895814895629883, 0.5536752939224243, -0.6006395220756531, 0.41921842098236084, -0.06009606644511223, 0.02077055349946022, 0.4650026261806488, 1.0798569917678833, 0.4997391998767853, -0.2515295147895813, 1.04770028591156, -1.0264370441436768, -0.9225050806999207, -0.8944304585456848, 0.14707131683826447, 0.1769612729549408, 0.2540856897830963, -0.2840813994407654, -1.3935359716415405, -1.4121389389038086, -0.7725863456726074, 0.32664617896080017, -0.27678588032722473, -0.5023818016052246, 0.6079952716827393, 0.23478226363658905, -0.8983436822891235, 0.775095522403717, -0.5498735904693604, -0.37901797890663147, 0.548842191696167, -0.13631141185760498, 0.6549065113067627, -0.05786499008536339, -1.336769700050354, 0.18882989883422852, -0.0038178646937012672, -0.684684157371521, -0.35341358184814453, -0.4387954771518707, -1.3136192560195923, 0.3573026955127716, 0.26440051198005676, -0.02733907848596573, 1.1429911851882935, 0.18779215216636658, -1.1857898235321045, 0.12904031574726105, -0.48529964685440063, -0.06370826810598373, -0.35130545496940613, -0.07365774363279343, -0.31475380063056946, -0.2860809564590454, -0.3447912931442261, 0.23922081291675568, 0.5153980255126953, 0.0514640174806118, -0.22138020396232605, -0.08793290704488754, -0.5577731728553772, -0.2020581066608429, -0.45533129572868347, 1.0303770303726196, -0.521957278251648, -0.27798041701316833, 0.12004444003105164, 0.7369457483291626, -0.17847870290279388, -0.2693943977355957, -0.07805640995502472, -1.1499830484390259, 0.4401479959487915, 0.2801695168018341, 1.0861588716506958, -0.9535442590713501, -0.850014865398407, -0.4753378927707672, -0.3055890202522278, 0.10086031258106232, -0.972367525100708, 0.9682957530021667, -0.45897096395492554, 0.08104333281517029, 0.20190349221229553, -0.8396611213684082, -0.0006151177221909165, 0.02856413833796978, -0.8642394542694092, -0.14365194737911224, 0.08797655254602432, 1.2039506435394287, -1.3968321084976196, -0.545890748500824, -0.059160735458135605, -0.1080961674451828, -0.8899756669998169, 1.4334362745285034, -0.0239744633436203, -0.13528862595558167, 0.11091020703315735, -0.4483332931995392, -0.05966927856206894, -0.5096552968025208, 0.22510413825511932, -0.4765816032886505, -0.29635336995124817, 0.571150004863739, -0.28744810819625854, 1.2937594652175903, -0.09457474946975708, 0.6879804134368896, -0.3761507272720337, -0.8431786894798279, 0.4524524211883545, 0.194039449095726, 0.1893492043018341, -0.5915341377258301, 0.24276456236839294, -0.4120251536369324, -0.8324651718139648, 0.28247806429862976, 0.685831606388092, 0.8748217821121216, -0.4950365424156189, 0.06150403246283531, 0.8972073197364807, -0.13340070843696594, 0.6330448389053345, 0.710645318031311, 0.6398512125015259, 0.1707247644662857, 0.7546849846839905, -0.1829661726951599, 0.10111211240291595, -0.9150429368019104, 0.26726233959198, 0.5896696448326111, 0.3783418834209442, 0.9211228489875793, 0.22507044672966003, -0.6712344884872437, -0.670823335647583, -0.20795398950576782, 0.8292038440704346, 1.2552227973937988, 0.11162695288658142, -0.5397995710372925, -0.6169249415397644, 0.03933725133538246, -0.5650920271873474, -0.019892996177077293, -0.1603815108537674, -0.3354852497577667, -0.3789762556552887, -0.2811872363090515, 0.7282935976982117, 0.677004873752594, 0.6870347857475281, -0.6685983538627625, -0.4356217086315155, 0.12738822400569916, 0.18915051221847534, -0.6059073209762573, -1.0542742013931274, 0.5044884085655212, -0.29121699929237366, 0.1250336617231369, 0.04034542292356491, 0.13565076887607574, -0.5762647986412048, -0.4196164906024933, 0.8979753255844116, -0.9177746772766113, -0.24710014462471008, 0.07523336261510849, 0.26191720366477966, -0.973140299320221, -0.5845274925231934, 0.19309844076633453, 0.2865668833255768, -0.04731324315071106, 0.2049911469221115, 0.5232157707214355, 0.08784251660108566, -0.17481572926044464, -0.01859729178249836, -0.21258847415447235, -0.03660670667886734, 0.3813149034976959, 0.4532668888568878, -0.39885562658309937, 0.08844835311174393, -0.5699666738510132, 0.7995386719703674, 0.49394574761390686, -0.6701287031173706, 0.16860570013523102, -0.7323178648948669, -0.12613390386104584, 0.10318765044212341, -0.5003944635391235, -0.011573165655136108, -0.8807263970375061, 0.09984694421291351, -0.784224271774292, -0.22077681124210358, -0.08806044608354568, 0.10811051726341248, 0.3249400556087494, -0.06908852607011795, 0.8257309198379517, 0.48164600133895874, 0.11364229023456573, 0.4185751676559448, -0.5751791596412659, 0.6485585570335388, 0.5338236689567566, 0.07334083318710327, -0.2665238082408905, -0.1915418803691864, -1.114726185798645, -0.3777431547641754, -0.794585108757019, -0.530742883682251, -0.3566860258579254, 0.6222269535064697, -0.4939877390861511, -0.9365530014038086, 0.0969042256474495, -1.3666350841522217, -0.19726724922657013, -0.36903777718544006, -0.17745716869831085, -0.30045920610427856, -0.8508639335632324, -1.1341098546981812, -0.75933837890625, -0.47511547803878784, -0.9066576361656189, 0.1454121321439743, 0.02545882761478424, -0.6404600143432617, -0.3986779451370239, 0.20510609447956085, -0.6172232031822205, 0.9278026223182678, -0.9188423752784729, 0.7138198018074036, -0.20659975707530975, -0.28188449144363403, 0.06860624253749847, 0.2953017055988312, 0.4171997010707855, 0.025686001405119896, 0.011520414613187313, -0.6488444805145264, 0.2045210748910904, -0.23586690425872803, -0.10571319609880447, 0.12291688472032547, 0.28908637166023254, 0.9342397451400757, -0.00106405362021178, -0.24285316467285156, 0.2622888386249542, 1.2406412363052368, 0.20423927903175354, 0.33426347374916077, -0.2897719144821167, 0.9720668792724609, 0.027806144207715988, -0.1732296198606491, 0.69594407081604, 0.03052731789648533, 0.6546792984008789, 0.43045589327812195, -0.00906018540263176, -0.2838072180747986, -0.293563574552536, 0.3284839987754822, 1.9466317892074585, 0.21220432221889496, -0.04780089110136032, -0.9044312238693237, 0.8727277517318726, -0.8771487474441528, -1.324701189994812, 0.8909489512443542, 0.48007288575172424, 0.16938233375549316, -0.6574147939682007, -0.1788090169429779, 0.08749102056026459, 0.3501816391944885, 0.8601007461547852, -0.3312985897064209, -0.7899890542030334, 0.04537837952375412, 0.4355810284614563, 0.018066635355353355, 0.9161924719810486, -0.11248447746038437, 0.4330609142780304, 14.974726676940918, 0.9070909023284912, -0.1613631695508957, 0.5272676348686218, 0.2895885109901428, 0.22170774638652802, -0.1389254331588745, -0.25938868522644043, -1.0171592235565186, 0.09373936057090759, 1.4168559312820435, -0.002814025152474642, 0.31651848554611206, -0.09817073494195938, 0.1554638296365738, 0.6285229921340942, -0.3708038628101349, 1.0826456546783447, 0.4106142222881317, -1.4701603651046753, 0.4852283000946045, 0.2259051352739334, -0.08954261988401413, 0.2760128676891327, 0.6098974943161011, 0.6150733828544617, 0.6337521076202393, -0.18292132019996643, 0.7566692233085632, 0.19497370719909668, 1.0414211750030518, -0.13213972747325897, 0.21472328901290894, 0.19863538444042206, -1.2980877161026, -0.30454641580581665, -0.7168157696723938, -1.0622228384017944, 0.3412972688674927, -0.1847413033246994, -0.3161485493183136, -0.24934746325016022, -0.1582416146993637, 0.7345050573348999, 0.2127951979637146, 0.46677735447883606, 0.0537593737244606, 0.8755451440811157, 0.6556457877159119, -0.21234819293022156, 0.5692592263221741, 0.16855765879154205, 0.2373104989528656, -0.025709960609674454, -0.1194748729467392, 0.4733075201511383, 0.2612018883228302, 0.09689686447381973, -0.040585957467556, -0.022743454203009605, -0.36400124430656433, -0.2794797122478485, 0.04352281987667084, 0.23979854583740234, 0.5251092910766602, 0.009452594444155693, -0.3907147943973541, 0.22982940077781677, 0.5458337664604187, 0.20076142251491547, -0.5455666184425354, -0.30265456438064575, 0.5639126300811768, -0.5364294648170471, 0.16041302680969238, 0.3365335464477539, -0.18508121371269226, -0.44937664270401, -1.2873258590698242, -0.08133656531572342, 0.3085785210132599, -0.914361834526062, -0.789935290813446, 1.1638329029083252, -0.009858888573944569, -0.5270987749099731, 0.17838366329669952, -0.17475932836532593, -0.2539941370487213, 0.344354510307312, -0.8865047693252563, -0.15994974970817566, -0.14646874368190765, -0.19541139900684357, 0.2572232782840729, -0.10777395963668823, 1.3146077394485474, 0.015771767124533653, -0.12487302720546722, -0.16123411059379578, 0.09279803186655045, -0.007462627720087767, -0.4072999358177185, -0.6100524067878723, 0.9355030059814453, 0.2612825036048889, 0.1022140234708786, 0.177569180727005, 0.05802132934331894, 0.34124553203582764, -0.5110594034194946, -0.43846502900123596, 0.48065853118896484, -0.988381564617157, -0.258935809135437, -1.2239843606948853, -1.1482596397399902, 0.13658113777637482, 0.7431294322013855, 0.05608509108424187, 0.20411317050457, -0.09037072211503983, -0.46557343006134033, -0.46018943190574646, -0.15576180815696716, -0.0634850561618805, 0.7199268341064453, -0.8570938110351562, -0.379179984331131, -0.6571505665779114, 0.6367957592010498, -0.5353829264640808, -0.3957325518131256, -0.5738856792449951, -0.005831540562212467, -0.0840146467089653, 1.1321747303009033, -0.5365040302276611, 0.5054740309715271, 1.1801789999008179, -0.20644964277744293, -0.809298038482666, -0.6300206184387207, -0.8899989724159241, 0.06267381459474564, 0.5745015144348145, -0.019525544717907906, -0.36873307824134827, 0.68016517162323, 0.2281665951013565, 0.17535120248794556, -0.6751775145530701, -0.7364717721939087, -0.7495651841163635, -0.2619701027870178, -0.527614176273346, 0.5405632257461548, -0.19856928288936615, -0.0002492390922270715, 0.5011559128761292, 0.29957422614097595, 0.3007775843143463, 0.021345073357224464, -0.3826785981655121, 0.1467023342847824, -0.24963192641735077, 0.3777380883693695, -0.5323584079742432, -0.7849820256233215, -1.4989378452301025, 0.02236567996442318, -0.9337445497512817, 0.06877025961875916, -0.8488456606864929, -0.1863723248243332, 0.2615085542201996, -0.45579618215560913, -0.14014224708080292, 0.4270228445529938, -0.40844064950942993, -0.13743315637111664, -0.5386362075805664, -0.7749438881874084, 1.1270928382873535, 0.6537528038024902, -1.0622587203979492, 0.11267038434743881, -0.23622091114521027, 0.23852041363716125, -0.020221520215272903, 0.3423565626144409, -0.4580368101596832, -0.9734616875648499, -0.987317681312561, -0.30495843291282654, 0.2875490188598633, -0.306712806224823, -0.922681450843811, 0.6939270496368408, -0.04397754743695259, -0.3434549570083618, -0.5143985748291016, 0.7613903284072876, -0.6398853063583374, -0.41268283128738403, 0.5551761388778687, -1.1214606761932373, 0.2576940655708313, -0.09968557208776474, -0.4110478162765503, -0.44324791431427, 0.8260661959648132, 0.3951382040977478, -1.181641936302185, -0.8118813633918762, 0.7534411549568176, -0.7671594023704529, 0.21205613017082214, -0.17040491104125977, -0.3448721170425415, -0.7054415345191956, -0.5865201950073242, 0.15515093505382538, 0.36535510420799255, -0.4866233170032501, 0.9428139925003052, 0.6298738121986389, -1.1012701988220215, 0.14574192464351654, 0.5529705882072449, 0.14704102277755737, -0.23962616920471191, 0.5131422281265259, -0.12019604444503784, -0.009457406587898731, 0.8704431056976318, -0.04915528744459152, 0.18304966390132904, -1.1860859394073486, 0.5751566886901855, 0.5034740567207336, -0.38010019063949585, 0.16004088521003723, 0.9732576012611389, -0.1712471842765808, -0.6543143391609192, 0.18518011271953583, -1.1513429880142212, -0.9895642399787903, 0.003260416677221656, 0.7259550094604492, 0.43150594830513, -0.31390371918678284, -0.14468801021575928, -0.6280261874198914, 0.48080897331237793, 0.10533665120601654, -0.603668212890625, 0.4683730900287628, -0.43598541617393494, -0.12264113128185272, 1.1098358631134033, 1.1515655517578125, -0.6837446093559265, -0.89173823595047, -0.5701118111610413, -0.55512934923172, -0.2928953468799591, -0.054132360965013504, 0.2198028415441513, -0.5381423234939575, 1.1209838390350342, 0.7745058536529541, 0.44879359006881714, -0.1624796837568283, -0.1659281998872757, 0.1785389482975006, 0.3368171155452728, 0.31147274374961853, -0.27534541487693787, -0.08306138217449188, 1.7220211029052734, 1.3316060304641724, -0.3158235549926758, 0.06858150660991669, -0.19660000503063202, -0.7267582416534424, 0.5868424773216248, 0.44509589672088623, -0.14927631616592407, 0.8126289248466492, -0.2851458787918091, 0.4338020086288452, -0.055245254188776016, -1.2678966522216797, -0.20866340398788452, 0.5106426477432251, 1.1416053771972656, 0.2676173150539398, 0.010055038146674633, 0.5339112877845764, 0.80507493019104, 0.26357531547546387, -0.19686582684516907, 0.5709684491157532, 0.3013363182544708, -0.24359913170337677, 0.008768226020038128, 0.011506587266921997, 0.45369014143943787, -0.5566374063491821, -0.5038171410560608, 0.5089362859725952, 0.19903676211833954, -0.06545613706111908, 0.7218688130378723, 1.341524600982666, -0.0031346804462373257, 0.5761208534240723, 0.25968658924102783, 0.3820684552192688, -0.6535237431526184, -0.15333767235279083, -0.08045239746570587, -0.7512436509132385, -0.5924332141876221, -0.10051065683364868, -0.758729100227356, -0.1753840297460556, 0.42867639660835266, 0.14402049779891968, 0.49025896191596985, 0.17152798175811768, 0.7961094975471497, 0.5600844621658325, 0.7767075896263123, -0.14336319267749786, -0.6923710107803345, -0.8881926536560059, -0.8113778829574585, -0.32730162143707275, -0.2243846356868744, 0.21408386528491974, -0.3343791663646698, 0.2401026040315628, 0.11783625930547714]}, "authors": [{"authorId": "2200082418", "name": "Zicheng Liu"}, {"authorId": "2297286771", "name": "Li Wang"}, {"authorId": "2266736017", "name": "Siyuan Li"}, {"authorId": "2184760529", "name": "Zedong Wang"}, {"authorId": "2260201864", "name": "Haitao Lin"}, {"authorId": "2290860154", "name": "Stan Z. Li"}], "references": [{"paperId": "9c464f92cb3ab18a7c09f5bcee8e6e80bdec3b3b", "title": "Transformer-VQ: Linear-Time Transformers via Vector Quantization"}, {"paperId": "661e8d555c4424b5953f17434f2ba910bfcf3afe", "title": "Efficient Long Sequence Modeling via State Space Augmented Transformer"}, {"paperId": "240300b1da360f22bf0b82c6817eacebba6deed4", "title": "What Makes Convolutional Models Great on Long Sequence Modeling?"}, {"paperId": "b40f0b0465cdf4b487fb2ef85d4e2672c4b623cc", "title": "Liquid Structural State-Space Models"}, {"paperId": "70e91e16eb321067d9402710e14a40cf28311f73", "title": "Mega: Moving Average Equipped Gated Attention"}, {"paperId": "6d7d141c75af752ffc0d8a6184cca3f9323d6c74", "title": "Simplified State Space Layers for Sequence Modeling"}, {"paperId": "eaef083b9d661f42cc0d89d9d8156218f33a91d9", "title": "Long Range Language Modeling via Gated State Spaces"}, {"paperId": "ca444821352a4bd91884413d8070446e2960715a", "title": "On the Parameterization and Initialization of Diagonal State Space Models"}, {"paperId": "71e15a9a52dcafca57bff5f310b95e2c7d0cfc87", "title": "Diagonal State Spaces are as Effective as Structured State Spaces"}, {"paperId": "dc0102a51a9d33e104a4a3808a18cf17f057228c", "title": "Transformer Quality in Linear Time"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "ca9047c78d48b606c4e4f0c456b1dda550de28b2", "title": "Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers"}, {"paperId": "dbf53ece1a6a8860e41ff5f721c72ceb0fb18dd6", "title": "H-Transformer-1D: Fast One-Dimensional Hierarchical Attention for Sequences"}, {"paperId": "5d032bd2632b6f5847767f39ce247098c6bbc563", "title": "Combiner: Full Attention Transformer with Sparse Computation Cost"}, {"paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"}, {"paperId": "af679d69fcc1d0fcf0f039aba937853bcb50a8de", "title": "Luna: Linear Unified Nested Attention"}, {"paperId": "e32a12b14e212506115cc6804667b3d8297917e1", "title": "Poolingformer: Long Document Modeling with Pooling Attention"}, {"paperId": "b3bf9fe13195e9aa70e1dac04e01fcff7008e812", "title": "Perceiver: General Perception with Iterative Attention"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "47f7ec3d0a5e6e83b6768ece35206a94dc81919c", "title": "Taming Transformers for High-Resolution Image Synthesis"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "0964490205fdc38c2f0980c9d778069089ca92e3", "title": "HiPPO: Recurrent Memory with Optimal Polynomial Projections"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "cd4ffe5e014601a3d6b64121355d29a730591490", "title": "Fast Transformers with Clustered Attention"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "bbc89fa342c06cf2216884238c531b1f6434e61d", "title": "Lipschitz Recurrent Neural Networks"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d", "title": "ETC: Encoding Long and Structured Inputs in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "b3beb9bc7395a8a489b9c64c46329a84d45968bd", "title": "Learning Problem-agnostic Speech Representations from Multiple Self-supervised Tasks"}, {"paperId": "a14af711aaa3ae83eb64d1f517b024b8c3094a8a", "title": "Trellis Networks for Sequence Modeling"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "da6e404d8911b0e5785019a79dc8607e0b313dc4", "title": "Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition"}, {"paperId": "608e4bbe7a2d6f04d68b5747d9d0778d5fce47df", "title": "Learning Longer-term Dependencies in RNNs with Auxiliary Losses"}, {"paperId": "f466157848d1a7772fb6d02cdac9a7a5e7ef982e", "title": "Neural Discrete Representation Learning"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "ac3ee98020251797c2b401e1389461df88e52e62", "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "5a69ec9a521e8562f1691f08722ef8fe38b5a426", "title": "Unveiling the Power of Mixup for Stronger Classi\ufb01ers"}, {"paperId": "30becc9209c02cd4f3f6aed86ea9bd37de50be9d", "title": "Improving the Gating Mechanism of Recurrent Neural Networks"}, {"paperId": "c8c4ab59ac29973a00df4e5c8df3773a3c59995a", "title": "Searching for Activation Functions"}, {"paperId": null, "title": "Large text compression benchmark"}, {"paperId": null, "title": "Flexconv"}, {"paperId": null, "title": "Simple hardware-efficient long convolutions"}, {"paperId": null, "title": "Reinventing rnns"}]}