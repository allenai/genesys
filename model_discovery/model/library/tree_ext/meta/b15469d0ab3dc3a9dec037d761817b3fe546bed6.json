{"paperId": "b15469d0ab3dc3a9dec037d761817b3fe546bed6", "title": "Pre-trained Language Models in Biomedical Domain: A Systematic Survey", "abstract": "Pre-trained language models (PLMs) have been the de facto paradigm for most natural language processing tasks. This also benefits the biomedical domain: researchers from informatics, medicine, and computer science communities propose various PLMs trained on biomedical datasets, e.g., biomedical text, electronic health records, protein, and DNA sequences for various biomedical tasks. However, the cross-discipline characteristics of biomedical PLMs hinder their spreading among communities; some existing works are isolated from each other without comprehensive comparison and discussions. It is nontrivial to make a survey that not only systematically reviews recent advances in biomedical PLMs and their applications but also standardizes terminology and benchmarks. This article summarizes the recent progress of pre-trained language models in the biomedical domain and their applications in downstream biomedical tasks. Particularly, we discuss the motivations of PLMs in the biomedical domain and introduce the key concepts of pre-trained language models. We then propose a taxonomy of existing biomedical PLMs that categorizes them from various perspectives systematically. Plus, their applications in biomedical downstream tasks are exhaustively discussed, respectively. Last, we illustrate various limitations and future trends, which aims to provide inspiration for the future research.", "venue": "ACM Computing Surveys", "year": 2021, "citationCount": 90, "influentialCitationCount": 4, "openAccessPdf": {"url": "https://arxiv.org/pdf/2110.05006", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "The motivations of PLMs in the biomedical domain are discussed and the key concepts of pre-trained language models are introduced and a taxonomy of existing biomedical PLMs is proposed that categorizes them from various perspectives systematically."}, "embedding": {"model": "specter_v2", "vector": [0.5336591601371765, 0.9372145533561707, -0.2588205337524414, -0.4244520664215088, -0.3703123927116394, 0.16493938863277435, 0.2082599699497223, -0.0969463437795639, -0.8407155275344849, 0.016080472618341446, 0.5704289674758911, 0.22914986312389374, 0.1253305971622467, 0.5961955189704895, 0.09349553287029266, -0.01654726266860962, -1.025394320487976, 0.4151146113872528, -0.6678627729415894, 0.14150108397006989, -0.6237922310829163, -0.6230325102806091, -0.1739918291568756, 0.2326502948999405, 0.08591372519731522, -0.27633947134017944, 0.4101470410823822, 0.7860565781593323, -0.3132106065750122, 0.517861008644104, 0.7051625847816467, -0.5674055814743042, 0.08109055459499359, -0.20386575162410736, -0.22273874282836914, 0.16479837894439697, 0.05897374078631401, -0.3224019706249237, -0.8890549540519714, 0.7150765657424927, -0.1393996924161911, 0.16382858157157898, 0.639912486076355, -0.2985518276691437, -0.41585221886634827, 1.1527118682861328, 0.8452221155166626, 0.5521814823150635, -0.38300472497940063, -0.2740243375301361, 1.2421094179153442, -1.130342960357666, 0.4226032793521881, 1.6455538272857666, 0.5129638314247131, 0.7994570136070251, -0.21007739007472992, -0.6982308626174927, 0.07463140785694122, -0.4987534284591675, -0.8612464666366577, -0.42161300778388977, -0.19267098605632782, -0.5879853963851929, 1.6354215145111084, -0.2665748596191406, -0.31824931502342224, 0.6095061302185059, 0.6214562654495239, 1.1036511659622192, -0.05330166965723038, -0.5365074276924133, -0.45298126339912415, 0.23018251359462738, 0.2714504599571228, 1.1496944427490234, -0.4553182125091553, 0.37166932225227356, -0.8305483460426331, -0.3396988809108734, 0.1853961944580078, 0.09126273542642593, -0.15121451020240784, 0.2580247223377228, -0.6444605588912964, 0.42597296833992004, 0.19336119294166565, 1.1492172479629517, -0.26022225618362427, 0.0069828154519200325, 0.29270029067993164, 0.32831981778144836, -0.11896058171987534, 0.6270357966423035, -0.5238922834396362, 0.971340537071228, -1.0456432104110718, -0.1862022578716278, 0.03569994494318962, 0.9065749645233154, -0.38896623253822327, -0.046789418905973434, -1.2006837129592896, 0.3510943055152893, 1.329403042793274, -0.12946972250938416, 0.8095559477806091, -0.254934161901474, -0.021298356354236603, -0.46318891644477844, 0.17450378835201263, -0.7329972386360168, -0.5838732719421387, -0.45301395654678345, -0.962737500667572, -1.8939452171325684, -0.49431994557380676, 0.11457580327987671, -1.2186365127563477, 0.987468957901001, -0.7850169539451599, 0.0689728856086731, 0.4917803704738617, 0.26262250542640686, 0.7134371995925903, 0.6787940859794617, 1.0663524866104126, -0.08144182711839676, 1.3204365968704224, -0.6819981932640076, -0.8289734125137329, -1.211891531944275, 0.5873761773109436, -0.1059313639998436, -0.023358415812253952, -0.4683418273925781, -0.5969855785369873, -0.8536405563354492, -0.40728914737701416, -0.34953823685646057, -0.4454570710659027, 0.6305192708969116, 0.8056386709213257, 0.28784996271133423, -1.1899765729904175, 0.8252527117729187, -0.05095558241009712, -0.37315890192985535, -0.037806298583745956, 0.24893292784690857, 0.1684950441122055, -0.3292505443096161, -1.4616328477859497, 0.4243372082710266, 0.4695083498954773, -0.5283147692680359, -0.6658293008804321, -0.21367217600345612, -1.1029441356658936, -0.09314052760601044, -0.0019434860441833735, -0.929408848285675, 1.0462602376937866, -0.13896645605564117, -1.0223697423934937, 1.5749140977859497, -0.4779057800769806, -0.12080276012420654, 0.09017856419086456, -0.16407598555088043, -1.008650541305542, -0.18450811505317688, -0.1683930903673172, 0.7641805410385132, -0.05442313477396965, -0.09782877564430237, 0.18761636316776276, 0.23929116129875183, -0.5396650433540344, -0.34203121066093445, -0.30719250440597534, 0.9705927968025208, -0.5541091561317444, -0.5199345946311951, 0.24526849389076233, 0.41705694794654846, -0.5995854139328003, -0.16306178271770477, -0.5598012804985046, -0.7569937109947205, 0.10601908713579178, -0.23572610318660736, 0.7364667654037476, -1.035382628440857, -0.8674050569534302, -0.22566115856170654, -0.002253658138215542, -0.01071560475975275, -0.9666411876678467, 0.718332052230835, -0.8171939253807068, 0.5285055041313171, -0.5351894497871399, -1.166994333267212, -0.2780492305755615, -0.04111069440841675, -0.21737129986286163, -0.05686946213245392, 0.3579617142677307, 0.971899151802063, -0.9600115418434143, -0.2356637567281723, -0.087027408182621, 0.2801593244075775, -0.7286883592605591, 1.1860458850860596, -0.07091409713029861, 0.24977925419807434, -0.1394091099500656, -0.06971367448568344, -0.07118142396211624, -0.4233068823814392, 0.3771412670612335, -0.5141067504882812, -0.2020418345928192, 0.0960308313369751, 0.35045406222343445, 1.25108802318573, -0.06699571758508682, 0.1271943300962448, -0.022072216495871544, -0.6613957285881042, -0.05674659088253975, 1.0294466018676758, 0.5172090530395508, 0.10994666069746017, 0.6891242265701294, 0.10313572734594345, -0.5111849308013916, -0.2214203029870987, 0.3335641324520111, 0.13340401649475098, 0.06050008907914162, -0.24704378843307495, 0.6870530843734741, -0.010294637642800808, 0.25311586260795593, 0.3748164772987366, 0.5467783808708191, -0.01383613608777523, 0.8433927893638611, -0.24662846326828003, 0.7906692624092102, -0.7680577039718628, 0.4525855481624603, 0.40734097361564636, 0.520662784576416, 0.5112550854682922, 0.0635531023144722, -0.4192560613155365, 0.1835859715938568, 0.2672674357891083, 0.5044988989830017, 1.328878402709961, -0.4334895610809326, -0.21462364494800568, -0.5155511498451233, -0.22951988875865936, -0.45905938744544983, 0.041665270924568176, -0.3248763680458069, -0.24835650622844696, -0.528449296951294, -1.1868815422058105, 0.9876794815063477, -0.07645399868488312, 0.3390788435935974, -0.6420000195503235, 0.26352545619010925, -0.20037059485912323, 0.12055428326129913, -0.925398051738739, -0.9396495223045349, 0.5179798007011414, -0.9686694145202637, -0.3341977894306183, -0.30940502882003784, -0.6103715896606445, 0.44841042160987854, -1.202147364616394, 0.862229585647583, -0.7424653172492981, -0.5463478565216064, 0.26982271671295166, 1.0318808555603027, -0.7357015609741211, -1.1903172731399536, -0.6092790365219116, 0.12147033959627151, 0.0412038117647171, 0.4887256622314453, 0.8064578175544739, 0.1153215691447258, -0.16810332238674164, -0.5999829173088074, 0.24959887564182281, 0.744091272354126, 0.49316418170928955, 0.8133738040924072, -0.1315518021583557, 0.1361638456583023, -1.5672391653060913, 0.9237970113754272, 0.14561329782009125, -0.06791031360626221, 0.44343894720077515, -0.39059165120124817, -0.040012210607528687, 0.6574640274047852, -0.5096069574356079, -0.46253931522369385, -0.33105266094207764, -0.13378866016864777, -0.020050114020705223, -0.21236778795719147, 0.9327039122581482, 0.3631010949611664, 0.5519763231277466, 0.2657577097415924, 0.6334707140922546, 0.18918254971504211, -0.19248944520950317, 0.17239615321159363, -0.2587261497974396, 0.3964759409427643, 0.42938369512557983, 0.12243462353944778, -0.30668413639068604, -0.31483861804008484, -0.8683645725250244, -0.4815670847892761, -0.6982605457305908, -0.35358926653862, -0.14056804776191711, 0.2566007673740387, -0.7719823718070984, -0.29630711674690247, -0.024245833978056908, -0.6307360529899597, 0.2846080958843231, 0.48654991388320923, 0.130382239818573, 0.20664501190185547, -0.7096405029296875, -1.5519616603851318, -0.5228764414787292, -0.8194729089736938, -0.8984990119934082, 0.5177910923957825, -0.061492692679166794, -0.24268710613250732, -0.3774769604206085, -0.22518891096115112, -0.015360938385128975, 0.5621386170387268, -0.4947064220905304, 1.3255255222320557, -0.28714123368263245, 0.541326105594635, -0.49356624484062195, 0.4759109318256378, 0.6888151168823242, 0.35009798407554626, 0.2035457044839859, -0.7770801186561584, 0.10583831369876862, 0.2777296304702759, 0.04754797741770744, 0.2445807009935379, 0.4315316379070282, 0.7413932681083679, 0.3788304030895233, -0.8308016657829285, 0.04126635566353798, 1.0151139497756958, -0.3114168643951416, -0.4903935194015503, -0.7157006859779358, 0.4085647761821747, 0.31813710927963257, -0.26379790902137756, 0.29673224687576294, -0.20616772770881653, 0.09241192042827606, -0.38413211703300476, -0.3885512053966522, 0.19001993536949158, -0.33277374505996704, 0.5959996581077576, 1.5140827894210815, 0.5657912492752075, -0.34077033400535583, -1.3624670505523682, 0.7123335003852844, -0.8411449790000916, -0.3354511559009552, 0.5372808575630188, 0.3934918940067291, 0.9202693104743958, -0.16011838614940643, -0.740810751914978, -0.5173271298408508, 0.4453621804714203, -0.1624993234872818, -0.24461305141448975, -0.22514662146568298, -0.2701907455921173, 0.46416014432907104, 0.21439425647258759, 0.32438576221466064, -0.8253046274185181, 0.3453872799873352, 14.51562786102295, 0.03832442685961723, -0.2337990552186966, 0.3346596956253052, 0.7412553429603577, 0.6722192168235779, 0.05784286558628082, -0.419272780418396, -0.9998230338096619, -0.1251990646123886, 1.3845188617706299, 0.08666129410266876, 0.07486899942159653, 0.5294919610023499, 0.4013153910636902, 0.24338950216770172, -0.989329993724823, 0.9049509763717651, 0.5863475203514099, -0.8002724051475525, 0.5805409550666809, 0.1762598156929016, -0.010656788013875484, 0.64745032787323, 0.5442420840263367, 0.8443300724029541, 0.13646960258483887, -0.6237967610359192, -0.12890306115150452, 0.6018142104148865, 0.47173845767974854, 0.36261823773384094, 0.8052197694778442, 0.8181377053260803, -0.5725657343864441, -0.38376733660697937, -0.5609976053237915, -0.5403024554252625, 0.1587214469909668, 0.5281395316123962, -1.161912202835083, 0.027241583913564682, -0.6492429971694946, 0.8458996415138245, 0.014429084956645966, 0.3350979685783386, -0.023487504571676254, 0.7884520888328552, 0.2547764182090759, 0.11506585776805878, 0.25998541712760925, 0.5796237587928772, 0.4613015353679657, 0.43911176919937134, -0.016447443515062332, 0.2388579249382019, 0.47202733159065247, 0.2005956619977951, -0.5967642664909363, 0.4353817403316498, -0.19212710857391357, -0.9810330271720886, -0.8102794885635376, 0.7084667086601257, 0.441658616065979, 0.087974414229393, -0.5397918224334717, 0.0784866213798523, 0.189622163772583, 0.1120036393404007, -0.09026223421096802, 0.08934113383293152, 0.4346306324005127, -0.442615807056427, -0.7586039304733276, 0.49320289492607117, -0.006093704141676426, -0.7116792798042297, -1.0117210149765015, -0.14536884427070618, 0.7497226595878601, -0.6335331797599792, -1.5421171188354492, 1.1554529666900635, -0.5840984582901001, -0.44833338260650635, 0.38558825850486755, -1.2905516624450684, 0.585106611251831, 0.8145701885223389, -1.3159843683242798, -0.43709906935691833, 0.44632601737976074, -0.19379495084285736, -0.4935365617275238, -0.20247437059879303, 1.5943248271942139, 0.3470102846622467, -0.6809474229812622, -0.10985672473907471, 0.16889746487140656, 0.6271224021911621, 0.2954854667186737, -0.29435521364212036, 0.1187358945608139, 0.27382609248161316, -0.39259082078933716, 0.9421727061271667, 0.06030459329485893, -0.30750393867492676, -0.8585784435272217, -0.4744892418384552, 1.2706226110458374, -0.6446101665496826, -0.6104995012283325, -0.663746178150177, -0.7505373954772949, 0.27979788184165955, 0.5169538855552673, -0.6941671967506409, 0.9986467957496643, -0.10359469801187515, 0.1591508835554123, 0.08028861880302429, -0.9560695886611938, 0.16846424341201782, 0.7345774173736572, -0.8073553442955017, -0.7740617394447327, 0.630540668964386, 0.06342197954654694, -0.5019789934158325, -0.5993608832359314, 0.16341011226177216, -0.2906222343444824, 0.8198993802070618, 0.9166586995124817, -1.0697089433670044, 0.6217573881149292, 0.7770091891288757, 0.1803770810365677, -0.8128125071525574, -0.44184914231300354, -0.5248222947120667, 0.2632519602775574, -0.3445237874984741, 0.7959221601486206, -0.23128920793533325, 0.025945402681827545, 1.0225422382354736, -0.10206913203001022, -0.540533721446991, -0.45353320240974426, -0.3357941508293152, -0.25778183341026306, 0.034922562539577484, -0.1649370789527893, 0.12087574601173401, 0.11164867132902145, 0.20776315033435822, 0.06519801169633865, 0.8301501274108887, -0.4603954553604126, -0.4812946915626526, 0.009523971006274223, -0.23416395485401154, -0.16973266005516052, -0.2785331904888153, -0.37404701113700867, -1.4603384733200073, 0.26216745376586914, -1.6275050640106201, 0.43989259004592896, -0.8317358493804932, -0.029652375727891922, 0.35057657957077026, -0.6804828643798828, 0.6128888130187988, 0.04085840657353401, -0.6063282489776611, -1.0772762298583984, -0.6001701354980469, 0.3269280195236206, 0.38976430892944336, 1.0662728548049927, -0.8125031590461731, 0.046599697321653366, -0.16787733137607574, -0.09300649911165237, 0.24638569355010986, 0.4747365713119507, -0.6909658312797546, -0.9581935405731201, -1.306579828262329, -0.15018761157989502, 0.2794647812843323, -0.2968671917915344, -0.5121466517448425, 0.7324855923652649, 0.16009928286075592, -0.1149715855717659, -0.06110720708966255, 0.5890103578567505, -0.8190007209777832, 0.0665288120508194, 0.7358575463294983, -1.1362813711166382, -0.061238475143909454, -0.15011964738368988, -0.5095067620277405, -0.6015321016311646, 0.5108828544616699, 0.24894462525844574, -1.2964189052581787, -0.2898109257221222, 0.7744210362434387, -0.9922313690185547, -0.26360225677490234, 0.00809730589389801, 0.26638367772102356, -0.35983744263648987, -0.008074342273175716, -0.6283926963806152, 0.530478298664093, -1.1095499992370605, 0.9216233491897583, 0.7942509055137634, -0.5096425414085388, -0.37223559617996216, 0.3086727261543274, 0.0653899759054184, -0.6443911194801331, 0.5974382758140564, 0.5342526435852051, -0.3568926155567169, 1.2314577102661133, 0.38706958293914795, 0.4161280691623688, -1.4229521751403809, 0.05183132737874985, 1.0528898239135742, -0.5222181081771851, -0.3943917453289032, 1.3322477340698242, 0.00652793375775218, -1.0275932550430298, 0.2792259752750397, -1.3234951496124268, -0.6746366620063782, -0.6093326807022095, 0.4348517954349518, -0.43566229939460754, -0.011209600605070591, -0.5510478615760803, -0.790929913520813, -0.21101048588752747, 0.1798834353685379, -0.16364657878875732, 0.8551117181777954, 0.01574230007827282, -0.41227811574935913, 0.4842572808265686, 0.8327277302742004, -0.7753862738609314, 0.166799396276474, -0.6357051730155945, 0.2563270926475525, 0.23490647971630096, 0.18988384306430817, -0.572139322757721, -0.7219751477241516, 0.38778141140937805, 0.4978731870651245, -0.4285317063331604, 0.3317318856716156, -0.3958837389945984, 0.1253223717212677, 0.6517670750617981, 0.04083281755447388, -0.5820181369781494, -0.8074594140052795, 1.3972859382629395, 1.2300336360931396, -0.8687410950660706, 0.11133714020252228, -0.8342673778533936, -0.7076994776725769, 1.0054394006729126, 0.05748102068901062, 0.3171243667602539, 1.5746824741363525, -0.2962309718132019, 0.23673328757286072, -0.09164971858263016, -0.783738374710083, 0.2703222334384918, 1.2132397890090942, 0.42990314960479736, 1.4915019273757935, 0.5935873985290527, -0.48026934266090393, 1.2892812490463257, 0.12454528361558914, 0.5542115569114685, 0.4006302058696747, 0.6313877105712891, 0.07210181653499603, -0.5890288949012756, 0.3658725321292877, 0.9235783219337463, -1.056140661239624, -0.7364387512207031, -0.2660495936870575, 0.18949343264102936, 0.5055954456329346, 0.6801507472991943, -0.05275781452655792, -0.0288175530731678, 0.4207009971141815, 0.8314121961593628, -0.09232378751039505, -1.1739604473114014, -0.4811793863773346, -0.1180732324719429, -0.3437137007713318, 0.26449793577194214, -0.49478596448898315, -0.30617037415504456, -0.4027533531188965, 0.5867997407913208, 0.68384850025177, 0.0541398748755455, 0.29643797874450684, 1.144494891166687, 0.49339884519577026, 0.3666043281555176, -0.594704806804657, 0.5886603593826294, -0.27719226479530334, -1.1209819316864014, -0.15747031569480896, -0.48787638545036316, -0.009441702626645565, 0.07400178164243698, 0.028707925230264664, 0.2879366874694824]}, "authors": [{"authorId": "2894465", "name": "Benyou Wang"}, {"authorId": "1974486100", "name": "Qianqian Xie"}, {"authorId": "2143384839", "name": "Jiahuan Pei"}, {"authorId": "2086549", "name": "P. Tiwari"}, {"authorId": "2156264847", "name": "Zhao Li"}, {"authorId": "2119314938", "name": "Jie Fu"}], "references": [{"paperId": "6e6bf202d2bb3d22c08863b160ea93fbb2d6b0cc", "title": "Med-UniC: Unifying Cross-Lingual Medical Vision-Language Pre-Training by Diminishing Bias"}, {"paperId": "30fd5cad61b20dd39a49fb50c3dbc300d146c049", "title": "Injecting Knowledge into Biomedical Pre-trained Models via Polymorphism and Synonymous Substitution"}, {"paperId": "a9d61f1688247bb8d92c393395129c52b7c0d0f8", "title": "Is Information Extraction Solved by ChatGPT? An Analysis of Performance, Evaluation Criteria, Robustness and Errors"}, {"paperId": "b6d6c33298b852cf63edac233deca70530d69a2a", "title": "PaLM 2 Technical Report"}, {"paperId": "7ed0faa6720cd176d57badbc0455af31a03f080c", "title": "Towards Expert-Level Medical Question Answering with Large Language Models"}, {"paperId": "1c5bc4f10b95a90d0283d0aacc94332aae508169", "title": "Huatuo-26M, a Large-scale Chinese Medical QA Dataset"}, {"paperId": "5eab810cc5d90de1c52127d1a5824f0817f46c30", "title": "Natural Language Reasoning, A Survey"}, {"paperId": "59fc3119090d6dd98ebc3a619e22ab4b603952fa", "title": "FactReranker: Fact-guided Reranker for Faithful Radiology Report Summarization"}, {"paperId": "e2cbafe8deed5db6d506e41cc4a261231ebb528a", "title": "CitationSum: Citation-aware Graph Contrastive Learning for Scientific Paper Summarization"}, {"paperId": "fdbe8d1896b754125c6255f07bd9fecc2ea59127", "title": "Putting ChatGPT's Medical Advice to the (Turing) Test"}, {"paperId": "6052486bc9144dc1730c12bf35323af3792a1fd0", "title": "Large language models encode clinical knowledge"}, {"paperId": "cf1f26e7cbed3958b3c2870656568c299fece6e3", "title": "Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models"}, {"paperId": "c3d877b29594bc6f244e638f576be3dca5551f11", "title": "A Comparative Study of Pretrained Language Models for Long Clinical Text"}, {"paperId": "8e97d6593f63e5d83a14bd234ebd0b95b730fba3", "title": "RoentGen: Vision-Language Foundation Model for Chest X-ray Generation"}, {"paperId": "143393d7067919a893162359777649001e708818", "title": "The Role of Local Alignment and Uniformity in Image-Text Contrastive Learning on Medical Images"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "cdd9c1d23f9e89d5113f3e31821bb174c6a6afed", "title": "MedCLIP: Contrastive Learning from Unpaired Medical Images and Text"}, {"paperId": "4867e6c7d190e37b9199a67ebeac62180b59aa32", "title": "Multi-Granularity Cross-modal Alignment for Generalized Medical Visual Representation Learning"}, {"paperId": "8a9e7290d403dd2098e5ce80d6338ae03071cf85", "title": "Readability Controllable Biomedical Document Summarization"}, {"paperId": "f5225015bcdad0a1daf7d205c67fc297fb9ec978", "title": "Adapting Pretrained Vision-Language Foundational Models to Medical Imaging Domains"}, {"paperId": "44279244407a64431810f982be6d0c7da4429dd7", "title": "BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining"}, {"paperId": "76120de60a9e59c23a372457a056da3c220c64b6", "title": "Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning"}, {"paperId": "81adb80e390f25d4a2d764b1063eeaa2c334d441", "title": "Multi-modal Masked Autoencoders for Medical Vision-and-Language Pre-training"}, {"paperId": "28ff0816f19a5e3e37eac5569de41872fd262f0a", "title": "Align, Reason and Learn: Enhancing Medical Vision-and-Language Pre-training with Knowledge"}, {"paperId": "89a87a8a3f94dc28ad941d64336c1744533b5a77", "title": "GRETEL: Graph Contrastive Topic Enhanced Language Model for Long Document Extractive Summarization"}, {"paperId": "d697b440dd0e65a05fe027e4c0ea85f62dcba033", "title": "Can large language models reason about medical questions?"}, {"paperId": "ae4acc595d460358c0ee44afc4483f2d9c5cb766", "title": "Pre-trained language models with domain knowledge for biomedical extractive summarization"}, {"paperId": "b1c037a32ea0cb74232c84fab435d1392ef36f88", "title": "LViT: Language Meets Vision Transformer in Medical Image Segmentation"}, {"paperId": "9695824d7a01fad57ba9c01d7d76a519d78d65e7", "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"}, {"paperId": "dbcdff38ed53f5d279862e287744fdc1ed439249", "title": "Breaking with Fixed Set Pathology Recognition through Report-Guided Contrastive Training"}, {"paperId": "a1aeb5442e31276b197696f49b3243112a4049ce", "title": "Making the Most of Text Semantics to Improve Biomedical Vision-Language Processing"}, {"paperId": "c57293882b2561e1ba03017902df9fc2f289dea2", "title": "Hierarchical Text-Conditional Image Generation with CLIP Latents"}, {"paperId": "0db5207510819b9956849eb84bfe8703f8f3688d", "title": "BioBART: Pretraining and Evaluation of A Biomedical Generative Language Model"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "4714313c8dcc5e51236e90146c24df1f440250e5", "title": "Graph Enhanced Contrastive Learning for Radiology Findings Summarization"}, {"paperId": "a83cdcc0135c58fddf89fc72f1b92b7a9d1e170f", "title": "LinkBERT: Pretraining Language Models with Document Links"}, {"paperId": "f30e95be411456a709e7cb9a8b3a3e557bd0356a", "title": "Clinical-Longformer and Clinical-BigBird: Transformers for long clinical sequences"}, {"paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d", "title": "High-Resolution Image Synthesis with Latent Diffusion Models"}, {"paperId": "a9c5e23c5559bfc4d95dd166c1ed29fa026bbf2e", "title": "Fine-tuning large neural language models for biomedical natural language processing"}, {"paperId": "2fca2821ac2beb60fa0e26866e8f063261713951", "title": "Joint Learning of Localized Representations from Medical Images and Reports"}, {"paperId": "9c4753ef43d2928866dc5bf6cec53d03373ec2fa", "title": "SimMIM: a Simple Framework for Masked Image Modeling"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "0b500aa5fcc175f07aecf26c0e8ddc4f0c6a931d", "title": "GLoRIA: A Multimodal Global-Local Representation Learning Framework for Label-efficient Medical Image Recognition"}, {"paperId": "505555bad8dae8af519e5f0d77f42b233e429d89", "title": "Continual knowledge infusion into pre-trained biomedical language models"}, {"paperId": "03229d15414f82417d1862f69a835e560611977e", "title": "ReMeDi: Resources for Multi-domain, Multi-service, Medical Dialogues"}, {"paperId": "b42d20ec9580ebd76860890a1d7a7fdcc742677e", "title": "Modeling Protein Using Large-scale Pretrain Language Model"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "07afa574f83862f074192333b643f04e99b0281d", "title": "BERTHop: An Effective Vision-and-Language Model for Chest X-ray Disease Diagnosis"}, {"paperId": "55c8521e976b54bfe48e24b5a3ce519932069143", "title": "Protein language model embeddings for fast, accurate, alignment-free protein structure prediction"}, {"paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"}, {"paperId": "423af636a86309e68f6716143ec6b6278aa95bc0", "title": "Biomedical Named Entity Recognition via Knowledge Guidance and Question Answering"}, {"paperId": "dc32a984b651256a8ec282be52310e6bd33d9815", "title": "Highly accurate protein structure prediction with AlphaFold"}, {"paperId": "25b3aacaa9b98f0e0d41588cf0e36efe4fb7dc43", "title": "BERTax: taxonomic classification of DNA sequences with Deep Neural Networks"}, {"paperId": "d8e375017de9fd2c875b6925cbd6c64519a9c558", "title": "MedGPT: Medical Concept Prediction from Clinical Narratives"}, {"paperId": "a6a7724763d8adba466519489b0b9d209e7f2d15", "title": "BARTScore: Evaluating Generated Text as Text Generation"}, {"paperId": "e337ed6543c2e6e7e51c312c7d998798fc79fdde", "title": "Knowledgeable or Educated Guess? Revisiting Language Models as Knowledge Bases"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "cb2a38002e2f346b084e7dd6c9fcf2bb45de5a9e", "title": "CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark"}, {"paperId": "896c76bf99de9c1ba6fc3dfb695dfa66e73e1eb3", "title": "Probing Pre-Trained Language Models for Disease Knowledge"}, {"paperId": "feba0c47bf12a02c3a725174bb53df78658a72a8", "title": "Pre-Trained Models: Past, Present and Future"}, {"paperId": "4a53a4ab7afa19c64a0721f4bcc3e643acfa681e", "title": "A GPT-2 Language Model for Biomedical Texts in Portuguese"}, {"paperId": "6003d268e9b5230dbc3e320497b50329d6186816", "title": "SciFive: a text-to-text transformer model for biomedical literature"}, {"paperId": "c07651110d3b98b63607557b57808d15d99013dd", "title": "ProteinBERT: a universal deep-learning model of protein sequence and function"}, {"paperId": "d9317660e2a538d9c018028956fd114d55330f82", "title": "Multi-Modal Understanding and Generation for Medical Images and Text via Vision-Language Pre-Training"}, {"paperId": "b58d8579ece27a60432e667bfbdb750590fa65d9", "title": "True Few-Shot Learning with Language Models"}, {"paperId": "54738ed18575f40e9ff3ad0181aaccc527fc4f95", "title": "Semi-Supervised Variational Reasoning for Medical Dialogue Generation"}, {"paperId": "1dd525b5af40e613ae1665cf15a193b5ef23431b", "title": "Improving BERT Model Using Contrastive Learning for Biomedical Relation Extraction"}, {"paperId": "a76c11fd3119c44520f7487b4141ff7e833bc5d0", "title": "Prediction of RNA\u2013protein interactions using a nucleotide language model"}, {"paperId": "58fe64beb45b18f63cbc001849a0dee3e4e60482", "title": "Improving Biomedical Pretrained Language Models with Knowledge"}, {"paperId": "4afa7d8e2de43b0b67366b1bce8768f5a246d153", "title": "Bayesian Optimization is Superior to Random Search for Machine Learning Hyperparameter Tuning: Analysis of the Black-Box Optimization Challenge 2020"}, {"paperId": "1991ea2ec85113cadf38faea840f4b5cf73ae0c7", "title": "ELECTRAMed: a new pre-trained language representation model for biomedical NLP"}, {"paperId": "4fe19d28d91fb42047ca4bc7602f647c007b32c2", "title": "Attention-based clinical note summarization"}, {"paperId": "420c897bc67e6f438db522d919d925df1a10aa8c", "title": "AMMU: A survey of transformer-based biomedical pretrained language models"}, {"paperId": "c464563311ded1ebe16cf68dc894f0d9c744d597", "title": "Sequence tagging for biomedical extractive question answering"}, {"paperId": "1d5c07e7415a7e9be078717197ddf9f3c70a2875", "title": "Does BERT Pretrained on Clinical Notes Reveal Sensitive Data?"}, {"paperId": "49a77a36a0a60d29aa7838ac49a055a69658b195", "title": "K-PLUG: Knowledge-injected Pre-trained Language Model for Natural Language Understanding and Generation in E-Commerce"}, {"paperId": "d25121da56c9050137800c69520111b30201d1ed", "title": "MS\u02c62: Multi-Document Summarization of Medical Studies"}, {"paperId": "a978fcb10817abe8bc91ab2ba0c0bb4605add1d9", "title": "Discourse Probing of Pretrained Language Models"}, {"paperId": "59cc829af19b7711c05dd9f2d12a0e7fe4a65569", "title": "COVID-19 information retrieval with deep-learning based semantic search, question answering, and abstractive summarization"}, {"paperId": "c49d8a576ee4c1778eafd75f00565f75864054e4", "title": "Self-supervised Image-text Pre-training With Mixed Data In Chest X-rays"}, {"paperId": "8994bce4b85a8b4087584661c49f8776f868f7dd", "title": "Interpretable Bias Mitigation for Textual Data: Reducing Genderization in Patient Notes While Maintaining Classification Performance"}, {"paperId": "25a493caee870b9950a9d972bdfae6c478d0816d", "title": "Multimodal Representation Learning via Maximization of Local Mutual Information"}, {"paperId": "dfb37e6216e792bf6bd5a30c0fc7ad55df1cb71e", "title": "Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth"}, {"paperId": "beb6a2d33b1979d9d2010fc5721fd307e015c342", "title": "Bidirectional Representation Learning From Transformers Using Multimodal Electronic Health Record Data to Predict Depression"}, {"paperId": "c0e6cd2ec3bc9eb46c7d45bb708854da3327339e", "title": "A Survey on Bias in Deep NLP"}, {"paperId": "474c63c4238e830ae395cad69bb4533e69731ff3", "title": "Limitations of Transformers on Clinical Text Classification"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "60c4ea58eb7fccbf189837a94760b2605bb54dde", "title": "A Cooperative Memory Network for Personalized Task-oriented Dialogue Systems with Incomplete User Profiles"}, {"paperId": "deee48c5e0ac0407a1e002905caaf2b174bdb0e6", "title": "MSA Transformer"}, {"paperId": "89d0505974747c21d28309b26257bfe56c4eaeda", "title": "Unsupervised Extractive Summarization using Pointwise Mutual Information"}, {"paperId": "6f412cbe1bc515c8c9fb0d6cd2e96c58d18e7951", "title": "A pre-training and self-training approach for biomedical named entity recognition"}, {"paperId": "75f1c7dadb4ed733fb4d3a4cc47b9cbde9ad98cc", "title": "Combining pre-trained language models and structured knowledge"}, {"paperId": "feecf3e9ff390ccd0101e9c2590dea32bcb4070f", "title": "Transformer-Based Models for Question Answering on COVID19"}, {"paperId": "c375e121926db9551f224ff235018ea38bb159b7", "title": "BinaryBERT: Pushing the Limit of BERT Quantization"}, {"paperId": "5b4376a0b97a474a4e063768cc4faf20691b7887", "title": "Automated Lay Language Summarization of Biomedical Scientific Reviews"}, {"paperId": "2ad565fb0ce9cda15a9e5ce37b5678ec09b134b9", "title": "Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue Generation"}, {"paperId": "f9327f5b4493bea71833d0bf6c5d039f331c069e", "title": "Cross2Self-attentive Bidirectional Recurrent Neural Network with BERT for Biomedical Semantic Text Similarity"}, {"paperId": "c6ba01a86927c3abb891ed268353c14f9faa8097", "title": "End-to-End QA on COVID-19: Domain Adaptation with Synthetic Training"}, {"paperId": "9eaceb2b21876a39f948c6841deee2c2767fba2f", "title": "LBERT: Lexically-aware Transformers based Bidirectional Encoder Representation model for learning Universal Bio-Entity Relations"}, {"paperId": "903ad24a5e924086869f6f9f0ae2992ae2971048", "title": "BioMedBERT: A Pre-trained Biomedical Language Model for QA and IR"}, {"paperId": "c7c201d81538bf68ff373238597fd2991a0dca44", "title": "Profile Prediction: An Alignment-Based Pre-Training Task for Protein Sequence Models"}, {"paperId": "06af86469540794522169e80361aff89d6d9535e", "title": "Summarizing Medical Conversations via Identifying Important Utterances"}, {"paperId": "c7dd71e6a24acbd9174cefdc68fa23baf5abcab9", "title": "Experiments on transfer learning architectures for biomedical relation extraction"}, {"paperId": "70b0c85638d195dbde56cbedc94ae4363b272b58", "title": "A Pre-Training Technique to Localize Medical BERT and to Enhance Biomedical BERT"}, {"paperId": "a9f104cf0c1584d4d6df46d2e551fcdffa4e4b84", "title": "Medical Knowledge-enriched Textual Entailment Framework"}, {"paperId": "a79b520571f7373cbeb8c6ffc02f6a719b3bce38", "title": "CODER: Knowledge-infused cross-lingual medical term embedding for term normalization"}, {"paperId": "76ad0d37bd3845431b3ca9d07f8db74c82752298", "title": "Pretrained Language Models for Biomedical and Clinical Tasks: Understanding and Extending the State-of-the-Art"}, {"paperId": "604959267cef4b1495df9b0bc03303c4f1b2f715", "title": "BioBERTpt - A Portuguese Neural Language Model for Clinical Named Entity Recognition"}, {"paperId": "fefa0bd805beef371a1679a74a1b9f9f8a1baacd", "title": "FedED: Federated Learning via Ensemble Distillation for Medical Relation Extraction"}, {"paperId": "59da4f7d85967d922b5d674779ffcee06f186c73", "title": "Investigation of BERT Model on Biomedical Relation Extraction Based on Revised Fine-tuning Mechanism"}, {"paperId": "2fcee0b96353e81595325ff77c47bfdb82d03fff", "title": "Biomedical Event Extraction as Sequence Labeling"}, {"paperId": "24bdcb3d033f25f4dd593cc028ba32d18822c9ab", "title": "Biomedical Event Extraction as Multi-turn Question Answering"}, {"paperId": "2739deec362784909563db9411c4b9d9e62a1ed5", "title": "Modern Clinical Text Mining: A Guide and Review."}, {"paperId": "4b6da028739a126b0df08e9b5d4f01c288c210f3", "title": "A BERT-Based Named Entity Recognition in Chinese Electronic Medical Record"}, {"paperId": "b9868f59ed09866143261e43e7596d1c71326399", "title": "Clinical concept extraction using transformers"}, {"paperId": "03935e520c612ac9f137d9e9ef388e0c08568b60", "title": "UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus"}, {"paperId": "c7b5bed0141ed30f1aadbf4b2cba786679015835", "title": "MedDG: A Large-scale Medical Consultation Dataset for Building Medical Dialogue System"}, {"paperId": "6d6595766a35f12a6ad671d05634b5e2159d4f3e", "title": "Bio-Megatron: Larger Biomedical Domain Language Model"}, {"paperId": "9be1d1bf82f6ca6a7bf6a7d92f8f37b647e493d0", "title": "Probing Pretrained Language Models for Lexical Semantics"}, {"paperId": "e39a4b182c3bae017b08df20b37b9d1d97c9a4bf", "title": "Multi-Stage Pretraining for Low-Resource Domain Adaptation"}, {"paperId": "5ba77a5bdeffb62aa0902ae68997bbc38db8a722", "title": "MedICaT: A Dataset of Medical Images, Captions, and Textual References"}, {"paperId": "4889ba5a8ae8b2169dd44d1d3a605bf9820bae8d", "title": "What Do Position Embeddings Learn? An Empirical Study of Pre-Trained Language Model Positional Encoding"}, {"paperId": "ef26dad0f2fa7c06c54c0b8c3fa1274354f7e6e5", "title": "Crosslingual named entity recognition for clinical de-identification applied to a COVID-19 Italian data set"}, {"paperId": "3b2664a15b46e95eecb9573f21c36892037b0264", "title": "Infusing Disease Knowledge into BERT for Health Question Answering, Medical Inference and Disease Name Recognition"}, {"paperId": "a2cde1da31a61adab24e702999680108ab58e5ff", "title": "COMETA: A Corpus for Medical Entity Linking in the Social Media"}, {"paperId": "6dd9f99cecd38504b667d320eb2a6267a9fee35d", "title": "Contrastive Learning of Medical Visual Representations from Paired Images and Text"}, {"paperId": null, "title": "Transformers: State-of-the-Art Natural Language Processing"}, {"paperId": "697a19567dbb8f31c10b6b33b490b5522987f47d", "title": "Unsupervised Pre-training for Biomedical Question Answering"}, {"paperId": "097210dc65924f8ce59523faf444e635523dc714", "title": "TernaryBERT: Distillation-aware Ultra-low Bit BERT"}, {"paperId": "f2861a7c7155c50e2efab3bdec1a491a1b786b03", "title": "BioALBERT: A Simple and Effective Pre-trained Language Model for Biomedical Named Entity Recognition"}, {"paperId": "c43d9cade31600400a0f62beb5bbcc1b548e009e", "title": "DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "065c60b4a8f69bccfbbf9b0ac3b3615b984b51bd", "title": "Improving fine-tuned question answering models for electronic health records"}, {"paperId": "1cad933afc55f1a562e27ebd4f65c5d0f5a6c26a", "title": "Task-specific Objectives of Pre-trained Language Models for Dialogue Adaptation"}, {"paperId": "850f298337728fea2e19ad48975ddee89a34c088", "title": "Biomedical named entity recognition using BERT in the machine reading comprehension framework"}, {"paperId": "ed2a06388dd14b052f33bac5e3bfc0fa26243b55", "title": "A Comparison of Pre-trained Vision-and-Language Models for Multimodal Representation Learning across Medical Images and Reports"}, {"paperId": "4535f00f4116082d93e35448048e116aa46e795d", "title": "Korean clinical entity recognition from diagnosis text using BERT"}, {"paperId": "44f02e037fd78116f921c8c57bc9ee3f7b2e64fd", "title": "Generating (Factual?) Narrative Summaries of RCTs: Experiments with Neural Multi-Document Summarization"}, {"paperId": "2b01b3334ce950c76c9c3c2c9146a7f0ce79cc50", "title": "Conceptualized Representation Learning for Chinese Biomedical Text Mining"}, {"paperId": "be52ae1d84e4614102b7a62697499f24c6fbe81d", "title": "LBERT: Lexically-aware Transformers based Bidirectional Encoder Representation model for learning Universal Bio-Entity Relations."}, {"paperId": "3d09912d7630b11dcb36af59eff64474ea281d80", "title": "The 2019 n2c2/OHNLP Track on Clinical Semantic Textual Similarity: Overview"}, {"paperId": "a2f38d03fd363e920494ad65a5f0ad8bd18cd60b", "title": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "eba8c42f158f0333b77c2c4c017e6a5fd47e806a", "title": "Ethics of Artificial Intelligence in Surgery"}, {"paperId": "7c462df4adefcf90af3c27ce7f7a8d83efbff2b0", "title": "Measurement of Semantic Textual Similarity in Clinical Texts: Comparison of Transformer-Based Models"}, {"paperId": "b01b962620a1627dbdd0d202eda9e7185fa8f2e0", "title": "Highly accurate classification of chest radiographic reports using a deep learning natural language model pre-trained on 3.8 million text reports"}, {"paperId": "ca9b4fc03ad3ea4680ab2204ecf215f333c616a4", "title": "ProtTrans: Towards Cracking the Language of Life\u2019s Code Through Self-Supervised Deep Learning and High Performance Computing"}, {"paperId": "18b0f8b819e15a6a91b3f6c0555209fd507630a3", "title": "A clinical specific BERT developed with huge size of Japanese clinical narrative"}, {"paperId": "790dd0db272b948806432db374b6d89717b54838", "title": "Biomedical-domain pre-trained language model for extractive summarization"}, {"paperId": "dc7975f6a57bc5991dd5145be490445425c593c4", "title": "A BERT-based One-Pass Multi-Task Model for Clinical Temporal Relation Extraction"}, {"paperId": "1a308d3793363f47eae2ca1429e3078a01bb5e26", "title": "MIE: A Medical Information Extractor towards Medical Dialogues"}, {"paperId": "c0091585ae4f9cccd4c1dba5aa7409c0886553fa", "title": "Transferability of Natural Language Inference to Biomedical Question Answering"}, {"paperId": "a562a6f14283f176a80a7254048db0efe0ee830c", "title": "Answering Questions on COVID-19 in Real-Time"}, {"paperId": "e23cb51f50f749320b9122fb5f75113b4d192c0a", "title": "Evaluation of Text Generation: A Survey"}, {"paperId": "2b364917b0c51e91fcf2ab9c1d66a14ed4b44c03", "title": "BERTology Meets Biology: Interpreting Attention in Protein Language Models"}, {"paperId": "4cd1eacb7d0e3657ac01a4f687638832546cd072", "title": "DeepEventMine: end-to-end neural nested event extraction from biomedical texts"}, {"paperId": "27f0246890395d743252fd93282544c7efdec443", "title": "CO-Search: COVID-19 Information Retrieval with Semantic Search, Question Answering, and Abstractive Summarization"}, {"paperId": "7a23a2948fa3a9d48e3c3bd071b522f417e59955", "title": "Results of the Seventh Edition of the BioASQ Challenge"}, {"paperId": "73834d44db8577576b347a6b30500ebbe4d6c3fa", "title": "Document Classification for COVID-19 Literature"}, {"paperId": "85bb1317013141d5e5f41d18376cd7257c46264a", "title": "Document Classification for COVID-19 Literature"}, {"paperId": "38f93092ece8eee9771e61c1edaf11b1293cae1b", "title": "Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning"}, {"paperId": "8b9d77d5e52a70af37451d3db3d32781b83ea054", "title": "On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines"}, {"paperId": "762baed866a8f23e19ea52f265c9ba7f353896ce", "title": "Automatic Text Summarization of COVID-19 Medical Research Articles using BERT and GPT-2"}, {"paperId": "d47a682723f710395454687319bb55635e653105", "title": "Language (Technology) is Power: A Critical Survey of \u201cBias\u201d in NLP"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "5b0b876a815f8a07876052c03c4a733d595f72fb", "title": "On the effectiveness of small, discriminatively pre-trained language representation models for biomedical text mining"}, {"paperId": "5d4de0fa45aeddc31142e6a24666d06ed7923f1e", "title": "Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction"}, {"paperId": "72cdd6ebe0221fb568ef20534f44ba5b35190a56", "title": "BERTweet: A pre-trained language model for English Tweets"}, {"paperId": "126fb7df6bcab2b70000dfe5b940ada63ae1ba6a", "title": "COVID-Twitter-BERT: A natural language processing model to analyse COVID-19 content on Twitter"}, {"paperId": "18629f4edead8bcf07e5ef694914ba83dd1e9666", "title": "Entity-Enriched Neural Models for Clinical Question Answering"}, {"paperId": "57fd722e2bbfffdb5b36a12ded59a303dbad95c5", "title": "On the Generation of Medical Dialogues for COVID-19"}, {"paperId": "8500552bb21127e6957f2b6fa1cede0b918000a1", "title": "Comparative Analysis of Text Classification Approaches in Electronic Health Records"}, {"paperId": "1d77bf9273392156b309b7ed871449776f9a1618", "title": "CAiRE-COVID: A Question Answering and Query-focused Multi-Document Summarization System for COVID-19 Scholarly Information Management"}, {"paperId": "016760dc4a05489ddf5dbb48aecbb49e214e1b71", "title": "Birds Have Four Legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-trained Language Models"}, {"paperId": "cebf0335d051b95a1810c0dd237b8bd5a36346a0", "title": "Evaluation of Dataset Selection for Pre-Training and Fine-Tuning Transformer Language Models for Clinical Question Answering"}, {"paperId": "4c3b5f8db4f44ed4d24e15227a0da30f7c20a665", "title": "Attend to Medical Ontologies: Content Selection for Clinical Abstractive Summarization"}, {"paperId": "3aaa8aaad5ef36550a6b47d6ee000f0b346a5a1f", "title": "Perturbed Masking: Parameter-free Probing for Analyzing and Interpreting BERT"}, {"paperId": "e0fe2936aa9c5142b75a382f29d3398f4b810c73", "title": "Towards Chinese clinical named entity recognition by dynamic embedding using domain-specific knowledge"}, {"paperId": "e014af8ae8d7dbd3c1c908dfba334a6d2181b8e1", "title": "Task-oriented Dialogue System for Automatic Disease Diagnosis via Hierarchical Reinforcement Learning"}, {"paperId": "636e89ca198156cd8b7a799f460004da7eb4c3ad", "title": "Chinese clinical named entity recognition with variant neural structures based on BERT methods"}, {"paperId": "e816f788767eec6a8ef0ea9eddd0e902435d4271", "title": "Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks"}, {"paperId": "0f995b05821b58b02e914422b56fba615d0e8d7f", "title": "Rapidly Bootstrapping a Question Answering Dataset for COVID-19"}, {"paperId": "bc411487f305e451d7485e53202ec241fcc97d3b", "title": "CORD-19: The Covid-19 Open Research Dataset"}, {"paperId": "f4e7e312e1e2b462936534fd566fb4a16e0d29d2", "title": "Text classification models for the automatic detection of nonmedical prescription medication use from social media"}, {"paperId": "dbcea4cfd482a0b7b366077d75b858ef38f37f8f", "title": "Robustly Pre-Trained Neural Model for Direct Temporal Relation Extraction"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "9afed5a68ec147ddf221c9ae6c7ff8f0ceef2ef8", "title": "The Russian Drug Reaction Corpus and Neural Models for Drug Reactions and Effectiveness Detection in User Reviews"}, {"paperId": "5e52f3b7fd14f151b26309e9f06239ddcd99b39a", "title": "MedDialog: A Large-scale Medical Dialogue Dataset"}, {"paperId": "25a49187e0d1e3ebebda71c7e77f31bc49358044", "title": "Inexpensive Domain Adaptation of Pretrained Language Models: Case Studies on Biomedical NER and Covid-19 QA"}, {"paperId": "6c62f9617830d2b5246a05a1a5d3664660dc7985", "title": "Understanding Medical Conversations with Scattered Keyword Attention and Weak Supervision from Responses"}, {"paperId": "c2d80269e20ba8fa41fe49313253faf3f18c48a6", "title": "Generative Adversarial Regularized Mutual Information Policy Gradient Framework for Automatic Diagnosis"}, {"paperId": "598a2ee223e2949c3b28389e922c1892b4717d2a", "title": "Pixel-BERT: Aligning Image Pixels with Text by Deep Multi-Modal Transformers"}, {"paperId": "e1b188b33a8ddc314679551a74bb561bef30af06", "title": "Named Entity Recognition in Spanish Biomedical Literature: Short Review and Bert Model"}, {"paperId": "b2fd96a52ded7a64f60c1e54f5bb488c787629c0", "title": "What Happens To BERT Embeddings During Fine-tuning?"}, {"paperId": "1c332cfa211400fc6f56983fb01a6692046116dd", "title": "DynaBERT: Dynamic BERT with Adaptive Width and Depth"}, {"paperId": "e06f6d79b57ddf9e8fecc0b24a8e3045ea66ad9a", "title": "On Biomedical Named Entity Recognition: Experiments in Interlingual Transfer for Clinical and Social Media Texts"}, {"paperId": "3bcb17559ce96eb20fa79af8194f4af0380d194a", "title": "Pre-trained models for natural language processing: A survey"}, {"paperId": "e092ecf56fcca38d0cd6fe9e1e6b11c380f6c286", "title": "A Survey on Contextual Embeddings"}, {"paperId": "d505eb794676927e919bcfeafdd1680a4bf10229", "title": "Hurtful words: quantifying biases in clinical contextual word embeddings"}, {"paperId": "c5f7074a264356c9a022a8dff24df79d1db8c3d3", "title": "ProGen: Language Modeling for Protein Generation"}, {"paperId": "bd5dce93d58fadf3a01bdf1e685ec26fad60e614", "title": "Federated Machine Learning"}, {"paperId": "0134bdb3cce9f9d5784adb40438a366a0e1f0ffd", "title": "Pre-trained language model augmented adversarial training network for Chinese clinical event detection."}, {"paperId": "0fe2636446cd686830da3d971b31a004d6094b3c", "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages"}, {"paperId": "f57954e72bf805b0717a0fc5b59156ac58f51648", "title": "Deep Scaled Dot-Product Attention Based Domain Adaptation Model For Biomedical Question Answering."}, {"paperId": "7af72a461ed7cda180e7eab878efd5f35d79bbf4", "title": "A Simple Framework for Contrastive Learning of Visual Representations"}, {"paperId": "616e0f73229c118e1e50a1d9e868a198915cecd8", "title": "Testing Contextualized Word Embeddings to Improve NER in Spanish Clinical Case Narratives"}, {"paperId": "1359d2ef45f1550941e22bf046026c89f6edf315", "title": "AraBERT: Transformer-based Model for Arabic Language Understanding"}, {"paperId": "dc5da5ac3aff86e4b0156c52d9641d05dc1eeace", "title": "MT-BioNER: Multi-task Learning for Biomedical Named Entity Recognition using Deep Bidirectional Transformers"}, {"paperId": "28263e06835ae078fed27faffc82986f32e3070e", "title": "Deep learning for electronic health records: A comparative review of multiple deep neural architectures"}, {"paperId": "4c72d6e102408889a6b3179d08b55b75a115bb90", "title": "Document-Level Biomedical Relation Extraction Leveraging Pretrained Self-Attention Structure and Entity Replacement: Algorithm and Pretreatment Method Validation Study"}, {"paperId": "42f0bae2dacba44e9b5d8f050da3cbe41b9fc437", "title": "Clinical XLNet: Modeling Sequential Clinical Notes and Predicting Prolonged Mechanical Ventilation"}, {"paperId": "d0e28f5dc1feae19e41087a92a87992977fd85af", "title": "Encoding word order in complex embeddings"}, {"paperId": "697aa112f629718e3975217f91cf893f4727ea96", "title": "Self-Supervised Contextual Language Representation of Radiology Reports to Improve the Identification of Communication Urgency"}, {"paperId": "a2d2a482ccd62a705c8fafeb5f93bca33a4d796d", "title": "Deep learning in clinical natural language processing: a methodical review"}, {"paperId": "797a9b822bc5159e93108a434fd28d4cb2635879", "title": "A survey of word embeddings for clinical text"}, {"paperId": "0cd8ab37c3f6e3ec1e570dcb2f73fc0bc3a4f541", "title": "Modeling aspects of the language of life through transfer-learning protein sequences"}, {"paperId": "d1f407b16fb8d99487baee37ed0805676c58e7ac", "title": "MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports"}, {"paperId": "add2f205338d70e10ce5e686df4a690e2851bdfc", "title": "Momentum Contrast for Unsupervised Visual Representation Learning"}, {"paperId": "3f55c542de1e5a19e33cba481dd5460b2a92a266", "title": "ConveRT: Efficient and Accurate Conversational Representations from Transformers"}, {"paperId": "93dc7870d37ea8aad5dc282d255dacf4fef33821", "title": "Optimizing the Factual Correctness of a Summary: A Study of Summarizing Radiology Reports"}, {"paperId": "388e2fcdcefbe0834e153ab2a0be127092f9674d", "title": "DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation"}, {"paperId": "9c800a101fdbc95d76494e74cfec4f533bc1adab", "title": "Enhancing Dialogue Symptom Diagnosis with Global Attention and Symptom Graph"}, {"paperId": "953ad57d381b866dcb16890bd1a568729bc6b7ca", "title": "PharmaCoNER: Pharmacological Substances, Compounds and proteins Named Entity Recognition track"}, {"paperId": "20b847537d3b7b9661733c1770c5faab3c0e2215", "title": "Biomedical Named Entity Recognition with Multilingual BERT"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "fa5eeae07c683533c907d3417eb098084a994456", "title": "Critical assessment of methods of protein structure prediction (CASP)\u2014Round XIII"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "bd01b18df9a39cdd5c66f44051d62f176e9c8e7e", "title": "A BERT-BiLSTM-CRF Model for Chinese Electronic Medical Records Named Entity Recognition"}, {"paperId": "63de7c5f4bbdfffb54ebcdbee3ba0fc289e3d29b", "title": "Named Entity Recognition Using BERT BiLSTM CRF for Chinese Electronic Health Records"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "a9885472e5c40ca4045a229ced1cc439a431387e", "title": "Biomedical relation extraction with pre-trained language representations and minimal task-specific architecture"}, {"paperId": "dfc7b58b67c31932b48586b3e23a43cc94695290", "title": "UNITER: UNiversal Image-TExt Representation Learning"}, {"paperId": "23c26e6ed3de8ec90fbffb3f4c90f8d24432682a", "title": "End-to-end Named Entity Recognition and Relation Extraction using Pre-trained Language Models"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "4267112ddb9959252cf25bb4b7692858434393a7", "title": "Representation Learning for Electronic Health Records"}, {"paperId": "1a00229c25dcc740fd0388ac1e98c42eaa52912e", "title": "Pre-trained Language Model for Biomedical Question Answering"}, {"paperId": "1f4ab7875649852babc851090fc8e0ce73d0e323", "title": "How to Pre-Train Your Model? Comparison of Different Pre-Training Models for Biomedical Question Answering"}, {"paperId": "c33b69855e03958f1d9d3cff7abd2eb2184ecd52", "title": "Fine-Tuning Bidirectional Encoder Representations From Transformers (BERT)\u2013Based Models on Large-Scale Electronic Health Record Notes: An Empirical Study"}, {"paperId": "fac2368c2ec81ef82fd168d49a0def2f8d1ec7d8", "title": "Entity, Relation, and Event Extraction with Contextualized Span Representations"}, {"paperId": "16dc153aaeef8f8e62bd7010f9ab2032ba671a11", "title": "Deep learning with sentence embeddings pre-trained on biomedical corpora improves the performance of finding similar sentences in electronic medical records"}, {"paperId": "49dad93e44975a94768773802b75fc2baabc33cf", "title": "Identifying enhancer-promoter interactions with neural network based on pre-trained DNA vectors and attention mechanism"}, {"paperId": "5b1aac9b91e626d6da47600ae8b1eab2a48707c9", "title": "Evaluation of Five Sentence Similarity Models on Electronic Medical Records"}, {"paperId": "d0086b86103a620a86bc918746df0aa642e2a8a3", "title": "Language Models as Knowledge Bases?"}, {"paperId": "0c3c4c88c7b07596221ac640c7b7102686e3eae3", "title": "PubMedQA: A Dataset for Biomedical Research Question Answering"}, {"paperId": "d97b04b3399b404581c5caa9e96331413cb432dc", "title": "Incorporating Domain Knowledge into Medical NLI using Knowledge Graphs"}, {"paperId": "ac1869e5648e4e6d68dd2b7632079107b49d316b", "title": "Learning to Infer Entities, Properties and their Relations from Clinical Conversations"}, {"paperId": "0090023afc66cd2741568599057f4e82b566137c", "title": "A Survey on Bias and Fairness in Machine Learning"}, {"paperId": "49bdeb07b045dd77f0bfe2b44436608770235a23", "title": "Federated Learning: Challenges, Methods, and Future Directions"}, {"paperId": "be16e643ed6cead716df162c4ac0806a2cdf52b0", "title": "Fine-tuning BERT for Joint Entity and Relation Extraction in Chinese Medical Text"}, {"paperId": "79c93274429d6355959f1e4374c2147bb81ea649", "title": "LXMERT: Learning Cross-Modality Encoder Representations from Transformers"}, {"paperId": "5c456e1cbc2756f790023e26632aa44427385b9d", "title": "An Effective Domain Adaptive Post-Training Method for BERT in Response Selection"}, {"paperId": "7ee67d8b002c111d21a3ec204d531476464924c4", "title": "BioFLAIR: Pretrained Pooled Contextualized Embeddings for Biomedical Sequence Labeling Tasks"}, {"paperId": "5aec474c31a2f4b74703c6f786c0a8ff85c450da", "title": "VisualBERT: A Simple and Performant Baseline for Vision and Language"}, {"paperId": "27ef74894b08899684909b5746beb1bf5b5a99d8", "title": "Clustering of Deep Contextualized Representations for Summarization of Biomedical Texts"}, {"paperId": "e66e64066606b17f6513a2c1ca4cb249c9c95489", "title": "Overview of the MEDIQA 2019 Shared Task on Textual Inference, Question Entailment and Question Answering"}, {"paperId": "1dd4f07cd25f29464cfd8b0a94d089e37265ebe2", "title": "BioBERT Based Named Entity Recognition in Electronic Medical Record"}, {"paperId": "79313c298988d2f3b3c68004bedbf4754c8a1605", "title": "DUT-NLP at MEDIQA 2019: An Adversarial Multi-Task Network to Jointly Model Recognizing Question Entailment and Question Answering"}, {"paperId": "ddbdd937d6793371f28755b5f170eaa67d0a5e74", "title": "WTMED at MEDIQA 2019: A Hybrid Approach to Biomedical Natural Language Inference"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "57633ff5c6f0708be25e651f51eef29d2fbfe48b", "title": "BEHRT: Transformer for Electronic Health Records"}, {"paperId": "493fac37cea49afb98c52c2f5dd75c303a325b25", "title": "Mitigating Gender Bias in Natural Language Processing: Literature Review"}, {"paperId": "ec7c9b201fc1ce18b4e0131691c9418f519a71c5", "title": "Evaluating Protein Transfer Learning with TAPE"}, {"paperId": "2ff41a463a374b138bb5a012e5a32bc4beefec20", "title": "Pre-Training with Whole Word Masking for Chinese BERT"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "1b7942148cba547a56013ccc6e292cdeb008be71", "title": "SEntNet: Source-aware Recurrent Entity Network for Dialogue Response Selection"}, {"paperId": "347bac45298f37cd83c3e79d99b826dc65a70c46", "title": "Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets"}, {"paperId": "9929e732e938c9be0a4e431c7cb785ac03938ff6", "title": "Extracting Symptoms and their Status from Clinical Conversations"}, {"paperId": "c3229debfda1b015c88404cf98f1074237d80809", "title": "Pre-training of Graph Augmented Transformers for Medication Recommendation"}, {"paperId": "b7bdf98ef84909d4ec0b2ebd5157ee3cb38522b8", "title": "Rethinking Complex Neural Network Architectures for Document Classification"}, {"paperId": "a022bda79947d1f656a1164003c1b3ae9a843df9", "title": "How to Fine-Tune BERT for Text Classification?"}, {"paperId": "637514b892ac71c7c1379d3e9d0217e6f53a7d3c", "title": "Classification of Traditional Chinese Medicine Cases based on Character-level Bert and Deep Learning"}, {"paperId": "18a93dc1558bf9d7534d0b416633cebaf75c1145", "title": "Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "5ffa8e4778c430412d804bf53c3ee9e77f0dacea", "title": "Modeling the language of life \u2013 Deep Learning Protein Sequences"}, {"paperId": "b3c2c9f53ab130f3eb76eaaab3afa481c5a405eb", "title": "ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission"}, {"paperId": "2a567ebd78939d0861d788f0fedff8d40ae62bf2", "title": "Publicly Available Clinical BERT Embeddings"}, {"paperId": "5df0b8b80aecda1efdebac5d1ab7bcf94a88c68f", "title": "Probing Biomedical Embeddings from Language Models"}, {"paperId": "79af328616d2440c77449d038f72d053c64d8f1f", "title": "Unified rational protein engineering with sequence-only deep representation learning"}, {"paperId": "db9ff3080be1acac2f403d0c79c9ec776a3d3b5f", "title": "SECNLP: A Survey of Embeddings in Clinical Natural Language Processing"}, {"paperId": "156d217b0a911af97fa1b5a71dc909ccef7a8028", "title": "SciBERT: A Pretrained Language Model for Scientific Text"}, {"paperId": "06b36e744dca445863c9f9aefe76aea95ba95999", "title": "Enhancing Clinical Concept Extraction with Contextual Embedding"}, {"paperId": "3637fcccc758786ae1c6529ab22fe85ea98e9c36", "title": "Learning protein sequence embeddings using information from structure"}, {"paperId": "e14fdf566f9fe9e605e047e8688c75ad4277bc17", "title": "End-to-End Knowledge-Routed Relational Dialogue System for Automatic Diagnosis"}, {"paperId": "62ccd99a65bfc7c735ae1f33b75b107665de95df", "title": "Federated Machine Learning"}, {"paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"}, {"paperId": "3d29ce781f297dc543e44dfb39990baff3a3acca", "title": "MIMIC-CXR-JPG, a large publicly available database of labeled chest radiographs"}, {"paperId": "66617d894e4cefc86efbf9ab984caada733f549e", "title": "A general approach for improving deep learning-based medical relation extraction using a pre-trained model and fine-tuning"}, {"paperId": "889ad3c713bd7f1b3a8e9b07e136ec4a88651893", "title": "Multi-Scale Attentive Interaction Networks for Chinese Medical Question Answer Selection"}, {"paperId": "280b1aa143a2b2746a827d5c480db76371c0aa4b", "title": "Unsupervised Multimodal Representation Learning across Medical Images and Reports"}, {"paperId": "e9aba084dc100209bfc6ca2433d6cadb75fa44df", "title": "CAS: French Corpus with Clinical Cases"}, {"paperId": "fc33b11d0cbc6ec891aa5faa88e471bfa3dee361", "title": "Clinical Concept Extraction with Contextual Word Embedding"}, {"paperId": "5dc8f1af682c4a148bfa0a08d07f5a30f0de2217", "title": "BioSentVec: creating sentence embeddings for biomedical texts"}, {"paperId": "f8b901c330e7f946ef93453b24682f294b8764a1", "title": "In-domain Context-aware Token Embeddings Improve Biomedical Named Entity Recognition"}, {"paperId": "a564fabf130ff6e2742cfba90c7a4018937d764d", "title": "Radiology Objects in COntext (ROCO): A Multimodal Image Dataset"}, {"paperId": "6cbdeb96380e028fb204f9802694e77bb772ed60", "title": "emrQA: A Large Corpus for Question Answering on Electronic Medical Records"}, {"paperId": "7304afb491930d520e194f4ca8b91a9652f0e658", "title": "MedSTS: a resource for clinical semantic textual similarity"}, {"paperId": "f2588de5173fb047192dbb93d62ce6636bdf46bd", "title": "Lessons from Natural Language Inference in the Clinical Domain"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "1abcc5349eeec3608f87caa32fcdb9baa24a3265", "title": "Conversational agents in healthcare: a systematic review"}, {"paperId": "3b821dbfa024027d8c009d8854c958c0e470837a", "title": "Task-oriented Dialogue System for Automatic Diagnosis"}, {"paperId": "0a78873e41615798d09391d9f40d41666b8c9beb", "title": "A Corpus with Multi-Level Annotations of Patients, Interventions and Outcomes to Support Language Processing for Medical Literature"}, {"paperId": "7d4a2515e9239ab03339a92075802f07461e8084", "title": "Crowdbreaks: Tracking Health Trends Using Public Social Media Data and Crowdsourcing"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "cd36768795c696c990ff5c89be8d8b3b205858bd", "title": "CliCR: a Dataset of Clinical Case Reports for Machine Reading Comprehension"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "a765d5e0f48368eddf9c604975fef5aa04925372", "title": "Mining Electronic Health Records (EHRs)"}, {"paperId": "9223c95f0e600aee2dcf476094a5102adc386e0f", "title": "Effective Use of Bidirectional Language Modeling for Transfer Learning in Biomedical Named Entity Recognition"}, {"paperId": "20de699c041ffc9e242cfdb03d4938ec5f849785", "title": "Capturing the Patient\u2019s Perspective: a Review of Advances in Natural Language Processing of Health-Related Text"}, {"paperId": "aa4148c4c5735fb7f5008a71f7ed5cf4d8eeebab", "title": "BioCreative VI Precision Medicine Track: creating a training corpus for mining protein-protein interactions affected by mutations"}, {"paperId": "135bafc83e9a73c88e759f98a28edfdb5c02f81d", "title": "Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints"}, {"paperId": "e8808581cda898f83dadcc79403064a584ac8bd0", "title": "MatchZoo: A Toolkit for Deep Text Matching"}, {"paperId": "d01450f9f0f7603e599f4e3ed4aa3eee1468af84", "title": "BIOSSES: a semantic sentence similarity estimation system for the biomedical domain"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "7baafe78580f101dae63e21cae79b06c8f7b7e50", "title": "Biomedical Natural Language Processing"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "61322ec6cfc54fe9723d4637239b8fb9938dc501", "title": "BioCreative V CDR task corpus: a resource for chemical disease relation extraction"}, {"paperId": "95cd83603a0d2b6918a8e34a5637a8f382da96f5", "title": "MIMIC-III, a freely accessible critical care database"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "995bbef8ff7bbbb7d994e3bfeed1ac169356db5f", "title": "Survey of Natural Language Processing Techniques in Bioinformatics"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "04b9e4192eca063b95ca65db901e1cccfb0ecd6f", "title": "Preparing a collection of radiology examinations for distribution and retrieval"}, {"paperId": "1bd9760237b03f4995f5e205e18d3d7e7ccf5f87", "title": "Overview of the Cancer Genetics and Pathway Curation tasks of BioNLP Shared Task 2013"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "c657ab339517fb8def7ce7f83bb81e746d558218", "title": "Data Resource Profile: Clinical Practice Research Datalink (CPRD)"}, {"paperId": "c4dd9a19d822c965ce8cde55ab23b8a0b628278a", "title": "An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition"}, {"paperId": "d755a7e943009af26e0a5b617ef60c29c1d4f4e0", "title": "CHEMDNER: The drugs and chemical names extraction challenge"}, {"paperId": "be4e25eeef837f272aea6aaf1aa62bd108f1924c", "title": "Text summarization in the biomedical domain: A systematic review of recent research"}, {"paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5", "title": "GloVe: Global Vectors for Word Representation"}, {"paperId": "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba", "title": "Convolutional Neural Networks for Sentence Classification"}, {"paperId": "cfb4edb7541fafcf593b466320c63ae32d27f57e", "title": "Extraction of relations between genes and diseases from text and large-scale data analysis: implications for translational research"}, {"paperId": "226f51c22f2852cbb456588d083acf1b52071951", "title": "Temporal Annotation in the Clinical Domain"}, {"paperId": "696753d59185436ec95ecf3021c413f353be4874", "title": "NCBI disease corpus: A resource for disease name recognition and concept normalization"}, {"paperId": "87f40e6f3022adbc1f1905e3e506abad05a9964f", "title": "Distributed Representations of Words and Phrases and their Compositionality"}, {"paperId": "6ea353ada2b89763f58d8068a74b2e6def526948", "title": "The DDI corpus: An annotated corpus with pharmacological substances and drug-drug interactions"}, {"paperId": "dcb515d7275da03bc1e03fe2c8e258c891f18243", "title": "Evaluating temporal relations in clinical text: 2012 i2b2 Challenge"}, {"paperId": "3598e8b4664477cb82b9887c78e4d178a2437f5c", "title": "The Genia Event Extraction Shared Task, 2013 Edition - Overview"}, {"paperId": "4efa5ee94e64ff63b8ecd8d6809742f813844cd8", "title": "Overview of BioNLP Shared Task 2013"}, {"paperId": "c83d05b15797ade0f8dffb9a311a859682d43a27", "title": "The SPECIES and ORGANISMS Resources for Fast and Accurate Identification of Taxonomic Names in Text"}, {"paperId": "f6b51c8753a871dc94ff32152c00c01e94f90f09", "title": "Efficient Estimation of Word Representations in Vector Space"}, {"paperId": "8a867967998066584ed87a6adec7c68389d308f2", "title": "BioCause: Annotating and analysing causality in the biomedical domain"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "574aa45e8868844e31e047c8a9227a2cea706ed6", "title": "BioASQ: A Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering"}, {"paperId": "506c7e333efa0b31823c1b1914b1180c346773ee", "title": "The EU-ADR corpus: Annotated drugs, diseases, targets, and their relationships"}, {"paperId": "a8dff94485a16320e1ef980420bc74b2882babee", "title": "Event extraction across multiple levels of biological organization"}, {"paperId": "1470722bd776c4c5b1bc7a6cbcf9ff93c952461f", "title": "The hallmarks of cancer"}, {"paperId": "b33e9e49df030509be2a9063565e6e90d05c7c2d", "title": "A review of causal inference for biomedical informatics"}, {"paperId": "5e095981ebf4d389e9356bd56e59e0ade1b42e88", "title": "2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text"}, {"paperId": "b8472b394125768bb53615cc53cb2ef1ae38b112", "title": "Overview of the Infectious Diseases (ID) task of BioNLP Shared Task 2011"}, {"paperId": "88a38c33d2207524e3c42203f46c2fd2e77edd49", "title": "Overview of the Epigenetics and Post-translational Modifications (EPI) task of BioNLP Shared Task 2011"}, {"paperId": "00248a60f905f49c451e106ee6647823e9359e6c", "title": "Overview of Genia Event Task in BioNLP Shared Task 2011"}, {"paperId": "cd5a26b89f0799db1cbc1dff5607cb6815739fe7", "title": "A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning"}, {"paperId": "f2f6fb25311ada4afb830ec084e604a397b8a0e0", "title": "Event extraction for systems biology by text mining the literature."}, {"paperId": "e1039346942874c59d89028bb934b72524827b8c", "title": "LINNAEUS: A species name identification system for biomedical literature"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "f5a0c6593ba95d23c025608ce9280848da8b929f", "title": "Overview of BioCreative II gene mention recognition"}, {"paperId": "78d0078bfc398008175faa2066ba833bca6883d7", "title": "Overview of the protein-protein interaction annotation extraction task of BioCreative II"}, {"paperId": "a5a1e9ff53a230f6ede07ae9c75a5d9b84bda2e1", "title": "A survey and analysis of Electronic Healthcare Record standards"}, {"paperId": "7533d30329cfdbf04ee8ee82bfef792d08015ee5", "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"}, {"paperId": "acfc8d0d536e71cb7b3d2ae1364ee3fc6eb6b963", "title": "A survey of current work in biomedical text mining"}, {"paperId": "3bd4d2de49d8a092abb295b845dba14874f8787d", "title": "Introduction to the Bio-entity Recognition Task at JNLPBA"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "e995078660f734127ba0e310c3e290ce29c554cb", "title": "Bioinformatics\u2014an introduction for computer scientists"}, {"paperId": "10f97f1fb4f5c2c8e6c44d4a33da46d331dd4aeb", "title": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition"}, {"paperId": "6c2b28f9354f667cd5bd07afc0471d8334430da7", "title": "A Neural Probabilistic Language Model"}, {"paperId": "3af95af0d1534b24df7ea4d94cbedba0b9663e37", "title": "Automatic evaluation of machine translation quality using n-gram co-occurrence statistics"}, {"paperId": "84aae91c8f7a19e174c75f64e40ffe38b678eee9", "title": "Computational biology"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "2f00d047edd943d56389678c55175bbbf257cde0", "title": "Natural Language Processing in Medicine: An Overview"}, {"paperId": "3ae97b823e47190c07350e9f22f4c44c5ca2d341", "title": "Computational biology"}, {"paperId": "752cefd84b78253a510b9b4530b6eb963824ec9b", "title": "A large\u2010scale experiment to assess protein structure prediction methods"}, {"paperId": "36e091c47b2330acf77f16205ad0d599cb190e82", "title": "Principles that govern the folding of protein chains."}, {"paperId": "2db77485736cf29778a4464fe500a289bd46e7ac", "title": "ChatGPT as a Factual Inconsistency Evaluator for Abstractive Text Summarization"}, {"paperId": "3f1ee0a36b970a0f8f118ccb3f6fd4ee4b5de949", "title": "A Survey on Biomedical Text Summarization with Pre-trained Language Model"}, {"paperId": null, "title": "Faithful ai in healthcare and medicine. medRxiv"}, {"paperId": "4bfa14526234e0548f4f261d29c83db92553c5f8", "title": "GenCompareSum: a hybrid unsupervised summarization method using salience"}, {"paperId": "50920f95cee87913dea19656e83ae06b51f9ba4a", "title": "Discovering Better Model Architectures for Medical Query Understanding"}, {"paperId": "30037743378708483e028896edef084b5b2f990d", "title": "Pre-trained language models to extract information from radiological reports"}, {"paperId": "5322e5936e4a46195b1a92001467a2350fe72782", "title": "KART: Privacy Leakage Framework of Language Models Pre-trained with Clinical Records"}, {"paperId": "1636928dc20917834a1824ec2cccd4232a11bc3f", "title": "ABioNER: A BERT-Based Model for Arabic Biomedical Named-Entity Recognition"}, {"paperId": "dc35daba3fb34b2e6a5b12530badb7b799262bbf", "title": "On Position Embeddings in BERT"}, {"paperId": "19164116fed967ca4dfd0905221f8c5f192a6999", "title": "Overview of the MEDIQA 2021 Shared Task on Summarization in the Medical Domain"}, {"paperId": "d888ac9e9ac54dacb5fa8b6ce29ee6ecf64d9710", "title": "A Multi-Task Approach for Improving Biomedical Named Entity Recognition by Incorporating Multi-Granularity information"}, {"paperId": "5134bc9d01cba38b18387e921872cc8d5cd9ae37", "title": "M 2 -MedDialog: A Dataset and Benchmarks for Multi-domain Multi-service Medical Dialogues"}, {"paperId": "4ab55fd59a5dc012e512925afdd78233280c54ff", "title": "Benchmarking of Transformer-Based Pre-Trained Models on Social Media Text Classification Datasets"}, {"paperId": "2fc12f2f3378e0aeab24df396f78ee8b59956973", "title": "Contextualized French Language Models for Biomedical Named Entity Recognition"}, {"paperId": "18396dd27d5b455d5fd062a1d0b7066a398bb8e4", "title": "Named Entity Recognition, Concept Normalization and Clinical Coding: Overview of the Cantemist Track for Cancer Text Mining in Spanish, Corpus, Guidelines, Methods and Results"}, {"paperId": "89a1c2f9b79db889b372041025a2b2f095a59bcd", "title": "Transfer Learning for Biomedical Question Answering"}, {"paperId": "79e7c4f4803905f64ced6d0f2a3d4482f7044638", "title": "2018 N2c2 Shared Task on Adverse Drug Events and Medication Extraction in Electronic Health Records"}, {"paperId": null, "title": "Electra: pre-training text encoders as discriminators rather than generators"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "a792d9c05008e56142acae588a9018ff9b3ba7a9", "title": "Relation Extraction from Clinical Narratives Using Pre-trained Language Models"}, {"paperId": "afc317b098cd6744611049ff16f351032ab14f83", "title": "A BERT-based Universal Model for Both Within- and Cross-sentence Clinical Temporal Relation Extraction"}, {"paperId": "a262d2eaf521111f4cd7dce8fa1e8f349f24d343", "title": "Chinese Computational Linguistics: 18th China National Conference, CCL 2019, Kunming, China, October 18\u201320, 2019, Proceedings"}, {"paperId": null, "title": "Proceedings of the 5th workshop on bionlp open shared tasks"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "f84fc762a3229f436f2a472bd90ef5070b5d31fb", "title": "Clinical information extraction applications: A literature review"}, {"paperId": null, "title": "The mythos of model interpretability: in machine learning, the concept of interpretability is both important and slippery"}, {"paperId": "eed781f498b563df5a9e8a241c67d63dd1d92ad5", "title": "Overview of the BioCreative VI chemical-protein interaction Track"}, {"paperId": "c7a340ec54a010ea8a289e44d0ccbbad647b6424", "title": "Hallmarks of Cancer Cell"}, {"paperId": "f697762b2b8cdf6df65e9246b96db4c4824ded5b", "title": "Recognizing Question Entailment for Medical Question Answering"}, {"paperId": "1f1eaf19e38b541eec8a02f099e3090536a4c936", "title": "The Unified Medical Language System (UMLS): integrating biomedical terminology"}, {"paperId": null, "title": "Speech & language processing. Pearson Education India"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}, {"paperId": "d5ccb7ae5f596560a1b797a7f7e03469a63da519", "title": "HuatuoGPT, Towards Taming Language Models To Be a Doctor"}]}