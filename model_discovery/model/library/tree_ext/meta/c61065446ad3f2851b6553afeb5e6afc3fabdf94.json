{"paperId": "c61065446ad3f2851b6553afeb5e6afc3fabdf94", "title": "OFA: A Framework of Initializing Unseen Subword Embeddings for Efficient Large-scale Multilingual Continued Pretraining", "abstract": "Instead of pretraining multilingual language models from scratch, a more efficient method is to adapt existing pretrained language models (PLMs) to new languages via vocabulary extension and continued pretraining. However, this method usually randomly initializes the embeddings of new subwords and introduces substantially more embedding parameters to the model, thus weakening the efficiency. To address these issues, we propose a novel framework: $\\textbf{O}$ne $\\textbf{F}$or $\\textbf{A}$ll ($\\textbf{OFA}$), which wisely initializes the embeddings of unseen subwords and thus can adapt a PLM to multiple languages efficiently and effectively. OFA takes advantage of external well-aligned multilingual static word vectors and injects the alignment knowledge into the subword embeddings. In addition, OFA applies matrix factorization and replaces the cumbersome embeddings with two lower-dimensional matrices, which largely reduces the number of parameters. We show OFA accelerates the convergence of continued pretraining, which is environmentally friendly as much fewer carbon footprints are generated. Through extensive experiments, we demonstrate OFA can achieve competitive or better performance than default continued pretraining baselines on a wide range of crosslingual downstream tasks. We make our code and models publicly available.", "venue": "arXiv.org", "year": 2023, "citationCount": 11, "influentialCitationCount": 3, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A novel framework, OFA, which wisely initializes the embeddings of unseen subwords and thus can adapt a PLM to multiple languages efficiently and effectively and accelerates the convergence of continued pretraining, which is environmentally friendly as much fewer carbon footprints are generated."}, "embedding": {"model": "specter_v2", "vector": [-0.11597540229558945, -0.02818823792040348, -0.17442460358142853, -0.2227535992860794, -0.16197271645069122, -0.6977561116218567, 0.34312403202056885, -0.16963735222816467, -0.6843419075012207, -0.35064515471458435, 0.7167103290557861, -0.2209148108959198, 0.4504985511302948, 0.3240751624107361, -0.6002002954483032, -0.010059366934001446, -1.1308480501174927, -0.1311611384153366, -0.4860585033893585, -0.8582189679145813, -0.5692619681358337, -0.6291276216506958, -0.7665101885795593, 0.06030840799212456, 0.43636536598205566, 0.059696417301893234, 0.6211161613464355, 0.7964637875556946, -0.6175049543380737, -0.47900596261024475, 0.4605156481266022, -0.5422758460044861, 0.625394880771637, -0.017042649909853935, -0.26808997988700867, 0.3042530119419098, 0.375649094581604, -0.5614795088768005, -0.22985902428627014, 0.8686321973800659, -0.3855507969856262, 0.4099768400192261, -0.13249513506889343, -0.508282482624054, -0.6182534098625183, 1.079562783241272, 0.6140519380569458, 0.8757923245429993, -0.26127538084983826, -0.5888711810112, 1.2017418146133423, -1.4839848279953003, 0.07645460963249207, 1.1630197763442993, 0.749333918094635, 0.4285902976989746, -0.3230252265930176, -0.9064900875091553, 1.1493648290634155, -0.17310824990272522, -0.6047136187553406, -0.39762768149375916, -0.15138030052185059, -0.1472872644662857, 1.9647878408432007, -0.7558788657188416, 0.5623845458030701, 0.6679091453552246, -0.0027418709360063076, 1.1331324577331543, -0.1370394378900528, -0.8271098732948303, -0.6789760589599609, 0.19997631013393402, 0.685204029083252, 0.793425977230072, -0.3689296841621399, 0.2724296748638153, -0.8399862051010132, 0.2449171245098114, 0.1339675337076187, 0.08399686962366104, 0.18801458179950714, 0.14151126146316528, -0.4498595893383026, 0.8697060942649841, 0.4076530635356903, 0.9528740644454956, -0.24113571643829346, 0.5090795159339905, 0.46170198917388916, 0.35254502296447754, 0.18712708353996277, 0.44122058153152466, -0.48857244849205017, 0.700483500957489, -0.7221867442131042, 0.20247608423233032, -0.48528844118118286, 0.510887086391449, 0.0741628035902977, 0.3582673966884613, -0.39668694138526917, 0.23573185503482819, 1.4389344453811646, 0.207474946975708, 0.8352674841880798, -0.36699843406677246, 0.0893770232796669, -0.7222995758056641, -0.110740065574646, -0.6619890332221985, -0.45726701617240906, -0.626291036605835, -0.2124711275100708, -1.5360716581344604, -0.544278621673584, -0.03659146651625633, -0.8653409481048584, 1.347893476486206, 0.12871545553207397, 0.11107899993658066, 0.3862372040748596, 0.2665354311466217, 0.3197721242904663, 1.1434192657470703, 0.14862549304962158, 0.03824757784605026, 0.8111140131950378, -1.2342989444732666, -0.693560779094696, -1.19649076461792, 0.6353530287742615, -0.44824397563934326, 0.3533238470554352, -0.1838991492986679, -0.7205188870429993, -1.1436094045639038, -1.0813297033309937, 0.09636199474334717, -1.0747439861297607, 0.24862530827522278, 1.0611801147460938, 0.5538098216056824, -0.9170867800712585, 0.45615944266319275, -0.18607592582702637, -0.3152328133583069, -0.18285609781742096, 0.17262877523899078, -0.01587390899658203, -0.5828468799591064, -1.5995761156082153, 0.35000091791152954, 0.5645124316215515, -0.11009100079536438, -0.2299852967262268, -0.549051821231842, -1.0985980033874512, -0.3457428514957428, -0.1140921413898468, -0.3000987768173218, 1.111445426940918, -0.26705434918403625, -1.0040600299835205, 0.6412745118141174, -0.33131855726242065, 0.15531833469867706, -0.18515397608280182, -0.39113399386405945, -0.9845308065414429, -0.8903431296348572, -0.11528920382261276, 0.7581046223640442, 0.28855088353157043, 0.03581980615854263, 0.14736393094062805, -0.014733104966580868, -0.17655687034130096, 0.2114049792289734, -1.1035946607589722, 0.7522121071815491, -0.3715042471885681, -0.7039155960083008, 0.255386084318161, 0.6804047226905823, -0.12529663741588593, -0.6673542261123657, -0.1343892216682434, -0.8801038265228271, 0.4985983371734619, -0.5258462429046631, 0.9922767877578735, -0.898408830165863, -0.625783383846283, -0.13135699927806854, -0.39663931727409363, 0.02963162027299404, -1.3060415983200073, 0.7473437190055847, -0.5244587063789368, 0.12315072119235992, 0.39037755131721497, -1.068372130393982, -0.0986705794930458, -0.29783016443252563, -0.7563673853874207, -0.3239932358264923, -0.03733997792005539, 0.9612505435943604, -0.9067003726959229, 0.6436278820037842, 0.1663670837879181, 0.43995702266693115, -1.0578316450119019, 0.8680436015129089, -0.18456342816352844, 0.15635409951210022, 0.34416836500167847, -0.3900686204433441, 0.26580795645713806, -0.03176262602210045, 0.4469093084335327, -0.41513916850090027, -0.21913625299930573, 0.5329434871673584, -0.5251011252403259, 1.641242265701294, -0.5055238604545593, 0.004416541196405888, 0.040443893522024155, -0.3128078281879425, -0.021876275539398193, -0.01268463209271431, 0.23279191553592682, -0.3004032075405121, 0.3360251188278198, 0.3675157427787781, -0.7068721055984497, 0.45604732632637024, 1.0249515771865845, 0.6086650490760803, -0.5598379373550415, 0.08884501457214355, 0.8616509437561035, 0.21848125755786896, 0.653999388217926, 0.2921919524669647, 0.20502135157585144, 0.432422012090683, 0.1681101769208908, -0.337838351726532, 0.645631730556488, -0.715056300163269, -0.2012070268392563, 0.021271176636219025, 0.5912789106369019, 0.030403360724449158, -0.32045063376426697, -0.7530611157417297, -0.28219911456108093, -0.16793255507946014, 0.6607239246368408, 1.7307844161987305, -0.4375999867916107, -0.26413780450820923, -0.6863824725151062, -0.37910473346710205, -0.21544532477855682, -0.2421722114086151, 0.07166791707277298, 0.02025745064020157, -0.631913423538208, -1.0504029989242554, 0.28988492488861084, 0.2671460509300232, 0.9264529347419739, -0.1578991413116455, 0.24837280809879303, -0.1547633409500122, 0.11220195144414902, -0.8688048124313354, -1.1427937746047974, 0.41357681155204773, -0.16987614333629608, 0.1549893617630005, -0.38119006156921387, -0.8615610003471375, 0.27479737997055054, -0.34990113973617554, 0.577451765537262, -0.4842340052127838, 0.03449363633990288, -0.00944703258574009, 0.45638060569763184, -0.29749834537506104, -0.6424461603164673, 0.16890841722488403, 0.7846632599830627, 0.048459455370903015, 0.6137067675590515, 0.6567909717559814, 0.1991322934627533, -0.037283822894096375, -0.3323288857936859, 0.2039961963891983, -0.23733532428741455, 0.08500988036394119, 0.6363493800163269, 0.05081920698285103, 0.31447088718414307, -1.0201629400253296, 0.921541154384613, 0.29156967997550964, -0.6985004544258118, 0.35414281487464905, -0.30343687534332275, -0.4210878908634186, 0.7479488849639893, -0.6822081208229065, 0.12327273190021515, -0.6108826398849487, 0.007486667018383741, -0.1384497433900833, 0.16341814398765564, 0.38439664244651794, 0.1515471637248993, 0.25892460346221924, -0.04051601141691208, 0.2579750120639801, 0.32608625292778015, -0.08926016092300415, 0.6013940572738647, -0.7436259984970093, 0.4464016854763031, 0.5279109477996826, 0.4372250437736511, -0.4628516435623169, -0.6590948104858398, -0.8436968922615051, -0.5131367444992065, -0.5687407851219177, -0.4431251585483551, -0.5694819092750549, 0.08444781601428986, -0.8550213575363159, -0.3106386363506317, 0.3159022033214569, -1.014003038406372, -0.2223622351884842, 0.34649205207824707, -0.08300208300352097, 0.29703184962272644, -0.9789950847625732, -1.034740686416626, -0.34941959381103516, -0.49001750349998474, -1.0826478004455566, 0.1626867949962616, -0.0007126971613615751, -0.4496847093105316, -0.676510751247406, 0.23407535254955292, -0.442508727312088, 0.9458743929862976, -0.6762816309928894, 0.6354106068611145, 0.08193127810955048, 0.39377352595329285, -0.5057656764984131, 0.605952799320221, 0.9855775833129883, -0.09914807975292206, 0.3083004951477051, -0.6619070768356323, -0.23830518126487732, -0.36468252539634705, -0.2877596616744995, 0.21738053858280182, 0.30149590969085693, 0.15770211815834045, -0.10389341413974762, -0.28542542457580566, 0.47580036520957947, 1.5087437629699707, -0.6896666884422302, -0.2349248081445694, 0.07172869145870209, 0.8071641325950623, 0.45075902342796326, -0.44842734932899475, 0.18750502169132233, 0.5477237105369568, 0.22141782939434052, -0.33239662647247314, -0.09544437378644943, -0.3104349672794342, -0.8760549426078796, 1.139836311340332, 2.269566535949707, 0.7563421130180359, 0.033497102558612823, -0.869446873664856, 0.8604639172554016, -0.9386361241340637, -0.42055046558380127, 0.7964066863059998, 0.6155584454536438, 0.3181208074092865, -0.750400722026825, -0.09327287971973419, 0.07407478988170624, 0.7354339361190796, 0.5641695261001587, -0.3878839612007141, -0.7885617613792419, -0.044498685747385025, 0.10264905542135239, 0.10188143700361252, 0.8932758569717407, -0.4653119444847107, 0.9382234811782837, 14.748092651367188, 0.6427910923957825, 0.12627726793289185, 0.7368610501289368, 0.48951947689056396, 0.3261416256427765, -0.5747751593589783, -0.5627556443214417, -1.541668176651001, -0.0872054472565651, 1.0935126543045044, 0.5341112613677979, 1.3555642366409302, -0.13571427762508392, -0.2900692820549011, 0.38824597001075745, -0.15461622178554535, 0.5036766529083252, 0.928735077381134, -0.8368209600448608, 0.4668115973472595, 0.1377858817577362, 0.5520069003105164, 0.768426775932312, 0.9715712070465088, 1.0512170791625977, 0.6976913809776306, -0.08608240634202957, 0.39538145065307617, -0.006110238842666149, 0.5741786956787109, -0.2650410234928131, 0.2992917001247406, 0.36743879318237305, -0.9148143529891968, -0.4121284484863281, -0.628470242023468, -1.1371577978134155, 0.28054559230804443, 0.2508113980293274, -0.2709924280643463, -0.49868595600128174, -0.006441567093133926, 0.9014504551887512, -0.03721220791339874, 0.04608861729502678, -0.2527831792831421, 0.2009904831647873, -0.2419755607843399, -0.05829467624425888, 0.5218406319618225, 0.4954563081264496, 0.35560959577560425, -0.1429506540298462, 0.14416831731796265, -0.20642918348312378, 0.5047420263290405, -0.0991082713007927, -0.4480614960193634, 0.32439562678337097, -0.22736254334449768, -0.605478048324585, -0.19179590046405792, 1.119235873222351, 0.4725477695465088, 0.40057694911956787, -0.5340144038200378, 0.3358380198478699, 0.6151351928710938, 0.31341856718063354, -0.46436548233032227, 0.14614038169384003, 0.4968949556350708, -0.43663325905799866, -0.14810796082019806, 0.031136978417634964, 0.10482391715049744, -0.7114720940589905, -0.771368145942688, -0.17627303302288055, 0.2603694200515747, -0.7518141865730286, -1.0324628353118896, 1.157842993736267, -0.5113700032234192, -0.2181703746318817, 0.18082359433174133, -1.2216516733169556, 0.011176114901900291, 0.5807032585144043, -1.2234872579574585, -0.7105250358581543, 0.45158204436302185, -0.3025738298892975, -0.42332354187965393, -0.42763370275497437, 1.2174190282821655, 0.1388643980026245, -0.7134571075439453, 0.06324567645788193, 0.2145017832517624, 0.01346069946885109, -0.1870691329240799, -0.3973305821418762, 0.907902181148529, 0.801548421382904, 0.1430334895849228, 0.38587644696235657, -0.05504198372364044, 0.018130477517843246, -0.9322637319564819, -0.11214165389537811, 0.9377694129943848, -0.842088520526886, 0.018236901611089706, -1.13097083568573, -0.31638872623443604, 0.3611694872379303, 0.648055374622345, -0.3982585668563843, 0.6250103712081909, 0.4518163204193115, -0.5446220636367798, -0.5215223431587219, -0.7630789279937744, 0.1361832171678543, 0.5601010918617249, -0.8229147791862488, -0.2177296131849289, 0.14617736637592316, 0.49236705899238586, -0.6450790166854858, -0.25480377674102783, -0.08145500719547272, 0.19599607586860657, 0.3033166527748108, 1.1054472923278809, -0.4613003134727478, 0.5366365909576416, 0.79542475938797, -0.5338688492774963, -1.2532621622085571, -0.2624836564064026, -0.7499216198921204, 0.2793094217777252, 0.2220347374677658, 0.611609697341919, -0.5132802128791809, -0.06333053112030029, 0.3334274888038635, 0.4098946750164032, -0.432532399892807, -0.28130650520324707, -0.5195531845092773, 0.08741112798452377, -0.5585358738899231, 0.5062921047210693, 0.029975445941090584, 0.24788379669189453, 0.21399839222431183, 0.5433070659637451, 0.6460067629814148, -0.5180240869522095, -0.9162868857383728, 0.4552907645702362, 0.26930806040763855, -0.23294669389724731, -0.5369645357131958, -0.4126785099506378, -1.4083901643753052, 0.3681952953338623, -1.7484368085861206, 0.04633954539895058, -0.94361811876297, -0.5823934078216553, 0.2644784152507782, -0.48512235283851624, 0.2755914628505707, 0.12175359576940536, 0.10823234170675278, -0.4289027750492096, -0.7453143000602722, -0.23230621218681335, 0.582298755645752, 0.7913737297058105, -0.7702404260635376, -0.0873161107301712, -0.3928714096546173, -0.011524340137839317, 0.35507655143737793, 0.30783331394195557, -0.06352892518043518, -0.8782236576080322, -1.834405541419983, 0.43126216530799866, -0.7325934767723083, -0.2595544755458832, -0.38114267587661743, 0.34026381373405457, 0.656454861164093, 0.09055640548467636, -0.04437726363539696, 0.1559433788061142, -0.9318974018096924, -0.49078378081321716, 0.3004588186740875, -0.2945916950702667, 0.9626705050468445, 0.4866466522216797, -0.6008426547050476, -0.10791853815317154, 0.7277161478996277, -0.2904818058013916, -0.9837669730186462, -1.0624644756317139, 0.505677342414856, -0.6536639332771301, -0.12164365500211716, 0.06909771263599396, -0.08982779085636139, -0.8635720014572144, -0.2486286461353302, 0.01924164593219757, 0.6918949484825134, -0.7289685606956482, 1.1919121742248535, 0.28695255517959595, -1.42164146900177, -0.05764729157090187, 0.8124004602432251, -0.19388331472873688, -0.600057065486908, 0.7265340685844421, 0.25482821464538574, -0.5082843899726868, 0.6121251583099365, 0.1706569492816925, 0.3674089014530182, -0.8366124033927917, 0.23395222425460815, 0.4714576005935669, -0.5119665265083313, 0.13505379855632782, 1.470803141593933, -0.2356431633234024, -1.370457410812378, 0.21390262246131897, -0.7743798494338989, -0.6360387802124023, -0.04937228187918663, 0.8877280354499817, 0.0042359111830592155, 0.018752845004200935, -0.6390625834465027, -0.4929348826408386, 0.37566885352134705, -0.2715678811073303, -0.47585055232048035, 0.8946968913078308, -0.43084144592285156, -0.3078850209712982, 0.688865065574646, 1.0952296257019043, -0.23601959645748138, -0.5889224410057068, -0.5161823034286499, -0.7085029482841492, -0.059257663786411285, 0.5369506478309631, -0.6463930606842041, -0.6631160378456116, 0.6051128506660461, 0.5594411492347717, 0.15308929979801178, 0.1385410726070404, -0.5029167532920837, 0.6399744749069214, 0.7156850099563599, 0.20987047255039215, -0.7655205130577087, -0.36838269233703613, 1.6064175367355347, 1.00328528881073, -0.661024808883667, 0.13494427502155304, 0.0167813990265131, -0.5810112357139587, 0.8156831860542297, 0.24637241661548615, -0.2301977574825287, 1.2550048828125, -0.21920053660869598, 0.5472493767738342, 0.6162689924240112, -0.4160340428352356, -0.2963123917579651, 0.9827264547348022, 0.7988880276679993, 0.5346518754959106, 0.13388948142528534, -0.04057980328798294, 1.0225645303726196, -0.17415288090705872, -0.4578777849674225, 0.16864165663719177, 0.24073797464370728, -0.16551616787910461, -0.27941712737083435, -0.08499342203140259, 0.29321980476379395, -0.36268892884254456, -0.6994683742523193, 0.287272185087204, 0.45902150869369507, 0.4779462218284607, 0.4527515172958374, 0.7751187086105347, -0.1781248301267624, 0.32497695088386536, 0.6137543320655823, 0.6974747180938721, -0.32908499240875244, -0.48325783014297485, 0.043867990374565125, -0.6979060769081116, 0.1066058948636055, -0.2813442647457123, -0.5917294025421143, -0.20375217497348785, -0.18516674637794495, 0.08425220102071762, -0.2547755539417267, 0.7616819143295288, 1.0740385055541992, 0.13105913996696472, 0.4486372768878937, -0.0975973904132843, -0.4596623480319977, -0.20232731103897095, -0.7590504884719849, 0.09336429834365845, -0.47880783677101135, -0.16075646877288818, 0.0990091934800148, -0.028732791543006897, -0.6227282285690308]}, "authors": [{"authorId": "2107995084", "name": "Yihong Liu"}, {"authorId": "2266791225", "name": "Peiqin Lin"}, {"authorId": "2261533492", "name": "Mingyang Wang"}, {"authorId": "144418438", "name": "Hinrich Sch\u00fctze"}], "references": [{"paperId": "3749d7dc47fe4af5bb7d53a0cf67ef99a4f798f8", "title": "Subspace Chronicles: How Linguistic Information Emerges, Shifts and Interacts during Language Model Training"}, {"paperId": "193955704f66923ac20a664bd184ed4663b2bdf9", "title": "Continual Pre-Training of Large Language Models: How to (re)warm your model?"}, {"paperId": "9a2f47777b99a92effb4e998b7082e1e92ae13bc", "title": "Improving Language Plasticity via Pretraining with Active Forgetting"}, {"paperId": "b1e08e85d6f268b45c003bb4a9dec5b6d1d3f7e7", "title": "Crosslingual Transfer Learning for Low-Resource Languages Based on Multilingual Colexification Graphs"}, {"paperId": "6797620a2f77b89f6111ce8d5c50a574cf7b6e7a", "title": "A study of conceptual language similarity: comparison and evaluation"}, {"paperId": "767dcc48c7ad2c943f3c1a25c46b873e7b8b3bc8", "title": "Glot500: Scaling Multilingual Corpora and Language Models to 500 Languages"}, {"paperId": "e4aa101556fc5b238a88d99c07c1055fe3bc4764", "title": "Taxi1500: A Multilingual Dataset for Text Classification in 1500 Languages"}, {"paperId": "30dbee07e832a77c17e24a14f12ad4485bd9a9dc", "title": "A Crosslingual Investigation of Conceptualization in 1335 Languages"}, {"paperId": "62a7f3c14c15d8f5d1c643ceb991dddb36e3c47c", "title": "XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models"}, {"paperId": "66817b3f93901a86079307af230d9e626146120c", "title": "Mini-Model Adaptation: Efficiently Extending Pretrained Models to New Languages via Aligned Shallow Training"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "f2c17758e74707d379b87372528221656d14b697", "title": "Taxonomy of Risks posed by Language Models"}, {"paperId": "0b4f0f6b04476c4f2cdfeabf99d4b835227f0bb2", "title": "Analyzing the Mono- and Cross-Lingual Pretraining Dynamics of Multilingual Language Models"}, {"paperId": "7a25155364476839b6d1fc0653cd8611327ab9ba", "title": "mGPT: Few-Shot Learners Go Multilingual"}, {"paperId": "2ac19d63e1adba20473a6d1122c598f81efc3c58", "title": "Adapting Pre-trained Language Models to African Languages via Multilingual Adaptive Fine-Tuning"}, {"paperId": "a98fc03f6eb0f79b499e50144e5387c917937d54", "title": "Expanding Pretrained Models to Thousands More Languages via Lexicon-based Adaptation"}, {"paperId": "b3a0730e21e0db2d6e08e4f03c5558d6f393dde4", "title": "Cross-Lingual Ability of Multilingual Masked Language Models: A Study of Language Structure"}, {"paperId": "4724ebee34ca2cd0a19c3a1ddb83d6d870dd7904", "title": "Few-shot Learning with Multilingual Generative Language Models"}, {"paperId": "eb0024439858af7cc951ce2efa5a6533c3781799", "title": "WECHSEL: Effective initialization of subword embeddings for cross-lingual transfer of monolingual language models"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "03aa38229a6c853d96430edfc8f1542598f2116e", "title": "AVocaDo: Strategy for Adapting Vocabulary to Downstream Domain"}, {"paperId": "ca2f1088d3e581b2c6c75cf0ebc96506d620f64d", "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? \ud83e\udd9c"}, {"paperId": "13bcfb944779165983aaef22cec8a3bbd3e98e62", "title": "UNKs Everywhere: Adapting Multilingual Language Models to New Scripts"}, {"paperId": "56446cb1da48cbe6e19e5051ed80c3861021e5ba", "title": "As Good as New. How to Successfully Recycle English GPT-2 to Make Models for Other Languages"}, {"paperId": "70efbd71c840e78d0ecee101d389db0aaea93652", "title": "exBERT: Extending Pre-trained Models with Domain-specific Vocabulary Under Constrained Training Resources"}, {"paperId": "bc87279d4b32a425377ff18ab63f7ecf95ff228c", "title": "Rethinking embedding coupling in pre-trained language models"}, {"paperId": "818210e8599152fa85e0eea18ca55462b95af653", "title": "Multilingual BERT Post-Pretraining Alignment"}, {"paperId": "74276a37bfa50f90dfae37f767b2b67784bd402a", "title": "mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer"}, {"paperId": "b896b846ae180d804c7290d8b9ae9ffc55325866", "title": "Language-agnostic BERT Sentence Embedding"}, {"paperId": "8425717e0bff9497498bc34931928cf8ee01f555", "title": "SimAlign: High Quality Word Alignments without Parallel Training Data using Static and Contextualized Embeddings"}, {"paperId": "ba4a34680e09e77984624c95f5245d91b54373f6", "title": "XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating Cross-lingual Generalization"}, {"paperId": "495da6f19baa09c6db3697d839e10432cdc25934", "title": "Multilingual Denoising Pre-training for Neural Machine Translation"}, {"paperId": "3b2538f84812f434c740115c185be3e5e216c526", "title": "Cross-Lingual Ability of Multilingual BERT: An Empirical Study"}, {"paperId": "6fec3e579c7cd4f13bdabbee2b6ac2e8ff5941c6", "title": "Unsupervised Cross-lingual Representation Learning at Scale"}, {"paperId": "9e9d919c1de684ca42c8b581ec62c7aa685f431e", "title": "On the Cross-lingual Transferability of Monolingual Representations"}, {"paperId": "b3ea2d9c8e5ea3b87ace121f0bece71565abc187", "title": "Quantifying the Carbon Emissions of Machine Learning"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "dec69765fc6c188897b09c8282d32db788e2c261", "title": "Improving Pre-Trained Multilingual Model with Vocabulary Expansion"}, {"paperId": "8199b4c196b09d6176816e4d7db8d6f3d65e07c1", "title": "From English To Foreign Languages: Transferring Pre-trained Language Models"}, {"paperId": "65f788fb964901e3f1149a0a53317535ca85ed7d", "title": "Unicoder: A Universal Language Encoder by Pre-training with Multiple Cross-lingual Tasks"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "809cc93921e4698bde891475254ad6dfba33d03b", "title": "How Multilingual is Multilingual BERT?"}, {"paperId": "160563abbd75265b19afc8b4169bab9e1eb33d97", "title": "Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "e7fd6848cb29ca221a7e17d823e06fb566f1f135", "title": "Mixed Precision Training"}, {"paperId": "3dcaf5e960a0d79df06a8cb1d603ad4555119db4", "title": "Universal Dependencies"}, {"paperId": "2e55ba6c97ce5eb55abd959909403fe8da7e9fe9", "title": "Overcoming catastrophic forgetting in neural networks"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "dbf336a8cb911bdda6ef06bc584015a8ed2b1565", "title": "Creating a massively parallel Bible corpus"}, {"paperId": "cb7c0f9aa1060e237ce2d29260334538e0e04a56", "title": "FOCUS: Effective Embedding Initialization for Monolingual Specialization of Multilingual Models"}, {"paperId": "38c6d8004d8b20c66f1adafe029785e0cb91a3f2", "title": "Entropy-guided Vocabulary Augmentation of Multilingual Language Models for Low-resource Tasks"}, {"paperId": "450a646a084432a30e015cac5fe2acfaa118455f", "title": "Isotropic Representation Can Improve Zero-Shot Cross-Lingual Transfer on Multilingual Language Models"}, {"paperId": null, "title": "we only use the data to continued pretrain all of our models."}, {"paperId": "070ff40f38675cfa42a104a545a47584ad823e70", "title": "Scale Efficiently: Insights from Pretraining and Finetuning Transformers"}, {"paperId": "b2474a00d7de3373bab934c09acef1994fa82207", "title": "Small Data? No Problem! Exploring the Viability of Pretrained Multilingual Language Models for Low-resourced Languages"}, {"paperId": "8eb74f94e98006dfce35b8a5de5b6b3cd629efc2", "title": "iNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "616253f6b1e83ede361457de2f51b0bf70555b13", "title": "Cross-lingual Name Tagging and Linking for 282 Languages"}, {"paperId": "ced77f962e3ceddc7ae06f666b20afde01a5918f", "title": "IT KOREA \ubbf8\ub798\uc804\ub7b5"}, {"paperId": "3fd8449d69ab785f23b5c00ed49456b65ec2f4d9", "title": "Alexandre Franc\u0327ois \u2013 2008 \u2013 Semantic maps and the typology of colexification"}, {"paperId": null, "title": "of the 2021 Conference of the North American Chapter of the Association for"}, {"paperId": null, "title": "2024. Translico: A contrastive learning framework to address the script barrier in multilingual pretrained language models"}, {"paperId": null, "title": "A Glot500-c The Glot500-c corpus"}, {"paperId": null, "title": "of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1"}]}