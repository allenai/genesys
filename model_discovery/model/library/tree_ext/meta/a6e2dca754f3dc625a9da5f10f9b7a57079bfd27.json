{"paperId": "a6e2dca754f3dc625a9da5f10f9b7a57079bfd27", "title": "MambaByte: Token-free Selective State Space Model", "abstract": "Token-free language models learn directly from raw bytes and remove the inductive bias of subword tokenization. Operating on bytes, however, results in significantly longer sequences. In this setting, standard autoregressive Transformers scale poorly as the effective memory required grows with sequence length. The recent development of the Mamba state space model (SSM) offers an appealing alternative approach with a fixed-sized memory state and efficient decoding. We propose MambaByte, a token-free adaptation of the Mamba SSM trained autoregressively on byte sequences. In terms of modeling, we show MambaByte to be competitive with, and even to outperform, state-of-the-art subword Transformers on language modeling tasks while maintaining the benefits of token-free language models, such as robustness to noise. In terms of efficiency, we develop an adaptation of speculative decoding with tokenized drafting and byte-level verification. This results in a $2.6\\times$ inference speedup to the standard MambaByte implementation, showing similar decoding efficiency as the subword Mamba. These findings establish the viability of SSMs in enabling token-free language modeling.", "venue": "arXiv.org", "year": 2024, "citationCount": 18, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes MambaByte, a token-free adaptation of the Mamba SSM trained autoregressively on byte sequences, and develops an adaptation of speculative decoding with tokenized drafting and byte-level verification, establishing the viability of SSMs in enabling token-free language modeling."}, "embedding": {"model": "specter_v2", "vector": [0.39088869094848633, 0.7908228039741516, -0.42342984676361084, -0.08161147683858871, -0.5568106770515442, -0.21879039704799652, 1.1066231727600098, -0.33283481001853943, -0.35985735058784485, -0.16221454739570618, 0.5100091695785522, -0.4633248448371887, 0.7443552613258362, -0.01791602186858654, -0.36560988426208496, 0.029208965599536896, -1.2080880403518677, -0.09086698293685913, 0.11587981134653091, -0.4357573091983795, 0.03683675080537796, -0.5736144781112671, -1.0102543830871582, 0.07644325494766235, -0.08677885681390762, 0.8395681977272034, -0.1357416957616806, 0.7819026112556458, -0.6828022003173828, 0.37974053621292114, 0.20684362947940826, -0.21465528011322021, 0.33172985911369324, 0.036443281918764114, -0.47184962034225464, -0.4578590989112854, 0.4917128086090088, -0.6199731826782227, -0.5168556571006775, 0.6424630284309387, -0.5719138979911804, 0.0627233013510704, 0.07890442758798599, -0.6542108058929443, 0.14950518310070038, 1.2437491416931152, 0.9829487800598145, 0.7746466994285583, -0.4360208809375763, -0.6309395432472229, 1.2820497751235962, -0.9926500916481018, 0.0757022425532341, 1.462274193763733, 0.40437108278274536, 0.6407594084739685, -0.24853761494159698, -0.9615854024887085, 1.1129652261734009, 0.2760663628578186, -0.8042030930519104, -0.7773009538650513, -0.2339448481798172, -0.0870218425989151, 1.7140735387802124, 0.1726972460746765, 0.3762890100479126, 0.5917194485664368, 0.10859414935112, 1.1203571557998657, 0.24469740688800812, -0.6889033913612366, -0.07051479816436768, -0.0044806040823459625, 0.48874959349632263, 0.9648134708404541, -0.19973765313625336, 0.32276955246925354, -1.2174468040466309, -0.17615871131420135, 0.4865889847278595, -0.2379789799451828, 0.35704392194747925, -0.29209911823272705, -0.3769306242465973, 0.7295284271240234, -0.22905029356479645, 0.6592978239059448, -0.0551614835858345, 1.0305893421173096, 0.6519854068756104, 0.05525432899594307, 0.22939686477184296, 0.23413345217704773, -0.2201501429080963, 0.060602542012929916, -1.087802767753601, 0.20894236862659454, 0.029961152002215385, 0.7768787145614624, -0.28373146057128906, 0.9794734120368958, -0.936191201210022, -0.1347116380929947, 1.6737998723983765, 0.42621099948883057, 0.5014541149139404, -0.4527837038040161, 0.007789498195052147, -1.022769808769226, 0.3117695450782776, -0.418337881565094, -0.05694438889622688, -0.16816231608390808, -0.3873993754386902, -1.3166115283966064, -0.4220532774925232, 0.3993256688117981, -1.1453828811645508, 0.8017932772636414, -0.21948406100273132, 0.840234100818634, -0.008126860484480858, -0.043674759566783905, 0.398938924074173, 0.844495952129364, 0.5062504410743713, -0.42290759086608887, 0.9385085105895996, -0.5735607147216797, -0.8377191424369812, -0.9940508008003235, 0.5671318769454956, 0.1907442808151245, -0.19284038245677948, -0.005631002597510815, -1.2848386764526367, -0.6595854163169861, -1.0617283582687378, 0.31185898184776306, -0.46731629967689514, -0.2762570083141327, 1.0814783573150635, 0.9439774751663208, -0.8359542489051819, 0.551405668258667, -0.909405529499054, 0.19073475897312164, 0.3684513568878174, 0.11231328547000885, 0.33038461208343506, 0.06396203488111496, -1.545021653175354, 0.4403611123561859, 0.08693971484899521, -0.4884459674358368, -0.49348756670951843, -0.7381660342216492, -1.2984247207641602, 0.04587769880890846, 0.3687518537044525, 0.08812559396028519, 1.4846911430358887, 0.2774806022644043, -1.5572984218597412, 0.2915198504924774, -0.6858450174331665, -0.4644359052181244, 0.13046428561210632, -0.20101171731948853, -0.8239564299583435, -0.5973443388938904, -0.17089560627937317, -0.06005040183663368, 0.9446743130683899, -0.19711872935295105, -0.3488241732120514, 0.1274753361940384, -0.3803469240665436, -0.7045551538467407, -0.17214646935462952, 0.9243732690811157, -0.21304382383823395, -0.1708381175994873, 0.48370757699012756, 0.5287071466445923, -0.11615356802940369, -0.4231943190097809, -0.540300726890564, -0.8139736652374268, 0.5290839672088623, -0.3736020028591156, 1.3578858375549316, -0.8218545317649841, -1.1408512592315674, 0.11381746828556061, -0.49742355942726135, 0.16758744418621063, -0.5321529507637024, 0.5054625272750854, -0.39953070878982544, 0.6108343005180359, 0.050435952842235565, -0.9288366436958313, 0.05856650322675705, -0.46361425518989563, -1.2288646697998047, -0.08149223029613495, -0.09467469155788422, 0.826509952545166, -0.633545994758606, -0.17319287359714508, 0.22903236746788025, 0.1343069076538086, -0.9021944999694824, 1.0694329738616943, -0.1442933976650238, 0.17316772043704987, -0.2910418212413788, -0.37421363592147827, 0.11430741101503372, -0.04043133556842804, 0.5740203261375427, -0.22399169206619263, -0.41960111260414124, 1.012691855430603, -0.7725062966346741, 1.299344778060913, -0.6395244002342224, 0.5666545033454895, -0.004775441717356443, -0.6998278498649597, 0.26854464411735535, 0.3098183274269104, -0.11530370265245438, -0.4086666703224182, 0.2684275507926941, 0.20041777193546295, -0.5436267852783203, 0.6415879130363464, 0.8722886443138123, 1.023317813873291, -0.45068177580833435, 0.2789500951766968, 0.4715212881565094, -0.4184506833553314, 0.3928450644016266, 0.485295832157135, 0.7100246548652649, 0.30729055404663086, 0.3980851173400879, -0.06711404025554657, 0.16153985261917114, -0.9242630004882812, 0.1759774386882782, 0.7037851810455322, 0.4923684000968933, 0.5077499747276306, 0.16845738887786865, -0.582866907119751, -0.32764723896980286, 0.038290273398160934, 0.3436347544193268, 1.3524261713027954, -0.24582844972610474, -0.7319108843803406, -0.6410799622535706, -0.26752740144729614, -0.3355354070663452, 0.5181581974029541, -0.10614722967147827, 0.06277687102556229, -1.0362392663955688, -0.5894086956977844, 0.7997288703918457, 0.27147436141967773, 0.9558809995651245, -0.3722105622291565, -0.271828293800354, -0.1911889761686325, 0.19803409278392792, -0.7243971824645996, -0.26376497745513916, 0.17105114459991455, -0.4046514630317688, 0.057727664709091187, 0.3754238486289978, 0.18071162700653076, -0.21047724783420563, -0.6714006066322327, 0.5565778017044067, -0.3281978368759155, -0.1409469097852707, 0.22471290826797485, 0.4951860308647156, -0.9227837324142456, -1.1653566360473633, 0.10721609741449356, 0.23987630009651184, -0.11711470037698746, 0.12183009833097458, 0.6585927605628967, 0.13578304648399353, -0.21444864571094513, -0.13511013984680176, 0.35031139850616455, -0.10080016404390335, 0.042978111654520035, 0.22312438488006592, -0.541937530040741, -0.23518669605255127, -1.1421188116073608, 0.2748314440250397, 0.3686867654323578, -0.7776124477386475, 0.12025890499353409, -0.9135028123855591, -0.13838255405426025, -0.01804060861468315, -0.3458503782749176, -0.21492032706737518, -0.847166121006012, 0.08627943694591522, 0.07906783372163773, -0.14002475142478943, 0.12481637299060822, 0.4603082239627838, 0.31203100085258484, -0.2950035631656647, 0.8293573260307312, 0.4742244780063629, -0.1229676678776741, 0.6437987089157104, -0.7477964758872986, 0.3723064959049225, 0.5055484771728516, 0.4180709421634674, 0.15900325775146484, -0.014973457902669907, -0.96163010597229, -0.13771365582942963, -0.1910645067691803, -0.2662665843963623, -0.12704426050186157, 0.09305845946073532, -0.6573562026023865, -0.7918720841407776, 0.16158750653266907, -1.1494061946868896, -0.42870593070983887, 0.28196755051612854, -0.24374085664749146, -0.24787910282611847, -0.7411876916885376, -1.0065616369247437, -0.9262222647666931, -0.3972892165184021, -0.6908658742904663, 0.2955206334590912, -0.3330616354942322, -0.6017899513244629, -0.23982104659080505, -0.07107105106115341, -0.469818651676178, 0.9372212886810303, -0.8925744295120239, 0.6826648116111755, -0.38471710681915283, -0.5946828126907349, -0.30046728253364563, 0.5485416054725647, 0.4179392457008362, -0.3958027958869934, 0.2860262989997864, -0.7192632555961609, 0.09675901383161545, -0.5052379369735718, 0.12811680138111115, 0.2539398968219757, 0.4144093096256256, 0.6723164916038513, -0.29274412989616394, -0.47467535734176636, 0.47230884432792664, 0.7779620885848999, -0.43877434730529785, 0.18682017922401428, 0.27654898166656494, 0.8887080550193787, 0.0004049108538310975, -0.04314048960804939, 0.7320516109466553, 0.212008997797966, 0.6448579430580139, 0.28564608097076416, 0.1381671130657196, 0.22453533113002777, -0.40878286957740784, 0.6193316578865051, 1.4457409381866455, 0.3458624482154846, 0.13021019101142883, -0.780977189540863, 0.7596340775489807, -1.0323197841644287, -0.8395469188690186, 0.5572696328163147, 0.7142623662948608, 0.2638980746269226, -0.31865817308425903, -0.23379920423030853, 0.1795695573091507, 0.32487085461616516, 0.7482441663742065, -0.055504702031612396, -1.1464506387710571, 0.31061607599258423, 0.5784534215927124, 0.4867333471775055, 0.49985235929489136, -0.6226029396057129, 0.7773795127868652, 15.086788177490234, 0.7893500924110413, -0.37023216485977173, 0.6298968195915222, 0.3896813988685608, 0.24661040306091309, -0.2690845727920532, -0.029197191819548607, -1.375446081161499, 0.05240646004676819, 1.4994041919708252, 0.06873372942209244, 0.36663511395454407, 0.26210010051727295, 0.057573284953832626, 0.37506231665611267, -0.22383637726306915, 0.2998751103878021, 0.42113980650901794, -1.584153175354004, 0.26029038429260254, -0.0493629015982151, -0.0893268883228302, 0.333173543214798, 0.7150039672851562, 0.8966079354286194, 0.587826669216156, -0.36978498101234436, 0.8988060355186462, 0.13543279469013214, 1.0995895862579346, 0.07305103540420532, 0.0036015368532389402, 0.5759591460227966, -0.8039709329605103, -0.18803881108760834, -0.21151253581047058, -1.12156343460083, 0.4389033019542694, -0.14680078625679016, -0.6326033473014832, -0.5887787342071533, -0.17876560986042023, 0.3146267831325531, 0.5936294198036194, 0.027807943522930145, -0.07552573084831238, 1.2905116081237793, -0.06543213129043579, 0.05091007053852081, 0.08816502243280411, 0.5982823371887207, 0.1792137175798416, -0.0034208542201668024, 0.08963743597269058, 0.18278935551643372, -0.2012430727481842, 0.18600738048553467, 0.05223742127418518, -0.29289039969444275, -0.16993024945259094, -0.43053337931632996, 0.14960621297359467, 0.7126737236976624, 0.5306265354156494, 0.0726555809378624, -0.29280364513397217, -0.03207089379429817, 0.06765803694725037, -0.07143474370241165, -0.3320592939853668, 0.18631473183631897, 0.750890851020813, -0.26855793595314026, 0.4419492483139038, 0.016949983313679695, -0.2399051934480667, -0.46627089381217957, -1.2168232202529907, -0.42245569825172424, 0.3148660659790039, -0.522872805595398, -0.09804578125476837, 0.7551085352897644, 0.03918519243597984, -0.23946760594844818, -0.11339999735355377, -0.6857644319534302, -0.22351306676864624, 0.46084195375442505, -1.0233997106552124, -0.80654376745224, 0.4802062511444092, -0.22780326008796692, -0.11492424458265305, -0.037201009690761566, 1.480355143547058, -0.21220527589321136, -0.40024277567863464, 0.06254562735557556, 0.13154558837413788, 0.06918799877166748, -0.37401115894317627, -0.5660924315452576, 1.3652637004852295, 0.5242117047309875, 0.20476816594600677, 0.5289459228515625, 0.2836797833442688, -0.01297014206647873, -0.9251853823661804, 0.03274288773536682, 0.7962619066238403, -1.1130644083023071, -0.20586732029914856, -1.2399935722351074, -0.6805514693260193, 0.6176881790161133, 0.20414680242538452, -0.18375691771507263, 0.038849711418151855, 0.3843032419681549, -0.6492094397544861, -0.222556471824646, -0.37764960527420044, 0.07504395395517349, 0.4174271821975708, -0.5999466776847839, -0.19100412726402283, -0.4644818603992462, 0.5351197719573975, -1.047815203666687, -0.31189754605293274, -0.24364475905895233, 0.367744117975235, -0.014624303206801414, 0.9846401810646057, -0.6485674381256104, 0.3068650960922241, 1.1834348440170288, -0.12923258543014526, -0.8758810758590698, -0.18452811241149902, -0.9216232895851135, -0.31347718834877014, 0.31895503401756287, 0.6123935580253601, -0.6154600381851196, 0.3273571729660034, 0.9214998483657837, 0.06938855350017548, -0.14731824398040771, -0.9929856657981873, -0.45528924465179443, 0.08484208583831787, -0.9895138144493103, 0.7926516532897949, -0.1703123301267624, -0.08220897614955902, -0.3113219738006592, 0.04366513341665268, 0.6120645999908447, -0.38434627652168274, -0.734653115272522, 0.4919867515563965, 0.06333357095718384, 0.05439549684524536, -0.3367968797683716, -0.5320635437965393, -1.1571468114852905, 0.28301700949668884, -0.8869062066078186, 0.3255586624145508, -0.7179296016693115, -0.6559714078903198, -0.06585578620433807, -0.42533841729164124, 0.04354917258024216, 0.5532948970794678, -0.18714021146297455, -0.30083373188972473, -0.5706586241722107, -0.36113885045051575, 0.3919333219528198, 0.5169269442558289, -0.9663860201835632, 0.3758808374404907, 0.1419401466846466, 0.2550387680530548, 0.1262291967868805, 0.2727763056755066, -0.3419168293476105, -0.45741233229637146, -0.9044315814971924, 0.09632957726716995, -0.001238589989952743, -0.05204034596681595, -0.2870400846004486, 0.1662069708108902, -0.03147285431623459, -0.23461000621318817, 0.03314724192023277, 0.6120491623878479, -0.49914097785949707, -0.47752511501312256, 0.6057429313659668, -0.7644346952438354, -0.12042617797851562, 0.2537754476070404, -0.4019582271575928, 0.04636581614613533, 0.9099765419960022, -0.291207879781723, -0.9033214449882507, -0.9612992405891418, 0.5075305700302124, -1.0380659103393555, -0.2190856784582138, -0.34424665570259094, -0.21140828728675842, -1.1008012294769287, -0.4715745449066162, -0.024147523567080498, -0.10525660216808319, -0.7281299233436584, 1.22324800491333, 0.11452040076255798, -0.7404528260231018, 0.1133129745721817, 0.7300370335578918, -0.3081777095794678, -0.3344610929489136, 0.38710054755210876, 0.22526080906391144, -0.20626045763492584, 1.0241419076919556, 0.20810510218143463, 0.3495827615261078, -1.1533282995224, -0.08464200794696808, 0.20500949025154114, -0.32040128111839294, -0.13219745457172394, 1.1280970573425293, -0.40922313928604126, -0.4513801634311676, 0.02089037373661995, -1.2819164991378784, -0.5345821380615234, -0.40285977721214294, 0.5553861260414124, 0.4078846871852875, 0.04228801280260086, -0.26970553398132324, -0.5797352194786072, -0.1968286633491516, -0.09929630160331726, -0.794663667678833, 0.2855798602104187, -0.20333197712898254, -0.29428359866142273, 0.8295806646347046, 0.5142967104911804, -0.4317891299724579, -0.5924311280250549, -0.3839958906173706, -0.4916456341743469, -0.2259913831949234, 0.41708454489707947, -0.19412128627300262, -0.11204748600721359, 0.7177841663360596, 0.6436180472373962, 0.6518623232841492, -0.4039611220359802, -0.4353286623954773, 0.27357134222984314, 0.4718686044216156, 0.5299960374832153, -0.5874432325363159, -0.9954021573066711, 1.2536975145339966, 1.0226565599441528, -0.6914369463920593, 0.4019971489906311, -0.25190380215644836, -0.30771395564079285, 0.5634096264839172, 0.20284166932106018, -0.04077748581767082, 1.1358507871627808, -0.1436452865600586, 0.4869876503944397, 0.49646708369255066, -1.0044033527374268, -0.09088956564664841, 0.5077518224716187, 0.9379799962043762, 0.6336029171943665, 0.4438709318637848, 0.03931942954659462, 0.9149236679077148, -0.12135709822177887, -0.0976179912686348, 0.5105395913124084, 0.6741740107536316, -0.38240912556648254, -0.15093618631362915, -0.10351165384054184, 0.9196423292160034, -0.8633632659912109, -0.7902932167053223, 0.292801171541214, 0.6897943615913391, -0.10929127782583237, 0.6134834289550781, 1.370797038078308, 0.21898093819618225, 0.2931528687477112, 0.6450763940811157, 0.4918261766433716, -0.7936156392097473, -0.22841699421405792, -0.3264693021774292, -0.15390799939632416, -0.4468545913696289, 0.12722857296466827, -0.6518022418022156, -0.4389571249485016, -0.3810650706291199, 0.05353913828730583, 0.10801317542791367, 0.753345251083374, 1.3217524290084839, 0.558114230632782, 0.1882759928703308, -0.17547369003295898, -0.48803943395614624, -0.734425961971283, -0.9291882514953613, -0.36303260922431946, -0.8173475861549377, 0.13991834223270416, -0.36785948276519775, -0.09593784064054489, -0.27887994050979614]}, "authors": [{"authorId": "2280932302", "name": "Junxiong Wang"}, {"authorId": "119292802", "name": "Tushaar Gangavarapu"}, {"authorId": "2266388043", "name": "Jing Nathan Yan"}, {"authorId": "2261743768", "name": "Alexander M. Rush"}], "references": [{"paperId": "6c1578d9eff8f9d25ddf0398a77ffcc888a4593b", "title": "Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling"}, {"paperId": "d53fe76bd2795a19ddf52d012917782f6f6f2c1e", "title": "Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models"}, {"paperId": "cde66097f4123a62bf3e28d48c764648e8c69f72", "title": "Simple linear attention language models balance the recall-throughput tradeoff"}, {"paperId": "25218efe864ee83bea43f8d1b0e0ed4ed81a0581", "title": "Speculative Streaming: Fast LLM Inference without Auxiliary Models"}, {"paperId": "f1a9e0830bc36c048fa4659beaa62609869895b5", "title": "Break the Sequential Dependency of LLM Inference Using Lookahead Decoding"}, {"paperId": "e30666ed82670463aa47686e744f0c6f2a0e083d", "title": "Cascade Speculative Drafting for Even Faster LLM Inference"}, {"paperId": "62b18cc55dcc7ffe52c28e1086aee893b7bc4334", "title": "Gated Linear Attention Transformers with Hardware-Efficient Training"}, {"paperId": "1be73fa3e856c33d0aed1d9e46693523e7fa3c60", "title": "Zoology: Measuring and Improving Recall in Efficient Language Models"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "31245344a6eb6cd897a71928dc4b174ab75e4070", "title": "Diffusion Models Without Attention"}, {"paperId": "532c2c7a247d9e97d20abec1b2f4612984fdab93", "title": "REST: Retrieval-Based Speculative Decoding"}, {"paperId": "c85268696fe1435605ae66a18653cfdcf8153753", "title": "Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture"}, {"paperId": "ba5261e729c181e28a98dee2c08d7cf5fc7127a2", "title": "Online Speculative Decoding"}, {"paperId": "43e624ddeed82df944a6cae0dedec3372438e243", "title": "Accelerating LLM Inference with Staged Speculative Decoding"}, {"paperId": "b069c32fcd77160f944ab3ba71ab6f0cfb782c68", "title": "Focused Transformer: Contrastive Training for Context Scaling"}, {"paperId": "412e266cddfd87c79087a88ba1e4d11b89a45a13", "title": "MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers"}, {"paperId": "eb3415db1b322b1f7bf95f8697aed701b0d40f88", "title": "Inference with Reference: Lossless Acceleration of Large Language Models"}, {"paperId": "f393aff1593c2d370ec0ae004910d18e40524967", "title": "Resurrecting Recurrent Neural Networks for Long Sequences"}, {"paperId": "a1f8082505c7e90b0a033e1b9da0a97d67aad66c", "title": "Accelerating Large Language Model Decoding with Speculative Sampling"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "7cdebb73662387d9040da4f27a7dc04dbffa3c3e", "title": "ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free Language Models"}, {"paperId": "a128b1c47e6842605fb95bceae930d2135fc38fc", "title": "Pretraining Without Attention"}, {"paperId": "d8e9f8c8a37cb4cd26b92ad0d942d641cd512644", "title": "Fast Inference from Transformers via Speculative Decoding"}, {"paperId": "6d7d141c75af752ffc0d8a6184cca3f9323d6c74", "title": "Simplified State Space Layers for Sequence Modeling"}, {"paperId": "eaef083b9d661f42cc0d89d9d8156218f33a91d9", "title": "Long Range Language Modeling via Gated State Spaces"}, {"paperId": "a30ac45ac5b7bd2148d3fb80ee7f3c29724e3170", "title": "How to Train Your HiPPO: State Space Models with Generalized Orthogonal Basis Projections"}, {"paperId": "ca444821352a4bd91884413d8070446e2960715a", "title": "On the Parameterization and Initialization of Diagonal State Space Models"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "218c5c69f3cf0c158e9b6af239a2cc62a688c6de", "title": "Speculative Decoding: Exploiting Speculative Execution for Accelerating Seq2seq Generation"}, {"paperId": "71e15a9a52dcafca57bff5f310b95e2c7d0cfc87", "title": "Diagonal State Spaces are as Effective as Structured State Spaces"}, {"paperId": "736eb449526fe7128917954ec5532b59e318ec78", "title": "Block-Recurrent Transformers"}, {"paperId": "b55ee75940d24934a54d7f1acfde06e9cb45ac44", "title": "It's Raw! Audio Generation with State-Space Models"}, {"paperId": "12809bcb734beafeb47876f42e7b438e27fe99fe", "title": "General-purpose, long-context autoregressive modeling with Perceiver AR"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "231e768f0cd280faa0f725bb353262cb4fed08d1", "title": "Hierarchical Transformers Are More Efficient Language Models"}, {"paperId": "e79d1206292bc5e67ba19737d87d4b2ea4a37105", "title": "Charformer: Fast Character Transformers via Gradient-based Subword Tokenization"}, {"paperId": "1006d191e9eb5b4dbc35fc0bb389328ddc75cba7", "title": "ByT5: Towards a Token-Free Future with Pre-trained Byte-to-Byte Models"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "969287b8a96e242793b11f0dbb99ec341228106f", "title": "Canine: Pre-training an Efficient Tokenization-Free Encoder for Language Representation"}, {"paperId": "0822f8d7e6a72a65e65f147d3a8d8fccd485da40", "title": "Shortformer: Better Language Modeling using Shorter Inputs"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "17aa716dae728e994a2539bf4952c05ad513bd7a", "title": "CharBERT: Character-aware Pre-trained Language Model"}, {"paperId": "4ca3b0ea12f02e2dea01a4aa505956bae5500a09", "title": "Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "9d92905edc1a5d027b0827d1309bc6ac03dd94a0", "title": "Character-Level Translation with Self-attention"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "ae677b0441bfaea0e0c78acfa8758fff353ab715", "title": "Neural Machine Translation with Byte-Level Subwords"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "6398cb8f2af1c988a097ed1e1cefb380195edfb8", "title": "(Preprint)"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "d7b6753a2d4a2b286c396854063bde3a91b75535", "title": "A Simple Method for Commonsense Reasoning"}, {"paperId": "9852ae077c7da6a9d178acaa2b44a335289507a6", "title": "Spell Once, Summon Anywhere: A Two-Level Open-Vocabulary Language Model"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "ed6262b569c0a62c51d941228c54f34e563af022", "title": "Japanese and Korean voice search"}, {"paperId": "6c2b28f9354f667cd5bd07afc0471d8334430da7", "title": "A Neural Probabilistic Language Model"}, {"paperId": "cf0f8f585c8822e3c6bcd9527d546eefc8486aea", "title": "S4ND: Modeling Images and Videos as Multidimensional Signals with State Spaces"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "c8c4ab59ac29973a00df4e5c8df3773a3c59995a", "title": "Searching for Activation Functions"}, {"paperId": null, "title": "Prefix Sums and Their Applications. (CMU-CS-90-190)"}, {"paperId": null, "title": "We introduce MambaByte, a token-free SSM for modeling long byte-sequences"}]}