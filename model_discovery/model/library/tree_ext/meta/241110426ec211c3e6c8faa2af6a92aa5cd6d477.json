{"paperId": "241110426ec211c3e6c8faa2af6a92aa5cd6d477", "title": "Orchid: Flexible and Data-Dependent Convolution for Sequence Modeling", "abstract": "In the rapidly evolving field of deep learning, the demand for models that are both expressive and computationally efficient has never been more critical. This paper introduces Orchid, a novel architecture designed to address the quadratic complexity of traditional attention mechanisms without compromising the ability to capture long-range dependencies and in-context learning. At the core of this architecture lies a new data-dependent global convolution layer, which contextually adapts its kernel conditioned on input sequence using a dedicated conditioning neural network. We design two simple conditioning networks that maintain shift equivariance in our data-dependent convolution operation. The dynamic nature of the proposed convolution kernel grants Orchid high expressivity while maintaining quasilinear scalability for long sequences. We evaluate the proposed model across multiple domains, including language modeling and image classification, to highlight its performance and generality. Our experiments demonstrate that this architecture not only outperforms traditional attention-based architectures such as BERT and Vision Transformers with smaller model sizes, but also extends the feasible sequence length beyond the limitations of the dense attention layers. This achievement represents a significant step towards more efficient and scalable deep learning models for sequence modeling.", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper introduces Orchid, a novel architecture designed to address the quadratic complexity of traditional attention mechanisms without compromising the ability to capture long-range dependencies and in-context learning."}, "embedding": {"model": "specter_v2", "vector": [0.5077660083770752, -0.28596851229667664, 0.004883246496319771, -0.597095787525177, 0.23980499804019928, -0.14061307907104492, 0.8237773180007935, -0.36605703830718994, -1.0630003213882446, -0.2893330752849579, 0.4034813344478607, 0.07831110805273056, 0.7260848879814148, 0.3311940133571625, -0.09667673707008362, -0.0023212723899632692, -1.0621135234832764, 0.16842392086982727, 0.13746584951877594, -0.3206726610660553, -0.03174654394388199, -0.32670947909355164, -0.9455049633979797, 0.03374045714735985, -0.1263917237520218, 0.7860414981842041, 0.7558003067970276, 1.3868181705474854, -0.22758226096630096, 0.30593228340148926, 0.4282234311103821, -0.347727507352829, 0.26440662145614624, 0.026315633207559586, -0.30822619795799255, -0.13152052462100983, 0.32186439633369446, -0.5337145328521729, -0.7369055151939392, 0.7662419676780701, -0.09008125215768814, 0.37163445353507996, 0.6041045188903809, -0.5133005380630493, -0.31866875290870667, 0.45172297954559326, 0.8052425980567932, 0.9317314028739929, -0.630110502243042, -0.5430393218994141, 1.2512480020523071, -1.4070816040039062, 0.19617803394794464, 1.329781413078308, 0.6807092428207397, 0.8583853244781494, -0.21988560259342194, -0.45080751180648804, 0.95595782995224, 0.3531513512134552, -0.6224617958068848, 0.27243778109550476, -0.09931004047393799, -0.4482666850090027, 1.4883263111114502, -0.401726633310318, 0.32075589895248413, 1.136730670928955, 0.20509350299835205, 1.106946587562561, -0.3277013897895813, -0.6988510489463806, -0.1909666210412979, -0.34154990315437317, 0.29992857575416565, 0.6964088082313538, -0.7386842370033264, 0.576724648475647, -0.6215660572052002, 0.3431546688079834, 0.4813985824584961, 0.4042450785636902, 0.34750717878341675, -0.1217389926314354, -0.2222357839345932, 0.5444644093513489, 0.6423525214195251, 0.6955302953720093, -0.4244721233844757, 1.1129039525985718, 0.6646341681480408, -0.07253295928239822, -0.33239632844924927, 0.10265893489122391, -0.12979087233543396, 0.3101314306259155, -0.5523563623428345, 0.18303409218788147, -0.10676580667495728, 1.1012120246887207, -0.31125861406326294, 0.226865753531456, -0.5585716366767883, 0.12577252089977264, 1.0325409173965454, -0.2537846565246582, 0.33027470111846924, -0.513175368309021, -0.11696900427341461, -0.9640538692474365, 0.15114900469779968, -0.6328895688056946, -0.15345357358455658, -0.2808293104171753, -0.7667825818061829, -1.1146069765090942, -0.6443257927894592, 0.2793356776237488, -1.1171343326568604, 0.9404201507568359, -0.5914170742034912, 0.5239613652229309, -0.20569854974746704, 0.22995765507221222, 0.1077396497130394, 0.45911890268325806, 0.7733671069145203, 0.2513046860694885, 0.9053030610084534, -0.8832675814628601, -0.462570458650589, -0.9757351875305176, 0.3648255169391632, 0.06393131613731384, 0.2421042025089264, -0.4004341959953308, -0.7010626792907715, -1.3684245347976685, -0.970378041267395, -0.1865716576576233, -0.6227315068244934, -0.037785034626722336, 0.9907528758049011, 0.2772115468978882, -0.947704017162323, 0.8406385183334351, -0.36268654465675354, -0.19654011726379395, 0.6065825819969177, -0.06223064661026001, 0.5471405982971191, -0.43781721591949463, -1.3809571266174316, 0.5827561020851135, 0.24503342807292938, -0.5312812328338623, -0.6473160982131958, -0.8954829573631287, -0.9383001923561096, -0.1358378529548645, 0.11420715600252151, -0.3099057674407959, 1.472506046295166, -0.36929452419281006, -0.8067265152931213, 0.7513860464096069, -0.29272064566612244, -0.3202933967113495, 0.2934030294418335, -0.4133972227573395, -0.6125468015670776, -0.5481926798820496, -0.36948370933532715, 0.5582473278045654, 0.48693060874938965, -0.09855084121227264, -0.23938648402690887, 0.13968002796173096, -0.4241124987602234, -0.29091593623161316, -0.4317563474178314, 1.0294924974441528, -0.5409538745880127, -0.5864055752754211, -0.21286962926387787, 0.32119229435920715, -0.16458116471767426, 0.14340117573738098, 0.08879215270280838, -0.8560763597488403, 1.1983622312545776, 0.0945567935705185, 0.7918086647987366, -1.0790362358093262, -0.7749398946762085, -0.45934075117111206, -0.4229239821434021, 0.09825588017702103, -0.7901653051376343, 0.6929581761360168, -0.4788142144680023, 0.21922729909420013, -0.16345636546611786, -1.1868191957473755, -0.08818437159061432, 0.15977416932582855, -0.6464086771011353, -0.2935520112514496, 0.2900868356227875, 1.32107675075531, -0.9863724112510681, 0.017134981229901314, -0.1608610600233078, 0.4103568196296692, -1.0006682872772217, 1.376924753189087, -0.623044490814209, -0.10487460345029831, 0.23259015381336212, -0.29072144627571106, 0.02223014645278454, -0.34207695722579956, 0.4809243977069855, -0.5373475551605225, -0.27516040205955505, 0.3455379009246826, 0.12089279294013977, 1.5791816711425781, -0.3312012553215027, 0.7211375832557678, -0.14789101481437683, -0.9802237153053284, 0.4243152439594269, 0.17294499278068542, -0.05481155216693878, -0.13022902607917786, 0.4386325478553772, -0.00928780809044838, -0.7741098999977112, 0.07111480832099915, 0.6267081499099731, 0.6038840413093567, -0.3902721703052521, -0.12982964515686035, 0.7118740677833557, -0.304410457611084, 0.27646011114120483, 0.4948042333126068, 0.5094003677368164, 0.6823304295539856, 0.2729625999927521, -0.251686692237854, 0.13168483972549438, -1.0326011180877686, -0.03564295172691345, 0.37315016984939575, 0.37949299812316895, 1.0877960920333862, 0.2619440257549286, -0.9305406808853149, -0.8182833194732666, 0.2859612703323364, 0.6115959882736206, 1.4726181030273438, 0.09770505875349045, 0.0728791207075119, -0.8755118250846863, -0.2848449647426605, -0.19762571156024933, 0.006587198004126549, -0.781366765499115, -0.3008027672767639, -0.46674326062202454, -0.8551019430160522, 0.8107692003250122, 0.7099539041519165, 0.9430020451545715, -0.7153121829032898, -0.35456931591033936, -0.061372920870780945, 0.34007325768470764, -0.9786694645881653, -1.127005696296692, 0.7039191722869873, -0.14095941185951233, 0.2204989343881607, 0.23493318259716034, -0.11289124190807343, -0.09446855634450912, -0.5444520711898804, 0.8860547542572021, -0.5430224537849426, -0.8747400641441345, 0.30282673239707947, 0.5351008772850037, -0.9686145186424255, -0.7705143690109253, 0.22894717752933502, 0.1277698427438736, 0.021161245182156563, 0.4538058340549469, 0.5147438645362854, -0.11596005409955978, -0.008735449984669685, -0.689110279083252, 0.010838847607374191, -0.007200798951089382, 0.08929190039634705, 0.6230949759483337, -0.5987157225608826, 0.052734434604644775, -0.8841286897659302, 0.3792789876461029, 0.1338769644498825, -0.43887633085250854, 0.12494978308677673, -0.5331677198410034, -0.2172505110502243, 0.3867862820625305, -0.8364799618721008, -0.34138762950897217, -0.5625709891319275, 0.04102538153529167, -0.7924946546554565, -0.3202187418937683, 0.21238292753696442, 0.4183581471443176, 0.38714057207107544, 0.3810775578022003, 0.41204217076301575, 0.5643513202667236, 0.03401830047369003, 0.3299783170223236, -1.0251092910766602, 1.0440456867218018, 0.2645702660083771, -0.1617875099182129, 0.052517518401145935, 0.11624009907245636, -0.8546836376190186, -0.5980364084243774, -0.5665770173072815, -0.7641366124153137, -0.5683014988899231, 0.7947205305099487, -0.5399002432823181, -0.9509214162826538, 0.1797192543745041, -1.1510326862335205, -0.21442730724811554, 0.2789677083492279, -0.18393932282924652, -0.23555371165275574, -0.9752829670906067, -0.9496809244155884, -0.565565824508667, -0.23932652175426483, -0.5338412523269653, 0.037489380687475204, 0.15297456085681915, -0.31990572810173035, -0.7934653162956238, -0.16121593117713928, -0.5905827283859253, 0.9558181166648865, -0.3184741735458374, 0.658297598361969, -0.0269155316054821, -0.34129276871681213, -0.31160396337509155, 0.2765703499317169, 0.9429813027381897, -0.08535382151603699, 0.5600464940071106, -0.8865599036216736, 0.234149768948555, -0.4368121922016144, -0.28041431307792664, 0.4408814013004303, 0.04140811040997505, 1.0123794078826904, 0.4041282534599304, -0.4321250021457672, 0.4698876738548279, 1.507935643196106, -0.22750817239284515, 0.13430607318878174, -0.12260257452726364, 0.8020408749580383, -0.22434940934181213, -0.20287732779979706, 0.6929306983947754, 0.14229092001914978, 0.44717827439308167, 0.5044794678688049, -0.05509115383028984, -0.10929503291845322, -0.6835237145423889, 0.1483505517244339, 1.1368978023529053, 0.17821402847766876, -0.04477360472083092, -1.2295321226119995, 0.8881774544715881, -0.9629408121109009, -1.190760850906372, 0.7124090790748596, 0.4016742408275604, 0.38148149847984314, -0.4885883033275604, -0.2302415370941162, -0.6712693572044373, 0.6112823486328125, 0.31753596663475037, -0.6010575294494629, -0.8550974130630493, -0.035301852971315384, 0.48681700229644775, 0.07949329912662506, 0.608497142791748, -0.6098405122756958, 0.307315468788147, 14.876066207885742, 0.47264543175697327, -0.4582987427711487, 0.3939419090747833, 0.6451351046562195, 0.16408511996269226, -0.2453514039516449, -0.17977575957775116, -1.3300970792770386, 0.08187416195869446, 1.0782264471054077, 0.32287174463272095, 0.43269261717796326, 0.32192835211753845, -0.0873207375407219, 0.6143714189529419, -0.7346672415733337, 0.6920841336250305, 0.5353630781173706, -1.3230164051055908, 0.16295380890369415, -0.11667324602603912, 0.29341351985931396, 0.4426858127117157, 0.8891788721084595, 0.7209686636924744, 0.39971500635147095, -0.3234373927116394, 0.6207776665687561, 0.6475253701210022, 1.0317769050598145, 0.13322100043296814, 0.03621932119131088, 0.5977036952972412, -0.987957775592804, -0.26633742451667786, -0.46280747652053833, -1.010237455368042, 0.1459827721118927, -0.28046196699142456, -0.6479209661483765, -0.3333245813846588, -0.027810193598270416, 1.049334168434143, 0.45458200573921204, -0.007874522358179092, 0.06785465776920319, 0.595304012298584, 0.40909653902053833, -0.30580416321754456, 0.6577852368354797, 0.31125202775001526, -0.11047594994306564, 0.6147741675376892, -0.14983390271663666, 0.2104872167110443, -0.023884616792201996, 0.4174089729785919, -0.4715355634689331, -0.6291880011558533, -0.2026343047618866, -0.2709038555622101, -0.24763473868370056, 0.6071739196777344, 0.5081630349159241, 0.2663304805755615, -0.6655042767524719, 0.5058681964874268, 0.37558498978614807, 0.3239493668079376, -0.7642437815666199, 0.14276377856731415, 0.7711443305015564, -0.7283926606178284, 0.6385866403579712, 0.12537328898906708, -0.21304340660572052, -0.36390265822410583, -1.0606319904327393, -0.0988026037812233, 0.41894325613975525, -0.8643450140953064, -0.8781367540359497, 0.8622652888298035, -0.2033226191997528, -0.31948575377464294, 0.4271036982536316, -1.059372901916504, -0.07014001160860062, 0.7507185339927673, -1.1014379262924194, -0.38706302642822266, -0.16229702532291412, -0.1956414133310318, -0.1943330615758896, 0.1969238668680191, 1.1610097885131836, 0.41431552171707153, -0.07974760234355927, -0.1351039856672287, -0.02883869968354702, 0.11687958985567093, -0.14032362401485443, -0.7564879059791565, 1.0482112169265747, 0.12193271517753601, -0.08491269499063492, 0.1352488249540329, 0.034837506711483, 0.33965498208999634, -0.3203703463077545, -0.48561081290245056, 0.6617178320884705, -0.9320908784866333, -0.5018824338912964, -1.0337470769882202, -0.9330684542655945, 0.5775373578071594, 0.507286548614502, -0.1437586396932602, 0.308206170797348, -0.02444716915488243, -0.7497109174728394, -0.2708691358566284, -0.24643617868423462, 0.19592443108558655, 0.7602899074554443, -0.7622616291046143, -0.1924116462469101, -0.4846227169036865, 0.5035570859909058, -0.745453417301178, -0.2705400884151459, -0.052635010331869125, 0.19329507648944855, -0.18679235875606537, 1.2442706823349, -0.8077747821807861, 0.8075190186500549, 0.8898265957832336, -0.2535752058029175, -0.5016884207725525, -0.3352217376232147, -0.5989863872528076, 0.27617147564888, 0.02561284229159355, 0.307213693857193, -0.18480776250362396, 0.24709215760231018, 0.7835130095481873, -0.032738097012043, -0.6226478815078735, -0.2688392996788025, -0.500645637512207, 0.14724625647068024, -0.6110641360282898, 0.30898594856262207, -0.02306343801319599, -0.6119405627250671, 0.16925525665283203, 0.08077256381511688, 0.45691677927970886, -0.4340549409389496, -0.5605707168579102, 0.1519886702299118, -0.06190815567970276, -0.023640859872102737, -0.584972620010376, -0.8187148571014404, -1.7925586700439453, -0.09442676603794098, -0.9981908798217773, -0.043666936457157135, -0.6223122477531433, -0.22654114663600922, 0.2693277895450592, -0.4719391167163849, -0.07877854257822037, 0.12200105935335159, -0.6126238107681274, -0.3672448992729187, -0.6910682916641235, -0.2942635715007782, 0.841498613357544, 0.9065172076225281, -0.5240647792816162, 0.47879448533058167, -0.026878729462623596, 0.30554336309432983, 0.0947013720870018, 0.3571121394634247, -0.11104528605937958, -0.7641052007675171, -0.9643356204032898, 0.10329222679138184, -0.2291717678308487, 0.13192278146743774, -0.7053840160369873, 0.6277401447296143, 0.08405037224292755, -0.0505375862121582, -0.12128693610429764, 0.6684579253196716, -0.9566537737846375, -0.3882904052734375, 0.6730797290802002, -1.0831120014190674, 0.07787434756755829, 0.29424938559532166, -0.2528812885284424, -0.2699042856693268, 0.7829234600067139, 0.33163055777549744, -0.9201685190200806, -1.2210057973861694, 1.04950749874115, -0.5663982033729553, 0.05638992041349411, -0.057120051234960556, -0.061406780034303665, -0.720579981803894, -0.4522080421447754, -0.14847370982170105, 0.3326432406902313, -0.6503958106040955, 1.0391212701797485, 0.5474392175674438, -1.2433106899261475, 0.16783159971237183, 0.302939236164093, 0.16256944835186005, -0.10441609472036362, 0.5008099675178528, 0.16375789046287537, -0.14399875700473785, 0.5353227257728577, -0.12897329032421112, 0.28570908308029175, -1.245192527770996, 0.5889075398445129, 1.0462369918823242, -0.06715595722198486, -0.024848323315382004, 1.368718147277832, -0.06547916680574417, -0.9702039361000061, 0.16167327761650085, -1.1577341556549072, -0.3777143955230713, -0.20854036509990692, 0.4350810945034027, 0.06712242215871811, -0.2084549367427826, 0.22208932042121887, -0.5506792664527893, 0.07535716891288757, -0.16679060459136963, -0.6176307201385498, 0.446396142244339, 0.010099794715642929, -0.22687888145446777, 0.9216029644012451, 1.2206629514694214, -1.174959659576416, -1.3069308996200562, -0.9675858616828918, -0.4166997969150543, -0.19962148368358612, -0.205926775932312, -0.2372300624847412, -0.3699060082435608, 0.9151504039764404, 0.2810993790626526, 0.42778992652893066, 0.1798437386751175, -0.27099981904029846, -0.018670188263058662, 0.6350560188293457, -0.24103304743766785, -0.5438346266746521, -0.022087374702095985, 1.651036262512207, 1.6028120517730713, -0.4732229709625244, 0.04179671034216881, -0.18278728425502777, -0.8152629733085632, 0.8296346068382263, 0.5033684968948364, -0.12063220143318176, 1.3134269714355469, -0.09919900447130203, 0.17303816974163055, 0.3455905616283417, -1.1931194067001343, -0.10843659192323685, 0.6926373243331909, 1.027794361114502, 0.5668317675590515, 0.3016151487827301, 0.3419761657714844, 0.7120162844657898, 0.34596407413482666, 0.09812282770872116, 0.15197481215000153, 0.4453246593475342, -0.003350899089127779, -0.17182455956935883, 0.31964507699012756, 0.4853109121322632, -0.6026443839073181, -0.664040207862854, 0.21357731521129608, 0.560052752494812, 0.37826189398765564, 0.17645858228206635, 1.103777527809143, -0.008999858051538467, 0.6279075741767883, 0.45859649777412415, 0.4261051416397095, -0.5729766488075256, -0.13908801972866058, -0.526906430721283, -0.8959799408912659, 0.08638162165880203, -0.38315650820732117, -1.068642258644104, -0.5740844011306763, -0.14263245463371277, 0.5747861266136169, -0.4597899615764618, 0.36508458852767944, 0.9859304428100586, 0.43816232681274414, 0.7002642750740051, -0.0626663938164711, -0.4270039200782776, -0.5744283199310303, -0.8745331168174744, 0.021861150860786438, -0.16627264022827148, 0.22357018291950226, -0.2349471002817154, 0.05068078637123108, 0.43233492970466614]}, "authors": [{"authorId": "2287928596", "name": "Mahdi Karami"}, {"authorId": "2244395679", "name": "Ali Ghodsi"}], "references": [{"paperId": "a01e1138600499f65462ed3d51c3e76af1aad18c", "title": "The pitfalls of next-token prediction"}, {"paperId": "d53fe76bd2795a19ddf52d012917782f6f6f2c1e", "title": "Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models"}, {"paperId": "cde66097f4123a62bf3e28d48c764648e8c69f72", "title": "Simple linear attention language models balance the recall-throughput tradeoff"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "5c104f905fcacf390270f619f232a2ba4eb873f2", "title": "FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores"}, {"paperId": "c85268696fe1435605ae66a18653cfdcf8153753", "title": "Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture"}, {"paperId": "3c8444cc4e96bdbe6853b886caf032afd1ee1d20", "title": "CausalLM is not optimal for in-context learning"}, {"paperId": "ce913026f693101e54d3ab9152e107034d81fce1", "title": "Holistic Evaluation of Language Models"}, {"paperId": "f393aff1593c2d370ec0ae004910d18e40524967", "title": "Resurrecting Recurrent Neural Networks for Long Sequences"}, {"paperId": "998ac3e945857cf2676ee7efdbaf443a0c6f820a", "title": "Hyena Hierarchy: Towards Larger Convolutional Language Models"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "a128b1c47e6842605fb95bceae930d2135fc38fc", "title": "Pretraining Without Attention"}, {"paperId": "240300b1da360f22bf0b82c6817eacebba6deed4", "title": "What Makes Convolutional Models Great on Long Sequence Modeling?"}, {"paperId": "c90a99eeb57019732a6cc996bb9eaf13faedf00f", "title": "In-context Learning and Induction Heads"}, {"paperId": "de32da8f5c6a50a6c311e9357ba16aa7d05a1bc9", "title": "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes"}, {"paperId": "eaef083b9d661f42cc0d89d9d8156218f33a91d9", "title": "Long Range Language Modeling via Gated State Spaces"}, {"paperId": "8115b6b67f33aef168d39fc29df045fce8780b5a", "title": "Better plain ViT baselines for ImageNet-1k"}, {"paperId": "8326dba15f6b8ee6e43c23eea3265a05e59e8135", "title": "Monarch: Expressive Structured Matrices for Efficient and Accurate Training"}, {"paperId": "90b21dbad8969b74d704eed15a3d98722a88e464", "title": "Pixelated Butterfly: Simple and Efficient Sparse training for Neural Network Models"}, {"paperId": "427fe0e6e2e2d6f927c62e80c75706e02c2a747f", "title": "Adaptive Fourier Neural Operators: Efficient Token Mixers for Transformers"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "5f895e84c1fea75de07b4f90da518273c2e57291", "title": "Scatterbrain: Unifying Sparse and Low-rank Attention Approximation"}, {"paperId": "ca9047c78d48b606c4e4f0c456b1dda550de28b2", "title": "Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers"}, {"paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"}, {"paperId": "cf5e6e3c50a798d87033e0e108e88b3647738bbe", "title": "How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers"}, {"paperId": "e32a12b14e212506115cc6804667b3d8297917e1", "title": "Poolingformer: Long Document Modeling with Pooling Attention"}, {"paperId": "14014c024674991149f3ecf9314c93f7e029ef1a", "title": "Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges"}, {"paperId": "7694aae9766d5f1fe74d900cd82aee898cb6e8e9", "title": "How to Train BERT with an Academic Budget"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "1d5c8c6e5a774d2fef8d92bd28670a6345a97f7a", "title": "CKConv: Continuous Kernel Convolution For Sequential Data"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "849b88ddc8f8cabc6d4246479b275a1ee65d0647", "title": "A Generalization of Transformer Networks to Graphs"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "2f7dc1ee85e9f6a97810c66016e09ffeed684f03", "title": "Fourier Neural Operator for Parametric Partial Differential Equations"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "2a218786f4615b82389f78472e7ff22e6ce57490", "title": "ConvBERT: Improving BERT with Span-based Dynamic Convolution"}, {"paperId": "37be1818608492dc5fd4a63e448650f5192ebcde", "title": "Monarch"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "fb7972f30812c7dd056d7943c3e3f00af022d607", "title": "Dynamic Convolution: Attention Over Convolution Kernels"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "7cf64265882f7129b127ce0e27ff7bca9173aa58", "title": "The Context"}, {"paperId": "ae04f3d011511ad8ed7ffdf9fcfb7f11e6899ca2", "title": "Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "81f5810fbbab9b7203b9556f4ce3c741875407bc", "title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "fea820b7d953d32069e189af2961c28fd213470b", "title": "Pay Less Attention with Lightweight and Dynamic Convolutions"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "6f3370fcf266fc10842b6d3e77c6cadd842a3580", "title": "Tensor Field Networks: Rotation- and Translation-Equivariant Neural Networks for 3D Point Clouds"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "54c3e878bf0ff2fdde16e439b5579ee99ee0d0d8", "title": "ACDC: A Structured Efficient Linear Layer"}, {"paperId": "5934400081d9541339da0f16d2613263f1a4c2a2", "title": "An Exploration of Parameter Redundancy in Deep Networks with Circulant Projections"}, {"paperId": "31277293b6a81c54b95a5c116c55a2cc528475cf", "title": "Mathematics of the Discrete Fourier Transform (DFT) with Audio Applications"}, {"paperId": "79d1b330f0ef51f63ecb9b291dd5a05de5a858c0", "title": "Toeplitz and Circulant Matrices: A Review"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "0e6beb95b5150ce99b108acdefabf70ccd3fee30", "title": "An algorithm for the machine calculation of complex Fourier series"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "fc1636e3e17a83d319c30e92be945e2d6c12fe15", "title": "Invertible Convolutional Flow"}, {"paperId": null, "title": "A method for stochastic optimization"}, {"paperId": "1cbfa10be8f8744a3e84e3f60b59f28ee4d17435", "title": "Discrete Time Signal Processing"}, {"paperId": null, "title": "h_0_f = self.transform(h_0) x_f = self.transform(x) y = torch.fft.irfft(x_f * (h_0_f + h_adapt_f)) return y[."}, {"paperId": null, "title": "continuous health monitoring data, leading to earlier detection of diseases and tailored treatment plans"}]}