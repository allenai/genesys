{"paperId": "bdd07688083de2fc792a48ba935cd33256066827", "title": "LongEmbed: Extending Embedding Models for Long Context Retrieval", "abstract": "Embedding models play a pivot role in modern NLP applications such as IR and RAG. While the context limit of LLMs has been pushed beyond 1 million tokens, embedding models are still confined to a narrow context window not exceeding 8k tokens, refrained from application scenarios requiring long inputs such as legal contracts. This paper explores context window extension of existing embedding models, pushing the limit to 32k without requiring additional training. First, we examine the performance of current embedding models for long context retrieval on our newly constructed LongEmbed benchmark. LongEmbed comprises two synthetic tasks and four carefully chosen real-world tasks, featuring documents of varying length and dispersed target information. Benchmarking results underscore huge room for improvement in these models. Based on this, comprehensive experiments show that training-free context window extension strategies like position interpolation can effectively extend the context window of existing embedding models by several folds, regardless of their original context being 512 or beyond 4k. Furthermore, for models employing absolute position encoding (APE), we show the possibility of further fine-tuning to harvest notable performance gains while strictly preserving original behavior for short inputs. For models using rotary position embedding (RoPE), significant enhancements are observed when employing RoPE-specific methods, such as NTK and SelfExtend, indicating RoPE's superiority over APE for context window extension. To facilitate future research, we release E5-Base-4k and E5-RoPE-Base, along with the LongEmbed benchmark.", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Comprehensive experiments show that training-free context window extension strategies like position interpolation can effectively extend the context window of existing embedding models by several folds, regardless of their original context being 512 or beyond 4k."}, "embedding": {"model": "specter_v2", "vector": [-0.15645307302474976, 0.21864719688892365, -1.00355064868927, -0.10010603815317154, -0.5441973805427551, -0.7514810562133789, 0.7007806897163391, -0.003909456543624401, -0.7795993685722351, 0.23905470967292786, 0.6558514833450317, -0.3011695444583893, -0.009172207675874233, 0.4032559394836426, -0.04520958289504051, 0.07234924286603928, -0.9876431226730347, 0.359903484582901, -0.09703617542982101, -0.374307245016098, -0.16437369585037231, -0.44867679476737976, -0.46673092246055603, 0.3966875672340393, 0.46607506275177, 0.24187715351581573, 0.003280038945376873, 0.7391531467437744, -0.39899858832359314, -0.33613121509552, 0.25253885984420776, -0.5536937713623047, 0.25725576281547546, 0.5408297181129456, -0.2688838541507721, -0.6985293030738831, 0.4172169864177704, -0.644623875617981, -0.5463957190513611, 0.2729541063308716, 0.025876373052597046, 0.39066922664642334, 0.49960383772850037, -0.5269966125488281, -0.9400824904441833, 1.199434757232666, 0.8277246356010437, 0.49886879324913025, -0.03352653235197067, -0.8159466981887817, 1.762906789779663, -1.6034845113754272, 0.8623835444450378, 1.069178819656372, 0.5163003206253052, 0.4670903980731964, -0.379891574382782, -0.2732110321521759, 0.0771007388830185, 0.3197120428085327, -0.7733645439147949, -0.28086408972740173, -0.019667183980345726, 0.2272639125585556, 1.6967241764068604, -0.052250929176807404, -0.2957890033721924, 0.7055147290229797, -0.336997926235199, 1.6152836084365845, -0.03672294691205025, -1.3108160495758057, -0.3084799349308014, 0.2544093132019043, 0.27787911891937256, 0.16283658146858215, -0.3660476803779602, 0.43391841650009155, -0.4903217852115631, -0.3372473120689392, 0.01782422512769699, -0.05217672884464264, 0.10386046022176743, 0.24268822371959686, -0.41362300515174866, 0.49456000328063965, 0.6165255308151245, 1.0452373027801514, 0.007296431809663773, 0.503994345664978, 0.4501051604747772, 0.6336175203323364, 0.24518251419067383, 0.3790549337863922, -0.17132779955863953, 0.35430097579956055, -1.162570595741272, 0.5383124947547913, 0.025612447410821915, 0.548780620098114, -0.10513756424188614, -0.34954163432121277, -1.1835920810699463, 0.31997281312942505, 1.174065351486206, -0.22951820492744446, 0.3121229410171509, -0.5710908770561218, 0.6012777090072632, -0.2949904501438141, 0.6008235216140747, -0.5039432048797607, -0.021708544343709946, 0.03798438236117363, -0.19238461554050446, -1.3513458967208862, -0.37958285212516785, -0.24440878629684448, -0.393322616815567, 0.5928722023963928, -0.050633758306503296, 0.2337731570005417, 0.7024184465408325, 0.7230625748634338, 0.7605978846549988, 0.7165178060531616, 0.11474728584289551, 0.09977452456951141, 0.769258975982666, -0.686835765838623, -0.8040629625320435, -1.1024044752120972, 1.4131838083267212, -0.3744428753852844, 0.4924662411212921, -0.712975263595581, -1.0291439294815063, -0.3384937047958374, -1.170958161354065, -0.13052991032600403, -1.0120058059692383, 0.7220314145088196, 0.9810146689414978, 0.3738473057746887, -0.7220945358276367, 0.9805518984794617, 0.20627784729003906, -0.11423087120056152, 0.14051604270935059, -0.04505082964897156, 0.08719369769096375, -0.8311142325401306, -2.050502061843872, 0.34706881642341614, 0.6914414763450623, -0.23932170867919922, 0.36346375942230225, -0.29337841272354126, -1.2859963178634644, -0.1337183117866516, 0.702392578125, -0.13925041258335114, 1.0206007957458496, 0.5038083791732788, -0.7852728366851807, 0.462960809469223, -0.3373800814151764, 0.1332438588142395, 0.5319724678993225, -0.2764188051223755, -0.9467771649360657, -0.5349113941192627, 0.05168499797582626, 0.3086351454257965, 0.35846033692359924, -0.13285282254219055, 0.013794473372399807, 0.30367419123649597, -0.0810500755906105, 0.34925350546836853, -0.48180267214775085, 0.9105923771858215, -0.43431392312049866, -0.3494330048561096, 0.08042297512292862, 0.39326706528663635, -0.007841595448553562, -0.14328666031360626, -0.044373515993356705, -1.1700319051742554, 1.1964248418807983, -0.06828480213880539, 1.439802885055542, -1.042184591293335, -0.7886775732040405, -0.20733417570590973, -0.6075474619865417, 0.2512454092502594, -0.8532900214195251, 1.0011507272720337, -0.2649550437927246, 0.6330264806747437, -0.06780651956796646, -1.1307891607284546, 0.6088507771492004, 0.20708592236042023, -0.7634962797164917, -0.6517111659049988, -0.08210816234350204, 1.5094058513641357, -0.8804872035980225, -0.2602978050708771, -0.27401167154312134, 0.19777433574199677, -0.5999054908752441, 0.8441570997238159, -0.7154595851898193, -0.13682083785533905, -0.057767048478126526, 0.17597231268882751, -0.13864099979400635, -0.13794225454330444, 0.5715745687484741, -0.03561561182141304, -0.10514160245656967, 0.6217429041862488, -0.7990379929542542, 1.4297854900360107, -0.4568871855735779, 0.7516869902610779, 0.18913492560386658, 0.09336692094802856, -0.3103755712509155, 0.6567657589912415, -0.246964693069458, -0.02614348754286766, -0.3045426309108734, 0.6439887881278992, -0.903427243232727, -0.05657969042658806, 1.0766469240188599, 0.9603382349014282, -0.3595885932445526, 0.34321051836013794, 0.15839500725269318, 0.06313366442918777, 0.6382227540016174, 0.4295850992202759, 0.5193067789077759, 0.3813933730125427, 0.18353500962257385, 0.3758872449398041, 0.12328816205263138, -0.5655373930931091, -0.1532750129699707, 0.13446752727031708, 0.6550206542015076, 0.31856653094291687, 0.41619762778282166, -0.5575947761535645, -0.41780659556388855, 0.2847464382648468, 0.28737673163414, 1.7751871347427368, -0.13547207415103912, -0.5289455652236938, -0.3087870478630066, -0.7546899318695068, 0.13614213466644287, 0.024667363613843918, -0.4585772454738617, 0.4000576138496399, -0.7823191285133362, -1.0710546970367432, 0.8174079656600952, 0.28546419739723206, 0.6787950396537781, -0.8309553861618042, 0.05482136458158493, -0.11307527869939804, -0.04027853161096573, -0.8171872496604919, -0.6494103074073792, 0.11175397783517838, -0.37383753061294556, -0.09692691266536713, 0.0841539278626442, -0.2453756332397461, -0.02024005725979805, -0.7072532176971436, 0.6510937809944153, -0.10631342977285385, -0.35257747769355774, 0.07161428034305573, 0.11568208038806915, -0.39130082726478577, -0.5195607542991638, 0.3262447714805603, 0.3102456331253052, -0.7543583512306213, 0.4374983608722687, 0.6944043040275574, -0.07554559409618378, 0.23751144111156464, -0.902393102645874, -0.3794434070587158, 0.4698845148086548, 0.40395259857177734, 0.6117365956306458, -0.15978147089481354, 0.3031114339828491, -1.0429620742797852, 1.271026611328125, 0.1993151754140854, -0.43156328797340393, 0.4572316110134125, -1.0123894214630127, -0.5162082314491272, 0.13595862686634064, -0.7035329937934875, -0.29815059900283813, -1.099197268486023, 0.41691818833351135, -0.027157707139849663, 0.013912552036345005, 0.7321526408195496, 0.29955214262008667, 0.4182337820529938, 0.5941038131713867, 0.09747367352247238, 0.14396890997886658, -0.18412728607654572, 1.07550048828125, -0.2343919724225998, 0.13030119240283966, -0.005355349276214838, 0.211502805352211, -0.20785535871982574, -0.08367954939603806, -0.7412186861038208, -0.4417164623737335, -0.6625850796699524, -0.6204761266708374, 0.01820233277976513, -0.056125350296497345, -0.31813332438468933, -0.6046504974365234, -0.6970871090888977, -0.8210407495498657, -0.27322256565093994, 0.03676082193851471, -0.14729247987270355, 0.22043634951114655, -0.8034658432006836, -1.4280462265014648, -0.49750176072120667, -0.5837913751602173, -0.6676284670829773, 0.6690800786018372, -0.045205116271972656, -0.024832293391227722, -0.8015731573104858, 0.38581380248069763, -0.2907938063144684, 0.5755594968795776, -0.26369401812553406, 0.8521506786346436, 0.08532457798719406, -0.09413453191518784, -0.6885961890220642, -0.03397290036082268, 0.37435683608055115, -0.3230420649051666, 0.33037444949150085, -0.5755844116210938, 0.13483530282974243, -0.47484609484672546, -0.2657856345176697, 0.4587670862674713, 0.16755501925945282, 0.16984082758426666, -0.45121774077415466, -0.9785924553871155, 0.24624915421009064, 1.6901339292526245, -0.9048337936401367, 0.4008190631866455, 0.2719505727291107, 0.5905197262763977, 0.4708259403705597, 0.35730984807014465, 0.4256880581378937, -0.04827291518449783, 0.4169336259365082, 0.18694406747817993, 0.024877121672034264, 0.0920175090432167, -0.5169072151184082, 0.45215585827827454, 1.0516777038574219, 0.144795760512352, -0.16770808398723602, -1.1409021615982056, 0.7304317951202393, -1.2895169258117676, -1.0965367555618286, 0.889860987663269, 0.5004013776779175, 0.6419748663902283, -0.6087947487831116, -0.5887481570243835, -0.2926069498062134, 0.2262045443058014, 0.6170328259468079, -0.43795883655548096, -0.4362083673477173, -0.09284680336713791, -0.11572786420583725, 0.019028302282094955, 0.5775270462036133, -0.7122875452041626, 0.8934102058410645, 14.631698608398438, 1.1021827459335327, 0.23540298640727997, 0.31829580664634705, 0.42509883642196655, 0.12216222286224365, -0.38509276509284973, -0.08627548813819885, -1.504119634628296, -0.02830926515161991, 0.9910133481025696, 0.1894347071647644, 0.3309623897075653, 0.3433327376842499, -0.08799344301223755, 0.32567474246025085, -0.49460843205451965, 0.3965495526790619, 0.46605804562568665, -1.6613577604293823, 0.1244312971830368, 0.5444756746292114, 0.4437859356403351, 0.5689863562583923, 1.0697922706604004, 1.0196634531021118, 0.3015568256378174, -0.5258622765541077, 0.003994102124124765, -0.10796398669481277, 1.3516429662704468, -0.014525537379086018, 0.5952145457267761, 0.5204598903656006, -0.7968384623527527, -0.7113040685653687, -0.8147569894790649, -0.6748350262641907, -0.016187772154808044, 0.057760320603847504, -1.316175103187561, -0.12198161333799362, -0.2895304262638092, 0.8517673015594482, -0.01844344288110733, 0.10525358468294144, -0.3777501881122589, 0.30553582310676575, 0.16805019974708557, -0.05648534372448921, 0.7978999614715576, 0.21663737297058105, 0.5393856763839722, 0.3502529561519623, 0.11086113005876541, 0.06120586767792702, 0.016460547223687172, 0.1303798109292984, -0.7567384243011475, 0.282490074634552, -0.7598562836647034, -0.2679358124732971, 0.17476756870746613, 0.9314571022987366, 0.9614341259002686, 0.23413339257240295, -0.08747822046279907, 0.5641540884971619, 0.7415594458580017, 0.5714573264122009, -0.19500170648097992, -0.44456377625465393, 0.6499718427658081, -0.3219981789588928, -0.21995331346988678, 0.21120896935462952, 0.06469358503818512, -0.5010398030281067, -0.21651022136211395, 0.2508752644062042, 0.37470972537994385, -0.5252909660339355, -0.7992571592330933, 0.9182665944099426, -0.11761415004730225, -0.990680992603302, -0.49984392523765564, -1.1015629768371582, -0.032364487648010254, 0.4686849117279053, -1.9169610738754272, -0.9675358533859253, 0.8018584251403809, -0.4876551330089569, -0.6943162679672241, 0.3362738788127899, 1.4636120796203613, 0.34007397294044495, -0.3739052712917328, 0.15075580775737762, 1.1175504922866821, 0.517846405506134, 0.5090290904045105, -1.0579266548156738, 0.4805741310119629, 0.08757123351097107, -0.017041031271219254, 0.5209335684776306, -0.29763397574424744, -0.02960536628961563, -0.4263308346271515, -0.3074580430984497, 0.6573045253753662, -1.354523777961731, -0.4797775447368622, -0.7966091632843018, -0.8090804815292358, 0.3427509665489197, 0.5918068885803223, -0.06453447788953781, 0.7541055679321289, 0.3280979096889496, -0.4538653492927551, -0.023074481636285782, -1.123353123664856, 0.6256721615791321, 0.5675395727157593, -0.7858881950378418, -0.5898412466049194, 0.36570048332214355, 0.7131546139717102, -1.0448408126831055, -0.9581272006034851, -0.11551056802272797, 0.41350701451301575, 0.07464360445737839, 1.1925626993179321, -0.4320885241031647, 0.6382272243499756, 0.8865687847137451, -0.3821983337402344, -0.552475094795227, 0.2963983416557312, -0.9239442944526672, -0.3004302978515625, 0.1197252944111824, 1.1971838474273682, -0.28414294123649597, 0.6230440139770508, 1.243891716003418, 0.38725540041923523, -0.8483865261077881, -0.7676842212677002, -0.6887114644050598, 0.20450617372989655, -0.2962033450603485, 0.5608994960784912, 0.36783653497695923, 0.2671279311180115, -0.008081420324742794, 0.5300968885421753, 0.7417135238647461, -0.28484705090522766, -0.45241954922676086, 0.09076610952615738, 0.030275005847215652, 0.09763520956039429, -0.30189040303230286, -0.229180708527565, -1.1384543180465698, 0.1843407154083252, -1.1906940937042236, -0.24913299083709717, -1.025150179862976, -0.8840566277503967, -0.4205334484577179, -0.3772454261779785, 0.13850949704647064, 0.33258911967277527, -0.22369800508022308, -0.4924154579639435, -0.2545360028743744, -0.29955151677131653, 0.5973209738731384, 0.828931450843811, -0.7554997801780701, -0.17365533113479614, -0.032087650150060654, 0.31166401505470276, -0.07275495678186417, 0.38305968046188354, -0.29604098200798035, -0.6362354755401611, -1.4114148616790771, 0.7112852931022644, -0.02129746973514557, -0.23391035199165344, -0.14963066577911377, 0.5742376446723938, 0.3816278874874115, -0.06242220103740692, -0.24456936120986938, 0.5778388381004333, -1.0816031694412231, -0.7837936282157898, -0.18551135063171387, -0.8980929851531982, 0.16857895255088806, 0.0015072827227413654, -0.43572887778282166, -0.3572740852832794, 0.26231712102890015, -0.7489712238311768, -0.744506299495697, -0.7454150915145874, 0.3343863785266876, -0.19048166275024414, -0.20048829913139343, -0.3871990442276001, -0.3292820155620575, -1.3750178813934326, -0.04854486882686615, -0.3568962514400482, 0.592684268951416, -0.14057403802871704, 0.6887515187263489, 0.5744303464889526, -1.4278134107589722, -0.1877305656671524, -0.09427410364151001, 0.15923160314559937, -0.0423177033662796, 0.47424620389938354, 0.054536040872335434, -0.06224983185529709, 0.6368200182914734, 0.5867019891738892, 0.345636248588562, -1.2959771156311035, 0.11247848719358444, 0.09300628304481506, -0.711978018283844, -0.04437455162405968, 0.9044808149337769, -1.0016932487487793, -1.1477149724960327, 0.010237292386591434, -1.3426564931869507, -0.7659846544265747, -0.04512834921479225, 0.6749599575996399, 0.15860936045646667, -0.1833788901567459, -0.14970815181732178, -0.43316584825515747, 0.15670469403266907, -0.2918388247489929, -0.7873699069023132, 0.7453773021697998, -0.2271067500114441, -0.4358338713645935, 0.3194259703159332, 0.9342461228370667, -0.4504622519016266, -0.6171460747718811, -0.8539133667945862, -0.0063103800639510155, -0.48627862334251404, 0.17747192084789276, -0.8168826103210449, 0.3415254056453705, 0.37757256627082825, 0.3994697034358978, 0.44024190306663513, -0.05746196582913399, -0.069949671626091, 0.51642906665802, 1.1745407581329346, -0.11959961801767349, -0.7563056945800781, -0.4852180778980255, 1.0723131895065308, 1.5741829872131348, -1.1909542083740234, 0.5323925018310547, 0.1541747897863388, -0.6886062026023865, 0.5967390537261963, 0.13557855784893036, 0.4692082405090332, 0.8205664157867432, -0.5602901577949524, 0.3467666804790497, 0.30419498682022095, -1.006962537765503, -0.03863554447889328, 1.1061511039733887, 0.9124007225036621, 0.5812280774116516, 0.31386637687683105, -0.055549897253513336, 0.6872768998146057, 0.17319351434707642, -0.03797437623143196, 0.27923911809921265, 0.6756424903869629, -0.1191275492310524, -0.6792013645172119, -0.04711071401834488, 0.4482618570327759, -0.7405017614364624, -0.7045052647590637, -0.20838430523872375, 0.7476598024368286, 0.22396664321422577, 0.5292021632194519, 0.3542541563510895, 0.07575998455286026, 0.36996936798095703, 0.3489867150783539, 0.19101372361183167, -0.6934592127799988, -0.29815053939819336, -0.3554914593696594, -0.3728010952472687, 0.11281254887580872, -0.07937085628509521, -0.5711184144020081, -0.35194826126098633, -0.0539032407104969, -0.03916878625750542, 0.4209389090538025, 0.6238653659820557, 0.815886914730072, 0.8704504370689392, -0.15031500160694122, -0.31943994760513306, -0.3334592282772064, -0.48383158445358276, -1.1455583572387695, -0.1973579227924347, -0.5285377502441406, -0.14011235535144806, -0.014749553985893726, -0.002953389659523964, -0.5995315909385681]}, "authors": [{"authorId": "2116276849", "name": "Dawei Zhu"}, {"authorId": "145769448", "name": "Liang Wang"}, {"authorId": "2242947624", "name": "Nan Yang"}, {"authorId": "2183730942", "name": "Yifan Song"}, {"authorId": "2139644141", "name": "Wenhao Wu"}, {"authorId": "2257346447", "name": "Furu Wei"}, {"authorId": "2257095532", "name": "Sujian Li"}], "references": [{"paperId": "7b0f35b63637a6b308da104ff5065e0fa22090f1", "title": "Dwell in the Beginning: How Language Models Embed Long Documents for Dense Retrieval"}, {"paperId": "b842b83a7ff5dff8e3b83915d8c15423b6085728", "title": "Gemma: Open Models Based on Gemini Research and Technology"}, {"paperId": "f016f079ee63a0487756f895c1d93ff0110d3ecd", "title": "Resonance RoPE: Improving Context Length Generalization of Large Language Models"}, {"paperId": "cf7ab5df804575bad88a9fcf0fbf7707bf500944", "title": "Training-Free Long-Context Scaling of Large Language Models"}, {"paperId": "2330035c7586a0dc0b1f09e9c00106b295acf543", "title": "Long-Context Language Modeling with Parallel Context Encoding"}, {"paperId": "c9603ec967879c24973b5bd48861df2e5555932e", "title": "LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens"}, {"paperId": "0e8176ecced2a01ca3c7dc31e8a3f72d0a7d3767", "title": "Generative Representational Instruction Tuning"}, {"paperId": "f288e2238ac8725baa7ca9874bbc3fed1e89a632", "title": "Data Engineering for Scaling Language Models to 128K Context"}, {"paperId": "63e365b1f1e7c053e3dbe540c33a8348fa079e54", "title": "Benchmarking and Building Long-Context Retrieval Models with LoCo and M2-BERT"}, {"paperId": "26e13e1da4f47c93c9ad0daf9cc9e2bb4ffd063d", "title": "InfLLM: Training-Free Long-Context Extrapolation for LLMs with an Efficient Context Memory"}, {"paperId": "4d5735c186ddb2430ac9689ccf61fdcbbfc23abc", "title": "BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation"}, {"paperId": "03bdd9cbb3b768ff3e96c97b28e106748b6e4fd0", "title": "Nomic Embed: Training a Reproducible Long Context Text Embedder"}, {"paperId": "0595dac8260443365dfbe4821787419736baaa66", "title": "Extending LLMs' Context Window with 100 Samples"}, {"paperId": "2b8439f319dfa73df62ca8957ff6d0c1f3c7a73c", "title": "Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon"}, {"paperId": "a9468d8bfa6bd016dfd3128c4e8408e30eb8549b", "title": "LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning"}, {"paperId": "88ca4ee548d07263386ca8e4effc4a001bb2716f", "title": "Improving Text Embeddings with Large Language Models"}, {"paperId": "e22ae34ea102a781d0494e115639e8d081bf6920", "title": "Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents"}, {"paperId": "2392b6d3a5cad9e5cf349169eaeee848266adf6a", "title": "LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models"}, {"paperId": "5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0", "title": "Qwen Technical Report"}, {"paperId": "5e0cb1c4b91a7486e1c2b15a44a0be56bd74bdc0", "title": "Effective Long-Context Scaling of Foundation Models"}, {"paperId": "73290ecbec2f38d1d647ddef1ada69cee41725b3", "title": "PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training"}, {"paperId": "819bbdc2dac9e13d9ca3e2508a6e063186ce5e40", "title": "YaRN: Efficient Context Window Extension of Large Language Models"}, {"paperId": "b31a5884a8ebe96b6300839b28608b97f8f8ef76", "title": "LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding"}, {"paperId": "84109e1235b725f4bb44a54bab8b493bd723fdd3", "title": "Towards General Text Embeddings with Multi-stage Contrastive Learning"}, {"paperId": "60b0476a97c00e355df28ba35422764a7fbe88e8", "title": "In-context Autoencoder for Context Compression in a Large Language Model"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "80980cd10d19f021c14a6b7eee871b6a5d328024", "title": "Augmenting Language Models with Long-Term Memory"}, {"paperId": "af385c0fdd0eda2bbf429bea6fedffc327c8a180", "title": "Randomized Positional Encodings Boost Length Generalization of Transformers"}, {"paperId": "60b35c6d68acced19b0c66edcfc0ee0a2c11efed", "title": "Landmark Attention: Random-Access Infinite Context Length for Transformers"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "980e55d9226cac302d0fae7732da4e67b8bc952c", "title": "Parallel Context Windows for Large Language Models"}, {"paperId": "5a3c1afe73d8bcc8288d17cb17be2baec8a98464", "title": "Text Embeddings by Weakly-Supervised Contrastive Pre-training"}, {"paperId": "88a74e972898de887ad9587d4c87c3a9f03f1dc5", "title": "MTEB: Massive Text Embedding Benchmark"}, {"paperId": "4dd9836b65c5694f6796159177fda6c7f594ab5f", "title": "SimLM: Pre-training with Representation Bottleneck for Dense Passage Retrieval"}, {"paperId": "d3dd80269f2542cc173afb3a1df24b582a1e4af2", "title": "Overcoming a Theoretical Limitation of Self-Attention"}, {"paperId": "6d7d4fca9840504f630e9bea6acaa07322a6e889", "title": "Text and Code Embeddings by Contrastive Pre-Training"}, {"paperId": "6281c40c66febca1d8003bcc6fdfd2189b30c38f", "title": "SCROLLS: Standardized CompaRison Over Long Language Sequences"}, {"paperId": "9f2cf7b35224aad3a8d261e4456fe2d65a5f5d3e", "title": "Large Dual Encoders Are Generalizable Retrievers"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "c26759e6c701201af2f62f7ee4eb68742b5bf085", "title": "SimCSE: Simple Contrastive Learning of Sentence Embeddings"}, {"paperId": "807600ef43073cd9c59d4208ee710e90cf14efa8", "title": "BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models"}, {"paperId": "43eee0596facea9faf72e3ab3a734d32a6aa82f1", "title": "SummScreen: A Dataset for Abstractive Screenplay Summarization"}, {"paperId": "aa28873534c24e4a8c5deb7bff723cd5fc69a6f0", "title": "QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization"}, {"paperId": "9001eb3c3d5a96ad3d804410c2437e6f60feade9", "title": "Constructing A Multi-hop QA Dataset for Comprehensive Evaluation of Reasoning Steps"}, {"paperId": "b26f2037f769d5ffc5f7bdcec2de8da28ec14bee", "title": "Dense Passage Retrieval for Open-Domain Question Answering"}, {"paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0", "title": "Natural Questions: A Benchmark for Question Answering Research"}, {"paperId": "7a84a692327534fd227fa1e07fcb3816b633c591", "title": "Neural Tangent Kernel: Convergence and Generalization in Neural Networks"}, {"paperId": "d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a", "title": "The NarrativeQA Reading Comprehension Challenge"}, {"paperId": "dd95f96e3322dcaee9b1e3f7871ecc3ebcd51bfe", "title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset"}, {"paperId": "f6b51c8753a871dc94ff32152c00c01e94f90f09", "title": "Efficient Estimation of Word Representations in Vector Space"}, {"paperId": "164125a65d42a791d2c1e108559344caef96d08b", "title": "Indexing by Latent Semantic Analysis"}, {"paperId": "2ff694e20f492a7acf7fd0646c5e1576f0b3c901", "title": "C-Pack: Packaged Resources To Advance General Chinese Embedding"}, {"paperId": "5a37124345d0fb44ac1b4809dda85bf61ab79564", "title": "Towards Unsupervised Dense Information Retrieval with Contrastive Learning"}, {"paperId": null, "title": "Understanding attention scaling from the perspective of entropy invariance"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Ntk-aware scaled rope allows llama models to have extended (8k+) context size without any fine-tuning and minimal perplexity degradation"}, {"paperId": null, "title": "Needle in a haystack - pressure testing"}]}