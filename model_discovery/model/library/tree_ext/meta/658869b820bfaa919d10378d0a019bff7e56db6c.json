{"paperId": "658869b820bfaa919d10378d0a019bff7e56db6c", "title": "Chunk, Align, Select: A Simple Long-sequence Processing Method for Transformers", "abstract": "Although dominant in natural language processing, transformer-based models remain challenged by the task of long-sequence processing, because the computational cost of self-attention operations in transformers swells quadratically with the input sequence length. To alleviate the complexity of long-sequence processing, we propose a simple framework to enable the offthe-shelf pre-trained transformers to process much longer sequences, while the computation and memory costs remain growing linearly with the input sequence lengths. More specifically, our method divides each long-sequence input into a batch of chunks, then aligns the interchunk information during the encoding steps, and finally selects the most representative hidden states from the encoder for the decoding process. To extract inter-chunk semantic information, we align the start and end token embeddings among chunks in each encoding transformer block. To learn an effective hidden selection policy, we design a dual updating scheme inspired by reinforcement learning, which regards the decoders of transformers as environments, and the downstream performance metrics as the rewards to evaluate the hidden selection actions. Our empirical results on real-world long-text summarization and reading comprehension tasks demonstrate effective improvements compared to prior longsequence processing baselines.", "venue": "arXiv.org", "year": 2023, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2308.13191", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes a simple framework to enable the offthe-shelf pre-trained transformers to process much longer sequences, while the computation and memory costs remain growing linearly with the input sequence lengths."}, "embedding": {"model": "specter_v2", "vector": [0.39538517594337463, 0.6633388996124268, -0.5554854869842529, -0.16111639142036438, -0.396039754152298, -0.3708265423774719, 0.5955296158790588, 0.3359917402267456, -0.37333977222442627, -0.04426608607172966, 1.1649563312530518, 0.217941552400589, 0.3843937814235687, 0.048323195427656174, -0.2959713637828827, 0.003816781332716346, -0.8849074840545654, -0.06642308831214905, 0.14326807856559753, -0.2475012093782425, 0.4017675220966339, -0.954639732837677, -0.7159982919692993, 0.2114318460226059, 0.8983161449432373, 0.13117867708206177, 0.29555758833885193, 0.6922290325164795, -0.6532262563705444, 0.4027259945869446, 0.1237630546092987, -0.37219080328941345, -0.13034090399742126, -0.28251713514328003, -0.8505796790122986, 0.03703776374459267, 0.5333407521247864, -0.36893677711486816, -0.3495175540447235, 0.9037790298461914, 0.00790518056601286, 0.1353110373020172, 0.3898128271102905, -0.21180559694766998, 0.04745025187730789, 1.3846765756607056, 0.6549487709999084, 0.3304697275161743, 0.1999848335981369, -0.7013899087905884, 1.694835901260376, -1.0934247970581055, 0.21733789145946503, 1.3301974534988403, 0.4257092773914337, 0.04053683206439018, 0.08591791987419128, -0.5046458840370178, 0.9319869875907898, 0.4079975187778473, -0.3823126554489136, -0.6566181778907776, -0.07389785349369049, -0.12057427316904068, 1.940040946006775, -0.256374329328537, 0.5100795030593872, 0.2693193256855011, 0.12024715542793274, 1.83555269241333, -0.3598356544971466, -0.6042835116386414, -0.3791414797306061, -0.5410960912704468, 0.7201585173606873, 0.6615452170372009, -0.4706053137779236, -0.06744324415922165, -1.0855423212051392, 0.19668790698051453, 0.1381234973669052, -0.019731221720576286, -0.03971393033862114, -0.12630441784858704, -0.33980420231819153, 0.26345255970954895, 0.3281796872615814, 0.590143620967865, -0.38342392444610596, 0.439531534910202, 1.0375478267669678, 0.3322964012622833, 0.4826648235321045, 0.551618754863739, -0.015627119690179825, 0.1779080629348755, -1.0013599395751953, 0.17397978901863098, -0.18490268290042877, 0.6456097960472107, -0.056421421468257904, 0.46540433168411255, -1.0693703889846802, 0.5812363028526306, 1.148451328277588, 0.1677844226360321, 0.49620819091796875, -0.6530733108520508, 0.2545416057109833, -0.6459169387817383, 0.3776128888130188, -0.5627580285072327, -0.20485790073871613, -0.36016952991485596, -0.6463961601257324, -1.2366299629211426, -0.31733959913253784, 0.24894149601459503, -0.4571196734905243, 0.7514322400093079, -0.1875104308128357, 0.40568462014198303, 0.1359894573688507, 0.22301170229911804, 0.5158575773239136, 0.9681178331375122, 0.32833829522132874, -0.49879953265190125, 1.1149036884307861, -1.0940574407577515, -0.9191827178001404, -0.9267645478248596, 0.8360080718994141, -0.27058252692222595, 0.21598456799983978, -0.00013319822028279305, -1.1884273290634155, -0.9768603444099426, -0.8909263610839844, 0.06556728482246399, -0.20995588600635529, 0.19089730083942413, 0.3836078345775604, 0.11953835934400558, -1.1404542922973633, 1.1112357378005981, -0.20543642342090607, -0.30758339166641235, 0.4285178780555725, -0.19617928564548492, 0.19515617191791534, -0.0778852179646492, -1.434484839439392, 0.5143246054649353, 0.276075541973114, -0.43106839060783386, -0.12033914029598236, -0.6230269074440002, -1.3341113328933716, 0.2428969144821167, 0.39313918352127075, -0.3940368592739105, 1.5102287530899048, -0.10866045951843262, -1.831832766532898, 0.33793750405311584, -0.669135332107544, -0.048181187361478806, 0.03375371918082237, -0.9186330437660217, 0.06658627837896347, -0.2966841459274292, -0.09580616652965546, 0.04118997976183891, 0.5660257339477539, 0.11275076866149902, -0.3005736470222473, 0.0035347160883247852, -0.6920163631439209, 0.35242676734924316, -0.20453684031963348, 0.869458794593811, -0.24339938163757324, -0.36684030294418335, 0.22451914846897125, 1.0817126035690308, 0.2096577286720276, -1.1108636856079102, -0.9786556959152222, -1.5899362564086914, 0.2948126196861267, -0.2059607356786728, 1.227267861366272, -0.8413162231445312, -0.5067148804664612, -0.5755960941314697, -0.13187624514102936, 0.2871302664279938, -0.704908549785614, 0.8738279938697815, -0.2980254590511322, 0.3003215491771698, 0.02512793429195881, -1.1515719890594482, 0.13091957569122314, -0.504956841468811, -0.9834831357002258, -0.01691417768597603, 0.0802873969078064, 1.1290993690490723, -1.336610198020935, 0.14341598749160767, 0.1609281599521637, -0.07829058915376663, -0.626059353351593, 1.4006626605987549, -0.5353104472160339, -0.009456532076001167, -0.23580124974250793, -0.42206743359565735, 0.10634136199951172, -0.3163905441761017, 0.46614742279052734, -0.31291964650154114, -0.3781437873840332, 1.0270214080810547, -0.2742583751678467, 1.4634915590286255, 0.04977928474545479, 0.3627355694770813, -0.5086702108383179, -0.951671838760376, -0.018493125215172768, 0.5158548355102539, -0.06348244100809097, -0.553218424320221, 0.08791714161634445, 0.07885677367448807, -1.0404003858566284, 0.07204180210828781, 1.036872386932373, 0.8818005323410034, -0.5920208096504211, 0.3856556713581085, 0.5387680530548096, -0.041472479701042175, 0.6124770641326904, 0.6827267408370972, 0.7069423198699951, 0.7074338793754578, 0.7905305624008179, 0.1251043677330017, 0.23483844101428986, -0.7032122015953064, 0.17757007479667664, 0.5735645890235901, 0.7393383979797363, 0.7251358032226562, 0.5266552567481995, -0.42271509766578674, -0.5734831690788269, -0.17769864201545715, 1.1134837865829468, 1.5170091390609741, -0.033441897481679916, -0.5458090305328369, -1.0397257804870605, -0.3638472557067871, -0.48449942469596863, 0.2812601625919342, -0.13353866338729858, -0.2140081226825714, -0.5267221331596375, -0.734837532043457, 0.8033681511878967, 0.27473029494285583, 1.265256643295288, -0.6576663851737976, -0.17175160348415375, 0.07695309817790985, -0.18672913312911987, -0.7124883532524109, -0.6788370013237, 0.2032412737607956, -0.4298360347747803, -0.30856695771217346, 0.023450009524822235, -0.1421874463558197, -0.11495183408260345, -0.5033855438232422, 1.1948026418685913, -0.5277478694915771, 0.16620133817195892, 0.11772603541612625, 0.1114717572927475, -0.6021779179573059, -0.47447454929351807, 0.3314514756202698, 0.08827859163284302, -0.13526257872581482, 0.269286572933197, 0.573154866695404, 0.0019344659522175789, -0.3054581880569458, -0.01736539974808693, 0.48910313844680786, 0.23426035046577454, 0.04478956758975983, 0.4833970367908478, -0.2102617472410202, 0.46619266271591187, -1.2787877321243286, 0.8562513589859009, 0.22467190027236938, -0.08777706325054169, 0.5993034839630127, -0.6831717491149902, -0.3002500534057617, 0.5517699718475342, -0.3477821350097656, -0.3120095729827881, -0.9028819799423218, 0.3668602406978607, 0.23084929585456848, -0.40556013584136963, 0.2929159998893738, -0.15055426955223083, 0.7024351358413696, -0.25300055742263794, 0.8746212124824524, 0.38628441095352173, -0.28797003626823425, 0.6163716316223145, -0.5618553161621094, 0.7612723708152771, 0.7641775012016296, 0.03063214011490345, -0.40139010548591614, -0.6281651854515076, -1.0057973861694336, -0.7767412066459656, -0.8162074089050293, -0.1350068598985672, -0.24299021065235138, 0.213492289185524, -0.438924103975296, -0.8029130697250366, 0.5049529075622559, -1.4360324144363403, -0.3612949252128601, -0.060219906270504, -0.5126945972442627, -0.18773648142814636, -0.664176344871521, -1.264228105545044, -0.45314717292785645, -0.9654308557510376, -0.6806676387786865, 0.19904902577400208, 0.11701859533786774, -0.5614045858383179, -0.38175201416015625, 0.29962489008903503, -0.600325345993042, 0.7811535000801086, -0.7097146511077881, 0.48315343260765076, -0.24825364351272583, -0.24625742435455322, 0.18282274901866913, 0.34468874335289, 0.6544934511184692, -0.05691848322749138, 0.05627591162919998, -0.5292084813117981, 0.03382425382733345, -0.45863276720046997, -0.24340592324733734, 0.28504183888435364, 0.737630307674408, 0.6228132843971252, -0.17839069664478302, -0.40319308638572693, 0.12644577026367188, 1.2024997472763062, -0.6678318977355957, 0.35058584809303284, 0.14431212842464447, 1.15671968460083, 0.46469154953956604, -0.007447593379765749, 0.5314773917198181, 0.5701775550842285, 0.2733825743198395, -0.047697629779577255, -0.4032086730003357, -0.06699351966381073, -0.6114702224731445, 0.8485547304153442, 1.950774908065796, 0.4260508716106415, -0.2636365592479706, -0.7463322877883911, 0.8166895508766174, -1.4092140197753906, -1.0617507696151733, 0.46729111671447754, 0.8080913424491882, 0.45327046513557434, -0.6088801622390747, 0.002006896072998643, 0.17151223123073578, 0.3535877466201782, 0.6656472682952881, -0.2510225474834442, -0.6382921934127808, 0.1818552017211914, 0.27508264780044556, 0.1677740216255188, 0.6981093287467957, -0.4087746739387512, 0.9485484957695007, 14.650193214416504, 0.8243841528892517, 0.04964128136634827, 0.3630048930644989, 0.5037365555763245, 0.22572486102581024, -0.35041874647140503, -0.0325644351541996, -1.1322044134140015, 0.05116478353738785, 1.3059028387069702, -0.19121143221855164, 0.4336565136909485, -0.395856112241745, 0.5998198986053467, -0.09582696855068207, -0.6451826691627502, 0.5975632667541504, 0.5682186484336853, -1.2483521699905396, 0.4775419235229492, -0.1400509476661682, 0.03571448102593422, 0.47567322850227356, 0.6350430250167847, 0.6938088536262512, 0.5347832441329956, -0.1770075410604477, 0.7437223196029663, 0.1435823291540146, 0.8435179591178894, -0.18587630987167358, 0.3312489688396454, 0.4189785122871399, -0.9491108059883118, -0.02483779564499855, -0.5598596930503845, -1.1379224061965942, 0.5512856245040894, 0.32785096764564514, -0.5991899967193604, 0.19014759361743927, -0.29300767183303833, 1.4540908336639404, 0.06625057756900787, 0.681011438369751, -0.6768473982810974, 1.1534770727157593, 0.25713416934013367, -0.1943846046924591, 0.35000964999198914, 0.22156716883182526, 0.36138471961021423, 0.27412188053131104, 0.04032000154256821, 0.24489179253578186, 0.29522326588630676, -0.11482937633991241, -0.5132867097854614, 0.17505332827568054, -0.2825068533420563, -0.15409576892852783, 0.42274707555770874, 0.3411344587802887, 0.5500637292861938, -0.24054361879825592, -0.12096968293190002, 0.36569929122924805, 0.6802865862846375, 0.14417558908462524, -0.15842905640602112, -0.5181786417961121, 0.27598822116851807, -0.3633175492286682, -0.011593207716941833, 0.7342826128005981, -0.45423761010169983, -0.5912815928459167, -0.8196031451225281, -0.4209343492984772, 0.16334091126918793, -0.7504790425300598, -0.2966402769088745, 0.522843062877655, -0.1927080601453781, -0.6073681116104126, 0.10250961780548096, -0.26110854744911194, -0.6549715995788574, 0.1944250762462616, -1.3881406784057617, -0.5713456273078918, 0.3565129041671753, -0.4812913239002228, -0.03379642963409424, 0.1502089649438858, 1.017181158065796, -0.23475179076194763, -0.5375690460205078, -0.20127694308757782, 0.3760529160499573, -0.01561791729182005, -0.16649338603019714, -1.2634023427963257, 0.6815400123596191, 0.49863067269325256, -0.30834174156188965, 0.2456558346748352, 0.19425314664840698, 0.11342872679233551, -0.6815594434738159, -0.07577497512102127, 1.0853397846221924, -0.6872951984405518, -0.6008104681968689, -0.5575826168060303, -1.1708974838256836, 0.20416978001594543, 1.0864514112472534, -0.6434634923934937, 0.3553914725780487, 0.2315230816602707, -0.1668023318052292, -0.2385939508676529, -0.4939051568508148, -0.156739741563797, 0.5127066969871521, -0.8352721929550171, -0.5662368535995483, -0.11124791949987411, 0.44978034496307373, -0.8443805575370789, -0.31286734342575073, -0.5331375002861023, -0.07255108654499054, -0.05033298581838608, 0.9243245124816895, -0.19512595236301422, 0.6236006617546082, 0.7627183198928833, 0.46454596519470215, -1.4355982542037964, -0.19954200088977814, -1.275506615638733, 0.35574907064437866, 0.5770360231399536, 0.40003877878189087, -0.5226568579673767, 0.18699994683265686, 0.3605128824710846, 0.1589536815881729, -0.4546315371990204, -0.5723380446434021, -0.2487626075744629, 0.14544929563999176, -0.2886775732040405, 0.29776129126548767, -0.20365649461746216, 0.38184332847595215, 0.29090338945388794, 0.388003945350647, 0.6230618357658386, 0.03780468553304672, -0.5967305302619934, 0.44567784667015076, -0.2179299145936966, 0.4721585214138031, -0.5594826340675354, -0.3158298432826996, -1.7435104846954346, 0.11906056106090546, -1.0549474954605103, 0.24563245475292206, -1.5164240598678589, -0.33305710554122925, 0.37076473236083984, -0.2538962960243225, 0.2717374861240387, -0.055282410234212875, -0.829607367515564, -0.3349328935146332, -0.5731126070022583, -1.237323522567749, 1.1241198778152466, 0.7035423517227173, -0.9015106558799744, -0.05398791283369064, -0.278319388628006, -0.03651794046163559, 0.054865140467882156, 0.5436428785324097, -0.29806995391845703, -0.7764572501182556, -1.301806092262268, 0.21330691874027252, -0.03669474646449089, -0.19290758669376373, -0.288314551115036, 0.43803027272224426, 0.4235598146915436, -0.23887348175048828, -0.29760971665382385, -0.20514015853405, -0.24425968527793884, -0.7168284058570862, 0.43277740478515625, -0.9270952939987183, 0.016998589038848877, -0.046797920018434525, -0.5674731135368347, -0.38735583424568176, 0.9007497429847717, -0.1967460811138153, -0.9733071327209473, -0.7733243107795715, 0.3023664951324463, -0.8765944838523865, 0.31561872363090515, -0.251224547624588, -0.19314292073249817, -1.2126673460006714, -0.3358113169670105, 0.255060613155365, 0.6273244023323059, -0.2100493609905243, 0.7965372204780579, 0.516987144947052, -0.977201521396637, -0.16603271663188934, 0.12343750149011612, -0.4081999659538269, 0.3284095227718353, 0.6606405377388, 0.38415902853012085, -0.18760935962200165, 0.26893186569213867, 0.48947951197624207, 0.1679459661245346, -0.9811909794807434, -0.3101411759853363, 0.5946547985076904, -0.8788087368011475, -0.23106640577316284, 0.8261452317237854, -0.5891863703727722, -0.8532798290252686, 0.1365615725517273, -1.1613770723342896, -0.9817357063293457, -0.07647965103387833, 0.9428611397743225, 0.5077909827232361, -0.4064473807811737, 0.011909333057701588, -0.4659590721130371, 0.1249019131064415, -0.3172476887702942, -0.5326656103134155, 0.9487130641937256, -0.44767680764198303, -0.46678659319877625, 0.7870838642120361, 0.6562445163726807, -0.6409400105476379, -0.6488798260688782, -0.7465295791625977, -0.1475597470998764, -0.07944102585315704, 0.2669820785522461, -0.2957001030445099, -0.28120675683021545, 0.7834584712982178, 0.1920822411775589, 0.52324378490448, 0.09968972951173782, -0.2716982662677765, 0.4096372425556183, 0.5217104554176331, -0.03163331001996994, -0.739835262298584, -0.4078505039215088, 1.5080136060714722, 1.3246445655822754, -0.7357325553894043, 0.41916170716285706, -0.08975100517272949, -0.673990786075592, 0.7641640305519104, 0.16925397515296936, -0.14677169919013977, 0.49294960498809814, -0.6149852871894836, 0.10439220070838928, 0.10547417402267456, -1.0337947607040405, -0.2661483883857727, 0.5141759514808655, 0.9850869178771973, 0.8435132503509521, 0.3250409960746765, 0.1066194400191307, 0.7061864733695984, 0.1291394680738449, -0.020699547603726387, 0.7617715001106262, 0.3027782738208771, -0.4637093245983124, -0.10114983469247818, 0.19064120948314667, 0.7077224850654602, -0.6594179272651672, -0.3012813329696655, 0.15210524201393127, 0.02143864706158638, -0.3033784329891205, 0.6706216931343079, 0.813080370426178, 0.09327317029237747, 0.6393712759017944, 0.1974000632762909, 0.4357977509498596, -0.7945932149887085, -0.6013107299804688, -0.269707053899765, -0.5206905007362366, -0.41245734691619873, -0.35210153460502625, -0.8478460311889648, -0.49673399329185486, 0.015488533303141594, 0.13504484295845032, 0.444286972284317, -0.040276918560266495, 1.469079852104187, 0.6656934022903442, 0.6222028732299805, -0.1492243856191635, -0.7540061473846436, -0.9014237523078918, -1.319411039352417, -0.10082663595676422, -0.19115838408470154, 0.15060916543006897, -0.023436205461621284, 0.14575259387493134, -0.1195860207080841]}, "authors": [{"authorId": "2214868031", "name": "Jiawen Xie"}, {"authorId": "144533942", "name": "Pengyu Cheng"}, {"authorId": "2234083638", "name": "Xiao Liang"}, {"authorId": "2116918591", "name": "Yong Dai"}, {"authorId": "2140321952", "name": "Nan Du"}], "references": [{"paperId": "6bd8f3d617fa0c6e38eb0f042d20bc571dbcea96", "title": "Self-playing Adversarial Language Game Enhances LLM Reasoning"}, {"paperId": "6f6e2e0311589a9af045f6acd00b7dee6d19fce4", "title": "The Impact of Positional Encoding on Length Generalization in Transformers"}, {"paperId": "60b35c6d68acced19b0c66edcfc0ee0a2c11efed", "title": "Landmark Attention: Random-Access Infinite Context Length for Transformers"}, {"paperId": "dbc368bc8b49347dd27679894524fa62f88492c9", "title": "Unlimiformer: Long-Range Transformers with Unlimited Length Input"}, {"paperId": "27d391d65ab42c30dc35595213ba6585633afa5d", "title": "CoLT5: Faster Long-Range Transformers with Conditional Computation"}, {"paperId": "35a3979bc9b680023d6e2bcf29a24d67053d0d86", "title": "Replacing Language Model for Style Transfer"}, {"paperId": "912a39c2e0e4a35747531669cfa952d2c5627729", "title": "Is Reinforcement Learning (Not) for Natural Language Processing?: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization"}, {"paperId": "3b39efe6c91ae432dd35bb79431edb8a6719f906", "title": "Investigating Efficiently Extending Transformers for Long Input Summarization"}, {"paperId": "732e3faec4e5be4d144256f2c379b9dc49f0b227", "title": "Efficient Long-Text Understanding with Short-Text Models"}, {"paperId": "6edccbd83a9aae204785d4821f97855677c33866", "title": "Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling?"}, {"paperId": "4eb45f33446018175e266738be22f4d830ed697e", "title": "Semantic Self-Segmentation for Abstractive Summarization of Long Documents in Low-Resource Regimes"}, {"paperId": "85e3cf70079adb1db8b1b50321a5d336edc1c3fa", "title": "Leveraging Locality in Abstractive Text Summarization"}, {"paperId": "da1d6445b6b64ce9eb4587ba8abbdc490f648ec1", "title": "Training Language Models with Memory Augmentation"}, {"paperId": "81b234a1e6da7bc8131e8585a9455dca5dd68754", "title": "Transkimmer: Transformer Learns to Layer-wise Skim"}, {"paperId": "68cf0b9021f904a765e760291d0c9a509aab0067", "title": "A Multi-Document Coverage Reward for RELAXed Multi-Document Summarization"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "c93fd79856450eba642e9bf848264b362980aab6", "title": "Transformers and the Representation of Biomedical Background Knowledge"}, {"paperId": "6281c40c66febca1d8003bcc6fdfd2189b30c38f", "title": "SCROLLS: Standardized CompaRison Over Long Language Sequences"}, {"paperId": "3c209e0703ffff26231b1145268c935df494631a", "title": "QuALITY: Question Answering with Long Input Texts, Yes!"}, {"paperId": "3dfb1f50f2a34a699c339dabaa6f9b3a977973de", "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences"}, {"paperId": "2d82ee05b132d4681c3bd517afc17d608fe6e525", "title": "Simple Local Attentions Remain Competitive for Long-Context Tasks"}, {"paperId": "274f903041b1a830b37f57929d837c1706e94ec7", "title": "PRIMERA: Pyramid-based Masked Sentence Pre-training for Multi-document Summarization"}, {"paperId": "c600b697700c844cbc85009be70f1cdfeef3593e", "title": "Summ^N: A Multi-Stage Summarization Framework for Long Input Dialogues and Documents"}, {"paperId": "0a41cb292242a82b2b09b3bf23b48349b981a640", "title": "DYLE: Dynamic Latent Extraction for Abstractive Long-Input Summarization"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "a6a7724763d8adba466519489b0b9d209e7f2d15", "title": "BARTScore: Evaluating Generated Text as Text Generation"}, {"paperId": "af679d69fcc1d0fcf0f039aba937853bcb50a8de", "title": "Luna: Linear Unified Nested Attention"}, {"paperId": "42e41ab2211b8ba78e36326ea21e05bd25d92c42", "title": "Efficiently Summarizing Text and Graph Encodings of Multi-Document Clusters"}, {"paperId": "56665fd91f7d05842380fe0f928461d66f10c5de", "title": "Contrastive Learning for Many-to-many Multilingual Neural Machine Translation"}, {"paperId": "9dc624d7258d1a56117ca720aea953ce46b66b21", "title": "Efficient Attentions for Long Document Summarization"}, {"paperId": "bf80051ca9ae1e76e2bdbdcf44df559e7eb73cb1", "title": "A Practical Survey on Faster and Lighter Transformers"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "c7d1487552f645afc2daa9b8439ab7fa1adc3d5e", "title": "TicketTalk: Toward human-level performance with end-to-end, transaction-based dialog systems"}, {"paperId": "d4e9bf1d5fab52698a3aa48c65b098ea327deea6", "title": "CTRLsum: Towards Generic Controllable Text Summarization"}, {"paperId": "d164fc8d71ca304bbd7833de5d03ad0a5ca32afa", "title": "Multi-document Summarization via Deep Learning Techniques: A Survey"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": null, "title": "Transformers: State-of-the-Art Natural Language Processing"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "0bdccacaf89bc45c3d9a8a8ac1c4e60a741d5b48", "title": "DynE: Dynamic Ensemble Decoding for Multi-Document Summarization"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "63857190aaf5aab1d94b54bb257b7b03b8cb5a50", "title": "GMAT: Global Memory Augmentation for Transformers"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "4fb0a181676a5200bc6e53dea1b770613c164aab", "title": "Leveraging Graph to Improve Abstractive Multi-Document Summarization"}, {"paperId": "19f1ad5c233e8e17b8defa02dd9cc750af16509a", "title": "Recurrent Chunking Mechanisms for Long-Text Machine Reading Comprehension"}, {"paperId": "f0f77fe7fc62ec627db40aa8deb40de06cfe8be4", "title": "Exploring Controllable Text Generation Techniques"}, {"paperId": "dbeeca8466e0c177ec67c60d529899232415ca87", "title": "On Faithfulness and Factuality in Abstractive Summarization"}, {"paperId": "6e6a2fe517b33e1f29d761ae31fb37ddccb9a213", "title": "A Large-Scale Multi-Document Summarization Dataset from the Wikipedia Current Events Portal"}, {"paperId": "cae24695391e7ef8e7d351a8c922b4016fbfbd02", "title": "Spying on Your Neighbors: Fine-grained Probing of Contextual Embeddings for Information about Surrounding Words"}, {"paperId": "4b52fd45a52aa84b2b1bb1c8cf36cc2884d7df7a", "title": "Improved Natural Language Generation via Loss Truncation"}, {"paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d", "title": "ETC: Encoding Long and Structured Inputs in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "361c00b22e29d0816ca896513d2c165e26399821", "title": "Grandmaster level in StarCraft II using multi-agent reinforcement learning"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "320b227027030fc291de2896fc3c6da49d7614be", "title": "Solving Rubik's Cube with a Robot Hand"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "9d7902e834d5d1d35179962c7a5b9d16623b0d39", "title": "How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings"}, {"paperId": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf", "title": "Patient Knowledge Distillation for BERT Model Compression"}, {"paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0", "title": "Natural Questions: A Benchmark for Question Answering Research"}, {"paperId": "1ec5f3b55a90c1b32ad74dbe4423019d006b6bd3", "title": "Reducing Word Omission Errors in Neural Machine Translation: A Contrastive Learning Approach"}, {"paperId": "cc27ec53160d88c25fc5096c0df65536eb780de4", "title": "Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "c41a11c0e9b8b92b4faaf97749841170b760760a", "title": "VideoBERT: A Joint Model for Video and Language Representation Learning"}, {"paperId": "2fe7dba5a58aee5156594b4d78634ecd6c7dcabd", "title": "End-to-End Open-Domain Question Answering with BERTserini"}, {"paperId": "305b2cf37e5dece81e95c92883d5a6e28ac93b22", "title": "Don\u2019t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a", "title": "The NarrativeQA Reading Comprehension Challenge"}, {"paperId": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b", "title": "Proximal Policy Optimization Algorithms"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "2a215755d7548ffc82079ce734c4ac60b62f6f56", "title": "Toward Controlled Generation of Text"}, {"paperId": "5507dc32b368c8afd3b9507e9b5888da7bd7d7cd", "title": "Sequence-to-Sequence Learning as Beam-Search Optimization"}, {"paperId": "f37076f426023241f19cdc2fb0a0fd733a6fa7fa", "title": "Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond"}, {"paperId": "1ac30af5522c7a50ec4d1ee43fd2bd8652a9bd52", "title": "A Neural Attention Model for Abstractive Sentence Summarization"}, {"paperId": "d316c82c12cf4c45f9e85211ef3d1fa62497bff8", "title": "High-Dimensional Continuous Control Using Generalized Advantage Estimation"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "b18833db0de9393d614d511e60821a1504fc6cd1", "title": "A Natural Policy Gradient"}, {"paperId": "93a07b66003f0a11edfde2dc3fc0bdcf1f1e497e", "title": "Discriminative Marginalized Probabilistic Neural Method for Multi-Document Summarization of Medical Literature"}, {"paperId": null, "title": "2023) processes long sequences via short-context PLMs. The origin long sequence is partitioned into overlapping chunks"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "2019a. Multi-news: A large-scale"}, {"paperId": null, "title": "Case Study on GovReport Dataset In addition to using regular automatic evaluation metrics to measure the effect of model generation"}, {"paperId": "ac4af1df88e178386d782705acc159eaa0c3904a", "title": "Actor-Critic Algorithms"}, {"paperId": "df8b633d327a69fee047ebc98fb9bb3a223ae1b3", "title": "The Locality Principle"}, {"paperId": "13167f9cd8c7906ca808b01d28dca6dd951da8a5", "title": "of the Association for Computational Linguistics"}, {"paperId": null, "title": "2022. Chain-of-thought prompting elicits reasoning in large language models"}, {"paperId": null, "title": "2022. Learned token pruning for transformers"}, {"paperId": null, "title": "2023. A length-extrapolatable transformer"}, {"paperId": null, "title": "8602\u20138615, Dublin, Ireland"}, {"paperId": null, "title": "2022. Memorizing transform-13"}, {"paperId": null, "title": "2024b. Adversarial preference optimization: Enhancing your alignment via rm-llm game"}, {"paperId": null, "title": "5657\u20135673, Abu Dhabi, United Arab Emirates"}]}