{"paperId": "ae9e6c36a68302803783f03cd914055b67d2559b", "title": "Improving the Robustness of Transformer-based Large Language Models with Dynamic Attention", "abstract": "Transformer-based models, such as BERT and GPT, have been widely adopted in natural language processing (NLP) due to their exceptional performance. However, recent studies show their vulnerability to textual adversarial attacks where the model's output can be misled by intentionally manipulating the text inputs. Despite various methods that have been proposed to enhance the model's robustness and mitigate this vulnerability, many require heavy consumption resources (e.g., adversarial training) or only provide limited protection (e.g., defensive dropout). In this paper, we propose a novel method called dynamic attention, tailored for the transformer architecture, to enhance the inherent robustness of the model itself against various adversarial attacks. Our method requires no downstream task knowledge and does not incur additional costs. The proposed dynamic attention consists of two modules: (I) attention rectification, which masks or weakens the attention value of the chosen tokens, and (ii) dynamic modeling, which dynamically builds the set of candidate tokens. Extensive experiments demonstrate that dynamic attention significantly mitigates the impact of adversarial attacks, improving up to 33\\% better performance than previous methods against widely-used adversarial attacks. The model-level design of dynamic attention enables it to be easily combined with other defense methods (e.g., adversarial training) to further enhance the model's robustness. Furthermore, we demonstrate that dynamic attention preserves the state-of-the-art robustness space of the original model compared to other dynamic modeling methods.", "venue": "Proceedings 2024 Network and Distributed System Security Symposium", "year": 2023, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://doi.org/10.14722/ndss.2024.24115", "status": "BRONZE"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes a novel method called dynamic attention, tailored for the transformer architecture, to enhance the inherent robustness of the model itself against various adversarial attacks, and demonstrates that dynamic attention preserves the state-of-the-art robustness space of the original model compared to other dynamic modeling methods."}, "embedding": {"model": "specter_v2", "vector": [0.22180315852165222, 0.6697285175323486, -0.19259721040725708, 0.3381931781768799, -0.7880807518959045, -0.6847659349441528, 0.8395281434059143, 0.0251636765897274, -0.25533294677734375, -0.47033631801605225, 0.45919445157051086, -0.09290722757577896, 0.44254258275032043, 0.0375564843416214, -0.47903186082839966, 0.016763873398303986, -0.4836236834526062, 0.5953011512756348, 0.14475734531879425, -0.5292285084724426, -0.29734712839126587, -0.6057202816009521, -0.27301663160324097, 0.23450453579425812, 0.48009082674980164, 0.37279343605041504, 0.031388070434331894, 0.6971327662467957, -0.26560142636299133, 0.25136807560920715, 0.26378926634788513, -0.7283961772918701, 0.3302188515663147, 0.36264708638191223, -0.3073124885559082, -0.1431635469198227, 0.2411072701215744, -0.3004789352416992, -0.874789297580719, 0.9811599850654602, -0.21576589345932007, 0.2941560745239258, 0.312862366437912, -0.6659032106399536, -0.8550527691841125, 1.3259687423706055, 0.4321610629558563, 1.189440131187439, -0.2232310026884079, -0.6581740975379944, 1.3395435810089111, -1.283403754234314, 0.08681420236825943, 1.7412927150726318, 0.3388494551181793, 0.4831795394420624, -0.25471165776252747, -0.7971675992012024, 0.9577219486236572, 0.2149733006954193, -0.7371368408203125, -0.14465397596359253, 0.20841239392757416, 0.024725057184696198, 1.7713119983673096, -0.42192506790161133, -0.25875043869018555, 0.6173596382141113, -0.013651165179908276, 1.7118914127349854, -0.3948294520378113, -0.8092705011367798, -0.8080136179924011, -0.012818373739719391, 0.11079663783311844, 0.7543029189109802, -0.5402950644493103, 0.22732113301753998, -0.6814558506011963, -0.19803576171398163, 0.06516250222921371, -0.17682693898677826, -0.07116256654262543, 0.05047355964779854, 0.10413292795419693, 0.9336512088775635, 0.23085133731365204, 0.8710900545120239, -0.10529673844575882, 0.8001749515533447, 0.6401530504226685, 0.4152494966983795, 0.15241573750972748, 0.44336482882499695, -0.09748712182044983, 0.4407626986503601, -0.7742507457733154, 0.3325652778148651, -0.14910903573036194, 0.854182243347168, -0.626292884349823, 0.5613563060760498, -1.0185610055923462, 0.029802704229950905, 1.1192524433135986, 0.48500266671180725, 0.4149479269981384, -0.18071332573890686, 0.5477976202964783, -0.9051885604858398, -0.10172475129365921, -0.9074689745903015, 0.2212783545255661, -0.013561778701841831, -0.6233920454978943, -1.33328115940094, -0.09737171977758408, 0.1851184219121933, -1.086646318435669, 0.7955498695373535, -0.4713298976421356, -0.1507033407688141, -0.2014489620923996, -0.19793419539928436, 0.43702757358551025, 0.7553808093070984, 0.3728335499763489, 0.14059887826442719, 1.0303415060043335, -0.3890964686870575, -0.6953558921813965, -1.027514100074768, 0.6282572746276855, -0.4434574842453003, 0.10535945743322372, -0.2400757074356079, -1.3413527011871338, -0.506420910358429, -0.5487454533576965, -0.02180606499314308, -0.6577203869819641, -0.07894031703472137, 0.37161415815353394, 0.6625118255615234, -0.8406357169151306, 0.5538464784622192, -0.3049946427345276, 0.07314431667327881, 0.6466981768608093, 0.27867865562438965, 0.30233341455459595, -0.3773154318332672, -1.8583877086639404, 0.45622581243515015, 0.5181514024734497, -0.6627129912376404, -0.34183722734451294, -0.7176530361175537, -1.1700161695480347, 0.20144516229629517, 0.2780240476131439, -0.1596095860004425, 1.2344651222229004, 0.12315962463617325, -1.0670835971832275, 0.5875518321990967, -0.5766371488571167, -0.14807677268981934, 0.26347023248672485, -0.23655225336551666, -0.1817886382341385, -0.5823401212692261, -0.14423935115337372, 0.14418326318264008, 0.6865674257278442, -0.11285929381847382, -0.008012216538190842, 0.3672337532043457, -0.16748541593551636, -0.4259243607521057, -0.5773864984512329, 1.0999494791030884, -0.24151857197284698, -0.6196220517158508, 0.21612320840358734, 0.6856074929237366, 0.14147375524044037, -0.5517230033874512, -0.6048587560653687, -1.2235816717147827, 1.1492292881011963, -0.3392302095890045, 0.9207693934440613, -0.8376500606536865, -0.6022840142250061, -0.08189123868942261, -0.043375011533498764, 0.18299371004104614, -0.7960616946220398, 0.979486882686615, -0.6381272077560425, 0.9227122664451599, 0.2126069962978363, -1.2428644895553589, 0.22753138840198517, -0.48433250188827515, -1.0306178331375122, -0.12639546394348145, 0.29065394401550293, 1.4517446756362915, -0.7795990109443665, 0.28524431586265564, 0.12903834879398346, 0.27384284138679504, -0.956184983253479, 1.1323719024658203, -0.4487341642379761, 0.28403449058532715, -0.32332858443260193, 0.11147677898406982, 0.15061596035957336, 0.12963540852069855, 0.09796567261219025, -0.35372447967529297, 0.08119112998247147, 0.5509390234947205, 0.07808610051870346, 0.8543372750282288, -0.24942852556705475, 0.5567447543144226, -0.27469512820243835, -1.0446865558624268, 0.06477183848619461, 0.7301851511001587, -0.18333537876605988, -0.3794495463371277, 0.6178370714187622, 0.17640230059623718, -0.6483299732208252, 0.3783264458179474, 0.7795427441596985, 0.5884153842926025, -0.4841573238372803, 0.16181185841560364, 0.41612330079078674, -0.36689046025276184, 0.5823075175285339, 0.5188961029052734, 0.7199374437332153, 0.20934255421161652, 0.28632453083992004, 0.07073336094617844, 0.37332314252853394, -0.8472620844841003, -0.03404422476887703, 0.5569616556167603, 0.6604799032211304, 0.7441384792327881, 0.7508177757263184, -0.5975393056869507, -0.3565426766872406, 0.013971014879643917, 0.6659780144691467, 1.5443476438522339, -0.4145159423351288, -0.3532801866531372, -0.5093105435371399, -0.4906066954135895, -0.23420099914073944, 0.07813167572021484, -0.6064322590827942, -0.5412044525146484, -0.5525992512702942, -1.2504569292068481, 1.209946870803833, 0.22624091804027557, 0.7037375569343567, -0.5551205277442932, -0.003923751413822174, -0.05971072241663933, -0.1805562973022461, -0.9322783946990967, -0.7383577823638916, 0.41717925667762756, -0.273336797952652, -0.10786337405443192, 0.3756624162197113, 0.048475395888090134, 0.05693461000919342, -0.8002073168754578, 0.7286777496337891, -0.6237131953239441, -0.11101546138525009, 0.15600676834583282, 0.27244091033935547, -1.0520026683807373, -1.1489720344543457, 0.3120326101779938, 0.06337670981884003, -0.17241132259368896, 0.3061302602291107, 0.6005086302757263, 0.5719430446624756, 0.039112288504838943, -0.7832096815109253, -0.635999321937561, -0.05233054235577583, 0.4266112148761749, 0.5491011738777161, -0.002322080312296748, -0.26394709944725037, -1.3610721826553345, 0.9108522534370422, 0.15789462625980377, -0.643019437789917, 0.36597511172294617, -0.28832942247390747, -0.21015840768814087, 0.844162106513977, -1.0177158117294312, -0.32378315925598145, -0.9314045906066895, 0.12295591831207275, -0.5214346051216125, 0.3352575898170471, 0.5399655103683472, -0.12611031532287598, 0.06292472034692764, 0.17146655917167664, 0.6665985584259033, 0.09528974443674088, -0.21340779960155487, 0.538447380065918, -1.2118782997131348, 0.32365909218788147, 0.11660376936197281, 0.737390398979187, -0.11530448496341705, -0.30823782086372375, -0.625508189201355, -0.40032729506492615, -0.0652245357632637, -0.14303012192249298, -0.13515622913837433, -0.2770242393016815, -0.33014413714408875, -0.9327739477157593, 0.36136186122894287, -1.0258657932281494, -0.07759898155927658, -0.05694664269685745, -0.5978944897651672, -0.002485286444425583, -0.8912221193313599, -1.491959571838379, -0.4861391484737396, -0.6768471002578735, -0.8972129821777344, 0.34597253799438477, 0.14567877352237701, -0.21887074410915375, -0.8549548983573914, -0.2852763831615448, -0.2587927281856537, 1.0524649620056152, -0.23497635126113892, 1.1869338750839233, -0.5104109048843384, -0.3282650411128998, -0.8010028600692749, 0.4788040518760681, 0.23724213242530823, -0.37868204712867737, 0.45111483335494995, -1.017168641090393, -0.0649237409234047, -0.018848398700356483, -0.23467975854873657, 0.36739489436149597, 0.40529152750968933, 0.6140198707580566, -0.0611560121178627, -0.6821280717849731, 0.4802626073360443, 1.2927205562591553, -0.33908045291900635, 0.10852999240159988, 0.4135044515132904, 1.1574044227600098, 0.11999717354774475, -0.12431911379098892, 0.5012504458427429, 0.12990762293338776, 0.18368825316429138, 0.44655734300613403, -0.09190322458744049, 0.4125770032405853, -0.6631886959075928, 0.5147746205329895, 1.2749605178833008, 0.5160121917724609, -0.7686301469802856, -1.1102670431137085, 0.6894623041152954, -1.0533922910690308, -1.0706557035446167, 0.8374690413475037, 0.5807920694351196, 0.08933352679014206, -0.2815712094306946, -0.6255015730857849, 0.10950789600610733, 0.6454058289527893, 0.5836218595504761, -0.3703208565711975, -0.7530601024627686, 0.07806583493947983, 0.47550177574157715, 0.36075088381767273, 0.623133659362793, -0.8027304410934448, 1.1106990575790405, 14.603529930114746, 1.0277584791183472, -0.05085291340947151, 0.6650599837303162, 0.43774670362472534, 0.2121170312166214, -0.434994101524353, -0.21577991545200348, -1.2535889148712158, -0.32746732234954834, 0.7917714715003967, -0.2994336485862732, 0.5006389021873474, -0.08548255264759064, 0.06260474771261215, 0.4045902192592621, -0.17342501878738403, 0.34565916657447815, 0.8572758436203003, -0.9824228286743164, 0.6060875654220581, 0.2591766119003296, 0.11425841599702835, 0.4813741147518158, 1.033474087715149, 0.8848904967308044, 0.7651985287666321, -0.6190171837806702, 0.6476860046386719, -0.04288363456726074, 0.6678599119186401, -0.2683350145816803, 0.46757322549819946, 0.5762037038803101, -1.1032954454421997, -0.49960681796073914, -0.7153527140617371, -0.8662668466567993, 0.3544956147670746, 0.08884505927562714, -0.4246712923049927, -0.45089587569236755, -0.08175863325595856, 0.8369941115379333, -0.03736579045653343, 0.30886244773864746, -0.39191752672195435, 0.7403789758682251, -0.18638326227664948, 0.3274972140789032, 0.19254980981349945, 0.7899332642555237, 0.7862544059753418, -0.0912821963429451, 0.0381338857114315, -0.07374168932437897, 0.12292816489934921, 0.43161073327064514, -0.8300945162773132, -0.1632450819015503, -0.4411696195602417, -0.5608261823654175, 0.1076149120926857, 0.6539931893348694, 0.3846915662288666, 0.35449013113975525, -0.2576178014278412, 0.1985803097486496, 0.6793018579483032, 0.05427037924528122, -0.36961254477500916, -0.005992640741169453, 0.19582179188728333, -0.12057854980230331, 0.2472672015428543, 0.6622173190116882, 0.02463127113878727, -0.5616013407707214, -0.5185534358024597, -0.5322356224060059, 0.44064098596572876, -0.46110713481903076, -0.7397956848144531, 1.1177172660827637, -0.20605075359344482, -0.2317480742931366, 0.36606091260910034, -0.5387477278709412, -0.2876970171928406, 0.6428278684616089, -1.4144879579544067, -1.0661922693252563, 0.7801465392112732, -0.049363281577825546, -0.34732699394226074, -0.04221628978848457, 1.2739683389663696, -0.03343519940972328, -0.35462456941604614, 0.5506444573402405, 0.4417964518070221, 0.5550915598869324, -0.11368202418088913, -0.775583803653717, 1.2493259906768799, 0.7465184926986694, -0.05348844453692436, 0.1381627470254898, 0.17882196605205536, -0.06510168313980103, -0.648405909538269, -0.21176078915596008, 1.0727828741073608, -1.2085405588150024, -0.16926079988479614, -0.8171007037162781, -1.0659091472625732, 0.5966629981994629, 0.4359224736690521, -0.38254597783088684, 0.08991406112909317, 0.23036758601665497, -0.7506903409957886, 0.07294034212827682, -0.9907583594322205, -0.06189082935452461, 0.024517903104424477, -0.9322119355201721, -0.5127192139625549, -0.031547125428915024, 0.33209228515625, -1.265650987625122, -0.45822829008102417, -0.36531388759613037, -0.03453535586595535, 0.42507684230804443, 1.1118308305740356, -0.44653308391571045, 0.5400785803794861, 1.028151035308838, -0.03284873440861702, -0.831566333770752, -0.33783191442489624, -1.0202882289886475, 0.229047954082489, 0.7250237464904785, 0.4419628977775574, -0.5207396745681763, 0.033113036304712296, 1.1634016036987305, 0.2466937005519867, -0.1024501845240593, -0.761850893497467, -0.32650047540664673, 0.6065959334373474, -0.5506303310394287, 0.1900448352098465, -0.052533335983753204, -0.006885251495987177, -0.34824761748313904, 0.11359552294015884, 0.935147762298584, -0.45407363772392273, -0.8752334117889404, 0.20974940061569214, -0.16786420345306396, 0.190466046333313, -0.37449315190315247, -0.5684312582015991, -1.098510503768921, 0.41216588020324707, -1.2173103094100952, -0.04621655121445656, -0.922507107257843, -0.5152846574783325, 0.35969799757003784, -0.16338922083377838, 0.36571240425109863, 0.19150422513484955, -0.2875954806804657, -0.041735921055078506, -0.614936888217926, -0.017882945016026497, 0.8634952902793884, 0.6204566955566406, -1.0809887647628784, 0.086671844124794, 0.33537402749061584, -0.05229983478784561, 0.24537293612957, 0.42914706468582153, -0.9891964197158813, -0.5374037027359009, -1.5452057123184204, 0.04373590648174286, -0.29040688276290894, -0.13324594497680664, -0.3252488076686859, 0.6627424359321594, 0.36374619603157043, -0.15919548273086548, 0.17781461775302887, 0.4371139407157898, -1.1003388166427612, -0.7847480773925781, 0.5009663105010986, -0.6681615710258484, 0.4487425684928894, 0.5677836537361145, -0.49647676944732666, -0.596713662147522, 0.6925696134567261, 0.14266060292720795, -1.1457818746566772, -0.21088682115077972, 0.8484227061271667, -1.1766444444656372, 0.4579874575138092, -0.16974806785583496, -0.032535724341869354, -1.1705611944198608, -0.5371445417404175, 0.002107061678543687, 0.44358906149864197, -0.5029944777488708, 1.121206283569336, 0.21896643936634064, -0.884580671787262, -0.05525389313697815, 0.515140175819397, -0.16408933699131012, -0.04090262949466705, 0.428728848695755, 0.24280203878879547, -0.1763567328453064, 0.6219178438186646, 0.44711869955062866, 0.5009898543357849, -1.2710367441177368, 0.2675706744194031, 0.8665204644203186, -0.9093416929244995, -0.31551873683929443, 1.290307641029358, -0.08704545348882675, -0.9557165503501892, 0.1171928271651268, -1.125264286994934, -0.7029382586479187, -0.018574250862002373, 0.5756812691688538, 0.0006619546911679208, -0.16217835247516632, -0.3677600622177124, -0.49088454246520996, 0.036662276834249496, -0.2769588828086853, -0.5733915567398071, 0.4600091576576233, -0.26520609855651855, -0.42231541872024536, 0.2688378095626831, 0.47800201177597046, -0.42287689447402954, -0.462172269821167, -1.0997662544250488, -0.3364565968513489, -0.27908727526664734, 0.31008389592170715, -0.18896549940109253, -0.7725853323936462, 0.9133644700050354, 0.1697690635919571, 0.6476046442985535, 0.19988112151622772, -0.38707029819488525, 0.3593059480190277, 0.5713056921958923, -0.13364380598068237, -0.3054697811603546, -0.6544531583786011, 1.9134430885314941, 1.2591173648834229, -0.6714933514595032, -0.025457382202148438, -0.32333165407180786, -0.7705366611480713, 0.8436002135276794, 0.07535756379365921, -0.06607488542795181, 1.0749717950820923, -0.14804355800151825, 0.29660582542419434, 0.4417065978050232, -0.9401901960372925, -0.17717139422893524, 0.8540910482406616, 1.0796897411346436, 0.5394768714904785, 0.004505264572799206, 0.2662560045719147, 0.6482762098312378, 0.22662843763828278, -0.23572342097759247, 0.7740024328231812, 0.38483357429504395, 0.015705620869994164, -0.5674011707305908, -0.43683817982673645, 0.52629554271698, -1.3862638473510742, -0.9587207436561584, -0.2042720764875412, 0.8259824514389038, 0.05013280734419823, 0.8665295243263245, 0.41123563051223755, -0.050087206065654755, 0.6689457297325134, 0.47224804759025574, 0.2478550523519516, -0.6031098961830139, -0.6586243510246277, -0.19534319639205933, -0.9458456635475159, 0.10070311278104782, -0.007373271510004997, -0.6567649245262146, -0.0011359946802258492, -0.5608562231063843, 0.14130055904388428, 0.01841162145137787, -0.032157979905605316, 1.0944926738739014, 0.03802116960287094, 0.4461894631385803, -0.24027462303638458, -0.4288526773452759, -0.15348178148269653, -0.9834100604057312, -0.22681215405464172, -0.5413323044776917, -0.21233542263507843, -0.0001588793529663235, -0.1831352263689041, -0.2825472354888916]}, "authors": [{"authorId": "1382593028", "name": "Lujia Shen"}, {"authorId": "2184142286", "name": "Yuwen Pu"}, {"authorId": "2237797356", "name": "Shouling Ji"}, {"authorId": "2145413923", "name": "Changjiang Li"}, {"authorId": "2261393552", "name": "Xuhong Zhang"}, {"authorId": "2268673949", "name": "Chunpeng Ge"}, {"authorId": "2268737549", "name": "Ting Wang"}], "references": [{"paperId": "34b0e55dcccab464f08b985ccd97984cd9ec7d3b", "title": "Theoretically Principled Trade-off for Stateful Defenses against Query-Based Black-Box Attacks"}, {"paperId": "9cefc046ab8159b190f535f1930f0ff1b9460f76", "title": "Towards a Robust Deep Neural Network Against Adversarial Texts: A Survey"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "a9734c02e8061c409c27f10675010a315111ab7b", "title": "Towards Certifying the Asymmetric Robustness for Neural Networks: Quantification and Applications"}, {"paperId": "0544a341e9dcf1c21fd8d41ebef61d5f813f5292", "title": "Improving the Adversarial Robustness of NLP Models by Information Bottleneck"}, {"paperId": "cd0c9080f3ccc18f74f977d2e237f0bc92e65363", "title": "Gradient Obfuscation Gives a False Sense of Security in Federated Learning"}, {"paperId": "d1c5b5f7f8362f69393810f873f9a995a5fdf8ff", "title": "Strengthening the Transferability of Adversarial Examples Using Advanced Looking Ahead and Self-CutMix"}, {"paperId": "1dd1795f6fa368b61c78c3afccf194bbcf25ed3a", "title": "Why adversarial training can hurt robust accuracy"}, {"paperId": "b6ea568803a46faa8d932149cd54406d6598422a", "title": "A\u00a0ppendix"}, {"paperId": "dea3b07c92017525f443b527824dff502e5ed590", "title": "Backdoor Pre-trained Models Can Transfer to All"}, {"paperId": "f8d55008f360a27251cf6e1898a98f2c74411361", "title": "Better constraints of imperceptibility, better adversarial examples in the text"}, {"paperId": "0972070c1c70c4793282e24a833f7d67e070d794", "title": "Detecting textual adversarial examples through randomized substitution and vote"}, {"paperId": "fa7b8acd47631bada5b66049824bfd335ac6bf8f", "title": "Towards Improving Adversarial Training of NLP Models"}, {"paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"}, {"paperId": "b34eb86ce405739fd3a76ac624637d62b6bf3498", "title": "Combating Word-level Adversarial Text with Robust Adversarial Training"}, {"paperId": "aa9ae8096216163ed40dd787917215b5ae4d3d90", "title": "Adversarial Graph Augmentation to Improve Graph Contrastive Learning"}, {"paperId": "d8d2e574965fe733eb1416e03df2b5c2914fc530", "title": "A Survey of Transformers"}, {"paperId": "9e5dd10d0706cec7d16e03f45f8a347c194d5888", "title": "Improving the Transferability of Adversarial Samples with Adversarial Transformations"}, {"paperId": "2a68b5042e335bb0d5f4ff24ceab6b1d689f0d91", "title": "Dynamic Defense Approach for Adversarial Robustness in Deep Neural Networks via Stochastic Ensemble Smoothed Model"}, {"paperId": "07b65c99f615ad2333eb427a5c3da204725939d9", "title": "Random Noise Defense Against Query-Based Black-Box Attacks"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "275588741254b9c2e7f1048d66c138f8abec02b9", "title": "Fast Certified Robust Training with Short Warmup"}, {"paperId": "a77dd2f328c39fe39be95f5185c555ff68efe5fe", "title": "Detecting Adversarial Examples from Sensitivity Inconsistency of Spatial-Transform Domain"}, {"paperId": "566cac7a6c6b0f38c21bd839ccdd53135b797b7f", "title": "Adversarial Examples Can Be Effective Data Augmentation for Unsupervised Machine Learning"}, {"paperId": "837ac4ed6825502f0460caec45e12e734c85b113", "title": "Dynamic Neural Networks: A Survey"}, {"paperId": "17af9510a38e4dec93398707f11d833c8af36254", "title": "Recent Advances in Adversarial Training for Adversarial Robustness"}, {"paperId": "b3e6ba0d027c92937b12d688a81c1b888102e14b", "title": "On the Effectiveness of Small Input Noise for Defending Against Query-based Black-Box Attacks"}, {"paperId": "35a9749df07a2ab97c51af4d260b095b00da7676", "title": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting"}, {"paperId": "30bd5f9f96e262f0557fe889113f49a8bbdd8f55", "title": "SoK: Certified Robustness for Deep Neural Networks"}, {"paperId": "7b49bcd9fd53158a57d158550461bcb72ac83fbc", "title": "Overview of the Transformer-based Models for NLP Tasks"}, {"paperId": "ae7d635c0a20f739aba3813b9fed114d1f9fce97", "title": "ALONE: A Dataset for Toxic Behavior among Adolescents on Twitter"}, {"paperId": "862b76d28870ed8a1378e5e91ab315ff27852181", "title": "Blacklight: Scalable Defense for Neural Networks against Query-Based Black-Box Attacks"}, {"paperId": "97667dbc4538e97143ba1f8fe257b8e97dfee2de", "title": "Lipschitz Bounds and Provably Robust Training by Laplacian Smoothing"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "5b82d89658b056fdca85bbae994270e3270f941f", "title": "A Hybrid Adversarial Attack for Different Application Scenarios"}, {"paperId": "4916fce2cbfdd23ef46f962bf6fffca39379dc70", "title": "Defense of Word-level Adversarial Attacks via Random Substitution Encoding"}, {"paperId": "2ffcf8352223c95ae8cef4daaec995525ecc926b", "title": "Adversarial Training for Large Neural Language Models"}, {"paperId": "0b55afee245a153f4f10ff5d27419a692ced8c93", "title": "Condition Aware and Revise Transformer for Question Answering"}, {"paperId": "0d5acd9ba016a7d4793d293b11c0057fb2edacd8", "title": "Frequency-Guided Word Substitutions for Detecting Textual Adversarial Examples"}, {"paperId": "d5f3c75ca69d1522cff0cff45fc363f49e66b6f3", "title": "Twitter"}, {"paperId": "ce7ae617528c1cdc2b1efb0010e8a8991e7c90b7", "title": "A Closer Look at Accuracy vs. Robustness"}, {"paperId": "fbf32abd431c70293f1ad1a9b85d4ecbe4e5d6ed", "title": "Adversarial Attacks and Defenses in Deep Learning"}, {"paperId": "6189bf5f4c851ad0217a782509f8818aca4c7ff4", "title": "Robustness Verification for Transformers"}, {"paperId": "ba2cb6a06233ddfb2454e9390ba2c35e72688d4e", "title": "DeT: Defending Against Adversarial Examples via Decreasing Transferability"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "d01fa0311e8e15b8b874b376123530c815f52852", "title": "FreeLB: Enhanced Adversarial Training for Natural Language Understanding"}, {"paperId": "b60a5fcbb085f136c71b6215c4c5f4c287e99f9b", "title": "Learning to Discriminate Perturbations for Blocking Adversarial Attacks in Text Classification"}, {"paperId": "07398e448180ad75c44d30f23a65289d40ff6f52", "title": "Achieving Verified Robustness to Symbol Substitutions via Interval Bound Propagation"}, {"paperId": "ae04f3d011511ad8ed7ffdf9fcfb7f11e6899ca2", "title": "Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment"}, {"paperId": "1adfa30bf112de20cb959014e44626d760aa8e4e", "title": "Generating Natural Language Adversarial Examples through Probability Weighted Word Saliency"}, {"paperId": "c3d846a3c51dc6423381257b95a4b821e778dce0", "title": "Adversarial Training Can Hurt Generalization"}, {"paperId": "bd4336b6015d4d680a27c25a0ed296df5692ddf1", "title": "BadNets: Evaluating Backdooring Attacks on Deep Neural Networks"}, {"paperId": "979f4f67fb97b57c65867ffc92f9fffb9d30e137", "title": "A Research Agenda: Dynamic Models to Defend Against Correlated Attacks"}, {"paperId": "f7f73185e3975bb62a3c42b2ba6bd4db57fee8ed", "title": "Certified Adversarial Robustness via Randomized Smoothing"}, {"paperId": "652107ea8161f607e3bdabc89199e9ff2fdfd015", "title": "Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey"}, {"paperId": "f91175950edf3804ff1573f570b03db9b108dece", "title": "TextBugger: Generating Adversarial Text Against Real-world Applications"}, {"paperId": "09e49c88eefc9ecfd9e2e8dff5141ff6bfeb2747", "title": "Why do Larger Models Generalize Better? A Theoretical Perspective via the XOR Problem"}, {"paperId": "85df5b9fcd85c41ec0e1eb6c1ab15b8d7147c885", "title": "A Statistical Approach to Assessing Neural Network Robustness"}, {"paperId": "98ebd263571748a30eb99d9b9d58bc0519be09ea", "title": "Defensive dropout for hardening deep neural networks under adversarial attacks"}, {"paperId": "2f201c77e7ccdf1f37115e16accac3486a65c03d", "title": "Stochastic Activation Pruning for Robust Adversarial Defense"}, {"paperId": "651adaa058f821a890f2c5d1053d69eb481a8352", "title": "Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples"}, {"paperId": "1e077413b25c4d34945cc2707e17e46ed4fe784a", "title": "Universal Language Model Fine-tuning for Text Classification"}, {"paperId": "fa12574c228542151ccd7d4e3f42cc4896cd274a", "title": "Black-Box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "110150e95aa99b3de8f09fb7e2931c89e3d78f2c", "title": "Towards Robust Detection of Adversarial Examples"}, {"paperId": "1439e05971a053c2368e6dee6d484b43c833d43c", "title": "Crafting adversarial input sequences for recurrent neural networks"}, {"paperId": "51a55df1f023571a7e07e338ee45a3e3d66ef73e", "title": "Character-level Convolutional Networks for Text Classification"}, {"paperId": "bee044c8e8903fb67523c1f8c105ab4718600cdb", "title": "Explaining and Harnessing Adversarial Examples"}, {"paperId": "665f89a20b05472d82df0a12f2dd63e8fcc4f3ea", "title": "Hidden factors and hidden topics: understanding rating dimensions with review text"}, {"paperId": "01d08fa6c229bf3070600e49f8ab05449361817e", "title": "Long-range Sequence Modeling with Predictable Sparse Attention"}, {"paperId": "23756011261f20d411dc4d9bcd3a56b69884a72a", "title": "Flooding-X: Improving BERT\u2019s Resistance to Adversarial Attacks via Loss-Restricted Fine-Tuning"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "6db46c62db8129f6af69037141c95577eb91cf38", "title": "MACROBERT: Maximizing Certified Region of BERT to Adversarial Word Substitutions"}, {"paperId": "2effdadfa3723abfa39db66e844a3c485203849a", "title": "An Empirical Study on Adversarial Attack on NMT: Languages and Positions Matter"}, {"paperId": "7b37c0a4976c4d2a5a440d494fbb0f3daede2a00", "title": "BERxiT: Early Exiting for BERT with Better Fine-Tuning and Extension to Regression"}, {"paperId": "93ad61c5700b3aabbc9192f742fea1a734bcb45b", "title": "TextShield: Robust Text Classification Based on Multimodal Embedding and Neural Machine Translation"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "d0134386fad3e9ad4ae83fc289bdb0fda9caf121", "title": "Fast and Accurate Text Classification: Skimming, Rereading and Early Stopping"}, {"paperId": null, "title": "Universal language model \ufb01ne-tuning for text classi\ufb01cation"}, {"paperId": "09cd7876b72d6105c83db59052572433a0a2b36c", "title": "WIT3: Web Inventory of Transcribed and Translated Talks"}, {"paperId": "7f5ce28afc0c2eafd4a6ef711e399bee4056c3b8", "title": "Spam Filtering with Naive Bayes - Which Naive Bayes?"}, {"paperId": null, "title": "text generation) under multiple attacks (TextBugger [31], TextFooler.[24], PWWS [49])"}, {"paperId": null, "title": "and set \u03b2 = 0 . 4 . Moreover"}, {"paperId": null, "title": "Fig. 9: The overall metric M of the dynamic attention model trained with the Amazon dataset under the pre\ufb01x-tuned model with different m \u2019s range and different \u03b2 value"}]}