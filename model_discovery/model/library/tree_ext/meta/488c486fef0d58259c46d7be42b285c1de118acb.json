{"paperId": "488c486fef0d58259c46d7be42b285c1de118acb", "title": "Long-MIL: Scaling Long Contextual Multiple Instance Learning for Histopathology Whole Slide Image Analysis", "abstract": "Histopathology image analysis is the golden standard of clinical diagnosis for Cancers. In doctors daily routine and computer-aided diagnosis, the Whole Slide Image (WSI) of histopathology tissue is used for analysis. Because of the extremely large scale of resolution, previous methods generally divide the WSI into a large number of patches, then aggregate all patches within a WSI by Multi-Instance Learning (MIL) to make the slide-level prediction when developing computer-aided diagnosis tools. However, most previous WSI-MIL models using global-attention without pairwise interaction and any positional information, or self-attention with absolute position embedding can not well handle shape varying large WSIs, e.g. testing WSIs after model deployment may be larger than training WSIs, since the model development set is always limited due to the difficulty of histopathology WSIs collection. To deal with the problem, in this paper, we propose to amend position embedding for shape varying long-contextual WSI by introducing Linear Bias into Attention, and adapt it from 1-d long sequence into 2-d long-contextual WSI which helps model extrapolate position embedding to unseen or under-fitted positions. We further utilize Flash-Attention module to tackle the computational complexity of Transformer, which also keep full self-attention performance compared to previous attention approximation work. Our method, Long-contextual MIL (Long-MIL) are evaluated on extensive experiments including 4 dataset including WSI classification and survival prediction tasks to validate the superiority on shape varying WSIs. The source code will be open-accessed soon.", "venue": "arXiv.org", "year": 2023, "citationCount": 2, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes to amend position embedding for shape varying long-contextual WSI by introducing Linear Bias into Attention, and adapt it from 1-d long sequence into 2-D long- contextual W SI which helps model extrapolate position embeding to unseen or under-fitted positions."}, "embedding": {"model": "specter_v2", "vector": [0.49366775155067444, 0.7137048840522766, -0.5894212126731873, -0.2767711579799652, -1.1025952100753784, 0.4013809263706207, 0.11521536856889725, -0.11845424771308899, -0.11089866608381271, -0.18682390451431274, 0.6530874967575073, 0.7246509194374084, -0.014434583485126495, 0.19795286655426025, 0.06532495468854904, -0.7263439297676086, -1.2378488779067993, -0.002865865593776107, 0.36810925602912903, -0.004913900978863239, -0.11483276635408401, -0.5468407273292542, -0.6498702168464661, 0.4070418179035187, 0.18295171856880188, 0.6647132039070129, 0.372188925743103, 1.1542319059371948, -0.26210838556289673, 0.008367275819182396, 0.5980159044265747, -0.2011701464653015, 0.4720956087112427, -0.06707731634378433, -0.5336683988571167, 0.4815664291381836, 0.6514132022857666, -0.1266302764415741, -0.38967737555503845, 0.6499935388565063, 0.11117640882730484, 0.08544369786977768, 0.6461141109466553, -0.6908924579620361, -0.22123055160045624, 0.2689223885536194, 0.06796061247587204, 0.6276758909225464, -0.8033722043037415, -0.44964364171028137, 1.515112280845642, -1.0944567918777466, 0.7339414358139038, 1.067825198173523, 0.7135875225067139, 0.417961984872818, 0.16761954128742218, -0.17896269261837006, 0.6173156499862671, 0.3790771961212158, -0.6399608850479126, 0.04947694018483162, 0.18618570268154144, -0.10564744472503662, 1.4182143211364746, -0.3252398371696472, 0.06687512993812561, 0.2844342887401581, 0.544173002243042, 1.459769368171692, -0.1610700786113739, -0.7846037149429321, -0.4513215124607086, -0.0052679916843771935, 0.5195607542991638, 0.9977771639823914, -0.5548666715621948, 0.112145334482193, -0.7431101202964783, 0.13366574048995972, 0.2885027229785919, 0.2899264693260193, 0.45002973079681396, -0.12177736312150955, -0.3721069395542145, -0.20459672808647156, 0.8388984203338623, 0.8572906255722046, -0.10059551894664764, 0.4935145378112793, 0.5397189259529114, 0.17944827675819397, 0.04886768013238907, 0.13606896996498108, 0.11833074688911438, 0.9965775012969971, -0.624038815498352, -0.0798235833644867, -0.6934885382652283, 0.8378954529762268, -0.2535029351711273, -0.44971439242362976, -0.6811208128929138, 0.2468668818473816, 1.0547256469726562, -0.3333348333835602, 0.587902307510376, -0.19342786073684692, 0.01988520659506321, -0.12041742354631424, -0.21851463615894318, -0.9836711883544922, -0.5240319967269897, -0.5951628684997559, -0.9525557160377502, -0.8755834698677063, -0.2843366265296936, 0.6257163882255554, -0.8013870716094971, 0.32551851868629456, 0.10167735069990158, 0.29334595799446106, -0.06178014725446701, 0.5712048411369324, 0.5935747027397156, 0.3057587444782257, 0.4099856913089752, 0.30366960167884827, 1.04017174243927, -1.5153430700302124, -0.33641383051872253, -0.49312886595726013, 0.4596148729324341, 0.05451402813196182, 0.14952552318572998, -0.418359637260437, -0.9524593949317932, -0.9607047438621521, -0.9590738415718079, 0.010445606894791126, -0.7927729487419128, -0.02022644877433777, 0.4902091324329376, -0.4162655770778656, -0.9142927527427673, 0.6265394687652588, -0.36499637365341187, -0.4786713421344757, 0.3530454635620117, -0.1555379331111908, -0.15929967164993286, -0.2811087965965271, -1.350409984588623, 0.055051881819963455, 0.0627208799123764, -0.2768186628818512, -0.39074450731277466, -0.8522345423698425, -0.8577257394790649, -0.08536390215158463, 0.38944995403289795, -0.7331418991088867, 0.9252681732177734, -0.4931085407733917, -0.5237319469451904, 1.1949776411056519, -0.17023923993110657, 0.34111058712005615, 0.6729018688201904, 0.3590596318244934, -0.45379728078842163, -0.1378020942211151, -0.36050963401794434, 0.5716188549995422, 0.3193967640399933, -0.2842789888381958, -0.1928844451904297, -0.16531403362751007, -0.3275690972805023, 0.06409312784671783, -0.3051416575908661, 0.20297475159168243, -0.45707663893699646, -0.1923961341381073, 0.5174663662910461, 0.3870217502117157, -0.519994854927063, 0.33712729811668396, -0.16390594840049744, -0.7489279508590698, 0.8570992350578308, 0.3102838695049286, 0.6849230527877808, -0.8675149083137512, -0.8627203702926636, -0.1307184100151062, -0.08478564023971558, -0.1755967140197754, -1.0690513849258423, 0.2784551680088043, -0.6152586340904236, 0.4364796578884125, -0.07417303323745728, -0.8027656674385071, -0.34941715002059937, -0.3127833604812622, -0.03206072375178337, -0.06641746312379837, 0.26067593693733215, 1.3236716985702515, -1.1016765832901, -0.4628407061100006, -0.14331220090389252, 0.21809028089046478, -0.5913549661636353, 0.7435429096221924, -0.390250563621521, -0.11822287738323212, -0.14930866658687592, 0.4024883210659027, 0.05511479824781418, -0.4789223074913025, 0.43028590083122253, -0.8653956651687622, 0.2012917399406433, 0.1428149789571762, -0.45988914370536804, 1.2150852680206299, -0.05480760708451271, 0.357263445854187, 0.16219106316566467, -0.6265688538551331, -0.16516374051570892, 0.47878289222717285, 0.320882111787796, -0.20377397537231445, 0.13399319350719452, -0.2230302393436432, -0.8309280872344971, -0.5363957285881042, 0.2239924520254135, 0.5761188864707947, -0.13105270266532898, -0.10965059697628021, 0.5659219622612, 0.38774943351745605, 0.03007115051150322, 0.4337742030620575, 0.6244193911552429, 0.15354347229003906, 0.8833297491073608, -0.37397170066833496, 0.35405465960502625, -0.7008078098297119, 0.09447478502988815, 0.4100532829761505, -0.03350534290075302, 1.1001578569412231, 0.4146001935005188, -1.0201101303100586, -0.7441492080688477, 0.3372352123260498, 0.5844994187355042, 1.154584288597107, -0.06401625275611877, -0.04424145445227623, -0.5984741449356079, -1.008284330368042, -0.14808765053749084, -0.855750560760498, -1.0286571979522705, -0.03491653874516487, -0.24478308856487274, -1.291270136833191, 0.40355971455574036, 0.5183936953544617, 0.8855853080749512, -0.7617618441581726, 0.09294463694095612, -0.18136724829673767, 0.11453556269407272, -0.37655410170555115, -0.7859647870063782, 0.3674677610397339, -0.32901012897491455, -0.5052919983863831, -0.2683005630970001, -0.3186028301715851, 0.9060540795326233, -0.15349069237709045, 0.7503120303153992, -0.21514643728733063, -1.2668036222457886, 0.8032466173171997, 0.5551769733428955, -0.7980925440788269, -0.2644738256931305, 0.2553577423095703, -0.4024684429168701, -0.061213575303554535, 0.32389920949935913, 0.5690301060676575, -0.33179667592048645, 0.3344974219799042, -0.6937678456306458, -0.002412129659205675, 0.5997137427330017, 0.8441431522369385, 1.396268367767334, -0.1154518648982048, 0.4484306871891022, -1.3630541563034058, 0.36563223600387573, 0.10581700503826141, -0.18534240126609802, 0.5511605739593506, -0.43086159229278564, -0.5851274132728577, 0.22397160530090332, -0.5001946091651917, -0.12207122892141342, -0.7901830673217773, 0.2813712954521179, -0.4362334907054901, -0.36485129594802856, 0.2288588434457779, 0.047819048166275024, -0.2128244787454605, 0.5760652422904968, 0.19468314945697784, 0.775151252746582, 0.5315327048301697, 0.2772457003593445, -0.9182140827178955, 0.45341792702674866, 0.28913575410842896, -0.0016874582506716251, 0.13360118865966797, 0.5674067139625549, -0.8274344205856323, -0.6981869339942932, -0.9581374526023865, -0.9484636187553406, -0.45207932591438293, 0.33762940764427185, -0.29218077659606934, -0.6320178508758545, 0.14565402269363403, 0.04542842507362366, -0.4049919545650482, 0.23629380762577057, -0.559920608997345, -0.26193293929100037, -1.0351448059082031, -0.8873399496078491, 0.033126238733530045, -0.8127105832099915, -1.0513252019882202, 0.5324896574020386, 0.002530464669689536, -0.19058622419834137, -0.8819639086723328, -0.11749241501092911, -0.18551692366600037, 0.7862739562988281, -0.08668585121631622, 0.702456533908844, -0.141741082072258, -0.514764666557312, -0.7184686064720154, 0.16430485248565674, 0.2732723653316498, 0.4085042178630829, 0.35741323232650757, -0.4378903806209564, 0.3122183680534363, -0.4159660339355469, -0.1795397400856018, 0.4339848458766937, 0.6571787595748901, 1.2026853561401367, 0.22539016604423523, -0.9998034834861755, 0.22796858847141266, 1.5929747819900513, -0.8526530861854553, 0.15556006133556366, 0.0673806443810463, 0.49352729320526123, 0.5487778782844543, 0.39883092045783997, 0.338439404964447, 0.09499239176511765, 0.22220337390899658, 0.5086631774902344, -0.5162833333015442, -0.6048803329467773, -0.08372417837381363, -0.05838262662291527, 1.1902060508728027, 0.35749131441116333, 0.2228909134864807, -1.201442003250122, 1.0982404947280884, -1.031367540359497, -1.1607751846313477, 0.8529295325279236, 0.3580704629421234, 0.00975352618843317, -0.4205966591835022, -0.2414230853319168, -0.4344126582145691, 0.38703587651252747, 0.3903588354587555, -0.4371227025985718, 0.21727649867534637, 0.1256306767463684, -0.02899312600493431, 0.24851153790950775, 0.7391257882118225, -0.7692354917526245, 0.10844150930643082, 14.874178886413574, 0.6739466786384583, -0.21052365005016327, 0.29035684466362, 1.4252263307571411, 0.1654289960861206, -0.12191157042980194, -0.4864659905433655, -1.2463295459747314, -0.02285848930478096, 0.6221411228179932, 0.4660879671573639, -0.056588783860206604, 0.5795493125915527, 0.11285445094108582, 0.19753694534301758, -0.42550837993621826, 0.4796689450740814, 0.9487850666046143, -1.3738306760787964, 0.22629699110984802, 0.0453675277531147, 0.6987554430961609, 0.32159924507141113, 0.9945151209831238, 0.23852574825286865, -0.15760783851146698, -0.3490122854709625, -0.3296239376068115, 0.5467978119850159, 0.912236213684082, 0.0024376108776777983, 0.8652796745300293, 0.06325484067201614, -1.0124188661575317, -0.26958346366882324, -0.7042356729507446, -0.21675345301628113, -0.29097992181777954, 0.30644819140434265, -1.2188812494277954, 0.024891171604394913, -0.0734352171421051, 0.818408727645874, -0.30779558420181274, 0.4288817346096039, 0.13745805621147156, 0.16592592000961304, 0.4977792799472809, 0.09990262240171432, 0.7312666773796082, 0.6853429675102234, 0.20480479300022125, 0.30535250902175903, 0.03135610371828079, 0.39597368240356445, 0.3187224566936493, -0.14240428805351257, -0.23423905670642853, -0.08700446784496307, -0.2744818329811096, 0.2072834074497223, -0.449017733335495, 1.5687530040740967, 0.3114528954029083, 0.27605950832366943, -0.4355774521827698, -0.12235833704471588, 0.53572678565979, -0.08817548304796219, -0.13935445249080658, -0.13374881446361542, 0.4676942229270935, 0.0874951183795929, -0.10298009216785431, 0.7009245753288269, -0.3116663098335266, -0.15719208121299744, -0.8419873118400574, -0.1238253191113472, 0.5939893126487732, -0.8095248937606812, -1.3809113502502441, 1.0173956155776978, -0.4964998960494995, -1.037542462348938, 0.5716124773025513, -1.0875622034072876, -0.5875746607780457, 0.34188103675842285, -1.656436800956726, -1.0782114267349243, -0.4170582592487335, -0.4315216839313507, -0.30620235204696655, 0.05319804325699806, 0.7743658423423767, -0.04284223914146423, -0.38661789894104004, 0.41982120275497437, 0.08458130061626434, -0.005556177813559771, 0.8671903610229492, -0.8668071627616882, 0.26231107115745544, 0.04877811297774315, -0.5469962358474731, 0.14135992527008057, -0.32608431577682495, 0.27532052993774414, -0.5051458477973938, -0.6075884103775024, -0.042114417999982834, -0.8068872094154358, -0.3641766607761383, -0.26083287596702576, -1.0672117471694946, 0.27569907903671265, 0.6070778369903564, 0.5312342643737793, 0.8544740676879883, -0.08792271465063095, 0.0035984867718070745, -0.7868582010269165, -1.210168480873108, 0.016194205731153488, 0.5439671277999878, -0.541689932346344, -0.16198422014713287, 0.14710082113742828, 0.12923042476177216, -0.9925925135612488, -0.9517471790313721, -0.00011806379916379228, 0.41667434573173523, 0.09409316629171371, 1.139630675315857, -0.592557966709137, 0.8693430423736572, 0.6750538349151611, -0.007244766224175692, -0.9898999929428101, -0.5567625761032104, -0.4314488470554352, 0.4073774218559265, 0.20344547927379608, 0.5878112316131592, -0.26004716753959656, 0.6489703059196472, 0.6921961307525635, -0.05821504071354866, -1.3506072759628296, -0.3057705760002136, 0.12762552499771118, 0.042323045432567596, 0.14195270836353302, 0.2703172564506531, 0.053061842918395996, 0.2797217071056366, -0.6773660182952881, 0.5755323767662048, 0.9338815212249756, 0.15788792073726654, -0.43746045231819153, 0.2920762300491333, 0.1938047707080841, 0.08262906223535538, -0.5184211730957031, -0.9085130095481873, -0.8119037747383118, -0.27483242750167847, -1.574417233467102, 0.13476411998271942, -0.7772737741470337, 0.12301954627037048, 0.13103510439395905, -1.0039678812026978, 0.15226680040359497, -0.3403594493865967, -0.18482400476932526, -0.9315710663795471, -0.6445716023445129, -0.8229698538780212, 0.13768664002418518, 1.5122390985488892, -1.139500617980957, 0.3305354416370392, -0.22992584109306335, -0.31731438636779785, 0.16529293358325958, 0.34606027603149414, 0.020119894295930862, -0.711953341960907, -0.6054050922393799, 0.05251343175768852, -0.10651908814907074, 0.030958805233240128, -0.8920443058013916, 1.0341578722000122, 0.3431554436683655, 0.5739761590957642, -0.5416312217712402, 0.04916819557547569, -1.2043839693069458, -0.19872966408729553, 0.3090108335018158, -1.1398749351501465, -0.27191588282585144, -0.11046329140663147, -0.4019600450992584, -0.5135469436645508, 0.42730167508125305, 0.36247265338897705, -1.6132971048355103, -0.8764756917953491, 1.0023120641708374, -0.08824247866868973, -0.22400005161762238, 0.2444460690021515, 0.020281251519918442, -1.0058153867721558, 0.04597308114171028, -0.5764570832252502, 0.8533806800842285, -0.4802264869213104, 0.6715417504310608, 0.4953729212284088, -1.4608527421951294, 0.1569058895111084, 0.3676864206790924, 0.16072462499141693, 0.37814831733703613, 1.3991971015930176, 0.682532012462616, -0.28039729595184326, 0.5973889231681824, -0.009140689857304096, -5.937049991189269e-06, -1.3610221147537231, 0.4128674864768982, 1.1687431335449219, -0.8738237619400024, 0.1392647624015808, 1.206907868385315, 0.04589654877781868, -0.9173837304115295, 0.02273142710328102, -0.7438455820083618, -0.5039509534835815, -0.0684511587023735, 1.1404800415039062, 0.38488057255744934, 0.1135910153388977, 0.005908987484872341, -0.687116801738739, 0.41307201981544495, -0.7450594902038574, -0.08616568893194199, 0.7755362391471863, -0.10202764719724655, -0.3033526539802551, 0.35477787256240845, 0.8842148184776306, -0.8513104319572449, -1.0230517387390137, -0.8878960609436035, -0.5345777869224548, -0.1713501214981079, -0.10919022560119629, -0.5967962145805359, -0.6585901379585266, 0.45246273279190063, 0.8833561539649963, 0.22220787405967712, 0.2684612572193146, 0.08936941623687744, 0.006879343185573816, 0.5237828493118286, -0.2040417343378067, -0.5918501615524292, -0.04433504864573479, 0.46717000007629395, 1.3160744905471802, -1.2013332843780518, 0.3098483681678772, -0.2594359815120697, -0.800391435623169, 0.9882725477218628, 0.700299859046936, 0.04076090455055237, 1.0941119194030762, -0.28857606649398804, 0.38128218054771423, 0.05667978897690773, -1.220731258392334, 0.057494305074214935, 1.3114376068115234, 1.1392107009887695, 0.5652037262916565, 0.2979193329811096, 0.4223483204841614, 0.7933653593063354, 0.7238259315490723, -0.11819639056921005, 0.32024717330932617, 0.20413386821746826, -0.20105379819869995, -0.0421736016869545, 0.16158059239387512, 0.8629624843597412, -0.6586090922355652, 0.029453665018081665, 0.08559220284223557, 0.5553746223449707, 0.2511449456214905, 0.040893156081438065, 0.7918220162391663, 0.21450074017047882, 0.25909218192100525, 0.2034444510936737, 0.3456419110298157, -0.35445383191108704, -0.17157036066055298, -0.13024210929870605, -1.0975791215896606, -0.22193646430969238, -0.4214462637901306, -0.7432260513305664, -0.2779442369937897, 0.4484684467315674, 0.4170171618461609, -0.2377036213874817, -0.01655910164117813, 0.6994869709014893, 0.8403045535087585, 0.7773667573928833, -0.056729353964328766, -0.32014545798301697, -0.3561837673187256, -0.7463243007659912, -0.07819141447544098, -0.33722907304763794, 0.25236180424690247, -0.08030132204294205, -0.0217237938195467, -0.17487645149230957]}, "authors": [{"authorId": "2257428953", "name": "Honglin Li"}, {"authorId": "2266502115", "name": "Yunlong Zhang"}, {"authorId": "50812118", "name": "Chenglu Zhu"}, {"authorId": "92652202", "name": "Jiatong Cai"}, {"authorId": "2257378789", "name": "Sunyi Zheng"}, {"authorId": "2266438802", "name": "Lin Yang"}], "references": [{"paperId": "8d6c91430e21457190dcac7e70c248e89301026b", "title": "Attention-Challenging Multiple Instance Learning for Whole Slide Image Classification"}, {"paperId": "539fadfb615ef84c240f4741061c44eeda540091", "title": "Scaling Laws of RoPE-based Extrapolation"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "b6346f9fa093b8e85df712485a2b851b9f680dac", "title": "LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"}, {"paperId": "2270ea2a710f37fcd07a0014357238f71622176b", "title": "Histopathology Whole Slide Image Analysis with Heterogeneous Graph Representation Learning"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "e8acb3e6ae754b18eb5e1d8466b11d6e1d81d1ae", "title": "Modeling Dense Multimodal Interactions Between Biological Pathways and Histology for Survival Prediction"}, {"paperId": "d7b84faaca6ea954240511e07222ddb59e7d6aad", "title": "Prompt-MIL: Boosting Multi-Instance Learning Schemes via Task-specific Prompt Tuning"}, {"paperId": "c300f5242805ba72b3c4d794dde16615a860ff7c", "title": "Task-Specific Fine-Tuning via Variational Information Bottleneck for Weakly-Supervised Pathology Whole Slide Image Classification"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "f393aff1593c2d370ec0ae004910d18e40524967", "title": "Resurrecting Recurrent Neural Networks for Long Sequences"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "998ac3e945857cf2676ee7efdbaf443a0c6f820a", "title": "Hyena Hierarchy: Towards Larger Convolutional Language Models"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "e965e93e76a9e6c4e4863d145b5c007b540d575d", "title": "OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization"}, {"paperId": "2735edd31e3ec3f7bbfccdf02605a98d8360e5ac", "title": "Benchmarking Self-Supervised Learning on Diverse Pathology Datasets"}, {"paperId": "b5bb1073d3b0607b6fcda9cd65589a338bc92a9b", "title": "Benchmarking the Robustness of Deep Neural Networks to Common Corruptions in Digital Pathology"}, {"paperId": "68cda2cfefe8c21dc64fee55deab87672a517d39", "title": "Scaling Vision Transformers to Gigapixel Images via Hierarchical Self-Supervised Learning"}, {"paperId": "44653f1464dc4716097ca938f5d77c80aa72993f", "title": "Node-aligned Graph Convolutional Network for Whole-slide Image Representation and Classification"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "d6c5aab433d9871cabc01ffb1e5e1ea89141155b", "title": "KERPLE: Kernelized Relative Positional Embedding for Length Extrapolation"}, {"paperId": "e27c59ca5853172ce28b6a0e3967ec693611820b", "title": "DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification"}, {"paperId": "50b39552842b9b58051910b2dd1ce061f54adbf9", "title": "Weakly Supervised Learning For Cell Recognition In Immunohistochemical Cytoplasm Staining Images"}, {"paperId": "551a32d6bb196127b75d256e8547b81ef67a7ad3", "title": "Artificial intelligence for diagnosis and Gleason grading of prostate cancer: the PANDA challenge"}, {"paperId": "53c3940f35b8b45d55ed49056282e1961954513d", "title": "Self-attention Does Not Need $O(n^2)$ Memory"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "02a8883f756f09327cc134970be71db4dd893843", "title": "BRACS: A Dataset for BReAst Carcinoma Subtyping in H&E Histology Images"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "5d1aadd4053ba4fdcd71fe1c87a53b7540ef4eea", "title": "Multimodal Co-Attention Transformer for Survival Prediction in Gigapixel Whole Slide Images"}, {"paperId": "64522a5b3476e9f201f6a5b3e312ef0005c562f1", "title": "SHAPE: Shifted Absolute Position Embedding for Transformers"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "a9c214e846188adb645021cd7b1964b8ea1fef6f", "title": "Rethinking and Improving Relative Position Encoding for Vision Transformer"}, {"paperId": "c4aaf708f58a979b662b0755525e1f4eb1688e8d", "title": "Whole Slide Images are 2D Point Clouds: Context-Aware Survival Prediction using Patch-based Graph Convolutional Networks"}, {"paperId": "19d6faed3a5fb23c8288420bd79d98c2bfa524a3", "title": "Generalizing Nucleus Recognition Model in Multi-source Ki67 Immunohistochemistry Stained Images via Domain-Specific Pruning"}, {"paperId": "7509c66a666e2e3f14bc8676b969b945ee6e136f", "title": "CAPE: Encoding Relative Positions with Continuous Augmented Positional Embeddings"}, {"paperId": "b3e47f14f623e194365a838623d25642dd85c483", "title": "SPIE-AAPM-NCI BreastPathQ Challenge: an image analysis challenge for quantitative tumor cellularity assessment in breast cancer histology images following neoadjuvant treatment"}, {"paperId": "ad4a0938c48e61b7827869e4ac3baffd0aefab35", "title": "Emerging Properties in Self-Supervised Vision Transformers"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "db46b0de44c5113c47f0ec5392eb91d0726497bf", "title": "A Simple and Effective Positional Encoding for Transformers"}, {"paperId": "b3bf9fe13195e9aa70e1dac04e01fcff7008e812", "title": "Perceiver: General Perception with Iterative Attention"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "849b88ddc8f8cabc6d4246479b275a1ee65d0647", "title": "A Generalization of Transformer Networks to Graphs"}, {"paperId": "720ecbc16f94add77579b38d7276a279782df17d", "title": "Dual-stream Multiple Instance Learning Network for Whole Slide Image Classification with Self-supervised Contrastive Learning"}, {"paperId": "84476fdf6ead3553f4493dff8e02308439d6222b", "title": "Improve Transformer Models with Better Relative Position Embeddings"}, {"paperId": "0cd82dfae930ac4b57c0e959f744f2d10bf87649", "title": "Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding"}, {"paperId": "f0c24d4ba514081a7bc77905e3e12998937ba68b", "title": "Whole slide images based cancer survival prediction using attention guided deep multiple instance learning networks"}, {"paperId": "cd4ffe5e014601a3d6b64121355d29a730591490", "title": "Fast Transformers with Clustered Attention"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "8256f48f759cf85044db251cc512f965834945b3", "title": "Rethinking Positional Encoding in Language Pre-training"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "0b991a1a5bcdb13646ac0b6873d09bde4cc36fb5", "title": "Masked Language Modeling for Proteins via Linearly Scalable Long-Context Transformers"}, {"paperId": "3e358c3033908a9506e7f1e3cf29283e359f43d6", "title": "Data-efficient and weakly supervised computational pathology on whole-slide images"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "b7c77e8e95051c87d1a5f66626a536e4d5140fab", "title": "Bias in Cross-Entropy-Based Training of Deep Survival Networks"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "addae423490bbe82da4fb2fc265237178686b4e8", "title": "Clinical-grade computational pathology using weakly supervised deep learning on whole slide images"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "949fef650da4c41afe6049a183b504b3cc91f4bd", "title": "Multimodal Transformer for Unaligned Multimodal Language Sequences"}, {"paperId": "7edacd94dc1509803d9bbcc1d92fea780d71cb3e", "title": "MnnFast: A Fast and Scalable System Architecture for Memory-Augmented Neural Networks"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "2c0cdbf4f412f320242481bf7fe718a6237e74e2", "title": "Graph CNN for Survival Analysis on Whole Slide Pathological Images"}, {"paperId": "45dd2a3cd7c27f2e9509b023d702408f5ac11c9d", "title": "Stacked Cross Attention for Image-Text Matching"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "57fbd1841a7cf8582682da399d2811655f020c0a", "title": "Attention-based Deep Multiple Instance Learning"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0", "title": "Convolutional Sequence to Sequence Learning"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "4d8340eae2c98ab5e0a3b1a7e071a7ddb9106cff", "title": "A Framework for Multiple-Instance Learning"}, {"paperId": "65ff54c376596bb93dc4c0b21de4220900f228d0", "title": "Deformable Proposal-Aware P2PNet: A Universal Network for Cell Recognition under Point Supervision"}, {"paperId": "48ad536d00742a31eb8c6408c5d7ad96e654fe7a", "title": "Receptive Field Alignment Enables Transformer Length Extrapolation"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": null, "title": "An attention free"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "trans-former language models"}, {"paperId": null, "title": "positional embedding for shape varying large WSI, which provides input length extrapolation ability to generalize on different input size and under-fitted positions of WSI during testing"}, {"paperId": null, "title": "Review the cancer genome atlas (tcga): an im-measurable source of knowledge"}, {"paperId": null, "title": "Electra: Pre-training text encoders as discriminators rather than generators"}]}