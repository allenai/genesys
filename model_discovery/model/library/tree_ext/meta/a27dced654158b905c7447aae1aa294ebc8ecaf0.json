{"paperId": "a27dced654158b905c7447aae1aa294ebc8ecaf0", "title": "Efficient Long-Range Transformers: You Need to Attend More, but Not Necessarily at Every Layer", "abstract": "Pretrained transformer models have demonstrated remarkable performance across various natural language processing tasks. These models leverage the attention mechanism to capture long- and short-range dependencies in the sequence. However, the (full) attention mechanism incurs high computational cost - quadratic in the sequence length, which is not affordable in tasks with long sequences, e.g., inputs with 8k tokens. Although sparse attention can be used to improve computational efficiency, as suggested in existing work, it has limited modeling capacity and often fails to capture complicated dependencies in long sequences. To tackle this challenge, we propose MASFormer, an easy-to-implement transformer variant with Mixed Attention Spans. Specifically, MASFormer is equipped with full attention to capture long-range dependencies, but only at a small number of layers. For the remaining layers, MASformer only employs sparse attention to capture short-range dependencies. Our experiments on natural language modeling and generation tasks show that a decoder-only MASFormer model of 1.3B parameters can achieve competitive performance to vanilla transformers with full attention while significantly reducing computational cost (up to 75%). Additionally, we investigate the effectiveness of continual training with long sequence data and how sequence length impacts downstream generation performance, which may be of independent interest.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "MASFormer, an easy-to-implement transformer variant with Mixed Attention Spans, is proposed, which is equipped with full attention to capture long-range dependencies, but only at a small number of layers."}, "embedding": {"model": "specter_v2", "vector": [0.5445088148117065, 0.7645046710968018, 0.19310325384140015, -0.07112093269824982, -0.21435102820396423, -0.4328562319278717, 0.8463354110717773, -0.06215126812458038, -0.11726181954145432, -0.22060158848762512, 0.6515256762504578, -0.1738099753856659, 0.38543006777763367, 0.01100693829357624, -0.2643377184867859, 0.11248818039894104, -0.7082421183586121, 0.3842724859714508, -0.2937183082103729, -0.49962329864501953, -0.016785288229584694, -0.8255687952041626, -0.7140411734580994, 0.07089287042617798, 0.5678630471229553, 0.3338564336299896, 0.7041965126991272, 0.7764515280723572, -0.47394654154777527, 0.5274943113327026, 0.5358585119247437, -0.7390982508659363, 0.19495083391666412, -0.14709991216659546, -0.37711381912231445, -0.03340139612555504, 0.353595107793808, -0.31623750925064087, -0.206401526927948, 0.6921398043632507, -0.2661060094833374, 0.11672753840684891, 0.43370041251182556, -0.5733687281608582, -0.6616140604019165, 1.5844402313232422, 0.7127708792686462, 0.6623939275741577, -0.1081220880150795, -0.362000048160553, 1.6784619092941284, -1.227866768836975, 0.07152798026800156, 1.420574426651001, 0.33381208777427673, 0.42903193831443787, -0.3559744358062744, -0.7442905306816101, 0.8960248231887817, 0.03176235407590866, -0.8240765333175659, -0.43677058815956116, 0.11600320041179657, -0.1326625645160675, 2.1305389404296875, -0.5009176731109619, 0.3109070658683777, 0.7128469944000244, -0.07241937518119812, 1.331666350364685, -0.294794499874115, -0.7519189715385437, -0.6263505220413208, -0.3308325409889221, 0.36126232147216797, 0.8454800844192505, -0.3975194990634918, 0.297101765871048, -1.0239758491516113, 0.27198588848114014, 0.5996289253234863, -0.12202645093202591, 0.009807346388697624, 0.32399651408195496, -0.4046497046947479, 0.48510923981666565, 0.3230786919593811, 1.1262718439102173, -0.21274970471858978, 0.7227742671966553, 0.37043482065200806, 0.3109782338142395, -0.2629854381084442, 0.5760027170181274, -0.08434799313545227, 0.6215555667877197, -1.0104366540908813, 0.15282206237316132, -0.26635462045669556, 1.0729869604110718, -0.10196081548929214, 0.6326631903648376, -0.9453334212303162, 0.13680125772953033, 1.4032015800476074, 0.14977233111858368, 0.5291420817375183, -0.6161582469940186, 0.510688066482544, -0.7699081897735596, -0.08852037787437439, -0.5526121258735657, 0.09719527512788773, -0.33649715781211853, -0.716888964176178, -1.5169663429260254, -0.19934619963169098, 0.1746654212474823, -0.8033144474029541, 1.0257008075714111, -0.5912811756134033, 0.19636958837509155, -0.032614566385746, 0.2659539580345154, 0.5496184229850769, 0.8379653692245483, 0.24990595877170563, 0.10506285727024078, 0.746685266494751, -0.8277232646942139, -0.7418012022972107, -1.2872823476791382, 0.4703291356563568, -0.3010106682777405, 0.23984627425670624, -0.054841626435518265, -1.4440929889678955, -0.9052798748016357, -0.7619779109954834, -0.12670211493968964, -0.5291715264320374, 0.2645353078842163, 1.0112066268920898, 0.3706590235233307, -1.2289024591445923, 0.6694721579551697, -0.14846271276474, 0.06658630073070526, 0.26957350969314575, 0.02554355561733246, 0.22394554316997528, -0.5006323456764221, -1.514562726020813, 0.3365706205368042, 0.3751618564128876, -0.20662276446819305, -0.2485794723033905, -0.9042854905128479, -1.5100072622299194, 0.188883438706398, 0.1309509575366974, -0.4161793887615204, 1.294560194015503, -0.043665945529937744, -1.2116775512695312, 0.5185355544090271, -0.48886051774024963, 0.14232325553894043, -0.23051400482654572, -0.3031730651855469, -0.2407778799533844, -0.7289819717407227, 0.040529269725084305, 0.44726014137268066, 0.3544159233570099, 0.19103696942329407, -0.11575762927532196, 0.20612354576587677, -0.3766555190086365, -0.19680152833461761, -0.09504324942827225, 1.1094980239868164, -0.0029173053335398436, -0.47988182306289673, -0.04691627621650696, 0.6597419381141663, -0.13701854646205902, -0.8150739669799805, -0.8531113266944885, -1.066310167312622, 0.3241998553276062, -0.3533654510974884, 0.933030366897583, -0.7114524245262146, -0.635651171207428, -0.26383543014526367, -0.35271695256233215, -0.1488349735736847, -0.8761611580848694, 0.7009939551353455, -0.7093135118484497, 0.48278215527534485, -0.11065752059221268, -1.1830329895019531, 0.29792577028274536, -0.2632160782814026, -0.8467215299606323, -0.482932448387146, 0.4201444685459137, 1.1858564615249634, -1.0522964000701904, -0.014522410929203033, 0.13330252468585968, 0.23083607852458954, -0.9855351448059082, 1.2104982137680054, -0.40836301445961, 0.17437459528446198, -0.028156446292996407, -0.16306158900260925, -0.05756070092320442, -0.424050897359848, 0.28161704540252686, -0.22578361630439758, -0.07914096117019653, 0.8795343637466431, -0.19641001522541046, 1.6844184398651123, -0.43027621507644653, 0.4398578107357025, -0.27353107929229736, -0.7929950952529907, 0.13645252585411072, 0.49863240122795105, -0.22772547602653503, -0.38523659110069275, 0.13426844775676727, 0.43424320220947266, -0.3620895445346832, 0.4514882564544678, 0.666562020778656, 0.4494297504425049, -0.40324902534484863, 0.14165166020393372, 0.7962403297424316, -0.16667509078979492, 0.5916803479194641, 0.6762365102767944, 0.7778127193450928, 0.4487241506576538, 0.4360283315181732, -0.019597483798861504, 0.2738574743270874, -0.8583784103393555, -0.08422458171844482, 0.44264665246009827, 1.0939868688583374, 0.940898060798645, 0.3910011649131775, -0.5096527338027954, -0.2846587300300598, -0.08596811443567276, 0.9987396001815796, 1.415759563446045, -0.33403104543685913, -0.31720036268234253, -0.4696725308895111, 0.005681898444890976, -0.5431839227676392, 0.3865498900413513, -0.2217767834663391, -0.07326814532279968, -0.6762328743934631, -0.70977383852005, 0.8269760608673096, 0.2772735059261322, 0.6734743118286133, -0.7544563412666321, -0.1314878761768341, -0.14028631150722504, -0.025300055742263794, -1.0422669649124146, -0.7678459882736206, 0.2465151846408844, -0.26723557710647583, -0.14040915668010712, 0.019054364413022995, -0.22258850932121277, 0.15825918316841125, -0.9731118679046631, 1.0309746265411377, -0.6472991108894348, -0.3563356101512909, 0.12019845843315125, 0.4408150017261505, -0.4257686138153076, -0.716291069984436, 0.19180701673030853, -0.13260389864444733, -0.17157593369483948, 0.025596708059310913, 0.1784527748823166, 0.15802451968193054, -0.45351260900497437, -0.17924851179122925, 0.33793163299560547, 0.2849574685096741, 0.04948567971587181, 0.6848815083503723, -0.23161378502845764, -0.17125298082828522, -1.278416395187378, 0.6983953714370728, 0.24075265228748322, -0.6302273273468018, 0.3491442799568176, -0.6288306713104248, -0.28724977374076843, 0.769243061542511, -0.5037312507629395, -0.4301055371761322, -0.6438890695571899, 0.3352237641811371, -0.2764529883861542, -0.30016541481018066, 0.31319698691368103, -0.1137668713927269, 0.6622251868247986, -0.2471647411584854, 0.7240941524505615, 0.042755961418151855, -0.11527477949857712, 0.7637350559234619, -1.1414750814437866, 0.3984808325767517, 0.39026692509651184, 0.3463948369026184, -0.6206258535385132, -0.26387348771095276, -0.6228305101394653, -0.5325896143913269, -0.1990320235490799, 0.04346143454313278, -0.19420866668224335, 0.35607022047042847, -0.4468422532081604, -0.7751615643501282, 0.2531445622444153, -1.4534132480621338, -0.23912103474140167, 0.03390531241893768, -0.517669141292572, 0.04632461816072464, -1.0897051095962524, -1.2331035137176514, -0.31296250224113464, -0.6653931736946106, -0.9088770747184753, 0.5613004565238953, 0.041183289140462875, -0.24756775796413422, -0.7617030143737793, 0.029064852744340897, -0.26328524947166443, 1.0417503118515015, -0.6039791703224182, 0.8620012998580933, -0.23523348569869995, -0.5241870284080505, -0.006714217830449343, 0.45292726159095764, 0.5253013968467712, -0.11398057639598846, 0.18533705174922943, -0.7503637671470642, 0.24939829111099243, -0.6451520919799805, -0.2793347239494324, 0.19753022491931915, 0.47451579570770264, 0.5152925848960876, -0.24620167911052704, -0.39639919996261597, 0.30971530079841614, 1.4144957065582275, -0.5336483120918274, 0.180862158536911, -0.09699869900941849, 1.2586525678634644, 0.2832804322242737, -0.41076526045799255, 0.535060703754425, 0.6408885717391968, 0.24652262032032013, 0.3324345648288727, 0.13567739725112915, -0.15841273963451385, -0.8674352169036865, 0.8763685822486877, 1.7835896015167236, 0.1627124845981598, -0.20538261532783508, -1.1265064477920532, 0.8518856763839722, -1.0765838623046875, -0.8986667394638062, 0.5355870127677917, 0.5469385385513306, 0.6007934212684631, -0.6984351873397827, -0.7796565890312195, -0.12774841487407684, 0.45699429512023926, 0.47506994009017944, -0.13466382026672363, -0.8541654944419861, 0.05441073700785637, 0.69376140832901, -0.06634916365146637, 0.7838799357414246, -0.05624975636601448, 0.8265789151191711, 14.683791160583496, 0.6987189054489136, 0.0808509960770607, 0.45985645055770874, 0.5831999778747559, 0.07783375680446625, -0.6749751567840576, -0.043074432760477066, -1.430645227432251, -0.07791120558977127, 0.8544215559959412, 0.12993547320365906, 0.8185268640518188, -0.1312616467475891, 0.06944780796766281, 0.4063463509082794, -0.7551844716072083, 0.7554897665977478, 0.5270915627479553, -1.3252454996109009, 0.6976668834686279, 0.12449578940868378, 0.2140391767024994, 0.261989563703537, 0.6778450608253479, 0.7842710018157959, 0.670227587223053, -0.6737931966781616, 0.5551955103874207, 0.1583082228899002, 0.8913880586624146, 0.012556038796901703, 0.138664111495018, 0.4065515995025635, -1.199607491493225, -0.14970184862613678, -0.44315287470817566, -1.2139968872070312, 0.44322770833969116, 0.33572545647621155, -0.548600971698761, -0.35987022519111633, -0.37695643305778503, 1.0217796564102173, -0.03852313384413719, 0.20223264396190643, -0.6418659687042236, 0.8104749917984009, 0.0326961949467659, 0.0037554819136857986, 0.3492058515548706, 0.3850724697113037, 0.3964379131793976, -0.006921072490513325, 0.4748302400112152, 0.06708578020334244, 0.14124420285224915, 0.7586537003517151, -0.36917614936828613, -0.18568198382854462, -0.44969403743743896, -0.6498565673828125, 0.2165089100599289, 0.7988888621330261, 0.3656121492385864, 0.4459841549396515, -0.27298349142074585, 0.18659232556819916, 0.7044411301612854, 0.19560179114341736, -0.16835778951644897, -0.14096345007419586, 0.24887505173683167, -0.37237417697906494, 0.17453047633171082, 0.5248156785964966, -0.08042357116937637, -0.42475274205207825, -0.7524715662002563, -0.44182026386260986, 0.43775755167007446, -0.8499490022659302, -0.8259018063545227, 0.6781095862388611, -0.33394142985343933, -0.1311127096414566, -0.19194912910461426, -0.6630481481552124, -0.4591035842895508, 0.5486756563186646, -1.5278329849243164, -1.1324050426483154, 0.38928040862083435, -0.13524338603019714, -0.07391373068094254, -0.1559511125087738, 1.089670181274414, 0.0675148218870163, -0.30572259426116943, 0.12433528155088425, -0.3172367811203003, 0.29186901450157166, -0.5491481423377991, -0.9988417029380798, 0.794622540473938, 0.7398756742477417, 0.11088403314352036, 0.3603796660900116, 0.004716959316283464, 0.2028317004442215, -0.7629287838935852, -0.06374148279428482, 1.242682695388794, -0.8235955238342285, -0.33005428314208984, -0.8653676509857178, -0.49437233805656433, 0.5813503861427307, 1.0112963914871216, -0.5427772402763367, 0.4779667854309082, 0.21204398572444916, -0.5018743276596069, -0.18428152799606323, -0.41617536544799805, -0.06818137317895889, 0.6636751890182495, -0.7601674795150757, -0.34100809693336487, -0.2369096428155899, 0.6108173727989197, -0.9052567481994629, -0.3879071772098541, -0.515245795249939, 0.1899280846118927, -0.025049759075045586, 0.872285783290863, -0.24151524901390076, 0.9039120674133301, 0.9695069193840027, 0.06890802085399628, -1.0669498443603516, -0.3161775767803192, -1.1726514101028442, 0.31222307682037354, 0.6052532196044922, 0.7502726316452026, -0.38261017203330994, -0.28843656182289124, 0.7692846655845642, 0.03253371641039848, -0.26524919271469116, -0.5889601707458496, -0.3436858057975769, -0.10856214910745621, -0.5544705986976624, 0.4152083992958069, 0.12340463697910309, 0.022460507228970528, 0.4612828195095062, 0.35186901688575745, 0.6872147917747498, -0.14691060781478882, -0.5228728652000427, 0.0012199899647384882, 0.15846037864685059, -0.28276604413986206, -0.7101908326148987, -0.4320826530456543, -1.2691267728805542, 0.21727491915225983, -1.2848999500274658, 0.13942819833755493, -1.2740232944488525, -0.440216064453125, 0.1027352586388588, -0.3058582544326782, 0.5396614670753479, 0.142634779214859, -0.4547908306121826, -0.3209032714366913, -1.0111991167068481, -0.34772083163261414, 0.8625475168228149, 0.7402871251106262, -0.7936582565307617, 0.3491329252719879, -0.2533624768257141, -0.15006136894226074, -0.0010183941340073943, 0.13376465439796448, -0.46989262104034424, -0.9144670963287354, -1.6934717893600464, 0.6470755934715271, -0.11030936986207962, -0.10962125658988953, -0.5007011890411377, 0.5184656381607056, 0.4149264395236969, -0.3672870695590973, 0.129038006067276, 0.24601124227046967, -0.5985897183418274, -0.3814435303211212, 0.3646744191646576, -0.9189813137054443, 0.4048886299133301, 0.06026401370763779, -0.7414324283599854, -0.36373427510261536, 0.6639315485954285, -0.211343452334404, -1.322253942489624, -0.6734674572944641, 0.6564755439758301, -0.5770987868309021, 0.2542291581630707, -0.41685494780540466, -0.1809433400630951, -1.037291407585144, -0.3771003484725952, 0.15917442739009857, 0.4872257709503174, -0.609447717666626, 1.0482597351074219, 0.624420702457428, -1.0262150764465332, -0.11226028949022293, 0.2800050675868988, -0.31889206171035767, 0.13478100299835205, 0.31193751096725464, 0.2109071910381317, -0.07182605564594269, 0.5295484066009521, 0.2808116376399994, 0.5129178166389465, -0.8779345750808716, -0.15707024931907654, 0.8536027669906616, -0.7323691248893738, 0.018100406974554062, 1.3057795763015747, -0.33651140332221985, -0.9651577472686768, -0.028654390946030617, -1.304647445678711, -0.8187497854232788, -0.414396196603775, 0.6128632426261902, -0.0637638047337532, -0.4259304106235504, -0.04386947676539421, -0.5473355650901794, 0.1359129250049591, 0.06843142956495285, -0.5119872689247131, 0.7729604244232178, -0.027596192434430122, -0.4443618357181549, 0.5663089752197266, 0.44125765562057495, -0.6328275203704834, -0.2769559323787689, -0.5279225707054138, -0.5811470746994019, 0.09331472963094711, 0.21441461145877838, -0.40731239318847656, -0.858113706111908, 1.085707187652588, -0.008643162436783314, 0.40474751591682434, 0.20435570180416107, -0.07293912768363953, 0.22568228840827942, 0.5207415819168091, 0.17866463959217072, -0.33712390065193176, -0.3725781738758087, 1.7350869178771973, 1.3392415046691895, -0.7022348046302795, -0.29100874066352844, -0.40259280800819397, -0.7267670035362244, 0.6868565082550049, 0.3212847113609314, 0.04451931267976761, 0.8688541650772095, -0.15375249087810516, -0.24914805591106415, 0.19565266370773315, -1.209307312965393, -0.2935386300086975, 0.6799906492233276, 1.280663251876831, 1.0380200147628784, 0.17660991847515106, 0.1887279450893402, 1.174888014793396, -0.2844189405441284, -0.17321936786174774, 0.42510128021240234, 0.2109323889017105, 0.10449642688035965, -0.22660811245441437, 0.31146857142448425, 0.6200904250144958, -0.6829164028167725, -1.119242787361145, 0.17078611254692078, 0.1789165437221527, 0.2556048333644867, 0.8023006916046143, 0.7305616140365601, 0.3688446879386902, 0.41734427213668823, 0.09768733382225037, 0.7325035333633423, -0.6680417060852051, -0.2815701365470886, -0.28983455896377563, -0.576537549495697, -0.35515356063842773, -0.21770396828651428, -0.5717616081237793, -0.34659743309020996, 0.019992293789982796, 0.10921891033649445, 0.04347359761595726, 0.1720895916223526, 1.3647466897964478, 0.3668641149997711, 0.6000690460205078, -0.24940909445285797, -0.42002755403518677, -0.1979088932275772, -1.1555098295211792, -0.055571310222148895, -0.4784356355667114, -0.09450055658817291, 0.06935833394527435, 0.178175687789917, 0.20173247158527374]}, "authors": [{"authorId": "153441799", "name": "Qingru Zhang"}, {"authorId": "2260341519", "name": "Dhananjay Ram"}, {"authorId": "2260341798", "name": "Cole Hawkins"}, {"authorId": "2260341493", "name": "Sheng Zha"}, {"authorId": "2260598206", "name": "Tuo Zhao"}], "references": [{"paperId": "661e8d555c4424b5953f17434f2ba910bfcf3afe", "title": "Efficient Long Sequence Modeling via State Space Augmented Transformer"}, {"paperId": "240300b1da360f22bf0b82c6817eacebba6deed4", "title": "What Makes Convolutional Models Great on Long Sequence Modeling?"}, {"paperId": "70e91e16eb321067d9402710e14a40cf28311f73", "title": "Mega: Moving Average Equipped Gated Attention"}, {"paperId": "6d7d141c75af752ffc0d8a6184cca3f9323d6c74", "title": "Simplified State Space Layers for Sequence Modeling"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "71e15a9a52dcafca57bff5f310b95e2c7d0cfc87", "title": "Diagonal State Spaces are as Effective as Structured State Spaces"}, {"paperId": "3dfb1f50f2a34a699c339dabaa6f9b3a977973de", "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences"}, {"paperId": "972706306f85b1bfb40c7d35c796ad5174eb0c9c", "title": "DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "5f895e84c1fea75de07b4f90da518273c2e57291", "title": "Scatterbrain: Unifying Sparse and Low-rank Attention Approximation"}, {"paperId": "f75d05e759447c2aedb7097728f29f9a520d9bc1", "title": "Do Long-Range Language Models Actually Use Long-Range Context?"}, {"paperId": "7e5008713c404445dd8786753526f1a45b93de12", "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "0964490205fdc38c2f0980c9d778069089ca92e3", "title": "HiPPO: Recurrent Memory with Optimal Polynomial Projections"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "9b539d413393047b28bb7be9b195f142aaf7a80e", "title": "Recipes for Building an Open-Domain Chatbot"}, {"paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d", "title": "ETC: Encoding Long and Structured Inputs in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "5ef82a8c8aa50f99285f2143b57ca4e82da1af80", "title": "Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "4171\u20134186, Minneapolis, Minnesota"}, {"paperId": null, "title": "2022. Scrolls: Stan-dardized comparison over long language sequences"}]}