{"paperId": "22b58dce1a13382418b8372bbd50ed3b2533f899", "title": "ByteTransformer: A High-Performance Transformer Boosted for Variable-Length Inputs", "abstract": "Transformers have become keystone models in natural language processing over the past decade. They have achieved great popularity in deep learning applications, but the increasing sizes of the parameter spaces required by transformer models generate a commensurate need to accelerate performance. Natural language processing problems are also routinely faced with variable-length sequences, as word counts commonly vary among sentences. Existing deep learning frameworks pad variable-length sequences to a maximal length, which adds significant memory and computational overhead. In this paper, we present ByteTransformer, a high-performance transformer boosted for variable-length inputs. We propose a padding-free algorithm that liberates the entire transformer from redundant computations on zero padded tokens. In addition to algorithmic-level optimization, we provide architecture-aware optimizations for transformer functional modules, especially the performance-critical algorithm Multi-Head Attention (MHA). Experimental results on an NVIDIA A100 GPU with variable-length sequence inputs validate that our fused MHA outperforms PyTorch by 6.13x. The end-to-end performance of ByteTransformer for a forward BERT transformer surpasses state-of-the-art transformer frameworks, such as PyTorch JIT, TensorFlow XLA, Tencent TurboTransformer, Microsoft DeepSpeed-Inference and NVIDIA FasterTransformer, by 87%, 131%, 138%, 74% and 55%, respectively. We also demonstrate the general applicability of our optimization methods to other BERT-like models, including ALBERT, DistilBERT, and DeBERTa.", "venue": "IEEE International Parallel and Distributed Processing Symposium", "year": 2022, "citationCount": 23, "influentialCitationCount": 2, "openAccessPdf": {"url": "https://arxiv.org/pdf/2210.03052", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "The end-to-end performance of ByteTransformer for a forward BERT transformer surpasses state-of-the-art transformer frameworks, such as PyTorch JIT, TensorFlow XLA, Tencent TurboTransformer, Microsoft DeepSpeed-Inference and NVIDIA FasterTransformer by 87%, 131, 138, 74% and 55%, respectively."}, "embedding": {"model": "specter_v2", "vector": [0.31819188594818115, 0.3175225257873535, -0.29251474142074585, -0.2373294085264206, -0.4347991347312927, -0.32670748233795166, 0.6827169060707092, -0.09080430120229721, -0.7412292957305908, -0.18025736510753632, 0.6994312405586243, -0.29661867022514343, 0.6659512519836426, -0.049875497817993164, -0.225057914853096, -0.08302414417266846, -0.7490428686141968, 0.31181108951568604, -0.14884960651397705, -0.15299515426158905, 0.06251645088195801, -0.5062605738639832, -1.3046327829360962, 0.022740181535482407, 0.20386724174022675, 0.4006342887878418, 0.21811607480049133, 0.9935216307640076, -0.8670181035995483, 0.31787556409835815, 0.4506075978279114, -0.5431071519851685, 0.10419957339763641, 0.14797420799732208, -0.5998275876045227, -0.18743674457073212, 0.5703002214431763, -0.6494712829589844, -0.2589725852012634, 0.8385261297225952, -0.1962209939956665, 0.3433353900909424, 0.18606723845005035, -0.6850811839103699, -0.11590409278869629, 1.055894374847412, 0.6176592707633972, 0.8721423745155334, -0.553199827671051, -0.18432515859603882, 1.590118408203125, -1.230063557624817, -0.004536052234470844, 1.3718173503875732, 0.3844662010669708, 0.23755790293216705, -0.3203527629375458, -0.3244327902793884, 0.6068294048309326, 0.3057805001735687, -0.4363979399204254, -0.43320271372795105, -0.05781024321913719, 0.02701237052679062, 2.3837473392486572, -0.2222370058298111, 0.27076229453086853, 0.31825879216194153, 0.1913335770368576, 1.458584189414978, -0.22240489721298218, -0.8736057877540588, -0.3188203275203705, -0.3967055678367615, 0.6613246202468872, 0.8320235013961792, -0.2812191843986511, 0.24081186950206757, -0.7486391663551331, 0.09545796364545822, 0.25051233172416687, 0.10695896297693253, 0.5492129325866699, 0.03376765549182892, -0.4232301115989685, 0.739302933216095, 0.30814841389656067, 0.7910081148147583, -0.27098751068115234, 0.8718252182006836, 0.8795190453529358, -0.01914179138839245, -0.002540080575272441, 0.5012749433517456, -0.10140746086835861, 0.04381059482693672, -0.9306238293647766, 0.1986737996339798, 0.007470059208571911, 0.6978649497032166, -0.045934032648801804, 0.642044186592102, -0.9422338008880615, -0.030611390247941017, 1.131701946258545, 0.4133356511592865, 0.351962685585022, -0.6437713503837585, 0.04460489749908447, -0.9428391456604004, -0.18344350159168243, -0.35109248757362366, -0.06281346082687378, -0.38514527678489685, -0.5199062824249268, -1.1995570659637451, -0.27850988507270813, 0.26882120966911316, -0.7962486743927002, 0.5401142239570618, -0.21377669274806976, 0.1774110496044159, -0.03878995403647423, 0.5196186304092407, 0.5393621921539307, 0.609749972820282, 0.3969804644584656, 0.2100784033536911, 1.1581164598464966, -1.1944071054458618, -0.6840980648994446, -1.2113466262817383, 0.5298362970352173, -0.43732950091362, 0.23775604367256165, -0.04938216134905815, -1.1548908948898315, -0.5831285119056702, -0.44710901379585266, -0.1657896637916565, -0.572975754737854, -0.137771338224411, 1.1467976570129395, 0.41654032468795776, -1.1716067790985107, 0.6632763147354126, -0.28263261914253235, 0.01180601492524147, 0.2453346848487854, 0.18965573608875275, 0.5015737414360046, -0.20499026775360107, -1.357560396194458, 0.10664486885070801, 0.16303396224975586, -0.6144930720329285, -0.18996870517730713, -0.7777724862098694, -0.9647355079650879, 0.35035064816474915, 0.10281968861818314, -0.36403709650039673, 1.6326632499694824, -0.2061486840248108, -1.129629135131836, 0.6345343589782715, -0.5230576992034912, -0.053015824407339096, -0.002472357824444771, -0.24537326395511627, -0.2221720665693283, -0.5466026663780212, 0.13158811628818512, 0.4203124940395355, 0.581142008304596, 0.23955491185188293, -0.24138012528419495, 0.2183646410703659, -0.3262854814529419, -0.03704153373837471, -0.4703303575515747, 0.8068339824676514, -0.3379512131214142, -0.295467346906662, -0.11655937135219574, 0.8782956004142761, -0.020694876089692116, -0.5102614164352417, -0.580998420715332, -1.0691874027252197, 0.5271391272544861, 0.1714438945055008, 0.7923206090927124, -0.8527711629867554, -0.8863067626953125, -0.2725886404514313, 0.08382034301757812, -0.1258309781551361, -0.6963397264480591, 0.3661678433418274, -0.4546530544757843, 0.25927242636680603, -0.12837117910385132, -1.0336562395095825, 0.18845878541469574, 0.1096978560090065, -0.7908542156219482, -0.07744087278842926, 0.07993593066930771, 1.1048860549926758, -1.0565495491027832, -0.11479417979717255, 0.2967517077922821, 0.4366622269153595, -1.168507695198059, 1.4222698211669922, -0.5084086060523987, -0.23248478770256042, 0.10383779555559158, -0.3448599874973297, -0.09889331459999084, -0.34956222772598267, 0.2741408944129944, -0.49947860836982727, -0.4657254219055176, 0.8585531115531921, 0.05820341035723686, 1.1720129251480103, -0.4769807457923889, 0.2702803909778595, -0.1589178591966629, -0.43117693066596985, 0.35117799043655396, 0.06415526568889618, -0.07994016259908676, -0.6544626355171204, 0.3963451683521271, 0.3381558954715729, -0.5347126722335815, 0.17073044180870056, 1.1501699686050415, 0.7912204265594482, -0.15674586594104767, 0.35596856474876404, 0.5383177399635315, -0.08983194828033447, 0.5562828183174133, 0.6174449920654297, 0.6804722547531128, 0.3039082884788513, 0.31633031368255615, -0.1670198142528534, 0.23514492809772491, -0.7472705245018005, -0.2742727994918823, 0.4127207398414612, 0.49775782227516174, 0.6028002500534058, 0.5508829355239868, -0.7803779244422913, -0.7817652821540833, 0.27351057529449463, 0.599291980266571, 1.851357102394104, -0.3455102741718292, -0.1861943006515503, -0.7108128070831299, -0.23980474472045898, -0.3077104091644287, 0.16226911544799805, -0.08319799602031708, 0.053014207631349564, -0.6463853716850281, -0.9266325235366821, 0.9208868145942688, 0.3779538571834564, 0.9540485739707947, -0.6836073994636536, -0.6212030649185181, -0.16098275780677795, 0.1427343338727951, -0.8756499290466309, -0.9043700695037842, 0.7148553729057312, -0.42979705333709717, 0.017935736104846, 0.16009992361068726, -0.1415083110332489, -0.007033723872154951, -0.6326336860656738, 1.1748608350753784, -0.6830517053604126, -0.42815643548965454, 0.10179372876882553, 0.6101893782615662, -0.3282327353954315, -0.6023434996604919, 0.48386168479919434, -0.10856176912784576, -0.10476860404014587, 0.4947011172771454, 0.45464131236076355, 0.0670887902379036, -0.3412943184375763, -0.3298710584640503, 0.2328619658946991, 0.06630364060401917, 0.10864874720573425, 0.6779639720916748, -0.6654114723205566, -0.38118404150009155, -1.0854949951171875, 0.6653347015380859, 0.22935687005519867, -0.4911946654319763, 0.07831727713346481, -0.7385385036468506, 0.2940032184123993, 0.8279674649238586, -0.4021030068397522, -0.10958831757307053, -0.6133801341056824, 0.051973335444927216, -0.5344452857971191, -0.1759759485721588, -0.04152951389551163, 0.3039132058620453, 0.482442706823349, -0.01890062913298607, 0.6508369445800781, 0.4988960325717926, -0.004883195739239454, 0.8658193349838257, -0.8900152444839478, 0.7280780076980591, 0.09696245938539505, 0.018995679914951324, -0.25084188580513, -0.17257948219776154, -0.645926833152771, -0.3275153636932373, -0.6165260672569275, -0.11839964985847473, -0.4746405780315399, 0.33118996024131775, -0.1693114936351776, -1.1803503036499023, 0.30355867743492126, -1.5304218530654907, -0.1660102754831314, 0.18743795156478882, -0.42535829544067383, -0.03207874670624733, -1.0773804187774658, -1.3826954364776611, -0.39834919571876526, -1.114959478378296, -1.270199179649353, 0.36883682012557983, 0.0340142659842968, -0.33864352107048035, -0.698722779750824, 0.019242126494646072, -0.5076488852500916, 1.1147127151489258, -0.7800549864768982, 0.8773561120033264, -0.35162559151649475, -0.2590900659561157, 0.1108127236366272, -0.08691541850566864, 0.2849957346916199, -0.38437631726264954, 0.27593207359313965, -0.9129138588905334, 0.34244805574417114, -0.6214584112167358, -0.21023772656917572, 0.1972581148147583, 0.18198363482952118, 0.6575990915298462, -0.34845438599586487, -0.19651652872562408, 0.6452030539512634, 1.4479314088821411, -0.8285474181175232, -0.022106900811195374, 0.4123757481575012, 1.162563443183899, -0.08787954598665237, -0.29094284772872925, 0.769687294960022, 0.23679226636886597, 0.30432167649269104, 0.6404784917831421, -0.08726964145898819, -0.15323498845100403, -0.29436251521110535, 0.4564841091632843, 1.291863203048706, 0.4206618368625641, -0.09325935691595078, -1.1110862493515015, 0.6848562359809875, -1.0389134883880615, -0.8526468276977539, 0.3852698802947998, 0.4051780700683594, 0.359392374753952, -0.48447978496551514, -0.23303250968456268, 0.012883898802101612, 0.5215539932250977, 0.7199166417121887, -0.5555014610290527, -1.2797126770019531, 0.07783838361501694, 0.5485607385635376, 0.727797269821167, 0.7975504398345947, -0.21048861742019653, 0.8131892085075378, 14.921614646911621, 0.8688857555389404, -0.46592769026756287, 0.33627548813819885, 0.6758447885513306, 0.03793812543153763, -0.6898570656776428, -0.27391719818115234, -1.4130340814590454, -0.17616261541843414, 1.2916827201843262, 0.039801258593797684, 0.6233921051025391, 0.419960618019104, 0.13507680594921112, 0.32340291142463684, -0.3417641818523407, 0.6703174114227295, 0.7237232327461243, -1.3732821941375732, 0.27428990602493286, 0.08446575701236725, -0.19522784650325775, 0.5434990525245667, 0.9048832058906555, 0.590454638004303, 0.7653754353523254, -0.5207273960113525, 0.796787440776825, -0.06624215096235275, 1.0443110466003418, -0.3181551694869995, 0.29417315125465393, 0.15707358717918396, -1.0104637145996094, 0.13433533906936646, -0.43521639704704285, -1.312157392501831, 0.10290784388780594, 0.4690645933151245, -0.8733180165290833, -0.5732681155204773, -0.2044149488210678, 1.1512792110443115, 0.4198282063007355, 0.10591691732406616, -0.17633768916130066, 0.6959531307220459, -0.07623925805091858, -0.3176223337650299, 0.7033051252365112, 0.49796822667121887, 0.2587299644947052, 0.20111142098903656, -0.12513233721256256, 0.03345458209514618, 0.03724117577075958, 0.475492924451828, -0.45875728130340576, -0.08159662038087845, -0.13719426095485687, -0.21498070657253265, 0.058539774268865585, 1.096158742904663, 0.2934335470199585, 0.3427317142486572, -0.3723416030406952, 0.18524116277694702, 0.7411142587661743, -0.04656299576163292, -0.46902674436569214, -0.16407658159732819, 0.4448082447052002, -0.41701364517211914, 0.12129277735948563, 0.6148518323898315, -0.4180596172809601, -0.3160761296749115, -0.8495259284973145, -0.602315366268158, 0.4249372184276581, -0.5306385159492493, -0.47412505745887756, 0.8751611113548279, -0.4223884642124176, -0.05632125213742256, 0.23167560994625092, -0.9340144991874695, -0.2497151494026184, 0.41286927461624146, -1.4356069564819336, -0.5112539529800415, 0.4158002436161041, -0.3269791603088379, -0.18264685571193695, 0.131021648645401, 1.210032343864441, 0.1343919336795807, -0.3608340620994568, 0.09319838136434555, 0.10760706663131714, 0.13810284435749054, -0.38057106733322144, -0.9530997276306152, 1.0185104608535767, 0.48297402262687683, -0.26218530535697937, 0.044606421142816544, 0.296760618686676, 0.478899210691452, -0.8016654849052429, -0.25982004404067993, 0.8696996569633484, -0.6378573775291443, 0.005431592930108309, -0.6208644509315491, -0.6137915849685669, 0.4135541021823883, 0.6198070645332336, -0.28213179111480713, 0.3322497010231018, 0.06393075734376907, -0.756683349609375, -0.188410222530365, -0.5470907688140869, 0.024543816223740578, 0.36528193950653076, -0.5518432259559631, -0.21497459709644318, -0.23745429515838623, 0.5916438102722168, -0.9548786878585815, -0.5130043625831604, -0.4951825439929962, 0.30871474742889404, -0.1385696828365326, 1.0080976486206055, -0.28234153985977173, 1.023740291595459, 1.3420450687408447, -0.13426697254180908, -0.7088815569877625, -0.07932073622941971, -0.7932568788528442, 0.056618716567754745, 0.17858724296092987, 0.4964067339897156, -0.49558690190315247, 0.4076700210571289, 0.7867216467857361, 0.1272871494293213, -0.5670417547225952, -0.570941150188446, -0.2613619863986969, 0.20947584509849548, -0.5355761647224426, 0.690082848072052, -0.21435494720935822, -0.16145801544189453, 0.3131442070007324, 0.4002910852432251, 0.28474119305610657, 0.05012606829404831, -0.5654083490371704, 0.08525195717811584, 0.24944956600666046, -0.15014219284057617, -0.6614279747009277, -0.5734774470329285, -1.4170289039611816, 0.19639527797698975, -1.3065390586853027, 0.11360985040664673, -0.9303703904151917, -0.2064797729253769, 0.048617828637361526, 0.005638048518449068, 0.5707898139953613, 0.1542147994041443, -0.4017195701599121, -0.4727138578891754, -0.5495763421058655, -0.5401909351348877, 0.925054669380188, 0.8613532781600952, -0.853358268737793, 0.5654761791229248, -0.4255485236644745, 0.26356348395347595, 0.02445557899773121, 0.40668240189552307, -0.3226941227912903, -0.6175948977470398, -1.4559261798858643, 0.22254377603530884, -0.05212509259581566, -0.03516342490911484, -0.5712466239929199, 0.5931177735328674, 0.2073351889848709, -0.4042382836341858, -0.0026656785048544407, 0.17624928057193756, -0.5910925269126892, -0.7274724245071411, 0.5891583561897278, -0.8405766487121582, 0.37861937284469604, 0.3045925199985504, -0.8070603609085083, 0.011731244623661041, 0.7246301174163818, -0.010371627286076546, -1.0028711557388306, -0.9061552286148071, 0.5007873177528381, -0.7389733195304871, 0.36596250534057617, -0.3140326738357544, -0.08940310031175613, -1.2901617288589478, -0.15545587241649628, 0.2484346330165863, 0.33059605956077576, -0.45443177223205566, 0.7827363610267639, 0.3458501994609833, -0.8572817444801331, 0.19185246527194977, 0.4155343174934387, -0.3463924825191498, 0.09461821615695953, 0.16173630952835083, 0.4144023358821869, -0.5270788073539734, 0.5925763845443726, -0.0005621049203909934, 0.06722258776426315, -1.1653029918670654, 0.09043632447719574, 0.6746693849563599, -0.8390001058578491, -0.28704389929771423, 1.0476701259613037, -0.6016958951950073, -0.8706169724464417, -0.05155311897397041, -1.0725772380828857, -0.5572341084480286, -0.424930602312088, 0.6295580863952637, 0.176276296377182, 0.24528852105140686, -0.15972474217414856, -0.667186975479126, -0.17130014300346375, -0.2830613851547241, -0.5788500905036926, 0.6292530298233032, 0.2106795758008957, -0.6068833470344543, 0.39295682311058044, 0.894961416721344, -0.7817398905754089, -0.5189006924629211, -0.7416556477546692, -0.48502710461616516, -0.06668628007173538, 0.45046839118003845, -0.1767817586660385, -0.7782750129699707, 0.9069289565086365, 0.07729081064462662, 0.4006248712539673, 0.03799103572964668, -0.44351595640182495, 0.4594857692718506, 0.5143327713012695, 0.06911421567201614, -0.24094222486019135, -0.43275028467178345, 1.7518411874771118, 0.7842060327529907, -0.4423394501209259, -0.03493872657418251, -0.12102300673723221, -0.5978188514709473, 0.9689139723777771, 0.3242669701576233, -0.01977710984647274, 0.7593876719474792, 0.4308735430240631, 0.13117988407611847, 0.15301960706710815, -1.1256821155548096, -0.3510518968105316, 0.5893646478652954, 0.8573602437973022, 0.9004274010658264, 0.17737719416618347, 0.15383292734622955, 0.7982854247093201, 0.0028613507747650146, -0.3189622163772583, 0.31443455815315247, 0.5319017171859741, -0.2944512367248535, -0.07973924279212952, -0.29387569427490234, 0.929755449295044, -0.8691988587379456, -1.060006022453308, 0.29382240772247314, 0.42516815662384033, -0.17158783972263336, 0.4003603160381317, 1.056916356086731, 0.16287104785442352, 0.35124751925468445, 0.0897277444601059, 0.34499692916870117, -0.46934574842453003, -0.5892987251281738, -0.2617492377758026, -0.6692190170288086, -0.2475358098745346, -0.004747641272842884, -0.408660352230072, -0.8170320987701416, -0.6089882850646973, 0.4771521985530853, 0.1599203497171402, 0.26059019565582275, 1.130245327949524, 0.26044031977653503, 0.8706344962120056, -0.35887762904167175, -0.5804737210273743, -0.42286181449890137, -0.7058520913124084, 0.184793621301651, -0.49445435404777527, -0.07039952278137207, 0.08884776383638382, -0.30779293179512024, -0.10460792481899261]}, "authors": [{"authorId": "2072522551", "name": "Yujia Zhai"}, {"authorId": "2187146820", "name": "Chengquan Jiang"}, {"authorId": null, "name": "Leyuan Wang"}, {"authorId": "145714181", "name": "Xiaoying Jia"}, {"authorId": "2145443268", "name": "Shang Zhang"}, {"authorId": "2117097570", "name": "Zizhong Chen"}, {"authorId": "89121677", "name": "Xin Liu"}, {"authorId": "2176234169", "name": "Yibo Zhu"}], "references": [{"paperId": "417f61a186936e07942755b1c2e6ff45f8b01129", "title": "Boosting Distributed Training Performance of the Unpadded BERT Model"}, {"paperId": "c022f75b00d795c6297d6a9ea948856ea4d365a1", "title": "DeepSpeed- Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "b7b3343b45c785ccab1c94beecc28ea91e041685", "title": "E.T.: Re-Thinking Self-Attention for Transformer Models on GPUs"}, {"paperId": "952305d9bbdaeaf7adb7ef12b94f221570c5d52d", "title": "LightSeq2: Accelerated Training for Transformer-Based Models on GPUs"}, {"paperId": "4b17dcd4546168675bcf7308e6d8f8d78b15191a", "title": "Accelerating Encrypted Computing on Intel GPUs"}, {"paperId": "a7baf0a12e2d1eb339b09b3a11ba33c75dee109a", "title": "FT-BLAS: a high performance BLAS implementation with online fault tolerance"}, {"paperId": "0c775d7ed34fb4690b4291490778649ae75c48d2", "title": "TurboTransformers: an efficient GPU serving system for transformer models"}, {"paperId": "725264948d7b6946259af5b8d966e996b9570f99", "title": "DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3", "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "5eda6d680dc1360e6d1b835c236a91f9dd1918fc", "title": "Behavior sequence transformer for e-commerce recommendation in Alibaba"}, {"paperId": "690edf44e8739fd80bdfb76f40c9a4a222f3bba8", "title": "BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "1eb09fecd75eb27825dce4f964b97f4f5cc399d7", "title": "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches"}, {"paperId": "1554887c6bd76c443a477b27dbcab35877787b27", "title": "LightSeq: A High Performance Inference Library for Transformers"}, {"paperId": null, "title": "Algorithm-based fault tolerance for convolutional neural networks"}, {"paperId": "b20ccccf9302c2da62bc42b30b44d042fdb6e167", "title": "Recent R&D Trends for Pretrained Language Model"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Understanding backtranslation at scale"}, {"paperId": "6a630ac89d7c0a57eb7bf4cb30dd5946bcf3ccce", "title": "google,\u6211,\u8428\u5a1c"}, {"paperId": null, "title": "Longformer: The longdocument transformer"}, {"paperId": "4954fa180728932959997a4768411ff9136aac81", "title": "This Paper Is Included in the Proceedings of the 12th Usenix Symposium on Operating Systems Design and Implementation (osdi '16). Tensorflow: a System for Large-scale Machine Learning Tensorflow: a System for Large-scale Machine Learning"}, {"paperId": null, "title": "NVIDIA"}, {"paperId": null, "title": "Accelerating fault-tolerant blas on x86 cpus"}]}