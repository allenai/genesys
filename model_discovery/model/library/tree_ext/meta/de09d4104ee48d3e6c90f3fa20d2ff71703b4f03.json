{"paperId": "de09d4104ee48d3e6c90f3fa20d2ff71703b4f03", "title": "Transformer with a Mixture of Gaussian Keys", "abstract": ",", "venue": "arXiv.org", "year": 2021, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": null}, "embedding": {"model": "specter_v2", "vector": [0.2546733319759369, 0.5560017228126526, -0.20405976474285126, 0.27086779475212097, -0.5617629289627075, -0.37515851855278015, 0.7458158135414124, -0.37576013803482056, 0.013669531792402267, -0.4655565619468689, 0.3321320116519928, -0.08768163621425629, -0.05777279660105705, -0.4731487035751343, -0.31797534227371216, -0.48286712169647217, -0.7397294640541077, 0.6368380188941956, 0.08376822620630264, 0.014099313877522945, -0.18080180883407593, -0.7240117192268372, -0.9400994181632996, 0.043764762580394745, 0.0015954781556501985, 1.2100944519042969, 0.07442528009414673, 1.0379828214645386, -0.5251749753952026, 0.6323156952857971, 0.7676733136177063, -0.6940646767616272, 0.6724928617477417, 0.08034561574459076, 0.18665680289268494, -0.10473306477069855, 0.5921341180801392, -0.5562071204185486, -0.6786887645721436, 0.8763146996498108, -0.06697089225053787, -0.1695849448442459, 0.18858981132507324, -1.466717004776001, -0.09599033743143082, 0.9190210700035095, 0.9185460805892944, -0.11873111128807068, -0.37579065561294556, -1.2093449831008911, 1.4411110877990723, -0.7209296822547913, 0.000917233934160322, 1.523694396018982, 0.5199393033981323, 0.15462645888328552, -0.6120187640190125, -0.7379694581031799, 0.2831459641456604, 0.03819689899682999, -0.653839111328125, -0.007421031594276428, 5.7156717957695946e-05, 0.04223068058490753, 1.022634744644165, -0.2509312331676483, 0.17853862047195435, 0.35663333535194397, -0.028596647083759308, 1.2644586563110352, 0.5799033641815186, -0.8015632629394531, -0.03907104954123497, 0.8688949346542358, 0.2456560730934143, 0.5273444056510925, -0.441511869430542, 0.45975762605667114, -0.8518788814544678, -0.7085147500038147, 0.2642157971858978, 0.3050200939178467, 0.013933541253209114, -1.1549127101898193, 0.09715962409973145, 0.8144189119338989, -0.06770950555801392, 0.5692495107650757, -0.13566993176937103, 1.0753895044326782, 0.22554610669612885, 0.2844887375831604, -0.3248056471347809, 0.11223842948675156, 0.16839978098869324, 0.4353451132774353, -0.49195316433906555, 0.12267883121967316, 0.2741905748844147, 1.0068567991256714, -0.1437475085258484, 0.17138104140758514, -0.41292697191238403, -0.004205232486128807, 1.7239128351211548, 0.2559891641139984, 0.2215874344110489, -0.5549530386924744, -0.4064001739025116, -0.8329521417617798, -0.07057107239961624, -0.4705861806869507, 0.2607947587966919, 0.0626123696565628, -0.4606702923774719, -0.7468723654747009, -0.23621727526187897, 0.359923392534256, -1.293294906616211, 0.6840651631355286, -0.5931114554405212, 0.06817296147346497, 0.48233896493911743, -0.35335227847099304, 0.465300977230072, 0.6745634078979492, 0.08228608220815659, 0.07754191011190414, 0.9340675473213196, -0.3404809832572937, -1.0316858291625977, -0.12819808721542358, 0.07386773824691772, -0.6292037963867188, -0.3281515836715698, 0.29737553000450134, -0.849022626876831, -1.0363471508026123, -0.7914403676986694, 0.47835642099380493, -0.5356888175010681, 0.09795363992452621, 1.1663386821746826, 1.3967171907424927, -1.424116611480713, 0.16407546401023865, -0.2676391899585724, -0.7177478075027466, 0.23706190288066864, 0.5309162735939026, -0.058733079582452774, -0.2973020076751709, -0.9892101287841797, 0.36985495686531067, 0.7731897234916687, -1.1381531953811646, -0.20837557315826416, -0.5801960229873657, -0.6251810789108276, -0.049827754497528076, 0.1814536303281784, -0.6493808627128601, 0.9248647689819336, 0.7746706008911133, -1.293618083000183, 0.1582593321800232, 0.07665067166090012, -0.06035647541284561, 0.11077133566141129, 0.19577756524085999, -0.5652986764907837, -0.5786169767379761, -0.2968965470790863, 0.2821555435657501, 0.6718541383743286, -0.4959959089756012, -0.5235121250152588, -0.2010795623064041, -0.29166287183761597, -0.03157934546470642, -0.6210257411003113, 0.9332749843597412, -0.2720852196216583, -0.4215131103992462, 0.7612614035606384, 0.3020721971988678, -0.2518342435359955, -0.3775647282600403, -0.4794169068336487, -0.6100290417671204, 0.8813888430595398, 0.18364723026752472, 0.7531774640083313, -0.6009355783462524, -0.6849326491355896, 0.25080394744873047, -0.4594825506210327, -0.5810912847518921, -0.4840705096721649, 0.7248981595039368, -0.9962059855461121, 0.18916916847229004, 0.12869995832443237, -0.6995933651924133, 0.19640354812145233, -0.09609709680080414, -0.8657783269882202, -0.21014176309108734, -0.43095579743385315, 0.5769078135490417, -0.607979953289032, 0.7872794270515442, 0.34757861495018005, 0.09470275044441223, -0.8078345656394958, 1.3329217433929443, -0.03608766570687294, -0.2217649221420288, 0.25993016362190247, -0.06582175195217133, 0.7180244326591492, 0.12953738868236542, 0.39998072385787964, -0.845490038394928, 0.36961260437965393, 0.33558937907218933, -1.2149910926818848, 1.4079068899154663, -0.07600657641887665, -0.20065529644489288, 0.4255687892436981, -0.9508242011070251, 0.17134074866771698, 0.7890682220458984, 0.13116544485092163, -0.12611885368824005, 0.3706294596195221, 0.5785055756568909, -0.4625754654407501, 0.5976584553718567, 0.3936041295528412, 0.5260300040245056, -0.15873049199581146, 0.4527831971645355, 1.031960129737854, -0.8763924837112427, 0.02869051694869995, 0.5118512511253357, 0.43462690711021423, -0.130494624376297, 0.16116367280483246, -0.26046299934387207, 0.1095379889011383, -1.2130953073501587, -0.5812240242958069, 0.6956918835639954, 0.9400713443756104, 0.7980086207389832, 0.17130792140960693, -0.590506374835968, -0.05554661899805069, -0.9607637524604797, 0.5533922910690308, 0.9703517556190491, -0.34737324714660645, -0.6863276958465576, -0.23495353758335114, -0.24631938338279724, -0.17290036380290985, 0.21562699973583221, -0.16729168593883514, -0.28433868288993835, -0.33608385920524597, -1.1393284797668457, 0.7315301299095154, 0.3522113561630249, 0.8169791102409363, -0.04966895654797554, 0.06672503799200058, -0.12706802785396576, 0.6502095460891724, -0.565434992313385, -0.4459288716316223, 0.8117903470993042, -0.35572972893714905, -0.41845253109931946, -0.06438612937927246, -0.22928772866725922, 0.2821875214576721, -0.9023101925849915, 0.4363245964050293, -1.2368766069412231, -0.013686992228031158, 0.6463322639465332, 0.6588934063911438, -0.8820387125015259, -0.906477153301239, -0.42011651396751404, 0.2538168728351593, -0.0339268296957016, 0.2519080340862274, -0.23893986642360687, 0.29248368740081787, -0.11051589995622635, -0.760114848613739, -0.05121677368879318, -0.045940250158309937, 0.4115981161594391, 0.27394723892211914, 0.28063562512397766, -0.42008307576179504, -0.8754727840423584, 1.363418459892273, 0.3745223879814148, -0.42684608697891235, -0.001054664608091116, -0.9971243143081665, -0.10346522927284241, 0.3769770562648773, -0.3253246247768402, 0.06702163070440292, -0.5619639158248901, 0.05753887817263603, -0.6099254488945007, -0.08419094979763031, -0.1074603945016861, -0.16828812658786774, -0.05007254704833031, -0.09373152256011963, 0.9869481921195984, 0.47263863682746887, 0.0650455504655838, 1.2483781576156616, -0.6247007846832275, 0.6993558406829834, 0.005419017281383276, 0.33459094166755676, 0.08807191997766495, -0.10152425616979599, -0.06268113106489182, 0.7610697150230408, 0.004704642575234175, 0.19355536997318268, -0.19903512299060822, -0.24429622292518616, -0.6883369088172913, -0.5961444973945618, 0.7565312385559082, -0.5583807826042175, 0.4706958532333374, -0.07250792533159256, -0.03695781156420708, -0.6255427002906799, -1.0601999759674072, -1.1334737539291382, -0.6632835268974304, -0.5438876748085022, -0.9459527730941772, -0.2466740608215332, 0.4504195749759674, -0.004902624059468508, -0.2291426807641983, -0.30102041363716125, -0.19813622534275055, 1.3931002616882324, -1.0332034826278687, 0.7138748168945312, -0.8577188849449158, -0.7927101850509644, -0.5792019367218018, 0.3412783741950989, 0.6536073684692383, 0.44330915808677673, 0.2047816514968872, -0.5297638177871704, 0.08421943336725235, 0.02378038689494133, -0.37950801849365234, -0.05990591272711754, 0.4999639689922333, 1.0669883489608765, 0.06555532664060593, -0.452030748128891, 0.563774049282074, 0.9771145582199097, 0.07670678943395615, 0.3384561836719513, -0.18177373707294464, 1.0675464868545532, -0.007490820251405239, -0.37237870693206787, 0.3493354618549347, 0.45522481203079224, 0.5906627774238586, 0.18222571909427643, 0.5089350342750549, 0.21120233833789825, -0.3055782914161682, 0.18775412440299988, 1.1060658693313599, 0.35753506422042847, -0.19054539501667023, -0.4009568393230438, 0.5091175436973572, -0.9291701316833496, -0.7580340504646301, 1.2855863571166992, 1.0505740642547607, 0.0733962133526802, -0.19471098482608795, -0.07051167637109756, 0.23596470057964325, 0.7292025089263916, 0.27238669991493225, 0.3088921010494232, -0.5816313624382019, 0.10493168979883194, 1.0916004180908203, 0.7752127051353455, 0.7153776288032532, -0.3304632604122162, 0.29436051845550537, 15.169049263000488, 0.835115909576416, -0.0513773150742054, 0.3099949061870575, 0.007277753669768572, 0.3694860339164734, -0.4638214409351349, 0.22815059125423431, -1.0149098634719849, 0.4032225012779236, 1.2505488395690918, 0.14058023691177368, 0.677774965763092, 0.238811656832695, -0.6178926825523376, 0.10980243235826492, -0.4938507676124573, 0.7936148643493652, 0.6714180111885071, -1.2156857252120972, 0.21044756472110748, 0.5616768002510071, 0.049792300909757614, 0.05204903706908226, 0.8188643455505371, 0.6008413434028625, 0.7996216416358948, -0.386904776096344, 0.5977370142936707, -0.00472652493044734, 0.35466527938842773, -0.462076872587204, 0.03774314746260643, 0.0019121021032333374, -1.0421515703201294, -0.2600391209125519, -0.1254754513502121, -0.5337157845497131, 0.44111311435699463, 0.22355005145072937, -0.24325591325759888, -0.15729258954524994, 0.22750861942768097, 0.021387042477726936, 0.6586247086524963, 0.45466718077659607, 0.0713576078414917, 0.3350672721862793, -0.859462320804596, 0.3883174955844879, -0.2662772834300995, 0.3020927906036377, 0.28533056378364563, -0.5535695552825928, 0.4627824127674103, -0.010275520384311676, 0.2670730650424957, 0.3017130196094513, -0.2763555645942688, -0.11563760042190552, -0.2571534216403961, -0.658145546913147, 0.0009779931278899312, 1.0128720998764038, 0.14835256338119507, -0.052475519478321075, -0.18376201391220093, 0.49093911051750183, -0.16052769124507904, -0.1017371267080307, -0.1999138444662094, -0.15683802962303162, 0.4572821855545044, -0.30299821496009827, 0.012342697940766811, 0.8655905723571777, -0.10947804898023605, -0.24002578854560852, -0.8646368980407715, -0.48623189330101013, 0.5241618752479553, -0.7229328155517578, -0.8124505877494812, 0.7227473258972168, -0.147775337100029, -0.2727343440055847, 0.5061850547790527, -0.8049588799476624, -0.6410369873046875, 0.6847511529922485, -0.7452822923660278, -1.0894681215286255, 0.2507537603378296, -0.030700329691171646, -0.748071014881134, -0.21990153193473816, 1.2746580839157104, 0.030357830226421356, 0.15055519342422485, 0.00955138634890318, -0.029288705438375473, -0.42911776900291443, 0.2731967270374298, -1.1997021436691284, 0.8054931163787842, 0.15361589193344116, 0.3282013237476349, 0.5629366040229797, 0.16440743207931519, 0.1051398366689682, -0.5220914483070374, 0.48255839943885803, 0.22769147157669067, -0.6665452718734741, -0.09003230184316635, -0.8521573543548584, -0.5349570512771606, 0.44106587767601013, 0.7265202403068542, -0.33989986777305603, 0.5891623497009277, -0.17915046215057373, -0.3808215260505676, -0.41417747735977173, -0.8588453531265259, -0.3979882597923279, 0.5017121434211731, -1.086898922920227, -0.30961379408836365, 0.2821587026119232, -0.2628794014453888, -1.0620030164718628, -0.9234602451324463, 0.34486624598503113, 0.46561935544013977, -0.14581653475761414, 1.3861645460128784, -0.3897978663444519, 0.04732086509466171, 0.4637924134731293, -0.6140046119689941, -1.0286719799041748, -0.2015531212091446, -0.7133223414421082, -0.196090430021286, 0.23353400826454163, -0.02270798571407795, -0.528936505317688, 0.640984833240509, 0.5904924273490906, 0.3215358257293701, -0.39572873711586, -0.5137006640434265, -0.2890312969684601, -0.2296389937400818, -0.7597401142120361, 0.16809552907943726, -0.3455466330051422, -0.18107850849628448, -0.21735785901546478, 0.10320122539997101, 0.5496248602867126, 0.1914418786764145, -0.7139608263969421, 0.7189252972602844, -0.2503437399864197, 0.04314924031496048, -0.6516208052635193, -1.177586317062378, -1.31201171875, -0.09134039282798767, -1.0809228420257568, -0.08197891712188721, -1.255010962486267, -0.388287752866745, -0.12394021451473236, -0.6731160283088684, -0.260398805141449, 0.2757299840450287, -0.3269484341144562, -0.32105761766433716, -0.6768171787261963, 0.19829149544239044, 0.46137431263923645, -0.098201684653759, -0.9122840166091919, 0.2324322760105133, 0.34809350967407227, -0.31070467829704285, 0.2629278302192688, 0.3533231019973755, -0.23949220776557922, -0.9280627965927124, -0.48219501972198486, -0.049712833017110825, -0.4273434281349182, -0.25034451484680176, -1.2212753295898438, 0.8464429378509521, 0.7946252226829529, -0.0060861255042254925, -0.3004360496997833, 0.7247635126113892, -1.2659658193588257, 0.5191653370857239, 0.44682976603507996, -0.427325963973999, -0.10143213719129562, -0.26371270418167114, -0.374849408864975, -0.2981938421726227, 0.8411015272140503, -0.02196742780506611, -1.0871394872665405, -0.4774238169193268, 0.5381689667701721, -0.5193323493003845, -0.2410491555929184, 0.3509275019168854, -0.29437118768692017, -0.7183042764663696, -0.42664510011672974, -0.4118105173110962, 0.08319970965385437, 0.06831640750169754, 1.027806282043457, 0.1589418202638626, -1.3597737550735474, 0.49516454339027405, 0.8359864354133606, -0.11232082545757294, -0.3716617226600647, 0.16628257930278778, 0.27919214963912964, -0.28260356187820435, 0.5521870851516724, -0.1547117382287979, 0.16933299601078033, -1.0542757511138916, -0.010558659210801125, 0.36946776509284973, -0.25632330775260925, 0.0012564827920868993, 1.370698094367981, -0.6943423748016357, -1.0509521961212158, 0.4889090359210968, -1.1166110038757324, -0.4977301061153412, -0.0209386944770813, 0.5499875545501709, -0.058456555008888245, 0.0942777618765831, -0.06365759670734406, -0.2492438554763794, 0.38524672389030457, 0.09151865541934967, -0.6781219840049744, -0.1469489187002182, -0.21696238219738007, -0.5811179280281067, 0.20001250505447388, 0.42943280935287476, -0.1479272097349167, -0.02216026559472084, -0.3959311842918396, -0.9066190123558044, -0.46025726199150085, 0.03435704857110977, -0.055181991308927536, -0.9698446989059448, 0.25892725586891174, 1.2828325033187866, 0.5785544514656067, 0.07803396135568619, 0.07310017943382263, -0.05902605503797531, 0.1828058660030365, 0.39544835686683655, -0.06716549396514893, -0.5606071949005127, 0.9261581897735596, 0.5936681628227234, -0.44599390029907227, 0.11519382148981094, -0.5049413442611694, -0.30636709928512573, 0.8961554765701294, 0.2170560508966446, 0.0788867399096489, 1.1486408710479736, 0.211867555975914, 0.29417669773101807, 0.42324531078338623, -0.5186808705329895, -0.4096784293651581, 0.20544840395450592, 1.3673062324523926, 0.3921694755554199, 0.4317968785762787, 0.07573442161083221, 0.7155028581619263, -0.10971663892269135, 0.02538357302546501, 0.5714710354804993, 0.8813671469688416, -0.1244395449757576, -1.0112947225570679, -0.3479408025741577, 1.000270128250122, -0.9395217299461365, -0.5942807197570801, 0.35840433835983276, 0.41236236691474915, 0.4920795261859894, 0.5197951793670654, 0.7854801416397095, -0.7246257662773132, 0.5358490943908691, 0.4684915840625763, 0.9097815155982971, -0.09423042833805084, 0.15020698308944702, -0.30839815735816956, -0.6010870337486267, -0.1456165462732315, -0.36897969245910645, -0.2877042889595032, -0.09579379111528397, -0.17756955325603485, -0.28703922033309937, 0.08841023594141006, 0.3210626542568207, 0.4814659357070923, 0.33152031898498535, 0.31755685806274414, -0.2504807114601135, -0.2155735045671463, -0.706183910369873, -0.9329968690872192, -0.2811439335346222, -0.4201592206954956, -0.7436597943305969, -0.18913601338863373, -0.021191857755184174, -0.3910764157772064]}, "authors": [{"authorId": "2116488139", "name": "Tam Nguyen"}, {"authorId": "150322732", "name": "T. Nguyen"}, {"authorId": "2134814752", "name": "Dung D. Le"}, {"authorId": "30813132", "name": "Khuong N. Nguyen"}, {"authorId": "145830668", "name": "A. Tran"}, {"authorId": "144908066", "name": "Richard Baraniuk"}, {"authorId": "3526349", "name": "Nhat Ho"}, {"authorId": "1782265", "name": "S. Osher"}], "references": [{"paperId": "37abe53ed31caa23ae833b2e67bb4aa1892e8d25", "title": "FMMformer: Efficient and Flexible Transformer via Decomposed Near-field and Far-field Attention"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "372cce47fa16c538946972e6a7ac8420e64000b0", "title": "Challenges in Information-Seeking QA: Unanswerable Questions and Paragraph Retrieval"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "9f0272bb258506fdc0ee7d8951593914d4f9c39d", "title": "Analyzing Individual Neurons in Pre-trained Language Models"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "61325245e98920a69b40e18c069fda0c1cf00f21", "title": "MEANTIME: Mixture of Attention Mechanisms with Multi-temporal Embeddings for Sequential Recommendation"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "b70252f0de1c7832fdd6c862af35f6667349fe55", "title": "Transformer VAE: A Hierarchical Model for Structure-Aware and Interpretable Music Representation Learning"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "3b504f939e55d567652737ef093c1087cd40689b", "title": "Analyzing Redundancy in Pretrained Transformer Models"}, {"paperId": "2b9955bc08fc5f4ddba73082ddabcfaabdbb4416", "title": "Poor Man's BERT: Smaller and Faster Transformer Models"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "199ff73d2f728e997f860b62a2322823d3e3d9e8", "title": "Designing and Interpreting Probes with Control Tasks"}, {"paperId": "9d7902e834d5d1d35179962c7a5b9d16623b0d39", "title": "How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings"}, {"paperId": "8cef9900c04d7f661c08f4b5b1ed4337ace042a3", "title": "Transformer Dissection: An Unified Understanding for Transformer\u2019s Attention via the Lens of Kernel"}, {"paperId": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf", "title": "Patient Knowledge Distillation for BERT Model Compression"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "84898960f68fa78296a102edc8ac81739f9a9408", "title": "Gaussian Transformer: A Lightweight Approach for Natural Language Inference"}, {"paperId": "830995ef17cc291c13f42dfd9f462137de1d2179", "title": "Augmenting Self-attention with Persistent Memory"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "95a251513853c6032bdecebd4b74e15795662986", "title": "What Does BERT Look at? An Analysis of BERT\u2019s Attention"}, {"paperId": "a039ea239e37f53a2cb60c68e0a1967994353166", "title": "Analyzing the Structure of Attention in a Transformer Language Model"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "97906df07855b029b7aae7c2a1c6c5e8df1d531c", "title": "BERT Rediscovers the Classical NLP Pipeline"}, {"paperId": "b03c7ff961822183bab66b2e594415e585d3fd09", "title": "Are Sixteen Heads Really Better than One?"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "16c844fd4d97f3c6eb38b0d6527c87d184efedc3", "title": "The Evolved Transformer"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "5f4a22ee70ca613d9c0630eafc96364fe365fdf8", "title": "Efficient Attention: Attention with Linear Complexities"}, {"paperId": "374aac3e3a9e40ac80f2e74615ef4ac4dc66c17c", "title": "A Bayesian Perspective of Convolutional Neural Networks through a Deconvolutional Generative Model"}, {"paperId": "b9de9599d7241459db9213b5cdd7059696f5ef8d", "title": "Character-Level Language Modeling with Deeper Self-Attention"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "8b354d76813bd5375e7e5c8d17f630bec5936a01", "title": "ListOps: A Diagnostic Dataset for Latent Tree Learning"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "1e077413b25c4d34945cc2707e17e46ed4fe784a", "title": "Universal Language Model Fine-tuning for Text Classification"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "204a4a70428f3938d2c538a4d74c7ae0416306d8", "title": "A Structured Self-attentive Sentence Embedding"}, {"paperId": "a2d407962bb1f5fcd209114f5687d4c11bf9dfad", "title": "All-but-the-Top: Simple and Effective Postprocessing for Word Representations"}, {"paperId": "13d9323a8716131911bfda048a40e2cde1a76a46", "title": "Structured Attention Networks"}, {"paperId": "b341e2bfc451b73927ee1b5f270d216b86fba349", "title": "A Probabilistic Framework for Deep Learning"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "2cd8e8f510c89c7c18268e8ad51c061e459ad321", "title": "A Decomposable Attention Model for Natural Language Inference"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e", "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "e01eae8dea6fbaa1ae7fc83535053932268df430", "title": "The ACL anthology network corpus"}, {"paperId": "bc6dff14a130c57a91d5a21339c23471faf1d46f", "title": "Et al"}, {"paperId": "7826ff60d2dfb24d2af18c5bc565c357ef9db4c1", "title": "A stochastic version of the delta rule"}, {"paperId": "9241ea3d8cb85633d314ecb74b31567b8e73f6af", "title": "Least squares quantization in PCM"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Set transformer: A framework for attention-based permutation-invariant neural networks"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": "0c9d3c8734b273880f1e9a8675d192064fe26eb0", "title": "Pattern Recognition"}, {"paperId": null, "title": "Universal language model \ufb01ne-tuning for text classi\ufb01cation"}, {"paperId": null, "title": "We construct a GMM and show that attention scores in self-attention match posterior distribution in our model, providing a probabilistic framework to study self-attention in transformers"}, {"paperId": null, "title": "We extend our MGK to use with linear attentions and propose the mixture of linear keys (MLK) for e\ufb03cient computation and better memory footprint"}, {"paperId": null, "title": "associated token, to attend to more diverse positions in the input sequence, thereby increasing the representation of each attention head and reducing the chance of learning redundant heads"}]}