{"paperId": "1c0b3679919cd0531973fced1a1eb49745d9332d", "title": "Instruction-tuned Language Models are Better Knowledge Learners", "abstract": "In order for large language model (LLM)-based assistants to effectively adapt to evolving information needs, it must be possible to update their factual knowledge through continued training on new data. The standard recipe for doing so involves continued pre-training on new documents followed by instruction-tuning on question-answer (QA) pairs. However, we find that LLMs trained with this recipe struggle to answer questions, even though the perplexity of documents is minimized. We found that QA pairs are generally straightforward, while documents are more complex, weaving many factual statements together in an intricate manner. Therefore, we hypothesize that it is beneficial to expose LLMs to QA pairs before continued pre-training on documents so that the process of encoding knowledge from complex documents takes into account how this knowledge is accessed through questions. Based on this, we propose pre-instruction-tuning (PIT), a method that instruction-tunes on questions prior to training on documents. This contrasts with standard instruction-tuning, which learns how to extract knowledge after training on documents. Extensive experiments and ablation studies demonstrate that pre-instruction-tuning significantly enhances the ability of LLMs to absorb knowledge from new documents, outperforming standard instruction-tuning by 17.8%.", "venue": "arXiv.org", "year": 2024, "citationCount": 11, "influentialCitationCount": 5, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Pre-instruction-tuning (PIT) is proposed, a method that instruction-tunes on questions prior to training on documents so that the process of encoding knowledge from complex documents takes into account how this knowledge is accessed through questions."}, "embedding": {"model": "specter_v2", "vector": [-0.021050428971648216, 0.6803622841835022, -0.39806032180786133, -0.1636105626821518, -0.4134129285812378, -0.6206917762756348, 0.6371721625328064, 0.01516090426594019, -0.627985954284668, -0.006105127744376659, 0.5968976616859436, -0.429464727640152, 0.05920543149113655, 0.17351451516151428, -0.3022826910018921, 0.5427931547164917, -0.9191175699234009, 0.660963237285614, 0.051369618624448776, -0.7066728472709656, -0.29141268134117126, -0.8664917945861816, -0.9417554140090942, 0.396199494600296, 0.8768420815467834, -0.14469808340072632, 0.2624497413635254, 1.1256916522979736, -0.6210517883300781, 0.46950802206993103, 0.483622670173645, -0.3152288496494293, -0.07016268372535706, 0.13107867538928986, -0.34818968176841736, -0.27908697724342346, 0.657319188117981, -0.8783405423164368, -0.4123305678367615, 0.4339946508407593, -0.38154125213623047, -0.04067302122712135, 0.5976748466491699, -0.3827928900718689, -0.4304020404815674, 0.5338217616081238, 0.9679611921310425, 0.752471923828125, -0.07013510912656784, -0.6946030259132385, 1.2687079906463623, -1.4319924116134644, 0.3620988130569458, 1.283796787261963, 0.6457558274269104, 0.7072983384132385, -0.15357705950737, -0.45445576310157776, 0.7182040214538574, -0.06416438519954681, -0.6043151617050171, -0.4710806608200073, -0.5231969356536865, -0.3112950921058655, 1.93722403049469, -0.2994052469730377, -0.26422059535980225, -0.07878262549638748, 0.18634198606014252, 1.5583178997039795, -0.1947898119688034, -0.89881432056427, -0.523180365562439, 0.6724711060523987, 0.29504936933517456, 1.2410515546798706, -0.37993085384368896, 0.49549949169158936, -0.6899667382240295, 0.013792352750897408, 0.9315488934516907, -0.10758300125598907, -0.4548923969268799, -0.1547640711069107, -0.556178867816925, 0.7264387607574463, 0.2558661997318268, 1.2181826829910278, -0.30249717831611633, 0.38003504276275635, 0.239421084523201, 0.8300247192382812, -0.4594145715236664, 0.7550185322761536, -0.8371868133544922, 0.28418949246406555, -0.519662082195282, 0.24752703309059143, 0.38366711139678955, 0.6814333200454712, 0.3787761330604553, -0.27118366956710815, -1.0403194427490234, 0.1740482747554779, 1.227743148803711, -0.05423855409026146, 0.5437865853309631, -0.6231429576873779, 0.6137528419494629, -0.259702205657959, 0.8684636950492859, -0.46054771542549133, -0.6462903618812561, -0.37253087759017944, -0.34965845942497253, -1.3702778816223145, -0.15805453062057495, -0.14057277143001556, -0.8416039943695068, 0.8607691526412964, -0.21107721328735352, -0.09526636451482773, 0.15494267642498016, 0.44036686420440674, 0.7101616263389587, 0.5699058175086975, 0.30983173847198486, -0.06403995305299759, 0.8918930888175964, -0.7739279866218567, -0.8366438150405884, -1.371281623840332, 1.1231846809387207, 0.059099532663822174, 0.5888882279396057, -0.4979470670223236, -1.217622995376587, -1.094961404800415, -1.0600206851959229, 0.011669530533254147, -0.587531566619873, 0.40276363492012024, 1.1644138097763062, 0.4674728810787201, -1.0889478921890259, 0.4395561218261719, -0.15479019284248352, -0.30173540115356445, -0.18875299394130707, 0.389297217130661, 0.302804559469223, -0.792847216129303, -1.3051055669784546, 0.3210456669330597, 0.6593998670578003, -1.0882550477981567, -0.5024625658988953, -0.7536669969558716, -1.104123592376709, -0.07934952527284622, 0.6554891467094421, -0.8759445548057556, 1.5301222801208496, -0.19579178094863892, -0.9067713618278503, 0.3923846483230591, -0.38680070638656616, 0.4940268099308014, 0.06909944117069244, -0.08742179721593857, -0.7255712151527405, -0.15817582607269287, -0.122758649289608, 0.4479030966758728, 0.4309001863002777, -0.7040911316871643, -0.5596294403076172, 0.05575517565011978, 0.3022162616252899, 0.019508322700858116, -0.6048679947853088, 0.3678319752216339, -0.5647177696228027, -0.18673516809940338, 0.3633230924606323, 1.0222692489624023, 0.2509140968322754, -0.09366898983716965, 0.16685792803764343, -0.9082366228103638, 0.5262801051139832, -0.36983901262283325, 1.340219497680664, -0.8938150405883789, -0.5289372205734253, -0.19481161236763, 0.14124715328216553, 0.16130036115646362, -1.0700116157531738, 0.6653990149497986, -0.08053219318389893, 0.39878615736961365, -0.33257725834846497, -0.8426113724708557, 0.3013627827167511, -0.059886593371629715, -0.7000508308410645, -0.9573793411254883, 0.30594751238822937, 1.3935837745666504, -0.8274698853492737, 0.14265933632850647, -0.2496175467967987, 0.17360720038414001, -0.9993354678153992, 1.3654004335403442, -0.9810359477996826, 0.32171395421028137, -0.24614495038986206, -0.3277137577533722, -0.018309876322746277, -0.19905276596546173, 0.15978658199310303, -0.3577100932598114, 0.0018782850820571184, 0.10216168314218521, -0.3938446640968323, 1.4063704013824463, -0.6473701596260071, 0.0915011465549469, 0.15271379053592682, -0.35959306359291077, 0.043773096054792404, 0.7312093377113342, -0.43479791283607483, -0.3109841048717499, -0.12783214449882507, 0.3945556581020355, -0.6766713857650757, -0.4434898793697357, 0.5852276086807251, 0.2951991856098175, -0.21055422723293304, 0.4283663034439087, 0.5229288935661316, -0.4679886996746063, 0.6956915855407715, 0.5287168622016907, 0.9820472002029419, 0.1553722769021988, 0.4455534815788269, 0.21713043749332428, 0.6651580333709717, -0.38358598947525024, -0.34445425868034363, 0.4481872320175171, 0.7590787410736084, 0.1655532568693161, -0.04901891574263573, -0.8640347719192505, -0.07112853974103928, -0.030666900798678398, 0.5802303552627563, 1.9221522808074951, -0.5127999782562256, -0.3818680942058563, -0.6430881023406982, -0.8117749691009521, -0.0644175186753273, 0.7357873916625977, -0.546600878238678, -0.2936314046382904, -0.546298086643219, -0.6074759364128113, 0.31160783767700195, 0.5440207719802856, 1.3226706981658936, -0.3898404836654663, -0.1709093600511551, 0.1304563730955124, 0.03745549917221069, -0.43276575207710266, -0.7229210734367371, 0.2826245427131653, -0.5993059873580933, -0.3059423565864563, 0.2580534517765045, -0.44369998574256897, 0.41325631737709045, -0.4976794123649597, 1.3193655014038086, 0.20592260360717773, 0.07352401316165924, 0.9153481125831604, 0.5180547833442688, -0.7242478132247925, -0.9293150305747986, 0.10413195937871933, 0.010451914742588997, -0.5557963252067566, 0.5461239218711853, 0.717179536819458, 0.3263833820819855, 0.5351639986038208, -0.9991464018821716, 0.18669621646404266, 0.5221042633056641, 0.1749429553747177, 0.5331953763961792, -0.09894810616970062, 0.5128902792930603, -1.4613218307495117, 0.9853599071502686, 0.24709197878837585, -0.19081348180770874, 0.8341681957244873, -0.6177058219909668, -0.06680052727460861, 0.6629952788352966, -0.4722411036491394, -0.5550739169120789, -1.1448339223861694, 0.47865208983421326, 0.49988386034965515, -0.3252336382865906, 0.6546162962913513, 0.15875244140625, -0.005563605111092329, 0.6278368234634399, 0.3644362688064575, 0.3878541886806488, 0.11018970608711243, 0.5635793805122375, -0.7373929619789124, 0.6270866394042969, 0.1450250893831253, 0.5141526460647583, -0.5348120331764221, -0.6739040017127991, -0.3406585156917572, -0.4949433505535126, -0.303801566362381, -0.47871580719947815, -0.1644597053527832, 0.03455984592437744, -0.43600696325302124, -0.344583660364151, -0.6551212072372437, -0.972142219543457, -0.6853740811347961, 0.00900485273450613, -0.36859264969825745, -0.1444598287343979, -1.2307041883468628, -0.7397417426109314, -0.21126104891300201, -0.13075031340122223, -0.6717244386672974, 0.33361145853996277, -0.12384089082479477, -0.516969621181488, -0.9176207780838013, 0.31514599919319153, -0.11158768832683563, 1.0756745338439941, -0.8476992249488831, 1.3620615005493164, 0.40048372745513916, -0.27340275049209595, -0.3556783199310303, -0.0011071078479290009, 0.346631795167923, 0.10778933018445969, -0.3532165586948395, -0.7661098837852478, -0.17731229960918427, 0.01918325386941433, -0.5419917106628418, 0.2218545526266098, -0.0921095460653305, 0.49440595507621765, -0.03835287690162659, -0.5688257813453674, 0.1505814641714096, 1.4719007015228271, -0.7714141607284546, -0.08869627863168716, 0.14060819149017334, 0.9087011218070984, 0.5975074768066406, 0.050819601863622665, 0.3318626880645752, 0.7554532289505005, 0.2444736212491989, -0.08081047981977463, 0.0055421446450054646, -0.18176428973674774, -0.684194803237915, 0.7470247149467468, 1.3776718378067017, 0.2068384885787964, 0.27462491393089294, -1.2231124639511108, 0.4593304395675659, -1.17995285987854, 0.12092802673578262, 0.8505988717079163, 0.8376538157463074, 0.6187878251075745, -0.7205926179885864, -0.5121108293533325, -0.37738534808158875, -0.10778467357158661, -0.22060145437717438, -0.637085497379303, -0.1930849254131317, 0.3405110239982605, 0.23969919979572296, -0.06488411873579025, 1.0440698862075806, -0.3581984043121338, 0.4767138361930847, 14.333355903625488, 0.4604322016239166, 0.3999710977077484, 0.6038919687271118, 0.09373249113559723, 0.7363733053207397, -0.8927607536315918, -0.27550333738327026, -1.0455219745635986, -0.6965394020080566, 1.2338594198226929, 0.07109755277633667, 0.729638397693634, -0.4003489017486572, -0.08397486060857773, 0.10552371293306351, -0.6328755021095276, 0.3636380136013031, 0.6779038906097412, -1.2606496810913086, 0.7664052248001099, 0.08798632770776749, 0.22380687296390533, -0.00013260729610919952, 0.8499717116355896, 1.3961515426635742, 0.24420595169067383, -0.5385705232620239, 0.2519027888774872, 0.4365473985671997, 0.7907692790031433, 0.022661596536636353, 0.6043378114700317, 0.9318161010742188, -0.6611573696136475, -0.6108314990997314, -0.39137548208236694, -0.6926804184913635, 0.07042158395051956, -0.43737268447875977, -0.94434654712677, -0.4734386205673218, -0.462494820356369, 0.33135971426963806, -0.4402463734149933, 0.11341026425361633, -0.5013372302055359, 0.5673477649688721, 0.08247330039739609, 0.17270620167255402, 0.025308821350336075, 0.8336253762245178, 0.08848316222429276, -0.24459989368915558, -0.03506122902035713, 0.33551251888275146, 0.16442729532718658, 0.2802334725856781, -0.4365589916706085, 0.08725635707378387, -0.5773370265960693, -0.2772057056427002, -0.20453540980815887, 0.3104275166988373, 0.8657591342926025, 0.2098940759897232, -0.6776783466339111, 0.17932672798633575, 0.8411006331443787, 0.3090599775314331, 0.3594343364238739, 0.1956433802843094, -0.07704296708106995, -0.05138770490884781, -0.12857535481452942, 0.3328469693660736, -0.11784756928682327, -0.3655846118927002, -0.6037856936454773, -0.6034052968025208, 0.5302635431289673, -0.7663006782531738, -0.6013925671577454, 0.612296462059021, -0.11449676752090454, -0.5121576189994812, -0.15483443439006805, -0.9283155798912048, -0.32182496786117554, 0.10044600814580917, -1.3980315923690796, -0.6850136518478394, 0.06378510594367981, -0.016283132135868073, -0.5731639266014099, -0.19983065128326416, 1.9098701477050781, 0.006433582864701748, -0.38344669342041016, 0.017495382577180862, 0.3405812680721283, -0.27881112694740295, 0.33965954184532166, -1.266674280166626, 0.4302906394004822, -0.043509479612112045, 0.07793296873569489, 0.563289225101471, -0.029962990432977676, -0.24954047799110413, -0.9743722081184387, -0.17745114862918854, 0.619204580783844, -1.4241842031478882, -0.5528808832168579, -0.3506624400615692, -1.3021442890167236, 0.6311756372451782, 0.5403851270675659, -0.6879318952560425, 0.6878823041915894, 0.1719880849123001, -0.5217995047569275, -0.23845157027244568, -1.1975516080856323, 0.047102369368076324, 0.3943800926208496, -0.5179717540740967, -0.7840349078178406, 0.15301863849163055, 0.5173354744911194, -0.9007040858268738, -0.7621318697929382, -0.34912097454071045, -0.12460630387067795, -0.05653081834316254, 0.7340385317802429, -0.27196595072746277, 0.24886932969093323, 0.676515519618988, 0.02278754860162735, -1.0757405757904053, -0.312853068113327, -0.5924989581108093, -0.019410215318202972, 0.10295073688030243, 1.0693470239639282, -0.5451011061668396, -0.06405776739120483, 1.3298907279968262, 0.09742756187915802, -0.07201750576496124, -0.352310448884964, 0.08456534892320633, 0.3715095818042755, -0.26215922832489014, 0.47165894508361816, 0.007599484641104937, -0.022657837718725204, 0.24409712851047516, 1.082829236984253, 1.0227919816970825, -0.360920250415802, -0.846526563167572, 0.7299343943595886, -0.2982952296733856, -0.2577158212661743, -0.1866467148065567, 0.054442230612039566, -1.5788494348526, -0.16130222380161285, -1.1569193601608276, 0.12401574850082397, -1.3552241325378418, -0.591051459312439, 0.2666025161743164, -0.014847143553197384, 0.06821132451295853, -0.27682480216026306, -0.8274885416030884, -0.847583532333374, -0.4893649220466614, -0.5136654376983643, 0.6198817491531372, 1.186753511428833, -0.6036791205406189, -0.03624052181839943, -0.36339351534843445, -0.35348913073539734, 0.287099152803421, 0.4179369807243347, -0.009487573057413101, -1.1030604839324951, -1.692230224609375, 0.4297027289867401, -0.08721369504928589, -0.21581438183784485, -0.5452258586883545, 0.9164069294929504, 0.5626124143600464, -0.016866983845829964, -0.05027678608894348, -0.008620398119091988, -1.1677474975585938, -0.6737924218177795, 0.22848008573055267, -0.5866782665252686, 0.22503097355365753, 0.8625187277793884, -0.4435390830039978, -0.39717477560043335, 0.3000256419181824, -0.5570917725563049, -1.1811020374298096, -0.9619369506835938, 0.20082682371139526, -0.6523452997207642, 0.020333511754870415, -0.34710216522216797, 0.2622276842594147, -1.12628173828125, -0.5471868515014648, 0.23365269601345062, 0.8070443868637085, -0.29788026213645935, 0.5833510160446167, 0.5138304829597473, -1.0575330257415771, -0.3447231352329254, 0.577655017375946, 0.3789939284324646, 0.21614070236682892, 0.5763750672340393, 0.1655968427658081, -0.22678518295288086, 0.8605239391326904, 0.3867338001728058, 0.41090986132621765, -0.6039038896560669, -0.13311180472373962, 0.8129643201828003, -0.5974791646003723, 0.11534512042999268, 0.9403431415557861, -0.23326840996742249, -1.4981297254562378, 0.37578681111335754, -1.3363091945648193, -0.894170343875885, -0.5630877017974854, 1.1889283657073975, -0.30017396807670593, -0.027483167126774788, 0.1846630722284317, -0.0832662358880043, 0.5430431365966797, -0.47372889518737793, -0.4855705201625824, 0.46663782000541687, -0.286591500043869, -0.6044516563415527, 0.7086262702941895, 0.48251447081565857, -0.8000723123550415, -0.7477293014526367, -0.7422599792480469, -0.18795061111450195, -0.14224344491958618, 0.38053956627845764, -0.9726354479789734, -0.007996858097612858, 0.4810554087162018, 0.5990332961082458, 0.17388999462127686, 0.24985578656196594, 0.030923638492822647, 0.003978129476308823, 1.0295964479446411, 0.06049486622214317, -0.33125919103622437, -0.15826447308063507, 1.165687084197998, 1.690942406654358, -1.2326111793518066, 0.2032172977924347, -0.08264075219631195, -0.6835192441940308, 1.0346314907073975, 0.7315855622291565, 0.5982571840286255, 0.9323804378509521, -0.2921876311302185, 0.5605387091636658, -0.19980205595493317, -0.9588654041290283, -0.06996528059244156, 0.9830592274665833, 1.3700618743896484, 0.791195809841156, 0.35708317160606384, 0.341137558221817, 1.167286992073059, -0.011350033804774284, 0.47054100036621094, 0.4228541851043701, 0.5463740229606628, -0.6450962424278259, -0.3097224235534668, -0.27480125427246094, 0.8676255941390991, -0.1634284406900406, -0.3814164102077484, -0.025499936193227768, 0.8302097320556641, 0.45901989936828613, 0.6553658246994019, 0.40683186054229736, 0.09391488879919052, 0.8699841499328613, 0.6422039866447449, 0.5561445951461792, -0.7468225359916687, -0.393236368894577, -0.6090434193611145, -0.3601156175136566, 0.17286375164985657, -0.3065709173679352, -0.34530216455459595, -0.6577144861221313, 0.1806335747241974, 0.48986363410949707, 0.2516447603702545, 0.24466678500175476, 1.2031594514846802, 0.6180837154388428, 0.454601913690567, -0.49670276045799255, 0.12534290552139282, -0.5177697539329529, -1.257755160331726, 0.37319090962409973, -0.7701128721237183, -0.04479215666651726, -0.45164135098457336, -0.389961302280426, -0.3318618834018707]}, "authors": [{"authorId": "2669515", "name": "Zhengbao Jiang"}, {"authorId": "2284929947", "name": "Zhiqing Sun"}, {"authorId": "2254168373", "name": "Weijia Shi"}, {"authorId": "2253404757", "name": "Pedro Rodriguez"}, {"authorId": "2110714400", "name": "Chunting Zhou"}, {"authorId": "2285194103", "name": "Graham Neubig"}, {"authorId": "2255374957", "name": "Xi Victoria Lin"}, {"authorId": "2072801764", "name": "Wen-tau Yih"}, {"authorId": "2284762857", "name": "Srinivasan Iyer"}], "references": [{"paperId": "b512451d431df9e411bea4c99f7135d010275445", "title": "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"}, {"paperId": "37680e5cb6030e01f1a44a5abe2257972196ae26", "title": "Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2"}, {"paperId": "38552c3f0f6afd651cc93b59ef7db6dafa405bf0", "title": "A Self-enhancement Approach for Domain-specific Chatbot Training via Knowledge Mining and Digest"}, {"paperId": "3a89e289e2dd29f5e52a2bf354a637762b661257", "title": "Fine-tuning Language Models for Factuality"}, {"paperId": "ddbd8fe782ac98e9c64dd98710687a962195dd9b", "title": "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection"}, {"paperId": "368fb35a07076eba01c2e4700499323cd4524513", "title": "RA-DIT: Retrieval-Augmented Dual Instruction Tuning"}, {"paperId": "f29f8b8aa2b7e608199b65d3cf751969d4024132", "title": "Physics of Language Models: Part 3.1, Knowledge Storage and Extraction"}, {"paperId": "47daf5f81470564f94adcac672405c2cd39dd186", "title": "Physics of Language Models: Part 3.2, Knowledge Manipulation"}, {"paperId": "8eafec7014d08043517834b5a2ed26384f188873", "title": "The Reversal Curse: LLMs trained on \"A is B\" fail to learn \"B is A\""}, {"paperId": "aa638d5ffb01a84bed00d4c890da3cfcb386a8fa", "title": "Adapting Large Language Models to Domains via Reading Comprehension"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "fbd2c8089870814449f9254a711041bbae145a82", "title": "How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources"}, {"paperId": "0d1c76d45afa012ded7ab741194baf142117c495", "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"}, {"paperId": "c53e3020e4b8f9e1cd7b6ed35221480a2647ea26", "title": "Meta-Learning Online Adaptation of Language Models"}, {"paperId": "546d0624adfc6e18fb87d8cc77e7705bb9ea7445", "title": "LIMA: Less Is More for Alignment"}, {"paperId": "c3ed333a37a6d9a0fcf1dad3106a114f66a45b99", "title": "WebCPM: Interactive Web Search for Chinese Long-form Question Answering"}, {"paperId": "e01515c6138bc525f7aec30fc85f2adf028d4156", "title": "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision"}, {"paperId": "ae736662f64d56f3ab1894fbd9c45f8f37251843", "title": "OpenAssistant Conversations - Democratizing Large Language Model Alignment"}, {"paperId": "38a9609a5bd874534527df9b00f2897927e57be9", "title": "MedAlpaca - An Open-Source Collection of Medical Conversational AI Models and Training Data"}, {"paperId": "b63e97330154acece935ffa6901e3f36518e5703", "title": "Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study"}, {"paperId": "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d", "title": "A Survey of Large Language Models"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "07b14c24833400b79978b0a5f084803337e30a15", "title": "REPLUG: Retrieval-Augmented Black-Box Language Models"}, {"paperId": "5bb3bd2ec1e99b11a84ccd0e4dce4bdb2a776a5e", "title": "Training Trajectories of Language Models Across Scales"}, {"paperId": "87126a964ed14d0d2207747fc732b197e2fc9493", "title": "Retrieval as Attention: End-to-end Learning of Retrieval and Reading within a Single Transformer"}, {"paperId": "398e4061dde8f5c80606869cebfa2031de7b5b74", "title": "Few-shot Learning with Retrieval Augmented Language Models"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "f92535edac9d1c735feabdb4d94c1157f12d899c", "title": "Neuro-Symbolic Language Modeling with Automaton-augmented Retrieval"}, {"paperId": "2f3efe44083af91cef562c1a3451eee2f8601d22", "title": "WebGPT: Browser-assisted question-answering with human feedback"}, {"paperId": "c2b86e6dee44dd1dc711425e13eadcf04444dea9", "title": "You Only Need One Model for Open-domain Question Answering"}, {"paperId": "002c256d30d6be4b23d365a8de8ae0e67e4c9641", "title": "Improving language models by retrieving from trillions of tokens"}, {"paperId": "ce828f9986b196308a3e40b1de58af1e8e68d728", "title": "Towards Continual Knowledge Learning of Language Models"}, {"paperId": "4e77a4d4bcc09f6b2f3bcb790d348f4dfdbf427b", "title": "Should We Be Pre-training? An Argument for End-task Aware Training as an Alternative"}, {"paperId": "0c47eb31b2dd76d8dc986173a1d3f00da1c9c74d", "title": "Efficient Nearest Neighbor Language Models"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "78513aa199fa5d71f0ab6154fb422d7f0674795e", "title": "Question Answering Infused Pre-training of General-Purpose Contextualized Representations"}, {"paperId": "6d4a9f1c41b078846901362ba0dce8295dd6a2a8", "title": "End-to-End Training of Multi-Document Reader and Retriever for Open-Domain Question Answering"}, {"paperId": "f62acd332fd7a6f35b117ed4ffaf93b19483dcf7", "title": "Can Generative Pre-trained Language Models Serve As Knowledge Bases for Closed-book QA?"}, {"paperId": "cbdb45fc16b0885905b91d84281c310e6cb49e9c", "title": "Cross-Task Generalization via Natural Language Crowdsourcing Instructions"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "58ed1fbaabe027345f7bb3a6312d41c5aac63e22", "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"}, {"paperId": "832fff14d2ed50eb7969c4c4b976c35776548f56", "title": "REALM: Retrieval-Augmented Language Model Pre-Training"}, {"paperId": "80376bdec5f534be78ba82821f540590ebce5559", "title": "How Much Knowledge Can You Pack into the Parameters of a Language Model?"}, {"paperId": "a75649771901a4881b44c0ceafa469fcc6e6f968", "title": "How Can We Know What Language Models Know?"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "d0086b86103a620a86bc918746df0aa642e2a8a3", "title": "Language Models as Knowledge Bases?"}, {"paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0", "title": "Natural Questions: A Benchmark for Question Answering Research"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "104715e1097b7ebee436058bfd9f45540f269845", "title": "Reading Wikipedia to Answer Open-Domain Questions"}, {"paperId": "3445f2d635ef18a60e409d070921737876e96f6b", "title": "Conference on Empirical Methods in Natural Language Processing EMNLP 2016"}, {"paperId": "c57dcfe972efbb5deaa8110c983c3a786d97095a", "title": "Language"}, {"paperId": "667526e216f36212d74fb1887da0481e791d9c98", "title": "The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022"}, {"paperId": "b26e260b443ed6cc4e4775ea34cbac8909005cd5", "title": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "2023. Stanford alpaca: An instruction-following llama model"}, {"paperId": null, "title": "Gemini Team. 2023."}, {"paperId": null, "title": "Meeting of the Association for Computational Lin-guistics"}, {"paperId": null, "title": "2023a. SALMON: self-alignment with principle-following reward models"}, {"paperId": null, "title": "Question: Who stars as J. Robert Oppenheimer in the film? Answer: Cillian Murphy"}, {"paperId": null, "title": "Answer: His studies, direction of the Manhattan Project, and 1954 security hearing"}, {"paperId": null, "title": "2023. GPT-4 technical report"}, {"paperId": null, "title": "2022. Multi-task prompted training enables zero-shot task generalization"}, {"paperId": null, "title": "2022. OPT-IML: scaling language model instruction meta learning through the lens of"}, {"paperId": null, "title": "2022. Quantifying memorization across neural language models"}, {"paperId": null, "title": "2023. As-trollama: Towards specialized foundation models in astronomy"}, {"paperId": null, "title": "2023. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality"}, {"paperId": null, "title": "2022. Memorization without overfitting: Analyzing the training dynamics of large language models"}, {"paperId": null, "title": "Question: What aspects of Oppenheimer's life does the film focus on?"}, {"paperId": null, "title": "Question: Who wrote and directed the film Oppenheimer? Answer: Christopher Nolan"}]}