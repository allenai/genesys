{"paperId": "debf13581cf35a61598f765101e6136f5e5a574b", "title": "RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document Abstractive Summarization", "abstract": "For long document summarization, discourse structure is important to discern the key content of the text and the differences in importance level between sentences. Unfortunately, the integration of rhetorical structure theory (RST) into parameter-efficient fine-tuning strategies for long document summarization remains unexplored. Therefore, this paper introduces RST-LoRA and proposes four RST-aware variants to explicitly incorporate RST into the LoRA model. Our empirical evaluation demonstrates that incorporating the type and uncertainty of rhetorical relations can complementarily enhance the performance of LoRA in summarization tasks. Furthermore, the best-performing variant we introduced outperforms the vanilla LoRA and full-parameter fine-tuning models, as confirmed by multiple automatic and human evaluations, and even surpasses previous state-of-the-art methods.", "venue": "North American Chapter of the Association for Computational Linguistics", "year": 2024, "citationCount": 1, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper introduces RST-LoRA and proposes four RST-aware variants to explicitly incorporate RST into the LoRA model, demonstrating that incorporating the type and uncertainty of rhetorical relations can complementarily enhance the performance of LoRA in summarization tasks."}, "embedding": {"model": "specter_v2", "vector": [-0.16657327115535736, 0.6732215285301208, -0.6173434853553772, 0.035532161593437195, -0.5671399831771851, -0.5459791421890259, 1.0817457437515259, 0.2240985929965973, -0.20380899310112, 0.37231799960136414, 1.4285287857055664, -0.10667009651660919, -0.5901559591293335, 0.1742575615644455, -0.0466948077082634, -0.2252686470746994, -0.9125012755393982, 0.32936298847198486, -0.041180238127708435, -0.5866705179214478, 0.3647066354751587, -1.0830316543579102, -0.3832394480705261, 0.24490123987197876, 0.43995246291160583, -0.20799431204795837, 0.0022725670132786036, 1.0915576219558716, -0.5806700587272644, 0.6687203645706177, -0.25362807512283325, -0.12554316222667694, 0.06054859980940819, -0.2874463200569153, -0.5627117156982422, -0.35219165682792664, 0.307330459356308, -0.6416246891021729, -0.2986128330230713, 0.4194278120994568, 0.0880584791302681, 0.07662668079137802, 1.0277202129364014, 0.3422529399394989, -0.006827244069427252, 1.2652039527893066, 0.170628160238266, 0.9047650694847107, 0.4157446622848511, -0.7979980111122131, 1.6135843992233276, -1.1927844285964966, 0.3522905111312866, 1.6179248094558716, 0.33592090010643005, 0.13414576649665833, 0.033918797969818115, -0.14115512371063232, 0.705983579158783, 0.2115466445684433, -0.860453188419342, -0.20575681328773499, 0.16460664570331573, -0.43612387776374817, 1.3285233974456787, -0.11771535873413086, -0.4556240141391754, 0.43040648102760315, -0.2381191849708557, 1.29446542263031, 0.08035841584205627, -0.8432083129882812, -0.22224202752113342, -0.5603582262992859, 0.6656436324119568, 0.3593878149986267, -0.08656669408082962, -0.14719681441783905, -0.8511422872543335, -0.23035532236099243, 0.0494224838912487, -0.836881697177887, -0.5711812376976013, 0.435745507478714, -0.39175647497177124, 0.5305806994438171, 0.18249861896038055, 0.7456168532371521, -0.32515397667884827, 0.4055226147174835, 0.4524190425872803, 0.5896543264389038, 0.22652427852153778, 0.6542025208473206, 0.2669857144355774, 0.5237255096435547, -0.5617415904998779, 0.29210397601127625, 0.4794310927391052, 0.030216816812753677, -0.27488458156585693, 0.21114985644817352, -1.4088245630264282, 0.45269593596458435, 0.9111367464065552, -0.3041454255580902, 0.2717578709125519, -1.1685317754745483, 0.18280023336410522, -0.43295636773109436, 0.6394230723381042, -1.024613618850708, -0.33615052700042725, -0.15774749219417572, -0.8308220505714417, -0.819542646408081, -0.3129805624485016, 0.13788145780563354, 0.010245714336633682, 0.5667505264282227, -0.1711461842060089, -0.18825003504753113, 0.07133189588785172, 0.5860833525657654, 0.939100980758667, 1.135708212852478, 0.09925729781389236, -0.9331133365631104, 0.9138396382331848, -0.5795945525169373, -1.19758141040802, -0.576450526714325, 0.9182569980621338, -0.02016267739236355, 0.32514485716819763, 0.21245262026786804, -1.2747533321380615, -0.631532609462738, -1.3149126768112183, -0.18395738303661346, 0.15621359646320343, 0.4497198462486267, 0.13954348862171173, 0.05395294353365898, -0.5736320614814758, 0.6055928468704224, 0.17966328561306, 0.03826625645160675, 0.009447511285543442, -0.1190122440457344, 0.525149941444397, -0.1813107579946518, -1.43416166305542, 0.4544162452220917, 0.5079292058944702, -0.7584876418113708, 0.005513000302016735, -0.30654481053352356, -0.6953384280204773, -0.0857619047164917, 0.6289618015289307, -1.0199781656265259, 1.258592128753662, 0.36726143956184387, -1.7645446062088013, 0.10628031194210052, -0.3300026059150696, -0.09207924455404282, 0.41980740427970886, -0.5962949991226196, 0.10617085546255112, -0.06884486228227615, 0.012314390391111374, -0.11436715722084045, 0.15661685168743134, -0.38836804032325745, -0.21549029648303986, 0.5331579446792603, 0.09623406827449799, 0.13899348676204681, -0.35840803384780884, 0.7846943736076355, -0.308889240026474, -0.3680485785007477, 0.07331033051013947, 1.03627347946167, 0.21083135902881622, -0.4693976640701294, -0.42648807168006897, -1.427800178527832, 0.5572963953018188, -0.04462813585996628, 2.212980031967163, -0.5280561447143555, -0.015358095057308674, -0.4913260340690613, 0.21463051438331604, 0.24670222401618958, -0.44431111216545105, 0.4696408808231354, -0.001215192023664713, 0.586856484413147, -0.6494972109794617, -0.7663469910621643, -0.1096736267209053, -0.24292489886283875, -0.8546649217605591, -0.11294395476579666, -0.015970850363373756, 1.083757996559143, -1.0234493017196655, 0.10716510564088821, 0.1728437840938568, -0.24042896926403046, -0.4700569212436676, 1.2403744459152222, -0.6631667613983154, 0.5255842208862305, -0.3511277735233307, -0.566904604434967, -0.10417123138904572, -0.3650684058666229, 0.4316532611846924, -0.13881805539131165, -0.487781822681427, 0.7178134918212891, -0.8258843421936035, 1.117802381515503, 0.21802666783332825, 0.7689952850341797, -0.11704130470752716, -0.5173673629760742, 0.1880669891834259, 0.28774726390838623, -0.27680790424346924, -0.18251153826713562, 0.30524060130119324, 0.354828417301178, -0.9089245200157166, -0.18034137785434723, 0.4469703733921051, 1.0707051753997803, -0.8872527480125427, 0.399788498878479, 0.1422826200723648, -0.13704891502857208, 1.163687825202942, 0.4274284541606903, 0.7409731149673462, 0.22419549524784088, 1.1107285022735596, -0.2951023578643799, 0.8252947926521301, -0.3746304214000702, -0.16550056636333466, 0.446004718542099, 0.9889763593673706, 0.626070499420166, 0.7760821580886841, -0.8829528093338013, -0.2257157266139984, 0.01199021004140377, 0.8069067001342773, 1.713536262512207, -0.06045515462756157, -0.8637633323669434, -0.6634588241577148, -0.2832934558391571, -0.6199040412902832, 0.5342041850090027, -0.4036085903644562, 0.1419132649898529, -1.1746758222579956, -1.0573220252990723, 0.8593194484710693, -0.08864094316959381, 1.0565184354782104, 0.13129942119121552, -0.2512299716472626, -0.33402425050735474, -0.32333600521087646, -0.4039953649044037, -0.5088614225387573, -0.1836070418357849, -0.12318577617406845, -0.6816406846046448, -0.21257661283016205, 0.08517636358737946, -0.32643017172813416, -0.4779857099056244, 1.07059645652771, -0.3661009669303894, 0.29560089111328125, -0.029737960547208786, 0.4947880804538727, -0.7674712538719177, -0.8885176181793213, -0.10925509035587311, 0.06465619057416916, -0.46018290519714355, 0.19184531271457672, 0.5357018113136292, -0.0011358693009242415, 0.2698981761932373, -0.5410735607147217, -0.16126896440982819, -0.0655331015586853, 0.31638282537460327, 0.2281823456287384, 0.1467761993408203, 0.2410421222448349, -1.322758436203003, 1.6612168550491333, 0.1763947308063507, -0.4114118218421936, 0.47913092374801636, -0.4540761113166809, -0.11831136047840118, 0.17238177359104156, -0.5479367971420288, -0.48939022421836853, -1.5470061302185059, 0.7784630060195923, 0.573687732219696, 0.08238352835178375, 1.026620864868164, 0.2585156559944153, 0.5145395994186401, 1.079559326171875, -0.11876920610666275, 0.06317012012004852, -0.2239421308040619, 0.5205341577529907, -0.3474923372268677, 0.7098181247711182, 0.2875979542732239, 0.0519927442073822, -0.23273521661758423, 0.06861882656812668, -1.0248188972473145, -0.8655194640159607, -0.3682711720466614, -0.17760677635669708, -0.2679542601108551, 0.059755098074674606, -0.6645523309707642, -0.41454169154167175, -0.35977065563201904, -1.2247488498687744, -0.08306602388620377, -0.06490562856197357, -0.28966179490089417, 0.10675126314163208, -0.5185723900794983, -1.083868145942688, -0.5409740209579468, -0.6446910500526428, -0.5953079462051392, 0.35974884033203125, -0.15864297747612, -0.8684165477752686, -0.31223854422569275, 0.4385201334953308, -0.4245132803916931, 0.3287176489830017, 0.20744970440864563, 1.154400110244751, 0.2632371783256531, -0.1759561151266098, 0.17941898107528687, 0.4392865300178528, 0.2551964521408081, -0.12665234506130219, 0.10288609564304352, -0.23993618786334991, 0.22094491124153137, 0.18952061235904694, -0.15060828626155853, 0.3556269109249115, 0.9829241633415222, 0.2971552610397339, -0.3326144516468048, -0.24660329520702362, -0.023189881816506386, 0.6127908825874329, -1.153759241104126, -0.2969922125339508, 0.30064067244529724, 0.9394379258155823, 1.0190730094909668, 0.178875133395195, 0.8333868384361267, 0.5303835272789001, 0.45150497555732727, 0.06438395380973816, -0.07741033285856247, -0.5688187479972839, -0.22344441711902618, 0.6335517764091492, 1.8811558485031128, -0.14688414335250854, -0.5556219220161438, -1.0059767961502075, 0.4746094346046448, -1.4796204566955566, -0.6492167115211487, 0.06184728816151619, 0.7735050916671753, 0.15353848040103912, -0.47088417410850525, -0.06415081769227982, 0.0663641095161438, 0.3581381142139435, 0.7077386379241943, -0.0075975325889885426, -0.27959829568862915, -0.436935693025589, -0.3089474141597748, -0.2513617277145386, 0.9529598355293274, -0.4849074184894562, 0.4827880263328552, 14.59705924987793, 0.573764443397522, 0.47205519676208496, 0.36352524161338806, 0.7062278985977173, 0.10762545466423035, -0.5603474974632263, -0.13557574152946472, -0.7491648197174072, -0.12184222787618637, 1.1954602003097534, -0.39821773767471313, 0.08536297082901001, -0.34650591015815735, 0.4629504978656769, -0.1712247133255005, -0.20615583658218384, 0.506675660610199, 0.5163074135780334, -1.5618683099746704, 0.845477819442749, 0.13728539645671844, 0.6924265623092651, -0.014265421777963638, 0.6035087704658508, 0.7373170256614685, 0.2897036373615265, -0.3599272668361664, 0.17055149376392365, 0.14397424459457397, 0.7263182401657104, -0.45482155680656433, 0.7930375933647156, 0.9640164971351624, -0.8559780716896057, -0.7446461915969849, -0.690651535987854, -1.3012953996658325, 0.39627745747566223, 0.20565252006053925, -0.7781461477279663, -0.07540667057037354, -0.3391973078250885, 0.739194393157959, 0.06419277936220169, 0.16623933613300323, -0.79987633228302, 0.9034496545791626, 0.03729714825749397, -0.03252245858311653, 0.24004028737545013, 0.519405722618103, 0.9900237321853638, 0.18280836939811707, 0.23090045154094696, 0.5824299454689026, 0.19724927842617035, -0.0790271908044815, -0.6017590165138245, 0.12535806000232697, -0.5355497598648071, -0.12017546594142914, 0.29387590289115906, 0.06515035778284073, 1.1223429441452026, 0.15216946601867676, 0.03323526680469513, -0.14878638088703156, 0.5606561899185181, 0.2282327264547348, 0.2086758017539978, -0.23685504496097565, -0.17277905344963074, 0.24025417864322662, -0.4364307224750519, 0.15426689386367798, -0.5798795223236084, -0.39591309428215027, -0.6527809500694275, -0.22037839889526367, 0.6987651586532593, -0.6104953289031982, -0.5076954364776611, 0.6803343892097473, 0.5921619534492493, -0.8794485926628113, -0.37554341554641724, -0.43976330757141113, -0.5800588130950928, 0.24643966555595398, -1.33930242061615, -0.5219424962997437, 0.11340145021677017, -0.5049762725830078, 0.11300479620695114, -0.3125660717487335, 0.9870577454566956, -0.5508634448051453, -0.3276117742061615, -0.1859666258096695, 0.5514141917228699, -0.6101620197296143, 0.18150117993354797, -1.0356477499008179, 0.24867486953735352, 0.33980822563171387, -0.47413673996925354, 0.4905383884906769, 0.4763738811016083, 0.001349593629129231, -0.5763864517211914, 0.10592865198850632, 0.8534161448478699, -1.1288871765136719, -0.43922463059425354, -0.33113908767700195, -1.3247246742248535, -0.394634872674942, 0.7831039428710938, -0.8843949437141418, 0.3966115117073059, 0.1916934847831726, 0.1024884358048439, 0.2305917739868164, -0.5798597931861877, 0.10068251937627792, 0.28482383489608765, -0.3079957365989685, -1.1742185354232788, 0.019913487136363983, 0.4537777900695801, -1.0250134468078613, -0.3062608242034912, -0.07562369108200073, -0.28023844957351685, 0.22352813184261322, 1.0309392213821411, -0.050814736634492874, 0.4163011908531189, 0.011669336818158627, 0.028299996629357338, -0.7991039752960205, -0.529550313949585, -1.3839229345321655, -0.36091530323028564, 0.22856618463993073, 0.3893705904483795, 0.03350425511598587, -0.11171397566795349, 0.3950742185115814, 0.2917960584163666, -0.14894920587539673, -0.8554697632789612, 0.1316828578710556, 0.4257291853427887, 0.19244523346424103, 0.09405770897865295, -0.11387638002634048, 0.01994163729250431, 0.6244515776634216, -0.013931287452578545, 0.9601091742515564, -0.26198166608810425, -0.8086555004119873, 0.8431574106216431, -0.5701071619987488, 0.3323364853858948, -0.867702066898346, 0.12068523466587067, -1.660182237625122, -0.113138347864151, -0.5954942107200623, -0.026635028421878815, -1.4474254846572876, -0.7218099236488342, 1.0298714637756348, -0.09455606341362, -0.5443570613861084, 0.11146599054336548, -0.8214396238327026, -0.5957298278808594, 0.06621867418289185, -0.8895121812820435, 0.9349013566970825, 0.7757190465927124, -1.0109235048294067, -0.3911198675632477, -0.006763635668903589, -0.14883959293365479, 0.5913870930671692, 0.46672406792640686, -0.513047993183136, -0.8209952712059021, -1.4003043174743652, 0.38923147320747375, -0.13445764780044556, -0.20542162656784058, -0.37286239862442017, 0.7851044535636902, 0.412114679813385, -0.2829912006855011, -0.23777323961257935, 0.13605593144893646, -0.2246982753276825, -0.5156213045120239, 0.1786104440689087, -0.9763175845146179, -0.03367345780134201, -0.26291951537132263, -0.24255363643169403, -0.5003678798675537, 0.495881050825119, -0.36154264211654663, -0.8406400084495544, -0.26107126474380493, -0.2445269227027893, -0.9276673793792725, 0.08144593238830566, -0.42685186862945557, -0.20713923871517181, -1.3166807889938354, -0.23127172887325287, 0.36954566836357117, 0.6954251527786255, -0.48238641023635864, 0.5974256992340088, 0.06286361813545227, -0.9674803018569946, -0.4311501681804657, -0.31267958879470825, -0.10928323119878769, 0.1706264615058899, 0.3363085389137268, 0.17008133232593536, -0.3236472010612488, 0.7553219199180603, 0.6284200549125671, 0.10243859887123108, -0.8086739182472229, -0.5977179408073425, 0.16351106762886047, -0.8911413550376892, -0.20940062403678894, 1.041261911392212, 0.08962798863649368, -0.5593738555908203, 0.3017234802246094, -0.8649347424507141, -1.2552053928375244, -0.006642497144639492, 1.365253210067749, 0.9526764750480652, -0.5741978883743286, -0.19875659048557281, -0.1546768695116043, 0.572873592376709, 0.014250711537897587, -0.37508946657180786, 0.7075486183166504, -0.6997318267822266, -0.49684926867485046, 1.1176466941833496, 0.36394843459129333, -0.5456097722053528, -0.6228722333908081, -0.6170431971549988, 0.38647523522377014, -0.16785311698913574, 0.4426112771034241, -0.5936776995658875, 0.6881471276283264, 0.58913654088974, 0.3057991862297058, 0.3960157632827759, 0.2087264508008957, -0.3250095546245575, -0.20459586381912231, 1.156096339225769, -0.2346421629190445, -0.936843752861023, -0.266519159078598, 1.2927125692367554, 1.8525986671447754, -0.8737623691558838, 1.0682681798934937, 0.20257271826267242, -1.0156785249710083, 1.194509744644165, 0.008234580047428608, 0.07647842913866043, 0.3974132239818573, -0.7378148436546326, 0.186788409948349, -0.15399782359600067, -0.9086272716522217, -0.07313618063926697, 1.2105878591537476, 0.7268854975700378, 0.9550915956497192, 0.12180553376674652, -0.7344034314155579, 0.9321072101593018, 0.016817808151245117, -0.05016922578215599, 0.9314326047897339, 0.3913027346134186, -0.6635626554489136, 0.010944479145109653, -0.11988694220781326, 0.16974607110023499, -0.6717233061790466, 0.26089614629745483, -0.4326987862586975, 0.4897291362285614, -0.3183443248271942, 0.8839633464813232, -0.022957542911171913, 0.3306666910648346, 0.6203595995903015, -0.22714754939079285, -0.07177484035491943, -0.5205039978027344, -0.2979544401168823, 0.3317906856536865, 0.07411005347967148, 0.122507743537426, -0.4787682294845581, -0.28668785095214844, -0.23287317156791687, -0.11394260823726654, 0.2711450159549713, 0.3616877496242523, 0.1344180852174759, 1.1187485456466675, 0.57327800989151, 0.5694062113761902, -0.30211594700813293, -0.39055711030960083, -0.6590369939804077, -1.3292628526687622, 0.23908667266368866, -0.8349176645278931, 0.07752013951539993, -0.4877241551876068, -0.09220931679010391, -0.2819690704345703]}, "authors": [{"authorId": "2167123387", "name": "Dongqi Pu"}, {"authorId": "2293393732", "name": "Vera Demberg"}], "references": [{"paperId": "08537561c9e1280a67e3edf78254f295a9647924", "title": "SciNews: From Scholarly Complexities to Public Narratives \u2013 a Dataset for Scientific News Report Generation"}, {"paperId": "c0a1d373838956db88a913a29732fb2324baaeec", "title": "Infusing Hierarchical Guidance into Prompt Tuning: A Parameter-Efficient Framework for Multi-level Implicit Discourse Relation Recognition"}, {"paperId": "9c5609baff6175b0a2e436bb69e89737c4be3cf4", "title": "Improving Biomedical Abstractive Summarisation with Knowledge Aggregation from Citation Papers"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "9cab8c423d9c13d4f35beb97a7f823c250e8f059", "title": "RECAP: Retrieval-Enhanced Context-Aware Prefix Encoder for Personalized Dialogue Response Generation"}, {"paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787", "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"}, {"paperId": "b759a516922b163a93fea70bcc45708a6c24a9c1", "title": "Echoes from Alexandria: A Large Resource for Multilingual Book Summarization"}, {"paperId": "5c61ff8c92025f105aefdb53361a2e5403aee57c", "title": "One Network, Many Masks: Towards More Parameter-Efficient Transfer Learning"}, {"paperId": "be658d4482299d7a77be324bdb9946bfcbcbad25", "title": "Incorporating Distributions of Discourse Structure for Long Document Abstractive Summarization"}, {"paperId": "2a2cf2dc6e63d3b1fc3d81ca6a88b3c23cf918d6", "title": "PIP: Parse-Instructed Prefix for Syntactically Controlled Paraphrase Generation"}, {"paperId": "cb783a24d137638cb840e0cfc3776dc037973bb5", "title": "Neural Architecture Search for Parameter-Efficient Fine-tuning of Large Pre-trained Language Models"}, {"paperId": "4e16bfc8ded08fbec67666869f39c043a6770946", "title": "Parameter-Efficient Fine-Tuning without Introducing New Latency"}, {"paperId": "1672864ca8037db4557a19c3eea5eecbe9ba3634", "title": "AWESOME: GPU Memory-constrained Long Document Summarization using Memory Mechanism and Global Salient Content"}, {"paperId": "5193003d574eff310742e6ce94612fc82851fee0", "title": "Towards Adaptive Prefix Tuning for Parameter-Efficient Language Model Fine-tuning"}, {"paperId": "32ac52069e562d4f900afee70bdca63f53461481", "title": "QLoRA: Efficient Finetuning of Quantized LLMs"}, {"paperId": "4b55c9eaa2eb8a52c326124ee97be7a2f2d087a9", "title": "Prefix Propagation: Parameter-Efficient Tuning for Long Sequences"}, {"paperId": "148644bf4ccef7e022b965304e8b3178be8af0fa", "title": "Conditional Adapters: Parameter-efficient Transfer Learning with Fast Inference"}, {"paperId": "381ab7a640f5b46b62f7e08d1af4a8e0d3eadd55", "title": "G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment"}, {"paperId": "684b0f42aa5d5b2bea09f6e0400336cf288cc787", "title": "An Empirical Study on the Transferability of Transformer Modules in Parameter-efficient Fine-tuning"}, {"paperId": "220ddeb4dc43bc922289fec8b1b60d7226068b20", "title": "Parameter-Efficient Fine-Tuning Design Spaces"}, {"paperId": "02d2527aca2ecbda72475dd90ac461a3eb73abd7", "title": "Parameter-Efficient Tuning Makes a Good Classification Head"}, {"paperId": "3e9b4218f6b943de8e57fe70f903911db11d24b6", "title": "Correcting Diverse Factual Errors in Abstractive Summarization via Post-Editing and Language Model Infilling"}, {"paperId": "73bf67f9ac4a28c5618f8df32cb64d810f57a9b9", "title": "Making Science Simple: Corpora for the Lay Summarisation of Scientific Literature"}, {"paperId": "70a40dc42f4cb37357aca335c717bbd009ff9345", "title": "Parameter-Efficient Finetuning for Robust Continual Multilingual Learning"}, {"paperId": "3b39efe6c91ae432dd35bb79431edb8a6719f906", "title": "Investigating Efficiently Extending Transformers for Long Input Summarization"}, {"paperId": "990f7efd58ae1382f0c2cf2c8d0580bd65e72e11", "title": "Know Where You're Going: Meta-Learning for Parameter-Efficient Fine-tuning"}, {"paperId": "55a250868627de2d202d06e7cb3f6cbcd3a66f88", "title": "ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts"}, {"paperId": "4f68042a0aa40f34027a49ceec64ad2bbe2211aa", "title": "When does Parameter-Efficient Transfer Learning Work for Machine Translation?"}, {"paperId": "2bbf022d9a61f124a01da306a7ddd49d1b93abae", "title": "When a sentence does not introduce a discourse entity, Transformer-based models still sometimes refer to it"}, {"paperId": "3d318019788418b21478e8736d03afadc1607690", "title": "HIBRIDS: Attention with Hierarchical Biases for Structure-aware Long Document Summarization"}, {"paperId": "4c09ac7b09628aa2aad12aea8dd6c2aef6c83aa0", "title": "Revisiting Parameter-Efficient Tuning: Are We Really There Yet?"}, {"paperId": "a3c8c57075dfebf7f5a57952afafb7407762cc46", "title": "Discourse-Aware Soft Prompting for Text Generation"}, {"paperId": "ee1ef7b70dc34adcc90c42cc28168165ea56501f", "title": "SummaC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization"}, {"paperId": "ad471be93216ddbf8544721d50ee5aed14f07cae", "title": "UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning"}, {"paperId": "abce205e296cda2256b7cc7f2229ac20566e28d5", "title": "DMRST: A Joint Framework for Document-Level Multilingual RST Discourse Segmentation and Parsing"}, {"paperId": "43a87867fe6bf4eb920f97fc753be4b727308923", "title": "Towards a Unified View of Parameter-Efficient Transfer Learning"}, {"paperId": "dac5711aea72aba9c607f049e295da5f8abb3c93", "title": "Residual Adapters for Parameter-Efficient ASR Adaptation to Atypical and Accented Speech"}, {"paperId": "f75fd3288a60233bbc766037941f5b370fae9168", "title": "Structural Guidance for Transformer Language Models"}, {"paperId": "a4ffce66918cfb33150a60bf8e26419199e63b01", "title": "BookSum: A Collection of Datasets for Long-form Narrative Summarization"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "2f6a29b079343ddbf08f7741363fac6316a3f1f7", "title": "Multilingual Neural RST Discourse Parsing"}, {"paperId": "cc29ba75c75d0c4c0e1031ad6d8af992cbc13673", "title": "Linguistic Profiling of a Neural Language Model"}, {"paperId": "71916251a13690af5e2e46c31e2a0b72e755eebb", "title": "Composing Elementary Discourse Units in Abstractive Summarization"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "483bd404163a7ec9b19ce13865a44be5287593a8", "title": "Exploiting Discourse-Level Segmentation for Extractive Summarization"}, {"paperId": "76037594f29a663fbd2799de2e5c7463c02a8a1d", "title": "Discourse-Aware Neural Extractive Text Summarization"}, {"paperId": "cc364d325e062825cf27cdb06d3c82abf7048064", "title": "Discourse-Aware Hierarchical Attention Network for Extractive Single-Document Summarization"}, {"paperId": "49f1525c78d42037ffe4cd5a0c451bb7f5eb27b2", "title": "Enhancing Machine Translation with Dependency-Aware Self-Attention"}, {"paperId": "cf6c88c892b7f4b1e92cb15a067fa49d1e089d64", "title": "Discourse Understanding and Factual Consistency in Abstractive Summarization"}, {"paperId": "b0cd945f73e0f28a47cacb53f16d394917eea3a8", "title": "Unsupervised Neural Single-Document Summarization of Reviews via Learning Latent Discourse Structure and its Ranking"}, {"paperId": "051d868dcc32611133eaaac55cce82a6d4f08733", "title": "Single Document Summarization as Tree Induction"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "305b2cf37e5dece81e95c92883d5a6e28ac93b22", "title": "Don\u2019t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"}, {"paperId": "b4bfadfca9742bb3ee98a0cd322d5ce4e59a3ceb", "title": "A Call for Clarity in Reporting BLEU Scores"}, {"paperId": "54a13bcc9613dcaa76fb25fbe96572f376cfcca9", "title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "680bfa179c33d56f524c6adf9b7f7f5a62e5ef46", "title": "Discourse-Aware Neural Rewards for Coherent Text Generation"}, {"paperId": "3e597e492c1ed6e7bbd539d5f2e5a6586c6074cd", "title": "Improved Neural Machine Translation with a Syntax-Aware Encoder and Decoder"}, {"paperId": "2c5b31ebbb2d2a1f7bd402c8e2943424f6fed535", "title": "A Joint Model of Rhetorical Discourse Structure and Summarization"}, {"paperId": "267aef492d17592a293aa17ec8a25f7264645bcb", "title": "The Role of Discourse Units in Near-Extractive Summarization"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "da7a8544f1d110c2ba1d430350810af61e0b1a35", "title": "Single Document Summarization based on Nested Tree Structure"}, {"paperId": "b88876344be6d9a8172f72bc0a836994f6b6f719", "title": "Discourse indicators for content selection in summarization"}, {"paperId": "7533d30329cfdbf04ee8ee82bfef792d08015ee5", "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "c63bb976dc0d3a897f3b0920170a4c573ef904c6", "title": "Automatic Evaluation of Summaries Using N-gram Co-occurrence Statistics"}, {"paperId": "a8912e439ac787c91892ea3d5223e7dd0fea4052", "title": "RHETORICAL STRUCTURE THEORY: A THEORY OF TEXT ORGANIZATION"}, {"paperId": "5ef82a8c8aa50f99285f2143b57ca4e82da1af80", "title": "Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning"}, {"paperId": "2cc134293669b20dce3d55a67d08fea665745e7b", "title": "Combining Parameter-efficient Modules for Task-level Generalisation"}, {"paperId": "90812d2cd9e1697821c4b4014f44f5bb1873bffe", "title": "Promoting Topic Coherence and Inter-Document Consorts in Multi-Document Summarization via Simplicial Complex and Sheaf Graph"}, {"paperId": "c48451c901211ed8e383a940d4e235452d5815e1", "title": "A Gradient Control Method for Backdoor Attacks on Parameter-Efficient Tuning"}, {"paperId": "6f5e0ef92fb4235a1e38065e6e021aeaeec13eb7", "title": "Parameter-Ef\ufb01cient Fine-Tuning with Layer Pruning on Medical Report Summarization and Medical Dialogue Generation"}, {"paperId": "e2c210f7aac35b6ba4038feaef605c7de7982fe6", "title": "SIMSUM: Document-level Text Simplification via Simultaneous Summarization"}, {"paperId": null, "title": ". Parameter-efficient multilingual sum-marisation: An empirical study"}, {"paperId": "42bf54a1bfd86739b62ddbafe14e12152746c382", "title": "DACSA: A large-scale Dataset for Automatic summarization of Catalan and Spanish newspaper Articles"}, {"paperId": "219be4772aab5f13a172c100bc7f2441ba9192ad", "title": "Modeling Hierarchical Syntax Structure with Triplet Position for Source Code Summarization"}, {"paperId": "e27e91bf11ef496fd46a857e7d2da92fbebf82b6", "title": "Passing Parser Uncertainty to the Transformer. Labeled Dependency Distributions for Neural Machine Translation."}, {"paperId": "b9a21c2bf389ba693cd4692a028c7f2821b1804e", "title": "Discourse-Aware Unsupervised Summarization for Long Scientific Documents"}, {"paperId": "471f2a7c86c5128f10afddc394007ffa0f8019fd", "title": "Extractive Summarization Considering Discourse and Coreference Relations based on Heterogeneous Graph"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": null, "title": "Structure-aware ab-stractive conversation summarization via discourse"}, {"paperId": null, "title": "Do we really need that many parameters in trans-former for extractive summarization?"}, {"paperId": "8422274e9cbe5dcdd87f203610dfaa63cce233ba", "title": "Advertisments"}, {"paperId": "e810465d72c677f0580b0524b7f5debe2a1d5d26", "title": "Discourse Trees Are Good Indicators of Importance in Text"}, {"paperId": "1daf375141571501ca8c30b62d7c14269d566762", "title": "From discourse structures to text summaries"}, {"paperId": null, "title": "and action graphs"}, {"paperId": null, "title": "utilizes tokens from the source material. A higher coverage score suggests a greater proportion of the summary\u2019s tokens originate from the source document"}, {"paperId": null, "title": "2022. PPT: Pre-trained prompt tuning for few-shot learning"}, {"paperId": null, "title": "Thirty-seventh Conference on Neural Information Processing Systems"}, {"paperId": null, "title": "2023c. Binary and ternary natural language generation"}, {"paperId": null, "title": "2022. Multi-lexsum: Real-world summaries of civil rights law-suits at multiple granularities"}, {"paperId": null, "title": "OpenAI"}, {"paperId": null, "title": "2024. Loftq: LoRA-fine-tuning-aware quantization for large language models"}, {"paperId": null, "title": "2023. Sparse low-rank adaptation of pre-trained language models"}]}