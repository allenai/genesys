{"paperId": "13925d7d5952b1ba5960dfe2c44d977be109b636", "title": "4M: Massively Multimodal Masked Modeling", "abstract": "Current machine learning models for vision are often highly specialized and limited to a single modality and task. In contrast, recent large language models exhibit a wide range of capabilities, hinting at a possibility for similarly versatile models in computer vision. In this paper, we take a step in this direction and propose a multimodal training scheme called 4M. It consists of training a single unified Transformer encoder-decoder using a masked modeling objective across a wide range of input/output modalities - including text, images, geometric, and semantic modalities, as well as neural network feature maps. 4M achieves scalability by unifying the representation space of all modalities through mapping them into discrete tokens and performing multimodal masked modeling on a small randomized subset of tokens. 4M leads to models that exhibit several key capabilities: (1) they can perform a diverse set of vision tasks out of the box, (2) they excel when fine-tuned for unseen downstream tasks or new input modalities, and (3) they can function as a generative model that can be conditioned on arbitrary modalities, enabling a wide variety of expressive multimodal editing capabilities with remarkable flexibility. Through experimental analyses, we demonstrate the potential of 4M for training versatile and scalable foundation models for vision tasks, setting the stage for further exploration in multimodal learning for vision and other domains.", "venue": "Neural Information Processing Systems", "year": 2023, "citationCount": 17, "influentialCitationCount": 2, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The potential of 4M for training versatile and scalable foundation models for vision tasks is demonstrated, setting the stage for further exploration in multimodal learning for vision and other domains."}, "embedding": {"model": "specter_v2", "vector": [0.5684859156608582, 0.5867706537246704, -0.2608201205730438, -0.029605640098452568, -0.6063717603683472, 0.12737786769866943, 1.1053273677825928, -0.4724113941192627, -0.4730311930179596, -0.769252359867096, 0.6259425282478333, 0.19913706183433533, 0.5041521787643433, 0.19955822825431824, -0.06274208426475525, 0.026060087606310844, -0.6191945672035217, 0.2368510514497757, -0.17534929513931274, -0.33342015743255615, -0.18667785823345184, -0.3354839086532593, -1.2109265327453613, 0.32325655221939087, -0.03109649568796158, 0.45308011770248413, 0.6690831184387207, 1.04057776927948, -0.19555528461933136, 0.38487428426742554, 0.5146982669830322, -0.4614242613315582, 0.26028305292129517, 0.28298333287239075, -0.45620813965797424, 0.4124946594238281, 0.4698823392391205, -0.6368018984794617, -0.7821514010429382, 0.5705840587615967, -0.18500842154026031, 0.12216086685657501, 0.6057087779045105, -0.6526547074317932, -0.64200359582901, 0.9259911775588989, 0.2962498962879181, 0.2466927021741867, -0.29371073842048645, -0.5561618208885193, 1.4405827522277832, -1.8390012979507446, 0.1633220762014389, 1.7929701805114746, 0.11510400474071503, 0.7357505559921265, -0.419323593378067, -0.37701311707496643, 0.6715914011001587, -0.012144003994762897, -0.7681871652603149, -0.24490202963352203, -0.16836756467819214, -0.3630070984363556, 1.2787472009658813, -0.5625877976417542, -0.07640186697244644, 0.8717089891433716, 0.021047033369541168, 1.471974492073059, -0.05688474699854851, -1.1917035579681396, -0.6504006385803223, 0.06672897934913635, -0.1246647760272026, 1.0916531085968018, -0.7548512816429138, 0.6374492049217224, -1.154953122138977, 0.3718434274196625, 0.5764173269271851, -0.0395858958363533, 0.3126318156719208, -0.13756699860095978, -0.7144971489906311, 0.6277083158493042, 0.6903519034385681, 0.4446391761302948, 0.0166664719581604, 0.9143428802490234, 0.3639722168445587, 0.09567251056432724, -0.3940095603466034, -0.14629513025283813, 0.2117026299238205, 0.47995129227638245, -0.8824387788772583, 0.2295295000076294, -0.4237535297870636, 0.8060766458511353, -0.04479285329580307, 0.3828867971897125, -0.8475915193557739, 0.2192872315645218, 1.7411751747131348, 0.1805780529975891, 0.4186698794364929, -0.5274010896682739, 0.3921055197715759, -0.9558538794517517, 0.22357937693595886, -0.4066394567489624, -0.22506959736347198, 0.003672221442684531, -0.36511939764022827, -0.9575503468513489, -0.4279012084007263, 0.3926904499530792, -1.5603185892105103, 0.9700649976730347, -0.5402303338050842, -0.11329103261232376, 0.044758208096027374, 0.33593448996543884, 0.7135688662528992, 0.5377432107925415, 0.6861014366149902, 0.7282407283782959, 1.0979275703430176, -1.0453417301177979, -0.2666991055011749, -0.7519571781158447, 0.3575453758239746, -0.48058632016181946, 0.4370754659175873, -0.18847252428531647, -1.1761208772659302, -1.321621298789978, -0.42475250363349915, -0.35116174817085266, -0.6431819796562195, 0.6437836289405823, 1.034825086593628, 0.596342146396637, -1.3787070512771606, 0.38437220454216003, -0.021910469979047775, -0.2360101193189621, 0.5223791003227234, 0.2893610894680023, -0.05402282625436783, -0.5543233156204224, -0.8599192500114441, 0.48746171593666077, -0.061680734157562256, -0.44143959879875183, -0.7414461374282837, -0.1618250459432602, -1.546366572380066, -0.1282692402601242, -0.13630543649196625, -0.5596961379051208, 1.2463533878326416, -0.01816996932029724, -0.8400275707244873, 1.0265339612960815, -0.7666025161743164, 0.36125025153160095, 0.17832355201244354, -0.19183853268623352, -0.49861523509025574, -0.22033382952213287, -0.04542834684252739, 1.3041225671768188, 0.9025183916091919, -0.686657726764679, 0.026698196306824684, 0.2954936623573303, -0.29567331075668335, 0.07376310229301453, -0.36062875390052795, 1.1083074808120728, -0.21907618641853333, -0.527870774269104, 0.36351239681243896, 0.6002491116523743, -0.035537563264369965, -0.10039569437503815, -0.7877042889595032, -0.7007677555084229, 0.8519870042800903, 0.07906436920166016, 0.016903067007660866, -1.2026103734970093, -0.3904392123222351, -0.31058457493782043, 0.03049183264374733, -0.4356808364391327, -1.2000813484191895, 0.920933187007904, -0.5229805707931519, 0.45284461975097656, -0.0669947937130928, -1.9063209295272827, 0.38985055685043335, -0.23210804164409637, -0.9271096587181091, -0.3101205825805664, 0.32608562707901, 1.3673427104949951, -0.36732253432273865, -0.3210366666316986, 0.15393966436386108, 0.41863417625427246, -0.6621461510658264, 0.9409162402153015, -0.20523697137832642, 0.16001266241073608, 0.3832240402698517, 0.30225056409835815, -0.008863972499966621, -0.17638380825519562, -0.1895027905702591, -0.7022445201873779, -0.06141962483525276, 0.10601112991571426, -0.05185266211628914, 1.7316291332244873, -0.15023499727249146, 0.7112945914268494, -0.29728665947914124, -0.46836453676223755, 0.2666209936141968, 0.4893452823162079, -0.13870960474014282, -0.23131684958934784, 0.3491505980491638, 0.02618880197405815, -0.7931059002876282, 0.30072951316833496, 0.9916130304336548, 0.41455078125, -0.3368358612060547, 0.04612700641155243, 0.6160046458244324, -0.37672626972198486, 0.32236266136169434, 0.6479898691177368, 0.3962872624397278, 0.41946670413017273, -0.14883723855018616, 0.27007734775543213, 0.021298961713910103, -1.0155645608901978, -0.7737207412719727, 0.8741057515144348, 0.6707003712654114, 1.325451135635376, 0.14222107827663422, -0.5336307287216187, -0.36358481645584106, -0.5849847793579102, 0.6218997836112976, 1.525938868522644, 0.044773343950510025, -0.20212633907794952, -0.46208909153938293, 0.12129572033882141, -0.3246278762817383, -0.42393893003463745, -0.6918820738792419, -0.08640208095312119, 0.06573247909545898, -0.8174147605895996, 0.927640974521637, 0.6449378728866577, 0.8879340291023254, -0.7416700124740601, -0.08512630313634872, -0.6248098015785217, 0.2741229236125946, -0.858721137046814, -0.6784522533416748, 0.1759214699268341, -0.016247136518359184, 0.23676902055740356, -0.24650976061820984, -0.5848244428634644, 0.3360632658004761, -0.4747738242149353, 0.5263916254043579, -0.6175135374069214, -0.9843742847442627, 0.4835093021392822, 0.5543014407157898, -0.7202709913253784, -0.6495360136032104, -0.21250677108764648, -0.08295777440071106, 0.10880523920059204, 0.1340620517730713, 0.6670821905136108, 0.3010464310646057, 0.2238871306180954, -0.6766902804374695, 0.42951759696006775, 0.3266107439994812, 0.3076125979423523, 0.6720114946365356, -0.4134067893028259, -0.08267489820718765, -0.4716503620147705, 0.6701887249946594, 0.39840182662010193, -0.08175363391637802, 0.136209174990654, -0.20440156757831573, -0.7320011258125305, 0.254699170589447, -0.7322934865951538, -0.47298964858055115, -0.3539113402366638, 0.5355778932571411, -0.3646802604198456, -0.5522640347480774, 0.2098526656627655, 0.23496446013450623, -0.033408425748348236, 0.09825160354375839, 0.7939934730529785, 0.481356680393219, -0.04853742569684982, 0.8362752795219421, -0.9617761969566345, 0.7212229371070862, 0.033432818949222565, 0.7226415872573853, 0.46760034561157227, 0.14799542725086212, -0.7587633728981018, -0.3378329873085022, -0.30087342858314514, -0.5773134827613831, -0.6358833312988281, 0.6137259602546692, -0.860222578048706, -0.8549422025680542, 0.36106666922569275, -1.163345217704773, 0.018442252650856972, -0.015220170840620995, -0.34103286266326904, -0.193984717130661, -0.7621849775314331, -1.1218681335449219, -0.42239513993263245, -0.04174485430121422, -1.052916169166565, 0.6303943991661072, 0.2479543536901474, -0.32749658823013306, -0.6081641316413879, -0.2568601071834564, 0.10298151522874832, 0.793374240398407, -0.5573752522468567, 0.8710524439811707, 0.2522867023944855, -0.365467369556427, -0.6379658579826355, -0.1581442505121231, 0.5802062749862671, -0.10533998161554337, 0.6019548773765564, -1.2787883281707764, 0.3666307032108307, -0.7062152028083801, -0.36119380593299866, 0.5330208539962769, 0.3669755160808563, 0.5032341480255127, 0.6712396740913391, -0.3528435528278351, 0.13218645751476288, 1.2484058141708374, -0.6618683338165283, 0.009082190692424774, -0.1908680498600006, 1.2490636110305786, 0.3170570135116577, -0.8506337404251099, 0.6264097094535828, 0.5815334320068359, 0.29432711005210876, 0.40297070145606995, -0.4138266146183014, -0.4768291413784027, -0.8072723746299744, 0.6884814500808716, 0.7784093022346497, 0.27994537353515625, -0.0567571297287941, -1.168773889541626, 0.7791256308555603, -0.9140282273292542, -0.6733843088150024, 0.8773165345191956, 0.45154768228530884, -0.230477973818779, -0.5200513601303101, -0.38533276319503784, -0.315433531999588, 0.6755432486534119, 0.44962456822395325, -0.1669933944940567, -0.6573280096054077, -0.29750198125839233, 0.4515826404094696, -0.08915486931800842, 0.441561222076416, -0.618817925453186, 0.4714634120464325, 14.582505226135254, 0.5406165719032288, -0.08577579259872437, 0.40709057450294495, 0.4909154772758484, 0.3188614249229431, -0.728280246257782, 0.07525674998760223, -1.1353610754013062, -0.44276538491249084, 0.6293274760246277, 0.5318341255187988, 0.5586802959442139, 0.0174720361828804, 0.017569752410054207, 0.1617867797613144, -0.6547908186912537, 0.8338150978088379, 0.781570553779602, -1.1983131170272827, 0.6292470693588257, 0.3214326500892639, 0.3068876564502716, 0.4599473476409912, 1.4731671810150146, 0.5241317749023438, 0.2897509038448334, -0.9197337627410889, 0.9284242987632751, 0.31414294242858887, 1.0350486040115356, 0.33644014596939087, -0.24218174815177917, 0.34051743149757385, -1.2310811281204224, -0.5238080024719238, -0.33200785517692566, -0.8593457937240601, 0.4749983549118042, -0.28047069907188416, -0.6167108416557312, -0.2849203944206238, -0.28094467520713806, 0.9465921521186829, 0.03707882761955261, 0.20552918314933777, 0.11875900626182556, 0.3256635367870331, 0.034418344497680664, 0.20543496310710907, 0.3193065822124481, 0.8538811802864075, 0.3600243031978607, -0.08485113084316254, 0.025345591828227043, -0.5968827605247498, 0.21924574673175812, 0.6745260953903198, -0.4363788068294525, -0.20567390322685242, -0.35427477955818176, -0.319927841424942, -0.4198952615261078, 0.9409694075584412, 0.22903022170066833, 0.6945540904998779, -0.6542766690254211, 0.2944408059120178, 0.19856464862823486, 0.23118272423744202, -0.386534184217453, 0.18931247293949127, -0.039990391582250595, -0.5016448497772217, 0.38141751289367676, 0.3794986605644226, -0.12293592095375061, -0.5703269839286804, -0.6141970753669739, 0.2762176990509033, 0.1802341192960739, -1.0791950225830078, -1.0019433498382568, 0.9670765399932861, -0.1597657948732376, -0.35544833540916443, 0.4603796899318695, -1.140853762626648, -0.31510129570961, 0.7044935822486877, -1.3712763786315918, -1.4995943307876587, -0.05507128685712814, 0.1518378108739853, -0.22183208167552948, -0.36841532588005066, 1.2636778354644775, 0.11376404017210007, 0.09286882728338242, 0.11049491912126541, -0.5169788599014282, 0.24232380092144012, -0.28992903232574463, -0.7971555590629578, 0.7341992855072021, 0.25812986493110657, 0.28800302743911743, 0.03840307518839836, -0.16051241755485535, 0.23850004374980927, -0.6112070679664612, 0.34452131390571594, 0.7454683184623718, -0.8106938600540161, -0.4304412603378296, -0.6694682240486145, -0.2836158871650696, 0.2314835488796234, 0.5242788791656494, -0.17234395444393158, 0.3988884389400482, 0.037959691137075424, -0.8929246664047241, -0.022874686866998672, -0.7309130430221558, 0.17534440755844116, 0.2249622941017151, -1.1036497354507446, -0.05513348430395126, 0.23331394791603088, 0.14359894394874573, -0.8665417432785034, -0.1894340217113495, -0.28813436627388, 0.14053595066070557, -0.08739755302667618, 0.9905093908309937, -0.6252819299697876, 0.965835690498352, 0.7699335217475891, -0.6149280071258545, -0.6905895471572876, 0.02588922716677189, -0.9291514158248901, 0.1077934205532074, 0.11025118082761765, 0.542118489742279, -0.2636401653289795, 0.15031638741493225, 0.7936332821846008, 0.18437601625919342, -0.46271079778671265, -0.4840841591358185, 0.009055891074240208, 0.03890860825777054, -0.5880817174911499, -0.018294110894203186, -0.527072012424469, -0.23749034106731415, 0.019669000059366226, 0.0661110207438469, 0.4172765612602234, -0.03584887087345123, -0.7699159979820251, 0.3599203824996948, -0.13214507699012756, -0.07948565483093262, -0.5307400226593018, -0.8991683721542358, -1.5237427949905396, 0.24714398384094238, -1.3637548685073853, 0.14257553219795227, -1.0145312547683716, -0.2328626811504364, 0.37595105171203613, -0.13213586807250977, 0.5392453670501709, 0.6719949245452881, -0.045239970088005066, 0.09333579242229462, -0.5449709892272949, -0.06727404147386551, 0.8961144685745239, 1.217244029045105, -0.8889368176460266, 0.42159733176231384, -0.09567546099424362, -0.17959578335285187, 0.1223277822136879, -0.0040288963355124, -0.13406908512115479, -0.8719797134399414, -1.3139264583587646, 0.04888620227575302, -0.08926989138126373, 0.6129512786865234, -0.9269126057624817, 0.47920894622802734, 0.6240748167037964, 0.016617050394415855, -0.005850073415786028, 0.9687210917472839, -0.802419126033783, -0.740666389465332, 0.17838560044765472, -1.0306053161621094, 0.29626744985580444, 0.1512557566165924, -0.4387582838535309, -0.5196500420570374, 0.7957050800323486, -0.14284008741378784, -0.936352550983429, -0.7957829236984253, 0.5549379587173462, -0.5678925514221191, -0.3253113925457001, -0.09543263167142868, -0.23410914838314056, -1.1186810731887817, -0.5756220817565918, -0.5848730206489563, 0.07877174019813538, -0.5384823679924011, 1.006864070892334, 1.0971901416778564, -1.0171606540679932, -0.16796906292438507, 0.4466797411441803, -0.061036691069602966, 0.03451474756002426, 0.8955855965614319, 0.2526608109474182, 0.005051211453974247, 0.2746860682964325, 0.04204844683408737, 0.2151125818490982, -1.0120857954025269, -0.09343312680721283, 0.7332844734191895, -0.09239836037158966, -0.26180875301361084, 1.434415340423584, -0.21912482380867004, -0.9422692656517029, 0.2051970213651657, -0.7251777052879333, -0.41125062108039856, -0.24219101667404175, 0.6656500101089478, -0.38051751255989075, -0.40495213866233826, -0.4930446743965149, -0.3432962894439697, 0.5471152663230896, -0.3419903814792633, -0.9367026090621948, 0.12213102728128433, -0.3609360158443451, -0.3658890724182129, 0.5940355658531189, 0.8264540433883667, -0.6525769233703613, -0.8522064089775085, -0.7370773553848267, -0.9151663184165955, -0.08086653053760529, -0.01474146917462349, -0.4868583083152771, -0.6802495718002319, 0.9807089567184448, 0.4446275532245636, 0.3503440022468567, 0.15816780924797058, 0.26585373282432556, 0.10282769799232483, 0.6162824630737305, -0.19649890065193176, -0.3914926052093506, -0.22988732159137726, 1.1363965272903442, 1.0924643278121948, -0.7858947515487671, -0.07687921077013016, -0.5269179344177246, -1.0474878549575806, 0.9980568885803223, 0.25449344515800476, 0.19242995977401733, 1.0944982767105103, -0.22415219247341156, 0.41817930340766907, 0.22371961176395416, -0.7045856714248657, -0.1442417949438095, 1.1115803718566895, 1.4398127794265747, 0.5114551186561584, 0.46280768513679504, 0.6738883852958679, 0.4502546191215515, -0.022344382479786873, -0.05054278299212456, 0.5204721093177795, 0.5623175501823425, -0.044432271271944046, -0.21652096509933472, 0.06289039552211761, 0.44010668992996216, -0.35199472308158875, -0.6051331758499146, 0.27024516463279724, 0.4491312801837921, 0.34085071086883545, 0.5734058022499084, 0.7177489995956421, -0.18544001877307892, 0.2855261564254761, 0.32800906896591187, 0.8266586065292358, -0.7653098702430725, 0.25135546922683716, -0.19943872094154358, -1.049485683441162, 0.26691481471061707, -0.6583655476570129, -0.4873144328594208, -0.6779049038887024, 0.18442191183567047, 0.6904156804084778, -0.6927816271781921, 0.564709484577179, 1.3556337356567383, 0.2704305350780487, 0.28427228331565857, -0.08788658678531647, -0.7862518429756165, -0.23211559653282166, -0.7101762294769287, -0.21434105932712555, -0.35920512676239014, 0.08260393887758255, -0.8190685510635376, -0.08197619020938873, 0.29625004529953003]}, "authors": [{"authorId": "2111623708", "name": "David Mizrahi"}, {"authorId": "153825349", "name": "Roman Bachmann"}, {"authorId": "2273474116", "name": "Ouguzhan Fatih Kar"}, {"authorId": "143895090", "name": "Teresa Yeo"}, {"authorId": "2273661239", "name": "Mingfei Gao"}, {"authorId": "2273361790", "name": "Afshin Dehghan"}, {"authorId": "40029556", "name": "Amir Zamir"}], "references": [{"paperId": "b6d6c33298b852cf63edac233deca70530d69a2a", "title": "PaLM 2 Technical Report"}, {"paperId": "7dc6da87eaa6f830354feb2db14023cab8678c91", "title": "ImageBind One Embedding Space to Bind Them All"}, {"paperId": "f9570989919338079088270a9cf1a7afc8db8093", "title": "DataComp: In search of the next generation of multimodal datasets"}, {"paperId": "3049c992adbd56e29c4d957ee0c4e9d05fe3c6d1", "title": "EVA-02: A Visual Representation for Neon Genesis"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "f02d56e630986997e0aea3d92bf53e0f363ce401", "title": "Prismer: A Vision-Language Model with Multi-Task Experts"}, {"paperId": "34dae77df952dc1cddbcc27ada3183cea6607457", "title": "X&Fuse: Fusing Visual Information in Text-to-Image Generation"}, {"paperId": "fbfef4723d8c8467d7bd523e1d0b703cce0e0f9c", "title": "Language Is Not All You Need: Aligning Perception with Language Models"}, {"paperId": "9ced6e814457eae83f5415364e266143defc81d1", "title": "MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation"}, {"paperId": "efa06fe7c6a4abbe465dbea4f7130f45720ac6f0", "title": "Tuning computer vision models with task rewards"}, {"paperId": "efbe97d20c4ffe356e8826c01dc550bacc405add", "title": "Adding Conditional Control to Text-to-Image Diffusion Models"}, {"paperId": "61e721334296ebfbbf6443b5ed9eb8c83b708c95", "title": "Scaling Vision Transformers to 22 Billion Parameters"}, {"paperId": "468992bf970c37bd1fef58b78a6c2fcd8c018868", "title": "Scaling Laws for Generative Mixed-Modal Language Models"}, {"paperId": "2a3213cb3c755f036d5dfec7261d726a819c78c1", "title": "Muse: Text-To-Image Generation via Masked Generative Transformers"}, {"paperId": "9ceaeff7117965832f4c05fd6355d021862d0a82", "title": "Images Speak in Images: A Generalist Painter for In-Context Visual Learning"}, {"paperId": "55036dea7f6068d6b5de6ffe178bb324d01918a0", "title": "Sketch-Guided Text-to-Image Diffusion Models"}, {"paperId": "d388fad28e83fe335d03251196c940b575e90122", "title": "ReCo: Region-Controlled Text-to-Image Generation"}, {"paperId": "2f68d3934b006fcd01732adbc1ab459b2485fc8e", "title": "MAGE: MAsked Generative Encoder to Unify Representation Learning and Image Synthesis"}, {"paperId": "78281482c1fdad8e167bab39cc9955c73d58ae8f", "title": "EVA: Exploring the Limits of Masked Visual Representation Learning at Scale"}, {"paperId": "e5c8960eb2ec034ffbd353ef39fd1cb541d3c7c9", "title": "LAION-5B: An open large-scale dataset for training next generation image-text models"}, {"paperId": "301e396abf449e9a7f6ec21cd84494adf026e0cd", "title": "Exploring Target Representations for Masked Autoencoders"}, {"paperId": "0a25c137edc7c9752aa6d99ae4084683c3fe6b56", "title": "Visual Prompting via Image Inpainting"}, {"paperId": "02251886950770e82b3d68564d60cdfe15e73199", "title": "Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks"}, {"paperId": "599be9043ef3571f65758cf36e184c9dc1781baf", "title": "BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers"}, {"paperId": "af9f365ed86614c800f082bd8eb14be76072ad16", "title": "Classifier-Free Diffusion Guidance"}, {"paperId": "794c5d5ca20e71eae416da91cf1fed0a8ef15658", "title": "Masked Autoencoders that Listen"}, {"paperId": "30438276aefb976dd2ce0f26df345f315f2dfc14", "title": "Improving Diffusion Model Efficiency Through Patching"}, {"paperId": "1243e13254bb4ea1f71b4be8a3e4e54ffd02d2fe", "title": "Scaling Autoregressive Models for Content-Rich Text-to-Image Generation"}, {"paperId": "8b5eab31e1c5689312fff3181a75bfbf5c13e51c", "title": "Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks"}, {"paperId": "d2425b430fbf5b8ddf9cf2309c36a80a71e5a449", "title": "OmniMAE: Single Model Masked Pretraining on Images and Videos"}, {"paperId": "06761cb27e14aa55a6c3d98b949898aa26416698", "title": "A Unified Sequence Interface for Vision Tasks"}, {"paperId": "3ff7153fd6bd47d08084c7f50f8fd70026c126e7", "title": "Compositional Visual Generation with Composable Diffusion Models"}, {"paperId": "32b3553d7dc8a263c63d32eeec2916d1647ab178", "title": "DiVAE: Photorealistic Images Synthesis with Denoising Diffusion Decoder"}, {"paperId": "9695824d7a01fad57ba9c01d7d76a519d78d65e7", "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"}, {"paperId": "055cd2faeebc7a9df43923d554a61ae924a4af6b", "title": "UViM: A Unified Modeling Approach for Vision with Learned Guiding Codes"}, {"paperId": "004b97aea43f9f62cc49dec20f449abfbae28811", "title": "Masked Autoencoders As Spatiotemporal Learners"}, {"paperId": "4b9b3c538999410c58e229ca15437a693cbb03c5", "title": "MuIT: An End-to-End Multitask Learning Transformer"}, {"paperId": "5922f437512158970c417f4413bface021df5f78", "title": "A Generalist Agent"}, {"paperId": "b21670e8061a06ab97e7d6052c9345a326e84ff8", "title": "UL2: Unifying Language Learning Paradigms"}, {"paperId": "a26a7a74f1e5fd562be95c3611a0680759fbdf84", "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "d2f63b56fc6bc373f5c023454c2b253326962865", "title": "DeiT III: Revenge of the ViT"}, {"paperId": "c57293882b2561e1ba03017902df9fc2f289dea2", "title": "Hierarchical Text-Conditional Image Generation with CLIP Latents"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "b1fc7d96d732f99510658c73a8d9da3fd7b25923", "title": "MultiMAE: Multi-modal Multi-task Masked Autoencoders"}, {"paperId": "a09cbcaac305884f043810afc4fa4053099b5970", "title": "Exploring Plain Vision Transformer Backbones for Object Detection"}, {"paperId": "15e234a67f30d6761f1d7670d501095d1697b69c", "title": "Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors"}, {"paperId": "b079f791e01e0b308b8e3dae7989a917be73a1a4", "title": "Transframer: Arbitrary Frame Prediction with Generative Models"}, {"paperId": "140a158aa77e0e5281bf4fb3b8fa44696a2dd209", "title": "3D Common Corruptions and Data Augmentation"}, {"paperId": "7c597874535c1537d7ddff3b3723015b4dc79d30", "title": "MaskGIT: Masked Generative Image Transformer"}, {"paperId": "8f2bca9d684005675e294b33c26481e36f528cdb", "title": "data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language"}, {"paperId": "c783e1fb3ce8514f981925ee590c00884660ee4e", "title": "CM3: A Causal Masked Multimodal Model of the Internet"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d", "title": "High-Resolution Image Synthesis with Latent Diffusion Models"}, {"paperId": "7002ae048e4b8c9133a55428441e8066070995cb", "title": "GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models"}, {"paperId": "7d0dfbddbf5b824e7048b2d40fa5945afd18ac9c", "title": "Are Large-scale Datasets Necessary for Self-Supervised Pre-training?"}, {"paperId": "008a428e049003fe768068a0f1fa1416af5c4982", "title": "Masked Feature Prediction for Self-Supervised Visual Pre-Training"}, {"paperId": "3cd4797725ca9cf954946ed5309e15ebab80b92a", "title": "Multimodal Conditional Image Synthesis with Product-of-Experts GANs"}, {"paperId": "2fd6f77540c1cc8e70b96208ccf9971b4251fc02", "title": "FLAVA: A Foundational Language And Vision Alignment Model"}, {"paperId": "658a017302d29e4acf4ca789cb5d9f27983717ff", "title": "Masked-attention Mask Transformer for Universal Image Segmentation"}, {"paperId": "91dc75f94da13452a54ad5c03fab2c5fda87e9ba", "title": "Uni-Perceiver: Pre-training Unified Architecture for Generic Perception for Zero-shot and Few-shot Tasks"}, {"paperId": "9c4753ef43d2928866dc5bf6cec53d03373ec2fa", "title": "SimMIM: a Simple Framework for Masked Image Modeling"}, {"paperId": "9653c070724e44f023e8cc3ec79f0b9e6d59480d", "title": "iBOT: Image BERT Pre-Training with Online Tokenizer"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "9c7a2cd13b783bb73ad2d1ec2880bdd9b995cbdc", "title": "Vector-quantized Image Modeling with Improved VQGAN"}, {"paperId": "599bc7cfe98c2b57ddbe111412203a636da57be0", "title": "Autoregressive Diffusion Models"}, {"paperId": "f1a66139fa051370018a3539f15e60f728e437ca", "title": "Omnidata: A Scalable Pipeline for Making Multi-Task Mid-Level Vision Datasets from 3D Scans"}, {"paperId": "19b3b074d38b250d024920732ae51a8ffa0996dd", "title": "Pix2seq: A Language Modeling Framework for Object Detection"}, {"paperId": "12ce370b38cc69403e81980f33b413650900105c", "title": "Multi-Task Self-Training for Learning General Representations"}, {"paperId": "9933a5af7895354087baf6c96b64dc8a8973eaed", "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs"}, {"paperId": "59a0ef2d3bccebb544a2df4ad0453d49cc8e731f", "title": "SoundStream: An End-to-End Neural Audio Codec"}, {"paperId": "f1902f99c53781601061d794d957f77982753352", "title": "Attention Bottlenecks for Multimodal Fusion"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "0f183bcfe65781c06b1a48a6f56e0f3c63e8e4a4", "title": "Cascaded Diffusion Models for High Fidelity Image Generation"}, {"paperId": "0d5406775fab3e71848908327fb5504df5f60f92", "title": "ImageNet-21K Pretraining for the Masses"}, {"paperId": "166e98317ed9c4687e71bef55a6800431e00b8fa", "title": "SiT: Self-supervised vIsion Transformer"}, {"paperId": "8e33914d6051dd031a5e096962b9398fc1d16067", "title": "Vision Transformers for Dense Prediction"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "a87bb9e70d1127b6a9c0e721e48c0b58c997c70e", "title": "UniT: Multimodal Multitask Learning with a Unified Transformer"}, {"paperId": "de18baa4964804cf471d85a5a090498242d2e79f", "title": "Improved Denoising Diffusion Probabilistic Models"}, {"paperId": "394be105b87e9bfe72c20efe6338de10604e1a11", "title": "Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts"}, {"paperId": "47f7ec3d0a5e6e83b6768ece35206a94dc81919c", "title": "Taming Transformers for High-Resolution Image Synthesis"}, {"paperId": "914a593b7f2e980470075a9955f1407641669a8f", "title": "Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation"}, {"paperId": "84c40cf28afdf84ec6941d92cacd49fed3c7ef9a", "title": "Hypersim: A Photorealistic Synthetic Dataset for Holistic Indoor Scene Understanding"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "014576b866078524286802b1d0e18628520aa886", "title": "Denoising Diffusion Implicit Models"}, {"paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8", "title": "Generative Pretraining From Pixels"}, {"paperId": "6e2d24dbf959aeb855926430bf1cb476346719b3", "title": "On the Theory of Transfer Learning: The Importance of Task Diversity"}, {"paperId": "5c126ae3421f05768d8edd97ecd44b1364e2c99a", "title": "Denoising Diffusion Probabilistic Models"}, {"paperId": "a0265f14b07811c502f9dd730ec1f10daf2ff345", "title": "Robust Learning Through Cross-Task Consistency"}, {"paperId": "5b2420f9e00b311f451a4fd10168960c8622cbef", "title": "OASIS: A Large-Scale Dataset for Single Image 3D in the Wild"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "80455126562cfe6a483e02b3446a3f30b8e9f229", "title": "Rethinking Few-Shot Image Classification: a Good Embedding Is All You Need?"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3", "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "7406e5c8341b9e8a72080edc15ee3317ce38de22", "title": "DIODE: A Dense Indoor and Outdoor DEpth Dataset"}, {"paperId": "7bd83b055702bc178aa26def5b6df463f8eab7b9", "title": "Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-Shot Cross-Dataset Transfer"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "096803265d747a37b8b032b8e71ef2e42f4bcd41", "title": "Bfloat16 Processing for Neural Networks"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "d9dcd1e99a91a9662b1f0edf248808ec5e9297ac", "title": "Mid-Level Visual Representations Improve Generalization and Sample Efficiency for Learning Visuomotor Policies"}, {"paperId": "2fe2cfd98e232f1396f01881853ed6b3d5e37d65", "title": "Taskonomy: Disentangling Task Transfer Learning"}, {"paperId": "04957e40d47ca89d38653e97f728883c0ad26e5d", "title": "Cascade R-CNN: Delving Into High Quality Object Detection"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "f466157848d1a7772fb6d02cdac9a7a5e7ef982e", "title": "Neural Discrete Representation Learning"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "0d57ba12a6d958e178d83be4c84513f7e42b24e5", "title": "Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "922197906907dc0a5e1b51fae40d3149333ecacf", "title": "UberNet: Training a Universal Convolutional Neural Network for Low-, Mid-, and High-Level Vision Using Diverse Datasets and Limited Memory"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "cb3a2ddcf305e2ec0f6b94af13d1e631ed261bdc", "title": "Predicting Depth, Surface Normals and Semantic Labels with a Common Multi-scale Convolutional Architecture"}, {"paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd", "title": "ImageNet Large Scale Visual Recognition Challenge"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "c1994ba5946456fc70948c549daf62363f13fa2d", "title": "Indoor Segmentation and Support Inference from RGBD Images"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "727e1e16ede6eaad241bad11c525da07b154c688", "title": "A Model of Inductive Bias Learning"}, {"paperId": "161ffb54a3fdf0715b198bb57bd22f910242eb49", "title": "Multitask Learning"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": null, "title": "ELECTRA: Pre-training text encoders as discriminators rather than generators"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "25f8e9e35cafd7fb686d939f274111bcffeafd6b", "title": "The Development of Embodied Cognition: Six Lessons from Babies"}, {"paperId": null, "title": "NegPrompt"}, {"paperId": null, "title": "WebDataset"}, {"paperId": null, "title": "Image-text pair dataset"}, {"paperId": null, "title": "Multimodal image synthesis and editing: A survey"}]}