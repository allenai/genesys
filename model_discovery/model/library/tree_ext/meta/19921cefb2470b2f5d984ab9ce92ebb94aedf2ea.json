{"paperId": "19921cefb2470b2f5d984ab9ce92ebb94aedf2ea", "title": "Sparsifiner: Learning Sparse Instance-Dependent Attention for Efficient Vision Transformers", "abstract": "Vision Transformers (ViT) have shown competitive advantages in terms of performance compared to convolutional neural networks (CNNs), though they often come with high computational costs. To this end, previous methods explore different attention patterns by limiting a fixed number of spatially nearby tokens to accelerate the ViT's multi-head self-attention (MHSA) operations. However, such structured attention patterns limit the token-to-token connections to their spatial relevance, which disregards learned semantic connections from a full attention mask. In this work, we propose an approach to learn instance-dependent attention patterns, by devising a lightweight connectivity predictor module that estimates the connectivity score of each pair of tokens. Intuitively, two tokens have high connectivity scores if the features are considered relevant either spatially or semantically. As each token only attends to a small number of other tokens, the binarized connectivity masks are often very sparse by nature and therefore provide the opportunity to reduce network FLOPs via sparse computations. Equipped with the learned unstructured attention pattern, sparse attention ViT (Sparsifiner) produces a superior Pareto frontier between FLOPs and top-1 accuracy on ImageNet compared to token sparsity. Our method reduces 48% ~ 69% FLOPs of MHSA while the accuracy drop is within 0.4%. We also show that combining attention and token sparsity reduces ViT FLOPs by over 60%.", "venue": "Computer Vision and Pattern Recognition", "year": 2023, "citationCount": 5, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2303.13755", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes an approach to learn instance-dependent attention patterns, by devising a lightweight connectivity predictor module that estimates the connectivity score of each pair of tokens, and produces a superior Pareto frontier between FLOPs and top-1 accuracy on ImageNet compared to token sparsity."}, "embedding": {"model": "specter_v2", "vector": [0.12822966277599335, 0.9593372941017151, -0.5872870087623596, 0.46554338932037354, -0.12079370021820068, 0.12691453099250793, 0.7132353186607361, 0.12521249055862427, -0.0443652905523777, -0.4051409959793091, 0.4116080403327942, 0.5986309051513672, 0.20793209969997406, -0.14912548661231995, -0.26018500328063965, 0.12843668460845947, -0.9446830153465271, 0.24587330222129822, 0.3666273355484009, -0.2513851523399353, 0.5390997529029846, -0.8516203761100769, -1.3803938627243042, 0.06985698640346527, 0.5984798073768616, 1.230624794960022, 0.3004121482372284, 0.682641327381134, -0.46510815620422363, 0.6285442113876343, 0.30719491839408875, -0.18888802826404572, 0.4583016037940979, 0.10405495017766953, -0.6118115782737732, -0.1275758594274521, 0.9025870561599731, 0.11598151177167892, -0.5876048803329468, 0.8916110396385193, -0.25222310423851013, 0.12663505971431732, 0.2942003011703491, -0.8573827743530273, -0.27843353152275085, 0.8725120425224304, 0.3265286087989807, 0.7018574476242065, -0.5136796832084656, -0.6176883578300476, 1.5893641710281372, -1.1767735481262207, 0.1377304345369339, 1.0011491775512695, 0.1868690401315689, 0.17612703144550323, -0.004307792987674475, -0.44499149918556213, 1.0431067943572998, 0.7952375411987305, -0.6812193989753723, -0.3055095672607422, 0.23182378709316254, -0.10517673939466476, 1.997675895690918, -0.6937344074249268, 0.43198058009147644, 0.2599905729293823, -0.19655409455299377, 1.2997894287109375, -0.20302540063858032, -0.6708477139472961, -0.10330861806869507, -0.08704487979412079, 0.050039418041706085, 0.8725531697273254, -0.15563541650772095, 0.1428626924753189, -1.290097951889038, 0.3781655728816986, 0.6597526669502258, -0.02757227048277855, 0.5934904217720032, -0.2274487018585205, -0.17722129821777344, 0.4630469083786011, 0.9595281481742859, 0.8595271706581116, -0.5423235893249512, 0.9286192059516907, 0.7807177305221558, 0.16805367171764374, -0.25452807545661926, 0.2997257709503174, 0.08757200837135315, 0.7368630766868591, -0.8285882472991943, -0.1059812530875206, -0.07425808906555176, 1.0065264701843262, 0.08396009355783463, 0.4546602666378021, -0.4896923005580902, 0.08633994311094284, 1.099846363067627, -0.07029406726360321, 0.3486509323120117, -0.4459971785545349, 0.22801759839057922, -0.5410675406455994, -0.3391149044036865, -0.7869145274162292, 0.256361186504364, -0.3338863253593445, -1.0114787817001343, -0.9428295493125916, -0.40898653864860535, 0.6607300639152527, -1.004992961883545, 0.36299964785575867, -0.3276599645614624, 0.5322099328041077, -0.3618853986263275, 0.4514908492565155, 0.6486431360244751, 0.23623262345790863, 0.25980648398399353, 0.542236328125, 1.219495415687561, -1.2475841045379639, -0.05628952756524086, -0.9716778993606567, -0.056753795593976974, -0.2223326563835144, 0.05248156934976578, 0.08618994802236557, -1.3606733083724976, -1.0345746278762817, -0.6161211133003235, 0.0033415029756724834, -0.7068995833396912, -0.1389196217060089, 0.8112757802009583, 0.005508009344339371, -1.395388126373291, 0.7839287519454956, -0.2930815815925598, -0.47852975130081177, 0.7437472939491272, 0.3818237781524658, 0.2455979585647583, -0.12607711553573608, -1.235626459121704, 0.3862365782260895, -0.06149331107735634, -0.5742303729057312, -0.6346679329872131, -0.419106125831604, -1.3816605806350708, 0.3045516908168793, 0.3852555453777313, -0.6109151244163513, 0.934235155582428, -0.33892983198165894, -0.7619213461875916, 0.817179799079895, -0.3394660949707031, -0.20007775723934174, 0.17426691949367523, 0.037110161036252975, -0.13658902049064636, 0.11527233570814133, 0.22277237474918365, 0.7714405059814453, 1.0411713123321533, -0.18141940236091614, -0.29031670093536377, 0.21699535846710205, -0.316759318113327, -0.27852901816368103, -0.497165322303772, 0.7522920370101929, -0.5497965216636658, -0.13228283822536469, 0.31748151779174805, 1.0608402490615845, -0.10455871373414993, -0.1021181121468544, -0.5754528045654297, -1.1817288398742676, 0.6248545050621033, 0.47591546177864075, 0.1575634926557541, -0.6940444707870483, -0.927937388420105, 0.09900257736444473, 0.1682499200105667, -0.06323359161615372, -1.029632806777954, 0.5664064288139343, -0.5153108835220337, 0.3565213680267334, 0.3042784035205841, -0.7569476962089539, -0.11424682289361954, -0.2984314560890198, -0.5837937593460083, -0.1783057600259781, 0.2519390881061554, 1.0503339767456055, -0.8925399780273438, -0.4110114872455597, 0.26164284348487854, 0.5267093777656555, -0.8441687226295471, 0.8244657516479492, -0.41932037472724915, -0.12046924233436584, -0.20671898126602173, 0.2692315876483917, 0.0694202184677124, -0.38531193137168884, 0.28095942735671997, -0.6232729554176331, -0.15852229297161102, 0.81744384765625, -0.22682607173919678, 1.2702044248580933, -0.21416515111923218, 0.5292714834213257, -0.06559223681688309, -1.3168104887008667, 0.387491375207901, 0.4814409911632538, 0.30832692980766296, -1.0047109127044678, 0.11765431612730026, -0.20728178322315216, -0.8642768859863281, 0.0684119462966919, 0.8281683921813965, 1.3034347295761108, -0.2552453875541687, -0.2797339856624603, 0.7185899615287781, -0.24146756529808044, 0.33902662992477417, 0.5625718235969543, 0.8233908414840698, 0.1568455696105957, 0.35411956906318665, -0.16435982286930084, 0.01913130283355713, -0.7100088000297546, 0.012971552088856697, 0.7629057168960571, 0.45652374625205994, 0.8751716613769531, 0.6141344904899597, -0.8819225430488586, -0.4764319062232971, 0.22717630863189697, 0.5917101502418518, 0.9619325399398804, 0.26614031195640564, -0.22140666842460632, -0.7458981871604919, -0.5559913516044617, -0.40778297185897827, -0.6996415257453918, -0.4538947343826294, -0.09104505181312561, -0.2502969801425934, -0.523410975933075, 0.7281968593597412, 0.4034973978996277, 1.3603994846343994, -1.0625510215759277, -0.4763071835041046, -0.3047212064266205, 0.07535452395677567, -0.9602523446083069, -0.3604303300380707, 0.5361153483390808, -0.24841736257076263, -0.41998207569122314, 0.06331395357847214, -0.5419185757637024, 0.35392826795578003, -0.3515758216381073, 1.0588098764419556, -0.3145468831062317, -0.7626305818557739, 0.2560219466686249, 0.2562723159790039, -0.6051278710365295, 0.3908257782459259, 0.31842514872550964, -0.022329388186335564, -0.3473617732524872, 0.14844146370887756, 0.31055229902267456, -0.5325829982757568, 0.059244245290756226, -0.2499789148569107, -0.3334079682826996, 0.00027615195722319186, 0.18016669154167175, 0.88844895362854, -0.2119770050048828, 0.0886298194527626, -0.8304218649864197, 0.17956775426864624, -0.08241673558950424, -0.28529879450798035, -0.13963940739631653, -0.5817199945449829, -0.4810808002948761, 0.4146517813205719, -0.5516160130500793, 0.09558936953544617, -0.5737431049346924, 0.6679499745368958, -0.5965151190757751, -0.49513599276542664, 0.0931655764579773, 0.34061387181282043, -0.43387603759765625, 0.34910768270492554, 0.44726017117500305, -0.03851545602083206, 0.2505795359611511, 0.4486238360404968, -1.190354585647583, 0.7851328253746033, -0.0963449776172638, 0.27502694725990295, 0.1264277845621109, -0.06564440578222275, -0.9106985330581665, -0.3706984519958496, -0.5597283840179443, -0.19499851763248444, -0.13519561290740967, 0.24587903916835785, -0.6655914187431335, -1.068497657775879, 0.008180570788681507, -0.9292294979095459, -0.524082601070404, -0.439435213804245, -0.4012438654899597, -0.2533056139945984, -0.8940463662147522, -0.8280167579650879, -0.4397493600845337, -0.7648734450340271, -0.8527281284332275, 0.21264035999774933, 0.2920563220977783, -0.2626494765281677, -0.4358426034450531, -0.3220633864402771, -0.3975032567977905, 1.0704129934310913, -0.47875094413757324, 0.42919522523880005, -0.03060637041926384, -0.7308117151260376, -0.14248661696910858, -0.36200568079948425, 0.1706385314464569, -0.08099544793367386, 0.09625042229890823, -0.867813766002655, 0.42424002289772034, -0.573186457157135, -0.5646860003471375, 0.573184072971344, 0.6177852153778076, 0.9315932393074036, -0.2081012725830078, -0.5398684740066528, 0.35169148445129395, 1.7767589092254639, -0.8207670450210571, 0.565875768661499, 0.2211928367614746, 1.110413908958435, 0.36944690346717834, -0.3637850284576416, 0.6028516292572021, 0.8622469305992126, 0.16379162669181824, 0.9643666744232178, -0.750000536441803, -0.5212243795394897, -0.4941742718219757, 0.11372840404510498, 1.0622634887695312, 0.26057443022727966, 0.03223253786563873, -0.7478259205818176, 1.416124701499939, -1.3103328943252563, -1.0090745687484741, 0.5702242255210876, 0.4669927656650543, -0.04454565420746803, -0.38130590319633484, -0.16697131097316742, -0.05864357203245163, 0.7856774926185608, 0.36398446559906006, -0.3354427218437195, -0.614352822303772, 0.14183980226516724, 1.015342354774475, 0.5311851501464844, 0.3574765622615814, -0.22333450615406036, 0.9895883798599243, 14.884339332580566, 0.7155821919441223, -0.21653693914413452, 0.3645179569721222, 0.6419753432273865, 0.2256104201078415, -0.22287267446517944, 0.3575170040130615, -1.1432836055755615, -0.09048020094633102, 0.4872209429740906, 0.4232819378376007, 0.5272835493087769, 0.08479580283164978, 0.04362742230296135, -0.09050925076007843, -0.3610219955444336, 0.4009576439857483, 0.6956692337989807, -1.222745656967163, 0.30868154764175415, 0.18434885144233704, 0.45969921350479126, 0.5670477747917175, 0.9344542026519775, 0.40840473771095276, 0.5536147952079773, -0.5120720863342285, 0.46053197979927063, 0.24086351692676544, 1.2862120866775513, 0.16490337252616882, 0.15153370797634125, -0.10730576515197754, -1.398391604423523, 0.034871723502874374, -0.6428133249282837, -1.0963032245635986, -0.022645238786935806, 0.33998310565948486, -0.27937278151512146, -0.351156085729599, 0.2050061821937561, 0.9787448048591614, 0.2759501338005066, 0.8219807744026184, -0.39273929595947266, 0.17377570271492004, 0.0408196821808815, 0.10036344826221466, 0.42877358198165894, 0.9909839034080505, -0.09298837184906006, -0.15973496437072754, -0.0252835750579834, -0.0875321477651596, 0.28030523657798767, 0.4989469647407532, -0.39658764004707336, -0.44627219438552856, -0.5502626895904541, 0.0508941188454628, 0.10452864319086075, 1.2113029956817627, 0.062021538615226746, 0.16315694153308868, -0.29903924465179443, 0.0961521714925766, 0.5063917636871338, 0.030572867020964622, -0.24306344985961914, -0.47196078300476074, 0.3825918734073639, -0.2542056143283844, 0.34475046396255493, 0.7248117923736572, -0.6151840686798096, -0.5041381120681763, -0.7916303873062134, -0.12364905327558517, 0.6919942498207092, -0.812304675579071, -0.478329598903656, 0.9557697772979736, -0.38459572196006775, -0.35578376054763794, 0.5676131248474121, -0.6598010063171387, -0.887127697467804, 0.2345108985900879, -1.8668804168701172, -1.0677759647369385, -0.16324970126152039, 0.18518821895122528, -0.18111039698123932, -0.0018453235970810056, 0.9511982798576355, 0.0303803738206625, -0.16969144344329834, 0.37909039855003357, -0.7144840955734253, 0.0010275603272020817, -0.041169583797454834, -0.8624618053436279, 0.845565915107727, 0.2783013582229614, 0.08976606279611588, -0.09592384845018387, -0.1299542337656021, 0.18755251169204712, -0.3331284821033478, -0.07327715307474136, 0.9261359572410583, -0.35751819610595703, -0.4205222725868225, -0.4197004735469818, -0.567229688167572, 0.27793487906455994, 0.9160298109054565, 0.4044623374938965, -0.1401785910129547, 0.1987820565700531, -0.7526376843452454, -0.26534950733184814, -1.049721121788025, -0.12232179194688797, 0.39288344979286194, -0.7922104597091675, -0.3243706226348877, -0.18351460993289948, -0.032957009971141815, -0.7588465213775635, -0.30902618169784546, -0.28664329648017883, 0.05003144592046738, -0.28091710805892944, 1.2512234449386597, 0.005041343625634909, 0.9874022603034973, 0.7859099507331848, 0.22721406817436218, -0.6996250152587891, -0.03930169343948364, -0.9424507021903992, 0.05114791914820671, 0.23088161647319794, 0.2733110189437866, -0.5301315784454346, 0.5988726615905762, 0.6135942339897156, 0.18337252736091614, -0.2389671355485916, -0.5301514863967896, 0.012849558144807816, -0.3690635561943054, -0.3786080777645111, 0.3591056764125824, 0.4658533036708832, 0.5785799026489258, -0.25553637742996216, 0.656495988368988, 0.453888475894928, 0.27716949582099915, -0.7120472192764282, -0.006454983726143837, -0.22317560017108917, 0.1789274960756302, -0.5626434087753296, -0.8812617659568787, -1.123130202293396, -0.11654168367385864, -1.1040140390396118, -0.05610198900103569, -1.2107634544372559, -0.4607316255569458, -0.07974281907081604, -0.7337319850921631, 0.7038484215736389, 0.6056388020515442, 0.24942204356193542, -0.5775958895683289, -0.7458885312080383, -0.7476349472999573, 0.555441677570343, 1.0010730028152466, -1.0609856843948364, 0.184993714094162, -0.3797038495540619, -0.5251781344413757, 0.40572458505630493, 0.5328934788703918, -0.3713148534297943, -0.5176540017127991, -1.1603666543960571, 0.4575721323490143, -0.10432621836662292, 0.2609264850616455, -0.9202954173088074, 1.1927928924560547, 0.5626639723777771, 0.030780130997300148, -0.10543998330831528, 0.18758125603199005, -0.8199971318244934, -1.059237003326416, 0.40666359663009644, -0.5804148316383362, -0.15216639637947083, 0.17849235236644745, -0.5999670624732971, -0.48682332038879395, 0.7536478042602539, 0.03874911367893219, -1.400699257850647, -1.0254652500152588, 0.671550989151001, -0.3981780409812927, 0.3572786748409271, -0.22089561820030212, -0.4615195393562317, -1.431656002998352, -0.24374601244926453, -0.1332031786441803, 0.6139569282531738, -0.5805029273033142, 0.7736201882362366, 0.6970390677452087, -1.033018946647644, 0.2391701638698578, 0.41817107796669006, -0.05653959885239601, 0.44046008586883545, 0.49603039026260376, 0.46114104986190796, -0.263489693403244, 0.26281777024269104, -0.26552900671958923, 0.27285581827163696, -0.40581753849983215, 0.142266646027565, 0.6502106785774231, -0.39581596851348877, -0.2564378082752228, 0.9774404168128967, -0.3662004768848419, -0.4124031960964203, 0.3217998445034027, -1.0806697607040405, -0.8185425996780396, 0.06173816695809364, 0.4291602075099945, 0.25642532110214233, -0.08504888415336609, -0.08995566517114639, -0.5830842852592468, 0.567764401435852, -0.337225079536438, -0.27336952090263367, 0.5034927129745483, 0.08721301704645157, -0.3758711516857147, -0.18246033787727356, 0.343528687953949, -1.0366158485412598, -0.943328320980072, -0.8829072713851929, -0.7436871528625488, -0.08627492189407349, 0.3968762457370758, -0.12973083555698395, -1.2306430339813232, 0.8912564516067505, 0.3471618890762329, 0.7825980186462402, -0.03696529567241669, -0.008465119637548923, 0.19442854821681976, 0.4956094026565552, 0.08149784803390503, -0.736397385597229, -0.010606681928038597, 1.2309329509735107, 0.8385554552078247, -0.649038553237915, 0.0018967891810461879, -0.17900662124156952, -0.7163631916046143, 0.40079137682914734, 0.708722710609436, -0.49459439516067505, 0.6909777522087097, -0.05047730356454849, -0.18158812820911407, -0.28025686740875244, -0.7275616526603699, -0.7746506333351135, 0.638106644153595, 1.6044161319732666, 0.45641028881073, -0.16405770182609558, 0.3702210783958435, 0.4730110466480255, 0.2737267017364502, -0.15855105221271515, 0.24575406312942505, 0.03513133153319359, -0.1500135064125061, 0.028036130592226982, 0.15792933106422424, 0.47097623348236084, -0.6875060200691223, -0.7126278281211853, -0.1405140608549118, 0.35093238949775696, 0.2770252227783203, 0.7307186126708984, 1.1831716299057007, 0.06592537462711334, 0.502171516418457, -0.33929601311683655, 0.5836331844329834, -0.6046145558357239, -0.3960764408111572, -0.19100959599018097, -0.9191133975982666, -0.3813735842704773, -0.23440717160701752, -0.4830215871334076, -0.39679333567619324, -0.13486528396606445, -0.0012096029240638018, -0.20633719861507416, 0.42681777477264404, 0.9472826719284058, 0.578100860118866, 0.8995460867881775, -0.006391734350472689, -1.0169217586517334, 0.11006869375705719, -0.5718315243721008, 0.05846041440963745, -0.6366692185401917, -0.061673298478126526, -0.18652667105197906, -0.11530610173940659, -0.23788917064666748]}, "authors": [{"authorId": "2212734382", "name": "Cong Wei"}, {"authorId": "40807486", "name": "Brendan Duke"}, {"authorId": "2052890223", "name": "R. Jiang"}, {"authorId": "3241876", "name": "P. Aarabi"}, {"authorId": "144639556", "name": "Graham W. Taylor"}, {"authorId": "2162768", "name": "F. Shkurti"}], "references": [{"paperId": "88b7f8ab3933ee4775eaa200029755e0022f8870", "title": "EViT: Privacy-Preserving Image Retrieval via Encrypted Vision Transformer in Cloud Computing"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "04715db23b5f63cf8d8e2e04c2798a74d16cdf6b", "title": "Not All Tokens Are Equal: Human-centric Visual Analysis via Token Clustering Transformer"}, {"paperId": "8326dba15f6b8ee6e43c23eea3265a05e59e8135", "title": "Monarch: Expressive Structured Matrices for Efficient and Accurate Training"}, {"paperId": "202967f77c4384bce80eaf2fa5737259008267d3", "title": "Learning to Merge Tokens in Vision Transformers"}, {"paperId": "658a017302d29e4acf4ca789cb5d9f27983717ff", "title": "Masked-attention Mask Transformer for Universal Image Segmentation"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "260ad39a1dac4b451019e2bf17925f4df8e3b69a", "title": "Per-Pixel Classification is Not All You Need for Semantic Segmentation"}, {"paperId": "33fd56e5067a1e8a9713378af3e1c1c08d5ce93b", "title": "Patch Slimming for Efficient Vision Transformers"}, {"paperId": "dbdcabd0444ad50b68ee09e30f39b66e9068f5d2", "title": "DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification"}, {"paperId": "77366bef01df1ab277149b330336a0ef9c5041c4", "title": "Transformer"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "cc9f3a61ea4eaabf43cbb30cd1dd718074932679", "title": "All Tokens Matter: Token Labeling for Training Better Vision Transformers"}, {"paperId": "3cbe314cc5407a6c3249815b5173f22ea15173c2", "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "fa08b41ccdfc5d8771adfbc34c176fa237d4646c", "title": "Is Space-Time Attention All You Need for Video Understanding?"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "8f2221bc4da30a56bfcd3ebe481952a981b81e49", "title": "SSTVOS: Sparse Spatiotemporal Transformers for Video Object Segmentation"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "2e1db8cb373f4d4a51d44308b7a457886d855fbb", "title": "End-to-End Object Detection with Adaptive Clustering Transformer"}, {"paperId": "c13a8f9edb933e60c7a989244aee56283a54ce37", "title": "UP-DETR: Unsupervised Pre-training for Object Detection with Transformers"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "f7f89feee68b6856c0a980a5888b42d18231be07", "title": "Learning Joint Spatial-Temporal Transformations for Video Inpainting"}, {"paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8", "title": "Generative Pretraining From Pixels"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "35ed258aede3df17ee20a6635364cb5fd2461049", "title": "End-to-End Dense Video Captioning with Masked Transformer"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "9af62668cb87f11fffb53a194588c8158fde6b00", "title": "DynamicViT: Ef\ufb01cient Vision Transformers with Dynamic Token Sparsi\ufb01cation"}, {"paperId": "eaa09c607780373cc809bce89b6b28b17e301f27", "title": "TokenLearner: Adaptive Space-Time Tokenization for Videos"}, {"paperId": null, "title": "Set transformer: A framework for attention-based permutation-invariant neural networks"}, {"paperId": null, "title": "license agreement with IEEE. Restrictions apply"}]}