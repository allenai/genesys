{"paperId": "446895e8cd74dd17762750d50e0bd1f57032e8f4", "title": "Mask-Conformer: Augmenting Conformer with Mask-Predict Decoder", "abstract": "Much of the recent progress in automatic speech recognition (ASR) lies in developing an acoustic encoder, such as enlarging its capacity and designing a refined architecture for speech processing. With these highly optimized encoders, the decoder has become less influential in its role as a language model (LM). In this work, we explore an effective approach for employing the LM structure in an ASR model. The proposed Mask-Conformer augments a Conformer-based model with a mask-predict decoder, which learns output context via the masked LM objective. The mask-predict decoder is applied to stacks of encoder layers, where the decoder output explicitly conditions the subsequent layers using cross-attention. We also propose a fill-mask decoding algorithm that refines a sequence using the decoder\u2019s linguistic information. Experimental results show that Mask-Conformer outperforms strong baselines on some tasks. In addition, our analyses validate the effectiveness of the proposed model design.", "venue": "Automatic Speech Recognition & Understanding", "year": 2023, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The proposed Mask-Conformer augments a Conformer-based model with a mask-predict decoder, which learns output context via the masked LM objective, and proposes a fill-mask decoding algorithm that refines a sequence using the decoder\u2019s linguistic information."}, "embedding": {"model": "specter_v2", "vector": [0.4845132529735565, 1.0223594903945923, -0.08042692393064499, -0.334879070520401, -0.4906335771083832, -0.05032286047935486, 0.26133692264556885, -0.4149869978427887, -0.13371902704238892, -0.6955093145370483, 0.9368781447410583, -0.28950804471969604, 0.6931655406951904, 0.5886383652687073, -0.11714845895767212, 0.34281420707702637, -0.8083670139312744, -0.48364385962486267, -0.08808309584856033, -0.24147652089595795, -0.5117131471633911, -1.1117565631866455, -0.5342576503753662, 0.7684845328330994, -0.09064514189958572, 0.5105025768280029, 0.6675872802734375, 1.073420763015747, -0.10022324323654175, 0.030470140278339386, 0.24030804634094238, -0.7078485488891602, 0.5615873336791992, -0.23041696846485138, 0.22321361303329468, 0.245614692568779, 0.2593268156051636, -0.28588247299194336, -0.1872955709695816, 0.7509925961494446, -0.2393530309200287, 0.13105636835098267, 0.33107686042785645, -0.08434874564409256, -0.12744061648845673, 1.6125247478485107, 0.303732305765152, 1.0088454484939575, -0.5368899703025818, -0.6777591705322266, 1.2491976022720337, -1.7186319828033447, -0.45342007279396057, 1.72068452835083, 0.5381246209144592, 0.6980785131454468, -0.588833749294281, -0.7356165647506714, 1.137264370918274, -0.3000583350658417, -1.027895450592041, -1.0967212915420532, 0.08204731345176697, 0.12106072157621384, 1.7075648307800293, -0.2568032443523407, -0.25711771845817566, 0.5637291073799133, 0.006153738591820002, 1.0109856128692627, -0.1302265226840973, -0.4482343792915344, -0.25557684898376465, 0.14494875073432922, 0.09265664219856262, 0.6866300106048584, -0.35559383034706116, 0.5592241883277893, -1.179093360900879, 0.08597033470869064, 0.17980250716209412, -0.4952276051044464, -0.16717538237571716, 0.19318491220474243, -0.11678579449653625, 0.4665307104587555, -0.008068890310823917, 0.9891826510429382, -0.14071714878082275, 0.6622462272644043, 0.4359220564365387, 0.18750767409801483, 0.23140034079551697, 0.16846194863319397, -0.2526596486568451, 0.513612687587738, -1.0768470764160156, -0.15048541128635406, -0.10888892412185669, 0.7117034792900085, -0.11866430938243866, 0.7934970855712891, -0.5366002321243286, 0.5177614688873291, 1.890052318572998, -0.003974951803684235, 0.4516349136829376, -0.8346920609474182, 0.6212325096130371, -1.1875145435333252, -0.13599421083927155, -0.6448060274124146, 0.13819807767868042, -0.5177126526832581, -0.44699907302856445, -1.1472163200378418, -0.9235746264457703, -0.08247217535972595, -0.8910831809043884, 1.172768235206604, -0.10852417349815369, -0.024892065674066544, 0.30174368619918823, 0.26188430190086365, -0.008057590574026108, 0.9154950976371765, 0.3402921259403229, -0.2898057997226715, 0.9027267694473267, -0.8975234031677246, -1.0742902755737305, -1.2720249891281128, 0.5370991826057434, -0.3928883671760559, -0.030856378376483917, -0.3097299039363861, -1.2018051147460938, -1.1919119358062744, -1.2501496076583862, 0.46039146184921265, -0.0628657191991806, 0.4834926128387451, 0.18226416409015656, 0.7831562757492065, -1.341050386428833, 0.6483290195465088, -0.26109856367111206, 0.09554989635944366, 0.19362719357013702, 0.187456876039505, 0.1712525486946106, 0.3331994414329529, -0.8431665301322937, 0.04555092006921768, 0.46874549984931946, -0.3102758228778839, 0.0019565143156796694, -0.7887277007102966, -1.2091028690338135, -0.3683965802192688, 0.40423381328582764, -0.2929452359676361, 1.686442255973816, 0.010955524630844593, -1.6388336420059204, 0.5090179443359375, -0.6251727938652039, 0.12115024030208588, -0.41837263107299805, -0.29465606808662415, -1.0655373334884644, -0.3624807298183441, -0.21080529689788818, 0.6630671620368958, 0.4296976923942566, -0.6963309645652771, -0.25448447465896606, 0.320148766040802, -0.7326654195785522, -0.11299002170562744, -0.06826175004243851, 0.9420527219772339, -0.3278188407421112, -0.6913581490516663, 0.438658744096756, 0.7647329568862915, 0.0852193608880043, -0.4699443578720093, -0.8969995975494385, -0.5361413359642029, 1.0833768844604492, -0.3388865292072296, 1.558824062347412, -1.100476861000061, -0.8862861394882202, 0.11006151884794235, -0.4300340712070465, 0.05660375580191612, -0.6536358594894409, 0.45267540216445923, -0.5051652789115906, 0.8098722100257874, -0.440451443195343, -1.4378968477249146, -0.048812560737133026, -0.414252907037735, -0.736993670463562, -0.39477214217185974, 0.5478006601333618, 0.563331663608551, -0.12783227860927582, -0.08495412766933441, -0.20170485973358154, 0.24371971189975739, -1.1172503232955933, 1.2612056732177734, -0.18056005239486694, 0.5480729937553406, 0.24986912310123444, -0.42046767473220825, 0.10254084318876266, 0.09439244121313095, 0.36887627840042114, -0.7590368390083313, -0.20552416145801544, 0.9344755411148071, -0.6861317753791809, 1.0429595708847046, -0.2731693685054779, 0.3272167146205902, 0.5266534686088562, -0.6074066758155823, 0.3434159755706787, 0.813237726688385, -0.18796487152576447, -0.3040691316127777, 0.6420053243637085, 0.4213476777076721, -0.038867972791194916, 0.3942160904407501, 0.7108984589576721, 0.6750213503837585, -0.2056373655796051, 0.29462730884552, 0.44952985644340515, -0.3332013189792633, 0.25532346963882446, 0.18801014125347137, 0.7027449607849121, 0.3568096160888672, 0.5258015394210815, -0.32211068272590637, 0.46270516514778137, -1.375667691230774, 0.06417449563741684, 0.1211470440030098, 0.62613844871521, 0.8457738161087036, 0.11491738259792328, -0.3451046049594879, -0.23738917708396912, -0.24147829413414001, 0.543001115322113, 1.170146107673645, -0.45893409848213196, -0.2950894832611084, -1.126002311706543, -0.23964762687683105, -0.5011279582977295, 0.19868062436580658, -0.046963538974523544, -0.3084588646888733, -0.9141725301742554, -0.5833646655082703, 0.9180541634559631, 0.22504346072673798, 0.8181124925613403, -0.406142920255661, 0.17693710327148438, -0.1463087797164917, 0.23182466626167297, -1.067654013633728, -1.2279586791992188, 0.283863365650177, -0.36207103729248047, 0.010748211294412613, 0.4534645676612854, -0.12408622354269028, -0.11153712123632431, -0.8702803254127502, 0.4851981997489929, -0.3685775399208069, -0.2074248045682907, 0.009980698116123676, 0.5401401519775391, -0.5657186508178711, -1.4631203413009644, 0.08429056406021118, 0.3672054409980774, 0.6753197312355042, 0.15013808012008667, 0.4778079092502594, -0.03821588680148125, 0.3917936086654663, -0.2505212426185608, 0.1303105354309082, 0.05532297492027283, -0.4974793791770935, 0.8109300136566162, -0.6885471940040588, 0.4488394558429718, -1.1314741373062134, 0.7138306498527527, 0.052664607763290405, -0.12323490530252457, 0.0345623679459095, -0.5776446461677551, -0.3813832402229309, 0.26017898321151733, -0.37374600768089294, -0.5576997399330139, -0.8712990283966064, -0.04483756422996521, -0.007747642695903778, -0.04282929375767708, 0.11013402789831161, -0.2236366868019104, 0.6383733749389648, -0.041359324008226395, 0.1916971504688263, 0.4281190037727356, -0.3413124978542328, 0.5710923671722412, -0.25334709882736206, 0.3693865239620209, 0.5219535827636719, 0.24805477261543274, -0.38589656352996826, -0.5650785565376282, -0.7979719638824463, -0.4214187562465668, -0.3094526529312134, 0.17277704179286957, -0.46407589316368103, 0.4414064586162567, -0.4341800808906555, -0.7587734460830688, -0.3838792145252228, -1.1424542665481567, 0.0242818221449852, -0.015310769900679588, 0.05813240632414818, -0.38205862045288086, -0.9362272024154663, -1.429880976676941, -0.798515796661377, -0.42827630043029785, -1.0554829835891724, 0.3480502963066101, -0.03953726217150688, -0.8028716444969177, -0.1156245768070221, -0.1361980140209198, -0.22532936930656433, 0.928328812122345, -1.2979013919830322, 0.7791346907615662, -0.11556946486234665, -0.2468513548374176, 0.24746094644069672, 0.4636210501194, 1.2198169231414795, 0.03592321276664734, 0.18776904046535492, -1.1910386085510254, 0.370041161775589, 0.0845748782157898, 0.2952609956264496, 0.053770631551742554, 0.32344475388526917, 0.728446900844574, -0.35627281665802, -0.6260033249855042, 0.37014615535736084, 0.7724071741104126, -0.13647401332855225, -0.07328500598669052, -0.43940678238868713, 0.7597101926803589, 0.5757809281349182, -0.49764561653137207, 0.3388676345348358, 0.17406919598579407, 0.5141491293907166, 0.04770563170313835, 0.01411490235477686, -0.484595388174057, -0.5737578272819519, 0.5289954543113708, 2.2445340156555176, 0.4689253270626068, -0.013962903991341591, -0.8094009160995483, 0.4908331632614136, -1.0247972011566162, -0.5051991939544678, 0.7423171401023865, 0.6488088965415955, 0.6561644673347473, -0.6007536053657532, -0.4361966550350189, 0.040097519755363464, 1.0126389265060425, 0.2948165833950043, 0.14599624276161194, -1.0316507816314697, 0.22429649531841278, 0.15731224417686462, -0.14949537813663483, 1.1141163110733032, -0.265817791223526, 0.68605637550354, 14.489114761352539, 0.3551185727119446, 0.34185633063316345, 1.0051051378250122, 0.6847189664840698, 0.10756919533014297, -0.32066676020622253, -0.13615229725837708, -1.5512694120407104, 0.0857858806848526, 1.5133100748062134, 0.33140507340431213, 0.5305382013320923, -0.4640955924987793, 0.2289769947528839, 0.3312325179576874, -0.6171382069587708, 0.7139315605163574, 0.5935733914375305, -1.0671223402023315, 0.3529181182384491, 0.3967975676059723, 0.3390405476093292, 0.31388387084007263, 0.6508621573448181, 0.8880545496940613, -0.10328169912099838, -0.3470427989959717, 1.0216848850250244, 0.047078222036361694, 0.4903477728366852, -0.06633887439966202, -0.16364243626594543, 0.3265782594680786, -1.2129242420196533, -0.2457979917526245, -0.22359181940555573, -0.7063112258911133, 0.607209324836731, 0.08594845980405807, -0.30007368326187134, -0.762424111366272, -0.043090470135211945, 0.2863239049911499, 0.23089514672756195, 0.1967218816280365, -0.04336242750287056, 1.1211620569229126, 0.16990862786769867, 0.2197413593530655, -0.1429567188024521, 0.6947423219680786, 0.7016581892967224, 0.22884225845336914, 0.08031415939331055, 0.10954936593770981, 0.10421149432659149, 0.5867312550544739, -0.6050738096237183, 0.06079597398638725, -0.36415180563926697, -0.15162813663482666, 0.05262979865074158, 0.38534262776374817, 0.5972745418548584, 0.395123153924942, -0.3875391483306885, 0.12181394547224045, 0.46311813592910767, 0.4548547565937042, -0.08406857401132584, 0.27919358015060425, 0.7202757000923157, -0.1181778535246849, 0.18266472220420837, 0.4160650074481964, -0.1251104772090912, 0.047958631068468094, -0.49697354435920715, -0.35533496737480164, -0.11515959352254868, -0.8823822736740112, -0.6715551614761353, 1.131381869316101, -0.22882527112960815, -0.31478747725486755, 0.23215968906879425, -0.8442118167877197, -0.0691753402352333, 0.399320513010025, -1.0725842714309692, -0.06822953373193741, 0.9328581094741821, -0.3878982961177826, -0.19515720009803772, -0.1823030710220337, 0.8908362984657288, 0.36026087403297424, -0.5595426559448242, 0.11247572302818298, -0.6196118593215942, 0.09100429713726044, -0.2827804982662201, -0.40755772590637207, 0.8741127848625183, 0.5289883613586426, 0.08914441615343094, 0.18439841270446777, 0.08534340560436249, 0.01934102736413479, -0.17964014410972595, -0.15509380400180817, 0.5609719157218933, -0.7329763174057007, -0.1814943552017212, -0.7020717263221741, -1.0256539583206177, 0.24231305718421936, 0.953925609588623, -0.20724265277385712, 0.646597683429718, 0.09987140446901321, -0.4221195876598358, -0.6203035116195679, -0.5263225436210632, 0.2812942862510681, 0.5550501942634583, -0.9570733904838562, -0.48048725724220276, -0.7733176946640015, 0.7901289463043213, -0.8438630104064941, -0.3231346905231476, 0.07874097675085068, -0.3264496326446533, -0.04548171907663345, 0.42286714911460876, -0.1915770322084427, 0.2703903913497925, 0.5139816999435425, -0.5732558965682983, -0.9939470291137695, 0.040893904864788055, -1.2381360530853271, 0.11702526360750198, 0.5280945897102356, 1.142385721206665, -0.21679577231407166, -0.12176595628261566, 0.5922324061393738, -0.4831100106239319, -0.45148205757141113, -0.997352659702301, -0.21476750075817108, -0.2872832417488098, -0.879252016544342, 0.3532826006412506, -0.3913003206253052, 0.09721539914608002, 0.1083611249923706, 0.5430898070335388, 0.9921554327011108, -0.3119527995586395, -1.3348954916000366, -0.06546011567115784, 0.19714003801345825, -0.17421840131282806, -0.5731118321418762, -0.5771188139915466, -1.3695440292358398, 0.046987857669591904, -1.2179828882217407, 0.5658729076385498, -0.6238116025924683, -0.6674497127532959, 0.4562512934207916, -0.4374038577079773, -0.07048112154006958, 0.22506852447986603, -0.27173513174057007, -0.11883798241615295, -0.6609064936637878, -0.2995407283306122, 0.7419956922531128, 0.39530080556869507, -0.5982195734977722, -0.07067674398422241, 0.12129092216491699, -0.23970825970172882, 0.3086625039577484, 0.45014244318008423, -0.696855902671814, -0.7666786313056946, -1.4343591928482056, 0.008886925876140594, -0.1678639054298401, -0.1747189462184906, -1.0381217002868652, 0.6093546748161316, 0.6020054221153259, -0.40154144167900085, -0.0422198511660099, 0.553130567073822, -0.9937542676925659, -0.4080038368701935, 0.13161520659923553, -0.8922783732414246, 0.4297145903110504, 0.3222709894180298, -0.40473470091819763, -0.5718063712120056, 0.5427616238594055, 0.10514756292104721, -0.8287597298622131, -0.43315041065216064, 0.34099990129470825, -1.1879709959030151, 0.10262161493301392, -0.10765519738197327, -0.30425459146499634, -0.9267032146453857, -0.18641716241836548, -0.0508304201066494, -0.03568801283836365, -0.7720121741294861, 1.1585264205932617, 0.36245197057724, -0.7210057377815247, 0.14249348640441895, 0.8949514031410217, -0.12825192511081696, -0.6206843256950378, 0.34625035524368286, 0.4201512932777405, -0.04901129752397537, 0.33979329466819763, 0.8697375655174255, 0.044080447405576706, -0.876080334186554, -0.16235901415348053, 1.1092779636383057, 0.25158461928367615, -0.17963872849941254, 1.2067914009094238, 0.043181128799915314, -0.8494443893432617, 0.12020831555128098, -1.2028237581253052, -0.11021789908409119, -0.5465611815452576, 0.6353814601898193, 0.05520377308130264, 0.05632539093494415, -0.3456650674343109, -0.386599600315094, 0.41899922490119934, -0.06836853921413422, -0.9449260830879211, 0.007631166372448206, -0.6779410243034363, -0.15986639261245728, 0.654390811920166, 0.719970166683197, -0.17934906482696533, -1.0895787477493286, -0.457160085439682, -0.11741042137145996, 0.2359924167394638, 0.18820956349372864, -0.21278423070907593, -0.7848140001296997, 0.8183339238166809, 0.3852374255657196, 0.25812309980392456, -0.038302529603242874, 0.11939245462417603, -0.15955273807048798, 0.26322290301322937, -0.020623544231057167, -0.9733068943023682, -0.5828198194503784, 1.0751152038574219, 1.400109887123108, -0.7429175972938538, -0.22160090506076813, -0.6139609217643738, -0.8620869517326355, 0.6146585941314697, 0.5451757907867432, 0.25675779581069946, 1.6242454051971436, 0.5327420234680176, 0.604062557220459, 0.5380411148071289, -1.1321834325790405, -0.36030682921409607, 0.762139618396759, 0.899337649345398, 1.0276468992233276, 0.39221954345703125, 0.12719669938087463, 0.9261742830276489, 0.014820446260273457, -0.6290006637573242, 0.5496870875358582, 0.1830049604177475, -0.3937995135784149, -0.33518606424331665, 0.06987208127975464, 0.4443812966346741, -1.0504041910171509, -0.6338182091712952, 0.08726221323013306, 0.46789461374282837, 0.17006845772266388, 1.3757376670837402, 0.9572245478630066, -0.1970585435628891, 0.6662960648536682, 0.5691592693328857, 0.20930305123329163, -1.1907597780227661, -0.47869983315467834, 0.1773051768541336, -0.5953681468963623, -0.4227270781993866, -0.0017639732686802745, -0.3116566240787506, -0.6960749626159668, 0.2829382121562958, 0.25192564725875854, 0.035460494458675385, 0.9498304724693298, 1.2890576124191284, 0.5476537346839905, 0.7333705425262451, 0.09409722685813904, -0.3893219232559204, -0.5690180659294128, -1.3325698375701904, -0.1914806216955185, -0.9344730377197266, 0.35142216086387634, 0.34209293127059937, 0.0073052626103162766, 0.13400520384311676]}, "authors": [{"authorId": "2279923673", "name": "Yosuke Higuchi"}, {"authorId": "2279924507", "name": "Andrew Rosenberg"}, {"authorId": "2280057098", "name": "Yuan Wang"}, {"authorId": "8785834", "name": "M. Baskar"}, {"authorId": "1720857", "name": "B. Ramabhadran"}], "references": [{"paperId": "15684a897a8fd83d81e6f76a120e9bdb433529da", "title": "Interdecoder: using Attention Decoders as Intermediate Regularization for CTC-Based Speech Recognition"}, {"paperId": "232348648aec220c269038d226ee4be5a900c171", "title": "BECTRA: Transducer-Based End-To-End ASR with Bert-Enhanced Encoder"}, {"paperId": "3bb913986a9f9b7e76f5646535c3f07f30b9cfb2", "title": "BERT Meets CTC: New Formulation of End-to-End Speech Recognition with Pre-trained Masked Language Model"}, {"paperId": "b635fbfd7f1a44f49e8da04d25aecfca7bc2a0cd", "title": "Acoustic-aware Non-autoregressive Spell Correction with Mask Sample Decoding"}, {"paperId": "fd82a861a0bdb8693a5e3596516f1c0848a3d80a", "title": "E-Branchformer: Branchformer with Enhanced Merging for Speech Recognition"}, {"paperId": "2503de6ff271d44d8f05be9fcd460855d456bb17", "title": "Non-autoregressive Error Correction for CTC-based ASR with Phone-conditioned Masked LM"}, {"paperId": "165a3d40a6f74520ef5af544ef01d6d27f288f4c", "title": "Intermediate-layer output Regularization for Attention-based Speech Recognition with Shared Decoder"}, {"paperId": "0cd31a2c81f9c14d6f9c0dc810bf98388d8be459", "title": "Branchformer: Parallel MLP-Attention Architectures to Capture Local and Global Context for Speech Recognition and Understanding"}, {"paperId": "1a65b38aaa72da05023d7d88fe1b88608b37b5fc", "title": "MAESTRO: Matched Speech Text Representations through Modality Matching"}, {"paperId": "1144cc3e86b1cc4160aedddb085d7861d4b528dc", "title": "Memory-Efficient Training of RNN-Transducer with Sampled Softmax"}, {"paperId": "53f2c96864b05ed440426c47220bcac755011b17", "title": "Ask2Mask: Guided Data Selection for Masked Speech Modeling"}, {"paperId": "5ea9c59f33acc03b7c6799b66eb62ccf18e1c645", "title": "Deliberation of Streaming RNN-Transducer by Non-Autoregressive Decoding"}, {"paperId": "416dab850fda842b13a4f28164514d98f836fff7", "title": "WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing"}, {"paperId": "7ac4227d0b4d38b16da27ed55bd53ce240a32404", "title": "A Comparative Study on Non-Autoregressive Modelings for Speech-to-Text Generation"}, {"paperId": "d7ffb34c2509f5a1c0656c8738f60b458d82edcf", "title": "Hierarchical Conditional End-to-End ASR with CTC and Multi-Granular Subword Units"}, {"paperId": "6fe21b01d2202defb8fcd75c40f306a88bd385dc", "title": "BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning for Automatic Speech Recognition"}, {"paperId": "7f31856eb04f6ea49aff276621de66ca85a1a554", "title": "Tied & Reduced RNN-T Decoder"}, {"paperId": "ebe259796870ebccf26577044d0087884209b884", "title": "w2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training"}, {"paperId": "4fffa5245d3972077c83614c2a08a47cb578631e", "title": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units"}, {"paperId": "2fc885d669263a151e8906f124d3388029b114a1", "title": "On the limit of English conversational speech recognition"}, {"paperId": "ccdafb4eaa0ce58438ea316b56f2a21b6602d0cd", "title": "Relaxing the Conditional Independence Assumption of CTC-based ASR by Conditioning on Intermediate Predictions"}, {"paperId": "2a8fa407e074bebeaf1e254be37fae7fc54610e3", "title": "SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network"}, {"paperId": "12a683f6e9ec558dbac9a24b5c06a12d8db16d87", "title": "Citrinet: Closing the Gap between Non-Autoregressive and Autoregressive End-to-End Models for Automatic Speech Recognition"}, {"paperId": "7099d5a4b2d4ed47905071fc23aff08580401e42", "title": "Echo State Speech Recognition"}, {"paperId": "fc912e9af47bf10428396b687b2bfb1e5832fcb1", "title": "Intermediate Loss Regularization for CTC-Based Speech Recognition"}, {"paperId": "8809d0732f6147d4ad9218c8f9b20227c837a746", "title": "Recent Developments on Espnet Toolkit Boosted By Conformer"}, {"paperId": "62ce4d65335c32844247e0ecf3be6de1ccb924b2", "title": "Rethinking Evaluation in ASR: Are Our Models Robust Enough?"}, {"paperId": "9ff525d1ebd389c359ddbf06df3e99c433c2bf9e", "title": "Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition"}, {"paperId": "5944499d410e01040dea78dc6913a3b097988c49", "title": "Transformer Transducer: One Model Unifying Streaming and Non-streaming Speech Recognition"}, {"paperId": "49a049dc85e2380dde80501a984878341dd8efdf", "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations"}, {"paperId": "1a671afdac8e7b759cf3b5ec7d03d485c76a989c", "title": "Mask CTC: Non-Autoregressive End-to-End ASR with CTC and Mask Predict"}, {"paperId": "0170fc76e934ee643f869df18fb617d5357e8b4e", "title": "Conformer: Convolution-augmented Transformer for Speech Recognition"}, {"paperId": "1bd7d2932de819ed1087b6453ef2c0be9f781ac1", "title": "ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context"}, {"paperId": "c006d720f754069af161e699fa957396b8ea88ba", "title": "Rnn-Transducer with Stateless Prediction Network"}, {"paperId": "bb2bc99f8220fc681320c541940c99ae30b286d6", "title": "Imputer: Sequence Modelling via Imputation and Dynamic Programming"}, {"paperId": "09e2c7adbed37440d4a339852cfa34e5b660f768", "title": "Transformer Transducer: A Streamable Speech Recognition Model with Transformer Encoders and RNN-T Loss"}, {"paperId": "4097148c147f06b54802000a8476d28e525c63cf", "title": "Specaugment on Large Scale Datasets"}, {"paperId": "4099c4d272c12081b562392606e6d567e4ae7031", "title": "Masked Language Model Scoring"}, {"paperId": "97412aded29b05ee69a63ea9ec2b22f41c321149", "title": "Generative Pre-Training for Speech with Autoregressive Predictive Coding"}, {"paperId": "1bf76b8b60d128cda9bd92dad2263793f46c3754", "title": "DEJA-VU: Double Feature Presentation and Iterated Loss in Deep Transformer Networks"}, {"paperId": "a0070675b4a7f55777cc1fceb5463c368e236337", "title": "Quartznet: Deep Automatic Speech Recognition with 1D Time-Channel Separable Convolutions"}, {"paperId": "06183bd57548b74e38acf4733837766c9fdcdef2", "title": "Two-Pass End-to-End Speech Recognition"}, {"paperId": "5efadc9019ce3378a0eb6c8f939cdde6c8918b1e", "title": "Mask-Predict: Parallel Decoding of Conditional Masked Language Models"}, {"paperId": "ff413cae44ca5e14281ebe4659b8627c349e8493", "title": "Lingvo: a Modular and Scalable Framework for Sequence-to-Sequence Modeling"}, {"paperId": "fe9fae85d21aba4c12d8aec83fbb074f1cdf7f80", "title": "Hierarchical Multitask Learning With CTC"}, {"paperId": "478d6102a2df86b0f4e69e398f96619312ecdc8c", "title": "An Analysis of Incorporating an External Language Model into a Sequence-to-Sequence Model"}, {"paperId": "0106ac3ed6867af22d732cf7640b766cc98d256b", "title": "Deliberation Networks: Sequence Generation Beyond One-Pass Decoding"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d", "title": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems"}, {"paperId": "3056add22b20e3361c38c0472d294a79d4031cb4", "title": "Listen, attend and spell: A neural network for large vocabulary conversational speech recognition"}, {"paperId": "b624504240fa52ab76167acfe3156150ca01cf3b", "title": "Attention-Based Models for Speech Recognition"}, {"paperId": "34038d9424ce602d7ac917a4e582d977725d4393", "title": "Librispeech: An ASR corpus based on public domain audio books"}, {"paperId": "8cb72cf5490c2a532d52237f688f915a92afe04c", "title": "From Feedforward to Recurrent LSTM Neural Networks for Language Modeling"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f", "title": "Towards End-To-End Speech Recognition with Recurrent Neural Networks"}, {"paperId": "7b4f3d0e4e2486a8d5d3f8e00549cf9a117bf88f", "title": "Sequence Transduction with Recurrent Neural Networks"}, {"paperId": "261a056f8b21918e8616a429b2df6e1d5d33be41", "title": "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks"}, {"paperId": "030a977bf32e81fb694117d78ac84a3fbe2a1d81", "title": "An analysis of noise in recurrent neural networks: convergence and generalization"}, {"paperId": "abbec7b096673b4a1f89ec20a2bf7b5bfa2c40b5", "title": "Non-Autoregressive Transformer for Speech Recognition"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": null, "title": "license agreement with IEEE. Restrictions apply"}]}