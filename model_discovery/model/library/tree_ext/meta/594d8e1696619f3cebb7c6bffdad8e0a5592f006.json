{"paperId": "594d8e1696619f3cebb7c6bffdad8e0a5592f006", "title": "Scaling Transformer to 1M tokens and beyond with RMT", "abstract": "A major limitation for the broader scope of problems solvable by transformers is the quadratic scaling of computational complexity with input size. In this study, we investigate the recurrent memory augmentation of pre-trained transformer models to extend input context length while linearly scaling compute. Our approach demonstrates the capability to store information in memory for sequences of up to an unprecedented two million tokens while maintaining high retrieval accuracy. Experiments with language modeling tasks show perplexity improvement as the number of processed input segments increases. These results underscore the effectiveness of our method, which has significant potential to enhance long-term dependency handling in natural language understanding and generation tasks, as well as enable large-scale context processing for memory-intensive applications.", "venue": "arXiv.org", "year": 2023, "citationCount": 59, "influentialCitationCount": 1, "openAccessPdf": {"url": "http://arxiv.org/pdf/2304.11062", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This study investigates the recurrent memory augmentation of pre-trained transformer models to extend input context length while linearly scaling compute and demonstrates the capability to store information in memory for sequences of up to an unprecedented two million tokens while maintaining high retrieval accuracy."}, "embedding": {"model": "specter_v2", "vector": [0.19269298017024994, 0.3323953449726105, -0.013319174759089947, -0.07109562307596207, -0.5452570915222168, -0.485512912273407, 0.7552656531333923, -0.053107887506484985, -0.4043596684932709, -0.2649344801902771, 0.7404240965843201, -0.25459784269332886, 0.5233901143074036, 0.1992509514093399, 0.1613890528678894, -0.005071981344372034, -0.8438223600387573, 0.5560380816459656, -0.256375789642334, -0.30091825127601624, 0.09812024980783463, -0.3985031545162201, -1.005300521850586, 0.08121173828840256, 0.27153122425079346, 0.3335762619972229, 0.42950311303138733, 0.5138425230979919, -0.629254937171936, 0.405355304479599, 0.3486407995223999, -0.1936158984899521, 0.1595127284526825, -0.08461686968803406, -0.4005146026611328, -0.19546684622764587, 0.346549391746521, -0.31328415870666504, -0.33653977513313293, 0.33546435832977295, -0.17461782693862915, 0.467190682888031, 0.08927071839570999, -0.5189999341964722, -0.09002223610877991, 1.252997875213623, 0.6633663177490234, 0.9187678694725037, -0.24971744418144226, -0.9883474111557007, 1.3469058275222778, -1.7713192701339722, 0.2890024483203888, 1.362508773803711, 0.3985724151134491, 0.35231754183769226, 0.030173929408192635, -0.3391319811344147, 1.0115855932235718, 0.2051641345024109, -0.7472594380378723, -0.5132436156272888, -0.001961035653948784, 0.27833765745162964, 2.1673173904418945, -0.3577234745025635, 0.3586716055870056, 0.1459008753299713, -0.12462688237428665, 1.4384843111038208, -0.14609436690807343, -1.0436617136001587, -0.3768583834171295, -0.2951880395412445, 0.44086435437202454, 0.8253703117370605, -0.4220825135707855, 0.08566641807556152, -0.8927815556526184, 0.03618863597512245, 0.5619783401489258, -0.06974087655544281, 0.41455531120300293, 0.28530460596084595, -0.2891561686992645, 0.4674040377140045, 0.04425669088959694, 1.0574548244476318, -0.09361086040735245, 0.6895244121551514, 0.5844959616661072, 0.3932598829269409, 0.234842449426651, 0.2721066176891327, -0.04939037188887596, 0.2413627803325653, -0.973308801651001, 0.18143367767333984, -0.29499655961990356, 0.8172003626823425, -0.263689786195755, 0.6793912649154663, -0.7864920496940613, 0.38069605827331543, 1.1296374797821045, 0.3521692156791687, 0.5754560828208923, -0.47608694434165955, 0.3730204999446869, -0.6290261745452881, -0.11596447974443436, -0.38948220014572144, -0.2675647437572479, -0.3150516152381897, -0.31744182109832764, -1.6805847883224487, -0.5444416403770447, 0.25737741589546204, -1.0786930322647095, 0.7889221906661987, -0.2051151543855667, 0.39055749773979187, 0.08544418215751648, 0.4203316271305084, 0.24231518805027008, 0.6677719354629517, 0.2174152135848999, -0.14014743268489838, 0.7635705471038818, -0.7018366456031799, -0.6552664041519165, -0.9450727105140686, 0.8725887537002563, -0.3933068513870239, -0.06133900582790375, -0.25292566418647766, -1.6015679836273193, -0.6219868063926697, -0.7035901546478271, 0.015066077001392841, -0.5637216567993164, 0.14301522076129913, 0.9746860265731812, 0.29314279556274414, -1.2161775827407837, 0.6865932941436768, -0.1843222677707672, 0.06882242858409882, 0.15963880717754364, 0.13122817873954773, 0.2946254014968872, -0.6438899636268616, -1.3795793056488037, 0.4964680075645447, 0.17460934817790985, -0.12451089173555374, -0.2050282061100006, -0.7243247628211975, -1.211105227470398, 0.020815277472138405, 0.20175237953662872, -0.448854923248291, 1.37216317653656, 0.12038515508174896, -1.0922363996505737, 0.5661711692810059, -0.6202544569969177, -0.012823731638491154, -0.06366412341594696, -0.3259880542755127, -0.3378247618675232, -0.5770080089569092, -0.10732688754796982, 0.16801989078521729, 0.45860666036605835, 0.14491109549999237, -0.37777042388916016, -0.04596252739429474, -0.6149277091026306, 0.23368500173091888, -0.005468958523124456, 0.8740497827529907, -0.12007827311754227, -0.39363762736320496, 0.6846147775650024, 0.5723090767860413, -0.2566841244697571, -0.9511966705322266, -0.14391562342643738, -0.9436140060424805, 0.5364993810653687, -0.18439194560050964, 1.083807110786438, -0.5092220306396484, -0.6439158320426941, 0.016599558293819427, -0.3522162139415741, -0.009364409372210503, -1.0185967683792114, 0.8173574805259705, -0.630011260509491, 0.4370366036891937, 0.005772639997303486, -1.0601108074188232, 0.042697858065366745, 0.07400628924369812, -0.9668895602226257, -0.41034406423568726, 0.3806731104850769, 1.166643500328064, -0.9894262552261353, -0.0817110687494278, 0.18848031759262085, 0.38941818475723267, -0.6132706999778748, 1.1677192449569702, -0.09383551776409149, -0.02631503716111183, 0.011947376653552055, 0.20280911028385162, 0.14604729413986206, -0.14251136779785156, 0.9007737040519714, -0.14201810956001282, -0.4038357436656952, 1.010111689567566, -0.46248048543930054, 1.3153878450393677, -0.5070169568061829, 0.4907251298427582, -0.12295998632907867, -0.895595371723175, 0.055783215910196304, 0.6243224143981934, -0.13699547946453094, -0.7736053466796875, 0.15175409615039825, 0.47178661823272705, -0.7186951637268066, 0.36157113313674927, 1.0655077695846558, 0.5816882252693176, -0.5298992395401001, 0.3027961850166321, 0.5997459888458252, -0.014050162397325039, 0.6456969380378723, 0.34993743896484375, 0.6973211765289307, 0.22233515977859497, 0.022029228508472443, -0.004469975829124451, 0.22198227047920227, -0.6020158529281616, 0.1674228459596634, 0.42288726568222046, 0.8054117560386658, 0.748397171497345, 0.2506779432296753, -0.6438629031181335, -0.568901538848877, 0.05648791044950485, 0.6451638340950012, 1.7318774461746216, -0.21745029091835022, -0.2430715709924698, -0.5789984464645386, -0.05676455795764923, -0.5901874303817749, -0.06611935794353485, -0.23892183601856232, 0.09142546355724335, -1.1115789413452148, -0.9756903648376465, 0.9964233040809631, 0.6418703198432922, 0.7756591439247131, -0.47698938846588135, -0.10923709720373154, -0.006604876834899187, -0.06589201092720032, -0.8215327262878418, -0.5532317757606506, 0.3985496461391449, -0.810499370098114, -0.08271460235118866, 0.15501286089420319, -0.3719710409641266, 0.17815637588500977, -0.2740454375743866, 1.1701825857162476, -0.10611256211996078, -0.47914499044418335, 0.10925529897212982, 0.4755917191505432, -0.4491051435470581, -0.5349007248878479, 0.20393386483192444, 0.2353127896785736, -0.7028856873512268, 0.18105266988277435, 0.39064231514930725, 0.11765648424625397, -0.07198546826839447, -0.421028196811676, 0.23923519253730774, -0.013629038818180561, 0.21360641717910767, 0.724865734577179, -0.46842333674430847, 0.17346514761447906, -1.0887619256973267, 0.7251323461532593, 0.34113675355911255, -0.45785394310951233, 0.46701598167419434, -0.8130966424942017, -0.22155547142028809, 0.3530833423137665, -0.4288930594921112, -0.39799046516418457, -0.7960891723632812, 0.32995036244392395, -0.28817740082740784, 0.1355491727590561, 0.27120205760002136, 0.30557891726493835, 0.6105843186378479, -0.37233173847198486, 0.6388158202171326, 0.07101163268089294, -0.19484300911426544, 0.8396283984184265, -1.0383423566818237, 0.29980331659317017, 0.31451699137687683, 0.19770221412181854, -0.2504154443740845, 0.11165519058704376, -0.6471131443977356, -0.2740124762058258, -0.38328707218170166, -0.6023666858673096, -0.23769940435886383, -0.31732800602912903, -0.49111834168434143, -0.6816434264183044, 0.049868352711200714, -1.0748027563095093, -0.026356779038906097, 0.17523320019245148, -0.4048748016357422, 0.032498620450496674, -1.0082134008407593, -1.5639780759811401, -0.8814747333526611, -0.7235098481178284, -0.4589695632457733, 0.3755868971347809, -0.012527357786893845, 0.0291066225618124, -0.6635763645172119, 0.22441719472408295, -0.30196306109428406, 0.9256455898284912, -0.6133482456207275, 0.9896942377090454, 0.029684454202651978, -0.4689149558544159, -0.056742556393146515, 0.3703233301639557, 0.2440277338027954, -0.30436432361602783, 0.3915557563304901, -0.8844170570373535, 0.25693732500076294, -0.5421852469444275, 0.004680844955146313, 0.22303929924964905, 0.3474135398864746, 0.13683369755744934, 0.047723375260829926, -0.5536400675773621, -0.1514274924993515, 1.3875888586044312, -0.5778594017028809, 0.15426291525363922, -0.09338764101266861, 0.9648540019989014, 0.24613669514656067, 0.09164122492074966, 0.5216056108474731, 0.3495452404022217, 0.014765461906790733, 0.15788480639457703, -0.22002777457237244, -0.02917233109474182, -0.5784761309623718, 0.29134759306907654, 1.8845468759536743, 0.07633959501981735, -0.14426521956920624, -1.0395888090133667, 0.8862683176994324, -1.3725719451904297, -0.8089919090270996, 0.7387585043907166, 0.6119908094406128, 0.19956794381141663, -0.7700669169425964, -0.3760388493537903, 0.15359677374362946, 0.6125265955924988, 0.278231680393219, -0.2236430048942566, -0.5354465246200562, -0.10372272878885269, 0.5700996518135071, 0.07991702109575272, 0.6269103288650513, 0.05023260414600372, 1.0493360757827759, 15.006135940551758, 0.742132842540741, -0.09096919000148773, 0.3726974427700043, 0.5828946828842163, -0.07289237529039383, -0.5464305281639099, 0.11387252807617188, -1.1715960502624512, -0.4282275438308716, 1.208588719367981, -0.11174202710390091, 0.807062029838562, 0.0381157360970974, 0.35999244451522827, 0.22317035496234894, -0.5385034084320068, 0.520779013633728, 0.5466386079788208, -1.2634475231170654, 0.5282187461853027, 0.22610309720039368, 0.06530861556529999, 0.5044982433319092, 0.693594753742218, 0.9693353176116943, 0.39259931445121765, -0.6216170191764832, 0.4546321928501129, -0.04643682390451431, 0.6208481192588806, -0.35285279154777527, 0.3488670885562897, 0.2529580295085907, -1.3878976106643677, -0.20303986966609955, -0.5289220809936523, -1.064561367034912, 0.36999085545539856, 0.3315812647342682, -1.2403509616851807, -0.16884420812129974, -0.33109527826309204, 0.6919943690299988, 0.12285611778497696, 0.007344530895352364, -0.2598443031311035, 0.6516955494880676, -0.06023331731557846, 0.12122509628534317, 0.10126583278179169, 0.33548253774642944, 0.2342347353696823, 0.34706851840019226, 0.24811528623104095, 0.2327878624200821, -0.02482215128839016, 0.019615672528743744, -0.5958244204521179, 0.06064460426568985, -0.4730295240879059, -0.36169788241386414, 0.29356393218040466, 0.9675152897834778, 0.23697055876255035, 0.03590512275695801, -0.019660137593746185, 0.22274541854858398, 0.6787347793579102, 0.01575474813580513, -0.32882460951805115, 0.09301186352968216, 0.5386953949928284, -0.3954576849937439, 0.11767806857824326, 0.21898119151592255, -0.20418435335159302, -0.6155872344970703, -0.5917040705680847, -0.13419754803180695, 0.40165457129478455, -0.5784382224082947, -0.5843604803085327, 1.0126219987869263, -0.2028520703315735, -0.5693747997283936, -0.3727792799472809, -0.8735822439193726, -0.11780781298875809, 0.46027934551239014, -1.7056045532226562, -0.9335247278213501, 0.48753681778907776, -0.22833462059497833, -0.3263680338859558, 0.4851076602935791, 1.3404951095581055, 0.11379843205213547, -0.4326249957084656, -0.02742105722427368, 0.053408823907375336, 0.12942913174629211, -0.3621257543563843, -0.6313115954399109, 0.7736539840698242, 0.5413755774497986, 0.0883173793554306, 0.6252457499504089, -0.17787830531597137, 0.351614385843277, -0.8438377380371094, -0.009936345741152763, 1.0970232486724854, -0.7572442889213562, -0.651191771030426, -0.8120532035827637, -0.8245924711227417, 0.36280563473701477, 0.6141483187675476, -0.38374242186546326, 0.4114535450935364, 0.25715577602386475, -0.5825684666633606, -0.1796485185623169, -0.8013921976089478, 0.21405194699764252, 0.7985403537750244, -0.9120896458625793, -0.4099608361721039, -0.4311874806880951, 0.32374855875968933, -0.9698999524116516, -0.6123735308647156, -0.2558004856109619, 0.29674410820007324, 0.11975989490747452, 0.7587215900421143, -0.5045797228813171, 0.4854584336280823, 0.8490265607833862, -0.1239718347787857, -0.7631434798240662, -0.09706804156303406, -0.6935612559318542, 0.09058607369661331, 0.5074806213378906, 0.7333948016166687, -0.35971271991729736, -0.018886767327785492, 1.1021264791488647, 0.1996488869190216, -0.49846598505973816, -0.8659491539001465, -0.1858171969652176, 0.0930672287940979, -0.6182244420051575, 0.5289121866226196, 0.15496960282325745, 0.24636180698871613, 0.25294896960258484, 0.5985026955604553, 0.6394476890563965, -0.4407290518283844, -0.38267621397972107, -0.16854676604270935, -0.0012086039641872048, 0.3324299454689026, -0.5040363073348999, -0.3489955961704254, -1.1506999731063843, 0.1277359426021576, -1.0905876159667969, 0.15167784690856934, -1.065614938735962, -0.5500455498695374, -0.19517900049686432, -0.5891181230545044, 0.30216753482818604, 0.33851388096809387, -0.4157902002334595, -0.3944301903247833, -0.7176103591918945, -0.44390150904655457, 0.6240875720977783, 0.5384384393692017, -0.47746631503105164, 0.14696018397808075, -0.34277623891830444, 0.11949879676103592, 0.014401305466890335, 0.4484706223011017, -0.2880544662475586, -0.816889762878418, -1.63289213180542, 0.4273502826690674, 0.11409138143062592, -0.3785790801048279, -0.2729814052581787, 0.5253475904464722, 0.27106744050979614, -0.061594221740961075, -0.23327070474624634, 0.5090840458869934, -0.587633490562439, -0.5164517760276794, 0.047250229865312576, -0.7922107577323914, 0.6734113693237305, 0.3366173803806305, -0.7767838835716248, -0.1684761643409729, 0.7340525984764099, -0.5034756660461426, -1.322107195854187, -0.5082880258560181, 0.2979578971862793, -1.0281345844268799, 0.18392314016819, -0.7048203349113464, -0.1141427755355835, -1.1105501651763916, -0.2511886954307556, 0.21437300741672516, 0.5490698218345642, -0.3987410068511963, 1.0471718311309814, 0.7178007364273071, -1.0917919874191284, 0.0350818894803524, 0.08704940974712372, -0.3951931595802307, -0.09475307911634445, 0.37260597944259644, 0.15914830565452576, 0.15877127647399902, 0.6676098108291626, 0.29402589797973633, 0.29008474946022034, -1.3016993999481201, 0.012268131598830223, 0.5394554138183594, -0.8375585079193115, -0.01692255213856697, 0.7746970057487488, -0.6651818752288818, -0.8020415306091309, -0.1045716404914856, -1.4843577146530151, -0.6247431635856628, -0.1425122320652008, 0.7257375717163086, 0.33158794045448303, 0.11818928271532059, -0.08210229128599167, -0.5954753160476685, 0.15832099318504333, -0.23549701273441315, -0.9738892912864685, 0.6857618689537048, -0.23466555774211884, -0.5237784385681152, 0.6321302056312561, 0.3246098458766937, -0.7460445165634155, -0.32272130250930786, -0.6555441617965698, -0.17028440535068512, -0.17562846839427948, 0.2039499282836914, -0.17991259694099426, -0.5553666353225708, 0.795199453830719, 0.4086515009403229, 0.44940662384033203, 0.009276201017200947, -0.35488104820251465, 0.3864806592464447, 0.6433200836181641, 0.37678229808807373, -0.6597015857696533, -0.642929196357727, 1.6372147798538208, 1.022290825843811, -0.5921860337257385, -0.08756684511899948, -0.09717055410146713, -0.6534189581871033, 0.6900220513343811, 0.12678244709968567, -0.022948501631617546, 0.7623421549797058, -0.007292283698916435, 0.43950796127319336, 0.26020318269729614, -1.34674072265625, -0.4705452024936676, 0.44681358337402344, 1.0756555795669556, 1.0094221830368042, 0.17095625400543213, -0.05962749198079109, 0.8838762044906616, 0.2391030639410019, 0.025275669991970062, 0.38591426610946655, 0.8804639577865601, -0.14032158255577087, -0.3525997996330261, 0.057419322431087494, 0.4187140166759491, -0.5704553723335266, -1.0797358751296997, 0.030227234587073326, 0.5683243870735168, -0.028918497264385223, 0.7935923933982849, 0.9730834364891052, 0.1489517092704773, 0.5363030433654785, 0.4400637745857239, 0.7924278974533081, -0.39161190390586853, -0.5579039454460144, 0.003446639981120825, -0.40745487809181213, -0.010789724066853523, -0.37030133605003357, -0.522619366645813, -0.7713085412979126, -0.21363404393196106, 0.03588101267814636, 0.29439735412597656, 0.39071786403656006, 1.167323112487793, 0.5822356939315796, 0.3628833293914795, -0.05528547987341881, -0.38523414731025696, -0.14756077527999878, -1.1521825790405273, 0.08714587241411209, -0.42622339725494385, -0.25784000754356384, 0.00604901323094964, 0.23459413647651672, -0.1965026557445526]}, "authors": [{"authorId": "2176183932", "name": "Aydar Bulatov"}, {"authorId": "51114080", "name": "Yuri Kuratov"}, {"authorId": "3359236", "name": "M. Burtsev"}], "references": [{"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "c12db2c60e8989f646a29ad4f4d24475e860ad91", "title": "LongNet: Scaling Transformers to 1, 000, 000, 000 Tokens"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8", "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"}, {"paperId": "27d391d65ab42c30dc35595213ba6585633afa5d", "title": "CoLT5: Faster Long-Range Transformers with Conditional Computation"}, {"paperId": "a8cf0f7a20f886acfb332071c2daaf58ba86a5ca", "title": "Recurrent Memory Transformer"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "0e802c0739771acf70e60d59c2df51cd7e8c50c0", "title": "Memorizing Transformers"}, {"paperId": "3c209e0703ffff26231b1145268c935df494631a", "title": "QuALITY: Question Answering with Long Input Texts, Yes!"}, {"paperId": "3dfb1f50f2a34a699c339dabaa6f9b3a977973de", "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "43a87867fe6bf4eb920f97fc753be4b727308923", "title": "Towards a Unified View of Parameter-Efficient Transfer Learning"}, {"paperId": "7e5008713c404445dd8786753526f1a45b93de12", "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow"}, {"paperId": "afad10da0a3b83a4f2a94e8c16c84ac64338e9fe", "title": "ERNIE-Doc: A Retrospective Long-Document Modeling Transformer"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "67ee20536c30a225b86902af2f091e28e5e19b40", "title": "Memformer: A Memory-Augmented Transformer for Sequence Modeling"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "168fc3525f7b97695a97b04e257ee9bd1e832acb", "title": "Memory Transformer"}, {"paperId": "63857190aaf5aab1d94b54bb257b7b03b8cb5a50", "title": "GMAT: Global Memory Augmentation for Transformers"}, {"paperId": "70557ea6b65846fc30729ceed224acd4ac64ca5d", "title": "MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning"}, {"paperId": "baed71eed57ad462f3ab138d4b1700a738cd5414", "title": "ETC: Encoding Long and Structured Data in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "9df88155d6b65e14e06f8dcd851d31b7753659b1", "title": "The lean mathematical library"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "2a31319e73d4486716168b65cdf7559baeda18ce", "title": "Star-Transformer"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "bbb3a49edf69a1909c0cf453858b451ef23fcbaf", "title": "Context-Aware Neural Model for Temporal Information Extraction"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "4b8b3b792415df36f0fcb5b5810bbea471adfd47", "title": "Memory Augmented Neural Networks with Wormhole Connections"}, {"paperId": "be8c6c69f3e357bfad2987e45b62cff7e7474378", "title": "Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes"}, {"paperId": "784ee73d5363c711118f784428d1ab89f019daa5", "title": "Hybrid computing using a neural network with dynamic external memory"}, {"paperId": "906ac7584faf8ead6004be4cc5122320c87df59c", "title": "Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes"}, {"paperId": "e837b79de602c69395498c1fbbe39bbb4e6f75ad", "title": "Learning to Transduce with Unbounded Memory"}, {"paperId": "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e", "title": "End-To-End Memory Networks"}, {"paperId": "d38e8631bba0720becdaf7b89f79d9f9dca45d82", "title": "Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets"}, {"paperId": "abb33d75dc297993fcc3fb75e0f4498f413eb4f6", "title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks"}, {"paperId": "c1126fbffd6b8547a44c58b192b36b08b18299de", "title": "Neural Turing Machines"}, {"paperId": "71ae756c75ac89e2d731c9c79649562b5768ff39", "title": "Memory Networks"}, {"paperId": "1eb09fecd75eb27825dce4f964b97f4f5cc399d7", "title": "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "1a3d22599028a05669e884f3eaf19a342e190a87", "title": "Backpropagation Through Time: What It Does and How to Do It"}, {"paperId": "a496212ca3444e1e14b0668b82e2459d02dc275a", "title": "Representation of Events in Nerve Nets and Finite Automata"}, {"paperId": "bb0656031cb17adf6bac5fd0fe8d53dd9c291508", "title": "An empirical analysis of compute-optimal large language model training"}, {"paperId": null, "title": "Memformer: A memoryaugmented transformer for sequence modeling. In Findings of the Association for Computational Linguistics: AACL-IJCNLP 2022, pages 308\u2013318"}, {"paperId": null, "title": "Addressing some limitations of transformers with feedback memory"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "090c5a5df345ab60c41d6de02b3e366e1a27cf43", "title": "A logical calculus of the ideas immanent in nervous activity"}, {"paperId": null, "title": "2023. Retentive network: A successor to transformer for large language models"}, {"paperId": null, "title": "2022. Block-Recurrent Transformers"}, {"paperId": null, "title": "2022. LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": null, "title": "2023. Hyena Hier-archy: Towards Larger Convolutional Language Models"}]}