{"paperId": "b3c1fad1f5f8f0213b6d3f3458fa86205a3434f7", "title": "A Survey for Biomedical Text Summarization: From Pre-trained to Large Language Models", "abstract": "The exponential growth of biomedical texts such as biomedical literature and electronic health records (EHRs), poses a significant challenge for clinicians and researchers to access clinical information efficiently. To tackle this challenge, biomedical text summarization (BTS) has been proposed as a solution to support clinical information retrieval and management. BTS aims at generating concise summaries that distill key information from single or multiple biomedical documents. In recent years, the rapid advancement of fundamental natural language processing (NLP) techniques, from pre-trained language models (PLMs) to large language models (LLMs), has greatly facilitated the progress of BTS. This growth has led to numerous proposed summarization methods, datasets, and evaluation metrics, raising the need for a comprehensive and up-to-date survey for BTS. In this paper, we present a systematic review of recent advancements in BTS, leveraging cutting-edge NLP techniques from PLMs to LLMs, to help understand the latest progress, challenges, and future directions. We begin by introducing the foundational concepts of BTS, PLMs and LLMs, followed by an in-depth review of available datasets, recent approaches, and evaluation metrics in BTS. We finally discuss existing challenges and promising future directions in the era of LLMs. To facilitate the research community, we line up open resources including available datasets, recent approaches, codes, evaluation metrics, and the leaderboard in a public project: https://github.com/KenZLuo/Biomedical-Text-Summarization-Survey/tree/master. We believe that this survey will be a useful resource to researchers, allowing them to quickly track recent advancements and provide guidelines for future BTS research within the research community.", "venue": "", "year": 2023, "citationCount": 5, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A systematic review of recent advancements in BTS, leveraging cutting-edge NLP techniques from PLMs to LLMs, to help understand the latest progress, challenges, and future directions is presented."}, "embedding": {"model": "specter_v2", "vector": [0.4130497872829437, 0.5034990906715393, -0.624206006526947, -0.34875187277793884, -0.9411205649375916, -0.06799844652414322, 0.33987417817115784, 0.5065860748291016, -0.6566993594169617, 0.10531718283891678, 1.3664823770523071, 0.5134987235069275, -0.14552398025989532, 0.5403611660003662, 0.41649481654167175, 0.012179282493889332, -0.865714967250824, 0.39905786514282227, -0.5150063037872314, 0.03407762944698334, 0.10735975950956345, -0.6925629377365112, 0.04147051274776459, 0.3514583706855774, 0.6694815158843994, -0.21343488991260529, -0.2898564338684082, 1.1809922456741333, -0.4468538463115692, 0.420176237821579, 0.1827402412891388, -0.0869758352637291, -0.3749673068523407, -0.3270966708660126, -0.326652467250824, -0.12220919132232666, 0.38145217299461365, -0.6217699646949768, -0.663899302482605, 0.8001731634140015, 0.23005180060863495, 0.018078207969665527, 0.7360178828239441, -0.3682594895362854, -0.13010497391223907, 1.1554145812988281, 0.43447640538215637, 0.5004013776779175, 0.2507723271846771, -0.522570013999939, 1.2314612865447998, -0.9593293070793152, 0.6478036046028137, 1.5819822549819946, 0.4974203109741211, 0.6779278516769409, -0.17284737527370453, -0.5408967733383179, 0.21397654712200165, -0.268818736076355, -0.8317441940307617, -0.7193018198013306, -0.2559965252876282, -0.3418371379375458, 1.7179967164993286, -0.009300805628299713, -0.28310516476631165, 0.07367300987243652, 0.48607805371284485, 1.5784457921981812, -0.42469388246536255, -0.403082937002182, -0.11952202767133713, -0.17374998331069946, 0.8202430009841919, 0.667553722858429, -0.015054437331855297, -0.40344297885894775, -1.1107797622680664, -0.7671869993209839, -0.4510555565357208, -0.08492127060890198, -0.6571177840232849, 0.30261659622192383, -0.58973628282547, 0.5298314094543457, 0.2262316197156906, 0.8223751187324524, -0.46822190284729004, 0.3111680746078491, 0.6122810244560242, 0.17880752682685852, 0.26001787185668945, 0.6572309136390686, -0.25437167286872864, 0.6594894528388977, -1.448363184928894, 0.26469042897224426, 0.2704433500766754, 0.8336666822433472, -0.5846134424209595, -0.03855627775192261, -1.3575425148010254, 0.32516947388648987, 0.9034571051597595, 0.09222566336393356, 0.5099727511405945, -0.6976333856582642, 0.18651705980300903, -0.2265036255121231, 0.5465152859687805, -0.8129602074623108, -0.861703097820282, -0.06540516763925552, -1.0303361415863037, -1.6297674179077148, -0.6634951829910278, -0.13943266868591309, -0.546478271484375, 0.7953703999519348, -0.4942515790462494, -0.16181787848472595, 0.5092723369598389, 0.25151801109313965, 1.3061668872833252, 0.840929388999939, 0.3200681209564209, -0.8889897465705872, 1.3602337837219238, -0.5820906758308411, -1.2834312915802002, -0.7950809597969055, 1.0244743824005127, -0.1747753620147705, -0.5037890672683716, -0.13708984851837158, -1.2111502885818481, -0.627610981464386, -0.7065675854682922, -0.3312416076660156, -0.08002926409244537, 0.5041669011116028, 0.36351025104522705, 0.0543619841337204, -1.0527541637420654, 0.728746235370636, -0.16078370809555054, -0.7780165076255798, 0.24078185856342316, 0.06607216596603394, 0.054531827569007874, -0.3793591558933258, -0.9236977100372314, 0.2481215000152588, 0.24362902343273163, -0.5814940929412842, -0.17054924368858337, -0.45465371012687683, -1.0159170627593994, 0.1582777053117752, 0.18875353038311005, -1.212819218635559, 1.106260895729065, 0.6431663036346436, -0.9090437293052673, 0.5662115812301636, -0.7909300923347473, -0.2678629159927368, 0.3896174728870392, -0.572636604309082, -0.46064141392707825, 0.3676452338695526, -0.009578227065503597, 0.6167945265769958, -0.26739153265953064, 0.019305691123008728, -0.11744020879268646, 0.14971251785755157, -0.717458963394165, -0.3856714069843292, -0.39887815713882446, 1.2495778799057007, -0.3606376647949219, -0.40296801924705505, 0.5591896176338196, 0.8956931829452515, -0.46188926696777344, -0.26707300543785095, -0.902346134185791, -0.9989693760871887, 0.17966759204864502, -0.2532089650630951, 1.412028431892395, -0.5653978586196899, -0.4707631468772888, -0.6816246509552002, 0.39574071764945984, 0.10281647741794586, -0.7661693096160889, 1.034669041633606, -0.22562596201896667, 0.7814748287200928, -0.5814660787582397, -1.3011183738708496, -0.16171468794345856, -0.4533156156539917, -0.6706052422523499, 0.044209714978933334, 0.39082279801368713, 1.1793036460876465, -0.8248802423477173, -0.09345399588346481, -0.16868498921394348, -0.19704051315784454, -0.8111123442649841, 1.0580452680587769, -0.35562777519226074, 0.42892903089523315, -0.45988115668296814, -0.06518667936325073, 0.294848769903183, -0.3776371479034424, 0.4323386251926422, -0.5838409066200256, -0.5532020926475525, 0.17953473329544067, -0.34260568022727966, 1.460861086845398, 0.5436018705368042, 0.19367405772209167, 0.11701695621013641, -0.7612910270690918, -0.045123472809791565, 0.8415660858154297, 0.4799847900867462, 0.13731084764003754, 0.5991594791412354, 0.11498835682868958, -0.9542214274406433, -0.2405988574028015, 0.3256208002567291, 0.8532440662384033, -0.5542829632759094, 0.11631542444229126, 0.32039377093315125, -0.15927082300186157, 1.0639921426773071, 0.8699103593826294, 1.050385594367981, -0.1937350332736969, 0.979017972946167, -0.12867631018161774, 0.7016883492469788, -0.08345943689346313, 0.5741329789161682, 0.8302761316299438, 0.6918016076087952, 1.0386103391647339, 0.509934663772583, -0.7942841649055481, 0.17545422911643982, 0.3207836449146271, 0.8125852346420288, 0.8749109506607056, -0.3820359408855438, -0.7843920588493347, -0.8468020558357239, -0.38094767928123474, -0.4912741780281067, 0.201370507478714, -0.4407743513584137, -0.3363952338695526, -0.6985584497451782, -1.4675527811050415, 1.0098180770874023, 0.056289710104465485, 0.6156046390533447, -0.23806923627853394, -0.14305216073989868, -0.13161702454090118, -0.37021932005882263, -0.9821175336837769, -0.7301401495933533, 0.14528708159923553, -1.0087717771530151, -0.6871942281723022, -0.40103334188461304, -0.1760447770357132, 0.34936395287513733, -0.8211414813995361, 0.8776878714561462, -0.5278339982032776, -0.3779870867729187, 0.2013506144285202, 0.6992272138595581, -0.6923047304153442, -0.8322692513465881, -0.47157207131385803, 0.1710280179977417, -0.5273564457893372, 0.49539902806282043, 0.8264772295951843, -0.15201431512832642, -0.30663034319877625, -0.5848900675773621, 0.3096361458301544, 0.28690776228904724, 0.25141891837120056, 0.6053901314735413, -0.17535580694675446, 0.5443729758262634, -1.2372373342514038, 1.3270632028579712, 0.18435269594192505, 0.09506792575120926, 0.5551590323448181, -0.3702827990055084, -0.3010472357273102, 0.4901520907878876, -0.3925369679927826, -0.23529274761676788, -0.9368948936462402, 0.326326459646225, 0.4948519766330719, -0.20606985688209534, 0.9149140119552612, 0.4227129817008972, 0.6487595438957214, 0.33519747853279114, 0.6374468803405762, 0.21901674568653107, -0.4398804306983948, 0.24032679200172424, -0.08241090178489685, 0.43712422251701355, 1.0768303871154785, -0.12439732253551483, -0.08645723760128021, -0.30337202548980713, -0.9535684585571289, -0.33439943194389343, -0.6431814432144165, -0.0873272642493248, 0.12974685430526733, 0.13283798098564148, -0.4775104820728302, -0.4189557433128357, -0.1180749461054802, -1.1974692344665527, 0.29406028985977173, 0.24041034281253815, 0.0712718814611435, -0.02330278418958187, -0.44792163372039795, -1.419281005859375, -0.45950955152511597, -1.2375812530517578, -0.7170811295509338, 0.7118963599205017, 0.0017821097280830145, -1.0332344770431519, 0.0035539621021598577, 0.19661512970924377, -0.29772183299064636, 0.47969773411750793, -0.03211892396211624, 1.1159721612930298, -0.4128943681716919, 0.6525228023529053, -0.6762194633483887, 0.38442790508270264, 0.2535856366157532, 0.21246539056301117, 0.2831619083881378, -0.20329301059246063, 0.15236936509609222, 0.3286426067352295, 0.16986437141895294, 0.5065375566482544, 1.1972676515579224, 0.5110795497894287, 0.23705416917800903, -0.8557735681533813, -0.10556844621896744, 0.9865235686302185, -0.6631302833557129, -0.633316695690155, -0.6013340950012207, 0.5932775139808655, 0.5508673191070557, -0.04507795721292496, 0.7853373289108276, -0.09284284710884094, 0.11618966609239578, -0.4219617545604706, -0.44709116220474243, -0.17964628338813782, -0.02815546840429306, 0.43409982323646545, 1.6839545965194702, 0.7771055102348328, -0.6760494112968445, -1.0118627548217773, 0.6467662453651428, -1.4361572265625, -0.3153567314147949, 0.13026836514472961, 0.46544599533081055, 0.5105153918266296, -0.5424186587333679, -0.31798213720321655, -0.1436394453048706, 0.3385908603668213, 0.0432165302336216, -0.2819119393825531, -0.2848048508167267, -0.20570382475852966, 0.06288633495569229, 0.10798501968383789, 0.28243327140808105, -0.5416995882987976, 0.3685317933559418, 14.435007095336914, 0.38298457860946655, 0.04006350785493851, 0.19416126608848572, 0.36136120557785034, 0.054966989904642105, 0.09154964238405228, -0.2954789102077484, -1.0408424139022827, -0.17980293929576874, 1.0884127616882324, -0.5497689843177795, -0.3325531482696533, 0.00011009801528416574, 0.9108002781867981, -0.3764975070953369, -0.8567811846733093, 0.8173695206642151, 0.5534856915473938, -1.2831201553344727, 0.7709338068962097, 0.16721105575561523, 0.4147316813468933, 0.5210193395614624, 0.29734376072883606, 0.5284988880157471, -0.13085520267486572, -0.31268274784088135, -0.09474201500415802, 0.47443267703056335, 0.25974297523498535, -0.013863594271242619, 1.0750900506973267, 0.9368881583213806, -0.5295445322990417, -0.42219188809394836, -0.6680185794830322, -0.704887866973877, 0.5494800806045532, 0.4941141903400421, -0.9493486881256104, 0.3708494007587433, -0.5781107544898987, 1.05412757396698, -0.03326011449098587, 0.7908123731613159, 0.04362344369292259, 0.7617366313934326, 0.14747491478919983, -0.12021390348672867, 0.20033468306064606, 0.561234712600708, 0.5452303886413574, 0.5557570457458496, 0.20269624888896942, 0.3712272346019745, 0.46317917108535767, 0.12293154746294022, -0.7592301964759827, 0.4616289436817169, -0.35094916820526123, -0.6167181730270386, -0.16299238801002502, 0.4696931540966034, 0.38771310448646545, -0.2629067003726959, -0.27532026171684265, -0.018180301412940025, 0.036924201995134354, 0.07383368909358978, 0.0852116048336029, -0.3229529857635498, 0.08051170408725739, -0.3260017931461334, -0.5400996804237366, 0.719294011592865, -0.37824007868766785, -0.6395535469055176, -0.7772687673568726, -0.2512498199939728, 0.8406445980072021, -0.49060359597206116, -0.806143581867218, 0.8184162974357605, -0.016828028485178947, -0.6732774376869202, 0.28743332624435425, -0.4123092293739319, -0.08160346001386642, 0.3230169415473938, -1.226628065109253, -0.27905598282814026, 0.26379501819610596, -0.6097434759140015, -0.06884777545928955, 0.019520964473485947, 1.5203815698623657, -0.1225162073969841, -0.9164441227912903, -0.5087161064147949, 0.33913323283195496, -0.12102847546339035, 0.4410967230796814, -0.6930334568023682, 0.31419962644577026, 0.36027151346206665, -0.587401807308197, 0.9057267904281616, 0.3478632867336273, -0.3607099950313568, -1.1074271202087402, -0.34953680634498596, 1.1271954774856567, -0.502515435218811, -0.7409935593605042, -0.37021133303642273, -0.8849924206733704, -0.08193885535001755, 0.5969999432563782, -0.8497976064682007, 0.6808459162712097, -0.27550360560417175, 0.4267082214355469, 0.12725640833377838, -1.1297955513000488, 0.1908152550458908, 0.3524059057235718, -0.16715724766254425, -0.6322566270828247, 0.62496018409729, 0.2821914255619049, -0.37801384925842285, -0.6385597586631775, 0.2798445522785187, -0.2765026092529297, 0.633873701095581, 0.6232976913452148, -0.686191737651825, 0.5782875418663025, 0.5128988027572632, 0.2173878252506256, -0.7347739338874817, -0.06334561854600906, -0.9089951515197754, 0.06594201922416687, -0.10536019504070282, 0.38617730140686035, -0.1385563611984253, 0.05009328946471214, 0.883286714553833, 0.18986789882183075, -0.403961181640625, -0.624030590057373, 0.012075294740498066, 0.25835713744163513, 0.227566197514534, -0.13714176416397095, -0.418338418006897, 0.38250473141670227, -0.042710211127996445, 0.26270386576652527, 0.9034342169761658, -0.2683418393135071, -0.3513270318508148, 0.7233960628509521, -0.47259652614593506, 0.5940513014793396, -0.7066255211830139, -0.32090654969215393, -1.5441539287567139, -0.0891980528831482, -0.9214715361595154, 0.21843212842941284, -1.7065839767456055, 0.11683855950832367, 1.0266486406326294, 0.053205106407403946, 0.11758255958557129, 0.13740628957748413, -0.6366761326789856, -1.2287453413009644, -0.4905490279197693, -0.759958028793335, 0.33834633231163025, 0.884692370891571, -1.0803008079528809, -0.17984279990196228, -0.3805009722709656, -0.3463154733181, 0.46319401264190674, 0.528091549873352, -0.8752998113632202, -0.7097786664962769, -1.146712303161621, -0.01702897809445858, 0.16918091475963593, -0.32783499360084534, -0.433224081993103, 1.145509958267212, 0.5472668409347534, -0.13464674353599548, -0.6133721470832825, 0.15871021151542664, -0.310451865196228, -0.24963237345218658, 0.8555759787559509, -1.1019976139068604, -0.17471055686473846, 0.2600399851799011, -0.6290345191955566, -0.6006439328193665, 0.42041245102882385, -0.2218567579984665, -0.9774894118309021, -0.046876657754182816, 0.3550683557987213, -1.0546292066574097, 0.04246620088815689, -0.47743067145347595, 0.0797291249036789, -0.9803026914596558, -0.29310956597328186, -0.19056099653244019, 1.046195149421692, -0.7405465841293335, 0.5155941247940063, 0.6572309136390686, -0.6760088801383972, -0.730201244354248, -0.14501650631427765, 0.09646237641572952, -0.31742194294929504, 0.7005699276924133, 0.6896395087242126, -0.35508546233177185, 0.923618733882904, 0.8098264336585999, 0.07343481481075287, -1.393147587776184, -0.11898616701364517, 0.5083192586898804, -0.5609897971153259, -0.478413850069046, 0.8782396912574768, -0.035461463034152985, -0.6861233115196228, 0.2524004578590393, -1.3826711177825928, -0.8968961834907532, -0.04558687284588814, 1.3108537197113037, 0.38230419158935547, 0.13207150995731354, -0.19571571052074432, -0.7485724091529846, 0.2003469616174698, -0.10129722207784653, -0.26891666650772095, 1.1055960655212402, -0.24803917109966278, -0.720322847366333, 0.40376153588294983, 0.6966484785079956, -0.6816447973251343, 0.29551398754119873, -0.6261172890663147, 0.3512648046016693, 0.354878693819046, 0.3497244417667389, -0.5493938326835632, -0.09526501595973969, 0.41395220160484314, 0.3673841059207916, 0.17566685378551483, 0.46667587757110596, -0.3290187120437622, 0.15455952286720276, 0.726883590221405, -0.40530750155448914, -0.6073114275932312, -0.8554778099060059, 0.8860014081001282, 1.5248395204544067, -0.9135132431983948, 0.6741852164268494, -0.24357536435127258, -0.7075725197792053, 1.092849612236023, -0.4174281656742096, 0.14800569415092468, 0.7604058384895325, -0.28167933225631714, 0.1440516859292984, -0.4388951063156128, -0.9891735911369324, 0.29828521609306335, 1.0295583009719849, 0.4833332300186157, 1.0981578826904297, 0.17647717893123627, -0.7910766005516052, 1.2544559240341187, 0.40169739723205566, 0.6432948708534241, 0.7263587117195129, 0.6848089098930359, -0.2823585867881775, -0.0728258267045021, 0.15713995695114136, 0.6816918253898621, -1.0036451816558838, -0.41005876660346985, -0.4942166209220886, 0.23858706653118134, -0.09205593168735504, 1.3591545820236206, 0.02456008829176426, 0.47836312651634216, 0.8265212178230286, 0.28547585010528564, 0.018048223108053207, -1.0736536979675293, -0.6421382427215576, 0.251862108707428, -0.1578020602464676, -0.011898825876414776, -0.4966660737991333, -0.7201307415962219, -0.40537229180336, 0.20130778849124908, 0.18670222163200378, 0.4178353548049927, 0.2811501622200012, 0.9790489673614502, 0.7573040127754211, 0.5048112273216248, -0.5812718272209167, 0.08475317060947418, -0.5697062611579895, -1.3077468872070312, -0.14655782282352448, -0.7035448551177979, 0.1312074065208435, 0.19688256084918976, -0.17624780535697937, -0.026758110150694847]}, "authors": [{"authorId": "145229872", "name": "Qianqian Xie"}, {"authorId": "31689330", "name": "Zheheng Luo"}, {"authorId": "2894465", "name": "Benyou Wang"}, {"authorId": "1881965", "name": "S. Ananiadou"}], "references": [{"paperId": "f63a02601c7c3fdabcfff118d98e815697c42e0f", "title": "shs-nlp at RadSum23: Domain-Adaptive Pre-training of Instruction-tuned LLMs for Radiology Report Impression Generation"}, {"paperId": "7ac387fa5d2bbfa99d8d1957d76e58e5154d1e0c", "title": "Summarizing, Simplifying, and Synthesizing Medical Evidence using GPT-3 (with Varying Success)"}, {"paperId": "c8779da397189ce5b16577db058461c5efb0d2c1", "title": "RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models"}, {"paperId": "a564daa5ffdd4ea4cbb28b6ea459da9f9f65428d", "title": "Faithful AI in Medicine: A Systematic Review with Large Language Models and Beyond"}, {"paperId": "848909fbae167f21589bfc7a54fbf27e306b883c", "title": "An Iterative Optimizing Framework for Radiology Report Summarization with ChatGPT"}, {"paperId": "574beee702be3856d60aa482ec725168fe64fc99", "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4"}, {"paperId": "348a1efa54376fa39053e5e25d52bd0eb6a0ba68", "title": "Capabilities of GPT-4 on Medical Challenge Problems"}, {"paperId": "59fc3119090d6dd98ebc3a619e22ab4b603952fa", "title": "FactReranker: Fact-guided Reranker for Faithful Radiology Report Summarization"}, {"paperId": "154493f69d7db3d49da0e51df0192c6ad5f1724a", "title": "Larger language models do in-context learning differently"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "e2cbafe8deed5db6d506e41cc4a261231ebb528a", "title": "CitationSum: Citation-aware Graph Contrastive Learning for Scientific Paper Summarization"}, {"paperId": "6052486bc9144dc1730c12bf35323af3792a1fd0", "title": "Large language models encode clinical knowledge"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "8a9e7290d403dd2098e5ce80d6338ae03071cf85", "title": "Readability Controllable Biomedical Document Summarization"}, {"paperId": "89a87a8a3f94dc28ad941d64336c1744533b5a77", "title": "GRETEL: Graph Contrastive Topic Enhanced Language Model for Long Document Extractive Summarization"}, {"paperId": "ae4acc595d460358c0ee44afc4483f2d9c5cb766", "title": "Pre-trained language models with domain knowledge for biomedical extractive summarization"}, {"paperId": "48078f2561917a8c64fee24e86185eba796a7ce9", "title": "RadBERT: Adapting Transformer-based Language Models to Radiology."}, {"paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a", "title": "Emergent Abilities of Large Language Models"}, {"paperId": "c4a734248999e48e93d7254f1e729b20afe1aa39", "title": "CHQ-Summ: A Dataset for Consumer Healthcare Question Summarization"}, {"paperId": "0db5207510819b9956849eb84bfe8703f8f3688d", "title": "BioBART: Pretraining and Evaluation of A Biomedical Generative Language Model"}, {"paperId": "c54a5fffdb9f30df445900742815de50dda28376", "title": "Abstractive summarization of hospitalisation histories with transformer networks"}, {"paperId": "0189aed0a2f9411d78e43ef4a855fe17cc971730", "title": "Human Evaluation and Correlation with Automatic Metrics in Consultation Note Generation"}, {"paperId": "4714313c8dcc5e51236e90146c24df1f440250e5", "title": "Graph Enhanced Contrastive Learning for Radiology Findings Summarization"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "31d871379976f859abc0dc0f9f713b004083e4e4", "title": "COVIDSum: A linguistically enriched SciBERT-based summarization model for COVID-19 scientific papers"}, {"paperId": "3dfb1f50f2a34a699c339dabaa6f9b3a977973de", "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "b15469d0ab3dc3a9dec037d761817b3fe546bed6", "title": "Pre-trained Language Models in Biomedical Domain: A Systematic Survey"}, {"paperId": "dbae4c89a93597c41ec4373f6da03a93eac2927b", "title": "Leveraging Pretrained Models for Automatic Summarization of Doctor-Patient Conversations"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "5e2a141d5bf0452bb78ada4a7c71c29821d8bb14", "title": "A systematic review of automatic text summarization for biomedical literature and EHRs"}, {"paperId": "5011b61b11fe88d2f79dd5bb330691d23b73dddc", "title": "Reinforcement Learning for Abstractive Question Summarization with Question-aware Semantic Rewards"}, {"paperId": "a0f287c8a1cd20a34d104789188b914d1bc9e8bc", "title": "Question-aware Transformer Models for Consumer Health Question Summarization"}, {"paperId": "781be521705dcd753a4092edc8de40aeaee9a37f", "title": "Towards Automating Medical Scribing : Clinic Visit Dialogue2Note Sentence Alignment and Snippet Summarization"}, {"paperId": "5a08cd9cca3f208283f5e913037df875ca24ef03", "title": "Medically Aware GPT-3 as a Data Generator for Medical Dialogue Summarization"}, {"paperId": "6003d268e9b5230dbc3e320497b50329d6186816", "title": "SciFive: a text-to-text transformer model for biomedical literature"}, {"paperId": "4fe19d28d91fb42047ca4bc7602f647c007b32c2", "title": "Attention-based clinical note summarization"}, {"paperId": "d25121da56c9050137800c69520111b30201d1ed", "title": "MS\u02c62: Multi-Document Summarization of Medical Studies"}, {"paperId": "59cc829af19b7711c05dd9f2d12a0e7fe4a65569", "title": "COVID-19 information retrieval with deep-learning based semantic search, question answering, and abstractive summarization"}, {"paperId": "34e29eaecab43fce7fd0de935fd40609112c47c2", "title": "Towards Objectively Evaluating the Quality of Generated Medical Summaries"}, {"paperId": "5b4376a0b97a474a4e063768cc4faf20691b7887", "title": "Automated Lay Language Summarization of Biomedical Scientific Reviews"}, {"paperId": "06af86469540794522169e80361aff89d6d9535e", "title": "Summarizing Medical Conversations via Identifying Important Utterances"}, {"paperId": "053b1d7b97eb2c91fc3921d589c160b0923c70b1", "title": "Learning to summarize from human feedback"}, {"paperId": "44f02e037fd78116f921c8c57bc9ee3f7b2e64fd", "title": "Generating (Factual?) Narrative Summaries of RCTs: Experiments with Neural Multi-Document Summarization"}, {"paperId": "a2f38d03fd363e920494ad65a5f0ad8bd18cd60b", "title": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "790dd0db272b948806432db374b6d89717b54838", "title": "Biomedical-domain pre-trained language model for extractive summarization"}, {"paperId": "788c6dd6e2441a15b7589e0d55c8289c97bb8c8d", "title": "Continual BERT: Continual Learning for Adaptive Extractive Summarization of COVID-19 Literature"}, {"paperId": "7d8c9587ec051ed1612a686d93c6d1a92b7cbda4", "title": "Generating Medical Reports from Patient-Doctor Conversations Using Sequence-to-Sequence Models"}, {"paperId": "762baed866a8f23e19ea52f265c9ba7f353896ce", "title": "Automatic Text Summarization of COVID-19 Medical Research Articles using BERT and GPT-2"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "e78040bda2d40045358b7090b896967cd8e58909", "title": "Summarization of biomedical articles using domain-specific word embeddings and graph ranking"}, {"paperId": "732a2f3532e41e05465e2b3a9b5eebc2ceb483c1", "title": "Generating SOAP Notes from Doctor-Patient Conversations Using Modular Summarization Techniques"}, {"paperId": "1d77bf9273392156b309b7ed871449776f9a1618", "title": "CAiRE-COVID: A Question Answering and Query-focused Multi-Document Summarization System for COVID-19 Scholarly Information Management"}, {"paperId": "4c3b5f8db4f44ed4d24e15227a0da30f7c20a665", "title": "Attend to Medical Ontologies: Content Selection for Clinical Abstractive Summarization"}, {"paperId": "e816f788767eec6a8ef0ea9eddd0e902435d4271", "title": "Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks"}, {"paperId": "bc411487f305e451d7485e53202ec241fcc97d3b", "title": "CORD-19: The Covid-19 Open Research Dataset"}, {"paperId": "62f1a84ed518bc11a285a5d7dd78f66dbe06b5fc", "title": "CheXbert: Combining Automatic Labelers and Expert Annotations for Accurate Radiology Report Labeling Using BERT"}, {"paperId": "929b4775b6896634e11a8feb0ca4ca64ef7b3e24", "title": "Extractive Summarization as Text Matching"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "3bcb17559ce96eb20fa79af8194f4af0380d194a", "title": "Pre-trained models for natural language processing: A survey"}, {"paperId": "80376bdec5f534be78ba82821f540590ebce5559", "title": "How Much Knowledge Can You Pack into the Parameters of a Language Model?"}, {"paperId": "3175467d02a809963a2aa0bf5b35789baf58365d", "title": "Deep contextualized embeddings for quantifying the informative content in biomedical text summarization"}, {"paperId": "25db56fc85fe15625c3375064a35e908ba6dfd2a", "title": "ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training"}, {"paperId": "60f43e763b370af0028317d7f6d94885cdfe390a", "title": "Federated Learning"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "d1f407b16fb8d99487baee37ed0805676c58e7ac", "title": "MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports"}, {"paperId": "93dc7870d37ea8aad5dc282d255dacf4fef33821", "title": "Optimizing the Factual Correctness of a Summary: A Study of Summarizing Radiology Reports"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "0c5598424cc96d8fb500eb553cb7969f86a0ede0", "title": "Evaluating the Factual Consistency of Abstractive Text Summarization"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "63748e59f4e106cbda6b65939b77589f40e48fcb", "title": "Text Summarization with Pretrained Encoders"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "38f23fe236b152cd4983c8f30d305a568afd0d3e", "title": "A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI"}, {"paperId": "11e5d5429f5143e8104d01fb2b9742b39c2a28d9", "title": "Abstractive Summarization: A Survey of the State of the Art"}, {"paperId": "2dad078c48278da520d5bd67ed2e4fca0ef85e83", "title": "On the Summarization of Consumer Health Questions"}, {"paperId": "347bac45298f37cd83c3e79d99b826dc65a70c46", "title": "Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "2a567ebd78939d0861d788f0fedff8d40ae62bf2", "title": "Publicly Available Clinical BERT Embeddings"}, {"paperId": "156d217b0a911af97fa1b5a71dc909ccef7a8028", "title": "SciBERT: A Pretrained Language Model for Scientific Text"}, {"paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"}, {"paperId": "0c1f8ee9a17a9db0bf3a66dd4821f5f86cb046b4", "title": "Learning to Summarize Radiology Findings"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "dd6b8e78c2bd08cd200180f7aca79d7a0a86cdad", "title": "Prioritising references for systematic reviews with RobotAnalyst: A user study"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38", "title": "Semi-supervised sequence tagging with bidirectional language models"}, {"paperId": "1bc49abe5145055f1fa259bd4e700b1eb6b7f08d", "title": "SummaRuNNer: A Recurrent Neural Network Based Sequence Model for Extractive Summarization of Documents"}, {"paperId": "95cd83603a0d2b6918a8e34a5637a8f382da96f5", "title": "MIMIC-III, a freely accessible critical care database"}, {"paperId": "1ac30af5522c7a50ec4d1ee43fd2bd8652a9bd52", "title": "A Neural Attention Model for Abstractive Sentence Summarization"}, {"paperId": "285c165c81fc9275955147a892b9a039ec8b1052", "title": "chrF: character n-gram F-score for automatic MT evaluation"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "04b9e4192eca063b95ca65db901e1cccfb0ecd6f", "title": "Preparing a collection of radiology examinations for distribution and retrieval"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "92dbb6ac991020cbea25d8f4663c38ab0d0492f8", "title": "Automated methods for the summarization of electronic health records"}, {"paperId": "be4e25eeef837f272aea6aaf1aa62bd108f1924c", "title": "Text summarization in the biomedical domain: A systematic review of recent research"}, {"paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5", "title": "GloVe: Global Vectors for Word Representation"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "87f40e6f3022adbc1f1905e3e506abad05a9964f", "title": "Distributed Representations of Words and Phrases and their Compositionality"}, {"paperId": "7de5085c35a6e62cef75c308769f29fb72f9479e", "title": "Mining electronic health records: towards better research applications and clinical care"}, {"paperId": "bd2062eb413816144bcfc1c8511f73712c67ac74", "title": "PubMed and beyond: a survey of web tools for searching biomedical literature"}, {"paperId": "5b73be2f2373f9f6bf3d3137bcdc7b8065901746", "title": "What can natural language processing do for clinical decision support?"}, {"paperId": "3366030d7a0cebe35087c1dbb39d7bbddd17993a", "title": "Summarization from Medical Documents: A Survey"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "7b95d389bc6affe6a127d53b04bcfd68138f1a1a", "title": "TextRank: Bringing Order into Text"}, {"paperId": "44fca068eecce2203d111213e3691647914a3945", "title": "LexRank: Graph-based Lexical Centrality as Salience in Text Summarization"}, {"paperId": "6c2b28f9354f667cd5bd07afc0471d8334430da7", "title": "A Neural Probabilistic Language Model"}, {"paperId": "dd5641e798d97077ab49818448c64bfa494b29da", "title": "Advances in Automatic Text Summarization"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "d80a6a85b0c263d638877fff66ddc12963e3c34f", "title": "A trainable document summarizer"}, {"paperId": "92aa352341f7a3ea03bc55329544750a42adde40", "title": "A computer readability formula designed for machine scoring."}, {"paperId": "26d5981f7da4b508961aea01d53cd60e2202ff2d", "title": "Derivation of New Readability Formulas (Automated Readability Index, Fog Count and Flesch Reading Ease Formula) for Navy Enlisted Personnel"}, {"paperId": "9a0e44fb87a44f19d93ea386cb6677ce399689c6", "title": "The Technique of Clear Writing."}, {"paperId": "4972b88f8f324a4fa18e921f62a9857af2b5fc7b", "title": "Crosslingual Generalization through Multitask Finetuning"}, {"paperId": "cd2d1a0f73ba8c40f882a386cd367899785fb877", "title": "PMC-LLaMA: Further Finetuning LLaMA on Medical Papers"}, {"paperId": null, "title": "Faithful AI in Healthcare and Medicine"}, {"paperId": "4729752f9d14a8ed63ed37b60506bef3e76c89ca", "title": "Few-shot fine-tuning SOTA summarization models for medical dialogues"}, {"paperId": "9a5f810099ea12f9f07bd4f2d4e232c9b383600c", "title": "The patient is more dead than alive: exploring the current state of the multi-document summarisation of the biomedical literature"}, {"paperId": "4bfa14526234e0548f4f261d29c83db92553c5f8", "title": "GenCompareSum: a hybrid unsupervised summarization method using salience"}, {"paperId": null, "title": "Hyung Won Chung"}, {"paperId": "562f4062b43830115568f9552b140721c958a72c", "title": "A Gradually Soft Multi-Task and Data-Augmented Approach to Medical Question Understanding"}, {"paperId": "e8f74c4ce0d230b016c49a1d473618650c126208", "title": "Optum at MEDIQA 2021: Abstractive Summarization of Radiology Reports using simple BART Finetuning"}, {"paperId": "960a0dabd013c307072a550c0c3ff703927dca88", "title": "BDKG at MEDIQA 2021: System Report for the Radiology Report Summarization Task"}, {"paperId": "18d1cd7da1ea12eb9bcc7b438e04fd117d5aa370", "title": "damo_nlp at MEDIQA 2021: Knowledge-based Preprocessing and Coverage-oriented Reranking for Medical Question Summarization"}, {"paperId": "8e1d376229b0bc6896eb50896761854a63b596ab", "title": "SumPubMed: Summarization Dataset of PubMed Scientific Articles"}, {"paperId": "1a2208420c24e39c3ea3f97bb19820c65d9e1ce3", "title": "ChicHealth @ MEDIQA 2021: Exploring the limits of pre-trained seq2seq models for medical summarization"}, {"paperId": "19164116fed967ca4dfd0905221f8c5f192a6999", "title": "Overview of the MEDIQA 2021 Shared Task on Summarization in the Medical Domain"}, {"paperId": "fc5e25efe0a30230b553c817e38bc8308e127a08", "title": "paht_nlp @ MEDIQA 2021: Multi-grained Query Focused Multi-Answer Summarization"}, {"paperId": "e6dea138484a59f7b0b42464f5f48c587c6894f3", "title": "QIAI at MEDIQA 2021: Multimodal Radiology Report Summarization"}, {"paperId": "f056922cb62d242a1da2e045ef50048111a3e82a", "title": "IBMResearch at MEDIQA 2021: Toward Improving Factual Correctness of Radiology Report Abstractive Summarization"}, {"paperId": "5c5751d45e298cea054f32b392c12c61027d2fe7", "title": "S2ORC: The Semantic Scholar Open Research Corpus"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Deepreinforcementlearningfromhumanpreferences"}, {"paperId": null, "title": "Deep reinforcement learning from human preferences. Advances in neural information processing systems"}, {"paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82", "title": "Deep Learning"}, {"paperId": "676b1549adae511164c1b5343f10260fd42035b4", "title": "The Impact of Frequency on Summarization"}, {"paperId": "1f1eaf19e38b541eec8a02f099e3090536a4c936", "title": "The Unified Medical Language System (UMLS): integrating biomedical terminology"}, {"paperId": "13167f9cd8c7906ca808b01d28dca6dd951da8a5", "title": "of the Association for Computational Linguistics"}, {"paperId": null, "title": "RedPajama: An Open Source Recipe to Reproduce LLaMA training dataset"}, {"paperId": null, "title": "Clinical-t5: Large language models built using mimic clinical text"}, {"paperId": null, "title": "2023. GPT-4 Technical Report"}, {"paperId": null, "title": "Qianqian and Zheheng"}, {"paperId": null, "title": "A Survey for Biomedical Text Summarization: From Pre-trained to Large Language Models"}]}