{"paperId": "a9d13e00c30fa82ec201587719efc11a11fceb7e", "title": "Efficiency 360: Efficient Vision Transformers", "abstract": "Transformers are widely used for solving tasks in natural language processing, computer vision, speech, and music domains. In this paper, we talk about the efficiency of transformers in terms of memory (the number of parameters), computation cost (number of floating points operations), and performance of models, including accuracy, the robustness of the model, and fair \\&bias-free features. We mainly discuss the vision transformer for the image classification task. Our contribution is to introduce an efficient 360 framework, which includes various aspects of the vision transformer, to make it more efficient for industrial applications. By considering those applications, we categorize them into multiple dimensions such as privacy, robustness, transparency, fairness, inclusiveness, continual learning, probabilistic models, approximation, computational complexity, and spectral complexity. We compare various vision transformer models based on their performance, the number of parameters, and the number of floating point operations (FLOPs) on multiple datasets.", "venue": "arXiv.org", "year": 2023, "citationCount": 5, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2302.08374", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper discusses the efficiency of transformers in terms of memory, computation cost, and performance of models, including accuracy, the robustness of the model, and fair \\&bias-free features, and introduces an efficient 360 framework, which includes various aspects of the vision transformer to make it more efficient for industrial applications."}, "embedding": {"model": "specter_v2", "vector": [0.41614770889282227, 0.22952993214130402, -0.2461894303560257, 0.08348800241947174, -0.5677297711372375, 0.2493346482515335, 0.6333032250404358, -0.36028021574020386, -0.6073125004768372, -0.7345356941223145, -0.1548381745815277, 0.23161573708057404, 0.30268242955207825, -0.10414496064186096, -0.20868241786956787, -0.14112313091754913, -0.5487766861915588, 0.1683807522058487, 0.057323724031448364, -0.038193799555301666, -0.10455170273780823, -0.2005538046360016, -1.6421751976013184, 0.26190271973609924, 0.22798649966716766, 1.6158018112182617, -0.4207207262516022, 1.0699785947799683, -0.3552994132041931, 0.47390711307525635, 0.7351697087287903, -0.7293099761009216, 0.7585697770118713, 0.4536813497543335, -0.2077828049659729, 0.12029173970222473, 0.5791040062904358, -0.4128219485282898, -0.5964175462722778, 1.188291311264038, -0.18405921757221222, 0.3026615381240845, 0.4883776605129242, -1.3300999402999878, -0.4017917513847351, -0.18741929531097412, 0.1970093697309494, 0.8014503717422485, -0.6183674335479736, -0.29863783717155457, 1.3861397504806519, -1.364442229270935, -0.6521438360214233, 1.4640339612960815, 0.35377028584480286, 0.27521198987960815, -0.1920083612203598, -1.0185438394546509, 0.26024341583251953, 0.09668241441249847, -0.7868674397468567, -0.6481314897537231, -0.3867740333080292, -0.19916358590126038, 1.2097227573394775, -0.12289252877235413, -0.2491600215435028, 0.33857718110084534, 0.2544693946838379, 1.0590931177139282, 0.6870220303535461, -0.6272826194763184, 0.08709601312875748, -0.18953289091587067, 0.4659730792045593, 1.2911056280136108, -0.1445835381746292, 0.35779961943626404, -1.6283050775527954, -0.6046831011772156, 0.23264437913894653, 0.2667262554168701, -0.033490974456071854, -0.7135318517684937, -0.17710186541080475, 0.9165295958518982, 0.5102654099464417, -0.15795382857322693, 0.24308612942695618, 0.8263207077980042, 0.6948831677436829, 0.24783757328987122, -0.08862792700529099, -0.03469064086675644, 0.32817795872688293, 0.7556246519088745, -0.3497217297554016, 0.1411711871623993, -0.08022679388523102, 0.8976581692695618, -0.4990164339542389, -0.09452630579471588, -0.7724823355674744, 0.4825270473957062, 1.3578243255615234, 0.6359866261482239, 0.4178115129470825, -0.8362836241722107, 0.05334211885929108, -0.8167881965637207, 0.1154838502407074, -0.46700406074523926, 0.4861709177494049, -0.10207271575927734, -1.181902527809143, -0.45656269788742065, -0.308387815952301, 0.5364304184913635, -1.2834208011627197, 0.24096782505512238, -0.6454979181289673, 0.023332318291068077, 0.14005230367183685, 0.4796704947948456, 0.39580586552619934, 0.622266948223114, 0.21828444302082062, 0.21987095475196838, 1.4815090894699097, -0.7724024057388306, -0.444805383682251, -0.829790472984314, -0.11033771932125092, -0.4636949598789215, 0.5414546728134155, 0.13880223035812378, -0.7576329112052917, -0.8260877728462219, -0.8064954876899719, -0.052275508642196655, -0.3309313952922821, 0.37312304973602295, 1.119795560836792, 0.6496700048446655, -1.1400187015533447, 0.2742229402065277, 0.02081650123000145, -0.3083272874355316, 0.8294768929481506, 0.3743460178375244, 0.3620516359806061, -0.45029422640800476, -0.8131294846534729, 0.21465854346752167, -0.29589152336120605, -1.0120141506195068, -0.3399933874607086, -0.2828807532787323, -1.0509074926376343, 0.3211738169193268, 0.24458728730678558, -0.8102670907974243, 1.2764389514923096, -0.1533806324005127, -0.7130377292633057, 0.6920722723007202, -0.33866992592811584, -0.060574792325496674, 0.47234272956848145, -0.12484242022037506, -0.18613505363464355, -0.3285263776779175, -0.027223283424973488, 0.5227748155593872, 0.909552812576294, -0.36114153265953064, -0.8077065348625183, 0.14392565190792084, -0.2052302211523056, 0.027214637026190758, -0.575025200843811, 1.0772911310195923, -0.5601100921630859, -0.268381267786026, 0.20386572182178497, 0.39216265082359314, -0.24139994382858276, 0.6689252257347107, -0.06765612959861755, -0.6388716101646423, 0.7465022802352905, 0.21293389797210693, 0.3742268681526184, -1.010206937789917, -1.5161700248718262, 0.3061724901199341, -0.06167730689048767, 0.007957635447382927, -0.6551687717437744, 0.046629246324300766, -0.39504265785217285, 0.19603829085826874, -0.034248463809490204, -1.0038337707519531, 0.034180015325546265, -0.19864985346794128, -1.0904780626296997, 0.11212708801031113, -0.3580099642276764, 1.0058132410049438, -0.5142809152603149, 0.40467745065689087, -0.02067745476961136, 0.061264872550964355, -0.655701756477356, 1.0204734802246094, 0.08811777085065842, -0.4348808228969574, 0.29103735089302063, -0.21878109872341156, 0.3613797426223755, -0.5363304615020752, 0.07712840288877487, -0.35633575916290283, 0.21855038404464722, 0.24152123928070068, -0.42876070737838745, 1.0684036016464233, -0.033712830394506454, 0.5714846849441528, -0.11039280891418457, -0.6365978717803955, 0.23646534979343414, 0.3906673789024353, -0.2835153639316559, -0.6803255081176758, 0.34569284319877625, 0.11359001696109772, -0.8757219910621643, 0.548781156539917, 0.36744970083236694, 0.7487810254096985, -0.21055765450000763, 0.433884859085083, 0.34834229946136475, -0.4403224587440491, -0.03794309124350548, -0.10216175764799118, 0.1934879571199417, -0.11213844269514084, 0.3931012749671936, -0.047202903777360916, 0.054679132997989655, -1.0370991230010986, -0.2256082147359848, 0.8858601450920105, 0.33845943212509155, 0.8532692193984985, 0.31660518050193787, -0.923308253288269, -0.18403689563274384, -0.5168012380599976, 0.7072848677635193, 1.3679829835891724, 0.1225430965423584, -0.17308364808559418, -0.6914631724357605, -0.3177376389503479, -0.6213008761405945, -0.4066573977470398, -0.19044610857963562, -0.24900053441524506, 0.21902042627334595, -1.3683221340179443, 0.9553762674331665, 0.3404971659183502, 1.375980019569397, -0.15200269222259521, -0.5768317580223083, -1.1616077423095703, 0.18802236020565033, -0.7919593453407288, -0.9227631092071533, 0.38532555103302, -0.4938167929649353, -0.2010618895292282, -0.023321060463786125, -0.15549150109291077, 0.2714965343475342, -0.12845368683338165, 0.4904276430606842, -0.5023149251937866, -0.3210422098636627, 0.327228307723999, 0.7425835728645325, -1.110204815864563, -0.29380133748054504, -0.4384152293205261, 0.07077664136886597, 0.16426579654216766, 0.45890000462532043, 0.3849547505378723, 0.32039210200309753, 0.06720968335866928, -0.3016242980957031, -0.44864892959594727, -0.012302291579544544, 0.06864041835069656, 0.7385565638542175, -0.10953521728515625, -0.6568174362182617, -0.5670815706253052, 1.2063565254211426, 0.5923935770988464, -0.7981827855110168, 0.33417436480522156, -1.0383566617965698, -0.18482929468154907, 0.19646821916103363, -0.6086838245391846, 0.13380718231201172, -0.18917900323867798, 0.5387283563613892, -0.9246890544891357, 0.034533604979515076, -0.4528449475765228, 0.34580332040786743, -0.404255747795105, 0.46995994448661804, 0.7575591802597046, 0.6777095794677734, 0.30553728342056274, 0.46531981229782104, -0.38285553455352783, 0.4998856484889984, 0.07513623684644699, 0.11661604791879654, 0.2038601189851761, 0.04360607638955116, -0.659864068031311, -0.5440995097160339, -0.33566024899482727, 0.28170034289360046, -0.12343106418848038, -0.11264488101005554, -0.7342489957809448, -1.3648103475570679, 0.10609535127878189, -0.9179662466049194, 0.35512834787368774, -0.31171390414237976, -0.2091888189315796, -0.3942795693874359, -0.775605320930481, -0.8419432044029236, -0.7050997614860535, -1.053728461265564, -1.1143836975097656, 0.2710019052028656, 0.23266930878162384, 0.4175366163253784, 0.15253929793834686, -0.6881757378578186, -0.08660762757062912, 0.7217895984649658, -0.6659157872200012, 0.7091651558876038, -0.2994166314601898, -0.592491626739502, -0.1330154687166214, -0.2534978985786438, 0.5506296753883362, -0.13980217278003693, 0.14912308752536774, -1.5894609689712524, 0.18411099910736084, 0.00526104960590601, -0.2492007166147232, 0.8313921093940735, 0.2211189717054367, 1.1973997354507446, -0.1477721631526947, -0.35923653841018677, 0.4995686709880829, 1.1831226348876953, -0.5875983834266663, 0.0980028510093689, 0.10006082057952881, 0.8525603413581848, -0.06810010224580765, -0.024601241573691368, 0.6020491719245911, 0.2634302079677582, 0.047250621020793915, 0.45888563990592957, -0.3018970489501953, 0.15559698641300201, -0.15531986951828003, 0.5312792062759399, 0.6495622992515564, 0.2682182490825653, -0.0308340135961771, -0.7953774929046631, 0.5045325756072998, -1.1450251340866089, -0.8163323402404785, 0.8039474487304688, 1.0930299758911133, -0.12137632071971893, 0.0588449165225029, -0.09997543692588806, 0.2772005796432495, 0.7601574063301086, 0.6362304091453552, -0.10437335819005966, -0.7767291069030762, 0.21945403516292572, 0.6373690962791443, 0.8063162565231323, 0.24592089653015137, -0.6644470691680908, -0.012110070325434208, 15.039868354797363, 1.1643919944763184, -0.48782283067703247, 0.6249789595603943, 0.983059823513031, 0.31727614998817444, -0.20093080401420593, -0.3226947784423828, -0.6284165978431702, -0.19040918350219727, 0.804533064365387, 0.10880456119775772, 0.7201208472251892, 0.39012590050697327, -0.5338496565818787, 0.30827420949935913, -0.30263710021972656, 1.467740535736084, 0.7863802313804626, -1.2741721868515015, 0.6027555465698242, 0.33151358366012573, 0.060020919889211655, 0.342384934425354, 1.061814308166504, 0.24056430160999298, 0.6373134851455688, -0.8020598292350769, 0.5058248043060303, 0.2319946587085724, 1.2085506916046143, -0.4213286340236664, 0.23291532695293427, 0.46518731117248535, -0.942309558391571, -0.34072309732437134, -0.6700268983840942, -1.1412936449050903, -0.4554775059223175, 0.2575085759162903, -0.6659562587738037, -0.3690583407878876, 0.08665123581886292, 0.3979435861110687, 0.2711726129055023, 0.534079372882843, -0.10136668384075165, 0.41527774930000305, -0.24552014470100403, -0.017128773033618927, -0.3159681558609009, 0.5133475661277771, -0.007392945233732462, -0.3979365825653076, 0.25832465291023254, -0.061156079173088074, 0.5133404731750488, 0.24573494493961334, -0.6594681739807129, -0.2685413360595703, -0.3159855902194977, -0.09133242070674896, -0.26337361335754395, 0.8492763638496399, 0.2587905526161194, 0.5114707350730896, -0.2156592160463333, 0.11266064643859863, 0.22657901048660278, 0.11478839069604874, -0.3228784203529358, 0.17188748717308044, 0.729748010635376, -0.3214426636695862, 0.0683170035481453, 0.8258702158927917, -0.38592052459716797, -0.6130620241165161, -0.5624701380729675, -0.5302723050117493, 0.6154239177703857, -0.7457242608070374, -0.9577938318252563, 0.7374765276908875, -0.43081825971603394, -0.48115047812461853, 1.2175484895706177, -1.0155054330825806, -0.357470840215683, 0.28912290930747986, -1.5467169284820557, -0.9824165105819702, 0.21821853518486023, -0.047681231051683426, -0.1093328595161438, -0.11313365399837494, 1.2464416027069092, -0.1625279039144516, 0.23139865696430206, 0.3016660213470459, -0.2815832495689392, 0.15673966705799103, -0.11453954130411148, -0.644504725933075, 0.8675008416175842, 0.5492714643478394, 0.3186373710632324, 0.23082368075847626, -0.19418643414974213, 0.6526199579238892, -0.21492955088615417, -0.16964679956436157, 0.43668025732040405, -0.5014083385467529, -0.523935854434967, -0.8040735721588135, -0.32175570726394653, 0.04947529733181, 0.30569666624069214, 0.3247946798801422, 0.32567349076271057, -0.09470119327306747, -0.8649332523345947, -0.6363598108291626, -0.7989310622215271, 0.16359132528305054, 0.33532771468162537, -1.1587765216827393, -0.05185985937714577, -0.1673886775970459, 0.005744711961597204, -1.023057460784912, -0.02654598094522953, -0.19055864214897156, 0.27425962686538696, -0.23661266267299652, 1.3515681028366089, -0.15812377631664276, 0.5141398906707764, 0.6596636176109314, -0.34151843190193176, -0.37472864985466003, -0.04003927484154701, -0.757017195224762, 0.3207953870296478, 0.03648754209280014, 0.15622326731681824, -0.8452814221382141, -0.13741835951805115, 0.7132468819618225, 0.7924509644508362, -0.28564247488975525, -0.8723410367965698, -0.04089029133319855, -0.48016753792762756, -0.5919417142868042, 0.45570752024650574, -0.34939634799957275, -0.49443840980529785, -0.1473071277141571, 0.317219614982605, 0.773409366607666, 0.18809935450553894, -0.23637880384922028, 0.293760746717453, -0.37319710850715637, 0.23685379326343536, -0.31066715717315674, -0.5193362236022949, -1.3758623600006104, -0.026405492797493935, -0.9789719581604004, 0.09435544908046722, -0.7328494787216187, -0.29613929986953735, 0.09791801869869232, -0.5718925595283508, 0.2161426842212677, 0.31425538659095764, 0.11686227470636368, -0.05789110064506531, -0.3397270739078522, -0.4054546058177948, 0.6305320262908936, 0.6369730234146118, -0.969482421875, 0.6612980365753174, 0.34682226181030273, -0.21952380239963531, 0.5035566091537476, 0.2722606360912323, -0.6219984889030457, -0.9824334979057312, -0.5055501461029053, -0.1506047397851944, -0.36050352454185486, 0.2981238067150116, -0.8490676283836365, 0.9051273465156555, 0.08358002454042435, 0.0741296336054802, 0.5718375444412231, 0.7808184027671814, -1.2181637287139893, -0.5629345178604126, 0.6447830200195312, -1.054370641708374, -0.29009300470352173, 0.06278905272483826, -0.27744755148887634, -0.06101067364215851, 0.7821465730667114, 0.3134983777999878, -1.0146337747573853, -0.48307737708091736, 0.7533730864524841, -0.40003374218940735, 0.22481298446655273, 0.03553585708141327, -0.17782503366470337, -1.291429877281189, -0.39477309584617615, 0.12826447188854218, 0.12655410170555115, -0.14930488169193268, 0.8607528209686279, 0.6789263486862183, -1.0235954523086548, 0.5928608179092407, 0.6798244714736938, -0.12153990566730499, -0.05698757246136665, -0.19752071797847748, 0.2771136462688446, -0.33689552545547485, 0.16520124673843384, 0.025186579674482346, 0.1772160530090332, -1.2323747873306274, 0.19410429894924164, 0.9857334494590759, -0.1745627522468567, -0.19249047338962555, 1.1517109870910645, 0.06601548939943314, -0.7258843183517456, 0.22118794918060303, -1.2343201637268066, -0.5350145697593689, -0.26774540543556213, 0.5012835264205933, 0.08221971988677979, 0.1446428894996643, 0.1614830642938614, -0.6965851783752441, 0.26248905062675476, 0.36985164880752563, -0.5985820293426514, 0.22961534559726715, -0.11835303157567978, -0.34851083159446716, 0.36629733443260193, 0.2830275893211365, -0.5100651383399963, -0.9501235485076904, -0.7644791603088379, -0.43100506067276, -0.8182950019836426, 0.21589241921901703, -0.08381476998329163, -0.7809084057807922, 0.9103885293006897, 1.0239237546920776, 0.289228618144989, 0.5553897619247437, -0.5951549410820007, 0.19975581765174866, 0.4901031255722046, 0.1836380511522293, -0.3853265047073364, -0.5997327566146851, 1.0332955121994019, 0.9872555136680603, -0.7423425912857056, 0.35784685611724854, -0.7842797040939331, -0.8908885717391968, 0.7480442523956299, 0.10200774669647217, -0.19841910898685455, 0.8669655919075012, -0.06216447055339813, 0.14359836280345917, 0.20899350941181183, -0.8750997185707092, -0.2825900912284851, 1.0941520929336548, 1.3620295524597168, 0.07449173927307129, 0.024550698697566986, 0.6156051754951477, 0.8464566469192505, 0.16280196607112885, 0.28528451919555664, 0.6213279366493225, 0.23183751106262207, -0.24662433564662933, 0.0840011015534401, -0.4812087118625641, 0.7923486232757568, -0.8766381144523621, -0.6350892782211304, 0.24238112568855286, 0.24593232572078705, 0.23277923464775085, 0.730312705039978, 0.6748198866844177, 0.03785184770822525, 0.6541895866394043, 0.16364054381847382, 0.37769412994384766, -0.5678043365478516, -0.023829814046621323, -0.19038145244121552, -0.9115405082702637, -0.06032053008675575, -0.2827230989933014, -0.29761889576911926, -0.31213873624801636, -0.3915221691131592, 0.3448578417301178, 0.022676341235637665, 0.0728541761636734, 0.8485420942306519, 0.5056920051574707, 0.16368266940116882, -0.1249890923500061, -0.24660484492778778, -0.6607787013053894, -0.34533312916755676, -0.17223751544952393, -0.939903974533081, 0.11867431551218033, -0.21657425165176392, -0.2880198061466217, 0.0667671263217926]}, "authors": [{"authorId": "2064356655", "name": "B. N. Patro"}, {"authorId": "1791302", "name": "Vijay Srinivas Agneeswaran"}], "references": [{"paperId": "79b0be57c8ed56e21f1ac17437af9807713a0bb9", "title": "Skip-Attention: Improving Vision Transformers by Paying Less Attention"}, {"paperId": "5f7f90e5a8a48ee5c4414983ac99e286fd0c2375", "title": "Online Continual Learning with Contrastive Vision Transformer"}, {"paperId": "e0deb98643893fe711392d7e9e7ef324421b4235", "title": "Towards Efficient Adversarial Training on Vision Transformers"}, {"paperId": "0b8e8760d7dd64c7439019aeb3b6ac55dd5075d4", "title": "Wave-ViT: Unifying Wavelet and Transformers for Visual Representation Learning"}, {"paperId": "86609b3567c1f039aecd87cc87ef8b8a995215bc", "title": "Global Context Vision Transformers"}, {"paperId": "45cb47f6d7bb749b7c80b6f3f19894b92acc3495", "title": "THE-X: Privacy-Preserving Transformer Inference with Homomorphic Encryption"}, {"paperId": "3957d510ad5ff9ba1525126ccf8c1ffd926aa94f", "title": "Continual Learning with Lifelong Vision Transformer"}, {"paperId": "b53beca1816bf01c7ec015aa2cbb456a04b9bd46", "title": "Uncertainty-Guided Probabilistic Transformer for Complex Action Recognition"}, {"paperId": "bf6ce546c589fa8054b3972b266532664914bd21", "title": "Fast Vision Transformers with HiLo Attention"}, {"paperId": "f634a09747e4ca11754a9bfdccf7485c884f9f86", "title": "TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation"}, {"paperId": "259c681c76335540e13081efad584efdf9101868", "title": "DaViT: Dual Attention Vision Transformers"}, {"paperId": "2ad12a7be5eaf339a98c4defd8669e11fe726acc", "title": "MaxViT: Multi-Axis Vision Transformer"}, {"paperId": "de0454637d24b02fb57bc4ac863664dfa2c91d44", "title": "Improving Vision Transformers by Revisiting High-frequency Components"}, {"paperId": "952ca0aabff4c192b6c5faed6aad72fbc505a3d6", "title": "TransDARC: Transformer-based Driver Activity Recognition with Latent Space Feature Calibration"}, {"paperId": "6c22336873706b1cf5205ac6bd2432aa69d97821", "title": "ViTAEv2: Vision Transformer Advanced by Exploring Inductive Bias for Image Recognition and Beyond"}, {"paperId": "430bab3890e1e52c4c1f74900b0e408e47a1cb8f", "title": "How Do Vision Transformers Work?"}, {"paperId": "48e84128b0f288f544176138805a97fbe592a1dd", "title": "DynaMixer: A Vision MLP Architecture with Dynamic Mixing"}, {"paperId": "f4b11a696aa5a03fed1bfc47e65fdb7eb0e529c1", "title": "UniFormer: Unifying Convolution and Self-Attention for Visual Recognition"}, {"paperId": "e5cb26148791b57bfd36aa26ce2401e231d01b57", "title": "Vision Transformer with Deformable Attention"}, {"paperId": "9137efc758f80dd22bb56f82cca5c94f78a5db3e", "title": "MViTv2: Improved Multiscale Vision Transformers for Classification and Detection"}, {"paperId": "b476c932e959cfe645911786f1a070c70b5375c6", "title": "An Image Patch is a Wave: Phase-Aware Vision MLP"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "b10c6201fec56772fa97bbcaf37b4ead61b6270a", "title": "DyTox: Transformers for Continual Learning with DYnamic TOken eXpansion"}, {"paperId": "1cbb3d96242c3f47c3f40aada33616d0f5c07737", "title": "Inductive Biases and Variable Creation in Self-Attention Mechanisms"}, {"paperId": "cbb9446dcb53bb5efda262942f7c7b0f5b3b7195", "title": "UniNet: Unified Architecture Search with Convolution, Transformer, and MLP"}, {"paperId": "c0098a949d3f78ef4c21cbf9c6d1adf9c4412e3b", "title": "Uncertainty-Guided Transformer Reasoning for Camouflaged Object Detection"}, {"paperId": "605c69f22a2be97e18478987c69be29d596a3dd2", "title": "Redesigning the Transformer Architecture with Insights from Multi-particle Dynamical Systems"}, {"paperId": "6a6b41ac276476d0fcf77b0af0f0e7312638ecfa", "title": "ViT Cane: Visual Assistant for the Visually Impaired"}, {"paperId": "58970a426b687bb080b7fed3b4b78ab1ebaa56f4", "title": "Hire-MLP: Vision MLP via Hierarchical Rearrangement"}, {"paperId": "39b492db00faead70bc3f4fb4b0364d94398ffdb", "title": "Do Vision Transformers See Like Convolutional Neural Networks?"}, {"paperId": "f02d8976c7eadbc01482cd000a1df3598061597c", "title": "Flying Guide Dog: Walkable Path Discovery for the Visually Impaired Utilizing Drones and Transformer-based Semantic Segmentation"}, {"paperId": "dfa8694c3329c31205cd2454fa59c9e607b43695", "title": "Contextual Transformer Networks for Visual Recognition"}, {"paperId": "f75cddf2d42ed01b34686704eb3504becef67442", "title": "CycleMLP: A MLP-like Architecture for Dense Prediction"}, {"paperId": "71363797140647ebb3f540584de0a8758d2f7aa2", "title": "AS-MLP: An Axial Shifted MLP Architecture for Vision"}, {"paperId": "0b036cd5dfc49d835d0c759c8ca31d89f2410e65", "title": "CMT: Convolutional Neural Networks Meet Vision Transformers"}, {"paperId": "714bb0c515a76527438b83d9120badb228502feb", "title": "Trans4Trans: Efficient Transformer for Transparent Object Segmentation to Help Visually Impaired People Navigate in the Real World"}, {"paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "9b6af0e358e76d22f209c75b1702c3e6ea7815b1", "title": "Global Filter Networks for Image Classification"}, {"paperId": "2435ffb8ed3212156d6b6f19f633a861399cf30e", "title": "Vision Permutator: A Permutable MLP-Like Architecture for Visual Recognition"}, {"paperId": "e43eaeca5077d01061a38aebd24f8e3fa5948ad9", "title": "Co-advise: Cross Inductive Bias Distillation"}, {"paperId": "cf5e6e3c50a798d87033e0e108e88b3647738bbe", "title": "How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "60707f6d2bffeab09e8f1d073fce4fc06ab89ec1", "title": "S2-MLP: Spatial-Shift MLP Architecture for Vision"}, {"paperId": "576c462dbc1f3d732b919ef1daac37a817123e52", "title": "ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias"}, {"paperId": "2e8149dafb864ec3675087c99bf5572fcf4eb170", "title": "RegionViT: Regional-to-Local Attention for Vision Transformers"}, {"paperId": "a0964686d80e173529efca6377f47e6a1b2fe69a", "title": "Less is More: Pay Less Attention in Vision Transformers"}, {"paperId": "5e4f03f68c6867d850f457dc5cc36738e5dff6c1", "title": "Vision Transformers are Robust Learners"}, {"paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de", "title": "Pay Attention to MLPs"}, {"paperId": "1f133158a8973fb33fea188f20517cd7e69bfe7f", "title": "FNet: Mixing Tokens with Fourier Transforms"}, {"paperId": "48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5", "title": "ResMLP: Feedforward Networks for Image Classification With Data-Efficient Training"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "8d3ddc27dce9c6c0fe110e4f9cb45d3b59feb04b", "title": "Visformer: The Vision-friendly Transformer"}, {"paperId": "cc9f3a61ea4eaabf43cbb30cd1dd718074932679", "title": "All Tokens Matter: Token Labeling for Training Better Vision Transformers"}, {"paperId": "5b68522f58b61e7235b852677337ef3725075fd9", "title": "Co-Scale Conv-Attentional Image Transformers"}, {"paperId": "18b0e932d313d319c6be5a53f2390ee02a727d50", "title": "Fourier Image Transformer"}, {"paperId": "319d6c88152780f2835687100921393457668cc0", "title": "ODE Transformer: An Ordinary Differential Equation-Inspired Model for Neural Machine Translation"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "3cbe314cc5407a6c3249815b5173f22ea15173c2", "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"}, {"paperId": "0eff37167876356da2163b2e396df2719adf7de9", "title": "CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification"}, {"paperId": "d2a3bb6356d439146cd8d8e72dc728a1e3d93e7f", "title": "Understanding Robustness of Transformers for Image Classification"}, {"paperId": "fbd730a948a06cd4918c1d632ffdb4572b52d99b", "title": "Involution: Inverting the Inherence of Convolution for Visual Recognition"}, {"paperId": "3544650f12a05cf4ed3bf2f7e22fc5c02fcabf50", "title": "Pretrained Transformers as Universal Computation Engines"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "c16835c8e535ebd9c10a550ca9455fe384a14449", "title": "High-Performance Large-Scale Image Recognition Without Normalization"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78", "title": "Bottleneck Transformers for Visual Recognition"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "2f7dc1ee85e9f6a97810c66016e09ffeed684f03", "title": "Fourier Neural Operator for Parametric Partial Differential Equations"}, {"paperId": "91531cb745eaa5b60d9abdbe19b8926267e64baf", "title": "TextHide: Tackling Data Privacy for Language Understanding Tasks"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "8e990e779cd70b70e316b129f334edfb8aa89af1", "title": "Differentially Private Language Models Benefit from Public Pre-training"}, {"paperId": "55f9dcb397d89d81b04ccc108aa9d5086b0ffcc3", "title": "MP2ML: a mixed-protocol machine learning framework for private inference"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "f5c8464032a936451b222be1984cabf42d6adfa8", "title": "Are we done with ImageNet?"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "bc51622358d8eea83248ef29402fe10640d07ba6", "title": "Big Transfer (BiT): General Visual Representation Learning"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "49b64383fe36268410c430352637ed23b16820c5", "title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations"}, {"paperId": "4e0bb8c1c683b43357c5d5216f6b74ff2cb32434", "title": "Do ImageNet Classifiers Generalize to ImageNet?"}, {"paperId": "0d3c46a3cbfe06cec259fec954b6ff6df6c1a566", "title": "Learning long-range spatial dependencies with horizontal gated-recurrent units"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "dfb1bcdeb2eeb1a50ae218f5cc318842eabcfee6", "title": "Deep Neural Networks Motivated by Partial Differential Equations"}, {"paperId": "8b354d76813bd5375e7e5c8d17f630bec5936a01", "title": "ListOps: A Diagnostic Dataset for Latent Tree Learning"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "a83cec6a91701bd8500f8c43ad731d4353c71d55", "title": "3D Object Representations for Fine-Grained Categorization"}, {"paperId": "84b50ebe85f7a1721800125e7882fce8c45b5c5a", "title": "Cats and dogs"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "e01eae8dea6fbaa1ae7fc83535053932268df430", "title": "The ACL anthology network corpus"}, {"paperId": "7be3afdb7b7894321027ec90ea0a990aa7a0f266", "title": "Natural Language Understanding"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "02b28f3b71138a06e40dbd614abf8568420ae183", "title": "Automated Flower Classification over a Large Number of Classes"}, {"paperId": "10f97f1fb4f5c2c8e6c44d4a33da46d331dd4aeb", "title": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition"}, {"paperId": "32e0057c9a06d23182ff41553c9df1c9a8c4b757", "title": "Efficient Token Mixing for Transformers via Adaptive Fourier Neural Operators"}, {"paperId": "0def290ae38abb4a04e35e0bcdc86b71d237f494", "title": "On the Adversarial Robustness of Vision Transformers"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "13167f9cd8c7906ca808b01d28dca6dd951da8a5", "title": "of the Association for Computational Linguistics"}]}