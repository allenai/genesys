{"paperId": "9a83aeadc8db65fb6da39ec977360541cddaff5c", "title": "EfficientViT: Memory Efficient Vision Transformer with Cascaded Group Attention", "abstract": "Vision transformers have shown great success due to their high model capabilities. However, their remarkable performance is accompanied by heavy computation costs, which makes them unsuitable for real-time applications. In this paper, we propose a family of high-speed vision transformers named Efficient ViT. We find that the speed of existing transformer models is commonly bounded by memory inefficient operations, especially the tensor reshaping and element-wise functions in MHSA. Therefore, we design a new building block with a sandwich layout, i.e., using a single memory-bound MHSA between efficient FFN layers, which improves memory efficiency while enhancing channel communication. Moreover, we discover that the attention maps share high similarities across heads, leading to computational redundancy. To address this, we present a cascaded group attention module feeding attention heads with different splits of the full feature, which not only saves computation cost but also improves attention diversity. Comprehensive experiments demonstrate EfficientViT outperforms existing efficient models, striking a good trade-off between speed and accuracy. For instance, our EfficientViT-M5 surpasses MobileNetV3-Large by 1.9% in accuracy, while getting 40.4% and 45.2% higher throughput on Nvidia V100 GPU and Intel Xeon CPU, respectively. Compared to the recent efficient model MobileViT-XXS, EfficientViT-M2 achieves 1.8% superior accuracy, while running $5.8\\times/3.7\\times$ faster on the GPU/CPU, and $7.4\\times faster$ when converted to ONNX format. Code and models are available at here.", "venue": "Computer Vision and Pattern Recognition", "year": 2023, "citationCount": 95, "influentialCitationCount": 6, "openAccessPdf": {"url": "https://arxiv.org/pdf/2305.07027", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes a family of high-speed vision transformers named Efficient ViT, and designs a new building block with a sandwich layout, i.e., using a single memory-bound MHSA between efficient FFN layers, which improves memory efficiency while enhancing channel communication."}, "embedding": {"model": "specter_v2", "vector": [0.3806822896003723, 0.40610843896865845, -0.45997154712677, 0.22232817113399506, 0.3273463547229767, 0.30358123779296875, 0.5751095414161682, -0.5315043926239014, -0.36367151141166687, -0.6823413372039795, 0.4371446669101715, 0.43819937109947205, 0.42628979682922363, -0.05458647012710571, 0.2459293007850647, -0.05034981667995453, -0.8456650972366333, 0.09471210837364197, 0.23658934235572815, -0.29674822092056274, 0.38995224237442017, -0.3222361207008362, -1.4673022031784058, 0.12023834884166718, 0.1129683256149292, 1.451235055923462, 0.5369926691055298, 1.0317399501800537, -0.42720305919647217, 0.7276194095611572, 0.5762268304824829, -0.2796296179294586, 0.42373764514923096, 0.29142606258392334, -0.37299999594688416, 0.15938912332057953, 0.6313002109527588, -0.3952198028564453, -0.41997456550598145, 0.9595023393630981, 0.009408378973603249, 0.3606349229812622, 0.2599516808986664, -1.0619362592697144, -0.1305166780948639, 0.23747114837169647, 0.43486693501472473, 0.5154885053634644, -1.0572400093078613, -0.23243209719657898, 1.3108603954315186, -1.5046979188919067, 0.0647808313369751, 1.4700113534927368, 0.3692294955253601, 0.37017685174942017, -0.059892378747463226, -0.5693870186805725, 0.7879976630210876, 0.3779793083667755, -0.4596816897392273, -0.35387182235717773, 0.15210911631584167, -0.1026264876127243, 1.6964118480682373, -0.8032270073890686, 0.37802571058273315, 0.3959416151046753, 0.22395548224449158, 1.3260338306427002, 0.0028699811082333326, -0.5614643096923828, 0.06710414588451385, -0.44416719675064087, 0.3601105511188507, 1.1313687562942505, -0.1127825677394867, 0.09565400332212448, -1.216199278831482, 0.23294056951999664, 0.6634083986282349, 0.27076584100723267, 0.3622441589832306, -0.09451176226139069, -0.519914448261261, 0.9487815499305725, 0.9945237040519714, 0.40184512734413147, -0.6064143776893616, 0.8542380332946777, 0.6176575422286987, -0.10696230083703995, -0.2440054565668106, 0.1745457649230957, 0.17810018360614777, 0.7634432315826416, -0.582954466342926, 0.062082089483737946, -0.17451341450214386, 0.7144173383712769, -0.014364314265549183, 0.275028795003891, -0.2183179259300232, -0.11328215152025223, 1.3354331254959106, 0.26583331823349, -0.006904381327331066, -0.8317729234695435, -0.062323082238435745, -0.5863656401634216, -0.13028272986412048, -0.9222663640975952, -0.08795202523469925, -0.3742147982120514, -1.1441833972930908, -0.5235008597373962, -0.5152233839035034, 0.6044061779975891, -1.0965498685836792, 0.2692183256149292, -0.32918602228164673, 0.44735848903656006, -0.29235875606536865, 0.4098799228668213, 0.6588422656059265, 0.510499894618988, 0.47163110971450806, 0.33988624811172485, 1.3810813426971436, -1.4814592599868774, -0.5374240279197693, -1.1550384759902954, -0.21205557882785797, -0.47922396659851074, 0.10842636227607727, -0.08052798360586166, -1.0245846509933472, -1.5055370330810547, -0.5940834879875183, -0.07399618625640869, -0.6196993589401245, -0.09813973307609558, 1.314479112625122, -0.07039645314216614, -1.3420429229736328, 0.5748191475868225, -0.46431612968444824, -0.24475868046283722, 0.48319903016090393, 0.6209903359413147, 0.4063971936702728, -0.17271512746810913, -0.7868101596832275, 0.3449394404888153, -0.18617093563079834, -0.12789447605609894, -0.3699251413345337, -0.35474923253059387, -0.8865918517112732, 0.03035769797861576, 0.07339061796665192, -0.9013481140136719, 1.0644830465316772, -0.22768616676330566, -0.775904655456543, 0.5800851583480835, -0.3592953681945801, -0.13474948704242706, -0.3278260827064514, -0.06588583439588547, -0.09683863073587418, 0.20248842239379883, -0.0787014588713646, 1.063697338104248, 1.2468725442886353, 0.07805526256561279, -0.31602051854133606, -0.05719057098031044, -0.4552266597747803, -0.03810349479317665, -0.505109429359436, 1.2201582193374634, -0.53447026014328, -0.08413924276828766, 0.3135859966278076, 0.6456148028373718, -0.19105534255504608, 0.225929394364357, -0.29134422540664673, -0.9192830920219421, 0.9082401990890503, 0.24069523811340332, 0.5205668807029724, -0.7450716495513916, -0.6582826375961304, -0.32672011852264404, 0.5898838043212891, -0.011460838839411736, -0.6855266094207764, 0.2723211348056793, -0.09809555113315582, -0.1266029179096222, 0.5096275210380554, -1.1383755207061768, -0.09997889399528503, -0.1978478580713272, -0.8216902613639832, -0.09760800749063492, 0.13725298643112183, 1.160157561302185, -0.6858184337615967, -0.15352432429790497, 0.16995735466480255, 0.2954850196838379, -0.9141421318054199, 0.9419787526130676, -0.246689572930336, 0.013987256214022636, -0.15539266169071198, 0.0870232954621315, 0.21870501339435577, -0.8740895986557007, 0.42645975947380066, -1.0307464599609375, -0.20078296959400177, 0.3855537176132202, -0.1129332035779953, 0.9511457681655884, 0.0028913156129419804, 0.6225918531417847, 0.23915821313858032, -0.7202494144439697, 0.48301807045936584, -0.0026927199214696884, -0.12236480414867401, -0.45577260851860046, 0.6962729096412659, 0.13041329383850098, -0.44974035024642944, 0.43701454997062683, 0.7919831871986389, 1.217274785041809, -0.2919233739376068, -0.08557697385549545, 0.7042840123176575, 0.048005104064941406, -0.11058272421360016, 0.21745695173740387, 0.3281291723251343, -0.044892944395542145, 0.20549064874649048, -0.26782581210136414, 0.08567389845848083, -0.9715344905853271, -0.1948602795600891, 0.8166249990463257, 0.06267540156841278, 0.7618172764778137, 0.289054811000824, -1.19121515750885, -0.23722288012504578, 0.24614934623241425, 0.8258368968963623, 1.422225832939148, 0.29673922061920166, -0.2044714093208313, -0.6132919192314148, -0.2540145814418793, -0.5769883990287781, -0.8078237771987915, -0.44562897086143494, -0.20895732939243317, -0.29899388551712036, -0.9593346118927002, 0.5737305879592896, 0.4991712272167206, 1.6198126077651978, -0.9837192893028259, -0.5832198858261108, -0.4824795126914978, 0.33616673946380615, -0.8940074443817139, -0.5019525289535522, 0.47963032126426697, -0.5519050359725952, -0.25639402866363525, 0.1221243143081665, -0.4193378984928131, 0.27720892429351807, -0.15484602749347687, 0.838869035243988, -0.42192429304122925, -0.2512911856174469, 0.277523398399353, 0.7041524052619934, -0.6647980809211731, -0.06863155215978622, 0.10746157914400101, 0.018733812496066093, 0.23283888399600983, 0.4213620722293854, 0.4154476225376129, -0.4495643079280853, 0.2081380933523178, -0.14707809686660767, 0.3440099358558655, 0.14424514770507812, -0.07809749245643616, 0.927604615688324, -0.6560872793197632, -0.012686438858509064, -0.5237559080123901, 0.40961119532585144, 0.43774881958961487, -0.49284201860427856, -0.26513805985450745, -0.4632686674594879, -0.42557641863822937, 0.3061337172985077, -0.6513054966926575, 0.24299119412899017, -0.628422200679779, 0.5302808880805969, -0.9073412418365479, -0.29380160570144653, -0.4002659022808075, 0.38237783312797546, -0.45999178290367126, 0.23084430396556854, 0.36667484045028687, 0.32459086179733276, 0.15986022353172302, 0.2380545735359192, -1.0507621765136719, 0.6973627805709839, 0.44892287254333496, -0.029375238344073296, 0.25834619998931885, 0.20579072833061218, -0.751625120639801, -0.5405375957489014, -0.5336661338806152, -0.27030229568481445, -0.5816395282745361, 0.5820020437240601, -0.5705320239067078, -1.1226528882980347, 0.4263269901275635, -0.9564793705940247, -0.11769267916679382, 0.3446993827819824, 0.01505707111209631, -0.300843745470047, -1.2750407457351685, -1.1592265367507935, -0.3772251307964325, -1.1307107210159302, -1.1850908994674683, 0.33208537101745605, 0.3530108630657196, -0.1620512753725052, -0.5190544128417969, -0.5717930197715759, -0.6918778419494629, 1.2716625928878784, -0.32958775758743286, 0.557498037815094, -0.09853207319974899, -0.7418957948684692, -0.07416350394487381, -0.21905142068862915, 0.4856064021587372, -0.33584561944007874, 0.2938351035118103, -0.9782018065452576, 0.4504406750202179, -0.27704039216041565, -0.16693110764026642, 0.6362425684928894, 0.7267454266548157, 0.7083960771560669, 0.15605325996875763, -0.41699740290641785, 0.5085045099258423, 1.2663960456848145, -0.7913303971290588, 0.3344649374485016, 0.24605828523635864, 1.2015297412872314, 0.12583951652050018, -0.26693645119667053, 0.5391351580619812, 0.36717599630355835, 0.13488169014453888, 0.9275733232498169, -0.4945148825645447, -0.5553983449935913, -0.2781621813774109, 0.4274556338787079, 1.324780821800232, 0.07360826432704926, 0.24196529388427734, -0.7956949472427368, 0.87086421251297, -1.1564586162567139, -0.7589987516403198, 0.6661608219146729, 0.588261604309082, -0.2294125258922577, -0.3392789959907532, -0.02002616412937641, -0.18218058347702026, 1.0767087936401367, 0.6702762246131897, -0.26262903213500977, -0.6055918335914612, 0.09062039852142334, 0.6736767292022705, 0.24045947194099426, 0.5219588279724121, -0.3463713228702545, 0.5751489400863647, 14.781391143798828, 0.6405825614929199, -0.5140703916549683, 0.23248089849948883, 0.6585739850997925, 0.5436440706253052, -0.10410014539957047, -0.007267825771123171, -1.4531244039535522, -0.09674924612045288, 1.0899312496185303, 0.32787901163101196, 0.46720024943351746, 0.18950746953487396, -0.2518993318080902, 0.36677286028862, -0.12313708662986755, 0.8435004353523254, 0.5329140424728394, -1.372185230255127, 0.18893098831176758, 0.39154985547065735, 0.08419932425022125, 0.9017500281333923, 1.0380641222000122, 0.5318760871887207, 0.31822630763053894, -0.34627509117126465, 0.1685868799686432, 0.06241777166724205, 0.8561187386512756, -0.001769891707226634, 0.22474037110805511, 0.0829826071858406, -1.3457828760147095, -0.0155107406899333, -0.927042543888092, -1.469091534614563, -0.03350767493247986, 0.09258077293634415, -0.49030375480651855, -0.6945590972900391, 0.11204133927822113, 1.2331613302230835, -0.04137540981173515, 0.6157258749008179, -0.23183879256248474, 0.28113722801208496, -0.19836586713790894, -0.003983020316809416, 0.3856185972690582, 0.5977318286895752, -0.01372114010155201, -0.35638269782066345, -0.002907364396378398, -0.4217308461666107, 0.3847145438194275, 0.37052351236343384, -0.420015811920166, -0.5793652534484863, -0.41615450382232666, -0.03515470400452614, -0.15999487042427063, 1.4054895639419556, -0.10279716551303864, 0.1689257174730301, -0.3342815339565277, 0.0573132261633873, 0.2297734171152115, 0.052284564822912216, -0.4757099747657776, -0.1129361093044281, 0.519182562828064, -0.580143928527832, 0.430524080991745, 0.6171857118606567, -0.4519233703613281, -0.39632612466812134, -1.1134077310562134, -0.07504798471927643, 0.3216094970703125, -1.0162054300308228, -0.607589602470398, 1.2138981819152832, -0.3699953556060791, -0.42111828923225403, 0.32443660497665405, -0.9556804299354553, -0.4545001983642578, 0.292896568775177, -1.3965414762496948, -1.1748803853988647, -0.22219683229923248, 0.21707889437675476, -0.44333237409591675, 0.060516439378261566, 1.0983606576919556, 0.05702601373195648, -0.18221157789230347, -0.24621325731277466, -0.7805706262588501, -0.05139826610684395, -0.3153209686279297, -0.4007745683193207, 1.0669317245483398, 0.5043607950210571, -0.08369619399309158, -0.034859951585531235, -0.10616375505924225, 0.378169447183609, -0.5913789868354797, -0.33393293619155884, 0.6633681058883667, -0.4552394151687622, -0.021293871104717255, -0.8798442482948303, -0.6810922026634216, 0.35485437512397766, 0.6792529821395874, 0.5634217858314514, -0.07451431453227997, 0.08395411819219589, -0.7506269216537476, -0.2442215234041214, -0.5717717409133911, -0.10666344314813614, 0.26332342624664307, -0.7443684339523315, -0.04848252609372139, -0.2704479992389679, 0.3382622301578522, -0.661141037940979, -0.330810010433197, -0.22445960342884064, 0.19914360344409943, -0.4402152895927429, 1.2255702018737793, -0.0812947079539299, 0.52992844581604, 0.7002949118614197, -0.2568804621696472, -0.6075451374053955, -0.2337518334388733, -0.9767400026321411, -0.13059429824352264, -0.010921994224190712, -0.010608767159283161, -0.5482074022293091, 0.2939217984676361, 0.2643211781978607, 0.2717364728450775, -0.47485896944999695, -0.14515800774097443, 0.1331353336572647, -0.6614968776702881, -0.5123250484466553, 0.08835891634225845, -0.4461018145084381, -0.35881516337394714, 0.2414914220571518, 0.4795103371143341, 0.37762874364852905, 0.2755880355834961, -0.34398558735847473, 0.1549753099679947, -0.48003819584846497, -0.19163791835308075, -0.4172896146774292, -0.9172889590263367, -1.5821759700775146, -0.2109709531068802, -0.8494241237640381, -0.2284182906150818, -0.9242051839828491, -0.6053217649459839, 0.1678851693868637, -0.32229670882225037, 0.4245953857898712, 0.3068368136882782, 0.23295719921588898, -0.03934678062796593, -0.37065085768699646, -0.99090576171875, 0.5908457040786743, 1.219564437866211, -0.4932856559753418, 0.1642102599143982, -0.17721711099147797, -0.09773702919483185, 0.7126733064651489, 0.34418851137161255, -0.18441084027290344, -0.7025896906852722, -0.9095107316970825, 0.3646344244480133, -0.3699311316013336, 0.31059762835502625, -1.0361443758010864, 0.9365803599357605, 0.6699579358100891, 0.01999417133629322, -0.18509764969348907, 0.44031453132629395, -0.6694654226303101, -0.8689930438995361, 0.5420170426368713, -0.32586318254470825, 0.17077574133872986, 0.35341373085975647, -0.7220901250839233, -0.35239648818969727, 1.142050862312317, 0.27219656109809875, -0.9866065382957458, -1.5249472856521606, 0.6825667023658752, -0.44806426763534546, 0.0310946274548769, -0.3327787518501282, -0.24353240430355072, -1.6326042413711548, -0.372683048248291, -0.0929938480257988, 0.08257678151130676, -0.5275841355323792, 0.7292200922966003, 0.7015519142150879, -1.133533000946045, 0.31146445870399475, 0.6924663782119751, -0.27464672923088074, 0.10349583625793457, 0.42783141136169434, 0.8600791096687317, -0.1592450886964798, 0.19361133873462677, -0.4118731915950775, 0.04615427181124687, -0.6522983908653259, 0.29784607887268066, 0.8376781940460205, -0.3186494708061218, -0.18876688182353973, 1.1354331970214844, 0.21849693357944489, -0.7155919075012207, 0.12873700261116028, -1.132237434387207, -0.7461254000663757, -0.01696471869945526, 0.9619870185852051, 0.15448175370693207, 0.08008645474910736, -0.11155164986848831, -0.6920683979988098, 0.655157208442688, 0.007750750984996557, -0.22492404282093048, 0.46726465225219727, -0.0398724302649498, -0.545763373374939, 0.2996455430984497, 0.6675365567207336, -0.8012048602104187, -1.045211672782898, -0.7425752282142639, -0.8411091566085815, 0.16915617883205414, 0.4462389349937439, -0.06427142024040222, -1.054395079612732, 1.0155340433120728, 0.7085617184638977, 0.6336577534675598, 0.6457545161247253, -0.26989129185676575, 0.24193792045116425, 0.6023266911506653, 0.11514884233474731, -0.18677926063537598, -0.2657337784767151, 1.3025456666946411, 0.8411893248558044, -0.47109460830688477, 0.13697636127471924, -0.2925657331943512, -0.6528909206390381, 0.7735768556594849, 0.25531548261642456, -0.6992860436439514, 0.8657276034355164, 0.015297223813831806, -0.07686428725719452, 0.06862185895442963, -1.0771467685699463, -0.5973730087280273, 0.8943130970001221, 1.4275264739990234, 0.11098571121692657, -0.10615861415863037, 0.618915855884552, 0.5616156458854675, 0.3851541578769684, -0.017684808000922203, 0.2552611231803894, 0.2365463376045227, -0.4941353499889374, 0.5340635180473328, -0.26639342308044434, 0.5542675256729126, -0.6943243741989136, -0.7380926609039307, 0.2059495747089386, 0.7243478894233704, 0.1861080527305603, 0.6252118945121765, 1.0670256614685059, -0.24342718720436096, 0.32111871242523193, -0.20761050283908844, 0.5698119401931763, -0.23854798078536987, -0.2870910167694092, 0.14534121751785278, -0.9537940621376038, -0.34013357758522034, -0.5526343584060669, -0.06764177978038788, -0.33607691526412964, -0.5871263742446899, 0.4747254252433777, -0.3589076101779938, 0.40822529792785645, 0.7325470447540283, 0.7878010272979736, 0.7815383076667786, -0.3049650192260742, -1.1300170421600342, -0.14663900434970856, -0.6675653457641602, 0.09624136984348297, -0.6998636722564697, -0.0015553876291960478, -0.45345786213874817, -0.31551507115364075, -0.2448078989982605]}, "authors": [{"authorId": "2110789401", "name": "Xinyu Liu"}, {"authorId": "2484788", "name": "Houwen Peng"}, {"authorId": "66887984", "name": "Ningxin Zheng"}, {"authorId": "2108623481", "name": "Yuqing Yang"}, {"authorId": "145030939", "name": "Han Hu"}, {"authorId": "3080513", "name": "Yixuan Yuan"}], "references": [{"paperId": "3100ec129ffed6138d670d16113ab1abdf43b6a7", "title": "DS-Net++: Dynamic Weight Slicing for Efficient Inference in CNNs and Vision Transformers"}, {"paperId": "2fe71acc2c3f1e75b6149dea72838f0b594ad013", "title": "TinyViT: Fast Pretraining Distillation for Small Vision Transformers"}, {"paperId": "aa0b4b6ab37e75ba8407e0eddd69e778319e8fe0", "title": "LightViT: Towards Light-Weight Convolution-Free Vision Transformers"}, {"paperId": "05b7bd47fa5cbe10497c49004b57eb5ab4fdd0b4", "title": "EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for Mobile Vision Applications"}, {"paperId": "066c143b427571fb5568f2c581ea9066478d2e55", "title": "Separable Self-attention for Mobile Vision Transformers"}, {"paperId": "dd1139cfc609c2f3263d02e97176d5275caebc0a", "title": "EfficientFormer: Vision Transformers at MobileNet Speed"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "bf6ce546c589fa8054b3972b266532664914bd21", "title": "Fast Vision Transformers with HiLo Attention"}, {"paperId": "b4da9f3505e22d3e766ba21890285b822dc71599", "title": "EdgeViTs: Competing Light-weight CNNs on Mobile Devices with Vision Transformers"}, {"paperId": "21d2f55c247f83f3290ffa5311081005458cf8fe", "title": "Towards Lightweight Transformer Via Group-Wise Transformation for Vision-and-Language Tasks"}, {"paperId": "58c486ad4020177f5ed3d9f2883f3fc327b55770", "title": "MiniViT: Compressing Vision Transformers with Weight Multiplexing"}, {"paperId": "3c7f3b153c2b5b4074d95ac9d659a267a2bafa3f", "title": "Auto-scaling Vision Transformers without Training"}, {"paperId": "dc0102a51a9d33e104a4a3808a18cf17f057228c", "title": "Transformer Quality in Linear Time"}, {"paperId": "c3a302ed0a8687f8b7bc50e4a1dff0f96b4fbf52", "title": "GhostNets on Heterogeneous Devices via Cheap Operations"}, {"paperId": "2a4024163826151303aa0bbb18320b8a67167794", "title": "Pale Transformer: A General Vision Transformer Backbone with Pale-Shaped Attention"}, {"paperId": "72e81bc41ffae1d414836169107910025aaacb75", "title": "Lite Vision Transformer with Enhanced Self-Attention"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "66d735987a31d666a6459566ae026c40ab9a1c3a", "title": "The Efficiency Misnomer"}, {"paperId": "da74a10824193be9d3889ce0d6ed4c6f8ee48b9e", "title": "MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer"}, {"paperId": "bff6ffaa3443b79744d6b1e152dc454955455649", "title": "Towards Memory-Efficient Neural Networks via Multi-Level in situ Generation"}, {"paperId": "a66686e60a3eda0c606e036403cf0a07a5962595", "title": "Mobile-Former: Bridging MobileNet and Transformer"}, {"paperId": "5d032bd2632b6f5847767f39ce247098c6bbc563", "title": "Combiner: Full Attention Transformer with Sparse Computation Cost"}, {"paperId": "66775d9f16b3f4ca43dba2b31c7c42ca6dcba72b", "title": "GLiT: Neural Architecture Search for Global and Local Image Transformer"}, {"paperId": "d645bd08fc19d52164695f9cd5ae863345459a06", "title": "AutoFormer: Searching Transformers for Visual Recognition"}, {"paperId": "bf459cca52f336de2afe61e6e6348571c73943c1", "title": "Improving the Efficiency of Transformers for Resource-Constrained Devices"}, {"paperId": "7b664a306b7d2f68dd816ea1d6586cf3472d75c1", "title": "Early Convolutions Help Transformers See Better"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "8690d62d4bbbd0b1ed5e1f25320d10853bfbeb01", "title": "Scaling Vision with Sparse Mixture of Experts"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "003326a15fc4a8833785a47a741d7712474fa256", "title": "LeViT: a Vision Transformer in ConvNet\u2019s Clothing for Faster Inference"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "d28c8205a3e890e0012cb3af4b3964748e066ed9", "title": "Characterizing Co-Located Workloads in Alibaba Cloud Datacenters"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "3836ccb33191799e748e8e96f85a813eaf650ff8", "title": "Data Movement Is All You Need: A Case Study on Optimizing Transformers"}, {"paperId": "f5c8464032a936451b222be1984cabf42d6adfa8", "title": "Are we done with ImageNet?"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "a4cc0701170331a1fd0e58bad962bd7f39f5efc9", "title": "GhostNet: More Features From Cheap Operations"}, {"paperId": "6de905c188817e2c3cafcf9db292ac99ace7609a", "title": "SWIRL: High-performance many-core CPU code generation for deep neural networks"}, {"paperId": "fb564bacfa790d44ab02a72256d55aa8b2209914", "title": "MixConv: Mixed Depthwise Convolutional Kernels"}, {"paperId": "a7ce95c6f674b7b5b19a532491d160d142f8b2d6", "title": "FairNAS: Rethinking Evaluation Fairness of Weight Sharing Neural Architecture Search"}, {"paperId": "c2c083df88e88223e1a411e61040b94c233b1b63", "title": "MMDetection: Open MMLab Detection Toolbox and Benchmark"}, {"paperId": "21de3a36cb51adc205fad8a1d3d69118891dc3dd", "title": "AutoAugment: Learning Augmentation Strategies From Data"}, {"paperId": "a6f4917d043494d2ebaebe6b65cb35e6a07fda41", "title": "Importance Estimation for Neural Network Pruning"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "5e19eba1e6644f7c83f607383d256deea71f87ae", "title": "Searching for MobileNetV3"}, {"paperId": "b03c7ff961822183bab66b2e594415e585d3fd09", "title": "Are Sixteen Heads Really Better than One?"}, {"paperId": "79e523beb1e1411a241edde0464b07c2ebc231d1", "title": "Single Path One-Shot Neural Architecture Search with Uniform Sampling"}, {"paperId": "4a1004ecd34118116344633c7cdcc34493c423ee", "title": "Rethinking the Value of Network Pruning"}, {"paperId": "693c97ecedb0a84539b7162c95e89fa3cd84ca73", "title": "MnasNet: Platform-Aware Neural Architecture Search for Mobile"}, {"paperId": "c02b909a514af6b9255315e2d50112845ca5ed0e", "title": "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"}, {"paperId": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4", "title": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "79cfb51a51fc093f66aac8e858afe2e14d4a1f20", "title": "Focal Loss for Dense Object Detection"}, {"paperId": "d0611891b9e8a7c5731146097b6f201578f47b2f", "title": "Learning Transferable Architectures for Scalable Image Recognition"}, {"paperId": "9da734397acd7ff7c557960c62fb1b400b27bd89", "title": "ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "5b6ec746d309b165f9f9def873a2375b6fb40f3d", "title": "Xception: Deep Learning with Depthwise Separable Convolutions"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "a83cec6a91701bd8500f8c43ad731d4353c71d55", "title": "3D Object Representations for Fine-Grained Categorization"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "84b50ebe85f7a1721800125e7882fce8c45b5c5a", "title": "Cats and dogs"}, {"paperId": "a538b05ebb01a40323997629e171c91aa28b8e2f", "title": "Rectified Linear Units Improve Restricted Boltzmann Machines"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "e9dd235240904627b12782653b66318712780703", "title": "A Visual Vocabulary for Flower Classification"}, {"paperId": "68b1fd4f1a4d56e6a6db3ae1c98e1cd6bddf39dd", "title": "An Improved One millisecond Mobile Backbone"}, {"paperId": "b8a919f4a2aaa97bef19aa43e01f8bc347693b73", "title": "NASViT: Neural Architecture Search for Efficient Vision Transformers with Gradient Conflict aware Supernet Training"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "42b65c3871ef550cc6d8e9668ef6646aa1db975c", "title": "An Optimized Data\ufb02ow for Mitigating Attention Performance Bottlenecks"}, {"paperId": "320d87fa661661bcc9082aeca7f82566971f5e12", "title": "NViT: Vision Transformer Compression and Parameter Redistribution"}, {"paperId": null, "title": "Xiaohua Zhai, and A\u00e4ron van den Oord"}, {"paperId": null, "title": "14428 Authorized licensed use limited to the terms of the applicable license agreement with IEEE"}, {"paperId": null, "title": "Onnx: Open neural network exchange. https://github.com/onnx/onnx, 2019"}, {"paperId": null, "title": "Open neural network exchange"}, {"paperId": null, "title": "Pytorch image models, 2019"}, {"paperId": "ec3071fb918ad69ec80df1ca9cf1fdeb386a9603", "title": "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": null, "title": "Ruoming Pang, Vijay Vasudevan, et al. Searching for mo-bilenetv3"}, {"paperId": "e7297db245c3feb1897720b173a59fe7e36babb7", "title": "Optimal Brain Damage"}, {"paperId": null, "title": "Edgenext: ef\ufb01ciently [66 14429 Authorized licensed use limited to the terms of the applicable"}, {"paperId": null, "title": "license agreement with IEEE. Restrictions apply"}, {"paperId": null, "title": "Coremltools : Use coremltools to convert machine learning models from third - party libraries to the core ml format , 2021"}]}