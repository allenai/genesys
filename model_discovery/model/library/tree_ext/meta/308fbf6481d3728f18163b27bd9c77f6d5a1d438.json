{"paperId": "308fbf6481d3728f18163b27bd9c77f6d5a1d438", "title": "RecycleGPT: An Autoregressive Language Model with Recyclable Module", "abstract": "Existing large language models have to run K times to generate a sequence of K tokens. In this paper, we present RecycleGPT, a generative language model with fast decoding speed by recycling pre-generated model states without running the whole model in multiple steps. Our approach relies on the observation that adjacent tokens in a sequence usually have strong correlations and the next token in a sequence can be reasonably guessed or inferred based on the preceding ones. Experiments and analysis demonstrate the effectiveness of our approach in lowering inference latency, achieving up to 1.4x speedup while preserving high performance.", "venue": "arXiv.org", "year": 2023, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2308.03421", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "RecycleGPT is presented, a generative language model with fast decoding speed by recycling pre-generated model states without running the whole model in multiple steps based on the observation that adjacent tokens in a sequence usually have strong correlations."}, "embedding": {"model": "specter_v2", "vector": [-0.09693659842014313, 0.6725289821624756, -0.08550114184617996, -0.17901846766471863, -0.33896738290786743, -0.4479660391807556, 0.6498761177062988, -0.3743034601211548, -0.21030378341674805, -0.49751701951026917, 0.6587387323379517, -0.177361398935318, 0.7732616662979126, -0.05958763137459755, -0.5143495202064514, -0.12075453996658325, -1.1612465381622314, 0.17453773319721222, 0.1330445110797882, 0.03691179305315018, -0.3108481764793396, -0.5744209885597229, -1.1543973684310913, 0.1628296822309494, 0.12436163425445557, 0.4381927251815796, -0.1227477416396141, 0.8196420073509216, -0.6696017384529114, 0.6249732375144958, 0.41201889514923096, -0.35624489188194275, 0.17451491951942444, -0.3564605712890625, -0.22940859198570251, -0.19680558145046234, -0.06338538974523544, -0.3178885877132416, -0.49531078338623047, 0.47301504015922546, -0.3961845338344574, 0.14718495309352875, 0.23908057808876038, -0.6577407121658325, 0.010201528668403625, 1.3561140298843384, 0.46300533413887024, 0.6025279760360718, -0.2933008670806885, -0.7026085257530212, 0.9183045029640198, -1.3836921453475952, -0.14614780247211456, 1.6426985263824463, 0.2931642532348633, 0.3056744635105133, -0.23271027207374573, -0.6091242432594299, 1.053099513053894, -0.21636265516281128, -1.0001537799835205, -0.501919150352478, -0.07913998514413834, -0.07326866686344147, 1.8577706813812256, -0.3874843418598175, 0.2509080469608307, 0.7314791083335876, 0.17631025612354279, 1.240706443786621, -0.05240309238433838, -0.6054781079292297, 0.15153437852859497, 0.08929965645074844, 0.5646044611930847, 0.9906108379364014, -0.25199469923973083, 0.1957850456237793, -1.0334452390670776, -0.2401616871356964, 0.7229809165000916, -0.19712336361408234, 0.41142407059669495, -0.017101416364312172, 0.18266499042510986, 0.8632838129997253, -0.06576510518789291, 0.7403939962387085, -0.212867870926857, 0.9363887906074524, 0.4020879864692688, -0.06802276521921158, 0.11446498334407806, -0.07151024788618088, 0.1683892011642456, 0.12682203948497772, -0.6851692795753479, 0.04389307275414467, -0.13279904425144196, 1.0030945539474487, -0.36896172165870667, 0.9302557706832886, -0.5895071029663086, 0.3079294264316559, 1.6724193096160889, 0.09837885200977325, 0.49587252736091614, -0.7919613122940063, 0.24606172740459442, -0.9090944528579712, -0.07350943237543106, -0.2516655921936035, -0.06944617629051208, -0.34828558564186096, -0.6426375508308411, -1.405722737312317, -0.6348732113838196, -0.026333240792155266, -1.1333624124526978, 0.6924654245376587, -0.3263288736343384, 0.5934070944786072, 0.019708117470145226, 0.12129081785678864, 0.34369638562202454, 1.0239540338516235, 0.5860610008239746, -0.020822690799832344, 0.8891074657440186, -0.8120221495628357, -0.4614187180995941, -1.2576388120651245, 0.4506825804710388, 0.30801019072532654, -0.43823888897895813, -0.11140691488981247, -1.1546190977096558, -0.919231116771698, -0.5273377895355225, 0.30870336294174194, -0.2342439591884613, -0.009354284964501858, 1.394763469696045, 0.9086491465568542, -0.9239272475242615, 0.4385688900947571, -0.5566383600234985, 0.08906857669353485, 0.3334640860557556, 0.050145819783210754, 0.3032827377319336, -0.13477961719036102, -1.1850775480270386, -0.33947861194610596, 0.2931266129016876, -0.2184358686208725, -0.11162066459655762, -0.5254567265510559, -0.9428403973579407, 0.006661665625870228, 0.2333441972732544, -0.48451289534568787, 1.3352935314178467, 0.23453369736671448, -1.4971603155136108, 0.35693684220314026, -0.49755141139030457, -0.132040336728096, 0.05761865898966789, -0.273440420627594, -0.4176335036754608, -0.6020682454109192, -0.34423404932022095, 0.13390378654003143, 0.49921709299087524, -0.2888803780078888, -0.13259507715702057, -0.00910591147840023, -0.5930514931678772, -0.4355660080909729, -0.06446284800767899, 0.9394550323486328, -0.900909423828125, -0.39802253246307373, 0.6285563707351685, 0.36417561769485474, -0.6049001812934875, -0.6666067838668823, -0.44094786047935486, -0.874906599521637, 0.2136376053094864, -0.12007885426282883, 0.8961251974105835, -0.7809110879898071, -1.0267210006713867, 0.1691889464855194, -0.49765482544898987, -0.04648435115814209, -0.7977306246757507, 0.6324593424797058, -0.6059806942939758, 0.49218252301216125, 0.15429821610450745, -0.9319127798080444, -0.27532216906547546, -0.1345444619655609, -1.1024419069290161, -0.4821816086769104, 0.21146570146083832, 0.8889629244804382, -0.967991292476654, 0.142666295170784, -0.15085355937480927, 0.38306644558906555, -0.9165882468223572, 1.3156460523605347, -0.13063888251781464, 0.18765680491924286, -0.5026023387908936, -0.25429442524909973, 0.32696405053138733, -0.11297671496868134, 0.5703282356262207, 0.28207334876060486, -0.046880967915058136, 0.6167876720428467, -0.5804338455200195, 1.1516515016555786, -0.49158138036727905, 0.16645005345344543, -0.33599939942359924, -0.5490019917488098, 0.6419570446014404, 0.3017203211784363, -0.21537186205387115, -0.30486860871315, 0.19456104934215546, 0.13605931401252747, -0.751415491104126, 0.2760592997074127, 0.800625741481781, 0.9823883175849915, -0.5908895134925842, 0.48670777678489685, 0.3014064431190491, -0.022282613441348076, 0.08318329602479935, 0.5859777331352234, 0.9945019483566284, 0.40250810980796814, 0.4110831320285797, 0.4182587265968323, 0.15225553512573242, -1.0361101627349854, 0.3227197527885437, 0.9383243918418884, 1.171987771987915, 0.7126957774162292, 0.5044326782226562, -0.6565825343132019, -0.0856020450592041, -0.1351592242717743, 0.7574747204780579, 1.158587098121643, -0.6767789721488953, -0.34249773621559143, -0.4511321783065796, 0.05700070783495903, -0.5165411233901978, 0.3307567536830902, -0.15420715510845184, -0.16031669080257416, -0.7102094888687134, -1.1027015447616577, 0.8721121549606323, 0.4853302538394928, 0.8891220688819885, -0.5315170884132385, -0.014435905031859875, -0.18714752793312073, 0.3572781980037689, -0.8629187941551208, -0.2650609612464905, 0.48028579354286194, -0.7462937831878662, 0.5482138991355896, 0.13873855769634247, 0.006500669289380312, 0.15599125623703003, -0.7690415978431702, 1.0380669832229614, -0.41792866587638855, -0.18872833251953125, 0.1181153878569603, 0.34205976128578186, -0.5235861539840698, -1.1106796264648438, -0.1992366760969162, 0.1250360608100891, -0.22719654440879822, 0.23477426171302795, 0.41586005687713623, 0.17191414535045624, -0.2030630111694336, -0.049938466399908066, 0.001154651865363121, -0.283134400844574, -0.4537106156349182, 0.388155460357666, -0.3523891866207123, -0.08261667191982269, -1.3094209432601929, 0.4694708585739136, -0.09665407985448837, -0.7205198407173157, -0.1292629987001419, -0.49309805035591125, -0.036371540278196335, 0.44198569655418396, -0.4686185419559479, -0.31492120027542114, -0.5403977036476135, -0.20662489533424377, -0.32158103585243225, -0.12334771454334259, -0.00905713252723217, 0.535862922668457, 0.6426299810409546, -0.4131718575954437, 0.9338499903678894, 0.08427742123603821, -0.2746887505054474, 0.5665942430496216, -0.5905592441558838, 0.5744642019271851, 0.286032497882843, 0.3246208429336548, -0.35827115178108215, -0.18552552163600922, -0.5764564871788025, 0.12804383039474487, -0.26295965909957886, -0.15579752624034882, -0.3723129630088806, -0.3029846251010895, -0.9206089973449707, -0.9543529152870178, 0.08011973649263382, -1.103829026222229, -0.2804359197616577, 0.2800138592720032, -0.12407557666301727, -0.13682544231414795, -0.7731215953826904, -1.176361083984375, -1.2261542081832886, -0.544613242149353, -0.5097958445549011, 0.3572864830493927, 0.0685979425907135, -0.24344444274902344, -0.2613673508167267, 0.3537060022354126, -0.5048571825027466, 0.609465479850769, -0.9217496514320374, 0.7602302432060242, 0.04307752102613449, -0.8248026967048645, -0.42568084597587585, 0.6276524662971497, 0.26034536957740784, -0.34667977690696716, 0.1646208018064499, -0.986126720905304, 0.46736350655555725, -0.7300825119018555, 0.06575746834278107, 0.4343293309211731, 0.42378735542297363, 1.0104588270187378, -0.1098402738571167, -0.6591877341270447, 0.15601880848407745, 1.1844398975372314, -0.3708162009716034, 0.46514713764190674, -0.28353628516197205, 0.7126390933990479, 0.03573859483003616, -0.24856005609035492, 0.8388053774833679, 0.19345876574516296, 0.6103821992874146, 0.008940727449953556, 0.19000343978405, 0.2190377414226532, -0.5973065495491028, 0.7567725777626038, 1.3845884799957275, 0.2252502590417862, -0.3548038899898529, -0.7006336450576782, 0.7655331492424011, -1.27334725856781, -0.7960853576660156, 0.35925665497779846, 1.0941146612167358, 0.09040538221597672, -0.43483856320381165, -0.08297309279441833, -0.2314140498638153, 0.35393887758255005, 0.26996517181396484, -0.10221552103757858, -1.1774910688400269, 0.36019080877304077, 0.43621009588241577, 0.114825040102005, 0.6858786940574646, -0.10636256635189056, 0.7628129124641418, 15.118969917297363, 0.5031742453575134, 0.1397220939397812, 0.36450231075286865, 0.6101440191268921, 0.3043602406978607, -0.4786360263824463, 0.014702094718813896, -1.532952070236206, 0.03139433264732361, 1.6625746488571167, 0.22472484409809113, 0.5667257905006409, 0.3852222263813019, 0.33759015798568726, 0.04445831850171089, -0.24969153106212616, 0.527289867401123, 0.40494397282600403, -1.055878758430481, 0.22547459602355957, 0.3681590259075165, -0.16606689989566803, 0.6948740482330322, 0.7408022284507751, 1.0485954284667969, 0.9523305296897888, -0.3587222099304199, 0.3881986141204834, 0.44324055314064026, 0.044615499675273895, -0.31721338629722595, 0.1552039384841919, 0.35844653844833374, -0.9828096628189087, -0.00716687785461545, -0.7552034854888916, -0.8487523794174194, 0.36924687027931213, 0.2965163588523865, -0.8974029421806335, -0.4416266083717346, -0.10103411227464676, 0.400724321603775, 0.09980034083127975, 0.45140329003334045, -0.19649063050746918, 1.0450645685195923, -0.2206857055425644, -0.01274036429822445, -0.014229555614292622, 0.11308996379375458, 0.07924017310142517, -0.11317089945077896, 0.32636019587516785, 0.08983968198299408, -0.2109178602695465, 0.4383392333984375, -0.4357110261917114, -0.21777167916297913, -0.4521993398666382, -0.4303518235683441, 0.20335911214351654, 0.9224867224693298, 0.482260525226593, 0.29198533296585083, -0.4240966737270355, 0.3591451942920685, 0.45383769273757935, 0.20038536190986633, -0.35759976506233215, 0.30848878622055054, 0.32565799355506897, -0.47252681851387024, 0.2917729914188385, 0.29271674156188965, 0.23218287527561188, -0.31526005268096924, -0.8498893976211548, -0.15071170032024384, 0.4812268316745758, -1.0106236934661865, -0.6905816197395325, 0.9642980098724365, -0.27093416452407837, -0.4418984055519104, -0.4761144518852234, -0.5704822540283203, -0.25295594334602356, 0.5880463123321533, -0.9604595899581909, -0.6011222004890442, 0.4755985736846924, -0.252261221408844, -0.312564492225647, 0.15647318959236145, 1.4604649543762207, -0.15643127262592316, -0.44199338555336, -0.12219972908496857, 0.09302657842636108, 0.27251964807510376, -0.6006196737289429, -0.6351015567779541, 1.2648670673370361, 0.5598798394203186, 0.16698065400123596, 0.6624001264572144, -0.049523741006851196, 0.03862779960036278, -0.7575719356536865, -0.39235493540763855, 0.670815646648407, -0.9407838582992554, -0.5160601139068604, -1.074885606765747, -0.8372344970703125, 0.6999022364616394, 0.5658612251281738, -0.18981529772281647, 0.49894383549690247, 0.32165223360061646, -0.7098659873008728, -0.25972780585289, -0.31443047523498535, 0.15791545808315277, 0.37974879145622253, -0.4736765921115875, 0.17330226302146912, -0.4542666971683502, 0.35066238045692444, -0.8414539694786072, -0.6290560364723206, -0.6968948245048523, 0.20830288529396057, -0.06729937344789505, 0.9567227363586426, -0.4477822482585907, 0.37859514355659485, 0.8788519501686096, 0.28639522194862366, -0.7313330769538879, -0.21126119792461395, -0.9461497664451599, 0.04768974334001541, 0.6026566624641418, 0.6845515966415405, -0.49279722571372986, 0.24316979944705963, 1.0766081809997559, 0.38560566306114197, 0.11925546079874039, -0.6717458367347717, -0.4117891788482666, 0.1657242774963379, -0.9193590879440308, 0.5304162502288818, -0.43931812047958374, -0.10919831693172455, 0.054455406963825226, 0.03939352184534073, 0.9801980257034302, -0.2265981137752533, -0.6501251459121704, 0.6005469560623169, -0.11391328275203705, -0.1958802491426468, -0.1425386220216751, -0.3664650619029999, -1.375313639640808, 0.09277742356061935, -0.923675000667572, 0.17708449065685272, -0.7610994577407837, -0.3391726613044739, 0.07780721783638, -0.047024741768836975, 0.17543449997901917, 0.4134705662727356, -0.2997986078262329, -0.48187679052352905, -0.8637861609458923, -0.3266102373600006, 0.6409711241722107, 0.2931605577468872, -0.5405914783477783, -0.15186740458011627, 0.2900487780570984, 0.007923638448119164, 0.09810948371887207, 0.4200727045536041, -0.6827130913734436, -0.7367475628852844, -0.9888092875480652, 0.4131552278995514, 0.023652005940675735, 0.09138499200344086, -0.5480762720108032, 0.5613203644752502, 0.5753455758094788, 0.03719671070575714, -0.25774264335632324, 0.6133917570114136, -0.6807706356048584, -0.05523156747221947, 0.21367552876472473, -0.609359085559845, 0.20026463270187378, 0.3081628382205963, -0.2015773057937622, -0.023047931492328644, 0.47256678342819214, -0.41890907287597656, -1.304972767829895, -0.8438640236854553, 0.3821743428707123, -1.2865586280822754, -0.0789451003074646, -0.5602228045463562, -0.040860649198293686, -1.0011420249938965, -0.6441739797592163, 0.13216835260391235, 0.2286025732755661, -0.6809398531913757, 1.3291934728622437, 0.4390205144882202, -0.7093764543533325, 0.15147680044174194, 0.29803550243377686, -0.1861204355955124, -0.24979948997497559, 0.596198558807373, 0.1462380588054657, 0.1490444540977478, 0.573276698589325, 0.6177077889442444, 0.166704460978508, -1.0441347360610962, 0.031100085005164146, 0.7096706032752991, -0.47387808561325073, -0.33487048745155334, 0.8751133680343628, -0.5419096946716309, -0.7520675659179688, -0.1386319398880005, -1.3355807065963745, -0.6488405466079712, -0.4211217761039734, 0.6639102101325989, 0.02804381027817726, -0.03987877070903778, -0.009781277738511562, -0.6440651416778564, 0.25518497824668884, -0.2551412880420685, -0.5130292177200317, 0.541163444519043, -0.2630298137664795, -0.39828959107398987, 0.8404867649078369, 0.3967217803001404, -0.32647979259490967, -0.41890910267829895, -0.6248648166656494, -0.4722694158554077, -0.28278613090515137, 0.48041287064552307, 0.04117990657687187, -0.6024577617645264, 0.5312122106552124, 0.6114519238471985, 0.2891940176486969, -0.13166213035583496, -0.061020489782094955, -0.1736731231212616, 0.5199751257896423, 0.5380552411079407, -0.4635712504386902, -0.5194888114929199, 1.161774754524231, 1.113381028175354, -0.35619327425956726, 0.26799049973487854, -0.5571895241737366, -1.0375702381134033, 0.7733571529388428, 0.2753026485443115, -0.05072537064552307, 0.9964447617530823, 0.014599254354834557, 0.35531070828437805, 0.3626469075679779, -1.1940773725509644, -0.4058176279067993, 0.3010076582431793, 0.9036677479743958, 1.0291615724563599, 0.0031579071655869484, 0.340615451335907, 0.8519682884216309, 0.17291750013828278, 0.2479056864976883, 0.6996017098426819, 0.34235790371894836, -0.14580900967121124, -0.18163543939590454, -0.04148286208510399, 0.5066537261009216, -0.5958033800125122, -0.7203927636146545, 0.35856157541275024, 0.4577144682407379, -0.2582765221595764, 0.9173561930656433, 1.1084575653076172, 0.2512892186641693, 0.3658497929573059, 0.38269221782684326, 0.498928040266037, -0.48924216628074646, -0.3870832026004791, 0.21750083565711975, -0.44625064730644226, -0.3331228792667389, 0.01918189786374569, -0.6355218291282654, -0.5356977581977844, -0.08383119106292725, 0.4370444118976593, 0.17907246947288513, 0.17481079697608948, 0.9455606341362, 0.6283810138702393, 0.4420439600944519, 0.3310011327266693, 0.08474265038967133, -0.21008552610874176, -0.8250977396965027, -0.5007773637771606, -1.0597643852233887, -0.31689733266830444, 0.09045474231243134, 0.05238876864314079, -0.27236539125442505]}, "authors": [{"authorId": "2116341314", "name": "Yu Jiang"}, {"authorId": "2199246712", "name": "Qiaozhi He"}, {"authorId": "2072655811", "name": "Xiaomin Zhuang"}, {"authorId": "47039787", "name": "Zhihua Wu"}, {"authorId": "48884878", "name": "Kunpeng Wang"}, {"authorId": "2694567", "name": "Wenlai Zhao"}, {"authorId": "145789924", "name": "Guangwen Yang"}], "references": [{"paperId": "5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200", "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints"}, {"paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8", "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "a1f8082505c7e90b0a033e1b9da0a97d67aad66c", "title": "Accelerating Large Language Model Decoding with Speculative Sampling"}, {"paperId": "d8e9f8c8a37cb4cd26b92ad0d942d641cd512644", "title": "Fast Inference from Transformers via Speculative Decoding"}, {"paperId": "379e42895f6d40ab9e9559609f505aba89145a5d", "title": "Efficiently Scaling Transformer Inference"}, {"paperId": "4be7d1524edb0137599a5cc95f72844b85a52fe1", "title": "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "ae06a01845948c86210f88dfca9abdd02e4506cf", "title": "Lossless Acceleration for Seq2seq Generation with Aggressive Decoding"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "bd44f34b47c8a4b6947695853fc2814ac69664a6", "title": "Datasheet for the Pile"}, {"paperId": "da0d38cf2ac7e2a6908e0d9e1fff07058daab2ed", "title": "Sparse is Enough in Scaling Transformers"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "5e38dc1ccf33ac1df09b8eb6476f110cb3d1966f", "title": "Learning N: M Fine-grained Structured Sparse Neural Networks From Scratch"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "48745e3485f84cc5a2dab8e1ce41de0a38afb490", "title": "Efficient Transformer-based Large Scale Language Representations using Hardware-friendly Block Structured Pruning"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "70f2c1567ef94fdf4581e1290bf7667cc9a4dcfc", "title": "LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "143b0bd73e7e765945e0b8620f84f52878617560", "title": "Successfully Applying the Stabilized Lottery Ticket Hypothesis to the Transformer Architecture"}, {"paperId": "c5cc2340766d68ece08bb1520d357bcf8c03ad48", "title": "The Right Tool for the Job: Matching Model and Instance Complexities"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "dc52b09089704ebd6f471177474bc29741c50023", "title": "Fast Transformer Decoding: One Write-Head is All You Need"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "10eda4521c032adabaa8e70d6569e17370b29dcd", "title": "Root Mean Square Layer Normalization"}, {"paperId": "ce106590145e89ea4b621c99665862967ccf5dac", "title": "Q8BERT: Quantized 8Bit BERT"}, {"paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3", "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d", "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"}, {"paperId": "401dc39c2c8c910253d47980cfa3b4d2f7790d9b", "title": "WinoGrande"}, {"paperId": "92343cecdc990380de362b969eec60081959f507", "title": "Asynchronous Pipeline for Processing Huge Corpora on Medium to Low Resource Infrastructures"}, {"paperId": "6b2704fd8517a9917cfd9d3735930be48717d3de", "title": "Sharing Attention Weights for Fast Transformer"}, {"paperId": "a39398f68ae7e042f2ef5009e31b4e6a20fd5736", "title": "Learning Deep Transformer Models for Machine Translation"}, {"paperId": "f4238bd2385a52413ccbacfd9e409a650235bd13", "title": "Adaptive Attention Span in Transformers"}, {"paperId": "4043a936960de8e149dc208178fe1bcb157c7fa4", "title": "Recent Advances in Natural Language Inference: A Survey of Benchmarks, Resources, and Approaches"}, {"paperId": "5e04881e91bff952d102d967c4ffb498ec30d4af", "title": "Blockwise Parallel Decoding for Deep Autoregressive Models"}, {"paperId": "88bb0a28bb58d847183ec505dda89b63771bb495", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"}, {"paperId": "932a5de79d8a8ebb75ea0c43493450fd9922e738", "title": "Crowdsourcing Multiple Choice Science Questions"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "0d57ba12a6d958e178d83be4c84513f7e42b24e5", "title": "Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "1eb09fecd75eb27825dce4f964b97f4f5cc399d7", "title": "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches"}, {"paperId": "d1a6b3a5efde3783b53f822dc8dd00aaac934b95", "title": "SpecInfer: Accelerating Generative LLM Serving with Speculative Inference and Token Tree Verification"}, {"paperId": "903fb78627f336841e7689c84d7b2576e9331f0a", "title": "Recurrent Attention for Neural Machine Translation"}, {"paperId": null, "title": "A framework for few-shot language model evaluation"}, {"paperId": null, "title": "Improving language understanding with unsupervised learning"}, {"paperId": null, "title": "Long short-term memory. Supervised sequence labelling with recurrent neural networks, pp"}]}