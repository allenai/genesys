{"paperId": "05bcf9999525656cfaa59bc71f8572d771ff3776", "title": "Language Models Can See: Plugging Visual Controls in Text Generation", "abstract": "Generative language models (LMs) such as GPT-2/3 can be prompted to generate text with remarkable quality. While they are designed for text-prompted generation, it remains an open question how the generation process could be guided by modalities beyond text such as images. In this work, we propose a training-free framework, called MAGIC (iMAge-Guided text generatIon with CLIP), for plugging in visual controls in the generation process and enabling LMs to perform multimodal tasks (e.g., image captioning) in a zero-shot manner. MAGIC is a simple yet efficient plug-and-play framework, which directly combines an off-the-shelf LM (i.e., GPT-2) and an image-text matching model (i.e., CLIP) for image-grounded text generation. During decoding, MAGIC influences the generation of the LM by introducing a CLIP-induced score, called magic score, which regularizes the generated result to be semantically related to a given image while being coherent to the previously generated context. Notably, the proposed decoding scheme does not involve any gradient update operation, therefore being computationally efficient. On the challenging task of zero-shot image captioning, MAGIC outperforms the state-of-the-art method by notable margins with a nearly 27 times decoding speedup. MAGIC is a flexible framework and is theoretically compatible with any text generation tasks that incorporate image grounding. In the experiments, we showcase that it is also capable of performing visually grounded story generation given both an image and a text prompt.", "venue": "arXiv.org", "year": 2022, "citationCount": 79, "influentialCitationCount": 19, "openAccessPdf": {"url": "http://arxiv.org/pdf/2205.02655", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "A training-free framework for plugging in visual controls in the generation process and enabling LMs to perform multimodal tasks (e.g., image captioning) in a zero-shot manner, which outperforms the state-of-the-art method by notable margins with a nearly 27 times decoding speedup."}, "embedding": {"model": "specter_v2", "vector": [0.59906005859375, 0.7526625394821167, 0.055854059755802155, 0.07634143531322479, -0.7449895739555359, -0.2787409722805023, 0.9460736513137817, -0.4278697073459625, -0.13193447887897491, -0.6379848122596741, 0.6649109125137329, 0.21591104567050934, 0.10317383706569672, -0.4439411759376526, -0.5091068744659424, -0.02805963158607483, -0.8389806151390076, 0.51236492395401, 0.029407484456896782, -0.4751073718070984, -0.008540915325284004, -1.0087473392486572, -1.3540043830871582, 0.37969690561294556, 0.3871239125728607, 0.27389058470726013, 0.7462647557258606, 1.532476782798767, -0.36362192034721375, 0.27684450149536133, 0.5423396825790405, -0.6085258722305298, 0.15943509340286255, -0.5235139727592468, 0.022155484184622765, 0.06637603044509888, 0.42415595054626465, -0.640241265296936, -0.5589532256126404, 0.3348330855369568, 0.36919334530830383, 0.21605101227760315, 0.6573496460914612, -0.5130488276481628, -0.461903840303421, 0.5329614281654358, 0.4967750608921051, -0.024176044389605522, 0.4164803624153137, -0.5470002293586731, 1.3320494890213013, -1.2652226686477661, 0.8910623788833618, 1.5546307563781738, -0.06836608797311783, 0.7918975949287415, 0.24207699298858643, 0.13807500898838043, 0.9130338430404663, -0.2310093641281128, -0.585172712802887, -0.004952386487275362, -0.093218132853508, -0.2867068648338318, 1.2677499055862427, -0.1909196525812149, 0.06374575942754745, 0.8783348798751831, -0.14350971579551697, 1.5619192123413086, -0.5303106904029846, -1.3788154125213623, -0.29414933919906616, -0.06643597781658173, -0.5048253536224365, 1.141454815864563, -0.7037084102630615, 0.3449612855911255, -0.9890924692153931, 0.22124795615673065, 0.6402586698532104, -0.3747454881668091, -0.2261776179075241, -0.018210649490356445, -0.48010724782943726, 0.7589274048805237, 0.4347684681415558, 0.7354595065116882, 0.195224791765213, 0.7952913045883179, 0.007069038692861795, -0.03912957385182381, 0.021710623055696487, 0.023750144988298416, 0.47998154163360596, 0.4965748190879822, -1.0987319946289062, 0.6328189373016357, 0.1815277487039566, 1.015876293182373, -0.40855419635772705, -0.23968584835529327, -1.4557631015777588, 0.10059791058301926, 1.3826669454574585, 0.1430371254682541, 0.7035518884658813, -0.5268218517303467, 0.7783495187759399, -1.1594369411468506, 0.36947906017303467, -0.8481922745704651, 0.03529515117406845, 0.027048375457525253, -0.32075729966163635, -0.8629667162895203, -0.3733265995979309, 0.03625922650098801, -1.2354931831359863, 0.9602699875831604, -0.19610288739204407, 0.12038524448871613, -0.0015129295643419027, 0.7343885898590088, 0.8021451234817505, 0.8743096590042114, 0.02763300947844982, 0.4468914866447449, 0.998306155204773, -1.0136692523956299, -0.5154175758361816, -1.1384645700454712, 0.382470041513443, -0.22129403054714203, 0.6020639538764954, -0.5264272689819336, -1.3487169742584229, -1.0572324991226196, -1.1612893342971802, -0.2648952305316925, -0.677086353302002, 0.44287848472595215, 0.8791155815124512, 0.5328549742698669, -1.1832880973815918, 0.7474966049194336, 0.01829991489648819, -0.6656367182731628, 0.17336729168891907, -0.07875248789787292, 0.23032227158546448, -0.632476806640625, -1.129617691040039, -0.030913636088371277, -0.2660960257053375, -0.7369805574417114, -0.23352140188217163, -0.15978559851646423, -1.2123433351516724, -0.3405947685241699, 0.34257861971855164, -1.1600334644317627, 1.156275749206543, -0.1564347892999649, -1.3128622770309448, 0.9514552354812622, -0.41065090894699097, 0.24719476699829102, 0.6929524540901184, -0.3420378267765045, -0.09071427583694458, 0.21292684972286224, 0.07136733829975128, 1.3484219312667847, 0.49706602096557617, -0.28817078471183777, -0.05016779154539108, 0.4039413630962372, -0.24262438714504242, 0.12445294111967087, -0.041474610567092896, 0.6468538045883179, -1.010991096496582, -0.42624351382255554, 0.3571454584598541, 0.5959368944168091, -0.2658141553401947, -0.05832918733358383, -0.5784094929695129, -0.5386724472045898, 0.5893906354904175, 0.14597077667713165, 0.38519829511642456, -0.5859434604644775, -0.6716901659965515, -0.4031738042831421, -0.24126532673835754, -0.719248354434967, -1.0229765176773071, 0.6957367658615112, -0.15934816002845764, 0.6932587027549744, -0.0587058924138546, -1.316211462020874, 0.31179964542388916, -0.4500921368598938, -0.7870210409164429, -0.6065739393234253, 0.470973938703537, 1.4874216318130493, -0.7259938716888428, -0.30292409658432007, -0.06664379686117172, 0.23464739322662354, -0.7520781755447388, 1.1994272470474243, -0.9517804980278015, 0.27143213152885437, -0.702141284942627, -0.4382939338684082, -0.14692778885364532, -0.19163911044597626, 0.04214831441640854, -0.15677224099636078, -0.006471169646829367, 0.16888205707073212, -0.06966806203126907, 1.9686741828918457, 0.13752034306526184, 0.6539522409439087, -0.6410468220710754, -0.4519496560096741, 0.36898013949394226, 0.7349089980125427, -0.29466649889945984, -0.5356521010398865, 0.2894892692565918, 0.17565709352493286, -0.9399198889732361, -0.3614588677883148, 0.5710092782974243, 0.5532416105270386, -0.3892189860343933, 0.21638700366020203, 0.2732972800731659, -0.712028980255127, 0.7417187094688416, 0.6907176971435547, 0.7835536003112793, 0.8818463087081909, -0.48751839995384216, 0.48427385091781616, 0.09483818709850311, -0.6234042644500732, -0.8002669811248779, 1.0071616172790527, 1.2530020475387573, 2.0797970294952393, 0.3591639995574951, -0.7032917141914368, -0.2790977954864502, -0.06245884671807289, 1.05660080909729, 1.3996726274490356, 0.10295620560646057, -0.3051578998565674, -1.2073895931243896, -0.1443479359149933, -0.7331321835517883, 0.06376992911100388, -0.6968970894813538, 0.011908459477126598, -0.19128499925136566, -1.0338003635406494, 0.5628212690353394, 0.3164364695549011, 0.9499483108520508, -0.5945645570755005, -0.3363927900791168, -0.3201925754547119, -0.24841730296611786, -0.950410008430481, -0.7636494636535645, -0.12968583405017853, -0.20261505246162415, 0.028282904997467995, -0.9016824960708618, -0.3623095154762268, 0.5110334157943726, -0.7137051224708557, 0.9127947688102722, -0.21099524199962616, -0.8054293990135193, 0.5986434817314148, 0.23458828032016754, -0.39017602801322937, -0.5869747996330261, 0.07006815820932388, -0.5889917612075806, -0.3089219331741333, -0.41298314929008484, 0.47695714235305786, -0.05775361508131027, -0.003528254572302103, -0.6165553331375122, 0.8857778310775757, -0.0092740124091506, -0.2620384693145752, 0.7565590143203735, -0.7151200771331787, -0.24214304983615875, -0.624671459197998, 0.7874485850334167, 0.35171642899513245, -0.12829922139644623, 0.3442453444004059, -0.1446961760520935, -0.37927407026290894, -0.00709694717079401, -0.6285569071769714, -0.3433951437473297, -0.694474995136261, 0.3925040066242218, -0.1957884430885315, -0.35700276494026184, 0.17236272990703583, -0.005803318228572607, 0.5382726192474365, 0.20212705433368683, 0.2008875608444214, 0.24329741299152374, 0.07202892750501633, 1.1506532430648804, -1.407185435295105, 0.836050808429718, -0.060226920992136, 0.48251068592071533, 0.16861394047737122, 0.03148113563656807, -0.19162438809871674, -0.4896235764026642, 0.10137447714805603, -0.6464410424232483, -1.0828144550323486, 1.0959887504577637, -0.34039953351020813, -0.38435545563697815, -0.23920589685440063, -1.0859935283660889, -0.195707306265831, 0.19114930927753448, -0.7557520866394043, -0.828751802444458, -0.9447250366210938, -0.6815704703330994, -0.4710874557495117, -0.4721796214580536, -0.8183482885360718, 0.7793692350387573, 0.25002607703208923, -0.32728147506713867, -0.5847987532615662, 0.19835583865642548, -0.15013520419597626, 0.5320100784301758, 0.21213456988334656, 0.7257295846939087, 0.26388537883758545, -0.6864813566207886, -0.6335393190383911, 0.5217147469520569, -0.21106164157390594, -0.5227563977241516, 0.3741452097892761, -0.8495253324508667, 0.4352059066295624, -0.5572226643562317, -0.3440646827220917, 0.16791601479053497, 0.35750025510787964, 0.08053607493638992, 0.325115442276001, -0.9505070447921753, 0.29473578929901123, 1.5149893760681152, -0.517075777053833, 0.21139764785766602, 0.18132318556308746, 0.7790339589118958, 0.6190669536590576, -0.2256094515323639, 0.45525678992271423, 0.3664957582950592, 0.5034670829772949, 0.025802074000239372, -0.5483819842338562, -0.5190649032592773, -1.2516798973083496, 0.6964799165725708, 1.1522008180618286, 0.27523165941238403, -0.7762694954872131, -0.8429247736930847, 0.5635762810707092, -1.6719049215316772, -0.7368115782737732, 0.3795974850654602, 0.5726928114891052, -0.2861541211605072, -0.4800467789173126, -0.24500039219856262, -0.588810384273529, 0.8030534386634827, 0.33855751156806946, -0.10920022428035736, -0.17032524943351746, -0.29323193430900574, 0.39376387000083923, -0.4538431763648987, 0.6141961216926575, -0.31397730112075806, 0.4371974766254425, 14.316438674926758, 0.8733769059181213, 0.2289149910211563, 0.16771259903907776, 0.960117757320404, -0.09628026187419891, -0.4231118857860565, -0.07719995081424713, -0.8457158803939819, -0.5035539269447327, 0.7105833292007446, 0.0942344069480896, 0.07786265015602112, 0.03823239728808403, 0.42761415243148804, 0.14435678720474243, -0.6101154685020447, 0.5791803598403931, 0.985572874546051, -1.2224019765853882, 0.6055532693862915, 0.22879886627197266, 0.37183284759521484, 0.21728616952896118, 1.0340453386306763, 0.4482358396053314, 0.001544282422401011, -0.5493422150611877, 0.887469470500946, 0.48270606994628906, 0.8638542294502258, 0.14006976783275604, -0.003907123114913702, 0.2575247585773468, -0.7961726784706116, 0.03147875517606735, -0.5043155550956726, -0.8551045060157776, 0.8104773163795471, -0.00012079500447725877, -0.3615245223045349, -0.06825613230466843, -0.2236439436674118, 0.41363680362701416, -0.024817001074552536, 0.46036410331726074, -0.40880075097084045, 0.3950147330760956, 0.043534841388463974, -0.19735577702522278, 0.6322312951087952, 0.43722450733184814, 0.4289460778236389, -0.03622615337371826, 0.8155915141105652, 0.14037279784679413, 0.10054783523082733, 0.9904977679252625, -0.3421971797943115, 0.16899137198925018, -0.5723890662193298, -0.02013433165848255, -0.5005009174346924, 0.8267529010772705, -0.3585800230503082, 0.26715442538261414, -0.23241817951202393, 0.5953693985939026, 0.26610997319221497, 0.1831265240907669, -0.3622116148471832, 0.06439419090747833, -0.32946982979774475, 0.07277943938970566, 0.41234707832336426, 0.577929675579071, 0.10387705266475677, -0.4803670048713684, -0.4421737790107727, 0.12038953602313995, 0.24910622835159302, -1.4080567359924316, -0.8013917803764343, 1.023235559463501, -0.12604600191116333, -0.5119420289993286, -0.18353170156478882, -0.6232702136039734, -1.0651289224624634, 0.19890490174293518, -1.025998830795288, -0.9133728742599487, 0.04025915637612343, -0.36671894788742065, -0.14279942214488983, 0.050779785960912704, 0.9534361362457275, -0.3082796037197113, -0.1681705117225647, 0.11755523085594177, -0.00021743710385635495, -0.013752962462604046, -0.14759410917758942, -0.7850000262260437, 0.9594031572341919, 0.16865821182727814, 0.29159024357795715, -0.30887648463249207, 0.14553098380565643, -0.021340947598218918, -0.7315823435783386, 0.16936363279819489, 0.5817092061042786, -0.7589042782783508, -0.9487834572792053, -1.0572028160095215, -0.4802438020706177, -0.38729536533355713, 0.9818660616874695, -0.7151718139648438, 0.2516847848892212, -0.19386687874794006, -0.20610207319259644, 0.2740701138973236, -0.7867122888565063, 0.4579758644104004, 0.34337061643600464, -0.3025425672531128, -0.11812113970518112, 0.4475959539413452, 0.5638420581817627, -1.2422866821289062, 0.20193466544151306, -0.4813796281814575, 0.23048338294029236, -0.2428545504808426, 0.9077900052070618, -0.12844862043857574, 1.1149389743804932, 0.677745521068573, 0.02144967019557953, -0.4129050374031067, 0.05744292214512825, -1.3903636932373047, 0.6341177225112915, 0.5475566983222961, 1.0429449081420898, 0.19631686806678772, 0.43379247188568115, 1.2598694562911987, 0.496320903301239, -0.4030255079269409, -0.0952855572104454, -0.08131171017885208, 0.30289873480796814, -0.6771095991134644, 0.18453022837638855, -0.6211021542549133, 0.22151488065719604, 0.1121860072016716, 0.31602978706359863, 0.5943480730056763, -0.31148087978363037, -0.6920726299285889, 0.7685731053352356, 0.3008193373680115, -0.10910151153802872, -0.44598397612571716, -0.5487926006317139, -1.5785177946090698, -0.2360626459121704, -1.238147497177124, 0.3355053663253784, -1.5994391441345215, -0.19056330621242523, 0.6519893407821655, 0.09728911519050598, -0.16945980489253998, 0.09372250735759735, -0.22954390943050385, 0.29178154468536377, -0.7693189978599548, -0.7011716961860657, 0.7526916861534119, 1.1917990446090698, -0.7064539194107056, 0.2143697887659073, -0.4168066382408142, -0.07104875147342682, 0.4059600234031677, 0.1031973659992218, -0.28984230756759644, -0.9637556672096252, -1.3797138929367065, 0.5380997061729431, 0.2735367715358734, 0.3247954547405243, -1.188114047050476, 0.6729241609573364, 1.031531572341919, 0.08259814977645874, -0.23857048153877258, 0.4097241461277008, -0.23154579102993011, -0.5686167478561401, -0.19611015915870667, -1.0789070129394531, 0.29149365425109863, 0.3251505196094513, -0.5501388907432556, -0.20593248307704926, 0.29068151116371155, -0.4406948685646057, -1.2504096031188965, -0.3805064260959625, 0.4025249481201172, -0.6635063886642456, 0.12331444025039673, -0.4271121323108673, -0.26541051268577576, -0.8399112820625305, -1.042169213294983, -0.3346163034439087, 0.3886808454990387, -0.39643388986587524, 1.3795280456542969, 0.7444336414337158, -1.2648714780807495, -0.2946387231349945, -0.021990397945046425, -0.11129394918680191, 0.09624791890382767, 0.7412719130516052, -0.05325615778565407, -0.19216452538967133, 0.4235950708389282, 0.547607958316803, 0.22369521856307983, -0.778961181640625, -0.09558267891407013, 0.8535467982292175, -0.5400279760360718, -0.5054444670677185, 1.0689283609390259, 0.1242358535528183, -0.8314916491508484, 0.0842694640159607, -0.8023126125335693, -0.321781724691391, -0.35635504126548767, 0.8793937563896179, -0.31815916299819946, -0.28134942054748535, 0.09433010965585709, 0.03038807213306427, 1.0397839546203613, -0.06288250535726547, -1.5044472217559814, 0.37805283069610596, -0.4572206139564514, -0.0365474596619606, 0.1886250227689743, 0.678528368473053, -1.0049632787704468, -0.739294707775116, -0.12822860479354858, -0.610999584197998, -0.02074485830962658, 0.1316603571176529, -0.8220482468605042, -0.4536243975162506, 1.116999626159668, 0.7359029054641724, 0.25583094358444214, 0.14477422833442688, 0.4389314353466034, 0.32382890582084656, 0.33213335275650024, -0.15498381853103638, -0.6005546450614929, 0.026166271418333054, 0.8573924899101257, 1.477548599243164, -0.340253621339798, 0.03717014193534851, -0.23696990311145782, -0.8590279221534729, 0.9985178709030151, 0.22532404959201813, 0.10803820192813873, 0.5455549359321594, -0.12838314473628998, 0.2562958300113678, 0.0914502963423729, -1.0840950012207031, -0.3373810648918152, 0.9193646907806396, 1.6426602602005005, 0.7288931608200073, -0.06856736540794373, 0.02729373425245285, 0.9559014439582825, -0.080705426633358, 0.27375006675720215, 0.561687171459198, 0.2847553491592407, -0.26343321800231934, -0.3715994656085968, -0.28388699889183044, 0.25719910860061646, -0.5416907668113708, -0.5632837414741516, -0.10834787040948868, 0.537348747253418, 0.32831382751464844, 0.9459263682365417, 0.7784588932991028, 0.13745293021202087, 0.5607307553291321, 0.16919001936912537, 0.709474503993988, -0.2959625720977783, 0.053538668900728226, 0.089482381939888, -0.884770929813385, 0.04681431129574776, -0.1124015673995018, -0.5955917835235596, -0.5719874501228333, 0.2329069823026657, 0.5850082039833069, -0.2960103750228882, 0.22489313781261444, 0.9926063418388367, 0.6471275091171265, 0.40166622400283813, -0.33961084485054016, -1.0026726722717285, 0.5649382472038269, -0.5635216236114502, 0.5029246211051941, -0.33440354466438293, -0.6101835370063782, -0.38306427001953125, -0.023351507261395454, 0.3507905602455139]}, "authors": [{"authorId": "50087162", "name": "Yixuan Su"}, {"authorId": "1684523", "name": "Tian Lan"}, {"authorId": "2144475412", "name": "Yahui Liu"}, {"authorId": "144097210", "name": "Fangyu Liu"}, {"authorId": "1755465", "name": "Dani Yogatama"}, {"authorId": "2152546690", "name": "Yan Wang"}, {"authorId": "47648549", "name": "Lingpeng Kong"}, {"authorId": "50638196", "name": "Nigel Collier"}], "references": [{"paperId": "c57293882b2561e1ba03017902df9fc2f289dea2", "title": "Hierarchical Text-Conditional Image Generation with CLIP Latents"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "492a655a67e6ec7423a968cedb70eec0cdbc8e98", "title": "A Contrastive Framework for Neural Text Generation"}, {"paperId": "a2502d2cd7144c5e2bc1d0d7ec37d2c84b37d381", "title": "ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic"}, {"paperId": "3ea60cbce6c9065661d207fccf021c5d58a83f01", "title": "Scaling Up Vision-Language Pretraining for Image Captioning"}, {"paperId": "a7aa150b55d64d339b1c154d6d88455fc3cbc44f", "title": "ClipCap: CLIP Prefix for Image Captioning"}, {"paperId": "9fbca6164b8f94011cf1a1c3c10c23e2ba71a55b", "title": "TaCL: Improving BERT Pre-training with Token-aware Contrastive Learning"}, {"paperId": "50f6dd2aa07074d2904f153a0e489285499436c1", "title": "Unifying Multimodal Transformer for Bi-directional Image and Text Generation"}, {"paperId": "fff229da5a4fea06f99210e846bd28ecabe859b8", "title": "Rewire-then-Probe: A Contrastive Recipe for Probing Biomedical Knowledge of Pre-trained Language Models"}, {"paperId": "a4eb806502ec66d8cf1fe40693d3b81a7494e03d", "title": "Exploring Dense Retrieval for Dialogue Response Selection"}, {"paperId": "841ca3d87a422451596b8a4b8350e92106971791", "title": "Multi-Task Pre-Training for Plug-and-Play Task-Oriented Dialogue System"}, {"paperId": "821ad6c9f0fecb5fabb486a5a87a93b7ea65bcc0", "title": "VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding"}, {"paperId": "d031caface1f23995d4dc791e67454d7b4a19c1d", "title": "CONTaiNER: Few-Shot Named Entity Recognition via Contrastive Learning"}, {"paperId": "ac95a18762133d4065ac8af518c33084d83c5582", "title": "DialogLM: Pre-trained Model for Long Dialogue Understanding and Summarization"}, {"paperId": "946f28b30c0aede54eed7787c717dfd2e2c59bdd", "title": "Plan-then-Generate: Controlled Data-to-Text Generation via Planning"}, {"paperId": "0cf07903ea51d147e924ff1732ecd609ae9b35a0", "title": "Few-Shot Table-to-Text Generation with Prototype Memory"}, {"paperId": "e79be3f9ce409f1a9b7084ef880298665e5212d0", "title": "TACo: Token-aware Cascade Contrastive Learning for Video-Text Alignment"}, {"paperId": "8f167ec1149921fac63b1ea855443de109bb013a", "title": "How Much Can CLIP Benefit Vision-and-Language Tasks?"}, {"paperId": "c1ff08b59f00c44f34dfdde55cd53370733a2c19", "title": "Alias-Free Generative Adversarial Networks"}, {"paperId": "b31eb3428320342dfde042693ff2ca106dabed0d", "title": "SimCLS: A Simple Framework for Contrastive Learning of Abstractive Summarization"}, {"paperId": "63c74d15940af1af9b386b5762e4445e54c73719", "title": "VinVL: Revisiting Visual Representations in Vision-Language Models"}, {"paperId": "afa76fedf8701e057b2bf7a228bf41980ac2d1c9", "title": "RSTNet: Captioning with Adaptive Attention on Visual and Non-Visual Words"}, {"paperId": "c27ad8bcef5123c1f6be3561f9173cce03d1c2ef", "title": "Removing Word-Level Spurious Alignment between Images and Pseudo-Captions in Unsupervised Image Captioning"}, {"paperId": "38b0567e83386ddc294d6c81b541deacbd8e3c2a", "title": "CLIPScore: A Reference-free Evaluation Metric for Image Captioning"}, {"paperId": "c26759e6c701201af2f62f7ee4eb68742b5bf085", "title": "SimCSE: Simple Contrastive Learning of Sentence Embeddings"}, {"paperId": "2435c04832d486975304a094e55ecbab8acf8a5f", "title": "Fast, Effective, and Self-Supervised: Transforming Masked Language Models into Universal Lexical and Sentence Encoders"}, {"paperId": "aaa99de83292370a964fcaa51e6e866a96726bb2", "title": "StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery"}, {"paperId": "ada35e2c099fbde9d07a279311f4abe698341cd8", "title": "Human-like Controllable Image Captioning with Verb-specific Semantic Roles"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "616e0ed02ca024a8c1d4b86167f7486ea92a13d9", "title": "VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning"}, {"paperId": "3e8f037d1b2c893f4df37deda1da3dcc577a8bac", "title": "Non-Autoregressive Text Generation with Pre-trained Language Models"}, {"paperId": "141a5033d9994242b18bb3b217e79582f1ee9306", "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"}, {"paperId": "8484fdb56e4690927dc0191ede11c2d24bc5e2ef", "title": "MAUVE: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "b5ef0f91663f0cbd6910dec9a890c138f7ec10e0", "title": "Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks"}, {"paperId": "355403d7ce4b625307fd3ebb2beea269ecc15213", "title": "Dense Regression Network for Video Grounding"}, {"paperId": "d645d1b87e4f0bb371fd95fc9cb890d3a6cd8de1", "title": "PROTOTYPE-TO-STYLE: Dialogue Generation With Style-Aware Editing on Retrieval Memory"}, {"paperId": "7af72a461ed7cda180e7eab878efd5f35d79bbf4", "title": "A Simple Framework for Contrastive Learning of Visual Representations"}, {"paperId": "14fdc18d9c164e5b0d6d946b3238c04e81921358", "title": "Analyzing and Improving the Image Quality of StyleGAN"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "e04a80263d252a3d8a382ba37a249b9345620570", "title": "Plug and Play Language Models: A Simple Approach to Controlled Text Generation"}, {"paperId": "6648b4db5f12c30941ea78c695e77aded19672bb", "title": "Unified Vision-Language Pre-Training for Image Captioning and VQA"}, {"paperId": "a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be", "title": "Towards Unsupervised Image Captioning With Shared Multimodal Embeddings"}, {"paperId": "53a77e8f73f2ca422d6e38fa9ecc490231ac044c", "title": "Neural Text Generation with Unlikelihood Training"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "d8d89a0a1eca983512247af701a9e5596c903a16", "title": "Interpreting the Latent Space of GANs for Semantic Face Editing"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "eba62fe8050e475ffe533b9f70db538074d8d0d1", "title": "Context and Attribute Grounded Dense Captioning"}, {"paperId": "79de42d6ca8d1bf2952c46eb74e6e0561f979257", "title": "Dense Relational Captioning: Triple-Stream Networks for Relationship-Based Captioning"}, {"paperId": "171a027fc6c7f4194569170accc48187c8bb5aaa", "title": "Grounded Video Description"}, {"paperId": "ceb2ebef0b41e31c1a21b28c2734123900c005e2", "title": "A Style-Based Generator Architecture for Generative Adversarial Networks"}, {"paperId": "580fd9a601314ea32dc85ec98267b411dd3465cf", "title": "Unsupervised Image Captioning"}, {"paperId": "c677000c9078fdff8622be15a37db7d4945f36c2", "title": "Engaging Image Captioning via Personality"}, {"paperId": "a27973d90c1427369cb10aa0202d671f0422e21e", "title": "Diverse and Coherent Paragraph Generation from Images"}, {"paperId": "abc7998326cc4fc3c9c0c3a9ede8ae2538439966", "title": "\"Factual\" or \"Emotional\": Stylized Image Captioning with Adaptive Learning and Attention"}, {"paperId": "b4df354db88a70183a64dbc9e56cf14e7669a6c0", "title": "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"}, {"paperId": "ceabd7ff28ce2d501511da998252aeb938adc98b", "title": "Partially-Supervised Image Captioning"}, {"paperId": "29de7c0fb3c09eaf55b20619bceaeafe72fd87a6", "title": "Hierarchical Neural Story Generation"}, {"paperId": "a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8", "title": "Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering"}, {"paperId": "561ed7e47524fb3218e6a38f41cd877a9c33d3b9", "title": "StyleNet: Generating Attractive Visual Captions with Styles"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "2adae2da173b9dd720c8bcac0250a90a7f1ec697", "title": "Time-Contrastive Networks: Self-Supervised Learning from Video"}, {"paperId": "2cbb8de53759e75411bc528518947a3094fbce3a", "title": "Billion-Scale Similarity Search with GPUs"}, {"paperId": "9f4d7d622d1f7319cc511bfef661cd973e881a4c", "title": "Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning"}, {"paperId": "f90d9c5615f4a0e3f9a1ce2a0075269b9bab6b5f", "title": "SPICE: Semantic Propositional Image Caption Evaluation"}, {"paperId": "e1ce8d00729f9e61eeb315f3cbd7b5354706adbd", "title": "Synthesizing the preferred inputs for neurons in neural networks via deep generator networks"}, {"paperId": "85b68477a6e031d88b963833e15a4b4fc6855264", "title": "A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories"}, {"paperId": "d7ce5665a72c0b607f484c1b448875f02ddfac3b", "title": "DenseCap: Fully Convolutional Localization Networks for Dense Captioning"}, {"paperId": "7da9c26ea68a31d119e8222d1a5c33ef136ebed8", "title": "SentiCap: Generating Image Descriptions with Sentiments"}, {"paperId": "11c9c31dff70de92ada9160c78ff8bb46b2912d6", "title": "Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models"}, {"paperId": "4d8f2d14af5991d4f0d050d22216825cac3157bd", "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "55e022fb7581bb9e1fce678d21fb25ffbb3fbb88", "title": "Deep visual-semantic alignments for generating image descriptions"}, {"paperId": "258986132bf17755fe8263e42429fe73218c1534", "title": "CIDEr: Consensus-based image description evaluation"}, {"paperId": "d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0", "title": "Show and tell: A neural image caption generator"}, {"paperId": "82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9", "title": "Explain Images with Multimodal Recurrent Neural Networks"}, {"paperId": "a5e4377d2149a8167d89383d785793967cf74602", "title": "Meteor Universal: Language Specific Translation Evaluation for Any Target Language"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "cfaae9b6857b834043606df3342d8dc97524aa9d", "title": "Learning a similarity metric discriminatively, with application to face verification"}, {"paperId": "74d2ad28be32a5802a1b15d4e9a430db2234a3dd", "title": "Automatic Evaluation of Machine Translation Quality Using Longest Common Subsequence and Skip-Bigram Statistics"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "0dffd5c04f5830deadd4fba16ee1575abc5ee051", "title": "Exponential convergence of Langevin distributions and their discrete approximations"}, {"paperId": "a6cada3417aae1488138e96e876c6afc331349e6", "title": "Typical Decoding for Natural Language Generation"}, {"paperId": null, "title": "wide range of natural language understanding (NLU) tasks"}, {"paperId": null, "title": "ELECTRA: pre-training text encoders as discriminators rather than generators"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "237175d9a7864dcf396751593605ea022c31421b", "title": "Supplementary materials for: Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space"}, {"paperId": "6c11626ae08706e6185fceff0a6d05e4bfd6bd06", "title": "Unsupervised Learning of Visual Representations using Videos"}, {"paperId": "b4103e9b1d7e1699dd0d606b08c34394e2aff72d", "title": "Optimal scaling of discrete approximations to Langevin diffusions"}, {"paperId": "cfb4592221080deb127de94e8063fb403b13a298", "title": "Measuring nominal scale agreement among many raters."}]}