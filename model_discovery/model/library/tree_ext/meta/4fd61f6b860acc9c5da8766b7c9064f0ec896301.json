{"paperId": "4fd61f6b860acc9c5da8766b7c9064f0ec896301", "title": "A Modern Self-Referential Weight Matrix That Learns to Modify Itself", "abstract": "The weight matrix (WM) of a neural network (NN) is its program. The programs of many traditional NNs are learned through gradient descent in some error function, then remain fixed. The WM of a self-referential NN, however, can keep rapidly modifying all of itself during runtime. In principle, such NNs can meta-learn to learn, and meta-meta-learn to meta-learn to learn, and so on, in the sense of recursive self-improvement. While NN architectures potentially capable of implementing such behaviour have been proposed since the '90s, there have been few if any practical studies. Here we revisit such NNs, building upon recent successes of fast weight programmers and closely related linear Transformers. We propose a scalable self-referential WM (SRWM) that learns to use outer products and the delta update rule to modify itself. We evaluate our SRWM in supervised few-shot learning and in multi-task reinforcement learning with procedurally generated game environments. Our experiments demonstrate both practical applicability and competitive performance of the proposed SRWM. Our code is public.", "venue": "International Conference on Machine Learning", "year": 2022, "citationCount": 21, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A scalable self-referential WM (SRWM) that learns to use outer products and the delta update rule to modify itself and is evaluated in supervised few-shot learning and in multi-task reinforcement learning with procedurally generated game environments."}, "embedding": {"model": "specter_v2", "vector": [0.0802198201417923, 0.5264668464660645, -0.48911646008491516, 0.1417631059885025, 0.24203403294086456, 0.23964037001132965, 0.4147487282752991, -0.21449990570545197, -0.7754398584365845, -0.04734477028250694, 0.11166012287139893, 0.3385085165500641, 0.1932457536458969, -0.2597605884075165, -0.7628781795501709, 0.05589630827307701, -1.1160533428192139, -0.26195797324180603, 0.7310347557067871, -0.9326411485671997, 0.31624773144721985, -0.8711115121841431, -1.3717739582061768, 0.010798383504152298, 0.43805864453315735, 0.5447949767112732, -0.2525124251842499, 0.9010667204856873, -0.1694697141647339, 1.111187219619751, 0.5936635136604309, -0.3325272500514984, 0.6968222260475159, 0.16747087240219116, -0.2533983886241913, -0.44040799140930176, 0.388165146112442, -0.40194839239120483, -0.571190595626831, 0.7348889112472534, -0.23312672972679138, 0.3288798928260803, 0.2279224693775177, -0.699090838432312, -0.1783064901828766, 0.8176028728485107, 0.38772961497306824, 0.6694948673248291, -0.6934859752655029, -0.1824701428413391, 0.988059401512146, -0.7704114317893982, 0.2670080065727234, 1.1205095052719116, 0.786465585231781, 0.7791014909744263, -0.6087192893028259, -0.5684516429901123, 0.6434462666511536, -0.08395878225564957, -0.671265184879303, -0.27353954315185547, 0.10460617393255234, -0.3029802143573761, 1.4900985956192017, -0.522164523601532, 0.11213012784719467, 0.39878660440444946, 0.599530041217804, 1.0628200769424438, -0.3106566071510315, -0.6840609312057495, 0.26094409823417664, 0.3843591511249542, 0.2649098336696625, 1.0632492303848267, -0.25211262702941895, 0.8001000285148621, -1.1918901205062866, -0.1661883443593979, 0.8806573152542114, 0.11491209268569946, 0.19509506225585938, -0.9330832958221436, 0.012966274283826351, 0.9094825983047485, 0.23514728248119354, 0.6796499490737915, -0.4161403775215149, 1.4337632656097412, 0.8384307026863098, 0.8583210110664368, -0.024136576801538467, 0.41894832253456116, 0.47819989919662476, -0.12446022033691406, -0.4087302088737488, 0.3787868320941925, -0.09207552671432495, 0.7207121849060059, 0.41847580671310425, 0.5039085745811462, -0.5827006101608276, 0.6727080345153809, 1.2090340852737427, -0.6303549408912659, 0.6808881759643555, -1.523174524307251, 0.18567949533462524, -0.5844033360481262, 0.3242863714694977, -0.6450775265693665, 0.00855080783367157, -0.5023545026779175, -0.7926474809646606, -0.1486387550830841, -0.4139016568660736, -0.020742179825901985, -0.31651756167411804, 0.7612892985343933, -0.04107031598687172, -0.05686910077929497, -0.11793898046016693, 0.6536262631416321, 0.14407682418823242, 0.2212045043706894, 0.3808620274066925, 0.2371247112751007, 0.4260031282901764, -0.9166597127914429, -0.705669641494751, -1.0007641315460205, 0.4191534221172333, 0.34494709968566895, 0.04578210040926933, -0.22088384628295898, -1.7187436819076538, -1.2307732105255127, -1.287259578704834, 0.42206376791000366, -0.137175515294075, -0.42078107595443726, 1.6736233234405518, 0.4316674470901489, -0.7507559657096863, 1.6217801570892334, -0.2656920552253723, -0.06713762134313583, 0.2855193316936493, 0.2870839536190033, 0.2690689265727997, 0.1842254400253296, -1.2134084701538086, 0.5758892893791199, 0.5022963881492615, -0.5222555994987488, -0.1992461383342743, -0.979752779006958, -1.018334984779358, -0.44825538992881775, 0.8181669116020203, -0.8701631426811218, 1.6079484224319458, -0.31553396582603455, -1.423065423965454, 0.4242924451828003, 0.4321984648704529, -0.17989104986190796, 0.6172210574150085, 0.044895097613334656, -0.4388587176799774, -0.35583874583244324, -0.4414399266242981, 0.65176922082901, 0.6930001378059387, -0.6898449063301086, -0.3849904239177704, 0.01606687158346176, 0.3845485746860504, -0.09584549069404602, -0.5032692551612854, 0.5192232131958008, -0.251119464635849, 0.09426072239875793, 0.11075355857610703, 0.8044377565383911, -0.02451036311686039, 0.0996701717376709, 0.26722046732902527, -1.1283632516860962, 0.14740993082523346, 0.7846487164497375, 1.1591156721115112, -1.0164127349853516, -0.8204899430274963, 0.040345799177885056, 0.25336623191833496, -0.09774361550807953, -0.8982537984848022, 0.6390854120254517, -0.45078080892562866, 0.04153260961174965, 0.008817539550364017, -0.6737248301506042, 0.0016893971478566527, -0.04515190050005913, -0.1784326285123825, -0.23154307901859283, -0.20159034430980682, 0.8569048643112183, -1.164812684059143, -0.013892916962504387, -0.10406249016523361, 0.14370682835578918, -0.8244048953056335, 1.3268547058105469, -0.14394338428974152, -0.6450760364532471, 0.2725186049938202, -0.7787026762962341, -0.266022652387619, 0.21956050395965576, 0.025919895619153976, -0.5839031338691711, -0.2458895891904831, 0.14914444088935852, -0.8923237323760986, 1.6783416271209717, -0.3551851809024811, 0.18317988514900208, 0.14011085033416748, -0.39952242374420166, 0.02466990239918232, 0.4000668525695801, 0.053279951214790344, -0.5583416819572449, 0.30037596821784973, 0.033897411078214645, -0.20887728035449982, -0.013692577369511127, 0.7994937300682068, 0.8194058537483215, -0.062164440751075745, 0.3708484172821045, 0.7061988115310669, -0.4468463659286499, 0.8952398896217346, 0.3696911036968231, 0.8088356852531433, 0.5288221836090088, 0.4219718873500824, -0.034433070570230484, 0.0934540182352066, -0.7127566933631897, 0.08171866834163666, 0.9335635900497437, 0.4553280174732208, 0.7411797046661377, 0.15268750488758087, -1.0644571781158447, -0.6587170362472534, -0.28720518946647644, 0.7418720722198486, 1.908087134361267, -0.2159973531961441, 0.12675735354423523, -0.6895930767059326, 0.037687405943870544, -0.12336702644824982, 0.40427714586257935, -0.8835143446922302, -0.7364428043365479, -0.8385698199272156, -0.6729336977005005, 0.6192981004714966, 0.3396395146846771, 1.2154920101165771, -0.70052170753479, -0.7972718477249146, 0.34312841296195984, 1.1369926929473877, 0.17458781599998474, -0.9811413884162903, 0.5683790445327759, -0.6407958269119263, -0.15981189906597137, 0.14376433193683624, 0.05770276486873627, -0.03635271638631821, -0.1320822834968567, 0.8074474930763245, -0.2479647994041443, -0.2976455092430115, 0.2708267569541931, 0.9941809177398682, -0.6167492866516113, -0.6904463768005371, 0.3048500120639801, 0.024778369814157486, -0.22247964143753052, -0.36454933881759644, 0.061778731644153595, -0.35549286007881165, -0.023635966703295708, -0.6153444051742554, 0.008677945472300053, 0.13811908662319183, 0.08864733576774597, 0.053196728229522705, -0.38231855630874634, 0.22516357898712158, -1.577123999595642, 1.455923318862915, 0.2374798059463501, -0.19690343737602234, 0.051835205405950546, -1.0217045545578003, -0.003862915560603142, 0.11608610302209854, -1.0743253231048584, -0.23243902623653412, -1.0628560781478882, 0.519192099571228, -0.18339595198631287, -0.056771449744701385, -0.0496576689183712, 0.6707272529602051, -0.5702173113822937, 0.7994676232337952, 0.10932312160730362, 0.8136893510818481, 0.4777970016002655, 0.7505829334259033, -1.1234155893325806, 0.7017092108726501, -0.23963628709316254, 0.5423808693885803, -0.15478485822677612, -0.2514176368713379, -0.051597561687231064, -0.5792295336723328, -0.3167160153388977, 0.08522631973028183, -0.7610931992530823, -0.17204786837100983, -0.3501717448234558, -1.6859850883483887, -0.092179074883461, -0.8425816893577576, -0.9141515493392944, -0.32348811626434326, -0.5613604784011841, -0.47135642170906067, -0.8593928813934326, -1.2068564891815186, -0.7721543312072754, -0.7679993510246277, -0.4912642240524292, -0.5967262387275696, 0.11035149544477463, -0.625987708568573, -0.4434627592563629, 0.305350124835968, -0.6610018014907837, 1.5091174840927124, -0.831174910068512, 0.4775093197822571, 0.5178059339523315, -0.050113335251808167, 0.06215928867459297, 0.3456529974937439, 0.5588617920875549, -0.07626901566982269, -0.04375581815838814, -0.41245701909065247, 0.2239169031381607, -0.2042422592639923, -0.6703190803527832, 0.08101751655340195, 0.04088655114173889, 0.7468329668045044, -0.013237438164651394, 0.13100610673427582, 0.300258070230484, 1.4834845066070557, -0.17302651703357697, 0.33141952753067017, 0.7205315828323364, 0.7784551978111267, 0.33788782358169556, -0.2631722092628479, 0.5279451608657837, 0.4686737656593323, 0.38914987444877625, 0.5142816305160522, -0.025343123823404312, -0.08696746826171875, -0.3477405905723572, 0.28118595480918884, 1.0893964767456055, -0.16920217871665955, 0.6776399612426758, -0.32180434465408325, 0.26849496364593506, -1.6076431274414062, -1.150818943977356, 0.7962384223937988, 0.8210869431495667, 0.8975764513015747, -0.047077957540750504, -0.08146815001964569, -0.27117276191711426, 0.37131941318511963, 0.413065642118454, -0.8349143862724304, -0.9529881477355957, 0.3262843191623688, 0.1680488884449005, 0.3431771695613861, 0.5466426610946655, -0.22989879548549652, 0.4646763801574707, 14.56418514251709, 0.750388503074646, 0.37820732593536377, 0.6913022994995117, 0.19128499925136566, 0.2038799673318863, -0.19868125021457672, -0.44535326957702637, -0.7586143016815186, -0.4815254509449005, 0.9275826811790466, 0.1371554583311081, 1.065911889076233, 0.3054228723049164, -0.05549176037311554, -0.2600772976875305, -0.3261945843696594, 0.43956854939460754, 0.4265764653682709, -1.5069968700408936, 0.0013526573311537504, -0.21752066910266876, 0.3593362867832184, 0.3440681993961334, 0.8374433517456055, 1.0225545167922974, 0.847960889339447, 0.22784015536308289, 0.638670802116394, 0.6987141966819763, 0.874966025352478, -0.4926788806915283, 0.1283530741930008, 0.46703997254371643, -0.5766208171844482, -0.1560518443584442, -0.7606852054595947, -1.0668156147003174, -0.14501364529132843, -0.28594428300857544, 0.12490231543779373, -0.8042887449264526, -0.12293916195631027, 0.11233539134263992, 0.24983936548233032, 0.5448930263519287, 0.10775741934776306, 0.19841016829013824, 0.35172051191329956, 0.06365590542554855, 0.11476501077413559, 0.3412569463253021, -0.23259732127189636, -0.4119783043861389, -0.24000079929828644, 0.16919942200183868, -0.266950786113739, 0.7114332318305969, -0.34800368547439575, -0.14978985488414764, -0.24879829585552216, 0.20299243927001953, -0.2086564004421234, 1.046800971031189, 1.1849493980407715, 0.3655696213245392, 0.10331132262945175, 0.1407252699136734, 0.8595998287200928, -0.023366602137684822, -0.396484911441803, -0.3944583535194397, 0.6520034074783325, -0.3473135232925415, -0.3897768557071686, 0.2696436047554016, -0.24727031588554382, -0.27159830927848816, -1.0885004997253418, -0.441920667886734, 0.004232597537338734, -1.0076017379760742, -0.7446713447570801, 0.7274677157402039, -0.3241354823112488, -0.4840693771839142, 0.17752069234848022, -0.510329008102417, -0.7085496783256531, -0.030749088153243065, -0.9803498983383179, -0.001018042559735477, 0.20875634253025055, -0.2432854026556015, -0.6592066884040833, -0.2389911562204361, 0.9887778759002686, -0.10486543923616409, -0.46846458315849304, 0.19010286033153534, 0.06645787507295609, -0.265863299369812, 0.23531152307987213, -0.9558561444282532, 0.5528149604797363, -0.1666734367609024, -0.4195084869861603, 0.7611258625984192, 0.3194139301776886, 0.1903601735830307, -0.8382924199104309, -0.13100117444992065, -0.08726169914007187, -0.42137229442596436, 0.06377962231636047, -0.5633442997932434, -1.1847461462020874, -0.015098096802830696, 0.7879316210746765, -0.01983649469912052, 0.20021244883537292, -0.024100154638290405, -0.7176499366760254, -0.8463107943534851, -0.8836445212364197, 0.4987845718860626, 0.8246414661407471, -0.5281140208244324, -0.5671581029891968, -0.5978726148605347, 0.3033285439014435, -1.1533939838409424, -0.7153713703155518, -0.5501044392585754, 0.36965957283973694, -0.6281135082244873, 1.2774200439453125, -0.3074061870574951, 0.5522738695144653, 0.5245470404624939, 0.5438154935836792, -0.9793519973754883, -0.4263010621070862, -0.8416442275047302, 0.21843121945858002, 0.5015735626220703, 0.260307639837265, -0.6763458847999573, 0.580713152885437, 1.0635372400283813, 0.1548779308795929, -0.33633819222450256, -0.5719618201255798, -0.27815210819244385, 0.01086890697479248, -0.7745933532714844, 0.33994412422180176, -0.3360710144042969, 0.05404716357588768, 0.04843171685934067, 0.2963835299015045, 0.056860387325286865, 0.3725254535675049, -1.012131690979004, 0.2691754102706909, 0.09081385284662247, -0.03869430720806122, -0.6576761603355408, -0.28227466344833374, -0.7773826718330383, -0.39705753326416016, -1.0400673151016235, 0.0928768515586853, -0.9146237373352051, -0.462711900472641, 0.20724697411060333, -0.5791663527488708, 0.012104439549148083, 0.46356678009033203, -0.21580339968204498, -0.48387980461120605, -0.5057350397109985, -0.8805853128433228, 0.7174959182739258, 0.8212254047393799, -1.008426308631897, -0.14812453091144562, -0.01634456403553486, -0.24338260293006897, 0.17835454642772675, 0.9554591774940491, -0.7146657109260559, -0.8400903940200806, -0.9446284174919128, 0.7651748657226562, 0.10765641927719116, 0.07807900011539459, -1.1992629766464233, 1.3033990859985352, 0.09303086251020432, 0.062263112515211105, 0.1513831615447998, 0.10759229958057404, -0.9287137389183044, -0.31855615973472595, 0.5789191126823425, -0.9996320605278015, 0.27755388617515564, 0.18484385311603546, -0.6934633255004883, 0.03698624670505524, 0.12392393499612808, 0.06613670289516449, -1.1437885761260986, -0.7202408313751221, 0.4056677222251892, -0.9085113406181335, 0.23779018223285675, -0.1792837232351303, -0.4574146568775177, -1.1336783170700073, -0.17004051804542542, 0.1685308814048767, 0.45133358240127563, -0.4341476559638977, 0.7332906126976013, 0.4388781189918518, -1.2822433710098267, 0.458629846572876, 0.28284263610839844, 0.28856953978538513, -0.2896384596824646, 0.9495342373847961, -0.10532284528017044, -0.18166866898536682, -0.249799445271492, -0.32212623953819275, 0.767699658870697, -0.18303461372852325, -0.12925434112548828, 1.149564504623413, -0.04238075390458107, 0.10028214752674103, 0.8901627659797668, -0.568015456199646, -1.0458091497421265, 0.3005315065383911, -1.0027580261230469, -0.7068239450454712, -0.5493135452270508, 0.5679453015327454, 0.529992401599884, -0.4124457538127899, 0.3722236752510071, 0.04557277634739876, 0.44781002402305603, -0.3149033486843109, -0.34350699186325073, 0.7120980620384216, -0.22424596548080444, -0.47577062249183655, 1.009806752204895, 0.38080155849456787, -0.8667268753051758, -1.2399024963378906, -0.5705834031105042, -0.44806376099586487, -0.018412834033370018, 0.3008272051811218, -0.3903811275959015, -0.7940038442611694, 0.5168853402137756, 0.7376290559768677, 0.2686942517757416, -0.2854062020778656, -0.4656451940536499, -0.17623178660869598, 0.7364968657493591, 0.30715420842170715, -1.23158860206604, 0.00437459722161293, 0.9430072903633118, 1.3862937688827515, -0.548682451248169, 0.369128942489624, 0.07063746452331543, -0.5884809494018555, 1.2085245847702026, 0.898991048336029, -0.3999425172805786, 0.4583268463611603, -0.23515793681144714, 0.18528185784816742, 0.13895612955093384, -1.3342856168746948, -0.2500859797000885, 0.505760133266449, 1.116349458694458, 0.5565531849861145, -0.008129274472594261, 0.06057381257414818, 0.6112587451934814, 0.3438454866409302, 0.38430625200271606, 0.8039892315864563, 0.4793843924999237, -0.3743595480918884, -0.1763138622045517, 0.3215370178222656, 0.68177729845047, -0.41814184188842773, -0.12369855493307114, 0.8124324679374695, 0.744374692440033, 0.5767733454704285, 0.6379130482673645, 0.5448935031890869, -0.05148713290691376, 0.8666603565216064, -0.07620053738355637, 0.7223175764083862, -0.5550925135612488, -1.0478516817092896, -0.4159109592437744, -0.5661953687667847, -0.4724825918674469, -0.09829752892255783, -0.40117794275283813, -0.7206032276153564, -0.31482258439064026, 0.33395740389823914, 0.0945359393954277, 0.3041730225086212, 0.7275909185409546, 0.342665433883667, 0.7163558602333069, -0.16660930216312408, -0.7871468663215637, -0.8652958273887634, -0.7531368136405945, 0.014340756461024284, -0.5518763065338135, -0.5836211442947388, -0.5188093781471252, -0.16135349869728088, -0.6223909854888916]}, "authors": [{"authorId": "2350348", "name": "Kazuki Irie"}, {"authorId": "35328044", "name": "Imanol Schlag"}, {"authorId": "2258963332", "name": "R'obert Csord'as"}, {"authorId": "145341374", "name": "J. Schmidhuber"}], "references": [{"paperId": "97c943bda664004e6aded753abec22a0f4d20eef", "title": "The CLEAR Benchmark: Continual LEArning on Real-World Imagery"}, {"paperId": "c3112a62284b1f7b699b5aad3adb2d837f7f4e12", "title": "HyperTransformer: Model Generation for Supervised and Semi-Supervised Few-Shot Learning"}, {"paperId": "e528466e2aff981511d4ca6e063211297c0b4175", "title": "The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization"}, {"paperId": "86589b6286ef3c55b8b4fccfb41a3b30b7afdf61", "title": "Going Beyond Linear Transformers with Recurrent Fast Weight Programmers"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "2bb6dd038ee17a111323431f5900d32ae0aa6379", "title": "Meta-Learning Bidirectional Update Rules"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "76e3ad12881e7ab1c36318d8f8818eca3f828349", "title": "Meta Learning Backpropagation And Improving It"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "3a76603f03b45903bb030b2efd79984693625dc2", "title": "Meta-Learning through Hebbian Plasticity in Random Networks"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "ef5d57e30d21d0d816e3c178d468b42703f71809", "title": "Adaptive reinforcement learning through evolving self-modifying neural networks"}, {"paperId": "361850e0ec285528990c61235fc6c1e15cfd5ab6", "title": "Addressing Catastrophic Forgetting in Few-Shot Problems"}, {"paperId": "35172f0513d6a9fb9b1a40b7ad466da96a112d68", "title": "Meta-Baseline: Exploring Simple Meta-Learning for Few-Shot Learning"}, {"paperId": "8d814620a1ca77e745bc8a33b96b86148f2804fe", "title": "Leveraging Procedural Generation to Benchmark Reinforcement Learning"}, {"paperId": "b81d6c9138a51e7e109ec59d04f22f7186b3b7dc", "title": "TorchBeast: A PyTorch Platform for Distributed RL"}, {"paperId": "6c72c4ef7c76b4d64fa4c244ec38d70de053d97e", "title": "Torchmeta: A Meta-Learning library for PyTorch"}, {"paperId": "a513bb6e1967f5a31ad4f38954e66d4169b613e5", "title": "Metalearned Neural Memory"}, {"paperId": "7ee12d3bf8e0ce20d281b4550e39a1ee53839452", "title": "Risks from Learned Optimization in Advanced Machine Learning Systems"}, {"paperId": "146c231532d4e38de95e63368dcd09d0f8cea291", "title": "Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity"}, {"paperId": "b48f327d8f2515216ac19314a58292c43bb53422", "title": "Metalearning with Hebbian Fast Weights"}, {"paperId": "e6a83abec5cffb0bf1669f2f2c1efdf2b15cb171", "title": "TADAM: Task dependent adaptive metric for improved few-shot learning"}, {"paperId": "3504bc0739501220d07e8e3ecb4ad26a06fc50ad", "title": "RADMM: Recurrent Adaptive Mixture Model with Applications to Domain Robust Language Modeling"}, {"paperId": "249ac07c5b87f44b85500e2d26b68a7edb93e83d", "title": "Differentiable plasticity: training plastic neural networks with backpropagation"}, {"paperId": "16f7cceb805ac18a87ba8c9d9051ec0bcbbabe3b", "title": "Self in NARS, an AGI System"}, {"paperId": "80196cdfcd0c6ce2953bf65a7f019971e2026386", "title": "IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures"}, {"paperId": "2bdebf2fb0f5c21907fcaae6d87c7ba5811e778a", "title": "Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm"}, {"paperId": "fa9decd1395cc2f39e9921f870ebc8a8ec2bd08d", "title": "Dynamic Evaluation of Neural Sequence Models"}, {"paperId": "7e9c1e0d247b20a0683f4797d9ea248c3b53d424", "title": "A Simple Neural Attentive Meta-Learner"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "c889d6f98e6d79b89c3a6adf8a921f88fa6ba518", "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"}, {"paperId": "470d11b8ca4586c930adbbfc3f60bff08f2a0161", "title": "Meta Networks"}, {"paperId": "282a380fb5ac26d99667224cef8c630f6882704f", "title": "Learning to reinforcement learn"}, {"paperId": "29c887794eed2ca9462638ff853e6fe1ab91d5d8", "title": "Optimization as a Model for Few-Shot Learning"}, {"paperId": "954b01151ff13aef416d27adc60cd9a076753b1a", "title": "RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning"}, {"paperId": "c91ae35dbcb6d479580ecd235eabf98374acdb55", "title": "Using Fast Weights to Attend to the Recent Past"}, {"paperId": "235c08ccf3e4f0614cefd8901398a708d921f717", "title": "Growing Recursive Self-Improvers"}, {"paperId": "3904315e2eca50d0086e4b7273f7fd707c652230", "title": "Meta-Learning with Memory-Augmented Neural Networks"}, {"paperId": "be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6", "title": "Matching Networks for One Shot Learning"}, {"paperId": "f88a6f6fd6611543220482e6b3a5f379b7bf5049", "title": "Increasing the Action Gap: New Operators for Reinforcement Learning"}, {"paperId": "815c84ab906e43f3e6322f2ca3fd5e1360c64285", "title": "Human-level concept learning through probabilistic program induction"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "ebcea2d842d3d4e320500086aff0deb4cb4412ff", "title": "Efficient object localization using Convolutional Networks"}, {"paperId": "09843092ceaa229d657ecc8f629b54f1e57aa0c5", "title": "Singularity Hypotheses: A Scientific and Philosophical Assessment"}, {"paperId": "c9c0ad54afad21f3c778de7435fc83b9f8fe1017", "title": "Self-Programming: Operationalizing Autonomy"}, {"paperId": "11540131eae85b2e11d53df7f1360eeb6476e7f4", "title": "Learning to Forget: Continual Prediction with LSTM"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "7ee98330fb5969839d88bcabdb44d03848dc9d35", "title": "A \u2018Self-Referential\u2019 Weight Matrix"}, {"paperId": "61639af1a89c69094bcc0ed40fad752832b037c3", "title": "Reducing the Ratio Between Learning Complexity and Number of Time Varying Variables in Fully Recurrent Nets"}, {"paperId": "b20b5747c50766246dd76f4edb2eb6393f14613e", "title": "An 'introspective' network that can learn to run its own weight change algorithm"}, {"paperId": "32437ae95b6c70517a325bb14d2b9c33473fb96f", "title": "A neural network that embeds its own meta-levels"}, {"paperId": "bc22e87a26d020215afe91c751e5bdaddd8e4922", "title": "Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks"}, {"paperId": "add21b42c325bdbf145b536ee4bb66cb8cf1a59a", "title": "Learning algorithms and fixed dynamics"}, {"paperId": "2ae5a5507253aa3cada113d41d35fada1e84555f", "title": "An Efficient Gradient-Based Algorithm for On-Line Training of Recurrent Network Trajectories"}, {"paperId": "8001b80755bb8b189f3e1a51db8d108303b9fe7b", "title": "Fixed-weight networks can learn"}, {"paperId": "7826ff60d2dfb24d2af18c5bc565c357ef9db4c1", "title": "A stochastic version of the delta rule"}, {"paperId": "cd62c9976534a6a2096a38244f6cbb03635a127e", "title": "Phoneme recognition using time-delay neural networks"}, {"paperId": "56cbfcbfffd8c54bd8477d10b6e0e17e097b97c7", "title": "Connectionism and cognitive architecture: A critical analysis"}, {"paperId": "bef2ae523cd4447af687fae13bfbb606e4a4a5ca", "title": "A Formal Theory of Inductive Inference. Part II"}, {"paperId": "e7a2ffd26cd76e5b662ecb8624ecb3e177dbb8da", "title": "Pitfalls of Static Language Modelling"}, {"paperId": null, "title": "Livewired: The inside story of the ever-changing brain"}, {"paperId": null, "title": "For FC100, we applied 20% dropout after each max-pooling layer"}, {"paperId": "85d346297ec37a451d4500afad53fed8f281af92", "title": "Adaptive Switching Circuits"}, {"paperId": null, "title": "The original setting (Lake et al., 2015) splits these 1632 classes into 1200 for training and 432 for testing without validation"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": "9819b600a828a57e1cde047bbe710d3446b30da5", "title": "Recurrent neural network based language model"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": null, "title": "100 color image classes (600 images per class, each of size 32\u00d7 32) are split into train/valid/test classes of 60/20/20 (Oreshkin et al., 2018)"}, {"paperId": "501c889b848e32b95d1e8ffca3d754a5dc102f3a", "title": "The Logic of Intelligence"}, {"paperId": "402a5f749c99c75c98a626539553c2e4b5939c29", "title": "G\u00f6del Machines: Fully Self-referential Optimal Universal Self-improvers"}, {"paperId": null, "title": "Steps towards \u201cself-referential\u201d learning. Technical"}, {"paperId": null, "title": "Making the world differentiable: On using fully recurrent self-supervised neural networks for dynamic reinforcement learning and planning in non-stationary environments."}, {"paperId": "bdaec1b3eb9a8f7a2b296be009a148c35236f3ce", "title": "Evolutionary principles in self-referential learning, or on learning how to learn: The meta-meta-. hook"}, {"paperId": "d7d9d643a378b6fd69fff63d113f4eae1983adc8", "title": "Speculations Concerning the First Ultraintelligent Machine"}, {"paperId": "a6bcf0e9b5034c4c9cbea839baadd69a42b05cc1", "title": "Learning curves for stochastic gradient descent in linear feedforward networks"}]}