{"paperId": "0399533de2d1d21f456663d1bd5355c8b3c32a58", "title": "Unlearn What You Want to Forget: Efficient Unlearning for LLMs", "abstract": "Large language models (LLMs) have achieved significant progress from pre-training on and memorizing a wide range of textual data, however, this process might suffer from privacy issues and violations of data protection regulations. As a result, the ability to easily remove data related to individual users from such models while not deteriorating their predictive quality after the removal becomes increasingly important. To address these issues, in this work, we propose an efficient unlearning framework that could efficiently update LLMs without having to retrain the whole model after data removals, by introducing lightweight unlearning layers learned with a selective teacher-student objective into the transformers. In addition, we introduce a fusion mechanism to effectively combine different unlearning layers that learns to forget different sets of data to handle a sequence of forgetting operations. Experiments on classification and generation tasks demonstrate the effectiveness of our proposed methods compared to the state-of-the-art baselines.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "citationCount": 63, "influentialCitationCount": 5, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes an efficient unlearning framework that could efficiently update LLMs without having to retrain the whole model after data removals, by introducing lightweight unlearning layers learned with a selective teacher-student objective into the transformers."}, "embedding": {"model": "specter_v2", "vector": [0.15885500609874725, 0.9396427273750305, -0.5226047039031982, 0.1313299685716629, -0.46609798073768616, -0.15406307578086853, 0.727070689201355, 0.08558841049671173, -0.6647124290466309, 0.07259481400251389, 0.19278791546821594, -0.01361143495887518, 0.6752548217773438, 0.13667871057987213, -0.6508724093437195, 0.3866061270236969, -0.7485978007316589, 0.3579272925853729, 0.2792086899280548, -0.24648691713809967, -0.3829803168773651, -0.7261263132095337, -1.2171303033828735, 0.3189917206764221, 0.6778275966644287, 0.2969008982181549, 0.05396789684891701, 0.7459733486175537, -0.4813765585422516, 0.5183723568916321, 0.6048610806465149, -0.6468831300735474, 0.04420915246009827, 0.18143653869628906, -0.3731015622615814, 0.12413233518600464, 0.3704746961593628, -0.6389195322990417, -0.3919966220855713, 0.45918339490890503, -0.4139883518218994, 0.31995218992233276, 0.5290730595588684, -0.5829866528511047, -0.439603328704834, 0.9403449892997742, 0.32019245624542236, 0.4847767949104309, -0.29528379440307617, -0.7224350571632385, 1.0688695907592773, -1.9332231283187866, 0.17387384176254272, 1.4856197834014893, 0.5870615839958191, 0.5515563488006592, -0.29646262526512146, -0.7964848279953003, 0.7153885364532471, -0.07811889797449112, -0.8405168652534485, -0.4943433105945587, -0.42649877071380615, -0.1826247125864029, 1.5803256034851074, -0.42571502923965454, -0.2950471043586731, 0.5511949062347412, -0.060450389981269836, 1.8918583393096924, -0.37116900086402893, -0.8022592067718506, -0.7247986793518066, 0.4913177490234375, 0.11179427057504654, 1.238030195236206, -0.09295462816953659, 0.1841125339269638, -0.8319617509841919, -0.07399941235780716, 0.43563851714134216, 0.3015696406364441, -0.015989182516932487, -0.3498460352420807, 0.26165321469306946, 0.6799349784851074, 0.21866819262504578, 1.0106861591339111, 0.1449577361345291, 0.5948238968849182, 0.27001404762268066, 0.42368775606155396, 0.39691227674484253, 0.20627707242965698, -0.2897490859031677, 0.4468526542186737, -0.9773715138435364, 0.11344906687736511, -0.27112606167793274, 1.0670201778411865, -0.0047677913680672646, 0.09603778272867203, -0.8292034268379211, 0.2980557680130005, 1.1485110521316528, -0.06126461178064346, 0.9358382821083069, -0.2409275770187378, 0.280751496553421, -0.46086257696151733, 0.16908107697963715, -0.42346763610839844, -0.07457783073186874, -0.24150796234607697, -0.8418306708335876, -1.2581607103347778, -0.6621735692024231, 0.18630893528461456, -0.8964139819145203, 0.919741690158844, -0.486400306224823, 0.3527216911315918, -0.15356683731079102, 0.07705741375684738, 0.5346245169639587, 0.4493791460990906, 0.3185258209705353, -0.2761441469192505, 0.3634384870529175, -0.8517885804176331, -0.7207463383674622, -1.1840593814849854, 0.8377324342727661, -0.12015318125486374, 0.21908333897590637, -0.15960624814033508, -1.0715185403823853, -1.0863933563232422, -0.8734329342842102, -0.312147855758667, -0.6780461072921753, 0.550439178943634, 1.079666256904602, 0.40413233637809753, -0.7711957097053528, 1.1573511362075806, -0.30913224816322327, -0.039330556988716125, 0.3124767243862152, 0.21358075737953186, 0.17478807270526886, -0.6551850438117981, -1.3124009370803833, 0.2548474073410034, 0.34444642066955566, -0.6825951337814331, -0.5105246305465698, -0.5946970582008362, -1.078099012374878, -0.2899075150489807, 0.35556989908218384, -0.4399796426296234, 1.5607329607009888, -0.2232057750225067, -0.9127564430236816, 0.5270859599113464, -0.41268402338027954, 0.23902447521686554, 0.6353906989097595, -0.48611029982566833, -0.475046306848526, -0.9194006323814392, -0.3523828983306885, 0.12541517615318298, 0.7932131886482239, -0.43961137533187866, -0.28317588567733765, 0.3358616530895233, -0.5042508244514465, -0.30306291580200195, -0.619795024394989, 0.10493198037147522, -0.5754066109657288, -0.5281716585159302, 0.18675822019577026, 0.8252387642860413, 0.34820228815078735, -0.4507194757461548, -0.15466982126235962, -1.1522520780563354, 0.9909291863441467, -0.22901853919029236, 1.2770463228225708, -0.7993513941764832, -0.8520507216453552, -0.19365371763706207, 0.0853961780667305, 0.3613511919975281, -1.2476754188537598, 0.6249909996986389, -0.3023476302623749, 0.4726395308971405, 0.061195921152830124, -1.606689453125, 0.06578483432531357, -0.35905322432518005, -0.8418364524841309, -0.37831220030784607, 0.15142473578453064, 1.058415412902832, -1.2967365980148315, 0.4255093038082123, -0.22062544524669647, 0.43350091576576233, -0.9784834384918213, 1.4022018909454346, -0.4841781556606293, 0.07469882816076279, -0.017686791718006134, -0.1319892704486847, 0.26161476969718933, 0.005852853879332542, 0.27188074588775635, -0.12798257172107697, 0.18050122261047363, 0.24816466867923737, -0.32651686668395996, 1.3057835102081299, -0.593823254108429, 0.3195612132549286, -0.3760705590248108, -0.2621229588985443, 0.03668249025940895, 0.7203260064125061, -0.3933054208755493, -0.0798845961689949, 0.22584542632102966, 0.46656909584999084, -0.9562495350837708, 0.15373291075229645, 1.1732776165008545, 0.35815367102622986, -0.14315147697925568, 0.45201921463012695, 0.9186457991600037, -0.23184573650360107, 0.32770365476608276, 0.5719135999679565, 0.6024941802024841, 0.3754693567752838, 0.3568178415298462, 0.5615710616111755, 0.5457282066345215, -1.2866569757461548, -0.14751699566841125, 0.7608969211578369, 0.9821439385414124, 0.7476798295974731, -0.014522339217364788, -0.657681405544281, 0.03334631025791168, -0.20155024528503418, 1.0174394845962524, 1.7528738975524902, -0.48409709334373474, -0.37941741943359375, -0.448486328125, -0.6656692624092102, 0.05585658922791481, 0.5462954640388489, -0.47376129031181335, -0.6796367168426514, -0.12878523766994476, -1.1379436254501343, 0.5295619964599609, 0.18527238070964813, 0.7340846061706543, -0.42779168486595154, 0.24127016961574554, -0.03313760459423065, 0.32609015703201294, -0.34612610936164856, -0.7216320633888245, 0.2880701720714569, -0.7760416269302368, -0.07817257940769196, 0.1314125806093216, -0.10570447146892548, 0.4567142426967621, -0.6108102202415466, 0.9944836497306824, 0.01779465191066265, -0.25464922189712524, 0.3620665371417999, 0.4677831530570984, -0.9360021948814392, -0.7211329936981201, 0.3797128200531006, 0.4268069267272949, -0.02120891399681568, 0.40483468770980835, 0.6955877542495728, 0.5324795246124268, -0.2380564659833908, -0.8106129169464111, 0.0059509435668587685, 0.16326560080051422, -0.045709751546382904, 0.7525685429573059, 0.058151766657829285, 0.3340471088886261, -1.9101239442825317, 0.9808934330940247, -0.13685302436351776, -0.14786596596240997, 0.44552263617515564, -0.8769063949584961, -0.19894510507583618, 0.59425950050354, -0.9233293533325195, -0.49557432532310486, -1.020920991897583, 0.47534507513046265, -0.23968148231506348, 0.16436469554901123, 0.37586116790771484, 0.3027789294719696, 0.13953045010566711, -0.093500055372715, 0.39114707708358765, 0.1713370978832245, -0.5918538570404053, 0.5946047306060791, -0.8015256524085999, 0.4526943266391754, 0.13846847414970398, 0.6043661832809448, -0.34179461002349854, -0.55284583568573, -0.46415263414382935, -0.8303397297859192, -0.39845436811447144, -0.46588239073753357, -0.11352557688951492, -0.7343088984489441, -0.8006673455238342, -0.3715364336967468, 0.09798911213874817, -1.0293909311294556, -0.2522139251232147, 0.15520809590816498, -0.4169155955314636, 0.06140979006886482, -1.0990264415740967, -1.1637051105499268, -0.7930388450622559, -0.44182994961738586, -0.7207821011543274, 0.16119840741157532, -0.027759436517953873, -0.44089558720588684, -0.9392604827880859, -0.05178261548280716, -0.36242246627807617, 1.061856985092163, -0.6906017065048218, 0.8815621137619019, 0.03609425947070122, -0.31619638204574585, -0.5794597864151001, 0.2909528911113739, 0.5448208451271057, 0.08321628719568253, -0.10915599018335342, -1.1767038106918335, -0.5475265979766846, -0.1883040964603424, -0.41514110565185547, 0.5351845026016235, 0.03408484160900116, 0.8575772047042847, -0.2395111620426178, -0.7136201858520508, 0.28218385577201843, 1.5232622623443604, -0.8519166707992554, -0.18104204535484314, -0.1977211982011795, 1.150578260421753, -0.0748840793967247, -0.24013830721378326, 0.5653789043426514, 0.26577937602996826, -0.1560066044330597, 0.14070919156074524, -0.11501846462488174, -0.026895901188254356, -1.0287895202636719, 0.6559176445007324, 1.6727348566055298, 0.0728064700961113, -0.12592341005802155, -0.8588606119155884, 0.5027613043785095, -1.277562141418457, -0.3126039206981659, 0.8951196074485779, 1.1043899059295654, 0.7955608367919922, -0.40081456303596497, -0.57293701171875, -0.23653799295425415, 0.15798164904117584, 0.23719628155231476, -0.6110073924064636, -0.46041780710220337, 0.2882935106754303, 0.6185141801834106, 0.37044069170951843, 0.875892162322998, -0.1997704803943634, 0.6672289371490479, 14.349870681762695, 0.8201003670692444, 0.0890970304608345, 0.9071651697158813, 0.6084574460983276, 0.056068554520606995, -0.5154110789299011, -0.3407294750213623, -1.4156829118728638, -0.517246663570404, 0.9667685031890869, 0.20734429359436035, 0.5683961510658264, 0.017255796119570732, -0.1761321723461151, 0.14910933375358582, -0.5707972049713135, 0.6668000817298889, 0.8743798136711121, -0.9938943982124329, 0.9877559542655945, -0.034546785056591034, 0.46148648858070374, 0.3369563817977905, 1.1122734546661377, 1.1809213161468506, 0.3459293842315674, -0.49946358799934387, 0.603537380695343, 0.7361616492271423, 1.0035110712051392, -0.22290365397930145, 0.7264441847801208, 0.6833644509315491, -0.6652920842170715, -0.17146936058998108, -0.6197764873504639, -0.978264570236206, -0.11991370469331741, 0.19564811885356903, -0.7603663802146912, -0.31749826669692993, -0.37122392654418945, 0.9634755253791809, -0.5831717848777771, 0.23265306651592255, -0.3107815384864807, 0.5945518016815186, 0.39694270491600037, 0.46801677346229553, 0.005881247576326132, 0.5289469361305237, 0.1457715928554535, -0.1894223392009735, 0.3144671320915222, -0.17962270975112915, -0.09218881279230118, 0.354214072227478, -0.9246642589569092, -0.03860537335276604, -0.44621536135673523, -0.32234978675842285, -0.17945922911167145, 0.5540183186531067, 0.9682385921478271, 0.2787371575832367, -0.5759771466255188, 0.5540340542793274, 0.8045949339866638, 0.1501871794462204, 0.16756926476955414, -0.023465650156140327, 0.020124945789575577, 0.18870459496974945, -0.17680300772190094, 0.7255635857582092, 0.1719885766506195, -0.6804578304290771, -0.7535507678985596, -0.30467602610588074, 0.4776303470134735, -0.5810409188270569, -0.9990795850753784, 0.8025920391082764, -0.4889789819717407, -0.6135233640670776, -0.1250256896018982, -0.48870784044265747, -0.15525195002555847, 0.5435658097267151, -1.3889964818954468, -0.8622536659240723, 0.4991280734539032, -0.5274891257286072, -0.5727295875549316, -0.41882970929145813, 1.2430418729782104, 0.09221580624580383, -0.335333913564682, 0.38515257835388184, 0.3633003532886505, -0.11906259506940842, 0.2410939633846283, -0.7335205078125, 0.587468683719635, 0.2416842132806778, 0.0157517958432436, 0.6059215068817139, 0.10251618921756744, -0.04013892263174057, -0.6686344146728516, -0.5742332935333252, 1.1906023025512695, -1.2042258977890015, -0.8548880815505981, -0.6708903908729553, -1.071614146232605, 0.9436296820640564, 0.604199230670929, -0.4608466327190399, 0.46903982758522034, 0.37444183230400085, -0.6044241786003113, -0.23011763393878937, -0.8815599679946899, 0.012518946081399918, 0.164997398853302, -0.7034114003181458, -0.2780441343784332, 0.0589015819132328, 0.1909417062997818, -0.9845435619354248, -0.30084478855133057, -0.5183653235435486, -0.2772597074508667, -0.0673094391822815, 0.8825863599777222, -0.3396890163421631, 0.3094264566898346, 0.8364912867546082, 0.44182494282722473, -1.2868634462356567, -0.16323991119861603, -0.957896888256073, -0.12657180428504944, 0.5454952120780945, 0.6799461841583252, -0.37200555205345154, 0.005165466573089361, 0.8652773499488831, 0.6206246614456177, -0.21077485382556915, -0.21822142601013184, -0.2725088894367218, 0.28289347887039185, -0.5195639133453369, 0.4411981999874115, 0.14051590859889984, -0.11325772851705551, 0.23171168565750122, 0.18521223962306976, 0.48644915223121643, 0.07986968755722046, -1.0596976280212402, 0.4132229685783386, -0.4027652442455292, 0.02605454996228218, -0.25459590554237366, 0.05981073155999184, -1.1109437942504883, -0.0247501228004694, -1.3875480890274048, -0.0872565507888794, -0.7470070123672485, -0.23811310529708862, 0.1358981728553772, -0.3478953540325165, 0.29005497694015503, -0.1141166239976883, -0.40802642703056335, -0.5672355890274048, -0.7197403907775879, -0.5224109292030334, 0.8246471881866455, 1.0144869089126587, -0.6097951531410217, 0.18633593618869781, -0.026994001120328903, -0.04945472255349159, 0.31086671352386475, 0.3414135277271271, -0.6702287197113037, -1.1066159009933472, -1.543893575668335, 0.34463995695114136, -0.2677377462387085, -0.17825286090373993, -0.4628901779651642, 0.7174695134162903, 0.4723673164844513, 0.2899682819843292, -0.025821255519986153, 0.15496596693992615, -1.0120922327041626, -0.4062182605266571, 0.3542071580886841, -0.6642042398452759, 0.20853860676288605, 0.3186284899711609, -0.48114773631095886, -0.5158190131187439, 0.32106807827949524, -0.01740821823477745, -1.308645248413086, -0.6597943902015686, 0.9014178514480591, -0.4303120970726013, 0.16427969932556152, -0.5082147717475891, 0.44749540090560913, -0.7421197891235352, -0.6534984111785889, 0.02441748045384884, 0.35643789172172546, -0.32674580812454224, 1.1780964136123657, 0.6726850867271423, -1.345128059387207, 0.05709100887179375, 0.6689009666442871, 0.023114483803510666, 0.0885298028588295, 0.6096242070198059, 0.2956750988960266, 0.008185630664229393, 0.41967344284057617, 0.6133845448493958, 0.7548213005065918, -0.7726311087608337, 0.12770232558250427, 0.6513916850090027, -0.7768837809562683, 0.0429515540599823, 1.2120726108551025, -0.39820149540901184, -1.3426949977874756, 0.26517364382743835, -1.372823715209961, -0.484096884727478, -0.08985342085361481, 0.915690541267395, -0.015190468169748783, 0.19868998229503632, 0.007761955726891756, -0.15955394506454468, -0.22007933259010315, -0.46222662925720215, -0.20745393633842468, 1.1137055158615112, -0.4190934896469116, -0.4014282524585724, 1.0998797416687012, 0.7760645747184753, -0.424896240234375, -0.793212890625, -0.9556717872619629, -0.2268732637166977, -0.28719499707221985, 0.3687998652458191, -0.41168317198753357, -0.6489781141281128, 0.5404356122016907, 0.3822595179080963, 0.06695842742919922, -0.09444106370210648, -0.3817175030708313, 0.3450610339641571, 0.5011653304100037, 0.18025963008403778, -0.9473451972007751, -0.38159045577049255, 1.2608420848846436, 1.3843612670898438, -1.076761245727539, 0.3256092071533203, -0.09984167665243149, -0.7219721078872681, 0.8887038230895996, 0.3879287838935852, 0.2738673686981201, 0.9803785085678101, -0.5150253772735596, 0.009525956586003304, 0.5755619406700134, -1.2457143068313599, -0.09874608367681503, 1.010419487953186, 1.04848313331604, 1.294189214706421, 0.3092488944530487, 0.2351795732975006, 1.2871097326278687, 0.38789406418800354, 0.42122775316238403, 0.8024858832359314, 0.6063814163208008, -0.22951312363147736, -0.49173325300216675, 0.22241519391536713, 0.8761723637580872, -0.5186424255371094, -0.5899614095687866, 0.2130223959684372, 0.5294697880744934, 0.6397889256477356, 0.39091014862060547, 0.39801621437072754, 0.02623150311410427, 0.5947695374488831, 0.5852383375167847, 0.6163983941078186, -0.9669189453125, -0.2900845408439636, -0.5268548727035522, -0.9149763584136963, 0.1747892200946808, -0.046448808163404465, -0.6435837745666504, -0.23810578882694244, -0.2704879641532898, 0.43385767936706543, -0.029707029461860657, -0.21457049250602722, 1.1822024583816528, 0.32095634937286377, 0.43146055936813354, -0.4015222191810608, -0.06779986619949341, -0.39351189136505127, -1.2227404117584229, -0.5322442054748535, -0.16350224614143372, 0.2063838243484497, -0.3942338228225708, -0.22521819174289703, -0.17615832388401031]}, "authors": [{"authorId": "47739850", "name": "Jiaao Chen"}, {"authorId": "2263629011", "name": "Diyi Yang"}], "references": [{"paperId": "546d0624adfc6e18fb87d8cc77e7705bb9ea7445", "title": "LIMA: Less Is More for Alignment"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "873a581320d928249609d3c07229d5af182a379c", "title": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver?"}, {"paperId": "220ddeb4dc43bc922289fec8b1b60d7226068b20", "title": "Parameter-Efficient Fine-Tuning Design Spaces"}, {"paperId": "e65b346d442e9962a4276dc1c1af2956d9d5f1eb", "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions"}, {"paperId": "ccbb76dc7996f370043b34e32844b1b18a586227", "title": "Privacy Adhering Machine Un-learning in NLP"}, {"paperId": "91fb2254c5942048425e642c8a6c8d400006150e", "title": "Knowledge Unlearning for Mitigating Privacy Risks in Language Models"}, {"paperId": "6c46b7b401be5ada79f00b36cb8e5b41286ae2aa", "title": "Measuring Forgetting of Memorized Training Examples"}, {"paperId": "ab0e3d3e4d42369de5933a3b4c237780b41c0d77", "title": "Solving Quantitative Reasoning Problems with Language Models"}, {"paperId": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large Language Models are Zero-Shot Reasoners"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "f4df78183261538e718066331898ee5cad7cad05", "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "9286ac6e9b1aacd7d93496eb4615ae7678876d2a", "title": "Fast Model Editing at Scale"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "56874f9aef515902c5a49d84d10f629f8dcd5f40", "title": "Differentially Private Fine-tuning of Language Models"}, {"paperId": "6a758ada5c48a2ae48d1392d12ce4f4e1977e0dd", "title": "Large Language Models Can Be Strong Differentially Private Learners"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "9ba50f992ccd92f428503ea6246157260a26cd77", "title": "Do Prompt-Based Models Really Understand the Meaning of Their Prompts?"}, {"paperId": "2cbf8688cbaddb28eac94fafb01251178f664dc7", "title": "Large-Scale Differentially Private BERT"}, {"paperId": "4566c0d22ebf3c31180066ab23b6c445aeec78d5", "title": "Deduplicating Training Data Makes Language Models Better"}, {"paperId": "dc2699529f7980426e67dd80dd61adf12e2e595a", "title": "Entailment as Few-Shot Learner"}, {"paperId": "2c871df72c52b58f05447fcb3afc838168d94505", "title": "Knowledge Neurons in Pretrained Transformers"}, {"paperId": "89e83cf5f3ee0d0f42a12b7576b49e1d10605ae1", "title": "Remember What You Want to Forget: Algorithms for Machine Unlearning"}, {"paperId": "df7d26339adf4eb0c07160947b9d2973c24911ba", "title": "Extracting Training Data from Large Language Models"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "303fbc9cac7f963f4334510682a300eb5e37977f", "title": "Approximate Data Deletion from Machine Learning Models: Algorithms and Evaluations"}, {"paperId": "4f03e69963b9649950ba29ae864a0de8c14f1f86", "title": "K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters"}, {"paperId": "8e58dc63817a2a26e5a2ddad38d8b1d19d1c3795", "title": "Machine Unlearning"}, {"paperId": "f9700e31a1d0ae34d4571ab056dfb268c1543349", "title": "SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization"}, {"paperId": "c956d133b78e0d9b20885593809f0b636ce34093", "title": "Eternal Sunshine of the Spotless Net: Selective Forgetting in Deep Networks"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "263210f256603e3b62476ffb5b9bbbbc6403b646", "title": "What do Neural Machine Translation Models Learn about Morphology?"}, {"paperId": "e9a986c8ff6c2f381d026fe014f6aaa865f34da7", "title": "Deep Learning with Differential Privacy"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "70fda5147aedd42c64143a464117b5ffde18a2e4", "title": "Differential Privacy: A Survey of Results"}, {"paperId": "5e04e20d9c550fc1cef1f1f86b30aadf0492fbac", "title": "Efficient Model Updates for Approximate Unlearning of Graph-Structured Data"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "2022. Continual learning and private unlearning"}, {"paperId": null, "title": "2023. Survey of hallucination in natural language generation"}, {"paperId": null, "title": "2022. Human-in-the-loop abstractive dialogue"}, {"paperId": null, "title": "2022. Holistic evaluation of language models"}]}