{"paperId": "b695d8e4edf66d7aa7a049cfb48038e35b0845b1", "title": "EdgeTran: Co-designing Transformers for Efficient Inference on Mobile Edge Platforms", "abstract": "Automated design of efficient transformer models has recently attracted significant attention from industry and academia. However, most works only focus on certain metrics while searching for the best-performing transformer architecture. Furthermore, running traditional, complex, and large transformer models on low-compute edge platforms is a challenging problem. In this work, we propose a framework, called ProTran, to profile the hardware performance measures for a design space of transformer architectures and a diverse set of edge devices. We use this profiler in conjunction with the proposed co-design technique to obtain the best-performing models that have high accuracy on the given task and minimize latency, energy consumption, and peak power draw to enable edge deployment. We refer to our framework for co-optimizing accuracy and hardware performance measures as EdgeTran. It searches for the best transformer model and edge device pair. Finally, we propose GPTran, a multi-stage block-level grow-and-prune post-processing step that further improves accuracy in a hardware-aware manner. The obtained transformer model is 2.8$\\times$ smaller and has a 0.8% higher GLUE score than the baseline (BERT-Base). Inference with it on the selected edge device enables 15.0% lower latency, 10.0$\\times$ lower energy, and 10.8$\\times$ lower peak power draw compared to an off-the-shelf GPU.", "venue": "arXiv.org", "year": 2023, "citationCount": 2, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2303.13745", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes a framework, called ProTran, to profile the hardware performance measures for a design space of transformer architectures and a diverse set of edge devices and proposes GPTran, a multi-stage block-level grow-and-prune post-processing step that further improves accuracy in a hardware-aware manner."}, "embedding": {"model": "specter_v2", "vector": [0.12699179351329803, -0.04313411936163902, -1.3509894609451294, 0.5551390647888184, -0.17821337282657623, 0.08950775861740112, 0.13029839098453522, -0.3813515901565552, 0.024549558758735657, -0.5120123624801636, 0.3318190574645996, -0.6271911263465881, 0.23858937621116638, -0.2561490535736084, -0.23536396026611328, 0.5475128889083862, -1.0435396432876587, 0.14688439667224884, 0.09945276379585266, -0.06445278227329254, 0.22898779809474945, -0.10194841772317886, -1.3465301990509033, 0.19635197520256042, 0.5016403198242188, 1.5007188320159912, -0.44464635848999023, 1.1541297435760498, -0.17980989813804626, 0.5492433309555054, 0.7466327548027039, 0.04998667910695076, 0.17170359194278717, 0.4432622492313385, 0.12020210176706314, -0.27129894495010376, 0.07157491892576218, -0.792749285697937, -0.27773046493530273, 0.5240726470947266, 0.36262834072113037, -0.326504111289978, 0.17884646356105804, -1.3621809482574463, 0.2706897556781769, 0.3401222825050354, 0.14237089455127716, 0.826884925365448, -0.7977442741394043, -0.773697555065155, 1.1073205471038818, -1.3756693601608276, -0.1051969900727272, 0.5723689794540405, 0.47531288862228394, -0.1499386429786682, -0.21055635809898376, -0.2760588824748993, 0.019939610734581947, 0.008289316669106483, -0.9438592791557312, -1.0177068710327148, 0.08707039058208466, 0.10878708213567734, 1.7568250894546509, -0.15975745022296906, -0.2531502842903137, 0.37314626574516296, 0.4071340262889862, 1.2667194604873657, 0.23923276364803314, -0.864713191986084, 0.5404842495918274, -0.4925622344017029, 0.19112704694271088, 0.7715490460395813, 0.3039146959781647, 0.017119087278842926, -1.2749234437942505, -0.6241195201873779, 0.24676689505577087, 0.10217410326004028, 0.6494590640068054, -0.3665086030960083, 0.16569682955741882, 0.30361029505729675, 0.20258034765720367, 0.3347989320755005, -0.2521689832210541, 1.0724267959594727, 0.9001863598823547, 0.11770278215408325, -0.18482829630374908, 0.03390791639685631, -0.09559611976146698, -0.09787419438362122, -1.3188350200653076, -0.4167309105396271, 0.36835041642189026, 1.164817452430725, -0.5746964812278748, 0.3698735535144806, -0.7381590604782104, -0.3895619511604309, 0.9308933615684509, -0.09309879690408707, -0.21391412615776062, -0.3719669580459595, 0.15468251705169678, -0.3549346625804901, 0.17264986038208008, -0.15195703506469727, -0.13235078752040863, -0.39106056094169617, -1.1221615076065063, -0.45191627740859985, -1.090637445449829, 0.06509421020746231, -0.4583461284637451, -0.13281789422035217, -0.5422338843345642, 0.7735875248908997, 0.00983370840549469, 0.03688526898622513, 0.6709877848625183, 0.18761655688285828, -0.3645751476287842, 0.2344534546136856, 0.9315474629402161, -1.7772403955459595, -0.3210064172744751, -1.0154820680618286, 0.42528608441352844, -0.7562950849533081, -0.09484653174877167, -0.023654896765947342, -1.2203340530395508, -0.8518181443214417, -1.084366798400879, 0.24231456220149994, -0.31197649240493774, 0.40570005774497986, 1.1766126155853271, 0.48466867208480835, -1.3522006273269653, 0.358517050743103, -0.7758938074111938, 0.11292237043380737, 0.13315321505069733, 0.692012369632721, 1.0088589191436768, -0.04636147990822792, -0.45345035195350647, -0.24066883325576782, -0.13296222686767578, -0.980948805809021, -0.27785494923591614, -0.7855552434921265, -0.7467635869979858, 0.2545294463634491, 0.47697481513023376, -0.9148719906806946, 0.6860397458076477, 0.26604217290878296, -1.0502420663833618, 0.5534429550170898, -0.04882615804672241, 0.18955561518669128, 0.08442238718271255, -0.25914865732192993, -0.7766123414039612, -0.41529732942581177, -0.13100028038024902, 0.093544602394104, 0.6551629900932312, -0.1324198842048645, -0.3289404809474945, 0.2070733606815338, -0.09887512773275375, 0.00864160992205143, -0.08543042093515396, 1.0336503982543945, -0.7667462825775146, 0.059375204145908356, -0.12830331921577454, 0.5368613600730896, -0.48966825008392334, -0.0202677883207798, -0.39213189482688904, -0.18467365205287933, 0.8557578325271606, 0.18983222544193268, 1.5267990827560425, -0.6833932399749756, -0.9295689463615417, 0.31994950771331787, 0.30060291290283203, -0.0927695780992508, 0.015360645018517971, 0.23953789472579956, -0.06403800845146179, -0.08741255849599838, 0.5658391118049622, -0.4381352961063385, 0.1748250424861908, -0.7633274793624878, -0.47792473435401917, -0.4462831914424896, -0.5763807892799377, 0.9420393109321594, -0.44572553038597107, 0.20985937118530273, -0.12307602912187576, 0.5520251989364624, -1.1286991834640503, 0.9180929064750671, -0.09499679505825043, -0.4106205701828003, -0.23327291011810303, 0.3711094260215759, 0.20764826238155365, -0.9503307938575745, 0.5034069418907166, -0.4977872669696808, 0.07946576923131943, 0.2499973624944687, -0.45004603266716003, 1.1838620901107788, -1.0599864721298218, 0.2753434181213379, 0.4623364210128784, -0.21161627769470215, 0.2924976348876953, 0.06118961051106453, 0.06604325771331787, -0.5518767237663269, 0.8090812563896179, 0.6966242790222168, -0.34697261452674866, 0.588553786277771, 1.1161457300186157, 1.6417635679244995, -0.5892548561096191, 0.4513286054134369, -0.06144179776310921, 0.22547750174999237, 0.24199847877025604, -0.12854711711406708, 1.1068648099899292, 0.35070356726646423, 0.29136186838150024, -0.619875431060791, 0.3268372118473053, -1.1926848888397217, -0.17425362765789032, 0.37081828713417053, 0.4996265172958374, 0.11687655746936798, 0.6264598965644836, -0.542678952217102, -0.35481831431388855, -0.3910197913646698, 0.40439334511756897, 1.4063247442245483, 0.02188529260456562, -0.5074834823608398, -0.866041898727417, -0.3906582295894623, -0.47571128606796265, 0.01775069162249565, 0.09287067502737045, -0.11401019990444183, -0.27355819940567017, -1.1190459728240967, 0.7952666878700256, 0.6284254193305969, 1.2675877809524536, -0.24269165098667145, -1.2726202011108398, -0.6120163798332214, 0.5163137912750244, -0.8925312757492065, -0.48587530851364136, 0.5809657573699951, -0.6545761823654175, 0.12689270079135895, 0.38849806785583496, -0.23018938302993774, 0.17828625440597534, -0.4643556773662567, 1.3204901218414307, 0.15491633117198944, -0.40616941452026367, -0.012451582588255405, 0.3759094774723053, -0.07743757218122482, -0.41340407729148865, 0.18334238231182098, -0.23832492530345917, -0.4494386315345764, 0.36515599489212036, -0.046675898134708405, -0.044908057898283005, 0.21482938528060913, -0.17226924002170563, -0.0044364724308252335, 0.20251236855983734, 0.10851789265871048, 0.49209845066070557, -0.027568325400352478, -0.3886905014514923, -0.6626625061035156, 0.7767853140830994, 0.10197009146213531, -0.6043563485145569, 0.012904803268611431, -0.7827703952789307, -0.10898195952177048, 0.770404040813446, -0.6565626263618469, 0.32764551043510437, -1.4617513418197632, 0.2362547218799591, -0.6786007285118103, 0.28685617446899414, -0.6751219034194946, -0.10941825807094574, -0.3578851819038391, 0.34043121337890625, 0.43577802181243896, -0.011913972906768322, 0.5001657605171204, 0.11040546000003815, -0.6393606662750244, 0.1404411643743515, -0.37222737073898315, -0.26906904578208923, 0.08858278393745422, 0.23033200204372406, -0.36382514238357544, -0.22351931035518646, 0.0641564205288887, 0.2766849100589752, -0.20445507764816284, -0.22127960622310638, -0.7174125909805298, -0.7719518542289734, -0.35585662722587585, -0.847723662853241, -0.5759871602058411, 0.5757706761360168, -0.48913878202438354, -0.6022101640701294, -1.483791470527649, -1.1420453786849976, -0.3214736878871918, -1.5232963562011719, -1.849004864692688, 0.7935055494308472, 0.09901238232851028, -0.579863965511322, -0.5206464529037476, -0.8379555940628052, -0.6860452890396118, 1.248331069946289, -0.33164167404174805, 0.5777624845504761, -0.036320675164461136, -0.7500207424163818, 0.30695250630378723, -0.23470517992973328, -0.23815390467643738, -0.5373519062995911, 0.3201795220375061, -0.6115806102752686, 0.21391786634922028, -0.46515655517578125, 0.2959579825401306, -0.23650842905044556, 0.4570683240890503, 1.3779866695404053, 0.26755291223526, -0.9471600651741028, 0.7889643907546997, 1.5394667387008667, -0.6474900245666504, 0.4172590374946594, 0.33076784014701843, 0.8520520329475403, -0.541348934173584, 0.1411844938993454, 1.0196644067764282, 0.006689769681543112, 0.7939573526382446, 0.20347152650356293, -0.3953092396259308, 0.10251270979642868, -0.015099158510565758, 0.6452813744544983, 1.3548818826675415, 0.4830363094806671, -0.048930052667856216, -0.6733769178390503, 0.6410340070724487, -1.368848443031311, 0.08868706226348877, 0.5703243613243103, 1.086417555809021, -0.23807020485401154, 0.40510183572769165, 0.09505875408649445, 0.28050747513771057, 0.5626869797706604, 0.25083979964256287, -0.5084071755409241, -1.1659530401229858, 0.6473554372787476, 1.1478315591812134, 0.8352383971214294, 0.38750025629997253, 0.20132572948932648, 0.2024778574705124, 14.546910285949707, 1.493364691734314, 0.033789291977882385, 0.5392294526100159, 0.9285638332366943, 0.46821844577789307, -0.2193523645401001, 0.13849838078022003, -1.4847066402435303, 0.577390193939209, 1.8090035915374756, -0.1899404525756836, 0.26118433475494385, 0.5405948162078857, -0.16477340459823608, -0.18149666488170624, -0.6481223702430725, 0.6914187669754028, 0.570763885974884, -1.3801510334014893, 0.003908343613147736, 0.49459120631217957, 0.22512465715408325, 0.32370439171791077, 0.6805211901664734, 0.5559583902359009, 0.5102258920669556, -0.4646904468536377, 0.17706678807735443, -0.21120882034301758, 1.3707367181777954, -1.0991814136505127, 0.707360029220581, 0.1478213667869568, -1.066723108291626, 0.3743866980075836, -0.2203209400177002, -1.3207136392593384, 0.2090918868780136, 0.705052375793457, -0.474884033203125, -0.42853984236717224, -0.04027111083269119, 0.4497522711753845, 0.6389566659927368, 0.474708616733551, -0.3053538203239441, 0.19679401814937592, -0.29618093371391296, -0.04581836611032486, -0.30408698320388794, 0.46088337898254395, -0.23406440019607544, -0.3096223473548889, 0.3050127625465393, -0.5180437564849854, 0.5466933250427246, 0.0981842428445816, -0.417415052652359, -0.35505783557891846, -0.48817017674446106, 0.13503269851207733, 0.2418016493320465, 1.3195465803146362, -0.472601979970932, 0.31898048520088196, -0.6606972813606262, 0.5311888456344604, 0.0938047468662262, -0.4147186279296875, -1.089147925376892, 0.05738319829106331, 0.6633062362670898, -0.2412378042936325, -0.3438182771205902, 0.5110117793083191, -0.9337237477302551, -0.5548692345619202, -0.5904645323753357, -0.5643740892410278, 0.31965890526771545, -0.5810443162918091, -0.02299167774617672, 0.8278155326843262, -0.43234848976135254, -0.46191802620887756, 0.26404237747192383, -0.9593865275382996, -0.5259565114974976, 0.12887750566005707, -1.3570961952209473, -0.6494572758674622, 0.27723485231399536, -0.5813400745391846, -0.28946366906166077, 0.10278993099927902, 1.1369516849517822, 0.5604517459869385, 0.061151158064603806, 0.47472575306892395, 0.2320101112127304, -0.2850194275379181, -0.2649059295654297, -0.3885882794857025, 1.4777116775512695, 0.4007447063922882, -0.3652343451976776, -0.01247484888881445, 0.24070894718170166, 0.039673611521720886, -1.1462626457214355, -0.09016253799200058, 0.2459380179643631, -0.7531771063804626, 0.33102941513061523, -1.039504885673523, -0.15687717497348785, 0.37114447355270386, 0.4291200637817383, 0.44275543093681335, 0.6929706931114197, 0.04331239312887192, -0.29965564608573914, -0.0849534422159195, -0.7675420641899109, 0.5259369015693665, 1.0092618465423584, -0.6429954171180725, 0.4137474298477173, -0.32285064458847046, 0.11227448284626007, -1.3567662239074707, -0.863810658454895, 0.2369382232427597, 0.1783123016357422, -0.7863075733184814, 1.0028514862060547, 0.3527999222278595, 1.1341853141784668, 0.8342275023460388, -0.30902066826820374, -0.5801770091056824, 0.13404466211795807, -1.1968187093734741, -0.540372371673584, -0.25654542446136475, 0.4858418405056, -0.11702778190374374, 0.6827391982078552, 0.34840258955955505, 0.3218640089035034, -0.9465089440345764, 0.0008131407084874809, -0.151892751455307, -0.6765802502632141, -0.2103518694639206, 0.2471400797367096, -0.11279279738664627, 0.033815812319517136, 0.33700644969940186, 0.39216291904449463, 0.5399460196495056, 0.13651901483535767, -0.3236284554004669, 0.6170516014099121, 0.011037550866603851, -0.6846348643302917, -0.36133942008018494, -0.5501387715339661, -1.232528567314148, -0.00940271932631731, -0.9565982818603516, -0.08837994933128357, -0.2316504716873169, -0.45841607451438904, -0.03408355638384819, -0.1841934770345688, -0.26160258054733276, 0.25794312357902527, 0.08921065181493759, -0.5676881074905396, -0.9132933616638184, -1.1397430896759033, 0.6043018698692322, 0.42905497550964355, 0.032746121287345886, 0.03432575613260269, -0.2522643208503723, -0.2363218516111374, 0.6792781352996826, 0.3532019257545471, -0.046460844576358795, -0.6609457731246948, -0.9041748642921448, 0.49300310015678406, 0.011800088919699192, -0.33962246775627136, -0.9427325129508972, 0.7893214225769043, 0.4908004105091095, -0.21707262098789215, 0.16245050728321075, 0.12080086767673492, -1.1800557374954224, -0.23998905718326569, 0.5856439471244812, 0.28130367398262024, 0.6753894686698914, 0.4802572429180145, -1.0063090324401855, 0.4021894931793213, 0.9314287304878235, 0.005766004323959351, -0.26472386717796326, -1.150342583656311, 0.47274959087371826, -0.42203542590141296, 0.11722961813211441, 0.1085776537656784, -0.1201699748635292, -1.1607613563537598, -0.15949958562850952, 0.1544618159532547, 0.3907736837863922, 0.27249500155448914, 0.7484543323516846, 0.12787632644176483, -1.2417364120483398, 0.16215525567531586, 0.6462982296943665, -0.16455936431884766, -0.36005842685699463, 0.12333587557077408, 0.7753500938415527, -0.795600414276123, -0.056686609983444214, -0.3091849982738495, 0.19098368287086487, -0.994219183921814, 0.18782007694244385, 0.1651596873998642, -0.9458248615264893, 0.09615236520767212, 0.8633202910423279, -0.4978651702404022, -0.41584518551826477, -0.36741167306900024, -0.733755886554718, -0.018563156947493553, -0.6379010677337646, 0.5987875461578369, 0.6561678647994995, 0.45838382840156555, 0.4331381320953369, -1.046939730644226, 0.1478533148765564, -0.09988915920257568, -0.1327643096446991, 0.3967955708503723, -0.10757821798324585, -0.6193838119506836, 0.026110103353857994, 0.4043861925601959, -0.08657322824001312, -0.32193073630332947, -0.40800750255584717, -0.3460257649421692, -0.05202264338731766, 0.7795369625091553, -0.03541575372219086, -0.6669477820396423, 0.41336655616760254, 0.31772419810295105, 0.18250268697738647, 0.6838598251342773, -0.3565710186958313, 0.5521889925003052, 0.0588228739798069, 0.962579607963562, -0.5789664387702942, -0.6628150343894958, 0.8029937744140625, 0.29161161184310913, -0.4767638146877289, 0.6758247017860413, -0.8368675708770752, 0.14953771233558655, 0.4887535274028778, 0.5129806995391846, -0.26772671937942505, 0.8988142013549805, 1.486076831817627, -0.4393146336078644, 0.3863011598587036, -0.8294684290885925, -0.39396989345550537, 0.5309371948242188, 0.8525094389915466, 0.5461843013763428, 0.4961736798286438, -0.08246301114559174, 0.689446747303009, 0.4163673222064972, 0.5383840799331665, 0.7257436513900757, 0.6953592896461487, 0.03307188302278519, -0.3351329267024994, -0.4478626251220703, 0.8051888942718506, -0.7927927374839783, -1.0103628635406494, 0.20065838098526, 0.7809255123138428, -0.12058107554912567, 0.49247637391090393, 0.9404968023300171, -0.28703010082244873, 0.28125977516174316, -0.4814237952232361, 0.6975256204605103, -0.3245236873626709, 0.014845949597656727, 0.23015406727790833, -0.20130959153175354, -0.3718649744987488, 0.41176918148994446, 0.24739199876785278, -0.4018375873565674, -0.912155270576477, 0.4509628415107727, -0.05028373375535011, 0.4969327449798584, 0.5544359087944031, 1.4325183629989624, 1.2627860307693481, -0.12577573955059052, -0.9066547155380249, 0.16260699927806854, -0.15879744291305542, -0.01721767894923687, -0.9958806037902832, -0.6824383735656738, -0.2846956253051758, -0.09217944741249084, -0.7960076928138733]}, "authors": [{"authorId": "52089303", "name": "Shikhar Tuli"}, {"authorId": "144874163", "name": "N. Jha"}], "references": [{"paperId": "a7d298cbbac81bd47396edbf6a97fbc1fa0cf5c6", "title": "AccelTran: A Sparsity-Aware Accelerator for Dynamic Inference With Transformers"}, {"paperId": "6399b5be2e4ab3c8d6d6625f3d1cd513ffb9bbab", "title": "CODEBench: A Neural Architecture and Hardware Accelerator Co-Design Framework"}, {"paperId": "1bcd42583a7b4475d3b456678e7f3752acd9edd1", "title": "FlexiBERT: Are Current Transformer Architectures too Homogeneous and Rigid?"}, {"paperId": "08b06339d025324171ab7fb8d764155cefa70409", "title": "Towards efficient vision transformer inference: a first study of transformers on mobile devices"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "8bb197ec64709c305c007cfff4260e2a782c8577", "title": "Accelerating Framework of Transformer by Hardware Design and Model Compression Co-Optimization"}, {"paperId": "c67b1a62b868a758791c88d5465c7b6d53510fc3", "title": "Energon: Toward Efficient Acceleration of Transformers Using Dynamic Sparse Attention"}, {"paperId": "c7e9f4c4ce5c2597c35f0116f297d1f2606fa555", "title": "Dynamic Transformer for Efficient Machine Translation on Embedded Devices"}, {"paperId": "47354f49a4768719add414ea853977cb868faf25", "title": "AutoBERT-Zero: Evolving BERT Backbone from Scratch"}, {"paperId": "ac9b21d8408c19eef33778e05ba908ba969f29ed", "title": "NAAS: Neural Accelerator Architecture Search"}, {"paperId": "1f133158a8973fb33fea188f20517cd7e69bfe7f", "title": "FNet: Mixing Tokens with Fourier Transforms"}, {"paperId": "dd0a27aa2285bc64798fa76944400ab6d9ce3025", "title": "NAS-BERT: Task-Agnostic and Adaptive-Size BERT Compression with Neural Architecture Search"}, {"paperId": "8557d9505a7e1b09dced5b019259004d56cc1b95", "title": "COSCO: Container Orchestration Using Co-Simulation and Gradient Based Optimization for Fog Computing Environments"}, {"paperId": "40235eded15f44c8c4a7f48468adcc7df4e171fb", "title": "Rethinking Network Pruning \u2013 under the Pre-train and Fine-tune Paradigm"}, {"paperId": "73e0f38ab49b19b86321016b773e15f1d02e3a72", "title": "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning"}, {"paperId": "56f7d52db43af791aa549ff0b66543f2c69751c4", "title": "CC-News-En: A Large English News Corpus"}, {"paperId": "94eb8e46767ae77e265b0a20dcc0d9f69d2d6e2b", "title": "A Survey of Deep Active Learning"}, {"paperId": "9ed4321e552d069ff6aa6f88480809e23927131d", "title": "Surrogate NAS Benchmarks: Going Beyond the Limited Search Spaces of Tabular NAS Benchmarks"}, {"paperId": "2a218786f4615b82389f78472e7ff22e6ce57490", "title": "ConvBERT: Improving BERT with Span-based Dynamic Convolution"}, {"paperId": "8acc99c96a9cce2a14e049f756f608dab3491f24", "title": "MCUNet: Tiny Deep Learning on IoT Devices"}, {"paperId": "7c6c31412c5dad22543bb71e31620e8868d644a3", "title": "FTRANS: energy-efficient acceleration of transformers using FPGA"}, {"paperId": "eb1602ecba96beadeb7d2f05e1b57fa6b339fc69", "title": "SqueezeBERT: What can computer vision teach NLP about efficient neural networks?"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "ef8d788a904ed66bd8e30ffa69bc3ea1fe57dda7", "title": "HAT: Hardware-Aware Transformers for Efficient Natural Language Processing"}, {"paperId": "66ceae37af0e7ace4755a5e8f41162d0f6cf7677", "title": "MicroNet for Efficient Language Modeling"}, {"paperId": "66f0f35fc78bdf2af9de46093d49a428970cde2e", "title": "Movement Pruning: Adaptive Sparsity by Fine-Tuning"}, {"paperId": "a81674f480dba239e12c80910528cae5d3a28e97", "title": "schuBERT: Optimizing Elements of BERT"}, {"paperId": "2573af4e13d9a5dddb257d22cd38a600528d9a8b", "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"}, {"paperId": "1c332cfa211400fc6f56983fb01a6692046116dd", "title": "DynaBERT: Dynamic BERT with Adaptive Width and Depth"}, {"paperId": "d9b824dbecbe3a1f0b1489f9e4521a532a63818d", "title": "Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning"}, {"paperId": "54d4ff8d536b292149a4fa017c22349cf4e54ce4", "title": "AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural Architecture Search"}, {"paperId": "bc51622358d8eea83248ef29402fe10640d07ba6", "title": "Big Transfer (BiT): General Visual Representation Learning"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "93ad19fbc85360043988fa9ea7932b7fdf1fa948", "title": "Well-Read Students Learn Better: The Impact of Student Initialization on Knowledge Distillation"}, {"paperId": "4cdf2fad22afc865999747336c7399fe422e6e8e", "title": "Optuna: A Next-generation Hyperparameter Optimization Framework"}, {"paperId": "9a9dcc604321dd2dda93c3ad268e554b7f2b356e", "title": "ChamNet: Towards Efficient Network Design Through Platform-Aware Model Adaptation"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "21937ecd9d66567184b83eca3d3e09eb4e6fbd60", "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "fe9b8aac9fa3bfd9724db5a881a578e471e612d7", "title": "Efficient Neural Architecture Search via Parameter Sharing"}, {"paperId": "cc2bc56b30e283bc6e7193dd42e66e56658b4875", "title": "NeST: A Neural Network Synthesis Tool Based on a Grow-and-Prune Paradigm"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "e2cc7d9e4e479a936da6e6c1289673614abb2a7d", "title": "Natural-Parameter Networks: A Class of Probabilistic Neural Networks"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "93499a7c7f699b6630a86fad964536f9423bb6d0", "title": "Effective Approaches to Attention-based Neural Machine Translation"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "0df9c70875783a73ce1e933079f328e8cf5e9ea2", "title": "From RankNet to LambdaRank to LambdaMART: An Overview"}, {"paperId": "82c291ff9f97931e6a2806fc082f82e1d792de49", "title": "An analysis of diversity measures"}, {"paperId": "f55238913918c61b0dad87974699d05a5d71e709", "title": "An elementary proof of a theorem of Johnson and Lindenstrauss"}, {"paperId": "8490234d79b47e459824dcf87c1e288211a3c964", "title": "Cumulated gain-based evaluation of IR techniques"}, {"paperId": "1267fe36b5ece49a9d8f913eb67716a040bbcced", "title": "On the limited memory BFGS method for large scale optimization"}, {"paperId": "b76e98a0a023d37c6534aa2ead09c8ff595f0bae", "title": "A Robustly Optimized BERT Pre-training Approach with Post-training"}, {"paperId": null, "title": "AutoTiny- BERT: Automatic hyper-parameter optimization for efficient pre-trained language models"}, {"paperId": null, "title": "Apple unleashes M1"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Distinguished Alumnus Award by IIT, Kharagpur"}, {"paperId": "247f95271f7fb870436ca4759d949901cdd16ed1", "title": "Backtracking Search Algorithms"}, {"paperId": "2454e846733f0f0d6ae98c489a632a7199d07ed6", "title": "Random number generation and Quasi-Monte Carlo methods"}, {"paperId": "4954fa180728932959997a4768411ff9136aac81", "title": "This Paper Is Included in the Proceedings of the 12th Usenix Symposium on Operating Systems Design and Implementation (osdi '16). Tensorflow: a System for Large-scale Machine Learning Tensorflow: a System for Large-scale Machine Learning"}, {"paperId": null, "title": "OpenVINO: An open-source toolkit for optimizing and deploying AI inference (2022)"}, {"paperId": null, "title": "Open Neural Network Exchange (2022)"}, {"paperId": null, "title": "OpenWebText Corpus"}, {"paperId": null, "title": "His research interests include machine algorithms/architectures and smart healthcare"}, {"paperId": null, "title": "4 Model-B"}, {"paperId": null, "title": "Apple unleashes M 1 . [ Online ] NVIDIA Jetson Nano Developer Kit"}, {"paperId": null, "title": "Intel Neural Compute Stick 2"}]}