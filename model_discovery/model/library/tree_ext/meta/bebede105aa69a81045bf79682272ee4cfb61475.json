{"paperId": "bebede105aa69a81045bf79682272ee4cfb61475", "title": "Mastering Symbolic Operations: Augmenting Language Models with Compiled Neural Networks", "abstract": "Language models' (LMs) proficiency in handling deterministic symbolic reasoning and rule-based tasks remains limited due to their dependency implicit learning on textual data. To endow LMs with genuine rule comprehension abilities, we propose\"Neural Comprehension\"- a framework that synergistically integrates compiled neural networks (CoNNs) into the standard transformer architecture. CoNNs are neural modules designed to explicitly encode rules through artificially generated attention weights. By incorporating CoNN modules, the Neural Comprehension framework enables LMs to accurately and robustly execute rule-intensive symbolic tasks. Extensive experiments demonstrate the superiority of our approach over existing techniques in terms of length generalization, efficiency, and interpretability for symbolic operations. Furthermore, it can be applied to LMs across different model scales, outperforming tool-calling methods in arithmetic reasoning tasks while maintaining superior inference efficiency. Our work highlights the potential of seamlessly unifying explicit rule learning via CoNNs and implicit pattern learning in LMs, paving the way for true symbolic comprehension capabilities.", "venue": "", "year": 2023, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work highlights the potential of seamlessly unifying explicit rule learning via CoNNs and implicit pattern learning in LMs, paving the way for true symbolic comprehension capabilities."}, "embedding": {"model": "specter_v2", "vector": [0.39725032448768616, 0.6252304315567017, -0.2568517029285431, -0.22838740050792694, 0.02581682987511158, -0.19825881719589233, 0.39690759778022766, -0.03794516250491142, -0.25189536809921265, -0.2467932552099228, 0.027802685275673866, -0.4129597842693329, 0.18751290440559387, -0.3452444076538086, -0.01921909861266613, 0.22904714941978455, -0.9590355157852173, 0.20026010274887085, -0.06068410724401474, -0.34150201082229614, 0.49380412697792053, -0.20734690129756927, -1.5244220495224, 0.2533605694770813, 0.3685215711593628, 0.4070001542568207, -0.056142132729291916, 1.0161887407302856, -0.38067442178726196, 0.6975235342979431, 0.2862607538700104, -0.5078979134559631, -0.16307009756565094, 0.22231142222881317, -0.3709675669670105, -0.7237033247947693, 0.5395521521568298, -0.4810025095939636, -0.4964043200016022, 0.9743900895118713, -0.49771052598953247, 0.3119962811470032, 0.4818999469280243, -0.5083783864974976, -0.5520800352096558, 1.14822256565094, 0.966277539730072, 0.6324448585510254, -0.27191561460494995, 0.05167759582400322, 1.441864252090454, -1.1768162250518799, 0.19438916444778442, 1.3962595462799072, 0.7094568610191345, 0.5025808215141296, -0.08460046350955963, -0.7544988989830017, 0.5327970385551453, -0.1760232001543045, -0.7543754577636719, -0.5665405988693237, -0.425187885761261, -0.0035027421545237303, 2.0092978477478027, -0.3117337226867676, -0.2728229761123657, 0.0017318084137514234, 0.1548490822315216, 1.0874040126800537, -0.04661434516310692, -0.7992539405822754, -0.23961107432842255, -0.20429666340351105, 0.3087253272533417, 1.2033026218414307, -0.030519677326083183, 0.375543475151062, -0.9423419833183289, 0.06539027392864227, 0.9476123452186584, 0.03577492758631706, 0.20792563259601593, -0.08723558485507965, -0.4703672528266907, 0.7004090547561646, 0.20916861295700073, 0.7385826706886292, -0.13872908055782318, 0.6519107818603516, 0.5626469254493713, 0.5868790745735168, -0.3736828863620758, 0.8663501739501953, -0.22448545694351196, 0.267322838306427, -0.8396965265274048, 0.5159136652946472, 0.4009369909763336, 0.909687876701355, -0.29984673857688904, 0.7079735994338989, -0.3508871793746948, 0.23570434749126434, 1.0727882385253906, 0.4095076024532318, 0.4337630271911621, -1.086401343345642, 0.32575541734695435, -0.4190399944782257, 0.12199168652296066, -0.8153412938117981, -0.27169138193130493, -0.3367142379283905, -0.5109452605247498, -0.9503843784332275, -0.22543568909168243, 0.02272675931453705, -0.6138710975646973, 0.7919135689735413, -0.7493985295295715, -0.18898724019527435, 0.22377994656562805, 0.03446615859866142, 0.5847548842430115, 0.4641125798225403, 0.5869799852371216, 0.30211490392684937, 0.9787797331809998, -0.31214311718940735, -0.4989697337150574, -1.0738707780838013, 0.8697449564933777, 0.07344885915517807, 0.20030242204666138, -0.030700433999300003, -1.4572315216064453, -1.0652897357940674, -0.9043711423873901, 0.03693874552845955, -0.9113926887512207, 0.44764775037765503, 1.2789955139160156, 0.2075931280851364, -1.0248461961746216, 1.0427918434143066, 0.13910968601703644, -0.11273735016584396, 0.4351533055305481, 0.5386936664581299, 0.4517185389995575, -0.32665514945983887, -1.318814754486084, 0.5143975615501404, 0.5590972304344177, -0.3755519688129425, -0.20665805041790009, -0.1904265433549881, -1.4693328142166138, 0.2670730948448181, 0.6568151712417603, -0.7237610816955566, 1.6258234977722168, 0.05878523364663124, -1.1971473693847656, 0.7452073097229004, -0.11172095686197281, 0.05409972369670868, -0.2227790653705597, -0.23502977192401886, -0.6944535970687866, -0.0636446550488472, -0.2182956337928772, 0.5973063111305237, 0.3882550299167633, -0.39282849431037903, -0.05893414095044136, 0.31377074122428894, 0.009584087878465652, -0.3119560778141022, -0.028644146397709846, 1.0944548845291138, -0.14845432341098785, -0.2732553482055664, 0.22478239238262177, 0.7931464910507202, 0.06296495348215103, -0.09697932004928589, -0.4582712650299072, -0.8394547700881958, 0.4792799651622772, -0.21811553835868835, 1.345115065574646, -0.8122798800468445, -0.614778459072113, 0.05015156790614128, 0.16507014632225037, -0.0018915841355919838, -0.39485886693000793, 0.3705406188964844, -0.4084663391113281, 0.6279922127723694, -0.6113429069519043, -0.7743929028511047, -0.04094185307621956, 0.0440843440592289, -0.5644423365592957, -0.5590457916259766, 0.05957705155014992, 1.210981845855713, -0.9315142035484314, -0.224648118019104, 0.08468587696552277, -0.13773708045482635, -0.8437705636024475, 1.3658490180969238, -0.5453040599822998, -0.0858311876654625, -0.029593847692012787, -0.10617390275001526, -0.39381492137908936, -0.28229692578315735, 0.4947843849658966, -0.19343926012516022, -0.20833580195903778, 0.35732102394104004, -0.4085627794265747, 1.0826137065887451, -0.4314269721508026, 0.27984073758125305, -0.15705154836177826, -0.3142266869544983, 0.2511783540248871, 0.33986780047416687, -0.8931694030761719, -0.454792320728302, 0.4139024615287781, 0.5258091688156128, -0.10982190817594528, -0.13966067135334015, 0.6756251454353333, 0.7646907567977905, -0.552940309047699, 0.47240403294563293, 0.618010401725769, -0.6243714094161987, 0.9309859871864319, 0.03606337681412697, 0.4614776372909546, 0.4990770220756531, 0.7223873734474182, 0.13376839458942413, 0.7657677531242371, -0.39070233702659607, -0.39781397581100464, 0.663639485836029, 1.2926301956176758, 0.6560031175613403, 0.4992509186267853, -0.6270377039909363, -0.21563337743282318, 0.12041879445314407, 0.7637285590171814, 1.9765968322753906, -0.16381192207336426, 0.14600734412670135, -0.8449761867523193, -0.21487481892108917, -0.14111781120300293, 0.5561009049415588, -0.32278862595558167, -0.38731077313423157, -1.013142704963684, -0.5779804587364197, 1.4122570753097534, 0.820881187915802, 1.18489670753479, -1.0798943042755127, -0.5605344772338867, -0.3520255982875824, 0.7093574404716492, -0.46904218196868896, -0.38415005803108215, 0.31070879101753235, -0.8343497514724731, -0.5383473038673401, 0.44690147042274475, -0.2980252206325531, 0.28943192958831787, -0.677894115447998, 0.8360300660133362, -0.08806867152452469, -0.3057056963443756, -0.13117319345474243, 1.147452473640442, -0.5123241543769836, -0.8763105869293213, 0.3086576759815216, -0.13649742305278778, -0.38765400648117065, 0.07703608274459839, 0.37035083770751953, 0.2136678546667099, -0.043240051716566086, -0.589934229850769, 0.20340698957443237, 0.5570734739303589, -0.04502461850643158, 0.3257693946361542, -0.49277371168136597, 0.1630273461341858, -1.6562834978103638, 0.871463418006897, 0.3082691729068756, -0.35249778628349304, 0.36624813079833984, -0.8514118790626526, 0.07866522669792175, 0.7796429991722107, -0.39735934138298035, -0.5404588580131531, -1.2041581869125366, 0.5914453268051147, 0.02248641662299633, -0.6801828742027283, 0.664955735206604, 0.20043082535266876, -0.13806737959384918, 0.19218233227729797, 0.5826805233955383, 0.7084630131721497, -0.09838494658470154, 0.5379746556282043, -0.984010636806488, 0.8876842856407166, -0.036110538989305496, 0.2478300780057907, -0.5026190280914307, -0.1442706435918808, -0.4016343355178833, -0.06619458645582199, 0.12412358820438385, -0.0679255872964859, -0.056234776973724365, 0.1699703484773636, -0.07933735102415085, -1.1236414909362793, 0.17618653178215027, -1.291420340538025, -0.5777543783187866, 0.3579486012458801, -0.7480320334434509, 0.07707734405994415, -1.1511646509170532, -1.3631693124771118, -0.6390219330787659, -0.26343774795532227, -0.8466662764549255, 0.22666102647781372, 0.002301745815202594, -0.8027081489562988, -0.6481621861457825, -0.08647730201482773, -0.6028169989585876, 1.2685099840164185, -0.3633372187614441, 1.3883413076400757, -0.38485562801361084, 0.08609248697757721, -0.19679614901542664, 0.0148326950147748, 0.4609193205833435, -0.49444499611854553, 0.3996991813182831, -0.7240002155303955, 0.6852225661277771, -0.27232012152671814, -0.44998499751091003, -0.15830685198307037, -0.0965912789106369, 1.0120084285736084, -0.36756986379623413, -0.2676386833190918, 0.16134709119796753, 1.3039904832839966, -0.23217687010765076, -0.05530534312129021, -0.12245447188615799, 0.9663650989532471, 0.5266280174255371, -0.5686848759651184, 0.08889031410217285, 0.39749592542648315, 0.19540628790855408, 0.1520051211118698, 0.003390784142538905, -0.15493223071098328, -0.33746013045310974, 0.44272273778915405, 1.3688925504684448, -0.12437276542186737, 0.17606057226657867, -1.2175711393356323, 0.10732754319906235, -0.8663193583488464, -0.42450448870658875, 0.4716360569000244, 0.6191338300704956, 0.553900957107544, -0.2408047616481781, -0.8033970594406128, 0.26701635122299194, 0.49911201000213623, 0.344831645488739, -0.368585467338562, -0.790766716003418, 0.10286218672990799, 0.62000572681427, 0.09732043743133545, 0.48705729842185974, -0.3712858259677887, 0.2764609754085541, 14.758525848388672, 0.5648933053016663, -0.12903666496276855, 0.4529419243335724, 0.5191229581832886, 0.5931785106658936, -0.11990773677825928, -0.2846580147743225, -0.9343922138214111, -0.5737009048461914, 1.152513027191162, 0.34077519178390503, 0.5471940636634827, 0.30764493346214294, -0.13956142961978912, 0.08237051218748093, -0.6583467125892639, 0.46798768639564514, 0.6192969679832458, -1.3227239847183228, 0.6557253003120422, 0.01074169296771288, 0.24963393807411194, -0.13834671676158905, 0.7739483118057251, 0.9197109341621399, 0.6599786281585693, -0.906653106212616, 0.6540030837059021, 0.4258255958557129, 1.1674338579177856, 0.03226468339562416, 0.5542498230934143, 0.4648635685443878, -0.8783131837844849, -0.4351845979690552, -0.08952468633651733, -1.2591506242752075, -0.238823801279068, -0.3153625428676605, -0.12520356476306915, -0.42272207140922546, -0.6792411804199219, 0.7142757177352905, -0.08894497901201248, 0.1540316492319107, -0.5587201714515686, 0.5031392574310303, 0.3354171812534332, -0.03286860138177872, -0.23738646507263184, 0.6685925722122192, -0.1155201867222786, 0.14102230966091156, 0.04080870747566223, 0.11098004877567291, -0.11433851718902588, 0.8110985159873962, -0.4234350323677063, -0.14168179035186768, -0.6523232460021973, -0.31891411542892456, 0.05988750606775284, 0.29454147815704346, 0.22317416965961456, 0.15143312513828278, -0.1392333209514618, -0.0743817463517189, 0.5586979389190674, 0.3557519316673279, 0.08127709478139877, -0.5958289504051208, -0.016251470893621445, -0.5457556247711182, 0.17579345405101776, 0.16147497296333313, -1.0390270948410034, -0.4780275523662567, -1.1124095916748047, -0.6717023253440857, 0.3047679662704468, -0.7895954847335815, -0.30899572372436523, 0.744311511516571, 0.02398861199617386, -0.14049193263053894, 0.03161942958831787, -1.163204312324524, -0.5323072671890259, 0.1746387928724289, -0.9574363231658936, -0.5586655139923096, 0.14823131263256073, -0.528599739074707, -0.3163437247276306, -0.13457010686397552, 1.5486793518066406, -0.2809644341468811, -0.392110139131546, -0.06486582010984421, -0.37293535470962524, 0.21550221741199493, -0.5682525038719177, -0.8073707818984985, 0.5732887983322144, 0.2007526010274887, -0.2033233344554901, 0.8186108469963074, 0.09247621893882751, -0.08143027871847153, -0.6989595293998718, 0.14971810579299927, 1.072176456451416, -0.7181204557418823, -0.4057878851890564, -0.7062489986419678, -0.8995746374130249, 0.36669889092445374, 0.13853323459625244, -0.5109092593193054, 0.18879862129688263, -0.16648629307746887, -0.720469057559967, -0.14630861580371857, -0.7052299380302429, 0.14874479174613953, 0.7530040740966797, -0.7894333600997925, -0.7185426354408264, -0.4608105719089508, 0.07609764486551285, -0.9452748894691467, -0.4112672805786133, -0.3490101993083954, 0.21390585601329803, -0.11564649641513824, 0.7869084477424622, -0.3829593360424042, 1.0580132007598877, 0.6289857029914856, 0.32390832901000977, -0.4079599678516388, 0.20533894002437592, -0.6659526824951172, -0.22295202314853668, -0.19134820997714996, 0.9561905860900879, -0.8802276253700256, -0.2625311315059662, 0.8504458069801331, -0.08049242943525314, -0.425529420375824, -0.23732957243919373, 0.0057846554554998875, -0.015082931146025658, -0.7692580819129944, 0.6010276675224304, -0.16047808527946472, -0.12481717020273209, -0.09885023534297943, 0.6352377533912659, 0.5307968854904175, -0.38137662410736084, -0.27273884415626526, 0.19048352539539337, -0.3284793794155121, -0.21113167703151703, -1.008829951286316, -0.28142696619033813, -1.0787568092346191, 0.1347494274377823, -1.3216123580932617, 0.3626573383808136, -0.7819214463233948, -0.6296330690383911, 0.2103913426399231, -0.08689054846763611, 0.46573832631111145, 0.4360349178314209, -0.40945106744766235, -0.727596640586853, -0.2407151311635971, -0.5704769492149353, 0.43549036979675293, 0.7117503881454468, -0.31634774804115295, 0.2872483432292938, -0.15312814712524414, -0.11356626451015472, 0.4660778045654297, 0.4887799322605133, -0.557364821434021, -0.5682346820831299, -1.380356788635254, 0.557525098323822, 0.14495226740837097, 0.1304779201745987, -0.8883068561553955, 0.9648990631103516, 0.2559814751148224, -0.30401837825775146, 0.4498465359210968, -0.12539619207382202, -0.4216151833534241, -0.7882575988769531, 0.6241953372955322, -1.130043387413025, 0.5756758451461792, 0.46082088351249695, -0.6735122203826904, -0.2833712100982666, 0.49704185128211975, -0.29099664092063904, -0.8910022974014282, -0.6962409615516663, -0.051536720246076584, -1.0328633785247803, 0.20696459710597992, -0.4085884988307953, -0.128334179520607, -1.0439064502716064, -0.19651126861572266, -0.05175827443599701, 0.2708436846733093, -0.568176805973053, 0.5561089515686035, 0.7565118074417114, -0.6535314321517944, 0.27561548352241516, 0.48397496342658997, -0.2554282248020172, 0.06500526517629623, 0.26466104388237, 0.48346832394599915, -0.57634437084198, 0.6611114740371704, 0.16631381213665009, 0.7487560510635376, -0.8385615944862366, -0.4542182683944702, 0.859524130821228, -0.5122811198234558, 0.0012682487722486258, 0.8715866804122925, -0.37574395537376404, -1.2738184928894043, 0.15648001432418823, -1.5676159858703613, -0.7633568048477173, -0.6204981207847595, 0.3830879330635071, 0.12604396045207977, -0.3315179944038391, 0.20216117799282074, -0.02805361896753311, 0.36478519439697266, 0.027121568098664284, -0.2925451099872589, 0.4255337715148926, 0.19862428307533264, -0.7612189054489136, 0.6615294814109802, 0.29488545656204224, -0.7070833444595337, -0.410603791475296, -0.5093992352485657, -0.01447342336177826, 0.3633522689342499, -0.10417048633098602, -0.36426299810409546, -0.5995597839355469, 0.7020391225814819, -0.2985827624797821, 0.14798112213611603, -0.26560431718826294, -0.4521901309490204, 0.1597946286201477, 0.9474080204963684, -0.05909441411495209, -0.31814053654670715, -0.5280059576034546, 1.4565317630767822, 1.3985456228256226, -0.5190392136573792, 0.19899049401283264, -0.5146042108535767, -0.477451890707016, 1.5081433057785034, 0.3571162223815918, -0.15284720063209534, 0.6236773133277893, -0.13442683219909668, -0.15289266407489777, -0.256185919046402, -0.7604382634162903, -0.1039152666926384, 0.6149544715881348, 0.9034520387649536, 0.6419242024421692, 0.1275300830602646, 0.19725453853607178, 1.19355046749115, -0.27959144115448, 0.6290109753608704, 0.35177555680274963, 0.9679068326950073, -0.4711967706680298, 0.05970611423254013, -0.042356137186288834, 0.8039088249206543, -0.45926499366760254, -1.0531535148620605, 0.2143336832523346, 0.9315798878669739, 0.5962100625038147, 0.3114878535270691, 0.5430068969726562, -0.0036730263382196426, 0.6845099925994873, 0.7447437644004822, 0.3835899829864502, -0.9147186279296875, -0.5806088447570801, -0.8231893181800842, -0.054826948791742325, 0.033484380692243576, -0.09629501402378082, -0.48636361956596375, -0.7929181456565857, -0.3199799060821533, 0.5761414766311646, -0.2294740527868271, 0.17180776596069336, 1.247652292251587, 0.4207555949687958, 0.46726271510124207, -0.7586548924446106, -0.48659956455230713, -0.6898159980773926, -0.7568894028663635, 0.24739712476730347, -0.7801377177238464, -0.5433176159858704, -0.4875381588935852, -0.30696961283683777, -0.09587071090936661]}, "authors": [{"authorId": "2142839441", "name": "Yixuan Weng"}, {"authorId": "2187504043", "name": "Minjun Zhu"}, {"authorId": "2066079622", "name": "Fei Xia"}, {"authorId": "2156072001", "name": "Bin Li"}, {"authorId": "1954845", "name": "Shizhu He"}, {"authorId": "2200096", "name": "Kang Liu"}, {"authorId": "11447228", "name": "Jun Zhao"}], "references": [{"paperId": "ed3873864a14ed4f9ee09d3cf70d1ead2fa2be10", "title": "LMTuner: An user-friendly and highly-integrable Training Framework for fine-tuning Large Language Models"}, {"paperId": "9b00bbe822fc98d00dcb32a32b7ff986b6b58d3e", "title": "Transformer: A General Framework from Machine Translation to Others"}, {"paperId": "32dcd0887537cece54e214f531d2c384470b023f", "title": "Large Language Models as Tool Makers"}, {"paperId": "574beee702be3856d60aa482ec725168fe64fc99", "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4"}, {"paperId": "746bb45433f6b24d3ae64d6cd51c4e9d00a0ffa7", "title": "Large-scale Multi-modal Pre-trained Models: A Comprehensive Survey"}, {"paperId": "681cee58cf7e54199191cf9e0baf6851d8356704", "title": "Complex QA and language models hybrid architectures, Survey"}, {"paperId": "2029349c55c1dba3493c5b3bd25152f18ba21ae2", "title": "Augmented Language Models: a Survey"}, {"paperId": "53d128ea815bcc0526856eb5a9c42cc977cb36a7", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools"}, {"paperId": "a5cc5edcabba4c9c62cfbc3379daa140084a2a24", "title": "Tracr: Compiled Transformers as a Laboratory for Interpretability"}, {"paperId": "7715ba5e75f5256e1061c7473afe61bb0dbb9065", "title": "Large Language Models are Better Reasoners with Self-Verification"}, {"paperId": "525d93a382f6e7873b5d8a2e0713eb3dff7fb250", "title": "Transformers learn in-context by gradient descent"}, {"paperId": "7aa801b907b59b8ee4cfb1296d9dac22c5164c5d", "title": "What learning algorithm is in-context learning? Investigations with linear models"}, {"paperId": "6c943670dca38bfc7c8b477ae7c2d1fba1ad3691", "title": "Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks"}, {"paperId": "6c1e1cc1e0e1f8fd026fe517607b2d4535565fa7", "title": "PAL: Program-aided Language Models"}, {"paperId": "4d17732d90440682b0500f4e209c6cc4fac20e0e", "title": "Teaching Algorithmic Reasoning via In-context Learning"}, {"paperId": "965e409a3e7b5670d609837fac9823b160d6639c", "title": "Logical Tasks for Measuring Extrapolation and Rule Comprehension"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "4809452eb4ed547adaf44a004d47ee910265ba34", "title": "Inverse scaling can become U-shaped"}, {"paperId": "7947e99f8c12af240f2c7a4fcff3f0f553621b96", "title": "Visual Answer Localization with Cross-Modal Mutual Knowledge Transfer"}, {"paperId": "9b45af10429681249fafb07c3b6012ea4ce63ffe", "title": "A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models"}, {"paperId": "3fa70115248377c3d1517c9f978791a296fbc1dd", "title": "Large Language Models Can Self-Improve"}, {"paperId": "5c02d55fe14e2baf4b6b59a476ee6a20698397ef", "title": "Language Models Understand Us, Poorly"}, {"paperId": "663a41c866d49ce052801fbc88947d39764cad29", "title": "Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them"}, {"paperId": "fc7497d1a56846f95c77e0da67c07e0a4e6c9367", "title": "ReasonChainQA: Text-based Complex Question Answering with Explainable Evidence Chains"}, {"paperId": "89c671c600ba523f42b6a3d8b44915162fafabd1", "title": "Learning To Locate Visual Answer In Video Corpus Using Question"}, {"paperId": "90350aa626bed47b02d0c162462e5b0ca82be6b2", "title": "Automatic Chain of Thought Prompting in Large Language Models"}, {"paperId": "2a7ae3e98357569c41424dacd60c62d3df78a0db", "title": "Limitations of Language Models in Arithmetic and Symbolic Induction"}, {"paperId": "de32da8f5c6a50a6c311e9357ba16aa7d05a1bc9", "title": "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes"}, {"paperId": "f843233f76a5dff07bfa93a71a1cf13d8aa6a94a", "title": "Exploring Length Generalization in Large Language Models"}, {"paperId": "ab0e3d3e4d42369de5933a3b4c237780b41c0d77", "title": "Solving Quantitative Reasoning Problems with Language Models"}, {"paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a", "title": "Emergent Abilities of Large Language Models"}, {"paperId": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large Language Models are Zero-Shot Reasoners"}, {"paperId": "5437e8adab596d7294124c0e798708e050e25321", "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "d08f54a72f9ec38b6004cead11413328d0b82cb3", "title": "Towards Better Chinese-centric Neural Machine Translation for Low-resource Languages"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "38115e80d805fb0fb8f090dc88ced4b24be07878", "title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis"}, {"paperId": "5f19ae1135a9500940978104ec15a5b8751bc7d2", "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "af46b5ee6d0c1aada1c482d53018a50909aa4c90", "title": "Impact of Pretraining Term Frequencies on Few-Shot Reasoning"}, {"paperId": "5cbe278b65a81602a864184bbca37de91448a5f5", "title": "Competition-level code generation with AlphaCode"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "03488f1a193066b5ea8b9b800e119f07df5c1d9e", "title": "Reasoning Like Program Executors"}, {"paperId": "92173d081b15824d22a9ef070e118744ceee8052", "title": "Show Your Work: Scratchpads for Intermediate Computation with Language Models"}, {"paperId": "2db6c10f135d5701ae7aec45986124ce264c1344", "title": "Learning Symbolic Rules for Reasoning in Quasi-Natural Language"}, {"paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea", "title": "Training Verifiers to Solve Math Word Problems"}, {"paperId": "747109831e034e2c82d06730c6cc44792322e8c0", "title": "Neuro-Symbolic Forward Reasoning"}, {"paperId": "ca522c599f138824f926c2ddb72eed446ff3a20f", "title": "More but Correct: Generating Diversified and Entity-revised Medical Response"}, {"paperId": "0735fb79bf34698c1df4461a05ed51c232c412e4", "title": "Thinking Like Transformers"}, {"paperId": "b58d8579ece27a60432e667bfbdb750590fa65d9", "title": "True Few-Shot Learning with Language Models"}, {"paperId": "d7a7ebd1565c3795bc2bcdec4334d42a65ad17c5", "title": "Pretrained Language Models for Text Generation: A Survey"}, {"paperId": "da40abf66a805f97964c42c7639f459d8bad36ff", "title": "Neuro-Symbolic Artificial Intelligence: Current Trends"}, {"paperId": "13c4e5a6122f3fa2663f63e49537091da6532f35", "title": "Are NLP Models really able to Solve Simple Math Word Problems?"}, {"paperId": "687b13c44f849d23c2496996b5da83e706094db9", "title": "Beyond English-Centric Multilingual Machine Translation"}, {"paperId": "016863a86189c4e8ccecf9a36c4406c439a8a84c", "title": "INT: An Inequality Benchmark for Evaluating Generalization in Theorem Proving"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "3dd61d97827e3f380bf9304101149a3f865051fc", "title": "Injecting Numerical Reasoning Skills into Language Models"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9e12539d92088001e08b1e903c490127c479de4c", "title": "Transformers as Soft Reasoners over Language"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "53a77e8f73f2ca422d6e38fa9ecc490231ac044c", "title": "Neural Text Generation with Unlikelihood Training"}, {"paperId": "b285c067f2da04bf5647beb8853bfddf6d9b4e1b", "title": "A Multi-Type Multi-Span Network for Reading Comprehension that Requires Discrete Reasoning"}, {"paperId": "eef7cfe8267954adbb4675576072a1d80ca7a3a8", "title": "MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms"}, {"paperId": "54a13bcc9613dcaa76fb25fbe96572f376cfcca9", "title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost"}, {"paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586", "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"}, {"paperId": "4c6fe6179c408e1fbb3871af13d1a8e64f766e54", "title": "Solving General Arithmetic Word Problems"}, {"paperId": "17230f5b3956188055a48c5f4f61d131cce0662f", "title": "Parsing Algebraic Word Problems into Equations"}, {"paperId": "a7862e14b4c20cefd6dc4f611f8aa866fabf130b", "title": "Learning to Solve Arithmetic Word Problems with Verb Categorization"}, {"paperId": null, "title": "Looped transformers as programmable computers, 2023"}, {"paperId": "79bbf1fb50dfb9989c3fb5dd3cfa7112f9a7394f", "title": "MedConQA: Medical Conversational Question Answering System based on Knowledge Graphs"}, {"paperId": "df4ee70ee7edbec4b618f5c2b18de0a9a4bd8d5e", "title": "A Multi-tasking and Multi-stage Chinese Minority Pre-trained Language Model"}, {"paperId": null, "title": "Autoformalization with large language"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "0c0a778e6fdf7e36b1750c533dcc916f86608607", "title": "A Survey on Context Learning"}, {"paperId": null, "title": "The previous SoTA baselines are obtained from: (a) GPT-3 175B finetuned [Cobbe et al., 2021]; (b) GPT-3 175B finetuned plus an additional 175B verifier[Cobbe et al., 2021]"}, {"paperId": "015ca32bca81dbda1e2e432445eef798582236e1", "title": "Conference Paper"}, {"paperId": null, "title": "Paradigm shift in nat-ural language processing"}]}