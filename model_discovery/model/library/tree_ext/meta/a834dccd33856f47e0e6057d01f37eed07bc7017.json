{"paperId": "a834dccd33856f47e0e6057d01f37eed07bc7017", "title": "On Inter-dataset Code Duplication and Data Leakage in Large Language Models", "abstract": "Motivation. Large language models (LLMs) have exhibited remarkable proficiency in diverse software engineering (SE) tasks. Handling such tasks typically involves acquiring foundational coding knowledge on large, general-purpose datasets during a pre-training phase, and subsequently refining on smaller, task-specific datasets as part of a fine-tuning phase. Problem statement. Data leakage is a well-known issue in training of machine learning models. A manifestation of this issue is the intersection of the training and testing splits. While intra-dataset code duplication examines this intersection within a given dataset and has been addressed in prior research, inter-dataset code duplication, which gauges the overlap between different datasets, remains largely unexplored. If this phenomenon exists, it could compromise the integrity of LLM evaluations because of the inclusion of fine-tuning test samples that were already encountered during pre-training, resulting in inflated performance metrics. Contribution. This paper explores the phenomenon of inter-dataset code duplication and its impact on evaluating LLMs across diverse SE tasks. Study design. We conduct an empirical study using the CSN dataset, a widely adopted pre-training dataset, and five fine-tuning datasets used for various SE tasks. We first identify the intersection between the pre-training and fine-tuning datasets using a deduplication process. Then, we fine-tune four models pre-trained on CSN to evaluate their performance on samples encountered during pre-training and those unseen during that phase. Results. Our findings reveal a potential threat to the evaluation of various LLMs across multiple SE tasks, stemming from the inter-dataset code duplication phenomenon. Moreover, we demonstrate that this threat is accentuated by factors like the LLM's size and the chosen fine-tuning technique.", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The findings reveal a potential threat to the evaluation of various LLMs across multiple SE tasks, stemming from the inter-dataset code duplication phenomenon, and it is demonstrated that this threat is accentuated by factors like the LLM's size and the chosen fine-tuning technique."}, "embedding": {"model": "specter_v2", "vector": [-0.1829771101474762, 0.1374853402376175, -0.44088512659072876, 0.004270513541996479, -0.5631934404373169, -0.6406042575836182, 0.18193693459033966, -0.08971233665943146, -0.3042011260986328, -0.2070966511964798, 0.2862619161605835, -0.6144139170646667, 0.30135565996170044, 0.5042418837547302, -0.35829493403434753, 0.45073479413986206, -0.4402272403240204, 0.09845956414937973, -0.32036951184272766, 0.12515810132026672, -0.004347013309597969, -0.7920644879341125, -0.9041157364845276, 0.2632819414138794, 0.9785376787185669, 0.26750263571739197, 0.13937093317508698, 0.6202641725540161, -0.4789721369743347, 0.5088962316513062, 0.19748377799987793, -0.6660835146903992, 0.42821168899536133, 0.06325270980596542, -0.41844239830970764, 0.26931753754615784, 0.5233408212661743, -0.41072845458984375, -0.20778216421604156, 0.7194868922233582, -0.31890878081321716, -0.08777860552072525, -0.011137301102280617, -0.9452900886535645, -0.47168514132499695, 0.7703551054000854, 0.6086801290512085, 0.579680323600769, -0.4729713499546051, -0.34597718715667725, 0.7889677882194519, -1.3937495946884155, 0.4366268813610077, 0.7926614880561829, 0.9527422189712524, 0.298755943775177, -0.3583125174045563, -0.8465530872344971, -0.1643293797969818, -0.47662419080734253, -1.0401893854141235, -0.4401588439941406, -0.09208724647760391, -0.7788568735122681, 2.002307653427124, -0.5732682943344116, -0.40133464336395264, 0.04836045578122139, 0.021478040143847466, 0.8827705383300781, -0.06817608326673508, -0.6393256187438965, 0.10829450935125351, 0.5569719076156616, 0.21758855879306793, 0.9355477690696716, 0.012369326315820217, 0.23942625522613525, -0.5735625624656677, -0.6043831706047058, 0.39080196619033813, -0.1529475897550583, 0.02733759954571724, -0.5580981969833374, 0.32825204730033875, 0.5411439538002014, 0.03420626372098923, 0.6097269058227539, 0.23454201221466064, 0.6974557042121887, 0.8533602356910706, 0.7418332695960999, 0.15240739285945892, 0.6612637639045715, -0.5564360022544861, 0.06829683482646942, -1.266281247138977, -0.12420852482318878, -0.023649627342820168, 1.2040797472000122, 0.13870595395565033, 0.3055134415626526, -0.41954705119132996, 0.321047842502594, 1.1800143718719482, -0.6775313019752502, 0.7260420322418213, -0.5036470293998718, 0.804955244064331, -0.059688396751880646, 0.17921607196331024, -0.23791520297527313, -0.26029646396636963, -0.5724535584449768, -0.4197075068950653, -1.2046780586242676, -0.6452206373214722, -0.11773999035358429, -0.5744158625602722, 0.7003531455993652, -0.6681706309318542, 0.006721946410834789, 0.3336993157863617, 0.45414403080940247, 0.7059395909309387, -0.1867232620716095, 0.2600846588611603, -0.01675589568912983, 0.2281831055879593, -0.7582457065582275, -0.1307796686887741, -1.184596300125122, 1.3368008136749268, -0.669875979423523, 0.43924573063850403, -0.8059141635894775, -1.566070318222046, -0.9997645616531372, -0.7124143242835999, -0.09761584550142288, -0.08194709569215775, 0.5557563900947571, 0.7403116226196289, 0.4928671419620514, -1.1733266115188599, 0.8582818508148193, -0.04462094604969025, -0.09689468145370483, 0.5627570748329163, 0.15036582946777344, 0.08723222464323044, -0.5256626009941101, -0.7127062082290649, 0.0906771570444107, 0.25715020298957825, -1.0594156980514526, -0.33195433020591736, -0.8280023336410522, -1.329827904701233, -0.22828955948352814, 0.3839028477668762, -0.289847731590271, 1.3933100700378418, -0.3705344498157501, -0.6731122732162476, 0.7289698123931885, 0.14054162800312042, 0.4014575779438019, 0.48189881443977356, 0.38594967126846313, -0.5108136534690857, -1.0720816850662231, -0.17770718038082123, -0.00015816904488019645, 0.24632827937602997, -0.35631632804870605, 0.38049378991127014, 0.4971868395805359, -0.10528939962387085, -0.3785295784473419, -0.20242519676685333, 0.8206574320793152, -0.26066702604293823, -0.32564806938171387, 0.2821418046951294, 0.7318688631057739, 0.16176433861255646, -0.21996192634105682, -0.3478851914405823, -0.5884219408035278, 0.49783724546432495, -0.13563281297683716, 1.3819231986999512, -0.9165653586387634, -0.8900683522224426, -0.15039312839508057, -0.15541812777519226, 0.12438096106052399, -0.8342763781547546, 0.9159519672393799, -0.5365029573440552, 1.0507392883300781, -0.4623514711856842, -1.288704514503479, 0.006849793717265129, -0.34553638100624084, -0.3687925636768341, -0.19315943121910095, -0.09592915326356888, 1.162101149559021, -0.48042717576026917, 0.34329625964164734, -0.5165219306945801, -0.12254052609205246, -1.11641526222229, 0.9782113432884216, -0.28860077261924744, -0.305189847946167, 0.4670265316963196, 0.06498253345489502, 0.47528010606765747, -0.4880674481391907, 0.33795061707496643, -0.38770774006843567, -0.2653619945049286, 0.533307671546936, -0.32259395718574524, 1.64669668674469, -0.6610766053199768, 0.1956050843000412, -0.13347788155078888, -0.5197627544403076, 0.07322799414396286, 0.599033534526825, -0.28930363059043884, -0.3548254072666168, 0.38980212807655334, 0.6861969232559204, -0.5620288848876953, 0.25396355986595154, 0.9260187149047852, 0.43847590684890747, -0.33392244577407837, 0.5626856088638306, 0.7836460471153259, -0.5882229208946228, 0.64056795835495, 0.13606151938438416, 0.7382173538208008, -0.03966930881142616, 0.4407656192779541, -0.24972382187843323, 0.5003666281700134, -0.628032922744751, 0.12646237015724182, 0.006488758139312267, 0.6443799138069153, 0.7470483183860779, 0.453943133354187, -0.4135975241661072, -0.6241958737373352, 0.049540773034095764, 0.5168583989143372, 1.302825689315796, -0.4496690630912781, -0.30280518531799316, -0.8302456736564636, -0.5593451261520386, 0.027556225657463074, 0.2586251199245453, -0.3411983549594879, -0.5243710875511169, -0.14593730866909027, -0.8659536242485046, 0.9364967942237854, 0.3824419677257538, 0.7912079095840454, -0.18505145609378815, -0.41407203674316406, -0.3558102250099182, 0.4611123204231262, -0.6674897074699402, -0.7871733903884888, 0.500023603439331, -0.7815050482749939, -0.3798271417617798, 0.33282119035720825, -0.6226658225059509, 0.40938207507133484, -0.25081318616867065, 1.2913445234298706, 0.07522087544202805, -0.5823200941085815, 0.2506449818611145, 0.7151342630386353, -0.5103215575218201, -1.4986143112182617, 0.08720845729112625, -0.07353676110506058, -0.873918354511261, 0.5844998955726624, 0.6048233509063721, 0.6985229253768921, 0.43142804503440857, -0.7753705382347107, 0.05239633843302727, 0.12492185831069946, 0.11734342575073242, 0.44607236981391907, -0.08049552887678146, 0.33052122592926025, -1.058391809463501, 1.2146868705749512, -0.15324020385742188, -0.8669183850288391, 0.981636643409729, -0.8141324520111084, -0.27596932649612427, 0.7834604382514954, -0.4362795650959015, -0.17310895025730133, -1.531821608543396, 0.7061322331428528, -0.17852799594402313, 0.27397090196609497, 0.3274880349636078, 0.5153146386146545, -0.2293432652950287, 0.33789172768592834, 0.321204274892807, 0.5183832049369812, -0.32963261008262634, 0.1584922969341278, -0.4050062894821167, -0.0048927199095487595, 0.26263079047203064, 0.10514800995588303, -0.6546781659126282, -0.7591004371643066, -0.29517093300819397, 0.059314433485269547, -0.17899443209171295, 0.09444522112607956, 0.18060202896595, -0.40217992663383484, -0.9283866882324219, -0.17567428946495056, 0.0783502459526062, -0.9993743896484375, -0.3641555607318878, -0.202149897813797, -0.11941836029291153, -0.13439355790615082, -0.9755684733390808, -1.1230745315551758, -0.14141365885734558, -0.5701573491096497, -1.3989484310150146, 0.07696469128131866, 0.06792689114809036, -0.3825899660587311, -0.5333841443061829, 0.09067433327436447, -0.17637422680854797, 0.919272243976593, -0.899469792842865, 1.0594022274017334, 0.07992294430732727, 0.07531023025512695, 0.02107919007539749, -0.17949728667736053, 0.7981222867965698, -0.17983734607696533, 0.5163120627403259, -0.6742199063301086, -0.06261570006608963, 0.020344505086541176, -0.7815337777137756, -0.24155013263225555, 0.057862743735313416, 0.7051272392272949, 0.2683892846107483, -0.21109506487846375, 0.5400463938713074, 1.8009666204452515, -0.7894227504730225, -0.20181508362293243, -0.0689999908208847, 0.7610807418823242, 0.11989831179380417, -0.45994454622268677, 0.7331112027168274, -0.04193972051143646, 0.22442315518856049, -0.007274663541465998, 0.16600936651229858, -0.10299807786941528, -0.4170234203338623, 0.1399891972541809, 1.792715311050415, 0.5714317560195923, 0.21280144155025482, -1.3726240396499634, 0.9260561466217041, -0.9680700898170471, 0.040007904171943665, 0.5386608242988586, 1.035820722579956, 0.8531554937362671, -0.47358033061027527, -0.7754043340682983, -0.1410914659500122, 0.33815881609916687, 0.0003810632333625108, -0.46608781814575195, -0.7366805672645569, 0.21863698959350586, 0.4534482955932617, 0.3398590683937073, 0.2333400547504425, -0.08949271589517593, 0.26241791248321533, 14.713942527770996, 0.77396559715271, 0.24127927422523499, 1.0941270589828491, 0.2906467914581299, 0.12575379014015198, -0.7980676889419556, -0.2565366327762604, -0.9051544070243835, 0.035570453852415085, 1.0506387948989868, -0.1999559998512268, 0.7679508328437805, 0.4002738296985626, -0.12590603530406952, 0.0018805130384862423, -0.3927224576473236, 0.7820050120353699, 0.4902237057685852, -1.5998382568359375, 0.20966866612434387, 0.02694481983780861, 1.296870231628418, 0.6044303774833679, 0.7437359690666199, 0.8108600378036499, 0.3829183578491211, -0.5843551158905029, 0.3731509745121002, -0.27293169498443604, 1.1621301174163818, -0.23215150833129883, 0.8987837433815002, 0.5336551070213318, -0.6871574521064758, -0.2903662919998169, -0.8691317439079285, -1.0559074878692627, -0.19636094570159912, 0.23953235149383545, -0.9969937205314636, -0.4461027681827545, -0.4222750663757324, 0.5882111191749573, -0.4779011011123657, 0.4050990343093872, 0.08606498688459396, 0.19957202672958374, 0.24258355796337128, 0.5756509304046631, -0.023592691868543625, 0.5109568238258362, -0.2573124170303345, -0.16535601019859314, -0.020581217482686043, -0.7568032145500183, 0.17437881231307983, 0.6988895535469055, -0.9034847021102905, -0.08616885542869568, -0.3976883292198181, -0.4021453559398651, -0.08625156432390213, 0.3382168114185333, 0.5880895853042603, 0.2723730206489563, -0.8465465307235718, 0.2760833203792572, 1.0106158256530762, 0.16541877388954163, -0.33210477232933044, 0.49354666471481323, 0.8217940330505371, -0.32628223299980164, -0.2928682267665863, 0.25813329219818115, -0.5526573657989502, -0.44070979952812195, -0.24356479942798615, -0.34754109382629395, -0.05103997513651848, -0.6228105425834656, -0.742888867855072, 0.5167495608329773, -0.3287924528121948, -0.8034901022911072, 0.27055972814559937, -0.3779385983943939, 0.14226211607456207, 0.5582594871520996, -1.0973126888275146, -0.615989625453949, -0.06276864558458328, -0.33243072032928467, -0.1824064701795578, -0.5782769918441772, 1.0534099340438843, 0.41470542550086975, -0.5076797604560852, 0.5343658924102783, 0.4622059762477875, 0.025033362209796906, 0.15964749455451965, -0.4536667764186859, 1.158545970916748, 0.3566794991493225, -0.5970168709754944, 0.5916962027549744, -0.26955774426460266, -0.24327914416790009, -0.4827299118041992, -0.5353913307189941, 0.880408763885498, -0.7530120611190796, -0.20677722990512848, -0.6285576820373535, -0.9787918329238892, 0.390970915555954, 0.27599406242370605, -0.12175021320581436, 0.9727940559387207, -0.10167703032493591, -0.61072838306427, 0.2805382013320923, -1.2409559488296509, -0.14424723386764526, 0.7341510057449341, -1.3883119821548462, -0.24627678096294403, 0.23458126187324524, 0.310970276594162, -1.3259543180465698, -0.8245232105255127, -0.22239719331264496, -0.3337666392326355, -0.32375022768974304, 0.3253788650035858, -0.6161831617355347, 1.0522319078445435, 0.9731811881065369, -0.11243816465139389, -0.8907895088195801, -0.017396049574017525, -0.6200971007347107, 0.30689501762390137, 0.22794026136398315, 0.7976744174957275, -0.3160989582538605, 0.21174754202365875, 1.367490291595459, -0.052208736538887024, -0.06834292411804199, -0.5234013795852661, -0.3559216558933258, 0.21399027109146118, -0.6027355194091797, 0.3409130573272705, 0.43574288487434387, -0.06336908787488937, -0.2949707806110382, 0.646955132484436, 0.38726770877838135, -0.47774699330329895, -0.7019151449203491, 0.5736873149871826, 0.012372455559670925, -0.22317127883434296, -0.43190595507621765, -0.42062002420425415, -0.8398743867874146, 0.2683085799217224, -1.360026478767395, -0.03825651481747627, -0.35867589712142944, -0.29289743304252625, -0.20699496567249298, 0.20801110565662384, -0.17294549942016602, 0.7817468643188477, -0.3812902569770813, -0.5553419589996338, -0.19949345290660858, -0.21783447265625, 0.6127654314041138, 0.44979098439216614, -0.5172377824783325, -0.2392379343509674, -0.33212053775787354, -0.14751513302326202, 0.10194884985685349, 0.45525306463241577, -0.6616350412368774, -1.0107170343399048, -1.6100128889083862, 0.39392516016960144, -0.291382372379303, -0.07310797274112701, -0.6940416097640991, 0.8095181584358215, 0.2674124538898468, -0.36167392134666443, 0.5203808546066284, -0.5017951726913452, -1.2593748569488525, 0.026909183710813522, 0.3004092872142792, -0.4700273871421814, 0.4644072949886322, 0.6830089688301086, -0.8138807415962219, -0.3407260477542877, -0.0552806481719017, 0.08866634219884872, -1.0595691204071045, -0.7353168725967407, 0.23558691143989563, -0.235811248421669, 0.5282540321350098, 0.08285537362098694, -0.1318141371011734, -1.0678242444992065, 0.2300669103860855, 0.4428389072418213, 0.41679057478904724, 0.4804076850414276, 0.9726111888885498, 0.022239526733756065, -0.9322860240936279, 0.18381819128990173, 0.8193697333335876, 0.09990238398313522, 0.009183264337480068, 0.7172744870185852, 0.4002905786037445, -0.7228084206581116, 0.2158827930688858, 0.2878243923187256, 0.4465577304363251, -0.9025102257728577, -0.11118436604738235, 0.6678521633148193, -0.5187003016471863, 0.3386100232601166, 1.3821481466293335, -0.28778326511383057, -1.4187204837799072, -0.22478365898132324, -1.36233389377594, 0.15960927307605743, -0.5873490571975708, 0.37330496311187744, 0.2864043116569519, 0.6850590705871582, 0.1447151154279709, -0.5322068929672241, 0.1891361027956009, -0.20247194170951843, -0.06844540685415268, 0.418500155210495, -0.11363065987825394, -0.4145379960536957, 0.5099305510520935, 1.2378536462783813, -0.580349326133728, -0.5896296501159668, -0.7187842726707458, -0.5273406505584717, -0.39759400486946106, 0.2913164794445038, -0.4656715989112854, -0.765326738357544, 0.36445990204811096, 0.23659087717533112, -0.02204805426299572, -0.010789705440402031, -0.38637423515319824, -0.07632674276828766, 0.17170611023902893, 0.24631083011627197, -0.9346621036529541, -0.7152044177055359, 1.0363259315490723, 1.208497166633606, -1.4299744367599487, 0.4154011011123657, -0.0217305775731802, -0.7431599497795105, 0.9945809841156006, 0.669593870639801, 0.26642024517059326, 0.9114709496498108, 0.060518838465213776, -0.08330611884593964, 0.1237589418888092, -0.8356122374534607, 0.45722636580467224, 0.6646745204925537, 0.6243687868118286, 1.1693888902664185, 0.3341779112815857, -0.09465718269348145, 0.9826532602310181, 0.01116742379963398, 0.5400450229644775, 1.1345618963241577, 1.0748867988586426, 0.1481911540031433, -0.18451735377311707, 0.30741214752197266, 0.7812415361404419, -0.49450790882110596, -0.7389830946922302, -0.052241332828998566, 0.6034592986106873, 0.5413111448287964, 0.4244379699230194, 0.7882837653160095, -0.38887447118759155, 0.4667331278324127, 0.6903695464134216, 0.23977741599082947, -0.8320793509483337, -0.6815745234489441, -0.6103904843330383, -0.48662638664245605, 0.03390762582421303, -0.12137947976589203, -0.37872928380966187, -0.33618295192718506, -0.20938225090503693, 0.08903250098228455, -0.09019817411899567, 0.47409817576408386, 1.0765788555145264, 0.89421546459198, 0.5569489002227783, -0.3656487762928009, 0.13996872305870056, -0.6475926041603088, -0.8777052164077759, -0.09081189334392548, -0.41306617856025696, -0.32128071784973145, -0.05257760360836983, -0.1981617510318756, -0.2591031789779663]}, "authors": [{"authorId": "2279620921", "name": "Jos'e Antonio Hern'andez L'opez"}, {"authorId": "2237865625", "name": "Boqi Chen"}, {"authorId": "2279544583", "name": "Tushar Sharma"}, {"authorId": "2279547379", "name": "D'aniel Varr'o"}], "references": [{"paperId": "445c71912a718b6add8b79d01ee02aaadb51a5cb", "title": "A survey on machine learning techniques applied to source code"}, {"paperId": "e2d5f5ae4af1f6e9ff394bfcac523a6ea7a61621", "title": "A systematic literature review on source code similarity measurement and clone detection: techniques, applications, and challenges"}, {"paperId": "9ada8fa11b1cdece31f253acae50b62df8d5f823", "title": "CodeT5+: Open Code Large Language Models for Code Understanding and Generation"}, {"paperId": "3e4085e5869f1b7959707a1e1d7d273b6057eb4e", "title": "StarCoder: may the source be with you!"}, {"paperId": "4c4d97cd03267c77235e6a1487339ec26a6382f9", "title": "Towards Efficient Fine-Tuning of Pre-trained Code Models: An Experimental Study and Beyond"}, {"paperId": "4e3c65511292a800b17be6653bd057e7a545a0b0", "title": "An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation"}, {"paperId": "1bf21dabbdfc81fd4f9e92b1201ecce744cabb6a", "title": "SantaCoder: don't reach for the stars!"}, {"paperId": "42630c03d3817b1153d245f20742ad4b30a80b75", "title": "JEMMA: An extensible Java dataset for ML4Code applications"}, {"paperId": "2dc07d25a22467c01b6d5088ea148e58eb18cc2a", "title": "Parameter-Efficient Finetuning of Transformers for Source Code"}, {"paperId": "f3a6115e5fb2237df938976e005468f0b18da797", "title": "The Stack: 3 TB of permissively licensed source code"}, {"paperId": "95d4876594c2baad73e3f2f6d64469cd45aaac27", "title": "ASTRO: An AST-Assisted Approach for Generalizable Neural Clone Detection"}, {"paperId": "df1cc92fba512ce7d28d1d608ea19f18cda185ca", "title": "No more fine-tuning? an experimental evaluation of prompt tuning in code intelligence"}, {"paperId": "38c198185f216df2b9ea93454daf4466241f4805", "title": "NaturalCC: An Open-Source Toolkit for Code Intelligence"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "e2baf81813d5a515f554ee60bcddcc57548f8c22", "title": "Code Search: A Survey of Techniques for Finding Code"}, {"paperId": "38115e80d805fb0fb8f090dc88ced4b24be07878", "title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis"}, {"paperId": "4b27f18bff43d605805c92696a979714ced0b805", "title": "UniXcoder: Unified Cross-Modal Pre-training for Code Representation"}, {"paperId": "d407aa1cc3f9ce8478d3052344947fb49baa04d4", "title": "CodeFill: Multi-token Code Completion by Jointly learning from Structure and Naming Sequences"}, {"paperId": "775a9c722262c7b656876a5fef20f4577afd8981", "title": "Multilingual training for Software Engineering"}, {"paperId": "c23d9d44e8bc68408cea9f305d1f24d915bc0d0d", "title": "Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey"}, {"paperId": "a30f912f8c5e2a2bfb06351d4578e1ba3fa37896", "title": "CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation"}, {"paperId": "343594d16840c3841e70ca603f500a79c433848b", "title": "On the Evaluation of Neural Code Summarization"}, {"paperId": "952aee889b77417ce629bb583f850e787614a46e", "title": "On the Nature of Code Cloning in Open-Source Java Projects"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "0646bb09db4d1ba24150e69b71edcd4aff691b3c", "title": "Unified Pre-training for Program Understanding and Generation"}, {"paperId": "69a72ff5b30642d11c96635e99aadad3140d33a7", "title": "CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation"}, {"paperId": "4083958684292f6fa2f5c7fd4f9be975e80145b6", "title": "GraphCodeBERT: Pre-training Code Representations with Data Flow"}, {"paperId": "a2c0f78fbf5fc4421a97b265969b4c469e8c45b3", "title": "TranS^3: A Transformer-based Framework for Unifying Code Summarization and Code Search"}, {"paperId": "0fe2636446cd686830da3d971b31a004d6094b3c", "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages"}, {"paperId": "4a4646a5ce6b57e369403e4efea1a2e4559fe9f1", "title": "What Would Elsa Do? Freezing Layers During Transformer Fine-Tuning"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "b7af363ff612f41e0c1071ae24ce68a836aaa678", "title": "Code Generation as a Dual Task of Code Summarization"}, {"paperId": "fbe25e4f069a19dc63daca27b7c98cff338663b9", "title": "CodeSearchNet Challenge: Evaluating the State of Semantic Code Search"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "3092325d55f6aa9ba28b0841bdcfd61991a38d48", "title": "A Neural Model for Generating Natural Language Summaries of Program Subroutines"}, {"paperId": "8ace1951c95f9bbbcf83571ff6c0579521507e2e", "title": "The adverse effects of code duplication in machine learning models of code"}, {"paperId": "d13b77b2bbef250e92cacb0715e09b35cd289200", "title": "Overcoming Catastrophic Forgetting by Soft Parameter Pruning"}, {"paperId": "020ba12d8029a5689412ba12155613dd4267baa0", "title": "Cross-project code clones in GitHub"}, {"paperId": "49164d216b7e7968ded2d9863af161191f2c32e5", "title": "Summarizing Source Code with Transferred API Knowledge"}, {"paperId": "e033a0b29af2939fd44e5765d03380c08897a9e8", "title": "Deep Code Search"}, {"paperId": "a26b00c607b6d6a2697f5444f14a9afc37701444", "title": "D\u00e9j\u00e0Vu: a map of code duplicates on GitHub"}, {"paperId": "3807a517403cfc7ed67fdfea64baf62b9948bcfe", "title": "A Parallel Corpus of Python Functions and Documentation Strings for Automated Code Documentation and Code Generation"}, {"paperId": "95badade580eeff6a2f512268a017b9b66c6a212", "title": "Software Defect Prediction via Convolutional Neural Network"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "46003591181f3a4632355ac5c6184c43752c72a1", "title": "Stack Overflow in Github: Any Snippets There?"}, {"paperId": "32aa2517b03c871c11e521c2a3406f457833e2c3", "title": "Summarizing Source Code using a Neural Attention Model"}, {"paperId": "484ed558a5863060b373e8a2cb7cb302b8c36116", "title": "A Convolutional Attention Network for Extreme Summarization of Source Code"}, {"paperId": "e1abe96610cb3bc989e727f0b59cebedb14260f1", "title": "SourcererCC: Scaling Code Clone Detection to Big-Code"}, {"paperId": "9277dc7dd5b348645e8fcf4a987e5b3fc9132c7c", "title": "Towards a Big Data Curated Benchmark of Inter-project Code Clones"}, {"paperId": "37e2106bebd02f4ac9c410941fde7f358279e4a4", "title": "Defects4J: a database of existing faults to enable controlled testing studies for Java programs"}, {"paperId": "2d3efc22854e07d2b84c92446ef5e8cdd2c6b965", "title": "DECKARD: Scalable and Accurate Tree-Based Detection of Code Clones"}, {"paperId": "1e41ed1ac234cba0138329047e16a8a424389e77", "title": "A comparison of modified reconstructability analysis and Ashenhurst\u2010Curtis decomposition of Boolean functions"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "b584309dccafe64a7d6b96f064554330cbe1bbd3", "title": "Effect of scale on catastrophic forgetting in neural networks"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": null, "title": "\u201cAssessing generalizability of Code-BERT,\u201d"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "2209b7af4d41bc60f1b044a8305a49df77da1637", "title": "A Survey on Software Clone Detection Research"}, {"paperId": "c213af6582c0d518a6e8e14217611c733eeb1ef1", "title": "Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem"}, {"paperId": null, "title": "We provide evidence of a potential threat to the evaluations of various LLMs due to inter-dataset code duplication"}, {"paperId": null, "title": "\u201cBreaking the silence: the threats of using llms in software engineering,\u201d"}, {"paperId": null, "title": "\u201cExplor-ing parameter-efficient fine-tuning techniques for code generation with large language models,\u201d"}]}