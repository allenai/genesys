{"paperId": "8444b6982b5fa799e016e20f833594bb2f9ab12e", "title": "UniCoder: Scaling Code Large Language Model via Universal Code", "abstract": "Intermediate reasoning or acting steps have successfully improved large language models (LLMs) for handling various downstream natural language processing (NLP) tasks. When applying LLMs for code generation, recent works mainly focus on directing the models to articulate intermediate natural-language reasoning steps, as in chain-of-thought (CoT) prompting, and then output code with the natural language or other structured intermediate steps. However, such output is not suitable for code translation or generation tasks since the standard CoT has different logical structures and forms of expression with the code. In this work, we introduce the universal code (UniCode) as the intermediate representation. It is a description of algorithm steps using a mix of conventions of programming languages, such as assignment operator, conditional operator, and loop. Hence, we collect an instruction dataset UniCoder-Instruct to train our model UniCoder on multi-task learning objectives. UniCoder-Instruct comprises natural-language questions, code solutions, and the corresponding universal code. The alignment between the intermediate universal code representation and the final code solution significantly improves the quality of the generated code. The experimental results demonstrate that UniCoder with the universal code significantly outperforms the previous prompting methods by a large margin, showcasing the effectiveness of the structural clues in pseudo-code.", "venue": "arXiv.org", "year": 2024, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The experimental results demonstrate that UniCoder with the universal code significantly outperforms the previous prompting methods by a large margin, showcasing the effectiveness of the structural clues in pseudo-code."}, "embedding": {"model": "specter_v2", "vector": [0.27368879318237305, 0.9250537753105164, -0.3302367031574249, 0.05933716520667076, -0.5428785681724548, -0.6470337510108948, 0.1984332650899887, 0.4213876724243164, -0.020315250381827354, 0.030654551461338997, 0.7858737707138062, -0.9671841263771057, 0.4475278854370117, 0.21063947677612305, -0.23047605156898499, 0.1954369843006134, -0.4535326063632965, 0.019542045891284943, -0.3846840262413025, -0.1931678056716919, 0.04642846807837486, -0.7262070178985596, -0.7531508207321167, 0.2750551998615265, 1.1214388608932495, -0.14184634387493134, 0.29885515570640564, 1.1877325773239136, -0.5701209306716919, 0.9037433862686157, 0.524162232875824, -0.32753458619117737, 0.20356807112693787, -0.2776208817958832, -0.6944940686225891, -0.250162273645401, 0.17826330661773682, -0.6214774250984192, -0.034127503633499146, 0.8372430205345154, -0.19024799764156342, 0.029049620032310486, 0.43301811814308167, -0.4663408398628235, -0.6270785927772522, 1.134166955947876, 0.812195360660553, 0.5976595878601074, 0.4616917669773102, -0.14340952038764954, 1.4312154054641724, -1.1218841075897217, 0.37866491079330444, 1.4145938158035278, 0.3056122064590454, 0.7961034178733826, -0.2418731153011322, -0.1773177683353424, 0.26732081174850464, -0.2626659572124481, -0.6446242332458496, -0.20651446282863617, -0.5180975794792175, -0.2180168628692627, 1.955450415611267, -0.6256141662597656, -0.38136398792266846, 0.1645703762769699, 0.13669045269489288, 1.424719214439392, -0.2523452937602997, -1.1008909940719604, -0.25693145394325256, -0.04208841174840927, 0.34314101934432983, 1.151607871055603, -0.22733524441719055, 0.18561691045761108, -0.4450710415840149, 0.03279661014676094, 0.8293462991714478, -0.1715075522661209, -0.5757942199707031, -0.061609573662281036, -0.5523518323898315, 0.6546543836593628, 0.3073008060455322, 0.9009253978729248, 0.010965007357299328, 0.4504014849662781, 0.4251653254032135, 0.41082751750946045, -0.587268590927124, 0.6670730710029602, -0.6132100820541382, 0.08604562282562256, -0.26386159658432007, 0.22870716452598572, 0.20307278633117676, 0.9530304670333862, -0.08298693597316742, -0.006611189339309931, -0.9812459945678711, -0.07423456013202667, 1.1943947076797485, 0.12221021950244904, 0.6627106666564941, -0.9348955750465393, 0.6026827692985535, -0.2606986165046692, 0.07914873957633972, -0.2811966836452484, -0.29540005326271057, -0.21285703778266907, -0.10867956280708313, -1.203424096107483, 0.03982273489236832, -0.5801745057106018, -0.4683069586753845, 0.8633041977882385, -0.15877600014209747, -0.4044800400733948, 0.8451583385467529, 0.46243414282798767, 0.6580596566200256, 0.6445322632789612, 0.24128735065460205, 0.03347652778029442, 0.9334603548049927, -0.8560047149658203, -0.5953623652458191, -1.013366460800171, 1.125974416732788, -0.37309449911117554, 0.3470074534416199, -0.4146019518375397, -1.0624016523361206, -1.2920352220535278, -0.662863552570343, -0.2245580106973648, -0.126495823264122, 0.2914847433567047, 1.3496487140655518, 0.2761649787425995, -1.1459351778030396, 0.6240139603614807, 0.07690075039863586, -0.43327537178993225, -0.17458170652389526, -0.21475625038146973, 0.3306864798069, -0.7522605061531067, -1.1763763427734375, -0.15056152641773224, 0.3571106791496277, -0.7814573049545288, -0.32662251591682434, -0.4381538927555084, -1.4832549095153809, -0.2249639928340912, 0.31562259793281555, -0.4075463116168976, 1.954179048538208, -0.032889436930418015, -1.2268205881118774, 0.19298017024993896, -0.23447750508785248, 0.4002492129802704, -0.14079712331295013, -0.11455672979354858, -0.43180447816848755, -0.13267947733402252, 0.32125124335289, 0.8929357528686523, -0.04006291180849075, -0.2792360484600067, -0.5069074630737305, 0.4710097312927246, 0.30178913474082947, -0.0507696233689785, -0.15018217265605927, 1.0597093105316162, 0.11658598482608795, -0.10584994405508041, 0.36172714829444885, 0.8890413641929626, -0.2894495129585266, 0.01766299456357956, -0.2992296814918518, -1.3607206344604492, 0.3207801282405853, 0.050031229853630066, 1.0818142890930176, -0.9180508852005005, -0.5041705369949341, -0.8029650449752808, -0.18868689239025116, -0.1302083432674408, -0.8307403326034546, 0.7218073606491089, -0.6957253217697144, 0.4477028250694275, -0.5942319631576538, -0.4450802803039551, -0.07392411679029465, -0.05913285166025162, -0.7045522332191467, -0.6565521955490112, 0.4324598014354706, 1.0120354890823364, -1.1636474132537842, -0.15982888638973236, -0.25564080476760864, -0.4557201862335205, -1.0619360208511353, 1.4129540920257568, -0.6181122660636902, 0.13750651478767395, -0.30047091841697693, -0.18236951529979706, -0.09247467666864395, -0.13536471128463745, 0.2677927017211914, -0.042393721640110016, -0.2860478162765503, 0.46679145097732544, -0.3452283442020416, 1.6552094221115112, -0.33891111612319946, 0.3269015848636627, -0.1480484902858734, -0.313204288482666, 0.14247140288352966, 0.7059831023216248, -0.5941377282142639, -0.25819170475006104, 0.13955213129520416, 0.7198352813720703, -0.14814944565296173, -0.7074428796768188, 0.4903935492038727, 0.47321054339408875, -0.42761868238449097, 0.7980608940124512, 0.7607772350311279, -0.5231562256813049, 0.8465161919593811, 0.6771847009658813, 0.7822702527046204, 0.4715401828289032, 0.8528788685798645, -0.0346468947827816, 0.5472439527511597, -0.5213595032691956, -0.2194247543811798, 0.2638344466686249, 0.40998145937919617, 0.9705833196640015, 0.6565354466438293, -0.7712218165397644, 0.22395986318588257, 0.20631243288516998, 0.6712467074394226, 1.4260108470916748, -0.14857251942157745, -0.2870814800262451, -0.9487072825431824, -0.7682797908782959, -0.3215106725692749, 0.5420709848403931, -0.20154665410518646, -0.2553587555885315, -0.4701831042766571, -0.6355751752853394, 0.6228918433189392, 0.44615674018859863, 0.8198683857917786, -0.7695134282112122, -0.265883207321167, -0.14838814735412598, -0.0980566218495369, -0.7870072722434998, -0.6957123875617981, 0.6955389976501465, -0.5474685430526733, -0.6509851217269897, 0.40561816096305847, -0.42842617630958557, 0.3296774923801422, -0.4038386344909668, 0.7506999373435974, -0.2456529587507248, -0.3069899380207062, 0.21286986768245697, 0.2599555253982544, -0.2254560887813568, -1.156108021736145, -0.08142457902431488, -0.22741389274597168, -0.26398396492004395, 0.6088767647743225, 0.5979569554328918, 0.40224725008010864, -0.359192430973053, -0.6502295732498169, 0.15688100457191467, 0.2945549190044403, -0.2917866110801697, 0.2779942750930786, -0.4609571695327759, -0.3740404546260834, -1.0109893083572388, 1.3221023082733154, 0.18606846034526825, -0.12812303006649017, 0.19995489716529846, -0.465913325548172, 0.09329230338335037, 0.9674280881881714, -0.3933446407318115, -0.08089759945869446, -0.7795926928520203, 0.5574508309364319, 0.45239418745040894, -0.5910633206367493, 0.3783700168132782, 0.1663871705532074, 0.1862449049949646, 0.6642023324966431, 0.35016727447509766, 0.3141672611236572, -0.07272419333457947, 0.610378623008728, -0.4621729254722595, 0.4576863944530487, -0.12791816890239716, 0.2393609881401062, -0.8141652941703796, -0.7291839122772217, -0.09791501611471176, -0.433846652507782, -0.06873540580272675, -0.23711375892162323, -0.0765974223613739, 0.4690288305282593, -0.5764478445053101, -0.6570797562599182, -0.5360788106918335, -1.5576094388961792, -0.415214866399765, -0.09689196944236755, -0.3284778892993927, -0.03589199110865593, -0.7928786873817444, -1.159996509552002, -0.12337309867143631, -0.25654274225234985, -1.1108334064483643, 0.5105773210525513, 0.24354678392410278, -0.5515084862709045, -0.33770638704299927, 0.32892826199531555, -0.24510109424591064, 0.5852519273757935, -0.7429559826850891, 1.3424761295318604, 0.09517562389373779, -0.12020213901996613, 0.09668068587779999, -0.013149380683898926, 0.3439392149448395, 0.17899198830127716, 0.47879520058631897, -0.32071003317832947, 0.444009393453598, -0.06317818909883499, -0.8929096460342407, -0.2783488631248474, -0.1890401393175125, 0.30884066224098206, -0.0310873594135046, -0.24934044480323792, 0.10413366556167603, 1.4284383058547974, -0.5279950499534607, -0.036548420786857605, -0.07469223439693451, 1.0200356245040894, 0.8481135368347168, -0.1429537534713745, 0.24706292152404785, 0.5098903775215149, 0.030450036749243736, 0.0840667262673378, 0.17065595090389252, -0.262723833322525, -0.6146796941757202, 0.9882502555847168, 1.3593913316726685, 0.4714975655078888, 0.3160695731639862, -1.4845243692398071, 0.4698120057582855, -1.2387043237686157, -0.0695466622710228, 0.1955440193414688, 0.20568247139453888, 0.7390070557594299, -0.7853317856788635, -0.8899087309837341, 0.029976874589920044, 0.5302883386611938, -0.01696162298321724, -0.027153685688972473, -0.9125291109085083, 0.45071128010749817, 0.05024566501379013, -0.4395819306373596, 0.8582178354263306, -0.2520080506801605, 0.5011019706726074, 14.62032413482666, 0.6883739233016968, -0.07126689702272415, 0.40708717703819275, 0.5126355886459351, 0.7816310524940491, -0.6468493342399597, -0.11528286337852478, -1.142296552658081, -0.6920073628425598, 1.3323173522949219, 0.09152399003505707, 0.5938222408294678, 0.10352147370576859, -0.012754471972584724, -0.006064101122319698, -0.6403149366378784, 0.5535537600517273, 0.5831071734428406, -0.8297461867332458, 0.7651767730712891, 0.05076083540916443, 0.4202914237976074, 0.11042270809412003, 0.2248273491859436, 1.0349102020263672, 0.6727765798568726, -0.33608028292655945, 0.650911271572113, -0.4687900245189667, 0.7843468189239502, 0.09009768813848495, 0.6319116353988647, 0.6453179717063904, -0.8638916611671448, -0.7887151837348938, -0.5393375158309937, -1.4728912115097046, -0.057122066617012024, -0.12812350690364838, -0.6481721997261047, -0.4305923581123352, -0.7149861454963684, 0.5541090965270996, -0.11860556155443192, 0.23229902982711792, -0.9951868653297424, 0.4006294906139374, 0.29584044218063354, -0.4311312735080719, 0.1087779551744461, 0.6861419081687927, 0.16968004405498505, -0.37920939922332764, -0.005963674280792475, 0.4710465967655182, 0.3387214243412018, 0.66987544298172, -0.47697576880455017, 0.3382508456707001, -0.4992275536060333, -0.3466842472553253, -0.17391833662986755, 0.8824774622917175, 0.11707600951194763, 0.5254534482955933, -0.554024338722229, 0.15593001246452332, 0.9677066802978516, 0.2588317394256592, 0.09238116443157196, -0.35682225227355957, 0.1460171490907669, -0.40235772728919983, -0.2060755044221878, 0.4760923683643341, -0.17902885377407074, -0.4295078217983246, -0.6728565096855164, -0.6730916500091553, 0.2257605344057083, -1.0265774726867676, -0.2990986108779907, 0.9906460642814636, -0.4078918993473053, -1.0230764150619507, 0.013454990461468697, -0.8668358325958252, -0.5430158972740173, 0.021460067480802536, -1.2678096294403076, -0.4956193268299103, 0.20397843420505524, -0.2523559629917145, -0.2872401475906372, 0.03924647346138954, 1.5054703950881958, -0.2839262783527374, -0.6763665080070496, -0.2381257265806198, -0.24875223636627197, 0.20924046635627747, -0.262106329202652, -1.204296350479126, 0.5780198574066162, 0.8574187159538269, -0.14691337943077087, 0.6330868005752563, 0.0016329095233231783, 0.0003839376731775701, -0.7050340175628662, -0.2653448283672333, 0.9492341876029968, -0.8000088334083557, -0.1019461378455162, -0.8645691275596619, -0.6502092480659485, 0.006039838306605816, 0.6632868051528931, -0.10783574730157852, 0.5325323343276978, -0.2609337866306305, -0.5290910601615906, -0.12449046969413757, -0.9118118286132812, 0.1000853106379509, 0.3967127203941345, -0.7711789608001709, -0.5297489166259766, 0.18954059481620789, 1.1811764240264893, -0.6485361456871033, -0.3056204319000244, -0.4921782910823822, -0.2726050317287445, 0.22222007811069489, 0.09420043230056763, -0.5948768854141235, 1.4296084642410278, 0.5936294198036194, -0.1671687513589859, -0.6033996939659119, 0.12340748310089111, -1.3069422245025635, 0.2374974489212036, 0.2455572783946991, 1.264458179473877, -0.445045530796051, -0.2619918882846832, 1.2433770895004272, 0.014177831821143627, -0.3424467146396637, -0.3602263927459717, 0.38569942116737366, 0.2863260507583618, -0.6767329573631287, 0.4731367230415344, -0.3463849127292633, 0.5852003693580627, 0.31197255849838257, 1.1962097883224487, 0.6033839583396912, -0.4832623600959778, -0.2403344362974167, 0.4413736164569855, 0.07979357242584229, -0.28441867232322693, -0.24975097179412842, -0.14045561850070953, -1.5122730731964111, -0.07508290559053421, -1.3349617719650269, 0.679551362991333, -0.9297549724578857, -0.2297082245349884, 0.3983982801437378, 0.011889221146702766, 0.2789846956729889, -0.06185149401426315, -0.5301934480667114, -0.5895733833312988, -0.5585562586784363, -0.626997709274292, 0.7593255639076233, 1.1446568965911865, -0.4190424084663391, 0.15724727511405945, -0.2524454891681671, -0.6197596192359924, 0.04986358433961868, 0.1636866182088852, -0.43085145950317383, -0.6915021538734436, -1.4261932373046875, 0.3860798180103302, 0.03785749152302742, -0.31523194909095764, -0.7876068949699402, 0.7821187973022461, 0.5898842215538025, -0.40520569682121277, 0.5373204946517944, -0.6179029941558838, -0.7622683644294739, -1.0656037330627441, 0.5902685523033142, -0.7976348996162415, 0.28263676166534424, 0.42013058066368103, -0.5913793444633484, -0.4617982804775238, -0.11696246266365051, -0.4981640875339508, -1.1330469846725464, -0.5808075666427612, 0.16414903104305267, -0.8303842544555664, 0.07491517812013626, -0.04810212180018425, -0.026337699964642525, -0.9520782232284546, -0.2092457264661789, 0.5208963751792908, 0.33105146884918213, -0.3080447316169739, 1.0782808065414429, 0.3628576993942261, -0.8328360915184021, 0.1874774992465973, 0.48320305347442627, 0.04310862347483635, 0.13824127614498138, -0.04656870290637016, 0.12917017936706543, -0.8729677200317383, 0.6979786157608032, 0.36438852548599243, 0.2833573818206787, -0.6475110650062561, 0.07748919725418091, 0.6905063986778259, -0.44261112809181213, 0.13053198158740997, 1.0534234046936035, -0.5478845238685608, -1.5584125518798828, 0.029212698340415955, -1.6042563915252686, -0.8175308704376221, -0.6495811343193054, 0.851140558719635, -0.17538012564182281, -0.08665135502815247, 0.02180357091128826, -0.16913223266601562, 0.288323312997818, 0.14974558353424072, -0.29951924085617065, 0.42496004700660706, -0.048055898398160934, -0.8711994886398315, 0.1625855565071106, 0.5883005261421204, -0.6280121207237244, -0.44138410687446594, -0.1675036996603012, -0.4131394922733307, 0.15951555967330933, -0.02116105519235134, -0.20618155598640442, -0.3678526282310486, 0.8132635354995728, 0.1596575826406479, 0.3233162760734558, 0.10174860060214996, -0.22750505805015564, 0.14795786142349243, 0.6082226634025574, 0.34413468837738037, -0.12254973500967026, -0.23353935778141022, 1.1656235456466675, 1.3730496168136597, -1.115720272064209, -0.165572851896286, -0.46009039878845215, -0.47736799716949463, 1.3879469633102417, 0.9285093545913696, 0.27634069323539734, 0.5621743202209473, -0.16977441310882568, 0.3395771086215973, 0.2284258008003235, -0.9437360167503357, -0.09558447450399399, 0.16616502404212952, 1.0427427291870117, 1.1740496158599854, 0.35590749979019165, -0.23253321647644043, 1.0166302919387817, 0.028682228177785873, 0.2544298768043518, 0.9829926490783691, 0.6645606160163879, -0.290779173374176, -0.2598770558834076, -0.2196204662322998, 0.42675626277923584, -0.2706252336502075, -0.8348761796951294, 0.1787765920162201, 0.41210293769836426, 0.40848132967948914, 0.9418930411338806, 0.3552255928516388, 0.30226489901542664, 0.5333585739135742, 0.23295283317565918, 0.3307879865169525, -1.1737245321273804, -0.29496049880981445, -0.4827131927013397, -0.6532617807388306, -0.26356789469718933, -0.07305201888084412, -0.38728392124176025, -0.9601299166679382, 0.15864887833595276, 0.3662610948085785, 0.3244926333427429, 0.16690640151500702, 1.0968108177185059, 0.564076840877533, 0.4499230682849884, -0.3238164186477661, -0.3200603127479553, -0.4827117621898651, -1.3010499477386475, 0.29006537795066833, -0.9198458790779114, -0.31125980615615845, 0.19665798544883728, -0.23402662575244904, -0.02059609442949295]}, "authors": [{"authorId": "2284180939", "name": "Tao Sun"}, {"authorId": "2165382882", "name": "Linzheng Chai"}, {"authorId": "2276103971", "name": "Jian Yang"}, {"authorId": "2109472880", "name": "Yuwei Yin"}, {"authorId": "2234806", "name": "Hongcheng Guo"}, {"authorId": "2182423032", "name": "Jiaheng Liu"}, {"authorId": "2275240628", "name": "Bing Wang"}, {"authorId": "46554649", "name": "Liqun Yang"}, {"authorId": "2258837278", "name": "Zhoujun Li"}], "references": [{"paperId": "79dc4eea8557862015fe5edc58b700e1637c0fb1", "title": "MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series"}, {"paperId": "6415a2521fe9bd27baaecd25abd8eaac8eae48b9", "title": "m3P: Towards Multimodal Multilingual Translation with Multimodal Prompt"}, {"paperId": "16861054ec33d376d8f0182f7bec89f118c70ef9", "title": "Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging"}, {"paperId": "1f2a20a6efaf83214861dddae4a38a83ae18fe32", "title": "DeepSeek-Coder: When the Large Language Model Meets Programming - The Rise of Code Intelligence"}, {"paperId": "606b535686f98015ea8dd3c9ba8aa9243bc9dc2d", "title": "xCoT: Cross-lingual Instruction Tuning for Cross-lingual Chain-of-Thought Reasoning"}, {"paperId": "6346dd1e2426e51d2ab8b7eef017714d2d60ed22", "title": "CodeTransOcean: A Comprehensive Multilingual Benchmark for Code Translation"}, {"paperId": "467924b6967b6e0a074ca0c62f824fa99215f985", "title": "Large Language Models for Compiler Optimization"}, {"paperId": "b092ac4a0bcfec38eae7819e40fd8c9e97f4cc7f", "title": "Can Programming Languages Boost Each Other via Instruction Tuning?"}, {"paperId": "0b0debb710366cdff461938c80763eace1651af6", "title": "Code Llama: Open Foundation Models for Code"}, {"paperId": "ba4aa83248a1d08b521392eb971e47d10b7c74e1", "title": "Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought"}, {"paperId": "41a2e7c079179ae94557d3198de674a16a5987a6", "title": "Refining ChatGPT-Generated Code: Characterizing and Mitigating Code Quality Issues"}, {"paperId": "454c8fef2957aa2fb13eb2c7a454393a2ee83805", "title": "WizardCoder: Empowering Code Large Language Models with Evol-Instruct"}, {"paperId": "06a9645ed92c628f4bc237218c4265d6db68beb2", "title": "Machine-Created Universal Language for Cross-lingual Transfer"}, {"paperId": "05526b42336c74298ca4ccbcb792107900574062", "title": "Prompting with Pseudo-Code Instructions"}, {"paperId": "77b85c027bdaea07db4c86b59665600cedaeeb92", "title": "Improving ChatGPT Prompt for Code Generation"}, {"paperId": "94beb9f249d6d2f1c00d8edfa2db861633aee6f9", "title": "Structured Chain-of-Thought Prompting for Code Generation"}, {"paperId": "b45ec1cb2ba6b2d1ac24723fa836aee06a3db97a", "title": "Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation"}, {"paperId": "131f499e4d3503da93022d07fcf804a18483bea9", "title": "WizardLM: Empowering Large Language Models to Follow Complex Instructions"}, {"paperId": "ba2f935d2578fbf77ec1aa79e26e3db396771e38", "title": "Self-collaboration Code Generation via ChatGPT"}, {"paperId": "470754e17de89081f63dde4719922fe9b63251d5", "title": "Large Language Models are Edge-Case Fuzzers: Testing Deep Learning Libraries via FuzzGPT"}, {"paperId": "bafe023fb072045dc0cd50316382a61c8dcb9fae", "title": "CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Benchmarking on HumanEval-X"}, {"paperId": "af5c7848417882012203ac21399977ebda695a2b", "title": "RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation"}, {"paperId": "1bf21dabbdfc81fd4f9e92b1201ecce744cabb6a", "title": "SantaCoder: don't reach for the stars!"}, {"paperId": "e1b732e02cd6f41e4e1eb793ec4b356cee2587f1", "title": "ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages"}, {"paperId": "8a4fc5f00cd4aca61e148e46a2125c3a406719f1", "title": "DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation"}, {"paperId": "780f7eebde16b1ae5843df3a79a7772899ef6a71", "title": "MultiPL-E: A Scalable and Extensible Approach to Benchmarking Neural Code Generation"}, {"paperId": "876eb375cb7b365475040046df669c039ad54202", "title": "CodeT: Code Generation with Generated Tests"}, {"paperId": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large Language Models are Zero-Shot Reasoners"}, {"paperId": "5288b9f3a9f575543f44c39e1d3b78b3ca4c99da", "title": "InCoder: A Generative Model for Code Infilling and Synthesis"}, {"paperId": "5cbe278b65a81602a864184bbca37de91448a5f5", "title": "Competition-level code generation with AlphaCode"}, {"paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea", "title": "Training Verifiers to Solve Math Word Problems"}, {"paperId": "af95bc91c4af75540f89281c8992965588f12ee5", "title": "Skeleton-Aware Neural Sign Language Translation"}, {"paperId": "df6f3c607ae3956db722f76f3f81e672c3dfa803", "title": "CodeQA: A Question Answering Dataset for Source Code Comprehension"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "a30f912f8c5e2a2bfb06351d4578e1ba3fa37896", "title": "CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation"}, {"paperId": "a38e0f993e4805ba8a9beae4c275c91ffcec01df", "title": "Program Synthesis with Large Language Models"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "ac3cdb50606f7770eef8e4cd951840a4f71287a0", "title": "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm"}, {"paperId": "c297430bcb8511d16df60a7425e6846260d144b9", "title": "Improving Neural Machine Translation with Soft Template Prediction"}, {"paperId": "805a6d1df9f460abfcea3d51d181cf1e80680be4", "title": "A Transformer-based Approach for Source Code Summarization"}, {"paperId": "10467a1466aeec246ac0a577bfc311ec4de110de", "title": "Alternating Language Modeling for Cross-Lingual Pre-Training"}, {"paperId": "427b717d9323e834467b433c6b2561b77c0467d8", "title": "Low-Resource Response Generation with Template Prior"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "27e1dbe9f7c71cd6cc1b0357f49aef497e572d09", "title": "Learning to Generate Pseudo-Code from Source Code Using Statistical Machine Translation (T)"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "362cae35fb65710af8230a4ee8e1aad1f275a4e7", "title": "WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with Refined Data Generation"}, {"paperId": null, "title": "Code-bert: A pre-trained model for programming and nat-ural languages"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "2023. Gpt-4 technical report"}, {"paperId": null, "title": "2024. R2c2-coder: Enhancing and benchmarking real-world repository-level code completion abilities of code large language models"}, {"paperId": null, "title": "2024. E2-llm: Efficient and extreme length extension of large language models"}, {"paperId": null, "title": "2024. D-cpt law: Domain-specific continual pre-training scaling law for large language models"}, {"paperId": null, "title": "2024. Sev-enllm: Benchmarking, eliciting, and enhancing abilities of large language models in cyber threat intelligence"}, {"paperId": null, "title": "2023. Dynamic planning with a LLM"}, {"paperId": null, "title": "2022. UM4: unified multilingual multiple teacher-student model for zero-resource neural machine translation"}, {"paperId": null, "title": "2023. Magicoder: Source code is all you need"}, {"paperId": null, "title": "2023. Code translation with compiler representations"}, {"paperId": null, "title": "2023. Codefuse-13b: A pretrained multi-lingual code large language model"}, {"paperId": null, "title": "2023. Tree of thoughts: Deliberate problem solving with large language models"}]}