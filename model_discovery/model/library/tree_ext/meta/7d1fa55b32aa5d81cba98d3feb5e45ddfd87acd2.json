{"paperId": "7d1fa55b32aa5d81cba98d3feb5e45ddfd87acd2", "title": "A Close Look at Spatial Modeling: From Attention to Convolution", "abstract": "Vision Transformers have shown great promise recently for many vision tasks due to the insightful architecture design and attention mechanism. By revisiting the self-attention responses in Transformers, we empirically observe two interesting issues. First, Vision Transformers present a queryirrelevant behavior at deep layers, where the attention maps exhibit nearly consistent contexts in global scope, regardless of the query patch position (also head-irrelevant). Second, the attention maps are intrinsically sparse, few tokens dominate the attention weights; introducing the knowledge from ConvNets would largely smooth the attention and enhance the performance. Motivated by above observations, we generalize self-attention formulation to abstract a queryirrelevant global context directly and further integrate the global context into convolutions. The resulting model, a Fully Convolutional Vision Transformer (i.e., FCViT), purely consists of convolutional layers and firmly inherits the merits of both attention mechanism and convolutions, including dynamic property, weight sharing, and short- and long-range feature modeling, etc. Experimental results demonstrate the effectiveness of FCViT. With less than 14M parameters, our FCViT-S12 outperforms related work ResT-Lite by 3.7% top1 accuracy on ImageNet-1K. When scaling FCViT to larger models, we still perform better than previous state-of-the-art ConvNeXt with even fewer parameters. FCViT-based models also demonstrate promising transferability to downstream tasks, like object detection, instance segmentation, and semantic segmentation. Codes and models are made available at: https://github.com/ma-xu/FCViT.", "venue": "arXiv.org", "year": 2022, "citationCount": 5, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2212.12552", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "The resulting model, a Fully Convolutional Vision Transformer (i.e., FCViT), purely consists of convolutional layers and firmly inherits the merits of both attention mechanism and convolutions, including dynamic property, weight sharing, and short- and long-range feature modeling, etc."}, "embedding": {"model": "specter_v2", "vector": [0.623151957988739, 0.5295689105987549, -0.40356743335723877, -0.07543222606182098, -0.18590375781059265, 0.05998453125357628, 0.6397008299827576, -0.4119299650192261, -0.5942662954330444, -0.8821019530296326, 0.48186036944389343, 0.6585434675216675, 0.29850831627845764, -0.18962128460407257, -0.2555217444896698, 0.2050444334745407, -0.4648679494857788, 0.005493516102433205, 1.1076335906982422, -0.4721450209617615, 0.2657758295536041, -0.5115944743156433, -1.367714524269104, 0.3347412645816803, 0.11697492003440857, 1.0266599655151367, 0.7577683329582214, 0.8436323404312134, -0.10581715404987335, 0.35430753231048584, 0.3412642776966095, -0.34923428297042847, 0.43279746174812317, 0.18367160856723785, -0.5497440099716187, -0.03787834569811821, 0.850913941860199, -0.14511752128601074, -0.742165207862854, 1.1606099605560303, -0.1756175011396408, 0.31717538833618164, 0.39530307054519653, -0.6627815961837769, -0.44178086519241333, 0.15539947152137756, 0.41791224479675293, 0.9701919555664062, -0.6992581486701965, -0.5834890604019165, 1.4313478469848633, -0.9625624418258667, 0.09129355102777481, 1.6106575727462769, 0.4239805042743683, 0.1419696807861328, -0.03927086666226387, -0.10266910493373871, 0.7668248414993286, 0.2953323423862457, -0.6252396106719971, -0.2087082713842392, 0.2325781285762787, -0.08907387405633926, 1.5611164569854736, -0.3021624684333801, 0.1716199368238449, 0.4529610872268677, -0.09865837544202805, 1.5753552913665771, -0.08693265914916992, -0.6786291003227234, -0.20418675243854523, -0.1795063316822052, 0.49839115142822266, 0.655022382736206, -0.23664891719818115, 0.31949383020401, -0.5140904784202576, 0.15955950319766998, 1.0173864364624023, 0.2495843917131424, 0.4250202476978302, -0.448612779378891, -0.2606448531150818, 0.4233717620372772, 1.176174283027649, 0.7322869300842285, -0.454388827085495, 1.1482592821121216, 0.4137990474700928, -0.1909983903169632, -0.16800366342067719, 0.3492523729801178, -0.10778387635946274, 0.9995449185371399, -0.861848771572113, 0.05903693288564682, -0.3130902945995331, 1.0891202688217163, -0.12528298795223236, 0.003762387903407216, -0.4284788966178894, 0.18736015260219574, 1.0853441953659058, 0.1409027874469757, 0.4049660563468933, -0.8731728792190552, 0.030792538076639175, -0.6157748699188232, -0.03615763783454895, -0.876294732093811, -0.013391426764428616, -0.5516117811203003, -0.5520237684249878, -0.8902723789215088, -0.2708013951778412, 0.8049766421318054, -1.1015568971633911, 0.3749734163284302, -0.2474185973405838, 0.2625623345375061, -0.08661945909261703, 0.7658188343048096, 0.580278217792511, 0.3055002987384796, 0.5564746856689453, 0.7841647863388062, 1.6621730327606201, -1.2801282405853271, -0.09644642472267151, -1.0850543975830078, -0.2064361721277237, -0.31954488158226013, 0.45179569721221924, -0.4425407946109772, -1.068497657775879, -1.5073707103729248, -0.6870591044425964, -0.13331416249275208, -0.9416841864585876, 0.18434518575668335, 1.1520434617996216, 0.169233500957489, -1.3632667064666748, 0.8536326289176941, -0.31719815731048584, -0.682913064956665, 0.9438689947128296, -0.10775332152843475, 0.28574109077453613, -0.21986544132232666, -1.109945297241211, 0.2955952286720276, -0.021031217649579048, -0.46580612659454346, -0.2904631197452545, -0.45887458324432373, -1.2676012516021729, 0.14281761646270752, 0.5060000419616699, -0.9280607104301453, 1.131076455116272, -0.5749701261520386, -0.41410237550735474, 0.9524909257888794, -0.48993805050849915, -0.07510483264923096, 0.2655751407146454, -0.15911749005317688, -0.17079801857471466, -0.12902650237083435, 0.3498590290546417, 0.5923163890838623, 0.730790913105011, -0.3506943881511688, -0.3340800404548645, -0.2018917202949524, -0.21255657076835632, -0.11030744016170502, -0.3492661714553833, 1.2982432842254639, -0.9506093263626099, -0.42438891530036926, 0.6972429156303406, 0.9347670078277588, -0.14270776510238647, 0.10634701699018478, -0.14478184282779694, -1.223558783531189, 0.8607219457626343, 0.49067002534866333, 0.31431180238723755, -0.8827061057090759, -1.0697388648986816, -0.326977401971817, -0.19042715430259705, -0.15176312625408173, -0.9429452419281006, 0.16639548540115356, -0.32037022709846497, 0.38223981857299805, 0.06995757669210434, -0.9402492046356201, 0.017184874042868614, -0.2529001533985138, -0.7878608107566833, -0.13686256110668182, 0.405862033367157, 1.5141361951828003, -1.0267523527145386, -0.3535568118095398, -0.11076715588569641, 0.27209365367889404, -0.6930806040763855, 0.8549427390098572, -0.5591583251953125, -0.35929742455482483, -0.5212274789810181, 0.2924230694770813, 0.041092198342084885, -0.49401071667671204, -0.02076096460223198, -0.9472609758377075, -0.10802360624074936, 0.43741166591644287, -0.07887590676546097, 1.182011604309082, 0.09984693676233292, 0.4595221281051636, 0.0027610259130597115, -0.962972104549408, 0.22578464448451996, -0.18342258036136627, -0.2113175094127655, -0.8625102639198303, 0.258026659488678, -0.18617577850818634, -0.9685604572296143, -0.05318998172879219, 0.7384675145149231, 1.2928946018218994, -0.29196470975875854, -0.12020989507436752, 0.5395388007164001, -0.37572622299194336, -0.11083553731441498, 0.43143248558044434, 0.8023200035095215, 0.702558696269989, 0.17072010040283203, -0.4794394075870514, -0.13911660015583038, -0.5740597248077393, 0.0021369413007050753, 0.9331554174423218, 0.09227975457906723, 1.4029382467269897, 0.4276752173900604, -1.1009358167648315, -0.5193264484405518, -0.0029638248961418867, 0.4948127865791321, 1.5720728635787964, 0.4346734881401062, 0.18332557380199432, -0.8431215882301331, -0.44048261642456055, -0.3391992747783661, -0.5813555717468262, -1.0266013145446777, -0.01459459774196148, -0.2109309732913971, -0.8090552091598511, 0.6710636615753174, 0.5045528411865234, 1.5948247909545898, -0.8583037853240967, -0.6479331254959106, -0.2729758620262146, 0.26737797260284424, -0.9160336852073669, -0.8879841566085815, 0.3538438677787781, -0.21670551598072052, -0.2594963610172272, 0.013006488792598248, -0.5444003939628601, 0.0869000256061554, -0.08882225304841995, 1.000848650932312, -0.5415872931480408, -0.8356478810310364, 0.4597908556461334, 0.6512584686279297, -0.8765294551849365, 0.20840738713741302, 0.16290053725242615, -0.31474989652633667, -0.0724831074476242, 0.4484373927116394, 0.359687864780426, -0.5139641165733337, 0.4647846221923828, -0.5391954779624939, -0.22519591450691223, 0.28558701276779175, -0.20497392117977142, 1.0674998760223389, -0.09328880161046982, 0.06293504685163498, -0.8720104694366455, 0.3732706308364868, 0.30329737067222595, -0.2923727035522461, 0.3821970224380493, -0.40902218222618103, -0.36927375197410583, 0.05653632432222366, -0.6852372288703918, -0.14391690492630005, -0.29292812943458557, 0.5614644289016724, -1.0526525974273682, -0.7586123943328857, -0.1264268159866333, 0.14996494352817535, 0.0009467524359934032, 0.5667710304260254, 0.43191611766815186, 0.4822362959384918, 0.038453198969364166, 0.34076058864593506, -1.2485891580581665, 0.97324138879776, 0.20895594358444214, -0.09240783751010895, 0.3284638226032257, 0.059185054153203964, -0.9331610798835754, -0.7537776827812195, -0.838760495185852, -0.4688721001148224, -0.22822634875774384, 0.647627592086792, -0.48926904797554016, -0.7358462810516357, 0.048837658017873764, -0.9611271619796753, -0.4051099717617035, -0.10670521855354309, -0.5991082787513733, -0.4505780339241028, -1.0092365741729736, -0.4689103066921234, -0.4841212034225464, -0.3912545144557953, -0.7451252341270447, 0.4859126806259155, 0.38453859090805054, -0.018026532605290413, -0.5010027289390564, -0.37015458941459656, -0.2505658268928528, 1.4242379665374756, -0.21860773861408234, 0.008540133945643902, -0.1963159441947937, -0.6850191354751587, -0.32948291301727295, -0.5256099104881287, 0.17696091532707214, -0.18756119906902313, 0.08150679618120193, -1.1405054330825806, 0.6128965616226196, -0.11950068175792694, -0.07259467244148254, 1.0308029651641846, 0.6976940631866455, 0.8788283467292786, 0.3012681305408478, -0.7081772685050964, 0.4852183163166046, 1.5305280685424805, -0.7085140943527222, 0.5383819937705994, 0.18926893174648285, 0.7827863693237305, 0.29923340678215027, 0.01695135049521923, 0.24681036174297333, 0.5882598757743835, 0.20616817474365234, 0.8438944816589355, -0.6998203992843628, -0.7047156095504761, -0.5771089196205139, -0.13529112935066223, 0.07106849551200867, 0.16054312884807587, 0.28268739581108093, -0.9084026217460632, 1.209294319152832, -1.3022984266281128, -1.1267285346984863, 0.8399091958999634, 0.4963241517543793, -0.17525407671928406, -0.4423927366733551, 0.008509291335940361, -0.8547487854957581, 0.9611788392066956, 0.5213828682899475, -0.5528019666671753, -0.12755051255226135, -0.14729493856430054, 0.486752450466156, 0.49202725291252136, 0.5231132507324219, -1.0069559812545776, 0.9309564828872681, 14.452638626098633, 0.7051249146461487, -0.20847757160663605, 0.3748171925544739, 0.9464951753616333, 0.5347314476966858, 0.08281677961349487, 0.06711886823177338, -1.0165297985076904, -0.23248650133609772, 0.35112255811691284, 0.38692063093185425, 0.3078579604625702, 0.42576369643211365, -0.13019713759422302, 0.21077284216880798, -0.3631958067417145, 0.881399929523468, 0.8413287997245789, -1.19382643699646, 0.11106624454259872, -0.004550276789814234, 0.15522241592407227, 0.8728268146514893, 0.9826288819313049, 0.3882775902748108, 0.3781297206878662, -0.3393615782260895, 0.48130562901496887, 0.4569387435913086, 1.0764060020446777, 0.5054287910461426, 0.09956599771976471, 0.11896071583032608, -1.1768769025802612, -0.16252797842025757, -0.9295763969421387, -0.8963454961776733, -0.08393684029579163, -0.17645691335201263, -0.17765115201473236, -0.5393721461296082, 0.3559951186180115, 0.5174813866615295, -0.19519153237342834, 0.5000917911529541, -0.09057427942752838, 0.08991754800081253, -0.10545727610588074, -0.2281377911567688, 0.34943631291389465, 0.8618677854537964, -0.011883153580129147, 0.14574502408504486, -0.29502370953559875, 0.5506285429000854, 0.1942373812198639, 0.8127106428146362, -0.23784218728542328, -0.43913155794143677, -0.24528932571411133, 0.05095769092440605, -0.35900449752807617, 1.0290675163269043, 0.09256238490343094, 0.10691598802804947, -0.05786191672086716, 0.38148394227027893, 0.17692455649375916, 0.3537236750125885, -0.5425621271133423, -0.3656224012374878, 0.484353631734848, -0.006210689432919025, 0.5555640459060669, 0.7253702282905579, -0.2975361943244934, -0.4440380930900574, -0.7059154510498047, 0.3722960948944092, 0.6647530198097229, -1.0747648477554321, -0.7804358601570129, 1.2142571210861206, -0.21406754851341248, -0.16839541494846344, 0.8583691716194153, -0.8115273118019104, -0.7126875519752502, 0.3892616927623749, -1.6971994638442993, -1.0399353504180908, -0.3152833878993988, -0.136484295129776, -0.08253764361143112, 0.06622914969921112, 0.7054668068885803, -0.21937333047389984, -0.06796300411224365, -0.014831854961812496, -0.8220977187156677, 0.11261893063783646, -0.07787324488162994, -0.9547936916351318, 1.013815999031067, 0.1961870789527893, -0.029108833521604538, 0.0024786945432424545, 0.04343734681606293, 0.27721673250198364, -0.44740816950798035, -0.19866465032100677, 0.5170187950134277, -0.7382457852363586, -0.39586955308914185, -0.35108399391174316, -0.621114194393158, 0.17108190059661865, 0.6278089284896851, 0.5618489980697632, -0.3319273889064789, -0.14111042022705078, -0.7807919979095459, -0.2991948425769806, -0.9808576107025146, -0.12526579201221466, 0.567619264125824, -0.7602795362472534, -0.6041542291641235, -0.005657663103193045, 0.45760664343833923, -0.8653358817100525, -0.24822187423706055, -0.06772085279226303, 0.3256417214870453, -0.3766671121120453, 1.5133228302001953, -0.603466808795929, 0.6543605923652649, 0.5761998891830444, -0.3692859709262848, -0.3389250338077545, -0.396634578704834, -0.6751795411109924, 0.3600853681564331, 0.19157513976097107, 0.2798461318016052, -0.7196478247642517, 0.6056416034698486, 1.1129761934280396, 0.1383601576089859, -0.689486563205719, -0.31163591146469116, -0.14863739907741547, -0.14644739031791687, -0.5089914798736572, 0.39843687415122986, 0.12465700507164001, -0.2540875971317291, -0.07576305419206619, 0.9249917268753052, 0.8793386220932007, 0.3275673985481262, -0.3895813226699829, 0.2595804035663605, -0.21061564981937408, -0.059440821409225464, -0.7402738332748413, -1.193948745727539, -1.7652270793914795, -0.38174471259117126, -0.8041224479675293, -0.11841686069965363, -1.2574334144592285, -0.36330580711364746, 0.06556452065706253, -0.703079342842102, 0.1798204928636551, 0.39643025398254395, 0.03111155331134796, -0.45725271105766296, -0.5278427600860596, -0.8751377463340759, 0.36621972918510437, 1.1169466972351074, -0.8120673894882202, 0.23385564982891083, 0.22947855293750763, -0.5831823945045471, 0.47251570224761963, 0.36782070994377136, -0.08514722436666489, -0.6025670170783997, -1.194915533065796, 0.08822944015264511, -0.2494722306728363, 0.44685453176498413, -0.8948610424995422, 1.2479792833328247, 0.33021262288093567, 0.11838767677545547, -0.2554599344730377, 0.4858316481113434, -0.8953636884689331, -0.9454602003097534, 0.05669434368610382, -0.7514897584915161, -0.13713018596172333, 0.21801677346229553, -0.21128705143928528, -0.40403488278388977, 1.0076215267181396, 0.10181976109743118, -1.4079357385635376, -1.2508710622787476, 0.5962129235267639, -0.05472467467188835, 0.1304456740617752, -0.1655423939228058, -0.2402912825345993, -1.4093832969665527, -0.24897022545337677, -0.46644699573516846, 0.3778248131275177, -0.466850221157074, 0.9505912661552429, 0.7548558712005615, -1.0091441869735718, 0.25495800375938416, 0.41794154047966003, -0.07555237412452698, 0.35501375794410706, 0.6486912369728088, 0.3947499096393585, -0.3098016381263733, 0.4832763373851776, 0.11684796959161758, 0.05812915787100792, -0.5845497846603394, 0.6009766459465027, 0.9516934752464294, 0.1411033272743225, -0.001298127812333405, 1.0402475595474243, 0.3663789629936218, -0.6975244283676147, 0.2766900360584259, -1.1688226461410522, -0.4940963387489319, -0.19243302941322327, 0.6184870004653931, 0.014000562950968742, -0.11105022579431534, -0.21518577635288239, -0.6049865484237671, 0.6294676661491394, -0.047025226056575775, -0.31342166662216187, 0.4374309778213501, 0.06319752335548401, -0.26155394315719604, 0.053443294018507004, 0.8337640762329102, -1.1772449016571045, -1.2263118028640747, -1.1910473108291626, -0.5774288177490234, -0.5975117683410645, 0.22648601233959198, -0.30014437437057495, -0.9083485007286072, 0.6774707436561584, 0.5623664855957031, 0.7107133865356445, 0.29944658279418945, 0.5729275345802307, -0.18031565845012665, 0.49913468956947327, -0.23279903829097748, -0.38510003685951233, -0.20972467958927155, 1.1036728620529175, 1.4314615726470947, -0.8128353953361511, 0.1565985083580017, -0.4937562346458435, -0.6485527157783508, 0.6333343386650085, 0.6843565106391907, -0.5524333119392395, 1.086431622505188, -0.2160368412733078, 0.024474237114191055, -0.1797814965248108, -0.6852797865867615, -0.6473487615585327, 0.8222674131393433, 1.3932501077651978, 0.0976896658539772, 0.045218873769044876, 0.6208083629608154, 0.8144229650497437, 0.45105674862861633, -0.2598128318786621, 0.10071619600057602, 0.18360736966133118, -0.44499966502189636, 0.5931436419487, -0.12187924981117249, 0.5445173382759094, -0.5392946600914001, -0.3806889057159424, 0.07803421467542648, 0.5776638984680176, 0.20627900958061218, 0.38343027234077454, 1.3373676538467407, 0.1177983209490776, 0.9756749272346497, -0.07281143963336945, 0.4072568416595459, -0.5088658332824707, -0.05702055245637894, -0.0926911011338234, -1.2050760984420776, -0.38062044978141785, -0.48823925852775574, -0.9727346301078796, -0.1804584562778473, 0.39041629433631897, 0.11516991257667542, -0.5067333579063416, 0.383266806602478, 0.6678399443626404, 0.7028656601905823, 0.758005678653717, -0.3513099253177643, -0.9146957397460938, -0.2921750843524933, -0.6898571252822876, 0.17367519438266754, -0.4780488610267639, 0.19567644596099854, -0.3770497143268585, 0.0898362249135971, -0.058606039732694626]}, "authors": [{"authorId": "1663912566", "name": "Xu Ma"}, {"authorId": "2113269100", "name": "Huan Wang"}, {"authorId": "12282768", "name": "Can Qin"}, {"authorId": "49243413", "name": "Kunpeng Li"}, {"authorId": "6294448", "name": "Xing Zhao"}, {"authorId": "2089772402", "name": "Jie Fu"}, {"authorId": "2156255943", "name": "Yun Fu"}], "references": [{"paperId": "270195c8ecc14b98a206461282b88f8fae798932", "title": "Vision GNN: An Image is Worth Graph of Nodes"}, {"paperId": "fa717a2e31f0cef4e26921f3b147a98644d2e64c", "title": "Focal Modulation Networks"}, {"paperId": "9f1b0e4c42a5a85d4c023030557ade4419f82ecf", "title": "Scaling Up Your Kernels to 31\u00d731: Revisiting Large Kernel Design in CNNs"}, {"paperId": "ba637c4f1a170f1e2dadeadb71a63cf2b9a46de2", "title": "Visual attention network"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "c78ffe94ad3d5b41595ab6474a924c429f1420a6", "title": "Augmenting Convolutional networks with attention-based aggregation"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "20ee3dc902706d8dffcbc08f8cc89ce749abc8b0", "title": "Benchmarking Detection Transfer Learning with Vision Transformers"}, {"paperId": "2e644c67a697073d561da4f4dad35e5ad5316cfd", "title": "SOFT: Softmax-free Transformer with Linear Complexity"}, {"paperId": "f454f6b5f2ca9749ddf442eb5134612ef7f758c1", "title": "ResNet strikes back: An improved training procedure in timm"}, {"paperId": "485c08025157973bb52a935c6aa3bee74f990c01", "title": "Sparse MLP for Image Recognition: Is Self-Attention Really Necessary?"}, {"paperId": "a66686e60a3eda0c606e036403cf0a07a5962595", "title": "Mobile-Former: Bridging MobileNet and Transformer"}, {"paperId": "71363797140647ebb3f540584de0a8758d2f7aa2", "title": "AS-MLP: An Axial Shifted MLP Architecture for Vision"}, {"paperId": "0b036cd5dfc49d835d0c759c8ca31d89f2410e65", "title": "CMT: Convolutional Neural Networks Meet Vision Transformers"}, {"paperId": "48418b285a92376a38daafa664a2dd07d42e3fe3", "title": "Focal Self-attention for Local-Global Interactions in Vision Transformers"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "60707f6d2bffeab09e8f1d073fce4fc06ab89ec1", "title": "S2-MLP: Spatial-Shift MLP Architecture for Vision"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "6b6ffb94626e672caffafc77097491d9ee7a8682", "title": "On the Connection between Local Attention and Dynamic Depth-wise Convolution"}, {"paperId": "adb4302eb7c420a46d770afe2448d4508c65fe58", "title": "ResT: An Efficient Transformer for Visual Recognition"}, {"paperId": "d5e999aae76d5270ef272076979c809817458212", "title": "An Attention Free Transformer"}, {"paperId": "5faf75b5c5a4d83bd6407b4aba8fb0bccd7fa31d", "title": "Conformer: Local Features Coupling Global Representations for Visual Recognition"}, {"paperId": "48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5", "title": "ResMLP: Feedforward Networks for Image Classification With Data-Efficient Training"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "14c52ffa7ea9c1971d5d82ea369c946c98d056a9", "title": "LocalViT: Bringing Locality to Vision Transformers"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "9efe8dbde586d6248ecfc69f08b918012e2ac478", "title": "Revisiting ResNets: Improved Training and Scaling Strategies"}, {"paperId": "dfb37e6216e792bf6bd5a30c0fc7ad55df1cb71e", "title": "Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "bb713d56a39a040b35e4f9e036fb4422f543e614", "title": "On the Relationship between Self-Attention and Convolutional Layers"}, {"paperId": "c2c083df88e88223e1a411e61040b94c233b1b63", "title": "MMDetection: Open MMLab Detection Toolbox and Benchmark"}, {"paperId": "1e83c20def5c84efa6d4a0d80aa3159f55cb9c3f", "title": "Attention is not Explanation"}, {"paperId": "a84906dbd4d6640f918d0b6ed2a7313dda0d55f1", "title": "Panoptic Feature Pyramid Networks"}, {"paperId": "cd8ddaaf56e38dddafdeac3f9643b9b5e9d35d54", "title": "Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks"}, {"paperId": "de95601d9e3b20ec51aa33e1f27b1880d2c44ef2", "title": "CBAM: Convolutional Block Attention Module"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "b7b915d508987b73b61eccd2b237e7ed099a2d29", "title": "Maxout Networks"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": null, "title": "Pytorch image models. https: / / github . com / rwightman / pytorch - image models, 2019"}]}