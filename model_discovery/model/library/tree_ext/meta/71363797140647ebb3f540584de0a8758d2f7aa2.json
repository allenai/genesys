{"paperId": "71363797140647ebb3f540584de0a8758d2f7aa2", "title": "AS-MLP: An Axial Shifted MLP Architecture for Vision", "abstract": "An Axial Shifted MLP architecture (AS-MLP) is proposed in this paper. Different from MLP-Mixer, where the global spatial feature is encoded for information flow through matrix transposition and one token-mixing MLP, we pay more attention to the local features interaction. By axially shifting channels of the feature map, AS-MLP is able to obtain the information flow from different axial directions, which captures the local dependencies. Such an operation enables us to utilize a pure MLP architecture to achieve the same local receptive field as CNN-like architecture. We can also design the receptive field size and dilation of blocks of AS-MLP, etc, in the same spirit of convolutional neural networks. With the proposed AS-MLP architecture, our model obtains 83.3% Top-1 accuracy with 88M parameters and 15.2 GFLOPs on the ImageNet-1K dataset. Such a simple yet effective architecture outperforms all MLP-based architectures and achieves competitive performance compared to the transformer-based architectures (e.g., Swin Transformer) even with slightly lower FLOPs. In addition, AS-MLP is also the first MLP-based architecture to be applied to the downstream tasks (e.g., object detection and semantic segmentation). The experimental results are also impressive. Our proposed AS-MLP obtains 51.5 mAP on the COCO validation set and 49.5 MS mIoU on the ADE20K dataset, which is competitive compared to the transformer-based architectures. Our AS-MLP establishes a strong baseline of MLP-based architecture. Code is available at https://github.com/svip-lab/AS-MLP.", "venue": "International Conference on Learning Representations", "year": 2021, "citationCount": 161, "influentialCitationCount": 22, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "An Axial Shifted MLP architecture (AS-MLP) is proposed, which is the first MLP-based architecture to be applied to the downstream tasks and achieves competitive performance compared to the transformer-based architectures even with slightly lower FLOPs."}, "embedding": {"model": "specter_v2", "vector": [0.47788259387016296, 0.587264895439148, -0.41610556840896606, 0.14860600233078003, 0.02100127562880516, 0.08030036836862564, 0.6662578582763672, -0.2992282807826996, -0.494258850812912, -0.7363751530647278, 0.7973468899726868, 0.4120032489299774, 0.6557708978652954, -0.2309861034154892, -0.26604628562927246, -0.5988963842391968, -0.7417874336242676, -0.4931071102619171, 0.3882673978805542, -0.034067727625370026, 0.3474697768688202, -0.12287286669015884, -0.9787374138832092, 0.752190113067627, -0.23778283596038818, 1.1236993074417114, 0.21926012635231018, 1.12385892868042, -0.5942937731742859, 0.7010607123374939, 0.47468018531799316, -0.09432799369096756, 0.4550480246543884, 0.28574231266975403, -0.8025174140930176, 0.1535015106201172, 0.641425609588623, -0.5067164897918701, -0.5728636384010315, 0.7048335075378418, -0.1706445962190628, 0.13838635385036469, 0.18937109410762787, -0.8367812633514404, -0.08975426852703094, 0.7915258407592773, 0.19665135443210602, 0.9693781137466431, -0.8633859157562256, -0.3252578377723694, 1.095670223236084, -1.5272269248962402, -0.45224133133888245, 1.4443416595458984, 0.44815099239349365, 0.2752227187156677, -0.27559515833854675, -0.1423860639333725, 0.6732581257820129, 0.11760655790567398, -0.132884219288826, -0.2828977108001709, 0.4571690559387207, -0.26881611347198486, 1.492397427558899, -0.612159013748169, 0.20588873326778412, 0.6810266971588135, 0.04619895666837692, 1.6504416465759277, 0.3189241588115692, -0.7757724523544312, -0.03379074111580849, -0.28321054577827454, 0.47031939029693604, 0.46125710010528564, -0.11408980190753937, 0.2353115826845169, -1.3039582967758179, 0.3786156475543976, 0.5098409652709961, 0.2926703691482544, 0.6174600124359131, -0.3353521525859833, -0.7135221362113953, 0.476868599653244, 1.1390538215637207, 0.7204974293708801, -0.4223878085613251, 1.1434046030044556, 0.5210505723953247, -0.038901038467884064, -0.18278659880161285, 0.5290674567222595, -0.033966753631830215, 0.6902148127555847, -0.6794025301933289, -0.041874125599861145, -0.6945682764053345, 0.4416255056858063, -0.28039252758026123, 0.3931591808795929, -0.4466252624988556, 0.12258665263652802, 1.4275100231170654, 0.3528085947036743, 0.24216827750205994, -1.0164216756820679, 0.14725567400455475, -0.4059932231903076, -0.22933778166770935, -0.9389132261276245, -0.2578178942203522, -0.8405210375785828, -0.54423987865448, -0.5531150698661804, -0.21091938018798828, 0.4633258879184723, -1.00836181640625, 0.28607091307640076, -0.740047037601471, 0.14412887394428253, 0.4880863428115845, 0.2183888852596283, 0.3273499310016632, 0.5497738718986511, 0.3206370770931244, 0.3886789083480835, 1.1110700368881226, -1.631028652191162, -0.20422908663749695, -1.1514753103256226, -0.1288425773382187, -0.5468481183052063, 0.033394113183021545, -0.37071722745895386, -0.8358945846557617, -1.2445663213729858, -0.849084734916687, 0.31450775265693665, -0.6914939284324646, 0.2015981376171112, 0.8380868434906006, 0.19895371794700623, -1.2398062944412231, 0.9493032693862915, -0.4498421847820282, -0.6085862517356873, 0.9239764213562012, 0.08041076362133026, 0.7749025821685791, 0.17209820449352264, -0.7048277854919434, 0.06850997358560562, 0.3371892273426056, -0.14347875118255615, -0.06515254825353622, -0.416174978017807, -0.7736387848854065, 0.07391207665205002, -0.08255390077829361, -0.7074058651924133, 1.218702793121338, -0.2800186574459076, -1.188192367553711, 0.24420571327209473, 0.1773395836353302, -0.10124699771404266, -0.15481582283973694, -0.1616380214691162, -0.1395525187253952, 0.14189289510250092, 0.018416298553347588, 1.158636212348938, 0.8856989145278931, -0.144757479429245, -0.5198996067047119, -0.057039715349674225, -0.3345465064048767, 0.14148984849452972, -0.4748440384864807, 0.7282482385635376, -0.19308869540691376, -0.6372013092041016, 0.8424221873283386, 0.48523473739624023, -0.13050435483455658, -0.1856803447008133, -0.319446325302124, -0.4202694892883301, 1.13546621799469, 0.3892936706542969, 0.4642863869667053, -1.0975959300994873, -1.106297492980957, -0.30819302797317505, -0.20569215714931488, -0.07175257802009583, -0.701047956943512, 0.2005942463874817, -0.24692441523075104, -0.11548170447349548, -0.1277473419904709, -0.6395545601844788, -0.3097206950187683, -0.3698921799659729, -0.8730642795562744, -0.2852233350276947, 0.4958142042160034, 1.0688107013702393, -0.8993386030197144, -0.057108476758003235, 0.1281399428844452, 0.2628917694091797, -0.8086256980895996, 0.7831621170043945, -0.07167734205722809, 0.2610164284706116, -0.07333537936210632, 0.1553078144788742, -0.01786624640226364, -0.4790484309196472, 0.19994501769542694, -0.6274759769439697, -0.16434656083583832, 0.2968604266643524, -0.40105918049812317, 1.3588742017745972, -0.059119995683431625, 0.7769570350646973, -0.15212532877922058, -0.6628187298774719, 0.36344844102859497, 0.2193891853094101, 0.11991070210933685, -0.40109530091285706, 0.5552671551704407, 0.08007888495922089, -0.6256433725357056, 0.06225265562534332, 0.6343732476234436, 1.279967188835144, -0.32597118616104126, 0.00915345549583435, 0.8951351046562195, -0.02948615700006485, 0.002332804026082158, 0.42291387915611267, 0.3313863277435303, 0.41603589057922363, 0.004891682416200638, -0.5672951340675354, 0.32711926102638245, -0.8202990889549255, -0.1304447501897812, 0.6257197856903076, -0.03298691660165787, 1.1699861288070679, 0.6251959800720215, -0.9940756559371948, -0.4712637662887573, -0.3606107831001282, 0.535858154296875, 1.3380951881408691, -0.00804383959621191, 0.2138092964887619, -0.8572431802749634, -0.5441980957984924, -0.45145249366760254, -0.5909203290939331, -0.08729185163974762, -0.16206522285938263, -0.30007150769233704, -1.2168866395950317, 0.9873950481414795, 0.795870840549469, 1.5654807090759277, -0.8619982600212097, -0.6503464579582214, -0.5031667947769165, 0.4207809269428253, -0.8200740814208984, -0.5455148816108704, 0.22874480485916138, -0.5862299799919128, -0.04357670247554779, -0.18253783881664276, -0.5141919255256653, 0.30705907940864563, -0.5992727875709534, 0.378467857837677, -1.2612322568893433, -0.2389383763074875, 0.08185829222202301, 0.7791335582733154, -0.6283860802650452, -0.3738299608230591, 0.10766181349754333, -0.15438877046108246, 0.6140105724334717, 0.22835460305213928, 0.14110611379146576, -0.6903121471405029, -0.13450492918491364, -0.331666499376297, -0.11238128691911697, 0.5700531005859375, -0.26146751642227173, 0.7689677476882935, -0.5861467123031616, 0.6749534606933594, -0.6863136887550354, 0.6548670530319214, 0.5201139450073242, -0.10949781537055969, -0.34378543496131897, -0.5238192677497864, 0.06412245333194733, 0.20863543450832367, -0.23449526727199554, -0.17357006669044495, -0.24886485934257507, 0.15499936044216156, -0.5894492268562317, -0.45639848709106445, -0.46295323967933655, 0.519101083278656, -0.13536275923252106, 0.5633270144462585, 0.23000271618366241, 0.5893617272377014, 0.05333280563354492, 0.727939784526825, -0.4699822962284088, 0.8752816319465637, 0.4493253231048584, -0.16723103821277618, 0.5742435455322266, 0.14297179877758026, -0.755199134349823, -0.3429326117038727, -0.7278448343276978, -0.4430137276649475, -0.5549808144569397, 0.49582400918006897, -0.40357157588005066, -0.8808234930038452, 0.6469783782958984, -0.9572997093200684, 0.10812698304653168, -0.3680400848388672, 0.04096556827425957, -0.49504444003105164, -1.300376296043396, -1.2090054750442505, -0.11807390302419662, -0.8047069311141968, -1.2681180238723755, 0.007171270903199911, 0.533780038356781, -0.17384696006774902, -0.14570152759552002, -0.4189498722553253, -0.6041293740272522, 1.4693318605422974, -0.3841199576854706, 0.35689106583595276, -0.37223345041275024, -0.26619985699653625, -0.05763278156518936, -0.22984997928142548, 0.9074902534484863, -0.213299959897995, 0.3879925608634949, -1.4905345439910889, 0.5317311882972717, -0.2737649977207184, -0.023947130888700485, 0.8061647415161133, 0.7555707097053528, 0.5712983012199402, 0.0693177655339241, -0.3944283425807953, 0.376630961894989, 0.9439898729324341, -0.6984316110610962, 0.0809696838259697, 0.097255177795887, 0.9341538548469543, 0.03614400699734688, -0.45904695987701416, 0.3328053951263428, -0.14269579946994781, -0.2228582501411438, 0.622357189655304, -0.4371856451034546, -0.6748993992805481, -0.4018494188785553, -0.030154522508382797, 0.8577582836151123, 0.46260857582092285, 0.548718273639679, -0.9013335108757019, 0.9432414770126343, -1.0138169527053833, -0.8117367625236511, 0.9263116121292114, 0.4647749364376068, -0.22052474319934845, -0.22473447024822235, -0.11131695657968521, 0.2228260189294815, 0.9652148485183716, 1.0310719013214111, -0.027672717347741127, -0.8629377484321594, 0.09770538657903671, 0.044841308146715164, 0.39898785948753357, 0.6867769956588745, -0.7628220319747925, 0.3607776165008545, 14.847416877746582, 0.15559251606464386, -0.48535287380218506, 0.0914967879652977, 0.8797484636306763, 0.3607236444950104, 0.32284578680992126, 0.07591056823730469, -0.9145811200141907, 0.1492641270160675, 0.787363588809967, 0.8148558735847473, 0.3617316782474518, 0.4857885539531708, -0.5698553919792175, 0.3647494316101074, -0.6073693633079529, 0.8272272944450378, 0.543578565120697, -1.4564746618270874, -0.013016666285693645, 0.23764663934707642, 0.5315400958061218, 0.7346960306167603, 0.9230290055274963, 0.4067516624927521, -0.06220528483390808, -0.11078359186649323, 0.4665278196334839, 0.026390312239527702, 0.4654303193092346, -0.045016124844551086, 0.26904162764549255, -0.06887839734554291, -1.1140209436416626, -0.5556773543357849, -0.31030574440956116, -1.0249632596969604, -0.18399789929389954, 0.07201739400625229, -0.25123193860054016, -0.7505850195884705, 0.172397181391716, 0.7951801419258118, -0.04850665479898453, 0.3404702842235565, -0.03874843940138817, 0.29045581817626953, 0.023528460413217545, -0.03640832006931305, 0.5602354407310486, 0.8647411465644836, 0.49725964665412903, 0.28472059965133667, -0.3816761374473572, -0.30535250902175903, 0.06719236820936203, 0.4183772802352905, -0.5669428706169128, -0.43678632378578186, -0.207826167345047, -0.2630959749221802, -0.20070485770702362, 0.9782939553260803, -0.2283836305141449, 0.3177674114704132, -0.32070451974868774, 0.12740080058574677, -0.20733189582824707, 0.3560626208782196, -0.4042219817638397, -0.4120858609676361, 0.2714625895023346, -0.37339040637016296, 0.30619165301322937, 0.8449491858482361, -0.41922900080680847, -0.10903993993997574, -0.6973013877868652, 0.15080341696739197, 0.4324842691421509, -0.6449549198150635, -0.43267080187797546, 1.0990147590637207, -0.321899950504303, -0.40357813239097595, 0.726932168006897, -1.0205610990524292, -0.2791180908679962, 0.12883096933364868, -1.3530601263046265, -0.7151493430137634, -0.1019209548830986, -0.37635400891304016, -0.22430802881717682, -0.1901790201663971, 0.6334852576255798, 0.12218360602855682, -0.0403660349547863, -0.4380592703819275, -0.5602174401283264, 0.5466560125350952, -0.1645117998123169, -0.7552527785301208, 0.9620954394340515, 0.6691325902938843, -0.07031700015068054, -0.366314560174942, -0.29886049032211304, 0.7366109490394592, -0.03445421904325485, -0.2982698380947113, 0.37173736095428467, -0.36476582288742065, -0.333169162273407, -0.30279216170310974, -0.4898107349872589, 0.34496355056762695, 0.9190688729286194, 0.7824313044548035, -0.20018163323402405, -0.10683794319629669, -0.5203882455825806, -0.7468452453613281, -0.7016686201095581, -0.05709870532155037, 0.2239944040775299, -0.5255847573280334, -0.46202170848846436, -0.2720775306224823, 0.5809097290039062, -0.644842267036438, -0.25542956590652466, 0.09095646440982819, 0.19422654807567596, -0.24962551891803741, 1.3390781879425049, -0.34961646795272827, 0.5416029095649719, 0.644875168800354, -0.490686297416687, -0.7844516634941101, -0.20685476064682007, -0.7719764113426208, 0.11348146200180054, 0.12299966812133789, 0.5110329389572144, -0.7107800841331482, 0.5782378911972046, 0.0003566162195056677, -0.0005143106682226062, -0.8299748301506042, -0.24949179589748383, 0.07939375191926956, -0.47858893871307373, -0.5209082961082458, 0.35797005891799927, -0.21571359038352966, 0.06603814661502838, 0.2603442668914795, 1.1415815353393555, 0.5455214977264404, -0.057644788175821304, -0.45667946338653564, -0.23920875787734985, -0.14714422821998596, -0.09184781461954117, -1.0226712226867676, -1.1566712856292725, -1.5161044597625732, -0.5227707028388977, -1.2287747859954834, -0.06362461298704147, -0.951372504234314, -0.39232683181762695, 0.38265037536621094, -0.8500580191612244, -0.010367538779973984, 0.48100507259368896, 0.08574308454990387, -0.007550160400569439, -0.41664400696754456, -0.38441595435142517, 0.5810661315917969, 0.9078229069709778, -0.6698390245437622, -0.012240340933203697, 0.22923582792282104, -0.3032245635986328, 0.8162824511528015, 0.46313053369522095, -0.3514377474784851, -0.7607017159461975, -0.965819239616394, 0.22256143391132355, -0.3747739791870117, 0.026408636942505836, -1.4496421813964844, 0.8809524774551392, 0.617658257484436, 0.17661349475383759, -0.2857604920864105, 0.36376476287841797, -0.8688799142837524, -1.0322530269622803, 0.6290225982666016, -0.9481144547462463, -0.047659169882535934, 0.002523578703403473, -0.319257527589798, -0.5022984147071838, 0.9805752038955688, 0.38977670669555664, -0.8397995829582214, -1.2988413572311401, 0.35416996479034424, -0.44348642230033875, 0.15944218635559082, 0.13000477850437164, -0.307041198015213, -1.5080047845840454, 0.2083224505186081, -0.40943336486816406, 0.11610584706068039, -0.710237443447113, 0.825114905834198, 0.6327913403511047, -1.2091821432113647, 0.1649785339832306, 0.8415123820304871, -0.2648957669734955, 0.33598843216896057, 0.4650970995426178, 0.7936720252037048, -0.766234278678894, 0.5439798831939697, -0.40951085090637207, -0.3754119873046875, -0.4403221905231476, 0.2921781539916992, 0.9051199555397034, -0.10378707945346832, -0.22369539737701416, 1.1151301860809326, -0.3144433796405792, -0.9577413201332092, 0.41655611991882324, -1.2018804550170898, -0.5610811710357666, 0.055909719318151474, 0.5719006657600403, 0.5308102965354919, 0.08873606473207474, 0.06090373173356056, -0.7073196172714233, 0.339907169342041, 0.12598150968551636, -0.5062804818153381, 0.12974804639816284, -0.04215865582227707, -0.2608644664287567, 0.41318896412849426, 0.7316099405288696, -0.6785186529159546, -1.321755051612854, -0.9568055868148804, -0.5128382444381714, -0.19517114758491516, 0.04655289649963379, -0.02475302293896675, -1.0166950225830078, 0.8509089350700378, 0.7293321490287781, 0.4980386197566986, 0.329035222530365, 0.24821433424949646, -0.10704825818538666, 0.5062671899795532, -0.40277403593063354, -0.6609174013137817, 0.3616422116756439, 1.0227267742156982, 0.998664140701294, -0.5893585681915283, 0.09362366795539856, -0.3559971749782562, -0.7519969344139099, 0.8684543967247009, 0.40812066197395325, -0.5209283828735352, 0.8071255683898926, 0.012138016521930695, 0.3652820587158203, 0.370578408241272, -0.5099546909332275, -0.19195778667926788, 0.4347572326660156, 1.0464240312576294, 0.22683630883693695, 0.1811429113149643, 0.5672898888587952, 0.5544613599777222, 0.6268789768218994, -0.4750221073627472, 0.41194093227386475, 0.6144264936447144, -0.4829859435558319, 0.5495923161506653, -0.26525434851646423, 0.3428420126438141, -0.7050040364265442, -0.08092527836561203, 0.26463714241981506, 0.5471235513687134, 0.0676146149635315, 0.6038305759429932, 1.2126989364624023, -0.1500779241323471, 0.4264591336250305, 0.2705037593841553, 0.4629257023334503, -0.16728836297988892, 0.009781168773770332, -0.14771707355976105, -1.124396562576294, -0.28981104493141174, -0.5202864408493042, -0.537402331829071, -0.6442785859107971, -0.220891535282135, 0.6681588888168335, -0.3801358640193939, 0.7274354100227356, 0.7716891169548035, 0.8230133056640625, 1.2960835695266724, -0.10505867004394531, -0.8502348065376282, -0.40336427092552185, -0.9754323363304138, 0.11749858409166336, -0.4932522177696228, 0.1559460461139679, -0.007938213646411896, 0.07537508755922318, -0.05935017392039299]}, "authors": [{"authorId": "35180251", "name": "Dongze Lian"}, {"authorId": "2112609106", "name": "Zehao Yu"}, {"authorId": "143900241", "name": "Xing Sun"}, {"authorId": "1702868", "name": "Shenghua Gao"}], "references": [{"paperId": "f75cddf2d42ed01b34686704eb3504becef67442", "title": "CycleMLP: A MLP-like Architecture for Dense Prediction"}, {"paperId": "c38ba200201655f8cb9594cddd52daa8b6f4f335", "title": "What Makes for Hierarchical Vision Transformer?"}, {"paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"}, {"paperId": "2435ffb8ed3212156d6b6f19f633a861399cf30e", "title": "Vision Permutator: A Permutable MLP-Like Architecture for Visual Recognition"}, {"paperId": "60707f6d2bffeab09e8f1d073fce4fc06ab89ec1", "title": "S2-MLP: Spatial-Shift MLP Architecture for Vision"}, {"paperId": "1f668aebd03b5150c2c2fddae48f4a65cb4a80a8", "title": "Container: Context Aggregation Network"}, {"paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de", "title": "Pay Attention to MLPs"}, {"paperId": "48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5", "title": "ResMLP: Feedforward Networks for Image Classification With Data-Efficient Training"}, {"paperId": "0768aba7d87ddda3482fd7892b189f84711ede47", "title": "Do You Even Need Attention? A Stack of Feed-Forward Layers Does Surprisingly Well on ImageNet"}, {"paperId": "fc92009ab34045f9e6d490684c7761f768e88c54", "title": "Beyond Self-Attention: External Attention Using Two Linear Layers for Visual Tasks"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "14c52ffa7ea9c1971d5d82ea369c946c98d056a9", "title": "LocalViT: Bringing Locality to Vision Transformers"}, {"paperId": "003326a15fc4a8833785a47a741d7712474fa256", "title": "LeViT: a Vision Transformer in ConvNet\u2019s Clothing for Faster Inference"}, {"paperId": "8f8f73f0f208302546c825ed474432389ed63be4", "title": "EfficientNetV2: Smaller Models and Faster Training"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "0eff37167876356da2163b2e396df2719adf7de9", "title": "CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification"}, {"paperId": "96da196d6f8c947db03d13759f030642f8234abf", "title": "DeepViT: Towards Deeper Vision Transformer"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "63812f583caac3ac32bbfb64f66ba69e57c1e90a", "title": "Conditional Positional Encodings for Vision Transformers"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "6d5f423164cd5ef9324281652987c8a65009e98e", "title": "Sparse R-CNN: End-to-End Object Detection with Learnable Proposals"}, {"paperId": "93586a3caf5c3428045399abbc5e1b096b59d623", "title": "Disentangled Non-Local Neural Networks"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "8eba733040b016e9c7ec5c3dc87cc1b28a5c2000", "title": "Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation"}, {"paperId": "ea700a101e501b455b1f7258216a4feff74e7286", "title": "Adaptive Context Network for Scene Parsing"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "a88c914f5a738d38f02790bb5de41453bf17bde1", "title": "Object-Contextual Representations for Semantic Segmentation"}, {"paperId": "c2c083df88e88223e1a411e61040b94c233b1b63", "title": "MMDetection: Open MMLab Detection Toolbox and Benchmark"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "4bbfd46721c145852e443ae4aad35148b814bf91", "title": "TSM: Temporal Shift Module for Efficient Video Understanding"}, {"paperId": "ad655c25e052fa4eeed53421344aca6f239c4c9d", "title": "Dual Attention Network for Scene Segmentation"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "9217e28b2273eb3b26e4e9b7b498b4661e6e09f5", "title": "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation"}, {"paperId": "04957e40d47ca89d38653e97f728883c0ad26e5d", "title": "Cascade R-CNN: Delving Into High Quality Object Detection"}, {"paperId": "70c810ba62c5ee40d611e134b2ac2ca61c4de16b", "title": "Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "4a73a1840945e87583d89ca0216a2c449d50a4a3", "title": "Deformable Convolutional Networks"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "7f5fc84819c0cf94b771fe15141f65b123f7b8ec", "title": "Multi-Scale Context Aggregation by Dilated Convolutions"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "083ca4bd4d5b231a1d7a0715ec55cc57a0f44b13", "title": "Aggregating Nested Transformers"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": null, "title": "2021) 224 \u00d7 224 82.6 65M 15.0G -CaiT-S36"}, {"paperId": null, "title": "Transformer-based ViT-B/16"}, {"paperId": null, "title": "MMSegmentation Contributors"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "we also design AS-MLP in the mobile setting. For a fair comparison, we modify the Swin Transformer correspondingly to adopt to the mobile setting"}]}