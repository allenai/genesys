{"paperId": "1ebcf1884390c28f24b3adaf5a7aba5b9453b48b", "title": "CulturaX: A Cleaned, Enormous, and Multilingual Dataset for Large Language Models in 167 Languages", "abstract": "Extensive training datasets represent one of the important factors for the impressive learning capabilities of large language models (LLMs). However, these training datasets for current LLMs, especially the recent state-of-the-art models, are often not fully disclosed. Creating training data for high-performing LLMs involves extensive cleaning and deduplication to ensure the necessary level of quality. The lack of transparency for training data has thus hampered research on attributing and addressing hallucination and bias issues in LLMs, hindering replication efforts and further advancements in the community. These challenges become even more pronounced in multilingual learning scenarios, where the available multilingual text datasets are often inadequately collected and cleaned. Consequently, there is a lack of open-source and readily usable dataset to effectively train LLMs in multiple languages. To overcome this issue, we present CulturaX, a substantial multilingual dataset with 6.3 trillion tokens in 167 languages, tailored for LLM development. Our dataset undergoes meticulous cleaning and deduplication through a rigorous pipeline of multiple stages to accomplish the best quality for model training, including language identification, URL-based filtering, metric-based cleaning, document refinement, and data deduplication. CulturaX is released in Hugging Face facilitate research and advancements in multilingual LLMs: https://huggingface.co/datasets/uonlp/CulturaX.", "venue": "International Conference on Language Resources and Evaluation", "year": 2023, "citationCount": 39, "influentialCitationCount": 6, "openAccessPdf": {"url": "https://arxiv.org/pdf/2309.09400", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work presents CulturaX, a substantial multilingual dataset with 6.3 trillion tokens in 167 languages, tailored for LLM development, and undergoes meticulous cleaning and deduplication through a rigorous pipeline of multiple stages to accomplish the best quality for model training."}, "embedding": {"model": "specter_v2", "vector": [-0.25486424565315247, 0.3260059356689453, -0.6821380853652954, 0.10988673567771912, -0.5780194997787476, -0.4836961328983307, 0.8266663551330566, -0.14590442180633545, -0.44618552923202515, 0.22772517800331116, 0.5422012805938721, -0.2266899049282074, 0.35588276386260986, 0.660179615020752, -0.2636873424053192, 0.09566652774810791, -1.1503098011016846, 0.429657906293869, -0.8442279696464539, 0.05005539208650589, -0.2309439778327942, -0.5804789662361145, -0.5960294008255005, -0.017160147428512573, 0.6961092948913574, 0.2237057387828827, 0.3885401785373688, 0.6468884348869324, -0.6485694646835327, 0.4039359390735626, 0.2892415225505829, -0.5071238875389099, 0.09880981594324112, 0.13487502932548523, -0.4663715958595276, 0.05332772806286812, 0.48168569803237915, -0.5396904349327087, -0.326764851808548, 0.6989326477050781, -0.42372697591781616, -0.08430661261081696, 0.35437819361686707, -0.8138362765312195, -0.5518728494644165, 1.3445791006088257, 0.7867104411125183, 0.4681985676288605, -0.347613126039505, -0.7691777348518372, 1.0497281551361084, -1.5991344451904297, 0.5522198677062988, 1.349938154220581, 0.7101966142654419, 0.3076571226119995, -0.2161509245634079, -1.0989638566970825, 0.3184421956539154, 0.016329903155565262, -1.063862919807434, -0.6317336559295654, -0.12802037596702576, -0.35528290271759033, 1.6945160627365112, -0.5307128429412842, -0.14537504315376282, 0.6037293672561646, -0.23392076790332794, 1.409043788909912, 0.20063257217407227, -0.949019193649292, -0.4705983102321625, 0.528484046459198, 0.20618656277656555, 0.7731595635414124, -0.5227794051170349, 0.1928175538778305, -0.7983656525611877, -0.19907891750335693, 0.25145766139030457, -0.19983315467834473, 0.0009443953749723732, 0.03074992075562477, -0.3183678984642029, 0.6922244429588318, 0.11008317023515701, 1.0585302114486694, -0.11445298790931702, 0.4521051049232483, 0.5421077609062195, 0.6053399443626404, 0.29225513339042664, 0.47965186834335327, -0.6413979530334473, 0.20207646489143372, -1.0139074325561523, 0.20777061581611633, -0.035226933658123016, 0.9028775095939636, -0.15053680539131165, 0.4157043397426605, -0.4785716235637665, 0.3495539128780365, 1.2607395648956299, 0.03154362365603447, 0.6973365545272827, -0.6316794157028198, 0.4429835379123688, -0.730675995349884, 0.33160027861595154, -0.2760965824127197, -0.2652038335800171, -0.524802565574646, -0.49743011593818665, -1.4170076847076416, -0.3682849407196045, 0.04524204879999161, -0.7481482028961182, 0.9080591797828674, -0.32800450921058655, 0.006350253242999315, 0.37293925881385803, 0.28458619117736816, 0.7160561680793762, 0.5649283528327942, 0.1562870889902115, -0.1899372786283493, 0.8619616031646729, -0.8072184920310974, -0.7720116972923279, -0.9539921879768372, 0.9601524472236633, -0.6601322293281555, 0.32190510630607605, -0.1451694816350937, -1.283316731452942, -0.6965325474739075, -0.7867688536643982, -0.13935613632202148, -0.7497773170471191, 0.731275200843811, 0.9389469027519226, 0.38158807158470154, -0.8368657231330872, 0.4978170096874237, 0.13033545017242432, -0.19338266551494598, 0.20559543371200562, -0.003163072280585766, -0.0452074371278286, -0.62183678150177, -1.484529733657837, 0.4924507141113281, 0.3821578919887543, -0.5451268553733826, -0.4916520416736603, -0.5011807680130005, -1.0910115242004395, -0.3751598000526428, 0.04520221799612045, 0.16547705233097076, 1.132698893547058, 0.06744752079248428, -0.8104057908058167, 0.7468721270561218, -0.546018660068512, 0.003334991866722703, 0.42159217596054077, -0.0910647064447403, -1.0540521144866943, -0.7504798173904419, -0.018472926691174507, 0.37727633118629456, 0.4338259696960449, -0.3357909619808197, 0.2141849398612976, 0.2881578803062439, -0.3457282781600952, 0.055601250380277634, -0.5526084899902344, 1.0824936628341675, -0.5051717162132263, -0.592659592628479, 0.19112175703048706, 0.6281404495239258, 0.23045934736728668, -0.4134436249732971, -0.673336386680603, -0.7034590244293213, 0.6711882948875427, -0.6959227919578552, 1.0460582971572876, -0.7733245491981506, -0.7993595600128174, -0.28693097829818726, -0.1872127503156662, 0.12276171892881393, -0.8929769396781921, 1.1239409446716309, -0.12784190475940704, 0.75240558385849, 0.04531974345445633, -1.5691611766815186, 0.0513773187994957, -0.2886863350868225, -0.7202118039131165, -0.1656021773815155, -0.05275151878595352, 0.9033032655715942, -0.6332528591156006, 0.12357691675424576, 0.019504522904753685, 0.5010891556739807, -0.8494445085525513, 0.8594107627868652, -0.23762333393096924, 0.3269159495830536, 0.277609646320343, 0.0929485484957695, 0.22950519621372223, 0.06963054090738297, 0.40283679962158203, -0.15837462246418, -0.5411367416381836, 0.4554681181907654, -0.5707753896713257, 1.4410418272018433, -0.5994449257850647, 0.40184810757637024, 0.2704184949398041, -0.13830596208572388, -0.09548360109329224, 0.7268499135971069, -0.043891921639442444, -0.1663852334022522, 0.29523178935050964, 0.7849366664886475, -0.9025482535362244, 0.4126615524291992, 0.9139481782913208, 0.7649339437484741, -0.2733735144138336, 0.09769229590892792, 0.7706400752067566, -0.1574663370847702, 0.6719855666160583, 0.5010590553283691, 0.3407997786998749, 0.19988957047462463, 0.10799507796764374, -0.20856481790542603, 0.34419354796409607, -0.5466526746749878, -0.15391729772090912, 0.24924692511558533, 0.5178132057189941, 0.7157071828842163, 0.16276755928993225, -0.5649790167808533, -0.28986656665802, -0.0276535302400589, 0.41107437014579773, 1.2298591136932373, -0.3927548825740814, -0.5923864245414734, -0.741510272026062, -0.2434360533952713, 0.06278502196073532, 0.10401518642902374, -0.3264753520488739, 0.1431778222322464, -0.3810798227787018, -0.7263380885124207, 1.0085846185684204, -0.3208966553211212, 0.7157963514328003, -0.6554763317108154, 0.4048658013343811, -0.142061248421669, 0.14645375311374664, -0.7123959064483643, -0.7648981809616089, 0.29642581939697266, -0.34778207540512085, -0.1387847363948822, -0.027222732082009315, -0.5566906332969666, 0.14271076023578644, -0.601424515247345, 0.9939807057380676, -0.3223224878311157, 0.009910278022289276, -0.09477578848600388, 0.6016806364059448, -0.6613327860832214, -1.1911125183105469, 0.1722465604543686, 0.4927854537963867, -0.3366284668445587, 0.17026087641716003, 0.6197697520256042, 0.7406741976737976, -0.15508779883384705, -0.4141094982624054, 0.1986870914697647, 0.12911292910575867, 0.1642659604549408, 0.6856666207313538, -0.18206800520420074, 0.3159852921962738, -1.195011854171753, 0.9715551137924194, 0.014370602555572987, -0.3456677198410034, 0.5212221145629883, -0.7598211169242859, -0.5340418219566345, 0.7138769030570984, -0.5895599126815796, -0.2018965184688568, -1.0705337524414062, 0.5626324415206909, -0.26115280389785767, -0.12044291198253632, 0.5486555695533752, 0.2859409749507904, 0.3699992001056671, 0.04867240786552429, 0.5836929678916931, 0.2763237953186035, -0.8305325508117676, 0.7975462675094604, -0.36698874831199646, 0.3412288725376129, 0.48845356702804565, 0.1613556295633316, -0.3761562705039978, -0.6064040660858154, -0.8335338234901428, -0.24146021902561188, -0.31651273369789124, -0.36017677187919617, -0.18303677439689636, -0.20891261100769043, -0.9535152316093445, -0.1490461528301239, 0.544481635093689, -1.0452635288238525, -0.0751984715461731, 0.31650111079216003, 0.04806575924158096, 0.08208159357309341, -1.1072697639465332, -1.4385486841201782, -0.48927244544029236, -0.5385023951530457, -0.9916779398918152, 0.3181952238082886, -0.20897094905376434, -0.35438597202301025, -0.726826548576355, 0.07410459965467453, 0.010125897824764252, 0.9634596705436707, -0.6798467040061951, 0.761001467704773, 0.0637720599770546, 0.30475738644599915, -0.34097835421562195, 0.1725827306509018, 0.6545076966285706, -0.11128450185060501, 0.4242960214614868, -0.8317484855651855, -0.16740626096725464, -0.24977409839630127, -0.6283475756645203, -0.1745026707649231, 0.396441787481308, 0.38911253213882446, -0.23254650831222534, -0.3323914706707001, 0.5088566541671753, 1.3464956283569336, -0.8007259368896484, -0.17438998818397522, -0.06973236799240112, 1.0463391542434692, 0.26724773645401, -0.5266101956367493, 0.5736289024353027, 0.28993505239486694, 0.29395657777786255, -0.019147532060742378, -0.22507727146148682, -0.27000927925109863, -0.7398733496665955, 0.5290696620941162, 2.0219459533691406, 0.6747596263885498, -0.010327774100005627, -1.064910650253296, 0.8520733714103699, -0.6606370806694031, -0.3381451666355133, 0.4601604640483856, 0.6674384474754333, 0.8064512014389038, -0.6393934488296509, -0.4675620198249817, -0.009845196269452572, 0.35734376311302185, 0.30699506402015686, -0.20200709998607635, -0.5561494827270508, -0.26766401529312134, 0.10238482058048248, 0.038974735885858536, 0.656976580619812, -0.42628583312034607, 0.828976571559906, 14.80792236328125, 0.9507524371147156, -0.05312565714120865, 0.8060531616210938, 0.5400874018669128, 0.030398912727832794, -0.3920072019100189, -0.11572279036045074, -1.3084139823913574, -0.042707230895757675, 1.1809731721878052, 0.19506561756134033, 1.0905447006225586, 0.09666809439659119, 0.20395395159721375, 0.311257928609848, 0.018291642889380455, 0.6072338819503784, 0.6289550065994263, -1.0850614309310913, 0.4025834798812866, 0.33613768219947815, 0.7555539011955261, 0.9027435779571533, 0.7580546140670776, 0.9219856858253479, 0.35917845368385315, -0.5698314309120178, 0.8710708022117615, -0.023234045132994652, 0.9952408671379089, -0.23369021713733673, 0.3647838532924652, 0.5854294896125793, -0.8984203934669495, -0.07048077881336212, -0.6727305054664612, -1.1030489206314087, 0.2399374544620514, 0.3173961937427521, -0.909341037273407, -0.36166560649871826, -0.3176879286766052, 0.9128946661949158, -0.25363001227378845, 0.1860284060239792, 0.11210530251264572, 0.9462442994117737, 0.03645019605755806, 0.3382369875907898, 0.27746525406837463, 0.4018426835536957, 0.416189044713974, -0.18871565163135529, -0.04296068847179413, -0.8388827443122864, 0.1243969202041626, 0.18804103136062622, -0.8776127696037292, 0.3875791132450104, -0.4275135397911072, -0.6146344542503357, 0.16961659491062164, 0.8779911398887634, 0.5275407433509827, 0.15236303210258484, -0.4669134318828583, 0.2583830952644348, 0.891697108745575, 0.1710987389087677, -0.19508084654808044, 0.17551930248737335, 0.5198377966880798, -0.31627243757247925, -0.25056639313697815, 0.2484031766653061, -0.011296841315925121, -0.7554343342781067, -0.40570634603500366, -0.4411241114139557, -0.0028994979802519083, -0.5893656611442566, -0.7368921637535095, 0.9744082689285278, -0.42145514488220215, -0.40788543224334717, 0.08429452776908875, -0.5457383990287781, 0.18846501410007477, 0.852449357509613, -1.33778715133667, -1.2781180143356323, 0.6659667491912842, -0.3203790783882141, -0.25296398997306824, -0.3093087077140808, 1.488613486289978, 0.35814592242240906, -0.42183002829551697, 0.007671963889151812, 0.7692874670028687, 0.12025220692157745, -0.10154595226049423, -0.6611631512641907, 1.017338752746582, 0.32329991459846497, 0.12826743721961975, 0.4205544590950012, -0.10489324480295181, -0.10167566686868668, -0.6564599871635437, -0.4721500873565674, 1.406460165977478, -0.994022011756897, -0.3676145374774933, -1.1470025777816772, -0.8662179708480835, 0.3213655650615692, 0.5992226004600525, -0.39396795630455017, 0.33210545778274536, 0.24990564584732056, -0.5261904001235962, 0.145379438996315, -0.932723343372345, -0.04284582659602165, 0.4217517077922821, -0.957111656665802, -0.1034855991601944, 0.4462430775165558, 0.23144100606441498, -0.7151489853858948, -0.5942752957344055, -0.4819907248020172, 0.20490270853042603, 0.1032814085483551, 0.6583138704299927, -0.534791886806488, 0.34115350246429443, 1.0012120008468628, -0.32947006821632385, -1.2083348035812378, 0.14587795734405518, -0.9514150023460388, -0.15949848294258118, 0.49789562821388245, 0.8780468702316284, -0.4523791968822479, -0.06950251758098602, 0.5381122827529907, 0.22622688114643097, -0.4859619140625, -0.5895494818687439, -0.6788665652275085, 0.40729567408561707, -0.45394930243492126, 0.4738604426383972, 0.3377133309841156, -0.008037813939154148, 0.1105862632393837, 0.05531992390751839, 0.20921795070171356, -0.18880155682563782, -0.9547982215881348, 0.4669386148452759, 0.03355627879500389, -0.024224283173680305, -0.4975253939628601, -0.2613063454627991, -0.9879950284957886, 0.20496536791324615, -1.4039226770401, -0.06259112060070038, -0.8129162192344666, -0.4451599717140198, -0.3507741391658783, -0.0016227454179897904, 0.25513139367103577, 0.6251155138015747, -0.12663668394088745, -0.5593854784965515, -0.22816738486289978, -0.029789840802550316, 0.8714331388473511, 0.9155663251876831, -0.7014093995094299, 0.024490531533956528, -0.3655310571193695, 0.2189493328332901, 0.119242824614048, 0.38693341612815857, -0.41857022047042847, -0.9070417284965515, -1.6364378929138184, 0.011970456689596176, -0.4350043833255768, -0.4422825574874878, -0.6819661259651184, 0.05953251197934151, 0.47075027227401733, -0.25181373953819275, 0.0991491749882698, 0.24711830914020538, -0.6832590103149414, -0.1512533724308014, 0.31424811482429504, -0.5222235321998596, 0.4742700457572937, 0.18822938203811646, -1.041404128074646, -0.5213920474052429, 0.509628415107727, -0.18364207446575165, -0.9064698815345764, -0.5794662833213806, 0.5365007519721985, -0.44823211431503296, 0.10800498723983765, -0.3181603252887726, 0.16725966334342957, -0.9221464395523071, -0.37423115968704224, 0.11268092691898346, 0.29432085156440735, -0.08031509071588516, 1.3963587284088135, 0.06687904894351959, -1.0776844024658203, -0.31315580010414124, 0.6242910623550415, -0.12187404930591583, -0.5771540403366089, 0.33381587266921997, 0.32867974042892456, -0.3778325617313385, 0.7081778645515442, 0.3099916875362396, 0.4973320960998535, -0.7947940826416016, -0.16470710933208466, 0.5732333064079285, -0.5775222778320312, 0.029196010902523994, 1.1271673440933228, -0.6716372966766357, -1.434358835220337, 0.23968540132045746, -1.1956892013549805, -0.7129120826721191, -0.3132036626338959, 0.8058632612228394, 0.12332388013601303, 0.37669607996940613, -0.818187415599823, -0.40549588203430176, -0.13198988139629364, -0.013350064866244793, -0.5931005477905273, 0.5857892632484436, -0.3638561964035034, -0.2281508594751358, 0.6449087262153625, 1.1839061975479126, -0.19068555533885956, -0.42934170365333557, -0.4924849569797516, -0.7531148195266724, -0.07146015763282776, 0.45819956064224243, -0.8093039989471436, -0.5623164772987366, 0.45838820934295654, 0.2591017484664917, 0.4766915440559387, -0.24130597710609436, -0.43626970052719116, 0.462629497051239, 0.46873971819877625, 0.22439037263393402, -0.8586881756782532, -0.973497211933136, 1.5960161685943604, 1.3585236072540283, -1.2369403839111328, 0.0759631097316742, 0.11112529039382935, -0.8182693719863892, 0.4874439835548401, -0.05263400077819824, 0.3842979967594147, 1.1537864208221436, -0.4722553491592407, 0.47060930728912354, 0.17305952310562134, -0.8006770014762878, 0.114107146859169, 0.7102232575416565, 0.8076719641685486, 1.117286205291748, 0.6380666494369507, -0.20421597361564636, 0.8319166302680969, -0.15409182012081146, -0.012770690023899078, 0.511101245880127, 0.75700443983078, 0.15912199020385742, -0.34747007489204407, 0.09318694472312927, 0.644845187664032, -0.49198079109191895, -0.8361621499061584, -0.18042360246181488, 0.5577653050422668, 0.561044454574585, 0.6052412390708923, 0.472872257232666, 0.11103197932243347, 0.3005649745464325, 0.5107037425041199, 0.3727336525917053, -0.47675687074661255, -0.3899546265602112, -0.3401578962802887, -0.48548436164855957, 0.16066117584705353, -0.0734010711312294, -0.5618151426315308, -0.21949853003025055, -0.36067166924476624, 0.16627976298332214, 0.21712203323841095, 0.7837018966674805, 1.1627806425094604, 0.6592527627944946, -0.06030102074146271, -0.19150100648403168, -0.4284364581108093, -0.32411104440689087, -1.2860016822814941, -0.6388172507286072, -0.34720170497894287, -0.10896161943674088, -0.23331674933433533, -0.3663675785064697, -0.2767100930213928]}, "authors": [{"authorId": "2116085512", "name": "Thuat Nguyen"}, {"authorId": "2186540882", "name": "Chien Van Nguyen"}, {"authorId": "1405279380", "name": "Viet Dac Lai"}, {"authorId": "2027979466", "name": "Hieu Man"}, {"authorId": "1692755523", "name": "Nghia Trung Ngo"}, {"authorId": "2462276", "name": "Franck Dernoncourt"}, {"authorId": "2238208116", "name": "Ryan Rossi"}, {"authorId": "1811211", "name": "Thien Huu Nguyen"}], "references": [{"paperId": "3e664adb009dce373129a3563e4b2cb08731bc76", "title": "PolyLM: An Open Source Polyglot Large Language Model"}, {"paperId": "7a1e71cb1310c4a873e7a4e54d1a6dab0553adce", "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"}, {"paperId": "dfbfa21a93c3164ae8a033398c8de42b03b1b84d", "title": "ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning"}, {"paperId": "16c64f74ce0e6a59b0709c0d8e66596a5bc08ed6", "title": "The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "bf8491bef353df126e2306ad2fe4b898697b906a", "title": "A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a", "title": "Emergent Abilities of Large Language Models"}, {"paperId": "aa4d9972af3264d032dbee58501ed4ac49477103", "title": "Scaling Laws and Interpretability of Learning from Repeated Data"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "645a317c9305207e95d03b5756a65e7e850f32d5", "title": "Towards a Cleaner Document-Oriented Multilingual Crawled Corpus"}, {"paperId": "fd1b829261ba04bb92e0ab60c4f6e7cea0d99fbf", "title": "Ethical and social risks of harm from Language Models"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "4566c0d22ebf3c31180066ab23b6c445aeec78d5", "title": "Deduplicating Training Data Makes Language Models Better"}, {"paperId": "d77ad36898a623b2e82d96a0b8d9920204ca60bf", "title": "Ungoliant: An Optimized Pipeline for the Generation of a Very Large-Scale Multilingual Web Corpus"}, {"paperId": "49f905eb03958c7cfae52ac759ea8978b8b2a6ea", "title": "Alignment of Language Agents"}, {"paperId": "6803adc7d8b891be652d18815f830f7a42a0f5b5", "title": "Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets"}, {"paperId": "f577654d9dd29d88c6db9ee39a4fd831573b8770", "title": "Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "74276a37bfa50f90dfae37f767b2b67784bd402a", "title": "mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer"}, {"paperId": "14fc61fdc8f2205ff96ff6dc9c4c881e4063db8c", "title": "ParaCrawl: Web-Scale Acquisition of Parallel Corpora"}, {"paperId": "528dd0da358b4939d99eeb92548deccfeac48bd6", "title": "A Monolingual Approach to Contextualized Word Embeddings for Mid-Resource Languages"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "6fec3e579c7cd4f13bdabbee2b6ac2e8ff5941c6", "title": "Unsupervised Cross-lingual Representation Learning at Scale"}, {"paperId": "c20c68c45127439139a08adb0b1f2b8354a94d6c", "title": "CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "92343cecdc990380de362b969eec60081959f507", "title": "Asynchronous Pipeline for Processing Huge Corpora on Medium to Low Resource Infrastructures"}, {"paperId": "f48f90464d9694e2ea18767f14842c64c9a1e8fb", "title": "WikiMatrix: Mining 135M Parallel Sentences in 1620 Language Pairs from Wikipedia"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "8ace1951c95f9bbbcf83571ff6c0579521507e2e", "title": "The adverse effects of code duplication in machine learning models of code"}, {"paperId": "1c3112ef8a346b9817382ed34a8c146c53d5bcf5", "title": "XNLI: Evaluating Cross-lingual Sentence Representations"}, {"paperId": "d7b6753a2d4a2b286c396854063bde3a91b75535", "title": "A Simple Method for Commonsense Reasoning"}, {"paperId": "e73bd7f9bdc262b9b7fb60ca0d5230d3ab0fad5e", "title": "Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates"}, {"paperId": "0fe73c19513dfd17372d8ef58da0d0149725832c", "title": "Learning Word Vectors for 157 Languages"}, {"paperId": "3e27529f55fa966201613b2d8b56b1934ce6af54", "title": "Natural Language Processing with Small Feed-Forward Networks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5feb32a73dd1bd9e13f84a7b3344497a5545106b", "title": "FastText.zip: Compressing text classification models"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "8215fb083cb4b0ed2b6858b81dcc30fbd0afb6e1", "title": "Mining of Massive Datasets"}, {"paperId": "883d1d06d857a85a0e64bb19f0b17d56f2cc9d7b", "title": "KenLM: Faster and Smaller Language Model Queries"}, {"paperId": "cc01d321f281ee7ce94092021a21346cb43b3a33", "title": "A Modern Introduction to Probability and Statistics: Understanding Why and How"}, {"paperId": "8addb1718c2bc6bbb0d82cd1a57b41198bf65965", "title": "On the resemblance and containment of documents"}, {"paperId": null, "title": "Falcon-40B: an open large language model with state-of-the-art performance"}, {"paperId": null, "title": "Jurassic-1: Technical details and evaluation"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Cc-news"}, {"paperId": null, "title": "2023. Introducing mpt-7b: A new standard for open-source, commercially usable llms"}, {"paperId": null, "title": "Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. 2023. The refinedweb dataset for falcon llm: Outperforming curated corpora with web data"}, {"paperId": null, "title": "Together Computer. 2023. Redpajama: An open source recipe to reproduce llama training dataset"}]}