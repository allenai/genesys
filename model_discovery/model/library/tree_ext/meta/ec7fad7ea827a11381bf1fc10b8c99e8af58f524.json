{"paperId": "ec7fad7ea827a11381bf1fc10b8c99e8af58f524", "title": "What is this Article about? Extreme Summarization with Topic-aware Convolutional Neural Networks", "abstract": "We introduce \"extreme summarization,\" a new\u00a0single-document summarization task which aims at creating a short,\u00a0one-sentence news summary answering the question \"What is the\u00a0article about?\". We argue that extreme summarization, by nature, is\u00a0not amenable to extractive strategies and requires an abstractive\u00a0modeling approach. In the hope of driving research on this task\u00a0further: (a) we collect a real-world, large scale dataset by\u00a0harvesting online articles from the British Broadcasting Corporation\u00a0(BBC); and (b) propose a novel abstractive model which is\u00a0conditioned on the article's topics and based entirely on\u00a0convolutional neural networks. We demonstrate experimentally that\u00a0this architecture captures long-range dependencies in a document and\u00a0recognizes pertinent content, outperforming an oracle extractive\u00a0system and state-of-the-art abstractive approaches when evaluated automatically and by humans on the extreme summarization\u00a0dataset.", "venue": "Journal of Artificial Intelligence Research", "year": 2019, "citationCount": 17, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://jair.org/index.php/jair/article/download/11315/26523", "status": "GOLD"}, "tldr": {"model": "tldr@v2.0.0", "text": "A novel abstractive model is proposed which is conditioned on the article's topics and based entirely on convolutional neural networks, outperforming an oracle extractive system and state-of-the-art abstractive approaches when evaluated automatically and by humans on the extreme summarization dataset."}, "embedding": {"model": "specter_v2", "vector": [-0.016131846234202385, 0.7944495677947998, -0.6412224173545837, -0.2417701929807663, -0.44367197155952454, -0.22542111575603485, 0.8810238838195801, 0.0487930029630661, -0.3977545201778412, -0.016181224957108498, 1.438978910446167, 0.5064657330513, -0.23123858869075775, 0.23129631578922272, -0.15727022290229797, 0.048682279884815216, -0.7176592946052551, 0.09132450819015503, -0.25370854139328003, -0.36592724919319153, 0.42010697722435, -0.7953477501869202, -0.6248294711112976, 0.34945276379585266, 0.22327207028865814, 0.43180567026138306, -0.5077834129333496, 1.3461487293243408, -0.45124781131744385, 0.6350715756416321, -0.0747559666633606, -0.2088434398174286, 0.026406940072774887, -0.4587855637073517, -0.5554361343383789, 0.10884618014097214, 0.5481875538825989, -1.0027204751968384, -0.4248714745044708, 0.5092962980270386, -0.2965090870857239, -0.013317783363163471, 0.6258976459503174, -0.25577807426452637, -0.06319554150104523, 1.2990139722824097, 0.501137375831604, 0.881711483001709, 0.0512554794549942, -0.8302658200263977, 1.7908886671066284, -1.184152364730835, 0.497479110956192, 1.1920512914657593, 0.48034733533859253, 0.2779908776283264, -0.0709095150232315, -0.34192579984664917, 1.0958118438720703, 0.01904362440109253, -0.5918102860450745, -0.4475715756416321, 0.3433723747730255, -0.3275698721408844, 1.547348141670227, -0.16440612077713013, -0.002464660443365574, 0.2850792407989502, -0.004738744348287582, 1.7663935422897339, -0.3144584596157074, -0.5880604386329651, -0.348137766122818, -0.24782732129096985, 0.9863671064376831, 0.24309736490249634, -0.23121656477451324, -0.3447856903076172, -1.0348007678985596, -0.00044386612717062235, -0.2445763647556305, 0.12406814843416214, -0.6362879872322083, 0.3581617474555969, -0.046027399599552155, 0.5240017771720886, 0.16127809882164001, 0.6477971076965332, -0.6871268153190613, 0.8457004427909851, 0.45193544030189514, 0.36094123125076294, 0.5749271512031555, 0.3405923545360565, 0.10132552683353424, 0.721558153629303, -1.118146538734436, 0.5864259004592896, 0.47599175572395325, 0.9339227080345154, -0.1269255429506302, 0.22022438049316406, -1.0734798908233643, 0.169065922498703, 0.8483232855796814, -0.2804722785949707, 0.2382313311100006, -0.752143383026123, 0.26724669337272644, -0.5248170495033264, 0.4801107943058014, -1.0097404718399048, -0.6872932314872742, -0.5846813917160034, -0.4797278344631195, -0.9247486591339111, -0.683333694934845, -0.42090511322021484, -0.42732247710227966, 0.5541543960571289, -0.5963725447654724, -0.3676513135433197, 0.20374394953250885, 0.4288051724433899, 1.0551162958145142, 0.9100569486618042, 0.2965840995311737, -0.5539363622665405, 1.132682204246521, -0.9246845841407776, -1.250849723815918, -0.9818931818008423, 0.5081656575202942, -0.25976255536079407, -0.4197086989879608, -0.2310052216053009, -1.214964747428894, -0.6223698258399963, -1.2481637001037598, -0.07344342768192291, -0.1603422611951828, 0.5270338654518127, 0.6342582106590271, -0.1306162178516388, -0.7712888717651367, 0.7732324004173279, 0.2963801622390747, -0.40630191564559937, 0.23896650969982147, 0.13628453016281128, 0.332989901304245, -0.06849352270364761, -0.7757492065429688, 0.13338467478752136, 0.25831201672554016, -0.681567370891571, 0.15600377321243286, -0.5595523118972778, -0.7301936745643616, 0.3169761896133423, 0.6306793689727783, -0.8147755861282349, 1.3499268293380737, -0.027272094041109085, -1.1711121797561646, 0.30518633127212524, -0.11838369071483612, 0.0004899196210317314, 0.09871178865432739, -0.887795090675354, -0.4264737367630005, 0.12706859409809113, -0.024214724078774452, 0.15465974807739258, 0.4856303036212921, -0.14973270893096924, -0.48579639196395874, 0.07440292090177536, -0.3213335871696472, -0.13676278293132782, -0.6872394680976868, 1.2230045795440674, -0.3625357747077942, -0.4372904300689697, 0.10703316330909729, 0.8497402667999268, 0.317765474319458, -0.5440811514854431, -0.8719109892845154, -1.29731285572052, 0.6482986807823181, -0.26171377301216125, 1.423019289970398, -0.7404093146324158, -0.2660839557647705, -0.6993188858032227, 0.1674693375825882, -0.11680376529693604, -0.27395516633987427, 0.5960983037948608, -0.07889648526906967, 0.65843266248703, -0.11343000084161758, -1.238427758216858, 0.10643181949853897, -0.5685385465621948, -0.9221993684768677, -0.25629374384880066, 0.2146035134792328, 1.019745111465454, -0.5581643581390381, 0.2282790094614029, -0.5605339407920837, -0.21835343539714813, -0.5956087112426758, 0.9823164343833923, -0.6911517977714539, -0.006322967354208231, -0.7818959951400757, -0.43466466665267944, 0.29862725734710693, -0.11815514415502548, 0.13960818946361542, -0.41553667187690735, -0.41355186700820923, 0.37728235125541687, -0.5628414154052734, 0.9824279546737671, 0.3689006567001343, 0.8315020203590393, 0.09373126178979874, -0.6631227135658264, -0.017105894163250923, 0.4742887020111084, -0.36364054679870605, -0.18450117111206055, 0.44214126467704773, 0.0878576785326004, -1.3206520080566406, -0.03850780054926872, 0.8043416142463684, 1.0019001960754395, -0.8993332386016846, 0.5229063034057617, 0.8959150314331055, -0.1123238131403923, 0.5138781666755676, 0.7535763382911682, 0.7424725294113159, 0.4606865644454956, 0.5167891383171082, -0.07595312595367432, 0.09431833773851395, -0.21253974735736847, 0.19737042486667633, 0.5180827379226685, 1.0044485330581665, 1.1824902296066284, 0.878458559513092, -1.132439374923706, -0.5211419463157654, 0.32158297300338745, 0.908239483833313, 1.2187082767486572, -0.17344820499420166, -0.5282747745513916, -0.9210688471794128, -0.626187801361084, -0.5315649509429932, 0.4560317397117615, -0.3896810710430145, -0.13505809009075165, -0.8396409153938293, -1.1578726768493652, 0.649503231048584, 0.08229563385248184, 1.0747710466384888, -0.25331005454063416, -0.09191015362739563, -0.21389110386371613, -0.3434772491455078, -0.5774742364883423, -0.5796590447425842, 0.3069669008255005, -0.3578035235404968, -0.08513575047254562, -0.24300387501716614, 0.10136515647172928, 0.10616213083267212, -0.751480758190155, 1.0673648118972778, -0.21587634086608887, 0.13020652532577515, 0.3307594954967499, 0.3398418724536896, -1.2740147113800049, -0.42110294103622437, 0.1203293651342392, 0.029200412333011627, 0.0014662275789305568, 0.5379169583320618, 0.6613075137138367, -0.22384333610534668, -0.1801113784313202, -0.6364343762397766, 0.17870396375656128, 0.08602393418550491, -0.08481169492006302, 0.29306110739707947, 0.10684280097484589, 0.2986683249473572, -1.0368858575820923, 1.2104319334030151, -0.04022716358304024, -0.014478446915745735, 0.23385398089885712, -0.4547962546348572, -0.20239391922950745, 0.2912464439868927, -0.32689374685287476, -0.5015207529067993, -1.2958978414535522, 0.5576392412185669, 0.3098434507846832, -0.42505308985710144, 0.6294671297073364, 0.43668389320373535, 0.7352644801139832, 0.2837255001068115, 0.25880664587020874, 0.25162166357040405, -0.4200396239757538, 0.16360674798488617, -0.23366837203502655, 0.8760779500007629, 0.8487597107887268, -0.22813624143600464, 0.08880072832107544, -0.3388315439224243, -0.7604495882987976, -1.1114739179611206, -0.4882671535015106, -0.03659086674451828, -0.6443199515342712, 0.25388073921203613, -0.6574372053146362, -0.13216160237789154, 0.16169781982898712, -1.3219013214111328, 0.23334668576717377, -0.11990032345056534, -0.0806107297539711, -0.2340346723794937, -1.045747995376587, -1.0449036359786987, -0.20915649831295013, -0.8313619494438171, -0.18001316487789154, 0.3674619495868683, 0.3553062379360199, -0.9954431653022766, -0.10564486682415009, -0.0431094691157341, -0.5527233481407166, 0.6621916890144348, 0.18458759784698486, 0.6518309116363525, -0.44352859258651733, -0.12972427904605865, -0.46100637316703796, 0.4734669327735901, 0.4183923006057739, -0.6355708241462708, 0.09320999681949615, -0.1291528046131134, 0.44295352697372437, 0.2624991536140442, 0.028493866324424744, 0.43188807368278503, 0.866274356842041, 0.04420206695795059, -0.3585890233516693, -0.5833179950714111, 0.043703049421310425, 1.2437279224395752, -1.2543965578079224, -0.11182854324579239, 0.2566549777984619, 0.6202706694602966, 0.863269031047821, -0.3046688735485077, 0.7852199077606201, 0.14789344370365143, 0.3566434979438782, 0.2613004148006439, -0.250326931476593, -0.6216007471084595, -0.16311350464820862, 0.5575223565101624, 1.4446059465408325, 0.09362960606813431, -0.477228045463562, -0.7772327661514282, 0.8078412413597107, -1.3645960092544556, -0.8928390741348267, 0.27252456545829773, 0.2733864486217499, -0.3076247274875641, -0.4247399866580963, -0.15683099627494812, -0.3702673614025116, 0.7199932336807251, 0.3502250015735626, -0.14947625994682312, -0.725673496723175, 0.0176535751670599, -0.22078871726989746, 0.33157244324684143, 0.3241423964500427, -0.5400890707969666, 0.2526698112487793, 14.736865997314453, 0.45405203104019165, 0.36411961913108826, 0.1387031525373459, 0.5130626559257507, -0.23445932567119598, -0.3555589020252228, 0.06452331691980362, -1.3582357168197632, -0.10719367861747742, 1.0787029266357422, -0.1325853019952774, 0.01953747682273388, 0.05957904830574989, 0.27102917432785034, 0.0008244962664321065, -0.4509207010269165, 0.30546510219573975, 0.9208886027336121, -1.5707050561904907, 0.49403297901153564, 0.41885703802108765, 0.2772078216075897, 0.47509440779685974, 0.5829831957817078, 0.7598770260810852, 0.30012354254722595, 0.04926697537302971, 0.791038990020752, 0.5591675043106079, 0.28003978729248047, -0.45628032088279724, 0.9232978820800781, 0.8392224311828613, -0.14402276277542114, -0.6507815718650818, -0.6296141147613525, -1.0359779596328735, 0.7055872082710266, 0.28926536440849304, -0.051036056131124496, 0.1343594789505005, 0.00983995757997036, 0.7224779725074768, 0.2093878984451294, 0.540762722492218, -0.49660423398017883, 0.7303261160850525, 0.030094487592577934, -0.2872774600982666, 0.46883994340896606, 0.6144787073135376, 1.001277208328247, 0.052472084760665894, 0.2808504104614258, 0.6607040762901306, -0.17802387475967407, 0.2590782642364502, -0.9212096929550171, -0.03765460476279259, -0.40845614671707153, -0.16809293627738953, -0.3357981741428375, 0.49132224917411804, 0.5184211730957031, 0.005254571791738272, -0.48652350902557373, 0.30990952253341675, 0.3666413724422455, 0.18106971681118011, 0.21744394302368164, -0.6215731501579285, -0.11739268898963928, 0.11357750743627548, 0.36618050932884216, 0.6658928394317627, -0.2717505693435669, -0.4864097535610199, -0.7025921940803528, 0.019433563575148582, 0.5966629981994629, -0.8795076012611389, -0.43959227204322815, 0.8664646744728088, 0.153285413980484, -0.8158884048461914, -0.14633865654468536, -0.2335212379693985, -0.6899149417877197, 0.11377374082803726, -0.9796310663223267, -0.47714313864707947, -0.14467746019363403, -0.6571760177612305, -0.04672882333397865, -0.053191110491752625, 0.9735509753227234, -0.40135708451271057, -0.4585575461387634, -0.502835750579834, 0.40799224376678467, -0.17384426295757294, 0.10213377326726913, -0.9344526529312134, 0.15571007132530212, 0.34012898802757263, -0.20918066799640656, 0.12736234068870544, 0.6217779517173767, 0.07119251787662506, -0.4511459469795227, -0.03397473692893982, 0.9558620452880859, -0.8426228761672974, -0.8405635952949524, -0.4409976005554199, -0.6782737374305725, 0.350557416677475, 1.0568281412124634, -0.4561308026313782, 0.5285437703132629, 0.37437787652015686, 0.05473511666059494, -0.011660144664347172, -0.6880400776863098, -0.05127719044685364, 0.2589111924171448, -0.16947676241397858, -0.8277807235717773, 0.0967903882265091, 0.6726309657096863, -0.5739212036132812, -0.3139939606189728, -0.41501790285110474, -0.11604306101799011, 0.08405111730098724, 0.5539788007736206, -0.46283379197120667, 0.9325253963470459, 0.6717153191566467, 0.10752172768115997, -1.0710211992263794, -0.28492555022239685, -1.0476733446121216, -0.1389208287000656, 0.5413312911987305, 0.40434491634368896, 0.13845333456993103, 0.1471039205789566, 0.9849050641059875, 0.09405500441789627, -0.29770994186401367, -0.31323882937431335, 0.053631171584129333, 0.2524094879627228, -0.1411900371313095, 0.131451815366745, -0.3209676146507263, -0.09946329146623611, 0.21340778470039368, 0.1564948707818985, 0.8715118169784546, -0.0016143352258950472, -0.3799190819263458, 0.8428159952163696, -0.5702492594718933, 0.2909851372241974, -0.8455067276954651, -0.5057386755943298, -1.6509557962417603, -0.001712658442556858, -0.5072792172431946, -0.058609336614608765, -1.4944709539413452, -0.19633765518665314, 1.261597752571106, -0.05568675696849823, -0.29527297616004944, 0.5291919112205505, -0.4178861081600189, -0.47741734981536865, -0.20630885660648346, -1.2213557958602905, 0.6623438000679016, 0.549635112285614, -0.9674392938613892, -0.015465441159904003, -0.16391430795192719, -0.7611914873123169, 0.6557824015617371, 0.4754610061645508, -0.8390740156173706, -0.42665398120880127, -1.349166750907898, 0.42898690700531006, -0.23846209049224854, -0.05552320182323456, -0.6634353995323181, 0.9546800255775452, 0.7293779850006104, 0.21852971613407135, -0.5870043039321899, -0.09755142033100128, -0.48917198181152344, -0.5526337027549744, -0.11096567660570145, -0.9238025546073914, -0.35995182394981384, 0.002130248351022601, 0.009901262819766998, -0.6385349631309509, 0.30841967463493347, -0.5026554465293884, -0.8559977412223816, -0.622172474861145, 0.16982153058052063, -0.8808299899101257, -0.07771425694227219, -0.0707758441567421, -0.34726157784461975, -1.2045211791992188, -0.5977174043655396, -0.22454559803009033, 0.593464732170105, -0.4661618769168854, 0.8180752396583557, -0.14495953917503357, -1.1156433820724487, -0.6365147233009338, -0.17468422651290894, -0.13277600705623627, 0.17811432480812073, 0.6500077843666077, 0.11140934377908707, -0.21292732656002045, 0.6695758700370789, 0.48242536187171936, 0.23898304998874664, -0.7723705172538757, -0.2674541473388672, 0.25735461711883545, -0.38167834281921387, -0.6307395696640015, 0.8141157031059265, -0.3735653758049011, -0.5245760679244995, 0.26641854643821716, -1.0155820846557617, -1.2223594188690186, 0.39218252897262573, 1.3535164594650269, 0.3779790997505188, -0.25017663836479187, -0.16819651424884796, -0.2845105528831482, 0.4444003999233246, -0.2832672595977783, -0.287545382976532, 1.2934839725494385, -0.7137134075164795, -0.3033168613910675, 0.5227512121200562, 0.7211092114448547, -0.45580026507377625, -0.578689694404602, -0.760657787322998, 0.08264573663473129, 0.2837549149990082, 0.5957922339439392, -0.323000431060791, 0.02140168659389019, 0.34206733107566833, 0.18680620193481445, 0.7137278318405151, 0.6540976762771606, 0.10616651922464371, 0.10570410639047623, 0.6478394865989685, -0.41064929962158203, -1.1081069707870483, -0.40821290016174316, 0.9950860142707825, 1.8708031177520752, -0.5730036497116089, 1.100003957748413, 0.08733326196670532, -0.6358587741851807, 1.3123399019241333, -0.16837352514266968, -0.18057242035865784, 0.855769157409668, -0.4913482367992401, 0.043539538979530334, -0.5302302837371826, -0.8966981768608093, 0.052499182522296906, 0.7398022413253784, 0.4832265377044678, 0.3035028874874115, 0.10869970917701721, -0.41131746768951416, 1.3428655862808228, 0.28270187973976135, 0.2241591364145279, 1.145857810974121, 0.48370498418807983, -0.4467882215976715, 0.2814074754714966, 0.028011420741677284, 0.6033098101615906, -1.3316707611083984, 0.10678720474243164, -0.34509238600730896, 0.9127151966094971, -0.1312025636434555, 0.8559898138046265, 0.6651148796081543, 0.266564279794693, 0.7426959276199341, 0.224641814827919, -0.18278925120830536, -0.730976402759552, -0.5341850519180298, -0.04135798662900925, 0.17213259637355804, 0.005250797141343355, -0.5980833172798157, -0.9030186533927917, -0.23528507351875305, -0.29199090600013733, -0.01633984036743641, 0.13953368365764618, 0.4646693170070648, 1.3395888805389404, 0.9575771689414978, 0.6320692300796509, -0.2272900640964508, -0.5716068148612976, -0.5037473440170288, -0.9865370392799377, -0.3856326937675476, -0.5626589059829712, 0.23023651540279388, 0.0669604241847992, -0.7190494537353516, -0.24491706490516663]}, "authors": [{"authorId": null, "name": "Shashi Narayan"}, {"authorId": "40146204", "name": "Shay B. Cohen"}, {"authorId": "1747893", "name": "Mirella Lapata"}], "references": [{"paperId": "67cd86eee52bdcfe302a4deb3e8ebcdd93a6fc62", "title": "ScisummNet: A Large Annotated Corpus and Content-Impact Models for Scientific Paper Summarization with Citation Networks"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "0bd5beed98675a63f9207851674d478009549900", "title": "Generating Summaries with Topic Templates and Structured Convolutional Decoders"}, {"paperId": "bc494b9c6d9602a69b76ab9ea0e95d348a2fce19", "title": "HighRES: Highlight-based Reference-less Evaluation of Summarization"}, {"paperId": "1c71771c701aadfd72c5866170a9f5d71464bb88", "title": "Unified Language Model Pre-training for Natural Language Understanding and Generation"}, {"paperId": "145b8b5d99a2beba6029418ca043585b90138d12", "title": "MASS: Masked Sequence to Sequence Pre-training for Language Generation"}, {"paperId": "426d517d1405cdf6c60e0e56436372a91d7d2a6d", "title": "Jointly Extracting and Compressing Documents with Summary State Representations"}, {"paperId": "a10a6495723ea8c928680ecdd61714f5750586c3", "title": "Fine-tune BERT for Extractive Summarization"}, {"paperId": "a01fb557abc65ec5c37c28ca18298f27aa0dba72", "title": "Abstractive Summarization of Reddit Posts with Multi-level Memory Networks"}, {"paperId": "c0199a7a37c22797c899571e51dba9690e606fa2", "title": "WikiHow: A Large Scale Text Summarization Dataset"}, {"paperId": "63f81ec1a331f66f8ced0c189bf30829fe017c1c", "title": "BanditSum: Extractive Summarization as a Contextual Bandit"}, {"paperId": "16d0afaeb8419ec1c37c3473ab581df916148d72", "title": "Neural Latent Extractive Document Summarization"}, {"paperId": "ddfa4ba42cc20e54b620640f320082d2f10fc89c", "title": "Improving Abstraction in Text Summarization"}, {"paperId": "7af89df3691d8c33aaf1858f7cc51da1bc9549a9", "title": "Bottom-Up Abstractive Summarization"}, {"paperId": "6b8ab30eefbbb5de171311086fcd5a4a00a6b4a3", "title": "Summarizing Opinions: Aspect Extraction Meets Sentiment Prediction and They Are Both Weakly Supervised"}, {"paperId": "2770a733eecdda23c1b3f9408c9202efec4f0da0", "title": "Guiding Generation for Abstractive Text Summarization Based on Key Information Guide Network"}, {"paperId": "41b3180745068934bd9f7f2fbc2efc00c64d534b", "title": "Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting"}, {"paperId": "d381709212dccf397284eee54a1e3010a4ef777f", "title": "A Unified Model for Extractive and Abstractive Summarization using Inconsistency Loss"}, {"paperId": "29de7c0fb3c09eaf55b20619bceaeafe72fd87a6", "title": "Hierarchical Neural Story Generation"}, {"paperId": "4e346eb1628df6a12c1a121f862fb3a16c6fec60", "title": "Newsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies"}, {"paperId": "c72582122ff631117a05deb2aefa04b01362e3fa", "title": "Learning to Extract Coherent Summary via Deep Reinforcement Learning"}, {"paperId": "46d8767a078778aaa00d436b671a78f90667ebff", "title": "Multi-Reward Reinforced Summarization with Saliency and Entailment"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "eed0e6fdc9ed7cd663f6458a391b6420d8205648", "title": "Actor-Critic based Training Framework for Abstractive Summarization"}, {"paperId": "59562be2cf8e01e8b7bb7560cef56158ea171227", "title": "Ranking Sentences for Extractive Summarization with Reinforcement Learning"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "05b1127ee39504516009b25384ca2bd7f2e1b9d9", "title": "Deep Communicating Agents for Abstractive Summarization"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "9b4a861151fabae1dfd61c917d031c86d26be704", "title": "Controllable Abstractive Summarization"}, {"paperId": "c624c38e53f321a6df2d16bd707499ce744ca114", "title": "Abstractive Document Summarization with a Graph-Based Attentional Neural Model"}, {"paperId": "524fd6d2bd91bc9fc6ff7f4ee19e52f652718644", "title": "Best-Worst Scaling More Reliable than Rating Scales: A Case Study on Sentiment Intensity Annotation"}, {"paperId": "80becd9dacaa403e1dc7da5ea2f148db6a252ec2", "title": "Graph-based Neural Multi-Document Summarization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "032274e57f7d8b456bd255fe76b909b2c1d7458e", "title": "A Deep Reinforced Model for Abstractive Summarization"}, {"paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0", "title": "Convolutional Sequence to Sequence Learning"}, {"paperId": "309a8aef55ca8f89ef56973bb2c3b38d84a29113", "title": "Neural Extractive Summarization with Side Information"}, {"paperId": "668db48c6a79826456341680ee1175dfc4cced71", "title": "Get To The Point: Summarization with Pointer-Generator Networks"}, {"paperId": "b53907a11dc14d7d36e56212b6af71f8b22020af", "title": "Selective Encoding for Abstractive Sentence Summarization"}, {"paperId": "0dc964d025422fb0905b2065a5d09fd59b9e6e77", "title": "The limits of automatic summarisation according to ROUGE"}, {"paperId": "88caa4a0253a8b0076176745ebc072864eab66e1", "title": "Language Modeling with Gated Convolutional Networks"}, {"paperId": "1bc49abe5145055f1fa259bd4e700b1eb6b7f08d", "title": "SummaRuNNer: A Recurrent Neural Network Based Sequence Model for Extractive Summarization of Documents"}, {"paperId": "f958d4921951e394057a1c4ec33bad9a34e5dad1", "title": "A Convolutional Encoder Model for Neural Machine Translation"}, {"paperId": "7ab2166f6cdb1737e000df66d29c6538afc6811d", "title": "TopicRNN: A Recurrent Neural Network with Long-Range Semantic Dependency"}, {"paperId": "2759976e7d8a27c788fb52a24830fc63ce0de570", "title": "Why Neural Translations are the Right Length"}, {"paperId": "e948c83c01187df81dc9de15dea7e18a0b0468a9", "title": "Towards Constructing Sports News from Live Text Commentary"}, {"paperId": "5ab72d44237533534de8402e30f3ccce25ce30de", "title": "Distraction-Based Neural Networks for Modeling Document"}, {"paperId": "e8b7225037dfa77623824f28f58927212bc3949e", "title": "Neural Network-Based Abstract Generation for Opinions and Arguments"}, {"paperId": "507d6e09f51b2fc93f756ab748f6eadd11b7b86e", "title": "Learning-Based Single-Document Summarization with Compression and Anaphoricity Constraints"}, {"paperId": "29a294eaec7b485245aa21d994f7300f6b5da8fc", "title": "Neural Summarization by Extracting Sentences and Words"}, {"paperId": "02534853626c18c9a097c2712f1ddf3613257d35", "title": "Incorporating Copying Mechanism in Sequence-to-Sequence Learning"}, {"paperId": "6067628004373e61b962bd4b470308882e57448b", "title": "Contextual LSTM (CLSTM) models for Large scale NLP tasks"}, {"paperId": "f37076f426023241f19cdc2fb0a0fd733a6fa7fa", "title": "Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond"}, {"paperId": "33108287fbc8d94160787d7b2c7ef249d3ad6437", "title": "Modeling Coverage for Neural Machine Translation"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "adcfef04625c2763028815759750d47c7c3fe689", "title": "\u5927\u898f\u6a21\u8981\u7d04\u8cc7\u6e90\u3068\u3057\u3066\u306eNew York Times Annotated Corpus"}, {"paperId": "a8583c6e8bc2f6bcb9b200910b76ff534d7b246e", "title": "Best-Worst Scaling: Theory, Methods and Applications"}, {"paperId": "1ac30af5522c7a50ec4d1ee43fd2bd8652a9bd52", "title": "A Neural Attention Model for Abstractive Sentence Summarization"}, {"paperId": "52ebb5873677dd900a97e4bd4042fb40be14f937", "title": "Topical Coherence for Graph-based Extractive Summarization"}, {"paperId": "f12192424dfd1a2df308346520556a1a7ed6094c", "title": "Optimizing Sentence Modeling and Selection for Document Summarization"}, {"paperId": "b122a828f5fee3c6afc54e70f41b00184d6383fc", "title": "LCSTS: A Large Scale Chinese Short Text Summarization Dataset"}, {"paperId": "d1505c6123c102e53eb19dff312cb25cea840b72", "title": "Teaching Machines to Read and Comprehend"}, {"paperId": "9653d5c2c7844347343d073bbedd96e05d52f69b", "title": "Pointer Networks"}, {"paperId": "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e", "title": "End-To-End Memory Networks"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e", "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"}, {"paperId": "4d36e239f21ae8d1553e38a050e465347e73d8f8", "title": "Extractive Summarization using Continuous Vector Space Models"}, {"paperId": "1f9b0dda97b9f787a64ad2b2c006e83b9cdf042f", "title": "Fast and Robust Compressive Summarization with Dual Decomposition and Multi-Task Learning"}, {"paperId": "aa7bfd2304201afbb19971ebde87b17e40242e91", "title": "On the importance of initialization and momentum in deep learning"}, {"paperId": "e8c2f3247d8d6f8586b73bfa87f8c8bef8f055ea", "title": "Generating Extractive Summaries of Scientific Paradigms"}, {"paperId": "d1275b2a2ab53013310e759e5c6878b96df643d4", "title": "Context dependent recurrent neural network language model"}, {"paperId": "84069287da0a6b488b8c933f3cb5be759cb6237e", "title": "On the difficulty of training recurrent neural networks"}, {"paperId": "6d9dc8cdfd8fc7d5fa54bc42aa4e97191a0832e3", "title": "Multiple Aspect Summarization Using Integer Linear Programming"}, {"paperId": "1d1d8900596aec8759239e2739f777a9ed77b717", "title": "Annotated Gigaword"}, {"paperId": "9a2ff12901dbf606d0306593081c5dcbb9fb6e4b", "title": "Jointly Learning to Extract and Compress"}, {"paperId": "413c1142de9d91804d6d11c67ff3fed59c9fc279", "title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization"}, {"paperId": "6c95908d08323c5acfc5bfdf7399f31563ade4f5", "title": "Discourse Constraints for Document Compression"}, {"paperId": "d15f8a1e6cbe110bff7aca45b63ba068a2f03d97", "title": "Towards a Unified Approach to Simultaneous Single-Document and Multi-Document Summarizations"}, {"paperId": "7453a974d355883f342aaa6e29eb86a13edcedb9", "title": "Automatic Generation of Story Highlights"}, {"paperId": "f9a00e41500c5e23fcc1ab3502a2c20acf4b8f6a", "title": "Summarization with a Joint Model for Sentence Extraction and Compression"}, {"paperId": "65810ccd8be5010a6a4b9e51cf4b229761b15e99", "title": "Enhancing diversity, coverage and balance for summarization through structure learning"}, {"paperId": "dfe2fa7bccd54940823feaaf22b063ea7af411a7", "title": "FastSum: Fast and Accurate Query-based Multi-document Summarization"}, {"paperId": "0be949cc24188ef7205bdaaeb7df2508344b8d5a", "title": "DUC in context"}, {"paperId": "802b58b789338b2325d4d7361044809f3e2ca949", "title": "Automatic summarising: The state of the art"}, {"paperId": "bb88d2460070a1157165b86e93f3ed61878adef8", "title": "Document Summarization Using Conditional Random Fields"}, {"paperId": "e603906531a44ed64aa57d15dc68db10b75ae7be", "title": "Multi-Document Summarization by Maximizing Informative Content-Words"}, {"paperId": "6d9f0bcb44ac9a266e5de7eeada0f01b5f957d84", "title": "A compositional context sensitive multi-document summarizer: exploring the factors that influence summarization"}, {"paperId": "aa5d79f1c2ec606b836a4fe3fd6cee795d336c1e", "title": "Automatic Text Summarization of Newswire: Lessons Learned from the Document Understanding Conference"}, {"paperId": "44fca068eecce2203d111213e3691647914a3945", "title": "LexRank: Graph-based Lexical Centrality as Salience in Text Summarization"}, {"paperId": "f2a665c064f84a301d64a0ab79f9ed6047dc74e2", "title": "Event-Based Extractive Summarization"}, {"paperId": "91fa6f6dfb09d3a38e500c2eafa3606b87924aa4", "title": "The Effects of Human Variation in DUC Summarization Evaluation"}, {"paperId": "7b95d389bc6affe6a127d53b04bcfd68138f1a1a", "title": "TextRank: Bringing Order into Text"}, {"paperId": "d8554b2ceb4a171667abb8acf6e262b621b51a1e", "title": "MEAD - A Platform for Multidocument Multilingual Text Summarization"}, {"paperId": "8bb5860185c6a8656176e64ce239c320d387a53e", "title": "Hedge Trimmer: A Parse-and-Trim Approach to Headline Generation"}, {"paperId": "c63bb976dc0d3a897f3b0920170a4c573ef904c6", "title": "Automatic Evaluation of Summaries Using N-gram Co-occurrence Statistics"}, {"paperId": "92ba9c288cbd0089cf6e9d988c9672f095a67109", "title": "Using Hidden Markov Modeling to Decompose Human-Written Summaries"}, {"paperId": "b0330630a66b982d243d8b5efcd1beb36714cdff", "title": "Inferring Strategies for Sentence Ordering in Multidocument News Summarization"}, {"paperId": "1058ed844c2c291733e355f1ba84d3e85547e270", "title": "Automatic summarization of English broadcast news speech"}, {"paperId": "10ce81dadc2e07d69c8a4f0bbdf7d14b3f37882e", "title": "The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries"}, {"paperId": "5a343015d755a9001a26287b7a92028b5d026617", "title": "Bootstrap Methods and Their Application"}, {"paperId": "d80a6a85b0c263d638877fff66ddc12963e3c34f", "title": "A trainable document summarizer"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "ed0370be4ff9d76a44d77a290f20bd4345fef1e1", "title": "ScisummNet: A Large Annotated Corpus and Content-Impact Models for Scienti\ufb01c Paper Summarization with Citation Networks"}, {"paperId": "98346b7de76e905d9f23064cf02606e4771e03c4", "title": "Supplementary: Document Modeling with External Attention for Sentence Extraction"}, {"paperId": "1363c78901f7204047241768af8c13e49f405625", "title": "Improving Neural Abstractive Document Summarization with Explicit Information Selection Modeling"}, {"paperId": null, "title": "resolves UNK by simply copying the most attended word from the source text"}, {"paperId": "4574d77fff19e093782178595a8988a7f3aa1969", "title": "Latent Dirichlet Allocation"}, {"paperId": "4c915c1eecb217c123a36dc6d3ce52d12c742614", "title": "Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning"}, {"paperId": "e17283db2dadc7467802648ac2a94945dc7a5242", "title": "Using Lexical Chains for Text Summarization"}, {"paperId": "343219e299d980873c72f37c21841a0ea54b2c1d", "title": "Sentence extraction as a classification task"}, {"paperId": null, "title": "Best-worst scaling: A model for the largest difference judgments. University of Alberta"}, {"paperId": null, "title": "An expert\u2019s advice for college students and parents"}, {"paperId": null, "title": "none of the RNN-based abstractive models generates UNK words on XSum. We believe this is due to the smaller vocabulary size (81,092 for XSum vs. 157,939 for Newsroom-Abs; Table 2)"}]}