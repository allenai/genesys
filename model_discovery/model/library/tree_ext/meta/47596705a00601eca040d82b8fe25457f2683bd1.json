{"paperId": "47596705a00601eca040d82b8fe25457f2683bd1", "title": "Hardware-Software Co-Design of an In-Memory Transformer Network Accelerator", "abstract": "Transformer networks have outperformed recurrent and convolutional neural networks in terms of accuracy in various sequential tasks. However, memory and compute bottlenecks prevent transformer networks from scaling to long sequences due to their high execution time and energy consumption. Different neural attention mechanisms have been proposed to lower computational load but still suffer from the memory bandwidth bottleneck. In-memory processing can help alleviate memory bottlenecks by reducing the transfer overhead between the memory and compute units, thus allowing transformer networks to scale to longer sequences. We propose an in-memory transformer network accelerator (iMTransformer) that uses a combination of crossbars and content-addressable memories to accelerate transformer networks. We accelerate transformer networks by (1) computing in-memory, thus minimizing the memory transfer overhead, (2) caching reusable parameters to reduce the number of operations, and (3) exploiting the available parallelism in the attention mechanism computation. To reduce energy consumption, the following techniques are introduced: (1) a configurable attention selector is used to choose different sparse attention patterns, (2) a content-addressable memory aided locality sensitive hashing helps to filter the number of sequence elements by their importance, and (3) FeFET-based crossbars are used to store projection weights while CMOS-based crossbars are used as an attentional cache to store attention scores for later reuse. Using a CMOS-FeFET hybrid iMTransformer introduced a significant energy improvement compared to the CMOS-only iMTransformer. The CMOS-FeFET hybrid iMTransformer achieved an 8.96\u00d7 delay improvement and 12.57\u00d7 energy improvement for the Vanilla transformers compared to the GPU baseline at a sequence length of 512. Implementing BERT using CMOS-FeFET hybrid iMTransformer achieves 13.71\u00d7 delay improvement and 8.95\u00d7 delay improvement compared to the GPU baseline at sequence length of 512. The hybrid iMTransformer also achieves a throughput of 2.23 K samples/sec and 124.8 samples/s/W using the MLPerf benchmark using BERT-large and SQuAD 1.1 dataset, an 11\u00d7 speedup and 7.92\u00d7 energy improvement compared to the GPU baseline.", "venue": "Frontiers in Electronics", "year": 2022, "citationCount": 8, "influentialCitationCount": 1, "openAccessPdf": {"url": "https://www.frontiersin.org/articles/10.3389/felec.2022.847069/pdf", "status": "GOLD"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes an in-memory transformer network accelerator (iMTransformer) that uses a combination of crossbars and content-addressable memories to accelerate transformer networks."}, "embedding": {"model": "specter_v2", "vector": [0.3790937066078186, -0.05894368141889572, -0.2298157811164856, 0.11786582320928574, -0.23869688808918, 0.0180924404412508, 0.18068304657936096, -0.1163017675280571, -0.5081789493560791, -0.4197124242782593, 0.6207951903343201, -0.05270516127347946, 0.41826948523521423, -0.2628325819969177, -0.16696035861968994, 0.025271445512771606, -0.6671671867370605, -0.17432193458080292, 0.6441457867622375, 0.13171470165252686, 0.39439406991004944, -0.23843567073345184, -1.3961951732635498, 0.32398325204849243, -0.14823293685913086, 1.2834352254867554, 0.33682411909103394, 0.847748875617981, -0.16348639130592346, 0.6139763593673706, 0.9317438006401062, -0.24313829839229584, 0.13896533846855164, 0.20433245599269867, -0.16384677588939667, -0.27705782651901245, 0.43994587659835815, -0.17183354496955872, -0.5557777881622314, 0.7998715043067932, -0.11905418336391449, 0.2634023129940033, 0.35010647773742676, -0.4300232231616974, 0.16435359418392181, 0.44309061765670776, 0.5874794721603394, 1.1246029138565063, -0.7410131692886353, -0.48058846592903137, 1.0388180017471313, -1.5530822277069092, -0.2749229669570923, 1.0994073152542114, 0.8529627323150635, 0.1447107046842575, 0.024746131151914597, -0.42188870906829834, 0.013279927894473076, 0.14855214953422546, -0.5729475617408752, -0.5310378670692444, 0.027473190799355507, -0.14069697260856628, 2.0628435611724854, -0.26125866174697876, 0.5350180864334106, 0.3289124667644501, 0.49739086627960205, 1.0205823183059692, -0.44819313287734985, -0.6333236694335938, -0.05795136094093323, -0.4550000727176666, 0.7795977592468262, 1.0211899280548096, -0.006319320760667324, 0.28871801495552063, -1.0364882946014404, 0.14919282495975494, 0.6688539981842041, 0.5985608100891113, 0.7874733209609985, -0.10091110318899155, -0.48608049750328064, 0.7281057834625244, 0.5452960133552551, 0.6701285243034363, -0.22970591485500336, 1.064530611038208, 1.0757026672363281, 0.025067629292607307, -0.30895277857780457, 0.24194863438606262, 0.48792266845703125, 0.07633865624666214, -1.1905158758163452, -0.21900120377540588, -0.2579757869243622, 0.905806839466095, -0.3181283473968506, 0.6455899477005005, -0.23632380366325378, -0.1071159616112709, 0.9218195080757141, 0.08345524966716766, 0.5476661920547485, -0.3034190833568573, -0.26547691226005554, -0.7223672866821289, -0.2424505352973938, -0.6798229813575745, -0.30835387110710144, -0.5344403386116028, -0.926605224609375, -0.9733503460884094, -0.6523209810256958, 0.7343654632568359, -0.9241217970848083, 0.04788823053240776, -0.7039309740066528, 0.5384380221366882, -0.12537312507629395, -0.1816401481628418, 0.6342390179634094, 0.394963800907135, 0.1836077719926834, 0.32417383790016174, 1.2912925481796265, -1.5283843278884888, -0.5196762681007385, -0.996065616607666, -0.24360628426074982, -0.3890961706638336, -0.1667785346508026, -0.45071789622306824, -1.3615825176239014, -1.2676773071289062, -1.031295657157898, 0.049344129860401154, -0.48399969935417175, -0.3745529055595398, 0.9263275861740112, 0.18977798521518707, -1.3340038061141968, 0.8214383721351624, -0.9572351574897766, -0.30483418703079224, 0.3703336715698242, 0.4377730190753937, 0.810886561870575, 0.21057850122451782, -0.9476603269577026, 0.12846270203590393, 0.23225896060466766, -0.4919165074825287, -0.5120437145233154, -0.607066810131073, -0.6988440155982971, 0.6079590320587158, -0.16300834715366364, -0.5921410918235779, 1.285222053527832, -0.17620410025119781, -0.5286058783531189, 0.3245132565498352, -0.1841392070055008, -0.15515893697738647, -0.2755536139011383, 0.1226295530796051, -0.5704053044319153, -0.08174175024032593, -0.28572455048561096, 0.5018454194068909, 0.6595035791397095, 0.20704233646392822, -0.23927265405654907, 0.2119411677122116, -0.5204513669013977, -0.011433376930654049, -0.41787847876548767, 1.0123025178909302, -0.5289885401725769, -0.2963252663612366, 0.4199469983577728, 0.6358031034469604, -0.2345256805419922, -0.15299543738365173, -0.22275906801223755, -0.3799952566623688, 0.9310992956161499, 0.4474967420101166, 1.1961157321929932, -1.044244408607483, -1.3365426063537598, 0.11205267906188965, 0.08591460436582565, -0.14267908036708832, -0.41398242115974426, 0.34147387742996216, -0.39776936173439026, -0.025102531537413597, 0.564083456993103, -0.38538801670074463, -0.3737572729587555, -0.5721012353897095, -0.5429902672767639, -0.3739779591560364, -0.035519734025001526, 1.074386715888977, -0.9262359738349915, 0.1364961415529251, -0.24040667712688446, 0.48828426003456116, -1.0570526123046875, 0.9974822998046875, -0.028098907321691513, -0.2655106484889984, -0.21605683863162994, 0.034481436014175415, -0.07969150692224503, -0.9288930296897888, 0.5276404023170471, -0.8899913430213928, -0.13931266963481903, 0.4635219871997833, 0.22795994579792023, 1.1008288860321045, -0.11772160977125168, 0.5188453197479248, -0.39876770973205566, -0.5565482378005981, 0.34993976354599, 0.41592293977737427, -0.08824306726455688, -0.7267286777496338, 0.8325367569923401, 0.3048872947692871, -0.285277783870697, 0.46566513180732727, 1.2659763097763062, 0.9995326399803162, -0.5152854323387146, 0.2656169831752777, 0.6126607656478882, 0.1663622260093689, 0.4187060296535492, 0.10818281024694443, 0.7242615818977356, 0.12651635706424713, 0.13602621853351593, -0.38161996006965637, 0.2162807434797287, -1.1310592889785767, 0.023184597492218018, 0.7085532546043396, 0.34145984053611755, 0.6952153444290161, 0.37724393606185913, -0.746027410030365, -0.7648006081581116, -0.004551403224468231, 0.35461321473121643, 1.1583993434906006, -0.042976200580596924, 0.01814715377986431, -0.7060837149620056, -0.15291647613048553, -0.7350380420684814, -0.5746537446975708, -0.0996236577630043, -0.4623004198074341, -0.19233949482440948, -0.8212277889251709, 0.9274901747703552, 0.8763054609298706, 1.352841854095459, -0.7465532422065735, -1.2143512964248657, -0.15687736868858337, 0.17336879670619965, -0.7289206981658936, -0.8628675937652588, 0.6852311491966248, -0.7140306830406189, 0.21902860701084137, 0.4500151574611664, -0.440076619386673, 0.05274775251746178, -0.4349079132080078, 1.2138097286224365, -0.42667338252067566, -0.5386899709701538, -0.013577425852417946, 0.6528134942054749, -0.38267970085144043, -0.38825345039367676, 0.28783825039863586, -0.16906607151031494, -0.37403225898742676, 0.8303478360176086, -0.034400876611471176, -0.283622145652771, -0.11123868077993393, -0.2588590979576111, 0.07123085856437683, 0.169693723320961, 0.36577680706977844, 0.5304730534553528, -0.5543738007545471, -0.08618505299091339, -0.7468822598457336, 0.6664983034133911, 0.16415980458259583, -0.28846046328544617, 0.021925771608948708, -0.5078758001327515, -0.0002105839375872165, 0.5464739203453064, -0.6059550642967224, 0.04636929929256439, -0.8401904106140137, -0.005015876609832048, -0.839191198348999, 0.28558680415153503, -0.018342582508921623, 0.46387287974357605, -0.0859808623790741, 0.1757718324661255, 0.6730095744132996, 0.38670188188552856, 0.3370554745197296, -0.20344263315200806, -0.9973404407501221, 0.5247578024864197, 0.25455600023269653, -0.15982984006404877, -0.1514039933681488, 0.15155766904354095, -0.35995692014694214, -0.3213302195072174, -0.22106510400772095, -0.09516001492738724, -0.6369481086730957, 0.10175813734531403, -0.6534768342971802, -1.1816977262496948, -0.0819743201136589, -0.9143309593200684, 0.1005931943655014, 0.3481203317642212, -0.41364482045173645, -0.24025097489356995, -1.198500156402588, -1.3358973264694214, -0.36044034361839294, -1.4039665460586548, -1.5412976741790771, 0.18698030710220337, 0.34811586141586304, -0.3772263824939728, -0.4570152461528778, -0.47931304574012756, -0.8798632025718689, 1.426504135131836, -0.2641633152961731, 0.3655490279197693, -0.14369513094425201, -0.4834403991699219, 0.3224189877510071, -0.08720295876264572, 0.1877395510673523, -0.5021138787269592, 0.17191986739635468, -0.9711905717849731, 0.3273483216762543, -0.36183422803878784, -0.12952668964862823, 0.4258882701396942, 0.21275122463703156, 0.8199794292449951, 0.2746497690677643, -0.5530908107757568, 0.2884284257888794, 1.6223175525665283, 0.094220831990242, 0.4534785747528076, -0.13368290662765503, 0.6754262447357178, -0.5559476613998413, -0.15398041903972626, 0.4760599136352539, -0.345722496509552, 0.31194326281547546, -0.10177276283502579, -0.26490211486816406, -0.04834423214197159, -0.19808588922023773, 0.28092753887176514, 1.2748035192489624, 0.5979204773902893, 0.3134656250476837, -0.6808438897132874, 0.7184566259384155, -1.2921992540359497, -0.8419625163078308, 0.8502227067947388, 0.6880804896354675, 0.26516783237457275, 0.017564838752150536, 0.08880312740802765, 0.2312016785144806, 0.3421975374221802, 0.259858638048172, -0.5775672197341919, -1.0842621326446533, 0.38513314723968506, 0.9463185667991638, 0.6255311965942383, 0.5011045932769775, -0.2852667272090912, 0.251849502325058, 14.848904609680176, 0.7156900763511658, -0.47169890999794006, 0.5723884105682373, 0.655413806438446, 0.2223987877368927, -0.0634392648935318, -0.02261785790324211, -1.1205512285232544, 0.2700703740119934, 1.7065274715423584, 0.08136466890573502, 0.11152493953704834, 0.341602087020874, -0.20832544565200806, 0.27998989820480347, -0.5301440954208374, 0.6943787932395935, 0.5590553879737854, -1.7072111368179321, 0.04024320840835571, 0.1408054530620575, -0.11045302450656891, 0.5479280352592468, 0.9424452185630798, 0.42457863688468933, 0.39804303646087646, -0.27927497029304504, 0.41480690240859985, 0.47781985998153687, 1.3265910148620605, -0.6672332286834717, 0.4214160144329071, -0.18917478621006012, -1.3592894077301025, -0.04596509411931038, -0.5353915095329285, -0.9347988367080688, 0.03249563276767731, 0.2380228489637375, -0.5977470278739929, -0.5285075902938843, 0.1847921907901764, 0.7976841926574707, 0.3487398028373718, 0.5047131776809692, -0.07726264744997025, 0.21611903607845306, 0.10208652168512344, -0.2638942003250122, 0.17822988331317902, 0.6757257580757141, -0.2230791449546814, 0.14446921646595, 0.005800224840641022, -0.1328011453151703, 0.24799489974975586, 0.2668498456478119, -0.34944087266921997, -0.6525056958198547, -0.1385934203863144, -0.24160011112689972, 0.13562677800655365, 0.8841525316238403, -0.1573103368282318, 0.25427237153053284, -0.6474525332450867, 0.24770815670490265, 0.30032244324684143, -0.2482169270515442, -0.7893518805503845, -0.5765564441680908, 0.4499727487564087, -0.4307768940925598, 0.33147957921028137, 0.6204501390457153, -0.33999037742614746, -0.6911095976829529, -1.0271791219711304, -0.33566364645957947, 0.1857515126466751, -0.8795110583305359, -0.4554920494556427, 1.4430147409439087, -0.6779011487960815, -0.3600021004676819, 0.4200495183467865, -0.8743761777877808, -0.2585061192512512, 0.4120911657810211, -1.12807035446167, -0.4721987545490265, -0.09283070266246796, -0.19017720222473145, -0.37009361386299133, 0.17447593808174133, 1.0762770175933838, 0.3921089172363281, -0.32860010862350464, 0.23638130724430084, -0.1833093911409378, 0.106081023812294, -0.2661537528038025, -0.24980370700359344, 1.1760766506195068, 0.559956431388855, -0.43732714653015137, 0.19113679230213165, 0.08974849432706833, 0.25683239102363586, -0.7972980737686157, -0.3375200927257538, 0.6099355220794678, -0.3192664086818695, -0.11172409355640411, -0.8716058135032654, -0.744739294052124, 0.6242474913597107, 0.5601344704627991, -0.026028450578451157, 0.37042301893234253, -0.19503174722194672, -0.47873637080192566, -0.4571295976638794, -0.6855998039245605, 0.14999347925186157, 0.5302859544754028, -0.8129451870918274, -0.17529883980751038, -0.6884965896606445, 0.2811066508293152, -1.065622091293335, -0.822181224822998, -0.12214425951242447, 0.48072317242622375, -0.454312264919281, 1.185534119606018, 0.1790834367275238, 1.0569928884506226, 0.9049789905548096, 0.03846998140215874, -0.299667626619339, -0.1161007210612297, -0.4818035066127777, -0.12412858754396439, 0.02638573944568634, 0.18421413004398346, -0.3477083444595337, 0.6233718395233154, 0.47611814737319946, 0.1444556713104248, -0.455982506275177, -0.23546278476715088, 0.11804305016994476, -0.5287014842033386, -0.3279683291912079, 0.3124977946281433, -0.3385632038116455, 0.28470921516418457, 0.2887064218521118, 0.4251279830932617, -0.0033569152001291513, -0.17880696058273315, -0.3375874161720276, -0.2186490297317505, -0.24190722405910492, -0.2545216381549835, -0.5304791331291199, -0.9996182918548584, -1.1224783658981323, -0.2599650025367737, -1.0349926948547363, 0.007943703792989254, -0.34270620346069336, 0.17829479277133942, -0.0706326961517334, -0.518441915512085, 0.1240372359752655, 0.2183956652879715, 0.12868456542491913, -0.4008120000362396, -0.6741031408309937, -0.722304105758667, 0.551474928855896, 0.7098976373672485, -0.4104730486869812, 0.41456758975982666, -0.5092668533325195, -0.0898708701133728, 0.22573833167552948, 0.21936841309070587, -0.3202688694000244, -0.8687313795089722, -0.9101231098175049, 0.12208627164363861, 0.15501298010349274, -0.33434224128723145, -1.3785008192062378, 1.2055431604385376, 0.6889654397964478, 0.12421663105487823, -0.39203619956970215, 0.1978420466184616, -0.91190105676651, -0.2296571582555771, 0.7335196733474731, -0.562566876411438, 0.8552380800247192, 0.8568711876869202, -0.7582921385765076, -0.2406068742275238, 0.6976102590560913, 0.2824847996234894, -0.8686047792434692, -1.144902229309082, 0.46689459681510925, -0.886603593826294, 0.1725846827030182, -0.3757393956184387, -0.28891855478286743, -0.9054812788963318, -0.17166069149971008, -0.007659677416086197, 0.06394694745540619, -0.36328041553497314, 0.6365891695022583, 0.8591530919075012, -1.072672963142395, 0.4076429307460785, 0.7222630977630615, -0.3233569264411926, -0.42962852120399475, 0.6279373168945312, 0.5574659705162048, -0.47090375423431396, 0.372927725315094, -0.46113038063049316, 0.08790726214647293, -1.1270453929901123, 0.4636107087135315, 0.8919684290885925, -0.6129833459854126, 0.06386470049619675, 0.8075461387634277, -0.3499908745288849, -0.42800232768058777, 0.014071127399802208, -1.088441014289856, -0.4820547103881836, -0.39022305607795715, 0.9215933084487915, 0.028569959104061127, 0.34566909074783325, 0.165087029337883, -0.6151549816131592, 0.04034911096096039, -0.20537206530570984, -0.37647074460983276, 0.248511403799057, 0.26609373092651367, -0.3746071457862854, 0.3526850640773773, 0.7494537830352783, -0.8728064298629761, -0.5893308520317078, -0.9150915741920471, -0.19944073259830475, -0.030825408175587654, 0.36249780654907227, 0.11333408206701279, -0.9838137030601501, 0.7609469294548035, 0.8069748878479004, 0.04212123528122902, 0.6988290548324585, -0.5275970697402954, 0.4618680477142334, 0.2552850544452667, 0.1247173324227333, -0.21316970884799957, -0.325478196144104, 1.6613712310791016, 0.6587573885917664, -0.24826690554618835, 0.20929276943206787, -0.19541135430335999, -0.30472052097320557, 1.2020152807235718, 0.43937957286834717, -0.43359389901161194, 1.085681438446045, 0.9293131232261658, -0.20428043603897095, 0.12415406107902527, -1.044609546661377, -0.20523689687252045, 0.3685828745365143, 0.6153684854507446, 0.811966061592102, -0.02621762827038765, 0.30783385038375854, 0.7375209331512451, 0.483072429895401, 0.26708874106407166, 0.4062938094139099, 0.7028639912605286, -0.15167304873466492, -0.1403467357158661, -0.011489242315292358, 0.7733213305473328, -0.8296630382537842, -1.081142783164978, 0.5829707384109497, 0.6037943363189697, -0.18771398067474365, 0.3482970595359802, 1.5232701301574707, -0.5962592959403992, 0.5029987096786499, -0.10844676941633224, 0.5493590831756592, -0.13633224368095398, -0.9446433186531067, 0.04603050649166107, -0.6275613307952881, -0.16976727545261383, -0.21182215213775635, -0.48767325282096863, -0.5237699151039124, -0.5187974572181702, 0.44919466972351074, 0.035814620554447174, 0.059596721082925797, 0.5304876565933228, 0.7947490215301514, 1.402181625366211, -0.3109529912471771, -0.7993364334106445, -0.24220995604991913, -0.7122889757156372, 0.2588999569416046, -0.6323344111442566, -0.025125809013843536, -0.21060359477996826, 0.03744025528430939, -0.3396502435207367]}, "authors": [{"authorId": "2086240", "name": "Ann Franchesca Laguna"}, {"authorId": "2287007346", "name": "Mohammed Mehdi"}, {"authorId": "153208721", "name": "A. Kazemi"}, {"authorId": "35875297", "name": "Xunzhao Yin"}, {"authorId": "2751894", "name": "M. Niemier"}, {"authorId": "2192525369", "name": "Sharon Hu"}], "references": [{"paperId": "92729b71a1da6b6a5426e0dd79baee4fe938b826", "title": "SAPIENS: A 64-kb RRAM-Based Non-Volatile Associative Memory for One-Shot Learning and Inference at the Edge"}, {"paperId": "e6f55f010f13d92ab8042c77cb1b7c35f2c2121f", "title": "Across-Array Coding for Resistive Memories With Sneak-Path Interference and Lognormal Distributed Resistance Variations"}, {"paperId": "5028f9a02defaabf52d2b047216604a2a866ac6c", "title": "A Flash-Based Multi-Bit Content-Addressable Memory with Euclidean Squared Distance"}, {"paperId": "8bd63a8c9e27e9f61744833360f04c0d11a62aaa", "title": "MIMHD: Accurate and Efficient Hyperdimensional Inference Using Multi-Bit In-Memory Computing"}, {"paperId": "ff9bc524b62f690db05aa77fa126c30316af9c1c", "title": "Application-driven Design Exploration for Dense Ferroelectric Embedded Non-volatile Memories"}, {"paperId": "98fa341022daa8204cf830a2862376958f59d62b", "title": "Attention-in-Memory for Few-Shot Learning with Configurable Ferroelectric FET Arrays"}, {"paperId": "fbcafa9e32ef6d0bac9b912ca50405f63fd2332a", "title": "Ratio-based multi-level resistive memory cells"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "7bb6015f45457fdbe3bb39e17dc9cb0786ecd688", "title": "A Modern Primer on Processing in Memory"}, {"paperId": "5cdbe6ddc13c50b156f6d0dc58c297289857649a", "title": "In-Memory Nearest Neighbor Search with FeFET Multi-Bit Content-Addressable Memories"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "2b63c513b0cedac4913cd642cb547f4d272929de", "title": "Seed-and-Vote based In-Memory Accelerator for DNA Read Mapping"}, {"paperId": "99026c277735284df33636455702e9eaf469583b", "title": "ReTransformer: ReRAM-based Processing-in-Memory Architecture for Transformer Acceleration"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "755f16fdbbfb0b128adb3cda9c8c2799aea34290", "title": "Extremely Low Bit Transformer Quantization for On-Device Neural Machine Translation"}, {"paperId": "13d529dc8dd1687526ee9642eb067b49436070e2", "title": "Attentive Fusion Enhanced Audio-Visual Encoding for Transformer Based Robust Speech Recognition"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "f46c562229c5bc419bbbfb63239431590e4b340a", "title": "Train Big, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers"}, {"paperId": "dbdd71f0d482d6ffc2f6b045bc2aa3b26fa39e5f", "title": "In-Memory Computing in Emerging Memory Technologies for Machine Learning: An Overview"}, {"paperId": "62aa3f35c30702d87c5faf90a450369ee4da8db9", "title": "FARM: A Flexible Accelerator for Recurrent and Memory Augmented Neural Networks"}, {"paperId": "4b5cc2b25be1a2f9e8693a131a34a7f274cba7f0", "title": "Understanding Self-Attention of Self-Supervised Audio Transformers"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "cb8f42be23fc1d147db93f9774a2b12ada360bba", "title": "Isaac"}, {"paperId": "1b7601652f5b9ce8824eca06da9d2ef246361f8c", "title": "Computing-in-Memory for Performance and Energy-Efficient Homomorphic Encryption"}, {"paperId": "1a3c4fbc5e244bab3227f42cfb011bc93c79d864", "title": "FeFET: A versatile CMOS compatible device with game-changing potential"}, {"paperId": "5290d7921f0266c8b50b79fc8a0b7d22868f4f60", "title": "The Cost of Training NLP Models: A Concise Overview"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "123b1964ca1f217caa95a95c09924ee2d9f904ea", "title": "FeCAM: A Universal Compact Digital and Analog Content Addressable Memory Using Ferroelectric"}, {"paperId": "0ff02cddd42e0434ff0e768ab1117ff326e3db6c", "title": "Memory devices and applications for in-memory computing"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "647cc5d6bb2de6d7e1c62b34642a22b688d79a8e", "title": "A Fast and Energy Efficient Computing-in-Memory Architecture for Few-Shot Learning Applications"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "f4e0723e048941ea73c77a7c69dbb731ef8de750", "title": "Bridging Text and Video: A Universal Multimodal Transformer for Video-Audio Scene-Aware Dialog"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "0e22d8a86c17c415d9c1f737fb8cb7ada5e75656", "title": "Ferroelectric ternary content-addressable memory for one-shot learning"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "132ae47905b1a648c095da54b8533e87cf642897", "title": "Fully Quantized Transformer for Machine Translation"}, {"paperId": "02e39222b6491eb945733e0885a4a007e87fa4d5", "title": "Audiovisual Transformer Architectures for Large-Scale Classification and Synchronization of Weakly Labeled Audio Events"}, {"paperId": "ce106590145e89ea4b621c99665862967ccf5dac", "title": "Q8BERT: Quantized 8Bit BERT"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "ca8794c8b50fedab08f4404235abe747626ce2d2", "title": "An Ultra-Dense 2FeFET TCAM Design Based on a Multi-Domain FeFET Model"}, {"paperId": "208577b5827f019f765ec0b7bb83dd1f4d2facdf", "title": "Analog content-addressable memories with memristors"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "bd4cd0d7e954abc298b5ee46511578ef07858875", "title": "X-MANN: A Crossbar based Architecture for Memory Augmented Neural Networks"}, {"paperId": "a52f9317ae528087324b1126923cef8bd46e3f13", "title": "Ferroelectric FET Based In-Memory Computing for Few-Shot Learning"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "c0b317be2ab7e6434c4d5a36f7cc4e87f6f6289d", "title": "Design of Hardware-Friendly Memory Enhanced Neural Networks"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "61218c257e9945e47b59ea15fdf5178d06411cca", "title": "RASSA: Resistive Prealignment Accelerator for Approximate DNA Long Read Mapping"}, {"paperId": "aa6516158b7cad7d9ad7e83b690c296d19b2f7c7", "title": "A ferroelectric field effect transistor based synaptic weight cell"}, {"paperId": "391b9abe440b2d1068a979efad93e9e5d2f57f37", "title": "Computing in memory with FeFETs"}, {"paperId": "6fea0db6b77faedb51e0a1f0f976d6dc46f3e1a1", "title": "RADAR: A 3D-ReRAM based DNA Alignment Accelerator Architecture"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "302c56e718d449b25cd3d6873f2e58078c584617", "title": "Marian: Fast Neural Machine Translation in C++"}, {"paperId": "8d6a334ebf682a0483960625661b65411c4800e7", "title": "Design and optimization of FeFET-based crossbars for binary convolution neural networks"}, {"paperId": "eb878bd0679579e2cbaadb55b4134d193c89c266", "title": "NeuroSim: A Circuit-Level Macro Model for Benchmarking Neuro-Inspired Architectures in Online Learning"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "e467bc21bae51a6ff782d213a2b3db8b717ac2a9", "title": "In-Memory Processing Paradigm for Bitwise Logic Operations in STT\u2013MRAM"}, {"paperId": "8593b583276e8259e8a18ac86f388fd6dbee1c56", "title": "Design and benchmarking of ferroelectric FET based TCAM"}, {"paperId": "d1b53e3a977dffe016d88387e59e48d6dbdedcc6", "title": "In-Memory Computation of a Machine-Learning Classifier in a Standard 6T SRAM Array"}, {"paperId": "29092f0deaac3898e43b3f094bf15d82b6a99afd", "title": "Learning to Remember Rare Events"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "7f7c2e6cf49d88825e79b66f9ae8108fcb64d11a", "title": "Emerging Memory Technologies: Recent Trends and Prospects"}, {"paperId": "9071775ebcfebddd54d879fe7e6c627673e4d305", "title": "ISAAC: A Convolutional Neural Network Accelerator with In-Situ Analog Arithmetic in Crossbars"}, {"paperId": "c5d9c2d338f56441f6b9929dfa1c1ee97e0d8576", "title": "Acceleration of Deep Neural Network Training with Resistive Cross-Point Devices: Design Considerations"}, {"paperId": "67b76200ca430d3dc7b980f9a6570eb2cd188c06", "title": "A 28 nm Configurable Memory (TCAM/BCAM/SRAM) Using Push-Rule 6T Bit Cell Enabling Logic-in-Memory"}, {"paperId": "a6d61c32cb27e9cb7c8576ea51206ab9d4d8f53b", "title": "Emerging Trends in Design and Applications of Memory-Based Computing and Content-Addressable Memories"}, {"paperId": "323201d1d3d2617736cc4d853c6519ab0fdc1702", "title": "A High-Performance and Energy-Efficient TCAM Design for IP-Address Lookup"}, {"paperId": "0b44fcbeea9415d400c5f5789d6b892b6f98daff", "title": "Building a Large Annotated Corpus of English: The Penn Treebank"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "5d8e604c95b3ade2a77e7c3e045e325f34f4c8d8", "title": "Design, Automation & Test in Europe Conference & Exhibition, DATE 2021, Grenoble, France, February 1-5, 2021"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "f5ad5d0fa3313fb5450ed19a2a94c84450d91d46", "title": "A Self-Disabled Sensing Technique for Content-Addressable Memories"}, {"paperId": "f3a217c11175f2cf904b2f7f6378b7ade176f2d0", "title": "Associative memory. A system-theoretical approach"}, {"paperId": null, "title": "NY, USA"}, {"paperId": null, "title": "In-Memory Transformer Network Accelerator"}, {"paperId": null, "title": "this article, or claim that may be made by its manufacturer, is not endorsed by the publisher. Copyright \u00a9 2022 Laguna, Shari \ufb01"}, {"paperId": null, "title": "Conflict of Interest: The authors"}]}