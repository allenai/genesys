{"paperId": "a8404aa3b7eb9799be52a2a8789bea3733da8950", "title": "Graph Convolutions Enrich the Self-Attention in Transformers!", "abstract": "Transformers, renowned for their self-attention mechanism, have achieved state-of-the-art performance across various tasks in natural language processing, computer vision, time-series modeling, etc. However, one of the challenges with deep Transformer models is the oversmoothing problem, where representations across layers converge to indistinguishable values, leading to significant performance degradation. We interpret the original self-attention as a simple graph filter and redesign it from a graph signal processing (GSP) perspective. We propose a graph-filter-based self-attention (GFSA) to learn a general yet effective one, whose complexity, however, is slightly larger than that of the original self-attention mechanism. We demonstrate that GFSA improves the performance of Transformers in various fields, including computer vision, natural language processing, graph regression, speech recognition, and code classification.", "venue": "arXiv.org", "year": 2023, "citationCount": 2, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes a graph-filter-based self-attention (GFSA) to learn a general yet effective one, whose complexity, however, is slightly larger than that of the original self-attention mechanism."}, "embedding": {"model": "specter_v2", "vector": [0.5235424041748047, 1.3351320028305054, 0.10683406889438629, -0.05837560445070267, 0.21803933382034302, 0.06472362577915192, 0.8056904077529907, -0.0019463773351162672, -0.02721972018480301, -0.6361036896705627, 0.5631078481674194, 0.40921810269355774, 0.6910653114318848, -0.3250722289085388, -0.3231937885284424, 0.0915934145450592, -0.9456319808959961, -0.3600897789001465, 0.32357344031333923, -0.3264752924442291, 0.023287007585167885, -0.9568945169448853, -0.9910100698471069, 0.18316611647605896, 0.2507384121417999, 0.7582950592041016, -0.0702337771654129, 0.880954384803772, -0.45716455578804016, 0.5125347375869751, 0.5748366713523865, -0.7487324476242065, 0.24807284772396088, -0.2812809646129608, -0.20753954350948334, -0.024638082832098007, 0.6927415728569031, 0.17938074469566345, -0.9053300023078918, 1.4656239748001099, -0.39517661929130554, 0.4959602355957031, 0.5030147433280945, -0.6063483357429504, -0.4588969349861145, 1.1886721849441528, 0.5974220633506775, 0.6305738687515259, -0.4514215588569641, -0.5560661554336548, 1.5995149612426758, -1.0433080196380615, 0.07106427103281021, 1.6570427417755127, 0.6573473811149597, 0.44853055477142334, -0.29868581891059875, -0.7205114960670471, 0.9688875675201416, 0.24514618515968323, -0.5331060886383057, -0.16018950939178467, 0.25003352761268616, 0.03648817166686058, 1.8230576515197754, -0.4328254759311676, 0.04692208394408226, 0.6453543901443481, 0.1446826308965683, 1.2962173223495483, 0.12360379844903946, -0.5153264403343201, -0.26024848222732544, -0.3661769926548004, 0.2622927129268646, 1.1981091499328613, -0.549528181552887, 0.2912975549697876, -0.9220150709152222, 0.08979222923517227, 0.6045483350753784, 0.11395642161369324, -0.11151470243930817, -0.023883873596787453, 0.1040923148393631, 0.6804488301277161, 0.7986649870872498, 1.0314723253250122, -0.35277533531188965, 1.2397526502609253, 0.5737008452415466, 0.31209367513656616, 0.2055450826883316, 0.34024864435195923, 0.688355028629303, 0.5934932827949524, -0.4998525381088257, -0.088433638215065, -0.14629141986370087, 1.0442909002304077, 0.04373117908835411, 0.6304367184638977, -0.4851856827735901, 0.15340515971183777, 1.0768460035324097, -0.16398388147354126, 0.4165906608104706, -0.5567931532859802, 0.009907303377985954, -0.5881739854812622, -0.5069339871406555, -1.3181164264678955, -0.006920488551259041, -0.6610952019691467, -1.2866358757019043, -1.1416313648223877, -0.193008691072464, 0.5994030833244324, -0.8607439994812012, 0.8361807465553284, -0.672604501247406, 0.4816596210002899, -0.3720189034938812, 0.09342925250530243, 0.4648227393627167, 0.5667438507080078, 0.29659563302993774, 0.32878267765045166, 0.9567158222198486, -1.0993636846542358, -0.8384400606155396, -0.9056362509727478, 0.2553967833518982, 0.12255463749170303, 0.32357487082481384, 0.04988114908337593, -1.1962032318115234, -1.2548370361328125, -0.8470314741134644, 0.38244161009788513, -0.5006122589111328, -0.020347001031041145, 1.0357378721237183, 0.44394007325172424, -1.0018771886825562, 1.3839318752288818, -0.2825702428817749, -0.51121586561203, 0.7270578145980835, 0.19367022812366486, 0.2000720500946045, -0.23826541006565094, -1.1646231412887573, 0.2004067301750183, 0.017212463542819023, -0.4388731122016907, -0.2618143856525421, -0.5577753186225891, -1.224538803100586, 0.4749807119369507, 0.40424975752830505, -0.5079309344291687, 0.9502103924751282, -0.07132048159837723, -0.9007551074028015, 0.9830705523490906, -0.1991506814956665, -0.5597172975540161, 0.2064313441514969, -0.0073510813526809216, -0.716903030872345, -0.3104306757450104, -0.09272977709770203, 0.03344612941145897, 0.8309678435325623, -0.13188669085502625, -0.061479050666093826, 0.08730185031890869, -0.6054902076721191, -0.5948501825332642, -0.402900367975235, 0.6772751808166504, -0.5776563882827759, -0.5787514448165894, 0.3862054944038391, 0.5985100269317627, 0.11700944602489471, -0.43523743748664856, -0.3625543415546417, -1.2945096492767334, 0.49658021330833435, 0.3470478057861328, 1.1518980264663696, -1.1954318284988403, -1.0288505554199219, -0.027571948245167732, 0.25562623143196106, -0.16144096851348877, -0.8450993895530701, 0.8972914814949036, -0.7569565176963806, 0.5255895256996155, -0.05907279998064041, -0.9226841926574707, 0.03657468035817146, -0.199388325214386, -0.6025776863098145, 0.0696217268705368, 0.5691394209861755, 0.8892529606819153, -1.3489307165145874, 0.053921379148960114, -0.15315544605255127, 0.13579519093036652, -0.8782666921615601, 0.9587151408195496, -0.139137864112854, -0.3667440712451935, 0.02745809406042099, -0.4185570180416107, 0.3104360103607178, -0.5090360045433044, 0.26607778668403625, -0.8079150319099426, 0.051198165863752365, 0.5096493363380432, -0.12459567189216614, 1.2417666912078857, 0.09306545555591583, 0.7411512136459351, -0.21660052239894867, -1.1691452264785767, 0.39234158396720886, 0.22862543165683746, 0.07449595630168915, -0.3156289756298065, 0.18923525512218475, -0.1628926694393158, -0.590155839920044, 0.4022882282733917, 0.24072076380252838, 0.8517964482307434, -0.06021257862448692, 0.009653299115598202, 0.823015034198761, -0.48490646481513977, 0.29327791929244995, 0.4859413206577301, 1.3427438735961914, 0.2914332449436188, 0.3904549181461334, -0.248236745595932, 0.2768729627132416, -0.9984996914863586, -0.0850181132555008, 0.7536523342132568, 0.5000584125518799, 0.9839330315589905, 0.5076680183410645, -0.6646193265914917, -0.17324140667915344, -0.1427696794271469, 1.0914735794067383, 1.3325982093811035, -0.48926034569740295, -0.41061970591545105, -0.7772538661956787, -0.48182207345962524, -0.18775169551372528, 0.014633522368967533, -0.7776123285293579, -0.7771878242492676, -0.17407195270061493, -1.0049316883087158, 0.7121965885162354, 0.2673087418079376, 1.210511326789856, -0.41819193959236145, 0.1259780079126358, 0.06297343224287033, 0.47981807589530945, -0.8621605634689331, -1.1755297183990479, 0.5031659007072449, -0.3031783998012543, -0.282720148563385, 0.18700291216373444, -0.176172137260437, 0.32863515615463257, -0.39350539445877075, 0.6765684485435486, -0.4295801520347595, -0.22761641442775726, 0.3124138414859772, 0.5813332796096802, -0.7372974157333374, -0.6433530449867249, 0.0014601320726796985, 0.14465147256851196, 0.43144190311431885, 0.42407748103141785, 0.020163774490356445, -0.060587089508771896, 0.0589735209941864, -0.12696799635887146, -0.45264795422554016, 0.0524437353014946, 0.16072826087474823, 0.2651360034942627, 0.5540398359298706, -0.11699548363685608, -1.4433573484420776, 0.9297928810119629, 0.11544876545667648, -0.16876962780952454, -0.019998591393232346, -0.8773449063301086, -0.18558137118816376, 0.602348268032074, -0.7556648850440979, -0.25286853313446045, -0.7000827789306641, 0.7661116123199463, -0.4530387818813324, -0.041636910289525986, 0.19993020594120026, 0.22780080139636993, -0.08449119329452515, 0.4735981225967407, 0.2623273730278015, 0.2500826120376587, 0.48832371830940247, 0.4745824933052063, -1.2392566204071045, 1.1850675344467163, 0.27319905161857605, 0.5224028825759888, 0.14104650914669037, 0.163081556558609, -0.8600728511810303, -0.6063779592514038, -0.5107780694961548, 0.052260491997003555, -0.5916441679000854, 0.3237367272377014, -0.6305927038192749, -1.16606605052948, 0.08303973078727722, -0.8254289627075195, -0.21414078772068024, -0.11876947432756424, -0.4141768217086792, -0.29515522718429565, -0.7454417943954468, -1.0144950151443481, -0.9554534554481506, -0.3374882936477661, -0.08791270107030869, 0.11138878017663956, 0.22336332499980927, -0.1547258496284485, -0.6160047054290771, -0.4696585237979889, -0.6607232093811035, 1.0449310541152954, -0.26959228515625, 0.47820115089416504, -0.04454038292169571, -0.4645392894744873, -0.30079811811447144, -0.07343503087759018, 0.5006504654884338, 0.23486243188381195, 0.22720670700073242, -1.029571771621704, 0.31685391068458557, -0.21502991020679474, 0.2123471349477768, 0.5126222372055054, 0.5530948042869568, 0.8606471419334412, -0.14396867156028748, -0.5062590837478638, 0.24327504634857178, 1.2975200414657593, -0.49592649936676025, 0.1324605792760849, -0.09413307905197144, 0.7768867611885071, 0.24512210488319397, -0.4360583424568176, 0.43483373522758484, 0.5277007222175598, -0.17470169067382812, 0.4818785786628723, -0.3124789893627167, -0.27377262711524963, -1.0357439517974854, 0.378182590007782, 1.3296425342559814, 0.09968582540750504, -0.10005038976669312, -0.8677352070808411, 0.8365647196769714, -1.4174071550369263, -1.2705841064453125, 0.34709078073501587, 0.5482370853424072, -0.15408866107463837, -0.02737661451101303, -0.15908178687095642, -0.04367924481630325, 0.8439496159553528, 0.5197487473487854, -0.4163745641708374, -0.37070536613464355, -0.19799922406673431, 0.6682204008102417, 0.664443850517273, 0.4545515477657318, -0.5556911826133728, 0.7749550342559814, 14.693397521972656, 0.4020669460296631, 0.10975492000579834, 0.24039863049983978, 0.4674835503101349, 0.6896677613258362, -0.21429619193077087, 0.2040327489376068, -0.5487363338470459, -0.15312980115413666, 0.5622795820236206, -0.020035013556480408, 0.7797529697418213, 0.10706782341003418, -0.010512000881135464, 0.5192053318023682, -0.48334428668022156, 0.8708183169364929, 0.442413866519928, -1.269400715827942, 0.14661787450313568, 0.18582242727279663, 0.08778588473796844, 0.4232373833656311, 0.7548365592956543, 0.658001184463501, 0.7729673385620117, -0.10207414627075195, 0.32729387283325195, 0.4645324945449829, 0.7003896236419678, 0.3901000916957855, -0.07857145369052887, 0.24587233364582062, -1.2873806953430176, -0.4055374264717102, -0.6892253160476685, -1.0504299402236938, 0.03631100431084633, 0.056581657379865646, -0.5562760829925537, -0.36520421504974365, 0.10264339298009872, 1.1113297939300537, 0.042077139019966125, 0.3619319200515747, -0.2560707926750183, 0.7112027406692505, 0.03269976004958153, -0.20802326500415802, 0.18542835116386414, 0.30412402749061584, 0.19837474822998047, 0.20934607088565826, 0.23803678154945374, 0.226742684841156, -0.10026827454566956, 0.7814420461654663, -0.3899138271808624, -0.31920915842056274, -0.3519512712955475, -0.7095195651054382, -0.24912939965724945, 0.7664546370506287, 0.41612929105758667, 0.02808152511715889, -0.5886416435241699, 0.4346392750740051, 0.2777162492275238, 0.38212907314300537, -0.27502769231796265, -0.2874584496021271, -0.026649534702301025, -0.035571906715631485, 0.018016021698713303, 0.5066720843315125, 0.021114593371748924, -0.38525596261024475, -0.9724212288856506, -0.18454883992671967, 0.7501421570777893, -1.0043184757232666, -1.0821237564086914, 0.9949617981910706, -0.7219750285148621, -0.30090317130088806, 0.4929167926311493, -0.8065177798271179, -0.8180931806564331, 0.3208259046077728, -1.161040186882019, -0.5869792699813843, -0.265459805727005, -0.16562893986701965, -0.41871172189712524, -0.4043797552585602, 0.9767177104949951, 0.04799782857298851, -0.17250598967075348, 0.01069614663720131, -0.7776817679405212, -0.04257864132523537, -0.271912544965744, -1.2476412057876587, 1.4274437427520752, 0.4751749336719513, -0.02230009436607361, 0.3199489414691925, 0.3854285478591919, 0.1906612664461136, -0.5741639733314514, 0.04908478632569313, 0.5438277125358582, -0.38565948605537415, -0.01594967022538185, -0.7928500175476074, -1.1846388578414917, 0.1311308890581131, 0.6536797285079956, 0.04262109100818634, -0.15133999288082123, -0.019024383276700974, -0.7620733976364136, -0.16229645907878876, -0.5416034460067749, 0.27756816148757935, 0.8784816861152649, -0.9642750024795532, -0.14940251410007477, -0.12621411681175232, 0.027744358405470848, -0.6009047627449036, -0.33318135142326355, -0.3065091073513031, 0.011908580549061298, -0.22242341935634613, 0.9123396873474121, -0.5312328934669495, 0.3815320134162903, 0.5776715874671936, 0.04058389365673065, -0.8697325587272644, -0.6194821000099182, -1.5972639322280884, 0.2787425220012665, 0.3710289001464844, 0.13737495243549347, -0.6405476927757263, 0.787496030330658, 0.7287462949752808, -0.10963965952396393, -0.2073969542980194, -0.361508846282959, -0.3465549349784851, -0.4898390769958496, -0.27825987339019775, 0.2954821288585663, 0.3992729187011719, 0.1448480188846588, 0.23275575041770935, 0.5436715483665466, 0.4586431384086609, 0.2594596743583679, -0.9579210877418518, 0.3558674156665802, -0.5185020565986633, 0.06977731734514236, -0.9291616082191467, -0.44958803057670593, -1.2164548635482788, 0.011243131943047047, -1.3615282773971558, -0.3715685307979584, -1.1248854398727417, -0.7838571071624756, 0.5979933738708496, -0.40614813566207886, -0.1080540269613266, 0.23805715143680573, -0.7992092370986938, -0.32273274660110474, -0.8979020714759827, -0.2811076045036316, 0.6615918874740601, 0.944785475730896, -1.109908103942871, 0.32620182633399963, 0.21004994213581085, -0.30119481682777405, 0.23902665078639984, 0.30536094307899475, -0.53318852186203, -0.7064847350120544, -0.9507485628128052, 0.12697279453277588, -0.2687334418296814, 0.08083844929933548, -1.1084779500961304, 1.137740969657898, 0.4336940348148346, -0.29435160756111145, 0.12703797221183777, 0.45071375370025635, -0.8632298111915588, -0.417409747838974, 0.49066585302352905, -0.8058977723121643, 0.17145784199237823, -0.05506818741559982, 0.06398992985486984, -0.4832873046398163, 0.9277250170707703, 0.16428408026695251, -1.498350739479065, -0.2933623492717743, 0.7377781867980957, -0.46374499797821045, 0.21389178931713104, -0.4824633300304413, -0.17208629846572876, -1.1755985021591187, -0.8077755570411682, -0.13725657761096954, 0.3342909812927246, -0.6080644726753235, 0.952456533908844, 0.2490067481994629, -1.2708648443222046, 0.16888131201267242, 0.6256721615791321, 0.12087337672710419, -0.1741316318511963, 0.5280983448028564, 0.12242385745048523, 0.12449819594621658, 0.2756150960922241, 0.30593982338905334, 0.44863414764404297, -0.5546215772628784, 0.4688760042190552, 0.8839200139045715, -0.4021247625350952, -0.4053996503353119, 1.1504110097885132, 0.09769224375486374, -0.6334505081176758, 0.2302359789609909, -1.4320437908172607, -0.4637584090232849, -0.1420229971408844, 0.09970437735319138, 0.09138418734073639, -0.314031720161438, 0.16426672041416168, -0.3479335606098175, 0.316471129655838, 0.22331377863883972, -0.18473611772060394, 0.7772289514541626, 0.07497545331716537, -0.25460517406463623, 0.30470362305641174, 0.7388377785682678, -0.5828583836555481, -0.8917835354804993, -1.113793134689331, -0.21757103502750397, -0.3192770183086395, 0.38301271200180054, 0.23248471319675446, -0.7855026125907898, 0.93013596534729, 0.28139081597328186, 1.0406173467636108, 0.27064022421836853, -0.2648598551750183, -0.1935867965221405, 0.3526061475276947, -0.32611221075057983, -0.9876295924186707, -0.11814551055431366, 1.1491434574127197, 1.3148188591003418, -0.36567309498786926, 0.012042086571455002, -0.847804069519043, -0.6984862685203552, 0.7855932712554932, 0.23785647749900818, -0.518088698387146, 1.2065423727035522, -0.28697437047958374, -0.3396816551685333, -0.18761219084262848, -1.2432318925857544, -0.6385958194732666, 0.7861682176589966, 1.3063628673553467, 0.6192893981933594, -0.04203443601727486, 0.39527538418769836, 0.8113678097724915, 0.16027691960334778, -0.11323022842407227, 0.5009043216705322, -0.12806937098503113, -0.01904826983809471, 0.26065289974212646, 0.23978690803050995, 0.5047152042388916, -0.6839165091514587, -0.4736994504928589, 0.09185979515314102, 0.5309672951698303, -0.0852036103606224, 0.5903990864753723, 0.7325038313865662, -0.24832949042320251, 0.9671011567115784, -0.0709935799241066, 0.47875261306762695, -0.5876216888427734, -0.2569466233253479, -0.0872371643781662, -0.6500731706619263, -0.08806601166725159, -0.28595468401908875, -0.9800437092781067, -0.34884974360466003, 0.1421956568956375, -0.09251904487609863, -0.0905432403087616, 0.3086293339729309, 0.42818811535835266, 0.24364949762821198, 0.9009877443313599, 0.1618824303150177, -0.1966935396194458, -0.3828648030757904, -0.986987829208374, -0.007612355053424835, -0.18739354610443115, 0.056488122791051865, -0.3569920063018799, -0.6817642450332642, -0.16502107679843903]}, "authors": [{"authorId": "67027632", "name": "Jeongwhan Choi"}, {"authorId": "2190174361", "name": "Hyowon Wi"}, {"authorId": "2109187265", "name": "Jayoung Kim"}, {"authorId": "2171121134", "name": "Yehjin Shin"}, {"authorId": "2265425696", "name": "Kookjin Lee"}, {"authorId": "2265401305", "name": "Nathaniel Trask"}, {"authorId": "2265649308", "name": "Noseong Park"}], "references": [{"paperId": "c43f5c366fff23b38f179779c4c05f6d15c09dcc", "title": "Setting the Record Straight on Transformer Oversmoothing"}, {"paperId": "5eadf15ddd1a11476dc059bff3e5cbef35ca76a1", "title": "Mitigating Over-smoothing in Transformers via Regularized Nonlocal Functionals"}, {"paperId": "ab892825da3c560ff72d84d57a4239a6f12fa8b9", "title": "Scattering Vision Transformer: Spectral Mixing Matters"}, {"paperId": "e8720b0170ee0d33b760ad58a29d77ea15b2b6a9", "title": "Centered Self-Attention Layers"}, {"paperId": "8b9f01585a679dffe92261ecdec56425db9ef97f", "title": "Demystifying Oversmoothing in Attention-Based Graph Neural Networks"}, {"paperId": "2f2d4ce7ca8ed125e3ee5ecd97bd638eabadd2e1", "title": "A Fractional Graph Laplacian Approach to Oversmoothing"}, {"paperId": "ade39c39048d66465c7288e4a7f8258a1bce9e60", "title": "Alleviating Over-smoothing for Unsupervised Sentence Representation"}, {"paperId": "c57467e652f3f9131b3e7e40c23059abe395f01d", "title": "SpectFormer: Frequency and Attention is what you need in a Vision Transformer"}, {"paperId": "12454696085d66beaeb6cd43857de982a8445824", "title": "Transformers in Speech Processing: A Survey"}, {"paperId": "90dead8a056b848be164c2e5cdadfa2e191c3265", "title": "A Survey on Oversmoothing in Graph Neural Networks"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "519193aa26820af205e6040d4595ca30ebcebcb0", "title": "ContraNorm: A Contrastive Learning Perspective on Oversmoothing and Beyond"}, {"paperId": "385c363ea8e450f362d389f401beaeb5b42a0022", "title": "Stabilizing Transformer Training by Preventing Attention Entropy Collapse"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "8ad64183b0d49ba90bdb09803c777524b8fe545b", "title": "A Non-Asymptotic Analysis of Oversmoothing in Graph Neural Networks"}, {"paperId": "67dee251b7406f5ca888532649f545be17e14df6", "title": "GREAD: Graph Neural Reaction-Diffusion Networks"}, {"paperId": "776e38d8d1bbfe4a5b7b80b803eb3c5df0e1a1b5", "title": "Random-LTD: Random and Layerwise Token Dropping Brings Efficient Training for Large-scale Transformers"}, {"paperId": "4cf7889c0fc5e181c20e64a4b26cb08ce25e7b45", "title": "Addressing Token Uniformity in Transformers via Singular Value Transformation"}, {"paperId": "0cd31a2c81f9c14d6f9c0dc810bf98388d8be459", "title": "Branchformer: Parallel MLP-Attention Architectures to Capture Local and Global Context for Speech Recognition and Understanding"}, {"paperId": "5eeb80dc67590422db64ca95ec0aded24799cfb6", "title": "Signal Propagation in Transformers: Theoretical Perspectives and the Role of Rank Collapse"}, {"paperId": "277dd73bfeb5c46513ce305136b0e71fcd2a311c", "title": "Recipe for a General, Powerful, Scalable Graph Transformer"}, {"paperId": "2afb4cacbfa6b374f72accc37e779afc593ba843", "title": "Not too little, not too much: a theoretical analysis of graph (over)smoothing"}, {"paperId": "c71f2c3f92051e34513c02b423a046f3c80cec35", "title": "A Simple Yet Effective SVD-GCN for Directed Graphs"}, {"paperId": "de0454637d24b02fb57bc4ac863664dfa2c91d44", "title": "Improving Vision Transformers by Revisiting High-frequency Components"}, {"paperId": "3a5b7838b5348315572a8c1aa8c33deea16f159d", "title": "The Principle of Diversity: Training Stronger Vision Transformers Calls for Reducing All Levels of Redundancy"}, {"paperId": "b9225c672a5078409d890393780a5eb90f2ec3ca", "title": "Anti-Oversmoothing in Deep Vision Transformers via the Fourier Domain Analysis: From Theory to Practice"}, {"paperId": "383116b2685d0c7ae9669ac929b628b9af0af5f3", "title": "Revisiting Over-smoothing in BERT from the Perspective of Graph"}, {"paperId": "a30f912f8c5e2a2bfb06351d4578e1ba3fa37896", "title": "CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation"}, {"paperId": "9b6af0e358e76d22f209c75b1702c3e6ea7815b1", "title": "Global Filter Networks for Image Classification"}, {"paperId": "8602fd5b0ac73bb422f238b265479f363c0ffe61", "title": "Refiner: Refining Self-attention for Vision Transformers"}, {"paperId": "1f133158a8973fb33fea188f20517cd7e69bfe7f", "title": "FNet: Mixing Tokens with Fourier Transforms"}, {"paperId": "a1bb2e9134ca0ee67d2cbd8c54eb021625a8f17d", "title": "Vision Transformers with Patch Diversification"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "96da196d6f8c947db03d13759f030642f8234abf", "title": "DeepViT: Towards Deeper Vision Transformer"}, {"paperId": "9389af659f14239319186dff1cef49e8ece742c8", "title": "OGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs"}, {"paperId": "0646bb09db4d1ba24150e69b71edcd4aff691b3c", "title": "Unified Pre-training for Program Understanding and Generation"}, {"paperId": "6c7c67ff9f3d5e0c0d53c672af90632d271926ac", "title": "Lipschitz Normalization for Self-Attention Layers with Application to Graph Neural Networks"}, {"paperId": "dfb37e6216e792bf6bd5a30c0fc7ad55df1cb71e", "title": "Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "dcbc25586bd446d3d011aa1614185cc1dc4f4942", "title": "Multi-hop Attention Graph Neural Networks"}, {"paperId": "024b25b6ffa156f01b31703476e429a3775967a7", "title": "Signal Processing on Directed Graphs: The Role of Edge Directionality When Processing and Learning From Network Data"}, {"paperId": "c6d550c3fcecf27b979be84c4cd444cc1c72bf47", "title": "A Note on Over-Smoothing for Graph Neural Networks"}, {"paperId": "0ee0801ba010a441403f9ed666ef9bf006b3aa07", "title": "Adaptive Universal Generalized PageRank Graph Neural Network"}, {"paperId": "0170fc76e934ee643f869df18fb617d5357e8b4e", "title": "Conformer: Convolution-augmented Transformer for Speech Recognition"}, {"paperId": "0fe2636446cd686830da3d971b31a004d6094b3c", "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages"}, {"paperId": "92515b7ed018194e340f9edefeb52d9b19f679ef", "title": "Detecting Code Clones with Graph Neural Network and Flow-Augmented Abstract Syntax Tree"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "2a6d160b529272964ce1a6707adf52f3d6ba4861", "title": "Diffusion Improves Graph Learning"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "00549af4bc3270e0f688acbf694f912d7ee39cad", "title": "Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "3c5f1ab37f70db503636075e15b3173f86eea00b", "title": "Green AI"}, {"paperId": "63c99c04869a52ac69850e21732b26d8633852ea", "title": "GRU-ODE-Bayes: Continuous modeling of sporadically-observed time series"}, {"paperId": "4ce9c20642dce5eb7930966053a1e3da4ef617f2", "title": "Graph Neural Networks Exponentially Lose Expressive Power for Node Classification"}, {"paperId": "b0fae9fbb4e580d92395eabafe73e317ae6510e3", "title": "SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition"}, {"paperId": "ea5dd6a3d8f210d05e53a7b6fa5e16f1b115f693", "title": "Graph Neural Networks: A Review of Methods and Applications"}, {"paperId": "26b47e35fe6e4260fdf7b7cc98f279a73c277494", "title": "Multi-Granularity Hierarchical Attention Fusion Networks for Reading Comprehension and Question Answering"}, {"paperId": "5aea95e1ae78a66474051a330ded374e199b658c", "title": "Representation Learning on Graphs with Jumping Knowledge Networks"}, {"paperId": "cb0f3ee1e98faf92429d601cdcd76c69c1e484eb", "title": "Neural Network Acceptability Judgments"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "33998aff64ce51df8dee45989cdca4b6b1329ec4", "title": "Graph Attention Networks"}, {"paperId": "a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096", "title": "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "36eff562f65125511b5dfab68ce7f7a943c27478", "title": "Semi-Supervised Classification with Graph Convolutional Networks"}, {"paperId": "e0b207e96351671453aa8bf05b7225c8a340a0b2", "title": "Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks"}, {"paperId": "5694e46284460a648fe29117cbc55f6c9be3fa3c", "title": "Densely Connected Convolutional Networks"}, {"paperId": "c41eb895616e453dcba1a70c9b942c5063cc656c", "title": "Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "34038d9424ce602d7ac917a4e582d977725d4393", "title": "Librispeech: An ASR corpus based on public domain audio books"}, {"paperId": "0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f", "title": "Towards End-To-End Speech Recognition with Recurrent Neural Networks"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "24a968b1a085cfb55072288b7509433c8275a69a", "title": "Discrete Signal Processing on Graphs: Frequency Analysis"}, {"paperId": "4dc1c7699b98cea7af2c457bb5647c497e7d0c03", "title": "Discrete Signal Processing on Graphs"}, {"paperId": "2c846c5ac7e8bd020b89f6c4767a01731114ee4d", "title": "ZINC: A Free Tool to Discover Chemistry for Biology"}, {"paperId": "3371d7f50540dc8e157df672c71bd0317047c3a2", "title": "Functions of matrices - theory and computation"}, {"paperId": "0b44fcbeea9415d400c5f5789d6b892b6f98daff", "title": "Building a Large Annotated Corpus of English: The Penn Treebank"}, {"paperId": "d08a0eb7024dff5c4fabd58144a38031633d4e1a", "title": "Benchmarking Graph Neural Networks"}, {"paperId": "2451a67b49177bfb442a66739b22679aca2e1fbd", "title": "Jump Self-attention: Capturing High-order Statistics in Transformers"}, {"paperId": "acf87283fa8ae426f1a4987b345b401bf2913f61", "title": "Do Transformers Really Perform Badly for Graph Representation?"}, {"paperId": "e382a73c4f87020e5ee8af8feacc6053347a129f", "title": "On Orthogonality Constraints for Transformers"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": null, "title": ": A general-purpose speech toolkit"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "8ff46c88964a36985f2b45933a3d47b81bd87bd0", "title": "Quora Question Pairs"}, {"paperId": "db8885a0037fe47d973ade79d696586453710233", "title": "The Sixth PASCAL Recognizing Textual Entailment Challenge"}, {"paperId": "475354f10798f110d34792b6d88f31d6d5cb099e", "title": "Automatically Constructing a Corpus of Sentential Paraphrases"}, {"paperId": "54006daf3f120085a75aed3554ab4bdbcfa62309", "title": "ON THE EARLY HISTORY OF THE SINGULAR VALUE DECOMPOSITION *"}, {"paperId": null, "title": "Graph Convolutions"}, {"paperId": null, "title": "we explore the influence of the polynomial order, denoted as K"}]}