{"paperId": "13d12b26db345f62e8e512db181b96a7f8763b47", "title": "An Embodied Generalist Agent in 3D World", "abstract": "Leveraging massive knowledge from large language models (LLMs), recent machine learning models show notable successes in general-purpose task solving in diverse domains such as computer vision and robotics. However, several significant challenges remain: (i) most of these models rely on 2D images yet exhibit a limited capacity for 3D input; (ii) these models rarely explore the tasks inherently defined in 3D world, e.g., 3D grounding, embodied reasoning and acting. We argue these limitations significantly hinder current models from performing real-world tasks and approaching general intelligence. To this end, we introduce LEO, an embodied multi-modal generalist agent that excels in perceiving, grounding, reasoning, planning, and acting in the 3D world. LEO is trained with a unified task interface, model architecture, and objective in two stages: (i) 3D vision-language (VL) alignment and (ii) 3D vision-language-action (VLA) instruction tuning. We collect large-scale datasets comprising diverse object-level and scene-level tasks, which require considerable understanding of and interaction with the 3D world. Moreover, we meticulously design an LLM-assisted pipeline to produce high-quality 3D VL data. Through extensive experiments, we demonstrate LEO's remarkable proficiency across a wide spectrum of tasks, including 3D captioning, question answering, embodied reasoning, navigation and manipulation. Our ablative studies and scaling analyses further provide valuable insights for developing future embodied generalist agents. Code and data are available on project page.", "venue": "arXiv.org", "year": 2023, "citationCount": 28, "influentialCitationCount": 3, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces LEO, an embodied multi-modal generalist agent that excels in perceiving, grounding, reasoning, planning, and acting in the 3D world and demonstrates its remarkable proficiency across a wide spectrum of tasks, including 3D captioning, question answering, embodied reasoning, navigation and manipulation."}, "embedding": {"model": "specter_v2", "vector": [-0.3919382095336914, 0.31912025809288025, -0.06964550912380219, -0.16870032250881195, -0.08272507786750793, 0.07747286558151245, 0.5872946977615356, -0.48533520102500916, -0.7318243384361267, -0.5035219192504883, 0.4528004825115204, 0.08761253952980042, 0.15932390093803406, 0.07067230343818665, -0.4898020923137665, 0.38694843649864197, -1.0471678972244263, 0.7190579771995544, 0.10704328864812851, -0.765564501285553, 0.022655194625258446, -0.1633278727531433, -0.8560454845428467, 0.1125611886382103, 0.2651398479938507, 0.31315919756889343, 0.7904713153839111, 1.2718361616134644, 0.2252957820892334, 0.7175425887107849, 0.36103925108909607, 0.26766982674598694, 0.275399774312973, 0.2068975865840912, -0.541927695274353, 0.09815546125173569, 0.36508768796920776, -0.9210329651832581, -0.9562071561813354, 0.5885857343673706, 0.0507170706987381, 0.2936556041240692, 0.5332267880439758, -0.7472120523452759, -0.44835707545280457, 0.25185656547546387, 0.6814613342285156, 0.2714516818523407, 0.44989028573036194, -0.5366677045822144, 1.3085129261016846, -1.2610840797424316, 0.7434820532798767, 1.9614489078521729, 0.10482160747051239, 0.7857945561408997, -0.025127846747636795, -0.2759917378425598, 1.0313615798950195, -0.33011049032211304, -0.5857575535774231, -0.21778322756290436, -0.12315306067466736, -0.09216166287660599, 1.4311646223068237, -0.860009491443634, 0.20347903668880463, 0.9486202597618103, 0.24170812964439392, 1.7502483129501343, -0.09045884758234024, -1.0731513500213623, -0.0816931501030922, -0.40464749932289124, 0.10792170464992523, 1.1901564598083496, -0.1684589982032776, 0.5102367997169495, -1.2599314451217651, 0.42089542746543884, 0.9596153497695923, -0.4365924000740051, -0.17066527903079987, -0.9656332731246948, -0.9279478192329407, 0.5919066071510315, 0.7526409029960632, 0.27560240030288696, -0.4172537326812744, 0.7561442255973816, 0.033253688365221024, 0.16963639855384827, -0.40094900131225586, 0.17660067975521088, -0.08479603379964828, 0.6435417532920837, -0.20163585245609283, 0.49678242206573486, 0.3602227568626404, 1.1465661525726318, -0.5713170170783997, -0.21840181946754456, -0.30046147108078003, 0.025004234164953232, 1.7244713306427002, 0.20526936650276184, 0.5965816974639893, -0.5501472353935242, 0.563826322555542, -0.33550503849983215, 0.6902170181274414, -0.8085848689079285, -0.8356125950813293, -0.15942883491516113, 0.05485037341713905, -0.44556060433387756, -0.3672164976596832, 0.17107868194580078, -1.0778306722640991, 0.5332223773002625, 0.21137617528438568, -0.4381531774997711, 0.3105683922767639, 0.7829293012619019, 0.9489269256591797, 0.3359203040599823, 0.22290313243865967, 1.2344143390655518, 1.230208158493042, -1.1416139602661133, -0.4499155879020691, -1.2378970384597778, 0.5266445875167847, 0.41460180282592773, 0.23978736996650696, -0.43535491824150085, -0.988344669342041, -1.0198074579238892, -1.083356261253357, -0.449476033449173, -0.9036723375320435, 0.6246761083602905, 1.1792021989822388, 0.07496730238199234, -0.9013630151748657, 0.19623389840126038, -0.43987753987312317, -0.5779802203178406, 0.3898668885231018, 0.26889950037002563, -0.4971240758895874, -0.4781317412853241, -0.47052061557769775, 0.7096056938171387, 0.7631599307060242, -0.14435486495494843, -0.7654914259910583, 0.5732107758522034, -1.6449558734893799, -0.6423400640487671, 0.22624419629573822, -1.2463322877883911, 1.261818766593933, 0.4365585744380951, -1.0770567655563354, 0.7602511644363403, -0.3673277497291565, 0.08919471502304077, 0.36818426847457886, -0.706322431564331, -0.6200729012489319, 0.08132684975862503, -0.2032402604818344, 1.1741905212402344, 0.1540965884923935, -0.8214184641838074, -0.27622032165527344, -0.15661871433258057, 0.2553434669971466, 0.2949807643890381, 0.22453157603740692, 0.821923017501831, -0.41986700892448425, -0.35157516598701477, 0.9847323894500732, 0.3115159273147583, -0.090545654296875, 0.3175729513168335, -0.3453807234764099, -0.7736712694168091, 0.8569634556770325, 0.2896668612957001, 0.13989761471748352, -0.6687712669372559, 0.03847746178507805, -0.6888440251350403, 0.03815596178174019, -0.5167236328125, -1.38468337059021, 0.5796135067939758, -0.3050658702850342, 0.19944772124290466, 0.15702728927135468, -1.0435501337051392, 0.3390711843967438, -0.1544492393732071, -0.11725140362977982, 0.1345924437046051, 0.2563150227069855, 1.5976239442825317, -1.301479458808899, -0.294937402009964, 0.22545622289180756, -0.1566038876771927, -0.8782755732536316, 1.0634851455688477, -0.8330788016319275, 0.2985086143016815, -0.6567370891571045, -0.10071025788784027, -0.3938272297382355, -0.16850554943084717, 0.2497328221797943, -0.6490121483802795, 0.0633474811911583, 0.3981168568134308, -0.6988581418991089, 2.0484402179718018, -0.2359500378370285, 0.6903173327445984, 0.09988473355770111, -0.29095715284347534, -0.14406850934028625, 0.36050406098365784, -0.7317363023757935, -0.33803126215934753, 0.47681924700737, 0.14386071264743805, -0.5846817493438721, -0.5680720806121826, 0.5283927321434021, 0.7201699614524841, -0.3042152523994446, 0.15149113535881042, 0.2073463648557663, -0.6166586875915527, 0.3011443316936493, 0.5219196081161499, 0.39449992775917053, 0.9798067808151245, 0.2931877076625824, -0.05688503757119179, 0.06842906773090363, -0.7458962798118591, -0.5768874883651733, 0.6306537389755249, 0.4703858196735382, 0.9955618381500244, 0.010315553285181522, -0.9575514793395996, 0.01890035904943943, 0.034919679164886475, 0.9003750681877136, 1.5281620025634766, 0.5946190357208252, 0.07571471482515335, -0.6016043424606323, -0.499573677778244, -0.547318696975708, 0.22699543833732605, -0.5801374316215515, 0.31379181146621704, -0.4497053623199463, -0.48488855361938477, 0.536957323551178, 0.6437032222747803, 1.4976918697357178, -1.0932649374008179, -0.7886216640472412, -0.4182299077510834, 0.07806048542261124, -1.082720398902893, -0.6452152729034424, -0.07185588032007217, -0.2045588195323944, -0.6766002774238586, 0.20548591017723083, -0.6826348900794983, 0.5555355548858643, -0.4401609003543854, 0.9395666122436523, -0.6771073341369629, 0.06554011255502701, 0.6351460814476013, 0.20598864555358887, -0.8889814019203186, -0.7760705351829529, 0.0510711707174778, 0.26415202021598816, -0.5588677525520325, -0.04964806139469147, 0.8025068640708923, 0.17845764756202698, 0.29221102595329285, -0.48310795426368713, 0.6350551247596741, 0.4309304356575012, -0.02808399312198162, 0.39239975810050964, -0.6454505324363708, 0.2738969027996063, -0.4458235800266266, 0.8520883321762085, 0.5476827621459961, -0.25050729513168335, 0.1832914799451828, 0.11186060309410095, -0.24103043973445892, -0.25140824913978577, -0.7504981160163879, -0.38329029083251953, -0.5903935432434082, 0.3043868839740753, -0.09225760400295258, -0.8987917304039001, 0.360081285238266, 0.08124666661024094, 0.0035137073136866093, 0.660523533821106, 0.40327176451683044, 0.43025708198547363, -0.06982963532209396, 0.7627907991409302, -0.8588417768478394, 0.6536816358566284, -0.1383526623249054, 0.21589305996894836, 0.15442857146263123, -0.03334913030266762, -0.6127404570579529, -0.396359384059906, -0.22794291377067566, -0.6927124261856079, -0.4506955146789551, 0.5858872532844543, -0.7656316757202148, -0.9642226099967957, 0.28960326313972473, -1.3143962621688843, -0.656882643699646, 0.48996248841285706, -0.026074614375829697, -0.6043773889541626, -1.0405207872390747, -0.9124431014060974, -0.31379860639572144, 0.10350567102432251, -1.0637568235397339, 0.6472994089126587, -0.010956478305161, -0.7444188594818115, -0.3025462031364441, 0.07420025765895844, -0.1407753974199295, 0.09704757481813431, 0.01917538233101368, 0.71849125623703, 0.08892043679952621, -0.21688595414161682, -0.5206351280212402, 0.10182042419910431, -0.09579198062419891, -0.08478092402219772, 0.03451385721564293, -0.2509653568267822, 0.2588752806186676, -0.6139889359474182, -0.5697053670883179, -0.07851216197013855, 0.11457595974206924, 0.3369094431400299, 0.643825113773346, -0.5401365756988525, 0.11226347088813782, 0.9757582545280457, -0.339717835187912, -0.2022387534379959, 0.263934463262558, 1.0073267221450806, 0.6317328810691833, -0.07417570799589157, 0.27565085887908936, 1.0206074714660645, 0.4263591766357422, 0.818010687828064, 0.07166729867458344, -0.5022379159927368, -0.907050371170044, 0.5777199864387512, 0.49288564920425415, 0.15476560592651367, -0.08034070581197739, -1.0210583209991455, 0.6167137622833252, -1.2012585401535034, -0.32689008116722107, 0.7384945750236511, 0.46568048000335693, -0.13988466560840607, -0.2134239822626114, -0.07335571199655533, -0.8695508241653442, 0.8036907315254211, 0.2333362102508545, -0.41755473613739014, -0.059342991560697556, -0.03361191228032112, -0.3728088140487671, -0.5532754063606262, 0.5458893179893494, -0.6730762124061584, 0.6152543425559998, 14.258997917175293, 0.19636046886444092, 0.3559229373931885, 0.04212166741490364, 0.3441396951675415, 0.4981917440891266, -0.03130948543548584, -0.5474163293838501, -1.042172908782959, -0.8374477028846741, 0.6419572830200195, 0.6861037611961365, 0.4728122353553772, 0.08275781571865082, 0.2852446734905243, 0.02246580645442009, -1.2174206972122192, 0.9326794743537903, 0.7707718014717102, -0.8357821702957153, 0.6266258358955383, 0.08015386760234833, 0.00131364562548697, 0.6404317617416382, 0.7610254883766174, 0.9155336618423462, 0.6251450181007385, -0.6751973628997803, 1.029949426651001, 0.03524932265281677, 0.5006464719772339, 0.17172758281230927, 0.0467989407479763, 1.1609336137771606, -0.8604668974876404, -0.3788740336894989, -0.04431894049048424, -0.9141979813575745, 0.2779064178466797, -0.812003493309021, -0.16508081555366516, -0.3455963432788849, -0.29538872838020325, 0.386635422706604, 0.4328347146511078, 0.4505510926246643, -0.5529836416244507, -0.5856409072875977, -0.35357487201690674, -0.45967575907707214, 0.36730873584747314, 0.5119150876998901, 0.6369418501853943, -0.3506619334220886, -0.02500360831618309, 0.7852655649185181, 0.015356097370386124, 0.5792577266693115, -0.5724935531616211, -0.3963499367237091, -0.44322365522384644, -0.11012643575668335, -0.1618185043334961, 0.2906213104724884, 0.253842830657959, 0.5791475772857666, -0.17277339100837708, 0.4744340181350708, 0.7202363610267639, 0.2882862687110901, -0.2328399419784546, 0.18421317636966705, -0.020977633073925972, -0.770418643951416, 0.15675042569637299, -0.2928679287433624, 0.12522149085998535, -0.6369405388832092, -0.40773701667785645, -0.459916889667511, 0.12423483282327652, -1.1608729362487793, -0.6209598779678345, 0.9685876965522766, -0.03273191675543785, -0.6306113600730896, 0.33463698625564575, -1.39068603515625, -0.25105735659599304, -0.0836791917681694, -1.1978087425231934, -1.3898370265960693, -0.10487375408411026, -0.06704271584749222, 0.2415468543767929, 0.10548356920480728, 1.1776922941207886, -0.38167068362236023, -0.5106374621391296, -0.22808490693569183, -0.6001046299934387, 0.150600865483284, -0.5233919024467468, -0.6140066981315613, 0.6821792721748352, -0.10132337361574173, 0.32363948225975037, 0.1652393341064453, -0.06385631859302521, -0.12460815906524658, -0.9074395298957825, 0.3144036531448364, 0.17676088213920593, -1.3465321063995361, -0.4839997887611389, -0.7520836591720581, -0.29284125566482544, 0.5409600138664246, 0.3091064989566803, -0.0812021940946579, -0.02769193984568119, 0.007217311765998602, -0.809678316116333, 0.3791663944721222, -1.038896083831787, 0.5603095889091492, 0.6750608682632446, -0.5874922275543213, -0.85712069272995, 0.10060245543718338, 0.4099588394165039, -1.4194490909576416, -0.000564389571081847, -0.2647581398487091, 0.6271107792854309, -0.20697329938411713, 0.8970895409584045, -0.8894526958465576, 0.46323278546333313, 0.3538351058959961, -0.31913721561431885, -0.9802978038787842, 0.1543680876493454, -0.5765313506126404, -0.2268235981464386, -0.5768789052963257, 0.5425453782081604, -0.28717589378356934, 0.05841543525457382, 0.8009136319160461, 0.3937859833240509, -0.481677770614624, -0.18578454852104187, -0.20175987482070923, -0.040110401809215546, -0.4893806278705597, 0.0790615901350975, -0.4892452359199524, -0.11822883784770966, 0.44301047921180725, 0.7796087861061096, 1.2632012367248535, -0.275238960981369, -0.5600331425666809, 0.9581176042556763, 0.09215100109577179, -0.23266273736953735, -0.41189059615135193, -0.4228488504886627, -2.1304004192352295, 0.14560078084468842, -0.9150245189666748, 0.41494593024253845, -1.4842987060546875, -0.6322411298751831, 0.2038077861070633, 0.1355564147233963, 0.008249972946941853, 0.6200832724571228, -0.6042869687080383, 0.15397676825523376, -0.5496497750282288, -0.8383313417434692, 0.8803441524505615, 1.4679763317108154, -0.6746694445610046, 0.16599023342132568, -0.17572526633739471, 0.22806048393249512, 0.8710529208183289, 0.2540878653526306, -0.07918962836265564, -0.7778334617614746, -1.5610613822937012, 0.38304656744003296, -0.09727020561695099, 0.4462817907333374, -1.3419604301452637, 1.0541863441467285, 0.5872252583503723, 0.15475142002105713, -0.44066929817199707, 0.9978076219558716, -1.0847305059432983, -0.8104145526885986, 0.4060555100440979, -0.6541306376457214, 0.1044561117887497, 0.3241809010505676, -0.1528802067041397, -0.2833639979362488, 0.6976048946380615, -0.41350728273391724, -1.0230592489242554, -1.2827578783035278, 0.24138766527175903, -0.3989315629005432, -0.20386867225170135, 0.1978544294834137, -0.12580133974552155, -1.0955880880355835, -0.7291801571846008, -0.23984619975090027, 0.6374858617782593, -0.5309768915176392, 0.8063978552818298, 1.1055712699890137, -1.1053109169006348, -0.32046350836753845, 0.08095873147249222, 0.21267201006412506, 0.7236793041229248, 0.38816481828689575, -0.04039526358246803, -0.6358962655067444, 0.5527032613754272, 0.1072985976934433, 0.7600778937339783, -0.6747393608093262, -0.06728915125131607, 1.0967991352081299, 0.062441274523735046, -0.233941450715065, 1.1790851354599, 0.08725272119045258, -1.5299257040023804, 0.21478191018104553, -0.7785366773605347, -0.5480844378471375, -0.4872991442680359, 0.5173488259315491, -0.13752752542495728, -0.4996931552886963, -0.4673219621181488, -0.3484026789665222, 0.8089268803596497, -0.11127504706382751, -0.5142605304718018, 0.24322043359279633, -0.20013250410556793, -0.07723802328109741, 0.45493102073669434, 0.7873750925064087, -0.6992655992507935, -0.835097074508667, -0.21993479132652283, -0.6118237972259521, 0.3209426999092102, -0.013386599719524384, -0.6903983950614929, -0.22868488729000092, 0.4397242069244385, 0.19275212287902832, 0.10253206640481949, -0.2690075635910034, 0.46095865964889526, -0.010170641355216503, 1.436299443244934, 0.3132007420063019, -0.23229877650737762, 0.09504056721925735, 1.3579356670379639, 1.9261677265167236, -1.184954285621643, 0.2146717607975006, -0.5889857411384583, -0.3189133107662201, 1.0313388109207153, 0.5931116938591003, -0.30002743005752563, 0.49123963713645935, -0.491828054189682, -0.030723942443728447, -0.11894631385803223, -0.33574193716049194, -0.2981800436973572, 0.9663483500480652, 1.3680936098098755, 0.263904869556427, 0.5453252792358398, 0.29660481214523315, 0.4301678240299225, 0.019591176882386208, -0.022116433829069138, 0.29518911242485046, 0.557030200958252, -0.28909537196159363, 0.3256186842918396, 0.07557948678731918, 0.23451004922389984, 0.1573074907064438, -0.142707958817482, -0.06174851208925247, 1.0071582794189453, 0.0058191088028252125, 0.7573241591453552, 0.5971885323524475, 0.3974511921405792, 0.8109238147735596, -0.009041002951562405, 1.1076569557189941, -0.7681481242179871, 0.5051624178886414, -0.20205426216125488, -0.33874475955963135, -0.14397160708904266, -0.6805643439292908, -0.5433620810508728, -0.8612437844276428, 0.3136483430862427, 0.23468466103076935, -0.5816469192504883, 0.4560653269290924, 1.1742662191390991, 0.5682725310325623, 0.5564220547676086, -0.8938663601875305, -0.8650460243225098, -0.2815898358821869, -0.8755099773406982, 0.48934072256088257, -0.528921365737915, 0.02328890934586525, -0.7446053624153137, -0.13685497641563416, -0.4959404468536377]}, "authors": [{"authorId": "2192712129", "name": "Jiangyong Huang"}, {"authorId": "2183144395", "name": "Silong Yong"}, {"authorId": "2242178224", "name": "Xiaojian Ma"}, {"authorId": "2170539011", "name": "Xiongkun Linghu"}, {"authorId": "2145015272", "name": "Puhao Li"}, {"authorId": "2267823550", "name": "Yan Wang"}, {"authorId": "2117895397", "name": "Qing Li"}, {"authorId": "2254283518", "name": "Song-Chun Zhu"}, {"authorId": "26663607", "name": "Baoxiong Jia"}, {"authorId": "2239060852", "name": "Siyuan Huang"}], "references": [{"paperId": "fc53f8f3a84f1fc4993689d8f98cf6551d07a22d", "title": "LL3DA: Visual Interactive Instruction Tuning for Omni-3D Understanding, Reasoning, and Planning"}, {"paperId": "d40986251df7569f1441762767605769b6bc15ea", "title": "GROOT: Learning to Follow Instructions by Watching Gameplay Videos"}, {"paperId": "d7d712e507c1c6273b05c773c825a668c5cf1504", "title": "MindAgent: Emergent Gaming Interaction"}, {"paperId": "af3ab5da98e0807784b57e321ed887a3666a8ab6", "title": "Multimodal Foundation Models: From Specialists to General-Purpose Assistants"}, {"paperId": "3803d1f291e162bdaa4678a2c5a2bbcf63c050f4", "title": "MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning"}, {"paperId": "6bcc6ab9c28805d4067e99b2cdc7524550fe80e1", "title": "PointLLM: Empowering Large Language Models to Understand Point Clouds"}, {"paperId": "30cfc4e7174211aa48c965826d51db773f0d37c7", "title": "Chat-3D: Data-efficiently Tuning Large Language Model for Universal Dialogue of 3D Scenes"}, {"paperId": "64a80a33018a0fdc182b06111e32b2e08e186f6a", "title": "3D-VisTA: Pre-trained Transformer for 3D Vision and Text Alignment"}, {"paperId": "38939304bb760473141c2aca0305e44fbe04e6e8", "title": "RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control"}, {"paperId": "4279a38a098d1d359881b73c6a88a112fe93443a", "title": "Scalable 3D Captioning with Pretrained Models"}, {"paperId": "fd755dc7b5b206c17fd953db04e1c888d45b6e4e", "title": "LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset, Framework, and Benchmark"}, {"paperId": "d47524cd5c3c4b57af2e5a29f6f91c420310f236", "title": "MIMIC-IT: Multi-Modal In-Context Instruction Tuning"}, {"paperId": "f197bf0fc2f228483f6af3285000d54d8d97f9eb", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models"}, {"paperId": "00cb69a9f280317d1c59ac5827551ee9b10642b8", "title": "EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought"}, {"paperId": "8bd6a2a89503be083176f2cc26fabedb79238cbd", "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"}, {"paperId": "81e7e82245c2f230eeb8aaaa1a2b2604c143754a", "title": "MultiModal-GPT: A Vision and Language Model for Dialogue with Humans"}, {"paperId": "d6d3604f369bb0415cbe814e43ca3131323b03e2", "title": "Otter: A Multi-Modal Model with In-Context Instruction Tuning"}, {"paperId": "570079bbdd8758dfe865097e05719313c9c1301a", "title": "LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model"}, {"paperId": "7e32aac43e9f1df49e116add03327ee6f365dbf3", "title": "mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality"}, {"paperId": "ca6a2bc279be5a3349a22bfd6866ed633d18734b", "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"}, {"paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8", "title": "Visual Instruction Tuning"}, {"paperId": "7a2ec15a7a3e3f54be083aa559ec6f6453e3c9ac", "title": "ARNOLD: A Benchmark for Language-Grounded Task Learning With Continuous States in Realistic 3D Scenes"}, {"paperId": "9e8cb8c91a0acb6e661b58ad724aa758490f2bea", "title": "Instruction Tuning with GPT-4"}, {"paperId": "7470a1702c8c86e6f28d32cfa315381150102f5b", "title": "Segment Anything"}, {"paperId": "326f6a8011e43322c433751b9cc31fd56564621c", "title": "Where are we in the search for an Artificial Visual Cortex for Embodied Intelligence?"}, {"paperId": "611e2100a3f8ed02b2583d4e53fd27a12d223b4c", "title": "LERF: Language Embedded Radiance Fields"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "69cfdc8df16ae63b7acba4ac6f727f78b86893c3", "title": "ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions"}, {"paperId": "38fe8f324d2162e63a967a9ac6648974fc4c66f3", "title": "PaLM-E: An Embodied Multimodal Language Model"}, {"paperId": "bf8491bef353df126e2306ad2fe4b898697b906a", "title": "A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity"}, {"paperId": "ccb1ccc4deacc4fb18000f0e1ce24329548963ae", "title": "Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents"}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "9285b7898f9d8140dbcfc22d34e6bc4c1ecd3d2e", "title": "Open-World Multi-Task Control Through Goal-Aware Representation Learning and Adaptive Horizon Prediction"}, {"paperId": "92d3f7cea95bba8cb905454324c3eeb84d2b6e58", "title": "End-to-End 3D Dense Captioning with Vote2Cap-DETR"}, {"paperId": "e65b346d442e9962a4276dc1c1af2956d9d5f1eb", "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions"}, {"paperId": "1b31dbf44e68b698120552366df03e6e35a1e428", "title": "Objaverse: A Universe of Annotated 3D Objects"}, {"paperId": "fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d", "title": "RT-1: Robotics Transformer for Real-World Control at Scale"}, {"paperId": "9ceaeff7117965832f4c05fd6355d021862d0a82", "title": "Images Speak in Images: A Generalist Painter for In-Context Visual Learning"}, {"paperId": "774408d8848b129d93fb67548ec6571d99b31a2d", "title": "OpenScene: 3D Scene Understanding with Open Vocabularies"}, {"paperId": "77f75c36451f58743f7678189c759b71a3706efd", "title": "Perceive, Ground, Reason, and Act: A Benchmark for General-purpose Visual Representation"}, {"paperId": "88c741be2c0200f0eff9877d99fbce612ba64d07", "title": "Language Conditioned Spatial Relation Reasoning for 3D Object Grounding"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "e5c8960eb2ec034ffbd353ef39fd1cb541d3c7c9", "title": "LAION-5B: An open large-scale dataset for training next generation image-text models"}, {"paperId": "c1a4fb211cf995b1af1247a152fcc145594ec13b", "title": "SQA3D: Situated Question Answering in 3D Scenes"}, {"paperId": "25425e299101b13ec2872417a14f961f4f8aa18e", "title": "VIMA: General Robot Manipulation with Multimodal Prompts"}, {"paperId": "f3cf71c51b882fe3111d71c4bf104297d38197f8", "title": "Inner Monologue: Embodied Reasoning through Planning with Language Models"}, {"paperId": "4f0f2096e006725576f1ccf0edda7c234d38fa66", "title": "ZSON: Zero-Shot Object-Goal Navigation using Multimodal Goal Embeddings"}, {"paperId": "8b5eab31e1c5689312fff3181a75bfbf5c13e51c", "title": "Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks"}, {"paperId": "32c9b3859086d15184989454eb878638659e64c6", "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge"}, {"paperId": "fade0ef67bcad3369e83348111a73c0f9578786f", "title": "3DJCG: A Unified Framework for Joint Dense Captioning and Visual Grounding on 3D Point Clouds"}, {"paperId": "5922f437512158970c417f4413bface021df5f78", "title": "A Generalist Agent"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "12aeb6e6835e54a34a147b2070093ad775a42115", "title": "Habitat-Web: Learning Embodied Object-Search Strategies from Human Demonstrations at Scale"}, {"paperId": "cb5e3f085caefd1f3d5e08637ab55d39e61234fc", "title": "Do As I Can, Not As I Say: Grounding Language in Robotic Affordances"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "8f6c652a392995bd047a2f7b94474ab1e6e23ff0", "title": "ScanQA: 3D Question Answering for Spatial Scene Understanding"}, {"paperId": "dd2819016c6bf244c39b3e6707b60389bbdbcd21", "title": "Point-BERT: Pre-training 3D Point Cloud Transformers with Masked Point Modeling"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "69ff4686b6517a0f9ae59503fedd8ed6e7be9983", "title": "3DVG-Transformer: Relation Modeling for Visual Grounding on Point Clouds"}, {"paperId": "69ee9b3a915951cc84b74599a3a2699a66d4004f", "title": "CLIPort: What and Where Pathways for Robotic Manipulation"}, {"paperId": "f46bce5b7dd78736133c1af1824ddb83c0ec2e55", "title": "Habitat-Matterport 3D Dataset (HM3D): 1000 Large-scale 3D Environments for Embodied AI"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "0af51c6a6041a439796a334f65327a992c8a3e63", "title": "Embodied BERT: A Transformer Model for Embodied, Language-guided Visual Task Completion"}, {"paperId": "01b5412f3d17e90e09226d7c40ad4d4468a1414d", "title": "Multimodal Few-Shot Learning with Frozen Language Models"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "8e201bdf5b69113d53462312bdb16f270a35f346", "title": "SceneGraphFusion: Incremental 3D Scene Graph Prediction from RGB-D Sequences"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "ba4a4d31d2af23eefadbf19e5efd5a7d4fd89143", "title": "Less is More: CLIPBERT for Video-and-Language Learning via Sparse Sampling"}, {"paperId": "7a4ba78d377eea9650e5e399a0878e30bd22f648", "title": "Scan2Cap: Context-aware Dense Captioning in RGB-D Scans"}, {"paperId": "53794499a3830c3ebb365ecc57f0e8c8a20a682d", "title": "ReferIt3D: Neural Listeners for Fine-Grained 3D Object Identification in Real-World Scenes"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "862bca372c0c7475f9e5eb4951b9309f39cd4ace", "title": "Dark, Beyond Deep: A Paradigm Shift to Cognitive AI with Humanlike Common Sense"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "6c161841cdb547f77930942e4ab46f4369751676", "title": "ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "f1e6bfd59428ecd91e8194b80503d3d24583a0ca", "title": "RIO: 3D Object Instance Re-Localization in Changing Indoor Environments"}, {"paperId": "93d63ec754f29fa22572615320afe0521f7ec66d", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"}, {"paperId": "b4a35e548de27b6924e5f2ee41d37238a5c4a1d5", "title": "Habitat: A Platform for Embodied AI Research"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "83040001210751239553269727b9ea53e152af71", "title": "Building Machines that Learn and Think Like People"}, {"paperId": "8bffce7de83c4a9bb48317c0dd3f38dac053a2f6", "title": "One Big Net For Everything"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "8674494bd7a076286b905912d26d47f7501c4046", "title": "PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space"}, {"paperId": "e52e37cd91366f07df1f98e88f87010f494dd16e", "title": "ScanNet: Richly-Annotated 3D Reconstructions of Indoor Scenes"}, {"paperId": "815c84ab906e43f3e6322f2ca3fd5e1360c64285", "title": "Human-level concept learning through probabilistic program induction"}, {"paperId": "97ad70a9fa3f99adf18030e5e38ebe3d90daa2db", "title": "VQA: Visual Question Answering"}, {"paperId": "7637ed79d30d0139901175ae4abedd822c217ab4", "title": "3D-LLM: Injecting the 3D World into Large Language Models"}, {"paperId": "84dc889beff9d51fe429cff8c92735e7410ee3c2", "title": "Aligning Large Multi-Modal Model with Robust Instruction Tuning"}, {"paperId": "a939c3838f69dec80d0e414f4054bf699b002e59", "title": "Mask3D for 3D Semantic Instance Segmentation"}, {"paperId": "089254dfb8fb0fbfac55696d1f9eba02e4079e97", "title": "Visual Question Answering"}, {"paperId": null, "title": "A bayesian skill rating system"}, {"paperId": "4fae92cf350729bc89172e6afef7ebda01e99034", "title": "An organizing principle for cerebral function : the unit module and the distributed system"}, {"paperId": null, "title": "Stanford alpaca: An instruction-following llama model"}, {"paperId": null, "title": "An Embodied Generalist"}, {"paperId": null, "title": "From images to textual prompts: Zero-shot vqa with frozen large language models"}, {"paperId": null, "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality"}]}