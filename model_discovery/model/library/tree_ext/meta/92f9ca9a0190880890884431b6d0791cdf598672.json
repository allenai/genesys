{"paperId": "92f9ca9a0190880890884431b6d0791cdf598672", "title": "Prototypical Transformer as Unified Motion Learners", "abstract": "In this work, we introduce the Prototypical Transformer (ProtoFormer), a general and unified framework that approaches various motion tasks from a prototype perspective. ProtoFormer seamlessly integrates prototype learning with Transformer by thoughtfully considering motion dynamics, introducing two innovative designs. First, Cross-Attention Prototyping discovers prototypes based on signature motion patterns, providing transparency in understanding motion scenes. Second, Latent Synchronization guides feature representation learning via prototypes, effectively mitigating the problem of motion uncertainty. Empirical results demonstrate that our approach achieves competitive performance on popular motion tasks such as optical flow and scene depth. Furthermore, it exhibits generality across various downstream tasks, including object tracking and video stabilization.", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The Prototypical Transformer (ProtoFormer), a general and unified framework that approaches various motion tasks from a prototype perspective, seamlessly integrates prototype learning with Transformer by thoughtfully considering motion dynamics, introducing two innovative designs."}, "embedding": {"model": "specter_v2", "vector": [-0.49978119134902954, 0.22498993575572968, -0.6576985120773315, 0.24570325016975403, -0.0961158499121666, 0.15169617533683777, 0.6102383732795715, -0.400765061378479, -0.10376137495040894, -0.8470990657806396, 0.5338073372840881, 0.5672105550765991, 0.09526587277650833, 0.0377337820827961, -0.18944065272808075, 0.10208222270011902, -0.8764569759368896, 0.07098498195409775, 0.4127519428730011, -0.24452336132526398, -0.11808869987726212, -0.3664467930793762, -1.1887067556381226, 0.23911231756210327, 0.19713832437992096, 0.757175624370575, 0.22099432349205017, 1.2645344734191895, 0.17114125192165375, 0.1975289285182953, 0.6717159748077393, 0.24221183359622955, 0.7212008237838745, -0.1890297383069992, -0.2608213722705841, -0.09246180951595306, 0.8348075151443481, -0.6895555853843689, -0.8681747913360596, 0.531201958656311, -0.16560058295726776, 0.30676349997520447, 0.7071889638900757, -0.8201736807823181, -0.1956333965063095, 0.08149950951337814, 0.6799820065498352, 0.7607957124710083, -0.06538401544094086, -0.2399718463420868, 1.291175127029419, -1.3968913555145264, 0.875575602054596, 1.6516313552856445, 0.7701044082641602, 0.4021208882331848, -0.32967257499694824, -0.2187710702419281, 0.8553537130355835, 0.1456133872270584, -0.5943301916122437, -0.45372167229652405, -0.049765732139348984, -0.6485198140144348, 0.9490640163421631, -0.5945119261741638, 0.5330994725227356, 0.6548648476600647, 0.17411211133003235, 1.6263548135757446, -0.4260372817516327, -0.4886414408683777, 0.0032672446686774492, 0.2469918131828308, 0.3055230677127838, 0.8152028322219849, -0.19061453640460968, 0.5107545256614685, -1.2149301767349243, 0.11724357306957245, 1.00531005859375, -0.3410128057003021, -0.5620625615119934, -0.7502148151397705, -0.5446471571922302, 0.48761945962905884, 1.03126060962677, 0.6592945456504822, -0.37807366251945496, 1.0686326026916504, 0.3482000529766083, 0.22577081620693207, -0.13753856718540192, 0.36479464173316956, 0.33637160062789917, 0.5699208974838257, -0.7562723755836487, 0.3550722599029541, 0.0852036252617836, 0.8007200360298157, 0.10321131348609924, 0.18332821130752563, -0.6133741140365601, -0.1562977284193039, 1.5771996974945068, 0.23041661083698273, 0.7403653860092163, -1.0557968616485596, -0.32742518186569214, -0.8042613863945007, 0.6282292604446411, -1.3185685873031616, 0.029248034581542015, 0.09230653941631317, -0.5951447486877441, -0.8782885074615479, -0.2839953601360321, 0.8075140714645386, -0.7219423651695251, 0.5464345812797546, 0.3393714427947998, 0.5384854674339294, -0.2905837595462799, 1.0344460010528564, 0.45198872685432434, 0.6551529765129089, 0.18534062802791595, 0.24050654470920563, 0.3699970543384552, -1.1736505031585693, -0.20192821323871613, -0.4038490951061249, 0.21787196397781372, -0.21645969152450562, 0.2872331440448761, -0.014295519329607487, -0.979555070400238, -1.8976783752441406, -0.762631893157959, 0.02476518228650093, -0.3292999565601349, -0.03162996098399162, 1.2496328353881836, 0.3302727937698364, -1.0554620027542114, 0.9000828266143799, -0.4439910352230072, -0.39616653323173523, 0.42662009596824646, 0.005367848556488752, 0.014123617671430111, -0.2828260362148285, -0.5320939421653748, 0.08125986158847809, 0.3806737959384918, -0.2657407820224762, -0.6428490281105042, -0.7141843438148499, -1.0545872449874878, -0.4148153066635132, -0.02044384740293026, -1.3324249982833862, 1.1872665882110596, -0.4409913122653961, -1.4059926271438599, 0.16425269842147827, -0.12807685136795044, 0.3979600667953491, 0.5350357890129089, -0.6954229474067688, -0.37735989689826965, 0.06671024858951569, 0.04805220291018486, 1.0924880504608154, 0.5767900347709656, -0.4434826672077179, -0.3349020183086395, 0.411253958940506, -0.4434379041194916, -0.3185364902019501, -0.1998719871044159, 0.4236938953399658, -0.42298898100852966, -0.22254537045955658, 0.3703247904777527, 0.7828118801116943, -0.02259191684424877, 0.21770079433918, 0.08542050421237946, -0.9826998710632324, 1.563773512840271, 0.5133237242698669, 0.6139741539955139, -0.8590279221534729, -0.41353726387023926, -0.041046686470508575, 0.004625364206731319, -0.3177851736545563, -0.9911078810691833, 0.11437031626701355, -0.24216026067733765, 0.1442994773387909, 0.38037779927253723, -0.7479891180992126, -0.3683549463748932, -0.3386329114437103, -0.7335508465766907, 0.28338637948036194, 0.3457070589065552, 1.4164159297943115, -1.3831998109817505, -0.10298532247543335, 0.5747410655021667, 0.1762475073337555, -0.9066610336303711, 1.146175503730774, -0.25059768557548523, 0.2744581699371338, -0.32625189423561096, 0.12915490567684174, -0.3213987648487091, -0.3207532465457916, 0.2837914526462555, -0.7289461493492126, 0.0028878236189484596, 0.4249725639820099, -0.850653886795044, 1.4489060640335083, -0.11515351384878159, 0.811530351638794, -0.26112210750579834, -0.7622685432434082, 0.34259793162345886, 0.6444548964500427, 0.050780221819877625, -0.5208951234817505, 0.32750722765922546, 0.4877866208553314, -0.7651562690734863, -0.17039459943771362, 0.7726918458938599, 0.932028591632843, 0.15837395191192627, -0.1513732671737671, 0.823417603969574, -0.6346636414527893, 0.1127450093626976, 0.3316028416156769, 0.3320527970790863, 0.9872913956642151, 0.2919827699661255, -0.29768967628479004, -0.13885998725891113, -0.6175448894500732, 0.04871493950486183, 0.6088641285896301, 0.28559204936027527, 1.116430401802063, -0.2071445733308792, -0.965989887714386, -0.7082364559173584, -0.24592959880828857, 0.8148259520530701, 0.7485342621803284, 0.6529411673545837, -0.43244192004203796, -0.08652473241090775, -0.28410860896110535, -0.21677854657173157, -0.7082233428955078, -0.6914786100387573, -0.19666792452335358, -0.7742383480072021, -0.0868125930428505, 0.2537543773651123, 0.8020932674407959, 1.1012392044067383, -0.6011038422584534, -0.7022652626037598, -0.19104163348674774, 0.14832188189029694, -0.4569767117500305, -0.6470012068748474, -0.5804086327552795, -0.4540272057056427, -0.4648617208003998, -0.19456548988819122, -0.04984094575047493, 0.08227856457233429, 0.07785334438085556, 0.8414851427078247, -0.5945027470588684, -0.6459988355636597, 0.766027569770813, 0.5001525282859802, -0.387909471988678, -0.36684784293174744, -0.3189930021762848, 0.4483920633792877, -0.06280683726072311, -0.4058365225791931, 0.36257293820381165, -0.572654128074646, 0.5170580744743347, -0.24207670986652374, 0.046474896371364594, -0.15945616364479065, 0.27137264609336853, 0.8633484244346619, -0.7240158915519714, -0.15276870131492615, -0.5200129151344299, 0.5503957867622375, -0.04654926061630249, -0.3166109621524811, 0.20914945006370544, -0.479600727558136, -0.5223050713539124, 0.058090560138225555, -1.121272087097168, 0.009951723739504814, -0.9410812258720398, 1.0792843103408813, -1.1024426221847534, -0.4046390950679779, -0.04090152308344841, 0.5603830814361572, -0.07078053802251816, 0.9297996163368225, -0.13424305617809296, 0.11755992472171783, 0.20606811344623566, 0.6314879059791565, -1.1440465450286865, 1.1118199825286865, -0.10679565370082855, 0.2489122450351715, 0.4468139708042145, -0.024429574608802795, -0.8501240015029907, -0.3043977618217468, -1.0846837759017944, -0.4593571424484253, -0.9529407620429993, 0.3158303201198578, -0.6588491797447205, -1.17039155960083, -0.10406436026096344, -1.253042459487915, -0.478843629360199, -0.1484990119934082, -0.14442287385463715, -0.6335984468460083, -1.033125877380371, -0.5455562472343445, -0.741701066493988, -0.5367215871810913, -0.8603229522705078, 0.7847374677658081, 0.32160690426826477, -0.7320016026496887, -0.5518625378608704, 0.518642783164978, -0.9367403984069824, 0.5930217504501343, -0.030258508399128914, 0.01654745079576969, 0.6650166511535645, -0.8823204636573792, -0.10913006216287613, 0.46410828828811646, -0.00010303260933142155, -0.13963304460048676, 0.7008115649223328, -0.8456814289093018, 0.025782929733395576, -0.39514562487602234, -0.5537186861038208, 0.3453176021575928, 0.5870708227157593, 0.27814674377441406, 0.0844971239566803, -0.6628223657608032, 0.4824492037296295, 1.1571472883224487, -0.5034167766571045, 0.09915035218000412, 0.3318743407726288, 1.0415211915969849, 0.5601081848144531, -0.13909733295440674, 0.37094932794570923, 0.24256843328475952, 0.5610392689704895, 0.06522790342569351, -0.012707763351500034, -0.6765715479850769, -0.7978841662406921, 0.5265727639198303, 1.0339158773422241, 0.3047475814819336, 0.2764131724834442, -0.8572589755058289, 0.823775589466095, -1.7720820903778076, -0.9264258742332458, 0.6104942560195923, 0.8232176303863525, -0.2124590128660202, -0.6657554507255554, 0.4757653772830963, -0.6180394291877747, 0.6752127408981323, 0.029528122395277023, -0.35053253173828125, 0.0662139356136322, -0.05165446177124977, 0.36455315351486206, -0.5584447383880615, 0.6433388590812683, -0.5051518678665161, 0.31366750597953796, 14.956646919250488, 0.2350362241268158, -0.6669191718101501, 0.4812804162502289, 0.6623551845550537, 0.47738081216812134, -0.3793593645095825, 0.22520560026168823, -0.9070717692375183, -0.29328861832618713, 0.8053996562957764, 0.15901567041873932, -0.26837924122810364, 0.5026276111602783, -0.017146337777376175, 0.12137734889984131, -1.0403212308883667, 1.0810120105743408, 0.1957089900970459, -1.6214654445648193, 0.47521114349365234, -0.1373303383588791, 0.5395058989524841, 0.41936638951301575, 0.7030210494995117, 0.31750333309173584, 0.30158576369285583, -0.24530810117721558, 1.1426327228546143, 0.4170176386833191, 0.6265482902526855, 0.3322560489177704, -0.17830495536327362, -0.014948769472539425, -1.2325618267059326, -0.15829743444919586, -0.4133683145046234, -0.6239470839500427, 0.4733051359653473, -0.19967177510261536, -0.5578471422195435, 0.03202170878648758, 0.24518214166164398, 1.0242999792099, 0.33437836170196533, 1.055142879486084, -0.2011387050151825, 0.14586035907268524, -0.22955162823200226, 0.2068120390176773, 0.07825028151273727, 0.6260398030281067, 0.23420776426792145, -0.07362033426761627, 0.15960057079792023, -0.03515158221125603, 0.5912081599235535, 0.5826596021652222, -0.06707622110843658, -0.2359696626663208, -0.4788883328437805, 0.10455100238323212, -0.03405795246362686, 0.8118976354598999, 0.13097608089447021, -0.006754655856639147, 0.10062813013792038, -0.06930537521839142, 0.3108876645565033, 0.15026035904884338, -0.07405208051204681, 0.1870734691619873, 0.26809632778167725, -0.2544362246990204, 0.019723966717720032, 0.390507310628891, 0.013492821715772152, -0.6233808994293213, -0.6826114058494568, 0.027633463963866234, 0.2803410589694977, -1.0537456274032593, -0.6776330471038818, 0.5556276440620422, 0.19847382605075836, -0.5750544667243958, 0.1453610062599182, -0.8349995613098145, -0.6752262711524963, 0.02108960598707199, -1.020067811012268, -0.7225739359855652, -0.5175138115882874, 0.01009700819849968, -0.20790183544158936, 0.17185558378696442, 0.5584834814071655, -0.40770867466926575, -0.1574552357196808, -0.04789971932768822, -0.6046029329299927, -0.17293225228786469, 0.007352664601057768, -0.662955641746521, 0.7612531185150146, 0.21155652403831482, 0.19864924252033234, 0.39663273096084595, 0.18830843269824982, 0.16865408420562744, -0.8560773134231567, 0.34105974435806274, -0.11618448048830032, -0.7042527198791504, -0.3107715845108032, -0.46712592244148254, -0.9414619207382202, -0.09300390630960464, 0.08870568871498108, 0.4512888491153717, 0.003517625154927373, -0.11445469409227371, -0.7725935578346252, -0.1890251338481903, -0.5716691613197327, 0.1822657436132431, 0.28104516863822937, -0.6788527965545654, -0.738394558429718, -0.1909075230360031, 0.39208778738975525, -0.9085208177566528, -0.14509393274784088, 0.07872331142425537, 0.7367171049118042, -0.44532260298728943, 0.9669713973999023, -0.5887510180473328, 0.3333228826522827, 0.25658369064331055, 0.17772124707698822, -0.4307335615158081, -0.21197712421417236, -1.369891881942749, -0.23172788321971893, -0.12942688167095184, -0.07205189019441605, -0.05925888568162918, 0.28212636709213257, 0.47308599948883057, 0.13886965811252594, -0.17805135250091553, -0.4209146797657013, -0.305710107088089, -0.23607084155082703, -0.3836198151111603, -0.36596328020095825, 0.04407849535346031, 0.004790305159986019, 0.07464249432086945, 0.49088090658187866, 0.3145883083343506, -0.4086439907550812, -0.43069887161254883, 1.203452467918396, -0.14811456203460693, -0.4856390058994293, -0.9061566591262817, -0.775765061378479, -1.6684142351150513, -0.3572327792644501, -0.824524462223053, 0.09939625859260559, -0.7828959822654724, -0.6984661221504211, 0.18475480377674103, -0.18277010321617126, -0.3315677046775818, 0.27820611000061035, -0.36214375495910645, -0.2910394072532654, -0.03969178721308708, -0.605476975440979, 0.8534746766090393, 1.1607919931411743, -0.8192959427833557, -0.4499322772026062, -0.21662002801895142, 0.2737397253513336, 0.4570973515510559, 0.016900934278964996, -0.05608850345015526, -0.7145640254020691, -0.8241260051727295, 0.14619873464107513, 0.1233539879322052, 0.3913736939430237, -1.1194567680358887, 1.020087480545044, 0.2018209844827652, 0.29662472009658813, 0.026036592200398445, 0.2684515416622162, -0.7262583374977112, -0.06297855824232101, 0.45341312885284424, -0.4143657684326172, 0.5010396838188171, 0.19554689526557922, -0.19323469698429108, -0.3615725040435791, 1.0818430185317993, 0.09906385838985443, -0.9259002208709717, -1.0709713697433472, 0.4799342155456543, -0.17495012283325195, -0.14798445999622345, -0.05836683139204979, -0.5512688159942627, -1.274478793144226, -0.32375577092170715, 0.061641108244657516, 0.49541062116622925, -0.331291139125824, 0.9898097515106201, 0.753212571144104, -1.3843395709991455, 0.3651122450828552, 0.195815309882164, 0.11655465513467789, 0.3548244833946228, 0.6917540431022644, 0.6629445552825928, -0.42936408519744873, 0.2621016502380371, -0.11968357861042023, -0.15898607671260834, -0.17244818806648254, 0.2562200427055359, 1.0851680040359497, 0.15770655870437622, -0.3146199584007263, 1.1200149059295654, 0.23659411072731018, -0.30136585235595703, -0.05516244098544121, -0.6707043051719666, -0.10036005079746246, -0.3242896497249603, 0.6819037795066833, 0.4035544693470001, -0.5154609084129333, 0.000530027027707547, -0.34244459867477417, 0.6321327090263367, -0.14712116122245789, -0.6485456824302673, 0.27656206488609314, 0.18214701116085052, -0.15549151599407196, 0.626341700553894, 0.6488999724388123, -1.157989263534546, -0.8917533159255981, -0.4295912981033325, -0.3873552083969116, -0.6085737943649292, -0.1178988441824913, 0.23810315132141113, -0.3190687894821167, 0.38083595037460327, 0.7442528605461121, -0.0067597199231386185, 0.10791872441768646, 0.09720923751592636, -0.12505961954593658, 0.5984621644020081, 0.11401324719190598, -0.6123883724212646, 0.5203357338905334, 0.8091185092926025, 1.224461555480957, -0.6879717111587524, 0.3285865783691406, -0.27114003896713257, -0.08500351011753082, 0.9907336235046387, 0.6522861123085022, -0.5719141364097595, 0.9414629340171814, -0.6784273982048035, 0.07373644411563873, -0.018971089273691177, -0.9128516912460327, -0.05418144538998604, 1.3109174966812134, 1.4617711305618286, 0.23507575690746307, -0.0753815770149231, 0.2893325388431549, -0.12057429552078247, 0.3295724391937256, 0.2967958152294159, 0.3954916298389435, 0.5113152265548706, -0.17948509752750397, -0.061301108449697495, 0.017813272774219513, -0.050846800208091736, -0.14065703749656677, 0.3792211413383484, 0.11659342795610428, 0.9188192486763, 0.19605694711208344, 0.2695815861225128, 1.0355604887008667, 0.11621858924627304, 0.5308541655540466, -0.19453926384449005, 0.793999969959259, -0.49623242020606995, -0.029672391712665558, 0.32273414731025696, -1.107900619506836, -0.6788743734359741, -0.9011818170547485, -0.666735827922821, -0.08356216549873352, 0.06601928174495697, 0.04851837456226349, -0.060789745301008224, -0.11117135733366013, 0.6344961524009705, 0.5240920782089233, 0.21173396706581116, -0.23677365481853485, -0.9866134524345398, -0.07164691388607025, -0.6290867328643799, 0.5945170521736145, 0.09968265146017075, 0.14734886586666107, -0.7517595887184143, 0.09500957280397415, 0.07696378976106644]}, "authors": [{"authorId": "2185018157", "name": "Cheng Han"}, {"authorId": "2304571258", "name": "Yawen Lu"}, {"authorId": "2292263389", "name": "Guohao Sun"}, {"authorId": "2168264438", "name": "James Liang"}, {"authorId": "9278220", "name": "Zhiwen Cao"}, {"authorId": "2288041686", "name": "Qifan Wang"}, {"authorId": "2304466513", "name": "Qiang Guan"}, {"authorId": "2958423", "name": "S. Dianat"}, {"authorId": "2277519064", "name": "Raghuveer M. Rao"}, {"authorId": "2288574052", "name": "Tong Geng"}, {"authorId": "2282459165", "name": "Zhiqiang Tao"}, {"authorId": "2282498299", "name": "Dongfang Liu"}], "references": [{"paperId": "4765d2007b13f8ed4a839d1f29965be8f517bd83", "title": "ProMotion: Prototypes As Motion Learners"}, {"paperId": "b095cb7b8004baeea70d57e86ca12a43721c65a1", "title": "Facing the Elephant in the Room: Visual Prompt Tuning or Full Finetuning?"}, {"paperId": "3af3302f61e8f0266d6a596ccbe5b524b57827f8", "title": "Collaborative Multi-task Learning for Multi-Object Tracking and Segmentation"}, {"paperId": "131ba9932572c92155874db93626cf299659254e", "title": "FLatten Transformer: Vision Transformer using Focused Linear Attention"}, {"paperId": "beeb17c6582b3d016c79c43eeb78c55c3219b550", "title": "E2VPT: An Effective and Efficient Approach for Visual Prompt Tuning"}, {"paperId": "cbeee2f7f03acb575f250e7b1857ceb775db98ec", "title": "SeqTrack: Sequence to Sequence Learning for Visual Object Tracking"}, {"paperId": "3ae97a7f1391ab35fcf9952437a37b18b2676126", "title": "CLUSTSEG: Clustering for Universal Segmentation"}, {"paperId": "4bb1c9f323d08ca918f12a51f8a7940198073eb4", "title": "Fusion is Not Enough: Single Modal Attacks on Fusion Models for 3D Object Detection"}, {"paperId": "aa57dbbd08b15c151026e266a5f2bfefab533538", "title": "TransFlow: Transformer as Flow Learner"}, {"paperId": "23d786f87d19e5e081b257f2c642ffd5c8516ff3", "title": "Rethinking Optical Flow from Geometric Matching Consistent Perspective"}, {"paperId": "6e49b9891675b66cff80373777031638aff21ed6", "title": "FlowFormer++: Masked Cost Volume Autoencoding for Pretraining Optical Flow Estimation"}, {"paperId": "72862e6e858c44ebd94d6ba90dc420963d9d0f39", "title": "Image as Set of Points"}, {"paperId": "32e07cc454af5249d34f005e277c307fdc2f638d", "title": "Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks"}, {"paperId": "92aeaaeea146b2e7e3851d84104f188a9451cc93", "title": "Optical Flow for Autonomous Driving: Applications, Challenges and Improvements"}, {"paperId": "cac6de6637ecbd85c9fe95bbce341603d98cd5a7", "title": "K-means clustering algorithms: A comprehensive review, variants analysis, and advances in the era of big data"}, {"paperId": "0b481055434bc5ddfbfe2e6a92a1e2909877abed", "title": "Lite-Mono: A Lightweight CNN and Transformer Architecture for Self-Supervised Monocular Depth Estimation"}, {"paperId": "5b30d42fbec716cc9e0eb5fc0d0af02a671fbd3f", "title": "Structure-Preserving Motion Estimation for Learned Video Compression"}, {"paperId": "38b8448d282d9c607855db648766a003649323a3", "title": "GMMSeg: Gaussian Mixture based Generative Semantic Segmentation Models"}, {"paperId": "13505e4960c94db050549fca34aebe39ed294b46", "title": "Learning Equivariant Segmentation with Instance-Unique Querying"}, {"paperId": "d56b830f5e703db55043f2b43d7fd217e7b7872a", "title": "Vehicle and Pedestrian Detection Algorithm Based on Lightweight YOLOv3-Promote and Semi-Precision Acceleration"}, {"paperId": "5b1a2d2016fdb87572a07baf65fb0d64cffdf03c", "title": "Visual Recognition with Deep Nearest Centroids"}, {"paperId": "5437f983d652766a950ffcde61cfbeb413e379cd", "title": "Unsupervised Video Object Segmentation via Prototype Memory Network"}, {"paperId": "a3335ad0d5e4061edda2b66567e517022642ea96", "title": "Safety-Enhanced Autonomous Driving Using Interpretable Sensor Fusion Transformer"}, {"paperId": "35efa06e8c55a209677bcb48a6790b654d8b322f", "title": "Physical Attack on Monocular Depth Estimation with Optimal Adversarial Patches"}, {"paperId": "6a481bd1abebe623fb3e606ee3f73ab6ef3c8895", "title": "Protoformer: Embedding Prototypes for Transformers"}, {"paperId": "5617e3540f157f0a4dc2b176a1e6d448f7d00948", "title": "Learning Optical Flow with Kernel Patch Attention"}, {"paperId": "2db659238b719ad855ec16d56e5d8e85c0c6afd0", "title": "A Triangulation-Based Visual Localization for Field Robots"}, {"paperId": "7d1763539498a2e2ea70514664b8f320193f7b45", "title": "P3Depth: Monocular Depth Estimation with a Piecewise Planarity Prior"}, {"paperId": "ea9088c20493ffb2952db09446ce5683141350f5", "title": "DIP: Deep Inverse Patchmatch for High-Resolution Optical Flow"}, {"paperId": "09e70edfe628ba2e444cf7a3638c2ed0c25a33a4", "title": "CRAFT: Cross-Attentional Flow Transformer for Robust Optical Flow"}, {"paperId": "7bffc157b3b3626a3912a3b0ef74ce5904630fce", "title": "FlowFormer: A Transformer Architecture for Optical Flow"}, {"paperId": "39b27ee48caa5bb68a8c50ef5f02121729847334", "title": "Unified Transformer Tracker for Object Tracking"}, {"paperId": "7475b217b16ce44c64e070f59972e999dca0a771", "title": "Rethinking Semantic Segmentation: A Prototype View"}, {"paperId": "54613977f4c845d3cd2e28cebd7f49c9df6aaf59", "title": "Global Matching with Overlapping Attention for Optical Flow Estimation"}, {"paperId": "77a2256bbd2169c4df0b4c05382eaeaee734034f", "title": "Coarse-to-Fine Sparse Transformer for Hyperspectral Image Reconstruction"}, {"paperId": "3ae69ec5a9fd4f28dfc495ddf1259e936b140000", "title": "Learning Optical Flow with Adaptive Graph Reasoning"}, {"paperId": "997c877f683a90f4f7352bafb2709b803fd3a20e", "title": "Deep Robotic Grasping Prediction with Hierarchical RGB-D Fusion"}, {"paperId": "c0df4a52eff06bcd3a1c079e540d24b3442fbe95", "title": "Variational Abnormal Behavior Detection With Motion Consistency"}, {"paperId": "e4733ff919aefc7048774876b05e73bae56fcb49", "title": "GMFlow: Learning Optical Flow via Global Matching"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "11b4fdc10051fd32ca268e1cb75cc6c4540d31e6", "title": "Evaluating the Performance of Ensemble Methods and Voting Strategies for Dense 2D Pedestrian Detection in the Wild"}, {"paperId": "829f9f80ccf6900b01c07cf1795596409108084f", "title": "R-MSFM: Recurrent Multi-Scale Feature Modulation for Monocular Depth Estimating"}, {"paperId": "8a1cbc71deac64756fb757e68cb0fbb28d8f20d8", "title": "Separable Flow: Learning Motion Cost Volumes for Optical Flow Estimation"}, {"paperId": "f27040f1f81144b17ec4c2b30610960e96353002", "title": "TVT: Transferable Vision Transformer for Unsupervised Domain Adaptation"}, {"paperId": "9933a5af7895354087baf6c96b64dc8a8973eaed", "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs"}, {"paperId": "3c574538e1d37cc5f7428aeda5e106c932a48e12", "title": "Do Different Tracking Tasks Require Different Appearance Models?"}, {"paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"}, {"paperId": "adf34b98727b0f17604705d8a3b988daef0776ef", "title": "FVC: A New Framework towards Deep Video Compression in Feature Space"}, {"paperId": "68f080e0ac836ea230cb5316fbed273c70422d75", "title": "Segmenter: Transformer for Semantic Segmentation"}, {"paperId": "9ee5045f42d7fbd4f848e91a354d63793365fdd1", "title": "AutoFlow: Learning a Better Training Set for Optical Flow"}, {"paperId": "c0559fc7e7d6ea0f783ba791ddd5deaa74cf58a9", "title": "Multi-Modal Fusion Transformer for End-to-End Autonomous Driving"}, {"paperId": "d2ac32c2fbfd1b8fc53c62880868d71c0e2dfd57", "title": "Learning to Estimate Hidden Motions with Global Motion Aggregation"}, {"paperId": "0cbfd6647f906c9cf82ecafdfbbdc2a317af8467", "title": "Adaptive Prototype Learning and Allocation for Few-Shot Segmentation"}, {"paperId": "7c3ce1b3ad598a282546e03e2dc8b52c338caed6", "title": "Transformer Tracking"}, {"paperId": "75284d5e4dfe1cd8a9ce69085210319e14fcfa3d", "title": "Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking"}, {"paperId": "96da196d6f8c947db03d13759f030642f8234abf", "title": "DeepViT: Towards Deeper Vision Transformer"}, {"paperId": "256db9dba1978f004a67c86ffc321563b1aee79a", "title": "Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "0839722fb5369c0abaff8515bfc08299efc790a1", "title": "ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision"}, {"paperId": "3a906b77fa218adc171fecb28bb81c24c14dcc7b", "title": "Transformers in Vision: A Survey"}, {"paperId": "d29430adccb805ab57b349afa8553954347b3197", "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"}, {"paperId": "d40c77c010c8dbef6142903a02f2a73a85012d5d", "title": "A Survey on Vision Transformer"}, {"paperId": "787119e3c3f819244c82b7d97779473773e60696", "title": "MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers"}, {"paperId": "2ac7999cce9f415ee87643f56631b55ed26aa10e", "title": "End-to-End Video Instance Segmentation with Transformers"}, {"paperId": "9717f7d873859ca0080caf944f7a2d9b456be121", "title": "AdaBins: Depth Estimation Using Adaptive Bins"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "6cdd8852c1324ebc36d20a453d5eb95a3df8c6f7", "title": "Prototype Mixture Models for Few-shot Semantic Segmentation"}, {"paperId": "1e88135a462f5a55e2ac76575853446b00f5313e", "title": "Part-aware Prototype Network for Few-shot Semantic Segmentation"}, {"paperId": "2a3c878dff8af653be003a247b0ae5bc78274019", "title": "Self-supervised Monocular Depth and Visual Odometry Learning with Scale-consistent Geometric Constraints"}, {"paperId": "27d52bf3265bea0f9929980f6ffb4c2009eecfee", "title": "Ocean: Object-aware Anchor-free Tracking"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "45ba71512adb1cc72b2ebcc382645d1fa4a534f1", "title": "Pedestrian detection using a moving camera: A novel framework for foreground detection"}, {"paperId": "9c50d19707244af585314eb2f1a705f706082005", "title": "Towards Better Generalization: Joint Depth-Pose Learning Without PoseNet"}, {"paperId": "3230e2d6b4671cc03974af2219c6d3270e6fac70", "title": "RAFT: Recurrent All-Pairs Field Transforms for Optical Flow"}, {"paperId": "d1e61fa7824709cae37fb59483dd0772e3101c08", "title": "Know Your Surroundings: Exploiting Scene Information for Object Tracking"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "c6e57b2d36a4231cef82d7e0e27413ae4bb4dee5", "title": "Virtual KITTI 2"}, {"paperId": "0e298911b60740a85b5bc4d47076fca0ca6c6132", "title": "PWStableNet: Learning Pixel-Wise Warping Maps for Video Stabilization"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "346f813f3aee101cc288da86c2cf9aad024bb32a", "title": "PANet: Few-Shot Image Semantic Segmentation With Prototype Alignment"}, {"paperId": "b7a2d31bf89ae5d9204dd2ce75db9dfa23e8b1ac", "title": "Enforcing Geometric Constraints of Virtual Normal for Depth Prediction"}, {"paperId": "c96faae7bb03d3222c57d56c9383c0cfdb6590fa", "title": "Deep Online Video Stabilization With Multi-Grid Warping Transformation Learning"}, {"paperId": "b20e564edbef25009fa1baa2c369437c89147e61", "title": "AnomalyNet: An Anomaly Detection Network for Video Surveillance"}, {"paperId": "ab995c4273111cde3e31ff7347c475aace10f1a5", "title": "DVC: An End-To-End Deep Video Compression Framework"}, {"paperId": "5132500b23d2da47129b3f4f68dd30947a29e502", "title": "CCNet: Criss-Cross Attention for Semantic Segmentation"}, {"paperId": "900ab48d25b44c076e31224b7befa503d9550c53", "title": "LaSOT: A High-Quality Benchmark for Large-Scale Single Object Tracking"}, {"paperId": "63b059cdad77906ff381515b3cfac21757e5e64c", "title": "Deep Ordinal Regression Network for Monocular Depth Estimation"}, {"paperId": "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b", "title": "TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "54c802e7dadac855de06725bf146cdf20319e46b", "title": "PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "a4a0a1e2b573affc16de38b7fff91f6e2507140b", "title": "Unmasking the Abnormal Events in Video"}, {"paperId": "a87cc499cf101b3697cacc65094b4b6590e0d061", "title": "ECO: Efficient Convolution Operators for Tracking"}, {"paperId": "a93d81c7f033f1e2b54d3288b60d214f55ccc010", "title": "Optical Flow Estimation Using a Spatial Pyramid Network"}, {"paperId": "4463dc4a32b948f0230f3b782cbfecaf1c9e5b1d", "title": "Unsupervised Monocular Depth Estimation with Left-Right Consistency"}, {"paperId": "29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "title": "Fully-Convolutional Siamese Networks for Object Tracking"}, {"paperId": "e24f9317ad8e391902c43f6b160730e98ad9904d", "title": "The HCI Benchmark Suite: Stereo and Flow Ground Truth with Uncertainties for Urban Autonomous Driving"}, {"paperId": "1ced31e02234bc3d1092ffb2c7442ffbd51cb309", "title": "A Large Dataset to Train Convolutional Networks for Disparity, Optical Flow, and Scene Flow Estimation"}, {"paperId": "8852ace0721030fb88d41d7be5efe8b8542e7bca", "title": "Prototypical Priors: From Improving Classification to Zero-Shot Learning"}, {"paperId": "2ce63d77eecc35faef85a3b752a314c93a077ac9", "title": "Learning Multi-domain Convolutional Neural Networks for Visual Tracking"}, {"paperId": "c2fb5b39428818d7ec8cc78e152e19c21b7db568", "title": "FlowNet: Learning Optical Flow with Convolutional Networks"}, {"paperId": "b422a2d3ef04399c1d2135d941196613f6255f16", "title": "Statistical guarantees for the EM algorithm: From population to sample-based analysis"}, {"paperId": "dd2cf76ae78a3262a094ac865aa9f60c55472c5d", "title": "Depth Map Prediction from a Single Image using a Multi-Scale Deep Network"}, {"paperId": "79b949d9b35c3f51dd20fb5c746cc81fc87147eb", "title": "Vision meets robotics: The KITTI dataset"}, {"paperId": "e30db6dc7a0ba7d533587c3c40d68f36d2128419", "title": "Data-driven analysis of analogous brain networks in monkeys and humans during natural vision"}, {"paperId": "7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62", "title": "A Naturalistic Open Source Movie for Optical Flow Evaluation"}, {"paperId": "27ac1bff9e24a62d21d17149964e7fbb54c2ade9", "title": "Recognizing Human Actions by Learning and Matching Shape-Motion Prototype Trees"}, {"paperId": "55b8c0b9309840b3b0dc6bd694060b247f15d3b6", "title": "k-means Requires Exponentially Many Iterations Even in the Plane"}, {"paperId": "edf0098901ac34547e1c6f33d85ce1a74400d215", "title": "Reverse Optical Flow for Self-Supervised Adaptive Autonomous Robot Navigation"}, {"paperId": "7d175cdb2ba75e9de3d76e29fb6ddbc453f9c637", "title": "Cratylus"}, {"paperId": "fa25610fb8586c2b50a3654edc5bb42fa7fc4729", "title": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction"}, {"paperId": "ddfa4e9b667dba47693ac0e961a6abaf3bbdaee3", "title": "Intensified fuzzy clusters for classifying plant, soil, and residue regions of interest from color images"}, {"paperId": "ef4df0277debc4fe468b3920da795d102f0325b6", "title": "Cognitive neuroscience: Neural mechanisms for the recognition of biological movements"}, {"paperId": "8aebea85c02957fa205c8b5f2a1e8bfa0075a3e9", "title": "Distinguishing prototype-based and exemplar-based processes in dot-pattern category learning."}, {"paperId": "18e72194da757ba303eca05ed8954aadaed9b316", "title": "Navigation of a mobile robot on the temporal development of the optic flow"}, {"paperId": "52b7bf3ba59b31f362aa07f957f1543a29a4279e", "title": "Support-Vector Networks"}, {"paperId": "18ce82b07ac84aaf30b502c93076cec2accbfcaa", "title": "Human problem solving: The state of the theory in 1970."}, {"paperId": "b1bac97ec2b37301e73b4cbf597c1b80f0a7c021", "title": "Unified 3D Segmenter As Prototypical Classifiers"}, {"paperId": "de31f3a588f4c07ced5c0444dc0d81366efaac07", "title": "Fusion is Not Enough: Single-Modal Attacks to Compromise Fusion Models in Autonomous Driving"}, {"paperId": "7478d41b1d40e15625b21c1037743d15a5bad2a7", "title": "ClusterFomer: Clustering As A Universal Visual Learner"}, {"paperId": "f3b1dd33a2a8b533a0c08382b2a2bbf721beac21", "title": "k-means Mask Transformer"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "03ce51e5e854faa614e79afe4dab8baeb5f73980", "title": "Twins: Revisiting Spatial Attention Design in Vision Transformers"}, {"paperId": null, "title": "A robustly optimized bert pretraining approach In ICLR"}, {"paperId": "3458c8b05f1e6b292ec109cdfd1fd96aff6cdb3b", "title": "SKFlow: Optical Flow Estimation Using Selective Kernel Networks"}, {"paperId": "17d3f0abff5569768e890afb8633d5f29bb9c289", "title": "Few-Shot Semantic Segmentation with Prototype Learning"}, {"paperId": "aeceff26e63df1723d36c16c8244c701bc8ec09e", "title": "On Intelligence"}, {"paperId": "8e0be569ea77b8cb29bb0e8b031887630fe7a96c", "title": "Random Forests"}, {"paperId": "ef432081e6384e7011c5b2949d61efdfe299786e", "title": "Language of Vision"}, {"paperId": null, "title": "feats: output feature embeddings from regular projection, shape: (batch_size, channels, height, width)"}, {"paperId": null, "title": "_0: initial cluster centers by adaptive pooling from the features, shape: (batch_size, num_clusters, dimension)"}]}