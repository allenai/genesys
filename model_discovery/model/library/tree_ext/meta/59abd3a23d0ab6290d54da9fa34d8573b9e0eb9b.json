{"paperId": "59abd3a23d0ab6290d54da9fa34d8573b9e0eb9b", "title": "vTrain: A Simulation Framework for Evaluating Cost-effective and Compute-optimal Large Language Model Training", "abstract": "As large language models (LLMs) become widespread in various application domains, a critical challenge the AI community is facing is how to train these large AI models in a cost-effective manner. Existing LLM training plans typically employ a heuristic based parallel training strategy which is based on empirical observations rather than grounded upon a thorough examination of the search space of LLM parallelization. Such limitation renders existing systems to leave significant performance left on the table, wasting millions of dollars worth of training cost. This paper presents our profiling-driven simulator called vTrain, providing AI practitioners a fast yet accurate software framework to determine an efficient and cost-effective LLM training system configuration. We demonstrate vTrain's practicality through several case studies, e.g., effectively evaluating optimal training parallelization strategies that balances training time and its associated training cost, efficient multi-tenant GPU cluster schedulers targeting multiple LLM training jobs, and determining a compute-optimal LLM model architecture given a fixed compute budget.", "venue": "arXiv.org", "year": 2023, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper presents a profiling-driven simulator called vTrain, providing AI practitioners a fast yet accurate software framework to determine an efficient and cost-effective LLM training system configuration, and demonstrates its practicality through several case studies."}, "embedding": {"model": "specter_v2", "vector": [0.16176684200763702, -0.05514099821448326, -0.31363946199417114, -0.03400625288486481, -0.2861526310443878, -0.11101508140563965, 0.6598237156867981, -0.3274037837982178, -0.8892403841018677, -0.5364603400230408, 0.39082008600234985, -0.420370489358902, 0.318291574716568, 0.25145986676216125, -0.30774256587028503, 0.3325987458229065, -0.9482638239860535, 0.8042146563529968, -0.2796332538127899, -0.16541323065757751, -0.38788464665412903, -0.15050233900547028, -1.8507694005966187, 0.1223355084657669, 0.6598504781723022, 0.4598565101623535, -0.11901208758354187, 1.2736835479736328, -0.19366315007209778, 0.22894242405891418, 0.2970333695411682, 0.1864362210035324, 0.3937855064868927, 0.09742528200149536, -0.3741246163845062, 0.0260394886136055, 0.17255204916000366, -0.22086484730243683, -0.45297762751579285, 0.5301450490951538, -0.12029258906841278, 0.4152078330516815, 0.33037814497947693, -0.7100083231925964, 0.43678519129753113, 0.4068751931190491, 0.10815319418907166, 1.1887086629867554, -0.2735467553138733, -0.5364471077919006, 0.8835199475288391, -1.1320370435714722, 0.212255597114563, 1.4753581285476685, 0.47129136323928833, 0.05066503584384918, -0.17376723885536194, -0.5889357328414917, 0.3931260406970978, -0.5217183828353882, -0.6173826456069946, -0.5074591636657715, -0.3575800657272339, -0.47889411449432373, 2.1479649543762207, -0.11975649744272232, 0.3131754696369171, 0.05218629166483879, 0.30269595980644226, 1.6843066215515137, -0.4107280671596527, -1.047232747077942, -0.09815936535596848, 0.052532341331243515, 0.4274498224258423, 0.883229672908783, -0.2675767242908478, 0.3800811767578125, -1.0320184230804443, -0.5841517448425293, 0.26956906914711, -0.28355443477630615, 0.6794037222862244, -0.16096819937229156, -0.34466177225112915, 0.7742761373519897, 0.18930962681770325, 0.8384521007537842, -0.20026816427707672, 0.780008852481842, 0.6649832725524902, 0.39896252751350403, 0.402724027633667, 0.4422614276409149, 0.3038773834705353, 0.3461347222328186, -1.182654619216919, 0.35839635133743286, -0.12797923386096954, 0.8877002000808716, -0.2528231739997864, 0.43023157119750977, -0.8491371273994446, 0.3959529995918274, 1.0935310125350952, -0.07430654764175415, 0.7992871999740601, -0.6341067552566528, 0.21504828333854675, -0.47625404596328735, 0.2757149934768677, -0.05951087921857834, -0.5139053463935852, -0.531758189201355, -0.5917737483978271, -0.9783867597579956, -0.7043370008468628, -0.2853993773460388, -0.6946679353713989, 0.267000287771225, 0.07891850918531418, 0.08210361748933792, 0.15867926180362701, 0.7369887232780457, 0.2937203049659729, 0.43214669823646545, 0.44974181056022644, 0.38303640484809875, 1.024813175201416, -0.9516152739524841, -0.05382492020726204, -1.6372075080871582, 0.8255774974822998, -0.2581574618816376, 0.30217257142066956, -0.5207214951515198, -1.6173933744430542, -0.7811583876609802, -0.6526116132736206, -0.1462787240743637, -0.11242204159498215, 0.6595351696014404, 1.9147955179214478, 0.19277440011501312, -0.9070988297462463, 0.5313044786453247, -0.4913758337497711, -0.02698785997927189, 0.04252048209309578, 0.24702151119709015, 0.4901082217693329, -0.483002245426178, -1.034977912902832, 0.02963670715689659, 0.18453407287597656, -0.6528828740119934, -0.2390529215335846, -0.3209492862224579, -0.8872296214103699, -0.15722538530826569, 0.020379427820444107, -0.669354259967804, 1.572609543800354, -0.37591326236724854, -0.8090662360191345, 0.7560939788818359, -0.4635363221168518, 0.08825336396694183, 0.42458245158195496, -0.023523902520537376, -0.6815396547317505, -0.4593247175216675, -0.4386436343193054, 0.6889799237251282, 0.2805286645889282, -0.14298465847969055, -0.37744277715682983, 0.2737325131893158, -0.01645226962864399, 0.5095868110656738, -0.22745633125305176, 1.1705423593521118, -0.7836628556251526, 0.010228943079710007, 0.34056439995765686, 0.3428337574005127, -0.6246886253356934, -0.4246179163455963, -0.01689370535314083, -0.6818951964378357, 0.2578863203525543, 0.035419728606939316, 0.7754334807395935, -0.8846689462661743, -0.6253118515014648, -0.013946647755801678, 0.02617958001792431, -0.32892554998397827, -0.5455861687660217, 0.6481230854988098, -0.06558787822723389, 0.021001756191253662, -0.30324435234069824, -0.9567979574203491, 0.13336414098739624, -0.3483473062515259, -0.2650299072265625, -0.3591364920139313, -0.30066612362861633, 0.9342684149742126, -0.679759681224823, -0.20070268213748932, -0.3162999153137207, 0.06847728788852692, -1.102362871170044, 1.246933937072754, -0.6735637784004211, 0.11040957272052765, -0.09565117955207825, -0.2478732317686081, -0.025841254740953445, -0.3437170088291168, 0.7133766412734985, -0.12916451692581177, -0.3455079197883606, 0.17825312912464142, 0.014303906820714474, 1.3997505903244019, -0.4093879759311676, 0.27555325627326965, -0.040716502815485, -0.3613192141056061, -0.1577029824256897, 0.35341620445251465, -0.08720587193965912, -0.5240223407745361, 0.5516095161437988, 0.4722837209701538, -0.22859814763069153, 0.31461232900619507, 1.1355527639389038, 0.8256088495254517, -0.631445586681366, 0.5555955767631531, 0.32658636569976807, -0.1397756040096283, 0.7635668516159058, 0.5211650133132935, 0.48045915365219116, 0.27208468317985535, 0.037104442715644836, -0.2103918343782425, 0.04632323980331421, -0.42797520756721497, -0.33499106764793396, 0.6533496975898743, 0.7136456370353699, 0.15679742395877838, 0.08499149978160858, -0.9507974982261658, -0.4788418114185333, 0.2924381196498871, 0.7232068777084351, 1.9086652994155884, -0.27069994807243347, 0.2887880206108093, -1.1319811344146729, -0.14822706580162048, -0.04598572477698326, 0.06977780908346176, -0.02500576712191105, -0.04855097457766533, -0.7148393988609314, -1.1558887958526611, 0.8323410749435425, 0.2388577163219452, 0.5829014182090759, -1.021277666091919, -0.9040921330451965, -0.5198889970779419, 0.3300994038581848, -0.8963470458984375, -0.5969513058662415, 0.34448039531707764, -0.7443968057632446, 0.2160577028989792, 0.004670369438827038, -0.14921879768371582, 0.08697105944156647, -0.09536843001842499, 1.2233186960220337, 0.0672631487250328, -0.5294696688652039, 0.07618233561515808, 0.8612368702888489, -0.6389319896697998, -0.7354940176010132, 0.08182528614997864, 0.6006243824958801, -0.37279656529426575, 0.18481667339801788, 0.4913750886917114, 0.1017780527472496, -0.05008136108517647, -0.4109211266040802, 0.7044852375984192, 0.36972376704216003, -0.25417712330818176, 0.5966759920120239, -0.46305084228515625, -0.374705046415329, -1.3347210884094238, 1.2158148288726807, -0.04456472769379616, -0.6285125017166138, 0.5695454478263855, -0.4629093110561371, -0.14487658441066742, 0.48765072226524353, -0.7842016816139221, -0.23967045545578003, -1.0134881734848022, 0.3098050057888031, -0.22354073822498322, -0.37229496240615845, 0.468303918838501, 0.832114040851593, -0.2492881566286087, 0.488585501909256, 0.5207074284553528, 0.17414315044879913, -0.009407710283994675, 0.23860640823841095, -0.7700535655021667, 0.3116523027420044, -0.1031058207154274, -0.025408316403627396, -0.3829697072505951, -0.47593915462493896, -0.9201214909553528, -0.23120437562465668, -0.23532095551490784, -0.17206688225269318, -0.5748019814491272, -0.13837051391601562, -0.5617378950119019, -0.7682474851608276, -0.307573527097702, -0.8951032161712646, -0.47659268975257874, 0.6034784913063049, 0.02845136821269989, 0.019045794382691383, -1.1158655881881714, -1.4975814819335938, -0.7213795781135559, -1.1147738695144653, -1.248093843460083, 0.6183775067329407, 0.05205830559134483, -0.5021473169326782, -0.32998836040496826, 0.002997087314724922, -0.11339449882507324, 0.7922767996788025, -0.6877085566520691, 0.9136247038841248, 0.3084818422794342, -0.0973253846168518, -0.37900131940841675, 0.01863471418619156, -0.3422819972038269, -1.0706957578659058, 0.2203403115272522, -0.6607460379600525, -0.33243051171302795, -0.679667055606842, -0.4801037609577179, -0.10130533576011658, 0.4001058340072632, 0.7026350498199463, 0.33999907970428467, -0.7225287556648254, 0.4910759925842285, 1.1972520351409912, -0.5626160502433777, -0.5262506604194641, 0.010801766067743301, 1.0773588418960571, 0.07873813807964325, -0.22466795146465302, 0.6657876372337341, -0.04004524275660515, 0.7014929056167603, -0.20364350080490112, -0.45603394508361816, 0.23483534157276154, -0.23988208174705505, 0.41318100690841675, 1.5617170333862305, 0.44766169786453247, -0.39345958828926086, -1.2645584344863892, 0.3438245952129364, -1.1126407384872437, -0.16514210402965546, 0.8186126947402954, 0.827174186706543, -0.005701822228729725, -0.14504466950893402, 0.15672259032726288, -0.5473066568374634, 0.11739049851894379, 0.21396712958812714, -0.7870738506317139, -0.9908629059791565, 0.26924410462379456, 0.29992109537124634, 0.05811977759003639, 0.5454196929931641, -0.18359516561031342, 0.8445971012115479, 14.747078895568848, 0.9134665131568909, 0.09075877070426941, 0.8068434596061707, 0.5277594923973083, 0.058541055768728256, -0.678844153881073, -0.49741023778915405, -0.8432140350341797, -0.2371044158935547, 1.658632516860962, -0.14747807383537292, 1.2307714223861694, 0.24068255722522736, -0.04238095134496689, -0.18228839337825775, -0.36382466554641724, 0.5915382504463196, 0.29651686549186707, -1.1028953790664673, 0.647443413734436, 0.259797602891922, 0.21089795231819153, 1.0606637001037598, 0.48000118136405945, 0.9549149870872498, 0.6814873218536377, -0.5684696435928345, 0.6395173072814941, 0.09897729009389877, 0.8967252373695374, -0.6088420748710632, 0.28529950976371765, 1.140120267868042, -0.9598926901817322, 0.13090573251247406, -0.6415995955467224, -1.2753856182098389, 0.22879517078399658, 0.014367248862981796, -0.5328409075737, -0.30235129594802856, -0.34525197744369507, 0.18345855176448822, 0.1992204785346985, 0.22707124054431915, 0.3879394233226776, 0.47895756363868713, -0.3039628863334656, 0.07678201049566269, 0.36009106040000916, 0.23802731931209564, -0.08153369277715683, 0.23396673798561096, -0.06855612993240356, 0.016306009143590927, 0.4042338728904724, 0.17965681850910187, -0.6087108850479126, -0.09839941561222076, -0.49953439831733704, -0.44245561957359314, -0.026268288493156433, 0.8181688189506531, 0.09109443426132202, 0.2069026529788971, -0.3506219983100891, 0.423979252576828, 1.1400893926620483, 0.20238752663135529, -0.3030199110507965, 0.4476947486400604, 0.7261358499526978, -0.76717209815979, -0.5330703854560852, 0.2153429388999939, -0.12066926807165146, -0.6621337532997131, -0.7350859045982361, -0.6745889186859131, 0.31762728095054626, -0.3970833122730255, -0.48082810640335083, 1.2798808813095093, -0.07910482585430145, -0.13290134072303772, -0.07853967696428299, -0.5516444444656372, -0.03272667154669762, 0.7334524989128113, -1.0648634433746338, -0.7214646339416504, 0.5967317819595337, -0.5412065386772156, -0.32168352603912354, -0.14465652406215668, 1.3577625751495361, 0.31533029675483704, -0.6934034824371338, 0.39072921872138977, 0.3712546229362488, -0.3162859380245209, -0.7951695322990417, -0.23076744377613068, 1.3481767177581787, 0.4588012099266052, 0.16997674107551575, 0.21579313278198242, 0.20407812297344208, -0.13428978621959686, -1.1100542545318604, 0.040802616626024246, 0.6203488707542419, -0.7889615297317505, -0.447664350271225, -1.103395700454712, -0.7386505007743835, 0.48616930842399597, 0.02217889577150345, -0.2807573974132538, 0.406999409198761, 0.21685761213302612, -0.1447353959083557, 0.3127291798591614, -0.6421713829040527, 0.1070224791765213, 0.6172134876251221, -0.7914434671401978, 0.20292821526527405, 0.49821937084198, 0.3546857535839081, -1.4907357692718506, -0.41659364104270935, -0.31528976559638977, 0.2967606782913208, -0.18804210424423218, 0.9150285720825195, -0.4555341601371765, 0.5954458713531494, 0.9495446085929871, 0.2358434498310089, -0.7048709988594055, 0.019613387063145638, -0.5793863534927368, -0.06213602423667908, -0.546997606754303, 0.6568611860275269, -0.2189510315656662, 0.6720690727233887, 1.0479536056518555, 0.17909467220306396, -0.4007304012775421, -0.36408811807632446, 0.07927410304546356, -0.17908844351768494, -0.673435628414154, 0.49241015315055847, -0.09386218339204788, -0.099068783223629, -0.036989569664001465, 0.10754663497209549, 0.8959029912948608, -0.17974835634231567, -0.20334959030151367, 0.5932198762893677, -0.017210641875863075, -0.21936847269535065, -0.6966726779937744, -0.010113670490682125, -1.1035813093185425, 0.047534167766571045, -1.2512954473495483, -0.043681710958480835, -0.6991600394248962, -0.20318110287189484, -0.2016649842262268, 0.14110450446605682, -0.08088485896587372, 0.4158298373222351, -0.3801777958869934, -0.6524720191955566, -0.2353850156068802, -0.590087354183197, 0.6336525082588196, 0.6677970886230469, -0.3522496521472931, 0.07764542102813721, -0.18419283628463745, 0.5257448554039001, 0.45354658365249634, 0.36258089542388916, -0.4220753312110901, -0.9704306721687317, -1.6365578174591064, 0.28347527980804443, 0.40660661458969116, -0.3628925085067749, -1.113024353981018, 0.6667913794517517, 0.16839280724525452, -0.08585640788078308, 0.2775725722312927, 0.23333527147769928, -0.6960037350654602, -0.15155884623527527, 0.2703445255756378, -0.734321117401123, 0.7744284868240356, 0.8140816688537598, -0.8439518809318542, -0.09905801713466644, 0.5868531465530396, -0.4060409963130951, -0.8632475137710571, -0.7765858173370361, 0.3757792115211487, -0.8042511343955994, 0.017729874700307846, -0.4037894308567047, 0.04609442502260208, -0.6419952511787415, -0.06165153160691261, 0.4014202952384949, 0.592683732509613, -0.23769375681877136, 0.8953973650932312, 0.45937931537628174, -0.7751989364624023, 0.07885248959064484, 0.36202508211135864, -0.2537950575351715, -0.2667325735092163, 0.9081483483314514, 0.18929651379585266, -0.5967602729797363, 0.6228151321411133, 0.08358972519636154, 0.5357481837272644, -1.093652606010437, -0.06374365836381912, 0.7262980937957764, -0.5614457726478577, -0.16547399759292603, 1.3063565492630005, -0.12374269962310791, -1.5126560926437378, -0.12240450084209442, -0.7975670099258423, -0.6355115175247192, -0.7931609153747559, 0.6548559069633484, -0.09268266707658768, 0.12492655962705612, -0.15069305896759033, -0.5488846898078918, -0.10847456753253937, -0.17131298780441284, -0.9466201066970825, 0.0831642672419548, -0.009730199351906776, -0.2689360976219177, 0.73863285779953, 0.42193785309791565, -0.6727024912834167, -0.5132434368133545, -0.6795680522918701, -0.061053019016981125, -0.009648325853049755, 0.564388632774353, -0.3992522656917572, -0.535287082195282, 0.7314105033874512, 0.3208356201648712, -0.10130295902490616, -0.03909970074892044, -0.35891464352607727, 0.46979501843452454, 0.5969460010528564, 0.511872410774231, -0.5413725972175598, -0.9894725680351257, 1.27878999710083, 1.0044057369232178, -0.8385446071624756, 0.43172985315322876, 0.04845296964049339, -1.0987094640731812, 0.5288100838661194, 0.708263099193573, 0.10915171355009079, 0.4098065197467804, 0.07264655828475952, 0.2388460487127304, -0.33463621139526367, -0.8685818314552307, -0.06952545046806335, 1.3131145238876343, 0.1597912609577179, 1.356778860092163, 0.8835189342498779, 0.045841559767723083, 0.5002851486206055, -0.1570531278848648, 0.3447569012641907, 0.03910887986421585, 0.7626863121986389, -0.11573509126901627, 0.07562880218029022, 0.08763917535543442, 0.9176955223083496, -0.2917783558368683, -0.5737367272377014, 0.18302857875823975, 0.5834227204322815, 0.0035539392847567797, 0.40459367632865906, 1.0154885053634644, 0.010078172199428082, 0.4350530505180359, 0.034446604549884796, 0.6362500786781311, -0.4652722179889679, -0.6001368761062622, -0.07076939940452576, -0.172531396150589, -0.06623274087905884, 0.16579991579055786, -0.5009881854057312, -0.6060635447502136, -0.6329267024993896, 0.7523082494735718, 0.4028659164905548, 0.3652760982513428, 1.2184242010116577, 0.8828370571136475, 0.7312768697738647, -0.7413462996482849, -1.0916043519973755, -0.20680035650730133, -0.8932088613510132, -0.12472182512283325, -0.7238643765449524, -0.5824341177940369, -0.274438738822937, 0.21372927725315094, -0.8684127926826477]}, "authors": [{"authorId": "2275222935", "name": "Jehyeon Bang"}, {"authorId": "2111060657", "name": "Yujeong Choi"}, {"authorId": "2275709681", "name": "Myeongwoo Kim"}, {"authorId": "2275283842", "name": "Yongdeok Kim"}, {"authorId": "1998820", "name": "Minsoo Rhu"}], "references": [{"paperId": "71de9b9cb83dcf53a86c7a3cb3ff7b36b3917978", "title": "Sia: Heterogeneity-aware, goodput-optimized ML-cluster scheduling"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "3995c7a3704db252cfcce18ef56562a89f4cf693", "title": "ElasticFlow: An Elastic Serverless Training Platform for Distributed Deep Learning"}, {"paperId": "d5fe97309afdf0da633e04b5da4212a054661ecf", "title": "Lucid: A Non-intrusive, Scalable and Interpretable Scheduler for Deep Learning Training Jobs"}, {"paperId": "ff5eb1bd55d61ae919865f6b4dab84e6ae1974f3", "title": "Optimus-CC: Efficient Large NLP Model Training with 3D Parallelism Aware Communication Compression"}, {"paperId": "92ffac92cdb5ae7fce881b4d65996458dfe7f241", "title": "Multi-resource interleaving for deep learning training"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "d2e024bf5e490c1e3e09bc1c493b6eda8941eeb4", "title": "Efficient Strong Scaling Through Burst Parallel Training"}, {"paperId": "e581a00152e3764d56277a409bc2c46f6092c484", "title": "Chronus: A Novel Deadline-aware Scheduler for Deep Learning Training Jobs"}, {"paperId": "f2c7e5d1762c42d3ff38d66964b71a3b67a30105", "title": "Themis: a network bandwidth-aware collective scheduling policy for distributed training of DL models"}, {"paperId": "ac35dffd21c16b02e140a36726b3a21d266cab0f", "title": "Characterization and Prediction of Deep Learning Workloads in Large-Scale GPU Datacenters"}, {"paperId": "72dd63d67588a42fc817bbb8d655b397f67425df", "title": "ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep learning"}, {"paperId": "774591fdd988eaaff3917e7c5171d044b0843e63", "title": "Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM"}, {"paperId": "12b71736392209b4292471b7da0aed71ba2aa545", "title": "ZeRO-Offload: Democratizing Billion-Scale Model Training"}, {"paperId": "3ccddb9316e82ce76cb70383c6c18a4a01596ad1", "title": "Lazy Batching: An SLA-aware Batching System for Cloud Machine Learning Inference"}, {"paperId": "2adcdc9e9e81147499e1372f992d25ac6265fb29", "title": "Pollux: Co-adaptive Cluster Scheduling for Goodput-Optimized Deep Learning"}, {"paperId": "2f4d6d3748ac6822711fe0bbd4cf6d2e66fa6613", "title": "Heterogeneity-Aware Cluster Scheduling Policies for Deep Learning Workloads"}, {"paperId": "f2d05e6dbdad363e41aafb64e81889150f32b939", "title": "ASTRA-SIM: Enabling SW/HW Co-Design Exploration for Distributed DL Training Platforms"}, {"paperId": "725264948d7b6946259af5b8d966e996b9570f99", "title": "DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters"}, {"paperId": "21a4cd35f19cfe8df1065b066b16edd048d2535d", "title": "DAPPLE: a pipelined data parallel approach for training large models"}, {"paperId": "de65c34bfb7e16ef9dec1d24893d54e08e7ccf34", "title": "FlexReduce: Flexible All-reduce for Distributed Deep Learning on Asymmetric Network Topology"}, {"paperId": "1882f194cb43828852cc052887671e55a80f945a", "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"}, {"paperId": "ac04ed0f3ae0f5b269c9b3e0d1232007d60dbf7e", "title": "Memory-Efficient Pipeline-Parallel DNN Training"}, {"paperId": "f491c4d10f9d656f64a2ad1269588ec2a5a54025", "title": "Daydream: Accurately Estimating the Efficacy of Optimizations for DNN Training"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "3b2a4cda4a1b9a4c2b2e478f4778719dca52c3fb", "title": "Balancing efficiency and fairness in heterogeneous GPU clusters for deep learning"}, {"paperId": "e7dd73e84efa11f0b0bc7654c93f7fc19058f5d0", "title": "Prague: High-Performance Heterogeneity-Aware Asynchronous Decentralized Training"}, {"paperId": "cd410e078d091c567a1fb3438f705ac5d75009ec", "title": "EFLOPS: Algorithm and System Co-Design for a High Performance Distributed Training Platform"}, {"paperId": "1e009f755503bffd7644fcd0a45939c54b838b37", "title": "BlueConnect: Decomposing all-reduce for deep learning on heterogeneous network hierarchy"}, {"paperId": "3fd7c9ba742dd2b435afa75217847e5087e2f2a8", "title": "PipeDream: generalized pipeline parallelism for DNN training"}, {"paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3", "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "976945fb2879961e5faee43472d3df0d8510ada9", "title": "PREMA: A Predictive Multi-Task Scheduling Algorithm For Preemptible Neural Processing Units"}, {"paperId": "4c3ae07aab62ad4aaa7448be0a0ed834b624b5a0", "title": "Themis: Fair and Efficient GPU Cluster Scheduling for Machine Learning Workloads"}, {"paperId": "54ddd67944520f249b906ba4e817188686eae94d", "title": "Analysis of Large-Scale Multi-Tenant GPU Clusters for DNN Training Workloads"}, {"paperId": "d79a26226393f687ddbc375e32055b40b8ad8d38", "title": "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism"}, {"paperId": "0606676f16d581fa453f6b7b8a14fc7c4af8d025", "title": "Gandiva: Introspective Cluster Scheduling for Deep Learning"}, {"paperId": "7dd7198bb8a61dd22879068e8c4619b32f0470f8", "title": "Supporting Very Large Models using Automatic Dataflow Graph Partitioning"}, {"paperId": "f971658ab845d7573c4bbb760d5e7e5332025254", "title": "Beyond Data and Model Parallelism for Deep Neural Networks"}, {"paperId": "93a06eb066fe58ed7d036e46e4cee53483e16bb8", "title": "Optimus: an efficient dynamic resource scheduler for deep learning clusters"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "9a090954cf24e619f66e7c8c55c4ca184e7dcc17", "title": "GARNET: A detailed on-chip network model inside a full-system simulator"}, {"paperId": "6f4e48c2a5de9337d147ebbb7d0ff0e555adceca", "title": "Bandwidth optimal all-reduce algorithms for clusters of workstations"}, {"paperId": "8c92e2f083ce579fc7ee0be2c4d2719c7c2a4c07", "title": "GitHub Copilot"}, {"paperId": "920241246c82176173d442fd43214b2762be6e56", "title": "Elastic Resource Sharing for Distributed Deep Learning"}, {"paperId": null, "title": "\u201cPyTorch Distributed: Experiences on Accelerating Data Parallel Training,\u201d"}, {"paperId": "57bc3e71a889013981b191b6431bec3dc45eba9f", "title": "AntMan: Dynamic Scaling on GPU Clusters for Deep Learning"}, {"paperId": "8d2d560bf1c4c6930d2d1411e48b642bd5b81179", "title": "Tiresias: A GPU Cluster Manager for Distributed Deep Learning"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "\u201cCUPTI"}, {"paperId": null, "title": "\u201cPyTorch Documentation,\u201d"}, {"paperId": null, "title": "\u201cIntroduction to Generative AI Studio,\u201d"}, {"paperId": null, "title": "\u201cNVIDIA Collective Communications Library (NCCL),\u201d \u201dhttps"}, {"paperId": null, "title": "\u201cNVIDIA Teams With Microsoft to Build Massive Cloud AI Computer,\u201d"}, {"paperId": null, "title": "\u201cMegatron-DeepSpeed"}, {"paperId": null, "title": "\u201cElasticFlow Traces,\u201d"}, {"paperId": null, "title": "\u201cIntroducing the Introducing the AI Research SuperCluster ,\u201d"}, {"paperId": null, "title": "\u201cNVLink and NVSwitch,\u201d"}, {"paperId": null, "title": "\u201cPerformance reported by NCCL tests,\u201d"}, {"paperId": null, "title": "\u201cOnline Evolutionary Size Orchestration for Scheduling Deep Learning Workloads in Clusters,\u201d"}, {"paperId": null, "title": "\u201cAzure OpenAI Service,\u201d"}, {"paperId": null, "title": "\u201cAmazon EC2 P4 Instances,\u201d"}]}