{"paperId": "61a4023aad982d435dcde9f40bb9c2a735e88a9c", "title": "RIFormer: Keep Your Vision Backbone Effective But Removing Token Mixer", "abstract": "This paper studies how to keep a vision backbone effective while removing token mixers in its basic building blocks. Token mixers, as self-attention for vision transformers (ViTs), are intended to perform information communication between different spatial tokens but suffer from considerable computational cost and latency. However, directly removing them will lead to an incomplete model structure prior, and thus brings a significant accuracy drop. To this end, we first develop an RepIdentityFormer base on the re-parameterizing idea, to study the token mixer free model architecture. And we then explore the improved learning paradigm to break the limitation of simple token mixer free backbone, and summarize the empirical practice into 5 guidelines. Equipped with the proposed optimization strategy, we are able to build an extremely simple vision backbone with encouraging performance, while enjoying the high efficiency during inference. Extensive experiments and ablative analysis also demonstrate that the inductive bias of network architecture, can be incorporated into simple network structure with appropriate optimization strategy. We hope this work can serve as a starting point for the exploration of optimization-driven efficient network design.", "venue": "Computer Vision and Pattern Recognition", "year": 2023, "citationCount": 9, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper develops an RepIdentityFormer base on the re-parameterizing idea, and explores the improved learning paradigm to break the limitation of simple token mixer free backbone, and summarizes the empirical practice into 5 guidelines."}, "embedding": {"model": "specter_v2", "vector": [0.16427123546600342, 0.68928062915802, -0.7086179256439209, 0.17484314739704132, -0.33838367462158203, -0.09085544943809509, 0.8338879942893982, -0.07927475869655609, -0.39205700159072876, -0.5068090558052063, 0.6238155961036682, 0.5014685988426208, 0.22191168367862701, -0.04394382983446121, -0.3104616403579712, -0.27290448546409607, -0.9029783010482788, 0.14503227174282074, 0.2025415301322937, -0.16553594172000885, 0.1082642674446106, -0.5659216642379761, -1.2367510795593262, 0.418929785490036, 0.20295105874538422, 0.8754197955131531, 0.28415921330451965, 0.7348046898841858, -0.32180920243263245, 0.9004898071289062, 0.09291079640388489, -0.2183242291212082, 0.41353023052215576, 0.15879787504673004, -0.4068955183029175, -0.4548574686050415, 0.7177436947822571, -0.36526355147361755, -0.8602235913276672, 0.6628910303115845, -0.0359112024307251, 0.10411103069782257, 0.45840078592300415, -0.9924952387809753, -0.21708771586418152, 1.0651243925094604, 0.6459366679191589, 0.8157097101211548, -0.6207352876663208, -0.5308603644371033, 1.3289097547531128, -0.9547736048698425, 0.15331807732582092, 1.5027289390563965, 0.2990129590034485, 0.13552604615688324, 0.060425952076911926, -0.6343550086021423, 1.153864860534668, 0.530208170413971, -0.7410001158714294, -0.5151598453521729, 0.2998029291629791, 0.08881564438343048, 1.4753791093826294, -0.5476484894752502, 0.35303446650505066, 0.7751456499099731, 0.005945026408880949, 1.7541900873184204, -0.024287505075335503, -0.8222459554672241, -0.059156354516744614, 0.13216519355773926, 0.3720776438713074, 0.6784771084785461, -0.3251371383666992, 0.36421483755111694, -1.2698338031768799, 0.21794040501117706, 0.8472365736961365, -0.15404385328292847, 0.4517260789871216, 0.04246013984084129, -0.36293521523475647, 0.47387146949768066, 0.8499880433082581, 0.8896458148956299, -0.5855107307434082, 0.9218941926956177, 0.3993656039237976, 0.3862592577934265, -0.2965865731239319, 0.23148685693740845, 0.44959381222724915, 0.7043145298957825, -0.7143803238868713, 0.1199650689959526, -0.3843822777271271, 0.941226601600647, -0.15410298109054565, 0.36857882142066956, -0.9647652506828308, -0.04517561197280884, 1.607755184173584, -0.1425001174211502, 0.4945387542247772, -1.0797007083892822, 0.13600431382656097, -0.7720637917518616, 0.26042014360427856, -0.701366126537323, 0.17070350050926208, -0.4570341110229492, -0.8326009511947632, -1.1938120126724243, -0.17342326045036316, 0.5969527959823608, -0.909294068813324, 0.6352356672286987, -0.35435739159584045, 0.3140083849430084, 0.009577221237123013, 0.4896334409713745, 0.5492510199546814, 0.167759969830513, 0.4107509255409241, 0.23781025409698486, 1.1036232709884644, -1.1818187236785889, -0.5786881446838379, -0.9711791276931763, 0.11205767095088959, -0.32155340909957886, -0.12103715538978577, -0.07623545825481415, -1.2066491842269897, -1.239295482635498, -0.8728799223899841, 0.08005133271217346, -0.5635160207748413, -0.395183801651001, 1.359374761581421, 0.05875793844461441, -1.26799476146698, 0.6815311312675476, -0.2546893060207367, -0.19620071351528168, 0.6727147102355957, 0.13524730503559113, 0.3716535270214081, -0.20883266627788544, -1.2056043148040771, 0.3484486937522888, 0.13312454521656036, -0.09781084209680557, -0.618430495262146, -0.38573265075683594, -1.0161792039871216, 0.10581070929765701, 0.27849215269088745, -0.8983986973762512, 1.165875792503357, -0.5954259634017944, -0.9311758279800415, 0.551628589630127, -0.42466986179351807, -0.17627719044685364, 0.3824038505554199, -0.0983726978302002, -0.390334814786911, -0.01708976924419403, 0.13213126361370087, 0.9132203459739685, 0.744588315486908, -0.582628071308136, -0.35821208357810974, -0.16951371729373932, -0.1975620687007904, -0.006581383291631937, 0.034986771643161774, 0.6479325890541077, -0.198027566075325, -0.11567139625549316, 0.5402513742446899, 0.9854831099510193, -0.03126031532883644, -0.03154394030570984, -0.25861814618110657, -1.101637840270996, 0.4420420527458191, 0.5095703601837158, 0.35686492919921875, -0.7490609884262085, -1.2394943237304688, 0.05688400939106941, 0.15292629599571228, -0.25097668170928955, -1.0647221803665161, 0.6149628758430481, -0.2902650535106659, 0.17784824967384338, 0.3908490836620331, -0.7956876158714294, -0.007739809807389975, -0.15066008269786835, -0.7094845771789551, -0.21876920759677887, -0.10443509370088577, 1.0947308540344238, -1.0456393957138062, -0.3792474865913391, 0.3287462592124939, 0.462629109621048, -0.8683598637580872, 1.0961511135101318, -0.24137376248836517, 0.06916224211454391, -0.2497503161430359, 0.03639483451843262, 0.1441861093044281, -0.39800918102264404, 0.0933990627527237, -0.6512445211410522, -0.13098454475402832, 0.5707066655158997, -0.4915768504142761, 1.37732994556427, -0.2825027108192444, 0.9623861312866211, -0.03332041949033737, -0.9527725577354431, 0.11971032619476318, 0.5359742045402527, -0.029181309044361115, -0.8320788741111755, 0.24937084317207336, -0.23187758028507233, -0.5144348740577698, 0.08214042335748672, 0.8711802363395691, 1.0630989074707031, -0.028547754511237144, -0.35469144582748413, 0.29661229252815247, -0.11415493488311768, 0.0826588124036789, 0.45250949263572693, 0.5720027089118958, 0.1745181828737259, 0.11195777356624603, -0.05453317612409592, -0.24002093076705933, -0.9392690658569336, -0.06372161954641342, 1.2025208473205566, 0.3702779710292816, 0.7161833047866821, 0.21312718093395233, -0.6413618326187134, -0.09151475131511688, -0.211837500333786, 0.304317444562912, 1.089346170425415, 0.2540706992149353, -0.2981970012187958, -0.6358485817909241, -0.08420265465974808, -0.35345450043678284, -0.0718080997467041, -0.3187963664531708, -0.11367461830377579, -0.18033194541931152, -0.6888309717178345, 0.7980282306671143, 0.38217872381210327, 1.3999876976013184, -0.7273255586624146, -0.3577641546726227, -0.16378794610500336, -0.01870778389275074, -0.5514488816261292, -0.42901137471199036, 0.24381834268569946, -0.3001411557197571, -0.19452475011348724, -0.04947724565863609, -0.17694242298603058, 0.0910920798778534, -0.09968085587024689, 0.7016664147377014, -0.47247597575187683, -0.1273350715637207, 0.38895612955093384, 0.7917652130126953, -0.6069523096084595, -0.15633858740329742, 0.11470277607440948, -0.20024310052394867, -0.07363969832658768, 0.13974951207637787, 0.3826135993003845, -0.6226298213005066, -0.005684351548552513, -0.37329399585723877, -0.15690968930721283, 0.06393923610448837, 0.09233572334051132, 0.5726704001426697, -0.07887881994247437, 0.16999350488185883, -0.7870280742645264, 0.7393872141838074, -0.10850296914577484, -0.37322181463241577, -0.03049035370349884, -0.9472644329071045, -0.35551607608795166, 0.19022031128406525, -0.5699148774147034, -0.1642373502254486, -0.9342498779296875, 0.4811510145664215, -0.552397608757019, -0.3395460546016693, -0.04865832254290581, 0.36885902285575867, -0.005132653284817934, 0.3432987630367279, 0.47823628783226013, 0.0012130654649809003, 0.27921417355537415, 0.8510070443153381, -0.6843883991241455, 0.8317304253578186, 0.24134427309036255, -0.1694757342338562, 0.3700921833515167, -0.1836000680923462, -1.085135817527771, -0.5105999708175659, -0.6645045280456543, 0.01870919205248356, -0.4272057116031647, 0.05653650313615799, -0.8818080425262451, -1.2801612615585327, 0.30430787801742554, -1.0310559272766113, -0.37197345495224, -0.12582440674304962, -0.03814280033111572, -0.2415551394224167, -0.9665292501449585, -0.8746384978294373, -0.8006420135498047, -0.23531249165534973, -0.6146496534347534, 0.1710682511329651, 0.22541722655296326, -0.3288092017173767, -0.5618582963943481, -0.14469830691814423, -0.1479111760854721, 1.1800175905227661, -0.62007737159729, 0.19707342982292175, 0.11283131688833237, -0.9957789778709412, -0.1360795646905899, -0.040368348360061646, 0.21961893141269684, -0.06330199539661407, 0.13322530686855316, -1.320326566696167, 0.398479163646698, -0.4539322555065155, -0.2445247322320938, 0.6610727906227112, 0.7267115116119385, 0.8012464046478271, -0.3565369248390198, -0.6805002093315125, 0.2740453779697418, 1.3071504831314087, -0.6087958216667175, 0.40569207072257996, 0.43532654643058777, 0.8185029029846191, 0.22776900231838226, -0.1974247545003891, 0.43751442432403564, 0.922357976436615, 0.2666197419166565, 0.5944909453392029, -0.42383143305778503, -0.3154374063014984, -0.735609233379364, 0.3063613176345825, 1.0537431240081787, 0.1278742402791977, -0.08865474909543991, -0.5775321125984192, 0.9463191032409668, -1.5720038414001465, -1.249947428703308, 0.7878007888793945, 0.9693301320075989, -0.05908752232789993, -0.41981765627861023, -0.1325204074382782, -0.24032975733280182, 0.6346025466918945, 0.5566582679748535, -0.16906554996967316, -0.25871986150741577, -0.018175369128584862, 0.32823240756988525, 0.43595626950263977, 0.8305763602256775, -0.23181715607643127, 0.9698665142059326, 15.14838695526123, 0.5093472599983215, -0.18217577040195465, 0.33313968777656555, 0.633921205997467, 0.5040329098701477, -0.4311681091785431, 0.20431169867515564, -1.0689363479614258, 0.010471138171851635, 0.9795633554458618, 0.4966673254966736, 0.6336898803710938, 0.14168336987495422, -0.11677976697683334, -0.11439525336027145, -0.3627830147743225, 0.6485803127288818, 0.5646029114723206, -1.2202847003936768, 0.35945525765419006, -0.11938312649726868, 0.006799890194088221, 0.6336010694503784, 0.9050025343894958, 0.5758433938026428, 0.6951216459274292, -0.46816137433052063, 0.7243050336837769, 0.3828180432319641, 0.5073139667510986, 0.054975707083940506, 0.15831358730793, 0.16352185606956482, -1.1072981357574463, -0.021112099289894104, -0.607012152671814, -1.1023541688919067, -0.07777337729930878, 0.03618145361542702, -0.24518978595733643, -0.46078282594680786, -0.1457638442516327, 0.5298418402671814, 0.2466598004102707, 0.6088534593582153, -0.2546887695789337, 0.42909765243530273, -0.12555688619613647, 0.3120349943637848, 0.3666769862174988, 0.8020064234733582, 0.02112162485718727, -0.2478102296590805, -0.251049667596817, -0.1626110076904297, -0.040201619267463684, 0.433685839176178, -0.4023951292037964, -0.5693005919456482, -0.5605122447013855, 0.10661190748214722, 0.47655612230300903, 0.9715900421142578, 0.2530607581138611, 0.1445932686328888, -0.05695537477731705, 0.27248716354370117, 0.5350249409675598, 0.33237260580062866, -0.4356400668621063, -0.1879679560661316, 0.3482157588005066, -0.4443678855895996, -0.15173572301864624, 0.8706929087638855, 0.03856126591563225, -0.4966494143009186, -0.798731803894043, -0.012012739665806293, 0.4086326062679291, -0.9700021147727966, -0.7174219489097595, 0.933773398399353, -0.05734409764409065, -0.16495509445667267, 0.14144554734230042, -0.47896435856819153, -0.6073755621910095, 0.17598414421081543, -1.9613052606582642, -1.0920931100845337, -0.1448042243719101, 0.16595324873924255, -0.45841920375823975, 0.10736775398254395, 0.84129798412323, -0.056578829884529114, -0.15034465491771698, 0.27781927585601807, -0.11776965111494064, 0.017316093668341637, 0.16207373142242432, -0.626936674118042, 0.5324377417564392, 0.1018010750412941, 0.3162144720554352, 0.40450140833854675, -0.04842577502131462, 0.5862501263618469, -0.4427792727947235, 0.08413193374872208, 0.7951111793518066, -0.8087753057479858, -0.5869182348251343, -0.4939080476760864, -0.5880131721496582, 0.5599249005317688, 1.0184409618377686, 0.05592593550682068, -0.10591485351324081, 0.15824776887893677, -0.6548422574996948, -0.511758029460907, -0.9039598703384399, 0.26735666394233704, 0.4938594102859497, -0.7294371724128723, -0.48850882053375244, -0.2305511236190796, -0.06819362938404083, -0.654198169708252, -0.4543311297893524, -0.5684302449226379, 0.3231078088283539, -0.34752389788627625, 1.4172862768173218, -0.18962837755680084, 0.19803796708583832, 0.6918939352035522, -0.07065718621015549, -0.7846285104751587, -0.2314368486404419, -1.0858864784240723, 0.15608516335487366, 0.471585214138031, 0.25263479351997375, -0.8827390670776367, 0.35997670888900757, 0.7196547985076904, 0.29946836829185486, 0.06502028554677963, -0.724321186542511, -0.24356640875339508, -0.11129213124513626, -0.48824697732925415, 0.4407713711261749, 0.15558116137981415, 0.2582353353500366, 0.25811758637428284, 0.6085857152938843, 0.6119336485862732, 0.3538506031036377, -0.7838008999824524, 0.19651953876018524, -0.19803981482982635, 0.16715653240680695, -0.4942702054977417, -0.4823658764362335, -1.5441687107086182, -0.1999797821044922, -1.1590474843978882, 0.07114088535308838, -1.194028615951538, -0.5710851550102234, -0.04808800667524338, -0.7135061025619507, 0.14559192955493927, 0.5351161360740662, -0.3960121273994446, -0.1897028237581253, -0.2746298909187317, -0.7128512859344482, 0.7012951374053955, 0.9991869926452637, -0.9749910235404968, 0.21030446887016296, -0.19702152907848358, -0.44255146384239197, 0.34507402777671814, 0.4432588517665863, -0.5617823004722595, -0.786794126033783, -1.120676875114441, 0.07796921581029892, -0.005699171684682369, 0.21143539249897003, -0.7310236096382141, 1.0441159009933472, 0.3879632353782654, 0.17391736805438995, -0.16421404480934143, 0.6553513407707214, -1.06839120388031, -0.5009917616844177, 0.26966968178749084, -0.8195480704307556, 0.01908816210925579, -0.08735336363315582, -0.4379584789276123, -0.31189894676208496, 0.8366938829421997, 0.1141643226146698, -1.3293507099151611, -0.7649005055427551, 0.44294774532318115, -0.6308656334877014, 0.2404622882604599, -0.33299773931503296, -0.40099573135375977, -1.489625334739685, -0.22476014494895935, 0.026283863931894302, 0.5221015214920044, -0.5003543496131897, 0.9967008829116821, 0.5968601107597351, -1.2195188999176025, 0.13040627539157867, 0.44445618987083435, -0.12425180524587631, 0.23500685393810272, 0.4150000810623169, 0.2296375334262848, 0.05142559856176376, 0.44210049510002136, 0.04972158744931221, 0.17719106376171112, -0.43095913529396057, 0.19771137833595276, 0.7975447773933411, -0.320518434047699, -0.04487933963537216, 0.9003756642341614, -0.060611337423324585, -0.4688301384449005, 0.439176082611084, -1.0681835412979126, -0.6078845262527466, -0.06106391176581383, 0.43236833810806274, 0.4482768177986145, -0.4934277832508087, 0.0018170361872762442, -0.6081006526947021, 0.3929869830608368, -0.4161396920681, -0.6257221698760986, 0.24854260683059692, -0.26887139678001404, -0.0866105780005455, 0.38914671540260315, 0.5435444116592407, -0.8398669362068176, -0.9814272522926331, -0.5769230723381042, -0.6425862312316895, -0.417440801858902, 0.535506546497345, -0.13479356467723846, -0.7605925798416138, 0.63926100730896, 0.6878434419631958, 0.4267826974391937, -0.16465526819229126, 0.03499749302864075, -0.29487887024879456, 0.6317287683486938, -0.08024045825004578, -0.7245119214057922, -0.282478004693985, 0.6938210725784302, 0.8914767503738403, -0.6621258854866028, 0.02143065258860588, 0.021736808121204376, -0.39163506031036377, 0.4406477212905884, 0.49465474486351013, -0.39039891958236694, 0.6670447587966919, -0.11782792210578918, 0.40212205052375793, 0.04245609790086746, -1.030861258506775, -0.43551722168922424, 0.21805357933044434, 1.5879300832748413, 0.4773368835449219, -0.09552258998155594, 0.6189865469932556, 0.3831072449684143, 0.2644108831882477, 0.07225199043750763, 0.2666034996509552, 0.10666438192129135, -0.14172492921352386, 0.1926289051771164, -0.04535302147269249, 0.34814324975013733, -0.43816840648651123, -0.7853261232376099, 0.21772556006908417, 0.7571249008178711, 0.058313824236392975, 0.7638570666313171, 1.13275945186615, 0.36829453706741333, 0.4095708429813385, -0.10327741503715515, 0.8262710571289062, 0.039111439138650894, -0.34000033140182495, -0.029172753915190697, -0.7584603428840637, -0.19835372269153595, -0.6007081866264343, -0.4857271909713745, -0.1741650104522705, -0.17604126036167145, 0.1491711288690567, -0.04225923493504524, 0.12819063663482666, 0.6789022088050842, 0.6084746718406677, 0.7410017251968384, -0.05961015820503235, -0.48603159189224243, 0.006097750272601843, -0.8282379508018494, 0.15798060595989227, -0.6123347878456116, 0.1911144107580185, -0.2892915904521942, -0.3649248480796814, -0.5804040431976318]}, "authors": [{"authorId": "2110182417", "name": "Jiahao Wang"}, {"authorId": "1734973476", "name": "Songyang Zhang"}, {"authorId": "2144386151", "name": "Yong Liu"}, {"authorId": "2137407647", "name": "Taiqiang Wu"}, {"authorId": "3001727", "name": "Yujiu Yang"}, {"authorId": "46522599", "name": "Xihui Liu"}, {"authorId": "152568027", "name": "Kai Chen"}, {"authorId": "2143481782", "name": "Ping Luo"}, {"authorId": "1807606", "name": "Dahua Lin"}], "references": [{"paperId": "fc4cbc7a75f5a3bbca59db5513231555f078fe78", "title": "MetaFormer Baselines for Vision"}, {"paperId": "1dff6b1b35e2d45d4db57c8b4e4395486c3e365f", "title": "Token Merging: Your ViT But Faster"}, {"paperId": "dfdb2894d50e095ce97f994ed6cee38554c4c84f", "title": "Q-ViT: Accurate and Fully Quantized Low-bit Vision Transformer"}, {"paperId": "2475b38a76a9c2dc67f74446e2e686815764b0f2", "title": "EcoFormer: Energy-Saving Attention with Linear Complexity"}, {"paperId": "3e448df5aa191f7a3945d0fd609c8bc5966a2333", "title": "HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions"}, {"paperId": "2fe71acc2c3f1e75b6149dea72838f0b594ad013", "title": "TinyViT: Fast Pretraining Distillation for Small Vision Transformers"}, {"paperId": "270195c8ecc14b98a206461282b88f8fae798932", "title": "Vision GNN: An Image is Worth Graph of Nodes"}, {"paperId": "b65de6b99535e9c3b07fd672b363d4496306eafb", "title": "Re-parameterizing Your Optimizers rather than Architectures"}, {"paperId": "6ece13cb596bf2fb47453fa76d83094f40bc786d", "title": "Attention Probe: Vision Transformer Distillation in the Wild"}, {"paperId": "58c486ad4020177f5ed3d9f2883f3fc327b55770", "title": "MiniViT: Compressing Vision Transformers with Weight Multiplexing"}, {"paperId": "9f1b0e4c42a5a85d4c023030557ade4419f82ecf", "title": "Scaling Up Your Kernels to 31\u00d731: Revisiting Large Kernel Design in CNNs"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "722d71a19e4049b30a03d1028158881560432135", "title": "SPViT: Enabling Faster Vision Transformers via Latency-Aware Soft Token Pruning"}, {"paperId": "730a34374384f8abb886e464758b1a145edef938", "title": "RepMLPNet: Hierarchical Vision MLP with Re-parameterized Locality"}, {"paperId": "38212997a6e8c55141574c329bb58d2eadcb0db5", "title": "AdaViT: Adaptive Vision Transformers for Efficient Image Recognition"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "f454f6b5f2ca9749ddf442eb5134612ef7f758c1", "title": "ResNet strikes back: An improved training procedure in timm"}, {"paperId": "c27052d878c81564edfc4f6027b48ad684d94af0", "title": "Dead Pixel Test Using Effective Receptive Field"}, {"paperId": "c723187a2230749b1e706df2217e928c8271a660", "title": "Learning Efficient Vision Transformers via Fine-Grained Manifold Distillation"}, {"paperId": "9b6af0e358e76d22f209c75b1702c3e6ea7815b1", "title": "Global Filter Networks for Image Classification"}, {"paperId": "dbdcabd0444ad50b68ee09e30f39b66e9068f5d2", "title": "DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification"}, {"paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60", "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"}, {"paperId": "48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5", "title": "ResMLP: Feedforward Networks for Image Classification With Data-Efficient Training"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "2b8088253e2378fce001a090fe923b81e8dedf25", "title": "RepVGG: Making VGG-style ConvNets Great Again"}, {"paperId": "b5b006dc558cb7fbd532d67e989173b536e8ac80", "title": "MiniLMv2: Multi-Head Self-Attention Relation Distillation for Compressing Pretrained Transformers"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "6f6f73e69ee0d9d5d7d088bb882db1851d98175a", "title": "Pre-Trained Image Processing Transformer"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "c5ced88892855b7dfea915e278468bc8d68e907c", "title": "ResRep: Lossless CNN Pruning via Decoupling Remembering and Forgetting"}, {"paperId": "5335fe1bf347f7ad1dce1611ea4b60bd8391a090", "title": "Transferring Inductive Biases through Knowledge Distillation"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "c6c734e16f66fbfcefac7625cc64599e83292c1e", "title": "MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf", "title": "Patient Knowledge Distillation for BERT Model Compression"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "4bd23d951846832bdf550df574cdec07bc08dec1", "title": "Bi-Real Net: Enhancing the Performance of 1-bit CNNs With Improved Representational Capability and Advanced Training Algorithm"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "edccc38cbd8765c658b3880facec76e9f4a8ee5c", "title": "DiracNets: Training Very Deep Neural Networks Without Skip-Connections"}, {"paperId": "01a4f33da8ad94ced3cf58548b28dbbb44148571", "title": "Understanding the Effective Receptive Field in Deep Convolutional Neural Networks"}, {"paperId": "5582bebed97947a41e3ddd9bd1f284b73f1648c2", "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "7d2a78a1f713b71c3a337247d042c5c2f0b2da84", "title": "EfficientViT: Enhanced Linear Attention for High-Resolution Low-Computation Visual Recognition"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "17eaf8f5d53407baa3c8ce3bdf5cc1a3503182eb", "title": "Adder Attention for Vision Transformer"}, {"paperId": "9af62668cb87f11fffb53a194588c8158fde6b00", "title": "DynamicViT: Ef\ufb01cient Vision Transformers with Dynamic Token Sparsi\ufb01cation"}, {"paperId": "7d76a09aa363685bc0f04a502ed853dc09a574e2", "title": "Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization"}, {"paperId": null, "title": "Grad-CAM [36] activation maps of four different pre-trained backbones on ImageNet-1K. We sample 4 images to visualize from the validation set"}, {"paperId": null, "title": "MACs (G) Throughput (images/s) Top-1 (%) Convolution RSB-ResNet-34"}, {"paperId": null, "title": "def get_equivalent_scale_bias(self):eq_s,eq_b=self.fuse_affine(self.norm1, self.token_mixer) return eq_s, eq_b"}]}