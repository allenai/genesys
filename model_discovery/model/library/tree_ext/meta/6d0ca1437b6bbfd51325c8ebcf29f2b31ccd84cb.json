{"paperId": "6d0ca1437b6bbfd51325c8ebcf29f2b31ccd84cb", "title": "Beyond Scaling Laws: Understanding Transformer Performance with Associative Memory", "abstract": "Increasing the size of a Transformer model does not always lead to enhanced performance. This phenomenon cannot be explained by the empirical scaling laws. Furthermore, improved generalization ability occurs as the model memorizes the training samples. We present a theoretical framework that sheds light on the memorization process and performance dynamics of transformer-based language models. We model the behavior of Transformers with associative memories using Hopfield networks, such that each transformer block effectively conducts an approximate nearest-neighbor search. Based on this, we design an energy function analogous to that in the modern continuous Hopfield network which provides an insightful explanation for the attention mechanism. Using the majorization-minimization technique, we construct a global energy function that captures the layered architecture of the Transformer. Under specific conditions, we show that the minimum achievable cross-entropy loss is bounded from below by a constant approximately equal to 1. We substantiate our theoretical results by conducting experiments with GPT-2 on various data sizes, as well as training vanilla Transformers on a dataset of 2M tokens.", "venue": "arXiv.org", "year": 2024, "citationCount": 2, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A theoretical framework that sheds light on the memorization process and performance dynamics of transformer-based language models, and model the behavior of Transformers with associative memories using Hopfield networks, such that each transformer block effectively conducts an approximate nearest-neighbor search."}, "embedding": {"model": "specter_v2", "vector": [-0.11846271902322769, 0.4798767864704132, -0.31767114996910095, -0.016558052971959114, -0.5579139590263367, -0.1591843217611313, 0.6256782412528992, -0.10064427554607391, -0.48000991344451904, -0.19046704471111298, 0.33751240372657776, -0.1475318819284439, 0.07973573356866837, -0.028930868953466415, -0.18006166815757751, -0.07874039560556412, -1.1612135171890259, 0.33553555607795715, -0.13439325988292694, -0.3247687518596649, 0.08872638642787933, -0.6149320602416992, -0.9610439538955688, -0.059669896960258484, 0.5792479515075684, 1.1202946901321411, -0.024410530924797058, 0.6242609620094299, -0.32938870787620544, 0.37719517946243286, 0.5276644825935364, -0.5488292574882507, 0.3187987208366394, 0.23859737813472748, -0.5248247385025024, -0.30974382162094116, 0.4368310570716858, -0.1678999811410904, -0.8990179300308228, 0.8912880420684814, -0.24610590934753418, 0.42007195949554443, 0.6856222152709961, -0.5334038138389587, -0.5895565152168274, 0.7846056222915649, 0.9354974627494812, 0.7502089738845825, -0.6860036253929138, -0.5782240033149719, 1.365787386894226, -1.268821120262146, -0.09223632514476776, 1.0927202701568604, 0.46732065081596375, 0.42305198311805725, -0.014215136878192425, -0.7788098454475403, 0.5708324313163757, -0.037289708852767944, -1.0278993844985962, -0.2722965180873871, -0.15552321076393127, 0.06538671255111694, 1.4061001539230347, -0.43259474635124207, 0.3102107048034668, 0.14842163026332855, 0.31658467650413513, 1.6141432523727417, 0.24388015270233154, -0.6216837167739868, -0.09045697003602982, -0.039103299379348755, 0.299382746219635, 0.8534302115440369, -0.26017382740974426, 0.30642756819725037, -0.9290143251419067, -0.03800463303923607, 0.17933286726474762, -0.22937054932117462, 0.13680300116539001, -0.3047691583633423, 0.15468308329582214, 0.7151122093200684, 0.4665839672088623, 0.717570424079895, -0.43906062841415405, 0.9334211945533752, 0.5511907935142517, 0.47342514991760254, 0.14646130800247192, 0.4594516158103943, 0.2531629502773285, 0.2689468264579773, -1.1028343439102173, 0.21728573739528656, -0.1918545812368393, 0.7079428434371948, -0.24720622599124908, 0.5714619159698486, -0.4927854537963867, 0.35549068450927734, 1.4315799474716187, 0.27009499073028564, 0.5019797086715698, -0.34658053517341614, 0.3377048075199127, -0.9234960079193115, -0.08850651234388351, -0.5104424953460693, 0.0956934317946434, -0.580094575881958, -0.6564450860023499, -1.251970887184143, -0.7433164715766907, 0.570406973361969, -1.077418327331543, 0.8015473484992981, -0.7744898796081543, -0.1294853687286377, 0.10539069026708603, 0.4288311302661896, -0.014646203257143497, 0.4374805986881256, 0.4850577712059021, 0.09231536835432053, 0.6968901753425598, -0.5010695457458496, -0.8378427624702454, -0.8004884719848633, 0.5642148852348328, -0.31098270416259766, 0.13649845123291016, -0.2788625955581665, -1.4418164491653442, -0.6671972274780273, -0.9441410899162292, 0.4000336527824402, -0.40246492624282837, -0.1859852820634842, 0.9731348156929016, 0.44452494382858276, -1.3840004205703735, 0.9142916202545166, -0.2891598641872406, -0.07201969623565674, 0.7345241904258728, 0.5530548095703125, 0.28572070598602295, -0.27945372462272644, -1.274051308631897, 0.8035888671875, 0.4570082128047943, -0.7154368758201599, -0.25096768140792847, -0.5827498435974121, -0.917967677116394, 0.07530329376459122, 0.026491159573197365, -0.4406583607196808, 1.19852876663208, 0.052160147577524185, -0.7815582156181335, 0.40313151478767395, -0.12329024076461792, 0.12014980614185333, 0.09918864071369171, -0.12566982209682465, -0.6144713163375854, -0.5103343725204468, -0.16112549602985382, 0.4262917935848236, 0.3880006670951843, -0.4811481535434723, 0.03498833626508713, 0.16556745767593384, -0.7198938727378845, 0.04769282042980194, -0.4875860810279846, 0.4185498058795929, -0.10045678913593292, -0.6927457451820374, 0.36742135882377625, 0.5554308891296387, 0.19167914986610413, -0.19091638922691345, -0.47044089436531067, -1.0362238883972168, 0.5179693102836609, -0.2693282663822174, 1.2233020067214966, -0.8424577116966248, -0.7811187505722046, 0.29068246483802795, -0.16980895400047302, 0.027972666546702385, -0.6772147417068481, 0.5352299809455872, -0.15122392773628235, 0.7078801393508911, -0.18460197746753693, -1.0537160634994507, 0.1862201690673828, -0.057845860719680786, -0.6395930051803589, -0.4249579906463623, 0.06924868375062943, 0.9028276205062866, -0.6902443170547485, 0.019591528922319412, -0.00930868461728096, 0.5662320852279663, -0.5418184399604797, 1.2124505043029785, -0.0908529981970787, -0.21305274963378906, -0.11288774013519287, -0.1906665414571762, 0.3493019640445709, -0.47860443592071533, 0.3351627588272095, -0.13251227140426636, 0.13499411940574646, 0.6107010841369629, -0.10907934606075287, 1.0982455015182495, -0.3769844174385071, 0.6664042472839355, -0.17988650500774384, -0.7442653179168701, 0.162372887134552, 0.4682334363460541, -0.30654188990592957, -0.7444837093353271, 0.4543691575527191, 0.3913555145263672, -0.6607542634010315, 0.44421592354774475, 0.8520037531852722, 0.6319672465324402, -0.34066468477249146, 0.2923542261123657, 0.6761223673820496, -0.2985762357711792, 0.4439363181591034, 0.25453051924705505, 0.6043727993965149, -0.028893789276480675, 0.14288632571697235, -0.42576298117637634, 0.03303186222910881, -1.040156364440918, -0.3444361388683319, 0.6079196929931641, 0.6060126423835754, 0.43866196274757385, 0.028598589822649956, -0.7827029228210449, -0.5166265368461609, -0.7210841774940491, 0.4859015941619873, 1.13752281665802, -0.05538817122578621, -0.3169873058795929, -0.7228860855102539, -0.1737559735774994, -0.4321528375148773, 0.18107900023460388, -0.3069514334201813, -0.365041583776474, -0.3699760138988495, -0.90397709608078, 0.8955563306808472, 0.39815160632133484, 1.2949566841125488, -0.2758852541446686, -0.15506045520305634, -0.4086243808269501, 0.19788174331188202, -0.6185687780380249, -0.7976149916648865, 0.5821040272712708, -0.5941776037216187, 0.18846911191940308, 0.09770726412534714, -0.21907968819141388, -0.028736747801303864, -0.845989465713501, 0.7908124327659607, -0.11051025986671448, -0.023466816172003746, 0.10400053858757019, 0.759873628616333, -0.5744564533233643, -0.7916160225868225, 0.2096817046403885, 0.4405665993690491, -0.30009958148002625, 0.21551229059696198, 0.42111465334892273, -0.18035657703876495, -0.1031399741768837, -0.37941113114356995, -0.0730900838971138, 0.4064689874649048, 0.1332005113363266, 0.4431169629096985, -0.29024654626846313, -0.04878171533346176, -0.4207631051540375, 1.2295727729797363, 0.5118679404258728, -0.36164894700050354, 0.6530499458312988, -0.9670528173446655, 0.1944083571434021, 0.2414199411869049, -0.591333270072937, 0.024703018367290497, -1.1689318418502808, 0.4836157262325287, -0.4898231029510498, 0.31643450260162354, 0.10283356159925461, 0.4040108323097229, -0.12531086802482605, -0.09418705105781555, 0.7467969059944153, 0.4423965811729431, 0.15420185029506683, 0.22217148542404175, -0.8074745535850525, 0.2103954553604126, 0.2508968710899353, 0.15838617086410522, -0.457908034324646, -0.18159782886505127, -0.5667046904563904, -0.2627825438976288, 0.22062331438064575, 0.2892252504825592, -0.34116408228874207, 0.32264283299446106, -0.3511104881763458, -1.0207823514938354, 0.03897637873888016, -0.7887423038482666, -0.18631482124328613, 0.12241605669260025, -0.13135649263858795, -0.3348308801651001, -1.3690913915634155, -1.7628676891326904, -0.9677993059158325, -0.7668352723121643, -1.0434787273406982, -0.12898869812488556, 0.026376469060778618, -0.2650018036365509, -0.4660917818546295, -0.19537752866744995, -0.519296407699585, 1.5346183776855469, -1.0514384508132935, 0.9665486216545105, -0.17548848688602448, -0.5419297218322754, 0.029021264985203743, 0.23229512572288513, 0.6612341403961182, -0.36751171946525574, 0.07202774286270142, -1.0104676485061646, 0.12513425946235657, -0.5701285600662231, -0.2994406223297119, 0.355648934841156, 0.4782666563987732, 0.8056713938713074, -0.23694062232971191, -0.3042231798171997, 0.056528039276599884, 1.4523359537124634, -0.286253958940506, 0.17817161977291107, 0.18029943108558655, 0.8155426383018494, 0.12822479009628296, -0.594965398311615, 0.29385119676589966, 0.3395211696624756, 0.26393792033195496, -0.06124955415725708, 0.17927926778793335, -0.08883906155824661, -0.7572015523910522, -0.045360106974840164, 1.937019944190979, 0.16996678709983826, -0.2990014851093292, -0.907961905002594, 0.5107095837593079, -1.09380042552948, -0.766684353351593, 1.2659028768539429, 1.0752917528152466, -0.11662058532238007, -0.34384649991989136, -0.4435274302959442, 0.25188568234443665, 0.5759809613227844, 0.4964241683483124, -0.09818045049905777, -0.6746078133583069, -0.008062249980866909, 0.7499475479125977, 0.5433573126792908, 0.6203820109367371, -0.43057364225387573, 0.6067654490470886, 15.18132209777832, 1.1248061656951904, -0.05659712478518486, 0.6867832541465759, 0.680992841720581, 0.3087855279445648, -0.5656018257141113, -0.17384351789951324, -0.5386178493499756, 0.10785719007253647, 1.271721363067627, 0.25347891449928284, 0.8988157510757446, -0.21041983366012573, -0.3867715001106262, 0.5237410068511963, -0.2292546182870865, 0.6762404441833496, 0.42802244424819946, -1.403119444847107, 0.7171503305435181, 0.3444894552230835, 0.33591386675834656, 0.5081301927566528, 1.093965768814087, 0.6694965362548828, 0.5630720257759094, -0.497675359249115, 0.7006540894508362, 0.09838292747735977, 0.783782958984375, -0.2832123041152954, 0.1079893559217453, -0.05077998712658882, -0.9951494932174683, -0.19437479972839355, -0.29342183470726013, -0.7189365029335022, 0.11888252198696136, 0.0903848186135292, -0.16788502037525177, -0.5125439167022705, -0.0784824937582016, 0.13827279210090637, 0.4614602327346802, 0.4428570866584778, -0.27041080594062805, 0.6119222640991211, -0.23677000403404236, -0.18065012991428375, 0.24233265221118927, 0.6650398373603821, -0.026304354891180992, -0.39883965253829956, 0.4108521640300751, -0.13475629687309265, 0.14062991738319397, 0.16946232318878174, -0.7595066428184509, 0.029219459742307663, -0.2792941629886627, -0.4762749969959259, 0.31901970505714417, 0.3229527473449707, 0.3652631640434265, 0.22505007684230804, -0.0885239690542221, 0.29938045144081116, 0.7321524620056152, 0.2520604729652405, -0.07802600413560867, -0.10313689708709717, 0.7502185702323914, -0.1908789575099945, -0.0877787247300148, 0.5752670168876648, -0.23252005875110626, -0.3575637638568878, -0.5090922117233276, -0.110231913626194, 0.2061195820569992, -0.9506523013114929, -0.738124430179596, 1.1947836875915527, -0.3168739974498749, -0.1728605031967163, 0.5325092077255249, -0.7357844710350037, -0.2135610282421112, 0.26461106538772583, -1.2370104789733887, -0.6300013065338135, 0.5114330053329468, -0.1384773552417755, -0.5259995460510254, -0.07753991335630417, 1.268211007118225, 0.1332201063632965, 0.010972744785249233, 0.2760290205478668, 0.07614696025848389, 0.21105311810970306, -0.32539111375808716, -0.6677953600883484, 0.7177523374557495, -0.03516453504562378, -0.056897424161434174, 0.3798324465751648, 0.2861787974834442, 0.3021581768989563, -0.5054301023483276, 0.05568347126245499, 1.004652976989746, -0.749305784702301, -0.3348466753959656, -0.5999255180358887, -0.8744029998779297, 0.269115149974823, 0.6371726393699646, -0.3666456341743469, 0.2526531517505646, 0.21188896894454956, -0.87929767370224, -0.26490315794944763, -0.6695411205291748, 0.03853989019989967, 0.46913623809814453, -1.248433232307434, -0.3023148775100708, -0.10236407816410065, -0.038371678441762924, -0.7218008637428284, -0.3973686695098877, -0.1419443041086197, 0.13074539601802826, 0.022069593891501427, 0.6935364007949829, -0.37352055311203003, 0.6298761367797852, 0.8443245887756348, -0.26463502645492554, -0.9337282776832581, -0.16486799716949463, -0.5689415335655212, 0.28110551834106445, -0.12553712725639343, 0.6816509366035461, -0.6738183498382568, 0.19860708713531494, 0.927774965763092, 0.1551668643951416, -0.5357690453529358, -0.9118475317955017, -0.32569822669029236, 0.10876226425170898, -0.6201043128967285, 0.40635305643081665, 0.13409313559532166, 0.0901542529463768, -0.16543474793434143, 0.38233909010887146, 0.5596878528594971, -0.11415039747953415, -0.845555305480957, -0.6026605367660522, -0.3125966191291809, 0.15604400634765625, -0.8910542130470276, -0.7614462375640869, -1.1123361587524414, 0.21870574355125427, -1.2025189399719238, -0.0025207872968167067, -0.7893308997154236, -0.26961880922317505, -0.3143778145313263, -0.6602024435997009, 0.020049775019288063, 0.4816739559173584, -0.19196723401546478, -0.21655577421188354, -0.3857267200946808, -0.4649154245853424, 0.806464433670044, 0.5489832758903503, -0.8337643146514893, 0.2572481334209442, -0.4949333369731903, 0.16563516855239868, -0.12284360080957413, 0.5586570501327515, -0.4497618079185486, -0.8333110809326172, -1.3659785985946655, 0.21168933808803558, -0.150575190782547, -0.3364529609680176, -0.7693606615066528, 0.805441677570343, 0.7884379029273987, -0.05644944682717323, 0.3105957806110382, 0.5877386331558228, -0.7691985964775085, -0.5517918467521667, 0.5620299577713013, -1.0301258563995361, 0.6513932943344116, 0.19027328491210938, -0.5340114235877991, -0.3501906096935272, 0.933029294013977, -0.04996970668435097, -0.8828262090682983, -0.41334742307662964, 0.7192831039428711, -1.0376992225646973, 0.267326682806015, -0.2370823621749878, -0.055227130651474, -1.1065961122512817, -0.43135276436805725, -0.34839215874671936, 0.39957207441329956, -0.4241327941417694, 1.0383557081222534, 0.47183549404144287, -1.379884958267212, 0.2693498134613037, 0.6056475639343262, -0.09298639744520187, -0.5641286969184875, 0.47311365604400635, 0.23987098038196564, -0.1851760447025299, 0.439191073179245, 0.21360965073108673, 0.2824549674987793, -0.9411585330963135, -0.10685539990663528, 0.77183598279953, -0.4910190999507904, 0.2163621336221695, 1.0582311153411865, -0.2991504371166229, -1.0692161321640015, 0.04841232672333717, -0.9082769155502319, -0.25248411297798157, -0.5742147564888, 0.4103068709373474, -0.07275556027889252, -0.07615385949611664, 0.081051766872406, -0.3699670732021332, 0.27712225914001465, -0.2542576193809509, -0.6870979070663452, 0.01041516475379467, -0.1027575209736824, -0.08310025185346603, 0.5005189776420593, 0.5775734782218933, -1.0817546844482422, -0.5827019214630127, -0.6061046719551086, -0.40842074155807495, -0.2066660076379776, 0.43508076667785645, -0.07957560569047928, -0.9176154732704163, 0.9284326434135437, 1.0472698211669922, 0.3903701603412628, 0.0022583857644349337, -0.08788282424211502, 0.030338386073708534, 0.3121735155582428, 0.36224365234375, -0.7301642298698425, -0.5523162484169006, 1.265654444694519, 0.7951328754425049, -0.43643978238105774, -0.045598071068525314, 0.10402754694223404, -0.6065359711647034, 0.6404038667678833, 0.20224343240261078, -0.031644441187381744, 1.1010326147079468, -0.02137010172009468, 0.2883242666721344, 0.027677731588482857, -1.006614089012146, -0.23110628128051758, 0.6633764505386353, 0.8221095204353333, 0.6306020617485046, 0.5813635587692261, 0.026400204747915268, 0.6244350671768188, 0.01081206277012825, -0.08113885670900345, 0.11338584125041962, 0.6864749193191528, -0.2856171131134033, -0.13316713273525238, 0.16573473811149597, 0.7103573083877563, -0.8380545973777771, -0.9708074331283569, 0.1973453313112259, 0.7137756943702698, -0.11977486312389374, 0.583939790725708, 1.0841219425201416, -0.5226255655288696, 0.3248612582683563, 0.47988855838775635, 0.7633733153343201, 0.2645215392112732, -0.4217994213104248, -0.4555909335613251, -0.543350875377655, 0.18809738755226135, -0.23869968950748444, -0.3701634705066681, -0.23976469039916992, -0.670045793056488, 0.038800474256277084, 0.4739176034927368, 0.3468693792819977, 1.0067167282104492, 0.5030463933944702, 0.4096069633960724, -0.2511885464191437, -0.45774778723716736, -0.47419244050979614, -0.8141241669654846, -0.019706696271896362, -0.5092602968215942, -0.1269398182630539, -0.16038361191749573, -0.11001969873905182, -0.8190116882324219]}, "authors": [{"authorId": "145822914", "name": "Xueyan Niu"}, {"authorId": "2274936370", "name": "Bo Bai"}, {"authorId": "2247982803", "name": "Lei Deng"}, {"authorId": "2153819102", "name": "Wei Han"}], "references": [{"paperId": "3fd5bc3077d04965eaa3498372c39bbdd09d55e4", "title": "Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention"}, {"paperId": "49873ee415619efd9e1e4c16f73ee066ff008c1f", "title": "MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies"}, {"paperId": "e61fde1309a9f5aab2060ace6f709711823c9ca5", "title": "Understanding Emergent Abilities of Language Models from the Loss Perspective"}, {"paperId": "e1446fc9b11e73e9f1d867df9012fdc3d3df60d0", "title": "RAGGED: Towards Informed Design of Retrieval Augmented Generation Systems"}, {"paperId": "98755a7ca75afbb29a19f8129b9f25796ad0e0b7", "title": "Language models scale reliably with over-training and on downstream tasks"}, {"paperId": "a3dd3adc37cdb8991936f3feb109c20b6f892f3d", "title": "Extending Context Window of Large Language Models via Semantic Compression"}, {"paperId": "db633c6b1c286c0386f0078d8a2e6224e03a6227", "title": "Mistral 7B"}, {"paperId": "5e0cb1c4b91a7486e1c2b15a44a0be56bd74bdc0", "title": "Effective Long-Context Scaling of Foundation Models"}, {"paperId": "c96297261467b5daa2d01227496a70d444602434", "title": "Baichuan 2: Open Large-scale Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "6001a5d38df9a043421a670357842d8df71d656b", "title": "Grokking of Hierarchical Structure in Vanilla Transformers"}, {"paperId": "9e16d8cc6096ec0d2733a4ecf41ce09d9a4bd19c", "title": "Scaling Data-Constrained Language Models"}, {"paperId": "b6d6c33298b852cf63edac233deca70530d69a2a", "title": "PaLM 2 Technical Report"}, {"paperId": "12d16f426edc6ab248fb476007bd1646282d4d68", "title": "Language Model Behavior: A Comprehensive Survey"}, {"paperId": "8b293973061026d9d0eed90e71e30928e029171e", "title": "Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "a1d1983a7b19845141e6505bd32dc395e5a136ba", "title": "Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "18e736f814c6d64a27dc9ff088fb288bcac39002", "title": "Word Acquisition in Neural Language Models"}, {"paperId": "3c5edd9eb4dcf4a0cff3250b32ede349c2edf63e", "title": "Hierarchical Associative Memory"}, {"paperId": "4a54d58a4b20e4f3af25cea3c188a12082a95e02", "title": "Transformer Feed-Forward Layers Are Key-Value Memories"}, {"paperId": "804a6d7c23335bbca6eec3b7d3c8366dcbe395a5", "title": "Hopfield Networks is All You Need"}, {"paperId": "9e949c47d558dd8a5b5d9d67a8789723ed061e0f", "title": "Triple descent and the two kinds of overfitting: where and why do they appear?"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "b0ea633e0c22fbd8cbc531c7326376725d16ce25", "title": "Does Syntax Need to Grow on Trees? Sources of Hierarchical Inductive Bias in Sequence-to-Sequence Networks"}, {"paperId": "97cd86d8d8c0f27cd3e64c6ca5cfdeb957ee39f4", "title": "Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One"}, {"paperId": "ea415809bf87ef4b99966c6c50de6cb996a02a97", "title": "Deep double descent: where bigger models and more data hurt"}, {"paperId": "7be8c119dbe065c52125ee7716601751f3116844", "title": "Generalization through Memorization: Nearest Neighbor Language Models"}, {"paperId": "830995ef17cc291c13f42dfd9f462137de1d2179", "title": "Augmenting Self-attention with Persistent Memory"}, {"paperId": "f86f1748d1b6d22870f4347fd5d65314ba800583", "title": "Reconciling modern machine-learning practice and the classical bias\u2013variance trade-off"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "84bad036fbe21a024975cefa71785930fdec758e", "title": "On a Model of Associative Memory with Huge Storage Capacity"}, {"paperId": "37a67228271527037c9250ae3fd220199275e42e", "title": "Majorization-Minimization Algorithms in Signal Processing, Communications, and Machine Learning"}, {"paperId": "63e39cdf1ad884da6bc69096bb3413b5b1100559", "title": "Using the Output Embedding to Improve Language Models"}, {"paperId": "ed332c92664cd64843a7ba9373d992e9547230f6", "title": "Dense Associative Memory for Pattern Recognition"}, {"paperId": "6303aeaabb4d341d059b4f31d40d106604920c6b", "title": "Iterative Solution of Nonlinear Equations in Several Variables"}, {"paperId": "98b4d4e24aab57ab4e1124ff8106909050645cfa", "title": "Neural networks and physical systems with emergent collective computational abilities."}, {"paperId": "419c4635a6bcae1302f03681498de4ce16074e21", "title": "Learning Patterns and Pattern Sequences by Self-Organizing Nets of Threshold Elements"}, {"paperId": "bb0656031cb17adf6bac5fd0fe8d53dd9c291508", "title": "An empirical analysis of compute-optimal large language model training"}, {"paperId": null, "title": "Openwebtext corpus"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "7fc604e1a3e45cd2d2742f96d62741930a363efa", "title": "A Tutorial on Energy-Based Learning"}, {"paperId": null, "title": "Acknowledgments The author thanks Dr. Yongqi Xu for stimulating discussions and practical assistance with the experiments"}, {"paperId": null, "title": "Gemma: Introducing new state-of-the-art open models, 2024"}]}