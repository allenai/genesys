{"paperId": "6e33594cb0af7def21d805046be3957ab9461cf4", "title": "Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation", "abstract": "The advent of scalable deep models and large datasets has improved the performance of Neural Machine Translation (NMT). Knowledge Distillation (KD) enhances efficiency by transferring knowledge from a teacher model to a more compact student model. However, KD approaches to Transformer architecture often rely on heuristics, particularly when deciding which teacher layers to distill from. In this paper, we introduce the \u201cAlign-to-Distill\u201d (A2D) strategy, designed to address the feature mapping problem by adaptively aligning student attention heads with their teacher counterparts during training. The Attention Alignment Module (AAM) in A2D performs a dense head-by-head comparison between student and teacher attention heads across layers, turning the combinatorial mapping heuristics into a learning problem. Our experiments show the efficacy of A2D, demonstrating gains of up to +3.61 and +0.63 BLEU points for WMT-2022 De\u2192Dsb and WMT-2014 En\u2192De, respectively, compared to Transformer baselines.The code and data are available at https://github.com/ncsoft/Align-to-Distill.", "venue": "International Conference on Language Resources and Evaluation", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The \u201cAlign-to-Distill\u201d (A2D) strategy, designed to address the feature mapping problem by adaptively aligning student attention heads with their teacher counterparts during training, is introduced."}, "embedding": {"model": "specter_v2", "vector": [-0.053084488958120346, 0.9233865141868591, -0.6151778697967529, 0.11381535232067108, -0.2936840355396271, -0.5727323293685913, 1.107904314994812, -0.21387508511543274, -0.29524046182632446, 0.08487973362207413, 0.5347182750701904, -0.4865102767944336, 0.15890443325042725, 0.06664930284023285, -0.14135996997356415, 0.007241433020681143, -0.13251139223575592, 0.8657543659210205, -0.23488697409629822, -0.33657965064048767, -0.33036601543426514, -0.7714925408363342, -0.5109784007072449, -0.358571320772171, 0.6151341199874878, 0.6325398683547974, 0.27854594588279724, 0.5597620606422424, -0.7689310312271118, 0.11225275695323944, 0.48621535301208496, -0.5387603044509888, 0.6538172960281372, -0.27752918004989624, -0.7468982338905334, -0.23805750906467438, 0.5453096032142639, -0.5646504759788513, -0.39617377519607544, 0.9626771211624146, 0.10104767978191376, 0.08462786674499512, 0.46114346385002136, -0.7010950446128845, -0.4605729579925537, 0.6851390600204468, 0.5373323559761047, 0.8865417838096619, -0.40486520528793335, -0.4393925070762634, 0.8441794514656067, -1.1945234537124634, 0.1105460599064827, 1.0649101734161377, 0.35474154353141785, 0.34966832399368286, -0.11667779833078384, -0.49546560645103455, 0.5274313688278198, 0.3651612401008606, -0.6762898564338684, -0.11841098964214325, -0.07053937762975693, -0.23179388046264648, 1.4775762557983398, -0.5052831172943115, 0.3544465899467468, 0.43262994289398193, -0.429126501083374, 1.4776015281677246, 0.18349121510982513, -0.9148411750793457, -0.3434465527534485, 0.24214637279510498, 0.32417306303977966, 0.9397204518318176, -0.33696290850639343, 0.1629161536693573, -0.6921577453613281, 0.015539299696683884, 0.44888052344322205, -0.28874820470809937, 0.03936413675546646, -0.24167189002037048, -0.31779977679252625, 0.6657702326774597, 0.38828909397125244, 0.734051525592804, -0.5171564221382141, 0.5485813617706299, 0.2793324589729309, 0.6810705661773682, 0.06323347985744476, 0.5471113324165344, -0.5157425403594971, 0.5642823576927185, -1.0876482725143433, 0.06346358358860016, -0.13865482807159424, 0.8896011710166931, 0.11219855397939682, 0.3066495358943939, -0.8976232409477234, -0.005373771768063307, 1.0188945531845093, 0.0537312775850296, 0.7826398015022278, -0.9428833723068237, 0.08719199895858765, -0.5812718272209167, -0.19469264149665833, -0.6919645667076111, 0.035682253539562225, -0.41912463307380676, -0.631358802318573, -1.23928701877594, -0.6970694661140442, 0.07468441873788834, -0.8379567861557007, 0.9184564352035522, -0.06088816747069359, 0.4641555845737457, -0.18577657639980316, 0.5704847574234009, 0.46126821637153625, 0.36519524455070496, -0.1013033539056778, 0.1037660762667656, 0.8666108846664429, -1.0149227380752563, -0.6181923151016235, -0.9622869491577148, 0.6350665092468262, -0.4145030379295349, 0.07103482633829117, -0.17057117819786072, -1.4852619171142578, -0.9735725522041321, -0.8895407915115356, -0.26153239607810974, -0.5016707181930542, 0.14850419759750366, 0.6871424317359924, 0.3132396340370178, -1.1241964101791382, 0.6169207096099854, -0.21601663529872894, -0.16406044363975525, 0.3909350633621216, 0.18821202218532562, 0.20041221380233765, -0.4621696472167969, -1.1781959533691406, 0.9011605978012085, 0.49829792976379395, -0.43668925762176514, -0.34090930223464966, -0.8583549857139587, -0.7467897534370422, -0.07451921701431274, 0.22311177849769592, -1.1562385559082031, 1.5757265090942383, -0.3714011311531067, -1.3351234197616577, 0.6759858727455139, -0.11904241144657135, 0.18060950934886932, 0.4877394735813141, -0.23876626789569855, -0.2040078490972519, -0.5852877497673035, 0.018085753545165062, 0.8021199703216553, 0.11546838283538818, 0.2181088924407959, -0.02669672667980194, 0.3836519718170166, -0.2632286250591278, 0.04922106862068176, -0.4861232042312622, 0.615180492401123, -0.399932324886322, -0.19382347166538239, 0.449668288230896, 0.7818734049797058, 0.06277570128440857, -0.17590075731277466, -0.6917614340782166, -0.9156497120857239, 0.7305784225463867, -0.18014325201511383, 0.5347101092338562, -0.42227891087532043, -0.200700581073761, -0.20260180532932281, 0.3344633877277374, -0.055531393736600876, -0.8170427083969116, 0.05542578548192978, -0.3866257667541504, 0.05968175083398819, -0.12175176292657852, -0.9407569766044617, 0.33165839314460754, -0.21220038831233978, -0.5060406923294067, -0.3738294839859009, 0.17533577978610992, 1.2727947235107422, -0.666713297367096, 0.0704067125916481, 0.015747711062431335, 0.26908332109451294, -1.2341465950012207, 1.3531076908111572, -0.3861570656299591, 0.609306812286377, -0.3670603632926941, -0.22575992345809937, 0.2790622115135193, -0.334695041179657, 0.26502525806427, -0.38366425037384033, 0.03830903023481369, 0.8835681676864624, -0.2053220272064209, 1.8653498888015747, -0.25497037172317505, 0.6978228688240051, 0.027608774602413177, -1.2266565561294556, 0.6232144236564636, 0.42794522643089294, -0.19108527898788452, -0.5820524096488953, 0.3785974979400635, 0.9217366576194763, -0.35036811232566833, 0.029328731819987297, 0.7621792554855347, 0.6321561336517334, -0.31674760580062866, -0.018744071945548058, 0.7350028157234192, -0.41055065393447876, 0.11941753327846527, 0.2600243091583252, 0.6187140941619873, 0.38714346289634705, 0.4421508312225342, -0.25449138879776, 0.1961601823568344, -0.48633602261543274, -0.21048001945018768, 0.24293160438537598, 0.7468538284301758, 0.5193319916725159, 0.22725152969360352, -1.1221017837524414, -0.24111680686473846, -0.043702684342861176, 0.8047860264778137, 1.0010347366333008, -0.24499419331550598, 0.09594420343637466, -0.8778433203697205, -0.641226589679718, -0.3516857624053955, 0.31723928451538086, -0.2763929069042206, -0.3894439935684204, -0.7373586297035217, -0.8757801055908203, 0.5936746597290039, 0.08379911631345749, 1.4592658281326294, 0.07261799275875092, -0.14611774682998657, -0.35575297474861145, -0.22012227773666382, -0.8184184432029724, -0.39858224987983704, 0.46620264649391174, -0.18115021288394928, -0.11070108413696289, -0.33777183294296265, -0.36958956718444824, 0.1872929036617279, -0.5487480759620667, 1.3195593357086182, -0.45972418785095215, -0.04503089562058449, 0.04151477292180061, 0.7398037314414978, -0.4896058738231659, -0.5564234852790833, 0.45729562640190125, 0.41151320934295654, -0.4563014507293701, 0.4654269814491272, 0.369390070438385, -0.3353649079799652, -0.026286209002137184, -0.19631464779376984, 0.5018823742866516, -0.12487119436264038, -0.07610183209180832, 0.755258321762085, -0.62607342004776, 0.10140697658061981, -0.754304051399231, 0.7337309122085571, -0.22031642496585846, -0.5605548024177551, 0.24604620039463043, -0.7913921475410461, -0.32439589500427246, 0.3637022376060486, -0.4035131335258484, 0.11115461587905884, -1.1471459865570068, 0.26382526755332947, -0.5628703236579895, -0.17390306293964386, 0.23419277369976044, 0.28846877813339233, 0.25967416167259216, 0.1284460872411728, 0.38120415806770325, 0.1522093564271927, -0.3075527846813202, 1.1274068355560303, -0.8528251647949219, 0.7033491134643555, 0.07773035019636154, 0.07105622440576553, -0.5926561951637268, -0.05910932645201683, -0.0031669638119637966, -0.6298466324806213, 0.4399665892124176, -0.3789535164833069, -0.09295352548360825, 0.44320109486579895, -0.6846417188644409, -0.23992258310317993, -0.175960972905159, -1.277490258216858, -0.383267343044281, -0.23499444127082825, -0.14200414717197418, -0.4851055443286896, -1.2907718420028687, -0.9625783562660217, 0.34126436710357666, -0.46761149168014526, -1.381626844406128, 0.08811948448419571, 0.29146724939346313, -0.47830700874328613, -0.706367015838623, 0.12514467537403107, -0.257837176322937, 1.2280255556106567, -0.7824717164039612, 1.0940216779708862, -0.3955650329589844, -0.3910844624042511, -0.06578146666288376, 0.19778724014759064, 0.3609411418437958, -0.025374239310622215, -0.024854330345988274, -0.8398469686508179, 0.38868287205696106, -0.5075613856315613, -0.6710377931594849, -0.020549947395920753, 0.4890512526035309, 0.49368929862976074, -0.17835712432861328, -0.43801894783973694, 0.5360042452812195, 0.9637746810913086, -0.9875199198722839, -0.04682878404855728, 0.6103487014770508, 1.0257353782653809, 0.11836733669042587, -0.46943020820617676, 0.07379412651062012, 0.8122173547744751, 0.7936604619026184, 0.1009940430521965, -0.36003804206848145, -0.6955791711807251, -0.5759760141372681, 0.19879677891731262, 1.894363284111023, 0.4493921101093292, 0.2498101443052292, -1.0931422710418701, 0.39371341466903687, -1.1162067651748657, -0.1672045737504959, 0.678623378276825, 0.5968650579452515, 0.6755892634391785, -0.630073070526123, -0.4159204959869385, -0.5273805260658264, 0.3915391266345978, -0.07885605841875076, -0.2762357294559479, -0.6867625117301941, 0.130344957113266, 0.6316878795623779, 0.017022280022501945, 0.7337921857833862, 0.14925450086593628, 0.8354803323745728, 14.925484657287598, 1.0770639181137085, -0.22294509410858154, 0.9718077778816223, 0.7874173521995544, -0.09670700132846832, -0.5554361939430237, -0.13772159814834595, -0.9790002703666687, 0.025275489315390587, 1.030575156211853, 0.03392599895596504, 0.44000059366226196, 0.03292045369744301, -0.04167597368359566, 0.4275314211845398, -0.6867466568946838, 0.5886761546134949, 0.43493714928627014, -1.455783724784851, 0.5878695249557495, 0.19533300399780273, 0.7720668315887451, 0.5001457929611206, 0.8553937673568726, 1.0309478044509888, 0.5893183946609497, -0.4864221215248108, 0.542312741279602, 0.36492711305618286, 0.7363024353981018, 0.07607722282409668, 0.3147786557674408, 0.4035264849662781, -0.6375757455825806, 0.17027553915977478, -0.4692858159542084, -0.9887338876724243, 0.3647094964981079, 0.2264183759689331, -0.36032557487487793, -0.25488516688346863, -0.4364672899246216, 0.38620027899742126, 0.35164201259613037, 0.3451464772224426, -0.3863033354282379, 0.46528565883636475, -0.16895851492881775, 0.3844844102859497, 0.35435351729393005, 0.3370126187801361, 0.13684795796871185, -0.15089358389377594, 0.45873093605041504, -0.2092602401971817, 0.3213564157485962, 0.7838600277900696, -0.8358702063560486, -0.28518643975257874, -0.37899917364120483, -0.009742194786667824, 0.3816036283969879, 0.6276860237121582, 0.5604711771011353, -0.04578651487827301, -0.3134538531303406, 0.6414696574211121, 0.6992267966270447, 0.06914127618074417, -0.3020131587982178, 0.008292893879115582, 0.531944215297699, -0.36837923526763916, -0.20877566933631897, 0.49759581685066223, -0.16245701909065247, -0.3130895793437958, -0.7868260145187378, -0.7225400805473328, 0.22505348920822144, -1.0323785543441772, -0.49864134192466736, 1.0410434007644653, -0.35710084438323975, -0.4840869605541229, 0.07250574976205826, -0.577706515789032, -0.20865924656391144, 0.7285134196281433, -1.9158574342727661, -0.6573275327682495, 0.21425120532512665, -0.1301073133945465, -0.22013117372989655, -0.3840599060058594, 1.3198068141937256, 0.42155686020851135, -0.3427238166332245, 0.12645362317562103, -0.006712219677865505, -0.19236552715301514, -0.014451789669692516, -0.829006016254425, 1.0320661067962646, 0.0633058026432991, -0.049478694796562195, -0.04145468398928642, -0.09682890772819519, 0.2636362910270691, -0.6520028114318848, -0.011377936229109764, 0.5394519567489624, -0.9412907958030701, -0.39657431840896606, -0.16066642105579376, -0.5097721219062805, 0.5304323434829712, 1.0243356227874756, -0.18246759474277496, 0.49200189113616943, -0.07273941487073898, -0.7709934115409851, 0.26851534843444824, -1.0172159671783447, 0.15291300415992737, 0.14881844818592072, -0.6195754408836365, -0.42907941341400146, 0.010897374711930752, 0.5993191003799438, -1.186117172241211, -0.5198420286178589, -0.31737080216407776, -0.08434782177209854, 0.1709628403186798, 1.0082589387893677, -0.6198122501373291, 0.6628172993659973, 0.8859509825706482, -0.15670667588710785, -1.1987756490707397, -0.1280672550201416, -1.0102094411849976, -0.05478935316205025, 0.24521878361701965, 0.660667359828949, -0.4194536805152893, 0.27630120515823364, 0.893895149230957, 0.033954083919525146, -0.4415740966796875, -0.5862956643104553, -0.2814527153968811, 0.5419383645057678, -0.2607787847518921, 0.6916109919548035, 0.6609839797019958, -0.10766182094812393, 0.2602148950099945, 0.507093071937561, 0.40646785497665405, -0.4184221029281616, -0.9097626209259033, 0.41940543055534363, -0.17754089832305908, -0.24186009168624878, -1.0082132816314697, -0.6811956763267517, -1.9115216732025146, -0.017763497307896614, -1.657373309135437, -0.28728628158569336, -1.2982650995254517, -0.24684123694896698, -0.11365144699811935, -0.18774062395095825, 0.25504744052886963, 0.20942971110343933, -0.2829414904117584, -0.4800862967967987, -0.5595859289169312, -0.1328437626361847, 1.1458879709243774, 0.9626160860061646, -0.7010886073112488, 0.3711481988430023, -0.5647204518318176, -0.23810575902462006, 0.34828418493270874, 0.3500906229019165, -0.31850048899650574, -0.7736411094665527, -1.9333919286727905, 0.30251431465148926, -0.2212020605802536, -0.1393088847398758, -0.45365646481513977, 0.6613672971725464, 0.554470956325531, -0.17382122576236725, 0.23960839211940765, 0.3546367883682251, -0.9761480093002319, -0.6563554406166077, 0.30478742718696594, -0.6628802418708801, 0.3789631128311157, 0.5481608510017395, -0.9075126051902771, -0.09446138143539429, 0.5722512602806091, -0.19221055507659912, -0.891809344291687, -0.6066391468048096, 0.33512410521507263, -0.4746103286743164, 0.2954889237880707, -0.5269320011138916, -0.18270352482795715, -1.5094510316848755, -0.32367199659347534, 0.12230677157640457, 0.5085409283638, -0.5636425614356995, 0.5795577168464661, -0.13919854164123535, -1.541393756866455, -0.05248507112264633, 0.31362998485565186, -0.2861798107624054, 0.00029664571047760546, 0.16335009038448334, 0.7991127967834473, -0.3521631956100464, 0.335020512342453, 0.009156221523880959, 0.38521018624305725, -0.23270484805107117, -0.14370295405387878, 0.8823868036270142, -0.4242492914199829, -0.15795250236988068, 1.1614054441452026, -0.622463047504425, -1.370485544204712, 0.013387251645326614, -0.851999819278717, -0.0711398497223854, -0.3478323221206665, 0.49634644389152527, 0.1969970315694809, 0.16494303941726685, 0.3469686508178711, -0.252187043428421, 0.24465809762477875, -0.13449518382549286, -0.42210522294044495, 0.4588867425918579, -0.2096319943666458, -0.511454164981842, 0.1068243607878685, 0.7632870078086853, -0.8976290225982666, -0.4280458092689514, -1.0448052883148193, -0.31767895817756653, -0.054317131638526917, 0.6313706040382385, -0.6000409722328186, -1.0161628723144531, 0.9518277645111084, 0.7158051133155823, 0.10737885534763336, 0.43089210987091064, 0.07762854546308517, 0.23757553100585938, 0.8010563850402832, -0.05946692079305649, -0.28678855299949646, -0.48513758182525635, 1.383878231048584, 0.8949320912361145, -0.878707766532898, 0.09938928484916687, -0.045538920909166336, -0.3844060003757477, 0.7778497338294983, 0.4035815894603729, 0.28764307498931885, 0.5369646549224854, -0.2260100245475769, 0.18224216997623444, -0.11935531347990036, -0.6515337824821472, -0.4024806022644043, 0.707457423210144, 1.1645314693450928, 0.8298448920249939, 0.2169845849275589, 0.18509049713611603, 0.8040367960929871, -0.21198269724845886, 0.1798061728477478, 0.2456035315990448, 0.3675641715526581, -0.33346986770629883, -0.18978524208068848, 0.15114715695381165, 0.3997003138065338, -0.2744028568267822, -0.8673644065856934, -0.16123007237911224, 0.577329158782959, 0.24838009476661682, 0.4721832871437073, 0.892524778842926, 0.10863649845123291, 0.53704833984375, 0.3434126675128937, 0.8130000233650208, -0.22028906643390656, -0.1854495406150818, -0.31073620915412903, -0.6459538340568542, 0.04944983869791031, -0.16645626723766327, -0.21553988754749298, -0.35582399368286133, -0.5262485146522522, 0.26378563046455383, 0.06034131348133087, 0.46971043944358826, 1.190152883529663, 0.6984790563583374, 0.8452378511428833, -0.25400203466415405, -0.3558541536331177, -0.2983490228652954, -0.8523779511451721, 0.43751952052116394, -0.8681919574737549, -0.2495022565126419, -0.2819214463233948, 0.13306677341461182, -0.44789865612983704]}, "authors": [{"authorId": "2290166263", "name": "Heegon Jin"}, {"authorId": "46235583", "name": "Seonil Son"}, {"authorId": "2290335834", "name": "Jemin Park"}, {"authorId": "2290002001", "name": "Youngseok Kim"}, {"authorId": "2806472", "name": "Hyungjong Noh"}, {"authorId": "2290032436", "name": "Yeonsoo Lee"}], "references": [{"paperId": "4b5e4948a572bd8d5045fdb532fa1391cb0b51eb", "title": "Dynamic Knowledge Distillation for Pre-trained Language Models"}, {"paperId": "e79957010ec7c5c221888e368624289cf301146e", "title": "Distilling Linguistic Context for Language Model Compression"}, {"paperId": "d648fe08d223c68dc7a16dbfd4bb5be3e166086d", "title": "Pay Better Attention to Attention: Head Selection in Multilingual and Multi-Domain Sequence Modeling"}, {"paperId": "926eb6dbb08791dad76e4a0468731b02a85a5bba", "title": "Selective Knowledge Distillation for Neural Machine Translation"}, {"paperId": "e339c5d31ffc7029c1f72d567ac07b4606701c72", "title": "ALP-KD: Attention-Based Layer Projection for Knowledge Distillation"}, {"paperId": "6044e943a7f7e8741431028fdbdaf63754cd8d5f", "title": "Pre-trained Summarization Distillation"}, {"paperId": "0d5a3fd61911590e887927c39e3cedd36c9c3c8c", "title": "Why Skip If You Can Combine: A Simple Knowledge Distillation Technique for Intermediate Layers"}, {"paperId": "ac6535d096fc79dde2d9ce0329e0626b79ede7f0", "title": "Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine Translation"}, {"paperId": "1728cb805a9573b59330890ba9723e73d6c3c974", "title": "Knowledge Distillation: A Survey"}, {"paperId": "7ea2a78a8d8a6327bd13aa4f2d9ace9231bd9662", "title": "Revisiting Knowledge Distillation via Label Smoothing Regularization"}, {"paperId": "2573af4e13d9a5dddb257d22cd38a600528d9a8b", "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"}, {"paperId": "c6c734e16f66fbfcefac7625cc64599e83292c1e", "title": "MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers"}, {"paperId": "f74cb4f88f0023bbc350786808ba84c1b7833cec", "title": "Self-Distillation Amplifies Regularization in Hilbert Space"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "7402b604f14b8b91c53ed6eed04af92c59636c97", "title": "Well-Read Students Learn Better: On the Importance of Pre-training Compact Models"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf", "title": "Patient Knowledge Distillation for BERT Model Compression"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "b4bfadfca9742bb3ee98a0cd322d5ce4e59a3ceb", "title": "A Call for Clarity in Reporting BLEU Scores"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "f7b032a4df721d4ed2bab97f6acd33d62477b7a5", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer"}, {"paperId": "b13e9d23983273c0c67b91ae70c55d4c3f745b8b", "title": "Learning to Translate in Real-time with Neural Machine Translation"}, {"paperId": "57a10537978600fd33dcdd48922c791609a4851a", "title": "Sequence-Level Knowledge Distillation"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "8604f376633af8b347e31d84c6150a93b11e34c2", "title": "FitNets: Hints for Thin Deep Nets"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "d770060812fb646b3846a7d398a3066145b5e3c8", "title": "Do Deep Nets Really Need to be Deep?"}, {"paperId": "30c9bb327b7f2b9f1d1e5b69b9d0c97b410948d9", "title": "Model compression"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "3c7ab18a86779b2bfbb6c1fc86e9948acfb428d4", "title": "Kullback-Leibler Divergence"}, {"paperId": "891b1dd6e081ea70ffa0120b4ed91715a0eae785", "title": "Distillation"}, {"paperId": null, "title": "2022. Online semantic parsing for latency reduction in task-oriented dialogue"}]}