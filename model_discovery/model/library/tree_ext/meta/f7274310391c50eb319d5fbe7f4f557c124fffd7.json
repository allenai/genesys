{"paperId": "f7274310391c50eb319d5fbe7f4f557c124fffd7", "title": "Addressing Order Sensitivity of In-Context Demonstration Examples in Causal Language Models", "abstract": "In-context learning has become a popular paradigm in natural language processing. However, its performance can be significantly influenced by the order of in-context demonstration examples. In this paper, we found that causal language models (CausalLMs) are more sensitive to this order compared to prefix language models (PrefixLMs). We attribute this phenomenon to the auto-regressive attention masks within CausalLMs, which restrict each token from accessing information from subsequent tokens. This results in different receptive fields for samples at different positions, thereby leading to representation disparities across positions. To tackle this challenge, we introduce an unsupervised fine-tuning method, termed the Information-Augmented and Consistency-Enhanced approach. This approach utilizes contrastive learning to align representations of in-context examples across different positions and introduces a consistency loss to ensure similar representations for inputs with different permutations. This enhances the model's predictive consistency across permutations. Experimental results on five benchmarks suggest that our proposed method can reduce the sensitivity of CausalLMs to the order of in-context examples and exhibit robust generalizability, particularly when demonstrations are sourced from a candidate pool different from that used in the training phase, or when the number of in-context examples differs from what is used during training.", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "An unsupervised fine-tuning method is introduced that can reduce the sensitivity of CausalLMs to the order of in-context examples and exhibit robust generalizability, particularly when demonstrations are sourced from a candidate pool different from that used in the training phase, or when the number of in-context examples differs from what is used during training."}, "embedding": {"model": "specter_v2", "vector": [0.07391902059316635, 0.008917594328522682, -0.23119314014911652, -0.29320618510246277, -0.27904993295669556, -0.40825676918029785, 0.9873488545417786, -0.11501114070415497, -0.7075104713439941, -0.12172524631023407, 0.8189202547073364, -0.17251648008823395, -0.008917363360524178, 0.4150334596633911, -0.450666606426239, 0.007641739211976528, -1.264937400817871, -0.07457911223173141, -0.08651390671730042, 0.029847441241145134, 0.12276354432106018, -0.5827476978302002, -1.0847947597503662, 0.7104060649871826, 0.17094115912914276, 0.1564541757106781, 0.6496391296386719, 0.9492924809455872, -0.42106857895851135, 0.4413008689880371, 0.32442522048950195, -0.11345010995864868, 0.5068603157997131, 0.13244934380054474, -0.11920857429504395, -0.4301348030567169, 0.7238312363624573, -0.6415680050849915, -0.9586831331253052, 0.4879487156867981, -0.34444448351860046, 0.5538086295127869, 0.621268093585968, -0.45572176575660706, -0.47521570324897766, 1.1355892419815063, 0.7431296706199646, 0.9763318300247192, 0.105197474360466, -0.5474351048469543, 1.5523288249969482, -1.2860771417617798, 0.29125797748565674, 1.5183967351913452, 0.23801380395889282, 0.6957130432128906, 0.036961134523153305, -0.5964751243591309, 1.2511427402496338, 0.404168039560318, -0.6726780533790588, 0.003923370502889156, 0.04885116219520569, -0.021745828911662102, 1.4956351518630981, -0.37211406230926514, 0.01762630231678486, 1.1092830896377563, -0.26765432953834534, 1.5763704776763916, 0.39064761996269226, -1.112363576889038, -0.18238960206508636, 0.07906702160835266, 0.180534228682518, 0.5121628642082214, -0.591194748878479, 1.0648090839385986, -0.9810546040534973, -0.09456399828195572, 0.8743088245391846, -0.22654449939727783, -0.04764105752110481, 0.06364884227514267, -0.33426633477211, 0.48889678716659546, 0.546390175819397, 1.137823462486267, -0.13934680819511414, 0.8896018862724304, 0.37323999404907227, 0.32019174098968506, -0.6432213187217712, 0.587421715259552, -0.012733361683785915, 0.5073192119598389, -0.6288663744926453, 0.48193883895874023, 0.06628162413835526, 0.8443149328231812, -0.5814465284347534, 0.03487715870141983, -0.7455728650093079, 0.24366715550422668, 1.4081429243087769, -0.25995558500289917, 0.5890598893165588, -0.7338756918907166, 0.42029502987861633, -0.9215579628944397, 0.38015252351760864, -0.6092214584350586, 0.05664370208978653, -0.27006930112838745, -0.16263535618782043, -1.2243521213531494, 0.059904444962739944, 0.5461815595626831, -0.35943886637687683, 1.0915368795394897, -0.3025851249694824, 0.3206886649131775, 0.04005778580904007, 0.36162427067756653, 0.09317999333143234, 0.542707085609436, 0.6078675389289856, 0.07609150558710098, 0.5483027696609497, -0.38240522146224976, -0.404462993144989, -0.9905663728713989, 0.5546184182167053, -0.19965671002864838, 0.6256754398345947, -0.2758670151233673, -0.7543891072273254, -1.2097809314727783, -1.1010304689407349, 0.41483065485954285, -0.5140670537948608, 0.008859861642122269, 0.823930561542511, -0.0658581480383873, -0.9126715064048767, 1.2260417938232422, -0.12298253923654556, -0.05982724204659462, 0.3855102062225342, -0.036403071135282516, 0.15920379757881165, -0.7097925543785095, -1.3607946634292603, 0.2769743800163269, 0.5708902478218079, -0.4281478226184845, -0.4549299478530884, -0.7178916335105896, -1.2922406196594238, -0.2671164870262146, 0.25295454263687134, -0.36424481868743896, 1.2477848529815674, 0.08008645474910736, -0.7092982530593872, 0.3430429995059967, -0.3576743006706238, 0.1852542906999588, 0.27958524227142334, -0.25647011399269104, -0.7334783673286438, -0.3672921657562256, 0.20261704921722412, 1.0384702682495117, 0.21225190162658691, -0.8392462134361267, -0.5788820385932922, 0.16738098859786987, -0.15299630165100098, 0.05334014818072319, -0.07673221081495285, 0.5020099878311157, -0.07853363454341888, -0.45369860529899597, 0.29401883482933044, 0.7879048585891724, 0.10017681121826172, -0.2225189357995987, -0.08529017120599747, -1.3285259008407593, 0.7614821195602417, 0.12955519556999207, 0.936165452003479, -0.8331187963485718, -1.1805251836776733, -0.18294133245944977, -0.7025901675224304, -0.23144245147705078, -1.0514001846313477, 0.859336256980896, -0.29791587591171265, 0.7432686686515808, -0.0438188761472702, -0.8594481348991394, -0.06844227761030197, -0.062190596014261246, -0.888778030872345, -0.45536935329437256, 0.07441460341215134, 0.8353074789047241, -1.3379391431808472, -0.2241228073835373, 0.2843690514564514, 0.213409423828125, -0.9338029623031616, 1.2352904081344604, -0.4832139015197754, 0.5419596433639526, -0.0794670581817627, -0.7734948396682739, -0.28101420402526855, -0.18425826728343964, 0.23295480012893677, -0.25755080580711365, -0.2338518500328064, 0.9538356065750122, -0.45774003863334656, 1.2652355432510376, -0.7104625105857849, 0.5423328280448914, -0.6291179656982422, -0.4218834340572357, -0.3048148453235626, 0.5904989242553711, -0.30010277032852173, -0.5686184167861938, 0.0725119486451149, 0.46600231528282166, -0.2764771580696106, -0.31477561593055725, 0.6513203978538513, 1.0117268562316895, -0.27223876118659973, 0.2567981481552124, 0.16974857449531555, -0.2249876856803894, 0.7862682342529297, 0.27154919505119324, 0.2915414273738861, 0.8973485231399536, 0.498836487531662, 0.014665663242340088, 0.3165399730205536, -0.9739920496940613, -0.2724190652370453, 0.7933388352394104, 0.6020442247390747, 0.6281617283821106, 0.18217238783836365, -0.8271388411521912, -0.49368733167648315, -0.076931431889534, 0.32264548540115356, 1.2487058639526367, -0.2258685678243637, -0.31117647886276245, -0.33842751383781433, -0.39840051531791687, -0.38018372654914856, 0.5679559707641602, -0.5437440872192383, 0.21529456973075867, -0.8458608388900757, -0.1681741625070572, 0.5170934796333313, 0.7042246460914612, 1.1262996196746826, -0.9804095029830933, -0.5908213257789612, -0.009095849469304085, 0.31265413761138916, -0.6671950817108154, -0.6426819562911987, 0.17522956430912018, -0.4918588697910309, -0.3740723133087158, 0.273592084646225, -0.2938959002494812, 0.03736055642366409, -0.8687468767166138, 0.7672473788261414, -0.3415530025959015, -0.43384215235710144, 0.12802007794380188, 0.557991623878479, -0.5248326659202576, -0.9445564150810242, -0.05492062121629715, -0.0733305960893631, -0.6173078417778015, 0.24634413421154022, 0.572478711605072, -0.16037710011005402, -0.2982860803604126, -0.3988959789276123, -0.1112116351723671, 0.06497381627559662, 0.2936945855617523, 0.7459633946418762, -0.2902541160583496, 0.10731252282857895, -0.9793459177017212, 0.8993147611618042, 0.19125254452228546, -0.5281436443328857, 0.10354498773813248, -0.5034969449043274, -0.33540573716163635, 0.8694148063659668, -0.4413292706012726, -0.25309354066848755, -0.8753169178962708, 0.3244560956954956, -0.18154370784759521, -0.5751004815101624, 0.33153036236763, 0.4486674666404724, 0.6767516732215881, 0.49294161796569824, 0.18935106694698334, 0.1498420387506485, 0.07689218968153, 0.44380250573158264, -0.9963536858558655, 0.4780654013156891, -0.08845027536153793, -0.09849783778190613, -0.21469421684741974, -0.018594656139612198, -0.6210191249847412, -0.3030686378479004, -0.38168254494667053, -0.347329318523407, -0.23968346416950226, -0.15656819939613342, -0.4831845760345459, -0.8277859687805176, -0.17150218784809113, -1.0722166299819946, -0.5216089487075806, 0.15174981951713562, 0.06656419485807419, -0.1706475466489792, -0.953465461730957, -1.160726547241211, -0.782986044883728, 0.25162431597709656, -0.880165159702301, 0.14153988659381866, -0.08194517344236374, -0.8089255094528198, -0.48744824528694153, -0.10051966458559036, -0.6435341835021973, 0.6609081029891968, -0.5916394591331482, 0.9749471545219421, -0.010575028136372566, -0.47199034690856934, -0.2641580104827881, 0.4114178717136383, 0.3666391670703888, 0.1181502491235733, 0.3198305666446686, -1.198857307434082, 0.33875688910484314, -0.13821814954280853, -0.2548351287841797, 0.11397407203912735, 0.19721125066280365, 0.9009959101676941, -0.18283063173294067, -0.7115558981895447, -0.020797980949282646, 1.542077898979187, -0.04230881482362747, 0.03310517966747284, 0.1462857723236084, 0.8183793425559998, 0.9166198372840881, 0.3430938720703125, 0.2896489202976227, 0.09247838705778122, 0.4365990459918976, 0.16615645587444305, 0.3365638554096222, -0.02907850593328476, -1.0167925357818604, 0.07723082602024078, 1.1788979768753052, 0.3180762529373169, 0.3129568099975586, -0.876122772693634, 0.7094721794128418, -1.2003957033157349, -1.0321927070617676, 0.792144775390625, 0.8628904819488525, 0.5233237743377686, -0.7298892140388489, -0.3345053493976593, -0.035982996225357056, 0.4214365780353546, 0.5185520052909851, -0.24367190897464752, -0.3381022810935974, 0.40512311458587646, 0.1324019581079483, -0.2677949070930481, 0.8835566639900208, -0.6777851581573486, 0.3379169702529907, 14.882686614990234, 0.5627652406692505, 0.11972919851541519, 0.30595991015434265, 0.6382920742034912, 0.42099419236183167, -0.560440182685852, -0.21721726655960083, -1.0738813877105713, 0.0630829781293869, 0.7912825345993042, 0.7572231888771057, 0.6049056649208069, -0.03186801075935364, 0.14103418588638306, 0.13438226282596588, -1.0698423385620117, 0.5837792158126831, 0.4111770987510681, -1.2056553363800049, 0.4361412823200226, -0.028610501438379288, 0.4391592741012573, 0.17190223932266235, 0.7876768112182617, 0.6288644671440125, 0.3456251323223114, -0.5490445494651794, 0.49989911913871765, -0.05401337146759033, 0.7419079542160034, -0.20672565698623657, 0.04933755844831467, 0.5287526845932007, -0.8443357348442078, -0.5028442740440369, -0.5648224353790283, -1.1554301977157593, 0.08617977052927017, -0.4846261739730835, -0.6372766494750977, -0.6703554391860962, 0.10799836367368698, 0.6000317931175232, 0.3937060832977295, 0.29228392243385315, -0.8802761435508728, 0.46830475330352783, 0.32516157627105713, -0.42867228388786316, 0.3783528208732605, 0.8038239479064941, 0.20066706836223602, 0.06392964720726013, 0.014164397493004799, 0.03407733514904976, -0.03466318920254707, 0.7388607263565063, -0.14858011901378632, -0.07833682745695114, -0.6550531983375549, -0.017590733245015144, 0.5681100487709045, 0.2680961787700653, 0.6771236658096313, 0.3416360020637512, -0.16279645264148712, -0.051045212894678116, 0.8274036049842834, 0.46351754665374756, -0.048049699515104294, 0.1960541158914566, 0.24931292235851288, -0.4726563096046448, 0.029491612687706947, 0.4432399570941925, -0.08291953057050705, -0.03549608215689659, -0.3176089823246002, -0.15193676948547363, 0.19173455238342285, -0.8160049915313721, -1.0476911067962646, 0.8618746399879456, 0.4201633930206299, -0.5339000225067139, -0.06397108733654022, -0.8905898332595825, -0.4868043065071106, 0.3181076645851135, -1.3193773031234741, -0.3996049463748932, 0.22102759778499603, -0.3038560152053833, -0.07455005496740341, -0.09350970387458801, 1.3443503379821777, 0.04895741119980812, -0.06267566978931427, 0.028530150651931763, -0.11765838414430618, -0.21872904896736145, 0.029094643890857697, -1.1944578886032104, 0.7578635215759277, 0.2574172616004944, 0.18128132820129395, 0.9260339140892029, 0.10208173841238022, 0.1302163451910019, -0.1186814159154892, -0.05387644097208977, 0.8539479374885559, -0.6662325859069824, -0.4898563325405121, -0.5744052529335022, -0.8608882427215576, 0.3003513813018799, 0.7180017828941345, -0.27195659279823303, 0.3075803518295288, 0.07401418685913086, -0.7046664357185364, -0.09180889278650284, -0.6722121834754944, 0.8571984767913818, 0.7190244793891907, -0.6662924885749817, -0.735088586807251, -0.334886759519577, 0.24123698472976685, -0.875667929649353, -0.3913790285587311, -0.16541408002376556, 0.22333328425884247, -0.22790291905403137, 0.9566991925239563, -0.41640979051589966, 1.0505704879760742, 0.5185815095901489, -0.2374807745218277, -0.9255519509315491, -0.2568344175815582, -0.5956895351409912, 0.2743387818336487, 0.11976637691259384, 0.6995103359222412, -0.41187554597854614, 0.0743480697274208, 0.7746624946594238, -0.02438397891819477, -0.3585682213306427, -0.525127112865448, -0.29235514998435974, 0.2992152273654938, -0.6966392993927002, 0.47652262449264526, -0.01624043472111225, 0.03059874288737774, -0.038438718765974045, 0.7834723591804504, 0.7536292672157288, -0.46515342593193054, -0.6468494534492493, -0.11794805526733398, 0.49579694867134094, -0.3185790777206421, -0.5628010630607605, -0.06767831742763519, -1.4843093156814575, 0.010402865707874298, -1.1784393787384033, 0.04617482051253319, -1.2041665315628052, -0.6849943399429321, -0.29292523860931396, -0.3156120777130127, -0.06578744202852249, 0.11254125088453293, -0.8154485821723938, -0.26908132433891296, -0.24159930646419525, -0.2952686846256256, 0.3561326563358307, 0.921524167060852, -0.6521465182304382, 0.17297686636447906, -0.026402762159705162, 0.2082592099905014, 0.1771405041217804, 0.5141302943229675, -0.3119560778141022, -1.0417389869689941, -1.271817922592163, 0.3006584048271179, -0.2875058948993683, 0.23994119465351105, -0.7098981738090515, 0.7126765251159668, 0.5571703314781189, 0.2045157253742218, -0.3672977089881897, 0.466004878282547, -1.2763478755950928, -0.6479679942131042, 0.4423748254776001, -1.3106584548950195, 0.2867623567581177, 0.25403261184692383, -0.0640997365117073, -0.4252265393733978, 0.34396791458129883, -0.30283045768737793, -1.3068568706512451, -1.1472060680389404, 0.21567818522453308, -0.5721579194068909, 0.3105022609233856, -0.12163667380809784, -0.09496211260557175, -0.986981213092804, -0.13728466629981995, 0.1643304079771042, 0.37338986992836, -0.6346921920776367, 0.8913893103599548, 0.6913742423057556, -1.2610987424850464, 0.24666383862495422, 0.4988884925842285, 0.1990571767091751, 0.05159558355808258, 0.47452312707901, 0.04242574796080589, -0.197645902633667, 0.6399518251419067, 0.2601531445980072, 0.007010734640061855, -0.9048795104026794, 0.05672038346529007, 0.6222438216209412, -0.4113113582134247, 0.11752953380346298, 1.1325078010559082, -0.1431311070919037, -1.1250182390213013, 0.4768750071525574, -1.1054250001907349, -0.8130955696105957, -0.5026410818099976, 0.6964356899261475, 0.1865963637828827, -0.5370249152183533, 0.2193773090839386, -0.32068753242492676, 0.17016178369522095, -0.40897202491760254, -0.7975422143936157, -0.021720224991440773, 0.07067019492387772, 0.09554357081651688, 0.7147671580314636, 0.9675167202949524, -0.5580158829689026, -1.263144850730896, -0.5181623101234436, -0.3637202978134155, -0.5741307735443115, -0.3354213833808899, -0.41583359241485596, -0.3524090051651001, 0.7543867230415344, 0.3263799846172333, 0.09678830206394196, -0.5404490828514099, 0.014124910347163677, -0.2981736361980438, 0.45260635018348694, 0.1587696373462677, -0.7297126054763794, -0.058814484626054764, 0.9859507083892822, 1.7382410764694214, -0.9000633955001831, 0.18963004648685455, -0.2268287092447281, -0.45491382479667664, 0.8830131888389587, 0.7422347664833069, -0.4510529637336731, 0.7644348740577698, -0.29475414752960205, 0.17894037067890167, 0.2549031972885132, -0.8663241863250732, 0.27735039591789246, 0.5648097395896912, 1.4952948093414307, 0.9033530950546265, 0.39611661434173584, 0.08214186131954193, 0.44525450468063354, -0.0010197178926318884, -0.17329230904579163, 0.3007766306400299, 0.5177382230758667, 0.18365007638931274, -0.4771052300930023, 0.0973387286067009, 0.6289948225021362, -0.6185625195503235, -0.8475621938705444, 0.279248982667923, 1.188646912574768, 0.17073097825050354, 0.647659957408905, 0.9470076560974121, 0.15865735709667206, 0.5162859559059143, 0.2440066933631897, 0.6874576807022095, -0.5131973624229431, -0.36724159121513367, -0.21867457032203674, -0.711704432964325, -0.09582448750734329, -0.49413013458251953, -0.8350560665130615, -0.7085685729980469, 0.5328503251075745, 0.3774860203266144, -0.11410269141197205, 0.3268490731716156, 0.9780498147010803, 0.5008093118667603, 0.6215877532958984, -0.34381428360939026, -0.4328611195087433, -0.5491287708282471, -0.9913321137428284, 0.39757704734802246, -0.1983625739812851, -0.17799367010593414, -0.30272793769836426, -0.32735276222229004, -0.49954915046691895]}, "authors": [{"authorId": "2264255437", "name": "Yanzheng Xiang"}, {"authorId": "1830443015", "name": "Hanqi Yan"}, {"authorId": "2253541219", "name": "Lin Gui"}, {"authorId": "2237125679", "name": "Yulan He"}], "references": [{"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787", "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"}, {"paperId": "ea75117f34b168a20f2a4309ac2eb685ca6b1436", "title": "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance"}, {"paperId": "aafa168f9756f42c4ff707f6577cdd2eccc62b12", "title": "RetICL: Sequential Retrieval of In-Context Examples with Reinforcement Learning"}, {"paperId": "500cfab9345de174644d7534bb39695f17920601", "title": "How Do In-Context Examples Affect Compositional Generalization?"}, {"paperId": "dc385646887a3669ae0ee506a263d592f4f7c7a6", "title": "Finding Support Examples for In-Context Learning"}, {"paperId": "b6207fe49e29c77402f8dbab052e949990949609", "title": "In-context Example Selection with Influences"}, {"paperId": "3d5922d71a370f32b7f232a596def914f67eebd1", "title": "Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering"}, {"paperId": "89744cbaa080c82785b1cb8d54710bbbca32f8ed", "title": "Data Curation Alone Can Stabilize In-context Learning"}, {"paperId": "b8bd29a6104d26a16687400049a4e7e026ae6258", "title": "Active Example Selection for In-Context Learning"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "f4df78183261538e718066331898ee5cad7cad05", "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "0adec918885dff698acf359988ed79a543157f80", "title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"}, {"paperId": "56fa0b9cba4d9aee5ccc327365b3b3a721031c69", "title": "Calibrate Before Use: Improving Few-Shot Performance of Language Models"}, {"paperId": "59641c10ed7431a3cf841f308367dc2dc0281b74", "title": "What Makes Good In-Context Examples for GPT-3?"}, {"paperId": "85e7d63f75c0916bd350a229e040c5fbb1472e7a", "title": "Making Pre-trained Language Models Better Few-shot Learners"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "270f3bea8ca801870a6cc56b4d36f7f2019c9ed0", "title": "MPNet: Masked and Permuted Pre-training for Language Understanding"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "afed6dc6900d3b37e528b9086661bba583d60bf6", "title": "Analysing Mathematical Reasoning Abilities of Neural Models"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "f40aeae3e522ada1f6a9f326841b01ef5c8657b6", "title": "Unifying Language Learning Paradigms"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "8ff46c88964a36985f2b45933a3d47b81bd87bd0", "title": "Quora Question Pairs"}, {"paperId": "e808f28d411a958c5db81ceb111beb2638698f47", "title": "The PASCAL Recognising Textual Entailment Challenge"}, {"paperId": null, "title": "answers by feeding them to LLMs. For the MMLU benchmark, we present the average experimental results for the same sub-tasks as shown in Table 1 We"}, {"paperId": null, "title": "2022. Chain of thought prompting elicits reasoning in large language models"}]}