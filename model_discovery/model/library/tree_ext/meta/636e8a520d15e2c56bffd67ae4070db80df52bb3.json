{"paperId": "636e8a520d15e2c56bffd67ae4070db80df52bb3", "title": "Short-Long Convolutions Help Hardware-Efficient Linear Attention to Focus on Long Sequences", "abstract": "To mitigate the computational complexity in the self-attention mechanism on long sequences, linear attention utilizes computation tricks to achieve linear complexity, while state space models (SSMs) popularize a favorable practice of using non-data-dependent memory pattern, i.e., emphasize the near and neglect the distant, to processing sequences. Recent studies have shown the priorities by combining them as one. However, the efficiency of linear attention remains only at the theoretical level in a causal setting, and SSMs require various designed constraints to operate effectively on specific data. Therefore, in order to unveil the true power of the hybrid design, the following two issues need to be addressed: (1) hardware-efficient implementation for linear attention and (2) stabilization of SSMs. To achieve this, we leverage the thought of tiling and hierarchy to propose CHELA (short-long Convolutions with Hardware-Efficient Linear Attention), which replaces SSMs with short-long convolutions and implements linear attention in a divide-and-conquer manner. This approach enjoys global abstraction and data-dependent selection from stable SSM and linear attention while maintaining real linear complexity. Our comprehensive experiments on the Long Range Arena benchmark and language modeling tasks demonstrate the effectiveness of the proposed method.", "venue": "arXiv.org", "year": 2024, "citationCount": 2, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "CHELA (short-long Convolutions with Hardware-Efficient Linear Attention), which replaces SSMs with short-long convolutions and implements linear attention in a divide-and-conquer manner and enjoys global abstraction and data-dependent selection from stable SSM and linear attention while maintaining real linear complexity."}, "embedding": {"model": "specter_v2", "vector": [0.19899606704711914, 0.2631899416446686, -0.13814736902713776, -0.12850433588027954, -0.14516347646713257, -0.01050135400146246, 0.6417627334594727, -0.3038965165615082, -0.5817448496818542, -0.04933875426650047, 0.7034562230110168, 0.14200043678283691, 0.5944753885269165, -0.09990006685256958, -0.38842278718948364, 0.020870594307780266, -1.3495347499847412, -0.12514321506023407, 0.30899545550346375, 0.026146013289690018, 0.4185378849506378, -0.383228063583374, -1.241537094116211, 0.3003290593624115, 0.16177642345428467, 0.4655611515045166, 0.3781929016113281, 1.0147898197174072, -0.46790483593940735, 0.4567091763019562, 0.25384074449539185, -0.04040984809398651, 0.20681343972682953, 0.06879397481679916, -0.5173636674880981, -0.5921252369880676, 0.6053070425987244, -0.38308408856391907, -1.1174622774124146, 0.7858664989471436, -0.09561314433813095, 0.16892190277576447, 0.25823551416397095, -0.40249043703079224, 0.0977870523929596, 0.8049566745758057, 0.41290655732154846, 1.0245778560638428, -0.3653177320957184, -0.3364032208919525, 1.202957272529602, -1.1101350784301758, -0.13002455234527588, 1.7340396642684937, 0.3151516318321228, 0.31531912088394165, -0.1352682262659073, -0.7042554616928101, 0.815916895866394, 0.20961302518844604, -0.7418590188026428, -0.5353306531906128, -0.23697501420974731, -0.05490926653146744, 1.7767869234085083, -0.197478249669075, -0.10374674946069717, 0.7272701263427734, 0.40956079959869385, 1.4991587400436401, -0.07585100829601288, -0.6241523027420044, 0.14295630156993866, -0.3893459737300873, 0.8753153681755066, 0.9550502300262451, -0.19997495412826538, 0.6579684615135193, -1.038610577583313, -0.049067288637161255, 1.0145056247711182, 0.02728913351893425, 0.4105219841003418, -0.18476971983909607, -0.5213972926139832, 0.6017029881477356, 0.4831031262874603, 0.8749539852142334, -0.1607445627450943, 0.8896017074584961, 0.5543121695518494, 0.004664141219109297, -0.3899194300174713, 0.5989605784416199, 0.37364661693573, 0.22811070084571838, -0.6503723859786987, 0.03626728057861328, -0.1503177434206009, 1.3280292749404907, -0.2823663651943207, 0.6361560225486755, -0.7687210440635681, -0.1470639407634735, 1.1018388271331787, 0.2265499234199524, 0.4379362165927887, -0.5957542061805725, -0.03724370151758194, -0.7149116396903992, 0.2512781620025635, -0.5949357748031616, -0.22380174696445465, -0.645090639591217, -0.7845861315727234, -1.0361413955688477, -0.13426803052425385, 0.18145857751369476, -0.5981557369232178, 0.6316171884536743, -0.722956657409668, 0.31781306862831116, 0.15397995710372925, 0.21738743782043457, 0.19407327473163605, 0.8025186657905579, 0.31709298491477966, -0.07279983907938004, 1.0765479803085327, -1.1595089435577393, -0.6546568870544434, -1.3138399124145508, 0.04668843373656273, 0.04605203494429588, 0.2209911048412323, -0.5302072763442993, -1.1937851905822754, -1.3516074419021606, -1.2616283893585205, 0.13543345034122467, -0.3440958857536316, -0.11240877956151962, 1.330201268196106, -0.08207555115222931, -0.9421427845954895, 0.7197420597076416, -0.7439289689064026, -0.32891884446144104, 0.504944920539856, -0.12651926279067993, 0.7270139455795288, -0.0468120239675045, -1.1605124473571777, 0.2054625004529953, 0.23336367309093475, -0.5327445268630981, -0.5349134206771851, -0.33934900164604187, -1.12997567653656, 0.33482369780540466, 0.3979455232620239, -0.3366096615791321, 1.2398101091384888, 0.11566146463155746, -0.7046378254890442, 0.21326234936714172, -0.5811863541603088, -0.2874319851398468, 0.012626130133867264, -0.3111172318458557, -0.4870871901512146, -0.3947065770626068, -0.13291777670383453, 0.5782954692840576, 0.4687659740447998, -0.47917425632476807, -0.3721049427986145, -0.17390628159046173, -0.14854267239570618, -0.16997358202934265, -0.2981886863708496, 0.9010341763496399, -0.709773063659668, -0.09145994484424591, 0.4600429832935333, 0.6020961999893188, -0.26939836144447327, -0.23761625587940216, -0.0895097628235817, -0.8746516108512878, 0.4044841229915619, 0.24185504019260406, 1.4069181680679321, -0.9675503373146057, -1.0267757177352905, -0.3807145953178406, -0.3472942113876343, -0.21814753115177155, -0.7810182571411133, 0.5094570517539978, -0.2418738603591919, 0.1044272929430008, 0.1796443909406662, -0.7424554228782654, -0.29591983556747437, -0.3032287657260895, -1.1037999391555786, -0.2232375591993332, 0.04586527869105339, 1.0962845087051392, -1.1639314889907837, -0.36785563826560974, -0.28276920318603516, -0.10102709382772446, -0.8658142685890198, 1.503867268562317, -0.40806424617767334, 0.001983135938644409, -0.08094791322946548, -0.3068053424358368, -0.1495470255613327, -0.44767990708351135, 0.3227202892303467, -0.5764811038970947, -0.6497424840927124, 0.4325678050518036, -0.12028408795595169, 1.3703950643539429, -0.19536758959293365, 0.838294267654419, -0.5066560506820679, -0.3595348000526428, 0.08987945318222046, 0.1518535017967224, -0.26809799671173096, -0.5360831618309021, 0.36827096343040466, -0.3540116846561432, -0.5027638077735901, -0.01826421730220318, 0.676795244216919, 1.2960132360458374, -0.6863453984260559, 0.21681688725948334, 0.5274777412414551, 0.03410613164305687, 0.4597837030887604, 0.5046824216842651, 0.9016841650009155, 0.23715801537036896, 0.7076014280319214, -0.31937670707702637, 0.16273166239261627, -0.7711603045463562, -0.126776322722435, 0.9973610043525696, 0.5287495851516724, 0.8104292750358582, 0.3278549313545227, -1.008163571357727, -0.604526937007904, 0.16248606145381927, 0.5591302514076233, 1.3769510984420776, 0.01870565675199032, -0.14940793812274933, -0.946325957775116, -0.10436610877513885, -0.4760694205760956, 0.3600883483886719, -0.45116809010505676, -0.23848816752433777, -0.7380643486976624, -0.7679948806762695, 0.933441162109375, 0.737838864326477, 1.2288625240325928, -0.6826077103614807, -0.8096328973770142, -0.13371428847312927, 0.5777375102043152, -0.5413679480552673, -0.8744673728942871, 0.603949785232544, -0.3689461648464203, -0.012397142127156258, 0.3379596471786499, -0.07265438139438629, -0.019271953031420708, -0.20913060009479523, 0.4130588173866272, -0.9170628190040588, -0.3503447473049164, 0.06406628340482712, 0.994334876537323, -0.8646790981292725, -0.5186122059822083, 0.2931746542453766, -0.027624333277344704, -0.24718692898750305, 0.43537572026252747, 0.4485216736793518, -0.08557149022817612, 0.029216527938842773, -0.0803995281457901, 0.16747446358203888, 0.44787439703941345, 0.23548275232315063, 0.42833393812179565, -0.11617442220449448, 0.01018553040921688, -0.9880672693252563, 0.6091372966766357, 0.30560269951820374, -0.6668146848678589, 0.19009505212306976, -0.4967481195926666, 0.018418172374367714, 0.1492261290550232, -0.6801150441169739, -0.3896602392196655, -0.7133129835128784, 0.47248440980911255, -0.449268639087677, -0.4291575253009796, 0.15626965463161469, 0.30558526515960693, 0.013392426073551178, 0.4757804870605469, 0.7794938087463379, 0.33089929819107056, 0.25082963705062866, 0.1449500173330307, -0.7851728796958923, 0.7897996306419373, 0.24517850577831268, -0.030898315832018852, 0.07732425630092621, -0.05340598523616791, -0.9146765470504761, -0.6751478314399719, -0.4678461253643036, -0.5825039148330688, -0.21465307474136353, 0.3824161887168884, -0.49698689579963684, -1.181150197982788, -0.028153665363788605, -1.3147989511489868, -0.3413827121257782, 0.21249692142009735, -0.3705954849720001, -0.236855149269104, -1.0725531578063965, -1.0693656206130981, -1.0656918287277222, -0.2858485281467438, -0.7046520113945007, 0.2828098237514496, 0.16719916462898254, -0.5422154664993286, -0.23344051837921143, -0.1907060146331787, -0.665789008140564, 1.2038935422897339, -0.7258609533309937, 0.6529408097267151, -0.0003360084956511855, -0.7149506211280823, -0.37293049693107605, -0.005539495963603258, -0.06496833264827728, -0.15258291363716125, -0.12421421706676483, -0.998758852481842, 0.12318730354309082, 0.13762667775154114, -0.12349355220794678, 0.36121928691864014, 0.2979937493801117, 1.020627498626709, 0.011941430158913136, -0.6592340469360352, 0.09610495716333389, 1.3300350904464722, 0.1998630315065384, 0.35712945461273193, -0.16222025454044342, 0.9295356273651123, 0.1531480997800827, 0.16254779696464539, 0.6416470408439636, 0.12028361856937408, 0.2035641074180603, 0.16094107925891876, -0.08142059296369553, -0.06400298327207565, -0.47093191742897034, 0.3073395788669586, 1.3708467483520508, 0.12986573576927185, 0.24103060364723206, -0.8912887573242188, 0.5142781138420105, -1.3080555200576782, -1.2094870805740356, 0.9146591424942017, 0.687045693397522, 0.27066275477409363, -0.14393571019172668, -0.4601583778858185, -0.39912378787994385, 0.46075528860092163, 0.6068392992019653, -0.5569429397583008, -0.38082247972488403, -0.007732572965323925, 0.06211470812559128, 0.20196345448493958, 0.6131730079650879, -0.7661860585212708, 0.5564839243888855, 14.99135684967041, 0.5535058379173279, -0.10134199261665344, 0.47250911593437195, 0.8536340594291687, 0.5161140561103821, 0.1529095470905304, -0.2977714538574219, -1.4298195838928223, -0.14495424926280975, 1.262091875076294, 0.033851008862257004, 0.4725857675075531, 0.21706128120422363, -0.1551990956068039, 0.048630017787218094, -0.7647070288658142, 0.6480034589767456, 0.598567008972168, -1.4965254068374634, 0.3368283808231354, 0.049564436078071594, 0.20609942078590393, 0.03758687898516655, 0.5448413491249084, 0.6192264556884766, 0.549809455871582, -0.23353439569473267, 0.4768356680870056, 0.47314631938934326, 0.983967661857605, 0.019770290702581406, 0.2110631763935089, 0.31811514496803284, -1.109639048576355, -0.36276939511299133, -0.6672901511192322, -1.0529546737670898, 0.09213852137327194, -0.5248201489448547, -0.35524827241897583, -0.7513536214828491, -0.40406376123428345, 0.19307111203670502, 0.1983034461736679, 0.5830802321434021, 0.10116510093212128, 0.5105984210968018, 0.45504966378211975, -0.46553245186805725, 0.3868461549282074, 0.8050349354743958, 0.0004030618001706898, 0.2011493295431137, -0.11430412530899048, 0.3630925416946411, -0.004869323223829269, 0.532715916633606, 0.1084209680557251, -0.5031461119651794, -0.420564204454422, -0.4509236216545105, 0.10721753537654877, 0.3887961506843567, 0.45562899112701416, 0.22676390409469604, -0.4472755789756775, 0.10099920630455017, 0.6444268822669983, 0.32674819231033325, -0.47710907459259033, -0.0330674834549427, 0.3695344626903534, -0.7326661944389343, -0.11753376573324203, 0.15051288902759552, -0.6482445597648621, -0.4481659531593323, -1.3368024826049805, -0.33914506435394287, 0.5511667132377625, -0.7588410973548889, -0.48510804772377014, 1.275620460510254, -0.1287936568260193, -0.2893185317516327, 0.4183460474014282, -0.5113523602485657, -0.4365027844905853, 0.22811801731586456, -0.5772787928581238, -0.4457457661628723, -0.13986951112747192, -0.5757446885108948, 0.2463381588459015, -0.24772368371486664, 1.2755688428878784, -0.021027684211730957, -0.6005533933639526, -0.0038880319334566593, -0.22626514732837677, -0.206709623336792, -0.23783241212368011, -0.5876289010047913, 0.99894779920578, 0.535068690776825, -0.18795844912528992, 0.6111233234405518, 0.18776628375053406, -0.09750986099243164, -0.9874091744422913, -0.1354808509349823, 0.6913235187530518, -0.6812673211097717, -0.21066796779632568, -1.0096603631973267, -0.9861043095588684, 0.4359443485736847, 0.7572638988494873, -0.3849520683288574, -0.18310214579105377, 0.08217210322618484, -0.4184783399105072, -0.21035903692245483, -0.17018452286720276, 0.482483834028244, 0.7571725249290466, -0.6984992623329163, -0.3647914528846741, -0.5056328177452087, 0.5831648111343384, -0.8948701024055481, -0.09319976717233658, -0.3204032778739929, 0.10367270559072495, 0.011412408202886581, 1.0659571886062622, -0.5832059383392334, 0.6583288908004761, 0.779945433139801, -0.09268603473901749, -0.38545823097229004, -0.5643227696418762, -0.5836571455001831, 0.0034642864484339952, 0.29744720458984375, 0.30901017785072327, -0.3228098452091217, 0.36857789754867554, 0.7015401721000671, 0.04059320688247681, -0.22972659766674042, -0.4121840298175812, -0.2883272171020508, -0.4355694353580475, -0.40451759099960327, 0.2684312164783478, -0.23862676322460175, 0.1779237687587738, 0.33385804295539856, 0.3471944332122803, 0.8701237440109253, -0.07070094347000122, -0.09511365741491318, 0.3618184030056, 0.258062481880188, -0.014142932370305061, -0.35295405983924866, -0.35099178552627563, -1.5596672296524048, -0.23542191088199615, -0.6926072239875793, 0.3178255259990692, -0.6154010891914368, -0.21568690240383148, 0.13481466472148895, -0.2846373915672302, -0.07263917475938797, 0.41748473048210144, -0.6709437370300293, -0.6161319613456726, -0.47641104459762573, -0.7845893502235413, 0.6321734189987183, 0.7587940096855164, -0.6293191313743591, 0.16322647035121918, 0.09248802065849304, 0.08241129666566849, 0.3109818398952484, 0.3511684834957123, -0.23547165095806122, -0.45044049620628357, -1.0398011207580566, -0.15013593435287476, 0.09940576553344727, -0.3517751097679138, -1.0617492198944092, 1.1797770261764526, 0.0963497906923294, -0.058115169405937195, -0.36345675587654114, 0.4913640320301056, -0.8012861609458923, -0.5149247646331787, 0.7294331789016724, -1.109668254852295, 0.014164755120873451, 0.5049662590026855, -0.4298776686191559, -0.2592335343360901, 0.7344576120376587, 0.2697935700416565, -0.9545222520828247, -0.9431048631668091, 0.4336189329624176, -0.6616666316986084, 0.03912757337093353, -0.14800423383712769, 0.09002706408500671, -1.3400317430496216, -0.2798234820365906, 0.07354975491762161, 0.3628269135951996, -0.6465263366699219, 1.009598731994629, 0.4695977568626404, -1.1004127264022827, 0.3899695873260498, 0.6839245557785034, -0.09163003414869308, -0.004651985131204128, 0.5287835597991943, -0.013984723947942257, -0.24748310446739197, 1.058695912361145, -0.15141057968139648, 0.31568822264671326, -0.9581518769264221, 0.456734836101532, 0.5232569575309753, -0.13963794708251953, 0.3152012228965759, 0.9251379370689392, 0.24535706639289856, -0.34438908100128174, 0.7245018482208252, -1.1013813018798828, -0.7036061882972717, -0.27391910552978516, 0.794564962387085, 0.4812684655189514, -0.7138330936431885, 0.13399472832679749, -0.3924252390861511, 0.07863125205039978, -0.08461332321166992, -0.5289573073387146, 0.4053821265697479, -0.2630387544631958, -0.25272753834724426, 1.0409071445465088, 0.7188903093338013, -0.6681267619132996, -1.1623238325119019, -0.741670548915863, -0.17764538526535034, -0.37636953592300415, 0.04194410890340805, -0.10486289113759995, -0.3027121126651764, 0.982166051864624, 0.5786907076835632, 0.343964546918869, -0.2593252956867218, -0.07292602211236954, -0.06454150378704071, 0.5071931481361389, 0.38629060983657837, -0.29516956210136414, -0.19615262746810913, 1.5297749042510986, 1.8025742769241333, -0.49564820528030396, -0.014146670699119568, -0.37078818678855896, -0.4523799419403076, 0.9466229677200317, 1.0623619556427002, -0.31193873286247253, 0.6304795145988464, 0.26905789971351624, -0.04438347369432449, 0.15728017687797546, -1.1658740043640137, -0.31148454546928406, 0.6102581024169922, 0.7130454778671265, 0.4046241343021393, 0.11734044551849365, 0.1999569833278656, 0.8681480884552002, 0.2618018090724945, -0.1130293682217598, 0.1822163462638855, 0.5656559467315674, -0.49882858991622925, 0.399215430021286, -0.17997147142887115, 0.6187220811843872, -0.208927720785141, -0.6158910393714905, 0.6274960041046143, 0.4845161736011505, -0.1781829595565796, 0.2949298322200775, 1.3951843976974487, 0.03112010285258293, 0.5230292081832886, 0.24651536345481873, 0.5262271165847778, -0.46528881788253784, -0.027354905381798744, 0.20926067233085632, -0.6789068579673767, -0.333135187625885, 0.18775026500225067, -0.985297679901123, -0.3696279525756836, 0.05817212164402008, 0.26421910524368286, -0.32546305656433105, 0.25833407044410706, 0.5734732747077942, 0.5666429400444031, 0.7782729268074036, -0.23745998740196228, -0.7901616096496582, -0.5220135450363159, -0.9888556599617004, 0.2788134217262268, -0.7633959650993347, -0.07458498328924179, -0.11880627274513245, 0.047891464084386826, -0.12982192635536194]}, "authors": [{"authorId": "2200082418", "name": "Zicheng Liu"}, {"authorId": "2118155623", "name": "Siyuan Li"}, {"authorId": "2297286771", "name": "Li Wang"}, {"authorId": "2184760529", "name": "Zedong Wang"}, {"authorId": "2302788743", "name": "Yunfan Liu"}, {"authorId": "2290860154", "name": "Stan Z. Li"}], "references": [{"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "9c464f92cb3ab18a7c09f5bcee8e6e80bdec3b3b", "title": "Transformer-VQ: Linear-Time Transformers via Vector Quantization"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "54155c2977a977bf129849455dcae3a2b79b3f41", "title": "Simple Hardware-Efficient Long Convolutions for Sequence Modeling"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "661e8d555c4424b5953f17434f2ba910bfcf3afe", "title": "Efficient Long Sequence Modeling via State Space Augmented Transformer"}, {"paperId": "240300b1da360f22bf0b82c6817eacebba6deed4", "title": "What Makes Convolutional Models Great on Long Sequence Modeling?"}, {"paperId": "b40f0b0465cdf4b487fb2ef85d4e2672c4b623cc", "title": "Liquid Structural State-Space Models"}, {"paperId": "70e91e16eb321067d9402710e14a40cf28311f73", "title": "Mega: Moving Average Equipped Gated Attention"}, {"paperId": "6d7d141c75af752ffc0d8a6184cca3f9323d6c74", "title": "Simplified State Space Layers for Sequence Modeling"}, {"paperId": "ca444821352a4bd91884413d8070446e2960715a", "title": "On the Parameterization and Initialization of Diagonal State Space Models"}, {"paperId": "71e15a9a52dcafca57bff5f310b95e2c7d0cfc87", "title": "Diagonal State Spaces are as Effective as Structured State Spaces"}, {"paperId": "bec8d76b2fdb82ee5a4d1a6ad3c0cb18fcb88608", "title": "Harnessing Hard Mixed Samples with Decoupled Regularizer"}, {"paperId": "dc0102a51a9d33e104a4a3808a18cf17f057228c", "title": "Transformer Quality in Linear Time"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "e62000bf455daf9d02626d9708c497290e1826fa", "title": "FlexConv: Continuous Kernel Convolutions with Differentiable Kernel Sizes"}, {"paperId": "37abe53ed31caa23ae833b2e67bb4aa1892e8d25", "title": "FMMformer: Efficient and Flexible Transformer via Decomposed Near-field and Far-field Attention"}, {"paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"}, {"paperId": "e32a12b14e212506115cc6804667b3d8297917e1", "title": "Poolingformer: Long Document Modeling with Pooling Attention"}, {"paperId": "9dc624d7258d1a56117ca720aea953ce46b66b21", "title": "Efficient Attentions for Long Document Summarization"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "0cd82dfae930ac4b57c0e959f744f2d10bf87649", "title": "Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding"}, {"paperId": "0964490205fdc38c2f0980c9d778069089ca92e3", "title": "HiPPO: Recurrent Memory with Optimal Polynomial Projections"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "bbc89fa342c06cf2216884238c531b1f6434e61d", "title": "Lipschitz Recurrent Neural Networks"}, {"paperId": "0170fc76e934ee643f869df18fb617d5357e8b4e", "title": "Conformer: Convolution-augmented Transformer for Speech Recognition"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d", "title": "ETC: Encoding Long and Structured Inputs in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "a14af711aaa3ae83eb64d1f517b024b8c3094a8a", "title": "Trellis Networks for Sequence Modeling"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "9f1623d474ebd4b9f483f559e96e647934ed8158", "title": "Sequence"}, {"paperId": "0d3c46a3cbfe06cec259fec954b6ff6df6c1a566", "title": "Learning long-range spatial dependencies with horizontal gated-recurrent units"}, {"paperId": "da6e404d8911b0e5785019a79dc8607e0b313dc4", "title": "Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition"}, {"paperId": "8b354d76813bd5375e7e5c8d17f630bec5936a01", "title": "ListOps: A Diagnostic Dataset for Latent Tree Learning"}, {"paperId": "608e4bbe7a2d6f04d68b5747d9d0778d5fce47df", "title": "Learning Longer-term Dependencies in RNNs with Auxiliary Losses"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "1eb09fecd75eb27825dce4f964b97f4f5cc399d7", "title": "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "e01eae8dea6fbaa1ae7fc83535053932268df430", "title": "The ACL anthology network corpus"}, {"paperId": "37b187e3df04fe7dd31293222407b4b86f3089fb", "title": "Attention!"}, {"paperId": "5a69ec9a521e8562f1691f08722ef8fe38b5a426", "title": "Unveiling the Power of Mixup for Stronger Classi\ufb01ers"}, {"paperId": "45bf4dbc7cf158623f15da3e0c9b13688f663557", "title": "Perception"}, {"paperId": "30becc9209c02cd4f3f6aed86ea9bd37de50be9d", "title": "Improving the Gating Mechanism of Recurrent Neural Networks"}, {"paperId": null, "title": "Linformer"}, {"paperId": "c8c4ab59ac29973a00df4e5c8df3773a3c59995a", "title": "Searching for Activation Functions"}, {"paperId": null, "title": "Large text compression benchmark"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": null, "title": "Long short-term"}, {"paperId": null, "title": "Efficient content-based sparse attention with routing trans-formers"}, {"paperId": null, "title": "A survey of trans-formers"}, {"paperId": null, "title": "Revisiting large kernel"}, {"paperId": null, "title": "and better large language model"}, {"paperId": null, "title": "Flashat-tention: Fast and memory-efficient exact attention with"}, {"paperId": null, "title": "Short-Long Convolutions Help Hardware-Efficient Linear Attention to Focus on Long Sequences"}]}