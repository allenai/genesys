{"paperId": "862479f7bd78a69c52a0691766848caa8eb4660f", "title": "Linearizing Large Language Models", "abstract": "Linear transformers have emerged as a subquadratic-time alternative to softmax attention and have garnered significant interest due to their fixed-size recurrent state that lowers inference cost. However, their original formulation suffers from poor scaling and underperforms compute-matched transformers. Recent linear models such as RWKV and Mamba have attempted to address these shortcomings by proposing novel time-mixing and gating architectures, but pre-training large language models requires significant data and compute investments. Thus, the search for subquadratic architectures is limited by the availability of compute and quality pre-training datasets. As a cost-effective alternative to pre-training linear transformers, we propose Scalable UPtraining for Recurrent Attention (SUPRA). We present a method to uptrain existing large pre-trained transformers into Recurrent Neural Networks (RNNs) with a modest compute budget. This allows us to leverage the strong pre-training data and performance of existing transformer LLMs, while requiring 5% of the training cost. We find that our linearization technique leads to competitive performance on standard benchmarks, but we identify persistent in-context learning and long-context modeling shortfalls for even the largest linear models. Our code and models can be found at https://github.com/TRI-ML/linear_open_lm.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work presents Scalable UPtraining for Recurrent Attention (SUPRA), a method to uptrain existing large pre-trained transformers into Recurrent Neural Networks (RNNs) with a modest compute budget, and finds that the linearization technique leads to competitive performance on standard benchmarks, but it is identified persistent in-context learning and long-context modeling shortfalls for even the largest linear models."}, "embedding": {"model": "specter_v2", "vector": [0.14580968022346497, 0.7637237906455994, -0.4795116186141968, -0.2568819522857666, -0.5830221176147461, -0.22301585972309113, 0.8098204135894775, -0.3528541624546051, -0.3123137652873993, -0.6452816724777222, 0.7392428517341614, -0.2769939601421356, 0.6936547160148621, 0.2731425166130066, -0.25780314207077026, 0.19591251015663147, -0.8248342275619507, 0.1294366419315338, -0.11169677972793579, -0.23941515386104584, -0.3181225061416626, -0.38086971640586853, -0.6454172730445862, 0.06183791533112526, 0.08588068187236786, 0.5840609073638916, 0.15318435430526733, 0.9577841758728027, -0.26785808801651, 0.6853619813919067, 0.6011137962341309, -0.10153716802597046, 0.36969414353370667, -0.10698648542165756, -0.424782395362854, -0.08952252566814423, 0.38028132915496826, -0.25742512941360474, -0.6063443422317505, 0.4769934117794037, -0.21764440834522247, 0.34823423624038696, -0.07410013675689697, -0.5434344410896301, -0.43579113483428955, 1.0849508047103882, 0.6030303835868835, 0.8308503031730652, -0.610111653804779, -0.5479670166969299, 1.4741895198822021, -1.4722635746002197, 0.009747747331857681, 1.7363784313201904, 0.4072481095790863, 0.18802794814109802, -0.36434388160705566, -0.736481249332428, 1.3652423620224, 0.2206372320652008, -0.9145305752754211, -0.776373028755188, 0.11992932111024857, 0.3500942587852478, 2.252314329147339, -0.23938633501529694, 0.4585467576980591, 0.38836395740509033, -0.0487886480987072, 1.2887272834777832, -0.09694233536720276, -0.82032710313797, -0.39750635623931885, 0.21550579369068146, 0.33502012491226196, 0.6029598712921143, -0.6298559904098511, 0.17177893221378326, -0.5990291237831116, -0.023054752498865128, 0.17586369812488556, 0.045291025191545486, 0.28649383783340454, 0.0214979387819767, 0.13077135384082794, 0.7324004769325256, 0.8258394002914429, 0.7858615517616272, -0.20655934512615204, 1.0407178401947021, 0.401386559009552, 0.34935250878334045, 0.31313326954841614, 0.3329598307609558, -0.36645305156707764, 0.5669369101524353, -0.8910272717475891, -0.03556711971759796, -0.2245948761701584, 0.7643623352050781, -0.14203236997127533, 0.4298407733440399, -0.6538090705871582, 0.10742485523223877, 1.5499614477157593, 0.11823523789644241, 0.6256405711174011, -0.7530245184898376, 0.21313969790935516, -0.6821762919425964, -0.5426648259162903, -0.44798043370246887, -0.347733736038208, -0.7449331879615784, -0.7855754494667053, -1.4840991497039795, -0.7389115691184998, 0.36693045496940613, -0.8346368670463562, 1.046410083770752, -0.3158973455429077, 0.18247941136360168, 0.09054441004991531, 0.2951526939868927, 0.35661035776138306, 1.0658013820648193, 0.4676533341407776, -0.18515539169311523, 0.9753316044807434, -1.1311253309249878, -0.41603487730026245, -1.2881252765655518, 0.6013232469558716, -0.04350310564041138, 0.3291521966457367, -0.17879559099674225, -1.213789939880371, -0.9260378479957581, -0.6552923321723938, -0.4718261659145355, -0.6786550879478455, 0.13593712449073792, 1.053508996963501, 0.2866799831390381, -1.049304485321045, 0.2458544671535492, -0.6149264574050903, 0.09475671499967575, 0.47181183099746704, 0.271341472864151, 0.4880855977535248, -0.2671363353729248, -1.1138408184051514, 0.3186573386192322, 0.011269657872617245, 0.06995353102684021, -0.20237864553928375, -0.7932418584823608, -1.0193679332733154, 0.10813284665346146, 0.20950669050216675, -0.22081761062145233, 1.4305988550186157, -0.39398497343063354, -1.463126540184021, 0.765605092048645, -0.5906118750572205, -0.03559662029147148, 0.10419797897338867, -0.45549383759498596, -0.23891839385032654, -0.7270944714546204, -0.5234798789024353, 0.4926750063896179, 0.5208909511566162, 0.03496763855218887, -0.17127113044261932, 0.032352857291698456, -0.21921002864837646, -0.26904192566871643, -0.19841504096984863, 0.8954265117645264, -0.4969097375869751, 0.1381780505180359, 0.30456164479255676, 0.6028907895088196, -0.3674347996711731, -0.509376585483551, -0.4318241477012634, -1.2574149370193481, 0.6642038822174072, -0.13025927543640137, 1.079179048538208, -0.874434769153595, -0.5029267072677612, -0.019397981464862823, 0.11868718266487122, -0.08741786330938339, -0.966797947883606, 0.3365836441516876, -0.5603927373886108, 0.19156068563461304, 0.31146591901779175, -1.3314634561538696, 0.16036812961101532, -0.23781220614910126, -0.854594349861145, -0.05716285482048988, 0.25803595781326294, 1.4982527494430542, -0.7577546834945679, 0.0010143406689167023, 0.02793877013027668, 0.6475164890289307, -1.2256864309310913, 1.3972868919372559, -0.2079947292804718, -0.027177145704627037, 0.08855187892913818, -0.18722160160541534, -0.1518426239490509, -0.5107187628746033, 0.7644838690757751, -0.4662514328956604, -0.13499340415000916, 0.764305591583252, -0.25912216305732727, 0.9141143560409546, -0.8638370037078857, 0.7112878561019897, -0.1705196499824524, -1.0612577199935913, -0.13783779740333557, 0.1275462806224823, -0.3707364499568939, -0.6669740676879883, 0.30701887607574463, 0.337350070476532, -0.7920244336128235, 0.5555950403213501, 0.7810196280479431, 0.547831654548645, -0.23454956710338593, -0.2090899646282196, 0.809698224067688, -0.09849351644515991, 0.16318850219249725, 0.5393326282501221, 0.5542502403259277, 0.3196713924407959, 0.5141559839248657, 0.05797379091382027, 0.18314434587955475, -1.2850972414016724, 0.1665523797273636, 0.1936744749546051, 0.7111327648162842, 0.6157921552658081, 0.5501724481582642, -0.6848063468933105, -0.5107585787773132, 0.14759351313114166, 0.6186137199401855, 1.830322027206421, -0.49995461106300354, -0.08295174688100815, -0.3705494701862335, 0.11367905139923096, -0.5232733488082886, 0.007856560871005058, -0.27022531628608704, -0.17893457412719727, -0.9458255767822266, -0.9860038757324219, 0.41334038972854614, 0.3437246084213257, 0.5713938474655151, -0.4183362126350403, -0.08227786421775818, -0.286685973405838, 0.3018317222595215, -1.1122636795043945, -0.5202459096908569, 0.6569257378578186, -0.7595740556716919, 0.16837899386882782, 0.22117337584495544, -0.11353671550750732, 0.20126010477542877, -0.7751216292381287, 1.0155010223388672, -0.681908905506134, -0.3087639808654785, 0.11028482764959335, 0.7685163021087646, -0.48479267954826355, -0.5434791445732117, 0.5336523056030273, 0.22165866196155548, -0.08811642229557037, 0.11860974133014679, 0.3012298345565796, -0.021595513448119164, -0.2936909794807434, 0.00546548655256629, 0.28572648763656616, 0.150396466255188, -0.28961336612701416, 0.7485678195953369, -0.5679960250854492, 0.18414075672626495, -1.4581516981124878, 0.4828192889690399, 0.06987527757883072, -0.8069406151771545, 0.35398468375205994, -0.8184343576431274, -0.312984436750412, 0.6146766543388367, -0.8621431589126587, -0.12488723546266556, -0.8212054371833801, 0.2873556911945343, -0.5686132311820984, 0.21456722915172577, 0.0748681128025055, 0.23608006536960602, 0.4908156096935272, 0.052303530275821686, 0.2553871273994446, -0.17158424854278564, 0.015142288990318775, 0.8323835134506226, -0.8626924157142639, 0.5936238765716553, 0.5061944723129272, 0.46646931767463684, -0.24152685701847076, -0.13037650287151337, -0.6303946375846863, -0.770038366317749, -0.587453305721283, -0.1969401240348816, -0.20607243478298187, 0.08147527277469635, -0.9015882611274719, -0.7895894050598145, -0.1751410812139511, -0.8046755194664001, -0.49788954854011536, -0.012357652187347412, -0.37396255135536194, -0.11237327009439468, -1.3480514287948608, -1.4272854328155518, -0.7872040271759033, -0.8309329152107239, -0.7903062105178833, 0.31330710649490356, 0.41288867592811584, -0.32010993361473083, -0.8021639585494995, -0.031110722571611404, -0.3156994879245758, 1.32600736618042, -0.8578277230262756, 0.7341262698173523, 0.041419338434934616, -0.5844952464103699, -0.27802082896232605, 0.08479125052690506, 0.5072041153907776, -0.5090844631195068, 0.29363009333610535, -1.243445634841919, 0.06396140158176422, -0.7455852627754211, -0.24852435290813446, 0.07926903665065765, 0.6726916432380676, 0.5160276293754578, -0.0602596290409565, -0.4160134792327881, 0.6910620927810669, 1.3741296529769897, -0.8117673397064209, 0.10313735157251358, 0.04492642357945442, 1.141218662261963, -0.08834995329380035, -0.46090787649154663, 0.20926375687122345, 0.4708082377910614, 0.25255075097084045, 0.26752734184265137, -0.2639450430870056, 0.11585816740989685, -0.7161427736282349, 0.781663715839386, 1.8302282094955444, 0.3082035779953003, 0.17737627029418945, -0.7563216090202332, 0.8257953524589539, -1.1413151025772095, -0.7137546539306641, 0.9199255704879761, 0.5902013778686523, 0.376810222864151, -0.46943676471710205, -0.2986471354961395, -0.3965209126472473, 0.1627594381570816, 0.41341283917427063, -0.4788368344306946, -0.8689316511154175, 0.09133613854646683, 0.6688209772109985, 0.2128550112247467, 0.9524966478347778, -0.014407159760594368, 0.8553630709648132, 14.540267944335938, 0.6677472591400146, -0.21673397719860077, 0.9349907636642456, 0.9646959900856018, -0.15031184256076813, -0.33543023467063904, 0.13162295520305634, -1.5677111148834229, -0.3902183175086975, 1.535017490386963, 0.36336657404899597, 1.0068283081054688, 0.08704482764005661, 0.20351353287696838, 0.5260563492774963, -0.5701172351837158, 0.6826122403144836, 0.4661833345890045, -1.0768015384674072, 0.10751838982105255, 0.14463375508785248, 0.43305543065071106, 0.9054977297782898, 0.8623453378677368, 1.2538976669311523, 0.6966131925582886, -0.4583265781402588, 0.4746372103691101, 0.4203803241252899, 0.8440122604370117, 0.10867395997047424, 0.29208266735076904, 0.3216037154197693, -1.1297359466552734, -0.46174755692481995, -0.4705524146556854, -1.09096097946167, 0.28226375579833984, 0.15110892057418823, -0.03898775577545166, -0.6477578282356262, -0.13534103333950043, 0.80568528175354, -0.11497406661510468, 0.05065102502703667, -0.126405730843544, 0.7826349139213562, -0.47157782316207886, 0.2355041205883026, 0.4597514569759369, 0.34286490082740784, -0.20646445453166962, 0.08291726559400558, -0.1389983594417572, 0.037897348403930664, 0.05804852768778801, 0.6204168796539307, -0.7329174280166626, 0.00035645722527988255, 0.06899462640285492, -0.5337388515472412, -0.01532390434294939, 1.0513811111450195, 0.5601317882537842, 0.0007259458070620894, -0.5645368099212646, 0.09550441801548004, 0.9518911242485046, 0.3874097466468811, -0.31497922539711, 0.090660959482193, 0.18733449280261993, -0.48169073462486267, 0.05075599625706673, 0.6716006994247437, 0.1479812115430832, -0.7600329518318176, -0.629335343837738, -0.30646777153015137, 0.41019678115844727, -0.923711359500885, -0.42762190103530884, 0.6656054258346558, -0.34897127747535706, -0.07033739984035492, 0.10837727785110474, -0.5696995258331299, -0.14242634177207947, 0.5632593631744385, -1.7080202102661133, -0.9271067380905151, 0.29019322991371155, -0.42488768696784973, -0.25930511951446533, 0.08026556670665741, 0.9586116671562195, 0.3888383209705353, -0.7942038774490356, 0.2473834604024887, -0.005273107439279556, -0.09025458991527557, -0.4925651550292969, -0.5281828045845032, 0.8845590353012085, 0.41629117727279663, -0.025056082755327225, 0.37273380160331726, 0.0253550224006176, 0.6969678401947021, -0.9120628833770752, 0.03428313136100769, 1.064000129699707, -0.9322823286056519, -0.13451343774795532, -0.927369236946106, -0.7233087420463562, 0.8837572932243347, 0.4834613800048828, 0.1388680636882782, 0.18177732825279236, 0.47917068004608154, -0.8739926815032959, -0.4723532199859619, -0.3238433003425598, -0.13348200917243958, 0.44892171025276184, -1.0158476829528809, -0.14285646378993988, -0.12646090984344482, 0.7126113176345825, -0.8913001418113708, -0.4719376266002655, -0.3962024450302124, 0.15597407519817352, 0.29603829979896545, 0.9708034992218018, -0.5632804036140442, 0.506401538848877, 1.125897765159607, -0.16741491854190826, -0.5368067026138306, -0.1437155306339264, -1.0791923999786377, -0.32515695691108704, 0.3785651624202728, 0.48471710085868835, -0.4964675307273865, 0.08018404990434647, 0.6807069778442383, 0.3548237979412079, -0.6034059524536133, -0.6772741675376892, -0.11434875428676605, 0.0905269905924797, -0.6440039873123169, 0.056588780134916306, 0.0747634768486023, -0.035198695957660675, 0.5175530314445496, 0.39392581582069397, 0.5312564373016357, -0.3509538769721985, -0.6594089269638062, 0.2946360111236572, 0.007875482551753521, -0.18843093514442444, -0.5711264610290527, -0.519852340221405, -1.5307403802871704, 0.16044139862060547, -1.3462527990341187, -0.10272764414548874, -0.8509684801101685, -0.11085629463195801, -0.04375056177377701, -0.46791571378707886, 0.26724773645401, 0.15434792637825012, -0.199002206325531, -0.18486453592777252, -0.7733985781669617, -0.7999265193939209, 0.8803000450134277, 0.4995007812976837, -0.6453259587287903, -0.02729465253651142, 0.11377786844968796, -0.00030173774575814605, 0.17309442162513733, 0.22795425355434418, -0.34434112906455994, -0.7954296469688416, -1.1391834020614624, 0.7309547066688538, -0.16925393044948578, -0.11644898355007172, -0.4656361937522888, 0.5297860503196716, 0.2861587703227997, -0.42229729890823364, 0.13184486329555511, 0.3427664041519165, -0.8868812322616577, -0.5022514462471008, 0.22731813788414001, -0.8435966372489929, 0.3432264029979706, 0.34642812609672546, -0.5976636409759521, -0.18754032254219055, 0.8445065021514893, 0.19139902293682098, -0.904972493648529, -0.5105347633361816, 0.39845964312553406, -0.5906307697296143, 0.0821738913655281, -0.6050820350646973, 0.10246681421995163, -1.0164508819580078, -0.514549970626831, 0.005038706585764885, 0.49809005856513977, -0.6823188662528992, 0.9491849541664124, 0.07947540283203125, -1.127368450164795, 0.11683540791273117, 0.34419572353363037, -0.1978565901517868, 0.2347468137741089, 0.38561326265335083, 0.556159496307373, -0.26216015219688416, 0.8042147755622864, 0.5905457735061646, 0.2485111504793167, -0.9241401553153992, 0.18387587368488312, 0.9875218868255615, -0.8516625761985779, -0.18653172254562378, 1.2575798034667969, -0.09997647255659103, -1.3469427824020386, 0.2867071032524109, -1.4547072649002075, -0.432685524225235, -0.28606483340263367, 0.4523196518421173, -0.08519165217876434, -0.19193971157073975, 0.03009055182337761, -0.44993576407432556, 0.39559656381607056, 0.11966316401958466, -0.2716843783855438, 0.9223170280456543, -0.269581139087677, -0.546515166759491, 0.9510415196418762, 1.2908227443695068, -0.7022972106933594, -0.5093373656272888, -1.1702485084533691, -0.5758030414581299, 0.2572482228279114, 0.6586596369743347, -0.12742391228675842, -0.8940756320953369, 0.8561810255050659, 0.6426766514778137, 0.2195410579442978, 0.3524113893508911, 0.15646643936634064, -0.16980352997779846, 0.8190121650695801, -0.13875095546245575, -0.652931272983551, -0.5717287063598633, 1.2548240423202515, 1.0182727575302124, -0.8264545798301697, 0.49375250935554504, -0.15532007813453674, -0.4713311195373535, 0.6229937076568604, 0.15350697934627533, -0.15440599620342255, 0.9957961440086365, -0.2594677209854126, 0.23546357452869415, 0.22501535713672638, -1.499794363975525, -0.3272712528705597, 0.7493413686752319, 0.49370309710502625, 0.9244092702865601, 0.2841704487800598, 0.3802528381347656, 0.6915799379348755, 0.12857094407081604, -0.07870086282491684, 0.08057569712400436, 0.3004201650619507, -0.136834055185318, 0.19529440999031067, 0.07714605331420898, 0.513666033744812, -0.7329067587852478, -0.7082707285881042, 0.4115546643733978, 0.28610488772392273, -0.07637908309698105, 0.48855042457580566, 1.0912606716156006, 0.4875871539115906, 0.6355568766593933, 0.2157440036535263, 0.3743791878223419, -0.4178835451602936, -0.24644030630588531, 0.02857791818678379, -0.7698146104812622, -0.3450215458869934, -0.11080750823020935, -0.3413897156715393, -0.2707633078098297, -0.1772061139345169, 0.09666069597005844, -0.29034432768821716, 0.3865278363227844, 1.2705022096633911, 0.2949182689189911, 0.8580278158187866, -0.1662835329771042, -0.7628671526908875, -0.33083266019821167, -0.8502586483955383, 0.20193129777908325, -0.6065216064453125, 0.08745747804641724, 0.26507338881492615, -0.23959259688854218, -0.30686187744140625]}, "authors": [{"authorId": "72847120", "name": "Jean-Pierre Mercat"}, {"authorId": "2291068185", "name": "Igor Vasiljevic"}, {"authorId": "150299584", "name": "Sedrick Scott Keh"}, {"authorId": "2284685268", "name": "Kushal Arora"}, {"authorId": "2298523", "name": "Achal Dave"}, {"authorId": "2143070716", "name": "Adrien Gaidon"}, {"authorId": "2283843631", "name": "Thomas Kollar"}], "references": [{"paperId": "3fd5bc3077d04965eaa3498372c39bbdd09d55e4", "title": "Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention"}, {"paperId": "d53fe76bd2795a19ddf52d012917782f6f6f2c1e", "title": "Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models"}, {"paperId": "f4a0c4154203808f362e4678f3741b3d317fdc82", "title": "The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry"}, {"paperId": "85447eeb6e5276e713957835125a2273f9ac0694", "title": "In-Context Language Learning: Architectures and Algorithms"}, {"paperId": "7294c426b8a95975ca932eaf8f700acdd3d950b2", "title": "Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "db633c6b1c286c0386f0078d8a2e6224e03a6227", "title": "Mistral 7B"}, {"paperId": "02ad9f3fefe33cb9ca546591bec65dbdf7766c80", "title": "Ring Attention with Blockwise Transformers for Near-Infinite Context"}, {"paperId": "819bbdc2dac9e13d9ca3e2508a6e063186ce5e40", "title": "YaRN: Efficient Context Window Extension of Large Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "240103933ffe3dac2179cc160a2bd91299357a53", "title": "Retentive Network: A Successor to Transformer for Large Language Models"}, {"paperId": "7a1e71cb1310c4a873e7a4e54d1a6dab0553adce", "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200", "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints"}, {"paperId": "998ac3e945857cf2676ee7efdbaf443a0c6f820a", "title": "Hyena Hierarchy: Towards Larger Convolutional Language Models"}, {"paperId": "379e42895f6d40ab9e9559609f505aba89145a5d", "title": "Efficiently Scaling Transformer Inference"}, {"paperId": "e3fc46d5f4aae2c7a8a86b6bd21ca8db5d40fcbd", "title": "The Devil in Linear Transformer"}, {"paperId": "c49ac1f916d6d2edeb187e6619c8d23acd95eb21", "title": "cosFormer: Rethinking Softmax in Attention"}, {"paperId": "6281c40c66febca1d8003bcc6fdfd2189b30c38f", "title": "SCROLLS: Standardized CompaRison Over Long Language Sequences"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "af679d69fcc1d0fcf0f039aba937853bcb50a8de", "title": "Luna: Linear Unified Nested Attention"}, {"paperId": "d5e999aae76d5270ef272076979c809817458212", "title": "An Attention Free Transformer"}, {"paperId": "4e3935ef7da6bcbb202ec7f8b285c313cadcd044", "title": "A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "054e307c1edf4b28137ffcbce980fe81f0647d20", "title": "Finetuning Pretrained Transformers into RNNs"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "84c8c8bcbe8033cb9034bda61bd65ae60a22dae2", "title": "Higher Order Linear Transformer"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "661d142c23cb2a3207d5f1ba2ac7ff61f2d4fb2f", "title": "Triton: an intermediate language and compiler for tiled neural network computations"}, {"paperId": "d08b35243edc5be07387a9ed218070b31e502901", "title": "Group Normalization"}, {"paperId": "d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a", "title": "The NarrativeQA Reading Comprehension Challenge"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": null, "title": "Recurrentgemma"}, {"paperId": null, "title": "Hun-gry hungry hippos: Towards language modeling with state space models"}, {"paperId": null, "title": "A framework for few-shot language model evaluation"}, {"paperId": null, "title": "Gpt-neox-20b"}, {"paperId": null, "title": "Dynamically scaled rope further increases strength of retaining walls, 2023"}]}