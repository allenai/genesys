{"paperId": "61ae335f89b2ecc9736fba81b074660882c6347c", "title": "UNIREX: A Unified Learning Framework for Language Model Rationale Extraction", "abstract": "An extractive rationale explains a language model\u2019s (LM\u2019s) prediction on a given task instance by highlighting the text inputs that most influenced the prediction. Ideally, rationale extraction should be faithful (reflective of LM\u2019s actual behavior) and plausible (convincing to humans), without compromising the LM\u2019s (i.e., task model\u2019s) task performance. Although attribution algorithms and select-predict pipelines are commonly used in rationale extraction, they both rely on certain heuristics that hinder them from satisfying all three desiderata. In light of this, we propose UNIREX, a flexible learning framework which generalizes rationale extractor optimization as follows: (1) specify architecture for a learned rationale extractor; (2) select explainability objectives (i.e., faithfulness and plausibility criteria); and (3) jointly the train task model and rationale extractor on the task using selected objectives. UNIREX enables replacing prior works\u2019 heuristic design choices with a generic learned rationale extractor in (1) and optimizing it for all three desiderata in (2)-(3). To facilitate comparison between methods w.r.t. multiple desiderata, we introduce the Normalized Relative Gain (NRG) metric. Across five English text classification datasets, our best UNIREX configuration outperforms the strongest baselines by an average of 32.9% NRG. Plus, we find that UNIREX-trained rationale extractors\u2019 faithfulness can even generalize to unseen datasets and tasks.", "venue": "BIGSCIENCE", "year": 2021, "citationCount": 34, "influentialCitationCount": 6, "openAccessPdf": {"url": "https://aclanthology.org/2022.bigscience-1.5.pdf", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "UNIREX, a flexible learning framework which generalizes rationale extractor optimization as follows, and introduces the Normalized Relative Gain (NRG) metric, which finds that UNIREX-trained rationale extractors\u2019 faithfulness can even generalize to unseen datasets and tasks."}, "embedding": {"model": "specter_v2", "vector": [0.09452533721923828, 0.4216633141040802, -0.6318056583404541, -0.14696921408176422, -0.6143649220466614, -0.11519571393728256, 0.7549796104431152, -0.41248857975006104, -0.2898775339126587, 0.3275463581085205, 0.644154965877533, -0.45379215478897095, -0.048615194857120514, 0.6948585510253906, 0.39331117272377014, 0.24879594147205353, -0.38859355449676514, 0.35050657391548157, -0.5499894618988037, -0.2805328965187073, 0.21055926382541656, -0.7077426910400391, -0.35322803258895874, 0.017517080530524254, 0.06927014142274857, 0.016483042389154434, 0.33198586106300354, 1.049479365348816, -0.5368311405181885, 0.30435308814048767, 0.42471542954444885, -0.4564724862575531, -0.2085057646036148, 0.2210693657398224, -0.6719900965690613, 0.2406713366508484, -0.12703564763069153, -0.5561478137969971, -0.49383819103240967, 0.19075217843055725, -0.16310074925422668, -0.09686091542243958, 1.0851902961730957, -0.9003281593322754, -0.3446537256240845, 1.2893463373184204, 0.5445129871368408, 0.7589125633239746, -0.5794905424118042, -0.4451809525489807, 1.7225632667541504, -1.7481510639190674, 0.23307186365127563, 0.9198278784751892, 0.1818409115076065, 0.5947043299674988, -0.3846166431903839, -0.7206253409385681, 0.7631248831748962, -0.07526878267526627, -0.9314089417457581, -0.4322109520435333, 0.10524511337280273, -0.5361353158950806, 1.8864350318908691, -0.5118620991706848, -0.864815354347229, 0.8667222857475281, 0.07847470790147781, 1.7493371963500977, -0.08041965216398239, -0.9803540706634521, -0.47073638439178467, 0.06640531122684479, 0.20540037751197815, 0.5275511741638184, -0.5169036984443665, -0.03846641257405281, -1.0154539346694946, -0.07228647917509079, 0.4497758746147156, -0.4487040638923645, -0.3544502258300781, 0.2433951050043106, -0.22282984852790833, 0.8527643084526062, 0.3067043125629425, 1.0451555252075195, -0.051741816103458405, 0.7974812388420105, 0.20821857452392578, -0.00534296128898859, -0.11579515039920807, 0.5940539240837097, -0.6698338985443115, 0.5940695405006409, -0.8467326760292053, 0.20131036639213562, -0.1078520193696022, 0.8127821087837219, -0.2990478575229645, 0.5558425188064575, -0.9552382826805115, 0.2936510741710663, 1.6089706420898438, -0.21205265820026398, 1.0398362874984741, -0.3245963454246521, 0.722328245639801, -0.5759313702583313, 0.38072216510772705, -0.39058753848075867, -0.5942345857620239, -0.5654444694519043, -0.21992255747318268, -1.1006028652191162, -0.6368093490600586, -0.1886831820011139, -0.5575497150421143, 0.9186121225357056, -0.7269806265830994, -0.48117855191230774, 0.13419310748577118, 0.5561134219169617, 0.675138533115387, 0.20990248024463654, 0.5479564666748047, 0.19018100202083588, 0.5237834453582764, -0.7208551168441772, -0.6413547992706299, -1.4612613916397095, 0.9461109638214111, -0.7112691402435303, 0.5081803202629089, -0.47187769412994385, -0.6922301650047302, -0.9062356948852539, -0.9741137623786926, -0.046203114092350006, -0.13094520568847656, 1.1551251411437988, 1.2053252458572388, 0.370048463344574, -0.828813374042511, 0.7177408933639526, 0.3328322768211365, 0.24831610918045044, -0.12855879962444305, 0.19358573853969574, 0.3672462999820709, -0.2951207160949707, -1.2090154886245728, 0.17958444356918335, 0.47904229164123535, -0.5871771574020386, -0.24021928012371063, -0.2421984076499939, -0.7586366534233093, -0.21233628690242767, 0.43639686703681946, -0.9471344947814941, 1.5678590536117554, -0.355875164270401, -1.2759642601013184, 0.648811399936676, -0.15939944982528687, 0.5902159214019775, 0.37411031126976013, -0.367920458316803, -0.6827824711799622, -0.903654158115387, 0.18142935633659363, 0.6383756995201111, 0.5849595069885254, -0.27777165174484253, -0.5254592895507812, 0.544511616230011, -0.3060833215713501, 0.11468754708766937, -0.46667057275772095, 0.5074840784072876, -0.5731890201568604, -0.5313230752944946, 0.11715800315141678, 0.7320206761360168, 0.20710262656211853, -0.5294146537780762, -0.7510292530059814, -1.3006736040115356, 0.6052351593971252, -0.32421329617500305, 1.2092583179473877, -0.4793097674846649, -0.605506181716919, -0.24432684481143951, 0.3125440180301666, -0.36076295375823975, -0.6136690378189087, 0.5888963937759399, -0.515628457069397, 0.9555013179779053, -0.18946200609207153, -1.3345907926559448, 0.15700720250606537, -0.46323496103286743, -0.705155611038208, -0.5425878763198853, 0.11104804277420044, 1.087538480758667, -0.5226267576217651, 0.011860725469887257, 0.009229734539985657, 0.2772481441497803, -0.37063679099082947, 1.1429091691970825, -0.33342164754867554, -0.14350338280200958, -0.8169084191322327, -0.3735540211200714, -0.14943188428878784, -0.6055753827095032, 0.4810614585876465, -0.20368485152721405, -0.19934508204460144, 0.503852367401123, -0.288858562707901, 1.4589464664459229, -0.6887050271034241, 0.8386635184288025, -0.5200896263122559, 0.18481017649173737, 0.16026721894741058, 0.782156765460968, -0.36032113432884216, 0.026045169681310654, 0.4060766100883484, 0.9710774421691895, -0.8390876054763794, -0.039162833243608475, 0.6610540747642517, 0.41886982321739197, -0.22291609644889832, 0.46520012617111206, 0.5505918860435486, -0.07846198976039886, 0.2611583471298218, 0.23201687633991241, 0.8204658031463623, 0.7506797313690186, 0.6413331031799316, -0.20016832649707794, 0.5398942828178406, -0.6102718114852905, -0.539961576461792, 0.2704527676105499, 1.0229835510253906, 0.7449967861175537, -0.1109078973531723, -0.6766079068183899, 0.1002860963344574, 0.09778784215450287, 0.7169896960258484, 1.5868504047393799, -0.22527241706848145, -0.5403708815574646, -0.4283946454524994, -0.6723646521568298, -0.39784616231918335, 0.7383982539176941, -0.6267133355140686, -0.06899387389421463, -0.16187022626399994, -1.2836259603500366, 0.562275767326355, 0.47592660784721375, 0.8006394505500793, -0.2429053783416748, 0.20017220079898834, 0.1456974297761917, -0.48872965574264526, -0.7970314621925354, -0.5580496191978455, 0.5575513243675232, -0.6286786794662476, -0.1795208901166916, 0.27470770478248596, 0.3689824342727661, -0.02318522520363331, -0.38699427247047424, 1.0542138814926147, 0.07430003583431244, -0.22807714343070984, 0.1624004989862442, 0.6212355494499207, -0.4612638056278229, -0.44489723443984985, 0.4032895565032959, 0.0892011895775795, -0.2353830337524414, 0.38889819383621216, 0.8497391939163208, 0.31016963720321655, 0.3635405898094177, -0.381194144487381, 0.5948397517204285, 0.27608954906463623, 0.04435141384601593, 0.46126696467399597, -0.05997055396437645, 0.01082941610366106, -0.9300526976585388, 1.2264256477355957, -0.1591963917016983, 0.054271526634693146, 0.3273991048336029, -0.9412323236465454, 0.011514697223901749, 0.4292450249195099, -0.29036059975624084, -0.46355557441711426, -1.0993062257766724, 0.710692822933197, -0.10525931417942047, -0.1962968111038208, 0.41832056641578674, 0.22924448549747467, 0.541925847530365, 0.39903655648231506, 0.1311134696006775, -0.21542149782180786, -0.4266365170478821, 0.5701937079429626, -0.49725019931793213, 0.03125753626227379, 0.08225450664758682, 0.33837318420410156, -0.6437751054763794, -0.41750022768974304, -0.4391467273235321, -0.7350279688835144, -0.3954221308231354, -0.14628279209136963, -0.4266546964645386, 0.2583281099796295, -0.4854091703891754, -0.4713510572910309, -0.5854709148406982, -1.279113531112671, -0.035804931074380875, 0.6409323215484619, -0.20518481731414795, -0.18178100883960724, -1.7714482545852661, -0.8706892132759094, -0.5525566935539246, -0.34465816617012024, -1.0872607231140137, 0.5298147797584534, 0.015214411541819572, -0.7586841583251953, -1.2017396688461304, -0.2416800558567047, 0.28325942158699036, 0.8570855855941772, -0.6882315278053284, 1.2257319688796997, -0.08408725261688232, -0.16325348615646362, -0.05572078749537468, 0.1250489205121994, 0.00925019197165966, 0.15740394592285156, 0.30430158972740173, -1.355757474899292, 0.4098673164844513, 0.013987516984343529, -0.3502448797225952, 0.06320105493068695, 0.41078534722328186, 0.8285166025161743, 0.004366453271359205, -0.871617317199707, 0.07672594487667084, 1.6746504306793213, -1.053715705871582, -0.2642410099506378, 0.5564672946929932, 1.083456039428711, 0.6022801995277405, -0.44655343890190125, 0.44055426120758057, 0.4799348711967468, 0.808167576789856, 0.1484648436307907, -0.37102797627449036, -0.37480428814888, -0.6310521960258484, 0.4699767231941223, 1.250998854637146, -0.09016437083482742, -0.3250315189361572, -1.3268251419067383, 0.18477357923984528, -1.4031686782836914, -0.06577259302139282, 0.2114948183298111, 0.6560041904449463, 0.5692170858383179, -0.24865055084228516, -0.630649209022522, 0.06497408449649811, 0.4861161708831787, -0.28493359684944153, -0.0600818507373333, -0.20255669951438904, 0.35760995745658875, -0.18806405365467072, 0.05644899234175682, 0.8150323033332825, -0.5336852073669434, 0.44306910037994385, 14.256060600280762, 0.9200535416603088, -0.006735020317137241, 0.5968446135520935, 0.87291020154953, 0.3464527130126953, -0.7596787214279175, -0.2865213453769684, -1.5340453386306763, -0.5620966553688049, 0.9659686088562012, -0.0536765493452549, 0.21377219259738922, 0.24257709085941315, 0.11341893672943115, 0.6032586693763733, -0.531772255897522, 0.7883489727973938, 0.6472786664962769, -1.056580662727356, 0.7652341723442078, 0.23965737223625183, 0.14552155137062073, 0.15562622249126434, 0.756308376789093, 0.9845868349075317, 0.47790852189064026, -0.8106004595756531, 0.8092912435531616, -0.2833665907382965, 0.553852915763855, 0.1205567792057991, 0.5516415238380432, 0.45292386412620544, -0.8305753469467163, -0.2838658392429352, -0.3574422001838684, -0.9179786443710327, -0.08095499128103256, 0.3179853558540344, -1.3671761751174927, -0.1784364879131317, -0.7097201347351074, 0.45669981837272644, -0.15265193581581116, -0.18687449395656586, -0.9706913232803345, 0.8013004064559937, 0.5797379016876221, 0.04177875444293022, 0.23440603911876678, 1.2660932540893555, 0.44595828652381897, -0.05121036246418953, -0.0863000676035881, -0.43207618594169617, 0.1094837486743927, 0.4802546799182892, -0.9972788095474243, 0.38216787576675415, -0.15613438189029694, -0.08386028558015823, -0.09958487004041672, 1.1837680339813232, -0.01440383680164814, 0.6825742125511169, -0.20450644195079803, 0.21428315341472626, 0.8118259310722351, 0.3638703227043152, -0.17778857052326202, 0.3565618693828583, 0.18703213334083557, -0.2907520532608032, -0.49457165598869324, 0.3959956169128418, -0.4559866487979889, -0.6785118579864502, -0.761894702911377, -0.28429359197616577, 0.4271449148654938, -1.171964168548584, -1.1305807828903198, 0.8495092391967773, -0.22781780362129211, -0.6961292028427124, -0.07794161885976791, -1.0920006036758423, -0.21757416427135468, 0.6137034893035889, -1.8359577655792236, -0.9484513998031616, 0.2742615044116974, -0.308994859457016, 0.2568322420120239, -0.30685508251190186, 1.1981947422027588, -0.3861558735370636, -0.5126219391822815, -0.18834491074085236, -0.1483253687620163, -0.08871348202228546, 0.30342167615890503, -1.0811634063720703, 0.36942899227142334, 0.11392603069543839, 0.11971312016248703, 0.555109977722168, 0.17346647381782532, -0.1341935247182846, -0.4463854134082794, -0.33262914419174194, 1.0596957206726074, -1.2636098861694336, -0.2871147692203522, -0.4158001244068146, -0.5472248196601868, 0.16945530474185944, 0.5402066111564636, -0.7928206920623779, 1.0653654336929321, 0.7114507555961609, -0.6704389452934265, 0.43041497468948364, -0.5073785781860352, 0.3847106397151947, 0.40005332231521606, -0.3619403541088104, -0.5434223413467407, 0.35101279616355896, 0.04365495592355728, -0.7591352462768555, -0.027088545262813568, -0.6661145687103271, -0.2967453896999359, 0.5179488658905029, 0.6397190093994141, -0.8372997641563416, 1.2289986610412598, 0.493194580078125, -0.44830596446990967, -1.0971509218215942, -0.5005856156349182, -0.9407747983932495, 0.35238760709762573, 0.23019786179065704, 1.6026853322982788, -0.09646949917078018, -0.4502646028995514, 1.3438535928726196, 0.2826959788799286, -0.035739973187446594, -0.4061260223388672, -0.13634072244167328, 0.1859274059534073, -0.5545466542243958, 0.2592710852622986, 0.1471531093120575, -0.16417378187179565, 0.6368256211280823, 0.3181821405887604, 0.6318907141685486, 0.02253986895084381, -0.5390876531600952, 0.3641362190246582, -0.36738118529319763, -0.2338697761297226, -0.8395801782608032, 0.09740795940160751, -0.9232203960418701, 0.2497095912694931, -1.4281045198440552, 0.21885916590690613, -1.3102903366088867, -0.35451704263687134, -0.07763565331697464, -0.2952348589897156, 0.6076475977897644, -0.11329151690006256, -0.5235790014266968, -0.6116681098937988, 0.043900713324546814, -0.08322679251432419, 0.739185094833374, 0.6770938634872437, -0.39230382442474365, 0.11768760532140732, -0.1729063242673874, -0.636607825756073, 0.4266413152217865, 0.6161486506462097, -0.7257936596870422, -1.044478416442871, -1.746389389038086, 0.5956982374191284, 0.05360504984855652, -0.16307586431503296, -0.35875600576400757, 0.4085586369037628, 0.028948917984962463, 0.32871487736701965, 0.7266291379928589, -0.026378294453024864, -0.8462066650390625, -0.5345026254653931, -0.025952404364943504, -1.063968539237976, 0.2534756064414978, 0.226309135556221, -0.6381769180297852, 0.03888869658112526, -0.003150913631543517, -0.40832963585853577, -0.800351619720459, -0.6463479399681091, 0.4186667799949646, -0.6102627515792847, 0.03565871715545654, -0.4434262812137604, -0.032520998269319534, -1.0549715757369995, -0.1573317050933838, 0.4628361165523529, 0.363768070936203, -0.576270341873169, 1.401929259300232, 0.5059913992881775, -1.2091822624206543, -0.286531537771225, -0.14298488199710846, 0.020450927317142487, -0.5864009857177734, 0.26173296570777893, 0.10806476324796677, 0.109471894800663, 0.6201040744781494, 0.36746615171432495, 0.3799584209918976, -0.7069019079208374, -0.6511402726173401, 0.9112116098403931, -0.6908242106437683, -0.13451145589351654, 1.210492491722107, -0.12299184501171112, -0.8992665410041809, -0.38323742151260376, -0.671411395072937, -0.8271703720092773, -0.5341019034385681, 0.8671118021011353, -0.03475220873951912, 0.2617219090461731, 0.17195911705493927, -0.4237559735774994, 0.006147592794150114, -0.3360971510410309, -0.8814066648483276, 0.49270161986351013, -0.44640010595321655, 0.18226374685764313, 0.5777098536491394, 0.4596920609474182, -0.46697279810905457, -0.6430832147598267, -0.19764301180839539, 0.17008307576179504, -0.12798501551151276, 0.9442909359931946, -0.8745203018188477, -0.640905499458313, 0.5841222405433655, -0.09813647717237473, -0.10195943713188171, 0.09186934679746628, -0.4740971624851227, -0.37755995988845825, 0.32429954409599304, 0.11316259205341339, -0.7669535279273987, -0.3867849111557007, 1.0589964389801025, 1.7732793092727661, -0.9549289345741272, 0.2627266049385071, -0.07806307077407837, -0.8486610054969788, 1.6122033596038818, 0.6203706860542297, 0.7239266037940979, 0.6314611434936523, -0.09741490334272385, 0.23635371029376984, -0.03038567118346691, -1.1674318313598633, 0.05938651040196419, 1.0047348737716675, 1.081112265586853, 1.5158543586730957, 0.41893965005874634, 0.00941078644245863, 1.2906138896942139, 0.07000064104795456, 0.3993510901927948, 1.0528894662857056, 0.48947516083717346, -0.12303207069635391, -0.23052296042442322, 0.09429839253425598, 0.4993373155593872, -0.5519235134124756, -0.5787042379379272, -0.13912366330623627, 0.6203046441078186, 0.022946186363697052, 0.8554973602294922, -0.1331576406955719, 0.015386492945253849, 0.31628379225730896, 0.6571100354194641, 0.09919745475053787, -0.6108443140983582, -0.3428628742694855, -0.23700173199176788, -0.309670627117157, 0.1646798849105835, -0.17261025309562683, -0.07857213914394379, -0.7869503498077393, 0.0996658056974411, 0.11577294766902924, -0.21009092032909393, 0.8679063320159912, 1.489094614982605, 0.3545541763305664, 0.6135995984077454, -0.19747336208820343, -0.2694394886493683, -0.15448835492134094, -1.1354501247406006, 0.08441430330276489, -0.9473616480827332, -0.39282387495040894, -0.6909801363945007, -0.45611444115638733, 0.26348087191581726]}, "authors": [{"authorId": "2114015857", "name": "Aaron Chan"}, {"authorId": "2095979", "name": "Maziar Sanjabi"}, {"authorId": "36299222", "name": "Lambert Mathias"}, {"authorId": "48327785", "name": "L Tan"}, {"authorId": "35557488", "name": "Shaoliang Nie"}, {"authorId": "2602530", "name": "Xiaochang Peng"}, {"authorId": "1384550891", "name": "Xiang Ren"}, {"authorId": "22593971", "name": "Hamed Firooz"}], "references": [{"paperId": "dc1909cb3d1913f92d45ed5a7fbe95179befbdc3", "title": "Improving Deep Learning Interpretability by Saliency Guided Training"}, {"paperId": "9dc28baf794cbd1d5f24eb91b55f94871aa52d1d", "title": "Understanding Interlocking Dynamics of Cooperative Rationalization"}, {"paperId": "bebb3a214c9c0eab2099f1b7f5824bbf73726ec7", "title": "Self-training with Few-shot Rationalization"}, {"paperId": "5710567c482376c3c7c559062e884492090f7aca", "title": "Discretized Integrated Gradients for Explaining Language Models"}, {"paperId": "a9ec8eae66d6e7a8517eef0a4060ba9d45706f41", "title": "SalKG: Learning From Knowledge Graph Explanations for Commonsense Reasoning"}, {"paperId": "7fa273f450251523e6b7fcc2eb3fdbdfd4a30493", "title": "CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in NLP"}, {"paperId": "15d8e512e2091925f73fdb5615d99cfdf24d8ecf", "title": "Efficient Explanations from Empirical Explainers"}, {"paperId": "97fcbad1088e219621b72ef928b2e3824c46bbd7", "title": "Local Interpretations for Explainable Natural Language Processing: A Survey"}, {"paperId": "ca2f1088d3e581b2c6c75cf0ebc96506d620f64d", "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? \ud83e\udd9c"}, {"paperId": "17d4681b29b79c4ee5029ae39acabfdf9946bd77", "title": "FiD-Ex: Improving Sequence-to-Sequence Models for Extractive Rationale Generation"}, {"paperId": "2232808cf3161ca4c434126e35f47ee33c0c8219", "title": "Evaluating Explanations: How Much Do Explanations from the Teacher Aid Students?"}, {"paperId": "508884a136a461869be128027950d2aa1778518c", "title": "The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?"}, {"paperId": "087087d91598aa62a11061ed156f8f6e699a7930", "title": "Evaluating and Characterizing Human Rationales"}, {"paperId": "8c3babcb113081d0c4cfdfbd6fb3518a595892c9", "title": "Captum: A unified and generic model interpretability library for PyTorch"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6fd0e9572d7c7d726b5ec68b0c455b686f648585", "title": "NILE : Natural Language Inference with Faithful Natural Language Explanations"}, {"paperId": "c9aeb7e31b16b7273a80ae748b3ff48105928147", "title": "An Information Bottleneck Approach for Controlling Conciseness in Rationale Extraction"}, {"paperId": "cffd8f947ba03644f62baea31c64c8920b06288e", "title": "Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?"}, {"paperId": "922e6e3bafe38a712597c05d3a907bd10763b427", "title": "Learning to Faithfully Rationalize by Construction"}, {"paperId": "b2a839e3ee68e81b863b73ee08c6626c94477fef", "title": "WT5?! Training Text-to-Text Models to Explain their Predictions"}, {"paperId": "579476d19566efc842929ea6bdd18ab760c8cfa2", "title": "Towards Faithfully Interpretable NLP Systems: How Should We Define and Evaluate Faithfulness?"}, {"paperId": "adc61e21eafecfbf6ebecc570f9f913659a2bfb2", "title": "Deep Learning--based Text Classification"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "087dd95e13efd47aef2a6582e6801b39fc0f83d8", "title": "ERASER: A Benchmark to Evaluate Rationalized NLP Models"}, {"paperId": "ae182cca456e3b265e2fbb69f16db950f53fd410", "title": "Rethinking Cooperative Rationalization: Introspective Extraction and Complement Control"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "874e9318c09c711ecd48a903b3824a3a03e2cd62", "title": "Explain Yourself! Leveraging Language Models for Commonsense Reasoning"}, {"paperId": "46bfca498faf4964b693e3cb70e17389075168d2", "title": "Do Human Rationales Improve Machine Explanations?"}, {"paperId": "64ffb253d20ee12114a8d15d01404bd17ae99220", "title": "Interpretable Neural Predictions with Differentiable Binary Variables"}, {"paperId": "d5264eb05df3dd108ce96fa932368eefe9b25fee", "title": "SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (OffensEval)"}, {"paperId": "c242438dac5aa4d9b13766c14240bb8426690d58", "title": "e-SNLI: Natural Language Inference with Natural Language Explanations"}, {"paperId": "bc00ff34ec7772080c7039b17f7069a2f7df0889", "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead"}, {"paperId": "1083ca53df2fb3df1d0df22fd39966bc9fba7f94", "title": "Hate Speech Dataset from a White Supremacy Forum"}, {"paperId": "5f614777d25efd14b7426e99cb2544f2d6be133e", "title": "A Benchmark for Interpretability Methods in Deep Neural Networks"}, {"paperId": "901c011dd14950c1f14dba5b6b4d17673be3a669", "title": "SemEval-2018 Task 3: Irony Detection in English Tweets"}, {"paperId": "99ad0533f84c110da2d0713d5798e6e14080b159", "title": "Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences"}, {"paperId": "ec6d889a96ec1ef379b388633ddf97e6de9a0ead", "title": "Evaluating neural network explanation methods using hybrid documents and morphological agreement"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "442e10a3c6640ded9408622005e3c2a8906ce4c2", "title": "A Unified Approach to Interpreting Model Predictions"}, {"paperId": "1a2118bed729579528deb51e745d58dd3629baf6", "title": "Learning Important Features Through Propagating Activation Differences"}, {"paperId": "f302e136c41db5de1d624412f68c9174cf7ae8be", "title": "Axiomatic Attribution for Deep Networks"}, {"paperId": "5c39e37022661f81f79e481240ed9b175dec6513", "title": "Towards A Rigorous Science of Interpretable Machine Learning"}, {"paperId": "4c41104e871bccbd56494350a71d77a7f1da5bb0", "title": "Understanding Neural Networks through Representation Erasure"}, {"paperId": "467d5d8fc766e73bfd3e9415f75479823f92c2f7", "title": "Rationalizing Neural Predictions"}, {"paperId": "9462eee3e5eff15df5e97c38e24072c65e581cee", "title": "Representation of Linguistic Form and Function in Recurrent Neural Networks"}, {"paperId": "51a55df1f023571a7e07e338ee45a3e3d66ef73e", "title": "Character-level Convolutional Networks for Text Classification"}, {"paperId": "fafa541419b3756968fe5b3156c6f0257cb29c23", "title": "Visualizing and Understanding Neural Models in NLP"}, {"paperId": "c52acb4e4143ace520166691a29faaeaf892ac47", "title": "Extraction of Salient Sentences from Labelled Documents"}, {"paperId": "dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71", "title": "Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps"}, {"paperId": "665f89a20b05472d82df0a12f2dd63e8fcc4f3ea", "title": "Hidden factors and hidden topics: understanding rating dimensions with review text"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "14e2aec7e25d8880a851a547cf8d27a9721f8e6c", "title": "Modeling Annotators: A Generative Approach to Learning from Annotator Rationales"}, {"paperId": "0ea9df70ae9e4c9c4e99e0e53046eb041c18f2cf", "title": "Learning to Explain: Generating Stable Explanations Fast"}, {"paperId": null, "title": "Multi-Choice QA Instead of a fixed label space, multichoice QA has a different (but fixed-size) set of answer choices per instance. For instance i, let qi be the question"}, {"paperId": null, "title": "for all ( x i , y \u2217 i )"}, {"paperId": null, "title": "2021) addressed the optimization issue by regularizing the task model to yield faithful rationales via the AA, while other works (Situ et al., 2021"}, {"paperId": null, "title": "Connection to UNIREX Unlike prior works, UNIREX enables both the task model and rationale extractor to be jointly optimized for faithfulness, plausibility, and task performance"}, {"paperId": null, "title": "Related Work Faithfulness Many prior works have tried to improve the faithfulness of extractive rationales through the use of AAs (Bastings & Filippova, 2020)"}, {"paperId": null, "title": "requiring only one forward pass) to mimic an AA\u2019s behavior. Another line of work aims to produce faithful rationales by construction, via SPPs (Jain et al., 2020"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "c21a4d70d83e0f6eb2a9e1c41d034842dd561e47", "title": "CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge"}, {"paperId": null, "title": "The PyTorch Lightning team"}, {"paperId": null, "title": "Gold Rationale Supervision If a learned rationale extractor is chosen, UNIREX enables users to specify how much gold rationale supervision to use"}, {"paperId": null, "title": "2017; Li et al., 2015) or perturbation-based (Li et al., 2016"}, {"paperId": null, "title": "Ablation Studies We present five ablation studies to validate the effectiveness of our UNIREX design choices. The results of these ablation studies"}, {"paperId": null, "title": "Aitor Garc\u00eda-Pablos, and Montse Cuadros"}, {"paperId": null, "title": "The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery"}, {"paperId": null, "title": "while f task is a linear layer"}, {"paperId": null, "title": "AAs are typically gradient-based (Sundararajan et al., 2017"}, {"paperId": null, "title": "Datasets As described in \u00a74.1.1, we primarily experiment with the SST (sentiment analysis"}, {"paperId": "cfb4592221080deb127de94e8063fb403b13a298", "title": "Measuring nominal scale agreement among many raters."}, {"paperId": null, "title": "Sequence Classi\ufb01cation"}, {"paperId": null, "title": "we formalize the text classi\ufb01cation problem in more detail"}, {"paperId": null, "title": "task i task"}, {"paperId": null, "title": "If a learned rationale extractor is chosen, UNIREX enables users to specify how much gold rationale supervision to use. Ideally, each train instance would be annotated with a gold rationale"}]}