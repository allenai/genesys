{"paperId": "bb1841c934f956322abdef2c64180e6f43035b29", "title": "How Good Is It? Evaluating the Efficacy of Common versus Domain-Specific Prompts on Foundational Large Language Models", "abstract": "Recently, large language models (LLMs) have expanded into various domains. However, there remains a need to evaluate how these models perform when prompted with commonplace queries compared to domain-specific queries, which may be useful for benchmarking prior to fine-tuning domain-specific downstream tasks. This study evaluates LLMs, specifically Gemma-2B and Gemma-7B, across diverse domains, including cybersecurity, medicine, and finance, compared to common knowledge queries. This study employs a comprehensive methodology to evaluate foundational models, encompassing problem formulation, data analysis, and the development of novel outlier detection techniques. This methodological rigor enhances the credibility of the presented evaluation frameworks. This study focused on assessing inference time, response length, throughput, quality, and resource utilization and investigated the correlations between these factors. The results indicate that model size and types of prompts used for inference significantly influenced response length and quality. In addition, common prompts, which include various types of queries, generate diverse and inconsistent responses at irregular intervals. In contrast, domain-specific prompts consistently generate concise responses within a reasonable time. Overall, this study underscores the need for comprehensive evaluation frameworks to enhance the reliability of benchmarking procedures in multidomain AI research.", "venue": "", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The results indicate that model size and types of prompts used for inference significantly influenced response length and quality, and this underscores the need for comprehensive evaluation frameworks to enhance the reliability of benchmarking procedures in multidomain AI research."}, "embedding": {"model": "specter_v2", "vector": [-0.09314035624265671, 0.25572216510772705, -0.18478527665138245, -0.12811115384101868, -0.6056787371635437, -0.4294365346431732, 0.5810844898223877, -0.09647014737129211, -0.26595133543014526, 0.04863402247428894, 0.10964024066925049, -0.2507823407649994, 0.031858205795288086, 0.23038654029369354, -0.24981358647346497, 0.24204213917255402, -0.808305561542511, 0.7017940282821655, -0.29432129859924316, -0.03362785652279854, -0.2466457635164261, -0.2848545014858246, -0.7308253645896912, -0.06607772409915924, 0.4519646465778351, 0.4471856355667114, -0.1958792805671692, 0.863534688949585, -0.20921295881271362, 0.5887598395347595, -0.05061790719628334, -0.19682055711746216, 0.2867531478404999, -0.022365955635905266, -0.32838866114616394, -0.26196810603141785, 0.6109714508056641, -0.7661510109901428, -0.5908074378967285, 0.5758334994316101, -0.15007682144641876, 0.22793127596378326, 0.6593212485313416, -0.7815929055213928, -0.5167499780654907, 0.368827760219574, 1.0568441152572632, 0.9205594658851624, 0.6444018483161926, -0.1122795045375824, 1.4780176877975464, -0.9628099203109741, 0.7562236189842224, 1.5437390804290771, 0.323660671710968, 0.0639554038643837, -0.05807248130440712, -0.7337314486503601, 0.4761994779109955, -0.25677135586738586, -0.7358261346817017, -0.05853068828582764, -0.2662673592567444, -0.4959440529346466, 1.5860925912857056, -0.20442475378513336, -0.5433367490768433, 0.5598358511924744, 0.09166040271520615, 1.4248628616333008, 0.030390875414013863, -0.8070067167282104, 0.31977516412734985, 0.03426168113946915, 0.31590062379837036, 0.4675041437149048, -0.35689735412597656, 0.4098665118217468, -0.6792738437652588, -0.8063954710960388, 0.4881601333618164, -0.06651843339204788, -0.052129339426755905, 0.5881896018981934, -0.5304861068725586, 0.8468934893608093, 0.1531117558479309, 0.7331265211105347, -0.5468038320541382, 0.32022973895072937, 0.09074857085943222, 0.660645067691803, -0.005527574103325605, 0.6643514633178711, -0.3476215600967407, 0.25511622428894043, -0.696644127368927, 0.6450064778327942, 0.4817180037498474, 1.0657583475112915, -0.47602972388267517, 0.10173755139112473, -0.9643323421478271, 0.09984833747148514, 1.275307536125183, 0.15993110835552216, 0.5828121900558472, -0.7317309975624084, 0.20871949195861816, -0.10488471388816833, 0.9662641882896423, -0.9635265469551086, -0.43638116121292114, 0.14155980944633484, -0.09866877645254135, -1.4680217504501343, -0.133082777261734, -0.21926087141036987, -0.43319129943847656, 0.7278856635093689, -0.25499284267425537, 0.036420851945877075, 0.2430107146501541, 0.6320652365684509, 0.9124041199684143, 0.3784281313419342, 0.5576496720314026, 0.3018285036087036, 0.593602180480957, 0.042148247361183167, -0.46936360001564026, -1.2429794073104858, 1.2452577352523804, -0.3325420320034027, 0.18201708793640137, -0.5395524501800537, -1.0270856618881226, -0.628182053565979, -0.516011655330658, 0.2601151466369629, -0.42708921432495117, 0.46856582164764404, 1.0356932878494263, 0.1426837295293808, -0.6963743567466736, 0.05411843582987785, 0.2312929928302765, -0.7485350966453552, -0.21849243342876434, -0.20204190909862518, 0.17864292860031128, -0.8342956304550171, -1.263794183731079, 0.46372127532958984, 0.5269381403923035, -0.9140592813491821, -0.4079108238220215, 0.24243704974651337, -1.1974987983703613, -0.2512514591217041, 0.4745054244995117, -0.3851402997970581, 1.5092648267745972, -0.1329345703125, -0.6410064697265625, 0.6906028985977173, 0.14567618072032928, 0.14388421177864075, 0.4554692506790161, -0.08689085394144058, -1.063903570175171, -0.23246893286705017, 0.23729974031448364, 0.496582567691803, -0.042243003845214844, -0.026447253301739693, -0.12573906779289246, 0.4901358485221863, 0.020017366856336594, -0.3027459681034088, -0.0011646751081570983, 1.1515355110168457, 0.09338627010583878, -0.3943353593349457, 0.2316160649061203, 0.7765791416168213, -0.31861209869384766, 0.0988057553768158, -0.2026229053735733, -1.040893316268921, 0.7625212669372559, -0.3439263105392456, 0.9549872279167175, -0.9089508652687073, -0.9034131765365601, -0.29387104511260986, -0.31188222765922546, -0.554203987121582, -0.8252750635147095, 0.8249934315681458, -0.3835524022579193, 0.4920969605445862, -0.34164899587631226, -0.4367935359477997, 0.10920131951570511, -0.06108895689249039, -0.8563638925552368, -0.09271016716957092, 0.14541086554527283, 0.9781295657157898, -0.8411073088645935, 0.02327553927898407, -0.09931674599647522, -0.4970689117908478, -0.812431275844574, 1.5853679180145264, -0.9382004141807556, 0.19666928052902222, -0.4208548963069916, 0.34248408675193787, 0.10710837692022324, -0.41250234842300415, 0.26467689871788025, 0.05993853881955147, -0.17767375707626343, 0.20963357388973236, -0.4654776155948639, 1.4973490238189697, 0.17648105323314667, 0.1602236032485962, -0.10324177891016006, -0.5098074674606323, 0.3755705952644348, 0.7721997499465942, -0.11728405207395554, -0.7506082653999329, 0.22178231179714203, 0.6366667151451111, -0.7043733596801758, -0.31348487734794617, 0.37255093455314636, 0.8064289093017578, -0.6828597187995911, 0.4744270443916321, 0.3784064054489136, -0.33239585161209106, 0.6068772077560425, 0.33001357316970825, 0.774036705493927, 0.020023617893457413, 0.5776268839836121, 0.10825688391923904, 0.19229422509670258, -0.30164504051208496, 0.08255941420793533, 0.7113677263259888, 0.8320608139038086, 0.38106635212898254, 0.3122709095478058, -0.8837584257125854, 0.10866331309080124, 0.2277912050485611, 0.581231415271759, 1.445124626159668, -0.0018250108696520329, -0.31324151158332825, -0.6072776913642883, -0.3610222339630127, 0.040906354784965515, 0.6082097887992859, -0.053435828536748886, -0.17052648961544037, -0.2200329750776291, -0.9319711923599243, 0.8594505786895752, 0.40210241079330444, 0.6982175707817078, -0.629078209400177, -0.5039985179901123, -0.1549685299396515, -0.0630606934428215, -1.0272412300109863, -0.23940013349056244, -0.02208440564572811, -0.5184765458106995, -0.4522361755371094, 0.095147505402565, 0.07625294476747513, 0.19080354273319244, -0.6647108197212219, 1.0868747234344482, -0.4171315133571625, -0.540557861328125, 0.9626497030258179, 0.7045080065727234, -0.6223114728927612, -0.8757075667381287, -0.6952738165855408, 0.0058831810019910336, -0.5442013144493103, 0.7112276554107666, 0.8947029113769531, 0.308682382106781, 0.4329540729522705, -0.9425380229949951, -0.20267146825790405, 0.3238467276096344, 0.2734368145465851, 0.3305673897266388, -0.2516027092933655, 0.25569596886634827, -0.6104802489280701, 1.4656214714050293, -0.3860987722873688, -0.6499898433685303, 0.5845756530761719, -0.47723567485809326, -0.5473828911781311, 0.5264307260513306, -0.47552230954170227, -0.05832073837518692, -1.0228581428527832, 0.7443591356277466, 0.10148990154266357, -0.9821006655693054, 0.900877833366394, 0.33433419466018677, 0.22160665690898895, 0.6346096396446228, 0.1856461763381958, 0.03240504488348961, -0.30368661880493164, 0.4346911311149597, -0.2971680164337158, 0.2413737028837204, -0.1654750257730484, -0.017436668276786804, -0.4794556200504303, -0.35335931181907654, -0.7948116064071655, -0.01229817233979702, -0.1704714000225067, 0.17112751305103302, -0.25163713097572327, -0.12487342953681946, -0.7109337449073792, -0.5178999900817871, -0.13494369387626648, -1.1474506855010986, -0.20699501037597656, 0.14962193369865417, -0.04622023552656174, -0.05086275190114975, -0.9564023017883301, -1.029526710510254, -0.8095715641975403, -0.1912439614534378, -0.7501214146614075, 0.525617778301239, 0.035488393157720566, -0.7202157974243164, -0.5038952827453613, 0.161445751786232, -0.4347962737083435, 0.6861517429351807, -0.10595180839300156, 0.9763602614402771, -0.5821697115898132, -0.3263808488845825, -0.8155189752578735, 0.2382114976644516, -0.10877259820699692, -0.12691259384155273, 0.250866562128067, -0.739042341709137, 0.1292508840560913, 0.007428226061165333, -0.5193976759910583, -0.3729003369808197, 0.1879032850265503, 0.43295979499816895, -0.0020571760833263397, -0.4262147843837738, -0.15252043306827545, 0.9426565170288086, -0.45403844118118286, -0.5200222730636597, 0.05316455662250519, 0.2979199290275574, 0.3145905137062073, 0.2735939025878906, 0.867389976978302, 0.24958078563213348, 0.4913811683654785, -0.13327035307884216, 0.04146398603916168, 0.5609326362609863, -0.40897437930107117, 0.5847876071929932, 0.8915549516677856, 0.5333016514778137, -0.2255609780550003, -1.4874111413955688, 0.41085535287857056, -1.2498500347137451, -0.3734467327594757, 0.7155973315238953, 0.7750866413116455, 0.2062024474143982, -0.5067333579063416, -0.22776585817337036, -0.6276684999465942, 0.1635388284921646, -0.1498812884092331, -0.4350072145462036, -0.20163565874099731, -0.15103285014629364, 0.12966273725032806, -0.21080991625785828, 0.06551872193813324, -0.6465615630149841, 0.41163843870162964, 15.25828742980957, 0.5810912847518921, -0.031935106962919235, 0.48208945989608765, 0.8597279191017151, 0.6472347378730774, -0.39545938372612, -0.21391619741916656, -0.8118529915809631, -0.1093817725777626, 1.463005542755127, -0.12425371259450912, 0.297988623380661, 0.5786872506141663, -0.026559272781014442, -0.0509035661816597, -0.9452497363090515, 0.7700642943382263, 0.46282970905303955, -0.8310264348983765, 0.3442200720310211, -0.002926294459030032, 0.18814577162265778, 0.32249847054481506, 0.4951893091201782, 0.5958700776100159, 0.5686145424842834, -0.811428964138031, 0.4009724259376526, 0.21609897911548615, 0.8272770047187805, 0.20035235583782196, 0.5337925553321838, 0.7089056372642517, -0.6632888317108154, -0.6031064987182617, -0.667105495929718, -1.1633988618850708, -0.0231320858001709, -0.10909020155668259, -1.1471973657608032, -0.09329992532730103, -0.472917377948761, 0.5186705589294434, 0.04430069029331207, 0.5401684045791626, -0.09379522502422333, 0.5330402255058289, -0.22585713863372803, 0.24228760600090027, 0.1227259412407875, 0.4703458547592163, 0.455911785364151, -0.09630759805440903, 0.2396588772535324, -0.07150294631719589, 0.8329765200614929, 0.743324875831604, -0.3795894384384155, 0.2776486873626709, -0.948275089263916, -0.831168532371521, 0.3103155791759491, 0.444647878408432, 0.48795872926712036, 0.16841663420200348, -0.6214741468429565, 0.2029535323381424, 0.22083815932273865, 0.6716060638427734, -0.1288972795009613, 0.16425058245658875, 0.34418925642967224, -0.6956658363342285, -0.6556102633476257, 0.5636314749717712, -0.10013333708047867, -0.3371710479259491, -0.5782938599586487, -0.4715883135795593, 0.9757075905799866, -0.6725559830665588, -1.3681610822677612, 0.6569173336029053, 0.0057875048369169235, -0.8203755021095276, -0.41107773780822754, -0.9318139553070068, -0.2497011125087738, 0.5899294018745422, -1.0573530197143555, -0.6504896283149719, 0.10368233174085617, 0.005664512049406767, -0.38746339082717896, -0.2880489230155945, 1.7054929733276367, -0.18971295654773712, -0.6885674595832825, -0.06892624497413635, 0.1732126623392105, -0.04759424179792404, 0.2752592861652374, -0.5185360908508301, 0.7095314860343933, 0.1628001481294632, -0.22027619183063507, 0.5652782320976257, -0.10033667832612991, -0.48306161165237427, -0.8168458938598633, -0.0216242466121912, 0.4165528416633606, -1.120862603187561, -0.33796337246894836, -0.4984759986400604, -0.7179348468780518, 0.4450646638870239, 0.14048892259597778, -0.42172738909721375, 0.6548596024513245, -0.22769927978515625, -0.4329310357570648, 0.17575900256633759, -1.0321197509765625, 0.037787407636642456, 0.1695002317428589, -0.9520142078399658, -0.5918658971786499, 0.7430062294006348, 0.5013235211372375, -0.8820061087608337, -0.6636011004447937, -0.24470952153205872, -0.3448403775691986, 0.2791300415992737, 0.8208860754966736, -0.887988805770874, 0.38903138041496277, 0.6687504053115845, -0.37555646896362305, -0.39883649349212646, 0.09688954055309296, -0.7390410900115967, 0.019486356526613235, -0.4028817415237427, 0.6892445683479309, -0.8274059295654297, -0.37683770060539246, 1.9028546810150146, 0.35692304372787476, 0.05783358961343765, -0.7158910632133484, -0.33222371339797974, 0.01180658582597971, -0.2742666006088257, 0.45716941356658936, 0.046201568096876144, -0.09320114552974701, -0.3838163912296295, 0.47929659485816956, 0.8537113070487976, -0.5009121298789978, -0.08911633491516113, 0.5530803799629211, -0.4206741750240326, 0.01844431273639202, -0.3070296347141266, -0.41684359312057495, -1.5071965456008911, 0.0611613392829895, -0.8265750408172607, -0.06387200951576233, -0.6557801961898804, -0.5095852017402649, 0.34425947070121765, -0.3046102523803711, 0.07928026467561722, 0.4987822473049164, -1.0337135791778564, -0.6954207420349121, -0.2656156122684479, -0.3883129954338074, 0.4740217924118042, 0.6118094325065613, -0.7640039920806885, 0.08000744879245758, -0.3373658359050751, 0.08091951161623001, 0.15058866143226624, 0.18449237942695618, -0.5003641247749329, -0.46155110001564026, -0.9593845009803772, -0.056462548673152924, 0.045990973711013794, 0.2652895152568817, -0.5189212560653687, 0.9731424450874329, 0.0015041794395074248, -0.060919467359781265, 0.22802972793579102, 0.2623879611492157, -1.1129261255264282, -0.28080058097839355, 0.2775334119796753, -0.7521886825561523, 0.2738502025604248, 0.4947439134120941, -0.4522249400615692, -0.6125363707542419, 0.5974771976470947, -0.4380590319633484, -0.9405971765518188, -0.704796552658081, 0.13035383820533752, -0.792691707611084, 0.2546408474445343, 0.10172673314809799, 0.04962838441133499, -1.0143083333969116, -0.3873525559902191, 0.2089177668094635, 0.5124529004096985, -0.2811337411403656, 0.7097521424293518, 0.7097790241241455, -0.9717177152633667, -0.0863351821899414, 0.34451475739479065, 0.2128053456544876, -0.16895692050457, 0.24106183648109436, 0.27598825097084045, -0.21399056911468506, 0.8113167881965637, 0.3424028158187866, 0.2434835433959961, -0.5336090922355652, -0.12664121389389038, 0.4721563458442688, -0.11474864929914474, -0.08797701448202133, 0.9463024139404297, 0.11983694136142731, -1.0745127201080322, 0.2229372262954712, -1.2436269521713257, -0.23828460276126862, -0.6477147936820984, 0.4180208742618561, 0.11285869777202606, -0.2933156490325928, -0.01580370031297207, -0.40349364280700684, -0.18534237146377563, -0.15106263756752014, -0.32471659779548645, 0.24379581212997437, 0.1515011042356491, -0.2652147710323334, 0.5502500534057617, 0.1634417474269867, -0.8641483187675476, -0.3023853898048401, -0.26721927523612976, 0.44155171513557434, -0.3170982301235199, 0.06105692312121391, -0.807712972164154, -0.14198729395866394, 0.34196507930755615, 0.5627774596214294, 0.10622621327638626, 0.23178806900978088, -0.028810637071728706, 0.10600628703832626, 1.0512077808380127, 0.2272508293390274, -0.6079040169715881, -0.6427116990089417, 0.9703965783119202, 1.5926074981689453, -1.2462518215179443, 0.2507978677749634, -0.0018188991816714406, -0.7089434862136841, 0.9798675179481506, 0.7591170072555542, 0.47438567876815796, 0.4502822160720825, -0.45466145873069763, 0.2689133584499359, -0.2679726779460907, -0.796583890914917, 0.3193109333515167, 0.8339089155197144, 0.5249268412590027, 0.8920213580131531, 0.5708619356155396, -0.024350948631763458, 0.9519784450531006, 0.40028879046440125, 0.5109713673591614, 0.3467276096343994, 0.8617169857025146, -0.22081208229064941, -0.020592570304870605, -0.1683754324913025, 0.645289421081543, -0.38193613290786743, -0.42981287837028503, -0.6115930080413818, 0.8783435225486755, -0.16402383148670197, 0.6288484334945679, 0.40528029203414917, 0.05052229017019272, 0.5436508655548096, 0.5418110489845276, -0.16841770708560944, -0.7057023644447327, -0.08142852783203125, -0.26209837198257446, -0.3242768347263336, -0.10039535164833069, -0.11681149899959564, -0.40799498558044434, -0.11677016317844391, 0.19450603425502777, 0.3597434163093567, 0.025991495698690414, -0.07819487899541855, 0.9963660836219788, 0.7976288795471191, -0.2548259198665619, -0.7082996964454651, 0.16687041521072388, -0.6133174300193787, -1.1376646757125854, -0.03617105633020401, -0.360658198595047, -0.49730193614959717, -0.3486790359020233, -0.2980462610721588, -0.48174893856048584]}, "authors": [{"authorId": "121177913", "name": "Oluyemi E. Amujo"}, {"authorId": "37923918", "name": "S. Yang"}], "references": [{"paperId": "8597c0dc4fa5805306d9dd73622b9d27f4e74557", "title": "A multimodal approach to cross-lingual sentiment analysis with ensemble of transformer and LLM"}, {"paperId": "250430f92bc02b99161dcf915d13eb102b3f1bf2", "title": "Large Language Model (LLM) AI text generation detection based on transformer deep learning algorithm"}, {"paperId": "b842b83a7ff5dff8e3b83915d8c15423b6085728", "title": "Gemma: Open Models Based on Gemini Research and Technology"}, {"paperId": "9b580b32de576d76ed6522c5e478c33ca9ced953", "title": "On a Foundation Model for Operating Systems"}, {"paperId": "fa874e7b66a5b936469872054986c8f340701146", "title": "A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4"}, {"paperId": "b6346f9fa093b8e85df712485a2b851b9f680dac", "title": "LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"}, {"paperId": "af3ab5da98e0807784b57e321ed887a3666a8ab6", "title": "Multimodal Foundation Models: From Specialists to General-Purpose Assistants"}, {"paperId": "c47ba62dd18c70aafa04a8e04e105f624090217c", "title": "LLM Based Generation of Item-Description for Recommendation System"}, {"paperId": "28e2ecb4183ebc0eec504b12dddc677f8aef8745", "title": "Benchmarking Large Language Models in Retrieval-Augmented Generation"}, {"paperId": "b3eea15d7eacb33e6f8e6b7bc10961b64d23081f", "title": "LeanContext: Cost-Efficient Domain-Specific Question Answering Using LLMs"}, {"paperId": "000f964393dafe113a8e66734d63b2a145844159", "title": "Large Language Models for Software Engineering: A Systematic Literature Review"}, {"paperId": "7d78238a9bad60433d616abdd93c735087d99670", "title": "LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Generation"}, {"paperId": "eb546a0b7883fbc9a41d8c7218888322fb5dc62d", "title": "NLLG Quarterly arXiv Report 06/23: What are the most influential current AI Papers?"}, {"paperId": "f5ea85f67fc5ea9cce2c5345ed92740f7377cb2e", "title": "Using an LLM to Help with Code Understanding"}, {"paperId": "57f2c0720ffaec896f612b6f3b13fd1c538b4749", "title": "Unlocking the Potential of User Feedback: Leveraging Large Language Model as User Simulators to Enhance Dialogue System"}, {"paperId": "f4bdec0cf595720bc8ee5df2196324bac8f52ab4", "title": "Full Parameter Fine-tuning for Large Language Models with Limited Resources"}, {"paperId": "4e16bfc8ded08fbec67666869f39c043a6770946", "title": "Parameter-Efficient Fine-Tuning without Introducing New Latency"}, {"paperId": "6942bde24d01c412bdd53414cc88459afa5fac7d", "title": "Eliciting the Translation Ability of Large Language Models via Multilingual Finetuning with Translation Instructions"}, {"paperId": "32ac52069e562d4f900afee70bdca63f53461481", "title": "QLoRA: Efficient Finetuning of Quantized LLMs"}, {"paperId": "07f07d4d59fdbc3596284f51057cb006779d42c1", "title": "A Bibliometric Review of Large Language Models Research from 2017 to 2023"}, {"paperId": "bfad52fc64ca0169644b6e7e0ea9a46470d51709", "title": "Can ChatGPT Replace Traditional KBQA Models? An In-Depth Analysis of the Question Answering Performance of the GPT LLM Family"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "9f71d4bd511a4797c4f0c0122350d3381adc8a2e", "title": "The Science of Detecting LLM-Generated Text"}, {"paperId": "dfc3f176db3a8799eb47fd9bb8414d834b3bc681", "title": "Publishing trends in JDLTE: A five-year perspective"}, {"paperId": "06d7cb8c8816360feb33c3367073e0ef66d7d0b0", "title": "Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks"}, {"paperId": "456a70485aafc12dfed4fb7354668d72aae9b658", "title": "SecureBERT: A Domain-Specific Language Model for Cybersecurity"}, {"paperId": "0c181f508ec9de8e48f62523ba8a9bcb1f51f83a", "title": "Pre-Trained Language Models for Text Generation: A Survey"}, {"paperId": "2fd6f77540c1cc8e70b96208ccf9971b4251fc02", "title": "FLAVA: A Foundational Language And Vision Alignment Model"}, {"paperId": "bff4fa1130a64e96db72488e104c634f6dda8e7a", "title": "10 Security and Privacy Problems in Large Foundation Models"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "b5850a86c886baef1c536c34c33b23da2e728492", "title": "Progressive Generation of Long Text with Pretrained Language Models"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "1a54a6486d8e4c906e6a334157ee6832ad01871c", "title": "Deep learning for cyber security intrusion detection: Approaches, datasets, and comparative study"}, {"paperId": "f22c3412062f4568ec2ec017f13342f1d69b53ed", "title": "Triangularization of Matrices and Polynomial Maps"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "61d24c45e41f4f6cfc3d9da2f03efde1862b839e", "title": "Using Similarity Measures to Select Pretraining Data for NER"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "dc0e658d488a011c18bed43820e117a8adc3e066", "title": "Triangular Matrix Algebras: Recollements, Torsion Theories, and Derived equivalences"}, {"paperId": "6a16c62fbbc1d08bb8db14715af565252a0c099e", "title": "Advancing TTP Analysis: Harnessing the Power of Encoder-Only and Decoder-Only Language Models with Retrieval Augmented Generation"}, {"paperId": "5d4a6ce39cfe7bfc6305cba86464efff8bc20c97", "title": "A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges"}, {"paperId": "878d1d35f18aa91921ecb614d9f9a56a6febf63d", "title": "Decentralised Governance for Foundation Model based AI Systems: Exploring the Role of Blockchain in Responsible AI"}, {"paperId": "fc138ab0309aaded3efc9030486339ba8b53c9bb", "title": "The Function of chat GPT in Social Media: According to chat GPT"}, {"paperId": "42029832864c30c42a77538939f176f572b324a6", "title": "SecureFalcon: The Next Cyber Reasoning System for Cyber Security"}, {"paperId": "ea448c9cf089fd4a2c038f7330f3de51e6e0c6e8", "title": "A Framework for Designing Foundation Model based Systems"}, {"paperId": "95840ec08ba2e30490ee02fd0518bbfc0e8a0f4c", "title": "Prompt Engineering for Large Language Models"}, {"paperId": null, "title": "\u201cIntroducing gemini: our largest and most capable ai model,\u201d"}, {"paperId": "15b0d15a1ef487a14d24544d76f6da1271a4f7ec", "title": "Recent Advances in Pre-trained Language Models: Why Do They Work and How Do They Work"}, {"paperId": "ec936b808e0fab9281c050ad4010cddec92c8cbe", "title": "P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks"}, {"paperId": null, "title": "\u201cElectra: Pre-training text encoders as discriminators rather than generators,\u201d"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "\u201cRecall-oriented understudy for gisting evaluation (rouge),\u201d"}, {"paperId": "6038d62f22be3162324d3cb5214512966fc6ddb0", "title": "Music Transformer \uae30\ubc18 \uc74c\uc545"}, {"paperId": "13697bc3e4047683ed8375845783b7f2ab590f37", "title": "Audio-Journey: Efficient Visual+LLM-aided Audio Encodec Diffusion"}, {"paperId": null, "title": "\u201cLlm-based task-oriented dialog system with few-shot retrieval augmentation,\u201d"}, {"paperId": null, "title": "\u201cAi medical dataset,\u201d"}, {"paperId": null, "title": "When using semantic textual similarity (STS) with ChatGPT responses as a reference, the 7B model exhibits superior performance compared to 2B"}, {"paperId": null, "title": "\u201cStanford alpaca: An instruction-following llama model,\u201d"}, {"paperId": null, "title": "There is a strong correlation between inference time and response length compared to the other parameters"}, {"paperId": null, "title": "7B models consume more GPU memory than 2B models"}, {"paperId": null, "title": "\u201cfinance-alpaca (revision 51d16b6),\u201d"}, {"paperId": null, "title": "Across all categories, the 2B model tends to have higher throughput than its 7B counterpart"}, {"paperId": null, "title": "\u201cLlama 3 model card,\u201d"}, {"paperId": null, "title": "Privacy in Communication Networks"}, {"paperId": null, "title": "common prompts tend to produce responses with greater diversity in length and longer inference times"}, {"paperId": null, "title": "7B model with a response length limit of 50 yields responses with higher ROUGE-L scores in all domains compared to any other parameter"}, {"paperId": null, "title": "\u201cAlpaca: A strong, replicable instruction-following model. stanford center for research on foundation models,\u201d"}, {"paperId": null, "title": "Our analysis compares resource utilization and the quality and length of responses generated by the models"}, {"paperId": null, "title": "foundation models of diverse sizes, specifically Gemma-2B and Gemma-7B, within"}, {"paperId": null, "title": "\u201cMitre att&ck,\u201d"}]}