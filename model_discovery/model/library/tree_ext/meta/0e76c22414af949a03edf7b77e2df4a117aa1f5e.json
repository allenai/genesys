{"paperId": "0e76c22414af949a03edf7b77e2df4a117aa1f5e", "title": "Softmax-free Linear Transformers", "abstract": null, "venue": "International Journal of Computer Vision", "year": 2022, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2207.03341", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "A family of Softmax-Free Transformers (SOFT) is proposed, with a Gaussian kernel function adopted to replace the dot-product similarity, enabling a full self-attention matrix to be approximated under low-rank matrix decomposition."}, "embedding": {"model": "specter_v2", "vector": [0.44300827383995056, 1.1137754917144775, -0.08501798659563065, -0.007569530513137579, 0.18722859025001526, 0.24120356142520905, 0.9736191034317017, -0.11360689252614975, -0.47577306628227234, -0.9164472818374634, 0.4768127202987671, 0.7351704835891724, 0.6247622966766357, -0.1762976348400116, -0.41163522005081177, 0.010622957721352577, -0.7013596296310425, -0.38205385208129883, 0.442450612783432, -0.5311233401298523, 0.018311383202672005, -0.7699530124664307, -1.4340637922286987, 0.2986615300178528, 0.19066782295703888, 1.0984381437301636, 0.5530082583427429, 1.1565581560134888, -0.43430665135383606, 0.607101559638977, 0.23702652752399445, -0.4193795323371887, 0.4570259749889374, 0.1565406322479248, -0.3636482059955597, 0.09425649791955948, 0.740644097328186, -0.1477893888950348, -0.8020853400230408, 1.0043436288833618, -0.05195220559835434, 0.22734034061431885, 0.5572841167449951, -0.585334300994873, -0.7936756014823914, 0.5522205233573914, 0.7882599234580994, 0.5311606526374817, -0.4791029095649719, -0.327920138835907, 1.1575109958648682, -1.3840821981430054, 0.06040127947926521, 1.4726340770721436, 0.27048733830451965, 0.26306405663490295, 0.058268334716558456, -0.23609884083271027, 0.7894940376281738, 0.4379308521747589, -0.8259602785110474, -0.6862612962722778, -0.028701258823275566, -0.15927428007125854, 1.9856367111206055, -0.5590097308158875, -0.025921905413269997, 0.6492776870727539, 0.3955300748348236, 1.3053992986679077, 0.24761980772018433, -0.7488911151885986, -0.008609718643128872, 0.2981911599636078, 0.07862754911184311, 0.8792566061019897, -0.6101080775260925, 0.3274379372596741, -1.1915719509124756, 0.40009719133377075, 0.6313856244087219, -0.018402082845568657, 0.6285961270332336, -0.41028937697410583, -0.17821872234344482, 0.57809978723526, 0.8484160304069519, 0.5989945530891418, -0.2658461630344391, 0.7829751968383789, 0.704914927482605, 0.19265294075012207, -0.09945248812437057, 0.02585143782198429, 0.22961831092834473, 0.5441799163818359, -0.7139482498168945, -0.24239398539066315, -0.4480040669441223, 0.9577436447143555, -0.08234265446662903, 0.7966674566268921, -0.6870381832122803, 0.2875646650791168, 1.5397690534591675, 0.36985430121421814, 0.5884177088737488, -0.33642539381980896, -0.16393078863620758, -0.9527695775032043, -0.2691039443016052, -1.0862890481948853, 0.31729137897491455, -0.47431421279907227, -0.8073384761810303, -0.541613757610321, -0.380075067281723, 0.559535801410675, -1.2704812288284302, 0.3892544209957123, -0.4155850410461426, -0.04864770546555519, 0.17724381387233734, 0.5146520733833313, 0.6685254573822021, 0.32373595237731934, 0.2774980366230011, 0.4903993010520935, 1.3179129362106323, -0.8353405594825745, -0.591461718082428, -0.9782031178474426, -0.16193237900733948, -0.29367297887802124, 0.1328495442867279, -0.1481223851442337, -1.2618350982666016, -1.5401215553283691, -0.8383657932281494, -0.04616686329245567, -0.7945869565010071, 0.3733462989330292, 0.9965152144432068, 0.4454328417778015, -1.0785893201828003, 0.7804387211799622, -0.29308196902275085, -0.37183019518852234, 0.6823574304580688, 0.11380156129598618, 0.1510295271873474, 0.014805169776082039, -1.03984534740448, 0.47183409333229065, 0.08198621869087219, -0.27569255232810974, -0.2769029140472412, -0.13362261652946472, -1.5135995149612427, 0.13610120117664337, 0.21957024931907654, -0.3412335216999054, 1.0497325658798218, -0.5039529204368591, -1.3721071481704712, 0.6018631458282471, -0.4772263467311859, -0.17649996280670166, 0.279572993516922, -0.22577472031116486, -0.34132882952690125, -0.31751054525375366, -0.09134518355131149, 0.7744928002357483, 1.2860767841339111, -0.4167068898677826, -0.1900937706232071, 0.11185027658939362, -0.5307387113571167, 0.05294128879904747, -0.6373112797737122, 0.9480149149894714, -0.5919093489646912, -0.39154231548309326, 0.38920843601226807, 0.6535335779190063, 0.1019107848405838, -0.3529641926288605, -0.3517114818096161, -1.0725880861282349, 0.35685479640960693, 0.5657296776771545, 0.28115928173065186, -1.021738886833191, -1.302794337272644, 0.01299753412604332, -0.06580361723899841, -0.090764120221138, -0.9360151886940002, 0.5553904175758362, -0.39993971586227417, -0.2353825718164444, 0.4349445402622223, -1.0672177076339722, 0.2901822626590729, -0.2028200626373291, -0.6166274547576904, 0.17078933119773865, 0.3591570556163788, 1.3001562356948853, -0.8595409989356995, -0.3439684510231018, 0.2397295981645584, 0.39177149534225464, -0.6436861157417297, 1.2089755535125732, -0.0029034120962023735, -0.4935883581638336, 0.28625139594078064, -0.09044096618890762, 0.3304462134838104, -0.3173133134841919, 0.20580382645130157, -0.6492775678634644, -0.015151462517678738, 0.4004407525062561, -0.4767712950706482, 1.4151407480239868, -0.0870475247502327, 0.9503663778305054, -0.5092365741729736, -0.8453420996665955, 0.29777759313583374, 0.19760356843471527, -0.02326218970119953, -0.716373085975647, 0.47779884934425354, -0.35094234347343445, -0.7822316884994507, 0.27146559953689575, 0.7984552979469299, 1.227260708808899, -0.07987352460622787, -0.22430050373077393, 0.9507676362991333, -0.21284954249858856, 0.09348621964454651, 0.43009477853775024, 0.48418065905570984, 0.4940340518951416, 0.25500550866127014, 0.0020399780478328466, -0.17358118295669556, -1.0404995679855347, -0.07597500085830688, 0.9506750702857971, 0.40355804562568665, 1.2694061994552612, -0.04411576688289642, -0.5670660138130188, -0.09904041141271591, -0.4309200644493103, 0.4914528429508209, 1.481583595275879, -0.12722623348236084, -0.16906005144119263, -0.7971604466438293, -0.08432724326848984, -0.4499187171459198, -0.4840160310268402, -0.6179506182670593, -0.4568367004394531, 0.09584026038646698, -0.7482926845550537, 0.6253282427787781, 0.35656800866127014, 0.9760077595710754, -0.6913341283798218, -0.48588642477989197, -0.006507975049316883, 0.6108125448226929, -0.996040940284729, -0.885248601436615, 0.26267126202583313, -0.008731482550501823, 0.004902903456240892, -0.2601035237312317, -0.1982840746641159, 0.38802865147590637, -0.36824607849121094, 0.5800256133079529, -1.1352266073226929, -0.6305556893348694, 0.34314393997192383, 0.2738090753555298, -0.9404614567756653, -0.35945042967796326, 0.0389917716383934, 0.29286253452301025, 0.26694464683532715, 0.31555184721946716, 0.3394688069820404, -0.20177723467350006, 0.0037085486110299826, -0.2538897395133972, -0.2555399537086487, 0.3699024021625519, -0.1521030217409134, 0.6762030720710754, -0.27085068821907043, 0.004256384912878275, -0.7301363945007324, 0.5857961773872375, 0.3378690183162689, -0.1058453619480133, -0.08824333548545837, -0.9897134900093079, -0.2718281149864197, 0.23930229246616364, -0.7521467804908752, -0.44165176153182983, -0.06244369596242905, 0.3872092068195343, -0.6710478663444519, -0.4163806736469269, -0.2594779431819916, 0.3930777311325073, -0.35703611373901367, 0.6023967266082764, 0.7590755820274353, 0.2818969488143921, 0.3135335445404053, 0.8260390162467957, -0.6675617694854736, 1.192767858505249, 0.40541914105415344, 0.3494188189506531, 0.22444847226142883, -0.2812364101409912, -0.9127025008201599, -0.2944388687610626, -0.5449900031089783, -0.2132810652256012, -0.619687557220459, 0.5322239398956299, -0.710269033908844, -1.3979034423828125, 0.2449478805065155, -0.8237537145614624, 0.002242557005956769, -0.39163193106651306, -0.12907612323760986, -0.45858365297317505, -0.5913445353507996, -0.9205220341682434, -0.7771798372268677, -0.5697095394134521, -0.7335805892944336, -0.2075643688440323, 0.5196627378463745, -0.009086779318749905, -0.2519714832305908, -0.25249892473220825, -0.47838830947875977, 1.2401719093322754, -0.8169736862182617, -0.04715992510318756, 0.042466260492801666, -0.30271458625793457, -0.1597132384777069, -0.26729175448417664, 0.7547762393951416, -0.08389261364936829, 0.22130341827869415, -1.295731782913208, 0.34276890754699707, -0.5497158169746399, -0.28846508264541626, 0.4936799705028534, 0.548814594745636, 0.39064982533454895, -0.006921510212123394, -0.29114994406700134, 0.5482580661773682, 1.490660548210144, -0.5399831533432007, 0.3339449465274811, 0.08370336145162582, 0.9143950939178467, 0.08982891589403152, -0.4411916136741638, 0.6735429763793945, 0.9173551201820374, 0.2684296667575836, 0.6854333877563477, -0.8459885716438293, -0.49680715799331665, -0.5632486343383789, 0.45407700538635254, 1.1540412902832031, 0.10031884163618088, 0.1359815001487732, -0.6017996668815613, 1.005314826965332, -1.273046612739563, -1.131861925125122, 0.6285555362701416, 0.607571005821228, 0.1942979246377945, -0.0678166002035141, -0.3216295838356018, -0.4776698052883148, 0.33080264925956726, 0.4818485379219055, -0.26253557205200195, -0.8866161704063416, -0.409097284078598, 0.6448582410812378, 0.5327761173248291, 0.45492005348205566, -0.6786357760429382, 0.8375827670097351, 14.721534729003906, 0.48187342286109924, -0.22077734768390656, 0.4376033544540405, 0.4198909401893616, 0.48421698808670044, 0.17889420688152313, 0.0726243406534195, -0.8519909381866455, -0.28134116530418396, 0.45872870087623596, 0.5749358534812927, 0.5634635090827942, 0.39036720991134644, -0.10040194541215897, 0.2204483598470688, -0.2717060148715973, 1.0152344703674316, 0.8748372197151184, -1.180464744567871, -0.17036104202270508, 0.038897398859262466, 0.326317697763443, 0.6864089965820312, 0.9366885423660278, 0.5638149380683899, 0.5112387537956238, -0.17877241969108582, 0.7425825595855713, 0.7606525421142578, 0.9089664220809937, 0.2688470482826233, -0.09059560298919678, -0.04768595099449158, -1.0699881315231323, -0.10865166038274765, -0.777737021446228, -0.9509550333023071, -0.23561280965805054, 0.24105088412761688, -0.33174654841423035, -0.43494391441345215, 0.17686326801776886, 0.5538303852081299, -0.026574673131108284, 0.37968146800994873, 0.04397508129477501, 0.47432655096054077, 0.04271164909005165, -0.1272253841161728, 0.1679733395576477, 0.7597323656082153, -0.013915568590164185, 0.49291476607322693, -0.28136736154556274, 0.0314180850982666, 0.09443004429340363, 0.602580189704895, -0.18581360578536987, -0.1784205287694931, 0.24019984900951385, -0.04957941174507141, -0.3829655647277832, 1.0438162088394165, 0.32335877418518066, 0.07636518776416779, -0.14733099937438965, 0.7107703685760498, 0.4291673004627228, 0.1877138614654541, -0.3255762755870819, -0.5383462905883789, 0.5816846489906311, -0.5877535343170166, 0.4693813621997833, 0.418885201215744, -0.35650205612182617, -0.7391239404678345, -0.6465321779251099, 0.054460156708955765, 0.15508514642715454, -1.0799318552017212, -0.8224702477455139, 1.030886173248291, -0.3817627429962158, -0.14852897822856903, 0.3480081260204315, -0.8499004244804382, -0.49165964126586914, 0.46234309673309326, -1.4685862064361572, -0.7996731996536255, -0.07579159736633301, -0.20920221507549286, -0.28725743293762207, -0.31344765424728394, 0.692918598651886, -0.10404889285564423, 0.06790328770875931, 0.48760437965393066, -0.12879227101802826, 0.059374645352363586, 0.045377857983112335, -0.7838136553764343, 0.8571905493736267, 0.48091045022010803, 0.004007989540696144, 0.29939183592796326, 0.1896115094423294, 0.4127909541130066, -0.6830562949180603, 0.2664908766746521, 0.6344477534294128, -0.36970439553260803, -0.5612298846244812, -0.9213466644287109, -0.6389501094818115, -0.12279479205608368, 0.9930758476257324, 0.31789430975914, -0.2451656460762024, -0.049911078065633774, -0.6166185140609741, -0.25106823444366455, -0.5161077976226807, 0.03796033188700676, 0.3577331602573395, -0.9935594201087952, -0.3911062479019165, -0.09245870262384415, -0.13689662516117096, -0.839636504650116, -0.4909095764160156, -0.6395972371101379, 0.2262517511844635, -0.3742870092391968, 1.4431434869766235, -0.3997519612312317, 0.2801375985145569, 0.7493407130241394, -0.09379205107688904, -0.7815395593643188, -0.3732500374317169, -0.773815929889679, 0.11321514844894409, 0.36574503779411316, 0.20177501440048218, -0.6369665265083313, 0.3513588011264801, 0.5480654239654541, 0.08368843793869019, -0.3256230652332306, -0.7083611488342285, -0.3121137320995331, -0.4196290373802185, -0.7024076581001282, 0.06370600312948227, -0.05498722940683365, 0.3018513023853302, 0.01907617412507534, 0.47085654735565186, 0.3594212532043457, 0.21770694851875305, -0.8170456886291504, 0.14705610275268555, 0.016848992556333542, -0.07071507722139359, -0.47311240434646606, -0.8063765168190002, -1.4395577907562256, -0.24610571563243866, -1.1138290166854858, 0.16829314827919006, -1.329314947128296, -0.4984591603279114, 0.26738259196281433, -0.5759150385856628, 0.3955420255661011, 0.41263702511787415, -0.23396511375904083, 0.016580700874328613, -0.5357133150100708, -0.44493454694747925, 0.7983968257904053, 0.8924236297607422, -0.8471046686172485, 0.14064697921276093, -0.09683173149824142, -0.16306401789188385, 0.21084077656269073, 0.37987032532691956, -0.32773178815841675, -0.7046039700508118, -0.9068467617034912, 0.1447182446718216, -0.21693286299705505, 0.10578850656747818, -1.2675575017929077, 1.0094047784805298, 0.14268805086612701, 0.2289794683456421, 0.08871471136808395, 0.6648032665252686, -0.7641714811325073, -0.9139611721038818, 0.24095872044563293, -0.7881024479866028, -0.3098430931568146, -0.06278223544359207, -0.6182076930999756, -0.1956169456243515, 0.8313400149345398, 0.19886475801467896, -1.0752662420272827, -0.839681088924408, 0.515513002872467, -0.651427149772644, 0.09712950885295868, -0.3781627416610718, -0.7035472989082336, -1.2529138326644897, -0.43467840552330017, -0.2895607352256775, -0.05973486602306366, -0.7562183141708374, 1.2108031511306763, 0.9807134866714478, -1.203155755996704, 0.09626836329698563, 0.6158022880554199, 0.21029017865657806, -0.2048475742340088, 0.5760847330093384, 0.20044724643230438, 0.0933697521686554, 0.3086164891719818, -0.278507798910141, 0.22848771512508392, -0.6150107383728027, 0.2140040248632431, 0.9210653305053711, 0.26409170031547546, 0.027101535350084305, 1.0241507291793823, 0.015679549425840378, -0.7012707591056824, 0.10439170897006989, -1.1226720809936523, -0.4796963036060333, -0.02586965076625347, 0.2982231378555298, -0.012324104085564613, -0.0056602610275149345, -0.4737703502178192, -0.5165311098098755, 0.10211110860109329, -0.12605373561382294, -0.6194621920585632, 0.2642166018486023, -0.2257484793663025, 0.18242128193378448, 0.19182640314102173, 0.8379864692687988, -0.851415753364563, -1.292942762374878, -0.9970875978469849, -0.9313643574714661, -0.2891971468925476, 0.4533618688583374, -0.14243485033512115, -0.8030276894569397, 0.7931155562400818, 1.1194685697555542, 0.39932015538215637, 0.09868981689214706, 0.006252123508602381, -0.18220990896224976, 0.5628418922424316, -0.48590245842933655, -1.157151222229004, -0.26108288764953613, 1.314253568649292, 0.8710703253746033, -0.8753235340118408, -0.03635970503091812, -0.28966525197029114, -0.7262967228889465, 0.5698581337928772, 0.3515898585319519, -0.35517019033432007, 0.9088250994682312, -0.19299569725990295, 0.24455012381076813, 0.27144354581832886, -0.8470615148544312, -0.9472905993461609, 1.1840401887893677, 1.5589942932128906, 0.47830379009246826, 0.17325381934642792, 0.6432837247848511, 0.45411866903305054, 0.06443142890930176, -0.04258016124367714, 0.31947773694992065, 0.2536602020263672, -0.3488084375858307, 0.374765545129776, -0.23110447824001312, 0.5316886901855469, -0.3881547749042511, -0.5735636353492737, 0.4218960106372833, 0.06553461402654648, 0.5133374333381653, 0.7135093808174133, 1.1415563821792603, -0.11737469583749771, 0.7989088892936707, -0.18775801360607147, 0.7061862945556641, -0.14870966970920563, -0.2039591521024704, -0.04287414252758026, -1.1673394441604614, -0.16424188017845154, -0.12082439661026001, -0.7379980683326721, -0.4072011709213257, 0.13189345598220825, 0.22789417207241058, -0.6226826310157776, 0.7114388346672058, 0.887633740901947, 0.5237002372741699, 0.679634690284729, -0.06395117938518524, -0.679176926612854, -0.3635869324207306, -0.8260281682014465, 0.33977386355400085, -0.30249619483947754, -0.013289324007928371, -0.2804848253726959, 0.19452756643295288, 0.1981058418750763]}, "authors": [{"authorId": "31727033", "name": "Jiachen Lu"}, {"authorId": "2152827279", "name": "Li Zhang"}, {"authorId": "2086001", "name": "Junge Zhang"}, {"authorId": "2259619084", "name": "Xiatian Zhu"}, {"authorId": "2116310107", "name": "Hang Xu"}, {"authorId": "1384556269", "name": "Jianfeng Feng"}], "references": [{"paperId": "d2f63b56fc6bc373f5c023454c2b253326962865", "title": "DeiT III: Revenge of the ViT"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "2e644c67a697073d561da4f4dad35e5ad5316cfd", "title": "SOFT: Softmax-free Transformer with Linear Complexity"}, {"paperId": "f829a355de02c08567927154d3045a6eb5425c91", "title": "Is Attention Better Than Matrix Decomposition?"}, {"paperId": "a143725bccbef904b10348625f5b0dd1eafd7f32", "title": "Visual Parser: Representing Part-whole Hierarchies with Transformers"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "fc92009ab34045f9e6d490684c7761f768e88c54", "title": "Beyond Self-Attention: External Attention Using Two Linear Layers for Visual Tasks"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "5b68522f58b61e7235b852677337ef3725075fd9", "title": "Co-Scale Conv-Attentional Image Transformers"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "3cbe314cc5407a6c3249815b5173f22ea15173c2", "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"}, {"paperId": "054e307c1edf4b28137ffcbce980fe81f0647d20", "title": "Finetuning Pretrained Transformers into RNNs"}, {"paperId": "610b302950a19acef1c45456111dcd495f638c18", "title": "ConViT: improving vision transformers with soft convolutional inductive biases"}, {"paperId": "62e5eec6d90c57c8099961bfecddc7accf0fad95", "title": "Improving Generalization of Transfer Learning Across Domains Using Spatio-Temporal Features in Autonomous Driving"}, {"paperId": "b3bf9fe13195e9aa70e1dac04e01fcff7008e812", "title": "Perceiver: General Perception with Iterative Attention"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "93884d89dfc8c3886f642018227a43fb7b58044f", "title": "Generalizing to Unseen Domains: A Survey on Domain Generalization"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "63812f583caac3ac32bbfb64f66ba69e57c1e90a", "title": "Conditional Positional Encodings for Vision Transformers"}, {"paperId": "cec7872b194aadf54140578b9be52939eb1112e9", "title": "LambdaNetworks: Modeling Long-Range Interactions Without Attention"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78", "title": "Bottleneck Transformers for Visual Recognition"}, {"paperId": "d29430adccb805ab57b349afa8553954347b3197", "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "6d5f423164cd5ef9324281652987c8a65009e98e", "title": "Sparse R-CNN: End-to-End Object Detection with Learnable Proposals"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "da60e046aac895b5775ed34bde45beb86aad0fe8", "title": "Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "54c7445f319823c7dcc948c830e75e2fa7460b33", "title": "Exploring Self-Attention for Image Recognition"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "448529da2bf004cf79084401ad3cbd6b511e4969", "title": "Bridging the Gap Between Anchor-Based and Anchor-Free Detection via Adaptive Training Sample Selection"}, {"paperId": "a88c914f5a738d38f02790bb5de41453bf17bde1", "title": "Object-Contextual Representations for Semantic Segmentation"}, {"paperId": "8cef9900c04d7f661c08f4b5b1ed4337ace042a3", "title": "Transformer Dissection: An Unified Understanding for Transformer\u2019s Attention via the Lens of Kernel"}, {"paperId": "3827ecf84bc0429b73d9c57a6b2b55e723d4cfba", "title": "Dynamic Graph Message Passing Networks"}, {"paperId": "bc626a52664e948a0ffb2b95d0e1e6377a01171a", "title": "Cascade R-CNN: High Quality Object Detection and Instance Segmentation"}, {"paperId": "c2c083df88e88223e1a411e61040b94c233b1b63", "title": "MMDetection: Open MMLab Detection Toolbox and Benchmark"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "5132500b23d2da47129b3f4f68dd30947a29e502", "title": "CCNet: Criss-Cross Attention for Semantic Segmentation"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "8b354d76813bd5375e7e5c8d17f630bec5936a01", "title": "ListOps: A Diagnostic Dataset for Latent Tree Learning"}, {"paperId": "9217e28b2273eb3b26e4e9b7b498b4661e6e09f5", "title": "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "79cfb51a51fc093f66aac8e858afe2e14d4a1f20", "title": "Focal Loss for Dense Object Detection"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "f07c036a26bfca2b043f7c85f0326b177cd5561f", "title": "Spectral Norm Regularization for Improving the Generalizability of Deep Learning"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "1031a69923b80ad01cf3fbb703d10757a80e699b", "title": "Pyramid Scene Parsing Network"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "88512be44744615f4baa8e14f600f036db4c2433", "title": "Semantic Understanding of Scenes Through the ADE20K Dataset"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "c8c494ee5488fe20e0aa01bddf3fc4632086d654", "title": "The Cityscapes Dataset for Semantic Urban Scene Understanding"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "6fc6803df5f9ae505cae5b2f178ade4062c768d0", "title": "Fully convolutional networks for semantic segmentation"}, {"paperId": "d7011869ba77b81f2b2504494ced6fd068a43e9b", "title": "Professional CUDA C Programming"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "e01eae8dea6fbaa1ae7fc83535053932268df430", "title": "The ACL anthology network corpus"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "eda90bd43f4256986688e525b45b833a3addab97", "title": "A tutorial on spectral clustering"}, {"paperId": "709f3102347a44748a7bbcbe4b1273b07dc71661", "title": "On Iterative Computation of Generalized Inverses and Associated Projections"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": null, "title": "https://www.mindspore.cn"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Pytorch image models"}, {"paperId": "62f77aac48515022bee3d95d383486e307395766", "title": "Positive definite kernels: past, present and future"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "b6fff8b8ea77f157913986e7af53951d9fc1128e", "title": "Using the Nystr\u00f6m Method to Speed Up Kernel Machines"}, {"paperId": null, "title": "Proposition 2. (cid:107) AA k A \u2212 A (cid:107) and (cid:107) A k \u2212 A \u2020 (cid:107) decreases to 0 monotonously, if \u03b1 is suf\ufb01ciently small"}, {"paperId": null, "title": "SUBMITTED"}, {"paperId": null, "title": "5.1. If F is a non-singular and symmetric matrix, then"}, {"paperId": null, "title": "To prove Proposition 5"}, {"paperId": null, "title": "Comparing the attention heatmaps of a query patch (marked by the cross \"+\") against all the patches of an image"}]}