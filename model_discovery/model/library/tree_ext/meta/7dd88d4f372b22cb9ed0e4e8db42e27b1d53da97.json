{"paperId": "7dd88d4f372b22cb9ed0e4e8db42e27b1d53da97", "title": "Efficiency-oriented approaches for self-supervised speech representation learning", "abstract": "Self-supervised learning enables the training of large neural models without the need for large, labeled datasets. It has been generating breakthroughs in several fields, including computer vision, natural language processing, biology, and speech. In particular, the state-of-the-art in several speech processing applications, such as automatic speech recognition or speaker identification, are models where the latent representation is learned using self-supervised approaches. Several configurations exist in self-supervised learning for speech, including contrastive, predictive, and multilingual approaches. There is, however, a crucial limitation in most existing approaches: their high computational costs. These costs limit the deployment of models, the size of the training dataset, and the number of research groups that can afford research with large self-supervised models. Likewise, we should consider the environmental costs that high energy consumption implies. Efforts in this direction comprise optimization of existing models, neural architecture efficiency, improvements in finetuning for speech processing tasks, and data efficiency. But despite current efforts, more work could be done to address high computational costs in self-supervised representation learning.", "venue": "arXiv.org", "year": 2023, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "More work could be done to address high computational costs in self-supervised representation learning, which limit the deployment of models, the size of the training dataset, and the number of research groups that can afford research with large self-supervised models."}, "embedding": {"model": "specter_v2", "vector": [0.21264857053756714, 1.3132013082504272, -0.3587096333503723, -0.19879332184791565, -0.35593169927597046, 0.1392180621623993, 0.25738632678985596, -0.24021267890930176, -0.4369337260723114, -0.4487815499305725, 0.6544457674026489, 0.536430835723877, 0.5423344373703003, 0.13565693795681, -0.11721260100603104, -0.06573260575532913, -0.8572990894317627, -0.0014434756012633443, 0.03131933882832527, -0.13568876683712006, -0.5689033269882202, -0.8578858375549316, -1.2815275192260742, 0.010940567590296268, 0.42470359802246094, 0.09620256721973419, 0.23228219151496887, 0.7971398234367371, -0.30411145091056824, -0.030742965638637543, 0.12117640674114227, -0.3464629650115967, 0.22541022300720215, -0.13914461433887482, -0.2664705812931061, 0.11114908009767532, 0.4430645704269409, -0.06395869702100754, -0.5059182643890381, 0.7802242040634155, -0.028242578729987144, 0.0907229632139206, 0.06935819983482361, -0.7632139921188354, 0.05263272300362587, 0.972122311592102, 0.6137627363204956, 0.8550043106079102, -0.3511166572570801, -0.6978451013565063, 1.1970888376235962, -0.7084234952926636, 0.1387791782617569, 1.5237979888916016, 0.3933853507041931, 0.7058523297309875, -0.3347472548484802, -0.9143352508544922, 0.4985497295856476, -0.050169553607702255, -0.6342508792877197, -0.9411007165908813, 0.38454708456993103, -0.2516081929206848, 1.561870813369751, -0.5895344614982605, -0.15846499800682068, 0.5676010847091675, -0.3338397741317749, 1.447417140007019, 0.2109731137752533, -0.5350772142410278, -0.034581080079078674, 0.48865821957588196, 0.5552476048469543, 0.9341997504234314, -0.42717409133911133, 0.6904190182685852, -1.5511813163757324, -0.2876538336277008, 0.11156339198350906, -0.26264655590057373, 0.3454522490501404, -0.5111464858055115, -0.12305103987455368, 0.9432048797607422, 0.11548071354627609, 0.8872627019882202, -0.07173490524291992, 0.8025652766227722, 0.9827381372451782, 0.4740895926952362, 0.344226211309433, 0.2713029682636261, 0.04177536442875862, 0.4894684851169586, -0.9519880414009094, -0.22909259796142578, 0.05302423611283302, 0.8815336227416992, 0.2726787030696869, 1.1271840333938599, -0.3043905794620514, 0.8107765913009644, 1.4210785627365112, 0.1954241394996643, 0.9360856413841248, -0.7570744752883911, 0.02953883819282055, -0.8065234422683716, -0.2851288318634033, -0.3530289828777313, -0.4921513795852661, -0.48680272698402405, -0.8354714512825012, -1.1316994428634644, -0.5440731644630432, -0.11754206568002701, -0.7655799388885498, 0.7230014204978943, -0.2443534880876541, -0.20640777051448822, 0.8836513161659241, 0.2532626986503601, 0.178193598985672, 0.5318169593811035, 0.3153093755245209, -0.31010526418685913, 1.1336101293563843, -1.137621283531189, -0.9537114500999451, -0.9026749134063721, 0.3315879702568054, 0.11952146142721176, -0.09398245066404343, -0.3590020537376404, -1.132225513458252, -0.8784240484237671, -0.5730652809143066, 0.5810491442680359, -0.07003907114267349, 0.5205684900283813, 1.243931770324707, 0.48966580629348755, -0.8112483024597168, 0.9782087206840515, -0.3681604266166687, -0.5283455848693848, 0.4345419108867645, 0.14528341591358185, 0.1504901647567749, 0.39620205760002136, -1.0135642290115356, 0.13659009337425232, 0.2976733446121216, -0.9347596764564514, -0.41514042019844055, -0.19455234706401825, -1.274855375289917, -0.09823330491781235, 0.1713249385356903, -0.2191448211669922, 1.2794649600982666, -0.5211811065673828, -1.5176682472229004, 0.8105906248092651, -0.3906398415565491, -0.325968861579895, 0.07502250373363495, 0.25404810905456543, -1.0071794986724854, -0.19630949199199677, 0.008719346486032009, 0.4092704951763153, 0.7932299375534058, -0.6576939821243286, -0.2878274917602539, -0.004794327076524496, -0.5310117602348328, -0.08721723407506943, -0.3176719546318054, 0.9056230187416077, -0.27634286880493164, -0.5874157547950745, 0.7018163204193115, 0.26728084683418274, -0.17210085690021515, -0.26103925704956055, -0.39604082703590393, -1.2394943237304688, 0.6860774755477905, 0.13610398769378662, 0.5848193168640137, -1.352685570716858, -1.014024019241333, -0.024118725210428238, -0.40014779567718506, 0.033405616879463196, -0.7378074526786804, 0.5902814865112305, -0.5089199542999268, 0.0823550596833229, -0.312859445810318, -1.1430809497833252, 0.09485375136137009, -0.1364918351173401, -0.6383758187294006, -0.12039893120527267, 0.11714678257703781, 0.3265865743160248, -0.9182433485984802, 0.029555780813097954, -0.2273847460746765, 0.2601623237133026, -0.7118318676948547, 1.4279041290283203, -0.04916426166892052, -0.09639454632997513, 0.6565665006637573, -0.3728512227535248, 0.11544888466596603, 0.12586408853530884, 0.5340638756752014, -0.6801577210426331, -0.1813524216413498, 0.7004189491271973, -0.6208796501159668, 1.4348119497299194, -0.41728076338768005, 0.5868720412254333, 0.42965012788772583, -0.5456200242042542, 0.08083859086036682, 0.840628981590271, 0.1252552568912506, -0.39103037118911743, 0.12726525962352753, 0.08204062283039093, -0.40773218870162964, 0.3204193711280823, 0.21523398160934448, 0.9174697995185852, 0.2300361692905426, 0.5659948587417603, 0.9905980229377747, -0.12016545981168747, 0.7250500917434692, 0.2631320357322693, 0.7324362993240356, 0.09488634020090103, 0.43317562341690063, -0.2785218358039856, 0.07551143318414688, -0.9957320690155029, 0.23064856231212616, -0.06995789706707001, 0.14038461446762085, 0.5953001379966736, 0.01318938098847866, -0.3350328505039215, -0.22262907028198242, -0.22198887169361115, 0.725510835647583, 1.5929237604141235, -0.6570756435394287, -0.20540212094783783, -1.188591480255127, -0.5392704010009766, -0.5809103846549988, 0.005963668692857027, 0.23407378792762756, -0.0946088507771492, -0.5897102952003479, -0.8680322766304016, 0.7509435415267944, 0.35413506627082825, 0.8764281272888184, -0.4700849950313568, -0.4266080856323242, -0.05819466710090637, 0.5188537836074829, -0.6194004416465759, -0.7936975955963135, 0.9052352905273438, -0.4361838400363922, -0.20487478375434875, -0.18083800375461578, -0.2590984106063843, 0.11287291347980499, -0.11889225989580154, 0.5556901693344116, -0.8053739070892334, -0.2377159148454666, 0.15473616123199463, 0.5572296380996704, -1.2299679517745972, -1.1663686037063599, 0.2320404350757599, 0.6776629686355591, -0.19395576417446136, 0.10906273126602173, 0.14102140069007874, 0.13826380670070648, 0.09852565824985504, -0.13365553319454193, -0.41017165780067444, 0.012365848757326603, 0.22752459347248077, 0.4405341148376465, 0.11202060431241989, 0.5974352955818176, -1.2057065963745117, 0.7134156823158264, 0.13579386472702026, -0.25890034437179565, -0.06263025104999542, -1.0268198251724243, 0.16568678617477417, 0.2584410011768341, -0.4452788233757019, -0.4734335243701935, -0.21704766154289246, 0.34045884013175964, -0.24217690527439117, -0.3655799627304077, -0.3482153117656708, 0.33169910311698914, 0.1479976326227188, 0.5329406261444092, 0.655997633934021, 0.9267487525939941, 0.19919399917125702, 0.5973033308982849, -0.5414320230484009, 0.38864418864250183, 0.5676711797714233, 0.499798059463501, -0.017408166080713272, -0.6939985752105713, -0.979398787021637, -0.5184363126754761, -0.6451562643051147, -0.11714612692594528, -0.14552314579486847, -0.09572022408246994, -0.8250223398208618, -0.8078821897506714, -0.16063472628593445, -0.8284071683883667, 0.010803000070154667, -0.5028082132339478, 0.037336673587560654, -0.6748855710029602, -0.604058027267456, -0.9955774545669556, -1.4136091470718384, -0.7873618602752686, -0.5630821585655212, 0.22104483842849731, 0.04134351387619972, -0.30303916335105896, -0.17197659611701965, -0.00528531102463603, 0.02125464752316475, 0.9694879651069641, -1.4159895181655884, 0.27905574440956116, -0.10655736178159714, 0.09971146285533905, 0.09954586625099182, 0.05041856691241264, 0.7757543325424194, -0.037898194044828415, -0.022784395143389702, -1.227752685546875, 0.09258623421192169, -0.386299729347229, -0.3549637794494629, 0.3547056019306183, 0.2016950249671936, 0.55878746509552, -0.1807166039943695, -0.3794391453266144, 0.34050026535987854, 0.992598831653595, -0.5175907611846924, -0.35297301411628723, -0.21388380229473114, 0.9222742915153503, 0.7192649841308594, -0.5948389768600464, 0.23656797409057617, 0.6262179017066956, 0.5599178075790405, -0.03517032042145729, -0.4463436007499695, -0.3750843107700348, -0.5668711066246033, 0.3744012713432312, 1.7166091203689575, 0.41842713952064514, 0.23536796867847443, -0.4458007216453552, 1.0099087953567505, -1.2320507764816284, -0.8017124533653259, 0.7380388975143433, 0.514880895614624, 0.22361096739768982, -0.5311053991317749, 0.10151004791259766, 0.4026176631450653, 0.5471836924552917, 0.5797312259674072, -0.42685261368751526, -0.5944215059280396, -0.10695362836122513, 0.1565922051668167, 0.6048035621643066, 0.23725658655166626, -0.5696210861206055, 0.7361741662025452, 15.008650779724121, 0.7055636048316956, 0.08548923581838608, 0.9947329163551331, 0.12428198009729385, 0.41772985458374023, -0.21706342697143555, -0.067628413438797, -0.9170323610305786, -0.2189418226480484, 1.3210716247558594, 0.35349133610725403, 0.9775558710098267, 0.3625048100948334, -0.03215772286057472, 0.25694984197616577, -0.08132825791835785, 0.7882604002952576, 0.6889306306838989, -1.0532803535461426, 0.0669686421751976, -0.06426577270030975, 0.2923664450645447, 0.5345181822776794, 0.3391856849193573, 0.5442034006118774, 0.5699878334999084, 0.35543784499168396, 0.26178810000419617, 0.031316809356212616, 0.8423746228218079, -0.11433598399162292, 0.019341126084327698, 0.4898947775363922, -0.8306260704994202, -0.41519641876220703, -0.5016253590583801, -0.5098754167556763, 0.07927507162094116, 0.2207900881767273, -0.563123345375061, -0.6651440858840942, -0.11372467130422592, 0.2868080735206604, 0.4141412675380707, 0.22334524989128113, -0.13752661645412445, 1.0689072608947754, -0.07980796694755554, 0.2255038172006607, -0.2602274417877197, 0.7129672765731812, 0.5168861746788025, 0.167878657579422, -0.20804762840270996, -0.11269465833902359, -0.12930449843406677, 0.043703675270080566, -0.27525994181632996, 0.015411478467285633, -0.4546433389186859, -0.26827776432037354, -0.40485915541648865, 0.6790454387664795, 0.7339304089546204, 0.3217809498310089, -0.12439816445112228, 0.5114119052886963, 0.7699942588806152, 0.2338109165430069, 0.15394829213619232, 0.14963982999324799, 0.4772673547267914, -0.29452595114707947, -0.23525258898735046, 0.43817082047462463, -0.03272554650902748, -0.5119646787643433, -0.7477270364761353, -0.25705257058143616, 0.4030175805091858, -0.7791022062301636, -1.0509729385375977, 1.1267746686935425, -0.4569327235221863, -0.10440700501203537, 0.19123470783233643, -0.642579197883606, -0.29784074425697327, -0.006120253819972277, -1.1782530546188354, -0.20354267954826355, 0.4722180962562561, -0.4285176992416382, -0.1580229103565216, -0.7515281438827515, 1.4278484582901, 0.13641023635864258, -0.6072239875793457, 0.44446861743927, 0.17419320344924927, -0.3527912199497223, -0.00226127402856946, -0.7010130882263184, 0.5926476120948792, 0.025865092873573303, 0.04031616449356079, 0.05433586612343788, 0.19181285798549652, 0.471297949552536, -0.4522663652896881, -0.16643545031547546, 0.7327937483787537, -0.26312437653541565, -0.4673766791820526, -0.5324608087539673, -0.6731283664703369, -0.29537323117256165, 0.5825461149215698, -0.18934786319732666, 0.5705698728561401, 0.16241925954818726, -0.6274376511573792, -0.5341179370880127, -0.7958101630210876, 0.15757974982261658, 1.075264573097229, -1.0470061302185059, -0.22025713324546814, 0.36718639731407166, 0.29745393991470337, -0.36826300621032715, -0.4027697741985321, -0.21011680364608765, -0.2112618386745453, 0.09289462864398956, 0.5559791922569275, -0.29913148283958435, -0.21244579553604126, 0.5589711666107178, -0.04523978382349014, -1.1796880960464478, -0.04785100743174553, -1.245509147644043, -0.2467215657234192, 0.44292163848876953, 0.5081619024276733, -0.43969738483428955, 0.7283545136451721, 0.517114520072937, -0.07846011966466904, -0.016643481329083443, -0.9779335856437683, -0.47775691747665405, -0.5936030149459839, -0.22849957644939423, 0.25658389925956726, 0.06988021731376648, 0.08333039283752441, 0.3472462296485901, 0.6365800499916077, 0.6516016125679016, 0.2511577010154724, -0.8442354202270508, 0.4130628705024719, -0.21583910286426544, 0.2816772758960724, -0.5181587338447571, -0.39809170365333557, -0.8766019344329834, 0.49705204367637634, -1.4298995733261108, 0.1677575409412384, -0.8565753102302551, -0.47883540391921997, 0.11609823256731033, -0.15156100690364838, -0.14976973831653595, 0.5432387590408325, -0.5268107056617737, -0.5046564340591431, -0.31587696075439453, -0.5588439702987671, 0.7679473161697388, 0.4385695159435272, -1.0298689603805542, -0.33924615383148193, 0.22226472198963165, -0.15115617215633392, 0.5443268418312073, 0.6909106969833374, -0.5356815457344055, -0.8433736562728882, -0.9138683676719666, -0.26886045932769775, -0.17491117119789124, -0.13775020837783813, -1.1826095581054688, 0.7993651628494263, 0.3895907700061798, -0.6460167765617371, -0.10987251251935959, 0.3070034980773926, -1.064963936805725, -0.21279318630695343, 0.3015938997268677, -0.8377959132194519, -0.3179250657558441, -0.24754877388477325, -0.2176363170146942, -0.5340200662612915, 0.337375670671463, 0.17147664725780487, -1.1912922859191895, -0.3387659788131714, 0.1862560659646988, -0.754336416721344, 0.056215569376945496, -0.05762528255581856, -0.14672289788722992, -0.89991694688797, -0.10757140815258026, -0.22940360009670258, 0.2464297115802765, -0.6925658583641052, 0.8042284250259399, 0.1169937327504158, -1.0285558700561523, 0.08402345329523087, 0.5481418371200562, 0.3759949505329132, -0.2824634611606598, 0.8758666515350342, 0.008980671875178814, 0.021375421434640884, 0.5710941553115845, 0.12670692801475525, 0.2840687334537506, -0.8458462357521057, -0.06685970723628998, 0.8597960472106934, -0.2234867662191391, 0.1965121179819107, 0.9110379815101624, -0.3003299832344055, -1.3750470876693726, 0.34319889545440674, -0.7832580804824829, -0.38101640343666077, -0.04432499408721924, 0.2848946154117584, 0.6584741473197937, -0.30293920636177063, -0.26379698514938354, -0.3511665463447571, 0.03592442721128464, 0.04240908473730087, -0.5547852516174316, 0.5567165613174438, -0.2278645932674408, 0.12377390265464783, 0.5966529846191406, 0.6023550033569336, -0.7317095398902893, -1.128286361694336, -0.6852121353149414, -0.5188635587692261, 0.3984399735927582, 0.5153647065162659, -0.11508575081825256, -0.9243630766868591, 0.5961112976074219, 0.9380971789360046, 0.46579796075820923, -0.20197753608226776, -0.11652468144893646, 0.1835339218378067, 0.5762156844139099, 0.15187598764896393, -1.3715964555740356, -0.5086420178413391, 1.1718640327453613, 1.1468130350112915, -1.0341544151306152, 0.07325844466686249, -0.7103073000907898, -0.9335983991622925, 0.57469642162323, 0.37130728363990784, 0.18962734937667847, 1.1386947631835938, -0.2657826542854309, 0.32415780425071716, -0.05508856102824211, -0.9708632230758667, -0.9568649530410767, 0.6421301364898682, 1.286998987197876, 0.7620136141777039, 0.481507271528244, 0.21383202075958252, 0.8569967746734619, -0.22037069499492645, -0.2037387639284134, 0.4253290593624115, 0.20695610344409943, -0.24811355769634247, 0.1167682632803917, 0.42430752515792847, 0.7364480495452881, -0.49710020422935486, -0.2109474539756775, 0.3594721257686615, 0.07364916801452637, 0.303940087556839, 0.9699767231941223, 0.6132603287696838, -0.1671101301908493, 0.7206458449363708, 0.4349461793899536, 0.21177968382835388, -0.8519892692565918, -0.34690752625465393, -0.03796793147921562, -0.044178556650877, -0.049806736409664154, -0.4596867263317108, -0.8180059194564819, -0.7673541903495789, 0.3145408630371094, -0.251414030790329, 0.20188960433006287, 1.1179851293563843, 0.7556740045547485, 0.8941649198532104, 0.6449116468429565, 0.267582505941391, -0.22172324359416962, -0.5177985429763794, -0.9363667964935303, -0.16844245791435242, -0.7474406361579895, -0.28069067001342773, -0.08936355262994766, -0.553159236907959, -0.26338693499565125]}, "authors": [{"authorId": "2275197086", "name": "Luis Lugo"}, {"authorId": "2275205582", "name": "Valentin Vielzeuf"}], "references": [{"paperId": "67377c8759a5a21ed27a8f6eee585dde1c3bd6a7", "title": "On the (In)Efficiency of Acoustic Feature Extractors for Self-Supervised Speech Representation Learning"}, {"paperId": "a66bf047e0830c24e6e91c583a8c27632d7995ab", "title": "SummaryMixing: A Linear-Complexity Alternative to Self-Attention for Speech Recognition and Understanding"}, {"paperId": "1dc2d0f43df7f7a7847817203411357eca79a5b3", "title": "Reducing Barriers to Self-Supervised Learning: HuBERT Pre-training with Academic Compute"}, {"paperId": "e4f2d75856ce149b994f079ae50fd33ca47245d3", "title": "DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models"}, {"paperId": "f2ff978e9ca296e66d1cfe3aa4fa94703d6fc22a", "title": "READ: Recurrent Adaptation of Large Transformers"}, {"paperId": "f7b96d49d4efbefbe4c679331683b8c50393f505", "title": "DinoSR: Self-Distillation and Online Clustering for Self-supervised Speech Representation Learning"}, {"paperId": "6007263dd3d14373be5f84fb6ccb0be3f7fce903", "title": "Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning"}, {"paperId": "1028bf42a4c792acefd3be9da45e58f2b1620fe3", "title": "Structured Pruning of Self-Supervised Pre-Trained Models for Speech Recognition and Understanding"}, {"paperId": "998ac3e945857cf2676ee7efdbaf443a0c6f820a", "title": "Hyena Hierarchy: Towards Larger Convolutional Language Models"}, {"paperId": "911ef69f9f0a8d3f396814e85dd79ce3ed9140b9", "title": "Stabilising and Accelerating Light Gated Recurrent Units for Automatic Speech Recognition"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "d8496775f90ca21735decc238855550c11efd85a", "title": "Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language"}, {"paperId": "a6fbb4e63cac9bc243f79ec61fccdb7e335032d0", "title": "MelHuBERT: A Simplified Hubert on Mel Spectrograms"}, {"paperId": "8b23ea62c8b3b0bab039247c1f7c8bd62ffdab48", "title": "Accidental Learners: Spoken Language Identification in Multilingual Self-Supervised Models"}, {"paperId": "901e2c286da05e34669c2aef50ed9b4b54d81451", "title": "Comparative Layer-Wise Analysis of Self-Supervised Speech Models"}, {"paperId": "bb0e9064f28cb8befc9ec049278d531b515a430d", "title": "Extracting Speaker and Emotion Information from Self-Supervised Speech Models via Channel-Wise Correlations"}, {"paperId": "40e4e877f8eff6bf3df25ce3f709830215887d27", "title": "Match to Win: Analysing Sequences Lengths for Efficient Self-Supervised Learning in Speech and Audio"}, {"paperId": "1d91bc3979e87380c31ac8aa152919228a639a04", "title": "Deep versus Wide: An Analysis of Student Architectures for Task-Agnostic Knowledge Distillation of Self-Supervised Speech Models"}, {"paperId": "eaef083b9d661f42cc0d89d9d8156218f33a91d9", "title": "Long Range Language Modeling via Gated State Spaces"}, {"paperId": "960d40497717ad22a7ebb84db238fa2415fc89cc", "title": "LST: Ladder Side-Tuning for Parameter and Memory Efficient Transfer Learning"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "f76a5b176f3435214eb87dd105f730f0b53672c3", "title": "Self-Supervised Speech Representation Learning: A Review"}, {"paperId": "e37ae30846ad20539b7ae84ed64229bf9b0abeed", "title": "On-demand compute reduction with stochastic wav2vec 2.0"}, {"paperId": "8eed13f1f9dabd0bc5952e65b739598f426beb04", "title": "Federated Self-supervised Speech Representations: Are We There Yet?"}, {"paperId": "2ad12a7be5eaf339a98c4defd8669e11fe726acc", "title": "MaxViT: Multi-Axis Vision Transformer"}, {"paperId": "737e04f68423170fc68f19596950ed255a78c5af", "title": "Autoregressive Co-Training for Learning Discrete Speech Representations"}, {"paperId": "d77f01d3df9e2f1fd05f5bd51eb283afa691bb27", "title": "LightHuBERT: Lightweight and Configurable Speech Representation Learning with Once-for-All Hidden-Unit BERT"}, {"paperId": "8f2bca9d684005675e294b33c26481e36f528cdb", "title": "data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language"}, {"paperId": "0228d04512e04306ed5971117a4e07d11df458b8", "title": "SPIRAL: Self-supervised Perturbation-Invariant Representation Learning for Speech Pre-Training"}, {"paperId": "d92e0443768ec3715205cb232ef1a1917372b0af", "title": "ESPnet-SLU: Advancing Spoken Language Understanding Through ESPnet"}, {"paperId": "19dbb57ad106137553bff4282149ac2800b5c176", "title": "XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale"}, {"paperId": "416dab850fda842b13a4f28164514d98f836fff7", "title": "WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing"}, {"paperId": "aa62d5e43cb151cd574e4df058b4c6a509d62644", "title": "Self-Supervised Representation Learning: Introduction, advances, and challenges"}, {"paperId": "d96c3d7de60765fe77df0427d55cd267d4614c15", "title": "Wav2vec-Switch: Contrastive Learning from Original-Noisy Speech Pairs for Robust Speech Recognition"}, {"paperId": "70c4f2cbf88bbd9583a1a23fff82faa8cffa5e2b", "title": "Distilhubert: Speech Representation Learning by Layer-Wise Distillation of Hidden-Unit Bert"}, {"paperId": "586cafd248d01c1a1c67a57b3cef9f807173110c", "title": "Performance-Efficiency Trade-Offs in Unsupervised Pre-Training for Speech Recognition"}, {"paperId": "a7d61ab4a3442fd2382f6c11f991421c0d98674a", "title": "Layer-Wise Analysis of a Self-Supervised Speech Representation Model"}, {"paperId": "339b2b711fb5b228d097b03ebc3e62a521779235", "title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "4fffa5245d3972077c83614c2a08a47cb578631e", "title": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units"}, {"paperId": "362635eb7cd72d4ca7414cb257dadbced12fbe8f", "title": "PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition"}, {"paperId": "656ed155c2d345c19d9bff4b50f2ae00db8407cc", "title": "Compacter: Efficient Low-Rank Hypercomplex Adapter Layers"}, {"paperId": "d5e999aae76d5270ef272076979c809817458212", "title": "An Attention Free Transformer"}, {"paperId": "1f133158a8973fb33fea188f20517cd7e69bfe7f", "title": "FNet: Mixing Tokens with Fourier Transforms"}, {"paperId": "d8e81e80490113434f7ac338c5f8d5a23f05a3de", "title": "SUPERB: Speech processing Universal PERformance Benchmark"}, {"paperId": "2a500dae25af18424997733df2e1600250293f40", "title": "The Zero Resource Speech Challenge 2021: Spoken Language Modelling"}, {"paperId": "b257038ef379092509b1dd1d66a351f47363d6eb", "title": "LeBenchmark: A Reproducible Framework for Assessing Self-Supervised Representation Learning from Speech"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "67958614e6d80f8e7e789f47db2ef11654326289", "title": "Integration of Pre-Trained Networks with Continuous Token Interface for End-to-End Spoken Language Understanding"}, {"paperId": "cf63ee2eb587fd91ab887f08fc9aed734c73f7be", "title": "Leveraging Pre-Trained Representations to Improve Access to Untranscribed Speech from Endangered Languages"}, {"paperId": "dc9d32cab9f8856455821925eab7cb9f1fa9a18e", "title": "Self-Supervised Pretraining Improves Self-Supervised Pretraining"}, {"paperId": "253c6c9e6b976d0b89052a21249ff23146a81a4b", "title": "Wav2vec-C: A Self-supervised Model for Speech Representation Learning"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "255e6239bcc51047d020d41ce0179c1270f3c22f", "title": "Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning"}, {"paperId": "29911d41f88c0f6412ea0b4112bc6c3c37377ba1", "title": "The Zero Resource Speech Benchmark 2021: Metrics and baselines for unsupervised spoken language modeling"}, {"paperId": "3199b35d570c17c6eedd5e538333cb3410e89b67", "title": "Semi-Supervised Spoken Language Understanding via Self-Supervised Speech and Language Model Pretraining"}, {"paperId": "9ff525d1ebd389c359ddbf06df3e99c433c2bf9e", "title": "Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "c828f4bf1a752700dd2c4a96fdd08ba938cda43d", "title": "Cluster-Former: Clustering-based Sparse Transformer for Question Answering"}, {"paperId": "57d67fe8981cb2689693c55710666fdbe1c10e9b", "title": "Taming Resource Heterogeneity In Distributed ML Training With Dynamic Batching"}, {"paperId": "f2f3c91fad164c8919699159e8eab511f03d0fe2", "title": "Relating by Contrasting: A Data-efficient Framework for Multimodal Generative Models"}, {"paperId": "863d7fdbdcd4bdb1b6eeb9c99ae144d236f03259", "title": "Unsupervised Cross-lingual Representation Learning for Speech Recognition"}, {"paperId": "49a049dc85e2380dde80501a984878341dd8efdf", "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations"}, {"paperId": "38f93092ece8eee9771e61c1edaf11b1293cae1b", "title": "Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "0170fc76e934ee643f869df18fb617d5357e8b4e", "title": "Conformer: Convolution-augmented Transformer for Speech Recognition"}, {"paperId": "8af925f4edf45131b5b6fed8aa655089d58692fa", "title": "Lite Transformer with Long-Short Range Attention"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "7af72a461ed7cda180e7eab878efd5f35d79bbf4", "title": "A Simple Framework for Contrastive Learning of Visual Representations"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "4287533d12143cdbc4948b60ecece28b6c750f17", "title": "Side-Tuning: A Baseline for Network Adaptation via Additive Side Networks"}, {"paperId": "f59c038dee828e0a8c2fc28130d12e39ee4952d6", "title": "Libri-Light: A Benchmark for ASR with Limited or No Supervision"}, {"paperId": "4097148c147f06b54802000a8476d28e525c63cf", "title": "Specaugment on Large Scale Datasets"}, {"paperId": "20ba55ee3229db5cb190a00e788c59f08d2a767d", "title": "Self-Training With Noisy Student Improves ImageNet Classification"}, {"paperId": "a2cd2944fab5b3d03e194895a13f82ec853b949d", "title": "Multi-condition training for noise-robust speech emotion recognition"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "d9c3bc1c2915ff02d33f66c800ad756cb87821d6", "title": "Transformer-Based Acoustic Modeling for Hybrid Speech Recognition"}, {"paperId": "84913d6f08942ddf8dd51418820537abfaa5ae19", "title": "vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations"}, {"paperId": "f20f40a28f0e6a18f6008ef333d04a84e7ef32fd", "title": "From Senones to Chenones: Tied Context-Dependent Graphemes for Hybrid Speech Recognition"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "27ac832ee83d8b5386917998a171a0257e2151e2", "title": "Attention Augmented Convolutional Networks"}, {"paperId": "b0fae9fbb4e580d92395eabafe73e317ae6510e3", "title": "SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition"}, {"paperId": "bdc046e65bc80cf13929ca0c3934d6faee830723", "title": "Convolutional Self-Attention Networks"}, {"paperId": "07b1a0ed6ba8a497355ac105e9110a927e3cf913", "title": "Dataset Distillation"}, {"paperId": "a364a2b6bb97fcb4207468e6500cf3042bbf8d07", "title": "Speech Recognition"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "360cfa09b2f7c8e10b1831d899c5a51aefa1883e", "title": "Light Gated Recurrent Units for Speech Recognition"}, {"paperId": "083ec74cc10f96fbb64322ba23450666fd4df6cd", "title": "Speech2Vec: A Sequence-to-Sequence Framework for Learning Word Embeddings from Speech"}, {"paperId": "8c1b00128e74f1cd92aede3959690615695d5101", "title": "QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension"}, {"paperId": "e7fd6848cb29ca221a7e17d823e06fb566f1f135", "title": "Mixed Precision Training"}, {"paperId": "29e944711a354c396fad71936f536e83025b6ce0", "title": "Categorical Reparameterization with Gumbel-Softmax"}, {"paperId": "13497bd108d4412d02050e646235f456568cf822", "title": "Deep Speech 2 : End-to-End Speech Recognition in English and Mandarin"}, {"paperId": "9cee45ef1212ebbc7d468f9b1d7df24f5005e64d", "title": "Highway long short-term memory RNNS for distant speech recognition"}, {"paperId": "34038d9424ce602d7ac917a4e582d977725d4393", "title": "Librispeech: An ASR corpus based on public domain audio books"}, {"paperId": "223e9b53fc271d451801fb63869945a0d8c2ed61", "title": "An investigation of deep neural networks for noise robust speech recognition"}, {"paperId": "a97b5db17acc731ef67321832dbbaf5766153135", "title": "Supervised Sequence Labelling with Recurrent Neural Networks"}, {"paperId": "5ef82a8c8aa50f99285f2143b57ca4e82da1af80", "title": "Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning"}, {"paperId": "15d70fd0fb93b01fc31cf51d2b1bb5ebf465d6b4", "title": "On the Nature of Discrete Speech Representations in Multilingual Self-supervised Models"}, {"paperId": "547dc53aaf3ec60d307556e22cc5c3fe54b95329", "title": "Dataset Distillation with Attention Labels for Fine-tuning BERT"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "\u201cFithu-bert: Going thinner and deeper for knowledge distillation of speech self-supervised learning,\u201d"}, {"paperId": null, "title": "\u201cSus-tainable ai: Environmental implications, challenges and opportunities,\u201d"}]}