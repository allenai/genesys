{"paperId": "a01e1138600499f65462ed3d51c3e76af1aad18c", "title": "The pitfalls of next-token prediction", "abstract": "Can a mere next-token predictor faithfully model human intelligence? We crystallize this emerging concern and correct popular misconceptions surrounding it, and advocate a simple multi-token objective. As a starting point, we argue that the two often-conflated phases of next-token prediction -- autoregressive inference and teacher-forced training -- must be treated distinctly. The popular criticism that errors can compound during autoregressive inference, crucially assumes that teacher-forcing has learned an accurate next-token predictor. This assumption sidesteps a more deep-rooted problem we expose: in certain classes of tasks, teacher-forcing can simply fail to learn an accurate next-token predictor in the first place. We describe a general mechanism of how teacher-forcing can fail, and design a minimal planning task where both the Transformer and the Mamba architecture empirically fail in that manner -- remarkably, despite the task being straightforward to learn. Finally, we provide preliminary evidence that this failure can be resolved using a simple modification that predicts multiple tokens in advance. We hope this finding can ground future debates and inspire explorations beyond the next-token prediction paradigm. We make our code available under https://github.com/gregorbachmann/Next-Token-Failures", "venue": "arXiv.org", "year": 2024, "citationCount": 11, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A general mechanism of how teacher-forcing can fail is described, and a minimal planning task where both the Transformer and the Mamba architecture empirically fail in that manner -- remarkably, despite the task being straightforward to learn."}, "embedding": {"model": "specter_v2", "vector": [0.2604731023311615, 1.4130584001541138, -0.5597708821296692, 0.04994920268654823, -0.2404620498418808, -0.17299868166446686, 1.0665770769119263, -0.24281848967075348, -0.1874365657567978, -0.050905581563711166, 0.346465528011322, -0.2587197721004486, 0.27149873971939087, -0.0051461802795529366, -0.06427770853042603, -0.16245156526565552, -0.7842913866043091, 0.41413670778274536, -0.2036701887845993, -0.34601688385009766, -0.0463629849255085, -0.8065500855445862, -1.0136133432388306, 0.016729887574911118, 0.463905930519104, 0.4884625971317291, -0.03010835312306881, 0.59852135181427, -0.13264517486095428, 1.1200945377349854, 0.3552244007587433, -0.25404268503189087, 0.44998201727867126, -0.015013805590569973, -0.9226126074790955, -0.25705304741859436, 0.16127625107765198, -0.4118227958679199, -0.5674779415130615, 0.6928156018257141, -0.6069103479385376, 0.10270124673843384, 0.4326956570148468, -1.1148645877838135, -0.037843432277441025, 1.263442873954773, 0.8923118114471436, 0.7121297717094421, -0.22888539731502533, -0.40790921449661255, 1.4475245475769043, -0.575789213180542, 0.22237931191921234, 1.41568922996521, 0.4224141240119934, 0.44663456082344055, -0.207804873585701, -0.3689197897911072, 1.1992313861846924, 0.3491727411746979, -0.9892483353614807, -0.6380107998847961, 0.0881379097700119, -0.21998398005962372, 1.5346399545669556, -0.6710081100463867, 0.08988383412361145, 0.3056453764438629, -0.03736250475049019, 1.4883781671524048, 0.23497813940048218, -0.9645825028419495, -0.22765567898750305, 0.17631514370441437, 0.34132885932922363, 0.5214916467666626, -0.6849052906036377, 0.3853157162666321, -1.074414610862732, 0.20840029418468475, 0.5066747069358826, -0.26636695861816406, 0.28132039308547974, 0.3359513282775879, -0.2662383019924164, 0.3464418053627014, 0.09211287647485733, 1.001322627067566, -0.6513799428939819, 0.877153754234314, 0.35269895195961, 0.4630354940891266, -0.12393670529127121, 0.23364441096782684, -0.022632425650954247, 0.016241924837231636, -0.781834602355957, 0.22657565772533417, -0.028608517721295357, 0.9573961496353149, 0.0745924860239029, 0.8048537969589233, -0.989480197429657, -0.24276041984558105, 1.2463363409042358, -0.2862618863582611, 0.6420090198516846, -1.104756474494934, 0.21670155227184296, -0.6831082105636597, 0.7961297035217285, -0.471987783908844, -0.3541968762874603, 0.03217964619398117, -0.7094057202339172, -0.9286102056503296, -0.01181847508996725, 0.2830309569835663, -0.9168529510498047, 0.4394456744194031, -0.420390784740448, -0.07199449092149734, -0.15248562395572662, 0.8315017223358154, -0.01687905378639698, 0.21963371336460114, 0.46138229966163635, -0.028808822855353355, 0.8503335118293762, -0.5271677374839783, -0.7267542481422424, -1.1186308860778809, 0.03397068381309509, 0.08788131922483444, 0.040274593979120255, 0.1380111426115036, -1.5235873460769653, -1.162104606628418, -1.1005955934524536, 0.07938079535961151, -0.08451292663812637, 0.06350984424352646, 1.545697569847107, 0.2521778345108032, -0.8303459286689758, 1.1163616180419922, -0.6966911554336548, 0.4394311010837555, 0.2998618483543396, 0.2486005425453186, 0.20651690661907196, 0.028317980468273163, -1.1424610614776611, 0.5829819440841675, 0.4443490505218506, -0.37957262992858887, -0.5563836097717285, -0.3874638080596924, -0.7807478904724121, 0.1898948848247528, 0.6589856743812561, -0.29548031091690063, 1.6803829669952393, -0.47210970520973206, -1.3366565704345703, 0.372623085975647, -0.7077091932296753, -0.23113632202148438, 0.48763543367385864, 0.03906764090061188, -0.45295968651771545, -0.23993119597434998, -0.051085565239191055, 0.49060291051864624, 0.5205671787261963, -0.2435995489358902, -0.4955759346485138, 0.01064422819763422, -0.2235945165157318, -0.28127723932266235, 0.19406235218048096, 0.6234018206596375, 0.1871253103017807, 0.17065076529979706, 0.4474658966064453, 0.7999128699302673, -0.18509447574615479, -0.7688812613487244, -0.4673311412334442, -1.7566502094268799, -0.27794504165649414, 0.06729119271039963, 0.8686019778251648, -0.6466090679168701, -1.0716625452041626, -0.11701969057321548, -0.19360147416591644, -0.3898429870605469, -0.40766453742980957, 0.21353855729103088, -0.4448763430118561, 0.5770158767700195, 0.3340488076210022, -0.8555604219436646, 0.4527733027935028, -0.3764652609825134, -0.720757007598877, -0.09356085956096649, 0.2298879623413086, 0.8175294995307922, -0.8879553079605103, -0.17758116126060486, 0.25496727228164673, 0.03703700378537178, -0.6679267883300781, 1.1754378080368042, -0.3943898379802704, 0.29223546385765076, -0.4015163779258728, -0.3134956359863281, -0.06200788542628288, -0.31167906522750854, 0.653937578201294, -0.1752757579088211, -0.33628469705581665, 0.7953071594238281, -0.692264974117279, 1.2888591289520264, -0.14454880356788635, 0.39517632126808167, -0.26266294717788696, -0.8449418544769287, -0.07678801566362381, 0.6601475477218628, 0.09647120535373688, -0.5857573747634888, 0.14835605025291443, 0.22096021473407745, -0.1817549467086792, 0.4327995479106903, 0.5818253755569458, 0.647588312625885, -0.3665904402732849, 0.21267955005168915, 0.5686696171760559, -0.20946252346038818, 0.45865222811698914, 0.297157347202301, 0.6964955925941467, 0.6413968801498413, 0.6553221940994263, -0.07000240683555603, 0.03421342745423317, -0.4191077947616577, 0.49593719840049744, 0.8833588361740112, 0.33423730731010437, 0.5303327441215515, 0.31597310304641724, -1.2313196659088135, -0.5184879302978516, 0.20939111709594727, 0.6094924211502075, 1.401766300201416, -0.3909839391708374, -0.19690436124801636, -0.6709001660346985, -0.16348446905612946, -0.5958980321884155, 0.7866590023040771, -0.3880768418312073, 0.11599550396203995, -0.6387291550636292, -0.6142550706863403, 0.5503516793251038, 0.042196158319711685, 0.9173874855041504, -0.8349320292472839, -0.3850184679031372, 0.14128617942333221, 0.23505941033363342, -0.8173787593841553, -0.09682239592075348, 0.5349953770637512, -0.21182937920093536, -0.25341010093688965, 0.3372376263141632, 0.1330745369195938, 0.01704125851392746, -0.6988884806632996, 0.9511803984642029, -0.034208573400974274, -0.00827508233487606, 0.3300209641456604, 0.6464897394180298, -0.8821534514427185, -0.530199408531189, 0.07929697632789612, 0.31480786204338074, -0.3069181740283966, 0.5298511385917664, 0.22378478944301605, -0.221285879611969, -0.19343070685863495, 0.055108532309532166, 0.4846291244029999, 0.24161109328269958, 0.04473903030157089, 0.40053656697273254, 0.27797234058380127, 0.19230981171131134, -1.082659125328064, 0.4698476493358612, -0.12804438173770905, -0.6313807964324951, 0.05790190398693085, -1.2064377069473267, -0.35745078325271606, 0.7869663834571838, -0.39891132712364197, -0.3335750102996826, -0.7645682096481323, 0.3028208315372467, -0.07603545486927032, -0.8364743590354919, 0.016152193769812584, 0.29618069529533386, 0.43817204236984253, 0.05119849741458893, 0.8323445916175842, 0.11339777708053589, -0.06702404469251633, 0.4523216784000397, -0.9114286303520203, 0.853761613368988, 0.28118014335632324, 0.1102340817451477, -0.21716560423374176, -0.12884432077407837, -0.382908433675766, -0.8126072883605957, -0.2132945954799652, -0.49891144037246704, -0.4111551344394684, 0.12128865718841553, -0.9464945793151855, -1.4800280332565308, -0.041110679507255554, -1.2081570625305176, -0.8714123368263245, 0.10093329101800919, -0.4209219217300415, -0.5828571915626526, -1.2019997835159302, -1.096840262413025, -0.9543055295944214, -0.47884535789489746, -0.7299945950508118, 0.09372362494468689, 0.1383175551891327, -0.6682416200637817, -0.35729193687438965, -0.22041650116443634, -0.04172072559595108, 0.6490451693534851, -0.964017391204834, 0.4485785961151123, -0.3715425133705139, -0.5052965879440308, 0.0655241310596466, 0.6450780034065247, 0.10130743682384491, -0.3699037730693817, -0.10539975762367249, -1.0167808532714844, 0.4105650782585144, -0.3367624580860138, -0.32497939467430115, -0.04587770625948906, 0.03954995796084404, 0.5666397213935852, -0.5828291177749634, -0.43609341979026794, -0.058694347739219666, 1.2524627447128296, -0.5289294123649597, 0.5399325489997864, 0.48874393105506897, 0.9751905798912048, 0.30011051893234253, 0.04874386638402939, 0.5759795308113098, 0.7489861249923706, 0.4769769608974457, 0.2859518826007843, 0.37527862191200256, -0.0734160766005516, -0.6649401783943176, 0.6338152885437012, 0.9885092973709106, -0.08689642697572708, 0.08073292672634125, -1.279360055923462, 1.0661864280700684, -1.4800699949264526, -1.1401240825653076, 0.6958733797073364, 0.93250972032547, 0.46037253737449646, -0.15247076749801636, -0.2628220319747925, -0.03687377646565437, 0.10899235308170319, -0.10698840767145157, -0.09750860929489136, -0.6512417197227478, 0.5309499502182007, 0.38811957836151123, 0.13028156757354736, 0.7464408278465271, -0.27022191882133484, 1.0048635005950928, 14.878390312194824, 0.892387866973877, 0.2934633493423462, 0.6709092855453491, 0.5841304063796997, 0.6105703711509705, -0.47288978099823, 0.03130092844367027, -1.274785041809082, 0.0019584016408771276, 1.3773002624511719, -9.775081707630306e-05, 0.8151383996009827, 0.2891896665096283, 0.04238268360495567, -0.12044952809810638, -0.5781108140945435, 0.24810506403446198, 0.30394014716148376, -1.1408979892730713, 0.44199496507644653, -0.05124068260192871, 0.26929235458374023, 0.4364778399467468, 0.3235255181789398, 1.0594110488891602, 1.069311499595642, -0.6849979162216187, 0.8447244167327881, 0.2952422499656677, 0.48995500802993774, -0.2935228645801544, 0.2717483937740326, 0.9142958521842957, -0.7209265232086182, -0.2807704210281372, -0.6220479011535645, -1.550679087638855, 0.15272599458694458, 0.211978942155838, -0.808263897895813, -0.5375404357910156, -0.5539052486419678, -0.14000385999679565, 0.3383513391017914, 0.21092407405376434, -0.49812090396881104, 0.6832799911499023, -0.1894584745168686, 0.2793556749820709, 0.27327442169189453, 0.5524726510047913, 0.004007090348750353, -0.4307398200035095, -0.06494123488664627, 0.2104257494211197, 0.46776288747787476, 0.3768070936203003, -0.26562049984931946, -0.42751649022102356, -0.2200516164302826, -0.11602567881345749, 0.31050238013267517, 0.8638609647750854, 0.4761621057987213, 0.00984612014144659, -0.02520374022424221, 0.05152692645788193, 0.8077599406242371, 0.0057692513801157475, 0.12528197467327118, 0.03121434524655342, 0.3358643651008606, -0.5451481938362122, -0.09459226578474045, 0.5980130434036255, -0.12302187830209732, -0.20623396337032318, -0.8912459015846252, -0.5666697025299072, 0.048908233642578125, -0.7918199896812439, -0.5014786720275879, 0.4733079671859741, -0.45931315422058105, -0.23589837551116943, -0.4509239196777344, -0.3214508295059204, -0.4688900411128998, 0.1976405829191208, -1.398599624633789, -1.0495022535324097, 0.27208203077316284, 0.014181859791278839, -0.2561023235321045, 0.08194249123334885, 1.2377136945724487, -0.1260901242494583, -0.2827669084072113, 0.0036317070480436087, -0.1982661932706833, 0.2753947377204895, -0.3571099042892456, -1.3272281885147095, 0.8099595904350281, 0.2763950228691101, 0.13233356177806854, 0.2298085242509842, 0.23936447501182556, 0.3350638747215271, -0.6632134318351746, 0.18086786568164825, 0.9255841970443726, -1.260241985321045, -0.26181209087371826, -0.39636170864105225, -0.6052020192146301, 0.8861766457557678, 0.6316887140274048, -0.07563422620296478, -0.14482112228870392, 0.28687065839767456, -0.3302329480648041, -0.03071896918118, -0.5888376832008362, 0.24569149315357208, 0.3798316419124603, -0.6160217523574829, -0.771982729434967, 0.0849580392241478, 0.14431500434875488, -0.9706570506095886, -0.67643141746521, -0.6491000652313232, 0.2962436378002167, -0.31745603680610657, 0.6051821112632751, -0.43134647607803345, 0.23197956383228302, 0.6569616198539734, 0.37637636065483093, -1.033989429473877, -0.4735937714576721, -1.1829522848129272, 0.3166501820087433, 0.49142006039619446, 0.5041384696960449, -0.3306422531604767, 0.3850787878036499, 1.3741943836212158, 0.09621787816286087, 0.17513152956962585, -0.9730268716812134, -0.1419297605752945, 0.1856522262096405, -0.8921082019805908, 0.550081193447113, 0.01809309795498848, 0.38340631127357483, 0.14716538786888123, 0.20830084383487701, 0.8356409668922424, -0.05014602467417717, -0.5957794785499573, 0.6385601162910461, -0.07079057395458221, 0.20057815313339233, -0.5738856196403503, -0.2628239691257477, -1.3562930822372437, 0.22728155553340912, -0.6864838004112244, 0.5468758344650269, -1.0369991064071655, -0.6720710396766663, -0.12690377235412598, -0.3369681239128113, 0.4400801360607147, 0.4302726984024048, -0.4150545001029968, -0.055027611553668976, -0.4289768934249878, -0.7343822717666626, 0.4732717275619507, 0.9838318228721619, -0.978111207485199, 0.2973785102367401, 0.1621980220079422, -0.21526919305324554, 0.6515868902206421, 0.5500848293304443, -0.5167441368103027, -0.41060009598731995, -1.0002713203430176, 0.32996228337287903, 0.21693602204322815, -0.022049523890018463, -0.9113553166389465, 1.0579272508621216, 0.13700205087661743, 0.08733740448951721, -0.08548671007156372, 0.3989287316799164, -1.2166457176208496, -0.5562472343444824, -0.06768235564231873, -0.6518290638923645, -0.18905360996723175, -0.15427114069461823, -0.6266824007034302, -0.06628693640232086, 0.3991750478744507, -0.1953805834054947, -1.3028230667114258, -0.8092861771583557, 0.28107166290283203, -0.9453274011611938, -0.059583358466625214, -0.19531555473804474, 0.05478395149111748, -0.9955401420593262, -0.10684829950332642, -0.22916263341903687, 0.5189968347549438, -0.5677496790885925, 0.8306659460067749, 0.22322802245616913, -0.9532756209373474, -0.0360754057765007, 0.20769526064395905, -0.45840588212013245, 0.2599669396877289, 0.4823121130466461, 0.2752714455127716, 0.26621517539024353, 0.9178018569946289, 0.036440905183553696, 0.518658459186554, -0.47760316729545593, -0.12859967350959778, 0.6057839393615723, -0.7299428582191467, -0.19767414033412933, 0.5744694471359253, -0.6871005892753601, -1.005999207496643, 0.28452083468437195, -0.923770546913147, -0.8459725975990295, -0.2648565173149109, 0.924077033996582, 0.3887642025947571, -0.3994147479534149, 0.041104190051555634, -0.3446843922138214, -0.09887149930000305, -0.01332913339138031, -0.45643073320388794, 0.1658899337053299, -0.4436987638473511, -0.08193919062614441, 0.8001665472984314, -0.051767271012067795, -0.47573718428611755, -0.8114661574363708, -0.25628799200057983, -0.08544699102640152, -0.09276071190834045, 0.23424559831619263, -0.5946523547172546, -0.2755845785140991, 0.7260128855705261, 0.4669959545135498, 0.318871408700943, -0.3355574309825897, -0.3671458959579468, -0.28076159954071045, 0.73048996925354, 0.783976137638092, -0.8501598834991455, -0.6598461270332336, 1.1890349388122559, 0.8672784566879272, -0.9996356964111328, 0.5655746459960938, 0.21708765625953674, -0.7607933878898621, 0.9123671650886536, 0.992798924446106, -0.10844684392213821, 0.520434558391571, -0.45463910698890686, 0.22690081596374512, 0.032207902520895004, -1.1724382638931274, -0.47991493344306946, 0.5677710771560669, 1.1530170440673828, 0.5889550447463989, 0.44539889693260193, 0.5002144575119019, 1.0773640871047974, -0.30130377411842346, 0.46425092220306396, 0.6928316950798035, 0.09556349366903305, -0.32328543066978455, 0.3273136615753174, 0.1482493281364441, 0.6694158315658569, -0.9956866502761841, -0.49096766114234924, 0.37367478013038635, 0.8466383218765259, 0.43091049790382385, 0.7205806374549866, 1.0143723487854004, 0.2837271988391876, 0.23670309782028198, 0.6818216443061829, 0.6772997379302979, -0.40679481625556946, -0.4774729609489441, -0.13368429243564606, -0.3030887544155121, -0.16007216274738312, -0.40971991419792175, -0.5301579236984253, -0.6418857574462891, -0.18259915709495544, 0.22496461868286133, 0.4150089621543884, -0.0573875866830349, 1.665812611579895, 0.3774798512458801, 0.5945215225219727, -0.17900513112545013, -0.8143494129180908, -0.5311098694801331, -0.9901828169822693, -0.06117309629917145, -0.7966191172599792, -0.08176343888044357, -0.20399333536624908, -0.37044233083724976, -0.3290328085422516]}, "authors": [{"authorId": "2290915944", "name": "Gregor Bachmann"}, {"authorId": "34602162", "name": "Vaishnavh Nagarajan"}], "references": [{"paperId": "24a2468a1a16d6c332efc44be90854e4f748eeca", "title": "Mechanics of Next Token Prediction with Self-Attention"}, {"paperId": "c78350e81298ca87bc1d59b466fa40081232caaa", "title": "Teaching Large Language Models to Reason with Reinforcement Learning"}, {"paperId": "6f6642062eb4890da148f397badfa4c98f94508a", "title": "Implicit Bias of Next-Token Prediction"}, {"paperId": "1b3f1fc36ef84e90e837df474121f5d67afd13d9", "title": "Transformers, parallel computation, and logarithmic depth"}, {"paperId": "5339f21241f64f76a0a891888fb1796f9aede7d1", "title": "Arrows of Time for Large Language Models"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "4067a6f57f708dec4459d3d4322373e06c2b168c", "title": "PaSS: Parallel Speculative Sampling"}, {"paperId": "4726d1dc54851db99c29180127d840bd19f20afc", "title": "Positional Description Matters for Transformers Arithmetic"}, {"paperId": "55f1cde49846c58b0bedebde15b8f7d939f39432", "title": "Are We Falling in a Middle-Intelligence Trap? An Analysis and Mitigation of the Reversal Curse"}, {"paperId": "49a02664e552320a43cea541c07ca312e45350b5", "title": "Future Lens: Anticipating Subsequent Tokens from a Single Hidden State"}, {"paperId": "e879f54b2b5760bbb6d010977ddcedfb62452b38", "title": "Can Large Language Models Really Improve by Self-critiquing Their Own Plans?"}, {"paperId": "75c19f3249f644f5cb2182282fc117c089fd3f65", "title": "The Expressive Power of Transformers with Chain of Thought"}, {"paperId": "abe90a291e7cf567ce5c9012a692beeae153068d", "title": "Think before you speak: Training Language Models With Pause Tokens"}, {"paperId": "9977fee41d9cce1b2ed924da966140ac8120762b", "title": "Evaluating Cognitive Maps and Planning in Large Language Models with CogEval"}, {"paperId": "47daf5f81470564f94adcac672405c2cd39dd186", "title": "Physics of Language Models: Part 3.2, Knowledge Manipulation"}, {"paperId": "73dd6fce2db3e34d1f87f8449b1e8bde78c31547", "title": "Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve"}, {"paperId": "b1fe7bdcfef4e12febe7e8bed8826e66689d60ed", "title": "Auto-Regressive Next-Token Predictors are Universal Learners"}, {"paperId": "1972150fc20d97c8ad3328d432e9cd7e1bd16e7f", "title": "ChatGPT is no Stochastic Parrot. But it also Claims that 1 is Greater than 1"}, {"paperId": "aade40af0d85b0b4fe15c97f6222d5c2e4d6d9b3", "title": "Graph of Thoughts: Solving Elaborate Problems with Large Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "0db0af0cd3ceb0531a050a03e6ceb849580ff53b", "title": "Teaching Arithmetic to Small Transformers"}, {"paperId": "9502c180be0ebc92fcf2085ea90c3cb45280a6bc", "title": "Introduction to Latent Variable Energy-Based Models: A Path Towards Autonomous Machine Intelligence"}, {"paperId": "7d97c17a75beb89f938eaac1d3ca60ac2245fb2e", "title": "Faith and Fate: Limits of Transformers on Compositionality"}, {"paperId": "dedfe929d182cc3537a9ed765d589b4735ce062a", "title": "On the Planning Abilities of Large Language Models - A Critical Investigation"}, {"paperId": "c2260403fd5cb2de73491323433e48b6ec36872c", "title": "Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective"}, {"paperId": "43053735958a3eff73249f54648d13646f72a570", "title": "Autoregressive Modeling with Lookahead Attention"}, {"paperId": "2f3822eb380b5e753a6d579f31dfc3ec4c4a0820", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models"}, {"paperId": "aad167be3c902388ea625da4117fcae4325b8b7d", "title": "Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes"}, {"paperId": "12910786da7a34c9ee26798fd81b0ed7b0e38789", "title": "Finding Neurons in a Haystack: Case Studies with Sparse Probing"}, {"paperId": "3aaf6a2cbad5850ad81ab5c163599cb3d523436f", "title": "Self-Refine: Iterative Refinement with Self-Feedback"}, {"paperId": "574beee702be3856d60aa482ec725168fe64fc99", "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4"}, {"paperId": "24576dcca716c82f66b8cc3c85ecfae18be41edd", "title": "Adaptive Computation with Elastic Input Sequence"}, {"paperId": "7cbc7aa08b96de770d9ce5c90d01e75e9df2caee", "title": "Language models are better than humans at next-token prediction"}, {"paperId": "c2d0b6abc49aa4749bec53990934a86378aac9d6", "title": "A Measure-Theoretic Characterization of Tight Language Models"}, {"paperId": "8fd462f6248d5e3f1b6602697c09489086b5655f", "title": "Distilling Reasoning Capabilities into Smaller Language Models"}, {"paperId": "e82e3f4347674b75c432cb80604d38ee630d4bf6", "title": "Transformers Learn Shortcuts to Automata"}, {"paperId": "69144d537f90f214d5b07a7c79121d16afd7da16", "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models"}, {"paperId": "99832586d55f540f603637e458a292406a0ed75d", "title": "ReAct: Synergizing Reasoning and Acting in Language Models"}, {"paperId": "c90a99eeb57019732a6cc996bb9eaf13faedf00f", "title": "In-context Learning and Induction Heads"}, {"paperId": "f3cf71c51b882fe3111d71c4bf104297d38197f8", "title": "Inner Monologue: Embodied Reasoning through Planning with Language Models"}, {"paperId": "f843233f76a5dff07bfa93a71a1cf13d8aa6a94a", "title": "Exploring Length Generalization in Large Language Models"}, {"paperId": "955191363c3676f71766af3d14d1e6bbc0f040d6", "title": "The Parallelism Tradeoff: Limitations of Log-Precision Transformers"}, {"paperId": "e850d4c0dad3aee3b8b40be5e5d5e5c31354d8cc", "title": "PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change"}, {"paperId": "8ce9b1e527c4d9d15239621ec4e3ef3fbbe32202", "title": "On the Role of Bidirectionality in Language Model Pre-Training"}, {"paperId": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large Language Models are Zero-Shot Reasoners"}, {"paperId": "5e3a7235c730b512f0bb3004a6deb0c88ec9fc8e", "title": "On the Paradox of Learning to Reason from Data"}, {"paperId": "932b6353204e56f20917edadda2fa636ace21090", "title": "Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks"}, {"paperId": "23dd78e424d32f6a48660dcd67ce994b8a7db8be", "title": "STaR: Bootstrapping Reasoning With Reasoning"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "996445d847f06e99b0bd259345408a0cf1bce87e", "title": "Locating and Editing Factual Associations in GPT"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "92173d081b15824d22a9ef070e118744ceee8052", "title": "Show Your Work: Scratchpads for Intermediate Computation with Language Models"}, {"paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea", "title": "Training Verifiers to Solve Math Word Problems"}, {"paperId": "063eee315e864f0842d3074629dccc4bb36d19e7", "title": "Discovering Non-monotonic Autoregressive Orderings with Variational Inference"}, {"paperId": "0f2199296f01694ee46b6059879260fb80a84fa6", "title": "Teaching Autoregressive Language Models Complex Tasks By Demonstration"}, {"paperId": "57a1258571a21817d89197dc84c986861fb6e580", "title": "Measuring and Improving BERT\u2019s Mathematical Abilities by Predicting the Order of Reasoning."}, {"paperId": "476afc913d63f3ba1882f6419f718984379b2380", "title": "Why Machine Reading Comprehension Models Learn Shortcuts?"}, {"paperId": "ca2f1088d3e581b2c6c75cf0ebc96506d620f64d", "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? \ud83e\udd9c"}, {"paperId": "ac3cdb50606f7770eef8e4cd951840a4f71287a0", "title": "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm"}, {"paperId": "9e6763597414d865237fdd065eed50bbc5ff14f5", "title": "Limitations of Autoregressive Models and Their Alternatives"}, {"paperId": "053b1d7b97eb2c91fc3921d589c160b0923c70b1", "title": "Learning to summarize from human feedback"}, {"paperId": "168fc3525f7b97695a97b04e257ee9bd1e832acb", "title": "Memory Transformer"}, {"paperId": "3f1d72105060bebba68b672dd6197c0deddca26f", "title": "Consistency of a Recurrent Language Model with Respect to Incomplete Decoding"}, {"paperId": "25db56fc85fe15625c3375064a35e908ba6dfd2a", "title": "ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training"}, {"paperId": "7a15950dc71079285a4eaf195de5aadd87c41b40", "title": "Fine-Tuning Language Models from Human Preferences"}, {"paperId": "5e04881e91bff952d102d967c4ffb498ec30d4af", "title": "Blockwise Parallel Decoding for Deep Autoregressive Models"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "15e81c8d1c21f9e928c72721ac46d458f3341454", "title": "Non-Autoregressive Neural Machine Translation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "032274e57f7d8b456bd255fe76b909b2c1d7458e", "title": "A Deep Reinforced Model for Abstractive Summarization"}, {"paperId": "b123a0d46ad917b79c43c5ae981e03ed2458ed11", "title": "Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems"}, {"paperId": "3bd8c180acd9363c5d177c04b2973f2a3ffef068", "title": "Limits of End-to-End Learning"}, {"paperId": "2fe874a1c85ecc9e848bf9defd76535e19d51f39", "title": "Professor Forcing: A New Algorithm for Training Recurrent Networks"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "0d24a0695c9fc669e643bad51d4e14f056329dec", "title": "An Actor-Critic Algorithm for Sequence Prediction"}, {"paperId": "4758a42c3a481230d6bea5561616a1f85c5cf9a4", "title": "On the Sample Complexity of End-to-end Training vs. Semantic Abstraction Training"}, {"paperId": "b7aee9dfb027d6061c6a653684c0fa9a9bba750d", "title": "Sequence Level Training with Recurrent Neural Networks"}, {"paperId": "257aeef7463eee895d3657823b1b9f0fe80df0fb", "title": "Learning to Search Better than Your Teacher"}, {"paperId": "2f2961362355e45fa014ca0bb8ce4495aedf8824", "title": "Thinking fast and slow."}, {"paperId": "e28b84c2800d81532c89997ee3120ae3bf32977d", "title": "Reinforcement and Imitation Learning via Interactive No-Regret Learning"}, {"paperId": "4479eb79b292be3b3c5327e537f617d9d0a1e29e", "title": "Repetition"}, {"paperId": "523b12db4004b89284387f978c2af8ae0e79d54b", "title": "Knowledge Matters: Importance of Prior Information for Optimization"}, {"paperId": "79ab3c49903ec8cb339437ccf5cf998607fc313e", "title": "A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning"}, {"paperId": "70e10a5459c6f1aaf346ee4f2dcc837151fbe75c", "title": "Efficient Reductions for Imitation Learning"}, {"paperId": "ce9a21b93ba29d4145a8ef6bf401e77f261848de", "title": "A Learning Algorithm for Continually Running Fully Recurrent Neural Networks"}, {"paperId": "c57dcfe972efbb5deaa8110c983c3a786d97095a", "title": "Language"}, {"paperId": "0c6e8912fe8ed3c8cf9008a7d59edcf469522a45", "title": "Clever Hans : the horse of Mr. Von Osten"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Openwebtext corpus"}, {"paperId": null, "title": "Fail-ures of gradient-based deep learning"}, {"paperId": "6d12a1d23b21a9b170118a56386552bc5d4727de", "title": "A Mathematical Theory of Communication"}, {"paperId": null, "title": "Lower bounds for reductions"}, {"paperId": "c1e3f2d537e50e0d5263e4731ab6c7983acd6687", "title": "Prediction and Entropy of Printed English"}, {"paperId": null, "title": "Do large language models need sensory grounding for meaning and understanding?"}, {"paperId": "dceabf5eec3d1ef36c938fae8defbf6775d487f1", "title": "Eliciting Language Model Behaviors using Reverse Language Models"}, {"paperId": "526e22c130b18924976553d29ba11bc9d898d58b", "title": "Machine Learning manuscript No. (will be inserted by the editor) Search-based Structured Prediction"}, {"paperId": null, "title": "On the inconsistencies of conditionals learned by masked language models"}, {"paperId": null, "title": "We identify that the next-token prediction debate must not conflate autoregressive inference with teacher-forcing"}, {"paperId": null, "title": "We design a minimal lookahead task (\u00a74.1). We empirically demonstrate the failure of teacher-forcing for the Transformer and Mamba architectures, despite the task being easy to learn (\u00a75)"}, {"paperId": null, "title": "We note that there may be specific workarounds to make the Transformer (efficiently) learn the path-star task"}, {"paperId": null, "title": "Fractal patterns may unravel the intelligence in"}, {"paperId": null, "title": "b) Node-ID-agnostic memorization: If the number of training data is \u2126( | E | !) , the model"}, {"paperId": null, "title": "We consolidate existing critiques against next-token prediction and crystallize new core points of contention (\u00a76 and \u00a73, \u00a74)"}, {"paperId": null, "title": "are you clever? clever hans"}, {"paperId": null, "title": "The k leading response tokens are sensitive in that even if one subroutine is altered, the first k tokens are each completely altered"}, {"paperId": null, "title": "Generalization beyond overfitting on small"}, {"paperId": null, "title": "that in lookahead tasks, next-token prediction during training (i.e., teacher-forcing) can give rise to problematic learning mechanisms that are detrimental to even in-distribution performance (\u00a74)"}]}