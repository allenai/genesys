{"paperId": "6ac92ad74a4f41f2479da7edb2b483dbf57f10b7", "title": "Attendre: Wait To Attend By Retrieval With Evicted Queries in Memory-Based Transformers for Long Context Processing", "abstract": "As LLMs have become capable of processing more complex types of inputs, researchers have recently studied how to efficiently and affordably process possibly arbitrarily long sequences. One effective approach is to use a FIFO memory to store keys and values of an attention sublayer from past chunks to allow subsequent queries to attend. However, this approach requires a large memory and/or takes into the consideration the specific LM architecture. Moreover, due to the causal nature between the key-values in prior context and the queries at present, this approach cannot be extended to bidirectional attention such as in an encoder-decoder or PrefixLM decoder-only architecture. In this paper, we propose to use eviction policies, such as LRA and LFA, to reduce the memory size and adapt to various architectures, and we also propose the Attendre layer, a wait-to-attend mechanism by retrieving the key-value memory (K/V memory) with evicted queries in the query memory (Q memory). As a first step, we evaluate this method in the context length extension setup using the TriviaQA reading comprehension task, and show the effectiveness of the approach.", "venue": "arXiv.org", "year": 2024, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The Attendre layer is proposed, a wait-to-attend mechanism by retrieving the key-value memory (K/V memory) with evicted queries in the query memory (Q memory) with evicted queries in the query memory (Q memory) is evaluated."}, "embedding": {"model": "specter_v2", "vector": [0.7063490152359009, 0.3883258104324341, -0.2326519787311554, -0.27717113494873047, -0.2778570353984833, 0.06666158884763718, 0.35975220799446106, 0.08353637158870697, -0.6621196866035461, -0.09623726457357407, 0.8102365136146545, -0.15717679262161255, 0.21793557703495026, 0.24633006751537323, -0.19279161095619202, 0.06290740519762039, -1.3762420415878296, -0.3002432584762573, 0.14585651457309723, -0.03527062013745308, 0.4788648188114166, -0.5950350165367126, -1.1065303087234497, 0.5414171814918518, 0.15279406309127808, 0.2212391197681427, 0.6029056310653687, 1.2977489233016968, -0.3510192334651947, 0.409037321805954, 0.029842548072338104, -0.022968947887420654, -0.20047052204608917, -0.0869814082980156, -0.5164135098457336, -0.5105730891227722, 0.8586015105247498, -0.6379292011260986, -0.41240203380584717, 0.4384431540966034, 0.0852055475115776, 0.14171136915683746, 0.03341810032725334, -0.1269730031490326, -0.02560098096728325, 1.1008710861206055, 0.5044702291488647, 1.0654590129852295, 0.21126724779605865, -0.6886091232299805, 1.439382553100586, -1.425843596458435, 0.19624775648117065, 1.3671131134033203, 0.030754761770367622, 0.6137874126434326, 0.0974700078368187, -0.009717204608023167, 0.9554564356803894, 0.5123066306114197, -0.4928736090660095, -0.621239960193634, -0.055746302008628845, 0.33045461773872375, 1.906458854675293, -0.13225050270557404, -0.09125308692455292, 0.4624854624271393, 0.5167028307914734, 1.6223570108413696, -0.13078191876411438, -1.2439872026443481, -0.1390107274055481, -0.4734005630016327, 0.6278612017631531, 0.5308107137680054, -0.7830588221549988, -0.011763617396354675, -0.97614586353302, -0.048890307545661926, 0.3430759906768799, -0.13542039692401886, -0.23108486831188202, 0.01830533891916275, -0.5880050659179688, 0.14582107961177826, 0.1198805421590805, 0.6846303939819336, 0.08993291109800339, 0.5539861917495728, 0.6210319399833679, 0.5286208391189575, -0.29581812024116516, 0.2630447447299957, -0.06575985997915268, 0.25650277733802795, -1.002234935760498, 0.04597146436572075, -0.23268947005271912, 1.0130283832550049, -0.4205293357372284, 0.030548078939318657, -0.9625089168548584, 0.03872048482298851, 1.232366681098938, -0.054475970566272736, 0.495379775762558, -0.5248222351074219, 0.44458699226379395, -0.8784576058387756, 0.23036015033721924, -0.27042582631111145, -0.22962702810764313, -0.30204159021377563, -0.34529581665992737, -1.3493435382843018, -0.19526158273220062, 0.2776429057121277, -0.4609416425228119, 0.9463871717453003, -0.47832706570625305, 0.13185423612594604, 0.20057903230190277, 0.4119797646999359, 0.2951821982860565, 0.5541750192642212, 0.268217533826828, -0.265843003988266, 1.0360442399978638, -0.6418539881706238, -0.7064406871795654, -1.0097920894622803, 0.7623891234397888, -0.2811875343322754, 0.611021876335144, 0.07383406907320023, -1.1971858739852905, -1.0415973663330078, -1.0914534330368042, -0.17168180644512177, -0.23081322014331818, 0.18611325323581696, 0.8011069297790527, -0.04109317436814308, -1.4656846523284912, 0.7503846287727356, 0.006182815879583359, -0.2813946306705475, 0.047967325896024704, 0.28431689739227295, 0.5457671284675598, -0.393370658159256, -1.5321953296661377, -0.10292232781648636, 0.16082656383514404, -0.3783699572086334, -0.2672246992588043, -0.3198721706867218, -1.0342069864273071, 0.14280009269714355, 0.7065957188606262, -0.5347367525100708, 1.2936618328094482, -0.13179050385951996, -1.1769356727600098, 0.40327781438827515, -0.7590115070343018, 0.2887771725654602, -0.24750110507011414, -0.7058428525924683, -0.513335108757019, -0.029321901500225067, -0.49266260862350464, 0.7176637649536133, 0.4439108371734619, -0.07506950199604034, -0.4851161539554596, 0.030608797445893288, -0.20124484598636627, 0.23323407769203186, -0.045309800654649734, 0.8524482250213623, -0.5123205780982971, -0.20321378111839294, 0.4388379752635956, 0.8504323363304138, 0.07166967540979385, -0.34428173303604126, 0.02415650337934494, -1.0622090101242065, 0.4816794991493225, 0.16002556681632996, 1.9384387731552124, -0.722985029220581, -0.6415128111839294, -0.25070324540138245, -0.4470605254173279, -0.07243893295526505, -0.8872655630111694, 0.5681708455085754, -0.1941181868314743, 0.16547326743602753, -0.07512267678976059, -0.8103681206703186, -0.4306408166885376, -0.3966476023197174, -0.9126918315887451, -0.350421279668808, 0.028145570307970047, 1.1356291770935059, -1.1926923990249634, -0.12019839137792587, -0.29771170020103455, -0.010657493956387043, -0.6558030247688293, 1.1978917121887207, -0.6928935647010803, 0.373324990272522, -0.13428851962089539, -0.24803148210048676, -0.23777422308921814, -0.46559664607048035, 0.3520575165748596, -0.13280397653579712, -0.052817996591329575, 0.6078023910522461, -0.0730896070599556, 1.6655547618865967, -0.3915615379810333, 0.9045802354812622, -0.2890571653842926, -0.0869697779417038, -0.11643604189157486, 0.7083429098129272, -0.5501360893249512, -0.4716145694255829, 0.4328036904335022, 0.18074779212474823, -0.4462759494781494, -0.15298879146575928, 0.9669779539108276, 1.411939024925232, -0.4548614025115967, 0.2545487880706787, 0.1935126781463623, 0.30762338638305664, 0.32923731207847595, 0.4883919358253479, 0.4277518093585968, 0.5880908966064453, 0.4449048340320587, -0.05346756428480148, 0.8116156458854675, -1.004712462425232, -0.2285403609275818, 0.6402285695075989, 0.7034603953361511, 0.6546422243118286, 0.44149500131607056, -0.6905779242515564, -0.42647311091423035, 0.2311658263206482, 0.2637536823749542, 1.7543401718139648, -0.1561679244041443, -0.020695140585303307, -0.8498143553733826, -0.13276392221450806, -0.9128174185752869, 0.2586880326271057, -0.19801083207130432, -0.07422611862421036, -1.0695092678070068, -0.6006428003311157, 0.771296501159668, 0.5586861968040466, 0.7547504305839539, -0.9172390103340149, -0.5406402945518494, -0.051123958081007004, 0.30655452609062195, -0.6912204623222351, -1.0639318227767944, 0.05268526077270508, -0.9535474181175232, -0.14306329190731049, -0.007176352199167013, -0.49413928389549255, 0.18755346536636353, -0.7161843180656433, 0.9674541354179382, -0.27581122517585754, -0.10105543583631516, 0.3072558045387268, 0.2508030831813812, -0.387592613697052, -0.3880765736103058, 0.08030721545219421, -0.00878235511481762, 0.1165885403752327, 0.7802059054374695, 0.5078409314155579, -0.3980197608470917, -0.022406872361898422, -0.3743880093097687, 0.13717922568321228, 0.3571079969406128, -0.12997305393218994, 0.9753974080085754, -0.8103429079055786, 0.38876423239707947, -1.116546630859375, 0.6468371152877808, 0.2232820689678192, -0.3699725568294525, 0.4367764890193939, -0.6841835379600525, -0.4862281382083893, 0.38412779569625854, -0.6472654938697815, -0.26930540800094604, -1.0213474035263062, 0.13116268813610077, -0.15629085898399353, -0.24268335103988647, 0.17439736425876617, -0.10001209378242493, 0.36663803458213806, -0.04196362569928169, 0.5186554789543152, 0.15747149288654327, 0.061115507036447525, 0.7320806980133057, -0.3019874393939972, 0.6750108599662781, 0.2904316186904907, -0.715419590473175, -0.13905352354049683, -0.005419578403234482, -0.7273339629173279, -0.22855649888515472, -0.5488482117652893, -0.4634637236595154, -0.35163626074790955, 0.11727949976921082, -0.47235894203186035, -1.0493379831314087, -0.1320202499628067, -1.0062100887298584, -0.2246904969215393, 0.37856581807136536, -0.06935715675354004, -0.43199899792671204, -0.748386025428772, -1.3428552150726318, -0.4409160315990448, -0.757018506526947, -0.9904418587684631, 0.16572707891464233, 0.06590975821018219, -0.6060853600502014, -0.38246145844459534, -0.2311989963054657, -0.6185254454612732, 0.7670883536338806, -0.7794328927993774, 0.9932202100753784, 0.0400659441947937, -0.5499396920204163, -0.009638523682951927, 0.38402917981147766, 0.1814175695180893, -0.2357374131679535, -0.29779353737831116, -1.1407276391983032, -0.03298930451273918, 0.2099996656179428, -0.012633347883820534, 0.26497921347618103, 0.37369900941848755, 0.890321671962738, 0.06621241569519043, -0.5540047287940979, 0.10618675500154495, 1.3204220533370972, -0.31528034806251526, 0.3065613806247711, -0.15710440278053284, 0.8470237851142883, 0.43470603227615356, 0.2358918935060501, 0.5595006346702576, 0.11391522735357285, 0.10013597458600998, 0.2805127203464508, 0.34605443477630615, -0.18763576447963715, -0.20828479528427124, 0.629370927810669, 1.5849552154541016, 0.24777640402317047, -0.26949167251586914, -0.8387799263000488, 0.6426311135292053, -1.087180733680725, -0.5688122510910034, 0.71148282289505, 0.8340684771537781, 0.4372882544994354, -0.2949267625808716, -0.6136908531188965, -0.1292155385017395, 0.4313720464706421, 0.3739437460899353, -0.24732588231563568, -0.9808539152145386, -0.025655651465058327, 0.22231972217559814, -0.12395725399255753, 0.9647799730300903, -0.162930428981781, 0.5248792767524719, 14.896748542785645, 0.49432769417762756, 0.18866460025310516, 0.42128705978393555, 0.7395379543304443, 0.08179008960723877, -0.3229582905769348, -0.16528062522411346, -1.3694207668304443, -0.09124837815761566, 1.5287959575653076, 0.6107003092765808, 0.31210070848464966, -0.1825241595506668, 0.07346467673778534, -0.17619818449020386, -1.2155567407608032, 0.3103070855140686, 0.768673300743103, -1.0455334186553955, 0.4651465117931366, 0.12505602836608887, 0.010886904783546925, 0.2397342026233673, 0.7372229695320129, 0.4813919961452484, -0.3799256384372711, -0.12171663343906403, 0.49910029768943787, 0.6144170761108398, 0.9989345669746399, -0.2062779814004898, 0.31363752484321594, 0.1155913770198822, -0.9440126419067383, -0.5225445032119751, -0.7937129139900208, -0.9052016139030457, 0.15760838985443115, -0.15739098191261292, -0.3460250496864319, -0.5246451497077942, -0.43368667364120483, 0.3561931550502777, 0.10771268606185913, 0.566392719745636, -0.523739755153656, 0.6956583261489868, 0.3466280996799469, -0.2505868971347809, 0.20378054678440094, 0.6219905614852905, 0.5641201734542847, -0.12539388239383698, -0.16056858003139496, 0.27140581607818604, -0.16728869080543518, 0.13241949677467346, -0.47147977352142334, 0.01653503067791462, -0.2079457938671112, 0.18772706389427185, 0.2598232626914978, 0.3264794647693634, 0.4782234728336334, 0.3175714313983917, -0.6506813764572144, 0.3141676187515259, 0.44065794348716736, 0.45631325244903564, 0.22411766648292542, -0.5603983998298645, 0.16661734879016876, -0.6552250981330872, -0.016056030988693237, 0.48198026418685913, -0.12080284208059311, -0.39503633975982666, -0.6002745032310486, -0.32234227657318115, 0.32731324434280396, -0.7358384728431702, -0.2826527953147888, 0.8596420884132385, 0.06975601613521576, -0.7202594876289368, 0.04270268231630325, -0.6968864798545837, -0.4671383500099182, 0.4764869511127472, -1.4358298778533936, -0.3657345473766327, 0.606369137763977, -0.38184332847595215, -0.04911249130964279, 0.2188764065504074, 1.144484043121338, -0.022575324401259422, -0.12397189438343048, 0.36388662457466125, -0.11900528520345688, -0.1793392300605774, 0.07782161235809326, -0.7764992117881775, 0.5918816328048706, 0.72733074426651, -0.3554416000843048, 0.4509832561016083, -0.20184144377708435, 0.03699471801519394, -0.9653487801551819, -0.01851007342338562, 1.032525658607483, -1.2078293561935425, -0.787450909614563, -0.8608269691467285, -1.1983665227890015, 0.3483844995498657, 0.7706331610679626, -0.3431408107280731, 0.36962467432022095, -0.04213276505470276, 0.0015398248797282577, -0.42207956314086914, -0.4094308316707611, 0.31453660130500793, 0.6402431130409241, -0.7578330636024475, -0.5746079087257385, -0.6346359252929688, 0.7084170579910278, -0.9193146824836731, -0.6904754042625427, -0.34071019291877747, -0.022067541256546974, 0.05217648297548294, 0.9141199588775635, -0.23516954481601715, 0.486720472574234, 0.7612387537956238, -0.14468254148960114, -0.2463727593421936, 0.08063758909702301, -0.9410552978515625, -0.5021423101425171, 0.32969266176223755, 0.48190659284591675, -0.12110383808612823, 0.026451803743839264, 0.6232168078422546, 0.2639845609664917, -0.8453841805458069, -0.5752465128898621, 0.14081528782844543, 0.34283846616744995, -0.6792395114898682, 0.6541633009910583, -0.5742743015289307, 0.2369876205921173, 0.20581991970539093, 0.6279826760292053, 1.13583242893219, -0.29113900661468506, -0.40322133898735046, -0.0654175728559494, 0.32994142174720764, 0.0592082217335701, -0.43040958046913147, -0.30466097593307495, -1.7335022687911987, -0.4502580463886261, -0.7986583709716797, 0.18644945323467255, -0.5846918821334839, -0.6310040950775146, 0.12615610659122467, -0.5869691371917725, -0.012747835367918015, -0.21738600730895996, -0.5069777369499207, -0.5201674699783325, -0.4467740058898926, -0.8236405253410339, 0.5031719207763672, 1.0002703666687012, -0.32463809847831726, -0.10545855760574341, -0.0004794253909494728, 0.35800594091415405, -0.0645572692155838, 0.44051191210746765, -0.06702558696269989, -1.1442776918411255, -1.4312630891799927, 0.675376296043396, 0.05819772556424141, -0.30929940938949585, -0.8054711222648621, 0.6969152092933655, 0.5592185258865356, -0.020659837871789932, -0.5369404554367065, 0.07436782121658325, -0.6237115859985352, -0.9140121340751648, 0.23980829119682312, -1.112209439277649, 0.17515189945697784, 0.256307989358902, -0.5418407320976257, -0.2744932770729065, 0.36447131633758545, -0.3914668560028076, -1.0349119901657104, -0.9978922009468079, 0.3117573857307434, -0.785803496837616, 0.2393423318862915, -0.5852551460266113, -0.1559048742055893, -1.0501197576522827, -0.17796282470226288, -0.053853295743465424, 0.6959176063537598, -0.38919347524642944, 0.9372678995132446, 0.9913739562034607, -0.7722638845443726, 0.16549637913703918, 0.5699215531349182, -0.02269376441836357, 0.2740500867366791, 0.37167203426361084, 0.32199662923812866, -0.05811416357755661, 0.8020633459091187, 0.3813670873641968, 0.0024717727210372686, -1.0405372381210327, 0.2171718031167984, 0.46130192279815674, -0.2176569402217865, -0.10271812230348587, 0.9888509511947632, -0.3706207871437073, -0.43876275420188904, 0.5476424098014832, -1.3872222900390625, -0.975631058216095, -0.2234417200088501, 1.2538565397262573, 0.12703633308410645, -0.16291025280952454, 0.0493290089070797, -0.4002438187599182, 0.46609118580818176, -0.2579151391983032, -0.5167917609214783, 0.17551033198833466, -0.6806546449661255, -0.48571810126304626, 0.6210314631462097, 0.6269558072090149, -0.5223718285560608, -0.7515912652015686, -0.6845428943634033, -0.0725877657532692, 0.08500036597251892, 0.21939446032047272, -0.2626126706600189, -0.10899431258440018, 1.2032196521759033, 0.5349507331848145, -0.15990905463695526, 0.47417011857032776, 0.018666096031665802, 0.16649562120437622, 0.5360704064369202, 0.09738081693649292, -0.163791686296463, -0.3737207055091858, 1.1618719100952148, 1.2846269607543945, -0.6497837901115417, 0.27949947118759155, 0.04301595315337181, -0.36972251534461975, 1.1243678331375122, 0.5545061826705933, 0.1288360208272934, 0.6962618827819824, -0.4485703408718109, 0.35432133078575134, 0.3420310616493225, -1.2385246753692627, -0.016303636133670807, 0.9610489010810852, 0.9238200783729553, 0.6889347434043884, -0.028281304985284805, -0.13240423798561096, 0.841998815536499, 0.21246182918548584, 0.14807088673114777, 0.7532230019569397, 0.7442818880081177, -0.3854512870311737, -0.3518581986427307, -0.0851767361164093, 0.5253613591194153, -0.9918397068977356, -0.8515684604644775, 0.7164328694343567, 0.41503143310546875, -0.1662057787179947, 0.576927900314331, 1.1544089317321777, 0.19649429619312286, 0.364373117685318, 0.36159220337867737, 0.6675939559936523, -0.6887444257736206, -0.38243818283081055, -0.15447470545768738, -0.7705844640731812, -0.3430123031139374, -0.14825649559497833, -0.5606815218925476, -0.543790340423584, 0.3642493486404419, 0.2812768220901489, -0.3171316981315613, 0.0531950518488884, 0.8963584899902344, 0.6190276741981506, 0.4401440918445587, -0.1621498465538025, -0.26903343200683594, -0.215042844414711, -1.1254703998565674, 0.5431919097900391, -0.46941912174224854, 0.21488800644874573, 0.3465988337993622, 0.1260979175567627, -0.16455864906311035]}, "authors": [{"authorId": "2278970280", "name": "Zi Yang"}, {"authorId": "2278831818", "name": "Nan Hua"}], "references": [{"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "4ea5ca620122e6a9a2b000444d36491cebf49c7c", "title": "Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey"}, {"paperId": "c0aac09fe67c39fbb377e45e03e38cd0d9b24ab4", "title": "Optimizing Retrieval-augmented Reader Models via Token Elimination"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "ff01d3dab60dd4b7426c884b009dda83540c0c1e", "title": "Attention Sorting Combats Recency Bias In Long Context Language Models"}, {"paperId": "44cfa54407e6403e2c3124957e532c2fa3a994bc", "title": "With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "b069c32fcd77160f944ab3ba71ab6f0cfb782c68", "title": "Focused Transformer: Contrastive Training for Context Scaling"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "6f6e2e0311589a9af045f6acd00b7dee6d19fce4", "title": "The Impact of Positional Encoding on Length Generalization in Transformers"}, {"paperId": "c193eb176985a81ae64f63c5e50b2f11cfb7c4e6", "title": "Dynamic Context Pruning for Efficient and Interpretable Autoregressive Transformers"}, {"paperId": "2d01b6afbc86cba1cb895dbcd9396b13952bf0e5", "title": "Focus Your Attention (with Adaptive IIR Filters)"}, {"paperId": "dbc368bc8b49347dd27679894524fa62f88492c9", "title": "Unlimiformer: Long-Range Transformers with Unlimited Length Input"}, {"paperId": "f711aae062ae30c0888910b2bdcc5be6c1d1c340", "title": "Enhancing Large Language Model with Self-Controlled Memory Framework"}, {"paperId": "594d8e1696619f3cebb7c6bffdad8e0a5592f006", "title": "Scaling Transformer to 1M tokens and beyond with RMT"}, {"paperId": "68adb03744692247fb834406798894db9fe77010", "title": "A Survey on Long Text Modeling with Transformers"}, {"paperId": "5db8c4cc8742f410d6c40a3f23eeb4739d10d0fe", "title": "Pre-computed memory or on-the-fly encoding? A hybrid approach to retrieval augmentation makes the most of your compute"}, {"paperId": "980d1c3bf9d1a3c0ce68567e0efc1a72f203f12c", "title": "Global memory transformer for processing long documents"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "70e91e16eb321067d9402710e14a40cf28311f73", "title": "Mega: Moving Average Equipped Gated Attention"}, {"paperId": "3b39efe6c91ae432dd35bb79431edb8a6719f906", "title": "Investigating Efficiently Extending Transformers for Long Input Summarization"}, {"paperId": "b21670e8061a06ab97e7d6052c9345a326e84ff8", "title": "UL2: Unifying Language Learning Paradigms"}, {"paperId": "3dfb1f50f2a34a699c339dabaa6f9b3a977973de", "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences"}, {"paperId": "2d82ee05b132d4681c3bd517afc17d608fe6e525", "title": "Simple Local Attentions Remain Competitive for Long-Context Tasks"}, {"paperId": "002c256d30d6be4b23d365a8de8ae0e67e4c9641", "title": "Improving language models by retrieving from trillions of tokens"}, {"paperId": "64a29bee2e1ad29547d590a3cc26274f4c537145", "title": "Not All Memories are Created Equal: Learning to Forget by Expiring"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "67ee20536c30a225b86902af2f091e28e5e19b40", "title": "Memformer: A Memory-Augmented Transformer for Sequence Modeling"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "70557ea6b65846fc30729ceed224acd4ac64ca5d", "title": "MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "dc52b09089704ebd6f471177474bc29741c50023", "title": "Fast Transformer Decoding: One Write-Head is All You Need"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"}, {"paperId": "942deb7d865b7782c03176d95e3a0d56cb71009e", "title": "Training Deep Nets with Sublinear Memory Cost"}, {"paperId": "2dad9763f8b128da231b3fb9c9fff7ad730b89a1", "title": "Long-Range Language Modeling with Selective Cache"}, {"paperId": "780b7c5e2440459bcc532b251e51c9223037acc2", "title": "Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics"}, {"paperId": null, "title": "2022b. Memorizing trans-formers"}, {"paperId": null, "title": "2023. Lm-infinite: Simple on-the-fly length generalization for large language models"}, {"paperId": null, "title": "2023. Longnet: Scaling trans-formers to 1,000,000,000 tokens"}, {"paperId": null, "title": "2023. With a little 9"}, {"paperId": null, "title": "2023. Token turing machines"}, {"paperId": null, "title": "2023. Trams: Training-free memory selection for"}, {"paperId": null, "title": "2023. In-context autoencoder for context compression in a large language model"}]}