{"paperId": "b92628d13e8d090d042232fe6ae0b8998634b893", "title": "LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks", "abstract": "Fine-tuning pretrained language models (LMs) without making any architectural changes has become a norm for learning various language downstream tasks. However, for non-language downstream tasks, a common practice is to employ task-specific designs for input, output layers, and loss functions. For instance, it is possible to fine-tune an LM into an MNIST classifier by replacing the word embedding layer with an image patch embedding layer, the word token output layer with a 10-way output layer, and the word prediction loss with a 10-way classification loss, respectively. A natural question arises: Can LM fine-tuning solve non-language downstream tasks without changing the model architecture or loss function? To answer this, we propose Language-Interfaced Fine-Tuning (LIFT) and study its efficacy and limitations by conducting an extensive empirical study on a suite of non-language classification and regression tasks. LIFT does not make any changes to the model architecture or loss function, and it solely relies on the natural language interface, enabling\"no-code machine learning with LMs.\"We find that LIFT performs comparably well across a wide range of low-dimensional classification and regression tasks, matching the performances of the best baselines in many cases, especially for the classification tasks. We also report experimental results on the fundamental properties of LIFT, including inductive bias, robustness, and sample complexity. We also analyze the effect of pretraining on LIFT and a few properties/techniques specific to LIFT, e.g., context-aware learning via appropriate prompting, calibrated predictions, data generation, and two-stage fine-tuning. Our code is available at https://github.com/UW-Madison-Lee-Lab/LanguageInterfacedFineTuning.", "venue": "Neural Information Processing Systems", "year": 2022, "citationCount": 83, "influentialCitationCount": 19, "openAccessPdf": {"url": "https://arxiv.org/pdf/2206.06565", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "Language-Interfaced Fine-Tuning is proposed and found that LIFT performs comparably well across a wide range of low-dimensional classification and regression tasks, matching the performances of the best baselines in many cases, especially for the classification tasks."}, "embedding": {"model": "specter_v2", "vector": [0.4423694908618927, 0.6211479902267456, -0.024057626724243164, 0.04555235803127289, -0.2675990164279938, -0.22587881982326508, 0.5689395666122437, -0.4381273090839386, -0.8023686408996582, -0.15738001465797424, 0.294131338596344, -0.21204939484596252, 0.7091501951217651, 0.20196349918842316, 0.09958270192146301, 0.10088798403739929, -0.7896347045898438, 0.061513662338256836, -0.5319463014602661, -0.56099933385849, -0.3417266607284546, -0.8075987100601196, -0.7420297265052795, 0.27274686098098755, 0.24363645911216736, 0.41008201241493225, 0.4514754116535187, 1.0729870796203613, -0.3580424189567566, 0.03373102843761444, 0.474854439496994, -0.21874384582042694, 0.3575626611709595, -0.09525211155414581, -0.409712553024292, -0.080583356320858, 0.36789900064468384, -0.3766367435455322, -0.029799308627843857, 0.5853651762008667, -0.06004530191421509, 0.42285269498825073, 0.6016360521316528, -0.4784393012523651, -0.7210436463356018, 0.7926119565963745, 0.4934745728969574, 0.4557622969150543, -0.6146131753921509, -0.04904086887836456, 0.958902895450592, -1.5635987520217896, -0.09784997254610062, 1.2990520000457764, 0.5105174779891968, 0.8854619264602661, -0.625625729560852, -0.9101864695549011, 0.684174120426178, -0.2918532192707062, -0.8324229121208191, -0.33988797664642334, -0.0628589540719986, -0.26616227626800537, 1.9254852533340454, -0.5647030472755432, -0.4938967823982239, 0.6815868616104126, 0.050068967044353485, 0.9151510000228882, 0.2044193148612976, -0.984108030796051, -0.8114377856254578, 0.5393378734588623, 0.16820859909057617, 0.8145274519920349, -0.5880204439163208, 0.380008339881897, -0.826537013053894, 0.15563061833381653, 0.27018749713897705, -0.34788766503334045, -0.012574911117553711, 0.1324538290500641, -0.3477655351161957, 0.7528671026229858, 0.454492449760437, 0.8097859621047974, 0.02835175022482872, 0.6574907302856445, 0.726719856262207, 0.6497304439544678, 0.3576028347015381, 0.656516432762146, -0.40130507946014404, 0.540891170501709, -0.6646691560745239, 0.002231432357802987, 0.08873162418603897, 0.7408354878425598, 0.24543938040733337, 0.3538931608200073, -1.0380958318710327, 0.4168550372123718, 1.028658390045166, 0.05676241219043732, 0.7289288640022278, -0.40576255321502686, 0.5935325026512146, -0.8504346013069153, -0.1415877491235733, -0.453704833984375, -0.37590262293815613, -0.31082984805107117, -0.9969496130943298, -0.974801242351532, -0.3443693518638611, -0.39879652857780457, -0.508222758769989, 1.042557716369629, -0.3975396454334259, -0.15651363134384155, 0.380035936832428, 0.633213222026825, 0.8031021952629089, 0.7251477837562561, 0.5266276001930237, 0.3166506588459015, 1.0466912984848022, -0.9766967296600342, -0.35280922055244446, -0.8729105591773987, 0.9584673047065735, -0.5267192125320435, 1.022092580795288, -0.28835761547088623, -0.8894423246383667, -1.2326146364212036, -0.9132612943649292, -0.284374475479126, -0.7850989103317261, 0.8342617750167847, 0.7624737024307251, 0.4131511449813843, -0.9351668953895569, 0.8247061967849731, 0.24386171996593475, -0.15667606890201569, 0.046565163880586624, 0.3519333302974701, 0.09439767897129059, -0.26286861300468445, -1.6166267395019531, 0.40739017724990845, 0.5404927134513855, -0.5284236669540405, -0.2829161584377289, -0.6059200763702393, -0.984258234500885, -0.19232133030891418, 0.07879800349473953, -0.7534314393997192, 1.3853321075439453, -0.6003437042236328, -1.7859759330749512, 0.9746105670928955, -0.045855700969696045, 0.30252376198768616, 0.39505764842033386, -0.19730575382709503, -0.5705612301826477, -0.7475219964981079, -0.43300125002861023, 0.94710773229599, 0.6279590129852295, 0.03552297130227089, -0.09586326032876968, 0.6089726090431213, -0.2332303524017334, 0.2694418728351593, -0.8643916845321655, 0.5332989692687988, -0.220366969704628, -0.47041890025138855, -0.10762716829776764, 0.4905136525630951, 0.05428166314959526, -0.5457518696784973, -0.49798259139060974, -1.1406947374343872, 0.5964941382408142, 0.18238772451877594, 0.882106602191925, -1.1812442541122437, -0.9056791067123413, -0.22452712059020996, -0.1577942818403244, -0.04454934969544411, -1.2923645973205566, 0.7066805362701416, -0.5526273250579834, 0.4274657964706421, -0.06332021206617355, -1.4237021207809448, 0.2056899070739746, -0.6214616298675537, -0.478316068649292, -0.2655405104160309, 0.4192997217178345, 1.021995186805725, -0.7891596555709839, 0.2537759244441986, -0.19327740371227264, 0.5497250556945801, -1.1554303169250488, 1.121624231338501, -0.40948352217674255, 0.4613257646560669, 0.37365999817848206, -0.6219691038131714, -0.08490654826164246, -0.24947914481163025, 0.07335997372865677, -0.5824190974235535, -0.04304911941289902, 0.4715372323989868, -0.3979363739490509, 1.6274235248565674, -0.9625248312950134, 0.715979814529419, -0.0969701036810875, -0.381244957447052, 0.091130830347538, 0.43154680728912354, -0.33011338114738464, -0.21204522252082825, 0.14157916605472565, 0.48431551456451416, -0.42061847448349, 0.3035029172897339, 0.9797988533973694, 0.5411862730979919, -0.2326769083738327, 0.3834696412086487, 0.470581978559494, -0.27536311745643616, 0.2986627519130707, 0.18030622601509094, 0.5447224378585815, 0.414630264043808, 0.3259218633174896, -0.14779146015644073, 0.6672227382659912, -0.8489163517951965, -0.43644022941589355, 0.5536408424377441, 0.7776568531990051, 0.7156375646591187, -0.07880420237779617, -0.41648852825164795, -0.2745732069015503, -0.34292250871658325, 0.7255924344062805, 1.9586445093154907, -0.46085894107818604, 0.06432144343852997, -0.7285173535346985, -0.3318912088871002, -0.2478366196155548, -0.04728430509567261, -0.27120158076286316, -0.2871364653110504, -0.6025823354721069, -1.1803420782089233, 0.669015109539032, -0.006761979311704636, 0.9630796313285828, -0.6786395907402039, 0.06638164073228836, -0.2540419399738312, 0.26843810081481934, -0.7375959753990173, -1.0280646085739136, 0.4521181881427765, -0.5445210933685303, -0.016962632536888123, -0.11735288798809052, -0.4343840777873993, 0.36361995339393616, -0.378746896982193, 0.99897301197052, -0.40257811546325684, -0.3741585612297058, 0.05540166422724724, 0.44185981154441833, -0.27464795112609863, -0.752415120601654, 0.868408739566803, 0.34249264001846313, 0.08163060992956161, 0.2672227621078491, 0.4743365943431854, -0.024428779259324074, -0.10795562714338303, -0.3755796551704407, 0.18158668279647827, 0.2677401602268219, 0.17956125736236572, 0.6459208130836487, -0.16702330112457275, 0.27140748500823975, -1.6871147155761719, 1.4313863515853882, 0.16060824692249298, -0.17638614773750305, 0.15662509202957153, -0.7604612708091736, -0.15786223113536835, 0.7782912254333496, -0.8935871124267578, -0.42553338408470154, -0.6894552111625671, 0.18418213725090027, -0.018732452765107155, -0.3321729898452759, 0.07583383470773697, 0.24264603853225708, 0.2346491515636444, 0.5574429631233215, 0.21750281751155853, 0.34162914752960205, -0.26006630063056946, 1.1106492280960083, -0.6273508667945862, 0.43996095657348633, 0.14131030440330505, 0.51442950963974, -0.31967946887016296, -0.5408446788787842, -0.7177029252052307, -0.6435275673866272, -0.2522830069065094, -0.3638356328010559, 0.04329948499798775, 0.30193832516670227, -0.7844301462173462, -0.97638338804245, -0.11317828297615051, -0.9819358587265015, -0.6037945747375488, -0.001296382280997932, -0.24524560570716858, -0.11003093421459198, -1.269296646118164, -1.3844354152679443, -0.3216208219528198, -0.8693874478340149, -0.9382696151733398, 0.10327284783124924, -0.14719663560390472, -0.7088349461555481, -0.7724559307098389, -0.0235225148499012, -0.46148550510406494, 1.1174641847610474, -0.9044226408004761, 1.170514702796936, 0.06484123319387436, 0.256028950214386, 0.033725716173648834, 0.013872026465833187, 1.0117563009262085, -0.00042561718146316707, 0.16851641237735748, -1.3293001651763916, 0.024667995050549507, -0.2690449059009552, -0.519227921962738, 0.34545379877090454, 0.04778615012764931, 0.6299473643302917, -0.07541054487228394, -0.3215481638908386, 0.8237653970718384, 1.3900437355041504, -0.853679895401001, -0.11701253056526184, 0.24867217242717743, 1.0353121757507324, 0.4512278735637665, -0.6086486577987671, 0.21676144003868103, 0.36241719126701355, 0.1967996209859848, -0.3453464210033417, -0.412671834230423, -0.43154478073120117, -0.7328466773033142, 0.7850714325904846, 1.6366266012191772, 0.5194542407989502, 0.06708486378192902, -0.9841694831848145, 0.3049863278865814, -0.9092563986778259, -0.22355112433433533, 0.6711260080337524, 0.6085144281387329, 0.7904079556465149, -0.40851378440856934, -0.5658004879951477, -0.1689174473285675, 0.19975651800632477, 0.3189704120159149, -0.32561859488487244, -1.006629467010498, 0.13030657172203064, 0.22556503117084503, 0.09959187358617783, 0.6709824800491333, -0.7391521334648132, 0.8661642074584961, 14.377100944519043, 0.8701915740966797, -0.22136515378952026, 0.7933337688446045, 0.8441160917282104, 0.16152511537075043, -0.30738475918769836, -0.49467796087265015, -1.3679348230361938, -0.2516922950744629, 0.8585338592529297, 0.5246345400810242, 0.8827162981033325, 0.10818638652563095, 0.1514214426279068, 0.2423781007528305, -0.7334800362586975, 0.822856068611145, 0.5122433304786682, -1.114034652709961, 0.4236186444759369, 0.06731671094894409, 0.707560122013092, 0.5211628079414368, 1.114768385887146, 1.0340614318847656, 0.3264225125312805, -0.3779047727584839, 0.3147721290588379, 0.019333597272634506, 1.1478633880615234, -0.08836326003074646, 0.08917955309152603, 0.5647358298301697, -0.6705533862113953, -0.2440612018108368, -0.31074777245521545, -1.358664631843567, -0.09267910569906235, 0.32966649532318115, -0.7031967043876648, -0.8205097317695618, -0.32746621966362, 0.5972352623939514, 0.09956426173448563, -0.04623962938785553, -0.44256141781806946, 0.71297287940979, 0.1686798334121704, 0.03187969699501991, 0.28711411356925964, 0.47157564759254456, 0.2327526956796646, 0.47738757729530334, -0.10740209370851517, -0.17132878303527832, 0.11627382785081863, 0.4503825306892395, -0.8468844294548035, 0.12744221091270447, -0.28528788685798645, -0.04337528720498085, -0.3049877882003784, 1.0096299648284912, 0.5860816240310669, 0.5502578020095825, -0.3053334355354309, 0.47836804389953613, 0.89825439453125, 0.48109641671180725, -0.015118595212697983, -0.17764414846897125, 0.6245782971382141, -0.338288813829422, -0.09982417523860931, 0.17435327172279358, -0.3190106749534607, -0.5527852773666382, -0.8322036266326904, -0.46794918179512024, 0.08542419224977493, -0.5424169898033142, -1.1812469959259033, 0.802577555179596, -0.509490966796875, -0.3542485237121582, 0.21607603132724762, -0.9341681599617004, -0.19090618193149567, 0.911653459072113, -1.650734543800354, -0.5663818717002869, 0.7858501076698303, -0.5759509205818176, -0.32017773389816284, -0.2708507180213928, 1.4018220901489258, 0.1718779057264328, -0.4819082021713257, 0.5058910846710205, 0.23632891476154327, 0.360831081867218, 0.08584797382354736, -0.4948844313621521, 0.8236024379730225, 0.18681345880031586, -0.1972203403711319, 0.20882165431976318, -0.315456748008728, 0.3745972514152527, -0.5316604375839233, -0.331039160490036, 0.876270592212677, -0.8032355308532715, -0.2553442418575287, -0.9756669998168945, -0.5493386387825012, 0.03699387237429619, 0.5883602499961853, -0.43623289465904236, 0.7035796046257019, 0.5281721353530884, -0.8639742136001587, -0.35233035683631897, -0.6146687269210815, 0.27379870414733887, 0.5198376178741455, -1.087477684020996, -0.10636711120605469, 0.10038002580404282, 0.4484144449234009, -0.9912496209144592, -0.4162943661212921, -0.18000337481498718, 0.032695695757865906, 0.26274576783180237, 1.0331335067749023, -0.4618570804595947, 0.9286449551582336, 0.8258072733879089, -0.1455250382423401, -1.2482507228851318, -0.157268226146698, -0.6337025165557861, 0.29525473713874817, 0.5186253190040588, 1.0069307088851929, -0.5339921712875366, 0.07320839911699295, 0.745032548904419, 0.3486897647380829, -0.47284623980522156, -0.2020818293094635, -0.27505820989608765, 0.2955971360206604, -0.5596476197242737, 0.1078638881444931, 0.050693489611148834, -0.2149306684732437, 0.556681752204895, 0.538385808467865, 0.46275636553764343, -0.3609013855457306, -0.6434202790260315, 0.44212061166763306, 0.24816811084747314, -0.3137664794921875, -0.7552610635757446, -0.12057052552700043, -1.533016562461853, 0.27294912934303284, -1.7578742504119873, 0.022680647671222687, -0.6098893284797668, -0.5146712064743042, -0.18071816861629486, -0.31661367416381836, 0.2097320407629013, 0.07856933027505875, -0.0510660745203495, -0.11378800868988037, -0.40615907311439514, -0.19051681458950043, 0.7901192307472229, 0.8477826118469238, -0.7264919877052307, -0.09146390855312347, 0.04455867409706116, -0.24258476495742798, 0.39864256978034973, 0.614374041557312, -0.49636131525039673, -0.9110376834869385, -1.7018386125564575, 0.4226054847240448, -0.37862521409988403, -0.14010415971279144, -0.7201942205429077, 0.44519418478012085, 0.42169898748397827, 0.025478651747107506, 0.3714519739151001, 0.17704488337039948, -0.7154242396354675, -0.859714686870575, 0.30055150389671326, -1.1664130687713623, 0.2232501357793808, 0.3022448718547821, -0.7376277446746826, -0.1785372942686081, 0.3297325670719147, -0.1408781260251999, -1.0454597473144531, -0.8544691205024719, 0.4016611874103546, -0.47401198744773865, 0.3996628224849701, -0.41876083612442017, 0.08679260313510895, -1.0841346979141235, -0.1334182769060135, 0.006175070069730282, 0.37485453486442566, -0.7441807389259338, 1.02764093875885, 0.2804623544216156, -1.101749300956726, -0.1971787065267563, 0.5527490377426147, -0.09690841287374496, -0.1663384884595871, 0.48715582489967346, 0.31312891840934753, -0.28219956159591675, 0.4632989466190338, 0.591515839099884, 0.38512930274009705, -0.8525994420051575, -0.20376630127429962, 1.0680203437805176, -0.7031739950180054, -0.08268748223781586, 1.462351679801941, -0.09542936831712723, -1.6589021682739258, 0.1636335253715515, -0.9722185134887695, -0.40774762630462646, -0.2609235644340515, 0.623065173625946, -0.0750172883272171, 0.00767260929569602, 0.02065086178481579, -0.3805634379386902, 0.21382272243499756, -0.038985688239336014, -0.5102689266204834, 0.370883971452713, -0.4684479236602783, -0.2706240117549896, 0.5285744071006775, 1.2813048362731934, -0.7969802021980286, -0.8151310682296753, -0.8068259358406067, -0.2658121585845947, 0.3441637456417084, 0.20962877571582794, -0.622715175151825, -0.7364339828491211, 0.7795085906982422, 0.4727167785167694, 0.034181248396635056, 0.22666418552398682, -0.5300309062004089, 0.21343107521533966, 0.9397739768028259, -0.10765449702739716, -0.8445034623146057, -0.41759178042411804, 1.6322004795074463, 1.1906795501708984, -1.3125522136688232, -0.16208453476428986, -0.16208435595035553, -0.6570730209350586, 0.9602348208427429, 0.5188115835189819, 0.018431561067700386, 1.3189537525177002, -0.38727453351020813, 0.337697297334671, 0.5315774083137512, -1.1058107614517212, -0.3371323347091675, 1.0240482091903687, 0.9274887442588806, 1.091204285621643, 0.4531554579734802, 0.08454656600952148, 0.8776606321334839, -0.36798006296157837, -0.11335244029760361, 0.32250741124153137, 0.13964663445949554, 0.06169021502137184, -0.27283960580825806, -0.04560044780373573, 0.5960631370544434, -0.6074576377868652, -0.8231896758079529, 0.3287518620491028, 0.5404722690582275, 0.5833237767219543, 0.5987348556518555, 0.5829246044158936, -0.2376837432384491, 0.6512235403060913, 0.30659136176109314, 0.4251474142074585, -0.9217515587806702, -0.568479061126709, -0.569506824016571, -0.5283575057983398, 0.19613155722618103, -0.007978583686053753, -0.3175869882106781, -0.42034995555877686, -0.16980400681495667, 0.5354055762290955, -0.2358185201883316, 0.5018381476402283, 1.1391156911849976, 0.4671236574649811, 0.5308290123939514, -0.1556151956319809, -0.6647960543632507, -0.43020209670066833, -0.9589105844497681, 0.2417246401309967, -0.4360050857067108, -0.061679739505052567, 0.14827437698841095, -0.20499995350837708, 0.09687434881925583]}, "authors": [{"authorId": "2067506606", "name": "Tuan Dinh"}, {"authorId": "2111186856", "name": "Yuchen Zeng"}, {"authorId": "2165321339", "name": "Ruisu Zhang"}, {"authorId": "70991748", "name": "Ziqian Lin"}, {"authorId": "113117127", "name": "Shashank Rajput"}, {"authorId": "2165226185", "name": "Michael Gira"}, {"authorId": "8414722", "name": "Jy-yong Sohn"}, {"authorId": "1740595", "name": "Dimitris Papailiopoulos"}, {"authorId": "2115495251", "name": "Kangwook Lee"}], "references": [{"paperId": "1c1ca2392155ddf30408a442e6b504b5d60d4f2a", "title": "When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment"}, {"paperId": "efa1647594b236361610a20d507127f0586a379b", "title": "Diffusion Models in Vision: A Survey"}, {"paperId": "a8fd9c1625011741f74401ff9bdc1c584e25c86d", "title": "Language Models are General-Purpose Interfaces"}, {"paperId": "bd1331b233e84bab7eba503abc60b31ac08e7881", "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models"}, {"paperId": "d253beffd28d88cc3150c9e80511a6187ea6613b", "title": "Unveiling Transformers with LEGO: a synthetic reasoning task"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large Language Models are Zero-Shot Reasoners"}, {"paperId": "5922f437512158970c417f4413bface021df5f78", "title": "A Generalist Agent"}, {"paperId": "81986b8a3d3fe6c5be06fc4527953fb514ad12e8", "title": "Improving In-Context Few-Shot Learning via Self-Supervised Training"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "67d2bc2b68207ee95b543a19ec288a2aa8945e4d", "title": "Can Neural Nets Learn the Same Model Twice? Investigating Reproducibility and Double Descent from the Decision Boundary Perspective"}, {"paperId": "f4df78183261538e718066331898ee5cad7cad05", "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"}, {"paperId": "b9b220b485d2add79118ffdc2aaa148b67fa53ef", "title": "Pre-Trained Language Models for Interactive Decision-Making"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "8a408271a1a2226163a579499905a0f4752b5085", "title": "GenLabel: Mixup Relabeling using Generative Models"}, {"paperId": "7c42aa14249fe3e4552d0eeebb8a5cfff389ea5d", "title": "Improved Input Reprogramming for GAN Conditioning"}, {"paperId": "002c256d30d6be4b23d365a8de8ae0e67e4c9641", "title": "Improving language models by retrieving from trillions of tokens"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "40b4d98588719407fb72a014ab79e4145695654b", "title": "Quantifying Adaptability in Pre-trained Language Models with 500 Tasks"}, {"paperId": "c23d9d44e8bc68408cea9f305d1f24d915bc0d0d", "title": "Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey"}, {"paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea", "title": "Training Verifiers to Solve Math Word Problems"}, {"paperId": "f3a332ff1b73acda482e5d83696b2c701f487819", "title": "P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"}, {"paperId": "0cc771ca7859b395728c428b2a707007c4d69416", "title": "Pretrained Language Models are Symbolic Mathematics Solvers too!"}, {"paperId": "3acff13163f51765bb36147f6107967765509d9b", "title": "Deep Neural Networks and Tabular Data: A Survey"}, {"paperId": "c206a6e7f51f5e1b6bfc479a174b66ad88ada2db", "title": "Exploring the Limits of Large Scale Pre-training"}, {"paperId": "fa349e881c72825a8082a1c80e85583dba6d2840", "title": "Cross-lingual Intermediate Fine-tuning improves Dialogue State Tracking"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "9933a5af7895354087baf6c96b64dc8a8973eaed", "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs"}, {"paperId": "2406cf39805c70264c4226b7325a09b506c70921", "title": "TAPEX: Table Pre-training via Learning a Neural SQL Executor"}, {"paperId": "dc32a984b651256a8ec282be52310e6bd33d9815", "title": "Highly accurate protein structure prediction with AlphaFold"}, {"paperId": "01b5412f3d17e90e09226d7c40ad4d4468a1414d", "title": "Multimodal Few-Shot Learning with Frozen Language Models"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "6d4a9f1c41b078846901362ba0dce8295dd6a2a8", "title": "End-to-End Training of Multi-Document Reader and Retriever for Open-Domain Question Answering"}, {"paperId": "009560d2710138a446e6e254d8ddcb65eaa0e687", "title": "Tabular Data: Deep Learning is Not All You Need"}, {"paperId": "5fa2103e36b3e76e49edb8433a1206a6b25e3ead", "title": "SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training"}, {"paperId": "386bfd0e411dee4f512a8737c55dd84846981182", "title": "TABBIE: Pretrained Representations of Tabular Data"}, {"paperId": "0adec918885dff698acf359988ed79a543157f80", "title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"}, {"paperId": "3e32139deb17761a25075f8839daa61ad5992fc9", "title": "Cross-Attention is All You Need: Adapting Pretrained Transformers for Machine Translation"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "a9fe5bd8da2d9603cf2cf6c6ea8b0f83c6d3a4f9", "title": "How many data points is a prompt worth?"}, {"paperId": "3544650f12a05cf4ed3bf2f7e22fc5c02fcabf50", "title": "Pretrained Transformers as Universal Computation Engines"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "2cc3ab9fa41ba2804e301f7eae9598636e62422a", "title": "Investigating the Limitations of Transformers with Simple Arithmetic Tasks"}, {"paperId": "616e0ed02ca024a8c1d4b86167f7486ea92a13d9", "title": "VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning"}, {"paperId": "ac3cdb50606f7770eef8e4cd951840a4f71287a0", "title": "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm"}, {"paperId": "141a5033d9994242b18bb3b217e79582f1ee9306", "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"}, {"paperId": "46c585ee9abf76779ea4b863d2da4358efd0d1d3", "title": "Adaptive Semiparametric Language Models"}, {"paperId": "59641c10ed7431a3cf841f308367dc2dc0281b74", "title": "What Makes Good In-Context Examples for GPT-3?"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "a2ec47b9bcc95d2456a8a42199233e5d9129ef18", "title": "TabTransformer: Tabular Data Modeling Using Contextual Embeddings"}, {"paperId": "d688594d2aac080f657b7be251e89cca6a7df165", "title": "FairBatch: Batch Selection for Model Fairness"}, {"paperId": "3f74ac68ee7a852c9891e9f356d932bbfbb34145", "title": "Intermediate Self-supervised Learning for Machine Translation Quality Estimation"}, {"paperId": "1b055049c568be70d6a762679cdb93f630d5d6e6", "title": "Tabular Transformers for Modeling Multivariate Time Series"}, {"paperId": "7ba0dc20800195c6350995695c8bf86be6227c49", "title": "Improving Zero and Few-Shot Abstractive Summarization with Intermediate Fine-tuning and Data Augmentation"}, {"paperId": "b360427d0991143013da6a208ccf28bcc8028fab", "title": "Large Scale Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "45cdda3f96ae32927c7b073ebbedf46f5e0fbdc5", "title": "Enhancing the Numeracy of Word Embeddings: A Linear Algebraic Perspective"}, {"paperId": "055fac05cd424e7b1bdcd359ff7980ca8d938ef3", "title": "Learning Helpful Inductive Biases from Self-Supervised Pretraining"}, {"paperId": "b042444e4e9501ab2fcae6b1f6b9d834146b3fc9", "title": "Do Language Embeddings capture Scales?"}, {"paperId": "84476fdf6ead3553f4493dff8e02308439d6222b", "title": "Improve Transformer Models with Better Relative Position Embeddings"}, {"paperId": "6b989b8327db3a7212141c59c1569f0219775058", "title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks"}, {"paperId": "19af8292ff3cc10aad6f190490f0d34691658179", "title": "Investigating Pretrained Language Models for Graph-to-Text Generation"}, {"paperId": "a65cff2a792cd2133d2db91d88327bdac6cbf108", "title": "Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup"}, {"paperId": "3bddc8f2dff60d9da7d7c5f315f3467966f61ff1", "title": "Auto-Sklearn 2.0: Hands-free AutoML via Meta-Learning"}, {"paperId": "ea8c46e193d5121e440daf96edfd15a47151c293", "title": "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering"}, {"paperId": "8256f48f759cf85044db251cc512f965834945b3", "title": "Rethinking Positional Encoding in Language Pre-training"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "f2f3c83db919a2429c4fcad2d0a0ed4e5294354a", "title": "Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting"}, {"paperId": "52cb05d721688cb766c6e282e9d55c3b8e3dc0cf", "title": "TaPas: Weakly Supervised Table Parsing via Pre-training"}, {"paperId": "88338c58701f34503c7af77e34f19d9a5cd66313", "title": "Adversarial Attacks on Deep-learning Models in Natural Language Processing"}, {"paperId": "a750d10fef892f63c7a52eb70f2a5f081bfebc82", "title": "Abstractive Text Summarization based on Language Model Conditioning and Locality Modeling"}, {"paperId": "1d0d9550ecd2bece6a34fe1ffd12fb7504e7aaa0", "title": "XGPT: Cross-modal Generative Pre-Training for Image Captioning"}, {"paperId": "a834fa118bb738a276ebf2756d66f11b543a63c8", "title": "The Tree Ensemble Layer: Differentiability meets Conditional Computation"}, {"paperId": "4243555758433880a67b15b50f752b1e2a8c4609", "title": "UniViLM: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation"}, {"paperId": "7af72a461ed7cda180e7eab878efd5f35d79bbf4", "title": "A Simple Framework for Contrastive Learning of Visual Representations"}, {"paperId": "4f03e69963b9649950ba29ae864a0de8c14f1f86", "title": "K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters"}, {"paperId": "d0e28f5dc1feae19e41087a92a87992977fd85af", "title": "Encoding word order in complex embeddings"}, {"paperId": "b39eed03d345f5c244eac12fd1315d26eba77d62", "title": "Deep Learning for Symbolic Mathematics"}, {"paperId": "01f2b214962997260020279bd1fd1f8f372249d4", "title": "Evaluating Commonsense in Pre-trained Language Models"}, {"paperId": "75352cc69a29bd5fc411e0e79737cb96b6309161", "title": "Distilling Knowledge Learned in BERT for Text Generation"}, {"paperId": "388e2fcdcefbe0834e153ab2a0be127092f9674d", "title": "DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation"}, {"paperId": "db95ba221305a3aa2ec8bbc78de0f42485c63c12", "title": "Generalizing Question Answering System with Pre-trained Language Model Fine-tuning"}, {"paperId": "2be2f27c079663d3e3a769bcb04b0d341e76a707", "title": "SpeechBERT: Cross-Modal Pre-trained Language Model for End-to-end Spoken Question Answering"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "6648b4db5f12c30941ea78c695e77aded19672bb", "title": "Unified Vision-Language Pre-Training for Image Captioning and VQA"}, {"paperId": "0427110f0e79f41e69a8eb00a3ec8868bac26a4f", "title": "Do NLP Models Know Numbers? Probing Numeracy in Embeddings"}, {"paperId": "0b22dbd48ce4e13bdbf0c9d5e86a9cefdaf6d40a", "title": "Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data"}, {"paperId": "75acc731bdd2b626edc74672a30da3bc51010ae8", "title": "CTRL: A Conditional Transformer Language Model for Controllable Generation"}, {"paperId": "5019dbe8d1da5f128f4f373d6849095cf18fd519", "title": "The Woman Worked as a Babysitter: On Biases in Language Generation"}, {"paperId": "3e0201b514f5f09703eaa0eed25afaa9f09be20a", "title": "Improving Neural Story Generation by Targeted Common Sense Grounding"}, {"paperId": "9fe69cf5c104b2205cdb7908df8cdb389256b4b5", "title": "TabNet: Attentive Interpretable Tabular Learning"}, {"paperId": "2bc1c8bd00bbf7401afcb5460277840fd8bab029", "title": "Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training"}, {"paperId": "65a9c7b0800c86a196bc14e7621ff895cc6ab287", "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "3813b88a4ec3c63919df47e9694b577f4691f7e5", "title": "A survey on Image Data Augmentation for Deep Learning"}, {"paperId": "a5dde0a71fb0465d33b95496c4bb64914b3d62d9", "title": "Exploring Numeracy in Word Embeddings"}, {"paperId": "acaa653a7f0b7a2909058a48efe824dee54cb72f", "title": "Convolutional Neural Networks on Randomized Data"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "fd846869e6f25d9b1a524aef8b54a08b81a1b1fa", "title": "Comparison of Diverse Decoding Methods from Conditional Language Models"}, {"paperId": "329b84a919bfd1771be5bd14fa81e7b3f74cc961", "title": "An Introduction to Variational Autoencoders"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "c41a11c0e9b8b92b4faaf97749841170b760760a", "title": "VideoBERT: A Joint Model for Video and Language Representation Learning"}, {"paperId": "040a54b2b2dd2fb1da1c36ca30538c4f0b242aab", "title": "AlphaStar: an evolutionary computation perspective"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "16c844fd4d97f3c6eb38b0d6527c87d184efedc3", "title": "The Evolved Transformer"}, {"paperId": "8d23d6432c27843040f51dcf0191877f7a9994e9", "title": "Robust Statistics"}, {"paperId": "b47381e04739ea3f392ba6c8faaf64105493c196", "title": "Sentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data Tasks"}, {"paperId": "1de9dc2a70bca2cb0b689d777e7a41f460e39b5f", "title": "Learning with Bad Training Data via Iterative Trimmed Loss Minimization"}, {"paperId": "f91ff6c0aeba78f94f02b761446d5d911e6ab390", "title": "On Self Modulation for Generative Adversarial Networks"}, {"paperId": "567889d2653b20f8bde30d91c93d8d4167778b44", "title": "Autonomous Deep Learning: A Genetic DCNN Designer for Image Classification"}, {"paperId": "9784fbf77295860b2e412137b86356d70b25e3c0", "title": "The Natural Language Decathlon: Multitask Learning as Question Answering"}, {"paperId": "616f2a867291e503e057ba63817aaff10bc90ecb", "title": "Regularization Learning Networks"}, {"paperId": "5a8f99c24bce7241a23c0941ab4be7e7b8faf49d", "title": "A Reductions Approach to Fair Classification"}, {"paperId": "3f735937020c82e400c8b075ada95c80c26a5e94", "title": "Automated Assistance for Creative Writing with an RNN Language Model"}, {"paperId": "f170fed9acd71bd5feb20901c7ec1fe395f3fae5", "title": "Visualisation and 'diagnostic classifiers' reveal how recurrent and recursive neural networks process hierarchical structure"}, {"paperId": "0197f278e2dedd67ec5067f47037b8cdd3ae8509", "title": "Deep Multimodal Learning: A Survey on Recent Advances and Trends"}, {"paperId": "c4c06578f4870e4b126e6837907929f3c900b99f", "title": "Dynamic Routing Between Capsules"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "7cfa5c97164129ce3630511f639040d28db1d4b7", "title": "FiLM: Visual Reasoning with a General Conditioning Layer"}, {"paperId": "f9c602cc436a9ea2f9e7db48c77d924e09ce3c32", "title": "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms"}, {"paperId": "7aa38b85fa8cba64d6a4010543f6695dbf5f1386", "title": "Towards Deep Learning Models Resistant to Adversarial Attacks"}, {"paperId": "9ae0a24f0928cab1554a6ac880f6b350f85be698", "title": "One Model To Learn Them All"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "d89ee98810039d2061ed42ee8026da49c503d16b", "title": "Learning multiple visual domains with residual adapters"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "802168a81571dde28f5ddb94d84677bc007afa7b", "title": "Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles"}, {"paperId": "e2a85a6766b982ff7c8980e57ca6342d22493827", "title": "Adversarial Machine Learning at Scale"}, {"paperId": "8f3b80ddc0dd62e6c3369fabb1715990c29e9b9a", "title": "Learning without Forgetting"}, {"paperId": "1db6e3078597386ac4222ba6c3f4f61b61f53539", "title": "Adversarial Feature Learning"}, {"paperId": "bef4ae975a0068484cfa62d3b006991d68716c04", "title": "Where does AlphaGo go: from church-turing thesis to AlphaGo thesis and beyond"}, {"paperId": "d64c956fc484d0cf965b1c9b705e60a356875894", "title": "Structured and Efficient Variational Deep Learning with Matrix Gaussian Posteriors"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "775a4e375cc79b53b94e37fa3eedff481823e4a6", "title": "Efficient and Robust Automated Machine Learning"}, {"paperId": "62adfea3cc1cd9eb6b53e0e8a40be5dfda2adf8d", "title": "Weight Uncertainty in Neural Network"}, {"paperId": "f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6", "title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "f164ee353ada936ef97d0d379f8581336ddc9733", "title": "Prediction of full load electrical power output of a base load operated combined cycle power plant using machine learning methods"}, {"paperId": "46d71d947231f86e1f9d4581e61212385debbe14", "title": "OpenML: networked science in machine learning"}, {"paperId": "13bc4e683075bdd6a3f0155241c276a772d4aa06", "title": "Generative adversarial networks"}, {"paperId": "0407b605b8f55db72e2545586bfe8e946b691b70", "title": "An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks"}, {"paperId": "d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad", "title": "Intriguing properties of neural networks"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "a25fbcbbae1e8f79c4360d26aa11a3abf1a11972", "title": "A Survey on Transfer Learning"}, {"paperId": "57458bc1cffe5caa45a885af986d70f723f406b4", "title": "A unified architecture for natural language processing: deep neural networks with multitask learning"}, {"paperId": "61d468d5254730bbecf822c6b60d7d6595d9889c", "title": "Using data mining to predict secondary school student performance"}, {"paperId": "787827850b614135f6b432603afc90b58a8cc665", "title": "Computer Vision: A Modern Approach"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "ba54dd47c1b27766ed5347d29d90a39753b7c13a", "title": "Artificial convolution neural network for medical image pattern recognition"}, {"paperId": "319f22bd5abfd67ac15988aa5c7f705f018c3ccd", "title": "Learning internal representations by error propagation"}, {"paperId": "1a3f80af28be2a2c22fdd40379a9a2396de0b276", "title": "Natural-Language Processing"}, {"paperId": "b42e3a759348f27cca2f918a6bd0b139a5312e44", "title": "A Survey of Pretrained Language Models Based Text Generation"}, {"paperId": "d4fb836846b79d8692df8bf54d20d1a9d02ffe7d", "title": "Debiasing Pre-Trained Language Models via Efficient Fine-Tuning"}, {"paperId": "13a4bcc9d83d18a6a6ccd59cce2ae75b4eff04cb", "title": "Regression Transformer: Concurrent Conditional Generation and Regression by Blending Numerical and Textual Tokens"}, {"paperId": "8faac15828f76fe8dff49309a8167d34814ae18c", "title": "A Conversational Paradigm for Program Synthesis"}, {"paperId": "0ce43def1c95802a464449f055e78c08d6d99dc2", "title": "Towards Table-to-Text Generation with Numerical Reasoning"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "9e8cebfb6077a9b1e5d5f2734df171a192ebf532", "title": "Text Generation with Efficient (Soft) Q-Learning"}, {"paperId": "07b64856abe1b69dba22da9ca69781d96ea6ecaa", "title": "Regularization is all you Need: Simple Neural Nets can Excel on Tabular Data"}, {"paperId": "a33b4a2002161a18bc7eb929566d77fd5178c2e9", "title": "Predicting Inductive Biases of Pre-Trained Models"}, {"paperId": null, "title": "GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/mesh-transformer-jax"}, {"paperId": null, "title": "Openai fine-tuning documentation: Preparing your dataset"}, {"paperId": null, "title": "Autoprompt: Eliciting knowledge from language models with automatically generated prompts"}, {"paperId": "5cdea2672c090d987a2020942f46c20c05282aef", "title": "Pretrained Language Models and Backtranslation for English-Basque Biomedical Neural Machine Translation"}, {"paperId": null, "title": "Iris dataset for machine learning, 2020"}, {"paperId": null, "title": "compositional text generation tasks such as completing stories, high temperature leads to better and more creative performance"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "59d9318f07331ec15e54fe2a4218bc4a5c247a38", "title": "Foolbox: A Python toolbox to benchmark the robustness of machine learning models"}, {"paperId": null, "title": "UCI machine learning repository"}, {"paperId": null, "title": "Xgboost: extreme gradient boosting"}, {"paperId": "9dc62fe526f67674512d749ad1880f8eaa5ca3de", "title": "Understanding Machine Learning From Theory to Algorithms 1st Edition Shwartz Solutions Manual"}, {"paperId": "4574d77fff19e093782178595a8988a7f3aa1969", "title": "Latent Dirichlet Allocation"}, {"paperId": "dc52d1ede1b90bf9d296bc5b34c9310b7eaa99a2", "title": "The mnist database of handwritten digits"}, {"paperId": null, "title": "Random decision forests"}, {"paperId": "ead572634c6f7253bf187a3e9a7dc87ae2e34258", "title": "Learning With Continuous Classes"}]}