{"paperId": "5f0b826ffe17faa2cdec21752e7d1863bd909f2c", "title": "Foundation Models in Robotics: Applications, Challenges, and the Future", "abstract": "We survey applications of pretrained foundation models in robotics. Traditional deep learning models in robotics are trained on small datasets tailored for specific tasks, which limits their adaptability across diverse applications. In contrast, foundation models pretrained on internet-scale data appear to have superior generalization capabilities, and in some instances display an emergent ability to find zero-shot solutions to problems that are not present in the training data. Foundation models may hold the potential to enhance various components of the robot autonomy stack, from perception to decision-making and control. For example, large language models can generate code or provide common sense reasoning, while vision-language models enable open-vocabulary visual recognition. However, significant open research challenges remain, particularly around the scarcity of robot-relevant training data, safety guarantees and uncertainty quantification, and real-time execution. In this survey, we study recent papers that have used or built foundation models to solve robotics problems. We explore how foundation models contribute to improving robot capabilities in the domains of perception, decision-making, and control. We discuss the challenges hindering the adoption of foundation models in robot autonomy and provide opportunities and potential pathways for future advancements. The GitHub project corresponding to this paper (Preliminary release. We are committed to further enhancing and updating this work to ensure its quality and relevance) can be found here: https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models", "venue": "arXiv.org", "year": 2023, "citationCount": 44, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "How foundation models contribute to improving robot capabilities in the domains of perception, decision-making, and control is explored and the challenges hindering the adoption of foundation models in robot autonomy are discussed."}, "embedding": {"model": "specter_v2", "vector": [0.152405247092247, 0.7763084173202515, -0.45158517360687256, 0.1592678427696228, 0.16999046504497528, 0.3460821807384491, 0.31543755531311035, -0.47890397906303406, -0.5679162740707397, -0.6478227972984314, -0.007080456707626581, 0.22996410727500916, 0.10119606554508209, 0.19567906856536865, -0.7889724969863892, 0.039369069039821625, -0.9815478324890137, 0.17991304397583008, 0.3707733750343323, -0.3443787395954132, -0.35199296474456787, -0.26376259326934814, -1.4772329330444336, -0.005976835265755653, 0.21785597503185272, 0.5030722618103027, 0.37920063734054565, 0.9474023580551147, 0.3304966688156128, 0.7504218220710754, 1.1161800622940063, 0.3819272816181183, 0.43681809306144714, 0.26950472593307495, -0.2553280293941498, -0.20051905512809753, 0.2621995806694031, -0.4654182195663452, -1.0763317346572876, 1.0217722654342651, -0.31860730051994324, 0.18041181564331055, 0.37595808506011963, -1.1302335262298584, -0.21364089846611023, 0.12132535129785538, 0.9061022400856018, 0.421891987323761, -0.44695210456848145, 0.11576400697231293, 1.0873980522155762, -1.0293364524841309, 0.1580858826637268, 1.46669602394104, 0.36699432134628296, 0.8869001865386963, -0.20995455980300903, -0.7750804424285889, 0.4702158570289612, -0.3207366466522217, -0.4737001657485962, -0.2358512431383133, -0.34410732984542847, -0.6029447913169861, 1.511438250541687, -1.0784426927566528, 0.18515345454216003, 0.8154876828193665, 0.7660911083221436, 1.2213832139968872, 0.08385367691516876, -0.601909875869751, 0.46108537912368774, -0.04124400019645691, 0.21291686594486237, 1.0704540014266968, 0.23635786771774292, 0.6186930537223816, -1.1870079040527344, 0.35844510793685913, 0.5416569113731384, 0.1218961775302887, 0.0682043582201004, -0.7686190009117126, -0.5305938720703125, 0.6145870685577393, 0.9014013409614563, -0.02339627407491207, -0.32888102531433105, 1.102283000946045, 0.5158653855323792, 0.30122169852256775, -0.8951470851898193, 0.432968407869339, 0.23528461158275604, 0.8253061175346375, -0.03379353508353233, 0.32887691259384155, 0.24091164767742157, 1.1458566188812256, 0.1440012902021408, 0.21536557376384735, -0.036247219890356064, -0.22582173347473145, 1.3204843997955322, 0.20729076862335205, 0.7164059281349182, -0.8528795838356018, 0.17776402831077576, -0.5689973831176758, 0.6837992072105408, -0.35586994886398315, -0.3547380566596985, -0.34736379981040955, -0.5865147709846497, -0.2059672623872757, -0.5343864560127258, 0.31495505571365356, -0.9722586870193481, 0.6398764848709106, -0.33949771523475647, -0.163183331489563, 0.6158475279808044, 0.8272438645362854, 0.06265706568956375, 0.32819661498069763, -0.05248812213540077, 0.8220223188400269, 0.46940988302230835, -1.1717042922973633, -0.5800722241401672, -1.4188652038574219, 0.0672711580991745, 0.26193317770957947, 0.44812503457069397, -0.06917820870876312, -0.7531564831733704, -1.267774224281311, -1.3645319938659668, 0.02126806043088436, -0.5925736427307129, 0.44573476910591125, 1.3657965660095215, -0.19691386818885803, -0.832700252532959, 0.8009799718856812, -0.47882702946662903, -0.28228145837783813, 0.14954638481140137, 0.7667043209075928, 0.09944701939821243, -0.32675883173942566, -0.7975699305534363, 0.7845547199249268, 0.7099849581718445, -0.4353680908679962, -1.289013147354126, 0.3061239719390869, -1.447880506515503, -0.46801239252090454, 0.3293439447879791, -0.7262288928031921, 1.390041708946228, 0.045361004769802094, -1.2524480819702148, 0.48139119148254395, 0.060816749930381775, -0.2999518811702728, 0.27748146653175354, -0.4410302937030792, -0.5527117848396301, -0.16606256365776062, -0.12052346765995026, 0.8362693190574646, 0.2612634301185608, -0.4926241636276245, -0.007245179265737534, 0.13132339715957642, 0.12336491793394089, -0.4845908582210541, -0.2138454020023346, 0.5653841495513916, -0.3207375705242157, 0.32066217064857483, 0.5508546233177185, 0.1786055713891983, -0.5071913003921509, 0.22973208129405975, -0.18336977064609528, -0.8267787098884583, 0.7419436573982239, 0.2797418534755707, -0.020243026316165924, -1.1294974088668823, -0.6753131151199341, -0.14626511931419373, -0.18004348874092102, -0.6036092638969421, -0.6801797151565552, 0.27239760756492615, -0.234808087348938, 0.27667608857154846, 0.07703696936368942, -0.6837599873542786, -0.03839476406574249, 0.2428032010793686, -1.0079814195632935, 0.38152310252189636, 0.46436262130737305, 0.8192288875579834, -1.2636711597442627, 0.2681891918182373, 0.3145487308502197, -0.09276954084634781, -0.9562439918518066, 1.18918776512146, -0.5042247772216797, 0.2184326946735382, -0.21924607455730438, -0.29530397057533264, -0.36826640367507935, -0.20758436620235443, 0.3598484694957733, -0.40991291403770447, -0.05995948612689972, 0.5388513803482056, -0.4395526051521301, 1.7638074159622192, -0.4208901822566986, 0.3593617081642151, 0.3440707325935364, -0.4569602906703949, 0.24549102783203125, 0.3779323697090149, -0.24907487630844116, -0.15802784264087677, 0.5936046838760376, 0.31900444626808167, -0.14952364563941956, -0.20523770153522491, 0.5213603973388672, 0.8048973083496094, -0.34146562218666077, -0.2371300309896469, 0.8065391182899475, -0.8281208276748657, 0.4528866112232208, 0.26337194442749023, 0.6667225360870361, 0.8052463531494141, 0.0511602982878685, -0.19669972360134125, -0.20393240451812744, -0.6693190932273865, -0.04070603847503662, 0.6258096694946289, 0.35070717334747314, 1.0062494277954102, -0.0405593141913414, -0.8732839822769165, -0.43396201729774475, -0.14505259692668915, 1.0393315553665161, 0.7410175800323486, 0.5845109820365906, 0.0497853085398674, -0.6269384622573853, -0.10414746403694153, -0.3976263999938965, 0.0991363599896431, -0.607927143573761, -0.38290661573410034, -0.3232792019844055, -0.5994219779968262, 0.5896987318992615, 0.5158692598342896, 1.1501507759094238, -0.5459833741188049, -0.6329984664916992, -0.29200485348701477, 0.6258361339569092, -0.9888659715652466, 0.05574902519583702, 0.7369207739830017, -0.46818384528160095, -0.5182719230651855, 0.5497258305549622, -0.14434193074703217, 0.20476065576076508, -0.29820185899734497, 0.4669601023197174, -0.5083452463150024, -0.6237702369689941, 0.38319581747055054, 0.7831308245658875, -0.911049485206604, -0.41344302892684937, -0.05449296534061432, 0.5805789828300476, -0.4515562355518341, -0.21797887980937958, 0.3619321286678314, 0.10506222397089005, -0.019113140180706978, -0.3778266906738281, -0.0064759040251374245, 0.4188390076160431, 0.09586641192436218, 0.7526405453681946, -0.2764921188354492, 0.1213446855545044, -0.29423782229423523, 0.7161701321601868, 0.04361002892255783, -0.5463154911994934, -0.10978766530752182, -0.7090135216712952, -0.015030233189463615, 0.6826914548873901, -0.8303869366645813, 0.18278981745243073, -0.23016919195652008, 0.7468154430389404, -1.0074920654296875, -0.2667490243911743, -0.0908612459897995, 0.5202062129974365, -0.1126985028386116, 0.7414504885673523, 0.2969595491886139, 0.7813246846199036, 0.30608314275741577, 0.24827006459236145, -1.1323622465133667, 0.7650352120399475, 0.13868172466754913, -0.027386223897337914, 0.22674693167209625, -0.07791943103075027, -0.3561643064022064, -0.582531750202179, -0.34662923216819763, -0.18798165023326874, -0.5990566611289978, 0.4525001049041748, -1.0581393241882324, -0.7249960899353027, -0.35392099618911743, -0.7095150947570801, -0.7776408195495605, -0.16277125477790833, 0.08177615702152252, -0.7991316914558411, -1.101646065711975, -0.8551008701324463, -0.8299586772918701, -0.19423237442970276, -1.2561639547348022, 0.4455088973045349, 0.3781265914440155, -0.21565866470336914, -0.023256786167621613, -0.11136715859174728, -0.5470167398452759, 0.5757827162742615, -0.43008315563201904, 0.28663039207458496, -0.1104748547077179, -0.33649006485939026, -0.3886411190032959, 0.27880215644836426, 0.48206132650375366, -0.45088091492652893, 0.12381502240896225, -1.106601357460022, 0.1851397007703781, -0.5880089402198792, -1.1034489870071411, 0.35426241159439087, -0.2857242524623871, 0.5949768424034119, 0.19926822185516357, -0.406444251537323, 0.10773803293704987, 1.3176674842834473, -0.8900907635688782, 0.09221450239419937, 0.37021976709365845, 0.9060054421424866, 0.3554513454437256, -0.09400102496147156, 0.24773602187633514, 0.34626075625419617, -0.0008516496163792908, 0.8939724564552307, 0.0892791897058487, -0.4347646236419678, -0.9547002911567688, 0.8309726119041443, 0.6498348116874695, 0.46259286999702454, 0.3922273814678192, -0.9368470907211304, 0.9086949229240417, -1.4388508796691895, -0.47276028990745544, 0.8866395354270935, 0.7449368238449097, 0.1275094598531723, 0.1457049399614334, -0.36802414059638977, -0.22810867428779602, 0.8553227186203003, -0.24030296504497528, -0.7577165961265564, -0.4529644250869751, 0.1747821867465973, -0.07940090447664261, 0.32947513461112976, 0.43049877882003784, -0.49258244037628174, 0.26979386806488037, 14.647565841674805, 0.5625919103622437, -0.3765396475791931, 0.5085220336914062, 0.10751353949308395, 0.5851022005081177, 0.008446436375379562, 0.07184675335884094, -1.0307313203811646, -0.5941915512084961, 1.2379635572433472, 0.3872013986110687, 0.8247324824333191, 1.0246922969818115, -0.17352521419525146, 0.09889178723096848, -0.8279543519020081, 0.4847988188266754, 0.491357684135437, -0.8954349756240845, 0.2634185552597046, 0.14907768368721008, 0.35428446531295776, 1.2171895503997803, 0.7974758744239807, 1.0081573724746704, 0.8909868001937866, -0.5319616794586182, 1.0232393741607666, 0.04957568645477295, 0.877772867679596, 0.23890142142772675, 0.4586985409259796, 1.1073447465896606, -0.7694934010505676, -0.5420938730239868, -0.8149469494819641, -1.3155198097229004, -0.2163134515285492, -0.04725300148129463, -0.7684224247932434, -0.4060097932815552, -0.1125810518860817, 0.5735610127449036, 0.3362891972064972, 0.3848111629486084, -0.6352910399436951, 0.17063045501708984, -0.639693021774292, -0.18685343861579895, -0.01356915757060051, 0.6833890676498413, -0.08517109602689743, -0.3076496124267578, -0.03420227766036987, -0.2517087459564209, 0.8879761099815369, 0.5591368079185486, -0.3972572088241577, -0.6624596118927002, -0.7229157090187073, -0.10771322250366211, -0.5442517399787903, 0.8020967245101929, 0.34708404541015625, 0.48264220356941223, -0.007122885435819626, -0.02776355855166912, 0.5515520572662354, 0.22782939672470093, -0.17377924919128418, -0.2127624750137329, 0.30318325757980347, -0.6968860626220703, -0.26082298159599304, 0.11145512759685516, -0.36659327149391174, -0.8231500387191772, -0.503244936466217, -0.13163723051548004, -0.036165185272693634, -0.9534631371498108, -0.5097775459289551, 0.7192391157150269, -0.19753596186637878, -0.47779300808906555, 0.26863011717796326, -1.2918728590011597, -0.24068401753902435, -0.15921732783317566, -1.3836753368377686, -0.8653303980827332, -0.09442806988954544, -0.048688486218452454, -0.09593386948108673, 0.059325892478227615, 1.1535005569458008, -0.300618439912796, -0.46696603298187256, -0.5645975470542908, -0.25946804881095886, -0.10968057066202164, -0.351721853017807, -0.7562639713287354, 0.5007060766220093, 0.30742311477661133, -0.3591042459011078, 0.18424071371555328, 0.46932336688041687, 0.07659534364938736, -1.1738485097885132, -0.16971684992313385, -0.17170627415180206, -0.8831005096435547, -0.15841813385486603, -0.7430599927902222, -0.41998299956321716, 0.4215051829814911, 0.35988959670066833, 0.1312047839164734, -0.15005087852478027, -0.06788857281208038, -0.7768301963806152, -0.19257241487503052, -0.8925389051437378, 0.2078624814748764, 0.40120330452919006, -0.7394286394119263, -0.7430227994918823, 0.012364402413368225, 0.1812009960412979, -0.998675525188446, -0.07099293172359467, 0.18318404257297516, 0.3919241726398468, -0.09721405804157257, 0.9530975222587585, -0.21545593440532684, 0.6580848693847656, 0.33287930488586426, -0.0427621528506279, -0.5510736107826233, 0.17399156093597412, -0.8414634466171265, 0.1243353933095932, -0.49944353103637695, 0.46974191069602966, -0.627629280090332, -0.06217145547270775, 0.9811530113220215, -0.048380009829998016, -0.3249138295650482, -0.6566475629806519, -0.5879225730895996, -0.21215666830539703, -0.5555799007415771, -0.03712195158004761, -0.5600888133049011, 0.1454494297504425, 0.028676239773631096, 0.6100936532020569, 1.022202730178833, -0.006197134032845497, -0.6231105327606201, 0.6737001538276672, 0.25025609135627747, -0.19772808253765106, -0.23835556209087372, -0.5158671140670776, -1.522080898284912, 0.146963968873024, -1.2285041809082031, 0.9073066115379333, -1.1042847633361816, -0.8761082291603088, 0.00992930680513382, -0.5322994589805603, 0.19096748530864716, 0.9238753318786621, -0.5341132283210754, -0.3830114006996155, -0.11429861187934875, -0.8671698570251465, 0.8884401917457581, 0.8289106488227844, -0.8858538269996643, 0.17961935698986053, -0.21041128039360046, 0.31943804025650024, 0.8746670484542847, 0.626257061958313, -0.31865084171295166, -0.7966647148132324, -1.0614409446716309, 0.4886305034160614, -0.504824697971344, 0.14244744181632996, -1.4460231065750122, 1.1924055814743042, 0.2079363912343979, -0.026319235563278198, 0.4292965829372406, 0.6481496095657349, -1.1591330766677856, -0.656439483165741, 0.8417622447013855, -0.8109226822853088, -0.1033514216542244, 0.44130679965019226, 0.12262991815805435, -0.36229580640792847, 0.5996790528297424, 0.1405268907546997, -1.0611358880996704, -0.9480295181274414, 0.07351109385490417, -0.7977703213691711, -0.2778484523296356, 0.03911826014518738, 0.09617998450994492, -0.7949942946434021, -0.18686367571353912, -0.2075304090976715, 0.6658321619033813, -0.031107885763049126, 0.9579938650131226, 0.9035658240318298, -0.9292237162590027, 0.4624521732330322, 0.3273690938949585, 0.13134676218032837, 0.4079284071922302, 0.1341661661863327, 0.22706472873687744, -0.3190031051635742, 0.21999719738960266, -0.14457562565803528, 0.3111416697502136, -0.040551505982875824, 0.377132773399353, 0.9588334560394287, -0.03542124852538109, -0.3188287019729614, 0.8572571277618408, 0.06975115835666656, -1.3289155960083008, 0.5676112771034241, -1.4046138525009155, -0.4917004406452179, -0.8841322660446167, 0.39709147810935974, -0.032974567264318466, -0.4457474648952484, 0.09536629170179367, -0.4596906900405884, 0.5127005577087402, 0.14182066917419434, -0.4200519025325775, 0.36816686391830444, 0.10424800217151642, -0.019811803475022316, 0.9918051958084106, 0.15042290091514587, -0.7792060375213623, -1.2036586999893188, -0.06436676532030106, -0.47876664996147156, 0.041174277663230896, 0.045922935009002686, -0.26795780658721924, -0.4220340847969055, 1.0286275148391724, 0.7195791006088257, -0.01691078394651413, -0.002049180679023266, -0.04128934070467949, -0.37193936109542847, 1.3247636556625366, 0.6928050518035889, -0.6778630018234253, -0.002325511071830988, 1.2987236976623535, 1.6573681831359863, -0.9830143451690674, 0.47455713152885437, -0.5866787433624268, -0.4276745617389679, 1.2120106220245361, 0.8164346218109131, -0.8082050085067749, 0.7082741260528564, -0.3116619884967804, -0.38965240120887756, 0.20037350058555603, -0.8481621742248535, -0.24760711193084717, 0.4216107130050659, 1.04231858253479, -0.031464774161577225, 0.1020461842417717, 0.6944879293441772, 0.808479368686676, 0.11453463137149811, 0.4008060395717621, 0.9534273743629456, 0.6753544211387634, -0.44291117787361145, 0.6356377601623535, 0.14911265671253204, 0.327168732881546, -0.46228089928627014, -0.06810548901557922, 0.20110955834388733, 0.8928513526916504, 0.4729098379611969, 0.731362521648407, 0.5062798261642456, -0.44605526328086853, 0.5538899302482605, -0.20047341287136078, 0.5874104499816895, -0.8626701235771179, -0.10053297132253647, -0.24949413537979126, -0.5006563067436218, -0.37616389989852905, -0.3138555884361267, -0.45087483525276184, -1.1640236377716064, 0.4792530834674835, -0.045625217258930206, -0.2027580589056015, 0.8115552663803101, 0.8575740456581116, 0.5207616686820984, 0.5964789390563965, -0.5959858894348145, -0.8561588525772095, -0.7317374348640442, -0.7945312261581421, 0.5344722867012024, -0.9128343462944031, 0.13101056218147278, -0.7993802428245544, -0.5136612057685852, -0.20208895206451416]}, "authors": [{"authorId": "1416657816", "name": "Roya Firoozi"}, {"authorId": "2273927013", "name": "Johnathan Tucker"}, {"authorId": "2264968694", "name": "Stephen Tian"}, {"authorId": "2237986850", "name": "Anirudha Majumdar"}, {"authorId": "2274075988", "name": "Jiankai Sun"}, {"authorId": "2266440298", "name": "Weiyu Liu"}, {"authorId": "2253507326", "name": "Yuke Zhu"}, {"authorId": "2254874914", "name": "Shuran Song"}, {"authorId": "2253595046", "name": "Ashish Kapoor"}, {"authorId": "1944801", "name": "Karol Hausman"}, {"authorId": "2704814", "name": "Brian Ichter"}, {"authorId": "2283848260", "name": "Danny Driess"}, {"authorId": "2266457554", "name": "Jiajun Wu"}, {"authorId": "2252024329", "name": "Cewu Lu"}, {"authorId": "2243338895", "name": "Mac Schwager"}], "references": [{"paperId": "8cf15664e0200c27900365e7b62e0f7377d3e96c", "title": "A Survey of Reasoning with Foundation Models"}, {"paperId": "337f421a364a6fa8ca423afd627bee2426f69395", "title": "Robot Learning in the Era of Foundation Models: A Survey"}, {"paperId": "2033c8d1a160814022501032137adac2ccb83495", "title": "Aria-NeRF: Multimodal Egocentric View Synthesis"}, {"paperId": "ad4beeecbdfc7dd238eb55e2b19113f62096d95b", "title": "Habitat 3.0: A Co-Habitat for Humans, Avatars and Robots"}, {"paperId": "b24a191abe87ac6cb159711a56d658c75c22ecec", "title": "Video Language Planning"}, {"paperId": "ef7d31137ef06c5be8c2824ecc5af6ce3358cc8f", "title": "Open X-Embodiment: Robotic Learning Datasets and RT-X Models"}, {"paperId": "98478ac589e5b40a20630ff54bb4eec4ab4c5f6b", "title": "GAIA-1: A Generative World Model for Autonomous Driving"}, {"paperId": "24837b98b550f82f59fc4e2716bcd525abdddcc7", "title": "Connected Autonomous Vehicle Motion Planning with Video Predictions from Smart, Self-Supervised Infrastructure"}, {"paperId": "2368d84435085af4cb680bcacf68a8c2fce721dc", "title": "The Safety Filter: A Unified View of Safety-Critical Control in Autonomous Systems"}, {"paperId": "38939304bb760473141c2aca0305e44fbe04e6e8", "title": "RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control"}, {"paperId": "67188a50e1d8a601896f1217451b99f646af4ac8", "title": "Towards A Unified Agent with Foundation Models"}, {"paperId": "1cd8373490efc2d74c2796f4b2aa27c7d4415ec9", "title": "VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models"}, {"paperId": "e418bddc14666671c4df6a9747f39f0f522a1bad", "title": "Large Language Models as General Pattern Machines"}, {"paperId": "d1500f1dbd62e26ef0753f31e845078f58479968", "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners"}, {"paperId": "03251361c1d67c6b5badffc7059fdd7fbfea1fed", "title": "Statler: State-Maintaining Language Models for Embodied Reasoning"}, {"paperId": "d77e806cd177a162fd20445ed6df566e08d58ced", "title": "ViNT: A Foundation Model for Visual Navigation"}, {"paperId": "fdaa21fce5ee5aadf1bb8c55d5f7c3155b905846", "title": "Faster Segment Anything: Towards Lightweight SAM for Mobile Applications"}, {"paperId": "8c88c693d5dc2802d3b76b85740e1f04fdaaf801", "title": "Large sequence models for sequential decision-making: a survey"}, {"paperId": "c01e94a36be5b3578fedb17205205b330290a778", "title": "Fast Segment Anything"}, {"paperId": "0aaee2b99ec6f659657658416e88ad7f4161ac7f", "title": "Mass-Producing Failures of Multimodal Systems with Language Models"}, {"paperId": "3b0c02955e88f5862e61b560c7f70ba8cf235b1d", "title": "HomeRobot: Open-Vocabulary Mobile Manipulation"}, {"paperId": "2562fe379554d201aad312f786903f4c60b68acf", "title": "RoboCat: A Self-Improving Generalist Agent for Robotic Manipulation"}, {"paperId": "b9a1189f2de7fd5e66551d7c425556e5642b823a", "title": "ChessGPT: Bridging Policy Learning and Language Modeling"}, {"paperId": "dc135dabef805c7271f53ec4b212bdf8996cfd9d", "title": "AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers"}, {"paperId": "1ed36ffa0555efa22542a0af26d04fb809dceb33", "title": "SAM3D: Zero-Shot 3D Object Detection via Segment Anything Model"}, {"paperId": "db9507cdd3e2d7d9c90ed185bd831e55c62dcec9", "title": "AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration"}, {"paperId": "f69f95835deec7748a688675721b6d581b60d42b", "title": "LIV: Language-Image Representations and Rewards for Robotic Control"}, {"paperId": "9bbfda47b615c29eb0c567808eabe498e036cc46", "title": "Quantifying Representation Reliability in Self-Supervised Learning Models"}, {"paperId": "3099d6f4965b4d73aa1e2b2880522ec89ed2dc0a", "title": "PaLI-X: On Scaling up a Multilingual Vision and Language Model"}, {"paperId": "d2bf230a0229a98066b47f8635ec0b45e26b86e1", "title": "How To Not Train Your Dragon: Training-free Embodied Object Goal Navigation with Semantic Frontiers"}, {"paperId": "c2c7ad3112c4b575e5d8163a0e574f9eb743cb52", "title": "Zero-shot Visual Question Answering with Language Model Feedback"}, {"paperId": "f197bf0fc2f228483f6af3285000d54d8d97f9eb", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models"}, {"paperId": "c695c4e68561347564ea0daa50dc339dff73d8c5", "title": "Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory"}, {"paperId": "00cb69a9f280317d1c59ac5827551ee9b10642b8", "title": "EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought"}, {"paperId": "459d791ea4bc20dc2789e43fffcfcaae452721da", "title": "You Only Look at One: Category-Level Object Representations for Pose Estimation From a Single Example"}, {"paperId": "692bc40edf4785d88c39e0c0fe9f270541fecf8a", "title": "Towards Generalist Robots: A Promising Paradigm via Generative Simulation"}, {"paperId": "4b203ee52e27cbf27d210dd671951150729a8259", "title": "ULIP-2: Towards Scalable Multimodal Pre-training for 3D Understanding"}, {"paperId": "72a2cff51bb9a87bbe4fc41325f5a4afc82a0366", "title": "NL2TL: Transforming Natural Languages to Temporal Logics using Large Language Models"}, {"paperId": "c0cf0971c153a84bbf0729d289b3b960969bb5dd", "title": "Track Anything: Segment Anything Meets Videos"}, {"paperId": "3720dd1ec6ca00e2e538c9d2a30dd00bf59a5d44", "title": "Anything-3D: Towards Single-view Anything Reconstruction in the Wild"}, {"paperId": "253b41369d003952874c6a47a6038277b165cfa0", "title": "Affordances from Human Videos as a Versatile Representation for Robotics"}, {"paperId": "5a9cb1b3dc4655218b3deeaf4a2417a9a8cd0891", "title": "DINOv2: Learning Robust Visual Features without Supervision"}, {"paperId": "6ff07b09cd44431603aeb1aab515a9f1355a63ed", "title": "L3MVN: Leveraging Large Language Models for Visual Target Navigation"}, {"paperId": "5278a8eb2ba2429d4029745caf4e661080073c81", "title": "Generative Agents: Interactive Simulacra of Human Behavior"}, {"paperId": "7470a1702c8c86e6f28d32cfa315381150102f5b", "title": "Segment Anything"}, {"paperId": "e1bd151a3f670fd0f77580702fe7a85dc78a41cb", "title": "Chain-of-Thought Predictive Control"}, {"paperId": "70da4fb798a86cbe8cad96c27ced0415885bbd9d", "title": "AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators"}, {"paperId": "23684a07517870cffd1f97fafbaae16ba22bd2b7", "title": "Large AI Models in Health Informatics: Applications, Challenges, and the Future"}, {"paperId": "8f2d4758e6d525509ae36bb30224dc9259027e6b", "title": "Text2Motion: from natural language instructions to feasible plans"}, {"paperId": "6aca520f9a226235062649eeb12928b51c69b90a", "title": "Affordance Diffusion: Synthesizing Hand-Object Interactions"}, {"paperId": "611e2100a3f8ed02b2583d4e53fd27a12d223b4c", "title": "LERF: Language Embedded Radiance Fields"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "93565fe6db3948c9c414af1d1edccf4aff5e2e10", "title": "Audio Visual Language Maps for Robot Navigation"}, {"paperId": "c3e5a20b844c042d2174263d2fd5b30d8cc8f0b0", "title": "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection"}, {"paperId": "2ebd5df74980a37370b0bcdf16deff958289c041", "title": "Foundation Models for Decision Making: Problems, Methods, and Opportunities"}, {"paperId": "38fe8f324d2162e63a967a9ac6648974fc4c66f3", "title": "PaLM-E: An Embodied Multimodal Language Model"}, {"paperId": "3608d756066d65ce4f7fa132e844dec37beb0fc6", "title": "Nerflets: Local Radiance Fields for Efficient Structure-Aware 3D Scene Representation from 2D Supervision"}, {"paperId": "9976672fd95dd1b7579117a01957f5a0c46e9d01", "title": "Open-World Object Manipulation using Pre-trained Vision-Language Models"}, {"paperId": "d318e0169f649656c71f02a1f84194a734fe1962", "title": "Reward Design with Language Models"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "a68db57f08f6d72c0d3b22d451d2606dca880f94", "title": "MimicPlay: Long-Horizon Imitation Learning by Watching Human Play"}, {"paperId": "3396609b96dd24cac3b1542aec686ce362f32fe2", "title": "Language-Driven Representation Learning for Robotics"}, {"paperId": "e701e4c02a32da186d25b08373ada12d83b73b3d", "title": "Scaling Robot Learning with Semantically Imagined Experience"}, {"paperId": "89e184d2bc830af568e439db9476caa0c047e11a", "title": "Guiding Pretraining in Reinforcement Learning with Large Language Models"}, {"paperId": "9a01fc428d195a9c5ea2005dc2943a650d59aa76", "title": "GenAug: Retargeting behaviors to unseen situations via Generative Augmentation"}, {"paperId": "61e721334296ebfbbf6443b5ed9eb8c83b708c95", "title": "Scaling Vision Transformers to 22 Billion Parameters"}, {"paperId": "102e4c860e39a2bfd7bf3f03b9ad69aac7bf3b5f", "title": "Collaborating with language models for embodied reasoning"}, {"paperId": "da2fe6cd385194b0274d04d04ee72e8caf3854d4", "title": "Learning Universal Policies via Text-Guided Video Generation"}, {"paperId": "abba9a6f99d877fdd1b8412ddfcc26fdac6163dc", "title": "SMART: Self-supervised Multi-task pretrAining with contRol Transformers"}, {"paperId": "bfe6fd05f09647b001c7eb6e333a95c881c88344", "title": "Human-Timescale Adaptation in an Open-Ended Task Space"}, {"paperId": "85cffa0fc2f15cf17814a5248ba53a228665d156", "title": "A System-Level View on Out-of-Distribution Data in Robotics"}, {"paperId": "f99dbe259144101efd79599ca8c072064ddbf031", "title": "Collision Avoidance Testing of the Waymo Automated Driving System"}, {"paperId": "713ceff7a052d2270340f474ec2a987bd1c61117", "title": "Policy Adaptation from Foundation Model Feedback"}, {"paperId": "fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d", "title": "RT-1: Robotics Transformer for Real-World Control at Scale"}, {"paperId": "f1c39410893794ee3643efa85be1816964aa85ea", "title": "Imagen Editor and EditBench: Advancing and Evaluating Text-Guided Image Inpainting"}, {"paperId": "9ffc8f7b3fbd5e609f609b1c20206129f22b4eb7", "title": "CACTI: A Framework for Scalable Multi-Task Multi-Scene Visual Imitation Learning"}, {"paperId": "18493a8c345cf6ca0a7f01a14afa0b9c72d1ff8f", "title": "PartSLIP: Low-Shot Part Segmentation for 3D Point Clouds via Pretrained Image-Language Models"}, {"paperId": "f403f84183be8660c1c7aa91c98cea74f39d3924", "title": "Navigating to objects in the real world"}, {"paperId": "cfca7eedc6ede9d363d1662280a74d78dcdc9d4a", "title": "Scaling Language-Image Pre-Training via Masking"}, {"paperId": "55dff8d4cdeab9c86dccb1c8b739ac0518cdbed0", "title": "Robotic Skill Acquisition via Instruction Augmentation with Vision-Language Models"}, {"paperId": "03d6484cbe5cc6e8c15c9271bfb29211671a6f56", "title": "StructDiffusion: Language-Guided Creation of Physically-Valid Structures using Unseen Objects"}, {"paperId": "c305ab1bdba79442bec72ec7f5c5ee7c49c2a566", "title": "Visual Language Maps for Robot Navigation"}, {"paperId": "9cf66efb5ddc0eef574f909fd4e1fa09994c0184", "title": "CLIP-Fields: Weakly Supervised Semantic Fields for Robotic Memory"}, {"paperId": "99832586d55f540f603637e458a292406a0ed75d", "title": "ReAct: Synergizing Reasoning and Acting in Language Models"}, {"paperId": "25425e299101b13ec2872417a14f961f4f8aa18e", "title": "VIMA: General Robot Manipulation with Multimodal Prompts"}, {"paperId": "979810ca765695a481c37126103b8ba256ee2192", "title": "Real-World Robot Learning with Masked Visual Pre-training"}, {"paperId": "1d26c947406173145a4665dd7ab255e03494ea28", "title": "GLM-130B: An Open Bilingual Pre-trained Model"}, {"paperId": "4fd4e392fb39124744bdfbb6d71ae2030be5132e", "title": "DALL-E-Bot: Introducing Web-Scale Diffusion Models to Robotics"}, {"paperId": "aa509ec67f311cd09d109356f7fa37a40072aabb", "title": "Phenaki: Variable Length Video Generation From Open Domain Textual Description"}, {"paperId": "8f84dcbad8cd3b5b4d9229c56bc95f24be859a35", "title": "Grounding Language with Visual Affordances over Unstructured Data"}, {"paperId": "3fbe2e8413df0207c26ff393c9aaa8488e3ca4c3", "title": "VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training"}, {"paperId": "893a01e62fb1cff5074de7354d4159bf70766815", "title": "NeRF-Loc: Transformer-Based Object Localization Within Neural Radiance Fields"}, {"paperId": "c03fa01fbb9c77fe3d10609ba5f1dee33a723867", "title": "ProgPrompt: Generating Situated Robot Task Plans using Large Language Models"}, {"paperId": "626d405aa05d96f8c1f27fa09e93b292084670b0", "title": "PACT: Perception-Action Causal Transformer for Autoregressive Robotics Pre-Training"}, {"paperId": "41531594d7e0f3b2e138ae43e0a0f6e24a9b014c", "title": "Code as Policies: Language Model Programs for Embodied Control"}, {"paperId": "28630034bb29760df01ab033b743e30b37f336ae", "title": "PaLI: A Jointly-Scaled Multilingual Language-Image Model"}, {"paperId": "60c8d0619481eaafdd1189af610d0e636271fed5", "title": "Perceiver-Actor: A Multi-Task Transformer for Robotic Manipulation"}, {"paperId": "5f5b855f58da599c2730120e55d8320fac867279", "title": "Leveraging Large Language Models for Robot 3D Scene Understanding"}, {"paperId": "bba58099a13b59f8272dc2c0129057670e252fa1", "title": "Neural Feature Fusion Fields: 3D Distillation of Self-Supervised 2D Image Representations"}, {"paperId": "17bcb1edbe068e8fe6a97da552c70a77a15bbce7", "title": "Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned"}, {"paperId": "97e6b89f8f256289b01b9f31799d957db81f2d4e", "title": "LATTE: LAnguage Trajectory TransformEr"}, {"paperId": "e5cc18a2764a1fa8dfc6073cd1c4433abf99fa39", "title": "Task-Relevant Failure Detection for Trajectory Predictors in Autonomous Vehicles"}, {"paperId": "d5c4550d285b57111e52c5956dbc40942d36b117", "title": "Semantic Abstraction: Open-World 3D Scene Understanding from 2D Vision-Language Models"}, {"paperId": "01724c36660359545e1368fc80c99f4bde44a190", "title": "XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model"}, {"paperId": "f3cf71c51b882fe3111d71c4bf104297d38197f8", "title": "Inner Monologue: Embodied Reasoning through Planning with Language Models"}, {"paperId": "cdf54c147434c83a4a380916b6c1279b0ca19fc2", "title": "LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action"}, {"paperId": "65fc1f1c567801fee3788974e753cdbf934f07e9", "title": "Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos"}, {"paperId": "32c9b3859086d15184989454eb878638659e64c6", "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge"}, {"paperId": "9dae204dad41633188022002a04c8aa67c79a4e1", "title": "Simple Open-Vocabulary Object Detection with Vision Transformers"}, {"paperId": "5922f437512158970c417f4413bface021df5f78", "title": "A Generalist Agent"}, {"paperId": "b21670e8061a06ab97e7d6052c9345a326e84ff8", "title": "UL2: Unifying Language Learning Paradigms"}, {"paperId": "c57293882b2561e1ba03017902df9fc2f289dea2", "title": "Hierarchical Text-Conditional Image Generation with CLIP Latents"}, {"paperId": "5dff8ba275384e6091dce0d16774e9ef2b2a04b9", "title": "Self-Supervised Traffic Advisors: Distributed, Multi-view Traffic Prediction for Smart Cities"}, {"paperId": "09dd56a2d32e55c824bc5dce693918b6068db938", "title": "Zero-Shot Category-Level Object Pose Estimation"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "cb5e3f085caefd1f3d5e08637ab55d39e61234fc", "title": "Do As I Can, Not As I Say: Grounding Language in Robotic Affordances"}, {"paperId": "ada81a4de88a6ce474df2e2446ad11fea480616e", "title": "Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language"}, {"paperId": "c9bdc9ad2c3cf3230ba9aac7b5783ab411f0d204", "title": "R3M: A Universal Visual Representation for Robot Manipulation"}, {"paperId": "742b195fb4c2868a4e60012c8e0bf7db43bb5650", "title": "CoWs on Pasture: Baselines and Benchmarks for Language-Driven Zero-Shot Object Navigation"}, {"paperId": "523acd658742fb9c978e3f7638c09d7ce78af719", "title": "Masked Visual Pre-training for Motor Control"}, {"paperId": "68de81265a2ef91f838b00a9bd39e2ab53cb63fb", "title": "COMPASS: Contrastive Multimodal Pretraining for Autonomous Systems"}, {"paperId": "1947bf44da309a3fc7bc50af0a6a09553d345c76", "title": "Failure Prediction with Statistical Guarantees for Vision-Based Robot Control"}, {"paperId": "5d49c7401c5f2337c4cc88d243ae39ed659afe64", "title": "Red Teaming Language Models with Language Models"}, {"paperId": "7610bcc3444c824a25f5c3779c097a9bdd4c185a", "title": "A Survey on Safety-Critical Driving Scenario Generation\u2014A Methodological Perspective"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "266cc7ff4856b6a2ce9cc0a3e5f6c155ecc448a2", "title": "Can Wikipedia Help Offline Reinforcement Learning?"}, {"paperId": "4d9c9d5e5afc3313bfbcf5e69e49ec32f4ec49d4", "title": "Sim-to-Lab-to-Real: Safe Reinforcement Learning with Shielding and Generalization Guarantees"}, {"paperId": "92a8f7f09f3705cb5a6009a42220a6f01ea084e8", "title": "Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents"}, {"paperId": "cc9826c222ac1e81b4b374dd9e0df130f298b1e8", "title": "Language-driven Semantic Segmentation"}, {"paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d", "title": "High-Resolution Image Synthesis with Latent Diffusion Models"}, {"paperId": "1111653b0ec18bc18bd53f30f9ce8176e3382fd1", "title": "Neural Descriptor Fields: SE(3)-Equivariant Object Representations for Manipulation"}, {"paperId": "0483be6c3ec6cd41ffe248f86effc7468d3ac7be", "title": "CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields"}, {"paperId": "5341b412383c43f4a693ad63ec4489e3ec7688c8", "title": "Grounded Language-Image Pre-training"}, {"paperId": "f3ce9ba3fcec362b70263a7ed63d9404975496a0", "title": "PointCLIP: Point Cloud Understanding by CLIP"}, {"paperId": "dd2819016c6bf244c39b3e6707b60389bbdbcd21", "title": "Point-BERT: Pre-training 3D Point Cloud Transformers with Masked Point Modeling"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "f675c62abfa788ea0be85d3124eba15a14d5e9d6", "title": "FILIP: Fine-grained Interactive Language-Image Pre-Training"}, {"paperId": "b7e7e14724dfbbaf6b8ad482aae98b7fcec5ccd9", "title": "Sample-Efficient Safety Assurances using Conformal Prediction"}, {"paperId": "69ee9b3a915951cc84b74599a3a2699a66d4004f", "title": "CLIPort: What and Where Pathways for Robotic Manipulation"}, {"paperId": "d6a1e9699d4e3571ab1eb74ab9eaba75095b809c", "title": "PlaTe: Visually-Grounded Planning With Transformers in Procedural Tasks"}, {"paperId": "20e6909ce6c5f12b61e5c9022d97134137360273", "title": "Learning Language-Conditioned Robot Behavior from Offline Data and Crowd-Sourced Annotation"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "aeae048c7d8d4ea03bb9cb1b75c65903c915909a", "title": "iGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday Household Tasks"}, {"paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "9f2e34581ca03160e8fd8b770203a5e7c2a902d3", "title": "RRL: Resnet as representation for Reinforcement Learning"}, {"paperId": "4aa88c1406414cda3ce9cf76c8af0abaa8391760", "title": "Habitat 2.0: Training Home Assistants to Rearrange their Habitat"}, {"paperId": "fda4530df9eec0e3f714dba3459ac50dab17d89c", "title": "Audioclip: Extending Clip to Image, Text and Audio"}, {"paperId": "2a805d0e1b067444a554c5169d189fa1f649f411", "title": "Scaling Vision Transformers"}, {"paperId": "ad4a0938c48e61b7827869e4ac3baffd0aefab35", "title": "Emerging Properties in Self-Supervised Vision Transformers"}, {"paperId": "be3e601b21630aea8b133354a56fb55f881a1fed", "title": "Adversarial Inverse Reinforcement Learning With Self-Attention Dynamics Model"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "3a906b77fa218adc171fecb28bb81c24c14dcc7b", "title": "Transformers in Vision: A Survey"}, {"paperId": "d40c77c010c8dbef6142903a02f2a73a85012d5d", "title": "A Survey on Vision Transformer"}, {"paperId": "82210f690823835f9c4b55e988bf773b4b53234d", "title": "Waymo's Safety Methodologies and Safety Readiness Determinations"}, {"paperId": "3e6a384a13e9e679759c30ab2e0f22fb0bdf7da2", "title": "Transporter Networks: Rearranging the Visual World for Robotic Manipulation"}, {"paperId": "19ee0064fd121b19bdcb19fd6f25f1d2759c7847", "title": "Detecting Rewards Deterioration in Episodic Reinforcement Learning"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "6dd9f99cecd38504b667d320eb2a6267a9fee35d", "title": "Contrastive Learning of Medical Visual Representations from Paired Images and Text"}, {"paperId": "5c126ae3421f05768d8edd97ecd44b1364e2c99a", "title": "Denoising Diffusion Probabilistic Models"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "1301e9d11b728268ed1ff3f1a9adc155308d5250", "title": "Language Conditioned Imitation Learning Over Unstructured Data"}, {"paperId": "d1ac487f21829ef56c8ffdcd37ea414bce68c809", "title": "Improving Vision-and-Language Navigation with Image-Text Pairs from the Web"}, {"paperId": "98789b46f7be983300a0e93e1c53bab56b36efd1", "title": "RoboTHOR: An Open Simulation-to-Real Embodied AI Platform"}, {"paperId": "34981c96dda64943625404cdb2deda296af75842", "title": "TartanAir: A Dataset to Push the Limits of Visual SLAM"}, {"paperId": "428b663772dba998f5dc6a24488fff1858a0899f", "title": "NeRF"}, {"paperId": "7af72a461ed7cda180e7eab878efd5f35d79bbf4", "title": "A Simple Framework for Contrastive Learning of Visual Representations"}, {"paperId": "ba39d83ec8b79f35d8195835f46cc4e36e5a4211", "title": "Real-time Out-of-distribution Detection in Learning-Enabled Cyber-Physical Systems"}, {"paperId": "c1db2556124e9bcb83d79f9d05786aba45b4995e", "title": "Learning a Decision Module by Imitating Driver's Control Behaviors"}, {"paperId": "3e519d85cdcefdd1d2ad89829d6ad445695d8c58", "title": "RoboNet: Large-Scale Multi-Robot Learning"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "965359b3008ab50dd04e171551220ec0e7f83aba", "title": "Generative Modeling by Estimating Gradients of the Data Distribution"}, {"paperId": "b4a35e548de27b6924e5f2ee41d37238a5c4a1d5", "title": "Habitat: A Platform for Embodied AI Research"}, {"paperId": "99a7df93a2e16bd7ac3349d52cc34417cda7909d", "title": "Learning Latent Plans from Play"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "b227f3e4c0dc96e5ac5426b85485a70f2175a205", "title": "Representation Learning with Contrastive Predictive Coding"}, {"paperId": "7139a5f730652abbeabf9e140009907d2c7da3e5", "title": "VirtualHome: Simulating Household Activities Via Programs"}, {"paperId": "e89a4fe6e8286eccedd702216153f0f248adb151", "title": "Gibson Env: Real-World Perception for Embodied Agents"}, {"paperId": "155b7782dbd713982a4133df3aee7adfd0b6b304", "title": "Unsupervised Feature Learning via Non-parametric Instance Discrimination"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "fc50c9392fd23b6c88915177c6ae904a498aacea", "title": "Scaling Egocentric Vision: The EPIC-KITCHENS Dataset"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "a62bdda9ae6f86fc06d7edf5d3b429eda3a6640e", "title": "SuperPoint: Self-Supervised Interest Point Detection and Description"}, {"paperId": "c37c23b12e00168833eccff8025a830ce27c5abc", "title": "Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments"}, {"paperId": "8337441971f941716a9e525a67f37088eb01fd13", "title": "Matterport3D: Learning from RGB-D Data in Indoor Environments"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91", "title": "Multimodal Machine Learning: A Survey and Taxonomy"}, {"paperId": "a20f3dfc9142b48b924e68ee22ba259a0d621bb2", "title": "AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "78a11b7d2d7e1b19d92d2afd51bd3624eca86c3c", "title": "Improved Deep Metric Learning with Multi-class N-pair Loss Objective"}, {"paperId": "954b01151ff13aef416d27adc60cd9a076753b1a", "title": "RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "9b686d76914befea66377ec79c1f9258d70ea7e3", "title": "ShapeNet: An Information-Rich 3D Model Repository"}, {"paperId": "f971a22287ead6aa23ecd84a4afd8efca57cee3c", "title": "NetVLAD: CNN Architecture for Weakly Supervised Place Recognition"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "2dcef55a07f8607a819c21fe84131ea269cc2e3c", "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"}, {"paperId": "88789ee88311acef28475ad33dbcd6b3c4be8358", "title": "Wikipedia"}, {"paperId": "128cb6b891aee1b5df099acb48e2efecfcff689f", "title": "The Winograd Schema Challenge"}, {"paperId": "d107231cce2676dbeea87e00bb0c587c280b9c53", "title": "Least-Squares Estimation of Transformation Parameters Between Two Point Patterns"}, {"paperId": "8dcaf96f66340c453e775ab217a1b1bd9ba63449", "title": "Time series analysis, forecasting and control"}, {"paperId": "7637ed79d30d0139901175ae4abedd822c217ab4", "title": "3D-LLM: Injecting the 3D World into Large Language Models"}, {"paperId": "f01b7d88743a0833bc101b8b7e13730dbf49de2b", "title": "Conformal Prediction for Uncertainty-Aware Planning with Diffusion Dynamics Model"}, {"paperId": "69764fcc646e4c608ac08eeb4c784cf8465268d2", "title": "BEHAVIOR-1K: A Benchmark for Embodied AI with 1, 000 Everyday Activities and Realistic Simulation"}, {"paperId": "08335bb56ee4e66a97c896a44f2ccf43f7ebe52e", "title": "Prompts and Pre-Trained Language Models for Offline Reinforcement Learning"}, {"paperId": "a09560239e398fe8aea05856823b46219a7dc539", "title": "Zero-Shot Reward Specification via Grounded Natural Language"}, {"paperId": "5755f5ed765dd6295f6780dc5b2e3a1d32a1aa1c", "title": "ULIP: Learning Unified Representation of Language, Image and Point Cloud for 3D Understanding"}, {"paperId": "00919831a34e783d185c3ff2c760b2cb0f0bff39", "title": "Quantifying Uncertainty in Foundation Models via Ensembles"}, {"paperId": "75a035b79f4aec38ad64ede8a18bd04efc28bd0c", "title": "Task-Driven Out-of-Distribution Detection with Statistical Guarantees for Robot Learning"}, {"paperId": null, "title": "Vision trans-formers for dense prediction"}, {"paperId": "e1746a4424d5f5765a04ed5e851314836fd0281d", "title": "Neuro-Symbolic Program Search for Autonomous Driving Decision Module Design"}, {"paperId": "98e7d51e99eeafa6f526940b222badf12e933d8f", "title": "The Transformer Model in Equations"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "0c0a778e6fdf7e36b1750c533dcc916f86608607", "title": "A Survey on Context Learning"}, {"paperId": "6021fed1f235de2d440b91c1ddc0c1da3d8a1357", "title": "Transforming Minecraft into a research platform"}, {"paperId": null, "title": "Adam Stooke, Anuj"}, {"paperId": null, "title": "principles and model abilities"}, {"paperId": null, "title": "Decom-posing NeRF for editing via feature \ufb01eld distillation"}, {"paperId": null, "title": "FeatureNeRF: Learning generalizable nerfs by distilling pre-trained vision foundation models"}, {"paperId": null, "title": "Distilled feature \ufb01elds enable few-shot manipulation"}, {"paperId": null, "title": "The gpt-3 architecture, on a napkin"}, {"paperId": null, "title": "MUTEX: Learning uni\ufb01ed policies from multimodal task speci\ufb01cations"}, {"paperId": null, "title": "Planning with diffusion for \ufb02exible behavior synthesis"}, {"paperId": null, "title": "CLIP 2 : Contrastive language-image-point pretraining from real-world point cloud data"}, {"paperId": null, "title": "Can of\ufb02ine reinforcement learning help natural language understanding?"}]}