{"paperId": "83b8108014e3db4f46354a28ae68193f143c4e7e", "title": "Structured Pruning of Large Language Models", "abstract": "Large language models have recently achieved state of the art performance across a wide variety of natural language tasks. Meanwhile, the size of these models and their latency have significantly increased, which makes their usage costly, and raises an interesting question: do language models need to be large? We study this question through the lens of model compression. We present a novel, structured pruning approach based on low rank factorization and augmented Lagrangian L0 norm regularization. Our structured approach achieves significant inference speedups while matching or outperforming our unstructured pruning baseline at various sparsity levels. We apply our method to state of the art models on the enwiki8 dataset and obtain a 1.19 perplexity score with just 5M parameters, vastly outperforming a model of the same size trained from scratch. We also demonstrate that our method can be applied to language model fine-tuning by pruning the BERT model on several downstream classification benchmarks.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2019, "citationCount": 225, "influentialCitationCount": 28, "openAccessPdf": {"url": "https://arxiv.org/pdf/1910.04732", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "A novel, structured pruning approach based on low rank factorization and augmented Lagrangian L0 norm regularization is presented, which achieves significant inference speedups while matching or outperforming the authors' unstructured pruning baseline at various sparsity levels."}, "embedding": {"model": "specter_v2", "vector": [0.014215025119483471, 0.7020261287689209, -0.4718853831291199, -0.0786551684141159, -0.26787567138671875, -0.11537371575832367, 0.6234105229377747, -0.5865553021430969, -0.6741454601287842, -0.1636459082365036, 0.8768811821937561, -0.02320263721048832, 0.10711577534675598, 0.2263500839471817, 0.007226765621453524, 0.3823204040527344, -0.7067078351974487, 0.4451044499874115, -0.329954594373703, -0.5589039921760559, -0.4107131361961365, -0.7274760007858276, -0.9141509532928467, -0.13274182379245758, 0.43550145626068115, 0.37299707531929016, 0.20436757802963257, 0.47847869992256165, -0.34452417492866516, 0.42840543389320374, 0.7294098138809204, -0.33216285705566406, 0.23316100239753723, 0.29378366470336914, -0.1080511063337326, -0.2524535059928894, 0.1289748251438141, -0.6591420769691467, -0.6581748127937317, 0.7193057537078857, -0.5469964146614075, 0.6036853790283203, 0.2515069246292114, -0.42294424772262573, -0.4058612883090973, 0.8281251192092896, 0.5615503787994385, 0.46130451560020447, -0.2147909253835678, -0.7040020823478699, 1.3817180395126343, -1.5672630071640015, 0.6969247460365295, 1.8225380182266235, 0.45644423365592957, 0.3749648332595825, -0.540708601474762, -0.7505237460136414, 0.8426949381828308, -0.0033921636641025543, -1.2209168672561646, -0.3520697355270386, -0.33160898089408875, 0.03811129182577133, 2.1676764488220215, -0.40068528056144714, -0.2764030992984772, 0.384146124124527, -0.196727454662323, 1.189402461051941, -0.22631023824214935, -0.5108050107955933, -0.3862791061401367, -0.03861738368868828, 0.4757978022098541, 0.961834192276001, -0.16684527695178986, 0.42605534195899963, -0.8914731740951538, -0.32694298028945923, -0.008800337091088295, 0.02791961282491684, 0.02165905199944973, 0.18455688655376434, 0.15762382745742798, 0.8544260263442993, 0.17285646498203278, 0.42618101835250854, 0.10913824290037155, 1.029486060142517, 0.545996904373169, 0.5550427436828613, 0.27136266231536865, 0.5584011077880859, -0.568824291229248, 0.38109874725341797, -1.004089117050171, 0.43553847074508667, 0.21151070296764374, 0.9334219098091125, -0.24385018646717072, 0.17693249881267548, -0.6488691568374634, 0.32631805539131165, 1.1911271810531616, -0.006015397142618895, 0.4570774734020233, -0.8022448420524597, 0.2549382746219635, -0.5263696312904358, -0.041888277977705, -0.6113627552986145, -0.30195152759552, -0.42821773886680603, -1.1501222848892212, -1.4930363893508911, -0.7076610922813416, 0.09559764713048935, -0.5932140350341797, 0.9929853677749634, -0.4190121591091156, 0.35598817467689514, -0.04467368498444557, 0.098554328083992, 0.6042234897613525, 0.8773492574691772, 0.22829569876194, 0.0014177996199578047, 0.9366568922996521, -1.026914358139038, -0.535402238368988, -1.0897090435028076, 1.1095064878463745, -0.2350599467754364, 0.08521819859743118, 0.1005641371011734, -1.077802300453186, -0.8030092120170593, -0.34968727827072144, -0.512883722782135, -0.5250083208084106, 0.652560293674469, 0.9949989318847656, 0.25381672382354736, -0.6907362937927246, 0.5822157859802246, -0.3433098793029785, 0.1751728057861328, 0.5258938670158386, 0.36286661028862, 0.0764644667506218, -0.605319619178772, -1.4235098361968994, 0.3628733456134796, 0.29558032751083374, -0.45751315355300903, -0.1910003423690796, -0.717864990234375, -1.16258704662323, 0.3404483199119568, 0.38286423683166504, -0.5066161751747131, 0.9820080995559692, 0.24385252594947815, -1.0430840253829956, 0.5354246497154236, -0.46418678760528564, -0.300580233335495, 0.2576262950897217, -0.4889143705368042, -0.39063507318496704, -0.5889860987663269, -0.47656992077827454, 0.43857401609420776, 0.5010627508163452, 0.060332462191581726, -0.12357994168996811, 0.47355860471725464, -0.1122184544801712, -0.3260137736797333, -0.2859402596950531, 1.1208633184432983, -0.5442959666252136, -0.40774109959602356, 0.3574012815952301, 0.4308348000049591, -0.27255213260650635, -0.1344837248325348, -0.17180034518241882, -1.1192325353622437, 0.7552757263183594, -0.39485248923301697, 1.2814651727676392, -0.9213700890541077, -0.474038302898407, 0.052460722625255585, 0.27679046988487244, 0.07640225440263748, -1.0053296089172363, 0.6300671100616455, -0.2734261155128479, 0.7741885185241699, 0.09168259799480438, -1.3369295597076416, 0.2436339110136032, -0.14391480386257172, -0.9665993452072144, -0.19740864634513855, -0.0057617980055511, 1.0417511463165283, -0.8368642926216125, 0.24539686739444733, -0.14710727334022522, 0.5062875747680664, -1.415593147277832, 0.8351247906684875, -0.6409657001495361, 0.020909016951918602, 0.02445949986577034, -0.24460899829864502, 0.1960311383008957, -0.31519466638565063, 0.5151026844978333, -0.2952432930469513, 0.008959591388702393, 0.6031476855278015, -0.5275583863258362, 1.1537638902664185, -0.6494481563568115, 0.49483126401901245, 0.10471726953983307, -0.39394769072532654, -0.05835409834980965, 0.15356776118278503, -0.20024976134300232, -0.30211955308914185, 0.20278723537921906, 0.20586833357810974, -0.6004529595375061, 0.34680378437042236, 0.6885740756988525, 0.6661453247070312, -0.2948736846446991, 0.3612464666366577, 0.5888164639472961, -0.1521458476781845, 0.9908518195152283, 0.7316155433654785, 0.7675724029541016, 0.49391698837280273, 0.3732699751853943, 0.19044972956180573, 0.540988028049469, -1.001168966293335, 0.2576560378074646, 0.5469726324081421, 1.076629400253296, 0.5333107709884644, 0.6407095789909363, -0.7253435254096985, -0.500137984752655, 0.20943650603294373, 0.6566025018692017, 1.6030067205429077, -0.5115339159965515, -0.7681878805160522, -0.23816940188407898, -0.10046294331550598, -0.20789770781993866, 0.0798468291759491, -0.12654432654380798, -0.11073670536279678, -0.7731227278709412, -1.1015090942382812, 0.879585325717926, 0.19813944399356842, 0.6992105841636658, 0.036187559366226196, 0.11977224051952362, -0.4988239109516144, 0.009453960694372654, -0.9172280430793762, -0.24420344829559326, 0.4311959743499756, -0.5907564163208008, 0.0534851998090744, 0.305119127035141, 0.043240971863269806, 0.26450657844543457, -0.6426541805267334, 1.1696373224258423, -0.3130813241004944, -0.40834730863571167, -0.05015585198998451, 0.33511608839035034, -0.4182923138141632, -0.6644747257232666, 0.3081319034099579, 0.40467432141304016, -0.45452263951301575, 0.27976492047309875, 0.5565704107284546, 0.29354432225227356, -0.09488493204116821, -0.41525787115097046, 0.24501363933086395, 0.04453249275684357, 0.33227285742759705, 0.7105492353439331, 0.12432882189750671, 0.0011983097065240145, -1.3909907341003418, 0.8372981548309326, 0.184792622923851, -0.8268671631813049, 0.3066234588623047, -0.6099653840065002, -0.224943146109581, 0.8079535961151123, -0.5347980260848999, -0.4729771316051483, -0.9366862773895264, 0.18995912373065948, -0.5983684062957764, 0.005059406161308289, 0.5050108432769775, 0.5528336763381958, 0.400132417678833, 0.20355544984340668, 0.2499573975801468, 0.33826571702957153, -0.5365153551101685, 0.7010858058929443, -0.8880303502082825, 0.21484723687171936, 0.363439679145813, 0.5803191661834717, -0.019945601001381874, 0.02996530383825302, -0.8893214464187622, -0.48310062289237976, -0.479505330324173, -0.2539706230163574, 0.20246478915214539, -0.15827804803848267, -0.9931969046592712, -0.32931646704673767, -0.474660724401474, -1.0941553115844727, -0.06668072193861008, 0.14444996416568756, -0.06529930233955383, 0.07244538515806198, -0.9854833483695984, -1.437140941619873, -0.7092499136924744, -0.614335298538208, -0.9063950181007385, 0.7520682215690613, -0.2742733061313629, -0.5876033306121826, -0.5069771409034729, -0.16750353574752808, -0.1512129008769989, 0.733334481716156, -0.7728411555290222, 0.984495222568512, -0.13056133687496185, -0.2537473440170288, -0.5259953141212463, -0.07698602974414825, 0.5797125101089478, -0.6917804479598999, 0.23416009545326233, -0.8183277249336243, 0.03915359079837799, -0.40783101320266724, -0.22499263286590576, 0.47409787774086, 0.28548839688301086, 0.6845808625221252, -0.030747825279831886, -0.7154807448387146, 0.6028244495391846, 1.3681368827819824, -1.1158835887908936, 0.0032248306088149548, -0.40215545892715454, 0.9890967607498169, 0.030501576140522957, -0.34498825669288635, 0.5125060677528381, -0.20725776255130768, 0.2535279095172882, 0.00374278100207448, -0.0009898273274302483, 0.028888294473290443, -0.6760733127593994, 0.4030171036720276, 1.6024235486984253, 0.3872191309928894, -0.060681626200675964, -0.9133338928222656, 0.35061684250831604, -1.1309071779251099, -0.9125775694847107, 0.5311000347137451, 0.7167242169380188, 0.36083984375, -0.4236004054546356, -0.5773018002510071, -0.3350706398487091, 0.21906155347824097, 0.2582968473434448, -0.2766115069389343, -0.5201509594917297, 0.0005872424226254225, 0.49230465292930603, 0.5025732517242432, 0.6969944834709167, -0.2895713448524475, 0.8497763276100159, 14.669894218444824, 1.2054778337478638, 0.16939234733581543, 0.8475898504257202, 0.8008772730827332, -0.2540254294872284, -0.2082514464855194, -0.05299331992864609, -1.6702460050582886, -0.28111597895622253, 1.0021748542785645, 0.1031709834933281, 0.9450754523277283, 0.14404089748859406, 0.5421710014343262, 0.14252273738384247, -0.41813719272613525, 0.7130141854286194, 0.36662858724594116, -1.236248254776001, 0.41037943959236145, 0.3066377341747284, 0.49750080704689026, 0.8824895024299622, 0.6071757674217224, 1.235634207725525, 0.3881717026233673, -0.8002111315727234, 0.07217840105295181, 0.36437803506851196, 0.9348432421684265, -0.02105490304529667, 0.3662710189819336, 0.9386248588562012, -0.8335935473442078, -0.6357336044311523, -0.7578650116920471, -1.3546556234359741, 0.44568932056427, 0.42507556080818176, -0.2724240720272064, -0.5330237150192261, -0.4184008240699768, 0.9638945460319519, -0.04658627510070801, 0.14592808485031128, -0.10699352622032166, 0.5940560102462769, -0.6544233560562134, 0.3028701841831207, 0.23803505301475525, 0.08619552105665207, 0.29421499371528625, -0.2170329988002777, -0.06585238128900528, -0.10527125746011734, 0.10716790705919266, 0.6934338212013245, -0.6916512846946716, -0.06475990265607834, -0.5031202435493469, -0.43393388390541077, -0.16649098694324493, 0.8040034174919128, 0.6425616145133972, 0.14481984078884125, -0.6523422002792358, 0.0035900999791920185, 0.7802800536155701, 0.26674240827560425, -0.5210373997688293, 0.3304854929447174, 0.29533740878105164, -0.3989274203777313, -0.2686811685562134, 0.41299769282341003, -0.029200607910752296, -1.0459614992141724, -0.7229197025299072, -0.3701013922691345, 0.28632327914237976, -0.6832350492477417, -0.7265470623970032, 0.5156493782997131, -0.10102017968893051, -0.38081714510917664, 0.07965846359729767, -0.7044498920440674, 0.2619572579860687, 0.520317018032074, -1.2182685136795044, -0.7770841717720032, 0.768830418586731, -0.6722879409790039, -0.10672332346439362, -0.08573763817548752, 1.2578872442245483, 0.48744136095046997, -0.49307453632354736, 0.0788918137550354, 0.44353440403938293, 0.0031927782110869884, -0.5453164577484131, -0.2201915681362152, 0.6640102863311768, 0.3590866029262543, -0.04061809927225113, 0.8387638926506042, -0.04309701547026634, 0.033888619393110275, -0.8244359493255615, -0.3527957499027252, 1.1663789749145508, -0.7642099857330322, -0.40242254734039307, -0.9698503613471985, -0.6133051514625549, 0.44899463653564453, 0.05000632256269455, -0.3356008231639862, 0.4400448799133301, 0.3010389506816864, -0.7293654680252075, 0.012404078617691994, -0.7027696371078491, 0.1707116663455963, 0.6470497846603394, -0.7962166666984558, -0.0881451964378357, 0.3662360608577728, 0.33891409635543823, -0.8356797099113464, -0.54454505443573, 0.04350685328245163, 0.1702195256948471, 0.32305341958999634, 1.0768392086029053, -0.5114056468009949, 0.953700840473175, 0.9695501923561096, -0.14814184606075287, -0.4628063440322876, -0.054318126291036606, -0.9974825978279114, -0.47038647532463074, -0.09008856117725372, 0.5781872272491455, -0.2775876224040985, 0.15101158618927002, 1.0858843326568604, 0.5526999235153198, -0.7027835845947266, -0.6126278638839722, -0.4378657042980194, 0.07693259418010712, -0.42946043610572815, 0.05646343529224396, -0.42739465832710266, -0.07623313367366791, 0.3134594261646271, 0.22174037992954254, 0.37923580408096313, -0.4534755051136017, -0.9067481160163879, 0.5325299501419067, -0.24168552458286285, -0.09039291739463806, -0.5181000828742981, -0.232574462890625, -1.719841718673706, 0.5687009692192078, -1.204342246055603, -0.2810055911540985, -0.8527088761329651, -0.5379015803337097, 0.28313329815864563, 0.2235162854194641, -0.07691469043493271, 0.6287636160850525, -0.17606137692928314, -0.3862631916999817, -0.4905993342399597, -0.4356740117073059, 0.8046192526817322, 0.620037317276001, -0.71416836977005, 0.10986142605543137, -0.1002773717045784, 0.24252519011497498, 0.6517369151115417, 0.27191346883773804, -0.35497426986694336, -1.0579320192337036, -1.4699302911758423, 0.892681896686554, -0.3222048282623291, -0.11801403760910034, -0.4176185727119446, 0.6019119024276733, 0.4997836947441101, -0.2133529633283615, 0.11116567254066467, 0.48026788234710693, -1.0656332969665527, -0.545461118221283, 0.39113155007362366, -0.9335768818855286, 0.1403910517692566, 0.15668563544750214, -0.29521581530570984, -0.362941175699234, 0.4997747540473938, 0.006870187819004059, -1.2401102781295776, -0.6037306189537048, 0.2935871183872223, -0.6502734422683716, 0.15537217259407043, -0.535735547542572, 0.19429746270179749, -0.9591580033302307, -0.5597797632217407, -0.19771654903888702, 0.5934420228004456, -0.7571361064910889, 0.830613911151886, 0.23295201361179352, -0.8399673700332642, 0.043558258563280106, 0.2805899977684021, -0.2555306851863861, 0.10529114305973053, 0.4007946848869324, 0.4862980544567108, -0.42980852723121643, 0.8121147751808167, 1.013443946838379, 0.6908606886863708, -1.1227164268493652, 0.2143862545490265, 0.7641828656196594, -0.7680349349975586, -0.4575888514518738, 1.151991605758667, -0.28706568479537964, -1.1422147750854492, 0.3396456837654114, -1.385116457939148, -0.3528381884098053, -0.23858247697353363, 0.6176444888114929, 0.3668326437473297, 0.02111712470650673, -0.13632136583328247, -0.29060596227645874, -0.013283457607030869, 0.05631515383720398, -0.4301837086677551, 0.7314693331718445, -0.501787006855011, -0.8459259867668152, 0.27565374970436096, 1.1969953775405884, -0.5863032937049866, -0.2120610475540161, -0.8011725544929504, -0.35736510157585144, -0.21541178226470947, 0.4735030233860016, -0.30362391471862793, -0.47028350830078125, 0.3806114196777344, 0.08029914647340775, 0.05015626549720764, 0.190738707780838, -0.37271106243133545, 0.24306757748126984, 1.1303956508636475, 0.15509477257728577, -0.8896980881690979, -0.9988387823104858, 1.809240460395813, 1.30207359790802, -0.8927909135818481, 0.7045623064041138, -0.4806878864765167, -0.4507535994052887, 0.502781331539154, 0.126752108335495, -0.35463884472846985, 1.3085906505584717, 0.0561918243765831, -0.32153788208961487, 0.1950177252292633, -1.3449151515960693, -0.25681039690971375, 0.8076789975166321, 0.47878798842430115, 1.0615814924240112, -0.12216547131538391, -0.394406259059906, 0.9953696727752686, 0.10941369086503983, 0.24653959274291992, 0.11370499432086945, 0.07615955919027328, 0.10147363692522049, 0.03799203038215637, 0.1877988874912262, 0.8816966414451599, -0.7139620780944824, -0.9021950960159302, 0.08444487303495407, 0.5624783635139465, 0.42596912384033203, 0.6155418157577515, 0.5619803071022034, 0.1287178248167038, 0.17854565382003784, 0.3826102018356323, 0.220617413520813, -0.6732795834541321, -0.32662123441696167, 0.1684352457523346, -0.4082619547843933, 0.014937229454517365, 0.11107613146305084, -0.27339786291122437, -0.31164196133613586, -0.26861104369163513, 0.15586039423942566, -0.3040121793746948, 0.0332946740090847, 1.2960094213485718, 0.5913888216018677, 0.34003087878227234, -0.598992645740509, -0.3462146818637848, -0.4754222333431244, -0.8892601728439331, -0.0887736827135086, -0.37834545969963074, -0.37382593750953674, -0.20671406388282776, -0.24101488292217255, -0.30418989062309265]}, "authors": [{"authorId": "2860279", "name": "Ziheng Wang"}, {"authorId": "39749986", "name": "Jeremy Wohlwend"}, {"authorId": "49986267", "name": "Tao Lei"}], "references": [{"paperId": "b14c9c65b43ad61eeab71ec73ba947d727d08db1", "title": "Neural Network Distiller: A Python Package For DNN Compression Research"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "3d109085f37405370a765dea876fd654e5ea3a1c", "title": "Optimizing Speech Recognition For The Edge"}, {"paperId": "f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1", "title": "Reducing Transformer Depth on Demand with Structured Dropout"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d", "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"}, {"paperId": "0fc85e11928eb15d3c3a2fa737490ffc7b3986e2", "title": "Transformer to CNN: Label-scarce distillation for efficient text classification"}, {"paperId": "2f9d4887d0022400fc40c774c4c78350c3bc5390", "title": "Small and Practical BERT Models for Sequence Labeling"}, {"paperId": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf", "title": "Patient Knowledge Distillation for BERT Model Compression"}, {"paperId": "93ad19fbc85360043988fa9ea7932b7fdf1fa948", "title": "Well-Read Students Learn Better: The Impact of Student Initialization on Knowledge Distillation"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "64ffb253d20ee12114a8d15d01404bd17ae99220", "title": "Interpretable Neural Predictions with Differentiable Binary Variables"}, {"paperId": "5f994dc8cae24ca9d1ed629e517fcc652660ddde", "title": "ERNIE: Enhanced Language Representation with Informative Entities"}, {"paperId": "26384278cf5d575fc32cb92c303fb648fa0d5217", "title": "The State of Sparsity in Deep Neural Networks"}, {"paperId": "0c325138b1ecb7a8ccbd5d6741780dea9461e7ae", "title": "Efficient and Effective Sparse LSTM on FPGA with Bank-Balanced Sparsity"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "71010dbca09469fd64b77daf881f62538d41d73e", "title": "West: Word Encoded Sequence Transducers"}, {"paperId": "9dad5f3b491fba9496c90bb7cfe10d1c0f00fadc", "title": "Balanced Sparsity for Efficient DNN Inference on GPU"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "d393943a873ead524069d0f7f55acef05cc9ba45", "title": "Efficient Contextualized Representation: Language Model Pruning for Sequence Labeling"}, {"paperId": "680aafd3d51e666b297e27b93d9554cc2caf1c4d", "title": "An Analysis of Neural Language Modeling at Multiple Scales"}, {"paperId": "21937ecd9d66567184b83eca3d3e09eb4e6fbd60", "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "1717255b6aea01fe956cef998abbc3c399b5d7cf", "title": "AMC: AutoML for Model Compression and Acceleration on Mobile Devices"}, {"paperId": "2ec7156913117949ab933f27f492d0149bc0031f", "title": "Learning Sparse Neural Networks through L0 Regularization"}, {"paperId": "efbac99adf8628aae7f070e5b4388a295956f9d2", "title": "CondenseNet: An Efficient DenseNet Using Learned Group Convolutions"}, {"paperId": "56257b0804c9c2418b32337d3af0970f7b67b084", "title": "Block-Sparse Recurrent Neural Networks"}, {"paperId": "bdf5e611c842ca6cd93bb342afb82bed85fb8aa6", "title": "Slim Embedding Layers for Recurrent Neural Language Models"}, {"paperId": "b36a5bb1707bb9c70025294b3a310138aae8327a", "title": "Automatic differentiation in PyTorch"}, {"paperId": "c2e1139691c3a337831e36ee7afeab8817ab5d48", "title": "The tensor algebra compiler"}, {"paperId": "3b4d671a8c7018c0b42673ba581e5ff3ae762d6c", "title": "To prune, or not to prune: exploring the efficacy of pruning for model compression"}, {"paperId": "ca1060c50642f9f05735d3007873439347b3bea5", "title": "Learning Intrinsic Sparse Structures within Long Short-term Memory"}, {"paperId": "7ba9b6266569bd7b6a3c2ec64348c5b969a5ceb7", "title": "Simple Recurrent Units for Highly Parallelizable Recurrence"}, {"paperId": "a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096", "title": "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation"}, {"paperId": "2397ce306e5d7f3d0492276e357fb1833536b5d8", "title": "On the State of the Art of Evaluation in Neural Language Models"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "9302e07c4951559ad9a538295029881a171faeec", "title": "Bayesian Compression for Deep Learning"}, {"paperId": "1cc2f313bcb3b106af081f7031b924c9ad2662bd", "title": "Exploring Sparsity in Recurrent Neural Networks"}, {"paperId": "34cc3ceae5c3f7c8acbb89f2bff63f9d452b00d5", "title": "Variational Dropout Sparsifies Deep Neural Networks"}, {"paperId": "d418295cd3027c43eccc5592ae5b8303ba8192be", "title": "Trained Ternary Quantization"}, {"paperId": "9ec499af9b85f30bdbdd6cdfbb07d484808c526a", "title": "Efficient softmax approximation for GPUs"}, {"paperId": "136cf66392f1d6bf42da4cc070888996dc472b91", "title": "On Multiplicative Integration with Recurrent Neural Networks"}, {"paperId": "230579a14d54ae00073d6c3522ffcef313320be9", "title": "Compression of Neural Machine Translation Models via Pruning"}, {"paperId": "2e2b189f668cf2c06ebc44dc9b166648256cf457", "title": "EIE: Efficient Inference Engine on Compressed Deep Neural Network"}, {"paperId": "4aa9f5150b46320f534de4747a2dd0cd7f3fe292", "title": "Semi-supervised Sequence Learning"}, {"paperId": "642d0f49b7826adcf986616f4af77e736229990f", "title": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"}, {"paperId": "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff", "title": "Learning both Weights and Connections for Efficient Neural Network"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "e7bf9803705f2eb608db1e59e5c7636a3f171916", "title": "Compressing Deep Convolutional Networks using Vector Quantization"}, {"paperId": "33a9d1a702eb75da709d26c44aaeb7c2015c870b", "title": "A Discriminative Graph-Based Parser for the Abstract Meaning Representation"}, {"paperId": "d770060812fb646b3846a7d398a3066145b5e3c8", "title": "Do Deep Nets Really Need to be Deep?"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "121008ab27e8bf13566311910274fd79d73ca940", "title": "An Augmented Lagrangian Approach to Constrained MAP Inference"}, {"paperId": "0409ab66f7604b07109019f93256756d630d3bc2", "title": "On Dual Decomposition and Linear Programming Relaxations for Natural Language Processing"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "a07609c2ed39d049d3e59b61408fb600c6ab0950", "title": "GPU Kernels for Block-Sparse Weights"}, {"paperId": null, "title": "Sequencelevel knowledge distillation"}, {"paperId": "475354f10798f110d34792b6d88f31d6d5cb099e", "title": "Automatically Constructing a Corpus of Sentential Paraphrases"}]}