{"paperId": "1ea09be3944b6c9054a76e46101f91dd787b36ce", "title": "Zero-TPrune: Zero-Shot Token Pruning through Leveraging of the Attention Graph in Pre-Trained Transformers", "abstract": "Deployment of Transformer models on edge devices is becoming increasingly challenging due to the exponentially growing inference cost that scales quadratically with the number of tokens in the input sequence. Token pruning is an emerging solution to address this challenge due to its ease of deployment on various Transformer backbones. However, most token pruning methods require computationally expensive fine-tuning, which is undesirable in many edge deployment cases. In this work, we propose Zero-TPrune, the first zero-shot method that considers both the importance and similarity of tokens in performing token pruning. It leverages the attention graph of pre-trained Transformer models to produce an importance distribution for tokens via our proposed Weighted Page Rank (WPR) algorithm. This distribution further guides token partitioning for efficient similarity-based pruning. Due to the elimination of the fine-tuning overhead, Zero-TPrune can prune large models at negligible computational cost, switch between different pruning configurations at no computational cost, and perform hyperparameter tuning efficiently. We evaluate the performance of Zero-TPrune on vision tasks by applying it to various vision Transformer backbones and testing them on ImageNet. Without any fine-tuning, Zero-TPrune reduces the FLOPs cost of DeiT-S by 34.7% and improves its throughput by 45.3% with only 0.4% accuracy loss. Compared with state-of-the-art pruning methods that require fine-tuning, Zero-TPrune not only eliminates the need for fine-tuning after pruning but also does so with only 0.1% accuracy loss. Compared with state-of-the-art fine-tuning-free pruning methods, Zero-TPrune reduces accuracy loss by up to 49% with similar FLOPs budgets. Project webpage: https://jha-lab.github.io/zerotprune.", "venue": "arXiv.org", "year": 2023, "citationCount": 7, "influentialCitationCount": 1, "openAccessPdf": {"url": "http://arxiv.org/pdf/2305.17328", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes Zero-TPrune, the first zero-shot method that considers both the importance and similarity of tokens in performing token pruning, which can prune large models at negligible computational cost, switch between different pruning configurations at no computational cost, and perform hyperparameter tuning efficiently."}, "embedding": {"model": "specter_v2", "vector": [0.18906278908252716, 0.5533896088600159, -0.6784230470657349, 0.5106558203697205, -0.06754633039236069, 0.17341843247413635, 0.699285089969635, -0.4143275320529938, -0.5401949286460876, -0.6301427483558655, 0.27037444710731506, 0.33408990502357483, 0.24027808010578156, -0.15085415542125702, -0.10247769951820374, 0.3458992838859558, -0.4964871406555176, 0.3935419023036957, 0.5966758728027344, -0.33075645565986633, 0.2271333634853363, -0.8605485558509827, -1.5935194492340088, 0.014382610097527504, 0.40713629126548767, 1.0276683568954468, 5.170891745365225e-05, 0.5392931699752808, -0.4243480861186981, 0.6840903759002686, 0.47711050510406494, -0.5824159979820251, 0.4556076228618622, 0.24297617375850677, -0.3828141987323761, -0.004218354355543852, 0.6437251567840576, -0.5889690518379211, -0.7130497694015503, 1.0442585945129395, -0.1259169578552246, 0.35683202743530273, 0.24127869307994843, -0.9007712602615356, -0.3297605812549591, 0.7702358961105347, 0.5873669981956482, 0.4823135435581207, -0.7571250796318054, -0.5817779898643494, 1.3686400651931763, -1.561546802520752, 0.533745288848877, 1.1414159536361694, 0.6399155855178833, 0.3007274568080902, 0.10864077508449554, -0.46559008955955505, 0.8899586796760559, 0.810941755771637, -0.6397292017936707, -0.6811292171478271, 0.051722679287195206, -0.09193463623523712, 2.0180881023406982, -0.6648002862930298, 0.34067919850349426, 0.4511905014514923, -0.05676303431391716, 1.4606622457504272, -0.4396919906139374, -0.7269370555877686, -0.1937893033027649, -0.2749409079551697, 0.402033269405365, 1.1623339653015137, -0.36813589930534363, 0.2441893368959427, -1.0494391918182373, 0.03302059322595596, 0.25099483132362366, 0.19405852258205414, 0.7119928598403931, -0.2213892638683319, 0.31762072443962097, 0.451109915971756, 0.23570466041564941, 0.5575376749038696, -0.392799437046051, 1.0305917263031006, 0.8750263452529907, 0.08166339248418808, 0.03587833419442177, -0.0029238134156912565, 0.19409553706645966, 0.44560372829437256, -0.9361358880996704, 0.126370370388031, -0.21957111358642578, 1.0355019569396973, -0.22188234329223633, 0.4324962794780731, -1.1287412643432617, 0.37002235651016235, 0.8551645278930664, -0.30395397543907166, 0.23439693450927734, -0.9768552184104919, -0.1781574785709381, -0.7367842793464661, 0.17244590818881989, -0.4604186713695526, 0.3230910003185272, -0.167230486869812, -0.8601791858673096, -0.8138844966888428, -0.43628957867622375, 0.6830019354820251, -1.330566644668579, 0.43820908665657043, -0.4131714701652527, 0.8230970501899719, -0.42851194739341736, 0.2538982927799225, 0.8997696042060852, 0.0008263548952527344, 0.5279896259307861, 0.4641542136669159, 1.250091314315796, -1.2498060464859009, -0.2117524892091751, -1.0481973886489868, 0.25979557633399963, -0.38040316104888916, 0.2113495022058487, 0.1049039214849472, -1.346472144126892, -0.9944391250610352, -0.6110475063323975, -0.13944467902183533, -0.6570338606834412, 0.2572048306465149, 0.7775338888168335, 0.13218966126441956, -0.856580376625061, 0.9265360832214355, -0.24074997007846832, -0.09963946789503098, 0.7908767461776733, 0.1883576512336731, 0.42083945870399475, -0.46074575185775757, -1.413819670677185, 0.566565215587616, -0.20825329422950745, -0.4362350404262543, -0.5319375395774841, -0.5915711522102356, -1.0688287019729614, 0.2601826786994934, 0.74665766954422, -0.6368678212165833, 1.2967709302902222, -0.04722007364034653, -1.10000479221344, 0.810485303401947, -0.3430067002773285, -0.05527069419622421, 0.5593887567520142, -0.3507661819458008, -0.2745009660720825, -0.32588136196136475, 0.043985795229673386, 0.578844428062439, 1.084763526916504, 0.09186077862977982, -0.3186996579170227, 0.5033731460571289, -0.3136087954044342, -0.3840540647506714, -0.19630324840545654, 0.8359271883964539, -0.8174734115600586, -0.08358823508024216, 0.3875619173049927, 0.725883960723877, -0.10748708248138428, -0.3545982539653778, -0.4312954545021057, -1.2570960521697998, 0.563859760761261, 0.19500426948070526, 0.6035101413726807, -0.6493551135063171, -1.0433017015457153, -0.1669713407754898, 0.33585524559020996, 0.0873485580086708, -0.759830117225647, 0.3221471905708313, -0.13107898831367493, 0.5176892876625061, 0.5468296408653259, -1.0826613903045654, 0.3950512409210205, -0.5446578860282898, -0.7822629809379578, -0.29839542508125305, -0.06875040382146835, 1.2863199710845947, -1.073891043663025, -0.1960231363773346, 0.4288298785686493, 0.5043780207633972, -1.0023406744003296, 0.48114481568336487, -0.48545217514038086, -0.4054771959781647, -0.2073180228471756, 0.04179326072335243, -0.09857819974422455, -0.27595803141593933, 0.27912524342536926, -0.5108039975166321, -0.1311420053243637, 0.6623450517654419, -0.2246391475200653, 1.1379719972610474, -0.2881665527820587, 0.5010319352149963, -0.4090006649494171, -0.5977755188941956, 0.24509897828102112, 0.4273730516433716, 0.12741361558437347, -0.7467767596244812, 0.43352147936820984, 0.2376265525817871, -0.8105341196060181, 0.4699680209159851, 1.1453992128372192, 1.164832353591919, -0.40844231843948364, -0.19571144878864288, 0.5817056894302368, 0.16928192973136902, 0.6058734655380249, 0.43855053186416626, 0.9663456678390503, 0.610684335231781, 0.05522112548351288, 0.026164023205637932, -0.05094379559159279, -0.6414598226547241, 0.40430089831352234, 1.0566784143447876, 0.40001606941223145, 0.6661840677261353, 0.49569499492645264, -1.0096783638000488, -0.6082621216773987, 0.20312274992465973, 0.7508143186569214, 1.4986960887908936, 0.2504200339317322, -0.5046217441558838, -0.8233482241630554, -0.42604464292526245, -0.5062916278839111, -0.07121177762746811, -0.24445582926273346, -0.28186604380607605, -0.28150033950805664, -0.6609131693840027, 0.8375503420829773, 0.12423079460859299, 1.3666810989379883, -0.9206117987632751, -0.5473042130470276, -0.19765403866767883, -0.04391001909971237, -0.97238689661026, -0.26916658878326416, 0.14093288779258728, -0.13891223073005676, -0.16061638295650482, 0.13851487636566162, -0.14903497695922852, 0.15975220501422882, -0.4902714192867279, 1.330883502960205, -0.3041180372238159, -0.8069217205047607, 0.14724788069725037, 0.28639766573905945, -0.4750242531299591, -0.12159565091133118, 0.29934003949165344, 0.048312459141016006, -0.5111969709396362, 0.5968982577323914, 0.3767593204975128, -0.3287702202796936, 0.18447066843509674, -0.10469299554824829, 0.0009216245380230248, 0.1001066043972969, 0.045645974576473236, 1.0413185358047485, -0.12177443504333496, 0.12339471280574799, -0.9725672602653503, 0.6753513813018799, 0.2963399887084961, -0.5821080207824707, 0.31787601113319397, -0.6838221549987793, -0.5367391109466553, 0.5579758286476135, -0.6927439570426941, -0.06426002085208893, -0.9196946024894714, 0.4695464074611664, -1.0857892036437988, 0.026181362569332123, -0.32089415192604065, 0.38118839263916016, 0.20139180123806, 0.3113722801208496, 0.42730003595352173, -0.3587619364261627, 0.004784776829183102, 0.7357724905014038, -1.1735166311264038, 0.7150070071220398, 0.16654519736766815, -0.12548543512821198, 0.07464191317558289, -0.037339694797992706, -0.8974524736404419, -0.4315566420555115, -0.5042860507965088, 0.03792422637343407, -0.6297192573547363, 0.10353831201791763, -0.5052546262741089, -0.9713157415390015, 0.2324778139591217, -0.9676426649093628, -0.28722506761550903, -0.1939878761768341, -0.4429217278957367, -0.38227784633636475, -0.9896721839904785, -1.0554219484329224, -0.5661119818687439, -0.842881977558136, -0.9771493077278137, 0.32113009691238403, 0.03293333575129509, -0.3354439437389374, -0.12137023359537125, -0.279817134141922, -0.5980908870697021, 0.7938225269317627, -0.5329108238220215, 0.512942910194397, -0.21107377111911774, -0.7042606472969055, -0.3348790109157562, -0.01410844549536705, 0.41173917055130005, -0.5161707997322083, 0.2643772065639496, -1.0001945495605469, 0.4131228029727936, -0.4934459924697876, -0.23851704597473145, 0.7362097501754761, 0.7540667653083801, 0.8308737874031067, 0.16256928443908691, -0.5342687964439392, 0.20827314257621765, 1.371746301651001, -0.6666664481163025, 0.5546262860298157, 0.32776302099227905, 0.9111007452011108, -0.08264195173978806, -0.0044699301943182945, 0.6953445672988892, 0.23572216928005219, 0.16704125702381134, 0.4301983118057251, -0.3853796720504761, -0.37432006001472473, -0.6835672855377197, 0.408056378364563, 1.0167254209518433, 0.24953703582286835, -0.05545127019286156, -0.7716988921165466, 1.159478783607483, -1.5931998491287231, -1.0961281061172485, 0.693143367767334, 0.8273405432701111, -0.35270777344703674, -0.05223102867603302, -0.15010800957679749, -0.38385558128356934, 0.931131899356842, 0.377517968416214, -0.6186962723731995, -0.7201777696609497, 0.3277606666088104, 0.7694041132926941, 0.6271793246269226, 0.468436598777771, -0.3608796000480652, 1.232602596282959, 14.754496574401855, 1.2842704057693481, 0.046454574912786484, 0.43947833776474, 0.7279936671257019, 0.27636170387268066, -0.2213466614484787, 0.2756478488445282, -1.371305227279663, -0.1789928823709488, 0.6671164035797119, -0.08925951272249222, 0.5592114925384521, 0.4430706202983856, -0.020326152443885803, 0.010167710483074188, -0.49174126982688904, 0.4512083828449249, 0.46215975284576416, -1.1659468412399292, 0.34754619002342224, -0.04224134981632233, 0.23975925147533417, 0.8337216377258301, 0.9252713322639465, 0.9737529158592224, 0.8055857419967651, -0.3973938226699829, 0.5823811888694763, 0.48187100887298584, 1.07660973072052, -0.16249704360961914, 0.2247351109981537, 0.3108607232570648, -1.0434454679489136, 0.05240340903401375, -0.9910220503807068, -1.0080536603927612, 0.10048189759254456, 0.33192500472068787, -0.5713393092155457, -0.38816067576408386, 0.1351439207792282, 0.8017542362213135, 0.31384897232055664, 0.5117276906967163, -0.32111772894859314, 0.24829508364200592, -0.30607670545578003, 0.4621153771877289, 0.35653024911880493, 0.3016504943370819, 0.24793224036693573, -0.23791556060314178, 0.12744887173175812, -0.08917421847581863, 0.3798578977584839, 0.3867708742618561, -0.7407629489898682, -0.4552953243255615, -0.5806516408920288, -0.02784203551709652, 0.07054115831851959, 1.0530743598937988, -0.07453484833240509, -0.055474258959293365, -0.1997259557247162, 0.2787775993347168, 0.37871208786964417, -0.03070114366710186, -0.7732857465744019, -0.24275130033493042, 0.3232841491699219, -0.47830960154533386, 0.3252973258495331, 1.0425621271133423, -0.060623738914728165, -0.5909979343414307, -0.733110249042511, -0.14283134043216705, 0.296218603849411, -0.7471887469291687, -0.46133944392204285, 0.8727250695228577, -0.37494078278541565, -0.4541524350643158, -0.00015609373804181814, -0.46549391746520996, -0.408340722322464, 0.15173007547855377, -1.4715471267700195, -1.0013065338134766, 0.21522442996501923, -0.3434998095035553, -0.0021050935611128807, 0.012703495100140572, 0.9331176280975342, 0.40863072872161865, -0.11925499141216278, 0.19297635555267334, -0.05820026248693466, 0.04846201092004776, -0.2606551945209503, -0.4100634753704071, 1.1766254901885986, 0.28394845128059387, 0.012006636708974838, 0.015777738764882088, 0.14125138521194458, 0.09212243556976318, -0.15191762149333954, -0.2719975411891937, 0.7555805444717407, -0.8075359463691711, -0.6136085987091064, -0.6550693511962891, -0.5660836100578308, 0.6110894083976746, 0.45616915822029114, 0.09684314578771591, -0.17672868072986603, 0.36232680082321167, -0.5523048639297485, 0.03944392502307892, -0.8475782871246338, 0.3544568717479706, 0.8463776111602783, -0.7877703905105591, -0.22652693092823029, -0.2766803205013275, -0.024894436821341515, -0.8089396953582764, -0.319999635219574, -0.03216889128088951, 0.5441093444824219, -0.48613792657852173, 1.240267276763916, -0.3131875991821289, 0.9421929121017456, 0.9912593960762024, 0.2944222688674927, -0.7302472591400146, -0.11324041336774826, -0.9768984317779541, 0.07183755934238434, 0.202771857380867, 0.23971420526504517, -0.2950592041015625, 0.5653233528137207, 0.8538451790809631, 0.27911585569381714, -0.4361955225467682, -0.5055234432220459, -0.5879887342453003, -0.03716889023780823, -0.5598931908607483, 0.3206765055656433, -0.1913042813539505, 0.02433488890528679, 0.12270753085613251, 0.24154876172542572, 0.11933965981006622, 0.2081427276134491, -0.8247196674346924, 0.23592925071716309, -0.22562360763549805, 0.21898779273033142, -0.6438587307929993, -0.5491000413894653, -1.217556118965149, 0.16265743970870972, -1.044295072555542, 0.07072288542985916, -1.2171132564544678, -0.4148549735546112, 0.07444324344396591, -0.5372753143310547, 0.19619347155094147, 0.6812825202941895, -0.06953617185354233, -0.330069363117218, -0.671942949295044, -0.9980043768882751, 0.648523211479187, 0.787295937538147, -0.9143639206886292, 0.1104825884103775, -0.1131739392876625, 0.05248294770717621, 0.8280057907104492, 0.42718759179115295, -0.7296220660209656, -0.7826893329620361, -1.2361900806427002, 0.3970598876476288, -0.27584823966026306, 0.10479128360748291, -0.8048000931739807, 1.056748628616333, 0.6401827931404114, -0.2146276831626892, -0.22335340082645416, 0.34498339891433716, -0.759589672088623, -0.5601465106010437, 0.3351423442363739, -0.48665180802345276, -0.043736036866903305, 0.1841154843568802, -0.6698843240737915, -0.04463357850909233, 0.5806812644004822, 0.11142738163471222, -1.2518014907836914, -1.2962309122085571, 0.6880829930305481, -0.5771853923797607, 0.1927255392074585, -0.4462052881717682, -0.45265114307403564, -1.283516526222229, -0.36136722564697266, -0.2766350209712982, 0.4491738975048065, -0.5100882649421692, 1.0304207801818848, 0.6665616035461426, -1.2038118839263916, 0.04056166857481003, 0.19851702451705933, -0.13681113719940186, -0.04538809880614281, 0.5991589426994324, 0.4857510030269623, 0.00021648597612511367, 0.1931648999452591, -0.10094235092401505, 0.48430943489074707, -0.887692391872406, 0.1121472716331482, 0.8541871905326843, -0.7120576500892639, -0.5270214676856995, 0.9587671160697937, -0.29334554076194763, -0.5616265535354614, 0.016308018937706947, -0.9902760982513428, -0.35813090205192566, -0.19764064252376556, 0.3780103921890259, 0.6734060049057007, 0.14711548388004303, 0.019297193735837936, -0.7420616745948792, 0.22820895910263062, -0.3606911599636078, -0.6459713578224182, 0.5635221004486084, 0.21771839261054993, -0.23527877032756805, 0.12019812315702438, 0.34426939487457275, -0.7471262216567993, -0.8207136392593384, -0.7662800550460815, -0.307989239692688, -0.23084162175655365, 0.5902994275093079, -0.19277571141719818, -0.6997628211975098, 0.7084494829177856, 0.3824901282787323, 0.434518039226532, -0.05469293147325516, -0.37827593088150024, 0.30631572008132935, 0.8899234533309937, 0.10475092381238937, -1.165383219718933, -0.5326159596443176, 1.3185137510299683, 0.7889540195465088, -0.5484982132911682, 0.26902392506599426, -0.20994402468204498, -0.5992418527603149, 0.3827739357948303, 0.4280085265636444, -0.6347464323043823, 0.6606103181838989, -0.11080411076545715, -0.22684307396411896, -0.07767140865325928, -1.023539662361145, -0.853538453578949, 0.5218418836593628, 1.0766886472702026, 0.13349713385105133, -0.17194128036499023, 0.16226623952388763, 0.6570419669151306, 0.43878090381622314, 0.3641784191131592, 0.23751705884933472, 0.13697029650211334, -0.3145062327384949, -0.05666150897741318, 0.22000080347061157, 0.804533064365387, -0.9301095008850098, -0.8894739151000977, -0.16851067543029785, 0.6227707266807556, 0.41017454862594604, 0.5572968125343323, 0.9249132871627808, -0.06348302960395813, 0.7322695255279541, 0.16384388506412506, 0.6002346277236938, -0.26382845640182495, -0.34644755721092224, -0.06810321658849716, -0.6298834085464478, -0.05806897580623627, 0.17447605729103088, -0.3938014805316925, -0.2514711916446686, -0.5664211511611938, 0.12073105573654175, -0.13519029319286346, -0.01148177683353424, 1.0289760828018188, 0.8150249123573303, 0.8689326047897339, -0.58332359790802, -0.6149383187294006, -0.1074133962392807, -0.5774965286254883, 0.20036020874977112, -0.49073827266693115, -0.4472387731075287, -0.4415194094181061, 0.034483619034290314, -0.44692832231521606]}, "authors": [{"authorId": "2120308872", "name": "Hongjie Wang"}, {"authorId": "90563574", "name": "Bhishma Dedhia"}, {"authorId": "144874163", "name": "N. Jha"}], "references": [{"paperId": "4a822bb044bdf51489b1aee4cf6736d8d3daa5bd", "title": "Dynamic Token Pruning in Plain Vision Transformers for Semantic Segmentation"}, {"paperId": "bccf49f7cdf0662ef421b7c22537ef9b0b33e6e1", "title": "Joint Token Pruning and Squeezing Towards More Aggressive Compression of Vision Transformers"}, {"paperId": "6518091d7f2af10629b836df8c7a53ce4104c4fb", "title": "Token Merging for Fast Stable Diffusion"}, {"paperId": "ec68079f15b620a8a7ad19b3477f895e2ecf193d", "title": "HeatViT: Hardware-Efficient Adaptive Token Pruning for Vision Transformers"}, {"paperId": "1dff6b1b35e2d45d4db57c8b4e4395486c3e365f", "title": "Token Merging: Your ViT But Faster"}, {"paperId": "74263c63be360a664e4acfa71db7123caa53bdd9", "title": "Adaptive Sparse ViT: Towards Learnable Adaptive Token Pruning by Fully Exploiting Self-Attention"}, {"paperId": "968e91c7b6948bbe4abcb85467cec8b623d35940", "title": "Training Vision Transformers with Only 2040 Images"}, {"paperId": "b7dc007054cf17dea3b22a2d1e71ba4cc8606648", "title": "Revisiting Weakly Supervised Pre-Training of Visual Perception Models"}, {"paperId": "722d71a19e4049b30a03d1028158881560432135", "title": "SPViT: Enabling Faster Vision Transformers via Latency-Aware Soft Token Pruning"}, {"paperId": "c2a0c18e810535db52e5ebaf180c64ce70356748", "title": "A-ViT: Adaptive Tokens for Efficient Vision Transformer"}, {"paperId": "8144ca1f78c045cb001815090bcf8a726e37e0ad", "title": "Adaptive Token Sampling for Efficient Vision Transformers"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "c156b1b30e3dd9284615e5304f2fb2826c09d0ff", "title": "Learned Token Pruning for Transformers"}, {"paperId": "cf5e6e3c50a798d87033e0e108e88b3647738bbe", "title": "How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "2a805d0e1b067444a554c5169d189fa1f649f411", "title": "Scaling Vision Transformers"}, {"paperId": "dbdcabd0444ad50b68ee09e30f39b66e9068f5d2", "title": "DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification"}, {"paperId": "6da4b231148bf26677233d1f778d08a5d26f4313", "title": "TR-BERT: Dynamic Token Reduction for Accelerating BERT Inference"}, {"paperId": "cc9f3a61ea4eaabf43cbb30cd1dd718074932679", "title": "All Tokens Matter: Token Labeling for Training Better Vision Transformers"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "73e0f38ab49b19b86321016b773e15f1d02e3a72", "title": "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "a50d31c082521817a1e74cae584963a63163ca70", "title": "Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime with Search"}, {"paperId": "5d34881ff68bd203ff790187e7e5c9e034389cfa", "title": "FastBERT: a Self-distilling BERT with Adaptive Inference Time"}, {"paperId": "94f94e8892261d0377159379ca5a166ceae19a14", "title": "PoWER-BERT: Accelerating BERT Inference via Progressive Word-vector Elimination"}, {"paperId": "4585611042d2be0d997ee135e3fe219d668db9ec", "title": "Depth-Adaptive Transformer"}, {"paperId": "5b8077a4a77e9431ae622e3a6da6aa34b48cf0b8", "title": "Differentiable Ranks and Sorting using Optimal Transport"}, {"paperId": "b03c7ff961822183bab66b2e594415e585d3fd09", "title": "Are Sixteen Heads Really Better than One?"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "47d79963ac69111d8dc82a228d26e6a746a4d087", "title": "Transformers"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "04cca8e341a5da42b29b0bc831cb25a0f784fa01", "title": "Adaptive Computation Time for Recurrent Neural Networks"}, {"paperId": "340f48901f72278f6bf78a04ee5b01df208cc508", "title": "Human-level control through deep reinforcement learning"}, {"paperId": "d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad", "title": "Intriguing properties of neural networks"}, {"paperId": "a83cec6a91701bd8500f8c43ad731d4353c71d55", "title": "3D Object Representations for Fine-Grained Categorization"}, {"paperId": "18c125ce0f64e85577f7d30132cf0e92ec664bf4", "title": "Describing Textures in the Wild"}, {"paperId": "522d65a3db7431015aeaa201a7fc4450a57e40c3", "title": "Fine-Grained Visual Classification of Aircraft"}, {"paperId": "84b50ebe85f7a1721800125e7882fce8c45b5c5a", "title": "Cats and dogs"}, {"paperId": "c069629a51f6c1c301eb20ed77bc6b586c24ce32", "title": "The Caltech-UCSD Birds-200-2011 Dataset"}, {"paperId": "e78f3223bf67c45c7fe45301ff8400b438c99e1d", "title": "Learning Control in Robotics"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "c82d90336ba365c7914fe4bd6c292a8c6916a801", "title": "Recognizing indoor scenes"}, {"paperId": "e9dd235240904627b12782653b66318712780703", "title": "A Visual Vocabulary for Flower Classification"}, {"paperId": "eb82d3035849cd23578096462ba419b53198a556", "title": "The PageRank Citation Ranking : Bringing Order to the Web"}, {"paperId": null, "title": "Ponder-Net: Learning to Ponder"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Iasonas Kokkinos, Sammy Mohamed, and Andrea Vedaldi"}, {"paperId": "c21aab2435abee44a5904e0ead5deec729bbb96a", "title": "The International Conference on Machine Learning (ICML 2011)"}]}