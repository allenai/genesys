{"paperId": "1c8aea2bfb61f4661b6907018a5a8bca390900dd", "title": "PALM: Pre-training an Autoencoding&autoregressive Language Model for Context-conditioned Generation", "abstract": "Self-supervised pre-training, such as BERT, MASS and BART, has emerged as a powerful technique for natural language understanding and generation. Existing pre-training techniques employ autoencoding and/or autoregressive objectives to train Transformer-based models by recovering original word tokens from corrupted text with some masked tokens. The training goals of existing techniques are often inconsistent with the goals of many language generation tasks, such as generative question answering and conversational response generation, for producing new text given context. \nThis work presents PALM with a novel scheme that jointly pre-trains an autoencoding and autoregressive language model on a large unlabeled corpus, specifically designed for generating new text conditioned on context. The new scheme alleviates the mismatch introduced by the existing denoising scheme between pre-training and fine-tuning where generation is more than reconstructing original text. An extensive set of experiments show that PALM achieves new state-of-the-art results on a variety of language generation benchmarks covering generative question answering (Rank 1 on the official MARCO leaderboard), abstractive summarization on CNN/DailyMail as well as Gigaword, question generation on SQuAD, and conversational response generation on Cornell Movie Dialogues.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2020, "citationCount": 58, "influentialCitationCount": 4, "openAccessPdf": {"url": "https://www.aclweb.org/anthology/2020.emnlp-main.700.pdf", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "PALM is presented with a novel scheme that jointly pre-trains an autoencoding and autoregressive language model on a large unlabeled corpus, specifically designed for generating new text conditioned on context."}, "embedding": {"model": "specter_v2", "vector": [0.4712821841239929, 0.6960924863815308, 0.456677109003067, -0.12236034870147705, -0.7283276319503784, -0.6922329664230347, 0.821535587310791, -0.0060693793930113316, -0.07006175816059113, 0.05456630513072014, 0.9414589405059814, -0.08313941955566406, 0.40773138403892517, -0.3755379319190979, -0.38164815306663513, -0.029911501333117485, -0.746406614780426, 0.10320135951042175, -0.37295758724212646, -0.609736979007721, -0.15510106086730957, -1.149116039276123, -1.0207853317260742, 0.412179172039032, 0.6974837779998779, 0.13944824039936066, 0.1710045486688614, 1.3072823286056519, -0.560880720615387, 0.4758603572845459, 0.12627439200878143, -0.3821779489517212, -0.07703517377376556, -0.6956019997596741, -0.6733093857765198, 0.19687457382678986, -0.022558437660336494, -0.33738502860069275, -0.20463356375694275, 0.34322747588157654, 0.09817416965961456, 0.06428994983434677, 0.26140135526657104, -0.20270070433616638, -0.5209652185440063, 1.598008394241333, 0.9317001700401306, 0.681481659412384, 0.11966957151889801, -0.5891947746276855, 1.2464183568954468, -1.1821300983428955, 0.37014177441596985, 1.4943417310714722, 0.2944134771823883, 0.8792340159416199, -0.38343366980552673, -0.41191062331199646, 0.7989595532417297, -0.07699067890644073, -0.7557511329650879, -0.4158349931240082, 0.3562130630016327, -0.0871133804321289, 1.5216083526611328, -0.23267437517642975, 0.18742980062961578, 0.7094582915306091, -0.18979108333587646, 1.2617098093032837, -0.21184395253658295, -0.6753537058830261, -0.20264562964439392, 0.0008578518172726035, 0.18738876283168793, 0.8774148225784302, -0.693478524684906, 0.18721064925193787, -0.7904269695281982, 0.053236592561006546, 0.15449753403663635, -0.40506890416145325, -0.29413819313049316, 0.1692167967557907, -0.2051219940185547, 0.8153441548347473, 0.1588594764471054, 0.9349104762077332, -0.20699605345726013, 0.7732411623001099, 0.4796232581138611, 0.23339678347110748, 0.2924116253852844, 0.5591962933540344, 0.22585517168045044, 0.30131372809410095, -0.6655178666114807, 0.6394479274749756, -0.07958126068115234, 0.6876000761985779, 0.09729110449552536, 0.6800278425216675, -1.165335774421692, 0.19401343166828156, 1.3103214502334595, 0.04582691565155983, 0.8155587315559387, -0.9765850901603699, 0.34930965304374695, -0.7117551565170288, -0.023509996011853218, -0.2391894906759262, 0.14998000860214233, -0.2798326909542084, -0.8325702548027039, -1.3637830018997192, -0.4517771005630493, -0.44969287514686584, -0.9828117489814758, 1.0337351560592651, -0.1291082352399826, -0.03049788996577263, 0.6917773485183716, 0.3879894018173218, 0.448810338973999, 0.969963788986206, -0.01288992166519165, -0.12603875994682312, 0.6562806963920593, -0.7035221457481384, -0.7667900919914246, -1.0433986186981201, 0.6809518933296204, -0.15052615106105804, 0.0695471465587616, -0.19074609875679016, -1.4940077066421509, -0.9470981359481812, -0.8584535717964172, -0.0008750408887863159, -0.3386010527610779, -0.01882859878242016, 1.0181622505187988, 0.9198248386383057, -1.006685495376587, 0.6948267221450806, 0.008179686963558197, -0.09941165149211884, 0.3417087197303772, -0.0295040775090456, 0.05822853371500969, -0.582208514213562, -1.1666743755340576, -0.3363857865333557, 0.08313015848398209, -0.40857475996017456, -0.2615889608860016, -0.7866048812866211, -1.1618797779083252, -0.25336405634880066, 0.17168746888637543, -0.6586592793464661, 1.3595659732818604, -0.14154782891273499, -1.6482466459274292, 0.5347118377685547, -0.5294939875602722, -0.229691281914711, 0.31232771277427673, -0.3434472978115082, -0.23401153087615967, -0.5359295606613159, 0.03029336966574192, 0.3847481906414032, 0.32962167263031006, -0.26814791560173035, -0.11118310689926147, 0.15144087374210358, -0.37845370173454285, -0.2924395203590393, 0.13404715061187744, 0.5691254138946533, -0.17325438559055328, -0.3315814733505249, 0.5028600096702576, 0.978857696056366, -0.0694560632109642, -1.2199214696884155, -0.8499895334243774, -1.2050244808197021, 0.7557807564735413, -0.03491438925266266, 0.7657189965248108, -0.7678895592689514, -0.7916993498802185, -0.2071557641029358, -0.2532529830932617, -0.24548828601837158, -0.9895287752151489, 0.8252965211868286, -0.5883844494819641, 0.6256635785102844, -0.2820194661617279, -1.1799249649047852, -0.02794417180120945, -0.313996821641922, -1.2010219097137451, -0.5608300566673279, 0.6375980973243713, 1.161098599433899, -0.9475982189178467, 0.17350028455257416, -0.09662605822086334, 0.15788908302783966, -1.1985479593276978, 1.2688499689102173, -0.5404834151268005, 0.4967292845249176, -0.334523469209671, -0.18061493337154388, -0.07044191658496857, 0.03348424658179283, 0.3492620587348938, 0.01182807981967926, -0.03717005252838135, 0.6718518733978271, -0.5829164981842041, 1.503920078277588, -0.29055315256118774, 0.20268476009368896, -0.32113537192344666, -0.7771320939064026, 0.47094935178756714, 0.5443729758262634, -0.28482675552368164, -0.2510718107223511, 0.0759441927075386, 0.4442572295665741, -0.5210197567939758, 0.20025154948234558, 0.8428801894187927, 0.5574474334716797, -0.47353875637054443, 0.2378281056880951, 0.9220606088638306, -0.5709786415100098, 0.9676275253295898, 0.581874668598175, 1.2369763851165771, 0.3716803193092346, -0.020586460828781128, 0.2687542140483856, 0.454887717962265, -0.6108591556549072, 0.08443883806467056, 0.7365053296089172, 1.0418812036514282, 1.4586102962493896, 0.38359692692756653, -0.4905978739261627, -0.32451361417770386, -0.15404388308525085, 1.2123770713806152, 1.1726628541946411, -0.5608043074607849, -0.4484237730503082, -1.086463451385498, -0.41563257575035095, -0.7352842092514038, 0.4174012541770935, -0.43962207436561584, -0.2859421670436859, -0.7552089691162109, -0.855853796005249, 0.7496615052223206, 0.2952548861503601, 1.0448344945907593, -0.5397353172302246, 0.20703136920928955, -0.013103049248456955, -0.1936170607805252, -0.6214132905006409, -0.5840195417404175, 0.0626625269651413, -0.290047824382782, -0.08835001289844513, -0.2660259008407593, -0.16281680762767792, 0.2186792641878128, -0.7348297834396362, 0.9994677901268005, -0.3036644458770752, -0.27021530270576477, 0.2961072325706482, 0.378263920545578, -0.5976924896240234, -1.0678812265396118, 0.10506470501422882, -0.17054519057273865, -0.03811369836330414, -0.06537852436304092, 0.16400711238384247, -0.001961806323379278, -0.2634789049625397, -0.3253985345363617, 0.1188855767250061, -0.233632430434227, 0.22536595165729523, 0.6889361143112183, -0.23086772859096527, 0.04597432538866997, -1.4532256126403809, 0.9667435884475708, 0.25774097442626953, -0.34367263317108154, 0.1784072369337082, -0.3080171048641205, -0.2623326778411865, 0.6006075143814087, -0.41505366563796997, -0.519491970539093, -0.9170506000518799, 0.19250725209712982, 0.06915537267923355, -0.36101001501083374, 0.2973664402961731, 0.04328178986907005, 0.8408244848251343, 0.16620314121246338, 0.5975244641304016, 0.2306828498840332, 0.06266193836927414, 0.9398186206817627, -1.1070802211761475, 0.7623863816261292, 0.279502272605896, 0.5444827079772949, -0.2761795222759247, -0.42551082372665405, -0.4378591477870941, -0.39012283086776733, 0.03561423346400261, 0.20087115466594696, -0.4369700253009796, 0.4579678475856781, -0.5549079179763794, -0.7003728747367859, 0.06412241607904434, -1.2628957033157349, -0.2660069763660431, -0.4616602063179016, -0.6291941404342651, -0.2725563943386078, -0.9011538028717041, -0.7561952471733093, -0.8598628044128418, -0.6949556469917297, -0.699220597743988, 0.46915698051452637, 0.03966209292411804, -0.46771860122680664, -0.546468198299408, 0.5325419902801514, -0.04573842138051987, 0.6255307793617249, -0.49276313185691833, 0.8594979643821716, 0.03331473097205162, -0.3573117256164551, -0.19418686628341675, 0.6231224536895752, 0.5820622444152832, -0.3686986565589905, 0.10018004477024078, -0.8350074291229248, 0.1813361942768097, -0.4156581163406372, -0.5627654194831848, 0.2519710659980774, 0.3130593001842499, 0.4913899004459381, -0.03441447764635086, -0.21748386323451996, 0.28025057911872864, 1.3325589895248413, -0.4574185013771057, 0.3961520493030548, -0.23917680978775024, 0.793087363243103, 0.5185841917991638, -0.5352094769477844, 0.3972940742969513, 0.4721144437789917, 0.1126614511013031, 0.03115846775472164, 0.027573807165026665, -0.18372118473052979, -0.9151689410209656, 0.7924177050590515, 1.5843632221221924, 0.40478336811065674, -0.6420748829841614, -1.02744460105896, 1.0790657997131348, -1.3117296695709229, -0.5040969252586365, 0.3804864287376404, 0.4052262008190155, 0.42028796672821045, -0.7835919857025146, -0.32153576612472534, 0.2700938880443573, 0.4821022152900696, 0.3201577961444855, -0.03724965825676918, -0.6621935963630676, -0.1646612137556076, 0.5730052590370178, -0.24306800961494446, 0.7171996831893921, -0.18802708387374878, 0.6546198129653931, 14.617268562316895, 0.6419435739517212, 0.27986398339271545, 0.5527073740959167, 0.6943279504776001, 0.20020394027233124, -0.6789010167121887, 0.01805076375603676, -1.1108217239379883, -0.4444441497325897, 0.9732781648635864, -0.01724630780518055, 0.5120205879211426, -0.015805620700120926, 0.09150990843772888, 0.3016185462474823, -0.49893465638160706, 0.43221887946128845, 0.5116243362426758, -1.5973219871520996, 0.5620375871658325, 0.33503323793411255, 0.582611620426178, 0.20529073476791382, 0.769280195236206, 0.8892547488212585, 0.7312398552894592, -0.31194499135017395, 0.44083765149116516, 0.38993385434150696, 0.5104649066925049, 0.0166885145008564, 0.4669925272464752, 0.302349716424942, -0.5047428011894226, -0.4963270425796509, -0.30855605006217957, -0.8431981205940247, 0.62470543384552, 0.17658673226833344, -0.5264592170715332, -0.1492566019296646, -0.1894657164812088, 0.385915070772171, 0.1104995459318161, -0.017070747911930084, -0.4328858554363251, 1.1592357158660889, 0.06331323087215424, -0.0010315271792933345, 0.1929168850183487, 0.39013177156448364, 0.5206424593925476, -0.28107109665870667, 0.4535098969936371, 0.34057337045669556, 0.05510810762643814, 0.8131266832351685, -0.6845932006835938, -0.08777979016304016, -0.437550812959671, -0.37373456358909607, -0.16937842965126038, 0.675481915473938, 0.6087045073509216, 0.31775176525115967, -0.09001666307449341, 0.09002307057380676, 0.5126543045043945, 0.1871008425951004, 0.1406947672367096, -0.21459031105041504, -0.013268684968352318, -0.025756657123565674, 0.23174825310707092, 0.5833308100700378, -0.16059868037700653, -0.22242797911167145, -0.7659215331077576, -0.3161875903606415, 0.19426247477531433, -0.9724445343017578, -0.7337659597396851, 0.9530007839202881, -0.4728381037712097, -0.2410513013601303, -0.7112316489219666, -0.2622620165348053, -0.7719018459320068, 0.5502339601516724, -1.0928101539611816, -0.7800379991531372, 0.27359986305236816, -0.515634298324585, -0.31997010111808777, -0.41757968068122864, 1.3816429376602173, -0.3858727216720581, -0.40647363662719727, -0.13226954638957977, -0.0765974223613739, 0.13708198070526123, -0.5270196199417114, -1.2147513628005981, 0.8009769916534424, 0.6759349703788757, 0.006072483956813812, 0.05222021043300629, 0.14990395307540894, 0.10987095534801483, -0.8827117085456848, -0.24040116369724274, 1.0253198146820068, -0.9251382946968079, -0.723466157913208, -1.124153971672058, -0.8817026019096375, 0.017526356503367424, 0.8717303276062012, -0.5482602715492249, 0.5154854655265808, 0.12861400842666626, -0.11044706404209137, -0.23959578573703766, -0.8128937482833862, 0.12063654512166977, 0.4198736548423767, -0.48249635100364685, -0.2866997718811035, 0.1420907825231552, 0.7101430892944336, -0.9415169358253479, -0.10761717706918716, -0.47542011737823486, -0.18443235754966736, -0.18800249695777893, 0.6350284218788147, -0.24732229113578796, 0.9432851672172546, 0.8144624829292297, 0.053183384239673615, -0.7984497547149658, -0.10199965536594391, -1.3782271146774292, 0.3653733432292938, 1.261958122253418, 0.7733618021011353, -0.25929877161979675, 0.5030952095985413, 0.7639479637145996, 0.15802627801895142, -0.18083789944648743, -0.6729460954666138, 0.11535504460334778, 0.19707557559013367, -0.6289631724357605, 0.6532382965087891, -0.3308335244655609, -0.25927916169166565, 0.4076394736766815, 0.4823138117790222, 0.5477012395858765, -0.3748079240322113, -0.7727428674697876, 0.9777060151100159, 0.3243941068649292, -0.05864816904067993, -0.323321670293808, -0.3299693167209625, -1.0702866315841675, -0.020657915621995926, -1.0211060047149658, 0.13649283349514008, -1.1559267044067383, -0.6140438914299011, 0.5719542503356934, 0.23317742347717285, -0.12493017315864563, 0.2598058581352234, -0.30060818791389465, -0.4045012891292572, -1.1436793804168701, -0.5192911028862, 0.8601945638656616, 0.5121059417724609, -0.8152700066566467, -0.2889310121536255, -0.13804104924201965, -0.5604767799377441, 0.07269351929426193, 0.4455331861972809, -0.3224281370639801, -0.8422390818595886, -1.4099491834640503, 0.33424627780914307, 0.0036910967901349068, 0.152692049741745, -0.8161216974258423, 0.32324063777923584, 0.9097211360931396, -0.08502784371376038, -0.2527102530002594, 0.1348404586315155, -0.13530735671520233, -0.35070520639419556, -0.09048721939325333, -0.8381251096725464, 0.23747877776622772, -0.0004972098395228386, -0.3967268764972687, -0.4973961114883423, 0.5680686831474304, -0.4471834897994995, -1.306227445602417, -0.43177950382232666, 0.21203742921352386, -0.9136921167373657, 0.3137566149234772, -0.5785230398178101, -0.16379457712173462, -1.0774625539779663, -0.7326437830924988, 0.08757654577493668, 0.43094199895858765, -0.7908774614334106, 0.888756275177002, 0.6610985398292542, -0.9164881110191345, -0.36650288105010986, 0.30582231283187866, -0.3061304986476898, 0.2717731297016144, 1.0913121700286865, 0.06817325204610825, -0.10046330094337463, 0.28382474184036255, 0.7838550209999084, 0.29045259952545166, -0.6222852468490601, -0.34050917625427246, 0.9137491583824158, -1.0765693187713623, 0.11121757328510284, 1.2504018545150757, -0.40626007318496704, -1.3502742052078247, -0.3075751066207886, -1.041238784790039, -0.6517637968063354, -0.4593183994293213, 0.6941377520561218, 0.14500662684440613, -0.3233795762062073, -0.004739550873637199, -0.09810219705104828, 0.22053378820419312, -0.16375717520713806, -1.0765844583511353, 0.7879695892333984, -0.28788623213768005, -0.44021886587142944, 0.4359094202518463, 0.4616411626338959, -0.5111571550369263, -0.3945462703704834, -0.6330936551094055, -0.5718271136283875, 0.15909279882907867, 0.336635559797287, -0.5284680724143982, -0.41830047965049744, 0.8426380157470703, 0.5253515243530273, 0.6394551992416382, 0.22396673262119293, 0.003352412022650242, 0.39199507236480713, 0.5706930160522461, -0.2775304317474365, -0.757477343082428, -0.20786339044570923, 1.285746455192566, 1.4540287256240845, -0.7133634686470032, -0.023277167230844498, -0.37996482849121094, -0.7993066906929016, 0.8183030486106873, 0.15675482153892517, -0.04681554436683655, 0.7404020428657532, -0.5972002744674683, 0.3858307898044586, 0.28517860174179077, -1.3421499729156494, -0.4934864342212677, 0.48656535148620605, 1.6154106855392456, 0.7921336889266968, -0.1856006681919098, 0.2905770540237427, 1.2783833742141724, -0.2683420479297638, -0.1425943225622177, 0.7872804999351501, 0.40006154775619507, 0.051826111972332, -0.503494143486023, 0.04912997782230377, 0.22924377024173737, -0.8361074924468994, -0.27172383666038513, -0.0509885810315609, 0.4665677845478058, 0.4516086280345917, 1.1627743244171143, 0.7810503244400024, 0.11408901959657669, 0.6216456294059753, 0.43194901943206787, 0.3768574297428131, -0.6924152970314026, -0.43775296211242676, 0.041790276765823364, -0.4618968069553375, -0.07918708771467209, -0.31637728214263916, -0.8317362070083618, -0.27263569831848145, 0.1562325656414032, 0.27857279777526855, 0.3885832130908966, 0.33987855911254883, 1.2977031469345093, 0.6817776560783386, 0.5153322815895081, 0.2037757784128189, -0.23207229375839233, -0.1635037213563919, -1.0566374063491821, 0.019254613667726517, -0.48139098286628723, -0.10866349190473557, 0.2482912391424179, 0.10563251376152039, -0.006232688203454018]}, "authors": [{"authorId": "2555622", "name": "Bin Bi"}, {"authorId": "143971529", "name": "Chenliang Li"}, {"authorId": "29701485", "name": "Chen Wu"}, {"authorId": "2047087220", "name": "Ming Yan"}, {"authorId": "38700603", "name": "Wei Wang"}], "references": [{"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "f64e1d6bc13aae99aab5449fc9ae742a9ba7761e", "title": "UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training"}, {"paperId": "6191a5122d67dfbab421bc89540d264822dd8173", "title": "ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework for Natural Language Generation"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "405f28f754e4c2cf8028df5be7c996c2d55e0677", "title": "Concept Pointer Network for Abstractive Summarization"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "d198c9667c38db589e92e1280e08e2ac226c7063", "title": "Incorporating External Knowledge into Machine Reading for Generative Question Answering"}, {"paperId": "63748e59f4e106cbda6b65939b77589f40e48fcb", "title": "Text Summarization with Pretrained Encoders"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "81f5810fbbab9b7203b9556f4ce3c741875407bc", "title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans"}, {"paperId": "1c71771c701aadfd72c5866170a9f5d71464bb88", "title": "Unified Language Model Pre-training for Natural Language Understanding and Generation"}, {"paperId": "145b8b5d99a2beba6029418ca043585b90138d12", "title": "MASS: Masked Sequence to Sequence Pre-training for Language Generation"}, {"paperId": "b5aa927c906101b3f8854a29f374551e3ea64474", "title": "Pre-trained language model representations for language generation"}, {"paperId": "4c09d30704c0ceb128bb31ee09f957ee58d5032c", "title": "Multi-style Generative Reading Comprehension"}, {"paperId": "57c945496f3ef2e93dd3f75b454d9d4922d7e47a", "title": "Cut to the Chase: A Context Zoom-in Network for Reading Comprehension"}, {"paperId": "7af89df3691d8c33aaf1858f7cc51da1bc9549a9", "title": "Bottom-Up Abstractive Summarization"}, {"paperId": "71fa9cfcc7d6584f4e9f7ad2a2c1a6234eec412d", "title": "Retrieve, Rerank and Rewrite: Soft Template Based Neural Summarization"}, {"paperId": "c3fe330480f2558c79e71a9cf3d78264143de56a", "title": "Entity Commonsense Representation for Neural Abstractive Summarization"}, {"paperId": "2fed2b40953d33a1fc38221b55476005fd91db70", "title": "Global Encoding for Abstractive Summarization"}, {"paperId": "0985497d1de3ffd11713e75289cc2ad55836623d", "title": "Multi-Passage Machine Reading Comprehension with Cross-Passage Answer Verification"}, {"paperId": "d8b6e965b771e3d0707dd8caa57224a0dfbb886e", "title": "Harvesting Paragraph-level Question-Answer Pairs from Wikipedia"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "1e077413b25c4d34945cc2707e17e46ed4fe784a", "title": "Universal Language Model Fine-tuning for Text Classification"}, {"paperId": "41232a69c0f8d4b993e6c6e00b16c223442c962f", "title": "Faithful to the Original: Fact Aware Neural Abstractive Summarization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "53875e16feb74e9425e2f9da743794c850087817", "title": "S-Net: From Answer Extraction to Answer Generation for Machine Reading Comprehension"}, {"paperId": "668db48c6a79826456341680ee1175dfc4cced71", "title": "Get To The Point: Summarization with Pointer-Generator Networks"}, {"paperId": "aab5002a22b9b4244a8329b140bd0a86021aa2d1", "title": "OpenNMT: Open-Source Toolkit for Neural Machine Translation"}, {"paperId": "364f7f7bac907ce326dce84b26eb857f186d3dc2", "title": "Cutting-off Redundant Repeating Generations for Neural Abstractive Summarization"}, {"paperId": "8d574fde3e46ad766fac26094e3bb1cf55a08226", "title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset"}, {"paperId": "424aef7340ee618132cc3314669400e23ad910ba", "title": "Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling"}, {"paperId": "dd95f96e3322dcaee9b1e3f7871ecc3ebcd51bfe", "title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "4aa9f5150b46320f534de4747a2dd0cd7f3fe292", "title": "Semi-supervised Sequence Learning"}, {"paperId": "1ac30af5522c7a50ec4d1ee43fd2bd8652a9bd52", "title": "A Neural Attention Model for Abstractive Sentence Summarization"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "86311b182786bfde19446f6ded0854de973d4060", "title": "A Neural Conversational Model"}, {"paperId": "d1505c6123c102e53eb19dff312cb25cea840b72", "title": "Teaching Machines to Read and Comprehend"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "ea45438193cd724445d08cf3a1fa9137ffed54f6", "title": "Chameleons in Imagined Conversations: A New Approach to Understanding Coordination of Linguistic Style in Dialogs"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "3ed3310558a40388d24c77a43d7b3f13eb6e3d3c", "title": "Paragraph-level Neural Question Generation with Maxout Pointer and Gated Self-attention Networks"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": "6f446441441ce26bb410be56e4cdf99e57d84bf2", "title": "48th Annual Meeting of the Association for Computational Linguistics"}, {"paperId": null, "title": "English giga-word"}]}