{"paperId": "73fd85ebd43faa2afc6e88a379a932d8017851fc", "title": "Large Scale Transfer Learning for Tabular Data via Language Modeling", "abstract": "Tabular data -- structured, heterogeneous, spreadsheet-style data with rows and columns -- is widely used in practice across many domains. However, while recent foundation models have reduced the need for developing task-specific datasets and predictors in domains such as language modeling and computer vision, this transfer learning paradigm has not had similar impact in the tabular domain. In this work, we seek to narrow this gap and present TabuLa-8B, a language model for tabular prediction. We define a process for extracting a large, high-quality training dataset from the TabLib corpus, proposing methods for tabular data filtering and quality control. Using the resulting dataset, which comprises over 1.6B rows from 3.1M unique tables, we fine-tune a Llama 3-8B large language model (LLM) for tabular data prediction (classification and binned regression) using a novel packing and attention scheme for tabular prediction. Through evaluation across a test suite of 329 datasets, we find that TabuLa-8B has zero-shot accuracy on unseen tables that is over 15 percentage points (pp) higher than random guessing, a feat that is not possible with existing state-of-the-art tabular prediction models (e.g. XGBoost, TabPFN). In the few-shot setting (1-32 shots), without any fine-tuning on the target datasets, TabuLa-8B is 5-15 pp more accurate than XGBoost and TabPFN models that are explicitly trained on equal, or even up to 16x more data. We release our model, code, and data along with the publication of this paper.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A process for extracting a large, high-quality training dataset from the TabLib corpus is defined, proposing methods for tabular data filtering and quality control, and a Llama 3-8B large language model is fine-tune for tabular data prediction using a novel packing and attention scheme for tabular prediction."}, "embedding": {"model": "specter_v2", "vector": [-0.1821214109659195, 0.34586137533187866, -0.7307577729225159, -0.35576191544532776, -0.8079273104667664, -0.17526204884052277, 0.39578041434288025, -0.08192358911037445, -0.06622865051031113, 0.4937616288661957, 0.4668693244457245, -0.08800525963306427, 0.25852835178375244, -0.11533207446336746, -0.3780188262462616, 0.34323224425315857, -0.6373606324195862, 0.9013497829437256, -0.25868895649909973, -0.6129598617553711, 0.09208279103040695, -0.7910327911376953, -0.7969343066215515, 0.5438994765281677, 0.1942419409751892, 1.1474173069000244, -0.21710515022277832, 0.2891475260257721, -0.9558667540550232, 0.5679416060447693, 0.3165406882762909, -0.6712439060211182, 0.2760196924209595, -0.023698873817920685, -0.8542519807815552, 0.15336722135543823, 0.6134136319160461, -0.18721002340316772, -0.3327021300792694, 0.22221636772155762, -0.3718909025192261, 0.5670819878578186, 0.6428728103637695, -0.48888009786605835, -0.35234758257865906, 0.47836804389953613, 0.6422557830810547, 0.3931451141834259, -0.010060292668640614, -0.8563978672027588, 1.5908339023590088, -1.2800872325897217, 0.28322479128837585, 1.2993648052215576, 0.5666367411613464, 0.6455109119415283, -0.3589981198310852, -0.8011971712112427, 0.13664086163043976, 0.12014108896255493, -0.584290623664856, -0.15137243270874023, -0.6135045289993286, -0.3310226500034332, 1.322668194770813, -0.3042477071285248, -0.5326827764511108, 0.4761393368244171, 0.23968221247196198, 1.3513177633285522, 0.20088595151901245, -0.7473317384719849, -0.334259033203125, 0.33237406611442566, 0.1182136982679367, 0.7602974772453308, -0.5345577001571655, 0.06662826240062714, -1.208304524421692, 0.20088839530944824, 0.12645310163497925, -0.15308769047260284, 0.22863012552261353, -0.4398637115955353, -0.2876783609390259, 0.5142008066177368, 0.39666515588760376, 0.4349600672721863, -0.05514286831021309, 0.5769327878952026, 0.6372283697128296, 0.34460538625717163, -0.029721064493060112, 0.4701847732067108, -0.6471300721168518, 0.04607434198260307, -0.7628997564315796, 0.04795107990503311, 0.030139394104480743, 1.0233691930770874, -0.029607465490698814, -0.10036899149417877, -1.1440335512161255, 0.420695424079895, 1.0433151721954346, -0.20806752145290375, 0.6339471340179443, -0.4692826569080353, 0.47676950693130493, -0.359247624874115, 0.3742932081222534, -0.6626684665679932, -0.16762515902519226, -0.13639412820339203, -0.40429380536079407, -1.2009183168411255, -0.2619380056858063, -0.14250782132148743, -0.8286380171775818, 0.29890456795692444, -0.4177629351615906, -0.510957658290863, -0.3028901219367981, 0.47240349650382996, 0.7378548383712769, 0.9588444828987122, 0.13599970936775208, -0.029614172875881195, 0.7551884055137634, -0.6711633205413818, -0.5566176176071167, -0.9529270529747009, 0.9025464057922363, -0.1183130294084549, 0.30652716755867004, 0.04283573478460312, -1.0945242643356323, -0.9667462110519409, -0.6382635235786438, -0.18862462043762207, -0.9458397626876831, 0.20904789865016937, 0.9218192100524902, 0.7346656918525696, -0.4200233221054077, 0.6518033742904663, -0.036198459565639496, -0.3048665225505829, 0.6371203064918518, 0.2631146013736725, 0.06984720379114151, -0.7643558382987976, -1.2627421617507935, 0.4535192549228668, 0.16178150475025177, -0.7989349365234375, -0.12036346644163132, -0.6684896349906921, -1.010426640510559, 0.018384680151939392, 0.7288158535957336, -0.1856374889612198, 1.0190678834915161, -0.1638660877943039, -1.0631390810012817, 0.8868440985679626, -0.27919384837150574, -0.010097709484398365, 0.4889289140701294, -0.0799512267112732, -0.48893481492996216, -1.0826328992843628, -0.012465855106711388, 0.5211396217346191, 0.30532199144363403, -0.2808409333229065, -0.2631242275238037, 0.4007376432418823, -0.4624476432800293, -0.1952468454837799, -0.5022619962692261, 0.6223627924919128, -0.5472554564476013, -0.11746911704540253, 0.007233213633298874, 0.9075325727462769, 0.26022034883499146, -0.01027466170489788, -0.3917361795902252, -0.9829219579696655, 0.36737972497940063, -0.05026712641119957, 0.9280797839164734, -0.620233416557312, -0.749565601348877, -0.48067858815193176, -0.36647841334342957, -0.21681688725948334, -0.7111331224441528, 0.7645432353019714, -0.16072697937488556, 0.5977975726127625, -0.054356180131435394, -1.1839470863342285, 0.2230808287858963, -0.19248639047145844, -0.7563928365707397, -0.2946317195892334, -0.04542910307645798, 1.161787986755371, -0.35044947266578674, -0.09210740029811859, -0.04193856939673424, -0.23474423587322235, -0.973783016204834, 1.1941927671432495, -0.7462409734725952, -0.19982388615608215, -0.12901052832603455, 0.05969976261258125, 0.09173046797513962, -0.47774916887283325, 0.29348036646842957, -0.29270315170288086, -0.2018631398677826, 0.6101739406585693, -0.37582889199256897, 1.0359748601913452, -0.3090495765209198, 0.4305760860443115, -0.35120105743408203, -0.4023797810077667, 0.7126392126083374, 0.08388989418745041, 0.16640730202198029, -0.6613287329673767, 0.19025857746601105, 0.4825822710990906, -1.0222402811050415, 0.13689644634723663, 0.9736955761909485, 0.26897165179252625, -0.6256970763206482, 0.14587247371673584, 0.5808109045028687, -0.05889492854475975, 0.5531400442123413, 0.1634521335363388, 0.5909143686294556, 0.7075859904289246, 0.4605220854282379, -0.17969048023223877, 0.40702736377716064, -0.23098918795585632, -0.1200878843665123, 0.49856749176979065, 0.8599551916122437, 0.9626619815826416, 0.4588112235069275, -0.8866488337516785, -0.5306940078735352, 0.2871902287006378, 0.35741427540779114, 1.720842719078064, 0.1669783741235733, -0.5444518327713013, -0.32426097989082336, -0.5917832851409912, 0.2874068319797516, 0.196537047624588, -0.8380609750747681, 0.007108216639608145, -0.37677571177482605, -1.0399868488311768, 0.16674448549747467, 0.4010814428329468, 0.8502605557441711, -0.6684545874595642, -0.032986000180244446, -0.3063320815563202, -0.030004385858774185, -0.4965199828147888, -0.7604358196258545, 0.7111878395080566, -0.28096306324005127, 0.31937095522880554, 0.16214419901371002, 0.07624311745166779, -0.07918321341276169, -0.6808428764343262, 1.1752840280532837, -0.5388075113296509, -0.16233409941196442, 0.03238831087946892, 0.2692098319530487, -0.49465471506118774, -0.6316347122192383, 0.43861639499664307, -0.03766659274697304, 0.12604345381259918, 0.6180720925331116, 0.9394991397857666, 0.4580615758895874, 0.7528181672096252, -0.3154742419719696, 0.3684024214744568, 0.13009428977966309, 0.683847188949585, 0.5304409861564636, -0.4364151358604431, -0.05983344092965126, -1.151503324508667, 0.645784318447113, -0.1063285693526268, -0.6278940439224243, 0.5106823444366455, -0.5024881958961487, -0.45313310623168945, 0.5309276580810547, -0.34801241755485535, -0.14695046842098236, -0.9127745032310486, 0.5088521242141724, -0.1189412847161293, -0.14785310626029968, 0.7135369777679443, 0.30081143975257874, 0.25997668504714966, 0.41848939657211304, 0.3752647340297699, 0.4892846941947937, -0.38706013560295105, 0.34937119483947754, -0.6443180441856384, 0.101396843791008, -0.03888578712940216, 0.26375946402549744, -0.25777289271354675, 0.06488674134016037, -0.20804210007190704, -0.9844991564750671, -0.4918639659881592, -0.7810677289962769, -0.22516736388206482, 0.17185337841510773, -0.1507488340139389, -0.962910532951355, -0.42968490719795227, -0.6143143177032471, -0.528874933719635, 0.16398312151432037, -0.67100989818573, -0.29661327600479126, -1.395391583442688, -0.9409759044647217, -0.6782556176185608, -0.18386241793632507, -0.5239996314048767, 0.2774428129196167, -0.06679854542016983, -0.4613339304924011, -0.5523953437805176, -0.3382653594017029, 0.19488243758678436, 0.7784760594367981, -0.3851981461048126, 1.0618460178375244, -0.004490279126912355, -0.44589734077453613, -0.3481452167034149, 0.1303924024105072, 0.41551870107650757, 0.2891063094139099, 0.09714725613594055, -0.26596975326538086, 0.23864434659481049, -0.4765584468841553, -1.0809229612350464, 0.1239192932844162, 0.2430756390094757, 0.919943630695343, 0.17522881925106049, -0.47544026374816895, 0.4207075536251068, 1.378307580947876, -0.3684385418891907, 0.126652792096138, 0.3927328586578369, 0.890579879283905, 0.49069833755493164, 0.25110599398612976, 0.7585350871086121, 0.1272524744272232, 0.8186231255531311, 0.006668242160230875, -0.039837077260017395, 0.07164913415908813, -0.727153480052948, 0.44969841837882996, 1.1569081544876099, 0.5456032156944275, -0.26997968554496765, -1.4991165399551392, 0.7297968864440918, -0.9015832543373108, -0.5240519046783447, 0.5068930983543396, 0.9805508852005005, 0.490372896194458, -0.23873645067214966, -0.2026287168264389, -0.3796495199203491, 0.17648981511592865, -0.081709124147892, -0.15746605396270752, -0.5468044877052307, 0.10410594195127487, 0.4245661497116089, 0.36204373836517334, 0.3871721625328064, -0.522773802280426, 0.4920010268688202, 14.895837783813477, 1.258043646812439, -0.15691128373146057, 0.32245710492134094, 0.9917341470718384, 0.26043224334716797, -0.16279944777488708, -0.5393015146255493, -1.505348801612854, -0.18678657710552216, 1.1371036767959595, -0.19100214540958405, 0.4530195891857147, 0.014754461124539375, -0.2689290940761566, 0.3150337040424347, -0.644985556602478, 0.6762900352478027, 0.6900293827056885, -1.4299094676971436, 0.505777895450592, 0.3883477747440338, 0.39198338985443115, -0.02053595334291458, 1.1346524953842163, 1.2006243467330933, 0.3845781683921814, -1.252842664718628, 0.6293880939483643, 0.13869674503803253, 1.154992699623108, 0.00565341068431735, 0.5131551623344421, 0.541765570640564, -0.45544925332069397, -0.23515334725379944, -0.9262963533401489, -0.9413486123085022, 0.04795747622847557, -0.5032613277435303, -0.9696336984634399, 0.1022493839263916, -0.17137476801872253, 0.851445198059082, 0.12843194603919983, 0.28298401832580566, 0.44241636991500854, 0.5447951555252075, 0.41672828793525696, -0.29575374722480774, 0.27239444851875305, 0.4247537851333618, -0.17309336364269257, -0.2384748011827469, 0.22088809311389923, -0.07228533923625946, -0.040868137031793594, 0.48074251413345337, -0.805515706539154, 0.5361963510513306, -0.15343888103961945, -0.021633297204971313, -0.2942192852497101, 0.8028077483177185, 0.6317178606987, 0.4522932171821594, -0.5529963374137878, 0.08087813854217529, 0.6174429655075073, -0.25073063373565674, -0.312347412109375, 0.2739734351634979, 0.20841310918331146, 0.02280755341053009, 0.32123440504074097, 0.7410126328468323, -0.738171398639679, -0.4718084931373596, -0.9114534854888916, -0.5328858494758606, 0.6927517056465149, -0.9283758401870728, -1.282925009727478, 0.9504912495613098, -0.3559679388999939, -0.9074753522872925, 0.3219037353992462, -1.2834168672561646, 0.4199972450733185, 0.6748369336128235, -0.8304436802864075, -0.3015138506889343, -0.21080994606018066, -0.48565244674682617, -0.13280780613422394, -0.16988202929496765, 1.2588505744934082, 0.21423257887363434, -0.30805161595344543, 0.08958745747804642, 0.4817606508731842, 0.12960565090179443, 0.348990261554718, -0.8630946278572083, 0.661797046661377, -0.4499768316745758, 0.01231018640100956, 0.35155022144317627, -0.18763896822929382, 0.016914786770939827, -0.619957447052002, -0.38184791803359985, 0.6039648056030273, -1.5263400077819824, -0.4026428759098053, -1.1531107425689697, -0.9515527486801147, 0.4411812424659729, 0.4868618845939636, -0.3901151418685913, 0.5640475749969482, 0.5819955468177795, -0.562309741973877, -0.452498197555542, -0.7096140384674072, 0.1195766031742096, 0.04347262904047966, -0.13301986455917358, -0.3263188898563385, -0.043811384588479996, 0.05555035173892975, -1.0329395532608032, -0.5422033667564392, -0.12181336432695389, 0.08010481297969818, -0.09131618589162827, 0.7279048562049866, -0.7752491235733032, 1.5440400838851929, 1.1192392110824585, -0.45942479372024536, -0.7594890594482422, -0.05914485454559326, -0.5101644396781921, 0.44045644998550415, 0.1563391536474228, 0.9931667447090149, -0.24963046610355377, 0.8955155611038208, 0.9036402702331543, 0.580960214138031, -0.6561174988746643, -0.36118391156196594, -0.3598176836967468, 0.5244995951652527, -0.0974971354007721, 0.27255794405937195, 0.2361857295036316, -0.06840687990188599, 0.23232096433639526, -0.1720290333032608, -0.22834640741348267, -0.5100898742675781, -0.45359206199645996, 0.7631244659423828, -0.14340758323669434, -0.04409678652882576, -0.17581810057163239, -0.15456810593605042, -1.8009480237960815, -0.14209896326065063, -1.1914584636688232, 0.2452724575996399, -0.9413700699806213, -0.25237733125686646, -0.03762654960155487, -0.21631768345832825, 0.28460603952407837, 0.6480059623718262, -0.32315778732299805, -0.4660474359989166, -0.6315745115280151, -0.4572658836841583, 0.9649472832679749, 1.1096869707107544, -0.6962465643882751, 0.4498547613620758, -0.0966227725148201, 0.009027853608131409, -0.3774034082889557, 0.40424656867980957, -0.5577118992805481, -0.4149818420410156, -0.8272700309753418, 0.07134724408388138, 0.5044403076171875, -0.43524256348609924, -0.6464834213256836, 0.39488685131073, -0.22611315548419952, 0.10763561725616455, -0.32917526364326477, 0.6198002696037292, -1.021841287612915, -0.657978355884552, 0.003000571858137846, -1.0631455183029175, -0.02841462939977646, 0.6084077954292297, -0.9214750528335571, -0.40881073474884033, 0.5186573266983032, 0.012338990345597267, -0.7954110503196716, -0.49509555101394653, 0.5661637187004089, -0.4894695580005646, 0.12410890311002731, -0.18186084926128387, -0.2552186846733093, -1.2353968620300293, -0.7770346403121948, 0.1359216868877411, 0.624121904373169, -0.3331727683544159, 1.0319877862930298, -0.01728970557451248, -1.3880188465118408, -0.019462788477540016, 0.10925783962011337, -0.021350063383579254, -0.24291805922985077, 0.40298447012901306, 0.2971091568470001, -0.4515255093574524, 0.830159068107605, -0.4261462390422821, 0.5928634405136108, -0.8649608492851257, 0.3816024363040924, 0.9239974617958069, -0.4190185070037842, 0.16411300003528595, 1.0759843587875366, -0.2932303845882416, -1.2069180011749268, 0.11263210326433182, -0.8663942813873291, -0.45162689685821533, -0.12184684723615646, 0.3538530170917511, -0.0032329242676496506, 0.19546042382717133, -0.11805988103151321, -0.37707141041755676, -0.018996328115463257, -0.10464156419038773, -0.2729088366031647, 0.5675219297409058, -0.08987845480442047, -0.4926183819770813, 1.1782002449035645, 1.007035732269287, -0.4022515118122101, -0.4569927155971527, -0.5840706825256348, -0.09180404245853424, -0.4242514371871948, -0.1996854543685913, -0.9797605276107788, -0.25624045729637146, 0.7779763340950012, -0.09073103964328766, 0.5305526256561279, 0.1529119461774826, -0.38314253091812134, 0.16443896293640137, 0.5221251249313354, 0.3082653284072876, -0.4582686126232147, -0.11883185058832169, 1.393361210823059, 1.4224873781204224, -1.1300458908081055, 0.21250233054161072, -0.5702812075614929, -0.850602924823761, 1.171655535697937, 0.8211451172828674, 0.43462663888931274, 0.6122718453407288, -0.42283883690834045, 0.228938028216362, 0.287718802690506, -1.5484511852264404, 0.07597850263118744, 1.2256590127944946, 0.7759401202201843, 0.9408549666404724, 0.10214979946613312, 0.19292160868644714, 0.8762845396995544, -0.26295122504234314, 0.055704791098833084, 0.5776959657669067, 0.20400366187095642, -0.24976202845573425, -0.26341745257377625, -0.2510402798652649, 0.8644213080406189, -0.45690059661865234, -0.4515010714530945, -0.10242591798305511, 0.7999997735023499, 0.1869771033525467, 0.45797887444496155, 0.7855188846588135, -0.332260400056839, 0.6926127672195435, 0.5065293908119202, 0.13622520864009857, -0.740857720375061, -0.4591241478919983, -0.45795178413391113, -0.5968904495239258, 0.22847461700439453, 0.20472121238708496, -0.6116876006126404, -0.1884230673313141, -0.5620916485786438, 0.7393498420715332, 0.011298309080302715, -0.10047167539596558, 1.026620626449585, 0.24003329873085022, 0.17505145072937012, -0.3925143778324127, 0.09451919049024582, -0.5584684014320374, -0.9588879942893982, -0.2504146695137024, -0.3643050491809845, -0.22842220962047577, -0.5171838998794556, 0.2260996699333191, -0.23093801736831665]}, "authors": [{"authorId": "2262139047", "name": "Josh Gardner"}, {"authorId": "2307084499", "name": "Juan C. Perdomo"}, {"authorId": "2262137823", "name": "Ludwig Schmidt"}], "references": [{"paperId": "f89ba7a675769d6c4c2ee2b9f967fad34e6f971a", "title": "Why Tabular Foundation Models Should Be a Research Priority"}, {"paperId": "feca496290013a250adb2c72ecd20c8d5fd30f24", "title": "OpenGraph: Towards Open Graph Foundation Models"}, {"paperId": "5e71d0e85f65a1c0fb2af7bff281209122c58932", "title": "When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method"}, {"paperId": "659fe890e963c574c083f1b60754a071d945b5b2", "title": "CARTE: pretraining and transfer for tabular learning"}, {"paperId": "1f2a20a6efaf83214861dddae4a38a83ae18fe32", "title": "DeepSeek-Coder: When the Large Language Model Meets Programming - The Rise of Code Intelligence"}, {"paperId": "3bad8a3b6f4e361b23802cdad0cad92a28513ccc", "title": "Scaling Laws for Forgetting When Fine-Tuning Large Language Models"}, {"paperId": "1d16f8d30daa934154649b56cc02162cd6c5c4cc", "title": "Benchmarking Distribution Shift in Tabular Data with TableShift"}, {"paperId": "17a6116e5bbd8b87082cbb2e795885567300c483", "title": "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting"}, {"paperId": "a994b90a982e622dfb473a9c7a51b1993f12f511", "title": "Tabular Representation, Noisy Operators, and Impacts on Table Structure Understanding Tasks in LLMs"}, {"paperId": "d395c771f6537259610497ba218cce5b9bfc2c50", "title": "In-Context Pretraining: Language Modeling Beyond Document Boundaries"}, {"paperId": "f45f85fa1beaa795c24c4ff86f1f2deece72252f", "title": "A decoder-only foundation model for time-series forecasting"}, {"paperId": "263c3403b634065a7a0e0dc455e2c7764ba8fe50", "title": "TabLib: A Dataset of 627M Tables with Context"}, {"paperId": "a2fc6b0ecee77b61586aad7efcedbb5f468b1d21", "title": "From Supervised to Generative: A Novel Paradigm for Tabular Deep Learning with Large Language Models"}, {"paperId": "123acfbccca0460171b6b06a4012dbb991cde55b", "title": "Large Language Models Are Zero-Shot Time Series Forecasters"}, {"paperId": "32b15b02bd2640346678a773079c5d42190bbac9", "title": "TimeGPT-1"}, {"paperId": "0b0debb710366cdff461938c80763eace1651af6", "title": "Code Llama: Open Foundation Models for Code"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "ce913026f693101e54d3ab9152e107034d81fce1", "title": "Holistic Evaluation of Language Models"}, {"paperId": "5e4125b3a2ec91e866d970498f8a138c5a5cc89b", "title": "When Do Neural Nets Outperform Boosted Trees on Tabular Data?"}, {"paperId": "777317e5af8742b30408e98778fa067750e69f78", "title": "Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "a02fbaf22237a1aedacb1320b6007cd70c1fe6ec", "title": "Robust Speech Recognition via Large-Scale Weak Supervision"}, {"paperId": "746d7f8b5cb203adf06cd3a57cfbc09ca0f434c0", "title": "Subgroup Robustness Grows On Trees: An Empirical Baseline Investigation"}, {"paperId": "e76368389e5448ec4b82fe8c67f3490874ed7c4e", "title": "Two-stage LLM Fine-tuning with Less Specialization and More Generalization"}, {"paperId": "9dcee248452d84b6bf26911ba6726ae5ce1a46f3", "title": "TabLLM: Few-shot Classification of Tabular Data with Large Language Models"}, {"paperId": "e5c8960eb2ec034ffbd353ef39fd1cb541d3c7c9", "title": "LAION-5B: An open large-scale dataset for training next generation image-text models"}, {"paperId": "28630034bb29760df01ab033b743e30b37f336ae", "title": "PaLI: A Jointly-Scaled Multilingual Language-Image Model"}, {"paperId": "de32da8f5c6a50a6c311e9357ba16aa7d05a1bc9", "title": "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes"}, {"paperId": "ef4a99f703bd6c51f86056313716c39ea48baeb8", "title": "Why do tree-based models still outperform deep learning on tabular data?"}, {"paperId": "4c4f0fcf1ce04f12290d8c876abfbe57817de430", "title": "TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second"}, {"paperId": "1243e13254bb4ea1f71b4be8a3e4e54ffd02d2fe", "title": "Scaling Autoregressive Models for Content-Rich Text-to-Image Generation"}, {"paperId": "b92628d13e8d090d042232fe6ae0b8998634b893", "title": "LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "5f19ae1135a9500940978104ec15a5b8751bc7d2", "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models"}, {"paperId": "f4df78183261538e718066331898ee5cad7cad05", "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"}, {"paperId": "f9838a3be5c94bb2674a0e224de349b50e18f3c4", "title": "Learning To Retrieve Prompts for In-Context Learning"}, {"paperId": "344643acca0db56a4f7a65c4979e6313c427975c", "title": "JUWELS Cluster and Booster: Exascale Pathfinder with Modular Supercomputing Architecture at Juelich Supercomputing Centre"}, {"paperId": "3acff13163f51765bb36147f6107967765509d9b", "title": "Deep Neural Networks and Tabular Data: A Survey"}, {"paperId": "5fa06d856ba6ae9cd1366888f8134d7fd0db75b9", "title": "Revisiting Deep Learning Models for Tabular Data"}, {"paperId": "009560d2710138a446e6e254d8ddcb65eaa0e687", "title": "Tabular Data: Deep Learning is Not All You Need"}, {"paperId": "5fa2103e36b3e76e49edb8433a1206a6b25e3ead", "title": "SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training"}, {"paperId": "0adec918885dff698acf359988ed79a543157f80", "title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"}, {"paperId": "ce9ca56036307217ea565644d3d3bd74b879e045", "title": "Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "4383a975c09b72ba2f1a77cd779bb6965dbfb2fb", "title": "Scaling Laws for Transfer"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "a75649771901a4881b44c0ceafa469fcc6e6f968", "title": "How Can We Know What Language Models Know?"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "0e4f02c49b9d5ec13ab389a47adc4831cb7bac07", "title": "Introduction to the Special Collection on the Fragile Families Challenge"}, {"paperId": "7365f887c938ca21a6adbef08b5a520ebbd4638f", "title": "Model Cards for Model Reporting"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "d03e451db07f764a0294d44aec13a5993d927790", "title": "OpenML Benchmarking Suites"}, {"paperId": "ee0a0f04d45f86bf50b24d7258e884725fcaa621", "title": "CatBoost: unbiased boosting with categorical features"}, {"paperId": "26bc9195c6343e4d7f434dd65b4ad67efe2be27a", "title": "XGBoost: A Scalable Tree Boosting System"}, {"paperId": "1f3d3aaa4e33aee616ee7fbf1bb7ad40ca7ff5f1", "title": "UniPredict: Large Language Models are Universal Tabular Predictors"}, {"paperId": "85cac89ba01a07f3dbf6dbb1e0c56067a3105714", "title": "CROSS-CONTAMINATION: ACCELERATING LARGE LANGUAGE MODELS WITHOUT IMPACTING PERFORMANCE"}, {"paperId": "40cc6c7d159823e9393f2399537675706c0b419a", "title": "Multimodal AutoML on Structured Tables with Text Fields"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Fasttext"}, {"paperId": "8e0be569ea77b8cb29bb0e8b031887630fe7a96c", "title": "Random Forests"}, {"paperId": null, "title": "Meta Llama 3 Team. Introducing meta llama 3: The most capable openly available llm to date"}, {"paperId": null, "title": "OpenML-CTR23 \u2013 a curated tabular regression benchmarking suite"}, {"paperId": null, "title": "Gemini: a family of highly capable multimodal models"}, {"paperId": null, "title": "OpenAI GPT-4 Team"}, {"paperId": null, "title": "Others are free to build on the dataset as long as they adhere to the original terms of use put forth [13]"}]}