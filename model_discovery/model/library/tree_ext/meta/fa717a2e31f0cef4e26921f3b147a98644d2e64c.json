{"paperId": "fa717a2e31f0cef4e26921f3b147a98644d2e64c", "title": "Focal Modulation Networks", "abstract": "We propose focal modulation networks (FocalNets in short), where self-attention (SA) is completely replaced by a focal modulation mechanism for modeling token interactions in vision. Focal modulation comprises three components: (i) hierarchical contextualization, implemented using a stack of depth-wise convolutional layers, to encode visual contexts from short to long ranges, (ii) gated aggregation to selectively gather contexts for each query token based on its content, and (iii) element-wise modulation or affine transformation to inject the aggregated context into the query. Extensive experiments show FocalNets outperform the state-of-the-art SA counterparts (e.g., Swin and Focal Transformers) with similar computational costs on the tasks of image classification, object detection, and segmentation. Specifically, FocalNets with tiny and base size achieve 82.3% and 83.9% top-1 accuracy on ImageNet-1K. After pretrained on ImageNet-22K in 224 resolution, it attains 86.5% and 87.3% top-1 accuracy when finetuned with resolution 224 and 384, respectively. When transferred to downstream tasks, FocalNets exhibit clear superiority. For object detection with Mask R-CNN, FocalNet base trained with 1\\times outperforms the Swin counterpart by 2.1 points and already surpasses Swin trained with 3\\times schedule (49.0 v.s. 48.5). For semantic segmentation with UPerNet, FocalNet base at single-scale outperforms Swin by 2.4, and beats Swin at multi-scale (50.5 v.s. 49.7). Using large FocalNet and Mask2former, we achieve 58.5 mIoU for ADE20K semantic segmentation, and 57.9 PQ for COCO Panoptic Segmentation. Using huge FocalNet and DINO, we achieved 64.3 and 64.4 mAP on COCO minival and test-dev, respectively, establishing new SoTA on top of much larger attention-based models like Swinv2-G and BEIT-3. Code and checkpoints are available at https://github.com/microsoft/FocalNet.", "venue": "Neural Information Processing Systems", "year": 2022, "citationCount": 147, "influentialCitationCount": 20, "openAccessPdf": {"url": "https://arxiv.org/pdf/2203.11926", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "Focal modulation networks (FocalNets in short), where self-attention is completely replaced by a focal modulation mechanism for modeling token interactions in vision, exhibit clear superiority on the tasks of image classification, object detection, and segmentation."}, "embedding": {"model": "specter_v2", "vector": [0.6134571433067322, 0.1789509803056717, -0.7162438631057739, -0.1003442034125328, -0.3171502351760864, -0.010994108393788338, 1.163516879081726, -0.6787142753601074, -0.41283223032951355, -0.29184195399284363, 0.5504488945007324, 0.7942165732383728, 0.36936694383621216, -0.11105653643608093, -0.20099562406539917, -0.04733603447675705, -0.8194347023963928, -0.40691566467285156, 0.6840253472328186, -0.23824264109134674, 0.3361141085624695, -0.49506282806396484, -1.2827714681625366, 0.5415735840797424, -0.09304987639188766, 0.8153820037841797, 0.5590701103210449, 1.2677334547042847, -0.2042943239212036, 0.11821244657039642, -0.018213951960206032, 0.30682095885276794, 0.38045433163642883, 0.07557497173547745, -0.2261984795331955, 0.2582607567310333, 0.7256182432174683, -0.32335448265075684, -0.7606626152992249, 0.7160267233848572, -0.15121860802173615, 0.1988902986049652, 0.39671698212623596, -0.4009060859680176, -0.24986889958381653, 0.6933061480522156, 0.7221183180809021, 1.0692857503890991, -0.7614568471908569, -0.19190002977848053, 1.0755951404571533, -1.2780109643936157, 0.5102454423904419, 1.574386477470398, -0.016839411109685898, 0.4856841266155243, -0.20619472861289978, -0.35940971970558167, 0.8540923595428467, 0.6072362065315247, -0.5428979396820068, -0.3794500231742859, -0.03019740991294384, -0.13422198593616486, 1.622372031211853, -0.3546534776687622, 0.3004116714000702, 0.6158552765846252, 0.2256380319595337, 1.3145469427108765, -0.03281030431389809, -0.846006453037262, -0.41775187849998474, -0.14487291872501373, 0.35235700011253357, 0.5050631761550903, -0.20244918763637543, 0.48675674200057983, -1.0314052104949951, 0.3977087438106537, 0.7041125893592834, 0.3893166184425354, 0.21379974484443665, 0.30311119556427, -0.624182939529419, 0.6183360815048218, 0.9859232306480408, 0.9683237671852112, -0.4652242362499237, 1.2840819358825684, 0.4144522547721863, 0.01709359884262085, -0.10843978822231293, 0.45684123039245605, 0.107766292989254, 0.7465511560440063, -0.9275297522544861, 0.33598220348358154, -0.36406368017196655, 0.9570647478103638, 0.31905582547187805, 0.19366079568862915, -0.7805123329162598, -0.05760124698281288, 1.3055121898651123, -0.011880370788276196, 0.4401800036430359, -1.054776906967163, -0.2591690123081207, -0.5822585225105286, 0.021582167595624924, -0.7705518007278442, 0.04068056121468544, -0.46221449971199036, -0.46492311358451843, -0.9382147789001465, -0.46990418434143066, 0.3788701593875885, -0.9636279344558716, 0.6755327582359314, -0.2931109070777893, 0.37974032759666443, -0.25802695751190186, 0.5541578531265259, 0.5048335790634155, 0.39175695180892944, 0.358350932598114, 0.3355705142021179, 1.1889358758926392, -1.2985775470733643, -0.46116936206817627, -0.8975547552108765, 0.04740166291594505, -0.36372244358062744, 0.06707272678613663, -0.4162449836730957, -1.048864722251892, -1.1444623470306396, -1.1729625463485718, 0.12413778901100159, -1.1006518602371216, -0.2339780479669571, 0.9956609606742859, 0.3327939510345459, -0.8022437691688538, 0.5710504651069641, -0.532803475856781, -0.26103928685188293, 0.7849718332290649, 0.0647294744849205, 0.6187502145767212, -0.09381363540887833, -1.4893174171447754, 0.3960748016834259, 0.13084685802459717, -0.4294719696044922, -0.7353484034538269, -0.7707886099815369, -0.8559597730636597, -0.13976509869098663, 0.5106069445610046, -0.7832853198051453, 1.203479528427124, -0.46363565325737, -0.6858440637588501, 0.6977828145027161, -0.2398308366537094, -0.08819275349378586, 0.32603350281715393, -0.46050330996513367, -0.31972312927246094, 0.3797025978565216, 0.2171657830476761, 1.107264518737793, 0.8121346831321716, -0.266670286655426, -0.24885348975658417, 0.04737381637096405, 0.022930970415472984, -0.17635582387447357, -0.23665989935398102, 0.8138237595558167, -0.5414997935295105, -0.20845958590507507, -0.005356951151043177, 0.8251772522926331, -0.28965994715690613, -0.28110435605049133, -0.31299954652786255, -0.6813997030258179, 1.3626914024353027, 0.547140896320343, 0.8535208106040955, -0.9374620318412781, -1.0263047218322754, -0.20994535088539124, -0.018938029184937477, -0.10560291260480881, -0.777795672416687, 0.18941275775432587, -0.015297211706638336, 0.35401445627212524, 0.015350702218711376, -0.7857458591461182, 0.10746339708566666, -0.16596347093582153, -0.6280856728553772, -0.2554769814014435, 0.4170362949371338, 1.3849858045578003, -0.6359726190567017, -0.28759264945983887, 0.23610813915729523, 0.4172123074531555, -0.9185618162155151, 0.8726702332496643, -0.8187552690505981, 0.06080694869160652, -0.09963914006948471, 0.3500252962112427, -0.249276801943779, -0.38128215074539185, 0.2760728597640991, -0.6571763157844543, -0.13032501935958862, 0.411655992269516, -0.39172011613845825, 1.289575219154358, -0.2529292404651642, 0.7589395046234131, 0.14802290499210358, -0.7098875045776367, -0.0856391116976738, 0.01599310338497162, -0.16371281445026398, -0.5912397503852844, 0.3213229477405548, -0.07719944417476654, -0.7926710247993469, 0.145308256149292, 1.1379647254943848, 1.1051108837127686, -0.43914204835891724, -0.2215266078710556, 0.8054067492485046, -0.3098076283931732, 0.30845579504966736, 0.5078612565994263, 0.5452532172203064, 0.2801067531108856, 0.1507743000984192, -0.41688334941864014, -0.27215519547462463, -0.8481128811836243, -0.2826683819293976, 0.9195153713226318, 0.23162119090557098, 1.0142613649368286, 0.4983314275741577, -0.6478146910667419, -0.4107513725757599, 0.23149441182613373, 0.25431111454963684, 1.636080026626587, 0.18123331665992737, -0.14634990692138672, -1.0382541418075562, -0.43400895595550537, -0.6280531883239746, -0.6311548352241516, -0.820736289024353, -0.09880378842353821, -0.5288994312286377, -1.0909417867660522, 0.9910377860069275, 0.381043940782547, 1.449039101600647, -1.0030333995819092, -0.8609037399291992, -0.21141456067562103, 0.5111381411552429, -0.8805307745933533, -0.7110257744789124, 0.21768571436405182, -0.1008920967578888, -0.29924920201301575, 0.20947924256324768, -0.21605508029460907, -0.08703741431236267, -0.17370161414146423, 0.9760960340499878, -0.2622969448566437, -0.7344995141029358, 0.5848895907402039, 0.547426700592041, -0.686791181564331, -0.311604380607605, 0.5142555832862854, -0.05429660901427269, 0.11404978483915329, 0.2621132433414459, 0.36863622069358826, -0.7859562635421753, 0.6006192564964294, -0.9972192645072937, -0.3994092047214508, 0.014776064082980156, 0.10129934549331665, 0.9738612174987793, -0.5650779008865356, 0.5431808829307556, -1.289101243019104, 0.11441922932863235, -0.18084043264389038, -0.3875824809074402, -0.01861437037587166, -0.5155585408210754, -0.9092569947242737, -0.1366748809814453, -0.5864244699478149, -0.06276106834411621, -0.9639716744422913, 0.7751208543777466, -0.5992974638938904, -0.4774799644947052, -0.03836540877819061, -0.07784948498010635, -0.1268203854560852, 0.7200976014137268, 0.154316246509552, -0.20847880840301514, 0.4235374927520752, 0.8584893941879272, -0.8720340728759766, 0.6722068190574646, 0.36808252334594727, -0.26989734172821045, 0.5041326880455017, 0.01638857275247574, -1.2104681730270386, -0.5809476375579834, -0.49245354533195496, -0.48386943340301514, -0.6459941267967224, 0.6675404906272888, -0.46912986040115356, -0.5723475217819214, 0.2431054711341858, -0.9337584972381592, -0.4329947531223297, 0.010743239894509315, -0.5638136267662048, -0.5321058630943298, -1.1848934888839722, -0.7915067672729492, -0.26961418986320496, -0.3948657512664795, -0.8830261826515198, 0.39750486612319946, 0.4313378930091858, -0.45465826988220215, -0.8002810478210449, -0.4440392553806305, -0.42399919033050537, 1.3583837747573853, -0.047972001135349274, 0.29731109738349915, 0.08826860040426254, -0.9833550453186035, -0.2714272439479828, -0.18863889575004578, 0.4622246026992798, -0.244024395942688, 0.24374300241470337, -1.0847090482711792, 0.5947064757347107, -0.2116280347108841, -0.15547727048397064, 0.9103617072105408, 0.7893134355545044, 0.6401487588882446, 0.23054441809654236, -0.7267662882804871, 0.5342209339141846, 1.3906856775283813, -0.7018284797668457, 0.3388923406600952, 0.2863854169845581, 0.82919842004776, 0.09330683946609497, -0.2061765342950821, 0.27521800994873047, 0.24050866067409515, 0.14235177636146545, 0.7281923294067383, -0.10411319881677628, -0.5723481178283691, -0.5114626288414001, 0.22614754736423492, 0.8057926297187805, 0.398020476102829, 0.2336791455745697, -0.503839910030365, 1.2414276599884033, -1.2765558958053589, -0.8337927460670471, 1.033976674079895, 0.47158128023147583, -0.13538475334644318, -0.4467417001724243, -0.09017111361026764, -0.501215934753418, 0.8420663475990295, 0.7386900782585144, -0.7358116507530212, -0.2247396558523178, -0.493658185005188, 0.3452855944633484, 0.10513968765735626, 0.7207217812538147, -0.6985312104225159, 0.8244794607162476, 14.670753479003906, 0.8086615204811096, -0.4949207007884979, 0.7251600027084351, 0.8169379830360413, 0.020096486434340477, -0.1612483114004135, -0.06504116952419281, -1.4477224349975586, -0.027903731912374496, 0.9868168234825134, 0.6356027126312256, 0.16139686107635498, 0.21463367342948914, -0.1323939710855484, 0.11200803518295288, -0.16088882088661194, 0.3890637755393982, 0.42609861493110657, -1.5798710584640503, 0.22977161407470703, 0.09305710345506668, 0.8010638356208801, 0.8248484134674072, 1.126893162727356, 0.4125002920627594, 0.21588367223739624, -0.6508813500404358, 0.24016456305980682, 0.4131450653076172, 1.2241084575653076, 0.20989163219928741, -0.006814535707235336, -0.05395250394940376, -0.9787406921386719, -0.14993101358413696, -0.5605834126472473, -0.8202585577964783, 0.2115139216184616, -0.1310596466064453, -0.0006475668051280081, -0.6532481908798218, -0.07992188632488251, 0.7742334604263306, 0.2498585432767868, 0.29583707451820374, -0.04738244414329529, 0.4618908762931824, 0.06936337798833847, 0.007437821943312883, 0.8122783899307251, 0.912476122379303, 0.25602805614471436, 0.6617476940155029, -0.38467761874198914, 0.16173864901065826, 0.2501354217529297, 0.6881532073020935, -0.5597081780433655, -0.40322306752204895, -0.4456806480884552, -0.09035149216651917, -0.12123969942331314, 1.1898646354675293, 0.08066580444574356, -0.08326800912618637, -0.3302028477191925, 0.11507340520620346, -0.18131829798221588, 0.20781564712524414, -0.3684822618961334, -0.33039650321006775, 0.41846609115600586, -0.00013866899826098233, 0.3913259208202362, 0.37074902653694153, -0.41054925322532654, -0.4401499927043915, -0.9519806504249573, 0.1910923570394516, 0.26089584827423096, -0.7252232432365417, -0.5808578133583069, 1.0284092426300049, 0.10054057091474533, -0.1008882150053978, 0.35395070910453796, -0.9579393863677979, -0.5470896363258362, 0.200877383351326, -1.5655184984207153, -0.8963557481765747, 0.02156819961965084, -0.18413706123828888, -0.11574047803878784, 0.042627666145563126, 0.746401846408844, 0.22748945653438568, 0.014410286210477352, 0.031786464154720306, -0.6019999384880066, -0.1472937911748886, -0.057673510164022446, -0.8423089385032654, 0.6247826218605042, 0.2462746500968933, -0.08811745792627335, 0.07422544062137604, -0.12876750528812408, 0.4657365679740906, -0.2382025122642517, -0.1484268754720688, 0.16968828439712524, -0.856268048286438, -0.5102155804634094, -0.5008282661437988, -0.6610399484634399, 0.28566354513168335, 1.024672508239746, 0.2628379464149475, 0.24990332126617432, -0.24662284553050995, -0.40796348452568054, -0.012224688194692135, -0.9491993188858032, 0.05789472907781601, 0.6083303689956665, -0.4858798086643219, -0.4196428954601288, -0.24551571905612946, 0.6781806349754333, -0.7729230523109436, -0.43259337544441223, -0.2146204262971878, 0.3559497594833374, -0.36447590589523315, 1.1199159622192383, -0.5425562262535095, 0.7301660776138306, 0.7880343794822693, -0.7590445876121521, -0.7049949169158936, -0.06504271179437637, -1.0362122058868408, 0.04343530908226967, 0.26981276273727417, 0.33860117197036743, -0.29836592078208923, 0.13632942736148834, 0.4590478539466858, 0.11977306753396988, -0.7946746349334717, -0.4914223849773407, 0.14169156551361084, 0.07949411123991013, -0.7035879492759705, 0.5777587294578552, 0.07399871945381165, -0.31323179602622986, 0.13038985431194305, 0.6798207759857178, 0.38570067286491394, 0.014097634702920914, -0.5718473792076111, 0.15204055607318878, 0.2887030839920044, -0.05540068820118904, -0.6336802840232849, -1.0120748281478882, -1.5817394256591797, -0.17679305374622345, -0.9031571745872498, -0.2593598961830139, -0.5947955846786499, -0.4912620484828949, 0.4092922806739807, -0.6522003412246704, -0.20873893797397614, 0.18659938871860504, 0.3743007183074951, -0.16578015685081482, -0.8159614205360413, -0.9417632818222046, 0.5354464054107666, 1.2876185178756714, -0.6757799983024597, 0.11301468312740326, -0.14922687411308289, -0.480525404214859, 0.5976759791374207, 0.2972366511821747, -0.018949834629893303, -0.36810898780822754, -1.0678187608718872, -0.098253034055233, -0.3423290252685547, 0.27186480164527893, -0.7863677144050598, 0.7258846759796143, 0.5993265509605408, 0.06836800277233124, 0.023998789489269257, 0.3962310254573822, -0.4950719475746155, -0.9032109379768372, 0.153321772813797, -0.5833983421325684, -0.11906776577234268, 0.04522034525871277, -0.5058907866477966, -0.3335038721561432, 0.9848750233650208, 0.34939342737197876, -1.3199504613876343, -0.9802871346473694, 0.4962346851825714, -0.7360902428627014, -0.012674191035330296, -0.3091171979904175, -0.297711044549942, -1.3558348417282104, -0.29877394437789917, -0.4908759891986847, 0.31266453862190247, -0.6222029328346252, 0.8746351599693298, 0.5337972640991211, -1.3292129039764404, 0.16454321146011353, 0.26525765657424927, -0.3215632438659668, 0.3614501655101776, 0.7674582600593567, 0.40310001373291016, -0.14361706376075745, 0.7815636396408081, -0.01905161514878273, -0.02321871928870678, -0.5618386268615723, 0.06575138866901398, 1.1113409996032715, -0.1292056143283844, 0.10730927437543869, 0.955295205116272, 0.32254865765571594, -0.5795220136642456, 0.03302828595042229, -1.0932430028915405, -0.4820449948310852, 0.17986084520816803, 0.8249481320381165, 0.37959128618240356, -0.24916942417621613, -0.04976450279355049, -0.3528038263320923, 0.5918306112289429, -0.1790502369403839, -0.6209844946861267, 0.47080227732658386, -0.30639150738716125, -0.31514039635658264, 0.5895673036575317, 0.6164477467536926, -0.8998381495475769, -1.1981019973754883, -1.1130894422531128, -0.478533536195755, -0.26984837651252747, 0.15223953127861023, -0.3984670639038086, -0.6149560809135437, 0.7790014147758484, 0.5889844298362732, 0.7670104503631592, 0.30563870072364807, 0.23878951370716095, 0.13302087783813477, 0.3696734607219696, -0.3489224910736084, -0.5298840403556824, -0.1391810178756714, 1.0241179466247559, 1.1964510679244995, -0.49500760436058044, 0.11927004158496857, -0.12138719856739044, -0.2524698078632355, 0.7316603064537048, 0.5606790781021118, -0.7466732859611511, 1.071166753768921, -0.21340486407279968, 0.35561925172805786, 0.1289495825767517, -1.2605713605880737, -0.38464492559432983, 0.47156986594200134, 1.0717519521713257, 0.10706519335508347, 0.29752177000045776, 0.16979269683361053, 0.8869683742523193, 0.4508655369281769, -0.20696716010570526, 0.44494348764419556, 0.261525422334671, -0.5394935607910156, 0.2509816586971283, -0.23065687716007233, 0.5256797075271606, -1.0366777181625366, -0.26157259941101074, 0.034776266664266586, 0.5726584196090698, 0.4513278305530548, 0.4976368248462677, 1.0341912508010864, 0.08816730976104736, 0.4856601357460022, 0.0914437398314476, 0.742903470993042, -0.5759701132774353, -0.23433338105678558, 0.25038832426071167, -0.9685909152030945, -0.24933582544326782, -0.7381280064582825, -0.7097269296646118, -0.13094009459018707, 0.13475251197814941, 0.15499716997146606, -0.573985755443573, 0.5946133732795715, 1.1472599506378174, 0.8174341917037964, 0.896395206451416, -0.20999234914779663, -1.242903232574463, -0.033447179943323135, -1.1674286127090454, 0.2934809923171997, -0.6097806096076965, 0.015337910503149033, -0.5639964938163757, 0.018159957602620125, -0.12172672152519226]}, "authors": [{"authorId": "120157163", "name": "Jianwei Yang"}, {"authorId": null, "name": "Chunyuan Li"}, {"authorId": "48441311", "name": "Jianfeng Gao"}], "references": [{"paperId": "02251886950770e82b3d68564d60cdfe15e73199", "title": "Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks"}, {"paperId": "5c4f8de98525eebd762773093d149ba459cef290", "title": "Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via Feature Distillation"}, {"paperId": "c431408780586268e8bcf2483b01a80728d10960", "title": "Vision Transformer Adapter for Dense Predictions"}, {"paperId": "aa8611fd47415740470c3947595d25b906d56112", "title": "ELEVATER: A Benchmark and Toolkit for Evaluating Language-Augmented Visual Models"}, {"paperId": "5e76879aaea118b532fb24a50b721076d4c6ae93", "title": "Unified Contrastive Learning in Image-Text-Label Space"}, {"paperId": "259c681c76335540e13081efad584efdf9101868", "title": "DaViT: Dual Attention Vision Transformers"}, {"paperId": "1504ab3e1ae7af39bbf3dba62b132ec027611c38", "title": "MixFormer: Mixing Features across Windows and Dimensions"}, {"paperId": "9dc481ec44178e797466bbad968071917842156b", "title": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection"}, {"paperId": "ba637c4f1a170f1e2dadeadb71a63cf2b9a46de2", "title": "Visual attention network"}, {"paperId": "3d5daaa51a8ac3ebca1f823866184fa4ee4d0b0f", "title": "Mixing and Shifting: Exploiting Global and Local Dependencies in Vision MLPs"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "c78ffe94ad3d5b41595ab6474a924c429f1420a6", "title": "Augmenting Convolutional networks with attention-based aggregation"}, {"paperId": "756b1a89ddcc71ac445af250f4f35f07de8f2318", "title": "SeMask: Semantically Masked Transformers for Semantic Segmentation"}, {"paperId": "15b0e710a9b8069d898ae6a0963d627e0fb86bd8", "title": "MPViT: Multi-Path Vision Transformer for Dense Prediction"}, {"paperId": "c2a0c18e810535db52e5ebaf180c64ce70356748", "title": "A-ViT: Adaptive Tokens for Efficient Vision Transformer"}, {"paperId": "5341b412383c43f4a693ad63ec4489e3ec7688c8", "title": "Grounded Language-Image Pre-training"}, {"paperId": "658a017302d29e4acf4ca789cb5d9f27983717ff", "title": "Masked-attention Mask Transformer for Universal Image Segmentation"}, {"paperId": "38212997a6e8c55141574c329bb58d2eadcb0db5", "title": "AdaViT: Adaptive Vision Transformers for Efficient Image Recognition"}, {"paperId": "b476c932e959cfe645911786f1a070c70b5375c6", "title": "An Image Patch is a Wave: Phase-Aware Vision MLP"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "21ec90872abd986c12afe39bebe807732ffa70c9", "title": "Florence: A New Foundation Model for Computer Vision"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "f454f6b5f2ca9749ddf442eb5134612ef7f758c1", "title": "ResNet strikes back: An improved training procedure in timm"}, {"paperId": "485c08025157973bb52a935c6aa3bee74f990c01", "title": "Sparse MLP for Image Recognition: Is Self-Attention Really Necessary?"}, {"paperId": "ca30f4371367f07a17ba42d9dab76cac1d9fd943", "title": "Panoptic SegFormer: Delving Deeper into Panoptic Segmentation with Transformers"}, {"paperId": "58970a426b687bb080b7fed3b4b78ab1ebaa56f4", "title": "Hire-MLP: Vision MLP via Hierarchical Rearrangement"}, {"paperId": "fd547648ded5dd4c45a3594b398844876d93c339", "title": "S2-MLPv2: Improved Spatial-Shift MLP Architecture for Vision"}, {"paperId": "f75cddf2d42ed01b34686704eb3504becef67442", "title": "CycleMLP: A MLP-like Architecture for Dense Prediction"}, {"paperId": "71363797140647ebb3f540584de0a8758d2f7aa2", "title": "AS-MLP: An Axial Shifted MLP Architecture for Vision"}, {"paperId": "0b036cd5dfc49d835d0c759c8ca31d89f2410e65", "title": "CMT: Convolutional Neural Networks Meet Vision Transformers"}, {"paperId": "260ad39a1dac4b451019e2bf17925f4df8e3b69a", "title": "Per-Pixel Classification is Not All You Need for Semantic Segmentation"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "48418b285a92376a38daafa664a2dd07d42e3fe3", "title": "Focal Self-attention for Local-Global Interactions in Vision Transformers"}, {"paperId": "262654ac1d13cf8d8b204594f4a88d3e04f3dd37", "title": "K-Net: Towards Unified Image Segmentation"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "1fb10189c500e4902cd1b5afd406f57323d21be8", "title": "VOLO: Vision Outlooker for Visual Recognition"}, {"paperId": "2435ffb8ed3212156d6b6f19f633a861399cf30e", "title": "Vision Permutator: A Permutable MLP-Like Architecture for Visual Recognition"}, {"paperId": "fd51da088c5fe89eba0e363edad746bb3c2407d1", "title": "End-to-End Semi-Supervised Object Detection with Soft Teacher"}, {"paperId": "8602fd5b0ac73bb422f238b265479f363c0ffe61", "title": "Refiner: Refining Self-attention for Vision Transformers"}, {"paperId": "dbdcabd0444ad50b68ee09e30f39b66e9068f5d2", "title": "DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification"}, {"paperId": "1f668aebd03b5150c2c2fddae48f4a65cb4a80a8", "title": "Container: Context Aggregation Network"}, {"paperId": "1ee1160b8c7c70ded02e786c184a6da651e88bed", "title": "Dynamic Head: Unifying Object Detection Heads with Attentions"}, {"paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60", "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"}, {"paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de", "title": "Pay Attention to MLPs"}, {"paperId": "68f080e0ac836ea230cb5316fbed273c70422d75", "title": "Segmenter: Transformer for Semantic Segmentation"}, {"paperId": "df9dfbe775df0c66a57308ec52900a590a92c9f7", "title": "SCTN: Sparse Convolution-Transformer Network for Scene Flow Estimation"}, {"paperId": "48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5", "title": "ResMLP: Feedforward Networks for Image Classification With Data-Efficient Training"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "a1bb2e9134ca0ee67d2cbd8c54eb021625a8f17d", "title": "Vision Transformers with Patch Diversification"}, {"paperId": "cc9f3a61ea4eaabf43cbb30cd1dd718074932679", "title": "All Tokens Matter: Token Labeling for Training Better Vision Transformers"}, {"paperId": "5b68522f58b61e7235b852677337ef3725075fd9", "title": "Co-Scale Conv-Attentional Image Transformers"}, {"paperId": "14c52ffa7ea9c1971d5d82ea369c946c98d056a9", "title": "LocalViT: Bringing Locality to Vision Transformers"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "028fb10e650f68617fb7b3891da879f6cda69d94", "title": "Augmented Transformer with Adaptive Graph for Temporal Action Proposal Generation"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "7c3ce1b3ad598a282546e03e2dc8b52c338caed6", "title": "Transformer Tracking"}, {"paperId": "3cbe314cc5407a6c3249815b5173f22ea15173c2", "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"}, {"paperId": "0eff37167876356da2163b2e396df2719adf7de9", "title": "CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification"}, {"paperId": "91e8117e7ebc966bc76de2cb52ec717d2acdb1a4", "title": "Scaling Local Self-Attention for Parameter Efficient Visual Backbones"}, {"paperId": "75284d5e4dfe1cd8a9ce69085210319e14fcfa3d", "title": "Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking"}, {"paperId": "fbd730a948a06cd4918c1d632ffdb4572b52d99b", "title": "Involution: Inverting the Inherence of Convolution for Visual Recognition"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "b9c3fbbea151fc2c78339139ce645ee33d2f60cd", "title": "Trear: Transformer-Based RGB-D Egocentric Action Recognition"}, {"paperId": "3a906b77fa218adc171fecb28bb81c24c14dcc7b", "title": "Transformers in Vision: A Survey"}, {"paperId": "d29430adccb805ab57b349afa8553954347b3197", "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "787119e3c3f819244c82b7d97779473773e60696", "title": "MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers"}, {"paperId": "2ac7999cce9f415ee87643f56631b55ed26aa10e", "title": "End-to-End Video Instance Segmentation with Transformers"}, {"paperId": "6d5f423164cd5ef9324281652987c8a65009e98e", "title": "Sparse R-CNN: End-to-End Object Detection with Learnable Proposals"}, {"paperId": "2e1db8cb373f4d4a51d44308b7a457886d855fbb", "title": "End-to-End Object Detection with Adaptive Clustering Transformer"}, {"paperId": "c13a8f9edb933e60c7a989244aee56283a54ce37", "title": "UP-DETR: Unsupervised Pre-training for Object Detection with Transformers"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "fb93ca1e004cbdcb93c8ffc57357189fa4eb6770", "title": "ResNeSt: Split-Attention Networks"}, {"paperId": "fb7972f30812c7dd056d7943c3e3f00af022d607", "title": "Dynamic Convolution: Attention Over Convolution Kernels"}, {"paperId": "448529da2bf004cf79084401ad3cbd6b511e4969", "title": "Bridging the Gap Between Anchor-Based and Anchor-Free Detection via Adaptive Training Sample Selection"}, {"paperId": "c5ff974a69fd0c760b4855b819e61e89f31cfffe", "title": "Objects365: A Large-Scale, High-Quality Dataset for Object Detection"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "a88c914f5a738d38f02790bb5de41453bf17bde1", "title": "Object-Contextual Representations for Semantic Segmentation"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "061d6d5f3df0db70b12f9e90bec327e19b7259c1", "title": "Local Relation Networks for Image Recognition"}, {"paperId": "66143960c0325c70329a3869cc8052f0416b87aa", "title": "GCNet: Non-Local Networks Meet Squeeze-Excitation Networks and Beyond"}, {"paperId": "6303bac53abd725c3b458190a6abe389a4a1e72d", "title": "Deep High-Resolution Representation Learning for Human Pose Estimation"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "9217e28b2273eb3b26e4e9b7b498b4661e6e09f5", "title": "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation"}, {"paperId": "04957e40d47ca89d38653e97f728883c0ad26e5d", "title": "Cascade R-CNN: Delving Into High Quality Object Detection"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "9da734397acd7ff7c557960c62fb1b400b27bd89", "title": "ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "5582bebed97947a41e3ddd9bd1f284b73f1648c2", "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "31f9eb39d840821979e5df9f34a6e92dd9c879f2", "title": "Learning Deep Features for Discriminative Localization"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327", "title": "Going deeper with convolutions"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "63f1f2dad0a2e84d37a97258008c5609195487f0", "title": "Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "7dee2bc2be709c0009b7623b7af78246f32e0a60", "title": "Demystifying Local Vision Transformer: Sparse Connectivity, Weight Sharing, and Dynamic Weight"}, {"paperId": "03ce51e5e854faa614e79afe4dab8baeb5f73980", "title": "Twins: Revisiting Spatial Attention Design in Vision Transformers"}, {"paperId": "96d4f14f107608b68451bd0efe71a76dbc7cf9fe", "title": "Sparse-MLP: A Fully-MLP Architecture with Conditional Computation"}, {"paperId": "361ae6c15a64e4da7debc320a47dd28e5040a3c2", "title": "TubeR: Tube-Transformer for Action Detection"}, {"paperId": "9af62668cb87f11fffb53a194588c8158fde6b00", "title": "DynamicViT: Ef\ufb01cient Vision Transformers with Dynamic Token Sparsi\ufb01cation"}, {"paperId": "9e4b20d6d51cabd02ff58ed4e1b5736190e269e9", "title": "Cross-channel Communication Networks"}, {"paperId": null, "title": "Visualization of gating values G at last layer of our FocalNet-B (LRF) pretrained on ImageNet-1K. The order from left to right column is same to Fig"}]}