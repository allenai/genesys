{"paperId": "f3d7fdcdb1191a4a59e78f54d67fcd46a3462d2b", "title": "Temporal Scaling Law for Large Language Models", "abstract": "Recently, Large Language Models (LLMs) have been widely adopted in a wide range of tasks, leading to increasing attention towards the research on how scaling LLMs affects their performance. Existing works, termed Scaling Laws, have discovered that the final test loss of LLMs scales as power-laws with model size, computational budget, and dataset size. However, the temporal change of the test loss of an LLM throughout its pre-training process remains unexplored, though it is valuable in many aspects, such as selecting better hyperparameters \\textit{directly} on the target LLM. In this paper, we propose the novel concept of Temporal Scaling Law, studying how the test loss of an LLM evolves as the training steps scale up. In contrast to modeling the test loss as a whole in a coarse-grained manner, we break it down and dive into the fine-grained test loss of each token position, and further develop a dynamic hyperbolic-law. Afterwards, we derive the much more precise temporal scaling law by studying the temporal patterns of the parameters in the dynamic hyperbolic-law. Results on both in-distribution (ID) and out-of-distribution (OOD) validation datasets demonstrate that our temporal scaling law accurately predicts the test loss of LLMs across training steps. Our temporal scaling law has broad practical applications. First, it enables direct and efficient hyperparameter selection on the target LLM, such as data mixture proportions. Secondly, viewing the LLM pre-training dynamics from the token position granularity provides some insights to enhance the understanding of LLM pre-training.", "venue": "arXiv.org", "year": 2024, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes the novel concept of Temporal Scaling Law, studying how the test loss of an LLM evolves as the training steps scale up, and derives the much more precise temporal scaling law by studying the temporal patterns of the parameters in the dynamic hyperbolic-law."}, "embedding": {"model": "specter_v2", "vector": [-0.15803144872188568, 0.5527127385139465, -0.5233362913131714, -0.384759783744812, -0.7625972628593445, -0.27382776141166687, 0.8134073615074158, -0.16276279091835022, -0.6824747920036316, -0.19922880828380585, 0.11866319179534912, -0.008283683098852634, 0.04773156717419624, 0.21421083807945251, -0.3939882218837738, 0.06703605502843857, -1.132951021194458, 0.670224666595459, 0.21586763858795166, 0.20698069036006927, -0.6491605639457703, -0.7120024561882019, -0.651934027671814, -0.1734439730644226, 0.5795831680297852, 0.5784372091293335, -0.0649057999253273, 1.094876766204834, -0.36403486132621765, -0.008132895454764366, 0.22036714851856232, -0.559622049331665, 0.528351366519928, -0.3738177418708801, -0.13923068344593048, 0.07105059176683426, 0.041077613830566406, -0.4651808440685272, -1.0502945184707642, 0.9109416007995605, -0.12302117794752121, 0.6557466387748718, 0.2831280529499054, -0.8243110775947571, -0.13400587439537048, 0.7098497152328491, 0.45760923624038696, 0.7223119139671326, -0.5544093251228333, -0.6446946263313293, 1.0408800840377808, -1.1645877361297607, -0.04993388056755066, 1.7215068340301514, 0.5254418253898621, 0.07671104371547699, -0.16303721070289612, -0.6748547554016113, 0.5088574290275574, -0.2635532021522522, -0.8599410057067871, -0.15408940613269806, -0.42061635851860046, -0.01357216015458107, 1.4017714262008667, -0.4091259837150574, 0.023487955331802368, 0.24453933537006378, -0.08205944299697876, 1.5689810514450073, -0.1424601972103119, -0.8769097328186035, -0.09538744390010834, 0.32458212971687317, 0.1241440698504448, 0.6337831616401672, -0.32602617144584656, 0.31998592615127563, -0.9362749457359314, -0.4279802441596985, 0.08425037562847137, -0.4692794680595398, 0.3672616183757782, -0.08334363251924515, 0.021206645295023918, 0.8368821740150452, 0.050515685230493546, 0.5491041541099548, 0.18963949382305145, 0.9883649945259094, 0.6785008311271667, 0.5623641014099121, 1.0159884691238403, -0.03916657343506813, -0.43822741508483887, 0.04939913749694824, -1.0992929935455322, 0.02062196470797062, -0.18376249074935913, 0.6003232598304749, -0.5453828573226929, 0.19392311573028564, -0.4972960650920868, 0.8805841207504272, 1.483877182006836, 0.17072102427482605, 0.9522578716278076, -0.32480525970458984, 0.49826380610466003, -0.7324155569076538, 0.08503257483243942, 0.06127815693616867, -0.3882925510406494, -0.5358662605285645, -0.6888492107391357, -1.2834498882293701, -0.20057301223278046, 0.46146950125694275, -0.800255537033081, 1.076864242553711, 0.049042198807001114, 0.05984858050942421, 0.27977508306503296, 0.13922026753425598, -0.0289494339376688, 0.9552863836288452, 0.3179091215133667, -0.18474790453910828, 0.6789828538894653, -0.5699974298477173, -0.28372836112976074, -0.7387824058532715, 1.0689587593078613, -0.3245943784713745, 0.5518611669540405, -0.28522735834121704, -1.4063619375228882, -1.050992488861084, -0.8023776412010193, 0.47655364871025085, -0.4317893087863922, 0.3917371928691864, 0.6577869653701782, 0.42930591106414795, -0.9438455700874329, 0.9249961972236633, -0.5368087291717529, -0.5284220576286316, 0.3759225010871887, 0.3854861855506897, 0.08565803617238998, -0.43165647983551025, -1.2155817747116089, 0.33809593319892883, 0.48365551233291626, -0.8656115531921387, 0.013511519879102707, -0.5003507137298584, -0.9468047022819519, -0.24526166915893555, -0.014109402894973755, -0.14277534186840057, 1.525018334388733, 0.006034091114997864, -1.3066705465316772, 0.3977777659893036, 0.07317610085010529, 0.041155651211738586, 0.6620548367500305, -0.08647321909666061, -0.7283106446266174, -0.5714062452316284, -0.26924073696136475, 0.5941863656044006, 0.11236350238323212, -0.22540651261806488, -0.3992874324321747, 0.23048166930675507, -0.6183159947395325, -0.05026386305689812, -0.43446478247642517, 0.5926805734634399, -0.5506021976470947, -0.620381772518158, 0.3628368675708771, 0.409585177898407, 0.09669952839612961, -0.22038018703460693, -0.1911771595478058, -1.3154723644256592, 0.43050068616867065, -0.21983373165130615, 0.8997545838356018, -1.0131169557571411, -1.0165910720825195, -0.05121366307139397, -0.48520681262016296, 0.14031767845153809, -0.970670759677887, 0.6113189458847046, 0.016989270225167274, 0.4714745283126831, -0.07702705264091492, -1.2646198272705078, 0.3919598460197449, -0.3233126997947693, -0.646797239780426, 0.1588243991136551, 0.03304292634129524, 0.9585928320884705, -0.8293924927711487, 0.2878611087799072, -0.13380761444568634, 0.06379042565822601, -0.7423243522644043, 1.1379036903381348, -0.48616984486579895, -0.26736193895339966, 0.1848982721567154, -0.31583935022354126, 0.34273555874824524, -0.22138892114162445, 0.5096787810325623, 0.19097742438316345, 0.0663943812251091, 0.41140151023864746, -0.3908173739910126, 1.074647307395935, -0.0490013062953949, 0.39523932337760925, -0.40050292015075684, -0.6271715760231018, -0.06944850087165833, 0.43960490822792053, -0.09997989237308502, -0.42390841245651245, 0.5614062547683716, 0.5272491574287415, -0.44034919142723083, 0.3258783519268036, 0.5420284271240234, 0.36927273869514465, -0.40144965052604675, 0.5585654973983765, 0.7911426424980164, -0.00429342407733202, 0.8866333961486816, 0.11945789307355881, 0.2044670432806015, 0.35664674639701843, 0.4346731901168823, -0.03134077787399292, 0.00396378617733717, -1.1287411451339722, -0.23912747204303741, 0.4924556314945221, 0.6303892135620117, 0.41581806540489197, 0.3152528703212738, -0.5614967942237854, -0.868829607963562, -0.3961162865161896, 0.2473226636648178, 1.4389055967330933, -0.3532085418701172, -0.010281824506819248, -0.6053643226623535, -0.3080761432647705, -0.026626672595739365, -0.028565876185894012, -0.4615687429904938, -0.15873204171657562, -0.539211630821228, -1.3719536066055298, 1.1021631956100464, 0.1820877641439438, 0.6587100028991699, -0.21712814271450043, 0.33041971921920776, -0.13111336529254913, 0.4183412790298462, -0.7959995865821838, -0.7764165997505188, 0.13108579814434052, -0.6601501107215881, 0.06476102024316788, -0.17731840908527374, -0.016634982079267502, -0.07814774662256241, -0.9591330289840698, 0.4070805609226227, -0.566290020942688, -0.012929605320096016, -0.031794920563697815, 0.38516104221343994, -0.7964910864830017, -1.335857629776001, 0.24167853593826294, 0.6460461020469666, -0.02025299333035946, -0.014383108355104923, 0.7468109726905823, 0.25417688488960266, 0.10641556978225708, -0.7803113460540771, 0.027862166985869408, 0.16859468817710876, -0.1379915028810501, 0.45391979813575745, -0.031954411417245865, 0.3621845841407776, -0.8319525122642517, 1.140816569328308, 0.0694311261177063, -0.7077748775482178, 0.7587100863456726, -0.9059187173843384, -0.23516559600830078, 0.31427866220474243, -1.2616753578186035, 0.12072374671697617, -1.3024673461914062, 0.37784817814826965, -0.22093719244003296, 0.28444764018058777, 0.09648856520652771, 0.518328070640564, 0.40562689304351807, 0.10070103406906128, 0.4932200312614441, 0.3776988089084625, -0.3603409230709076, 0.19581633806228638, -0.7237919569015503, 0.2342732697725296, 0.27559196949005127, 0.30455106496810913, -0.17140689492225647, -0.295337975025177, -0.6903299689292908, -0.26041918992996216, -0.4930014908313751, -0.2081393152475357, -0.5139172077178955, -0.2400941252708435, -0.41246533393859863, -0.7212573289871216, 0.16944490373134613, -0.622954249382019, -0.46584272384643555, 0.1407204121351242, 0.42034727334976196, -0.29771697521209717, -1.0478516817092896, -1.7367453575134277, -0.7417604327201843, -0.3318236768245697, -0.6461629867553711, 0.030956126749515533, 0.01830640807747841, -0.2908838987350464, -0.570144534111023, 0.15868118405342102, -0.6801238656044006, 0.8088216185569763, -0.9947421550750732, 1.0079907178878784, -0.25416725873947144, 0.15885530412197113, -0.5709018707275391, 0.4068549573421478, 0.5750728249549866, -0.5506795644760132, 0.3952105641365051, -0.893271803855896, -0.24914059042930603, -0.37606531381607056, -0.3865317702293396, -0.010533679276704788, 0.627149760723114, 0.6577426791191101, -0.07539323717355728, -0.5255014896392822, 0.3389091491699219, 1.1956490278244019, -0.5474053025245667, -0.1910870373249054, 0.03183869272470474, 0.47290337085723877, 0.30840224027633667, -0.26528188586235046, 0.48881664872169495, 0.06070983037352562, 0.4814470112323761, -0.3518654704093933, -0.2644537389278412, -0.0015105957863852382, -0.8534848690032959, 0.5892773270606995, 2.069934844970703, 0.7736524939537048, -0.5814357399940491, -0.8467298150062561, 0.3617440462112427, -1.254063367843628, -0.5949769020080566, 0.9925931096076965, 1.1333719491958618, 0.0619802288711071, -0.3914162218570709, 0.25475454330444336, 0.08818091452121735, 0.3196122348308563, 0.2668236494064331, -0.4291546940803528, -0.27888548374176025, -0.16767600178718567, 0.06895198673009872, 0.11350686103105545, 0.570450484752655, -0.40823325514793396, 0.7657387256622314, 14.956476211547852, 1.2911800146102905, -0.08053824305534363, 1.1408214569091797, 0.8520991802215576, -0.11350957304239273, -0.09915940463542938, -0.41826027631759644, -1.0047011375427246, 0.2244575321674347, 1.4035587310791016, -0.015311152674257755, 0.808268129825592, -0.18662351369857788, 0.2940578758716583, 0.1379808634519577, -0.14719408750534058, 0.6739732027053833, 0.47872230410575867, -1.060158610343933, 0.42880383133888245, 0.23156167566776276, 0.7253121733665466, 1.2046617269515991, 0.6359683871269226, 0.9188029170036316, 0.6581546068191528, -0.12716159224510193, 0.9245572686195374, -0.06734366714954376, 1.2843382358551025, -0.1455664336681366, 0.35349979996681213, 0.6020967960357666, -0.9859235286712646, -0.024892909452319145, -0.5961148142814636, -0.8023998141288757, 0.22125758230686188, 0.2968777120113373, -0.7867494821548462, -0.545559287071228, -0.35257261991500854, 0.44972628355026245, 0.21866454184055328, 0.45971548557281494, 0.18875837326049805, 1.0058106184005737, -0.44286781549453735, 0.10350170731544495, 0.166718527674675, 0.4453200399875641, 0.1391267627477646, -0.03724638745188713, 0.45447033643722534, -0.13332466781139374, 0.3000829219818115, 0.0794372484087944, -0.9407169222831726, 0.331821471452713, -0.006577346473932266, -0.5323587656021118, -0.009473981335759163, 0.24645136296749115, 0.13064564764499664, -0.07395660132169724, -0.07493534684181213, 0.2996072471141815, 0.7049548029899597, 0.40734410285949707, -0.3938990831375122, 0.46583646535873413, 0.6451946496963501, -0.2818465530872345, -0.3139796257019043, 0.46100595593452454, -0.024451328441500664, -0.46855828166007996, -0.454586923122406, -0.1809268742799759, 0.2719087302684784, -0.6766120195388794, -0.8508666157722473, 0.9800173044204712, 0.057287171483039856, -0.6435685157775879, 0.3563353419303894, -0.5766414999961853, -0.018632015213370323, 0.22228635847568512, -1.2385544776916504, -0.5557559132575989, 1.1059035062789917, -0.46883395314216614, -0.04136047139763832, -0.15964925289154053, 0.8830844759941101, 0.18033181130886078, -0.5483555197715759, 0.4617123603820801, 0.6385560631752014, -0.1831502616405487, -0.36729153990745544, -0.3123045861721039, 1.0806328058242798, 0.3136208653450012, -0.017458172515034676, -0.020227013155817986, -0.18982885777950287, 0.179603710770607, -0.2637462913990021, 0.004710183013230562, 0.8157032132148743, -0.6916758418083191, -0.2170322686433792, -0.7524319291114807, -0.8393204212188721, 0.11939821392297745, 0.01599530503153801, -0.07182809710502625, 0.3153223693370819, 0.11794929206371307, -0.5332059860229492, -0.23638400435447693, -0.49742376804351807, -0.05805284157395363, 0.31950104236602783, -0.9099878072738647, 0.25402992963790894, 0.08494208753108978, 0.4441567361354828, -0.8551669716835022, -0.42726847529411316, 0.07212454080581665, -0.03705365210771561, 0.24228234589099884, 0.5983218550682068, -0.6586682200431824, 0.19303253293037415, 0.7507455945014954, -0.25539466738700867, -0.8828030824661255, 0.013743379153311253, -0.7895280122756958, 0.16599753499031067, 0.24219940602779388, 0.6634029746055603, -0.4362879991531372, 0.04039453715085983, 0.5909243226051331, 0.22735436260700226, -0.6339035630226135, -1.112180471420288, -0.6851900219917297, 0.1545765995979309, -1.1505091190338135, 0.2168445587158203, -0.24145203828811646, -0.0942562147974968, -0.307730495929718, 0.21500997245311737, 0.7885029315948486, -0.4682750105857849, -1.0297579765319824, 0.19507017731666565, -0.007703552488237619, -0.17619118094444275, -1.0190489292144775, -0.48586413264274597, -1.514951467514038, 0.0380699560046196, -1.5468494892120361, -0.0012137809535488486, -0.7445183396339417, -0.18581266701221466, -0.43273770809173584, -0.3112330138683319, -0.48478928208351135, 0.617486298084259, 0.007506044581532478, -0.20515871047973633, -0.16271424293518066, -0.48118114471435547, 1.0682957172393799, 0.6139055490493774, -0.6703096628189087, -0.01060873456299305, 0.314307302236557, 0.7901501655578613, 0.3553473949432373, 0.5441398024559021, -0.7263346314430237, -0.9691169261932373, -1.3036574125289917, 0.471062570810318, -0.24949787557125092, -0.35083428025245667, -0.6765346527099609, 0.4269197881221771, 0.2524918019771576, -0.034530337899923325, 0.2335270494222641, 0.5357867479324341, -0.4178057909011841, -0.44024741649627686, 0.5143135190010071, -0.9292656183242798, 0.27079224586486816, 0.2624528110027313, -0.43822920322418213, -0.33822324872016907, 0.6452163457870483, 0.08207467943429947, -0.5679976344108582, 0.046896856278181076, 0.8398061394691467, -0.34043556451797485, 0.38352108001708984, -0.10890724509954453, 0.1828518658876419, -0.756984531879425, -0.3340187668800354, 0.03698068857192993, 0.2507883608341217, -0.5304158329963684, 1.1783092021942139, 0.01419984269887209, -1.4308165311813354, -0.11645276844501495, 0.5114650726318359, -0.05078599229454994, -0.16521894931793213, 0.567945122718811, 0.27977389097213745, -0.36500126123428345, 0.6443312764167786, 0.8217662572860718, 0.15955416858196259, -0.9416849613189697, -0.11612728238105774, 0.7586688995361328, -0.6111512780189514, -0.11806521564722061, 1.5041693449020386, -0.05565038323402405, -1.4851763248443604, 0.26070478558540344, -1.200818657875061, -0.11830003559589386, -0.326203316450119, 0.6162174940109253, 0.2619728147983551, -0.09648410230875015, 0.0013348297215998173, -0.09044644236564636, -0.058961644768714905, 0.14280374348163605, -0.7984549403190613, 0.5162451267242432, -0.3613310754299164, -0.2513757646083832, 1.0559868812561035, 1.0097237825393677, -0.6815745234489441, -1.0334986448287964, -0.9045863151550293, -0.4378608167171478, -0.24563398957252502, -0.07559265941381454, -0.10995160788297653, -0.38765841722488403, 0.3951972424983978, 0.5846149325370789, 0.5485658049583435, -0.39856672286987305, 0.3268390893936157, 0.09389648586511612, 0.09000320732593536, 0.24410505592823029, -0.9084467887878418, -0.6674078702926636, 1.2060954570770264, 1.081142783164978, -0.9739972352981567, 0.21956674754619598, 0.24858249723911285, -0.45479831099510193, 0.7108621001243591, 0.21664780378341675, 0.12382052838802338, 1.1564512252807617, -0.17340363562107086, 0.11895964294672012, 0.43569180369377136, -1.0796451568603516, -0.04934212565422058, 1.1770539283752441, 0.2900271415710449, 0.6975664496421814, 0.8107046484947205, 0.027554621919989586, 0.636616587638855, -0.06818801909685135, -0.09992414712905884, 0.014241144992411137, 0.2338082194328308, -0.3227997124195099, -0.3061278164386749, 0.001393606187775731, 0.908678412437439, -0.5682612061500549, -0.39131733775138855, 0.24601054191589355, 0.6462799310684204, 0.1825486719608307, 0.5796183943748474, 1.0510189533233643, -0.108409583568573, 0.2907158136367798, 0.37394341826438904, 0.6420251131057739, -0.31434324383735657, 0.1883355677127838, -0.004935535602271557, -0.7275123596191406, 0.47875019907951355, 0.06659740954637527, -0.6477458477020264, -0.45291605591773987, -0.49288830161094666, 0.15387506783008575, 0.08750060945749283, 0.3666151165962219, 1.261203408241272, 0.18588633835315704, 0.23985245823860168, -0.1814601868391037, -0.3572275638580322, -0.5826770067214966, -1.2764647006988525, -0.20609436929225922, -0.23284874856472015, -0.21951505541801453, 0.11336573213338852, -0.04579754173755646, -0.7818451523780823]}, "authors": [{"authorId": "2249971338", "name": "Yizhe Xiong"}, {"authorId": "2298904872", "name": "Xiansheng Chen"}, {"authorId": "2299108794", "name": "Xin Ye"}, {"authorId": "2298921971", "name": "Hui Chen"}, {"authorId": "1818920", "name": "Zijia Lin"}, {"authorId": "2298903058", "name": "Haoran Lian"}, {"authorId": "2293626051", "name": "Jianwei Niu"}, {"authorId": "2242661989", "name": "Guiguang Ding"}], "references": [{"paperId": "198fb07ae84ca36f98a362058fb8a90e214bea06", "title": "RepViT: Revisiting Mobile CNN From ViT Perspective"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "9b4f7c97c0b83a80c32bc0b93595cbcfb4ecb16d", "title": "DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining"}, {"paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8", "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "468992bf970c37bd1fef58b78a6c2fcd8c018868", "title": "Scaling Laws for Generative Mixed-Modal Language Models"}, {"paperId": "16de2006e2960ba410772c6b6d460b83c0a5cc4b", "title": "Reproducible Scaling Laws for Contrastive Language-Image Learning"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "0b0d7d87c58d41b92d907347b778032be5966f60", "title": "Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "fc46ccb83dc121c33de7ab6bdedab7d970780b2f", "title": "Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting"}, {"paperId": "4383a975c09b72ba2f1a77cd779bb6965dbfb2fb", "title": "Scaling Laws for Transfer"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "2b8088253e2378fce001a090fe923b81e8dedf25", "title": "RepVGG: Making VGG-style ConvNets Great Again"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "3efbcfeeb0ea1051a71101d3318da4411081f0b8", "title": "Scaling Laws for Autoregressive Generative Modeling"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "79c5ace95f0bcd33c1e02b7e83a2e0cdadb6b50a", "title": "IMRAM: Iterative Matching With Recurrent Attention Memory for Cross-Modal Image-Text Retrieval"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "9770fff7379a7ab9006b48939462354dda9a2053", "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "1536e8958697c5364f68b2e2448905dbbeb3a0ca", "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "5ed791f810da580c78df6a052c6b9f2e258f6b0a", "title": "The LAMBADA dataset: Word prediction requiring a broad discourse context"}, {"paperId": "7bd3ca52fc490c66702ef882688bd96402f7d4ce", "title": "Coefficient of determination for multiple measurement error models"}, {"paperId": "6471fd1cbc081fb3b7b5b14d6ab9eaaba02b5c17", "title": "Generating Sequences With Recurrent Neural Networks"}, {"paperId": "6c2b28f9354f667cd5bd07afc0471d8334430da7", "title": "A Neural Probabilistic Language Model"}, {"paperId": "3de5d40b60742e3dfa86b19e7f660962298492af", "title": "Class-Based n-gram Models of Natural Language"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28", "title": "An Adversarial Winograd Schema Challenge at Scale"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Socialiqa: Common-sense reasoning about social interactions"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "A corpus and evaluation framework for deeper understanding of commonsense stories"}, {"paperId": "9819b600a828a57e1cde047bbe710d3446b30da5", "title": "Recurrent neural network based language model"}, {"paperId": null, "title": "2022. Non-stationary transformers: Exploring the stationarity in time series forecasting"}, {"paperId": null, "title": "2022. Training compute-optimal large language models"}, {"paperId": null, "title": "2023. GPT-4 technical report"}, {"paperId": null, "title": "2023. Infoentropy loss to mitigate bias of learning difficulties for generative language models"}, {"paperId": null, "title": "2023. A framework for few-shot language model evaluation"}, {"paperId": null, "title": "Annual Conference on Neural Information Processing"}, {"paperId": null, "title": "Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16"}]}