{"paperId": "0557e6b4b071c65428d7b8fb9a7620839c3a578d", "title": "Improving Prompt Tuning with Learned Prompting Layers", "abstract": "Prompt tuning prepends a soft prompt to the input embeddings or hidden states and only optimizes the prompt to adapt pretrained models (PTMs) to downstream tasks. The previous work manually selects prompt layers which are far from optimal and failed to exploit the potential of prompt tuning. In this work, we propose a novel framework, \\underline{S}elective \\underline{P}rompt \\underline{T}uning (SPT), that learns to select the proper prompt layers by inserting a prompt controlled by a learnable probabilistic gate at each intermediate layer. We further propose a novel bi-level optimization framework, SPT-DARTS, that can better optimize the learnable gates and improve the final prompt tuning performances of the learned prompt layer settings. We conduct extensive experiments with ten benchmark datasets under the full-data and few-shot scenarios. The results demonstrate that our SPT framework can perform better than the previous state-of-the-art PETuning baselines with comparable or fewer tunable parameters.", "venue": "arXiv.org", "year": 2023, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A novel framework, SPT-DARTS, that learns to select the proper prompt layers by inserting a prompt controlled by a learnable probabilistic gate at each intermediate layer and can better optimize the learnable gates and improve the final prompt tuning performances of the learned prompt layer settings."}, "embedding": {"model": "specter_v2", "vector": [0.23115284740924835, 0.9861611127853394, -0.4260106384754181, -0.05164046213030815, -0.07592230290174484, -0.28906381130218506, 1.1186885833740234, -0.2576979696750641, -0.5520190596580505, -0.7968725562095642, 0.7278242707252502, 0.5136009454727173, 0.5251588821411133, 0.36180877685546875, 0.016212275251746178, 0.16982783377170563, -0.470280259847641, 0.5805494785308838, 0.05153907090425491, -0.7832821011543274, -0.029963217675685883, -0.9341358542442322, -0.862861156463623, -0.18841253221035004, 0.06786173582077026, 0.6648147106170654, 0.167622908949852, 0.9657008647918701, -0.5442847609519958, -0.1748509556055069, 0.4201872646808624, -0.2403029501438141, 0.6235518455505371, 0.19212019443511963, -0.19254851341247559, 0.1641242653131485, 0.24560101330280304, -0.9194700121879578, -0.7145963311195374, 0.6657580733299255, 0.0037147654220461845, 0.48907026648521423, 0.49727120995521545, -0.4597194790840149, -0.5935955047607422, 0.49707943201065063, 0.5649498105049133, 0.9353156685829163, -0.43466195464134216, -0.08501929044723511, 1.3041874170303345, -1.2985303401947021, 0.11448939889669418, 1.2528191804885864, 0.013901823200285435, 0.8201366662979126, -0.15198083221912384, -0.27173036336898804, 1.0974823236465454, 0.011690909042954445, -0.28281888365745544, -0.21240271627902985, 0.07754305750131607, -0.3420250415802002, 2.0213472843170166, -0.6378191113471985, -0.06808213889598846, 1.100718379020691, -0.18816913664340973, 1.3531299829483032, -0.13926996290683746, -0.8415506482124329, -0.5024727582931519, 0.2936859428882599, 0.5645757913589478, 0.6791284680366516, -0.6255094408988953, 1.2937030792236328, -0.8874289393424988, 0.3270309269428253, 0.8320987820625305, -0.1396080106496811, 0.284158319234848, 0.37409526109695435, -0.36681416630744934, 0.5504322052001953, 0.5711547136306763, 0.6025390625, -0.4464620053768158, 0.7210555672645569, 0.6865066885948181, -0.04957282915711403, -0.0024517772253602743, 0.5506421327590942, 0.042859651148319244, 0.2720196843147278, -0.4534868001937866, -0.04679999127984047, -0.1327294409275055, 0.6800983548164368, -0.20188909769058228, -0.00017500451940577477, -1.353411078453064, 0.026692647486925125, 1.1974157094955444, -0.6243318319320679, 0.376641184091568, -0.8001198172569275, 0.2077990025281906, -0.8422195911407471, 0.43708154559135437, -0.7424980401992798, -0.21363507211208344, 0.15095022320747375, -0.6681193113327026, -1.2268521785736084, -0.4723201096057892, 0.18525564670562744, -0.9805982708930969, 1.0804810523986816, -0.04502813518047333, 0.34459665417671204, -0.08485148847103119, 0.9746968746185303, 0.7476683855056763, 0.9054722189903259, 0.5535355806350708, 0.3182571828365326, 0.8607580661773682, -1.4427990913391113, -0.8745985627174377, -1.2399638891220093, 0.3078099191188812, -0.5062344670295715, 0.7487196922302246, -0.14205320179462433, -0.544096827507019, -1.2758979797363281, -1.131121039390564, -0.11608942598104477, -0.3873533606529236, 0.4167371392250061, 1.0423158407211304, 0.06560914218425751, -1.0296931266784668, 0.9009252190589905, -0.575547456741333, -0.5445438027381897, -0.05069241300225258, -0.05856294929981232, 0.4613884687423706, -0.010784166865050793, -1.3186633586883545, 0.23152382671833038, 0.4357207119464874, -0.4246818721294403, -0.1140064001083374, -0.7212872505187988, -0.7946470379829407, -0.04909726604819298, 0.5261505842208862, -0.5978723764419556, 1.7335941791534424, -0.2304576337337494, -1.5600703954696655, 0.9064036011695862, 0.1722090095281601, 0.4784579277038574, 0.4221162796020508, -0.3715893626213074, -0.42180657386779785, -0.32878515124320984, -0.18880626559257507, 1.4267641305923462, 0.43666723370552063, 0.07905447483062744, 0.03737862780690193, 0.46245303750038147, -0.01987389102578163, 0.1212339997291565, -0.3682573735713959, 0.7969299554824829, -0.2216922789812088, -0.06023785471916199, 0.1638709455728531, 1.212735891342163, 0.055370863527059555, -0.16909025609493256, -0.6187982559204102, -1.3525984287261963, 0.62009596824646, 0.2905740439891815, 0.7038546204566956, -1.1011496782302856, -0.9859568476676941, -0.7219038605690002, 0.10226548463106155, 0.07620200514793396, -1.2077373266220093, 0.6340723633766174, -0.3484509289264679, 0.2422093152999878, 0.5318726897239685, -1.475335717201233, 0.7045835852622986, 0.03541910648345947, -0.7423328757286072, -0.5060585737228394, 0.3826785981655121, 1.407549500465393, -0.859839916229248, 0.22513656318187714, 0.08701062202453613, 0.2220437228679657, -1.0482051372528076, 1.748582363128662, -0.6439032554626465, 0.11987601220607758, 0.023224037140607834, -0.3527177572250366, -0.3572896718978882, -0.5920835733413696, -0.14680086076259613, -0.6402369141578674, 0.20913559198379517, 0.6554953455924988, -0.5847793221473694, 1.4838427305221558, 0.10848873853683472, 0.31116652488708496, -0.29981154203414917, -0.7574480772018433, 0.555338442325592, 0.36443328857421875, -0.5105522871017456, -0.868664562702179, 0.5454232096672058, 0.37388312816619873, -0.8508814573287964, -0.03357088565826416, 1.374837875366211, 0.40868932008743286, -0.5467265248298645, -0.07997164130210876, 0.5369144082069397, 0.009531345218420029, 0.2804451286792755, 0.5979965925216675, 0.4922378957271576, 0.6436249613761902, 0.42921552062034607, 0.012284939177334309, -0.37686800956726074, -0.7769368886947632, 0.00025146789266727865, 0.36083725094795227, 0.313983678817749, 1.0203629732131958, 0.5934975147247314, -0.9333551526069641, -0.3046141564846039, -0.09576552361249924, 0.7883064150810242, 1.7819477319717407, 0.3922242224216461, -0.10206469148397446, -0.7193689942359924, -0.24905040860176086, -0.5975220203399658, 0.10025946795940399, -0.6205095648765564, -0.6855377554893494, -0.4474249482154846, -1.131722092628479, 0.43121230602264404, 0.47439083456993103, 1.0457491874694824, -0.6201119422912598, -0.3588092625141144, 0.10585466027259827, 0.1139049157500267, -0.9631454348564148, -1.093074083328247, 0.9290172457695007, -0.20698966085910797, -0.25515830516815186, 0.15625935792922974, 0.026431595906615257, 0.0304851271212101, -0.7435310482978821, 1.1633411645889282, -0.5910581946372986, -0.322994589805603, 0.38143816590309143, 0.35088256001472473, -0.04515153169631958, -0.5885312557220459, 0.2912842035293579, 0.29936057329177856, -0.2425122857093811, 0.4655556082725525, 0.7316516637802124, -0.23965121805667877, 0.21047216653823853, -0.6372195482254028, 0.3880000710487366, -0.21831898391246796, 0.08323374390602112, 1.151194453239441, -0.9528186321258545, 0.41214558482170105, -1.0387181043624878, 0.7827340364456177, -0.006602782290428877, -0.49627670645713806, 0.1274634748697281, -0.8398273587226868, -0.45446157455444336, 0.387406587600708, -0.8301340341567993, -0.349467933177948, -1.0256396532058716, 0.45473822951316833, -0.22384454309940338, -0.5288594365119934, -0.3049725592136383, 0.26311442255973816, 0.5514802932739258, 0.8170945048332214, -0.27866724133491516, -0.20875346660614014, -0.12478698790073395, 0.7339166402816772, -0.8990230560302734, 0.9054098725318909, -0.03738364577293396, -0.04781089723110199, -0.6323344111442566, -0.637478232383728, -0.1849997192621231, -1.1545346975326538, -0.6862866282463074, -0.25727909803390503, -0.42505913972854614, 0.6482136249542236, -0.22499729692935944, -0.5724157094955444, -0.034521203488111496, -1.2722536325454712, -0.6551688313484192, -0.4767290949821472, -0.588407039642334, -0.3823581337928772, -1.149010181427002, -1.1017073392868042, -0.16248776018619537, -0.4213049113750458, -0.7211881875991821, 0.4203587472438812, 0.747090220451355, -0.4785001277923584, -0.7000950574874878, 0.5164975523948669, -0.37245437502861023, 0.9466651082038879, -0.25367268919944763, 0.6603634357452393, -0.4805941581726074, -0.29955026507377625, -0.23765257000923157, -0.023555727675557137, 0.6642612218856812, -0.050178639590740204, 0.36871394515037537, -1.3458359241485596, 0.44335705041885376, -0.48078683018684387, -0.4828367531299591, 0.14456002414226532, -0.028507480397820473, 0.292883962392807, -0.09466014802455902, -0.29215192794799805, 0.6802437901496887, 1.5452697277069092, -0.6347917914390564, -0.056956879794597626, 0.3892352283000946, 0.896761417388916, 0.2780158519744873, 0.18933582305908203, 0.47088155150413513, 0.37959036231040955, 0.4690835475921631, 0.25513336062431335, -0.23523437976837158, -0.2540629208087921, -1.1014487743377686, 0.46330928802490234, 1.4949558973312378, 0.9072403311729431, 0.002198500093072653, -0.8402626514434814, 0.6852931976318359, -1.4468636512756348, -0.1718655526638031, 0.7599326372146606, 0.49621641635894775, 0.47937801480293274, -0.5567623376846313, -0.07615543156862259, -0.6193206906318665, 0.7489253878593445, 0.6117896437644958, -0.6849821209907532, -0.982337236404419, 0.3098248541355133, 0.30141937732696533, -0.2678694725036621, 0.5597478151321411, -0.2864348590373993, 0.8470465540885925, 14.129755973815918, 0.5360729098320007, -0.08810286968946457, 0.5700010061264038, 0.9913756251335144, 0.13803790509700775, -0.34928658604621887, -0.3057449758052826, -1.3580408096313477, -0.11501573771238327, 1.1373381614685059, 0.5585901141166687, 0.7385214567184448, -0.01977398805320263, -0.09158362448215485, 0.015295908786356449, -0.9949823617935181, 0.7044572830200195, 0.27579793334007263, -1.0867618322372437, -0.09317109733819962, -0.2862320840358734, 0.592959463596344, 0.5296076536178589, 0.9686912894248962, 0.9936484694480896, 0.26184263825416565, -0.22825725376605988, 0.4650252163410187, 0.3541874587535858, 0.9359298348426819, 0.10349379479885101, 0.19855624437332153, 0.45170196890830994, -0.41142934560775757, 0.2225523144006729, -0.5071505308151245, -1.1511249542236328, 0.40157294273376465, -0.12815268337726593, -0.34117037057876587, -0.5639548897743225, -0.24213698506355286, 0.6190868020057678, 0.32058432698249817, 0.21273639798164368, -0.4738605320453644, 0.5097793936729431, -0.3260391056537628, 0.22931231558322906, 0.9151396155357361, 0.3932873606681824, 0.2693299353122711, 0.10158984363079071, -0.08487427234649658, 0.5356218218803406, 0.3726098835468292, 0.9317231178283691, -0.3754432797431946, -0.30229970812797546, 0.11779153347015381, -0.3746824562549591, -0.031292371451854706, 1.2252237796783447, 0.21680210530757904, 0.2381468117237091, -0.03857751190662384, 0.4824128746986389, 0.32948046922683716, 0.32987362146377563, -0.25644534826278687, 0.24229703843593597, 0.2802485525608063, -0.4172057807445526, -0.4416794180870056, 0.81795334815979, -0.33653053641319275, -0.4716263711452484, -0.7285290360450745, -0.008347220718860626, 0.19035422801971436, -0.8050035834312439, -1.115706205368042, 0.8084697723388672, -0.10366535931825638, -0.13500991463661194, -0.049219999462366104, -0.6025264859199524, -0.7180116176605225, 0.3412875533103943, -1.6225576400756836, -0.26402395963668823, -0.15539197623729706, -0.7333530187606812, -0.4997762143611908, -0.07482047379016876, 1.1242153644561768, 0.1536199450492859, -0.7509972453117371, 0.37803977727890015, -0.44388288259506226, -0.3903687298297882, 0.15351194143295288, -1.215846061706543, 1.0266058444976807, 0.26039427518844604, -0.008173885755240917, -0.19655238091945648, 0.24420398473739624, 0.5279164910316467, -0.19912393391132355, -0.05137913301587105, 0.45794913172721863, -0.5927056074142456, -0.4097825288772583, -0.2675107717514038, -0.8481237888336182, 0.177017480134964, 1.0138986110687256, -0.10246831178665161, 0.45213863253593445, 0.1785706728696823, -0.6887301802635193, 0.06977733224630356, -0.9597419500350952, -0.11479981243610382, 0.3417070209980011, -0.5349864363670349, -0.49865829944610596, 0.09651022404432297, 0.6557885408401489, -1.3281867504119873, -0.27100425958633423, -0.4580281972885132, -0.46998196840286255, -0.12384264171123505, 0.8553943037986755, -0.37025555968284607, 0.6170434951782227, 0.9984816312789917, -0.3570268154144287, -1.0479075908660889, 0.139085054397583, -1.28509521484375, 0.13632097840309143, 0.5211144089698792, 0.3598359525203705, -0.4297780394554138, 0.025071196258068085, 1.2586392164230347, 0.11606691777706146, -0.5738369822502136, -0.26961034536361694, -0.32488682866096497, 0.20579306781291962, -0.11316994577646255, 0.4763185679912567, -0.2782476246356964, -0.14147315919399261, 0.45751380920410156, 0.5090775489807129, 0.2824156880378723, -0.18586374819278717, -0.9011170864105225, 0.005877014249563217, -0.05758284032344818, -0.4768432378768921, -0.5175095200538635, -0.10349296033382416, -2.0364139080047607, -0.5188800096511841, -1.2217165231704712, 0.41289782524108887, -1.051527738571167, -0.19999879598617554, 0.13083691895008087, -0.6334414482116699, 0.33404842019081116, -0.1330338716506958, -0.29538917541503906, -0.20134681463241577, -0.30988243222236633, -0.7365248799324036, 0.9355107545852661, 1.1050950288772583, -0.3861364722251892, -0.1360856294631958, -0.3281048834323883, -0.5682933330535889, 0.18634939193725586, 0.4209808111190796, -0.45570874214172363, -0.4089599549770355, -1.0854958295822144, 0.3365565240383148, 0.010604282841086388, 0.1306227445602417, -0.1786370724439621, 0.6399380564689636, 0.5135401487350464, -0.4338492751121521, 0.05946347117424011, 0.4223962128162384, -0.8304373025894165, -0.7245070338249207, -0.26053479313850403, -0.8163472414016724, 0.06361258774995804, 0.36078399419784546, -0.3907797038555145, -0.2543950378894806, 0.6734467148780823, 0.318539023399353, -0.6436262726783752, -1.2445896863937378, 0.702353298664093, -0.14845211803913116, 0.2822434902191162, -0.2735777497291565, -0.15568852424621582, -1.4805665016174316, 0.0697333887219429, -0.13250380754470825, 0.5635485053062439, -0.3536999523639679, 1.0831347703933716, 0.2016722857952118, -1.779350757598877, 0.34206539392471313, 0.28405630588531494, 0.1720428764820099, 0.4756050109863281, 0.4572184681892395, 0.4693410396575928, 0.12288786470890045, 0.3002091348171234, 0.07776037603616714, 0.1638363003730774, -0.27953988313674927, 0.08462505042552948, 1.0059878826141357, -0.6088811159133911, -0.2778445780277252, 1.310404896736145, -0.04677245020866394, -1.1512235403060913, 0.5269611477851868, -0.9389104843139648, -0.4012860953807831, -0.06302458792924881, 0.6592687368392944, 0.03464411944150925, -0.05364534631371498, 0.21321681141853333, -0.22837673127651215, 0.24334833025932312, -0.3245633542537689, -0.5247471928596497, 0.5939589738845825, -0.10297087579965591, 0.15764227509498596, 0.700703501701355, 1.0306861400604248, -1.6216765642166138, -1.6437654495239258, -0.8738916516304016, -0.27273285388946533, -0.04350680857896805, 0.2410181760787964, -0.8292956352233887, -0.6692472696304321, 0.776314914226532, 0.5952228903770447, 0.17924116551876068, 0.26194700598716736, 0.055886052548885345, 0.29393887519836426, 0.6216335892677307, -0.16256354749202728, -0.8965867757797241, 0.1912599354982376, 0.984862744808197, 1.0969797372817993, -1.1345676183700562, -0.4685163199901581, 0.20205022394657135, -0.6974292993545532, 0.8263311982154846, 0.8809869289398193, -0.31000828742980957, 0.48086854815483093, -0.28713110089302063, 0.29296043515205383, -0.07115991413593292, -1.1431324481964111, -0.06859088689088821, 0.7704030871391296, 1.1421998739242554, 0.3094594478607178, 0.45841196179389954, 0.29408642649650574, 1.1745436191558838, 0.1281837522983551, -0.18310019373893738, 0.609323263168335, -0.23259977996349335, -0.4863872230052948, -0.32776081562042236, 0.18072091042995453, 0.6400099396705627, -0.49351534247398376, -0.304657518863678, -0.1153731569647789, 0.5778350234031677, -0.008022601716220379, 0.5652508735656738, 0.7795666456222534, -0.08332562446594238, 0.8899226784706116, 0.07346567511558533, 0.4276340901851654, -0.9795467257499695, -0.510002851486206, 0.0004086886765435338, -0.8291788697242737, -0.3058473467826843, -0.07932740449905396, -0.5041812658309937, -0.3945329189300537, -0.2015773355960846, 0.3638930916786194, -0.43218865990638733, 0.13393473625183105, 1.1150321960449219, 0.3269975185394287, 0.8690351247787476, -0.21574082970619202, -0.9125572443008423, -0.7299533486366272, -1.0222209692001343, 0.1877579689025879, -0.7004162669181824, -0.31511780619621277, -0.2919103503227234, -0.10299898684024811, -0.5519594550132751]}, "authors": [{"authorId": "2264598842", "name": "Wei Zhu"}, {"authorId": "2221324582", "name": "Ming Tan"}], "references": [{"paperId": "e6e5c6468466fd2ece4e7653f1b4cb4f965b458c", "title": "F-PABEE: Flexible-Patience-Based Early Exiting For Single-Label and Multi-Label Text Classification Tasks"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "a981a57848e19adb80c4a29471fbb798ac050a8f", "title": "Late Prompt Tuning: A Late Prompt Could Be Better Than Many Prompts"}, {"paperId": "41129978a894dfc9726664444d6d0f7f468416cd", "title": "Sparse Structure Search for Parameter-Efficient Tuning"}, {"paperId": "a7b92f9c62cdf35c37d9ccdb20e43807eb86900a", "title": "IDPG: An Instance-Dependent Prompt Generation Method"}, {"paperId": "62b4845be5a4b8ccc7ac3896d03c023193208e95", "title": "Instance-Aware Prompt Learning for Language Understanding and Generation"}, {"paperId": "002c58077a1f1b296468b117230a1199e91f35c2", "title": "Black-Box Tuning for Language-Model-as-a-Service"}, {"paperId": "a3184d40d390793232c99c89b57b8f65c16320b2", "title": "ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation"}, {"paperId": "f3a332ff1b73acda482e5d83696b2c701f487819", "title": "P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"}, {"paperId": "775514b8f5a320b8772f93a3168701ad0c9eeebb", "title": "LiST: Lite Prompted Self-training Makes Parameter-efficient Few-shot Learners"}, {"paperId": "84310f76cf8909f87c6a7f2ed30ae28214cc9eab", "title": "LeeBERT: Learned Early Exit for BERT with cross-level optimization"}, {"paperId": "4690eb050572a279f94560b6bbdccaae577b45f5", "title": "MVP-BERT: Multi-Vocab Pre-training for Chinese BERT"}, {"paperId": "520bd2331cca8d5a9c032c186a2a0f7704ead6ff", "title": "R-Drop: Regularized Dropout for Neural Networks"}, {"paperId": "339b2b711fb5b228d097b03ebc3e62a521779235", "title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "656ed155c2d345c19d9bff4b50f2ae00db8407cc", "title": "Compacter: Efficient Low-Rank Hypercomplex Adapter Layers"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "bc37c6bdb8f39929a58b30464f72d6aa46cddc17", "title": "GPT Understands, Too"}, {"paperId": "85e7d63f75c0916bd350a229e040c5fbb1472e7a", "title": "Making Pre-trained Language Models Better Few-shot Learners"}, {"paperId": "bdeec55f95fd6b73e3e4635459b14c7248543efb", "title": "AdapterDrop: On the Efficiency of Adapters in Transformers"}, {"paperId": "15e5f85bf12c901efea51dee91dcea5d96572c96", "title": "Medical Knowledge Graph to Enhance Fraud, Waste, and Abuse Detection on Claim Data: Model Development and Performance Evaluation"}, {"paperId": "056935031bc5cf0aeeaa0946320de26e14a1817e", "title": "Revisiting Few-sample BERT Fine-tuning"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "98ef0db84e62aef969629264c9de1f4d0013f3b9", "title": "AdapterFusion: Non-Destructive Task Composition for Transfer Learning"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "69599593f93023e2f91ef6673ee9860f85777d98", "title": "NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search"}, {"paperId": "3cb1103dd1fedddc7524888eed519ebe09ac7f0c", "title": "Progressive DARTS: Bridging the Optimization Gap for NAS in the Wild"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "a7ce95c6f674b7b5b19a532491d160d142f8b2d6", "title": "FairNAS: Rethinking Evaluation Fairness of Weight Sharing Neural Architecture Search"}, {"paperId": "95a251513853c6032bdecebd4b74e15795662986", "title": "What Does BERT Look at? An Analysis of BERT\u2019s Attention"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "c1f457e31b611da727f9aef76c283a18157dfa83", "title": "DARTS: Differentiable Architecture Search"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "fe9b8aac9fa3bfd9724db5a881a578e471e612d7", "title": "Efficient Neural Architecture Search via Parameter Sharing"}, {"paperId": "2ec7156913117949ab933f27f492d0149bc0031f", "title": "Learning Sparse Neural Networks through L0 Regularization"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "6af58c061f2e4f130c3b795c21ff0c7e3903278f", "title": "Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales"}, {"paperId": "167e1359943b96b9e92ee73db1df69a1f65d731d", "title": "A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts"}, {"paperId": "99caef1072128737f3311b368c4cb6c6d82c1f45", "title": "The TREC question answering track"}, {"paperId": "c136f3882f1d466a494e9c52d424b4197b16be04", "title": "Learned Adapters Are Better Than Manually Designed Adapters"}, {"paperId": "4243ba22834129c254543198b7f36d364a1a0eb2", "title": "BADGE: Speeding Up BERT Inference after Deployment via Block-wise Bypasses and Divergence-based Early Exiting"}, {"paperId": "8bd3198940c205bad825c63b1950dfc2963a38e8", "title": "NAG-NER: a Unified Non-Autoregressive Generation Framework for Various NER Tasks"}, {"paperId": "ec936b808e0fab9281c050ad4010cddec92c8cbe", "title": "P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks"}, {"paperId": null, "title": "Parameterized hypercomplex graph neural networks for graph classification"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "74512e17ba6e9617260bf9a65503ffa22bc66e3a", "title": "Global Attention Decoder for Chinese Spelling Error Correction"}, {"paperId": "fc5e25efe0a30230b553c817e38bc8308e127a08", "title": "paht_nlp @ MEDIQA 2021: Multi-grained Query Focused Multi-Answer Summarization"}, {"paperId": "6fbd2bcf27c3df92c824406888cd9b25ceff31e3", "title": "GAML-BERT: Improving BERT Early Exiting by Gradient Aligned Mutual Learning"}, {"paperId": null, "title": "Pre-trained models: Past, present"}, {"paperId": null, "title": "Transform-ers: State-of-the-art natural language processing"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "BERT: Pre-training"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "e808f28d411a958c5db81ceb111beb2638698f47", "title": "The PASCAL Recognising Textual Entailment Challenge"}, {"paperId": "1cff7cc15555c38607016aaba24059e76b160adb", "title": "Annotating Expressions of Opinions and Emotions in Language"}, {"paperId": null, "title": "2022. Context-tuning: Learning contextualized prompts for natural language generation"}, {"paperId": null, "title": "2022. Delta tuning: A comprehensive study of parameter efficient methods for pre-trained language models"}, {"paperId": null, "title": "2023b. Acf: Aligned contrastive fine-tuning for language and vision tasks"}]}