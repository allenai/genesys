{"paperId": "be76b0f32e287d866bc7aefc700052f9825ed3ce", "title": "BudgetLongformer: Can we Cheaply Pretrain a SotA Legal Language Model From Scratch?", "abstract": "Pretrained transformer models have achieved state-of-the-art results in many tasks and benchmarks recently. Many state-of-the-art Language Models (LMs), however, do not scale well above the threshold of 512 input tokens. In specialized domains though (such as legal, scientific or biomedical), models often need to process very long text (sometimes well above 10000 tokens). Even though many efficient transformers have been proposed (such as Longformer, BigBird or FNet), so far, only very few such efficient models are available for specialized domains. Additionally, since the pretraining process is extremely costly in general - but even more so as the sequence length increases - it is often only in reach of large research labs. One way of making pretraining cheaper is the Replaced Token Detection (RTD) task, by providing more signal during training, since the loss can be computed over all tokens. In this work, we train Longformer models with the efficient RTD task on legal data to showcase that pretraining efficient LMs is possible using much less compute. We evaluate the trained models on challenging summarization tasks requiring the model to summarize long texts to show to what extent the models can achieve good performance on downstream tasks. We find that both the small and base models outperform their baselines on the in-domain BillSum and out-of-domain PubMed tasks in their respective parameter range. We publish our code and models for research purposes.", "venue": "arXiv.org", "year": 2022, "citationCount": 11, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2211.17135", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work trains Longformer models with the efficient RTD task on legal data to showcase that pretraining efficient LMs is possible using much less compute and finds that both the small and base models outperform their baselines on the in-domain BillSum and out-of-domain PubMed tasks in their respective parameter range."}, "embedding": {"model": "specter_v2", "vector": [0.24913151562213898, 0.8516275882720947, -0.5234706401824951, -0.10406746715307236, -0.6595590710639954, -0.35464370250701904, 0.8156057000160217, -0.09542082995176315, -0.7448534369468689, 0.038990169763565063, 0.8921114206314087, -0.1150941401720047, 0.533176600933075, 0.17790572345256805, -0.19065845012664795, 0.06401430815458298, -0.7756699323654175, 0.14675754308700562, -0.2128189653158188, -0.23374855518341064, -0.33685919642448425, -0.770145833492279, -0.3393397927284241, 0.10584762692451477, 0.3999834656715393, 0.13276681303977966, -0.13510020077228546, 0.6473814249038696, -0.18203264474868774, 0.6005984544754028, -0.015340290032327175, -0.4028466045856476, 0.18579941987991333, -0.09492981433868408, -0.4042663872241974, -0.24055659770965576, 0.6665152907371521, -0.5024152398109436, -0.4705400764942169, 0.7589482665061951, 0.24358780682086945, 0.0768120065331459, 0.37000200152397156, -0.2136635184288025, -0.43356868624687195, 1.5581021308898926, 0.7299644351005554, 0.8894719481468201, -0.18167881667613983, -0.47638314962387085, 1.4278639554977417, -0.9229590892791748, 0.8328004479408264, 1.3698967695236206, 0.41791588068008423, 0.7462419271469116, 0.04138205572962761, -0.6124356985092163, 0.6292794942855835, 0.4799632430076599, -0.8089369535446167, -0.5531637668609619, -0.1301746368408203, 0.10977514088153839, 2.045513391494751, -0.3760626018047333, -0.01931142993271351, 0.3884899914264679, -0.20749789476394653, 1.4679539203643799, -0.2978873550891876, -0.553051769733429, -0.5193721652030945, -0.17215770483016968, 0.2925744652748108, 0.9082009196281433, -0.2985953092575073, 0.11038406938314438, -0.9448269009590149, -0.1605493128299713, -0.05544919893145561, -0.16127993166446686, 0.023093100637197495, 0.5175328254699707, -0.17384843528270721, 0.5216297507286072, 0.2857888340950012, 1.2879959344863892, 0.0737789049744606, 0.7000488638877869, 0.7870705723762512, 0.531358003616333, 0.12091468274593353, 0.7184257507324219, -0.056939709931612015, 0.4443916976451874, -1.420871615409851, 0.320375919342041, -0.20069359242916107, 0.7045309543609619, -0.343902587890625, 0.5652469396591187, -1.1195513010025024, 0.04148655757308006, 1.0157281160354614, 0.23864924907684326, 0.6501168012619019, -0.7211835980415344, 0.3807859718799591, -0.7209134697914124, 0.17472203075885773, -0.2178279161453247, -0.24588297307491302, -0.25636276602745056, -0.8114601969718933, -1.4711674451828003, -0.4797544479370117, 0.020325446501374245, -0.8997303247451782, 0.858689546585083, -0.3046051263809204, 0.13967305421829224, 0.11510922759771347, 0.3646851181983948, 0.897725522518158, 0.6891040205955505, 0.2675410211086273, -0.09669748693704605, 0.6879666447639465, -0.6291794180870056, -0.9321267008781433, -0.9241055846214294, 0.9417296051979065, -0.3554924726486206, -0.03361665457487106, 0.10993155092000961, -1.238824486732483, -0.7251652479171753, -0.8900813460350037, -0.38217297196388245, -0.7804613709449768, 0.4055151343345642, 0.6172084212303162, 0.7178152203559875, -0.7874581813812256, 0.9007060527801514, -0.20684048533439636, -0.26008662581443787, 0.46570929884910583, -0.38436460494995117, 0.2234133929014206, -0.33505475521087646, -1.6641336679458618, 0.607704222202301, 0.1914045214653015, -0.7114266157150269, -0.01089512649923563, -0.4989398717880249, -1.4566540718078613, 0.07685916870832443, 0.28971371054649353, -0.385012686252594, 1.065621256828308, 0.3031802177429199, -1.2245192527770996, 0.984077513217926, -0.6072123050689697, -0.4654283821582794, 0.6102906465530396, -0.6436819434165955, -0.4147915542125702, -0.41334739327430725, 0.09318550676107407, 0.23612457513809204, 0.28500503301620483, 0.21038702130317688, -0.08556363731622696, 0.510977566242218, -0.29054611921310425, -0.43066322803497314, -0.10927706211805344, 1.0402653217315674, -0.3541010916233063, -0.26267871260643005, -0.061657268553972244, 0.8213146328926086, -0.12344095855951309, -0.4174635708332062, -0.7536919116973877, -1.3809586763381958, 0.46189722418785095, -0.3483178913593292, 1.298993706703186, -0.8185428380966187, -0.7658851742744446, -0.3143635094165802, -0.5246970653533936, 0.2737188935279846, -0.6552556157112122, 0.5263983011245728, -0.3579731285572052, 0.6329894065856934, -0.27392783761024475, -1.3913366794586182, 0.4845932126045227, -0.2806027829647064, -0.8399000763893127, 0.27246204018592834, 0.35075947642326355, 1.088277816772461, -0.8121504783630371, 0.02988828904926777, -0.08558406680822372, 0.019191795960068703, -1.1073709726333618, 0.9978369474411011, -0.23877160251140594, -0.2592310607433319, 0.04167976602911949, -0.014921088702976704, 0.1950482577085495, 0.024376390501856804, 0.07561447471380234, -0.28167471289634705, -0.49868473410606384, 0.554266631603241, -0.5583670139312744, 1.5569266080856323, 0.015072153881192207, 0.43896961212158203, 0.03898240625858307, -0.9421802163124084, -0.2999608516693115, 0.5759381651878357, 0.016384467482566833, -0.38859814405441284, 0.4080052673816681, 0.37585240602493286, -0.6786510944366455, 0.09175106883049011, 0.8144994974136353, 0.5165530443191528, -0.6014655828475952, 0.28803858160972595, 0.6213622689247131, -0.2817828953266144, 0.9837809205055237, 0.8812471628189087, 0.787021279335022, 0.2723347842693329, 0.4767778217792511, 0.2809605002403259, 0.33361583948135376, -0.6948552131652832, 0.22462812066078186, 0.7216440439224243, 0.6318652033805847, 0.8652265071868896, 0.47874879837036133, -0.22880688309669495, -0.5260677933692932, 0.025880254805088043, 0.406782865524292, 1.210964322090149, -0.45265451073646545, -0.4367835223674774, -0.6474847793579102, -0.17822158336639404, -0.2581157982349396, 0.08279404789209366, -0.13230866193771362, -0.04007004573941231, -0.8967176079750061, -1.0155251026153564, 1.1952476501464844, 0.007306373678147793, 0.6693665385246277, -0.39542415738105774, -0.2954401671886444, -0.24097514152526855, 0.17507535219192505, -0.8017393350601196, -0.6763137578964233, 0.032495543360710144, -0.09427469968795776, -0.18173594772815704, -0.30018290877342224, 0.1301025003194809, 0.130587637424469, -0.8032425045967102, 0.6083393692970276, -0.4163771867752075, -0.6308029890060425, 0.014746621251106262, 0.3838202655315399, -0.5454663634300232, -0.738578736782074, 0.2131880819797516, -0.022303452715277672, -0.36211493611335754, -0.05191780999302864, 0.5996493697166443, 0.13860465586185455, -0.40066686272621155, -0.7208712100982666, -0.19694700837135315, 0.03622087463736534, 0.3123026490211487, 0.350419819355011, -0.11451852321624756, 0.1340908259153366, -1.3972469568252563, 0.8541433215141296, 0.09865206480026245, -0.40397945046424866, 0.21780423820018768, -0.4865224063396454, -0.30938720703125, 0.5977049469947815, -0.4172806441783905, -0.2919772267341614, -0.9735924005508423, -0.025059470906853676, -0.024761227890849113, 0.08008211851119995, 0.6239190697669983, 0.009945925325155258, 0.8613039255142212, 0.3343265950679779, 0.3592050075531006, -0.20328357815742493, -0.2754538357257843, 0.7993321418762207, -0.6613044142723083, 0.5540663003921509, 0.40747538208961487, 0.5877837538719177, 0.260547399520874, -0.38707906007766724, -0.631822943687439, -0.5879942178726196, -0.797603189945221, -0.18566317856311798, -0.17792919278144836, -0.07329324632883072, -0.6208133101463318, -0.530192494392395, 0.057111259549856186, -1.1387354135513306, -0.26890861988067627, 0.05113275349140167, -0.47709694504737854, -0.0716862753033638, -0.7102059721946716, -1.1628531217575073, -0.6973139643669128, -0.7325929999351501, -0.2373306155204773, 0.6795017719268799, -0.03658683970570564, -0.4535280466079712, -0.28127461671829224, -0.06083439663052559, -0.1907530128955841, 0.8655509948730469, -0.16855069994926453, 0.6400224566459656, -0.12867102026939392, -0.11109090596437454, -0.5390276908874512, 0.1494230329990387, 0.6777916550636292, -0.24920304119586945, 0.06413759291172028, -0.5943989157676697, 0.11661189049482346, -0.4771939218044281, -0.5266116857528687, 0.8154835104942322, 0.42077064514160156, 0.3425827622413635, -0.13996584713459015, -0.3880016803741455, 0.2361566424369812, 1.0141338109970093, -0.8826838135719299, 0.033025942742824554, -0.10532265156507492, 0.6182168126106262, 0.17445790767669678, 0.11225904524326324, 0.538358747959137, 0.05799335986375809, 0.1316915899515152, -0.3926216959953308, -0.16263626515865326, -0.02259030193090439, -0.5683788061141968, 0.9645195603370667, 1.3362245559692383, 0.3357006311416626, -0.15272578597068787, -0.8057418465614319, 0.8241695165634155, -1.3523905277252197, -1.4253000020980835, 0.526862382888794, 0.22367329895496368, 0.7582665681838989, -0.14627738296985626, -0.377397745847702, 0.1682078093290329, -0.00954709853976965, 0.6145492792129517, -0.44289469718933105, -0.6278388500213623, -0.376619428396225, 0.5936324596405029, 0.6517378687858582, 0.5905998945236206, -0.4449479877948761, 0.7716207504272461, 14.987035751342773, 0.9599093198776245, -0.27897414565086365, 0.6552557945251465, 0.5767948031425476, -0.21476376056671143, -0.17257453501224518, -0.2206849604845047, -1.48108971118927, -0.2790045142173767, 0.9099727272987366, -0.403949111700058, 0.3185269236564636, 0.3249654471874237, 0.49863478541374207, -0.0817209780216217, -0.6037775278091431, 0.3377116024494171, 0.724675178527832, -1.4181932210922241, 0.1679709255695343, 0.2059110701084137, 0.3682185709476471, 0.6473184823989868, 0.7681557536125183, 0.648580014705658, 0.31559574604034424, -0.5602245330810547, 0.8675789833068848, 0.2656792998313904, 0.9615665078163147, 0.0017614398384466767, 0.629578709602356, 0.7804890275001526, -0.5333265662193298, -0.23539645969867706, -0.7549591660499573, -0.9734516739845276, 0.6018232107162476, 0.48185673356056213, -0.6636691689491272, -0.02526264265179634, -0.41450631618499756, 1.3046547174453735, 0.47049444913864136, 0.562156617641449, -0.380775511264801, 0.8583336472511292, -0.10017666220664978, 0.1638026088476181, 0.36675938963890076, 0.6811504364013672, 0.4780048727989197, 0.5178282856941223, 0.22923621535301208, 0.0761343389749527, 0.035385310649871826, 0.3075571060180664, -0.6973098516464233, 0.012572701089084148, -0.28090333938598633, -0.42623403668403625, -0.09927456825971603, 0.7763040065765381, 0.5326313972473145, -0.04351179301738739, -0.13177767395973206, 0.1999228298664093, 0.33397161960601807, -0.16376633942127228, -0.3366281986236572, -0.21351458132266998, 0.20355667173862457, -0.11372537165880203, 0.06063004955649376, 0.3737918734550476, -0.05308852344751358, -0.9574393630027771, -0.6794676184654236, -0.16855525970458984, 0.7566492557525635, -0.3517254889011383, -0.7482642531394958, 0.4049552381038666, -0.13998320698738098, -0.5563536882400513, 0.2908517122268677, -0.76584792137146, -0.35578998923301697, 0.3958825469017029, -2.030468463897705, -0.6667769551277161, 0.7518734335899353, -0.3877689242362976, -0.2739965319633484, 0.1638762205839157, 1.218286395072937, 0.41829541325569153, -0.39440757036209106, 0.2474542111158371, 0.3712187707424164, 0.15164630115032196, 0.2557694911956787, -0.9301275610923767, 0.5657647848129272, 0.6007511019706726, -0.1296301931142807, 0.708118736743927, 0.3026151955127716, 0.012695305049419403, -0.5689944624900818, -0.11285089701414108, 1.111547589302063, -1.0679792165756226, -0.3541204333305359, -0.7047721147537231, -0.6367682218551636, 0.07292585074901581, 0.7924430966377258, -0.47142574191093445, 0.43468645215034485, 0.004220166243612766, -0.3232579529285431, -0.07682789862155914, -0.927656352519989, -0.15592221915721893, 0.7910112142562866, -0.5764868259429932, -0.6493122577667236, 0.1000981405377388, -0.011384761892259121, -1.0481345653533936, -0.2959064543247223, -0.3142390549182892, -0.002159840427339077, 0.04689298942685127, 0.7305406332015991, -0.4303993880748749, 0.7089880704879761, 0.6613742113113403, 0.3330709636211395, -0.8248867392539978, 0.15453937649726868, -1.0142289400100708, 0.12071266025304794, 0.45299533009529114, 0.6572601199150085, -0.26222848892211914, 0.08572421222925186, 0.752016007900238, 0.13822884857654572, -0.32110095024108887, -1.0471231937408447, -0.6402474045753479, 0.34732338786125183, -0.3555547893047333, 0.16070693731307983, 0.06032582372426987, 0.2353835254907608, -0.18699339032173157, 0.09160078316926956, 0.45555177330970764, -0.421894371509552, -0.7232984304428101, 0.4160584509372711, 0.19549551606178284, 0.17270909249782562, -0.6292343735694885, -0.35400184988975525, -1.195227861404419, 0.17214882373809814, -1.182909369468689, -0.023576876148581505, -1.1436035633087158, -0.530354917049408, 0.37021538615226746, -0.2617712616920471, 0.2906017005443573, 0.16360913217067719, -0.45299389958381653, -0.4501582384109497, -0.9900550842285156, -0.6675835251808167, 0.7197317481040955, 0.7075588703155518, -1.1919111013412476, 0.3171590268611908, -0.2256767451763153, -0.0909651666879654, 0.16792131960391998, 0.2733282446861267, -0.6907778382301331, -0.5030039548873901, -1.1438989639282227, 0.3023236095905304, -0.2853047251701355, -0.34788066148757935, -0.521759033203125, 0.6043460369110107, 0.5316628813743591, -0.19909219443798065, -0.256384015083313, 0.19523686170578003, -0.3782193660736084, -0.5789235830307007, 0.5300660729408264, -0.8089490532875061, -0.20081578195095062, -0.16582362353801727, -0.8684686422348022, -0.4138622283935547, 0.4593983292579651, 0.08528661727905273, -1.1203210353851318, -0.19027504324913025, 0.425721138715744, -0.6133852005004883, 0.19232767820358276, -0.5848811268806458, -0.006191601045429707, -0.9396680593490601, -0.2499883621931076, 0.0009224899113178253, 0.6099539995193481, -0.33486753702163696, 0.7993020415306091, 0.1374257653951645, -0.8927567601203918, -0.218679279088974, -0.2193252593278885, -0.20599479973316193, -0.16981522738933563, 0.3537420928478241, -0.001955011859536171, -0.20919959247112274, 0.7151935696601868, 0.46273303031921387, 0.6658280491828918, -1.1830042600631714, -0.38393011689186096, 0.6607372760772705, -0.8713055849075317, -0.2693850100040436, 1.2791146039962769, -0.9064455032348633, -0.6960340142250061, 0.1718098372220993, -1.2635282278060913, -0.6370201110839844, 0.04255151003599167, 0.6876790523529053, 0.25828954577445984, -0.12436316162347794, -0.20354871451854706, -0.6342364549636841, 0.10854625701904297, -0.038190945982933044, -0.4981567859649658, 1.0326943397521973, 0.10416271537542343, -0.34252455830574036, 0.46211060881614685, 0.7383384704589844, -0.18169553577899933, -0.09863756597042084, -0.6406072974205017, -0.24797198176383972, 0.07956548780202866, 0.13418112695217133, -0.20927181839942932, -0.3255056142807007, 0.8523193001747131, 0.06330575793981552, 0.6306136250495911, -0.16523873805999756, -0.08301379531621933, 0.37943288683891296, 0.7460870146751404, 0.05121845752000809, -1.1351028680801392, -0.7215705513954163, 1.3916925191879272, 1.091263771057129, -0.7474616765975952, 0.5889481902122498, -0.1586655229330063, -0.4238322377204895, 0.6102048754692078, 0.06770319491624832, -0.1632324457168579, 0.8404151201248169, -0.2428625524044037, 0.16604569554328918, 0.2782467007637024, -0.7748569250106812, -0.42895597219467163, 0.6159494519233704, 0.6514154672622681, 0.8574442863464355, 0.022123493254184723, -0.45900946855545044, 1.1488242149353027, -0.21501967310905457, 0.05385356396436691, 0.5774637460708618, 0.4828546643257141, -0.1602235585451126, -0.3731911778450012, 0.09162195771932602, 0.5338460803031921, -0.8862701654434204, -0.4062594473361969, -0.15377050638198853, 0.20464253425598145, 0.5273559093475342, 0.5328503251075745, 0.23610611259937286, 0.7184442281723022, 0.7968881726264954, 0.3366750478744507, 0.469969242811203, -0.8912462592124939, -0.2286774069070816, -0.3389735221862793, -0.3162860572338104, -0.14162737131118774, -0.3879917860031128, -0.7990272641181946, -0.7332503199577332, -0.08859559893608093, 0.18190591037273407, 0.2847478687763214, 0.16657203435897827, 1.3586974143981934, 0.39749687910079956, 0.34792301058769226, -0.38744544982910156, -0.44912225008010864, -0.33763086795806885, -1.0206189155578613, -0.12315092235803604, -0.03189989551901817, 0.051927998661994934, 0.015608899295330048, -0.049226418137550354, 0.0886266753077507]}, "authors": [{"authorId": "67042743", "name": "Joel Niklaus"}, {"authorId": "2060413438", "name": "Daniele Giofr\u00e9"}], "references": [{"paperId": "b79323b909a7671449f0e06b9bd5d8473c58003b", "title": "Multi-LexSum: Real-World Summaries of Civil Rights Lawsuits at Multiple Granularities"}, {"paperId": "f30e95be411456a709e7cb9a8b3a3e557bd0356a", "title": "Clinical-Longformer and Clinical-BigBird: Transformers for long clinical sequences"}, {"paperId": "972706306f85b1bfb40c7d35c796ad5174eb0c9c", "title": "DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing"}, {"paperId": "fd33e77884e69f6bc099990fc2790248af2749d9", "title": "LexGLUE: A Benchmark Dataset for Legal Language Understanding in English"}, {"paperId": "c67843e9ccb8221abb5d2feecc4f3ce2708e9cf2", "title": "Swiss-Judgment-Prediction: A Multilingual Legal Judgment Prediction Benchmark"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "a6a7724763d8adba466519489b0b9d209e7f2d15", "title": "BARTScore: Evaluating Generated Text as Text Generation"}, {"paperId": "3a9efbd662326ec9338d4eaa32543f77a0834974", "title": "An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models"}, {"paperId": "1f133158a8973fb33fea188f20517cd7e69bfe7f", "title": "FNet: Mixing Tokens with Fourier Transforms"}, {"paperId": "1e3e65e7773b7869d9bd7f5394b54199e48195e6", "title": "Lawformer: A Pre-trained Language Model for Chinese Legal Long Documents"}, {"paperId": "7a16d9b4e04300d034502dc7dd58428714594e2c", "title": "Carbon Emissions and Large Neural Network Training"}, {"paperId": "529edafa160a77901bec123cf8858e6c08f6cd06", "title": "When does pretraining help?: assessing self-supervised learning for law and the CaseHOLD dataset of 53,000+ legal holdings"}, {"paperId": "6a1b25f7a67395ad1e676027322913acbb0a0635", "title": "CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review"}, {"paperId": "b5b006dc558cb7fbd532d67e989173b536e8ac80", "title": "MiniLMv2: Multi-Head Self-Attention Relation Distillation for Compressing Pretrained Transformers"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "8b9d77d5e52a70af37451d3db3d32781b83ea054", "title": "On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "e816f788767eec6a8ef0ea9eddd0e902435d4271", "title": "Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks"}, {"paperId": "5290d7921f0266c8b50b79fc8a0b7d22868f4f60", "title": "The Cost of Training NLP Models: A Concise Overview"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "baf60d13c98916b77b09bc525ede1cd610ed1db5", "title": "Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "edc90c96bc3b18ad73815db01795be92d0300417", "title": "BillSum: A Corpus for Automatic Summarization of US Legislation"}, {"paperId": "7402b604f14b8b91c53ed6eed04af92c59636c97", "title": "Well-Read Students Learn Better: On the Importance of Pre-training Compact Models"}, {"paperId": "ae677b0441bfaea0e0c78acfa8758fff353ab715", "title": "Neural Machine Translation with Byte-Level Subwords"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "40345901fd28cbf65791c34671db6548b1089ed4", "title": "BIGPATENT: A Large-Scale Dataset for Abstractive and Coherent Summarization"}, {"paperId": "d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "title": "Energy and Policy Considerations for Deep Learning in NLP"}, {"paperId": "aca16f64ddbf187f8944118c8f72777c3d682521", "title": "Neural Legal Judgment Prediction in English"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "030ce8003080c6f103b8a8b1e46137b7ee458cee", "title": "Multi-Task Learning for Abstractive and Extractive Summarization"}, {"paperId": "156d217b0a911af97fa1b5a71dc909ccef7a8028", "title": "SciBERT: A Pretrained Language Model for Scientific Text"}, {"paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "13bc4e683075bdd6a3f0155241c276a772d4aa06", "title": "Generative adversarial networks"}, {"paperId": null, "title": "BioELEC-TRA:Pretrained Biomedical text Encoder using Dis-criminators"}, {"paperId": null, "title": "LEGAL-BERT: The Muppets straight out of Law School"}, {"paperId": null, "title": "ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators"}, {"paperId": null, "title": "Reformer: The Ef\ufb01cient Transformer arXiv:2001.04451 [cs, stat]"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Universal Language Model Fine-tuning for Text Classi\ufb01cation"}, {"paperId": null, "title": "DEFINITIONS. \u201cAs used in this title: \u201c(1) Activity; program.\u2013The term \u2018program or activity"}, {"paperId": null, "title": "Prodromos Malakasiotis"}, {"paperId": null, "title": "2022. Pile of Law: Learning Re-sponsible Data Filtering from the Law and a 256GB Open-Source"}]}