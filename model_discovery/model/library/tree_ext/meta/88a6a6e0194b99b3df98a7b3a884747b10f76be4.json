{"paperId": "88a6a6e0194b99b3df98a7b3a884747b10f76be4", "title": "A survey of visual neural networks: current trends, challenges and opportunities", "abstract": null, "venue": "Multimedia Systems", "year": 2022, "citationCount": 8, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The basic architectures and current trends of these two types of VNNs, Convolutional neural networks and Transformer networks are introduced and the lightweight, robust and interpretable solutions are summarized and analyzed."}, "embedding": {"model": "specter_v2", "vector": [0.22949673235416412, 0.39168059825897217, -0.195450559258461, 0.16553150117397308, 0.41441965103149414, 0.23147059977054596, 0.4916582405567169, -0.4323717951774597, -0.4883330464363098, -0.6125352382659912, 0.23556268215179443, 0.5267407894134521, 0.764756977558136, -0.3461175560951233, 0.0019505287054926157, 0.10743004083633423, -0.34417232871055603, -0.41451185941696167, 0.9967736005783081, -0.3853125274181366, -0.047530241310596466, -0.010687680914998055, -1.5751490592956543, 0.3557438552379608, -0.2974865734577179, 1.271896243095398, 0.22472165524959564, 1.0169577598571777, -0.2959032654762268, 0.8894214630126953, 0.48297256231307983, -0.12678338587284088, 0.39328089356422424, 0.11877571791410446, -0.3729524314403534, 0.284995436668396, 0.888938307762146, -0.6066198945045471, -0.9460737109184265, 1.0295178890228271, -0.23770305514335632, 0.5953673720359802, 0.4430376887321472, -0.9535508155822754, -0.3295110762119293, -0.12134670466184616, 0.5490463972091675, 0.8967868685722351, -0.5950185060501099, 0.00133455079048872, 1.1370750665664673, -1.0801589488983154, 0.15324491262435913, 1.7905094623565674, 0.6340198516845703, 0.49552974104881287, 0.1339215189218521, -0.5811005234718323, 0.5159796476364136, -0.16447174549102783, -0.2290918380022049, -0.19727736711502075, 0.28788280487060547, -0.5750749111175537, 1.4118260145187378, -0.6363095045089722, 0.3122544288635254, 1.1437923908233643, 0.1062455028295517, 1.3822433948516846, -0.08022575080394745, -0.6678482890129089, -0.15812312066555023, -0.09887765347957611, 0.06304863095283508, 0.9871935248374939, -0.11484971642494202, 0.5495316386222839, -0.80660080909729, 0.5879426002502441, 0.8752655982971191, 0.34535637497901917, 0.1413467526435852, -0.48952680826187134, -0.11866052448749542, 0.964300274848938, 1.1599376201629639, 0.29629406332969666, -0.4627682566642761, 0.9740428328514099, 0.6852011680603027, -0.16371943056583405, -0.5955701470375061, 0.15580375492572784, 0.5157720446586609, 1.0493230819702148, -0.842339813709259, -0.0969930961728096, -0.5339252352714539, 0.8977488875389099, -0.4754910171031952, 0.7315857410430908, -0.3447819948196411, 0.4059138000011444, 1.131476640701294, -0.08227948099374771, 0.17278891801834106, -0.6398140788078308, 0.07386770844459534, -0.6123999953269958, -0.22619019448757172, -0.9484733939170837, 0.20663787424564362, -0.49488961696624756, -0.9354674220085144, -0.09993424266576767, -0.1829935759305954, 0.32072392106056213, -1.4640876054763794, 0.221607968211174, -0.7521097660064697, -0.08129074424505234, -0.029703643172979355, 0.37605494260787964, 0.8455685377120972, 0.5596922039985657, 0.4762674868106842, 0.9060474038124084, 1.0990359783172607, -1.4744712114334106, -0.45106664299964905, -0.995037853717804, -0.35539862513542175, -0.3661573529243469, 0.15715321898460388, -0.16314063966274261, -0.9188893437385559, -1.420627474784851, -0.8663000464439392, 0.0601792074739933, -0.6725471615791321, 0.14684201776981354, 0.9888626933097839, 0.08962255716323853, -1.4698846340179443, 0.7978696227073669, 0.18233728408813477, -0.7748742699623108, 0.7754813432693481, 0.1676551103591919, 0.356372594833374, -0.2260468751192093, -0.8150912523269653, 0.5096041560173035, 0.07839436829090118, -0.32411521673202515, -0.6648108959197998, 0.34601902961730957, -1.2876206636428833, 0.0027520388830453157, -0.25612056255340576, -0.7615405321121216, 0.9888896346092224, -0.5869923830032349, -0.6305593848228455, 0.5230044722557068, 0.07127801328897476, -0.13743987679481506, 0.20457755029201508, 0.1890891194343567, -0.4741445481777191, 0.004355549346655607, -0.19193723797798157, 0.8963919281959534, 0.6164886951446533, -0.31522563099861145, -0.3798448145389557, 0.5438632965087891, -0.13818225264549255, -0.3776497542858124, -0.6686448454856873, 1.3891795873641968, -0.6290000081062317, -0.41972681879997253, 0.4279649555683136, 0.8750353455543518, -0.040118586272001266, 0.29369574785232544, -0.3186761736869812, -0.9197391271591187, 1.1862119436264038, 0.0992063656449318, 0.13151322305202484, -0.8862197995185852, -1.0876842737197876, -0.2789419889450073, 0.12896445393562317, -0.05311746150255203, -1.076377034187317, 0.12709228694438934, -0.3950915038585663, -0.09369543194770813, 0.37141621112823486, -1.0201435089111328, -0.33203092217445374, -0.16366854310035706, -0.5394383668899536, 0.10166414827108383, 0.4112226963043213, 1.2710349559783936, -0.8702628016471863, -0.28403040766716003, 0.39650455117225647, 0.21694481372833252, -0.311553955078125, 1.14775550365448, -0.2938828468322754, -0.3929588496685028, -0.10373478382825851, 0.5352022051811218, 0.03751945495605469, -0.32622820138931274, 0.1114998608827591, -0.9303061366081238, 0.2079256772994995, 0.09188920259475708, -0.05262712761759758, 0.9598149061203003, 0.17185619473457336, 1.4078789949417114, -0.418161004781723, -0.8426358103752136, 0.41255712509155273, 0.23356229066848755, -0.3014051914215088, -0.6683233976364136, 0.8224428296089172, -0.19185732305049896, -0.7670888900756836, 0.05948616936802864, 0.5596942901611328, 0.9226008057594299, -0.2518574297428131, -0.07801785320043564, 0.8863769173622131, -0.09058418869972229, 0.09087412059307098, 0.14611361920833588, 0.26924386620521545, 0.08112610131502151, 0.0022881655022501945, 0.1896030604839325, -0.004966515116393566, -0.8673762083053589, -0.04021552577614784, 0.8007253408432007, 0.023150606080889702, 1.2689967155456543, 0.5818710327148438, -0.9608405828475952, -0.4034385085105896, -0.38506343960762024, 0.7013616561889648, 1.0467740297317505, 0.10486157238483429, 0.30947548151016235, -0.6736724972724915, -0.7613481879234314, -0.503383994102478, -0.6273874640464783, -0.6332180500030518, -0.07116314023733139, 0.08165954798460007, -0.7139599323272705, 1.2528539896011353, 0.6000171899795532, 1.3299728631973267, -1.1542831659317017, -0.6679167747497559, -0.6010195016860962, 0.4114300012588501, -0.9694615602493286, -0.3934924602508545, 0.34623196721076965, -0.7471368908882141, -0.5747578144073486, 0.032725222408771515, -0.5580880045890808, 0.42229747772216797, -0.43123021721839905, 0.6515786051750183, -0.6138457655906677, -0.36724230647087097, 0.03006652742624283, 0.8753954768180847, -0.6867178082466125, -0.26545098423957825, -0.3998570442199707, -0.006809909362345934, 0.016755200922489166, 0.3315049111843109, 0.48266759514808655, -0.1400804966688156, 0.15724729001522064, -0.6671577095985413, -0.30321168899536133, 0.27556851506233215, 0.06607748568058014, 0.9063947796821594, -0.10826608538627625, 0.22035780549049377, -0.6796221733093262, 0.9976264238357544, 0.44974395632743835, -0.49683570861816406, 0.3574203550815582, -0.48906415700912476, -0.14984063804149628, 0.49116724729537964, -0.6209322214126587, -0.17158493399620056, -0.3124869465827942, 0.5279860496520996, -1.1123483180999756, -0.5319375991821289, -0.2579539716243744, 0.4019676744937897, -0.5511249899864197, 0.5583130121231079, 0.139159694314003, 0.40416401624679565, 0.19726340472698212, 0.26218488812446594, -0.7456115484237671, 0.8686363697052002, 0.45746904611587524, 0.09347641468048096, 0.1691366285085678, -0.11492078751325607, -0.62720787525177, -0.5205017924308777, -0.5151429772377014, -0.1938164234161377, -0.9609264135360718, 0.5316022038459778, -0.45355498790740967, -0.5025936365127563, 0.3802119493484497, -1.139430284500122, 0.03459703549742699, -0.07741133123636246, -0.14401830732822418, -0.058085743337869644, -0.9563397765159607, -0.8485661745071411, -0.41629332304000854, -0.6085567474365234, -1.0743014812469482, -0.1727830171585083, 0.7555251717567444, -0.1317288875579834, -0.5618373155593872, -0.6672213077545166, -0.5292869806289673, 1.0175122022628784, 0.2822725772857666, 0.548743486404419, -0.11189036816358566, -0.37957289814949036, -0.32368066906929016, -0.36919793486595154, 1.1283940076828003, -0.0395754836499691, 0.47900837659835815, -1.3274900913238525, 0.33304348587989807, 0.05589704588055611, -0.2749091684818268, 0.9110206365585327, 0.5010380148887634, 0.6819730401039124, 0.5605281591415405, -0.18367575109004974, 0.6212024092674255, 1.4869470596313477, -0.5425199270248413, 0.12542012333869934, 0.1946786791086197, 0.9790791869163513, 0.2883646488189697, -0.6269568800926208, 0.08158945292234421, -0.13320276141166687, -0.08166519552469254, 0.9786757826805115, -0.7771846055984497, -1.0371183156967163, -0.580940306186676, 0.2128809243440628, 0.5865316987037659, 0.21901874244213104, -0.09684304147958755, -0.982970118522644, 1.010711669921875, -1.035399317741394, -0.7282344102859497, 0.7609462141990662, 0.5669906139373779, -0.41097578406333923, 0.17178155481815338, -0.23844529688358307, -0.36895009875297546, 1.0337990522384644, 0.7517150640487671, -0.4968366324901581, -0.6881039142608643, -0.3587552011013031, 0.5471515655517578, 0.4437856674194336, 0.3567591607570648, -0.8145999312400818, 0.3292190432548523, 14.308076858520508, 0.4244248569011688, -0.649290144443512, 0.1775304675102234, 0.6538997888565063, 0.3918702006340027, -0.16144661605358124, -0.16319528222084045, -0.8248355984687805, -0.20920979976654053, 0.5372936725616455, 0.6971824765205383, 0.32096153497695923, 0.625748336315155, -0.16259048879146576, 0.18511360883712769, -0.41591858863830566, 1.2740803956985474, 0.7505977749824524, -1.5201877355575562, 0.5780283808708191, 0.0362226665019989, 0.34839144349098206, 0.9458149671554565, 0.9107597470283508, 0.5015329718589783, 0.31049633026123047, -0.6043256521224976, 0.6106136441230774, 0.08097045123577118, 0.9045403003692627, 0.06748753786087036, 0.5865808129310608, 0.05290091782808304, -1.2372431755065918, -0.2796582877635956, -0.8616136312484741, -0.8725529909133911, -0.08185546845197678, -0.32295718789100647, -0.2661791741847992, -0.5655405521392822, 0.3289215564727783, 1.103854775428772, -0.4514061212539673, 0.7038655281066895, -0.4492530822753906, 0.0777723640203476, -0.15070535242557526, -0.1630718857049942, 0.5891578197479248, 0.5535447001457214, 0.14134076237678528, 0.1136121079325676, -0.27942752838134766, 0.0011008245637640357, 0.1762264370918274, 0.5890442132949829, -0.5630426406860352, -0.5081501007080078, -0.5371248722076416, -0.16113467514514923, -0.5413874983787537, 0.8591870665550232, -0.42518725991249084, 0.3712426424026489, -0.28212302923202515, 0.39823195338249207, 0.19317403435707092, 0.6695274710655212, -0.4754653573036194, -0.5374601483345032, 0.33591988682746887, -0.061752237379550934, 0.5784916877746582, 0.7969599962234497, -0.3388400971889496, -0.5753133893013, -0.688522219657898, 0.17542366683483124, 0.6069688200950623, -1.1971625089645386, -0.7327700853347778, 1.535029411315918, -0.5019676685333252, -0.3352181613445282, 0.5962910056114197, -1.2813458442687988, -0.5966684818267822, 0.4726303219795227, -1.4775490760803223, -0.7714976668357849, -0.44770264625549316, 0.23736262321472168, -0.27260690927505493, -0.41942349076271057, 0.6026483178138733, -0.1030573695898056, -0.1331295520067215, 0.004971453920006752, -0.6326345801353455, 0.7334960699081421, -0.3487285375595093, -0.37865960597991943, 0.7127766609191895, 0.9292123317718506, -0.04550623148679733, -0.30487388372421265, -0.0353984460234642, 0.3265233635902405, 0.07418271154165268, -0.39565205574035645, 0.4934540390968323, -0.3098098337650299, -0.6050310134887695, -0.6757640242576599, -0.5840628147125244, 0.2519124746322632, 0.8886441588401794, 0.3355046510696411, -0.21631282567977905, -0.16036301851272583, -0.8440578579902649, -0.2467474490404129, -0.8178961873054504, 0.09914299100637436, 0.20019182562828064, -0.9865441918373108, -0.5362445712089539, -0.22639523446559906, -0.01589355245232582, -0.47384950518608093, 0.10417268425226212, -0.22768458724021912, 0.11164205521345139, -0.6209741830825806, 1.3856853246688843, -0.9018407464027405, 0.6529240608215332, 0.3410230576992035, -0.4062819182872772, -0.32781246304512024, 0.020086096599698067, -0.5830445885658264, 0.43768393993377686, -0.03641890361905098, 0.025119995698332787, -0.4518390893936157, 0.5718970894813538, 0.4950118958950043, 0.3976840376853943, -0.6280224919319153, -0.4122130572795868, -0.1588677167892456, -0.39310532808303833, -0.6095660924911499, 0.08288680016994476, -0.2725680470466614, -0.6824592351913452, 0.10022975504398346, 0.2905119061470032, 0.2818194627761841, 0.20446309447288513, -0.6293064951896667, 0.041341543197631836, -0.45270004868507385, -0.055710118263959885, -0.7000654339790344, -0.9759953618049622, -1.5236027240753174, -0.056595657020807266, -1.0508222579956055, -0.2427048236131668, -1.3485314846038818, -0.6531749963760376, 0.5385903120040894, -0.7823227643966675, 0.3933168351650238, 0.9565387964248657, 0.03882367163896561, -0.005629663355648518, -0.5832776427268982, -0.6015094518661499, 0.6502697467803955, 1.047896146774292, -1.0544131994247437, 0.20877276360988617, -0.014109564945101738, 0.054333802312612534, 0.8489944338798523, 0.2602243721485138, -0.5415294766426086, -0.8967204093933105, -1.1189203262329102, -0.2879926264286041, -0.18783362209796906, 0.26124757528305054, -1.2669272422790527, 1.3155580759048462, 0.39247241616249084, 0.5863560438156128, -0.127591073513031, 0.4096800982952118, -0.8182995319366455, -0.7210305333137512, 0.4307485818862915, -0.5876930356025696, 0.2479826658964157, 0.35898980498313904, -0.22948800027370453, -0.907107949256897, 0.9006567597389221, 0.65615314245224, -0.8673915863037109, -1.3847979307174683, 0.7435202598571777, -0.5710477828979492, 0.08097095787525177, 0.12005279213190079, -0.7304832935333252, -1.0951582193374634, -0.3118591606616974, -0.26141026616096497, 0.26000285148620605, -0.6609048843383789, 1.0882545709609985, 1.5931529998779297, -1.2182071208953857, 0.16593629121780396, 0.737156093120575, -0.17163138091564178, 0.00017602696607355028, 0.3183377981185913, 0.2575156092643738, -0.5640617609024048, 0.2241494059562683, -0.40705621242523193, 0.021811071783304214, -0.9034806489944458, 0.22953809797763824, 1.6800298690795898, 0.0805136039853096, -0.15058894455432892, 1.3395695686340332, 0.169709712266922, -0.6586563587188721, 0.6646688580513, -1.2930994033813477, -0.8496383428573608, 0.0003454100515227765, 0.404968798160553, -0.24832744896411896, 0.05845828354358673, -0.36616337299346924, -0.4783762991428375, 0.24311833083629608, 0.1380208283662796, -0.3569249212741852, 0.3988991677761078, 0.2180282026529312, -0.1731640249490738, 0.2452772557735443, 0.909098207950592, -1.174135446548462, -1.427635908126831, -0.8792253732681274, -0.4461238384246826, -0.406954824924469, 0.0092255137860775, -0.06354872137308121, -1.6431745290756226, 0.9171745181083679, 0.908860981464386, 0.18759417533874512, 0.7361966371536255, -0.013065467588603497, 0.25200358033180237, 0.44824153184890747, -0.4999360144138336, -0.38292503356933594, 0.07754743844270706, 1.2362871170043945, 1.011974573135376, -0.6687341928482056, 0.07230762392282486, -0.22536177933216095, -0.473234623670578, 1.181885004043579, 0.5080239772796631, -0.5452583432197571, 1.0321441888809204, -0.49571478366851807, 0.2548242509365082, 0.015534861944615841, -0.4559849202632904, -0.30744224786758423, 0.9160857200622559, 1.3121470212936401, 0.21156978607177734, -0.17089375853538513, 0.785509467124939, 0.4975006878376007, 0.388569712638855, -0.10460886359214783, 0.5738348364830017, 0.033921338617801666, -0.12414491176605225, 0.2848075330257416, -0.05112553387880325, 0.5469545125961304, -0.47606125473976135, -0.39265257120132446, 0.0509578213095665, 0.8893669843673706, 0.3486480116844177, 0.8855178952217102, 0.9498948454856873, -0.36115962266921997, 1.0032615661621094, -0.1741936206817627, 0.4278618395328522, -0.2933289706707001, -0.5246142745018005, -0.13332928717136383, -0.7748088240623474, -0.24475687742233276, -0.4535016715526581, -0.6093964576721191, -0.03013964556157589, -0.2002726048231125, 0.5188934803009033, -0.4425281286239624, 0.185516357421875, 0.6297253966331482, 0.13005918264389038, 0.8269587755203247, -0.49372726678848267, -0.44966357946395874, -0.1710379272699356, -0.6314024329185486, -0.07982105016708374, -0.3869814872741699, 0.36701977252960205, -0.5520120859146118, -0.32485225796699524, -0.1336270421743393]}, "authors": [{"authorId": "2056811337", "name": "Ping Feng"}, {"authorId": "2173392", "name": "Zhenjun Tang"}], "references": [{"paperId": "270195c8ecc14b98a206461282b88f8fae798932", "title": "Vision GNN: An Image is Worth Graph of Nodes"}, {"paperId": "58c486ad4020177f5ed3d9f2883f3fc327b55770", "title": "MiniViT: Compressing Vision Transformers with Weight Multiplexing"}, {"paperId": "807159f51dbe947e5fd58fff4eef94726d48c4eb", "title": "TMIF: transformer-based multi-modal interactive fusion for automatic rumor detection"}, {"paperId": "a412398394cdc7a8c11733a2df1ca57a9a884a88", "title": "Predicting skeleton trajectories using a Skeleton-Transformer for video anomaly detection"}, {"paperId": "13f7a106bb3814ad1fab25fd1356e99e91f402d3", "title": "Q-ViT: Fully Differentiable Quantization for Vision Transformer"}, {"paperId": "dc2a41c444a4af205664e50190951d5433fdedf5", "title": "PRIME: A Few Primitives Can Boost Robustness to Common Corruptions"}, {"paperId": "e939b55a6f78bffeb00065aed897950c49d21182", "title": "Searching the Search Space of Vision Transformer"}, {"paperId": "35c0800e657faa18cf3fc3629bdbeafbb976b006", "title": "Are Transformers More Robust Than CNNs?"}, {"paperId": "aa62d5e43cb151cd574e4df058b4c6a509d62644", "title": "Self-Supervised Representation Learning: Introduction, advances, and challenges"}, {"paperId": "071f5565484ee844fe69b0e32e502e86ceb5196a", "title": "Deep Long-Tailed Learning: A Survey"}, {"paperId": "3717e40f0fe1a528f5be87f6022f6be771fe836c", "title": "Reality Transform Adversarial Generators for Image Splicing Forgery Detection and Localization"}, {"paperId": "39b492db00faead70bc3f4fb4b0364d94398ffdb", "title": "Do Vision Transformers See Like Convolutional Neural Networks?"}, {"paperId": "da80008114ba95d92b68af977a6df042ddfb47c0", "title": "TransForensics: Image Forgery Localization with Dense Self-Attention"}, {"paperId": "da9e16d4036bc00470e083d6877a8215567b5fd8", "title": "OSCAR-Net: Object-centric Scene Graph Attention for Image Attribution"}, {"paperId": "0b036cd5dfc49d835d0c759c8ca31d89f2410e65", "title": "CMT: Convolutional Neural Networks Meet Vision Transformers"}, {"paperId": "d645bd08fc19d52164695f9cd5ae863345459a06", "title": "AutoFormer: Searching Transformers for Visual Recognition"}, {"paperId": "c295391129426d89ec58cebb049d1cd2e976deec", "title": "Post-Training Quantization for Vision Transformer"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "b145a25df2457bedfddeecb4be37828e43f6cc80", "title": "Exploring Corruption Robustness: Inductive Biases in Vision Transformers and MLP-Mixers"}, {"paperId": "928432d433ea0490bfbf1396872c88a1d5d7b77f", "title": "Towards Fully Interpretable Deep Neural Networks: Are We There Yet?"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "efbe9f591090018f78b42c84613c8afda9292fdb", "title": "Chasing Sparsity in Vision Transformers: An End-to-End Exploration"}, {"paperId": "f43b98fcc2d56c60fc71bce96374c1e6b8e12c66", "title": "Shuffle Transformer: Rethinking Spatial Shuffle for Vision Transformer"}, {"paperId": "33fd56e5067a1e8a9713378af3e1c1c08d5ce93b", "title": "Patch Slimming for Efficient Vision Transformers"}, {"paperId": "13e5c87d143940a40ffcfa750470711c810e7d59", "title": "Explainable Models with Consistent Interpretations"}, {"paperId": "14c52ffa7ea9c1971d5d82ea369c946c98d056a9", "title": "LocalViT: Bringing Locality to Vision Transformers"}, {"paperId": "d2a3bb6356d439146cd8d8e72dc728a1e3d93e7f", "title": "Understanding Robustness of Transformers for Image Classification"}, {"paperId": "96da196d6f8c947db03d13759f030642f8234abf", "title": "DeepViT: Towards Deeper Vision Transformer"}, {"paperId": "dfb37e6216e792bf6bd5a30c0fc7ad55df1cb71e", "title": "Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "cec7872b194aadf54140578b9be52939eb1112e9", "title": "LambdaNetworks: Modeling Long-Range Interactions Without Attention"}, {"paperId": "229a4d27d04bd3901ef0ca41942eb0cdd4f28eed", "title": "Do We Actually Need Dense Over-Parameterization? In-Time Over-Parameterization in Sparse Training"}, {"paperId": "949c0941d4c57482318afa28f2c8eb82569fb401", "title": "Pruning and Quantization for Deep Neural Network Acceleration: A Survey"}, {"paperId": "7240ffa9f164ac1dddd91d9695b33ec798fdfad3", "title": "An Efficient Binary Convolutional Neural Network With Numerous Skip Connections for Fog Computing"}, {"paperId": "2b8088253e2378fce001a090fe923b81e8dedf25", "title": "RepVGG: Making VGG-style ConvNets Great Again"}, {"paperId": "03db82055bf039503c8111e997757f122aa5438d", "title": "A Survey on Neural Network Interpretability"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "0acd7ff5817d29839b40197f7a4b600b7fba24e4", "title": "Transformer Interpretability Beyond Attention Visualization"}, {"paperId": "993392bea9ac4249a6e7fc6c25785023b942b957", "title": "The Emerging Trends of Multi-Label Learning"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "1b5a5105416c87800f00b15e4517d57b9818f9c1", "title": "Robust and fast image hashing with two-dimensional PCA"}, {"paperId": "d3d9af665f1aaeb7643a4c3608ba184737bc467c", "title": "Explainable Face Recognition"}, {"paperId": "82d94353c60a8e0ff7ed4eb9f0dca65ac2ccbfcb", "title": "Search What You Want: Barrier Panelty NAS for Mixed Precision Quantization"}, {"paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8", "title": "Generative Pretraining From Pixels"}, {"paperId": "0e3715b20dd6249d93e97ae126df0b12eedc17a8", "title": "SkipConv: Skip Convolution for Computationally Efficient Deep CNNs"}, {"paperId": "022622e024890d6e044ac50e2da6b44c59bdf418", "title": "The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "f4cc061e63a88ae9ae3192ae6985b1699287f54d", "title": "Interpretable and Accurate Fine-grained Recognition via Region Grouping"}, {"paperId": "d325b441ff26e4bd911a04ce2b73c7a022517143", "title": "CP-NAS: Child-Parent Neural Architecture Search for 1-bit CNNs"}, {"paperId": "fb93ca1e004cbdcb93c8ffc57357189fa4eb6770", "title": "ResNeSt: Split-Attention Networks"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "de66ada65cd9d36e46f1f8dd2c8be480180038ec", "title": "What is the State of Neural Network Pruning?"}, {"paperId": "7af72a461ed7cda180e7eab878efd5f35d79bbf4", "title": "A Simple Framework for Contrastive Learning of Visual Representations"}, {"paperId": "6d4a87759917132913319960389f17fa1fe8b630", "title": "Fast is better than free: Revisiting adversarial training"}, {"paperId": "962bdacb3941053788d69696826c9b4307652cce", "title": "Towards Unified INT8 Training for Convolutional Neural Network"}, {"paperId": "02b1607af35b48f0bd716367caf6a7428b969369", "title": "AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty"}, {"paperId": "dc3863fce4d31a7544372953a4b7e4a2c10dc2b3", "title": "Holistic CNN Compression via Low-Rank Decomposition with Knowledge Transfer"}, {"paperId": "2e3002f131e1815bda7a10303eff97f79dea01ec", "title": "Rigging the Lottery: Making All Tickets Winners"}, {"paperId": "41c67d04be2d1632c0d3b0880c21c9fe797cdab8", "title": "EfficientDet: Scalable and Efficient Object Detection"}, {"paperId": "146c95362597f956de9fbab4d3598266f11d6d35", "title": "Training High-Performance and Large-Scale Deep Neural Networks with Full 8-bit Integers"}, {"paperId": "7e87fb8fe78694d42bdc3b4a3b04ffb218148233", "title": "Survey on Deep Neural Networks in Speech and Vision Systems"}, {"paperId": "9297fa2b614884ee65fc6f03e692ee100add375a", "title": "Differentiable Learning-to-Group Channels via Groupable Convolutional Neural Networks"}, {"paperId": "9fe3cebb4454abc5d3bcfcad9c3228fbacdbdb08", "title": "Similarity-Preserving Knowledge Distillation"}, {"paperId": "45557cc70cd6989ab6b03e5aeb787e34299099f7", "title": "Natural Adversarial Examples"}, {"paperId": "c703618d1f97a2d2184a09bbd73520034a19ef56", "title": "Improving Robustness Without Sacrificing Accuracy with Patch Gaussian Augmentation"}, {"paperId": "f4d38c99b8064efba89adddcfac91c85b9e687e9", "title": "ManTra-Net: Manipulation Tracing Network for Detection and Localization of Image Forgeries With Anomalous Features"}, {"paperId": "21de3a36cb51adc205fad8a1d3d69118891dc3dd", "title": "AutoAugment: Learning Augmentation Strategies From Data"}, {"paperId": "c3d846a3c51dc6423381257b95a4b821e778dce0", "title": "Adversarial Training Can Hurt Generalization"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "729b7dad41ef9942e6cb380dfad1b22ebf11b689", "title": "LIT: Learned Intermediate Representation Training for Model Compression"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "5e19eba1e6644f7c83f607383d256deea71f87ae", "title": "Searching for MobileNetV3"}, {"paperId": "d33deae7f654b07ac8a5c437a4fa018c29e6af17", "title": "You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle"}, {"paperId": "b03c7ff961822183bab66b2e594415e585d3fd09", "title": "Are Sixteen Heads Really Better than One?"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "0f736d2067ee9c950b876f14521268c6009e67d6", "title": "Relational Knowledge Distillation"}, {"paperId": "79e523beb1e1411a241edde0464b07c2ebc231d1", "title": "Single Path One-Shot Neural Architecture Search with Uniform Sampling"}, {"paperId": "49b64383fe36268410c430352637ed23b16820c5", "title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations"}, {"paperId": "6c405d4b5dc41a86be05acd59c06ed19daf01d14", "title": "Theoretically Principled Trade-off between Robustness and Accuracy"}, {"paperId": "120ffccea4787b88f78b55b9302891ff96cb4228", "title": "Slimmable Neural Networks"}, {"paperId": "594a91fe54eb44f0e5fffd35ab015a8456419d11", "title": "Activation Functions: Comparison of trends in Practice and Research for Deep Learning"}, {"paperId": "4a1004ecd34118116344633c7cdcc34493c423ee", "title": "Rethinking the Value of Network Pruning"}, {"paperId": "c02b909a514af6b9255315e2d50112845ca5ed0e", "title": "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"}, {"paperId": "d39a5ea57b1c242a0450385523fd3471b172458c", "title": "Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net"}, {"paperId": "cc145f046788029322835979a14459652da7247e", "title": "This looks like that: deep learning for interpretable image recognition"}, {"paperId": "3d8b62c060f8444907e7c975c6ae590373b51ed4", "title": "Quantizing deep convolutional networks for efficient inference: A whitepaper"}, {"paperId": "d00c7fc5201405d5411b5ad3da93c5575ce8f10e", "title": "RISE: Randomized Input Sampling for Explanation of Black-box Models"}, {"paperId": "1b59eea8ec4684381a885b59acd09c9151a49487", "title": "Manifold Mixup: Better Representations by Interpolating Hidden States"}, {"paperId": "f445493badf53febbaeab340a4fca98d9e4ab7f7", "title": "Do CIFAR-10 Classifiers Generalize to CIFAR-10?"}, {"paperId": "054db727adc1a3a877aae6ad4ac835a3a9b872ba", "title": "IGCV3: Interleaved Low-Rank Group Convolutions for Efficient Deep Neural Networks"}, {"paperId": "94be567c32ae76bdaadabd4975807a94181e39b3", "title": "How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)"}, {"paperId": "fae2a5101789afd51c1ececb28c75537c88734ec", "title": "Scalable Methods for 8-bit Training of Neural Networks"}, {"paperId": "f723eb3e7159f07b97464c8d947d15e78612abe4", "title": "AutoAugment: Learning Augmentation Policies from Data"}, {"paperId": "afc4cc092f990644ff7a11dc7ab60519920cbc9d", "title": "Learning Rich Features for Image Manipulation Detection"}, {"paperId": "24c6351f8b8b991bf1946424c55cd859b7b8a209", "title": "Redundancy-Reduced MobileNet Acceleration on Reconfigurable Logic for ImageNet Classification"}, {"paperId": "5023544ad6fa49b35526a62f22207e43c4db870d", "title": "Constructing Unrestricted Adversarial Examples with Generative Models"}, {"paperId": "73a3576e54e4ad0a00280e8c2daab9ba119352b1", "title": "Revisiting Oxford and Paris: Large-Scale Image Retrieval Benchmarking"}, {"paperId": "f7bb1636ced9036b3d0edafc7d82ad43164d41a3", "title": "Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models"}, {"paperId": "acdf151b8efc2c6b05662d69f27531afc557dc85", "title": "Training and Inference with Integers in Deep Neural Networks"}, {"paperId": "eae2eba75cc90990ff31d94d1942ffdea7c452b8", "title": "Mixed Precision Training of Convolutional Neural Networks using Integer Operations"}, {"paperId": "ee95231783167baa4785a642e8ef563a572c5d63", "title": "Deep Defense: Training DNNs with Improved Adversarial Robustness"}, {"paperId": "d3f6b3ce8f7b67c1e112a79b3fe9764242c655f5", "title": "Recovering from Random Pruning: On the Plasticity of Deep Convolutional Neural Networks"}, {"paperId": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4", "title": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"}, {"paperId": "2ec7156913117949ab933f27f492d0149bc0031f", "title": "Learning Sparse Neural Networks through L0 Regularization"}, {"paperId": "682b9d2212258fd5edbfca589c86390c31a956b0", "title": "Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)"}, {"paperId": "efbac99adf8628aae7f070e5b4388a295956f9d2", "title": "CondenseNet: An Efficient DenseNet Using Learned Group Convolutions"}, {"paperId": "de01f74a899ecc7e3228cddbc743aaf6faf5e55f", "title": "Towards better understanding of gradient-based attribution methods for Deep Neural Networks"}, {"paperId": "af03709f0893a7ff1c2656b73249d60030bab996", "title": "NISP: Pruning Networks Using Neuron Importance Score Propagation"}, {"paperId": "cd14707ba72d0d13c8bf42bfd9d072122db7c711", "title": "Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks"}, {"paperId": "ec350899ddc5f83dc9185a3516209ca3f6cc6d78", "title": "Fine-Tuning CNN Image Retrieval with No Human Annotation"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "bf9af274a17eea6ca3721acffab14e5c8e9f097a", "title": "Deep Learning for Case-based Reasoning through Prototypes: A Neural Network that Explains its Predictions"}, {"paperId": "e7fd6848cb29ca221a7e17d823e06fb566f1f135", "title": "Mixed Precision Training"}, {"paperId": "b9fd6c8ae5c3dce4a7a40989d6dbf62f0093dc6e", "title": "Interleaved Group Convolutions"}, {"paperId": "96d8412c14d8756d0b5682ec39fad5063fee2d9d", "title": "Exploiting Spatial Structure for Localizing Manipulated Image Regions"}, {"paperId": "8396c9a186882457e1d4c822f2ed401937674bb5", "title": "Learning Multi-attention Convolutional Neural Network for Fine-Grained Image Recognition"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "c1f05b723e53ac4eb1133249b445c0011d42ca79", "title": "Deep Convolutional Neural Networks for Image Classification: A Comprehensive Review"}, {"paperId": "90a16f34d109b63d95ab4da2d491cbe3a1c8b656", "title": "Learning Efficient Convolutional Networks through Network Slimming"}, {"paperId": "eb35fdc11a325f21a8ce0ca65058f7480a2fc91f", "title": "Improved Regularization of Convolutional Neural Networks with Cutout"}, {"paperId": "d0611891b9e8a7c5731146097b6f201578f47b2f", "title": "Learning Transferable Architectures for Scalable Image Recognition"}, {"paperId": "049fd80f52c0b1fa4d532945d95a24734b62bdf3", "title": "ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression"}, {"paperId": "ee53c9480132fc0d09b1192226cb2c460462fd6d", "title": "Channel Pruning for Accelerating Very Deep Neural Networks"}, {"paperId": "a4a3df5823d32075ef2227cc3671aff24a8d8634", "title": "MDNet: A Semantically and Visually Interpretable Medical Image Diagnosis Network"}, {"paperId": "9da734397acd7ff7c557960c62fb1b400b27bd89", "title": "ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"}, {"paperId": "7aa38b85fa8cba64d6a4010543f6695dbf5f1386", "title": "Towards Deep Learning Models Resistant to Adversarial Attacks"}, {"paperId": "f538dca4def5167a32fbc12107b69a05f0c9d832", "title": "SmoothGrad: removing noise by adding noise"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "136dee73f203df2f4831994bf4f0c0a4ad2e764e", "title": "Ensemble Adversarial Training: Attacks and Defenses"}, {"paperId": "013efe3ff541e518c51f08d1b62a62e0c57c0b14", "title": "Parseval Networks: Improving Robustness to Adversarial Examples"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "fdc6ad0f80d99304125bd436da32e4f65d5a45dc", "title": "Google's Cloud Vision API is Not Robust to Noise"}, {"paperId": "1a2118bed729579528deb51e745d58dd3629baf6", "title": "Learning Important Features Through Propagating Activation Differences"}, {"paperId": "08ad8fad21f6ec4cda4d56be1ca5e146b7c913a1", "title": "Understanding Black-box Predictions via Influence Functions"}, {"paperId": "f302e136c41db5de1d624412f68c9174cf7ae8be", "title": "Axiomatic Attribution for Deep Networks"}, {"paperId": "34cc3ceae5c3f7c8acbb89f2bff63f9d452b00d5", "title": "Variational Dropout Sparsifies Deep Neural Networks"}, {"paperId": "b4d1c1b9ec675638e1fb7fc1d6fc1fa820a52cc5", "title": "A deep learning approach to detection of splicing and copy-move forgeries in images"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "f7b032a4df721d4ed2bab97f6acd33d62477b7a5", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer"}, {"paperId": "1147174640a85ec0cb7211dc5d25878f2dc0ee09", "title": "Compact Deep Convolutional Neural Networks With Coarse Pruning"}, {"paperId": "5582bebed97947a41e3ddd9bd1f284b73f1648c2", "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"}, {"paperId": "5b6ec746d309b165f9f9def873a2375b6fb40f3d", "title": "Xception: Deep Learning with Depthwise Separable Convolutions"}, {"paperId": "36eff562f65125511b5dfab68ce7f7a943c27478", "title": "Semi-Supervised Classification with Graph Convolutional Networks"}, {"paperId": "5694e46284460a648fe29117cbc55f6c9be3fa3c", "title": "Densely Connected Convolutional Networks"}, {"paperId": "7361e42c5eb0d5438c4294cc7ea3f9a53d326309", "title": "Top-Down Neural Attention by Excitation Backprop"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "b699b0033764214ad9486da966e1a1ad37932f6f", "title": "A Deep Learning Approach to Universal Image Manipulation Detection Using a New Convolutional Layer"}, {"paperId": "8b053389eb8c18c61b84d7e59a95cb7e13f205b7", "title": "DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients"}, {"paperId": "cab372bc3824780cce20d9dd1c22d4df39ed081a", "title": "DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs"}, {"paperId": "1c4e9156ca07705531e45960b7a919dc473abb51", "title": "Wide Residual Networks"}, {"paperId": "a975ea4cc0078ca31d9c100cdb53a352c751ca68", "title": "Binarized Neural Networks on the ImageNet Classification Task"}, {"paperId": "77f0a39b8e02686fd85b01971f8feb7f60971f80", "title": "Identity Mappings in Deep Residual Networks"}, {"paperId": "b5c26ab8767d046cb6e32d959fdf726aee89bb62", "title": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning"}, {"paperId": "31f9eb39d840821979e5df9f34a6e92dd9c879f2", "title": "Learning Deep Features for Discriminative Localization"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35", "title": "DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks"}, {"paperId": "642d0f49b7826adcf986616f4af77e736229990f", "title": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"}, {"paperId": "e6f2f3a5cc7c7213835b9aede15715b5830520e1", "title": "Tensorizing Neural Networks"}, {"paperId": "17a273bbd4448083b01b5a9389b3c37f5425aac0", "title": "On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "05d408a8b720f3b45a7e3a83fb14015554133582", "title": "Median Filtering Forensics Based on Convolutional Neural Networks"}, {"paperId": "7ffdbc358b63378f07311e883dddacc9faeeaf4b", "title": "Fast R-CNN"}, {"paperId": "efb5032e6199c80f83309fd866b25be9545831fd", "title": "Compressing Neural Networks with the Hashing Trick"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "33af9298e5399269a12d4b9901492fe406af62b4", "title": "Striving for Simplicity: The All Convolutional Net"}, {"paperId": "8604f376633af8b347e31d84c6150a93b11e34c2", "title": "FitNets: Hints for Thin Deep Nets"}, {"paperId": "bee044c8e8903fb67523c1f8c105ab4718600cdb", "title": "Explaining and Harnessing Adversarial Examples"}, {"paperId": "62e348e26976c3ef77909b9af9788ebc2509009a", "title": "Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition"}, {"paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327", "title": "Going deeper with convolutions"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd", "title": "ImageNet Large Scale Visual Recognition Challenge"}, {"paperId": "df787a974fff59f557ed1ec620fc345568aec491", "title": "Learning Deep Representations for Graph Clustering"}, {"paperId": "cbb19236820a96038d000dc629225d36e0b6294a", "title": "Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition"}, {"paperId": "021fc345d40d3e6332cd2ef276e2eaa5e71102e4", "title": "Speeding up Convolutional Neural Networks with Low Rank Expansions"}, {"paperId": "d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad", "title": "Intriguing properties of neural networks"}, {"paperId": "5e83ab70d0cbc003471e87ec306d27d9c80ecb16", "title": "Network In Network"}, {"paperId": "1a2a770d23b4a171fa81de62a78a3deb0588f238", "title": "Visualizing and Understanding Convolutional Networks"}, {"paperId": "5cea23330c76994cb626df20bed31cc2588033df", "title": "Low-rank matrix factorization for Deep Neural Network training with high-dimensional output targets"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "26cb14c9d22cf946314d685fe3541ef9f641e429", "title": "End-to-end text recognition with convolutional neural networks"}, {"paperId": "5d21006fa32ff69f6b0a646f26ce0db84f2f4d33", "title": "Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition"}, {"paperId": "1f88427d7aa8225e47f946ac41a0667d7b69ac52", "title": "What is the best multi-stage architecture for object recognition?"}, {"paperId": "2a4393aa1bc3cb7fe2deecc88720bfb84dabb263", "title": "Notes on Convolutional Neural Networks"}, {"paperId": "30c9bb327b7f2b9f1d1e5b69b9d0c97b410948d9", "title": "Model compression"}, {"paperId": "e9fac1091d9a1646314b1b91e58f40dae3a750cd", "title": "The Vanishing Gradient Problem During Learning Recurrent Neural Nets and Problem Solutions"}, {"paperId": "e8eaf8aedb495b6ae0e174eea11e3cfcdf4a3724", "title": "Optimal Brain Surgeon and general network pruning"}, {"paperId": "078b1c9fdcb8b1e7e8bc6b3e32cf308887ba4dfd", "title": "Applications of Pontryagin\u2019s Maximum Principle to Economics"}, {"paperId": "8a334b9f86acaec466b915d28e5a3a70d30529ed", "title": "Deep Neural Networks"}, {"paperId": "7b0a5f7d35a2dbeca5664db23e73ff61146e9777", "title": "Defending against Adversarial Patches with Robust Self-Attention"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "c9d1f170f3d041791558b78101e8b291597d7f28", "title": "Efficient Vision Transformers via Fine-Grained Manifold Distillation"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "88cd4209db62a34d9cba0b9cbe9d45d1e57d21e5", "title": "Runtime Neural Pruning"}, {"paperId": null, "title": "Like what you like: Knowledge distill via neuron selectivity transfer"}, {"paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82", "title": "Deep Learning"}, {"paperId": "24529bffa95f07c01ccf6f02eb4dc9d859430159", "title": "Understanding Adversarial Training: Increasing Local Stability of Neural Nets through Robust Optimization"}, {"paperId": "d04d6db5f0df11d0cff57ec7e15134990ac07a4f", "title": "Learning Deep Architectures for AI"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}, {"paperId": "e7297db245c3feb1897720b173a59fe7e36babb7", "title": "Optimal Brain Damage"}, {"paperId": null, "title": "A survey of visual neural networks: current trends, challenges and opportunities"}, {"paperId": null, "title": "We introduce the basic architectures of CNNs and transformer, and review the development history of each classical network and their key techniques"}]}