{"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers", "abstract": "We introduce Performers, Transformer architectures which can estimate regular (softmax) full-rank-attention Transformers with provable accuracy, but using only linear (as opposed to quadratic) space and time complexity, without relying on any priors such as sparsity or low-rankness. To approximate softmax attention-kernels, Performers use a novel Fast Attention Via positive Orthogonal Random features approach (FAVOR+), which may be of independent interest for scalable kernel methods. FAVOR+ can be also used to efficiently model kernelizable attention mechanisms beyond softmax. This representational power is crucial to accurately compare softmax with other kernels for the first time on large-scale tasks, beyond the reach of regular Transformers, and investigate optimal attention-kernels. Performers are linear architectures fully compatible with regular Transformers and with strong theoretical guarantees: unbiased or nearly-unbiased estimation of the attention matrix, uniform convergence and low estimation variance. We tested Performers on a rich set of tasks stretching from pixel-prediction through text models to protein sequence modeling. We demonstrate competitive results with other examined efficient sparse and dense attention methods, showcasing effectiveness of the novel attention-learning paradigm leveraged by Performers.", "venue": "International Conference on Learning Representations", "year": 2020, "citationCount": 1217, "influentialCitationCount": 176, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Performers, Transformer architectures which can estimate regular (softmax) full-rank-attention Transformers with provable accuracy, but using only linear space and time complexity, without relying on any priors such as sparsity or low-rankness are introduced."}, "embedding": {"model": "specter_v2", "vector": [0.4859202206134796, 1.034159541130066, -0.5983365774154663, -0.06770164519548416, -0.24800097942352295, 0.3121738135814667, 0.4002443552017212, -0.31320351362228394, -0.2961268126964569, -0.31973493099212646, 0.7419925332069397, 0.3775124251842499, 0.26436713337898254, 0.39644670486450195, -0.32524943351745605, -0.019205540418624878, -0.7263444662094116, 0.353203684091568, -0.04850795492529869, -0.17594009637832642, 0.18494710326194763, -0.8527447581291199, -0.9106305241584778, 0.0967920646071434, 0.202814981341362, 0.7076013088226318, 0.14310850203037262, 0.762747585773468, -0.11395632475614548, 0.42296886444091797, 0.5466486811637878, -0.46881312131881714, 0.3821936845779419, 0.18027947843074799, -0.4279644191265106, -0.10364055633544922, 0.37717780470848083, 0.04545936360955238, -0.5685038566589355, 1.0062190294265747, -0.25152361392974854, 0.35944798588752747, 0.8749033808708191, -0.5011848211288452, -1.0868293046951294, 0.6466392278671265, 0.2577593922615051, 0.6201490163803101, -0.13437488675117493, -0.19547322392463684, 1.825446367263794, -1.4323663711547852, 0.2738410234451294, 1.2115161418914795, 0.5035830736160278, -0.08535535633563995, -0.418344646692276, -0.4298795461654663, 0.6568500995635986, 0.5055229067802429, -0.886722981929779, -0.3198927640914917, -0.2719937562942505, -0.3686653971672058, 2.095010995864868, -0.5415269136428833, -0.12616516649723053, 0.3849213719367981, 0.2608083486557007, 1.534558892250061, 0.10003925859928131, -0.48191359639167786, -0.21352609992027283, 0.11309744417667389, 0.5323304533958435, 0.5525922775268555, -0.5903666615486145, 0.28783702850341797, -0.9371045231819153, -0.36504068970680237, -0.01641836389899254, 0.22417417168617249, -0.23363138735294342, -0.25342878699302673, -0.48273512721061707, 0.40189167857170105, 0.6923514604568481, 0.39226940274238586, -0.6034467816352844, 0.909654438495636, 0.36433348059654236, 0.3046300709247589, -0.031852226704359055, 0.5911834836006165, -0.18052886426448822, 0.2602122724056244, -0.8817219734191895, 0.11836028099060059, -0.025909198448061943, 0.894379734992981, -0.07717719674110413, 0.19235937297344208, -0.8028767704963684, -0.008272407576441765, 1.09734308719635, 0.18150924146175385, 0.27279233932495117, -0.23676709830760956, -0.03337113559246063, -0.6677444577217102, 0.07000486552715302, -1.0608887672424316, -0.21126745641231537, -0.261561781167984, -0.9515880942344666, -0.805786669254303, -0.6765412092208862, 0.48903530836105347, -0.7258909344673157, 0.5845473408699036, -0.49650174379348755, 0.034165158867836, -0.02913152053952217, 1.02295982837677, 0.4645029604434967, 0.766708254814148, 0.4384216368198395, 0.5255836248397827, 1.2322520017623901, -0.697007954120636, -0.46602001786231995, -0.8944524526596069, 0.47325339913368225, -0.41975125670433044, 0.2647385597229004, 0.1310272514820099, -0.9779693484306335, -0.9199799299240112, -0.5511588454246521, 0.022147051990032196, -0.3766523599624634, 0.6912951469421387, 0.9310425519943237, -0.007794216740876436, -0.7248384356498718, 0.6963337063789368, -0.07236699759960175, -0.18407166004180908, 0.56699538230896, 0.4986806809902191, 0.04871928319334984, -0.2565422058105469, -1.0818054676055908, 0.3581203520298004, 0.33198580145835876, -0.7984486222267151, -0.456107497215271, -0.5912250280380249, -0.9485020041465759, 0.4605385661125183, 0.29716137051582336, -0.42227280139923096, 0.9922583699226379, -0.6010968685150146, -1.1457356214523315, 0.8694801330566406, -0.24215146899223328, 0.0687175840139389, 0.13132189214229584, -0.4581095576286316, -0.35157114267349243, -0.5544740557670593, -0.1516895741224289, 0.45482322573661804, 0.5616210699081421, 0.18274624645709991, -0.07021632790565491, 0.2963617742061615, -0.45507290959358215, -0.37367215752601624, -0.2909429669380188, 0.9496622681617737, -0.2816798985004425, -0.34235280752182007, 0.03130092844367027, 0.3857573866844177, -0.286462664604187, -0.1743982583284378, -0.5722253322601318, -1.0474557876586914, 0.506467878818512, 0.07664842903614044, 0.6272249817848206, -1.1589301824569702, -0.19937261939048767, -0.10208949446678162, 0.4140349328517914, -0.20319239795207977, -0.5893048048019409, 0.3409501016139984, -0.930260181427002, 0.03135905787348747, 0.018820391967892647, -0.7921626567840576, 0.2255893051624298, -0.4126858115196228, -0.5598543882369995, 0.16226741671562195, 0.5318688154220581, 1.1503938436508179, -0.732388436794281, 0.32167157530784607, -0.025224002078175545, 0.2941132187843323, -0.8736225366592407, 1.134019374847412, -0.1902693659067154, -0.267233282327652, -0.043940573930740356, 0.01011254545301199, -0.002926139859482646, -0.9740360379219055, 0.09241098165512085, -0.7691233158111572, 0.11800562590360641, 0.19794155657291412, -0.37890884280204773, 0.8402110934257507, -0.04005832225084305, 0.7203662395477295, -0.01162620447576046, -1.0574713945388794, 0.28130096197128296, 0.4475112557411194, -0.07680952548980713, -0.37410247325897217, 0.07570024579763412, 0.2032000571489334, -0.7298354506492615, 0.05562864616513252, 0.6518192887306213, 0.8830318450927734, -0.12895774841308594, 0.041429903358221054, 0.5859404802322388, 0.18890255689620972, -0.15475694835186005, 0.2047238051891327, 0.8370155096054077, 0.6720747351646423, 0.9759958386421204, -0.45765092968940735, 0.02186461351811886, -0.8257786631584167, -0.014553453773260117, 0.5167540311813354, 0.5640485286712646, 0.6909360289573669, 0.47667446732521057, -1.0311447381973267, -0.527199923992157, 0.2166948765516281, 0.6495636105537415, 1.8536845445632935, -0.320468544960022, -0.052470628172159195, -0.21959085762500763, -0.27649492025375366, -0.18999774754047394, -0.3765880763530731, -0.6946451663970947, -0.3788531720638275, -0.1776629537343979, -1.6010065078735352, 0.4384937286376953, 0.5133794546127319, 0.4762395918369293, -0.5339927673339844, -0.19131909310817719, -0.4671744406223297, 0.57080078125, -0.8132472038269043, -0.7612849473953247, 0.6328977346420288, 0.13063883781433105, -0.08087480068206787, -0.2700210511684418, 0.05290345847606659, 0.2191666066646576, -0.5746883153915405, 0.9484083652496338, -0.8201946020126343, -0.5074334740638733, 0.3717745244503021, 0.47066542506217957, -0.7990117073059082, -0.10797761380672455, 0.5718385577201843, 0.18714211881160736, 0.1540997326374054, 0.5617514252662659, 0.2604627013206482, 0.013772214762866497, 0.35183078050613403, -0.2156953364610672, 0.09985901415348053, 0.5557281970977783, 0.2985297739505768, 0.7057522535324097, -0.6086921095848083, 0.07545872777700424, -1.0607343912124634, 0.4291895627975464, -0.3669874668121338, -0.7503283023834229, 0.05786535143852234, -0.913896381855011, -0.24467600882053375, 0.5602459907531738, -0.9309424757957458, -0.07215280085802078, -0.30315467715263367, 0.4709021747112274, -0.4735748767852783, -0.2238062471151352, 0.23464590311050415, 0.3915301263332367, -0.01271174754947424, 0.8152806162834167, 0.3653145134449005, 0.064359150826931, 0.28506165742874146, 0.5555480718612671, -0.9186291098594666, 0.6246776580810547, 0.1843370497226715, 0.4222557842731476, -0.03077872470021248, -0.04707573354244232, -0.8297290802001953, -0.606128454208374, -0.5404154062271118, 0.0550973005592823, -0.10318493843078613, 0.4855511784553528, -0.8659893870353699, -1.245867133140564, -0.4925945997238159, -0.8150107264518738, -0.11275960505008698, -0.05156595632433891, -0.03764520585536957, -0.18967685103416443, -1.2815383672714233, -1.1078259944915771, -0.5879318118095398, -0.8373308777809143, -1.1570072174072266, 0.6772769093513489, 0.1562793105840683, -0.4984370768070221, -0.3133561611175537, -0.1923094242811203, -0.3492260277271271, 0.9846402406692505, -0.7412150502204895, 0.4237549901008606, -0.21061287820339203, -0.6124346852302551, -0.2515748143196106, -0.33236929774284363, 0.41381293535232544, -0.4633830785751343, 0.1875809133052826, -1.027942419052124, 0.44300779700279236, -0.8802897930145264, -0.4860846698284149, 0.5010942220687866, 0.4983453154563904, 0.6497499942779541, 0.1288737952709198, -0.6145420670509338, 0.4780975878238678, 1.020685076713562, -0.9551671743392944, 0.06393303722143173, 0.3596303164958954, 1.1808433532714844, 0.24227449297904968, -0.1613863706588745, 0.8072249293327332, 0.3346571624279022, 0.3928361237049103, 0.36502793431282043, -0.5194705128669739, 0.18033309280872345, -0.20423445105552673, 0.5315706133842468, 0.9377884268760681, -0.00406733900308609, 0.11924315989017487, -0.959805428981781, 0.7321113348007202, -1.4453240633010864, -0.9609951376914978, 0.263869047164917, 0.4715127944946289, 0.01339502539485693, -0.5076414346694946, -0.3079860806465149, -0.6286712884902954, 0.20606744289398193, 0.199991375207901, -0.5361325740814209, -0.20530496537685394, -0.17930419743061066, 0.5422552824020386, 0.5344826579093933, 0.3461252748966217, -0.45829981565475464, 0.6774072647094727, 15.175605773925781, 0.6552762985229492, 0.040890950709581375, 0.6101459860801697, 1.0055707693099976, 0.21650102734565735, 0.05148763954639435, 0.2520303428173065, -1.0300686359405518, -0.21197839081287384, 0.8792521953582764, 0.3969801664352417, 0.4452975392341614, 0.7434203028678894, -0.06596440821886063, 0.528546929359436, -0.5423091650009155, 0.9515626430511475, 0.46125349402427673, -1.1964576244354248, 0.02030152641236782, 0.3715563714504242, 0.5306922793388367, 0.7469958066940308, 0.9377729296684265, 0.7844828367233276, 0.6235062479972839, -0.7072878479957581, 0.4298909604549408, 0.7334108948707581, 0.6724957227706909, 0.20475883781909943, 0.53075110912323, 0.11987430602312088, -0.9649109244346619, -0.25497549772262573, -0.7641984820365906, -1.1343578100204468, 0.03248126804828644, 0.5334290266036987, -0.6278162002563477, -0.4794425368309021, 0.16842101514339447, 1.073359727859497, 0.40732884407043457, 0.0801190435886383, -0.12135675549507141, 0.6487727761268616, 0.05211504176259041, 0.13403557240962982, -0.1427217274904251, 0.627423107624054, 0.056804463267326355, 0.22906151413917542, -0.06681637465953827, 0.039737850427627563, 0.5202111005783081, 0.6869035363197327, -0.5408468842506409, 0.12792359292507172, -0.0179471205919981, -0.2756529748439789, -0.6222227811813354, 1.0817116498947144, 0.6993200778961182, -0.010641568340361118, -0.6067565679550171, 0.4463481903076172, 0.6855570673942566, 0.31183135509490967, -0.27613791823387146, -0.22406326234340668, 0.6363656520843506, -0.4038260877132416, -0.01844283565878868, 0.8080751299858093, -0.041274603456258774, -0.6085911989212036, -0.6947294473648071, -0.45063459873199463, 0.3429034948348999, -1.1329495906829834, -1.1943124532699585, 0.47376447916030884, -0.4851747453212738, -0.2617405652999878, 0.7216637134552002, -1.0938218832015991, -0.1186368465423584, 0.844547688961029, -1.4051800966262817, -0.6289616227149963, 0.09114644676446915, -0.6093423962593079, -0.29504576325416565, -0.22596712410449982, 0.9913466572761536, 0.1523812860250473, -0.3204248547554016, -0.08731263875961304, -0.043491095304489136, -0.043672848492860794, 0.3265705108642578, -0.8373869061470032, 0.811720073223114, -0.08686301112174988, -0.4044792056083679, 0.06693791598081589, 0.27816492319107056, 0.2800370752811432, -0.6690273284912109, 0.27590036392211914, 0.2684374153614044, -1.0348803997039795, -0.08921278268098831, -0.4560756981372833, -0.9238457083702087, 0.2983272075653076, 0.4508906602859497, 0.033294256776571274, 0.6563194990158081, 0.3277261257171631, -0.6023719310760498, -0.07888542860746384, -0.3041822612285614, -0.2096673548221588, 0.15859770774841309, -0.8294785022735596, -0.358074814081192, 0.2698439955711365, 0.1824413388967514, -0.7022101879119873, -0.618041455745697, -0.21536312997341156, 0.32508042454719543, -0.029246071353554726, 1.1613246202468872, -0.7239040732383728, 0.8660063743591309, 0.5770357251167297, -0.13068842887878418, -0.5985469818115234, -0.6648286581039429, -0.7821574807167053, -0.21454115211963654, -0.20963047444820404, 0.36440742015838623, -0.5065956115722656, 0.5843204855918884, 0.634691059589386, 0.14000433683395386, -0.44226109981536865, -0.29031166434288025, -0.0771881490945816, -0.49745723605155945, -0.25516167283058167, 0.1334257572889328, 0.2844788134098053, 0.12857824563980103, -0.022136883810162544, 0.007176994811743498, 0.7616153359413147, -0.0670270249247551, -0.6193404197692871, 0.5370826721191406, -0.5110551714897156, -0.6361099481582642, -0.6618158221244812, -0.827124834060669, -1.4725607633590698, 0.14681988954544067, -1.260737657546997, 0.019834274426102638, -0.6375662684440613, -0.18917034566402435, 0.5515761971473694, -0.612947404384613, 0.4265185296535492, -0.16156397759914398, -0.3343665897846222, -0.5503069758415222, -0.3845948278903961, -0.6884295344352722, 0.883402943611145, 0.6372584104537964, -0.8435002565383911, 0.23908598721027374, 0.013433177955448627, -0.3050740957260132, 0.3134390115737915, 0.20070095360279083, -0.652940034866333, -0.41409629583358765, -0.7138312458992004, 0.5046030879020691, -0.10401937365531921, 0.12230277806520462, -0.9649065136909485, 0.5152590870857239, 0.07401829957962036, 0.23885436356067657, 0.33428800106048584, 0.4722893238067627, -0.9924782514572144, -0.3016306161880493, 0.3066302537918091, -0.8935655951499939, 0.28150373697280884, -0.11492285877466202, -0.38154202699661255, -0.10919579118490219, 0.7810302972793579, -0.04111626744270325, -1.1301060914993286, -0.336997389793396, 0.3357023298740387, -0.6777409911155701, 0.09653833508491516, -0.24628490209579468, -0.22377723455429077, -1.139681339263916, -0.2226916253566742, -0.2815972864627838, 0.41883668303489685, -0.3128097653388977, 0.6529608964920044, 0.3314037621021271, -0.8541963696479797, 0.08383339643478394, 0.0587812177836895, 0.31277966499328613, -0.3014887869358063, 0.5886889100074768, 0.7603028416633606, 0.0932232141494751, 0.329875648021698, 0.25053301453590393, 0.2224946767091751, -0.8080027103424072, 0.34660017490386963, 0.6906801462173462, -0.508311927318573, -0.2641212046146393, 0.9357779622077942, 0.38348495960235596, -1.0011125802993774, -0.008141118101775646, -1.1367934942245483, -0.4211103022098541, -0.3511422276496887, 0.6821864247322083, 0.017309613525867462, -0.28509724140167236, -0.05093826726078987, -0.44213175773620605, 0.1829947680234909, -0.18229122459888458, 0.0010377583093941212, 0.7218616008758545, 0.18014200031757355, -0.2904563844203949, 0.21980686485767365, 0.6011435389518738, -0.9075577855110168, -0.6038903594017029, -1.0400888919830322, -0.11321458220481873, -0.04070424661040306, 0.3539603054523468, -0.11951914429664612, -0.6977714896202087, 0.5997315645217896, 0.8125990629196167, 0.11237400025129318, 0.31958165764808655, 0.12464231997728348, -0.3515092730522156, 1.0217901468276978, -0.3494955599308014, -0.6675971746444702, -0.331063836812973, 1.1197446584701538, 0.8594686388969421, -0.9412897825241089, 0.4785609841346741, -0.3161179721355438, -0.8293110132217407, 0.8878440856933594, 0.40016666054725647, -0.07177141308784485, 0.8678190112113953, -0.2833593785762787, -0.30531343817710876, -0.28241264820098877, -1.054580569267273, -0.5413370132446289, 1.322061538696289, 1.096963882446289, 0.8372816443443298, 0.2672988176345825, 0.4433737099170685, 0.9280100464820862, 0.2654149532318115, 0.18125735223293304, 0.42389193177223206, 0.1648809313774109, -0.3741346001625061, 0.3192921280860901, -0.3471585810184479, 0.8009609580039978, -0.9295879006385803, -0.6906104683876038, 0.21771271526813507, 0.18489116430282593, 0.09515713155269623, -0.020822444930672646, 0.46041083335876465, 0.14184653759002686, 0.7209711074829102, 0.13612595200538635, -0.37200430035591125, -0.38947737216949463, -0.23688089847564697, -0.2426852583885193, -0.7100040912628174, -0.26912209391593933, -0.041857119649648666, -0.40151655673980713, -0.2967364192008972, 0.04816523939371109, 0.25798991322517395, -0.1518687903881073, 0.10554081201553345, 0.9656538963317871, 0.8562856912612915, 0.8167052865028381, -0.5408532023429871, -0.8349003791809082, -0.26514801383018494, -0.7629929780960083, 0.04703756421804428, -0.37703782320022583, -0.14947257936000824, -0.2950085699558258, -0.1564226597547531, 0.06356746703386307]}, "authors": [{"authorId": "1805203", "name": "K. Choromanski"}, {"authorId": "52314889", "name": "Valerii Likhosherstov"}, {"authorId": "35363891", "name": "David Dohan"}, {"authorId": "32725720", "name": "Xingyou Song"}, {"authorId": "3071104", "name": "Andreea Gane"}, {"authorId": "2227764", "name": "Tam\u00e1s Sarl\u00f3s"}, {"authorId": "2052793706", "name": "Peter Hawkins"}, {"authorId": "29827891", "name": "Jared Davis"}, {"authorId": "1579862074", "name": "Afroz Mohiuddin"}, {"authorId": "40527594", "name": "Lukasz Kaiser"}, {"authorId": "2636941", "name": "David Belanger"}, {"authorId": "2654847", "name": "Lucy J. Colwell"}, {"authorId": "145689461", "name": "Adrian Weller"}], "references": [{"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "2b364917b0c51e91fcf2ab9c1d66a14ed4b44c03", "title": "BERTology Meets Biology: Interpreting Attention in Protein Language Models"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "0147893b1aac35b7dad24d5342638292b39b362e", "title": "Demystifying Orthogonal Monte Carlo and Beyond"}, {"paperId": "6bca62bac3f2226b88a525b995d87ceef86c0332", "title": "Simplified Self-Attention for Transformer-Based end-to-end Speech Recognition"}, {"paperId": "0170fc76e934ee643f869df18fb617d5357e8b4e", "title": "Conformer: Convolution-augmented Transformer for Speech Recognition"}, {"paperId": "248b58b3d024158607002ef483df7a8701b5a8fb", "title": "Energy-based models for atomic-resolution protein conformations"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "8cf62055fa0faab9c325f4b30415f5b0dc285434", "title": "Neuroevolution of self-interpretable agents"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "c5f7074a264356c9a022a8dff24df79d1db8c3d3", "title": "ProGen: Language Modeling for Protein Generation"}, {"paperId": "bb2bc99f8220fc681320c541940c99ae30b286d6", "title": "Imputer: Sequence Modelling via Imputation and Dynamic Programming"}, {"paperId": "765866ecb5fe6a225d4e791498caf6a8351c16c7", "title": "Faster Transformer Decoding: N-gram Masked Self-Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "91024d7f8f749c74e90c69d05b03644bb75edbf2", "title": "End-to-end multitask learning, from protein language to protein features without alignments"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "336868be817536e7c7fc88c391a2860cd869ea2b", "title": "Drawing early-bird tickets: Towards more efficient training of deep networks"}, {"paperId": "8cef9900c04d7f661c08f4b5b1ed4337ace042a3", "title": "Transformer Dissection: An Unified Understanding for Transformer\u2019s Attention via the Lens of Kernel"}, {"paperId": "d78aed1dac6656affa4a04cbf225ced11a83d103", "title": "Revealing the Dark Secrets of BERT"}, {"paperId": "b6e4cf90c1e1831f139bf8ad86f09e78824880ce", "title": "Protein interaction networks revealed by proteome coevolution"}, {"paperId": "6b2704fd8517a9917cfd9d3735930be48717d3de", "title": "Sharing Attention Weights for Fast Transformer"}, {"paperId": "0de0a44b859a3719d11834479112314b4caba669", "title": "A Multiscale Visualization of Attention in the Transformer Model"}, {"paperId": "a039ea239e37f53a2cb60c68e0a1967994353166", "title": "Analyzing the Structure of Attention in a Transformer Language Model"}, {"paperId": "d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "title": "Energy and Policy Considerations for Deep Learning in NLP"}, {"paperId": "26e44b8106a5145126c59b6d0c3af326337447f9", "title": "Unifying Orthogonal Monte Carlo Methods"}, {"paperId": "18a93dc1558bf9d7534d0b416633cebaf75c1145", "title": "Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "27ac832ee83d8b5386917998a171a0257e2151e2", "title": "Attention Augmented Convolutional Networks"}, {"paperId": "2c7c9b405362277e390b09636c20ed274844c01f", "title": "KAMA-NNs: Low-dimensional Rotation Based Neural Networks"}, {"paperId": "a9ec03dbe702f6909acd1f1f14a3395d0141043b", "title": "Generative Models for Graph-Based Protein Design"}, {"paperId": "d7fc80056c0a8231fc58ee86353b42ee338464da", "title": "Orthogonal Estimation of Wasserstein Distances"}, {"paperId": "49bc7fb789fec84878440da374c11a7e936b6139", "title": "Induction of Potent Neutralizing Antibody Responses by a Designed Protein Nanoparticle Vaccine for Respiratory Syncytial Virus"}, {"paperId": "bed7c155b843fda8a1c994ce71e9176e43b20f77", "title": "Factorized Attention: Self-Attention with Linear Complexities"}, {"paperId": "2b4696bf4bc923a139e8508086f854ca52b690d0", "title": "UniProt: a worldwide hub of protein knowledge"}, {"paperId": "9ea92ebeb7462f2db346cfa3281ad7497b1063d6", "title": "Deep reinforcement learning with relational inductive biases"}, {"paperId": "5dc62bdeb879e030a05d1d1bdab9a04de9d23b32", "title": "Transformer-XL: Language Modeling with Longer-Term Dependency"}, {"paperId": "fb507ada871d1e8c29e376dbf7b7879689aa89f9", "title": "Music Transformer: Generating Music with Long-Term Structure"}, {"paperId": "ad655c25e052fa4eeed53421344aca6f239c4c9d", "title": "Dual Attention Network for Scene Segmentation"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "bb669de2fce407df2f5cb2f8c51dedee3f467e04", "title": "The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation"}, {"paperId": "8b354d76813bd5375e7e5c8d17f630bec5936a01", "title": "ListOps: A Diagnostic Dataset for Latent Tree Learning"}, {"paperId": "962ba753d7ea794f4085f96ef191e9016aff31ac", "title": "The Geometry of Random Features"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "597b1dedb58ddb5ee5c35938c1a2574c7a11e0f6", "title": "Initialization matters: Orthogonal Predictive State Recurrent Neural Networks"}, {"paperId": "33998aff64ce51df8dee45989cdca4b6b1329ec4", "title": "Graph Attention Networks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5394da74498e00597295d18cd0557bd47e3fc341", "title": "The Unreasonable Effectiveness of Structured Random Orthogonal Embeddings"}, {"paperId": "32e934094c4d17fe4d734b2e169ba5e3cd0ee05e", "title": "Orthogonal Random Features"}, {"paperId": "455afd748e8834ef521e4b67c7c056d3c33429e2", "title": "Hierarchical Attention Networks for Document Classification"}, {"paperId": "f63e917638553414526a0cc8550de4ad2d83fe7a", "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "9653d5c2c7844347343d073bbedd96e05d52f69b", "title": "Pointer Networks"}, {"paperId": "5d833331b0e22ff359db05c62a8bca18c4f04b68", "title": "One billion word benchmark for measuring progress in statistical language modeling"}, {"paperId": "bd5fc28c7356915ec71abafbe86b7596c60720aa", "title": "The conference paper"}, {"paperId": "7a59fde27461a3ef4a21a249cc403d0d96e4a0d7", "title": "Random Features for Large-Scale Kernel Machines"}, {"paperId": "f2c1830eedc095b92a78dc3afa39a36343ed81ad", "title": "Introduction to algorithms"}, {"paperId": "995538af8de9868713128b35c511810445e65916", "title": "Parallel Prefix Computation"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "e399090e4dd760e8f09bd3d4de61b13b057c7740", "title": "Compiling machine learning programs via high-level tracing"}, {"paperId": "31181e73befea410e25de462eccd0e74ba8fea0b", "title": "Introduction to Algorithms, 3rd Edition"}, {"paperId": null, "title": "An efficient algorithm to compute the prefix-sum of L elements takes O(L) total steps and O(logL) time when computed in parallel (Ladner"}, {"paperId": null, "title": "where the first equality comes from the independence of different elements of z = (z 1 , ..., z n ) and the second equality is implied by the fact thatg is independent from g"}]}