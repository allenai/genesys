{"paperId": "d2421cffac277e230cb97fc2355b32e03dd8bb1f", "title": "ExeGPT: Constraint-Aware Resource Scheduling for LLM Inference", "abstract": "This paper presents ExeGPT, a distributed system designed for constraint-aware LLM inference. ExeGPT finds and runs with an optimal execution schedule to maximize inference throughput while satisfying a given latency constraint. By leveraging the distribution of input and output sequences, it effectively allocates resources and determines optimal execution configurations, including batch sizes and partial tensor parallelism. We also introduce two scheduling strategies based on Round-Robin Allocation and Workload-Aware Allocation policies, suitable for different NLP workloads. We evaluate ExeGPT on six LLM instances of T5, OPT, and GPT-3 and five NLP tasks, each with four distinct latency constraints. Compared to FasterTransformer, ExeGPT achieves up to 15.2\u00d7 improvements in throughput and 6\u00d7 improvements in latency. Overall, ExeGPT achieves an average throughput gain of 2.9\u00d7 across twenty evaluation scenarios. Moreover, when adapting to changing sequence distributions, the cost of adjusting the schedule in ExeGPT is reasonably modest. ExeGPT proves to be an effective solution for optimizing and executing LLM inference for diverse NLP workload and serving conditions.", "venue": "International Conference on Architectural Support for Programming Languages and Operating Systems", "year": 2024, "citationCount": 5, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2404.07947", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "ExeGPT proves to be an effective solution for optimizing and executing LLM inference for diverse NLP workload and serving conditions and achieves an average throughput gain of 2.9\u00d7 across twenty evaluation scenarios."}, "embedding": {"model": "specter_v2", "vector": [0.2739587724208832, -0.09163086861371994, -1.0826194286346436, 0.1698545664548874, 0.299148291349411, -0.5063375234603882, 0.4789940416812897, -0.3886532485485077, 0.019501851871609688, 0.11809379607439041, 0.4066973626613617, -0.7164254784584045, -0.0028057803865522146, 0.21080990135669708, -0.10729453712701797, 0.21456778049468994, -1.1091632843017578, 0.6233066916465759, -0.28707537055015564, -0.07882630825042725, 0.3826143741607666, 0.08751850575208664, -1.4079262018203735, 0.5134944915771484, 0.3590710163116455, 1.1043897867202759, -0.32688409090042114, 0.9438238143920898, -0.6931726336479187, 0.238057479262352, 0.14300808310508728, 0.12283989042043686, 0.5009740591049194, 0.4656261205673218, -0.22708973288536072, 0.26399126648902893, 0.060075096786022186, -0.6298295259475708, -0.243013396859169, 0.5029663443565369, -0.13942503929138184, 0.3226553797721863, 0.32706907391548157, -1.1065820455551147, -0.09413505345582962, 0.5881087779998779, 0.09334671497344971, 0.5651357769966125, -0.16521134972572327, -0.2820977568626404, 1.0384999513626099, -1.3980225324630737, 0.348344624042511, 0.978121817111969, 0.2527948319911957, 0.06148897111415863, -0.5936667919158936, -0.27659139037132263, 0.060551710426807404, 0.0032918215729296207, -0.7825537919998169, -0.46015408635139465, -0.5150919556617737, -0.3748910427093506, 1.527173399925232, -0.12806904315948486, -0.33197635412216187, 0.32590463757514954, 0.2808559536933899, 1.2830809354782104, 0.1894359290599823, -0.6495698094367981, 0.3739854097366333, -0.20670853555202484, -0.2424890547990799, 0.457307368516922, -0.07183080166578293, 0.3391340374946594, -1.3973897695541382, -0.24916721880435944, 0.1514609158039093, 0.05755877122282982, 0.2943990230560303, -0.1643068641424179, -0.3634820878505707, 0.36607030034065247, -0.3388429582118988, 0.3870980739593506, -0.47912806272506714, 0.6206188797950745, 0.8224599361419678, 0.3219764232635498, 0.2745550274848938, 0.017659923061728477, -0.2093588411808014, 0.02091808058321476, -1.1966811418533325, 0.28581997752189636, 0.6610076427459717, 0.6975716352462769, -0.3899541199207306, 0.31323015689849854, -1.2274826765060425, -0.000652194197755307, 0.8639539480209351, 0.050570614635944366, 0.1249365583062172, -0.6269887089729309, 0.2955816388130188, -0.37160372734069824, 0.3681989908218384, -0.5306881666183472, -0.3214070498943329, 0.07722204178571701, -0.634495735168457, -0.7665855288505554, -0.9018808007240295, -0.34624534845352173, -0.7212082147598267, 0.07717891037464142, -0.2468222975730896, 0.30614063143730164, 0.20566289126873016, 0.7724524140357971, 0.38429006934165955, 0.6182602047920227, -0.3387072682380676, -0.27058157324790955, 0.8738414645195007, -0.8573067784309387, -0.5165749192237854, -0.7848906517028809, 0.4851314127445221, -0.7843231558799744, -0.18238946795463562, -0.4362139403820038, -1.3631365299224854, -0.5547803640365601, -0.5594379305839539, 0.4462142586708069, -0.16672223806381226, 0.6341241598129272, 1.105272889137268, -0.09481088072061539, -0.8440222144126892, 0.6345139145851135, -0.04717988148331642, -0.025197932496666908, -0.022615278139710426, 0.3890034854412079, 0.7629480361938477, -0.4337719976902008, -1.1056870222091675, 0.1425400823354721, 0.7206196188926697, -0.41751646995544434, -0.3743845820426941, -0.7578626275062561, -0.5767695307731628, 0.032127585262060165, 0.8217728734016418, -0.5182046294212341, 1.374365210533142, 0.5538856983184814, -1.2596912384033203, 0.4946451187133789, 0.1835833340883255, 0.23579856753349304, 0.4849383533000946, 0.09514082968235016, -0.4857281446456909, -0.04428533837199211, 0.028431609272956848, 0.40374454855918884, 0.5534376502037048, 0.04055051878094673, -0.2431326061487198, 0.47867241501808167, -0.29869645833969116, 0.10733768343925476, -0.10430195182561874, 0.8854114413261414, -0.5027248859405518, -0.19353263080120087, 0.32840844988822937, 0.5544450283050537, -0.4753703474998474, 0.10390743613243103, -0.6894975900650024, -0.8410375714302063, 1.0758427381515503, 0.2190893143415451, 0.8996766209602356, -0.6422077417373657, -0.38817185163497925, -0.01861286163330078, -0.061875153332948685, 0.0625586211681366, -0.36129695177078247, 1.362786054611206, -0.22081361711025238, 0.26064518094062805, 0.025537634268403053, -0.6990381479263306, 0.27573978900909424, 0.2699223458766937, -0.9701865911483765, -0.6144185066223145, -0.13713091611862183, 0.8179846405982971, -0.5061228275299072, -0.03974176198244095, -0.0180684681981802, -0.11900228261947632, -0.796936571598053, 1.330208420753479, -1.1262706518173218, 0.23319914937019348, -0.016400108113884926, 0.007457980420440435, 0.3129897713661194, -0.8528634309768677, 1.2167772054672241, -0.5662195682525635, -0.30164122581481934, 0.19544440507888794, -0.6127102971076965, 1.199137568473816, -0.34588178992271423, 0.09981086850166321, 0.09083568304777145, -0.5239764451980591, 0.21601298451423645, 0.4279259145259857, 0.5340169668197632, -0.2773897051811218, 0.0562836229801178, 0.44471240043640137, -0.5420175790786743, -0.43667247891426086, 0.972035825252533, 1.107712984085083, -0.1371932476758957, 0.8329796195030212, 0.1894746869802475, 0.06428312510251999, 1.0404856204986572, 0.3007515072822571, 0.6618964672088623, 0.6193642616271973, 0.015957871451973915, -0.1444871574640274, 0.2962205111980438, -0.5986443758010864, -0.14537367224693298, 0.45603567361831665, 0.9941489100456238, -0.13491354882717133, 0.6419143080711365, -0.9723724126815796, -0.48042699694633484, 0.011494013480842113, 0.40341469645500183, 1.7169458866119385, 0.19577762484550476, -0.30168238282203674, -0.387175977230072, -0.5772159099578857, 0.43737196922302246, -0.08206471800804138, 0.14702333509922028, 0.09614121168851852, -0.3917708396911621, -1.1729873418807983, 0.6380103230476379, 0.27846434712409973, 1.0118012428283691, -0.8929933905601501, -0.3348959982395172, -0.4303622245788574, -0.041702330112457275, -1.2447547912597656, -0.48277536034584045, -0.02164045348763466, -0.37059056758880615, 0.008388648740947247, 0.5191547870635986, 0.0776747390627861, 0.33024707436561584, -0.5224941372871399, 1.0678480863571167, -0.0939982607960701, -0.6172181367874146, -0.1309254914522171, 0.4462372660636902, 0.011560228653252125, -0.6892633438110352, -0.02072417177259922, 0.18456660211086273, -0.19349929690361023, 0.44340285658836365, 0.32779398560523987, 0.15392610430717468, 0.30131852626800537, -0.7565965056419373, 0.1897789090871811, 0.3616907298564911, -0.3952750563621521, 0.3733465075492859, 0.06045316532254219, -0.06912905722856522, -0.6667711138725281, 1.2178363800048828, -0.09612578898668289, -0.7616875171661377, 0.024888496845960617, -0.8351761698722839, -0.21453560888767242, 0.46628227829933167, -0.9817725419998169, -0.0640716403722763, -1.4414376020431519, 0.5059722065925598, -0.45607131719589233, -0.2543388903141022, 0.4129514694213867, 0.7043002247810364, -0.1324446052312851, 0.2356453239917755, 0.7569330334663391, 0.536087155342102, 0.010229908861219883, 0.5506268739700317, -0.5552257895469666, 0.09037605673074722, -0.4952695369720459, 0.02599133364856243, -0.20074878633022308, 0.13692505657672882, -0.5915356874465942, -0.4786263704299927, -0.02346051298081875, 0.025807702913880348, -0.32781606912612915, -0.12079030275344849, 0.09282346814870834, -1.6853265762329102, -0.5290353298187256, -1.0648407936096191, -0.4418187737464905, 0.447444349527359, -0.1774655133485794, -0.08538078516721725, -0.9377479553222656, -1.5653976202011108, -0.6081655025482178, -0.8650007247924805, -1.3542022705078125, 0.5424244403839111, -0.408029168844223, -0.19479906558990479, -0.3818325400352478, -0.38385361433029175, -0.7277639508247375, 0.9820387959480286, -0.2594801187515259, 0.5375930666923523, 0.10250424593687057, -0.6416312456130981, 0.11950670927762985, -0.3741559684276581, 0.044655825942754745, -0.3756221532821655, 0.6321786046028137, -0.053974639624357224, 0.09105441719293594, -0.49655455350875854, -0.1836289018392563, -0.2483913153409958, 0.3165726065635681, 1.2413239479064941, -0.31127992272377014, -0.7161310911178589, 0.36434200406074524, 1.4625662565231323, -0.9103716611862183, -0.18488256633281708, -0.04484798014163971, 0.7437551617622375, 0.37987184524536133, 0.012791357934474945, 1.1332452297210693, -0.12614230811595917, 0.6037597060203552, 0.288216769695282, -0.14491669833660126, 0.4397472143173218, 0.003219505539163947, 0.3365497887134552, 1.3252555131912231, 0.6347562670707703, -0.4013519287109375, -0.8252339363098145, 0.355148047208786, -1.3582758903503418, -0.37195056676864624, 0.7638533115386963, 0.6522035002708435, 0.22228534519672394, -0.23137317597866058, -0.11753683537244797, -0.12846040725708008, 0.47032588720321655, 0.35293930768966675, -0.5939571261405945, -0.9031683802604675, 0.5902286767959595, 0.21407946944236755, 0.5045477151870728, 0.23918423056602478, 0.2597910165786743, 0.3671315014362335, 15.077281951904297, 0.8589429259300232, -0.00310621433891356, 0.24664521217346191, 0.13622495532035828, 0.3105292022228241, -0.1180565357208252, -0.20114324986934662, -1.4186456203460693, 0.4484301507472992, 1.3736467361450195, -0.16875530779361725, 0.4924597442150116, -0.09121950715780258, 0.26402437686920166, -0.03781390190124512, -0.3589015603065491, 0.2023380994796753, 0.2711578607559204, -1.7830746173858643, 0.37704595923423767, 0.43152865767478943, 0.21831399202346802, 0.5346331596374512, 0.6194164752960205, 0.4827132225036621, 0.7672892212867737, -0.3413524925708771, 0.0996096208691597, -0.0108152125030756, 1.5135446786880493, -0.3904654085636139, 0.6468231678009033, 0.7716209888458252, -0.9735639691352844, 0.13543152809143066, -0.4019210934638977, -1.2105544805526733, 0.2953346073627472, 0.5996743440628052, -1.377414584159851, 0.016855226829648018, -0.1469780057668686, 0.5471408367156982, 1.1164283752441406, 0.1195128932595253, -0.29607945680618286, 0.5083408951759338, 0.20539192855358124, 0.1837301403284073, -0.07551675289869308, 0.3241959810256958, 0.09776441752910614, 0.007651081308722496, -0.12892262637615204, -0.3530585765838623, 1.1658053398132324, 0.3342755436897278, -0.7193254828453064, -0.3177632689476013, -0.39031991362571716, -0.5505655407905579, 0.2010786086320877, 1.0532829761505127, 0.3498825430870056, 0.12688568234443665, -0.16650156676769257, 0.41562917828559875, 0.13149946928024292, 0.4745730459690094, -0.6216532588005066, 0.23541657626628876, 0.8167269825935364, -0.5476620197296143, 0.01908903382718563, 0.20424021780490875, -0.1565435826778412, -0.5149943828582764, -0.8267523646354675, -0.5062212347984314, 0.22150202095508575, -0.5536337494850159, -0.9621325135231018, 0.6347340941429138, -0.026209963485598564, -0.7489359974861145, -0.22449234127998352, -0.994960606098175, 0.12528282403945923, 0.48250076174736023, -1.134086012840271, -0.47405409812927246, 0.3969605565071106, -0.6989405155181885, -0.4114263951778412, 0.25968655943870544, 1.1082451343536377, 0.4334683120250702, -0.5049010515213013, -0.3163386583328247, 0.16080902516841888, -0.36888745427131653, -0.16247814893722534, -0.6782565116882324, 0.9271972179412842, 0.4032723903656006, -0.45314377546310425, 0.3472668528556824, 0.14982272684574127, -0.12619957327842712, -0.8526350259780884, -0.35874316096305847, 0.08226174116134644, -0.6400664448738098, 0.10901892185211182, -0.8643932342529297, -0.731326699256897, 0.3707374334335327, 0.45662039518356323, 0.06997794657945633, 0.5224741101264954, -0.2999771535396576, -0.11040966212749481, -0.08993642777204514, -1.0280734300613403, 0.2865176200866699, 0.6155436635017395, -0.40566951036453247, 0.1723465621471405, 0.689111053943634, 0.7438130974769592, -1.5285528898239136, -1.178173303604126, 0.15115675330162048, 0.0821557343006134, 0.050049860030412674, 1.1556228399276733, -0.17682762444019318, 1.1846566200256348, 0.4746496081352234, -0.21650336682796478, -0.46799254417419434, 0.33516159653663635, -1.285262942314148, -0.3272078335285187, -0.4059247076511383, 0.6198989748954773, -0.5997556447982788, 0.6280118823051453, 0.35392117500305176, 0.3173690140247345, -0.7324992418289185, 0.0913281962275505, -0.48721843957901, -0.508915364742279, 0.014187848195433617, 0.5129392147064209, 0.16897381842136383, -0.2143062800168991, -0.10029102116823196, 0.10212947428226471, 0.8757957816123962, 0.08921439200639725, 0.07687829434871674, 0.4858713448047638, 0.06588771939277649, -0.3600248396396637, -0.2888113260269165, -0.056890036910772324, -1.4188212156295776, 0.06218837946653366, -1.1778020858764648, 0.244299054145813, -0.8987982869148254, -0.4572264850139618, 0.11160483211278915, 0.20626217126846313, 0.2476619929075241, 0.7099866271018982, -0.0064698499627411366, -0.8237566351890564, -0.27370911836624146, -0.5142292380332947, 0.5030640959739685, 0.9367212057113647, -0.07846146821975708, 0.15564370155334473, -0.12795045971870422, 0.5207768678665161, 0.011515951715409756, 0.6566181182861328, -0.2923734486103058, -0.6846623420715332, -0.940741777420044, 0.24501368403434753, 0.16065794229507446, -0.19787386059761047, -0.23311902582645416, 0.641226053237915, -0.21629542112350464, -0.22489172220230103, -0.42638471722602844, -0.04761294648051262, -0.7607525587081909, -0.3500707149505615, 0.40550121665000916, -0.4250037670135498, 0.38025015592575073, 0.4228474497795105, -0.9111671447753906, 0.1354936957359314, 0.6974212527275085, -0.5717017650604248, -0.7575724720954895, -0.7409551739692688, 0.6365315318107605, -0.650497317314148, 0.27879804372787476, -0.06893818080425262, 0.038247909396886826, -1.4225386381149292, -0.0010485138045623899, 0.21167029440402985, 0.7352432608604431, -0.2980516850948334, 0.6129677891731262, 0.4640021324157715, -0.8677719831466675, 0.0044073546305298805, 0.3415463864803314, -0.284728080034256, -0.18019096553325653, 0.2459535300731659, 0.8013496398925781, -0.4760534167289734, 0.24775543808937073, 0.09179604053497314, -0.059422191232442856, -0.6834390759468079, 0.19263015687465668, 0.37165871262550354, -0.6171744465827942, 0.04516664519906044, 0.4552072286605835, -0.780558705329895, -1.2521480321884155, -0.1145826131105423, -0.7973520755767822, -0.2116544097661972, -0.7483766674995422, 0.5557938814163208, 0.5072888135910034, -0.12081187218427658, 0.5018506646156311, -0.7143160700798035, -0.014847551472485065, -0.21367284655570984, -0.6057453155517578, 0.15626759827136993, -0.24376659095287323, -0.8933820128440857, 0.20488184690475464, 0.12984780967235565, -0.3244914412498474, -0.24689410626888275, -0.4556316137313843, -0.056096021085977554, -0.3204900920391083, 0.06180616468191147, -0.5603588223457336, -0.3396233022212982, 0.28547796607017517, -0.23115262389183044, 0.7308964133262634, 0.3000549376010895, -0.44375455379486084, 0.593535304069519, 0.5078126192092896, 0.10464894026517868, -0.30640432238578796, -0.1908993124961853, 0.7104510068893433, 1.1294031143188477, -0.6161333322525024, 0.7900253534317017, -0.28327295184135437, -0.8446589708328247, 1.0994163751602173, 0.5141366720199585, 0.29439103603363037, 0.4178794324398041, 0.4493413269519806, -0.04393065720796585, -0.02380443923175335, -1.1809461116790771, -0.3048803508281708, 0.6996706128120422, 0.5491364598274231, 0.5732474327087402, 0.5123379826545715, -0.4172595143318176, -0.21265365183353424, 0.37477174401283264, 0.4984854459762573, 0.5908821225166321, 0.7900031208992004, -0.21725396811962128, -0.4581235647201538, -0.20887959003448486, 0.7291095852851868, -0.8277127742767334, -0.4932749271392822, 0.3934412896633148, 0.7671757340431213, 0.11565154045820236, 0.6721610426902771, 0.8563648462295532, -0.3762661814689636, 0.37736061215400696, -0.29314446449279785, 0.33205530047416687, -0.7378911972045898, 0.17137590050697327, -0.2660712003707886, -0.34771350026130676, -0.43253639340400696, -0.016045916825532913, 0.060178618878126144, -0.8239744901657104, -1.1732490062713623, 0.5815132260322571, 0.3030231297016144, 0.6140345931053162, 1.1245592832565308, 1.0400913953781128, 0.6697124242782593, 0.0068616922944784164, -0.8769887685775757, -0.697479784488678, -0.8106199502944946, 0.11247044056653976, -0.8907283544540405, -0.5741068124771118, -0.13773253560066223, -0.26178818941116333, -0.6007972359657288]}, "authors": [{"authorId": "2105614495", "name": "Hyungjun Oh"}, {"authorId": "2295991270", "name": "Kihong Kim"}, {"authorId": "2186400721", "name": "Jaemin Kim"}, {"authorId": "2220591222", "name": "Sungkyun Kim"}, {"authorId": "2108522497", "name": "Junyeol Lee"}, {"authorId": "2295990937", "name": "Du-seong Chang"}, {"authorId": "2296490384", "name": "Jiwon Seo"}], "references": [{"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "2c994fadbb84fb960d8306ee138dbeef41a5b323", "title": "SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models"}, {"paperId": "7da0f2501034522e3d50af7e9b8fa7ec9d7b65b6", "title": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers"}, {"paperId": "4be7d1524edb0137599a5cc95f72844b85a52fe1", "title": "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale"}, {"paperId": "c022f75b00d795c6297d6a9ea948856ea4d365a1", "title": "DeepSpeed- Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale"}, {"paperId": "76d40153acfbb35a7eb8272a4215854cafa10e78", "title": "PLATON: Pruning Large Transformer Models with Upper Confidence Bound of Weight Importance"}, {"paperId": "e03609f2587f690867e7ea0bedaf0db25282c548", "title": "ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "e4f82c0a13cae6739239ae0c25a554b6daff35af", "title": "Compression of Generative Pre-trained Language Models via Quantization"}, {"paperId": "b3848d32f7294ec708627897833c4097eb4d8778", "title": "LaMDA: Language Models for Dialog Applications"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "9202a718ce05395b6e17d5301e3a2e8b1021f31b", "title": "Prune Once for All: Sparse Pre-Trained Language Models"}, {"paperId": "adc13ef61e47628e9efcdca0c27654370e46dae5", "title": "SciXGen: A Scientific Paper Dataset for Context-Aware Text Generation"}, {"paperId": "73bcf4577284fa116ee73487b7cbb85c8266eaa0", "title": "Understanding and Overcoming the Challenges of Efficient Transformer Quantization"}, {"paperId": "77d956cdab4508d569ae5741549b78e715fd0749", "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods"}, {"paperId": "a38e0f993e4805ba8a9beae4c275c91ffcec01df", "title": "Program Synthesis with Large Language Models"}, {"paperId": "10f3ca78e194552427ebe9173b19d1b910469e27", "title": "Chimera: Efficiently Training Large-Scale Neural Networks with Bidirectional Pipelines"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "774591fdd988eaaff3917e7c5171d044b0843e63", "title": "Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM"}, {"paperId": "040ad14a2c97e51510889ae6a0c3c23b29da801d", "title": "TeraPipe: Token-Level Pipeline Parallelism for Training Large-Scale Language Models"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "3fd7c9ba742dd2b435afa75217847e5087e2f2a8", "title": "PipeDream: generalized pipeline parallelism for DNN training"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "ce106590145e89ea4b621c99665862967ccf5dac", "title": "Q8BERT: Quantized 8Bit BERT"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "40345901fd28cbf65791c34671db6548b1089ed4", "title": "BIGPATENT: A Large-Scale Dataset for Abstractive and Coherent Summarization"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "d79a26226393f687ddbc375e32055b40b8ad8d38", "title": "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism"}, {"paperId": "990a7b4eceedb6e053e6386269481bdfc42a1094", "title": "CoQA: A Conversational Question Answering Challenge"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "668db48c6a79826456341680ee1175dfc4cced71", "title": "Get To The Point: Summarization with Pointer-Generator Networks"}, {"paperId": "1a327709cc53ff9e52454e50a643abf4a0ac92af", "title": "Findings of the 2016 Conference on Machine Translation"}, {"paperId": "d1505c6123c102e53eb19dff312cb25cea840b72", "title": "Teaching Machines to Read and Comprehend"}, {"paperId": "cedcbbbd4b9f31cd17fba053407d2f8655634094", "title": "Monotonic Optimization: Problems and Solution Approaches"}, {"paperId": "77b312fc36d942cba23842b2f56da335fad70c80", "title": "On Bayesian Methods for Seeking the Extremum"}, {"paperId": "9d7a75601e0e50dd68d40cfb8ef0e891dad797a6", "title": "Orca: A Distributed Serving System for Transformer-Based Generative Models"}, {"paperId": null, "title": "NVIDIA"}, {"paperId": null, "title": "Accel-erating sparse deep neural networks"}, {"paperId": null, "title": "International Conference for High Performance Computing, Networking, Storage and Analysis , SC \u201921, New York, NY, USA,"}, {"paperId": null, "title": "Measuring massive multi-task language understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Seq2sql:Generating structuredqueriesfromnaturallanguageusingreinforcementlearning arXiv"}, {"paperId": "12d3f77fc40838f9616c1a2c1907dc7aa9808779", "title": "Discrete Monotonic Optimization with Application to a Discrete Location Problem"}, {"paperId": null, "title": ":Openpre-trainedtransformerlanguagemodels"}, {"paperId": null, "title": "ASPLOS \u201924, April 27-May 1, 2024"}, {"paperId": null, "title": "Unifyinglanguagelearningparadigms"}, {"paperId": null, "title": "Llama:Openandefficientfoundation languagemodels"}, {"paperId": null, "title": "Al-paca: A strong, replicable instruction-following model"}]}