{"paperId": "129c1855ceaf6d2c1825fe8bf16950ee63e4d636", "title": "Recurrent neural networks: vanishing and exploding gradients are not the end of the story", "abstract": "Recurrent neural networks (RNNs) notoriously struggle to learn long-term memories, primarily due to vanishing and exploding gradients. The recent success of state-space models (SSMs), a subclass of RNNs, to overcome such difficulties challenges our theoretical understanding. In this paper, we delve into the optimization challenges of RNNs and discover that, as the memory of a network increases, changes in its parameters result in increasingly large output variations, making gradient-based learning highly sensitive, even without exploding gradients. Our analysis further reveals the importance of the element-wise recurrence design pattern combined with careful parametrizations in mitigating this effect. This feature is present in SSMs, as well as in other architectures, such as LSTMs. Overall, our insights provide a new explanation for some of the difficulties in gradient-based learning of RNNs and why some architectures perform better than others.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "It is discovered that, as the memory of a network increases, changes in its parameters result in increasingly large output variations, making gradient-based learning highly sensitive, even without exploding gradients."}, "embedding": {"model": "specter_v2", "vector": [-0.012472495436668396, 0.6641405820846558, -0.09384993463754654, 0.051269471645355225, 0.24577674269676208, 0.08784820139408112, 0.7376634478569031, -0.8253846764564514, -0.4861181378364563, -0.0866449698805809, 0.5639020204544067, 0.15183301270008087, 0.45795729756355286, 0.15826381742954254, -0.0688428282737732, -0.15783657133579254, -1.2352019548416138, -0.7019149661064148, 0.09147047251462936, -0.4497085511684418, 0.19011318683624268, -0.10626548528671265, -1.346972107887268, -0.2815678119659424, -0.46693921089172363, 1.0776606798171997, 0.03730606660246849, 1.118930459022522, -0.19430041313171387, 1.2296390533447266, 0.6041855812072754, -0.10041454434394836, 0.4398763179779053, -0.2042607069015503, -0.2594873011112213, -0.4798555076122284, 0.3130092918872833, -0.6442427039146423, -0.8701840043067932, 0.6619709730148315, -0.46644169092178345, 0.391533225774765, 0.10275062918663025, -0.345370352268219, 0.3857349753379822, 0.2672622501850128, 0.8615118265151978, 0.932702898979187, -0.6324771046638489, -0.3352404534816742, 1.247437834739685, -1.0878612995147705, 0.4305994510650635, 1.4183249473571777, 0.7243558764457703, 0.6773016452789307, 0.023979727178812027, -0.533297598361969, 1.234236717224121, -0.2972138226032257, -0.5920124053955078, -0.5243605971336365, 0.2869326174259186, 0.18427972495555878, 1.5510188341140747, -0.32948771119117737, -0.10147034376859665, 0.6245087385177612, 0.07573799043893814, 1.1295182704925537, 0.05927925929427147, -0.7244151830673218, -0.07944926619529724, 0.36383679509162903, 0.6168035864830017, 0.8544135093688965, -0.3125763237476349, 0.7147150039672852, -0.9811556339263916, 0.24344833195209503, 0.9225575923919678, 0.13595138490200043, -0.20181240141391754, -0.21982122957706451, -0.02663569524884224, 0.7284764051437378, 0.6117653250694275, 0.5608510375022888, -0.5342100858688354, 1.1719375848770142, 0.4230133295059204, 0.5227116942405701, -0.02935398928821087, 0.18648646771907806, 0.039267949759960175, 0.309270977973938, -0.4534316658973694, -0.11989553272724152, 0.21000298857688904, 0.5978055000305176, -0.05516717582941055, 0.669069766998291, -0.08013413101434708, 0.18632429838180542, 1.25350022315979, -0.6926631927490234, 0.8631110191345215, -0.7456395626068115, 0.3096214234828949, -0.6946911811828613, 0.35583579540252686, -1.009240984916687, -0.4999004900455475, -0.7908822894096375, -0.990334689617157, -0.8874222636222839, -0.44372090697288513, 0.03381040319800377, -0.38885498046875, 1.170364260673523, -0.34695711731910706, 0.22075635194778442, 0.15915647149085999, 0.8832641243934631, 0.14370036125183105, 0.9210902452468872, -0.03623895347118378, -0.20532450079917908, 0.3418796956539154, -0.814853310585022, -1.0338842868804932, -1.0983892679214478, 0.5537286996841431, 0.39442992210388184, 0.10074567794799805, -0.40632185339927673, -1.129118800163269, -0.775878369808197, -1.4593225717544556, 0.5364593863487244, -0.46012377738952637, 0.013846229761838913, 1.15142023563385, 0.07146672904491425, -1.0230202674865723, 1.5479612350463867, -0.5360299348831177, 0.07422433793544769, 0.1283169388771057, 0.4090092182159424, 0.4519447982311249, 0.09925699234008789, -0.9499533176422119, 0.7098379135131836, 0.3251245617866516, 0.04590599611401558, 0.24147267639636993, -0.47839727997779846, -0.9057374000549316, 0.10636047273874283, 0.19928644597530365, -0.4667258858680725, 1.1218496561050415, 0.04530661180615425, -1.5117263793945312, 0.12592332065105438, -0.02996683493256569, -0.002336389385163784, 0.18172982335090637, -0.03646031394600868, -0.7364348769187927, -0.1084069088101387, -0.794017493724823, 0.3903256952762604, 0.4175366163253784, -0.22798840701580048, -0.18076039850711823, -0.2937910556793213, -0.9053786396980286, -0.2291417419910431, -0.436428427696228, 0.6704668402671814, 0.06308165937662125, 0.06733036041259766, 0.7455065250396729, 0.5274439454078674, -0.2719995081424713, -0.3430483043193817, -0.09435530751943588, -1.057707667350769, 0.3458462655544281, 0.35876405239105225, 1.3610209226608276, -0.7111883759498596, -0.8952604532241821, -0.1552026867866516, -0.295912504196167, -0.280953049659729, -0.6073185801506042, 0.07272695749998093, -0.5406360626220703, 0.5285054445266724, 0.13849669694900513, -0.9808667898178101, -0.12248369306325912, -0.04809361696243286, -0.9882123470306396, 0.023011507466435432, 0.4160572290420532, 0.8236569762229919, -1.0143531560897827, 0.021761013194918633, -0.11330343782901764, 0.12094123661518097, -0.29511281847953796, 1.4282065629959106, 0.01658889651298523, -0.3898869454860687, 0.011484654620289803, -0.5130118727684021, -0.23515744507312775, -0.5514604449272156, 0.47850677371025085, -0.24888452887535095, -0.4332210421562195, 0.7994382381439209, -0.9101653695106506, 1.071582555770874, -0.3751325011253357, 0.9575836658477783, -0.1572292000055313, -0.7575116157531738, 0.06850671023130417, 0.18912255764007568, -0.26711270213127136, -0.5198681354522705, 0.46052902936935425, 0.2656378448009491, -0.9497157335281372, 0.769302487373352, 0.716213047504425, 0.840735912322998, -0.35580217838287354, 0.3562091290950775, 0.8863102197647095, -0.17771783471107483, 0.25642791390419006, 0.3852398991584778, 0.4321456253528595, 0.4200844466686249, 0.04946734756231308, 0.06842672824859619, -0.15366609394550323, -1.2531569004058838, 0.2253955453634262, 0.5177258849143982, 0.6414392590522766, 1.1473301649093628, 0.5176926851272583, -0.9122499227523804, -0.30589866638183594, -0.24450847506523132, 0.3572191596031189, 0.9633253812789917, -0.42089736461639404, -0.0775671899318695, -0.322919636964798, 0.1381024569272995, -0.7217660546302795, 0.16706520318984985, -0.4209214746952057, -0.4502539336681366, -0.5851132273674011, -1.2607617378234863, 0.4970347583293915, 0.04122013971209526, 0.9641909003257751, -0.6546240448951721, -0.6506996154785156, -0.06537032872438431, 0.8080923557281494, -0.528492271900177, -0.4279042184352875, 0.5850696563720703, -1.1833350658416748, -0.13704116642475128, -0.08889015763998032, 0.005094415042549372, -0.031170330941677094, -0.6956472396850586, 0.8440227508544922, -0.34859612584114075, -0.11823837459087372, 0.31230223178863525, 1.2070258855819702, -0.8014447093009949, -0.38733845949172974, 0.030091453343629837, 0.44689762592315674, -0.015945367515087128, -0.33402153849601746, 0.3700707256793976, -0.4340405762195587, -0.12713202834129333, -0.44545578956604004, -0.2212638407945633, 0.13529455661773682, 0.2415689080953598, 0.41643697023391724, -0.5190510749816895, 0.6379391551017761, -0.9143930673599243, 1.0483930110931396, 0.08354315161705017, -0.6888467073440552, 0.27569133043289185, -1.2909024953842163, 0.3451290428638458, 0.38777804374694824, -0.584599494934082, -0.23574505746364594, -1.1279072761535645, 0.700455367565155, -0.5849642157554626, 0.11321497708559036, -0.04714737460017204, 1.0415880680084229, 0.22097662091255188, 0.06946074217557907, 0.05841270089149475, 0.5497519969940186, -0.029848888516426086, 0.0005730795674026012, -0.9007699489593506, 0.7545728087425232, 0.8786730766296387, -0.3347640931606293, -0.2790135443210602, 0.28797227144241333, -0.5551999807357788, -0.875740647315979, -0.4344487190246582, 0.10266844183206558, -0.394538551568985, -0.47107234597206116, -0.46512171626091003, -0.7231186628341675, 0.14604300260543823, -0.8141922354698181, -0.3503856658935547, -0.08560708910226822, -0.005908577237278223, -0.45932841300964355, -1.1670677661895752, -1.3117713928222656, -1.1209008693695068, -0.5728247165679932, -0.36657071113586426, -0.23680540919303894, 0.47177520394325256, -0.40964871644973755, -0.4061974883079529, 0.04111192375421524, -1.1400974988937378, 1.1026811599731445, -0.6673403382301331, 0.2641727328300476, 0.23959772288799286, -0.22727957367897034, -0.35038629174232483, 0.30703142285346985, 0.6067160367965698, -0.3711797893047333, 0.06755991280078888, -0.7392975687980652, 0.3880853056907654, -0.03353806957602501, -0.29077982902526855, 0.2313920110464096, 0.048339445143938065, 0.3672541081905365, -0.38066941499710083, -0.022923996672034264, 0.4080943167209625, 1.468860149383545, -0.8168989419937134, 0.20563063025474548, 0.17204312980175018, 0.6094463467597961, 0.4120035171508789, -0.43080273270606995, 0.5028887987136841, -0.15939520299434662, 0.03645970672369003, 0.41725656390190125, 0.0865875780582428, -0.3452470004558563, -0.8787980675697327, 0.4100624918937683, 1.5356690883636475, 0.5686302781105042, 0.3732088804244995, -0.1879388988018036, 0.5964578986167908, -1.3884975910186768, -0.7229819297790527, 0.854164183139801, 1.1128053665161133, 0.34974369406700134, -0.25360235571861267, -0.3871859312057495, -0.2517370879650116, 0.2971174120903015, 0.5436342358589172, -0.8585715889930725, -0.7236624360084534, -0.2421906441450119, 0.14726628363132477, 0.3361626863479614, 0.4150026738643646, 0.011556382291018963, 0.5437816381454468, 14.843353271484375, 0.05655326321721077, -0.3770163059234619, 0.09512747079133987, 0.6829519271850586, -0.14272546768188477, 0.1059315949678421, -0.27284950017929077, -1.1210018396377563, 0.03493225947022438, 1.7350337505340576, 0.7304543256759644, 0.5434548258781433, -0.11050423979759216, -0.06720839440822601, 0.009731588885188103, -0.3136589527130127, 1.0030605792999268, 0.32400694489479065, -1.4115118980407715, 0.091046541929245, -0.04999930039048195, 0.4754612445831299, 0.92740797996521, 0.9312223196029663, 0.5963689684867859, 0.4192451536655426, -0.1650351881980896, 0.405009001493454, 0.7761783599853516, 0.5340406894683838, -0.3174961805343628, 0.3337360918521881, 0.36237430572509766, -0.37343308329582214, -0.40928518772125244, -0.4333338141441345, -1.0805304050445557, 0.10140801221132278, -0.02307075634598732, -0.2838701903820038, -0.7661899328231812, 0.12571951746940613, 0.5289037823677063, -0.07008638978004456, 0.16173171997070312, -0.15506869554519653, 0.47315919399261475, -0.6186570525169373, -0.3319520950317383, 0.486378937959671, 0.05542350560426712, 0.2225978672504425, -0.14449651539325714, -0.017209690064191818, 0.1690472513437271, -0.5542482733726501, 0.7732735872268677, -0.31194043159484863, -0.3216470777988434, -0.34464049339294434, -0.24204587936401367, -0.18660935759544373, 0.6979055404663086, 0.6986621022224426, 0.27443480491638184, -0.03774555027484894, 0.36013272404670715, 0.6659777164459229, 0.36382102966308594, 0.3754013180732727, -0.3103165328502655, 0.5993832349777222, -0.650765597820282, -0.18536336719989777, 0.18207110464572906, -0.5450416207313538, -0.6149007081985474, -0.6450350284576416, 0.21883843839168549, 0.2568412125110626, -1.253464937210083, -0.3206959664821625, 0.9461398720741272, -0.44971293210983276, -0.0808950662612915, -0.25867095589637756, -0.6862070560455322, -0.29102420806884766, 0.318868488073349, -1.3656185865402222, 0.10616428405046463, 0.31117916107177734, -0.2608327865600586, -0.5827992558479309, -0.10683980584144592, 1.0873745679855347, -0.3295283317565918, -1.2291969060897827, -0.03254774212837219, 0.002306512091308832, -0.29747313261032104, -0.6343590617179871, -0.7758038640022278, 0.5607477426528931, 0.4255414307117462, -0.0013493538135662675, 0.5411010384559631, 0.2979530692100525, 0.6016853451728821, -0.6721504926681519, 0.12253785878419876, 0.4500008821487427, -0.6987028121948242, 0.1401664912700653, -0.23670165240764618, -0.8936371207237244, 0.4095248281955719, 0.25849348306655884, 0.28458014130592346, -0.2703916132450104, 0.34567970037460327, -0.3889883756637573, -0.2316838651895523, -0.27447885274887085, 0.5522038340568542, 0.44765403866767883, -0.8072420358657837, -0.33057165145874023, -0.4634035527706146, 0.17900660634040833, -0.41727253794670105, -0.22649434208869934, -0.101071298122406, 0.0778149738907814, -0.6366285085678101, 0.7353783249855042, -0.7714497447013855, 0.1579207330942154, 0.834574818611145, -0.11271386593580246, -0.7041991949081421, 0.04195656254887581, -0.9630581736564636, -0.11723724007606506, 0.045132558792829514, 0.4176180958747864, -0.8144456744194031, 0.40606001019477844, 1.0433025360107422, -0.004244053736329079, -0.46229085326194763, -0.8151775002479553, -0.25644204020500183, -0.4052698314189911, -0.35016322135925293, -0.09645947068929672, -0.250288188457489, -0.0737445056438446, 0.4507967531681061, 0.4549426734447479, 0.6247106790542603, -0.21851015090942383, -0.8210422396659851, -0.26167553663253784, -0.20797502994537354, 0.3676314651966095, -0.9936918616294861, -0.6080997586250305, -1.571010708808899, -0.03955276310443878, -0.8593202829360962, -0.20080944895744324, -0.7104012370109558, -0.8781379461288452, 0.12159965932369232, -0.7516106963157654, -0.12310902774333954, 0.6764253973960876, -0.4184921979904175, -0.4321121871471405, -0.12078134715557098, -0.8396166563034058, 0.8105849623680115, 0.41587406396865845, -0.22355973720550537, -0.28598394989967346, 0.17433637380599976, 0.19584350287914276, 0.3580244779586792, 0.8002300262451172, -0.2874391973018646, -0.4939347803592682, -0.9603855013847351, 0.6325284242630005, -0.09185454994440079, 0.11142558604478836, -0.8557450771331787, 0.9326626062393188, 0.6004928946495056, 0.17511577904224396, -0.2063901424407959, 0.3944675028324127, -0.7621799111366272, -0.24954551458358765, 0.2850155234336853, -0.6877439022064209, 0.13324977457523346, 0.2646405100822449, -0.3035896122455597, -0.2081298679113388, 0.4048095941543579, 0.013810825534164906, -0.9132519960403442, -0.7072258591651917, 0.4429319500923157, -0.5581874251365662, -0.2664230763912201, -0.5846998691558838, -0.5251747369766235, -0.8114742040634155, -0.30222782492637634, 0.0064122602343559265, 0.34132644534111023, -0.6357455849647522, 1.0095351934432983, 0.5249163508415222, -1.1967554092407227, 0.2677899897098541, 0.41310998797416687, -0.17271974682807922, -0.05635512247681618, 0.2624957263469696, -0.035294901579618454, -0.14405301213264465, 0.6650727987289429, 0.3184862434864044, 0.36269935965538025, -0.4443836212158203, -0.10039836913347244, 1.093653917312622, -0.26416757702827454, -0.04216723516583443, 0.9047464728355408, -0.40143683552742004, -0.9733790159225464, 0.4502109885215759, -1.1382582187652588, -0.5042423605918884, 0.11389991641044617, 0.4891970157623291, 0.47470569610595703, 0.01375037431716919, 0.19693563878536224, 0.022998031228780746, 0.2341664731502533, 0.24365152418613434, -0.48309990763664246, 0.6191734671592712, -0.4829920530319214, -0.010715622454881668, 1.5386931896209717, 1.304977536201477, -1.3546719551086426, -1.2895488739013672, -0.9044129848480225, 0.21545571088790894, 0.08520449697971344, 0.734978437423706, -0.11162982881069183, -0.8757509589195251, 0.7291617393493652, 1.1920639276504517, -0.00872891116887331, -0.012370315380394459, -0.31335318088531494, -0.3457024395465851, 0.6529654860496521, 0.0757635235786438, -0.92415851354599, -0.16477665305137634, 1.2471733093261719, 1.4723773002624512, -0.9404812455177307, 0.5272678136825562, 0.17755459249019623, -0.19037002325057983, 0.7724480032920837, 0.2352178692817688, -0.30827808380126953, 1.0173709392547607, -0.6363549828529358, 0.09420515596866608, -0.06639397144317627, -1.4063379764556885, 0.07122905552387238, 0.5688199996948242, 0.29681527614593506, 0.38544219732284546, 0.20122188329696655, 0.27429625391960144, 0.7838904857635498, -0.22989927232265472, -0.06450190395116806, 0.6344097256660461, 0.5451570749282837, -0.2236570119857788, 0.5060766339302063, 0.18509873747825623, 0.5507938861846924, -0.8689435124397278, -0.43395525217056274, 0.3223622143268585, 0.6666878461837769, -0.7009674906730652, 0.4323222041130066, 1.2241151332855225, 0.009242070838809013, 0.7223146557807922, 0.2110033482313156, 0.5587984919548035, -0.12328935414552689, -0.4287593960762024, -0.24948132038116455, -0.2911014258861542, -0.3638375997543335, 0.08393537998199463, -0.8278487324714661, -0.36466532945632935, 0.03290868178009987, -0.16212350130081177, -0.05374130979180336, 0.7327986359596252, 0.6338022947311401, 0.5980836153030396, 0.5787038207054138, 0.36580437421798706, -0.5286219120025635, -0.9247851967811584, -0.9510018825531006, -0.06520746648311615, -0.3983248770236969, 0.25767695903778076, -0.050724416971206665, -0.7220976948738098, -0.6776443123817444]}, "authors": [{"authorId": "2304328495", "name": "Nicolas Zucchet"}, {"authorId": "51931942", "name": "Antonio Orvieto"}], "references": [{"paperId": "917479a7a72ee7c1fb320c14d770e30ef322ef28", "title": "The Illusion of State in State-Space Models"}, {"paperId": "d53fe76bd2795a19ddf52d012917782f6f6f2c1e", "title": "Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models"}, {"paperId": "bbbed70ab3e2b3717e3af69007e36be7426935f7", "title": "Why do Learning Rates Transfer? Reconciling Optimization and Scaling Limits for Deep Learning"}, {"paperId": "63167c30b06aa6c3d76e09065ced0412090d6c3b", "title": "The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "cb84e762cdffbd3dd25f865474f384bb032960b1", "title": "A Spectral Condition for Feature Learning"}, {"paperId": "cb11a3b4e38fab6ed7b414926d382ce3105cd177", "title": "Persistent learning signals and working memory without continuous attractors"}, {"paperId": "0a304c773678824f7ab82e9f1acc8ed86dc668af", "title": "Universality of Linear Recurrences Followed by Non-linear Projections: Finite-Width Guarantees and Benefits of Complex Eigenvalues"}, {"paperId": "8aa92d7fc629fa95e75f7e1045ccd65df01fee50", "title": "Toward Understanding Why Adam Converges Faster Than SGD for Transformers"}, {"paperId": "b708aad20451d1be6572e65e3fd4f664e2b99f54", "title": "Inverse Approximation Theory for Nonlinear Recurrent Neural Networks"}, {"paperId": "55d8837c72863e63259a506b56222d08812699b0", "title": "Online learning of long-range dependencies"}, {"paperId": "f393aff1593c2d370ec0ae004910d18e40524967", "title": "Resurrecting Recurrent Neural Networks for Long Sequences"}, {"paperId": "6d7d141c75af752ffc0d8a6184cca3f9323d6c74", "title": "Simplified State Space Layers for Sequence Modeling"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "71e15a9a52dcafca57bff5f310b95e2c7d0cfc87", "title": "Diagonal State Spaces are as Effective as Structured State Spaces"}, {"paperId": "0b0d7d87c58d41b92d907347b778032be5966f60", "title": "Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "ca9047c78d48b606c4e4f0c456b1dda550de28b2", "title": "Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers"}, {"paperId": "bf80051ca9ae1e76e2bdbdcf44df559e7eb73cb1", "title": "A Practical Survey on Faster and Lighter Transformers"}, {"paperId": "026bb8a1066f50ddc8797e1341353603149a8cb8", "title": "Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "87da4c27f7b2ddac63654458b06c9d708d042f6a", "title": "Feature Learning in Infinite-Width Neural Networks"}, {"paperId": "fac144db777ddc3d85bb314087889689293affa0", "title": "Coupled Oscillatory Recurrent Neural Network (coRNN): An accurate and (gradient) stable architecture for learning long time dependencies"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "67a9dde04f367efc903b6d06097df9bdd9887ae7", "title": "Recurrent Independent Mechanisms"}, {"paperId": "653335c645c594a02df3081a72ea3eb6bd39d311", "title": "Gradient Descent Happens in a Tiny Subspace"}, {"paperId": "b0526da184f99f359fa7b3430ccc73a3340f3d70", "title": "Dynamical Isometry and a Mean Field Theory of RNNs: Gating Enables Signal Propagation in Recurrent Neural Networks"}, {"paperId": "0e9822e6c78b752f13ccf2943a8e41f9997f4a22", "title": "Can recurrent neural networks warp time?"}, {"paperId": "b74bfb6afd5abcb2c6fe0b2f8d60b97cdb80ca55", "title": "Orthogonal Recurrent Neural Networks with Scaled Cayley Transform"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "87a913817503379547bec61a5f010abac5b0f76b", "title": "Fast-Slow Recurrent Neural Networks"}, {"paperId": "9d1fb89b99aafc01ee56fc92df1ad150fba67c22", "title": "On orthogonality and learning recurrent networks with long term dependencies"}, {"paperId": "e7de07a63cc5df2e778a48c19ff27029223201ac", "title": "On the Computation of Complex-valued Gradients with Application to Statistically Optimum Beamforming"}, {"paperId": "88caa4a0253a8b0076176745ebc072864eab66e1", "title": "Language Modeling with Gated Convolutional Networks"}, {"paperId": "8a765725a44b91b60d414551dc555175cfff3cd9", "title": "Gradient Descent Learns Linear Dynamical Systems"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "952454718139dba3aafc6b3b67c4f514ac3964af", "title": "Recurrent Batch Normalization"}, {"paperId": "e9c771197a6564762754e48c1daafb066f449f2e", "title": "Unitary Evolution Recurrent Neural Networks"}, {"paperId": "d46b81707786d18499f911b4ab72bb10c65406ba", "title": "A Simple Way to Initialize Recurrent Networks of Rectified Linear Units"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "d6f2f611da110b5b5061731be3fc4c7f45d8ee23", "title": "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "1eb09fecd75eb27825dce4f964b97f4f5cc399d7", "title": "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "84069287da0a6b488b8c933f3cb5be759cb6237e", "title": "On the difficulty of training recurrent neural networks"}, {"paperId": "0d6203718c15f137fda2f295c96269bc2b254644", "title": "Learning Recurrent Neural Networks with Hessian-Free Optimization"}, {"paperId": "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649", "title": "Understanding the difficulty of training deep feedforward neural networks"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "9914a407d8de75ccfae2bf5cfdc5a565cf0e6000", "title": "The columnar organization of the neocortex."}, {"paperId": "b13813b49f160e1a2010c44bd4fb3d09a28446e3", "title": "Hierarchical Recurrent Neural Networks for Long-Term Dependencies"}, {"paperId": "d0be39ee052d246ae99c082a565aba25b811be2d", "title": "Learning long-term dependencies with gradient descent is difficult"}, {"paperId": "668087f0ae7ce1de6e0bd0965dbb480c08103260", "title": "Finding Structure in Time"}, {"paperId": "bd2fbbd4228f4e6c79a182876afa7fd972f79dde", "title": "Schemata and Sequential Thought Processes in PDP Models"}, {"paperId": "9249389a2fbc2151a80b4731f007c780616b067a", "title": "Fading memory and the problem of approximating nonlinear operators with volterra series"}, {"paperId": "c5083ad33f313b987903e519f81b88154a02c020", "title": "Neural Wave Machines: Learning Spatiotemporally Structured Representations with Locally Coupled Oscillatory Recurrent Neural Networks"}, {"paperId": "17f365fffb0c426b9269c6f863d6d6d14e1e2d0d", "title": "Approximation and Optimization Theory for Linear Continuous-Time Recurrent Neural Networks"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Lectures on convex optimization , volume 137"}, {"paperId": null, "title": "JAX: composable transformations of Python+NumPy programs"}, {"paperId": null, "title": "a method for stochastic optimization"}, {"paperId": "96364af2d208ea75ca3aeb71892d2f7ce7326b55", "title": "Statistical Language Models Based on Neural Networks"}, {"paperId": "2e5f2b57f4c476dd69dc22ccdf547e48f40a994c", "title": "Gradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term Dependencies"}, {"paperId": "3f3d13e95c25a8f6a753e38dfce88885097cbd43", "title": "Untersuchungen zu dynamischen neuronalen Netzen"}, {"paperId": null, "title": "\u2212 \u03bd \u2212 \u03bd The loss that we use is a next-token mean-squared error, that is L t = 1 2 \u2225 \u02c6 x t ( x 1: t \u2212 1 ) \u2212 x t \u2225 2 (134) with \u02c6 x t ( x 1: t \u2212 1 ) the prediction of the network"}]}