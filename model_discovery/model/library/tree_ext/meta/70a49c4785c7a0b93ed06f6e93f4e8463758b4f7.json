{"paperId": "70a49c4785c7a0b93ed06f6e93f4e8463758b4f7", "title": "ViR: Towards Efficient Vision Retention Backbones", "abstract": "Vision Transformers (ViTs) have attracted a lot of popularity in recent years, due to their exceptional capabilities in modeling long-range spatial dependencies and scalability for large scale training. Although the training parallelism of self-attention mechanism plays an important role in retaining great performance, its quadratic complexity baffles the application of ViTs in many scenarios which demand fast inference. This effect is even more pronounced in applications in which autoregressive modeling of input features is required. In Natural Language Processing (NLP), a new stream of efforts has proposed parallelizable models with recurrent formulation that allows for efficient inference in generative applications. Inspired by this trend, we propose a new class of computer vision models, dubbed Vision Retention Networks (ViR), with dual parallel and recurrent formulations, which strike an optimal balance between fast inference and parallel training with competitive performance. In particular, ViR scales favorably for image throughput and memory consumption in tasks that require higher-resolution images due to its flexible formulation in processing large sequence lengths. The ViR is the first attempt to realize dual parallel and recurrent equivalency in a general vision backbone for recognition tasks. We have validated the effectiveness of ViR through extensive experiments with different dataset sizes and various image resolutions and achieved competitive performance. Code: https://github.com/NVlabs/ViR", "venue": "", "year": 2023, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The ViR is the first attempt to realize dual parallel and recurrent equivalency in a general vision backbone for recognition tasks and scales favorably for image throughput and memory consumption in tasks that require higher-resolution images due to its flexible formulation in processing large sequence lengths."}, "embedding": {"model": "specter_v2", "vector": [0.816392183303833, 0.5301156640052795, -0.16801458597183228, 0.3079153001308441, -0.028540562838315964, 0.13131287693977356, 0.8257625102996826, -0.5119362473487854, -0.5283373594284058, -0.982086181640625, 0.47317618131637573, 0.2645546495914459, 0.40046265721321106, 0.27672144770622253, -0.18545088171958923, 0.011558675207197666, -0.5912100076675415, -0.11110192537307739, 0.33793044090270996, -0.3300101161003113, 0.07600649446249008, -0.22306649386882782, -1.6843291521072388, -0.10633868724107742, 0.03220900148153305, 0.9770138263702393, 0.5343794226646423, 1.2327561378479004, 0.0014754310250282288, 0.714870035648346, 0.6896987557411194, -0.2901120185852051, 0.38686424493789673, -0.007212395314127207, -0.24019093811511993, 0.13218578696250916, 0.8080413341522217, -0.21271689236164093, -0.8749526143074036, 0.5495681166648865, -0.18108926713466644, 0.45777714252471924, 0.6321092247962952, -0.6195149421691895, -0.6201382279396057, 0.1356491595506668, 0.14269137382507324, 0.9745129346847534, -0.5381840467453003, -0.31574925780296326, 1.3672540187835693, -1.118733525276184, 0.3253531754016876, 1.3554576635360718, 0.5119085311889648, 0.30519697070121765, 0.026432419195771217, -0.31794115900993347, 0.88080894947052, 0.11269637942314148, -0.4182621240615845, -0.5823097825050354, 0.28649845719337463, -0.0910758450627327, 1.7782567739486694, -0.45423948764801025, 0.25719785690307617, 0.9024980068206787, 0.22327174246311188, 1.1842886209487915, 0.23997552692890167, -0.7820795178413391, -0.3320024609565735, -0.3223372995853424, 0.6221502423286438, 0.9942656755447388, -0.20599210262298584, 0.5441107153892517, -1.1273139715194702, 0.18073228001594543, 0.8258158564567566, 0.27601438760757446, 0.17006418108940125, -0.3296671211719513, 0.2039821594953537, 0.8870717287063599, 0.9744569659233093, 0.48549190163612366, -0.5885288119316101, 0.7539336085319519, 0.5031996369361877, 0.0732303112745285, -0.26529252529144287, -0.0466436967253685, 0.3106939494609833, 0.9807966947555542, -0.7036441564559937, 0.0007168209413066506, -0.4137895703315735, 0.9736984968185425, -0.22629576921463013, 0.5081115365028381, -0.6415920257568359, 0.3147096335887909, 1.5500472784042358, 0.2518593668937683, 0.604353666305542, -0.6421191692352295, -0.30275848507881165, -0.9373264312744141, -0.36768513917922974, -0.8519765734672546, 0.08930680900812149, -0.5113850831985474, -1.2884730100631714, -1.107032299041748, -0.6123632192611694, 0.6498897671699524, -1.3107075691223145, 0.47437772154808044, -0.5746215581893921, 0.2916581332683563, 0.3162899613380432, 0.4023779630661011, 0.23906545341014862, 0.4812203347682953, 0.6297004818916321, -0.011464145965874195, 1.4974108934402466, -0.9121679663658142, -0.3800051510334015, -1.2459965944290161, -0.26686471700668335, 0.15964648127555847, -0.07577040046453476, -0.24005213379859924, -1.012538194656372, -1.4517544507980347, -0.7418572902679443, 0.0031545867677778006, -0.26113614439964294, 0.046922843903303146, 1.276352882385254, 0.17626063525676727, -1.2538414001464844, 0.5988351106643677, -0.2280743420124054, -0.48121175169944763, 0.6111177206039429, 0.15381883084774017, 0.35356733202934265, -0.3721250593662262, -0.5906187891960144, 0.11548333615064621, -0.2789267599582672, -0.03270871937274933, -0.38035017251968384, -0.2710600793361664, -1.3406676054000854, 0.08480957895517349, 0.10941630601882935, -1.0850119590759277, 1.1158063411712646, -0.3635120689868927, -0.9502084851264954, 0.8330817818641663, -0.6595214009284973, -0.22874368727207184, -0.07441084086894989, -0.1189543753862381, -0.10916338860988617, -0.27642422914505005, -0.25361642241477966, 0.7184032201766968, 1.143788456916809, -0.2331615835428238, -0.29115816950798035, -0.3109067976474762, -0.76253342628479, -0.3072231411933899, -0.1823500245809555, 0.785619854927063, -0.792990505695343, 0.09085311740636826, 0.7053409814834595, 0.3310190737247467, -0.31576311588287354, -0.4363321363925934, 0.22278055548667908, -1.2368618249893188, 0.6339257955551147, 0.13621854782104492, 0.18695466220378876, -0.9998964667320251, -0.8486955761909485, -0.07635839283466339, 0.17243635654449463, -0.18310759961605072, -1.0853261947631836, 0.36153504252433777, -0.4645916819572449, 0.19895097613334656, 0.15142177045345306, -1.0556209087371826, -0.15647631883621216, -0.011317512951791286, -1.1847679615020752, -0.01767921634018421, 0.4551515579223633, 1.3702003955841064, -0.7282941341400146, 0.10228999704122543, -0.014027166180312634, 0.38552433252334595, -0.5777760148048401, 1.2083936929702759, -0.3376464247703552, -0.08474259078502655, 0.19487294554710388, -0.22072434425354004, 0.08565700799226761, -0.5167996883392334, 0.7386289238929749, -0.5398397445678711, -0.06478491425514221, 0.19078482687473297, -0.0778871700167656, 0.9676846861839294, -0.2436506450176239, 0.8652909398078918, -0.3987424671649933, -0.8110582828521729, 0.618729829788208, 0.055415213108062744, -0.6121190190315247, -1.215909481048584, 0.2078348845243454, -0.08081933856010437, -0.8589760661125183, 0.5003980994224548, 0.8037027716636658, 0.9842747449874878, -0.267306923866272, -0.24309362471103668, 0.6802926659584045, -0.1793295294046402, 0.15655732154846191, 0.5671172142028809, 0.6448298692703247, 0.3104168772697449, 0.2085406631231308, 0.2030983418226242, 0.06370631605386734, -1.1186952590942383, 0.11850100010633469, 0.8952760696411133, 0.578324019908905, 1.090052843093872, 0.33718910813331604, -0.6782325506210327, -0.5878810286521912, 0.017816705629229546, 0.586990237236023, 1.1971601247787476, -0.21850848197937012, 0.08958762884140015, -0.3581746220588684, 0.17585930228233337, -0.8567324876785278, -0.5055542588233948, -0.2707216143608093, -0.14959126710891724, -0.3068346679210663, -0.7680150270462036, 0.6575896739959717, 0.5447937846183777, 1.215721845626831, -1.0733150243759155, -0.564261794090271, -0.726452648639679, 0.4067871570587158, -0.925343930721283, -0.2490740418434143, 0.28722167015075684, -0.6251645684242249, -0.10739748179912567, -0.21402467787265778, -0.40364208817481995, 0.11218006908893585, -0.17921043932437897, 0.8118623495101929, -0.2682848572731018, -0.5733649730682373, 0.6979255080223083, 0.6344811916351318, -0.713554322719574, -0.33586856722831726, -0.03851097449660301, 0.15995822846889496, -0.21461454033851624, 0.09552799165248871, 0.42548054456710815, -0.12644536793231964, -0.36439603567123413, -0.4308474063873291, -0.1510901153087616, 0.3662819266319275, 0.25921157002449036, 0.9983816146850586, -0.49144446849823, -0.10507669299840927, -0.8733738660812378, 0.56981360912323, 0.3386000990867615, -0.8044997453689575, 0.2095544934272766, -0.878775417804718, -0.1878139078617096, 0.19995732605457306, -0.5312233567237854, -0.2743968069553375, -0.48111212253570557, 0.5225560665130615, -1.046193242073059, -0.32237961888313293, -0.0654154121875763, 0.8584280014038086, 0.24067892134189606, 0.1567995548248291, 0.7554061412811279, 0.3922513425350189, 0.42193567752838135, 0.2670421898365021, -0.9849042892456055, 0.9933569431304932, 0.4849739670753479, 0.18190361559391022, -0.21039092540740967, 0.057772014290094376, -1.3534600734710693, -0.5230683088302612, -0.6610469818115234, -0.20274686813354492, -0.427184522151947, 0.16952210664749146, -0.7831839919090271, -1.240546703338623, 0.3049129843711853, -1.0496187210083008, -0.023738481104373932, -0.03294968232512474, -0.3361649513244629, -0.4281141757965088, -0.8237462043762207, -1.0966765880584717, -0.9698092341423035, -0.876755952835083, -0.5290504693984985, 0.3437800705432892, 0.8502953052520752, -0.08765649795532227, -0.283964604139328, 0.16418635845184326, -0.13640816509723663, 0.7623807191848755, -0.5628881454467773, 0.38190793991088867, 0.4123905599117279, -0.6329275369644165, 0.04547623172402382, -0.22003073990345, 0.5684572458267212, -0.5825729370117188, 0.27997514605522156, -1.2601546049118042, 0.30034899711608887, -0.4372738301753998, -0.45062607526779175, 0.8807753324508667, 0.6440932154655457, 0.30307358503341675, 0.3179909586906433, -0.3632957935333252, 0.45268476009368896, 1.6465132236480713, -0.6996666789054871, 0.8569139838218689, 0.13728883862495422, 0.9520276188850403, 0.0675431340932846, -0.5190717577934265, 0.3332937955856323, 0.3239934742450714, 0.08515077084302902, 0.47421085834503174, -0.45911210775375366, -0.3802458643913269, -0.7765393853187561, 0.3212345838546753, 1.3384300470352173, 0.12907429039478302, -0.017740095034241676, -0.760350227355957, 0.7918457388877869, -1.1829280853271484, -0.9850836992263794, 0.4936743974685669, 0.584939181804657, -0.19777244329452515, -0.5156444907188416, -0.27590814232826233, -0.49807557463645935, 0.5285876989364624, 0.6406692266464233, -0.5665463209152222, -0.7485116124153137, -0.16063615679740906, 0.7796053290367126, 0.377564013004303, 0.3230496942996979, -0.25261878967285156, 0.7633668184280396, 14.698016166687012, 0.40990328788757324, -0.15813472867012024, 0.2909187376499176, 0.5676065683364868, 0.7180817723274231, -0.28321224451065063, 0.12019432336091995, -1.3442155122756958, -0.6996128559112549, 1.140143871307373, 0.6411123871803284, 0.35973381996154785, 0.14449289441108704, -0.43551239371299744, 0.18683987855911255, -0.19169151782989502, 0.9313094615936279, 0.8830262422561646, -1.2108370065689087, 0.4518221318721771, 0.1708683967590332, 0.30311769247055054, 0.8124836087226868, 1.1566249132156372, 0.8782448768615723, 0.4106292724609375, -0.3468810021877289, 0.2691729664802551, 0.6277274489402771, 0.7651750445365906, 0.14061099290847778, 0.2049647569656372, 0.17147880792617798, -0.9485105872154236, -0.11263346672058105, -0.8104819059371948, -0.8910550475120544, -0.22320765256881714, -0.4195633828639984, -0.2395137995481491, -0.32940706610679626, 0.05380817502737045, 0.8410080075263977, -0.1089014858007431, 0.2534933090209961, -0.197173073887825, 0.4950628876686096, 0.020982570946216583, 0.14389871060848236, 0.23376387357711792, 0.3153987526893616, -0.0010630660690367222, -0.09388482570648193, -0.18448470532894135, 0.14787159860134125, -0.0459662601351738, 0.45316341519355774, -0.6166293621063232, -0.448478102684021, -0.5382373332977295, -0.21370640397071838, -0.5148319602012634, 0.907716691493988, 0.15741223096847534, 0.3902806043624878, -0.06427118182182312, 0.48156797885894775, 0.6451576352119446, 0.22399435937404633, -0.25671160221099854, 0.18983030319213867, 0.17240838706493378, -0.6925885677337646, 0.6617920994758606, 0.3627814054489136, 0.04074200242757797, -0.5320096611976624, -0.6827009916305542, -0.318121999502182, 0.4220384657382965, -1.0964325666427612, -0.7277431488037109, 1.0481059551239014, -0.5578661561012268, 0.11037950962781906, 0.12201560288667679, -0.8599109053611755, -0.38252246379852295, 0.2810888886451721, -1.6382819414138794, -0.9378954768180847, 0.012004658579826355, 0.04892054200172424, -0.10692092031240463, -0.22133730351924896, 1.0362012386322021, -0.6273474097251892, -0.2959149181842804, -0.03564545884728432, -0.515426754951477, -0.11537563800811768, -0.6049008369445801, -0.44173330068588257, 0.6928414702415466, 0.6703462600708008, 0.40877199172973633, 0.16765645146369934, 0.08146246522665024, 0.4216957092285156, -1.0148985385894775, 0.15682648122310638, 0.6988459229469299, -0.576900839805603, -0.5070164799690247, -0.6368903517723083, -0.6741021871566772, 0.40521588921546936, 0.5107132196426392, -0.14199942350387573, -0.13297243416309357, 0.5198582410812378, -0.9042842388153076, -0.13455015420913696, -0.17431923747062683, 0.3035261034965515, 0.5458682775497437, -1.0659540891647339, -0.5068826079368591, -0.25540032982826233, 0.33024874329566956, -0.5813071727752686, -0.1282958835363388, -0.1470804661512375, 0.4216448664665222, -0.32117247581481934, 1.1988297700881958, -0.19635054469108582, 0.5524128675460815, 0.9515771269798279, -0.012820308096706867, -0.19279931485652924, -0.4038715958595276, -0.8999103903770447, 0.1426643431186676, 0.3025653660297394, 0.03479602932929993, -0.6567175984382629, 0.12065980583429337, 0.6157141923904419, 0.2762625217437744, -0.10118427127599716, -0.4215525984764099, -0.20691870152950287, -0.40551793575286865, -0.5421529412269592, -0.31163445115089417, -0.4346814453601837, -0.4949836730957031, 0.7039400935173035, 0.36820778250694275, 0.7648041844367981, 0.16668693721294403, -0.4430520534515381, 0.322829008102417, -0.3677726984024048, -0.020510980859398842, -0.4157039523124695, -0.6625039577484131, -1.4417892694473267, 0.07459131628274918, -0.9617432355880737, -0.04455465078353882, -1.046520709991455, -0.31484314799308777, 0.20518234372138977, -0.43285584449768066, -0.005148814991116524, 0.5034875273704529, -0.1413392573595047, -0.12240882962942123, -0.23875930905342102, -0.8385028839111328, 0.8709498643875122, 0.7951476573944092, -0.6527251601219177, -0.012621420435607433, -0.18055623769760132, -0.24754299223423004, 0.26471737027168274, 0.2924477159976959, -0.28892526030540466, -0.8620784878730774, -0.9128454923629761, 0.15777508914470673, 0.05893215164542198, 0.3829977512359619, -1.0437511205673218, 1.0372990369796753, 0.743199348449707, 0.08335462212562561, -0.21920296549797058, 0.532834529876709, -0.7524085640907288, -0.38856738805770874, 0.3997369706630707, -0.6805749535560608, 0.19841992855072021, 0.3041574954986572, -0.11702703684568405, -0.05206619203090668, 0.6995732188224792, 0.03761759400367737, -0.9506397247314453, -1.2355170249938965, 0.5852697491645813, -0.6161823272705078, 0.051687877625226974, -0.4657706320285797, -0.28267160058021545, -1.2432239055633545, -0.12818127870559692, 0.028025763109326363, 0.2958495616912842, -0.5049741864204407, 0.9928620457649231, 1.244165062904358, -0.6567601561546326, 0.0039867982268333435, 0.5678019523620605, -0.13234789669513702, 0.12826330959796906, 0.820447564125061, 0.2645833492279053, 0.032279402017593384, 0.5294252038002014, -0.03077731654047966, -0.01024438813328743, -1.1008691787719727, 0.40827634930610657, 0.8634417057037354, -0.5639856457710266, -0.49966543912887573, 0.7372829914093018, 0.10332991182804108, -0.663058876991272, -0.08732399344444275, -0.7624980211257935, -0.9196608066558838, -0.13311578333377838, 0.3823045790195465, -0.15125033259391785, -0.3663238286972046, -0.029224172234535217, -0.3504392206668854, 0.45651775598526, -0.4310891628265381, -0.4667600989341736, 0.6756150722503662, -0.034213222563266754, -0.17621253430843353, 0.31081336736679077, 0.49337565898895264, -1.1261825561523438, -1.0169235467910767, -1.1808853149414062, -0.43905940651893616, 0.011923501268029213, 0.5181211829185486, 0.18168917298316956, -0.6739874482154846, 0.5837293863296509, 0.8885988593101501, 0.09978988766670227, 0.33193692564964294, 0.11534108966588974, -0.008654912933707237, 0.6463891267776489, -0.25718992948532104, -0.5655222535133362, -0.13155479729175568, 1.602707028388977, 1.4098304510116577, -0.5302414298057556, 0.23831477761268616, -0.4014904499053955, -0.9092288017272949, 0.5517444610595703, 0.14776542782783508, -0.8033693432807922, 0.5470073223114014, -0.36889922618865967, 0.03999192640185356, -0.20140478014945984, -1.147363543510437, -0.7418258786201477, 0.8379778861999512, 1.5832659006118774, 0.45358580350875854, -0.1545996516942978, 0.5904111862182617, 0.5865742564201355, 0.258743017911911, 0.09812363237142563, 0.393303781747818, 0.26815253496170044, 0.038493379950523376, 0.4158484935760498, 0.03061150386929512, 0.38360023498535156, -0.3988146185874939, -0.7673144936561584, 0.33706721663475037, 0.5303513407707214, -0.21844910085201263, 0.659027636051178, 1.318877100944519, 0.4022548794746399, 0.8299939036369324, -0.02029351145029068, 0.8292600512504578, -0.1659344583749771, -0.3052404522895813, 0.15796013176441193, -1.0674939155578613, -0.02693941257894039, -0.5047701597213745, -0.8956928253173828, -0.2833479940891266, 0.052795205265283585, 0.40648502111434937, -0.4180513024330139, 0.37460383772850037, 0.7992686629295349, 0.5934512615203857, 0.7698872089385986, -0.21489262580871582, -0.42041051387786865, -0.5060457587242126, -0.6336348056793213, 0.022064300253987312, -0.490185409784317, -0.001001742435619235, -0.10304292291402817, -0.06753528118133545, -0.06049516797065735]}, "authors": [{"authorId": "31374559", "name": "Ali Hatamizadeh"}, {"authorId": "2264261159", "name": "Michael Ranzinger"}, {"authorId": "2248128248", "name": "Jan Kautz"}], "references": [{"paperId": "240103933ffe3dac2179cc160a2bd91299357a53", "title": "Retentive Network: A Successor to Transformer for Large Language Models"}, {"paperId": "b94e95d76001a1273303f11c6cd429d17f626b9b", "title": "FasterViT: Fast Vision Transformers with Hierarchical Attention"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "9575afb5702bc33d7df14c48feeee5901ea00369", "title": "A Length-Extrapolatable Transformer"}, {"paperId": "86609b3567c1f039aecd87cc87ef8b8a995215bc", "title": "Global Context Vision Transformers"}, {"paperId": "dd1139cfc609c2f3263d02e97176d5275caebc0a", "title": "EfficientFormer: Vision Transformers at MobileNet Speed"}, {"paperId": "b4da9f3505e22d3e766ba21890285b822dc71599", "title": "EdgeViTs: Competing Light-weight CNNs on Mobile Devices with Vision Transformers"}, {"paperId": "2ad12a7be5eaf339a98c4defd8669e11fe726acc", "title": "MaxViT: Multi-Axis Vision Transformer"}, {"paperId": "7c597874535c1537d7ddff3b3723015b4dc79d30", "title": "MaskGIT: Masked Generative Image Transformer"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "f454f6b5f2ca9749ddf442eb5134612ef7f758c1", "title": "ResNet strikes back: An improved training procedure in timm"}, {"paperId": "7fff8018bf625447df837c2fda5c58a705fbc038", "title": "XCiT: Cross-Covariance Image Transformers"}, {"paperId": "ae8dceba0700cb85293666f712b5cdaf483d5053", "title": "The Image Local Autoregressive Transformer"}, {"paperId": "d5e999aae76d5270ef272076979c809817458212", "title": "An Attention Free Transformer"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "8d3ddc27dce9c6c0fe110e4f9cb45d3b59feb04b", "title": "Visformer: The Vision-friendly Transformer"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "5b68522f58b61e7235b852677337ef3725075fd9", "title": "Co-Scale Conv-Attentional Image Transformers"}, {"paperId": "003326a15fc4a8833785a47a741d7712474fa256", "title": "LeViT: a Vision Transformer in ConvNet\u2019s Clothing for Faster Inference"}, {"paperId": "8f8f73f0f208302546c825ed474432389ed63be4", "title": "EfficientNetV2: Smaller Models and Faster Training"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "0eff37167876356da2163b2e396df2719adf7de9", "title": "CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "63812f583caac3ac32bbfb64f66ba69e57c1e90a", "title": "Conditional Positional Encodings for Vision Transformers"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "80d8d820113062b371475b762e195e8629f608fd", "title": "Design and Implementation of an Approximate Softmax Layer for Deep Neural Networks"}, {"paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8", "title": "Generative Pretraining From Pixels"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "bc789aef715498e79a74f857fa090ece9e383bf1", "title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "d1c424c261c577958917055f72fb9e2ad0348865", "title": "PixelSNAIL: An Improved Autoregressive Generative Model"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "9ec499af9b85f30bdbdd6cdfbb07d484808c526a", "title": "Efficient softmax approximation for GPUs"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "0936352b78a52bc5d2b5e3f04233efc56664af51", "title": "Conditional Image Generation with PixelCNN Decoders"}, {"paperId": "41f1d50c85d3180476c4c7b3eea121278b0d8474", "title": "Pixel Recurrent Neural Networks"}, {"paperId": "a7976c2bacfbb194ddbe7fd10c2e50a545cf4081", "title": "LSTM: A Search Space Odyssey"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "c68796f833a7151f0a63d1d1608dc902b4fdc9b6", "title": "GENERATIVE ADVERSARIAL NETS"}]}