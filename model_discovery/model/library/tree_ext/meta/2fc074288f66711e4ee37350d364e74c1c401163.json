{"paperId": "2fc074288f66711e4ee37350d364e74c1c401163", "title": "Recursion in Recursion: Two-Level Nested Recursion for Length Generalization with Scalability", "abstract": "Binary Balanced Tree RvNNs (BBT-RvNNs) enforce sequence composition according to a preset balanced binary tree structure. Thus, their non-linear recursion depth is just $\\log_2 n$ ($n$ being the sequence length). Such logarithmic scaling makes BBT-RvNNs efficient and scalable on long sequence tasks such as Long Range Arena (LRA). However, such computational efficiency comes at a cost because BBT-RvNNs cannot solve simple arithmetic tasks like ListOps. On the flip side, RvNNs (e.g., Beam Tree RvNN) that do succeed on ListOps (and other structure-sensitive tasks like formal logical inference) are generally several times more expensive than even RNNs. In this paper, we introduce a novel framework -- Recursion in Recursion (RIR) to strike a balance between the two sides - getting some of the benefits from both worlds. In RIR, we use a form of two-level nested recursion - where the outer recursion is a $k$-ary balanced tree model with another recursive model (inner recursion) implementing its cell function. For the inner recursion, we choose Beam Tree RvNNs (BT-RvNN). To adjust BT-RvNNs within RIR we also propose a novel strategy of beam alignment. Overall, this entails that the total recursive depth in RIR is upper-bounded by $k \\log_k n$. Our best RIR-based model is the first model that demonstrates high ($\\geq 90\\%$) length-generalization performance on ListOps while at the same time being scalable enough to be trainable on long sequence inputs from LRA. Moreover, in terms of accuracy in the LRA language tasks, it performs competitively with Structured State Space Models (SSMs) without any special initialization - outperforming Transformers by a large margin. On the other hand, while SSMs can marginally outperform RIR on LRA, they (SSMs) fail to length-generalize on ListOps. Our code is available at: \\url{https://github.com/JRC1995/BeamRecursionFamily/}.", "venue": "Neural Information Processing Systems", "year": 2023, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The best RIR-based model is the first model that demonstrates high length-generalization performance on ListOps while at the same time being scalable enough to be trainable on long sequence inputs from LRA."}, "embedding": {"model": "specter_v2", "vector": [0.429889440536499, 0.3780757486820221, -0.23865783214569092, -0.49869492650032043, -0.008004463277757168, -0.6890147924423218, 0.07159406691789627, -0.2613023817539215, -0.6283995509147644, 0.45109668374061584, 0.1888519823551178, -0.721403956413269, -0.09965042024850845, -0.11694600433111191, -0.3090181350708008, -0.26789364218711853, -1.0011416673660278, 0.15118403732776642, 0.11383169144392014, -0.4647393524646759, 0.022248322144150734, -0.08083593845367432, -1.126680850982666, 0.014319173991680145, -0.04887697473168373, 0.5846893191337585, -0.3016473352909088, 0.7645813226699829, -0.5415351390838623, 0.7338247895240784, 0.6010246872901917, -0.6681064367294312, 0.3257633149623871, -0.06648557633161545, -0.60868901014328, -0.6411698460578918, 0.7498703598976135, -0.26972150802612305, -0.5448029041290283, 0.6364505887031555, -0.2856884300708771, 0.1641220599412918, 0.21138983964920044, -0.6940657496452332, 0.2714468836784363, 1.3307366371154785, 0.5489500164985657, 0.7197707295417786, -0.40845784544944763, -0.3838765025138855, 1.7283614873886108, -0.6041562557220459, 0.3037554919719696, 1.1969363689422607, 0.7622120380401611, 0.9933932423591614, -0.6088899970054626, -0.9721457362174988, 0.4288422763347626, 0.12432456761598587, -0.6495332717895508, -0.2999928295612335, -0.27962058782577515, -0.04763197526335716, 1.6200721263885498, -0.0913248062133789, -0.021953487768769264, 0.16338412463665009, -0.15868470072746277, 0.8408538699150085, 0.19392280280590057, -0.34838613867759705, 0.022340912371873856, -0.27886730432510376, 0.7439193725585938, 0.781524121761322, 0.0615018792450428, 0.5038481950759888, -1.0855101346969604, -0.21895034611225128, 0.6299582123756409, 0.030028903856873512, -0.028585845604538918, -0.5288813710212708, -0.422146201133728, 0.8281729221343994, 0.7514905333518982, 0.7545784115791321, -0.161056786775589, 1.1203855276107788, 0.5503092408180237, 0.30459946393966675, -0.6356256604194641, 0.7373688817024231, -0.39678627252578735, 0.4499914050102234, -0.6693238019943237, 0.5673948526382446, -0.16814865171909332, 0.5004682540893555, 0.1033121719956398, 0.5373724699020386, -0.28657102584838867, -0.045809388160705566, 1.2407207489013672, -0.02677798829972744, 0.4343809485435486, -0.7952225804328918, 0.14607897400856018, 0.07603848725557327, 0.04910716414451599, -0.15154656767845154, -0.7204294204711914, -0.3579041361808777, -0.844839334487915, -0.6866929531097412, -0.15143446624279022, 0.259359747171402, -0.5769900679588318, 1.2002654075622559, -0.10280564427375793, 0.19083648920059204, 0.28393125534057617, 0.1885470598936081, 0.6113506555557251, 0.45670828223228455, 0.28710678219795227, -0.2899948060512543, 0.9589967131614685, -0.3607296645641327, -0.42519184947013855, -0.5235863924026489, 0.9366123676300049, 0.6733689904212952, -0.29280826449394226, -0.2587330937385559, -1.1960864067077637, -0.9096667170524597, -0.9815549850463867, 0.25236329436302185, -0.5453699231147766, -0.5447742938995361, 1.0672757625579834, 0.6423251032829285, -0.958981990814209, 0.6464413404464722, -0.06406565755605698, -0.19094310700893402, 0.3420213460922241, 0.5995317101478577, -0.06914562731981277, -0.09558521956205368, -1.0771310329437256, 0.21151793003082275, 0.6116557717323303, -0.15602535009384155, -0.24721179902553558, -0.5884645581245422, -1.031873345375061, 0.06391650438308716, 0.18817558884620667, -0.6134007573127747, 1.495450735092163, 0.8324820399284363, -1.0220134258270264, 0.6287133097648621, -0.21844512224197388, -0.4818786084651947, 0.03720107302069664, 0.1939479559659958, -0.29358524084091187, -0.756734311580658, -0.35083216428756714, 0.6847289204597473, -0.08663734048604965, -0.4378706216812134, -0.2777385711669922, -0.4832385182380676, 0.032677557319402695, -0.3339112401008606, 0.09433804452419281, 0.8001505136489868, 0.22771000862121582, 0.11699800938367844, 0.7384839057922363, 0.7216315865516663, -0.3547525405883789, -0.08555066585540771, -0.2751525640487671, -1.17713463306427, 0.2873131334781647, 0.3385799527168274, 1.4679056406021118, -0.7137060165405273, -0.48774686455726624, -0.3234407305717468, 0.18328817188739777, -0.24039465188980103, -0.3720143139362335, 0.5160839557647705, -0.39069321751594543, 0.613370954990387, -0.3990773856639862, -0.4032793641090393, -0.09202317148447037, 0.007726005278527737, -1.2387596368789673, -0.14505857229232788, -0.1868640035390854, 1.0344879627227783, -0.8464287519454956, 0.11862845718860626, -0.1041654646396637, -0.25230008363723755, -0.8043855428695679, 1.1557049751281738, -0.5436535477638245, 0.25071561336517334, -0.03883574903011322, -0.6036674976348877, -0.09076797962188721, -0.3308867812156677, 0.3970014452934265, -0.2164963185787201, -0.5931423306465149, 0.973747968673706, -0.6700102686882019, 1.4470140933990479, -0.10778182744979858, 0.26828113198280334, -0.0965183675289154, -0.542894721031189, 0.23768781125545502, 0.18078401684761047, -0.25889191031455994, -0.21174515783786774, 0.29962649941444397, 0.13080205023288727, 0.0339985229074955, 0.3008018732070923, 0.5161192417144775, 0.7952581644058228, -0.5679393410682678, 0.20362588763237, 0.3373444974422455, -0.4137413799762726, 0.7958388328552246, 0.2605572044849396, 0.7857346534729004, 0.48776882886886597, 0.6213879585266113, 0.2035752683877945, 0.608930766582489, -0.7078652381896973, 0.16078774631023407, 0.7494890689849854, 0.7142189741134644, 0.40964317321777344, 0.21445980668067932, -0.9438123106956482, -0.354092001914978, 0.13236361742019653, 0.17793980240821838, 1.6270397901535034, -0.00993778184056282, -0.4071417450904846, -0.8669378757476807, -0.20526011288166046, -0.5048467516899109, 0.5179891586303711, -0.44440633058547974, 0.21440643072128296, -0.8428727388381958, -0.6472682356834412, 1.4531619548797607, 0.5911633968353271, 1.2092546224594116, -0.7014576196670532, -0.8625896573066711, -0.45745420455932617, 0.5365626215934753, -0.6048465967178345, 0.1740991324186325, 0.638568639755249, -0.8299520015716553, -0.04159323498606682, 0.35787180066108704, -0.05025646090507507, -0.2500792145729065, -0.917270839214325, 0.5979323983192444, -0.5889372229576111, -0.3913762867450714, -0.3057883381843567, 1.2078542709350586, -0.526236891746521, -0.7081843018531799, 0.45208683609962463, -0.051278531551361084, -0.33953967690467834, 0.2333650141954422, 0.1291447877883911, 0.1222115159034729, 0.10993196070194244, -0.4307403564453125, 0.12549780309200287, -0.38415810465812683, 0.14994612336158752, 0.3822869062423706, -0.36260858178138733, -0.0048775202594697475, -1.1565531492233276, 0.46436506509780884, 0.6037984490394592, -1.070244550704956, 0.27627700567245483, -0.6697498559951782, 0.07272224128246307, 0.03499043732881546, -0.3736715614795685, 0.18415580689907074, -0.7876307964324951, 0.2644065022468567, 0.0772910788655281, -0.5517734289169312, 0.08539425581693649, 0.4393956959247589, 0.21917466819286346, 0.3965999186038971, 0.36446040868759155, 0.1116548627614975, 0.039179008454084396, 0.6468906998634338, -0.6451188921928406, 0.6629237532615662, 0.4184611737728119, 0.2984248995780945, -0.3855465352535248, 0.5671648383140564, -0.41506507992744446, -0.3519253730773926, -0.3095199465751648, 0.141966313123703, -0.1133703961968422, 0.10962817072868347, -0.35614249110221863, -1.43291175365448, 0.11264053732156754, -1.0265617370605469, -0.6210750937461853, 0.08996931463479996, -0.5213978290557861, -0.1320604383945465, -1.1695481538772583, -1.1799002885818481, -1.1615163087844849, -0.5463927388191223, -0.9111486673355103, 0.47123196721076965, 0.1760023534297943, -0.4712323546409607, -0.17670537531375885, 0.06534603238105774, -0.49297553300857544, 0.643961489200592, -0.362505167722702, 1.0070595741271973, -0.29666274785995483, -0.31880101561546326, 0.148903489112854, 0.10417976975440979, 0.00014881326933391392, -0.43791818618774414, -0.14419974386692047, -0.6324804425239563, 0.5949143767356873, -0.43210870027542114, -0.9039489030838013, 0.130306214094162, 0.19770438969135284, 0.9375434517860413, -0.19192089140415192, -0.4814699590206146, 0.4200168251991272, 1.320983648300171, -0.2989056706428528, 0.32267332077026367, 0.11555419862270355, 0.9433406591415405, 0.19602397084236145, -0.3557581901550293, 0.24793358147144318, -0.04905303567647934, 0.41487300395965576, 0.34051936864852905, 0.364203542470932, 0.1003602147102356, -0.3949965834617615, 0.24648211896419525, 0.8621028661727905, 0.1255914568901062, -0.010153810493648052, -0.8960247039794922, 0.27139386534690857, -1.1773536205291748, -1.1097207069396973, 0.613027036190033, 0.8588005900382996, 0.6934168338775635, -0.3733999729156494, 0.07572592794895172, 0.48968401551246643, 0.2944774627685547, 0.39404627680778503, -0.514158308506012, -0.8804546594619751, -0.14670783281326294, 0.3517654836177826, 0.365242600440979, 0.3915692865848541, -0.0069219195283949375, 0.36766645312309265, 15.116202354431152, 0.6364988684654236, -0.08619629591703415, 0.10422206670045853, 0.5514565706253052, 0.5723225474357605, -0.4614450931549072, -0.35615476965904236, -1.829478144645691, -0.3136785924434662, 1.068739652633667, 0.47791606187820435, 0.8383095860481262, 0.38457056879997253, -0.3998110890388489, 0.49825718998908997, -0.796255350112915, 0.7417219877243042, 0.22886274755001068, -1.526939034461975, 0.2209458351135254, 0.3759268820285797, 0.23851269483566284, 0.32078036665916443, 0.5354201793670654, 0.6878169178962708, 0.7025891542434692, -0.7982375621795654, 0.34865090250968933, -0.056832000613212585, 1.0585497617721558, 0.21150663495063782, 0.32449662685394287, 0.5575518012046814, -0.8855893611907959, -0.4538630545139313, -0.460913747549057, -1.2982221841812134, -0.05643950402736664, -0.3126857876777649, -0.6245243549346924, -0.45130783319473267, -0.02005082368850708, 0.5543442368507385, 0.7119934558868408, 0.5798587203025818, -0.4898298680782318, 0.7282856106758118, -0.1433456540107727, -0.33832260966300964, 0.09296440333127975, 0.2895733118057251, -0.04212959483265877, -0.24695298075675964, -0.13079793751239777, 0.16618624329566956, -0.06447848677635193, 0.4959995746612549, -0.5555301904678345, -0.3306950330734253, -0.4638497233390808, -0.27868515253067017, -0.06474609673023224, 0.7433195114135742, 0.6226791143417358, 0.5780594944953918, 0.16409526765346527, -0.23433592915534973, 0.7484419345855713, 0.2249739170074463, -0.4134182333946228, -0.1942901760339737, 0.4495229423046112, -0.6836972236633301, 0.26233503222465515, 0.47505566477775574, -0.7087195515632629, -0.33793437480926514, -1.039999008178711, -0.617328405380249, 0.5522238612174988, -0.829553484916687, -0.6239703893661499, 1.007627010345459, 0.006156104151159525, 0.06673896312713623, 0.32331719994544983, -0.9354102611541748, 0.013219448737800121, 0.2763252258300781, -0.9956831336021423, -0.643047571182251, 0.03913501650094986, -0.3488359749317169, -0.26881739497184753, 0.2434881329536438, 1.254759430885315, -0.3507619798183441, -0.7347574830055237, -0.10517694056034088, -0.1440700888633728, -0.024360045790672302, -0.6623273491859436, -1.0380516052246094, 0.636509895324707, 0.11530470848083496, 0.17493890225887299, 0.8203093409538269, -0.020142214372754097, 0.3485713005065918, -0.7139148116111755, -0.10542606562376022, 0.5513512492179871, -1.137731671333313, 0.023952696472406387, -0.9500411748886108, -0.619206428527832, 0.786557674407959, 0.41501662135124207, -0.3890668451786041, 0.15345720946788788, 0.27528294920921326, -0.9056698679924011, -0.4773085117340088, -0.6356911659240723, 0.3650068938732147, 1.1779870986938477, -0.43271195888519287, -0.647758960723877, -0.7081612348556519, 0.5203859806060791, -1.117794394493103, -0.6505106091499329, 0.4170886278152466, 0.4690098464488983, -0.10045914351940155, 0.8715125322341919, -1.0102289915084839, 0.623974621295929, 0.5094468593597412, -0.21973364055156708, -0.13802555203437805, -0.057909730821847916, -1.0300260782241821, -0.12730155885219574, 0.3962462842464447, 0.7642049789428711, -0.8937559127807617, 0.35958582162857056, 0.46627798676490784, 0.3372226357460022, -0.7284010052680969, -0.7412258982658386, -0.11087255924940109, -0.0184322502464056, -0.5828181505203247, 0.8327857255935669, -0.47456690669059753, -0.203335702419281, 0.5301613211631775, 0.576050877571106, 0.8867189884185791, -0.4643551707267761, -0.05342778190970421, 0.49963411688804626, -0.22087201476097107, 0.0346684604883194, -0.617034912109375, -0.9191246032714844, -1.47642982006073, 0.04687907174229622, -1.015084981918335, 0.2914479076862335, -1.0590060949325562, -0.31936028599739075, 0.028682244941592216, -0.3139991760253906, 0.1524028778076172, 0.6690834760665894, -0.36149096488952637, -0.8757433295249939, -0.7127650380134583, -0.5506556630134583, 0.3866516947746277, 0.22078338265419006, -0.5543158054351807, 0.3357183337211609, 0.31683552265167236, 0.11583026498556137, 0.07550140470266342, 0.4909687638282776, -0.5747911930084229, -0.8346009850502014, -0.8380287885665894, 0.6946133971214294, -0.10705230385065079, -0.08068405091762543, -0.8234467506408691, 0.6190580129623413, 0.24689945578575134, -0.32057520747184753, -0.34557825326919556, 0.29967713356018066, -0.9212692379951477, -0.2757580280303955, 0.519418478012085, -1.33333420753479, 0.07130373269319534, 0.28606337308883667, -0.5315248966217041, 0.20073994994163513, 0.3122507631778717, -0.3743634521961212, -0.5938733816146851, -0.4296981990337372, 0.34469205141067505, -0.7429154515266418, 0.25297191739082336, -0.522227942943573, -0.2671166956424713, -1.1955398321151733, 0.1328139305114746, 0.2583264410495758, 0.5123303532600403, -0.39857903122901917, 0.11286450177431107, -0.00029619786073453724, -0.780785858631134, 0.39436572790145874, 0.010037037543952465, 0.01862940564751625, 0.2212434560060501, 0.3214128315448761, 0.07983144372701645, -0.38489097356796265, 0.5378066301345825, 0.08368117362260818, 0.14076413214206696, -1.1771149635314941, -0.0650235190987587, 0.708491861820221, -0.6323844790458679, 0.0464869923889637, 1.0400689840316772, -0.04173736274242401, -1.4250047206878662, 0.5881158113479614, -1.416454553604126, -0.7549854516983032, -0.8078359365463257, 0.7019209265708923, 0.3259935975074768, -0.4281522333621979, 0.21415463089942932, -0.3944464921951294, 0.5520955324172974, 0.23105019330978394, -0.5947688221931458, 0.555865466594696, 0.13849228620529175, -0.6526430249214172, 0.9971766471862793, 0.2219705730676651, -0.4385990798473358, -0.3870621621608734, -0.548455536365509, -0.09104838222265244, 0.09081684052944183, -0.0560862235724926, -0.44230279326438904, -0.12654326856136322, 0.8552137613296509, 0.39290758967399597, 0.7603771686553955, 0.14016515016555786, -0.3318568766117096, 0.04885024577379227, 0.9356653690338135, 0.3857949376106262, 0.35130298137664795, -0.6465013027191162, 1.2134917974472046, 1.3532077074050903, -0.32043278217315674, 0.49225059151649475, -0.44502243399620056, -0.3285030722618103, 0.9666934013366699, 0.77668696641922, -0.03577985614538193, 0.2870258390903473, -0.12555290758609772, -0.007094928994774818, -0.12720225751399994, -0.8505687117576599, -0.41529738903045654, 0.4538344144821167, 0.79627925157547, 0.5771069526672363, -0.17807531356811523, 0.1439822018146515, 0.9431012868881226, -0.15418781340122223, 0.20316840708255768, 0.23604004085063934, 0.5830686688423157, -0.29893964529037476, 0.019045960158109665, 0.16603803634643555, 0.4042661488056183, -0.5616374611854553, -0.4398048222064972, 0.008202643133699894, 0.8007113933563232, 0.3516048491001129, 0.5390295386314392, 0.7272690534591675, 0.03590435907244682, 0.3497738242149353, 0.42137476801872253, 0.664871871471405, -0.31569066643714905, -0.5917364954948425, -0.4916650950908661, -0.40304166078567505, -0.32487061619758606, -0.2627897262573242, -0.43539053201675415, -0.6421358585357666, -0.05105800926685333, -0.05668693408370018, 0.25761324167251587, 0.4567803144454956, 0.7798453569412231, 0.5003854036331177, 0.5541647672653198, -0.3768378496170044, -0.1386192888021469, -0.9067802429199219, -0.7182201147079468, 0.26968497037887573, -0.8097545504570007, -0.23377519845962524, -0.004058049526065588, -0.1619206666946411, -0.42742928862571716]}, "authors": [{"authorId": "123467107", "name": "Jishnu Ray Chowdhury"}, {"authorId": "2140493460", "name": "Cornelia Caragea"}], "references": [{"paperId": "9e3e56957e249cdebdd8673fd1174980ed694560", "title": "Efficient Beam Tree Recursion"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "d40dbe668d5b68419e934dfa4c5851ffa1c24aa2", "title": "Exposing Attention Glitches with Flip-Flop Language Modeling"}, {"paperId": "526706ca6db9800d103bf87b104e98bc4ae4feed", "title": "Beam Tree Recursive Cells"}, {"paperId": "465ec2212d865e875e64638b3dd1ecaac21c5ddd", "title": "Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation"}, {"paperId": "6b655b74da908e2e0d7c37996d36d5ff4a28f030", "title": "Sequence Modeling with Multiresolution Convolutional Memory"}, {"paperId": "f393aff1593c2d370ec0ae004910d18e40524967", "title": "Resurrecting Recurrent Neural Networks for Long Sequences"}, {"paperId": "54155c2977a977bf129849455dcae3a2b79b3f41", "title": "Simple Hardware-Efficient Long Convolutions for Sequence Modeling"}, {"paperId": "240300b1da360f22bf0b82c6817eacebba6deed4", "title": "What Makes Convolutional Models Great on Long Sequence Modeling?"}, {"paperId": "9166caa474031b62bacad8a920db8308e6a15120", "title": "An Exploration of Hierarchical Attention Transformers for Efficient Long Document Classification"}, {"paperId": "b40f0b0465cdf4b487fb2ef85d4e2672c4b623cc", "title": "Liquid Structural State-Space Models"}, {"paperId": "70e91e16eb321067d9402710e14a40cf28311f73", "title": "Mega: Moving Average Equipped Gated Attention"}, {"paperId": "6d7d141c75af752ffc0d8a6184cca3f9323d6c74", "title": "Simplified State Space Layers for Sequence Modeling"}, {"paperId": "a8cf0f7a20f886acfb332071c2daaf58ba86a5ca", "title": "Recurrent Memory Transformer"}, {"paperId": "a30ac45ac5b7bd2148d3fb80ee7f3c29724e3170", "title": "How to Train Your HiPPO: State Space Models with Generalized Orthogonal Basis Projections"}, {"paperId": "ca444821352a4bd91884413d8070446e2960715a", "title": "On the Parameterization and Initialization of Diagonal State Space Models"}, {"paperId": "2fc384087f55111a196c96d88029aab324aa543e", "title": "ChordMixer: A Scalable Neural Attention Model for Sequences with Different Lengths"}, {"paperId": "d6a0dfd5f39222d8924b7727a0a49f81fa247d71", "title": "Temporal Latent Bottleneck: Synthesis of Fast and Slow Processing Mechanisms in Sequence Learning"}, {"paperId": "71e15a9a52dcafca57bff5f310b95e2c7d0cfc87", "title": "Diagonal State Spaces are as Effective as Structured State Spaces"}, {"paperId": "736eb449526fe7128917954ec5532b59e318ec78", "title": "Block-Recurrent Transformers"}, {"paperId": "dc85180153687539724d20a5927b2fbdf5f8e2a4", "title": "Fast-R2D2: A Pretrained Recursive Neural Network based on Pruned CKY for Grammar Induction and Text Representation"}, {"paperId": "3c6ec875050ad4d2319725697d74154f66ced597", "title": "Hierarchical Perceiver"}, {"paperId": "dc0102a51a9d33e104a4a3808a18cf17f057228c", "title": "Transformer Quality in Linear Time"}, {"paperId": "70a10d95e968158c2a862af217186c74c44b5e25", "title": "Sliced Recursive Transformer"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "231e768f0cd280faa0f725bb353262cb4fed08d1", "title": "Hierarchical Transformers Are More Efficient Language Models"}, {"paperId": "1a22e6406e67c1737ec073cc646f60cb78631a4c", "title": "Learning Hierarchical Structures with Differentiable Nondeterministic Stacks"}, {"paperId": "dbf53ece1a6a8860e41ff5f721c72ceb0fb18dd6", "title": "H-Transformer-1D: Fast One-Dimensional Hierarchical Attention for Sequences"}, {"paperId": "5d032bd2632b6f5847767f39ce247098c6bbc563", "title": "Combiner: Full Attention Transformer with Sparse Computation Cost"}, {"paperId": "dab75d54f477c39529f2a88ae8ab26a1ea5bdb31", "title": "R2D2: Recursive Transformer based on Differentiable Tree for Interpretable Hierarchical Language Modeling"}, {"paperId": "db016d2b6d2577c47d62f9de2a7d1ddbf226386a", "title": "Modeling Hierarchical Structures with Continuous Recursive Neural Networks"}, {"paperId": "b50815251c948f00baedccaf5f56c281ffa7650f", "title": "Staircase Attention for Recurrent Processing of Sequences"}, {"paperId": "84daddd294fa3cc12596b5785f81c2a153d2fb1d", "title": "Hi-Transformer: Hierarchical Interactive Transformer for Efficient and Effective Long Document Modeling"}, {"paperId": "f80775a79d42a1ddfc0df808ea760c57af4949d0", "title": "Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding"}, {"paperId": "d969066d1dff7203055a493daaa3af8c490bf58e", "title": "Recognizing and Verifying Mathematical Equations using Multiplicative Differential Neural Units"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "79b4ec1aaf67a04a9afa0d8138f84b7be66c00cb", "title": "Do Transformer Modifications Transfer Across Implementations and Applications?"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "4bc9d6596069c9277b57a7ee1e1127d231f28663", "title": "Unsupervised Parsing with S-DIORA: Single Tree Encoding for Deep Inside-Outside Recursive Autoencoders"}, {"paperId": "a113053b624b599b204fbd6599284b726c17f916", "title": "ConjNLI: Natural Language Inference over Conjunctive Sentences"}, {"paperId": "5262a59603b816eb3a339da937170e2b134a139f", "title": "Compositional Generalization with Tree Stack Memory Units."}, {"paperId": "869e7b3409d2fdb87aee7cd1a1f2246e5a271e3d", "title": "Learning Context-free Languages with Nondeterministic Stack RNNs"}, {"paperId": "4ca3b0ea12f02e2dea01a4aa505956bae5500a09", "title": "Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing"}, {"paperId": "3f9514630194a9fba9505b594ec921b247fecb48", "title": "Evaluating Models\u2019 Local Decision Boundaries via Contrast Sets"}, {"paperId": "287e85aca777d6d3d73e1484ba9c0f09d40f578a", "title": "Ordered Memory"}, {"paperId": "47f1eb0dc42189ba7cf21b76598c8217eb1b6e05", "title": "Learning the Difference that Makes a Difference with Counterfactually-Augmented Data"}, {"paperId": "b3564be8b79f25585acb035f3deaf4ae93c26d8f", "title": "Theoretical Limitations of Self-Attention in Neural Sequence Models"}, {"paperId": "7cc730da554003dda77796d2cb4f06da5dfd5592", "title": "Hierarchical Transformers for Multi-Document Summarization"}, {"paperId": "0053f75b7053f43b9787a9955426281e672b147b", "title": "Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders"}, {"paperId": "fc09d6486be1c9bbfbef4165ce3c1ab664e5d084", "title": "PAWS: Paraphrase Adversaries from Word Scrambling"}, {"paperId": "b462bd9e3c4c991722b77fe696fda0a0372bf6dd", "title": "Stochastic Beams and Where to Find Them: The Gumbel-Top-k Trick for Sampling Sequences Without Replacement"}, {"paperId": "b0e2fe0fe9f4fc4ce05d5f637baff96a7e966c01", "title": "Cooperative Learning of Disjoint Syntax and Semantics"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "528a97b59f3d26ffe4549051ca5cf77cfdd5c559", "title": "On Tree-Based Neural Sentence Modeling"}, {"paperId": "eefbe0d29fa9955caffc51777991cefbdbbaabab", "title": "Sliced Recurrent Neural Networks"}, {"paperId": "a308e67ad08f29c7bcfeef9e7a20f72453e31678", "title": "Latent Tree Learning with Differentiable Parsers: Shift-Reduce Parsing and Chart Parsing"}, {"paperId": "175b58fe7e49bb5c0c771b73f8834bcff21b59c7", "title": "Stress Test Evaluation for Natural Language Inference"}, {"paperId": "e77099681374e940ea45821fd7e406394721552f", "title": "Stable Recurrent Models"}, {"paperId": "321f91528af535cefa1b6971df31c609673f463f", "title": "Backpropagating through Structured Argmax using a SPIGOT"}, {"paperId": "413a03a146e6f7b16c11e73243d83e6f1a6627a3", "title": "Breaking NLI Systems with Sentences that Require Simple Lexical Inferences"}, {"paperId": "0ef460c47377c3b9482d8177cbcafad1730a91a5", "title": "Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling"}, {"paperId": "8b354d76813bd5375e7e5c8d17f630bec5936a01", "title": "ListOps: A Diagnostic Dataset for Latent Tree Learning"}, {"paperId": "997c55547aeca733dfc5dfebd12412612ecba022", "title": "The Importance of Being Recurrent for Modeling Hierarchical Structure"}, {"paperId": "2997b26ffb8c291ce478bd8a6e47979d5a55c466", "title": "Annotation Artifacts in Natural Language Inference Data"}, {"paperId": "921196c32213a229245a9705ee4768bc941e7a26", "title": "An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling"}, {"paperId": "fdfa7dc73dc1fc6772d26f88c72e98b68d1f8498", "title": "Parallelizing Linear Recurrent Neural Nets Over Sequence Length"}, {"paperId": "1a0365567850837931d04126714ae6e2cbfc6270", "title": "Deep Learning for Extreme Multi-label Text Classification"}, {"paperId": "027f9695189355d18ec6be8e48f3d23ea25db35d", "title": "Learning to Compose Task-Specific Tree Structures"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "07c4fc48ad7b7d1a417b0bb72d0ae2d4efc5aa83", "title": "Depthwise Separable Convolutions for Neural Machine Translation"}, {"paperId": "3096b9e5b17dedbee9554fbd1d6e20f7a095e48a", "title": "Jointly learning sentence embeddings and syntax with unsupervised Tree-LSTMs"}, {"paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0", "title": "Convolutional Sequence to Sequence Learning"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "a9df777e4d8100e52e90fa4bd2d783d25a2fd173", "title": "Bilateral Multi-Perspective Matching for Natural Language Sentences"}, {"paperId": "88caa4a0253a8b0076176745ebc072864eab66e1", "title": "Language Modeling with Gated Convolutional Networks"}, {"paperId": "599f7863721d542dcef2da49b41d82b21e4f80b3", "title": "Learning to Compose Words into Sentences with Reinforcement Learning"}, {"paperId": "29e944711a354c396fad71936f536e83025b6ce0", "title": "Categorical Reparameterization with Gumbel-Softmax"}, {"paperId": "515a21e90117941150923e559729c59f5fdade1c", "title": "The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables"}, {"paperId": "705dcc8eadba137834e4b0359e2d696d4b209f5b", "title": "Neural Tree Indexers for Text Understanding"}, {"paperId": "455afd748e8834ef521e4b67c7c056d3c33429e2", "title": "Hierarchical Attention Networks for Document Classification"}, {"paperId": "831cfd0c5120f84a857b90f17ac761339fad0dd9", "title": "DAG-Structured Long Short-Term Memory for Semantic Compositionality"}, {"paperId": "36c097a225a95735271960e2b63a2cb9e98bff83", "title": "A Fast Unified Model for Parsing and Sentence Understanding"}, {"paperId": "e850595c3c2e4cbc3d7c3dd9fa5277d4ca77323e", "title": "The Forest Convolutional Network: Compositional Distributional Semantics with a Neural Chart and without Binarization"}, {"paperId": "f04df4e20a18358ea2f689b4c129781628ef7fc1", "title": "A large annotated corpus for learning natural language inference"}, {"paperId": "b3e11af71552d39070dd9183acb8b8171bc22b38", "title": "A Hierarchical Recurrent Encoder-Decoder for Generative Context-Aware Query Suggestion"}, {"paperId": "1f600f213dbbd70f06093438855f39022957b4bf", "title": "Long Short-Term Memory Over Recursive Structures"}, {"paperId": "04d1a26c2516dc14a765112a63ec60dc3cb3de72", "title": "Tree-Structured Composition in Neural Networks without Tree-Structured Architectures"}, {"paperId": "1492ddfd4f4b152b83f11db8c9ecdfd0d2543294", "title": "Compositional Distributional Semantics with Long Short Term Memory"}, {"paperId": "32de44f01a96d4473d21099d15e25bc2b9f08e2f", "title": "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks"}, {"paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5", "title": "GloVe: Global Vectors for Word Representation"}, {"paperId": "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba", "title": "Convolutional Neural Networks for Sentence Classification"}, {"paperId": "a129f612a9eff903d9133244a6f0914ef3cbda72", "title": "Semantic Parsing for Single-Relation Question Answering"}, {"paperId": "27725a2d2a8cee9bf9fffc6c2167017103aba0fa", "title": "A Convolutional Neural Network for Modelling Sentences"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "62c76ca0b2790c34e85ba1cce09d47be317c7235", "title": "Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation"}, {"paperId": "cfa2646776405d50533055ceb1b7f050e9014dcb", "title": "Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "3ce0f00d6c949192107f1bd6a167c03e1fb7393a", "title": "An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "d0be39ee052d246ae99c082a565aba25b811be2d", "title": "Learning long-term dependencies with gradient descent is difficult"}, {"paperId": "6a835df43fdc2f79126319f6fa033bb42147c6f6", "title": "Recursive Distributed Representations"}, {"paperId": "668087f0ae7ce1de6e0bd0965dbb480c08103260", "title": "Finding Structure in Time"}, {"paperId": "d08e4348d197e45871c133090ccd5ce76a4ae21b", "title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "81b3b3fe994a9eda6d3f9d2149aa4492d1933975", "title": "Learning Continuous Phrase Representations and Syntactic Parsing with Recursive Neural Networks"}, {"paperId": null, "title": "Learning task-dependent distributed representations by backpropagation through structure"}, {"paperId": "3f3d13e95c25a8f6a753e38dfce88885097cbd43", "title": "Untersuchungen zu dynamischen neuronalen Netzen"}]}