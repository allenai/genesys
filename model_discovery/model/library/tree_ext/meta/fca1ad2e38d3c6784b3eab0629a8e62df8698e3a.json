{"paperId": "fca1ad2e38d3c6784b3eab0629a8e62df8698e3a", "title": "A Multidimensional Communication Scheduling Method for Hybrid Parallel DNN Training", "abstract": "The transformer-based deep neural network (DNN) models have shown considerable success across diverse tasks, prompting widespread adoption of distributed training methods such as data parallelism and pipeline parallelism. With the increasing parameter number, hybrid parallel training becomes imperative to scale training. The primary bottleneck in scaling remains the communication overhead. The communication scheduling technique, emphasizing the overlap of communication with computation, has demonstrated its benefits in scaling. However, most existing works focus on data parallelism, overlooking the nuances of hybrid parallel training. In this paper, we propose TriRace, an efficient communication scheduling framework for accelerating communications in hybrid parallel training of asynchronous pipeline parallelism and data parallelism. To achieve effective computation-communication overlap, TriRace introduces 3D communication scheduling, which adeptly leverages data dependencies between communication and computations, efficiently scheduling AllReduce communication, sparse communication, and peer-to-peer communication in hybrid parallel training. To avoid possible communication contentions, TriRace also incorporates a topology-aware runtime which optimizes the execution of communication operations by considering ongoing communication operations and real-time network status. We have implemented a prototype of TriRace based on PyTorch and Pipedream-2BW, and conducted comprehensive evaluations with three representative baselines. Experimental results show that TriRace achieves up to 1.07\u20131.45\u00d7 speedup compared to the state-of-the-art pipeline parallelism training baseline Pipedream-2BW, and 1.24\u20131.81\u00d7 speedup compared to the Megatron.", "venue": "IEEE Transactions on Parallel and Distributed Systems", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "TriRace is proposed, an efficient communication scheduling framework for accelerating communications in hybrid parallel training of asynchronous pipeline parallelism and data parallelism, which adeptly leverages data dependencies between communication and computations, efficiently scheduling AllReduce communication, sparse communication, and peer-to-peer communication in hybrid parallel training."}, "embedding": {"model": "specter_v2", "vector": [0.11783629655838013, 0.16805638372898102, -0.3194740414619446, 0.26255548000335693, -0.31662479043006897, 0.2924904525279999, 0.8986519575119019, -0.17538835108280182, -0.718297004699707, -0.3034747838973999, 0.37987756729125977, -0.4670284688472748, 0.45490720868110657, -0.21726007759571075, -0.07924536615610123, -0.3393663167953491, -0.8491318821907043, 0.27444732189178467, 0.37223929166793823, -0.16226759552955627, -0.13459154963493347, 0.08163300901651382, -1.4152250289916992, 0.32126477360725403, 0.07208757102489471, 0.8165423274040222, -0.08936277776956558, 0.9238452911376953, -0.6318590641021729, 0.06160949543118477, 0.08403852581977844, 0.20474876463413239, 0.26696309447288513, 0.08693749457597733, -0.5972002148628235, 0.13147807121276855, 0.39226052165031433, -0.4587593376636505, -0.6726586818695068, 0.4919299781322479, 0.05818576365709305, 0.24092631042003632, -0.29091376066207886, -1.2270992994308472, 0.7106494903564453, 0.3422456681728363, 0.1204688623547554, 1.1005483865737915, -0.724867582321167, -0.6552627086639404, 0.5961117744445801, -1.3366442918777466, -0.1413562297821045, 1.0408486127853394, 0.5731752514839172, 0.1986532062292099, -0.5043061971664429, -0.7713499069213867, 0.16507872939109802, -0.29262229800224304, -0.4037673771381378, -0.32251396775245667, -0.04491959884762764, -0.20182302594184875, 1.5467381477355957, -0.09369540214538574, 0.2917051911354065, 0.6128178238868713, 0.21083760261535645, 0.8023523092269897, 0.10301763564348221, -0.5530408620834351, -0.06982345879077911, -0.3681909441947937, 0.5185523629188538, 0.15998831391334534, -0.23358415067195892, 0.4385581612586975, -1.355647325515747, -0.316301167011261, 0.4874349534511566, 0.5216595530509949, 0.26409006118774414, -0.10908568650484085, -0.2236921489238739, 0.3937619924545288, 0.4783939719200134, 0.37659719586372375, -0.6797136664390564, 0.6743488907814026, 0.969304084777832, 0.4525560438632965, 0.4042457044124603, -0.08133675158023834, 0.048819221556186676, 0.22742204368114471, -0.7916988730430603, 0.0024881165008991957, 0.4247915744781494, 0.8053556680679321, -0.3104204535484314, 0.014634829014539719, -0.6341461539268494, 0.1673860400915146, 0.8965320587158203, -0.14255613088607788, 0.2647843360900879, -0.531731903553009, 0.3869946300983429, -0.6614776253700256, -0.24167481064796448, -0.210673987865448, -0.26811090111732483, -0.23583322763442993, -1.0854077339172363, -0.5194258689880371, -0.6834141612052917, -0.14898739755153656, -0.7330412268638611, -0.01606058143079281, -0.1115369200706482, 0.6498010158538818, 0.33272454142570496, 0.40750569105148315, 0.8470407724380493, 0.7448036074638367, 0.27967992424964905, 0.19393323361873627, 1.0980322360992432, -1.5935267210006714, -0.18579792976379395, -0.5500651001930237, 0.32108163833618164, -0.47565093636512756, -0.20040889084339142, -0.4507169723510742, -1.5886634588241577, -0.7599179744720459, -0.653495192527771, 0.40895822644233704, -0.4033310115337372, -0.5298762917518616, 0.990955114364624, -0.05873662605881691, -1.433144450187683, 1.056618094444275, -0.6850519180297852, -0.5446209907531738, 0.40854066610336304, 0.6232293248176575, 0.3366921842098236, 0.10814791172742844, -1.0572397708892822, -0.08619089424610138, 0.1142701581120491, -0.6860623955726624, -0.5148158669471741, -0.7691181898117065, -0.08943969011306763, 0.1305292397737503, -0.23635926842689514, -0.784428060054779, 1.4059170484542847, -0.025191154330968857, -1.0059795379638672, 0.39633768796920776, 0.20360392332077026, -0.1815456748008728, 0.5179527997970581, 0.1060449630022049, -0.6768006086349487, 0.14993701875209808, -0.26094067096710205, 0.6053031086921692, 0.2701413929462433, 0.05706830695271492, -0.15580350160598755, 0.07800860702991486, -0.32370978593826294, 0.46853020787239075, -0.8015099763870239, 1.0592923164367676, -0.5079253911972046, -0.16429516673088074, 0.33638155460357666, 0.719465434551239, -0.31132972240448, 0.019487395882606506, -0.2517801821231842, -0.8060429692268372, 1.3121321201324463, 0.5597358345985413, 0.4891020953655243, -1.0758312940597534, -0.9747692346572876, 0.14890842139720917, 0.3724263310432434, 0.03133971989154816, -0.5887263417243958, 0.8890155553817749, -0.5399632453918457, 0.024627404287457466, 0.34115317463874817, -0.7276078462600708, -0.5422478318214417, -0.15370935201644897, -0.6466311812400818, -0.5548489689826965, -0.16145342588424683, 0.6709182858467102, -0.5537026524543762, 0.21769365668296814, -0.37929317355155945, 0.5034647583961487, -0.7420554757118225, 1.4029474258422852, -0.1939973086118698, 0.2538752853870392, 0.11618590354919434, -0.5035691857337952, 0.4796770215034485, -0.7329512238502502, 0.7289560437202454, -0.41638389229774475, -0.3037615716457367, 0.7604008913040161, -0.2498696744441986, 1.1451013088226318, -0.4413725435733795, 0.09438853710889816, 0.3224010467529297, -0.7851830124855042, 0.33296579122543335, 0.5512363910675049, 0.42264530062675476, -0.7970738410949707, 0.5569270849227905, 0.5196346640586853, -0.5688951015472412, 0.6814770102500916, 1.1242514848709106, 1.2283498048782349, -0.15026652812957764, 0.4968920946121216, 0.45347684621810913, 0.055150389671325684, 0.4708046019077301, 0.3997292220592499, 0.8785821199417114, -0.035517122596502304, -0.45929792523384094, -0.566257894039154, 0.023132914677262306, -0.779779314994812, -0.3917049169540405, 0.24343357980251312, 0.4028897285461426, 0.1945832371711731, 0.6582268476486206, -0.5762876272201538, -0.7027451395988464, -0.05158763751387596, 0.5509801506996155, 1.6173040866851807, 0.37438201904296875, 0.13634862005710602, -0.6557290554046631, -0.7030267119407654, -0.2395927459001541, -0.4980885684490204, 0.22577862441539764, 0.021339664235711098, -0.4047587215900421, -1.0179743766784668, 0.7785037159919739, 0.3995952308177948, 1.2617237567901611, -0.6078163385391235, -0.6323753595352173, -0.8003641366958618, 0.6993138790130615, -0.7858307361602783, -0.4417407810688019, 0.801143229007721, -0.9685187339782715, -0.14431458711624146, 0.0125820217654109, -0.3137311637401581, 0.3249911367893219, 0.3269248604774475, 1.3858317136764526, -0.27498680353164673, -0.11523180454969406, 0.09722891449928284, 0.6928108930587769, -0.5188559889793396, -0.6537737250328064, 0.3700052499771118, -0.08614803850650787, -0.4714365005493164, 0.256152480840683, -0.08014422655105591, -0.08233582228422165, 0.34280118346214294, -0.508503258228302, 0.35427385568618774, 0.17048150300979614, 0.0111070042476058, 0.7696229815483093, -0.43850278854370117, 0.08315347880125046, -1.2454743385314941, 1.1604092121124268, -0.3350157141685486, -0.3338758945465088, -0.0697685182094574, -0.5738824605941772, -0.28989213705062866, 0.37661054730415344, -0.7237212061882019, -0.20760641992092133, -1.2591626644134521, 0.30249977111816406, -0.7451225519180298, -0.3072132468223572, -0.3254603147506714, 0.796319842338562, -0.3198918104171753, 0.464085191488266, 0.3150356411933899, 0.8572582602500916, 0.17816314101219177, 0.20615296065807343, -0.6417926549911499, 0.24516141414642334, 0.03468110412359238, -0.09011482447385788, -0.15130698680877686, 0.06302302330732346, -0.7379242777824402, -0.10643057525157928, -0.37340104579925537, 0.005135600920766592, -0.23356284201145172, -0.07905393093824387, -0.6847392916679382, -1.0387914180755615, -0.033868685364723206, -1.2603204250335693, -0.32809603214263916, 0.1392376720905304, -0.0799851268529892, 0.18363124132156372, -1.2556771039962769, -1.523424506187439, -0.05436611548066139, -1.3468152284622192, -1.4088914394378662, 0.15272700786590576, 0.4158773720264435, -0.37631291151046753, -0.4838307499885559, -0.31395694613456726, -0.837871789932251, 1.1814560890197754, -0.4116818606853485, 0.44199949502944946, -0.33456116914749146, -0.14635126292705536, 0.17607371509075165, -0.6492047309875488, 0.2214512825012207, -0.9035918116569519, 0.20743992924690247, -0.5693982243537903, 0.19063009321689606, -0.5354894399642944, -0.46630552411079407, 0.1932930052280426, 0.11047988384962082, 1.2876664400100708, 0.22317001223564148, -0.6288136839866638, 0.5589953064918518, 1.1509877443313599, -0.6648401021957397, 0.06368666887283325, -0.05929696187376976, 0.8456763029098511, -0.07453698664903641, -0.590071976184845, 0.5424755811691284, 0.1604887843132019, 0.269260972738266, 0.40265214443206787, -0.7630952000617981, -0.4999437928199768, -0.09806657582521439, 0.0005231127142906189, 1.6695116758346558, 0.7310891151428223, -0.027929948642849922, -1.0249007940292358, 0.3549592196941376, -1.0813711881637573, -0.16801856458187103, 0.5352140665054321, 0.8307348489761353, 0.1939489245414734, -0.27040570974349976, 0.12235725671052933, -0.10015956312417984, 0.7415656447410583, 0.5970847606658936, -0.33655017614364624, -1.0762232542037964, 0.5692417621612549, 0.6997178196907043, 0.6199507117271423, 0.13584297895431519, -0.14751948416233063, 0.057401806116104126, 14.704887390136719, 0.7111703753471375, -0.28361228108406067, 0.6575398445129395, 0.617904543876648, 0.2973245680332184, -0.2988710105419159, -0.12164969742298126, -1.1884722709655762, 0.413563996553421, 1.9401565790176392, -0.004884549416601658, 0.4345647692680359, 0.1834414005279541, -0.3183106780052185, 0.019786806777119637, -0.38308119773864746, 0.6494658589363098, 0.3088265657424927, -1.5424902439117432, 0.25272008776664734, 0.29238608479499817, 0.5085365772247314, 0.9483152031898499, 0.45278072357177734, 0.35744544863700867, 0.722923219203949, -0.17138467729091644, -0.0033396899234503508, -0.03850127384066582, 1.2727130651474, -0.5709705352783203, 0.5648528933525085, 0.35496529936790466, -0.8257969617843628, 0.21949122846126556, -0.12533020973205566, -1.195763349533081, 0.029612993821501732, 0.453342080116272, -0.4381318986415863, -0.1506815254688263, -0.01570803113281727, 0.6572664380073547, 0.7373562455177307, 0.5208312273025513, 0.02701447159051895, 0.27932772040367126, -0.32796764373779297, 0.01996968314051628, -0.042197924107313156, 0.5114944577217102, -0.2277727723121643, 0.010544865392148495, -0.17922857403755188, -0.15538300573825836, 0.6432545781135559, 0.02658524364233017, -0.887412428855896, -0.4788071811199188, -0.40767303109169006, -0.18608932197093964, 0.2957642674446106, 0.9371089339256287, 0.3124874532222748, 0.2572633624076843, -0.8138739466667175, 0.3365006744861603, 0.5507675409317017, -0.1282568722963333, -0.4165402352809906, -0.25031498074531555, 0.5187299251556396, -0.4123024046421051, -0.42995119094848633, 0.36342763900756836, -0.7216557264328003, -0.016573725268244743, -1.1144747734069824, -0.09835390001535416, 0.3187752068042755, -0.5177390575408936, -0.7762202620506287, 1.243852138519287, -0.21171711385250092, -0.43081822991371155, 0.8421690464019775, -0.5192103385925293, -0.7233956456184387, 0.6636825799942017, -1.251196026802063, -0.31893953680992126, -0.24341736733913422, -0.16136665642261505, -0.6060348153114319, -0.01053385529667139, 1.2435718774795532, 0.5505916476249695, -0.585835874080658, -0.0033822027035057545, -0.31515684723854065, -0.23889511823654175, -0.09777188301086426, -0.31352874636650085, 1.1789116859436035, 0.24952132999897003, -0.3138599097728729, -0.43108290433883667, -0.16540057957172394, 0.39903903007507324, -0.7514941096305847, -0.39661484956741333, 0.5979164242744446, -0.0723857581615448, 0.12083570659160614, -0.5501390099525452, -0.7720264196395874, 0.1771467626094818, 0.7284639477729797, 0.23714393377304077, 0.5121085047721863, -0.05291590467095375, -0.5382297039031982, -0.360466331243515, -0.6098143458366394, 0.2460249960422516, 0.546819806098938, -0.6107770800590515, 0.17342643439769745, 0.19650724530220032, 0.8335222601890564, -1.5738093852996826, -0.9440141320228577, -0.2124902755022049, -0.22280538082122803, -0.1269272118806839, 1.0606073141098022, 0.056558020412921906, 1.09406578540802, 1.2209959030151367, 0.14821799099445343, -0.7690236568450928, 0.6147279739379883, -1.072185754776001, 0.19331856071949005, 0.015808813273906708, 0.26382723450660706, -0.6323214769363403, 0.719351589679718, 0.5238457322120667, 0.10792065411806107, -0.5379319190979004, -0.1460144966840744, 0.19221465289592743, -0.3289869427680969, -0.32128217816352844, 0.46587568521499634, -0.04379194229841232, -0.0779549852013588, 0.22843143343925476, 0.7681390047073364, 0.3895517587661743, -0.06596672534942627, -0.5392036437988281, 0.4085690975189209, -0.28364601731300354, 0.057302627712488174, -0.5536820292472839, -0.3962728977203369, -1.3632550239562988, 0.020931171253323555, -1.2696317434310913, -0.19460323452949524, -0.5685380697250366, -0.354356050491333, -0.3271888196468353, -0.32660597562789917, 0.09152007848024368, 0.6751244068145752, -0.055496834218502045, -0.598044753074646, -0.2470245361328125, -0.7210747599601746, 0.8631356954574585, 0.8914581537246704, 0.039751049131155014, -0.02560049295425415, -0.10960172861814499, 0.2272176742553711, 0.2208535522222519, 0.7892036437988281, -0.22597485780715942, -0.6603444814682007, -1.3280143737792969, -0.2906011939048767, 0.38586798310279846, 0.20291867852210999, -1.0811830759048462, 1.0628002882003784, 0.44642531871795654, -0.18624535202980042, -0.01803608052432537, 0.002262398600578308, -1.218156337738037, -0.36973506212234497, 0.3287126123905182, -0.6220590472221375, 0.5955079793930054, 0.5005511045455933, -0.4557700455188751, -0.11475247889757156, 1.5969310998916626, -0.06430929154157639, -0.32893821597099304, -0.7934635281562805, 0.6408311724662781, -0.3863917291164398, 0.22361505031585693, 0.33131542801856995, 0.016256963834166527, -1.59919273853302, 0.26766887307167053, -0.15821975469589233, 0.5729831457138062, -0.37749505043029785, 0.7047131657600403, 0.22955484688282013, -1.1729737520217896, 0.4946092367172241, 0.639545202255249, -0.730190098285675, 0.2648986279964447, 0.680214524269104, 1.2173746824264526, -0.5967432856559753, -0.03114566020667553, -0.3955353796482086, 0.05990058556199074, -1.1885268688201904, -0.22698751091957092, 0.7133539319038391, -0.3911587595939636, -0.38175731897354126, 0.9642900824546814, -0.5852214694023132, -1.136767864227295, 0.3751884698867798, -0.5449020862579346, -0.4610965847969055, -0.5095884799957275, 0.6413763761520386, 0.8908956050872803, 0.3376201391220093, 0.4777921438217163, -0.48427441716194153, -0.31076183915138245, -0.2166900932788849, -0.29975995421409607, 0.16786490380764008, 0.012328790500760078, -0.5673394203186035, 0.4427409768104553, 0.6021866798400879, -0.9239540696144104, -0.9712113738059998, -1.0265698432922363, -0.3375524878501892, -0.09092364460229874, 0.5068950653076172, -0.020241957157850266, -1.0264867544174194, 0.8366990685462952, 0.32210150361061096, 0.6445083618164062, 0.32409173250198364, -0.3311019241809845, 0.8232758045196533, -0.1014094278216362, 0.0554356649518013, -0.32837599515914917, -0.28546467423439026, 1.3398739099502563, 0.8404432535171509, -0.5403133034706116, 0.24710732698440552, -0.5600365996360779, -0.756260335445404, 1.0105383396148682, 0.6792340278625488, -0.2625114619731903, 1.0733453035354614, 0.4837358891963959, 0.09874790161848068, -0.06440375000238419, -1.0906158685684204, -0.05102779343724251, 0.09127992391586304, 0.5717645287513733, 0.6082750558853149, 0.38964664936065674, -0.20261043310165405, 0.31283050775527954, 0.4687005877494812, 0.030778395012021065, 0.11603357642889023, 0.7219745516777039, 0.16816121339797974, -0.2430080622434616, 0.09786781668663025, 0.550385594367981, -0.7470079660415649, -0.5255179405212402, 0.3274100124835968, 0.5660560727119446, -0.16200947761535645, 0.6086708307266235, 1.457184910774231, -0.4381895959377289, 0.5808455348014832, -0.26776474714279175, 0.12916317582130432, -0.5082738995552063, -0.6861904263496399, -0.11807263642549515, -0.46855318546295166, -0.47800061106681824, -0.24085326492786407, 0.028320083394646645, -0.7373087406158447, -1.1759586334228516, 0.7636697888374329, 0.3820608854293823, 0.6141360998153687, 0.677868664264679, 1.143390417098999, 1.2927762269973755, 0.12067868560552597, -1.1284440755844116, -0.45289346575737, -0.5883593559265137, -0.14899925887584686, -0.6081377267837524, -0.49833691120147705, 0.20301553606987, -0.058391135185956955, -0.8888301253318787]}, "authors": [{"authorId": "2290004260", "name": "Shengwei Li"}, {"authorId": "50756759", "name": "KaiCheng Lu"}, {"authorId": "3050140", "name": "Zhiquan Lai"}, {"authorId": "2267775902", "name": "Weijie Liu"}, {"authorId": "84577042", "name": "Ke-shi Ge"}, {"authorId": "2135905059", "name": "Dongsheng Li"}], "references": [{"paperId": "1ca5618423c64f0656d13c2bc0d387cc2006f7b2", "title": "ZeRO++: Extremely Efficient Collective Communication for Giant Model Training"}, {"paperId": "d3562d9e310873f49a3f10c93dc1db2e4e0b93ec", "title": "A2TP: Aggregator-aware In-network Aggregation for Multi-tenant Learning"}, {"paperId": "2d2b3fa757d7a839d6154b709f779366e624b903", "title": "Fold3D: Rethinking and Parallelizing Computational and Communicational Tasks in the Training of Large DNN Models"}, {"paperId": "6249ef6920bc8a022c99e6c6ecf6b3ff1fe05ed7", "title": "Compressed Collective Sparse-Sketch for Distributed Data-Parallel Training of Deep Learning Models"}, {"paperId": "baa467a4dccf87bc7e2c5a4ea6fd5e401d962d39", "title": "AutoPipe: A Fast Pipeline Parallelism Approach with Balanced Partitioning and Micro-batch Slicing"}, {"paperId": "0437f76a8e6607116659f16c7e4e656851fdd9d5", "title": "HPH: Hybrid Parallelism on Heterogeneous Clusters for Accelerating Large-scale DNNs Training"}, {"paperId": "041edc8b14bdd0e5627377956fd0e6c6c011146a", "title": "Machine Learning Model Sizes and the Parameter Gap"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "33ab9e678905dea63ae6ad5b8ac5c036a81ebd71", "title": "AutoByte: Automatic Configuration for Optimal Communication Scheduling in DNN Training"}, {"paperId": "43332a71939ae7f3bd4756cba2c5ef0763b5cfac", "title": "Varuna: scalable, low-cost training of massive deep learning models"}, {"paperId": "ee8984a6712791d4e0f2c776dad8119a3b893dd9", "title": "Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training"}, {"paperId": "f2c7e5d1762c42d3ff38d66964b71a3b67a30105", "title": "Themis: a network bandwidth-aware collective scheduling policy for distributed training of DL models"}, {"paperId": "10c0a1d3519dcc7b876d21d614f49d82467c9dc3", "title": "Parallel Training of Pre-Trained Models via Chunk-Based Dynamic Memory Management"}, {"paperId": "20e9bee9e0a59afb5ba6543eb93c64c3db3076c0", "title": "Hippie: A Data-Paralleled Pipeline Approach to Improve Memory-Efficiency and Scalability for Large DNN Training"}, {"paperId": "10f3ca78e194552427ebe9173b19d1b910469e27", "title": "Chimera: Efficiently Training Large-Scale Neural Networks with Bidirectional Pipelines"}, {"paperId": "bf38bdd65710ed4e3831c750275f5843058250bc", "title": "BAGUA: Scaling up Distributed Learning with System Relaxations"}, {"paperId": "72dd63d67588a42fc817bbb8d655b397f67425df", "title": "ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep learning"}, {"paperId": "12b71736392209b4292471b7da0aed71ba2aa545", "title": "ZeRO-Offload: Democratizing Billion-Scale Model Training"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "725264948d7b6946259af5b8d966e996b9570f99", "title": "DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters"}, {"paperId": "21a4cd35f19cfe8df1065b066b16edd048d2535d", "title": "DAPPLE: a pipelined data parallel approach for training large models"}, {"paperId": "488128bc81bb96ecdfdff8ca79fb793308d05285", "title": "Preemptive All-reduce Scheduling for Expediting Distributed DNN Training"}, {"paperId": "ac04ed0f3ae0f5b269c9b3e0d1232007d60dbf7e", "title": "Memory-Efficient Pipeline-Parallel DNN Training"}, {"paperId": "9d9dbb4487aca2b62ca3659446d7010ac65aa642", "title": "HetPipe: Enabling Large DNN Training on (Whimpy) Heterogeneous GPU Clusters through Integration of Pipelined Model Parallelism and Data Parallelism"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "408d0580d7e2befabf542119d7fc8318c684572b", "title": "Pipelined Backpropagation at Scale: Training Large Models without Batches"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "1e009f755503bffd7644fcd0a45939c54b838b37", "title": "BlueConnect: Decomposing all-reduce for deep learning on heterogeneous network hierarchy"}, {"paperId": "3fd7c9ba742dd2b435afa75217847e5087e2f2a8", "title": "PipeDream: generalized pipeline parallelism for DNN training"}, {"paperId": "76c929af6735cdff2c4badc9a9c8f39d15ea3e70", "title": "A generic communication scheduler for distributed DNN training acceleration"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "8221b23813858ee536997385097c1ef611184346", "title": "Blink: Fast and Generic Collectives for Distributed ML"}, {"paperId": "00c957711b12468cb38424caccdf5291bb354033", "title": "ZeRO: Memory optimizations Toward Training Trillion Parameter Models"}, {"paperId": "90cbe7f340a8de92143e5b464e6e963bb95f6129", "title": "Priority-based Parameter Propagation for Distributed DNN Training"}, {"paperId": "ca513657a09369be8cec83fda6a5948e744c78a6", "title": "Scaling Distributed Machine Learning with In-Network Aggregation"}, {"paperId": "2229ac756f89c3db017293918548555734d2f891", "title": "TicTac: Accelerating Distributed Deep Learning with Communication Scheduling"}, {"paperId": "e2c8726d092aea573e69f5b0a2654225883cfacf", "title": "Horovod: fast and easy distributed deep learning in TensorFlow"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "079932bf6ff8b99c899172ba60071818f6b5dfcb", "title": "Poseidon: An Efficient Communication Architecture for Distributed Deep Learning on GPU Clusters"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "1a327709cc53ff9e52454e50a643abf4a0ac92af", "title": "Findings of the 2016 Conference on Machine Translation"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "6e795c6e9916174ae12349f5dc3f516570c17ce8", "title": "Skip-Thought Vectors"}, {"paperId": "5ec85a0d88adcc4344bb5cc81b0d1aef9bcd8dcc", "title": "Findings of the 2014 Workshop on Statistical Machine Translation"}, {"paperId": "5d833331b0e22ff359db05c62a8bca18c4f04b68", "title": "One billion word benchmark for measuring progress in statistical language modeling"}, {"paperId": "6f4e48c2a5de9337d147ebbb7d0ff0e555adceca", "title": "Bandwidth optimal all-reduce algorithms for clusters of workstations"}, {"paperId": "704ee1ed2c95bedd7808a92e879bd30cba818739", "title": "A scalable, commodity data center network architecture"}, {"paperId": "cb542f525a3a91bc8d0d3fe69235f59e75822fd4", "title": "Better Together: Jointly Optimizing ML Collective Scheduling and Execution Planning using SYNDICATE"}, {"paperId": "5b3f41652c4630477eba8bb19534109c37dc17a3", "title": "Decoupling the All-Reduce Primitive for Accelerating Distributed Deep Learning"}, {"paperId": null, "title": "\u201cEf\ufb01cientlarge-scalelanguagemodeltrainingonGPU clustersusingmegatron-LM,\u201din"}, {"paperId": "8268f2312602bccd0d8d91aa28737843e428c3f3", "title": "Fine-tuning giant neural networks on commodity hardware with automatic pipeline model parallelism"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": null, "title": "\u201ciMLBench: A machinelearningbenchmarksuiteforCPU-GPUintegratedarchitectures,\u201d"}, {"paperId": null, "title": "\u201cPyTorchdistributed:Experiencesonacceleratingdataparallel training,\u201d2020"}, {"paperId": "08588107b9e37f9601bb5c801aa46b918cc3c8ec", "title": "A Unified Architecture for Accelerating Distributed DNN Training in Heterogeneous GPU/CPU Clusters"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "\u201cMegatron-LM:Trainingmulti-billionparameterlanguagemodelsusing modelparallelism,"}, {"paperId": null, "title": "\u201cOpenwebtext corpus,\u201d"}, {"paperId": null, "title": "\u201cNvidia collective communications library (NCCL),\u201d"}, {"paperId": null, "title": "\u201cParallax:Sparsity-awaredataparalleltrainingofdeepneuralnetworks,\u201din"}, {"paperId": null, "title": "\u201cAn introduction to cuda-aware MPI,\u201d"}, {"paperId": null, "title": "\u201cHanayo: Harnessing wave-like pipelineparallelismforenhancedlargemodeltrainingef\ufb01ciency,\u201din"}, {"paperId": null, "title": "MULTIDIMENSIONAL COMMUNICATION SCHEDULING METHOD FOR HYBRID PARALLEL DNN TRAINING"}, {"paperId": null, "title": "\u201cLogical/physical topology-aware col-lectivecommunicationindeeplearningtraining,\u201din"}]}