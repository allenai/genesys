{"paperId": "1d4c48335d841014d0145256c3c4e7f6c426b8fb", "title": "You Only Cache Once: Decoder-Decoder Architectures for Language Models", "abstract": "We introduce a decoder-decoder architecture, YOCO, for large language models, which only caches key-value pairs once. It consists of two components, i.e., a cross-decoder stacked upon a self-decoder. The self-decoder efficiently encodes global key-value (KV) caches that are reused by the cross-decoder via cross-attention. The overall model behaves like a decoder-only Transformer, although YOCO only caches once. The design substantially reduces GPU memory demands, yet retains global attention capability. Additionally, the computation flow enables prefilling to early exit without changing the final output, thereby significantly speeding up the prefill stage. Experimental results demonstrate that YOCO achieves favorable performance compared to Transformer in various settings of scaling up model size and number of training tokens. We also extend YOCO to 1M context length with near-perfect needle retrieval accuracy. The profiling results show that YOCO improves inference memory, prefill latency, and throughput by orders of magnitude across context lengths and model sizes. Code is available at https://aka.ms/YOCO.", "venue": "arXiv.org", "year": 2024, "citationCount": 6, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A decoder-decoder architecture, YOCO, for large language models, which only caches key-value pairs once, and improves inference memory, prefill latency, and throughput by orders of magnitude across context lengths and model sizes."}, "embedding": {"model": "specter_v2", "vector": [0.016182543709874153, 0.13028870522975922, -0.6712372899055481, -0.031070534139871597, -0.4330120086669922, -0.26174449920654297, 0.546085000038147, 0.1780262440443039, -0.6691937446594238, -0.24663853645324707, 0.28765034675598145, -0.07987083494663239, 0.7602607011795044, 0.18760377168655396, -0.04800284653902054, 0.272482305765152, -0.7274113297462463, 0.13764047622680664, -0.07288073003292084, -0.2030179649591446, 0.009391537867486477, -0.7506306767463684, -1.0384352207183838, 0.2996448874473572, 0.502265989780426, 0.5355792045593262, 0.23064954578876495, 1.113811731338501, -0.3406359851360321, 0.3530313968658447, 0.5537218451499939, -0.20224925875663757, -0.04825040325522423, 0.09482528269290924, -0.09096787124872208, -0.6960870027542114, 0.23470325767993927, -0.5556083917617798, -0.16400672495365143, 0.6671323180198669, -0.19076332449913025, 0.06851284950971603, 0.4561406672000885, -0.7315400242805481, -0.2635660469532013, 0.746692955493927, 0.588546872138977, 0.6477792263031006, -0.32794326543807983, -0.5976970791816711, 1.4045910835266113, -1.576220989227295, 0.0712318941950798, 1.107193946838379, 0.5371764302253723, 0.4385972023010254, -0.2107342928647995, -0.6019666194915771, 0.7789981365203857, -0.1916232854127884, -0.8765251636505127, -0.5328238606452942, -0.2911941707134247, -0.09562136977910995, 2.312756299972534, -0.31635844707489014, 0.1830909103155136, 0.46222931146621704, 0.11576632410287857, 1.528304100036621, -0.25529101490974426, -0.6929011940956116, -0.38969936966896057, 0.13989171385765076, 0.5625907182693481, 0.9647631049156189, -0.3902868330478668, 0.12925763428211212, -0.7228929996490479, -0.41281744837760925, 0.3899812698364258, -0.12927432358264923, 0.20497065782546997, -0.182199165225029, -0.41225337982177734, 0.6593344211578369, 0.1817549169063568, 0.8286833763122559, 0.038553573191165924, 0.9374828934669495, 0.6229791641235352, 0.18673762679100037, 0.09273216128349304, 0.25949281454086304, -0.19609113037586212, 0.10309440642595291, -1.266215205192566, 0.3342830240726471, 0.14524805545806885, 1.0583714246749878, -0.3488093614578247, 0.22972217202186584, -0.6137180924415588, 0.14825674891471863, 1.342452883720398, 0.40706774592399597, 0.4985741972923279, -0.48997068405151367, 0.17752867937088013, -0.9747171998023987, -0.19787165522575378, -0.5410614013671875, -0.09221857041120529, -0.4379662871360779, -0.33563026785850525, -1.368064284324646, -0.5310192704200745, 0.13731373846530914, -0.6195008158683777, 0.7103796005249023, -0.09423203021287918, 0.20738661289215088, 0.20153532922267914, 0.24653975665569305, 1.0360705852508545, 0.5376392602920532, 0.35234078764915466, 0.18283380568027496, 1.2741600275039673, -1.3029667139053345, -0.5709797143936157, -1.245767593383789, 1.0692476034164429, -0.3387603163719177, 0.07177650183439255, -0.14100567996501923, -1.2612565755844116, -0.9115029573440552, -0.7874556183815002, -0.40650466084480286, -0.7635356187820435, 0.2658044695854187, 0.970183789730072, 0.35241007804870605, -1.1297876834869385, 0.642556369304657, -0.24743019044399261, -0.00355487409979105, 0.04457545280456543, 0.1497892588376999, 0.4024442136287689, -0.1754092127084732, -1.358580231666565, 0.2089555859565735, 0.2749061584472656, -0.35244080424308777, -0.19631272554397583, -0.5714887976646423, -1.2380551099777222, -0.050198815762996674, 0.29135313630104065, -0.5335626006126404, 1.383662462234497, -0.11724359542131424, -1.1107409000396729, 0.7819774150848389, -0.8278732299804688, 0.3277808427810669, -0.019783565774559975, -0.3679647743701935, -0.5746256113052368, -0.4916055202484131, -0.04668203741312027, 0.5739858746528625, 0.5751045942306519, -0.32715243101119995, -0.16218213737010956, 0.04683273658156395, -0.4466683268547058, 0.2432568073272705, 0.05862881988286972, 0.8177603483200073, -0.8565545678138733, -0.23126274347305298, 0.31815871596336365, 0.6697424054145813, 0.07397275418043137, -0.3392658233642578, -0.48705896735191345, -0.911555290222168, 0.636428952217102, -0.059985674917697906, 1.395592451095581, -0.934868335723877, -0.8270988464355469, 0.018114909529685974, -0.0006439693388529122, 0.01601581647992134, -0.4108010530471802, 0.532438337802887, -0.08348269015550613, 0.44208818674087524, -0.19993872940540314, -1.1398509740829468, 0.012442964129149914, -0.2508818507194519, -0.5778212547302246, -0.4715908169746399, 0.16665595769882202, 1.276793122291565, -1.1362413167953491, -0.2961669862270355, -0.09510407596826553, 0.3624919354915619, -1.007035732269287, 1.0812543630599976, -0.5922607779502869, -0.03838978707790375, -0.3580440282821655, 0.0679127499461174, 0.039266373962163925, -0.24354158341884613, 0.45671921968460083, -0.34732556343078613, -0.05967682600021362, 0.3196062445640564, -0.10243423283100128, 1.2195667028427124, -0.5083654522895813, 0.19364824891090393, 0.004816278349608183, -0.16013367474079132, 0.039838653057813644, 0.28859180212020874, -0.39960163831710815, -0.5267745852470398, 0.4020869731903076, 0.7527784705162048, -0.736611008644104, 0.48727354407310486, 1.1759458780288696, 1.0567342042922974, -0.29809311032295227, 0.11576759815216064, 0.4568544626235962, -0.19935937225818634, 0.27310246229171753, 0.5727538466453552, 0.5161179900169373, 0.6662601828575134, 0.3777831196784973, 0.006923454347997904, 0.522642195224762, -0.5853481292724609, -0.2172924280166626, 0.7532260417938232, 0.8360906839370728, 0.7529720067977905, 0.4453981816768646, -0.30692270398139954, -0.3808854818344116, 0.07891897112131119, 0.5283468961715698, 1.3945560455322266, -0.2504320740699768, -0.2050071656703949, -0.8333890438079834, -0.32512083649635315, -0.042427826672792435, 0.07838056981563568, -0.15412749350070953, -0.2177509069442749, -0.5257957577705383, -0.5680631399154663, 1.0659394264221191, 0.37414810061454773, 0.8783750534057617, -0.5296695232391357, -0.28783777356147766, -0.21782468259334564, 0.27483874559402466, -1.047482967376709, -0.7256202101707458, 0.40767574310302734, -0.8542273640632629, 0.1921355128288269, 0.23173774778842926, -0.25112202763557434, 0.1393645703792572, -0.5526853203773499, 1.246720552444458, -0.03978673368692398, -0.074022077023983, 0.36287587881088257, 0.5590924620628357, -0.1590377539396286, -0.728374719619751, 0.4259825050830841, 0.09638508409261703, -0.2160111665725708, 0.4017796218395233, 0.6498748064041138, -0.0551830418407917, -0.3759344816207886, -0.18919721245765686, 0.36126598715782166, -0.08251960575580597, -0.06141216680407524, 0.5436751246452332, -0.6828427910804749, -0.20153240859508514, -1.2360923290252686, 0.8097344636917114, -0.10692450404167175, -0.3326982855796814, 0.30302485823631287, -0.8130452632904053, -0.2775910198688507, 0.5411542654037476, -0.43518325686454773, -0.2136421948671341, -0.9563658237457275, 0.0720551460981369, -0.46099653840065, 0.061862677335739136, 0.07958897203207016, 0.23543183505535126, 0.5432014465332031, -0.3397122323513031, 0.6426637172698975, 0.20095263421535492, -0.31527408957481384, 0.8576732873916626, -0.7472091317176819, 0.4901058077812195, 0.14523136615753174, -0.15529951453208923, -0.14942415058612823, -0.39719158411026, -0.7020108699798584, -0.24464458227157593, -0.580990195274353, -0.17890307307243347, -0.26338523626327515, 0.6444327235221863, -0.7614288926124573, -0.9682064056396484, 0.020484259352087975, -1.1669349670410156, -0.15627557039260864, 0.5595439672470093, -0.24840864539146423, 0.019894810393452644, -0.9676068425178528, -1.34098219871521, -0.7224219441413879, -0.9096750020980835, -1.1428425312042236, 0.5466888546943665, 0.12405430525541306, -0.27234315872192383, -0.8714718222618103, -0.11775292456150055, -0.49409186840057373, 0.9033507108688354, -0.8106163144111633, 0.703869104385376, -0.09712342172861099, -0.18437083065509796, -0.026572367176413536, 0.05916515365242958, 0.5652095675468445, -0.48525872826576233, 0.1488846391439438, -1.0305850505828857, 0.21545155346393585, -0.49956294894218445, -0.1979307383298874, 0.441443532705307, 0.24655011296272278, 0.5322552919387817, 0.21677052974700928, -0.9113996028900146, 0.44098716974258423, 1.6122654676437378, -0.6105771064758301, -0.04210101068019867, 0.009064078330993652, 1.1344859600067139, -0.4104256331920624, -0.38337579369544983, 0.42285075783729553, 0.5291498303413391, 0.3845301568508148, 0.06184560805559158, -0.14141394197940826, 0.1270802915096283, -0.5868043899536133, 0.6900001764297485, 1.6679120063781738, 0.6028621196746826, 0.024449605494737625, -0.7142729163169861, 0.6754506826400757, -1.2114752531051636, -0.523949384689331, 0.18920667469501495, 0.7656036019325256, 0.5309913158416748, -0.45958659052848816, -0.5124183893203735, -0.6297622323036194, 0.25742775201797485, 0.4980386197566986, -0.3429928719997406, -1.2145355939865112, 0.16642853617668152, 0.39388272166252136, 0.35798925161361694, 0.8134657740592957, -0.3582512438297272, 0.9786123037338257, 14.80197811126709, 0.792874276638031, 0.060684625059366226, 0.7036554217338562, 0.6716294884681702, 0.10666656494140625, -0.48173531889915466, -0.055264368653297424, -1.7195591926574707, -0.21060149371623993, 1.2886255979537964, 0.45833373069763184, 0.43673697113990784, 0.3838413953781128, 0.04341041296720505, 0.010717795230448246, -0.6380113959312439, 0.7712416648864746, 0.709307849407196, -0.987801194190979, 0.07984145730733871, 0.18356306850910187, 0.0015371061163023114, 0.6929275393486023, 0.8508727550506592, 1.0284295082092285, 0.5608547329902649, -0.3819783627986908, 0.4272901117801666, 0.5859667658805847, 0.8317445516586304, -0.02218034118413925, 0.05399390310049057, 0.3670262098312378, -0.9655652642250061, -0.030631469562649727, -0.489065021276474, -0.9663344621658325, 0.23902268707752228, 0.24142344295978546, -0.7364643216133118, -0.4345391094684601, -0.3522118031978607, 0.8434017300605774, -0.060723017901182175, 0.02493685483932495, 0.11828190088272095, 0.6326503753662109, -0.25190481543540955, -0.22882770001888275, 0.5609869956970215, 0.3692311942577362, 0.21880052983760834, 0.17950591444969177, -0.03223929554224014, -0.13128645718097687, -0.12202296406030655, 0.5921311378479004, -0.4433322250843048, -0.03612426668405533, -0.3846849501132965, -0.13048118352890015, -0.11749595403671265, 0.8820930123329163, 0.539993941783905, 0.025604257360100746, -0.4678176939487457, 0.6967293620109558, 0.8470929265022278, 0.004757332615554333, -0.4404590129852295, 0.3985134959220886, 0.504736602306366, -0.6474353075027466, 0.3227698504924774, 0.2710975110530853, -0.04658016189932823, -0.6967869997024536, -0.6858627796173096, -0.5017460584640503, 0.37260740995407104, -0.7267601490020752, -0.5591475963592529, 0.7614285349845886, -0.2592724561691284, -0.21310366690158844, -0.2527795433998108, -0.836336076259613, 0.020057329908013344, 0.5988739132881165, -1.4437998533248901, -0.5655930638313293, 0.6171255111694336, -0.436175674200058, -0.44356897473335266, 0.23956358432769775, 1.365749478340149, 0.10895419120788574, -0.04377429932355881, 0.26432642340660095, 0.5603439211845398, 0.33402371406555176, -0.5435449481010437, -0.6065492630004883, 1.1356014013290405, 0.0840512216091156, 0.00369111611507833, 0.4533878266811371, -0.3448457419872284, -0.0021773315966129303, -1.1328229904174805, 0.00421039666980505, 0.9043371677398682, -1.0879762172698975, -0.5468378067016602, -1.0786731243133545, -0.7135739326477051, 0.38709503412246704, 0.6472740173339844, -0.08580780774354935, 0.3713149130344391, 0.20649045705795288, -0.7510466575622559, -0.13833126425743103, -0.5860574245452881, 0.2229134738445282, 0.461302250623703, -0.8190679550170898, 0.08002208173274994, -0.22926683723926544, 0.41525521874427795, -1.0600873231887817, -0.4846421480178833, -0.4334433376789093, 0.5506754517555237, -0.12052842974662781, 0.895348072052002, -0.23620954155921936, 0.7405465841293335, 0.9412088990211487, -0.10625230520963669, -0.6947557330131531, 0.19899775087833405, -0.4273982346057892, -0.3782271444797516, 0.16748516261577606, 1.002326488494873, -0.3864476680755615, 0.02332850731909275, 0.9650652408599854, 0.5348894000053406, -0.8653257489204407, -0.5621764063835144, -0.18756604194641113, 0.2535252571105957, -0.6675584316253662, 0.23214629292488098, -0.08740607649087906, -0.0520479753613472, 0.284179151058197, 0.3812997341156006, 0.39227399230003357, -0.012765728868544102, -0.8942400217056274, 0.4585188627243042, 0.13404354453086853, -0.15492843091487885, -0.5489784479141235, -0.3467857539653778, -1.436087965965271, -0.10204487293958664, -1.281093955039978, -0.19972744584083557, -0.8882659673690796, -0.3394441604614258, -0.031018923968076706, -0.25597918033599854, 0.005342452321201563, 0.14636476337909698, -0.08921568840742111, -0.28214702010154724, -0.6579774618148804, -0.6830748915672302, 0.6124874949455261, 0.7595841884613037, -0.23058228194713593, 0.2126363217830658, -0.4752712547779083, 0.06171455234289169, 0.018572334200143814, 0.3554558753967285, -0.3229770064353943, -0.5779650211334229, -1.471942663192749, 0.6445947289466858, -0.028266238048672676, -0.03226180002093315, -0.6960196495056152, 0.5204490423202515, 0.6827225089073181, 0.01078520342707634, -0.24952559173107147, 0.24740298092365265, -0.7619754076004028, -0.6290745735168457, 0.3359350264072418, -0.5867225527763367, 0.5558242797851562, 0.46616998314857483, -0.7792803645133972, -0.0986383929848671, 0.5047661066055298, -0.27993708848953247, -1.2152451276779175, -0.9738010764122009, 0.3331272006034851, -0.5341602563858032, 0.30362898111343384, -0.4525682032108307, -0.13869290053844452, -0.7263479828834534, -0.3694000542163849, 0.04190545529127121, 0.47492071986198425, -0.4778457581996918, 1.2439732551574707, 0.5770901441574097, -0.9929379820823669, 0.12996020913124084, 0.5213160514831543, -0.16024376451969147, -0.16656842827796936, 0.47116819024086, 0.3882988393306732, -0.34782910346984863, 0.4421278238296509, 0.6963604092597961, -0.04624035209417343, -1.1125849485397339, 0.01055798027664423, 0.9102157950401306, -0.7121551632881165, -0.2861422002315521, 1.1424450874328613, -0.3984041213989258, -1.1568756103515625, -0.28328150510787964, -1.4040173292160034, -0.3620229661464691, -0.5365192890167236, 0.5360668301582336, -0.20628684759140015, 0.08195042610168457, -0.22370608150959015, -0.6854973435401917, 0.12005902826786041, -0.5006242990493774, -0.794793963432312, 0.08613361418247223, -0.05565478280186653, -0.5609766840934753, 0.6365231275558472, 1.2393450736999512, -0.47996005415916443, -0.4435340166091919, -0.6143150925636292, -0.5656942129135132, 0.18846231698989868, 0.6220937967300415, -0.5618041753768921, -0.4048810303211212, 0.6212325692176819, 0.3290579319000244, 0.07701952755451202, -0.14792612195014954, -0.32819852232933044, 0.55515456199646, 0.5069865584373474, 0.038323819637298584, -0.7710863947868347, -0.9835410118103027, 1.6360256671905518, 0.8279767632484436, -0.8135470151901245, 0.07141256332397461, 0.08161822706460953, -0.8533421158790588, 0.6408379673957825, 0.35373350977897644, -0.013059071265161037, 1.1365654468536377, -0.13893376290798187, 0.3400270938873291, 0.227029487490654, -1.1242543458938599, -0.2805318236351013, 0.8789157271385193, 0.6530267596244812, 0.9430094957351685, 0.19852490723133087, 0.028090493753552437, 0.7838065028190613, 0.15470807254314423, 0.04237541928887367, 0.07874873280525208, 0.5462074875831604, 0.050466250628232956, -0.1109357699751854, 0.09764289855957031, 0.7738155126571655, -0.6500413417816162, -1.4130191802978516, 0.29090896248817444, 0.6375004053115845, 0.15003100037574768, 0.5748222470283508, 0.8201879262924194, 0.16560667753219604, 0.30624622106552124, 0.5479484796524048, 0.647913932800293, -0.3935616910457611, -0.7657265663146973, -0.22838371992111206, -0.6465540528297424, -0.1258915215730667, 0.19358006119728088, -0.46402421593666077, -0.8101266026496887, -0.19571538269519806, 0.36811187863349915, 0.10396676510572433, 0.33021706342697144, 1.1570966243743896, 0.6603057980537415, 0.343057781457901, -0.34767448902130127, -0.004397059325128794, -0.4026314914226532, -0.8793458938598633, -0.09249261021614075, -0.7270939350128174, -0.031193731352686882, -0.04072947800159454, 0.1297314167022705, -0.6214116811752319]}, "authors": [{"authorId": "2108540694", "name": "Yutao Sun"}, {"authorId": "2294850817", "name": "Li Dong"}, {"authorId": "2271748644", "name": "Yi Zhu"}, {"authorId": "3110003", "name": "Shaohan Huang"}, {"authorId": "51456429", "name": "Wenhui Wang"}, {"authorId": "2118866998", "name": "Shuming Ma"}, {"authorId": "2270914501", "name": "Quanlu Zhang"}, {"authorId": "2300337691", "name": "Jianyong Wang"}, {"authorId": "2253471545", "name": "Furu Wei"}], "references": [{"paperId": "49873ee415619efd9e1e4c16f73ee066ff008c1f", "title": "MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies"}, {"paperId": "cbaf689fd9ea9bc939510019d90535d6249b3367", "title": "Jamba: A Hybrid Transformer-Mamba Language Model"}, {"paperId": "41b47f33a24feefd6728bdc1339d0d4ff5fec7be", "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context"}, {"paperId": "f288e2238ac8725baa7ca9874bbc3fed1e89a632", "title": "Data Engineering for Scaling Language Models to 128K Context"}, {"paperId": "62b18cc55dcc7ffe52c28e1086aee893b7bc4334", "title": "Gated Linear Attention Transformers with Hardware-Efficient Training"}, {"paperId": "1be73fa3e856c33d0aed1d9e46693523e7fa3c60", "title": "Zoology: Measuring and Improving Recall in Efficient Language Models"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "d7f64f2bdd80ea15f21ef7d867e102ac9ecdc797", "title": "GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling"}, {"paperId": "02ad9f3fefe33cb9ca546591bec65dbdf7766c80", "title": "Ring Attention with Blockwise Transformers for Near-Infinite Context"}, {"paperId": "5e0cb1c4b91a7486e1c2b15a44a0be56bd74bdc0", "title": "Effective Long-Context Scaling of Foundation Models"}, {"paperId": "819bbdc2dac9e13d9ca3e2508a6e063186ce5e40", "title": "YaRN: Efficient Context Window Extension of Large Language Models"}, {"paperId": "240103933ffe3dac2179cc160a2bd91299357a53", "title": "Retentive Network: A Successor to Transformer for Large Language Models"}, {"paperId": "c12db2c60e8989f646a29ad4f4d24475e860ad91", "title": "LongNet: Scaling Transformers to 1, 000, 000, 000 Tokens"}, {"paperId": "80980cd10d19f021c14a6b7eee871b6a5d328024", "title": "Augmenting Language Models with Long-Term Memory"}, {"paperId": "eb511ae6b9f04e4936891d26787f274b48b99d57", "title": "ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding"}, {"paperId": "5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200", "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "f6ba3fab410cf2182fde171beeeec57bffa3e90b", "title": "SuperScaler: Supporting Flexible DNN Parallelization via a Unified Abstraction"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "379e42895f6d40ab9e9559609f505aba89145a5d", "title": "Efficiently Scaling Transformer Inference"}, {"paperId": "1d26c947406173145a4665dd7ab255e03494ea28", "title": "GLM-130B: An Open Bilingual Pre-trained Model"}, {"paperId": "02251886950770e82b3d68564d60cdfe15e73199", "title": "Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks"}, {"paperId": "cf7c2e0e4fb2af689aaf4b7a7cddf7b1f4d5e3f0", "title": "VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "10eda4521c032adabaa8e70d6569e17370b29dcd", "title": "Root Mean Square Layer Normalization"}, {"paperId": "661d142c23cb2a3207d5f1ba2ac7ff61f2d4fb2f", "title": "Triton: an intermediate language and compiler for tiled neural network computations"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "d08b35243edc5be07387a9ed218070b31e502901", "title": "Group Normalization"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "fda8e7fafbf34cbba357beaf44e15e8351e2b390", "title": "Magneto: A Foundation Transformer"}, {"paperId": "28682682ce59cf90de9da7d62d1c17513fdac09a", "title": "Sequence Parallelism: Making 4D Parallelism Possible"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "World model on million-length video and language with ringattention"}, {"paperId": null, "title": "OpenLLaMA: An open reproduction of LLaMA"}, {"paperId": null, "title": "StableLM Alpha v2 models"}, {"paperId": null, "title": "Needle in a Haystack - pressure testing"}, {"paperId": null, "title": "Flash-Decoding for long-context inference"}, {"paperId": null, "title": "FLA: A Triton-based library for hardware-efficient implementations of linear attention mechanism"}, {"paperId": null, "title": "A framework for few-shot language model"}]}