{"paperId": "11cf88dce827bd67cbfa60400306318022e736d5", "title": "D4: Improving LLM Pretraining via Document De-Duplication and Diversification", "abstract": "Over recent years, an increasing amount of compute and data has been poured into training large language models (LLMs), usually by doing one-pass learning on as many tokens as possible randomly selected from large-scale web corpora. While training on ever-larger portions of the internet leads to consistent performance improvements, the size of these improvements diminishes with scale, and there has been little work exploring the effect of data selection on pre-training and downstream performance beyond simple de-duplication methods such as MinHash. Here, we show that careful data selection (on top of de-duplicated data) via pre-trained model embeddings can speed up training (20% efficiency gains) and improves average downstream accuracy on 16 NLP tasks (up to 2%) at the 6.7B model scale. Furthermore, we show that repeating data intelligently consistently outperforms baseline training (while repeating random data performs worse than baseline training). Our results indicate that clever data selection can significantly improve LLM pre-training, calls into question the common practice of training for a single epoch on as much data as possible, and demonstrates a path to keep improving our models past the limits of randomly sampling web data.", "venue": "Neural Information Processing Systems", "year": 2023, "citationCount": 42, "influentialCitationCount": 1, "openAccessPdf": {"url": "https://arxiv.org/pdf/2308.12284", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "The results indicate that clever data selection can significantly improve LLM pre-training, calls into question the common practice of training for a single epoch on as much data as possible, and demonstrates a path to keep improving the authors' models past the limits of randomly sampling web data."}, "embedding": {"model": "specter_v2", "vector": [-0.13934318721294403, 0.540037989616394, -0.6009528636932373, 0.045441240072250366, -0.4220741391181946, -0.7317955493927002, 0.769495964050293, -0.17316146194934845, -0.6927277445793152, -0.26510271430015564, 0.512752115726471, -0.29321274161338806, 0.26628604531288147, 0.45874977111816406, -0.3692876398563385, 0.20420433580875397, -0.9895635843276978, 0.5070767402648926, -0.4951684772968292, -0.07249075174331665, -0.34250736236572266, -0.6606212258338928, -0.46748021245002747, 0.13228929042816162, 0.536165177822113, 0.04899712651968002, 0.2698957324028015, 0.5837063789367676, -0.6325550675392151, -0.3473058044910431, 0.09311865270137787, -0.6428506970405579, 0.5191442370414734, -0.147536039352417, -0.5213677883148193, 0.13756440579891205, 0.49205371737480164, -0.22613807022571564, -0.40843436121940613, 0.5844025015830994, -0.0008636347483843565, 0.4254527986049652, 0.3399249315261841, -0.43977099657058716, -0.4200569987297058, 1.0601469278335571, 0.37707698345184326, 0.7132889628410339, -0.3434794247150421, -0.5877171158790588, 1.3185850381851196, -1.3465999364852905, 0.5960729718208313, 1.329869031906128, 0.7459793090820312, 0.5415323376655579, -0.20302392542362213, -0.5029789805412292, 0.5192061066627502, 0.20779117941856384, -0.8108080625534058, -0.2986823320388794, -0.06052810326218605, 0.08513730019330978, 2.2230775356292725, -0.6909376382827759, 0.038473185151815414, 0.4288424253463745, -0.3911875784397125, 1.578364610671997, -0.388883113861084, -0.8425506949424744, -0.47194796800613403, 0.2893778085708618, 0.07471539080142975, 0.5275632739067078, -0.3951100707054138, 0.08060777932405472, -0.803302526473999, -0.1712358295917511, 0.18544724583625793, -0.08027005195617676, 0.1848011612892151, 0.06799294054508209, 0.03834015130996704, 0.6187564730644226, 0.31621310114860535, 0.9928889870643616, -0.29562631249427795, 0.6448968648910522, 0.6484163403511047, 0.39293408393859863, 0.3934909403324127, 0.5927184820175171, -0.5749613642692566, 0.41763198375701904, -0.9982057809829712, 0.25721073150634766, 0.08922335505485535, 0.7183924317359924, -0.05667273700237274, 0.16677828133106232, -0.5220737457275391, 0.46065083146095276, 1.2237039804458618, -0.1371622383594513, 0.8558306097984314, -0.6394075751304626, 0.5876742005348206, -0.7053855061531067, 0.03401602804660797, -0.28493574261665344, -0.39011919498443604, -0.46108052134513855, -0.6078119874000549, -1.7312525510787964, -0.5047619938850403, -0.3017989695072174, -0.6789994835853577, 0.8696353435516357, -0.2879815995693207, 0.3540242314338684, 0.2744129002094269, 0.46577128767967224, 0.33354195952415466, 0.8240773677825928, 0.3927062749862671, -0.07129084318876266, 0.5636905431747437, -0.8105171322822571, -0.4181780219078064, -0.8495641946792603, 1.0344926118850708, -0.38449615240097046, 0.2702305018901825, -0.2872193157672882, -1.490466833114624, -0.6586117148399353, -0.5860612988471985, 0.005067464895546436, -0.4511404037475586, 0.4435425102710724, 0.8417162299156189, 0.3101317882537842, -0.7303224802017212, 0.9988176822662354, -0.09496523439884186, -0.5259626507759094, 0.27344992756843567, -0.08984457701444626, 0.2256847769021988, -0.3576768934726715, -1.3606714010238647, 0.36885055899620056, 0.35645416378974915, -0.6351622939109802, -0.05915376916527748, -0.829690158367157, -0.6537815928459167, -0.045225974172353745, 0.10453267395496368, -0.41456636786460876, 1.5241775512695312, -0.04567484185099602, -1.2443089485168457, 0.9757981896400452, -0.2429254949092865, -0.25315386056900024, 0.48283568024635315, -0.23471570014953613, -0.763305127620697, -0.5222635865211487, -0.3067763149738312, 0.6358078122138977, 0.36286795139312744, -0.10738735646009445, 0.01231051329523325, 0.300790011882782, -0.24071379005908966, 0.11167491227388382, -0.5176473259925842, 0.43661803007125854, -0.26346051692962646, -0.5053971409797668, 0.2963164448738098, 0.6486532092094421, 0.16286535561084747, -0.6923150420188904, -0.33707451820373535, -1.379138708114624, 0.49737414717674255, -0.36649855971336365, 0.8836215734481812, -0.886338472366333, -0.6894587278366089, -0.14024583995342255, -0.4649149775505066, 0.3511190116405487, -1.063659906387329, 1.0843843221664429, -0.32040029764175415, 0.8343865275382996, 0.06482534110546112, -1.6068612337112427, 0.30712568759918213, -0.33874770998954773, -0.7080429792404175, -0.37801358103752136, 0.271701842546463, 1.0319136381149292, -0.6668909788131714, 0.29649460315704346, -0.21469376981258392, 0.20245175063610077, -1.215777039527893, 0.8343860507011414, -0.7106714844703674, -0.051285769790410995, 0.4894760847091675, -0.2771975100040436, 0.434901624917984, -0.16474749147891998, 0.5658459067344666, -0.3528367578983307, -0.37541475892066956, 0.9489423632621765, -0.4769563674926758, 1.636281967163086, -0.6862860918045044, 0.3310371935367584, -0.015255813486874104, -0.631729245185852, -0.17016535997390747, 0.3505643606185913, 0.04949769377708435, -0.3302120268344879, -0.12771274149417877, 0.5275400280952454, -0.7706507444381714, 0.014051788486540318, 0.6241259574890137, 0.6327869892120361, -0.16087988018989563, 0.4184819757938385, 0.6480119228363037, -0.11845407634973526, 0.6955581307411194, 0.4203951954841614, 0.6675187945365906, 0.17186331748962402, 0.12356162071228027, 0.15059584379196167, 0.1786002367734909, -0.6086793541908264, 0.11975786834955215, 0.3976047933101654, 0.7542206645011902, 0.3515368103981018, 0.15301905572414398, -0.514388918876648, -0.6230879426002502, -0.3791452944278717, 0.5071430802345276, 1.4990835189819336, -0.43876194953918457, -0.28068113327026367, -0.5953168272972107, -0.523951530456543, 0.14317011833190918, 0.20468203723430634, 0.024722915142774582, 0.020056890323758125, -0.8373064398765564, -1.0867371559143066, 0.7672955393791199, -0.14935407042503357, 1.0700708627700806, -0.37310585379600525, 0.2481011599302292, -0.15003681182861328, 0.10633589327335358, -0.5821887254714966, -0.6078246235847473, 0.4259773790836334, -0.45397132635116577, 0.16462178528308868, -0.16738036274909973, -0.657684326171875, 0.17429818212985992, -0.26621726155281067, 0.9962932467460632, -0.4022260904312134, -0.21970234811306, 0.02684585563838482, 0.2769116461277008, -0.4821261763572693, -0.8835435509681702, 0.6975677013397217, 0.37686172127723694, -0.6853463053703308, 0.39305996894836426, 0.30675008893013, 0.03586414083838463, -0.04631916061043739, -0.6152865886688232, 0.0394851416349411, 0.16517040133476257, -0.06070218235254288, 0.5008678436279297, 0.14187303185462952, 0.46212252974510193, -1.0591771602630615, 0.8960104584693909, -0.043252792209386826, -0.30799436569213867, 0.43575093150138855, -0.5732415914535522, -0.5296246409416199, 0.579780101776123, -0.7512977719306946, -0.3500696122646332, -1.0347380638122559, 0.16192837059497833, 0.013335329480469227, 0.018940815702080727, 0.365962415933609, 0.35492074489593506, 0.4813534617424011, 0.29655709862709045, 0.40212100744247437, 0.34114503860473633, -0.687001645565033, 0.7658928036689758, -0.6852430701255798, 0.18722599744796753, 0.601285994052887, 0.47441887855529785, -0.39531946182250977, -0.3844910264015198, -0.8615429401397705, -0.33888983726501465, -0.5094531774520874, -0.4087856411933899, 0.06829071789979935, 0.032833438366651535, -0.4127187132835388, -0.4913468062877655, 0.024981383234262466, -1.2609589099884033, -0.26153719425201416, 0.01591099426150322, -0.11539784073829651, 0.09565835446119308, -0.932463526725769, -1.3665833473205566, -0.344957560300827, -0.47218993306159973, -0.3488992154598236, 0.1242135763168335, -0.034456003457307816, -0.34992700815200806, -0.7483737468719482, 0.38662952184677124, -0.3616665005683899, 0.8348665833473206, -1.0233935117721558, 0.965751588344574, -0.08534560352563858, 0.05003936588764191, -0.29997745156288147, 0.3933522403240204, 0.7408947944641113, -0.37080609798431396, 0.343654602766037, -0.7102908492088318, 0.14218373596668243, -0.6229159235954285, -0.30021223425865173, 0.37021446228027344, 0.40903982520103455, 0.46467819809913635, -0.3225732743740082, -0.5602594017982483, 0.38887819647789, 1.4399878978729248, -0.8512833714485168, 0.01451419573277235, 0.1307714283466339, 0.6376322507858276, 0.4319089949131012, -0.553579568862915, 0.7062749266624451, 0.23179779946804047, 0.11763615161180496, -0.182784304022789, -0.031557198613882065, -0.23859307169914246, -0.7858718633651733, 0.559338390827179, 1.8776098489761353, 0.6420351266860962, -0.3001066744327545, -0.9512800574302673, 0.7111524343490601, -0.959357500076294, -0.7613438367843628, 0.579228937625885, 0.5113526582717896, 0.798937976360321, -0.7363802790641785, -0.16922548413276672, -0.33194994926452637, 0.3135641813278198, 0.3111906945705414, -0.5126770734786987, -0.567544162273407, -0.06683208793401718, 0.2795923352241516, 0.42134374380111694, 0.4071343243122101, -0.2420222908258438, 0.9284156560897827, 14.899280548095703, 0.868931770324707, 0.20167176425457, 0.7483798265457153, 0.24469387531280518, -0.2077387422323227, -0.6251162886619568, -0.4338527321815491, -1.4445054531097412, -0.0381222739815712, 0.9759538769721985, 0.022743893787264824, 0.9578280448913574, 0.09614565223455429, 0.22360199689865112, 0.2864674925804138, -0.3800903260707855, 0.5482959151268005, 0.515866219997406, -1.471786379814148, 0.3637069761753082, 0.23031078279018402, 0.7568331956863403, 0.8473396897315979, 0.9184120297431946, 1.0176435708999634, 0.44517582654953003, -0.015462370589375496, 0.1324201077222824, 0.020649295300245285, 0.47335556149482727, -0.04800133407115936, 0.39965176582336426, 0.6837942600250244, -0.4139641523361206, -0.16370698809623718, -0.7644798755645752, -0.7941800355911255, 0.33309751749038696, 0.4236297607421875, -0.9451778531074524, -0.5801631808280945, -0.41721880435943604, 0.8958134651184082, 0.182436004281044, 0.37847691774368286, -0.11588951200246811, 0.6679472327232361, -0.36374086141586304, 0.08391750603914261, 0.3491978943347931, 0.6711689829826355, 0.39835289120674133, 0.24148793518543243, -0.13067008554935455, -0.41427454352378845, -0.08283539116382599, 0.25254446268081665, -1.0097252130508423, 0.1552831530570984, -0.18499024212360382, -0.4071395993232727, 0.17490066587924957, 0.6549522280693054, 0.795377790927887, 0.24860134720802307, -0.36740362644195557, 0.5801402926445007, 0.7615833878517151, 0.28610503673553467, -0.3231690227985382, -0.003410533769056201, 0.40547335147857666, -0.3496208190917969, -0.019931010901927948, 0.012070699594914913, -0.073418527841568, -0.44299644231796265, -0.5693126320838928, -0.023310944437980652, 0.18195046484470367, -0.4707511067390442, -0.9224659204483032, 0.5237542986869812, -0.33102983236312866, -0.5552856922149658, -0.0706344023346901, -0.711164116859436, -0.0043220301158726215, 0.45910635590553284, -1.4680172204971313, -0.5530015230178833, 0.6079050898551941, -0.4719002842903137, -0.324230819940567, -0.18542248010635376, 1.1755080223083496, 0.5135648250579834, -0.43646636605262756, 0.18381217122077942, 0.7155064344406128, -0.1691683977842331, 0.03896012529730797, -0.5470050573348999, 1.1369675397872925, 0.11706223338842392, -0.03505866229534149, 0.3047220706939697, -0.14558322727680206, 0.08531887829303741, -0.7502904534339905, -0.224294513463974, 1.2041584253311157, -0.7306768298149109, -0.4989697337150574, -0.6547055840492249, -0.7380538582801819, 0.3756859600543976, 0.6058938503265381, -0.8239931464195251, 0.4993492364883423, 0.31553786993026733, -0.3951706886291504, -0.11647183448076248, -1.0493026971817017, 0.22685427963733673, 0.7377771735191345, -0.6194356679916382, -0.2697954475879669, 0.5581904649734497, 0.460769921541214, -0.6470581889152527, -0.5705079436302185, -0.3833085000514984, -0.15220801532268524, 0.37515726685523987, 0.8906140923500061, -0.5310490131378174, 0.5542109608650208, 1.066292643547058, 0.050233472138643265, -1.1467326879501343, 0.07806691527366638, -0.8562413454055786, 0.09117645770311356, 0.6662198901176453, 0.7780458927154541, -0.3319792151451111, 0.39498642086982727, 0.7322458028793335, 0.32725775241851807, -0.24758243560791016, -0.47149085998535156, -0.846689760684967, 0.41454610228538513, -0.47500887513160706, 0.22773665189743042, 0.23586314916610718, 0.2206704467535019, 0.007841999642550945, 0.5805611610412598, 0.31117066740989685, -0.24190068244934082, -1.0202593803405762, 0.4686294496059418, 0.0045283399522304535, -0.15105006098747253, -0.5319095253944397, -0.17239323258399963, -1.5533479452133179, 0.4068949818611145, -1.5514403581619263, -0.18586915731430054, -0.9871304035186768, -0.6602047681808472, -0.1362544298171997, 0.12718063592910767, 0.0854925885796547, 0.663661539554596, -0.43893760442733765, -0.42487239837646484, -0.26103487610816956, -0.3097054064273834, 0.7555367350578308, 0.8578124046325684, -0.6243740916252136, -0.1592397391796112, -0.09520532935857773, 0.3090657591819763, 0.2943238914012909, 0.6453231573104858, -0.3526137173175812, -0.6672017574310303, -1.8774762153625488, 0.559403657913208, -0.38810521364212036, -0.19600637257099152, -0.4235231280326843, 0.4906085133552551, 0.3700399398803711, -0.05969162657856941, -0.15631026029586792, -0.021125707775354385, -0.9242441654205322, -0.6226418614387512, 0.06645668298006058, -0.626171886920929, 0.28772619366645813, 0.1486045867204666, -0.7825492024421692, -0.0580504909157753, 0.3364734649658203, -0.20063313841819763, -1.291069746017456, -0.7859033346176147, 0.2754010558128357, -0.6247392296791077, 0.2231898456811905, -0.32045087218284607, 0.00873495265841484, -1.1258138418197632, -0.10815770924091339, -0.07040327787399292, 0.5669532418251038, -0.42558106780052185, 0.8930298089981079, -0.1471061110496521, -1.218570351600647, -0.183053120970726, 0.30797189474105835, -0.3599785566329956, -0.014466309919953346, 0.6691685914993286, 0.24211812019348145, -0.25797927379608154, 0.6007304191589355, 0.4423356354236603, 0.5183374285697937, -0.6641244888305664, -0.3112848401069641, 0.7002817988395691, -0.6740797162055969, -0.10564442723989487, 1.2374427318572998, -0.8634083867073059, -1.2855767011642456, 0.27855467796325684, -0.9192801117897034, -0.25809136033058167, -0.06262678653001785, 0.43726038932800293, 0.315967321395874, 0.08273187279701233, 0.10254449397325516, -0.6224297285079956, 0.1335449516773224, -0.2368064671754837, -0.5450406074523926, 0.9352214336395264, -0.48214322328567505, -0.18303994834423065, 0.41724854707717896, 1.4080768823623657, -0.6425600051879883, -0.6486208438873291, -0.8585066795349121, -0.2653643488883972, 0.009373021312057972, 0.3067682385444641, -0.7845826148986816, -0.31183964014053345, 0.6588054299354553, 0.24580161273479462, 0.3581197261810303, -0.23096007108688354, -0.11864140629768372, 0.6119194626808167, 0.6783357262611389, 0.041471146047115326, -1.1453276872634888, -0.39842692017555237, 1.5780971050262451, 1.031843662261963, -0.9184744954109192, 0.23060782253742218, 0.18053275346755981, -0.8765078783035278, 0.7006818056106567, 0.1106472909450531, 0.02217562310397625, 0.9474586844444275, -0.40020236372947693, 0.1700635850429535, 0.3059937059879303, -0.9503472447395325, -0.1893891841173172, 0.7150372862815857, 0.8189405798912048, 0.8551764488220215, 0.1613340675830841, -0.14476177096366882, 0.8009970188140869, -0.09001410752534866, -0.12510372698307037, 0.18842418491840363, 0.35900405049324036, -0.09488082677125931, -0.4270489513874054, 0.2750184237957001, 0.5889800190925598, -0.5686343312263489, -0.5640477538108826, -0.20352280139923096, 0.6836977601051331, 0.32066619396209717, 0.4020370543003082, 0.9272441267967224, 0.07875371724367142, 0.4494883120059967, 0.48798835277557373, 0.6518263816833496, -0.47555413842201233, -0.45427200198173523, -0.34515318274497986, -0.6523586511611938, 0.18763288855552673, -0.1410249024629593, -0.788607656955719, -0.5458665490150452, -0.6088259220123291, 0.3137364983558655, 0.04869270697236061, 0.8338854908943176, 0.9774657487869263, 0.7539600133895874, 0.22201310098171234, -0.15573282539844513, -0.47402599453926086, -0.6797071099281311, -1.0764139890670776, -0.20782902836799622, -0.16034100949764252, -0.32364821434020996, 0.25836068391799927, -0.4151015281677246, -0.1811513751745224]}, "authors": [{"authorId": "2551387", "name": "Kushal Tirumala"}, {"authorId": "2257241733", "name": "Daniel Simig"}, {"authorId": "2201435", "name": "Armen Aghajanyan"}, {"authorId": "4690624", "name": "Ari S. Morcos"}], "references": [{"paperId": "95240dda409e28acccdc5cf619ad0c036cf4292d", "title": "Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time"}, {"paperId": "7a1e71cb1310c4a873e7a4e54d1a6dab0553adce", "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"}, {"paperId": "9e16d8cc6096ec0d2733a4ecf41ce09d9a4bd19c", "title": "Scaling Data-Constrained Language Models"}, {"paperId": "1567bcac0ab09269c9d0ff33c9a406132417fab9", "title": "A Pretrainer\u2019s Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity"}, {"paperId": "7c217cc7524251f42887438834912e06129c3299", "title": "To Repeat or Not To Repeat: Insights from Scaling LLM under Token-Crisis"}, {"paperId": "9b4f7c97c0b83a80c32bc0b93595cbcfb4ecb16d", "title": "DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining"}, {"paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8", "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"}, {"paperId": "638b08154fbb71fd34db2aae6cb40045577fe0de", "title": "SemDeDup: Data-efficient learning at web-scale through semantic deduplication"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "74013b7cfa0fc524803350fca51341004565eb22", "title": "Data Selection for Language Models via Importance Resampling"}, {"paperId": "e965e93e76a9e6c4e4863d145b5c007b540d575d", "title": "OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization"}, {"paperId": "6cf65eb8aa66116e14a97bb8f71552359ff814ba", "title": "Will we run out of data? Limits of LLM scaling based on human-generated data"}, {"paperId": "4be7d1524edb0137599a5cc95f72844b85a52fe1", "title": "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale"}, {"paperId": "45122c8f76a4e2fd0163d1f0522db37e97ea4721", "title": "Beyond neural scaling laws: beating power law scaling via data pruning"}, {"paperId": "6a8db14262ca2017cb253e12b8daeb57989a38df", "title": "Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt"}, {"paperId": "8b293973061026d9d0eed90e71e30928e029171e", "title": "Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models"}, {"paperId": "aa4d9972af3264d032dbee58501ed4ac49477103", "title": "Scaling Laws and Interpretability of Learning from Repeated Data"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "06d7cb8c8816360feb33c3367073e0ef66d7d0b0", "title": "Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "11154b89486fd7b41bfab5f8b0e19756c488523e", "title": "Dataset Distillation by Matching Training Trajectories"}, {"paperId": "9b1f4492a663c7f56f2b43ae1ed167d3857aacca", "title": "PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "fb01415a0decfa3f3d6339930e95028ae1ff4170", "title": "Efficient Large Scale Language Modeling with Mixtures of Experts"}, {"paperId": "4f4a409f701f7552d45c46a5b0fea69dca6f8e84", "title": "Unsupervised Dense Information Retrieval with Contrastive Learning"}, {"paperId": "68aca52dc55878a345420f9c32eaaec77794481b", "title": "Trivial or impossible - dichotomous data difficulty masks model differences (on ImageNet and beyond)"}, {"paperId": "a6e25ca9ee9d3e45c6d1957c0dc3324a9816c34e", "title": "Deep Learning on a Data Diet: Finding Important Examples Early in Training"}, {"paperId": "4566c0d22ebf3c31180066ab23b6c445aeec78d5", "title": "Deduplicating Training Data Makes Language Models Better"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "15e1ee23b52e2b9f5706e603856062bc26fb9f88", "title": "What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation"}, {"paperId": "5a94bcc168330318d3020aa4d41bd73cf68ab285", "title": "Dataset Condensation with Gradient Matching"}, {"paperId": "90d0ea843a4ba16b3c5b520d39fce9e9ede156ff", "title": "At the Speed of Sound: Efficient Audio Scene Classification"}, {"paperId": "e816f788767eec6a8ef0ea9eddd0e902435d4271", "title": "Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks"}, {"paperId": "1a6f4495474f75ae1e8bbf407f70d9a874e5b4d6", "title": "The Pushshift Reddit Dataset"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "c20c68c45127439139a08adb0b1f2b8354a94d6c", "title": "CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "9f73c3f86026c21d0e5e55c70462952c6ada1175", "title": "Accelerating Deep Learning by Focusing on the Biggest Losers"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "790985a4bee821046992ff3d5322ff11dd1b4262", "title": "Coresets for Data-efficient Training of Machine Learning Models"}, {"paperId": "131a2b1c2fb51d8c7eae9a359425664361ce71bd", "title": "Training Data Subset Search With Ensemble Active Learning"}, {"paperId": "d9f6ada77448664b71128bb19df15765336974a6", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "0af0fedaa1fee7293fcdc1abe180ba6fb37c5a4b", "title": "Semantic Redundancies in Image-Classification Datasets: The 10% You Don't Need"}, {"paperId": "a2b5d224895d96bfe2e384e2dcf1ebd136ac3782", "title": "An Empirical Study of Example Forgetting during Deep Neural Network Learning"}, {"paperId": "1536e8958697c5364f68b2e2448905dbbeb3a0ca", "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering"}, {"paperId": "88bb0a28bb58d847183ec505dda89b63771bb495", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"}, {"paperId": "c342c71cb23199f112d0bc644fcce56a7306bf94", "title": "Active Learning for Convolutional Neural Networks: A Core-Set Approach"}, {"paperId": "2cbb8de53759e75411bc528518947a3094fbce3a", "title": "Billion-Scale Similarity Search with GPUs"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "128cb6b891aee1b5df099acb48e2efecfcff689f", "title": "The Winograd Schema Challenge"}, {"paperId": "8addb1718c2bc6bbb0d82cd1a57b41198bf65965", "title": "On the resemblance and containment of documents"}, {"paperId": "29c7f009df21d0112c48dec254ff80cc45fac3af", "title": "Are Emergent Abilities of Large Language Models a Mirage?"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28", "title": "An Adversarial Winograd Schema Challenge at Scale"}, {"paperId": null, "title": "A corpus and evaluation framework for deeper understanding of commonsense stories"}, {"paperId": "d20bfd7a53f4367c277ae3b921994a0c2fc3b4ec", "title": "D\u00e9ja vu."}, {"paperId": null, "title": "West Bengal Barda is a large village located in Egra -I Block"}, {"paperId": null, "title": "Tamil Nadu Kodunaickenpatty pudur is a large village located in Omalur Taluka of"}, {"paperId": null, "title": "Chhotepur Population -Gurdaspur, Punjab Chhotepur is a medium size village located in Gurdaspur Tehsil of Gurdaspur district"}]}