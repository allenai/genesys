{"paperId": "43014fc85c4860487336579ec98f509fec1803f7", "title": "MegaBlocks: Efficient Sparse Training with Mixture-of-Experts", "abstract": "We present MegaBlocks, a system for efficient Mixture-of-Experts (MoE) training on GPUs. Our system is motivated by the limitations of current frameworks, which restrict the dynamic routing in MoE layers to satisfy the constraints of existing software and hardware. These formulations force a tradeoff between model quality and hardware efficiency, as users must choose between dropping tokens from the computation or wasting computation and memory on padding. To address these limitations, we reformulate MoE computation in terms of block-sparse operations and develop new block-sparse GPU kernels that efficiently handle the dynamism present in MoEs. Our approach never drops tokens and maps efficiently to modern hardware, enabling end-to-end training speedups of up to 40% over MoEs trained with the state-of-the-art Tutel library and 2.4x over DNNs trained with the highly-optimized Megatron-LM framework.", "venue": "Conference on Machine Learning and Systems", "year": 2022, "citationCount": 40, "influentialCitationCount": 1, "openAccessPdf": {"url": "https://arxiv.org/pdf/2211.15841", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "MegaBlocks, a system for efficient Mixture-of-Experts (MoE) training on GPUs, is presented, reformulate MoE computation in terms of block-sparse operations and develop new block-Sparse GPU kernels that efficiently handle the dynamism present in MoEs."}, "embedding": {"model": "specter_v2", "vector": [0.18918074667453766, 0.534325897693634, -0.5747681856155396, 0.05111043155193329, -0.4683334529399872, 0.24306124448776245, 0.52975994348526, -0.39818352460861206, -0.3572391867637634, -0.685966968536377, 0.3985638916492462, 0.43133631348609924, 0.940418004989624, 0.29487255215644836, -0.407640278339386, 0.16174450516700745, -0.7388665676116943, -0.08909168094396591, 0.3257489800453186, -0.4709388315677643, -0.13026833534240723, -0.5589999556541443, -1.2637317180633545, 0.6198280453681946, 0.3797755539417267, 0.9667092561721802, 0.052050188183784485, 0.6814693808555603, -0.5241192579269409, 0.7337059378623962, 0.605094850063324, -0.04144547879695892, 0.41964706778526306, 0.08115816861391068, 0.13878561556339264, -0.22273384034633636, 0.6760144829750061, -0.3766839802265167, -0.9553807973861694, 0.7727487087249756, -0.0905168354511261, 0.16503497958183289, 0.5221068859100342, -0.6285868883132935, 0.2599087059497833, 0.8310858011245728, 0.2366129606962204, 0.7791233062744141, -0.7330573201179504, -0.4898858070373535, 0.8608170747756958, -1.2986111640930176, 0.09950508922338486, 1.3226813077926636, 0.8341304063796997, 0.4900103211402893, -0.45757856965065, -0.6426500678062439, 0.9484357237815857, 0.22369614243507385, -0.6178982257843018, -0.9861977100372314, -0.2664669454097748, -0.34445858001708984, 2.2256906032562256, -0.6041603684425354, 0.25547701120376587, 0.718337893486023, -0.025414887815713882, 1.6590180397033691, -0.058766014873981476, -0.6252759099006653, -0.37279006838798523, 0.2973429560661316, 0.27301424741744995, 0.8475186824798584, -0.39079928398132324, 0.34799447655677795, -1.1791633367538452, 0.1058865338563919, 0.41716882586479187, -0.06902340799570084, 0.5344445109367371, -0.4190550446510315, -0.3249896764755249, 0.6872761249542236, 0.6091587543487549, 0.7521769404411316, -0.31988024711608887, 0.981934666633606, 0.785819411277771, -0.2986907660961151, -0.07725712656974792, -0.00016668289026711136, 0.16925998032093048, 0.2806219756603241, -1.3184360265731812, -0.16815592348575592, 0.1896476000547409, 0.8139687180519104, -0.21898114681243896, 0.874299168586731, -0.5826018452644348, 0.37113094329833984, 1.1790345907211304, -0.045142535120248795, 0.3430774509906769, -0.5520203709602356, 0.3121867775917053, -1.067124605178833, -0.12540844082832336, -0.7261448502540588, 0.27475252747535706, -0.7975677251815796, -1.1889934539794922, -0.7249734997749329, -0.5332871079444885, 0.24827143549919128, -1.063764214515686, 0.5662815570831299, -0.19811615347862244, 0.7676533460617065, 0.045027799904346466, 0.5042493939399719, 0.7992271184921265, 0.8844443559646606, 0.4209030568599701, 0.7974964380264282, 0.9017515182495117, -1.5320652723312378, -0.32243016362190247, -1.1561509370803833, 0.38968467712402344, -0.22766603529453278, -0.4931016266345978, 0.2433614432811737, -1.2405061721801758, -1.2295445203781128, -0.7564958930015564, -0.025197729468345642, -0.5095872282981873, 0.4981682598590851, 1.2264344692230225, 0.3713153898715973, -0.8762000799179077, 0.9357603192329407, -0.6815061569213867, 0.3364236652851105, 0.9815955758094788, 0.459883451461792, 0.36834436655044556, -0.3386933207511902, -0.9788893461227417, 0.3390868902206421, 0.14575645327568054, -0.3528032600879669, -0.6848472952842712, -0.6993941068649292, -1.161901593208313, 0.4151381850242615, -0.015415177680552006, -0.48617950081825256, 1.059679388999939, -0.5377434492111206, -1.0486515760421753, 0.789376974105835, -0.6267837285995483, -0.18126212060451508, 0.1630365252494812, -0.08471512049436569, -0.5324510931968689, -0.3744366466999054, -0.4736563265323639, 0.9870118498802185, 1.0571935176849365, -0.25350427627563477, -0.144356831908226, 0.4246924817562103, -0.4541417062282562, -0.1408703327178955, -0.36901402473449707, 0.853321373462677, -0.4484519362449646, -0.3105730414390564, 0.44057002663612366, 0.7016226053237915, -0.4104643166065216, -0.47991058230400085, -0.5247210264205933, -0.6130321025848389, 0.5555191040039062, 0.037481412291526794, 0.46550559997558594, -1.014107584953308, -0.8644728064537048, 0.1189933717250824, 0.03428681939840317, 0.05203285440802574, -0.9144673943519592, 0.18228471279144287, -0.5808616876602173, 0.0020254114642739296, 0.05349769443273544, -1.3025826215744019, 0.13297177851200104, -0.5590085387229919, -0.6016587018966675, -0.19348101317882538, 0.31111717224121094, 0.8911149501800537, -0.8617009520530701, -0.06121721863746643, 0.18067559599876404, 0.7886713147163391, -1.2399979829788208, 0.6669044494628906, -0.27995485067367554, 0.10077698528766632, 0.058719564229249954, -0.19748395681381226, 0.1820606291294098, -0.3372715711593628, 0.3664928376674652, -0.8178479075431824, 0.15972276031970978, 0.7170904278755188, -0.6073922514915466, 1.5328640937805176, -0.5936077833175659, 0.5713248252868652, 0.3502015471458435, -0.9951659440994263, 0.0194933470338583, 0.5178928971290588, -0.049475133419036865, -0.35194504261016846, 0.6370803713798523, 0.5199979543685913, -0.5747308135032654, 0.39437806606292725, 0.7537235617637634, 0.9288855195045471, -0.017481641843914986, -0.0392957404255867, 0.6833983659744263, -0.15353576838970184, 0.45606136322021484, 0.6419128179550171, 0.683434247970581, 0.3907397389411926, 0.030509736388921738, 0.05010611563920975, -0.028120262548327446, -0.6805738806724548, -0.09995175898075104, 0.7530957460403442, 0.7605724930763245, 0.7018216252326965, 0.45171263813972473, -0.7785873413085938, -0.5482717752456665, 0.22425216436386108, 0.5779088139533997, 1.3008997440338135, -0.33547502756118774, 0.2420898824930191, -0.7560689449310303, -0.5290311574935913, -0.2561185359954834, -0.29353076219558716, -0.1481613665819168, 0.09552732110023499, -0.4084230363368988, -1.4112359285354614, 0.5225448608398438, 0.28633013367652893, 0.8015046119689941, -0.599643349647522, -0.48611244559288025, -0.3669101893901825, 0.45035311579704285, -0.8648796081542969, -0.5221524238586426, 0.9379178285598755, -0.7266271710395813, -0.06097351387143135, 0.07350258529186249, -0.26550960540771484, 0.7297255992889404, -0.4740670323371887, 1.1902071237564087, -0.5424807667732239, -0.576250433921814, -0.1349405199289322, 0.5168783068656921, -0.11285050213336945, -0.36267581582069397, 0.43305763602256775, -0.07841403037309647, -0.02476470172405243, 0.14344079792499542, -0.07109709829092026, -0.1096746101975441, -0.0449041873216629, -0.14009226858615875, 0.264774888753891, 0.3654925525188446, -0.12253501266241074, 1.075950026512146, -0.17002803087234497, 0.12854625284671783, -1.4262263774871826, 0.10888204723596573, -0.24139609932899475, -0.22777310013771057, -0.22125546634197235, -0.10268895328044891, -0.29131948947906494, 0.8065937757492065, -0.7882930040359497, -0.3335270583629608, -0.12121082097291946, -0.0922892689704895, -0.7049593329429626, -0.4081138074398041, -0.3009291887283325, 0.39176687598228455, -0.28858816623687744, 0.5401297211647034, 0.3583869934082031, -0.06589039415121078, 0.07569597661495209, 0.7103376984596252, -1.1593494415283203, 0.8086820244789124, 0.17085368931293488, 0.11128093302249908, 0.37621742486953735, -0.28062495589256287, -0.45174142718315125, -0.43396592140197754, -0.8089550137519836, -0.11702915281057358, -0.419228732585907, 0.08209440857172012, -0.8865262269973755, -0.9300451278686523, 0.06911773234605789, -0.97968989610672, -0.35731032490730286, 0.2237797975540161, 0.031891994178295135, -0.03744000568985939, -1.2230271100997925, -1.5050971508026123, -0.6585234999656677, -0.7466930150985718, -1.268781065940857, 0.3469737470149994, 0.12403899431228638, -0.29680466651916504, -0.30978214740753174, -0.25390681624412537, -0.44238704442977905, 1.228341817855835, -0.46709150075912476, 0.29640457034111023, -0.07930544763803482, -0.4287002384662628, -0.3851248323917389, -0.051544442772865295, 0.6218132376670837, -0.7915575504302979, 0.3622124493122101, -1.2258789539337158, 0.28169816732406616, -0.4806881248950958, -0.7668500542640686, 0.7790204286575317, 0.8312796354293823, 0.8585724234580994, 0.11874233186244965, -0.6098028421401978, 0.9091475009918213, 1.5494482517242432, -0.6480104327201843, 0.28873831033706665, -0.26619353890419006, 1.1794589757919312, 0.050462059676647186, -0.658623218536377, 0.6015791296958923, -0.0027255089953541756, 0.26219797134399414, 0.489206999540329, -0.34763169288635254, -0.26664644479751587, -0.4015273451805115, 0.5339306592941284, 1.4330129623413086, 0.8382694721221924, 0.1464547961950302, -0.6118067502975464, 0.858997642993927, -1.2833435535430908, -0.888739824295044, 0.32126349210739136, 0.4712241291999817, -0.043375078588724136, -0.1252031773328781, -0.10831030458211899, -0.3289050757884979, 0.6061331033706665, 0.7200334072113037, -0.5845967531204224, -0.588179886341095, 0.024082569405436516, 0.8277662992477417, 0.4277847409248352, 0.4790504276752472, -0.3520861268043518, 0.5464054346084595, 14.392171859741211, 1.4057303667068481, -0.2562347650527954, 0.6104117631912231, 1.0947413444519043, -0.017383916303515434, -0.3169563412666321, -0.036246009171009064, -1.5332214832305908, 0.024755841121077538, 1.0415947437286377, 1.0912154912948608, 0.8674699664115906, 0.7022238373756409, -0.07529667764902115, -0.09052791446447372, -0.602709174156189, 0.9552719593048096, 0.6050339341163635, -1.4540263414382935, -0.2306039184331894, -0.16058336198329926, 0.8639470338821411, 0.9152364730834961, 0.9417508840560913, 1.00507390499115, 0.5733184814453125, -0.7251446843147278, 0.5977126359939575, 0.4281659722328186, 0.7847841382026672, 0.08347367495298386, 0.2063760757446289, 0.42450299859046936, -1.1310508251190186, 0.23673877120018005, -0.4892119765281677, -0.8141965866088867, 0.24519620835781097, 0.512139618396759, -0.4886188805103302, -0.5870988368988037, 0.11395058780908585, 1.1759353876113892, 0.3466016948223114, 0.6004157066345215, 0.11503671854734421, 0.45978865027427673, -0.5436599254608154, 0.35825738310813904, 0.30482760071754456, 0.39614784717559814, -0.11560944467782974, 0.3777909576892853, 0.03468548133969307, -0.044554974883794785, 0.1313503235578537, 0.6732487678527832, -0.46358898282051086, -0.5135617852210999, -0.034287117421627045, -0.03939184918999672, -0.3434050977230072, 1.3782968521118164, 0.024830512702465057, -0.1165902316570282, -0.420089453458786, 0.3730027973651886, 0.462592214345932, -0.07062966376543045, -0.4453369975090027, -0.052325911819934845, 0.05984845012426376, -0.6948966979980469, 0.43734586238861084, 0.8434070348739624, -0.5717827081680298, -0.8659404516220093, -0.8599684834480286, -0.7051073312759399, 0.2680412828922272, -0.6925581097602844, -0.6257339715957642, 1.0565420389175415, -0.45742732286453247, -0.3194931447505951, 0.4822266101837158, -0.7860823273658752, -0.4936770796775818, 0.6362869739532471, -1.315098524093628, -0.482505202293396, 0.1764620691537857, -0.5513144731521606, -0.49040308594703674, -0.15436698496341705, 0.9793403744697571, 0.45123356580734253, -0.3041731119155884, -0.18084724247455597, 0.0772257000207901, 0.02520645223557949, -0.3992381691932678, -0.4783024191856384, 1.2435771226882935, 0.5317934155464172, 0.038694508373737335, -0.1888815015554428, -0.07782852649688721, 0.23466086387634277, -0.3171112835407257, 0.059892814606428146, 0.48360610008239746, -0.5386967062950134, -0.3829714357852936, -0.7410615682601929, -0.6221593618392944, 0.2959548234939575, 0.47552937269210815, 0.3443440794944763, 0.29005661606788635, 0.1582881212234497, -0.8321592211723328, -0.27924543619155884, -0.6640944480895996, -0.2911571264266968, 0.17480577528476715, -0.6796666979789734, 0.027073567733168602, -0.11726551502943039, -0.4070369303226471, -1.2882130146026611, -0.4726247191429138, -0.2443343549966812, 0.41880300641059875, -0.545278787612915, 1.2481390237808228, -0.23565450310707092, 0.8349320888519287, 0.8031821250915527, 0.020774591714143753, -0.9220293760299683, 0.3978012800216675, -0.5608759522438049, -0.22795474529266357, 0.006774581968784332, 0.2856173813343048, -0.055661771446466446, 0.9414979815483093, 0.3596879243850708, -0.12393703311681747, -0.5257644057273865, -0.4421190023422241, -0.12445651739835739, -0.3419716954231262, -0.6356133222579956, 0.01804344914853573, -0.01069847121834755, -0.04926203936338425, -0.1744936853647232, 0.275397926568985, 0.24473966658115387, -0.0006588247488252819, -0.7739114165306091, 0.4552941620349884, 0.1863965094089508, -0.4973280131816864, -0.7255025506019592, -0.24407070875167847, -1.5878331661224365, 0.1304178386926651, -1.2784978151321411, 0.21787159144878387, -0.8017874956130981, -0.46763089299201965, -0.297136127948761, -0.326067179441452, 0.3282219469547272, 0.38128870725631714, 0.003989957273006439, -0.4713318943977356, -0.8442062139511108, -0.8119487166404724, 0.6834757328033447, 0.6476127505302429, -0.7669203877449036, 0.04756952077150345, -0.07846993952989578, 0.31130948662757874, 0.557602047920227, 0.38007116317749023, -0.670579731464386, -0.4891144633293152, -1.3977363109588623, 0.3641507625579834, 0.16191428899765015, 0.04777034372091293, -1.3304200172424316, 0.6950901746749878, 0.7558857202529907, 0.004412404727190733, -0.08509150892496109, 0.5136201977729797, -0.9980723261833191, -0.28853532671928406, 0.5007653832435608, -0.6756904721260071, -0.3502922058105469, 0.5460454821586609, -0.6624941825866699, -0.3718014657497406, 0.4989757537841797, 0.3054216504096985, -1.1310714483261108, -0.9262856841087341, 0.49393078684806824, -0.5081278681755066, 0.17459198832511902, -0.5135796666145325, -0.2262495756149292, -1.2131147384643555, -0.3105567395687103, -0.19268165528774261, 0.3810928761959076, -0.5275013446807861, 0.4451006054878235, 0.28781405091285706, -1.0363260507583618, 0.0995568186044693, 0.26695579290390015, -0.528249979019165, 0.30686017870903015, 1.151694655418396, 0.7666314244270325, -0.5769362449645996, 0.32960188388824463, -0.09761762619018555, 0.32183152437210083, -0.5079262256622314, 0.011460200883448124, 1.085449457168579, -0.7654078602790833, -0.11729465425014496, 1.3541558980941772, -0.23325036466121674, -0.7999507188796997, 0.42431411147117615, -1.0345394611358643, -0.4486270844936371, -0.234829381108284, 0.5094497203826904, 0.3324701189994812, 0.31983932852745056, -0.2636362314224243, -0.6316382884979248, 0.121379055082798, -0.11872628331184387, -0.5142132043838501, 0.7183488011360168, 0.4062527120113373, -0.2854323089122772, 0.3073657751083374, 0.7904202342033386, -0.5854535698890686, -1.0554746389389038, -0.7099913954734802, -0.8966013789176941, -0.08799190074205399, 0.4938223659992218, -0.2952796220779419, -1.3309303522109985, 1.1751689910888672, 0.4222564995288849, 0.036816537380218506, 0.02930767834186554, -0.4020826816558838, 0.5731812119483948, 0.4677572548389435, -0.2615826427936554, -0.7321603894233704, -0.5553012490272522, 1.177901029586792, 0.5174635648727417, -1.0744022130966187, -0.044749271124601364, -0.4299505352973938, -0.7171379327774048, 0.6124610900878906, 0.5536709427833557, -0.5555942058563232, 0.7309850454330444, -0.025436732918024063, -0.21494881808757782, 0.39125239849090576, -0.782210648059845, -0.46495717763900757, 1.041748285293579, 1.0441780090332031, 0.48676061630249023, -0.10690168291330338, 0.6437662839889526, 0.8235239386558533, 0.31526052951812744, -0.1985069066286087, -0.057518452405929565, 0.24167712032794952, -0.09645088016986847, 0.04635189473628998, -0.11824535578489304, 1.1362535953521729, -0.969325065612793, -0.9477776288986206, 0.6632879972457886, 0.26353365182876587, 0.808968722820282, 0.5688686370849609, 0.9255837202072144, -0.005524842068552971, 0.3550986051559448, -0.2379157692193985, 0.6626657843589783, -0.5308396220207214, -0.6081805229187012, 0.17144644260406494, -0.6574823260307312, -0.21970245242118835, -0.24157975614070892, -0.17959702014923096, -0.1977437287569046, -0.4871390461921692, 0.45650964975357056, -0.04311973229050636, 0.41113248467445374, 1.0267959833145142, 0.4244146943092346, 1.0492640733718872, -0.3435923755168915, -1.117687702178955, 0.03666657954454422, -0.7471060752868652, -0.018925374373793602, -0.540424644947052, -0.14623364806175232, 0.08334629982709885, -0.15694575011730194, -0.04187895357608795]}, "authors": [{"authorId": "2066558041", "name": "Trevor Gale"}, {"authorId": "22252150", "name": "D. Narayanan"}, {"authorId": "39660914", "name": "C. Young"}, {"authorId": "143834867", "name": "M. Zaharia"}], "references": [{"paperId": "2e700ff36108119f5ed19a53bd2eaa22b42ec3d8", "title": "Tutel: Adaptive Mixture-of-Experts at Scale"}, {"paperId": "bc8b82e8eb0b0714892e4ec7a54ebdf47c4fde96", "title": "Reducing Activation Recomputation in Large Transformer Models"}, {"paperId": "0dab58e476f3f0e6f580a295f7c4756c86f1f198", "title": "FasterMoE: modeling and optimizing training of large-scale dynamic pre-trained models"}, {"paperId": "bbc57e1b3cf90e09b64377f13de455793bc81ad5", "title": "Mixture-of-Experts with Expert Choice Routing"}, {"paperId": "c2536182c010c41941e8a031071a1880c34cec60", "title": "Unified Scaling Laws for Routed Language Models"}, {"paperId": "fb01415a0decfa3f3d6339930e95028ae1ff4170", "title": "Efficient Large Scale Language Modeling with Mixtures of Experts"}, {"paperId": "80d0116d77beeded0c23cf48946d9d10d4faee14", "title": "GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"}, {"paperId": "8690d62d4bbbd0b1ed5e1f25320d10853bfbeb01", "title": "Scaling Vision with Sparse Mixture of Experts"}, {"paperId": "0611d2f2ea6a3c8fb8534f42758a5a3e9c7bc8fe", "title": "Hash Layers For Large Sparse Models"}, {"paperId": "774591fdd988eaaff3917e7c5171d044b0843e63", "title": "Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM"}, {"paperId": "b15ea460c77a4ee8aa159a30ab0331deedfcf392", "title": "BASE Layers: Simplifying Training of Large, Sparse Models"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "1882f194cb43828852cc052887671e55a80f945a", "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"}, {"paperId": "70e9a09de05aa7ed8a74d56cf2d13ea9e38a6328", "title": "Sparse GPU Kernels for Deep Learning"}, {"paperId": "ac04ed0f3ae0f5b269c9b3e0d1232007d60dbf7e", "title": "Memory-Efficient Pipeline-Parallel DNN Training"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "db2d3dc613169b519f1a2dd35e0473dc2e848025", "title": "Fast Sparse ConvNets"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "661d142c23cb2a3207d5f1ba2ac7ff61f2d4fb2f", "title": "Triton: an intermediate language and compiler for tiled neural network computations"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "26384278cf5d575fc32cb92c303fb648fa0d5217", "title": "The State of Sparsity in Deep Neural Networks"}, {"paperId": "9dad5f3b491fba9496c90bb7cfe10d1c0f00fadc", "title": "Balanced Sparsity for Efficient DNN Inference on GPU"}, {"paperId": "dbb774a68de152d9b0f80d5eb4744d2995425b5c", "title": "HiCOO: Hierarchical Storage of Sparse Tensors"}, {"paperId": "f2c882fd290d616ff96c1c5d6af4578682e26556", "title": "Efficient Neural Audio Synthesis"}, {"paperId": "56257b0804c9c2418b32337d3af0970f7b67b084", "title": "Block-Sparse Recurrent Neural Networks"}, {"paperId": "e7fd6848cb29ca221a7e17d823e06fb566f1f135", "title": "Mixed Precision Training"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "2dfeb5a90abc49ab2a80a492a01a4e2c8e92ec22", "title": "In-datacenter performance analysis of a tensor processing unit"}, {"paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586", "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"}, {"paperId": "91c587158d19fdaeda6b453efa54064543a03e9d", "title": "Tensor-matrix products with a compressed sparse tensor"}, {"paperId": "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff", "title": "Learning both Weights and Connections for Efficient Neural Network"}, {"paperId": "0c0800259bd40b1ac96cc437629c5ea0ad729f22", "title": "Parallel sparse matrix-vector and matrix-transpose-vector multiplication using compressed sparse blocks"}, {"paperId": null, "title": "Mosaic LLMs (Part 2): GPT-3 Quality for <$500k"}, {"paperId": null, "title": "21: The International Conference for High Performance Computing, Networking, Storage and Analysis, St. Louis, Missouri, USA, November 14 "}, {"paperId": null, "title": "NVIDIA A100 Tensor Core GPU Architecture"}, {"paperId": null, "title": "Computer Vision Foundation / IEEE"}, {"paperId": null, "title": "NVIDIA. Accelerating matrix multiplication with block sparse format and nvidia tensor cores"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Training with Mixture-of-Experts AAAI 2019, The Thirty-First Innovative Applications of Arti\ufb01cial Intelligence Conference"}, {"paperId": null, "title": "SparseMatrix c) {"}, {"paperId": null, "title": "Installation Follow"}, {"paperId": null, "title": "Evaluation and expected result Once inside the Docker container with MegaBlocks installed ( \u00a7D.4), run 'python megablocks/ layers /dmoe_test.py'. After passing, the test suite will print \"OK"}, {"paperId": null, "title": "MosaicML"}, {"paperId": null, "title": "Zero accumulator tile"}, {"paperId": null, "title": "Language MegaBlocks: Efficient Sparse Training with Mixture-of-Experts Models are Few-Shot Learners"}, {"paperId": null, "title": "* / 8 __global__ void sdd(Matrix a, Matrix b"}, {"paperId": null, "title": ") Load row and column indices"}, {"paperId": null, "title": "* b: Dense, right input with shape (k, n)"}]}