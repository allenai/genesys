{"paperId": "bc7984bfcfae537dbe633eeeb8d69c42a994c724", "title": "ELLE: Efficient Lifelong Pre-training for Emerging Data", "abstract": "Current pre-trained language models (PLM) are typically trained with static data, ignoring that in real-world scenarios, streaming data of various sources may continuously grow. This requires PLMs to integrate the information from all the sources in a lifelong manner. Although this goal could be achieved by exhaustive pre-training on all the existing data, such a process is known to be computationally expensive. To this end, we propose ELLE, aiming at efficient lifelong pre-training for emerging data. Specifically, ELLE consists of (1) function preserved model expansion, which flexibly expands an existing PLM\u2019s width and depth to improve the efficiency of knowledge acquisition; and (2) pre-trained domain prompts, which disentangle the versatile knowledge learned during pre-training and stimulate the proper knowledge for downstream tasks. We experiment ELLE with streaming data from 5 domains on BERT and GPT. The results show the superiority of ELLE over various lifelong learning baselines in both pre-training efficiency and downstream performances. The codes are publicly available at https://github.com/thunlp/ELLE.", "venue": "Findings", "year": 2022, "citationCount": 52, "influentialCitationCount": 4, "openAccessPdf": {"url": "http://arxiv.org/pdf/2203.06311", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "The proposed ELLE consists of function preserved model expansion, which flexibly expands an existing PLM\u2019s width and depth to improve the efficiency of knowledge acquisition, and pre-trained domain prompts, which disentangle the versatile knowledge learned during pre-training and stimulate the proper knowledge for downstream tasks."}, "embedding": {"model": "specter_v2", "vector": [0.09236790239810944, 0.2686604857444763, -0.7458084225654602, -0.14857245981693268, -0.19035707414150238, -0.6121446490287781, 0.8297654390335083, -0.0018385914154350758, -0.5866007804870605, 0.14810951054096222, 0.30619561672210693, -0.08155599236488342, 0.3100195825099945, 0.21540921926498413, -0.5699691772460938, 0.5483996272087097, -1.1942787170410156, 0.6354640126228333, 0.08264928311109543, -0.8160775899887085, -0.44422978162765503, -0.5641083121299744, -0.9119088053703308, -0.05344286561012268, 0.8616489171981812, 0.4493829309940338, 0.2383052408695221, 1.165913701057434, -0.23914611339569092, 0.2633199691772461, 0.29455819725990295, -0.2176610231399536, 0.3975166976451874, 0.07160817086696625, -0.4438226521015167, -0.07042946666479111, 0.29408395290374756, -0.6549519300460815, -0.43107691407203674, 0.4126122295856476, -0.3978971540927887, 0.27767136693000793, 0.18337400257587433, -0.6835043430328369, -0.6355977058410645, 0.611956000328064, 1.275997281074524, 0.6403385400772095, -0.0009251215378753841, -0.7137627005577087, 1.3364118337631226, -1.624475121498108, 0.5136741399765015, 0.950038731098175, 0.4107343554496765, 0.6098180413246155, -0.05577968433499336, -0.5739962458610535, 0.8499262928962708, -0.004903196822851896, -0.4041758179664612, -0.19726833701133728, -0.032557979226112366, -0.1875196397304535, 1.7319051027297974, -0.5270532369613647, 0.3467786908149719, 0.8260796070098877, -0.46201661229133606, 1.5316990613937378, -0.5705462694168091, -0.6642662286758423, -0.395797461271286, 0.35470980405807495, 0.22623410820960999, 0.7449696063995361, -0.5255292654037476, 0.5034112930297852, -1.06083345413208, 0.10967961698770523, 0.4697309732437134, 0.1714351624250412, -0.15640871226787567, -0.03473576158285141, -0.11326617747545242, 0.47167035937309265, 0.36680951714515686, 0.8202139139175415, -0.28013989329338074, 0.251626580953598, 0.3338891863822937, 0.7178425788879395, 0.3739740252494812, 0.42707332968711853, -0.7337530255317688, -0.07526785880327225, -0.7744527459144592, 0.5627248883247375, -0.052130721509456635, 0.999422013759613, -0.17489199340343475, -0.17879259586334229, -0.40581491589546204, 0.4018593430519104, 1.1215438842773438, 0.03435955569148064, 0.714552104473114, -0.6415247917175293, 0.4292709529399872, -0.33825981616973877, 0.4502943158149719, -0.3919186294078827, -0.29372578859329224, -0.4012243151664734, -0.4650655686855316, -1.726412057876587, -0.3414863646030426, -0.32391443848609924, -0.7845624685287476, 0.8772904276847839, -0.26821571588516235, 0.36671462655067444, 0.40299639105796814, 0.38460773229599, 0.7721471786499023, 0.9180251359939575, -0.02203659527003765, -0.15254992246627808, 0.4644753038883209, -1.0405364036560059, -0.5508207082748413, -1.155689001083374, 0.7896348237991333, 0.19594235718250275, 0.3749925494194031, -0.1010965034365654, -1.4303897619247437, -1.0757066011428833, -0.856785237789154, -0.06764440983533859, -0.9804139733314514, -0.0030185654759407043, 1.0285149812698364, 0.17683455348014832, -1.0566343069076538, 0.8203019499778748, -0.06462980061769485, -0.2912183403968811, 0.3114335238933563, 0.13286548852920532, 0.1991606503725052, -0.7358914613723755, -1.63217031955719, 0.2549475431442261, 0.3712911307811737, -0.6819649934768677, -0.375767320394516, -0.6029391288757324, -0.9474741816520691, -0.31229349970817566, 0.3400392532348633, -0.34628060460090637, 1.5504063367843628, -0.44592559337615967, -1.3487218618392944, 0.5759716629981995, -0.21109932661056519, -0.07085913419723511, 0.4298166334629059, -0.3566380441188812, -0.9058510661125183, -0.27813488245010376, -0.29029974341392517, 0.5625499486923218, 0.30037161707878113, -0.06276580691337585, -0.4204741418361664, 0.15301918983459473, -0.2308710515499115, 0.10501499474048615, -0.5476570725440979, 0.4912603199481964, -0.5889967083930969, -0.0996183305978775, 0.0628134161233902, 0.9860979318618774, 0.0906359851360321, -0.4680028557777405, 0.24029310047626495, -1.175260066986084, 0.8503621220588684, -0.32340171933174133, 0.9807769656181335, -1.0577516555786133, -0.6539105772972107, -0.2566237151622772, -0.2656917870044708, 0.21538220345973969, -1.128959059715271, 0.8620781302452087, 0.007153278216719627, 0.12488945573568344, -0.0701206624507904, -1.2433582544326782, -0.09334845840930939, -0.0016393419355154037, -0.7759895324707031, -0.6218963265419006, 0.37988218665122986, 1.3009612560272217, -1.4434475898742676, 0.3327706754207611, -0.2984763979911804, 0.21405403316020966, -1.310246467590332, 1.1307111978530884, -1.1151885986328125, 0.27854642271995544, -0.01762167550623417, 0.10638198256492615, -0.0720096006989479, -0.2235720306634903, 0.2589995563030243, 0.13184908032417297, 0.012886527925729752, 0.3617304265499115, -0.29852643609046936, 1.7050747871398926, -0.33910471200942993, 0.47139281034469604, -0.14857038855552673, -0.6469985246658325, 0.39102858304977417, 0.650922417640686, 0.12789610028266907, -0.4449584186077118, -0.047621335834264755, 0.7116795778274536, -0.9170916676521301, 9.599937766324729e-05, 1.0293586254119873, 0.5560765266418457, -0.27643388509750366, -0.2641330361366272, 0.902729868888855, -0.034121960401535034, 0.7536741495132446, 0.35926949977874756, 0.563071608543396, 0.4027476906776428, 0.11237061768770218, 0.3206673860549927, 0.4072284698486328, -0.6040507555007935, 0.08347722142934799, 0.2763746678829193, 0.6347142457962036, 0.44128960371017456, -0.013089700601994991, -0.5586410164833069, -0.013953590765595436, 0.015122919343411922, 0.7298323512077332, 1.807995319366455, 0.0064178998582065105, -0.2848566174507141, -0.6026122570037842, -0.5951294302940369, -0.03850172087550163, 0.2144225835800171, -0.097128726541996, -0.01785145327448845, -0.5826820731163025, -0.6363953351974487, 0.42964980006217957, 0.40942928194999695, 1.1238223314285278, -0.5963674187660217, -0.20082330703735352, 0.13974569737911224, 0.01684851571917534, -0.5948956608772278, -0.6530897617340088, 0.15042869746685028, -0.6580763459205627, -0.09617423266172409, -0.2090226262807846, -0.47577810287475586, 0.21384169161319733, -0.8282361626625061, 0.9320785403251648, -0.3842197358608246, 0.03981250897049904, 0.6580678224563599, 0.2180628627538681, -0.5907302498817444, -0.7280866503715515, 0.13002121448516846, 0.13386867940425873, -0.22152946889400482, 0.1354423314332962, 0.4339613616466522, 0.12024965137243271, -0.05394773557782173, -0.5088657736778259, 0.14942148327827454, -0.11189233511686325, 0.014686045236885548, 0.5938293933868408, 0.08914712071418762, 0.7291598320007324, -1.498871088027954, 0.8250924348831177, -0.3188576400279999, -0.5809367895126343, 0.2798222303390503, -0.59146648645401, -0.706292986869812, 0.8721462488174438, -0.9863932132720947, -0.2570292055606842, -1.0310834646224976, 0.3636873960494995, -0.12114080041646957, -0.27981096506118774, 0.7214633822441101, 0.26514241099357605, 0.6770760416984558, 0.37383604049682617, 0.5186712145805359, -0.0538293719291687, -0.2730507254600525, 0.7460355162620544, -0.8672907948493958, 0.7071199417114258, 0.12375250458717346, 0.12602660059928894, -0.36020800471305847, -0.23862861096858978, -0.8592253923416138, -0.568116307258606, -0.6148808598518372, -0.4653511345386505, -0.31315186619758606, -0.1976468712091446, -0.6354072093963623, -0.24605396389961243, 0.05827939882874489, -1.0938920974731445, -0.7553077340126038, -0.12534862756729126, -0.33272939920425415, -0.44595494866371155, -1.40603768825531, -0.9039153456687927, -0.513893187046051, -0.3089357614517212, -0.36241331696510315, 0.2990477979183197, 0.006658215541392565, -0.22715379297733307, -1.2040060758590698, 0.3353937864303589, -0.3885185122489929, 0.9952887296676636, -0.3881117105484009, 0.7497041821479797, -0.12411302328109741, -0.06870658695697784, -0.3911570906639099, 0.4742646813392639, 0.7640546560287476, -0.06916555017232895, 0.07612331956624985, -0.7434950470924377, -0.025371886789798737, -0.31116604804992676, -0.4010961949825287, 0.07110970467329025, 0.22281773388385773, 0.39216098189353943, -0.13335271179676056, -0.38231921195983887, 0.3790276348590851, 1.4398819208145142, -0.397208571434021, -0.26678964495658875, -0.13723023235797882, 0.5975797772407532, 0.37744247913360596, -0.03574239835143089, 0.34665024280548096, 0.5905624628067017, -0.020538773387670517, -0.13405442237854004, -0.07517331093549728, 0.14063307642936707, -1.1807997226715088, 0.8854365348815918, 1.8256070613861084, 0.34924471378326416, -0.29398298263549805, -1.182263731956482, 0.9584956169128418, -1.4183223247528076, -0.30909499526023865, 0.8912714123725891, 0.6841806769371033, 0.7662363648414612, -0.6369649171829224, 0.026694880798459053, -0.47689729928970337, 0.19231219589710236, 0.158111110329628, -0.8487997055053711, -0.3142406940460205, 0.054654620587825775, 0.402773916721344, -0.06537069380283356, 0.706768810749054, -0.23807686567306519, 0.7064492106437683, 14.501649856567383, 0.7595483064651489, 0.04715130478143692, 0.7665331363677979, 0.376314252614975, 0.17993754148483276, -0.40006113052368164, -0.3315070867538452, -1.2538999319076538, -0.09536994993686676, 1.5082610845565796, 0.12248740345239639, 0.9211041331291199, -0.06865867227315903, -0.08708232641220093, 0.2530910074710846, -0.8930756449699402, 0.5262676477432251, 0.5041542053222656, -1.2214767932891846, 0.2861582338809967, 0.0915149673819542, 0.5097431540489197, 0.7608421444892883, 0.9590884447097778, 1.1866930723190308, 0.49059367179870605, -0.18364843726158142, 0.6245316863059998, 0.3904045820236206, 1.1747443675994873, 0.0729740783572197, 0.4138031005859375, 1.007021188735962, -0.6616246700286865, -0.42187708616256714, -0.350229412317276, -1.231703519821167, 0.3037412166595459, -0.21784080564975739, -0.597809374332428, -0.23719505965709686, -0.4485327899456024, 1.238560438156128, 0.02112244814634323, -0.04890180379152298, -0.112178735435009, 0.785330057144165, -0.18509498238563538, 0.17725257575511932, 0.2192377746105194, 0.45024147629737854, 0.3458291292190552, -0.15204313397407532, 0.3034839928150177, -0.17623105645179749, 0.13842539489269257, 0.3903459310531616, -0.785965621471405, 0.08899038285017014, -0.7862404584884644, -0.4273809790611267, -0.0447402223944664, 0.4366920292377472, 0.8183814883232117, 0.15009477734565735, -0.7601808309555054, 0.42209693789482117, 0.5435218811035156, 0.46564874053001404, -0.025234170258045197, 0.3970881700515747, 0.09226378798484802, -0.08764953911304474, -0.22839415073394775, 0.5265494585037231, 0.10343633592128754, -0.6525152921676636, -0.47248339653015137, -0.29914379119873047, 0.5950214266777039, -0.5990065932273865, -0.8918168544769287, 0.5522792339324951, -0.14237813651561737, -0.5761233568191528, -0.36052221059799194, -0.7123993039131165, -0.08073195070028305, 0.23313720524311066, -1.4492496252059937, -0.7122872471809387, 0.41876864433288574, -0.029128605499863625, -0.28582194447517395, -0.3280181288719177, 1.3485798835754395, 0.32180362939834595, -0.23277892172336578, -0.14620205760002136, 0.3735242784023285, -0.2576242685317993, -0.32458630204200745, -0.8668356537818909, 0.8192684650421143, 0.21325230598449707, 0.2172081172466278, 0.026717808097600937, -0.3717913329601288, -0.18780314922332764, -0.945960283279419, -0.44173136353492737, 0.8431838750839233, -1.1373746395111084, -0.48041507601737976, -0.8996219635009766, -0.8718997240066528, 0.6653578877449036, 0.5690943598747253, -0.3845618665218353, 0.3301510214805603, 0.38776451349258423, -0.3492450714111328, -0.13913074135780334, -1.018980860710144, -0.019871551543474197, 0.6773868203163147, -0.3882518708705902, -0.285248339176178, 0.1406053900718689, 0.8014974594116211, -0.9690044522285461, -0.4760364294052124, -0.10277109593153, -0.11939825117588043, 0.058394525200128555, 0.8473954200744629, -0.22113506495952606, 0.3906145393848419, 1.1090062856674194, -0.17299139499664307, -1.136203408241272, 0.3008297383785248, -1.0406712293624878, -0.2891591787338257, 0.3472285866737366, 0.919786274433136, -0.6946601271629333, 0.13060830533504486, 0.7842278480529785, 0.3421643078327179, -0.5946464538574219, -0.34450551867485046, -0.5567398071289062, 0.24911481142044067, -0.5251650214195251, 0.4964515268802643, 0.14785826206207275, 0.002021525986492634, 0.4776113033294678, 0.664834201335907, 0.30343833565711975, -0.5204581022262573, -0.9604186415672302, 0.6321314573287964, -0.23523318767547607, -0.1625145822763443, -0.3278098702430725, -0.02549893967807293, -1.711612582206726, -0.09117121249437332, -1.5172902345657349, -0.04942380636930466, -0.886498749256134, -0.7109225988388062, 0.044988784939050674, -0.385415643453598, -0.22513382136821747, 0.4782315790653229, -0.8258426785469055, -0.38050252199172974, -0.6976222395896912, -0.5597416758537292, 0.8155521154403687, 1.2307486534118652, -0.30403217673301697, -0.31100162863731384, -0.1251211166381836, 0.19414839148521423, 0.32362091541290283, 0.4827185869216919, -0.1371435523033142, -1.0999717712402344, -1.3087570667266846, 0.46362295746803284, 0.032513055950403214, -0.13331472873687744, -0.36243852972984314, 0.5243982076644897, 0.2863759696483612, -0.3737952709197998, -0.286975622177124, 0.346788614988327, -1.0687522888183594, -0.5784237384796143, -0.04806213080883026, -0.6477102637290955, 0.09101366251707077, 0.44792231917381287, -0.5455026030540466, -0.6004375219345093, 0.6475512385368347, -0.2561064660549164, -0.7898452877998352, -0.8968239426612854, 0.817683756351471, -0.14841751754283905, 0.4064492881298065, -0.33740663528442383, 0.058918774127960205, -1.2642236948013306, -0.6688495874404907, 0.029529670253396034, 0.8901149034500122, -0.4124830663204193, 0.99957275390625, 0.5732351541519165, -1.2822160720825195, -0.141750305891037, 0.8631247878074646, 0.05157363787293434, 0.5643386840820312, 0.5693165063858032, 0.18620629608631134, -0.19429253041744232, 0.569213330745697, 0.3821544349193573, 0.3454100489616394, -0.4568219780921936, -0.008357630111277103, 0.6684832572937012, -0.7631976008415222, -0.1685013622045517, 1.3021210432052612, -0.4694165587425232, -1.3509052991867065, 0.20605267584323883, -1.2651598453521729, -0.5370771884918213, -0.37911441922187805, 0.4956200420856476, 0.21487724781036377, -0.3792153298854828, 0.04243999719619751, -0.23771297931671143, 0.14442050457000732, 0.012543727643787861, -0.6469498872756958, 1.0195343494415283, -0.14750346541404724, 0.04164626821875572, 1.046011209487915, 0.8898695111274719, -0.7483460903167725, -0.9181807637214661, -0.9591286778450012, -0.2880905568599701, 0.003936472348868847, 0.14025461673736572, -0.9833502769470215, -0.15779250860214233, 0.5736613869667053, 0.24748405814170837, 0.6049139499664307, 0.44738590717315674, 0.09729114919900894, 0.5926927328109741, 0.6422773599624634, 0.17930923402309418, -0.941382884979248, -0.29363468289375305, 1.3854478597640991, 1.583357334136963, -1.048660159111023, -0.03158688172698021, -0.16988679766654968, -0.5675956606864929, 0.6330302357673645, 0.41345125436782837, -0.007016935385763645, 1.0151256322860718, -0.6335864067077637, 0.09156312793493271, 0.1678543984889984, -1.3464373350143433, -0.15187600255012512, 0.8904879689216614, 1.114914059638977, 0.4313323497772217, 0.44208061695098877, 0.34498441219329834, 0.9644669890403748, -0.05409109592437744, 0.4761686623096466, 0.12395311892032623, 0.22523412108421326, -0.2711542248725891, -0.33937910199165344, 0.3005657494068146, 0.5355305671691895, -0.2315128594636917, -0.3421371281147003, 0.06120667979121208, 0.6344302296638489, 0.6161742806434631, 0.6212138533592224, 0.6319113969802856, 0.17727531492710114, 0.7793199419975281, 0.40991660952568054, 0.6758183240890503, -0.7759339809417725, -0.06703706830739975, -0.2758481800556183, -0.6509326696395874, 0.24479174613952637, -0.16091133654117584, -0.5868815779685974, -0.32282811403274536, 0.0589059479534626, 0.6102867126464844, -0.061365094035863876, 0.18210898339748383, 0.9922183156013489, 0.6262462735176086, 0.17480920255184174, -0.2607174217700958, -0.03171698376536369, -0.3066159784793854, -1.0768003463745117, -0.05588459596037865, -0.13913796842098236, 0.09047427773475647, -0.2888152003288269, -0.03641794994473457, -0.2282877117395401]}, "authors": [{"authorId": "50625437", "name": "Yujia Qin"}, {"authorId": "2107983722", "name": "Jiajie Zhang"}, {"authorId": "2149202150", "name": "Yankai Lin"}, {"authorId": "2141313179", "name": "Zhiyuan Liu"}, {"authorId": "144326610", "name": "Peng Li"}, {"authorId": "1753344", "name": "Maosong Sun"}, {"authorId": "49178343", "name": "Jie Zhou"}], "references": [{"paperId": "ed8931af08ce757a92a01ed43a0619522e10e8ff", "title": "Lifelong Pretraining: Continually Adapting Language Models to Emerging Corpora"}, {"paperId": "7a49beff86a855f237f96ae3f0aefc9780cb31be", "title": "bert2BERT: Towards Reusable Pretrained Language Models"}, {"paperId": "ce828f9986b196308a3e40b1de58af1e8e68d728", "title": "Towards Continual Knowledge Learning of Language Models"}, {"paperId": "917c63f2186119166b3379f5d2816bb1a2f39b09", "title": "DEMix Layers: Disentangling Domains for Modular Language Modeling"}, {"paperId": "ac8d33e4c0a45e227a47353f3f26fbb231482dc1", "title": "Time-Aware Language Models as Temporal Knowledge Bases"}, {"paperId": "feba0c47bf12a02c3a725174bb53df78658a72a8", "title": "Pre-Trained Models: Past, Present and Future"}, {"paperId": "448af0627240e46df757e7b9c640ee30507c18e9", "title": "On the Effectiveness of Adapter-based Tuning for Pretrained Language Model Adaptation"}, {"paperId": "981995fd64611f475179b280f4e9c241051ac185", "title": "Knowledge Inheritance for Pre-trained Language Models"}, {"paperId": "2310d893abf4ec900cb9e0c5da58284a37329780", "title": "Accelerating Training of Transformer-Based Language Models with Progressive Layer Dropping"}, {"paperId": "a5d6b9ed787b558e20d61bd8f5816317ef1b9a39", "title": "On the Transformer Growth for Progressive BERT Training"}, {"paperId": "f46c562229c5bc419bbbfb63239431590e4b340a", "title": "Train Big, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers"}, {"paperId": "e816f788767eec6a8ef0ea9eddd0e902435d4271", "title": "Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "3161e2b6787d304c29dddb7d5fc188ca41be7bda", "title": "LAMOL: LAnguage MOdeling for Lifelong Language Learning"}, {"paperId": "3c5f1ab37f70db503636075e15b3173f86eea00b", "title": "Green AI"}, {"paperId": "45c0654f173f870165a880d2b63bae54ae4b4982", "title": "Blackbox Meets Blackbox: Representational Similarity & Stability Analysis of Neural Language Models and Brains"}, {"paperId": "94e43de5dca9355a60a225565aa26bd1cc065c3e", "title": "Episodic Memory in Lifelong Language Learning"}, {"paperId": "fc089a09074c84979d1f34e89341318a5bc26d3d", "title": "SemEval-2019 Task 4: Hyperpartisan News Detection"}, {"paperId": "ad7129af0644dbcafa9aa2f111cb76526ea444a1", "title": "Defending Against Neural Fake News"}, {"paperId": "5a3749929bf5fb8b1f98a7b2a43c3b957bcf6c88", "title": "Efficient Training of BERT by Progressively Stacking"}, {"paperId": "bc789aef715498e79a74f857fa090ece9e383bf1", "title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "9c54962b0fd011d5fe3f5b5275cc6ba091a2c7ae", "title": "On Tiny Episodic Memories in Continual Learning"}, {"paperId": "d9ff7a9344dd5d6653bd7a02bfd704422bb29951", "title": "Experience Replay for Continual Learning"}, {"paperId": "2270b8628fd8ca67ae39d277f45bc3c38ac63d5f", "title": "Mesh-TensorFlow: Deep Learning for Supercomputers"}, {"paperId": "4a954b3e72a61968ab235076bcc242aca3a05520", "title": "Efficient Lifelong Learning with A-GEM"}, {"paperId": "16be95fd3f9b635e9ede5812cc223deebf0142bc", "title": "Measuring the Evolution of a Scientific Field through Citation Frames"}, {"paperId": "ae7619604821adce52c28daa2aed14f5a191d975", "title": "Progress & Compress: A scalable framework for continual learning"}, {"paperId": "6ea8cbf0cc4cda3d981348a279b464524a8485cc", "title": "On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization"}, {"paperId": "713b0d9005944f80af00addc81b162ca74ea4b14", "title": "Memory Aware Synapses: Learning what (not) to forget"}, {"paperId": "df1769afbbf3904877629dd7e785f195361ec531", "title": "Lifelong Learning with Dynamically Expandable Networks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "118fae4b4d07453561f1eded88654f812c7c61ec", "title": "Gradient Episodic Memory for Continual Learning"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "2e55ba6c97ce5eb55abd959909403fe8da7e9fe9", "title": "Overcoming catastrophic forgetting in neural networks"}, {"paperId": "1703631a938b397ba7e858161ce16448f6046d6f", "title": "iCaRL: Incremental Classifier and Representation Learning"}, {"paperId": "53c9443e4e667170acc60ca1b31a0ec7151fe753", "title": "Progressive Neural Networks"}, {"paperId": "575b0b9e3996097962510191e3da186d7a32d56d", "title": "ChemProt-3.0: a global chemical biology diseases mapping"}, {"paperId": "36f652172792f8aab1cf3c4441a72a1bf79d17c8", "title": "Ups and Downs: Modeling the Visual Evolution of Fashion Trends with One-Class Collaborative Filtering"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "fab4d19ed77dad7c437d885eceb8aa65fae5a783", "title": "Image-Based Recommendations on Styles and Substitutes"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "eee62b0ac67fb8d9a0b4911acc0c68eeb5f47989", "title": "The transformer."}, {"paperId": "8e125d392ea0d8240be654d90a28838711a5bd36", "title": "Pretrained Language Model in Continual Learning: A Comparative Study"}, {"paperId": "a54ba84e9ea4f46d3614427788d88832aa0f5ed6", "title": "A VIRTUAL EVENT"}, {"paperId": "a0033c2b38d289fd71194eb830b14d0db8f5a18b", "title": "Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning"}, {"paperId": "7422756d2416c62d7660bd217d817acc8ec35a09", "title": "On Transferability of Prompt Tuning for Natural Language Understanding"}, {"paperId": "5c5751d45e298cea054f32b392c12c61027d2fe7", "title": "S2ORC: The Semantic Scholar Open Research Corpus"}, {"paperId": null, "title": "2020) for the comparison among training steps, FLOPs and train wall time"}, {"paperId": null, "title": "ELECTRA: pretraining text encoders as discriminators rather than generators"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "2019. BERT: Pre-training"}, {"paperId": null, "title": "2019) of a descendant PLM and its"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Mohamed Elhoseiny, Marcus Rohrbach, and Tinne Tuytelaars"}, {"paperId": "c213af6582c0d518a6e8e14217611c733eeb1ef1", "title": "Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem"}, {"paperId": null, "title": "Chapter of the Association for Computational Lin-guistics: Human Language Technologies, Volume 1 (Long Papers)"}]}