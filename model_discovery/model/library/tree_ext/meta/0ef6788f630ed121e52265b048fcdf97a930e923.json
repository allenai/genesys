{"paperId": "0ef6788f630ed121e52265b048fcdf97a930e923", "title": "Benchmarking Large Language Models on Answering and Explaining Challenging Medical Questions", "abstract": "LLMs have demonstrated impressive performance in answering medical questions, such as achieving passing scores on medical licensing examinations. However, medical board exam or general clinical questions do not capture the complexity of realistic clinical cases. Moreover, the lack of reference explanations means we cannot easily evaluate the reasoning of model decisions, a crucial component of supporting doctors in making complex medical decisions. To address these challenges, we construct two new datasets: JAMA Clinical Challenge and Medbullets. JAMA Clinical Challenge consists of questions based on challenging clinical cases, while Medbullets comprises simulated clinical questions. Both datasets are structured as multiple-choice question-answering tasks, accompanied by expert-written explanations. We evaluate seven LLMs on the two datasets using various prompts. Experiments demonstrate that our datasets are harder than previous benchmarks. Human and automatic evaluations of model-generated explanations provide insights into the promise and deficiency of LLMs for explainable medical QA.", "venue": "arXiv.org", "year": 2024, "citationCount": 3, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Human and automatic evaluations of model-generated explanations provide insights into the promise and deficiency of LLMs for explainable medical QA."}, "embedding": {"model": "specter_v2", "vector": [-0.285788357257843, 1.2342188358306885, -0.4169573485851288, -0.40509700775146484, -1.0842684507369995, -0.19742588698863983, 0.28989672660827637, 0.07099738717079163, -0.10287939012050629, 0.1850057989358902, 0.5618702173233032, -0.7440349459648132, -0.2974415719509125, 0.5634683966636658, 0.2815152704715729, 0.5230660438537598, -0.6177080273628235, 0.763784646987915, -0.11768624186515808, -0.2009933888912201, -0.35177066922187805, -0.72714763879776, -0.33344465494155884, 0.3428049385547638, 0.6865983605384827, 0.18559233844280243, -0.08355812728404999, 1.1293151378631592, -0.3214542269706726, 0.6573724746704102, 0.35264483094215393, -0.7116828560829163, -0.21199320256710052, -0.31859004497528076, -0.4678429663181305, 0.2270667850971222, 0.16111570596694946, -0.5157459378242493, -0.42990726232528687, 0.2919160723686218, 0.12026858329772949, -0.19216130673885345, 0.6920021772384644, -0.5951547026634216, -0.46311208605766296, 0.2203107327222824, 0.8101993203163147, 0.5768640041351318, 0.6030862927436829, -0.3375723958015442, 1.410688877105713, -1.0685118436813354, 0.9429230093955994, 1.5586485862731934, 0.07902322709560394, 0.92753005027771, 0.03345388546586037, -0.14812716841697693, 0.11853437125682831, 0.13989605009555817, -0.6040796041488647, -0.09570565819740295, -0.5759441256523132, -0.23543916642665863, 1.103352665901184, 0.0034458832815289497, -0.4471912980079651, 0.06705009937286377, 0.45568791031837463, 1.2977670431137085, 0.12203314900398254, -0.8240180611610413, 0.12003342807292938, 0.35704416036605835, 0.2774370312690735, 0.962866485118866, -0.27690258622169495, 0.2581462562084198, -0.6472383737564087, -0.5540935397148132, 0.35113653540611267, -0.4625782072544098, -0.6009800434112549, -0.07943716645240784, -0.5386513471603394, 0.591593861579895, 0.25635769963264465, 0.3965514302253723, -0.10954474657773972, -0.21742302179336548, -0.31228262186050415, 0.4323321282863617, -0.8395035266876221, 0.481812059879303, -0.6005778908729553, 0.3567964732646942, -0.6026474833488464, 0.4840124249458313, 0.5324676632881165, 0.6082479953765869, -0.4676344096660614, -0.488817036151886, -1.345002293586731, 0.02483334019780159, 1.6172728538513184, -0.12166242301464081, 0.6305273175239563, -0.7570392489433289, 0.29267463088035583, -0.3365432620048523, 0.8564847707748413, -0.48538991808891296, -0.5972444415092468, -0.33493372797966003, -0.21389392018318176, -1.128735899925232, -0.30092766880989075, -0.08001960813999176, -0.702237606048584, 0.7033409476280212, -0.0037375963293015957, -0.45149216055870056, 0.23821759223937988, 0.9143295884132385, 1.1976243257522583, 0.1938709318637848, 0.38449209928512573, 0.13053177297115326, 0.9760693311691284, -0.38713952898979187, -0.7995110750198364, -0.8875465393066406, 0.8785205483436584, -0.3855847120285034, 0.3527764081954956, -0.3308659791946411, -1.2364203929901123, -0.9535226821899414, -0.359028697013855, -0.21456483006477356, 0.33772188425064087, 0.5995512008666992, 0.8273253440856934, 0.2848072648048401, -1.1008918285369873, 0.20891998708248138, 0.04773568734526634, -0.3572455942630768, -0.08990836143493652, 0.22199876606464386, 0.15060313045978546, -0.8671330809593201, -1.0949184894561768, 0.1695547252893448, -0.03355428948998451, -0.8062173128128052, -0.2879267930984497, -0.32634755969047546, -1.3188714981079102, -0.09966814517974854, 0.46390828490257263, -0.9311447739601135, 1.7793818712234497, 0.23443053662776947, -0.6802809834480286, 0.7776903510093689, -0.5375615358352661, 0.17419424653053284, 0.5440018177032471, 0.05424511432647705, -1.2361128330230713, 0.2433025985956192, 0.05677555873990059, 0.9687671065330505, -0.08136781305074692, -0.40845778584480286, -0.09664280712604523, 0.6034203171730042, 0.28733792901039124, -0.49578630924224854, 0.42763447761535645, 0.6619700789451599, -0.3024498522281647, -0.16839025914669037, 0.2476511001586914, 0.771379292011261, -0.4456772208213806, 0.22713007032871246, -0.7719932198524475, -0.7828102111816406, 0.24474428594112396, -0.2029690444469452, 0.8429332971572876, -0.718026876449585, -0.7998716831207275, -0.29562339186668396, 0.1885068714618683, -0.2923184931278229, -0.7806193232536316, 0.5048283338546753, -0.4992449879646301, 0.3992609679698944, -0.5865912437438965, -0.8177733421325684, 0.253349244594574, 0.0805598571896553, -0.6088293790817261, -0.5066190361976624, 0.5083328485488892, 1.529416799545288, -0.42425209283828735, -0.4862067997455597, -0.16212306916713715, -0.16748204827308655, -0.7523686289787292, 1.4290590286254883, -0.6065513491630554, 0.5835534334182739, -0.29053863883018494, 0.12091493606567383, 0.0696864128112793, -0.7652629613876343, 0.23181895911693573, -0.08648845553398132, 0.25311586260795593, 0.41590121388435364, -0.557371973991394, 1.3448857069015503, 0.14443016052246094, 0.04552064836025238, -0.0993504673242569, -0.44292667508125305, -0.08438673615455627, 0.8313156962394714, -0.42694029211997986, -0.5423004031181335, 0.16493380069732666, 0.45358553528785706, -0.18958479166030884, -0.808042585849762, -0.11631613969802856, 0.11239796876907349, -0.20401310920715332, 0.2830541133880615, 0.5714794993400574, -0.20041491091251373, 0.5305266976356506, 0.6882595419883728, 0.8287618160247803, -0.023763401433825493, 0.604089081287384, 0.17196129262447357, 0.5671448111534119, -0.196084126830101, 0.09594778716564178, 0.666289210319519, 0.7360565662384033, 1.0892884731292725, 0.5382577180862427, -0.747780442237854, 0.2940570116043091, -0.2849733829498291, 0.3603545129299164, 0.6439542174339294, 0.053755730390548706, -0.34901970624923706, -0.5551212430000305, -0.7513893246650696, -0.256790429353714, 0.41414931416511536, -0.6623642444610596, -0.08174242824316025, -0.1133696585893631, -0.7485033869743347, 0.7255887985229492, 0.5019607543945312, 0.47865256667137146, -0.5024899244308472, -0.23176003992557526, -0.20130106806755066, -0.20398466289043427, -0.6242415904998779, -0.3811797499656677, -0.2335149347782135, -0.5288517475128174, -0.8648918867111206, -0.046875931322574615, 0.04553353413939476, 0.389072448015213, -0.9681426286697388, 1.34354829788208, -0.23120126128196716, -0.8601861000061035, 0.8508912920951843, 0.7140649557113647, -0.5074902176856995, -0.8032055497169495, -0.5194642543792725, -0.5012584328651428, -0.423108845949173, 0.17931167781352997, 1.1239222288131714, -0.07446134835481644, 0.6024000644683838, -1.0332040786743164, 0.10612459480762482, 0.592005729675293, 0.28541722893714905, 0.5724323987960815, -0.7615287899971008, 0.34841760993003845, -1.2924141883850098, 1.0895050764083862, -0.04370767995715141, -0.17439912259578705, 0.6747483015060425, -0.6761903762817383, -0.13442860543727875, 0.19906911253929138, -0.3978823721408844, -0.31996917724609375, -1.5237854719161987, -0.003315888810902834, 0.4453091621398926, -0.7405664920806885, 0.7488992810249329, 0.08154533058404922, 0.3455961346626282, 0.30608174204826355, -0.22710826992988586, 0.21241076290607452, -0.15503066778182983, 0.3765133023262024, -0.7153977155685425, 0.4459799528121948, 0.28028348088264465, 0.28227970004081726, -0.24184274673461914, -0.10302543640136719, 0.11762723326683044, -0.6553923487663269, -0.02531704679131508, 0.04070158675312996, -0.16992215812206268, 0.21055465936660767, -0.2630431056022644, -0.6333903074264526, -1.000519871711731, -0.8445533514022827, 0.06637823581695557, -0.09941397607326508, 0.23890773952007294, -0.047125495970249176, -0.9320619106292725, -1.0122166872024536, -0.3154667913913727, 0.1432354897260666, -0.8188231587409973, 0.8617743849754333, 0.15202224254608154, -0.7718440294265747, -0.4287162125110626, 0.20199494063854218, 0.2669236361980438, 0.5650830268859863, -0.3518396317958832, 1.4328476190567017, -0.025808319449424744, -0.23708391189575195, -0.5203382968902588, 0.3771154284477234, -0.0668662041425705, -0.031150182709097862, -0.13600672781467438, -0.40011143684387207, 0.29216381907463074, 0.48179444670677185, -0.6209856271743774, -0.1793803721666336, 0.2406352013349533, 0.8022294640541077, 0.29342326521873474, -0.5669257044792175, -0.04954446107149124, 1.1443721055984497, -0.5983035564422607, -0.3027196526527405, -0.18059852719306946, 0.49219071865081787, 1.0785586833953857, 0.379140704870224, 0.3543163537979126, 0.5226405262947083, 0.2295219600200653, -0.0637393370270729, -0.3861888349056244, -0.05364249274134636, -0.1254262924194336, 0.08582253009080887, 0.8471572399139404, 0.6395925283432007, -0.17264878749847412, -1.4151933193206787, 0.42962735891342163, -1.1525388956069946, 0.1592068076133728, 0.24829912185668945, 0.5405527353286743, 0.15859782695770264, -0.42724916338920593, -0.8500056862831116, -0.1290423721075058, 0.3346754014492035, -0.39465564489364624, -0.44106045365333557, -0.17909830808639526, -0.27401748299598694, 0.4798755347728729, -0.27961739897727966, 0.6884604096412659, 0.07673782110214233, -0.346996933221817, 14.7387113571167, 0.4434565007686615, 0.1644572913646698, 0.7623047232627869, 0.9767913222312927, 0.38295498490333557, -0.6254006028175354, 0.01558433286845684, -0.8970463275909424, -0.6657798886299133, 1.3352134227752686, 0.2859778106212616, -0.34101006388664246, -0.0798671618103981, 0.34639301896095276, -0.007757633458822966, -0.7218761444091797, 0.6363609433174133, 0.6719748973846436, -1.173065423965454, 0.75501948595047, 0.3849916458129883, 0.27347275614738464, -0.03193514421582222, 0.8699204325675964, 0.676206648349762, -0.037950385361909866, -0.933646023273468, 0.41271552443504333, 0.4774301052093506, 0.8918343186378479, 0.12369423359632492, 0.8909298777580261, 0.4561460614204407, -0.3934057056903839, -0.40802523493766785, -0.4667108356952667, -0.6901174783706665, 0.3328118920326233, -0.054029375314712524, -1.0910005569458008, 0.044985104352235794, -0.5491993427276611, 0.1062464788556099, -0.1394423246383667, 0.6321027874946594, -0.4950083792209625, 0.7234820127487183, 0.7194510698318481, 0.3085640072822571, 0.10857941955327988, 0.9380436539649963, 0.36760175228118896, -0.25549742579460144, 0.27709364891052246, 0.43790221214294434, 0.10490299761295319, 0.6452720165252686, -0.46257254481315613, 0.15304787456989288, -0.07624073326587677, -0.15956610441207886, -0.7424593567848206, 0.6296263933181763, 0.5778874158859253, 0.4116716682910919, -0.5580319762229919, -0.046763986349105835, 0.29208576679229736, 0.08750638365745544, -0.06406282633543015, 0.11956560611724854, 0.22152665257453918, 0.08177248388528824, -0.3850998878479004, 0.5072585940361023, -0.059678610414266586, -0.642877459526062, -0.3931519091129303, -0.3225783705711365, 0.8488426804542542, -0.9879706501960754, -1.1337594985961914, 0.9178897142410278, -0.33880576491355896, -1.1106103658676147, -0.2163231074810028, -0.9750702381134033, 0.06885790079832077, 0.4606854319572449, -1.6716994047164917, -0.4697931110858917, -0.044093403965234756, -0.24075394868850708, -0.36125531792640686, 0.25026389956474304, 1.430121898651123, -0.21186929941177368, -0.0490046925842762, -0.13366416096687317, -0.41015198826789856, -0.2765476107597351, 0.5503525137901306, -1.0579503774642944, 0.1588720679283142, -0.04345906153321266, -0.1181296557188034, 0.4865722954273224, -0.037137385457754135, -0.08148422837257385, -0.7051426768302917, -0.16484513878822327, 0.8523495197296143, -1.1899131536483765, -0.7230734825134277, -0.4127354323863983, -1.0146574974060059, 0.01984565518796444, 0.3018409013748169, -0.2194860428571701, 1.1677436828613281, -0.28822222352027893, -0.0650039091706276, 0.1464347094297409, -1.2549444437026978, 0.12384689599275589, 0.35520684719085693, -0.5616796612739563, -1.0632315874099731, 0.4425533413887024, 0.3615722060203552, -0.9748842120170593, -0.33337390422821045, 0.06133892759680748, -0.15445783734321594, 0.0007566940621472895, 0.3609982430934906, -1.2070013284683228, 0.806474506855011, 0.5150797367095947, 0.11883864551782608, -0.5072331428527832, -0.0927528664469719, -0.7514050006866455, 0.37218865752220154, -0.2167445570230484, 1.1713939905166626, -0.3048476278781891, -0.22410668432712555, 1.56890070438385, 0.1684136986732483, -0.6310078501701355, -0.7018514275550842, 0.35163256525993347, -0.10857614874839783, -0.27402111887931824, 0.24051541090011597, -0.1967872679233551, -0.08832337707281113, -0.24970372021198273, 0.8174468278884888, 1.189589262008667, -0.4456339478492737, -0.13745923340320587, 0.3021107316017151, -0.40971145033836365, -0.5088006258010864, -0.35418790578842163, -0.4790446162223816, -1.4424548149108887, -0.07436724007129669, -0.8811245560646057, 0.1620589792728424, -1.4711637496948242, -0.42142415046691895, 0.547318696975708, -0.3303722143173218, 0.00397722190245986, -0.11462420225143433, -0.470233291387558, -0.9800785779953003, -0.492845356464386, -0.6457051634788513, 0.39259445667266846, 1.1686323881149292, -0.8379419445991516, 0.45697346329689026, -0.3207053542137146, -0.6032829284667969, 0.17911747097969055, 0.029796939343214035, -0.3825007379055023, -0.8046633005142212, -1.2596780061721802, 0.24751950800418854, 0.5460848212242126, 0.2254241406917572, -0.46297207474708557, 0.7088315486907959, 0.3749569058418274, 0.05297418311238289, 0.22295770049095154, 0.18700428307056427, -0.7138075828552246, -0.43921390175819397, 0.5511325001716614, -1.2120944261550903, 0.17746035754680634, 0.2735197842121124, -0.49758827686309814, -0.6693309545516968, 0.3679446876049042, -0.20998477935791016, -1.261894941329956, -0.22694338858127594, 0.2913134694099426, -0.6790927052497864, 0.09076060354709625, -0.2639860212802887, 0.174437016248703, -0.7155815362930298, -0.7416607141494751, -0.5099047422409058, 0.9099035263061523, -0.6192746758460999, 0.7585045099258423, 0.7616150975227356, -0.6365777254104614, -0.2352226972579956, 0.22219565510749817, 0.30786293745040894, -0.19519732892513275, 0.7442986369132996, 0.3806034326553345, -0.38541293144226074, 0.9910810589790344, 0.27518579363822937, 0.22940373420715332, -0.8187569379806519, -0.1004118025302887, 0.7921665906906128, -0.41198310256004333, -0.03553808107972145, 1.0678434371948242, -0.012354638427495956, -1.110426664352417, 0.09120211750268936, -1.2224771976470947, -0.7797360420227051, -0.8004990220069885, 0.8555150032043457, -0.09403559565544128, 0.28667008876800537, 0.03131098300218582, -0.4544355273246765, 0.16749851405620575, 0.10469520837068558, -0.9370127320289612, 0.2537378966808319, -0.37941592931747437, -0.4282170832157135, 0.5390368103981018, 0.08611021190881729, -0.44934678077697754, 0.006660555023699999, -0.06409038603305817, 0.0758349671959877, -0.16913370788097382, -0.3601061999797821, -0.9968535900115967, -0.10846973955631256, 0.7923746109008789, 0.6401614546775818, -2.549517921579536e-05, 0.25874248147010803, 0.38059574365615845, 0.021397411823272705, 0.6497522592544556, -0.03965939208865166, 0.16181811690330505, -0.5967094302177429, 0.4026522934436798, 1.4285093545913696, -1.3430323600769043, -0.38527753949165344, -0.2895280122756958, -0.863610029220581, 1.051891803741455, 0.605847954750061, 0.5264996886253357, 0.7114886045455933, -0.44549286365509033, 0.8507794737815857, -0.3723759055137634, -1.0684013366699219, 0.17290127277374268, 1.407707929611206, 0.9204365611076355, 0.9830795526504517, 0.5716939568519592, -0.5898280143737793, 1.277881145477295, 0.0915742814540863, 0.4917355477809906, 0.8935696482658386, 0.5232903957366943, 0.06610459834337234, -0.683872401714325, -0.154541477560997, 0.8965373635292053, -0.7149960398674011, -0.18567821383476257, -0.3427351713180542, 0.6997896432876587, 0.5488253235816956, 1.0325396060943604, 0.13626281917095184, 0.5312104225158691, 0.8562749028205872, 0.3039051294326782, 0.17543964087963104, -1.1302481889724731, -0.1020585298538208, -0.3043764531612396, -0.3897716701030731, -0.26214975118637085, -0.2905701696872711, -0.4620765149593353, -0.882160484790802, 0.8621726632118225, 0.473286509513855, 0.5622735023498535, 0.03624530881643295, 1.4317604303359985, 0.8454853296279907, 0.5041877627372742, -0.7823397517204285, 0.5618661642074585, -0.603008508682251, -1.0017238855361938, 0.01277647539973259, -0.5670418739318848, 0.1259389966726303, -0.49159711599349976, -0.00543245067819953, -0.3691731095314026]}, "authors": [{"authorId": "7315244", "name": "Hanjie Chen"}, {"authorId": "2287924500", "name": "Zhouxiang Fang"}, {"authorId": "2287921199", "name": "Yash Singla"}, {"authorId": "1478928280", "name": "Mark Dredze"}], "references": [{"paperId": "59543d42558ce64d889284bff368ed9f020dde81", "title": "Small Language Models Learn Enhanced Reasoning Skills from Medical Textbooks"}, {"paperId": "00d4e5bccaba9248538295f4e117c9620f676ec1", "title": "K-QA: A Real-World Medical Q&A Benchmark"}, {"paperId": "91646157ec1bfbf4e39ee7136480f004213519bc", "title": "Hidden flaws behind expert-level accuracy of multimodal GPT-4 vision in medicine"}, {"paperId": "23be666d846f2956f540fedf7fa0494a981b3afc", "title": "Diagnostic Accuracy of a Large Language Model in Pediatric Case Studies."}, {"paperId": "bde9da9a39a065588d7f4573936731510d6f4f29", "title": "Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine"}, {"paperId": "d5e7c9eb41061be87d770cca7730f47d69a0cef7", "title": "LongBoX: Evaluating Transformers on Long-Sequence Clinical Tasks"}, {"paperId": "4032c638728e155bb2d5d5b676ce7c99ccbf7db9", "title": "Use of GPT-4 to Diagnose Complex Clinical Cases"}, {"paperId": "15a2682ba1b479dea284062dd097a9a349a2eceb", "title": "AlpaCare: Instruction-tuned Large Language Models for Medical Application"}, {"paperId": "39abce3268f309d5655247de0c442a28219df390", "title": "MedEval: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark for Language Model Evaluation"}, {"paperId": "5e761e9f5cd9672a181b256299cd2916a8079461", "title": "Augmenting Black-box LLMs with Medical Textbooks for Clinical Question Answering"}, {"paperId": "e78212a3a7e82e2a5763897ee7c5962bf73df48e", "title": "Large Language Models Answer Medical Questions Accurately, but Can't Match Clinicians' Knowledge."}, {"paperId": "93269fd1aad9fe3825904687af3aa6c18f82a5fd", "title": "Use of GPT-4 to Analyze Medical Records of Patients With Extensive Investigations and Delayed Diagnosis"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "f02e0bf625ed8e4978a0a12a2f4f29a7b0b1d60d", "title": "Chatbot vs Medical Student Performance on Free-Response Clinical Reasoning Examinations."}, {"paperId": "ebc502a4d173f6550a8cd6384cb06f2c43c7c1a3", "title": "ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data and Comprehensive Evaluation"}, {"paperId": "0e98bd81aadc503e77411e17eafd9bfe58ac33a4", "title": "Accuracy of a Generative Artificial Intelligence Model in a Complex Diagnostic Challenge."}, {"paperId": "e154dd91de91558f9d671370754eace62a54c911", "title": "A study of generative large language model for medical research and healthcare"}, {"paperId": "d4b250b67454a889a68e1a813eb844b85005b1f7", "title": "ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist Examination"}, {"paperId": "38a9609a5bd874534527df9b00f2897927e57be9", "title": "MedAlpaca - An Open-Source Collection of Medical Conversational AI Models and Training Data"}, {"paperId": "348a1efa54376fa39053e5e25d52bd0eb6a0ba68", "title": "Capabilities of GPT-4 on Medical Challenge Problems"}, {"paperId": "6052486bc9144dc1730c12bf35323af3792a1fd0", "title": "Large language models encode clinical knowledge"}, {"paperId": "d697b440dd0e65a05fe027e4c0ea85f62dcba033", "title": "Can large language models reason about medical questions?"}, {"paperId": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large Language Models are Zero-Shot Reasoners"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "5f19ae1135a9500940978104ec15a5b8751bc7d2", "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models"}, {"paperId": "c37d0b258386293097fa3f71f971dc5dfceb4684", "title": "Data Contamination: From Memorization to Exploitation"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "f4df78183261538e718066331898ee5cad7cad05", "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"}, {"paperId": "6bd91a3183ddb844641acb9f3fe9faec6a9ff617", "title": "Meta-learning via Language Model In-context Tuning"}, {"paperId": "43fae0a7af211d91557d115d2f82e3c46d8bf022", "title": "Compression, Transduction, and Creation: A Unified Framework for Evaluating Natural Language Generation"}, {"paperId": "a6a7724763d8adba466519489b0b9d209e7f2d15", "title": "BARTScore: Evaluating Generated Text as Text Generation"}, {"paperId": "e5120fa67a12848c957122e99cc896de9614dff1", "title": "CliniQG4QA: Generating Diverse Questions for Domain Adaptation of Clinical Question Answering"}, {"paperId": "fc97c3f375c7228a1df7caa5c0ce5d2a6a171bd7", "title": "What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "4ae52766028e69186052ea8f33a137fbbbdb986a", "title": "BLEURT: Learning Robust Metrics for Text Generation"}, {"paperId": "89e0504b68ace8bd3c71e9113de51a29702dcdb7", "title": "Large-Scale, Diverse, Paraphrastic Bitexts via Sampling and Clustering"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "458129e2fd3a4a40392f84809c68e74fc19e52cd", "title": "Bridging the Gap Between Consumers' Medication Questions and Trusted Answers"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "86c8e5e2979377f87c7fdb2108497d074943d462", "title": "A question-entailment approach to question answering"}, {"paperId": "6cbdeb96380e028fb204f9802694e77bb772ed60", "title": "emrQA: A Large Corpus for Question Answering on Electronic Medical Records"}, {"paperId": "b7252d581c01eec357c66b08360c2371845e73d7", "title": "What is a disease?"}, {"paperId": "d1505c6123c102e53eb19dff312cb25cea840b72", "title": "Teaching Machines to Read and Comprehend"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "fa25610fb8586c2b50a3654edc5bb42fa7fc4729", "title": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction"}, {"paperId": "eaabe34285452fa2407f31de2d8bbb0e85ec6825", "title": "Communications Through Limited-Response Questioning"}, {"paperId": "61b0f5cfd4f951632435707948201474e16e835b", "title": "Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding"}, {"paperId": "bd0d9d7b373f18ace4dea46a7038a3a0269ac947", "title": "RadQA: A Question Answering Dataset to Improve Comprehension of Radiology Reports"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "c0376f9c0c6f3d2c2fd044f6d9629ec9c0a2d552", "title": "Overview of the Medical Question Answering Task at TREC 2017 LiveQA"}, {"paperId": null, "title": "OpenAI. 2023."}, {"paperId": null, "title": "2022. Understanding the impact of explanations on advice-taking: a user study for ai-based clinical decision support systems"}, {"paperId": null, "title": "2023. Falcon-40b: an open large language model with state-of-the-art performance."}, {"paperId": null, "title": "2022. Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering"}, {"paperId": null, "title": "2023. Chatgpt in medicine: an overview of its applications, advantages, limitations, future prospects, and ethical considerations"}, {"paperId": null, "title": "2023a. Hu-atuogpt, towards taming language model to be a doctor"}, {"paperId": null, "title": "2023. Pmc-llama: Further fine-tuning llama on medical papers"}, {"paperId": "13167f9cd8c7906ca808b01d28dca6dd951da8a5", "title": "of the Association for Computational Linguistics"}, {"paperId": null, "title": "2023b. How chatbots and large language model artificial intelligence systems will reshape modern medicine: Fountain of creativity or pandora\u2019s box?"}, {"paperId": null, "title": "Punta Cana, Dominican Republic"}, {"paperId": null, "title": "2022. Chain-of-thought prompting elicits reasoning in large language models"}, {"paperId": null, "title": "2023. Towards expert-level medical question answering with large language models"}]}