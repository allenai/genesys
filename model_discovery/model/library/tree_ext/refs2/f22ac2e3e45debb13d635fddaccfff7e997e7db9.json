{
    "paperId": "f22ac2e3e45debb13d635fddaccfff7e997e7db9",
    "externalIds": {
        "ArXiv": "1706.07206",
        "DBLP": "conf/wassa/ArrasMMS17",
        "MAG": "2964045325",
        "ACL": "W17-5221",
        "DOI": "10.18653/v1/W17-5221",
        "CorpusId": 19624082
    },
    "title": "Explaining Recurrent Neural Network Predictions in Sentiment Analysis",
    "abstract": "Recently, a technique called Layer-wise Relevance Propagation (LRP) was shown to deliver insightful explanations in the form of input space relevances for understanding feed-forward neural network classification decisions. In the present work, we extend the usage of LRP to recurrent neural networks. We propose a specific propagation rule applicable to multiplicative connections as they arise in recurrent network architectures such as LSTMs and GRUs. We apply our technique to a word-based bi-directional LSTM model on a five-class sentiment prediction task, and evaluate the resulting LRP relevances both qualitatively and quantitatively, obtaining better results than a gradient-based related method which was used in previous work.",
    "venue": "WASSA@EMNLP",
    "year": 2017,
    "referenceCount": 28,
    "citationCount": 334,
    "influentialCitationCount": 39,
    "openAccessPdf": {
        "url": "https://www.aclweb.org/anthology/W17-5221.pdf",
        "status": "HYBRID"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work applies a specific propagation rule applicable to multiplicative connections as they arise in recurrent network architectures such as LSTMs and GRUs to a word-based bi-directional LSTM model on a five-class sentiment prediction task and evaluates the resulting LRP relevances both qualitatively and quantitatively."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "3422375",
            "name": "L. Arras"
        },
        {
            "authorId": "144535526",
            "name": "G. Montavon"
        },
        {
            "authorId": "145034054",
            "name": "K. M\u00fcller"
        },
        {
            "authorId": "1699054",
            "name": "W. Samek"
        }
    ],
    "references": [
        {
            "paperId": "a002e71561c90767240672f357b7d9e6d4d95186",
            "title": "Methods for interpreting and understanding deep neural networks"
        },
        {
            "paperId": "4c41104e871bccbd56494350a71d77a7f1da5bb0",
            "title": "Understanding Neural Networks through Representation Erasure"
        },
        {
            "paperId": "78201113a852abba42a94b6d7b6098fb261f8759",
            "title": "\"What is relevant in a text document?\": An interpretable machine learning approach"
        },
        {
            "paperId": "57b9ec1b2c4ff17baed4ecca932880fd13eb5d19",
            "title": "Automatic Rule Extraction from Long Short Term Memory Networks"
        },
        {
            "paperId": "9e3f3d1e1e86cc497315f78617c909ae9a485f21",
            "title": "Explaining Predictions of Non-Linear Classifiers in NLP"
        },
        {
            "paperId": "c0883f5930a232a9c1ad601c978caede29155979",
            "title": "\u201cWhy Should I Trust You?\u201d: Explaining the Predictions of Any Classifier"
        },
        {
            "paperId": "6df11b0bb0244d4d36e8955436067cc5d19734fa",
            "title": "Evaluating the Visualization of What a Deep Neural Network Has Learned"
        },
        {
            "paperId": "17a273bbd4448083b01b5a9389b3c37f5425aac0",
            "title": "On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation"
        },
        {
            "paperId": "fafa541419b3756968fe5b3156c6f0257cb29c23",
            "title": "Visualizing and Understanding Neural Models in NLP"
        },
        {
            "paperId": "c52acb4e4143ace520166691a29faaeaf892ac47",
            "title": "Extraction of Salient Sentences from Labelled Documents"
        },
        {
            "paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e",
            "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"
        },
        {
            "paperId": "dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71",
            "title": "Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps"
        },
        {
            "paperId": "1a2a770d23b4a171fa81de62a78a3deb0588f238",
            "title": "Visualizing and Understanding Convolutional Networks"
        },
        {
            "paperId": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
        },
        {
            "paperId": "2cf3ba61f1dc0765f48f784dd9e9df377964730f",
            "title": "Interpreting individual classifications of hierarchical networks"
        },
        {
            "paperId": "3fdfa50a9224e22da8d2987f06346371ba26dd03",
            "title": "Review and comparison of methods to study the contribution of variables in artificial neural network models"
        },
        {
            "paperId": "11540131eae85b2e11d53df7f1360eeb6476e7f4",
            "title": "Learning to Forget: Continual Prediction with LSTM"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "e23c34414e66118ecd9b08cf0cd4d016f59b0b85",
            "title": "Bidirectional recurrent neural networks"
        },
        {
            "paperId": "7a2ce83a46b76b62e9ae2ad9311433c17534e755",
            "title": "Use of some sensitivity criteria for choosing networks with good generalization ability"
        },
        {
            "paperId": "052b1d8ce63b07fec3de9dbb583772d860b7c769",
            "title": "Learning representations by back-propagating errors"
        },
        {
            "paperId": "e8a43dc785929dc787e4a60973b891b6e413c142",
            "title": "Challenges in Sentiment Analysis"
        },
        {
            "paperId": "1ced3323a40bb265f76c23751b63e37182f3ec9d",
            "title": "Semeval-2016 Task 4 : Sentiment Analysis in Twitter"
        },
        {
            "paperId": null,
            "title": "The Layer-wise Relevance Propagation Toolbox for Artificial Neural Networks"
        },
        {
            "paperId": "190cb6561961f9989c5071736e85ab2a40b9a818",
            "title": "Author ' s personal copy A Fast Quartet tree heuristic for hierarchical clustering"
        },
        {
            "paperId": null,
            "title": "prediction score vector f ( x ) , with one entry f c ( x class, which is used for sentiment prediction Bi-directional LSTM The bi-directional"
        },
        {
            "paperId": null,
            "title": "h 0 and c 0 are set to zero"
        },
        {
            "paperId": null,
            "title": "different sequence of word embeddings as input. One LSTM takes as input the words in their"
        }
    ]
}