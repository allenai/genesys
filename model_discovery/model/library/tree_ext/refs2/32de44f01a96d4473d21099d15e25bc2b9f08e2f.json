{
    "paperId": "32de44f01a96d4473d21099d15e25bc2b9f08e2f",
    "externalIds": {
        "MAG": "2963355447",
        "DBLP": "conf/acl/TaiSM15",
        "ArXiv": "1503.00075",
        "ACL": "P15-1150",
        "DOI": "10.3115/v1/P15-1150",
        "CorpusId": 3033526
    },
    "title": "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks",
    "abstract": "Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank).",
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2015,
    "referenceCount": 41,
    "citationCount": 3030,
    "influentialCitationCount": 424,
    "openAccessPdf": {
        "url": "https://aclanthology.org/P15-1150.pdf",
        "status": "HYBRID"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The Tree-LSTM is introduced, a generalization of LSTMs to tree-structured network topologies that outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences and sentiment classification."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "8421815",
            "name": "Kai Sheng Tai"
        },
        {
            "authorId": "2166511",
            "name": "R. Socher"
        },
        {
            "authorId": "144783904",
            "name": "Christopher D. Manning"
        }
    ],
    "references": [
        {
            "paperId": "60dda7f5efd67758bde1ee7f45e6d3ef86445495",
            "title": "Deep Recursive Neural Networks for Compositionality in Language"
        },
        {
            "paperId": "d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0",
            "title": "Show and tell: A neural image caption generator"
        },
        {
            "paperId": "0d0b3ff23fbf1ec7a0dfebd923a3ef224306491a",
            "title": "Learning to Execute"
        },
        {
            "paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
            "title": "GloVe: Global Vectors for Word Representation"
        },
        {
            "paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "title": "Sequence to Sequence Learning with Neural Networks"
        },
        {
            "paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "title": "Neural Machine Translation by Jointly Learning to Align and Translate"
        },
        {
            "paperId": "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba",
            "title": "Convolutional Neural Networks for Sentence Classification"
        },
        {
            "paperId": "f795853dba1b4dc7ead4c4c5d94d4e1666a5df24",
            "title": "ECNU: One Stone Two Birds: Ensemble of Heterogenous Measures for Semantic Relatedness and Textual Entailment"
        },
        {
            "paperId": "11ec56898a9e7f401a2affe776b5297bd4e25025",
            "title": "SemEval-2014 Task 1: Evaluation of Compositional Distributional Semantic Models on Full Sentences through Semantic Relatedness and Textual Entailment"
        },
        {
            "paperId": "3276b9487b2336f662488f2a180622f3bcac6e82",
            "title": "UNAL-NLP: Combining Soft Cardinality Features for Semantic Textual Similarity, Relatedness and Entailment"
        },
        {
            "paperId": "ac991aa2072cf22fee83db7aa536137e666ed9d1",
            "title": "The Meaning Factory: Formal Semantics for Recognizing Textual Entailment and Determining Semantic Similarity"
        },
        {
            "paperId": "f529dc492b7f3d1b22db64bc7ad36b1f13641a84",
            "title": "Illinois-LH: A Denotational and Distributional Approach to Semantics"
        },
        {
            "paperId": "f3de86aeb442216a8391befcacb49e58b478f512",
            "title": "Distributed Representations of Sentences and Documents"
        },
        {
            "paperId": "0ca7d208ff8d81377e0eaa9723820aeae7a7322d",
            "title": "Grounded Compositional Semantics for Finding and Describing Images with Sentences"
        },
        {
            "paperId": "27725a2d2a8cee9bf9fffc6c2167017103aba0fa",
            "title": "A Convolutional Neural Network for Modelling Sentences"
        },
        {
            "paperId": "1149888d75af4ed5dffc25731b875651c3ccdeb2",
            "title": "Hybrid speech recognition with Deep Bidirectional LSTM"
        },
        {
            "paperId": "87f40e6f3022adbc1f1905e3e506abad05a9964f",
            "title": "Distributed Representations of Words and Phrases and their Compositionality"
        },
        {
            "paperId": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
        },
        {
            "paperId": "43c0b8309d05102aa75980f6cd53e2e77f222a17",
            "title": "Modeling Documents with Deep Boltzmann Machines"
        },
        {
            "paperId": "ef12383f516840ec1ec998cd5921dfc6e197c9b2",
            "title": "PPDB: The Paraphrase Database"
        },
        {
            "paperId": "607cca37c1429b7380df35b3f761ae1499aa84ab",
            "title": "Multi-Step Regression Learning for Compositional Distributional Semantics"
        },
        {
            "paperId": "27e38351e48fe4b7da2775bf94341738bc4da07e",
            "title": "Semantic Compositionality through Recursive Matrix-Vector Spaces"
        },
        {
            "paperId": "2b669398c4cf2ebe04375c8b1beae20f4ac802fa",
            "title": "Improving Word Representations via Global Context and Multiple Word Prototypes"
        },
        {
            "paperId": "0060745e006c5f14ec326904119dca19c6545e51",
            "title": "Improving neural networks by preventing co-adaptation of feature detectors"
        },
        {
            "paperId": "2063745d08868c928455f422202b72146a1960fb",
            "title": "Compositional Matrix-Space Models for Sentiment Analysis"
        },
        {
            "paperId": "9c0ddf74f87d154db88d79c640578c1610451eec",
            "title": "Parsing Natural Scenes and Natural Language with Recursive Neural Networks"
        },
        {
            "paperId": "413c1142de9d91804d6d11c67ff3fed59c9fc279",
            "title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization"
        },
        {
            "paperId": "bc1022b031dc6c7019696492e8116598097a8c12",
            "title": "Natural Language Processing (Almost) from Scratch"
        },
        {
            "paperId": "745d86adca56ec50761591733e157f84cfb19671",
            "title": "Composition in Distributional Models of Semantics"
        },
        {
            "paperId": "8492070dc4031ed825e95e4803781752bb5e909f",
            "title": "Word Representations: A Simple and General Method for Semi-Supervised Learning"
        },
        {
            "paperId": "a600850ac0120cb09a0b7de7da80bb6a7a76de06",
            "title": "Accurate Unlexicalized Parsing"
        },
        {
            "paperId": "e9fac1091d9a1646314b1b91e58f40dae3a750cd",
            "title": "The Vanishing Gradient Problem During Learning Recurrent Neural Nets and Problem Solutions"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "68dd4b89ce1407372a29d05ca9e4e1a2e0513617",
            "title": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge."
        },
        {
            "paperId": "d0be39ee052d246ae99c082a565aba25b811be2d",
            "title": "Learning long-term dependencies with gradient descent is difficult"
        },
        {
            "paperId": "668087f0ae7ce1de6e0bd0965dbb480c08103260",
            "title": "Finding Structure in Time"
        },
        {
            "paperId": "052b1d8ce63b07fec3de9dbb583772d860b7c769",
            "title": "Learning representations by back-propagating errors"
        },
        {
            "paperId": "a14045a751f5d8ed387c8630a86a3a2861b90643",
            "title": "A Fast and Accurate Dependency Parser using Neural Networks"
        },
        {
            "paperId": "34f25a8704614163c4095b3ee2fc969b60de4698",
            "title": "Dropout: a simple way to prevent neural networks from overfitting"
        },
        {
            "paperId": "96364af2d208ea75ca3aeb71892d2f7ce7326b55",
            "title": "Statistical Language Models Based on Neural Networks"
        },
        {
            "paperId": "c4732c036d0b00d435bcd41ae904a9e936e4f683",
            "title": "The Measurement of Textual Coherence with Latent Semantic Analysis."
        }
    ]
}