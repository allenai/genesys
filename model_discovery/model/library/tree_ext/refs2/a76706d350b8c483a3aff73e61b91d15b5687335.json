{
    "paperId": "a76706d350b8c483a3aff73e61b91d15b5687335",
    "externalIds": {
        "MAG": "2794557536",
        "ArXiv": "1803.11175",
        "DBLP": "journals/corr/abs-1803-11175",
        "CorpusId": 4494896
    },
    "title": "Universal Sentence Encoder",
    "abstract": "We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.",
    "venue": "arXiv.org",
    "year": 2018,
    "referenceCount": 27,
    "citationCount": 1767,
    "influentialCitationCount": 267,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is found that transfer learning using sentence embeddings tends to outperform word level transfer with surprisingly good performance with minimal amounts of supervised training data for a transfer task."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "46724030",
            "name": "Daniel Matthew Cer"
        },
        {
            "authorId": "2781059",
            "name": "Yinfei Yang"
        },
        {
            "authorId": "1803858",
            "name": "Sheng-yi Kong"
        },
        {
            "authorId": "2065640764",
            "name": "Nan Hua"
        },
        {
            "authorId": "40831840",
            "name": "Nicole Limtiaco"
        },
        {
            "authorId": "40827793",
            "name": "Rhomni St. John"
        },
        {
            "authorId": "40832517",
            "name": "Noah Constant"
        },
        {
            "authorId": "1410898480",
            "name": "Mario Guajardo-Cespedes"
        },
        {
            "authorId": "40827370",
            "name": "Steve Yuan"
        },
        {
            "authorId": "7887562",
            "name": "Chris Tar"
        },
        {
            "authorId": "2305450",
            "name": "Yun-Hsuan Sung"
        },
        {
            "authorId": "2704071",
            "name": "B. Strope"
        },
        {
            "authorId": "2186634",
            "name": "R. Kurzweil"
        }
    ],
    "references": [
        {
            "paperId": "938f6ef7eed095919e6a482c7f1836a01d62db4b",
            "title": "Google Vizier: A Service for Black-Box Optimization"
        },
        {
            "paperId": "a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096",
            "title": "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c",
            "title": "Supervised Learning of Universal Sentence Representations from Natural Language Inference Data"
        },
        {
            "paperId": "435553998fbef790b5bed3491a8f634d9ec5cfa2",
            "title": "Efficient Natural Language Response Suggestion for Smart Reply"
        },
        {
            "paperId": "5966d7c7f60898d610812e24c64d4d57855ad86a",
            "title": "Semantics derived automatically from language corpora contain human-like biases"
        },
        {
            "paperId": "4954fa180728932959997a4768411ff9136aac81",
            "title": "TensorFlow: A system for large-scale machine learning"
        },
        {
            "paperId": "f04df4e20a18358ea2f689b4c129781628ef7fc1",
            "title": "A large annotated corpus for learning natural language inference"
        },
        {
            "paperId": "80a624b9327d9050244dfebac96f7f6cf806880f",
            "title": "Deep Unordered Composition Rivals Syntactic Methods for Text Classification"
        },
        {
            "paperId": "6e795c6e9916174ae12349f5dc3f516570c17ce8",
            "title": "Skip-Thought Vectors"
        },
        {
            "paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
            "title": "GloVe: Global Vectors for Word Representation"
        },
        {
            "paperId": "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba",
            "title": "Convolutional Neural Networks for Sentence Classification"
        },
        {
            "paperId": "87f40e6f3022adbc1f1905e3e506abad05a9964f",
            "title": "Distributed Representations of Words and Phrases and their Compositionality"
        },
        {
            "paperId": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
        },
        {
            "paperId": "f964e2011ebccda06c4c6268740f87af13602b88",
            "title": "Implicit and Explicit Stigmatizing Attitudes and Stereotypes About Depression"
        },
        {
            "paperId": "6af58c061f2e4f130c3b795c21ff0c7e3903278f",
            "title": "Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales"
        },
        {
            "paperId": "cdcf7cb29f37ac0546961ea8a076075b9cc1f992",
            "title": "Mining and summarizing customer reviews"
        },
        {
            "paperId": "167e1359943b96b9e92ee73db1df69a1f65d731d",
            "title": "A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts"
        },
        {
            "paperId": "2c8ac3e1f0edeed1fbd76813e61efdc384c319c7",
            "title": "Learning Question Classifiers"
        },
        {
            "paperId": "999c9cbebc16364198eb2c7b51e6a8459e8e6fd4",
            "title": "Math = male, me = female, therefore math \u2260 me."
        },
        {
            "paperId": "f94887ab51f9deb91cfe02a3b0e1139ba6e3b8b9",
            "title": "Harvesting implicit group attitudes and beliefs from a demonstration web site"
        },
        {
            "paperId": "10cc2d53ff8349d3432b8f822d58e4ddee3d475e",
            "title": "Measuring individual differences in implicit cognition: the implicit association test."
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "f87e9e630850fd35cdddfee8db62ec5a729cb7fe",
            "title": "PETTIT iMpliciT anD expliciT sTigMaTizing aTTiTuDes anD sTereoTypes aBouT Depression"
        },
        {
            "paperId": "348aaf563c4fd6de653a8eb1490c4b6b93e0c6d0",
            "title": "Are Emily and Greg More Employable than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination"
        },
        {
            "paperId": "1cff7cc15555c38607016aaba24059e76b160adb",
            "title": "Annotating Expressions of Opinions and Emotions in Language"
        },
        {
            "paperId": "5acf625a86079bfa28b4127f91f70ce2626c4c18",
            "title": "Math Male , Me Female , Therefore Math Me"
        }
    ]
}