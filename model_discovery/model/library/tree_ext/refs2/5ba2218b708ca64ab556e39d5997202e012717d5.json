{
    "paperId": "5ba2218b708ca64ab556e39d5997202e012717d5",
    "externalIds": {
        "MAG": "2593116425",
        "DBLP": "conf/icassp/GemmekeEFJLMPR17",
        "DOI": "10.1109/ICASSP.2017.7952261",
        "CorpusId": 21519176
    },
    "title": "Audio Set: An ontology and human-labeled dataset for audio events",
    "abstract": "Audio event recognition, the human-like ability to identify and relate sounds from audio, is a nascent problem in machine perception. Comparable problems such as object detection in images have reaped enormous benefits from comprehensive datasets - principally ImageNet. This paper describes the creation of Audio Set, a large-scale dataset of manually-annotated audio events that endeavors to bridge the gap in data availability between image and audio research. Using a carefully structured hierarchical ontology of 632 audio classes guided by the literature and manual curation, we collect data from human labelers to probe the presence of specific audio classes in 10 second segments of YouTube videos. Segments are proposed for labeling using searches based on metadata, context (e.g., links), and content analysis. The result is a dataset of unprecedented breadth and size that will, we hope, substantially stimulate the development of high-performance audio event recognizers.",
    "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
    "year": 2017,
    "referenceCount": 22,
    "citationCount": 2670,
    "influentialCitationCount": 405,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The creation of Audio Set is described, a large-scale dataset of manually-annotated audio events that endeavors to bridge the gap in data availability between image and audio research and substantially stimulate the development of high-performance audio event recognizers."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "3116662",
            "name": "J. Gemmeke"
        },
        {
            "authorId": "1745455",
            "name": "D. Ellis"
        },
        {
            "authorId": "36794621",
            "name": "Dylan Freedman"
        },
        {
            "authorId": "35996413",
            "name": "A. Jansen"
        },
        {
            "authorId": "39965499",
            "name": "W. Lawrence"
        },
        {
            "authorId": "2107422370",
            "name": "R. C. Moore"
        },
        {
            "authorId": "2114994",
            "name": "Manoj Plakal"
        },
        {
            "authorId": "39687627",
            "name": "Marvin Ritter"
        }
    ],
    "references": [
        {
            "paperId": "59d8c68de09da69a608ceb149f40114f5538c5b1",
            "title": "CNN architectures for large-scale audio classification"
        },
        {
            "paperId": "2cfb0bb902c3586cae6bd7c4f6e3dcca9be92a11",
            "title": "TUT database for acoustic scene classification and sound event detection"
        },
        {
            "paperId": "1462e12e74db83e8e2bf31ca0d9630a63303939d",
            "title": "AudioSentibank: Large-scale Semantic Ontology of Acoustic Concepts for Audio Content Analysis"
        },
        {
            "paperId": "0b01f47dcefe7c66e75e3d6a112d0011a15467c6",
            "title": "Distinct Cortical Pathways for Music and Speech Revealed by Hypothesis-Free Voxel Decomposition"
        },
        {
            "paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "title": "Deep Residual Learning for Image Recognition"
        },
        {
            "paperId": "44924305a548564ff2ed90f54a12cdc3b754c6fa",
            "title": "Detection and Classification of Acoustic Scenes and Events"
        },
        {
            "paperId": "39a7a74de74efac3b8123650315d55cfb9d5220c",
            "title": "A Dataset and Taxonomy for Urban Sound Research"
        },
        {
            "paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327",
            "title": "Going deeper with convolutions"
        },
        {
            "paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd",
            "title": "ImageNet Large Scale Visual Recognition Challenge"
        },
        {
            "paperId": "80c97ef62eee25ac48412cd1e20d9cc55e931b3f",
            "title": "Evidence for a basic level in a taxonomy of everyday action sounds"
        },
        {
            "paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "title": "ImageNet classification with deep convolutional neural networks"
        },
        {
            "paperId": "a6cf81593a4ca8a9370b8e3189941a126008db77",
            "title": "Similarity and categorization of environmental sounds"
        },
        {
            "paperId": "386c6597c843e8fd1f18168b59b945fde3028a76",
            "title": "CLEAR Evaluation of Acoustic Event Detection and Classification Systems"
        },
        {
            "paperId": "c81832ddcaba13f595510b8338f40fabf535ebbb",
            "title": "Sound Ontology for Computational Auditory Scence Analysis"
        },
        {
            "paperId": "0b943751afe6302e28f7e94ff53028e1d04f55e4",
            "title": "Content-Based Classification, Search, and Retrieval of Audio"
        },
        {
            "paperId": "68c03788224000794d5491ab459be0b2a2c38677",
            "title": "WordNet: A Lexical Database for English"
        },
        {
            "paperId": "687cd5d0b52572c8a8acd72a8e8f1bc958be5d5b",
            "title": "Common factors in the identification of an assortment of brief everyday sounds."
        },
        {
            "paperId": "0a36667de28f912ba999fe92ae718284012a67be",
            "title": "What in the World Do We Hear? An Ecological Approach to Auditory Event Perception"
        },
        {
            "paperId": "dbfd191afbbc8317577cbc44afe7156df546e143",
            "title": "Automatic Acquisition of Hyponyms from Large Text Corpora"
        },
        {
            "paperId": "ce1dfda3988b4a920129e336db4505337a116491",
            "title": "Auditory perception of breaking and bouncing events: a case study in ecological acoustics."
        },
        {
            "paperId": "e834a1e59f09519eda369a9b74eec76d27cc4846",
            "title": "Noisemes: Manual Annotation of Environmental Noise in Audio Streams"
        },
        {
            "paperId": null,
            "title": "Introducing the knowledge graph: things, not strings"
        }
    ]
}