{
    "paperId": "3f567d3d4975359fadfa9d750e1e4c4722d666c8",
    "externalIds": {
        "DBLP": "journals/corr/WangJ16b",
        "MAG": "2951528484",
        "ArXiv": "1611.01747",
        "CorpusId": 822804
    },
    "title": "A Compare-Aggregate Model for Matching Text Sequences",
    "abstract": "Many NLP tasks including machine comprehension, answer selection and text entailment require the comparison between sequences. Matching the important units between sequences is a key to solve these problems. In this paper, we present a general \"compare-aggregate\" framework that performs word-level matching followed by aggregation using Convolutional Neural Networks. We particularly focus on the different comparison functions we can use to match two vectors. We use four different datasets to evaluate the model. We find that some simple comparison functions based on element-wise operations can work better than standard neural network and neural tensor network.",
    "venue": "International Conference on Learning Representations",
    "year": 2016,
    "referenceCount": 31,
    "citationCount": 270,
    "influentialCitationCount": 52,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A general \"compare-aggregate\" framework that performs word-level matching followed by aggregation using Convolutional Neural Networks and finds that some simple comparison functions based on element-wise operations can work better than standard neural network and neural tensor network."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "2992833",
            "name": "Shuohang Wang"
        },
        {
            "authorId": "144924150",
            "name": "Jing Jiang"
        }
    ],
    "references": [
        {
            "paperId": "83e7654d545fbbaaf2328df365a781fb67b841b4",
            "title": "Enhanced LSTM for Natural Language Inference"
        },
        {
            "paperId": "162db03ef3cb50a07ff54ae4a1d4ea120e4162f2",
            "title": "Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference"
        },
        {
            "paperId": "ff1861b71eaedba46cb679bbe2c585dbe18f9b19",
            "title": "Machine Comprehension Using Match-LSTM and Answer Pointer"
        },
        {
            "paperId": "1261fe9bfde319abcc5d011bc70f7e7547b5258f",
            "title": "Improved Representation Learning for Question Answer Matching"
        },
        {
            "paperId": "52956422f86722aca6becb67ea4c3ad61f0c1aea",
            "title": "Inner Attention based Recurrent Neural Networks for Answer Selection"
        },
        {
            "paperId": "2cd8e8f510c89c7c18268e8ad51c061e459ad321",
            "title": "A Decomposable Attention Model for Natural Language Inference"
        },
        {
            "paperId": "29006d8c9c2247fca4cd3a22822c2b042e85572d",
            "title": "Pairwise Word Interaction Modeling with Deep Neural Networks for Semantic Similarity Measurement"
        },
        {
            "paperId": "a5d3dfa6394340fd027425aef9e7384789925726",
            "title": "Match-SRNN: Modeling the Recursive Matching Structure with Spatial RNN"
        },
        {
            "paperId": "46147f08468e873ff90d1d51e65493f262c7bb57",
            "title": "A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data"
        },
        {
            "paperId": "13fe71da009484f240c46f14d9330e932f8de210",
            "title": "Long Short-Term Memory-Networks for Machine Reading"
        },
        {
            "paperId": "596c882de006e4bb4a93f1fa08a5dd467bee060a",
            "title": "Learning Natural Language Inference with LSTM"
        },
        {
            "paperId": "ea407573bfcd39f9a478fe33cf6ce0ee1780a5f0",
            "title": "Natural Language Inference by Tree-Based Convolution and Heuristic Matching"
        },
        {
            "paperId": "7f3ae283243e15e05f188a05779ccfae9a3567f4",
            "title": "ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs"
        },
        {
            "paperId": "1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7",
            "title": "MovieQA: Understanding Stories in Movies through Question-Answering"
        },
        {
            "paperId": "35b91b365ceb016fb3e022577cec96fb9b445dc5",
            "title": "The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations"
        },
        {
            "paperId": "2846e83d405cbe3bf2f0f3b5f635dd8b3c680c45",
            "title": "Reasoning about Entailment with Neural Attention"
        },
        {
            "paperId": "f53e2ae46470b89cd1ce6e3bf1d60d9c59722ce1",
            "title": "WikiQA: A Challenge Dataset for Open-Domain Question Answering"
        },
        {
            "paperId": "f04df4e20a18358ea2f689b4c129781628ef7fc1",
            "title": "A large annotated corpus for learning natural language inference"
        },
        {
            "paperId": "f33e86970c11f9bb6d0abb60acdc9274d5c3f342",
            "title": "Applying deep learning to answer selection: A study and an open task"
        },
        {
            "paperId": "d1505c6123c102e53eb19dff312cb25cea840b72",
            "title": "Teaching Machines to Read and Comprehend"
        },
        {
            "paperId": "32de44f01a96d4473d21099d15e25bc2b9f08e2f",
            "title": "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks"
        },
        {
            "paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "title": "Adam: A Method for Stochastic Optimization"
        },
        {
            "paperId": "9f08b01251cb99f4ffae8c7b3e4468d3af9c98d3",
            "title": "Convolutional Neural Network Architectures for Matching Natural Language Sentences"
        },
        {
            "paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
            "title": "GloVe: Global Vectors for Word Representation"
        },
        {
            "paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "title": "Neural Machine Translation by Jointly Learning to Align and Translate"
        },
        {
            "paperId": "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba",
            "title": "Convolutional Neural Networks for Sentence Classification"
        },
        {
            "paperId": "564257469fa44cdb57e4272f85253efb9acfd69d",
            "title": "MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text"
        },
        {
            "paperId": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
        },
        {
            "paperId": "bc3831bd9f065b93eb82607f11f4d7d8ad2b6148",
            "title": "Learning concept importance using a weighted dependence model"
        },
        {
            "paperId": "e4351041d25c272a008bcd5765868dc3a28fe470",
            "title": "Under Review as a Conference Paper at Iclr 2017 Delving into Transferable Adversarial Ex- Amples and Black-box Attacks"
        },
        {
            "paperId": null,
            "title": "Effective approaches to attentionbased neural machine translation"
        }
    ]
}