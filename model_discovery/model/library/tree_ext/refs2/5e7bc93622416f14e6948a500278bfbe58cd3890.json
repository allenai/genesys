{
    "paperId": "5e7bc93622416f14e6948a500278bfbe58cd3890",
    "externalIds": {
        "ArXiv": "2005.01643",
        "DBLP": "journals/corr/abs-2005-01643",
        "MAG": "3022566517",
        "CorpusId": 218486979
    },
    "title": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems",
    "abstract": "In this tutorial article, we aim to provide the reader with the conceptual tools needed to get started on research on offline reinforcement learning algorithms: reinforcement learning algorithms that utilize previously collected data, without additional online data collection. Offline reinforcement learning algorithms hold tremendous promise for making it possible to turn large datasets into powerful decision making engines. Effective offline reinforcement learning methods would be able to extract policies with the maximum possible utility out of the available data, thereby allowing automation of a wide range of decision-making domains, from healthcare and education to robotics. However, the limitations of current algorithms make this difficult. We will aim to provide the reader with an understanding of these challenges, particularly in the context of modern deep reinforcement learning methods, and describe some potential solutions that have been explored in recent work to mitigate these challenges, along with recent applications, and a discussion of perspectives on open problems in the field.",
    "venue": "arXiv.org",
    "year": 2020,
    "referenceCount": 193,
    "citationCount": 1644,
    "influentialCitationCount": 160,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This tutorial article aims to provide the reader with the conceptual tools needed to get started on research on offline reinforcement learning algorithms: reinforcementlearning algorithms that utilize previously collected data, without additional online data collection."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -2.412942886352539,
            0.691848874092102,
            -2.9879238605499268,
            7.117620944976807,
            -4.306922435760498,
            -0.6636974811553955,
            2.8126707077026367,
            -4.587583065032959,
            -1.0728096961975098,
            -1.5066062211990356,
            -2.3170197010040283,
            3.1375198364257812,
            -2.0316274166107178,
            -0.692891538143158,
            -5.2992329597473145,
            0.7350716590881348,
            -1.8630180358886719,
            -0.5065363645553589,
            4.99519157409668,
            1.2546353340148926,
            -1.9962246417999268,
            0.799653172492981,
            -2.164956569671631,
            -0.41633179783821106,
            -3.8391103744506836,
            -0.5391249656677246,
            2.8527398109436035,
            1.2070374488830566,
            -2.7939260005950928,
            2.567899465560913,
            0.713367223739624,
            -3.3677802085876465,
            6.538908958435059,
            -2.5856828689575195,
            3.862245798110962,
            -1.7234916687011719,
            -4.409417629241943,
            7.362565994262695,
            -2.03940486907959,
            1.4623253345489502,
            -0.0808870792388916,
            0.29420042037963867,
            2.361072063446045,
            -3.3243961334228516,
            -1.5287259817123413,
            1.5372645854949951,
            0.9829854965209961,
            1.7608747482299805,
            0.9686832427978516,
            0.18374675512313843,
            2.438581943511963,
            1.4533518552780151,
            1.239856481552124,
            2.242640972137451,
            2.0044960975646973,
            3.812469720840454,
            3.6312496662139893,
            0.7668808102607727,
            1.8972163200378418,
            0.9255292415618896,
            5.686732292175293,
            4.879199981689453,
            -1.4457240104675293,
            0.4210485517978668,
            2.8231921195983887,
            -2.7991859912872314,
            1.404254674911499,
            2.955418825149536,
            0.9750757217407227,
            3.6597931385040283,
            -1.672102928161621,
            -2.818510055541992,
            3.092510223388672,
            -2.167440414428711,
            -3.409158706665039,
            0.7587098479270935,
            -0.4945971965789795,
            -2.8158302307128906,
            -1.9574216604232788,
            0.6063044667243958,
            0.46058082580566406,
            2.138885259628296,
            3.470517873764038,
            -0.07858362793922424,
            2.2030386924743652,
            -0.36080899834632874,
            -6.176124572753906,
            -1.6341626644134521,
            -1.1023039817810059,
            -7.439080238342285,
            -0.13481248915195465,
            -1.7456096410751343,
            1.0060241222381592,
            1.8731763362884521,
            -1.5114179849624634,
            1.5496509075164795,
            2.532646656036377,
            -1.3294333219528198,
            -2.3085296154022217,
            1.1449851989746094,
            4.122269153594971,
            1.260211706161499,
            2.881932020187378,
            3.1083221435546875,
            5.213855743408203,
            -0.5623723268508911,
            1.3126815557479858,
            4.224010467529297,
            2.6328933238983154,
            0.29415908455848694,
            -1.553830862045288,
            4.633066654205322,
            -1.9576294422149658,
            1.3150155544281006,
            0.1635800004005432,
            2.1829638481140137,
            -1.0544613599777222,
            1.7005891799926758,
            -3.0349183082580566,
            4.020575046539307,
            0.762728214263916,
            -1.475168228149414,
            -3.1174397468566895,
            -0.8961885571479797,
            -1.3933993577957153,
            0.2942490875720978,
            2.0511600971221924,
            -3.381774425506592,
            -1.0097309350967407,
            -0.42710885405540466,
            2.0359628200531006,
            0.16281703114509583,
            2.4221723079681396,
            0.1335229128599167,
            2.7070491313934326,
            0.2759499251842499,
            -2.8445444107055664,
            0.4756820797920227,
            -4.1047587394714355,
            -0.13018783926963806,
            -3.5762157440185547,
            2.796525001525879,
            -1.2355594635009766,
            -0.8441357612609863,
            3.3848369121551514,
            2.219778537750244,
            0.5889533758163452,
            0.6379742622375488,
            -0.1240634024143219,
            1.2510536909103394,
            1.6823160648345947,
            -4.6695146560668945,
            1.5604547262191772,
            2.2353482246398926,
            5.091780185699463,
            5.500441551208496,
            -4.125133514404297,
            0.32439324259757996,
            0.4725441336631775,
            1.8275043964385986,
            2.2392282485961914,
            -1.6931085586547852,
            -7.750347137451172,
            1.6867940425872803,
            2.4951324462890625,
            -3.3718671798706055,
            0.7979038953781128,
            3.1227991580963135,
            -2.2097861766815186,
            -2.6796979904174805,
            0.8326697945594788,
            5.112002849578857,
            -0.0543617308139801,
            4.592888832092285,
            1.9574859142303467,
            0.7416069507598877,
            2.5063247680664062,
            -4.813571929931641,
            3.5856025218963623,
            1.457633137702942,
            0.5043179988861084,
            -1.467869520187378,
            -4.538113594055176,
            -0.9305610656738281,
            -2.768031120300293,
            -4.816831588745117,
            -2.199641466140747,
            1.83513605594635,
            3.07767653465271,
            -0.5415555238723755,
            0.5222421884536743,
            2.507167339324951,
            1.4879785776138306,
            6.87029504776001,
            4.870156288146973,
            -0.5943294763565063,
            -0.04554319381713867,
            3.871765375137329,
            -2.662351131439209,
            -0.7326873540878296,
            1.9702163934707642,
            0.47353577613830566,
            -0.4132384657859802,
            0.15453341603279114,
            -0.010507255792617798,
            1.115012764930725,
            -3.7733469009399414,
            2.611363649368286,
            -0.0007572174072265625,
            1.843658208847046,
            -0.9485068321228027,
            1.018660545349121,
            0.6530023813247681,
            -2.0788772106170654,
            -4.327411651611328,
            -2.194824695587158,
            -3.397080898284912,
            0.8977618217468262,
            3.866692304611206,
            0.008496120572090149,
            -2.534105062484741,
            1.3200942277908325,
            3.093763589859009,
            0.6318193674087524,
            -1.4242472648620605,
            -3.5276565551757812,
            2.0001628398895264,
            2.9828238487243652,
            -0.6384196281433105,
            1.2144538164138794,
            -4.4465813636779785,
            -3.282196283340454,
            3.0243618488311768,
            -1.1284661293029785,
            -4.773877143859863,
            -1.6683310270309448,
            -2.2176499366760254,
            -0.9786497950553894,
            1.8251185417175293,
            2.9873218536376953,
            4.260503768920898,
            -0.7026321887969971,
            -0.5870842933654785,
            2.5511398315429688,
            5.9934844970703125,
            1.7510522603988647,
            -3.25114107131958,
            -0.09878304600715637,
            -0.41114187240600586,
            -1.0194885730743408,
            -2.5746161937713623,
            -2.8121509552001953,
            1.3035838603973389,
            -2.3140339851379395,
            0.6696667075157166,
            6.051236629486084,
            0.5553902387619019,
            2.92417049407959,
            0.48702308535575867,
            3.3529138565063477,
            1.0255558490753174,
            2.1629271507263184,
            1.5696015357971191,
            0.22668378055095673,
            -0.7516562938690186,
            -1.2713029384613037,
            -2.2831931114196777,
            -4.203136444091797,
            -2.511467695236206,
            0.3367161154747009,
            -0.8160572052001953,
            2.671802043914795,
            1.5621408224105835,
            -4.0222554206848145,
            -4.800193786621094,
            -4.342516899108887,
            -1.0208848714828491,
            -1.6333909034729004,
            1.2664417028427124,
            2.582604169845581,
            2.964200019836426,
            -1.3307030200958252,
            1.69525146484375,
            -2.169889450073242,
            0.6234176754951477,
            -4.772036552429199,
            -2.265414237976074,
            0.27161315083503723,
            -1.1198407411575317,
            -3.2179505825042725,
            -4.258535861968994,
            3.111241579055786,
            -2.659165143966675,
            3.71889328956604,
            -3.840285301208496,
            -0.18103185296058655,
            1.806531548500061,
            -2.3379383087158203,
            -1.045914649963379,
            -0.5981757044792175,
            -0.8133322596549988,
            2.0902252197265625,
            0.9876419305801392,
            -1.61472487449646,
            0.6026252508163452,
            6.722907066345215,
            2.640174627304077,
            2.8296923637390137,
            -0.45611774921417236,
            -2.3146092891693115,
            0.7804957628250122,
            -0.4462023377418518,
            6.750913619995117,
            -5.078341484069824,
            -0.6771733164787292,
            -1.9135844707489014,
            -0.0406738817691803,
            2.2218708992004395,
            -2.3607993125915527,
            2.7316198348999023,
            1.5199111700057983,
            -4.56343412399292,
            -1.4654958248138428,
            -6.450837135314941,
            -1.36285400390625,
            0.8664725422859192,
            -1.2680689096450806,
            0.8273767828941345,
            -0.4268046021461487,
            -0.8774020671844482,
            -0.6560929417610168,
            4.262547492980957,
            2.613476514816284,
            3.4685885906219482,
            -3.481687545776367,
            -5.628913879394531,
            -1.5079751014709473,
            -1.516848087310791,
            1.466355323791504,
            1.1593282222747803,
            -1.3158055543899536,
            6.381065845489502,
            -0.006938174366950989,
            -0.4240196943283081,
            -0.6276972889900208,
            -0.2950735092163086,
            3.33504581451416,
            -2.570525884628296,
            1.9116865396499634,
            -0.17730426788330078,
            -0.6473339200019836,
            -0.09222579002380371,
            4.322141647338867,
            -2.36956524848938,
            7.498204708099365,
            2.371117115020752,
            4.042792320251465,
            4.076548099517822,
            0.5937691926956177,
            2.06903076171875,
            -2.7457141876220703,
            -0.9484478235244751,
            -1.3633816242218018,
            -2.9331095218658447,
            -3.2430524826049805,
            -0.7566856145858765,
            6.763017654418945,
            -3.1138486862182617,
            0.7044345140457153,
            -5.576221942901611,
            -1.240563154220581,
            -3.4488511085510254,
            -3.3817808628082275,
            1.3661882877349854,
            1.5751266479492188,
            0.3052417039871216,
            2.0952701568603516,
            -0.3052510917186737,
            -0.47513043880462646,
            0.17132514715194702,
            2.0080060958862305,
            3.630186080932617,
            -3.7087063789367676,
            3.104224920272827,
            0.20451873540878296,
            -4.548950672149658,
            -0.8688324689865112,
            0.4487025737762451,
            1.0663740634918213,
            1.9391385316848755,
            -0.5421429872512817,
            4.8400044441223145,
            2.2264537811279297,
            2.8864200115203857,
            0.9030971527099609,
            -6.1903076171875,
            -3.3332738876342773,
            -5.761721611022949,
            0.6090289950370789,
            0.5839738845825195,
            -1.5769153833389282,
            1.0418343544006348,
            6.897718906402588,
            6.484382629394531,
            -4.60499382019043,
            -0.20353059470653534,
            4.351442337036133,
            0.38465356826782227,
            -1.8323274850845337,
            1.1968311071395874,
            0.1333618462085724,
            -0.34991610050201416,
            -1.4905097484588623,
            -3.539205551147461,
            -2.172795295715332,
            -3.496088981628418,
            -2.1462900638580322,
            3.7732315063476562,
            2.7930550575256348,
            -1.5150798559188843,
            -0.36010339856147766,
            -0.3514159023761749,
            2.498201608657837,
            3.4450747966766357,
            -2.30612850189209,
            2.7371339797973633,
            0.43637651205062866,
            -2.8091230392456055,
            -2.3811511993408203,
            7.254639625549316,
            -3.6983046531677246,
            5.009327411651611,
            -2.824608564376831,
            2.3825483322143555,
            2.533973455429077,
            1.3913464546203613,
            3.0026776790618896,
            2.627521514892578,
            1.3429553508758545,
            -2.399888277053833,
            -0.1897885799407959,
            -0.3304304778575897,
            -3.60144305229187,
            4.573963165283203,
            -0.7531032562255859,
            -2.835892677307129,
            -2.1261191368103027,
            3.8001341819763184,
            0.22700706124305725,
            -1.0530376434326172,
            2.2965548038482666,
            -1.171533226966858,
            -2.4263744354248047,
            0.3082141578197479,
            0.6429471373558044,
            2.8007452487945557,
            -3.166283130645752,
            -7.364358901977539,
            1.6401139497756958,
            0.22927173972129822,
            -5.977599143981934,
            2.7892932891845703,
            0.31428295373916626,
            2.513183355331421,
            -2.5104451179504395,
            3.46197509765625,
            -1.5969027280807495,
            -1.7714899778366089,
            -4.1525559425354,
            -0.4015839397907257,
            0.3241453766822815,
            -0.9898155331611633,
            -2.6188411712646484,
            -1.9984771013259888,
            2.4473657608032227,
            1.011925458908081,
            3.015047311782837,
            -0.018120285123586655,
            0.8946328163146973,
            -4.088979721069336,
            -0.030905604362487793,
            1.3301695585250854,
            2.4469268321990967,
            -0.8039196133613586,
            -2.2289369106292725,
            5.172371864318848,
            2.1566479206085205,
            4.804903030395508,
            0.6572930216789246,
            0.4265599250793457,
            -3.444549798965454,
            2.1589865684509277,
            4.603298187255859,
            -1.4138598442077637,
            -0.4377579391002655,
            3.763698101043701,
            -2.8675475120544434,
            7.113997459411621,
            3.192139148712158,
            2.2919840812683105,
            -0.4119913578033447,
            -3.376894474029541,
            3.8178272247314453,
            -1.1200143098831177,
            -3.4225564002990723,
            1.1238811016082764,
            2.381631374359131,
            -2.2208685874938965,
            -4.3061418533325195,
            -0.2796400189399719,
            -1.3761016130447388,
            0.6410079598426819,
            -4.632793426513672,
            3.9741454124450684,
            -3.0682921409606934,
            -0.14486952126026154,
            5.348374366760254,
            0.65946364402771,
            -2.777031421661377,
            -0.8873746395111084,
            0.9908156394958496,
            -0.8072749376296997,
            1.2192354202270508,
            0.9107617735862732,
            0.4447630047798157,
            0.4803752899169922,
            -5.926405429840088,
            -3.2800936698913574,
            -1.0505857467651367,
            8.641157150268555,
            9.07605266571045,
            3.986924409866333,
            2.1188957691192627,
            -2.3421099185943604,
            -4.033641815185547,
            1.0552445650100708,
            4.74058198928833,
            3.655613422393799,
            -0.9677817225456238,
            -0.10842619091272354,
            0.6115376949310303,
            1.777726411819458,
            -1.831881046295166,
            0.8394520878791809,
            1.655802607536316,
            -1.5858848094940186,
            -6.6050825119018555,
            0.4666348695755005,
            -3.092648506164551,
            -0.03475281596183777,
            -1.9586403369903564,
            -6.40967321395874,
            1.973289966583252,
            -6.297003269195557,
            -1.3356207609176636,
            -1.5828289985656738,
            0.40973612666130066,
            -0.6052210330963135,
            -0.290714830160141,
            2.6921420097351074,
            -1.613846778869629,
            -1.1566905975341797,
            -2.934126377105713,
            1.9022561311721802,
            -2.5958240032196045,
            0.5237287878990173,
            0.2124444842338562,
            2.318479299545288,
            -2.053722858428955,
            -4.9635796546936035,
            -2.0597054958343506,
            -1.1829477548599243,
            0.3624492287635803,
            -0.5160043239593506,
            -1.5822539329528809,
            3.935865879058838,
            4.688594341278076,
            -0.3878188133239746,
            -3.8708479404449463,
            0.3553641438484192,
            2.656214952468872,
            -7.910458564758301,
            -2.419498920440674,
            -3.505599021911621,
            -2.128216028213501,
            -0.9013896584510803,
            -3.3206028938293457,
            1.9391717910766602,
            -4.6338725090026855,
            -0.08172974735498428,
            -1.7989006042480469,
            0.1533520370721817,
            -2.3185458183288574,
            -6.766164302825928,
            1.7499746084213257,
            -1.498965859413147,
            3.2327136993408203,
            3.787552833557129,
            -1.2832798957824707,
            1.6176608800888062,
            0.3284163177013397,
            1.97465181350708,
            5.503122329711914,
            -0.2861420512199402,
            0.20136672258377075,
            -1.7070971727371216,
            1.4096691608428955,
            -1.1732006072998047,
            -0.4568485617637634,
            1.1927244663238525,
            -0.6429911255836487,
            0.11379820108413696,
            17.340946197509766,
            1.621822476387024,
            -2.8711588382720947,
            -0.33888691663742065,
            -1.936894416809082,
            -4.058778762817383,
            -2.7068586349487305,
            -0.003636978566646576,
            -0.05492211878299713,
            4.903600215911865,
            -0.9993600845336914,
            -6.173632621765137,
            -1.6354212760925293,
            -0.7663251161575317,
            -3.1094272136688232,
            -0.0906715840101242,
            -2.591688394546509,
            2.3980021476745605,
            3.39591121673584,
            0.007005929946899414,
            -0.5389883518218994,
            1.9684523344039917,
            -1.9381479024887085,
            -1.1322301626205444,
            -0.2819887697696686,
            1.3259649276733398,
            -0.6281076669692993,
            3.229306697845459,
            -4.6486124992370605,
            2.5785481929779053,
            2.4883031845092773,
            -0.42536747455596924,
            -0.002422034740447998,
            1.1000550985336304,
            -4.293967247009277,
            5.808765888214111,
            8.618571281433105,
            2.1517908573150635,
            3.3852553367614746,
            1.9293313026428223,
            -0.1821422576904297,
            -0.048198722302913666,
            0.5475963950157166,
            -1.9518206119537354,
            0.10473054647445679,
            1.3964070081710815,
            2.096343517303467,
            0.579075813293457,
            -1.6288442611694336,
            4.507382392883301,
            -0.10664112120866776,
            0.2701750099658966,
            -2.7461202144622803,
            2.3513200283050537,
            -1.1825984716415405,
            -1.5546727180480957,
            -0.8090968132019043,
            -3.6204915046691895,
            2.1569578647613525,
            0.8630495667457581,
            1.505774974822998,
            -0.20746320486068726,
            0.7052419185638428,
            -3.6606175899505615,
            1.7055747509002686,
            0.1784750521183014,
            -0.592978835105896,
            1.500357985496521,
            1.2884852886199951,
            1.3591809272766113,
            0.8256226778030396,
            2.0239720344543457,
            -0.8613060712814331,
            -1.8686754703521729,
            1.995145320892334,
            -4.129187107086182,
            0.5751819014549255,
            -3.5251147747039795,
            0.4896288514137268,
            3.237095355987549,
            -2.6400444507598877,
            1.5194494724273682,
            -0.13568758964538574,
            -1.3391475677490234,
            5.407979965209961,
            -3.1199333667755127,
            3.8644251823425293,
            -0.15763425827026367,
            -7.560573577880859,
            3.232696771621704,
            1.158557653427124,
            0.5412771105766296,
            2.038163900375366,
            -0.14153218269348145,
            -0.27948540449142456,
            -3.8964970111846924,
            -0.8188543915748596,
            2.071852684020996,
            -4.527144908905029,
            -5.124229907989502,
            1.7248286008834839,
            2.851370334625244,
            3.2852420806884766,
            1.4296512603759766,
            -4.007598876953125,
            0.23534470796585083,
            2.4004952907562256,
            -7.258940696716309,
            -3.8868966102600098,
            -1.1596386432647705,
            -0.9560220837593079,
            -1.596161127090454,
            -2.97383189201355,
            -0.36380821466445923,
            0.959369421005249,
            -2.884342908859253,
            0.5312055349349976,
            2.7683026790618896,
            0.9856387376785278,
            4.0410027503967285,
            -3.4394965171813965,
            -0.48916757106781006,
            3.206777572631836,
            -4.210896968841553,
            2.299591064453125,
            -1.2320643663406372,
            -1.6543610095977783,
            1.4292523860931396,
            0.13172626495361328,
            1.6643718481063843,
            1.3371881246566772,
            -4.0806756019592285,
            -1.9148391485214233,
            -1.0019713640213013,
            -1.4874473810195923,
            -0.9740856885910034,
            3.67257022857666,
            2.5923349857330322,
            -4.414308547973633,
            4.965273857116699,
            1.3323012590408325,
            -4.307778835296631,
            -2.6010735034942627,
            7.117160320281982,
            0.7295481562614441,
            3.106802463531494,
            2.885678291320801,
            -0.05521288514137268,
            -3.135960340499878,
            0.21043114364147186,
            1.5335826873779297,
            0.13125158846378326,
            4.772937774658203,
            -1.491811752319336,
            -2.1270289421081543,
            -5.615297794342041
        ]
    },
    "authors": [
        {
            "authorId": "1736651",
            "name": "S. Levine"
        },
        {
            "authorId": "1488785534",
            "name": "Aviral Kumar"
        },
        {
            "authorId": "145499435",
            "name": "G. Tucker"
        },
        {
            "authorId": "2550764",
            "name": "Justin Fu"
        }
    ],
    "references": [
        {
            "paperId": "0fd601997cc50364235b6639850ee3ec55033a1b",
            "title": "An Optimistic Perspective on Offline Deep Reinforcement Learning"
        },
        {
            "paperId": "bb4b7bc08a3c1959b5806e15fe3fc99596c9d7b2",
            "title": "Off-policy Bandits with Deficient Support"
        },
        {
            "paperId": "0272b14dd471fe7b81df703af1b71d7600b77215",
            "title": "Accelerating Online Reinforcement Learning with Offline Datasets"
        },
        {
            "paperId": "28db20a81eec74a50204686c3cf796c42a020d2e",
            "title": "Conservative Q-Learning for Offline Reinforcement Learning"
        },
        {
            "paperId": "dea0f1c5949f8d898b9b6ff68226a781558e413c",
            "title": "MOPO: Model-based Offline Policy Optimization"
        },
        {
            "paperId": "309c2c5ee60e725244da09180f913cd8d4b8d4e9",
            "title": "MOReL : Model-Based Offline Reinforcement Learning"
        },
        {
            "paperId": "5d0e2635a1ebe2c9347529975bc876d4286c9ab7",
            "title": "Distributionally Robust Neural Networks"
        },
        {
            "paperId": "a326d9f2d2d351001fece788165dbcbb524da2e4",
            "title": "D4RL: Datasets for Deep Data-Driven Reinforcement Learning"
        },
        {
            "paperId": "9a08c1e181ae42381ef0bbb8199e4832621ff2e3",
            "title": "Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning"
        },
        {
            "paperId": "b76bd29b659388a8a0e83348d002e41e5e4a3489",
            "title": "DisCor: Corrective Feedback in Reinforcement Learning via Distribution Correction"
        },
        {
            "paperId": "bbac680797af0f7ce4cdcc6430ff001fa0dfe670",
            "title": "Learning to Generalize Across Long-Horizon Tasks from Human Demonstrations"
        },
        {
            "paperId": "50d18a58adbfa995fb172b942dd3c9f31b490fc9",
            "title": "Batch Stationary Distribution Estimation"
        },
        {
            "paperId": "2b0e79ed1340a79344e37b6f57191b76d810962f",
            "title": "GenDICE: Generalized Offline Estimation of Stationary Values"
        },
        {
            "paperId": "0881655dcdf891f529ebe7ac18301e138a5e265b",
            "title": "Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning"
        },
        {
            "paperId": "e90e7b1f594ee21f5646a4786a7c6246af474261",
            "title": "BADGR: An Autonomous Self-Supervised Learning-Based Navigation System"
        },
        {
            "paperId": "568c6c8ca820a161c1097fe3bcc947f436075f57",
            "title": "GradientDICE: Rethinking Generalized Offline Estimation of Stationary Values"
        },
        {
            "paperId": "a2ae87883e63685ab989ab39bf13deed6de63684",
            "title": "Reinforcement Learning via Fenchel-Rockafellar Duality"
        },
        {
            "paperId": "27d78a26ddb9698b9cefcf6cdeafa4f834466103",
            "title": "AlgaeDICE: Policy Gradient from Arbitrary Experience"
        },
        {
            "paperId": "b5461f9c5d65e87561e00848921ee797902dae14",
            "title": "Causality for Machine Learning"
        },
        {
            "paperId": "7b5773650b4e52568d4e9e4c6384e9034d40fd66",
            "title": "Minimax Weight and Q-Function Learning for Off-Policy Evaluation"
        },
        {
            "paperId": "3e519d85cdcefdd1d2ad89829d6ad445695d8c58",
            "title": "RoboNet: Large-Scale Multi-Robot Learning"
        },
        {
            "paperId": "1757fa0cbcbceb2a7c991e64a660a84cef914143",
            "title": "From Importance Sampling to Doubly Robust Policy Gradient"
        },
        {
            "paperId": "c2c5d4650beb72a0e00a4c384064f4ab2ddef1dc",
            "title": "Doubly Robust Bias Reduction in Infinite Horizon Off-Policy Estimation"
        },
        {
            "paperId": "ad14227e4f51276892ffc37aa43fd8750bb5eba8",
            "title": "Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning"
        },
        {
            "paperId": "78aea5a51feb90e988a4d00302616e56d1be5eb0",
            "title": "Scaling data-driven robotics with reward sketching and batch reinforcement learning"
        },
        {
            "paperId": "cac78ad6696d6b6370942679f7d0e4425ef4b3e7",
            "title": "A Framework for Data-Driven Robotics"
        },
        {
            "paperId": "9be492858863c8c7c24be1ecb75724de5086bd8e",
            "title": "Behavior Regularized Offline Reinforcement Learning"
        },
        {
            "paperId": "f49cfdbc1052fd012242743c2da27ee8bb4f9277",
            "title": "Efficiently Breaking the Curse of Horizon in Off-Policy Evaluation with Double Reinforcement Learning"
        },
        {
            "paperId": "035c298e77b21968425eb44598c0516b1efbe4be",
            "title": "Efficiently Breaking the Curse of Horizon: Double Reinforcement Learning in Infinite-Horizon Processes"
        },
        {
            "paperId": "0b016c2d9c6846ea7be39e51a4e74fce7d07e825",
            "title": "Trajectory-wise Control Variates for Variance Reduction in Policy Gradient Methods"
        },
        {
            "paperId": "fa9c6c6fade247fec415407c2d4b4ea950924272",
            "title": "Safe Policy Improvement with Soft Baseline Bootstrapping"
        },
        {
            "paperId": "4012d4ab621f3f5f04b0f91849a60c6eaabe64b4",
            "title": "An Optimistic Perspective on Offline Reinforcement Learning"
        },
        {
            "paperId": "cc4435c2c1ea079721f48d08d0ae3436599d1533",
            "title": "Striving for Simplicity in Off-policy Deep Reinforcement Learning"
        },
        {
            "paperId": "753b7a701adc1b6072378bd048cfa8567885d9c7",
            "title": "Invariant Risk Minimization"
        },
        {
            "paperId": "57daffd65a5d73a439903f3e50950c21c9eba687",
            "title": "Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human Preferences in Dialog"
        },
        {
            "paperId": "9001698e033524864d4d45f051a5ba362d4afd9e",
            "title": "When to Trust Your Model: Model-Based Policy Optimization"
        },
        {
            "paperId": "d9f1f536c67e650992ec4afd66166740f860c99b",
            "title": "A Survey of Autonomous Driving: Common Practices and Emerging Technologies"
        },
        {
            "paperId": "82b4b03a4659d6e04bd7cbf51d6e08fde1348dbd",
            "title": "Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction"
        },
        {
            "paperId": "875280d96b2f138902061ae6409249ee4ded0da3",
            "title": "DualDICE: Behavior-Agnostic Estimation of Discounted Stationary Distribution Corrections"
        },
        {
            "paperId": "e60e0bbbd2d5c853c0aaae04ed6a9531122ba1ca",
            "title": "Intrinsically Efficient, Stable, and Bounded Off-Policy Evaluation for Reinforcement Learning"
        },
        {
            "paperId": "bc65f1fbf0ac429ffa1104cd8e026df861167331",
            "title": "Learning When-to-Treat Policies"
        },
        {
            "paperId": "62924cef027a66a75b5465ebb7a926c06f95790f",
            "title": "Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment"
        },
        {
            "paperId": "1fd4694e7c2d9c872a427d50e81b5475056de6bc",
            "title": "Model-Based Reinforcement Learning for Atari"
        },
        {
            "paperId": "4bdfc8c2c5f2d6d1a6ef51c3252bda70b01a1ebb",
            "title": "Generalized Off-Policy Actor-Critic"
        },
        {
            "paperId": "ab131a2e397a3d5b987d78fef31c3b060a118619",
            "title": "Diagnosing Bottlenecks in Deep Q-learning Algorithms"
        },
        {
            "paperId": "1df5d8dbc02ff5d8489a2c1d4514eeef56188b39",
            "title": "PIPPS: Flexible Model-Based Policy Search Robust to the Curse of Chaos"
        },
        {
            "paperId": "dc4ec37102afb166b96abc268ae3dc15e230d776",
            "title": "Off-Policy Deep Reinforcement Learning by Bootstrapping the Covariate Shift"
        },
        {
            "paperId": "9aa3ae820772b5f25df9d498bd60c72e70d1b5e6",
            "title": "Guidelines for reinforcement learning in healthcare"
        },
        {
            "paperId": "5285cb8faada5de8a92a47622950f6cfd476ac1d",
            "title": "Off-Policy Deep Reinforcement Learning without Exploration"
        },
        {
            "paperId": "6bc692616db7b1a7ef2ea7c270c893adfb57ed0e",
            "title": "Deep Reinforcement Learning and the Deadly Triad"
        },
        {
            "paperId": "54cd5a5ddd286442fa94da7ec344a7e76b9a6ccd",
            "title": "Visual Foresight: Model-Based Deep Reinforcement Learning for Vision-Based Robotic Control"
        },
        {
            "paperId": "a79c07a7c666e22566d6b41a2e283d902509facd",
            "title": "An Off-policy Policy Gradient Theorem Using Emphatic Weightings"
        },
        {
            "paperId": "b14432f521d626f136a2cce9e71c1ba85dbc178a",
            "title": "Reward-estimation variance elimination in sequential decision processes"
        },
        {
            "paperId": "fea3e63c97c7292dc6fbcb3ffe7131eb54053986",
            "title": "Learning Latent Dynamics for Planning from Pixels"
        },
        {
            "paperId": "e81ea45d8bec329fdb11fd84990852f620895d6f",
            "title": "Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation"
        },
        {
            "paperId": "e8eb2656bff427c97003c432e15cf16175b44cdf",
            "title": "Stochastic Primal-Dual Q-Learning"
        },
        {
            "paperId": "55860e5b42497c097f790f3fdbff0dbf18f623f1",
            "title": "Composable Action-Conditioned Predictors: Flexible Off-Policy Learning for Robot Navigation"
        },
        {
            "paperId": "9b114351bf97a66ab8cfef4c3b04a0f70503295e",
            "title": "Deep Imitative Models for Flexible Inference, Planning, and Control"
        },
        {
            "paperId": "b2174399c04a7d894bcd2dc7848a35aed4c67f80",
            "title": "Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience"
        },
        {
            "paperId": "ee9893ff2aa325ff3c9920f247436c514fd8b512",
            "title": "SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning"
        },
        {
            "paperId": "d333f99881b09426283a9c7a1d25f7ac30d63062",
            "title": "Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees"
        },
        {
            "paperId": "fe14961357ef37735ed95be0ffb30767a468e14f",
            "title": "Supervised Reinforcement Learning with Recurrent Neural Network for Dynamic Treatment Recommendation"
        },
        {
            "paperId": "c09a440abdc92d187c53812d8aa29ed7de29a37b",
            "title": "Learning to Drive in a Day"
        },
        {
            "paperId": "eb37e7b76d26b75463df22b2a3aa32b6a765c672",
            "title": "QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation"
        },
        {
            "paperId": "f21b4bfafa12ca1434b2b73c19cb2178b88bca3f",
            "title": "Evaluating Reinforcement Learning Algorithms in Observational Health Settings"
        },
        {
            "paperId": "56136aa0b2c347cbcf3d50821f310c4253155026",
            "title": "Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models"
        },
        {
            "paperId": "3a523641cab99381db21ff30df4050f7e2f546b3",
            "title": "Dual Policy Iteration"
        },
        {
            "paperId": "4f0b8f730273e9f11b2bfad2415485414b96299f",
            "title": "BDD100K: A Diverse Driving Video Database with Scalable Annotation Tooling"
        },
        {
            "paperId": "6ecc4b1ab05f3ec12484a0ea36abfd6271c5c5ba",
            "title": "Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review"
        },
        {
            "paperId": "4d3b69bdcd1d325d29badc6a38f2d6cc504fe7d1",
            "title": "Sim-to-Real: Learning Agile Locomotion For Quadruped Robots"
        },
        {
            "paperId": "16a931f72e51b8cc4acc2a586ee53fb9b0d8959d",
            "title": "Learning Synergies Between Pushing and Grasping with Self-Supervised Deep Reinforcement Learning"
        },
        {
            "paperId": "9ff74f68b0e82bed43c86882aebed1e5d5ac5da5",
            "title": "The AdobeIndoorNav Dataset: Towards Deep Reinforcement Learning based Real-world Indoor Robot Visual Navigation"
        },
        {
            "paperId": "d7b32bf240bb3b2f2a98d87ea21b669226e0f9d8",
            "title": "More Robust Doubly Robust Off-policy Evaluation"
        },
        {
            "paperId": "80196cdfcd0c6ce2953bf65a7f019971e2026386",
            "title": "IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures"
        },
        {
            "paperId": "f9ac7836563f98919095e7c87775f4c4932261aa",
            "title": "Offline A/B Testing for Recommender Systems"
        },
        {
            "paperId": "811df72e210e20de99719539505da54762a11c6d",
            "title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor"
        },
        {
            "paperId": "1bd66197d692581f4ac507107184ca9110b61d7d",
            "title": "SBEED: Convergent Reinforcement Learning with Nonlinear Function Approximation"
        },
        {
            "paperId": "3a5f60c2dea325de1dc92ae1eb7a513945bd6af1",
            "title": "Boosting the Actor with Dual Critic"
        },
        {
            "paperId": "5fd8f4d7bcea08e15229a6d0b6ba1bc11d44f348",
            "title": "Smoothed Dual Embedding Control"
        },
        {
            "paperId": "7eb0db941fbf19857631ec1c907f2888ea308779",
            "title": "Safe Policy Improvement with Baseline Bootstrapping"
        },
        {
            "paperId": "8890bb44abb89601c950eb5e56172bb58d5beea8",
            "title": "End-to-End Offline Goal-Oriented Dialog Policy Learning via Policy Gradient"
        },
        {
            "paperId": "71d7cc5f527554bb54adc32990cbc01eac3aee6b",
            "title": "Deep reinforcement learning for automated radiation adaptation in lung cancer"
        },
        {
            "paperId": "a729073d3ec9a159b86fd438e06f3dff2735beb5",
            "title": "Deep Reinforcement Learning for Sepsis Treatment"
        },
        {
            "paperId": "ec4df801c640169e18d8da1bdc65a0b6fc2d3d94",
            "title": "Leave no Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning"
        },
        {
            "paperId": "818c52f4ba56cb8cf152ad614f2f4803057a5cfe",
            "title": "Certifying Some Distributional Robustness with Principled Adversarial Training"
        },
        {
            "paperId": "c27db32efa8137cbf654902f8f728f338e55cd1c",
            "title": "Mastering the game of Go without human knowledge"
        },
        {
            "paperId": "880a018f1e0a587b39a4ca9a5c9f6ba4029e2ea1",
            "title": "End-to-End Driving Via Conditional Imitation Learning"
        },
        {
            "paperId": "1d3aa6e84299f8d36629e147679614ae09e55d2e",
            "title": "Agile Autonomous Driving using End-to-End Deep Imitation Learning"
        },
        {
            "paperId": "bdf6572b67a6c5d8aacd39e1826db2c5c8f85716",
            "title": "The Uncertainty Bellman Equation and Exploration"
        },
        {
            "paperId": "cce22bf6405042a965a86557684c46a441f2a736",
            "title": "Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning"
        },
        {
            "paperId": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "title": "Proximal Policy Optimization Algorithms"
        },
        {
            "paperId": "cf020b27d06efb28f3e5db264aceeec1f397817b",
            "title": "Value Prediction Network"
        },
        {
            "paperId": "a697f57b76c9072bb85b56fe6f987c598802b6ce",
            "title": "A Fast Integrated Planning and Control Framework for Autonomous Driving via Imitation Learning"
        },
        {
            "paperId": "749d4dbe27b1a587c8827af6659e954db8081080",
            "title": "Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning"
        },
        {
            "paperId": "88880d88073a99107bbc009c9f4a4197562e1e44",
            "title": "Safe Model-based Reinforcement Learning with Stability Guarantees"
        },
        {
            "paperId": "c9ac59fd59289eaedcb11cdf0cdb83a6d98f6d7f",
            "title": "A Reinforcement Learning Approach to Weaning of Mechanical Ventilation in Intensive Care Units"
        },
        {
            "paperId": "8db9df2eadea654f128c1887722c677c708e8a47",
            "title": "Deep Reinforcement Learning framework for Autonomous Driving"
        },
        {
            "paperId": "ff7bcaa4556cb13fc7bf03e477172493546172cd",
            "title": "What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?"
        },
        {
            "paperId": "9172cd6c253edf7c3a1568e03577db20648ad0c4",
            "title": "Reinforcement Learning with Deep Energy-Based Policies"
        },
        {
            "paperId": "ba847beb3ed679ff56d0414c04748de88ed46af9",
            "title": "Consistent On-Line Off-Policy Evaluation"
        },
        {
            "paperId": "1f81de57298677c98736d8b6f6736a279c75cc35",
            "title": "Predictive Off-Policy Policy Evaluation for Nonstationary Decision Problems, with Applications to Digital Marketing"
        },
        {
            "paperId": "11732140ada8e05c84e9024927c297565ebd6ad8",
            "title": "Batch Policy Gradient Methods for Improving Neural Conversation Models"
        },
        {
            "paperId": "d74ed94c7a83298a4b4f0e1c70200126e464cc05",
            "title": "1 year, 1000 km: The Oxford RobotCar dataset"
        },
        {
            "paperId": "2c2bed7759d817b023732b6e9b5d11911ea49dd5",
            "title": "Stochastic Primal-Dual Methods and Sample Complexity of Reinforcement Learning"
        },
        {
            "paperId": "117f12f75cfe4d5705d7beabbe961b2ced0d7025",
            "title": "Optimal and Adaptive Off-policy Evaluation in Contextual Bandits"
        },
        {
            "paperId": "39e1ecfb83eb34d177ef4bcdf522c5436fc76da0",
            "title": "An online primal-dual method for discounted Markov decision processes"
        },
        {
            "paperId": "ae42c0cff384495683192b06bd985cdd7a54632a",
            "title": "Interaction Networks for Learning about Objects, Relations and Physics"
        },
        {
            "paperId": "f7ac2479e686eb2a7a8afc23f99f213fcd3c5292",
            "title": "(CAD)$^2$RL: Real Single-Image Flight without a Single Real Image"
        },
        {
            "paperId": "4c25f50c7451fa72c562e21e3b11e416b11f74c8",
            "title": "Learning to Act by Predicting the Future"
        },
        {
            "paperId": "6a43d91c8d883e3463b358571125fa0ec7298b3a",
            "title": "Sample Efficient Actor-Critic with Experience Replay"
        },
        {
            "paperId": "8f92b4ea04758df2acfb49bd46a4cde923c3ddcb",
            "title": "Deep visual foresight for planning robot motion"
        },
        {
            "paperId": "e37b999f0c96d7136db07b0185b837d5decd599a",
            "title": "Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates"
        },
        {
            "paperId": "80763fc2ae7b2f9cba9e44c599b394abef84fbf2",
            "title": "Learning from Conditional Distributions via Dual Embeddings"
        },
        {
            "paperId": "88909a57da9a43ceb52aae8424b1f348dba99cab",
            "title": "Why is Posterior Sampling Better than Optimism for Reinforcement Learning?"
        },
        {
            "paperId": "bd58d3265263a87159a3f7ed3a5e4c887c5c0792",
            "title": "Safe Policy Improvement by Minimizing Robust Baseline Regret"
        },
        {
            "paperId": "6d15118290aafb76ee5e42e14ec35f90607dee44",
            "title": "Bootstrapping with Models: Confidence Intervals for Off-Policy Evaluation"
        },
        {
            "paperId": "ffdcad14d2f6a12f607b59f88da4a939f4821691",
            "title": "f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization"
        },
        {
            "paperId": "42dc11874d7894325aca528c8b23756d79c63679",
            "title": "Off-policy evaluation for slate recommendation"
        },
        {
            "paperId": "95cd83603a0d2b6918a8e34a5637a8f382da96f5",
            "title": "MIMIC-III, a freely accessible critical care database"
        },
        {
            "paperId": "0e3cc46583217ec81e87045a4f9ae3478a008227",
            "title": "End to End Learning for Self-Driving Cars"
        },
        {
            "paperId": "ec8a2f6cfe72309f5f1608d22ec28778d3ee976a",
            "title": "Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning"
        },
        {
            "paperId": "494e2d5b40dcebde349f9872c7317e5003f9c5d2",
            "title": "Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection"
        },
        {
            "paperId": "b9dd7a59a101fcecc6fe0e7aed517e84a7df7d2e",
            "title": "Learning Physical Intuition of Block Towers by Example"
        },
        {
            "paperId": "4b63e34276aa98d5345efa7fe09bb06d8a9d8f52",
            "title": "Deep Exploration via Bootstrapped DQN"
        },
        {
            "paperId": "84680b30a20775e5d319419a7f3f2a93e57c2a61",
            "title": "Value Iteration Networks"
        },
        {
            "paperId": "2fdb536da39a014c598ea67b0db88431fcd852a8",
            "title": "Doubly Robust Off-policy Value Evaluation for Reinforcement Learning"
        },
        {
            "paperId": "6640f4e4beae786f301928d82a9f8eb037aa6935",
            "title": "Learning Continuous Control Policies by Stochastic Value Gradients"
        },
        {
            "paperId": "f03b4ff1b4943691cec703b508c0a91f2d97a881",
            "title": "Supersizing self-supervision: Learning to grasp from 50K tries and 700 robot hours"
        },
        {
            "paperId": "83ff34eac4fc50cb92a34b5f2b10925aa22b3c12",
            "title": "Generalized Emphatic Temporal Difference Learning: Bias-Variance Analysis"
        },
        {
            "paperId": "024006d4c2a89f7acacc6e4438d156525b60a98f",
            "title": "Continuous control with deep reinforcement learning"
        },
        {
            "paperId": "bb91520cddf4bff2f42cbc278c4837e577cafdc1",
            "title": "Emphatic TD Bellman Operator is a Contraction"
        },
        {
            "paperId": "e4257bc131c36504a04382290cbc27ca8bb27813",
            "title": "Action-Conditional Video Prediction using Deep Networks in Atari Games"
        },
        {
            "paperId": "0c11db37dd24ca3a866481303bebfc37a93a37d0",
            "title": "Personalized Ad Recommendation Systems for Life-Time Value Optimization with Guarantees"
        },
        {
            "paperId": "22dc2f3a4afea29ce76fb02a156943afadd6cbd7",
            "title": "A Deeper Look at Planning as Learning from Replay"
        },
        {
            "paperId": "bb1a17010254abfa5e1f2a17553582ce449f8e16",
            "title": "Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images"
        },
        {
            "paperId": "1baba004465b6721717de67af1b0bf375d24863a",
            "title": "On Convergence of Emphatic Temporal-Difference Learning"
        },
        {
            "paperId": "f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6",
            "title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning"
        },
        {
            "paperId": "b6b8a1b80891c96c28cc6340267b58186157e536",
            "title": "End-to-End Training of Deep Visuomotor Policies"
        },
        {
            "paperId": "d6cc19f33b7714de62e45295c8be1bf1b0642557",
            "title": "An Emphatic Approach to the Problem of Off-policy Temporal-Difference Learning"
        },
        {
            "paperId": "449532187c94af3dd3aa55e16d2c50f7854d2199",
            "title": "Trust Region Policy Optimization"
        },
        {
            "paperId": "a8bbcf5ea723b1f9b7d2257dd6fd492cd280f0af",
            "title": "High-Confidence Off-Policy Evaluation"
        },
        {
            "paperId": "200d72f1fe0cb314d431c1396f4c133307fd6736",
            "title": "Doubly Robust Policy Evaluation and Optimization"
        },
        {
            "paperId": "e70f54ee0ab57394f4fdc1571f861a802fe80655",
            "title": "Offline and online evaluation of news recommender systems at swissinfo.ch"
        },
        {
            "paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd",
            "title": "ImageNet Large Scale Visual Recognition Challenge"
        },
        {
            "paperId": "3df673220e67cc55d40fbe495c9fba999d820613",
            "title": "Bias in Natural Actor-Critic Algorithms"
        },
        {
            "paperId": "687d0e59d5c35f022ce4638b3e3a6142068efc94",
            "title": "Deterministic Policy Gradient Algorithms"
        },
        {
            "paperId": "66ad2fbc8b73242a889699868611fcf239e3435d",
            "title": "Semi-supervised Learning with Deep Generative Models"
        },
        {
            "paperId": "2319a491378867c7049b3da055c5df60e1671158",
            "title": "Playing Atari with Deep Reinforcement Learning"
        },
        {
            "paperId": "244539f454800697ed663326b7cfba337ca0c2ec",
            "title": "Guided Policy Search"
        },
        {
            "paperId": "71b552b2e058d5a6a760ba203f10f13be759edd3",
            "title": "Synthesis and stabilization of complex behaviors through online trajectory optimization"
        },
        {
            "paperId": "b006aefa9c8be8c33138c4c5352f4d2d44378be9",
            "title": "Counterfactual reasoning and learning systems: the example of computational advertising"
        },
        {
            "paperId": "0067343a36c0292f36e627eb353f751c8a39f99a",
            "title": "Linear Off-Policy Actor-Critic"
        },
        {
            "paperId": "5e84a5549b2a985bd1bc0c3535de96c448b8b8cb",
            "title": "Reinforcement learning in feedback control"
        },
        {
            "paperId": "60b7d47758a71978e74edff6dd8dea4d9c791d7a",
            "title": "PILCO: A Model-Based and Data-Efficient Approach to Policy Search"
        },
        {
            "paperId": "50e9a441f56124b7b969e6537b66469a0e1aa707",
            "title": "Horde: a scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction"
        },
        {
            "paperId": "6695f04347569c829fe11c5ade2a2027fa6649ad",
            "title": "Sample-efficient batch reinforcement learning for dialogue management optimization"
        },
        {
            "paperId": "8acc06ebabba26b831787c08cba3c9ab7caee850",
            "title": "Informing sequential clinical decision-making through\u00a0reinforcement learning: an empirical study"
        },
        {
            "paperId": "d64705e93df52a219a92e7ca993af1fab28dc8de",
            "title": "Error Propagation for Approximate Policy and Value Iteration"
        },
        {
            "paperId": "79ab3c49903ec8cb339437ccf5cf998607fc313e",
            "title": "A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning"
        },
        {
            "paperId": "70e10a5459c6f1aaf346ee4f2dcc837151fbe75c",
            "title": "Efficient Reductions for Imitation Learning"
        },
        {
            "paperId": "28886248acf75e7b1cca167669161d9d214ed662",
            "title": "Learning from Logged Implicit Exploration Data"
        },
        {
            "paperId": "ec0072bc37f83f1a81459df43289613e04cc61e1",
            "title": "A contextual-bandit approach to personalized news article recommendation"
        },
        {
            "paperId": "9faba7a90a7415cc1ff3d2010bb3648f8ebdb3a2",
            "title": "Neuroevolutionary reinforcement learning for generalized helicopter control"
        },
        {
            "paperId": "a97ba611613d6ee20ec441a15e18cab9d4ebd3e6",
            "title": "Fast gradient-descent methods for temporal-difference learning with linear function approximation"
        },
        {
            "paperId": "5e706a090b154018caeb33b48c21df4d902a6079",
            "title": "On integral probability metrics, \u03c6-divergences and binary classification"
        },
        {
            "paperId": "0cafe2903b097fc042782c359cb231ea34ef7ed3",
            "title": "Near-optimal Regret Bounds for Reinforcement Learning"
        },
        {
            "paperId": "ab71bdfb49d4ccafce2e345893bb29284905dc3b",
            "title": "Hybrid Reinforcement/Supervised Learning of Dialogue Policies from Fixed Data Sets"
        },
        {
            "paperId": "22164c93285f86927114a14a7e5cf855f47ae66b",
            "title": "Adaptive Treatment of Epilepsy via Batch-mode Reinforcement Learning"
        },
        {
            "paperId": "504f7b5cb348a29f7192b877627f87f9f9c72590",
            "title": "An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning"
        },
        {
            "paperId": "cfed0e2068d92b25734a9b1c09480d361af34494",
            "title": "Exploration scavenging"
        },
        {
            "paperId": "c4673454332a692b259840a3ef80fc51557ac85b",
            "title": "Gaussian Processes and Reinforcement Learning for Identification and Control of an Autonomous Blimp"
        },
        {
            "paperId": "8570302f7b63e8fcf87030f556b065fd8c260021",
            "title": "Linearly-solvable Markov decision problems"
        },
        {
            "paperId": "41356b8998dd7ddf89429445320d82a269e3ab14",
            "title": "Tree-Based Batch Mode Reinforcement Learning"
        },
        {
            "paperId": "282001869bd502c7917db8b32b75593addfbbc68",
            "title": "Neural Fitted Q Iteration - First Experiences with a Data Efficient Neural Reinforcement Learning Method"
        },
        {
            "paperId": "b750a17921d32936425e05f8b00b96569e2fc5a6",
            "title": "Least-Squares Policy Iteration"
        },
        {
            "paperId": "523b4ce1c2a1336962444abc1dec215756c2f3e6",
            "title": "Approximately Optimal Approximate Reinforcement Learning"
        },
        {
            "paperId": "fa50cb361cef1a89c370a9f4434a3f33fe33febd",
            "title": "Learning from Scarce Experience"
        },
        {
            "paperId": "872d01b512def14d5a7d9dedecb4f8b3a67d979b",
            "title": "Marginal Mean Models for Dynamic Regimes"
        },
        {
            "paperId": "e54152403da98a0403afef8477d42383d606e1f9",
            "title": "Off-Policy Temporal Difference Learning with Function Approximation"
        },
        {
            "paperId": "84b23b154ef3083839a4da8c460a1e1c110ea63b",
            "title": "Autonomous helicopter control using reinforcement learning policy search methods"
        },
        {
            "paperId": "b18833db0de9393d614d511e60821a1504fc6cd1",
            "title": "A Natural Policy Gradient"
        },
        {
            "paperId": "78020db7e3d968f6e6cc26d18e31e5b668ca7fee",
            "title": "Eligibility Traces for Off-Policy Policy Evaluation"
        },
        {
            "paperId": "a20f0ce0616def7cc9a87446c228906cd5da093b",
            "title": "Policy Gradient Methods for Reinforcement Learning with Function Approximation"
        },
        {
            "paperId": "2b11305f69641ecb8bd4a5e59cfebe41ad9ed989",
            "title": "TD-Gammon, a Self-Teaching Backgammon Program, Achieves Master-Level Play"
        },
        {
            "paperId": "03b7e51c52084ac1db5118342a00b5fbcfc587aa",
            "title": "Q-learning"
        },
        {
            "paperId": "9cd8193a66cf53143cbba6ccb0c7b9c2ebf2452b",
            "title": "Self-improving reactive agents based on reinforcement learning, planning and teaching"
        },
        {
            "paperId": "831edc3d67457db83da40d260e93bfd7559347ae",
            "title": "Dyna, an integrated architecture for learning, planning, and reacting"
        },
        {
            "paperId": null,
            "title": "Does on-policy data collection fix errors in reinforcement learning? https://bair.berkeley.edu/blog/2020/03/16/discor"
        },
        {
            "paperId": "3a5ac09e759f3223ee78b995ae2b519efc0f9292",
            "title": "Introduction to Reinforcement Learning"
        },
        {
            "paperId": null,
            "title": "Off-policy policy gradient with state distribution correction"
        },
        {
            "paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82",
            "title": "Deep Learning"
        },
        {
            "paperId": "5c65d095600d6c647426fa3bc45031b208882d5f",
            "title": "Batch Reinforcement Learning"
        },
        {
            "paperId": "ac4af1df88e178386d782705acc159eaa0c3904a",
            "title": "Actor-Critic Algorithms"
        }
    ]
}