{
    "paperId": "7344b71d205a7ad71ebad2873c063d7008f231fc",
    "externalIds": {
        "ACL": "2016.iwslt-1.1",
        "DBLP": "conf/iwslt/CettoloNSBCF16",
        "MAG": "2953830716",
        "CorpusId": 19765788
    },
    "title": "The IWSLT 2016 Evaluation Campaign",
    "abstract": "The IWSLT 2016 Evaluation Campaign featured two tasks: the translation of talks and the translation of video conference conversations. While the first task extends previously offered tasks with talks from a different source, the second task is completely new. For both tasks, three tracks were organised: automatic speech recognition (ASR), spoken language translation (SLT), and machine translation (MT). Main translation directions that were offered are English to/from German and English to French. Additionally, the MT track included English to/from Arabic and Czech, as well as French to English. We received this year run submissions from 11 research labs. All runs were evaluated with objective metrics, while submissions for two of the MT talk tasks were also evaluated with human post-editing. Results of the human evaluation show improvements over the best submissions of last year.",
    "venue": "International Workshop on Spoken Language Translation",
    "year": 2016,
    "referenceCount": 38,
    "citationCount": 93,
    "influentialCitationCount": 11,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The IWSLT 2016 Evaluation Campaign featured two tasks: the translation of talks and thetranslation of video conference conversations, which showed improvements over the best submissions of last year."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "3077970",
            "name": "M. Cettolo"
        },
        {
            "authorId": "151149706",
            "name": "Niehues Jan"
        },
        {
            "authorId": "151220649",
            "name": "St\u00fcker Sebastian"
        },
        {
            "authorId": "2486762",
            "name": "L. Bentivogli"
        },
        {
            "authorId": "27086451",
            "name": "R. Cattoni"
        },
        {
            "authorId": "102811815",
            "name": "Marcello Federico"
        }
    ],
    "references": [
        {
            "paperId": "1416a33fe0c1ab8b16e13a73b565bab468207270",
            "title": "The University of Edinburgh\u2019s systems submission to the MT task at IWSLT"
        },
        {
            "paperId": "a1593496afff9f98e1ccb4a4e99069688439f00a",
            "title": "QCRI Machine Translation Systems for IWSLT 16"
        },
        {
            "paperId": "4b0fe8a85f396cb48c9894cf5069b36d1a4b6acc",
            "title": "Microsoft Speech Language Translation (MSLT) Corpus: The IWSLT 2016 release for English, French and German"
        },
        {
            "paperId": "ea6869663aa3fb7cd3ae63ed72773ae932d4b5a6",
            "title": "The MITLL-AFRL IWSLT 2016 Systems"
        },
        {
            "paperId": "57fa1b6652bb1f63b9b7573d57c2af6702af357e",
            "title": "LIMSI@IWSLT\u201916: MT Track"
        },
        {
            "paperId": "d223fa07e86d6486375119b055d8fec77c21a325",
            "title": "Neural versus Phrase-Based Machine Translation Quality: a Case Study"
        },
        {
            "paperId": "11595968389473196b0d60929dce09f358c3a691",
            "title": "The MateCat Tool"
        },
        {
            "paperId": "84629fdada0c109d498145cac8d35ab5be068db7",
            "title": "The efficacy of human post-editing for language translation"
        },
        {
            "paperId": "ea5cf5569eef0a99df9b6d92b628a33fc82ca2e7",
            "title": "On Some Pitfalls in Automatic Evaluation and Significance Testing for MT"
        },
        {
            "paperId": "facef9d98129c394beb5de4e0a6a144e602b492d",
            "title": "Evaluating Message Understanding Systems: An Analysis of the Third Message Understanding Conference (MUC-3)"
        },
        {
            "paperId": "60d30f6f6adb572c6d6ceca9be1065ad55bc79ee",
            "title": "Computer Intensive Methods for Testing Hypotheses: An Introduction"
        },
        {
            "paperId": "2b75974d31758c0ee646b683b95b10555c9cd550",
            "title": "The UMD Machine Translation Systems at IWSLT 2016: English-to-French Translation of Speech Transcripts"
        },
        {
            "paperId": "aea2f595131e44530b0665f916ab011a770cf163",
            "title": "RACAI Entry for the IWSLT 2016 Shared Task"
        },
        {
            "paperId": "80e25cdd2d948b3b60d9b58454a102fa1ff74343",
            "title": "The RWTH Aachen LVCSR system for IWSLT-2016 German Skype conversation recognition task"
        },
        {
            "paperId": "11909da1ff3bd7b4529375f12d3388797c2e368f",
            "title": "FBK\u2019s Neural Machine Translation Systems for IWSLT 2016"
        },
        {
            "paperId": "fabd8a19a2fe18ecf56ec4a8177f831f2e67cfd0",
            "title": "Adaptation and Combination of NMT Systems: The KIT Translation Systems for IWSLT 2016"
        },
        {
            "paperId": "cbdb9b7fe8bb5e8b01fc93316df10f4c61e4879e",
            "title": "UFAL Submissions to the IWSLT 2016 MT Track"
        },
        {
            "paperId": "b81a0061529d5273c75445a73ed19a53720ba917",
            "title": "The RWTH Aachen Machine Translation System for IWSLT 2016"
        },
        {
            "paperId": "db914f9276f97987fbec13784bd7071c34b30be4",
            "title": "The 2016 KIT IWSLT Speech-to-Text Systems for English and German"
        },
        {
            "paperId": "a211753030db4a1737016655be02cd38a6723a33",
            "title": "The IOIT English ASR system for IWSLT 2016"
        },
        {
            "paperId": null,
            "title": "International Workshop on Spoken Language Translation (IWSLT) , Seattle, WA"
        },
        {
            "paperId": "b54268e3b8d148c0695ca52bebb0f80e26a4b987",
            "title": "The IWSLT 2015 Evaluation Campaign"
        },
        {
            "paperId": "2826f9dccdcceb113b33ccf2841d488f1419bb30",
            "title": "Stanford Neural Machine Translation Systems for Spoken Language Domains"
        },
        {
            "paperId": "46a1931b4f9a885fffda35bbeacd26622b256534",
            "title": "The AMARA Corpus: Building Parallel Language Resources for the Educational Domain"
        },
        {
            "paperId": "81aace0e90c6a962059b117c24db0d856f340f41",
            "title": "Report on the 11th IWSLT evaluation campaign"
        },
        {
            "paperId": "5b18bf9693f4b45194dc2ec5c3ec22c7b11eb763",
            "title": "Complexity of spoken versus written language for machine translation"
        },
        {
            "paperId": "64f0bd4f725063b376d347455407b36e68ca9d08",
            "title": "QCRI at IWSLT 2013: experiments in Arabic-English and English-Arabic spoken language translation"
        },
        {
            "paperId": "569e2ecbe48a854f5a80b58c4d018c1a2cd5a648",
            "title": "Report on the 10th IWSLT evaluation campaign"
        },
        {
            "paperId": "09cd7876b72d6105c83db59052572433a0a2b36c",
            "title": "WIT3: Web Inventory of Transcribed and Translated Talks"
        },
        {
            "paperId": "f7ef63734af6843e99ee7ce6972a077baf37ecfa",
            "title": "Measuring User Productivity in Machine Translation Enhanced Computer Assisted Translation"
        },
        {
            "paperId": null,
            "title": "\u201cRecent efforts in spoken language processing,\u201d"
        },
        {
            "paperId": "75f8a4d7ed6a0f32fa098cac967de247938d9ce5",
            "title": "An Introduction to the Bootstrap"
        },
        {
            "paperId": "3d07b5087e53c6f7c228b3c7e769494527be228e",
            "title": "A Study of Translation Edit Rate with Targeted Human Annotation"
        },
        {
            "paperId": "694b3c58712deefb59502847ba1b52b192c413e5",
            "title": "Europarl: A Parallel Corpus for Statistical Machine Translation"
        },
        {
            "paperId": "606d91bcd2bca5f6cd23a455bda53c79e6b8e39b",
            "title": "Evaluating Machine Translation Output with Automatic Sentence Segmentation"
        },
        {
            "paperId": "a5899f1ec92af7d01f35225161430116a6eabbea",
            "title": "A STUDY OF TRANSLATION ERROR RATE WITH TARGETED HUMAN ANNOTATION"
        },
        {
            "paperId": "c56ddd7f0fe11fc5f6543d82cf817db4331d7670",
            "title": "Overview of the IWSLT evaluation campaign"
        },
        {
            "paperId": "79794914adfbe844151b01bd0216c275cc33de4f",
            "title": "Toward a Broad-coverage Bilingual Corpus for Speech Translation of Travel Conversations in the Real World"
        }
    ]
}