{
    "paperId": "4d74c808f5720eb9eb312f7be85be03bd7207071",
    "externalIds": {
        "DBLP": "journals/nn/Yarotsky17",
        "MAG": "2528305538",
        "ArXiv": "1610.01145",
        "DOI": "10.1016/j.neunet.2017.07.002",
        "CorpusId": 426133,
        "PubMed": "28756334"
    },
    "title": "Error bounds for approximations with deep ReLU networks",
    "abstract": null,
    "venue": "Neural Networks",
    "year": 2016,
    "referenceCount": 35,
    "citationCount": 1089,
    "influentialCitationCount": 174,
    "openAccessPdf": {
        "url": "https://arxiv.org/pdf/1610.01145",
        "status": "GREEN"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is proved that deep ReLU networks more efficiently approximate smooth functions than shallow networks and adaptive depth-6 network architectures more efficient than the standard shallow architecture are described."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "3217253",
            "name": "D. Yarotsky"
        }
    ],
    "references": [
        {
            "paperId": "87524c2bb725f967b7fac73442d6412b43d422d1",
            "title": "Why Deep Neural Networks for Function Approximation?"
        },
        {
            "paperId": "47d540eaa09d5f060b620146a319b5556805e08e",
            "title": "Why Deep Neural Networks?"
        },
        {
            "paperId": "9e52ade2f71f358a5aa3852d9b410c6cc2cf01cc",
            "title": "Deep vs. shallow networks : An approximation theory perspective"
        },
        {
            "paperId": "03e04983f7ce6a9c2b42948840b3312aea33f9f3",
            "title": "On the Expressive Power of Deep Neural Networks"
        },
        {
            "paperId": "fee8ac08e412269d15e75a4b00cc3bf0b25e8e7f",
            "title": "Learning Real and Boolean Functions: When Is Deep Better Than Shallow"
        },
        {
            "paperId": "4206c84525a7904df3613b843491c0ae6a5507eb",
            "title": "Benefits of Depth in Neural Networks"
        },
        {
            "paperId": "f8e99110b48c353aabdb11cf0fd399e1e2a09980",
            "title": "Representation Benefits of Deep Feedforward Networks"
        },
        {
            "paperId": "325e51cdb065666f3c9e21e70a823bbe33fefae7",
            "title": "On the Expressive Power of Deep Learning: A Tensor Analysis"
        },
        {
            "paperId": "193edd20cae92c6759c18ce93eeea96afd9528eb",
            "title": "Deep learning in neural networks: An overview"
        },
        {
            "paperId": "b034b5769ab94acf9fb8ae48c7edb560a300bb63",
            "title": "On the Number of Linear Regions of Deep Neural Networks"
        },
        {
            "paperId": "085d57b7f44e97ba6fa54543170b884a7461fc08",
            "title": "On the Complexity of Neural Network Classifiers: A Comparison Between Shallow and Deep Architectures"
        },
        {
            "paperId": "4b4d7ff8192c3862379f6ee58ad1fa0ec3de3937",
            "title": "Shallow vs. Deep Sum-Product Networks"
        },
        {
            "paperId": "6d24e178f433964ed9f44618bd62c43cfadaa480",
            "title": "The Solovay-Kitaev algorithm"
        },
        {
            "paperId": "9b46c16d13126a43822ecc6047569c1d8d0ada4c",
            "title": "Classical and Quantum Computation"
        },
        {
            "paperId": "32759c5bc68bb00717f922104b59fe88c597aa86",
            "title": "On the near optimality of the stochastic approximation of smooth functions by neural networks"
        },
        {
            "paperId": "dacdcd3e8020b4121b13c98d43f11f9a3d8c377b",
            "title": "Poly-Locality in Quantum Computing"
        },
        {
            "paperId": "da07bb3688f5ec5b42ee19fb06270a68be6ac46a",
            "title": "Neural Network Learning: Theoretical Foundations"
        },
        {
            "paperId": "bac00cc57c6daffeeac4e648d493911e8e233f68",
            "title": "Approximation by neural networks is not continuous"
        },
        {
            "paperId": "6e37979d2a910e8a2337927731619fd789a5213b",
            "title": "Approximation theory of the MLP model in neural networks"
        },
        {
            "paperId": "33b84d2c6f9d53d2a63ed427a569f3208a64d647",
            "title": "Tight Bounds for the VC-Dimension of Piecewise Polynomial Networks"
        },
        {
            "paperId": "fe5e6b810957da9bc10b099b00fd64c221d97961",
            "title": "Almost Linear VC-Dimension Bounds for Piecewise Polynomial Networks"
        },
        {
            "paperId": "94d43b9ba85a57523c9b553dd5ca645aa5716d03",
            "title": "Bounding the Vapnik-Chervonenkis Dimension of Concept Classes Parameterized by Real Numbers"
        },
        {
            "paperId": "9134c6e67cca05c93bf8a865b1960049c1064025",
            "title": "Approximation properties of a multilayered feedforward artificial neural network"
        },
        {
            "paperId": "d474299d7a51b89a1d7394d426cf881a89b8013d",
            "title": "Efficient distribution-free learning of probabilistic concepts"
        },
        {
            "paperId": "7b3a41df5bc4c1cc0f07d0554130ec160cd936f4",
            "title": "Optimal nonlinear approximation"
        },
        {
            "paperId": "867f3b81a22b4887490ae26d58d51788aa5bd503",
            "title": "Error bounds for approximations with deep ReLU networks"
        },
        {
            "paperId": "4f2e84f1c5ea7a0d5d8ebfa12a78a869f13d7b59",
            "title": "Deep learning for neural networks"
        },
        {
            "paperId": "2913c2bf3f92b5ae369400a42b2d27cc5bc05ecb",
            "title": "Deep Learning"
        },
        {
            "paperId": "0e168de5975a9dfbe12837ef19a0366d938bc1d7",
            "title": "Neural Networks for Optimal Approximation of Smooth and Analytic Functions"
        },
        {
            "paperId": "50e392ce073ffbcfe8f36af471894c93d8b8b6a4",
            "title": "Distribution-free Learning of Probabilistic Concepts"
        },
        {
            "paperId": "a36b028d024bf358c4af1a5e1dc3ca0aed23b553",
            "title": "Chervonenkis: On the uniform convergence of relative frequencies of events to their probabilities"
        },
        {
            "paperId": "06c126b1238dc11cc1e36a3b876dab4044637fa1",
            "title": "Lower bounds for approximation by nonlinear manifolds"
        },
        {
            "paperId": "4c748a41adc3ea4362054c945ffa4f6b56b131dc",
            "title": "The synthesis of two-terminal switching circuits"
        },
        {
            "paperId": null,
            "title": "b) Let p \u2265 0 , c 1 > 0 be some constants. For any (cid:15) \u2208 (0 , 12 ) , if a ReLU network architecture of depth L \u2264 c 1 ln p (1 /(cid:15) ) is capable of approximating any function f \u2208 F d,"
        },
        {
            "paperId": null,
            "title": "(cid:101) c"
        }
    ]
}