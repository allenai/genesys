{
    "paperId": "b624504240fa52ab76167acfe3156150ca01cf3b",
    "externalIds": {
        "ArXiv": "1506.07503",
        "MAG": "2953022181",
        "DBLP": "journals/corr/ChorowskiBSCB15",
        "CorpusId": 1921173
    },
    "title": "Attention-Based Models for Speech Recognition",
    "abstract": "Recurrent sequence generators conditioned on input data through an attention mechanism have recently shown very good performance on a range of tasks including machine translation, handwriting synthesis [1,2] and image caption generation [3]. We extend the attention-mechanism with features needed for speech recognition. We show that while an adaptation of the model used for machine translation in [2] reaches a competitive 18.7% phoneme error rate (PER) on the TIMET phoneme recognition task, it can only be applied to utterances which are roughly as long as the ones it was trained on. We offer a qualitative explanation of this failure and propose a novel and generic method of adding location-awareness to the attention mechanism to alleviate this issue. The new method yields a model that is robust to long inputs and achieves 18% PER in single utterances and 20% in 10-times longer (repeated) utterances. Finally, we propose a change to the attention mechanism that prevents it from concentrating too much on single frames, which further reduces PER to 17.6% level.",
    "venue": "Neural Information Processing Systems",
    "year": 2015,
    "referenceCount": 34,
    "citationCount": 2487,
    "influentialCitationCount": 130,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The attention-mechanism is extended with features needed for speech recognition and a novel and generic method of adding location-awareness to the attention mechanism is proposed to alleviate the issue of high phoneme error rate."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "2292403",
            "name": "J. Chorowski"
        },
        {
            "authorId": "3335364",
            "name": "Dzmitry Bahdanau"
        },
        {
            "authorId": "1862138",
            "name": "Dmitriy Serdyuk"
        },
        {
            "authorId": "1979489",
            "name": "Kyunghyun Cho"
        },
        {
            "authorId": "1751762",
            "name": "Yoshua Bengio"
        }
    ],
    "references": [
        {
            "paperId": "59b81ff81da55efc724c84ddc9d3ffd8e57a8d0e",
            "title": "Blocks and Fuel: Frameworks for deep learning"
        },
        {
            "paperId": "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e",
            "title": "End-To-End Memory Networks"
        },
        {
            "paperId": "a583af2696030bcf5f556edc74573fbee902be0b",
            "title": "Weakly Supervised Memory Networks"
        },
        {
            "paperId": "5fcd41ca42659ff792fc8ee7d535156e8e69f987",
            "title": "On Using Monolingual Corpora in Neural Machine Translation"
        },
        {
            "paperId": "4d8f2d14af5991d4f0d050d22216825cac3157bd",
            "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"
        },
        {
            "paperId": "24741d280869ad9c60321f5ab6e5f01b7852507d",
            "title": "Deep Speech: Scaling up end-to-end speech recognition"
        },
        {
            "paperId": "47d2dc34e1d02a8109f5c04bb6939725de23716d",
            "title": "End-to-end Continuous Speech Recognition using Attention-based Recurrent NN: First Results"
        },
        {
            "paperId": "c1126fbffd6b8547a44c58b192b36b08b18299de",
            "title": "Neural Turing Machines"
        },
        {
            "paperId": "71ae756c75ac89e2d731c9c79649562b5768ff39",
            "title": "Memory Networks"
        },
        {
            "paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "title": "Sequence to Sequence Learning with Neural Networks"
        },
        {
            "paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "title": "Neural Machine Translation by Jointly Learning to Align and Translate"
        },
        {
            "paperId": "8a756d4d25511d92a45d0f4545fa819de993851d",
            "title": "Recurrent Models of Visual Attention"
        },
        {
            "paperId": "0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f",
            "title": "Towards End-To-End Speech Recognition with Recurrent Neural Networks"
        },
        {
            "paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e",
            "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"
        },
        {
            "paperId": "8dc1d5c47b8af57cbff36632318b4302706df6a3",
            "title": "Combining time- and frequency-domain convolution in convolutional neural network-based phone recognition"
        },
        {
            "paperId": "2f7ad26514bce4df6c8ebc42c90383ef3a974df4",
            "title": "Pylearn2: a machine learning research library"
        },
        {
            "paperId": "6471fd1cbc081fb3b7b5b14d6ab9eaaba02b5c17",
            "title": "Generating Sequences With Recurrent Neural Networks"
        },
        {
            "paperId": "4177ec52d1b80ed57f2e72b0f9a42365f1a8598d",
            "title": "Speech recognition with deep recurrent neural networks"
        },
        {
            "paperId": "8729441d734782c3ed532a7d2d9611b438c0a09a",
            "title": "ADADELTA: An Adaptive Learning Rate Method"
        },
        {
            "paperId": "855d0f722d75cc56a66a00ede18ace96bafee6bd",
            "title": "Theano: new features and speed improvements"
        },
        {
            "paperId": "7b4f3d0e4e2486a8d5d3f8e00549cf9a117bf88f",
            "title": "Sequence Transduction with Recurrent Neural Networks"
        },
        {
            "paperId": "0060745e006c5f14ec326904119dca19c6545e51",
            "title": "Improving neural networks by preventing co-adaptation of feature detectors"
        },
        {
            "paperId": "5a9ef216bf11f222438fff130c778267d39a9564",
            "title": "Practical Variational Inference for Neural Networks"
        },
        {
            "paperId": "bc6dff14a130c57a91d5a21339c23471faf1d46f",
            "title": "Et al"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "47128bb3ce4ed00691c0d7d58c02791c3e963ab7",
            "title": "Darpa Timit Acoustic-Phonetic Continuous Speech Corpus CD-ROM {TIMIT} | NIST"
        },
        {
            "paperId": "b3db94f62118e192ef0465ca9edafcd6c074c137",
            "title": "DARPA TIMIT:: acoustic-phonetic continuous speech corpus CD-ROM, NIST speech disc 1-1.1"
        },
        {
            "paperId": "31868290adf1c000c611dfc966b514d5a34e8d23",
            "title": "FUNDAMENTAL TECHNOLOGIES IN MODERN SPEECH RECOGNITION Digital Object Identifier 10.1109/MSP.2012.2205597"
        },
        {
            "paperId": "3a1a2cff2b70fb84a7ca7d97f8adcc5855851795",
            "title": "The Kaldi Speech Recognition Toolkit"
        },
        {
            "paperId": "63936fa32f9e75ab2a864daae6791ce02112183d",
            "title": "Theano: A CPU and GPU Math Compiler in Python"
        },
        {
            "paperId": "9eab007a8c0af72f1fdffe2aef210d790fb79d79",
            "title": "The Application of Hidden Markov Models in Speech Recognition"
        },
        {
            "paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "title": "Gradient-based learning applied to document recognition"
        },
        {
            "paperId": "261a056f8b21918e8616a429b2df6e1d5d33be41",
            "title": "Connectionist Temporal Classi\ufb01cation: Labelling Unsegmented Sequence Data with Recurrent Neural Networks"
        },
        {
            "paperId": "845ee9838c1f5bf63b7db2c95ec5d27af14a4e02",
            "title": "Connectionist Temporal Classi\ufb01cation: Labelling Unsegmented Sequences with Recurrent Neural Networks"
        }
    ]
}