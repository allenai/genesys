{
    "paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
    "externalIds": {
        "DBLP": "conf/cvpr/HeZRS16",
        "MAG": "2949650786",
        "ArXiv": "1512.03385",
        "DOI": "10.1109/cvpr.2016.90",
        "CorpusId": 206594692
    },
    "title": "Deep Residual Learning for Image Recognition",
    "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
    "venue": "Computer Vision and Pattern Recognition",
    "year": 2015,
    "referenceCount": 53,
    "citationCount": 171151,
    "influentialCitationCount": 28144,
    "openAccessPdf": {
        "url": "https://repositorio.unal.edu.co/bitstream/unal/81443/1/98670607.2022.pdf",
        "status": "GREEN"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "39353098",
            "name": "Kaiming He"
        },
        {
            "authorId": "1771551",
            "name": "X. Zhang"
        },
        {
            "authorId": "3080683",
            "name": "Shaoqing Ren"
        },
        {
            "authorId": null,
            "name": "Jian Sun"
        }
    ],
    "references": [
        {
            "paperId": "b92aa7024b87f50737b372e5df31ef091ab54e62",
            "title": "Training Very Deep Networks"
        },
        {
            "paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
            "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"
        },
        {
            "paperId": "020928259a848b91b7c36062e4bbc6df6398c02e",
            "title": "Object Detection via a Multi-region and Semantic Segmentation-Aware CNN Model"
        },
        {
            "paperId": "e0945081b5b87187a53d4329cf77cd8bff635795",
            "title": "Highway Networks"
        },
        {
            "paperId": "7ffdbc358b63378f07311e883dddacc9faeeaf4b",
            "title": "Fast R-CNN"
        },
        {
            "paperId": "f075f89b4f4026748cbf2fb9f989a9934c42ee8f",
            "title": "Object Detection Networks on Convolutional Feature Maps"
        },
        {
            "paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e",
            "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
        },
        {
            "paperId": "d6f2f611da110b5b5061731be3fc4c7f45d8ee23",
            "title": "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification"
        },
        {
            "paperId": "8604f376633af8b347e31d84c6150a93b11e34c2",
            "title": "FitNets: Hints for Thin Deep Nets"
        },
        {
            "paperId": "8ad35df17ae4064dd174690efb04d347428f1117",
            "title": "Convolutional neural networks at constrained time cost"
        },
        {
            "paperId": "6fc6803df5f9ae505cae5b2f178ade4062c768d0",
            "title": "Fully convolutional networks for semantic segmentation"
        },
        {
            "paperId": "fb91db6aa4f710814f8aec28a7f3ecbc4e5ad4fd",
            "title": "Deeply-Supervised Nets"
        },
        {
            "paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327",
            "title": "Going deeper with convolutions"
        },
        {
            "paperId": "eb42cf88027de515750f230b23b1a057dc782108",
            "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
        },
        {
            "paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd",
            "title": "ImageNet Large Scale Visual Recognition Challenge"
        },
        {
            "paperId": "6bdb186ec4726e00a8051119636d4df3b94043b5",
            "title": "Caffe: Convolutional Architecture for Fast Feature Embedding"
        },
        {
            "paperId": "cbb19236820a96038d000dc629225d36e0b6294a",
            "title": "Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition"
        },
        {
            "paperId": "71b7178df5d2b112d07e45038cb5637208659ff7",
            "title": "Microsoft COCO: Common Objects in Context"
        },
        {
            "paperId": "b034b5769ab94acf9fb8ae48c7edb560a300bb63",
            "title": "On the Number of Linear Regions of Deep Neural Networks"
        },
        {
            "paperId": "1109b663453e78a59e4f66446d71720ac58cec25",
            "title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks"
        },
        {
            "paperId": "99c970348b8f70ce23d6641e201904ea49266b6e",
            "title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks"
        },
        {
            "paperId": "5e83ab70d0cbc003471e87ec306d27d9c80ecb16",
            "title": "Network In Network"
        },
        {
            "paperId": "fc26b9c1afe81e1b20195123fe6f3ced9520abb6",
            "title": "Visualizing and Understanding Convolutional Neural Networks"
        },
        {
            "paperId": "2f4df08d9072fc2ac181b7fced6a245315ce05c8",
            "title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation"
        },
        {
            "paperId": "b7b915d508987b73b61eccd2b237e7ed099a2d29",
            "title": "Maxout Networks"
        },
        {
            "paperId": "f72c079d9179cfaada1135a7e4c77d48b6309a30",
            "title": "Pushing Stochastic Gradient towards Second-Order Methods -- Backpropagation Learning with Transformations in Nonlinearities"
        },
        {
            "paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "title": "ImageNet classification with deep convolutional neural networks"
        },
        {
            "paperId": "5183230b706b72f6f6c19415c423d93c79ddde53",
            "title": "Aggregating Local Image Descriptors into Compact Codes"
        },
        {
            "paperId": "0060745e006c5f14ec326904119dca19c6545e51",
            "title": "Improving neural networks by preventing co-adaptation of feature detectors"
        },
        {
            "paperId": "b8ef1230a5cc9ea7cd8358f1ae7d1af97813ba14",
            "title": "Deep Learning Made Easier by Linear Transformations in Perceptrons"
        },
        {
            "paperId": "d720a95e1501922ea17ee31f299f43b2db5e15ef",
            "title": "Vlfeat: an open and portable library of computer vision algorithms"
        },
        {
            "paperId": "a538b05ebb01a40323997629e171c91aa28b8e2f",
            "title": "Rectified Linear Units Improve Restricted Boltzmann Machines"
        },
        {
            "paperId": "3a9b175324ba11bc0e16c0633912d897b2fac4e2",
            "title": "The Pascal Visual Object Classes (VOC) Challenge"
        },
        {
            "paperId": "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649",
            "title": "Understanding the difficulty of training deep feedforward neural networks"
        },
        {
            "paperId": "bc6dff14a130c57a91d5a21339c23471faf1d46f",
            "title": "Et al"
        },
        {
            "paperId": "23694b6d61668e62bb11f17c1d75dde3b4951948",
            "title": "Fisher Kernels on Visual Vocabularies for Image Categorization"
        },
        {
            "paperId": "4f04da90218f8ddfa3a758188edade8c7bd95ac1",
            "title": "Locally adapted hierarchical basis preconditioning"
        },
        {
            "paperId": "1bd875676fe49f83d431500cea908da1bdf068da",
            "title": "A multigrid tutorial, Second Edition"
        },
        {
            "paperId": "5763bd6b3f24a01c3bc7cd15d3c916b4840b759d",
            "title": "Accelerated Gradient Descent by Factor-Centering Decomposition"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "1f711685bfe9e67d6afe0d5a3cb6675c310237d6",
            "title": "Modern Applied Statistics with S-Plus."
        },
        {
            "paperId": "d0be39ee052d246ae99c082a565aba25b811be2d",
            "title": "Learning long-term dependencies with gradient descent is difficult"
        },
        {
            "paperId": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27",
            "title": "Backpropagation Applied to Handwritten Zip Code Recognition"
        },
        {
            "paperId": "1efc5a54a4b3f4675bee194ee5842978e45a5bc2",
            "title": "Fast surface interpolation using hierarchical basis functions"
        },
        {
            "paperId": "b87274e6d9aa4e6ba5148898aa92941617d2b6ed",
            "title": "Efficient BackProp"
        },
        {
            "paperId": "4748d22348e72e6e06c2476486afddbc76e5eca7",
            "title": "Product Quantization for Nearest Neighbor Search"
        },
        {
            "paperId": "7b7908f71188b89adf62ce9126a0466e1a34338f",
            "title": "The devil is in the details: an evaluation of recent feature encoding methods"
        },
        {
            "paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086",
            "title": "Learning Multiple Layers of Features from Tiny Images"
        },
        {
            "paperId": "75a026ddfdd9c219d69fe8af816f085ea1b3877d",
            "title": "Centering Neural Network Gradient Factors"
        },
        {
            "paperId": "bf7e1b6997433dcb2121b07cce1de1c61471ff2d",
            "title": "Pattern Recognition and Neural Networks"
        },
        {
            "paperId": "83b6755242f1cff6bacf270f65b4626d4d118f32",
            "title": "Neural Networks for Pattern Recognition"
        },
        {
            "paperId": "3f3d13e95c25a8f6a753e38dfce88885097cbd43",
            "title": "Untersuchungen zu dynamischen neuronalen Netzen"
        },
        {
            "paperId": "8a2384ff41dc2c337e6aaacbcfd13f74e0e2f1ea",
            "title": "A multigrid tutorial"
        }
    ]
}