{
    "paperId": "a24f8830089b74df7a6aa3eb09c884817a0629e0",
    "externalIds": {
        "MAG": "2951956533",
        "DBLP": "journals/ml/GrunwaldL07",
        "ArXiv": "math/0406221",
        "DOI": "10.1007/s10994-007-0716-7",
        "CorpusId": 10379509
    },
    "title": "Suboptimal behavior of Bayes and MDL in classification under misspecification",
    "abstract": null,
    "venue": "Machine-mediated learning",
    "year": 2004,
    "referenceCount": 43,
    "citationCount": 81,
    "influentialCitationCount": 6,
    "openAccessPdf": {
        "url": "https://link.springer.com/content/pdf/10.1007/s10994-007-0716-7.pdf",
        "status": "HYBRID"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is shown that forms of Bayesian and MDL inference that are often applied to classification problems can be inconsistent, which means that there exists a learning problem such that for all amounts of data the generalization errors of the MDL classifier and the Bayes classifier relative to the Bayesian posterior both remain bounded away from the smallest achievable generalization error."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "144729640",
            "name": "P. Gr\u00fcnwald"
        },
        {
            "authorId": "144162125",
            "name": "J. Langford"
        }
    ],
    "references": [
        {
            "paperId": "8acf6797593352a4c9ce718665c1868cc2a67c96",
            "title": "The Minimum Description Length Principle (Adaptive Computation and Machine Learning)"
        },
        {
            "paperId": "a18f95f80df905e2b3c9f1d28cbfdc2f2fc2562e",
            "title": "Misspecification in infinite-dimensional Bayesian statistics"
        },
        {
            "paperId": "7dbdb4209626fd92d2436a058663206216036e68",
            "title": "Elements of Information Theory"
        },
        {
            "paperId": "3c56e086eb04ebc4a26c760df7d1fa842c931ccc",
            "title": "Statistical and Inductive Inference by Minimum Message Length (Information Science and Statistics)"
        },
        {
            "paperId": "1a73cf28eb97f7eb1f0bb6a7a3e68015103e1faa",
            "title": "Fast Non-Parametric Bayesian Inference on Infinite Trees"
        },
        {
            "paperId": "a158aa1f314e905da3cf80219c0e4c20fed0441f",
            "title": "Comparing Bayes Model Averaging and Stacking When Model Approximation Error Cannot be Ignored"
        },
        {
            "paperId": "634dca8af08a82d871680aaf19ef9ad6fab69b2e",
            "title": "Finding Cutpoints in Noisy Binary Sequences - A Revised Empirical Evaluation"
        },
        {
            "paperId": "609be06b5a91ffb8c35abd1636cd2431ff32435d",
            "title": "PAC-Bayesian model averaging"
        },
        {
            "paperId": "09d75a405711e32c0581d23d732cde61d10cfe34",
            "title": "The minimum description length principle and reasoning under uncertainty"
        },
        {
            "paperId": "65d34977d9055f42e51dc1e7d9b4ca2f36c17537",
            "title": "The Minimum Description Length Principle in Coding and Modeling"
        },
        {
            "paperId": "0d0bbb8ce1243ac52e0c98cc0f43deff6373b22d",
            "title": "A Decision-Theoretic Extension of Stochastic Complexity and Its Applications to Learning"
        },
        {
            "paperId": "eb5d54b084b0a34040087d1631cb86e4db9b5ca6",
            "title": "Asymptotic behavior of Bayes estimates under possibly incorrect models"
        },
        {
            "paperId": "46054429406bcb6e2a80216f0092f80016a8c579",
            "title": "An Experimental and Theoretical Comparison of Model Selection Methods"
        },
        {
            "paperId": "5575b4e9b3e7eb79f5b35db078dcb39740d9a624",
            "title": "On the Stochastic Complexity of Learning Realizable and Unrealizable Rules"
        },
        {
            "paperId": "afab27c25c2cccb95832c59f1d30956cb7fdb3c0",
            "title": "Coding Decision Trees"
        },
        {
            "paperId": "fca98082fa9ff8e9dbae9922491ae54976a0ccef",
            "title": "Minimum complexity density estimation"
        },
        {
            "paperId": "72247e4e34de0dd2d0428522ded24b49fb1632be",
            "title": "Stochastic Complexity in Statistical Inquiry"
        },
        {
            "paperId": "84dae6a2870c68005732b9db6890f375490f2d4e",
            "title": "Inferring Decision Trees Using the Minimum Description Length Principle"
        },
        {
            "paperId": "71448a9b8d35d5f3123405d3d7a66288618daab2",
            "title": "Occam's Razor"
        },
        {
            "paperId": "5c63ab340634a23b84a233f1a7725c4b5ddffe9c",
            "title": "On the consistency of Bayes estimates"
        },
        {
            "paperId": "ae7beb7920485aca9c252ce3ecc3972c52eb3c37",
            "title": "A UNIVERSAL PRIOR FOR INTEGERS AND ESTIMATION BY MINIMUM DESCRIPTION LENGTH"
        },
        {
            "paperId": "0b4d43ef0051a225e07af8194e81007ebba8d787",
            "title": "Occam's razor"
        },
        {
            "paperId": "a1d76ee9b6fb4d441e31abcd4dadc4e44c576017",
            "title": "An Information Measure for Classification"
        },
        {
            "paperId": "8043220ae5ef8dabcee283c8409085bc276009f3",
            "title": "Merging of Opinions with Increasing Information"
        },
        {
            "paperId": "aee6ac03ab1bc0821f820b622a2e34f3054c74c1",
            "title": "BAYESIAN THEORY"
        },
        {
            "paperId": "ec582dac8bc0eeb713fc50eb907fb9c0bfd42d62",
            "title": "Invited review of the book Statistical and Inductive Inference by Minimum Message Length"
        },
        {
            "paperId": "498b9eb71695c94fbf0b19447ddf7a43cf9c9634",
            "title": "Minimum message length and generalized Bayesian nets with asymmetric languages"
        },
        {
            "paperId": null,
            "title": "Minimum Description Length: recent developments in theory and practice, chapter 1"
        },
        {
            "paperId": "d68725804eadecf83d707d89e12c5132bf376187",
            "title": "Sparse Bayesian Learning and the Relevance Vector Machine"
        },
        {
            "paperId": "30afca3a4056bc54deadc1c5794048436d1c9eb4",
            "title": "Dependency Networks for Inference, Collaborative Filtering, and Data Visualization"
        },
        {
            "paperId": "b7caf811d6980627caad1a8b3053f40348693508",
            "title": "Probabilities for SV Machines"
        },
        {
            "paperId": "6d368700395e894adf241c2ed6bc4e7f2719a96b",
            "title": "Refinements of MDL and MML Coding"
        },
        {
            "paperId": "8044fb7ae6c271dca38201cbe603b7921c821334",
            "title": "Minimum Message Length and Kolmogorov Complexity"
        },
        {
            "paperId": "82f84ef88da9b82c485e4f900b1d097a90b277fc",
            "title": "Estimation of mixture models"
        },
        {
            "paperId": "10b5d888d5632f72f5ab6c4ba47adaa2a0e2d0a7",
            "title": "Invited discussion of A. R. Barron: Information-theoretic characterization of Bayes performance and the choice of priors in parametric and nonparametric problems"
        },
        {
            "paperId": "bed107422083bcf98a7bc509929ce5b71e6e5023",
            "title": "Why the logistic function? A tutorial discussion on probabilities and neural networks"
        },
        {
            "paperId": "8b7d60f49e7a5368920457c885c813a912c34997",
            "title": "Complexity Regularization with Application to Artificial Neural Networks"
        },
        {
            "paperId": null,
            "title": "Application of the theory of martingales"
        },
        {
            "paperId": null,
            "title": "MDL Tutorial"
        },
        {
            "paperId": "5c6f9529bc85afe7a3a35d8720ab5213233b8d70",
            "title": "Advances in Minimum Description"
        },
        {
            "paperId": null,
            "title": "Let c \u2208 C be an arbitrary classifier and let P (\u03b8|c) be given by the uniform prior with P (\u03b8 | c) \u2261 1"
        },
        {
            "paperId": null,
            "title": "Appendix: Proposition 2 and its Proof Proposition 2. Consider any given sample S of arbitrary size m"
        },
        {
            "paperId": null,
            "title": "The set of distributions P is \u2018simple\u2019"
        }
    ]
}