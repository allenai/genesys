{
    "paperId": "8a765725a44b91b60d414551dc555175cfff3cd9",
    "externalIds": {
        "ArXiv": "1609.05191",
        "DBLP": "journals/corr/HardtMR16",
        "MAG": "2950701806",
        "CorpusId": 7597719
    },
    "title": "Gradient Descent Learns Linear Dynamical Systems",
    "abstract": "We prove that gradient descent efficiently converges to the global optimizer of the maximum likelihood objective of an unknown linear time-invariant dynamical system from a sequence of noisy observations generated by the system. Even though the objective function is non-convex, we provide polynomial running time and sample complexity bounds under strong but natural assumptions. Linear systems identification has been studied for many decades, yet, to the best of our knowledge, these are the first polynomial guarantees for the problem we consider.",
    "venue": "Journal of machine learning research",
    "year": 2016,
    "referenceCount": 33,
    "citationCount": 214,
    "influentialCitationCount": 17,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is proved that gradient descent efficiently converges to the global optimizer of the maximum likelihood objective of an unknown linear time-invariant dynamical system from a sequence of noisy observations generated by the system."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "1775622",
            "name": "Moritz Hardt"
        },
        {
            "authorId": "1901958",
            "name": "Tengyu Ma"
        },
        {
            "authorId": "9229182",
            "name": "B. Recht"
        }
    ],
    "references": [
        {
            "paperId": "9b8be6c3ebd7a79975067214e5eaea05d4ac2384",
            "title": "Gradient Descent Converges to Minimizers"
        },
        {
            "paperId": "76690f5e2d33da6b7bd4cdec5affe5aa9ed83ff9",
            "title": "Beyond Convexity: Stochastic Quasi-Convex Optimization"
        },
        {
            "paperId": "a70c24f8e97aea58d6fe913372abab1daeaf1264",
            "title": "Escaping From Saddle Points - Online Stochastic Gradient for Tensor Decomposition"
        },
        {
            "paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "title": "Sequence to Sequence Learning with Neural Networks"
        },
        {
            "paperId": "244539f454800697ed663326b7cfba337ca0c2ec",
            "title": "Guided Policy Search"
        },
        {
            "paperId": "84069287da0a6b488b8c933f3cb5be759cb6237e",
            "title": "On the difficulty of training recurrent neural networks"
        },
        {
            "paperId": "38e696b0fa508ee6e3dda713f136caa7b1febb7d",
            "title": "Atomic Norm Denoising With Applications to Line Spectral Estimation"
        },
        {
            "paperId": "82b6605d74f93481a4e1ebe094fc12ab49be0c55",
            "title": "Linear system identification via atomic norm regularization"
        },
        {
            "paperId": "3e03d70155ff7b341d8f2d8e70e4c62de6352aed",
            "title": "Relationships between positive real, passive dissipative, & positive systems"
        },
        {
            "paperId": "1d6ae9a60950112017a3d8e7db0ca5e411767fc9",
            "title": "Linear Systems Theory"
        },
        {
            "paperId": "fd2dfe0e3bfe28659c1f93dc228ed161145b8fb9",
            "title": "Convex optimization in robust identification of nonlinear feedback"
        },
        {
            "paperId": "0b2c1fbd6596f4f6275de7a46f2e14982dded30a",
            "title": "Iterative minimization of H2 control performance criteria"
        },
        {
            "paperId": "7be6e3fee96ab9181cd7375119ee8588496b3bc1",
            "title": "A learning theory approach to system identification and stochastic adaptive control"
        },
        {
            "paperId": "50645f4ec320ae1af42983a673dbc117404e663d",
            "title": "Introduction to Mathematical Systems Theory: Linear Systems, Identification and Control"
        },
        {
            "paperId": "30f67b7275cec21a94be945dfe4beff08c7e004a",
            "title": "Simultaneous localization and mapping: part I"
        },
        {
            "paperId": "5b1678a7f286ec4a8bcbdea531ba48af1e0c29e7",
            "title": "Learning appearance manifolds from video"
        },
        {
            "paperId": "50bd45acdf0d9a19eec2a9f03c429083a77cf772",
            "title": "Rank minimization and applications in system theory"
        },
        {
            "paperId": "6503fcffc6692b99f467815d2a3471116115f5bd",
            "title": "A rank minimization heuristic with application to minimum order system approximation"
        },
        {
            "paperId": "8383e3cbda3e579d4cbf9a3c1b2b06f5f0b21ac8",
            "title": "Finite sample properties of system identification methods"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "d61540a96c22a1ed4a2b78558a2ebdd39f221a90",
            "title": "Probability in Banach Spaces: Isoperimetry and Processes"
        },
        {
            "paperId": "b69df07c579407372db14aa2b9925fe5d4555a23",
            "title": "Uniqueness of prediction error estimates of multivariable moving average models"
        },
        {
            "paperId": "fece9362f374b640f691bef6a3cbaf9814d8d228",
            "title": "Inequalities of A. Markoff and S. Bernstein for polynomials and related functions"
        },
        {
            "paperId": "608f05fd20a6337754b607e4deae9ffd3de0ed9f",
            "title": "On Line Learning In Neural Networks"
        },
        {
            "paperId": "c03d1fca5457910ab9ccecd5eb9f575b12571ff4",
            "title": "System Identi cation"
        },
        {
            "paperId": "30be801a9a5319e0546a80f96cf71285cc31d16e",
            "title": "On the Global Convergence of Identification of Output Error Models"
        },
        {
            "paperId": null,
            "title": "+ \u03c4 i ).The first inequality is trivial. We prove the second one. Consider a such that a \u2208 B \u03b1,\u03ba 0 ,\u03ba 1 ,\u03ba 2 . We wil show that a \u2208 B \u03b1,\u03c4 0 ,\u03c4 1 ,\u03c4 2"
        },
        {
            "paperId": "5ddb52169d654ac5bb53674b15511a1b95ba71ca",
            "title": "Complex Numbers and Functions"
        },
        {
            "paperId": "0903a7a6663b23073f6f2092ab6ecce024cf15a9",
            "title": "On-Line Learning in Neural Networks"
        },
        {
            "paperId": null,
            "title": "System Identification: Theory for the User"
        },
        {
            "paperId": "3eaa0bed1c4606ab23464c374d78620651b871d7",
            "title": "Some properties of the output error method"
        },
        {
            "paperId": "c73b1fae91142cb05436505acca72e548f7056e9",
            "title": "A classification of linear controllable systems"
        },
        {
            "paperId": null,
            "title": "2\u03c0ik/M for some integer k such that |q a (z) \u2212 q a (w)| \u2264 O(\u03c4 2 n/(\u03b1M )). Therefore let M = cn for sufficiently large c (which depends on \u03c4 i 's), we have that for every z with |z| = 1/\u03b1"
        }
    ]
}