{
    "paperId": "8d4f727b181e14632b7dd15435e4f756e2926ad9",
    "externalIds": {
        "MAG": "2755888403",
        "ArXiv": "1709.05289",
        "DBLP": "journals/nn/PetersenV18",
        "DOI": "10.1016/j.neunet.2018.08.019",
        "CorpusId": 32835461,
        "PubMed": "30245431"
    },
    "title": "Optimal approximation of piecewise smooth functions using deep ReLU neural networks",
    "abstract": null,
    "venue": "Neural Networks",
    "year": 2017,
    "referenceCount": 63,
    "citationCount": 434,
    "influentialCitationCount": 57,
    "openAccessPdf": {
        "url": "https://arxiv.org/pdf/1709.05289",
        "status": "GREEN"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is proved that one cannot approximate a general function f\u2208E\u03b2(Rd) using neural networks that are less complex than those produced by the construction, which partly explains the benefits of depth for ReLU networks by showing that deep networks are necessary to achieve efficient approximation of (piecewise) smooth functions."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "31421135",
            "name": "P. Petersen"
        },
        {
            "authorId": "2064876683",
            "name": "Felix Voigtl\u00e4nder"
        }
    ],
    "references": [
        {
            "paperId": "83af8edebf7e4550dd1f53e3bac55ba51d19bd5b",
            "title": "Memory-optimal neural network approximation"
        },
        {
            "paperId": "6d1840e4d6a43ce46d80fba5327eb5c20b4c2e34",
            "title": "Neural Networks and Rational Functions"
        },
        {
            "paperId": "23effc082f2582b39e277dfc99bbce198cf36451",
            "title": "Optimal Approximation with Sparsely Connected Deep Neural Networks"
        },
        {
            "paperId": "df43aab40523d0beb2e717efc5c5a88652a88564",
            "title": "Analysis vs. synthesis sparsity for $\\alpha$-shearlets"
        },
        {
            "paperId": "fdbe123a6535720274db2518af49abe9e9daac87",
            "title": "Why and when can deep-but not shallow-networks avoid the curse of dimensionality: A review"
        },
        {
            "paperId": "23a4083ff361a73a781dcad0d6e239ae75540396",
            "title": "Depth-Width Tradeoffs in Approximating Natural Functions with Neural Networks"
        },
        {
            "paperId": "4d74c808f5720eb9eb312f7be85be03bd7207071",
            "title": "Error bounds for approximations with deep ReLU networks"
        },
        {
            "paperId": "f7059e8db0a4b312713bd3d8aede0551d43f9710",
            "title": "Learning Functions: When Is Deep Better Than Shallow"
        },
        {
            "paperId": "4206c84525a7904df3613b843491c0ae6a5507eb",
            "title": "Benefits of Depth in Neural Networks"
        },
        {
            "paperId": "846aedd869a00c09b40f1f1f35673cb22bc87490",
            "title": "Mastering the game of Go with deep neural networks and tree search"
        },
        {
            "paperId": "b0a02fecff9300f09fff77122290a9f570a43673",
            "title": "A Mathematical Theory of Deep Convolutional Neural Networks for Feature Extraction"
        },
        {
            "paperId": "f8e99110b48c353aabdb11cf0fd399e1e2a09980",
            "title": "Representation Benefits of Deep Feedforward Networks"
        },
        {
            "paperId": "b034b5769ab94acf9fb8ae48c7edb560a300bb63",
            "title": "On the Number of Linear Regions of Deep Neural Networks"
        },
        {
            "paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "title": "ImageNet classification with deep convolutional neural networks"
        },
        {
            "paperId": "4b4d7ff8192c3862379f6ee58ad1fa0ec3de3937",
            "title": "Shallow vs. Deep Sum-Product Networks"
        },
        {
            "paperId": "c38c8680e694e36babdb9496637d0e9d6dbfe59c",
            "title": "Full length article: Compactly supported shearlets are optimally sparse"
        },
        {
            "paperId": "53aea2e87e124eaa587ef20dae55094d868fd57e",
            "title": "Group Invariant Scattering"
        },
        {
            "paperId": "433bfa2fb7185200ad928d0b6dc4afa17f459813",
            "title": "Compactly supported shearlets are optimally sparse"
        },
        {
            "paperId": "58f9ab28afe2ecc5bea8dbc70fd9be812462539f",
            "title": "Representation and Compression of Multidimensional Piecewise Functions Using Surflets"
        },
        {
            "paperId": "0a813d13300e25c25aac93fa99f9b1822e6048cb",
            "title": "Optimally Sparse Multidimensional Representation Using Shearlets"
        },
        {
            "paperId": "67b1cc159aacf2f30239577e6cf7a741b64f31e0",
            "title": "Sparse geometric image representations with bandelets"
        },
        {
            "paperId": "7a2fe24293995a046fe2433801234c7c228da4e1",
            "title": "Compressing Piecewise Smooth Multidimensional Functions Using Surflets: Rate-Distortion Analysis"
        },
        {
            "paperId": "832f6a52920db02135d751c46c026a78ad16128c",
            "title": "New tight frames of curvelets and optimal representations of objects with piecewise C2 singularities"
        },
        {
            "paperId": "9788780417087b7766689d9d84864b7fb6290b81",
            "title": "Introduction to Smooth Manifolds"
        },
        {
            "paperId": "67ad9b3f3d91b101909297d79b912532446485c0",
            "title": "Neural networks for classification: a survey"
        },
        {
            "paperId": "da07bb3688f5ec5b42ee19fb06270a68be6ac46a",
            "title": "Neural Network Learning: Theoretical Foundations"
        },
        {
            "paperId": "4bdd1f845d26e488d67c0e4549cff17407b980ad",
            "title": "Lower bounds for approximation by MLP neural networks"
        },
        {
            "paperId": "6e37979d2a910e8a2337927731619fd789a5213b",
            "title": "Approximation theory of the MLP model in neural networks"
        },
        {
            "paperId": "25aa271bdf4506b979e0095afc53e2cedca84366",
            "title": "Geometry of Sets and Measures in Euclidean Spaces: Fractals and Rectifiability"
        },
        {
            "paperId": "60ad4a043430cf503a2fbafbac8df377de62a39c",
            "title": "Unconditional Bases Are Optimal Bases for Data Compression and for Statistical Estimation"
        },
        {
            "paperId": "990504fc9e5a1f3619ace4fa7f5bf667069018b1",
            "title": "Original Contribution: Multilayer feedforward networks with a nonpolynomial activation function can approximate any function"
        },
        {
            "paperId": "04113e8974341f97258800126d05fd8df2751b7e",
            "title": "Universal approximation bounds for superpositions of a sigmoidal function"
        },
        {
            "paperId": "02c76c01bef98edbd8a2f2041454035f77837ace",
            "title": "Handwritten digit recognition by neural networks with single-layer training"
        },
        {
            "paperId": "a9209f90c02a378720879a3bb93aa2f7181cf5f2",
            "title": "Approximation and Estimation Bounds for Artificial Neural Networks"
        },
        {
            "paperId": "70927dc841596f3e3dba07b472ccc565b944ddf0",
            "title": "Recognizing Hand-Printed Letters and Digits Using Backpropagation Learning"
        },
        {
            "paperId": "0cf5a3bb338ab51d70153eab0e0539ba6dbab1c7",
            "title": "Applications of Neural Networks to Character Recognition"
        },
        {
            "paperId": "698dc5bce03ff7f9d733651f516ad8232b3c139f",
            "title": "Use of an Artificial Neural Network for Data Analysis in Clinical Decision-Making: The Diagnosis of Acute Coronary Occlusion"
        },
        {
            "paperId": "8da1dda34ecc96263102181448c94ec7d645d085",
            "title": "Approximation by superpositions of a sigmoidal function"
        },
        {
            "paperId": "f22f6972e66bdd2e769fa64b0df0a13063c0c101",
            "title": "Multilayer feedforward networks are universal approximators"
        },
        {
            "paperId": "319f22bd5abfd67ac15988aa5c7f705f018c3ccd",
            "title": "Learning internal representations by error propagation"
        },
        {
            "paperId": "f8d37fc9764f952e9f3fa5c7293c0f39b0c7821a",
            "title": "Real Analysis: Modern Techniques and Their Applications"
        },
        {
            "paperId": "c444bd7102b4dd32fa32ce6f1b8ff206fdd221ae",
            "title": "Real and Functional Analysis"
        },
        {
            "paperId": "db6771a5f12946037d817fad8b1a432c89764e5e",
            "title": "Entropies of several sets of real valued functions"
        },
        {
            "paperId": "9b486c647916df9f8be0f8d4fc5c94c493bfaa80",
            "title": "PRINCIPLES OF NEURODYNAMICS. PERCEPTRONS AND THE THEORY OF BRAIN MECHANISMS"
        },
        {
            "paperId": "01b5f4f367bee272337a9b781c3883256f6cf128",
            "title": "On the extension of a vector function so as to preserve a Lipschitz condition"
        },
        {
            "paperId": "c7c21d98d1f01e192ef1c8165386fb6e61e68827",
            "title": "Depth-Width Tradeoffs in Approximating Natural Functions with Neural Networks"
        },
        {
            "paperId": "2913c2bf3f92b5ae369400a42b2d27cc5bc05ecb",
            "title": "Deep Learning"
        },
        {
            "paperId": "9f7cf8c49579d52a90508d031198fa36364b30d1",
            "title": "Optimally Sparse Data Representations"
        },
        {
            "paperId": "38f72c963350ca9ae397f245dc0196386f7f75e7",
            "title": "Sobolev Spaces"
        },
        {
            "paperId": "8cb82eb90cc4f2307d7a95e46f9f3c80d66802a2",
            "title": "Introduction to Shearlets"
        },
        {
            "paperId": "31868290adf1c000c611dfc966b514d5a34e8d23",
            "title": "FUNDAMENTAL TECHNOLOGIES IN MODERN SPEECH RECOGNITION Digital Object Identifier 10.1109/MSP.2012.2205597"
        },
        {
            "paperId": "23068cc1a7996fa5bd810d4768f83a46935326f7",
            "title": "Functional Analysis"
        },
        {
            "paperId": "722c52711a8014694d68839f0ffc52ba8f7fc621",
            "title": "Approximation and estimation bounds for artificial neural networks"
        },
        {
            "paperId": "ba06decaa784655589ebe8109b3697cd7302abef",
            "title": "Sparse Components of Images and Optimal Atomic Decompositions"
        },
        {
            "paperId": "0843c2f5cbd7dda30cbeed73d95b77d068408476",
            "title": "Curvelets: A Surprisingly Effective Nonadaptive Representation for Objects with Edges"
        },
        {
            "paperId": "0e168de5975a9dfbe12837ef19a0366d938bc1d7",
            "title": "Neural Networks for Optimal Approximation of Smooth and Analytic Functions"
        },
        {
            "paperId": "b48e57f017aea179f5d6e76dd0277dc718bfd500",
            "title": "Artificial neural networks for cancer research: outcome prediction."
        },
        {
            "paperId": "3da3a6ad646426582758459a4bcd0955a22daaae",
            "title": "Measure theory and fine properties of functions"
        },
        {
            "paperId": "090c5a5df345ab60c41d6de02b3e366e1a27cf43",
            "title": "A logical calculus of the ideas immanent in nervous activity"
        },
        {
            "paperId": "86ab4cae682fbd49c5a5bedb630e5a40fa7529f6",
            "title": "Handwritten Digit Recognition with a Back-Propagation Network"
        },
        {
            "paperId": "88263b99ae7d88ae8719ad463e171058686349f0",
            "title": "Principles of mathematical analysis"
        },
        {
            "paperId": "2e50a837da4883efa0cdfa7b261e2db5835e0d4d",
            "title": "\u00dcber die zusammenziehende und Lipschitzsche Transformationen"
        },
        {
            "paperId": null,
            "title": "The assumption is reasonable if one wants to understand the behavior of networks that are used in practice"
        }
    ]
}