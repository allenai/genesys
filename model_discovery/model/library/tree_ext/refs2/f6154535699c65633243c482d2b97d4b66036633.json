{
    "paperId": "f6154535699c65633243c482d2b97d4b66036633",
    "externalIds": {
        "MAG": "2951225978",
        "DBLP": "journals/corr/ThickstunHK16",
        "ArXiv": "1611.09827",
        "CorpusId": 11445252
    },
    "title": "Learning Features of Music from Scratch",
    "abstract": "This paper introduces a new large-scale music dataset, MusicNet, to serve as a source of supervision and evaluation of machine learning methods for music research. MusicNet consists of hundreds of freely-licensed classical music recordings by 10 composers, written for 11 instruments, together with instrument/note annotations resulting in over 1 million temporal labels on 34 hours of chamber music performances under various studio and microphone conditions. \nThe paper defines a multi-label classification task to predict notes in musical recordings, along with an evaluation protocol, and benchmarks several machine learning architectures for this task: i) learning from spectrogram features; ii) end-to-end learning with a neural net; iii) end-to-end learning with a convolutional neural net. These experiments show that end-to-end models trained for note prediction learn frequency selective filters as a low-level representation of audio.",
    "venue": "International Conference on Learning Representations",
    "year": 2016,
    "referenceCount": 39,
    "citationCount": 183,
    "influentialCitationCount": 26,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A multi-label classification task to predict notes in musical recordings is defined, along with an evaluation protocol, and several machine learning architectures for this task are benchmarked."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "50343904",
            "name": "John Thickstun"
        },
        {
            "authorId": "1753355",
            "name": "Za\u00efd Harchaoui"
        },
        {
            "authorId": "144695232",
            "name": "S. Kakade"
        }
    ],
    "references": [
        {
            "paperId": "a066233a0b52a0e07197540ff2c73f42daf198f4",
            "title": "DeepBach: a Steerable Model for Bach Chorales Generation"
        },
        {
            "paperId": "873ac1a11a990f7ba47567997f314b27f2221753",
            "title": "On the Potential of Simple Framewise Approaches to Piano Transcription"
        },
        {
            "paperId": "2e5ceabac22b1559de8d32623a0eb347869f88ba",
            "title": "Feature Learning for Chord Recognition: The Deep Chroma Extractor"
        },
        {
            "paperId": "df0402517a7338ae28bc54acaac400de6b456a46",
            "title": "WaveNet: A Generative Model for Raw Audio"
        },
        {
            "paperId": "b9ba8c4a00f5ee43e768db2acc8b56f017176f3e",
            "title": "Automatic Tagging Using Deep Convolutional Neural Networks"
        },
        {
            "paperId": "629380a24c3fc7c26e96415f5cf8d6496b2d1c38",
            "title": "Directly modeling voiced and unvoiced components in speech waveforms by neural networks"
        },
        {
            "paperId": "62ac6cff952bb1e3b6e653b877fa254fdcd5ab55",
            "title": "A weakly-supervised discriminative model for audio-to-score alignment"
        },
        {
            "paperId": "d72e52acccfa531b54bfc6cb244e9e96e574f4fc",
            "title": "Unsupervised Transcription of Piano Music"
        },
        {
            "paperId": "2f168528dd77998bb3648efccb194f99a7ec5d79",
            "title": "Metric Learning for Temporal Sequence Alignment"
        },
        {
            "paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd",
            "title": "ImageNet Large Scale Visual Recognition Challenge"
        },
        {
            "paperId": "e93c7d71074c0d4890915263c7c34711d41b6940",
            "title": "End-to-end learning for music audio"
        },
        {
            "paperId": "eeff60867041d2ea92d1b38a20c2031d240d8872",
            "title": "Deep content-based music recommendation"
        },
        {
            "paperId": "8916b9fc3722c440f5a3ed04c3ea0f624aa71801",
            "title": "Learning Optimal Features for Polyphonic Audio-to-Score Alignment"
        },
        {
            "paperId": "96c1d283995fa03452835082d88b04e5eb87c1dc",
            "title": "Automatic music transcription: challenges and future directions"
        },
        {
            "paperId": "7a42dedd7050442a78940bae6a62899919693b17",
            "title": "Moving Beyond Feature Design: Deep Architectures and Automatic Feature Learning in Music Informatics"
        },
        {
            "paperId": "b3970c31b964b2e57d41e4cb920b09175c0c351c",
            "title": "Joint Multi-Pitch Detection Using Harmonic Envelope Estimation for Polyphonic Music Transcription"
        },
        {
            "paperId": "38b5018cb6d21b593dbd2efe1fc092c579fc4c63",
            "title": "Multiple Fundamental Frequency Estimation by Modeling Spectral Peaks and Non-Peak Regions"
        },
        {
            "paperId": "d06346fe3aae35b65117b5fd7611093d133b7f06",
            "title": "Learning Multi-modal Similarity"
        },
        {
            "paperId": "c9d26a0d690b354ff4e2853fb41a36a3fe81ae47",
            "title": "Multipitch Estimation of Piano Sounds Using a New Probabilistic Spectral Smoothness Principle"
        },
        {
            "paperId": "c1a83739c388adc9dfb1e2aa49310b49b97f1966",
            "title": "Introduction to Digital Speech Processing"
        },
        {
            "paperId": "a66f1e80f644b28fa5aee3b7405a9fa1ea3eee85",
            "title": "Ground-truth transcriptions of real music from force-aligned MIDI syntheses"
        },
        {
            "paperId": "78dae646303057aff3ddc85ed7ed17a069fe2b9f",
            "title": "RWC Music Database: Music genre database and musical instrument sound database"
        },
        {
            "paperId": "f0d7bedc709073a8d764e5e32a2af3f5d05f926e",
            "title": "Improving polyphonic and poly-instrumental music to score alignment"
        },
        {
            "paperId": "49ec5d806d3fa51068729976e88f3dec6addc19d",
            "title": "Polyphonic audio matching and alignment for music retrieval"
        },
        {
            "paperId": "b42417c8a4e783b55c41ee74619dc31e887e6630",
            "title": "Alignment of Monophonic and Polyphonic Music to a Score"
        },
        {
            "paperId": "29adf4df05695a27479082bf3ca2ccfdd53c2a9b",
            "title": "Automatic Segmentation of Acoustic Musical Signals Using Hidden Markov Models"
        },
        {
            "paperId": "bcd857d75841aa3e92cd4284a8818aba9f6c0c3f",
            "title": "Published as a conference paper at ICLR 2018 S IMULATING A CTION D YNAMICS WITH N EURAL P ROCESS N ETWORKS"
        },
        {
            "paperId": "e4351041d25c272a008bcd5765868dc3a28fe470",
            "title": "Under Review as a Conference Paper at Iclr 2017 Delving into Transferable Adversarial Ex- Amples and Black-box Attacks"
        },
        {
            "paperId": "211f8b2398e1343c5190638f121ef78127719a88",
            "title": "An Iterative Multi Range Non-Negative Matrix Factorization Algorithm for Polyphonic Music Transcription"
        },
        {
            "paperId": "b179b573b0675713bee1b0ce323accf07e6277fb",
            "title": "Large-Scale Content-Based Matching of MIDI and Audio Files"
        },
        {
            "paperId": "e5c114afc8c4d4e10ae068ba8e3387cc13e17a6e",
            "title": "librosa: Audio and Music Signal Analysis in Python"
        },
        {
            "paperId": "f3e4bc59566580fdbd00df21fdf1b7e4b152aa3e",
            "title": "Let it Bee - Towards NMF-Inspired Audio Mosaicing"
        },
        {
            "paperId": "6d37fbd2fccaef3ecdf75d34a7aee18ab9519a6f",
            "title": "MIR_EVAL: A Transparent Implementation of Common MIR Metrics"
        },
        {
            "paperId": "b66f76d2e6bfa950a83864f5e5510eae70aa0f1a",
            "title": "Million Song Dataset Challenge !"
        },
        {
            "paperId": "ebd90bf432c2c8021ad084fbe418af73ca72f4a2",
            "title": "Understanding Features and Distance Functions for Music Sequence Alignment"
        },
        {
            "paperId": "c87745fe5d0fe016d55a033049057d69943a2f47",
            "title": "Towards automatic extraction of harmony information from music signals"
        },
        {
            "paperId": null,
            "title": "High resolution audio synchronization using chroma features"
        },
        {
            "paperId": "598d394d156aab29eab94a9b38461e211f8ba0b3",
            "title": "A Discriminative Model for Polyphonic Piano Transcription"
        },
        {
            "paperId": null,
            "title": "TensorFlow: Large-scale machine learning on heterogeneous systems"
        }
    ]
}