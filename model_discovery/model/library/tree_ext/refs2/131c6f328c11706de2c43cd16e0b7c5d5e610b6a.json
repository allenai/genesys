{
    "paperId": "131c6f328c11706de2c43cd16e0b7c5d5e610b6a",
    "externalIds": {
        "DBLP": "journals/corr/abs-2304-13712",
        "ArXiv": "2304.13712",
        "DOI": "10.1145/3649506",
        "CorpusId": 258331833
    },
    "title": "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond",
    "abstract": "This article presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs) in their downstream Natural Language Processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from the perspectives of models, data, and downstream tasks. First, we offer an introduction and brief summary of current language models. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a detailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as knowledge-intensive tasks, traditional natural language understanding tasks, generation tasks, emergent abilities, and considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and limitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated with each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such as efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide aims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the successful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly updated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide. An LLMs evolutionary tree, editable yet regularly updated, can be found at llmtree.ai.",
    "venue": "ACM Transactions on Knowledge Discovery from Data",
    "year": 2023,
    "referenceCount": 171,
    "citationCount": 336,
    "influentialCitationCount": 11,
    "openAccessPdf": {
        "url": "https://dl.acm.org/doi/pdf/10.1145/3649506",
        "status": "HYBRID"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs) in their downstream Natural Language Processing (NLP) tasks, enabling the successful implementation of these models in a wide range of NLP tasks."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -5.59736967086792,
            -0.2849832773208618,
            -3.705878257751465,
            3.252554416656494,
            5.103273391723633,
            -2.922027587890625,
            3.4574475288391113,
            0.5462700724601746,
            -0.5955766439437866,
            2.2032625675201416,
            -1.376228928565979,
            0.3626244068145752,
            -0.9579401016235352,
            1.4493732452392578,
            -1.021985650062561,
            -0.026138097047805786,
            0.7873700857162476,
            -2.2108771800994873,
            4.593940258026123,
            0.3821311593055725,
            -2.573232889175415,
            4.185610771179199,
            -3.0809926986694336,
            -0.6813809275627136,
            1.3899898529052734,
            -1.3870960474014282,
            7.137810230255127,
            1.5693594217300415,
            -2.014188766479492,
            -0.8868448138237,
            -2.412628650665283,
            -5.619991302490234,
            1.5615794658660889,
            -5.521127700805664,
            1.326532006263733,
            -2.8336124420166016,
            -5.43934440612793,
            7.809367656707764,
            -2.0126304626464844,
            0.00682830810546875,
            0.11100006103515625,
            0.6382807493209839,
            0.04174375534057617,
            0.056748077273368835,
            3.231788158416748,
            1.9839367866516113,
            4.400103569030762,
            0.6242535710334778,
            -0.8724958896636963,
            1.5789434909820557,
            2.6199564933776855,
            -2.870678663253784,
            1.5964840650558472,
            2.700833320617676,
            2.550963878631592,
            -0.2629280388355255,
            2.615082025527954,
            1.9383916854858398,
            1.7117013931274414,
            -3.1277012825012207,
            5.57805871963501,
            4.086946487426758,
            -2.364820957183838,
            1.9551892280578613,
            4.293978691101074,
            -2.3344011306762695,
            -3.8792476654052734,
            2.2122573852539062,
            3.129136562347412,
            3.5342793464660645,
            -0.055445313453674316,
            -2.5431251525878906,
            1.1920764446258545,
            3.2643702030181885,
            -1.941126823425293,
            -0.9433448314666748,
            -0.12065085768699646,
            -5.438574314117432,
            -2.487152099609375,
            -3.2193164825439453,
            1.4265801906585693,
            0.05792585015296936,
            -0.2602907419204712,
            4.29509162902832,
            2.766915798187256,
            0.39160794019699097,
            -8.712179183959961,
            2.957872152328491,
            4.912308216094971,
            -4.265693187713623,
            -0.7974377274513245,
            0.899686336517334,
            -0.8595174551010132,
            3.213164806365967,
            -1.461437463760376,
            -2.1438052654266357,
            -0.6920574307441711,
            -2.2072503566741943,
            -1.0214717388153076,
            -1.195746660232544,
            3.8793909549713135,
            -1.0041799545288086,
            1.2829474210739136,
            2.0588583946228027,
            3.1166725158691406,
            -3.2183351516723633,
            -0.574202835559845,
            2.1342105865478516,
            -0.8279604911804199,
            -0.5031539797782898,
            -0.9512734413146973,
            3.0385119915008545,
            -0.3046358525753021,
            -3.321394920349121,
            0.6360002160072327,
            -2.912993907928467,
            -2.2868711948394775,
            0.9076551795005798,
            -2.6432909965515137,
            6.508310317993164,
            -2.7407379150390625,
            1.0525856018066406,
            -1.8045296669006348,
            -0.9855296015739441,
            1.5310640335083008,
            0.2738635540008545,
            -0.7078651785850525,
            -4.808309555053711,
            0.025668077170848846,
            -1.4803686141967773,
            4.2502970695495605,
            -0.5610548853874207,
            6.531397342681885,
            -1.690014362335205,
            2.021472930908203,
            2.9294886589050293,
            -1.6100006103515625,
            1.7514437437057495,
            1.2824461460113525,
            -2.178325891494751,
            -0.4487426280975342,
            6.514153003692627,
            -0.5063797235488892,
            -0.28342103958129883,
            0.7502901554107666,
            1.522825002670288,
            0.4042656123638153,
            -2.0556302070617676,
            -1.0758192539215088,
            4.86094856262207,
            3.979785919189453,
            -4.653681755065918,
            -2.6065573692321777,
            -1.127396583557129,
            0.2650693953037262,
            4.16441535949707,
            0.8098459243774414,
            0.25962144136428833,
            -1.9415028095245361,
            -0.4318729043006897,
            0.5060902833938599,
            1.525943398475647,
            -8.16642951965332,
            -2.2890024185180664,
            5.03035831451416,
            -4.367267608642578,
            -1.5904617309570312,
            4.037797451019287,
            1.6568747758865356,
            2.6856250762939453,
            -0.6690791249275208,
            2.1535093784332275,
            -0.5172849893569946,
            -1.107100486755371,
            -1.483499526977539,
            1.3951350450515747,
            -2.82243013381958,
            -2.824707508087158,
            -1.0111745595932007,
            -1.2138069868087769,
            -1.8180112838745117,
            -1.0650243759155273,
            -7.5870208740234375,
            1.8209501504898071,
            -2.243100643157959,
            -1.1648497581481934,
            -1.7787559032440186,
            -2.418745279312134,
            1.6268961429595947,
            -1.662903070449829,
            -2.810349464416504,
            -1.9971423149108887,
            5.990652084350586,
            5.134342193603516,
            5.296736717224121,
            4.368926048278809,
            2.341860294342041,
            4.097470283508301,
            -1.9024066925048828,
            3.4480080604553223,
            2.021852493286133,
            0.02605898678302765,
            -1.0850244760513306,
            0.8254536986351013,
            3.711054801940918,
            4.792016983032227,
            -6.389869213104248,
            5.891010284423828,
            0.14369577169418335,
            1.737229824066162,
            0.6702053546905518,
            4.133193016052246,
            -5.35367488861084,
            0.8622629046440125,
            1.6572935581207275,
            -1.9333629608154297,
            -5.389469146728516,
            0.2517146170139313,
            2.176600933074951,
            1.4907803535461426,
            -4.662778854370117,
            -0.7365508079528809,
            2.926638603210449,
            -3.6615843772888184,
            3.5287115573883057,
            -1.0474674701690674,
            0.9934589862823486,
            -3.758779525756836,
            -1.47671377658844,
            -3.8479912281036377,
            -3.7650747299194336,
            -3.189649820327759,
            -1.2843377590179443,
            -1.904552698135376,
            -4.510992050170898,
            0.4342985153198242,
            -5.184660911560059,
            2.3938393592834473,
            -0.3839460611343384,
            -1.8042184114456177,
            2.152531623840332,
            4.363202095031738,
            -2.265484094619751,
            5.41439962387085,
            4.910248279571533,
            3.3789210319519043,
            1.0228934288024902,
            1.3064624071121216,
            -3.247222423553467,
            -2.9544565677642822,
            0.6682610511779785,
            -3.9254722595214844,
            4.911606311798096,
            -0.6254060864448547,
            -0.8779421448707581,
            4.2660298347473145,
            -1.8667449951171875,
            -0.5972297191619873,
            2.4839768409729004,
            4.225058555603027,
            -0.41245824098587036,
            5.047062873840332,
            1.8416705131530762,
            3.5639212131500244,
            -0.8237255811691284,
            -0.7597256898880005,
            -2.3633055686950684,
            -0.1940351128578186,
            -3.409801959991455,
            5.597307205200195,
            4.184638977050781,
            1.1071330308914185,
            0.11041620373725891,
            -2.599903106689453,
            -2.7669079303741455,
            -6.42097282409668,
            1.2238099575042725,
            -4.968380451202393,
            3.5194456577301025,
            0.9008995294570923,
            0.6692135334014893,
            -4.428725242614746,
            -2.8378982543945312,
            -0.7569156885147095,
            3.210336685180664,
            0.5268323421478271,
            -1.4577758312225342,
            -1.0491726398468018,
            -3.5472452640533447,
            -4.110217094421387,
            -0.6654036045074463,
            4.14657735824585,
            -2.4228010177612305,
            -5.102533340454102,
            -0.9608851671218872,
            -2.9561657905578613,
            3.6566295623779297,
            -0.1928737461566925,
            -0.5082154273986816,
            -0.6560205817222595,
            -0.9308300018310547,
            1.4300813674926758,
            2.4336376190185547,
            -0.9540446996688843,
            1.8202314376831055,
            4.482682228088379,
            1.4825177192687988,
            1.0987156629562378,
            -3.2604308128356934,
            -5.762792587280273,
            0.43111586570739746,
            0.14885804057121277,
            2.8620219230651855,
            -3.6800293922424316,
            -0.2029033899307251,
            0.5627971887588501,
            2.643073558807373,
            1.8235406875610352,
            -7.636170864105225,
            2.073859691619873,
            -0.5600699186325073,
            -2.9199981689453125,
            -4.22853422164917,
            -2.3024184703826904,
            -3.345832347869873,
            2.385251998901367,
            0.20002490282058716,
            1.608404517173767,
            -2.9830896854400635,
            2.4987430572509766,
            2.6007957458496094,
            3.3848953247070312,
            0.44580745697021484,
            2.418447971343994,
            -3.7819197177886963,
            -2.850996494293213,
            -1.241851568222046,
            -3.67458438873291,
            0.8072128295898438,
            -2.4667205810546875,
            0.18249574303627014,
            4.697256565093994,
            0.6240429878234863,
            2.958918571472168,
            -2.880894660949707,
            1.8751517534255981,
            0.7939537167549133,
            -0.8556097745895386,
            -2.751335620880127,
            -3.446852922439575,
            1.0754501819610596,
            0.6744768023490906,
            5.068150520324707,
            2.081740617752075,
            4.199217319488525,
            2.0157809257507324,
            0.17687642574310303,
            1.2572863101959229,
            0.3655276298522949,
            0.4636828303337097,
            -2.5632851123809814,
            1.629028081893921,
            1.568123698234558,
            2.775434970855713,
            2.3320388793945312,
            -2.07425856590271,
            10.482505798339844,
            -3.8470940589904785,
            2.6774232387542725,
            -5.558657646179199,
            -2.5841517448425293,
            -5.738954067230225,
            -4.287986755371094,
            3.682539463043213,
            -4.539193153381348,
            -3.6228137016296387,
            -1.7469632625579834,
            -4.163547992706299,
            0.8012468814849854,
            1.5715422630310059,
            -2.1679463386535645,
            4.031127452850342,
            -3.1993508338928223,
            1.2902698516845703,
            1.2179465293884277,
            3.8012588024139404,
            -0.317929744720459,
            2.8737876415252686,
            0.46554750204086304,
            1.546026587486267,
            -0.6755181550979614,
            -2.5451912879943848,
            1.8711013793945312,
            2.9159862995147705,
            -3.876335859298706,
            -3.3529574871063232,
            0.2563304901123047,
            -2.2358694076538086,
            3.206547737121582,
            0.5381163358688354,
            -1.9487175941467285,
            -2.9351916313171387,
            2.3200623989105225,
            4.777867317199707,
            -4.285123825073242,
            6.357756614685059,
            0.4989510774612427,
            -0.7629927396774292,
            -1.5309337377548218,
            0.8119698762893677,
            -3.7398171424865723,
            0.8273162245750427,
            -3.030418872833252,
            -5.82191276550293,
            2.0363759994506836,
            1.3558318614959717,
            3.787625789642334,
            0.7042559385299683,
            1.4317634105682373,
            -2.0678393840789795,
            -5.3616838455200195,
            1.6485135555267334,
            6.095269203186035,
            4.088429927825928,
            -1.9549850225448608,
            0.6033229231834412,
            2.7261247634887695,
            1.993536353111267,
            -0.8657361268997192,
            3.5191664695739746,
            2.2690675258636475,
            1.2050950527191162,
            -2.300032138824463,
            -1.2548370361328125,
            -2.0855700969696045,
            0.09710392355918884,
            1.2299870252609253,
            0.27908748388290405,
            2.931565999984741,
            -4.819504261016846,
            1.5833945274353027,
            1.1191624402999878,
            -1.817117691040039,
            3.662278175354004,
            -0.9521439075469971,
            3.6039953231811523,
            0.27401697635650635,
            1.5009187459945679,
            -2.8466343879699707,
            0.6893628835678101,
            5.079037189483643,
            -2.4070653915405273,
            -1.9816161394119263,
            -2.386640787124634,
            1.3349601030349731,
            1.606979250907898,
            -1.6518077850341797,
            -2.060063600540161,
            -1.2450189590454102,
            1.2421085834503174,
            -1.5757488012313843,
            2.692291736602783,
            -0.13010793924331665,
            1.201786756515503,
            -0.5877503752708435,
            0.13202455639839172,
            -1.806757926940918,
            -4.915534019470215,
            -1.6410096883773804,
            4.934879302978516,
            2.5468392372131348,
            0.3377363383769989,
            -3.86842679977417,
            2.5583786964416504,
            -4.042934417724609,
            1.6071758270263672,
            2.6840627193450928,
            -1.933367371559143,
            3.1538095474243164,
            -4.758805751800537,
            -3.072187662124634,
            1.841697335243225,
            2.471928119659424,
            -4.825797080993652,
            0.008812189102172852,
            5.670538425445557,
            1.7980434894561768,
            0.16308799386024475,
            -0.1288478970527649,
            -2.797794818878174,
            0.809225857257843,
            5.603614807128906,
            3.651374340057373,
            0.040480852127075195,
            0.3555554151535034,
            -2.178525924682617,
            -5.066242218017578,
            1.7092151641845703,
            3.0291504859924316,
            2.0721986293792725,
            3.1960947513580322,
            -5.4662251472473145,
            1.038149118423462,
            -2.632443428039551,
            -1.6716915369033813,
            4.3755927085876465,
            6.172436714172363,
            -2.009119987487793,
            -1.3541138172149658,
            -1.3919434547424316,
            -2.391191005706787,
            1.3054413795471191,
            -4.988164901733398,
            3.4588193893432617,
            -0.4212779998779297,
            -0.9971209168434143,
            2.77856707572937,
            1.0644460916519165,
            -0.1548336148262024,
            -0.5902129411697388,
            2.5279154777526855,
            -1.6875983476638794,
            0.23585814237594604,
            3.2268497943878174,
            -0.37165647745132446,
            1.399129867553711,
            -0.06160879135131836,
            -3.8936543464660645,
            0.1354067325592041,
            5.866511344909668,
            6.950798988342285,
            5.20651912689209,
            2.7941770553588867,
            -1.7941385507583618,
            1.3425565958023071,
            -1.6243841648101807,
            1.8687145709991455,
            4.204984664916992,
            -2.6720504760742188,
            0.7162025570869446,
            0.7121040225028992,
            1.8086620569229126,
            2.7674155235290527,
            6.35451602935791,
            2.2978034019470215,
            3.499330759048462,
            -6.206732749938965,
            0.6310531497001648,
            -1.8092249631881714,
            -2.4317283630371094,
            -3.0972790718078613,
            -1.609468936920166,
            4.4382643699646,
            1.492821455001831,
            -2.1822757720947266,
            -1.5062745809555054,
            -0.7690935730934143,
            -1.9164706468582153,
            -2.6369717121124268,
            6.333475112915039,
            2.7524423599243164,
            -1.5416141748428345,
            -0.9097417593002319,
            0.854452908039093,
            -0.12051378190517426,
            -0.21552133560180664,
            -1.5940831899642944,
            3.2280359268188477,
            2.057243824005127,
            -0.8998032808303833,
            -0.2734498977661133,
            -4.1388750076293945,
            3.038600206375122,
            1.7822606563568115,
            0.9130560159683228,
            4.507968902587891,
            2.3453166484832764,
            -0.7947763800621033,
            -0.2512739300727844,
            -1.6494624614715576,
            0.6278506517410278,
            1.8039542436599731,
            -1.8980156183242798,
            -3.98586106300354,
            0.8262952566146851,
            -2.881131172180176,
            -3.8091373443603516,
            1.2603777647018433,
            -3.1606500148773193,
            1.9720958471298218,
            4.950533866882324,
            -1.9075427055358887,
            0.6193468570709229,
            -0.35827401280403137,
            3.852895736694336,
            -4.047825813293457,
            2.0626423358917236,
            1.9267826080322266,
            4.403857707977295,
            1.5394972562789917,
            -0.014712408185005188,
            4.690497398376465,
            0.053514689207077026,
            3.564840078353882,
            -2.241568088531494,
            -5.148699760437012,
            3.951617479324341,
            -1.4714250564575195,
            0.08929204940795898,
            0.5219356417655945,
            -3.879714250564575,
            2.2794501781463623,
            18.0645809173584,
            -0.5701608657836914,
            -3.66105580329895,
            2.454030990600586,
            -2.31619930267334,
            -0.8928632736206055,
            -4.997696876525879,
            3.514333724975586,
            0.950415849685669,
            -1.2829196453094482,
            0.01120680570602417,
            1.5629818439483643,
            -2.79744029045105,
            1.7015029191970825,
            -3.3364949226379395,
            1.1538333892822266,
            0.01186460256576538,
            3.8770852088928223,
            -2.2658348083496094,
            -1.8359966278076172,
            0.21948841214179993,
            0.9393832683563232,
            -3.0485262870788574,
            -3.8735764026641846,
            -1.3698973655700684,
            0.7510276436805725,
            1.1177849769592285,
            1.2430845499038696,
            -3.552525758743286,
            -1.723179817199707,
            -1.1606366634368896,
            1.3017464876174927,
            -0.7401459813117981,
            1.092871904373169,
            -2.2240748405456543,
            1.3495826721191406,
            0.4690336287021637,
            -5.139204502105713,
            1.9255683422088623,
            1.606276512145996,
            -1.4632768630981445,
            2.6705563068389893,
            -1.2195658683776855,
            2.9122443199157715,
            -0.8504681587219238,
            1.4293378591537476,
            1.974677562713623,
            -2.169644832611084,
            0.7763622403144836,
            2.659139633178711,
            -0.6752905249595642,
            -1.138874888420105,
            -0.7394933700561523,
            -1.3991260528564453,
            2.853044033050537,
            -2.821990489959717,
            1.9375004768371582,
            -5.930761814117432,
            -0.6607478857040405,
            -0.5262358784675598,
            1.8309273719787598,
            -1.0639941692352295,
            -0.07891368865966797,
            0.25955426692962646,
            -3.7790582180023193,
            -0.23693495988845825,
            -1.3143506050109863,
            2.4742512702941895,
            2.2154412269592285,
            0.4927964210510254,
            1.6911931037902832,
            4.5184478759765625,
            -1.2352962493896484,
            -3.4414145946502686,
            -0.7577770352363586,
            -3.010855197906494,
            4.138832092285156,
            -2.4237308502197266,
            -2.083750009536743,
            6.358209609985352,
            -2.0104031562805176,
            2.409543514251709,
            -1.0215632915496826,
            0.0413549542427063,
            4.8422651290893555,
            -1.537320613861084,
            3.2265303134918213,
            1.4264371395111084,
            -4.151561260223389,
            2.5350279808044434,
            -2.8317041397094727,
            0.8184854984283447,
            3.5238659381866455,
            7.306735038757324,
            -0.008382320404052734,
            -2.3039727210998535,
            -1.0345239639282227,
            -3.7014851570129395,
            -3.580402374267578,
            -1.544386625289917,
            3.5006978511810303,
            1.6657612323760986,
            2.3280482292175293,
            -3.4742038249969482,
            -3.0599260330200195,
            -2.9377450942993164,
            -1.9649417400360107,
            -4.444735527038574,
            -1.1706924438476562,
            -0.19516131281852722,
            1.7665282487869263,
            -1.3134254217147827,
            -0.377186119556427,
            3.402160167694092,
            2.127725601196289,
            -1.3101521730422974,
            1.0721547603607178,
            1.169847846031189,
            0.32900771498680115,
            4.737414360046387,
            0.883234977722168,
            -1.3891282081604004,
            -0.708524227142334,
            -3.775442600250244,
            -1.4431400299072266,
            -0.35046082735061646,
            -0.7696258425712585,
            -3.328869342803955,
            -4.284228801727295,
            -0.3216007947921753,
            3.73868989944458,
            -4.928285598754883,
            -2.466029644012451,
            -0.6901071071624756,
            0.20814567804336548,
            -0.3786941170692444,
            3.7230117321014404,
            0.29362455010414124,
            -2.1556053161621094,
            4.844930648803711,
            0.7016481757164001,
            -4.893437385559082,
            -1.5711555480957031,
            10.099631309509277,
            -0.6824566125869751,
            -0.3346715569496155,
            -2.331799030303955,
            0.6117078065872192,
            1.3731101751327515,
            0.17133429646492004,
            2.8409154415130615,
            0.22210735082626343,
            2.86395001411438,
            -0.03723782300949097,
            -3.9756133556365967,
            -1.834054708480835
        ]
    },
    "authors": [
        {
            "authorId": "7788583",
            "name": "Jingfeng Yang"
        },
        {
            "authorId": "1791983892",
            "name": "Hongye Jin"
        },
        {
            "authorId": "2057059798",
            "name": "Ruixiang Tang"
        },
        {
            "authorId": "50017230",
            "name": "Xiaotian Han"
        },
        {
            "authorId": "2151233715",
            "name": "Qizhang Feng"
        },
        {
            "authorId": "5795999",
            "name": "Haoming Jiang"
        },
        {
            "authorId": "2021632793",
            "name": "Bing Yin"
        },
        {
            "authorId": "2193021044",
            "name": "Xia Hu"
        }
    ],
    "references": [
        {
            "paperId": "a9468d8bfa6bd016dfd3128c4e8408e30eb8549b",
            "title": "LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning"
        },
        {
            "paperId": "c4d3b9a87295db0b9f6466b7f3ce2f175c6d3157",
            "title": "GrowLength: Accelerating LLMs Pretraining by Progressively Growing Training Length"
        },
        {
            "paperId": "f42f61a547c5996be6aee175145b0d74e6324dff",
            "title": "Navigate through Enigmatic Labyrinth A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future"
        },
        {
            "paperId": "aade40af0d85b0b4fe15c97f6222d5c2e4d6d9b3",
            "title": "Graph of Thoughts: Solving Elaborate Problems with Large Language Models"
        },
        {
            "paperId": "888728745dbb769e29ed475d4f7661eebe1a71cf",
            "title": "A Survey on Evaluation of Large Language Models"
        },
        {
            "paperId": "36f7bc27c9a37eb337c35df4ae86f148e13d4e9a",
            "title": "Understanding In-Context Learning via Supportive Pretraining Data"
        },
        {
            "paperId": "2922768fd451ecdb45f48c1a83eb57f54a91221b",
            "title": "Textbooks Are All You Need"
        },
        {
            "paperId": "8f936af93fb2b52b9678ff8f17c1ebe8de236a88",
            "title": "Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning"
        },
        {
            "paperId": "ce913026f693101e54d3ab9152e107034d81fce1",
            "title": "Holistic Evaluation of Language Models"
        },
        {
            "paperId": "2f3822eb380b5e753a6d579f31dfc3ec4c4a0820",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models"
        },
        {
            "paperId": "38179848e2d6a3ad373b1793848816111428ac36",
            "title": "OpenAGI: When LLM Meets Domain Experts"
        },
        {
            "paperId": "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d",
            "title": "A Survey of Large Language Models"
        },
        {
            "paperId": "83edcfbb206ddad38a971d605da09390604248ea",
            "title": "BloombergGPT: A Large Language Model for Finance"
        },
        {
            "paperId": "381ab7a640f5b46b62f7e08d1af4a8e0d3eadd55",
            "title": "G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment"
        },
        {
            "paperId": "a9e155fda1d97baa2b8712f580cc61887cc64e9b",
            "title": "ChatGPT outperforms crowd workers for text-annotation tasks"
        },
        {
            "paperId": "12c6be503e4e5b7c9cb1810152d4364f26628a8d",
            "title": "Data-centric Artificial Intelligence: A Survey"
        },
        {
            "paperId": "bdf7bf9e81a6c12e22323d0402885b2ba62f623e",
            "title": "Does Synthetic Data Generation of LLMs Help Clinical Text Mining?"
        },
        {
            "paperId": "8221f1597000543432b7021ca79dbc51a7a63f9c",
            "title": "Is ChatGPT a Good NLG Evaluator? A Preliminary Study"
        },
        {
            "paperId": "72f0acc688f3d7968c5783a39bc3469c6c6282fc",
            "title": "In AI, is bigger always better?"
        },
        {
            "paperId": "4161ad2d2495d8af1d62dc5e71882bde642cd1c1",
            "title": "Large Language Models Are State-of-the-Art Evaluators of Translation Quality"
        },
        {
            "paperId": "57e849d0de13ed5f91d086936296721d4ff75a75",
            "title": "LLaMA: Open and Efficient Foundation Language Models"
        },
        {
            "paperId": "5c7353fac22a8fdc43fc2f5c006b5d6902c47e75",
            "title": "On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective"
        },
        {
            "paperId": "6839816cd3ab194dfa3ffe3066cc35d099820e00",
            "title": "Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT"
        },
        {
            "paperId": "3599a236f285af48782fc30b1341d13ec7320735",
            "title": "A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT"
        },
        {
            "paperId": "40c318400809abf5e50aba5a5a80c8012a7715d5",
            "title": "GPTScore: Evaluate as You Desire"
        },
        {
            "paperId": "873a581320d928249609d3c07229d5af182a379c",
            "title": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver?"
        },
        {
            "paperId": "9f71d4bd511a4797c4f0c0122350d3381adc8a2e",
            "title": "The Science of Detecting LLM-Generated Text"
        },
        {
            "paperId": "a4a41319d5805a29316f24ed9519f09db77d4c29",
            "title": "Benchmarking Large Language Models for News Summarization"
        },
        {
            "paperId": "f2b0017ddd77fa38760a18145e63553105a1a236",
            "title": "The Flan Collection: Designing Data and Methods for Effective Instruction Tuning"
        },
        {
            "paperId": "d7d9fe989cd6abbb8c8170790bf54643ea48d421",
            "title": "A benchmark for toxic comment classification on Civil Comments dataset"
        },
        {
            "paperId": "780c99d13537370f63c03feeb1343bed9d98a4f9",
            "title": "Is ChatGPT A Good Translator? Yes With GPT-4 As The Engine"
        },
        {
            "paperId": "70b98d90767345b15e0569082c0e4ac661279b5d",
            "title": "Is GPT-3 a Good Data Annotator?"
        },
        {
            "paperId": "db4ab91d5675c37795e719e997a2827d3d83cd45",
            "title": "Towards Reasoning in Large Language Models: A Survey"
        },
        {
            "paperId": "3936fd3c6187f606c6e4e2e20b196dbc41cc4654",
            "title": "Constitutional AI: Harmlessness from AI Feedback"
        },
        {
            "paperId": "6d7b8a478801bd9d21df82d5f33ae6eced90da5e",
            "title": "Solving math word problems with process- and outcome-based feedback"
        },
        {
            "paperId": "471a49220cea2069e8b8a76821b1d2434204a732",
            "title": "FiE: Building a Global Probability Space by Leveraging Early Fusion in Encoder for Open-Domain Question Answering"
        },
        {
            "paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e",
            "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"
        },
        {
            "paperId": "99ca5162211a895a5dfbff9d7e36e21e09ca646e",
            "title": "Measuring Progress on Scalable Oversight for Large Language Models"
        },
        {
            "paperId": "4809452eb4ed547adaf44a004d47ee910265ba34",
            "title": "Inverse scaling can become U-shaped"
        },
        {
            "paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1",
            "title": "Scaling Instruction-Finetuned Language Models"
        },
        {
            "paperId": "1d26c947406173145a4665dd7ab255e03494ea28",
            "title": "GLM-130B: An Open Bilingual Pre-trained Model"
        },
        {
            "paperId": "83851f1a32d41975582ca62355858ab5e34738f7",
            "title": "News Summarization and Evaluation in the Era of GPT-3"
        },
        {
            "paperId": "28630034bb29760df01ab033b743e30b37f336ae",
            "title": "PaLI: A Jointly-Scaled Multilingual Language-Image Model"
        },
        {
            "paperId": "475c3014a68d545f1d2319f94fd3ab99fc3f6bec",
            "title": "Shortcut Learning of Large Language Models in Natural Language Understanding"
        },
        {
            "paperId": "02251886950770e82b3d68564d60cdfe15e73199",
            "title": "Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks"
        },
        {
            "paperId": "398e4061dde8f5c80606869cebfa2031de7b5b74",
            "title": "Few-shot Learning with Retrieval Augmented Language Models"
        },
        {
            "paperId": "914254fac74a2da051cccf6ca16afcaad416a079",
            "title": "AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model"
        },
        {
            "paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a",
            "title": "Emergent Abilities of Large Language Models"
        },
        {
            "paperId": "00df5cf0d83c48657d453ab8083d8805a67f744f",
            "title": "Measuring the Carbon Intensity of AI in Cloud Instances"
        },
        {
            "paperId": "bd1331b233e84bab7eba503abc60b31ac08e7881",
            "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models"
        },
        {
            "paperId": "1b0cf7a2e2178e244c7805dc1971de5ab0b8466a",
            "title": "DDXPlus: A New Dataset For Automatic Medical Diagnosis"
        },
        {
            "paperId": "716f9d0f6e96f437e127de90c87f7b2f7a6c8f12",
            "title": "SeqZero: Few-shot Compositional Semantic Parsing with Sequential Prompts and Zero-shot Models"
        },
        {
            "paperId": "43b7437ed33a29d3d90239ad66f325a465ff7e91",
            "title": "Meta Learning for Natural Language Processing: A Survey"
        },
        {
            "paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221",
            "title": "OPT: Open Pre-trained Transformer Language Models"
        },
        {
            "paperId": "15190e8b459bd85d546286f7d7da61b4f4f3f58a",
            "title": "What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?"
        },
        {
            "paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb",
            "title": "PaLM: Scaling Language Modeling with Pathways"
        },
        {
            "paperId": "038ece8c19e11cefa1cb205fb2f88cbce836df61",
            "title": "Adversarial attack and defense technologies in natural language processing: A survey"
        },
        {
            "paperId": "58c9838b45edad4b7fc11bd7119f113ea5a3d7f1",
            "title": "BRIO: Bringing Order to Abstractive Summarization"
        },
        {
            "paperId": "8342b592fe238f3d230e4959b06fd10153c45db1",
            "title": "Training Compute-Optimal Large Language Models"
        },
        {
            "paperId": "5ca0a54fa0f76ae0e1881899c61b36d35d3bd166",
            "title": "How does the pre-training objective affect what large language models learn about linguistic properties?"
        },
        {
            "paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
            "title": "Training language models to follow instructions with human feedback"
        },
        {
            "paperId": "2e43501a14b831744999355c177321709659aff1",
            "title": "TableFormer: Robust Transformer Modeling for Table-Text Encoding"
        },
        {
            "paperId": "1bc9865ebf52b59abac7f5ee4456ff2ac37fcff3",
            "title": "ST-MoE: Designing Stable and Transferable Sparse Expert Models"
        },
        {
            "paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5",
            "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"
        },
        {
            "paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19",
            "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"
        },
        {
            "paperId": "b3848d32f7294ec708627897833c4097eb4d8778",
            "title": "LaMDA: Language Models for Dialog Applications"
        },
        {
            "paperId": "3dfb1f50f2a34a699c339dabaa6f9b3a977973de",
            "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences"
        },
        {
            "paperId": "80d0116d77beeded0c23cf48946d9d10d4faee14",
            "title": "GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"
        },
        {
            "paperId": "68f141724814839d556a989646194be88641b143",
            "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
        },
        {
            "paperId": "e616c305f00b6a16d616b76ced86f88dcb4e4c1c",
            "title": "Multilingual Machine Translation Systems from Microsoft for WMT21 Shared Task"
        },
        {
            "paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea",
            "title": "Training Verifiers to Solve Math Word Problems"
        },
        {
            "paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca",
            "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"
        },
        {
            "paperId": "f3a332ff1b73acda482e5d83696b2c701f487819",
            "title": "P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"
        },
        {
            "paperId": "9289826beb6206eeaf500105f7329d6d5a495d8a",
            "title": "Robust fine-tuning of zero-shot models"
        },
        {
            "paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd",
            "title": "Finetuned Language Models Are Zero-Shot Learners"
        },
        {
            "paperId": "9ba50f992ccd92f428503ea6246157260a26cd77",
            "title": "Do Prompt-Based Models Really Understand the Meaning of Their Prompts?"
        },
        {
            "paperId": "76e9e2ec3de437ffb30d8b7b629f7fe3e61de5c2",
            "title": "On the Opportunities and Risks of Foundation Models"
        },
        {
            "paperId": "a38e0f993e4805ba8a9beae4c275c91ffcec01df",
            "title": "Program Synthesis with Large Language Models"
        },
        {
            "paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269",
            "title": "Evaluating Large Language Models Trained on Code"
        },
        {
            "paperId": "94b38a1cf2905a9f8dd90f5e22f904a07a59b6bc",
            "title": "XLM-E: Cross-lingual Language Model Pre-training via ELECTRA"
        },
        {
            "paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092",
            "title": "LoRA: Low-Rank Adaptation of Large Language Models"
        },
        {
            "paperId": "af679d69fcc1d0fcf0f039aba937853bcb50a8de",
            "title": "Luna: Linear Unified Nested Attention"
        },
        {
            "paperId": "476afc913d63f3ba1882f6419f718984379b2380",
            "title": "Why Machine Reading Comprehension Models Learn Shortcuts?"
        },
        {
            "paperId": "0adec918885dff698acf359988ed79a543157f80",
            "title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"
        },
        {
            "paperId": "bbfdcbfee1762d48cae9db8637f21ea3c234ba30",
            "title": "GPT3Mix: Leveraging Large-scale Language Models for Text Augmentation"
        },
        {
            "paperId": "13c4e5a6122f3fa2663f63e49537091da6532f35",
            "title": "Are NLP Models really able to Solve Simple Math Word Problems?"
        },
        {
            "paperId": "b249fe4e5e2bada6655ce5d61e7f50da5d471cb4",
            "title": "Domain Generalization: A Survey"
        },
        {
            "paperId": "56fa0b9cba4d9aee5ccc327365b3b3a721031c69",
            "title": "Calibrate Before Use: Improving Few-Shot Performance of Language Models"
        },
        {
            "paperId": "346081161bdc8f18e2a4c4af7f51d35452b5cb01",
            "title": "Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies"
        },
        {
            "paperId": "05ef3566499e24888a8c500944336616f8f418a4",
            "title": "Calibrated Fine-Tuning for Pre-trained Language Models via Manifold Smoothing"
        },
        {
            "paperId": null,
            "title": "Transformers: State-of-the-Art Natural Language Processing"
        },
        {
            "paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678",
            "title": "Measuring Massive Multitask Language Understanding"
        },
        {
            "paperId": "922ca07d02384c9b8e807912f3b64e48c36a2357",
            "title": "Mitigating Gender Bias in Captioning Systems"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93",
            "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"
        },
        {
            "paperId": "1b04936c2599e59b120f743fbb30df2eed3fd782",
            "title": "Shortcut learning in deep neural networks"
        },
        {
            "paperId": "f64e1d6bc13aae99aab5449fc9ae742a9ba7761e",
            "title": "UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training"
        },
        {
            "paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2",
            "title": "Scaling Laws for Neural Language Models"
        },
        {
            "paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb",
            "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"
        },
        {
            "paperId": "207da6d2c07289bf72a2b5974bb3f011ebb5dd0d",
            "title": "Adversarial NLI: A New Benchmark for Natural Language Understanding"
        },
        {
            "paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
            "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"
        },
        {
            "paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
        },
        {
            "paperId": "c95383f251a62c63217586059c67f63507c3e839",
            "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"
        },
        {
            "paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc",
            "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"
        },
        {
            "paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b",
            "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"
        },
        {
            "paperId": "093d9253a2fe765ca6577b091d3f99bab3155a7d",
            "title": "Benchmarking Zero-shot Text Classification: Datasets, Evaluation and Entailment Approach"
        },
        {
            "paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0",
            "title": "Natural Questions: A Benchmark for Question Answering Research"
        },
        {
            "paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de",
            "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"
        },
        {
            "paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
            "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"
        },
        {
            "paperId": "157a7ae44613a1fcf34e2be8c1e19a4f6e3c50e3",
            "title": "Transfer Learning in Natural Language Processing"
        },
        {
            "paperId": "d9f6ada77448664b71128bb19df15765336974a6",
            "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"
        },
        {
            "paperId": "b611a8095630557229dc5fb6b07c272f1cd614da",
            "title": "Nuanced Metrics for Measuring Unintended Bias with Real Data for Text Classification"
        },
        {
            "paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702",
            "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"
        },
        {
            "paperId": "ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc",
            "title": "Cross-lingual Language Model Pretraining"
        },
        {
            "paperId": "305b2cf37e5dece81e95c92883d5a6e28ac93b22",
            "title": "Don\u2019t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"
        },
        {
            "paperId": "990a7b4eceedb6e053e6386269481bdfc42a1094",
            "title": "CoQA: A Conversational Question Answering Challenge"
        },
        {
            "paperId": "39e734da43eb8c72e9549b42e96760545036f8e5",
            "title": "QuAC: Question Answering in Context"
        },
        {
            "paperId": "4d1c856275744c0284312a3a50efb6ca9dc4cd4c",
            "title": "Know What You Don\u2019t Know: Unanswerable Questions for SQuAD"
        },
        {
            "paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"
        },
        {
            "paperId": "88bb0a28bb58d847183ec505dda89b63771bb495",
            "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"
        },
        {
            "paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f",
            "title": "Deep Contextualized Word Representations"
        },
        {
            "paperId": "18858cc936947fc96b5c06bbe3c6c2faa5614540",
            "title": "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification"
        },
        {
            "paperId": "b123a0d46ad917b79c43c5ae981e03ed2458ed11",
            "title": "Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems"
        },
        {
            "paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c",
            "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"
        },
        {
            "paperId": "554c9b3aa8c3b7504810270b18b942a0d22156e7",
            "title": "DeepFix: Fixing Common C Language Errors by Deep Learning"
        },
        {
            "paperId": "2e55ba6c97ce5eb55abd959909403fe8da7e9fe9",
            "title": "Overcoming catastrophic forgetting in neural networks"
        },
        {
            "paperId": "dd95f96e3322dcaee9b1e3f7871ecc3ebcd51bfe",
            "title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset"
        },
        {
            "paperId": "1a327709cc53ff9e52454e50a643abf4a0ac92af",
            "title": "Findings of the 2016 Conference on Machine Translation"
        },
        {
            "paperId": "f37076f426023241f19cdc2fb0a0fd733a6fa7fa",
            "title": "Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond"
        },
        {
            "paperId": "f04df4e20a18358ea2f689b4c129781628ef7fc1",
            "title": "A large annotated corpus for learning natural language inference"
        },
        {
            "paperId": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
        },
        {
            "paperId": "b29447ba499507a259ae9d8f685d60cc1597d7d3",
            "title": "Semantic Parsing on Freebase from Question-Answer Pairs"
        },
        {
            "paperId": "1c61f9ef06fe74505775a833ff849185757199e7",
            "title": "Learning Word Vectors for Sentiment Analysis"
        },
        {
            "paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008",
            "title": "ROUGE: A Package for Automatic Evaluation of Summaries"
        },
        {
            "paperId": "10f97f1fb4f5c2c8e6c44d4a33da46d331dd4aeb",
            "title": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition"
        },
        {
            "paperId": "d7da009f457917aa381619facfa5ffae9329a6e9",
            "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"
        },
        {
            "paperId": "ae7f67c705c12391f7198527a0b962340ac8d39c",
            "title": "ChatAug: Leveraging ChatGPT for Text Data Augmentation"
        },
        {
            "paperId": "5d85d6d2da35e07f813791dd024529f0bcea8f3d",
            "title": "LLM for Patient-Trial Matching: Privacy-Aware Data Augmentation Towards Better Performance and Generalizability"
        },
        {
            "paperId": "a9d460f8eb9001b1bed11b7fb2af555185c70fcf",
            "title": "Do pretrained Transformers Really Learn In-context by Gradient Descent?"
        },
        {
            "paperId": "8aa98fbfb6f1e979dead13ce24075503fe47658e",
            "title": "A Survey for In-context Learning"
        },
        {
            "paperId": null,
            "title": "Inverse scaling prize"
        },
        {
            "paperId": null,
            "title": "Stanford alpaca: An instruction-following llama model"
        },
        {
            "paperId": "ec936b808e0fab9281c050ad4010cddec92c8cbe",
            "title": "P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks"
        },
        {
            "paperId": "045ccef36eabb0230428a343558e773dc6423491",
            "title": "Fine-tuning Pre-trained Language Models with Noise Stability Regularization"
        },
        {
            "paperId": "a334264ed4d2d83d204fcfd528269aa3da917035",
            "title": "Few-Shot (Dis)Agreement Identification in Online Discussions with Regularized and Augmented Meta-Learning"
        },
        {
            "paperId": "d9cbe86b3f4d22a682b6859f62c9d4daac4b0b64",
            "title": "Sentence-level Media Bias Analysis Informed by Discourse Structures"
        },
        {
            "paperId": "53d8b356551a2361020a948f64454a6d599af69f",
            "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"
        },
        {
            "paperId": null,
            "title": "Mesh-Transformer-JAX:Model-ParallelImplementationofTransformerLanguageModelwithJAX"
        },
        {
            "paperId": null,
            "title": "Electra: Pre-training text encoders as discriminators rather than generators"
        },
        {
            "paperId": "d033c3643a9cae57e473a67997668bb5b5bc27cc",
            "title": "Pricing"
        },
        {
            "paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": "cb73e619841e0705b3b95af313dbae8db50d4d69",
            "title": "How Stereotypes Are Shared Through Language: A Review and Introduction of the Social Categories and Stereotypes Communication (SCSC) Framework"
        },
        {
            "paperId": "0c0a778e6fdf7e36b1750c533dcc916f86608607",
            "title": "A Survey on Context Learning"
        },
        {
            "paperId": "3bf2e6941dbb87ac0d2c771c159e1e27366a26e3",
            "title": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics"
        },
        {
            "paperId": "a213a4472f3926ccd2ca5d88ef0c468d6368eefc",
            "title": "A foundation of language."
        },
        {
            "paperId": null,
            "title": "2023. GPT-4 Technical Report"
        },
        {
            "paperId": null,
            "title": "LLMs struggle when the knowledge requirements do not match their learned knowledge, or when they face tasks that only require contextual knowledge"
        },
        {
            "paperId": null,
            "title": "Fine-tuned models or specified models still have their space in tasks that are far from LLMs\u2019 pretraining objectives and data"
        },
        {
            "paperId": null,
            "title": "2023. A benchmark for toxic comment"
        },
        {
            "paperId": null,
            "title": "2023.Colt5:Fasterlong-rangetransformerswithconditionalcomputation"
        },
        {
            "paperId": null,
            "title": "d) LLMs exhibit a tendency towards closed-sourcing"
        },
        {
            "paperId": null,
            "title": "(c) Meta contributes significantly to open-source LLMs and promotes research of LLMs"
        },
        {
            "paperId": null,
            "title": "Emergent abilities become serendipity for uses that arise as LLMs scale up, such as ability in word manipulation and logical ability"
        },
        {
            "paperId": null,
            "title": "The zero-shot approach of LLMs prohibits the learning of shortcuts from task-specific datasets, which is prevalent in fine-tuned models"
        },
        {
            "paperId": null,
            "title": "Received 6 June 2023; revised 30 October 2023; accepted 16 January 2024"
        },
        {
            "paperId": null,
            "title": "2022. Robust fine-tuning of zero-shot models In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 7959\u20137971"
        },
        {
            "paperId": null,
            "title": "ChatGPT Is Banned in Italy Over Privacy Concerns\u2014The New York Times"
        },
        {
            "paperId": null,
            "title": "Promptify: Structured output from llms"
        },
        {
            "paperId": null,
            "title": "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond 160:"
        },
        {
            "paperId": null,
            "title": "Gpt-4 system card"
        },
        {
            "paperId": null,
            "title": "OpenAI"
        }
    ]
}