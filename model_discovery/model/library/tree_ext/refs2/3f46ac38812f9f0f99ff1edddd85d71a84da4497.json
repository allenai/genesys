{
    "paperId": "3f46ac38812f9f0f99ff1edddd85d71a84da4497",
    "externalIds": {
        "ArXiv": "1906.05890",
        "MAG": "2952126211",
        "DBLP": "conf/iclr/LyuL20",
        "CorpusId": 189898036
    },
    "title": "Gradient Descent Maximizes the Margin of Homogeneous Neural Networks",
    "abstract": "In this paper, we study the implicit regularization of the gradient descent algorithm in homogeneous neural networks, including fully-connected and convolutional neural networks with ReLU or LeakyReLU activations. In particular, we study the gradient descent or gradient flow (i.e., gradient descent with infinitesimal step size) optimizing the logistic loss or cross-entropy loss of any homogeneous model (possibly non-smooth), and show that if the training loss decreases below a certain threshold, then we can define a smoothed version of the normalized margin which increases over time. We also formulate a natural constrained optimization problem related to margin maximization, and prove that both the normalized margin and its smoothed version converge to the objective value at a KKT point of the optimization problem. Our results generalize the previous results for logistic regression with one-layer or multi-layer linear networks, and provide more quantitative convergence results with weaker assumptions than previous results for homogeneous smooth neural networks. We conduct several experiments to justify our theoretical finding on MNIST and CIFAR-10 datasets. Finally, as margin is closely related to robustness, we discuss potential benefits of training longer for improving the robustness of the model.",
    "venue": "International Conference on Learning Representations",
    "year": 2019,
    "referenceCount": 72,
    "citationCount": 283,
    "influentialCitationCount": 54,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The implicit regularization of the gradient descent algorithm in homogeneous neural networks, including fully-connected and convolutional neural networks with ReLU or LeakyReLU activations, is studied, and it is proved that both the normalized margin and its smoothed version converge to the objective value at a KKT point of the optimization problem."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -6.219671726226807,
            -0.7388724088668823,
            -0.5770848989486694,
            0.024436265230178833,
            0.43749141693115234,
            -1.5387243032455444,
            2.4299471378326416,
            -6.5801615715026855,
            0.6672639846801758,
            -1.7191669940948486,
            -2.9608728885650635,
            3.4244933128356934,
            1.631133794784546,
            -3.041124105453491,
            -3.7303786277770996,
            3.12501859664917,
            -1.9727835655212402,
            1.5605908632278442,
            1.684455156326294,
            1.8965545892715454,
            -3.246647596359253,
            4.467593669891357,
            -4.5391387939453125,
            -4.448630332946777,
            -0.3951203525066376,
            1.9253628253936768,
            0.7493917942047119,
            -0.7480611801147461,
            1.292392373085022,
            -2.0791492462158203,
            1.34501314163208,
            -4.831378936767578,
            9.08676528930664,
            0.6987955570220947,
            1.8244038820266724,
            1.161926507949829,
            1.338826298713684,
            7.642504692077637,
            -3.6774075031280518,
            -0.06856781244277954,
            1.7769980430603027,
            1.7076462507247925,
            -1.1954785585403442,
            -0.7287355065345764,
            2.6614906787872314,
            -1.7875593900680542,
            0.5963901281356812,
            4.576438903808594,
            -0.7652984857559204,
            1.3888823986053467,
            -0.06281259655952454,
            0.5586927533149719,
            0.522737979888916,
            3.357910633087158,
            2.954303741455078,
            -2.542018413543701,
            0.43248239159584045,
            0.13901221752166748,
            4.547125816345215,
            -0.6316553354263306,
            0.38936492800712585,
            1.601962685585022,
            -4.365540504455566,
            2.270563840866089,
            0.26823797821998596,
            -4.343702793121338,
            0.39777588844299316,
            7.454397201538086,
            1.7996125221252441,
            1.4172797203063965,
            -1.7498257160186768,
            -4.050100326538086,
            1.154905080795288,
            -1.6496144533157349,
            -3.955350399017334,
            0.7061704993247986,
            -2.6843695640563965,
            -8.338480949401855,
            1.7216331958770752,
            3.6480796337127686,
            -1.546197533607483,
            2.1538219451904297,
            -3.234416961669922,
            -0.6399003863334656,
            5.074802875518799,
            -2.228450298309326,
            -1.565382480621338,
            -1.5129218101501465,
            1.0318928956985474,
            -0.17929765582084656,
            1.563178539276123,
            -0.1255636215209961,
            4.008700370788574,
            1.8353407382965088,
            -2.1260104179382324,
            2.4330005645751953,
            -3.0895156860351562,
            0.8064961433410645,
            -0.8268395066261292,
            0.06429440528154373,
            3.6216752529144287,
            -1.309151291847229,
            3.2944722175598145,
            0.3565463125705719,
            -0.4043329060077667,
            -3.0009331703186035,
            0.9408933520317078,
            -0.1298454999923706,
            -1.8554015159606934,
            -7.926565170288086,
            -2.640604019165039,
            2.303696632385254,
            -0.1884949803352356,
            0.432007372379303,
            -1.2740626335144043,
            1.2283519506454468,
            -0.7703688740730286,
            -2.5041425228118896,
            0.30644553899765015,
            3.1792774200439453,
            -2.5608890056610107,
            -2.668015718460083,
            -2.69453763961792,
            3.0316379070281982,
            -4.0502238273620605,
            2.0290098190307617,
            -0.5257587432861328,
            3.8080811500549316,
            -3.9589829444885254,
            -5.887022972106934,
            0.9945026636123657,
            -2.1890616416931152,
            -0.8141767978668213,
            0.19297491014003754,
            3.7782626152038574,
            2.2711029052734375,
            -3.528083562850952,
            -0.4279997646808624,
            -3.784613609313965,
            -0.7526843547821045,
            1.7074012756347656,
            5.829956531524658,
            1.468851923942566,
            1.5436136722564697,
            2.9646382331848145,
            1.3519190549850464,
            1.8466591835021973,
            -2.0676229000091553,
            2.0992815494537354,
            3.8037221431732178,
            4.220120906829834,
            -0.23948633670806885,
            2.809603691101074,
            0.9898725748062134,
            -0.6573977470397949,
            2.9945807456970215,
            -2.5244429111480713,
            0.7269960641860962,
            -1.2438721656799316,
            0.27831098437309265,
            2.7600107192993164,
            -1.5936195850372314,
            -10.116437911987305,
            -1.533031940460205,
            3.867272138595581,
            -0.7166263461112976,
            3.0039689540863037,
            1.6961193084716797,
            1.6242200136184692,
            0.8701115250587463,
            -0.06701640784740448,
            -0.08990415930747986,
            -2.2063536643981934,
            6.012379169464111,
            -2.2001774311065674,
            2.6355178356170654,
            5.338970184326172,
            -1.7993333339691162,
            2.9482455253601074,
            2.948037624359131,
            -3.3776602745056152,
            -3.1916210651397705,
            -5.615717887878418,
            -3.4330391883850098,
            -5.464445114135742,
            -2.9079723358154297,
            -3.3339133262634277,
            -0.3452345132827759,
            -3.384152889251709,
            1.4697370529174805,
            1.2420547008514404,
            -0.8749902248382568,
            4.508681297302246,
            4.902808666229248,
            1.1293725967407227,
            0.3449135422706604,
            0.42170006036758423,
            -2.619866371154785,
            -1.4194663763046265,
            -2.468979835510254,
            2.334742784500122,
            2.391226291656494,
            -0.1014644131064415,
            -0.26669883728027344,
            -0.22377176582813263,
            -0.5053088068962097,
            -1.348880648612976,
            2.7604846954345703,
            4.517989635467529,
            0.0503656268119812,
            0.8479982614517212,
            -0.9086114764213562,
            -2.8303558826446533,
            1.7708518505096436,
            -5.472820281982422,
            -1.2574310302734375,
            -1.0306124687194824,
            -0.6823171377182007,
            0.6533463001251221,
            0.6860829591751099,
            -1.8510448932647705,
            0.8328025937080383,
            -4.172983169555664,
            -2.368178129196167,
            4.668651103973389,
            -4.797624588012695,
            1.4127014875411987,
            3.9562840461730957,
            -0.021684199571609497,
            4.232076644897461,
            -1.2011700868606567,
            -0.49034783244132996,
            0.34637191891670227,
            0.28316330909729004,
            -4.758480072021484,
            1.0805959701538086,
            0.3678995370864868,
            0.9519802927970886,
            -3.1455554962158203,
            0.5390433073043823,
            6.4039177894592285,
            -3.037722110748291,
            -0.45341843366622925,
            4.50550651550293,
            -0.34806638956069946,
            3.734579086303711,
            -3.771644115447998,
            -2.085963487625122,
            -1.9458281993865967,
            -0.815467357635498,
            -1.425874948501587,
            1.6335186958312988,
            1.061495065689087,
            -0.02388972043991089,
            3.3986806869506836,
            3.875269889831543,
            3.327681303024292,
            1.3559685945510864,
            4.456679821014404,
            -0.323548823595047,
            0.8076552748680115,
            5.962337970733643,
            -2.7709078788757324,
            1.139404058456421,
            2.861921787261963,
            0.27493515610694885,
            -3.6477503776550293,
            -1.5284450054168701,
            0.19915543496608734,
            1.6851170063018799,
            -0.30829861760139465,
            2.5792653560638428,
            -2.2523531913757324,
            -7.610239028930664,
            -2.6250336170196533,
            0.40691447257995605,
            -0.12435877323150635,
            -0.9681020379066467,
            3.9909768104553223,
            3.7984113693237305,
            -0.21729737520217896,
            -1.1780180931091309,
            -0.03148007392883301,
            -2.9474570751190186,
            -3.784632444381714,
            -4.228336334228516,
            -2.505673885345459,
            0.2638946771621704,
            2.752840280532837,
            -1.953571081161499,
            -4.951052665710449,
            -0.9655798077583313,
            -3.6055872440338135,
            1.7178171873092651,
            -4.34169340133667,
            3.195887327194214,
            0.9824106693267822,
            3.715897560119629,
            -2.4889912605285645,
            1.095750093460083,
            -3.0479063987731934,
            1.6322951316833496,
            2.985182046890259,
            -2.4888689517974854,
            1.1638965606689453,
            0.011679813265800476,
            3.6374433040618896,
            -4.5914106369018555,
            -0.4172883629798889,
            -1.6793932914733887,
            -0.03415822982788086,
            -0.49865642189979553,
            3.243504047393799,
            -0.7579752206802368,
            -0.5668503046035767,
            -2.8023226261138916,
            -1.951216220855713,
            4.561478137969971,
            -3.187807321548462,
            1.5832889080047607,
            -1.498742938041687,
            2.396660327911377,
            -3.8096866607666016,
            -2.8739476203918457,
            2.053654670715332,
            2.975511074066162,
            3.8483328819274902,
            2.365053415298462,
            1.1258831024169922,
            2.22314715385437,
            -1.9883064031600952,
            3.4918646812438965,
            4.578640937805176,
            5.8424835205078125,
            -0.30581796169281006,
            -4.027472019195557,
            -4.321821212768555,
            -1.9610412120819092,
            2.1848058700561523,
            1.136549472808838,
            2.9898786544799805,
            6.727353572845459,
            -0.14780250191688538,
            0.4349357485771179,
            -3.1650400161743164,
            -2.9676060676574707,
            3.6671037673950195,
            -4.810333251953125,
            0.4606490135192871,
            0.8735313415527344,
            1.2537273168563843,
            4.466128349304199,
            0.7206527590751648,
            0.29098832607269287,
            1.5950987339019775,
            2.51719069480896,
            6.542147636413574,
            0.49804985523223877,
            2.895536422729492,
            2.4147701263427734,
            -0.16125722229480743,
            -0.5889847278594971,
            -1.1094129085540771,
            -2.022862434387207,
            2.5472679138183594,
            -1.8132479190826416,
            7.185018539428711,
            -3.111837863922119,
            -1.272581696510315,
            -4.485980033874512,
            -4.78936767578125,
            1.1121138334274292,
            -1.403012990951538,
            1.6369390487670898,
            -3.5849666595458984,
            -3.529543876647949,
            0.5706366300582886,
            -4.165661334991455,
            4.210577011108398,
            2.1655097007751465,
            -0.12026900053024292,
            1.2820439338684082,
            -0.45240581035614014,
            4.238935947418213,
            0.2197420597076416,
            -3.1564717292785645,
            -2.117182970046997,
            2.4326212406158447,
            0.45306524634361267,
            1.7946354150772095,
            -2.064014434814453,
            3.0550537109375,
            -0.8389436602592468,
            -1.512915015220642,
            1.453089714050293,
            -4.1908860206604,
            -5.417998790740967,
            -3.0389537811279297,
            -0.7727862596511841,
            1.1833754777908325,
            -2.1192569732666016,
            1.8263299465179443,
            6.223384857177734,
            1.4255067110061646,
            -3.2357797622680664,
            -5.338479995727539,
            4.320298194885254,
            -0.2500322461128235,
            -1.9997888803482056,
            2.8510632514953613,
            -2.6679928302764893,
            -1.255350947380066,
            -0.9191116690635681,
            -4.658858299255371,
            -1.525351643562317,
            -3.8272719383239746,
            -1.2112276554107666,
            2.543027400970459,
            3.5550174713134766,
            1.8000600337982178,
            -2.064330577850342,
            4.5945820808410645,
            3.1506245136260986,
            1.6562652587890625,
            -3.263176679611206,
            3.5922465324401855,
            0.8256207704544067,
            2.8273682594299316,
            -0.5099614858627319,
            1.554985761642456,
            -1.126053810119629,
            5.661290168762207,
            -1.4582083225250244,
            0.525201678276062,
            0.1267673373222351,
            6.920254707336426,
            1.5502948760986328,
            -0.5415860414505005,
            1.6019172668457031,
            0.048332661390304565,
            -1.5985525846481323,
            1.5613535642623901,
            1.9412909746170044,
            3.406740665435791,
            0.7669315934181213,
            -2.8952553272247314,
            -3.041930913925171,
            0.620448887348175,
            0.8415013551712036,
            -4.161222457885742,
            3.6760261058807373,
            0.40135568380355835,
            -2.8832197189331055,
            0.9563494920730591,
            0.5106915831565857,
            -0.14496827125549316,
            0.09900563955307007,
            0.4469270408153534,
            1.5007078647613525,
            1.7340362071990967,
            -2.6920759677886963,
            4.468517780303955,
            -2.2095751762390137,
            3.5791072845458984,
            -1.411405086517334,
            2.115422248840332,
            2.4940876960754395,
            2.058396339416504,
            -0.883403480052948,
            -0.7088769674301147,
            0.2358701527118683,
            -2.7246670722961426,
            -2.1773006916046143,
            -4.271172046661377,
            1.7764348983764648,
            1.563949465751648,
            2.847522735595703,
            1.8911774158477783,
            0.19864007830619812,
            -1.5370404720306396,
            -3.3702666759490967,
            -3.8244690895080566,
            2.087200403213501,
            0.7547608017921448,
            -3.5844860076904297,
            4.609074592590332,
            3.350804567337036,
            1.9522619247436523,
            5.2394843101501465,
            3.430678129196167,
            -0.3574135899543762,
            1.5678510665893555,
            4.22541618347168,
            1.549726963043213,
            1.3501747846603394,
            -1.3545424938201904,
            -3.0846946239471436,
            3.5757436752319336,
            -0.03859591484069824,
            -1.5092167854309082,
            1.8155170679092407,
            1.6189064979553223,
            0.4265959858894348,
            0.45546483993530273,
            -1.7941126823425293,
            4.405507564544678,
            2.992370367050171,
            -0.5813769102096558,
            -2.4643187522888184,
            -1.83552885055542,
            -1.1427644491195679,
            0.2890961766242981,
            -5.2202863693237305,
            -0.12753409147262573,
            -3.1464271545410156,
            2.6165168285369873,
            -1.3225252628326416,
            0.8851133584976196,
            -0.8616592288017273,
            -3.8809022903442383,
            -1.6738860607147217,
            -3.4451112747192383,
            -2.809454917907715,
            4.0882568359375,
            -1.0032141208648682,
            0.7111839056015015,
            -0.7396698594093323,
            1.8555347919464111,
            -0.2396562099456787,
            4.77329158782959,
            3.8474583625793457,
            5.194595813751221,
            3.6977505683898926,
            -2.8458266258239746,
            -1.734025478363037,
            -2.6633176803588867,
            4.106493949890137,
            3.445647716522217,
            -3.092977523803711,
            -2.8107521533966064,
            2.7067158222198486,
            0.19850802421569824,
            -4.874222755432129,
            -2.6349568367004395,
            -1.6649669408798218,
            4.680930137634277,
            -3.340249538421631,
            -3.4193227291107178,
            -2.730167865753174,
            1.2678577899932861,
            3.6973466873168945,
            -0.3003220558166504,
            2.295238733291626,
            -4.2614240646362305,
            -3.5278706550598145,
            -0.5929160118103027,
            1.7104907035827637,
            -0.9599522352218628,
            1.425893783569336,
            3.4135007858276367,
            -2.549875259399414,
            0.3797207474708557,
            -2.006932497024536,
            1.061346173286438,
            0.7386694550514221,
            -0.8782634735107422,
            2.3679280281066895,
            1.7394733428955078,
            -0.5850745439529419,
            -5.341306686401367,
            1.4872543811798096,
            -0.20800545811653137,
            -0.8299577832221985,
            0.37029844522476196,
            -0.5415817499160767,
            2.8971965312957764,
            4.057765960693359,
            0.699783205986023,
            -4.339598655700684,
            1.8396137952804565,
            0.4449501633644104,
            -5.072741985321045,
            -0.48515304923057556,
            -4.177868366241455,
            2.0737905502319336,
            -5.1580963134765625,
            -2.8834242820739746,
            1.6082918643951416,
            -2.304328441619873,
            -2.5576982498168945,
            4.0410685539245605,
            -1.8673440217971802,
            1.3055040836334229,
            -2.2435812950134277,
            -0.19583454728126526,
            -3.0481793880462646,
            -0.18634575605392456,
            1.6059281826019287,
            -3.2184529304504395,
            -0.08499112725257874,
            2.355919599533081,
            1.4525597095489502,
            3.930483818054199,
            1.0390678644180298,
            2.1524343490600586,
            2.1006009578704834,
            0.8497858047485352,
            -1.0243254899978638,
            -3.6710963249206543,
            1.9981738328933716,
            2.3976528644561768,
            0.020780161023139954,
            18.771587371826172,
            0.2117653787136078,
            -0.07417330145835876,
            -2.5522632598876953,
            -0.4839767813682556,
            -3.8235161304473877,
            -2.772578716278076,
            2.2064218521118164,
            0.42289382219314575,
            4.8628644943237305,
            0.960737943649292,
            0.8609091639518738,
            0.3104081153869629,
            0.10531169176101685,
            -4.910646438598633,
            -1.080936074256897,
            -1.6343841552734375,
            3.0499022006988525,
            -0.32746899127960205,
            -2.075025796890259,
            -4.383889198303223,
            -1.1395313739776611,
            0.7557231783866882,
            -0.16134214401245117,
            1.4727286100387573,
            3.599222421646118,
            -0.7472699880599976,
            -1.7365448474884033,
            -5.355451583862305,
            0.3433939814567566,
            1.9977573156356812,
            0.5404558777809143,
            -1.6476233005523682,
            2.3431949615478516,
            -3.953402042388916,
            2.519066333770752,
            6.3826727867126465,
            -1.0760468244552612,
            3.7131667137145996,
            -0.48661893606185913,
            0.007329781539738178,
            1.0572419166564941,
            -2.0592856407165527,
            0.8106358647346497,
            -2.1621170043945312,
            0.4848382771015167,
            1.6474257707595825,
            -1.884062647819519,
            -2.761789560317993,
            4.807907581329346,
            6.80946683883667,
            0.7893005013465881,
            -1.483051061630249,
            1.8858633041381836,
            2.2222743034362793,
            5.31314754486084,
            -0.768017053604126,
            0.7173864841461182,
            -1.0295974016189575,
            4.2927985191345215,
            0.6428216695785522,
            2.5943541526794434,
            -4.750853538513184,
            -5.459069728851318,
            0.34943220019340515,
            1.9729766845703125,
            -2.796417474746704,
            2.269371271133423,
            1.8640652894973755,
            2.065633773803711,
            3.676459789276123,
            -0.28362053632736206,
            1.2569928169250488,
            -2.702608108520508,
            -4.359364986419678,
            -4.545942306518555,
            0.05972883850336075,
            1.3667188882827759,
            1.8017743825912476,
            6.353875160217285,
            0.601211428642273,
            -2.026923418045044,
            -2.7775182723999023,
            2.6946349143981934,
            5.165916919708252,
            -0.7356076240539551,
            2.1032416820526123,
            -1.1620700359344482,
            -0.7617190480232239,
            0.34568074345588684,
            -1.0128812789916992,
            -2.807532787322998,
            -2.2596590518951416,
            -0.671372652053833,
            3.228672981262207,
            -3.109030246734619,
            -3.6801304817199707,
            -1.7660918235778809,
            -6.481427192687988,
            -4.984347820281982,
            3.7236180305480957,
            2.2013068199157715,
            2.421509027481079,
            -0.9707974195480347,
            2.186933994293213,
            1.0377347469329834,
            0.9073945879936218,
            -5.281682014465332,
            -3.742002248764038,
            -2.0205941200256348,
            2.9694323539733887,
            -3.9616222381591797,
            -2.0156452655792236,
            0.9772530794143677,
            -3.5517778396606445,
            0.2645520567893982,
            -1.7022291421890259,
            3.3840672969818115,
            1.4716870784759521,
            3.056922197341919,
            3.007199287414551,
            -3.6293487548828125,
            0.5681491494178772,
            -2.315558433532715,
            -2.0871641635894775,
            4.008366107940674,
            0.7514722347259521,
            -0.9995678663253784,
            -0.707636833190918,
            -3.7768607139587402,
            1.472179889678955,
            -2.8051013946533203,
            -1.2117671966552734,
            -3.552578926086426,
            -2.611880302429199,
            0.8184961676597595,
            0.22179937362670898,
            0.6721941232681274,
            -3.882267475128174,
            3.3641252517700195,
            4.460077285766602,
            -1.2565743923187256,
            0.8734009861946106,
            8.462065696716309,
            0.7905721664428711,
            2.0156502723693848,
            -0.3467722535133362,
            0.343241423368454,
            2.4415481090545654,
            -0.30005115270614624,
            -1.3316097259521484,
            2.2157411575317383,
            4.932186603546143,
            1.8010367155075073,
            -3.050196886062622,
            -2.0519728660583496
        ]
    },
    "authors": [
        {
            "authorId": "41049476",
            "name": "Kaifeng Lyu"
        },
        {
            "authorId": "2151965388",
            "name": "Jian Li"
        }
    ],
    "references": [
        {
            "paperId": "801218f718e04bc98a01ca4eb64fab56107520e8",
            "title": "Improved Sample Complexities for Deep Networks and Robust Classification via an All-Layer Margin"
        },
        {
            "paperId": "76c2679deb0b7689c658c199254963889d4d2b69",
            "title": "The implicit bias of gradient descent on nonseparable data"
        },
        {
            "paperId": "6d35b7b3696a61a10afa98ef1894840aa92cc37f",
            "title": "A refined primal-dual analysis of the implicit bias"
        },
        {
            "paperId": "217a85f667778567d7ffc8b56060783caf5803b0",
            "title": "Implicit Regularization in Deep Matrix Factorization"
        },
        {
            "paperId": "6b81ffcb4b461f7f657cfb4d9b076cdc595b1077",
            "title": "Lexicographic and Depth-Sensitive Margins in Homogeneous and Non-Homogeneous Deep Models"
        },
        {
            "paperId": "c232afff29037ca4058f2b45e987cd12081bae0a",
            "title": "Implicit Regularization of Discrete Gradient Dynamics in Deep Linear Neural Networks"
        },
        {
            "paperId": "1029daa28aa772e441470e61bdd610c222e92932",
            "title": "On Exact Computation with an Infinitely Wide Neural Net"
        },
        {
            "paperId": "bcf397d57dbcb5d423a341bfadef8dfc09d0cfb8",
            "title": "Implicit regularization for deep neural networks driven by an Ornstein-Uhlenbeck like process"
        },
        {
            "paperId": "96828bb19aef978e028f03f8e7fcb5977b70fd23",
            "title": "Better Approximations of High Dimensional Smooth Functions by Deep Neural Networks with Rectified Power Units"
        },
        {
            "paperId": "9f9fc406c76255fec51a6196ce167c0ff1d1efc0",
            "title": "Wide neural networks of any depth evolve as linear models under gradient descent"
        },
        {
            "paperId": "96c82727dd5a80fef93007f888bb8569feb6bd85",
            "title": "Fixup Initialization: Residual Learning Without Normalization"
        },
        {
            "paperId": "313b368457e54e6a7482b008d5eb4182eb1b4d1c",
            "title": "Stochastic Gradient Descent Optimizes Over-parameterized Deep ReLU Networks"
        },
        {
            "paperId": "03e7e8663c69e691be6b6403b1eb1bbf593d31f2",
            "title": "Gradient Descent Finds Global Minima of Deep Neural Networks"
        },
        {
            "paperId": "e657b21aa3466b89c7582fc4881a7470131e21ee",
            "title": "A Continuous-Time View of Early Stopping for Least Squares Regression"
        },
        {
            "paperId": "9c985db0a4a255a06e0fbf2ce147ea741720f9f0",
            "title": "Regularization Matters: Generalization and Optimization of Neural Nets v.s. their Induced Kernel"
        },
        {
            "paperId": "5786917220aab2f6d0b00606eee9fe0ad0700f1b",
            "title": "Gradient descent aligns the layers of deep linear networks"
        },
        {
            "paperId": "f0ded4902d7f9c111e50047f8c9494effb7282d1",
            "title": "Sorting out Lipschitz function approximation"
        },
        {
            "paperId": "42ec3db12a2e4628885451b13035c2e975220a25",
            "title": "A Convergence Theory for Deep Learning via Over-Parameterization"
        },
        {
            "paperId": "7a84a692327534fd227fa1e07fcb3816b633c591",
            "title": "Neural Tangent Kernel: Convergence and Generalization in Neural Networks"
        },
        {
            "paperId": "974fefe7b8506a9a2132fc5ec4c1084ab51df03b",
            "title": "On Tighter Generalization Bound for Deep Neural Networks: CNNs, ResNets, and Beyond"
        },
        {
            "paperId": "8e1ea054aa0a807f288a9e17cb783b17222e5b6c",
            "title": "When will gradient methods converge to max\u2010margin classifier under ReLU models?"
        },
        {
            "paperId": "d8b477a120798e3c8983de485c1a8cff06ff33db",
            "title": "Stochastic Gradient Descent on Separable Data: Exact Convergence with a Fixed Learning Rate"
        },
        {
            "paperId": "0e662587c790e5d11475f5b0bce3638b4d1effa0",
            "title": "Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced"
        },
        {
            "paperId": "67a97032fd3ad81cda45e1e5d4a1a7d851494525",
            "title": "Implicit Bias of Gradient Descent on Linear Convolutional Networks"
        },
        {
            "paperId": "1a3a683a24c819e6f2da5e85a3b52817378ca43b",
            "title": "Stochastic Subgradient Method Converges on Tame Functions"
        },
        {
            "paperId": "4a5a17d7849b91a3af583c7b99403844e1a5cdb1",
            "title": "Risk and parameter convergence of logistic regression"
        },
        {
            "paperId": "59ef5569832b2fbb865466b3951ad0957537cd54",
            "title": "Convergence of Gradient Descent on Separable Data"
        },
        {
            "paperId": "ec6977956cfa40baca1453d37b80f1faf55f0d5f",
            "title": "On the Power of Over-parametrization in Neural Networks with Quadratic Activation"
        },
        {
            "paperId": "33416f2dc49db24cca520a3b234f02463a4e833e",
            "title": "Characterizing Implicit Bias in Terms of Optimization Geometry"
        },
        {
            "paperId": "651adaa058f821a890f2c5d1053d69eb481a8352",
            "title": "Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples"
        },
        {
            "paperId": "8b4b861583f698e89c8cd9e198aad86809a71de7",
            "title": "Algorithmic Regularization in Over-parameterized Matrix Sensing and Neural Networks with Quadratic Activations"
        },
        {
            "paperId": "018a844cd7a496aed84f166e4b02ff547c3b5d16",
            "title": "Size-Independent Sample Complexity of Neural Networks"
        },
        {
            "paperId": "15f482d59820225c0b9451118b4ca785ba423e4b",
            "title": "Implicit Regularization in Nonconvex Statistical Estimation: Gradient Descent Converges Linearly for Phase Retrieval, Matrix Completion, and Blind Deconvolution"
        },
        {
            "paperId": "11adc8bd35bd897502f9b5452ab7ac668ec9b0fb",
            "title": "The Implicit Bias of Gradient Descent on Separable Data"
        },
        {
            "paperId": "4fc3ee440c2b0f66255a9e6966cee871ee0cc6da",
            "title": "A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks"
        },
        {
            "paperId": "9753967a3af8e1db1e2da52a9bb3255bd1ce5c51",
            "title": "Spectrally-normalized margin bounds for neural networks"
        },
        {
            "paperId": "99ed21b585f4d6cbc4e20002bedca8d6c08169c6",
            "title": "Recovery Guarantees for One-hidden-layer Neural Networks"
        },
        {
            "paperId": "2103cf5f7ad126e21d0e4258ad2872abab0bebed",
            "title": "Gradient Descent Can Take Exponential Time to Escape Saddle Points"
        },
        {
            "paperId": "1ecc2bd0bc6ffa0a2f466a058589c20593e3e57c",
            "title": "The Marginal Value of Adaptive Gradient Methods in Machine Learning"
        },
        {
            "paperId": "013efe3ff541e518c51f08d1b62a62e0c57c0b14",
            "title": "Parseval Networks: Improving Robustness to Adversarial Examples"
        },
        {
            "paperId": "54ddb00fa691728944fd8becea90a373d21597cf",
            "title": "Understanding deep learning requires rethinking generalization"
        },
        {
            "paperId": "df40ce107a71b770c9d0354b78fdd8989da80d2f",
            "title": "Towards Evaluating the Robustness of Neural Networks"
        },
        {
            "paperId": "0a87ebdb470c4ff0c371dbe58c28c44118e6c23f",
            "title": "Approximation by Combinations of ReLU and Squared ReLU Ridge Functions With  $\\ell^1$  and  $\\ell^0$  Controls"
        },
        {
            "paperId": "f657e68dde470641ba1a6cd7ab755e6359a32840",
            "title": "Robust Large Margin Deep Neural Networks"
        },
        {
            "paperId": "6fe02ad979baad659f04c3376a77dbb2cb4699a5",
            "title": "Path-SGD: Path-Normalized Optimization in Deep Neural Networks"
        },
        {
            "paperId": "d6f2f611da110b5b5061731be3fc4c7f45d8ee23",
            "title": "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification"
        },
        {
            "paperId": "4b675d8f63888d7d6d7d77a0834efa5eaded64c5",
            "title": "In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning"
        },
        {
            "paperId": "95b4d5ebb584e0173ce25b903d9666697a488404",
            "title": "Towards a deeper geometric, analytic and algorithmic understanding of margins"
        },
        {
            "paperId": "d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad",
            "title": "Intriguing properties of neural networks"
        },
        {
            "paperId": "033c08ca48aaed2d5ab0a17d668d410538678ed8",
            "title": "Evasion Attacks against Machine Learning at Test Time"
        },
        {
            "paperId": "dac51acfdd67d630b104e0ce259960435e68ae22",
            "title": "Approximate KKT points and a proximity measure for termination"
        },
        {
            "paperId": "2cf3142e55965c6dce7e3ee2f93d1fb2d5aba416",
            "title": "Margins, Shrinkage, and Boosting"
        },
        {
            "paperId": "9ec1cd529405a8a852115fcb7e4b004f8e268681",
            "title": "Curves of Descent"
        },
        {
            "paperId": "6ba3cb0ce765768e096245a7cb408888fa484df2",
            "title": "Boosting: Foundations and Algorithms"
        },
        {
            "paperId": "65311ed8bb113763b747ea4ac7baed97ef3623c3",
            "title": "On the equivalence of weak learnability and linear separability: new relaxations and efficient boosting algorithms"
        },
        {
            "paperId": "e6d88754cb0f64fc1a4728bb13ffe3863fd771ad",
            "title": "Convergence of the Iterates of Descent Methods for Analytic Cost Functions"
        },
        {
            "paperId": "f6d16b4db8779721715a00008ba03b5c67e4669c",
            "title": "Margin Maximizing Loss Functions"
        },
        {
            "paperId": "4d19272112b50547614479a0c409fca66e3b05f7",
            "title": "Boosting the margin: A new explanation for the effectiveness of voting methods"
        },
        {
            "paperId": "fdb852427e99de6bc62afffe87d395085ffbbd26",
            "title": "Geometric categories and o-minimal structures"
        },
        {
            "paperId": "cc761fe70e533c42f1ca91d4d0d6509be7e51989",
            "title": "Geometric theory of dynamical systems : an introduction"
        },
        {
            "paperId": "99ee1cc66f8f2daf824f56434fc79d363fb589f1",
            "title": "Generalized gradients and applications"
        },
        {
            "paperId": "622bf5c5bd224ccb43d60f81ed78f805ef10ce56",
            "title": "The method of steepest descent for non-linear minimization problems"
        },
        {
            "paperId": "0e9f7ddbeb0917e483c883d4cbe635fb260497da",
            "title": "Theory III: Dynamics and Generalization in Deep Networks1"
        },
        {
            "paperId": "7a4122ee1a93986aa60553389957d554561c4180",
            "title": "Connecting Optimization and Regularization Paths"
        },
        {
            "paperId": null,
            "title": "for linear model). The loss-based learning rate scheduling is indeed a variant of line search. In particular, we initialize \u03b1(0) by some value, and do the following at each epoch t: Step 1"
        },
        {
            "paperId": null,
            "title": "Chapter IV - Nonsmooth Optimization Problems"
        },
        {
            "paperId": "5153c9d7686ffe3462c32bcb1d1586aca83b5825",
            "title": "AN INTRODUCTION TO O-MINIMAL GEOMETRY"
        },
        {
            "paperId": "4ca1abad559212f09377137bb46bd787db629566",
            "title": "Nonsmooth analysis and control theory"
        },
        {
            "paperId": "849a2f9fff249cb5c7356aa6b8f4a7c43ce74746",
            "title": "Optimization And Nonsmooth Analysis"
        },
        {
            "paperId": "1f7f8a1dc33804a5764d135e013d768ba89b9998",
            "title": "Mathematical Programming Methods"
        },
        {
            "paperId": null,
            "title": "IfL(t) <L(t \u2212 1), \u03b1(t) \u2190 \u03b1(t) \u00b7 r u and end this epoch; otherwise, \u03b1(t) \u2190 \u03b1(t)/r d and go to Step 2"
        },
        {
            "paperId": null,
            "title": "This specific choice of those hyperparameters is not important"
        }
    ]
}