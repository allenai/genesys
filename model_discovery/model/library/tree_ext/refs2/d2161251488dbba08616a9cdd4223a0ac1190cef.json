{
    "paperId": "d2161251488dbba08616a9cdd4223a0ac1190cef",
    "externalIds": {
        "DBLP": "conf/sigir/VoorheesT00",
        "MAG": "2028175314",
        "DOI": "10.1145/345508.345577",
        "CorpusId": 11465263
    },
    "title": "Building a question answering test collection",
    "abstract": "The TREC-8 Question Answering (QA) Track was the first large-scale evaluation of domain-independent question answering systems. In addition to fostering research on the QA task, the track was used to investigate whether the evaluation methodology used for document retrieval is appropriate for a different natural language processing task. As with document relevance judging, assessors had legitimate differences of opinions as to whether a response actually answers a question, but comparative evaluation of QA systems was stable despite these differences. Creating a reusable QA test collection is fundamentally more difficult than creating a document retrieval test collection since the QA task has no equivalent to document identifiers.",
    "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
    "year": 2000,
    "referenceCount": 21,
    "citationCount": 541,
    "influentialCitationCount": 64,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The TREC-8 Question Answering (QA) Track was the first large-scale evaluation of domain-independent question answering systems and was used to investigate whether the evaluation methodology used for document retrieval is appropriate for a different natural language processing task."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "1746656",
            "name": "E. Voorhees"
        },
        {
            "authorId": "2575691",
            "name": "Dawn M. Tice"
        }
    ],
    "references": [
        {
            "paperId": "46be284f1e1ece64465af6fe3a69ce544e0c7e33",
            "title": "The TREC-8 Question Answering Track Evaluation"
        },
        {
            "paperId": "eea69a2b0a806727a58a827be9f907c8bcfd36b0",
            "title": "A usability case study using TREC and ZPRISE"
        },
        {
            "paperId": "11c4c4b285fb103494614bd31f2c9494a1b7bf3b",
            "title": "The DARPA High-Performance Knowledge Bases Project"
        },
        {
            "paperId": "162c68e07814704109122d61771c1ce067e95b86",
            "title": "Variations in relevance judgments and the measurement of retrieval effectiveness"
        },
        {
            "paperId": "e78cabd2f0a8bc2487bf77fa5c62657ed589f64e",
            "title": "Question Answering from Frequently Asked Question Files: Experiences with the FAQ FINDER System"
        },
        {
            "paperId": "799aa56df7a1bdbc952d10bcf3eccdf2d7a7d9f5",
            "title": "SRI International FASTUS system: MUC-6 test results and analysis"
        },
        {
            "paperId": "ba634828840e6a586eb269a47b3517cf557ad61d",
            "title": "MURAX: a robust linguistic approach for question answering using an on-line encyclopedia"
        },
        {
            "paperId": "74ce4c5cbe63220cd4ed88ee301bdd9307d4dee6",
            "title": "BBN: Description of the PLUM System as Used for MUC-4"
        },
        {
            "paperId": "1162683ba416540ecd5c828b115fcfbeb8f37024",
            "title": "Answer-passage retrieval by text searching"
        },
        {
            "paperId": "d063a2a29f13d3a3ed4922f20c045795a1958786",
            "title": "Five Lectures on Artificial Intelligence"
        },
        {
            "paperId": "2b4d358cda26b03484091d88c1871c5edf38b373",
            "title": "Relevance assessments and retrieval system evaluation"
        },
        {
            "paperId": "e0d16bdb90a1f9918c5ad801615778e7f72df53d",
            "title": "The Sixth Text REtrieval Conference (TREC-6)"
        },
        {
            "paperId": "57c85e170091a6cbd2b2228989022a846f407dfc",
            "title": "Ask Me Tomorrow: The NRC and University of Ottawa Question Answering System"
        },
        {
            "paperId": "7f6e1f9ab56e4ba7b9b7a1b536ceaecf2687911a",
            "title": "A Sys Called Qanda"
        },
        {
            "paperId": "df8568c6e19d427aae989887a47c3a88f8124dda",
            "title": "From Sentence Processing to Information Access on the World Wide Web"
        },
        {
            "paperId": "46bf2acd3cd09525ab79183039536ab3ee985365",
            "title": "Overview of the Sixth Text REtrieval Conference (TREC-6)"
        },
        {
            "paperId": "849a38b3ab9734aaf803744c490e21a572bac973",
            "title": "BEN: description of the PLUM system as used for MUC-6"
        },
        {
            "paperId": null,
            "title": "BBN Systems"
        },
        {
            "paperId": "691b598b993ff019e426ac29a7817bb01d16fdfa",
            "title": "Relevance and Information Behavior."
        },
        {
            "paperId": null,
            "title": "Kendalr s tau"
        },
        {
            "paperId": null,
            "title": "Lunar rocks in natural english: Exploratio ns in natural language question answering"
        }
    ]
}