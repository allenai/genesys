{
    "paperId": "1518039b5001f1836565215eb047526b3ac7f462",
    "externalIds": {
        "DBLP": "conf/acl/SennrichHB16a",
        "ACL": "P16-1162",
        "MAG": "1816313093",
        "ArXiv": "1508.07909",
        "DOI": "10.18653/v1/P16-1162",
        "CorpusId": 1114678
    },
    "title": "Neural Machine Translation of Rare Words with Subword Units",
    "abstract": "Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). We discuss the suitability of different word segmentation techniques, including simple character n-gram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English-German and English-Russian by 1.1 and 1.3 BLEU, respectively.",
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2015,
    "referenceCount": 42,
    "citationCount": 7095,
    "influentialCitationCount": 960,
    "openAccessPdf": {
        "url": "https://www.aclweb.org/anthology/P16-1162.pdf",
        "status": "HYBRID"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper introduces a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units, and empirically shows that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English-German and English-Russian by 1.3 BLEU."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "2082372",
            "name": "Rico Sennrich"
        },
        {
            "authorId": "2259100",
            "name": "B. Haddow"
        },
        {
            "authorId": "2539211",
            "name": "Alexandra Birch"
        }
    ],
    "references": [
        {
            "paperId": "ff1577528a34a11c2a81d2451d346c412c674c02",
            "title": "Character-based Neural Machine Translation"
        },
        {
            "paperId": "93a9694b6a4149e815c30a360347593b75860761",
            "title": "Variable-Length Word Encodings for Neural Translation Models"
        },
        {
            "paperId": "d8c5e6adf7023def3be0bee91799e18607cf588f",
            "title": "The Edinburgh/JHU Phrase-based Machine Translation Systems for WMT 2015"
        },
        {
            "paperId": "726244c312dc1145e9e9ee32ce641ab8dd9c6e74",
            "title": "A Joint Dependency Model of Morphological and Syntactic Structure for Statistical Machine Translation"
        },
        {
            "paperId": "285c165c81fc9275955147a892b9a039ec8b1052",
            "title": "chrF: character n-gram F-score for automatic MT evaluation"
        },
        {
            "paperId": "2da338d8972e473df62a566290c9de95a52209e5",
            "title": "Results of the WMT15 Metrics Shared Task"
        },
        {
            "paperId": "891ce1687e2befddd19f54e4eef1d3f39c8dbaf7",
            "title": "Character-Aware Neural Language Models"
        },
        {
            "paperId": "93499a7c7f699b6630a86fad964536f9423bb6d0",
            "title": "Effective Approaches to Attention-based Neural Machine Translation"
        },
        {
            "paperId": "6dab1c6491929d396e9e5463bc2e87af88602aa2",
            "title": "Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation"
        },
        {
            "paperId": "1938624bb9b0f999536dcc8d8f519810bb4e1b3b",
            "title": "On Using Very Large Target Vocabulary for Neural Machine Translation"
        },
        {
            "paperId": "1956c239b3552e030db1b78951f64781101125ed",
            "title": "Addressing the Rare Word Problem in Neural Machine Translation"
        },
        {
            "paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "title": "Sequence to Sequence Learning with Neural Networks"
        },
        {
            "paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "title": "Neural Machine Translation by Jointly Learning to Align and Translate"
        },
        {
            "paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e",
            "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"
        },
        {
            "paperId": "46f418bf6fab132f193661226c5c27d67f870ea5",
            "title": "Compositional Morphology for Word Representations and Language Modelling"
        },
        {
            "paperId": "fa144b01862baa5de61d22fd3f922a3ddd54ac4d",
            "title": "Integrating an Unsupervised Transliteration Model into Statistical Machine Translation"
        },
        {
            "paperId": "944a1cfd79dbfb6fef460360a0765ba790f4027a",
            "title": "Recurrent Continuous Translation Models"
        },
        {
            "paperId": "53ab89807caead278d3deb7b6a4180b277d3cb77",
            "title": "Better Word Representations with Recursive Neural Networks for Morphology"
        },
        {
            "paperId": "7b5e31257f01aba987f16e175a3e49e00a5bd3bb",
            "title": "A Simple, Fast, and Effective Reparameterization of IBM Model 2"
        },
        {
            "paperId": "db734a0e1dc65fe3fe2eef474aefba6d083f54dd",
            "title": "A New Algorithm For Data Compression"
        },
        {
            "paperId": "8729441d734782c3ed532a7d2d9611b438c0a09a",
            "title": "ADADELTA: An Adaptive Learning Rate Method"
        },
        {
            "paperId": "84069287da0a6b488b8c933f3cb5be759cb6237e",
            "title": "On the difficulty of training recurrent neural networks"
        },
        {
            "paperId": "88b66f705a329da8292e7b8aa4bfe26de4759cfa",
            "title": "Machine Translation without Words through Substring Alignment"
        },
        {
            "paperId": "5ab5cc1c135a1af68fdea604474b70f4121db623",
            "title": "Unsupervised Morphology Rivals Supervised Morphology for Arabic MT"
        },
        {
            "paperId": "b0b3c2e5e924621b234a24037fa4f4410b478b49",
            "title": "Character-Based Pivot Translation for Under-Resourced Languages and Domains"
        },
        {
            "paperId": "36ffcc1cc218ca36de384a107fb48e5abe2e6359",
            "title": "Unsupervised Multilingual Learning for Morphological Segmentation"
        },
        {
            "paperId": "37e08e5a6b9f6ae06fe9742ba390b93a4962286b",
            "title": "Can We Translate Letters?"
        },
        {
            "paperId": "4ee2eab4c298c1824a9fb8799ad8eed21be38d21",
            "title": "Moses: Open Source Toolkit for Statistical Machine Translation"
        },
        {
            "paperId": "cdaae7a8f0db8b280266606004f1c6f164a13f6d",
            "title": "Empirical Methods for Compound Splitting"
        },
        {
            "paperId": "0c5043108eda7d2fa467fe91e3c47d4ba08e0b48",
            "title": "Unsupervised Discovery of Morphemes"
        },
        {
            "paperId": "3c096159a3277e71021273db030a5d1b866bd3d4",
            "title": "Modeling out-of-vocabulary words for robust speech recognition"
        },
        {
            "paperId": "3dffe5ebf00f10dd137beff00d94952f1af658c3",
            "title": "Improving SMT quality with morpho-syntactic analysis"
        },
        {
            "paperId": "1aa9c0045f1fe8c79cce03c7c14ef4b4643a21f8",
            "title": "A new algorithm for data compression"
        },
        {
            "paperId": "8c3cf30db12d17638b01e0e464e09d6b58a88187",
            "title": "Variable length word encodings for neural translation models"
        },
        {
            "paperId": "25eb839f39507fe6983ad3e692b2f8d93a5cb0cc",
            "title": "Neural Machine Translation Systems for WMT \u2019 15"
        },
        {
            "paperId": "1fd7fc06653723b05abe5f3d1de393ddcf6bdddb",
            "title": "SUBWORD LANGUAGE MODELING WITH NEURAL NETWORKS"
        },
        {
            "paperId": "71088c81d1fb157844c61ac24fb1dd2a70d0e59f",
            "title": "Character-Based PSMT for Closely Related Languages"
        },
        {
            "paperId": "dca029eafe302034f0e7784b9266403938c55263",
            "title": "Morphology-aware statistical machine translation based on morphs induced in an unsupervised manner"
        },
        {
            "paperId": "ec5f929b57cf12b4d624ab125f337c14ad642ab1",
            "title": "Modelling out-of-vocabulary words for robust speech recognition"
        },
        {
            "paperId": "6c0f01c67f43e35859025d3424e0268b4d1ee2f1",
            "title": "Word hy-phen-a-tion by com-put-er"
        },
        {
            "paperId": null,
            "title": "Annual Conference of the European Association for Machine Translation (EAMT'09)"
        },
        {
            "paperId": "13167f9cd8c7906ca808b01d28dca6dd951da8a5",
            "title": "of the Association for Computational Linguistics"
        }
    ]
}