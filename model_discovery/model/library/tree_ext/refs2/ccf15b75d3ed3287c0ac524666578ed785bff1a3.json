{
    "paperId": "ccf15b75d3ed3287c0ac524666578ed785bff1a3",
    "externalIds": {
        "DBLP": "journals/corr/abs-2302-07863",
        "DOI": "10.48550/arXiv.2302.07863",
        "CorpusId": 263869576
    },
    "title": "Big Little Transformer Decoder",
    "abstract": "The recent emergence of Large Language Models based on the Transformer architecture has enabled dramatic advancements in the field of Natural Language Processing. However, these models have long inference latency, which limits their deployment, and which makes them prohibitively expensive for various real-time applications. The inference latency is further exacerbated by autoregressive generative tasks, as models need to run iteratively to generate tokens sequentially without leveraging token-level parallelization. To address this, we propose Big Little Decoder (BiLD), a framework that can improve inference efficiency and latency for a wide range of text generation applications. The BiLD framework contains two models with different sizes that collaboratively generate text. The small model runs autoregressively to generate text with a low inference cost, and the large model is only invoked occasionally to refine the small model\u2019s inaccurate predictions in a non-autoregressive manner. To coordinate the small and large models, BiLD introduces two simple yet effective policies: (1) the fallback policy that determines when to hand control over to the large model; and (2) the rollback policy that determines when the large model needs to correct the small model\u2019s inaccurate predictions. To evaluate our framework across different tasks and models, we apply BiLD to various text generation scenarios encompassing machine translation on IWSLT 2017 De-En and WMT 2014 De-En, and summarization on XSUM and CNN/DailyMail. On an NVIDIA T4 GPU, our",
    "venue": "arXiv.org",
    "year": 2023,
    "referenceCount": 85,
    "citationCount": 18,
    "influentialCitationCount": 2,
    "openAccessPdf": {
        "url": "https://arxiv.org/pdf/2302.07863",
        "status": "GREEN"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Big Little Decoder (BiLD) is proposed, a framework that can improve inference efficiency and latency for a wide range of text generation applications and is applied to various text generation scenarios encompassing machine translation on IWSLT 2017 De-En and WMT 2014 de-En, and summarization on XSUM and CNN/DailyMail."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -2.3011484146118164,
            0.7796618938446045,
            1.64833664894104,
            3.4638423919677734,
            2.466108798980713,
            0.3238929808139801,
            3.4897074699401855,
            -1.7235736846923828,
            1.120554804801941,
            0.5347442030906677,
            -0.9817748665809631,
            3.7442195415496826,
            -0.0057104527950286865,
            -0.8773135542869568,
            -3.5903029441833496,
            1.239184856414795,
            0.7924752235412598,
            3.4243156909942627,
            4.739955902099609,
            2.8372015953063965,
            -4.281402111053467,
            -0.34977710247039795,
            -0.5669070482254028,
            -0.5337816476821899,
            -1.7851632833480835,
            0.2504439651966095,
            2.4800288677215576,
            1.2594184875488281,
            -4.706839561462402,
            3.6630616188049316,
            -0.36581501364707947,
            -3.4605157375335693,
            5.525567531585693,
            -3.750518321990967,
            5.6508259773254395,
            -3.751631021499634,
            -3.5752038955688477,
            6.407472133636475,
            -3.164041519165039,
            -1.842559814453125,
            2.4030230045318604,
            -0.9415985941886902,
            -1.9132421016693115,
            1.5877094268798828,
            2.562260389328003,
            2.1144204139709473,
            2.3219282627105713,
            0.6352971792221069,
            -0.8649375438690186,
            2.3377981185913086,
            4.182104587554932,
            1.7418915033340454,
            -2.6703333854675293,
            4.063191890716553,
            0.6517153382301331,
            -2.420060157775879,
            1.1595436334609985,
            -1.7657748460769653,
            3.054743528366089,
            -5.6706414222717285,
            4.314680099487305,
            4.841999053955078,
            1.789917230606079,
            -0.022831149399280548,
            3.2124974727630615,
            -3.9631781578063965,
            -2.6892237663269043,
            4.362606525421143,
            0.631569504737854,
            2.040515422821045,
            0.3149128258228302,
            -6.522628307342529,
            -1.4859451055526733,
            -0.2272132933139801,
            -4.696230888366699,
            0.4314593970775604,
            -3.1199090480804443,
            -6.072802543640137,
            1.4503798484802246,
            -3.5752809047698975,
            -0.5815476775169373,
            0.539596438407898,
            2.985567092895508,
            4.120475769042969,
            0.9636099338531494,
            -2.233386516571045,
            -5.265542984008789,
            0.6920210719108582,
            2.095433235168457,
            -0.9653314352035522,
            -0.2471122443675995,
            -0.3923923969268799,
            -3.5513734817504883,
            1.950598120689392,
            -3.484489679336548,
            0.023926734924316406,
            2.6565897464752197,
            1.0556648969650269,
            -2.4118306636810303,
            1.7011120319366455,
            3.808303117752075,
            -1.1302978992462158,
            1.7338805198669434,
            0.8932878971099854,
            3.560349941253662,
            -4.31983757019043,
            -1.6111608743667603,
            2.693985939025879,
            -0.3975043296813965,
            -2.5443243980407715,
            -3.953361988067627,
            4.368400573730469,
            -1.6514393091201782,
            0.9407069683074951,
            -1.9065628051757812,
            0.5958496928215027,
            -0.905262291431427,
            -2.7411890029907227,
            -2.0626468658447266,
            1.1704466342926025,
            -0.7920656204223633,
            -1.2568737268447876,
            -0.3100910186767578,
            1.7309600114822388,
            -0.901350736618042,
            2.4553115367889404,
            -0.3738853633403778,
            1.4139052629470825,
            1.7826383113861084,
            -1.6813658475875854,
            2.2763724327087402,
            -1.0628222227096558,
            4.402564525604248,
            -3.300692081451416,
            1.3088772296905518,
            2.1621556282043457,
            -4.285397529602051,
            3.2246286869049072,
            -1.6305642127990723,
            0.9153411984443665,
            -1.2395983934402466,
            5.312126159667969,
            -1.6883645057678223,
            -0.2991262972354889,
            0.39602136611938477,
            3.015502452850342,
            3.447230100631714,
            1.7043784856796265,
            -0.11757077276706696,
            4.904177665710449,
            2.357573986053467,
            -5.399925231933594,
            -0.05355992540717125,
            0.43032121658325195,
            0.8964080214500427,
            8.150309562683105,
            -6.809177398681641,
            2.0803184509277344,
            -0.8116885423660278,
            1.6537704467773438,
            -0.25713878870010376,
            0.16474908590316772,
            -10.990738868713379,
            -0.7253180146217346,
            3.4087889194488525,
            -4.4335432052612305,
            -2.682917594909668,
            -0.10431450605392456,
            0.553367018699646,
            4.455314636230469,
            -0.6327872276306152,
            0.7187477350234985,
            1.6151148080825806,
            3.7944488525390625,
            6.895432472229004,
            5.114387512207031,
            1.585314154624939,
            -2.9833338260650635,
            1.6734732389450073,
            -1.5786510705947876,
            -1.0767621994018555,
            -2.3955187797546387,
            -8.402776718139648,
            1.5673449039459229,
            -6.663405895233154,
            -3.276146650314331,
            -4.215820789337158,
            -3.1393356323242188,
            -0.10854774713516235,
            -2.4358468055725098,
            -1.8233104944229126,
            0.11375489830970764,
            4.5099968910217285,
            6.5225300788879395,
            -0.28291645646095276,
            -0.0301806777715683,
            5.786133289337158,
            4.178083419799805,
            -6.293091773986816,
            0.6952504515647888,
            2.0768613815307617,
            -0.7802051305770874,
            -2.7222189903259277,
            -0.09265998005867004,
            5.750059604644775,
            2.093315839767456,
            -1.8931818008422852,
            3.3019895553588867,
            -0.7372065782546997,
            2.3990750312805176,
            0.411907821893692,
            -0.6648207902908325,
            -0.1050584614276886,
            2.756120204925537,
            -2.1430461406707764,
            -2.2197163105010986,
            -9.06098747253418,
            2.141920328140259,
            5.44881010055542,
            2.170727252960205,
            0.3183490037918091,
            0.2392200231552124,
            0.30405527353286743,
            -4.237468719482422,
            -4.075093746185303,
            -2.3995628356933594,
            4.491625785827637,
            0.985856294631958,
            4.628480434417725,
            3.1175761222839355,
            -2.23478627204895,
            -5.503735065460205,
            0.7034196853637695,
            -0.9669522047042847,
            -6.149411678314209,
            -1.6978695392608643,
            -3.469663143157959,
            0.6875542998313904,
            -0.758541464805603,
            -2.4898643493652344,
            3.3565213680267334,
            -0.20781683921813965,
            -0.5701351761817932,
            3.4103565216064453,
            1.1165283918380737,
            -2.5406017303466797,
            -2.682492733001709,
            1.870602011680603,
            -0.24791598320007324,
            -2.6610000133514404,
            -2.007240056991577,
            -0.49229374527931213,
            3.1809091567993164,
            0.44743970036506653,
            1.5614975690841675,
            2.3651740550994873,
            -0.009610533714294434,
            -1.2894784212112427,
            1.7311017513275146,
            0.15836796164512634,
            -1.810068964958191,
            3.352903127670288,
            2.6942896842956543,
            4.806542873382568,
            -1.3637371063232422,
            -4.46053409576416,
            -3.807258129119873,
            0.668269157409668,
            -0.4073319435119629,
            2.361593008041382,
            0.3781734108924866,
            0.615098237991333,
            -0.8624692559242249,
            -6.438601016998291,
            -0.6136390566825867,
            -6.20147180557251,
            -1.4268618822097778,
            -2.6780691146850586,
            1.6654469966888428,
            8.17507553100586,
            3.5812690258026123,
            -5.02210807800293,
            -0.4448700249195099,
            -0.9949837327003479,
            -1.0864869356155396,
            -3.314009666442871,
            -1.3353662490844727,
            0.4895364046096802,
            -2.32191801071167,
            -2.24061918258667,
            -3.8996894359588623,
            3.1948766708374023,
            -2.4755115509033203,
            -3.0470705032348633,
            -4.076352596282959,
            2.9234375953674316,
            6.4233903884887695,
            -2.887598752975464,
            -0.5765233039855957,
            -1.9484943151474,
            -1.7417750358581543,
            3.1371829509735107,
            3.5655410289764404,
            0.7387694716453552,
            0.13459855318069458,
            4.419398307800293,
            1.8038421869277954,
            -3.224895477294922,
            -0.3659113645553589,
            -2.8280434608459473,
            -2.1917572021484375,
            1.6379814147949219,
            5.070831298828125,
            -3.6276378631591797,
            1.9899442195892334,
            0.4424930810928345,
            1.9639348983764648,
            0.21191968023777008,
            -2.2616350650787354,
            1.1353302001953125,
            -3.774048328399658,
            1.5732852220535278,
            -6.512116432189941,
            -0.49438679218292236,
            -5.769719123840332,
            0.3683260977268219,
            3.6369190216064453,
            0.728255033493042,
            -4.189767360687256,
            3.6314802169799805,
            1.3582136631011963,
            3.757997751235962,
            4.341033935546875,
            1.868151307106018,
            -0.9612323045730591,
            -5.592623710632324,
            0.6910622715950012,
            -2.321086883544922,
            0.9120175838470459,
            0.8089625835418701,
            -0.3325192332267761,
            6.930280685424805,
            -1.3630456924438477,
            1.3486051559448242,
            0.8103264570236206,
            0.6009400486946106,
            0.07369545102119446,
            3.1752500534057617,
            -1.7066235542297363,
            -1.5457342863082886,
            -0.8185964822769165,
            1.5194512605667114,
            4.313658714294434,
            -3.3273839950561523,
            1.7458183765411377,
            3.1189444065093994,
            1.1846117973327637,
            1.560144066810608,
            0.38098737597465515,
            2.5673282146453857,
            1.4310301542282104,
            1.434045672416687,
            0.6953668594360352,
            -1.2168734073638916,
            0.30408746004104614,
            -2.148928642272949,
            12.781879425048828,
            -1.0447962284088135,
            0.2280784249305725,
            -5.315621376037598,
            -2.9556796550750732,
            -0.6175944805145264,
            -4.329990863800049,
            3.196437358856201,
            -2.8907368183135986,
            -3.9589638710021973,
            0.9915362000465393,
            -5.589992523193359,
            0.029490262269973755,
            0.3081022799015045,
            -0.0967705249786377,
            2.440563201904297,
            -3.2844603061676025,
            4.326253890991211,
            -2.1557860374450684,
            1.601934552192688,
            -2.3790321350097656,
            2.27337384223938,
            1.3257211446762085,
            -1.6049134731292725,
            -1.6707441806793213,
            -0.08915847539901733,
            3.126497983932495,
            1.1538364887237549,
            -4.375668525695801,
            -2.8400235176086426,
            -0.9659978151321411,
            -3.518929958343506,
            -0.5309494733810425,
            -0.6431674361228943,
            -3.045236349105835,
            -0.4366786479949951,
            4.405954837799072,
            3.6756763458251953,
            -4.083218574523926,
            -2.091362714767456,
            5.743988990783691,
            -1.1519443988800049,
            -3.215986490249634,
            -0.7835193872451782,
            -2.9606399536132812,
            -3.213031768798828,
            -0.954819917678833,
            -3.5427589416503906,
            0.46091997623443604,
            -1.032617211341858,
            5.691548824310303,
            3.486447811126709,
            3.020169973373413,
            1.1000745296478271,
            -0.1912100464105606,
            3.09222674369812,
            5.895650863647461,
            5.0060834884643555,
            -1.2258567810058594,
            -2.1595892906188965,
            2.9384994506835938,
            3.17857027053833,
            -4.029216289520264,
            3.7722933292388916,
            -1.7177963256835938,
            3.0783634185791016,
            -6.09035587310791,
            -0.8806331157684326,
            0.9234827756881714,
            0.707533597946167,
            2.64961576461792,
            3.929270029067993,
            -1.7137465476989746,
            -1.307585597038269,
            -0.4352108836174011,
            3.5776915550231934,
            -3.1358084678649902,
            2.119365930557251,
            -1.1847643852233887,
            2.1975154876708984,
            2.784477949142456,
            -1.2908756732940674,
            -1.8723217248916626,
            -5.265963077545166,
            3.7769157886505127,
            -4.900169849395752,
            -3.409804344177246,
            -1.9670809507369995,
            1.3722784519195557,
            1.0362821817398071,
            -1.9787200689315796,
            -2.104750156402588,
            0.03356856107711792,
            0.2790444791316986,
            -2.025057315826416,
            2.5116825103759766,
            -2.021902084350586,
            -0.35974380373954773,
            -0.7137671709060669,
            0.3129248023033142,
            -1.559882640838623,
            -6.0175676345825195,
            -0.7886872887611389,
            1.2248897552490234,
            -0.22730669379234314,
            0.1292608082294464,
            -1.491288185119629,
            0.5311155319213867,
            0.15249808132648468,
            -1.0298856496810913,
            1.3060822486877441,
            1.8255764245986938,
            2.1361517906188965,
            -4.707865238189697,
            -4.836747646331787,
            0.12030182778835297,
            4.280012130737305,
            -4.001896858215332,
            -2.9902126789093018,
            4.469175338745117,
            1.5288262367248535,
            0.17485031485557556,
            1.2261766195297241,
            0.38563644886016846,
            0.9451943635940552,
            2.9285264015197754,
            5.327377796173096,
            -2.159841775894165,
            -0.11455559730529785,
            -0.7583838105201721,
            -4.172783851623535,
            2.9154791831970215,
            0.07084906101226807,
            -0.22999322414398193,
            -0.3664515018463135,
            -8.052962303161621,
            1.2042902708053589,
            -2.187354564666748,
            -3.117006778717041,
            5.085826396942139,
            3.754408359527588,
            2.351684808731079,
            -5.548657417297363,
            0.03557080030441284,
            -0.48589852452278137,
            1.5036734342575073,
            -4.972653388977051,
            0.8502352237701416,
            -0.9370088577270508,
            2.857090473175049,
            4.877786636352539,
            -0.25947821140289307,
            -0.48985475301742554,
            -0.1471019834280014,
            -2.47308611869812,
            -2.1544923782348633,
            1.0227469205856323,
            1.7109805345535278,
            1.233630895614624,
            0.9851322770118713,
            -0.8846028447151184,
            1.7090709209442139,
            0.6356847286224365,
            4.755316734313965,
            4.657592296600342,
            4.83903694152832,
            2.403134346008301,
            -3.280363082885742,
            -0.6311619877815247,
            -3.25239896774292,
            0.32987460494041443,
            2.762011766433716,
            -4.040830135345459,
            0.24295783042907715,
            1.8149683475494385,
            2.677338123321533,
            -2.062833309173584,
            0.2525731325149536,
            -4.058500289916992,
            3.5165271759033203,
            -4.809006690979004,
            -0.736823558807373,
            -2.3922314643859863,
            3.0875461101531982,
            1.8492969274520874,
            -1.6599981784820557,
            2.549233913421631,
            0.12239590287208557,
            -2.3029732704162598,
            -1.3801167011260986,
            -0.23198363184928894,
            -2.1247317790985107,
            -2.0610742568969727,
            4.8095831871032715,
            3.5732955932617188,
            0.2369658350944519,
            -0.1206926554441452,
            3.536426305770874,
            -1.683722734451294,
            -1.7105765342712402,
            -1.1773202419281006,
            5.621993064880371,
            3.2619614601135254,
            0.3156694173812866,
            1.7647502422332764,
            0.10716784000396729,
            3.586703300476074,
            0.9039978981018066,
            1.5390483140945435,
            2.343249797821045,
            1.0670393705368042,
            2.382425308227539,
            0.9151461720466614,
            -0.8512004613876343,
            -3.5833053588867188,
            -2.389627456665039,
            -0.681538462638855,
            -6.706880569458008,
            -0.08008313179016113,
            -3.8925082683563232,
            -4.662461757659912,
            3.7146260738372803,
            -2.799703598022461,
            0.24307309091091156,
            1.4745153188705444,
            0.5925966501235962,
            -0.8171541690826416,
            -3.905210018157959,
            1.5795353651046753,
            -3.2113261222839355,
            2.7855448722839355,
            -1.051950216293335,
            -0.7421767711639404,
            2.8374366760253906,
            2.386929512023926,
            2.987464189529419,
            4.686833381652832,
            1.078359603881836,
            -2.668778896331787,
            -0.5455695390701294,
            1.8103723526000977,
            3.163580894470215,
            -0.6920651197433472,
            0.2887762188911438,
            -1.3781074285507202,
            1.867525339126587,
            16.41164779663086,
            -0.6213926076889038,
            -2.7704873085021973,
            -0.558096706867218,
            0.35267066955566406,
            -4.425416469573975,
            -3.3660922050476074,
            3.13619327545166,
            1.8865852355957031,
            2.168328285217285,
            -2.924923896789551,
            -2.0498526096343994,
            0.25617653131484985,
            1.5097874402999878,
            -2.719287872314453,
            -4.380981922149658,
            -4.071186065673828,
            2.4157729148864746,
            -2.812664031982422,
            0.6895847916603088,
            -0.3597027063369751,
            3.4217348098754883,
            -1.3710683584213257,
            -1.4761472940444946,
            1.0619909763336182,
            5.319227695465088,
            1.9845117330551147,
            4.004209995269775,
            -0.5299011468887329,
            2.7174758911132812,
            4.455636501312256,
            0.5523670315742493,
            -1.6538810729980469,
            1.59661066532135,
            -2.5336670875549316,
            5.685632228851318,
            2.628079652786255,
            -2.624967098236084,
            3.4971773624420166,
            0.9845445156097412,
            -0.7955442070960999,
            2.243694543838501,
            -4.201009273529053,
            2.3609344959259033,
            -1.4018360376358032,
            4.164076328277588,
            2.1236255168914795,
            -0.4008648991584778,
            -1.8467097282409668,
            4.608226299285889,
            1.0393173694610596,
            -4.8006978034973145,
            -2.442192316055298,
            -0.3030139207839966,
            2.312797784805298,
            5.120767116546631,
            -1.873405933380127,
            -2.8137879371643066,
            3.8753161430358887,
            -2.88041090965271,
            2.4732658863067627,
            0.1759081780910492,
            -1.3704214096069336,
            -4.501040935516357,
            -2.6595890522003174,
            -2.6779160499572754,
            -4.300874710083008,
            2.643012046813965,
            3.0010623931884766,
            0.2615203857421875,
            3.6665902137756348,
            1.6998766660690308,
            -1.5031291246414185,
            -3.0563852787017822,
            -2.8276290893554688,
            -2.1807405948638916,
            2.962867259979248,
            -3.076167583465576,
            -0.6098340749740601,
            7.33626651763916,
            -5.240703582763672,
            1.0498740673065186,
            -2.4395670890808105,
            0.32152828574180603,
            3.5991432666778564,
            -2.131415605545044,
            4.693592548370361,
            2.285844564437866,
            -2.198482036590576,
            5.097041130065918,
            -2.4422245025634766,
            -1.8795902729034424,
            4.678266525268555,
            4.828164100646973,
            1.9411484003067017,
            -4.852825164794922,
            -1.6230568885803223,
            -2.4090821743011475,
            -3.5964059829711914,
            -1.8538941144943237,
            8.5215425491333,
            6.142332553863525,
            0.7151436805725098,
            -4.8675642013549805,
            -0.21621081233024597,
            0.6974581480026245,
            -1.0932786464691162,
            -5.189061164855957,
            -0.8518924117088318,
            -2.1599414348602295,
            4.322734832763672,
            -5.095822811126709,
            -5.256843090057373,
            1.7751083374023438,
            2.5825939178466797,
            0.5070049166679382,
            -1.83024263381958,
            4.2207560539245605,
            -1.2018780708312988,
            4.046983242034912,
            -0.12117744982242584,
            -1.3360095024108887,
            -2.326061725616455,
            -3.6504693031311035,
            -1.7710566520690918,
            2.094909191131592,
            4.210788726806641,
            0.22102093696594238,
            -0.5726728439331055,
            -1.251121997833252,
            1.9285870790481567,
            -1.5738375186920166,
            2.7909514904022217,
            1.6664146184921265,
            -1.1050825119018555,
            -2.292644739151001,
            0.47396135330200195,
            0.202513188123703,
            -2.346637725830078,
            5.619340896606445,
            5.20883846282959,
            -2.5380377769470215,
            -2.5003559589385986,
            9.745752334594727,
            1.411858081817627,
            -0.6301323771476746,
            -1.8240015506744385,
            -3.6166632175445557,
            -1.9213507175445557,
            -1.9793301820755005,
            0.4450301229953766,
            -0.7251042127609253,
            4.215580940246582,
            -0.5633581280708313,
            2.0049171447753906,
            -0.16880622506141663
        ]
    },
    "authors": [
        {
            "authorId": "2109586102",
            "name": "Sehoon Kim"
        },
        {
            "authorId": "11379939",
            "name": "K. Mangalam"
        },
        {
            "authorId": "2244770235",
            "name": "Jitendra Malik"
        },
        {
            "authorId": "1717098",
            "name": "Michael W. Mahoney"
        },
        {
            "authorId": "10419477",
            "name": "A. Gholami"
        },
        {
            "authorId": "1732330",
            "name": "K. Keutzer"
        }
    ],
    "references": [
        {
            "paperId": "0a6906bd6f026d3da3031c641ed03081bd0b574e",
            "title": "Full Stack Optimization of Transformer Inference: a Survey"
        },
        {
            "paperId": "a1f8082505c7e90b0a033e1b9da0a97d67aad66c",
            "title": "Accelerating Large Language Model Decoding with Speculative Sampling"
        },
        {
            "paperId": "a7ca1bce0af7fe4703f5c3296db2dcc8dc112f20",
            "title": "FiDO: Fusion-in-Decoder optimized for stronger performance and faster inference"
        },
        {
            "paperId": "379e42895f6d40ab9e9559609f505aba89145a5d",
            "title": "Efficiently Scaling Transformer Inference"
        },
        {
            "paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e",
            "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"
        },
        {
            "paperId": "4be7d1524edb0137599a5cc95f72844b85a52fe1",
            "title": "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale"
        },
        {
            "paperId": "2ef60a4ea4ea53056be811ff55679eb59fb4b586",
            "title": "Confident Adaptive Language Modeling"
        },
        {
            "paperId": "64a8a7eb8360f4003af85c2c8a3bf245fb2f94ae",
            "title": "Extreme Compression for Pre-trained Transformers Made Simple and Efficient"
        },
        {
            "paperId": "e03609f2587f690867e7ea0bedaf0db25282c548",
            "title": "ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers"
        },
        {
            "paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221",
            "title": "OPT: Open Pre-trained Transformer Language Models"
        },
        {
            "paperId": "860552613fa7529553c4cd934b98be52c57e2528",
            "title": "Autoencoding Language Model Based Ensemble Learning for Commonsense Validation and Explanation"
        },
        {
            "paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb",
            "title": "PaLM: Scaling Language Modeling with Pathways"
        },
        {
            "paperId": "fb145e1e49d3269d8223c7710e22b45438613ff0",
            "title": "A Fast Post-Training Pruning Framework for Transformers"
        },
        {
            "paperId": "8342b592fe238f3d230e4959b06fd10153c45db1",
            "title": "Training Compute-Optimal Large Language Models"
        },
        {
            "paperId": "6da9a81b75e7ad02867860753d1aa276673a3a77",
            "title": "The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models"
        },
        {
            "paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19",
            "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"
        },
        {
            "paperId": "b3848d32f7294ec708627897833c4097eb4d8778",
            "title": "LaMDA: Language Models for Dialog Applications"
        },
        {
            "paperId": "df36065bbf5041cb06d066591a87e813cb7ade09",
            "title": "Ensemble Transformer for Efficient and Accurate Ranking Tasks: an Application to Question Answering Systems"
        },
        {
            "paperId": "80d0116d77beeded0c23cf48946d9d10d4faee14",
            "title": "GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"
        },
        {
            "paperId": "4a8964ea0de47010fb458021b68fa3ef5c4b77b2",
            "title": "Primer: Searching for Efficient Transformers for Language Modeling"
        },
        {
            "paperId": "ef18db2a18ac61e72783a613328842ce86ef00bf",
            "title": "AutoTinyBERT: Automatic Hyper-parameter Optimization for Efficient Pre-trained Language Models"
        },
        {
            "paperId": "dd0a27aa2285bc64798fa76944400ab6d9ce3025",
            "title": "NAS-BERT: Task-Agnostic and Adaptive-Size BERT Compression with Neural Architecture Search"
        },
        {
            "paperId": "7b8f3f65a98340d6e5ab94bd9a4ccb8f75704fd8",
            "title": "I-BERT: Integer-only BERT Quantization"
        },
        {
            "paperId": "74276a37bfa50f90dfae37f767b2b67784bd402a",
            "title": "mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer"
        },
        {
            "paperId": "0bff8d9f3685e09407f0296e7aa3486f1a48a949",
            "title": "QiaoNing at SemEval-2020 Task 4: Commonsense Validation and Explanation System Based on Ensemble of Language Model"
        },
        {
            "paperId": "9e96657d76ce74173b658cf933b4bd74c13f8b8d",
            "title": "Jointly Masked Sequence-to-Sequence Model for Non-Autoregressive Neural Machine Translation"
        },
        {
            "paperId": "eb1602ecba96beadeb7d2f05e1b57fa6b339fc69",
            "title": "SqueezeBERT: What can computer vision teach NLP about efficient neural networks?"
        },
        {
            "paperId": "ac6535d096fc79dde2d9ce0329e0626b79ede7f0",
            "title": "Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine Translation"
        },
        {
            "paperId": "0bdccacaf89bc45c3d9a8a8ac1c4e60a741d5b48",
            "title": "DynE: Dynamic Ensemble Decoding for Multi-Document Summarization"
        },
        {
            "paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
            "title": "Linformer: Self-Attention with Linear Complexity"
        },
        {
            "paperId": "ef8d788a904ed66bd8e30ffa69bc3ea1fe57dda7",
            "title": "HAT: Hardware-Aware Transformers for Efficient Natural Language Processing"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "66f0f35fc78bdf2af9de46093d49a428970cde2e",
            "title": "Movement Pruning: Adaptive Sparsity by Fine-Tuning"
        },
        {
            "paperId": "1b0c8b26affd13e10ace5770e85478d60dcc368e",
            "title": "GOBO: Quantizing Attention-Based NLP Models for Low Latency and Energy Efficient Inference"
        },
        {
            "paperId": "8af925f4edf45131b5b6fed8aa655089d58692fa",
            "title": "Lite Transformer with Long-Short Range Attention"
        },
        {
            "paperId": "2573af4e13d9a5dddb257d22cd38a600528d9a8b",
            "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"
        },
        {
            "paperId": "c6c734e16f66fbfcefac7625cc64599e83292c1e",
            "title": "MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers"
        },
        {
            "paperId": "7dc21b6c7c02708e4de6c6c260b4439b46fbd086",
            "title": "Improving BERT Fine-Tuning via Self-Ensemble and Self-Distillation"
        },
        {
            "paperId": "54d4ff8d536b292149a4fa017c22349cf4e54ce4",
            "title": "AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural Architecture Search"
        },
        {
            "paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500",
            "title": "Reformer: The Efficient Transformer"
        },
        {
            "paperId": "775f6da764a134e7bd0e361c27f7d7411afef4d3",
            "title": "Minimizing the Bag-of-Ngrams Difference for Non-Autoregressive Neural Machine Translation"
        },
        {
            "paperId": "1e5b826ddf0754f6e93234ba1260bd939c255e7f",
            "title": "Understanding Knowledge Distillation in Non-autoregressive Machine Translation"
        },
        {
            "paperId": "fe2f254923c72958fb65e025adf38ec6403dd6f8",
            "title": "Fast Structured Decoding for Sequence Models"
        },
        {
            "paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
        },
        {
            "paperId": "4585611042d2be0d997ee135e3fe219d668db9ec",
            "title": "Depth-Adaptive Transformer"
        },
        {
            "paperId": "ce106590145e89ea4b621c99665862967ccf5dac",
            "title": "Q8BERT: Quantized 8Bit BERT"
        },
        {
            "paperId": "c95383f251a62c63217586059c67f63507c3e839",
            "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"
        },
        {
            "paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc",
            "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"
        },
        {
            "paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b",
            "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"
        },
        {
            "paperId": "f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1",
            "title": "Reducing Transformer Depth on Demand with Structured Dropout"
        },
        {
            "paperId": "0cbf97173391b0430140117027edcaf1a37968c7",
            "title": "TinyBERT: Distilling BERT for Natural Language Understanding"
        },
        {
            "paperId": "5b446648504afeecf7c73028aa02c2da16db6224",
            "title": "Hint-Based Training for Non-Autoregressive Machine Translation"
        },
        {
            "paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d",
            "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"
        },
        {
            "paperId": "4754993282f677e1b43407518cc7bfc665a8a37e",
            "title": "Facebook FAIR\u2019s WMT19 News Translation Task Submission"
        },
        {
            "paperId": "df9e4fbe7f7a8d3a1d4804b2065308a24b8490ae",
            "title": "Imitation Learning for Non-Autoregressive Neural Machine Translation"
        },
        {
            "paperId": "f87de21b46683b5743c4d82af3c9cb8bbcd26f21",
            "title": "Levenshtein Transformer"
        },
        {
            "paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583",
            "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"
        },
        {
            "paperId": "b03c7ff961822183bab66b2e594415e585d3fd09",
            "title": "Are Sixteen Heads Really Better than One?"
        },
        {
            "paperId": "5efadc9019ce3378a0eb6c8f939cdde6c8918b1e",
            "title": "Mask-Predict: Parallel Decoding of Conditional Masked Language Models"
        },
        {
            "paperId": "a08293b2c9c5bcddb023cc7eb3354d4d86bfae89",
            "title": "Distilling Task-Specific Knowledge from BERT into Simple Neural Networks"
        },
        {
            "paperId": "26384278cf5d575fc32cb92c303fb648fa0d5217",
            "title": "The State of Sparsity in Deep Neural Networks"
        },
        {
            "paperId": "665480b3d3a0b91b361d1742f2c54407b49f1e4e",
            "title": "Non-Autoregressive Machine Translation with Auxiliary Regularization"
        },
        {
            "paperId": "58d34a4fb936ffe95917d8fb4016ff5e3520429a",
            "title": "Insertion Transformer: Flexible Sequence Generation via Insertion Operations"
        },
        {
            "paperId": "a9a4a12900d0ac1063505bb28d5e0180d78a39a0",
            "title": "Non-Monotonic Sequential Text Generation"
        },
        {
            "paperId": "16c844fd4d97f3c6eb38b0d6527c87d184efedc3",
            "title": "The Evolved Transformer"
        },
        {
            "paperId": "305b2cf37e5dece81e95c92883d5a6e28ac93b22",
            "title": "Don\u2019t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"
        },
        {
            "paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"
        },
        {
            "paperId": "54a13bcc9613dcaa76fb25fbe96572f376cfcca9",
            "title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost"
        },
        {
            "paperId": "9c5c89199114858eafbe50b46d77d38ffd03b28a",
            "title": "Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement"
        },
        {
            "paperId": "15e81c8d1c21f9e928c72721ac46d458f3341454",
            "title": "Non-Autoregressive Neural Machine Translation"
        },
        {
            "paperId": "b36a5bb1707bb9c70025294b3a310138aae8327a",
            "title": "Automatic differentiation in PyTorch"
        },
        {
            "paperId": "d65ce2b8300541414bfe51d03906fca72e93523c",
            "title": "On Calibration of Modern Neural Networks"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "ff7bcaa4556cb13fc7bf03e477172493546172cd",
            "title": "What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?"
        },
        {
            "paperId": "6ff2a434578ff2746b9283e45abf296887f48a2d",
            "title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks"
        },
        {
            "paperId": "efbd381493bb9636f489b965a2034d529cd56bcd",
            "title": "Pointer Sentinel Mixture Models"
        },
        {
            "paperId": "d1505c6123c102e53eb19dff312cb25cea840b72",
            "title": "Teaching Machines to Read and Comprehend"
        },
        {
            "paperId": "f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6",
            "title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning"
        },
        {
            "paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19",
            "title": "Distilling the Knowledge in a Neural Network"
        },
        {
            "paperId": "5ec85a0d88adcc4344bb5cc81b0d1aef9bcd8dcc",
            "title": "Findings of the 2014 Workshop on Statistical Machine Translation"
        },
        {
            "paperId": "092217c2267f6e0673590aa151d811e579ff7760",
            "title": "Roofline: an insightful visual performance model for multicore architectures"
        },
        {
            "paperId": "5839ad026ee43f3b72493c416dddb4203791714d",
            "title": "Translation"
        },
        {
            "paperId": "b8b45b14df9029562b8995c6ab7fd90a8810f312",
            "title": "GPT3.int8(): 8-bit Matrix Multiplication for Transformers at Scale"
        },
        {
            "paperId": "9405cc0d6169988371b2755e573cc28650d14dfe",
            "title": "Language Models are Unsupervised Multitask Learners"
        },
        {
            "paperId": "cb0ab255c4079e2082ba6e3a807529527d96687c",
            "title": "Overview of the IWSLT 2017 Evaluation Campaign"
        }
    ]
}