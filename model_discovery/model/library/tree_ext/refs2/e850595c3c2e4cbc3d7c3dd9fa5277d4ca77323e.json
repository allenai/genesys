{
    "paperId": "e850595c3c2e4cbc3d7c3dd9fa5277d4ca77323e",
    "externalIds": {
        "MAG": "2250385622",
        "DBLP": "conf/emnlp/LeZ15",
        "ACL": "D15-1137",
        "DOI": "10.18653/v1/D15-1137",
        "CorpusId": 15762346
    },
    "title": "The Forest Convolutional Network: Compositional Distributional Semantics with a Neural Chart and without Binarization",
    "abstract": "According to the principle of compositionality, the meaning of a sentence is computed from the meaning of its parts and the way they are syntactically combined. In practice, however, the syntactic structure is computed by automatic parsers which are far-from-perfect and not tuned to the specifics of the task. Current recursive neural network (RNN) approaches for computing sentence meaning therefore run into a number of practical difficulties, including the need to carefully select a parser appropriate for the task, deciding how and to what extent syntactic context modifies the semantic composition function, as well as on how to transform parse trees to conform to the branching settings (typically, binary branching) of the RNN. This paper introduces a new model, the Forest Convolutional Network, that avoids all of these challenges, by taking a parse forest as input, rather than a single tree, and by allowing arbitrary branching factors. We report improvements over the state-of-the-art in sentiment analysis and question classification.",
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2015,
    "referenceCount": 32,
    "citationCount": 37,
    "influentialCitationCount": 0,
    "openAccessPdf": {
        "url": "https://www.aclweb.org/anthology/D15-1137.pdf",
        "status": "HYBRID"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A new model, the Forest Convolutional Network, is introduced that avoids all of the challenges of current recursive neural network approaches for computing sentence meaning, by taking a parse forest as input, rather than a single tree, and by allowing arbitrary branching factors."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "144106794",
            "name": "Phong Le"
        },
        {
            "authorId": "1787819",
            "name": "Willem H. Zuidema"
        }
    ],
    "references": [
        {
            "paperId": "57e562b46338f176e3b20c2dd0b66f17dfbef9e8",
            "title": "Dependency-based Convolutional Neural Networks for Sentence Embedding"
        },
        {
            "paperId": "72fe521bd4eff2d33ddf76302ccca7745ad19e57",
            "title": "A Re-ranking Model for Dependency Parser with Recursive Convolutional Neural Network"
        },
        {
            "paperId": "1492ddfd4f4b152b83f11db8c9ecdfd0d2543294",
            "title": "Compositional Distributional Semantics with Long Short Term Memory"
        },
        {
            "paperId": "32de44f01a96d4473d21099d15e25bc2b9f08e2f",
            "title": "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks"
        },
        {
            "paperId": "60dda7f5efd67758bde1ee7f45e6d3ef86445495",
            "title": "Deep Recursive Neural Networks for Compositionality in Language"
        },
        {
            "paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
            "title": "GloVe: Global Vectors for Word Representation"
        },
        {
            "paperId": "2672f1ab4e31a6cbdfc77563a81318aec27cdd04",
            "title": "The Inside-Outside Recursive Neural Network model for Dependency Parsing"
        },
        {
            "paperId": "1eb09fecd75eb27825dce4f964b97f4f5cc399d7",
            "title": "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches"
        },
        {
            "paperId": "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba",
            "title": "Convolutional Neural Networks for Sentence Classification"
        },
        {
            "paperId": "f3de86aeb442216a8391befcacb49e58b478f512",
            "title": "Distributed Representations of Sentences and Documents"
        },
        {
            "paperId": "0ca7d208ff8d81377e0eaa9723820aeae7a7322d",
            "title": "Grounded Compositional Semantics for Finding and Describing Images with Sentences"
        },
        {
            "paperId": "27725a2d2a8cee9bf9fffc6c2167017103aba0fa",
            "title": "A Convolutional Neural Network for Modelling Sentences"
        },
        {
            "paperId": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
        },
        {
            "paperId": "0abb49fe138e8fb7332c26b148a48d0db39724fc",
            "title": "Stochastic Pooling for Regularization of Deep Convolutional Neural Networks"
        },
        {
            "paperId": "ae5e6c6f5513613a161b2c85563f9708bf2e9178",
            "title": "Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection"
        },
        {
            "paperId": "bc1022b031dc6c7019696492e8116598097a8c12",
            "title": "Natural Language Processing (Almost) from Scratch"
        },
        {
            "paperId": "413c1142de9d91804d6d11c67ff3fed59c9fc279",
            "title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization"
        },
        {
            "paperId": "044b239c207a9decc77a7c2eb6de1f95b92c9fc3",
            "title": "From symbolic to sub-symbolic information in question classification"
        },
        {
            "paperId": "311a30c808ee16e13e8d1a9ba5c12213de5ddf60",
            "title": "Dynamic Programming for Linear-Time Incremental Parsing"
        },
        {
            "paperId": "94a9af119df61f501980cf095700f35c2a7762a3",
            "title": "Question Classification using Head Words and their Hypernyms"
        },
        {
            "paperId": "1ba700aec9f23ecb76622f2202badf25f6ad896e",
            "title": "Forest Reranking: Discriminative Parsing with Non-Local Features"
        },
        {
            "paperId": "0ecb33ced5b0976accdf13817151f80568b6fdcb",
            "title": "Coarse-to-Fine n-Best Parsing and MaxEnt Discriminative Reranking"
        },
        {
            "paperId": "a600850ac0120cb09a0b7de7da80bb6a7a76de06",
            "title": "Accurate Unlexicalized Parsing"
        },
        {
            "paperId": "2c8ac3e1f0edeed1fbd76813e61efdc384c319c7",
            "title": "Learning Question Classifiers"
        },
        {
            "paperId": "30da8ecce8b3ebc3e9344a79e5c2f8dc4c423bd2",
            "title": "Recognition and Parsing of Context-Free Languages in Time n^3"
        },
        {
            "paperId": "de93f011bd95a7ba720a2bfe588d5188bd4351c4",
            "title": "Inside-Outside Semantics : A Framework for Neural Models of Semantic Composition"
        },
        {
            "paperId": "81b3b3fe994a9eda6d3f9d2149aa4492d1933975",
            "title": "Learning Continuous Phrase Representations and Syntactic Parsing with Recursive Neural Networks"
        },
        {
            "paperId": "5420a258b488e9b195715497392d61da3edc2d82",
            "title": "Smoothing a probablistic lexicon via syntactic transformations"
        },
        {
            "paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "title": "Gradient-based learning applied to document recognition"
        },
        {
            "paperId": null,
            "title": "Learning task-dependent distributed representations by backpropagation through structure"
        },
        {
            "paperId": null,
            "title": "Deep Learning and Unsupervised Feature Learning Workshop"
        },
        {
            "paperId": null,
            "title": "how to deal with different branching factors of nodes in the relevant syntactic trees"
        }
    ]
}