{
    "paperId": "3c0db904b9cc6f2f44eeb7c14ec29fcb900c1972",
    "externalIds": {
        "DBLP": "conf/ic3k/TsakalosH18",
        "DOI": "10.5220/0006894201470152",
        "CorpusId": 52901042
    },
    "title": "Sentiment Classification using N-ary Tree-Structured Gated Recurrent Unit Networks",
    "abstract": "Recurrent Neural Networks(RNN) is a good way of modeling sequences. However this type of Artificial Neural Networks(ANN) has two major drawbacks, it is not good at capturing long range connections and it is not robust at the vanishing gradient problem(Hochreiter, 1998). Luckily, there have been invented RNNs that can deal with these problems. Namely, Gated Recurrent Units(GRU) networks(Chung et al., 2014)(G\u00fcl\u00e7ehre et al., 2013) and Long Short Term Memory(LSTM) networks(Hochreiter and Schmidhuber, 1997). Many problems in Natural Language Processing can be approximated with a sequence model. But, it is known that the syntactic rules of natural language have a recursive structure(Socher et al., 2011b). Therefore a Recursive Neural Network(Goller and Kuchler, 1996) can be a great alternative. Kai Sheng Tai (Tai et al., 2015) has come up with an architecture that gives the good properties of LSTM in a Recursive Neural Network. In this report, we will present another alternative of Recursive Neural Networks combined with GRU which performs very similar on binary and fine-grained Sentiment Classification (on Stanford Sentiment Treebank dataset) with N-ary Tree-Structured LSTM but is trained faster.",
    "venue": "International Conference on Knowledge Discovery and Information Retrieval",
    "year": 2018,
    "referenceCount": 26,
    "citationCount": 1,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Kai Sheng Tai (Tai et al., 2015) has come up with an architecture that gives the good properties of LSTM in a Recursive Neural Network combined with GRU which performs very similar on binary and fine-grained Sentiment Classification with N-ary Tree-Structured L STM but is trained faster."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "81129579",
            "name": "Vasileios Tsakalos"
        },
        {
            "authorId": "39803194",
            "name": "R. Henriques"
        }
    ],
    "references": [
        {
            "paperId": "fb32191ec07ba4d7badc76ca428c816995b5785a",
            "title": "Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access"
        },
        {
            "paperId": "230579a14d54ae00073d6c3522ffcef313320be9",
            "title": "Compression of Neural Machine Translation Models via Pruning"
        },
        {
            "paperId": "993c55eef970c6a11ec367dbb1bf1f0c1d5d72a6",
            "title": "Inverting Convolutional Networks with Convolutional Networks"
        },
        {
            "paperId": "32de44f01a96d4473d21099d15e25bc2b9f08e2f",
            "title": "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks"
        },
        {
            "paperId": "ac3ee98020251797c2b401e1389461df88e52e62",
            "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling"
        },
        {
            "paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
            "title": "GloVe: Global Vectors for Word Representation"
        },
        {
            "paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "title": "Sequence to Sequence Learning with Neural Networks"
        },
        {
            "paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "title": "Neural Machine Translation by Jointly Learning to Align and Translate"
        },
        {
            "paperId": "4ea80c206b8ad73a6d320c9d8ed0321d84fe6d85",
            "title": "Recursive Neural Networks for Learning Logical Semantics"
        },
        {
            "paperId": "3d1d42c9435b419ac928ebf7bcf4c86a460d6ef4",
            "title": "Semantic Parsing via Paraphrasing"
        },
        {
            "paperId": "1149888d75af4ed5dffc25731b875651c3ccdeb2",
            "title": "Hybrid speech recognition with Deep Bidirectional LSTM"
        },
        {
            "paperId": "6c902b2076a948ad994a542bb9c93e1a6513fc40",
            "title": "Learned-norm pooling for deep neural networks"
        },
        {
            "paperId": "87f40e6f3022adbc1f1905e3e506abad05a9964f",
            "title": "Distributed Representations of Words and Phrases and their Compositionality"
        },
        {
            "paperId": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
        },
        {
            "paperId": "53ab89807caead278d3deb7b6a4180b277d3cb77",
            "title": "Better Word Representations with Recursive Neural Networks for Morphology"
        },
        {
            "paperId": "f6b51c8753a871dc94ff32152c00c01e94f90f09",
            "title": "Efficient Estimation of Word Representations in Vector Space"
        },
        {
            "paperId": "84b520a8d6de79f62bb095b565d077e95bfb6f5b",
            "title": "POMDP-Based Statistical Spoken Dialog Systems: A Review"
        },
        {
            "paperId": "9c0ddf74f87d154db88d79c640578c1610451eec",
            "title": "Parsing Natural Scenes and Natural Language with Recursive Neural Networks"
        },
        {
            "paperId": "413c1142de9d91804d6d11c67ff3fed59c9fc279",
            "title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization"
        },
        {
            "paperId": "5d6e6ecb0150cd2681076297d94d39ced0db0c3a",
            "title": "Multilingual Dependency Analysis with a Two-Stage Discriminative Parser"
        },
        {
            "paperId": "0ecb33ced5b0976accdf13817151f80568b6fdcb",
            "title": "Coarse-to-Fine n-Best Parsing and MaxEnt Discriminative Reranking"
        },
        {
            "paperId": "9e8c0be2f9b7717a4220b45bffdb68ab6936ac1a",
            "title": "Semantics of linear/modal lambda calculus"
        },
        {
            "paperId": "e9fac1091d9a1646314b1b91e58f40dae3a750cd",
            "title": "The Vanishing Gradient Problem During Learning Recurrent Neural Nets and Problem Solutions"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "a14045a751f5d8ed387c8630a86a3a2861b90643",
            "title": "A Fast and Accurate Dependency Parser using Neural Networks"
        },
        {
            "paperId": null,
            "title": "Learning taskdependent distributed representations by backpropagation through structure"
        }
    ]
}