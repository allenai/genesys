{
    "paperId": "514e7fb769950dbe96eb519c88ca17e04dc829f6",
    "externalIds": {
        "DBLP": "conf/acl/EbrahimiRLD18",
        "MAG": "2799194071",
        "ACL": "P18-2006",
        "DOI": "10.18653/v1/P18-2006",
        "CorpusId": 21698802
    },
    "title": "HotFlip: White-Box Adversarial Examples for Text Classification",
    "abstract": "We propose an efficient method to generate white-box adversarial examples to trick a character-level neural classifier. We find that only a few manipulations are needed to greatly decrease the accuracy. Our method relies on an atomic flip operation, which swaps one token for another, based on the gradients of the one-hot input vectors. Due to efficiency of our method, we can perform adversarial training which makes the model more robust to attacks at test time. With the use of a few semantics-preserving constraints, we demonstrate that HotFlip can be adapted to attack a word-level classifier as well.",
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2017,
    "referenceCount": 25,
    "citationCount": 926,
    "influentialCitationCount": 125,
    "openAccessPdf": {
        "url": "https://www.aclweb.org/anthology/P18-2006.pdf",
        "status": "HYBRID"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "An efficient method to generate white-box adversarial examples to trick a character-level neural classifier based on an atomic flip operation, which swaps one token for another, based on the gradients of the one-hot input vectors is proposed."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "39043512",
            "name": "J. Ebrahimi"
        },
        {
            "authorId": "36290866",
            "name": "Anyi Rao"
        },
        {
            "authorId": "3021654",
            "name": "Daniel Lowd"
        },
        {
            "authorId": "1721158",
            "name": "D. Dou"
        }
    ],
    "references": [
        {
            "paperId": "2b110fce160468eb179b6c43ea27e098757a56dd",
            "title": "Adversarial Example Generation with Syntactically Controlled Paraphrase Networks"
        },
        {
            "paperId": "765bdcf27ebc1eb03a14f1e47aefa4dda1e03073",
            "title": "Synthetic and Natural Noise Both Break Neural Machine Translation"
        },
        {
            "paperId": "3502b5ef1afb16f76bcae33db17179195bbcdaae",
            "title": "Generating Natural Adversarial Examples"
        },
        {
            "paperId": "ffb949d3493c3b2f3c9acf9c75cb03938933ddf0",
            "title": "Adversarial Examples for Evaluating Reading Comprehension Systems"
        },
        {
            "paperId": "7aa38b85fa8cba64d6a4010543f6695dbf5f1386",
            "title": "Towards Deep Learning Models Resistant to Adversarial Attacks"
        },
        {
            "paperId": "b663e16f3b466278c0ee24f1780935755c6dd436",
            "title": "Deceiving Google's Perspective API Built for Detecting Toxic Comments"
        },
        {
            "paperId": "57567039998db7ef670c6ee6837301402d72c078",
            "title": "Learning Robust Representations of Text"
        },
        {
            "paperId": "df40ce107a71b770c9d0354b78fdd8989da80d2f",
            "title": "Towards Evaluating the Robustness of Neural Networks"
        },
        {
            "paperId": "f797fd44b9ddd5845611eb7a705ca9464a8819d1",
            "title": "Very Deep Convolutional Networks for Text Classification"
        },
        {
            "paperId": "2cd55ded95d5d13430edfa223ba591b514ebe8a5",
            "title": "Adversarial Training Methods for Semi-Supervised Text Classification"
        },
        {
            "paperId": "1439e05971a053c2368e6dee6d484b43c833d43c",
            "title": "Crafting adversarial input sequences for recurrent neural networks"
        },
        {
            "paperId": "4d070993cb75407b285e14cb8aac0077624ef4d9",
            "title": "Character-based Neural Machine Translation"
        },
        {
            "paperId": "819167ace2f0caae7745d2f25a803979be5fbfae",
            "title": "The Limitations of Deep Learning in Adversarial Settings"
        },
        {
            "paperId": "891ce1687e2befddd19f54e4eef1d3f39c8dbaf7",
            "title": "Character-Aware Neural Language Models"
        },
        {
            "paperId": "93499a7c7f699b6630a86fad964536f9423bb6d0",
            "title": "Effective Approaches to Attention-based Neural Machine Translation"
        },
        {
            "paperId": "bee044c8e8903fb67523c1f8c105ab4718600cdb",
            "title": "Explaining and Harnessing Adversarial Examples"
        },
        {
            "paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "title": "Neural Machine Translation by Jointly Learning to Align and Translate"
        },
        {
            "paperId": "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba",
            "title": "Convolutional Neural Networks for Sentence Classification"
        },
        {
            "paperId": "d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad",
            "title": "Intriguing properties of neural networks"
        },
        {
            "paperId": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
        },
        {
            "paperId": "835ec26481c12e4b0961ca3f77b84b7b23e9bf7a",
            "title": "The Significance of Letter Position in Word Recognition"
        },
        {
            "paperId": "6f006a3895dd8fb24f83235a67f2fe72418aa800",
            "title": "Adversarial learning"
        },
        {
            "paperId": "d94f56e7ef07b6e785b830e41da30c257b9a6ece",
            "title": "Adversarial classification"
        },
        {
            "paperId": "d7da009f457917aa381619facfa5ffae9329a6e9",
            "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"
        },
        {
            "paperId": "34f25a8704614163c4095b3ee2fc969b60de4698",
            "title": "Dropout: a simple way to prevent neural networks from overfitting"
        }
    ]
}