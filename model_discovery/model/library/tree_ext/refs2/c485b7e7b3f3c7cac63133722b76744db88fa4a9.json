{
    "paperId": "c485b7e7b3f3c7cac63133722b76744db88fa4a9",
    "externalIds": {
        "DBLP": "journals/tacl/TengZ17",
        "ACL": "Q17-1012",
        "MAG": "2728982475",
        "DOI": "10.1162/tacl_a_00053",
        "CorpusId": 5135260
    },
    "title": "Head-Lexicalized Bidirectional Tree LSTMs",
    "abstract": "Sequential LSTMs have been extended to model tree structures, giving competitive results for a number of tasks. Existing methods model constituent trees by bottom-up combinations of constituent nodes, making direct use of input word information only for leaf nodes. This is different from sequential LSTMs, which contain references to input words for each node. In this paper, we propose a method for automatic head-lexicalization for tree-structure LSTMs, propagating head words from leaf nodes to every constituent node. In addition, enabled by head lexicalization, we build a tree LSTM in the top-down direction, which corresponds to bidirectional sequential LSTMs in structure. Experiments show that both extensions give better representations of tree structures. Our final model gives the best results on the Stanford Sentiment Treebank and highly competitive results on the TREC question type classification task.",
    "venue": "Transactions of the Association for Computational Linguistics",
    "year": 2017,
    "referenceCount": 47,
    "citationCount": 31,
    "influentialCitationCount": 4,
    "openAccessPdf": {
        "url": "http://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00053",
        "status": "GOLD"
    },
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper proposes a method for automatic head-lexicalization for tree-structure LSTMs, propagating head words from leaf nodes to every constituent node, and builds a tree LSTM in the top-down direction, which corresponds to bidirectional sequential LSTm in structure."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "2272668",
            "name": "Zhiyang Teng"
        },
        {
            "authorId": null,
            "name": "Yue Zhang"
        }
    ],
    "references": [
        {
            "paperId": "fce10a1a9727cbda33d44b62409e303f1009417a",
            "title": "What Do Recurrent Neural Network Grammars Learn About Syntax?"
        },
        {
            "paperId": "39f1b108687f643015f96a0c800585a44621f99c",
            "title": "Parsing as Language Modeling"
        },
        {
            "paperId": "f1ee33068dfff064ef4018422a7fb1c6d6710711",
            "title": "Context-Sensitive Lexicon Features for Neural Sentiment Analysis"
        },
        {
            "paperId": "7345843e87c81e24e42264859b214d26042f8d51",
            "title": "Recurrent Neural Network Grammars"
        },
        {
            "paperId": "3899f87a2031f3434f89beb68c11a1ca6428328a",
            "title": "End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures"
        },
        {
            "paperId": "10f62af29c3fc5e2572baddca559ffbfd6be8787",
            "title": "A C-LSTM Neural Network for Text Classification"
        },
        {
            "paperId": "492f57ee9ceb61fb5a47ad7aebfec1121887a175",
            "title": "Gated Graph Sequence Neural Networks"
        },
        {
            "paperId": "e5f0762b9cfd07f88608f5502ed4467a8b5546cb",
            "title": "Top-down Tree Long Short-Term Memory Networks"
        },
        {
            "paperId": "9e975e86fff32a9f901b2035688970fcd0fca2a0",
            "title": "Sentence Modeling with Gated Recursive Neural Network"
        },
        {
            "paperId": "5b791cd374c7109693aaddee2c12d659ae4e3ec0",
            "title": "Grid Long Short-Term Memory"
        },
        {
            "paperId": "1f600f213dbbd70f06093438855f39022957b4bf",
            "title": "Long Short-Term Memory Over Recursive Structures"
        },
        {
            "paperId": "f267934e9de60c5badfa9d3f28918e67ae7a2bf4",
            "title": "Generative Image Modeling Using Spatial LSTMs"
        },
        {
            "paperId": "b36b7f7c68923d14ba2859b5d28a1124616a8c89",
            "title": "Transition-Based Dependency Parsing with Stack Long Short-Term Memory"
        },
        {
            "paperId": "a7976c2bacfbb194ddbe7fd10c2e50a545cf4081",
            "title": "LSTM: A Search Space Odyssey"
        },
        {
            "paperId": "1492ddfd4f4b152b83f11db8c9ecdfd0d2543294",
            "title": "Compositional Distributional Semantics with Long Short Term Memory"
        },
        {
            "paperId": "df77714269f1f88182092f8535b1bc290fcd835d",
            "title": "When Are Tree Structures Necessary for Deep Learning of Representations?"
        },
        {
            "paperId": "32de44f01a96d4473d21099d15e25bc2b9f08e2f",
            "title": "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks"
        },
        {
            "paperId": "47570e7f63e296f224a0e7f9a0d08b0de3cbaf40",
            "title": "Grammar as a Foreign Language"
        },
        {
            "paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "title": "Adam: A Method for Stochastic Optimization"
        },
        {
            "paperId": "964153213e608b65ebd49684fa9dcbfe1c720fb4",
            "title": "Global Belief Recursive Neural Networks"
        },
        {
            "paperId": "d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0",
            "title": "Show and tell: A neural image caption generator"
        },
        {
            "paperId": "2672f1ab4e31a6cbdfc77563a81318aec27cdd04",
            "title": "The Inside-Outside Recursive Neural Network model for Dependency Parsing"
        },
        {
            "paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "title": "Sequence to Sequence Learning with Neural Networks"
        },
        {
            "paperId": "1eb09fecd75eb27825dce4f964b97f4f5cc399d7",
            "title": "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches"
        },
        {
            "paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "title": "Neural Machine Translation by Jointly Learning to Align and Translate"
        },
        {
            "paperId": "1149888d75af4ed5dffc25731b875651c3ccdeb2",
            "title": "Hybrid speech recognition with Deep Bidirectional LSTM"
        },
        {
            "paperId": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
        },
        {
            "paperId": "acc4e56c44771ebf69302a06af51498aeb0a6ac8",
            "title": "Parsing with Compositional Vector Grammars"
        },
        {
            "paperId": "f6b51c8753a871dc94ff32152c00c01e94f90f09",
            "title": "Efficient Estimation of Word Representations in Vector Space"
        },
        {
            "paperId": "9c0ddf74f87d154db88d79c640578c1610451eec",
            "title": "Parsing Natural Scenes and Natural Language with Recursive Neural Networks"
        },
        {
            "paperId": "f24fb33e739b0181fc171b515f957190e3bb6430",
            "title": "Syntactic Processing Using the Generalized Perceptron and Beam Search"
        },
        {
            "paperId": "044b239c207a9decc77a7c2eb6de1f95b92c9fc3",
            "title": "From symbolic to sub-symbolic information in question classification"
        },
        {
            "paperId": "865081156ed7506d21de25d7b865f278b6b8191d",
            "title": "Transition-Based Parsing of the Chinese Treebank using a Global Discriminative Model"
        },
        {
            "paperId": "57458bc1cffe5caa45a885af986d70f723f406b4",
            "title": "A unified architecture for natural language processing: deep neural networks with multitask learning"
        },
        {
            "paperId": "0ecb33ced5b0976accdf13817151f80568b6fdcb",
            "title": "Coarse-to-Fine n-Best Parsing and MaxEnt Discriminative Reranking"
        },
        {
            "paperId": "b9eea85e590f6e522e3681b8e45012684c60b0fd",
            "title": "Parsing the WSJ Using CCG and Log-Linear Models"
        },
        {
            "paperId": "3fc44ff7f37ec5585310666c183c65e0a0bb2446",
            "title": "Head-Driven Statistical Models for Natural Language Parsing"
        },
        {
            "paperId": "a600850ac0120cb09a0b7de7da80bb6a7a76de06",
            "title": "Accurate Unlexicalized Parsing"
        },
        {
            "paperId": "2c8ac3e1f0edeed1fbd76813e61efdc384c319c7",
            "title": "Learning Question Classifiers"
        },
        {
            "paperId": "76d5e3fa888bee872b7adb7fa810089aa8ab1d58",
            "title": "A Maximum-Entropy-Inspired Parser"
        },
        {
            "paperId": "545a4e23bf00ddbc1d3325324b4c61f57cf45081",
            "title": "Recurrent nets that time and count"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "668087f0ae7ce1de6e0bd0965dbb480c08103260",
            "title": "Finding Structure in Time"
        },
        {
            "paperId": "34f25a8704614163c4095b3ee2fc969b60de4698",
            "title": "Dropout: a simple way to prevent neural networks from overfitting"
        },
        {
            "paperId": "9819b600a828a57e1cde047bbe710d3446b30da5",
            "title": "Recurrent neural network based language model"
        },
        {
            "paperId": "9e86e53e42a36bef4f2240ab7e3d4d2449dddcd8",
            "title": "Language Processing"
        },
        {
            "paperId": "13167f9cd8c7906ca808b01d28dca6dd951da8a5",
            "title": "of the Association for Computational Linguistics"
        }
    ]
}