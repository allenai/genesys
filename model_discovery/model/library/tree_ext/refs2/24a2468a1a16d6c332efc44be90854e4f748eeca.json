{
    "paperId": "24a2468a1a16d6c332efc44be90854e4f748eeca",
    "externalIds": {
        "ArXiv": "2403.08081",
        "DBLP": "conf/aistats/LiHIRO24",
        "DOI": "10.48550/arXiv.2403.08081",
        "CorpusId": 268379753
    },
    "title": "Mechanics of Next Token Prediction with Self-Attention",
    "abstract": "Transformer-based language models are trained on large datasets to predict the next token given an input sequence. Despite this simple training objective, they have led to revolutionary advances in natural language processing. Underlying this success is the self-attention mechanism. In this work, we ask: $\\textit{What}$ $\\textit{does}$ $\\textit{a}$ $\\textit{single}$ $\\textit{self-attention}$ $\\textit{layer}$ $\\textit{learn}$ $\\textit{from}$ $\\textit{next-token}$ $\\textit{prediction?}$ We show that training self-attention with gradient descent learns an automaton which generates the next token in two distinct steps: $\\textbf{(1)}$ $\\textbf{Hard}$ $\\textbf{retrieval:}$ Given input sequence, self-attention precisely selects the $\\textit{high-priority}$ $\\textit{input}$ $\\textit{tokens}$ associated with the last input token. $\\textbf{(2)}$ $\\textbf{Soft}$ $\\textbf{composition:}$ It then creates a convex combination of the high-priority tokens from which the next token can be sampled. Under suitable conditions, we rigorously characterize these mechanics through a directed graph over tokens extracted from the training data. We prove that gradient descent implicitly discovers the strongly-connected components (SCC) of this graph and self-attention learns to retrieve the tokens that belong to the highest-priority SCC available in the context window. Our theory relies on decomposing the model weights into a directional component and a finite component that correspond to hard retrieval and soft composition steps respectively. This also formalizes a related implicit bias formula conjectured in [Tarzanagh et al. 2023]. We hope that these findings shed light on how self-attention processes sequential data and pave the path toward demystifying more complex architectures.",
    "venue": "International Conference on Artificial Intelligence and Statistics",
    "year": 2024,
    "referenceCount": 64,
    "citationCount": 10,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is proved that gradient descent implicitly discovers the strongly-connected components (SCC) of this graph and self-attention learns to retrieve the tokens that belong to the highest-priority SCC available in the context window."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -0.8463414907455444,
            0.6355381011962891,
            -1.3567769527435303,
            2.391024589538574,
            1.6522455215454102,
            1.4681286811828613,
            0.8318518400192261,
            2.057725191116333,
            -1.0256181955337524,
            4.700965881347656,
            -0.37356725335121155,
            0.7774261236190796,
            0.5333095788955688,
            -1.21586012840271,
            1.10493004322052,
            4.0065765380859375,
            -1.2761683464050293,
            1.878537893295288,
            2.0805013179779053,
            2.9453883171081543,
            2.8709444999694824,
            2.7665390968322754,
            -2.795764684677124,
            -8.734721183776855,
            -3.2250022888183594,
            -0.5114476680755615,
            4.121220588684082,
            -1.6815874576568604,
            -6.193041801452637,
            3.4631998538970947,
            -1.1241064071655273,
            -4.870133399963379,
            1.6748290061950684,
            -2.0757899284362793,
            1.535361886024475,
            -2.1081387996673584,
            -2.689349889755249,
            9.85934066772461,
            -4.795884132385254,
            -2.866541624069214,
            -1.6037988662719727,
            3.7919762134552,
            -3.861677408218384,
            2.683845281600952,
            4.861599922180176,
            2.150294780731201,
            4.075410842895508,
            -0.6447104215621948,
            -5.746551036834717,
            1.4129596948623657,
            3.561258554458618,
            -0.2634609639644623,
            -2.6452977657318115,
            4.1273193359375,
            0.440600723028183,
            -3.4456191062927246,
            1.1529428958892822,
            -5.122395038604736,
            5.1057538986206055,
            -4.526054859161377,
            5.045632362365723,
            6.554100513458252,
            2.60410213470459,
            -2.6625022888183594,
            2.877793550491333,
            -6.281952857971191,
            -4.32013463973999,
            1.536399006843567,
            3.1280131340026855,
            0.8113139867782593,
            -0.04241037368774414,
            -6.790117263793945,
            -1.9621740579605103,
            3.445101737976074,
            1.2030283212661743,
            4.9353837966918945,
            1.05619478225708,
            -2.197509765625,
            -7.2363128662109375,
            0.03273928165435791,
            -3.937927722930908,
            0.025943636894226074,
            -1.4707635641098022,
            1.9555659294128418,
            6.91901159286499,
            0.8844079971313477,
            -3.4642069339752197,
            0.618706226348877,
            1.373595952987671,
            1.2587326765060425,
            -0.9390742182731628,
            3.009796619415283,
            -1.0159668922424316,
            3.186603546142578,
            -4.556321144104004,
            0.4190146028995514,
            3.773940086364746,
            1.562371015548706,
            -4.0573835372924805,
            0.8338908553123474,
            5.564533710479736,
            3.3984813690185547,
            3.9436984062194824,
            2.357905387878418,
            0.5347222685813904,
            -0.055589258670806885,
            -1.5048246383666992,
            -0.49383971095085144,
            2.9194908142089844,
            1.485778570175171,
            1.9136991500854492,
            0.7620110511779785,
            -0.32628482580184937,
            -1.9619415998458862,
            2.304469585418701,
            -3.0649266242980957,
            -3.5176472663879395,
            1.1944080591201782,
            -2.217519998550415,
            1.6392393112182617,
            -3.1946563720703125,
            -1.3545359373092651,
            -0.0330071747303009,
            1.0223658084869385,
            2.6829633712768555,
            -2.07016921043396,
            -2.9041080474853516,
            -1.4266071319580078,
            1.985051155090332,
            -3.390220880508423,
            3.4344611167907715,
            1.2452211380004883,
            4.642391681671143,
            -1.8654356002807617,
            3.3458011150360107,
            3.450759172439575,
            -3.1832916736602783,
            5.759578704833984,
            -0.9389603137969971,
            2.346890449523926,
            -1.2613650560379028,
            3.656444549560547,
            0.25062334537506104,
            3.7926197052001953,
            -0.7880889177322388,
            4.737663269042969,
            2.912104606628418,
            0.5442584753036499,
            -2.7667651176452637,
            4.5967698097229,
            4.764533042907715,
            -3.926859140396118,
            -1.9982987642288208,
            0.5481679439544678,
            -1.7367300987243652,
            6.625206470489502,
            -2.6767725944519043,
            5.107638359069824,
            0.028601691126823425,
            -0.6085332036018372,
            1.3326103687286377,
            -2.278299570083618,
            -14.280146598815918,
            -2.026197910308838,
            -0.8023151159286499,
            -4.177670955657959,
            -2.3414173126220703,
            5.798779010772705,
            1.7682856321334839,
            5.768651008605957,
            -1.9220424890518188,
            -0.8066555261611938,
            -1.944500207901001,
            1.7399014234542847,
            6.694433212280273,
            5.778683662414551,
            2.017545700073242,
            -4.997313022613525,
            -1.052167296409607,
            2.2714343070983887,
            -1.7259669303894043,
            -3.026634454727173,
            -7.641839504241943,
            2.2743988037109375,
            -5.0355119705200195,
            -3.0881505012512207,
            -1.1856210231781006,
            -2.8228187561035156,
            1.4388914108276367,
            -3.0389487743377686,
            1.0513899326324463,
            -3.801004409790039,
            4.349628448486328,
            6.50872802734375,
            0.46108126640319824,
            -0.6149950623512268,
            1.1079264879226685,
            4.323184490203857,
            0.24771732091903687,
            -3.333256959915161,
            0.896196722984314,
            1.9568829536437988,
            -5.4114837646484375,
            -5.606204986572266,
            1.1891517639160156,
            5.101269721984863,
            -4.687887668609619,
            1.1229170560836792,
            2.017627239227295,
            1.0629862546920776,
            0.09762553870677948,
            -1.9967575073242188,
            0.13323228061199188,
            4.091653823852539,
            -0.5412821769714355,
            -3.1518707275390625,
            -6.236185073852539,
            -3.9154038429260254,
            4.7425618171691895,
            -0.027408182621002197,
            2.348135471343994,
            0.9191151857376099,
            1.3097708225250244,
            -0.3212924897670746,
            -0.6290496587753296,
            -1.9578322172164917,
            3.1627702713012695,
            -2.746807336807251,
            2.698568344116211,
            -2.3828916549682617,
            -5.75553035736084,
            -6.678774833679199,
            -0.14603376388549805,
            -1.6337811946868896,
            0.2827015221118927,
            -5.661005020141602,
            -2.599583148956299,
            2.4061567783355713,
            -1.0322154760360718,
            -2.6444506645202637,
            5.234525203704834,
            -2.5942506790161133,
            0.6280715465545654,
            2.62740159034729,
            1.5441746711730957,
            -1.5388613939285278,
            -4.953302383422852,
            -0.99930739402771,
            -1.122537612915039,
            1.1516447067260742,
            -2.880844831466675,
            -1.6271297931671143,
            1.1790664196014404,
            1.769265055656433,
            -2.5443472862243652,
            2.5428552627563477,
            -1.6245514154434204,
            -2.3719303607940674,
            1.6908440589904785,
            -0.8434250354766846,
            0.6517724990844727,
            4.474370956420898,
            1.0993287563323975,
            3.699018955230713,
            -6.127031326293945,
            -0.1991865485906601,
            -2.375476837158203,
            -2.0620291233062744,
            -3.3926830291748047,
            1.1472247838974,
            0.18861281871795654,
            -2.033738374710083,
            -0.11740344762802124,
            -2.0214900970458984,
            -0.057807326316833496,
            -3.01525616645813,
            -0.08037698268890381,
            -3.4945170879364014,
            1.503524661064148,
            5.545106887817383,
            -0.6711058616638184,
            0.016508005559444427,
            0.9694308042526245,
            -2.7377076148986816,
            -0.5560349822044373,
            -1.6455764770507812,
            -1.8595547676086426,
            -3.1643340587615967,
            -2.1361937522888184,
            -0.7129520177841187,
            -5.070873260498047,
            6.511448860168457,
            -5.134648323059082,
            1.4006098508834839,
            -5.406647682189941,
            0.5192919373512268,
            2.771608352661133,
            0.0703270435333252,
            1.7269089221954346,
            -0.8063137531280518,
            1.3712360858917236,
            0.8755962252616882,
            0.5222080945968628,
            3.9882986545562744,
            -1.0457521677017212,
            0.7226619124412537,
            0.7600215673446655,
            -0.9629135727882385,
            0.8361484408378601,
            -1.4177517890930176,
            2.348891019821167,
            1.6854019165039062,
            3.2935361862182617,
            -3.402986526489258,
            2.824983835220337,
            -1.796862244606018,
            -4.073780059814453,
            -0.7358021140098572,
            0.4392252564430237,
            2.997544527053833,
            -1.1027649641036987,
            -1.7044012546539307,
            -6.100185394287109,
            2.653801918029785,
            -6.355064392089844,
            3.745408058166504,
            5.433421611785889,
            1.2729651927947998,
            -1.0653718709945679,
            1.9537302255630493,
            -2.2663493156433105,
            5.7831315994262695,
            -2.3850350379943848,
            3.1213276386260986,
            -1.7825026512145996,
            -5.971571445465088,
            -3.1931231021881104,
            -2.141972303390503,
            0.08677104115486145,
            -1.3394181728363037,
            -3.465087413787842,
            7.5676679611206055,
            -0.3288128972053528,
            0.9842643141746521,
            -0.027804136276245117,
            1.4171478748321533,
            -0.27103543281555176,
            -2.7471823692321777,
            -2.8338184356689453,
            -1.990422010421753,
            1.6987714767456055,
            3.3178837299346924,
            -0.5095654726028442,
            -1.370853304862976,
            -0.7688378691673279,
            3.379016160964966,
            1.9019230604171753,
            -0.251820832490921,
            -1.246164083480835,
            -0.4641574025154114,
            -3.050340175628662,
            4.970777988433838,
            -0.6374010443687439,
            2.0227437019348145,
            2.207651138305664,
            -0.3939637839794159,
            7.792427062988281,
            -3.021371841430664,
            -1.8647125959396362,
            -4.70136022567749,
            -1.842516541481018,
            -3.7641658782958984,
            -1.8165671825408936,
            4.133554458618164,
            1.9609220027923584,
            -4.031965255737305,
            -0.12553465366363525,
            -3.1414430141448975,
            0.4472382962703705,
            -1.78921377658844,
            -0.577689528465271,
            3.8794543743133545,
            -0.9272170066833496,
            2.2187938690185547,
            2.8802099227905273,
            -0.3973429203033447,
            -1.4571809768676758,
            1.132930040359497,
            3.366894245147705,
            -0.8715119361877441,
            0.899707555770874,
            3.8003273010253906,
            1.6664202213287354,
            -5.233542442321777,
            -0.6958342790603638,
            -7.556784629821777,
            0.4772888123989105,
            -2.1882290840148926,
            3.506021738052368,
            -1.070983648300171,
            -0.5931140184402466,
            1.702702522277832,
            -0.27443403005599976,
            1.5396324396133423,
            -1.8042608499526978,
            -2.0470433235168457,
            10.404611587524414,
            -2.5795676708221436,
            -4.19834566116333,
            2.7423229217529297,
            -2.881279706954956,
            -4.2737321853637695,
            2.637923240661621,
            -2.748577117919922,
            2.5810422897338867,
            -1.153279423713684,
            -4.00131893157959,
            5.460329055786133,
            2.252072811126709,
            2.2368011474609375,
            -3.7779979705810547,
            6.533609390258789,
            6.5843000411987305,
            2.9109230041503906,
            -1.3891732692718506,
            -2.751088857650757,
            8.268753051757812,
            1.3753342628479004,
            -1.5289559364318848,
            0.6924465894699097,
            -0.38978084921836853,
            2.4672160148620605,
            -4.959054946899414,
            -2.9174954891204834,
            2.9720025062561035,
            1.0373239517211914,
            3.4121737480163574,
            -1.140407919883728,
            -1.577669382095337,
            -5.482003211975098,
            1.6623928546905518,
            3.6172537803649902,
            -5.250829219818115,
            1.4731590747833252,
            0.12023624777793884,
            0.6489793062210083,
            -0.42782315611839294,
            0.29271772503852844,
            1.977384328842163,
            -1.6931239366531372,
            1.9047291278839111,
            -4.927045822143555,
            -0.9096894264221191,
            -0.872083306312561,
            -2.749424934387207,
            2.937321662902832,
            -1.8314677476882935,
            0.48753640055656433,
            -1.529207468032837,
            1.3980931043624878,
            -5.948870658874512,
            2.289966106414795,
            -6.13323974609375,
            3.525312662124634,
            3.043842315673828,
            -1.6188828945159912,
            -0.7356780171394348,
            -4.549562454223633,
            0.17884328961372375,
            4.807405948638916,
            0.6227526664733887,
            0.07321834564208984,
            -4.425240993499756,
            1.5594806671142578,
            -2.101933002471924,
            -1.7676029205322266,
            2.0135955810546875,
            8.657144546508789,
            4.140477180480957,
            1.4652835130691528,
            -4.913516998291016,
            1.091160774230957,
            0.39039909839630127,
            -1.0538498163223267,
            -2.2115888595581055,
            5.719758987426758,
            0.676468014717102,
            -0.9949753284454346,
            1.036565899848938,
            3.544192314147949,
            5.545053958892822,
            4.16120719909668,
            7.063366889953613,
            -2.3965847492218018,
            1.3385906219482422,
            -0.594463586807251,
            -3.098231792449951,
            -1.263521432876587,
            0.01216953992843628,
            -2.4919774532318115,
            2.093099594116211,
            -3.3666818141937256,
            -1.361339807510376,
            0.9800703525543213,
            0.6571167707443237,
            2.1465747356414795,
            4.312011241912842,
            -1.0333303213119507,
            1.2664755582809448,
            -0.20207485556602478,
            -4.325413703918457,
            7.450549602508545,
            -5.648593425750732,
            -2.8419103622436523,
            -4.550541877746582,
            2.9986491203308105,
            2.6250863075256348,
            -4.23048210144043,
            2.3286631107330322,
            2.240413188934326,
            1.1166915893554688,
            4.448889255523682,
            -3.682178258895874,
            0.8972328305244446,
            0.7934583425521851,
            -0.5636460185050964,
            -0.07569107413291931,
            0.7584779262542725,
            2.895932912826538,
            7.739713191986084,
            4.508292198181152,
            0.8181549906730652,
            0.19595679640769958,
            0.7439836263656616,
            -1.7967690229415894,
            -0.9328418374061584,
            -1.0616509914398193,
            1.7228584289550781,
            0.3329763412475586,
            1.661689281463623,
            1.220237135887146,
            -0.006477326154708862,
            3.392169237136841,
            2.1446478366851807,
            -0.6996435523033142,
            1.0672060251235962,
            -1.8405646085739136,
            -2.1444215774536133,
            -2.838710069656372,
            1.3302643299102783,
            -3.2421913146972656,
            -2.118359088897705,
            4.7292680740356445,
            0.5849990844726562,
            0.8082566261291504,
            -1.022281527519226,
            -3.999312400817871,
            -3.8301045894622803,
            1.426743507385254,
            3.7105865478515625,
            0.8698983788490295,
            -1.5549664497375488,
            2.764847755432129,
            0.9197207093238831,
            2.0644071102142334,
            -3.7551307678222656,
            -0.8497610092163086,
            6.073757171630859,
            4.420222282409668,
            4.314154624938965,
            1.5479438304901123,
            -1.1174631118774414,
            0.6759746074676514,
            3.0394997596740723,
            2.1195755004882812,
            1.9544270038604736,
            0.5235147476196289,
            3.2303314208984375,
            2.8188271522521973,
            -1.1512373685836792,
            -3.0054657459259033,
            0.7467621564865112,
            -5.650485992431641,
            -6.276640892028809,
            1.471796989440918,
            -1.9089490175247192,
            -0.08879655599594116,
            0.6243574619293213,
            0.5660724639892578,
            -2.240866184234619,
            2.7195916175842285,
            1.838640809059143,
            -0.2170998752117157,
            -1.1681709289550781,
            0.6676258444786072,
            -7.2660112380981445,
            4.128389358520508,
            -3.6473443508148193,
            -2.396730899810791,
            1.0636506080627441,
            -0.2324984222650528,
            1.8617644309997559,
            1.4168230295181274,
            -0.11334496736526489,
            -4.765505790710449,
            0.9179407358169556,
            6.0031352043151855,
            0.582302451133728,
            0.4191996455192566,
            3.2391152381896973,
            0.5505363941192627,
            1.6701581478118896,
            18.631967544555664,
            2.50357985496521,
            0.8701902627944946,
            2.4417715072631836,
            -0.10542410612106323,
            -2.52607798576355,
            -2.644439697265625,
            1.3766216039657593,
            2.381230354309082,
            4.030027866363525,
            -2.7424168586730957,
            -0.1932402402162552,
            -2.733457565307617,
            -1.9969297647476196,
            -6.432312965393066,
            -2.1363654136657715,
            -3.2574193477630615,
            3.50622820854187,
            3.8628480434417725,
            1.528226375579834,
            2.2615199089050293,
            0.19707761704921722,
            0.9277031421661377,
            -0.47645318508148193,
            0.42739251255989075,
            5.739283561706543,
            -1.083286166191101,
            2.8532233238220215,
            -1.6035244464874268,
            -2.004918098449707,
            -3.852593183517456,
            1.8522002696990967,
            -2.217608690261841,
            0.005500972270965576,
            -1.427732229232788,
            1.0019915103912354,
            1.8463144302368164,
            -4.122491836547852,
            -0.827494204044342,
            -0.9613313674926758,
            1.8959616422653198,
            -1.82539701461792,
            -8.750526428222656,
            -3.729530096054077,
            2.544157028198242,
            4.504001140594482,
            2.8616418838500977,
            -1.1509519815444946,
            -0.576036810874939,
            1.7237317562103271,
            1.864553451538086,
            -3.5051467418670654,
            -0.6790211796760559,
            6.127864837646484,
            2.421999931335449,
            2.050290107727051,
            -0.637342095375061,
            1.0246500968933105,
            2.5390501022338867,
            0.05390059947967529,
            0.6890853047370911,
            -2.2253854274749756,
            -4.974416732788086,
            -1.0767468214035034,
            -2.918973445892334,
            -0.2674013376235962,
            -2.225788116455078,
            2.852311134338379,
            1.0141782760620117,
            0.8684757947921753,
            2.671875,
            -0.1414129137992859,
            0.03656558692455292,
            -5.2650299072265625,
            -6.5733160972595215,
            -4.701845169067383,
            -2.9695963859558105,
            -1.254045009613037,
            1.301044225692749,
            6.70572566986084,
            -6.9498372077941895,
            1.1298010349273682,
            -4.0044403076171875,
            2.4978880882263184,
            3.830778121948242,
            -5.901739597320557,
            0.17446762323379517,
            3.938688278198242,
            -2.383547306060791,
            0.4613480567932129,
            1.6658844947814941,
            0.3441145122051239,
            3.405994415283203,
            4.4796671867370605,
            2.2923927307128906,
            -2.7782578468322754,
            0.90850830078125,
            -2.429733991622925,
            -3.6479358673095703,
            2.1379384994506836,
            2.3756189346313477,
            -0.9572485685348511,
            0.049618542194366455,
            0.4392698407173157,
            4.154501914978027,
            -3.5134780406951904,
            1.0945916175842285,
            -4.695889472961426,
            -1.0597578287124634,
            -5.361400604248047,
            3.6817827224731445,
            -3.705409049987793,
            -2.830683946609497,
            2.0467324256896973,
            -0.6891709566116333,
            0.5486105680465698,
            -3.0111660957336426,
            1.2843259572982788,
            3.4209508895874023,
            0.43722251057624817,
            -0.2619943618774414,
            -1.9697843790054321,
            -1.7943812608718872,
            -2.3657193183898926,
            1.5256991386413574,
            4.1095404624938965,
            2.239388942718506,
            -1.4769268035888672,
            -2.2237954139709473,
            0.12345288693904877,
            3.354107141494751,
            -1.3920698165893555,
            -0.6786167025566101,
            -1.9947731494903564,
            -0.8163183927536011,
            0.28502175211906433,
            -0.08699905872344971,
            2.125385284423828,
            -4.742720603942871,
            1.8733011484146118,
            3.0914392471313477,
            0.45935797691345215,
            2.0486748218536377,
            8.7362642288208,
            -3.0167043209075928,
            -3.325153112411499,
            -4.494564056396484,
            1.272560715675354,
            -0.7462491393089294,
            -3.9580161571502686,
            5.456875801086426,
            1.2762160301208496,
            1.2555673122406006,
            3.755361318588257,
            -3.618697166442871,
            -0.3529767692089081
        ]
    },
    "authors": [
        {
            "authorId": "1527089987",
            "name": "Yingcong Li"
        },
        {
            "authorId": "2284934923",
            "name": "Yixiao Huang"
        },
        {
            "authorId": "46214352",
            "name": "M. E. Ildiz"
        },
        {
            "authorId": "2241094",
            "name": "A. Rawat"
        },
        {
            "authorId": "3103394",
            "name": "Samet Oymak"
        }
    ],
    "references": [
        {
            "paperId": "2bc63d667572453d1da74abb32c5780a676099ad",
            "title": "Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality"
        },
        {
            "paperId": "6f6642062eb4890da148f397badfa4c98f94508a",
            "title": "Implicit Bias of Next-Token Prediction"
        },
        {
            "paperId": "adc09237bd89ed9d1bae26a019414bf5a1cbf5a1",
            "title": "How Do Nonlinear Transformers Learn and Generalize in In-Context Learning?"
        },
        {
            "paperId": "04a75094f7acbd1243b69d78af8fcc8608011b2d",
            "title": "From Self-Attention to Markov Models: Unveiling the Dynamics of Generative Transformers"
        },
        {
            "paperId": "aba4949ea029543da347b080f6acbb4e6a05aaa7",
            "title": "In-Context Learning with Transformers: Softmax Attention Adapts to Function Lipschitzness"
        },
        {
            "paperId": "3f5b93774cd2c6e37e1c080589d80ed90a36a976",
            "title": "Provably learning a multi-head attention layer"
        },
        {
            "paperId": "6c757c359139d126f57ae566153c6264f220efca",
            "title": "Attention with Markov: A Framework for Principled Analysis of Transformers via Markov Chains"
        },
        {
            "paperId": "3c537970f5dc1d7b75df15912d9668b06e1d3fd1",
            "title": "Towards Understanding the Word Sensitivity of Attention Layers: A Study via Random Features"
        },
        {
            "paperId": "d03d34a404676709d183bd71dc5da96f05a74cc4",
            "title": "An Information-Theoretic Analysis of In-Context Learning"
        },
        {
            "paperId": "6cee47349bf526bd63ee62da15b3c88701f97f15",
            "title": "On the Optimization and Generalization of Multi-head Attention"
        },
        {
            "paperId": "ab643f5b02786fc4772b662adcdb558c557d3bf6",
            "title": "In-Context Convergence of Transformers"
        },
        {
            "paperId": "f9a4ed62ea6da274c1c81748b2bca240655b7c29",
            "title": "Transformers as Support Vector Machines"
        },
        {
            "paperId": "b978428a41d4051f0fd744845a4bce0523dbee85",
            "title": "What can a Single Attention Layer Learn? A Study Through the Random Features Lens"
        },
        {
            "paperId": "3f16d91bdfca925df761d27fd3b11af7d68c63d8",
            "title": "On the Role of Attention in Prompt-tuning"
        },
        {
            "paperId": "50eb97f832ffcd2114f79957c977215176384e3d",
            "title": "Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer"
        },
        {
            "paperId": "163b4d6a79a5b19af88b8585456363340d9efd04",
            "title": "GPT-4 Technical Report"
        },
        {
            "paperId": "f3fde8a09b757ab356da1314d7a938504edf8314",
            "title": "How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding"
        },
        {
            "paperId": "57e849d0de13ed5f91d086936296721d4ff75a75",
            "title": "LLaMA: Open and Efficient Foundation Language Models"
        },
        {
            "paperId": "91166a75f0e32b782a57028f1501aba6335ac550",
            "title": "A Theoretical Understanding of shallow Vision Transformers: Learning, Generalization, and Sample Complexity"
        },
        {
            "paperId": "a7fa71dc6856ebef79f354597128d1c68b19b6e4",
            "title": "Transformers as Algorithms: Generalization and Stability in In-context Learning"
        },
        {
            "paperId": "525d93a382f6e7873b5d8a2e0713eb3dff7fb250",
            "title": "Transformers learn in-context by gradient descent"
        },
        {
            "paperId": "7aa801b907b59b8ee4cfb1296d9dac22c5164c5d",
            "title": "What learning algorithm is in-context learning? Investigations with linear models"
        },
        {
            "paperId": "13d3733e0dabbb4ccdd036a5f04fd5b3e39eecb0",
            "title": "Vision Transformers provably learn spatial structure"
        },
        {
            "paperId": "de32da8f5c6a50a6c311e9357ba16aa7d05a1bc9",
            "title": "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes"
        },
        {
            "paperId": "dcb31b98ec58f3fff9f94f148e2952595f017fd9",
            "title": "ProtGPT2 is a deep unsupervised language model for protein design"
        },
        {
            "paperId": "26133033149afb4b45e5d0a4bd1dc712a236810e",
            "title": "ProGen2: Exploring the Boundaries of Protein Language Models"
        },
        {
            "paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb",
            "title": "PaLM: Scaling Language Modeling with Pathways"
        },
        {
            "paperId": "10bd4160b44803ada6a3d2e366c44b7e2a4ffe90",
            "title": "An Explanation of In-context Learning as Implicit Bayesian Inference"
        },
        {
            "paperId": "1cbb3d96242c3f47c3f40aada33616d0f5c07737",
            "title": "Inductive Biases and Variable Creation in Self-Attention Mechanisms"
        },
        {
            "paperId": "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500",
            "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling"
        },
        {
            "paperId": "dfb37e6216e792bf6bd5a30c0fc7ad55df1cb71e",
            "title": "Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth"
        },
        {
            "paperId": "4a69ad4abbf38420a6df4db541a40d7e5b46ca14",
            "title": "Label-Imbalanced and Group-Sensitive Classification under Overparameterization"
        },
        {
            "paperId": "48d3e2815410ec850f2bae5f48eeccabd13bc3ee",
            "title": "The Implicit Bias for Adaptive Optimization Algorithms on Homogeneous Neural Networks"
        },
        {
            "paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8",
            "title": "Generative Pretraining From Pixels"
        },
        {
            "paperId": "799a6f18c79b56c04c42bd96e4e39f8119b57843",
            "title": "Gradient descent follows the regularization path for general losses"
        },
        {
            "paperId": "40ca4fcfffa7ca9aa9b7ff06ecf3cd0436712d78",
            "title": "$O(n)$ Connections are Expressive Enough: Universal Approximability of Sparse Transformers"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "509b4661ed74a24c2ffdbf131f9e1c6a1783752d",
            "title": "Are Transformers universal approximators of sequence-to-sequence functions?"
        },
        {
            "paperId": "97412aded29b05ee69a63ea9ec2b22f41c321149",
            "title": "Generative Pre-Training for Speech with Autoregressive Predictive Coding"
        },
        {
            "paperId": "36451fe94b7b1f978b8301cf3f7305566bd3b454",
            "title": "Towards Explaining the Regularization Effect of Initial Large Learning Rate in Training Neural Networks"
        },
        {
            "paperId": "76c2679deb0b7689c658c199254963889d4d2b69",
            "title": "The implicit bias of gradient descent on nonseparable data"
        },
        {
            "paperId": "89b78ccb0ab37c5f6a610e61384363798f127b71",
            "title": "Characterizing the implicit bias via a primal-dual analysis"
        },
        {
            "paperId": "725c691c1b53d0c132c4b2e8de10f8cc63730813",
            "title": "The Implicit Bias of AdaGrad on Separable Data"
        },
        {
            "paperId": "bcf397d57dbcb5d423a341bfadef8dfc09d0cfb8",
            "title": "Implicit regularization for deep neural networks driven by an Ornstein-Uhlenbeck like process"
        },
        {
            "paperId": "4a5a17d7849b91a3af583c7b99403844e1a5cdb1",
            "title": "Risk and parameter convergence of logistic regression"
        },
        {
            "paperId": "33416f2dc49db24cca520a3b234f02463a4e833e",
            "title": "Characterizing Implicit Bias in Terms of Optimization Geometry"
        },
        {
            "paperId": "11adc8bd35bd897502f9b5452ab7ac668ec9b0fb",
            "title": "The Implicit Bias of Gradient Descent on Separable Data"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "63e39cdf1ad884da6bc69096bb3413b5b1100559",
            "title": "Using the Output Embedding to Improve Language Models"
        },
        {
            "paperId": "f6d16b4db8779721715a00008ba03b5c67e4669c",
            "title": "Margin Maximizing Loss Functions"
        },
        {
            "paperId": "385742fffcf113656f0d3cf6c06ef95cb8439dc6",
            "title": "Depth-First Search and Linear Graph Algorithms"
        },
        {
            "paperId": "7efdee766894ebc7f3cc8780138875e9b334b436",
            "title": "Margin Maximization in Attention Mechanism"
        },
        {
            "paperId": null,
            "title": "on Learning Representations"
        },
        {
            "paperId": "9405cc0d6169988371b2755e573cc28650d14dfe",
            "title": "Language Models are Unsupervised Multitask Learners"
        },
        {
            "paperId": "7a4122ee1a93986aa60553389957d554561c4180",
            "title": "Connecting Optimization and Regularization Paths"
        },
        {
            "paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "title": "Improving Language Understanding by Generative Pre-Training"
        },
        {
            "paperId": null,
            "title": "Construct TPGs and apply Tarjan\u2019s"
        },
        {
            "paperId": null,
            "title": "b) All the training details (e.g., data splits, hyperparameters, how they were chosen)"
        },
        {
            "paperId": null,
            "title": "Given dimension d and vocabulary size K , generate random embedding table E = [ e 1 \u00b7 \u00b7 \u00b7 e K ] \u22a4 \u2208 R K \u00d7 d such that each e E is randomly sampled from unit sphere"
        },
        {
            "paperId": null,
            "title": "Given sample size n and sequence length T"
        },
        {
            "paperId": null,
            "title": "Under a general setting"
        },
        {
            "paperId": null,
            "title": "Our theory reveals insightful connections between continuous and discrete optimization, namely: Self-attention implicitly discovers the strongly-connected components of the TPGs during training"
        },
        {
            "paperId": "1e25ca5ad8af2f604a57f504803ffa6dcfa11984",
            "title": "Transformers as Multi-Task Feature Selectors: Generalization Analysis of In-Context Learning"
        },
        {
            "paperId": null,
            "title": "The quarks of attention: Structure and capacity of neu-Mechanics"
        }
    ]
}