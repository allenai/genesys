{
    "paperId": "d0075dd5603c9d477edf0a41f59ab6dcf0e91976",
    "externalIds": {
        "ArXiv": "2403.08763",
        "DBLP": "journals/corr/abs-2403-08763",
        "DOI": "10.48550/arXiv.2403.08763",
        "CorpusId": 268379604
    },
    "title": "Simple and Scalable Strategies to Continually Pre-train Large Language Models",
    "abstract": "Large language models (LLMs) are routinely pre-trained on billions of tokens, only to start the process over again once new data becomes available. A much more efficient solution is to continually pre-train these models, saving significant compute compared to re-training. However, the distribution shift induced by new data typically results in degraded performance on previous data or poor adaptation to the new data. In this work, we show that a simple and scalable combination of learning rate (LR) re-warming, LR re-decaying, and replay of previous data is sufficient to match the performance of fully re-training from scratch on all available data, as measured by the final loss and the average score on several language model (LM) evaluation benchmarks. Specifically, we show this for a weak but realistic distribution shift between two commonly used LLM pre-training datasets (English$\\rightarrow$English) and a stronger distribution shift (English$\\rightarrow$German) at the $405$M parameter model scale with large dataset sizes (hundreds of billions of tokens). Selecting the weak but realistic shift for larger-scale experiments, we also find that our continual learning strategies match the re-training baseline for a 10B parameter LLM. Our results demonstrate that LLMs can be successfully updated via simple and scalable continual learning strategies, matching the re-training baseline using only a fraction of the compute. Finally, inspired by previous work, we propose alternatives to the cosine learning rate schedule that help circumvent forgetting induced by LR re-warming and that are not bound to a fixed token budget.",
    "venue": "Trans. Mach. Learn. Res.",
    "year": 2024,
    "referenceCount": 98,
    "citationCount": 21,
    "influentialCitationCount": 2,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work shows that a simple and scalable combination of learning rate (LR) re-warming, LR re-decaying, and replay of previous data is sufficient to match the performance of fully re-training from scratch on all available data, as measured by the final loss and the average score on several language model (LM) evaluation benchmarks."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -3.0206151008605957,
            -1.847607135772705,
            -2.617643356323242,
            3.0067615509033203,
            -1.7254064083099365,
            -0.0694623589515686,
            2.3258957862854004,
            0.21547695994377136,
            -1.834296464920044,
            3.0475616455078125,
            -0.24522548913955688,
            5.400269508361816,
            0.44722211360931396,
            1.397706151008606,
            -2.658735752105713,
            1.2779085636138916,
            0.026552528142929077,
            -1.8760546445846558,
            6.529335021972656,
            1.508202314376831,
            -3.0989272594451904,
            1.639577865600586,
            -1.956825613975525,
            -3.422048807144165,
            -3.662607431411743,
            -1.3542277812957764,
            4.770444869995117,
            2.2022173404693604,
            -2.501035690307617,
            -9.985268115997314e-05,
            0.49692654609680176,
            -4.021549224853516,
            4.437090873718262,
            -5.597116470336914,
            4.875433444976807,
            -4.526247024536133,
            -1.3540335893630981,
            8.483294486999512,
            -3.267455577850342,
            0.024550557136535645,
            -1.3667519092559814,
            -1.398383617401123,
            0.17491555213928223,
            1.2002493143081665,
            4.151468753814697,
            1.5680725574493408,
            3.770228624343872,
            0.3189570903778076,
            -0.8825559020042419,
            1.530426263809204,
            3.3535566329956055,
            -0.2966195344924927,
            0.27575522661209106,
            0.9551618099212646,
            2.3621649742126465,
            -0.6519948840141296,
            -0.6470605731010437,
            3.318171977996826,
            2.4755654335021973,
            -2.606598377227783,
            5.232696533203125,
            6.639046669006348,
            -0.5346419215202332,
            -0.4256391227245331,
            1.3380746841430664,
            -4.29461669921875,
            -4.9821367263793945,
            3.9305484294891357,
            0.3806251287460327,
            -0.5421085357666016,
            -0.013255834579467773,
            -5.390633583068848,
            -0.2451041042804718,
            0.980751097202301,
            -1.3044216632843018,
            -0.5676873326301575,
            -0.040702998638153076,
            -5.7203569412231445,
            -0.8927350640296936,
            -0.8011007308959961,
            -1.8573309183120728,
            2.5071535110473633,
            0.04684479534626007,
            2.438596487045288,
            3.737368106842041,
            -1.662827730178833,
            -6.028496265411377,
            1.9556301832199097,
            0.7126345634460449,
            -3.0793838500976562,
            3.720435619354248,
            0.44038134813308716,
            0.15778177976608276,
            2.913144588470459,
            -5.443743705749512,
            0.33553987741470337,
            -0.7026158571243286,
            -1.1222124099731445,
            -3.122093915939331,
            -0.6931111812591553,
            4.118669509887695,
            0.311055451631546,
            1.6753519773483276,
            1.5842713117599487,
            3.268965721130371,
            -2.9977498054504395,
            0.696679413318634,
            -0.2934998571872711,
            -0.4045087695121765,
            -0.6599524021148682,
            0.451426237821579,
            3.4053659439086914,
            -0.7148245573043823,
            -3.229335308074951,
            -1.3009397983551025,
            -4.71612548828125,
            0.7445967793464661,
            0.7490860223770142,
            -3.4091053009033203,
            2.430192470550537,
            -1.0696446895599365,
            0.3264116048812866,
            -2.795680522918701,
            -1.2654109001159668,
            -0.2572517395019531,
            1.5045692920684814,
            -2.1264734268188477,
            -0.5777461528778076,
            -2.0446395874023438,
            -2.959397792816162,
            2.6443095207214355,
            -0.550112247467041,
            3.7957077026367188,
            -2.831420660018921,
            4.146651268005371,
            2.096212387084961,
            -5.807918071746826,
            1.9438812732696533,
            -2.456977128982544,
            -0.9117074608802795,
            0.6458790302276611,
            5.075747013092041,
            -1.0083308219909668,
            -1.0508403778076172,
            0.14023423194885254,
            3.6718814373016357,
            1.2329869270324707,
            -1.3839576244354248,
            -0.691344141960144,
            5.543004512786865,
            5.5581464767456055,
            -6.412315368652344,
            0.5930275917053223,
            -0.531700611114502,
            -0.3596356213092804,
            6.319369316101074,
            -5.891379356384277,
            0.007865235209465027,
            -0.22191038727760315,
            0.6199919581413269,
            2.0673441886901855,
            -1.6513936519622803,
            -11.31808090209961,
            -1.1367924213409424,
            3.389044761657715,
            -4.324244499206543,
            -0.6130038499832153,
            1.1836824417114258,
            -0.664891242980957,
            0.37315165996551514,
            -1.2420361042022705,
            3.010240077972412,
            -1.4637537002563477,
            2.4017012119293213,
            0.9615738987922668,
            3.1638946533203125,
            4.440945625305176,
            -1.0092132091522217,
            -1.8487613201141357,
            1.29996657371521,
            0.9370405077934265,
            -2.4679863452911377,
            -5.356855392456055,
            0.5496610403060913,
            -3.5238356590270996,
            -2.383223533630371,
            -3.307075262069702,
            -4.020021438598633,
            1.4147796630859375,
            1.437518835067749,
            -2.558561086654663,
            0.040144383907318115,
            4.072014331817627,
            7.223910331726074,
            4.715394973754883,
            -0.7735875844955444,
            1.667083740234375,
            3.629695415496826,
            -4.604647159576416,
            0.9988795518875122,
            3.310338258743286,
            -0.14195293188095093,
            -2.702848434448242,
            -1.8026390075683594,
            0.7305890917778015,
            2.8057074546813965,
            -2.4570059776306152,
            1.979933261871338,
            1.4786361455917358,
            1.8309332132339478,
            2.1500725746154785,
            -2.0882279872894287,
            -2.426112413406372,
            -0.568816602230072,
            0.018381938338279724,
            -1.6112042665481567,
            -3.966322422027588,
            3.8499507904052734,
            7.997021675109863,
            0.8767879009246826,
            -2.760507106781006,
            0.6127907633781433,
            2.3346381187438965,
            -2.543670654296875,
            2.2030234336853027,
            -3.950141429901123,
            1.0518922805786133,
            -1.102614164352417,
            -0.7776371240615845,
            -0.5566900968551636,
            -3.6802735328674316,
            -4.6111040115356445,
            -0.3152872323989868,
            -1.1854712963104248,
            -4.91871976852417,
            -3.885255813598633,
            -5.233044624328613,
            1.3440654277801514,
            -2.6902523040771484,
            -0.2512051463127136,
            4.929083347320557,
            0.2745601534843445,
            1.6566404104232788,
            6.2255167961120605,
            2.575014352798462,
            -1.3000013828277588,
            -1.3408212661743164,
            1.370647668838501,
            -1.314846396446228,
            -0.6121443510055542,
            -2.2247419357299805,
            -2.883807897567749,
            0.02456769347190857,
            -0.165219247341156,
            1.957707166671753,
            3.3108649253845215,
            1.7635833024978638,
            -0.11286154389381409,
            1.20706307888031,
            -0.5261291861534119,
            -1.2765671014785767,
            6.910676002502441,
            1.206235408782959,
            4.640911102294922,
            -2.10325026512146,
            -0.6128171682357788,
            -4.63361930847168,
            -2.5566587448120117,
            -0.4730926752090454,
            3.0638110637664795,
            5.737527847290039,
            1.2795467376708984,
            -0.21845108270645142,
            -4.301399230957031,
            0.8520610928535461,
            -6.384484767913818,
            -2.332103967666626,
            -1.5614948272705078,
            2.3649487495422363,
            4.965518474578857,
            1.7234671115875244,
            -0.24108031392097473,
            -2.8361377716064453,
            -1.8647279739379883,
            -2.555158853530884,
            -1.369533658027649,
            -1.5851390361785889,
            1.0810095071792603,
            -2.890369415283203,
            -4.559962749481201,
            -2.739490032196045,
            5.481659412384033,
            -3.33184814453125,
            -0.09855583310127258,
            -1.3282219171524048,
            1.4663240909576416,
            5.0809102058410645,
            -0.30067721009254456,
            0.6491978764533997,
            0.6070218086242676,
            -1.8465557098388672,
            2.766268253326416,
            2.200348138809204,
            0.17728790640830994,
            2.4127049446105957,
            0.07520502805709839,
            0.6106721758842468,
            -5.026001930236816,
            2.228226661682129,
            -3.8693020343780518,
            0.9058611392974854,
            3.401256799697876,
            3.5504260063171387,
            -3.923953056335449,
            1.3433215618133545,
            0.28266236186027527,
            1.4311168193817139,
            -0.8816722631454468,
            -3.3576607704162598,
            2.5597124099731445,
            0.006751269102096558,
            1.2463397979736328,
            -3.0605244636535645,
            0.775522768497467,
            -3.1526341438293457,
            0.3582834005355835,
            4.44630241394043,
            2.297930955886841,
            -3.1563520431518555,
            3.1413705348968506,
            1.2526934146881104,
            4.384769916534424,
            1.2348839044570923,
            5.219810485839844,
            -1.5061005353927612,
            -3.4198508262634277,
            -0.19048070907592773,
            -4.041165351867676,
            2.195294141769409,
            -0.34577232599258423,
            0.47123825550079346,
            4.874309539794922,
            1.0290861129760742,
            0.9432343244552612,
            -2.066209316253662,
            0.8852599859237671,
            0.9406777620315552,
            0.04521369934082031,
            0.49043285846710205,
            -2.3286705017089844,
            -0.6365674734115601,
            1.803634524345398,
            3.2075140476226807,
            -0.5994957685470581,
            1.82335364818573,
            6.30579948425293,
            1.0257104635238647,
            -0.4831538200378418,
            -1.7448408603668213,
            -0.7221711874008179,
            0.7501168251037598,
            -1.2154064178466797,
            3.573554039001465,
            0.21087300777435303,
            3.1776628494262695,
            -2.7431766986846924,
            11.159049034118652,
            0.18999627232551575,
            0.885608434677124,
            -3.50923228263855,
            -1.3745044469833374,
            -2.043610095977783,
            -2.687565803527832,
            1.431051254272461,
            -1.1524746417999268,
            -2.278799057006836,
            3.4348578453063965,
            -5.6818084716796875,
            -0.1012323796749115,
            0.5729562640190125,
            0.7119978666305542,
            5.540987014770508,
            -2.802137613296509,
            3.2232611179351807,
            1.4296278953552246,
            0.42831122875213623,
            -1.4102002382278442,
            0.6871064901351929,
            0.07015472650527954,
            0.6089281439781189,
            -2.228748321533203,
            -0.06265830993652344,
            2.7453246116638184,
            1.5688666105270386,
            -3.477515697479248,
            -3.0341029167175293,
            -3.0513195991516113,
            -5.1588897705078125,
            1.4924275875091553,
            1.8581576347351074,
            -4.194301128387451,
            0.17393583059310913,
            4.105835437774658,
            2.2182815074920654,
            -3.7754948139190674,
            -2.0838494300842285,
            4.773046493530273,
            0.6286661028862,
            -2.33636212348938,
            3.354745388031006,
            -1.979871153831482,
            -4.188443183898926,
            -1.6433888673782349,
            -4.28304386138916,
            -0.34009090065956116,
            -0.9864563941955566,
            2.316370725631714,
            4.782803058624268,
            6.916333198547363,
            2.7287135124206543,
            -2.236848831176758,
            3.4929587841033936,
            5.688442230224609,
            2.6008708477020264,
            -1.9994145631790161,
            -0.07551127672195435,
            2.493917465209961,
            0.8769211769104004,
            -4.459626197814941,
            3.5134167671203613,
            0.9549394845962524,
            2.13942551612854,
            -3.046724319458008,
            -0.6453009843826294,
            -0.5408630967140198,
            0.9780784845352173,
            2.1572213172912598,
            0.9433429837226868,
            0.43931812047958374,
            -2.202971935272217,
            -0.49872931838035583,
            4.179543972015381,
            0.6767724752426147,
            4.558566093444824,
            0.7997176051139832,
            4.286355018615723,
            0.29413309693336487,
            1.4661285877227783,
            -2.587475061416626,
            -0.9996605515480042,
            2.371428966522217,
            -5.68471097946167,
            -0.5991560220718384,
            -1.458484172821045,
            1.022312045097351,
            4.103764533996582,
            -1.8038263320922852,
            -0.6338385939598083,
            -0.28758302330970764,
            1.3004767894744873,
            -4.168370246887207,
            5.365373611450195,
            0.6101277470588684,
            0.6668210625648499,
            0.17793583869934082,
            1.5660114288330078,
            -3.4645793437957764,
            -1.2320291996002197,
            0.3895207643508911,
            1.2355737686157227,
            -1.6519194841384888,
            -4.529646396636963,
            -4.069331645965576,
            2.66877818107605,
            -2.7588677406311035,
            0.4407714009284973,
            6.098499298095703,
            1.9548108577728271,
            2.186583995819092,
            -8.210774421691895,
            -1.094756841659546,
            0.8225584030151367,
            4.510061264038086,
            0.1328783929347992,
            -3.628133773803711,
            3.4231033325195312,
            3.635570764541626,
            1.7830150127410889,
            3.0364227294921875,
            0.6432247757911682,
            0.9396741390228271,
            3.802558422088623,
            4.6131591796875,
            1.478895664215088,
            -0.24751713871955872,
            0.142414391040802,
            -3.729243278503418,
            1.0110924243927002,
            1.6803061962127686,
            -1.4796427488327026,
            0.31447890400886536,
            -4.37443733215332,
            1.755812644958496,
            -0.6764872074127197,
            -3.3620331287384033,
            5.403223991394043,
            5.089271068572998,
            2.314817190170288,
            -3.271286964416504,
            -2.1649155616760254,
            -0.749459981918335,
            0.8381686806678772,
            -5.660140514373779,
            2.2921836376190186,
            -1.3976664543151855,
            2.726508617401123,
            3.140531539916992,
            -1.786054015159607,
            -0.0017995238304138184,
            0.21715497970581055,
            -2.347865343093872,
            0.25371694564819336,
            -1.7754722833633423,
            1.7723782062530518,
            0.8601748943328857,
            0.6471990942955017,
            -1.855228066444397,
            -1.202575445175171,
            2.0238840579986572,
            6.538239479064941,
            5.929989814758301,
            2.7978415489196777,
            3.628781318664551,
            -1.4962947368621826,
            -1.3684470653533936,
            -1.8812767267227173,
            1.3648827075958252,
            3.430311918258667,
            -5.25377082824707,
            -2.787003517150879,
            0.25312888622283936,
            2.89520001411438,
            -0.09463021159172058,
            3.893874406814575,
            -0.4015709161758423,
            3.2268576622009277,
            -4.0931596755981445,
            -2.693695068359375,
            -2.6033518314361572,
            0.501833975315094,
            1.0362865924835205,
            -1.1911742687225342,
            2.267369508743286,
            1.2063747644424438,
            -2.520989418029785,
            0.3752967417240143,
            -3.947685956954956,
            -0.7281175851821899,
            -0.8879913687705994,
            3.489175319671631,
            1.9440009593963623,
            -0.6557132005691528,
            1.68001127243042,
            1.0867830514907837,
            -1.1856725215911865,
            -1.4795453548431396,
            -1.8790309429168701,
            5.207976341247559,
            2.104863405227661,
            -2.693514585494995,
            -0.9241024255752563,
            -4.202147483825684,
            -1.6909393072128296,
            1.6652209758758545,
            -0.29607492685317993,
            3.3639395236968994,
            5.001838207244873,
            2.191924810409546,
            1.7119427919387817,
            -1.0035301446914673,
            -2.4814066886901855,
            -2.830918312072754,
            -1.0650687217712402,
            -5.59328031539917,
            -1.1341854333877563,
            -1.889327049255371,
            -2.6726205348968506,
            4.241756439208984,
            -3.20515775680542,
            -1.0572686195373535,
            2.781766891479492,
            -1.4403319358825684,
            -2.3196234703063965,
            -3.1483187675476074,
            1.96834135055542,
            -2.485276222229004,
            3.7332003116607666,
            0.06807723641395569,
            -0.8401908874511719,
            3.153937816619873,
            -0.22308480739593506,
            5.174723148345947,
            4.239943981170654,
            2.4539623260498047,
            1.822160005569458,
            -0.38055044412612915,
            4.244809150695801,
            -1.7834508419036865,
            -2.928464412689209,
            1.1279473304748535,
            -1.381152868270874,
            1.8348143100738525,
            15.585810661315918,
            0.07364299893379211,
            -0.7583894729614258,
            -0.0025923848152160645,
            -2.3418731689453125,
            -3.6341466903686523,
            -5.816903114318848,
            2.1620798110961914,
            -0.5011080503463745,
            0.6614120602607727,
            -1.2852911949157715,
            -1.6438838243484497,
            -0.7027926445007324,
            1.242272973060608,
            -1.5322628021240234,
            -1.2420257329940796,
            -1.1401773691177368,
            4.178593635559082,
            -0.4559707045555115,
            -0.6381075382232666,
            0.022144615650177002,
            0.3216177225112915,
            -0.8514137864112854,
            -1.816687822341919,
            -0.9734814167022705,
            4.5289530754089355,
            3.338836193084717,
            3.1403985023498535,
            -1.7314527034759521,
            -0.13239246606826782,
            1.3032443523406982,
            0.4627746343612671,
            -1.2127139568328857,
            0.935734748840332,
            -1.9653000831604004,
            4.2012553215026855,
            1.5210329294204712,
            -3.8052477836608887,
            2.4563169479370117,
            2.8191134929656982,
            -3.214128017425537,
            0.04444947838783264,
            -1.8128275871276855,
            -0.45076417922973633,
            -4.240281581878662,
            3.0770061016082764,
            1.7214103937149048,
            -1.7619218826293945,
            0.8412725329399109,
            4.985002040863037,
            -1.476170539855957,
            -2.437227725982666,
            -1.1903177499771118,
            0.21190345287322998,
            -2.8010120391845703,
            1.7483397722244263,
            3.2986137866973877,
            -4.944333076477051,
            2.0094587802886963,
            -3.1282434463500977,
            1.1016879081726074,
            -1.1401785612106323,
            -2.3153607845306396,
            -4.576083183288574,
            -2.2919692993164062,
            -1.2788965702056885,
            -4.927212715148926,
            0.07706630229949951,
            4.370687961578369,
            -1.02300226688385,
            2.4469175338745117,
            2.605389356613159,
            1.0639712810516357,
            -4.030817985534668,
            -0.5830823183059692,
            -4.953790664672852,
            1.873801589012146,
            -1.095656394958496,
            -1.656221866607666,
            7.296376705169678,
            -1.043753981590271,
            1.1387314796447754,
            -1.9526422023773193,
            -2.2942354679107666,
            3.1044082641601562,
            -0.9964630007743835,
            5.008575439453125,
            3.279913902282715,
            -0.914651095867157,
            0.20539888739585876,
            0.43487754464149475,
            -1.1978991031646729,
            2.0456697940826416,
            5.399965286254883,
            2.1711292266845703,
            -5.235404968261719,
            -3.290850877761841,
            -3.8844032287597656,
            -4.507502555847168,
            -1.6324645280838013,
            7.322807312011719,
            3.6317620277404785,
            0.22553394734859467,
            -3.126647710800171,
            -0.32123059034347534,
            1.3440529108047485,
            -3.666829824447632,
            -7.877147674560547,
            -2.7119622230529785,
            -4.32728385925293,
            3.8014090061187744,
            -4.3737382888793945,
            -2.590230703353882,
            -1.1177748441696167,
            2.917792797088623,
            -0.22881436347961426,
            2.6538963317871094,
            1.751572608947754,
            0.20662790536880493,
            4.668869972229004,
            2.085864543914795,
            -1.5923161506652832,
            -3.3803553581237793,
            -2.387138843536377,
            -2.145076274871826,
            -1.1248844861984253,
            2.4455976486206055,
            -2.547530174255371,
            0.07226943969726562,
            0.9199601411819458,
            0.07795286178588867,
            -2.203718662261963,
            -0.686398983001709,
            -0.5577444434165955,
            -1.3214709758758545,
            -2.2249979972839355,
            0.8789843916893005,
            -0.6708289980888367,
            -0.906140923500061,
            1.7028918266296387,
            2.782504081726074,
            -5.1445207595825195,
            -0.7548385858535767,
            10.64354133605957,
            0.6089598536491394,
            -0.11926184594631195,
            -2.8073744773864746,
            0.278418630361557,
            -0.9915949106216431,
            0.4277768135070801,
            1.00504732131958,
            2.826279640197754,
            0.6816902160644531,
            4.518232345581055,
            -1.9116559028625488,
            -4.799866199493408
        ]
    },
    "authors": [
        {
            "authorId": "2303800652",
            "name": "Adam Ibrahim"
        },
        {
            "authorId": "2217687159",
            "name": "Benjamin Th'erien"
        },
        {
            "authorId": "2291113135",
            "name": "Kshitij Gupta"
        },
        {
            "authorId": "2249531331",
            "name": "Mats L. Richter"
        },
        {
            "authorId": "2291068795",
            "name": "Quentin Anthony"
        },
        {
            "authorId": "26418330",
            "name": "Timoth\u00e9e Lesort"
        },
        {
            "authorId": "2064781956",
            "name": "Eugene Belilovsky"
        },
        {
            "authorId": "2239232896",
            "name": "Irina Rish"
        }
    ],
    "references": [
        {
            "paperId": "2797cbda8c845504119b62ee25deb1500ec2dfaf",
            "title": "DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence"
        },
        {
            "paperId": "3dd6bc488283f1e4cc967d98a6a6c3d7f1a6cf76",
            "title": "Zamba: A Compact 7B SSM Hybrid Model"
        },
        {
            "paperId": "53a803388e83ae89261624099d7be4287ace67cb",
            "title": "DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model"
        },
        {
            "paperId": "97352d95cc1fd9b7d9e959d61dd751a619975bfe",
            "title": "Arcee's MergeKit: A Toolkit for Merging Large Language Models"
        },
        {
            "paperId": "ad1bb59e3e18a0dd8503c3961d6074f162baf710",
            "title": "Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research"
        },
        {
            "paperId": "c3d1832ed0444f75d44116fabbdda891aebc4b01",
            "title": "LLaMA Pro: Progressive LLaMA with Block Expansion"
        },
        {
            "paperId": "04a340b15945c70e642227bf249639b171beb3f8",
            "title": "PLLaMa: An Open-source Large Language Model for Plant Science"
        },
        {
            "paperId": "e88d72202d449ad198308e21e7fa28680a8d2a21",
            "title": "EcomGPT-CT: Continual Pre-training of E-commerce Large Language Models with Semi-structured Data"
        },
        {
            "paperId": "2c0312c604f9f7638bb4533b39e0ae81e7f6ab12",
            "title": "The Falcon Series of Open Language Models"
        },
        {
            "paperId": "739cf040ed2c2af49077db48d489a46be5fb6157",
            "title": "Efficient Continual Pre-training for Building Domain Specific Large Language Models"
        },
        {
            "paperId": "f56ad6a6a588945c4ee9ddd7b0d1efef2f2f3f31",
            "title": "DiLoCo: Distributed Low-Communication Training of Language Models"
        },
        {
            "paperId": "21f005c5b15f5c41a45b76b733cb928dfc8e9b05",
            "title": "TiC-CLIP: Continual Training of CLIP Models"
        },
        {
            "paperId": "db633c6b1c286c0386f0078d8a2e6224e03a6227",
            "title": "Mistral 7B"
        },
        {
            "paperId": "193955704f66923ac20a664bd184ed4663b2bdf9",
            "title": "Continual Pre-Training of Large Language Models: How to (re)warm your model?"
        },
        {
            "paperId": "72e46cabbe8fcb8c25ba83c516bebd3c857943a3",
            "title": "Exploring Continual Learning for Code Generation Models"
        },
        {
            "paperId": "2651f0179874bd010f58d2c9fa7d118807c80977",
            "title": "TIES-Merging: Resolving Interference When Merging Models"
        },
        {
            "paperId": "67aff54dfbabf66193559b9467d60972fcf446c9",
            "title": "Online Continual Learning Without the Storage Constraint"
        },
        {
            "paperId": "b05cfda924a147dfc100dc0b3eea451c6db32868",
            "title": "Recyclable Tuning for Continual Pre-training"
        },
        {
            "paperId": "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d",
            "title": "A Survey of Large Language Models"
        },
        {
            "paperId": "3f9eb5b21c0e4488a2d83b2b665f2fbdea4ffd2e",
            "title": "How Efficient Are Today\u2019s Continual Learning Algorithms?"
        },
        {
            "paperId": "57e849d0de13ed5f91d086936296721d4ff75a75",
            "title": "LLaMA: Open and Efficient Foundation Language Models"
        },
        {
            "paperId": "e3ec55e9e6720194a0ed5d4033d93a941c8a4f99",
            "title": "Continual Pre-training of Language Models"
        },
        {
            "paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e",
            "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"
        },
        {
            "paperId": "296efa8421e3d304e6f7aaeff3aff089a31e52ae",
            "title": "Challenging Common Assumptions about Catastrophic Forgetting and Knowledge Accumulation"
        },
        {
            "paperId": "a08a3b08a5a1de6462a7da2906b1cd81691d6c18",
            "title": "CERT: Continual Pre-Training on Sketches for Library-Oriented Code Generation"
        },
        {
            "paperId": "58fc91ecbedf05e663495ff8f92b97279b9c2e3c",
            "title": "Continual evaluation for lifelong learning: Identifying the stability gap"
        },
        {
            "paperId": "d304d0bdfa81fd10b187aa0e4f41d410eb19d6e3",
            "title": "Fine-tuned Language Models are Continual Learners"
        },
        {
            "paperId": "b3bc37a15aa74c523d656ad89b1896651f5eef72",
            "title": "Continual Pre-Training Mitigates Forgetting in Language and Vision"
        },
        {
            "paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3",
            "title": "Flamingo: a Visual Language Model for Few-Shot Learning"
        },
        {
            "paperId": "a3ba7fdf789bcef381acd0d277a086428153bb9f",
            "title": "TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models"
        },
        {
            "paperId": "8342b592fe238f3d230e4959b06fd10153c45db1",
            "title": "Training Compute-Optimal Large Language Models"
        },
        {
            "paperId": "0b0d7d87c58d41b92d907347b778032be5966f60",
            "title": "Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer"
        },
        {
            "paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
            "title": "High-Resolution Image Synthesis with Latent Diffusion Models"
        },
        {
            "paperId": "b2d1fb4f78d24f03119f28a516ccabfc9591e71f",
            "title": "An Empirical Investigation of the Role of Pre-training in Lifelong Learning"
        },
        {
            "paperId": "68f141724814839d556a989646194be88641b143",
            "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"
        },
        {
            "paperId": "74ee70e3ecbb2a7123a14de75bee7d3d8514f1cb",
            "title": "Wide Neural Networks Forget Less Catastrophically"
        },
        {
            "paperId": "ce828f9986b196308a3e40b1de58af1e8e68d728",
            "title": "Towards Continual Knowledge Learning of Language Models"
        },
        {
            "paperId": "2a805d0e1b067444a554c5169d189fa1f649f411",
            "title": "Scaling Vision Transformers"
        },
        {
            "paperId": "228a0098d66c0df8532ea37027e3964d35f1030e",
            "title": "Understanding Continual Learning Settings with Data Distribution Drift Analysis"
        },
        {
            "paperId": "2154bdb9ce841eb98b9fd13bf7bf0a42f11f89a6",
            "title": "Moshpit SGD: Communication-Efficient Decentralized Training on Heterogeneous Unreliable Devices"
        },
        {
            "paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4",
            "title": "Learning Transferable Visual Models From Natural Language Supervision"
        },
        {
            "paperId": "4383a975c09b72ba2f1a77cd779bb6965dbfb2fb",
            "title": "Scaling Laws for Transfer"
        },
        {
            "paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e",
            "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"
        },
        {
            "paperId": "56912f12c35af9579999b45fe6ab7d5b9f090df6",
            "title": "Efficient Continual Learning with Modular Networks and Task-Driven Priors"
        },
        {
            "paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678",
            "title": "Measuring Massive Multitask Language Understanding"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "e816f788767eec6a8ef0ea9eddd0e902435d4271",
            "title": "Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks"
        },
        {
            "paperId": "e10b7cb072737b1fbdcba7948e573268b3573ae9",
            "title": "Dark Experience for General Continual Learning: a Strong, Simple Baseline"
        },
        {
            "paperId": "cf8fc87c3d624fb9a17b0d1192e835ef7308806e",
            "title": "Online Fast Adaptation and Knowledge Accumulation: a New Approach to Continual Learning"
        },
        {
            "paperId": "47c528344fedb6cb67a38e43d095b41c34715330",
            "title": "Adaptive Federated Optimization"
        },
        {
            "paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a",
            "title": "On Layer Normalization in the Transformer Architecture"
        },
        {
            "paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2",
            "title": "Scaling Laws for Neural Language Models"
        },
        {
            "paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45",
            "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"
        },
        {
            "paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
        },
        {
            "paperId": "00c957711b12468cb38424caccdf5291bb354033",
            "title": "ZeRO: Memory optimizations Toward Training Trillion Parameter Models"
        },
        {
            "paperId": "8e79f3bfb2b1fc3cfdf188a6aef046185a72170a",
            "title": "How Does Learning Rate Decay Help Modern Neural Networks"
        },
        {
            "paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a",
            "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"
        },
        {
            "paperId": "913f0771782023e2bf400e4d344eab7d2a674d23",
            "title": "Online Continual Learning with Maximally Interfered Retrieval"
        },
        {
            "paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0",
            "title": "Natural Questions: A Benchmark for Question Answering Research"
        },
        {
            "paperId": "80f9f109d1564cb8f82aa440a5f6f3fbe220c9ef",
            "title": "ERNIE 2.0: A Continual Pre-training Framework for Language Understanding"
        },
        {
            "paperId": null,
            "title": "Microsoft"
        },
        {
            "paperId": "eef7cfe8267954adbb4675576072a1d80ca7a3a8",
            "title": "MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms"
        },
        {
            "paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad",
            "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"
        },
        {
            "paperId": "9770fff7379a7ab9006b48939462354dda9a2053",
            "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"
        },
        {
            "paperId": "e9b88ab77abfc358ff79ef1355e1f3992d3abf00",
            "title": "Learning to Remember: A Synaptic Plasticity Driven Framework for Continual Learning"
        },
        {
            "paperId": "d9ff7a9344dd5d6653bd7a02bfd704422bb29951",
            "title": "Experience Replay for Continual Learning"
        },
        {
            "paperId": "d79a26226393f687ddbc375e32055b40b8ad8d38",
            "title": "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism"
        },
        {
            "paperId": "2b877889ac31b73d1ede70b00eb4c7118ef8eca2",
            "title": "Learning to Learn without Forgetting By Maximizing Transfer and Minimizing Interference"
        },
        {
            "paperId": "1536e8958697c5364f68b2e2448905dbbeb3a0ca",
            "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering"
        },
        {
            "paperId": "d3707cf521e3596313af1f53acba6413d0d528a6",
            "title": "Training Tips for the Transformer Model"
        },
        {
            "paperId": "88bb0a28bb58d847183ec505dda89b63771bb495",
            "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"
        },
        {
            "paperId": "d07284a6811f1b2745d91bdb06b040b57f226882",
            "title": "Decoupled Weight Decay Regularization"
        },
        {
            "paperId": "0d57ba12a6d958e178d83be4c84513f7e42b24e5",
            "title": "Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour"
        },
        {
            "paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c",
            "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"
        },
        {
            "paperId": "942deb7d865b7782c03176d95e3a0d56cb71009e",
            "title": "Training Deep Nets with Sublinear Memory Cost"
        },
        {
            "paperId": "d1dbf643447405984eeef098b1b320dee0b3b8a7",
            "title": "Communication-Efficient Learning of Deep Networks from Decentralized Data"
        },
        {
            "paperId": "1518039b5001f1836565215eb047526b3ac7f462",
            "title": "Neural Machine Translation of Rare Words with Subword Units"
        },
        {
            "paperId": "3039ceebdf1b2f4831482a64ee1646b1414e790b",
            "title": "The stability-plasticity dilemma: investigating the continuum from catastrophic forgetting to age-limited learning effects"
        },
        {
            "paperId": "6845e11d6263a7e620c82e1123f5e2f4d8e7a60a",
            "title": "Natural Questions"
        },
        {
            "paperId": "2722b9e5ab8da95f03e578bb65879c452c105385",
            "title": "Catastrophic forgetting in connectionist networks"
        },
        {
            "paperId": "48af7fe0a2769363f88d08cd7871178d507761bc",
            "title": "W\u00fcrstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models"
        },
        {
            "paperId": "15b4748d5929d0352c164a8732c82536d073689e",
            "title": "Towards better structured and less noisy Web data: Oscar with Register annotations"
        },
        {
            "paperId": "b584309dccafe64a7d6b96f064554330cbe1bbd3",
            "title": "Effect of scale on catastrophic forgetting in neural networks"
        },
        {
            "paperId": "15789db234a9338e57aff9709868dcbd290727d3",
            "title": "Continual Pre-training of Language Models for Math Problem Understanding with Syntax-Aware Memory Network"
        },
        {
            "paperId": null,
            "title": "An English benchmark designed to evaluate both zero-shot and few-shot scenarios, in order to evaluate both the general knowledge and on-the-fly problem solving of the model under test."
        },
        {
            "paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28",
            "title": "An Adversarial Winograd Schema Challenge at Scale"
        },
        {
            "paperId": null,
            "title": "An English question-answering benchmark designed to test the physical commonsense reasoning abilities of the model"
        },
        {
            "paperId": null,
            "title": "An English math word problem benchmark composed of multiple-choice questions across various areas of mathematics"
        },
        {
            "paperId": null,
            "title": "Is an English question-answering benchmark comprised of question-answer pairs provided by trivia enthusiasts."
        },
        {
            "paperId": "8834919f0240ddd5f7c63e94ab30cad5195f8131",
            "title": "\u8425\u9500\u65e0\u754c\uff0cAlways on"
        },
        {
            "paperId": "f7ad35a51c59ff24fcd2d7f438a96bbfb922bde5",
            "title": "Measuring Models"
        },
        {
            "paperId": null,
            "title": "Annealing phase \u2013 The learning rate is annealed to a small value \u03b7 min over T ann timesteps from timestep t ann to t end = t ann + T ann , helping train the model to convergence before being deployed"
        },
        {
            "paperId": null,
            "title": "Gemma"
        },
        {
            "paperId": null,
            "title": "SlimPa-jama: A 627B token cleaned and deduplicated version of RedPajama"
        },
        {
            "paperId": null,
            "title": "Video generation models as world simulators"
        },
        {
            "paperId": null,
            "title": "GPT-NeoX: Large Scale Autoregressive Language Modeling in"
        },
        {
            "paperId": null,
            "title": "Together Computer"
        },
        {
            "paperId": null,
            "title": "A study of continual learning under language shift"
        }
    ]
}