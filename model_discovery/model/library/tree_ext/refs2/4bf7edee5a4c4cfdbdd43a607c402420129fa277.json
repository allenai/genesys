{
    "paperId": "4bf7edee5a4c4cfdbdd43a607c402420129fa277",
    "externalIds": {
        "MAG": "2951290603",
        "DBLP": "conf/iclr/SeoMFH17",
        "CorpusId": 1460418
    },
    "title": "Query-Reduction Networks for Question Answering",
    "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.",
    "venue": "International Conference on Learning Representations",
    "year": 2016,
    "referenceCount": 33,
    "citationCount": 100,
    "influentialCitationCount": 19,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term and long-term sequential dependencies to reason over multiple facts, is proposed."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "4418074",
            "name": "Minjoon Seo"
        },
        {
            "authorId": "48872685",
            "name": "Sewon Min"
        },
        {
            "authorId": "143787583",
            "name": "Ali Farhadi"
        },
        {
            "authorId": "2548384",
            "name": "Hannaneh Hajishirzi"
        }
    ],
    "references": [
        {
            "paperId": "63a6a8ce2ad114b38d0fff30e71cf973529a9b5b",
            "title": "Gated End-to-End Memory Networks"
        },
        {
            "paperId": "784ee73d5363c711118f784428d1ab89f019daa5",
            "title": "Hybrid computing using a neural network with dynamic external memory"
        },
        {
            "paperId": "05dd7254b632376973f3a1b4d39485da17814df5",
            "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"
        },
        {
            "paperId": "f81be44000814e7bcb12ae04b4e2d9c01b6515b3",
            "title": "Learning End-to-End Goal-Oriented Dialog"
        },
        {
            "paperId": "9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d",
            "title": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems"
        },
        {
            "paperId": "f96898d15a1bf1fa8925b1280d0e07a7a8e72194",
            "title": "Dynamic Memory Networks for Visual and Textual Question Answering"
        },
        {
            "paperId": "7ed797b646aa333e4e1dfa174b4117c634353ee2",
            "title": "Addressing a Question Answering Challenge by Combining Statistical Methods with Inductive Rule Learning and Reasoning"
        },
        {
            "paperId": "7e45b68037b5f86c4bce305b2725f4871c6b091e",
            "title": "Strongly-Typed Recurrent Neural Networks"
        },
        {
            "paperId": "35b91b365ceb016fb3e022577cec96fb9b445dc5",
            "title": "The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations"
        },
        {
            "paperId": "c87dccf7c21e67679389f23f86f039cd96720c3f",
            "title": "Solving Geometry Problems: Combining Text and Diagram Interpretation"
        },
        {
            "paperId": "4d05ab884a6c1645b80ce5d02b09c7e5ff499790",
            "title": "Towards Neural Network-based Reasoning"
        },
        {
            "paperId": "452059171226626718eb677358836328f884298e",
            "title": "Ask Me Anything: Dynamic Memory Networks for Natural Language Processing"
        },
        {
            "paperId": "d1505c6123c102e53eb19dff312cb25cea840b72",
            "title": "Teaching Machines to Read and Comprehend"
        },
        {
            "paperId": "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e",
            "title": "End-To-End Memory Networks"
        },
        {
            "paperId": "abb33d75dc297993fcc3fb75e0f4498f413eb4f6",
            "title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks"
        },
        {
            "paperId": "9665247ea3421929f9b6ad721f139f11edb1dbb8",
            "title": "Learning Longer Memory in Recurrent Neural Networks"
        },
        {
            "paperId": "71ae756c75ac89e2d731c9c79649562b5768ff39",
            "title": "Memory Networks"
        },
        {
            "paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e",
            "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"
        },
        {
            "paperId": "078b55e2f4899cf95a4c8d65613c340fa190acf8",
            "title": "The Second Dialog State Tracking Challenge"
        },
        {
            "paperId": "564257469fa44cdb57e4272f85253efb9acfd69d",
            "title": "MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text"
        },
        {
            "paperId": "b29447ba499507a259ae9d8f685d60cc1597d7d3",
            "title": "Semantic Parsing on Freebase from Question-Answer Pairs"
        },
        {
            "paperId": "c0be2ac2f45681f1852fc1d298af5dceb85834f4",
            "title": "Paraphrase-Driven Learning for Open Question Answering"
        },
        {
            "paperId": "80c2d8c691b09f8b4e53f512b9d2641b49fda935",
            "title": "Large-scale Semantic Parsing via Schema Matching and Lexicon Extension"
        },
        {
            "paperId": "413c1142de9d91804d6d11c67ff3fed59c9fc279",
            "title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization"
        },
        {
            "paperId": "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649",
            "title": "Understanding the difficulty of training deep feedforward neural networks"
        },
        {
            "paperId": "5bca4ea91e35f5f8216aa453da0e65b6636f191a",
            "title": "Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems"
        },
        {
            "paperId": "c4ff3e96d374a7f87f8714b6c76d30702a7c3359",
            "title": "Knowledge in Action"
        },
        {
            "paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10",
            "title": "Long Short-Term Memory"
        },
        {
            "paperId": "bcd857d75841aa3e92cd4284a8818aba9f6c0c3f",
            "title": "Published as a conference paper at ICLR 2018 S IMULATING A CTION D YNAMICS WITH N EURAL P ROCESS N ETWORKS"
        },
        {
            "paperId": null,
            "title": "2016). We use answer candidate embedding matrix, and add 2 dimension of 0-1 matrix which expresses whether the answer candidate matches with any word in the paragraph and the question"
        },
        {
            "paperId": null,
            "title": "Differentiable Neural Computer(DNC"
        },
        {
            "paperId": null,
            "title": "Mustafa Suleyman, and Phil Blunsom. Teaching machines to read and comprehend. In NIPS"
        },
        {
            "paperId": null,
            "title": "Average error rates"
        }
    ]
}