{
    "paperId": "f22f6972e66bdd2e769fa64b0df0a13063c0c101",
    "externalIds": {
        "DBLP": "journals/nn/HornikSW89",
        "MAG": "2137983211",
        "DOI": "10.1016/0893-6080(89)90020-8",
        "CorpusId": 2757547
    },
    "title": "Multilayer feedforward networks are universal approximators",
    "abstract": null,
    "venue": "Neural Networks",
    "year": 1989,
    "referenceCount": 25,
    "citationCount": 20978,
    "influentialCitationCount": 499,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is rigorously established that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available."
    },
    "embedding": null,
    "authors": [
        {
            "authorId": "1764952",
            "name": "K. Hornik"
        },
        {
            "authorId": "2964655",
            "name": "M. Stinchcombe"
        },
        {
            "authorId": "2149702798",
            "name": "H. White"
        }
    ],
    "references": [
        {
            "paperId": "ee7f0bc85b339d781c2e0c7e6db8e339b6b9fec2",
            "title": "Universal approximation using feedforward networks with non-sigmoid hidden layer activation functions"
        },
        {
            "paperId": "8da1dda34ecc96263102181448c94ec7d645d085",
            "title": "Approximation by superpositions of a sigmoidal function"
        },
        {
            "paperId": "60b7c281f3a677274b7126c67b7f4059c631b1ea",
            "title": "There exists a neural network that does not make avoidable mistakes"
        },
        {
            "paperId": "8a392cb17eb8074e0c5e5d1b47264b8857c7b54a",
            "title": "Nonlinear dynamics of artificial neural systems"
        },
        {
            "paperId": "635002028da357f80e6e39dc04356990c3eaaf6d",
            "title": "The logic of activation functions"
        },
        {
            "paperId": "4bb08f30bb2c83334b21fbbc68c3f2622d4fb04b",
            "title": "Parallel distributed processing: explorations in the microstructure of cognition, vol. 1: foundations"
        },
        {
            "paperId": "7b4b0fecdb43b0cdd8abd4e504b43de4e10897d1",
            "title": "Probability and Measure"
        },
        {
            "paperId": "300328d09233d3ada652d6aace66353c3bdb5762",
            "title": "On the Representation of Continuous Functions of Several Variables as Superpositions of Continuous Functions of one Variable and Addition"
        },
        {
            "paperId": "e96586f330e8d7011317b298524f66990008704c",
            "title": "Theory of the Back Propagation Neural Network"
        },
        {
            "paperId": null,
            "title": "How neural networks work (Tech. Rep. LA-UR-88-418)"
        },
        {
            "paperId": null,
            "title": "The case for conceptual and operational separation of network architectures and learning mechanisms (Discussion Paper 88-21)"
        },
        {
            "paperId": null,
            "title": "Multilayer feedforward networks can learn arbitrary mappings: Connectionist nonparametric regression with automatic and semi-automatic determination of network complexity (Discussion Paper)"
        },
        {
            "paperId": null,
            "title": "Multilayer feedforward networks are universal approximators (Discussion Paper 88-45)"
        },
        {
            "paperId": null,
            "title": "San Diego: SOS Printing"
        },
        {
            "paperId": null,
            "title": "Capabilities of three layer percep - trans"
        },
        {
            "paperId": "257843bde91001dc94fffdba287879fcb3b2f89a",
            "title": "Kolmogorov''s Mapping Neural Network Existence Theorem"
        },
        {
            "paperId": "70a0ed1d60bdccee721ec6437e7d1c55c96d887a",
            "title": "IEEE First International Conference on Neural Networks : Sheraton Harbor Island East, San Diego, California, June 21-24, 1987"
        },
        {
            "paperId": null,
            "title": "C.\u2018onvergence rates of maximum likelihood and related estimates in general parameter vpaces (Working Paper)"
        },
        {
            "paperId": null,
            "title": "Modeles connexiontstes de l\u2019upprentissage"
        },
        {
            "paperId": null,
            "title": "Abstract inference"
        },
        {
            "paperId": null,
            "title": "The thirteenth problem of Hilbert"
        },
        {
            "paperId": null,
            "title": "Perceprrons"
        },
        {
            "paperId": "88263b99ae7d88ae8719ad463e171058686349f0",
            "title": "Principles of mathematical analysis"
        },
        {
            "paperId": null,
            "title": "E-entropy and e-capacity of sets in functional spaces"
        },
        {
            "paperId": null,
            "title": "Some results for sieve estimation with dependent observations"
        }
    ]
}