{
    "paperId": "164a79729f6134ea81f80b38d5b95d9d7307c774",
    "externalIds": {
        "DBLP": "journals/pr/WangGTLHL23",
        "DOI": "10.1016/j.patcog.2022.109259",
        "CorpusId": 254757579
    },
    "title": "TETFN: A text enhanced transformer fusion network for multimodal sentiment analysis",
    "abstract": null,
    "venue": "Pattern Recognition",
    "year": 2022,
    "referenceCount": 45,
    "citationCount": 52,
    "influentialCitationCount": 2,
    "openAccessPdf": null,
    "tldr": null,
    "embedding": null,
    "authors": [
        {
            "authorId": "2119264226",
            "name": "Di Wang"
        },
        {
            "authorId": "115274800",
            "name": "Xutong Guo"
        },
        {
            "authorId": "2207890",
            "name": "Yu-min Tian"
        },
        {
            "authorId": "2135256722",
            "name": "Jinhui Liu"
        },
        {
            "authorId": "1753049",
            "name": "Lihuo He"
        },
        {
            "authorId": "48122280",
            "name": "Xuemei Luo"
        }
    ],
    "references": [
        {
            "paperId": "7d2104fd8c7f3b35ceb6d4197cd3ded3df1eb3c1",
            "title": "Multimodal channel-wise attention transformer inspired by multisensory integration mechanisms of the brain"
        },
        {
            "paperId": "a3c7ee84cf29f3e72fd680a0a36b85d28f9a5c1b",
            "title": "Bi-Bimodal Modality Fusion for Correlation-Controlled Multimodal Sentiment Analysis"
        },
        {
            "paperId": "897937116ac0645e7d8f0d539b68545a6116191f",
            "title": "Learning Modality-Specific Representations with Self-Supervised Multi-Task Learning for Multimodal Sentiment Analysis"
        },
        {
            "paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
        },
        {
            "paperId": "33172567ab1dff9ca32c8d995d88bbff466f3236",
            "title": "Integrating Multimodal Information in Large Pretrained Transformers"
        },
        {
            "paperId": "dde6151c4e82cbfd573e3ec1d1a36af4a1121220",
            "title": "MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis"
        },
        {
            "paperId": "3f2e7e083a3837573a4c456f468d90c5a54967d1",
            "title": "Learning Relationships between Text, Audio, and Video via Deep Canonical Correlation for Multimodal Language Analysis"
        },
        {
            "paperId": "9d7902e834d5d1d35179962c7a5b9d16623b0d39",
            "title": "How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings"
        },
        {
            "paperId": "4aa6298b606941a282d735fa3143da293199d2ca",
            "title": "VL-BERT: Pre-training of Generic Visual-Linguistic Representations"
        },
        {
            "paperId": "65a9c7b0800c86a196bc14e7621ff895cc6ab287",
            "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"
        },
        {
            "paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de",
            "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"
        },
        {
            "paperId": "9e43330f452a3ce3a946464214f2c3865eb7c7e4",
            "title": "Divide, Conquer and Combine: Hierarchical Feature Fusion Network with Local and Global Perspectives for Multimodal Affective Computing"
        },
        {
            "paperId": "2609821b209198d97a016d9f4e95d8aad6b5cf6a",
            "title": "Graph-based multimodal fusion with metric learning for multimodal classification"
        },
        {
            "paperId": "949fef650da4c41afe6049a183b504b3cc91f4bd",
            "title": "Multimodal Transformer for Unaligned Multimodal Language Sequences"
        },
        {
            "paperId": "7812022785cf5f3fa331d011df57a2ddce5ea082",
            "title": "Strong and Simple Baselines for Multimodal Utterance Embeddings"
        },
        {
            "paperId": "ff9a94031385c61db8a402a4df95146a08cfcdb2",
            "title": "Multimodal Sentiment Analysis via RNN variants"
        },
        {
            "paperId": "d581e8fd6bb0c1eccb88084bf281beb4f94358c7",
            "title": "Found in Translation: Learning Robust Joint Representations by Cyclic Translations Between Modalities"
        },
        {
            "paperId": "96e05dd7f08df72f57b22ebf67a7bd5b5b797989",
            "title": "Learning visual and textual representations for multimodal matching and classification"
        },
        {
            "paperId": "5d9273f34a6418c0291dd63f89810896962289e2",
            "title": "Words Can Shift: Dynamically Adjusting Word Representations Using Nonverbal Behaviors"
        },
        {
            "paperId": "006fdeff6e1a81c404317ee4056d6cc72f9c0e50",
            "title": "Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph"
        },
        {
            "paperId": "034f1c5589644a6b42f50bf61b1628a1c5607fd9",
            "title": "Learning Factorized Multimodal Representations"
        },
        {
            "paperId": "0b5aef2894d3248fb5ecc955d50501f0aa276036",
            "title": "Multimodal Sentiment Analysis using Hierarchical Fusion with Context Modeling"
        },
        {
            "paperId": "949cc039d4c5fea8313e2d7d67fbd95a15b18259",
            "title": "Investigating Audio, Video, and Text Fusion Methods for End-to-End Automatic Personality Prediction"
        },
        {
            "paperId": "609512f19e06bf393cb79fbf57183f75b8d889d2",
            "title": "Memory Fusion Network for Multi-view Sequential Learning"
        },
        {
            "paperId": "86405b78521d6b27290d5bae069a952137035ad7",
            "title": "Multi-level Multiple Attentions for Contextual Multimodal Sentiment Analysis"
        },
        {
            "paperId": "3a84214cb69ea0b34352285029f368b75718c32b",
            "title": "Understanding of a convolutional neural network"
        },
        {
            "paperId": "5a96f2bfa2deae2bc35b250251d5fbe82ef4932b",
            "title": "Tensor Fusion Network for Multimodal Sentiment Analysis"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "32cc8287887f4eeaf133c5e058e63e3b6d4bb39b",
            "title": "Neural Bag-of-Ngrams"
        },
        {
            "paperId": "0d21cc2677e544b46673ff19ad4f378f32129069",
            "title": "Convolutional MKL Based Multimodal Emotion Recognition and Sentiment Analysis"
        },
        {
            "paperId": "ed1fe0b01c0e97fa840dc4d9f020e8ce1f7ea3c7",
            "title": "Multilayer and Multimodal Fusion of Deep Neural Networks for Video Classification"
        },
        {
            "paperId": "1389564ab24d4b63c921a1ed564e5410b5199f7d",
            "title": "MOSI: Multimodal Corpus of Sentiment Intensity and Subjectivity Analysis in Online Opinion Videos"
        },
        {
            "paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
            "title": "GloVe: Global Vectors for Word Representation"
        },
        {
            "paperId": "511cbe73e535d9afb6c2c4f37c93a7f0e7d54f28",
            "title": "COVAREP \u2014 A collaborative voice analysis repository for speech technologies"
        },
        {
            "paperId": "0a7d07d1fa0b77160347e5baa1687e2df0a8cc61",
            "title": "Are They Different? Affect, Feeling, Emotion, Sentiment, and Opinion Detection in Text"
        },
        {
            "paperId": "ec55a1835fe496d052c0df691539b6ecda61acbc",
            "title": "Detection of Glottal Closure Instants From Speech Signals: A Quantitative Review"
        },
        {
            "paperId": "4eb600aa4071b9a73da49e5374d6e22ca46eaba6",
            "title": "Understanding bag-of-words model: a statistical framework"
        },
        {
            "paperId": "c14f33e11bc1f2b5fee93b3ce4e8046433e26e11",
            "title": "Sentiment analysis: A combined approach"
        },
        {
            "paperId": "6eaecfcb51a3edd5fb7b25c3d7a20f555b9e7b76",
            "title": "A tutorial on?-support vector machines"
        },
        {
            "paperId": "e42cbd2dd928367da98b4fa056de2b9b29e39ed8",
            "title": "CTFN: Hierarchical Learning for Multimodal Sentiment Analysis Using Coupled-Translation Fusion Network"
        },
        {
            "paperId": "2f6f5ec900352d90456073322daadd59d757ddba",
            "title": "Multi-task learning for gait-based identity recognition and emotion recognition using attention enhanced temporal graph convolutional network"
        },
        {
            "paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": "8e54dd2b426b8d656a77c155818a87dd34c40754",
            "title": "Long Short Term Memory Networks for Anomaly Detection in Time Series"
        },
        {
            "paperId": null,
            "title": "A brief tutorial on maxent"
        },
        {
            "paperId": "2825733f97124013e8841b3f8a0f5bd4ee4af88a",
            "title": "An empirical study of the naive Bayes classifier"
        }
    ]
}