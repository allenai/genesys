{
    "acronym": "ceba5c0dca926cf4d60d98e219a611dcd50f470d",
    "title": "The Progression of Transformers from Language to Vision to MOT: A Literature Review on Multi-Object Tracking with Transformers",
    "seed_ids": [
        "transformer",
        "2cd605106b88c85d7d8b865b1ef0f8c8293debf1"
    ],
    "s2id": "ceba5c0dca926cf4d60d98e219a611dcd50f470d",
    "abstract": "The transformer neural network architecture allows for autoregressive sequence-to-sequence modeling through the use of attention layers. It was originally created with the application of machine translation but has revolutionized natural language processing. Recently, transformers have also been applied across a wide variety of pattern recognition tasks, particularly in computer vision. In this literature review, we describe major advances in computer vision utilizing transformers. We then focus specifically on Multi-Object Tracking (MOT) and discuss how transformers are increasingly becoming competitive in state-of-the-art MOT works, yet still lag behind traditional deep learning methods.",
    "authors": [
        "Abhi Kamboj"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This literature review of transformer neural network architecture focuses specifically on Multi-Object Tracking and discusses how transformers are increasingly becoming competitive in state-of-the-art MOT works, yet still lag behind traditional deep learning methods."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}