{
    "acronym": "9bbcc6eb7ab49ebed302118a98c9e28ea88987b2",
    "title": "Retrieval is Accurate Generation",
    "seed_ids": [
        "gpt2",
        "8b25d0065d30ed3c9e6a6cae94de53ef132d656d",
        "5697a0ede5425954d48daa6e1893dc87bd7d8be7",
        "da1d6445b6b64ce9eb4587ba8abbdc490f648ec1",
        "13a0d8bb38f739990c8cd65a44061c6534f17221",
        "492a655a67e6ec7423a968cedb70eec0cdbc8e98",
        "46c585ee9abf76779ea4b863d2da4358efd0d1d3",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "9bbcc6eb7ab49ebed302118a98c9e28ea88987b2",
    "abstract": "Standard language models generate text by selecting tokens from a fixed, finite, and standalone vocabulary. We introduce a novel method that selects context-aware phrases from a collection of supporting documents. One of the most significant challenges for this paradigm shift is determining the training oracles, because a string of text can be segmented in various ways and each segment can be retrieved from numerous possible documents. To address this, we propose to initialize the training oracles using linguistic heuristics and, more importantly, bootstrap the oracles through iterative self-reinforcement. Extensive experiments show that our model not only outperforms standard language models on a variety of knowledge-intensive tasks but also demonstrates improved generation quality in open-ended text generation. For instance, compared to the standard language model counterpart, our model raises the accuracy from 23.47% to 36.27% on OpenbookQA, and improves the MAUVE score from 42.61% to 81.58% in open-ended text generation. Remarkably, our model also achieves the best performance and the lowest latency among several retrieval-augmented baselines. In conclusion, we assert that retrieval is more accurate generation and hope that our work will encourage further research on this new paradigm shift.",
    "authors": [
        "Bowen Cao",
        "Deng Cai",
        "Leyang Cui",
        "Xuxin Cheng",
        "Wei Bi",
        "Yuexian Zou",
        "Shuming Shi"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel method that selects context-aware phrases from a collection of supporting documents is introduced that achieves the best performance and the lowest latency among several retrieval-augmented baselines and asserts that retrieval is more accurate generation."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}