{
    "acronym": "26070516a42646deab6100b5c5a50c5bd9e36cb4",
    "title": "A unified multi-task learning model for AST-level and token-level code completion",
    "seed_ids": [
        "transformerxl",
        "49cf6a22a5dac5bc98b653534af65ffa0bc0e76d",
        "0fe2636446cd686830da3d971b31a004d6094b3c",
        "40df572b0fbeae0f3db9b364be838c6467d189f2"
    ],
    "s2id": "26070516a42646deab6100b5c5a50c5bd9e36cb4",
    "abstract": null,
    "authors": [
        "F. Liu",
        "Ge Li",
        "Bolin Wei",
        "Xin Xia",
        "Zhiyi Fu",
        "Zhi Jin"
    ],
    "venue": "Empirical Software Engineering",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A unified multi-task learning based code completion model for both AST-level and token-level code completion that captures the long-term dependency in the input programs and employs a self-attentional architecture based network as the base language model."
    },
    "citationCount": 19,
    "influentialCitationCount": 2,
    "code": null,
    "description": null,
    "url": null
}