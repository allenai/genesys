{
    "acronym": "6bd2925ac5ae8498994e4dde4e2d22b90e0071dc",
    "title": "Soft Masked Mamba Diffusion Model for CT to MRI Conversion",
    "seed_ids": [
        "s4",
        "f73c70994599030511cce7248514bd39ceeebb8e",
        "3af7273d7ca20c0c63cbaa47e60b058840835052",
        "1df04f33a8ef313cc2067147dbb79c3ca7c5c99f",
        "6d7d141c75af752ffc0d8a6184cca3f9323d6c74",
        "eaef083b9d661f42cc0d89d9d8156218f33a91d9",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "ca9047c78d48b606c4e4f0c456b1dda550de28b2",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7"
    ],
    "s2id": "6bd2925ac5ae8498994e4dde4e2d22b90e0071dc",
    "abstract": "Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) are the predominant modalities utilized in the field of medical imaging. Although MRI capture the complexity of anatomical structures with greater detail than CT, it entails a higher financial costs and requires longer image acquisition times. In this study, we aim to train latent diffusion model for CT to MRI conversion, replacing the commonly-used U-Net or Transformer backbone with a State-Space Model (SSM) called Mamba that operates on latent patches. First, we noted critical oversights in the scan scheme of most Mamba-based vision methods, including inadequate attention to the spatial continuity of patch tokens and the lack of consideration for their varying importance to the target task. Secondly, extending from this insight, we introduce Diffusion Mamba (DiffMa), employing soft masked to integrate Cross-Sequence Attention into Mamba and conducting selective scan in a spiral manner. Lastly, extensive experiments demonstrate impressive performance by DiffMa in medical image generation tasks, with notable advantages in input scaling efficiency over existing benchmark models. The code and models are available at https://github.com/wongzbb/DiffMa-Diffusion-Mamba",
    "authors": [
        "Zhenbin Wang",
        "Lei Zhang",
        "Lituan Wang",
        "Zhenwei Zhang"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This study aims to train latent diffusion model for CT to MRI conversion, replacing the commonly-used U-Net or Transformer backbone with a State-Space Model (SSM) called Mamba that operates on latent patches that operates on latent patches."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}