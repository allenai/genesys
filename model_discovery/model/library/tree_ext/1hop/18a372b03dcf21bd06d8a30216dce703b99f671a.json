{
    "acronym": "18a372b03dcf21bd06d8a30216dce703b99f671a",
    "title": "Vision-and-Language Navigation Generative Pretrained Transformer",
    "seed_ids": [
        "transformer",
        "gpt2",
        "104f75283ae9027eb478e7984bd26b680277ce6f",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "18a372b03dcf21bd06d8a30216dce703b99f671a",
    "abstract": "In the Vision-and-Language Navigation (VLN) field, agents are tasked with navigating real-world scenes guided by linguistic instructions. Enabling the agent to adhere to instructions throughout the process of navigation represents a significant challenge within the domain of VLN. To address this challenge, common approaches often rely on encoders to explicitly record past locations and actions, increasing model complexity and resource consumption. Our proposal, the Vision-and-Language Navigation Generative Pretrained Transformer (VLN-GPT), adopts a transformer decoder model (GPT2) to model trajectory sequence dependencies, bypassing the need for historical encoding modules. This method allows for direct historical information access through trajectory sequence, enhancing efficiency. Furthermore, our model separates the training process into offline pre-training with imitation learning and online fine-tuning with reinforcement learning. This distinction allows for more focused training objectives and improved performance. Performance assessments on the VLN dataset reveal that VLN-GPT surpasses complex state-of-the-art encoder-based models.",
    "authors": [
        "Hanlin Wen"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This proposal adopts a transformer decoder model (GPT2) to model trajectory sequence dependencies, bypassing the need for historical encoding modules, and separates the training process into offline pre-training with imitation learning and online fine-tuning with reinforcement learning."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}