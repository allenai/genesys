{
    "acronym": "d288b03efdea01d96dc1666bef13db71ea2d9deb",
    "title": "A Study on Performance Improvement of Prompt Engineering for Generative AI with a Large Language Model",
    "seed_ids": [
        "bert",
        "8cf819f6ee33909484ece40d79944c9c37f01a89",
        "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d",
        "3bcb17559ce96eb20fa79af8194f4af0380d194a",
        "7a15950dc71079285a4eaf195de5aadd87c41b40",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "d288b03efdea01d96dc1666bef13db71ea2d9deb",
    "abstract": "In the realm of Generative AI, where various models are introduced, prompt engineering emerges as a significant technique within natural language processing-based Generative AI. Its primary function lies in effectively enhancing the results of sentence generation by large language models (LLMs). Notably, prompt engineering has gained attention as a method capable of improving LLM performance by modifying the structure of input prompts alone. In this study, we apply prompt engineering to Korean-based LLMs, presenting an efficient approach for generating specific conversational responses with less data. We achieve this through the utilization of the query transformation module (QTM). Our proposed QTM transforms input prompt sentences into three distinct query methods, breaking them down into objectives and key points, making them more comprehensible for LLMs. For performance validation, we employ Korean versions of LLMs, specifically SKT GPT-2 and Kakaobrain KoGPT-3. We compare four different query methods, including the original unmodified query, using Google SSA to assess the naturalness and specificity of generated sentences. The results demonstrate an average improvement of 11.46% when compared to the unmodified query, underscoring the efficacy of the proposed QTM in achieving enhanced performance.",
    "authors": [
        "Daeseung Park",
        "Gi-taek An",
        "Chayapol Kamyod",
        "Cheong-Ghil Kim"
    ],
    "venue": "Journal of Web Engineering",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This study applies prompt engineering to Korean-based LLMs, presenting an efficient approach for generating specific conversational responses with less data through the utilization of the query transformation module (QTM)."
    },
    "citationCount": 3,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}