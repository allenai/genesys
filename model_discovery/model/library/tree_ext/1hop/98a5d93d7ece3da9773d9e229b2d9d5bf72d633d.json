{
    "acronym": "98a5d93d7ece3da9773d9e229b2d9d5bf72d633d",
    "title": "PharmGPT: Domain-Specific Large Language Models for Bio-Pharmaceutical and Chemistry",
    "seed_ids": [
        "gpt",
        "1d26c947406173145a4665dd7ab255e03494ea28",
        "13a0d8bb38f739990c8cd65a44061c6534f17221",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "a3184d40d390793232c99c89b57b8f65c16320b2",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "8323c591e119eb09b28b29fd6c7bc76bd889df7a",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "98a5d93d7ece3da9773d9e229b2d9d5bf72d633d",
    "abstract": "Large language models (LLMs) have revolutionized Natural Language Processing (NLP) by by minimizing the need for complex feature engineering. However, the application of LLMs in specialized domains like biopharmaceuticals and chemistry remains largely unexplored. These fields are characterized by intricate terminologies, specialized knowledge, and a high demand for precision areas where general purpose LLMs often fall short. In this study, we introduce PharmGPT, a suite of multilingual LLMs with 13 billion and 70 billion parameters, specifically trained on a comprehensive corpus of hundreds of billions of tokens tailored to the Bio-Pharmaceutical and Chemical sectors. Our evaluation shows that PharmGPT matches or surpasses existing general models on key benchmarks, such as NAPLEX, demonstrating its exceptional capability in domain-specific tasks. This advancement establishes a new benchmark for LLMs in the Bio-Pharmaceutical and Chemical fields, addressing the existing gap in specialized language modeling. Furthermore, this suggests a promising path for enhanced research and development in these specialized areas, paving the way for more precise and effective applications of NLP in specialized domains.",
    "authors": [
        "Linqing Chen",
        "Weilei Wang",
        "Zilong Bai",
        "Peng Xu",
        "Yan Fang",
        "Jie Fang",
        "Wentao Wu",
        "Lizhi Zhou",
        "Ruiji Zhang",
        "Yu-Nong Xia",
        "Chaobo Xu",
        "Ran Hu",
        "Licong Xu",
        "Qijun Cai",
        "Haoran Hua",
        "Jing Sun",
        "Jin Liu",
        "Tian Qiu",
        "Haowen Liu",
        "Meng Hu",
        "Xiuwen Li",
        "Fei Gao",
        "Yufu Wang",
        "Lin Tie",
        "Chaochao Wang",
        "Jianping Lu",
        "Cheng Sun",
        "Yixin Wang",
        "Shengjie Yang",
        "Yuancheng Li",
        "Lu Jin",
        "Lisha Zhang",
        "Fu Bian",
        "Changyang Tu"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This study introduces PharmGPT, a suite of multilingual LLMs with 13 billion and 70 billion parameters, specifically trained on a comprehensive corpus of hundreds of billions of tokens tailored to the Bio-Pharmaceutical and Chemical sectors, demonstrating its exceptional capability in domain-specific tasks."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}