{
    "acronym": "9a17c7118143747a38a6a7aeef9818c223cd1708",
    "title": "FigGen: Text to Scientific Figure Generation",
    "seed_ids": [
        "classfreediffu",
        "c57293882b2561e1ba03017902df9fc2f289dea2",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d"
    ],
    "s2id": "9a17c7118143747a38a6a7aeef9818c223cd1708",
    "abstract": "The generative modeling landscape has experienced tremendous growth in recent years, particularly in generating natural images and art. Recent techniques have shown impressive potential in creating complex visual compositions while delivering impressive realism and quality. However, state-of-the-art methods have been focusing on the narrow domain of natural images, while other distributions remain unexplored. In this paper, we introduce the problem of text-to-figure generation, that is creating scientific figures of papers from text descriptions. We present FigGen, a diffusion-based approach for text-to-figure as well as the main challenges of the proposed task. Code and models are available at https://github.com/joanrod/figure-diffusion",
    "authors": [
        "J. A. Rodr\u00edguez",
        "David V\u00e1zquez",
        "I. Laradji",
        "M. Pedersoli",
        "Pau Rodr\u00edguez L\u00f3pez"
    ],
    "venue": "Tiny Papers @ ICLR",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper presents FigGen, a diffusion-based approach for text-to-figure generation, that is creating scientific figures of papers from text descriptions, as well as the main challenges of the proposed task."
    },
    "citationCount": 3,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}