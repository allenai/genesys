{
    "acronym": "bdb6a18851cefa300db68107ac5e3d218ba77ff8",
    "title": "LLM4GEN: Leveraging Semantic Representation of LLMs for Text-to-Image Generation",
    "seed_ids": [
        "gpt3",
        "964bd39b546f0f6625ff3b9ef1083f797807ef2e",
        "1d26c947406173145a4665dd7ab255e03494ea28",
        "3ff7153fd6bd47d08084c7f50f8fd70026c126e7",
        "13a0d8bb38f739990c8cd65a44061c6534f17221",
        "c57293882b2561e1ba03017902df9fc2f289dea2",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d"
    ],
    "s2id": "bdb6a18851cefa300db68107ac5e3d218ba77ff8",
    "abstract": "Diffusion Models have exhibited substantial success in text-to-image generation. However, they often encounter challenges when dealing with complex and dense prompts that involve multiple objects, attribute binding, and long descriptions. This paper proposes a framework called \\textbf{LLM4GEN}, which enhances the semantic understanding ability of text-to-image diffusion models by leveraging the semantic representation of Large Language Models (LLMs). Through a specially designed Cross-Adapter Module (CAM) that combines the original text features of text-to-image models with LLM features, LLM4GEN can be easily incorporated into various diffusion models as a plug-and-play component and enhances text-to-image generation. Additionally, to facilitate the complex and dense prompts semantic understanding, we develop a LAION-refined dataset, consisting of 1 million (M) text-image pairs with improved image descriptions. We also introduce DensePrompts which contains 7,000 dense prompts to provide a comprehensive evaluation for the text-to-image generation task. With just 10\\% of the training data required by recent ELLA, LLM4GEN significantly improves the semantic alignment of SD1.5 and SDXL, demonstrating increases of 7.69\\% and 9.60\\% in color on T2I-CompBench, respectively. The extensive experiments on DensePrompts also demonstrate that LLM4GEN surpasses existing state-of-the-art models in terms of sample quality, image-text alignment, and human evaluation. The project website is at: \\textcolor{magenta}{\\url{https://xiaobul.github.io/LLM4GEN/}}",
    "authors": [
        "Mushui Liu",
        "Yuhang Ma",
        "Xinfeng Zhang",
        "Yang Zhen",
        "Zeng Zhao",
        "Zhipeng Hu",
        "Bai Liu",
        "Changjie Fan"
    ],
    "venue": "",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A framework called LLM4GEN is proposed, which enhances the semantic understanding ability of text-to-image diffusion models by leveraging the semantic representation of Large Language Models (LLMs)."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}