{
    "acronym": "7f505660c595d6547e258de0a5978fc2d5fad925",
    "title": "You Only Scan Once: Efficient Multi-dimension Sequential Modeling with LightNet",
    "seed_ids": [
        "transnormerllm",
        "transnormer",
        "dc0005e3fb9ad04e43dc60b12df8e27f29dd04c3",
        "46732358e98ce6be0c564ae11f71d556a64b4c35",
        "157ed5647da39a7f5d33a84a90414b2a9e97e301",
        "4d84441e7f296d42d6493bb5a7b16d36e479b354",
        "51f38bd957fa863022feb5878fa1ba3bea6657cf",
        "7154fc93bdefcd237a0ce3902511c0b154049253",
        "38c48a1cd296d16dc9c56717495d6e44cc354444",
        "7294c426b8a95975ca932eaf8f700acdd3d950b2",
        "62b18cc55dcc7ffe52c28e1086aee893b7bc4334",
        "0664d52b1040e048fff7e7d1d13a310964207768",
        "434d751d355d7a7c20efa570e785c76286245e77",
        "2a38daf98d506477f8180806f503409d5036eaf4",
        "8bc8b9ae855bc0aa19e7223899440ffbdc61f4d8",
        "240103933ffe3dac2179cc160a2bd91299357a53",
        "026b3396a63ed5772329708b7580d633bb86bec9",
        "f35f5aedc30e2c5ded210d9c91ba6e84bd029425",
        "f393aff1593c2d370ec0ae004910d18e40524967",
        "e3fc46d5f4aae2c7a8a86b6bd21ca8db5d40fcbd",
        "6d7d141c75af752ffc0d8a6184cca3f9323d6c74",
        "eaef083b9d661f42cc0d89d9d8156218f33a91d9",
        "ca444821352a4bd91884413d8070446e2960715a",
        "6be32b4321f95b79bb2e37feeab0c3c7f902195e",
        "c49ac1f916d6d2edeb187e6619c8d23acd95eb21",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
        "6f68e1bb253925d8431588555d3010419f322e04"
    ],
    "s2id": "7f505660c595d6547e258de0a5978fc2d5fad925",
    "abstract": "Linear attention mechanisms have gained prominence in causal language models due to their linear computational complexity and enhanced speed. However, the inherent decay mechanism in linear attention presents challenges when applied to multi-dimensional sequence modeling tasks, such as image processing and multi-modal learning. In these scenarios, the utilization of sequential scanning to establish a global receptive field necessitates multiple scans for multi-dimensional data, thereby leading to inefficiencies. This paper identifies the inefficiency caused by a multiplicative linear recurrence and proposes an efficient alternative additive linear recurrence to avoid the issue, as it can handle multi-dimensional data within a single scan. We further develop an efficient multi-dimensional sequential modeling framework called LightNet based on the new recurrence. Moreover, we present two new multi-dimensional linear relative positional encoding methods, MD-TPE and MD-LRPE to enhance the model's ability to discern positional information in multi-dimensional scenarios. Our empirical evaluations across various tasks, including image classification, image generation, bidirectional language modeling, and autoregressive language modeling, demonstrate the efficacy of LightNet, showcasing its potential as a versatile and efficient solution for multi-dimensional sequential modeling.",
    "authors": [
        "Zhen Qin",
        "Yuxin Mao",
        "Xuyang Shen",
        "Dong Li",
        "Jing Zhang",
        "Yuchao Dai",
        "Yiran Zhong"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper identifies the inefficiency caused by a multiplicative linear recurrence and proposes an efficient alternative additive linear recurrence to avoid the issue, as it can handle multi-dimensional data within a single scan."
    },
    "citationCount": 1,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}