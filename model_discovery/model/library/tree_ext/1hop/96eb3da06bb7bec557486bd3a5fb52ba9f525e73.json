{
    "acronym": "96eb3da06bb7bec557486bd3a5fb52ba9f525e73",
    "title": "Exploiting Rich Textual User-Product Context for Improving Personalized Sentiment Analysis",
    "seed_ids": [
        "longformer",
        "925ad2897d1b5decbea320d07e99afa9110e09b2"
    ],
    "s2id": "96eb3da06bb7bec557486bd3a5fb52ba9f525e73",
    "abstract": "User and product information associated with a review is useful for sentiment polarity prediction. Typical approaches incorporating such information focus on modeling users and products as implicitly learned representation vectors. Most do not exploit the potential of historical reviews, or those that currently do require unnecessary modifications to model architecture or do not make full use of user/product associations. The contribution of this work is twofold: i) a method to explicitly employ historical reviews belonging to the same user/product in initializing representations, and ii) efficient incorporation of textual associations between users and products via a user-product cross-context module. Experiments on the IMDb, Yelp-2013 and Yelp-2014 English benchmarks with BERT, SpanBERT and Longformer pretrained language models show that our approach substantially outperforms previous state-of-the-art.",
    "authors": [
        "Chenyang Lyu",
        "Linyi Yang",
        "Yue Zhang",
        "Yvette Graham",
        "Jennifer Foster"
    ],
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A method to explicitly employ historical reviews belonging to the same user/product in initializing representations and efficient incorporation of textual associations between users and products via a user-product cross-context module are proposed."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}