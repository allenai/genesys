{
    "acronym": "4d249bbfc172d5d4360244447f9e2245e318803d",
    "title": "Evading Data Contamination Detection for Language Models is (too) Easy",
    "seed_ids": [
        "gpt3",
        "8106d03fb984afd8c3d066cd4f993eb2616a0da5",
        "c03493310626e5220a3fe92b654fc5d56645a975",
        "32e11cf020021c225782a3b77b5cfed4ae8e14a0",
        "cb754310302086dfbbcd098263200e2a03f65874",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "4d249bbfc172d5d4360244447f9e2245e318803d",
    "abstract": "Large language models are widespread, with their performance on benchmarks frequently guiding user preferences for one model over another. However, the vast amount of data these models are trained on can inadvertently lead to contamination with public benchmarks, thus compromising performance measurements. While recently developed contamination detection methods try to address this issue, they overlook the possibility of deliberate contamination by malicious model providers aiming to evade detection. We argue that this setting is of crucial importance as it casts doubt on the reliability of public benchmarks. To more rigorously study this issue, we propose a categorization of both model providers and contamination detection methods. This reveals vulnerabilities in existing methods that we exploit with EAL, a simple yet effective contamination technique that significantly inflates benchmark performance while completely evading current detection methods.",
    "authors": [
        "Jasper Dekoninck",
        "Mark Niklas Muller",
        "Maximilian Baader",
        "Marc Fischer",
        "Martin T. Vechev"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a categorization of both model providers and contamination detection methods, and reveals vulnerabilities in existing methods that are exploited with EAL, a simple yet effective contamination technique that significantly inflates benchmark performance while completely evading current detection methods."
    },
    "citationCount": 8,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}