{
    "acronym": "6bdfffbf92d01c8b543088d40d46233610e469a8",
    "title": "CLIP in Medical Imaging: A Comprehensive Survey",
    "seed_ids": [
        "bert",
        "2c7e346aa311fec4dda04bdf3a214ce2026d8807",
        "69af965772bf6bb1247586894167d595bb3a7794",
        "785650a805851c7e945523e495c5a523c60f72a4",
        "b39743039412e40fef6d5b2f86db36320eab30e1",
        "c57293882b2561e1ba03017902df9fc2f289dea2",
        "5f19ae1135a9500940978104ec15a5b8751bc7d2",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7"
    ],
    "s2id": "6bdfffbf92d01c8b543088d40d46233610e469a8",
    "abstract": "Contrastive Language-Image Pre-training (CLIP), a simple yet effective pre-training paradigm, successfully introduces text supervision to vision models. It has shown promising results across various tasks, attributable to its generalizability and interpretability. The use of CLIP has recently gained increasing interest in the medical imaging domain, serving both as a pre-training paradigm for aligning medical vision and language, and as a critical component in diverse clinical tasks. With the aim of facilitating a deeper understanding of this promising direction, this survey offers an in-depth exploration of the CLIP paradigm within the domain of medical imaging, regarding both refined CLIP pre-training and CLIP-driven applications. In this study, We (1) start with a brief introduction to the fundamentals of CLIP methodology. (2) Then, we investigate the adaptation of CLIP pre-training in the medical domain, focusing on how to optimize CLIP given characteristics of medical images and reports. (3) Furthermore, we explore the practical utilization of CLIP pre-trained models in various tasks, including classification, dense prediction, and cross-modal tasks. (4) Finally, we discuss existing limitations of CLIP in the context of medical imaging and propose forward-looking directions to address the demands of medical imaging domain. We expect that this comprehensive survey will provide researchers in the field of medical image analysis with a holistic understanding of the CLIP paradigm and its potential implications. The project page can be found on https://github.com/zhaozh10/Awesome-CLIP-in-Medical-Imaging.",
    "authors": [
        "Zihao Zhao",
        "Yuxiao Liu",
        "Han Wu",
        "Yonghao Li",
        "Sheng Wang",
        "L. Teng",
        "Disheng Liu",
        "Xiang Li",
        "Zhiming Cui",
        "Qian Wang",
        "Dinggang Shen"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This survey offers an in-depth exploration of the CLIP paradigm within the domain of medical imaging, regarding both refined CLIP pre-training and CLIP-driven applications, and investigates the adaptation of CLIP pre-training in the medical domain."
    },
    "citationCount": 13,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}