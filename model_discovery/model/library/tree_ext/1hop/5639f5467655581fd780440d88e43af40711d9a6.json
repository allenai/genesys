{
    "acronym": "5639f5467655581fd780440d88e43af40711d9a6",
    "title": "Memory Efficient Optimizers with 4-bit States",
    "seed_ids": [
        "gpt2",
        "1d26c947406173145a4665dd7ab255e03494ea28",
        "13a0d8bb38f739990c8cd65a44061c6534f17221",
        "8c62277dada489904a63de4dd87336c27c68fb5e",
        "2cd605106b88c85d7d8b865b1ef0f8c8293debf1",
        "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad",
        "faadd7d081c8d67e8c2567e8a5579e46cd6b2280",
        "29ddc1f43f28af7c846515e32cc167bc66886d0c",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "5639f5467655581fd780440d88e43af40711d9a6",
    "abstract": "Optimizer states are a major source of memory consumption for training neural networks, limiting the maximum trainable model within given memory budget. Compressing the optimizer states from 32-bit floating points to lower bitwidth is promising to reduce the training memory footprint, while the current lowest achievable bitwidth is 8-bit. In this work, we push optimizer states bitwidth down to 4-bit through a detailed empirical analysis of first and second moments. Specifically, we find that moments have complicated outlier patterns, that current block-wise quantization cannot accurately approximate. We use a smaller block size and propose to utilize both row-wise and column-wise information for better quantization. We further identify a zero point problem of quantizing the second moment, and solve this problem with a linear quantizer that excludes the zero point. Our 4-bit optimizers are evaluated on a wide variety of benchmarks including natural language understanding, machine translation, image classification, and instruction tuning. On all the tasks our optimizers can achieve comparable accuracy with their full-precision counterparts, while enjoying better memory efficiency.",
    "authors": [
        "Bingrui Li",
        "Jianfei Chen",
        "Jun Zhu"
    ],
    "venue": "Neural Information Processing Systems",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work pushes optimizer states bitwidth down to 4-bit through a detailed empirical analysis of first and second moments, and identifies a zero point problem of quantizing the second moment, and solves this problem with a linear quantizer that excludes the zero point."
    },
    "citationCount": 9,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}