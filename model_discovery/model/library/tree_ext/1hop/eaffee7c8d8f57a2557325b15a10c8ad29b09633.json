{
    "acronym": "eaffee7c8d8f57a2557325b15a10c8ad29b09633",
    "title": "Learn2Talk: 3D Talking Face Learns from 2D Talking Face",
    "seed_ids": [
        "transformer",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "dd23991294bf53c6301ab79fa49752e6458d2eab"
    ],
    "s2id": "eaffee7c8d8f57a2557325b15a10c8ad29b09633",
    "abstract": "Speech-driven facial animation methods usually contain two main classes, 3D and 2D talking face, both of which attract considerable research attention in recent years. However, to the best of our knowledge, the research on 3D talking face does not go deeper as 2D talking face, in the aspect of lip-synchronization (lip-sync) and speech perception. To mind the gap between the two sub-fields, we propose a learning framework named Learn2Talk, which can construct a better 3D talking face network by exploiting two expertise points from the field of 2D talking face. Firstly, inspired by the audio-video sync network, a 3D sync-lip expert model is devised for the pursuit of lip-sync between audio and 3D facial motion. Secondly, a teacher model selected from 2D talking face methods is used to guide the training of the audio-to-3D motions regression network to yield more 3D vertex accuracy. Extensive experiments show the advantages of the proposed framework in terms of lip-sync, vertex accuracy and speech perception, compared with state-of-the-arts. Finally, we show two applications of the proposed framework: audio-visual speech recognition and speech-driven 3D Gaussian Splatting based avatar animation.",
    "authors": [
        "Yixiang Zhuang",
        "Baoping Cheng",
        "Yao Cheng",
        "Yuntao Jin",
        "Renshuai Liu",
        "Chengyang Li",
        "Xuan Cheng",
        "Jing Liao",
        "Juncong Lin"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a learning framework named Learn2Talk, which can construct a better 3D talking face network by exploiting two expertise points from the field of 2D talking face, and shows two applications of the proposed framework: audio-visual speech recognition and speech-driven 3D Gaussian Splatting based avatar animation."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}