{
    "acronym": "5603e598fa1916d1c696004bc360b75931547105",
    "title": "Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs",
    "seed_ids": [
        "gpt2",
        "13a0d8bb38f739990c8cd65a44061c6534f17221",
        "5f19ae1135a9500940978104ec15a5b8751bc7d2",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "5603e598fa1916d1c696004bc360b75931547105",
    "abstract": "Large language models (LLMs) have recently shown great advances in a variety of tasks, including natural language understanding and generation. However, their use in high-stakes decision-making scenarios is still limited due to the potential for errors. Selective prediction is a technique that can be used to improve the reliability of the LLMs by allowing them to abstain from making predictions when they are unsure of the answer. In this work, we propose a novel framework for adaptation with self-evaluation to improve the selective prediction performance of LLMs. Our framework is based on the idea of using parameter-efficient tuning to adapt the LLM to the specific task at hand while improving its ability to perform self-evaluation. We evaluate our method on a variety of question-answering (QA) datasets and show that it outperforms state-of-the-art selective prediction methods. For example, on the CoQA benchmark, our method improves the AUACC from 91.23% to 92.63% and improves the AUROC from 74.61% to 80.25%.",
    "authors": [
        "Jiefeng Chen",
        "Jinsung Yoon",
        "Sayna Ebrahimi",
        "Sercan \u00d6. Arik",
        "Tomas Pfister",
        "Somesh Jha"
    ],
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a novel framework for adaptation with self-evaluation to improve the selective prediction performance of LLMs and evaluates the method on a variety of question-answering datasets and shows that it outperforms state-of-the-art selective prediction methods."
    },
    "citationCount": 19,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}