{
    "acronym": "5b2533fe2b15d0ba116112c640237fac6f42a958",
    "title": "DiffuVST: Narrating Fictional Scenes with Global-History-Guided Denoising Models",
    "seed_ids": [
        "diffusionlm",
        "a979742220a88b1d32e1fbe72c41e8ba3007053c",
        "69144d537f90f214d5b07a7c79121d16afd7da16",
        "b64537bdf7a103aa01972ba06ea24a9c08f7cd74",
        "1386b8a11929cf02da291c56aca353e33bbc22ed",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "29ddc1f43f28af7c846515e32cc167bc66886d0c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "5b2533fe2b15d0ba116112c640237fac6f42a958",
    "abstract": "Recent advances in image and video creation, especially AI-based image synthesis, have led to the production of numerous visual scenes that exhibit a high level of abstractness and diversity. Consequently, Visual Storytelling (VST), a task that involves generating meaningful and coherent narratives from a collection of images, has become even more challenging and is increasingly desired beyond real-world imagery. While existing VST techniques, which typically use autoregressive decoders, have made significant progress, they suffer from low inference speed and are not well-suited for synthetic scenes. To this end, we propose a novel diffusion-based system DiffuVST, which models the generation of a series of visual descriptions as a single conditional denoising process. The stochastic and non-autoregressive nature of DiffuVST at inference time allows it to generate highly diverse narratives more efficiently. In addition, DiffuVST features a unique design with bi-directional text history guidance and multimodal adapter modules, which effectively improve inter-sentence coherence and image-to-text fidelity. Extensive experiments on the story generation task covering four fictional visual-story datasets demonstrate the superiority of DiffuVST over traditional autoregressive models in terms of both text quality and inference speed.",
    "authors": [
        "Shengguang Wu",
        "Mei Yuan",
        "Qi Su"
    ],
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Extensive experiments on the story generation task covering four fictional visual-story datasets demonstrate the superiority of DiffuVST over traditional autoregressive models in terms of both text quality and inference speed."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}