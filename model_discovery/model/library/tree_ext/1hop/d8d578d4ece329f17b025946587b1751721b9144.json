{
    "acronym": "d8d578d4ece329f17b025946587b1751721b9144",
    "title": "MixCE: Training Autoregressive Language Models by Mixing Forward and Reverse Cross-Entropies",
    "seed_ids": [
        "gpt2",
        "23447f473cd240494b0a20ea008038aaef7e3391",
        "13a0d8bb38f739990c8cd65a44061c6534f17221",
        "492a655a67e6ec7423a968cedb70eec0cdbc8e98",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "d8d578d4ece329f17b025946587b1751721b9144",
    "abstract": "Autoregressive language models are trained by minimizing the cross-entropy of the model distribution Q relative to the data distribution P \u2013 that is, minimizing the forward cross-entropy, which is equivalent to maximum likelihood estimation (MLE). We have observed that models trained in this way may \u201cover-generalize\u201d, in the sense that they produce non-human-like text. Moreover, we believe that reverse cross-entropy, i.e., the cross-entropy of P relative to Q, is a better reflection of how a human would evaluate text generated by a model. Hence, we propose learning with MixCE, an objective that mixes the forward and reverse cross-entropies. We evaluate models trained with this objective on synthetic data settings (where P is known) and real data, and show that the resulting models yield better generated text without complex decoding strategies.",
    "authors": [
        "Shiyue Zhang",
        "Shijie Wu",
        "Ozan Irsoy",
        "Steven Lu",
        "Mohit Bansal",
        "Mark Dredze",
        "D. Rosenberg"
    ],
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes learning with MixCE, an objective that mixes the forward and reverse cross-entropies, and evaluates models trained with this objective on synthetic data settings and real data, showing that the resulting models yield better generated text without complex decoding strategies."
    },
    "citationCount": 7,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}