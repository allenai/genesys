{
    "acronym": "4ef22b759ede5cfd95ec9ee642920bbc612fa530",
    "title": "DORY: Deliberative Prompt Recovery for LLM",
    "seed_ids": [
        "gpt3",
        "50796b0f3edf9cb5ff1e447c298b33755378aa4f"
    ],
    "s2id": "4ef22b759ede5cfd95ec9ee642920bbc612fa530",
    "abstract": "Prompt recovery in large language models (LLMs) is crucial for understanding how LLMs work and addressing concerns regarding privacy, copyright, etc. The trend towards inference-only APIs complicates this task by restricting access to essential outputs for recovery. To tackle this challenge, we extract prompt-related information from limited outputs and identify a strong(negative) correlation between output probability-based uncertainty and the success of prompt recovery. This finding led to the development of Deliberative PrOmpt RecoverY (DORY), our novel approach that leverages uncertainty to recover prompts accurately. DORY involves reconstructing drafts from outputs, refining these with hints, and filtering out noise based on uncertainty. Our evaluation across diverse LLMs and prompt benchmarks shows that DORY outperforms existing baselines, improving performance by approximately 10.82% and establishing a new state-of-the-art record in prompt recovery tasks. Significantly, DORY operates using a single LLM without any external resources or model, offering a cost-effective, user-friendly prompt recovery solution.",
    "authors": [
        "Lirong Gao",
        "Ru Peng",
        "Yiming Zhang",
        "Junbo Zhao"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The development of Deliberative PrOmpt RecoverY (DORY), a novel approach that leverages uncertainty to recover prompts accurately and outperforms existing baselines, offering a cost-effective, user-friendly prompt recovery solution."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}