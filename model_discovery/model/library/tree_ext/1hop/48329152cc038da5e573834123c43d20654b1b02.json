{
    "acronym": "48329152cc038da5e573834123c43d20654b1b02",
    "title": "DiM: Diffusion Mamba for Efficient High-Resolution Image Synthesis",
    "seed_ids": [
        "mamba",
        "722ae1415e102ff258d5cbf31cfaacd6fd31d99f",
        "da9178eae82d1ca5492aaecd0151ba49481cb8b1",
        "0a32e6ff6eaac83ff325bae4557a8362222979aa",
        "3af7273d7ca20c0c63cbaa47e60b058840835052",
        "7154fc93bdefcd237a0ce3902511c0b154049253",
        "b24e899ec0f77eef2fc87a9b8e50516367aa1f97",
        "38c48a1cd296d16dc9c56717495d6e44cc354444",
        "5a77b508302771fc083bf24e0bcda8553c9b5421",
        "6d7d141c75af752ffc0d8a6184cca3f9323d6c74",
        "a30ac45ac5b7bd2148d3fb80ee7f3c29724e3170",
        "ca444821352a4bd91884413d8070446e2960715a",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d"
    ],
    "s2id": "48329152cc038da5e573834123c43d20654b1b02",
    "abstract": "Diffusion models have achieved great success in image generation, with the backbone evolving from U-Net to Vision Transformers. However, the computational cost of Transformers is quadratic to the number of tokens, leading to significant challenges when dealing with high-resolution images. In this work, we propose Diffusion Mamba (DiM), which combines the efficiency of Mamba, a sequence model based on State Space Models (SSM), with the expressive power of diffusion models for efficient high-resolution image synthesis. To address the challenge that Mamba cannot generalize to 2D signals, we make several architecture designs including multi-directional scans, learnable padding tokens at the end of each row and column, and lightweight local feature enhancement. Our DiM architecture achieves inference-time efficiency for high-resolution images. In addition, to further improve training efficiency for high-resolution image generation with DiM, we investigate\"weak-to-strong\"training strategy that pretrains DiM on low-resolution images ($256\\times 256$) and then finetune it on high-resolution images ($512 \\times 512$). We further explore training-free upsampling strategies to enable the model to generate higher-resolution images (e.g., $1024\\times 1024$ and $1536\\times 1536$) without further fine-tuning. Experiments demonstrate the effectiveness and efficiency of our DiM. The code of our work is available here: {\\url{https://github.com/tyshiwo1/DiM-DiffusionMamba/}}.",
    "authors": [
        "Yao Teng",
        "Yue Wu",
        "Han Shi",
        "Xuefei Ning",
        "Guohao Dai",
        "Yu Wang",
        "Zhenguo Li",
        "Xihui Liu"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes Diffusion Mamba (DiM), which combines the efficiency of Mamba, a sequence model based on State Space Models (SSM), with the expressive power of diffusion models for efficient high-resolution image synthesis."
    },
    "citationCount": 4,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}