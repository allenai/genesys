{
    "acronym": "bf53b1f16b364704bcfc633b3f531450551aa45d",
    "title": "Location Aware Modular Biencoder for Tourism Question Answering",
    "seed_ids": [
        "bert",
        "2573af4e13d9a5dddb257d22cd38a600528d9a8b",
        "c6c734e16f66fbfcefac7625cc64599e83292c1e",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "67b1f8e48118bb1aa250f400d475425317bf4117",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c"
    ],
    "s2id": "bf53b1f16b364704bcfc633b3f531450551aa45d",
    "abstract": "Answering real-world tourism questions that seek Point-of-Interest (POI) recommendations is challenging, as it requires both spatial and non-spatial reasoning, over a large candidate pool. The traditional method of encoding each pair of question and POI becomes inefficient when the number of candidates increases, making it infeasible for real-world applications. To overcome this, we propose treating the QA task as a dense vector retrieval problem, where we encode questions and POIs separately and retrieve the most relevant POIs for a question by utilizing embedding space similarity. We use pretrained language models (PLMs) to encode textual information, and train a location encoder to capture spatial information of POIs. Experiments on a real-world tourism QA dataset demonstrate that our approach is effective, efficient, and outperforms previous methods across all metrics. Enabled by the dense retrieval architecture, we further build a global evaluation baseline, expanding the search space by 20 times compared to previous work. We also explore several factors that impact on the model's performance through follow-up experiments. Our code and model are publicly available at https://github.com/haonan-li/LAMB.",
    "authors": [
        "Haonan Li",
        "Martin Tomko",
        "Timothy Baldwin"
    ],
    "venue": "International Joint Conference on Natural Language Processing",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes treating the QA task as a dense vector retrieval problem, where questions and POIs are encoded separately and retrieved the most relevant POIs for a question by utilizing embedding space similarity."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}