{
    "acronym": "70afa5d4c72943e691d4f4a3bc95800be4542816",
    "title": "MLP-ASR: Sequence-length agnostic all-MLP architectures for speech recognition",
    "seed_ids": [
        "gmlp",
        "9b6af0e358e76d22f209c75b1702c3e6ea7815b1",
        "1f133158a8973fb33fea188f20517cd7e69bfe7f",
        "09e2c7adbed37440d4a339852cfa34e5b660f768"
    ],
    "s2id": "70afa5d4c72943e691d4f4a3bc95800be4542816",
    "abstract": "We propose multi-layer perceptron (MLP)-based architectures suitable for variable length input. MLP-based architectures, recently proposed for image classification, can only be used for inputs of a fixed, pre-defined size. However, many types of data are naturally variable in length, for example, acoustic signals. We propose three approaches to extend MLP-based architectures for use with sequences of arbitrary length. The first one uses a circular convolution applied in the Fourier domain, the second applies a depthwise convolution, and the final relies on a shift operation. We evaluate the proposed architectures on an automatic speech recognition task with the Librispeech and Tedlium2 corpora. The best proposed MLP-based architectures improves WER by 1.0 / 0.9%, 0.9 / 0.5% on Librispeech dev-clean/dev-other, test-clean/test-other set, and 0.8 / 1.1% on Tedlium2 dev/test set using 86.4% the size of self-attention-based architecture.",
    "authors": [
        "Jin Sakuma",
        "Tatsuya Komatsu",
        "Robin Scheibler"
    ],
    "venue": "arXiv.org",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Three approaches to extend MLP-based architectures for use with sequences of arbitrary length are proposed, one of which uses a circular convolution applied in the Fourier domain, the second applies a depthwise convolution, and the final relies on a shift operation."
    },
    "citationCount": 5,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}