{
    "acronym": "aa4acbad4d6a3a8195d70c174564df752a5e1ba5",
    "title": "MeaeQ: Mount Model Extraction Attacks with Efficient Queries",
    "seed_ids": [
        "gpt2",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "aa4acbad4d6a3a8195d70c174564df752a5e1ba5",
    "abstract": "We study model extraction attacks in natural language processing (NLP) where attackers aim to steal victim models by repeatedly querying the open Application Programming Interfaces (APIs). Recent works focus on limited-query budget settings and adopt random sampling or active learning-based sampling strategies on publicly available, unannotated data sources. However, these methods often result in selected queries that lack task relevance and data diversity, leading to limited success in achieving satisfactory results with low query costs. In this paper, we propose MeaeQ (Model extraction attack with efficient Queries), a straightforward yet effective method to address these issues. Specifically, we initially utilize a zero-shot sequence inference classifier, combined with API service information, to filter task-relevant data from a public text corpus instead of a problem domain-specific dataset. Furthermore, we employ a clustering-based data reduction technique to obtain representative data as queries for the attack. Extensive experiments conducted on four benchmark datasets demonstrate that MeaeQ achieves higher functional similarity to the victim model than baselines while requiring fewer queries. Our code is available at https://github.com/C-W-D/MeaeQ.",
    "authors": [
        "Chengwei Dai",
        "Minxuan Lv",
        "Kun Li",
        "Wei Zhou"
    ],
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper proposes MeaeQ (Model extraction attack with efficient Queries), a straightforward yet effective method to address model extraction attacks in natural language processing that achieves higher functional similarity to the victim model than baselines while requiring fewer queries."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}