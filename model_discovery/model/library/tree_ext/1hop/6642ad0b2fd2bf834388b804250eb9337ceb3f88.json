{
    "acronym": "6642ad0b2fd2bf834388b804250eb9337ceb3f88",
    "title": "Improving Question Answering with External Knowledge",
    "seed_ids": [
        "gpt",
        "6ff68b34a5f78bdd14437fe5a79aebbc42c26467",
        "8f346de21a13dacf5b65e2de81e84d54226a5b9f",
        "9a5ba9aee44ab873f3d60b05e2773c693707da88"
    ],
    "s2id": "6642ad0b2fd2bf834388b804250eb9337ceb3f88",
    "abstract": "We focus on multiple-choice question answering (QA) tasks in subject areas such as science, where we require both broad background knowledge and the facts from the given subject-area reference corpus. In this work, we explore simple yet effective methods for exploiting two sources of external knowledge for subject-area QA. The first enriches the original subject-area reference corpus with relevant text snippets extracted from an open-domain resource (i.e., Wikipedia) that cover potentially ambiguous concepts in the question and answer options. As in other QA research, the second method simply increases the amount of training data by appending additional in-domain subject-area instances. Experiments on three challenging multiple-choice science QA tasks (i.e., ARC-Easy, ARC-Challenge, and OpenBookQA) demonstrate the effectiveness of our methods: in comparison to the previous state-of-the-art, we obtain absolute gains in accuracy of up to 8.1%, 13.0%, and 12.8%, respectively. While we observe consistent gains when we introduce knowledge from Wikipedia, we find that employing additional QA training instances is not uniformly helpful: performance degrades when the added instances exhibit a higher level of difficulty than the original training data. As one of the first studies on exploiting unstructured external knowledge for subject-area QA, we hope our methods, observations, and discussion of the exposed limitations may shed light on further developments in the area.",
    "authors": [
        "Xiaoman Pan",
        "Kai Sun",
        "Dian Yu",
        "Heng Ji",
        "Dong Yu"
    ],
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2019,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work explores simple yet effective methods for exploiting two sources of externalknowledge for exploiting unstructured external knowledge for subject-area QA on multiple-choice question answering tasks in subject areas such as science."
    },
    "citationCount": 61,
    "influentialCitationCount": 5,
    "code": null,
    "description": null,
    "url": null
}