{
    "acronym": "690df0820f35a47e1ce44f90e6ddb4132aa09267",
    "title": "Vision-Language Models for Vision Tasks: A Survey",
    "seed_ids": [
        "gpt2",
        "b39743039412e40fef6d5b2f86db36320eab30e1",
        "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7",
        "29ddc1f43f28af7c846515e32cc167bc66886d0c",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "690df0820f35a47e1ce44f90e6ddb4132aa09267",
    "abstract": "Most visual recognition studies rely heavily on crowd-labelled data in deep neural networks (DNNs) training, and they usually train a DNN for each single visual recognition task, leading to a laborious and time-consuming visual recognition paradigm. To address the two challenges, Vision-Language Models (VLMs) have been intensively investigated recently, which learns rich vision-language correlation from web-scale image-text pairs that are almost infinitely available on the Internet and enables zero-shot predictions on various visual recognition tasks with a single VLM. This paper provides a systematic review of visual language models for various visual recognition tasks, including: (1) the background that introduces the development of visual recognition paradigms; (2) the foundations of VLM that summarize the widely-adopted network architectures, pre-training objectives, and downstream tasks; (3) the widely-adopted datasets in VLM pre-training and evaluations; (4) the review and categorization of existing VLM pre-training methods, VLM transfer learning methods, and VLM knowledge distillation methods; (5) the benchmarking, analysis and discussion of the reviewed methods; (6) several research challenges and potential research directions that could be pursued in the future VLM studies for visual recognition.",
    "authors": [
        "Jingyi Zhang",
        "Jiaxing Huang",
        "Sheng Jin",
        "Shijian Lu"
    ],
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A systematic review of visual language models for various visual recognition tasks, including the background that introduces the development of visual recognition paradigms, and the foundations of VLM that summarize the widely-adopted network architectures, pre-training objectives, and downstream tasks."
    },
    "citationCount": 126,
    "influentialCitationCount": 4,
    "code": null,
    "description": null,
    "url": null
}