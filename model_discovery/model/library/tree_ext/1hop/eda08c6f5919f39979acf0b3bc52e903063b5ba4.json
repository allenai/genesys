{
    "acronym": "eda08c6f5919f39979acf0b3bc52e903063b5ba4",
    "title": "Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge Evaluation",
    "seed_ids": [
        "gpt2",
        "be55e8ec4213868db08f2c3168ae666001bea4b8",
        "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d",
        "964bd39b546f0f6625ff3b9ef1083f797807ef2e",
        "1d26c947406173145a4665dd7ab255e03494ea28",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "50796b0f3edf9cb5ff1e447c298b33755378aa4f",
        "04f4e55e14150b7c48b0287ba77c7443df76ed45",
        "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "eda08c6f5919f39979acf0b3bc52e903063b5ba4",
    "abstract": "New Natural Langauge Process~(NLP) benchmarks are urgently needed to align with the rapid development of large language models (LLMs). We present Xiezhi, the most comprehensive evaluation suite designed to assess holistic domain knowledge.Xiezhi comprises multiple-choice questions across 516 diverse disciplines ranging from 13 different subjects with 249,587 questions and accompanied by Xiezhi-Specialty with 14,041 questions and Xiezhi-Interdiscipline with 10,746 questions. We conduct evaluation of the 47 cutting-edge LLMs on Xiezhi. Results indicate that LLMs exceed average performance of humans in science, engineering, agronomy, medicine, and art, but fall short in economics, jurisprudence, pedagogy, literature, history, and management. All the evaluation code and data are open sourced in https://github.com/MikeGu721/XiezhiBenchmark",
    "authors": [
        "Zhouhong Gu",
        "Xiaoxuan Zhu",
        "Haoning Ye",
        "Lin Zhang",
        "Jianchen Wang",
        "Sihang Jiang",
        "Zhuozhi Xiong",
        "Zihan Li",
        "Qi He",
        "Rui Xu",
        "Wenhao Huang",
        "Weiguo Zheng",
        "Hongwei Feng",
        "Yanghua Xiao"
    ],
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Evaluation of the 47 cutting-edge LLMs on Xiezhi indicates that LLMs exceed average performance of humans in science, engineering, agronomy, medicine, and art, but fall short in economics, jurisprudence, pedagogy, literature, history, and management."
    },
    "citationCount": 30,
    "influentialCitationCount": 8,
    "code": null,
    "description": null,
    "url": null
}