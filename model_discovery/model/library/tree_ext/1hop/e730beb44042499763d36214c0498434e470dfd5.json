{
    "acronym": "e730beb44042499763d36214c0498434e470dfd5",
    "title": "MambaIR: A Simple Baseline for Image Restoration with State-Space Model",
    "seed_ids": [
        "mamba",
        "b24e899ec0f77eef2fc87a9b8e50516367aa1f97",
        "38c48a1cd296d16dc9c56717495d6e44cc354444",
        "bb6644a9f5920abfc1fa008f366a9ff48468e063",
        "6d7d141c75af752ffc0d8a6184cca3f9323d6c74",
        "eaef083b9d661f42cc0d89d9d8156218f33a91d9",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "ca9047c78d48b606c4e4f0c456b1dda550de28b2",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7"
    ],
    "s2id": "e730beb44042499763d36214c0498434e470dfd5",
    "abstract": "Recent years have seen significant advancements in image restoration, largely attributed to the development of modern deep neural networks, such as CNNs and Transformers. However, existing restoration backbones often face the dilemma between global receptive fields and efficient computation, hindering their application in practice. Recently, the Selective Structured State Space Model, especially the improved version Mamba, has shown great potential for long-range dependency modeling with linear complexity, which offers a way to resolve the above dilemma. However, the standard Mamba still faces certain challenges in low-level vision such as local pixel forgetting and channel redundancy. In this work, we introduce a simple but effective baseline, named MambaIR, which introduces both local enhancement and channel attention to improve the vanilla Mamba. In this way, our MambaIR takes advantage of the local pixel similarity and reduces the channel redundancy. Extensive experiments demonstrate the superiority of our method, for example, MambaIR outperforms SwinIR by up to 0.45dB on image SR, using similar computational cost but with a global receptive field. Code is available at \\url{https://github.com/csguoh/MambaIR}.",
    "authors": [
        "Hang Guo",
        "Jinmin Li",
        "Tao Dai",
        "Zhihao Ouyang",
        "Xudong Ren",
        "Shutao Xia"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A simple but effective baseline is introduced, named MambaIR, which introduces both local enhancement and channel attention to improve the vanilla Mamba, and takes advantage of the local pixel similarity and reduces the channel redundancy."
    },
    "citationCount": 47,
    "influentialCitationCount": 7,
    "code": null,
    "description": null,
    "url": null
}