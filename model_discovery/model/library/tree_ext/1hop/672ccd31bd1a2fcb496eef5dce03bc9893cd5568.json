{
    "acronym": "672ccd31bd1a2fcb496eef5dce03bc9893cd5568",
    "title": "Abstractive Text Summarization Based on Neural Fusion",
    "seed_ids": [
        "bert",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "145b8b5d99a2beba6029418ca043585b90138d12",
        "faadd7d081c8d67e8c2567e8a5579e46cd6b2280"
    ],
    "s2id": "672ccd31bd1a2fcb496eef5dce03bc9893cd5568",
    "abstract": "Abstractive text summarization, in comparison to extractive text summarization, offers the potential to generate more accurate summaries. In our work, we present a stage-wise abstractive text summarization model that incorporates Elementary Discourse Unit (EDU) segmentation, EDU selection, and EDU fusion. We first segment the articles into a fine-grained form, EDUs, and build a Rhetorical Structure Theory (RST) graph for each article in order to represent the dependencies among EDUs. Those EDUs are encoded in a Graph Attention Networks (GATs), and those with higher importance will be selected as candidates to be fused. The fusing stage is done by BART which merges the selected EDUs into summaries. Our model outperforms the baseline of BART (large) on the CNN/Daily Mail dataset, showing its effectiveness in abstractive text summarization.",
    "authors": [
        "Yllias Chali",
        "Wenzhao Zhu"
    ],
    "venue": "The International FLAIRS Conference Proceedings",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work presents a stage-wise abstractive text summarization model that incorporates Elementary Discourse Unit (EDU) segmentation, EDU selection, and EDU fusion that outperforms the baseline of BART (large) on the CNN/Daily Mail dataset."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}