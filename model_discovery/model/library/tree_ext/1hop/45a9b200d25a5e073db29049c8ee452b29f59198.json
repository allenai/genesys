{
    "acronym": "45a9b200d25a5e073db29049c8ee452b29f59198",
    "title": "G OOD FOR M ISCONCEIVED R EASONS : R EVISITING N EURAL M ULTIMODAL M ACHINE T RANSLATION",
    "seed_ids": [
        "lighdynconv",
        "faadd7d081c8d67e8c2567e8a5579e46cd6b2280"
    ],
    "s2id": "45a9b200d25a5e073db29049c8ee452b29f59198",
    "abstract": "A neural multimodal machine translation (MMT) system is one that aims to perform better translation by extending conventional text-only translation models with multimodal information. Many recent studies report improvements when equipping their models with the multimodal module, despite the controversy whether such improvements indeed come from the multimodal part. We revisit the recent development of neural multimodal machine translation by proposing two interpretable MMT models that achieve new state-of-the-art results on the standard Multi30k dataset. To our surprise, however, while we observe similar gains as in the recent developed multimodal-integrated models, our models learn to ignore the multimodal information. Upon further investigation, we discover that the improvements bought about by the multimodal models over text-only counterpart are in fact results of the regularization effect. We report our empirical \ufb01ndings which express the importance of MMT models\u2019 interpretability and set new paradigms for future MMT research.",
    "authors": [],
    "venue": "",
    "year": 2020,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work revisits the recent development of neural multimodal machine translation by proposing two interpretable MMT models that achieve new state-of-the-art results on the standard Multi30k dataset, and expresses the importance of MMT models\u2019 interpretability and set new paradigms for future MMT research."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}