{
    "acronym": "054f4506663e05e6d3e6bcf55f02a2d9d014bcc5",
    "title": "Large Language Model-guided Document Selection",
    "seed_ids": [
        "gpt3",
        "f5789596531fad358c3166fdb5bd72d8e661c32c",
        "11cf88dce827bd67cbfa60400306318022e736d5",
        "9e16d8cc6096ec0d2733a4ecf41ce09d9a4bd19c",
        "13a0d8bb38f739990c8cd65a44061c6534f17221",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "04f4e55e14150b7c48b0287ba77c7443df76ed45",
        "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad",
        "92e121c6e114fe3cfb89370df03847c66a9b4e28",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "054f4506663e05e6d3e6bcf55f02a2d9d014bcc5",
    "abstract": "Large Language Model (LLM) pre-training exhausts an ever growing compute budget, yet recent research has demonstrated that careful document selection enables comparable model quality with only a fraction of the FLOPs. Inspired by efforts suggesting that domain-specific training document selection is in fact an interpretable process [Gunasekar et al., 2023], as well as research showing that instruction-finetuned LLMs are adept zero-shot data labelers [Gilardi et al.,2023], we explore a promising direction for scalable general-domain document selection; employing a prompted LLM as a document grader, we distill quality labels into a classifier model, which is applied at scale to a large, and already heavily-filtered, web-crawl-derived corpus autonomously. Following the guidance of this classifier, we drop 75% of the corpus and train LLMs on the remaining data. Results across multiple benchmarks show that: 1. Filtering allows us to quality-match a model trained on the full corpus across diverse benchmarks with at most 70% of the FLOPs, 2. More capable LLM labelers and classifier models lead to better results that are less sensitive to the labeler's prompt, 3. In-context learning helps to boost the performance of less-capable labeling models. In all cases we use open-source datasets, models, recipes, and evaluation frameworks, so that results can be reproduced by the community.",
    "authors": [
        "Xiang Kong",
        "Tom Gunter",
        "Ruoming Pang"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work uses a prompted LLM as a document grader to distill quality labels into a classifier model, which is applied at scale to a large, and already heavily-filtered, web-crawl-derived corpus autonomously and helps to boost the performance of less-capable labeling models."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}