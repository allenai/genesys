{
    "acronym": "c3c8dabed23b61df42f7d10a78e922b951fdcc20",
    "title": "The Lay Person's Guide to Biomedicine: Orchestrating Large Language Models",
    "seed_ids": [
        "longt5",
        "4161ad2d2495d8af1d62dc5e71882bde642cd1c1",
        "e7ad08848d5d7c5c47673ffe0da06af443643bda",
        "cd471b5ef162906ef3d9a84398b3f98e9ee4bf56",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "3dfb1f50f2a34a699c339dabaa6f9b3a977973de",
        "053b1d7b97eb2c91fc3921d589c160b0923c70b1",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481"
    ],
    "s2id": "c3c8dabed23b61df42f7d10a78e922b951fdcc20",
    "abstract": "Automated lay summarisation (LS) aims to simplify complex technical documents into a more accessible format to non-experts. Existing approaches using pre-trained language models, possibly augmented with external background knowledge, tend to struggle with effective simplification and explanation. Moreover, automated methods that can effectively assess the `layness' of generated summaries are lacking. Recently, large language models (LLMs) have demonstrated a remarkable capacity for text simplification, background information generation, and text evaluation. This has motivated our systematic exploration into using LLMs to generate and evaluate lay summaries of biomedical articles. We propose a novel \\textit{Explain-then-Summarise} LS framework, which leverages LLMs to generate high-quality background knowledge to improve supervised LS. We also evaluate the performance of LLMs for zero-shot LS and propose two novel LLM-based LS evaluation metrics, which assess layness from multiple perspectives. Finally, we conduct a human assessment of generated lay summaries. Our experiments reveal that LLM-generated background information can support improved supervised LS. Furthermore, our novel zero-shot LS evaluation metric demonstrates a high degree of alignment with human preferences. We conclude that LLMs have an important part to play in improving both the performance and evaluation of LS methods.",
    "authors": [
        "Zheheng Luo",
        "Qianqian Xie",
        "Sophia Ananiadou"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel \\textit{Explain-then-Summarise} LS framework is proposed, which leverages LLMs to generate high-quality background knowledge to improve supervised LS and concludes that LLMs have an important part to play in improving both the performance and evaluation of LS methods."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}