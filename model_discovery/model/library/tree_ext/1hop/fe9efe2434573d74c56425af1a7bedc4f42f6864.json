{
    "acronym": "fe9efe2434573d74c56425af1a7bedc4f42f6864",
    "title": "AST-GCN: Augmented Spatial Temporal Graph Convolutional Neural Network for Gait Emotion Recognition",
    "seed_ids": [
        "transformer"
    ],
    "s2id": "fe9efe2434573d74c56425af1a7bedc4f42f6864",
    "abstract": "Skeleton-based methods have recently achieved good performance in deep learning-based gait emotion recognition (DL-GER). However, the current methods have two drawbacks that limit the ability to learn discriminative emotional features from gait. First, these methods do not exclude the effect of the subject\u2019s walking orientation on emotion classification. Second, they do not sufficiently learn the implicit connections between the joints during human walking. In this paper, an augmented spatial-temporal graph convolutional neural network (AST-GCN) is introduced to solve these two problems. The interframe shift encoding (ISE) module acquires interframe shifts of joints to make the network sensitive to changes in emotion-related joint movements regardless of the subject\u2019s walking orientation. A multichannel implicit connection inference method learns more implicit connection relations related to emotions. Notably, we unify current skeleton-based methods into a common framework that validates the most powerful feature representation capability of our AST-GCN from a theoretical perspective. In addition, we extend the skeleton-based gait dataset using posture estimation software. Experiments demonstrate that our AST-GCN outperforms state-of-the-art methods on three datasets on two tasks.",
    "authors": [
        "Chuang Chen",
        "Xiao Sun",
        "Zhengzheng Tu",
        "Meng Wang"
    ],
    "venue": "IEEE transactions on circuits and systems for video technology (Print)",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "An augmented spatial-temporal graph convolutional neural network (AST-GCN) is introduced to solve two problems of skeleton-based gait emotion recognition and unify current skeleton-based methods into a common framework that validates the most powerful feature representation capability of the AST-GCN from a theoretical perspective."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}