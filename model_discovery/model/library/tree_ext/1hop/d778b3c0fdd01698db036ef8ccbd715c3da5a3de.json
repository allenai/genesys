{
    "acronym": "d778b3c0fdd01698db036ef8ccbd715c3da5a3de",
    "title": "A Comprehensive Survey of Abstractive Text Summarization Techniques",
    "seed_ids": [
        "bert"
    ],
    "s2id": "d778b3c0fdd01698db036ef8ccbd715c3da5a3de",
    "abstract": "Abstractive text summarization [16] leverages advanced machine learning and deep neural networks to generate entirely new text that encapsulates the essence of the input text. It differs from extractive summarization [20], which mechanically concatenates text segments. Abstractive summarization is needed to address information overload and enhance content creation. However, it faces challenges such as maintaining consistency, capturing subtle nuances, and striking a balance between conciseness and comprehensiveness. Various approaches to abstractive summarization are presented, including the seq2seq model [17], attention mechanism [18], pointer-generator network [10], and copy mechanism. These approaches have different strengths and weaknesses depending on the application. Abstractive summarization finds practical applications in news summarization, research paper summarization, legal document summarization, customer support, and e-commerce product descriptions.",
    "authors": [
        "Nikesh Kumar",
        "Rayirth Soni",
        "Tarun Adhikari",
        "Suresh Kumar"
    ],
    "venue": "2024 International Conference on Communication, Computer Sciences and Engineering (IC3SE)",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Various approaches to abstractive summarization are presented, including the seq2seq model, attention mechanism, pointer-generator network, and copy mechanism, which have different strengths and weaknesses depending on the application."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}