{
    "acronym": "5b9a313513b5deddeedbb58e8e39c1f3eb6c1b92",
    "title": "Comprehensive Evaluation of Large Language Models for Topic Modeling",
    "seed_ids": [
        "bert",
        "a5421264347581b7950acc2d12d2680a466beec2",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c"
    ],
    "s2id": "5b9a313513b5deddeedbb58e8e39c1f3eb6c1b92",
    "abstract": "Recent work utilizes Large Language Models (LLMs) for topic modeling, generating comprehensible topic labels for given documents. However, their performance has mainly been evaluated qualitatively, and there remains room for quantitative investigation of their capabilities. In this paper, we quantitatively evaluate LLMs from multiple perspectives: the quality of topics, the impact of LLM-specific concerns, such as hallucination and shortcuts for limited documents, and LLMs' controllability of topic categories via prompts. Our findings show that LLMs can identify coherent and diverse topics with few hallucinations but may take shortcuts by focusing only on parts of documents. We also found that their controllability is limited.",
    "authors": [
        "T. Doi",
        "Masaru Isonuma",
        "Hitomi Yanaka"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": null
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}