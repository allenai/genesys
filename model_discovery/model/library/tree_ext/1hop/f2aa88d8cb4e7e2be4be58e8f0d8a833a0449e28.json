{
    "acronym": "f2aa88d8cb4e7e2be4be58e8f0d8a833a0449e28",
    "title": "How interesting and coherent are the stories generated by a large\u2010scale neural language model? Comparing human and automatic evaluations of machine\u2010generated text",
    "seed_ids": [
        "gpt2",
        "ad7129af0644dbcafa9aa2f111cb76526ea444a1",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "f2aa88d8cb4e7e2be4be58e8f0d8a833a0449e28",
    "abstract": "Evaluation of the narrative text generated by machines has traditionally been a challenge, particularly when attempting to evaluate subjective elements such as interest or believability. Recent improvements in narrative machine text generation have been largely driven by the emergence of transformer\u2010based language models, trained on massive quantities of data, resulting in higher quality text generation. In this study, a corpus of stories is generated using the pre\u2010trained GPT\u2010Neo transformer model, with human\u2010written prompts as inputs upon which to base the narrative text. The stories generated through this process are subsequently evaluated through both human evaluation and two automated metrics: BERTScore and BERT Next Sentence Prediction, with the aim of determining whether there is a correlation between the automatic scores and the human judgements. The results show variation in human evaluation results in comparison to modern automated metrics, suggesting further work is required to train automated metrics to identify text that is defined as interesting by humans.",
    "authors": [
        "Dominic Callan",
        "Jennifer Foster"
    ],
    "venue": "Expert Syst. J. Knowl. Eng.",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The results show variation in human evaluation results in comparison to modern automated metrics, suggesting further work is required to train automated metrics to identify text that is defined as interesting by humans."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}