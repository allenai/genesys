{
    "acronym": "6dfe924408e00e4cbbb7b348031ccfb7b30448e8",
    "title": "Draw Your Art Dream: Diverse Digital Art Synthesis with Multimodal Guided Diffusion",
    "seed_ids": [
        "classfreediffu",
        "c57293882b2561e1ba03017902df9fc2f289dea2",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "2cd605106b88c85d7d8b865b1ef0f8c8293debf1"
    ],
    "s2id": "6dfe924408e00e4cbbb7b348031ccfb7b30448e8",
    "abstract": "Digital art synthesis is receiving increasing attention in the multimedia community because of engaging the public with art effectively. Current digital art synthesis methods usually use single-modality inputs as guidance, thereby limiting the expressiveness of the model and the diversity of generated results. To solve this problem, we propose the multimodal guided artwork diffusion (MGAD) model, which is a diffusion-based digital artwork generation approach that utilizes multimodal prompts as guidance to control the classifier-free diffusion model. Additionally, the contrastive language-image pretraining (CLIP) model is used to unify text and image modalities. Extensive experimental results on the quality and quantity of the generated digital art paintings confirm the effectiveness of the combination of the diffusion model and multimodal guidance. Code is available at https://github.com/haha-lisa/MGAD-multimodal-guided-artwork-diffusion.",
    "authors": [
        "Nisha Huang",
        "Fan Tang",
        "Weiming Dong",
        "Changsheng Xu"
    ],
    "venue": "ACM Multimedia",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The multi-modality guided artwork diffusion (MGAD) model is proposed, which is a diffusion-based digital artwork generation approach that utilizes multimodal prompts as guidance to control the classifier-free diffusion model."
    },
    "citationCount": 27,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}