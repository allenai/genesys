{
    "acronym": "c54a5fffdb9f30df445900742815de50dda28376",
    "title": "Abstractive summarization of hospitalisation histories with transformer networks",
    "seed_ids": [
        "longformer",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "25db56fc85fe15625c3375064a35e908ba6dfd2a",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481"
    ],
    "s2id": "c54a5fffdb9f30df445900742815de50dda28376",
    "abstract": "In this paper we present a novel approach to abstractive summarization of patient hospitalisation histories. We applied an encoder-decoder framework with Longformer neural network as an encoder and BERT as a decoder. Our experiments show improved quality on some summarization tasks compared with pointer-generator networks. We also conducted a study with experienced physicians evaluating the results of our model in comparison with PGN baseline and human-generated abstracts, which showed the effectiveness of our model.",
    "authors": [
        "Alexander Yalunin",
        "D. Umerenkov",
        "V. Kokh"
    ],
    "venue": "arXiv.org",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "An encoder-decoder framework with Longformer neural network as an encoder and BERT as a decoder is applied to abstractive summarization of patient hospitalisation histories to show improved quality on some summarization tasks compared with pointer-generator networks."
    },
    "citationCount": 7,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}