{
    "acronym": "f56e9b5622141de6319e6bca39ab0ad235ef89e5",
    "title": "Large-Scale Self-Supervised Speech Representation Learning for Automatic Speaker Verification",
    "seed_ids": [
        "gpt"
    ],
    "s2id": "f56e9b5622141de6319e6bca39ab0ad235ef89e5",
    "abstract": "The speech representations learned from large-scale unlabeled data have shown better generalizability than those from supervised learning and thus attract a lot of interest to be applied for various downstream tasks. In this paper, we explore the limits of speech representations learned by different self-supervised objectives and datasets for automatic speaker verification (ASV), especially with a well-recognized SOTA ASV model, ECAPA-TDNN [1], as a downstream model. The representations from all hidden layers of the pre-trained model are firstly averaged with learnable weights and then fed into the ECAPA-TDNN as input features. The experimental results on Voxceleb dataset show that the weighted average representation is significantly superior to FBank, a conventional handcrafted feature for ASV. Our best single system achieves 0.537%, 0.569%, and 1.180% equal error rate (EER) on the three official trials of VoxCeleb1, separately. Accordingly, the ensemble system with three pre-trained models can further improve the EER to 0.479%, 0.536% and 1.023%. Among the three evaluation trials, our best system outperforms the winner system [2] of the VoxCeleb Speaker Recognition Challenge 2021 (VoxSRC2021) on the VoxCeleb1-E trial.",
    "authors": [
        "Zhengyang Chen",
        "Sanyuan Chen",
        "Yu Wu",
        "Yao Qian",
        "Chengyi Wang",
        "Shujie Liu",
        "Y. Qian",
        "Michael Zeng"
    ],
    "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The limits of speech representations learned by different self-supervised objectives and datasets for automatic speaker verification (ASV) are explored, especially with a well-recognized SOTA ASV model, ECAPA-TDNN, as a downstream model."
    },
    "citationCount": 87,
    "influentialCitationCount": 8,
    "code": null,
    "description": null,
    "url": null
}