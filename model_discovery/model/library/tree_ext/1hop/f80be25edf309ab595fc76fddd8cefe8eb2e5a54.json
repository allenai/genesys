{
    "acronym": "f80be25edf309ab595fc76fddd8cefe8eb2e5a54",
    "title": "GNN-FiLM: Graph Neural Networks with Feature-wise Linear Modulation",
    "seed_ids": [
        "lighdynconv"
    ],
    "s2id": "f80be25edf309ab595fc76fddd8cefe8eb2e5a54",
    "abstract": "This paper presents a new Graph Neural Network (GNN) type using feature-wise linear modulation (FiLM). Many standard GNN variants propagate information along the edges of a graph by computing \"messages\" based only on the representation of the source of each edge. In GNN-FiLM, the representation of the target node of an edge is additionally used to compute a transformation that can be applied to all incoming messages, allowing feature-wise modulation of the passed information. \nResults of experiments comparing different GNN architectures on three tasks from the literature are presented, based on re-implementations of baseline methods. Hyperparameters for all methods were found using extensive search, yielding somewhat surprising results: differences between baseline models are smaller than reported in the literature. Nonetheless, GNN-FiLM outperforms baseline methods on a regression task on molecular graphs and performs competitively on other tasks.",
    "authors": [
        "Marc Brockschmidt"
    ],
    "venue": "International Conference on Machine Learning",
    "year": 2019,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper presents a new Graph Neural Network type using feature-wise linear modulation (FiLM), which outperforms baseline methods on a regression task on molecular graphs and performs competitively on other tasks."
    },
    "citationCount": 105,
    "influentialCitationCount": 17,
    "code": null,
    "description": null,
    "url": null
}