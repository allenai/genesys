{
    "acronym": "44855f05648a7b3a0d78729959f900de629c686f",
    "title": "Retrieval-Augmented Transformer-XL for Close-Domain Dialog Generation",
    "seed_ids": [
        "transformerxl",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c"
    ],
    "s2id": "44855f05648a7b3a0d78729959f900de629c686f",
    "abstract": "\n \n \nTransformer-based models have demonstrated excellent capabilities of capturing patterns and structures in natural language generation and achieved state-of-the-art results in many tasks. In this paper we present a transformer-based model for multi-turn dialog response generation. Our solution is based on a hybrid approach which augments a transformer-based generative model with a novel retrieval mechanism, which leverages the memorized information in the training data via k-Nearest Neighbor search. Our system is evaluated on two datasets made by customer/assistant dialogs: the Taskmaster-1, released by Google and holding high quality, goal-oriented conversational data and a proprietary dataset collected from a real customer service call center. Both achieve better BLEU scores over strong baselines. \n \n \n",
    "authors": [
        "Giovanni Bonetta",
        "R. Cancelliere",
        "Ding Liu",
        "Paul Vozila"
    ],
    "venue": "The Florida AI Research Society",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper presents a hybrid approach which augments a transformer-based generative model with a novel retrieval mechanism, which leverages the memorized information in the training data via k-Nearest Neighbor search."
    },
    "citationCount": 10,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}