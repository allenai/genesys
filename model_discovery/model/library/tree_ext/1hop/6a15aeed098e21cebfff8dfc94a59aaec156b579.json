{
    "acronym": "6a15aeed098e21cebfff8dfc94a59aaec156b579",
    "title": "Exploring COVID-related relationship extraction: Contrasting data sources and analyzing misinformation",
    "seed_ids": [
        "bert"
    ],
    "s2id": "6a15aeed098e21cebfff8dfc94a59aaec156b579",
    "abstract": null,
    "authors": [
        "Tanvi Sharma",
        "Amer Farea",
        "Nadeesha Perera",
        "Frank Emmert-Streib"
    ],
    "venue": "Heliyon",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper delves into the extraction of COVID-related relations using transformer-based language models, including Bidirectional Encoder Representations from Transformers (BERT) and DistilBERT, demonstrating that language models can unveil previously unseen entities and relations, a crucial aspect in identifying instances of misinformation."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}