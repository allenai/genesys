{
    "acronym": "690edf44e8739fd80bdfb76f40c9a4a222f3bba8",
    "title": "BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer",
    "seed_ids": [
        "gpt",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "690edf44e8739fd80bdfb76f40c9a4a222f3bba8",
    "abstract": "Modeling users' dynamic preferences from their historical behaviors is challenging and crucial for recommendation systems. Previous methods employ sequential neural networks to encode users' historical interactions from left to right into hidden representations for making recommendations. Despite their effectiveness, we argue that such left-to-right unidirectional models are sub-optimal due to the limitations including: \\begin enumerate* [label=series\\itshape\\alph*\\upshape)] \\item unidirectional architectures restrict the power of hidden representation in users' behavior sequences; \\item they often assume a rigidly ordered sequence which is not always practical. \\end enumerate* To address these limitations, we proposed a sequential recommendation model called BERT4Rec, which employs the deep bidirectional self-attention to model user behavior sequences. To avoid the information leakage and efficiently train the bidirectional model, we adopt the Cloze objective to sequential recommendation, predicting the random masked items in the sequence by jointly conditioning on their left and right context. In this way, we learn a bidirectional representation model to make recommendations by allowing each item in user historical behaviors to fuse information from both left and right sides. Extensive experiments on four benchmark datasets show that our model outperforms various state-of-the-art sequential models consistently.",
    "authors": [
        "Fei Sun",
        "Jun Liu",
        "Jian Wu",
        "Changhua Pei",
        "Xiao Lin",
        "Wenwu Ou",
        "Peng Jiang"
    ],
    "venue": "International Conference on Information and Knowledge Management",
    "year": 2019,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A sequential recommendation model called BERT4Rec is proposed, which employs the deep bidirectional self-attention to model user behavior sequences, and outperforms various state-of-the-art sequential models consistently."
    },
    "citationCount": 1549,
    "influentialCitationCount": 242,
    "code": null,
    "description": null,
    "url": null
}