{
    "acronym": "86194a67c29be577e4010914d1570970d27522b2",
    "title": "Fast streaming translation using machine learning with transformer",
    "seed_ids": [
        "lineartransformer",
        "8f69ccdb1391074b523f5093cb68cc635c4e2391",
        "6f68e1bb253925d8431588555d3010419f322e04"
    ],
    "s2id": "86194a67c29be577e4010914d1570970d27522b2",
    "abstract": "Machine Translation is the usage of machine learning techniques in translation from one language to another. It has recently been applied to streaming translation, also known as automatic subtitling. The most common challenge in this area is the trade-off between correctness and speed. Due to its real-time feature, streaming translation needs high speed as it has strict playtime constraints. This paper proposes an enhanced Transformer model for fast streaming translation. The proposed machine-learning method is described, implemented, and evaluated based on a common German-English bilingual dataset. The evaluation results have shown that the proposed system successfully achieved a good speed in the training phase, and a high speed in the actual translating phrase that is fast enough for real-time applications, while also maintaining robust correctness. We believe the proposed Transformer model is a significant contribution to natural-language processing, and would be useful for other real-time translation applications.",
    "authors": [
        "Jiabao Qiu",
        "M. Moh",
        "Teng-Sheng Moh"
    ],
    "venue": "ACM Southeast Conference",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The proposed Transformer model is believed to be a significant contribution to natural-language processing, and would be useful for other real-time translation applications."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}