{
    "acronym": "7bcdfc0759561118cd79667379c5d174e2a747f2",
    "title": "SaProt: Protein Language Modeling with Structure-aware Vocabulary",
    "seed_ids": [
        "bert",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481"
    ],
    "s2id": "7bcdfc0759561118cd79667379c5d174e2a747f2",
    "abstract": "Large-scale protein language models (PLMs), such as the ESM family, have achieved remarkable performance in various downstream tasks related to protein structure and function by undergoing unsupervised training on residue sequences. They have become essential tools for researchers and practitioners in biology. However, a limitation of vanilla PLMs is their lack of explicit consideration for protein structure information, which suggests the potential for further improvement. Motivated by this, we introduce the concept of a \u201cstructure-aware vocabulary\u201d that integrates residue tokens with structure tokens. The structure tokens are derived by encoding the 3D structure of proteins using Foldseek. We then propose SaProt, a large-scale general-purpose PLM trained on an extensive dataset comprising approximately 40 million protein sequences and structures. Through extensive evaluation, our SaProt model surpasses well-established and renowned baselines across 10 significant downstream tasks, demonstrating its exceptional capacity and broad applicability. We have made the code1, pre-trained model, and all relevant materials available at https://github.com/westlake-repl/SaProt.",
    "authors": [
        "Jin Su",
        "Chenchen Han",
        "Yuyang Zhou",
        "Junjie Shan",
        "Xibin Zhou",
        "Fajie Yuan"
    ],
    "venue": "bioRxiv",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work introduces the concept of a \u201cstructure-aware vocabulary\u201d that integrates residue tokens with structure tokens and proposes SaProt, a large-scale general-purpose PLM trained on an extensive dataset comprising approximately 40 million protein sequences and structures."
    },
    "citationCount": 36,
    "influentialCitationCount": 6,
    "code": null,
    "description": null,
    "url": null
}