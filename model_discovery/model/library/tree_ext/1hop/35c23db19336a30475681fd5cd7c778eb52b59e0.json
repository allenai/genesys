{
    "acronym": "35c23db19336a30475681fd5cd7c778eb52b59e0",
    "title": "Memorization for Good: Encryption with Autoregressive Language Models",
    "seed_ids": [
        "gpt2",
        "29ddc1f43f28af7c846515e32cc167bc66886d0c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "35c23db19336a30475681fd5cd7c778eb52b59e0",
    "abstract": "Over-parameterized neural language models (LMs) can memorize and recite long sequences of training data. While such memorization is normally associated with undesired properties such as overfitting and information leaking, our work casts memorization as an unexplored capability of LMs. We propose the first symmetric encryption algorithm with autoregressive language models (SELM). We show that autoregressive LMs can encode arbitrary data into a compact real-valued vector (i.e., encryption) and then losslessly decode the vector to the original message (i.e., decryption) via random subspace optimization and greedy decoding. While SELM is not amenable to conventional cryptanalysis, we investigate its security through a novel empirical variant of the classic IND-CPA (indistinguishability under chosen-plaintext attack) game and show promising results on security. Our code and datasets are available at https://github.com/OSU-NLP-Group/SELM.",
    "authors": [
        "Samuel Stevens",
        "Yung-Chun Su"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes the first symmetric encryption algorithm with autoregressive language models (SELM) and shows that autore progressive LMs can encode arbitrary data into a compact real-valued vector and then losslessly decode the vector to the original message."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}