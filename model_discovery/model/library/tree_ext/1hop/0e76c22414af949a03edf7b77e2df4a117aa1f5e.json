{
    "acronym": "0e76c22414af949a03edf7b77e2df4a117aa1f5e",
    "title": "Softmax-free Linear Transformers",
    "seed_ids": [
        "nystromformer",
        "performer",
        "linformer",
        "reformer",
        "2e644c67a697073d561da4f4dad35e5ad5316cfd",
        "3cbe314cc5407a6c3249815b5173f22ea15173c2",
        "054e307c1edf4b28137ffcbce980fe81f0647d20",
        "b3bf9fe13195e9aa70e1dac04e01fcff7008e812",
        "9ed25f101f19ea735ca300848948ed64064b97ca",
        "cec7872b194aadf54140578b9be52939eb1112e9",
        "6fa1cfc4f97f03a8485692418c7aa1a06c574a85",
        "7e9ff94476f41041c75e253e84f487db00e9c861",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
        "7e5709d81558d3ef4265de29ea75931afeb1f2dd",
        "6f68e1bb253925d8431588555d3010419f322e04",
        "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
        "8cef9900c04d7f661c08f4b5b1ed4337ace042a3",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7"
    ],
    "s2id": "0e76c22414af949a03edf7b77e2df4a117aa1f5e",
    "abstract": null,
    "authors": [
        "Jiachen Lu",
        "Li Zhang",
        "Junge Zhang",
        "Xiatian Zhu",
        "Hang Xu",
        "Jianfeng Feng"
    ],
    "venue": "International Journal of Computer Vision",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A family of Softmax-Free Transformers (SOFT) is proposed, with a Gaussian kernel function adopted to replace the dot-product similarity, enabling a full self-attention matrix to be approximated under low-rank matrix decomposition."
    },
    "citationCount": 3,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}