{
    "acronym": "bfd6c10943a5db5f3df74bae20e3ee6570d73a75",
    "title": "VANER: Leveraging Large Language Model for Versatile and Adaptive Biomedical Named Entity Recognition",
    "seed_ids": [
        "bert",
        "ffdd0b97b9ba996ba85e1a96f4a50ef86b796a4a",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c"
    ],
    "s2id": "bfd6c10943a5db5f3df74bae20e3ee6570d73a75",
    "abstract": "Prevalent solution for BioNER involves using representation learning techniques coupled with sequence labeling. However, such methods are inherently task-specific, demonstrate poor generalizability, and often require dedicated model for each dataset. To leverage the versatile capabilities of recently remarkable large language models (LLMs), several endeavors have explored generative approaches to entity extraction. Yet, these approaches often fall short of the effectiveness of previouly sequence labeling approaches. In this paper, we utilize the open-sourced LLM LLaMA2 as the backbone model, and design specific instructions to distinguish between different types of entities and datasets. By combining the LLM's understanding of instructions with sequence labeling techniques, we use mix of datasets to train a model capable of extracting various types of entities. Given that the backbone LLMs lacks specialized medical knowledge, we also integrate external entity knowledge bases and employ instruction tuning to compel the model to densely recognize carefully curated entities. Our model VANER, trained with a small partition of parameters, significantly outperforms previous LLMs-based models and, for the first time, as a model based on LLM, surpasses the majority of conventional state-of-the-art BioNER systems, achieving the highest F1 scores across three datasets.",
    "authors": [
        "Junyi Bian",
        "W. Zhai",
        "Xiaodi Huang",
        "Jiaxuan Zheng",
        "Shanfeng Zhu"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The model VANER, trained with a small partition of parameters, significantly outperforms previous LLMs-based models and, for the first time, as a model based on LLM, surpasses the majority of conventional state-of-the-art BioNER systems, achieving the highest F1 scores across three datasets."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}