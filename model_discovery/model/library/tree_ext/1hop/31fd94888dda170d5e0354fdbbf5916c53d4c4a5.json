{
    "acronym": "31fd94888dda170d5e0354fdbbf5916c53d4c4a5",
    "title": "Exploring Adversarial Robustness of Deep State Space Models",
    "seed_ids": [
        "s4",
        "mamba",
        "mega",
        "s5",
        "b24e899ec0f77eef2fc87a9b8e50516367aa1f97",
        "38c48a1cd296d16dc9c56717495d6e44cc354444",
        "b3caabbae4b7c3b842086b21940ce9d5b25d476f",
        "d2d0371158803df93a249c9f7237ffd79b875816",
        "70e91e16eb321067d9402710e14a40cf28311f73",
        "6d7d141c75af752ffc0d8a6184cca3f9323d6c74",
        "eaef083b9d661f42cc0d89d9d8156218f33a91d9",
        "ca444821352a4bd91884413d8070446e2960715a",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "ca9047c78d48b606c4e4f0c456b1dda550de28b2"
    ],
    "s2id": "31fd94888dda170d5e0354fdbbf5916c53d4c4a5",
    "abstract": "Deep State Space Models (SSMs) have proven effective in numerous task scenarios but face significant security challenges due to Adversarial Perturbations (APs) in real-world deployments. Adversarial Training (AT) is a mainstream approach to enhancing Adversarial Robustness (AR) and has been validated on various traditional DNN architectures. However, its effectiveness in improving the AR of SSMs remains unclear. While many enhancements in SSM components, such as integrating Attention mechanisms and expanding to data-dependent SSM parameterizations, have brought significant gains in Standard Training (ST) settings, their potential benefits in AT remain unexplored. To investigate this, we evaluate existing structural variants of SSMs with AT to assess their AR performance. We observe that pure SSM structures struggle to benefit from AT, whereas incorporating Attention yields a markedly better trade-off between robustness and generalization for SSMs in AT compared to other components. Nonetheless, the integration of Attention also leads to Robust Overfitting (RO) issues. To understand these phenomena, we empirically and theoretically analyze the output error of SSMs under AP. We find that fixed-parameterized SSMs have output error bounds strictly related to their parameters, limiting their AT benefits, while input-dependent SSMs may face the problem of error explosion. Furthermore, we show that the Attention component effectively scales the output error of SSMs during training, enabling them to benefit more from AT, but at the cost of introducing RO due to its high model complexity. Inspired by this, we propose a simple and effective Adaptive Scaling (AdS) mechanism that brings AT performance close to Attention-integrated SSMs without introducing the issue of RO.",
    "authors": [
        "Biqing Qi",
        "Yang Luo",
        "Junqi Gao",
        "Pengfei Li",
        "Kai Tian",
        "Zhiyuan Ma",
        "Bowen Zhou"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work evaluates existing structural variants of SSMs with AT to assess their AR performance and proposes a simple and effective Adaptive Scaling (AdS) mechanism that brings AT performance close to Attention-integrated SSMs without introducing the issue of RO."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}