{
    "acronym": "fb635d202d0a6563b3246276911613524f3b0769",
    "title": "Can large language models understand uncommon meanings of common words?",
    "seed_ids": [
        "gpt3",
        "c1592c211f8b7791a55afd7162249c723b87c237",
        "ed38c6b157c11476939c426ec6871c926f2f3524",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c"
    ],
    "s2id": "fb635d202d0a6563b3246276911613524f3b0769",
    "abstract": "Large language models (LLMs) like ChatGPT have shown significant advancements across diverse natural language understanding (NLU) tasks, including intelligent dialogue and autonomous agents. Yet, lacking widely acknowledged testing mechanisms, answering `whether LLMs are stochastic parrots or genuinely comprehend the world' remains unclear, fostering numerous studies and sparking heated debates. Prevailing research mainly focuses on surface-level NLU, neglecting fine-grained explorations. However, such explorations are crucial for understanding their unique comprehension mechanisms, aligning with human cognition, and finally enhancing LLMs' general NLU capacities. To address this gap, our study delves into LLMs' nuanced semantic comprehension capabilities, particularly regarding common words with uncommon meanings. The idea stems from foundational principles of human communication within psychology, which underscore accurate shared understandings of word semantics. Specifically, this paper presents the innovative construction of a Lexical Semantic Comprehension (LeSC) dataset with novel evaluation metrics, the first benchmark encompassing both fine-grained and cross-lingual dimensions. Introducing models of both open-source and closed-source, varied scales and architectures, our extensive empirical experiments demonstrate the inferior performance of existing models in this basic lexical-meaning understanding task. Notably, even the state-of-the-art LLMs GPT-4 and GPT-3.5 lag behind 16-year-old humans by 3.9% and 22.3%, respectively. Additionally, multiple advanced prompting techniques and retrieval-augmented generation are also introduced to help alleviate this trouble, yet limitations persist. By highlighting the above critical shortcomings, this research motivates further investigation and offers novel insights for developing more intelligent LLMs.",
    "authors": [
        "Jinyang Wu",
        "Feihu Che",
        "Xinxin Zheng",
        "Shuai Zhang",
        "Ruihan Jin",
        "Shuai Nie",
        "Pengpeng Shao",
        "Jianhua Tao"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This study delves into LLMs' nuanced semantic comprehension capabilities, particularly regarding common words with uncommon meanings, with the innovative construction of a Lexical Semantic Comprehension (LeSC) dataset with novel evaluation metrics, the first benchmark encompassing both fine-grained and cross-lingual dimensions."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}