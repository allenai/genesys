{
    "acronym": "232b32209c3900d1098868286488358430ba4f8f",
    "title": "Is Mamba Compatible with Trajectory Optimization in Offline Reinforcement Learning?",
    "seed_ids": [
        "hiddenattnmamba",
        "31fdba3a68f286894f025e734a277e2ce94dd84c",
        "9b8130a2a5d3398f4993f540ddd01d440d99d62e",
        "b9646f057887825d7471ec01664494b0b7ca5a83",
        "3af7273d7ca20c0c63cbaa47e60b058840835052",
        "e34868427f607bd35f11576963c36b95673e5a75",
        "26e6cd121c5fdb147df83cb848e4813c926737c8",
        "b24e899ec0f77eef2fc87a9b8e50516367aa1f97",
        "38c48a1cd296d16dc9c56717495d6e44cc354444",
        "b72e539c78e061e4e93f8af8299bba3e305c503e",
        "d98b5c1d0f9a4e39dc79ea7a3f74e54789df5e13",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "6f68e1bb253925d8431588555d3010419f322e04",
        "a8427ce5aee6d62800c725588e89940ed4910e0d",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "232b32209c3900d1098868286488358430ba4f8f",
    "abstract": "Transformer-based trajectory optimization methods have demonstrated exceptional performance in offline Reinforcement Learning (offline RL), yet it poses challenges due to substantial parameter size and limited scalability, which is particularly critical in sequential decision-making scenarios where resources are constrained such as in robots and drones with limited computational power. Mamba, a promising new linear-time sequence model, offers performance on par with transformers while delivering substantially fewer parameters on long sequences. As it remains unclear whether Mamba is compatible with trajectory optimization, this work aims to conduct comprehensive experiments to explore the potential of Decision Mamba in offline RL (dubbed DeMa) from the aspect of data structures and network architectures with the following insights: (1) Long sequences impose a significant computational burden without contributing to performance improvements due to the fact that DeMa's focus on sequences diminishes approximately exponentially. Consequently, we introduce a Transformer-like DeMa as opposed to an RNN-like DeMa. (2) For the components of DeMa, we identify that the hidden attention mechanism is key to its success, which can also work well with other residual structures and does not require position embedding. Extensive evaluations from eight Atari games demonstrate that our specially designed DeMa is compatible with trajectory optimization and surpasses previous state-of-the-art methods, outdoing Decision Transformer (DT) by 80\\% with 30\\% fewer parameters, and exceeds DT in MuJoCo with only a quarter of the parameters.",
    "authors": [
        "Yang Dai",
        "Oubo Ma",
        "Longfei Zhang",
        "Xingxing Liang",
        "Shengchao Hu",
        "Mengzhu Wang",
        "Shouling Ji",
        "Jincai Huang",
        "Li Shen"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work introduces a Transformer-like DeMa, a specially designed DeMa that is compatible with trajectory optimization and surpasses previous state-of-the-art methods, outdoing Decision Transformer by 80% with 30% fewer parameters, and exceeds DT in MuJoCo with only a quarter of the parameters."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}