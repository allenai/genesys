{
    "acronym": "47c1c6f46db3d77d4941f270646059d2aaae73f8",
    "title": "A Review of Video Generation Approaches",
    "seed_ids": [
        "axialattn",
        "366244acdd930e488ae224ab6e2a92dc24aa7e06",
        "e763fdc9ae56826ff799163ea035b29bffd8ea6f",
        "18d41e3bd94cf38736e37580912c3b4ba56f08d5"
    ],
    "s2id": "47c1c6f46db3d77d4941f270646059d2aaae73f8",
    "abstract": "Generating videos from some initial frames is an appealing field of research in deep learning. There exists an ever expanding foray of approaches to generate long-range and realistic video frame series. Generating videos can help predict trajectories and even model object movements, to enhance autonomous robots. However, there are only a few comprehensive studies that review various approaches on the basis of their relative advantages, disadvantages, and evolution. Hence, this paper presents a detailed overview of Deep Learning based approaches employed to tackle the complex problem of video generation. The approaches involve Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs) and even the Transformer model. Finally, the performance of all the approaches are examined and compared on the BAIR Robot Pushing dataset.",
    "authors": [
        "Rishika Bhagwatkar",
        "Saketh Bachu",
        "Khurshed Fitter",
        "Akshay Ravindra Kulkarni",
        "S. Chiddarwar"
    ],
    "venue": "2020 International Conference on Power, Instrumentation, Control and Computing (PICC)",
    "year": 2020,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper presents a detailed overview of Deep Learning based approaches employed to tackle the complex problem of video generation, which involve Variational Autoencoders, Generative Adversarial Networks, and even the Transformer model."
    },
    "citationCount": 7,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}