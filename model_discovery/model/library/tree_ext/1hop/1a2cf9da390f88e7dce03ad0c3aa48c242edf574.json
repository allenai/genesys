{
    "acronym": "1a2cf9da390f88e7dce03ad0c3aa48c242edf574",
    "title": "A fine-grained comparison of pragmatic language understanding in humans and language models",
    "seed_ids": [
        "gpt2",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "1a2cf9da390f88e7dce03ad0c3aa48c242edf574",
    "abstract": "Pragmatics and non-literal language understanding are essential to human communication, and present a long-standing challenge for artificial language models. We perform a fine-grained comparison of language models and humans on seven pragmatic phenomena, using zero-shot prompting on an expert-curated set of English materials. We ask whether models (1) select pragmatic interpretations of speaker utterances, (2) make similar error patterns as humans, and (3) use similar linguistic cues as humans to solve the tasks. We find that the largest models achieve high accuracy and match human error patterns: within incorrect responses, models favor literal interpretations over heuristic-based distractors. We also find preliminary evidence that models and humans are sensitive to similar linguistic cues. Our results suggest that pragmatic behaviors can emerge in models without explicitly constructed representations of mental states. However, models tend to struggle with phenomena relying on social expectation violations.",
    "authors": [
        "Jennifer Hu",
        "Sammy Floyd",
        "Olessia Jouravlev",
        "Evelina Fedorenko",
        "E. Gibson"
    ],
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A fine-grained comparison of language models and humans on seven pragmatic phenomena, using zero-shot prompting on an expert-curated set of English materials, suggests that pragmatic behaviors can emerge in models without explicitly constructed representations of mental states."
    },
    "citationCount": 29,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}