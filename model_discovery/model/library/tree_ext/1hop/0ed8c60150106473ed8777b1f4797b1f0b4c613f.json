{
    "acronym": "0ed8c60150106473ed8777b1f4797b1f0b4c613f",
    "title": "TWAG: A Topic-Guided Wikipedia Abstract Generator",
    "seed_ids": [
        "memcompress",
        "addd2d86d19c1e7c8854e827fb2656a50c250440",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "0bd5beed98675a63f9207851674d478009549900",
        "7cc730da554003dda77796d2cb4f06da5dfd5592"
    ],
    "s2id": "0ed8c60150106473ed8777b1f4797b1f0b4c613f",
    "abstract": "Wikipedia abstract generation aims to distill a Wikipedia abstract from web sources and has met significant success by adopting multi-document summarization techniques. However, previous works generally view the abstract as plain text, ignoring the fact that it is a description of a certain entity and can be decomposed into different topics. In this paper, we propose a two-stage model TWAG that guides the abstract generation with topical information. First, we detect the topic of each input paragraph with a classifier trained on existing Wikipedia articles to divide input documents into different topics. Then, we predict the topic distribution of each abstract sentence, and decode the sentence from topic-aware representations with a Pointer-Generator network. We evaluate our model on the WikiCatSum dataset, and the results show that TWAG outperforms various existing baselines and is capable of generating comprehensive abstracts.",
    "authors": [
        "Fangwei Zhu",
        "Shangqing Tu",
        "Jiaxin Shi",
        "Juan-Zi Li",
        "Lei Hou",
        "Tong Cui"
    ],
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A two-stage model TWAG is proposed that guides the abstract generation with topical information and outperforms various existing baselines and is capable of generating comprehensive abstracts."
    },
    "citationCount": 10,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}