{
    "acronym": "83b40da37bcca822ff2daff18e460e07067bfad3",
    "title": "\u201cYou are an expert annotator\u201d: Automatic Best\u2013Worst-Scaling Annotations for Emotion Intensity Modeling",
    "seed_ids": [
        "gpt2",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "83b40da37bcca822ff2daff18e460e07067bfad3",
    "abstract": "Labeling corpora constitutes a bottleneck to create models for new tasks or domains. Large language models mitigate the issue with automatic corpus labeling methods, particularly for categorical annotations. Some NLP tasks such as emotion intensity prediction, however, require text regression, but there is no work on automating annotations for continuous label assignments. Regression is considered more challenging than classification: The fact that humans perform worse when tasked to choose values from a rating scale lead to comparative annotation methods, including best\u2013worst scaling. This raises the question if large language model-based annotation methods show similar patterns, namely that they perform worse on rating scale annotation tasks than on comparative annotation tasks. To study this, we automate emotion intensity predictions and compare direct rating scale predictions, pairwise comparisons and best\u2013worst scaling. We find that the latter shows the highest reliability. A transformer regressor fine-tuned on these data performs nearly on par with a model trained on the original manual annotations.",
    "authors": [
        "Christopher Bagdon",
        "P. Karmalkar",
        "Harsha Gurulingappa",
        "Roman Klinger"
    ],
    "venue": "North American Chapter of the Association for Computational Linguistics",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "An automate emotion intensity predictions and a transformer regressor fine-tuned on these data performs nearly on par with a model trained on the original manual annotations, finding that the latter shows the highest reliability."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}