{
    "acronym": "aa99a3b9a4174f1bbd9cb12e28171c4b183949c0",
    "title": "A Review of Multi-Modal Large Language and Vision Models",
    "seed_ids": [
        "transformer",
        "gpt2",
        "gpt3",
        "04f4e55e14150b7c48b0287ba77c7443df76ed45",
        "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "aa99a3b9a4174f1bbd9cb12e28171c4b183949c0",
    "abstract": "Large Language Models (LLMs) have recently emerged as a focal point of research and application, driven by their unprecedented ability to understand and generate text with human-like quality. Even more recently, LLMs have been extended into multi-modal large language models (MM-LLMs) which extends their capabilities to deal with image, video and audio information, in addition to text. This opens up applications like text-to-video generation, image captioning, text-to-speech, and more and is achieved either by retro-fitting an LLM with multi-modal capabilities, or building a MM-LLM from scratch. This paper provides an extensive review of the current state of those LLMs with multi-modal capabilities as well as the very recent MM-LLMs. It covers the historical development of LLMs especially the advances enabled by transformer-based architectures like OpenAI's GPT series and Google's BERT, as well as the role of attention mechanisms in enhancing model performance. The paper includes coverage of the major and most important of the LLMs and MM-LLMs and also covers the techniques of model tuning, including fine-tuning and prompt engineering, which tailor pre-trained models to specific tasks or domains. Ethical considerations and challenges, such as data bias and model misuse, are also analysed to underscore the importance of responsible AI development and deployment. Finally, we discuss the implications of open-source versus proprietary models in AI research. Through this review, we provide insights into the transformative potential of MM-LLMs in various applications.",
    "authors": [
        "Kilian Carolan",
        "Laura Fennelly",
        "A. Smeaton"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper provides an extensive review of the current state of those LLMs with multi-modal capabilities as well as the very recent MM-LLMs and also covers the techniques of model tuning, including fine-tuning and prompt engineering, which tailor pre-trained models to specific tasks or domains."
    },
    "citationCount": 3,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}