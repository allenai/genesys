{
    "acronym": "911f28279f8f80f1520181ecc4e839c54408a68c",
    "title": "Offline Actor-Critic Reinforcement Learning Scales to Large Models",
    "seed_ids": [
        "perceiverio",
        "60c8d0619481eaafdd1189af610d0e636271fed5",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "b3bf9fe13195e9aa70e1dac04e01fcff7008e812"
    ],
    "s2id": "911f28279f8f80f1520181ecc4e839c54408a68c",
    "abstract": "We show that offline actor-critic reinforcement learning can scale to large models - such as transformers - and follows similar scaling laws as supervised learning. We find that offline actor-critic algorithms can outperform strong, supervised, behavioral cloning baselines for multi-task training on a large dataset containing both sub-optimal and expert behavior on 132 continuous control tasks. We introduce a Perceiver-based actor-critic model and elucidate the key model features needed to make offline RL work with self- and cross-attention modules. Overall, we find that: i) simple offline actor critic algorithms are a natural choice for gradually moving away from the currently predominant paradigm of behavioral cloning, and ii) via offline RL it is possible to learn multi-task policies that master many domains simultaneously, including real robotics tasks, from sub-optimal demonstrations or self-generated data.",
    "authors": [
        "J. T. Springenberg",
        "A. Abdolmaleki",
        "Jingwei Zhang",
        "Oliver Groth",
        "Michael Bloesch",
        "Thomas Lampe",
        "Philemon Brakel",
        "Sarah Bechtle",
        "Steven Kapturowski",
        "Roland Hafner",
        "N. Heess",
        "Martin A. Riedmiller"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is shown that offline actor-critic reinforcement learning can scale to large models - such as transformers - and follows similar scaling laws as supervised learning and via offline RL it is possible to learn multi-task policies that master many domains simultaneously from sub-optimal demonstrations or self-generated data."
    },
    "citationCount": 3,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}