{
    "acronym": "304584c54c2e06fe26df675d65d0605dcfe426c7",
    "title": "DESCGEN: A Distantly Supervised Datasetfor Generating Entity Descriptions",
    "seed_ids": [
        "memcompress",
        "6e6a2fe517b33e1f29d761ae31fb37ddccb9a213",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "d0086b86103a620a86bc918746df0aa642e2a8a3",
        "ad7129af0644dbcafa9aa2f111cb76526ea444a1"
    ],
    "s2id": "304584c54c2e06fe26df675d65d0605dcfe426c7",
    "abstract": "Short textual descriptions of entities provide summaries of their key attributes and have been shown to be useful sources of background knowledge for tasks such as entity linking and question answering. However, generating entity descriptions, especially for new and long-tail entities, can be challenging since relevant information is often scattered across multiple sources with varied content and style. We introduce DESCGEN: given mentions spread over multiple documents, the goal is to generate an entity summary description. DESCGEN consists of 37K entity descriptions from Wikipedia and Fandom, each paired with nine evidence documents on average. The documents were collected using a combination of entity linking and hyperlinks into the entity pages, which together provide high-quality distant supervision. Compared to other multi-document summarization tasks, our task is entity-centric, more abstractive, and covers a wide range of domains. We also propose a two-stage extract-then-generate baseline and show that there exists a large gap (19.9% in ROUGE-L) between state-of-art models and human performance, suggesting that the data will support significant future work.",
    "authors": [
        "Weijia Shi",
        "Mandar Joshi",
        "Luke Zettlemoyer"
    ],
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Compared to other multi-document summarization tasks, this task is entity-centric, more abstractive, and covers a wide range of domains, and there exists a large gap between state-of-art models and human performance."
    },
    "citationCount": 3,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}