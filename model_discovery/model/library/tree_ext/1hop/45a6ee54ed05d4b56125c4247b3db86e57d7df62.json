{
    "acronym": "45a6ee54ed05d4b56125c4247b3db86e57d7df62",
    "title": "An Empirical Bayes Framework for Open-Domain Dialogue Generation",
    "seed_ids": [
        "gpt2",
        "b9d2ae1d2a494cd9c43031b7131bb697b8752533",
        "6ebfbc954b9975d2f2651f380b9bdf46ae963178",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "45a6ee54ed05d4b56125c4247b3db86e57d7df62",
    "abstract": "To engage human users in meaningful conversation, open-domain dialogue agents are required to generate diverse and contextually coherent dialogue. Despite recent advancements, which can be attributed to the usage of pretrained language models, the generation of diverse and coherent dialogue remains an open research problem. A popular approach to address this issue involves the adaptation of variational frameworks. However, while these approaches successfully improve diversity, they tend to compromise on contextual coherence. Hence, we propose the Bayesian Open-domain Dialogue with Empirical Bayes (BODEB) framework, an empirical bayes framework for constructing an Bayesian open-domain dialogue agent by leveraging pretrained parameters to inform the prior and posterior parameter distributions. Empirical results show that BODEB achieves better results in terms of both diversity and coherence compared to variational frameworks.",
    "authors": [
        "Jing Yang Lee",
        "Kong Aik Lee",
        "Woon-Seng Gan"
    ],
    "venue": "IEEE Games Entertainment Media Conference",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes the Bayesian Open-domain Dialogue with Empirical Bayes (BODEB) framework, an empirical bayes framework for constructing an Bayesian open-domain dialogue agent by leveraging pretrained parameters to inform the prior and posterior parameter distributions."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}