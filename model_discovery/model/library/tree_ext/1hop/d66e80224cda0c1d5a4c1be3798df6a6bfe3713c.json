{
    "acronym": "d66e80224cda0c1d5a4c1be3798df6a6bfe3713c",
    "title": "GPT-3 for Few-Shot Dialogue State Tracking",
    "seed_ids": [
        "gpt",
        "85e7d63f75c0916bd350a229e040c5fbb1472e7a",
        "8323c591e119eb09b28b29fd6c7bc76bd889df7a",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "d66e80224cda0c1d5a4c1be3798df6a6bfe3713c",
    "abstract": "GPT-3 (Brown et al., 2020) has attracted considerable attention due to its superior performance across a wide range of Natural Language Processing (NLP) tasks, especially with its powerful and versatile in-context few-shot learning ability. That is, it has been shown that by carefully crafting a prompt, consisting of a few labelled examples followed by an unlabelled example, GPT\u20193 is able to do few-shot sentiment classification, three-digit arithmetic and much more. We seek to evaluate its performance on a novel and notably more complicated task: few-shot Dialogue State Tracking (DST). We propose a few-shot prompting framework that selects in-context examples based on similarity which outperforms the original random in-context selection framework. We also review and formalise the two types of completion strategies employed by previous literature, which we name constrained and unconstrained, and propose a third \"semi-constrained\" completion strategy, which is particularly well adapted for DST. Additionally, we propose a prompt ensembling technique that reliably outperforms individual models. Furthermore, we are the first, to the best of our knowledge, to fine-tune GPT-3 for the task of few-shot DST, showing that it reliably outperforms its GPT-2 counterpart. Furthermore, we seek to synthesise and formalise the largely heterogeneous body of previous work on prompt programming and in-context learning for GPT-3. In an attempt to contribute to the understanding of the strengths, weaknesses and inner-working of GPT-3, we perform numerous ablative studies that validate and confute previous in-context learning empirical findings: mainly, we find that natural language instructions in the prompt have little impact on performance, larger language models do not always induce higher downstream performance and that GPT-3 is highly sensitive to the order and number of the in-context examples.",
    "authors": [
        "Nicholas Pezzotti"
    ],
    "venue": "",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is found that natural language instructions in the prompt have little impact on performance, larger language models do not always induce higher downstream performance and that GPT-3 is highly sensitive to the order and number of the in-context examples."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}