{
    "acronym": "a32bac7214a57d8b7db0b5b8d9c0ace2c8a74a3a",
    "title": "OCTO+: A Suite for Automatic Open-Vocabulary Object Placement in Mixed Reality",
    "seed_ids": [
        "bert"
    ],
    "s2id": "a32bac7214a57d8b7db0b5b8d9c0ace2c8a74a3a",
    "abstract": "One key challenge in Augmented Reality is the placement of virtual content in natural locations. Most existing automated techniques can only work with a closed-vocabulary, fixed set of objects. In this paper, we introduce and evaluate several methods for automatic object placement using recent advances in open-vocabulary vision-language models. Through a multifaceted evaluation, we identify a new state-of-the-art method, OCTO+. We also introduce a benchmark for automatically evaluating the placement of virtual objects in augmented reality, alleviating the need for costly user studies. Through this, in addition to human evaluations, we find that OCTO+ places objects in a valid region over 70% of the time, outperforming other methods on a range of metrics.",
    "authors": [
        "Aditya Sharma",
        "Luke Yoffe",
        "Tobias H\u00f6llerer"
    ],
    "venue": "2024 IEEE International Conference on Artificial Intelligence and eXtended and Virtual Reality (AIxVR)",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper introduces and evaluates several methods for automatic object placement using recent advances in open-vocabulary vision-language models, and identifies a new state-of-the-art method, OCTO+."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}