{
    "acronym": "1ffc56181f12989505e2f08673d812127a7cffdc",
    "title": "Have a chat with BERT ; passage re-ranking using conversational context",
    "seed_ids": [
        "gpt",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c"
    ],
    "s2id": "1ffc56181f12989505e2f08673d812127a7cffdc",
    "abstract": "In this thesis, the problem of question answering using conversational context is explored for the Conversational Assistance Track of the Text REtrieval Conference. The goal of the task in this track is to provide an answer to a query by retrieving responses from a large set of short text passages and ranking these according to their computed relevance to the query. The state-of-the-art NLP model BERT [1] is compared to the baseline ranker BM25 [2]. It is researched how including conversational context in the input influences the predictive power of these models. Multiple methods for dealing with the input restrictions of the BERT model are compared; clipping, summarization and, rank and score fusion. This was evaluated on two datasets of a different nature; a dataset containing artificially generated conversational sessions and one containing handcrafted, more human-like sessions. The results show that BERT outperforms BM25 in all experiments, regardless if or how much context is taken into account. Adding conversational context to the input however does not increase predictive power in both models. Nonetheless, the context processing methods can still be compared; the fusion methods perform best. Additionally, it does not matter for the experiments in this works whether the data is constructed artificially or in a more realistic manner.",
    "authors": [],
    "venue": "",
    "year": 2019,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The problem of question answering using conversational context is explored for the Conversational Assistance Track of the Text REtrieval Conference and BERT outperforms BM25 in all experiments, regardless if or how much context is taken into account."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}