{
    "acronym": "e97480a8de7da6f0516080ba214c67542ab8189f",
    "title": "Deep Generative Models for Decision-Making and Control",
    "seed_ids": [
        "gpt",
        "de18baa4964804cf471d85a5a090498242d2e79f",
        "7e9ff94476f41041c75e253e84f487db00e9c861",
        "59a916cdc943f0282908e6f3fa0360f4c5fb78d0"
    ],
    "s2id": "e97480a8de7da6f0516080ba214c67542ab8189f",
    "abstract": "Deep model-based reinforcement learning methods offer a conceptually simple approach to the decision-making and control problem: use learning for the purpose of estimating an approximate dynamics model, and offload the rest of the work to classical trajectory optimization. However, this combination has a number of empirical shortcomings, limiting the usefulness of model-based methods in practice. The dual purpose of this thesis is to study the reasons for these shortcomings and to propose solutions for the uncovered problems. Along the way, we highlight how inference techniques from the contemporary generative modeling toolbox, including beam search, classifier-guided sampling, and image inpainting, can be reinterpreted as viable planning strategies for reinforcement learning problems.",
    "authors": [
        "Michael Janner"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is highlighted how inference techniques from the contemporary generative modeling toolbox, including beam search, classifier-guided sampling, and image inpainting, can be reinterpreted as viable planning strategies for reinforcement learning problems."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}