{
    "acronym": "42117d01d498eb9f8c21b788c3565bc6855d620b",
    "title": "Learning to Transfer Prompts for Text Generation",
    "seed_ids": [
        "gpt2",
        "982cbf7fcee4f3964dd1d411fdeadad6e6f1d465",
        "85e7d63f75c0916bd350a229e040c5fbb1472e7a",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "f6fbb6809374ca57205bd2cf1421d4f4fa04f975",
        "7422756d2416c62d7660bd217d817acc8ec35a09",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "42117d01d498eb9f8c21b788c3565bc6855d620b",
    "abstract": "Pretrained language models (PLMs) have made remarkable progress in text generation tasks via fine-tuning. While, it is challenging to fine-tune PLMs in a data-scarce situation. Therefore, it is non-trivial to develop a general and lightweight model that can adapt to various text generation tasks based on PLMs. To fulfill this purpose, the recent prompt-based learning offers a potential solution. In this paper, we improve this technique and propose a novel prompt-based method (PTG) for text generation in a transferable setting. First, PTG learns a set of source prompts for various source generation tasks and then transfers these prompts as target prompts to perform target generation tasks. To consider both task- and instance-level information, we design an adaptive attention mechanism to derive the target prompts. For each data instance, PTG learns a specific target prompt by attending to highly relevant source prompts. In extensive experiments, PTG yields competitive or better results than fine-tuning methods. We release our source prompts as an open resource, where users can add or reuse them to improve new text generation tasks for future research. Code and data can be available at https://github.com/RUCAIBox/Transfer-Prompts-for-Text-Generation.",
    "authors": [
        "Junyi Li",
        "Tianyi Tang",
        "J. Nie",
        "Ji-rong Wen",
        "Wayne Xin Zhao"
    ],
    "venue": "North American Chapter of the Association for Computational Linguistics",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper improves this technique and proposes a novel prompt-based method (PTG) for text generation in a transferable setting that learns a set of source prompts for various source generation tasks and then transfers these prompts as target prompts to perform target generation tasks."
    },
    "citationCount": 32,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}