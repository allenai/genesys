{
    "acronym": "a0cb110490f68603634b6f22cc5c846504a6906e",
    "title": "CopySpell: Improving Chinese Spelling Correction Model with Copy Mechanism",
    "seed_ids": [
        "bert"
    ],
    "s2id": "a0cb110490f68603634b6f22cc5c846504a6906e",
    "abstract": "The Chinese Spelling Correction (CSC) task aims to detect and correct spelling errors in texts. In recent years, BERT-based models have achieved significant breakthroughs in this field. However, CSC models still suffer from over-correction of the valid character to a similar one, which is caused by the training with downstream tasks. To solve this dilemma, we introduce CopySpell, a novel model that combines a copy mechanism with a new training method. By sharing original character information through a copy block, the model encourages robust and accurate outputs while avoiding over-correction. This approach allows the model to explore associations beyond the similar characters. Experiments are conducted on widely used benchmarks, and our model has achieved state-of-the-art results. We will also release the source code for future research and communication.",
    "authors": [
        "Jiaxuan Gao",
        "Chunwei Luo",
        "Dayang Liu",
        "Qinghang Lu",
        "Dong Liang"
    ],
    "venue": "2023 3rd International Conference on Electronic Information Engineering and Computer (EIECT)",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": null
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}