{
    "acronym": "512fdb53eb341bc56769728274615c9bbe5bc23d",
    "title": "Flow Matching in Latent Space",
    "seed_ids": [
        "classfreediffu",
        "c69361b20ad3d88ad4c5e9e1a3a66d0932f2bc43",
        "498ac9b2e494601d20a3d0211c16acf2b7954a54",
        "2f4c451922e227cbbd4f090b74298445bbd900d0",
        "1386b8a11929cf02da291c56aca353e33bbc22ed",
        "c57293882b2561e1ba03017902df9fc2f289dea2",
        "3b2a675bb617ae1a920e8e29d535cdf27826e999",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "94bcd712aed610b8eaeccc57136d65ec988356f2",
        "de18baa4964804cf471d85a5a090498242d2e79f"
    ],
    "s2id": "512fdb53eb341bc56769728274615c9bbe5bc23d",
    "abstract": "Flow matching is a recent framework to train generative models that exhibits impressive empirical performance while being relatively easier to train compared with diffusion-based models. Despite its advantageous properties, prior methods still face the challenges of expensive computing and a large number of function evaluations of off-the-shelf solvers in the pixel space. Furthermore, although latent-based generative methods have shown great success in recent years, this particular model type remains underexplored in this area. In this work, we propose to apply flow matching in the latent spaces of pretrained autoencoders, which offers improved computational efficiency and scalability for high-resolution image synthesis. This enables flow-matching training on constrained computational resources while maintaining their quality and flexibility. Additionally, our work stands as a pioneering contribution in the integration of various conditions into flow matching for conditional generation tasks, including label-conditioned image generation, image inpainting, and semantic-to-image generation. Through extensive experiments, our approach demonstrates its effectiveness in both quantitative and qualitative results on various datasets, such as CelebA-HQ, FFHQ, LSUN Church&Bedroom, and ImageNet. We also provide a theoretical control of the Wasserstein-2 distance between the reconstructed latent flow distribution and true data distribution, showing it is upper-bounded by the latent flow matching objective. Our code will be available at https://github.com/VinAIResearch/LFM.git.",
    "authors": [
        "Quan Dao",
        "Hao Phung",
        "Binh Duc Nguyen",
        "A. Tran"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes to apply flow matching in the latent spaces of pretrained autoencoders, which offers improved computational efficiency and scalability for high-resolution image synthesis and stands as a pioneering contribution in the integration of various conditions into flow matching for conditional generation tasks."
    },
    "citationCount": 22,
    "influentialCitationCount": 2,
    "code": null,
    "description": null,
    "url": null
}