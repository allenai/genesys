{
    "acronym": "b9a701c90f3d3df27366f5b29a97f798eb940ac7",
    "title": "ChapterBreak: A Challenge Dataset for Long-Range Language Models",
    "seed_ids": [
        "bigbird",
        "routingtransformer",
        "compressivetransformer",
        "0e802c0739771acf70e60d59c2df51cd7e8c50c0",
        "736eb449526fe7128917954ec5532b59e318ec78",
        "12809bcb734beafeb47876f42e7b438e27fe99fe",
        "3dfb1f50f2a34a699c339dabaa6f9b3a977973de",
        "f75d05e759447c2aedb7097728f29f9a520d9bc1",
        "9dc624d7258d1a56117ca720aea953ce46b66b21",
        "46c585ee9abf76779ea4b863d2da4358efd0d1d3",
        "0822f8d7e6a72a65e65f147d3a8d8fccd485da40",
        "7e9ff94476f41041c75e253e84f487db00e9c861",
        "7e5709d81558d3ef4265de29ea75931afeb1f2dd",
        "6f68e1bb253925d8431588555d3010419f322e04",
        "63857190aaf5aab1d94b54bb257b7b03b8cb5a50",
        "d27669c82faf78ea08cceaa0a171b540cccc304d",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "657329c633709dd1ac34a30d57341b186b1a47c2",
        "f51497f463566581874c941353dd9d80069c5b77",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "b9a701c90f3d3df27366f5b29a97f798eb940ac7",
    "abstract": "While numerous architectures for long-range language models (LRLMs) have recently been proposed, a meaningful evaluation of their discourse-level language understanding capabilities has not yet followed. To this end, we introduce ChapterBreak, a challenge dataset that provides an LRLM with a long segment from a narrative that ends at a chapter boundary and asks it to distinguish the beginning of the ground-truth next chapter from a set of negative segments sampled from the same narrative. A fine-grained human annotation reveals that our dataset contains many complex types of chapter transitions (e.g., parallel narratives, cliffhanger endings) that require processing global context to comprehend. Experiments on ChapterBreak show that existing LRLMs fail to effectively leverage long-range context, substantially underperforming a segment-level model trained directly for this task. We publicly release our ChapterBreak dataset to spur more principled future research into LRLMs.",
    "authors": [
        "Simeng Sun",
        "Katherine Thai",
        "Mohit Iyyer"
    ],
    "venue": "North American Chapter of the Association for Computational Linguistics",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": null
    },
    "citationCount": 12,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}