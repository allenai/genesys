{
    "acronym": "36765790f1f8372996b32bd7cb167b74b14f01f3",
    "title": "A Unified Framework for Human-centric Point Cloud Video Understanding",
    "seed_ids": [
        "transformer",
        "128fc3e518a9616cd2780d974d32b4ef47ba5901",
        "34103f1294844c447fe8872bf5c3ab1c7ce32103",
        "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7"
    ],
    "s2id": "36765790f1f8372996b32bd7cb167b74b14f01f3",
    "abstract": "Human-centric Point Cloud Video Understanding (PVU) is an emerging field focused on extracting and interpreting human-related features from sequences of human point clouds, further advancing downstream human-centric tasks and applications. Previous works usually focus on tackling one specific task and rely on huge labeled data, which has poor generalization capability. Considering that human has specific characteristics, including the structural semantics of human body and the dynamics of human motions, we propose a unified framework to make full use of the prior knowledge and explore the inherent features in the data itself for generalized human-centric point cloud video understanding. Extensive experiments demonstrate that our method achieves state-of-the-art performance on various human-related tasks, including action recognition and 3D pose estimation. All datasets and code will be released soon.",
    "authors": [
        "Yiteng Xu",
        "Kecheng Ye",
        "Xiao Han",
        "Yiming Ren",
        "Xinge Zhu",
        "Yuexin Ma"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a unified framework to make full use of the prior knowledge and explore the inherent features in the data itself for generalized human-centric point cloud video understanding."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}