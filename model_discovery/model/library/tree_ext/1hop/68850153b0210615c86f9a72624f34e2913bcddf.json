{
    "acronym": "68850153b0210615c86f9a72624f34e2913bcddf",
    "title": "Document-Level Machine Translation with Large Language Models",
    "seed_ids": [
        "gpt2",
        "4161ad2d2495d8af1d62dc5e71882bde642cd1c1",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "b0de1d5fe394226cec0a59d783ab739eb52da76f",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "68850153b0210615c86f9a72624f34e2913bcddf",
    "abstract": "Large language models (LLMs) such as ChatGPT can produce coherent, cohesive, relevant, and fluent answers for various natural language processing (NLP) tasks. Taking document-level machine translation (MT) as a testbed, this paper provides an in-depth evaluation of LLMs' ability on discourse modeling. The study focuses on three aspects: 1) Effects of Context-Aware Prompts, where we investigate the impact of different prompts on document-level translation quality and discourse phenomena; 2) Comparison of Translation Models, where we compare the translation performance of ChatGPT with commercial MT systems and advanced document-level MT methods; 3) Analysis of Discourse Modelling Abilities, where we further probe discourse knowledge encoded in LLMs and shed light on impacts of training techniques on discourse modeling. By evaluating on a number of benchmarks, we surprisingly find that LLMs have demonstrated superior performance and show potential to become a new paradigm for document-level translation: 1) leveraging their powerful long-text modeling capabilities, GPT-3.5 and GPT-4 outperform commercial MT systems in terms of human evaluation; 2) GPT-4 demonstrates a stronger ability for probing linguistic knowledge than GPT-3.5. This work highlights the challenges and opportunities of LLMs for MT, which we hope can inspire the future design and evaluation of LLMs.We release our data and annotations at https://github.com/longyuewangdcu/Document-MT-LLM.",
    "authors": [
        "Longyue Wang",
        "Chenyang Lyu",
        "Tianbo Ji",
        "Zhirui Zhang",
        "Dian Yu",
        "Shuming Shi",
        "Zhaopeng Tu"
    ],
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "An in-depth evaluation of LLMs' ability on discourse modeling using document-level machine translation (MT) as a testbed finds that LLMs have demonstrated superior performance and show potential to become a new paradigm for document- level translation."
    },
    "citationCount": 67,
    "influentialCitationCount": 3,
    "code": null,
    "description": null,
    "url": null
}