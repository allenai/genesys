{
    "acronym": "c1ce9178f5b236dab5feffb0bf5042aa6b472036",
    "title": "Enhanced Text Summarization through Hybrid Integration of RoBERTa, T5, and Pegasus Models",
    "seed_ids": [
        "transformer"
    ],
    "s2id": "c1ce9178f5b236dab5feffb0bf5042aa6b472036",
    "abstract": "The domain of Natural Language Processing (NLP) confronts a pivotal challenge in text summarization, with the goal of condensing extensive texts into concise, informative summaries. This research presents a revolutionary approach to text summarizing that combines the best features of top NLP models, RoBERTa, T5, and Pegasus, into a unified framework. This method employs RoBERTa for precise sentence relevance determination, and T5 and Pegasus for crafting coherent summaries, thereby generating outputs that are both compact and closely aligned with the semantic content of the original texts. Our assessment across various datasets, utilizing established metrics such as METEOR, ROUGE, BLEU scores, readability metrics, and BERT score, reveals the superiority of our proposed system over conventional summarization methods, showcasing its efficacy in producing high-quality summaries. Furthermore, our system achieves an ideal balance in compression accuracy, adeptly preserving essential information while ensuring the brevity and readability of summaries. This study not only establishes a new standard in text summarization but also heralds future progress by demonstrating the advantages of amalgamating multiple NLP models. The encouraging outcomes highlight the promise of our neural network-based strategy in pushing the boundaries of text summarization, thereby opening new pathways for exploration in this critical segment of NLP.",
    "authors": [
        "Sameera Datta Myla",
        "Ravinder Saini",
        "Nitika Kapoor"
    ],
    "venue": "2024 International Conference on Advances in Modern Age Technologies for Health and Engineering Science (AMATHE)",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This research presents a revolutionary approach to text summarizing that combines the best features of top NLP models, RoBERTa, T5, and Pegasus, into a unified framework, and achieves an ideal balance in compression accuracy."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}