{
    "acronym": "6800aa338a783bc901a8f98a598bdc1b71fc938f",
    "title": "Multiple View Performers for Shape Completion",
    "seed_ids": [
        "performer",
        "dc1b905c0af4dc318b63cd52fbc867c788df4b8c",
        "77706ee4cbdbb23345da22af37bc1b9f5ec8f110",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d"
    ],
    "s2id": "6800aa338a783bc901a8f98a598bdc1b71fc938f",
    "abstract": "We propose the Multiple View Performer (MVP) - a new architecture for 3D shape completion from a series of temporally sequential views. MVP accomplishes this task by using linear-attention Transformers called Performers. Our model allows the current observation of the scene to attend to the previous ones for more accurate infilling. The history of past observations is compressed via the compact associative memory approximating modern continuous Hopfield memory, but crucially of size independent from the history length. We compare our model with several baselines for shape completion over time, demonstrating the generalization gains that MVP provides. To the best of our knowledge, MVP is the first multiple view voxel reconstruction method that does not require registration of multiple depth views and the first causal Transformer based model for 3D shape completion.",
    "authors": [
        "David Watkins-Valls",
        "Peter K. Allen",
        "K. Choromanski",
        "Jacob Varley",
        "Nicholas R. Waytowich"
    ],
    "venue": "arXiv.org",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "To the best of the knowledge, MVP is the first multiple view voxel reconstruction method that does not require registration of multiple depth views and the first causal Transformer based model for 3D shape completion."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}