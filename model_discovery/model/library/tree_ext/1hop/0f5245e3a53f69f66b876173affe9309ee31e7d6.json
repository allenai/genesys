{
    "acronym": "0f5245e3a53f69f66b876173affe9309ee31e7d6",
    "title": "OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking",
    "seed_ids": [
        "bert",
        "83b8108014e3db4f46354a28ae68193f143c4e7e",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "0f5245e3a53f69f66b876173affe9309ee31e7d6",
    "abstract": "Large language models (LLMs) have revolutionized the landscape of Natural Language Processing, but are computationally expensive. To reduce the cost without sacrificing performance, previous studies have explored various approaches to harness the potential of Smaller Language Models (SLMs) as cost-effective alternatives to their larger counterparts. Driven by findings that SLMs and LLMs exhibit complementary strengths in a structured knowledge extraction task, this work presents a novel SLM/LLM routing framework designed to improve computational efficiency and enhance task performance. In dialogue state tracking tasks, the proposed routing framework enhances performance substantially compared to relying solely on LLMs, while reducing the computational costs by over 50%.",
    "authors": [
        "Chia-Hsuan Lee",
        "Hao Cheng",
        "Mari Ostendorf"
    ],
    "venue": "North American Chapter of the Association for Computational Linguistics",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel SLM/LLM routing framework designed to improve computational efficiency and enhance task performance in dialogue state tracking tasks and reduces the computational costs by over 50%."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}