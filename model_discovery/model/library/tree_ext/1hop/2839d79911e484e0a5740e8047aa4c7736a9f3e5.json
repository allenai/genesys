{
    "acronym": "2839d79911e484e0a5740e8047aa4c7736a9f3e5",
    "title": "FETILDA: Evaluation Framework for Effective Representations of Long Financial Documents",
    "seed_ids": [
        "bert",
        "nystromformer",
        "bigbird",
        "longformer",
        "etc",
        "6fa1cfc4f97f03a8485692418c7aa1a06c574a85",
        "d27669c82faf78ea08cceaa0a171b540cccc304d",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "4d244972ed2e0286363bfb054cb269574d21a72c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "2839d79911e484e0a5740e8047aa4c7736a9f3e5",
    "abstract": "In the financial sphere, there is a wealth of accumulated unstructured financial data, such as the textual disclosure documents that companies submit on a regular basis to regulatory agencies, such as the Securities and Exchange Commission. These documents are typically very long and tend to contain valuable soft information about a company\u2019s performance that is not present in quantitative predictors. It is therefore of great interest to learn predictive models from these long textual documents, especially for forecasting numerical key performance indicators. In recent years, there has been great progress in natural language processing via pre-trained language models (LMs) learned from large corpora of textual data. This prompts the important question of whether they can be used effectively to produce representations for long documents, as well as how we can evaluate the effectiveness of representations produced by various LMs. Our work focuses on answering this critical question, namely, the evaluation of the efficacy of various LMs in extracting useful soft information from long textual documents for prediction tasks. In this article, we propose and implement a deep learning evaluation framework that utilizes a sequential chunking approach combined with an attention mechanism. We perform an extensive set of experiments on a collection of 10-K reports submitted annually by U.S. banks, and another dataset of reports submitted by U.S. companies, to investigate thoroughly the performance of different types of language models. Overall, our framework using LMs outperforms strong baseline methods for textual modeling as well as for numerical regression. Our work provides better insights into how utilizing pre-trained domain-specific and fine-tuned long-input LMs for representing long documents can improve the quality of representation of textual data and, therefore, help in improving predictive analyses.",
    "authors": [
        "Bolun (Namir) Xia",
        "Vipula Rawte",
        "Aparna Gupta",
        "Mohammed Zaki"
    ],
    "venue": "ACM Transactions on Knowledge Discovery from Data",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work provides better insights into how utilizing pre-trained domain-specific and fine-tuned long-input LMs for representing long documents can improve the quality of representation of textual data and, therefore, help in improving predictive analyses."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}