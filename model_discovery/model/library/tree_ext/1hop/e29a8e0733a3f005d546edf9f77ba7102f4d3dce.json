{
    "acronym": "e29a8e0733a3f005d546edf9f77ba7102f4d3dce",
    "title": "Figure Eight at SemEval-2019 Task 3: Ensemble of Transfer Learning Methods for Contextual Emotion Detection",
    "seed_ids": [
        "gpt"
    ],
    "s2id": "e29a8e0733a3f005d546edf9f77ba7102f4d3dce",
    "abstract": "This paper describes our transfer learning-based approach to contextual emotion detection as part of SemEval-2019 Task 3. We experiment with transfer learning using pre-trained language models (ULMFiT, OpenAI GPT, and BERT) and fine-tune them on this task. We also train a deep learning model from scratch using pre-trained word embeddings and BiLSTM architecture with attention mechanism. The ensembled model achieves competitive result, ranking ninth out of 165 teams. The result reveals that ULMFiT performs best due to its superior fine-tuning techniques. We propose improvements for future work.",
    "authors": [
        "J. Xiao"
    ],
    "venue": "International Workshop on Semantic Evaluation",
    "year": 2019,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper trains a deep learning model from scratch using pre-trained word embeddings and BiLSTM architecture with attention mechanism and reveals that ULMFiT performs best due to its superior fine-tuning techniques."
    },
    "citationCount": 15,
    "influentialCitationCount": 2,
    "code": null,
    "description": null,
    "url": null
}