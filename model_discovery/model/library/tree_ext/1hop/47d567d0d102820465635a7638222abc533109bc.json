{
    "acronym": "47d567d0d102820465635a7638222abc533109bc",
    "title": "Explainable Assessment of Healthcare Articles with QA",
    "seed_ids": [
        "longformer",
        "925ad2897d1b5decbea320d07e99afa9110e09b2"
    ],
    "s2id": "47d567d0d102820465635a7638222abc533109bc",
    "abstract": "The healthcare domain suffers from the spread of poor quality articles on the Internet. While manual efforts exist to check the quality of online healthcare articles, they are not sufficient to assess all those in circulation. Such quality assessment can be automated as a text classification task, however, explanations for the labels are necessary for the users to trust the model predictions. While current explainable systems tackle explanation generation as summarization, we propose a new approach based on question answering (QA) that allows us to generate explanations for multiple criteria using a single model. We show that this QA-based approach is competitive with the current state-of-the-art, and complements summarization-based models for explainable quality assessment. We also introduce a human evaluation protocol more appropriate than automatic metrics for the evaluation of explanation generation models.",
    "authors": [
        "Alodie Boissonnet",
        "Marzieh Saeidi",
        "Vassilis Plachouras",
        "Andreas Vlachos"
    ],
    "venue": "Workshop on Biomedical Natural Language Processing",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a new approach based on question answering (QA) that allows for explanations for multiple criteria using a single model, and shows that this QA-based approach is competitive with the current state-of-the-art, and complements summarization-based models for explainable quality assessment."
    },
    "citationCount": 5,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}