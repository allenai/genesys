{
    "acronym": "2166c701d73e4030e4b2a2cdcff40e05a86291c3",
    "title": "STAR: Sparse Transformer-based Action Recognition",
    "seed_ids": [
        "performer",
        "lineartransformer",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
        "7e5709d81558d3ef4265de29ea75931afeb1f2dd",
        "6f68e1bb253925d8431588555d3010419f322e04",
        "8cef9900c04d7f661c08f4b5b1ed4337ace042a3"
    ],
    "s2id": "2166c701d73e4030e4b2a2cdcff40e05a86291c3",
    "abstract": "The cognitive system for human action and behavior has evolved into a deep learning regime, and especially the advent of Graph Convolution Networks has transformed the field in recent years. However, previous works have mainly focused on over-parameterized and complex models based on dense graph convolution networks, resulting in low efficiency in training and inference. Meanwhile, the Transformer architecture-based model has not yet been well explored for cognitive application in human action and behavior estimation. This work proposes a novel skeleton-based human action recognition model with sparse attention on the spatial dimension and segmented linear attention on the temporal dimension of data. Our model can also process the variable length of video clips grouped as a single batch. Experiments show that our model can achieve comparable performance while utilizing much less trainable parameters and achieve high speed in training and inference. Experiments show that our model achieves 4~18x speedup and 1/7~1/15 model size compared with the baseline models at competitive accuracy.",
    "authors": [
        "Feng Shi",
        "Chonghan Lee",
        "Liang Qiu",
        "Yizhou Zhao",
        "Tianyi Shen",
        "Shivran Muralidhar",
        "Tian Han",
        "Song-Chun Zhu",
        "V. Narayanan"
    ],
    "venue": "arXiv.org",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a novel skeleton-based human action recognition model with sparse attention on the spatial dimension and segmented linear Attention on the temporal dimension of data that can achieve comparable performance while utilizing much less trainable parameters and achieve high speed in training and inference."
    },
    "citationCount": 21,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}