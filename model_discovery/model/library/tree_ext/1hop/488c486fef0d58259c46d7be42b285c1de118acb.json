{
    "acronym": "488c486fef0d58259c46d7be42b285c1de118acb",
    "title": "Long-MIL: Scaling Long Contextual Multiple Instance Learning for Histopathology Whole Slide Image Analysis",
    "seed_ids": [
        "nystromformer",
        "linformer",
        "alibi",
        "flashattn",
        "539fadfb615ef84c240f4741061c44eeda540091",
        "fdc53c2c10742464087c0525f77e32604827a21d",
        "b6346f9fa093b8e85df712485a2b851b9f680dac",
        "026b3396a63ed5772329708b7580d633bb86bec9",
        "f393aff1593c2d370ec0ae004910d18e40524967",
        "998ac3e945857cf2676ee7efdbaf443a0c6f820a",
        "5a77b508302771fc083bf24e0bcda8553c9b5421",
        "87c5b281fa43e6f27191b20a8dd694eda1126336",
        "d6c5aab433d9871cabc01ffb1e5e1ea89141155b",
        "53c3940f35b8b45d55ed49056282e1961954513d",
        "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "a9c214e846188adb645021cd7b1964b8ea1fef6f",
        "7509c66a666e2e3f14bc8676b969b945ee6e136f",
        "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4",
        "b3bf9fe13195e9aa70e1dac04e01fcff7008e812",
        "9ed25f101f19ea735ca300848948ed64064b97ca",
        "6fa1cfc4f97f03a8485692418c7aa1a06c574a85",
        "84476fdf6ead3553f4493dff8e02308439d6222b",
        "0cd82dfae930ac4b57c0e959f744f2d10bf87649",
        "6f68e1bb253925d8431588555d3010419f322e04",
        "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
        "0b991a1a5bcdb13646ac0b6873d09bde4cc36fb5",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "657329c633709dd1ac34a30d57341b186b1a47c2",
        "34a4e6818d680875ff0bef9a76de0376118446d1",
        "2cf3bd0cc1382f35384e259d99e4f9744eeaed28",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "48ad536d00742a31eb8c6408c5d7ad96e654fe7a",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "488c486fef0d58259c46d7be42b285c1de118acb",
    "abstract": "Histopathology image analysis is the golden standard of clinical diagnosis for Cancers. In doctors daily routine and computer-aided diagnosis, the Whole Slide Image (WSI) of histopathology tissue is used for analysis. Because of the extremely large scale of resolution, previous methods generally divide the WSI into a large number of patches, then aggregate all patches within a WSI by Multi-Instance Learning (MIL) to make the slide-level prediction when developing computer-aided diagnosis tools. However, most previous WSI-MIL models using global-attention without pairwise interaction and any positional information, or self-attention with absolute position embedding can not well handle shape varying large WSIs, e.g. testing WSIs after model deployment may be larger than training WSIs, since the model development set is always limited due to the difficulty of histopathology WSIs collection. To deal with the problem, in this paper, we propose to amend position embedding for shape varying long-contextual WSI by introducing Linear Bias into Attention, and adapt it from 1-d long sequence into 2-d long-contextual WSI which helps model extrapolate position embedding to unseen or under-fitted positions. We further utilize Flash-Attention module to tackle the computational complexity of Transformer, which also keep full self-attention performance compared to previous attention approximation work. Our method, Long-contextual MIL (Long-MIL) are evaluated on extensive experiments including 4 dataset including WSI classification and survival prediction tasks to validate the superiority on shape varying WSIs. The source code will be open-accessed soon.",
    "authors": [
        "Honglin Li",
        "Yunlong Zhang",
        "Chenglu Zhu",
        "Jiatong Cai",
        "Sunyi Zheng",
        "Lin Yang"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper proposes to amend position embedding for shape varying long-contextual WSI by introducing Linear Bias into Attention, and adapt it from 1-d long sequence into 2-D long- contextual W SI which helps model extrapolate position embeding to unseen or under-fitted positions."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}