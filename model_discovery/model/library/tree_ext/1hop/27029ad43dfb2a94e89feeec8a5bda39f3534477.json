{
    "acronym": "27029ad43dfb2a94e89feeec8a5bda39f3534477",
    "title": "The Exponential Capacity of Dense Associative Memories",
    "seed_ids": [
        "hopfield"
    ],
    "s2id": "27029ad43dfb2a94e89feeec8a5bda39f3534477",
    "abstract": "Recent generalizations of the Hopfield model of associative memories are able to store a number P of random patterns that grows exponentially with the number N of neurons, P=exp(\u03b1N). Besides the huge storage capacity, another interesting feature of these networks is their connection to the attention mechanism which is part of the Transformer architecture widely applied in deep learning. In this work, we study a generic family of pattern ensembles using a statistical mechanics analysis which gives exact asymptotic thresholds for the retrieval of a typical pattern, \u03b1_{1}, and lower bounds for the maximum of the load \u03b1 for which all patterns can be retrieved, \u03b1_{c}, as well as sizes of attraction basins. We discuss in detail the cases of Gaussian and spherical patterns, and show that they display rich and qualitatively different phase diagrams.",
    "authors": [
        "C. Lucibello",
        "Marc M'ezard"
    ],
    "venue": "Physical Review Letters",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work studies a generic family of pattern ensembles using a statistical mechanics analysis which gives exact asymptotic thresholds for the retrieval of a typical pattern, \u03b1_{1}, and lower bounds for the maximum of the load \u03b1 for which all patterns can be retrieved, \u03b1_{c}, as well as sizes of attraction basins."
    },
    "citationCount": 20,
    "influentialCitationCount": 2,
    "code": null,
    "description": null,
    "url": null
}