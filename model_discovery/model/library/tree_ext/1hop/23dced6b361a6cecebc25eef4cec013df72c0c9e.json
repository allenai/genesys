{
    "acronym": "23dced6b361a6cecebc25eef4cec013df72c0c9e",
    "title": "German Also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset",
    "seed_ids": [
        "bert",
        "022b74aaf1b0d46ba9efcef4771cf9acf58b8da2",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "23dced6b361a6cecebc25eef4cec013df72c0c9e",
    "abstract": "The advent of Large Language Models (LLMs) has led to remarkable progress on a wide range of natural language processing tasks. Despite the advances, these large-sized models still suffer from hallucinating information in their output, which poses a major issue in automatic text summarization, as we must guarantee that the generated summary is consistent with the content of the source document. Previous research addresses the challenging task of detecting hallucinations in the output (i.e. inconsistency detection) in order to evaluate the faithfulness of the generated summaries. However, these works primarily focus on English and recent multilingual approaches lack German data. This work presents Absinth, a manually annotated dataset for hallucination detection in German news summarization and explores the capabilities of novel open-source LLMs on this task in both fine-tuning and in-context learning settings. We open-source and release the Absinth dataset to foster further research on hallucination detection in German.",
    "authors": [
        "Laura Mascarell",
        "Ribin Chalumattu",
        "Annette Rios"
    ],
    "venue": "International Conference on Language Resources and Evaluation",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Absinth is presented, a manually annotated dataset for hallucination detection in German news summarization and the capabilities of novel open-source LLMs on this task are explored in both fine-tuning and in-context learning settings."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}