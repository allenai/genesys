{
    "acronym": "bb104dc51121a0f64a5327526fad449cb03dd1bb",
    "title": "Evidence Sentence Extraction for Machine Reading Comprehension",
    "seed_ids": [
        "gpt",
        "6ff68b34a5f78bdd14437fe5a79aebbc42c26467",
        "9a5ba9aee44ab873f3d60b05e2773c693707da88"
    ],
    "s2id": "bb104dc51121a0f64a5327526fad449cb03dd1bb",
    "abstract": "Remarkable success has been achieved in the last few years on some limited machine reading comprehension (MRC) tasks. However, it is still difficult to interpret the predictions of existing MRC models. In this paper, we focus on extracting evidence sentences that can explain or support the answers of multiple-choice MRC tasks, where the majority of answer options cannot be directly extracted from reference documents. Due to the lack of ground truth evidence sentence labels in most cases, we apply distant supervision to generate imperfect labels and then use them to train an evidence sentence extractor. To denoise the noisy labels, we apply a recently proposed deep probabilistic logic learning framework to incorporate both sentence-level and cross-sentence linguistic indicators for indirect supervision. We feed the extracted evidence sentences into existing MRC models and evaluate the end-to-end performance on three challenging multiple-choice MRC datasets: MultiRC, RACE, and DREAM, achieving comparable or better performance than the same models that take as input the full reference document. To the best of our knowledge, this is the first work extracting evidence sentences for multiple-choice MRC.",
    "authors": [
        "Hai Wang",
        "Dian Yu",
        "Kai Sun",
        "Jianshu Chen",
        "Dong Yu",
        "D. Roth",
        "David A. McAllester"
    ],
    "venue": "Conference on Computational Natural Language Learning",
    "year": 2019,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper focuses on extracting evidence sentences that can explain or support the answers of multiple-choice MRC tasks, where the majority of answer options cannot be directly extracted from reference documents."
    },
    "citationCount": 53,
    "influentialCitationCount": 9,
    "code": null,
    "description": null,
    "url": null
}