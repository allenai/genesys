{
    "acronym": "ba2a423d8c7ae6cfa3424fb13bdbe3a35e5f2273",
    "title": "Unsupervised Evaluation of Interactive Dialog with DialoGPT",
    "seed_ids": [
        "gpt"
    ],
    "s2id": "ba2a423d8c7ae6cfa3424fb13bdbe3a35e5f2273",
    "abstract": "It is important to define meaningful and interpretable automatic evaluation metrics for open-domain dialog research. Standard language generation metrics have been shown to be ineffective for dialog. This paper introduces the FED metric (fine-grained evaluation of dialog), an automatic evaluation metric which uses DialoGPT, without any fine-tuning or supervision. It also introduces the FED dataset which is constructed by annotating a set of human-system and human-human conversations with eighteen fine-grained dialog qualities. The FED metric (1) does not rely on a ground-truth response, (2) does not require training data and (3) measures fine-grained dialog qualities at both the turn and whole dialog levels. FED attains moderate to strong correlation with human judgement at both levels.",
    "authors": [
        "Shikib Mehri",
        "M. Esk\u00e9nazi"
    ],
    "venue": "SIGDIAL Conferences",
    "year": 2020,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The FED metric (fine-grained evaluation of dialog), an automatic evaluation metric which uses DialoGPT, without any fine-tuning or supervision is introduced, which attains moderate to strong correlation with human judgement at both levels."
    },
    "citationCount": 143,
    "influentialCitationCount": 43,
    "code": null,
    "description": null,
    "url": null
}