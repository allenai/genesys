{
    "acronym": "da91ccd44cb0ccf82b75cb448e2ed40ba9454306",
    "title": "Automatic Speech Recognition Datasets in Cantonese: A Survey and New Dataset",
    "seed_ids": [
        "lrt",
        "4e4a031305beefec1935eac801b81fd64f55f82f",
        "faadd7d081c8d67e8c2567e8a5579e46cd6b2280"
    ],
    "s2id": "da91ccd44cb0ccf82b75cb448e2ed40ba9454306",
    "abstract": "Automatic speech recognition (ASR) on low resource languages improves the access of linguistic minorities to technological advantages provided by artificial intelligence (AI). In this paper, we address the problem of data scarcity for the Hong Kong Cantonese language by creating a new Cantonese dataset. Our dataset, Multi-Domain Cantonese Corpus (MDCC), consists of 73.6 hours of clean read speech paired with transcripts, collected from Cantonese audiobooks from Hong Kong. It comprises philosophy, politics, education, culture, lifestyle and family domains, covering a wide range of topics. We also review all existing Cantonese datasets and analyze them according to their speech type, data source, total size and availability. We further conduct experiments with Fairseq S2T Transformer, a state-of-the-art ASR model, on the biggest existing dataset, Common Voice zh-HK, and our proposed MDCC, and the results show the effectiveness of our dataset. In addition, we create a powerful and robust Cantonese ASR model by applying multi-dataset learning on MDCC and Common Voice zh-HK.",
    "authors": [
        "Tiezheng Yu",
        "Rita Frieske",
        "Peng Xu",
        "Samuel Cahyawijaya",
        "Cheuk Tung Shadow Yiu",
        "Holy Lovenia",
        "Wenliang Dai",
        "Elham J. Barezi",
        "Qifeng Chen",
        "Xiaojuan Ma",
        "Bertram E. Shi",
        "Pascale Fung"
    ],
    "venue": "International Conference on Language Resources and Evaluation",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A powerful and robust Cantonese ASR model is created by applying multi-dataset learning on MDCC and Common Voice zh-HK and the results show the effectiveness of the dataset."
    },
    "citationCount": 5,
    "influentialCitationCount": 2,
    "code": null,
    "description": null,
    "url": null
}