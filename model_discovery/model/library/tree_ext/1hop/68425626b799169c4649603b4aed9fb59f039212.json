{
    "acronym": "68425626b799169c4649603b4aed9fb59f039212",
    "title": "Towards Detailed Text-to-Motion Synthesis via Basic-to-Advanced Hierarchical Diffusion Model",
    "seed_ids": [
        "gpt",
        "classfreediffu",
        "498ac9b2e494601d20a3d0211c16acf2b7954a54",
        "c57293882b2561e1ba03017902df9fc2f289dea2",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "de18baa4964804cf471d85a5a090498242d2e79f"
    ],
    "s2id": "68425626b799169c4649603b4aed9fb59f039212",
    "abstract": "Text-guided motion synthesis aims to generate 3D human motion that not only precisely reflects the textual description but reveals the motion details as much as possible. Pioneering methods explore the diffusion model for text-to-motion synthesis and obtain significant superiority. However, these methods conduct diffusion processes either on the raw data distribution or the low-dimensional latent space, which typically suffer from the problem of modality inconsistency or detail-scarce. To tackle this problem, we propose a novel Basic-to-Advanced Hierarchical Diffusion Model, named B2A-HDM, to collaboratively exploit low-dimensional and high-dimensional diffusion models for high quality detailed motion synthesis. Specifically, the basic diffusion model in low-dimensional latent space provides the intermediate denoising result that to be consistent with the textual description, while the advanced diffusion model in high-dimensional latent space focuses on the following detail-enhancing denoising process. Besides, we introduce a multi-denoiser framework for the advanced diffusion model to ease the learning of high-dimensional model and fully explore the generative potential of the diffusion model. Quantitative and qualitative experiment results on two text-to-motion benchmarks (HumanML3D and KIT-ML) demonstrate that B2A-HDM can outperform existing state-of-the-art methods in terms of fidelity, modality consistency, and diversity.",
    "authors": [
        "Zhenyu Xie",
        "Yang Wu",
        "Xuehao Gao",
        "Zhongqian Sun",
        "Wei Yang",
        "Xiaodan Liang"
    ],
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel Basic-to-Advanced Hierarchical Diffusion Model is proposed, named B2A-HDM, to collaboratively exploit low-dimensional and high-dimensional diffusion models for high quality detailed motion synthesis and can outperform existing state-of-the-art methods in terms of fidelity, modality consistency, and diversity."
    },
    "citationCount": 5,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}