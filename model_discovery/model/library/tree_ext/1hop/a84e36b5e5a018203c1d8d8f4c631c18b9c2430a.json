{
    "acronym": "a84e36b5e5a018203c1d8d8f4c631c18b9c2430a",
    "title": "Turn of Phrase: Contrastive Pre-Training for Discourse-Aware Conversation Models",
    "seed_ids": [
        "gpt",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d"
    ],
    "s2id": "a84e36b5e5a018203c1d8d8f4c631c18b9c2430a",
    "abstract": "Turn of Phrase: Contrastive Pre-Training for Discourse-Aware Conversation Models Roland Laboulaye Department of Computer Science, BYU Master of Science Understanding long conversations requires recognizing a discourse flow unique to conversation. Recent advances in unsupervised representation learning of text have been attained primarily through language modeling, which models discourse only implicitly and within a small window. These representations are in turn evaluated chiefly on sentence pair or paragraph-question pair benchmarks, which measure only local discourse coherence. In order to improve performance on discourse-reliant, long conversation tasks, we propose Turn-of-Phrase Pre-Training, an objective designed to encode long conversation discourse flow. We leverage tree-structured Reddit conversations in English to, relative to a chosen conversation path through the tree, select paths of varying degrees of relatedness. The final utterance of the chosen path is appended to the related paths and the model learns to identify the most coherent conversation path. We demonstrate that our pre-training objective encodes conversational discourse awareness by improving performance on a dialogue act classification task. We then demonstrate the value of transferring discourse awareness with a comprehensive array of conversation-level classification tasks evaluating persuasion, conflict, and deception.",
    "authors": [
        "Roland R. Laboulaye"
    ],
    "venue": "",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes Turn-of-Phrase Pre-Training, an objective designed to encode long conversation discourse flow, and demonstrates the value of transferring discourse awareness with a comprehensive array of conversation-level classification tasks evaluating persuasion, conflict, and deception."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}