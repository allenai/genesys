{
    "acronym": "539015e31fe90a8e5b6eba62c4258c94722f829b",
    "title": "Diffusion model for adversarial attack against NLP models",
    "seed_ids": [
        "diffuseq",
        "69144d537f90f214d5b07a7c79121d16afd7da16",
        "b64537bdf7a103aa01972ba06ea24a9c08f7cd74",
        "1386b8a11929cf02da291c56aca353e33bbc22ed"
    ],
    "s2id": "539015e31fe90a8e5b6eba62c4258c94722f829b",
    "abstract": "Current black-box adversarial attacks have proven to be highly effective in generating adversarial texts that can successfully deceive natural language processing models, thereby revealing potential weaknesses in these models. This research proposes an innovative transfer-based black-box attack method, which capitalizes on the combined generative and discriminative abilities of the diffusion model. To ensure semantic similarity and enhance the adversarial ability of generated texts, well-designed semantic-preserving and adversarial objectives are introduced to the training procedure of the diffusion model. The results show that the proposed method can generate adversarial texts that successfully attack text classification models.",
    "authors": [
        "Shilin Qiu",
        "Min Gou",
        "Tao Liang"
    ],
    "venue": "Conference on Computer Graphics, Artificial Intelligence, and Data Processing",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "An innovative transfer-based black-box attack method is proposed, which capitalizes on the combined generative and discriminative abilities of the diffusion model to generate adversarial texts that successfully attack text classification models."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}