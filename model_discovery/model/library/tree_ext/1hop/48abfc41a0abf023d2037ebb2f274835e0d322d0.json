{
    "acronym": "48abfc41a0abf023d2037ebb2f274835e0d322d0",
    "title": "Compositional Exemplars for In-context Learning",
    "seed_ids": [
        "gpt2",
        "47e15941c8b157873c8264e4bf50318d1ba5cd18",
        "5f19ae1135a9500940978104ec15a5b8751bc7d2",
        "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad",
        "9405cc0d6169988371b2755e573cc28650d14dfe",
        "c21a4d70d83e0f6eb2a9e1c41d034842dd561e47"
    ],
    "s2id": "48abfc41a0abf023d2037ebb2f274835e0d322d0",
    "abstract": "Large pretrained language models (LMs) have shown impressive In-Context Learning (ICL) ability, where the model learns to do an unseen task via a prompt consisting of input-output examples as the demonstration, without any parameter updates. The performance of ICL is highly dominated by the quality of the selected in-context examples. However, previous selection methods are mostly based on simple heuristics, leading to sub-optimal performance. In this work, we formulate in-context example selection as a subset selection problem. We propose CEIL (Compositional Exemplars for In-context Learning), which is instantiated by Determinantal Point Processes (DPPs) to model the interaction between the given input and in-context examples, and optimized through a carefully-designed contrastive learning objective to obtain preference from LMs. We validate CEIL on 12 classification and generation datasets from 7 distinct NLP tasks, including sentiment analysis, paraphrase detection, natural language inference, commonsense reasoning, open-domain question answering, code generation, and semantic parsing. Extensive experiments demonstrate not only the state-of-the-art performance but also the transferability and compositionality of CEIL, shedding new light on effective and efficient in-context learning. Our code is released at https://github.com/HKUNLP/icl-ceil.",
    "authors": [
        "Jiacheng Ye",
        "Zhiyong Wu",
        "Jiangtao Feng",
        "Tao Yu",
        "Lingpeng Kong"
    ],
    "venue": "International Conference on Machine Learning",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes CEIL (Compositional Exemplars for In-context Learning), which is instantiated by Determinantal Point Processes to model the interaction between the given input and in-context examples, and optimized through a carefully-designed contrastive learning objective to obtain preference from LMs."
    },
    "citationCount": 62,
    "influentialCitationCount": 7,
    "code": null,
    "description": null,
    "url": null
}