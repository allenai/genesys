{
    "acronym": "a45fd3a9eb9bbd4f265800bb0b46c9ae4bfe3cd7",
    "title": "VoP: Text-Video Co-Operative Prompt Tuning for Cross-Modal Retrieval",
    "seed_ids": [
        "gpt2",
        "ccc1aee91d57fc12d8064efa88d3d6ab72850382",
        "29ddc1f43f28af7c846515e32cc167bc66886d0c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "a45fd3a9eb9bbd4f265800bb0b46c9ae4bfe3cd7",
    "abstract": "Many recent studies leverage the pre-trained CLIP for text-video cross-modal retrieval by tuning the backbone with additional heavy modules, which not only brings huge computational burdens with much more parameters, but also leads to the knowledge forgetting from upstream models. In this work, we propose the VoP: Text-Video Cooperative Prompt Tuning for efficient tuning on the text-video retrieval task. The proposed VoP is an end-to-end framework with both video & text prompts introducing, which can be regarded as a powerful baseline with only 0.1% trainable parameters. Further, based on the spatiotemporal characteristics of videos, we develop three novel video prompt mechanisms to improve the performance with different scales of trainable parameters. The basic idea of the VoP enhancement is to model the frame position, frame context, and layer function with specific trainable prompts, respectively. Extensive experiments show that compared to full fine-tuning, the enhanced VoP achieves a 1.4% average R@1 gain across five text-video retrieval benchmarks with 6\u00d7 less parameter overhead. The code will be available at https://github.com/bighuang624/VoP.",
    "authors": [
        "Siteng Huang",
        "Biao Gong",
        "Yulin Pan",
        "Jianwen Jiang",
        "Yiliang Lv",
        "Yuyuan Li",
        "Donglin Wang"
    ],
    "venue": "Computer Vision and Pattern Recognition",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The VoP: Text-Video Cooperative Prompt Tuning for efficient tuning on the text-video retrieval task is proposed, an end-to-end framework with both video & text prompts introducing, which can be regarded as a powerful baseline with only 0.1% trainable parameters."
    },
    "citationCount": 19,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}