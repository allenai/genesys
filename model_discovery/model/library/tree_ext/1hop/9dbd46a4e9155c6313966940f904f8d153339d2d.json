{
    "acronym": "9dbd46a4e9155c6313966940f904f8d153339d2d",
    "title": "Autoregressive Score Generation for Multi-trait Essay Scoring",
    "seed_ids": [
        "bert"
    ],
    "s2id": "9dbd46a4e9155c6313966940f904f8d153339d2d",
    "abstract": "Recently, encoder-only pre-trained models such as BERT have been successfully applied in automated essay scoring (AES) to predict a single overall score. However, studies have yet to explore these models in multi-trait AES, possibly due to the inefficiency of replicating BERT-based models for each trait. Breaking away from the existing sole use of *encoder*, we propose an autoregressive prediction of multi-trait scores (ArTS), incorporating a *decoding* process by leveraging the pre-trained T5. Unlike prior regression or classification methods, we redefine AES as a score-generation task, allowing a single model to predict multiple scores. During decoding, the subsequent trait prediction can benefit by conditioning on the preceding trait scores. Experimental results proved the efficacy of ArTS, showing over 5% average improvements in both prompts and traits.",
    "authors": [
        "Heejin Do",
        "Yunsu Kim",
        "Gary Geunbae Lee"
    ],
    "venue": "Findings",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes an autoregressive prediction of multi-trait scores (ArTS), incorporating a *decoding* process by leveraging the pre-trained T5, allowing a single model to predict multiple scores."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}