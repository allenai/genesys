{
    "acronym": "622b064bd56d5be022f6dae9f7656fa8b658e0cf",
    "title": "From Complex to Simple: Unraveling the Cognitive Tree for Reasoning with Small Language Models",
    "seed_ids": [
        "gpt2",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "622b064bd56d5be022f6dae9f7656fa8b658e0cf",
    "abstract": "Reasoning is a distinctive human capacity, enabling us to address complex problems by breaking them down into a series of manageable cognitive steps. Yet, complex logical reasoning is still cumbersome for language models. Based on the dual process theory in cognitive science, we are the first to unravel the cognitive reasoning abilities of language models. Our framework employs an iterative methodology to construct a Cognitive Tree (CogTree). The root node of this tree represents the initial query, while the leaf nodes consist of straightforward questions that can be answered directly. This construction involves two main components: the implicit extraction module (referred to as the intuitive system) and the explicit reasoning module (referred to as the reflective system). The intuitive system rapidly generates multiple responses by utilizing in-context examples, while the reflective system scores these responses using comparative learning. The scores guide the intuitive system in its subsequent generation step. Our experimental results on two popular and challenging reasoning tasks indicate that it is possible to achieve a performance level comparable to that of GPT-3.5 (with 175B parameters), using a significantly smaller language model that contains fewer parameters (<=7B) than 5% of GPT-3.5.",
    "authors": [
        "Junbing Yan",
        "Chengyu Wang",
        "Taolin Zhang",
        "Xiaofeng He",
        "Jun Huang",
        "Wei Zhang"
    ],
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work is the first to unravel the cognitive reasoning abilities of language models using an iterative methodology to construct a Cognitive Tree (CogTree), and indicates that it is possible to achieve a performance level comparable to that of GPT-3.5."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}