{
    "acronym": "e389b995793946f70d6ef1a8cd15229668aed146",
    "title": "ACL TA-DA: A Dataset for Text Summarization and Generation",
    "seed_ids": [
        "gpt2",
        "8bd042ae4648ea2d58c7495da37e3caca2af539a",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "e04a80263d252a3d8a382ba37a249b9345620570",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "e389b995793946f70d6ef1a8cd15229668aed146",
    "abstract": "Selecting appropriate natural language datasets is imperative to achieving good performance in deep learning natural language tasks. Recent state-of-the-art language models train huge corpora to achieving high language understanding performances. Also, to conduct diverse NLP tasks, fine-tuning pre-trained language models with task specific datasets is necessary. In this paper, we introduce ACL TA-DA (Association of Computational Linguistics Titles Abstracts DAta) consisting of 22k English titles and corresponding abstracts of papers published in ACL. Two NLP tasks, (1) text summarization and (2) text generation, are suitable tasks for our ACL TA-DA dataset. We train and report results from several state-of-the-art text summarization and generation models with our dataset to demonstrate that our dataset can be widely applied.",
    "authors": [
        "Min-Su Park",
        "Eunil Park"
    ],
    "venue": "ACM Symposium on Applied Computing",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper introduces ACL TA-DA (Association of Computational Linguistics Titles Abstracts DAta), a dataset consisting of 22k English titles and corresponding abstracts of papers published in ACL and trains and reports results from several state-of-the-art text summarization and generation models with the authors' dataset to demonstrate that the dataset can be widely applied."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}