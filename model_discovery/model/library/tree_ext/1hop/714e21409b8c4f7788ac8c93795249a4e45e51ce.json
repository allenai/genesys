{
    "acronym": "714e21409b8c4f7788ac8c93795249a4e45e51ce",
    "title": "Enhancing Efficiency in Vision Transformer Networks: Design Techniques and Insights",
    "seed_ids": [
        "transformer",
        "gpt3",
        "bert",
        "131ba9932572c92155874db93626cf299659254e",
        "9a83aeadc8db65fb6da39ec977360541cddaff5c",
        "c57467e652f3f9131b3e7e40c23059abe395f01d",
        "19921cefb2470b2f5d984ab9ce92ebb94aedf2ea",
        "0cd526723b87ae37981922992992d203448a2014",
        "ec139916edd6feb9b3cb3a0325ca96e21dbb0147",
        "bf6ce546c589fa8054b3972b266532664914bd21",
        "fa717a2e31f0cef4e26921f3b147a98644d2e64c",
        "ba637c4f1a170f1e2dadeadb71a63cf2b9a46de2",
        "934942934a6a785e2a80daa6421fa79971558b89",
        "b52844a746dafd8a5051cef49abbbda64a312605",
        "87e6f235c7a1fdeceb41605db64419fa11f7b98b",
        "2c4d5b1278125d84c9e66ebe1032af888d9211f3",
        "9b6af0e358e76d22f209c75b1702c3e6ea7815b1",
        "6b6ffb94626e672caffafc77097491d9ee7a8682",
        "3a906b77fa218adc171fecb28bb81c24c14dcc7b",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7"
    ],
    "s2id": "714e21409b8c4f7788ac8c93795249a4e45e51ce",
    "abstract": "Intrigued by the inherent ability of the human visual system to identify salient regions in complex scenes, attention mechanisms have been seamlessly integrated into various Computer Vision (CV) tasks. Building upon this paradigm, Vision Transformer (ViT) networks exploit attention mechanisms for improved efficiency. This review navigates the landscape of redesigned attention mechanisms within ViTs, aiming to enhance their performance. This paper provides a comprehensive exploration of techniques and insights for designing attention mechanisms, systematically reviewing recent literature in the field of CV. This survey begins with an introduction to the theoretical foundations and fundamental concepts underlying attention mechanisms. We then present a systematic taxonomy of various attention mechanisms within ViTs, employing redesigned approaches. A multi-perspective categorization is proposed based on their application, objectives, and the type of attention applied. The analysis includes an exploration of the novelty, strengths, weaknesses, and an in-depth evaluation of the different proposed strategies. This culminates in the development of taxonomies that highlight key properties and contributions. Finally, we gather the reviewed studies along with their available open-source implementations at our \\href{https://github.com/mindflow-institue/Awesome-Attention-Mechanism-in-Medical-Imaging}{GitHub}\\footnote{\\url{https://github.com/xmindflow/Awesome-Attention-Mechanism-in-Medical-Imaging}}. We aim to regularly update it with the most recent relevant papers.",
    "authors": [
        "Moein Heidari",
        "Reza Azad",
        "Sina Ghorbani Kolahi",
        "Ren'e Arimond",
        "Leon Niggemeier",
        "Alaa Sulaiman",
        "Afshin Bozorgpour",
        "Ehsan Khodapanah Aghdam",
        "A. Kazerouni",
        "I. Hacihaliloglu",
        "D. Merhof"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A systematic taxonomy of various attention mechanisms within ViTs, employing redesigned approaches is presented, and a multi-perspective categorization is proposed based on their application, objectives, and the type of attention applied."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}