{
    "acronym": "9b117b2cbeb09b56e5134b490b5b290980206477",
    "title": "Apollo: Zero-shot MultiModal Reasoning with Multiple Experts",
    "seed_ids": [
        "gpt2",
        "05bcf9999525656cfaa59bc71f8572d771ff3776",
        "ada81a4de88a6ce474df2e2446ad11fea480616e",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "9b117b2cbeb09b56e5134b490b5b290980206477",
    "abstract": "We propose a modular framework that leverages the expertise of different foundation models over different modalities and domains in order to perform a single, complex, multi-modal task, without relying on prompt engineering or otherwise tailor-made multi-modal training. Our approach enables decentralized command execution and allows each model to both contribute and benefit from the expertise of the other models. Our method can be extended to a variety of foundation models (including audio and vision), above and beyond only language models, as it does not depend on prompts. We demonstrate our approach on two tasks. On the well-known task of stylized image captioning, our experiments show that our approach outperforms semi-supervised state-of-the-art models, while being zero-shot and avoiding costly training, data collection, and prompt engineering. We further demonstrate this method on a novel task, audio-aware image captioning, in which an image and audio are given and the task is to generate text that describes the image within the context of the provided audio. Our code is available on GitHub.",
    "authors": [
        "Daniela Ben-David",
        "Tzuf Paz-Argaman",
        "Reut Tsarfaty"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "On the well-known task of stylized image captioning, the experiments show that this approach outperforms semi-supervised state-of-the-art models, while being zero-shot and avoiding costly training, data collection, and prompt engineering."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}