{
    "acronym": "7821e7639ffaeea175422f35fae2eb1c095ed1a6",
    "title": "Protein Language Models and Structure Prediction: Connection and Progression",
    "seed_ids": [
        "flash",
        "c51192d7440807dc98cc4374fb5d919390d70b0b",
        "dc0102a51a9d33e104a4a3808a18cf17f057228c",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "b15469d0ab3dc3a9dec037d761817b3fe546bed6",
        "bc519f58ae61afbf6318d6e4239d2d565c7ba467",
        "366244acdd930e488ae224ab6e2a92dc24aa7e06",
        "8323c591e119eb09b28b29fd6c7bc76bd889df7a",
        "75acc731bdd2b626edc74672a30da3bc51010ae8",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "ad7129af0644dbcafa9aa2f111cb76526ea444a1",
        "145b8b5d99a2beba6029418ca043585b90138d12",
        "7ebed46b7f3ec913e508e6468304fcaea832eda1",
        "031e4e43aaffd7a479738dcea69a2d5be7957aa3",
        "ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "7821e7639ffaeea175422f35fae2eb1c095ed1a6",
    "abstract": "The prediction of protein structures from sequences is an important task for function prediction, drug design, and related biological processes understanding. Recent advances have proved the power of language models (LMs) in processing the protein sequence databases, which inherit the advantages of attention networks and capture useful information in learning representations for proteins. The past two years have witnessed remarkable success in tertiary protein structure prediction (PSP), including evolution-based and single-sequence-based PSP. It seems that instead of using energy-based models and sampling procedures, protein language model (pLM)-based pipelines have emerged as mainstream paradigms in PSP. Despite the fruitful progress, the PSP community needs a systematic and up-to-date survey to help bridge the gap between LMs in the natural language processing (NLP) and PSP domains and introduce their methodologies, advancements and practical applications. To this end, in this paper, we first introduce the similarities between protein and human languages that allow LMs extended to pLMs, and applied to protein databases. Then, we systematically review recent advances in LMs and pLMs from the perspectives of network architectures, pre-training strategies, applications, and commonly-used protein databases. Next, different types of methods for PSP are discussed, particularly how the pLM-based architectures function in the process of protein folding. Finally, we identify challenges faced by the PSP community and foresee promising research directions along with the advances of pLMs. This survey aims to be a hands-on guide for researchers to understand PSP methods, develop pLMs and tackle challenging problems in this field for practical purposes.",
    "authors": [
        "Bozhen Hu",
        "Jun-Xiong Xia",
        "Jiangbin Zheng",
        "Cheng Tan",
        "Yufei Huang",
        "Yongjie Xu",
        "Stan Z. Li"
    ],
    "venue": "arXiv.org",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The similarities between protein and human languages that allow LMs extended to pLMs, and applied to protein databases are introduced, and different types of methods for PSP are discussed, particularly how the pLM-based architectures function in the process of protein folding."
    },
    "citationCount": 20,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}