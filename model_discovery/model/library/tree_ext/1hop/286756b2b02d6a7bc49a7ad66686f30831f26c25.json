{
    "acronym": "286756b2b02d6a7bc49a7ad66686f30831f26c25",
    "title": "Differentiating ChatGPT-Generated and Human-Written Medical Texts: Quantitative Study",
    "seed_ids": [
        "gpt2",
        "848909fbae167f21589bfc7a54fbf27e306b883c",
        "44279244407a64431810f982be6d0c7da4429dd7",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "286756b2b02d6a7bc49a7ad66686f30831f26c25",
    "abstract": "Background Large language models, such as ChatGPT, are capable of generating grammatically perfect and human-like text content, and a large number of ChatGPT-generated texts have appeared on the internet. However, medical texts, such as clinical notes and diagnoses, require rigorous validation, and erroneous medical content generated by ChatGPT could potentially lead to disinformation that poses significant harm to health care and the general public. Objective This study is among the first on responsible artificial intelligence\u2013generated content in medicine. We focus on analyzing the differences between medical texts written by human experts and those generated by ChatGPT and designing machine learning workflows to effectively detect and differentiate medical texts generated by ChatGPT. Methods We first constructed a suite of data sets containing medical texts written by human experts and generated by ChatGPT. We analyzed the linguistic features of these 2 types of content and uncovered differences in vocabulary, parts-of-speech, dependency, sentiment, perplexity, and other aspects. Finally, we designed and implemented machine learning methods to detect medical text generated by ChatGPT. The data and code used in this paper are published on GitHub. Results Medical texts written by humans were more concrete, more diverse, and typically contained more useful information, while medical texts generated by ChatGPT paid more attention to fluency and logic and usually expressed general terminologies rather than effective information specific to the context of the problem. A bidirectional encoder representations from transformers\u2013based model effectively detected medical texts generated by ChatGPT, and the F1 score exceeded 95%. Conclusions Although text generated by ChatGPT is grammatically perfect and human-like, the linguistic characteristics of generated medical texts were different from those written by human experts. Medical text generated by ChatGPT could be effectively detected by the proposed machine learning algorithms. This study provides a pathway toward trustworthy and accountable use of large language models in medicine.",
    "authors": [
        "Wenxiong Liao",
        "Zheng Liu",
        "Haixing Dai",
        "Shaochen Xu",
        "Zihao Wu",
        "Yiyang Zhang",
        "Xiaoke Huang",
        "Dajiang Zhu",
        "Hongmin Cai",
        "Tianming Liu",
        "Xiang Li"
    ],
    "venue": "JMIR Medical Education",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This study focuses on analyzing the differences between medical texts written by human experts and those generated by ChatGPT and designing machine learning workflows to effectively detect and differentiate medical texts generated by ChatGPT."
    },
    "citationCount": 36,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}