{
    "acronym": "e4add4391dfa2a806a50cc1fbe9a9696dac9501f",
    "title": "MPCViT: Searching for Accurate and Efficient MPC-Friendly Vision Transformer with Heterogeneous Attention",
    "seed_ids": [
        "cosformer",
        "linformer",
        "1859fb2b30a2e9d54cbb9605bdd6f270caac6d66",
        "ec139916edd6feb9b3cb3a0325ca96e21dbb0147",
        "86c8d930b492a4f9cadc6c60aecdaaded49acc86",
        "6cfd71d6f3cbe63a0af95b0622a6dd7387ab6acf",
        "c49ac1f916d6d2edeb187e6619c8d23acd95eb21",
        "2e644c67a697073d561da4f4dad35e5ad5316cfd",
        "2d98048c2d2fcd3f6b989d2a54003808906ab4b7",
        "3cbe314cc5407a6c3249815b5173f22ea15173c2",
        "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87"
    ],
    "s2id": "e4add4391dfa2a806a50cc1fbe9a9696dac9501f",
    "abstract": "Secure multi-party computation (MPC) enables computation directly on encrypted data and protects both data and model privacy in deep learning inference. However, existing neural network architectures, including Vision Transformers (ViTs), are not designed or optimized for MPC and incur significant latency overhead. We observe Softmax accounts for the major latency bottleneck due to a high communication complexity, but can be selectively replaced or linearized without compromising the model accuracy. Hence, in this paper, we propose an MPC-friendly ViT, dubbed MPCViT, to enable accurate yet efficient ViT inference in MPC. Based on a systematic latency and accuracy evaluation of the Softmax attention and other attention variants, we propose a heterogeneous attention optimization space. We also develop a simple yet effective MPC-aware neural architecture search algorithm for fast Pareto optimization. To further boost the inference efficiency, we propose MPCViT+, to jointly optimize the Softmax attention and other network components, including GeLU, matrix multiplication, etc. With extensive experiments, we demonstrate that MPCViT achieves 1.9%, 1.3% and 3.6% higher accuracy with 6.2\u00d7, 2.9\u00d7 and 1.9\u00d7 latency reduction compared with baseline ViT, MPCFormer and THE-X on the Tiny-ImageNet dataset, respectively. MPCViT+ further achieves a better Pareto front compared with MPCViT. The code and models for evaluation are available at https://github.com/PKU-SEC-Lab/mpcvit.",
    "authors": [
        "Wenyuan Zeng",
        "Meng Li",
        "Wenjie Xiong",
        "Tong Tong",
        "Wen-jie Lu",
        "Jin Tan",
        "Runsheng Wang",
        "Ru Huang"
    ],
    "venue": "IEEE International Conference on Computer Vision",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper proposes an MPC-friendly ViT, dubbed MPCViT, to enable accurate yet efficient ViT inference in MPC, and develops a simple yet effective MPC-aware neural architecture search algorithm for fast Pareto optimization."
    },
    "citationCount": 6,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}