{
    "acronym": "b758359af8c509cf99cc5c0f9b4293e200903880",
    "title": "Zero-shot Entity and Tweet Characterization with Designed Conditional Prompts and Contexts",
    "seed_ids": [
        "gpt2",
        "85e7d63f75c0916bd350a229e040c5fbb1472e7a",
        "d9f6ada77448664b71128bb19df15765336974a6",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "b758359af8c509cf99cc5c0f9b4293e200903880",
    "abstract": "Online news and social media have been the de facto mediums to disseminate information globally from the beginning of the last decade. However, bias in content and purpose of intentions are not regulated, and managing bias is the responsibility of content consumers. In this regard, understanding the stances and biases of news sources towards speci\ufb01c entities becomes important. To address this problem, we use pretrained language models, which have been shown to bring about good results with no task-speci\ufb01c training or few-shot training. In this work, we approach the prob-lem of characterizing Named Entities and Tweets as an open-ended text classi\ufb01cation and open-ended fact probing problem. We evaluate the zero-shot language model capabilities of Generative Pretrained Transformer 2 (GPT-2) to characterize Entities and Tweets subjectively with human psychology-inspired and logical conditional pre\ufb01xes and contexts. First, we \ufb01ne-tune the GPT-2 modelon a su\ufb03ciently large news corpus and evaluate subjective characterization of popular entities in the corpus by priming with pre\ufb01xes. Second, we \ufb01ne-tune GPT-2 with a Tweets corpus from a few popular hashtags and evaluate characterizing tweets by priming the language model with pre\ufb01xes, questions, and contextual synopsis prompts. Entity characterization results were positive across measures and human evaluation.",
    "authors": [
        "S. Srivatsa",
        "Tushar Mohan",
        "Kumari Neha",
        "Nishchay Malakar",
        "P. Kumaraguru",
        "S. Srinivasa"
    ],
    "venue": "arXiv.org",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work evaluates the zero-shot language model capabilities of Generative Pretrained Transformer 2 (GPT-2) to characterize Entities and Tweets subjectively with human psychology-inspired and logical conditional pre\ufb01xes and contexts and results were positive across measures and human evaluation."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}