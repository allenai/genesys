{
    "acronym": "008cfd24dfdfb28fc6a89c32772c7ffe5cb0cf8a",
    "title": "Towards mental time travel: a hierarchical memory for reinforcement learning agents",
    "seed_ids": [
        "transformerxl",
        "b3bf9fe13195e9aa70e1dac04e01fcff7008e812",
        "46c585ee9abf76779ea4b863d2da4358efd0d1d3",
        "7e9ff94476f41041c75e253e84f487db00e9c861",
        "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
        "f51497f463566581874c941353dd9d80069c5b77",
        "59a916cdc943f0282908e6f3fa0360f4c5fb78d0",
        "7cc730da554003dda77796d2cb4f06da5dfd5592",
        "203b543bfa1e564bb80ff4229b43174d7c71b0c0"
    ],
    "s2id": "008cfd24dfdfb28fc6a89c32772c7ffe5cb0cf8a",
    "abstract": "Reinforcement learning agents often forget details of the past, especially after delays or distractor tasks. Agents with common memory architectures struggle to recall and integrate across multiple timesteps of a past event, or even to recall the details of a single timestep that is followed by distractor tasks. To address these limitations, we propose a Hierarchical Chunk Attention Memory (HCAM), which helps agents to remember the past in detail. HCAM stores memories by dividing the past into chunks, and recalls by first performing high-level attention over coarse summaries of the chunks, and then performing detailed attention within only the most relevant chunks. An agent with HCAM can therefore\"mentally time-travel\"-- remember past events in detail without attending to all intervening events. We show that agents with HCAM substantially outperform agents with other memory architectures at tasks requiring long-term recall, retention, or reasoning over memory. These include recalling where an object is hidden in a 3D environment, rapidly learning to navigate efficiently in a new neighborhood, and rapidly learning and retaining new object names. Agents with HCAM can extrapolate to task sequences much longer than they were trained on, and can even generalize zero-shot from a meta-learning setting to maintaining knowledge across episodes. HCAM improves agent sample efficiency, generalization, and generality (by solving tasks that previously required specialized architectures). Our work is a step towards agents that can learn, interact, and adapt in complex and temporally-extended environments.",
    "authors": [
        "Andrew Kyle Lampinen",
        "Stephanie C. Y. Chan",
        "Andrea Banino",
        "Felix Hill"
    ],
    "venue": "Neural Information Processing Systems",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Hierarchical Chunk Attention Memory improves agent sample efficiency, generalization, and generality (by solving tasks that previously required specialized architectures), and is a step towards agents that can learn, interact, and adapt in complex and temporally-extended environments."
    },
    "citationCount": 40,
    "influentialCitationCount": 4,
    "code": null,
    "description": null,
    "url": null
}