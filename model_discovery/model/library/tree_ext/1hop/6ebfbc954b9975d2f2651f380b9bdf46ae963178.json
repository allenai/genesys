{
    "acronym": "6ebfbc954b9975d2f2651f380b9bdf46ae963178",
    "title": "PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable",
    "seed_ids": [
        "gpt",
        "75acc731bdd2b626edc74672a30da3bc51010ae8",
        "791c3c30f2af10ac06f4fbc5b1e8960064aacbc7",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "6ebfbc954b9975d2f2651f380b9bdf46ae963178",
    "abstract": "Pre-training models have been proved effective for a wide range of natural language processing tasks. Inspired by this, we propose a novel dialogue generation pre-training framework to support various kinds of conversations, including chit-chat, knowledge grounded dialogues, and conversational question answering. In this framework, we adopt flexible attention mechanisms to fully leverage the bi-directional context and the uni-directional characteristic of language generation. We also introduce discrete latent variables to tackle the inherent one-to-many mapping problem in response generation. Two reciprocal tasks of response generation and latent act recognition are designed and carried out simultaneously within a shared network. Comprehensive experiments on three publicly available datasets verify the effectiveness and superiority of the proposed framework.",
    "authors": [
        "Siqi Bao",
        "H. He",
        "Fan Wang",
        "Hua Wu"
    ],
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2019,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a novel dialogue generation pre-training framework to support various kinds of conversations, including chit-chat, knowledge grounded dialogues, and conversational question answering, and introduces discrete latent variables to tackle the inherent one-to-many mapping problem in response generation."
    },
    "citationCount": 251,
    "influentialCitationCount": 32,
    "code": null,
    "description": null,
    "url": null
}