{
    "acronym": "4fcd94cd8ee484004588c60531952bc56c3af67b",
    "title": "RotRNN: Modelling Long Sequences with Rotations",
    "seed_ids": [
        "s4",
        "resurrectrnn",
        "f393aff1593c2d370ec0ae004910d18e40524967",
        "6d7d141c75af752ffc0d8a6184cca3f9323d6c74",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "7e9ff94476f41041c75e253e84f487db00e9c861"
    ],
    "s2id": "4fcd94cd8ee484004588c60531952bc56c3af67b",
    "abstract": "Linear recurrent models, such as State Space Models (SSMs) and Linear Recurrent Units (LRUs), have recently shown state-of-the-art performance on long sequence modelling benchmarks. Despite their success, they come with a number of drawbacks, most notably their complex initialisation and normalisation schemes. In this work, we address some of these issues by proposing RotRNN -- a linear recurrent model which utilises the convenient properties of rotation matrices. We show that RotRNN provides a simple model with fewer theoretical assumptions than prior works, with a practical implementation that remains faithful to its theoretical derivation, achieving comparable scores to the LRU and SSMs on several long sequence modelling datasets.",
    "authors": [
        "Rares Dolga",
        "Kai Biegun",
        "Jake Cunningham",
        "David Barber"
    ],
    "venue": "",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is shown that RotRNN provides a simple model with fewer theoretical assumptions than prior works, with a practical implementation that remains faithful to its theoretical derivation, achieving comparable scores to the LRU and SSMs on several long sequence modelling datasets."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}