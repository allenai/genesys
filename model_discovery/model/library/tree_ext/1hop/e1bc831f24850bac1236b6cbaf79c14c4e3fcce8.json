{
    "acronym": "e1bc831f24850bac1236b6cbaf79c14c4e3fcce8",
    "title": "Weak-to-Strong Compositional Learning from Generative Models for Language-based Object Detection",
    "seed_ids": [
        "gpt3",
        "bert",
        "cf694df964caa156ec306b45d3a3127533cb458f",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7"
    ],
    "s2id": "e1bc831f24850bac1236b6cbaf79c14c4e3fcce8",
    "abstract": "Vision-language (VL) models often exhibit a limited understanding of complex expressions of visual objects (e.g., attributes, shapes, and their relations), given complex and diverse language queries. Traditional approaches attempt to improve VL models using hard negative synthetic text, but their effectiveness is limited. In this paper, we harness the exceptional compositional understanding capabilities of generative foundational models. We introduce a novel method for structured synthetic data generation aimed at enhancing the compositional understanding of VL models in language-based object detection. Our framework generates densely paired positive and negative triplets (image, text descriptions, and bounding boxes) in both image and text domains. By leveraging these synthetic triplets, we transform 'weaker' VL models into 'stronger' models in terms of compositional understanding, a process we call\"Weak-to-Strong Compositional Learning\"(WSCL). To achieve this, we propose a new compositional contrastive learning formulation that discovers semantics and structures in complex descriptions from synthetic triplets. As a result, VL models trained with our synthetic data generation exhibit a significant performance boost in the Omnilabel benchmark by up to +5AP and the D3 benchmark by +6.9AP upon existing baselines.",
    "authors": [
        "Kwanyong Park",
        "Kuniaki Saito",
        "Donghyun Kim"
    ],
    "venue": "",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel method for structured synthetic data generation aimed at enhancing the compositional understanding of VL models in language-based object detection and proposes a new compositional contrastive learning formulation that discovers semantics and structures in complex descriptions from synthetic triplets."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}