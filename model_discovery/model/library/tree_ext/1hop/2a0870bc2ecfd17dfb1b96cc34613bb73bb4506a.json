{
    "acronym": "2a0870bc2ecfd17dfb1b96cc34613bb73bb4506a",
    "title": "BLACK BOX ATTACKS ON TRANSFORMER LANGUAGE MODELS",
    "seed_ids": [
        "gpt",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "2a0870bc2ecfd17dfb1b96cc34613bb73bb4506a",
    "abstract": "Language models based on Transformers have proven remarkably effective at producing human-quality text. While such models enable users to quickly generate coherent long-form passages, they are also prone to leaking information about the individual data records used for training. In this work we first implement a Transformer-based architecture for dialog completion. We next investigate the susceptibility of this model to membership inference attack under varying conditions of data and information availability. We show how to train attack models to infer membership in a Transformer language model target even in a query-limited black box setting.",
    "authors": [
        "Vedant Misra"
    ],
    "venue": "",
    "year": 2019,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work implements a Transformer-based architecture for dialog completion and investigates the susceptibility of this model to membership inference attack under varying conditions of data and information availability, and shows how to train attack models to infer membership in a Trans transformer language model target even in a query-limited black box setting."
    },
    "citationCount": 9,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}