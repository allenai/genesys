{
    "acronym": "235303a8bc1e4892efd525a38ead657422d8a519",
    "title": "Transformers are Sample Efficient World Models",
    "seed_ids": [
        "gpt2",
        "6b7bf6cf5d0e1004d4468edfac4e8f81c0d0c50d",
        "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7",
        "2d9ae4c167510ed78803735fc57ea67c3cc55a35",
        "2cd605106b88c85d7d8b865b1ef0f8c8293debf1",
        "59a916cdc943f0282908e6f3fa0360f4c5fb78d0",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "235303a8bc1e4892efd525a38ead657422d8a519",
    "abstract": "Deep reinforcement learning agents are notoriously sample inefficient, which considerably limits their application to real-world problems. Recently, many model-based methods have been designed to address this issue, with learning in the imagination of a world model being one of the most prominent approaches. However, while virtually unlimited interaction with a simulated environment sounds appealing, the world model has to be accurate over extended periods of time. Motivated by the success of Transformers in sequence modeling tasks, we introduce IRIS, a data-efficient agent that learns in a world model composed of a discrete autoencoder and an autoregressive Transformer. With the equivalent of only two hours of gameplay in the Atari 100k benchmark, IRIS achieves a mean human normalized score of 1.046, and outperforms humans on 10 out of 26 games, setting a new state of the art for methods without lookahead search. To foster future research on Transformers and world models for sample-efficient reinforcement learning, we release our code and models at https://github.com/eloialonso/iris.",
    "authors": [
        "Vincent Micheli",
        "Eloi Alonso",
        "Franccois Fleuret"
    ],
    "venue": "International Conference on Learning Representations",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "IRIS is introduced, a data-efficient agent that learns in a world model composed of a discrete autoencoder and an autoregressive Transformer that outperforms humans on 10 out of 26 games, setting a new state of the art for methods without lookahead search."
    },
    "citationCount": 102,
    "influentialCitationCount": 13,
    "code": null,
    "description": null,
    "url": null
}