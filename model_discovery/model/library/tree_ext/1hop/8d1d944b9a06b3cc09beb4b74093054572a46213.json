{
    "acronym": "8d1d944b9a06b3cc09beb4b74093054572a46213",
    "title": "UNSEE: Unsupervised Non-contrastive Sentence Embeddings",
    "seed_ids": [
        "bert",
        "85e7d63f75c0916bd350a229e040c5fbb1472e7a",
        "faadd7d081c8d67e8c2567e8a5579e46cd6b2280"
    ],
    "s2id": "8d1d944b9a06b3cc09beb4b74093054572a46213",
    "abstract": "In this paper, we introduce UNSEE, which stands for Unsupervised Non-Contrastive Sentence Embeddings. UNSEE demonstrates better performance compared to SimCSE in the Massive Text Embedding (MTEB) benchmark. We begin by highlighting the issue of representation collapse that occurs with the replacement of contrastive objectives with non-contrastive objectives in SimCSE. Subsequently, we introduce a straightforward solution called the target network to mitigate this problem. This approach enables us to harness non-contrastive objectives while ensuring training stability and achieving performance improvements similar to those seen with contrastive objectives. We have reached peak performance in non-contrastive sentence embeddings through extensive fine-tuning and optimization. These efforts have resulted in superior sentence representation models, emphasizing the importance of careful tuning and optimization for non-contrastive objectives.",
    "authors": [
        "\u00d6mer Veysel \u00c7agatan"
    ],
    "venue": "Conference of the European Chapter of the Association for Computational Linguistics",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper introduces UNSEE, which stands for Unsupervised Non-Contrastive Sentence Embeddings, and introduces a straightforward solution called the target network to mitigate the issue of representation collapse that occurs with the replacement of contrastive objectives with non-contrastive objectives in SimCSE."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}