{
    "acronym": "8f29d94a68894496b49a077a4a1f175629fb9744",
    "title": "Parallel Hierarchical Transformer with Attention Alignment for Abstractive Multi-Document Summarization",
    "seed_ids": [
        "memcompress",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "7cc730da554003dda77796d2cb4f06da5dfd5592",
        "203b543bfa1e564bb80ff4229b43174d7c71b0c0"
    ],
    "s2id": "8f29d94a68894496b49a077a4a1f175629fb9744",
    "abstract": "In comparison to single-document summarization, abstractive Multi-Document Summarization (MDS) brings challenges on the representation and coverage of its lengthy and linked sources. This study develops a Parallel Hierarchical Transformer (PHT) with attention alignment for MDS. By incorporating word- and paragraph-level multi-head attentions, the hierarchical architecture of PHT allows better processing of dependencies at both token and document levels. To guide the decoding towards a better coverage of the source documents, the attention-alignment mechanism is then introduced to calibrate beam search with predicted optimal attention distributions. Based on the WikiSum data, a comprehensive evaluation is conducted to test improvements on MDS by the proposed architecture. By better handling the inner- and cross-document information, results in both ROUGE and human evaluation suggest that our hierarchical model generates summaries of higher quality relative to other Transformer-based baselines at relatively low computational cost.",
    "authors": [
        "Ye Ma",
        "Lu Zong"
    ],
    "venue": "arXiv.org",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A Parallel Hierarchical Transformer with attention alignment for MDS is developed by incorporating word- and paragraph-level multi-head attentions and suggests that the hierarchical model generates summaries of higher quality relative to other Transformer-based baselines at relatively low computational cost."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}