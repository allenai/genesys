{
    "acronym": "55cd2d0a8f26c4dc458303f937af2b6fb8f8b693",
    "title": "PolyFormer: Referring Image Segmentation as Sequential Polygon Generation",
    "seed_ids": [
        "gpt2",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "22312f763328cf540791de8c2449ea1e7436f476",
        "5e00596fa946670d894b1bdaeff5a98e3867ef13",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "55cd2d0a8f26c4dc458303f937af2b6fb8f8b693",
    "abstract": "In this work, instead of directly predicting the pixel-level segmentation masks, the problem of referring image seg-mentation is formulated as sequential polygon generation, and the predicted polygons can be later converted into segmentation masks. This is enabled by a new sequence-to-sequence framework, Polygon Transformer (PolyFormer), which takes a sequence of image patches and text query to-kens as input, and outputs a sequence of polygon vertices autoregressively. For more accurate geometric localization, we propose a regression-based decoder, which predicts the precise floating-point coordinates directly, without any co-ordinate quantization error. In the experiments, PolyFormer outperforms the prior art by a clear margin, e.g., 5.40% and 4.52% absolute improvements on the challenging Re-fCOCO+ and RefCOCOg datasets. It also shows strong generalization ability when evaluated on the referring video segmentation task without fine-tuning, e.g., achieving competitive 61.5% J&F on the Ref-DAVIS17 dataset.",
    "authors": [
        "Jiang Liu",
        "Hui Ding",
        "Zhaowei Cai",
        "Yuting Zhang",
        "R. Satzoda",
        "V. Mahadevan",
        "R. Manmatha"
    ],
    "venue": "Computer Vision and Pattern Recognition",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a regression-based decoder, which predicts the precise floating-point coordinates directly, without any co-ordinate quantization error, and shows strong generalization ability when evaluated on the referring video segmentation task without fine-tuning."
    },
    "citationCount": 69,
    "influentialCitationCount": 9,
    "code": null,
    "description": null,
    "url": null
}