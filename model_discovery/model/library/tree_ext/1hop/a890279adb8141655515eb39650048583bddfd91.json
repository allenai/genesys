{
    "acronym": "a890279adb8141655515eb39650048583bddfd91",
    "title": "StARformer: Transformer With State-Action-Reward Representations for Robot Learning",
    "seed_ids": [
        "gpt2",
        "94b69cf199fa0b6c842e17fe5d6174a9d161c3df",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
        "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8",
        "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "a890279adb8141655515eb39650048583bddfd91",
    "abstract": "Reinforcement Learning (RL) can be considered as a sequence modeling task, where an agent employs a sequence of past state-action-reward experiences to predict a sequence of future actions. In this work, we propose State-Action-Reward Transformer (StARformer), a Transformer architecture for robot learning with image inputs, which explicitly models short-term state-action-reward representations (StAR-representations), essentially introducing a Markovian-like inductive bias to improve long-term modeling. StARformer first extracts StAR-representations using self-attending patches of image states, action, and reward tokens within a short temporal window. These StAR-representations are combined with pure image state representations, extracted as convolutional features, to perform self-attention over the whole sequence. Our experimental results show that StARformer outperforms the state-of-the-art Transformer-based method on image-based Atari and DeepMind Control Suite benchmarks, under both offline-RL and imitation learning settings. We find that models can benefit from our combination of patch-wise and convolutional image embeddings. StARformer is also more compliant with longer sequences of inputs than the baseline method. Finally, we demonstrate how StARformer can be successfully applied to a real-world robot imitation learning setting via a human-following task.",
    "authors": [
        "Jinghuan Shang",
        "Xiang Li",
        "Kumara Kahatapitiya",
        "Yu-Cheol Lee",
        "M. Ryoo"
    ],
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "StARformer is proposed, a Transformer architecture for robot learning with image inputs, which explicitly models short-term state-action-reward representations (StAR-representations), essentially introducing a Markovian-like inductive bias to improve long-term modeling."
    },
    "citationCount": 6,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}