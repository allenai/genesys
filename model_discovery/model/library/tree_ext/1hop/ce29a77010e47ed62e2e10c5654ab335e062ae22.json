{
    "acronym": "ce29a77010e47ed62e2e10c5654ab335e062ae22",
    "title": "Improving Media Bias Detection with state-of-the-art Transformers",
    "seed_ids": [
        "gpt",
        "6c761cfdb031701072582e434d8f64d436255da6",
        "2a218786f4615b82389f78472e7ff22e6ce57490",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "d9f6ada77448664b71128bb19df15765336974a6",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "ce29a77010e47ed62e2e10c5654ab335e062ae22",
    "abstract": "This thesis introduces MBIB, the Media Bias Identification Benchmark. MBIB, inspired by GLUE [Wang et al., 2019b], consists of nine unified media bias tasks and associated datasets. It allows for comprehensive performance analyses and the comparison of models aimed at detecting media bias. An extensive overview of existing media bias datasets is created. Out of this overview of 115 datasets 22 datasets are selected, preprocessed, and combined to form the data basis for MBIB. A framework is developed to evaluate models on MBIB in a unified way. The framework is then used to evaluate transformer models on the benchmark and to set baseline performances. With MBIB this thesis presents a comprehensive and demanding task collection, aimed at developing advanced methods for detecting media bias. Additionally, it shows that the transformer model choice matters less for performance than initially presumed. Finally, it can function as a catalog of current datasets and provide a deeper understanding of remaining research gaps related to media bias.",
    "authors": [
        "Martin Wessel",
        "Juhi Kulshrestha",
        "I. Echizen"
    ],
    "venue": "",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "MBIB shows that the transformer model choice matters less for performance than initially presumed, and can function as a catalog of current datasets and provide a deeper understanding of remaining research gaps related to media bias."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}