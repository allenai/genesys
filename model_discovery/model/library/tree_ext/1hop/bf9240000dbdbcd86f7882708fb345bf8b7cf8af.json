{
    "acronym": "bf9240000dbdbcd86f7882708fb345bf8b7cf8af",
    "title": "JBNU at SemEval-2020 Task 4: BERT and UniLM for Commonsense Validation and Explanation",
    "seed_ids": [
        "gpt",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "145b8b5d99a2beba6029418ca043585b90138d12",
        "ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "bf9240000dbdbcd86f7882708fb345bf8b7cf8af",
    "abstract": "This paper presents our contributions to the SemEval-2020 Task 4 Commonsense Validation and Explanation (ComVE) and includes the experimental results of the two Subtasks B and C of the SemEval-2020 Task 4. Our systems rely on pre-trained language models, i.e., BERT (including its variants) and UniLM, and rank 10th and 7th among 27 and 17 systems on Subtasks B and C, respectively. We analyze the commonsense ability of the existing pretrained language models by testing them on the SemEval-2020 Task 4 ComVE dataset, specifically for Subtasks B and C, the explanation subtasks with multi-choice and sentence generation, respectively.",
    "authors": [
        "Seung-Hoon Na",
        "Jong-Hyeon Lee"
    ],
    "venue": "International Workshop on Semantic Evaluation",
    "year": 2020,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The commonsense ability of the existing pretrained language models are analyzed by testing them on the SemEval-2020 Task 4 ComVE dataset, specifically for Subtasks B and C, the explanation subtasks with multi-choice and sentence generation, respectively."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}