{
    "acronym": "22a0bfac8cc0cb9c01123d8a898e3235ddcab269",
    "title": "Weigh Your Own Words: Improving Hate Speech Counter Narrative Generation via Attention Regularization",
    "seed_ids": [
        "gpt2",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "492a655a67e6ec7423a968cedb70eec0cdbc8e98",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "22a0bfac8cc0cb9c01123d8a898e3235ddcab269",
    "abstract": "Recent computational approaches for combating online hate speech involve the automatic generation of counter narratives by adapting Pretrained Transformer-based Language Models (PLMs) with human-curated data. This process, however, can produce in-domain overfitting, resulting in models generating acceptable narratives only for hatred similar to training data, with little portability to other targets or to real-world toxic language. This paper introduces novel attention regularization methodologies to improve the generalization capabilities of PLMs for counter narratives generation. Overfitting to training-specific terms is then discouraged, resulting in more diverse and richer narratives. We experiment with two attention-based regularization techniques on a benchmark English dataset. Regularized models produce better counter narratives than state-of-the-art approaches in most cases, both in terms of automatic metrics and human evaluation, especially when hateful targets are not present in the training data. This work paves the way for better and more flexible counter-speech generation models, a task for which datasets are highly challenging to produce.",
    "authors": [
        "Helena Bonaldi",
        "Giuseppe Attanasio",
        "Debora Nozza",
        "Marco Guerini"
    ],
    "venue": "CS4OA",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Novel attention regularization methodologies to improve the generalization capabilities of Pretrained Transformer-based Language Models for counter narratives generation and paves the way for better and more flexible counter-speech generation models."
    },
    "citationCount": 3,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}