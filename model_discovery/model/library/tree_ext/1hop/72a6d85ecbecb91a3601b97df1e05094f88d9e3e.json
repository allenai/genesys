{
    "acronym": "72a6d85ecbecb91a3601b97df1e05094f88d9e3e",
    "title": "SEMA: Semantic Attention for Capturing Long-Range Dependencies in Egocentric Lifelogs",
    "seed_ids": [
        "reformer",
        "c49ac1f916d6d2edeb187e6619c8d23acd95eb21",
        "1a883522f3c0051d70be1f8cbdb8989a77395006",
        "7e9ff94476f41041c75e253e84f487db00e9c861",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
        "6f68e1bb253925d8431588555d3010419f322e04",
        "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "657329c633709dd1ac34a30d57341b186b1a47c2",
        "34a4e6818d680875ff0bef9a76de0376118446d1"
    ],
    "s2id": "72a6d85ecbecb91a3601b97df1e05094f88d9e3e",
    "abstract": "Transformer architecture is a defacto standard for modeling global dependency in long sequences. However, quadratic space and time complexity for self-attention prohibits transformers from scaling to extremely long sequences (> 10k). Low-rank decomposition as a non-negative matrix factorization (NMF) of self-attention demonstrates remarkable performance in linear space and time complexity with strong theoretical guarantees. However, our analysis reveals that NMF-based works struggle to capture the rich spatio-temporal visual cues scattered across the long sequences resulting from egocentric lifelogs. To capture such cues, we propose a novel attention mechanism named SEMantic Atention (SEMA), which factorizes the self-attention matrix into a semantically meaningful subspace. We demonstrate SEMA in a representation learning setting, aiming to recover activity patterns in extremely long (weeks-long) egocentric lifelogs using a novel self-supervised training pipeline. Compared to the current state-of-the-art, we report significant improvement in terms of (NMI, AMI, and F-Score) for EgoRoutine, UTE, and Epic Kitchens datasets. Furthermore, to underscore the efficacy of SEMA, we extend its application to conventional video tasks such as online action detection, video recognition, and action localization. Code is available at https://github.com/Pravin74/Semantic_attention/",
    "authors": [
        "Pravin Nagar",
        "Ajay Shastry",
        "Jayesh Chaudhari",
        "Chetan Arora"
    ],
    "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a novel attention mechanism named SEMantic Atention (SEMA), which factorizes the self-attention matrix into a semantically meaningful subspace and extends its application to conventional video tasks such as online action detection, video recognition, and action localization."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}