{
    "acronym": "15c711580ece83bd6efe7824cac078cb3dc5552c",
    "title": "Improving Content Recommendation: Knowledge Graph-Based Semantic Contrastive Learning for Diversity and Cold-Start Users",
    "seed_ids": [
        "bert",
        "a022bda79947d1f656a1164003c1b3ae9a843df9",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "15c711580ece83bd6efe7824cac078cb3dc5552c",
    "abstract": "Addressing the challenges related to data sparsity, cold-start problems, and diversity in recommendation systems is both crucial and demanding. Many current solutions leverage knowledge graphs to tackle these issues by combining both item-based and user-item collaborative signals. A common trend in these approaches focuses on improving ranking performance at the cost of escalating model complexity, reducing diversity, and complicating the task. It is essential to provide recommendations that are both personalized and diverse, rather than solely relying on achieving high rank-based performance, such as Click-through rate, Recall, etc. In this paper, we propose a hybrid multi-task learning approach, training on user-item and item-item interactions. We apply item-based contrastive learning on descriptive text, sampling positive and negative pairs based on item metadata. Our approach allows the model to better understand the relationships between entities within the knowledge graph by utilizing semantic information from text. It leads to more accurate, relevant, and diverse user recommendations and a benefit that extends even to cold-start users who have few interactions with items. We perform extensive experiments on two widely used datasets to validate the effectiveness of our approach. Our findings demonstrate that jointly training user-item interactions and item-based signals using synopsis text is highly effective. Furthermore, our results provide evidence that item-based contrastive learning enhances the quality of entity embeddings, as indicated by metrics such as uniformity and alignment.",
    "authors": [
        "Yejin Kim",
        "Scott Rome",
        "Kevin Foley",
        "Mayur Nankani",
        "Rimon Melamed",
        "Javier Morales",
        "Abhay Yadav",
        "Maria Peifer",
        "Sardar Hamidian",
        "H. H. Huang"
    ],
    "venue": "International Conference on Language Resources and Evaluation",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The findings demonstrate that jointly training user-item interactions and item-based signals using synopsis text is highly effective and provides evidence that item-based contrastive learning enhances the quality of entity embeddings, as indicated by metrics such as uniformity and alignment."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}