{
    "acronym": "683de10cda9cd3b709983db2da67f1f059fa516a",
    "title": "Towards More Effective and Economic Sparsely-Activated Model",
    "seed_ids": [
        "gpt",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "8323c591e119eb09b28b29fd6c7bc76bd889df7a",
        "d0086b86103a620a86bc918746df0aa642e2a8a3",
        "ad7129af0644dbcafa9aa2f111cb76526ea444a1",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "683de10cda9cd3b709983db2da67f1f059fa516a",
    "abstract": "The sparsely-activated models have achieved great success in natural language processing through large-scale parameters and relatively low computational cost, and gradually become a feasible technique for training and implementing extremely large models. Due to the limit of communication cost, activating multiple experts is hardly affordable during training and inference. Therefore, previous work usually activate just one expert at a time to alleviate additional communication cost. Such routing mechanism limits the upper bound of model performance. In this paper, we first investigate a phenomenon that increasing the number of activated experts can boost the model performance with higher sparse ratio. To increase the number of activated experts without an increase in computational cost, we propose SAM (Switch and Mixture) routing, an efficient hierarchical routing mechanism that activates multiple experts in a same device (GPU). Our methods shed light on the training of extremely large sparse models and experiments prove that our models can achieve significant performance gain with great efficiency improvement.",
    "authors": [
        "Hao Jiang",
        "Ke Zhan",
        "Jianwei Qu",
        "Yongkang Wu",
        "Zhaoye Fei",
        "Xinyu Zhang",
        "Lei Chen",
        "Zhicheng Dou",
        "Xipeng Qiu",
        "Zi-Han Guo",
        "Ruofei Lai",
        "Jiawen Wu",
        "Enrui Hu",
        "Yinxia Zhang",
        "Yantao Jia",
        "Fan Yu",
        "Zhao Cao"
    ],
    "venue": "arXiv.org",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "To increase the number of activated experts without an increase in computational cost, SAM (Switch and Mixture) routing is proposed, an efficient hierarchical routing mechanism that activates multiple experts in a same device (GPU)."
    },
    "citationCount": 8,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}