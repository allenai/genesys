{
    "acronym": "41ecff85ec0c8082fcd4efcf31fc5ec3911dce88",
    "title": "Large Language Models as Agents in Two-Player Games",
    "seed_ids": [
        "gpt3",
        "e7ad08848d5d7c5c47673ffe0da06af443643bda",
        "5f19ae1135a9500940978104ec15a5b8751bc7d2",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "7a15950dc71079285a4eaf195de5aadd87c41b40",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "41ecff85ec0c8082fcd4efcf31fc5ec3911dce88",
    "abstract": "By formally defining the training processes of large language models (LLMs), which usually encompasses pre-training, supervised fine-tuning, and reinforcement learning with human feedback, within a single and unified machine learning paradigm, we can glean pivotal insights for advancing LLM technologies. This position paper delineates the parallels between the training methods of LLMs and the strategies employed for the development of agents in two-player games, as studied in game theory, reinforcement learning, and multi-agent systems. We propose a re-conceptualization of LLM learning processes in terms of agent learning in language-based games. This framework unveils innovative perspectives on the successes and challenges in LLM development, offering a fresh understanding of addressing alignment issues among other strategic considerations. Furthermore, our two-player game approach sheds light on novel data preparation and machine learning techniques for training LLMs.",
    "authors": [
        "Yang Liu",
        "Peng Sun",
        "Hang Li"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This position paper delineates the parallels between the training methods of LLMs and the strategies employed for the development of agents in two-player games, as studied in game theory, reinforcement learning, and multi-agent systems."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}