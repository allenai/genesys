{
    "acronym": "86547e821574cdf672b23896c7a3015b84fd00ec",
    "title": "Safe Reinforcement Learning with Free-form Natural Language Constraints and Pre-Trained Language Models",
    "seed_ids": [
        "gpt3",
        "7a15950dc71079285a4eaf195de5aadd87c41b40"
    ],
    "s2id": "86547e821574cdf672b23896c7a3015b84fd00ec",
    "abstract": "Safe reinforcement learning (RL) agents accomplish given tasks while adhering to specific constraints. Employing constraints expressed via easily-understandable human language offers considerable potential for real-world applications due to its accessibility and non-reliance on domain expertise. Previous safe RL methods with natural language constraints typically adopt a recurrent neural network, which leads to limited capabilities when dealing with various forms of human language input. Furthermore, these methods often require a ground-truth cost function, necessitating domain expertise for the conversion of language constraints into a well-defined cost function that determines constraint violation. To address these issues, we proposes to use pre-trained language models (LM) to facilitate RL agents' comprehension of natural language constraints and allow them to infer costs for safe policy learning. Through the use of pre-trained LMs and the elimination of the need for a ground-truth cost, our method enhances safe policy learning under a diverse set of human-derived free-form natural language constraints. Experiments on grid-world navigation and robot control show that the proposed method can achieve strong performance while adhering to given constraints. The usage of pre-trained LMs allows our method to comprehend complicated constraints and learn safe policies without the need for ground-truth cost at any stage of training or evaluation. Extensive ablation studies are conducted to demonstrate the efficacy of each part of our method.",
    "authors": [
        "Xingzhou Lou",
        "Junge Zhang",
        "Ziyan Wang",
        "Kaiqi Huang",
        "Yali Du"
    ],
    "venue": "Adaptive Agents and Multi-Agent Systems",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The usage of pre-trained LMs is used to facilitate RL agents' comprehension of natural language constraints and allow them to infer costs for safe policy learning, which enhances safe policy learning under a diverse set of human-derived free-form natural language constraints."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}