{
    "acronym": "3f877562995d1408b0b3abd5dfbbe8eeecb6061e",
    "title": "From Understanding to Utilization: A Survey on Explainability for Large Language Models",
    "seed_ids": [
        "streamingllm",
        "fdc53c2c10742464087c0525f77e32604827a21d",
        "e74ea82b8eda84925b6defdfca9ed33b50d6d2ef",
        "7bd4ca8706a79983d31ab74e6c79bfdfd949602e",
        "7c23ce3547ae837ff633b14e457a93de6d270b37",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "fd1b829261ba04bb92e0ab60c4f6e7cea0d99fbf",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "d0086b86103a620a86bc918746df0aa642e2a8a3",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "3f877562995d1408b0b3abd5dfbbe8eeecb6061e",
    "abstract": "Explainability for Large Language Models (LLMs) is a critical yet challenging aspect of natural language processing. As LLMs are increasingly integral to diverse applications, their\"black-box\"nature sparks significant concerns regarding transparency and ethical use. This survey underscores the imperative for increased explainability in LLMs, delving into both the research on explainability and the various methodologies and tasks that utilize an understanding of these models. Our focus is primarily on pre-trained Transformer-based LLMs, such as LLaMA family, which pose distinctive interpretability challenges due to their scale and complexity. In terms of existing methods, we classify them into local and global analyses, based on their explanatory objectives. When considering the utilization of explainability, we explore several compelling methods that concentrate on model editing, control generation, and model enhancement. Additionally, we examine representative evaluation metrics and datasets, elucidating their advantages and limitations. Our goal is to reconcile theoretical and empirical understanding with practical implementation, proposing exciting avenues for explanatory techniques and their applications in the LLMs era.",
    "authors": [
        "Haoyan Luo",
        "Lucia Specia"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This survey underscores the imperative for increased explainability in LLMs, delving into both the research on explainability and the various methodologies and tasks that utilize an understanding of these models."
    },
    "citationCount": 8,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}