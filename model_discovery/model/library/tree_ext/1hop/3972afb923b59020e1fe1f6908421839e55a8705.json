{
    "acronym": "3972afb923b59020e1fe1f6908421839e55a8705",
    "title": "Fairness Concerns in App Reviews: A Study on AI-based Mobile Apps",
    "seed_ids": [
        "gpt3"
    ],
    "s2id": "3972afb923b59020e1fe1f6908421839e55a8705",
    "abstract": "Fairness is one of the socio-technical concerns that must be addressed in AI-based systems. Unfair AI-based systems, particularly unfair AI-based mobile apps, can pose difficulties for a significant proportion of the global population. This paper aims to analyze fairness concerns in AI-based app reviews. We first manually constructed a ground-truth dataset, including 1,132 fairness and 1,473 non-fairness reviews. Leveraging the ground-truth dataset, we developed and evaluated a set of machine learning and deep learning models that distinguish fairness reviews from non-fairness reviews. Our experiments show that our best-performing model can detect fairness reviews with a precision of 94%. We then applied the best-performing model on approximately 9.5M reviews collected from 108 AI-based apps and identified around 92K fairness reviews. Next, applying the K-means clustering technique to the 92K fairness reviews, followed by manual analysis, led to the identification of six distinct types of fairness concerns (e.g., 'receiving different quality of features and services in different platforms and devices' and 'lack of transparency and fairness in dealing with user-generated content'). Finally, the manual analysis of 2,248 app owners' responses to the fairness reviews identified six root causes (e.g., 'copyright issues') that app owners report to justify fairness concerns.",
    "authors": [
        "A. R. Nasab",
        "Maedeh Dashti",
        "Mojtaba Shahin",
        "Mansooreh Zahedi",
        "Hourieh Khalajzadeh",
        "Chetan Arora",
        "Peng Liang"
    ],
    "venue": "",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A set of machine learning and deep learning models that distinguish fairness reviews from non-fairness reviews are developed and evaluated and show that the best-performing model can detect fairness reviews with a precision of 94%."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}