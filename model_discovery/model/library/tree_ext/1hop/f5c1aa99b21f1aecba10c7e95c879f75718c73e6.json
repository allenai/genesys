{
    "acronym": "f5c1aa99b21f1aecba10c7e95c879f75718c73e6",
    "title": "Subtle Misogyny Detection and Mitigation: An Expert-Annotated Dataset",
    "seed_ids": [
        "bert",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481"
    ],
    "s2id": "f5c1aa99b21f1aecba10c7e95c879f75718c73e6",
    "abstract": "Using novel approaches to dataset development, the Biasly dataset captures the nuance and subtlety of misogyny in ways that are unique within the literature. Built in collaboration with multi-disciplinary experts and annotators themselves, the dataset contains annotations of movie subtitles, capturing colloquial expressions of misogyny in North American film. The dataset can be used for a range of NLP tasks, including classification, severity score regression, and text generation for rewrites. In this paper, we discuss the methodology used, analyze the annotations obtained, and provide baselines using common NLP algorithms in the context of misogyny detection and mitigation. We hope this work will promote AI for social good in NLP for bias detection, explanation, and removal.",
    "authors": [
        "Brooklyn Sheppard",
        "Anna Richter",
        "Allison Cohen",
        "Elizabeth Allyn Smith",
        "Tamara Kneese",
        "Carolyne Pelletier",
        "Ioana Baldini",
        "Yue Dong"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work discusses the methodology used, analyzes the annotations obtained, and provides baselines using common NLP algorithms in the context of misogyny detection and mitigation, hoping this work will promote AI for social good in NLP for bias detection, explanation, and removal."
    },
    "citationCount": 3,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}