{
    "acronym": "1e3e65e7773b7869d9bd7f5394b54199e48195e6",
    "title": "Lawformer: A Pre-trained Language Model for Chinese Legal Long Documents",
    "seed_ids": [
        "longformer",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "2cf3bd0cc1382f35384e259d99e4f9744eeaed28",
        "f4238bd2385a52413ccbacfd9e409a650235bd13"
    ],
    "s2id": "1e3e65e7773b7869d9bd7f5394b54199e48195e6",
    "abstract": null,
    "authors": [
        "Chaojun Xiao",
        "Xueyu Hu",
        "Zhiyuan Liu",
        "Cunchao Tu",
        "Maosong Sun"
    ],
    "venue": "AI Open",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper releases the Longformer-based pretrained language model, named as Lawformer, for Chinese legal long documents understanding, and demonstrates that the model can achieve promising improvement on tasks with long documents as inputs."
    },
    "citationCount": 159,
    "influentialCitationCount": 24,
    "code": null,
    "description": null,
    "url": null
}