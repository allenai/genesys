{
    "acronym": "68ba1c084972c4446cab907de8ad943e33dabd07",
    "title": "Knowledge Transfer by Discriminative Pre-training for Academic Performance Prediction",
    "seed_ids": [
        "performer",
        "reformer",
        "7e9ff94476f41041c75e253e84f487db00e9c861",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
        "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8",
        "6f68e1bb253925d8431588555d3010419f322e04",
        "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
        "34a4e6818d680875ff0bef9a76de0376118446d1",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c"
    ],
    "s2id": "68ba1c084972c4446cab907de8ad943e33dabd07",
    "abstract": "The needs for precisely estimating a student's academic performance have been emphasized with an increasing amount of attention paid to Intelligent Tutoring System (ITS). However, since labels for academic performance, such as test scores, are collected from outside of ITS, obtaining the labels is costly, leading to label-scarcity problem which brings challenge in taking machine learning approaches for academic performance prediction. To this end, inspired by the recent advancement of pre-training method in natural language processing community, we propose DPA, a transfer learning framework with Discriminative Pre-training tasks for Academic performance prediction. DPA pre-trains two models, a generator and a discriminator, and fine-tunes the discriminator on academic performance prediction. In DPA's pre-training phase, a sequence of interactions where some tokens are masked is provided to the generator which is trained to reconstruct the original sequence. Then, the discriminator takes an interaction sequence where the masked tokens are replaced by the generator's outputs, and is trained to predict the originalities of all tokens in the sequence. Compared to the previous state-of-the-art generative pre-training method, DPA is more sample efficient, leading to fast convergence to lower academic performance prediction error. We conduct extensive experimental studies on a real-world dataset obtained from a multi-platform ITS application and show that DPA outperforms the previous state-of-the-art generative pre-training method with a reduction of 4.05% in mean absolute error and more robust to increased label-scarcity.",
    "authors": [
        "Byungsoo Kim",
        "Hangyeol Yu",
        "Dongmin Shin",
        "Youngduck Choi"
    ],
    "venue": "Educational Data Mining",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "DPA is more sample efficient, leading to fast convergence to lower academic performance prediction error, and outperforms the previous state-of-the-art generative pre-training method with a reduction of 4.05% in mean absolute error and more robust to increased label-scarcity."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}