{
    "acronym": "cea62bcb7b951befe148daa34b6100593c2031f0",
    "title": "Exploring and Benchmarking the Planning Capabilities of Large Language Models",
    "seed_ids": [
        "gpt3"
    ],
    "s2id": "cea62bcb7b951befe148daa34b6100593c2031f0",
    "abstract": "We seek to elevate the planning capabilities of Large Language Models (LLMs)investigating four main directions. First, we construct a comprehensive benchmark suite encompassing both classical planning domains and natural language scenarios. This suite includes algorithms to generate instances with varying levels of difficulty, allowing for rigorous and systematic evaluation of LLM performance. Second, we investigate the use of in-context learning (ICL) to enhance LLM planning, exploring the direct relationship between increased context length and improved planning performance. Third, we demonstrate the positive impact of fine-tuning LLMs on optimal planning paths, as well as the effectiveness of incorporating model-driven search procedures. Finally, we investigate the performance of the proposed methods in out-of-distribution scenarios, assessing the ability to generalize to novel and unseen planning challenges.",
    "authors": [
        "Bernd Bohnet",
        "Azade Nova",
        "Aaron T Parisi",
        "Kevin Swersky",
        "Katayoon Goshvadi",
        "Hanjun Dai",
        "Dale Schuurmans",
        "Noah Fiedel",
        "Hanie Sedghi"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A comprehensive benchmark suite encompassing both classical planning domains and natural language scenarios is constructed, exploring the direct relationship between increased context length and improved planning performance and the positive impact of fine-tuning LLMs on optimal planning paths."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}