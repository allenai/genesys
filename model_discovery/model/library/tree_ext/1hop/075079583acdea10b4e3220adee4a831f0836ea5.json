{
    "acronym": "075079583acdea10b4e3220adee4a831f0836ea5",
    "title": "FastBlend: a Powerful Model-Free Toolkit Making Video Stylization Easier",
    "seed_ids": [
        "classfreediffu",
        "e342165a614588878ad0f4bc9bacf3905df34d08",
        "c57293882b2561e1ba03017902df9fc2f289dea2",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d"
    ],
    "s2id": "075079583acdea10b4e3220adee4a831f0836ea5",
    "abstract": "With the emergence of diffusion models and rapid development in image processing, it has become effortless to generate fancy images in tasks such as style transfer and image editing. However, these impressive image processing approaches face consistency issues in video processing. In this paper, we propose a powerful model-free toolkit called FastBlend to address the consistency problem for video processing. Based on a patch matching algorithm, we design two inference modes, including blending and interpolation. In the blending mode, FastBlend eliminates video flicker by blending the frames within a sliding window. Moreover, we optimize both computational efficiency and video quality according to different application scenarios. In the interpolation mode, given one or more keyframes rendered by diffusion models, FastBlend can render the whole video. Since FastBlend does not modify the generation process of diffusion models, it exhibits excellent compatibility. Extensive experiments have demonstrated the effectiveness of FastBlend. In the blending mode, FastBlend outperforms existing methods for video deflickering and video synthesis. In the interpolation mode, FastBlend surpasses video interpolation and model-based video processing approaches. The source codes have been released on GitHub.",
    "authors": [
        "Zhongjie Duan",
        "Chengyu Wang",
        "Cen Chen",
        "Weining Qian",
        "Jun Huang",
        "Mingyi Jin"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A powerful model-free toolkit called FastBlend is proposed to address the consistency problem for video processing, based on a patch matching algorithm, and it outperforms existing methods for video deflickering and video synthesis."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}