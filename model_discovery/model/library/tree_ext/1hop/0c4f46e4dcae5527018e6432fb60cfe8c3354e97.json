{
    "acronym": "0c4f46e4dcae5527018e6432fb60cfe8c3354e97",
    "title": "VideoPoet: A Large Language Model for Zero-Shot Video Generation",
    "seed_ids": [
        "gpt3",
        "1206b05eae5a06ba662ae79fb291b50e359c4f42",
        "498ac9b2e494601d20a3d0211c16acf2b7954a54",
        "87c5b281fa43e6f27191b20a8dd694eda1126336",
        "b21670e8061a06ab97e7d6052c9345a326e84ff8",
        "c57293882b2561e1ba03017902df9fc2f289dea2",
        "3b2a675bb617ae1a920e8e29d535cdf27826e999",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "2d9ae4c167510ed78803735fc57ea67c3cc55a35",
        "2cd605106b88c85d7d8b865b1ef0f8c8293debf1"
    ],
    "s2id": "0c4f46e4dcae5527018e6432fb60cfe8c3354e97",
    "abstract": "We present VideoPoet, a language model capable of synthesizing high-quality video, with matching audio, from a large variety of conditioning signals. VideoPoet employs a decoder-only transformer architecture that processes multimodal inputs -- including images, videos, text, and audio. The training protocol follows that of Large Language Models (LLMs), consisting of two stages: pretraining and task-specific adaptation. During pretraining, VideoPoet incorporates a mixture of multimodal generative objectives within an autoregressive Transformer framework. The pretrained LLM serves as a foundation that can be adapted for a range of video generation tasks. We present empirical results demonstrating the model's state-of-the-art capabilities in zero-shot video generation, specifically highlighting VideoPoet's ability to generate high-fidelity motions. Project page: http://sites.research.google/videopoet/",
    "authors": [
        "D. Kondratyuk",
        "Lijun Yu",
        "Xiuye Gu",
        "Jos\u00e9 Lezama",
        "Jonathan Huang",
        "Rachel Hornung",
        "Hartwig Adam",
        "Hassan Akbari",
        "Y. Alon",
        "Vighnesh Birodkar",
        "Yong Cheng",
        "Ming-Chang Chiu",
        "Josh Dillon",
        "Irfan Essa",
        "Agrim Gupta",
        "Meera Hahn",
        "Anja Hauth",
        "David Hendon",
        "Alonso Martinez",
        "David C. Minnen",
        "David A. Ross",
        "Grant Schindler",
        "Mikhail Sirotenko",
        "Kihyuk Sohn",
        "Krishna Somandepalli",
        "Huisheng Wang",
        "Jimmy Yan",
        "Ming Yang",
        "Xuan Yang",
        "Bryan Seybold",
        "Lu Jiang"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Empirical results demonstrating the model's state-of-the-art capabilities in zero-shot video generation are presented, specifically highlighting VideoPoet's ability to generate high-fidelity motions."
    },
    "citationCount": 75,
    "influentialCitationCount": 5,
    "code": null,
    "description": null,
    "url": null
}