{
    "acronym": "5e20c344594321a80d5dde9f6c3015ebb6c121e7",
    "title": "Gl\u00f3rIA: A Generative and Open Large Language Model for Portuguese",
    "seed_ids": [
        "gpt2",
        "gpt3",
        "7f4bdef8c9d660af6b18a55de0699e5e65ce3b54",
        "be55e8ec4213868db08f2c3168ae666001bea4b8",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "5e20c344594321a80d5dde9f6c3015ebb6c121e7",
    "abstract": "Significant strides have been made in natural language tasks, largely attributed to the emergence of powerful large language models (LLMs). These models, pre-trained on extensive and diverse corpora, have become increasingly capable of comprehending the intricacies of language. Despite the abundance of LLMs for many high-resource languages, the availability of such models remains limited for European Portuguese. We introduce Gl\\'orIA, a robust European Portuguese decoder LLM. To pre-train Gl\\'orIA, we assembled a comprehensive PT-PT text corpus comprising 35 billion tokens from various sources. We present our pre-training methodology, followed by an assessment of the model's effectiveness on multiple downstream tasks. Additionally, to evaluate our models' language modeling capabilities, we introduce CALAME-PT (Context-Aware LAnguage Modeling Evaluation for Portuguese), the first Portuguese zero-shot language-modeling benchmark. Evaluation shows that Gl\\'orIA significantly outperforms existing open PT decoder models in language modeling and that it can generate sound, knowledge-rich, and coherent PT-PT text. The model also exhibits strong potential for various downstream tasks.",
    "authors": [
        "Ricardo Lopes",
        "Jo\u00e3o Magalh\u00e3es",
        "David Semedo"
    ],
    "venue": "International Conference on Computational Processing of the Portuguese Language",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Evaluation shows that GlorIA significantly outperforms existing open PT decoder models in language modeling and that it can generate sound, knowledge-rich, and coherent PT-PT text, which exhibits strong potential for various downstream tasks."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}