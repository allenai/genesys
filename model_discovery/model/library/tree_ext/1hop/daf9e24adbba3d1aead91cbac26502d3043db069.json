{
    "acronym": "daf9e24adbba3d1aead91cbac26502d3043db069",
    "title": "Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken Language Understanding",
    "seed_ids": [
        "gpt2",
        "13a0d8bb38f739990c8cd65a44061c6534f17221",
        "f8cf6c42d48326ff7ae172c5e555178d440bf7cb",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "a8ec7942f0a77bfb61a8c534ad951e66e2f94188",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "daf9e24adbba3d1aead91cbac26502d3043db069",
    "abstract": "Recently, large pretrained language models have demonstrated strong language understanding capabilities. This is particularly reflected in their zero-shot and in-context learning abilities on downstream tasks through prompting. To assess their impact on spoken language understanding (SLU), we evaluate several such models like ChatGPT and OPT of different sizes on multiple benchmarks. We verify the emergent ability unique to the largest models as they can reach intent classification accuracy close to that of supervised models with zero or few shots on various languages given oracle transcripts. By contrast, the results for smaller models fitting a single GPU fall far behind. We note that the error cases often arise from the annotation scheme of the dataset; responses from ChatGPT are still reasonable. We show, however, that the model is worse at slot filling, and its performance is sensitive to ASR errors, suggesting serious challenges for the application of those textual models on SLU.",
    "authors": [
        "Mutian He",
        "Philip N. Garner"
    ],
    "venue": "Interspeech",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is shown that the ChatGPT model is worse at slot filling, and its performance is sensitive to ASR errors, suggesting serious challenges for the application of those textual models on SLU."
    },
    "citationCount": 15,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}