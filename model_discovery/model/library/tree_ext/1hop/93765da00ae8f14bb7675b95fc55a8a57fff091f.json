{
    "acronym": "93765da00ae8f14bb7675b95fc55a8a57fff091f",
    "title": "Can Perplexity Reflect Large Language Model's Ability in Long Text Understanding?",
    "seed_ids": [
        "alibi",
        "a54761081c2b001c057fb6e1ea9a48058d5aa5e0",
        "539fadfb615ef84c240f4741061c44eeda540091",
        "f5afaccfe90268485a9961c5771ec5e71e9b806c",
        "f51497f463566581874c941353dd9d80069c5b77"
    ],
    "s2id": "93765da00ae8f14bb7675b95fc55a8a57fff091f",
    "abstract": "Recent studies have shown that Large Language Models (LLMs) have the potential to process extremely long text. Many works only evaluate LLMs' long-text processing ability on the language modeling task, with perplexity (PPL) as the evaluation metric. However, in our study, we find that there is no correlation between PPL and LLMs' long-text understanding ability. Besides, PPL may only reflect the model's ability to model local information instead of catching long-range dependency. Therefore, only using PPL to prove the model could process long text is inappropriate. The local focus feature of PPL could also explain some existing phenomena, such as the great extrapolation ability of the position method ALiBi. When evaluating a model's ability in long text, we might pay more attention to PPL's limitation and avoid overly relying on it.",
    "authors": [
        "Yutong Hu",
        "Quzhe Huang",
        "Mingxu Tao",
        "Chen Zhang",
        "Yansong Feng"
    ],
    "venue": "Tiny Papers @ ICLR",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "There is no correlation between PPL and LLMs' long-text understanding ability and PPL may only reflect the model's ability to model local information instead of catching long-range dependency, therefore, only using PPL to prove the model could process long text is inappropriate."
    },
    "citationCount": 5,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}