{
    "acronym": "2833716cabbd7c709f4b266832b8b3fa3e37d2c6",
    "title": "RS-Mamba for Large Remote Sensing Image Dense Prediction",
    "seed_ids": [
        "mamba",
        "b24e899ec0f77eef2fc87a9b8e50516367aa1f97",
        "38c48a1cd296d16dc9c56717495d6e44cc354444",
        "6d7d141c75af752ffc0d8a6184cca3f9323d6c74",
        "ca444821352a4bd91884413d8070446e2960715a",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "ca9047c78d48b606c4e4f0c456b1dda550de28b2",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7"
    ],
    "s2id": "2833716cabbd7c709f4b266832b8b3fa3e37d2c6",
    "abstract": "Context modeling is critical for remote sensing image dense prediction tasks. Nowadays, the growing size of very-high-resolution (VHR) remote sensing images poses challenges in effectively modeling context. While transformer-based models possess global modeling capabilities, they encounter computational challenges when applied to large VHR images due to their quadratic complexity. The conventional practice of cropping large images into smaller patches results in a notable loss of contextual information. To address these issues, we propose the Remote Sensing Mamba (RSM) for dense prediction tasks in large VHR remote sensing images. RSM is specifically designed to capture the global context of remote sensing images with linear complexity, facilitating the effective processing of large VHR images. Considering that the land covers in remote sensing images are distributed in arbitrary spatial directions due to characteristics of remote sensing over-head imaging, the RSM incorporates an omnidirectional selective scan module to globally model the context of images in multiple directions, capturing large spatial features from various directions. Extensive experiments on semantic segmentation and change detection tasks across various land covers demonstrate the effectiveness of the proposed RSM. We designed simple yet effective models based on RSM, achieving state-of-the-art performance on dense prediction tasks in VHR remote sensing images without fancy training strategies. Leveraging the linear complexity and global modeling capabilities, RSM achieves better efficiency and accuracy than transformer-based models on large remote sensing images. Interestingly, we also demonstrated that our model generally performs better with a larger image size on dense prediction tasks. Our code is available at https://github.com/walking-shadow/Official_Remote_Sensing_Mamba.",
    "authors": [
        "Sijie Zhao",
        "Hao Chen",
        "Xue-liang Zhang",
        "P. Xiao",
        "Lei Bai",
        "Wanli Ouyang"
    ],
    "venue": "IEEE Transactions on Geoscience and Remote Sensing",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The Remote Sensing Mamba (RSM) is specifically designed to capture the global context of remote sensing images with linear complexity, facilitating the effective processing of large VHR images."
    },
    "citationCount": 15,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}