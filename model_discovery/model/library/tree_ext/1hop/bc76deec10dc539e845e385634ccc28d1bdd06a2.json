{
    "acronym": "bc76deec10dc539e845e385634ccc28d1bdd06a2",
    "title": "Measuring Adversarial Datasets",
    "seed_ids": [
        "bert",
        "92e121c6e114fe3cfb89370df03847c66a9b4e28",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "bc76deec10dc539e845e385634ccc28d1bdd06a2",
    "abstract": "In the era of widespread public use of AI systems across various domains, ensuring adversarial robustness has become increasingly vital to maintain safety and prevent undesirable errors. Researchers have curated various adversarial datasets (through perturbations) for capturing model deficiencies that cannot be revealed in standard benchmark datasets. However, little is known about how these adversarial examples differ from the original data points, and there is still no methodology to measure the intended and unintended consequences of those adversarial transformations. In this research, we conducted a systematic survey of existing quantifiable metrics that describe text instances in NLP tasks, among dimensions of difficulty, diversity, and disagreement. We selected several current adversarial effect datasets and compared the distributions between the original and their adversarial counterparts. The results provide valuable insights into what makes these datasets more challenging from a metrics perspective and whether they align with underlying assumptions.",
    "authors": [
        "Yuanchen Bai",
        "Raoyi Huang",
        "Vijay Viswanathan",
        "Tzu-Sheng Kuo",
        "Tongshuang Wu"
    ],
    "venue": "ARTOFSAFETY",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A systematic survey of existing quantifiable metrics that describe text instances in NLP tasks, among dimensions of difficulty, diversity, and disagreement, provides valuable insights into what makes these datasets more challenging from a metrics perspective and whether they align with underlying assumptions."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}