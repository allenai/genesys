{
    "acronym": "aade40af0d85b0b4fe15c97f6222d5c2e4d6d9b3",
    "title": "Graph of Thoughts: Solving Elaborate Problems with Large Language Models",
    "seed_ids": [
        "gpt",
        "5f19ae1135a9500940978104ec15a5b8751bc7d2",
        "92173d081b15824d22a9ef070e118744ceee8052",
        "3d473cbb7a377cf960abff31748a1a39bb6c7d7c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "aade40af0d85b0b4fe15c97f6222d5c2e4d6d9b3",
    "abstract": "We introduce Graph of Thoughts (GoT): a framework that\nadvances prompting capabilities in large language models\n(LLMs) beyond those offered by paradigms such as \nChain-of-Thought or Tree of Thoughts (ToT). The key idea and \nprimary advantage of GoT is the ability to model the information \ngenerated by an LLM as an arbitrary graph, where units of \ninformation (\"LLM thoughts\") are vertices, and edges correspond\nto dependencies between these vertices. This approach enables \ncombining arbitrary LLM thoughts into synergistic outcomes, \ndistilling the essence of whole networks of thoughts,\nor enhancing thoughts using feedback loops. We illustrate\nthat GoT offers advantages over state of the art on different\ntasks, for example increasing the quality of sorting by 62%\nover ToT, while simultaneously reducing costs by >31%.\nWe ensure that GoT is extensible with new thought \ntransformations and thus can be used to spearhead new prompting\nschemes. This work brings the LLM reasoning closer to human \nthinking or brain mechanisms such as recurrence, both\nof which form complex networks",
    "authors": [
        "Maciej Besta",
        "Nils Blach",
        "Ale\u0161 Kub\u00ed\u010dek",
        "Robert Gerstenberger",
        "Lukas Gianinazzi",
        "Joanna Gajda",
        "Tomasz Lehmann",
        "Michal Podstawski",
        "H. Niewiadomski",
        "P. Nyczyk",
        "Torsten Hoefler"
    ],
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Graph of Thoughts is introduced: a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-of-Thought or Tree of Thoughts, and is ensured that GoT is extensible with new thought transformations and thus can be used to spearhead new prompting schemes."
    },
    "citationCount": 270,
    "influentialCitationCount": 15,
    "code": null,
    "description": null,
    "url": null
}