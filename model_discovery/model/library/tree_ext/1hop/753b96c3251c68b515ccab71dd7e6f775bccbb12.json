{
    "acronym": "753b96c3251c68b515ccab71dd7e6f775bccbb12",
    "title": "Language Driven Image Editing via Transformers",
    "seed_ids": [
        "gpt2",
        "c57293882b2561e1ba03017902df9fc2f289dea2",
        "2cd605106b88c85d7d8b865b1ef0f8c8293debf1",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "753b96c3251c68b515ccab71dd7e6f775bccbb12",
    "abstract": "With the emergence of specifically tailored neural architectures that cope with both modalities, cross-modal language and image processing has attracted increasing attention. A major motivation has been the search for a quantum leap in language understanding supported by visual grounding, which has been oriented mostly to solve tasks where language descriptions of images are to be provided, and vice-versa, where images are to be generated on the basis of keywords. Adopting a distinct angle of inquiry, this paper addresses rather the cross-modal challenge of language driven image design, focusing on the task of editing an image on the basis of language instructions to modify it. And adopting as well a distinct research path, which dispenses with specifically tailored architectures, the approach proposed here resorts rather to a general purpose, suitably instantiated neural architecture of the Transformer class. Experimentation with this approach delivered very encouraging results, empirically demonstrating that this is an effective methodology for language driven image design and the basis for further advances in cross-modal processing and its applications with affordable compute and data.",
    "authors": [
        "Rodrigo Santos",
        "A. Branco",
        "J. Silva"
    ],
    "venue": "IEEE International Conference on Tools with Artificial Intelligence",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper addresses rather the cross-modal challenge of language driven image design, focusing on the task of editing an image on the basis of language instructions to modify it, and resorts rather to a general purpose, suitably instantiated neural architecture of the Transformer class."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}