{
    "acronym": "27a7c915481ca56fbff1a7207195b8c3d2e73b5e",
    "title": "Calvados at MEDIQA-Chat 2023: Improving Clinical Note Generation with Multi-Task Instruction Finetuning",
    "seed_ids": [
        "longt5",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "492a655a67e6ec7423a968cedb70eec0cdbc8e98",
        "3dfb1f50f2a34a699c339dabaa6f9b3a977973de",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481"
    ],
    "s2id": "27a7c915481ca56fbff1a7207195b8c3d2e73b5e",
    "abstract": "This paper presents our system for the MEDIQA-Chat 2023 shared task on medical conversation summarization. Our approach involves finetuning a LongT5 model on multiple tasks simultaneously, which we demonstrate improves the model\u2019s overall performance while reducing the number of factual errors and hallucinations in the generated summary. Furthermore, we investigated the effect of augmenting the data with in-text annotations from a clinical named entity recognition model, finding that this approach decreased summarization quality. Lastly, we explore using different text generation strategies for medical note generation based on the length of the note. Our findings suggest that the application of our proposed approach can be beneficial for improving the accuracy and effectiveness of medical conversation summarization.",
    "authors": [
        "Kirill Milintsevich",
        "Navneet Agarwal"
    ],
    "venue": "Clinical Natural Language Processing Workshop",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The proposed approach involves finetuning a LongT5 model on multiple tasks simultaneously, which it is demonstrated improves the model\u2019s overall performance while reducing the number of factual errors and hallucinations in the generated summary."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}