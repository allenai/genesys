{
    "acronym": "31b27d90c2d5732386dd3a46a7d8336c0555c6fe",
    "title": "Deep Latent State Space Models for Time-Series Generation",
    "seed_ids": [
        "s4",
        "hippo",
        "ca444821352a4bd91884413d8070446e2960715a",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "11df9ac34655f4ad746e4db39c49f928f0cbd201",
        "1d5c8c6e5a774d2fef8d92bd28670a6345a97f7a"
    ],
    "s2id": "31b27d90c2d5732386dd3a46a7d8336c0555c6fe",
    "abstract": "Methods based on ordinary differential equations (ODEs) are widely used to build generative models of time-series. In addition to high computational overhead due to explicitly computing hidden states recurrence, existing ODE-based models fall short in learning sequence data with sharp transitions - common in many real-world systems - due to numerical challenges during optimization. In this work, we propose LS4, a generative model for sequences with latent variables evolving according to a state space ODE to increase modeling capacity. Inspired by recent deep state space models (S4), we achieve speedups by leveraging a convolutional representation of LS4 which bypasses the explicit evaluation of hidden states. We show that LS4 significantly outperforms previous continuous-time generative models in terms of marginal distribution, classification, and prediction scores on real-world datasets in the Monash Forecasting Repository, and is capable of modeling highly stochastic data with sharp temporal transitions. LS4 sets state-of-the-art for continuous-time latent generative models, with significant improvement of mean squared error and tighter variational lower bounds on irregularly-sampled datasets, while also being x100 faster than other baselines on long sequences.",
    "authors": [
        "Linqi Zhou",
        "Michael Poli",
        "Winnie Xu",
        "Stefano Massaroli",
        "Stefano Ermon"
    ],
    "venue": "International Conference on Machine Learning",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "LS4 is proposed, a generative model for sequences with latent variables evolving according to a state space ODE to increase modeling capacity, and sets state-of-the-art for continuous-time latent generative models, with significant improvement of mean squared error and tighter variational lower bounds on irregularly-sampled datasets."
    },
    "citationCount": 20,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}