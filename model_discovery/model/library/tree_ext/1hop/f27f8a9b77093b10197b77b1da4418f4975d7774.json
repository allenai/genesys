{
    "acronym": "f27f8a9b77093b10197b77b1da4418f4975d7774",
    "title": "When can I Speak? Predicting initiation points for spoken dialogue agents",
    "seed_ids": [
        "gpt2",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "f27f8a9b77093b10197b77b1da4418f4975d7774",
    "abstract": "Current spoken dialogue systems initiate their turns after a long period of silence (700-1000ms), which leads to little real-time feedback, sluggish responses, and an overall stilted conversational flow. Humans typically respond within 200ms and successfully predicting initiation points in advance would allow spoken dialogue agents to do the same. In this work, we predict the lead-time to initiation using prosodic features from a pre-trained speech representation model (wav2vec 1.0) operating on user audio and word features from a pre-trained language model (GPT-2) operating on incremental transcriptions. To evaluate errors, we propose two metrics w.r.t. predicted and true lead times. We train and evaluate the models on the Switchboard Corpus and find that our method outperforms features from prior work on both metrics and vastly outperforms the common approach of waiting for 700ms of silence.",
    "authors": [
        "Siyan Li",
        "Ashwin Paranjape",
        "Christopher D. Manning"
    ],
    "venue": "SIGDIAL Conferences",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work predicts the lead-time to initiation using prosodic features from a pre-trained speech representation model (wav2vec 1.0) operating on user audio and word features from an GPT-2 model operating on incremental transcriptions and finds that the method outperforms features from prior work on both metrics and vastly outperforms the common approach of waiting for 700ms of silence."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}