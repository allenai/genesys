{
    "acronym": "68cf0b9021f904a765e760291d0c9a509aab0067",
    "title": "A Multi-Document Coverage Reward for RELAXed Multi-Document Summarization",
    "seed_ids": [
        "longformer",
        "42e41ab2211b8ba78e36326ea21e05bd25d92c42",
        "6e6a2fe517b33e1f29d761ae31fb37ddccb9a213",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "7cc730da554003dda77796d2cb4f06da5dfd5592"
    ],
    "s2id": "68cf0b9021f904a765e760291d0c9a509aab0067",
    "abstract": "Multi-document summarization (MDS) has made significant progress in recent years, in part facilitated by the availability of new, dedicated datasets and capacious language models. However, a standing limitation of these models is that they are trained against limited references and with plain maximum-likelihood objectives. As for many other generative tasks, reinforcement learning (RL) offers the potential to improve the training of MDS models; yet, it requires a carefully-designed reward that can ensure appropriate leverage of both the reference summaries and the input documents. For this reason, in this paper we propose fine-tuning an MDS baseline with a reward that balances a reference-based metric such as ROUGE with coverage of the input documents. To implement the approach, we utilize RELAX (Grathwohl et al., 2018), a contemporary gradient estimator which is both low-variance and unbiased, and we fine-tune the baseline in a few-shot style for both stability and computational efficiency. Experimental results over the Multi-News and WCEP MDS datasets show significant improvements of up to +0.95 pp average ROUGE score and +3.17 pp METEOR score over the baseline, and competitive results with the literature. In addition, they show that the coverage of the input documents is increased, and evenly across all documents.",
    "authors": [
        "Jacob Parnell",
        "Inigo Jauregi Unanue",
        "M. Piccardi"
    ],
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper proposes fine-tuning an MDS baseline with a reward that balances a reference-based metric such as ROUGE with coverage of the input documents, and implements RELAX, a contemporary gradient estimator which is both low-variance and unbiased."
    },
    "citationCount": 11,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}