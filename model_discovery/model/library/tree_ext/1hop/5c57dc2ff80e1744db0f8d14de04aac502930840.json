{
    "acronym": "5c57dc2ff80e1744db0f8d14de04aac502930840",
    "title": "SpanDrop: Simple and Effective Counterfactual Learning for Long Sequences",
    "seed_ids": [
        "longformer",
        "9dc624d7258d1a56117ca720aea953ce46b66b21",
        "9ed25f101f19ea735ca300848948ed64064b97ca",
        "35a9749df07a2ab97c51af4d260b095b00da7676",
        "7e9ff94476f41041c75e253e84f487db00e9c861",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
        "6f68e1bb253925d8431588555d3010419f322e04",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "f51497f463566581874c941353dd9d80069c5b77",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "5c57dc2ff80e1744db0f8d14de04aac502930840",
    "abstract": "Distilling supervision signal from a long sequence to make predictions is a challenging task in machine learning, especially when not all elements in the input sequence contribute equally to the desired output. In this paper, we propose SpanDrop, a simple and effective data augmentation technique that helps models identify the true supervision signal in a long sequence with very few examples. By directly manipulating the input sequence, SpanDrop randomly ablates parts of the sequence at a time and ask the model to perform the same task to emulate counterfactual learning and achieve input attribution. Based on theoretical analysis of its properties, we also propose a variant of SpanDrop based on the beta-Bernoulli distribution, which yields diverse augmented sequences while providing a learning objective that is more consistent with the original dataset. We demonstrate the effectiveness of SpanDrop on a set of carefully designed toy tasks, as well as various natural language processing tasks that require reasoning over long sequences to arrive at the correct answer, and show that it helps models improve performance both when data is scarce and abundant.",
    "authors": [
        "Peng Qi",
        "Guangtao Wang",
        "Jing Huang"
    ],
    "venue": "arXiv.org",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The effectiveness of SpanDrop is demonstrated on a set of carefully designed toy tasks, as well as various natural language processing tasks that require reasoning over long sequences to arrive at the correct answer, and it is shown that it helps models improve performance both when data is scarce and abundant."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}