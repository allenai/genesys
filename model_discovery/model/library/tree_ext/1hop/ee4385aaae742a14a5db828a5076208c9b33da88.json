{
    "acronym": "ee4385aaae742a14a5db828a5076208c9b33da88",
    "title": "Learning Event Graph Knowledge for Abductive Reasoning",
    "seed_ids": [
        "gpt",
        "4d16457cded23bce6eaa91cd17aefd22af2279f0"
    ],
    "s2id": "ee4385aaae742a14a5db828a5076208c9b33da88",
    "abstract": "Abductive reasoning aims at inferring the most plausible explanation for observed events, which would play critical roles in various NLP applications, such as reading comprehension and question answering. To facilitate this task, a narrative text based abductive reasoning task \\alphaNLI is proposed, together with explorations about building reasoning framework using pretrained language models. However, abundant event commonsense knowledge is not well exploited for this task. To fill this gap, we propose a variational autoencoder based model ege-RoBERTa, which employs a latent variable to capture the necessary commonsense knowledge from event graph for guiding the abductive reasoning task. Experimental results show that through learning the external event graph knowledge, our approach outperforms the baseline methods on the \\alphaNLI task.",
    "authors": [
        "Li Du",
        "Xiao Ding",
        "Ting Liu",
        "Bing Qin"
    ],
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A variational autoencoder based model ege-RoBERTa is proposed, which employs a latent variable to capture the necessary commonsense knowledge from event graph for guiding the abductive reasoning task."
    },
    "citationCount": 20,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}