{
    "acronym": "8155dad3723f4e5946561f8de6d37368b9b187e4",
    "title": "SC-Tune: Unleashing Self-Consistent Referential Comprehension in Large Vision Language Models",
    "seed_ids": [
        "gpt3",
        "5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0",
        "42a30dc5470f54ec249f25d3c31e05d7c376c8e3",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c"
    ],
    "s2id": "8155dad3723f4e5946561f8de6d37368b9b187e4",
    "abstract": "Recent trends in Large Vision Language Models (LVLMs) research have been increasingly focusing on advancing beyond general image understanding towards more nuanced, object-level referential comprehension. In this paper, we present and delve into the self-consistency capability of LVLMs, a crucial aspect that reflects the models' ability to both generate informative captions for specific objects and subsequently utilize these captions to accurately re-identify the objects in a closed-loop process. This capability significantly mirrors the precision and reliability of fine-grained visual-language understanding. Our findings reveal that the self-consistency level of existing LVLMs falls short of expectations, posing limitations on their practical applicability and potential. To address this gap, we introduce a novel fine-tuning paradigm named Self-Consistency Tuning (SC-Tune). It features the synergistic learning of a cyclic describer-locator system. This paradigm is not only data-efficient but also exhibits generalizability across multiple LVLMs. Through extensive experiments, we demonstrate that SC-Tune significantly elevates performance across a spectrum of object-level vision-language benchmarks and maintains competitive or improved performance on image-level vision-language benchmarks. Both our model and code will be publicly available at https://github.com/ivattyue/SC-Tune.",
    "authors": [
        "Tongtian Yue",
        "Jie Cheng",
        "Longteng Guo",
        "Xingyuan Dai",
        "Zijia Zhao",
        "Xingjian He",
        "Gang Xiong",
        "Yisheng Lv",
        "Jing Liu"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper introduces a novel fine-tuning paradigm named SC-Tune, which features the synergistic learning of a cyclic describer-locator system and significantly elevates performance across a spectrum of object-level vision-language benchmarks and maintains competitive or improved performance on image-level vision-language benchmarks."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}