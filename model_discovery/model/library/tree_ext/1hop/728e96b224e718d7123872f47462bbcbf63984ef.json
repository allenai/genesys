{
    "acronym": "728e96b224e718d7123872f47462bbcbf63984ef",
    "title": "Leveraging Prototypical Representations for Mitigating Social Bias without Demographic Information",
    "seed_ids": [
        "bert"
    ],
    "s2id": "728e96b224e718d7123872f47462bbcbf63984ef",
    "abstract": "Mitigating social biases typically requires identifying the social groups associated with each data sample. In this paper, we present DAFair, a novel approach to address social bias in language models. Unlike traditional methods that rely on explicit demographic labels, our approach does not require any such information. Instead, we leverage predefined prototypical demographic texts and incorporate a regularization term during the fine-tuning process to mitigate bias in the model\u2019s representations. Our empirical results across two tasks and two models demonstrate the effectiveness of our method compared to previous approaches that do not rely on labeled data. Moreover, with limited demographic-annotated data, our approach outperforms common debiasing approaches.",
    "authors": [
        "Shadi Iskander",
        "Kira Radinsky",
        "Yonatan Belinkov"
    ],
    "venue": "North American Chapter of the Association for Computational Linguistics",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "DAFair is presented, a novel approach to address social bias in language models that leverage predefined prototypical demographic texts and incorporate a regularization term during the fine-tuning process to mitigate bias in the model\u2019s representations."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}