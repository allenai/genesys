{
    "acronym": "d2a3064a61d495f45256bd976b7f05564396b23a",
    "title": "Fine-Tuning Pre-trained Language Models to Detect In-Game Trash Talks",
    "seed_ids": [
        "bert",
        "e083905b0fc1cf82937630cb8d69093b39e4cf98",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "d2a3064a61d495f45256bd976b7f05564396b23a",
    "abstract": "Common problems in playing online mobile and computer games were related to toxic behavior and abusive communication among players. Based on different reports and studies, the study also discusses the impact of online hate speech and toxicity on players' in-game performance and overall well-being. This study investigates the capability of pre-trained language models to classify or detect trash talk or toxic in-game messages. The study employs and evaluates the performance of pre-trained BERT and GPT language models in detecting toxicity within in-game chats. Using publicly available APIs, in-game chat data from DOTA 2 game matches were collected, processed, reviewed, and labeled as non-toxic, mild (toxicity), and toxic. The study was able to collect around two thousand in-game chats to train and test BERT (Base-uncased), BERT (Large-uncased), and GPT-3 models. Based on the three models\u2019 state-of-the-art performance, this study concludes pre-trained language models\u2019 promising potential for addressing online hate speech and in-game insulting trash talk.",
    "authors": [
        "Daniel Fesalbon",
        "Arvin De La Cruz",
        "Marvin Mallari",
        "Nelson Rodelas"
    ],
    "venue": "International Journal For Multidisciplinary Research",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Pre-trained language models\u2019 promising potential for addressing online hate speech and in-game insulting trash talk is concluded."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}