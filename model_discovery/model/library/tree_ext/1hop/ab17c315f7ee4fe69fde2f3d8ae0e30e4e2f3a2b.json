{
    "acronym": "ab17c315f7ee4fe69fde2f3d8ae0e30e4e2f3a2b",
    "title": "Iterative Hierarchical Attention for Answering Complex Questions over Long Documents",
    "seed_ids": [
        "etc",
        "395aae6e7a79e5760457ca38e868acc970016230",
        "4e3935ef7da6bcbb202ec7f8b285c313cadcd044",
        "d27669c82faf78ea08cceaa0a171b540cccc304d",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "01b15017ac59b8d6f2ce3598c4a7d6358c211426",
        "203b543bfa1e564bb80ff4229b43174d7c71b0c0"
    ],
    "s2id": "ab17c315f7ee4fe69fde2f3d8ae0e30e4e2f3a2b",
    "abstract": "We propose a new model, DocHopper, that iteratively attends to different parts of long, hierarchically structured documents to answer complex questions. Similar to multi-hop question-answering (QA) systems, at each step, DocHopper uses a query $q$ to attend to information from a document, combines this ``retrieved'' information with $q$ to produce the next query. However, in contrast to most previous multi-hop QA systems, DocHopper is able to ``retrieve'' either short passages or long sections of the document, thus emulating a multi-step process of ``navigating'' through a long document to answer a question. To enable this novel behavior, DocHopper does not combine document information with $q$ by concatenating text to the text of $q$, but by combining a compact neural representation of $q$ with a compact neural representation of a hierarchical part of the document, which can potentially be quite large. We experiment with DocHopper on four different QA tasks that require reading long and complex documents to answer multi-hop questions, and show that DocHopper achieves state-of-the-art results on three of the datasets. Additionally, DocHopper is efficient at inference time, being 3--10 times faster than the baselines.",
    "authors": [
        "Haitian Sun",
        "William W. Cohen",
        "R. Salakhutdinov"
    ],
    "venue": "",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A new model, DocHopper, that iteratively attends to different parts of long, hierarchically structured documents to answer complex questions, and is efficient at inference time, being 3--10 times faster than the baselines."
    },
    "citationCount": 10,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}