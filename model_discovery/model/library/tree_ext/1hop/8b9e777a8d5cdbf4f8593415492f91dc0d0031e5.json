{
    "acronym": "8b9e777a8d5cdbf4f8593415492f91dc0d0031e5",
    "title": "UNcommonsense Reasoning: Abductive Reasoning about Uncommon Situations",
    "seed_ids": [
        "gpt3",
        "94e5ca13e8c884509ccad233c77979923b677a3e",
        "c21a4d70d83e0f6eb2a9e1c41d034842dd561e47",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "8b9e777a8d5cdbf4f8593415492f91dc0d0031e5",
    "abstract": "Language technologies that accurately model the dynamics of events must perform commonsense reasoning. Existing work evaluating commonsense reasoning focuses on making inferences about common, everyday situations. To instead investigate the ability to model unusual, unexpected, and unlikely situations, we explore the task of uncommonsense abductive reasoning. Given a piece of context with an unexpected outcome, this task requires reasoning abductively to generate an explanation that makes the unexpected outcome more likely in the context. To this end, we curate and release a new English language corpus called UNcommonsense. We characterize the performance differences between human explainers and the best-performing large language models, finding that model-enhanced human-written explanations achieve the highest quality by trading off between specificity and diversity. Finally, we experiment with several imitation learning algorithms to train open and accessible language models on this task. When compared with the vanilla supervised fine-tuning approach, these methods consistently reduce lose rates on both common and uncommonsense abductive reasoning judged by human evaluators.",
    "authors": [
        "Wenting Zhao",
        "Justin T Chiu",
        "Jena D. Hwang",
        "Faeze Brahman",
        "Jack Hessel",
        "Sanjiban Choudhury",
        "Yejin Choi",
        "Xiang Lorraine Li",
        "Alane Suhr"
    ],
    "venue": "North American Chapter of the Association for Computational Linguistics",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work curates and releases a new English language corpus called UNcommonsense, and characterize the performance differences between human explainers and the best-performing large language models, finding that model-enhanced human-written explanations achieve the highest quality by trading off between specificity and diversity."
    },
    "citationCount": 3,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}