{
    "acronym": "28f9a6c3ac0330bb9157613ba89b9070f53eac4b",
    "title": "Do Nuclear Submarines Have Nuclear Captains? A Challenge Dataset for Commonsense Reasoning over Adjectives and Objects",
    "seed_ids": [
        "gpt"
    ],
    "s2id": "28f9a6c3ac0330bb9157613ba89b9070f53eac4b",
    "abstract": "How do adjectives project from a noun to its parts? If a motorcycle is red, are its wheels red? Is a nuclear submarine\u2019s captain nuclear? These questions are easy for humans to judge using our commonsense understanding of the world, but are difficult for computers. To attack this challenge, we crowdsource a set of human judgments that answer the English-language question \u201cGiven a whole described by an adjective, does the adjective also describe a given part?\u201d We build strong baselines for this task with a classification approach. Our findings indicate that, despite the recent successes of large language models on tasks aimed to assess commonsense knowledge, these models do not greatly outperform simple word-level models based on pre-trained word embeddings. This provides evidence that the amount of commonsense knowledge encoded in these language models does not extend far beyond that already baked into the word embeddings. Our dataset will serve as a useful testbed for future research in commonsense reasoning, especially as it relates to adjectives and objects",
    "authors": [
        "J. Mullenbach",
        "Jonathan Gordon",
        "Nanyun Peng",
        "Jonathan May"
    ],
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2019,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The findings indicate that, despite the recent successes of large language models on tasks aimed to assess commonsense knowledge, these models do not greatly outperform simple word-level models based on pre-trained word embeddings."
    },
    "citationCount": 9,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}