{
    "acronym": "e85415071e6ffffcf2f620ba3d4a2258710d5ecc",
    "title": "ConvFormer: Closing the Gap Between CNN and Vision Transformers",
    "seed_ids": [
        "metaformer",
        "gmlp",
        "9b6af0e358e76d22f209c75b1702c3e6ea7815b1",
        "6b6ffb94626e672caffafc77097491d9ee7a8682",
        "837ac4ed6825502f0460caec45e12e734c85b113",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7"
    ],
    "s2id": "e85415071e6ffffcf2f620ba3d4a2258710d5ecc",
    "abstract": ": Vision transformers have shown excellent performance in computer vision tasks. However, the computation cost of their (local) self-attention mechanism is expensive. Comparatively, CNN is more e\ufb03cient with built-in inductive bias. Recent works show that CNN is promising to compete with vision transformers by learning their architecture design and training protocols. Nevertheless, existing methods either ignore multi-level features or lack dynamic prosperity, leading to sub-optimal performance. In this paper, we propose a novel attention mechanism named MCA, which captures di\ufb00erent patterns of input images by multiple kernel sizes and enables input-adaptive weights with a gating mechanism. Based on MCA, we present a neural network named ConvFormer. ConvFormer adopts the general architecture of vision transformers, while replacing the (local) self-attention mechanism with our proposed MCA. Extensive experimental results demonstrated that ConvFormer achieves state-of-the-art performance on ImageNet classi\ufb01cation, which outperforms similar-sized vision transformers(ViTs) and convolutional neural networks (CNNs). Moreover, for object detection on COCO and semantic segmentation tasks on ADE20K, ConvFormer also shows excellent performance compared with recently advanced methods. Code and models will be available.",
    "authors": [
        "Zimian Wei",
        "H. Pan",
        "Xin-Yi Niu",
        "Dongsheng Li"
    ],
    "venue": "arXiv.org",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel attention mechanism named MCA is proposed, which captures di\ufb00erent patterns of input images by multiple kernel sizes and enables input-adaptive weights with a gating mechanism and is presented as a neural network named ConvFormer, which adopts the general architecture of vision transformers, while replacing the (local) self-attention mechanism with MCA."
    },
    "citationCount": 10,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}