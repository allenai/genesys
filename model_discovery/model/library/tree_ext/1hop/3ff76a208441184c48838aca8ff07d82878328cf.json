{
    "acronym": "3ff76a208441184c48838aca8ff07d82878328cf",
    "title": "Training-Free Acceleration of ViTs with Delayed Spatial Merging",
    "seed_ids": [
        "streamingllm",
        "fdc53c2c10742464087c0525f77e32604827a21d",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7"
    ],
    "s2id": "3ff76a208441184c48838aca8ff07d82878328cf",
    "abstract": "Token merging has emerged as a new paradigm that can accelerate the inference of Vision Transformers (ViTs) without any retraining or fine-tuning. To push the frontier of training-free acceleration in ViTs, we improve token merging by adding the perspectives of 1) activation outliers and 2) hierarchical representations. Through a careful analysis of the attention behavior in ViTs, we characterize a delayed onset of the convergent attention phenomenon, which makes token merging undesirable in the bottom blocks of ViTs. Moreover, we augment token merging with a hierarchical processing scheme to capture multi-scale redundancy between visual tokens. Combining these two insights, we build a unified inference framework called DSM: Delayed Spatial Merging. We extensively evaluate DSM on various ViT model scales (Tiny to Huge) and tasks (ImageNet-1k and transfer learning), achieving up to 1.8$\\times$ FLOP reduction and 1.6$\\times$ throughput speedup at a negligible loss while being two orders of magnitude faster than existing methods.",
    "authors": [
        "J. Heo",
        "Seyedarmin Azizi",
        "A. Fayyazi",
        "M. Pedram"
    ],
    "venue": "",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A careful analysis of the attention behavior in ViTs characterize a delayed onset of the convergent attention phenomenon, which makes token merging undesirable in the bottom blocks of ViTs, and builds a unified inference framework called DSM: Delayed Spatial Merging."
    },
    "citationCount": 4,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}