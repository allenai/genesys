{
    "acronym": "2e9aad8be8f2bbfe34664a22c2dd1dcdea25279e",
    "title": "A MultiModal Social Robot Toward Personalized Emotion Interaction",
    "seed_ids": [
        "gpt",
        "19f1846b59cedf805b281a26ef71899477b8135b",
        "7a15950dc71079285a4eaf195de5aadd87c41b40"
    ],
    "s2id": "2e9aad8be8f2bbfe34664a22c2dd1dcdea25279e",
    "abstract": "Human emotions are expressed through multiple modalities, including verbal and non-verbal information. Moreover, the affective states of human users can be the indicator for the level of engagement and successful interaction, suitable for the robot to use as a rewarding factor to optimize robotic behaviors through interaction. This study demonstrates a multimodal human-robot interaction (HRI) framework with reinforcement learning to enhance the robotic interaction policy and personalize emotional interaction for a human user. The goal is to apply this framework in social scenarios that can let the robots generate a more natural and engaging HRI framework.",
    "authors": [
        "Baijun Xie",
        "C. Park"
    ],
    "venue": "arXiv.org",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A multimodal human-robot interaction (HRI) framework with reinforcement learning is demonstrated to enhance the robotic interaction policy and personalize emotional interaction for a human user."
    },
    "citationCount": 4,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}