{
    "acronym": "13579f2d5d522779caeb4aa916fb9ab283f13670",
    "title": "SPRING: Situated Conversation Agent Pretrained with Multimodal Questions from Incremental Layout Graph",
    "seed_ids": [
        "gpt2",
        "553703db1b3e54e957ed91bad952ff3ba4f59bd5",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "13579f2d5d522779caeb4aa916fb9ab283f13670",
    "abstract": "Existing multimodal conversation agents have shown impressive abilities to locate absolute positions or retrieve attributes in simple scenarios, but they fail to perform well when complex relative positions and information alignments are involved, which poses a bottleneck in response quality. In this paper, we propose a Situated Conversation Agent Pretrained with Multimodal Questions from Incremental Layout Graph (SPRING) with abilities of reasoning multi-hops spatial relations and connecting them with visual attributes in crowded situated scenarios. Specifically, we design two types of Multimodal Question Answering (MQA) tasks to pretrain the agent. All QA pairs utilized during pretraining are generated from novel Increment Layout Graphs (ILG). QA pair difficulty labels automatically annotated by ILG are used to promote MQA-based Curriculum Learning. Experimental results verify the SPRING's effectiveness, showing that it significantly outperforms state-of-the-art approaches on both SIMMC 1.0 and SIMMC 2.0 datasets. We release our code and data at https://github.com/LYX0501/SPRING.",
    "authors": [
        "Yuxing Long",
        "Binyuan Hui",
        "Fulong Ye",
        "Yanyang Li",
        "Zhuoxin Han",
        "Caixia Yuan",
        "Yongbin Li",
        "Xiaojie Wang"
    ],
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper proposes a Situated Conversation Agent Pretrained with Multimodal Questions from Incremental Layout Graph (SPRING), with abilities of reasoning multi-hops spatial relations and connecting them with visual attributes in crowded situated scenarios."
    },
    "citationCount": 5,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}