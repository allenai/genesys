{
    "acronym": "083742c2a60ddd3cabd81666f16c716f56ab5af5",
    "title": "VideoMambaPro: A Leap Forward for Mamba in Video Understanding",
    "seed_ids": [
        "transformer",
        "ba4c5a116d07b37dea1046b6d16a60cb2d01cd47",
        "3af7273d7ca20c0c63cbaa47e60b058840835052",
        "b24e899ec0f77eef2fc87a9b8e50516367aa1f97",
        "38c48a1cd296d16dc9c56717495d6e44cc354444",
        "240103933ffe3dac2179cc160a2bd91299357a53",
        "026b3396a63ed5772329708b7580d633bb86bec9",
        "573f30d20cf4aada21dba273f5d47a7af09cac45",
        "ac2e15fbfe3ea338725f5d33d17a5a687609c431",
        "eaef083b9d661f42cc0d89d9d8156218f33a91d9",
        "4990f7542f0600e0501a7e7a931b32eb7cb804d5",
        "0ff05c98be6015695871bd8216c35e572a9d2d95",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "2e644c67a697073d561da4f4dad35e5ad5316cfd",
        "5d032bd2632b6f5847767f39ce247098c6bbc563",
        "1a883522f3c0051d70be1f8cbdb8989a77395006"
    ],
    "s2id": "083742c2a60ddd3cabd81666f16c716f56ab5af5",
    "abstract": "Video understanding requires the extraction of rich spatio-temporal representations, which transformer models achieve through self-attention. Unfortunately, self-attention poses a computational burden. In NLP, Mamba has surfaced as an efficient alternative for transformers. However, Mamba's successes do not trivially extend to computer vision tasks, including those in video analysis. In this paper, we theoretically analyze the differences between self-attention and Mamba. We identify two limitations in Mamba's token processing: historical decay and element contradiction. We propose VideoMambaPro (VMP) that solves the identified limitations by adding masked backward computation and elemental residual connections to a VideoMamba backbone. VideoMambaPro shows state-of-the-art video action recognition performance compared to transformer models, and surpasses VideoMamba by clear margins: 7.9% and 8.1% top-1 on Kinetics-400 and Something-Something V2, respectively. Our VideoMambaPro-M model achieves 91.9% top-1 on Kinetics-400, only 0.2% below InternVideo2-6B but with only 1.2% of its parameters. The combination of high performance and efficiency makes VideoMambaPro an interesting alternative for transformer models.",
    "authors": [
        "Hui Lu",
        "A. A. Salah",
        "Ronald Poppe"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper theoretically analyze the differences between self-attention and Mamba, and proposes VideoMambaPro (VMP) that solves the identified limitations by adding masked backward computation and elemental residual connections to a VideoMamba backbone."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}