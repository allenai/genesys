{
    "acronym": "598a297ac28e323db917ffb19e5481209e588430",
    "title": "Nexus at ArAIEval Shared Task: Fine-Tuning Arabic Language Models for Propaganda and Disinformation Detection",
    "seed_ids": [
        "bert"
    ],
    "s2id": "598a297ac28e323db917ffb19e5481209e588430",
    "abstract": "The spread of disinformation and propagandistic content poses a threat to societal harmony, undermining informed decision-making and trust in reliable sources. Online platforms often serve as breeding grounds for such content, and malicious actors exploit the vulnerabilities of audiences to shape public opinion. Although there have been research efforts aimed at the automatic identification of disinformation and propaganda in social media content, there remain challenges in terms of performance. The ArAIEval shared task aims to further research on these particular issues within the context of the Arabic language. In this paper, we discuss our participation in these shared tasks. We competed in subtasks 1A and 2A, where our submitted system secured positions 9th and 10th, respectively. Our experiments consist of fine-tuning transformer models and using zero- and few-shot learning with GPT-4.",
    "authors": [
        "Yunze Xiao",
        "Firoj Alam"
    ],
    "venue": "ARABICNLP",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper discusses theParticipation in the ArAIEval shared task, where the submitted system secured positions 9th and 10th, respectively, in subtasks 1A and 2A, and fine-tuning transformer models and using zero- and few-shot learning with GPT-4."
    },
    "citationCount": 3,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}