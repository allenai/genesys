{
    "acronym": "86cbbc77aa623e5647fec585d5efbaf8089d4c13",
    "title": "No-Skim: Towards Efficiency Robustness Evaluation on Skimming-based Language Models",
    "seed_ids": [
        "bert",
        "6da4b231148bf26677233d1f778d08a5d26f4313"
    ],
    "s2id": "86cbbc77aa623e5647fec585d5efbaf8089d4c13",
    "abstract": "To reduce the computation cost and the energy consumption in large language models (LLM), skimming-based acceleration dynamically drops unimportant tokens of the input sequence progressively along layers of the LLM while preserving the tokens of semantic importance. However, our work for the first time reveals the acceleration may be vulnerable to Denial-of-Service (DoS) attacks. In this paper, we propose No-Skim, a general framework to help the owners of skimming-based LLM to understand and measure the robustness of their acceleration scheme. Specifically, our framework searches minimal and unnoticeable perturbations at character-level and token-level to generate adversarial inputs that sufficiently increase the remaining token ratio, thus increasing the computation cost and energy consumption. We systematically evaluate the vulnerability of the skimming acceleration in various LLM architectures including BERT and RoBERTa on the GLUE benchmark. In the worst case, the perturbation found by No-Skim substantially increases the running cost of LLM by over 145% on average. Moreover, No-Skim extends the evaluation framework to various scenarios, making the evaluation conductible with different level of knowledge.",
    "authors": [
        "Sheng Zhang",
        "Mi Zhang",
        "Xudong Pan",
        "Min Yang"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "No-Skim is proposed, a general framework to help the owners of skimming-based LLM to understand and measure the robustness of their acceleration scheme, and extends the evaluation framework to various scenarios, making the evaluation conductible with different level of knowledge."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}