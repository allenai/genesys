{
    "acronym": "b6dd6426cbee2262a600104f63fbc5cb7512bec1",
    "title": "Corruption Is Not All Bad: Incorporating Discourse Structure Into Pre-Training via Corruption for Essay Scoring",
    "seed_ids": [
        "longformer",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "203b543bfa1e564bb80ff4229b43174d7c71b0c0"
    ],
    "s2id": "b6dd6426cbee2262a600104f63fbc5cb7512bec1",
    "abstract": "Existing approaches for automated essay scoring and document representation learning typically rely on discourse parsers to incorporate discourse structure into text representation. However, the performance of parsers is not always adequate, especially when they are used on noisy texts, such as student essays. In this paper, we propose an unsupervised pre-training approach to capture discourse structure of essays in terms of coherence and cohesion that does not require any discourse parser or annotation. We introduce several types of token, sentence and paragraph-level corruption techniques for our proposed pre-training approach and augment masked language modeling pre-training with our pre-training method to leverage both contextualized and discourse information. Our proposed unsupervised approach achieves a new state-of-the-art result on the task of essay Organization scoring.",
    "authors": [
        "Farjana Sultana Mim",
        "Naoya Inoue",
        "Paul Reisert",
        "Hiroki Ouchi",
        "Kentaro Inui"
    ],
    "venue": "IEEE/ACM Transactions on Audio Speech and Language Processing",
    "year": 2020,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper proposes an unsupervised pre-training approach to capture discourse structure of essays in terms of coherence and cohesion that does not require any discourse parser or annotation and introduces several types of token, sentence and paragraph-level corruption techniques."
    },
    "citationCount": 6,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}