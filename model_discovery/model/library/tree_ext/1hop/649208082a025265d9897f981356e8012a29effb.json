{
    "acronym": "649208082a025265d9897f981356e8012a29effb",
    "title": "EXPLAIN, EDIT, GENERATE: Rationale-Sensitive Counterfactual Data Augmentation for Multi-hop Fact Verification",
    "seed_ids": [
        "gpt2",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "649208082a025265d9897f981356e8012a29effb",
    "abstract": "Automatic multi-hop fact verification task has gained significant attention in recent years. Despite impressive results, these well-designed models perform poorly on out-of-domain data. One possible solution is to augment the training data with counterfactuals, which are generated by minimally altering the causal features of the original data. However, current counterfactual data augmentation techniques fail to handle multi-hop fact verification due to their incapability to preserve the complex logical relationships within multiple correlated texts. In this paper, we overcome this limitation by developing a rationale-sensitive method to generate linguistically diverse and label-flipping counterfactuals while preserving logical relationships. In specific, the diverse and fluent counterfactuals are generated via an Explain-Edit-Generate architecture. Moreover, the checking and filtering modules are proposed to regularize the counterfactual data with logical relations and flipped labels. Experimental results show that the proposed approach outperforms the SOTA baselines and can generate linguistically diverse counterfactual data without disrupting their logical relationships.",
    "authors": [
        "Yingjie Zhu",
        "Jiasheng Si",
        "Yibo Zhao",
        "Haiyang Zhu",
        "Deyu Zhou",
        "Yulan He"
    ],
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper develops a rationale-sensitive method to generate linguistically diverse and label-flipping counterfactuals while preserving logical relationships through an Explain-Edit-Generate architecture and shows that the proposed approach outperforms the SOTA baselines and can generate linguically diversecounterfactual data without disrupting their logical relationships."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}