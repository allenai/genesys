{
    "acronym": "df17247de8bf11c0c461bbfe11a4750c03d58ea5",
    "title": "SYMPLEX: Controllable Symbolic Music Generation using Simplex Diffusion with Vocabulary Priors",
    "seed_ids": [
        "ssdlm",
        "ee9ed60f41a0fe1c515c2e4d348ae4840f9f7e3e",
        "67cdecbcfed07b9a29d9e2a92da684604383afd7",
        "0b9770a377b3f96cef9f268cee1791d39a0d4893",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d"
    ],
    "s2id": "df17247de8bf11c0c461bbfe11a4750c03d58ea5",
    "abstract": "We present a new approach for fast and controllable generation of symbolic music based on the simplex diffusion, which is essentially a diffusion process operating on probabilities rather than the signal space. This objective has been applied in domains such as natural language processing but here we apply it to generating 4-bar multi-instrument music loops using an orderless representation. We show that our model can be steered with vocabulary priors, which affords a considerable level control over the music generation process, for instance, infilling in time and pitch and choice of instrumentation -- all without task-specific model adaptation or applying extrinsic control.",
    "authors": [
        "Nicolas Jonason",
        "Luca Casini",
        "Bob L. T. Sturm"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is shown that the model can be steered with vocabulary priors, which affords a considerable level control over the music generation process, for instance, infilling in time and pitch and choice of instrumentation -- all without task-specific model adaptation or applying extrinsic control."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}