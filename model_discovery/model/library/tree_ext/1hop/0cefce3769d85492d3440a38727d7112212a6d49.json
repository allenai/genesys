{
    "acronym": "0cefce3769d85492d3440a38727d7112212a6d49",
    "title": "RPLNet: Object-Object Affordance Recognition via Relational Phrase Learning",
    "seed_ids": [
        "longformer",
        "270f3bea8ca801870a6cc56b4d36f7f2019c9ed0",
        "925ad2897d1b5decbea320d07e99afa9110e09b2"
    ],
    "s2id": "0cefce3769d85492d3440a38727d7112212a6d49",
    "abstract": "Object-object affordance recognition aims to recognize the interactive relations between an object and other objects, which plays a crucial role in task decision-making and object selection of industrial robots. To address the problem of interference from complex interaction relations, we propose to recognize object-object affordances via relational phrase learning. The relational phrases are used as knowledge prior to improve the affordance expression. In addition, we propose a multi-scale feature pooling and aggregation module to enhance the visual feature representation of images. We redesign the initial block of transformer decoder to model the visual and phrase semantic features, improving the recognition performance. We collect and annotate object-object interaction images from the robot\u2019s view, and train and test our model on them. The experimental results show that our approach achieves the best performance compared to the state-of-the-art methods.",
    "authors": [
        "Dongpan Chen",
        "Dehui Kong",
        "Jinghua Li",
        "Baocai Yin"
    ],
    "venue": "2023 5th International Conference on Industrial Artificial Intelligence (IAI)",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The initial block of transformer decoder is redesign to model the visual and phrase semantic features, improving the recognition performance, and a multi-scale feature pooling and aggregation module is proposed to enhance the visual feature representation of images."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}