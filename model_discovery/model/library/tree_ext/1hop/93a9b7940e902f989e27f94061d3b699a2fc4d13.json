{
    "acronym": "93a9b7940e902f989e27f94061d3b699a2fc4d13",
    "title": "What Can We Learn from State Space Models for Machine Learning on Graphs?",
    "seed_ids": [
        "mamba",
        "02d3afd9c306ce0a0d39e211d60468732c591f8f",
        "c87b56ede2479fa809627a0ec89c97f5a1533ff9",
        "2dda6da7375bf5e8bcf60f87b17ba10757f3bc57",
        "1df04f33a8ef313cc2067147dbb79c3ca7c5c99f",
        "93e58491830abe1eb965ab37ec64fa97263f6048",
        "9bfd79af22a25c57becad12964034f0dd5ef53e6",
        "240103933ffe3dac2179cc160a2bd91299357a53",
        "6f6e2e0311589a9af045f6acd00b7dee6d19fce4",
        "026b3396a63ed5772329708b7580d633bb86bec9",
        "f35f5aedc30e2c5ded210d9c91ba6e84bd029425",
        "59b7448f816908cfb49a2ab5e63b2fa5786387f7",
        "998ac3e945857cf2676ee7efdbaf443a0c6f820a",
        "54155c2977a977bf129849455dcae3a2b79b3f41",
        "5a77b508302771fc083bf24e0bcda8553c9b5421",
        "240300b1da360f22bf0b82c6817eacebba6deed4",
        "70e91e16eb321067d9402710e14a40cf28311f73",
        "6d7d141c75af752ffc0d8a6184cca3f9323d6c74",
        "5eda60d4940d4185df45c5703e103458171d465d",
        "eaef083b9d661f42cc0d89d9d8156218f33a91d9",
        "ca444821352a4bd91884413d8070446e2960715a",
        "277dd73bfeb5c46513ce305136b0e71fcd2a311c",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "ca9047c78d48b606c4e4f0c456b1dda550de28b2",
        "7e9ff94476f41041c75e253e84f487db00e9c861",
        "c0f709acf38eb27702b0fbce1215db0ebaa2de2b",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
        "6f68e1bb253925d8431588555d3010419f322e04",
        "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
        "322cfc0af8b29eff694bc80bca5e456b35e400cc"
    ],
    "s2id": "93a9b7940e902f989e27f94061d3b699a2fc4d13",
    "abstract": "Machine learning on graphs has recently found extensive applications across domains. However, the commonly used Message Passing Neural Networks (MPNNs) suffer from limited expressive power and struggle to capture long-range dependencies. Graph transformers offer a strong alternative due to their global attention mechanism, but they come with great computational overheads, especially for large graphs. In recent years, State Space Models (SSMs) have emerged as a compelling approach to replace full attention in transformers to model sequential data. It blends the strengths of RNNs and CNNs, offering a) efficient computation, b) the ability to capture long-range dependencies, and c) good generalization across sequences of various lengths. However, extending SSMs to graph-structured data presents unique challenges due to the lack of canonical node ordering in graphs. In this work, we propose Graph State Space Convolution (GSSC) as a principled extension of SSMs to graph-structured data. By leveraging global permutation-equivariant set aggregation and factorizable graph kernels that rely on relative node distances as the convolution kernels, GSSC preserves all three advantages of SSMs. We demonstrate the provably stronger expressiveness of GSSC than MPNNs in counting graph substructures and show its effectiveness across 10 real-world, widely used benchmark datasets, where GSSC achieves best results on 7 out of 10 datasets with all significant improvements compared to the state-of-the-art baselines and second-best results on the other 3 datasets. Our findings highlight the potential of GSSC as a powerful and scalable model for graph machine learning. Our code is available at https://github.com/Graph-COM/GSSC.",
    "authors": [
        "Yinan Huang",
        "Siqi Miao",
        "Pan Li"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes Graph State Space Convolution (GSSC) as a principled extension of SSMs to graph-structured data and demonstrates the provably stronger expressiveness of GSSC than MPNNs in counting graph substructures and shows its effectiveness across 10 real-world, widely used benchmark datasets."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}