{
    "acronym": "176e0712b92cc698218f54ff0b47a7f3677606bf",
    "title": "Lifting Transformer for 3D Human Pose Estimation in Video",
    "seed_ids": [
        "funneltransformer",
        "7e5709d81558d3ef4265de29ea75931afeb1f2dd",
        "2a218786f4615b82389f78472e7ff22e6ce57490",
        "8af925f4edf45131b5b6fed8aa655089d58692fa"
    ],
    "s2id": "176e0712b92cc698218f54ff0b47a7f3677606bf",
    "abstract": "Despite great progress in video-based 3D human pose estimation, it is still challenging to learn a discriminative single-pose representation from redundant sequences. To this end, we propose a novel Transformer-based architecture, called Lifting Transformer, for 3D human pose estimation to lift a sequence of 2D joint locations to a 3D pose. Speci\ufb01cally, a vanilla Transformer encoder (VTE) is adopted to model long-range dependencies of 2D pose sequences. To reduce redundancy of the sequence and aggregate information from local context, fully-connected layers in the feed-forward network of VTE are replaced with strided convolutions to progressively reduce the sequence length. The modi\ufb01ed VTE is termed as strided Transformer encoder (STE) and it is built upon the outputs of VTE. STE not only signi\ufb01cantly reduces the computation cost but also effectively aggregates information to a single-vector representation in a global and local fashion. Moreover, a full-to-single supervision scheme is employed at both the full sequence scale and single target frame scale, applying to the outputs of VTE and STE, respectively. This scheme imposes extra temporal smoothness constraints in conjunction with the single target frame supervision. The proposed architecture is evaluated on two challenging benchmark datasets, namely, Human3.6M and HumanEva-I, and achieves state-of-the-art results with much fewer parameters.",
    "authors": [
        "Wenhao Li",
        "Hong Liu",
        "Runwei Ding",
        "Mengyuan Liu",
        "Pichao Wang"
    ],
    "venue": "arXiv.org",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel Transformer-based architecture is proposed for 3D human pose estimation to lift a sequence of 2D joint locations to a 3D pose, and achieves state-of-the-art results with much fewer parameters."
    },
    "citationCount": 20,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}