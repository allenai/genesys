{
    "acronym": "b98f6725341e75df30f9d61e284972c6b11a7e78",
    "title": "Semantic-Aware Autoregressive Image Modeling for Visual Representation Learning",
    "seed_ids": [
        "gpt",
        "gpt2",
        "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7",
        "2cd605106b88c85d7d8b865b1ef0f8c8293debf1",
        "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8",
        "270f3bea8ca801870a6cc56b4d36f7f2019c9ed0",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "b98f6725341e75df30f9d61e284972c6b11a7e78",
    "abstract": "The development of autoregressive modeling (AM) in computer vision lags behind natural language processing (NLP) in self-supervised pre-training. This is mainly caused by the challenge that images are not sequential signals and lack a natural order when applying autoregressive modeling. In this study, inspired by human beings\u2019 way of grasping an image, i.e., focusing on the main object first, we present a semantic-aware autoregressive image modeling (SemAIM) method to tackle this challenge. The key insight of SemAIM is to autoregressively model images from the semantic patches to the less semantic patches. To this end, we first calculate a semantic-aware permutation of patches according to their feature similarities and then perform the autoregression procedure based on the permutation. In addition, considering that the raw pixels of patches are low-level signals and are not ideal prediction targets for learning high-level semantic representation, we also explore utilizing the patch features as the prediction targets. Extensive experiments are conducted on a broad range of downstream tasks, including image classification, object detection, and instance/semantic segmentation, to evaluate the performance of SemAIM. The results demonstrate SemAIM achieves state-of-the-art performance compared with other self-supervised methods. Specifically, with ViT-B, SemAIM achieves 84.1% top-1 accuracy for fine-tuning on ImageNet, 51.3% AP and 45.4% AP for object detection and instance segmentation on COCO, which outperforms the vanilla MAE by 0.5%, 1.0%, and 0.5%, respectively. Code is available at https://github.com/skyoux/SemAIM.",
    "authors": [
        "Kaiyou Song",
        "Shan Zhang",
        "Tong Wang"
    ],
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A semantic-aware autoregressive image modeling method to autoregressively model images from the semantic patches to the less semantic patches, which achieves state-of-the-art performance compared with other self-supervised methods."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}