{
    "acronym": "fe2d04ea5feb7011127ca9875ed50d401b1d48ef",
    "title": "IID SQuAD Track: Expanding BiDAF and QANet Architectures for SQuAD",
    "seed_ids": [
        "transformerxl"
    ],
    "s2id": "fe2d04ea5feb7011127ca9875ed50d401b1d48ef",
    "abstract": "In this work, we produced a question-answering (Q & A) system that builds off of the Bidirectional Attention Flow (BiDAF) [1] and QANet [2] architectures to perform well on the SQuAD 2.0 [3] dataset and improve upon the performance of the provided baseline BiDAF model. We first outperformed the accuracy of the baseline BiDAF model on the SQuAD 2.0 dataset by expanding the BiDAF model to incorporate character-level embeddings, both alone and in combination with word-level embeddings. We also experimented with adding self-attention and co-attention layers to the BiDAF model. We found that the BiDAF model with character-level embeddings slightly outperformed the BiDAF model with combined character-level and word-level embeddings. We also discovered that co-attention did not improve the baseline BiDAF model, but self-attention increased the performance of the BiDAF model with character-level and word-level embeddings. We then implemented the QANet architecture to improve upon the performances of the baseline and expanded BiDAF models and build an even more accurate Q & A system. We experimented with the character dimensions of the QANet architecture and found that smaller character dimensions slightly outperformed larger character dimensions. We also augmented the QANet model by adding a segment-level recurrence mechanism from Transformer-XL [4]. However, this QANet + Transformer-XL model proved considerably unwieldy to train. Our highest performing QANet model achieved EM = 66.056 and F1 = 69.415 on the dev set and EM = 62.756 and F1 = 66.325 on the test set, putting us at 16/114 on the non-PCE SQuAD track dev leaderboard and 23/100 on the non-PCE SQuAD track test leaderboard (submission",
    "authors": [
        "Stanford CS224N",
        "Eva Prakash",
        "Josh Singh",
        "Vincent Li"
    ],
    "venue": "",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A question-answering (Q & A) system that builds off of the Bidirectional Attention Flow and QANet architectures to perform well on the SQuAD 2.0 dataset and improve upon the performance of the provided baseline BiDAF model and implement the QANet architecture to improve upon the performances of the baseline and expanded BiDAF models."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}