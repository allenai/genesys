{
    "acronym": "5168d3595acaf7528039ee542eb57d0dc3ad2fd8",
    "title": "How Easily do Irrelevant Inputs Skew the Responses of Large Language Models?",
    "seed_ids": [
        "gpt3",
        "bca0bbd01ea917b7a9fe369288ea3ba03d3b1ff3",
        "465471bb5bf1a945549d6291c2d23367966b4957",
        "e7ad08848d5d7c5c47673ffe0da06af443643bda",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c"
    ],
    "s2id": "5168d3595acaf7528039ee542eb57d0dc3ad2fd8",
    "abstract": "By leveraging the retrieval of information from external knowledge databases, Large Language Models (LLMs) exhibit enhanced capabilities for accomplishing many knowledge-intensive tasks. However, due to the inherent flaws of current retrieval systems, there might exist irrelevant information within those retrieving top-ranked passages. In this work, we present a comprehensive investigation into the robustness of LLMs to different types of irrelevant information under various conditions. We initially introduce a framework to construct high-quality irrelevant information that ranges from semantically unrelated, partially related, and related to questions. Furthermore, our analysis demonstrates that the constructed irrelevant information not only scores highly on similarity metrics, being highly retrieved by existing systems, but also bears semantic connections to the context. Our investigation reveals that current LLMs still face challenges in discriminating highly semantically related information and can be easily distracted by these irrelevant yet misleading content. Besides, we also find that current solutions for handling irrelevant information have limitations in improving the robustness of LLMs to such distractions. All the resources are available on GitHub at https://github.com/Di-viner/LLM-Robustness-to-Irrelevant-Information.",
    "authors": [
        "Siye Wu",
        "Jian Xie",
        "Jiangjie Chen",
        "Tinghui Zhu",
        "Kai Zhang",
        "Yanghua Xiao"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work presents a framework to construct high-quality irrelevant information that ranges from semantically unrelated, partially related, and related to questions and demonstrates that the constructed irrelevant information not only scores highly on similarity metrics, being highly retrieved by existing systems, but also bears semantic connections to the context."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}