{
    "acronym": "146cf9e9eeb1807034a8622504529c5ef93e956f",
    "title": "Text Diffusion with Reinforced Conditioning",
    "seed_ids": [
        "analogbits",
        "5fa10872ef8037853ff7c8baf5f77fb55a918eca",
        "020a50f6a7154850ac81e3cde69ad8198ded6751",
        "a979742220a88b1d32e1fbe72c41e8ba3007053c",
        "22775e58932cdfbd273a2a835a22c5d86800a458",
        "2c6ac935c826002976722ca8d3319f691975687e",
        "498ac9b2e494601d20a3d0211c16acf2b7954a54",
        "b64537bdf7a103aa01972ba06ea24a9c08f7cd74",
        "1386b8a11929cf02da291c56aca353e33bbc22ed",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "24425954960ce968e5f14360fbdd0605abcadfcf"
    ],
    "s2id": "146cf9e9eeb1807034a8622504529c5ef93e956f",
    "abstract": "Diffusion models have demonstrated exceptional capability in generating high-quality images, videos, and audio. Due to their adaptiveness in iterative refinement, they provide a strong potential for achieving better non-autoregressive sequence generation. However, existing text diffusion models still fall short in their performance due to a challenge in handling the discreteness of language. This paper thoroughly analyzes text diffusion models and uncovers two significant limitations: degradation of self-conditioning during training and misalignment between training and sampling. Motivated by our findings, we propose a novel Text Diffusion model called TReC, which mitigates the degradation with Reinforced Conditioning and the misalignment by Time-Aware Variance Scaling. Our extensive experiments demonstrate the competitiveness of TReC against autoregressive, non-autoregressive, and diffusion baselines. Moreover, qualitative analysis shows its advanced ability to fully utilize the diffusion process in refining samples.",
    "authors": [
        "Yuxuan Liu",
        "Tianchi Yang",
        "Shaohan Huang",
        "Zihan Zhang",
        "Haizhen Huang",
        "Furu Wei",
        "Weiwei Deng",
        "Feng Sun",
        "Qi Zhang"
    ],
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper proposes a novel Text Diffusion model called TReC, which mitigates the degradation with Reinforced Conditioning and the misalignment by Time-Aware Variance Scaling and demonstrates the competitiveness of TReC against autoregressive, non-autoregressive, and diffusion baselines."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}