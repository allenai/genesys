{
    "acronym": "19ddb13626cbcfabc1dc32805b5b3f8d4e40072d",
    "title": "Layer-Wise Multi-View Decoding for Improved Natural Language Generation",
    "seed_ids": [
        "lighdynconv",
        "faadd7d081c8d67e8c2567e8a5579e46cd6b2280",
        "16c844fd4d97f3c6eb38b0d6527c87d184efedc3"
    ],
    "s2id": "19ddb13626cbcfabc1dc32805b5b3f8d4e40072d",
    "abstract": "\u2014In sequence-to-sequence learning, e.g., natural language generation, the decoder relies on the attention mechanism to ef\ufb01ciently extract information from the encoder. While it is common practice to draw information from only the last encoder layer, recent work has proposed to use representations from different encoder layers for diversi\ufb01ed levels of information. Nonetheless, the decoder still obtains only a single view of the source sequences, which might lead to insuf\ufb01cient training of the encoder layer stack due to the hierarchy bypassing problem. In this work, we propose layer-wise multi-view decoding , where for each decoder layer, together with the representations from the last encoder layer, which serve as a global view, those from other encoder layers are supplemented for a stereoscopic view of the source sequences. Systematic experiments and analyses show that we successfully address the hierarchy bypassing problem, require almost negligible parameter increase, and substantially improve the performance of sequence-to-sequence learning with deep representations on \ufb01ve diverse tasks, i.e., machine translation, abstractive summarization, image captioning, video captioning, and medical report generation. In particular, our approach achieves new state-of-the-art results on eight benchmark datasets, including a low-resource machine translation dataset and two low-resource medical report generation datasets.",
    "authors": [
        "Fenglin Liu",
        "Xuancheng Ren",
        "Guangxiang Zhao",
        "Chenyu You",
        "Xian Wu",
        "Xu Sun"
    ],
    "venue": "",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes layer-wise multi-view decoding, where for each decoder layer, together with the representations from the last encoder layer, which serve as a global view, those from other encoder layers are supplemented for a stereoscopic view of the source sequences."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}