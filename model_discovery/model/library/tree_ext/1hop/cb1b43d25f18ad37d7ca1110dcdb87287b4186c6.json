{
    "acronym": "cb1b43d25f18ad37d7ca1110dcdb87287b4186c6",
    "title": "An Overview Of Temporal Commonsense Reasoning and Acquisition",
    "seed_ids": [
        "gpt",
        "7ebdc4ed93e37e7d3691085f4d08c495557ba71b",
        "5d733042a5185a97eb80e4c665eaeaf71f9d1bba",
        "7096304d19457833972daec4d3f5107befe30b1c",
        "9405cc0d6169988371b2755e573cc28650d14dfe",
        "92e121c6e114fe3cfb89370df03847c66a9b4e28"
    ],
    "s2id": "cb1b43d25f18ad37d7ca1110dcdb87287b4186c6",
    "abstract": "Temporal commonsense reasoning refers to the ability to understand the typical temporal context of phrases, actions, and events, and use it to reason over problems requiring such knowledge. This trait is essential in temporal natural language processing tasks, with possible applications such as timeline summarization, temporal question answering, and temporal natural language inference. Recent research on the performance of large language models suggests that, although they are adept at generating syntactically correct sentences and solving classification tasks, they often take shortcuts in their reasoning and fall prey to simple linguistic traps. This article provides an overview of research in the domain of temporal commonsense reasoning, particularly focusing on enhancing language model performance through a variety of augmentations and their evaluation across a growing number of datasets. However, these augmented models still struggle to approach human performance on reasoning tasks over temporal common sense properties, such as the typical occurrence times, orderings, or durations of events. We further emphasize the need for careful interpretation of research to guard against overpromising evaluation results in light of the shallow reasoning present in transformers. This can be achieved by appropriately preparing datasets and suitable evaluation metrics.",
    "authors": [
        "Georg Wenzel",
        "A. Jatowt"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The need for careful interpretation of research is emphasized to guard against overpromising evaluation results in light of the shallow reasoning present in transformers, and the need for appropriately preparing datasets and suitable evaluation metrics is emphasized."
    },
    "citationCount": 4,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}