{
    "acronym": "ee9ed60f41a0fe1c515c2e4d348ae4840f9f7e3e",
    "title": "Symbolic Music Generation with Non-Differentiable Rule Guided Diffusion",
    "seed_ids": [
        "classfreediffu",
        "498ac9b2e494601d20a3d0211c16acf2b7954a54",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "fda805c6e85a03d10549acdc5489420ca8f3d405",
        "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4",
        "eb0931c39904a40c6cb4aa35c9b21d5e3b7dc856",
        "4c64c35198453662882afd63d618a832c7d8c1b2",
        "ce510c6cfeac703706460680e977c54554840830"
    ],
    "s2id": "ee9ed60f41a0fe1c515c2e4d348ae4840f9f7e3e",
    "abstract": "We study the problem of symbolic music generation (e.g., generating piano rolls), with a technical focus on non-differentiable rule guidance. Musical rules are often expressed in symbolic form on note characteristics, such as note density or chord progression, many of which are non-differentiable which pose a challenge when using them for guided diffusion. We propose \\oursfull (\\ours), a novel guidance method that only requires forward evaluation of rule functions that can work with pre-trained diffusion models in a plug-and-play way, thus achieving training-free guidance for non-differentiable rules for the first time. Additionally, we introduce a latent diffusion architecture for symbolic music generation with high time resolution, which can be composed with SCG in a plug-and-play fashion. Compared to standard strong baselines in symbolic music generation, this framework demonstrates marked advancements in music quality and rule-based controllability, outperforming current state-of-the-art generators in a variety of settings. For detailed demonstrations, code and model checkpoints, please visit our project website: https://scg-rule-guided-music.github.io/.",
    "authors": [
        "Yujia Huang",
        "Adishree S. Ghatare",
        "Yuanzhe Liu",
        "Ziniu Hu",
        "Qinsheng Zhang",
        "Chandramouli Sastry",
        "Siddharth Gururani",
        "Sageev Oore",
        "Yisong Yue"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "oursfull (\\the authors'), a novel guidance method that only requires forward evaluation of rule functions that can work with pre-trained diffusion models in a plug-and-play way, thus achieving training-free guidance for non-differentiable rules for the first time."
    },
    "citationCount": 5,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}