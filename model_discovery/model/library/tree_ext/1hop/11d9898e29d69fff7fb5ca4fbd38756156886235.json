{
    "acronym": "11d9898e29d69fff7fb5ca4fbd38756156886235",
    "title": "MSDT: Masked Language Model Scoring Defense in Text Domain",
    "seed_ids": [
        "gpt2",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "11d9898e29d69fff7fb5ca4fbd38756156886235",
    "abstract": "Pre-trained language models allowed us to process downstream tasks with the help of fine-tuning, which aids the model to achieve fairly high accuracy in various Natural Language Processing (NLP) tasks. Such easily-downloaded language models from various websites empowered the public users as well as some major institutions to give a momentum to their real-life application. However, it was recently proven that models become extremely vulnerable when they are backdoor attacked with trigger-inserted poisoned datasets by malicious users. The attackers then redistribute the victim models to the public to attract other users to use them, where the models tend to misclassify when certain triggers are detected within the training sample. In this paper, we will introduce a novel improved textual backdoor defense method, named MSDT, that outperforms the current existing defensive algorithms in specific datasets. The experimental results illustrate that our method can be effective and constructive in terms of defending against backdoor attack in text domain.",
    "authors": [
        "Jaechul Roh",
        "Minhao Cheng",
        "Yajun Fang"
    ],
    "venue": "International Conference on Universal Village",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel improved textual backdoor defense method, named MSDT, that outperforms the current existing defensive algorithms in specific datasets and can be effective and constructive in terms of defending against backdoor attack in text domain."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}