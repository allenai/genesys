{
    "acronym": "fb7c7fa69cd2d1533467ea3f9e1716c1ddd47821",
    "title": "An Attention Free Long Short-Term Memory for Time Series Forecasting",
    "seed_ids": [
        "aft",
        "d5e999aae76d5270ef272076979c809817458212"
    ],
    "s2id": "fb7c7fa69cd2d1533467ea3f9e1716c1ddd47821",
    "abstract": "Deep learning is playing an increasingly important role in time series analysis. We focused on time series forecasting using attention free mechanism, a more efficient framework, and proposed a new architecture for time series prediction for which linear models seem to be unable to capture the time dependence. We proposed an architecture built using attention free LSTM layers that overcome linear models for conditional variance prediction. Our findings confirm the validity of our model, which also allowed to improve the prediction capacity of a LSTM, while improving the efficiency of the learning task.",
    "authors": [
        "Hugo Inzirillo",
        "Ludovic De Villelongue"
    ],
    "venue": "Social Science Research Network",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The findings confirm the validity of the model, which also allowed to improve the prediction capacity of a LSTM, while improving the efficiency of the learning task."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}