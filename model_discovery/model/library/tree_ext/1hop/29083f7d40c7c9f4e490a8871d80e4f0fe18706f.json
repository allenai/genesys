{
    "acronym": "29083f7d40c7c9f4e490a8871d80e4f0fe18706f",
    "title": "Accelerating Greedy Coordinate Gradient via Probe Sampling",
    "seed_ids": [
        "gpt2",
        "87c5b281fa43e6f27191b20a8dd694eda1126336",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "053b1d7b97eb2c91fc3921d589c160b0923c70b1",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "16c844fd4d97f3c6eb38b0d6527c87d184efedc3",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "29083f7d40c7c9f4e490a8871d80e4f0fe18706f",
    "abstract": "Safety of Large Language Models (LLMs) has become a critical issue given their rapid progresses. Greedy Coordinate Gradient (GCG) is shown to be effective in constructing adversarial prompts to break the aligned LLMs, but optimization of GCG is time-consuming. To reduce the time cost of GCG and enable more comprehensive studies of LLM safety, in this work, we study a new algorithm called $\\texttt{Probe sampling}$. At the core of the algorithm is a mechanism that dynamically determines how similar a smaller draft model's predictions are to the target model's predictions for prompt candidates. When the target model is similar to the draft model, we rely heavily on the draft model to filter out a large number of potential prompt candidates. Probe sampling achieves up to $5.6$ times speedup using Llama2-7b-chat and leads to equal or improved attack success rate (ASR) on the AdvBench. Furthermore, probe sampling is also able to accelerate other prompt optimization techniques and adversarial methods, leading to acceleration of $1.8\\times$ for AutoPrompt, $2.4\\times$ for APE and $2.4\\times$ for AutoDAN.",
    "authors": [
        "Yiran Zhao",
        "Wenyue Zheng",
        "Tianle Cai",
        "Xuan Long Do",
        "Kenji Kawaguchi",
        "Anirudh Goyal",
        "Michael Shieh"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work studies a new algorithm called probe sampling, a mechanism that dynamically determines how similar a smaller draft model's predictions are to the target model's predictions for prompt candidates, which is able to accelerate other prompt optimization techniques and adversarial methods."
    },
    "citationCount": 5,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}