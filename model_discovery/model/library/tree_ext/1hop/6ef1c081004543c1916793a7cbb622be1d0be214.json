{
    "acronym": "6ef1c081004543c1916793a7cbb622be1d0be214",
    "title": "Prediction of antibiotic resistance mechanisms using a protein language model",
    "seed_ids": [
        "bert"
    ],
    "s2id": "6ef1c081004543c1916793a7cbb622be1d0be214",
    "abstract": "Motivation Antibiotic resistance has emerged as a major global health threat, with an increasing number of bacterial infections becoming difficult to treat. Predicting the underlying resistance mechanisms of antibiotic resistance genes (ARGs) is crucial for understanding and combating this problem. However, existing methods struggle to accurately predict resistance mechanisms for ARGs with low similarity to known sequences and lack sufficient interpretability of the prediction models. Results In this study, we present a novel approach for predicting ARG resistance mechanisms using Protein-BERT, a protein language model based on deep learning. Our method outperforms state-of-the-art techniques on diverse ARG datasets, including those with low homology to the training data, highlighting its potential for predicting the resistance mechanisms of unknown ARGs. Attention analysis of the model reveals that it considers biologically relevant features, such as conserved amino acid residues and antibiotic target binding sites, when making predictions. These findings provide valuable insights into the molecular basis of antibiotic resistance and demonstrate the interpretability of protein language models, offering a new perspective on their application in bioinformatics. Availability The source code is available for free at https://github.com/hmdlab/ARG-BERT. The output results of the model are published at https://waseda.box.com/v/ARG-BERT-suppl. Contact mhamada@waseda.jp",
    "authors": [
        "Kanami Yagimoto",
        "S. Hosoda",
        "Miwa Sato",
        "Michiaki Hamada"
    ],
    "venue": "bioRxiv",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel approach for predicting ARG resistance mechanisms using Protein-BERT, a protein language model based on deep learning that outperforms state-of-the-art techniques on diverse ARG datasets, including those with low homology to the training data, highlighting its potential for predicting the resistance mechanisms of unknown ARGs."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}