{
    "acronym": "5700818068c867450678cfa8910be7c749fabcf8",
    "title": "Code-mixed Sentiment and Hate-speech Prediction",
    "seed_ids": [
        "bert",
        "0ad942d11cec7aebddd69143b563ce2eccf063ab"
    ],
    "s2id": "5700818068c867450678cfa8910be7c749fabcf8",
    "abstract": "Code-mixed discourse combines multiple languages in a single text. It is commonly used in informal discourse in countries with several official languages, but also in many other countries in combination with English or neighboring languages. As recently large language models have dominated most natural language processing tasks, we investigated their performance in code-mixed settings for relevant tasks. We first created four new bilingual pre-trained masked language models for English-Hindi and English-Slovene languages, specifically aimed to support informal language. Then we performed an evaluation of monolingual, bilingual, few-lingual, and massively multilingual models on several languages, using two tasks that frequently contain code-mixed text, in particular, sentiment analysis and offensive language detection in social media texts. The results show that the most successful classifiers are fine-tuned bilingual models and multilingual models, specialized for social media texts, followed by non-specialized massively multilingual and monolingual models, while huge generative models are not competitive. For our affective problems, the models mostly perform slightly better on code-mixed data compared to non-code-mixed data.",
    "authors": [
        "Anjali Yadav",
        "Tanya Garg",
        "Matej Klemen",
        "Matej Ul\u010dar",
        "Basant Agarwal",
        "Marko Robnik-Sikonja"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "An evaluation of monolingual, bilingual, few-lingual, and massively multilingual models on several languages, using two tasks that frequently contain code-mixed text, in particular, sentiment analysis and offensive language detection in social media texts shows that the most successful classifiers are fine-tuned bilingual models and multilingual models, specialized for social media texts."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}