{
    "acronym": "27f8c420f0967eba781f0e1c03db7363570b66af",
    "title": "Private Fine-tuning of Large Language Models with Zeroth-order Optimization",
    "seed_ids": [
        "gpt3",
        "385c2ee0bf829676d1a5aacfc697fc6a9d245ed5",
        "13a0d8bb38f739990c8cd65a44061c6534f17221",
        "85e7d63f75c0916bd350a229e040c5fbb1472e7a"
    ],
    "s2id": "27f8c420f0967eba781f0e1c03db7363570b66af",
    "abstract": "Fine-tuning large pretrained models on private datasets may run the risk of violating privacy. Differential privacy is a framework for mitigating privacy risks by enforcing algorithmic stability. DP-SGD enables training models with private data in a privacy-preserving manner, but raises new obstacles in the form of performance loss and significant engineering challenges. We introduce DP-ZO, a new method for fine-tuning large language models that preserves the privacy of training data by privatizing zeroth-order optimization. A key insight into the design of our method is that the direction of the gradient in SPSA, the zeroth-order algorithm we use, is always random and the only information that depends on private data is the step size, i.e., a scalar. Therefore, we only need to privatize the scalar step size, which is memory-efficient. DP-ZO, which can be instantiated with either Laplace or Gaussian noise, provides a strong privacy-utility trade-off across different tasks, and model sizes, under conservative privacy budgets. One noteworthy result is that DP-ZO exhibits just $1.86\\%$ performance degradation due to privacy at $(1,10^{-5})$-DP when fine-tuning OPT-66B on 1000 training samples from SQuAD.",
    "authors": [
        "Xinyu Tang",
        "Ashwinee Panda",
        "Milad Nasr",
        "Saeed Mahloujifar",
        "Prateek Mittal"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work introduces DP-ZO, a new method for fine-tuning large language models that preserves the privacy of training data by privatizing zeroth-order optimization, and provides a strong privacy-utility trade-off across different tasks, and model sizes, under conservative privacy budgets."
    },
    "citationCount": 7,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}