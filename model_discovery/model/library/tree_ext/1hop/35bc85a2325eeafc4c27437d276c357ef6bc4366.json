{
    "acronym": "35bc85a2325eeafc4c27437d276c357ef6bc4366",
    "title": "Compositional Generalization for Multi-label Text Classification: A Data-Augmentation Approach",
    "seed_ids": [
        "bert",
        "5cdab78acc4f3aab429a0dd41c3ec7e605d42e7b",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "35bc85a2325eeafc4c27437d276c357ef6bc4366",
    "abstract": "Despite significant advancements in multi-label text classification, the ability of existing models to generalize to novel and seldom-encountered complex concepts, which are compositions of elementary ones, remains underexplored. This research addresses this gap. By creating unique data splits across three benchmarks, we assess the compositional generalization ability of existing multi-label text classification models. Our results show that these models often fail to generalize to compositional concepts encountered infrequently during training, leading to inferior performance on tests with these new combinations. To address this, we introduce a data augmentation method that leverages two innovative text generation models designed to enhance the classification models' capacity for compositional generalization. Our experiments show that this data augmentation approach significantly improves the compositional generalization capabilities of classification models on our benchmarks, with both generation models surpassing other text generation baselines. Our codes available at https://github.com/yychai74/LD-VAE.",
    "authors": [
        "Yuyang Chai",
        "Zhuang Li",
        "Jiahui Liu",
        "Lei Chen",
        "Fei Li",
        "Donghong Ji",
        "Chong Teng"
    ],
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A data augmentation method that leverages two innovative text generation models designed to enhance the classification models' capacity for compositional generalization significantly improves the compositional generalization capabilities of classification models on benchmarks, with both generation models surpassing other text generation baselines."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}