{
    "acronym": "1932269090210059b236559e4272cf84c6784640",
    "title": "A Survey on Data Augmentation in Large Model Era",
    "seed_ids": [
        "bert",
        "c0f26279b8a296dd24e80e1c671dc526b132d12d",
        "6f84447bbf037a4102904eba308fecbbc97ccabb",
        "8d531cb8cf51eec3b8f1106d189295fa3c81c02a",
        "ee1fdc0e4391f2ef7d3222d47d8677c574fcd95c",
        "dce62170e8be820bcec51aae2eceed3943ca6c9a",
        "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d",
        "484b4e96428a7d3ab46330a15b14278ca7bd68ca",
        "69144d537f90f214d5b07a7c79121d16afd7da16",
        "e342165a614588878ad0f4bc9bacf3905df34d08",
        "6f7e03e4ccd26c762090e25dc5d2eb1e1f8c641d",
        "23c265ba884b92ecbd9d18641078d964697e4590",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "cd4df0a6076fc94225684acbf4941c80014eb30a",
        "7eba731a7fd8de712b7b79b5af41a6e2d4dbd191",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "1932269090210059b236559e4272cf84c6784640",
    "abstract": "Large models, encompassing large language and diffusion models, have shown exceptional promise in approximating human-level intelligence, garnering significant interest from both academic and industrial spheres. However, the training of these large models necessitates vast quantities of high-quality data, and with continuous updates to these models, the existing reservoir of high-quality data may soon be depleted. This challenge has catalyzed a surge in research focused on data augmentation methods. Leveraging large models, these data augmentation techniques have outperformed traditional approaches. This paper offers an exhaustive review of large model-driven data augmentation methods, adopting a comprehensive perspective. We begin by establishing a classification of relevant studies into three main categories: image augmentation, text augmentation, and paired data augmentation. Following this, we delve into various data post-processing techniques pertinent to large model-based data augmentation. Our discussion then expands to encompass the array of applications for these data augmentation methods within natural language processing, computer vision, and audio signal processing. We proceed to evaluate the successes and limitations of large model-based data augmentation across different scenarios. Concluding our review, we highlight prospective challenges and avenues for future exploration in the field of data augmentation. Our objective is to furnish researchers with critical insights, ultimately contributing to the advancement of more sophisticated large models. We consistently maintain the related open-source materials at: https://github.com/MLGroup-JLU/LLM-data-aug-survey.",
    "authors": [
        "Yue Zhou",
        "Chenlu Guo",
        "Xu Wang",
        "Yi Chang",
        "Yuan Wu"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper offers an exhaustive review of large model-driven data augmentation methods, adopting a comprehensive perspective and furnishing researchers with critical insights, ultimately contributing to the advancement of more sophisticated large models."
    },
    "citationCount": 6,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}