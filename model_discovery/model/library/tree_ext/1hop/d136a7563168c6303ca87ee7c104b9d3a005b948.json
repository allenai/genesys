{
    "acronym": "d136a7563168c6303ca87ee7c104b9d3a005b948",
    "title": "Constructing Global Coherence Representations: Identifying Interpretability and Coherences of Transformer Attention in Time Series Data",
    "seed_ids": [
        "hopfield",
        "7e5709d81558d3ef4265de29ea75931afeb1f2dd",
        "a8427ce5aee6d62800c725588e89940ed4910e0d"
    ],
    "s2id": "d136a7563168c6303ca87ee7c104b9d3a005b948",
    "abstract": "Transformer models have shown significant advances recently based on the general concept of Attention \u2014 to focus on specifically important and relevant parts of the input data. However, methods for enhancing their interpretability and explainability are still lacking. This is the problem which we tackle in this paper, to make Multi-Headed Attention more interpretable and explainable for time series classification. We present a method for constructing global coherence representations from Multi-Headed Attention of Transformer architectures. Accordingly, we present abstraction and interpretation methods, leading to intuitive visualizations of the respective attention patterns. We evaluate our proposed approach and the presented methods on several datasets demonstrating their efficacy.",
    "authors": [
        "Leonid Schwenke",
        "Martin Atzmueller"
    ],
    "venue": "International Conference on Data Science and Advanced Analytics",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper presents a method for constructing global coherence representations from Multi-Headed Attention of Transformer architectures, and presents abstraction and interpretation methods, leading to intuitive visualizations of the respective attention patterns."
    },
    "citationCount": 5,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}