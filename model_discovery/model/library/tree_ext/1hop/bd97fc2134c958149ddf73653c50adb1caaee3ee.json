{
    "acronym": "bd97fc2134c958149ddf73653c50adb1caaee3ee",
    "title": "DAIC-WOZ: On the Validity of Using the Therapist\u2019s prompts in Automatic Depression Detection from Clinical Interviews",
    "seed_ids": [
        "bert",
        "9166caa474031b62bacad8a920db8308e6a15120",
        "925ad2897d1b5decbea320d07e99afa9110e09b2"
    ],
    "s2id": "bd97fc2134c958149ddf73653c50adb1caaee3ee",
    "abstract": "Automatic depression detection from conversational data has gained significant interest in recent years.The DAIC-WOZ dataset, interviews conducted by a human-controlled virtual agent, has been widely used for this task.Recent studies have reported enhanced performance when incorporating interviewer\u2019s prompts into the model.In this work, we hypothesize that this improvement might be mainly due to a bias present in these prompts, rather than the proposed architectures and methods.Through ablation experiments and qualitative analysis, we discover that models using interviewer\u2019s prompts learn to focus on a specific region of the interviews, where questions about past experiences with mental health issues are asked, and use them as discriminative shortcuts to detect depressed participants. In contrast, models using participant responses gather evidence from across the entire interview.Finally, to highlight the magnitude of this bias, we achieve a 0.90 F1 score by intentionally exploiting it, the highest result reported to date on this dataset using only textual information.Our findings underline the need for caution when incorporating interviewers\u2019 prompts into models, as they may inadvertently learn to exploit targeted prompts, rather than learning to characterize the language and behavior that are genuinely indicative of the patient\u2019s mental health condition.",
    "authors": [
        "S. Burdisso",
        "Ernesto Reyes-Ram'irez",
        "Esa\u00fa Villatoro-Tello",
        "Fernando S'anchez-Vega",
        "Adrian Pastor Lopez-Monroy",
        "P. Motl\u00edcek"
    ],
    "venue": "Clinical Natural Language Processing Workshop",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The findings underline the need for caution when incorporating interviewers\u2019 prompts into models, as they may inadvertently learn to exploit targeted prompts, rather than learning to characterize the language and behavior that are genuinely indicative of the patient\u2019s mental health condition."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}