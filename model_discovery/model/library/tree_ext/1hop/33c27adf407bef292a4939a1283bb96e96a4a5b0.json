{
    "acronym": "33c27adf407bef292a4939a1283bb96e96a4a5b0",
    "title": "Enhancing Low-Resource Relation Representations through Multi-View Decoupling",
    "seed_ids": [
        "gpt",
        "99b0d1cb964c3942c6f6ce30d40d7d8eb4a8e66f",
        "da454295392cf4caaa39cc465734237ffe55392f",
        "85e7d63f75c0916bd350a229e040c5fbb1472e7a"
    ],
    "s2id": "33c27adf407bef292a4939a1283bb96e96a4a5b0",
    "abstract": "Recently, prompt-tuning with pre-trained language models (PLMs) has demonstrated the significantly enhancing ability of relation extraction (RE) tasks. \nHowever, in low-resource scenarios, where the available training data is scarce, previous prompt-based methods may still perform poorly for prompt-based representation learning due to a superficial understanding of the relation. \nTo this end, we highlight the importance of learning high-quality relation representation in low-resource scenarios for RE, and propose a novel prompt-based relation representation method, named MVRE (Multi-View Relation Extraction), to better leverage the capacity of PLMs to improve the performance of RE within the low-resource prompt-tuning paradigm. Specifically, MVRE decouples each relation into different perspectives to encompass multi-view relation representations for maximizing the likelihood during relation inference.\nFurthermore, we also design a Global-Local loss and a Dynamic-Initialization method for better alignment of the multi-view relation-representing virtual words, containing the semantics of relation labels during the optimization learning process and initialization. Extensive experiments on\nthree benchmark datasets show that our method can achieve\nstate-of-the-art in low-resource settings.",
    "authors": [
        "Chenghao Fan",
        "Wei Wei",
        "Xiaoye Qu",
        "Zhenyi Lu",
        "Wenfeng Xie",
        "Yu Cheng",
        "Dangyang Chen"
    ],
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a novel prompt-based relation representation method, named MVRE (Multi-View Relation Extraction), to better leverage the capacity of PLMs to improve the performance of RE within the low-resource prompt-tuning paradigm."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}