{
    "acronym": "75c0019b1c4bec220f4750d7f6fc5da6030e1d5e",
    "title": "ML-SUPERB 2.0: Benchmarking Multilingual Speech Models Across Modeling Constraints, Languages, and Datasets",
    "seed_ids": [
        "transformer",
        "29ddc1f43f28af7c846515e32cc167bc66886d0c"
    ],
    "s2id": "75c0019b1c4bec220f4750d7f6fc5da6030e1d5e",
    "abstract": "ML-SUPERB evaluates self-supervised learning (SSL) models on the tasks of language identification and automatic speech recognition (ASR). This benchmark treats the models as feature extractors and uses a single shallow downstream model, which can be fine-tuned for a downstream task. However, real-world use cases may require different configurations. This paper presents ML-SUPERB~2.0, which is a new benchmark for evaluating pre-trained SSL and supervised speech models across downstream models, fine-tuning setups, and efficient model adaptation approaches. We find performance improvements over the setup of ML-SUPERB. However, performance depends on the downstream model design. Also, we find large performance differences between languages and datasets, suggesting the need for more targeted approaches to improve multilingual ASR performance.",
    "authors": [
        "Jiatong Shi",
        "Shi Wang",
        "William Chen",
        "Martijn Bartelds",
        "Vanya Bannihatti Kumar",
        "Jinchuan Tian",
        "Xuankai Chang",
        "Dan Jurafsky",
        "Karen Livescu",
        "Hung-yi Lee",
        "Shinji Watanabe"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The ML-SUPERB~2.0 benchmark is presented, which is a new benchmark for evaluating pre-trained SSL and supervised speech models across downstream models, fine-tuning setups, and efficient model adaptation approaches, and large performance differences between languages and datasets are found."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}