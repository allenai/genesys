{
    "acronym": "c330409aada991b31dfd801ce60aedd7858a4444",
    "title": "Language Model Decoding as Direct Metrics Optimization",
    "seed_ids": [
        "gpt2",
        "6151ee4af6a3fe78f2df7c605598cd9e02b23c5b",
        "13a0d8bb38f739990c8cd65a44061c6534f17221",
        "0e3d6a7c9c04cf3ba9c902724548846a5ade04b4",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "492a655a67e6ec7423a968cedb70eec0cdbc8e98",
        "7ade458d52d2dfe997b8a617a6b524bda12a619d",
        "7a15950dc71079285a4eaf195de5aadd87c41b40",
        "75acc731bdd2b626edc74672a30da3bc51010ae8",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "c330409aada991b31dfd801ce60aedd7858a4444",
    "abstract": "Despite the remarkable advances in language modeling, current mainstream decoding methods still struggle to generate texts that align with human texts across different aspects. In particular, sampling-based methods produce less-repetitive texts which are often disjunctive in discourse, while search-based methods maintain topic coherence at the cost of increased repetition. Overall, these methods fall short in achieving holistic alignment across a broad range of aspects. In this work, we frame decoding from a language model as an optimization problem with the goal of strictly matching the expected performance with human texts measured by multiple metrics of desired aspects simultaneously. The resulting decoding distribution enjoys an analytical solution that scales the input language model distribution via a sequence-level energy function defined by these metrics. And most importantly, we prove that this induced distribution is guaranteed to improve the perplexity on human texts, which suggests a better approximation to the underlying distribution of human texts. To facilitate tractable sampling from this globally normalized distribution, we adopt the Sampling-Importance-Resampling technique. Experiments on various domains and model scales demonstrate the superiority of our method in metrics alignment with human texts and human evaluation over strong baselines.",
    "authors": [
        "Haozhe Ji",
        "Pei Ke",
        "Hongning Wang",
        "Minlie Huang"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work frames decoding from a language model as an optimization problem with the goal of strictly matching the expected performance with human texts measured by multiple metrics of desired aspects simultaneously, and proves that this induced distribution is guaranteed to improve the perplexity on human texts."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}