{
    "acronym": "da61540e32168881796b5cad5ab52f389bc7790c",
    "title": "Resolving label uncertainty with implicit posterior models",
    "seed_ids": [
        "gpt2",
        "b30195763eb103e2e5564228119f3810ab423b2e",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "da61540e32168881796b5cad5ab52f389bc7790c",
    "abstract": "We propose a method for jointly inferring labels across a collection of data samples, where each sample consists of an observation and a prior belief about the label. By implicitly assuming the existence of a generative model for which a differentiable predictor is the posterior, we derive a training objective that allows learning under weak beliefs. This formulation unifies various machine learning settings; the weak beliefs can come in the form of noisy or incomplete labels, likelihoods given by a different prediction mechanism on auxiliary input, or common-sense priors reflecting knowledge about the structure of the problem at hand. We demonstrate the proposed algorithms on diverse problems: classification with negative training examples, learning from rankings, weakly and self-supervised aerial imagery segmentation, co-segmentation of video frames, and coarsely supervised text classification.",
    "authors": [
        "Esther Rolf",
        "Nikolay Malkin",
        "Alexandros Graikos",
        "A. Jojic",
        "Caleb Robinson",
        "N. Jojic"
    ],
    "venue": "Conference on Uncertainty in Artificial Intelligence",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a method for jointly inferring labels across a collection of data samples, where each sample consists of an observation and a prior belief about the label, and derives a training objective that allows learning under weak beliefs."
    },
    "citationCount": 8,
    "influentialCitationCount": 2,
    "code": null,
    "description": null,
    "url": null
}