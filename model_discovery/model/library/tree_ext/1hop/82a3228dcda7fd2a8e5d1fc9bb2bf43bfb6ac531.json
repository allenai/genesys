{
    "acronym": "82a3228dcda7fd2a8e5d1fc9bb2bf43bfb6ac531",
    "title": "Discovering Knowledge-Critical Subnetworks in Pretrained Language Models",
    "seed_ids": [
        "gpt2",
        "7805db74210aa113e83f20ffd0ad1ebcbb12ed7a",
        "cd471b5ef162906ef3d9a84398b3f98e9ee4bf56",
        "710d183174844da5b7f392667f3cc25d2b098dde",
        "d0086b86103a620a86bc918746df0aa642e2a8a3",
        "f48ae425e2567be2d993efcaaf74c2274fc9d7c5",
        "d9f6ada77448664b71128bb19df15765336974a6",
        "f6fbb6809374ca57205bd2cf1421d4f4fa04f975",
        "9405cc0d6169988371b2755e573cc28650d14dfe",
        "c21a4d70d83e0f6eb2a9e1c41d034842dd561e47"
    ],
    "s2id": "82a3228dcda7fd2a8e5d1fc9bb2bf43bfb6ac531",
    "abstract": "Pretrained language models (LMs) encode implicit representations of knowledge in their parameters. However, localizing these representations and disentangling them from each other remains an open problem. In this work, we investigate whether pretrained language models contain various knowledge-critical subnetworks: particular sparse computational subgraphs responsible for encoding specific knowledge the model has memorized. We propose a multi-objective differentiable weight masking scheme to discover these subnetworks and show that we can use them to precisely remove specific knowledge from models while minimizing adverse effects on the behavior of the original language model. We demonstrate our method on multiple GPT2 variants, uncovering highly sparse subnetworks (98%+) that are solely responsible for specific collections of relational knowledge. When these subnetworks are removed, the remaining network maintains most of its initial capacity (modeling language and other memorized relational knowledge) but struggles to express the removed knowledge, and suffers performance drops on examples needing this removed knowledge on downstream tasks after finetuning.",
    "authors": [
        "Deniz Bayazit",
        "Negar Foroutan",
        "Zeming Chen",
        "Gail Weiss",
        "Antoine Bosselut"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work investigates whether pretrained language models contain various knowledge-critical subnetworks: particular sparse computational subgraphs responsible for encoding specific knowledge the model has memorized, and proposes a multi-objective differentiable weight masking scheme to discover them."
    },
    "citationCount": 8,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}