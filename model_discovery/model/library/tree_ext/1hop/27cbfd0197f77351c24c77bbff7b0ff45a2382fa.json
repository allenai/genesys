{
    "acronym": "27cbfd0197f77351c24c77bbff7b0ff45a2382fa",
    "title": "CroCo v2: Improved Cross-view Completion Pre-training for Stereo Matching and Optical Flow",
    "seed_ids": [
        "roformer",
        "979810ca765695a481c37126103b8ba256ee2192",
        "7bffc157b3b3626a3912a3b0ef74ce5904630fce",
        "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7",
        "36b9d0f8610a82fd25854889d9327a04da4ff8fd",
        "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4",
        "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7"
    ],
    "s2id": "27cbfd0197f77351c24c77bbff7b0ff45a2382fa",
    "abstract": "Despite impressive performance for high-level downstream tasks, self-supervised pre-training methods have not yet fully delivered on dense geometric vision tasks such as stereo matching or optical flow. The application of self-supervised concepts, such as instance discrimination or masked image modeling, to geometric tasks is an active area of research. In this work, we build on the recent cross-view completion framework, a variation of masked image modeling that leverages a second view from the same scene which makes it well suited for binocular downstream tasks. The applicability of this concept has so far been limited in at least two ways: (a) by the difficulty of collecting real-world image pairs \u2013 in practice only synthetic data have been used \u2013 and (b) by the lack of generalization of vanilla transformers to dense downstream tasks for which relative position is more meaningful than absolute position. We explore three avenues of improvement. First, we introduce a method to collect suitable real-world image pairs at large scale. Second, we experiment with relative positional embeddings and show that they enable vision transformers to perform substantially better. Third, we scale up vision transformer based cross-completion architectures, which is made possible by the use of large amounts of data. With these improvements, we show for the first time that state-of-the-art results on stereo matching and optical flow can be reached without using any classical task-specific techniques like correlation volume, iterative estimation, image warping or multi-scale reasoning, thus paving the way towards universal vision models.",
    "authors": [
        "Philippe Weinzaepfel",
        "Thomas Lucas",
        "Vincent Leroy",
        "Yohann Cabon",
        "Vaibhav Arora",
        "Romain Br'egier",
        "G. Csurka",
        "L. Antsfeld",
        "Boris Chidlovskii",
        "J\u00e9r\u00f4me Revaud"
    ],
    "venue": "IEEE International Conference on Computer Vision",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Improvements are shown for the first time that state-of-the-art results on stereo matching and optical flow can be reached without using any classical task-specific techniques like correlation volume, iterative estimation, image warping or multi-scale reasoning, thus paving the way towards universal vision models."
    },
    "citationCount": 24,
    "influentialCitationCount": 2,
    "code": null,
    "description": null,
    "url": null
}