{
    "acronym": "2567a34501c1b258c102a07e737b87e556af0809",
    "title": "Speech Summarization of Long Spoken Document: Improving Memory Efficiency of Speech/Text Encoders",
    "seed_ids": [
        "longformer",
        "fnet",
        "d8d2e574965fe733eb1416e03df2b5c2914fc530",
        "1f133158a8973fb33fea188f20517cd7e69bfe7f",
        "35a9749df07a2ab97c51af4d260b095b00da7676",
        "925ad2897d1b5decbea320d07e99afa9110e09b2"
    ],
    "s2id": "2567a34501c1b258c102a07e737b87e556af0809",
    "abstract": "Speech summarization requires processing several minute-long speech sequences to allow exploiting the whole context of a spoken document. A conventional approach is a cascade of automatic speech recognition (ASR) and text summarization (TS). However, the cascade systems are sensitive to ASR errors. Moreover, the cascade system cannot be optimized for input speech and utilize para-linguistic information. Recently, there has been an increased interest in end-to-end (E2E) approaches optimized to output summaries directly from speech. Such systems can thus mitigate the ASR errors of cascade approaches. However, E2E speech summarization requires massive computational resources because it needs to encode long speech sequences. We propose a speech summarization system that enables E2E summarization from 100 seconds, which is the limit of the conventional method, to up to 10 minutes (i.e., the duration of typical instructional videos on YouTube). However, the modeling capability of this model for minute-long speech sequences is weaker than the conventional approach. We thus exploit auxiliary text information from ASR transcriptions to improve the modeling capabilities. The resultant system consists of a dual speech/text encoder decoder-based summarization system. We perform experiments on the How2 dataset showing the proposed system improved METEOR scores by up to 2.7 points by fully exploiting the long spoken documents.",
    "authors": [
        "Takatomo Kano",
        "A. Ogawa",
        "Marc Delcroix",
        "Roshan Sharma",
        "Kohei Matsuura",
        "Shinji Watanabe"
    ],
    "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a speech summarization system that enables E2E summarization from 100 seconds, which is the limit of the conventional method, to up to 10 minutes (i.e., the duration of typical instructional videos on YouTube), and exploits auxiliary text information from ASR transcriptions to improve the modeling capabilities."
    },
    "citationCount": 6,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}