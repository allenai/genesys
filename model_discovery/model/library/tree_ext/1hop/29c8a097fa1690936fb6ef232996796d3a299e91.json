{
    "acronym": "29c8a097fa1690936fb6ef232996796d3a299e91",
    "title": "Efficient Prompting Methods for Large Language Models: A Survey",
    "seed_ids": [
        "semanticcompress",
        "2f7364d8e5cf94315bf8905f57de9c5543e9a4bf",
        "7bd4ca8706a79983d31ab74e6c79bfdfd949602e",
        "5f19ae1135a9500940978104ec15a5b8751bc7d2",
        "8c62277dada489904a63de4dd87336c27c68fb5e",
        "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4",
        "657329c633709dd1ac34a30d57341b186b1a47c2",
        "29ddc1f43f28af7c846515e32cc167bc66886d0c"
    ],
    "s2id": "29c8a097fa1690936fb6ef232996796d3a299e91",
    "abstract": "Prompting has become a mainstream paradigm for adapting large language models (LLMs) to specific natural language processing tasks. While this approach opens the door to in-context learning of LLMs, it brings the additional computational burden of model inference and human effort of manual-designed prompts, particularly when using lengthy and complex prompts to guide and control the behavior of LLMs. As a result, the LLM field has seen a remarkable surge in efficient prompting methods. In this paper, we present a comprehensive overview of these methods. At a high level, efficient prompting methods can broadly be categorized into two approaches: prompting with efficient computation and prompting with efficient design. The former involves various ways of compressing prompts, and the latter employs techniques for automatic prompt optimization. We present the basic concepts of prompting, review the advances for efficient prompting, and highlight future research directions.",
    "authors": [
        "Kaiyan Chang",
        "Songcheng Xu",
        "Chenglong Wang",
        "Yingfeng Luo",
        "Tong Xiao",
        "Jingbo Zhu"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A comprehensive overview of efficient prompting methods is presented and the basic concepts of prompting are presented, the advances for efficient prompting are reviewed, and future research directions are highlighted."
    },
    "citationCount": 4,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}