{
    "acronym": "ee99f13bbbe4af7172059e4ab1ad28db7962465a",
    "title": "Evaluation of Geographical Distortions in Language Models: A Crucial Step Towards Equitable Representations",
    "seed_ids": [
        "bert",
        "a43a3fadc9190e61b34f59a913f1716e443519e4",
        "2029349c55c1dba3493c5b3bd25152f18ba21ae2"
    ],
    "s2id": "ee99f13bbbe4af7172059e4ab1ad28db7962465a",
    "abstract": "Language models now constitute essential tools for improving efficiency for many professional tasks such as writing, coding, or learning. For this reason, it is imperative to identify inherent biases. In the field of Natural Language Processing, five sources of bias are well-identified: data, annotation, representation, models, and research design. This study focuses on biases related to geographical knowledge. We explore the connection between geography and language models by highlighting their tendency to misrepresent spatial information, thus leading to distortions in the representation of geographical distances. This study introduces four indicators to assess these distortions, by comparing geographical and semantic distances. Experiments are conducted from these four indicators with ten widely used language models. Results underscore the critical necessity of inspecting and rectifying spatial biases in language models to ensure accurate and equitable representations.",
    "authors": [
        "R. Decoupes",
        "R. Interdonato",
        "Mathieu Roche",
        "M. Teisseire",
        "S. Valentin"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The connection between geography and language models is explored by highlighting their tendency to misrepresent spatial information, thus leading to distortions in the representation of geographical distances, by comparing geographical and semantic distances."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}