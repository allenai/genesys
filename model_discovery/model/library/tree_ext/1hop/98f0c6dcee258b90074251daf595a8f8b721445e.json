{
    "acronym": "98f0c6dcee258b90074251daf595a8f8b721445e",
    "title": "End-to-End Attention-based Image Captioning",
    "seed_ids": [
        "longformer",
        "925ad2897d1b5decbea320d07e99afa9110e09b2"
    ],
    "s2id": "98f0c6dcee258b90074251daf595a8f8b721445e",
    "abstract": "In this paper, we address the problem of image captioning specifically for molecular translation where the result would be a predicted chemical notation in InChI format for a given molecular structure. Current approaches mainly follow rule-based or CNN+RNN based methodology. However, they seem to underperform on noisy images and images with small number of distinguishable features. To overcome this, we propose an end-to-end transformer model. When compared to attention-based techniques, our proposed model outperforms on molecular datasets.",
    "authors": [
        "Carola Sundaramoorthy",
        "Lin Ziwen Kelvin",
        "Mahak Sarin",
        "Shubham Gupta"
    ],
    "venue": "arXiv.org",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper proposes an end-to-end transformer model for image captioning specifically for molecular translation where the result would be a predicted chemical notation in InChI format for a given molecular structure."
    },
    "citationCount": 5,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}