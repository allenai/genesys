{
    "acronym": "52bea123acbbefac6ebb3b40b6482465845ef014",
    "title": "ClarET: Pre-training a Correlation-Aware Context-To-Event Transformer for Event-Centric Generation and Classification",
    "seed_ids": [
        "gpt2",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "4d16457cded23bce6eaa91cd17aefd22af2279f0",
        "f48ae425e2567be2d993efcaaf74c2274fc9d7c5",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "52bea123acbbefac6ebb3b40b6482465845ef014",
    "abstract": "Generating new events given context with correlated ones plays a crucial role in many event-centric reasoning tasks. Existing works either limit their scope to specific scenarios or overlook event-level correlations. In this paper, we propose to pre-train a general Correlation-aware context-to-Event Transformer (ClarET) for event-centric reasoning. To achieve this, we propose three novel event-centric objectives, i.e., whole event recovering, contrastive event-correlation encoding and prompt-based event locating, which highlight event-level correlations with effective training. The proposed ClarET is applicable to a wide range of event-centric reasoning scenarios, considering its versatility of (i) event-correlation types (e.g., causal, temporal, contrast), (ii) application formulations (i.e., generation and classification), and (iii) reasoning types (e.g., abductive, counterfactual and ending reasoning). Empirical fine-tuning results, as well as zero- and few-shot learning, on 9 benchmarks (5 generation and 4 classification tasks covering 4 reasoning types with diverse event correlations), verify its effectiveness and generalization ability.",
    "authors": [
        "Yucheng Zhou",
        "Tao Shen",
        "Xiubo Geng",
        "Guodong Long",
        "Daxin Jiang"
    ],
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper proposes to pre-train a general Correlation-aware context-to-Event Transformer (ClarET) for event-centric reasoning, and proposes three novelevent-centric objectives, i.e., whole event recovering, contrastive event-correlation encoding and prompt-based event locating, which highlight event-level correlations with effective training."
    },
    "citationCount": 35,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}