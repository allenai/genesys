{
    "acronym": "470d2f3f92877cba3ec9ce2662737d7d76b33331",
    "title": "WebBrain: Learning to Generate Factually Correct Articles for Queries by Grounding on Large Web Corpus",
    "seed_ids": [
        "gpt2",
        "memcompress",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "0bd5beed98675a63f9207851674d478009549900",
        "7cc730da554003dda77796d2cb4f06da5dfd5592",
        "145b8b5d99a2beba6029418ca043585b90138d12",
        "031e4e43aaffd7a479738dcea69a2d5be7957aa3",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "470d2f3f92877cba3ec9ce2662737d7d76b33331",
    "abstract": "In this paper, we introduce a new NLP task -- generating short factual articles with references for queries by mining supporting evidence from the Web. In this task, called WebBrain, the ultimate goal is to generate a fluent, informative, and factually-correct short article (e.g., a Wikipedia article) for a factual query unseen in Wikipedia. To enable experiments on WebBrain, we construct a large-scale dataset WebBrain-Raw by extracting English Wikipedia articles and their crawlable Wikipedia references. WebBrain-Raw is ten times larger than the previous biggest peer dataset, which can greatly benefit the research community. From WebBrain-Raw, we construct two task-specific datasets: WebBrain-R and WebBrain-G, which are used to train in-domain retriever and generator, respectively. Besides, we empirically analyze the performances of the current state-of-the-art NLP techniques on WebBrain and introduce a new framework ReGen, which enhances the generation factualness by improved evidence retrieval and task-specific pre-training for generation. Experiment results show that ReGen outperforms all baselines in both automatic and human evaluations.",
    "authors": [
        "Hongjin Qian",
        "Yutao Zhu",
        "Zhicheng Dou",
        "Haoqi Gu",
        "Xinyu Zhang",
        "Zheng Liu",
        "Ruofei Lai",
        "Zhao Cao",
        "J. Nie",
        "Ji-rong Wen"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A new framework ReGen is introduced, which enhances the generation factualness by improved evidence retrieval and task-specific pre-training for generation, which outperforms all baselines in both automatic and human evaluations."
    },
    "citationCount": 16,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}