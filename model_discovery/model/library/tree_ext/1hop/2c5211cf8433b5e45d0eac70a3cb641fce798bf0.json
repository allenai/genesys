{
    "acronym": "2c5211cf8433b5e45d0eac70a3cb641fce798bf0",
    "title": "An In-depth Investigation of User Response Simulation for Conversational Search",
    "seed_ids": [
        "gpt2",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "ca545ceefe7c3535ffea0fbcc1cc86bddced3767",
        "d0086b86103a620a86bc918746df0aa642e2a8a3",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "2c5211cf8433b5e45d0eac70a3cb641fce798bf0",
    "abstract": "Conversational search has seen increased recent attention in both the IR and NLP communities. It seeks to clarify and solve users' search needs through multi-turn natural language interactions. However, most existing systems are trained and demonstrated with recorded or artificial conversation logs. Eventually, conversational search systems should be trained, evaluated, and deployed in an open-ended setting with unseen conversation trajectories. A key challenge is that training and evaluating such systems both require a human-in-the-loop, which is expensive and does not scale. One strategy is to simulate users, thereby reducing the scaling costs. However, current user simulators are either limited to only responding to yes-no questions from the conversational search system or unable to produce high-quality responses in general. This paper shows that existing user simulation systems could be significantly improved by a smaller finetuned natural language generation model. However, rather than merely reporting it as the new state-of-the-art, we consider it a strong baseline and present an in-depth investigation of simulating user response for conversational search. Our goal is to supplement existing work with an insightful hand-analysis of unsolved challenges by the baseline and propose our solutions. The challenges we identified include (1) a blind spot that is difficult to learn, and (2) a specific type of misevaluation in the standard setup. We propose a new generation system to effectively cover the training blind spot and suggest a new evaluation setup to avoid misevaluation. Our proposed system leads to significant improvements over existing systems and large language models such as GPT-4. Additionally, our analysis provides insights into the nature of the task to facilitate future work.",
    "authors": [
        "Zhenduo Wang",
        "Zhichao Xu",
        "Qingyao Ai",
        "Vivek Srikumar"
    ],
    "venue": "The Web Conference",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper shows that existing user simulation systems could be significantly improved by a smaller finetuned natural language generation model and proposes a new generation system to effectively cover the training blind spot and suggest a new evaluation setup to avoid misevaluation."
    },
    "citationCount": 7,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}