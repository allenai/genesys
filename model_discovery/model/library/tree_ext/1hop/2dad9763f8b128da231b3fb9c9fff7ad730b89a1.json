{
    "acronym": "2dad9763f8b128da231b3fb9c9fff7ad730b89a1",
    "title": "Long-Range Language Modeling with Selective Cache",
    "seed_ids": [
        "transformerxl",
        "compressivetransformer",
        "f75d05e759447c2aedb7097728f29f9a520d9bc1",
        "dbf53ece1a6a8860e41ff5f721c72ceb0fb18dd6",
        "5d032bd2632b6f5847767f39ce247098c6bbc563",
        "64a29bee2e1ad29547d590a3cc26274f4c537145",
        "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
        "d27669c82faf78ea08cceaa0a171b540cccc304d",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "657329c633709dd1ac34a30d57341b186b1a47c2",
        "f51497f463566581874c941353dd9d80069c5b77",
        "f6390beca54411b06f3bde424fb983a451789733",
        "f4238bd2385a52413ccbacfd9e409a650235bd13"
    ],
    "s2id": "2dad9763f8b128da231b3fb9c9fff7ad730b89a1",
    "abstract": ",",
    "authors": [
        "Xinting Huang",
        "Nora Hollenstein"
    ],
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": null
    },
    "citationCount": 3,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}