{
    "acronym": "c734fdbb873e50e0a6e4e857b9c0ce5ff97a02e8",
    "title": "Multimodal Contextual Dialogue Breakdown Detection for Conversational AI Models",
    "seed_ids": [
        "gpt3"
    ],
    "s2id": "c734fdbb873e50e0a6e4e857b9c0ce5ff97a02e8",
    "abstract": "Detecting dialogue breakdown in real time is critical for conversational AI systems, because it enables taking corrective action to successfully complete a task. In spoken dialog systems, this breakdown can be caused by a variety of unexpected situations including high levels of background noise, causing STT mistranscriptions, or unexpected user flows. In particular, industry settings like healthcare, require high precision and high flexibility to navigate differently based on the conversation history and dialogue states. This makes it both more challenging and more critical to accurately detect dialog breakdown. To accurately detect breakdown, we found it requires processing audio inputs along with downstream NLP model inferences on transcribed text in real time. In this paper, we introduce a Multimodal Contextual Dialogue Breakdown (MultConDB) model. This model significantly outperforms other known best models by achieving an F1 of 69.27.",
    "authors": [
        "Md Messal Monem Miah",
        "Ulie Schnaithmann",
        "Arushi Raghuvanshi",
        "Youngseo Son"
    ],
    "venue": "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 6: Industry Track)",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This model significantly outperforms other known best models by achieving an F1 of 69.27, and requires processing audio inputs along with downstream NLP model inferences on transcribed text in real time."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}