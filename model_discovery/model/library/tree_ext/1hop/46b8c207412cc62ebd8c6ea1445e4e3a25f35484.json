{
    "acronym": "46b8c207412cc62ebd8c6ea1445e4e3a25f35484",
    "title": "Applying Transformer-XL to Q & A",
    "seed_ids": [
        "transformerxl"
    ],
    "s2id": "46b8c207412cc62ebd8c6ea1445e4e3a25f35484",
    "abstract": "In this paper, we first re-implement QANet [1], a architecture highly inspired by the transformer model [2]. Then by making adjustments to incorporate elements of Transformer-XL and other high performing SQuAD models, we were able to achieve a modest performance gain on SQuAD 2.0. Overall, we were able to achieve a final EM and F1 test score of 64.379 and 68.108 [None PCE]. In order to make the features of Transformer-XL compatible with the task of Q&A, we shared memory between question passage pairs.",
    "authors": [
        "Sam Xu"
    ],
    "venue": "",
    "year": 2019,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "In order to make the features of Transformer-XL compatible with the task of Q&A, the architecture was re-implemented and shared memory between question passage pairs to achieve a modest performance gain on SQuAD 2.0."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}