{
    "acronym": "ef91db28bc3c301e3d8ef91b361178dbad54c1c1",
    "title": "Credit Risk Meets Large Language Models: Building a Risk Indicator from Loan Descriptions in P2P Lending",
    "seed_ids": [
        "bert",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "a022bda79947d1f656a1164003c1b3ae9a843df9",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "ef91db28bc3c301e3d8ef91b361178dbad54c1c1",
    "abstract": "Peer-to-peer (P2P) lending has emerged as a distinctive financing mechanism, linking borrowers with lenders through online platforms. However, P2P lending faces the challenge of information asymmetry, as lenders often lack sufficient data to assess the creditworthiness of borrowers. This paper proposes a novel approach to address this issue by leveraging the textual descriptions provided by borrowers during the loan application process. Our methodology involves processing these textual descriptions using a Large Language Model (LLM), a powerful tool capable of discerning patterns and semantics within the text. Transfer learning is applied to adapt the LLM to the specific task at hand. Our results derived from the analysis of the Lending Club dataset show that the risk score generated by BERT, a widely used LLM, significantly improves the performance of credit risk classifiers. However, the inherent opacity of LLM-based systems, coupled with uncertainties about potential biases, underscores critical considerations for regulatory frameworks and engenders trust-related concerns among end-users, opening new avenues for future research in the dynamic landscape of P2P lending and artificial intelligence.",
    "authors": [
        "Mario Sanz-Guerrero",
        "Javier Arroyo"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel approach to address the challenge of information asymmetry in P2P lending by leveraging the textual descriptions provided by borrowers during the loan application process, using a Large Language Model (LLM)."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}