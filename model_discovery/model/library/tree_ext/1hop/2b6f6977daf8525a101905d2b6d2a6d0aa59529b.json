{
    "acronym": "2b6f6977daf8525a101905d2b6d2a6d0aa59529b",
    "title": "Decoding Global Preferences: Temporal and Cooperative Dependency Modeling in Multi-Agent Preference-Based Reinforcement Learning",
    "seed_ids": [
        "transformer",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "053b1d7b97eb2c91fc3921d589c160b0923c70b1",
        "59a916cdc943f0282908e6f3fa0360f4c5fb78d0"
    ],
    "s2id": "2b6f6977daf8525a101905d2b6d2a6d0aa59529b",
    "abstract": "Designing accurate reward functions for reinforcement learning (RL) has long been challenging. Preference-based RL (PbRL) offers a promising approach by using human preferences\nto train agents, eliminating the need for manual reward design. While successful in single-agent tasks, extending PbRL to complex multi-agent scenarios is nontrivial. Existing PbRL methods lack the capacity to comprehensively capture both temporal and cooperative aspects, leading to inadequate reward functions. This work introduces an advanced multi-agent preference learning framework that effectively addresses these limitations. Based on a cascading Transformer architecture, our approach captures both temporal and cooperative dependencies, alleviating issues related to reward uniformity and intricate interactions among agents. Experimental results demonstrate substantial performance improvements in multi-agent cooperative tasks, and the reconstructed reward function closely resembles expert-defined reward functions. The source code is available at https://github.com/catezi/MAPT.",
    "authors": [
        "Tianchen Zhu",
        "Yue Qiu",
        "Haoyi Zhou",
        "Jianxin Li"
    ],
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Based on a cascading Transformer architecture, this work introduces an advanced multi-agent preference learning framework that effectively addresses limitations in PbRL, alleviating issues related to reward uniformity and intricate interactions among agents."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}