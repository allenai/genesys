{
    "acronym": "1f479fe113b0a4a5d6da08e0632395d3273fd3dd",
    "title": "InsNet: An Efficient, Flexible, and Performant Insertion-based Text Generation Model",
    "seed_ids": [
        "transformerxl",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "1f479fe113b0a4a5d6da08e0632395d3273fd3dd",
    "abstract": "We propose InsNet, an expressive insertion-based text generator with efficient training and flexible decoding (parallel or sequential). Unlike most existing insertion-based text generation works that require re-encoding of the context after each insertion operation and thus are inefficient to train, InsNet only requires one pass of context encoding for the entire sequence during training by introducing a novel insertion-oriented position encoding and a light-weighted slot representation strategy to enable computation sharing. Furthermore, we propose an algorithm InsNet-Dinic to better determine the parallelization of insertion operations that provides a controllable switch between parallel and sequential decoding, making it flexible to handle more parallelizable tasks such as machine translation with efficient decoding, or less parallelizable tasks such as open-domain text generation to guarantee high-quality outputs. Experiments on two lexically constrained text generation datasets and three machine translation datasets demonstrate InsNet's advantages over previous insertion-based methods in terms of training speed, inference efficiency, and generation quality.",
    "authors": [
        "Sidi Lu",
        "Tao Meng",
        "Nanyun Peng"
    ],
    "venue": "Neural Information Processing Systems",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Experiments on two lexically constrained text generation datasets and three machine translation datasets demonstrate InsNet's advantages over previous insertion-based methods in terms of training speed, inference efficiency, and generation quality."
    },
    "citationCount": 11,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}