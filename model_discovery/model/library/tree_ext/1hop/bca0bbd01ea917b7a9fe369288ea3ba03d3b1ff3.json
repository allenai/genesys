{
    "acronym": "bca0bbd01ea917b7a9fe369288ea3ba03d3b1ff3",
    "title": "A Survey of Large Language Models in Medicine: Progress, Application, and Challenge",
    "seed_ids": [
        "gpt3",
        "bert",
        "6bdfffbf92d01c8b543088d40d46233610e469a8",
        "44d16a076c00ecada3d425203377e4ec951c4ed0",
        "daaa7d4ffb9265226e4baadd2db9a01aa7b2f6fb",
        "9c5609baff6175b0a2e436bb69e89737c4be3cf4",
        "8e6c4425e48b09d64827c64d8de0008f41f9be54",
        "5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0",
        "94ce1d5924e05e8d75e43ce70044293ddcef850a",
        "848909fbae167f21589bfc7a54fbf27e306b883c",
        "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d",
        "1d26c947406173145a4665dd7ab255e03494ea28",
        "44279244407a64431810f982be6d0c7da4429dd7",
        "b21670e8061a06ab97e7d6052c9345a326e84ff8",
        "5f19ae1135a9500940978104ec15a5b8751bc7d2",
        "e96493b4181de6c60b761dc66492db8e66fd784f",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "b15469d0ab3dc3a9dec037d761817b3fe546bed6",
        "50796b0f3edf9cb5ff1e447c298b33755378aa4f",
        "4e767b191683dca0ea6d33216508159886144da4",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "031e4e43aaffd7a479738dcea69a2d5be7957aa3",
        "29ddc1f43f28af7c846515e32cc167bc66886d0c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "bca0bbd01ea917b7a9fe369288ea3ba03d3b1ff3",
    "abstract": "Large language models (LLMs), such as ChatGPT, have received substantial attention due to their capabilities for understanding and generating human language. While there has been a burgeoning trend in research focusing on the employment of LLMs in supporting different medical tasks (e.g., enhancing clinical diagnostics and providing medical education), a review of these efforts, particularly their development, practical applications, and outcomes in medicine, remains scarce. Therefore, this review aims to provide a detailed overview of the development and deployment of LLMs in medicine, including the challenges and opportunities they face. In terms of development, we provide a detailed introduction to the principles of existing medical LLMs, including their basic model structures, number of parameters, and sources and scales of data used for model development. It serves as a guide for practitioners in developing medical LLMs tailored to their specific needs. In terms of deployment, we offer a comparison of the performance of different LLMs across various medical tasks, and further compare them with state-of-the-art lightweight models, aiming to provide an understanding of the advantages and limitations of LLMs in medicine. Overall, in this review, we address the following questions: 1) What are the practices for developing medical LLMs 2) How to measure the medical task performance of LLMs in a medical setting? 3) How have medical LLMs been employed in real-world practice? 4) What challenges arise from the use of medical LLMs? and 5) How to more effectively develop and deploy medical LLMs? By answering these questions, this review aims to provide insights into the opportunities for LLMs in medicine and serve as a practical resource. We also maintain a regularly updated list of practical guides on medical LLMs at https://github.com/AI-in-Health/MedLLMsPracticalGuide",
    "authors": [
        "Hongjian Zhou",
        "Boyang Gu",
        "Xinyu Zou",
        "Yiru Li",
        "Sam S. Chen",
        "Peilin Zhou",
        "Junling Liu",
        "Y. Hua",
        "Chengfeng Mao",
        "Xian Wu",
        "Zheng Li",
        "Fenglin Liu"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A detailed overview of the development and deployment of LLMs in medicine, including the challenges and opportunities they face, is provided and a detailed introduction to the principles of existing medical LLMs are provided, including their basic model structures, number of parameters, and sources and scales of data used for model development."
    },
    "citationCount": 41,
    "influentialCitationCount": 2,
    "code": null,
    "description": null,
    "url": null
}