{
    "acronym": "af04d2d2c00a7cdedf5260d49858fb5d4debe2ef",
    "title": "LegalDuet: Learning Effective Representations for Legal Judgment Prediction through a Dual-View Legal Clue Reasoning",
    "seed_ids": [
        "bert",
        "0f655ded8a5e0a1e3770f59b9eadb7f68065f7d7",
        "1e3e65e7773b7869d9bd7f5394b54199e48195e6",
        "8382402fe166df3de499dac182e42baa51335926"
    ],
    "s2id": "af04d2d2c00a7cdedf5260d49858fb5d4debe2ef",
    "abstract": "Most existing Legal Judgment Prediction (LJP) models focus on discovering the legal triggers in the criminal fact description. However, in real-world scenarios, a professional judge not only needs to assimilate the law case experience that thrives on past sentenced legal judgments but also depends on the professional legal grounded reasoning that learned from professional legal knowledge. In this paper, we propose a LegalDuet model, which pretrains language models to learn a tailored embedding space for making legal judgments. It proposes a dual-view legal clue reasoning mechanism, which derives from two reasoning chains of judges: 1) Law Case Reasoning, which makes legal judgments according to the judgment experiences learned from analogy/confusing legal cases; 2) Legal Ground Reasoning, which lies in matching the legal clues between criminal cases and legal decisions. Our experiments show that LegalDuet achieves state-of-the-art performance on the CAIL2018 dataset and outperforms baselines with about 4% improvements on average. Our dual-view reasoning based pretraining can capture critical legal clues to learn a tailored embedding space to distinguish criminal cases. It reduces LegalDuet's uncertainty during prediction and brings pretraining advances to the confusing/low frequent charges. All codes are available at https://github.com/NEUIR/LegalDuet.",
    "authors": [
        "Pengjie Liu",
        "Zhenghao Liu",
        "Xiaoyuan Yi",
        "Liner Yang",
        "Shuo Wang",
        "Yu Gu",
        "Ge Yu",
        "Xing Xie",
        "Shuang-hua Yang"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A LegalDuet model, which pretrains language models to learn a tailored embedding space for making legal judgments and reduces LegalDuet's uncertainty during prediction and brings pretraining advances to the confusing/low frequent charges."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}