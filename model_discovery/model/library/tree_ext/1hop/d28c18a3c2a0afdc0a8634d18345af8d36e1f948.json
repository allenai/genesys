{
    "acronym": "d28c18a3c2a0afdc0a8634d18345af8d36e1f948",
    "title": "A Constructive Prediction of the Generalization Error Across Scales",
    "seed_ids": [
        "transformerxl"
    ],
    "s2id": "d28c18a3c2a0afdc0a8634d18345af8d36e1f948",
    "abstract": "The dependency of the generalization error of neural networks on model and dataset size is of critical importance both in practice and for understanding the theory of neural networks. Nevertheless, the functional form of this dependency remains elusive. In this work, we present a functional form which approximates well the generalization error in practice. Capitalizing on the successful concept of model scaling (e.g., width, depth), we are able to simultaneously construct such a form and specify the exact models which can attain it across model/data scales. Our construction follows insights obtained from observations conducted over a range of model/data scales, in various model types and datasets, in vision and language tasks. We show that the form both fits the observations well across scales, and provides accurate predictions from small- to large-scale models and data.",
    "authors": [
        "Jonathan S. Rosenfeld",
        "Amir Rosenfeld",
        "Yonatan Belinkov",
        "N. Shavit"
    ],
    "venue": "International Conference on Learning Representations",
    "year": 2019,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work presents a functional form which approximates well the generalization error in practice, and shows that the form both fits the observations well across scales, and provides accurate predictions from small- to large-scale models and data."
    },
    "citationCount": 159,
    "influentialCitationCount": 13,
    "code": null,
    "description": null,
    "url": null
}