{
    "acronym": "b46d3fcbbe2768ff2ab0e5d9c1e24c9716d986e8",
    "title": "RSTIE-KGC: A Relation Sensitive Textual Information Enhanced Knowledge Graph Completion Model",
    "seed_ids": [
        "bert",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481"
    ],
    "s2id": "b46d3fcbbe2768ff2ab0e5d9c1e24c9716d986e8",
    "abstract": "Nowadays, many knowledge graph completion models are proposed to assist the automatic construction of large knowledge graphs. While knowledge graph embedding models and textual information enhanced models are two tendencies in this area, they both suffer from some shortcomings, for example, relying too much on one single modal information may cause the limitation of performance. However, only a few works attempt to integrate multiple modalities. Besides, we found that the semantic similarity between head and tail entities correlates to the enhancing effect of textual information, and the semantic similarity is also related to relation types. We call this phenomenon relational sensitivity. To address these issues, we propose a relation sensitive textual information enhanced knowledge graph completion model (RSTIE-KGC). In our work, by integrating pre-trained language models (PLM) with knowledge graph embedding models, we fuse structural information and textual information, taking advantage of both topological and semantic features. Instead of finetuning the whole PLMs as existing models do, we choose a more efficient way, using frozen PLMs followed by an adapter to fit the text embeddings to our tasks, so that we can reduce training costs and enlarge the scale of negative samples, which maintains accuracy and effectiveness of our model. Based on the relational sensitivity, we propose our RelRank block, which selectively enhances textual information by calculating and filtering mean rank proportion (MRP) score for each relation type, thereby making better use of beneficial semantic information and reducing the noise and redundancy caused by textual information. The prediction process makes more refined use of textual information, as a result improving the accuracy of the model in the link prediction task. We conducted link prediction experiments on two real-world datasets. On FB15k-237, our model outperformed the current state-of-art textual information enhanced models in both MRR and Hit@k metrics. On WN18RR, our model also showed a stable prediction performance, and the results of both MRR and Hits@1 metrics were better than the most textual information enhanced models.",
    "authors": [
        "Wenyue Li",
        "Sapae Phyu",
        "Qin Liu",
        "Bowen Du",
        "Junyan Zhang",
        "Hongming Zhu"
    ],
    "venue": "International Conference on Computer Supported Cooperative Work in Design",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A relation sensitive textual information enhanced knowledge graph completion model (RSTIE-KGC) is proposed, by integrating pre-trained language models (PLM) with knowledge graph embedding models, which fuse structural information and textual information, taking advantage of both topological and semantic features."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}