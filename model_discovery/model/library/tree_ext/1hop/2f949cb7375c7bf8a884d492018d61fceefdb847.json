{
    "acronym": "2f949cb7375c7bf8a884d492018d61fceefdb847",
    "title": "Distractor Generation for Multiple-Choice Questions: A Survey of Methods, Datasets, and Evaluation",
    "seed_ids": [
        "bert",
        "975620e31d43bc5ff38e6f9b370f54df7926d145",
        "1d0bf6b0ddcbd8bce7b7a930d88ff922e5c55cea",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "6ff68b34a5f78bdd14437fe5a79aebbc42c26467",
        "c21a4d70d83e0f6eb2a9e1c41d034842dd561e47",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "2f949cb7375c7bf8a884d492018d61fceefdb847",
    "abstract": "Distractors are important in learning evaluation. This paper surveys distractor generation tasks using English multiple-choice question datasets for textual and multimodal contexts. In particular, this paper presents a thorough literature review of the recent studies on distractor generation tasks, discusses multiple choice components and their characteristics, analyzes the related datasets, and summarizes the evaluation metrics of distractor generation. Our investigation reveals that more than half of datasets are human-generated from educational sources in specific domains such as Science and English, which are largely text-based, with a lack of open domain and multimodal datasets.",
    "authors": [
        "Elaf Alhazmi",
        "Quan Z. Sheng",
        "W. Zhang",
        "Munazza Zaib",
        "A. Alhazmi"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is revealed that more than half of datasets are human-generated from educational sources in specific domains such as Science and English, which are largely text-based, with a lack of open domain and multimodal datasets."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}