{
    "acronym": "5ebcf1ed7765441dcc719c9f877d20a35224f340",
    "title": "Holmes: Benchmark the Linguistic Competence of Language Models",
    "seed_ids": [
        "bert",
        "7f94b69cac02fdd113385950297fcdbfbe3413ee",
        "be55e8ec4213868db08f2c3168ae666001bea4b8",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "5a2263092f49540fd0e049050a96882ff29b00c3",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "d0086b86103a620a86bc918746df0aa642e2a8a3",
        "e2587eddd57bc4ba286d91b27c185083f16f40ee",
        "d9f6ada77448664b71128bb19df15765336974a6",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "5ebcf1ed7765441dcc719c9f877d20a35224f340",
    "abstract": "We introduce Holmes, a benchmark to assess the linguistic competence of language models (LMs) - their ability to grasp linguistic phenomena. Unlike prior prompting-based evaluations, Holmes assesses the linguistic competence of LMs via their internal representations using classifier-based probing. In doing so, we disentangle specific phenomena (e.g., part-of-speech of words) from other cognitive abilities, like following textual instructions, and meet recent calls to assess LMs' linguistic competence in isolation. Composing Holmes, we review over 250 probing studies and feature more than 200 datasets to assess syntax, morphology, semantics, reasoning, and discourse phenomena. Analyzing over 50 LMs reveals that, aligned with known trends, their linguistic competence correlates with model size. However, surprisingly, model architecture and instruction tuning also significantly influence performance, particularly in morphology and syntax. Finally, we propose FlashHolmes, a streamlined version of Holmes designed to lower the high computation load while maintaining high-ranking precision.",
    "authors": [
        "Andreas Waldis",
        "Yotam Perlitz",
        "Leshem Choshen",
        "Yufang Hou",
        "Iryna Gurevych"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Holmes, a benchmark to assess the linguistic competence of language models (LMs) - their ability to grasp linguistic phenomena, is introduced and it is revealed that, aligned with known trends, their linguistic competence correlates with model size."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}