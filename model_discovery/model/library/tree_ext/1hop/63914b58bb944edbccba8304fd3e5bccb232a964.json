{
    "acronym": "63914b58bb944edbccba8304fd3e5bccb232a964",
    "title": "MEND: Meta dEmonstratioN Distillation for Efficient and Effective In-Context Learning",
    "seed_ids": [
        "gpt2",
        "13a0d8bb38f739990c8cd65a44061c6534f17221",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "63914b58bb944edbccba8304fd3e5bccb232a964",
    "abstract": "Large Language models (LLMs) have demonstrated impressive in-context learning (ICL) capabilities, where a LLM makes predictions for a given test input together with a few input-output pairs (demonstrations). Nevertheless, the inclusion of demonstrations leads to a quadratic increase in the computational overhead of the self-attention mechanism. Existing solutions attempt to distill lengthy demonstrations into compact vectors. However, they often require task-specific retraining or compromise LLM's in-context learning performance. To mitigate these challenges, we present Meta dEmonstratioN Distillation (MEND), where a language model learns to distill any lengthy demonstrations into vectors without retraining for a new downstream task. We exploit the knowledge distillation to enhance alignment between MEND and LLM, achieving both efficiency and effectiveness simultaneously. MEND is endowed with the meta-knowledge of distilling demonstrations through a two-stage training process, which includes meta-distillation pretraining and fine-tuning. Comprehensive evaluations across seven diverse ICL task partitions using decoder-only (GPT-2) and encoder-decoder (T5) attest to MEND's prowess. It not only matches but often outperforms the Vanilla ICL as well as other state-of-the-art distillation models, while significantly reducing the computational demands. This innovation promises enhanced scalability and efficiency for the practical deployment of large language models",
    "authors": [
        "Yichuan Li",
        "Xiyao Ma",
        "Sixing Lu",
        "Kyumin Lee",
        "Xiaohu Liu",
        "Chenlei Guo"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Meta dEmonstratioN Distillation (MEND) is presented, where a language model learns to distill any lengthy demonstrations into vectors without retraining for a new downstream task, and promises enhanced scalability and efficiency for the practical deployment of large language models."
    },
    "citationCount": 1,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}