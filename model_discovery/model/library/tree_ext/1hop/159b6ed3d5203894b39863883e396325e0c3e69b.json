{
    "acronym": "159b6ed3d5203894b39863883e396325e0c3e69b",
    "title": "Improved Active Multi-Task Representation Learning via Lasso",
    "seed_ids": [
        "gpt2",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "159b6ed3d5203894b39863883e396325e0c3e69b",
    "abstract": "To leverage the copious amount of data from source tasks and overcome the scarcity of the target task samples, representation learning based on multi-task pretraining has become a standard approach in many applications. However, up until now, most existing works design a source task selection strategy from a purely empirical perspective. Recently, \\citet{chen2022active} gave the first active multi-task representation learning (A-MTRL) algorithm which adaptively samples from source tasks and can provably reduce the total sample complexity using the L2-regularized-target-source-relevance parameter $\\nu^2$. But their work is theoretically suboptimal in terms of total source sample complexity and is less practical in some real-world scenarios where sparse training source task selection is desired. In this paper, we address both issues. Specifically, we show the strict dominance of the L1-regularized-relevance-based ($\\nu^1$-based) strategy by giving a lower bound for the $\\nu^2$-based strategy. When $\\nu^1$ is unknown, we propose a practical algorithm that uses the LASSO program to estimate $\\nu^1$. Our algorithm successfully recovers the optimal result in the known case. In addition to our sample complexity results, we also characterize the potential of our $\\nu^1$-based strategy in sample-cost-sensitive settings. Finally, we provide experiments on real-world computer vision datasets to illustrate the effectiveness of our proposed method.",
    "authors": [
        "Yiping Wang",
        "Yifang Chen",
        "Kevin G. Jamieson",
        "S. Du"
    ],
    "venue": "International Conference on Machine Learning",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The strict dominance of the L1-regularized-relevance-based ($\\nu^1$-based) strategy is shown by giving a lower bound for the $\\nu^2$- based strategy and a practical algorithm is proposed that uses the LASSO program to estimate $\\nu*1$ and recovers the optimal result in the known case."
    },
    "citationCount": 8,
    "influentialCitationCount": 2,
    "code": null,
    "description": null,
    "url": null
}