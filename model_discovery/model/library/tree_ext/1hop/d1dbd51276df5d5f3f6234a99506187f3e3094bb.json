{
    "acronym": "d1dbd51276df5d5f3f6234a99506187f3e3094bb",
    "title": "Megapixel Image Generation with Step-Unrolled Denoising Autoencoders",
    "seed_ids": [
        "roformer",
        "hierarchitrans",
        "231e768f0cd280faa0f725bb353262cb4fed08d1",
        "599bc7cfe98c2b57ddbe111412203a636da57be0",
        "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4",
        "bc519f58ae61afbf6318d6e4239d2d565c7ba467",
        "2cd605106b88c85d7d8b865b1ef0f8c8293debf1",
        "6fa1cfc4f97f03a8485692418c7aa1a06c574a85"
    ],
    "s2id": "d1dbd51276df5d5f3f6234a99506187f3e3094bb",
    "abstract": "An ongoing trend in generative modelling research has been to push sample resolutions higher whilst simultaneously reducing computational requirements for training and sampling. We aim to push this trend further via the combination of techniques - each component representing the current pinnacle of efficiency in their respective areas. These include vector-quantized GAN (VQ-GAN), a vector-quantization (VQ) model capable of high levels of lossy - but perceptually insignificant - compression; hourglass transformers, a highly scaleable self-attention model; and step-unrolled denoising autoencoders (SUNDAE), a non-autoregressive (NAR) text generative model. Unexpectedly, our method highlights weaknesses in the original formulation of hourglass transformers when applied to multidimensional data. In light of this, we propose modifications to the resampling mechanism, applicable in any task applying hierarchical transformers to multidimensional data. Additionally, we demonstrate the scalability of SUNDAE to long sequence lengths - four times longer than prior work. Our proposed framework scales to high-resolutions ($1024 \\times 1024$) and trains quickly (2-4 days). Crucially, the trained model produces diverse and realistic megapixel samples in approximately 2 seconds on a consumer-grade GPU (GTX 1080Ti). In general, the framework is flexible: supporting an arbitrary number of sampling steps, sample-wise self-stopping, self-correction capabilities, conditional generation, and a NAR formulation that allows for arbitrary inpainting masks. We obtain FID scores of 10.56 on FFHQ256 - close to the original VQ-GAN in less than half the sampling steps - and 21.85 on FFHQ1024 in only 100 sampling steps.",
    "authors": [
        "Alex F. McKinney",
        "Chris G. Willcocks"
    ],
    "venue": "arXiv.org",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes modifications to the resampling mechanism, applicable in any task applying hierarchical transformers to multidimensional data, and demonstrates the scalability of SUNDAE to long sequence lengths - four times longer than prior work."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}