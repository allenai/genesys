{
    "acronym": "d9d8aef662bb7a3730a62b1015c3ed99e4287523",
    "title": "On the Transformations across Reward Model, Parameter Update, and In-Context Prompt",
    "seed_ids": [
        "gpt3",
        "2d77b7203824e617206634277bce7eec2b71a2bd",
        "53a803388e83ae89261624099d7be4287ace67cb",
        "d8b51d518f2dd62943762ceaa8961d3b1bfbcc1a",
        "5215a3cfd67fdc6eb0201822dd0004bd4b830f91",
        "1671d70a135b1e28b3a9cbc830feaa9b0c57df32",
        "525d93a382f6e7873b5d8a2e0713eb3dff7fb250",
        "023edab4738690444e3924e224c2641017a0d794",
        "5f19ae1135a9500940978104ec15a5b8751bc7d2",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "29ddc1f43f28af7c846515e32cc167bc66886d0c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "d9d8aef662bb7a3730a62b1015c3ed99e4287523",
    "abstract": "Despite the general capabilities of pre-trained large language models (LLMs), they still need further adaptation to better serve practical applications. In this paper, we demonstrate the interchangeability of three popular and distinct adaptation tools: parameter updating, reward modeling, and in-context prompting. This interchangeability establishes a triangular framework with six transformation directions, each of which facilitates a variety of applications. Our work offers a holistic view that unifies numerous existing studies and suggests potential research directions. We envision our work as a useful roadmap for future research on LLMs.",
    "authors": [
        "Deng Cai",
        "Huayang Li",
        "Tingchen Fu",
        "Siheng Li",
        "Weiwen Xu",
        "Shuaiyi Li",
        "Bowen Cao",
        "Zhisong Zhang",
        "Xinting Huang",
        "Leyang Cui",
        "Yan Wang",
        "Lemao Liu",
        "Taro Watanabe",
        "Shuming Shi"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper demonstrates the interchangeability of three popular and distinct adaptation tools: parameter updating, reward modeling, and in-context prompting, which establishes a triangular framework with six transformation directions, each of which facilitates a variety of applications."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}