{
    "acronym": "7c32ee2b5523514ecd82b1fe268f652e120505ab",
    "title": "Detecting Conceptual Abstraction in LLMs",
    "seed_ids": [
        "transformer"
    ],
    "s2id": "7c32ee2b5523514ecd82b1fe268f652e120505ab",
    "abstract": "We show a novel approach to detecting noun abstraction within a large language model (LLM). Starting from a psychologically motivated set of noun pairs in taxonomic relationships, we instantiate surface patterns indicating hypernymy and analyze the attention matrices produced by BERT. We compare the results to two sets of counterfactuals and show that we can detect hypernymy in the abstraction mechanism, which cannot solely be related to the distributional similarity of noun pairs. Our findings are a first step towards the explainability of conceptual abstraction in LLMs.",
    "authors": [
        "Michaela Regneri",
        "Alhassan Abdelhalim",
        "Soren Laue"
    ],
    "venue": "International Conference on Language Resources and Evaluation",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel approach to detecting noun abstraction within a large language model (LLM) is shown, starting from a psychologically motivated set of noun pairs in taxonomic relationships and analyzing the attention matrices produced by BERT."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}