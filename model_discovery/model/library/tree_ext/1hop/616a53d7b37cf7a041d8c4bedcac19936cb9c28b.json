{
    "acronym": "616a53d7b37cf7a041d8c4bedcac19936cb9c28b",
    "title": "Impact of Position Bias on Language Models in Token Classification",
    "seed_ids": [
        "transformerxl",
        "b5416fc248f3dbcece522ef59f571a1f56e5e9a4",
        "964bd39b546f0f6625ff3b9ef1083f797807ef2e",
        "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4",
        "4889ba5a8ae8b2169dd44d1d3a605bf9820bae8d",
        "84476fdf6ead3553f4493dff8e02308439d6222b",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "616a53d7b37cf7a041d8c4bedcac19936cb9c28b",
    "abstract": "Language Models (LMs) have shown state-of-the-art performance in Natural Language Processing (NLP) downstream tasks such as Named Entity Recognition (NER) or Part-of-Speech (POS) tagging. Those tasks are known to suffer from data imbalance issues, particularly regarding the ratio of positive to negative examples and class disparities. This paper investigates an often-overlooked issue of encoder models, specifically the position bias of positive examples in token classification. We propose an evaluation approach to investigate position bias in transformer models with different position embedding techniques. We show that LMs can suffer from this bias with an average drop in performance ranging from 3% to 5%. We propose two methods: Random Position Shifting and Context Perturbation, that we apply on batches during the training process. The results show an improvement of \u2248 2% in the performance of the model on CoNLL03, UD_en, and TweeBank.",
    "authors": [
        "Mehdi Ben Amor",
        "M. Granitzer",
        "Jelena Mitrovi'c"
    ],
    "venue": "ACM Symposium on Applied Computing",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper investigates an often-overlooked issue of encoder models, specifically the position bias of positive examples in token classification, and proposes an evaluation approach to investigate position bias in transformer models with different position embedding techniques."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}