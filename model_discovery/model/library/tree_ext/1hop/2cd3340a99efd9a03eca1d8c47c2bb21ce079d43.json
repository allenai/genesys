{
    "acronym": "2cd3340a99efd9a03eca1d8c47c2bb21ce079d43",
    "title": "Pillar Attention Encoder for Adaptive Cooperative Perception",
    "seed_ids": [
        "transformer"
    ],
    "s2id": "2cd3340a99efd9a03eca1d8c47c2bb21ce079d43",
    "abstract": "Interest in cooperative perception (CP) is growing quickly due to its remarkable performance in improving perception capabilities for connected and automated vehicles. This improvement is crucial, especially for automated driving scenarios in which perception performance is one of the main bottlenecks to the development of safety and efficiency. However, current CP methods typically assume that all collaborating vehicles have enough communication bandwidth to share all features with an identical spatial size, which is impractical for real-world scenarios. In this article, we propose adaptive CP, a new CP framework that is not limited by the aforementioned assumptions, aiming to enable CP under more realistic and challenging conditions. To support this, a novel feature encoder is proposed and named pillar attention encoder. A pillar attention mechanism is designed to extract the feature data while considering its significance for the perception task. An adaptive feature filter is proposed to adjust the size of the feature data for sharing by considering the importance value of the feature. Experiments are conducted for cooperative object detection from multiple vehicle-based and infrastructure-based LiDAR sensors under various communication conditions. Results demonstrate that our method can successfully handle dynamic communication conditions and improve the mean average precision by 10.18% when compared with the state-of-the-art feature encoder.",
    "authors": [
        "Zhengwei Bai",
        "Guoyuan Wu",
        "Matthew J. Barth",
        "Hang Qiu",
        "Yongkang Liu",
        "E. A. Sisbot",
        "K. Oguchi"
    ],
    "venue": "IEEE Internet of Things Journal",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This article proposes adaptive CP, a new CP framework that is not limited by the aforementioned assumptions, aiming to enable CP under more realistic and challenging conditions, and proposes a novel feature encoder, named pillar attention encoder, which can successfully handle dynamic communication conditions."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}