{
    "acronym": "b69b84706fe84c4c614e4473760c57dffbfeb9a0",
    "title": "Waveformer: Linear-Time Attention with Forward and Backward Wavelet Transform",
    "seed_ids": [
        "performer",
        "rfa",
        "lineartransformer",
        "sinkhorn",
        "fnet",
        "c4f4e5e86cb9468235fd5d7c9ccce09a68084463",
        "9b6af0e358e76d22f209c75b1702c3e6ea7815b1",
        "1f133158a8973fb33fea188f20517cd7e69bfe7f",
        "9ed25f101f19ea735ca300848948ed64064b97ca",
        "7e9ff94476f41041c75e253e84f487db00e9c861",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
        "7e5709d81558d3ef4265de29ea75931afeb1f2dd",
        "6f68e1bb253925d8431588555d3010419f322e04",
        "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
        "07a9f47885cae97efb7b4aa109392128532433da",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "34a4e6818d680875ff0bef9a76de0376118446d1",
        "0fe2636446cd686830da3d971b31a004d6094b3c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "b69b84706fe84c4c614e4473760c57dffbfeb9a0",
    "abstract": "We propose Waveformer that learns attention mechanism in the wavelet coef\ufb01cient space, requires only linear time complexity",
    "authors": [
        "Yufan Zhuang",
        "Zihan Wang",
        "Fangbo Tao",
        "Jingbo Shang"
    ],
    "venue": "arXiv.org",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": null
    },
    "citationCount": 5,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}