{
    "acronym": "f2cb2a6d0cab9b2d98cd7af19b417c71c8badff9",
    "title": "Community Question Answering Ranking: Methodology Survey",
    "seed_ids": [
        "gpt",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "f2cb2a6d0cab9b2d98cd7af19b417c71c8badff9",
    "abstract": "This paper surveys the evolution of word embeddings along with the methodologies used in Community Question Answering (cQA), and how these methodologies use word embeddings to achieve higher performance metrics. The paper first discusses vector modelling and how it affected Natural Language Processing (NLP) as a whole, then it details some of the approaches used like the one-hot-encoding, word2vec and others. The paper then discusses contextualized embeddings and how they improve on the previous techniques. The paper then sheds some light on language modelling along with new attention-based architectures (Transformers), discussing briefly how they work and how they affected not only cQA but NLP in general. Then the paper discusses in brief the shift in the field from model-based AI where most of the focus is on producing a model with high performance metrics to Data Centric AI where the focus is on trying to have a systemic way of labelling the data to ease the generation of a highperformance model.",
    "authors": [
        "A. Zaazaa",
        "M. Rashwan",
        "O. Emam"
    ],
    "venue": "The Egyptian Journal of Language Engineering",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The shift in the field from model-based AI to Data Centric AI where the focus is on trying to have a systemic way of labelling the data to ease the generation of a highperformance model is discussed."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}