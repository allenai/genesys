{
    "acronym": "7011bf9aa7e68fabaa1df498da6d2dd8a950f037",
    "title": "Pushing the Limits of ChatGPT on NLP Tasks",
    "seed_ids": [
        "gpt2",
        "6001dce1c8f63350263e013e0e6ff69816f0a9af",
        "964bd39b546f0f6625ff3b9ef1083f797807ef2e",
        "1d26c947406173145a4665dd7ab255e03494ea28",
        "e7ad08848d5d7c5c47673ffe0da06af443643bda",
        "13a0d8bb38f739990c8cd65a44061c6534f17221",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "92173d081b15824d22a9ef070e118744ceee8052",
        "da454295392cf4caaa39cc465734237ffe55392f",
        "a07a94168608322600fd3cab54df1410b96852b6",
        "0fe2636446cd686830da3d971b31a004d6094b3c",
        "d6b414487787d0b6efd735a3236a690ad13aae70",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "75acc731bdd2b626edc74672a30da3bc51010ae8",
        "710d183174844da5b7f392667f3cc25d2b098dde",
        "80f9f109d1564cb8f82aa440a5f6f3fbe220c9ef",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "c21a4d70d83e0f6eb2a9e1c41d034842dd561e47",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "7011bf9aa7e68fabaa1df498da6d2dd8a950f037",
    "abstract": "Despite the success of ChatGPT, its performances on most NLP tasks are still well below the supervised baselines. In this work, we looked into the causes, and discovered that its subpar performance was caused by the following factors: (1) token limit in the prompt does not allow for the full utilization of the supervised datasets; (2) mismatch between the generation nature of ChatGPT and NLP tasks; (3) intrinsic pitfalls of LLMs models, e.g., hallucination, overly focus on certain keywords, etc. In this work, we propose a collection of general modules to address these issues, in an attempt to push the limits of ChatGPT on NLP tasks. Our proposed modules include (1) a one-input-multiple-prompts strategy that employs multiple prompts for one input to accommodate more demonstrations; (2) using fine-tuned models for better demonstration retrieval; (3) transforming tasks to formats that are more tailored to the generation nature; (4) employing reasoning strategies that are tailored to addressing the task-specific complexity; (5) the self-verification strategy to address the hallucination issue of LLMs; (6) the paraphrase strategy to improve the robustness of model predictions. We conduct experiments on 21 datasets of 10 representative NLP tasks, including question answering, commonsense reasoning, natural language inference, sentiment analysis, named entity recognition, entity-relation extraction, event extraction, dependency parsing, semantic role labeling, and part-of-speech tagging. Using the proposed assemble of techniques, we are able to significantly boost the performance of ChatGPT on the selected NLP tasks, achieving performances comparable to or better than supervised baselines, or even existing SOTA performances.",
    "authors": [
        "Xiaofei Sun",
        "Linfeng Dong",
        "Xiaoya Li",
        "Zhen Wan",
        "Shuhe Wang",
        "Tianwei Zhang",
        "Jiwei Li",
        "Fei Cheng",
        "L. Lyu",
        "Fei Wu",
        "Guoyin Wang"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Using the proposed assemble of techniques, this work is able to significantly boost the performance of ChatGPT on the selected NLP tasks, achieving performances comparable to or better than supervised baselines, or even existing SOTA performances."
    },
    "citationCount": 19,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}