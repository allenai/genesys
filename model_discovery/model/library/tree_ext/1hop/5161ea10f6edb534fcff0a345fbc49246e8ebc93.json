{
    "acronym": "5161ea10f6edb534fcff0a345fbc49246e8ebc93",
    "title": "Benchmarking Data Efficiency and Computational Efficiency of Temporal Action Localization Models",
    "seed_ids": [
        "reformer",
        "02bb5d558652a932b9e681edb9abfaa2040dced6",
        "7e5709d81558d3ef4265de29ea75931afeb1f2dd"
    ],
    "s2id": "5161ea10f6edb534fcff0a345fbc49246e8ebc93",
    "abstract": "In temporal action localization, given an input video, the goal is to predict which actions it contains, where they begin, and where they end. Training and testing current state-of-the-art deep learning models requires access to large amounts of data and computational power. However, gathering such data is challenging and computational resources might be limited. This work explores and measures how current deep temporal action localization models perform in settings constrained by the amount of data or computational power. We measure data efficiency by training each model on a subset of the training set. We find that TemporalMaxer outperforms other models in data-limited settings. Furthermore, we recommend TriDet when training time is limited. To test the efficiency of the models during inference, we pass videos of different lengths through each model. We find that TemporalMaxer requires the least computational resources, likely due to its simple architecture.",
    "authors": [
        "Jan Warchocki",
        "Teodor Oprescu",
        "Yunhan Wang",
        "Alexandru Damacus",
        "Paul Misterka",
        "Robert-Jan Bruintjes",
        "A. Lengyel",
        "Ombretta Strafforello",
        "J. V. Gemert"
    ],
    "venue": "2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work explores and measures how current deep temporal action localization models perform in settings constrained by the amount of data or computational power, and finds that TemporalMaxer requires the least computational resources, likely due to its simple architecture."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}