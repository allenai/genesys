{
    "acronym": "4f451ba06c4c9effd6c4ac0bae222495501a6200",
    "title": "Innovations in Neural Data-to-text Generation",
    "seed_ids": [
        "gpt2",
        "b92628d13e8d090d042232fe6ae0b8998634b893",
        "b99c61f6957c1b04ec1376b74f82dd1e83559695",
        "83fac78857c7e65fe10a11a798674dd3cd259c1d",
        "d0086b86103a620a86bc918746df0aa642e2a8a3",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "4f451ba06c4c9effd6c4ac0bae222495501a6200",
    "abstract": "The neural boom that has sparked natural language processing (NLP) research through the last decade has similarly led to significant innovations in data-to-text generation (DTG). This survey offers a consolidated view into the neural DTG paradigm with a structured examination of the approaches, benchmark datasets, and evaluation protocols. This survey draws boundaries separating DTG from the rest of the natural language generation (NLG) landscape, encompassing an up-to-date synthesis of the literature, and highlighting the stages of technological adoption from within and outside the greater NLG umbrella. With this holistic view, we highlight promising avenues for DTG research that not only focus on the design of linguistically capable systems but also systems that exhibit fairness and accountability.",
    "authors": [
        "Mandar Sharma",
        "A. Gogineni",
        "Naren Ramakrishnan"
    ],
    "venue": "arXiv.org",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This survey draws boundaries separating DTG from the rest of the natural language generation (NLG) landscape, encompassing an up-to-date synthesis of the literature, and highlighting the stages of technological adoption from within and outside the greater NLG umbrella."
    },
    "citationCount": 9,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}