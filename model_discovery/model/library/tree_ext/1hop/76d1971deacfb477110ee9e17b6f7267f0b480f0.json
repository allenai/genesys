{
    "acronym": "76d1971deacfb477110ee9e17b6f7267f0b480f0",
    "title": "Efficient Classification of Long Documents via State-Space Models",
    "seed_ids": [
        "s4",
        "longformer",
        "af385c0fdd0eda2bbf429bea6fedffc327c8a180",
        "9166caa474031b62bacad8a920db8308e6a15120",
        "a30ac45ac5b7bd2148d3fb80ee7f3c29724e3170",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "29584ed6d68a06fdf91440a018f6bc83a44fd177",
        "7e9ff94476f41041c75e253e84f487db00e9c861",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "cc2d1a66c701e9be9124eb95431b6c3dd79a61d3"
    ],
    "s2id": "76d1971deacfb477110ee9e17b6f7267f0b480f0",
    "abstract": "Transformer-based models have achieved state-of-the-art performance on numerous NLP applications. However, long documents which are prevalent in real-world scenarios cannot be efficiently processed by transformers with the vanilla self-attention module due to their quadratic computation complexity and limited length extrapolation ability. Instead of tack-ling the computation difficulty for self-attention with sparse or hierarchical structures, in this paper, we investigate the use of State-Space Models (SSMs) for long document classification tasks. We conducted extensive experiments on six long document classification datasets, including binary, multi-class, and multi-label classification, comparing SSMs (with and without pre-training) to self-attention-based models. We also introduce the SSM-pooler model and demonstrate that it achieves comparable performance while being on average 36% more efficient. Additionally our method exhibits higher robustness to the input noise even in the extreme scenario of 40%.",
    "authors": [
        "Peng Lu",
        "Suyuchen Wang",
        "Mehdi Rezagholizadeh",
        "Bang Liu",
        "I. Kobyzev"
    ],
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper investigates the use of State-Space Models (SSMs) for long document classification tasks and introduces the SSM-pooler model, which achieves comparable performance while being on average 36% more efficient than self-attention-based models."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}