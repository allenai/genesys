{
    "acronym": "c158916e4c3184836b4221607df29eea308b3a4d",
    "title": "Video-based Person Re-identification without Bells and Whistles",
    "seed_ids": [
        "axialattn",
        "366244acdd930e488ae224ab6e2a92dc24aa7e06"
    ],
    "s2id": "c158916e4c3184836b4221607df29eea308b3a4d",
    "abstract": "Video-based person re-identification (Re-ID) aims at matching the video tracklets with cropped video frames for identifying the pedestrians under different cameras. However, there exists severe spatial and temporal misalignment for those cropped tracklets due to the imperfect detection and tracking results generated with obsolete methods. To address this issue, we present a simple re-Detect and Link (DL) module which can effectively reduce those unexpected noise through applying the deep learning-based detection and tracking on the cropped tracklets. Furthermore, we introduce an improved model called Coarse-to-Fine Axial-Attention Network (CF-AAN). Based on the typical Non-local Network, we replace the non-local module with three 1-D position-sensitive axial attentions, in addition to our proposed coarse-to-fine structure. With the developed CF-AAN, compared to the original non-local operation, we can not only significantly reduce the computation cost but also obtain the state-of-the-art performance (91.3% in rank-1 and 86.5% in mAP) on the large-scale MARS dataset. Meanwhile, by simply adopting our DL module for data alignment, to our surprise, several baseline models can achieve better or comparable results with the current state-of-the-arts. Besides, we discover the errors not only for the identity labels of tracklets but also for the evaluation protocol for the test data of MARS. We hope that our work can help the community for the further development of invariant representation without the hassle of the spatial and temporal alignment and dataset noise. The code, corrected labels, evaluation protocol, and the aligned data will be available at https://github.com/jackie840129/CF-AAN.",
    "authors": [
        "Chih-Ting Liu",
        "Jun-Cheng Chen",
        "Chu-Song Chen",
        "Shao-Yi Chien"
    ],
    "venue": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A simple re-Detect and Link (DL) module which can effectively reduce those unexpected noise through applying the deep learning-based detection and tracking on the cropped tracklets and an improved model called Coarse-to-Fine AxialAttention Network (CF-AAN), based on the typical Nonlocal Network."
    },
    "citationCount": 10,
    "influentialCitationCount": 3,
    "code": null,
    "description": null,
    "url": null
}