{
    "acronym": "dc1b905c0af4dc318b63cd52fbc867c788df4b8c",
    "title": "Chefs' Random Tables: Non-Trigonometric Random Features",
    "seed_ids": [
        "performer",
        "fd1b829261ba04bb92e0ab60c4f6e7cea0d99fbf",
        "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7",
        "a25370452533bf47549243e97852b9cdf7a0ee0e",
        "f27e8c4731c575bd5f5db4c93ad8588f684dcbd0",
        "7e9ff94476f41041c75e253e84f487db00e9c861",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
        "6f68e1bb253925d8431588555d3010419f322e04",
        "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
        "0b991a1a5bcdb13646ac0b6873d09bde4cc36fb5",
        "34a4e6818d680875ff0bef9a76de0376118446d1"
    ],
    "s2id": "dc1b905c0af4dc318b63cd52fbc867c788df4b8c",
    "abstract": "We introduce chefs' random tables (CRTs), a new class of non-trigonometric random features (RFs) to approximate Gaussian and softmax kernels. CRTs are an alternative to standard random kitchen sink (RKS) methods, which inherently rely on the trigonometric maps. We present variants of CRTs where RFs are positive, a key requirement for applications in recent low-rank Transformers. Further variance reduction is possible by leveraging statistics which are simple to compute. One instantiation of CRTs, the optimal positive random features (OPRFs), is to our knowledge the first RF method for unbiased softmax kernel estimation with positive and bounded RFs, resulting in exponentially small tails and much lower variance than its counterparts. As we show, orthogonal random features applied in OPRFs provide additional variance reduction for any dimensionality $d$ (not only asymptotically for sufficiently large $d$, as for RKS). We test CRTs on many tasks ranging from non-parametric classification to training Transformers for text, speech and image data, obtaining new state-of-the-art results for low-rank text Transformers, while providing linear space and time complexity.",
    "authors": [
        "Valerii Likhosherstov",
        "K. Choromanski",
        "Kumar Avinava Dubey",
        "Frederick Liu",
        "Tam\u00e1s Sarl\u00f3s",
        "Adrian Weller"
    ],
    "venue": "Neural Information Processing Systems",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work introduces chefs' random tables (CRTs), a new class of non-trigonometric random features (RFs) to approximate Gaussian and softmax kernels, and shows that orthogonal random features applied in OPRFs provide additional variance reduction for any dimensionality $d$."
    },
    "citationCount": 15,
    "influentialCitationCount": 2,
    "code": null,
    "description": null,
    "url": null
}