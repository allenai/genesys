{
    "acronym": "95b2cb3f4a765014ce025afe5679660982554e6c",
    "title": "MambaTab: A Plug-and-Play Model for Learning Tabular Data",
    "seed_ids": [
        "mamba",
        "5a77b508302771fc083bf24e0bcda8553c9b5421",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "ca9047c78d48b606c4e4f0c456b1dda550de28b2"
    ],
    "s2id": "95b2cb3f4a765014ce025afe5679660982554e6c",
    "abstract": "Despite the prevalence of images and texts in machine learning, tabular data remains widely used across various domains. Existing deep learning models, such as convolutional neural networks and transformers, perform well however demand extensive preprocessing and tuning limiting accessibility and scalability. This work introduces an innovative approach based on a structured state-space model (SSM), MambaTab, for tabular data. SSMs have strong capabilities for efficiently extracting effective representations from data with long-range dependencies. MambaTab leverages Mamba, an emerging SSM variant, for end-to-end supervised learning on tables. Compared to state-of-the-art baselines, MambaTab delivers superior performance while requiring significantly fewer parameters, as empirically validated on diverse benchmark datasets. MambaTab's efficiency, scalability, generalizability, and predictive gains signify it as a lightweight,\"plug-and-play\"solution for diverse tabular data with promise for enabling wider practical applications.",
    "authors": [
        "Md. Atik Ahamed",
        "Qiang Cheng"
    ],
    "venue": "",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "MambaTab's efficiency, scalability, generalizability, and predictive gains signify it as a lightweight,\"plug-and-play\"solution for diverse tabular data with promise for enabling wider practical applications."
    },
    "citationCount": 10,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}