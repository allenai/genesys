{
    "acronym": "9898fa5e103efc283fa013ac4e5acddff8de04e8",
    "title": "Efficient Modulation for Vision Networks",
    "seed_ids": [
        "metaformer",
        "f35016b3180808fa97d59acbdecf47d6e2ed2819",
        "fc4cbc7a75f5a3bbca59db5513231555f078fe78",
        "066c143b427571fb5568f2c581ea9066478d2e55",
        "dd1139cfc609c2f3263d02e97176d5275caebc0a",
        "fa717a2e31f0cef4e26921f3b147a98644d2e64c",
        "ba637c4f1a170f1e2dadeadb71a63cf2b9a46de2",
        "d48bc9f476c2d983a374bc836e1e5af532d1a8a1",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7"
    ],
    "s2id": "9898fa5e103efc283fa013ac4e5acddff8de04e8",
    "abstract": "In this work, we present efficient modulation, a novel design for efficient vision networks. We revisit the modulation mechanism, which operates input through convolutional context modeling and feature projection layers, and fuses features via element-wise multiplication and an MLP block. We demonstrate that the modulation mechanism is particularly well suited for efficient networks and further tailor the modulation design by proposing the efficient modulation (EfficientMod) block, which is considered the essential building block for our networks. Benefiting from the prominent representational ability of modulation mechanism and the proposed efficient design, our network can accomplish better trade-offs between accuracy and efficiency and set new state-of-the-art performance in the zoo of efficient networks. When integrating EfficientMod with the vanilla self-attention block, we obtain the hybrid architecture which further improves the performance without loss of efficiency. We carry out comprehensive experiments to verify EfficientMod's performance. With fewer parameters, our EfficientMod-s performs 0.6 top-1 accuracy better than EfficientFormerV2-s2 and is 25% faster on GPU, and 2.9 better than MobileViTv2-1.0 at the same GPU latency. Additionally, our method presents a notable improvement in downstream tasks, outperforming EfficientFormerV2-s by 3.6 mIoU on the ADE20K benchmark. Code and checkpoints are available at https://github.com/ma-xu/EfficientMod.",
    "authors": [
        "Xu Ma",
        "Xiyang Dai",
        "Jianwei Yang",
        "Bin Xiao",
        "Yinpeng Chen",
        "Yun Fu",
        "Lu Yuan"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work revisits the modulation mechanism, which operates input through convolutional context modeling and feature projection layers, and fuses features via element-wise multiplication and an MLP block, and proposes the efficient modulation (EfficientMod) block, which is considered the essential building block for networks."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}