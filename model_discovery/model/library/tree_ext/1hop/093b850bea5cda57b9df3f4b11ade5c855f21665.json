{
    "acronym": "093b850bea5cda57b9df3f4b11ade5c855f21665",
    "title": "Task-Oriented Diffusion Model Compression",
    "seed_ids": [
        "classfreediffu",
        "2af61d71dd06cb509d4460eca9503dc2a177dba5",
        "315d7a58fada47c5729645f0af8ddfaa0743f82f",
        "82482585e94192b4e9913727e461f89cd08e9725",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "2cd605106b88c85d7d8b865b1ef0f8c8293debf1"
    ],
    "s2id": "093b850bea5cda57b9df3f4b11ade5c855f21665",
    "abstract": "As recent advancements in large-scale Text-to-Image (T2I) diffusion models have yielded remarkable high-quality image generation, diverse downstream Image-to-Image (I2I) applications have emerged. Despite the impressive results achieved by these I2I models, their practical utility is hampered by their large model size and the computational burden of the iterative denoising process. In this paper, we explore the compression potential of these I2I models in a task-oriented manner and introduce a novel method for reducing both model size and the number of timesteps. Through extensive experiments, we observe key insights and use our empirical knowledge to develop practical solutions that aim for near-optimal results with minimal exploration costs. We validate the effectiveness of our method by applying it to InstructPix2Pix for image editing and StableSR for image restoration. Our approach achieves satisfactory output quality with 39.2% and 56.4% reduction in model footprint and 81.4% and 68.7% decrease in latency to InstructPix2Pix and StableSR, respectively.",
    "authors": [
        "Geon-Yeong Kim",
        "Beomsu Kim",
        "Eunhyeok Park",
        "Sunghyun Cho"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper introduces a novel method for reducing both model size and the number of timesteps and achieves satisfactory output quality with 39.2% and 56.4% reduction in model footprint and 81.7% decrease in latency to InstructPix2Pix and StableSR, respectively."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}