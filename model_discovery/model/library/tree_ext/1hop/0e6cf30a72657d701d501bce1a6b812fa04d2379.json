{
    "acronym": "0e6cf30a72657d701d501bce1a6b812fa04d2379",
    "title": "Multimodal Sensing for Depression Risk Detection: Integrating Audio, Video, and Text Data",
    "seed_ids": [
        "transformer"
    ],
    "s2id": "0e6cf30a72657d701d501bce1a6b812fa04d2379",
    "abstract": "Depression is a major psychological disorder with a growing impact worldwide. Traditional methods for detecting the risk of depression, predominantly reliant on psychiatric evaluations and self-assessment questionnaires, are often criticized for their inefficiency and lack of objectivity. Advancements in deep learning have paved the way for innovations in depression risk detection methods that fuse multimodal data. This paper introduces a novel framework, the Audio, Video, and Text Fusion-Three Branch Network (AVTF-TBN), designed to amalgamate auditory, visual, and textual cues for a comprehensive analysis of depression risk. Our approach encompasses three dedicated branches\u2014Audio Branch, Video Branch, and Text Branch\u2014each responsible for extracting salient features from the corresponding modality. These features are subsequently fused through a multimodal fusion (MMF) module, yielding a robust feature vector that feeds into a predictive modeling layer. To further our research, we devised an emotion elicitation paradigm based on two distinct tasks\u2014reading and interviewing\u2014implemented to gather a rich, sensor-based depression risk detection dataset. The sensory equipment, such as cameras, captures subtle facial expressions and vocal characteristics essential for our analysis. The research thoroughly investigates the data generated by varying emotional stimuli and evaluates the contribution of different tasks to emotion evocation. During the experiment, the AVTF-TBN model has the best performance when the data from the two tasks are simultaneously used for detection, where the F1 Score is 0.78, Precision is 0.76, and Recall is 0.81. Our experimental results confirm the validity of the paradigm and demonstrate the efficacy of the AVTF-TBN model in detecting depression risk, showcasing the crucial role of sensor-based data in mental health detection.",
    "authors": [
        "Zhenwei Zhang",
        "Shengming Zhang",
        "Dong Ni",
        "Zhaoguo Wei",
        "Kongjun Yang",
        "Shan Jin",
        "Gan Huang",
        "Zhen Liang",
        "Li Zhang",
        "Linling Li",
        "Huijun Ding",
        "Zhiguo Zhang",
        "Jianhong Wang"
    ],
    "venue": "Italian National Conference on Sensors",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel framework, the Audio, Video, and Text Fusion-Three Branch Network (AVTF-TBN), designed to amalgamate auditory, visual, and textual cues for a comprehensive analysis of depression risk is introduced, showcasing the crucial role of sensor-based data in mental health detection."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}