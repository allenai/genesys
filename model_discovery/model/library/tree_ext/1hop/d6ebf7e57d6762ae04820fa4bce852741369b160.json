{
    "acronym": "d6ebf7e57d6762ae04820fa4bce852741369b160",
    "title": "Automated ICD Coding using Extreme Multi-label Long Text Transformer-based Models",
    "seed_ids": [
        "bigbird",
        "c3d877b29594bc6f244e638f576be3dca5551f11",
        "4fd46afb416a8a3bd24c664bd4e21c4c90fdd200",
        "f30e95be411456a709e7cb9a8b3a3e557bd0356a",
        "6fe5cfbe53f14012766240e4b1fd4af000ecb4ba",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c"
    ],
    "s2id": "d6ebf7e57d6762ae04820fa4bce852741369b160",
    "abstract": null,
    "authors": [
        "Leibo Liu",
        "O. Perez-Concha",
        "Anthony N. Nguyen",
        "Vicki Bennett",
        "Louisa R Jorm"
    ],
    "venue": "Artif. Intell. Medicine",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The optimisedPLM-ICD models are the new SOTA models for automated ICD coding on both datasets, while the novel XR-LAT models perform competitively with the previous SOTA PLM- ICD models."
    },
    "citationCount": 6,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}