{
    "acronym": "44372f8d37af7e1b35749c3958d206de374184d4",
    "title": "A Survey on Employing Large Language Models for Text-to-SQL Tasks",
    "seed_ids": [
        "gpt3",
        "42c08dc83138732377eb2e427cc793ccc1edfc42",
        "f1a9e0830bc36c048fa4659beaa62609869895b5",
        "0b0debb710366cdff461938c80763eace1651af6",
        "5f19ae1135a9500940978104ec15a5b8751bc7d2"
    ],
    "s2id": "44372f8d37af7e1b35749c3958d206de374184d4",
    "abstract": "The increasing volume of data stored in relational databases has led to the need for efficient querying and utilization of this data in various sectors. However, writing SQL queries requires specialized knowledge, which poses a challenge for non-professional users trying to access and query databases. Text-to-SQL parsing solves this issue by converting natural language queries into SQL queries, thus making database access more accessible for non-expert users. To take advantage of the recent developments in Large Language Models (LLMs), a range of new methods have emerged, with a primary focus on prompt engineering and fine-tuning. This survey provides a comprehensive overview of LLMs in text-to-SQL tasks, discussing benchmark datasets, prompt engineering, fine-tuning methods, and future research directions. We hope this review will enable readers to gain a broader understanding of the recent advances in this field and offer some insights into its future trajectory.",
    "authors": [
        "Liang Shi",
        "Zhengju Tang",
        "Zhi Yang"
    ],
    "venue": "",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A comprehensive overview of LLMs in text-to-SQL tasks is provided, discussing benchmark datasets, prompt engineering, fine-tuning methods, and future research directions, to enable readers to gain a broader understanding of the recent advances in this field."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}