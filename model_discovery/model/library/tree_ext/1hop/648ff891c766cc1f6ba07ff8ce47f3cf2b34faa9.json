{
    "acronym": "648ff891c766cc1f6ba07ff8ce47f3cf2b34faa9",
    "title": "Towards Retrieval-Augmented Architectures for Image Captioning",
    "seed_ids": [
        "transformer",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "648ff891c766cc1f6ba07ff8ce47f3cf2b34faa9",
    "abstract": "The objective of image captioning models is to bridge the gap between the visual and linguistic modalities by generating natural language descriptions that accurately reflect the content of input images. In recent years, researchers have leveraged deep learning-based models and made advances in the extraction of visual features and the design of multimodal connections to tackle this task. This work presents a novel approach towards developing image captioning models that utilize an external kNN memory to improve the generation process. Specifically, we propose two model variants that incorporate a knowledge retriever component that is based on visual similarities, a differentiable encoder to represent input images, and a kNN-augmented language model to predict tokens based on contextual cues and text retrieved from the external memory. We experimentally validate our approach on COCO and nocaps datasets and demonstrate that incorporating an explicit external memory can significantly enhance the quality of captions, especially with a larger retrieval corpus. This work provides valuable insights into retrieval-augmented captioning models and opens up new avenues for improving image captioning at a larger scale.",
    "authors": [
        "Sara Sarto",
        "Marcella Cornia",
        "L. Baraldi",
        "Alessandro Nicolosi",
        "R. Cucchiara"
    ],
    "venue": "ACM Transactions on Multimedia Computing, Communications, and Applications (TOMCCAP)",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes two model variants that incorporate a knowledge retriever component that is based on visual similarities, a differentiable encoder to represent input images, and a kNN-augmented language model to predict tokens based on contextual cues and text retrieved from the external memory."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}