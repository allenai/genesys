{
    "acronym": "192494b0f5baf2117961a9dbdd8693ea9e4ef827",
    "title": "Using fast visual inpainting transformers for anomaly detection",
    "seed_ids": [
        "lineartransformer",
        "6f68e1bb253925d8431588555d3010419f322e04",
        "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
        "6954a6bb9d6f3e365b26b694c963ae1d62a03444"
    ],
    "s2id": "192494b0f5baf2117961a9dbdd8693ea9e4ef827",
    "abstract": "The detection and segmentation of irregularities in images is an anomaly detection problem in computer vision. An approach that is used commonly uses autoencoders trained on good images to fully reconstruct anomalous images. These reconstructions can then be used to perform detection and segmentation by mathematically comparing the original input and the reconstruction. Other solutions introduce patch inpainting as a solution for anomaly detection. One approach uses an attention-based transformer model that achieves promising results. Transformers are generally slower models and thus faster versions have been proposed. We therefore combine the inpainting solution with two types of transformers and see that a linear attention approach performs slightly better than full attention when doing detection and segmentation on the MVTec AD dataset.",
    "authors": [
        "S\u00b4ebastiaan Versteeg BSc"
    ],
    "venue": "",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work combines the inpainting solution with two types of transformers and sees that a linear attention approach performs slightly better than full attention when doing detection and segmentation on the MVTec AD dataset."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}