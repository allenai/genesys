{
    "acronym": "7cf4f8cb8b4a373d869e785b79160dda7a49a250",
    "title": "Exploring The Landscape of Distributional Robustness for Question Answering Models",
    "seed_ids": [
        "gpt2",
        "13a0d8bb38f739990c8cd65a44061c6534f17221",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "d9f6ada77448664b71128bb19df15765336974a6",
        "29ddc1f43f28af7c846515e32cc167bc66886d0c",
        "b47381e04739ea3f392ba6c8faaf64105493c196",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "7cf4f8cb8b4a373d869e785b79160dda7a49a250",
    "abstract": "We conduct a large empirical evaluation to investigate the landscape of distributional robustness in question answering. Our investigation spans over 350 models and 16 question answering datasets, including a diverse set of architectures, model sizes, and adaptation methods (e.g., fine-tuning, adapter tuning, in-context learning, etc.). We find that, in many cases, model variations do not affect robustness and in-distribution performance alone determines out-of-distribution performance. Moreover, our findings indicate that i) zero-shot and in-context learning methods are more robust to distribution shifts than fully fine-tuned models; ii) few-shot prompt fine-tuned models exhibit better robustness than few-shot fine-tuned span prediction models; iii) parameter-efficient and robustness enhancing training methods provide no significant robustness improvements. In addition, we publicly release all evaluations to encourage researchers to further analyze robustness trends for question answering models.",
    "authors": [
        "Anas Awadalla",
        "Mitchell Wortsman",
        "Gabriel Ilharco",
        "Sewon Min",
        "Ian H. Magnusson",
        "Hannaneh Hajishirzi",
        "Ludwig Schmidt"
    ],
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This investigation spans over 350 models and 16 question answering datasets, including a diverse set of architectures, model sizes, and adaptation methods, and indicates that zero-shot and in-context learning methods are more robust to distribution shifts than fully fine-tuned models."
    },
    "citationCount": 13,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}