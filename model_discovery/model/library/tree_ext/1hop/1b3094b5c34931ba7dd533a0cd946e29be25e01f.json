{
    "acronym": "1b3094b5c34931ba7dd533a0cd946e29be25e01f",
    "title": "Fine-Grained Sentiment-Controlled Text Generation Approach Based on Pre-Trained Language Model",
    "seed_ids": [
        "gpt2",
        "982cbf7fcee4f3964dd1d411fdeadad6e6f1d465",
        "e04a80263d252a3d8a382ba37a249b9345620570",
        "7a15950dc71079285a4eaf195de5aadd87c41b40",
        "75acc731bdd2b626edc74672a30da3bc51010ae8",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "1b3094b5c34931ba7dd533a0cd946e29be25e01f",
    "abstract": "Sentiment-controlled text generation aims to generate texts according to the given sentiment. However, most of the existing studies focus only on the document- or sentence-level sentiment control, leaving a gap for finer-grained control over the content of generated results. Fine-grained control allows a generated review to express different opinions toward multiple aspects. Some previous works attempted to generate reviews conditioned on aspect-level sentiments, but they usually suffer from low adaptability and the lack of an annotated dataset. To alleviate these problems, we propose a novel pre-trained extended generative model that can dynamically refer to the prompt sentiment, together with an auxiliary classifier that extracts the fine-grained sentiments from the unannotated sentences, thus we conducted training on both annotated and unannotated datasets. We also propose a query-hint mechanism to further guide the generation process toward the aspect-level sentiments at every time step. Experimental results from real-world datasets demonstrated that our model has excellent adaptability in generating aspect-level sentiment-controllable review texts with high sentiment coverage and stable quality since, on both datasets, our model steadily outperforms other baseline models in the metrics of BLEU-4, METETOR, and ROUGE-L etc. The limitation of this work is that we only focus on fine-grained sentiments that are explicitly expressed. Moreover, the implicitly expressed fine-grained sentiment-controllable text generation will be an important puzzle for future work.",
    "authors": [
        "Linan Zhu",
        "Yifei Xu",
        "Zhechao Zhu",
        "Yinwei Bao",
        "Xiangjie Kong"
    ],
    "venue": "Applied Sciences",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel pre-trained extended generative model that can dynamically refer to the prompt sentiment, together with an auxiliary classifier that extracts the fine-grained sentiments from the unannotated sentences is proposed, which steadily outperforms other baseline models in the metrics of BLEU-4, METETOR, and ROUGE-L etc."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}