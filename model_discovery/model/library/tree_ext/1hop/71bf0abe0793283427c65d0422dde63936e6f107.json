{
    "acronym": "71bf0abe0793283427c65d0422dde63936e6f107",
    "title": "\u201cWhat makes a question inquisitive?\u201d A Study on Type-Controlled Inquisitive Question Generation",
    "seed_ids": [
        "gpt2",
        "2c953a3c378b40dadf2e3fb486713c8608b8e282",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "e04a80263d252a3d8a382ba37a249b9345620570",
        "75acc731bdd2b626edc74672a30da3bc51010ae8",
        "faadd7d081c8d67e8c2567e8a5579e46cd6b2280",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "71bf0abe0793283427c65d0422dde63936e6f107",
    "abstract": "We propose a type-controlled framework for inquisitive question generation. We annotate an inquisitive question dataset with question types, train question type classifiers, and finetune models for type-controlled question generation. Empirical results demonstrate that we can generate a variety of questions that adhere to specific types while drawing from the source texts. We also investigate strategies for selecting a single question from a generated set, considering both an informative vs. inquisitive question classifier and a pairwise ranker trained from a small set of expert annotations. Question selection using the pairwise ranker yields strong results in automatic and manual evaluation. Our human evaluation assesses multiple aspects of the generated questions, finding that the ranker chooses questions with the best syntax (4.59), semantics (4.37), and inquisitiveness (3.92) on a scale of 1-5, even rivaling the performance of human-written questions.",
    "authors": [
        "Lingyu Gao",
        "Debanjan Ghosh",
        "Kevin Gimpel"
    ],
    "venue": "STARSEM",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work annotates an inquisitive question dataset with question types, train question type classifiers, and finetune models for type-controlled question generation, and finds that the ranker chooses questions with the best syntax, semantics, and inquisitiveness, even rivaling the performance of human-written questions."
    },
    "citationCount": 9,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}