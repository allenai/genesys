{
    "acronym": "ea7dab04395e9292a80f147778b21670cd787a16",
    "title": "Towards Transformer-based Automated ICD Coding: Challenges, Pitfalls and Solutions",
    "seed_ids": [
        "longformer",
        "d8d2e574965fe733eb1416e03df2b5c2914fc530",
        "d27669c82faf78ea08cceaa0a171b540cccc304d",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "42f0bae2dacba44e9b5d8f050da3cbe41b9fc437",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "2a31319e73d4486716168b65cdf7559baeda18ce"
    ],
    "s2id": "ea7dab04395e9292a80f147778b21670cd787a16",
    "abstract": "Automated ICD coding, which aims to predict the International Classification of Disease (ICD) codes based on clinical discharge summaries, has received widespread concern from machine learning researchers due to its ability to save massive time and labour required by human coders. Unlike most NLP tasks, state-of-the-art ICD coding models were based on convolutional neural networks (CNN) or recurrent neural networks (RNN), while the popular transformer architecture did not perform well in ICD coding. In this paper, we investigate the challenges and pitfalls of transformer-based ICD coding by experimenting with different transformer architectures using an encoder-decoder architecture. We then present our solution to transformer-based ICD coding: our Longformer-based model significantly outperforms the CNN-based baseline models in five out of six metrics on the MIMIC-III full code dataset, and all evaluation metrics on the MIMIC-III top-50 code dataset. The source code for this project can be found at https://github.com/wren93/CSC2541-repo .",
    "authors": [
        "Weiming Ren",
        "Tianshu Zhu",
        "Ruijing Zeng",
        "Tongzi Wu"
    ],
    "venue": "",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The solution to transformer-based ICD coding is presented: the Longformer-based model significantly outperforms the CNN-based baseline models in five out of six metrics on the MIMIC-III full code dataset, and all evaluation metrics on a top-50 code dataset."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}