{
    "acronym": "8c9b3349762c0220f89d95a406ebc090a0e82451",
    "title": "Multiturn dialogue generation by modeling sentence-level and discourse-level contexts",
    "seed_ids": [
        "gpt2",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "6ebfbc954b9975d2f2651f380b9bdf46ae963178",
        "145b8b5d99a2beba6029418ca043585b90138d12",
        "031e4e43aaffd7a479738dcea69a2d5be7957aa3",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "8c9b3349762c0220f89d95a406ebc090a0e82451",
    "abstract": null,
    "authors": [
        "Yang Yang",
        "Juan Cao",
        "Yujun Wen",
        "Pengzhou Zhang"
    ],
    "venue": "Scientific Reports",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel multiturn dialogue generation model that captures contextual information at the sentence level and at the discourse level during the encoding process, which substantially outperforms the baseline model in terms of both automatic and human evaluation metrics."
    },
    "citationCount": 3,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}