{
    "acronym": "4ca824e792f3a2c777ffa5896a2e7cdf11b9518d",
    "title": "A Survey of Diffusion Models in Natural Language Processing",
    "seed_ids": [
        "d3pms",
        "diffuseq",
        "020a50f6a7154850ac81e3cde69ad8198ded6751",
        "1f898d66acabff511a3871b82799aa73c0055402",
        "a1186d7d9a9ef258c76afef1177e4f348061a537",
        "bb7e779c9360a94dd2779c2468fe06b82de7af59",
        "23b7cde603b5ec8d5d13d46e1c453dc52d7c3f6c",
        "a979742220a88b1d32e1fbe72c41e8ba3007053c",
        "2c6ac935c826002976722ca8d3319f691975687e",
        "0b9770a377b3f96cef9f268cee1791d39a0d4893",
        "69144d537f90f214d5b07a7c79121d16afd7da16",
        "b64537bdf7a103aa01972ba06ea24a9c08f7cd74",
        "1386b8a11929cf02da291c56aca353e33bbc22ed",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "de18baa4964804cf471d85a5a090498242d2e79f",
        "3bcb17559ce96eb20fa79af8194f4af0380d194a",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481"
    ],
    "s2id": "4ca824e792f3a2c777ffa5896a2e7cdf11b9518d",
    "abstract": "This survey paper provides a comprehensive review of the use of diffusion models in natural language processing (NLP). Diffusion models are a class of mathematical models that aim to capture the diffusion of information or signals across a network or manifold. In NLP, diffusion models have been used in a variety of applications, such as natural language generation, sentiment analysis, topic modeling, and machine translation. This paper discusses the different formulations of diffusion models used in NLP, their strengths and limitations, and their applications. We also perform a thorough comparison between diffusion models and alternative generative models, specifically highlighting the autoregressive (AR) models, while also examining how diverse architectures incorporate the Transformer in conjunction with diffusion models. Compared to AR models, diffusion models have significant advantages for parallel generation, text interpolation, token-level controls such as syntactic structures and semantic contents, and robustness. Exploring further permutations of integrating Transformers into diffusion models would be a valuable pursuit. Also, the development of multimodal diffusion models and large-scale diffusion language models with notable capabilities for few-shot learning would be important directions for the future advance of diffusion models in NLP.",
    "authors": [
        "Hao-Li Zou",
        "Zae Myung Kim",
        "Dongyeop Kang"
    ],
    "venue": "",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A thorough comparison between diffusion models and alternative generative models is performed, specifically highlighting the autoregressive (AR) models, while also examining how diverse architectures incorporate the Transformer in conjunction with diffusion models."
    },
    "citationCount": 7,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}