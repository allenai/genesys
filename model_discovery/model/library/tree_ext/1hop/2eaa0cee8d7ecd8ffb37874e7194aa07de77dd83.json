{
    "acronym": "2eaa0cee8d7ecd8ffb37874e7194aa07de77dd83",
    "title": "MyGO: Discrete Modality Information as Fine-Grained Tokens for Multi-modal Knowledge Graph Completion",
    "seed_ids": [
        "bert"
    ],
    "s2id": "2eaa0cee8d7ecd8ffb37874e7194aa07de77dd83",
    "abstract": "Multi-modal knowledge graphs (MMKG) store structured world knowledge containing rich multi-modal descriptive information. To overcome their inherent incompleteness, multi-modal knowledge graph completion (MMKGC) aims to discover unobserved knowledge from given MMKGs, leveraging both structural information from the triples and multi-modal information of the entities. Existing MMKGC methods usually extract multi-modal features with pre-trained models and employ a fusion module to integrate multi-modal features with triple prediction. However, this often results in a coarse handling of multi-modal data, overlooking the nuanced, fine-grained semantic details and their interactions. To tackle this shortfall, we introduce a novel framework MyGO to process, fuse, and augment the fine-grained modality information from MMKGs. MyGO tokenizes multi-modal raw data as fine-grained discrete tokens and learns entity representations with a cross-modal entity encoder. To further augment the multi-modal representations, MyGO incorporates fine-grained contrastive learning to highlight the specificity of the entity representations. Experiments on standard MMKGC benchmarks reveal that our method surpasses 20 of the latest models, underlining its superior performance. Code and data are available at https://github.com/zjukg/MyGO",
    "authors": [
        "Yichi Zhang",
        "Zhuo Chen",
        "Lingbing Guo",
        "Yajing Xu",
        "Binbin Hu",
        "Ziqi Liu",
        "Hua-zeng Chen",
        "Wen Zhang"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work introduces a novel framework MyGO to process, fuse, and augment the fine-grained modality information from MMKGs, and incorporates fine-grained contrastive learning to highlight the specificity of the entity representations."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}