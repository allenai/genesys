{
    "acronym": "166314254ab27888fb49399dcf17764feb347a66",
    "title": "Adaptively-Realistic Image Generation from Stroke and Sketch with Diffusion Model",
    "seed_ids": [
        "classfreediffu",
        "de18baa4964804cf471d85a5a090498242d2e79f"
    ],
    "s2id": "166314254ab27888fb49399dcf17764feb347a66",
    "abstract": "Generating images from hand-drawings is a crucial and fundamental task in content creation. The translation is difficult as there exist infinite possibilities and the different users usually expect different outcomes. Therefore, we propose a unified framework supporting a three-dimensional control over the image synthesis from sketches and strokes based on diffusion models. Users can not only decide the level of faithfulness to the input strokes and sketches, but also the degree of realism, as the user inputs are usually not consistent with the real images. Qualitative and quantitative experiments demonstrate that our framework achieves state-of-the-art performance while providing flexibility in generating customized images with control over shape, color, and realism. Moreover, our method unleashes applications such as editing on real images, generation with partial sketches and strokes, and multi-domain multi-modal synthesis.",
    "authors": [
        "Shin-I Cheng",
        "Yu-Jie Chen",
        "Wei-Chen Chiu",
        "Hsin-Ying Lee",
        "Hung-Yu Tseng"
    ],
    "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A unified framework supporting a three-dimensional control over the image synthesis from sketches and strokes based on diffusion models is proposed, achieving state-of-the-art performance while providing flexibility in generating customized images with control over shape, color, and realism."
    },
    "citationCount": 35,
    "influentialCitationCount": 6,
    "code": null,
    "description": null,
    "url": null
}