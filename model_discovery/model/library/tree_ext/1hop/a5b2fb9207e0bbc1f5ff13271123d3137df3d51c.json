{
    "acronym": "a5b2fb9207e0bbc1f5ff13271123d3137df3d51c",
    "title": "More Distinctively Black and Feminine Faces Lead to Increased Stereotyping in Vision-Language Models",
    "seed_ids": [
        "bert",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "7a15950dc71079285a4eaf195de5aadd87c41b40",
        "5e9c85235210b59a16bdd84b444a904ae271f7e7"
    ],
    "s2id": "a5b2fb9207e0bbc1f5ff13271123d3137df3d51c",
    "abstract": "Vision Language Models (VLMs), exemplified by GPT-4V, adeptly integrate text and vision modalities. This integration enhances Large Language Models' ability to mimic human perception, allowing them to process image inputs. Despite VLMs' advanced capabilities, however, there is a concern that VLMs inherit biases of both modalities in ways that make biases more pervasive and difficult to mitigate. Our study explores how VLMs perpetuate homogeneity bias and trait associations with regards to race and gender. When prompted to write stories based on images of human faces, GPT-4V describes subordinate racial and gender groups with greater homogeneity than dominant groups and relies on distinct, yet generally positive, stereotypes. Importantly, VLM stereotyping is driven by visual cues rather than group membership alone such that faces that are rated as more prototypically Black and feminine are subject to greater stereotyping. These findings suggest that VLMs may associate subtle visual cues related to racial and gender groups with stereotypes in ways that could be challenging to mitigate. We explore the underlying reasons behind this behavior and discuss its implications and emphasize the importance of addressing these biases as VLMs come to mirror human perception.",
    "authors": [
        "Messi H.J. Lee",
        "Jacob M. Montgomery",
        "Calvin K Lai"
    ],
    "venue": "",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is suggested that VLMs may associate subtle visual cues related to racial and gender groups with stereotypes in ways that could be challenging to mitigate, and the importance of addressing these biases as VLMs come to mirror human perception."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}