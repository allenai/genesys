{
    "acronym": "7befecfc6df5d3cdae7c9a769dd205d54745a286",
    "title": "Learning to Retrieve Entity-Aware Knowledge and Generate Responses with Copy Mechanism for Task-Oriented Dialogue Systems",
    "seed_ids": [
        "gpt",
        "6ebfbc954b9975d2f2651f380b9bdf46ae963178",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "7befecfc6df5d3cdae7c9a769dd205d54745a286",
    "abstract": "Task-oriented conversational modeling with unstructured knowledge access, as track 1 of the 9th Dialogue System Technology Challenges (DSTC 9), requests to build a system to generate response given dialogue history and knowledge access. This challenge can be separated into three subtasks, (1) knowledge-seeking turn detection, (2) knowledge selection, and (3) knowledge-grounded response generation. We use pre-trained language models, ELECTRA and RoBERTa, as our base encoder for different subtasks. For subtask 1 and 2, the coarse-grained information like domain and entity are used to enhance knowledge usage. For subtask 3, we use a latent variable to encode dialog history and selected knowledge better and generate responses combined with copy mechanism. Meanwhile, some useful post-processing strategies are performed on the model's final output to make further knowledge usage in the generation task. As shown in released evaluation results, our proposed system ranks second under objective metrics and ranks fourth under human metrics.",
    "authors": [
        "Chao-Hong Tan",
        "Xiaoyu Yang",
        "Zi'ou Zheng",
        "Tianda Li",
        "Yufei Feng",
        "Jia-Chen Gu",
        "QUAN LIU",
        "Dan Liu",
        "Zhenhua Ling",
        "Xiao-Dan Zhu"
    ],
    "venue": "arXiv.org",
    "year": 2020,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work uses pre-trained language models, ELECTRA and RoBERTa, as a base encoder for different subtasks and uses a latent variable to encode dialog history and selected knowledge better and generate responses combined with copy mechanism."
    },
    "citationCount": 9,
    "influentialCitationCount": 2,
    "code": null,
    "description": null,
    "url": null
}