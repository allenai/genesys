{
    "acronym": "410c4e32f6f06f803a775b2bce5e3eb2edeb98fa",
    "title": "You are what you eat? Feeding foundation models a regionally diverse food dataset of World Wide Dishes",
    "seed_ids": [
        "gpt3",
        "c57293882b2561e1ba03017902df9fc2f289dea2",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
        "fd1b829261ba04bb92e0ab60c4f6e7cea0d99fbf"
    ],
    "s2id": "410c4e32f6f06f803a775b2bce5e3eb2edeb98fa",
    "abstract": "Foundation models are increasingly ubiquitous in our daily lives, used in everyday tasks such as text-image searches, interactions with chatbots, and content generation. As use increases, so does concern over the disparities in performance and fairness of these models for different people in different parts of the world. To assess these growing regional disparities, we present World Wide Dishes, a mixed text and image dataset consisting of 765 dishes, with dish names collected in 131 local languages. World Wide Dishes has been collected purely through human contribution and decentralised means, by creating a website widely distributed through social networks. Using the dataset, we demonstrate a novel means of operationalising capability and representational biases in foundation models such as language models and text-to-image generative models. We enrich these studies with a pilot community review to understand, from a first-person perspective, how these models generate images for people in five African countries and the United States. We find that these models generally do not produce quality text and image outputs of dishes specific to different regions. This is true even for the US, which is typically considered to be more well-resourced in training data - though the generation of US dishes does outperform that of the investigated African countries. The models demonstrate a propensity to produce outputs that are inaccurate as well as culturally misrepresentative, flattening, and insensitive. These failures in capability and representational bias have the potential to further reinforce stereotypes and disproportionately contribute to erasure based on region. The dataset and code are available at https://github.com/oxai/world-wide-dishes/.",
    "authors": [
        "Jabez Magomere",
        "Shu Ishida",
        "Tejumade Afonja",
        "Aya Salama",
        "Daniel Kochin",
        "Foutse Yuehgoh",
        "Imane Hamzaoui",
        "Raesetje Sefala",
        "Aisha Alaagib",
        "Elizaveta Semenova",
        "Lauren Crais",
        "S. Hall"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is found that foundation models generally do not produce quality text and image outputs of dishes specific to different regions, and this is true even for the US, which is typically considered to be more well-resourced in training data - though the generation of US dishes does outperform that of the investigated African countries."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}