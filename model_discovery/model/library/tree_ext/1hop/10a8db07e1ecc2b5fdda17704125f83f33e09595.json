{
    "acronym": "10a8db07e1ecc2b5fdda17704125f83f33e09595",
    "title": "UMBCLU at SemEval-2024 Task 1: Semantic Textual Relatedness with and without machine translation",
    "seed_ids": [
        "bert"
    ],
    "s2id": "10a8db07e1ecc2b5fdda17704125f83f33e09595",
    "abstract": "The aim of SemEval-2024 Task 1, \u201cSemantic Textual Relatedness for African and Asian Languages\u201d is to develop models for identifying semantic textual relatedness (STR) between two sentences using multiple languages (14 African and Asian languages) and settings (supervised, unsupervised, and cross-lingual). Large language models (LLMs) have shown impressive performance on several natural language understanding tasks such as multilingual machine translation (MMT), semantic similarity (STS), and encoding sentence embeddings. Using a combination of LLMs that perform well on these tasks, we developed two STR models, TranSem and FineSem, for the supervised and cross-lingual settings. We explore the effectiveness of several training methods and the usefulness of machine translation. We find that direct fine-tuning on the task is comparable to using sentence embeddings and translating to English leads to better performance for some languages. In the supervised setting, our model performance is better than the official baseline for 3 languages with the remaining 4 performing on par. In the cross-lingual setting, our model performance is better than the baseline for 3 languages (leading to 1st place for Africaans and 2nd place for Indonesian), is on par for 2 languages and performs poorly on the remaining 7 languages.",
    "authors": [
        "Shubhashis Roy Dipta",
        "Sai Vallurupalli"
    ],
    "venue": "International Workshop on Semantic Evaluation",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is found that direct fine-tuning on the task is comparable to using sentence embeddings and translating to English leads to better performance for some languages and the effectiveness of several training methods and the usefulness of machine translation."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}