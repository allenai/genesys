{
    "acronym": "4369866a12d6c12c62bc1d2551d9cdf4e2b10fb2",
    "title": "GVDIFF: Grounded Text-to-Video Generation with Diffusion Models",
    "seed_ids": [
        "classfreediffu",
        "b0f7d7d545ed7f8bd82cfb0ef381cf9dcac339d4",
        "b8b5015b153709176385873e34339f9e520d128f",
        "1b492746ee3a304a13950cad1a59861b9ee44645",
        "498ac9b2e494601d20a3d0211c16acf2b7954a54",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d"
    ],
    "s2id": "4369866a12d6c12c62bc1d2551d9cdf4e2b10fb2",
    "abstract": "In text-to-video (T2V) generation, significant attention has been directed toward its development, yet unifying discrete and continuous grounding conditions in T2V generation remains under-explored. This paper proposes a Grounded text-to-Video generation framework, termed GVDIFF. First, we inject the grounding condition into the self-attention through an uncertainty-based representation to explicitly guide the focus of the network. Second, we introduce a spatial-temporal grounding layer that connects the grounding condition with target objects and enables the model with the grounded generation capacity in the spatial-temporal domain. Third, our dynamic gate network adaptively skips the redundant grounding process to selectively extract grounding information and semantics while improving efficiency. We extensively evaluate the grounded generation capacity of GVDIFF and demonstrate its versatility in applications, including long-range video generation, sequential prompts, and object-specific editing.",
    "authors": [
        "Huanzhang Dou",
        "Rui Li",
        "Wei Su",
        "Xi Li"
    ],
    "venue": "",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper proposes a Grounded text-to-Video generation framework, termed GVDIFF, and introduces a spatial-temporal grounding layer that connects the grounding condition with target objects and enables the model with the grounded generation capacity in the spatial-temporal domain."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}