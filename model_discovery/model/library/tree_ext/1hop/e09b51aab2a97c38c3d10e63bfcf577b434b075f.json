{
    "acronym": "e09b51aab2a97c38c3d10e63bfcf577b434b075f",
    "title": "Learnable Fourier Features for Multi-Dimensional Spatial Positional Encoding: Appendix",
    "seed_ids": [
        "reformer"
    ],
    "s2id": "e09b51aab2a97c38c3d10e63bfcf577b434b075f",
    "abstract": "where queries Q \u2208 RN\u00d7dk , keys K \u2208 RN\u00d7dk , and values V \u2208 RN\u00d7Dv . N is the number of items 4 to consider, e.g., the number of tokens in a sequence or the number of pixel patches in an image. dk 5 is the dimension of a key and query, and Dv is the dimension of a value vector. Queries, keys and 6 values are acquired via a linear projection of the input at each attention layer. For self-attention, they 7 share the same input: 8 Q = EXMQ;K = EXMK ;V = EXMV (2) where MQ \u2208 R|EX |\u00d7dk , MK \u2208 R|EX |\u00d7dk and MV \u2208 R|EX |\u00d7dv are the linear projection. EX \u2208 9 RN\u00d7|EX | is the embedding of input X , which is jointly represented by its content embedding, CX , 10 and its positional encoding, PX . 11",
    "authors": [],
    "venue": "",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Queries, keys and values are acquired via a linear projection of the input at each attention layer via the embedding of input X, which is jointly represented by its content embedding, CX, 10 and its positional encoding, PX."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}