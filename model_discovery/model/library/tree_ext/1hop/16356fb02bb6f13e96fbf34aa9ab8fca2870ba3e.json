{
    "acronym": "16356fb02bb6f13e96fbf34aa9ab8fca2870ba3e",
    "title": "ColorizeDiffusion: Adjustable Sketch Colorization with Reference Image and Text",
    "seed_ids": [
        "classfreediffu",
        "c57293882b2561e1ba03017902df9fc2f289dea2",
        "c10075b3746a9f3dd5811970e93c8ca3ad39b39d"
    ],
    "s2id": "16356fb02bb6f13e96fbf34aa9ab8fca2870ba3e",
    "abstract": "Diffusion models have recently demonstrated their effectiveness in generating extremely high-quality images and are now utilized in a wide range of applications, including automatic sketch colorization. Although many methods have been developed for guided sketch colorization, there has been limited exploration of the potential conflicts between image prompts and sketch inputs, which can lead to severe deterioration in the results. Therefore, this paper exhaustively investigates reference-based sketch colorization models that aim to colorize sketch images using reference color images. We specifically investigate two critical aspects of reference-based diffusion models: the\"distribution problem\", which is a major shortcoming compared to text-based counterparts, and the capability in zero-shot sequential text-based manipulation. We introduce two variations of an image-guided latent diffusion model utilizing different image tokens from the pre-trained CLIP image encoder and propose corresponding manipulation methods to adjust their results sequentially using weighted text inputs. We conduct comprehensive evaluations of our models through qualitative and quantitative experiments as well as a user study.",
    "authors": [
        "Dingkun Yan",
        "Liang Yuan",
        "Yuma Nishioka",
        "I. Fujishiro",
        "Suguru Saito"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper exhaustively investigates reference-based sketch colorization models that aim to colorize sketch images using reference color images and introduces two variations of an image-guided latent diffusion model utilizing different image tokens from the pre-trained CLIP image encoder and proposes corresponding manipulation methods to adjust their results sequentially using weighted text inputs."
    },
    "citationCount": 1,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}