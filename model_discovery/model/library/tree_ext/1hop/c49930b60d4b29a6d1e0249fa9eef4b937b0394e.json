{
    "acronym": "c49930b60d4b29a6d1e0249fa9eef4b937b0394e",
    "title": "Hierarchical Transformer-based Query by Multiple Documents",
    "seed_ids": [
        "longformer",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "7cc730da554003dda77796d2cb4f06da5dfd5592",
        "15cc6dac02a458f587712880e8b9c15bb97bbbeb"
    ],
    "s2id": "c49930b60d4b29a6d1e0249fa9eef4b937b0394e",
    "abstract": "It is often difficult for users to form keywords to express their information needs, especially when they are not familiar with the domain of the articles of interest. Moreover, in some search scenarios, there is no explicit query for the search engine to work with. Query-By-Multiple-Documents (QBMD), in which the information needs are implicitly represented by a set of relevant documents addresses these retrieval scenarios. Unlike the keyword-based retrieval task, the query documents are treated as exemplars of a hidden query topic, but it is often the case that they can be relevant to multiple topics. In this paper, we present a Hierarchical Interaction-based (HINT) bi-encoder retrieval architecture that encodes a set of query documents and retrieval documents separately for the QBMD task. We design a hierarchical attention mechanism that allows the model to 1) encode long sequences efficiently and 2) learn the interactions at low-level and high-level semantics (e.g., tokens and paragraphs) across multiple documents. With contextualized representations, the final scoring is calculated based on a stratified late interaction, which ensures each query document contributes equally to the matching against the candidate document. We build a large-scale, weakly supervised QBMD retrieval dataset based on Wikipedia for model training. We evaluate the proposed model on both Query-By-Single-Document (QBSD) and QBMD tasks. For QBSD, we use a benchmark dataset for legal case retrieval. For QBMD, we transform standard keyword-based retrieval datasets into the QBMD setting. Our experimental results show that HINT significantly outperforms all competitive baselines.",
    "authors": [
        "Zhiqi Huang",
        "Sheikh Muhammad Sarwar"
    ],
    "venue": "International Conference on the Theory of Information Retrieval",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A Hierarchical Interaction-based (HINT) bi-encoder retrieval architecture that encodes a set of query documents and retrieval documents separately for the QBMD task and shows that HINT significantly outperforms all competitive baselines."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}