{
    "acronym": "2943bd28f2e687dbb601c40a460289cb04edca67",
    "title": "Language Decision Transformers with Exponential Tilt for Interactive Text Environments",
    "seed_ids": [
        "longt5",
        "3dfb1f50f2a34a699c339dabaa6f9b3a977973de",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "2943bd28f2e687dbb601c40a460289cb04edca67",
    "abstract": "Text-based game environments are challenging because agents must deal with long sequences of text, execute compositional actions using text and learn from sparse rewards. We address these challenges by proposing Language Decision Transformers (LDTs), a framework that is based on transformer language models and decision transformers (DTs). Our LDTs extend DTs with 3 components: (1) exponential tilt to guide the agent towards high obtainable goals, (2) novel goal conditioning methods yielding better results than the traditional return-to-go (sum of all future rewards), and (3) a model of future observations that improves agent performance. LDTs are the first to address offline RL with DTs on these challenging games. Our experiments show that LDTs achieve the highest scores among many different types of agents on some of the most challenging Jericho games, such as Enchanter.",
    "authors": [
        "Nicolas Gontier",
        "Pau Rodr\u00edguez L\u00f3pez",
        "I. Laradji",
        "David V\u00e1zquez",
        "C. Pal"
    ],
    "venue": "",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Language Decision Transformers are the first to address offline RL with DTs on these challenging games and show that LDTs achieve the highest scores among many different types of agents on some of the most challenging Jericho games, such as Enchanter."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}