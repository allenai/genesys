{
    "acronym": "5c104f905fcacf390270f619f232a2ba4eb873f2",
    "title": "FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores",
    "seed_ids": [
        "hyena",
        "m2",
        "s4",
        "a6979a2520fa9342953c3c620d4030a4e44d2b7f",
        "c51192d7440807dc98cc4374fb5d919390d70b0b",
        "bfd2b76998a0521c12903ef5ced517adf70ad2ba",
        "067aaf0d1cde4ee21063be137559f2fe50125570",
        "a7d68b1702af08ce4dbbf2cd0b083e744ae5c6be",
        "998ac3e945857cf2676ee7efdbaf443a0c6f820a",
        "54155c2977a977bf129849455dcae3a2b79b3f41",
        "bb6644a9f5920abfc1fa008f366a9ff48468e063",
        "5a77b508302771fc083bf24e0bcda8553c9b5421",
        "a128b1c47e6842605fb95bceae930d2135fc38fc",
        "240300b1da360f22bf0b82c6817eacebba6deed4",
        "70e91e16eb321067d9402710e14a40cf28311f73",
        "6d7d141c75af752ffc0d8a6184cca3f9323d6c74",
        "eaef083b9d661f42cc0d89d9d8156218f33a91d9",
        "a30ac45ac5b7bd2148d3fb80ee7f3c29724e3170",
        "ca444821352a4bd91884413d8070446e2960715a",
        "87c5b281fa43e6f27191b20a8dd694eda1126336",
        "8326dba15f6b8ee6e43c23eea3265a05e59e8135",
        "90b21dbad8969b74d704eed15a3d98722a88e464",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "5f895e84c1fea75de07b4f90da518273c2e57291",
        "1a883522f3c0051d70be1f8cbdb8989a77395006",
        "af679d69fcc1d0fcf0f039aba937853bcb50a8de",
        "2365410a710b421b2295cdca0074946cb50bb1d4",
        "bf80051ca9ae1e76e2bdbdcf44df559e7eb73cb1",
        "1d5c8c6e5a774d2fef8d92bd28670a6345a97f7a",
        "7e9ff94476f41041c75e253e84f487db00e9c861",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
        "7e5709d81558d3ef4265de29ea75931afeb1f2dd",
        "6f68e1bb253925d8431588555d3010419f322e04",
        "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
        "a68c3412e60560290400d2707596f82a914b7c00",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "c958af9a7b872a8b84844a24fce3c8e02ac21093"
    ],
    "s2id": "5c104f905fcacf390270f619f232a2ba4eb873f2",
    "abstract": "Convolution models with long filters have demonstrated state-of-the-art reasoning abilities in many long-sequence tasks but lag behind the most optimized Transformers in wall-clock time. A major bottleneck is the Fast Fourier Transform (FFT)--which allows long convolutions to run in $O(N logN)$ time in sequence length $N$ but has poor hardware utilization. In this paper, we study how to optimize the FFT convolution. We find two key bottlenecks: the FFT does not effectively use specialized matrix multiply units, and it incurs expensive I/O between layers of the memory hierarchy. In response, we propose FlashFFTConv. FlashFFTConv uses a matrix decomposition that computes the FFT using matrix multiply units and enables kernel fusion for long sequences, reducing I/O. We also present two sparse convolution algorithms--1) partial convolutions and 2) frequency-sparse convolutions--which can be implemented simply by skipping blocks in the matrix decomposition, enabling further opportunities for memory and compute savings. FlashFFTConv speeds up exact FFT convolutions by up to 7.93$\\times$ over PyTorch and achieves up to 4.4$\\times$ speedup end-to-end. Given the same compute budget, FlashFFTConv allows Hyena-GPT-s to achieve 2.3 points better perplexity on the PILE and M2-BERT-base to achieve 3.3 points higher GLUE score--matching models with twice the parameter count. FlashFFTConv also achieves 96.1% accuracy on Path-512, a high-resolution vision task where no model had previously achieved better than 50%. Furthermore, partial convolutions enable longer-sequence models--yielding the first DNA model that can process the longest human genes (2.3M base pairs)--and frequency-sparse convolutions speed up pretrained models while maintaining or improving model quality.",
    "authors": [
        "Daniel Y. Fu",
        "Hermann Kumbong",
        "Eric N. D. Nguyen",
        "Christopher R'e"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Partial convolutions enable longer-sequence models--yielding the first DNA model that can process the longest human genes (2.3M base pairs)--and frequency-sparse convolutions speed up pretrained models while maintaining or improving model quality."
    },
    "citationCount": 14,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}