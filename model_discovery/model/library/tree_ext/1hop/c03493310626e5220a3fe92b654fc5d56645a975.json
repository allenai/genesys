{
    "acronym": "c03493310626e5220a3fe92b654fc5d56645a975",
    "title": "CLEAN-EVAL: Clean Evaluation on Contaminated Large Language Models",
    "seed_ids": [
        "gpt3",
        "d9f6ada77448664b71128bb19df15765336974a6"
    ],
    "s2id": "c03493310626e5220a3fe92b654fc5d56645a975",
    "abstract": "We are currently in an era of fierce competition among various large language models (LLMs) continuously pushing the boundaries of benchmark performance. However, genuinely assessing the capabilities of these LLMs has become a challenging and critical issue due to potential data contamination, and it wastes dozens of time and effort for researchers and engineers to download and try those contaminated models. To save our precious time, we propose a novel and useful method, Clean-Eval, which mitigates the issue of data contamination and evaluates the LLMs in a cleaner manner. Clean-Eval employs an LLM to paraphrase and back-translate the contaminated data into a candidate set, generating expressions with the same meaning but in different surface forms. A semantic detector is then used to filter the generated low-quality samples to narrow down this candidate set. The best candidate is finally selected from this set based on the BLEURT score. According to human assessment, this best candidate is semantically similar to the original contamination data but expressed differently. All candidates can form a new benchmark to evaluate the model. Our experiments illustrate that Clean-Eval substantially restores the actual evaluation results on contaminated LLMs under both few-shot learning and fine-tuning scenarios.",
    "authors": [
        "Wenhong Zhu",
        "Hong-ping Hao",
        "Zhiwei He",
        "Yun-Ze Song",
        "Yumeng Zhang",
        "Hanxu Hu",
        "Yiran Wei",
        "Rui Wang",
        "Hongyuan Lu"
    ],
    "venue": "North American Chapter of the Association for Computational Linguistics",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a novel and useful method, Clean-Eval, which mitigates the issue of data contamination and evaluates the LLMs in a cleaner manner, and substantially restores the actual evaluation results on contaminated LLMs under both few-shot learning and fine-tuning scenarios."
    },
    "citationCount": 5,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}