{
    "acronym": "3b2b86f956f070934e0947d25e2c9c6fff5b157e",
    "title": "DualTime: A Dual-Adapter Multimodal Language Model for Time Series Representation",
    "seed_ids": [
        "gpt2",
        "522828823ff726598675971036fff01b57320578",
        "b8e57155bbcc1ce8a112482c85b3a3bb25f3fe52",
        "afeeb8f5018eebb1a1d334b94dbbfc48d167efef",
        "83ac79bb8e8695fb3c3c024be74790d862adea74",
        "16f01c1b3ddd0b2abd5ddfe4fdb3f74767607277",
        "d84cf745c534c010b8e55e5a4a04878906848dc3",
        "5b7f5488c380cf5085a5dd93e993ad293b225eee",
        "563bac1c5cdd5096e9dbf8d4f3d5b3c4f7284e06",
        "fc46ccb83dc121c33de7ab6bdedab7d970780b2f",
        "35a9749df07a2ab97c51af4d260b095b00da7676",
        "30dcc0e191a376fea0e7a46f94c53872c029efc9",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "3b2b86f956f070934e0947d25e2c9c6fff5b157e",
    "abstract": "The recent rapid development of language models (LMs) has attracted attention in the field of time series, including multimodal time series modeling. However, we note that current time series multimodal methods are biased, often assigning a primary role to one modality while the other assumes a secondary role. They overlook the mutual benefits and complementary of different modalities. For example, in seizure diagnosis, relying solely on textual clinical reports makes it difficult to pinpoint the area and type of the disease, while electroencephalograms (EEGs) alone cannot provide an accurate diagnosis without considering the symptoms. In this study, based on the complementary information mining of time series multimodal data, we propose DualTime, a Dual-adapter multimodal language model for Time series representation implementing temporal-primary and textual-primary modeling simultaneously. By injecting lightweight adaption tokens, the LM pipeline shared by dual adapters encourages embedding alignment and achieves efficient fine-tuning. Empirically, our method outperforms state-of-the-art models in both supervised and unsupervised settings, highlighting the complementary benefits of different modalities. In addition, we conduct few-shot label transfer experiments, which further verifies the transferability and expressiveness of our proposed DualTime.",
    "authors": [
        "Weiqi Zhang",
        "Jiexia Ye",
        "Ziyue Li",
        "Jia Li",
        "F. Tsung"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "DualTime, a Dual-adapter multimodal language model for Time series representation implementing temporal-primary and textual-primary modeling simultaneously, outperforms state-of-the-art models in both supervised and unsupervised settings, highlighting the complementary benefits of different modalities."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}