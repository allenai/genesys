{
    "acronym": "8dd24b8476aa1a758765337fbaa889c4a923852d",
    "title": "HOP to the Next Tasks and Domains for Continual Learning in NLP",
    "seed_ids": [
        "bert",
        "29ddc1f43f28af7c846515e32cc167bc66886d0c"
    ],
    "s2id": "8dd24b8476aa1a758765337fbaa889c4a923852d",
    "abstract": "Continual Learning (CL) aims to learn a sequence of problems (i.e., tasks and domains) by transferring knowledge acquired on previous problems, whilst avoiding forgetting of past ones. Different from previous approaches which focused on CL for one NLP task or domain in a specific use-case, in this paper, we address a more general CL setting to learn from a sequence of problems in a unique framework. Our method, HOP, permits to hop across tasks and domains by addressing the CL problem along three directions: (i) we employ a set of adapters to generalize a large pre-trained model to unseen problems, (ii) we compute high-order moments over the distribution of embedded representations to distinguish independent and correlated statistics across different tasks and domains, (iii) we process this enriched information with auxiliary heads specialized for each end problem. Extensive experimental campaign on 4 NLP applications, 5 benchmarks and 2 CL setups demonstrates the effectiveness of our HOP.",
    "authors": [
        "Umberto Michieli",
        "Mete Ozay"
    ],
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper addresses a more general CL setting to learn from a sequence of problems in a unique framework, HOP, and permits to hop across tasks and domains by addressing the CL problem along three directions."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}