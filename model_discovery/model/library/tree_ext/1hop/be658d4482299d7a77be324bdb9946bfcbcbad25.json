{
    "acronym": "be658d4482299d7a77be324bdb9946bfcbcbad25",
    "title": "Incorporating Distributions of Discourse Structure for Long Document Abstractive Summarization",
    "seed_ids": [
        "longformer",
        "367d38c8a1e788ef061d7f48f74a440ac85a34c9",
        "89a87a8a3f94dc28ad941d64336c1744533b5a77",
        "3d318019788418b21478e8736d03afadc1607690",
        "24b951275a7a42ef36aca8352caaf6f4cd6238d2",
        "3dfb1f50f2a34a699c339dabaa6f9b3a977973de",
        "c600b697700c844cbc85009be70f1cdfeef3593e",
        "34042e2680e475510a1030b54165a81534ad88d3",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "67b1f8e48118bb1aa250f400d475425317bf4117",
        "63b5226b5cea33e7b862f737d5bf1a766ea3281a"
    ],
    "s2id": "be658d4482299d7a77be324bdb9946bfcbcbad25",
    "abstract": "For text summarization, the role of discourse structure is pivotal in discerning the core content of a text. Regrettably, prior studies on incorporating Rhetorical Structure Theory (RST) into transformer-based summarization models only consider the nuclearity annotation, thereby overlooking the variety of discourse relation types. This paper introduces the \u2018RSTformer\u2019, a novel summarization model that comprehensively incorporates both the types and uncertainty of rhetorical relations. Our RST-attention mechanism, rooted in document-level rhetorical structure, is an extension of the recently devised Longformer framework. Through rigorous evaluation, the model proposed herein exhibits significant superiority over state-of-the-art models, as evidenced by its notable performance on several automatic metrics and human evaluation.",
    "authors": [
        "Dongqi Pu",
        "Yifa Wang",
        "Vera Demberg"
    ],
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Through rigorous evaluation, the model proposed herein exhibits significant superiority over state-of-the-art models, as evidenced by its notable performance on several automatic metrics and human evaluation."
    },
    "citationCount": 9,
    "influentialCitationCount": 2,
    "code": null,
    "description": null,
    "url": null
}