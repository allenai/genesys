{
    "acronym": "d9f6ada77448664b71128bb19df15765336974a6",
    "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems",
    "seed_ids": [
        "gpt",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "e2587eddd57bc4ba286d91b27c185083f16f40ee",
        "7ebed46b7f3ec913e508e6468304fcaea832eda1",
        "f6fbb6809374ca57205bd2cf1421d4f4fa04f975",
        "bb104dc51121a0f64a5327526fad449cb03dd1bb",
        "b47381e04739ea3f392ba6c8faaf64105493c196"
    ],
    "s2id": "d9f6ada77448664b71128bb19df15765336974a6",
    "abstract": "In the last year, new models and methods for pretraining and transfer learning have driven striking performance improvements across a range of language understanding tasks. The GLUE benchmark, introduced a little over one year ago, offers a single-number metric that summarizes progress on a diverse set of such tasks, but performance on the benchmark has recently surpassed the level of non-expert humans, suggesting limited headroom for further research. In this paper we present SuperGLUE, a new benchmark styled after GLUE with a new set of more difficult language understanding tasks, a software toolkit, and a public leaderboard. SuperGLUE is available at this http URL.",
    "authors": [
        "Alex Wang",
        "Yada Pruksachatkun",
        "Nikita Nangia",
        "Amanpreet Singh",
        "Julian Michael",
        "Felix Hill",
        "Omer Levy",
        "Samuel R. Bowman"
    ],
    "venue": "Neural Information Processing Systems",
    "year": 2019,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A new benchmark styled after GLUE is presented, a new set of more difficult language understanding tasks, a software toolkit, and a public leaderboard are presented."
    },
    "citationCount": 1915,
    "influentialCitationCount": 266,
    "code": null,
    "description": null,
    "url": null
}