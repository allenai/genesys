{
    "acronym": "85bb1317013141d5e5f41d18376cd7257c46264a",
    "title": "Document Classification for COVID-19 Literature",
    "seed_ids": [
        "longformer",
        "925ad2897d1b5decbea320d07e99afa9110e09b2"
    ],
    "s2id": "85bb1317013141d5e5f41d18376cd7257c46264a",
    "abstract": "The global pandemic has made it more important than ever to quickly and accurately retrieve relevant scientific literature for effective consumption by researchers in a wide range of fields. We provide an analysis of several multi-label document classification models on the LitCovid dataset. We find that pre-trained language models outperform other models in both low and high data regimes, achieving a maximum F1 score of around 86%. We note that even the highest performing models still struggle with label correlation, distraction from introductory text and CORD-19 generalization. Both data and code are available on GitHub.",
    "authors": [
        "Bernal Jimenez Gutierrez",
        "Juncheng Zeng",
        "Dongdong Zhang",
        "Ping Zhang",
        "Yu Su"
    ],
    "venue": "NLPCOVID19",
    "year": 2020,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Analysis of several multi-label document classification models on the LitCovid dataset finds that pre-trained language models outperform other models in both low and high data regimes, achieving a maximum F1 score of around 86%."
    },
    "citationCount": 30,
    "influentialCitationCount": 3,
    "code": null,
    "description": null,
    "url": null
}