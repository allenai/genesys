{
    "acronym": "a3bd6467d14d571af6181614e35a3d1254c92bcd",
    "title": "TCE at Qur\u2019an QA 2023 Shared Task: Low Resource Enhanced Transformer-based Ensemble Approach for Qur\u2019anic QA",
    "seed_ids": [
        "bert",
        "2c953a3c378b40dadf2e3fb486713c8608b8e282"
    ],
    "s2id": "a3bd6467d14d571af6181614e35a3d1254c92bcd",
    "abstract": "In this paper, we present our approach to tackle Qur\u2019an QA 2023 shared tasks A and B. To address the challenge of low-resourced training data, we rely on transfer learning together with a voting ensemble to improve prediction stability across multiple runs. Additionally, we employ different architectures and learning mechanisms for a range of Arabic pre-trained transformer-based models for both tasks. To identify unanswerable questions, we propose using a thresholding mechanism. Our top-performing systems greatly surpass the baseline performance on the hidden split, achieving a MAP score of 25.05% for task A and a partial Average Precision (pAP) of 57.11% for task B.",
    "authors": [
        "Mohammed Elkomy",
        "Amany Sarhan"
    ],
    "venue": "ARABICNLP",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The approach to tackle Qur\u2019an QA 2023 shared tasks A and B relies on transfer learning together with a voting ensemble to improve prediction stability across multiple runs and proposes using a thresholding mechanism to identify unanswerable questions."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}