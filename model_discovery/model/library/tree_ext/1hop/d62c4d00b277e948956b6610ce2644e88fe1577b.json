{
    "acronym": "d62c4d00b277e948956b6610ce2644e88fe1577b",
    "title": "Large Language Models",
    "seed_ids": [
        "gpt",
        "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d",
        "272afc28d03890160b1f2808cc551c962ea9138c",
        "e82e3f4347674b75c432cb80604d38ee630d4bf6",
        "453fc588d97958c6fefad96e79edd896873b3e09",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "d62c4d00b277e948956b6610ce2644e88fe1577b",
    "abstract": "Large Language ModelsIn the latest edition of Stats, STAT!, Fralick and colleagues explain the statistics behind large language models - used in chat bots like ChatGPT and Bard. While these new tools may seem remarkably intelligent, at their core they just assemble sentences based on statistics from large amounts of text.",
    "authors": [
        "Michael R Douglas"
    ],
    "venue": "Communications of the ACM",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": null
    },
    "citationCount": 264,
    "influentialCitationCount": 16,
    "code": null,
    "description": null,
    "url": null
}