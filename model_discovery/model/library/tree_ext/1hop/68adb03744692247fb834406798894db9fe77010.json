{
    "acronym": "68adb03744692247fb834406798894db9fe77010",
    "title": "A Survey on Long Text Modeling with Transformers",
    "seed_ids": [
        "bigbird",
        "longformer",
        "longt5",
        "661e8d555c4424b5953f17434f2ba910bfcf3afe",
        "3bcea238b0c323d8f891829714bbe6e8a3de894c",
        "077f3c382d0dce221cf6aaef0e7185a249b71b9f",
        "9166caa474031b62bacad8a920db8308e6a15120",
        "3b39efe6c91ae432dd35bb79431edb8a6719f906",
        "732e3faec4e5be4d144256f2c379b9dc49f0b227",
        "f8d44802ac8190864c61c9aaf4a8b450261873ab",
        "4eb45f33446018175e266738be22f4d830ed697e",
        "85e3cf70079adb1db8b1b50321a5d336edc1c3fa",
        "3d318019788418b21478e8736d03afadc1607690",
        "33d15b2d2a434ab33a2a88585604f4728a324baf",
        "24b951275a7a42ef36aca8352caaf6f4cd6238d2",
        "e96493b4181de6c60b761dc66492db8e66fd784f",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "3dfb1f50f2a34a699c339dabaa6f9b3a977973de",
        "c600b697700c844cbc85009be70f1cdfeef3593e",
        "0a41cb292242a82b2b09b3bf23b48349b981a640",
        "d8d2e574965fe733eb1416e03df2b5c2914fc530",
        "af679d69fcc1d0fcf0f039aba937853bcb50a8de",
        "f4566761fe39c4b5273d696d9bc3f4195c9325bb",
        "9dc624d7258d1a56117ca720aea953ce46b66b21",
        "9ed25f101f19ea735ca300848948ed64064b97ca",
        "afad10da0a3b83a4f2a94e8c16c84ac64338e9fe",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
        "7e5709d81558d3ef4265de29ea75931afeb1f2dd",
        "6f68e1bb253925d8431588555d3010419f322e04",
        "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
        "0b991a1a5bcdb13646ac0b6873d09bde4cc36fb5",
        "d27669c82faf78ea08cceaa0a171b540cccc304d",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "34a4e6818d680875ff0bef9a76de0376118446d1",
        "f51497f463566581874c941353dd9d80069c5b77",
        "2cf3bd0cc1382f35384e259d99e4f9744eeaed28",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "203b543bfa1e564bb80ff4229b43174d7c71b0c0",
        "6cea705be536770d363c56d6db6da51bfb642499",
        "63b5226b5cea33e7b862f737d5bf1a766ea3281a",
        "4d244972ed2e0286363bfb054cb269574d21a72c",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "68adb03744692247fb834406798894db9fe77010",
    "abstract": "Modeling long texts has been an essential technique in the field of natural language processing (NLP). With the ever-growing number of long documents, it is important to develop effective modeling methods that can process and analyze such texts. However, long texts pose important research challenges for existing text models, with more complex semantics and special characteristics. In this paper, we provide an overview of the recent advances on long texts modeling based on Transformer models. Firstly, we introduce the formal definition of long text modeling. Then, as the core content, we discuss how to process long input to satisfy the length limitation and design improved Transformer architectures to effectively extend the maximum context length. Following this, we discuss how to adapt Transformer models to capture the special characteristics of long texts. Finally, we describe four typical applications involving long text modeling and conclude this paper with a discussion of future directions. Our survey intends to provide researchers with a synthesis and pointer to related work on long text modeling.",
    "authors": [
        "Zican Dong",
        "Tianyi Tang",
        "Lunyi Li",
        "Wayne Xin Zhao"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "An overview of the recent advances on long texts modeling based on Transformer models is provided and four typical applications involving long text modeling are described."
    },
    "citationCount": 37,
    "influentialCitationCount": 3,
    "code": null,
    "description": null,
    "url": null
}