{
    "acronym": "157ed5647da39a7f5d33a84a90414b2a9e97e301",
    "title": "Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence",
    "seed_ids": [
        "rwkv4",
        "hgrn",
        "aft",
        "d53fe76bd2795a19ddf52d012917782f6f6f2c1e",
        "917096f28209ef90c9e6363cf49438341120af5e",
        "de41158515fa7260a0983e787650884a98eed811",
        "434d751d355d7a7c20efa570e785c76286245e77",
        "fdc53c2c10742464087c0525f77e32604827a21d",
        "240103933ffe3dac2179cc160a2bd91299357a53",
        "17fbffb05fa14e21d1c506fd5f0f568b955fe983",
        "026b3396a63ed5772329708b7580d633bb86bec9",
        "f393aff1593c2d370ec0ae004910d18e40524967",
        "998ac3e945857cf2676ee7efdbaf443a0c6f820a",
        "5a77b508302771fc083bf24e0bcda8553c9b5421",
        "70e91e16eb321067d9402710e14a40cf28311f73",
        "87c5b281fa43e6f27191b20a8dd694eda1126336",
        "3dfb1f50f2a34a699c339dabaa6f9b3a977973de",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "d5e999aae76d5270ef272076979c809817458212",
        "6fa1cfc4f97f03a8485692418c7aa1a06c574a85",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
        "7e5709d81558d3ef4265de29ea75931afeb1f2dd",
        "6f68e1bb253925d8431588555d3010419f322e04",
        "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "34a4e6818d680875ff0bef9a76de0376118446d1",
        "04f4e55e14150b7c48b0287ba77c7443df76ed45",
        "f51497f463566581874c941353dd9d80069c5b77",
        "2cf3bd0cc1382f35384e259d99e4f9744eeaed28",
        "92e121c6e114fe3cfb89370df03847c66a9b4e28",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "157ed5647da39a7f5d33a84a90414b2a9e97e301",
    "abstract": "We present Eagle (RWKV-5) and Finch (RWKV-6), sequence models improving upon the RWKV (RWKV-4) architecture. Our architectural design advancements include multi-headed matrix-valued states and a dynamic recurrence mechanism that improve expressivity while maintaining the inference efficiency characteristics of RNNs. We introduce a new multilingual corpus with 1.12 trillion tokens and a fast tokenizer based on greedy matching for enhanced multilinguality. We trained four Eagle models, ranging from 0.46 to 7.5 billion parameters, and two Finch models with 1.6 and 3.1 billion parameters and find that they achieve competitive performance across a wide variety of benchmarks. We release all our models on HuggingFace under the Apache 2.0 license. Models at: https://huggingface.co/RWKV Training code at: https://github.com/RWKV/RWKV-LM Inference code at: https://github.com/RWKV/ChatRWKV Time-parallel training code at: https://github.com/RWKV/RWKV-infctx-trainer",
    "authors": [
        "Bo Peng",
        "Daniel Goldstein",
        "Quentin Anthony",
        "Alon Albalak",
        "Eric Alcaide",
        "Stella Biderman",
        "Eugene Cheah",
        "Teddy Ferdinan",
        "Haowen Hou",
        "P. Kazienko",
        "G. Kranthikiran",
        "Jan Koco'n",
        "Bartlomiej Koptyra",
        "Satyapriya Krishna",
        "Ronald McClelland",
        "Niklas Muennighoff",
        "Fares Obeid",
        "Atsushi Saito",
        "Guangyu Song",
        "Haoqin Tu",
        "Stanislaw Wo'zniak",
        "Ruichong Zhang",
        "Bingchen Zhao",
        "Qihang Zhao",
        "Peng Zhou",
        "Jian Zhu",
        "Ruijie Zhu"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work presents Eagle and Finch, sequence models improving upon the RWKV (RWKV-4) architecture, which introduces a new multilingual corpus with 1.12 trillion tokens and a fast tokenizer based on greedy matching for enhanced multilinguality."
    },
    "citationCount": 18,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}