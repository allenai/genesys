{
    "acronym": "f886006fdf3681aeb115445d6fd828d794a42a14",
    "title": "Enhanced Visual Question Answering: A Comparative Analysis and Textual Feature Extraction Via Convolutions",
    "seed_ids": [
        "transformer"
    ],
    "s2id": "f886006fdf3681aeb115445d6fd828d794a42a14",
    "abstract": "Visual Question Answering (VQA) has emerged as a highly engaging field in recent years, attracting increasing research efforts aiming to enhance VQA accuracy through the deployment of advanced models such as Transformers. Despite this growing interest, there has been limited exploration into the comparative analysis and impact of textual modalities within VQA, particularly in terms of model complexity and its effect on performance. In this work, we conduct a comprehensive comparison between complex textual models that leverage long dependency mechanisms and simpler models focusing on local textual features within a well-established VQA framework. Our findings reveal that employing complex textual encoders is not invariably the optimal approach for the VQA-v2 dataset. Motivated by this insight, we introduce an improved model, ConvGRU, which incorporates convolutional layers to enhance the representation of question text. Tested on the VQA-v2 dataset, ConvGRU achieves better performance without substantially increasing parameter complexity.",
    "authors": [
        "Zhilin Zhang"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is revealed that employing complex textual encoders is not invariably the optimal approach for the VQA-v2 dataset, and an improved model is introduced, ConvGRU, which incorporates convolutional layers to enhance the representation of question text."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}