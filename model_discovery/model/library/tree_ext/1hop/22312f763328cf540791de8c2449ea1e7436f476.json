{
    "acronym": "22312f763328cf540791de8c2449ea1e7436f476",
    "title": "UniTAB: Unifying Text and Box Outputs for Grounded Vision-Language Modeling",
    "seed_ids": [
        "gpt",
        "5e00596fa946670d894b1bdaeff5a98e3867ef13"
    ],
    "s2id": "22312f763328cf540791de8c2449ea1e7436f476",
    "abstract": null,
    "authors": [
        "Zhengyuan Yang",
        "Zhe Gan",
        "Jianfeng Wang",
        "Xiaowei Hu",
        "Faisal Ahmed",
        "Zicheng Liu",
        "Yumao Lu",
        "Lijuan Wang"
    ],
    "venue": "European Conference on Computer Vision",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "UniTAB\u2019s unified multi-task network and the task-agnostic output sequence design make the model parameter efficient and generalizable to new tasks, and could provide a more comprehensive and interpretable image description."
    },
    "citationCount": 93,
    "influentialCitationCount": 10,
    "code": null,
    "description": null,
    "url": null
}