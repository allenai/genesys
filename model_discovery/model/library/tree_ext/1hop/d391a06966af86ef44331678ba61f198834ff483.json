{
    "acronym": "d391a06966af86ef44331678ba61f198834ff483",
    "title": "Large Language Models on Lexical Semantic Change Detection: An Evaluation",
    "seed_ids": [
        "bert",
        "0b0debb710366cdff461938c80763eace1651af6"
    ],
    "s2id": "d391a06966af86ef44331678ba61f198834ff483",
    "abstract": "Lexical Semantic Change Detection stands out as one of the few areas where Large Language Models (LLMs) have not been extensively involved. Traditional methods like PPMI, and SGNS remain prevalent in research, alongside newer BERT-based approaches. Despite the comprehensive coverage of various natural language processing domains by LLMs, there is a notable scarcity of literature concerning their application in this specific realm. In this work, we seek to bridge this gap by introducing LLMs into the domain of Lexical Semantic Change Detection. Our work presents novel prompting solutions and a comprehensive evaluation that spans all three generations of language models, contributing to the exploration of LLMs in this research area.",
    "authors": [
        "Ruiyu Wang",
        "Matthew Choi"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work presents novel prompting solutions and a comprehensive evaluation that spans all three generations of language models, contributing to the exploration of LLMs in this research area."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}