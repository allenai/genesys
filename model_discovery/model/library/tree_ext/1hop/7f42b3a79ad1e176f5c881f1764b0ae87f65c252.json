{
    "acronym": "7f42b3a79ad1e176f5c881f1764b0ae87f65c252",
    "title": "Comparing Specialised Small and General Large Language Models on Text Classification: 100 Labelled Samples to Achieve Break-Even Performance",
    "seed_ids": [
        "gpt3",
        "bert",
        "7011bf9aa7e68fabaa1df498da6d2dd8a950f037",
        "dc385646887a3669ae0ee506a263d592f4f7c7a6",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "85e7d63f75c0916bd350a229e040c5fbb1472e7a",
        "d9f6ada77448664b71128bb19df15765336974a6"
    ],
    "s2id": "7f42b3a79ad1e176f5c881f1764b0ae87f65c252",
    "abstract": "When solving NLP tasks with limited labelled data, researchers can either use a general large language model without further update, or use a small number of labelled examples to tune a specialised smaller model. In this work, we address the research gap of how many labelled samples are required for the specialised small models to outperform general large models, while taking the performance variance into consideration. By observing the behaviour of fine-tuning, instruction-tuning, prompting and in-context learning on 7 language models, we identify such performance break-even points across 8 representative text classification tasks of varying characteristics. We show that the specialised models often need only few samples (on average $10 - 1000$) to be on par or better than the general ones. At the same time, the number of required labels strongly depends on the dataset or task characteristics, with this number being significantly lower on multi-class datasets (up to $100$) than on binary datasets (up to $5000$). When performance variance is taken into consideration, the number of required labels increases on average by $100 - 200\\%$ and even up to $1500\\%$ in specific cases.",
    "authors": [
        "Branislav Pecher",
        "Ivan Srba",
        "M. Bielikov\u00e1"
    ],
    "venue": "",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work addresses the research gap of how many labelled samples are required for the specialised small models to outperform general large models, while taking the performance variance into consideration."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}