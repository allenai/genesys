{
    "acronym": "8a11e0d0d1acdffc37d8eb1b33ca2b64bc9e851f",
    "title": "VPDETR: End-to-End Vanishing Point DEtection TRansformers",
    "seed_ids": [
        "transformer"
    ],
    "s2id": "8a11e0d0d1acdffc37d8eb1b33ca2b64bc9e851f",
    "abstract": "In the field of vanishing point detection, previous works commonly relied on extracting and clustering straight lines or classifying candidate points as vanishing points. This paper proposes a novel end-to-end framework, called VPDETR (Vanishing Point DEtection TRansformer), that views vanishing point detection as a set prediction problem, applicable to both Manhattan and non-Manhattan world datasets. By using the positional embedding of anchor points as queries in Transformer decoders and dynamically updating them layer by layer, our method is able to directly input images and output their vanishing points without the need for explicit straight line extraction and candidate points sampling. Additionally, we introduce an orthogonal loss and a cross-prediction loss to improve accuracy on the Manhattan world datasets. Experimental results demonstrate that VPDETR achieves competitive performance compared to state-of-the-art methods, without requiring post-processing.",
    "authors": [
        "Taiyan Chen",
        "Xianghua Ying",
        "Jinfa Yang",
        "Ruibin Wang",
        "Ruohao Guo",
        "Bowei Xing",
        "Ji Shi"
    ],
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper proposes a novel end-to-end framework, called VPDETR (Vanishing Point DEtection TRansformer), that views vanishing point detection as a set prediction problem, applicable to both Manhattan and non-Manhattan world datasets."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}