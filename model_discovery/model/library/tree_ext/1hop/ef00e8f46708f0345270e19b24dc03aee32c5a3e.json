{
    "acronym": "ef00e8f46708f0345270e19b24dc03aee32c5a3e",
    "title": "DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and Rewriting",
    "seed_ids": [
        "bert",
        "ddef60ffeb6541003eca1b69c5c338edda0a790e",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c"
    ],
    "s2id": "ef00e8f46708f0345270e19b24dc03aee32c5a3e",
    "abstract": "Coherence in writing, an aspect that second-language (L2) English learners often struggle with, is crucial in assessing L2 English writing. Existing automated writing evaluation systems primarily use basic surface linguistic features to detect coherence in writing. However, little effort has been made to correct the detected incoherence, which could significantly benefit L2 language learners seeking to improve their writing. To bridge this gap, we introduce DECOR, a novel benchmark that includes expert annotations for detecting incoherence in L2 English writing, identifying the underlying reasons, and rewriting the incoherent sentences. To our knowledge, DECOR is the first coherence assessment dataset specifically designed for improving L2 English writing, featuring pairs of original incoherent sentences alongside their expert-rewritten counterparts. Additionally, we fine-tuned models to automatically detect and rewrite incoherence in student essays. We find that incorporating specific reasons for incoherence during fine-tuning consistently improves the quality of the rewrites, achieving a result that is favored in both automatic and human evaluations.",
    "authors": [
        "Xuanming Zhang",
        "Anthony Diaz",
        "Zixun Chen",
        "Qingyang Wu",
        "Kun Qian",
        "Erik Voss",
        "Zhou Yu"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "DECOR is the first coherence assessment dataset specifically designed for improving L2 English writing, featuring pairs of original incoherent sentences alongside their expert-rewritten counterparts, and it is found that incorporating specific reasons for incoherence during fine-tuning consistently improves the quality of the rewrites."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}