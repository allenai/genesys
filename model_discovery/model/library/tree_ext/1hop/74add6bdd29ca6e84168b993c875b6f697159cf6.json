{
    "acronym": "74add6bdd29ca6e84168b993c875b6f697159cf6",
    "title": "Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions",
    "seed_ids": [
        "gpt2",
        "be55e8ec4213868db08f2c3168ae666001bea4b8",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "74add6bdd29ca6e84168b993c875b6f697159cf6",
    "abstract": "In this paper, we investigate the interplay between attention heads and specialized\"next-token\"neurons in the Multilayer Perceptron that predict specific tokens. By prompting an LLM like GPT-4 to explain these model internals, we can elucidate attention mechanisms that activate certain next-token neurons. Our analysis identifies attention heads that recognize contexts relevant to predicting a particular token, activating the associated neuron through the residual connection. We focus specifically on heads in earlier layers consistently activating the same next-token neuron across similar prompts. Exploring these differential activation patterns reveals that heads that specialize for distinct linguistic contexts are tied to generating certain tokens. Overall, our method combines neural explanations and probing isolated components to illuminate how attention enables context-dependent, specialized processing in LLMs.",
    "authors": [
        "Clement Neo",
        "Shay B. Cohen",
        "Fazl Barez"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This method combines neural explanations and probing isolated components to illuminate how attention enabling context-dependent, specialized processing in LLMs enables context-dependent, specialized processing in LLMs."
    },
    "citationCount": 2,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}