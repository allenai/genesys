{
    "acronym": "ecb1d0a65e3f7467dc90a43f32b17f4940a98613",
    "title": "Markedness in Visual Semantic AI",
    "seed_ids": [
        "gpt2",
        "5dd7bc394e032eb0e982699a5f0c781fab9e3111",
        "5e00596fa946670d894b1bdaeff5a98e3867ef13",
        "2cd605106b88c85d7d8b865b1ef0f8c8293debf1",
        "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8",
        "7ea0e91c5d5dc73f2133bc46d7ebb6cb83034dae",
        "039b1c1210c437f3b3ce6e0275ee2137bf5b951c",
        "5e9c85235210b59a16bdd84b444a904ae271f7e7",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "ecb1d0a65e3f7467dc90a43f32b17f4940a98613",
    "abstract": "We evaluate the state-of-the-art multimodal \u201dvisual semantic\u201d model CLIP (\u201dContrastive Language Image Pretraining\u201d) for biases related to the marking of age, gender, and race or ethnicity. Given the option to label an image as \u201da photo of a person\u201d or to select a label denoting race or ethnicity, CLIP chooses the \u201dperson\u201d label 47.9% of the time for White individuals, compared with 5.0% or less for individuals who are Black, East Asian, Southeast Asian, Indian, or Latino or Hispanic. The model is also more likely to rank the unmarked \u201dperson\u201d label higher than labels denoting gender for Male individuals (26.7% of the time) vs. Female individuals (15.2% of the time). Age also affects whether an individual is marked by the model: Female individuals under the age of 20 are more likely than Male individuals to be marked with a gender label, but less likely to be marked with an age label, while Female individuals over the age of 40 are more likely to be marked based on age than Male individuals. We trace our results back to the CLIP embedding space by examining the self-similarity (mean pairwise cosine similarity) for each social group, where higher self-similarity denotes greater attention directed by CLIP to the shared characteristics (i.e., age, race, or gender) of the social group. The results indicate that, as age increases, the self-similarity of representations of Female individuals increases at a higher rate than for Male individuals, with the disparity most pronounced at the \u201dmore than 70\u201d age range. Six of the ten least self-similar social groups are individuals who are White and Male, while all ten of the most self-similar social groups are individuals under the age of 10 or over the age of 70, and six of the ten are Female individuals. Our results yield evidence that bias in CLIP is intersectional: existing biases of self-similarity and markedness between Male and Female gender groups are further exacerbated when the groups compared are individuals who are White and Male and individuals who are Black and Female. CLIP is an English-language model trained on internet content gathered based on a query list generated from an American website (Wikipedia), and results indicate that CLIP reflects the biases of the language and society which produced this training data.",
    "authors": [
        "R. Wolfe",
        "Aylin Caliskan"
    ],
    "venue": "Conference on Fairness, Accountability and Transparency",
    "year": 2022,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Examination of the state-of-the-art multimodal \u201dvisual semantic\u201d model CLIP for biases related to the marking of age, gender, and race or ethnicity indicates that CLIP reflects the biases of the language and society which produced this training data."
    },
    "citationCount": 27,
    "influentialCitationCount": 1,
    "code": null,
    "description": null,
    "url": null
}