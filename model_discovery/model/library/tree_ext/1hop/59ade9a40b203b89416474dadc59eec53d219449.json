{
    "acronym": "59ade9a40b203b89416474dadc59eec53d219449",
    "title": "RidgeVPR: A Global Positioning Framework in Sparse Feature Outdoor Environments Using Visual Place Recognition and Ridge Line Feature Matching",
    "seed_ids": [
        "transformer",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7"
    ],
    "s2id": "59ade9a40b203b89416474dadc59eec53d219449",
    "abstract": "The GNSS (Global Navigation Satellite System) becomes indispensable for long-distance remote outdoor positioning tasks, but its stability is susceptible to various types of interference, such as suppression jamming and spoofing jamming, etc. In such scenes, global real-time positioning is hard to achieve through only visual SLAM (Simultaneous Localization and Mapping) or INS (Inertial Navigation Systems), especially in remote outdoor areas due to the prevalence of sparse features and accumulative INS accuracy degradation. In this paper, we explore a two-stage global real-time positioning framework under specific environmental conditions, which may be useful for localization applications in remote areas with sparse features. The first stage is to achieve coarse-level positioning using a single-scale feature fusion network to retrieve images from historically captured road datasets. In the second stage of fine-level positioning, we perform feature matching between the current taken image and the retrieved image, to calculate the camera pose transformation, to refine the position error between the two images. Specifically, the features are obtained from a specially designed combination of an image-level DNN (Deep Neural Network) and a ridge line feature detector, to better adapt to the low-texture environments. After that, we use the calculated camera pose and the retrieved historical image labeled with GNSS information to obtain the current image's GNSS. Experiments show the proposed image retrieval network and feature matching method achieve good results in terms of performance and accuracy. They also prove that our framework achieves global real-time positioning under GNSS suppression in our specific sparse feature datasets.",
    "authors": [
        "Shuai Zheng",
        "Bingzhuo Yu",
        "Yingjie Chen",
        "Songhao Zhang",
        "Jun Hong"
    ],
    "venue": "IEEE Transactions on Vehicular Technology",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Experiments show the proposed image retrieval network and feature matching method achieve good results in terms of performance and accuracy, and prove that the framework achieves global real-time positioning under GNSS suppression in the authors' specific sparse feature datasets."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}