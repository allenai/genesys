{
    "acronym": "e5d4f61545d026e54084bcb1ed1e3df92c7bc7b7",
    "title": "GPT on a Quantum Computer",
    "seed_ids": [
        "transformer",
        "gpt",
        "c49ac1f916d6d2edeb187e6619c8d23acd95eb21",
        "2e644c67a697073d561da4f4dad35e5ad5316cfd"
    ],
    "s2id": "e5d4f61545d026e54084bcb1ed1e3df92c7bc7b7",
    "abstract": "Large Language Models (LLMs) such as ChatGPT have transformed how we interact with and understand the capabilities of Artificial Intelligence (AI). However, the intersection of LLMs with the burgeoning field of Quantum Machine Learning (QML) is only in its nascent stages. This paper presents an exploration of this niche by detailing a comprehensive framework for implementing the foundational Transformer architecture -- integral to ChatGPT -- within a quantum computing paradigm. We meticulously design quantum circuits that implement adapted versions of the transformer's core components and the generative pre-training phase. By integrating quantum computing with LLMs, we aspire to open new avenues for research in QML and contribute to the ongoing evolution of AI technologies.",
    "authors": [
        "Yidong Liao",
        "Chris Ferrie"
    ],
    "venue": "",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper presents a comprehensive framework for implementing the foundational Transformer architecture -- integral to ChatGPT -- within a quantum computing paradigm, and meticulously design quantum circuits that implement adapted versions of the transformer's core components and the generative pre-training phase."
    },
    "citationCount": 3,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}