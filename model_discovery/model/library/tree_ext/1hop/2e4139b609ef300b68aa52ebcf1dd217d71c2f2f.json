{
    "acronym": "2e4139b609ef300b68aa52ebcf1dd217d71c2f2f",
    "title": "MiRANews: Dataset and Benchmarks for Multi-Resource-Assisted News Summarization",
    "seed_ids": [
        "memcompress",
        "9dc624d7258d1a56117ca720aea953ce46b66b21",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "83fac78857c7e65fe10a11a798674dd3cd259c1d",
        "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "7cc730da554003dda77796d2cb4f06da5dfd5592",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "2e4139b609ef300b68aa52ebcf1dd217d71c2f2f",
    "abstract": "One of the most challenging aspects of current single-document news summarization is that the summary often contains 'extrinsic hallucinations', i.e., facts that are not present in the source document, which are often derived via world knowledge. This causes summarization systems to act more like open-ended language models tending to hallucinate facts that are erroneous. In this paper, we mitigate this problem with the help of multiple supplementary resource documents assisting the task. We present a new dataset MiRANews and benchmark existing summarization models. In contrast to multi-document summarization, which addresses multiple events from several source documents, we still aim at generating a summary for a single document. We show via data analysis that it's not only the models which are to blame: more than 27% of facts mentioned in the gold summaries of MiRANews are better grounded on assisting documents than in the main source articles. An error analysis of generated summaries from pretrained models fine-tuned on MiRANews reveals that this has an even bigger effects on models: assisted summarization reduces 55% of hallucinations when compared to single-document summarization models trained on the main article only. Our code and data are available at https://github.com/XinnuoXu/MiRANews.",
    "authors": [
        "Xinnuo Xu",
        "Ondrej Dusek",
        "Shashi Narayan",
        "Verena Rieser",
        "Ioannis Konstas"
    ],
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A new dataset MiRANews is presented and assisted summarization reduces 55% of hallucinations when compared to single-document summarization models trained on the main article only, and error analysis of generated summaries from pretrained models fine-tuned on MiRanews reveals that this has an even bigger effects on models."
    },
    "citationCount": 5,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}