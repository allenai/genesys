{
    "acronym": "ca84496fa0bd042a455789eae00c98b8c4d6e0e4",
    "title": "RETSim: Resilient and Efficient Text Similarity",
    "seed_ids": [
        "flash",
        "7ca41cc5fc364b713aba5b573ae4ada801fd788a",
        "dc0102a51a9d33e104a4a3808a18cf17f057228c"
    ],
    "s2id": "ca84496fa0bd042a455789eae00c98b8c4d6e0e4",
    "abstract": "This paper introduces RETSim (Resilient and Efficient Text Similarity), a lightweight, multilingual deep learning model trained to produce robust metric embeddings for near-duplicate text retrieval, clustering, and dataset deduplication tasks. We demonstrate that RETSim is significantly more robust and accurate than MinHash and neural text embeddings, achieving new state-of-the-art performance on dataset deduplication, adversarial text retrieval benchmarks, and spam clustering tasks. We also introduce the W4NT3D benchmark (Wiki-40B 4dversarial Near-T3xt Dataset) for evaluating multilingual, near-duplicate text retrieval capabilities under adversarial settings. RETSim and the W4NT3D benchmark are open-sourced under the MIT License at https://github.com/google/unisim.",
    "authors": [
        "Marina Zhang",
        "Owen Vallis",
        "Aysegul Bumin",
        "Tanay Vakharia",
        "Elie Bursztein"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "It is demonstrated that RETSim is significantly more robust and accurate than MinHash and neural text embeddings, achieving new state-of-the-art performance on dataset deduplication, adversarial text retrieval benchmarks, and spam clustering tasks."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}