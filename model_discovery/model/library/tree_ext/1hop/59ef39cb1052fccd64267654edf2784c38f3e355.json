{
    "acronym": "59ef39cb1052fccd64267654edf2784c38f3e355",
    "title": "Correlation Dimension of Natural Language in a Statistical Manifold",
    "seed_ids": [
        "gpt2",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "59ef39cb1052fccd64267654edf2784c38f3e355",
    "abstract": "The correlation dimension of natural language is measured by applying the Grassberger-Procaccia algorithm to high-dimensional sequences produced by a large-scale language model. This method, previously studied only in a Euclidean space, is reformulated in a statistical manifold via the Fisher-Rao distance. Language exhibits a multifractal, with global self-similarity and a universal dimension around 6.5, which is smaller than those of simple discrete random sequences and larger than that of a Barab\\'asi-Albert process. Long memory is the key to producing self-similarity. Our method is applicable to any probabilistic model of real-world discrete sequences, and we show an application to music data.",
    "authors": [
        "Xin Du",
        "Kumiko Tanaka-Ishii"
    ],
    "venue": "Physical Review Research",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The correlation dimension of natural language is measured by applying the Grassberger-Procaccia algorithm to high-dimensional sequences produced by a large-scale language model through the Fisher-Rao distance, applicable to any probabilistic model of real-world discrete sequences."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}