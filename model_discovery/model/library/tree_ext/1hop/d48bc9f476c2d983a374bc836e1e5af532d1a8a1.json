{
    "acronym": "d48bc9f476c2d983a374bc836e1e5af532d1a8a1",
    "title": "ConvMLP: Hierarchical Convolutional MLPs for Vision",
    "seed_ids": [
        "gmlp",
        "a883336e5c2e9f46f5012343227a6be4671c9ca0",
        "f75cddf2d42ed01b34686704eb3504becef67442",
        "71363797140647ebb3f540584de0a8758d2f7aa2",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7"
    ],
    "s2id": "d48bc9f476c2d983a374bc836e1e5af532d1a8a1",
    "abstract": "MLP-based architectures, which consist of a sequence of consecutive multi-layer perceptron blocks, have recently been found to reach comparable results to convolutional and transformer-based methods on image classification. However, most methods adopt spatial MLPs which take fixed-dimension inputs, therefore making it difficult to apply them as backbones to downstream tasks such as object detection and semantic segmentation, which require inputs with arbitrary dimension. Moreover, single-stage designs further limit the performance in other computer vision tasks and fully-connected layers bear heavy computation. To tackle these problems, we propose ConvMLP: a Hierarchical Convolutional MLP for visual recognition, which is a lightweight, stage-wise, co-design of convolution layers, and MLPs. In particular, ConvMLP-S achieves 76.8% top-1 accuracy on ImageNet-1k with 9M parameters and 2.4 GMACs (15% and 19% of MLP-Mixer-B/16, respectively). Experiments on object detection and semantic segmentation further show that visual representation learned by ConvMLP can be seamlessly transferred to downstream tasks and achieve competitive results with fewer parameters. Our code and pre-trained models are open-sourced at https://github.com/SHI-Labs/Convolutional-MLPs.",
    "authors": [
        "Jiachen Li",
        "Ali Hassani",
        "Steven Walton",
        "Humphrey Shi"
    ],
    "venue": "2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
    "year": 2021,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Experiments on object detection and semantic segmentation show that visual representation learned by ConvMLP can be seamlessly transferred to downstream tasks and achieve competitive results with fewer parameters."
    },
    "citationCount": 51,
    "influentialCitationCount": 9,
    "code": null,
    "description": null,
    "url": null
}