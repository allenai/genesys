{
    "acronym": "85722b13631d9846866d45ff2bfc2a2fe1026ac8",
    "title": "LLMRec: Benchmarking Large Language Models on Recommendation Task",
    "seed_ids": [
        "gpt2",
        "ca7bd64d372e3bcb3f4633ca4a20291ff57de3c3",
        "cbf3bf8f541f5b446c59c8deacbcc18527768c75",
        "df602516e28a9ef0ef665ed0aef551984d8d770d",
        "50796b0f3edf9cb5ff1e447c298b33755378aa4f",
        "690edf44e8739fd80bdfb76f40c9a4a222f3bba8",
        "9405cc0d6169988371b2755e573cc28650d14dfe"
    ],
    "s2id": "85722b13631d9846866d45ff2bfc2a2fe1026ac8",
    "abstract": "Recently, the fast development of Large Language Models (LLMs) such as ChatGPT has significantly advanced NLP tasks by enhancing the capabilities of conversational models. However, the application of LLMs in the recommendation domain has not been thoroughly investigated. To bridge this gap, we propose LLMRec, a LLM-based recommender system designed for benchmarking LLMs on various recommendation tasks. Specifically, we benchmark several popular off-the-shelf LLMs, such as ChatGPT, LLaMA, ChatGLM, on five recommendation tasks, including rating prediction, sequential recommendation, direct recommendation, explanation generation, and review summarization. Furthermore, we investigate the effectiveness of supervised finetuning to improve LLMs' instruction compliance ability. The benchmark results indicate that LLMs displayed only moderate proficiency in accuracy-based tasks such as sequential and direct recommendation. However, they demonstrated comparable performance to state-of-the-art methods in explainability-based tasks. We also conduct qualitative evaluations to further evaluate the quality of contents generated by different models, and the results show that LLMs can truly understand the provided information and generate clearer and more reasonable results. We aspire that this benchmark will serve as an inspiration for researchers to delve deeper into the potential of LLMs in enhancing recommendation performance. Our codes, processed data and benchmark results are available at https://github.com/williamliujl/LLMRec.",
    "authors": [
        "Junling Liu",
        "Chao-Hong Liu",
        "Peilin Zhou",
        "Qichen Ye",
        "Dading Chong",
        "Kangan Zhou",
        "Yueqi Xie",
        "Yuwei Cao",
        "Shoujin Wang",
        "Chenyu You",
        "Philip S.Yu"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes LLMRec, a LLM-based recommender system designed for benchmarking LLMs on various recommendation tasks, and benchmark results indicate that LLMs displayed only moderate proficiency in accuracy-based tasks such as sequential and direct recommendation."
    },
    "citationCount": 14,
    "influentialCitationCount": 3,
    "code": null,
    "description": null,
    "url": null
}