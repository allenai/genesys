{
    "acronym": "05b6e5fabafb08283a7b89db45f72a40d5b4c7ad",
    "title": "Unknown Script: Impact of Script on Cross-Lingual Transfer",
    "seed_ids": [
        "bert",
        "2fa3f7ce620a1c7155daef6620dd6bb0e01934f3",
        "b76e98a0a023d37c6534aa2ead09c8ff595f0bae"
    ],
    "s2id": "05b6e5fabafb08283a7b89db45f72a40d5b4c7ad",
    "abstract": "Cross-lingual transfer has become an effective way of transferring knowledge between languages. In this paper, we explore an often overlooked aspect in this domain: the influence of the source language of a language model on language transfer performance. We consider a case where the target language and its script are not part of the pre-trained model. We conduct a series of experiments on monolingual and multilingual models that are pre-trained on different tokenization methods to determine factors that affect cross-lingual transfer to a new language with a unique script. Our findings reveal the importance of the tokenizer as a stronger factor than the shared script, language similarity, and model size.",
    "authors": [
        "Wondimagegnhue Tufa",
        "Ilia Markov",
        "Piek Vossen"
    ],
    "venue": "North American Chapter of the Association for Computational Linguistics",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper conducts a series of experiments on monolingual and multilingual models that are pre-trained on different tokenization methods to determine factors that affect cross-lingual transfer to a new language with a unique script."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}