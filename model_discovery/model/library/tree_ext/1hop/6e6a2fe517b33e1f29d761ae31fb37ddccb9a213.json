{
    "acronym": "6e6a2fe517b33e1f29d761ae31fb37ddccb9a213",
    "title": "A Large-Scale Multi-Document Summarization Dataset from the Wikipedia Current Events Portal",
    "seed_ids": [
        "memcompress"
    ],
    "s2id": "6e6a2fe517b33e1f29d761ae31fb37ddccb9a213",
    "abstract": "Multi-document summarization (MDS) aims to compress the content in large document collections into short summaries and has important applications in story clustering for newsfeeds, presentation of search results, and timeline generation. However, there is a lack of datasets that realistically address such use cases at a scale large enough for training supervised models for this task. This work presents a new dataset for MDS that is large both in the total number of document clusters and in the size of individual clusters. We build this dataset by leveraging the Wikipedia Current Events Portal (WCEP), which provides concise and neutral human-written summaries of news events, with links to external source articles. We also automatically extend these source articles by looking for related articles in the Common Crawl archive. We provide a quantitative analysis of the dataset and empirical results for several state-of-the-art MDS techniques.",
    "authors": [
        "D. Ghalandari",
        "Chris Hokamp",
        "N. Pham",
        "John Glover",
        "Georgiana Ifrim"
    ],
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2020,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work presents a new dataset for MDS that is large both in the total number of document clusters and in the size of individual clusters, and provides a quantitative analysis of the dataset and empirical results for several state-of-the-art MDS techniques."
    },
    "citationCount": 90,
    "influentialCitationCount": 11,
    "code": null,
    "description": null,
    "url": null
}