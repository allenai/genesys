{
    "acronym": "8ebdf9e8fd61b9255bd39dacdd0878f8c0d68c43",
    "title": "Attentive Multi-Layer Perceptron for Non-autoregressive Generation",
    "seed_ids": [
        "abc",
        "performer",
        "2d629fa3d687cfc453c6b61909c46983ebea0323",
        "70e91e16eb321067d9402710e14a40cf28311f73",
        "1944cebf4e41a10ea7bd02ce30404c18c9c4e04f",
        "c49ac1f916d6d2edeb187e6619c8d23acd95eb21",
        "e0cbbca02b332f398c6639b3bea0613f79166220",
        "f75cddf2d42ed01b34686704eb3504becef67442",
        "9ed25f101f19ea735ca300848948ed64064b97ca",
        "6fa1cfc4f97f03a8485692418c7aa1a06c574a85",
        "35a9749df07a2ab97c51af4d260b095b00da7676",
        "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
        "925ad2897d1b5decbea320d07e99afa9110e09b2",
        "657329c633709dd1ac34a30d57341b186b1a47c2",
        "34a4e6818d680875ff0bef9a76de0376118446d1",
        "366244acdd930e488ae224ab6e2a92dc24aa7e06",
        "c8b25fab5608c3e033d34b4483ec47e68ba109b7"
    ],
    "s2id": "8ebdf9e8fd61b9255bd39dacdd0878f8c0d68c43",
    "abstract": null,
    "authors": [
        "Shuyang Jiang",
        "Jinchao Zhang",
        "Jiangtao Feng",
        "Lin Zheng",
        "Lingpeng Kong"
    ],
    "venue": "ECML/PKDD",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel MLP variant, Attentive-Multi-Layer-AMLP, to produce a generation model with linear time and space complexity, which surpasses competitive efficient NAR models, by a significant margin on text-to-speech synthesis and machine translation."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}