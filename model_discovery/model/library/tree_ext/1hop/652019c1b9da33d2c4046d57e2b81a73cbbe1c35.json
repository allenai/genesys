{
    "acronym": "652019c1b9da33d2c4046d57e2b81a73cbbe1c35",
    "title": "SUM: Saliency Unification through Mamba for Visual Attention Modeling",
    "seed_ids": [
        "mamba",
        "62ac3ef81e54e1d1930fb5980b236345ee2e4f32",
        "0a32e6ff6eaac83ff325bae4557a8362222979aa",
        "b24e899ec0f77eef2fc87a9b8e50516367aa1f97",
        "38c48a1cd296d16dc9c56717495d6e44cc354444",
        "745594bd0dc3e9dc86f74e100cd2c98ed36256c0",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51"
    ],
    "s2id": "652019c1b9da33d2c4046d57e2b81a73cbbe1c35",
    "abstract": "Visual attention modeling, important for interpreting and prioritizing visual stimuli, plays a significant role in applications such as marketing, multimedia, and robotics. Traditional saliency prediction models, especially those based on Convolutional Neural Networks (CNNs) or Transformers, achieve notable success by leveraging large-scale annotated datasets. However, the current state-of-the-art (SOTA) models that use Transformers are computationally expensive. Additionally, separate models are often required for each image type, lacking a unified approach. In this paper, we propose Saliency Unification through Mamba (SUM), a novel approach that integrates the efficient long-range dependency modeling of Mamba with U-Net to provide a unified model for diverse image types. Using a novel Conditional Visual State Space (C-VSS) block, SUM dynamically adapts to various image types, including natural scenes, web pages, and commercial imagery, ensuring universal applicability across different data types. Our comprehensive evaluations across five benchmarks demonstrate that SUM seamlessly adapts to different visual characteristics and consistently outperforms existing models. These results position SUM as a versatile and powerful tool for advancing visual attention modeling, offering a robust solution universally applicable across different types of visual content.",
    "authors": [
        "Alireza Hosseini",
        "A. Kazerouni",
        "Saeed Akhavan",
        "Michael Brudno",
        "Babak Taati"
    ],
    "venue": "arXiv.org",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper proposes Saliency Unification through Mamba (SUM), a novel approach that integrates the efficient long-range dependency modeling of Mamba with U-Net to provide a unified model for diverse image types, ensuring universal applicability across different data types."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}