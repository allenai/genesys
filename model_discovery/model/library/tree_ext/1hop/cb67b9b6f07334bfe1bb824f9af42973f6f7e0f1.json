{
    "acronym": "cb67b9b6f07334bfe1bb824f9af42973f6f7e0f1",
    "title": "Memory Gym: Partially Observable Challenges to Memory-Based Agents in Endless Episodes",
    "seed_ids": [
        "mentaltimetravel",
        "d98b5c1d0f9a4e39dc79ea7a3f74e54789df5e13",
        "32c9b3859086d15184989454eb878638659e64c6",
        "3f3c01adbdd433d515c19ac8cf6c61c905f0061a",
        "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51",
        "008cfd24dfdfb28fc6a89c32772c7ffe5cb0cf8a",
        "59a916cdc943f0282908e6f3fa0360f4c5fb78d0"
    ],
    "s2id": "cb67b9b6f07334bfe1bb824f9af42973f6f7e0f1",
    "abstract": "Memory Gym introduces a unique benchmark designed to test Deep Reinforcement Learning agents, specifically comparing Gated Recurrent Unit (GRU) against Transformer-XL (TrXL), on their ability to memorize long sequences, withstand noise, and generalize. It features partially observable 2D environments with discrete controls, namely Mortar Mayhem, Mystery Path, and Searing Spotlights. These originally finite environments are extrapolated to novel endless tasks that act as an automatic curriculum, drawing inspiration from the car game \u201cI packed my bag\u201d. These endless tasks are not only beneficial for evaluating efficiency but also intriguingly valuable for assessing the effectiveness of approaches in memory-based agents. Given the scarcity of publicly available memory baselines, we contribute an implementation driven by TrXL and Proximal Policy Optimization. This implementation leverages TrXL as episodic memory using a sliding window approach. In our experiments on the finite environments, TrXL demonstrates superior sample efficiency in Mystery Path and outperforms in Mortar Mayhem. However, GRU is more efficient on Searing Spotlights. Most notably, in all endless tasks, GRU makes a remarkable resurgence, consistently outperforming TrXL by significant margins.",
    "authors": [
        "Marco Pleines",
        "M. Pallasch",
        "F. Zimmer",
        "M. Preuss"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "An implementation driven by TrXL and Proximal Policy Optimization is contributed, which leverages TrXL as episodic memory using a sliding window approach and makes a remarkable resurgence, consistently outperforming TrXL by significant margins."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}