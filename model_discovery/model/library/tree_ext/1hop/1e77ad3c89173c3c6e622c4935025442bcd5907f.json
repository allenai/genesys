{
    "acronym": "1e77ad3c89173c3c6e622c4935025442bcd5907f",
    "title": "Modal-adaptive Knowledge-enhanced Graph-based Financial Prediction from Monetary Policy Conference Calls with LLM",
    "seed_ids": [
        "bert",
        "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
        "50796b0f3edf9cb5ff1e447c298b33755378aa4f"
    ],
    "s2id": "1e77ad3c89173c3c6e622c4935025442bcd5907f",
    "abstract": "Financial prediction from Monetary Policy Conference (MPC) calls is a new yet challenging task, which targets at predicting the price movement and volatility for specific financial assets by analyzing multimodal information including text, video, and audio. Although the existing work has achieved great success using cross-modal transformer blocks, it overlooks the potential external financial knowledge, the varying contributions of different modalities to financial prediction, as well as the innate relations among different financial assets. To tackle these limitations, we propose a novel Modal-Adaptive kNowledge-enhAnced Graph-basEd financial pRediction scheme, named MANAGER. Specifically, MANAGER resorts to FinDKG to obtain the external related knowledge for the input text. Meanwhile, MANAGER adopts BEiT-3 and Hidden-unit BERT (HuBERT) to extract the video and audio features, respectively. Thereafter, MANAGER introduces a novel knowledge-enhanced cross-modal graph that fully characterizes the semantic relations among text, external knowledge, video and audio, to adaptively utilize the information in different modalities, with ChatGLM2 as the backbone. Extensive experiments on a publicly available dataset Monopoly verify the superiority of our model over cutting-edge methods.",
    "authors": [
        "Kun Ouyang",
        "Yi Liu",
        "Shicheng Li",
        "Ruihan Bao",
        "Keiko Harimoto",
        "Xu Sun"
    ],
    "venue": "FINNLP",
    "year": 2024,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A novel Modal-Adaptive kNowledge-enhAnced Graph-basEd financial pRediction scheme, named MANAGER, which fully characterizes the semantic relations among text, external knowledge, video and audio, to adaptively utilize the information in different modalities."
    },
    "citationCount": 1,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}