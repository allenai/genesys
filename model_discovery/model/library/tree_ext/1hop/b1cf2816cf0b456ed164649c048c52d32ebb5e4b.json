{
    "acronym": "b1cf2816cf0b456ed164649c048c52d32ebb5e4b",
    "title": "\"Beware of deception\": Detecting Half-Truth and Debunking it through Controlled Claim Editing",
    "seed_ids": [
        "gpt"
    ],
    "s2id": "b1cf2816cf0b456ed164649c048c52d32ebb5e4b",
    "abstract": "The prevalence of half-truths, which are statements containing some truth but that are ultimately deceptive, has risen with the increasing use of the internet. To help combat this problem, we have created a comprehensive pipeline consisting of a half-truth detection model and a claim editing model. Our approach utilizes the T5 model for controlled claim editing;\"controlled\"here means precise adjustments to select parts of a claim. Our methodology achieves an average BLEU score of 0.88 (on a scale of 0-1) and a disinfo-debunk score of 85% on edited claims. Significantly, our T5-based approach outperforms other Language Models such as GPT2, RoBERTa, PEGASUS, and Tailor, with average improvements of 82%, 57%, 42%, and 23% in disinfo-debunk scores, respectively. By extending the LIAR PLUS dataset, we achieve an F1 score of 82% for the half-truth detection model, setting a new benchmark in the field. While previous attempts have been made at half-truth detection, our approach is, to the best of our knowledge, the first to attempt to debunk half-truths.",
    "authors": [
        "Sandeep Singamsetty",
        "Nishtha Madaan",
        "S. Mehta",
        "Varad Bhatnagar",
        "P. Bhattacharyya"
    ],
    "venue": "arXiv.org",
    "year": 2023,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This approach is the first to attempt to debunk half-truths, and outperforms other Language Models such as GPT2, RoBERTa, PEGASUS, and Tailor, with average improvements of 82%, 57%, 42%, and 23% in disinfo-debunk scores, respectively."
    },
    "citationCount": 0,
    "influentialCitationCount": 0,
    "code": null,
    "description": null,
    "url": null
}