{
    "paperId": "1b71ead33dd0c4bf677622fb01fb774e23c6da87",
    "externalIds": {
        "ArXiv": "2407.15819",
        "DBLP": "journals/corr/abs-2407-15819",
        "DOI": "10.48550/arXiv.2407.15819",
        "CorpusId": 271329049
    },
    "title": "Accelerating Pre-training of Multimodal LLMs via Chain-of-Sight",
    "abstract": "This paper introduces Chain-of-Sight, a vision-language bridge module that accelerates the pre-training of Multimodal Large Language Models (MLLMs). Our approach employs a sequence of visual resamplers that capture visual details at various spacial scales. This architecture not only leverages global and local visual contexts effectively, but also facilitates the flexible extension of visual tokens through a compound token scaling strategy, allowing up to a 16x increase in the token count post pre-training. Consequently, Chain-of-Sight requires significantly fewer visual tokens in the pre-training phase compared to the fine-tuning phase. This intentional reduction of visual tokens during pre-training notably accelerates the pre-training process, cutting down the wall-clock training time by ~73%. Empirical results on a series of vision-language benchmarks reveal that the pre-train acceleration through Chain-of-Sight is achieved without sacrificing performance, matching or surpassing the standard pipeline of utilizing all visual tokens throughout the entire training process. Further scaling up the number of visual tokens for pre-training leads to stronger performances, competitive to existing approaches in a series of benchmarks.",
    "venue": "arXiv.org",
    "year": 2024,
    "referenceCount": 106,
    "citationCount": 0,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "Chain-of-Sight, a vision-language bridge module that accelerates the pre-training of Multimodal Large Language Models (MLLMs), employs a sequence of visual resamplers that capture visual details at various spacial scales, allowing up to a 16x increase in the token count post pre-training."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -5.157470226287842,
            -2.077031373977661,
            -1.0417296886444092,
            6.093550205230713,
            1.961591124534607,
            3.606722354888916,
            6.337878704071045,
            3.02205228805542,
            -2.8671300411224365,
            -2.339606761932373,
            -1.8020230531692505,
            3.4407286643981934,
            0.5678523182868958,
            1.0096220970153809,
            -2.979362726211548,
            -4.593947410583496,
            0.38068902492523193,
            -3.554415702819824,
            3.5987958908081055,
            -0.9368417263031006,
            -1.7477619647979736,
            -0.24494236707687378,
            -2.431230306625366,
            -0.7876251935958862,
            -2.9168457984924316,
            1.0852735042572021,
            5.774694442749023,
            1.8752529621124268,
            -1.500030755996704,
            -0.48914486169815063,
            0.40480077266693115,
            -4.017947196960449,
            4.040199279785156,
            -0.15309393405914307,
            2.855485439300537,
            -2.7910213470458984,
            -2.7812538146972656,
            5.644715785980225,
            -6.068917751312256,
            -1.2460997104644775,
            0.29966413974761963,
            1.3702411651611328,
            -0.7748968601226807,
            -0.4261660575866699,
            1.9502835273742676,
            0.7310092449188232,
            -0.6443686485290527,
            -1.2068724632263184,
            0.6806790232658386,
            1.9969565868377686,
            2.5337700843811035,
            2.19936466217041,
            -0.18125760555267334,
            -0.2783666253089905,
            -1.1606602668762207,
            -1.7637219429016113,
            0.488833487033844,
            3.916712760925293,
            -0.2899048626422882,
            -1.7719502449035645,
            4.719915390014648,
            6.683512210845947,
            2.0823659896850586,
            0.4251646399497986,
            3.1019928455352783,
            -5.526649475097656,
            -1.3804208040237427,
            2.5196454524993896,
            -0.23101747035980225,
            3.470026731491089,
            -3.6805624961853027,
            -6.921320915222168,
            -0.5163713097572327,
            0.9213255643844604,
            -1.7903802394866943,
            -1.6924104690551758,
            -2.913573980331421,
            -3.3978404998779297,
            -0.3660616874694824,
            -0.8681144714355469,
            0.8591265678405762,
            2.7817342281341553,
            3.5397114753723145,
            2.2124710083007812,
            2.890538454055786,
            -2.018324851989746,
            -5.039697170257568,
            0.10814252495765686,
            1.4208455085754395,
            -2.4267382621765137,
            0.7961613535881042,
            -1.130418300628662,
            -0.7891499996185303,
            0.206734299659729,
            -1.9156837463378906,
            1.014076590538025,
            -1.846207857131958,
            -2.8354482650756836,
            -0.6289205551147461,
            0.16884350776672363,
            0.6554692983627319,
            -0.5336306095123291,
            1.020721197128296,
            -2.231468439102173,
            6.354142189025879,
            -4.782770156860352,
            -1.904177188873291,
            0.07641881704330444,
            3.6469650268554688,
            -2.176992893218994,
            -2.504530429840088,
            3.6570348739624023,
            0.42783355712890625,
            -2.5623433589935303,
            -2.835545539855957,
            -0.14416106045246124,
            -0.1745360791683197,
            0.27330172061920166,
            -2.4572319984436035,
            1.4514744281768799,
            2.560842990875244,
            -0.2109399437904358,
            -1.5999865531921387,
            3.769630193710327,
            1.2653961181640625,
            0.3385579586029053,
            -3.5631308555603027,
            1.0302590131759644,
            0.49802565574645996,
            -4.608262538909912,
            1.608564853668213,
            -4.520997047424316,
            2.2308850288391113,
            -3.4027318954467773,
            1.8946853876113892,
            2.3212039470672607,
            -3.4111552238464355,
            -1.537592887878418,
            -1.8668172359466553,
            2.522425651550293,
            1.2321486473083496,
            4.04768705368042,
            1.994931936264038,
            0.08951422572135925,
            0.10732194781303406,
            1.2334084510803223,
            2.5143203735351562,
            0.9277048110961914,
            2.028266668319702,
            6.040269374847412,
            5.1476826667785645,
            -3.982846260070801,
            -0.20733880996704102,
            0.5010585784912109,
            1.2816758155822754,
            4.127581596374512,
            -6.234986305236816,
            -0.0635773241519928,
            -1.1673741340637207,
            0.5826170444488525,
            1.6066431999206543,
            -0.10716226696968079,
            -9.537166595458984,
            -0.985095202922821,
            4.4601149559021,
            -5.216707229614258,
            -0.6249186992645264,
            2.549561023712158,
            0.2568207085132599,
            -0.7047003507614136,
            -0.5446372032165527,
            1.0277596712112427,
            0.3947352170944214,
            3.8006224632263184,
            5.866701126098633,
            1.4354140758514404,
            -2.8726651668548584,
            0.712895393371582,
            -3.7796573638916016,
            0.4320333003997803,
            0.8845688104629517,
            -2.2462806701660156,
            -4.507549285888672,
            4.339767932891846,
            -8.33517074584961,
            -3.0279459953308105,
            -4.504898548126221,
            -3.0920028686523438,
            -2.201831817626953,
            -0.4107136130332947,
            0.49062207341194153,
            2.7150139808654785,
            4.5365309715271,
            4.098624229431152,
            0.2322542518377304,
            2.814199209213257,
            1.8833560943603516,
            2.6263813972473145,
            -2.47188663482666,
            3.0078606605529785,
            3.2016851902008057,
            -1.867889642715454,
            -0.2878197133541107,
            -5.941593170166016,
            0.5666581392288208,
            0.28056320548057556,
            -4.107219696044922,
            2.1720807552337646,
            0.32602351903915405,
            1.0863783359527588,
            -0.9037559032440186,
            -1.336477279663086,
            -2.9584062099456787,
            2.4846248626708984,
            -3.8938369750976562,
            -0.599514365196228,
            -4.180184364318848,
            2.681689977645874,
            4.571319103240967,
            -0.5672242045402527,
            2.6857566833496094,
            4.580480575561523,
            0.6238188147544861,
            -3.572706699371338,
            2.2383248805999756,
            -2.3061788082122803,
            3.007936477661133,
            0.8921418786048889,
            1.8508585691452026,
            0.8341640830039978,
            -3.442676067352295,
            -5.509418487548828,
            -0.23337823152542114,
            -4.397497177124023,
            -5.333409786224365,
            -1.3345980644226074,
            -3.315793991088867,
            -0.9135491251945496,
            -0.6880563497543335,
            -1.5542398691177368,
            6.12658166885376,
            1.8992053270339966,
            0.05934363603591919,
            4.331892490386963,
            2.271209716796875,
            -2.146416187286377,
            -2.1558620929718018,
            -0.3442331552505493,
            1.4917255640029907,
            -0.7976208329200745,
            1.154213309288025,
            -1.7120585441589355,
            2.685490131378174,
            -3.017629861831665,
            0.5440733432769775,
            -1.1599922180175781,
            2.3255271911621094,
            1.038702130317688,
            -0.6643816828727722,
            -2.3437511920928955,
            0.6135779619216919,
            0.9724582433700562,
            3.0566506385803223,
            4.2169389724731445,
            -2.0256690979003906,
            -1.4303027391433716,
            -1.1382126808166504,
            -2.9285688400268555,
            -2.4383962154388428,
            5.49118709564209,
            2.614995241165161,
            3.4880411624908447,
            0.6585396528244019,
            -1.3093023300170898,
            -1.2571104764938354,
            -5.533952713012695,
            -2.525066375732422,
            0.08244404196739197,
            1.7575206756591797,
            3.7867045402526855,
            4.005208969116211,
            -4.209427833557129,
            -1.8057987689971924,
            -2.7783946990966797,
            0.3206613063812256,
            -2.5716958045959473,
            -0.27362000942230225,
            -2.587630271911621,
            1.580352783203125,
            0.41419532895088196,
            -1.5000646114349365,
            3.1250386238098145,
            -0.9423478841781616,
            -0.850501537322998,
            -1.3857557773590088,
            2.4303035736083984,
            7.479864120483398,
            -1.8476848602294922,
            1.6432723999023438,
            1.8819093704223633,
            1.2705644369125366,
            -0.08925247192382812,
            0.7172420024871826,
            -1.057024359703064,
            0.22160598635673523,
            1.863486647605896,
            0.7262424230575562,
            -3.878941535949707,
            -0.0546567440032959,
            -6.236810684204102,
            -3.935849905014038,
            2.4265148639678955,
            1.021079659461975,
            -6.673590660095215,
            -1.8257849216461182,
            1.6431028842926025,
            2.5284085273742676,
            -2.031803846359253,
            -1.4544106721878052,
            -0.48084428906440735,
            1.0624972581863403,
            2.383814811706543,
            -4.77742862701416,
            -3.5197458267211914,
            -3.8919453620910645,
            -0.5067464113235474,
            1.9028313159942627,
            -0.7439078688621521,
            -1.6361315250396729,
            2.5316991806030273,
            2.514497756958008,
            1.5709025859832764,
            2.7801012992858887,
            0.7328502535820007,
            -0.37609219551086426,
            -3.585350751876831,
            0.8727898597717285,
            -1.8770203590393066,
            -0.9720650911331177,
            -2.516317367553711,
            1.0206928253173828,
            5.657544136047363,
            -3.1252102851867676,
            1.424159288406372,
            1.3806321620941162,
            2.261226177215576,
            1.5550495386123657,
            2.9583888053894043,
            1.3158763647079468,
            -3.387937307357788,
            0.8999270796775818,
            3.249941110610962,
            2.116013526916504,
            -0.31246691942214966,
            0.3594791889190674,
            5.620795249938965,
            2.080840826034546,
            -2.061805486679077,
            1.8186510801315308,
            2.1619858741760254,
            0.20991189777851105,
            2.6556661128997803,
            3.5070486068725586,
            -0.4903806447982788,
            -3.3690185546875,
            -1.517094373703003,
            12.391672134399414,
            -1.256032109260559,
            1.9466989040374756,
            -3.679272174835205,
            -4.913747787475586,
            -1.7997488975524902,
            -0.8710070848464966,
            4.152186393737793,
            -1.3537225723266602,
            -0.3261968493461609,
            1.0281410217285156,
            -1.3513283729553223,
            -2.8618340492248535,
            3.6489744186401367,
            -2.4912328720092773,
            8.553610801696777,
            0.11462512612342834,
            4.061989784240723,
            2.235069751739502,
            0.5421821475028992,
            -3.114147186279297,
            3.1759748458862305,
            6.084240913391113,
            -0.13767105340957642,
            -0.22067731618881226,
            2.1501142978668213,
            0.7860142588615417,
            0.9461578130722046,
            -2.1572372913360596,
            -5.896329402923584,
            -2.5093307495117188,
            -4.912692070007324,
            1.774125576019287,
            -2.1102163791656494,
            -3.5176451206207275,
            4.12113094329834,
            1.9781124591827393,
            4.080818176269531,
            -2.1520071029663086,
            -0.002918422222137451,
            2.402867317199707,
            -0.6078550815582275,
            -2.8469419479370117,
            -0.6415822505950928,
            -5.485499382019043,
            0.5246404409408569,
            -1.2446393966674805,
            -3.3794634342193604,
            -2.603628158569336,
            -3.6118016242980957,
            2.5391323566436768,
            2.3458311557769775,
            5.637748718261719,
            2.4974875450134277,
            -2.884385585784912,
            2.176215648651123,
            2.727341890335083,
            0.4215889573097229,
            1.8293430805206299,
            0.37753725051879883,
            2.0227952003479004,
            -0.2140531837940216,
            -2.2625749111175537,
            1.5699150562286377,
            -3.1515870094299316,
            1.3483439683914185,
            -1.7056087255477905,
            0.801253080368042,
            -1.200921893119812,
            2.5082812309265137,
            0.8815550208091736,
            1.8430131673812866,
            0.15012764930725098,
            -3.74406099319458,
            -0.7775853276252747,
            7.190701484680176,
            -2.5196709632873535,
            4.628646373748779,
            3.508042335510254,
            4.09233283996582,
            -0.8394177556037903,
            1.8308978080749512,
            -0.40417855978012085,
            -3.3520736694335938,
            5.030291557312012,
            -4.612975120544434,
            -1.9185876846313477,
            -0.09181743860244751,
            2.626425266265869,
            1.591064214706421,
            0.7504030466079712,
            0.3382379412651062,
            2.31082820892334,
            -1.8436903953552246,
            -4.112556457519531,
            4.636957168579102,
            1.2398533821105957,
            1.4722607135772705,
            -1.3916608095169067,
            2.91959285736084,
            -0.8726437091827393,
            -0.2673789858818054,
            -2.146390438079834,
            2.4836978912353516,
            5.2733869552612305,
            0.15318182110786438,
            -2.5657150745391846,
            2.010377883911133,
            -0.5614606142044067,
            2.59903883934021,
            1.6584014892578125,
            -0.19714190065860748,
            0.15066981315612793,
            -6.605920791625977,
            -0.49666738510131836,
            -2.6384119987487793,
            5.664698600769043,
            -5.618151664733887,
            1.337501049041748,
            4.142123699188232,
            8.274598121643066,
            2.2602951526641846,
            0.8885464668273926,
            1.9255883693695068,
            4.276402473449707,
            0.7329550385475159,
            7.1520843505859375,
            -5.0388593673706055,
            -0.17686142027378082,
            -1.826396107673645,
            -5.297428607940674,
            -0.34434831142425537,
            0.01419249176979065,
            -1.014078140258789,
            0.5675532817840576,
            -4.631999969482422,
            -3.3981566429138184,
            -1.296753168106079,
            -3.015338897705078,
            3.7012929916381836,
            4.6690673828125,
            0.2566400170326233,
            -0.07519739866256714,
            1.3475035429000854,
            -1.1174275875091553,
            2.653437614440918,
            -6.374159812927246,
            1.2713119983673096,
            -1.1154937744140625,
            5.66058349609375,
            4.20024299621582,
            1.121575951576233,
            2.046647071838379,
            -0.4135422706604004,
            -0.8154098391532898,
            -0.5999572277069092,
            -0.7925686836242676,
            1.3129245042800903,
            4.342750549316406,
            3.2137343883514404,
            -4.100320816040039,
            0.19718897342681885,
            4.502873420715332,
            2.8269309997558594,
            4.615985870361328,
            3.252622365951538,
            2.189971923828125,
            -3.514601707458496,
            2.2034189701080322,
            -3.9862265586853027,
            1.6635026931762695,
            3.214902877807617,
            -2.173964262008667,
            1.1065077781677246,
            -0.5729192495346069,
            -2.213308334350586,
            2.456496238708496,
            4.474850177764893,
            -0.16169807314872742,
            3.7049851417541504,
            -2.225752353668213,
            -2.71700382232666,
            -0.9933061003684998,
            0.8328195810317993,
            2.8622634410858154,
            -2.0637950897216797,
            1.1893610954284668,
            -3.1666064262390137,
            -0.9863544702529907,
            -1.0712220668792725,
            -2.9569902420043945,
            -3.1331472396850586,
            -0.33124053478240967,
            5.9611124992370605,
            3.638263702392578,
            -5.122492790222168,
            0.8334213495254517,
            2.714460849761963,
            -2.6760358810424805,
            -3.7935218811035156,
            0.9097169637680054,
            3.5687482357025146,
            -0.8951177597045898,
            -1.0895042419433594,
            -1.0678961277008057,
            -4.979115009307861,
            -2.1843013763427734,
            3.712414503097534,
            0.3338538408279419,
            2.41802978515625,
            2.4649291038513184,
            1.7861371040344238,
            -3.948199987411499,
            1.1943483352661133,
            -0.5487154722213745,
            -3.67103910446167,
            -1.731021761894226,
            -3.2118911743164062,
            -0.181973397731781,
            -4.650800704956055,
            -3.6754939556121826,
            5.74282169342041,
            -3.238637685775757,
            1.670719027519226,
            4.842036247253418,
            -1.1920387744903564,
            -1.12834894657135,
            -6.408511638641357,
            0.4954410791397095,
            -3.0867207050323486,
            5.021841049194336,
            2.1340394020080566,
            -0.5950210094451904,
            1.5356297492980957,
            0.4943680763244629,
            7.535783767700195,
            3.2266077995300293,
            4.347662925720215,
            -4.250883102416992,
            1.4453822374343872,
            1.601553201675415,
            0.21320953965187073,
            -2.6359143257141113,
            -0.7978498935699463,
            -1.454952597618103,
            2.3403284549713135,
            16.851478576660156,
            -1.3666837215423584,
            -2.3087105751037598,
            -0.18194641172885895,
            -1.0993061065673828,
            -1.3291590213775635,
            0.025622695684432983,
            2.765017032623291,
            -0.7344872355461121,
            2.5878355503082275,
            -0.19391047954559326,
            -3.894911766052246,
            -0.08875592797994614,
            1.6530123949050903,
            -6.664379119873047,
            -1.1062089204788208,
            -3.1643853187561035,
            1.8373970985412598,
            -2.5454649925231934,
            0.6432929039001465,
            0.9631661176681519,
            -0.6142139434814453,
            -1.7778112888336182,
            -1.2549524307250977,
            -0.8710991740226746,
            2.428297996520996,
            -0.7916550636291504,
            2.912740707397461,
            -4.170914173126221,
            0.6851458549499512,
            0.8200669288635254,
            2.8533172607421875,
            5.142094612121582,
            -0.1974298357963562,
            -1.3453503847122192,
            1.869072675704956,
            2.144024610519409,
            -0.22867733240127563,
            3.922823429107666,
            3.5552191734313965,
            -1.3802964687347412,
            1.6602777242660522,
            -2.5632827281951904,
            -0.9170642495155334,
            -3.754488945007324,
            3.1823008060455322,
            6.39790153503418,
            -4.386585235595703,
            -0.8587575554847717,
            4.768651962280273,
            -1.3362566232681274,
            -0.7526313066482544,
            -1.8153233528137207,
            0.5769152641296387,
            -0.6539021134376526,
            2.605295181274414,
            4.779745101928711,
            -6.171281814575195,
            4.097643852233887,
            -1.9149260520935059,
            0.8525684475898743,
            -0.8541282415390015,
            -1.975860595703125,
            -2.4800260066986084,
            -2.9583377838134766,
            3.4117703437805176,
            -4.306982517242432,
            0.7779008150100708,
            3.141171932220459,
            1.1905354261398315,
            3.305004835128784,
            -0.16568933427333832,
            5.860822677612305,
            -2.9000754356384277,
            -1.7506375312805176,
            -4.918784141540527,
            1.2148184776306152,
            -0.834896981716156,
            -1.0413566827774048,
            9.10118293762207,
            0.04071655869483948,
            3.7821202278137207,
            -1.7950866222381592,
            -0.37261664867401123,
            3.3247568607330322,
            -1.797379732131958,
            2.474416971206665,
            1.150066614151001,
            -1.545888900756836,
            -0.23260101675987244,
            0.16041433811187744,
            -1.0208165645599365,
            2.056567430496216,
            1.4876402616500854,
            3.444998025894165,
            -4.08619499206543,
            -2.107851982116699,
            -3.9205198287963867,
            -4.423012733459473,
            -2.7067766189575195,
            5.429233551025391,
            6.327591896057129,
            1.097325086593628,
            -3.085054874420166,
            0.7107802629470825,
            -3.4430418014526367,
            -2.8466649055480957,
            -4.312375068664551,
            1.3888758420944214,
            -4.130875110626221,
            3.6708929538726807,
            -6.781010627746582,
            -3.298314094543457,
            -1.679870367050171,
            0.5590265989303589,
            0.7697678804397583,
            -0.4347531199455261,
            2.8895015716552734,
            0.4208471477031708,
            1.3032337427139282,
            1.65886390209198,
            -1.1305112838745117,
            -2.8504061698913574,
            -1.1567168235778809,
            -1.7070904970169067,
            1.5894124507904053,
            0.29921022057533264,
            -0.5529862642288208,
            -0.13242235779762268,
            -2.099250316619873,
            -2.054119110107422,
            -2.3708856105804443,
            -3.5018134117126465,
            0.5705921649932861,
            -0.3919982314109802,
            -2.0750913619995117,
            -1.3626550436019897,
            -1.360547423362732,
            -3.794384002685547,
            -0.6383217573165894,
            1.820293664932251,
            -3.4648165702819824,
            0.28217774629592896,
            12.071414947509766,
            -0.7287286520004272,
            -1.071372151374817,
            -5.954036235809326,
            -4.37926721572876,
            -0.06464195251464844,
            1.4032907485961914,
            0.6883857250213623,
            -0.2321786880493164,
            4.76690673828125,
            1.3259185552597046,
            -1.2274458408355713,
            -3.0362300872802734
        ]
    },
    "authors": [
        {
            "authorId": "2275102564",
            "name": "Ziyuan Huang"
        },
        {
            "authorId": "2118930016",
            "name": "Kaixiang Ji"
        },
        {
            "authorId": "2268398906",
            "name": "Biao Gong"
        },
        {
            "authorId": "1750375688",
            "name": "Zhiwu Qing"
        },
        {
            "authorId": "2312344039",
            "name": "Qinglong Zhang"
        },
        {
            "authorId": "2312326968",
            "name": "Kecheng Zheng"
        },
        {
            "authorId": "2261367300",
            "name": "Jian Wang"
        },
        {
            "authorId": "2260719267",
            "name": "Jingdong Chen"
        },
        {
            "authorId": "2261787428",
            "name": "Ming Yang"
        }
    ],
    "references": [
        {
            "paperId": "887306ee7ebd9eebd7faea24106ec8e8f1a50987",
            "title": "How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites"
        },
        {
            "paperId": "01ae1c181dcb5117491affae728065e5e62bf074",
            "title": "InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD"
        },
        {
            "paperId": "b38845e9adbeeeab37519a2fc30e899411b4a36a",
            "title": "Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models"
        },
        {
            "paperId": "6675bcf6dc97c87da7afda223938ec7e51ecc3b2",
            "title": "MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training"
        },
        {
            "paperId": "10531a7bcbc807f66964ded03a70809c7e98f0a5",
            "title": "Griffon v2: Advancing Multimodal Perception with High-Resolution Scaling and Visual-Language Co-Referring"
        },
        {
            "paperId": "b14e5138d4d1f3577b2390541dc7b730a41bb651",
            "title": "DeepSeek-VL: Towards Real-World Vision-Language Understanding"
        },
        {
            "paperId": "b9c2beb83024832724f06a777dee888b6b0e1e10",
            "title": "RoboCodeX: Multimodal Code Generation for Robotic Behavior Synthesis"
        },
        {
            "paperId": "ec8e2b45c4601730015608a58e33409224a81228",
            "title": "SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models"
        },
        {
            "paperId": "cd1d7f5c4ce2d31ce9ee72db165a8272624da7d3",
            "title": "MoE-LLaVA: Mixture of Experts for Large Vision-Language Models"
        },
        {
            "paperId": "7260442ef9c0448f07ce3803efd49cebaffcebe9",
            "title": "DeepSeek LLM: Scaling Open-Source Language Models with Longtermism"
        },
        {
            "paperId": "6c64ddd2190909de2c680dd18abc9b92e80c39f9",
            "title": "Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision, Language, Audio, and Action"
        },
        {
            "paperId": "6a33e58ef961a3a0a5657518b2be86395eb7c8d0",
            "title": "InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks"
        },
        {
            "paperId": "4b1b5e219fb41a7413599c3b2ca6a7fdf045d1a5",
            "title": "Generative Multimodal Models are In-Context Learners"
        },
        {
            "paperId": "2141ed804636a1cf339d606cd03fd3b3e9582133",
            "title": "VILA: On Pre-training for Visual Language Models"
        },
        {
            "paperId": "4f5654ec1dfc04478be42d03eee8e6db6bd9ca14",
            "title": "Honeybee: Locality-enhanced Projector for Multimodal LLM"
        },
        {
            "paperId": "b50d19c5c298f6562c3b3c6c3822a351bdc89260",
            "title": "MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI"
        },
        {
            "paperId": "76a3f4a79ae9a00db2f2b5f6877021d8deb96ada",
            "title": "SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for Multi-modal Large Language Models"
        },
        {
            "paperId": "bf14244669d5505f63343d4365d99d24aa6c5e82",
            "title": "Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models"
        },
        {
            "paperId": "ad13b213681b6f634bc83a264df246e83dd9a9d9",
            "title": "mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration"
        },
        {
            "paperId": "2313afae52d98e569da2dedbf14daf9efc74e7cf",
            "title": "CogVLM: Visual Expert for Pretrained Language Models"
        },
        {
            "paperId": "f72be31de9f9a09d4410fd38bc717efe43444827",
            "title": "SALMONN: Towards Generic Hearing Abilities for Large Language Models"
        },
        {
            "paperId": "1ddbd08ad8cf22a5c66c4242194c4286328533bf",
            "title": "MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning"
        },
        {
            "paperId": "68e0e789b5147b1e7d028c7a825650075f4e26bf",
            "title": "PaLI-3 Vision Language Models: Smaller, Faster, Stronger"
        },
        {
            "paperId": "458111ac5a0f73bb35a2acf55298268be25ccfa2",
            "title": "Ferret: Refer and Ground Anything Anywhere at Any Granularity"
        },
        {
            "paperId": "124d4d374fbef2016fa9880489871a58a7450644",
            "title": "Improved Baselines with Visual Instruction Tuning"
        },
        {
            "paperId": "5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0",
            "title": "Qwen Technical Report"
        },
        {
            "paperId": "4309d572a37d655779f9dce6a2c98c66334132de",
            "title": "SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension"
        },
        {
            "paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a",
            "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"
        },
        {
            "paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0",
            "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"
        },
        {
            "paperId": "b37b1dc72b1882858f5120f2cd6883134089a6ed",
            "title": "MMBench: Is Your Multi-modal Model an All-around Player?"
        },
        {
            "paperId": "e2a58fd18961c3941102989e3a3d0d27c615e015",
            "title": "Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic"
        },
        {
            "paperId": "697e0add95e880bd42e00bef838181e105f91981",
            "title": "MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models"
        },
        {
            "paperId": "948e8cfae92c2004f2dd5c9316f5972f8baaea21",
            "title": "OBELISC: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents"
        },
        {
            "paperId": "0983883619a0ca597d055d0e58da2f514052913d",
            "title": "Macaw-LLM: Multi-Modal Language Modeling with Image, Audio, Video, and Text Integration"
        },
        {
            "paperId": "3099d6f4965b4d73aa1e2b2880522ec89ed2dc0a",
            "title": "PaLI-X: On Scaling up a Multilingual Vision and Language Model"
        },
        {
            "paperId": "00cb69a9f280317d1c59ac5827551ee9b10642b8",
            "title": "EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought"
        },
        {
            "paperId": "6a5525c316b9be7909c433a79e090ed731425083",
            "title": "What Makes for Good Visual Tokenizers for Large Language Models?"
        },
        {
            "paperId": "206400aba5f12f734cdd2e4ab48ef6014ea60773",
            "title": "Evaluating Object Hallucination in Large Vision-Language Models"
        },
        {
            "paperId": "8bd6a2a89503be083176f2cc26fabedb79238cbd",
            "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"
        },
        {
            "paperId": "ca6a2bc279be5a3349a22bfd6866ed633d18734b",
            "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"
        },
        {
            "paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8",
            "title": "Visual Instruction Tuning"
        },
        {
            "paperId": "57e849d0de13ed5f91d086936296721d4ff75a75",
            "title": "LLaMA: Open and Efficient Foundation Language Models"
        },
        {
            "paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb",
            "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"
        },
        {
            "paperId": "cfca7eedc6ede9d363d1662280a74d78dcdc9d4a",
            "title": "Scaling Language-Image Pre-Training via Masking"
        },
        {
            "paperId": "d3135733aa39dec20ce72aa138589dda27c8406d",
            "title": "Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering"
        },
        {
            "paperId": "28630034bb29760df01ab033b743e30b37f336ae",
            "title": "PaLI: A Jointly-Scaled Multilingual Language-Image Model"
        },
        {
            "paperId": "5cb75eed179b9cebad2bbb268dec1a711f2c62e1",
            "title": "MAR: Masked Autoencoders for Efficient Action Recognition"
        },
        {
            "paperId": "47a67e76ed84260ff19f7a948d764005d1edf1c9",
            "title": "A-OKVQA: A Benchmark for Visual Question Answering using World Knowledge"
        },
        {
            "paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336",
            "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"
        },
        {
            "paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221",
            "title": "OPT: Open Pre-trained Transformer Language Models"
        },
        {
            "paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3",
            "title": "Flamingo: a Visual Language Model for Few-Shot Learning"
        },
        {
            "paperId": "02b1356d3782be6cc790fc89b1d644b426cd8493",
            "title": "ResT V2: Simpler, Faster and Stronger"
        },
        {
            "paperId": "a09cbcaac305884f043810afc4fa4053099b5970",
            "title": "Exploring Plain Vision Transformer Backbones for Object Detection"
        },
        {
            "paperId": "1bfa62ddfa3f6691e0e40c06f8ead594b6449cfa",
            "title": "OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"
        },
        {
            "paperId": "01b5412f3d17e90e09226d7c40ad4d4468a1414d",
            "title": "Multimodal Few-Shot Learning with Frozen Language Models"
        },
        {
            "paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092",
            "title": "LoRA: Low-Rank Adaptation of Large Language Models"
        },
        {
            "paperId": "adb4302eb7c420a46d770afe2448d4508c65fe58",
            "title": "ResT: An Efficient Transformer for Visual Recognition"
        },
        {
            "paperId": "7ba9c013988eaff5cd186d73704af329d027872d",
            "title": "MDETR - Modulated Detection for End-to-End Multi-Modal Understanding"
        },
        {
            "paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6",
            "title": "Multiscale Vision Transformers"
        },
        {
            "paperId": "b3bf9fe13195e9aa70e1dac04e01fcff7008e812",
            "title": "Perceiver: General Perception with Iterative Attention"
        },
        {
            "paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4",
            "title": "Learning Transferable Visual Models From Natural Language Supervision"
        },
        {
            "paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881",
            "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"
        },
        {
            "paperId": "fdacf2a732f55befdc410ea927091cad3b791f13",
            "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"
        },
        {
            "paperId": "725264948d7b6946259af5b8d966e996b9570f99",
            "title": "DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "33eadd4e666a894306a22ba0839c5e0cef77280e",
            "title": "TextCaps: a Dataset for Image Captioning with Reading Comprehension"
        },
        {
            "paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
        },
        {
            "paperId": "00c957711b12468cb38424caccdf5291bb354033",
            "title": "ZeRO: Memory optimizations Toward Training Trillion Parameter Models"
        },
        {
            "paperId": "dfc7b58b67c31932b48586b3e23a43cc94695290",
            "title": "UNITER: UNiversal Image-TExt Representation Learning"
        },
        {
            "paperId": "1097cf8cf5961589ff693b069002e7181e24e631",
            "title": "OCR-VQA: Visual Question Answering by Reading Text in Images"
        },
        {
            "paperId": "28ad018c39d1578bea84e7cedf94459e3dbe1e70",
            "title": "OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge"
        },
        {
            "paperId": "af1f7739283bdbd2b7a94903041f6d6afd991907",
            "title": "Towards VQA Models That Can Read"
        },
        {
            "paperId": "a7ac99d7cf3f568ab1a741392144b646b856ae0c",
            "title": "GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering"
        },
        {
            "paperId": "fab133bb7c0e7208ee68a90fe03f2da4d1dee245",
            "title": "Scale-Aware Trident Networks for Object Detection"
        },
        {
            "paperId": "b4df354db88a70183a64dbc9e56cf14e7669a6c0",
            "title": "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"
        },
        {
            "paperId": "fdce9cbe5c726201575b3c8a8c1af0752f1af53f",
            "title": "MAttNet: Modular Attention Network for Referring Expression Comprehension"
        },
        {
            "paperId": "d07284a6811f1b2745d91bdb06b040b57f226882",
            "title": "Decoupled Weight Decay Regularization"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "b61a3f8b80bbd44f24544dc915f52fd30bbdf485",
            "title": "Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset"
        },
        {
            "paperId": "4a73a1840945e87583d89ca0216a2c449d50a4a3",
            "title": "Deformable Convolutional Networks"
        },
        {
            "paperId": "2a94c84383ee3de5e6211d43d16e7de387f68878",
            "title": "Feature Pyramid Networks for Object Detection"
        },
        {
            "paperId": "7e232313a59d735ef7c8a9f4cc7bc980a29deb5e",
            "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"
        },
        {
            "paperId": "29efbe391950ae438c63d86ad5c82b2942efb0b4",
            "title": "Modeling Context in Referring Expressions"
        },
        {
            "paperId": "cab372bc3824780cce20d9dd1c22d4df39ed081a",
            "title": "DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs"
        },
        {
            "paperId": "afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d",
            "title": "Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations"
        },
        {
            "paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "title": "Deep Residual Learning for Image Recognition"
        },
        {
            "paperId": "7f5fc84819c0cf94b771fe15141f65b123f7b8ec",
            "title": "Multi-Scale Context Aggregation by Dilated Convolutions"
        },
        {
            "paperId": "e65142010431ffc089b272a1174214e00693e503",
            "title": "Generation and Comprehension of Unambiguous Object Descriptions"
        },
        {
            "paperId": "f8e79ac0ea341056ef20f2616628b3e964764cfd",
            "title": "You Only Look Once: Unified, Real-Time Object Detection"
        },
        {
            "paperId": "11c9c31dff70de92ada9160c78ff8bb46b2912d6",
            "title": "Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models"
        },
        {
            "paperId": "6fc6803df5f9ae505cae5b2f178ade4062c768d0",
            "title": "Fully convolutional networks for semantic segmentation"
        },
        {
            "paperId": "92c141447f51b6732242376164ff961e464731c8",
            "title": "ReferItGame: Referring to Objects in Photographs of Natural Scenes"
        },
        {
            "paperId": "71b7178df5d2b112d07e45038cb5637208659ff7",
            "title": "Microsoft COCO: Common Objects in Context"
        },
        {
            "paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "title": "ImageNet classification with deep convolutional neural networks"
        },
        {
            "paperId": "8e080b98efbe65c02a116439205ca2344b9f7cd4",
            "title": "Im2Text: Describing Images Using 1 Million Captioned Photographs"
        },
        {
            "paperId": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27",
            "title": "Backpropagation Applied to Handwritten Zip Code Recognition"
        },
        {
            "paperId": "69e68bfaadf2dccff800158749f5a50fe82d173b",
            "title": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position"
        },
        {
            "paperId": "5ddb51ae85deca14dc7fc8adc07305c22a1ebe0a",
            "title": "Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities"
        },
        {
            "paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7",
            "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"
        },
        {
            "paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": "8b55402ffee2734bfc7d5d7595500916e1ef04e8",
            "title": "nocaps: novel object captioning at scale"
        },
        {
            "paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "title": "Improving Language Understanding by Generative Pre-Training"
        },
        {
            "paperId": null,
            "title": "OpenAI"
        },
        {
            "paperId": null,
            "title": "Vicuna: An open-source chat-bot impressing gpt-4 with 90%* chatgpt quality"
        },
        {
            "paperId": null,
            "title": "Introducing meta llama 3: The most capable openly available llm to date"
        },
        {
            "paperId": null,
            "title": "Gemini: a family of highly capable multimodal models"
        }
    ]
}