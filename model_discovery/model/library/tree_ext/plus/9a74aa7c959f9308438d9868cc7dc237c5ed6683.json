{
    "paperId": "9a74aa7c959f9308438d9868cc7dc237c5ed6683",
    "externalIds": {
        "DBLP": "journals/corr/abs-2407-20171",
        "ArXiv": "2407.20171",
        "DOI": "10.48550/arXiv.2407.20171",
        "CorpusId": 271533948
    },
    "title": "Diffusion Feedback Helps CLIP See Better",
    "abstract": "Contrastive Language-Image Pre-training (CLIP), which excels at abstracting open-world representations across domains and modalities, has become a foundation for a variety of vision and multimodal tasks. However, recent studies reveal that CLIP has severe visual shortcomings, such as which can hardly distinguish orientation, quantity, color, structure, etc. These visual shortcomings also limit the perception capabilities of multimodal large language models (MLLMs) built on CLIP. The main reason could be that the image-text pairs used to train CLIP are inherently biased, due to the lack of the distinctiveness of the text and the diversity of images. In this work, we present a simple post-training approach for CLIP models, which largely overcomes its visual shortcomings via a self-supervised diffusion process. We introduce DIVA, which uses the DIffusion model as a Visual Assistant for CLIP. Specifically, DIVA leverages generative feedback from text-to-image diffusion models to optimize CLIP representations, with only images (without corresponding text). We demonstrate that DIVA improves CLIP's performance on the challenging MMVP-VLM benchmark which assesses fine-grained visual abilities to a large extent (e.g., 3-7%), and enhances the performance of MLLMs and vision models on multimodal understanding and segmentation tasks. Extensive evaluation on 29 image classification and retrieval benchmarks confirms that our framework preserves CLIP's strong zero-shot capabilities. The code is available at https://github.com/baaivision/DIVA.",
    "venue": "arXiv.org",
    "year": 2024,
    "referenceCount": 106,
    "citationCount": 1,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "DIVA is introduced, which uses the DIffusion model as a Visual Assistant for CLIP, and leverages generative feedback from text-to-image diffusion models to optimize CLIP representations, with only images (without corresponding text)."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -4.410888671875,
            -4.04538631439209,
            -1.9845168590545654,
            4.717945575714111,
            -1.9005606174468994,
            0.16333627700805664,
            3.413548707962036,
            0.3473547101020813,
            -2.271547555923462,
            -1.7301944494247437,
            -5.059196472167969,
            4.092034339904785,
            0.40741586685180664,
            1.6786901950836182,
            -3.547421932220459,
            -3.578312873840332,
            -0.1884748339653015,
            1.9890352487564087,
            3.8552112579345703,
            -0.6443824768066406,
            1.5933549404144287,
            -0.34815388917922974,
            -0.9916453957557678,
            -1.917820692062378,
            -4.777472496032715,
            -3.596698522567749,
            3.1063284873962402,
            4.1465229988098145,
            -1.7551243305206299,
            -0.7966946363449097,
            1.0203227996826172,
            -4.43580436706543,
            6.943390369415283,
            -0.08906769752502441,
            3.609555721282959,
            -0.543534517288208,
            1.3349628448486328,
            5.337822914123535,
            -2.6130826473236084,
            -1.2526061534881592,
            1.2717734575271606,
            1.1588859558105469,
            3.038313388824463,
            -0.47172409296035767,
            -3.265028476715088,
            -0.3774946928024292,
            -2.755488872528076,
            1.241441011428833,
            -0.9983611106872559,
            1.3699440956115723,
            -2.147376537322998,
            1.4791457653045654,
            3.320364475250244,
            -0.31095510721206665,
            -3.896881580352783,
            -2.5533030033111572,
            -0.23529881238937378,
            7.216362953186035,
            0.8508570790290833,
            -2.969742774963379,
            3.5073208808898926,
            4.32968807220459,
            -0.3813079297542572,
            2.6043167114257812,
            3.255511999130249,
            -2.209170341491699,
            -0.3148317337036133,
            5.298145294189453,
            1.532468557357788,
            1.3328295946121216,
            -0.35316696763038635,
            -4.619420528411865,
            1.0639393329620361,
            0.12379372119903564,
            -2.3937625885009766,
            -0.8560530543327332,
            0.25140559673309326,
            -4.407331466674805,
            -1.9724794626235962,
            -1.7271833419799805,
            -1.3788864612579346,
            3.4337668418884277,
            1.0532708168029785,
            1.9553236961364746,
            3.5621836185455322,
            -0.7946175336837769,
            -1.2876578569412231,
            0.7534654140472412,
            -0.19746273756027222,
            -5.178592205047607,
            -2.482193946838379,
            -0.5841823816299438,
            1.0724403858184814,
            0.41396161913871765,
            -2.960237979888916,
            2.6027708053588867,
            -0.028667807579040527,
            0.7304903268814087,
            -2.384596347808838,
            -2.4603216648101807,
            4.317328453063965,
            -1.1453899145126343,
            1.3533949851989746,
            0.10939651727676392,
            3.4853572845458984,
            -3.918414831161499,
            -0.35602420568466187,
            -1.3054848909378052,
            4.714913368225098,
            -2.844204902648926,
            -2.0556459426879883,
            -1.1503360271453857,
            -0.8960723280906677,
            0.8926324844360352,
            -1.879757285118103,
            2.3297460079193115,
            -0.14561855792999268,
            0.19178146123886108,
            -2.9278857707977295,
            4.34327507019043,
            -1.719778299331665,
            -3.949202537536621,
            -5.298628807067871,
            2.5139341354370117,
            1.8869407176971436,
            1.9642443656921387,
            -1.2172293663024902,
            3.9775238037109375,
            -0.28022444248199463,
            -2.980147361755371,
            1.3114290237426758,
            -1.9452881813049316,
            2.349365711212158,
            -0.29075175523757935,
            4.838590621948242,
            5.154263973236084,
            -2.0216290950775146,
            -0.6104945540428162,
            0.7954981327056885,
            -0.6056475639343262,
            3.7878189086914062,
            2.990206241607666,
            1.1105504035949707,
            2.101118803024292,
            2.0074610710144043,
            1.552019715309143,
            -2.2434792518615723,
            2.280337333679199,
            7.163290500640869,
            5.580519676208496,
            2.122819423675537,
            -2.1456193923950195,
            -0.52956223487854,
            2.6312122344970703,
            -1.5345869064331055,
            1.566241979598999,
            -6.830303192138672,
            2.452411413192749,
            -1.548262357711792,
            2.45833683013916,
            -1.6914781332015991,
            2.065222978591919,
            -9.688213348388672,
            -3.6180126667022705,
            6.493253231048584,
            -4.383219242095947,
            -0.8391027450561523,
            3.8342983722686768,
            2.9472124576568604,
            2.7562313079833984,
            1.1307361125946045,
            -2.445194721221924,
            0.5373871326446533,
            6.605507850646973,
            2.005565643310547,
            4.604604721069336,
            -0.21854937076568604,
            -1.3259657621383667,
            -2.7787163257598877,
            1.5415738821029663,
            -0.8213144540786743,
            -0.9665938019752502,
            -6.98730993270874,
            -1.0125651359558105,
            -6.4422383308410645,
            -0.8751137256622314,
            -0.594538152217865,
            2.5717411041259766,
            -1.4059842824935913,
            -0.5319728851318359,
            4.0513410568237305,
            -0.11519670486450195,
            5.959259986877441,
            4.003176689147949,
            -0.31973791122436523,
            0.8828195333480835,
            3.4212045669555664,
            0.43094509840011597,
            1.5888671875,
            4.500364303588867,
            3.354858636856079,
            -0.2502872049808502,
            -3.0334932804107666,
            -4.389551162719727,
            3.8983426094055176,
            3.128192901611328,
            -3.8389170169830322,
            0.9459141492843628,
            4.055819511413574,
            -1.023170828819275,
            1.2593207359313965,
            -2.2653424739837646,
            -2.970262289047241,
            5.766028881072998,
            -3.594646453857422,
            0.24208936095237732,
            -4.850624084472656,
            0.331556499004364,
            2.3495569229125977,
            -1.513649582862854,
            1.9185214042663574,
            2.1841824054718018,
            0.05594676733016968,
            -1.9371531009674072,
            2.864271640777588,
            -5.645697593688965,
            0.6327047348022461,
            2.576021671295166,
            -0.7199870944023132,
            2.8714563846588135,
            -0.6341063976287842,
            -3.086916923522949,
            -0.22794482111930847,
            -1.611440658569336,
            -7.303589344024658,
            -0.260794460773468,
            -3.045315742492676,
            3.441589593887329,
            0.09209556877613068,
            -0.38779616355895996,
            4.411433219909668,
            -0.10124349594116211,
            2.5681686401367188,
            2.2860474586486816,
            1.7647149562835693,
            -0.4664619266986847,
            -4.7647857666015625,
            -2.886408805847168,
            0.9795185327529907,
            -0.07630273699760437,
            -0.47752419114112854,
            -0.9391937255859375,
            0.46718162298202515,
            -3.1879422664642334,
            -0.1416165828704834,
            -1.17503023147583,
            1.4041845798492432,
            2.9492311477661133,
            0.4775818884372711,
            -0.13660719990730286,
            4.354493618011475,
            3.3194258213043213,
            -1.3606255054473877,
            4.546197414398193,
            -1.8644492626190186,
            -3.1183972358703613,
            -3.1494204998016357,
            -0.8132098913192749,
            -2.5694727897644043,
            2.6803948879241943,
            4.339038848876953,
            1.6065559387207031,
            -0.32744520902633667,
            -3.867658853530884,
            -4.809540271759033,
            -4.269881725311279,
            -1.6744818687438965,
            -1.9049917459487915,
            6.2990241050720215,
            0.5760530829429626,
            2.072129011154175,
            -0.32688504457473755,
            -2.626016616821289,
            -2.137131929397583,
            -3.928183078765869,
            -2.7984089851379395,
            -6.809366226196289,
            -0.8789032697677612,
            2.129631280899048,
            -2.0936055183410645,
            -1.1492810249328613,
            2.913646936416626,
            -2.1285042762756348,
            1.238398790359497,
            -2.480879306793213,
            5.3031816482543945,
            3.7088775634765625,
            -0.3610568046569824,
            -0.9557862877845764,
            -0.36043038964271545,
            -2.881690502166748,
            1.2382433414459229,
            2.6806232929229736,
            -2.9507880210876465,
            -0.5400427579879761,
            3.8421614170074463,
            0.00287020206451416,
            -0.03474818170070648,
            3.3079757690429688,
            -1.823485016822815,
            -4.179515361785889,
            -1.3334510326385498,
            1.1385548114776611,
            -7.570349216461182,
            -2.8543314933776855,
            0.8966918587684631,
            2.59841251373291,
            -1.5087865591049194,
            -1.793768048286438,
            -0.2036953866481781,
            -0.14092975854873657,
            2.1544055938720703,
            -2.5578384399414062,
            -2.776834011077881,
            -1.7620078325271606,
            1.370424509048462,
            5.186751365661621,
            3.472379446029663,
            -1.7215712070465088,
            2.4981863498687744,
            3.7993860244750977,
            3.420527696609497,
            1.7189686298370361,
            0.9051340818405151,
            -1.5807957649230957,
            -4.732734203338623,
            -2.8471953868865967,
            -0.1693645417690277,
            1.9435350894927979,
            -1.731905460357666,
            3.696399211883545,
            8.684959411621094,
            -1.8814773559570312,
            -0.28862684965133667,
            0.28043365478515625,
            1.1841768026351929,
            3.7971649169921875,
            -0.27967560291290283,
            0.09987339377403259,
            -4.190703392028809,
            3.6990315914154053,
            2.592329978942871,
            2.7814605236053467,
            -4.696012496948242,
            0.4318683445453644,
            3.415992259979248,
            3.643357753753662,
            -0.06475341320037842,
            1.5875039100646973,
            -0.44836315512657166,
            2.1403822898864746,
            -0.8705135583877563,
            -2.183218479156494,
            1.3327275514602661,
            -1.1387953758239746,
            -0.14889122545719147,
            10.653608322143555,
            -0.627138078212738,
            1.0029479265213013,
            -6.215090751647949,
            -3.9255383014678955,
            -1.5114667415618896,
            -4.83966588973999,
            3.6098151206970215,
            -2.823381185531616,
            -2.9375972747802734,
            -1.9049160480499268,
            -4.865920543670654,
            1.4498220682144165,
            5.319719314575195,
            -3.6551856994628906,
            2.7145700454711914,
            2.1242103576660156,
            4.447914123535156,
            2.1913862228393555,
            0.2337217628955841,
            -3.1040334701538086,
            4.3827972412109375,
            2.65567946434021,
            0.6854745149612427,
            -1.1622955799102783,
            0.40392830967903137,
            -0.5474295020103455,
            0.9854503870010376,
            -3.156768798828125,
            -4.842131614685059,
            -3.242340564727783,
            -1.9966516494750977,
            -1.0014193058013916,
            -2.311523199081421,
            1.2921910285949707,
            0.10324060916900635,
            3.120194911956787,
            3.3756160736083984,
            -0.21281181275844574,
            -1.020993947982788,
            5.97580623626709,
            -2.183342456817627,
            -2.2241344451904297,
            6.709017753601074,
            -3.54152774810791,
            -3.000521659851074,
            -2.1560897827148438,
            -1.3002744913101196,
            -1.9090521335601807,
            1.2459443807601929,
            0.3911624550819397,
            3.6525979042053223,
            1.6431825160980225,
            1.1142339706420898,
            -4.860418319702148,
            3.595580577850342,
            5.254421710968018,
            2.691866397857666,
            0.41221630573272705,
            0.9890205264091492,
            0.13384166359901428,
            1.5257707834243774,
            -3.959223508834839,
            -0.22210842370986938,
            0.8966575860977173,
            6.3895769119262695,
            0.48122191429138184,
            -2.4061081409454346,
            -0.6007686853408813,
            3.722625732421875,
            2.9160475730895996,
            -1.972155213356018,
            0.8021637201309204,
            -4.588822364807129,
            1.0126961469650269,
            4.513105869293213,
            -3.9035212993621826,
            1.6225624084472656,
            2.871530532836914,
            1.930185317993164,
            0.4716609716415405,
            0.9563872814178467,
            -0.40900227427482605,
            -5.58514404296875,
            3.9695582389831543,
            -3.2790145874023438,
            -3.553852081298828,
            0.14758220314979553,
            0.5650272369384766,
            0.04976540803909302,
            -0.6320281028747559,
            0.32103231549263,
            1.8380348682403564,
            -0.28398990631103516,
            -3.5267887115478516,
            1.5578049421310425,
            1.9552147388458252,
            2.642812490463257,
            1.3329548835754395,
            3.921907424926758,
            -1.0749726295471191,
            0.4889100193977356,
            -4.15639591217041,
            -0.749108076095581,
            6.089616298675537,
            1.5523698329925537,
            -2.5750527381896973,
            0.33885928988456726,
            1.6019755601882935,
            2.3041419982910156,
            1.0240188837051392,
            1.7368032932281494,
            1.0417364835739136,
            -4.658886909484863,
            -2.696171283721924,
            -1.6154096126556396,
            5.514801979064941,
            -1.0898175239562988,
            -1.2338948249816895,
            4.349948883056641,
            4.450240612030029,
            2.6603074073791504,
            4.337955474853516,
            3.961425542831421,
            -1.6993582248687744,
            1.0570099353790283,
            5.575171947479248,
            -1.4097926616668701,
            2.5360894203186035,
            -0.5223151445388794,
            -7.682411193847656,
            3.3242220878601074,
            0.8163233399391174,
            -0.17140087485313416,
            0.38515228033065796,
            -6.150683403015137,
            -2.053907871246338,
            0.9224808216094971,
            -2.952284336090088,
            3.5189976692199707,
            3.445784330368042,
            1.6410402059555054,
            -0.7589696049690247,
            0.5286867022514343,
            -2.6095921993255615,
            -0.1731971800327301,
            -3.5137572288513184,
            2.1198160648345947,
            -1.4209036827087402,
            -1.1327910423278809,
            3.9427576065063477,
            -5.1218671798706055,
            -1.5947160720825195,
            2.9675631523132324,
            0.12625819444656372,
            -1.0913619995117188,
            -1.9177734851837158,
            1.958866834640503,
            4.167776107788086,
            -1.42330801486969,
            -6.2458953857421875,
            0.36384135484695435,
            -0.0573347806930542,
            5.353034019470215,
            3.8175859451293945,
            5.646203994750977,
            2.662808895111084,
            0.40922829508781433,
            -4.10830020904541,
            -5.067516803741455,
            -1.2446625232696533,
            5.099861145019531,
            0.7204312682151794,
            -2.6833291053771973,
            2.130638837814331,
            -1.0021601915359497,
            0.7250796556472778,
            2.8741350173950195,
            0.06465429067611694,
            4.75614595413208,
            -3.7969112396240234,
            -1.8936550617218018,
            -0.18421512842178345,
            -0.3091391921043396,
            -0.19930651783943176,
            0.09359103441238403,
            -1.3509743213653564,
            -0.7982167601585388,
            -0.8235645294189453,
            -0.9908770322799683,
            -2.158019781112671,
            -4.2726850509643555,
            -0.28301072120666504,
            -0.47118592262268066,
            -0.77830570936203,
            -4.612689018249512,
            0.9180256128311157,
            4.600098609924316,
            -0.8224172592163086,
            -2.5051145553588867,
            1.0005369186401367,
            5.752730846405029,
            -0.23403409123420715,
            -2.2370777130126953,
            -1.3527657985687256,
            -5.819887161254883,
            -0.30148351192474365,
            1.3932024240493774,
            1.0487322807312012,
            2.011443614959717,
            4.447563171386719,
            3.425612449645996,
            -3.0473012924194336,
            -2.7896206378936768,
            -2.6838326454162598,
            -1.613683819770813,
            -0.6318202614784241,
            -5.177029609680176,
            0.8722290992736816,
            -5.270374298095703,
            -4.276721000671387,
            3.040961742401123,
            -4.294318675994873,
            -0.5960670113563538,
            2.8710339069366455,
            -2.1722116470336914,
            1.5956950187683105,
            -3.9447085857391357,
            -3.6161890029907227,
            -3.8829569816589355,
            6.160320281982422,
            1.150125503540039,
            -1.4533097743988037,
            1.926523208618164,
            2.597838878631592,
            4.249283790588379,
            6.102622032165527,
            4.4759674072265625,
            -3.103865385055542,
            -0.00029950588941574097,
            2.2814149856567383,
            0.6106885075569153,
            -4.2866315841674805,
            -0.5813798904418945,
            -0.3784421682357788,
            0.3040807247161865,
            19.162738800048828,
            -3.1172432899475098,
            -1.2553491592407227,
            -2.098402976989746,
            -2.51168155670166,
            -3.506551504135132,
            -0.05402684211730957,
            3.5192272663116455,
            -2.80602765083313,
            2.0731797218322754,
            -0.45804062485694885,
            -5.486361503601074,
            -0.7721707820892334,
            3.72672438621521,
            -5.341826915740967,
            -2.404794692993164,
            -4.944295406341553,
            3.9792799949645996,
            -2.013037919998169,
            1.2561843395233154,
            -1.7406859397888184,
            0.3548833131790161,
            -2.7762715816497803,
            -3.598301887512207,
            0.5682071447372437,
            1.7718528509140015,
            -1.0621461868286133,
            2.5870633125305176,
            -6.184439659118652,
            0.4529697000980377,
            -0.6098077297210693,
            -4.05696964263916,
            3.9168448448181152,
            0.8172621726989746,
            0.8283725380897522,
            2.277832508087158,
            6.496628284454346,
            -2.294506072998047,
            -0.44214606285095215,
            -1.1223238706588745,
            0.8828436136245728,
            2.59967303276062,
            -5.094547271728516,
            0.4574488401412964,
            -3.522693157196045,
            0.9730970859527588,
            4.490562438964844,
            -3.0390968322753906,
            -3.0580015182495117,
            8.736215591430664,
            -1.2056032419204712,
            2.1933536529541016,
            -2.066664695739746,
            -0.055261433124542236,
            3.1004910469055176,
            5.30911922454834,
            0.36988553404808044,
            -2.420323371887207,
            3.678800582885742,
            0.3447498679161072,
            1.918220043182373,
            1.9840208292007446,
            -2.908649206161499,
            -3.892612934112549,
            2.9421143531799316,
            1.7842612266540527,
            -6.521833419799805,
            4.901881694793701,
            1.0745148658752441,
            -1.063391089439392,
            3.533428192138672,
            3.3784334659576416,
            2.5723209381103516,
            -0.4963826835155487,
            -3.059838056564331,
            -5.076412200927734,
            -1.053975224494934,
            -2.3240814208984375,
            4.131121635437012,
            5.174037933349609,
            -3.92653751373291,
            5.369035720825195,
            -2.093332290649414,
            2.5880279541015625,
            5.7684478759765625,
            -2.30854868888855,
            -0.14578412473201752,
            -0.4572696089744568,
            -0.5308274030685425,
            1.4853483438491821,
            -0.06448787450790405,
            0.8504078984260559,
            3.160599946975708,
            -0.6453539729118347,
            2.501887798309326,
            -6.172430515289307,
            -4.692748069763184,
            -2.7895400524139404,
            -6.475507736206055,
            -3.2417359352111816,
            7.274097442626953,
            3.038395881652832,
            3.7144179344177246,
            -4.1551103591918945,
            1.8741536140441895,
            -1.7775073051452637,
            -1.8730454444885254,
            -5.35792875289917,
            -1.564992904663086,
            -3.3612518310546875,
            1.961480975151062,
            -2.5777502059936523,
            2.327763557434082,
            -1.8812772035598755,
            1.5880423784255981,
            -1.8465152978897095,
            -0.5227614641189575,
            1.7804746627807617,
            1.1749742031097412,
            4.221776962280273,
            -0.07000178098678589,
            -0.6368513107299805,
            -4.835169315338135,
            -3.986997127532959,
            0.4540482461452484,
            0.24594682455062866,
            -0.22518280148506165,
            0.8512578010559082,
            -0.8460186719894409,
            -6.0218400955200195,
            0.727202296257019,
            0.12645766139030457,
            -0.5181189179420471,
            1.114618182182312,
            -0.5114938020706177,
            3.569632053375244,
            -0.06051838397979736,
            2.389157772064209,
            -1.6886022090911865,
            3.8738441467285156,
            3.412203550338745,
            0.41466736793518066,
            -1.1705396175384521,
            7.070636749267578,
            -1.3496794700622559,
            -1.4714226722717285,
            -1.8601984977722168,
            -4.018918514251709,
            -1.0327792167663574,
            1.9065544605255127,
            -2.011630058288574,
            -0.5837048292160034,
            3.634695291519165,
            -0.1680525541305542,
            -3.3313517570495605,
            -2.129849433898926
        ]
    },
    "authors": [
        {
            "authorId": "2273948946",
            "name": "Wenxuan Wang"
        },
        {
            "authorId": "2264040642",
            "name": "Quan Sun"
        },
        {
            "authorId": "2264274388",
            "name": "Fan Zhang"
        },
        {
            "authorId": "2107222678",
            "name": "Yepeng Tang"
        },
        {
            "authorId": "2313885550",
            "name": "Jing Liu"
        },
        {
            "authorId": "2274068951",
            "name": "Xinlong Wang"
        }
    ],
    "references": [
        {
            "paperId": "94773f22b5befd0e167a7de525d29bec2b09937a",
            "title": "Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs"
        },
        {
            "paperId": "b6dfec329f8f517678fa90348af8e5806c38ce01",
            "title": "Learnable Feature Augmentation Framework for Temporal Action Localization"
        },
        {
            "paperId": "d0710c18dd547c46cf4d1c2fe875cb197ff1225c",
            "title": "Open-Vocabulary Semantic Segmentation with Image Embedding Balancing"
        },
        {
            "paperId": "0bcda9580066202cba741f0e07292ad1ea0fd7f0",
            "title": "Everything to the Synthetic: Diffusion-driven Test-time Adaptation via Synthetic-Domain Alignment"
        },
        {
            "paperId": "9738dde55ab77cc26271a5753db7dd7851176fd6",
            "title": "BRAVE: Broadening the visual encoding of vision-language models"
        },
        {
            "paperId": "4956e8f57227ec8f642dc54e2c0c3742ebb388e7",
            "title": "Long-CLIP: Unlocking the Long-Text Capability of CLIP"
        },
        {
            "paperId": "65e8a4cca1a80f517bab8b4c3a39cc63d7527e66",
            "title": "CogView3: Finer and Faster Text-to-Image Generation via Relay Diffusion"
        },
        {
            "paperId": "956c34e071a4b7ec348e37f1aeeeaf909d2cd6a9",
            "title": "EVA-CLIP-18B: Scaling CLIP to 18 Billion Parameters"
        },
        {
            "paperId": "45151ac2726bb3bc7e545441a458fd4afb1bba48",
            "title": "UMG-CLIP: A Unified Multi-Granularity Vision Generalist for Open-World Understanding"
        },
        {
            "paperId": "ca00f4056f9039d3c1a4c3a113f5ee0527149b66",
            "title": "Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs"
        },
        {
            "paperId": "449eb627a55bda10cf6c899f5fc941828f34e5a5",
            "title": "Instruct-Imagen: Image Generation with Multi-modal Instruction"
        },
        {
            "paperId": "4b1b5e219fb41a7413599c3b2ca6a7fdf045d1a5",
            "title": "Generative Multimodal Models are In-Context Learners"
        },
        {
            "paperId": "4d1194e9e990ba9decd597cd93c555e5d1d06d54",
            "title": "Unveiling Parts Beyond Objects: Towards Finer-Granularity Referring Expression Segmentation"
        },
        {
            "paperId": "d198a5a1a0c6e31bd0ad70658c8c2a74b8753aed",
            "title": "Alpha-CLIP: A CLIP Model Focusing on Wherever You Want"
        },
        {
            "paperId": "3852b468bd6c5a22e1c13a425fdd7604b5bcb7e2",
            "title": "SODA: Bottleneck Diffusion Models for Representation Learning"
        },
        {
            "paperId": "1e0abe0e8c9471de5df11c24d5ded5c94911b226",
            "title": "Diffusion-TTA: Test-time Adaptation of Discriminative Models via Generative Feedback"
        },
        {
            "paperId": "1206b05eae5a06ba662ae79fb291b50e359c4f42",
            "title": "Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets"
        },
        {
            "paperId": "aeb6120224c8fec3398b7f597debcda2c6ce02c9",
            "title": "From CLIP to DINO: Visual Encoders Shout in Multi-modal Large Language Models"
        },
        {
            "paperId": "124d4d374fbef2016fa9880489871a58a7450644",
            "title": "Improved Baselines with Visual Instruction Tuning"
        },
        {
            "paperId": "67542b13bf5cad9ae7af5b7b78f2c7068688aa02",
            "title": "LexLIP: Lexicon-Bottlenecked Language-Image Pre-Training for Large-Scale Image-Text Sparse Retrieval"
        },
        {
            "paperId": "1ffc85ebcd8d0fffa27a80d76fde4e4f1a0f7768",
            "title": "Improving CLIP Fine-tuning Performance"
        },
        {
            "paperId": "f349e5e8f0d18c948c1ffd92d3791db2b0ba2e55",
            "title": "Data Filtering Networks"
        },
        {
            "paperId": "1cc39f7691af0bc1061dda7897a3f62f098573d6",
            "title": "Demystifying CLIP Data"
        },
        {
            "paperId": "a5b7fc1bff0910ff31975ec0a15ed30c41f0a968",
            "title": "Show-1: Marrying Pixel and Latent Diffusion Models for Text-to-Video Generation"
        },
        {
            "paperId": "72de731e88f7a6d983729d0dfafea1b41be5ac8f",
            "title": "Masked Diffusion as Self-supervised Representation Learner"
        },
        {
            "paperId": "b37b1dc72b1882858f5120f2cd6883134089a6ed",
            "title": "MMBench: Is Your Multi-modal Model an All-around Player?"
        },
        {
            "paperId": "2cfaa5b3571d3b75f040f6d639359a3c673f5561",
            "title": "DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models"
        },
        {
            "paperId": "697e0add95e880bd42e00bef838181e105f91981",
            "title": "MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models"
        },
        {
            "paperId": "986839c6da75e8f9ed1c767400657e5de7b527a4",
            "title": "StableRep: Synthetic Images from Text-to-Image Models Make Strong Visual Representation Learners"
        },
        {
            "paperId": "8c8f27ddb96ee17a1997a1f7e5e0e613ab6e3937",
            "title": "CM-MaskSD: Cross-Modality Masked Self-Distillation for Referring Image Segmentation"
        },
        {
            "paperId": "206400aba5f12f734cdd2e4ab48ef6014ea60773",
            "title": "Evaluating Object Hallucination in Large Vision-Language Models"
        },
        {
            "paperId": "5faee4af70f65e609eafe1f23f26593423f03750",
            "title": "Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers"
        },
        {
            "paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8",
            "title": "Visual Instruction Tuning"
        },
        {
            "paperId": "4538e353dd98f396c8facc29ebb72e9b1ba5f7c2",
            "title": "Synthetic Data from Diffusion Models Improves ImageNet Classification"
        },
        {
            "paperId": "db1c83ef73d2f7731b0dd255835f2f26db749e17",
            "title": "Not All Features Matter: Enhancing Few-shot CLIP with Adaptive Prior Refinement"
        },
        {
            "paperId": "c70833ab04675e6e339739c11eebd20c60db3d9f",
            "title": "Zero-shot Referring Image Segmentation with Global-Local Context Features"
        },
        {
            "paperId": "35aba190f28b5c39df333c06ca21f46bd4845eba",
            "title": "Sigmoid Loss for Language Image Pre-Training"
        },
        {
            "paperId": "a08b7123a7158f1a7fbbc18e8b5aaebd47980ecf",
            "title": "EVA-CLIP: Improved Training Techniques for CLIP at Scale"
        },
        {
            "paperId": "3bee6efbd60fdc13bce78a2a0f92bc3af119108e",
            "title": "CLIP for All Things Zero-Shot Sketch-Based Image Retrieval, Fine-Grained or Not"
        },
        {
            "paperId": "df4b6713abfe226d06099d7749f8b47903ac087b",
            "title": "Denoising Diffusion Autoencoders are Unified Self-supervised Learners"
        },
        {
            "paperId": "323400245885e08ad498cd108e30e18020662278",
            "title": "Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models"
        },
        {
            "paperId": "c09ca9da1fce13b1560f45c38321c7bb971f13fc",
            "title": "Unleashing Text-to-Image Diffusion Models for Visual Perception"
        },
        {
            "paperId": "641d7866db6691e22aa36de5c8ba05804233c016",
            "title": "Side Adapter Network for Open-Vocabulary Semantic Segmentation"
        },
        {
            "paperId": "1e05c5427d6a35a3b1bf37fb955f2ea94995a71d",
            "title": "Effective Data Augmentation With Diffusion Models"
        },
        {
            "paperId": "736973165f98105fec3729b7db414ae4d80fcbeb",
            "title": "Scalable Diffusion Models with Transformers"
        },
        {
            "paperId": "67db43cb6cc618c873c63fe2c83025c335b7a230",
            "title": "ZegCLIP: Towards Adapting CLIP for Zero-shot Semantic Segmentation"
        },
        {
            "paperId": "480c59487bb9b56a6692c1ba80fcf2c08ad75002",
            "title": "Fine-tuned CLIP Models are Efficient Video Learners"
        },
        {
            "paperId": "2f9053cea6b3f211ed60e2274b95948d54a7fd28",
            "title": "MovieCLIP: Visual Scene Recognition in Movies"
        },
        {
            "paperId": "29c2d3d77b6d6f24f4356d5ba20c1a6ab4229c76",
            "title": "Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP"
        },
        {
            "paperId": "498ac9b2e494601d20a3d0211c16acf2b7954a54",
            "title": "Imagen Video: High Definition Video Generation with Diffusion Models"
        },
        {
            "paperId": "1e33716e8820b867d5a8aaebab44c2d3135ea4ac",
            "title": "Make-A-Video: Text-to-Video Generation without Text-Video Data"
        },
        {
            "paperId": "c8ed469b1d00bc86fbb16fcfa6b407e4f57e3d86",
            "title": "Frozen CLIP Models are Efficient Video Learners"
        },
        {
            "paperId": "a32887af7eb1fcfd3b3d892ad41f3516a37f11c1",
            "title": "Tip-Adapter: Training-free Adaption of CLIP for Few-shot Classification"
        },
        {
            "paperId": "744c42180b9721c1c15b753ba9c00b019b5dfec2",
            "title": "Effective conditioned and composed image retrieval combining CLIP-based features"
        },
        {
            "paperId": "9695824d7a01fad57ba9c01d7d76a519d78d65e7",
            "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"
        },
        {
            "paperId": "6979ce65b9f657672cd3a0b9217ead51511c1838",
            "title": "VQGAN-CLIP: Open Domain Image Generation and Editing with Natural Language Guidance"
        },
        {
            "paperId": "c57293882b2561e1ba03017902df9fc2f289dea2",
            "title": "Hierarchical Text-Conditional Image Generation with CLIP Latents"
        },
        {
            "paperId": "408efdd599b2b27ecb95a4d799869c9ff568fb31",
            "title": "ReCLIP: A Strong Zero-Shot Baseline for Referring Expression Comprehension"
        },
        {
            "paperId": "c0e8812789e96f5a7aa3ad940dba1c237aec822d",
            "title": "Text2LIVE: Text-Driven Layered Image and Video Editing"
        },
        {
            "paperId": "dde448eb4d3358d12c674e9213d5de32c1752f3e",
            "title": "FitCLIP: Refining Large-Scale Pretrained Image-Text Models for Zero-Shot Video Understanding Tasks"
        },
        {
            "paperId": "0b5f27a5766c5d1394a6282ad94fec21d620bd6b",
            "title": "GroupViT: Semantic Segmentation Emerges from Text Supervision"
        },
        {
            "paperId": "cc9826c222ac1e81b4b374dd9e0df130f298b1e8",
            "title": "Language-driven Semantic Segmentation"
        },
        {
            "paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
            "title": "High-Resolution Image Synthesis with Latent Diffusion Models"
        },
        {
            "paperId": "5341b412383c43f4a693ad63ec4489e3ec7688c8",
            "title": "Grounded Language-Image Pre-training"
        },
        {
            "paperId": "42f2271cebb7f272b0066c1f22d33381f139ee68",
            "title": "Label-Efficient Semantic Segmentation with Diffusion Models"
        },
        {
            "paperId": "76a2b197b5427ffd1d3470c6d3ea026588eb5d0a",
            "title": "CRIS: CLIP-Driven Referring Image Segmentation"
        },
        {
            "paperId": "ec8afc75ec219f2a5f9ed9d7c9dde0720f69b5a2",
            "title": "Multi-Grained Vision Language Pre-Training: Aligning Texts with Visual Concepts"
        },
        {
            "paperId": "821ad6c9f0fecb5fabb486a5a87a93b7ea65bcc0",
            "title": "VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding"
        },
        {
            "paperId": "f671a09e3e5922e6d38cb77dda8d76d5ceac2a27",
            "title": "SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations"
        },
        {
            "paperId": "b1a5e147f8b4d4f750f8224ea2dcb0fdebb3ff73",
            "title": "CLIPDraw: Exploring Text-to-Drawing Synthesis through Language-Image Encoders"
        },
        {
            "paperId": "cf9b8da26d9b92e75ba49616ed2a1033f59fce14",
            "title": "Open-vocabulary Object Detection via Vision and Language Knowledge Distillation"
        },
        {
            "paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4",
            "title": "Learning Transferable Visual Models From Natural Language Supervision"
        },
        {
            "paperId": "633e2fbfc0b21e959a244100937c5853afca4853",
            "title": "Score-Based Generative Modeling through Stochastic Differential Equations"
        },
        {
            "paperId": "022622e024890d6e044ac50e2da6b44c59bdf418",
            "title": "The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization"
        },
        {
            "paperId": "5c126ae3421f05768d8edd97ecd44b1364e2c99a",
            "title": "Denoising Diffusion Probabilistic Models"
        },
        {
            "paperId": "45557cc70cd6989ab6b03e5aeb787e34299099f7",
            "title": "Natural Adversarial Examples"
        },
        {
            "paperId": "4ae0c4a511697e960c477ea3e37b3e11bf3e0e02",
            "title": "Learning Robust Global Representations by Penalizing Local Predictive Power"
        },
        {
            "paperId": "4e0bb8c1c683b43357c5d5216f6b74ff2cb32434",
            "title": "Do ImageNet Classifiers Generalize to ImageNet?"
        },
        {
            "paperId": "b4df354db88a70183a64dbc9e56cf14e7669a6c0",
            "title": "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"
        },
        {
            "paperId": "2a96afaf3261a87f0daa51699b4b3cf169e092c4",
            "title": "Rotation Equivariant CNNs for Digital Pathology"
        },
        {
            "paperId": "9c88c2357abcd58cc330179c1965fe0a8c067ebc",
            "title": "EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification"
        },
        {
            "paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d",
            "title": "Scene Parsing through ADE20K Dataset"
        },
        {
            "paperId": "179765729fc1e269393617795507607c29a66a8e",
            "title": "Remote Sensing Image Scene Classification: Benchmark and State of the Art"
        },
        {
            "paperId": "8e3f12804882b60ad5f59aad92755c5edb34860e",
            "title": "Food-101 - Mining Discriminative Components with Random Forests"
        },
        {
            "paperId": "3419ccd5c94d301ee08d716d037f0c3c6a62e78e",
            "title": "The Role of Context for Object Detection and Semantic Segmentation in the Wild"
        },
        {
            "paperId": "4965eec4d6fd69e9bff12dce7d9d84897433cc2a",
            "title": "Birdsnap: Large-Scale Fine-Grained Visual Categorization of Birds"
        },
        {
            "paperId": "71b7178df5d2b112d07e45038cb5637208659ff7",
            "title": "Microsoft COCO: Common Objects in Context"
        },
        {
            "paperId": "44040913380206991b1991daf1192942e038fe31",
            "title": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions"
        },
        {
            "paperId": "a83cec6a91701bd8500f8c43ad731d4353c71d55",
            "title": "3D Object Representations for Fine-Grained Categorization"
        },
        {
            "paperId": "18c125ce0f64e85577f7d30132cf0e92ec664bf4",
            "title": "Describing Textures in the Wild"
        },
        {
            "paperId": "db8c3cfaae04a14c1209d62953029b6fa53e23c7",
            "title": "Challenges in representation learning: A report on three machine learning contests"
        },
        {
            "paperId": "522d65a3db7431015aeaa201a7fc4450a57e40c3",
            "title": "Fine-Grained Visual Classification of Aircraft"
        },
        {
            "paperId": "c56e758ba18066a8cdc333f15dfdb7ea6af4d283",
            "title": "Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition"
        },
        {
            "paperId": "84b50ebe85f7a1721800125e7882fce8c45b5c5a",
            "title": "Cats and dogs"
        },
        {
            "paperId": "be9a17321537d9289875fe475b71f4821457b435",
            "title": "An Analysis of Single-Layer Networks in Unsupervised Feature Learning"
        },
        {
            "paperId": "908091b4a8757c3b2f7d9cfa2c4f616ee12c5157",
            "title": "SUN database: Large-scale scene recognition from abbey to zoo"
        },
        {
            "paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e",
            "title": "ImageNet: A large-scale hierarchical image database"
        },
        {
            "paperId": "02b28f3b71138a06e40dbd614abf8568420ae183",
            "title": "Automated Flower Classification over a Large Number of Classes"
        },
        {
            "paperId": "ed9db7b20e019cdb1c7db8b7921221ee2d9f36e2",
            "title": "Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories"
        },
        {
            "paperId": "639174f32a71ecfe9041ad05ff30eb39bd4977bf",
            "title": "ObjectNet: A large-scale bias-controlled dataset for pushing the limits of object recognition models"
        },
        {
            "paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086",
            "title": "Learning Multiple Layers of Features from Tiny Images"
        },
        {
            "paperId": null,
            "title": "The PASCAL visual object classes challenge 2006 (VOC2006) results"
        },
        {
            "paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "title": "Gradient-based learning applied to document recognition"
        },
        {
            "paperId": "cfee1826dd4743eab44c6e27a0cc5970effa4d80",
            "title": "Improving Image Generation with Better Captions"
        },
        {
            "paperId": null,
            "title": "Clipasso: Semantically-aware object sketching"
        },
        {
            "paperId": null,
            "title": "Emu: Generative pretraining in multimodality"
        }
    ]
}