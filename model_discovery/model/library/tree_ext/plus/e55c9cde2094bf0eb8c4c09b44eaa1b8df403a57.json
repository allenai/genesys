{
    "paperId": "e55c9cde2094bf0eb8c4c09b44eaa1b8df403a57",
    "externalIds": {
        "ArXiv": "2408.11855",
        "CorpusId": 271924362
    },
    "title": "FactorLLM: Factorizing Knowledge via Mixture of Experts for Large Language Models",
    "abstract": "Recent research has demonstrated that Feed-Forward Networks (FFNs) in Large Language Models (LLMs) play a pivotal role in storing diverse linguistic and factual knowledge. Conventional methods frequently face challenges due to knowledge confusion stemming from their monolithic and redundant architectures, which calls for more efficient solutions with minimal computational overhead, particularly for LLMs. In this paper, we explore the FFN computation paradigm in LLMs and introduce FactorLLM, a novel approach that decomposes well-trained dense FFNs into sparse sub-networks without requiring any further modifications, while maintaining the same level of performance. Furthermore, we embed a router from the Mixture-of-Experts (MoE), combined with our devised Prior-Approximate (PA) loss term that facilitates the dynamic activation of experts and knowledge adaptation, thereby accelerating computational processes and enhancing performance using minimal training data and fine-tuning steps. FactorLLM thus enables efficient knowledge factorization and activates select groups of experts specifically tailored to designated tasks, emulating the interactive functional segmentation of the human brain. Extensive experiments across various benchmarks demonstrate the effectiveness of our proposed FactorLLM which achieves comparable performance to the source model securing up to 85% model performance while obtaining over a 30% increase in inference speed. Code: https://github.com/zhenwuweihe/FactorLLM.",
    "venue": "",
    "year": 2024,
    "referenceCount": 80,
    "citationCount": 0,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper explores the FFN computation paradigm in LLMs and introduces FactorLLM, a novel approach that decomposes well-trained dense FFNs into sparse sub-networks without requiring any further modifications, while maintaining the same level of performance."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -5.129901885986328,
            0.4159059524536133,
            0.3305043578147888,
            5.807476043701172,
            1.6854958534240723,
            -1.1279611587524414,
            2.091427803039551,
            -0.901870846748352,
            -1.4667322635650635,
            1.3015820980072021,
            -2.5233688354492188,
            3.0170555114746094,
            -0.4063996970653534,
            -2.94111967086792,
            -3.027115821838379,
            -0.963935136795044,
            -1.24442458152771,
            0.13031011819839478,
            5.290801048278809,
            -0.16365143656730652,
            -1.236068844795227,
            3.624814033508301,
            -2.7131850719451904,
            0.36566686630249023,
            -1.793874979019165,
            -1.8923749923706055,
            3.218214273452759,
            0.19621671736240387,
            -1.86102294921875,
            0.746009349822998,
            0.9073084592819214,
            -7.493144512176514,
            4.969490051269531,
            -2.872330904006958,
            2.51206636428833,
            -4.144450664520264,
            -2.9739301204681396,
            7.513456344604492,
            -2.7082762718200684,
            1.5064842700958252,
            -2.5216574668884277,
            -0.5755378007888794,
            2.118328332901001,
            2.477385997772217,
            -0.36776840686798096,
            0.45560723543167114,
            1.409238576889038,
            0.10367786884307861,
            0.7434097528457642,
            0.3190259337425232,
            0.6105203032493591,
            -2.468109607696533,
            -1.9744939804077148,
            1.9653213024139404,
            -0.8922496438026428,
            -1.4695061445236206,
            -1.1998876333236694,
            2.428554058074951,
            5.506921291351318,
            -2.9536142349243164,
            4.451708793640137,
            4.467521667480469,
            -1.781008243560791,
            2.111436367034912,
            5.001358985900879,
            -3.634809970855713,
            -2.503251552581787,
            2.9294800758361816,
            0.9728866815567017,
            -0.2984502911567688,
            -0.5303416848182678,
            -4.897123336791992,
            0.4927414655685425,
            1.9460577964782715,
            -2.2041335105895996,
            0.47252529859542847,
            -0.5740207433700562,
            -6.481985092163086,
            -2.5760178565979004,
            0.29545384645462036,
            0.20558711886405945,
            1.5834832191467285,
            0.344308078289032,
            1.9147753715515137,
            2.444232940673828,
            -2.18680477142334,
            -3.2579662799835205,
            2.941800117492676,
            2.367854118347168,
            -4.2073798179626465,
            0.6027063131332397,
            2.934816837310791,
            -1.4864561557769775,
            1.610344648361206,
            -2.765613555908203,
            -1.9931416511535645,
            1.2570526599884033,
            -1.177553653717041,
            -1.4831624031066895,
            0.39773106575012207,
            1.46439528465271,
            -0.6396422982215881,
            2.0071632862091064,
            2.8255629539489746,
            4.505685806274414,
            -3.1778616905212402,
            0.2230992466211319,
            1.3831604719161987,
            1.4126765727996826,
            -1.711931824684143,
            -2.6035866737365723,
            0.2541843056678772,
            -0.04379677772521973,
            -2.5251970291137695,
            -2.6986289024353027,
            -2.9360764026641846,
            -2.8223133087158203,
            1.7275466918945312,
            -1.8026742935180664,
            5.767601490020752,
            -1.8990027904510498,
            -1.4828009605407715,
            -3.9788239002227783,
            0.7566524147987366,
            0.8025307059288025,
            1.3559573888778687,
            -2.2649106979370117,
            -1.9325261116027832,
            -0.311919242143631,
            -4.687499523162842,
            2.4951720237731934,
            -0.39299190044403076,
            4.226040840148926,
            -0.37722504138946533,
            0.680227518081665,
            3.1985182762145996,
            -3.0863730907440186,
            2.66298246383667,
            -2.3864762783050537,
            -0.7412041425704956,
            1.3750711679458618,
            3.46565580368042,
            -0.9785771369934082,
            -1.6663329601287842,
            -0.09855946898460388,
            2.773350238800049,
            0.7979573011398315,
            4.772168159484863,
            -0.04277975857257843,
            6.9234490394592285,
            5.416319847106934,
            -4.008126735687256,
            0.10513387620449066,
            1.3575444221496582,
            -3.3690030574798584,
            3.7522635459899902,
            -5.84539270401001,
            0.6652711033821106,
            -3.3406052589416504,
            1.638692021369934,
            1.1828781366348267,
            -1.0449187755584717,
            -6.793700695037842,
            -0.36482614278793335,
            4.563836097717285,
            -2.5836527347564697,
            -3.903207302093506,
            -0.3931148648262024,
            0.9687594771385193,
            3.427583694458008,
            0.18595653772354126,
            2.6732892990112305,
            3.3412411212921143,
            -0.7149184942245483,
            1.4918932914733887,
            3.120157241821289,
            1.3838772773742676,
            -1.470625877380371,
            0.27203887701034546,
            -1.0766055583953857,
            -2.5615968704223633,
            -1.540189266204834,
            -7.459471702575684,
            0.33254849910736084,
            -4.978923320770264,
            2.0055718421936035,
            -2.417482376098633,
            -2.0628490447998047,
            -0.49427032470703125,
            -0.5969778895378113,
            -4.27620792388916,
            0.6690447926521301,
            3.4236667156219482,
            5.000981330871582,
            0.265794038772583,
            3.89390230178833,
            3.6098990440368652,
            1.5441114902496338,
            -0.41819167137145996,
            0.5172488689422607,
            3.6032021045684814,
            -0.4436574876308441,
            -1.8386948108673096,
            0.3206356167793274,
            4.9051408767700195,
            2.8707361221313477,
            -2.5481600761413574,
            5.693653106689453,
            -1.6471636295318604,
            2.430866003036499,
            0.7182096242904663,
            0.7261795997619629,
            -0.8469196557998657,
            3.5811727046966553,
            -0.4949142634868622,
            -0.9143577218055725,
            -5.667704105377197,
            1.465144157409668,
            2.8134896755218506,
            2.8755099773406982,
            -1.4326351881027222,
            -1.4092597961425781,
            0.7641208171844482,
            -4.827927589416504,
            2.192668914794922,
            -6.248762130737305,
            0.10308998823165894,
            2.2938201427459717,
            -0.21930131316184998,
            -0.3540889024734497,
            2.1501846313476562,
            -7.713292598724365,
            -1.5155408382415771,
            -0.8671028017997742,
            -4.371640682220459,
            0.7458186745643616,
            -6.080819129943848,
            3.219306468963623,
            -0.6687065362930298,
            -4.760884761810303,
            4.349238395690918,
            3.895066261291504,
            1.9828530550003052,
            4.007475852966309,
            4.7377777099609375,
            2.6338047981262207,
            -2.4899020195007324,
            2.368046760559082,
            -3.034604787826538,
            -0.873651385307312,
            -0.6398982405662537,
            -2.207122564315796,
            2.967658758163452,
            0.32019221782684326,
            3.1584649085998535,
            2.237433671951294,
            0.9972060322761536,
            0.36254411935806274,
            1.6347424983978271,
            0.8350627422332764,
            2.0014002323150635,
            2.7391557693481445,
            2.649965286254883,
            2.9815714359283447,
            -1.7077429294586182,
            -1.805551528930664,
            -1.7072184085845947,
            -3.650538206100464,
            -0.7838455438613892,
            3.4570841789245605,
            3.9407947063446045,
            1.4490060806274414,
            1.394704818725586,
            -4.886029243469238,
            -2.175936222076416,
            -5.741227149963379,
            -2.567545175552368,
            0.21715980768203735,
            2.3777594566345215,
            4.64833927154541,
            -0.33345335721969604,
            -2.835559368133545,
            -1.308009147644043,
            0.2655724883079529,
            -0.4313261806964874,
            -2.8473334312438965,
            -2.97727370262146,
            -2.7685303688049316,
            0.9367338418960571,
            -1.9151593446731567,
            -2.587772846221924,
            5.264850616455078,
            -4.061100959777832,
            -4.4158430099487305,
            -2.9014391899108887,
            5.502749443054199,
            3.118587017059326,
            1.296683430671692,
            -0.34621989727020264,
            0.4943225085735321,
            0.9261487722396851,
            3.154439926147461,
            0.6145070791244507,
            0.10246896743774414,
            -0.20535123348236084,
            2.5210721492767334,
            -0.7009788155555725,
            -0.958206057548523,
            -0.48214757442474365,
            -2.8534045219421387,
            0.8582372069358826,
            0.1323603391647339,
            2.7586398124694824,
            -4.0135087966918945,
            0.5308707356452942,
            1.7972691059112549,
            1.1592947244644165,
            -2.281463146209717,
            -3.123276472091675,
            2.3472516536712646,
            -1.3779113292694092,
            0.8217936754226685,
            -4.876150131225586,
            -1.9258161783218384,
            -4.0696821212768555,
            -0.24057646095752716,
            0.4900889992713928,
            3.6195852756500244,
            -2.960667133331299,
            1.3511900901794434,
            -0.928949773311615,
            7.722553730010986,
            4.7081708908081055,
            2.151306629180908,
            -0.3745672106742859,
            -6.447446346282959,
            -0.4766814112663269,
            -1.5119847059249878,
            3.4171106815338135,
            1.4766209125518799,
            1.6843658685684204,
            5.139001846313477,
            -1.6576178073883057,
            -1.6317188739776611,
            -2.463653564453125,
            -1.59767746925354,
            1.1776700019836426,
            -2.2159695625305176,
            -0.8893873691558838,
            -0.46853354573249817,
            1.5436519384384155,
            3.5417327880859375,
            3.949192523956299,
            -0.36480993032455444,
            2.8162131309509277,
            3.959965705871582,
            2.282710552215576,
            1.723752498626709,
            0.17034368216991425,
            3.3294124603271484,
            2.7225732803344727,
            -1.683596134185791,
            1.5099728107452393,
            2.067671775817871,
            1.8337793350219727,
            -1.1804507970809937,
            12.62193489074707,
            -1.010049819946289,
            0.5559285283088684,
            -5.286494255065918,
            -4.259550094604492,
            -2.3571078777313232,
            -5.451254844665527,
            3.3229122161865234,
            -2.6357197761535645,
            -1.2739802598953247,
            1.7826141119003296,
            -3.3954763412475586,
            2.0805721282958984,
            1.9489648342132568,
            -3.5387191772460938,
            3.238309860229492,
            -1.6454523801803589,
            1.9638094902038574,
            0.15921753644943237,
            4.122363090515137,
            -1.5903170108795166,
            2.394517183303833,
            1.6956062316894531,
            0.7358834743499756,
            -1.577648401260376,
            0.6770110726356506,
            1.2688090801239014,
            -0.15992385149002075,
            -6.191155433654785,
            -1.0602251291275024,
            -1.7947691679000854,
            -2.577402353286743,
            -2.0884156227111816,
            0.2994781732559204,
            -0.7462687492370605,
            -3.1596479415893555,
            4.877249240875244,
            6.103024005889893,
            -4.578376293182373,
            2.0699894428253174,
            3.854313611984253,
            -1.7048964500427246,
            -3.8669052124023438,
            -2.546874523162842,
            -3.5196847915649414,
            -2.5641374588012695,
            1.4544016122817993,
            -5.904841423034668,
            0.5681685209274292,
            -0.1496226191520691,
            2.163440704345703,
            3.5023882389068604,
            1.4429831504821777,
            0.5664994716644287,
            -1.8652875423431396,
            3.0707273483276367,
            4.348043441772461,
            2.7850143909454346,
            0.7406205534934998,
            -0.2303595244884491,
            0.6334686279296875,
            1.406484603881836,
            0.018228143453598022,
            3.514730453491211,
            2.782655715942383,
            3.7700934410095215,
            -1.6602500677108765,
            -0.44275927543640137,
            -1.0026599168777466,
            0.9524041414260864,
            3.0050578117370605,
            1.5260961055755615,
            1.3707588911056519,
            -2.2914204597473145,
            1.6884963512420654,
            1.9797863960266113,
            -2.3961637020111084,
            2.262765407562256,
            -0.8060119152069092,
            1.458897590637207,
            0.22000527381896973,
            0.8021419644355774,
            -1.6742537021636963,
            -0.3703506588935852,
            1.5894591808319092,
            -2.6380772590637207,
            -4.06528377532959,
            -3.5848593711853027,
            -1.1377967596054077,
            -2.5085794925689697,
            -4.433997631072998,
            0.9026104807853699,
            0.7444563508033752,
            0.09557439386844635,
            -4.136130332946777,
            4.226746559143066,
            -0.11731509864330292,
            1.937403917312622,
            1.6052577495574951,
            0.4309502840042114,
            -0.9935576915740967,
            -4.893749713897705,
            -3.256953001022339,
            1.3004255294799805,
            0.13189442455768585,
            0.16453790664672852,
            -1.4883145093917847,
            1.9207594394683838,
            -1.9299430847167969,
            -0.09832629561424255,
            3.947634220123291,
            -0.5432649850845337,
            1.8704593181610107,
            -6.308472633361816,
            -5.28434944152832,
            0.6064085960388184,
            3.697728157043457,
            -5.151659965515137,
            0.07114499807357788,
            2.739192485809326,
            0.6456761360168457,
            2.3315749168395996,
            2.308748483657837,
            2.675243377685547,
            1.7689902782440186,
            4.800714492797852,
            4.536921501159668,
            -1.9427425861358643,
            -0.5269470810890198,
            -2.196051597595215,
            -5.412528038024902,
            0.5257740020751953,
            4.471144676208496,
            0.05891767144203186,
            3.264650344848633,
            -3.84169340133667,
            1.5217998027801514,
            -0.007828056812286377,
            -4.223899841308594,
            8.141372680664062,
            4.461478233337402,
            0.8904684782028198,
            -4.954019069671631,
            -0.8339529037475586,
            -0.9792705774307251,
            2.190685272216797,
            -6.174890518188477,
            3.639341354370117,
            -0.6237943172454834,
            2.663921594619751,
            3.180593490600586,
            -2.6489078998565674,
            -0.3047458827495575,
            0.8759162425994873,
            -2.2855682373046875,
            -1.3197455406188965,
            -1.3473812341690063,
            2.4363598823547363,
            0.8641318082809448,
            0.2631745934486389,
            -3.721755027770996,
            2.2604026794433594,
            2.808253526687622,
            4.934070587158203,
            5.594333171844482,
            3.3181538581848145,
            3.32529354095459,
            -3.772351026535034,
            0.07988891005516052,
            -3.4113669395446777,
            2.343407154083252,
            5.817784786224365,
            -5.120764255523682,
            -0.40771427750587463,
            -2.109539270401001,
            0.37404611706733704,
            1.7474232912063599,
            4.8652496337890625,
            -1.1433422565460205,
            3.827855348587036,
            -4.445342063903809,
            -1.8711295127868652,
            -3.261840343475342,
            0.24816754460334778,
            1.5622210502624512,
            -4.466924667358398,
            2.278566598892212,
            0.17902570962905884,
            -4.422294616699219,
            -1.0183093547821045,
            -1.6201975345611572,
            -1.870813012123108,
            -0.6524296998977661,
            1.2192602157592773,
            1.9358903169631958,
            -3.350266456604004,
            0.7686183452606201,
            2.2218260765075684,
            -0.9047132730484009,
            -1.1298248767852783,
            -6.083638668060303,
            3.9194588661193848,
            1.055739402770996,
            -0.8413524627685547,
            0.8423730134963989,
            -5.169098854064941,
            0.8002629280090332,
            1.6689802408218384,
            2.2727160453796387,
            2.1450772285461426,
            4.211679458618164,
            2.1684772968292236,
            -1.0693411827087402,
            -0.4982471168041229,
            -1.9997378587722778,
            -1.7356579303741455,
            -2.588639497756958,
            -5.579596519470215,
            0.13125571608543396,
            -3.235175132751465,
            -3.0614993572235107,
            2.707719564437866,
            -6.0573554039001465,
            1.6998398303985596,
            4.833006858825684,
            -4.8769683837890625,
            -0.4828874468803406,
            -2.4785518646240234,
            2.420060634613037,
            -3.2269725799560547,
            0.9636414647102356,
            0.607597827911377,
            0.5085360407829285,
            1.139312744140625,
            1.2065714597702026,
            3.8077034950256348,
            1.1394939422607422,
            3.0976357460021973,
            -4.594827175140381,
            -2.3081858158111572,
            1.8001136779785156,
            -1.462551236152649,
            -1.110350489616394,
            -1.5357098579406738,
            -0.10751807689666748,
            0.5619333982467651,
            18.833999633789062,
            -2.8611629009246826,
            0.6395260095596313,
            -0.06365963816642761,
            -0.43787771463394165,
            -4.360702037811279,
            -3.3309803009033203,
            2.99800968170166,
            1.6520148515701294,
            -0.2858496904373169,
            -0.5914633870124817,
            -3.025212287902832,
            -1.592106819152832,
            1.2761867046356201,
            0.610077977180481,
            1.254906177520752,
            -0.7205625176429749,
            1.006284475326538,
            -2.7162299156188965,
            0.8386406898498535,
            1.0151618719100952,
            -0.26973995566368103,
            0.13675421476364136,
            -4.212132930755615,
            -0.695820152759552,
            2.88179087638855,
            -0.33713576197624207,
            2.4963057041168213,
            -4.410988807678223,
            1.350478172302246,
            0.7988154888153076,
            4.123603343963623,
            -2.383838415145874,
            1.9168260097503662,
            0.26113051176071167,
            3.198838710784912,
            4.164190292358398,
            -1.3276119232177734,
            4.055389881134033,
            2.6238279342651367,
            -0.8295576572418213,
            1.9930405616760254,
            -1.0711692571640015,
            3.0398411750793457,
            -3.6692395210266113,
            -0.7388954162597656,
            3.525686502456665,
            -1.2378984689712524,
            -1.8375424146652222,
            4.1733479499816895,
            -1.4289255142211914,
            0.36348164081573486,
            1.1868963241577148,
            1.3354175090789795,
            -0.04259461164474487,
            -0.5861687660217285,
            0.8415361046791077,
            -1.9574828147888184,
            2.8047847747802734,
            2.9565672874450684,
            -0.9770140051841736,
            -0.8211316466331482,
            -2.1928887367248535,
            -2.378119468688965,
            -2.818136692047119,
            1.6575136184692383,
            -4.856168746948242,
            1.1961926221847534,
            2.063652276992798,
            2.9603638648986816,
            2.761603355407715,
            1.624253273010254,
            -1.8257158994674683,
            0.21926385164260864,
            -0.5468239784240723,
            -6.404982566833496,
            0.842030942440033,
            -0.9443421959877014,
            -1.7280068397521973,
            5.5300679206848145,
            -4.208246231079102,
            3.1135973930358887,
            -1.9518487453460693,
            -2.035501003265381,
            5.192068099975586,
            -2.559828281402588,
            3.388369560241699,
            -0.5941469669342041,
            -3.8866114616394043,
            4.508300304412842,
            -1.9310517311096191,
            -0.9915841817855835,
            3.949472427368164,
            5.210567474365234,
            1.6745184659957886,
            -5.231110095977783,
            -1.1809114217758179,
            -0.8328672647476196,
            -0.9789465665817261,
            -3.6820058822631836,
            4.065681457519531,
            4.061240196228027,
            1.249110221862793,
            -4.9256439208984375,
            -1.6511712074279785,
            2.3793230056762695,
            -2.3560287952423096,
            -6.4237165451049805,
            -4.536160469055176,
            -0.5603386163711548,
            4.971473217010498,
            0.18423974514007568,
            1.041062593460083,
            2.332699775695801,
            1.2065156698226929,
            -1.9414831399917603,
            1.9537575244903564,
            1.0658904314041138,
            1.2191938161849976,
            5.924979209899902,
            0.5885118246078491,
            -0.6734319925308228,
            -0.8530951142311096,
            -4.059162139892578,
            1.0054336786270142,
            -0.6061356067657471,
            -0.1538301408290863,
            -1.9883943796157837,
            -2.1847963333129883,
            0.3727138340473175,
            1.8448660373687744,
            0.3819241523742676,
            -1.8246922492980957,
            -0.393857479095459,
            0.029707103967666626,
            -0.8272253274917603,
            0.09498918056488037,
            2.154759407043457,
            0.6587578654289246,
            3.2765471935272217,
            -0.4216066002845764,
            -2.519451141357422,
            -4.692086219787598,
            10.446884155273438,
            0.23390257358551025,
            -1.1827741861343384,
            -1.3647016286849976,
            -2.4315500259399414,
            -0.6096893548965454,
            1.4571903944015503,
            2.0629656314849854,
            -1.7328011989593506,
            -0.20407791435718536,
            -0.5391194820404053,
            -2.829895496368408,
            -1.3364063501358032
        ]
    },
    "authors": [
        {
            "authorId": "2316676258",
            "name": "Zhongyu Zhao"
        },
        {
            "authorId": "2316639620",
            "name": "Menghang Dong"
        },
        {
            "authorId": "2268799823",
            "name": "Rongyu Zhang"
        },
        {
            "authorId": "2284684917",
            "name": "Wenzhao Zheng"
        },
        {
            "authorId": "2317039865",
            "name": "Yunpeng Zhang"
        },
        {
            "authorId": "2273577170",
            "name": "Huanrui Yang"
        },
        {
            "authorId": "2258959116",
            "name": "Dalong Du"
        },
        {
            "authorId": "2242659602",
            "name": "Kurt Keutzer"
        },
        {
            "authorId": "2273481225",
            "name": "Shanghang Zhang"
        }
    ],
    "references": [
        {
            "paperId": "c46da0df8ba53215bbf9922bc1fcd77236c0be54",
            "title": "Decomposing the Neurons: Activation Sparsity via Mixture of Experts for Continual Test Time Adaptation"
        },
        {
            "paperId": "765beb86fe9c0765ab61202015a684e30f9aa56b",
            "title": "Intuition-aware Mixture-of-Rank-1-Experts for Parameter Efficient Finetuning"
        },
        {
            "paperId": "ccd7a751d0735357f75ed89dc92df279bc02a572",
            "title": "Efficient Deweahter Mixture-of-Experts with Uncertainty-Aware Feature-Wise Linear Modulation"
        },
        {
            "paperId": "4706711dc4e1e16424db9f454a1f3b092b972785",
            "title": "SVD-LLM: Truncation-aware Singular Value Decomposition for Large Language Model Compression"
        },
        {
            "paperId": "2330035c7586a0dc0b1f09e9c00106b295acf543",
            "title": "Long-Context Language Modeling with Parallel Context Encoding"
        },
        {
            "paperId": "af6aa336c25ead669da0df560376a32314e08006",
            "title": "MoELoRA: Contrastive Learning Guided Mixture of Experts on Parameter-Efficient Fine-Tuning for Large Language Models"
        },
        {
            "paperId": "a091bf215c716a146140f81c751712db628c8e20",
            "title": "MobileVLM V2: Faster and Stronger Baseline for Vision Language Model"
        },
        {
            "paperId": "49b7baceecd32f81a08aa8e84e2fe71c2b879ee6",
            "title": "DistiLLM: Towards Streamlined Distillation for Large Language Models"
        },
        {
            "paperId": "5851121df5ce46be5faea265c868ec0beabfce96",
            "title": "Efficient Large Language Models: A Survey"
        },
        {
            "paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082",
            "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"
        },
        {
            "paperId": "95240dda409e28acccdc5cf619ad0c036cf4292d",
            "title": "Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time"
        },
        {
            "paperId": "4880ba8910bc320cb7c1aa943992a500f4c41f07",
            "title": "Dynamic Sparse No Training: Training-Free Fine-tuning for Sparse LLMs"
        },
        {
            "paperId": "188336f606e76fda9e219b954d1750ad26646fdb",
            "title": "ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models"
        },
        {
            "paperId": "4bba7619886dd031e76d6cd442f080c28bb340b5",
            "title": "The growing energy footprint of artificial intelligence"
        },
        {
            "paperId": "5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0",
            "title": "Qwen Technical Report"
        },
        {
            "paperId": "4ea8e22236681a09225ee3f8ff5fffd934ec9bae",
            "title": "From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference"
        },
        {
            "paperId": "eb2c2330177f765038a2b17e2ee3498965865797",
            "title": "OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models"
        },
        {
            "paperId": "338d8f3b199abcebc85f34016b0162ab3a9d5310",
            "title": "A Survey on Model Compression for Large Language Models"
        },
        {
            "paperId": "88cba3a919aa10c18f42ccbf2bab753c17b3d947",
            "title": "Fly-Swat or Cannon? Cost-Effective Language Model Choice via Meta-Modeling"
        },
        {
            "paperId": "d62c4d00b277e948956b6610ce2644e88fe1577b",
            "title": "Large Language Models"
        },
        {
            "paperId": "ed2db05074b86da6fbcb01b45bd0f1693baa93c4",
            "title": "Reducing the Carbon Impact of Generative AI Inference (today and in 2035)"
        },
        {
            "paperId": "c12db2c60e8989f646a29ad4f4d24475e860ad91",
            "title": "LongNet: Scaling Transformers to 1, 000, 000, 000 Tokens"
        },
        {
            "paperId": "af67be0fff8d087a0d8554b6e8998ab12409bbda",
            "title": "TensorGPT: Efficient Compression of the Embedding Layer in LLMs based on the Tensor-Train Decomposition"
        },
        {
            "paperId": "7d22ad3573101337bca2091fb0114b377c4f3db6",
            "title": "A Simple and Effective Pruning Approach for Large Language Models"
        },
        {
            "paperId": "bc8428e270a5474cabfaff578d44955f757ccacd",
            "title": "LoSparse: Structured Compression of Large Language Models based on Low-Rank and Sparse Approximation"
        },
        {
            "paperId": "aad167be3c902388ea625da4117fcae4325b8b7d",
            "title": "Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes"
        },
        {
            "paperId": "02a3e009d1b6b0489a1bc204edff906d33e3a8b2",
            "title": "Unimodal Training-Multimodal Prediction: Cross-modal Federated Learning with Hierarchical Aggregation"
        },
        {
            "paperId": "57e849d0de13ed5f91d086936296721d4ff75a75",
            "title": "LLaMA: Open and Efficient Foundation Language Models"
        },
        {
            "paperId": "ac608a4a6b19b3208e560eee5daadb3cc18638a2",
            "title": "Efficient Attention via Control Variates"
        },
        {
            "paperId": "909ad57ce8caa6b390a65ae09db352d27d8f3996",
            "title": "SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot"
        },
        {
            "paperId": "8fd462f6248d5e3f1b6602697c09489086b5655f",
            "title": "Distilling Reasoning Capabilities into Smaller Language Models"
        },
        {
            "paperId": "3820231d31540ecb05d94c74d959a2f61d3136ea",
            "title": "Mixture of Attention Heads: Selecting Attention Heads Per Token"
        },
        {
            "paperId": "5dca8e6a7d4657bf65a3ecf215fd5dfeb16cd255",
            "title": "Factorizing Knowledge in Neural Networks"
        },
        {
            "paperId": "d151ced8700d84a2efe411a234a4cb2c595e8ca9",
            "title": "Language model compression with weighted low-rank factorization"
        },
        {
            "paperId": "03d19fde1df67c7ea8dedc750dcd3a6291032577",
            "title": "Parameter-Efficient Sparsity for Large Language Models Fine-Tuning"
        },
        {
            "paperId": "1944cebf4e41a10ea7bd02ce30404c18c9c4e04f",
            "title": "Linear Complexity Randomized Self-attention Mechanism"
        },
        {
            "paperId": "80d0116d77beeded0c23cf48946d9d10d4faee14",
            "title": "GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"
        },
        {
            "paperId": "4a247cbfca9dcf91e2da24e6d2d84601a9041a8f",
            "title": "Do Language Models Have Beliefs? Methods for Detecting, Updating, and Visualizing Model Beliefs"
        },
        {
            "paperId": "561f9f5abb2c0960a886ab6221c821295f0461a1",
            "title": "MoEfication: Transformer Feed-forward Layers are Mixtures of Experts"
        },
        {
            "paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092",
            "title": "LoRA: Low-Rank Adaptation of Large Language Models"
        },
        {
            "paperId": "2c871df72c52b58f05447fcb3afc838168d94505",
            "title": "Knowledge Neurons in Pretrained Transformers"
        },
        {
            "paperId": "240b0caabb415578bdea4da7d0a32bdff2e8163f",
            "title": "Editing Factual Knowledge in Language Models"
        },
        {
            "paperId": "7e5008713c404445dd8786753526f1a45b93de12",
            "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow"
        },
        {
            "paperId": "fdacf2a732f55befdc410ea927091cad3b791f13",
            "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"
        },
        {
            "paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e",
            "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"
        },
        {
            "paperId": "4a54d58a4b20e4f3af25cea3c188a12082a95e02",
            "title": "Transformer Feed-Forward Layers Are Key-Value Memories"
        },
        {
            "paperId": "5270b626feb66c8c363e93ba6608daae93c5003b",
            "title": "Modifying Memories in Transformer Models"
        },
        {
            "paperId": "f30444fbb6ad806168e2564db4815cd27faa7fd9",
            "title": "It\u2019s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners"
        },
        {
            "paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678",
            "title": "Measuring Massive Multitask Language Understanding"
        },
        {
            "paperId": "1882f194cb43828852cc052887671e55a80f945a",
            "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "e165b379f983152874299e0f5a6e0c9596c9a3e8",
            "title": "Editable Neural Networks"
        },
        {
            "paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2",
            "title": "Scaling Laws for Neural Language Models"
        },
        {
            "paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45",
            "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"
        },
        {
            "paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
        },
        {
            "paperId": "9770fff7379a7ab9006b48939462354dda9a2053",
            "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"
        },
        {
            "paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad",
            "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"
        },
        {
            "paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c",
            "title": "Parameter-Efficient Transfer Learning for NLP"
        },
        {
            "paperId": "1536e8958697c5364f68b2e2448905dbbeb3a0ca",
            "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering"
        },
        {
            "paperId": "88bb0a28bb58d847183ec505dda89b63771bb495",
            "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"
        },
        {
            "paperId": "906a02507db6e5f7f2c6fb27dee0ec024eb4e5d7",
            "title": "Segregated Systems of Human Brain Networks"
        },
        {
            "paperId": "b587ee7c802a5bd222a69090f59285e0dfdb29f1",
            "title": "Sigmoid-Weighted Linear Units for Neural Network Function Approximation in Reinforcement Learning"
        },
        {
            "paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586",
            "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"
        },
        {
            "paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19",
            "title": "Distilling the Knowledge in a Neural Network"
        },
        {
            "paperId": "72d32c986b47d6b880dad0c3f155fe23d2939038",
            "title": "Deep Learning of Representations: Looking Forward"
        },
        {
            "paperId": "d431ec4483c56795e5ce896a6506aa59772e21d6",
            "title": "Network attributes for segregation and integration in the human brain"
        },
        {
            "paperId": "21ae8c524da3f1f5ea9660d7eb53329c21b18848",
            "title": "Segregation of cognitive and emotional function in the prefrontal cortex: a stereotactic meta-analysis"
        },
        {
            "paperId": "36e0b957b1a64bcc26bf8038e06e83122aec5a2a",
            "title": "Plug-and-Play: An Efficient Post-training Pruning Method for Large Language Models"
        },
        {
            "paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28",
            "title": "An Adversarial Winograd Schema Challenge at Scale"
        },
        {
            "paperId": "9405cc0d6169988371b2755e573cc28650d14dfe",
            "title": "Language Models are Unsupervised Multitask Learners"
        },
        {
            "paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "title": "Improving Language Understanding by Generative Pre-Training"
        },
        {
            "paperId": null,
            "title": "A method for stochastic optimization"
        },
        {
            "paperId": null,
            "title": "Locating and editing factual associations"
        },
        {
            "paperId": null,
            "title": "and efficient low-bitwidth quantization"
        },
        {
            "paperId": null,
            "title": "GPTQ: Accurate post-training compression for generative pretrained transformers"
        },
        {
            "paperId": null,
            "title": "on multilingual"
        },
        {
            "paperId": null,
            "title": "Phi-2 model card"
        },
        {
            "paperId": null,
            "title": "AI@Meta"
        },
        {
            "paperId": null,
            "title": ": Improving large language model quantization by keeping pivot tokens"
        },
        {
            "paperId": null,
            "title": "SlimPajama: A 627B token cleaned and deduplicated version of RedPajama"
        }
    ]
}