{
    "paperId": "7112d579583ce8c82acfc88cbfde2698df2925e5",
    "externalIds": {
        "ArXiv": "2407.10704",
        "DBLP": "journals/corr/abs-2407-10704",
        "DOI": "10.48550/arXiv.2407.10704",
        "CorpusId": 271212850
    },
    "title": "Quantized Prompt for Efficient Generalization of Vision-Language Models",
    "abstract": "In the past few years, large-scale pre-trained vision-language models like CLIP have achieved tremendous success in various fields. Naturally, how to transfer the rich knowledge in such huge pre-trained models to downstream tasks and datasets becomes a hot topic. During downstream adaptation, the most challenging problems are overfitting and catastrophic forgetting, which can cause the model to overly focus on the current data and lose more crucial domain-general knowledge. Existing works use classic regularization techniques to solve the problems. As solutions become increasingly complex, the ever-growing storage and inference costs are also a significant problem that urgently needs to be addressed. While in this paper, we start from an observation that proper random noise can suppress overfitting and catastrophic forgetting. Then we regard quantization error as a kind of noise, and explore quantization for regularizing vision-language model, which is quite efficiency and effective. Furthermore, to improve the model's generalization capability while maintaining its specialization capacity at minimal cost, we deeply analyze the characteristics of the weight distribution in prompts, conclude several principles for quantization module design and follow such principles to create several competitive baselines. The proposed method is significantly efficient due to its inherent lightweight nature, making it possible to adapt on extremely resource-limited devices. Our method can be fruitfully integrated into many existing approaches like MaPLe, enhancing accuracy while reducing storage overhead, making it more powerful yet versatile. Extensive experiments on 11 datasets shows great superiority of our method sufficiently. Code is available at https://github.com/beyondhtx/QPrompt.",
    "venue": "arXiv.org",
    "year": 2024,
    "referenceCount": 80,
    "citationCount": 2,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "To improve the model's generalization capability while maintaining its specialization capacity at minimal cost, to improve the model's generalization capability while maintaining its specialization capacity at minimal cost, the characteristics of the weight distribution in prompts are analyzed, and several principles for quantization module design are concluded."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -4.524076461791992,
            -2.3287088871002197,
            2.153634786605835,
            5.750065803527832,
            0.22869887948036194,
            1.4056721925735474,
            4.5493245124816895,
            -1.900611400604248,
            -1.3475254774093628,
            -0.6145507097244263,
            -3.094231128692627,
            6.249272346496582,
            -2.4677817821502686,
            2.2732672691345215,
            -4.459987163543701,
            0.8362728357315063,
            0.46900758147239685,
            -0.429044246673584,
            6.657344818115234,
            0.35248687863349915,
            -3.1411237716674805,
            0.7986859679222107,
            -1.8061732053756714,
            -1.8221672773361206,
            -3.5951528549194336,
            -0.8092480301856995,
            0.5613189339637756,
            2.7020673751831055,
            -2.2244720458984375,
            -0.4954602122306824,
            0.6914333701133728,
            -3.880657196044922,
            2.4794998168945312,
            -3.416691780090332,
            2.3227639198303223,
            -0.7319509983062744,
            -0.6145365238189697,
            8.17883014678955,
            -3.313540458679199,
            -0.623278796672821,
            -0.041381776332855225,
            0.09421145915985107,
            2.429326057434082,
            0.263592392206192,
            0.03655040264129639,
            -0.2984294891357422,
            0.6058357954025269,
            0.537760853767395,
            -0.6708961725234985,
            0.8402701616287231,
            1.4034078121185303,
            1.4814558029174805,
            -1.0836172103881836,
            1.8400503396987915,
            -1.390929937362671,
            -2.3955397605895996,
            -0.446596622467041,
            3.0293128490448,
            0.6352629661560059,
            -3.462514877319336,
            4.134917259216309,
            4.879634857177734,
            -0.7670038342475891,
            1.9635982513427734,
            4.688899517059326,
            -5.437938213348389,
            -1.4562005996704102,
            4.72288703918457,
            2.407741069793701,
            1.2933666706085205,
            0.9701989889144897,
            -5.486885070800781,
            1.055881142616272,
            1.484143853187561,
            -2.0217361450195312,
            -1.1808446645736694,
            1.4486345052719116,
            -7.708578586578369,
            -2.875746250152588,
            -2.3166582584381104,
            -0.4934728741645813,
            3.1861772537231445,
            0.3752008080482483,
            3.8466789722442627,
            2.709656238555908,
            0.5411295890808105,
            -3.907653570175171,
            0.1631615161895752,
            -0.49995458126068115,
            -2.334451675415039,
            0.08745604753494263,
            -0.5503281950950623,
            1.0268375873565674,
            1.934746265411377,
            -6.437982559204102,
            0.38848644495010376,
            0.7429715991020203,
            -1.49820876121521,
            -4.497934341430664,
            1.2408969402313232,
            4.253617763519287,
            0.049919068813323975,
            1.9457974433898926,
            0.9289069175720215,
            3.226567268371582,
            -5.661489486694336,
            0.8585549592971802,
            1.9697152376174927,
            1.6682312488555908,
            -1.4861797094345093,
            -4.074790954589844,
            2.043186664581299,
            -2.053213596343994,
            -2.4615464210510254,
            -0.7756144404411316,
            -1.588538408279419,
            -1.4357328414916992,
            4.3913068771362305,
            -3.346017599105835,
            2.301363706588745,
            -0.5472373962402344,
            -0.21245744824409485,
            -3.072767972946167,
            0.4579237699508667,
            2.552661180496216,
            3.2329068183898926,
            -0.4758788049221039,
            3.079329490661621,
            0.9678627848625183,
            -4.107639312744141,
            4.125036239624023,
            -2.830899715423584,
            4.655664443969727,
            -1.7768585681915283,
            3.64556884765625,
            3.586338996887207,
            -2.120887041091919,
            1.4497294425964355,
            -0.22005650401115417,
            -0.10488994419574738,
            0.028615660965442657,
            1.6182578802108765,
            -1.3441931009292603,
            -1.0855183601379395,
            2.6982107162475586,
            1.3260388374328613,
            -1.0394716262817383,
            2.3534724712371826,
            3.3293709754943848,
            7.541144847869873,
            3.288698673248291,
            -7.096585750579834,
            0.07506453990936279,
            2.0641984939575195,
            1.8973217010498047,
            4.690128326416016,
            -6.315323352813721,
            2.9224228858947754,
            -2.4689524173736572,
            0.523017406463623,
            -0.39173394441604614,
            -1.9678157567977905,
            -10.311091423034668,
            -0.16858918964862823,
            4.218718528747559,
            -5.026091575622559,
            -2.4711151123046875,
            2.1149089336395264,
            -2.0217533111572266,
            3.4974365234375,
            0.24892225861549377,
            1.7935551404953003,
            0.6492133140563965,
            5.474546909332275,
            1.6483913660049438,
            6.809103488922119,
            2.63804292678833,
            -1.7775150537490845,
            -1.0958614349365234,
            -0.1654352843761444,
            -3.560591697692871,
            -4.90415096282959,
            -9.617715835571289,
            -0.680133581161499,
            -5.845734596252441,
            -1.9010038375854492,
            -2.7637720108032227,
            0.36254364252090454,
            0.7390854358673096,
            -2.359621286392212,
            -0.8896298408508301,
            -1.1943227052688599,
            6.756763458251953,
            7.658918380737305,
            3.761944055557251,
            0.10579705238342285,
            2.529301166534424,
            4.965880870819092,
            -2.6410694122314453,
            1.7077994346618652,
            3.2254741191864014,
            -0.3854491114616394,
            -1.4904142618179321,
            -1.5667192935943604,
            5.626458168029785,
            1.7441275119781494,
            -4.484775543212891,
            3.263448715209961,
            4.524738311767578,
            0.5105066299438477,
            -1.6409361362457275,
            -0.08592355251312256,
            -3.842175245285034,
            2.934553623199463,
            -1.6626746654510498,
            -1.0138472318649292,
            -6.667726516723633,
            2.4780306816101074,
            4.537385940551758,
            1.312203049659729,
            -1.0114489793777466,
            -0.6921038031578064,
            -0.9323915243148804,
            -0.578044056892395,
            2.493663787841797,
            -5.204555988311768,
            3.420013904571533,
            1.2196283340454102,
            -0.8246757388114929,
            1.8511791229248047,
            -0.626379668712616,
            -5.003942012786865,
            2.6009199619293213,
            -0.2767775356769562,
            -8.873859405517578,
            -1.3219183683395386,
            -2.86509108543396,
            2.029470920562744,
            -2.402470111846924,
            -4.149175643920898,
            6.742973327636719,
            2.8893914222717285,
            3.1616458892822266,
            4.579516887664795,
            1.915382981300354,
            -1.9062288999557495,
            -4.608372688293457,
            1.0980987548828125,
            -1.158374547958374,
            -2.422041893005371,
            -1.6161836385726929,
            0.42449718713760376,
            -0.3297247290611267,
            0.21657826006412506,
            1.862432837486267,
            1.2600982189178467,
            1.701049566268921,
            -0.8703889846801758,
            -0.08473342657089233,
            0.6476864218711853,
            2.5041568279266357,
            4.922782897949219,
            1.7121752500534058,
            5.32521915435791,
            -1.071052074432373,
            -2.9843215942382812,
            -2.028467893600464,
            -0.5870206952095032,
            -1.4194308519363403,
            4.297089576721191,
            1.3619484901428223,
            -0.2479371726512909,
            0.3644883334636688,
            -4.112427234649658,
            -4.851201057434082,
            -4.452313423156738,
            -3.4222798347473145,
            1.1683783531188965,
            4.881279945373535,
            3.035227060317993,
            1.037336826324463,
            -1.0086976289749146,
            0.33509761095046997,
            -2.4707913398742676,
            -2.4547929763793945,
            -4.591729164123535,
            -3.4878835678100586,
            -0.4126560091972351,
            -2.9581713676452637,
            -4.251896381378174,
            -3.417203664779663,
            5.247754096984863,
            -4.429238319396973,
            0.136761873960495,
            -2.938692331314087,
            1.1808679103851318,
            4.126348495483398,
            -3.3350000381469727,
            2.1310532093048096,
            -1.298429250717163,
            1.5517323017120361,
            2.6640567779541016,
            5.087616920471191,
            -1.2459306716918945,
            1.9260523319244385,
            3.304105043411255,
            0.1180962324142456,
            -2.230508327484131,
            1.785561203956604,
            -5.225970268249512,
            -1.086241364479065,
            0.015872597694396973,
            3.527773857116699,
            -5.957979202270508,
            1.9553838968276978,
            0.6037386655807495,
            1.7082189321517944,
            -3.408094644546509,
            -0.9178591966629028,
            2.4580764770507812,
            0.8632957935333252,
            1.4381072521209717,
            -3.5843963623046875,
            -0.5168629288673401,
            -2.3117313385009766,
            -0.7840333580970764,
            4.157729625701904,
            2.138371706008911,
            -3.5689520835876465,
            4.586182594299316,
            0.5852844715118408,
            5.86128568649292,
            4.569835662841797,
            3.0157999992370605,
            -0.053501904010772705,
            -6.973124027252197,
            -0.36804360151290894,
            0.006558537483215332,
            3.01155424118042,
            -0.19169732928276062,
            -1.0209839344024658,
            4.981997966766357,
            -0.5003549456596375,
            1.159139633178711,
            0.905673086643219,
            -0.1740865260362625,
            3.1132779121398926,
            -1.3973617553710938,
            -0.6841939687728882,
            -3.617755889892578,
            -2.053542137145996,
            2.1819522380828857,
            3.9373984336853027,
            -0.9898700714111328,
            3.4335036277770996,
            1.8497202396392822,
            2.6611125469207764,
            0.734372079372406,
            1.2378638982772827,
            2.859592914581299,
            1.1559923887252808,
            -1.0393282175064087,
            3.3135266304016113,
            -1.2061710357666016,
            -3.1325182914733887,
            -3.4218955039978027,
            10.455621719360352,
            1.3544895648956299,
            -2.5613608360290527,
            -4.283515453338623,
            -1.9596049785614014,
            -2.334421157836914,
            -2.238588809967041,
            4.436240196228027,
            -2.100076198577881,
            -0.9836149215698242,
            1.4644825458526611,
            -5.738277435302734,
            2.9619040489196777,
            2.71281361579895,
            -1.2120596170425415,
            4.444764614105225,
            -2.0297417640686035,
            2.6835203170776367,
            -1.5550248622894287,
            -0.236965149641037,
            -4.898531436920166,
            2.9217495918273926,
            0.5658809542655945,
            0.6510621905326843,
            -1.9954544305801392,
            0.9414489269256592,
            2.3185794353485107,
            0.5504012703895569,
            -6.193323135375977,
            -3.449388265609741,
            -2.9237890243530273,
            -5.7536725997924805,
            0.1733212172985077,
            -0.03592700511217117,
            1.292814016342163,
            3.794116973876953,
            2.9061245918273926,
            1.778698444366455,
            -4.459235668182373,
            -2.132464647293091,
            5.195981025695801,
            -0.9659709334373474,
            -2.1622140407562256,
            1.5830538272857666,
            -3.3370964527130127,
            -4.7926859855651855,
            -0.5723527669906616,
            -4.666515350341797,
            1.3090755939483643,
            -0.4980223774909973,
            2.444934368133545,
            2.7923457622528076,
            4.5564470291137695,
            2.9258289337158203,
            -2.9894514083862305,
            6.420632362365723,
            4.57583475112915,
            3.69411039352417,
            -0.5338765382766724,
            1.045001745223999,
            2.8037238121032715,
            1.8587021827697754,
            -4.358501434326172,
            2.4506545066833496,
            -4.070024490356445,
            5.085169315338135,
            -5.1232757568359375,
            -0.5940183401107788,
            0.09078019857406616,
            2.275709390640259,
            1.905307412147522,
            2.1245357990264893,
            2.450626850128174,
            -1.168076753616333,
            0.6819580793380737,
            3.6535401344299316,
            -3.8069417476654053,
            6.250244140625,
            -0.17638394236564636,
            2.3637166023254395,
            1.7402796745300293,
            2.086019992828369,
            -0.42521920800209045,
            -3.2866013050079346,
            3.4006919860839844,
            -1.0959951877593994,
            -2.256244659423828,
            -0.9757571220397949,
            -0.1946789026260376,
            1.7798112630844116,
            -2.637868881225586,
            -0.5501132607460022,
            1.021277666091919,
            -1.1529443264007568,
            -3.62117600440979,
            2.924147605895996,
            0.5597314238548279,
            0.4623168706893921,
            0.2507118582725525,
            3.557356357574463,
            -1.3976953029632568,
            -0.7840412855148315,
            -2.2756965160369873,
            1.0126339197158813,
            3.4761364459991455,
            0.15448635816574097,
            -3.5386815071105957,
            0.6766420006752014,
            -2.1017825603485107,
            -0.08654001355171204,
            4.732909202575684,
            1.6569451093673706,
            0.7460469007492065,
            -7.221353530883789,
            -2.94753360748291,
            -0.7289788722991943,
            5.347014427185059,
            -2.853878974914551,
            -3.4370763301849365,
            4.192957878112793,
            3.1957736015319824,
            4.504410743713379,
            4.506062984466553,
            2.3834266662597656,
            0.9037009477615356,
            1.9537007808685303,
            4.340460300445557,
            2.792100429534912,
            1.0048904418945312,
            -2.072425603866577,
            -5.4916181564331055,
            2.2096548080444336,
            1.2819950580596924,
            -0.15835821628570557,
            0.5715766549110413,
            -1.8002787828445435,
            -0.2545422911643982,
            -1.2228741645812988,
            -2.2183146476745605,
            6.2313232421875,
            2.1269824504852295,
            1.109011173248291,
            -3.2771975994110107,
            -4.46591854095459,
            -1.1793205738067627,
            1.7423934936523438,
            -7.599483489990234,
            1.4848425388336182,
            -1.4355313777923584,
            2.339937686920166,
            2.406930446624756,
            -3.562237024307251,
            -1.6859426498413086,
            1.4217627048492432,
            0.5797067880630493,
            0.05832207202911377,
            -0.36498138308525085,
            5.120638370513916,
            2.7877604961395264,
            -1.2914458513259888,
            -5.048349380493164,
            -0.8430917263031006,
            2.4434547424316406,
            7.379072189331055,
            6.265634536743164,
            3.4383015632629395,
            4.608207702636719,
            -4.233731746673584,
            0.40354272723197937,
            -0.7120020389556885,
            1.173231840133667,
            2.970433235168457,
            -2.8840346336364746,
            0.48793545365333557,
            0.4666061997413635,
            0.867355227470398,
            0.46978694200515747,
            3.716968536376953,
            -1.6086643934249878,
            4.029527187347412,
            -3.972205638885498,
            -1.3695576190948486,
            -2.733915090560913,
            2.071702003479004,
            -2.3676645755767822,
            0.35776713490486145,
            1.5246520042419434,
            0.6885771751403809,
            -2.76432728767395,
            -0.8824925422668457,
            -3.3468008041381836,
            -3.3977274894714355,
            -2.2239954471588135,
            0.6079350709915161,
            -0.17862468957901,
            0.04391711950302124,
            -0.7128534317016602,
            4.8262939453125,
            -1.2491848468780518,
            -2.193993330001831,
            -1.634661316871643,
            3.8228018283843994,
            -0.57304447889328,
            -1.7919615507125854,
            0.32540297508239746,
            -4.738446235656738,
            -3.0454230308532715,
            0.5572307705879211,
            2.200706720352173,
            4.051361083984375,
            4.916898727416992,
            2.317368507385254,
            -3.888716459274292,
            -2.149994373321533,
            -1.4399091005325317,
            -0.5953563451766968,
            -4.771481513977051,
            -2.6400976181030273,
            0.43933987617492676,
            -4.023293495178223,
            -2.3589961528778076,
            2.50126314163208,
            -3.9915170669555664,
            1.5476492643356323,
            3.070213794708252,
            -1.29475736618042,
            1.059662103652954,
            -4.166934013366699,
            0.5687084197998047,
            -3.2255098819732666,
            4.114651679992676,
            1.7585806846618652,
            -0.3350812792778015,
            4.464422225952148,
            2.8573591709136963,
            2.1777191162109375,
            5.464980125427246,
            2.883188247680664,
            -3.823808193206787,
            1.7482045888900757,
            2.7919387817382812,
            0.7073743939399719,
            -4.175412178039551,
            0.6615039110183716,
            0.13848161697387695,
            0.9490262866020203,
            18.43938636779785,
            2.3988842964172363,
            -1.3741029500961304,
            -1.8826391696929932,
            -1.9974678754806519,
            -3.0131421089172363,
            -0.09496788680553436,
            2.5113775730133057,
            -0.4582595229148865,
            1.542420744895935,
            -2.265591621398926,
            -3.823004961013794,
            -0.17026746273040771,
            1.4581310749053955,
            -5.152459144592285,
            -1.4550317525863647,
            -3.5414531230926514,
            1.6435749530792236,
            -1.6137467622756958,
            0.6762501001358032,
            -3.61447811126709,
            0.886733889579773,
            -2.630127191543579,
            -1.1553311347961426,
            -3.3986916542053223,
            1.2520740032196045,
            0.3479006290435791,
            1.3343346118927002,
            -6.475403785705566,
            2.0265913009643555,
            1.2429155111312866,
            -0.053680241107940674,
            0.6622675061225891,
            -0.009705543518066406,
            -3.1612157821655273,
            2.5478219985961914,
            5.154090881347656,
            -2.3254945278167725,
            3.0587966442108154,
            1.0723977088928223,
            -1.1102418899536133,
            0.6298466920852661,
            -4.936269760131836,
            1.5536836385726929,
            -3.0791285037994385,
            1.1852967739105225,
            3.228376865386963,
            -1.0962598323822021,
            0.4290982484817505,
            7.432991027832031,
            1.6069588661193848,
            2.3215065002441406,
            -2.4023566246032715,
            2.185854911804199,
            0.9037338495254517,
            3.523357391357422,
            -1.5595155954360962,
            -3.4822888374328613,
            1.8824577331542969,
            -2.58735990524292,
            1.3260846138000488,
            -0.9946672916412354,
            -2.4167871475219727,
            -4.877762794494629,
            0.37949714064598083,
            -0.6398628950119019,
            -5.596266269683838,
            5.417763710021973,
            1.2480888366699219,
            -1.1541889905929565,
            5.51872444152832,
            3.4478707313537598,
            -0.5768071413040161,
            -3.0656566619873047,
            -0.90842604637146,
            -5.249518394470215,
            1.516647458076477,
            2.7830469608306885,
            -0.5201764106750488,
            5.97761344909668,
            -3.33602237701416,
            3.4009761810302734,
            -3.0502448081970215,
            0.38762155175209045,
            5.874648094177246,
            -4.051999092102051,
            4.637177467346191,
            0.576816201210022,
            -0.7046880125999451,
            6.257308006286621,
            -0.3177967071533203,
            -0.9272836446762085,
            3.589539051055908,
            2.688138961791992,
            3.319650411605835,
            -6.858249664306641,
            -2.5940213203430176,
            -3.625333786010742,
            -5.5333428382873535,
            -4.267558574676514,
            6.098300457000732,
            1.7575643062591553,
            2.694063186645508,
            -3.2615535259246826,
            -0.31187695264816284,
            -0.438196063041687,
            -0.32269036769866943,
            -3.777695894241333,
            -3.5209741592407227,
            -1.8299129009246826,
            6.607468605041504,
            -3.1470675468444824,
            -1.9523614645004272,
            -0.963908314704895,
            2.1443543434143066,
            -2.5829830169677734,
            -1.3055578470230103,
            2.6573071479797363,
            0.5949079394340515,
            4.776817798614502,
            -1.0415465831756592,
            -0.8514694571495056,
            -3.612903356552124,
            -5.110494613647461,
            -2.204965353012085,
            1.2657588720321655,
            1.9425394535064697,
            -1.3835246562957764,
            -0.469319611787796,
            -1.8770906925201416,
            2.8126072883605957,
            -0.6886824369430542,
            0.12401781976222992,
            -0.3213241398334503,
            -3.3532843589782715,
            -2.3376712799072266,
            -0.8753929734230042,
            1.675710916519165,
            -2.149730682373047,
            3.8051745891571045,
            3.2905750274658203,
            -4.271175384521484,
            -3.951622486114502,
            7.979953765869141,
            -0.10183925181627274,
            0.33355557918548584,
            -1.6086785793304443,
            -2.4783010482788086,
            -5.45725679397583,
            0.021703869104385376,
            -0.3947620987892151,
            0.262985497713089,
            3.066403388977051,
            -2.9566617012023926,
            -4.037508487701416,
            -2.995732307434082
        ]
    },
    "authors": [
        {
            "authorId": "2275199190",
            "name": "Tianxiang Hao"
        },
        {
            "authorId": "4827513",
            "name": "Xiaohan Ding"
        },
        {
            "authorId": "2288216721",
            "name": "Juexiao Feng"
        },
        {
            "authorId": "2276446915",
            "name": "Yuhong Yang"
        },
        {
            "authorId": "2298921971",
            "name": "Hui Chen"
        },
        {
            "authorId": "2242661989",
            "name": "Guiguang Ding"
        }
    ],
    "references": [
        {
            "paperId": "ea2c010f24f955d63489408f1ba951b1b0cfdbd8",
            "title": "Learn from the Learnt: Source-Free Active Domain Adaptation via Contrastive Sampling and Visual Persistence"
        },
        {
            "paperId": "f3d7fdcdb1191a4a59e78f54d67fcd46a3462d2b",
            "title": "Temporal Scaling Law for Large Language Models"
        },
        {
            "paperId": "438825debb5f7c129b0bbc7e3b5c95606545f5f0",
            "title": "PYRA: Parallel Yielding Re-Activation for Training-Inference Efficient Task Adaptation"
        },
        {
            "paperId": "f7d06f44a15cb1e7f3bb7c50864a231e4f4982f1",
            "title": "One-dimensional Adapter to Rule Them All: Concepts, Diffusion Models and Erasing Applications"
        },
        {
            "paperId": "0b91501128547a26339218fd7df65eeb6b0081d6",
            "title": "Re-parameterized Low-rank Prompt: Generalize a Vision-Language Model within 0.5K Parameters"
        },
        {
            "paperId": "f196eb14ee08dae4a71b23752a21823c4b0e928a",
            "title": "Confidence-based Visual Dispersal for Few-shot Unsupervised Domain Adaptation"
        },
        {
            "paperId": "b0b237dd905f12b23e3fc48ac7139e275158a007",
            "title": "Read-only Prompt Optimization for Vision-Language Few-shot Learning"
        },
        {
            "paperId": "d0a70f8ff7b34b26e825f732fd31973c6f530d59",
            "title": "Revisiting the Parameter Efficiency of Adapters from the Perspective of Precision Redundancy"
        },
        {
            "paperId": "85980d2de95a38d910e02e9bf0092412ba98edad",
            "title": "Regularized Mask Tuning: Uncovering Hidden Knowledge in Pre-trained Vision-Language Models"
        },
        {
            "paperId": "c61171fa674ddb0cbd8f4fa6efab8d0bba2ca289",
            "title": "Self-regulating Prompts: Foundational Model Adaptation without Forgetting"
        },
        {
            "paperId": "a17d4a542bcdd1d5ade9b64cef093fa76437f96a",
            "title": "Consolidator: Mergeable Adapter with Grouped Connections for Visual Adaptation"
        },
        {
            "paperId": "88779e873b7ec860d6b6a4c2ddfc28dd67c86b67",
            "title": "Visual-Language Prompt Tuning with Knowledge-Guided Context Optimization"
        },
        {
            "paperId": "f7cd725e671b49bc86b39e1ecbea8fa9962b5dd5",
            "title": "Box-Level Active Detection"
        },
        {
            "paperId": "529ddd65f6c252aaea91d6a8e5b55b7bc3951841",
            "title": "RepQ-ViT: Scale Reparameterization for Post-Training Quantization of Vision Transformers"
        },
        {
            "paperId": "1dff6b1b35e2d45d4db57c8b4e4395486c3e365f",
            "title": "Token Merging: Your ViT But Faster"
        },
        {
            "paperId": "f0b31fdf53ad60df454afd4ec8633b3aeb347bff",
            "title": "Scaling & Shifting Your Features: A New Baseline for Efficient Model Tuning"
        },
        {
            "paperId": "dfdb2894d50e095ce97f994ed6cee38554c4c84f",
            "title": "Q-ViT: Accurate and Fully Quantized Low-bit Vision Transformer"
        },
        {
            "paperId": "0d0dbfb1b315a43216020abaf74d289456198219",
            "title": "MaPLe: Multi-modal Prompt Learning"
        },
        {
            "paperId": "96328033cd5fba1973c81fefc69a4f9f956985d2",
            "title": "LASP: Text-to-Text Optimization for Language-Aware Soft Prompting of Vision & Language Models"
        },
        {
            "paperId": "f5b1f09b456b262cdf3300bb834eb935cfc1097a",
            "title": "Multimodal Open-Vocabulary Video Classification via Pre-Trained Vision and Language Models"
        },
        {
            "paperId": "d3461268e1153b1abec8f999f6375378a33e0061",
            "title": "Bridging the Gap between Object and Image-level Representations for Open-Vocabulary Detection"
        },
        {
            "paperId": "3268da152f1149675b5f1cfd03f97026128b9e09",
            "title": "Neural Prompt Search"
        },
        {
            "paperId": "2fe2f849b94cf08b559226bc9d78adcaef5ef186",
            "title": "AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition"
        },
        {
            "paperId": "2d2396f56cb08051b811e00fa5d09a86503d00cd",
            "title": "PromptDet: Towards Open-Vocabulary Detection Using Uncurated Images"
        },
        {
            "paperId": "adb272fbdea3631059cf88ab764bb6c2ce29f965",
            "title": "Visual Prompt Tuning"
        },
        {
            "paperId": "403ad5d6e78fcf29f1ac526fbc9ff6cbfea555eb",
            "title": "Open-Vocabulary DETR with Conditional Matching"
        },
        {
            "paperId": "7a7a4f41f9ca5682b1444140799ca4dde44352f5",
            "title": "Overcoming Oscillations in Quantization-Aware Training"
        },
        {
            "paperId": "4c69fdca6e8a1f10871ab9dc47f62c81ba7ead4a",
            "title": "Unified Visual Transformer Compression"
        },
        {
            "paperId": "b879450f50a6113f44a5baf0bcd5b4331eeb7bbc",
            "title": "Conditional Prompt Learning for Vision-Language Models"
        },
        {
            "paperId": "cc9826c222ac1e81b4b374dd9e0df130f298b1e8",
            "title": "Language-driven Semantic Segmentation"
        },
        {
            "paperId": "e9581d9758062f76e029bd19a58c4ae976cfb414",
            "title": "SLIP: Self-supervision meets Language-Image Pre-training"
        },
        {
            "paperId": "e77c484af99fc1eb3d3c36699ac81822e98cb74d",
            "title": "Image Segmentation Using Text and Image Prompts"
        },
        {
            "paperId": "8cafa8545ac3d42854e70408d837ef8244d52544",
            "title": "Decoupling Zero-Shot Semantic Segmentation"
        },
        {
            "paperId": "898b65bdec52856cd66b56dabe33e2a62df816f0",
            "title": "Prompting Visual-Language Models for Efficient Video Understanding"
        },
        {
            "paperId": "6d1ef4436904de111c8b1975bbf25d3fe2f165f7",
            "title": "DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting"
        },
        {
            "paperId": "39a620939887c9fc1f9bdd7ecfabde985a4aad3a",
            "title": "PTQ4ViT: Post-training Quantization for Vision Transformers with Twin Uniform Quantization"
        },
        {
            "paperId": "336e06e34eac2eeda8b34d95d545d8ff4dd1b2f9",
            "title": "Class-Agnostic Object Detection with Multi-modal Transformer"
        },
        {
            "paperId": "21ec90872abd986c12afe39bebe807732ffa70c9",
            "title": "Florence: A New Foundation Model for Computer Vision"
        },
        {
            "paperId": "197d5867a45a2988f4dd159063cdfbfe90164962",
            "title": "LiT: Zero-Shot Transfer with Locked-image text Tuning"
        },
        {
            "paperId": "f675c62abfa788ea0be85d3124eba15a14d5e9d6",
            "title": "FILIP: Fine-grained Interactive Language-Image Pre-Training"
        },
        {
            "paperId": "f3a332ff1b73acda482e5d83696b2c701f487819",
            "title": "P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"
        },
        {
            "paperId": "c04067f03fba2df0c14ea51a170f213eb2983708",
            "title": "CLIP-Adapter: Better Vision-Language Models with Feature Adapters"
        },
        {
            "paperId": "96ea07447d2f9adefe03852a878517a2a6d45b96",
            "title": "Learning to Prompt for Vision-Language Models"
        },
        {
            "paperId": "5da0e767a13fc0d9e26e412eb5584f14ddaa57aa",
            "title": "Manipulating Identical Filter Redundancy for Efficient Pruning on Deep and Complicated CNN"
        },
        {
            "paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069",
            "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"
        },
        {
            "paperId": "c295391129426d89ec58cebb049d1cd2e976deec",
            "title": "Post-Training Quantization for Vision Transformer"
        },
        {
            "paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092",
            "title": "LoRA: Low-Rank Adaptation of Large Language Models"
        },
        {
            "paperId": "8a0a7170977cf5c94d9079b351562077b78df87a",
            "title": "A White Paper on Neural Network Quantization"
        },
        {
            "paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4",
            "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"
        },
        {
            "paperId": "04e283adccf66742130bde4a4dedcda8f549dd7e",
            "title": "A Survey of Quantization Methods for Efficient Neural Network Inference"
        },
        {
            "paperId": "bc37c6bdb8f39929a58b30464f72d6aa46cddc17",
            "title": "GPT Understands, Too"
        },
        {
            "paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4",
            "title": "Learning Transferable Visual Models From Natural Language Supervision"
        },
        {
            "paperId": "141a5033d9994242b18bb3b217e79582f1ee9306",
            "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"
        },
        {
            "paperId": "2b8088253e2378fce001a090fe923b81e8dedf25",
            "title": "RepVGG: Making VGG-style ConvNets Great Again"
        },
        {
            "paperId": "33422275fbb9958f55419620697faf531482699b",
            "title": "How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering"
        },
        {
            "paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
        },
        {
            "paperId": "c5ced88892855b7dfea915e278468bc8d68e907c",
            "title": "ResRep: Lossless CNN Pruning via Decoupling Remembering and Forgetting"
        },
        {
            "paperId": "8cc855854384755336aa05c5376ea455137bfbce",
            "title": "LSQ+: Improving low-bit quantization through learnable offsets and better initialization"
        },
        {
            "paperId": "f14469790532b5136d283a1b46c6c47a50dbbc79",
            "title": "ACNet: Strengthening the Kernel Skeletons for Powerful CNN via Asymmetric Convolution Blocks"
        },
        {
            "paperId": "d77123b54dcc8014949584ab624e97298617bcad",
            "title": "Data-Free Quantization Through Weight Equalization and Bias Correction"
        },
        {
            "paperId": "be15556f57a283de15b1f2c30095ba34c70349de",
            "title": "Fighting Quantization Bias With Bias"
        },
        {
            "paperId": "48e59902a49e41f2f16229bb38c27348c461b8c7",
            "title": "Centripetal SGD for Pruning Very Deep Convolutional Networks With Complicated Structure"
        },
        {
            "paperId": "dc160709bbe528b506a37ead334f60d258413357",
            "title": "Learned Step Size Quantization"
        },
        {
            "paperId": "63521e29aacc8c07bcb8476389f9b0cc247802bd",
            "title": "Same, Same But Different - Recovering Neural Network Quantization Error Through Weight Factorization"
        },
        {
            "paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c",
            "title": "Parameter-Efficient Transfer Learning for NLP"
        },
        {
            "paperId": "f789425a7af1d012675118d7d10cd50afad09074",
            "title": "Post training 4-bit quantization of convolutional networks for rapid-deployment"
        },
        {
            "paperId": "3cd3f1585ced02cbb56a9e1428176a6c2b211da2",
            "title": "Learning to Quantize Deep Networks by Optimizing Quantization Intervals With Task Loss"
        },
        {
            "paperId": "90a16f34d109b63d95ab4da2d491cbe3a1c8b656",
            "title": "Learning Efficient Convolutional Networks through Network Slimming"
        },
        {
            "paperId": "89e88ab5b7ba7557573ad773a0a077484bee3759",
            "title": "Zero-Shot Learning \u2014 The Good, the Bad and the Ugly"
        },
        {
            "paperId": "c2a1cb1612ba21e067a5c3ba478a8d73b796b77a",
            "title": "Pruning Filters for Efficient ConvNets"
        },
        {
            "paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "title": "Deep Residual Learning for Image Recognition"
        },
        {
            "paperId": "642d0f49b7826adcf986616f4af77e736229990f",
            "title": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"
        },
        {
            "paperId": "63f1f2dad0a2e84d37a97258008c5609195487f0",
            "title": "Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs"
        },
        {
            "paperId": "851c2e1942642537499c743c324f10624b7b77ac",
            "title": "Accurate Post Training Quantization With Small Calibration Sets"
        },
        {
            "paperId": "53d8b356551a2361020a948f64454a6d599af69f",
            "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"
        },
        {
            "paperId": null,
            "title": "Autoprompt: Elic-iting knowledge from language models with automatically generated prompts"
        },
        {
            "paperId": null,
            "title": "Quantized Prompt for Efficient Generalization of Vision-Language Models 17 loss"
        },
        {
            "paperId": "34f25a8704614163c4095b3ee2fc969b60de4698",
            "title": "Dropout: a simple way to prevent neural networks from overfitting"
        },
        {
            "paperId": null,
            "title": "Domain generalization , which aims to show generalization to the domain shift, especially for out-of-distribution data"
        },
        {
            "paperId": null,
            "title": "Visual prompting: Mod-ifying pixel space to adapt pre-trained models"
        }
    ]
}