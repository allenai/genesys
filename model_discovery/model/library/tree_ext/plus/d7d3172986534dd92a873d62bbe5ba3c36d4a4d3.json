{
    "paperId": "d7d3172986534dd92a873d62bbe5ba3c36d4a4d3",
    "externalIds": {
        "ArXiv": "2408.04532",
        "CorpusId": 271768693
    },
    "title": "How Transformers Utilize Multi-Head Attention in In-Context Learning? A Case Study on Sparse Linear Regression",
    "abstract": "Despite the remarkable success of transformer-based models in various real-world tasks, their underlying mechanisms remain poorly understood. Recent studies have suggested that transformers can implement gradient descent as an in-context learner for linear regression problems and have developed various theoretical analyses accordingly. However, these works mostly focus on the expressive power of transformers by designing specific parameter constructions, lacking a comprehensive understanding of their inherent working mechanisms post-training. In this study, we consider a sparse linear regression problem and investigate how a trained multi-head transformer performs in-context learning. We experimentally discover that the utilization of multi-heads exhibits different patterns across layers: multiple heads are utilized and essential in the first layer, while usually only a single head is sufficient for subsequent layers. We provide a theoretical explanation for this observation: the first layer preprocesses the context data, and the following layers execute simple optimization steps based on the preprocessed context. Moreover, we demonstrate that such a preprocess-then-optimize algorithm can significantly outperform naive gradient descent and ridge regression algorithms. Further experimental results support our explanations. Our findings offer insights into the benefits of multi-head attention and contribute to understanding the more intricate mechanisms hidden within trained transformers.",
    "venue": "",
    "year": 2024,
    "referenceCount": 55,
    "citationCount": 0,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This study considers a sparse linear regression problem and investigates how a trained multi-head transformer performs in-context learning, offering insights into the benefits of multi-head attention and contribute to understanding the more intricate mechanisms hidden within trained transformers."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -4.518733978271484,
            -0.02224002778530121,
            1.3817138671875,
            3.6253552436828613,
            -0.7330052852630615,
            0.6499031782150269,
            2.224020004272461,
            -3.248764991760254,
            0.6940058469772339,
            -1.105827808380127,
            -2.907478094100952,
            6.433490753173828,
            -1.0531771183013916,
            1.8463270664215088,
            -4.477862358093262,
            -1.0749986171722412,
            0.16703492403030396,
            1.447171926498413,
            4.194887638092041,
            2.802649974822998,
            -2.2406039237976074,
            1.0581495761871338,
            -2.5189032554626465,
            -1.6101804971694946,
            1.2624176740646362,
            -1.310539960861206,
            4.374788284301758,
            -1.589796543121338,
            -4.091588020324707,
            1.8061832189559937,
            -1.4591100215911865,
            -5.866617679595947,
            6.196460247039795,
            -4.194787502288818,
            3.4615657329559326,
            -3.7804102897644043,
            -1.9996696710586548,
            9.310346603393555,
            -2.9039511680603027,
            -3.281034231185913,
            -0.7726219892501831,
            -0.7806521654129028,
            1.129891037940979,
            -1.1791396141052246,
            -1.7459712028503418,
            0.6318976879119873,
            0.7376065850257874,
            3.5629048347473145,
            1.140378475189209,
            1.1772352457046509,
            2.6089770793914795,
            1.231638789176941,
            -2.496156930923462,
            1.5902857780456543,
            1.2828750610351562,
            -0.7842152118682861,
            3.9491214752197266,
            -0.2653188109397888,
            2.410895347595215,
            -2.8493435382843018,
            4.9764723777771,
            2.8729588985443115,
            -0.7062927484512329,
            2.8528032302856445,
            4.668800354003906,
            -4.579817771911621,
            -2.980895519256592,
            4.3701019287109375,
            1.9248192310333252,
            3.583242654800415,
            2.8057804107666016,
            -5.77901029586792,
            0.7002940773963928,
            0.7837816476821899,
            -2.018467903137207,
            1.2955541610717773,
            1.9191533327102661,
            -7.684361457824707,
            0.04632753133773804,
            -0.4368034601211548,
            0.8527748584747314,
            1.2124227285385132,
            -0.40885400772094727,
            2.281830072402954,
            2.8230600357055664,
            -2.949216604232788,
            -5.362457275390625,
            3.43583607673645,
            -1.1890225410461426,
            -3.954246997833252,
            -0.36686915159225464,
            2.6738455295562744,
            -1.4333781003952026,
            0.6385417580604553,
            -3.5041489601135254,
            -1.8677892684936523,
            2.1725027561187744,
            -1.4761347770690918,
            -3.758470058441162,
            2.154543161392212,
            3.0163512229919434,
            1.6356192827224731,
            1.7000333070755005,
            1.3022677898406982,
            3.8113794326782227,
            -2.624521017074585,
            2.162288188934326,
            2.767711877822876,
            3.210456132888794,
            -0.39403587579727173,
            -4.600964546203613,
            3.4503090381622314,
            -0.7911597490310669,
            -0.9958913922309875,
            0.6580607891082764,
            -3.5488128662109375,
            -2.7351956367492676,
            -0.5093255043029785,
            -0.21103619039058685,
            4.125080108642578,
            -1.5502512454986572,
            1.4437733888626099,
            -2.929215431213379,
            1.4970093965530396,
            -0.30906492471694946,
            2.877319097518921,
            -0.04559865593910217,
            -0.6048484444618225,
            -0.3310658931732178,
            -6.1167144775390625,
            0.09721371531486511,
            -0.27541545033454895,
            2.0469398498535156,
            -2.6718175411224365,
            5.569699287414551,
            3.591822624206543,
            -4.290308475494385,
            1.2408201694488525,
            -3.0867977142333984,
            0.5064738392829895,
            -0.5520110130310059,
            4.053158760070801,
            -0.06795564293861389,
            -0.4805310070514679,
            4.0576701164245605,
            2.6001529693603516,
            0.20945881307125092,
            3.6620779037475586,
            3.185753345489502,
            5.885209560394287,
            0.4216254949569702,
            -5.192152976989746,
            1.6142041683197021,
            1.838409662246704,
            -1.600433349609375,
            2.2594494819641113,
            -5.994844913482666,
            0.16948089003562927,
            -3.4187183380126953,
            1.2155781984329224,
            1.8629653453826904,
            -1.0140814781188965,
            -11.082934379577637,
            3.2623205184936523,
            6.33558464050293,
            -5.323749542236328,
            -2.9750475883483887,
            0.9974566698074341,
            -1.1798546314239502,
            2.1596691608428955,
            2.4400930404663086,
            0.770529568195343,
            1.4867395162582397,
            0.4897822439670563,
            3.2280569076538086,
            3.581122636795044,
            -0.6201162338256836,
            -2.4758758544921875,
            0.1443394422531128,
            0.8746734857559204,
            -2.3135883808135986,
            -2.4094290733337402,
            -6.402094841003418,
            1.7445058822631836,
            -4.579935073852539,
            -4.1582512855529785,
            -1.6871451139450073,
            -3.7573187351226807,
            -2.2701525688171387,
            -0.27625173330307007,
            -0.6353372931480408,
            1.0024349689483643,
            4.903151988983154,
            5.732089042663574,
            4.642789363861084,
            2.7868971824645996,
            0.8866947889328003,
            0.8514125347137451,
            -1.372318983078003,
            -2.4020798206329346,
            3.37263560295105,
            0.13779684901237488,
            -0.12289983034133911,
            -0.2641538381576538,
            2.863292694091797,
            2.3873448371887207,
            -5.087179183959961,
            2.920461416244507,
            2.941580295562744,
            0.7510826587677002,
            1.1888552904129028,
            -1.1570688486099243,
            -1.1082005500793457,
            2.598377227783203,
            -3.552961587905884,
            -0.4529911279678345,
            -6.253790855407715,
            2.6077418327331543,
            2.2790799140930176,
            4.677539825439453,
            -2.4357173442840576,
            1.3584548234939575,
            3.1435093879699707,
            -4.85409688949585,
            -2.3234143257141113,
            -1.5968084335327148,
            2.9196524620056152,
            1.15260648727417,
            -3.041473388671875,
            3.013887405395508,
            -1.495410680770874,
            -3.3505725860595703,
            -2.0930466651916504,
            -1.8815901279449463,
            -6.801916122436523,
            -1.556739330291748,
            -5.331146240234375,
            1.8080754280090332,
            1.7149347066879272,
            -3.4115381240844727,
            5.500014305114746,
            2.178837537765503,
            0.3645501732826233,
            4.456373691558838,
            0.6232369542121887,
            -1.1604297161102295,
            -3.5886330604553223,
            0.47614991664886475,
            1.354249358177185,
            0.5864412188529968,
            -0.1209469735622406,
            2.099487781524658,
            3.6753060817718506,
            -2.6118226051330566,
            1.654973030090332,
            3.2002315521240234,
            0.4666929543018341,
            -1.2530663013458252,
            2.569246292114258,
            2.002995491027832,
            0.8357330560684204,
            7.0702996253967285,
            3.5816900730133057,
            5.455588340759277,
            -1.1654717922210693,
            -1.5460566282272339,
            -2.345852851867676,
            -4.58515739440918,
            -3.523266315460205,
            5.003850936889648,
            -1.2633216381072998,
            2.6441712379455566,
            0.8788906335830688,
            -6.364058971405029,
            0.19687211513519287,
            -4.59504508972168,
            -4.468939304351807,
            -0.4927871823310852,
            1.1651874780654907,
            5.489552021026611,
            0.7889758348464966,
            -1.815035343170166,
            -1.1592295169830322,
            -0.25426530838012695,
            0.9231529235839844,
            -2.028005599975586,
            -2.80155086517334,
            -0.7949233055114746,
            -0.6475156545639038,
            -2.0768628120422363,
            -5.409832000732422,
            6.706353187561035,
            -3.926748037338257,
            -0.6880550980567932,
            -0.9928216934204102,
            4.428770065307617,
            3.285101890563965,
            -2.9644551277160645,
            0.2501124143600464,
            -2.047088623046875,
            -1.4399070739746094,
            -0.40056708455085754,
            5.967808246612549,
            -2.2440543174743652,
            4.1365156173706055,
            3.103982925415039,
            2.5466184616088867,
            -0.08783680200576782,
            -2.5788490772247314,
            -5.414643287658691,
            -2.591034173965454,
            -0.7451544404029846,
            4.313828945159912,
            -4.317168712615967,
            -0.6386098265647888,
            1.1409870386123657,
            0.9221811890602112,
            0.06515699625015259,
            0.43944212794303894,
            4.3731560707092285,
            -1.1336597204208374,
            0.18915551900863647,
            -5.349935054779053,
            -1.4830811023712158,
            -2.442004442214966,
            -0.18741902709007263,
            2.0587196350097656,
            3.342458486557007,
            -3.519110679626465,
            3.170051097869873,
            -0.5801446437835693,
            4.457481384277344,
            2.8358192443847656,
            0.544528603553772,
            0.6372504830360413,
            -4.950415134429932,
            -1.1246519088745117,
            -1.1223572492599487,
            1.972354531288147,
            4.829716682434082,
            -0.1878846287727356,
            7.313294410705566,
            -0.9217984080314636,
            2.0519165992736816,
            -0.7427546977996826,
            -0.11251599341630936,
            0.6354261040687561,
            -3.3262696266174316,
            -2.927549362182617,
            -4.259404182434082,
            -0.14034146070480347,
            -0.5045832395553589,
            2.0114078521728516,
            -3.660618305206299,
            3.968663215637207,
            4.82653284072876,
            2.0271167755126953,
            0.9673792123794556,
            -0.5443365573883057,
            2.074983596801758,
            -1.3084168434143066,
            -3.139378070831299,
            -1.3280458450317383,
            -0.516822338104248,
            -0.7054293751716614,
            -3.752800941467285,
            10.444150924682617,
            -3.3853068351745605,
            1.695115327835083,
            -5.735917091369629,
            -2.8761305809020996,
            -2.2056050300598145,
            -1.5898733139038086,
            6.763672351837158,
            -2.7231602668762207,
            -0.7273421287536621,
            -2.014636754989624,
            -1.819558024406433,
            -0.20969772338867188,
            2.244196891784668,
            -0.6403318047523499,
            6.6312360763549805,
            0.2081313282251358,
            4.1777496337890625,
            -1.4688217639923096,
            -2.332082748413086,
            -3.7350213527679443,
            -0.47626346349716187,
            -0.490852028131485,
            0.5219702124595642,
            -0.7391006946563721,
            2.86411714553833,
            -0.7178350687026978,
            -0.2755672037601471,
            -1.5724008083343506,
            0.05449819564819336,
            -0.6854971051216125,
            -4.526695728302002,
            -1.2076960802078247,
            -0.6051118969917297,
            1.659893274307251,
            1.7013753652572632,
            2.010772466659546,
            4.239424705505371,
            -2.6884474754333496,
            -0.9862239360809326,
            3.4358913898468018,
            -1.973296046257019,
            0.008327841758728027,
            1.0510671138763428,
            -0.028195559978485107,
            -1.1030118465423584,
            -1.0230594873428345,
            -2.186298370361328,
            0.9090791344642639,
            -0.1889934539794922,
            -2.187016725540161,
            1.4705439805984497,
            4.064962387084961,
            -0.7998582124710083,
            -2.093311071395874,
            0.965139627456665,
            3.3707337379455566,
            -0.32840433716773987,
            -1.3992279767990112,
            -0.14857308566570282,
            3.0749428272247314,
            0.705742359161377,
            0.2271399199962616,
            5.085352897644043,
            -1.344158411026001,
            5.225762367248535,
            -3.458425521850586,
            -1.0657806396484375,
            -0.46358436346054077,
            1.8747128248214722,
            1.2173717021942139,
            0.6599944829940796,
            -0.3194202184677124,
            0.7460826635360718,
            -0.25680971145629883,
            2.4040892124176025,
            -4.111398696899414,
            5.83465576171875,
            -3.2095863819122314,
            2.710847854614258,
            3.4071450233459473,
            1.869989037513733,
            -2.4034218788146973,
            -5.46354866027832,
            3.3920793533325195,
            -2.689025402069092,
            -5.207028865814209,
            1.367085576057434,
            -1.0441770553588867,
            -0.38808926939964294,
            -3.4591519832611084,
            -2.566939115524292,
            0.6229952573776245,
            2.863640785217285,
            -6.4344024658203125,
            2.282299041748047,
            -1.0008628368377686,
            1.5069726705551147,
            1.3820860385894775,
            1.6808960437774658,
            -2.021754026412964,
            -1.686421275138855,
            -1.4393765926361084,
            1.0054752826690674,
            4.348829746246338,
            3.9312729835510254,
            -0.8640856742858887,
            -2.8563878536224365,
            1.6566386222839355,
            1.701589584350586,
            1.0967657566070557,
            2.8944408893585205,
            0.24853408336639404,
            -3.49436616897583,
            -6.624542236328125,
            -0.5063428282737732,
            2.5637383460998535,
            -0.05158752202987671,
            -2.507838249206543,
            6.745187759399414,
            6.072547912597656,
            2.754082441329956,
            2.8492884635925293,
            4.4914469718933105,
            3.0714926719665527,
            1.6209014654159546,
            5.130196571350098,
            1.0903984308242798,
            2.6999504566192627,
            2.673870801925659,
            -3.9789907932281494,
            2.8933730125427246,
            2.3635551929473877,
            -0.45634937286376953,
            0.9660928249359131,
            -4.024765968322754,
            0.6236738562583923,
            -1.8883213996887207,
            -1.781111478805542,
            7.420689582824707,
            4.082505226135254,
            1.8251004219055176,
            -5.419923782348633,
            -3.0317211151123047,
            -3.845897674560547,
            4.735710144042969,
            -10.384465217590332,
            1.7520256042480469,
            -0.4455845355987549,
            3.3112430572509766,
            4.366164207458496,
            -0.3044310510158539,
            1.9741053581237793,
            1.9469640254974365,
            -3.5691418647766113,
            0.8269801139831543,
            -1.453230381011963,
            2.260895252227783,
            1.0161242485046387,
            0.010679453611373901,
            -2.8836941719055176,
            -0.8021376132965088,
            -0.6378960609436035,
            5.855265140533447,
            6.573789596557617,
            3.9751040935516357,
            2.5799612998962402,
            0.23987358808517456,
            -0.9149163365364075,
            -2.136522054672241,
            2.372107744216919,
            6.59885311126709,
            -3.6614112854003906,
            -3.395662307739258,
            2.15110445022583,
            2.8402743339538574,
            -1.0726462602615356,
            3.8853139877319336,
            -0.18715925514698029,
            2.525418281555176,
            -6.0491228103637695,
            -0.0648912787437439,
            -2.4810476303100586,
            -0.46055248379707336,
            -0.11295938491821289,
            -2.471529483795166,
            3.877276659011841,
            -1.9512137174606323,
            -5.5184197425842285,
            -0.997046947479248,
            -1.1490484476089478,
            -3.4008803367614746,
            -5.094252586364746,
            2.2808055877685547,
            3.9286880493164062,
            0.18947044014930725,
            -1.0076956748962402,
            4.725964069366455,
            -0.9301834106445312,
            -2.9339599609375,
            -1.382070541381836,
            6.1710710525512695,
            -0.37669074535369873,
            -2.9549400806427,
            -1.0240850448608398,
            -0.23553532361984253,
            0.16366392374038696,
            -1.5470216274261475,
            2.1017212867736816,
            6.559967994689941,
            3.4834532737731934,
            2.193521738052368,
            -3.4493250846862793,
            1.9834650754928589,
            0.906783401966095,
            -3.2158868312835693,
            -1.903357744216919,
            -6.169302463531494,
            1.8006253242492676,
            -6.619326114654541,
            -3.7719368934631348,
            1.878434658050537,
            -5.071756839752197,
            -0.4907004237174988,
            1.8802379369735718,
            -0.4335019588470459,
            1.5099403858184814,
            -4.835048675537109,
            0.15028175711631775,
            -2.4091172218322754,
            0.6218433380126953,
            0.08868575096130371,
            -3.466757297515869,
            2.990812301635742,
            0.48848670721054077,
            2.2909839153289795,
            4.586780548095703,
            1.7506732940673828,
            -2.291685104370117,
            -0.28186583518981934,
            1.1054284572601318,
            0.10628938674926758,
            -1.8804703950881958,
            1.5873727798461914,
            -0.7511894106864929,
            -0.09091177582740784,
            15.017656326293945,
            2.1538426876068115,
            1.2711907625198364,
            -1.4044044017791748,
            -1.6233426332473755,
            -3.9257500171661377,
            -2.465754985809326,
            -2.190225601196289,
            0.2045072615146637,
            2.507516622543335,
            -1.9591593742370605,
            -4.300852298736572,
            -0.39905470609664917,
            0.09244126081466675,
            -2.7382519245147705,
            -4.553083896636963,
            -2.6022942066192627,
            1.8776484727859497,
            -0.5509679317474365,
            -3.1175808906555176,
            0.2737782597541809,
            4.7407684326171875,
            -5.0263776779174805,
            -1.193732738494873,
            -1.1700396537780762,
            2.304136276245117,
            2.2283101081848145,
            3.524735927581787,
            -7.893129348754883,
            0.4609552025794983,
            2.657144069671631,
            1.0564106702804565,
            -0.5834341049194336,
            -0.07627487182617188,
            -2.4235053062438965,
            4.586775779724121,
            3.182521343231201,
            -1.868401288986206,
            3.5620014667510986,
            1.5985771417617798,
            1.4490247964859009,
            2.6508636474609375,
            -2.3781161308288574,
            1.8916254043579102,
            -1.1180436611175537,
            -1.7842698097229004,
            2.5459067821502686,
            -3.490309238433838,
            -0.4531891942024231,
            1.730134129524231,
            1.7743139266967773,
            -0.8222440481185913,
            -1.5411028861999512,
            1.4776391983032227,
            2.7985990047454834,
            2.1126768589019775,
            0.7726933360099792,
            -2.4525504112243652,
            1.9528992176055908,
            2.144648551940918,
            -0.12357965111732483,
            0.038471370935440063,
            -1.5435233116149902,
            -4.05594539642334,
            -0.13908731937408447,
            -2.2427659034729004,
            -3.1696481704711914,
            4.211798667907715,
            2.0387625694274902,
            0.33241719007492065,
            2.449498176574707,
            1.635710597038269,
            -1.969594955444336,
            -2.0059316158294678,
            -2.332855224609375,
            -4.695746898651123,
            0.8089417219161987,
            0.41778120398521423,
            -1.3037396669387817,
            6.26536750793457,
            -3.459243059158325,
            3.726274013519287,
            -1.5225211381912231,
            1.0626015663146973,
            3.5855650901794434,
            -1.2857067584991455,
            4.2924041748046875,
            0.7218486070632935,
            -6.216545104980469,
            5.503478050231934,
            -2.634535312652588,
            0.5836882591247559,
            2.104553699493408,
            2.9682064056396484,
            4.961277484893799,
            -5.719772815704346,
            -1.0273079872131348,
            -2.639464855194092,
            -4.4720025062561035,
            -4.411436080932617,
            4.64066743850708,
            4.109738826751709,
            1.982000708580017,
            -2.674466133117676,
            -2.5057921409606934,
            1.3075895309448242,
            -1.4774738550186157,
            -6.680340766906738,
            -2.73398756980896,
            -3.5447874069213867,
            5.738893985748291,
            -1.2116341590881348,
            -1.06901216506958,
            -0.7515664100646973,
            -0.5770444273948669,
            -0.3954096734523773,
            1.7270557880401611,
            2.090214729309082,
            1.1485309600830078,
            8.733943939208984,
            -0.7731319665908813,
            -0.6910589933395386,
            -0.8808314800262451,
            -3.206238269805908,
            -3.7864742279052734,
            0.26642465591430664,
            -0.07959729433059692,
            -1.0755842924118042,
            -0.40471526980400085,
            0.6386430859565735,
            3.8647804260253906,
            -5.991005897521973,
            -2.4467663764953613,
            -2.053708553314209,
            -0.6718003153800964,
            -3.42067813873291,
            -0.1542002558708191,
            3.10095477104187,
            -3.071699619293213,
            1.6823910474777222,
            1.4120042324066162,
            -4.817052364349365,
            -0.09494620561599731,
            10.431107521057129,
            -0.5053475499153137,
            -1.0380356311798096,
            0.42746153473854065,
            -0.21732580661773682,
            -3.9448795318603516,
            0.5562044382095337,
            0.3854635953903198,
            -0.7664494514465332,
            4.640239715576172,
            1.3621357679367065,
            -1.9306309223175049,
            -2.2269396781921387
        ]
    },
    "authors": [
        {
            "authorId": "2294765801",
            "name": "Xingwu Chen"
        },
        {
            "authorId": "2315292153",
            "name": "Lei Zhao"
        },
        {
            "authorId": "2294574780",
            "name": "Difan Zou"
        }
    ],
    "references": [
        {
            "paperId": "ebbd118d7f6383f8a08eb6ea6fbfd24a19639505",
            "title": "What Can Transformer Learn with Varying Depth? Case Studies on Sequence Learning Tasks"
        },
        {
            "paperId": "2ccbafd636184c6edd83e585359514923b6cf849",
            "title": "The Unreasonable Ineffectiveness of the Deeper Layers"
        },
        {
            "paperId": "3c6f2e0c5ff5dff6151c3e6489378a53318a75b4",
            "title": "ShortGPT: Layers in Large Language Models are More Redundant Than You Expect"
        },
        {
            "paperId": "0fc695cd670033f6fbd48b90f8c3a2ee6f6c618e",
            "title": "How Well Can Transformers Emulate In-context Newton's Method?"
        },
        {
            "paperId": "2bc63d667572453d1da74abb32c5780a676099ad",
            "title": "Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality"
        },
        {
            "paperId": "ea3152821ce9ddd005429378073197feb6684398",
            "title": "In-Context Learning of a Linear Transformer Block: Benefits of the MLP Component and One-Step GD Initialization"
        },
        {
            "paperId": "f02d9889bab24f0da4446db0288fe7dfcde1b630",
            "title": "How Transformers Learn Causal Structure with Gradient Descent"
        },
        {
            "paperId": "a4a74b8e3d85f4f1c62ffffe5514f64a76cdaf92",
            "title": "Superiority of Multi-Head Attention in In-Context Linear Regression"
        },
        {
            "paperId": "7723b4da2f4565e81c5e7543cfdccc18311375b8",
            "title": "Transformers Implement Functional Gradient Descent to Learn Non-Linear Functions In Context"
        },
        {
            "paperId": "5128025d3fa915e08c1b33aa5228ee1f3e58884a",
            "title": "Transformers Learn Higher-Order Optimization Methods for In-Context Learning: A Study with Linear Models"
        },
        {
            "paperId": "1ec3a3ff77cb4b424499b3805ecc90182ecd8f8b",
            "title": "What Algorithms can Transformers Learn? A Study in Length Generalization"
        },
        {
            "paperId": "ef9df346acb04d97fdeb3d0046d8920e54b02351",
            "title": "How Do Transformers Learn In-Context Beyond Simple Functions? A Case Study on Learning with Representations"
        },
        {
            "paperId": "a7277d5aff39ca6d2c2c9880fc4e75d9c3ca0e3b",
            "title": "How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?"
        },
        {
            "paperId": "ab643f5b02786fc4772b662adcdb558c557d3bf6",
            "title": "In-Context Convergence of Transformers"
        },
        {
            "paperId": "f29f8b8aa2b7e608199b65d3cf751969d4024132",
            "title": "Physics of Language Models: Part 3.1, Knowledge Storage and Extraction"
        },
        {
            "paperId": "47daf5f81470564f94adcac672405c2cd39dd186",
            "title": "Physics of Language Models: Part 3.2, Knowledge Manipulation"
        },
        {
            "paperId": "f9a4ed62ea6da274c1c81748b2bca240655b7c29",
            "title": "Transformers as Support Vector Machines"
        },
        {
            "paperId": "3c8444cc4e96bdbe6853b886caf032afd1ee1d20",
            "title": "CausalLM is not optimal for in-context learning"
        },
        {
            "paperId": "0f71e7280049f6347e266d8b6d3a4c4ea8c93b8b",
            "title": "Are Transformers with One Layer Self-Attention Using Low-Rank Weight Matrices Universal Approximators?"
        },
        {
            "paperId": "cbec8bf16a459b0ae38856f604a6a14cd1343477",
            "title": "One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention"
        },
        {
            "paperId": "4a7530bbaee7563ee244f3ffed6b706bd96f08a8",
            "title": "Trained Transformers Learn Linear Models In-Context"
        },
        {
            "paperId": "70c3d5ab03a54281be91709b19e3f50a2e4be0e3",
            "title": "Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection"
        },
        {
            "paperId": "88d6b4442db878b1623c3fa51de814577dd66b48",
            "title": "Memorization Capacity of Multi-Head Attention in Transformers"
        },
        {
            "paperId": "f5e9337477d7a9eb6267d0310549fdefafbb7fe2",
            "title": "Transformers learn to implement preconditioned gradient descent for in-context learning"
        },
        {
            "paperId": "6cb8bc7398ffcd27c500fb743cf72c84cfe4df8d",
            "title": "Learning Transformer Programs"
        },
        {
            "paperId": "c134bfc429e955d22b25cf9d3bd15e80d6518781",
            "title": "Approximation and Estimation Ability of Transformers for Sequence-to-Sequence Functions with Infinite Dimensional Input"
        },
        {
            "paperId": "253c900b0569694d57e8f2904e330b51ae740fd8",
            "title": "A Mechanism for Sample-Efficient In-Context Learning for Sparse Retrieval Tasks"
        },
        {
            "paperId": "50eb97f832ffcd2114f79957c977215176384e3d",
            "title": "Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer"
        },
        {
            "paperId": "163b4d6a79a5b19af88b8585456363340d9efd04",
            "title": "GPT-4 Technical Report"
        },
        {
            "paperId": "f3fde8a09b757ab356da1314d7a938504edf8314",
            "title": "How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding"
        },
        {
            "paperId": "a7fa71dc6856ebef79f354597128d1c68b19b6e4",
            "title": "Transformers as Algorithms: Generalization and Stability in In-context Learning"
        },
        {
            "paperId": "a5cc5edcabba4c9c62cfbc3379daa140084a2a24",
            "title": "Tracr: Compiled Transformers as a Laboratory for Interpretability"
        },
        {
            "paperId": "525d93a382f6e7873b5d8a2e0713eb3dff7fb250",
            "title": "Transformers learn in-context by gradient descent"
        },
        {
            "paperId": "7aa801b907b59b8ee4cfb1296d9dac22c5164c5d",
            "title": "What learning algorithm is in-context learning? Investigations with linear models"
        },
        {
            "paperId": "e82e3f4347674b75c432cb80604d38ee630d4bf6",
            "title": "Transformers Learn Shortcuts to Automata"
        },
        {
            "paperId": "de32da8f5c6a50a6c311e9357ba16aa7d05a1bc9",
            "title": "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes"
        },
        {
            "paperId": "22187153e068b40e78b0932bab070cba4951240d",
            "title": "Risk Bounds of Multi-Pass SGD for Least Squares in the Interpolation Regime"
        },
        {
            "paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
            "title": "Training language models to follow instructions with human feedback"
        },
        {
            "paperId": "10bd4160b44803ada6a3d2e366c44b7e2a4ffe90",
            "title": "An Explanation of In-context Learning as Implicit Bayesian Inference"
        },
        {
            "paperId": "46ebd8e54cd72251642899da51deb8679cd76193",
            "title": "The Benefits of Implicit Regularization from SGD in Least Squares Problems"
        },
        {
            "paperId": "0735fb79bf34698c1df4461a05ed51c232c412e4",
            "title": "Thinking Like Transformers"
        },
        {
            "paperId": "1c0f8a6b8e6f4cc6fc81c4019fc07a2e5ec17107",
            "title": "Probing for Bridging Inference in Transformer Language Models"
        },
        {
            "paperId": "b0b3227aedafc936fa978144a9985e5a3652b73d",
            "title": "Benign overfitting in ridge regression"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "cdf766403e365643ac4dfdf9e10df8da1b75b63f",
            "title": "Perturbed Masking: Parameter-free Probing for Analyzing and Interpreting BERT"
        },
        {
            "paperId": "c95383f251a62c63217586059c67f63507c3e839",
            "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"
        },
        {
            "paperId": "c563c0e06684f42bc5d76dfc7304581c11312393",
            "title": "Benign overfitting in linear regression"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "5e23a28063b395bdaf784dc548a046885cb90cf2",
            "title": "Understanding intermediate layers using linear classifier probes"
        },
        {
            "paperId": "c2a1cb1612ba21e067a5c3ba478a8d73b796b77a",
            "title": "Pruning Filters for Efficient ConvNets"
        },
        {
            "paperId": "629ac1415536338db70d08ca8569ea7e0246ff88",
            "title": "High Dimensional Probability"
        },
        {
            "paperId": null,
            "title": "Looped Trans-formers as Programmable Computers"
        },
        {
            "paperId": null,
            "title": "Towards monosemanticity: Decomposing language models with dictionary learning"
        },
        {
            "paperId": null,
            "title": "Language models can explain neurons in language models"
        },
        {
            "paperId": "9405cc0d6169988371b2755e573cc28650d14dfe",
            "title": "Language Models are Unsupervised Multitask Learners"
        }
    ]
}