{
    "paperId": "c8e2a2514995d9d169afcee45bbc93dfa3f89bf8",
    "externalIds": {
        "ArXiv": "2408.01890",
        "CorpusId": 271709350
    },
    "title": "Cross-layer Attention Sharing for Large Language Models",
    "abstract": "As large language models (LLMs) evolve, the increase in model depth and parameter number leads to substantial redundancy. To enhance the efficiency of the attention mechanism, previous works primarily compress the KV cache or group attention heads, while largely overlooking redundancy between layers. Our comprehensive analyses across various LLMs show that highly similar attention patterns persist within most layers. It's intuitive to save the computation by sharing attention weights across layers. However, further analysis reveals two challenges: (1) Directly sharing the weight matrix without carefully rearranging the attention heads proves to be ineffective; (2) Shallow layers are vulnerable to small deviations in attention weights. Driven by these insights, we introduce LiSA, a lightweight substitute for self-attention in well-trained LLMs. LiSA employs tiny feed-forward networks to align attention heads between adjacent layers and low-rank matrices to approximate differences in layer-wise attention weights. Evaluations encompassing 13 typical benchmarks demonstrate that LiSA maintains high response quality in terms of accuracy and perplexity while reducing redundant attention calculations within 53-84% of the total layers. Our implementations of LiSA achieve a 6X compression of Q and K, with maximum throughput improvements of 19.5% for LLaMA3-8B and 32.3% for LLaMA2-7B.",
    "venue": "",
    "year": 2024,
    "referenceCount": 92,
    "citationCount": 0,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "LiSA is introduced, a lightweight substitute for self-attention in well-trained LLMs that maintains high response quality in terms of accuracy and perplexity while reducing redundant attention calculations within 53-84% of the total layers."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -4.785539150238037,
            0.7069012522697449,
            0.024549484252929688,
            5.688322067260742,
            1.681747317314148,
            0.5891903638839722,
            1.1747567653656006,
            3.2524962425231934,
            -0.7857823371887207,
            3.063955783843994,
            -1.1057626008987427,
            4.739650726318359,
            -0.5324022769927979,
            -0.21201372146606445,
            -2.7619049549102783,
            1.030210256576538,
            -3.466564178466797,
            -1.9027382135391235,
            7.42723274230957,
            0.8730493783950806,
            -2.1421749591827393,
            1.4936094284057617,
            0.5796105861663818,
            -1.5950055122375488,
            -1.0156091451644897,
            -2.1197943687438965,
            4.22666597366333,
            -0.1746983528137207,
            -2.7564334869384766,
            1.6263306140899658,
            -1.3690096139907837,
            -3.9191598892211914,
            6.364213943481445,
            -3.9344329833984375,
            3.388573408126831,
            -4.119199752807617,
            -1.3415846824645996,
            5.734892845153809,
            -2.1041948795318604,
            -0.8564049005508423,
            0.4593839943408966,
            -2.2843685150146484,
            -2.5690572261810303,
            0.6156372427940369,
            1.4269952774047852,
            2.7034058570861816,
            0.17517238855361938,
            2.4499921798706055,
            -1.5373148918151855,
            3.336820363998413,
            3.966805934906006,
            -0.9192460775375366,
            -0.3587920069694519,
            0.31335315108299255,
            -0.6498053073883057,
            1.244328260421753,
            2.4750256538391113,
            2.9785714149475098,
            2.4276790618896484,
            -2.7504782676696777,
            5.945192337036133,
            6.134904861450195,
            -0.47065800428390503,
            -0.63616943359375,
            2.798022508621216,
            0.14213892817497253,
            -4.210062026977539,
            5.322388648986816,
            2.527217149734497,
            1.0142513513565063,
            0.6107860803604126,
            -6.15758752822876,
            -1.6992967128753662,
            3.1221885681152344,
            -2.963219165802002,
            -0.05308377742767334,
            0.9732015132904053,
            -8.710216522216797,
            -0.6930431127548218,
            -0.22665253281593323,
            -1.1179096698760986,
            2.1044962406158447,
            0.6724081039428711,
            4.571380138397217,
            3.4142603874206543,
            -1.835849642753601,
            -3.361351490020752,
            2.8538658618927,
            3.902465343475342,
            -1.7780206203460693,
            0.5290695428848267,
            -0.06534180045127869,
            -0.1625012457370758,
            1.2707968950271606,
            -2.9530105590820312,
            1.6157665252685547,
            2.786939859390259,
            -1.9544563293457031,
            -4.455815315246582,
            0.2739347517490387,
            2.299173593521118,
            -2.0982184410095215,
            0.39744627475738525,
            1.6830114126205444,
            2.7880969047546387,
            -5.967705249786377,
            -1.4665911197662354,
            -0.38532307744026184,
            2.0355305671691895,
            -0.11134868860244751,
            -2.579224109649658,
            2.1628332138061523,
            1.666803002357483,
            -2.510636568069458,
            -2.5707528591156006,
            -3.2504796981811523,
            -3.8006644248962402,
            0.3666931688785553,
            -0.3453527092933655,
            6.476823806762695,
            -3.2554264068603516,
            -1.2708576917648315,
            -1.503312587738037,
            -1.7954041957855225,
            2.32908296585083,
            2.5306396484375,
            -1.3490595817565918,
            2.511967182159424,
            0.4300001859664917,
            -5.112247943878174,
            -0.24342769384384155,
            -0.9177317023277283,
            4.885878086090088,
            -0.4296339154243469,
            2.268002986907959,
            2.258735179901123,
            -5.849814414978027,
            5.819927215576172,
            -0.6918518543243408,
            -1.3376989364624023,
            2.006537437438965,
            3.8319177627563477,
            1.2649831771850586,
            -1.9630039930343628,
            0.31971287727355957,
            3.2685980796813965,
            2.6024093627929688,
            2.2217624187469482,
            0.27026987075805664,
            5.705100059509277,
            2.9937844276428223,
            -5.085379600524902,
            -0.37968122959136963,
            0.9195977449417114,
            -2.3876101970672607,
            2.5019454956054688,
            -4.624354362487793,
            2.2705273628234863,
            -3.1671221256256104,
            2.651240348815918,
            -0.23963314294815063,
            2.5842878818511963,
            -9.544366836547852,
            -3.145070791244507,
            3.480350971221924,
            -4.959064483642578,
            -2.33801007270813,
            1.149085283279419,
            -1.2523066997528076,
            3.704047441482544,
            2.067673683166504,
            0.5556300282478333,
            3.137028694152832,
            3.4592573642730713,
            2.0542142391204834,
            2.6916821002960205,
            0.34044724702835083,
            -3.6834306716918945,
            -2.2339954376220703,
            -2.1236791610717773,
            -0.16083943843841553,
            1.0440516471862793,
            -7.1904401779174805,
            -0.8943209052085876,
            -4.9581451416015625,
            -0.8436653017997742,
            -0.7086594104766846,
            -1.0814530849456787,
            -1.7029643058776855,
            -0.6066396832466125,
            -0.8055213689804077,
            0.5114494562149048,
            4.850863456726074,
            5.94056510925293,
            0.3824298679828644,
            -0.10476285219192505,
            1.346106767654419,
            0.8881738185882568,
            -3.0077648162841797,
            0.27606070041656494,
            0.310163676738739,
            -1.0284593105316162,
            1.4608500003814697,
            -4.4329376220703125,
            3.55092716217041,
            2.049609899520874,
            -5.058591842651367,
            2.7663822174072266,
            3.9924168586730957,
            0.4387963116168976,
            4.40167760848999,
            -0.2476518452167511,
            -1.308668851852417,
            4.276766300201416,
            -3.4442214965820312,
            -1.890916109085083,
            -6.6273393630981445,
            -0.018946021795272827,
            3.381885051727295,
            3.0866150856018066,
            1.0565929412841797,
            -2.312751054763794,
            0.10497783124446869,
            -5.828439235687256,
            0.19980394840240479,
            -3.09698486328125,
            0.9722002148628235,
            -1.7921408414840698,
            1.6243140697479248,
            -0.7104185223579407,
            -2.4249038696289062,
            -4.805783748626709,
            1.0730140209197998,
            -3.121835708618164,
            -5.094616889953613,
            -0.19192129373550415,
            -5.114428520202637,
            3.3081371784210205,
            -2.517488956451416,
            -2.9595885276794434,
            5.692658424377441,
            3.7011361122131348,
            3.3297958374023438,
            5.572444915771484,
            4.043294906616211,
            -1.4883403778076172,
            -4.306914329528809,
            0.3983195424079895,
            1.0825905799865723,
            -1.8576326370239258,
            0.4416142702102661,
            -1.2980560064315796,
            4.062931537628174,
            -1.8724720478057861,
            2.3022890090942383,
            0.9362156391143799,
            1.4223154783248901,
            0.41227155923843384,
            0.2197595089673996,
            0.40653321146965027,
            1.7252743244171143,
            5.218395709991455,
            3.2315444946289062,
            3.745213031768799,
            -0.5345756411552429,
            -0.6070884466171265,
            -4.193942070007324,
            0.8662198185920715,
            -2.891070604324341,
            1.4785754680633545,
            2.8597097396850586,
            0.6094779968261719,
            -1.437503457069397,
            -4.482120513916016,
            0.13249576091766357,
            -6.704677581787109,
            -1.400118112564087,
            -0.7917608618736267,
            2.780081272125244,
            1.9607927799224854,
            1.0454790592193604,
            -2.573307752609253,
            -1.059474229812622,
            1.505173683166504,
            -0.8505500555038452,
            -3.9602744579315186,
            -6.587957382202148,
            0.7364774942398071,
            0.09829676151275635,
            -1.3443567752838135,
            -3.224299430847168,
            3.6018757820129395,
            -3.1797897815704346,
            -1.710296630859375,
            -2.844521999359131,
            3.145364284515381,
            5.947628021240234,
            -2.3280375003814697,
            -0.5951605439186096,
            -0.8082007169723511,
            -1.5228655338287354,
            1.255558967590332,
            3.694080352783203,
            0.4955601692199707,
            3.0934267044067383,
            2.5973587036132812,
            -2.3082964420318604,
            -4.0550031661987305,
            -0.4277184009552002,
            -7.526397228240967,
            -2.064979076385498,
            -2.8860056400299072,
            6.318577766418457,
            -3.1357858180999756,
            0.7179681658744812,
            1.107804536819458,
            3.4968578815460205,
            -1.9866461753845215,
            -3.7126917839050293,
            1.3656284809112549,
            -1.292357087135315,
            -2.9382572174072266,
            -6.839978218078613,
            -2.3846092224121094,
            -3.6933584213256836,
            -0.3056473731994629,
            1.882192850112915,
            3.9406168460845947,
            -6.583827972412109,
            5.974599838256836,
            2.4886555671691895,
            5.5124359130859375,
            3.1982438564300537,
            1.5716276168823242,
            -1.1470038890838623,
            -1.622977614402771,
            -2.629260778427124,
            -1.5319281816482544,
            2.2153186798095703,
            0.9783053398132324,
            1.0518966913223267,
            5.892216205596924,
            1.0363807678222656,
            -0.0569610595703125,
            0.03613187372684479,
            0.8773090839385986,
            -0.8313940167427063,
            -0.5233197808265686,
            -0.2803988456726074,
            -2.9708480834960938,
            1.224208950996399,
            2.7444541454315186,
            4.478476047515869,
            -0.8886063098907471,
            1.3858301639556885,
            0.7958836555480957,
            -0.3354882597923279,
            0.3037899136543274,
            2.259277105331421,
            1.1593866348266602,
            -1.649306297302246,
            -0.4524737596511841,
            1.1879671812057495,
            -0.766166090965271,
            2.205918312072754,
            -2.104273796081543,
            13.248059272766113,
            -1.921546220779419,
            5.821202278137207,
            -3.7126262187957764,
            -2.123358964920044,
            -0.1447150707244873,
            -4.810118675231934,
            4.258518218994141,
            -2.1675422191619873,
            -1.2831896543502808,
            -1.1165820360183716,
            -4.524733543395996,
            2.2184319496154785,
            0.8431731462478638,
            0.06692621111869812,
            2.1495566368103027,
            0.7956556677818298,
            1.9556429386138916,
            -1.5062875747680664,
            -0.11807036399841309,
            -3.1991920471191406,
            1.2899372577667236,
            1.3070549964904785,
            -1.076493263244629,
            -2.221407413482666,
            -0.27381157875061035,
            -0.45723187923431396,
            0.955009937286377,
            -4.012914657592773,
            -2.6804580688476562,
            -2.4569523334503174,
            -3.9353699684143066,
            0.4124678075313568,
            1.7872706651687622,
            0.6441388726234436,
            -1.7534775733947754,
            3.3100154399871826,
            5.174960136413574,
            -3.0536434650421143,
            -0.866296112537384,
            3.9356601238250732,
            0.2990944981575012,
            -0.7902131676673889,
            1.5273356437683105,
            -3.7234392166137695,
            -2.5380921363830566,
            0.3575054407119751,
            -5.119549751281738,
            0.29608744382858276,
            -2.9048237800598145,
            2.4293019771575928,
            -0.03359377384185791,
            4.502114772796631,
            2.2738847732543945,
            0.37501901388168335,
            3.711113691329956,
            3.844881057739258,
            3.1045846939086914,
            2.1271986961364746,
            0.266042560338974,
            2.6445274353027344,
            2.23014235496521,
            -1.0038154125213623,
            1.806707739830017,
            0.13383913040161133,
            3.2664947509765625,
            -3.6263813972473145,
            -1.9883246421813965,
            -0.6132239103317261,
            4.098076343536377,
            -0.3785364031791687,
            -2.6389832496643066,
            0.9962130784988403,
            -1.7085239887237549,
            0.9985846877098083,
            3.9487383365631104,
            -4.966019630432129,
            4.324973106384277,
            0.14121997356414795,
            2.0191853046417236,
            -0.3946689963340759,
            -2.6286277770996094,
            -2.039963722229004,
            -2.2179739475250244,
            3.3521552085876465,
            -2.667541742324829,
            -1.6313570737838745,
            -2.582451820373535,
            -0.4430851936340332,
            0.275945782661438,
            -4.706975936889648,
            1.4524288177490234,
            0.21545624732971191,
            -0.5355238318443298,
            -3.2441353797912598,
            3.940293312072754,
            -1.9104124307632446,
            2.1072378158569336,
            1.8365191221237183,
            0.6767511367797852,
            -1.3645901679992676,
            -2.670851469039917,
            -0.9152671098709106,
            2.99703311920166,
            0.29576238989830017,
            0.13118195533752441,
            -1.1351902484893799,
            1.1755629777908325,
            -0.6771175265312195,
            -1.647310733795166,
            1.0538896322250366,
            1.2661528587341309,
            -0.56435227394104,
            -5.878684997558594,
            -1.6059463024139404,
            0.6644314527511597,
            4.596441745758057,
            -2.6997275352478027,
            -3.7276480197906494,
            4.912981986999512,
            5.889071464538574,
            3.523806095123291,
            1.4920618534088135,
            1.5955477952957153,
            2.2238173484802246,
            1.1679859161376953,
            1.3613128662109375,
            -1.1900169849395752,
            1.4819016456604004,
            -1.6955103874206543,
            -2.991750955581665,
            3.3909034729003906,
            1.8457585573196411,
            -1.3505091667175293,
            -2.536957263946533,
            -3.1701500415802,
            -2.1049156188964844,
            -1.74650239944458,
            -2.996645927429199,
            4.920486927032471,
            5.476917743682861,
            1.8168052434921265,
            0.025965780019760132,
            0.4404903054237366,
            -2.511780261993408,
            2.638279438018799,
            -8.877225875854492,
            4.3670573234558105,
            1.4437808990478516,
            0.4006025195121765,
            4.308868408203125,
            0.17747098207473755,
            -1.2620147466659546,
            2.5374257564544678,
            -4.388812065124512,
            0.43356621265411377,
            -2.105886459350586,
            4.372622489929199,
            1.1855318546295166,
            0.13340282440185547,
            -1.7163000106811523,
            1.6749508380889893,
            -1.1577448844909668,
            6.968515396118164,
            6.940600395202637,
            3.9422829151153564,
            3.694106101989746,
            -1.0601799488067627,
            0.2883669137954712,
            -4.711569786071777,
            3.613830089569092,
            3.1579227447509766,
            -5.635173797607422,
            -3.2300901412963867,
            1.5628788471221924,
            0.8537474870681763,
            2.5182344913482666,
            1.189990520477295,
            -2.5747859477996826,
            4.579327583312988,
            -4.1689653396606445,
            -1.8753509521484375,
            -1.55543851852417,
            -0.6838127374649048,
            1.5366215705871582,
            1.1682063341140747,
            2.2163336277008057,
            -0.982169508934021,
            -1.7511470317840576,
            -0.6193417906761169,
            -4.368940353393555,
            -1.311936855316162,
            0.06618607044219971,
            1.2830177545547485,
            4.467067718505859,
            -1.88796067237854,
            0.01077166199684143,
            4.656059265136719,
            -3.156956672668457,
            -1.2755950689315796,
            -3.712453603744507,
            4.556402206420898,
            2.5775814056396484,
            -0.302836537361145,
            -0.04489275813102722,
            -3.914914131164551,
            0.0745171308517456,
            -1.352636694908142,
            1.5124006271362305,
            3.8909971714019775,
            2.8722317218780518,
            2.964012622833252,
            0.1527080237865448,
            -1.7149488925933838,
            0.5919833183288574,
            -3.863722801208496,
            -1.4557334184646606,
            -5.904170989990234,
            -0.17290103435516357,
            -5.549355506896973,
            -3.106977701187134,
            4.135494709014893,
            -5.517241477966309,
            -1.618036150932312,
            4.682689666748047,
            -0.7144370675086975,
            1.5446407794952393,
            -2.2657904624938965,
            -0.8005288243293762,
            -2.7548327445983887,
            3.2861111164093018,
            -0.243544340133667,
            -2.0168795585632324,
            2.5288093090057373,
            -0.38037770986557007,
            2.7296643257141113,
            3.129981756210327,
            2.7493228912353516,
            -2.47236967086792,
            -0.3765180706977844,
            0.8358425498008728,
            1.025521993637085,
            -1.251955509185791,
            -2.150627374649048,
            -0.3087688386440277,
            4.082674980163574,
            14.613370895385742,
            -1.7419973611831665,
            -1.7954038381576538,
            -0.897658109664917,
            -1.072370171546936,
            -2.6410601139068604,
            -3.4704794883728027,
            -0.8073573708534241,
            -2.964996576309204,
            2.260509729385376,
            -2.964296340942383,
            -1.7924461364746094,
            0.6383460760116577,
            -1.9007729291915894,
            -1.0217301845550537,
            -1.74100661277771,
            -4.205489158630371,
            0.8851930499076843,
            -3.679727792739868,
            -4.7240800857543945,
            2.107529878616333,
            2.1049492359161377,
            -1.2324893474578857,
            0.020811766386032104,
            1.7209126949310303,
            3.8347291946411133,
            2.118906021118164,
            3.5617809295654297,
            -5.197018146514893,
            -0.6019477844238281,
            1.9671258926391602,
            1.9501463174819946,
            -0.5997965931892395,
            3.012078285217285,
            0.7049602270126343,
            3.686703681945801,
            1.113875389099121,
            -0.3922910690307617,
            3.3187599182128906,
            4.739510536193848,
            -0.6396827101707458,
            1.8392553329467773,
            -3.6158361434936523,
            2.4772186279296875,
            -2.1929361820220947,
            -0.49592727422714233,
            -0.7487156391143799,
            -3.5804357528686523,
            -3.4152278900146484,
            3.655730724334717,
            0.19126534461975098,
            -0.3898947238922119,
            -1.1629712581634521,
            2.7039573192596436,
            2.6506078243255615,
            2.4267771244049072,
            -0.7451071739196777,
            0.6608078479766846,
            2.8750929832458496,
            1.716097116470337,
            4.75112771987915,
            -0.41163626313209534,
            -2.8826844692230225,
            -1.9576212167739868,
            -1.8721590042114258,
            2.8435635566711426,
            -4.1317291259765625,
            2.3456521034240723,
            0.05883294343948364,
            -0.22225859761238098,
            4.313446044921875,
            2.8436386585235596,
            -1.4569059610366821,
            -1.6332645416259766,
            -0.054845571517944336,
            -3.5488784313201904,
            2.529959201812744,
            -0.0010643154382705688,
            0.6000919938087463,
            9.287130355834961,
            -2.180853843688965,
            2.4702694416046143,
            -2.202094554901123,
            -2.2729318141937256,
            1.8707168102264404,
            -1.4920529127120972,
            4.607426643371582,
            -0.6606101393699646,
            -1.818824052810669,
            4.000187873840332,
            -1.400854229927063,
            1.295499324798584,
            2.968886613845825,
            4.168710231781006,
            5.5512003898620605,
            -3.926595449447632,
            -5.308598518371582,
            -4.188883304595947,
            -3.92250919342041,
            -2.5119738578796387,
            5.94503116607666,
            5.588943958282471,
            -1.7585583925247192,
            -3.9619951248168945,
            -1.7039759159088135,
            -0.12553228437900543,
            -2.7549023628234863,
            -7.94014835357666,
            -1.587524652481079,
            -3.913148880004883,
            6.246323108673096,
            -4.088788032531738,
            -1.4501581192016602,
            -2.789219379425049,
            -0.25992000102996826,
            -2.1742663383483887,
            0.19254621863365173,
            2.610236883163452,
            0.27334752678871155,
            2.652743101119995,
            0.5045035481452942,
            -0.32990244030952454,
            -3.838183879852295,
            -0.7256538271903992,
            -3.0545592308044434,
            0.43415164947509766,
            1.4313716888427734,
            0.5415956377983093,
            -2.2926697731018066,
            0.15328580141067505,
            2.387831211090088,
            -1.723333477973938,
            -6.090390682220459,
            0.9604930281639099,
            0.20579683780670166,
            -1.3767597675323486,
            0.09059318900108337,
            4.9185333251953125,
            -0.03851701319217682,
            -0.22886216640472412,
            2.7841360569000244,
            -3.808789014816284,
            -3.4227733612060547,
            10.243406295776367,
            -1.7893271446228027,
            0.7218561172485352,
            -4.864304065704346,
            -0.4685441851615906,
            -2.2659459114074707,
            -0.09029614925384521,
            0.23359036445617676,
            1.428905963897705,
            3.2542343139648438,
            0.30105024576187134,
            -0.22305448353290558,
            -2.8241775035858154
        ]
    },
    "authors": [
        {
            "authorId": "2040853265",
            "name": "Yongyu Mu"
        },
        {
            "authorId": "2291199377",
            "name": "Yuzhang Wu"
        },
        {
            "authorId": "2218552428",
            "name": "Yuchun Fan"
        },
        {
            "authorId": "2109452621",
            "name": "Chenglong Wang"
        },
        {
            "authorId": "2315465224",
            "name": "Hengyu Li"
        },
        {
            "authorId": "2315065015",
            "name": "Qiaozhi He"
        },
        {
            "authorId": "2314889364",
            "name": "Murun Yang"
        },
        {
            "authorId": "2261739712",
            "name": "Tong Xiao"
        },
        {
            "authorId": "2240940961",
            "name": "Jingbo Zhu"
        }
    ],
    "references": [
        {
            "paperId": "6cd88ba6ec5ca40a9bf901c89bcc4542407c2457",
            "title": "Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"
        },
        {
            "paperId": "dc0bd7d97507b269f7eec9a467b7c566239514c7",
            "title": "A Simple and Effective L2 Norm-Based Strategy for KV Cache Compression"
        },
        {
            "paperId": "812356c723c082f88fb722531beaf45e344ffa1e",
            "title": "PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling"
        },
        {
            "paperId": "2f96229c404a5cbd0c0d06492f5ea3d6bfcf50d2",
            "title": "PyramidInfer: Pyramid KV Cache Compression for High-throughput LLM Inference"
        },
        {
            "paperId": "8b8a7f1ac390a2394802234d3c539da86c56de66",
            "title": "Reducing Transformer Key-Value Cache Size with Cross-Layer Attention"
        },
        {
            "paperId": "1d4c48335d841014d0145256c3c4e7f6c426b8fb",
            "title": "You Only Cache Once: Decoder-Decoder Architectures for Language Models"
        },
        {
            "paperId": "53a803388e83ae89261624099d7be4287ace67cb",
            "title": "DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model"
        },
        {
            "paperId": "4c69d79c0ee7ac964284a75135b317d1ce7fb2d6",
            "title": "Keyformer: KV Cache Reduction through Key Tokens Selection for Efficient Generative Inference"
        },
        {
            "paperId": "b842b83a7ff5dff8e3b83915d8c15423b6085728",
            "title": "Gemma: Open Models Based on Gemini Research and Technology"
        },
        {
            "paperId": "7b46d6e2e00a4b4693dbadbbee3a2586bbae3c2f",
            "title": "CHAI: Clustered Head Attention for Efficient LLM Inference"
        },
        {
            "paperId": "7a54aad06171f59149aca5380863c62729c70b41",
            "title": "GEAR: An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM"
        },
        {
            "paperId": "874f1242b0ad04fb8757064dc0a5dd8de38913ff",
            "title": "Not all Layers of LLMs are Necessary during Inference"
        },
        {
            "paperId": "59a6d07fe7fb8fdf02cc8e914e0fd607f52acfb8",
            "title": "Introduction to Transformers: an NLP Perspective"
        },
        {
            "paperId": "95240dda409e28acccdc5cf619ad0c036cf4292d",
            "title": "Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time"
        },
        {
            "paperId": "abdb0f9d1486dbb024c4bc9f8f9dc40464c58715",
            "title": "Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning"
        },
        {
            "paperId": "6c323c535365e1c7cbfd9703cbec3b5650a3346b",
            "title": "Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs"
        },
        {
            "paperId": "fdc53c2c10742464087c0525f77e32604827a21d",
            "title": "Efficient Streaming Language Models with Attention Sinks"
        },
        {
            "paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0",
            "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"
        },
        {
            "paperId": "d6eeb2898bd9bd34744194ef543062dda6c4531a",
            "title": "Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time"
        },
        {
            "paperId": "5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200",
            "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints"
        },
        {
            "paperId": "57e849d0de13ed5f91d086936296721d4ff75a75",
            "title": "LLaMA: Open and Efficient Foundation Language Models"
        },
        {
            "paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e",
            "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"
        },
        {
            "paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221",
            "title": "OPT: Open Pre-trained Transformer Language Models"
        },
        {
            "paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea",
            "title": "Training Verifiers to Solve Math Word Problems"
        },
        {
            "paperId": "d20bcf41b772ea31a8ddd20317ee99fe7e1f32ca",
            "title": "Fine-Tuned Transformers Show Clusters of Similar Representations Across Layers"
        },
        {
            "paperId": "9933a5af7895354087baf6c96b64dc8a8973eaed",
            "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs"
        },
        {
            "paperId": "dd0a27aa2285bc64798fa76944400ab6d9ce3025",
            "title": "NAS-BERT: Task-Agnostic and Adaptive-Size BERT Compression with Neural Architecture Search"
        },
        {
            "paperId": "1d3dd6a85ef874a328d34305b884eac5113e292d",
            "title": "Think you have Solved Direct-Answer Question Answering? Try ARC-DA, the Direct-Answer AI2 Reasoning Challenge"
        },
        {
            "paperId": "7b8f3f65a98340d6e5ab94bd9a4ccb8f75704fd8",
            "title": "I-BERT: Integer-only BERT Quantization"
        },
        {
            "paperId": "72ee114292dd4c37e79ca4994ea89d710033905f",
            "title": "Revisiting Linformer with a modified self-attention with linear complexity"
        },
        {
            "paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d",
            "title": "Rethinking Attention with Performers"
        },
        {
            "paperId": "1d194274f2db9fc43adc1b93f31ff2800c9c8db6",
            "title": "An efficient framework for counting pedestrians crossing a line using low-cost devices: the benefits of distilling the knowledge in a neural network"
        },
        {
            "paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678",
            "title": "Measuring Massive Multitask Language Understanding"
        },
        {
            "paperId": "6f68e1bb253925d8431588555d3010419f322e04",
            "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"
        },
        {
            "paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
            "title": "Linformer: Self-Attention with Linear Complexity"
        },
        {
            "paperId": "ef8d788a904ed66bd8e30ffa69bc3ea1fe57dda7",
            "title": "HAT: Hardware-Aware Transformers for Efficient Natural Language Processing"
        },
        {
            "paperId": "66f0f35fc78bdf2af9de46093d49a428970cde2e",
            "title": "Movement Pruning: Adaptive Sparsity by Fine-Tuning"
        },
        {
            "paperId": "1bd7d2932de819ed1087b6453ef2c0be9f781ac1",
            "title": "ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context"
        },
        {
            "paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d",
            "title": "ETC: Encoding Long and Structured Inputs in Transformers"
        },
        {
            "paperId": "159dc82a5ee901716b0154051988b5408acfc861",
            "title": "LadaBERT: Lightweight Adaptation of BERT through Hybrid Model Compression"
        },
        {
            "paperId": "2573af4e13d9a5dddb257d22cd38a600528d9a8b",
            "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"
        },
        {
            "paperId": "657329c633709dd1ac34a30d57341b186b1a47c2",
            "title": "Efficient Content-Based Sparse Attention with Routing Transformers"
        },
        {
            "paperId": "d9b824dbecbe3a1f0b1489f9e4521a532a63818d",
            "title": "Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning"
        },
        {
            "paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45",
            "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"
        },
        {
            "paperId": "dc52b09089704ebd6f471177474bc29741c50023",
            "title": "Fast Transformer Decoding: One Write-Head is All You Need"
        },
        {
            "paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3",
            "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"
        },
        {
            "paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b",
            "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"
        },
        {
            "paperId": "f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1",
            "title": "Reducing Transformer Depth on Demand with Structured Dropout"
        },
        {
            "paperId": "0cbf97173391b0430140117027edcaf1a37968c7",
            "title": "TinyBERT: Distilling BERT for Natural Language Understanding"
        },
        {
            "paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d",
            "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"
        },
        {
            "paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0",
            "title": "Natural Questions: A Benchmark for Question Answering Research"
        },
        {
            "paperId": "6b2704fd8517a9917cfd9d3735930be48717d3de",
            "title": "Sharing Attention Weights for Fast Transformer"
        },
        {
            "paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583",
            "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"
        },
        {
            "paperId": "b03c7ff961822183bab66b2e594415e585d3fd09",
            "title": "Are Sixteen Heads Really Better than One?"
        },
        {
            "paperId": "9770fff7379a7ab9006b48939462354dda9a2053",
            "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"
        },
        {
            "paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad",
            "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"
        },
        {
            "paperId": "990a7b4eceedb6e053e6386269481bdfc42a1094",
            "title": "CoQA: A Conversational Question Answering Challenge"
        },
        {
            "paperId": "1536e8958697c5364f68b2e2448905dbbeb3a0ca",
            "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering"
        },
        {
            "paperId": "6e45251b16cd423f3c025f004959c6d2b26efab0",
            "title": "Accelerating Neural Transformer via an Average Attention Network"
        },
        {
            "paperId": "82c8dedbd58a8a8b7031dc49ce57553231fb3ca4",
            "title": "Learning Deep Representations with Probabilistic Knowledge Transfer"
        },
        {
            "paperId": "c52ac453e154953abdb06fc041023e327ea609a4",
            "title": "Self-Attentional Acoustic Models"
        },
        {
            "paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329",
            "title": "Image Transformer"
        },
        {
            "paperId": "9f58a7e844cd15d8aef8b2de7f246979ababe429",
            "title": "Paraphrasing Complex Network: Network Compression via Factor Transfer"
        },
        {
            "paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9",
            "title": "Generating Wikipedia by Summarizing Long Sequences"
        },
        {
            "paperId": "3a6d4cd0768ae8768e733280d362bdb4d25924e7",
            "title": "The Reversible Residual Network: Backpropagation Without Storing Activations"
        },
        {
            "paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c",
            "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"
        },
        {
            "paperId": "896de8418884f4aab1ae4a60027500c9e8baffc3",
            "title": "BranchyNet: Fast inference via early exiting from deep neural networks"
        },
        {
            "paperId": "5ed791f810da580c78df6a052c6b9f2e258f6b0a",
            "title": "The LAMBADA dataset: Word prediction requiring a broad discourse context"
        },
        {
            "paperId": "93499a7c7f699b6630a86fad964536f9423bb6d0",
            "title": "Effective Approaches to Attention-based Neural Machine Translation"
        },
        {
            "paperId": "8604f376633af8b347e31d84c6150a93b11e34c2",
            "title": "FitNets: Hints for Thin Deep Nets"
        },
        {
            "paperId": "c0ac73f8cb1630cddc9c8f953ed4d30a6cb6a5b4",
            "title": "Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
        },
        {
            "paperId": "b8b45b14df9029562b8995c6ab7fd90a8810f312",
            "title": "GPT3.int8(): 8-bit Matrix Multiplication for Transformers at Scale"
        },
        {
            "paperId": null,
            "title": "A3: Accelerating attention mechanisms in neural"
        },
        {
            "paperId": null,
            "title": "Reformer: The efficient trans-former"
        },
        {
            "paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28",
            "title": "An Adversarial Winograd Schema Challenge at Scale"
        },
        {
            "paperId": "9405cc0d6169988371b2755e573cc28650d14dfe",
            "title": "Language Models are Unsupervised Multitask Learners"
        },
        {
            "paperId": "d0961cec97320f3ea5f0f4088bedaa81e35cdcbb",
            "title": "INTERSPEECH 2014 15th Annual Conference of the International Speech Communication Association"
        },
        {
            "paperId": "c87d57da3b1f2b467ef4995d30df832ee2281107",
            "title": "On robust estimation of the location parameter"
        },
        {
            "paperId": null,
            "title": "2023. Stanford alpaca: An instruction-following llama model"
        },
        {
            "paperId": null,
            "title": "2023. Split computing and early exiting for deep learning applications: Survey and research challenges"
        },
        {
            "paperId": null,
            "title": "2022. Chain-of-thought prompting elicits reasoning in large language models"
        },
        {
            "paperId": null,
            "title": "ECCV 2018 - 15th European Conference, Mu-nich, Germany, September 8-14"
        },
        {
            "paperId": null,
            "title": "2023. One wide feedforward is all you need"
        },
        {
            "paperId": null,
            "title": "Together Computer. 2023. Redpajama: An open source recipe to reproduce"
        },
        {
            "paperId": null,
            "title": "2024. Minicache: KV cache compression in depth dimension for large language models"
        },
        {
            "paperId": null,
            "title": "networks with approximation"
        },
        {
            "paperId": null,
            "title": "2023. A framework for few-shot language model evaluation"
        },
        {
            "paperId": null,
            "title": "2023. H2O: heavy-hitter oracle for efficient generative inference of large language models"
        },
        {
            "paperId": null,
            "title": "2024. The unreasonable inef-fectiveness of the deeper layers"
        },
        {
            "paperId": null,
            "title": "2022. An algorithm-hardware co-optimized framework for accelerating N: M sparse trans-formers"
        },
        {
            "paperId": null,
            "title": "2022. Few-shot task-agnostic neural architecture search for distilling large language models"
        }
    ]
}