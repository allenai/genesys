{
    "paperId": "1a638e5752e386612406d0479b7bad94877be8cb",
    "externalIds": {
        "ArXiv": "2408.07666",
        "CorpusId": 271865581
    },
    "title": "Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities",
    "abstract": "Model merging is an efficient empowerment technique in the machine learning community that does not require the collection of raw training data and does not require expensive computation. As model merging becomes increasingly prevalent across various fields, it is crucial to understand the available model merging techniques comprehensively. However, there is a significant gap in the literature regarding a systematic and thorough review of these techniques. This survey provides a comprehensive overview of model merging methods and theories, their applications in various domains and settings, and future research directions. Specifically, we first propose a new taxonomic approach that exhaustively discusses existing model merging methods. Secondly, we discuss the application of model merging techniques in large language models, multimodal large language models, and 10+ machine learning subfields, including continual learning, multi-task learning, few-shot learning, etc. Finally, we highlight the remaining challenges of model merging and discuss future research directions. A comprehensive list of papers about model merging is available at \\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}.",
    "venue": "",
    "year": 2024,
    "referenceCount": 242,
    "citationCount": 3,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "A new taxonomic approach is proposed that exhaustively discusses existing model merging methods and theories and discusses the application of model merging techniques in large language models, multimodal large language models, and 10+ machine learning subfields."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -2.248915433883667,
            -1.5789356231689453,
            0.32159411907196045,
            3.966212272644043,
            -0.9849275946617126,
            -1.2346248626708984,
            2.2418837547302246,
            -0.35491943359375,
            -3.304348945617676,
            1.5983099937438965,
            -2.399911880493164,
            4.484127044677734,
            -1.6125963926315308,
            0.19098442792892456,
            -2.473076343536377,
            1.7446086406707764,
            2.639444351196289,
            -1.9191877841949463,
            3.6951708793640137,
            0.5747010707855225,
            -2.1283955574035645,
            3.6253342628479004,
            -1.0545858144760132,
            -2.608926773071289,
            3.277517318725586,
            -2.133671998977661,
            2.9023613929748535,
            1.6692793369293213,
            -2.4515976905822754,
            1.3027558326721191,
            -0.190418541431427,
            -5.500594139099121,
            5.909306526184082,
            -5.51557731628418,
            2.4863498210906982,
            -4.911612510681152,
            -1.370507001876831,
            8.050651550292969,
            -1.5184965133666992,
            -0.5799958109855652,
            -0.7351993322372437,
            -2.103457450866699,
            2.8182854652404785,
            -0.04798761010169983,
            1.707303762435913,
            0.34543275833129883,
            -0.4034620523452759,
            1.6059179306030273,
            -0.04482388496398926,
            0.7432909607887268,
            -0.2772366404533386,
            -1.6809535026550293,
            1.3788251876831055,
            0.10880495607852936,
            0.004144251346588135,
            -0.5381075143814087,
            2.897028684616089,
            3.016312837600708,
            2.5501914024353027,
            -2.5451741218566895,
            6.580332279205322,
            5.7849836349487305,
            -2.0703418254852295,
            3.748518228530884,
            4.636723518371582,
            -1.5864861011505127,
            -4.924354553222656,
            1.0239778757095337,
            1.5180649757385254,
            -1.75331449508667,
            -0.680437445640564,
            -4.782312393188477,
            3.2923312187194824,
            2.1617050170898438,
            -2.329338550567627,
            -0.28154313564300537,
            -0.6330694556236267,
            -6.255283355712891,
            -3.914137363433838,
            -2.007591485977173,
            2.3737354278564453,
            2.2491211891174316,
            2.45241641998291,
            1.4463987350463867,
            3.5391736030578613,
            -0.4385851323604584,
            -3.6523191928863525,
            0.3667270541191101,
            0.8389603495597839,
            -3.6245806217193604,
            -4.159653663635254,
            2.8429059982299805,
            -1.252138376235962,
            2.455977201461792,
            -4.123770236968994,
            -0.14268875122070312,
            -0.2203267514705658,
            -0.16617050766944885,
            -4.308279991149902,
            0.6317932605743408,
            5.755548000335693,
            -3.3063273429870605,
            1.2558619976043701,
            0.10474562644958496,
            3.5398287773132324,
            -5.458944797515869,
            2.7839462757110596,
            -0.2782681882381439,
            -0.3763880729675293,
            0.691184401512146,
            -0.9484876394271851,
            4.057324409484863,
            -0.05639392137527466,
            -2.3115973472595215,
            -1.5928735733032227,
            -1.9057278633117676,
            -1.2428840398788452,
            1.4828157424926758,
            -1.9729092121124268,
            3.573493242263794,
            0.3193020522594452,
            0.6498477458953857,
            -4.465536594390869,
            2.859781265258789,
            2.4983901977539062,
            1.9688986539840698,
            0.5429492592811584,
            -1.8111603260040283,
            -0.8513318300247192,
            -3.2147669792175293,
            2.636354446411133,
            -3.065319061279297,
            5.868758201599121,
            -1.9151687622070312,
            1.2646591663360596,
            5.937256336212158,
            -5.845946311950684,
            2.8128061294555664,
            -2.7950191497802734,
            -1.745316743850708,
            0.9431120753288269,
            6.867812156677246,
            2.676852226257324,
            -2.2496891021728516,
            0.26675188541412354,
            4.735334873199463,
            0.3672511875629425,
            -4.045116424560547,
            2.559725761413574,
            5.043081283569336,
            0.8622885346412659,
            -3.1480393409729004,
            1.4132640361785889,
            1.1615899801254272,
            3.6599650382995605,
            5.441338539123535,
            -2.5773568153381348,
            2.3880679607391357,
            -0.6364800333976746,
            0.23331938683986664,
            -2.8315908908843994,
            2.795466423034668,
            -7.982443809509277,
            0.09251773357391357,
            4.201478004455566,
            -8.193819046020508,
            -3.1919143199920654,
            4.820159912109375,
            -1.8379281759262085,
            2.896099090576172,
            0.43166467547416687,
            2.3688924312591553,
            1.7174434661865234,
            4.128092288970947,
            -1.7825438976287842,
            0.5001267194747925,
            0.44325241446495056,
            -4.227848052978516,
            -0.8357477188110352,
            1.189305067062378,
            -1.8548774719238281,
            1.039373755455017,
            -5.759751796722412,
            0.3826809525489807,
            -1.432877540588379,
            0.22863060235977173,
            -4.179194927215576,
            -4.7304487228393555,
            -1.241837978363037,
            0.41301634907722473,
            -1.3024852275848389,
            0.4285922944545746,
            2.5361533164978027,
            3.2931079864501953,
            7.130487442016602,
            2.7685160636901855,
            4.801845550537109,
            2.178420066833496,
            -1.9243618249893188,
            0.15028291940689087,
            3.623154640197754,
            -2.0792481899261475,
            -0.875551700592041,
            -3.3972887992858887,
            3.5530755519866943,
            1.7636055946350098,
            -2.0460281372070312,
            5.605120658874512,
            0.8098666667938232,
            -0.43161243200302124,
            3.0188238620758057,
            -0.30805647373199463,
            -3.673464775085449,
            2.026594638824463,
            -4.240768909454346,
            -1.2228703498840332,
            -6.146556854248047,
            5.39941930770874,
            2.5261497497558594,
            2.647627592086792,
            -1.4057888984680176,
            -1.5079188346862793,
            0.24223801493644714,
            -2.8259823322296143,
            1.6503725051879883,
            -4.334352493286133,
            1.2206257581710815,
            0.9387356042861938,
            -1.0101335048675537,
            1.135547399520874,
            -3.299898624420166,
            -4.62101411819458,
            -1.417182207107544,
            0.9598201513290405,
            -4.910735130310059,
            -1.5116026401519775,
            -7.626916885375977,
            2.4275169372558594,
            -5.48541259765625,
            -1.0354232788085938,
            6.055115699768066,
            1.0911939144134521,
            -1.2801876068115234,
            3.2408652305603027,
            5.0111589431762695,
            -2.1067442893981934,
            -2.810479164123535,
            0.6968709230422974,
            -2.1917269229888916,
            -0.19999784231185913,
            0.6911085844039917,
            0.7645664215087891,
            3.34737491607666,
            -0.7663666009902954,
            1.071649193763733,
            1.534731388092041,
            3.618130922317505,
            -1.3172093629837036,
            2.222165822982788,
            2.934131145477295,
            0.6070542335510254,
            4.519527435302734,
            0.4920274615287781,
            2.058717966079712,
            -0.7810298204421997,
            -2.376295566558838,
            -4.7889790534973145,
            -0.9791672229766846,
            -0.9903321266174316,
            3.24062442779541,
            0.47028160095214844,
            0.4492112994194031,
            0.37048304080963135,
            -4.894336700439453,
            -1.7912667989730835,
            -8.21396255493164,
            -2.6842217445373535,
            -0.32471656799316406,
            -0.07137131690979004,
            0.9482530951499939,
            -0.18124833703041077,
            -1.1101306676864624,
            0.7904885411262512,
            0.0878785252571106,
            -1.793004035949707,
            -3.9241912364959717,
            -0.31536298990249634,
            1.2732182741165161,
            -1.084902048110962,
            -0.5687610507011414,
            -2.7186360359191895,
            5.904641151428223,
            -3.594287872314453,
            -2.3126397132873535,
            0.3391382098197937,
            3.9386706352233887,
            1.4746363162994385,
            -0.8071563243865967,
            0.7099326848983765,
            0.23406654596328735,
            -0.38147133588790894,
            2.3529281616210938,
            5.035774230957031,
            0.0922473669052124,
            1.4752676486968994,
            4.984147071838379,
            0.21320748329162598,
            1.029422640800476,
            0.41860878467559814,
            -0.26664572954177856,
            -1.0686118602752686,
            2.395815849304199,
            3.026531934738159,
            -5.339147567749023,
            -0.3926581144332886,
            3.4751875400543213,
            0.37031736969947815,
            0.507758617401123,
            -4.800772666931152,
            3.927570343017578,
            0.51511549949646,
            -0.8489335775375366,
            -3.4736547470092773,
            -4.200399398803711,
            -2.62070894241333,
            2.1615052223205566,
            -0.34214508533477783,
            4.459327697753906,
            -4.890081405639648,
            1.3420284986495972,
            0.3032190799713135,
            2.349515914916992,
            2.909174680709839,
            2.2811551094055176,
            -1.5182486772537231,
            -3.0151777267456055,
            -1.287337303161621,
            -2.434020519256592,
            4.3795270919799805,
            2.8139522075653076,
            5.6373610496521,
            5.837683200836182,
            -1.3629931211471558,
            1.9330462217330933,
            -2.7041358947753906,
            -0.33519798517227173,
            0.8821077346801758,
            -3.2111310958862305,
            -1.4720908403396606,
            -3.564343214035034,
            -0.43015503883361816,
            1.7040396928787231,
            2.3744897842407227,
            0.13357090950012207,
            2.408731460571289,
            3.7659027576446533,
            -1.1843589544296265,
            -0.965779185295105,
            -0.9054087400436401,
            2.5513601303100586,
            -1.2248575687408447,
            0.3601542115211487,
            3.2188329696655273,
            1.8087096214294434,
            0.1992495059967041,
            -5.132183074951172,
            12.965210914611816,
            -5.630804061889648,
            -0.3551185727119446,
            -4.286571025848389,
            -3.2492337226867676,
            -4.884842872619629,
            -4.288146018981934,
            3.107402801513672,
            -4.644081115722656,
            -4.557088851928711,
            0.24499154090881348,
            -3.6844282150268555,
            4.2391204833984375,
            3.9453635215759277,
            -0.9395329356193542,
            4.413140296936035,
            -3.3082292079925537,
            2.6524250507354736,
            -1.0656938552856445,
            1.275273084640503,
            -3.084798812866211,
            4.1739349365234375,
            0.1704731285572052,
            4.2104620933532715,
            -0.10386122018098831,
            0.8660853505134583,
            -1.7809109687805176,
            2.99542236328125,
            -2.6462013721466064,
            -3.5694026947021484,
            0.3938175439834595,
            -2.440166473388672,
            1.0405027866363525,
            1.1552979946136475,
            0.2170487940311432,
            1.6137914657592773,
            3.260777711868286,
            4.288161277770996,
            -4.922158241271973,
            -0.47094860672950745,
            2.235116958618164,
            -0.15618479251861572,
            -0.7230751514434814,
            2.0676326751708984,
            -2.1099178791046143,
            -4.4159369468688965,
            -1.382450819015503,
            -6.142694473266602,
            -0.9352163076400757,
            -1.1605238914489746,
            1.3489766120910645,
            1.8093494176864624,
            4.486367702484131,
            0.053854867815971375,
            -3.0865697860717773,
            2.850607395172119,
            4.319321632385254,
            2.7837204933166504,
            -0.7798758149147034,
            0.16070979833602905,
            0.701596736907959,
            2.9872145652770996,
            0.28590208292007446,
            4.943765640258789,
            0.06544965505599976,
            5.382584571838379,
            -3.648258924484253,
            -1.3991961479187012,
            -1.163732886314392,
            2.2273213863372803,
            2.0093884468078613,
            0.7956901788711548,
            3.405787706375122,
            -3.4485206604003906,
            2.003619909286499,
            1.8820549249649048,
            -1.5204553604125977,
            6.750084400177002,
            1.5467609167099,
            1.111217737197876,
            0.5653706789016724,
            5.455733776092529,
            -4.024084091186523,
            -1.814627766609192,
            5.527836799621582,
            -0.5696793794631958,
            -4.041340351104736,
            -4.61443567276001,
            0.20645558834075928,
            1.8943133354187012,
            -2.420210838317871,
            0.5723322629928589,
            1.090759515762329,
            0.15297088027000427,
            -3.7473855018615723,
            1.8242309093475342,
            -1.5484952926635742,
            1.6862250566482544,
            2.2704529762268066,
            2.196024179458618,
            -0.5392080545425415,
            -0.48431330919265747,
            -0.014567345380783081,
            3.0593814849853516,
            3.222278118133545,
            -1.639182209968567,
            -3.2427353858947754,
            -0.2056494653224945,
            -2.5079338550567627,
            0.11376893520355225,
            1.2502191066741943,
            1.876757264137268,
            3.118276357650757,
            -4.520300388336182,
            -3.601839065551758,
            -2.635685682296753,
            3.0565035343170166,
            -1.2978767156600952,
            -0.5402860045433044,
            3.862457513809204,
            2.997828483581543,
            1.6302664279937744,
            3.98014760017395,
            -0.8020095825195312,
            0.35846078395843506,
            3.417144775390625,
            1.3117836713790894,
            0.20520687103271484,
            -2.536146640777588,
            -0.6757601499557495,
            -6.637700080871582,
            4.721011638641357,
            0.9912886619567871,
            1.3649086952209473,
            -3.1262545585632324,
            -5.789836406707764,
            3.148151397705078,
            0.4729633927345276,
            -4.33073616027832,
            4.318906784057617,
            7.30568790435791,
            -2.487590789794922,
            -1.945230484008789,
            0.40791893005371094,
            -2.6937403678894043,
            -0.12178274989128113,
            -6.021256923675537,
            1.5693812370300293,
            -2.412853240966797,
            -1.8732184171676636,
            3.7619073390960693,
            2.0894699096679688,
            -2.3802380561828613,
            0.12047052383422852,
            0.24070917069911957,
            -0.8072667121887207,
            -0.12093091011047363,
            1.2776603698730469,
            1.7018444538116455,
            0.23755328357219696,
            -4.724855422973633,
            5.039163112640381,
            1.548581600189209,
            2.9840784072875977,
            5.198663234710693,
            3.558182716369629,
            3.478618860244751,
            -5.593747138977051,
            0.657548189163208,
            -1.9123127460479736,
            1.1501811742782593,
            2.7309787273406982,
            -4.041562557220459,
            -1.1496222019195557,
            -0.9007222652435303,
            -0.6688628196716309,
            0.8749158382415771,
            5.323390007019043,
            -0.7729985117912292,
            3.5079991817474365,
            -4.838199138641357,
            -2.850006341934204,
            -1.1420570611953735,
            0.8485243320465088,
            2.063553810119629,
            -3.9974918365478516,
            5.5400004386901855,
            -1.3852230310440063,
            -0.16820484399795532,
            1.8123774528503418,
            0.43535101413726807,
            -2.472655773162842,
            0.6482053995132446,
            1.7899760007858276,
            1.45989191532135,
            -0.9203273057937622,
            -0.023885361850261688,
            5.483710765838623,
            0.11706730723381042,
            1.1900807619094849,
            -3.085245132446289,
            4.6778974533081055,
            -0.8200230598449707,
            0.23342055082321167,
            -0.9987890720367432,
            -1.9900153875350952,
            1.4062376022338867,
            -0.46559303998947144,
            -1.4058496952056885,
            1.9934005737304688,
            4.265289783477783,
            -2.1041314601898193,
            -2.601546287536621,
            -1.6205991506576538,
            -4.654740810394287,
            -1.6977458000183105,
            -2.644293785095215,
            -3.3424978256225586,
            1.2560310363769531,
            -2.9977760314941406,
            -1.0094678401947021,
            1.2358598709106445,
            -5.869326591491699,
            0.8510851860046387,
            5.611827850341797,
            0.13118547201156616,
            0.940026581287384,
            -0.8488574028015137,
            -0.0386127233505249,
            -3.240522623062134,
            3.0825400352478027,
            3.488173007965088,
            0.4993748068809509,
            1.675752878189087,
            1.5472079515457153,
            1.7699073553085327,
            2.2231154441833496,
            2.414872169494629,
            -3.329972267150879,
            -2.839991331100464,
            1.6294186115264893,
            -0.9267074465751648,
            -1.7250299453735352,
            1.849602222442627,
            -0.9576560258865356,
            3.14254093170166,
            18.26329803466797,
            -0.4300025403499603,
            -1.6329864263534546,
            -1.823934555053711,
            -2.938504695892334,
            -4.053117275238037,
            -1.720999002456665,
            -0.474972128868103,
            -0.19239568710327148,
            0.637947678565979,
            0.2280895709991455,
            -3.4916136264801025,
            1.8028502464294434,
            1.8641741275787354,
            -1.2230805158615112,
            -2.5586745738983154,
            -2.0174784660339355,
            -0.46054771542549133,
            -0.7874913811683655,
            -0.2774337828159332,
            0.919318437576294,
            0.24835628271102905,
            0.8877063989639282,
            -3.3588645458221436,
            -2.7958340644836426,
            1.2329479455947876,
            4.078586101531982,
            1.4062387943267822,
            -2.3969004154205322,
            -1.9940125942230225,
            1.195826768875122,
            2.578751564025879,
            0.356589674949646,
            -2.1412293910980225,
            -3.518263339996338,
            4.777186393737793,
            2.1505908966064453,
            -2.148754358291626,
            2.466118097305298,
            1.8187257051467896,
            0.08050775527954102,
            2.3410067558288574,
            -2.6558568477630615,
            2.2647407054901123,
            -1.2017388343811035,
            -1.2024515867233276,
            3.4479012489318848,
            -1.6840471029281616,
            -2.733001708984375,
            4.935304641723633,
            -3.4285004138946533,
            -2.2664952278137207,
            -0.9314224720001221,
            -3.1499500274658203,
            4.936673164367676,
            -2.100159168243408,
            -0.9701216220855713,
            -3.7554335594177246,
            -0.01914331316947937,
            -0.04035097360610962,
            -0.4978455603122711,
            1.2839927673339844,
            -3.4750189781188965,
            -5.710081577301025,
            -4.5455322265625,
            -2.791937828063965,
            -5.07863187789917,
            4.550702095031738,
            2.599672794342041,
            1.4165579080581665,
            0.2513020634651184,
            1.6924786567687988,
            0.239346444606781,
            -3.6047768592834473,
            0.9117316007614136,
            -4.056243896484375,
            3.9802417755126953,
            -1.3154658079147339,
            0.9268553256988525,
            6.10492467880249,
            -0.6842856407165527,
            3.467574119567871,
            -2.853156089782715,
            -1.0795844793319702,
            4.58705997467041,
            -3.079110622406006,
            3.3412694931030273,
            -0.7039990425109863,
            -1.0397052764892578,
            5.548183917999268,
            -1.6532649993896484,
            1.286441445350647,
            2.7929954528808594,
            5.161696434020996,
            2.8114402294158936,
            -5.645719528198242,
            -4.502891540527344,
            -2.067695379257202,
            -2.135234832763672,
            -3.4837160110473633,
            4.218108654022217,
            2.8167717456817627,
            1.4656506776809692,
            -1.5549066066741943,
            1.0564095973968506,
            0.1080198585987091,
            -1.6078498363494873,
            -7.260310173034668,
            -2.6206564903259277,
            -2.7308754920959473,
            2.2886195182800293,
            -1.4444819688796997,
            -2.1285128593444824,
            1.2190406322479248,
            3.7265806198120117,
            -1.3530936241149902,
            1.56401526927948,
            0.15419548749923706,
            1.0054943561553955,
            5.2452216148376465,
            1.2881090641021729,
            0.4221230745315552,
            1.4938684701919556,
            -3.1444172859191895,
            -0.05030667781829834,
            0.33646899461746216,
            0.4573964476585388,
            -2.089984178543091,
            -1.397100567817688,
            -0.6130808591842651,
            2.7915029525756836,
            -0.08332572877407074,
            -2.158782720565796,
            1.0642359256744385,
            -0.10931754112243652,
            -1.3472847938537598,
            -0.43320485949516296,
            -0.33380743861198425,
            -0.22815173864364624,
            5.120704650878906,
            0.015679597854614258,
            -2.4387898445129395,
            -0.8683101534843445,
            7.955849647521973,
            1.8792551755905151,
            -2.0123085975646973,
            -1.8905925750732422,
            -0.7038119435310364,
            -2.0835824012756348,
            0.37506186962127686,
            1.828568458557129,
            1.687330722808838,
            2.8020076751708984,
            -2.7273945808410645,
            -2.8108279705047607,
            -2.3313653469085693
        ]
    },
    "authors": [
        {
            "authorId": "151497321",
            "name": "Enneng Yang"
        },
        {
            "authorId": "2279871211",
            "name": "Li Shen"
        },
        {
            "authorId": "2237427680",
            "name": "Guibing Guo"
        },
        {
            "authorId": "2237603955",
            "name": "Xingwei Wang"
        },
        {
            "authorId": "2316150631",
            "name": "Xiaochun Cao"
        },
        {
            "authorId": "2316176138",
            "name": "Jie Zhang"
        },
        {
            "authorId": "2135519749",
            "name": "Dacheng Tao"
        }
    ],
    "references": [
        {
            "paperId": "292233bff38fe6e8336ce55619ef5513dc63b359",
            "title": "Localize-and-Stitch: Efficient Model Merging via Sparse Task Arithmetic"
        },
        {
            "paperId": "f2ae2e34358f073f9d6150ea299ef32dc4040ca5",
            "title": "Activated Parameter Locating via Causal Intervention for Model Merging"
        },
        {
            "paperId": "30e33e9ec257a60d8f095a285f31c702511db04a",
            "title": "FuseChat: Knowledge Fusion of Chat Models"
        },
        {
            "paperId": "daaff30d9c716cd5ce747774f2057eb248185615",
            "title": "BadMerging: Backdoor Attacks Against Model Merging"
        },
        {
            "paperId": "7e05833d34eb3dd9a3a4d8eff8a83dfcef2f1804",
            "title": "Extend Model Merging from Fine-Tuned to Pre-Trained Large Language Models via Weight Disentanglement"
        },
        {
            "paperId": "23dd61ae65124c232d3efa78899fe0636644bda9",
            "title": "Task Prompt Vectors: Effective Initialization through Multi-Task Soft-Prompt Transfer"
        },
        {
            "paperId": "9ebfa722bb57091f990663519c496d70b12aeb84",
            "title": "Strong Copyright Protection for Language Models via Adaptive Model Fusion"
        },
        {
            "paperId": "64315f6368a31b0114d3ca3bc52bfc796295241d",
            "title": "Conditioned Language Policy: A General Framework for Steerable Multi-Objective Finetuning"
        },
        {
            "paperId": "23ab3d52e6a45cb5abfb2648488b7b37efde238f",
            "title": "Training-Free Model Merging for Multi-target Domain Adaptation"
        },
        {
            "paperId": "2018a64911680af735172e3bab2719a80927279f",
            "title": "Mitigating Catastrophic Forgetting in Language Transfer via Model Merging"
        },
        {
            "paperId": "3d834001f5ba5506bfc97aa37a0544cabdb45c0b",
            "title": "Fine-Tuning Linear Layers Only Is a Simple yet Effective Way for Task Arithmetic"
        },
        {
            "paperId": "f3c88571ad81badbaad9bb4327a9f3213b69ae1c",
            "title": "MagMax: Leveraging Model Merging for Seamless Continual Learning"
        },
        {
            "paperId": "32eb03c411272a50f2ebddca2df036aab325ed79",
            "title": "Harmony in Diversity: Merging Neural Networks with Canonical Correlation Analysis"
        },
        {
            "paperId": "d4e675cee154fb34db8514d68792392a8bb14cef",
            "title": "Erasure Coded Neural Network Inference via Fisher Averaging"
        },
        {
            "paperId": "e2047ddf1ec753c336f45ce9234ddf06f431b115",
            "title": "Unlocking the Potential of Model Merging for Low-Resource Languages"
        },
        {
            "paperId": "58010e8428b08f2c3df7a2fb03c30af5bdf1ef9a",
            "title": "Knowledge Composition using Task Vectors with Learned Anisotropic Scaling"
        },
        {
            "paperId": "6f8d26bef8ac26f747a8bd9919109798f61eb0ed",
            "title": "DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging"
        },
        {
            "paperId": "1fd321f013a34dfe71ed8d7d85f8dc8af4dcccba",
            "title": "It's Morphing Time: Unleashing the Potential of Multiple LLMs via Multi-objective Optimization"
        },
        {
            "paperId": "67a247273c759afe4e0c0a38abfd5b6250d11f6e",
            "title": "Adaptive Stochastic Weight Averaging"
        },
        {
            "paperId": "a811a75cc40441224971da90ec2a6c30886028e1",
            "title": "PAFT: A Parallel Training Paradigm for Effective LLM Fine-Tuning"
        },
        {
            "paperId": "aef234095eb56f3510737df572fd155668523bb0",
            "title": "WARP: On the Benefits of Weight Averaged Rewarded Policies"
        },
        {
            "paperId": "181fbb9f6e7765e05a7b90f024e10739e33536fe",
            "title": "Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs"
        },
        {
            "paperId": "4a20c3d273537272fde9cc9a0d937f914fc2a0dd",
            "title": "DEM: Distribution Edited Model for Training with Mixed Data Distributions"
        },
        {
            "paperId": "548881f1e934ea87c47f2b0facf4665ac306a7c0",
            "title": "Model Merging and Safety Alignment: One Bad Model Spoils the Bunch"
        },
        {
            "paperId": "46d90cddb7724f312cd9b35be92b3cb26920bb14",
            "title": "Mitigating Social Biases in Language Models through Unlearning"
        },
        {
            "paperId": "652344ac5269e90105d6af9e7bd72665577fe8e6",
            "title": "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"
        },
        {
            "paperId": "84f4ed2029085d2e009e6f262537c4201738737e",
            "title": "Twin-Merging: Dynamic Integration of Modular Expertise in Model Merging"
        },
        {
            "paperId": "1398dbee03dfc2454fec5e4ff1c7e62900e8468e",
            "title": "Self-MoE: Towards Compositional Large Language Models with Self-Specialized Experts"
        },
        {
            "paperId": "90ba2852b80d440a5528f869515b6df6fe38fe36",
            "title": "DELLA-Merging: Reducing Interference in Model Merging through Magnitude-Based Sampling"
        },
        {
            "paperId": "4cfc877734987982e9cd2f16648c6a2e58b47042",
            "title": "Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations"
        },
        {
            "paperId": "b26b5abbf765382d7a16c077a49bf1346e5f794f",
            "title": "Avoiding Copyright Infringement via Machine Unlearning"
        },
        {
            "paperId": "5456c327e73cfd64e354e75891bba8e547711451",
            "title": "Towards Efficient Pareto Set Approximation via Mixture of Experts Based Model Fusion"
        },
        {
            "paperId": "b01388f167b4363586a1da98176231a45e527be4",
            "title": "Diffusion Soup: Model Merging for Text-to-Image Diffusion Models"
        },
        {
            "paperId": "48c728bc4c61f931d8af84b90c58af4e5eff62ad",
            "title": "Merging Improves Self-Critique Against Jailbreak Attacks"
        },
        {
            "paperId": "c51c550cc3dbac1222799a7397bf4d26daf35a7a",
            "title": "MAP: Low-compute Model Merging with Amortized Pareto Fronts via Quadratic Approximation"
        },
        {
            "paperId": "da32540149b1d542baa83939d00da5c6baa64fd0",
            "title": "FusionBench: A Comprehensive Benchmark of Deep Model Fusion"
        },
        {
            "paperId": "9c9ca3a8320c0babd9fc331cc376ffff32fe1f67",
            "title": "Online Merging Optimizers for Boosting Rewards and Mitigating Tax in Alignment"
        },
        {
            "paperId": "e52b6cff443d692bbecfc8a5c1f46ff19bb1a52c",
            "title": "C2M3: Cycle-Consistent Multi-Model Merging"
        },
        {
            "paperId": "72c0837c1d66b82dfc1434722ef374efbe334a4d",
            "title": "WASH: Train your Ensemble with Communication-Efficient Weight Shuffling, then Average"
        },
        {
            "paperId": "6e468253c99c37c6a1174850b80dec8b732dcd51",
            "title": "A Second-Order perspective on Compositionality and Incremental Learning"
        },
        {
            "paperId": "a26013ad73804f983ffcea44a6ead683400012fb",
            "title": "EMR-Merging: Tuning-Free High-Performance Model Merging"
        },
        {
            "paperId": "a0a463a43771abdc99471e1f0d823293ae89d59e",
            "title": "Disperse-Then-Merge: Pushing the Limits of Instruction Tuning via Alignment Tax Reduction"
        },
        {
            "paperId": "6839e8ef0205ad4732e9f743977eb5bfc296ec2c",
            "title": "Towards Modular LLMs by Building and Reusing a Library of LoRAs"
        },
        {
            "paperId": "097f407d01be7ecaf166f43008be1af003e47eff",
            "title": "A safety realignment framework via subspace-oriented model fusion for large language models"
        },
        {
            "paperId": "8b9f3344e585ebe14b3ed930ae337d4d84f50d27",
            "title": "Localizing Task Information for Improved Model Merging and Compression"
        },
        {
            "paperId": "de816b055631ec74ad02f4c8600828dfa01cee07",
            "title": "Weak-to-Strong Extrapolation Expedites Alignment"
        },
        {
            "paperId": "669666b2dccdaede5ccb266128d948c5165a575f",
            "title": "No Train but Gain: Language Arithmetic for training-free Language Adapters enhancement"
        },
        {
            "paperId": "e71f048677c18d876f394814f34384860e670549",
            "title": "DynaMMo: Dynamic Model Merging for Efficient Class Incremental Learning for Medical Images"
        },
        {
            "paperId": "50ee8942d8ef99ba97059903b38558e7da4a8e20",
            "title": "MaxFusion: Plug&Play Multi-Modal Generation in Text-to-Image Diffusion Models"
        },
        {
            "paperId": "def1312b504778a26736c3dc5d7405bf634e7929",
            "title": "Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging"
        },
        {
            "paperId": "6ac9a1da483b3f19f97f9b8272676eb648905348",
            "title": "Linear Combination of Saved Checkpoints Makes Consistency and Diffusion Models Better"
        },
        {
            "paperId": "04dcc984785f7c7b201acad6507c3fd06e552990",
            "title": "Model Stock: All we need is just a few fine-tuned models"
        },
        {
            "paperId": "a49f5b8d9c2731697163fe45a52f3ec9ba0e18eb",
            "title": "Checkpoint Merging via Bayesian Optimization in LLM Pretraining"
        },
        {
            "paperId": "ec77f8647563134d566df49863169e2eb5484b75",
            "title": "A Unified Module for Accelerating STABLE-DIFFUSION: LCM-LORA"
        },
        {
            "paperId": "97352d95cc1fd9b7d9e959d61dd751a619975bfe",
            "title": "Arcee's MergeKit: A Toolkit for Merging Large Language Models"
        },
        {
            "paperId": "828f98e0feba2baa55a5486f354fd074cca0880c",
            "title": "Evolutionary Optimization of Model Merging Recipes"
        },
        {
            "paperId": "94665ddaa6ca8b7fe6f19c392a72604c7396f1e8",
            "title": "FedFisher: Leveraging Fisher Information for One-Shot Federated Learning"
        },
        {
            "paperId": "a11f3f54a80da0eba6a6ff23f5ab61689b45fdb8",
            "title": "Fisher Mask Nodes for Language Model Merging"
        },
        {
            "paperId": "0ea10f2132233b4f5d7cf701300cd0055e93e2d8",
            "title": "Ethos: Rectifying Language Models in Orthogonal Parameter Space"
        },
        {
            "paperId": "d6f56f30ea976787bbbf15f71807d8d4358b5d88",
            "title": "DAM: Dynamic Adapter Merging for Continual Video QA Learning"
        },
        {
            "paperId": "07894aeadab9158fdb97647c4792816ede1b60b9",
            "title": "Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM"
        },
        {
            "paperId": "3cfa6f1bbfbfb7a0c58b11f8142f153630a4c17b",
            "title": "SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data"
        },
        {
            "paperId": "e4aaa2d641cb7a5f6d5d8523af39a1ed5bb8660b",
            "title": "Adaptive Discovering and Merging for Incremental Novel Class Discovery"
        },
        {
            "paperId": "d77527b74884ec647547d630839131f995dfb39f",
            "title": "Training-Free Pretrained Model Merging"
        },
        {
            "paperId": "0e92de315ecc3cd3d86e0e84047ed8368ece690f",
            "title": "LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario"
        },
        {
            "paperId": "bba9778411de8940585fc730a2836d45e2292875",
            "title": "AdaMergeX: Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging"
        },
        {
            "paperId": "cecf84ccb00e9de02a065605a7130f27e5595657",
            "title": "Does Combining Parameter-efficient Modules Improve Few-shot Transfer Accuracy?"
        },
        {
            "paperId": "1de5b29e746bb33113b80a0997ef61a73ce70d78",
            "title": "Model Composition for Multimodal Large Language Models"
        },
        {
            "paperId": "d9cfa9d7dabd39b66a8c11e5dde69ba45e91093d",
            "title": "Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic"
        },
        {
            "paperId": "a8c422a624ad846ac4d2074a98645d9eb2f364a8",
            "title": "Model Tailor: Mitigating Catastrophic Forgetting in Multi-modal Large Language Models"
        },
        {
            "paperId": "49259f30ccc0fafe6ad19c80cb18dee6ea5d3739",
            "title": "LoRA-Flow: Dynamic LoRA Fusion for Large Language Models in Generative Tasks"
        },
        {
            "paperId": "ec345204fb7a465f6263bd54270ecd6f459e48ca",
            "title": "LoraRetriever: Input-Aware LoRA Retrieval and Composition for Mixed Tasks in the Wild"
        },
        {
            "paperId": "5dd7c7654811a45f364ceca9fdbc2b4116e49eda",
            "title": "Towards Safer Large Language Models through Machine Unlearning"
        },
        {
            "paperId": "036d3ac1c22ce7058ae74d82b445290c8849561d",
            "title": "Learning to Route Among Specialized Experts for Zero-Shot Generalization"
        },
        {
            "paperId": "9a4f03d132869db4a05c6789a4a1076575e2258b",
            "title": "Representation Surgery for Multi-Task Model Merging"
        },
        {
            "paperId": "aa0f298397a7b9cc235bc122924c0179c7fd9350",
            "title": "Merging Multi-Task Models via Weight-Ensembling Mixture of Experts"
        },
        {
            "paperId": "67f03ac399693393116076c0b8ec8ea05b910685",
            "title": "WARM: On the Benefits of Weight Averaged Reward Models"
        },
        {
            "paperId": "4a776e757e46c0c41020cb15e574a62aceb20cf5",
            "title": "Instructional Fingerprinting of Large Language Models"
        },
        {
            "paperId": "8c1243e089621d09025e1e51e8e01cb2cb20eabf",
            "title": "Knowledge Fusion of Large Language Models"
        },
        {
            "paperId": "411114f989a3d1083d90afd265103132fee94ebe",
            "title": "Mixtral of Experts"
        },
        {
            "paperId": "643da291df79ceba036a2287b2f4a372fabe8ed0",
            "title": "Merging Vision Transformers from Different Tasks and Domains"
        },
        {
            "paperId": "ab7d320cbae173aef86c31faa087780cba44551f",
            "title": "SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling"
        },
        {
            "paperId": "d3375864a1490281c221c5a1ccad8c55c7fcbe1e",
            "title": "Multimodal Attention Merging for Improved Speech Recognition and Audio Event Classification"
        },
        {
            "paperId": "9a9cb8f557d381b7959510caee5f73dd3245db49",
            "title": "Model Breadcrumbs: Scaling Multi-Task Model Merging with Sparse Masks"
        },
        {
            "paperId": "192028b7f0b920ce19cedc2dadc5992d71bc8ff6",
            "title": "Concrete Subspace Learning based Interference Elimination for Multi-task Model Fusion"
        },
        {
            "paperId": "912df62f362eb0d42a3393898818196d6a6fd57a",
            "title": "Controlled Text Generation via Language Model Arithmetic"
        },
        {
            "paperId": "f284407feaf17923e1aff838b9b39fb10c74f1ed",
            "title": "LM-Cocktail: Resilient Tuning of Language Models via Model Merging"
        },
        {
            "paperId": "185e88645dfc07d6ca81a55dfc66bd3452400276",
            "title": "ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs"
        },
        {
            "paperId": "e118080d723a62560b56c91c78986b5da6aaf21f",
            "title": "Language and Task Arithmetic with Parameter-Efficient Layers for Zero-Shot Summarization"
        },
        {
            "paperId": "e0b3cdd6639cc702e106f708bd3ba934e646ffba",
            "title": "Forgetting before Learning: Utilizing Parametric Arithmetic for Knowledge Updating in Large Language Models"
        },
        {
            "paperId": "9d85ea26518bace986a2f7cdffa24edad2b20c87",
            "title": "Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion"
        },
        {
            "paperId": "c0230760f644f6b7538d93e4296a5e9aa7028e45",
            "title": "Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch"
        },
        {
            "paperId": "70bb5d11373625bd27cec8f0bce4e105d47850cd",
            "title": "Task Arithmetic with LoRA for Continual Learning"
        },
        {
            "paperId": "5fcb839799d6a009c3b1437394ae691b9bdc5383",
            "title": "Proving Linear Mode Connectivity of Neural Networks via Optimal Transport"
        },
        {
            "paperId": "94cdb1d4167af68e6f9adb3ac483d2b0b8380f97",
            "title": "Equivariant Deep Weight Space Alignment"
        },
        {
            "paperId": "210bb7976a0d53377185141241bc3eae994a4833",
            "title": "Model Merging by Uncertainty-Based Gradient Matching"
        },
        {
            "paperId": "7a96b4f41b1b5ee621da33612228c6d0e3045dc8",
            "title": "Watermarking LLMs with Weight Quantization"
        },
        {
            "paperId": "9bf00afb0efb02a263fa3ddea1e768677498536c",
            "title": "Personalized Soups: Personalized Large Language Model Alignment via Post-hoc Parameter Merging"
        },
        {
            "paperId": "8fd11c6f3eb1d0aeb915369f3c4f0b1bb24cab0c",
            "title": "Large Language Model Unlearning"
        },
        {
            "paperId": "7ee9301f239556896403e00404db3cfef3b60903",
            "title": "Learn From Model Beyond Fine-Tuning: A Survey"
        },
        {
            "paperId": "57faebf64117cb458b62394560dda502360e90cd",
            "title": "Transformer Fusion with Optimal Transport"
        },
        {
            "paperId": "a09cbe54f842b9b243de4307349cb2800f3044d3",
            "title": "Parameter Efficient Multi-task Model Fusion with Partial Linearization"
        },
        {
            "paperId": "2ccb452691a5d3e3b600caaec119df9ff44688bd",
            "title": "AdaMerging: Adaptive Model Merging for Multi-Task Learning"
        },
        {
            "paperId": "feae1cd9e3fdeb77c3ff6e03831f09474a143c39",
            "title": "Merge, Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy"
        },
        {
            "paperId": "4f5c4ae2026b2bd97e26c6969e54cc634895e477",
            "title": "Jointly Training Large Autoregressive Multimodal Models"
        },
        {
            "paperId": "128217c0d1e99912ebc727c84686cc97a913b55f",
            "title": "Deep Model Fusion: A Survey"
        },
        {
            "paperId": "29f032fc875576b5c3c6b1c2d76af8639bacfb88",
            "title": "OpenChat: Advancing Open-source Language Models with Mixed-Quality Data"
        },
        {
            "paperId": "c96297261467b5daa2d01227496a70d444602434",
            "title": "Baichuan 2: Open Large-scale Language Models"
        },
        {
            "paperId": "c58c997e2d1e9a270a77c509680bfb1de3566121",
            "title": "MerA: Merging Pretrained Adapters For Few-Shot Learning"
        },
        {
            "paperId": "dd6a5032b61404ad6931cd28b1b5d7d9f75c9de8",
            "title": "Separate the Wheat from the Chaff: Model Deficiency Unlearning via Parameter-Efficient Module Operation"
        },
        {
            "paperId": "0fe88452660cb8a0e37f54bcd44f3cd6504354b5",
            "title": "Unified Model for Image, Video, Audio and Language Tasks"
        },
        {
            "paperId": "3f459219d75de63b5b7a26a8c6447ec1e79a985c",
            "title": "LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition"
        },
        {
            "paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a",
            "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"
        },
        {
            "paperId": "617bf3c2e34f0907fe610d9ced5cf83184fedb1b",
            "title": "Going Beyond Linear Mode Connectivity: The Layerwise Linear Feature Connectivity"
        },
        {
            "paperId": "83cecae1af6915dbec495f6eecb04235bcf9f6f3",
            "title": "Tangent Transformers for Composition, Privacy and Removal"
        },
        {
            "paperId": "66a2e3ed964e46cd268605fb3d9ee57a067a4aad",
            "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"
        },
        {
            "paperId": "f999f0396a674cf5c1a195fb99386e2b44fedb92",
            "title": "Tangent Model Composition for Ensembling and Continual Fine-tuning"
        },
        {
            "paperId": "9eb06c7c06f96e9f2a44226a8d7ce321372319f5",
            "title": "Layerwise Linear Mode Connectivity"
        },
        {
            "paperId": "929305892d4ddae575a0fc23227a8139f7681632",
            "title": "Jailbroken: How Does LLM Safety Training Fail?"
        },
        {
            "paperId": "a437c7ca499aed7486609c822d4d67e47c2bc04b",
            "title": "Sparse Model Soups: A Recipe for Improved Pruning via Model Averaging"
        },
        {
            "paperId": "7f1a473834eea608980e4e04cce21be18d65b9b6",
            "title": "Composing Parameter-Efficient Modules with Arithmetic Operations"
        },
        {
            "paperId": "e35776788d031de23050caadbb22bcb6e469a526",
            "title": "Lookaround Optimizer: k steps around, 1 step average"
        },
        {
            "paperId": "0e2f8491b7af5f715c8ac7e3a7fd96494bd417d8",
            "title": "Rewarded soups: towards Pareto-optimal alignment by interpolating weights fine-tuned on diverse rewards"
        },
        {
            "paperId": "7a816dd242c4c3f652a448dba54daa53f89a9e4f",
            "title": "Soft Merging of Experts with Adaptive Routing"
        },
        {
            "paperId": "fa168fe11fa77c9728412e49596f8a808b67a4d8",
            "title": "Early Weight Averaging meets High Learning Rates for LLM Pre-training"
        },
        {
            "paperId": "0d1c76d45afa012ded7ab741194baf142117c495",
            "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"
        },
        {
            "paperId": "5e0d3c25d375d83f0d88bfc17614dde5943c10c3",
            "title": "Task Arithmetic in the Tangent Space: Improved Editing of Pre-Trained Models"
        },
        {
            "paperId": "f7f1b23797c4886fcf7be184201d0a7d47baa40c",
            "title": "ZipIt! Merging Models from Different Tasks without Training"
        },
        {
            "paperId": "fc586657894b6573297a030c192d32764f752567",
            "title": "An Empirical Study of Multimodal Model Merging"
        },
        {
            "paperId": "eb6e30d13acd4df1d94575f715d56d314e834d1a",
            "title": "\u03c0-Tuning: Transferring Multimodal Foundation Models with Optimal Multi-task Interpolation"
        },
        {
            "paperId": "2fb84dcdfa68e31742e20ffff3f32a04ec85d3da",
            "title": "PopulAtion Parameter Averaging (PAPA)"
        },
        {
            "paperId": "163b4d6a79a5b19af88b8585456363340d9efd04",
            "title": "GPT-4 Technical Report"
        },
        {
            "paperId": "ac974291d7e3a152067382675524f3e3c2ded11b",
            "title": "Consistency Models"
        },
        {
            "paperId": "79dcd3843796fd552844cea6a0f244d5852fb9fb",
            "title": "Structured Pruning for Deep Convolutional Neural Networks: A Survey"
        },
        {
            "paperId": "76b19363b10d7ea783e4a6494eae40d73c8e9628",
            "title": "Parameter-efficient fine-tuning of large-scale pre-trained language models"
        },
        {
            "paperId": "7d80762f652be9d47d38fc3bb55a1a975d2ec595",
            "title": "DART: Diversify-Aggregate-Repeat Training Improves Generalization of Neural Networks"
        },
        {
            "paperId": "57e849d0de13ed5f91d086936296721d4ff75a75",
            "title": "LLaMA: Open and Efficient Foundation Language Models"
        },
        {
            "paperId": "1ed4bdfe692bff67ada28f4883492169103d156c",
            "title": "Robust Weight Signatures: Gaining Robustness as Easy as Patching Weights?"
        },
        {
            "paperId": "1f8e898c4771f902e5561b8e7959a745b8a8b146",
            "title": "Seasoning Model Soups for Robustness to Adversarial and Natural Distribution Shifts"
        },
        {
            "paperId": "629bc57782bb4326a3eb5f89314e350729c5f417",
            "title": "AdapterSoup: Weight Averaging to Improve Generalization of Pretrained Language Models"
        },
        {
            "paperId": "86d03160e6f05deb17d0169e515f5a55d6361f7c",
            "title": "Exploring the Benefits of Training Expert Language Models over Instruction Tuning"
        },
        {
            "paperId": "10b752a369ff01c748f2ec54b41326ba862a65fd",
            "title": "ForkMerge: Mitigating Negative Transfer in Auxiliary-Task Learning"
        },
        {
            "paperId": "99d477cc4a636dd7438cd9afd1610065c9d083cd",
            "title": "Backward Compatibility During Data Updates by Weight Interpolation"
        },
        {
            "paperId": "72cb8b39e8205313942b434a6992550fa124a66a",
            "title": "Re-basin via implicit Sinkhorn differentiation"
        },
        {
            "paperId": "ac667aa10db56b1483640aefeca05f2e25d8353b",
            "title": "Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization"
        },
        {
            "paperId": "3ff08b5ca57e786d8af7b204ef94c9972bd9a61e",
            "title": "Dataless Knowledge Fusion by Merging Weights of Language Models"
        },
        {
            "paperId": "71ba5f845bd22d42003675b7cea970ca9e590bcc",
            "title": "Editing Models with Task Arithmetic"
        },
        {
            "paperId": "656b5cb17d28c80fefb8c2f21e8f1f79b6dcd0dc",
            "title": "ColD Fusion: Collaborative Descent for Distributed Multitask Finetuning"
        },
        {
            "paperId": "8522f9a7bc7c958b5f66373b47ff68e1833089d6",
            "title": "AdaTask: A Task-aware Adaptive Learning Rate Approach to Multi-task Learning"
        },
        {
            "paperId": "3a1f0963f57baf8021c434ac14e5d4132b6735bd",
            "title": "REPAIR: REnormalizing Permuted Activations for Interpolation Repair"
        },
        {
            "paperId": "7bbd4e4d8405ffce1c58d1a33a8ae5b69e755529",
            "title": "Revisiting adapters with adversarial training"
        },
        {
            "paperId": "92f1b57b897479120c6eb74713c3de50f95c2b24",
            "title": "Plateau in Monotonic Linear Interpolation - A \"Biased\" View of Loss Landscape for Deep Networks"
        },
        {
            "paperId": "34e1c62586f0c86af60a6ff2c3e1121c1ebd779a",
            "title": "Stop Wasting My Time! Saving Days of ImageNet and BERT Training with Latest Weight Averaging"
        },
        {
            "paperId": "a9e20180153f6c139a4b6f2791b535fa6ffc3959",
            "title": "Git Re-Basin: Merging Models modulo Permutation Symmetries"
        },
        {
            "paperId": "5b19bf6c3f4b25cac96362c98b930cf4b37f6744",
            "title": "DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation"
        },
        {
            "paperId": "65f056d32dac701240a52a5daf8cedb611b04ceb",
            "title": "Patching open-vocabulary models by interpolating weights"
        },
        {
            "paperId": "8b3a67c7e5289eed160d2acfd04d71cfb552c67d",
            "title": "Branch-Train-Merge: Embarrassingly Parallel Training of Expert Language Models"
        },
        {
            "paperId": "d3b071c61992078d6cb77377621cf80f620136b4",
            "title": "BackdoorBench: A Comprehensive Benchmark of Backdoor Learning"
        },
        {
            "paperId": "44b6463ff3b39c51891235a0e891919dd21f00c0",
            "title": "Diverse Weight Averaging for Out-of-Distribution Generalization"
        },
        {
            "paperId": "7cdaa08890895e1ad92afb5fad429690ad7b1dac",
            "title": "Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning"
        },
        {
            "paperId": "aa8f3e081ad2869c9469e2726364bdae0d9bdc7f",
            "title": "Fusing finetuned models for better pretraining"
        },
        {
            "paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb",
            "title": "PaLM: Scaling Language Modeling with Pathways"
        },
        {
            "paperId": "54020e5fe48ebb250f27d744e20a63cac2988a84",
            "title": "Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time"
        },
        {
            "paperId": "0265144c696bf9371a0a63ece590dd2403ee71be",
            "title": "When Do Flat Minima Optimizers Work?"
        },
        {
            "paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
            "title": "High-Resolution Image Synthesis with Latent Diffusion Models"
        },
        {
            "paperId": "06b20a1c6883464fcb2855adc146874fe7937c41",
            "title": "Merging Models with Fisher-Weighted Averaging"
        },
        {
            "paperId": "ec108c1ec5b95d1f054b44bf4d6816a4e556b216",
            "title": "On Cross-Layer Alignment for Model Fusion of Heterogeneous Neural Networks"
        },
        {
            "paperId": "8dc51e275d3bb7342368ad58bf8cd1ea4de05f92",
            "title": "Ensemble of Averages: Improving Model Selection and Boosting Performance in Domain Generalization"
        },
        {
            "paperId": "4dc48bd4e1c0e5986b36eca8339bd45e944d8a82",
            "title": "The Role of Permutation Invariance in Linear Mode Connectivity of Neural Networks"
        },
        {
            "paperId": "f3a8de8c9117926199b0da0b548fecae3e20793a",
            "title": "Unrolling SGD: Understanding Factors Influencing Machine Unlearning"
        },
        {
            "paperId": "9289826beb6206eeaf500105f7329d6d5a495d8a",
            "title": "Robust fine-tuning of zero-shot models"
        },
        {
            "paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092",
            "title": "LoRA: Low-Rank Adaptation of Large Language Models"
        },
        {
            "paperId": "814a86b5aea4e4224baf5460489549e51208cf1b",
            "title": "GAN Cocktail: mixing GANs without dataset access"
        },
        {
            "paperId": "f14bad17c837124ba380a69e5569c5c95fe5eb39",
            "title": "Geometry of the Loss Landscape in Overparameterized Neural Networks: Symmetries and Invariances"
        },
        {
            "paperId": "cbdb45fc16b0885905b91d84281c310e6cb49e9c",
            "title": "Cross-Task Generalization via Natural Language Crowdsourcing Instructions"
        },
        {
            "paperId": "7fa273f450251523e6b7fcc2eb3fdbdfd4a30493",
            "title": "CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in NLP"
        },
        {
            "paperId": "deb435134d83e3c36ddcaa783392acf4a4e32dd7",
            "title": "Loss Surface Simplexes for Mode Connecting Volumes and Fast Ensembling"
        },
        {
            "paperId": "4d87a9f6a0bc9c67088193402813da5cba3f06c1",
            "title": "SWAD: Domain Generalization by Seeking Flat Minima"
        },
        {
            "paperId": "52d6636e0ba5d9a392d53d428c83e65a3a724974",
            "title": "SWA Object Detection"
        },
        {
            "paperId": "a2cd073b57be744533152202989228cb4122270a",
            "title": "Sharpness-Aware Minimization for Efficiently Improving Generalization"
        },
        {
            "paperId": "07bcda1dff9bb696ea9cbc69303eee8bd3d85bd6",
            "title": "GeDi: Generative Discriminator Guided Sequence Generation"
        },
        {
            "paperId": "716c197ad6ee927d828ccdee9191522087e6d840",
            "title": "Optimizing Mode Connectivity via Neuron Alignment"
        },
        {
            "paperId": "b2344edc5f46d7a7cf6f72549ef9fd9a32585f17",
            "title": "Neural networks with late-phase weights"
        },
        {
            "paperId": "4b6661347d5b58250130b89145dbd34ce310f2a0",
            "title": "Tackling the Objective Inconsistency Problem in Heterogeneous Federated Optimization"
        },
        {
            "paperId": "5c126ae3421f05768d8edd97ecd44b1364e2c99a",
            "title": "Denoising Diffusion Probabilistic Models"
        },
        {
            "paperId": "b145ea2049648535d6081407ebd315b072248183",
            "title": "BatchEnsemble: An Alternative Approach to Efficient Ensemble and Lifelong Learning"
        },
        {
            "paperId": "998620638cfc7c6b5d7b95fa8645f75723d78372",
            "title": "Federated Learning with Matched Averaging"
        },
        {
            "paperId": "7fd582680ee61f6333a23bd0374f05cd6fd3dcb4",
            "title": "A comprehensive survey on model compression and acceleration"
        },
        {
            "paperId": "449c5660d637741f7aa7ff42549c32b43c9968bf",
            "title": "Gradient Surgery for Multi-Task Learning"
        },
        {
            "paperId": "8fc7b672ee6dd2ee08cb2315d64be07ff9779e22",
            "title": "Stochastic Weight Averaging in Parallel: Large-Batch Training that Generalizes Well"
        },
        {
            "paperId": "3f06d02513a2763e472d2b5d5db08e9061081b9e",
            "title": "Linear Mode Connectivity and the Lottery Ticket Hypothesis"
        },
        {
            "paperId": "43a3caf942684aa7a354a12c0dc4bfbba50c563d",
            "title": "AdaShare: Learning What To Share For Efficient Deep Multi-Task Learning"
        },
        {
            "paperId": "1c3677364ea592629848ba2c6bd087f22cc579ea",
            "title": "Ensemble Learning"
        },
        {
            "paperId": "261004890f902acd810ac4e9b1025ca5981ceedf",
            "title": "Model Fusion via Optimal Transport"
        },
        {
            "paperId": "c95383f251a62c63217586059c67f63507c3e839",
            "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"
        },
        {
            "paperId": "7a15950dc71079285a4eaf195de5aadd87c41b40",
            "title": "Fine-Tuning Language Models from Human Preferences"
        },
        {
            "paperId": "75acc731bdd2b626edc74672a30da3bc51010ae8",
            "title": "CTRL: A Conditional Transformer Language Model for Controllable Generation"
        },
        {
            "paperId": "b0a4b1f67632f3abd6e27a397be2d004020859f2",
            "title": "Explaining Landscape Connectivity of Low-cost Solutions for Multilayer Nets"
        },
        {
            "paperId": "5ac658ff79e30358a2f4a8ac4486090c3b7a2289",
            "title": "Bayesian Nonparametric Federated Learning of Neural Networks"
        },
        {
            "paperId": "f79bfe86ced096597e6a8b4a88ca12f4b53be115",
            "title": "SWALP : Stochastic Weight Averaging in Low-Precision Training"
        },
        {
            "paperId": "49b64383fe36268410c430352637ed23b16820c5",
            "title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations"
        },
        {
            "paperId": "b611a8095630557229dc5fb6b07c272f1cd614da",
            "title": "Nuanced Metrics for Measuring Unintended Bias with Real Data for Text Classification"
        },
        {
            "paperId": "2b627185499791048681e8d24190c31dea928f16",
            "title": "Uniform convergence may be unable to explain generalization in deep learning"
        },
        {
            "paperId": "9e019730d5723069a8e0f46dc09ae3b2f69e9fcc",
            "title": "The European Union general data protection regulation: what it is and what it means*"
        },
        {
            "paperId": "7b9ee35587e60c9b4d4d0d1c15ad2049426a9819",
            "title": "Learning Private Neural Language Modeling with Attentive Aggregation"
        },
        {
            "paperId": "2b0d7e51efd004fe3847f54863540c79312f3546",
            "title": "Multi-Task Learning as Multi-Objective Optimization"
        },
        {
            "paperId": "af8a8dcb74561d52d904f7bc4afcc747e079b702",
            "title": "Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts"
        },
        {
            "paperId": "c99179ca3784e3465fd9ed049d7f34b50d39393e",
            "title": "Ensemble learning: A survey"
        },
        {
            "paperId": "7a84a692327534fd227fa1e07fcb3816b633c591",
            "title": "Neural Tangent Kernel: Convergence and Generalization in Neural Networks"
        },
        {
            "paperId": "b8989afff14fb630ca58b6afa917fb42574228ee",
            "title": "Averaging Weights Leads to Wider Optima and Better Generalization"
        },
        {
            "paperId": "2c90d366126a3ccd3c43e47891730650003059da",
            "title": "Essentially No Barriers in Neural Network Energy Landscape"
        },
        {
            "paperId": "f6195d8dc6aad8231e97b563246f2585842bc68b",
            "title": "Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs"
        },
        {
            "paperId": "6baca6351dc55baac44f0416e74a7e0ba2bfd03e",
            "title": "Visualizing the Loss Landscape of Neural Nets"
        },
        {
            "paperId": "c4f1281f55cbccc263cdf67d4ab4a1914e725bfc",
            "title": "An Investigation of How Neural Networks Learn from the Experiences of Peers Through Periodic Weight Averaging"
        },
        {
            "paperId": "582157494d72dd28dc28172f04dfd5f25fb17bff",
            "title": "GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "7493389667058116dbc7e808987f129325ee60d7",
            "title": "Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results"
        },
        {
            "paperId": "2e55ba6c97ce5eb55abd959909403fe8da7e9fe9",
            "title": "Overcoming catastrophic forgetting in neural networks"
        },
        {
            "paperId": "6bb5c2180948902448388ac66e1d04010c3d9965",
            "title": "Parallelizing Stochastic Gradient Descent for Least Squares Regression: Mini-batching, Averaging, and Model Misspecification"
        },
        {
            "paperId": "d1dbf643447405984eeef098b1b320dee0b3b8a7",
            "title": "Communication-Efficient Learning of Deep Networks from Decentralized Data"
        },
        {
            "paperId": "99e6f700d374e34c8376f1f43af994b278924f28",
            "title": "ESC: Dataset for Environmental Sound Classification"
        },
        {
            "paperId": "0f7c85357c366b314b5b55c400869a62fd23372c",
            "title": "Train faster, generalize better: Stability of stochastic gradient descent"
        },
        {
            "paperId": "41bebd1951e57588e7829e44fab1bac0cc9251d2",
            "title": "Torchvision the machine-vision package of torch"
        },
        {
            "paperId": "5ac423a83b4321b43249224fcc528bb70e086826",
            "title": "Catastrophic Forgetting, Rehearsal and Pseudorehearsal"
        },
        {
            "paperId": "8033e0edb3b43c4ba3605d70d0de14efbe69c976",
            "title": "Animating rotation with quaternion curves"
        },
        {
            "paperId": "35cbc2f146f054ace0a113d75162f386c8aed9fd",
            "title": "Cross-Task Linearity Emerges in the Pretraining-Finetuning Paradigm"
        },
        {
            "paperId": "9d607547cc9ebbd91efb3e5f52d40c997c42ea8d",
            "title": "Generalization Analysis of Stochastic Weight Averaging with General Sampling"
        },
        {
            "paperId": "a884bc8bc5b04e5ad096649856df5b7931fd3d23",
            "title": "Parameter-efficient Weight Ensembling Facilitates Task-level Knowledge Transfer"
        },
        {
            "paperId": "beb310b4ac6d9484547f11de3f29bb3faed36bce",
            "title": "Chat Vector: A Simple Approach to Equip LLMs With New Language Chat Capabilities"
        },
        {
            "paperId": "035113896965c71a2ae46d770055d0fa2db448a9",
            "title": "Trainable Weight Averaging: Efficient Training by Optimizing Historical Solutions"
        },
        {
            "paperId": "ad4d553ae695a5da33ef188ac37f2a7037c303f5",
            "title": "Deep Neural Network Fusion via Graph Matching with Applications to Model Ensemble and Federated Learning"
        },
        {
            "paperId": "f473fa00987739cc14af7d23c75a74973d86d6e5",
            "title": "Model Fusion of Heterogeneous Neural Networks via Cross-Layer Alignment"
        },
        {
            "paperId": "9405cc0d6169988371b2755e573cc28650d14dfe",
            "title": "Language Models are Unsupervised Multitask Learners"
        },
        {
            "paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "title": "Improving Language Understanding by Generative Pre-Training"
        },
        {
            "paperId": null,
            "title": "The california consumer privacy act: Towards a european-style privacy regime in the united states"
        },
        {
            "paperId": null,
            "title": "Weight averaging for neural networks and local resampling schemes"
        },
        {
            "paperId": "bd2e048c676ad778351bd7d7660240a978422117",
            "title": "On the Mathematical Foundations of Theoretical Statistics"
        },
        {
            "paperId": null,
            "title": "An automatic evaluator of instruction-following models"
        },
        {
            "paperId": null,
            "title": "Scalable learned model soup on a single gpu: An efficient subspace training strategy"
        },
        {
            "paperId": null,
            "title": "Resolving interference when merging models"
        },
        {
            "paperId": null,
            "title": "Merging by matching models in task subspaces"
        },
        {
            "paperId": null,
            "title": "Gemini: a family of highly capable multimodal models"
        }
    ]
}