{
    "paperId": "bedaa80419ce7e482b26e68081080e3e5ea9adf7",
    "externalIds": {
        "ArXiv": "2407.10416",
        "DBLP": "journals/corr/abs-2407-10416",
        "DOI": "10.48550/arXiv.2407.10416",
        "CorpusId": 271212416
    },
    "title": "SOFA: A Compute-Memory Optimized Sparsity Accelerator via Cross-Stage Coordinated Tiling",
    "abstract": "Benefiting from the self-attention mechanism, Transformer models have attained impressive contextual comprehension capabilities for lengthy texts. The requirements of high-throughput inference arise as the large language models (LLMs) become increasingly prevalent, which calls for large-scale token parallel processing (LTPP). However, existing dynamic sparse accelerators struggle to effectively handle LTPP, as they solely focus on separate stage optimization, and with most efforts confined to computational enhancements. By re-examining the end-to-end flow of dynamic sparse acceleration, we pinpoint an ever-overlooked opportunity that the LTPP can exploit the intrinsic coordination among stages to avoid excessive memory access and redundant computation. Motivated by our observation, we present SOFA, a cross-stage compute-memory efficient algorithm-hardware co-design, which is tailored to tackle the challenges posed by LTPP of Transformer inference effectively. We first propose a novel leading zero computing paradigm, which predicts attention sparsity by using log-based add-only operations to avoid the significant overhead of prediction. Then, a distributed sorting and a sorted updating FlashAttention mechanism are proposed with a cross-stage coordinated tiling principle, which enables fine-grained and lightweight coordination among stages, helping optimize memory access and latency. Further, we propose a SOFA accelerator to support these optimizations efficiently. Extensive experiments on 20 benchmarks show that SOFA achieves $9.5\\times$ speed up and $71.5\\times$ higher energy efficiency than Nvidia A100 GPU. Compared to 8 SOTA accelerators, SOFA achieves an average $15.8\\times$ energy efficiency, $10.3\\times$ area efficiency and $9.3\\times$ speed up, respectively.",
    "venue": "arXiv.org",
    "year": 2024,
    "referenceCount": 115,
    "citationCount": 0,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "SOFA, a cross-stage compute-memory efficient algorithm-hardware co-design, which is tailored to tackle the challenges posed by LTPP of Transformer inference effectively, and proposes a SOFA accelerator to support these optimizations efficiently."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -2.762340545654297,
            0.47320717573165894,
            0.65928715467453,
            5.363160133361816,
            2.6097631454467773,
            -0.811867356300354,
            3.0336270332336426,
            0.32785022258758545,
            1.0504415035247803,
            -0.4318642020225525,
            -0.08289727568626404,
            4.164726257324219,
            -0.020349860191345215,
            -0.8113212585449219,
            -4.568221569061279,
            -1.2599132061004639,
            -4.096185207366943,
            0.07372868061065674,
            6.335629940032959,
            3.937216281890869,
            0.5111343860626221,
            -2.237279176712036,
            -1.9019938707351685,
            2.712088108062744,
            -2.273493766784668,
            -0.08027622103691101,
            -0.9013158082962036,
            -2.1348085403442383,
            -0.41347989439964294,
            1.827735185623169,
            2.3677823543548584,
            -6.697321891784668,
            6.905553817749023,
            -4.288511276245117,
            3.7685933113098145,
            -4.243565082550049,
            -3.5251975059509277,
            8.83108139038086,
            -5.8259735107421875,
            0.337464302778244,
            0.9504859447479248,
            0.594711184501648,
            0.10088184475898743,
            0.11493997275829315,
            1.2513056993484497,
            3.9551496505737305,
            1.416601538658142,
            0.9502733945846558,
            0.010672062635421753,
            3.1309378147125244,
            3.2878260612487793,
            -1.060792088508606,
            -1.5541062355041504,
            -0.15771782398223877,
            -2.0247886180877686,
            -2.6182546615600586,
            1.0288636684417725,
            2.55729079246521,
            1.989571213722229,
            -3.752254009246826,
            5.372043609619141,
            1.919480800628662,
            -0.9793006181716919,
            1.6428446769714355,
            2.1883511543273926,
            -3.0667409896850586,
            -2.244971752166748,
            4.967829704284668,
            2.10953426361084,
            2.4818074703216553,
            -2.1904711723327637,
            -4.671638488769531,
            2.0941097736358643,
            -0.894527018070221,
            -2.761706590652466,
            1.5454566478729248,
            -4.6069560050964355,
            -6.15380859375,
            -2.4931747913360596,
            -5.651961326599121,
            0.27115708589553833,
            4.819516181945801,
            -0.16788798570632935,
            2.3828561305999756,
            3.2591753005981445,
            -3.638946533203125,
            -2.565640449523926,
            -0.19964411854743958,
            1.650416374206543,
            0.6412631869316101,
            -0.14551758766174316,
            0.9456637501716614,
            -1.7831159830093384,
            -0.464584618806839,
            -5.284119606018066,
            -0.6062568426132202,
            2.5536208152770996,
            0.6036774516105652,
            -3.622758150100708,
            0.9133380651473999,
            2.9163479804992676,
            1.6683471202850342,
            3.704453706741333,
            -1.8657472133636475,
            1.7598766088485718,
            -3.063117742538452,
            -4.921732425689697,
            3.607621192932129,
            0.08312688767910004,
            -1.9168133735656738,
            -4.284416198730469,
            4.315187454223633,
            1.3811761140823364,
            -1.5774568319320679,
            -2.291236639022827,
            -5.338221549987793,
            -3.306534767150879,
            -2.5002684593200684,
            -2.124584197998047,
            3.6637582778930664,
            -2.195110321044922,
            0.3566755950450897,
            -1.7884516716003418,
            0.9816681742668152,
            1.834717035293579,
            -0.7571383714675903,
            -0.987587571144104,
            -1.3065866231918335,
            -0.1223437637090683,
            -5.362880706787109,
            1.6996959447860718,
            -0.7226604223251343,
            1.8883914947509766,
            -2.595562696456909,
            1.561598777770996,
            -0.6863874197006226,
            -6.318535804748535,
            0.41201168298721313,
            -1.9111523628234863,
            2.1087822914123535,
            -0.22272099554538727,
            3.9239113330841064,
            -0.7063432931900024,
            -0.37702926993370056,
            1.4568707942962646,
            4.8209614753723145,
            0.8929735422134399,
            6.367175102233887,
            0.020156443119049072,
            5.237030029296875,
            3.179044246673584,
            -3.146036148071289,
            1.0786017179489136,
            2.1284608840942383,
            -2.1261703968048096,
            3.7130684852600098,
            -3.260925769805908,
            -2.6851091384887695,
            -0.12625354528427124,
            0.1422022581100464,
            0.8454128503799438,
            -0.6533187627792358,
            -8.90374755859375,
            0.11345648765563965,
            4.412638187408447,
            -2.6695165634155273,
            -4.02707576751709,
            -0.10061037540435791,
            -2.259922504425049,
            6.722883224487305,
            -2.855560302734375,
            1.0113928318023682,
            5.357036590576172,
            2.6420106887817383,
            4.773189544677734,
            4.06343936920166,
            0.003153562545776367,
            -2.0478830337524414,
            -3.8522589206695557,
            -1.417788028717041,
            0.5107954740524292,
            1.9819376468658447,
            -5.463575839996338,
            4.253673076629639,
            -6.979269981384277,
            -2.1094861030578613,
            -4.028748035430908,
            -1.5881766080856323,
            -4.013290882110596,
            2.0799612998962402,
            0.7180682420730591,
            -2.200240135192871,
            4.236116409301758,
            5.988722324371338,
            1.505940318107605,
            -1.9955360889434814,
            4.949551105499268,
            -0.8019702434539795,
            -2.001677989959717,
            1.540764570236206,
            -1.0121185779571533,
            1.0191950798034668,
            -1.7227561473846436,
            -1.4176843166351318,
            3.8823678493499756,
            -0.9819246530532837,
            -2.867253541946411,
            2.8045897483825684,
            3.8821253776550293,
            -0.6781588196754456,
            0.9934502243995667,
            2.2810769081115723,
            0.43328845500946045,
            2.3423986434936523,
            -3.6410624980926514,
            -3.9395713806152344,
            -7.708926677703857,
            4.102516174316406,
            5.801176071166992,
            0.43031662702560425,
            -0.06170767545700073,
            -0.774004340171814,
            -1.4742622375488281,
            -3.6748526096343994,
            -1.2241384983062744,
            1.033372163772583,
            4.058463096618652,
            0.14978167414665222,
            0.46124833822250366,
            -0.9089450836181641,
            -1.8315309286117554,
            -5.893756866455078,
            1.057478904724121,
            -2.0584769248962402,
            -4.739566802978516,
            -2.8309645652770996,
            -2.45314621925354,
            2.1760470867156982,
            -1.827765703201294,
            0.7058290243148804,
            6.745838165283203,
            1.4868671894073486,
            -0.7601573467254639,
            5.687582015991211,
            3.484196662902832,
            -1.0892512798309326,
            -3.827122688293457,
            -0.5883052349090576,
            2.741926908493042,
            -0.510779082775116,
            1.6624574661254883,
            -4.642853736877441,
            4.939620494842529,
            0.2193516194820404,
            4.055811882019043,
            2.337495803833008,
            0.23903298377990723,
            -3.167750835418701,
            1.7283138036727905,
            0.5991766452789307,
            -1.0182856321334839,
            4.095686912536621,
            4.561695098876953,
            8.199089050292969,
            -3.3567841053009033,
            -2.9430902004241943,
            -4.959053039550781,
            -0.24062427878379822,
            -3.1736559867858887,
            2.5907773971557617,
            3.0434298515319824,
            1.6666409969329834,
            -2.975595474243164,
            -5.243586540222168,
            -0.9634897708892822,
            -6.903952598571777,
            -4.118659973144531,
            -0.08752185106277466,
            1.50869882106781,
            8.60389518737793,
            3.585003614425659,
            -1.9033176898956299,
            -4.748811721801758,
            1.1698355674743652,
            -0.022257447242736816,
            -1.6216022968292236,
            -0.393628865480423,
            -2.0912928581237793,
            0.3318606913089752,
            0.952957034111023,
            -3.768878221511841,
            1.7982113361358643,
            -6.077496528625488,
            -2.621633529663086,
            -2.519845485687256,
            4.282307147979736,
            5.333292007446289,
            2.2197158336639404,
            -1.553395390510559,
            -2.597822904586792,
            -2.9523682594299316,
            1.8959569931030273,
            1.5838626623153687,
            1.6479651927947998,
            0.15656021237373352,
            4.135059833526611,
            0.49498099088668823,
            -2.102966070175171,
            -0.41510623693466187,
            -4.656942367553711,
            -1.5314092636108398,
            -0.7732687592506409,
            3.1950912475585938,
            -2.528365135192871,
            -0.770754337310791,
            -0.31587767601013184,
            3.7229442596435547,
            -0.04988732933998108,
            0.233298659324646,
            5.035261631011963,
            -5.600566864013672,
            -0.06409984827041626,
            -5.4916768074035645,
            -1.4211080074310303,
            -1.5421509742736816,
            -0.6432439684867859,
            1.7457835674285889,
            1.8075100183486938,
            -1.9735842943191528,
            5.204525947570801,
            -2.387295722961426,
            5.287360191345215,
            2.4654617309570312,
            3.118105173110962,
            0.141025573015213,
            -4.982234954833984,
            0.7613591551780701,
            -2.9303269386291504,
            -0.7288625240325928,
            -0.44096821546554565,
            -4.350940704345703,
            7.068316459655762,
            -0.8084425926208496,
            2.8621418476104736,
            -0.3834415674209595,
            -1.7252155542373657,
            1.5229929685592651,
            -3.547877073287964,
            -0.24248772859573364,
            0.9100825786590576,
            -1.3769314289093018,
            -2.2786474227905273,
            3.6529908180236816,
            -0.4167221486568451,
            0.6166703701019287,
            5.482125282287598,
            1.582322359085083,
            1.6326528787612915,
            2.977957248687744,
            4.191178798675537,
            0.791236162185669,
            1.2720766067504883,
            0.7827250957489014,
            -0.45451217889785767,
            -0.4600975215435028,
            0.21197748184204102,
            11.171064376831055,
            -1.3139723539352417,
            2.9255919456481934,
            -3.1705188751220703,
            -3.8734917640686035,
            -4.91752815246582,
            -1.8587932586669922,
            2.6563849449157715,
            -1.2742397785186768,
            0.46913468837738037,
            2.42404842376709,
            -0.6780375242233276,
            -1.7612736225128174,
            -0.02926775813102722,
            0.1832284927368164,
            6.451183319091797,
            -1.858211874961853,
            2.860684871673584,
            -3.177051067352295,
            -0.10713976621627808,
            -1.6248805522918701,
            2.1275296211242676,
            2.170858860015869,
            0.35901689529418945,
            -3.1119422912597656,
            5.031108379364014,
            1.0522472858428955,
            2.252668619155884,
            -5.094921112060547,
            -5.067534446716309,
            -1.096919298171997,
            -4.706918716430664,
            0.5783416032791138,
            1.9801721572875977,
            0.623049259185791,
            -1.34455406665802,
            4.977546215057373,
            6.308823585510254,
            -4.083977699279785,
            1.2889728546142578,
            5.955309867858887,
            1.3690721988677979,
            -1.0107367038726807,
            -0.19998681545257568,
            -6.579853057861328,
            -0.6820101737976074,
            -1.0702643394470215,
            -5.544177055358887,
            -1.442068099975586,
            -1.6925904750823975,
            2.366217613220215,
            3.277240037918091,
            3.1520512104034424,
            2.8153655529022217,
            -1.6086304187774658,
            3.8884224891662598,
            4.397007465362549,
            3.0567734241485596,
            -1.5730366706848145,
            2.485495090484619,
            5.121007442474365,
            3.109200954437256,
            1.5385856628417969,
            2.148202896118164,
            -3.468440532684326,
            2.5484914779663086,
            -4.0581488609313965,
            2.598696231842041,
            -0.3487860858440399,
            4.802985191345215,
            -1.4324206113815308,
            -0.5038107633590698,
            -1.0312328338623047,
            1.6319739818572998,
            0.8879069089889526,
            4.0174455642700195,
            -5.021122455596924,
            0.7989308834075928,
            0.7001600861549377,
            -0.7560725212097168,
            0.3437621593475342,
            -1.0651860237121582,
            -4.603320121765137,
            -2.7289879322052,
            0.8196377754211426,
            -3.8535523414611816,
            -1.5649280548095703,
            -1.6961188316345215,
            1.5581539869308472,
            -1.0049000978469849,
            -2.937380075454712,
            -2.4411873817443848,
            1.41078519821167,
            -3.6097192764282227,
            -4.75885534286499,
            5.547510147094727,
            2.5086445808410645,
            -0.25072920322418213,
            1.5729572772979736,
            2.0607099533081055,
            -0.7112408876419067,
            -6.243719100952148,
            1.1192281246185303,
            1.0853317975997925,
            3.132223606109619,
            -0.5973716378211975,
            1.0363435745239258,
            1.2793453931808472,
            -0.4239170551300049,
            -1.3977177143096924,
            2.0131795406341553,
            -0.8693370223045349,
            -0.14406530559062958,
            -5.236451148986816,
            -0.6805022358894348,
            0.2500537037849426,
            1.97958242893219,
            -4.502133369445801,
            -2.95219087600708,
            6.448289394378662,
            2.7616310119628906,
            0.9582513570785522,
            -0.3756898045539856,
            2.8500099182128906,
            2.470677375793457,
            -1.4287110567092896,
            6.308526992797852,
            -2.192030906677246,
            2.0256307125091553,
            1.2716057300567627,
            -1.7768203020095825,
            1.174046516418457,
            0.9137590527534485,
            -1.3657187223434448,
            -3.742324113845825,
            -2.6725943088531494,
            -3.3402280807495117,
            -3.4126038551330566,
            -3.5392415523529053,
            6.793504238128662,
            1.797900915145874,
            3.529261350631714,
            -1.4829360246658325,
            -0.38510584831237793,
            -1.5672664642333984,
            3.1195008754730225,
            -8.637123107910156,
            0.5510144829750061,
            -0.062361739575862885,
            2.60981822013855,
            5.1623921394348145,
            0.7636366486549377,
            0.846017599105835,
            3.349543333053589,
            -2.976986885070801,
            2.5106000900268555,
            -2.0518765449523926,
            1.7037822008132935,
            3.5727272033691406,
            3.274513006210327,
            -3.464852809906006,
            4.044425010681152,
            1.7438576221466064,
            4.429556846618652,
            6.274150848388672,
            4.977923393249512,
            -1.634559154510498,
            -3.8071751594543457,
            -0.6322647333145142,
            -4.194214820861816,
            1.1018692255020142,
            3.3354854583740234,
            -4.754469394683838,
            -1.8777494430541992,
            -1.7908074855804443,
            0.705160915851593,
            0.7473024129867554,
            3.403578758239746,
            -1.5349695682525635,
            4.7368268966674805,
            -2.793850898742676,
            -0.04091549664735794,
            -2.700166702270508,
            3.7421059608459473,
            1.6671576499938965,
            -1.9117463827133179,
            -1.926899790763855,
            -4.4272050857543945,
            -2.4183993339538574,
            -1.7019474506378174,
            -3.5653743743896484,
            -1.3784172534942627,
            -2.378121852874756,
            3.127436399459839,
            4.569611072540283,
            -0.028877153992652893,
            1.4605016708374023,
            4.365655899047852,
            -2.372476816177368,
            -3.592336654663086,
            -2.101203441619873,
            4.488748550415039,
            0.1604437530040741,
            0.21520602703094482,
            -1.5465271472930908,
            -1.8244259357452393,
            0.6474770307540894,
            1.2093257904052734,
            2.891200065612793,
            1.2554692029953003,
            -0.3402184844017029,
            2.8280091285705566,
            -1.629326581954956,
            0.5721004009246826,
            1.9881324768066406,
            -4.0909199714660645,
            -4.507251739501953,
            -5.090360641479492,
            1.1779506206512451,
            -2.843090057373047,
            -2.848107099533081,
            2.816739082336426,
            -4.027673244476318,
            -0.04037179797887802,
            3.5870108604431152,
            -0.9624263644218445,
            -1.0356929302215576,
            -5.79646110534668,
            -0.5403881669044495,
            -1.3772306442260742,
            3.066549301147461,
            -1.4876981973648071,
            0.07299917936325073,
            2.8390121459960938,
            0.3227115273475647,
            3.0999486446380615,
            4.145303249359131,
            1.2564430236816406,
            -4.809978008270264,
            -0.26306453347206116,
            4.148963451385498,
            2.526740550994873,
            0.3328341245651245,
            -2.0474939346313477,
            -0.00678195059299469,
            2.531752824783325,
            15.193743705749512,
            -0.7483906149864197,
            -1.3773140907287598,
            -3.059946060180664,
            1.5704894065856934,
            -3.574587821960449,
            -1.64312744140625,
            2.947658061981201,
            4.0255045890808105,
            2.590564012527466,
            -1.6127843856811523,
            -3.0712637901306152,
            3.716953992843628,
            1.7589235305786133,
            -3.2730422019958496,
            0.8096469044685364,
            -3.5360841751098633,
            2.9054503440856934,
            -4.262214183807373,
            0.7663495540618896,
            -0.4241623282432556,
            1.2304325103759766,
            -5.1524577140808105,
            -1.967044472694397,
            1.8545904159545898,
            5.127823829650879,
            0.6752685308456421,
            3.1279540061950684,
            -3.6976332664489746,
            0.5686003565788269,
            1.1930302381515503,
            4.440631866455078,
            -0.03457283973693848,
            0.4893624782562256,
            -2.732120990753174,
            5.634196758270264,
            3.110714912414551,
            1.0026323795318604,
            2.317580223083496,
            4.452992916107178,
            -2.1613824367523193,
            -2.342278480529785,
            -0.6557935476303101,
            -1.4098660945892334,
            -2.0857744216918945,
            2.6517887115478516,
            0.5036816596984863,
            -2.778312921524048,
            -4.927457809448242,
            4.191608905792236,
            -1.7828245162963867,
            -2.303018093109131,
            -3.8153438568115234,
            3.0861949920654297,
            2.288689613342285,
            6.444427967071533,
            0.352967232465744,
            -0.3105941116809845,
            5.975070953369141,
            -1.9564216136932373,
            2.267700672149658,
            -0.9589592814445496,
            -0.8961431384086609,
            -2.6262705326080322,
            -2.2720446586608887,
            3.432577133178711,
            -1.8334039449691772,
            1.5322649478912354,
            -0.3143981695175171,
            1.8763066530227661,
            4.170021057128906,
            1.4004758596420288,
            2.7064733505249023,
            -2.301253080368042,
            0.4624249339103699,
            -1.9266653060913086,
            4.107170104980469,
            -0.029839172959327698,
            -1.9897258281707764,
            9.502127647399902,
            -3.7735483646392822,
            2.0454084873199463,
            -1.0282670259475708,
            -1.9427399635314941,
            5.923508644104004,
            -4.551896572113037,
            4.560041427612305,
            1.6947507858276367,
            -4.414493083953857,
            2.295341968536377,
            -1.2306064367294312,
            0.4363515079021454,
            3.6437809467315674,
            3.070664882659912,
            3.730748414993286,
            -5.965478420257568,
            -1.890136957168579,
            -5.093229293823242,
            -2.467897891998291,
            -2.662738800048828,
            6.878120422363281,
            4.87437629699707,
            -1.7134528160095215,
            -0.67229163646698,
            -0.3269147574901581,
            -3.1851329803466797,
            -2.105583906173706,
            -6.243176460266113,
            0.7000912427902222,
            -3.6601972579956055,
            3.638263463973999,
            -5.152279853820801,
            -0.5361859798431396,
            -2.1592204570770264,
            -1.5240097045898438,
            -5.028547286987305,
            1.6485679149627686,
            2.597517490386963,
            -0.3251442313194275,
            2.1446423530578613,
            2.490912675857544,
            2.2444589138031006,
            -4.218592166900635,
            -2.929765224456787,
            -1.7383909225463867,
            1.7268775701522827,
            -0.23389938473701477,
            -0.7455339431762695,
            -2.1520330905914307,
            0.62674880027771,
            0.30594488978385925,
            -3.0913333892822266,
            -4.797354698181152,
            1.8154231309890747,
            -1.0722393989562988,
            -3.90342116355896,
            -2.743433952331543,
            -2.184352159500122,
            -3.5192346572875977,
            1.8312596082687378,
            5.784552097320557,
            -1.5242860317230225,
            -0.7928069829940796,
            10.932387351989746,
            1.242911696434021,
            -0.053346097469329834,
            -1.5550808906555176,
            -3.7639119625091553,
            -0.7436444759368896,
            0.8132836818695068,
            0.978173017501831,
            -4.300275802612305,
            5.5462965965271,
            -1.0810961723327637,
            1.0025526285171509,
            -3.5110607147216797
        ]
    },
    "authors": [
        {
            "authorId": "2290366430",
            "name": "Huizheng Wang"
        },
        {
            "authorId": "2290424142",
            "name": "Jiahao Fang"
        },
        {
            "authorId": "2290454164",
            "name": "Xinru Tang"
        },
        {
            "authorId": "2068670866",
            "name": "Zhiheng Yue"
        },
        {
            "authorId": "2303433487",
            "name": "Jinxi Li"
        },
        {
            "authorId": "2116661616",
            "name": "Yubin Qin"
        },
        {
            "authorId": "2258720517",
            "name": "Sihan Guan"
        },
        {
            "authorId": "2290295076",
            "name": "Qize Yang"
        },
        {
            "authorId": "2155652573",
            "name": "Yang Wang"
        },
        {
            "authorId": "2303489619",
            "name": "Chao Li"
        },
        {
            "authorId": "2211884231",
            "name": "Yang Hu"
        },
        {
            "authorId": "2301577046",
            "name": "Shouyi Yin"
        }
    ],
    "references": [
        {
            "paperId": "095becc96744fd1ebcb2fe7941b439e681ac4f1f",
            "title": "Hardware\u2013Software Co-Design Enabling Static and Dynamic Sparse Attention Mechanisms"
        },
        {
            "paperId": "eb06e95dd3eb5a916e52d2e463f474ef4967d8ca",
            "title": "LoongServe: Efficiently Serving Long-context Large Language Models with Elastic Sequence Parallelism"
        },
        {
            "paperId": "2717e5c7384ec12cfd6cf9c34897c6adad3230ed",
            "title": "Long-context LLMs Struggle with Long In-context Learning"
        },
        {
            "paperId": "a1f76db91c0debcf93ae9889736bce8470902113",
            "title": "Large Language Models: A Survey"
        },
        {
            "paperId": "cf278f48c09c2747f415c0b190c09773673ea959",
            "title": "A Survey on Hardware Accelerators for Large Language Models"
        },
        {
            "paperId": "72f77a393079431e4207b3afe678ee80b420e6f8",
            "title": "DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving"
        },
        {
            "paperId": "33230a9d2e4d0ef9c923813a07107b2e3bc56605",
            "title": "E^2-LLM: Efficient and Extreme Length Extension of Large Language Models"
        },
        {
            "paperId": "ad9146d98ae95bbeeef460abe083ecc2c4798672",
            "title": "Splitwise: Efficient Generative LLM Inference Using Phase Splitting"
        },
        {
            "paperId": "135141e6b69ec83cda44aa1c99718042ac938e23",
            "title": "RM-STC: Row-Merge Dataflow Inspired GPU Sparse Tensor Core for Energy-Efficient Sparse Acceleration"
        },
        {
            "paperId": "2b2cc0d755ce4ff8bb3a5b7cdc7df7b1f2b2eb5c",
            "title": "Eureka: Efficient Tensor Cores for One-sided Unstructured Sparsity in DNN Inference"
        },
        {
            "paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0",
            "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"
        },
        {
            "paperId": "b069c32fcd77160f944ab3ba71ab6f0cfb782c68",
            "title": "Focused Transformer: Contrastive Training for Context Scaling"
        },
        {
            "paperId": "3f5e63168d0ae1af41c3434e9e3e7e84dda9a5d8",
            "title": "FACT: FFN-Attention Co-optimized Transformer Architecture with Eager Correlation Prediction"
        },
        {
            "paperId": "d4bfbc2874baddf3f562603665e936707db7d340",
            "title": "HighLight: Efficient and Flexible DNN Acceleration with Hierarchical Structured Sparsity"
        },
        {
            "paperId": "163b4d6a79a5b19af88b8585456363340d9efd04",
            "title": "GPT-4 Technical Report"
        },
        {
            "paperId": "512ff5037b28be7415d318ae6e8eeb0abb8c7013",
            "title": "DTATrans: Leveraging Dynamic Token-Based Quantization With Accuracy Compensation Mechanism for Efficient Transformer Architecture"
        },
        {
            "paperId": "dccd031acf509c3ba2986be241b43594335c8af4",
            "title": "DeFiNES: Enabling Fast Exploration of the Depth-first Scheduling Space for DNN Accelerators through Analytical Modeling"
        },
        {
            "paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e",
            "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"
        },
        {
            "paperId": "200ef1cde362aafbf598a2b5a1c5f35504ca2289",
            "title": "ViTCoD: Vision Transformer Acceleration via Dedicated Algorithm and Accelerator Co-Design"
        },
        {
            "paperId": "65f739cf9a8e57834425da1510d249b22d0bdc7a",
            "title": "DeepBurning-SEG: Generating DNN Accelerators of Segment-Grained Pipeline Architecture"
        },
        {
            "paperId": "2edff3cca66f647b12bfc92f852be874d0e11e17",
            "title": "Ristretto: An Atomized Processing Architecture for Sparsity-Condensed Stream Flow in CNN"
        },
        {
            "paperId": "13270b9759cf0296b5a346fbb58b706e8ad0a982",
            "title": "Adaptable Butterfly Accelerator for Attention-based NNs via Hardware and Algorithm Co-design"
        },
        {
            "paperId": "f841f3d912be52a621aab1a979632e9daeab6599",
            "title": "Sparse Attention Acceleration with Synergistic In-Memory Pruning and On-Chip Recomputation"
        },
        {
            "paperId": "86891d00499eebe86d3f1e39143d412addf2652b",
            "title": "DFX: A Low-latency Multi-FPGA Appliance for Accelerating Transformer-based Text Generation"
        },
        {
            "paperId": "a262a3d81f72e4b07558e636489e85ca88045156",
            "title": "An Algorithm\u2013Hardware Co-Optimized Framework for Accelerating N:M Sparse Transformers"
        },
        {
            "paperId": "cbff35378657225ece138c33e6a23afb3b46b41f",
            "title": "SALO: an efficient spatial accelerator enabling hybrid sparse attention mechanisms for long sequences"
        },
        {
            "paperId": "1d2857724c7a244f4983d2e88ae68ae725c66c33",
            "title": "Cascading structured pruning: enabling high data reuse for sparse DNN accelerators"
        },
        {
            "paperId": "562acf986de6e4c18c920965178c4ec6c7dab5ab",
            "title": "Anticipating and eliminating redundant computations in accelerated sparse training"
        },
        {
            "paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336",
            "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"
        },
        {
            "paperId": "732fa35f283143e05a6c4224931c22f79ad95b2a",
            "title": "Sparseloop: An Analytical Approach To Sparse Tensor Accelerator Modeling"
        },
        {
            "paperId": "e867f531937f6e3b3ab08a3fe8e3a17f114b9b6e",
            "title": "CANDLES: Channel-Aware Novel Dataflow-Microarchitecture Co-Design for Low Energy Sparse Neural Network Acceleration"
        },
        {
            "paperId": "2babc9ba9dd301d6e61117302bd2a200f7b422e2",
            "title": "DOTA: detect and omit weak attentions for scalable transformer acceleration"
        },
        {
            "paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99",
            "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"
        },
        {
            "paperId": "b4af355a897145bd4cb9a2cfc38dff3ec10aeb0e",
            "title": "Fast and Low-Power Quantized Fixed Posit High-Accuracy DNN Implementation"
        },
        {
            "paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d",
            "title": "High-Resolution Image Synthesis with Latent Diffusion Models"
        },
        {
            "paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5",
            "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"
        },
        {
            "paperId": "c67b1a62b868a758791c88d5465c7b6d53510fc3",
            "title": "Energon: Toward Efficient Acceleration of Transformers Using Dynamic Sparse Attention"
        },
        {
            "paperId": "0f894952a4d51d00661dc26e11e6a7bab48c35fc",
            "title": "ESCALATE: Boosting the Efficiency of Sparse CNN Accelerator with Kernel Decomposition"
        },
        {
            "paperId": "b97c3c370401dc34d2adbeb24f34de5180a14be6",
            "title": "Sanger: A Co-Design Framework for Enabling Sparse Attention using Reconfigurable Architecture"
        },
        {
            "paperId": "3e2f56ef854017a424d139f84f800e1f769a7aa6",
            "title": "A 12.1 TOPS/W Quantized Network Acceleration Processor With Effective-Weight-Based Convolution and Error-Compensation-Based Prediction"
        },
        {
            "paperId": "6dd4e2591dcb45b84103029dfc0a3cc941f54576",
            "title": "Dadu-Eye: A 5.3 TOPS/W, 30 fps/1080p High Accuracy Stereo Vision Accelerator"
        },
        {
            "paperId": "bc79ffc6cb8417119f3c343914da57e73ed34ad8",
            "title": "Griffin: Rethinking Sparse Optimization for Deep Learning Architectures"
        },
        {
            "paperId": "49712e517e4e50a5ec231284e884902c58e2fb3d",
            "title": "S2TA: Exploiting Structured Sparsity for Energy-Efficient Mobile CNN Acceleration"
        },
        {
            "paperId": "2b38ddff8e24a07597c8d042ea7b8b85a678e9b2",
            "title": "FLAT: An Optimized Dataflow for Mitigating Attention Bottlenecks"
        },
        {
            "paperId": "e7a505e3e2221522ac9b9ae5d1a2f4440a9ca1d0",
            "title": "DepFiN: A 12nm, 3.8TOPs depth-first CNN processor for high res. image processing"
        },
        {
            "paperId": "2a805d0e1b067444a554c5169d189fa1f649f411",
            "title": "Scaling Vision Transformers"
        },
        {
            "paperId": "5af69480a7ae3b571df6782a11ec4437b386a7d9",
            "title": "ELSA: Hardware-Software Co-design for Efficient, Lightweight Self-Attention Mechanism in Neural Networks"
        },
        {
            "paperId": "dc2451d6cbf8270ecb54d7ee3eca44de3c84527c",
            "title": "GoSPA: An Energy-efficient High-performance Globally Optimized SParse Convolutional Neural Network Accelerator"
        },
        {
            "paperId": "bd2d1ec40a366294b1fd969dc3abe323511984d5",
            "title": "Sparsity-Aware and Re-configurable NPU Architecture for Samsung Flagship Mobile SoC"
        },
        {
            "paperId": "ae5e7794aaff65590e265bdf4d65c44f6fa05064",
            "title": "Dual-side Sparse Tensor Core"
        },
        {
            "paperId": "13d0fc47ba81fa824292ad16aaf939b05a4e0b24",
            "title": "Capstan: A Vector RDA for Sparsity"
        },
        {
            "paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4",
            "title": "Learning Transferable Visual Models From Natural Language Supervision"
        },
        {
            "paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881",
            "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"
        },
        {
            "paperId": "ed7a1bc29f273d296b1881a973141633226245ec",
            "title": "SPAGHETTI: Streaming Accelerators for Highly Sparse GEMM on FPGAs"
        },
        {
            "paperId": "7e5589aa46d506d7fd5c9534b0844c4a0d0d566d",
            "title": "VIA: A Smart Scratchpad for Vector Units with Application to Sparse Matrix Computations"
        },
        {
            "paperId": "73e0f38ab49b19b86321016b773e15f1d02e3a72",
            "title": "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning"
        },
        {
            "paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
        },
        {
            "paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504",
            "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"
        },
        {
            "paperId": "f00f2d4b8ddd55aa2cc202f44053e5f97a254175",
            "title": "WikiLingua: A New Benchmark Dataset for Multilingual Abstractive Summarization"
        },
        {
            "paperId": "44b67c61fea56e7b132a447d19a4cdb064b42470",
            "title": "MatRaptor: A Sparse-Sparse Matrix Multiplication Accelerator Based on Row-Wise Product"
        },
        {
            "paperId": null,
            "title": "Transformers: State-of-the-Art Natural Language Processing"
        },
        {
            "paperId": "9bc25860c60974331283216ef16425095477f84a",
            "title": "Procrustes: a Dataflow and Accelerator for Sparse Deep Neural Network Training"
        },
        {
            "paperId": "574db321479d78b30a242b54712bd9aa26eb7e4b",
            "title": "TensorDash: Exploiting Sparsity to Accelerate Deep Neural Network Training"
        },
        {
            "paperId": "7c6c31412c5dad22543bb71e31620e8868d644a3",
            "title": "FTRANS: energy-efficient acceleration of transformers using FPGA"
        },
        {
            "paperId": "6ab7393739616fb613f60c36ee96933104528d5d",
            "title": "tpSpMV: A two-phase large-scale sparse matrix-vector multiplication kernel for manycore architectures"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e",
            "title": "End-to-End Object Detection with Transformers"
        },
        {
            "paperId": "e5e3dcbea7a174ee851f6b2f2fcbad1f6602bcf2",
            "title": "DT-CNN: An Energy-Efficient Dilated and Transposed Convolutional Neural Network Processor for Region of Interest Based Image Segmentation"
        },
        {
            "paperId": "1b0c8b26affd13e10ace5770e85478d60dcc368e",
            "title": "GOBO: Quantizing Attention-Based NLP Models for Low Latency and Energy Efficient Inference"
        },
        {
            "paperId": "8af925f4edf45131b5b6fed8aa655089d58692fa",
            "title": "Lite Transformer with Long-Short Range Attention"
        },
        {
            "paperId": "d3c6c635b9cfd8890c7244d3db4be53d45944963",
            "title": "A^3: Accelerating Attention Mechanisms in Neural Networks with Approximation"
        },
        {
            "paperId": "25c679e5d2c4ac6e0a6f3d57081e28a40b0d70a1",
            "title": "ALRESCHA: A Lightweight Reconfigurable Sparse-Computation Accelerator"
        },
        {
            "paperId": "fcf1b4473a0af1f3ebc0fd556ee30c9309ff6345",
            "title": "SIGMA: A Sparse and Irregular GEMM Accelerator with Flexible Interconnects for DNN Training"
        },
        {
            "paperId": "35de1db54e5f4e6af59fd0fcfb83c381e730633a",
            "title": "Energy- and Area-Efficient Recursive-Conjugate-Gradient-Based MMSE Detector for Massive MIMO Systems"
        },
        {
            "paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
        },
        {
            "paperId": "87a494fcc23aa9cea191f75e3b599e63d3bdab35",
            "title": "SMASH: Co-designing Software Compression and Hardware-Accelerated Indexing for Efficient Sparse Matrix Operations"
        },
        {
            "paperId": "232d04b1cc0e9ad535a35e00aaa80360ec3e72c4",
            "title": "ExTensor: An Accelerator for Sparse Tensor Algebra"
        },
        {
            "paperId": "efa7a4154f5987ab485184597f4eabcc572e7360",
            "title": "Efficient SpMV Operation for Large and Highly Sparse Matrices using Scalable Multi-way Merge Parallelization"
        },
        {
            "paperId": "f9cd024497e1504c07a606a0df277441819a9e0d",
            "title": "SparTen: A Sparse Tensor Accelerator for Convolutional Neural Networks"
        },
        {
            "paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc",
            "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"
        },
        {
            "paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b",
            "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"
        },
        {
            "paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a",
            "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"
        },
        {
            "paperId": "989fa897fdb002a9a7cc4175f3b011ef5f9480cb",
            "title": "TensorDIMM: A Practical Near-Memory Processing Architecture for Embeddings and Tensor Operations in Deep Learning"
        },
        {
            "paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de",
            "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"
        },
        {
            "paperId": "f8e812169c2fdf9b3ba4361c6239d847b362ddc1",
            "title": "A Full HD 60 fps CNN Super Resolution Processor with Selective Caching based Layer Fusion for Mobile Devices"
        },
        {
            "paperId": "a821a00c54749a69a9d9fe0a7411de590d247715",
            "title": "DNNBuilder: an Automated Tool for Building High-Performance DNN Hardware Accelerators for FPGAs"
        },
        {
            "paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"
        },
        {
            "paperId": "5592c7e0225c956419a9a315718a87190b33f4c2",
            "title": "An Energy-Efficient Architecture for Binary Weight Convolutional Neural Networks"
        },
        {
            "paperId": "b36a5bb1707bb9c70025294b3a310138aae8327a",
            "title": "Automatic differentiation in PyTorch"
        },
        {
            "paperId": "469cbf3ed1237982e4b48e2db96fcb17435d4b1b",
            "title": "Hardware Design of Low-Power High-Throughput Sorting Unit"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "72ed74f00d0f7312f7ed96d93ed43f0052d526bc",
            "title": "Fused-layer CNN accelerators"
        },
        {
            "paperId": "efbd381493bb9636f489b965a2034d529cd56bcd",
            "title": "Pointer Sentinel Mixture Models"
        },
        {
            "paperId": "1853613a290537b4353763340ab8b37ad236bca2",
            "title": "YodaNN: An Ultra-Low Power Convolutional Neural Network Accelerator Based on Binary Weights"
        },
        {
            "paperId": "05dd7254b632376973f3a1b4d39485da17814df5",
            "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"
        },
        {
            "paperId": "21d7130230162af2a4cc1b9375bfe9b37dbbd499",
            "title": "Origami: A 803-GOp/s/W Convolutional Network Accelerator"
        },
        {
            "paperId": "7ee8bbe9c7c57cb5e114d2ec1f7f5abb5c2ca9ae",
            "title": "Modular Design Of Fast Leading Zeros Counting Circuit"
        },
        {
            "paperId": "f2f60e6e5d0464a0e1baf60c55d7e9f4acc9a9d5",
            "title": "A 4.3 GB/s Mobile Memory Interface With Power-Efficient Bandwidth Scaling"
        },
        {
            "paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e",
            "title": "ImageNet: A large-scale hierarchical image database"
        },
        {
            "paperId": "092217c2267f6e0673590aa151d811e579ff7760",
            "title": "Roofline: an insightful visual performance model for multicore architectures"
        },
        {
            "paperId": "ce30ce98e92a3f0e2431eb58c1b48e7f087354ce",
            "title": "Ouroboros: Speculative Decoding with Large Model Enhanced Drafting"
        },
        {
            "paperId": "bc4bf86b9bd3bc4311ca64485a02323024f81ad4",
            "title": "Accelerating Attention through Gradient-Based Learned Runtime Pruning"
        },
        {
            "paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7",
            "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"
        },
        {
            "paperId": null,
            "title": "A New Benchmark Dataset for Multilingual Abstractive Summarization, author=Faisal Ladhak, Esin Durmus, Claire Cardie and Kathleen McKeown"
        },
        {
            "paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28",
            "title": "An Adversarial Winograd Schema Challenge at Scale"
        },
        {
            "paperId": "9405cc0d6169988371b2755e573cc28650d14dfe",
            "title": "Language Models are Unsupervised Multitask Learners"
        },
        {
            "paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "title": "Improving Language Understanding by Generative Pre-Training"
        },
        {
            "paperId": null,
            "title": "In-datacenter"
        },
        {
            "paperId": "ff5da2bc9951173d51fcc1d50d44488702b5f1f5",
            "title": "Ramulator: A Fast and Extensible DRAM Simulator"
        },
        {
            "paperId": null,
            "title": "Computing\u2019s Energy Problem (and what we can do about it)"
        },
        {
            "paperId": null,
            "title": "Modern Computer Arithmetic , volume 18"
        },
        {
            "paperId": "3364bc50921a9566d61ef8cb73baa82341725e4b",
            "title": "CACTI 6.0: A Tool to Model Large Caches"
        },
        {
            "paperId": "6a630ac89d7c0a57eb7bf4cb30dd5946bcf3ccce",
            "title": "google,\u6211,\u8428\u5a1c"
        },
        {
            "paperId": null,
            "title": "Verilator and Systemperl"
        }
    ]
}