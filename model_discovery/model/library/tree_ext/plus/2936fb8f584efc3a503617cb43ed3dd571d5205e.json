{
    "paperId": "2936fb8f584efc3a503617cb43ed3dd571d5205e",
    "externalIds": {
        "DBLP": "journals/corr/abs-2407-17412",
        "ArXiv": "2407.17412",
        "DOI": "10.48550/arXiv.2407.17412",
        "CorpusId": 271404197
    },
    "title": "(PASS) Visual Prompt Locates Good Structure Sparsity through a Recurrent HyperNetwork",
    "abstract": "Large-scale neural networks have demonstrated remarkable performance in different domains like vision and language processing, although at the cost of massive computation resources. As illustrated by compression literature, structural model pruning is a prominent algorithm to encourage model efficiency, thanks to its acceleration-friendly sparsity patterns. One of the key questions of structural pruning is how to estimate the channel significance. In parallel, work on data-centric AI has shown that prompting-based techniques enable impressive generalization of large language models across diverse downstream tasks. In this paper, we investigate a charming possibility - \\textit{leveraging visual prompts to capture the channel importance and derive high-quality structural sparsity}. To this end, we propose a novel algorithmic framework, namely \\texttt{PASS}. It is a tailored hyper-network to take both visual prompts and network weight statistics as input, and output layer-wise channel sparsity in a recurrent manner. Such designs consider the intrinsic channel dependency between layers. Comprehensive experiments across multiple network architectures and six datasets demonstrate the superiority of \\texttt{PASS} in locating good structural sparsity. For example, at the same FLOPs level, \\texttt{PASS} subnetworks achieve $1\\%\\sim 3\\%$ better accuracy on Food101 dataset; or with a similar performance of $80\\%$ accuracy, \\texttt{PASS} subnetworks obtain $0.35\\times$ more speedup than the baselines.",
    "venue": "arXiv.org",
    "year": 2024,
    "referenceCount": 100,
    "citationCount": 0,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This paper proposes a novel algorithmic framework, namely \\texttt{PASS}, a tailored hyper-network to take both visual prompts and network weight statistics as input, and output layer-wise channel sparsity in a recurrent manner, which considers the intrinsic channel dependency between layers."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -4.418694496154785,
            0.19754469394683838,
            -0.4382489323616028,
            2.537982940673828,
            1.9588162899017334,
            0.9545934200286865,
            4.665360927581787,
            -0.5768774747848511,
            0.946983277797699,
            0.979385256767273,
            -2.575015068054199,
            3.8638057708740234,
            -2.616933822631836,
            0.09277895092964172,
            -3.888298988342285,
            -0.04602628946304321,
            -2.2623953819274902,
            -1.9659358263015747,
            4.540741443634033,
            4.10455846786499,
            -2.3510894775390625,
            -1.054305911064148,
            -0.35188406705856323,
            -1.2424330711364746,
            -3.4903368949890137,
            -2.443084239959717,
            2.8088417053222656,
            0.2195325493812561,
            -0.15945583581924438,
            0.32198071479797363,
            -0.9950581789016724,
            -4.61331033706665,
            8.170284271240234,
            -0.8068011999130249,
            4.046010971069336,
            -0.3397611975669861,
            -2.24924635887146,
            5.139571189880371,
            -3.621176242828369,
            0.6083332300186157,
            1.0640339851379395,
            1.9259278774261475,
            0.15426455438137054,
            -0.3844664990901947,
            0.6549986600875854,
            -1.5428601503372192,
            -3.0266828536987305,
            4.918979644775391,
            -2.89683198928833,
            2.378114700317383,
            1.5158145427703857,
            0.9034799337387085,
            -0.33605095744132996,
            1.620776653289795,
            -1.4404606819152832,
            -1.607447862625122,
            1.7489633560180664,
            2.4069180488586426,
            2.8584752082824707,
            -5.2338972091674805,
            5.612378120422363,
            1.7649798393249512,
            -2.0767292976379395,
            -1.5983426570892334,
            3.343804359436035,
            -4.1644792556762695,
            2.408017158508301,
            6.829556941986084,
            -0.53704833984375,
            0.5064433813095093,
            -0.6083110570907593,
            -7.622342109680176,
            1.7927932739257812,
            0.5975885391235352,
            -0.4080190062522888,
            -0.3210126757621765,
            -0.6658747792243958,
            -5.639074325561523,
            -2.8190131187438965,
            -3.3664019107818604,
            1.3577983379364014,
            2.6035332679748535,
            1.7259150743484497,
            3.8375303745269775,
            3.5493569374084473,
            -1.3267741203308105,
            -1.9940996170043945,
            -0.8949280381202698,
            1.2689696550369263,
            -4.955111980438232,
            1.1938821077346802,
            0.9126206636428833,
            -0.6795955896377563,
            0.7338321805000305,
            -3.1381399631500244,
            -0.38141006231307983,
            0.21399521827697754,
            0.07155638933181763,
            -4.0500640869140625,
            0.9832149744033813,
            1.6877890825271606,
            -0.7476015090942383,
            2.800255537033081,
            -1.0302549600601196,
            5.922910690307617,
            -4.4883575439453125,
            -0.5699610710144043,
            2.662360191345215,
            2.9878149032592773,
            -3.242173910140991,
            -1.292926549911499,
            1.4564158916473389,
            -1.9326233863830566,
            -0.9609020948410034,
            -0.7218643426895142,
            -1.7020076513290405,
            -0.023551002144813538,
            -0.36301514506340027,
            -1.776233434677124,
            3.8845977783203125,
            -3.3349039554595947,
            1.074620008468628,
            -5.60214900970459,
            3.8850269317626953,
            2.331249713897705,
            1.5370564460754395,
            0.4547080397605896,
            -0.08164472877979279,
            1.5661343336105347,
            -4.547067642211914,
            0.590219259262085,
            -0.8328461050987244,
            1.0386697053909302,
            -2.1319003105163574,
            5.145263671875,
            5.520449638366699,
            -2.3265016078948975,
            2.1791934967041016,
            0.13928064703941345,
            -0.34170544147491455,
            0.28948286175727844,
            2.694594144821167,
            -3.222144603729248,
            -1.9975764751434326,
            -0.38847577571868896,
            5.24924373626709,
            -0.5557800531387329,
            4.4653425216674805,
            1.4664362668991089,
            6.770118236541748,
            3.9865636825561523,
            -3.377866744995117,
            -1.0916634798049927,
            3.78340482711792,
            3.786444902420044,
            1.4410130977630615,
            -4.978370666503906,
            -1.7383438348770142,
            -2.4683923721313477,
            1.5213820934295654,
            0.21746763586997986,
            -1.0306904315948486,
            -11.301112174987793,
            -1.262070894241333,
            3.0374104976654053,
            -4.7180938720703125,
            -1.9483494758605957,
            -0.47194504737854004,
            -0.2403566837310791,
            5.761903762817383,
            0.0601891428232193,
            1.8309673070907593,
            -0.9267688989639282,
            5.645304203033447,
            3.202430248260498,
            4.134132385253906,
            -0.5073624849319458,
            0.16586092114448547,
            -2.739290714263916,
            0.9978523254394531,
            0.2088681012392044,
            1.2434626817703247,
            -7.143454074859619,
            -0.34441977739334106,
            -4.792966842651367,
            -0.21889711916446686,
            -1.1275136470794678,
            0.8675252795219421,
            -3.437413215637207,
            -2.7323966026306152,
            -0.09815892577171326,
            -1.0599710941314697,
            4.97936487197876,
            6.611071586608887,
            2.640619993209839,
            2.410533905029297,
            2.182135581970215,
            1.188593864440918,
            -1.3156664371490479,
            4.149302005767822,
            1.5024524927139282,
            1.633542537689209,
            -0.7169285416603088,
            1.6158783435821533,
            2.748636245727539,
            1.2385741472244263,
            -2.9619390964508057,
            1.865991473197937,
            0.3809454143047333,
            0.6736754775047302,
            2.417701005935669,
            1.9145323038101196,
            -1.246806025505066,
            2.8394904136657715,
            -4.163469314575195,
            -0.2284078598022461,
            -6.702070236206055,
            0.8644950985908508,
            4.524931907653809,
            0.8203184604644775,
            0.4167039692401886,
            -2.2308926582336426,
            0.7532927393913269,
            -2.6234090328216553,
            -0.6285070180892944,
            -2.0111446380615234,
            5.1757731437683105,
            -0.6227067112922668,
            1.4206002950668335,
            0.4320071041584015,
            -0.3738977313041687,
            -4.013067722320557,
            1.1503779888153076,
            -2.4062447547912598,
            -6.527822494506836,
            -4.766509056091309,
            -1.625317931175232,
            2.9987587928771973,
            0.5825233459472656,
            -0.6274360418319702,
            4.620293617248535,
            0.6821833252906799,
            1.604910135269165,
            3.377753257751465,
            -0.7685080766677856,
            1.6826937198638916,
            -4.517661094665527,
            0.32429125905036926,
            2.8838465213775635,
            -3.928910970687866,
            -1.2846457958221436,
            -1.275156021118164,
            2.8253602981567383,
            -0.7224932312965393,
            1.9370338916778564,
            1.3581067323684692,
            -0.1016266942024231,
            1.774524211883545,
            0.8312198519706726,
            1.345093011856079,
            -0.15087321400642395,
            1.066826343536377,
            4.094043731689453,
            2.857257127761841,
            0.2697722315788269,
            -3.0833754539489746,
            -1.5731792449951172,
            1.8688009977340698,
            -3.3813183307647705,
            0.789472222328186,
            0.5158844590187073,
            1.8678096532821655,
            -0.5226143598556519,
            -3.968827486038208,
            -4.013354301452637,
            -3.8377437591552734,
            -2.164839744567871,
            -1.3145569562911987,
            1.365991234779358,
            3.245784282684326,
            1.3878793716430664,
            -1.178993582725525,
            -1.8911606073379517,
            -2.247291326522827,
            -0.109578937292099,
            -4.596433162689209,
            -2.8225672245025635,
            -4.965208053588867,
            1.5059146881103516,
            -1.3759762048721313,
            -3.530205011367798,
            2.269458055496216,
            -0.21163885295391083,
            -1.0893265008926392,
            -4.704943656921387,
            4.023015022277832,
            6.411642551422119,
            0.745373010635376,
            -1.2812583446502686,
            -2.5559988021850586,
            -2.561383008956909,
            3.0537352561950684,
            3.449911117553711,
            -1.9068775177001953,
            2.7187623977661133,
            5.513621807098389,
            0.04735347628593445,
            -0.1524134874343872,
            3.6121342182159424,
            -7.3295745849609375,
            -2.4816336631774902,
            -1.6097661256790161,
            4.106499195098877,
            -5.113844871520996,
            -2.8244664669036865,
            0.018385589122772217,
            2.568610191345215,
            -1.11198890209198,
            -1.9985542297363281,
            1.6926162242889404,
            -1.9089683294296265,
            1.1089239120483398,
            -3.9515066146850586,
            -4.511463642120361,
            -4.168607711791992,
            3.81564998626709,
            6.410953998565674,
            4.55776834487915,
            0.4050229787826538,
            3.274369716644287,
            -1.0109293460845947,
            6.263976573944092,
            3.430187463760376,
            1.9589529037475586,
            -4.634443759918213,
            -7.869053840637207,
            -2.6540560722351074,
            -1.6295982599258423,
            3.0157361030578613,
            1.1702520847320557,
            -1.2867403030395508,
            5.4592790603637695,
            -0.4134872257709503,
            0.4845428168773651,
            -0.9179390668869019,
            1.6167333126068115,
            1.485353708267212,
            -1.6083755493164062,
            -1.401280403137207,
            -1.154536247253418,
            -1.887553095817566,
            2.1403603553771973,
            3.4084548950195312,
            -2.5816054344177246,
            3.4202046394348145,
            3.158160448074341,
            1.388335108757019,
            1.1632181406021118,
            2.579342842102051,
            1.2666734457015991,
            0.42049843072891235,
            -0.5128605365753174,
            -0.5447123050689697,
            -2.539243698120117,
            -2.595099925994873,
            -2.631267547607422,
            11.003713607788086,
            -2.034869432449341,
            -1.1934309005737305,
            -1.3832415342330933,
            -4.587587356567383,
            -1.4047281742095947,
            -4.791698932647705,
            4.397523403167725,
            -3.9939393997192383,
            -1.2606425285339355,
            0.5471199154853821,
            -3.885854721069336,
            1.904757022857666,
            3.5924923419952393,
            -1.712155818939209,
            3.384415864944458,
            0.10878366231918335,
            3.3899431228637695,
            1.0189560651779175,
            2.352863311767578,
            -3.3128762245178223,
            4.370327949523926,
            0.8052693605422974,
            -0.5742042660713196,
            -1.3027803897857666,
            3.459479570388794,
            -1.1002395153045654,
            0.48139140009880066,
            -3.9313690662384033,
            -3.581284523010254,
            -2.855116128921509,
            -4.039263725280762,
            -0.9554288387298584,
            1.115700125694275,
            0.49830394983291626,
            4.592755317687988,
            5.808107376098633,
            4.662736415863037,
            -3.9403796195983887,
            -1.1362488269805908,
            2.623774290084839,
            -3.915522336959839,
            -5.247189521789551,
            0.7946804165840149,
            -5.540975570678711,
            -2.367569923400879,
            -3.348029613494873,
            -3.9450230598449707,
            1.0373762845993042,
            -0.4215538501739502,
            -0.5573144555091858,
            3.429863452911377,
            1.7297791242599487,
            -0.12456685304641724,
            -4.204156875610352,
            4.6261305809021,
            4.019024848937988,
            2.0598511695861816,
            -0.15320301055908203,
            3.6854207515716553,
            4.951357841491699,
            2.8488242626190186,
            -0.906090497970581,
            1.3059661388397217,
            -1.9137184619903564,
            1.9988079071044922,
            -2.7937450408935547,
            -4.136913299560547,
            -2.8586058616638184,
            5.747718334197998,
            5.651905059814453,
            1.2785186767578125,
            0.6634534001350403,
            0.9742202758789062,
            0.9425858855247498,
            3.7625458240509033,
            -2.445573091506958,
            2.0075855255126953,
            0.5112981200218201,
            0.4080340266227722,
            0.41321080923080444,
            -0.9797223806381226,
            0.02643442153930664,
            -5.698691368103027,
            2.4626669883728027,
            -1.9643608331680298,
            -3.979001760482788,
            0.8065157532691956,
            -1.5787886381149292,
            -0.02934744954109192,
            -2.732820987701416,
            -1.5151054859161377,
            3.178900718688965,
            -1.9318702220916748,
            -5.023184776306152,
            2.3701817989349365,
            -2.3833534717559814,
            2.8990087509155273,
            1.1430803537368774,
            2.992082118988037,
            -2.5874252319335938,
            0.5258067846298218,
            -3.2744574546813965,
            5.761268615722656,
            2.8704161643981934,
            -0.8711892366409302,
            -2.3568058013916016,
            1.3305034637451172,
            0.7427361011505127,
            2.5186939239501953,
            1.269361138343811,
            3.4121346473693848,
            -0.7048678398132324,
            -4.393293380737305,
            -2.5145249366760254,
            -0.7715022563934326,
            3.802584648132324,
            -4.77750301361084,
            -3.270939588546753,
            7.019362449645996,
            3.9006290435791016,
            4.571134567260742,
            3.4754183292388916,
            0.5337631702423096,
            -0.5084795951843262,
            1.4949305057525635,
            5.3236846923828125,
            -2.1384923458099365,
            -0.09727537631988525,
            -0.3749242424964905,
            -4.467871189117432,
            0.1704193353652954,
            -1.7209687232971191,
            1.2081800699234009,
            2.3167905807495117,
            -5.012619972229004,
            -1.6698675155639648,
            -0.8895661234855652,
            -3.4497804641723633,
            5.838357925415039,
            0.6011024713516235,
            2.3686635494232178,
            -0.39466267824172974,
            -0.5736221671104431,
            -2.9682207107543945,
            0.8263167142868042,
            -8.256592750549316,
            0.2887569069862366,
            0.05677078664302826,
            3.402498483657837,
            4.048813819885254,
            -0.10045868158340454,
            -0.19161126017570496,
            2.6647140979766846,
            -1.7805699110031128,
            -0.09594947099685669,
            -1.7400786876678467,
            3.693559169769287,
            1.7976597547531128,
            2.8602547645568848,
            -3.0380823612213135,
            0.6204054951667786,
            1.858119010925293,
            5.1681694984436035,
            5.593625068664551,
            3.268886089324951,
            1.881457805633545,
            -2.8939385414123535,
            -1.8021962642669678,
            -5.581733703613281,
            0.47805705666542053,
            5.548161029815674,
            -4.67365026473999,
            -4.410801887512207,
            0.8486835956573486,
            -1.014683723449707,
            1.0713064670562744,
            2.7965683937072754,
            0.20185863971710205,
            5.907858371734619,
            -3.9452710151672363,
            -0.42065128684043884,
            -3.242158889770508,
            2.9261300563812256,
            0.01077704131603241,
            -0.9006942510604858,
            -1.1700515747070312,
            -0.7091294527053833,
            -0.3479151725769043,
            -2.8056869506835938,
            -2.562455654144287,
            0.09810823202133179,
            -1.8117082118988037,
            1.6118327379226685,
            3.6555542945861816,
            -0.9772199392318726,
            0.6520994901657104,
            2.396261692047119,
            -0.6059749722480774,
            -3.9301609992980957,
            -2.25522518157959,
            5.544731616973877,
            3.258533477783203,
            -0.040632545948028564,
            1.058142900466919,
            -3.565514087677002,
            -0.37455105781555176,
            2.6255221366882324,
            5.413620948791504,
            2.7172281742095947,
            0.551993191242218,
            2.4715888500213623,
            -3.0874667167663574,
            -2.7518844604492188,
            -1.3495969772338867,
            0.27563712000846863,
            -3.643939256668091,
            -5.577541351318359,
            -1.7328002452850342,
            -2.925985336303711,
            -2.300861358642578,
            1.4916292428970337,
            -2.893115282058716,
            -0.46524369716644287,
            4.264168739318848,
            -1.1601039171218872,
            -0.6985227465629578,
            -3.3332254886627197,
            -2.1633403301239014,
            -4.640110969543457,
            3.640596866607666,
            0.08589589595794678,
            -2.784198522567749,
            1.3091856241226196,
            3.172882318496704,
            1.3284488916397095,
            5.935180187225342,
            1.6890912055969238,
            -5.372298717498779,
            1.1984660625457764,
            1.9914584159851074,
            2.343350887298584,
            -4.728482246398926,
            -1.276082992553711,
            0.6340715289115906,
            2.088407278060913,
            15.16288948059082,
            0.5047838687896729,
            -0.7257523536682129,
            -2.296050786972046,
            0.8294884562492371,
            -4.381311893463135,
            0.8533710837364197,
            5.821812629699707,
            0.12712633609771729,
            0.05718456208705902,
            -1.114985466003418,
            -3.736605167388916,
            0.17451979219913483,
            0.10491089522838593,
            -5.114109992980957,
            -1.0316722393035889,
            -2.8627490997314453,
            2.8577382564544678,
            -2.676964521408081,
            1.7129653692245483,
            -2.254869222640991,
            1.0249799489974976,
            -2.749406337738037,
            -0.9041321277618408,
            2.9441819190979004,
            1.7493271827697754,
            -1.1763396263122559,
            3.3624911308288574,
            -6.8147759437561035,
            -0.9137178659439087,
            -1.287097692489624,
            1.2534668445587158,
            -0.46287351846694946,
            -0.0876501202583313,
            -1.3576757907867432,
            4.315080642700195,
            4.279060363769531,
            -1.2018183469772339,
            3.5986249446868896,
            1.9001860618591309,
            -0.2869202196598053,
            -0.3476337790489197,
            -4.045326232910156,
            3.5289244651794434,
            -1.8483502864837646,
            -0.6446481943130493,
            3.086001396179199,
            -0.8481627702713013,
            -4.554775714874268,
            5.725227355957031,
            -1.6812714338302612,
            1.9427595138549805,
            -5.413966655731201,
            3.410857677459717,
            2.56416392326355,
            6.841498851776123,
            1.0644584894180298,
            -2.0533013343811035,
            2.8370752334594727,
            -1.3185667991638184,
            1.5663050413131714,
            1.12066650390625,
            -0.2649185061454773,
            -1.3111189603805542,
            1.6900718212127686,
            1.708304524421692,
            -3.35788631439209,
            2.118562698364258,
            0.6148369908332825,
            0.6535168290138245,
            4.7450103759765625,
            1.9873642921447754,
            -0.3477415144443512,
            -3.113307237625122,
            -1.831608533859253,
            -3.9714343547821045,
            2.533039093017578,
            -2.671278953552246,
            -0.18979284167289734,
            6.437051773071289,
            -3.834447145462036,
            1.1413027048110962,
            -3.4998457431793213,
            0.42242300510406494,
            5.100595474243164,
            -1.1050987243652344,
            2.6089086532592773,
            -1.2580047845840454,
            -0.5602037310600281,
            1.1911487579345703,
            1.9153783321380615,
            0.7341675758361816,
            4.257630348205566,
            -0.3544016182422638,
            6.184950351715088,
            -4.180828094482422,
            -4.30784797668457,
            -4.883065700531006,
            -5.9810261726379395,
            -3.070613384246826,
            5.551548957824707,
            4.808911323547363,
            2.127007484436035,
            -3.337648391723633,
            0.18734431266784668,
            -0.7508734464645386,
            -1.0660450458526611,
            -4.533050537109375,
            -3.457881450653076,
            -2.7665629386901855,
            4.441747665405273,
            -2.6796340942382812,
            -0.27527326345443726,
            -1.7378840446472168,
            2.480293035507202,
            -4.466141700744629,
            -0.17639589309692383,
            2.5545477867126465,
            2.468958854675293,
            4.995814323425293,
            0.6301711201667786,
            -1.0307419300079346,
            -3.8160223960876465,
            -3.0215845108032227,
            -3.0614569187164307,
            2.692070484161377,
            1.2368320226669312,
            -0.41075560450553894,
            -0.42277100682258606,
            -2.819443702697754,
            1.1160967350006104,
            -2.3649497032165527,
            -0.8800233602523804,
            0.6844625473022461,
            -0.1213451623916626,
            -1.3488943576812744,
            -2.4313559532165527,
            3.2065792083740234,
            -3.680284261703491,
            5.4381103515625,
            4.6913957595825195,
            -1.5157256126403809,
            -0.6220930218696594,
            8.17702579498291,
            0.5156797170639038,
            1.000121831893921,
            -2.0475025177001953,
            -2.672395706176758,
            -2.3737690448760986,
            0.28372499346733093,
            2.575693130493164,
            -1.5044214725494385,
            0.39383307099342346,
            -1.9608783721923828,
            -0.3842570185661316,
            -2.3228540420532227
        ]
    },
    "authors": [
        {
            "authorId": "8242939",
            "name": "Tianjin Huang"
        },
        {
            "authorId": "2182421180",
            "name": "Fang Meng"
        },
        {
            "authorId": "2202890812",
            "name": "Lijuan Shen"
        },
        {
            "authorId": "2312916269",
            "name": "Fan Liu"
        },
        {
            "authorId": "1382535564",
            "name": "Yulong Pei"
        },
        {
            "authorId": "1691997",
            "name": "Mykola Pechenizkiy"
        },
        {
            "authorId": "47130544",
            "name": "Shiwei Liu"
        },
        {
            "authorId": "2308544925",
            "name": "Tianlong Chen"
        }
    ],
    "references": [
        {
            "paperId": "7d22ad3573101337bca2091fb0114b377c4f3db6",
            "title": "A Simple and Effective Pruning Approach for Large Language Models"
        },
        {
            "paperId": "2922768fd451ecdb45f48c1a83eb57f54a91221b",
            "title": "Textbooks Are All You Need"
        },
        {
            "paperId": "9d460930d9b5d12a65ff2b3efa23047ec75fbca1",
            "title": "The Emergence of Essential Sparsity in Large Pre-trained Models: The Weights that Matter"
        },
        {
            "paperId": "a221de00c82d9ed0bdc4278866390c737c09d391",
            "title": "Are Large Kernels Better Teachers than Transformers for ConvNets?"
        },
        {
            "paperId": "8f4358ee06b8ecbff57b0c2f08bf801f0836b6e2",
            "title": "Dynamic Sparsity Is Channel-Level Sparsity Learner"
        },
        {
            "paperId": "017010b941d902a467f6d329ae5e74fd67e67912",
            "title": "LLM-Pruner: On the Structural Pruning of Large Language Models"
        },
        {
            "paperId": "5f187af087ebbaf1ce4bca686a4b1c2afee92b6d",
            "title": "Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt"
        },
        {
            "paperId": "12c200e731017f9851afb1a6fe3fc7f76e6439c6",
            "title": "Explicit Visual Prompting for Low-Level Structure Segmentations"
        },
        {
            "paperId": "12c6be503e4e5b7c9cb1810152d4364f26628a8d",
            "title": "Data-centric Artificial Intelligence: A Survey"
        },
        {
            "paperId": "e60b6836b45ad0ae02a5fa663c8c31119f0c0a94",
            "title": "X-Pruner: eXplainable Pruning for Vision Transformers"
        },
        {
            "paperId": "57e849d0de13ed5f91d086936296721d4ff75a75",
            "title": "LLaMA: Open and Efficient Foundation Language Models"
        },
        {
            "paperId": "6fbf4e4c7872efdc03f7003d2d89b15ad8c4c552",
            "title": "The Capacity for Moral Self-Correction in Large Language Models"
        },
        {
            "paperId": "61e721334296ebfbbf6443b5ed9eb8c83b708c95",
            "title": "Scaling Vision Transformers to 22 Billion Parameters"
        },
        {
            "paperId": "da075ad0ec2c88335af85602a76a33e034536896",
            "title": "DepGraph: Towards Any Structural Pruning"
        },
        {
            "paperId": "86478f285356b5c8d27423e6b939634d9e010fba",
            "title": "Progressive Prompts: Continual Learning for Language Models"
        },
        {
            "paperId": "909ad57ce8caa6b390a65ae09db352d27d8f3996",
            "title": "SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot"
        },
        {
            "paperId": "11972f9f5a0226546aa3f21d54efab84e7a8ce01",
            "title": "You Can Have Better Graph Neural Networks by Not Training Weights at All: Finding Untrained GNNs Tickets"
        },
        {
            "paperId": "4edd2d2770729380eda23826af1b78298b334a23",
            "title": "Understanding and Improving Visual Prompting: A Label-Mapping Perspective"
        },
        {
            "paperId": "2c994fadbb84fb960d8306ee138dbeef41a5b323",
            "title": "SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models"
        },
        {
            "paperId": "09b7338021fff3200c2098b19824aecc83a66cb5",
            "title": "Unified Vision and Language Prompt Learning"
        },
        {
            "paperId": "e9bebbe12a1124dee2214e3f6bd7973540d8af63",
            "title": "LPT: Long-tailed Prompt Tuning for Image Classification"
        },
        {
            "paperId": "5ca02297d8d49f03f26148b74fea77272d09c78b",
            "title": "Prompt Vision Transformer for Domain Generalization"
        },
        {
            "paperId": "4be7d1524edb0137599a5cc95f72844b85a52fe1",
            "title": "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale"
        },
        {
            "paperId": "3268da152f1149675b5f1cfd03f97026128b9e09",
            "title": "Neural Prompt Search"
        },
        {
            "paperId": "81986b8a3d3fe6c5be06fc4527953fb514ad12e8",
            "title": "Improving In-Context Few-Shot Learning via Self-Supervised Training"
        },
        {
            "paperId": "aa8c61c9f6bb21c57e49611ccb995cfda1b53b10",
            "title": "Exploring Visual Prompts for Adapting Large-Scale Models"
        },
        {
            "paperId": "adb272fbdea3631059cf88ab764bb6c2ce29f965",
            "title": "Visual Prompt Tuning"
        },
        {
            "paperId": "b879450f50a6113f44a5baf0bcd5b4331eeb7bbc",
            "title": "Conditional Prompt Learning for Vision-Language Models"
        },
        {
            "paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
            "title": "Training language models to follow instructions with human feedback"
        },
        {
            "paperId": "f4df78183261538e718066331898ee5cad7cad05",
            "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"
        },
        {
            "paperId": "a9fe95263c98287c5e97e62bebc1845420babad6",
            "title": "Pruning Networks With Cross-Layer Ranking & k-Reciprocal Nearest Filters"
        },
        {
            "paperId": "821b08d595b6482e3d1f5bab6835b72d67ebd894",
            "title": "The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse Training"
        },
        {
            "paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5",
            "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"
        },
        {
            "paperId": "0c6838f8b1728c8fa5f10d5a3e4a6000e84438e7",
            "title": "HyperStyle: StyleGAN Inversion with HyperNetworks for Real Image Editing"
        },
        {
            "paperId": "7ba86f4a666cb0ba04a4c5c11e0c751cc1fbc204",
            "title": "SOSP: Efficiently Capturing Global Correlations by Second-Order Structured Pruning"
        },
        {
            "paperId": "f3a332ff1b73acda482e5d83696b2c701f487819",
            "title": "P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"
        },
        {
            "paperId": "96ea07447d2f9adefe03852a878517a2a6d45b96",
            "title": "Learning to Prompt for Vision-Language Models"
        },
        {
            "paperId": "7a27cc0cc37931e85315ed41333f01cb6de18c02",
            "title": "Differentiable Subset Pruning of Transformer Heads"
        },
        {
            "paperId": "2dcc6d63e840217306ecdef527ca66706eddc2cb",
            "title": "Group Fisher Pruning for Practical Network Compression"
        },
        {
            "paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069",
            "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"
        },
        {
            "paperId": "a85ba5bb3e97c999f5f6dbc78f277b107af1dba2",
            "title": "Sparse Training via Boosting Pruning Plasticity with Neuroregeneration"
        },
        {
            "paperId": "bb3425318de7eed5641cda147d61c9a057b9d054",
            "title": "Parameter-efficient Multi-task Fine-tuning for Transformers via Shared Hypernetworks"
        },
        {
            "paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4",
            "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"
        },
        {
            "paperId": "1a2e90dff605dad7dbefeed121e6d295c7a77d62",
            "title": "KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction"
        },
        {
            "paperId": "837ac4ed6825502f0460caec45e12e734c85b113",
            "title": "Dynamic Neural Networks: A Survey"
        },
        {
            "paperId": "ed48e85f0f94ae72eafa72aadc6b1e8013a38f47",
            "title": "Network Pruning Using Adaptive Exemplar Filters"
        },
        {
            "paperId": "400080a724d55bbdd3cfc1c54f0aae6af4ec7879",
            "title": "Neural Pruning via Growing Regularization"
        },
        {
            "paperId": "5f6fccc32953f57fe29b2316eb8351e84b0179dc",
            "title": "The Lottery Tickets Hypothesis for Supervised and Self-supervised Pre-training in Computer Vision Models"
        },
        {
            "paperId": "acbd97dbb88658aaa0f88499d1e207ea51962871",
            "title": "Meta-Learning via Hypernetworks"
        },
        {
            "paperId": "1ca969119f4f6006047b159e35267d9a1c4afe8b",
            "title": "On the Modularity of Hypernetworks"
        },
        {
            "paperId": "917b18b8dad23284c0a42f665f2ba1984fa360de",
            "title": "Gradient Flow in Sparse Neural Networks and How Lottery Tickets Win"
        },
        {
            "paperId": "389036b1366b64579725457993c1f63a4f3370ba",
            "title": "The Lottery Ticket Hypothesis for Pre-trained BERT Networks"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "959e6c5ed9f706d91aad8658787cdeac22d5c153",
            "title": "A Feature-map Discriminant Perspective for Pruning Deep Neural Networks"
        },
        {
            "paperId": "d808cf83a9747bff3e9677d1207b1ae99ffb3700",
            "title": "Efficient Image Super Resolution Via Channel Discriminative Deep Neural Network Pruning"
        },
        {
            "paperId": "9e096d124e27c6998ed5c8e429eba655d914fe22",
            "title": "DHP: Differentiable Meta Pruning via HyperNetworks"
        },
        {
            "paperId": "53f5ab272f9d10047ece88f2cc957160e47f5ea9",
            "title": "Good Subnetworks Provably Exist: Pruning via Greedy Forward Selection"
        },
        {
            "paperId": "ad4fb74f6a9f110fc3c9037c379da939e6f1ecad",
            "title": "HRank: Filter Pruning Using High-Rank Feature Map"
        },
        {
            "paperId": "c114ce10c4a315d92c3815f54bc9893e7e6ef182",
            "title": "Picking Winning Tickets Before Training by Preserving Gradient Flow"
        },
        {
            "paperId": "2ea4b0b2e7df55554d331b9e95c61b1f331875aa",
            "title": "Channel Pruning via Automatic Structure Search"
        },
        {
            "paperId": "7a87ab984ca45aae2c5768d22cd6df3b5fd509f9",
            "title": "What\u2019s Hidden in a Randomly Weighted Neural Network?"
        },
        {
            "paperId": "a75649771901a4881b44c0ceafa469fcc6e6f968",
            "title": "How Can We Know What Language Models Know?"
        },
        {
            "paperId": "c038b9997979a9a13d24184e5e2bea7217bbdd24",
            "title": "QKD: Quantization-aware Knowledge Distillation"
        },
        {
            "paperId": "a5cdd9a77304507e0204360a31edf8031c5a6847",
            "title": "Neural Network Pruning With Residual-Connections and Limited-Data"
        },
        {
            "paperId": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf",
            "title": "Patient Knowledge Distillation for BERT Model Compression"
        },
        {
            "paperId": "a6f4917d043494d2ebaebe6b65cb35e6a07fda41",
            "title": "Importance Estimation for Neural Network Pruning"
        },
        {
            "paperId": "a8fe949f73ad7c0ca5cdabed1a0493be72c4a598",
            "title": "Discrimination-aware Channel Pruning for Deep Neural Networks"
        },
        {
            "paperId": "89c10e08902cb90abbe1276a3042b93c2f9c78b4",
            "title": "Graph HyperNetworks for Neural Architecture Search"
        },
        {
            "paperId": "52ff452c2c38d082c07eb434996e07a8c242a692",
            "title": "Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks"
        },
        {
            "paperId": "d16b21f3e99171c86365679435f9f03766750639",
            "title": "NetAdapt: Platform-Aware Neural Network Adaptation for Mobile Applications"
        },
        {
            "paperId": "1717255b6aea01fe956cef998abbc3c399b5d7cf",
            "title": "AMC: AutoML for Model Compression and Acceleration on Mobile Devices"
        },
        {
            "paperId": "3b4d671a8c7018c0b42673ba581e5ff3ae762d6c",
            "title": "To prune, or not to prune: exploring the efficacy of pruning for model compression"
        },
        {
            "paperId": "90a16f34d109b63d95ab4da2d491cbe3a1c8b656",
            "title": "Learning Efficient Convolutional Networks through Network Slimming"
        },
        {
            "paperId": "049fd80f52c0b1fa4d532945d95a24734b62bdf3",
            "title": "ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression"
        },
        {
            "paperId": "ee53c9480132fc0d09b1192226cb2c460462fd6d",
            "title": "Channel Pruning for Accelerating Very Deep Neural Networks"
        },
        {
            "paperId": "2adb616a77fe28b49be2a2d66cccf2d7400e4a04",
            "title": "Data-Driven Sparse Structure Selection for Deep Neural Networks"
        },
        {
            "paperId": "3db8730c203f88d7f08a6a99e8c02a077dc9b011",
            "title": "Pruning Convolutional Neural Networks for Resource Efficient Inference"
        },
        {
            "paperId": "563783de03452683a9206e85fe6d661714436686",
            "title": "HyperNetworks"
        },
        {
            "paperId": "c2a1cb1612ba21e067a5c3ba478a8d73b796b77a",
            "title": "Pruning Filters for Efficient ConvNets"
        },
        {
            "paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "title": "Deep Residual Learning for Image Recognition"
        },
        {
            "paperId": "642d0f49b7826adcf986616f4af77e736229990f",
            "title": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"
        },
        {
            "paperId": "8e3f12804882b60ad5f59aad92755c5edb34860e",
            "title": "Food-101 - Mining Discriminative Components with Random Forests"
        },
        {
            "paperId": "eb42cf88027de515750f230b23b1a057dc782108",
            "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
        },
        {
            "paperId": "a83cec6a91701bd8500f8c43ad731d4353c71d55",
            "title": "3D Object Representations for Fine-Grained Categorization"
        },
        {
            "paperId": "18c125ce0f64e85577f7d30132cf0e92ec664bf4",
            "title": "Describing Textures in the Wild"
        },
        {
            "paperId": "62c76ca0b2790c34e85ba1cce09d47be317c7235",
            "title": "Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation"
        },
        {
            "paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e",
            "title": "ImageNet: A large-scale hierarchical image database"
        },
        {
            "paperId": "5ddb51ae85deca14dc7fc8adc07305c22a1ebe0a",
            "title": "Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities"
        },
        {
            "paperId": "2869a1136502a131eaafe2b9c297b72313d845c3",
            "title": "Dynamic Inter-treatment Information Sharing for Heterogeneous Treatment Effects Estimation"
        },
        {
            "paperId": "49215392c790076064c86c5d6ac301e951d8d42b",
            "title": "TVSPrune - Pruning Non-discriminative filters via Total Variation separability of intermediate representations without fine tuning"
        },
        {
            "paperId": "53d8b356551a2361020a948f64454a6d599af69f",
            "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"
        },
        {
            "paperId": "7248bcc92b8589ded8faf75e6b7ab423009446d6",
            "title": "Augment deep BP-parameter learning with local XAI-structural learning"
        },
        {
            "paperId": null,
            "title": "Autoprompt: Eliciting knowledge from language models with automatically generated prompts"
        },
        {
            "paperId": "be0dd2e91bb104494feeb5da2761cf930564f650",
            "title": "Under review as a conference paper at ICLR 2016"
        },
        {
            "paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086",
            "title": "Learning Multiple Layers of Features from Tiny Images"
        },
        {
            "paperId": "e7297db245c3feb1897720b173a59fe7e36babb7",
            "title": "Optimal Brain Damage"
        },
        {
            "paperId": null,
            "title": "Good subnetworks provably 18"
        },
        {
            "paperId": null,
            "title": "Understanding pruning at initialization: An effective node-path balancing perspective (2022"
        },
        {
            "paperId": null,
            "title": "\u2461 M ( i ) should be dependent to W ( i )"
        },
        {
            "paperId": null,
            "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality"
        }
    ]
}