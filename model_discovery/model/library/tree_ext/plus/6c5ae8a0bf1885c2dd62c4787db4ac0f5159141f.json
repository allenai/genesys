{
    "paperId": "6c5ae8a0bf1885c2dd62c4787db4ac0f5159141f",
    "externalIds": {
        "ArXiv": "2407.10817",
        "DBLP": "journals/corr/abs-2407-10817",
        "DOI": "10.48550/arXiv.2407.10817",
        "CorpusId": 271213398
    },
    "title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation",
    "abstract": "As large language models (LLMs) advance, it becomes more challenging to reliably evaluate their output due to the high costs of human evaluation. To make progress towards better LLM autoraters, we introduce FLAMe, a family of Foundational Large Autorater Models. FLAMe is trained on our large and diverse collection of 100+ quality assessment tasks comprising 5M+ human judgments, curated and standardized using publicly released human evaluations from previous research. FLAMe significantly improves generalization to a wide variety of held-out tasks, outperforming LLMs trained on proprietary data like GPT-4 and Claude-3 on many tasks. We show that FLAMe can also serve as a powerful starting point for further downstream fine-tuning, using reward modeling evaluation as a case study (FLAMe-RM). Notably, on RewardBench, our FLAMe-RM-24B model (with an accuracy of 87.8%) is the top-performing generative model trained exclusively on permissively licensed data, outperforming both GPT-4-0125 (85.9%) and GPT-4o (84.7%). Additionally, we explore a more computationally efficient approach using a novel tail-patch fine-tuning strategy to optimize our FLAMe multitask mixture for reward modeling evaluation (FLAMe-Opt-RM), offering competitive RewardBench performance while requiring approximately 25x less training datapoints. Overall, our FLAMe variants outperform all popular proprietary LLM-as-a-Judge models we consider across 8 out of 12 autorater evaluation benchmarks, encompassing 53 quality assessment tasks, including RewardBench and LLM-AggreFact. Finally, our analysis reveals that FLAMe is significantly less biased than these LLM-as-a-Judge models on the CoBBLEr autorater bias benchmark, while effectively identifying high-quality responses for code generation.",
    "venue": "arXiv.org",
    "year": 2024,
    "referenceCount": 128,
    "citationCount": 1,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "FLAMe significantly improves generalization to a wide variety of held-out tasks, outperforming LLMs trained on proprietary data like GPT-4 and Claude-3 on many tasks, and is significantly less biased than these LLM-as-a-Judge models on the CoBBLEr autorater bias benchmark."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -4.174330711364746,
            0.9175256490707397,
            -0.5230501890182495,
            2.226595878601074,
            -0.8654497265815735,
            -1.5933657884597778,
            1.2285683155059814,
            1.4012821912765503,
            -1.5734784603118896,
            3.122299909591675,
            -2.8512439727783203,
            2.1667320728302,
            1.9728360176086426,
            -0.5920343399047852,
            -1.7536104917526245,
            1.4417098760604858,
            2.5338010787963867,
            2.350019931793213,
            4.761290550231934,
            2.890450954437256,
            0.3063947856426239,
            3.4339733123779297,
            -0.1466267704963684,
            -1.271745204925537,
            -0.7625386118888855,
            -0.21167904138565063,
            4.280153274536133,
            2.622080087661743,
            -1.6675975322723389,
            3.830974578857422,
            0.20915764570236206,
            -5.503087043762207,
            3.5874924659729004,
            -3.577317237854004,
            2.119027614593506,
            -1.5005872249603271,
            -2.537729263305664,
            8.173800468444824,
            -1.5574791431427002,
            -0.659012496471405,
            -1.2326509952545166,
            -1.3004889488220215,
            2.20176362991333,
            -1.9039037227630615,
            -1.8537917137145996,
            1.6538026332855225,
            3.821171522140503,
            -1.4838167428970337,
            -3.4593234062194824,
            3.5698931217193604,
            4.33837890625,
            1.2994327545166016,
            2.9470396041870117,
            3.1198413372039795,
            -0.7885938882827759,
            -1.4529123306274414,
            -1.4303016662597656,
            -1.7815152406692505,
            0.36785221099853516,
            -2.1195147037506104,
            5.367709159851074,
            5.00681209564209,
            -0.5737501382827759,
            0.3243235945701599,
            0.370815247297287,
            -3.4581403732299805,
            -3.6638429164886475,
            6.088985443115234,
            -1.1195038557052612,
            2.709660053253174,
            1.7826610803604126,
            -2.6148860454559326,
            0.6549845933914185,
            2.9106674194335938,
            -2.090611696243286,
            0.04800856113433838,
            -0.9566873908042908,
            -6.219577789306641,
            -0.9019709825515747,
            -1.8588851690292358,
            1.585463285446167,
            -0.48895660042762756,
            -0.49821728467941284,
            2.4257941246032715,
            4.590126991271973,
            -0.6618973016738892,
            -4.093716621398926,
            0.8082894086837769,
            2.5597786903381348,
            -6.406943321228027,
            0.10810565948486328,
            1.6881647109985352,
            -0.15835338830947876,
            3.8032543659210205,
            -2.303494453430176,
            -1.3134613037109375,
            -3.54839825630188,
            -2.218322992324829,
            -1.4177736043930054,
            -1.1654475927352905,
            3.6099178791046143,
            0.29113271832466125,
            1.8831746578216553,
            3.004924774169922,
            3.2671351432800293,
            -2.2886910438537598,
            0.8105970621109009,
            -0.042281508445739746,
            -2.0267953872680664,
            -2.0005087852478027,
            -2.688727855682373,
            2.0491251945495605,
            -2.3094828128814697,
            -2.4637093544006348,
            -0.6039283275604248,
            -2.702017307281494,
            -2.949251413345337,
            1.401221752166748,
            -1.7138856649398804,
            4.059667587280273,
            -2.7846007347106934,
            -3.8237969875335693,
            -1.9292227029800415,
            -0.4364599287509918,
            0.26234930753707886,
            -1.8122378587722778,
            0.34545332193374634,
            -0.4791927933692932,
            -1.001209020614624,
            -4.294613838195801,
            3.1091957092285156,
            1.1580145359039307,
            4.906160831451416,
            -3.111774206161499,
            1.883819818496704,
            5.78057336807251,
            -2.51159930229187,
            0.7131786346435547,
            -0.8172191977500916,
            -1.9861781597137451,
            0.9459202289581299,
            2.383875846862793,
            1.5714763402938843,
            -0.08094708621501923,
            -0.6229791641235352,
            4.336994171142578,
            1.077415943145752,
            2.682718276977539,
            -0.21529974043369293,
            5.278858184814453,
            2.089740514755249,
            -4.01399564743042,
            -1.8650990724563599,
            -0.4645354747772217,
            1.3919556140899658,
            3.5541725158691406,
            -6.606727600097656,
            3.511906147003174,
            -2.032360792160034,
            -1.1976211071014404,
            0.4844950735569,
            -0.769842803478241,
            -7.535769462585449,
            -3.8153278827667236,
            4.049624919891357,
            -2.6431140899658203,
            -1.3415277004241943,
            -0.19453376531600952,
            0.8863906264305115,
            -0.6735366582870483,
            -0.02520844340324402,
            4.810318946838379,
            4.143435478210449,
            2.0728981494903564,
            2.3124237060546875,
            2.4514458179473877,
            1.8865795135498047,
            -3.7127537727355957,
            -1.7785334587097168,
            0.15088510513305664,
            -1.0071624517440796,
            -0.9339038133621216,
            -3.635545015335083,
            1.7020378112792969,
            -5.614898681640625,
            -3.153110980987549,
            -1.441772699356079,
            -3.9607937335968018,
            -1.0618596076965332,
            -0.788004994392395,
            -5.547430992126465,
            1.6096999645233154,
            4.9661970138549805,
            4.7638139724731445,
            0.34404897689819336,
            2.1035845279693604,
            0.6361998915672302,
            2.9582767486572266,
            -2.7026314735412598,
            0.14280349016189575,
            2.312277317047119,
            2.189548969268799,
            -1.1686152219772339,
            -1.0080463886260986,
            6.545116424560547,
            4.185385704040527,
            -2.6196231842041016,
            3.1200597286224365,
            0.0957726538181305,
            2.1628165245056152,
            0.13243457674980164,
            0.42334431409835815,
            -2.978286027908325,
            -0.3374118506908417,
            -1.0187277793884277,
            0.3227052688598633,
            -3.978989839553833,
            -1.4240312576293945,
            4.373778343200684,
            1.4875173568725586,
            -2.171497344970703,
            -1.136326789855957,
            0.833048939704895,
            -5.6587629318237305,
            2.8510351181030273,
            -5.192262649536133,
            2.9777324199676514,
            -0.5284583568572998,
            0.3811810612678528,
            -2.568634033203125,
            -0.5261815786361694,
            -0.3328956961631775,
            0.8928744196891785,
            -2.5969693660736084,
            -4.638818740844727,
            1.076349139213562,
            -4.349785804748535,
            1.8283636569976807,
            -1.9120285511016846,
            -2.907365322113037,
            4.870086669921875,
            1.185119867324829,
            -0.4019174575805664,
            6.793674468994141,
            3.1290669441223145,
            1.1313002109527588,
            -1.9142429828643799,
            2.9152417182922363,
            -3.8136961460113525,
            -0.6077239513397217,
            -0.7562124729156494,
            -2.465217351913452,
            3.1632847785949707,
            0.4928542375564575,
            1.7477946281433105,
            2.479635715484619,
            -3.5236730575561523,
            0.4645290970802307,
            -2.827317714691162,
            0.8848654627799988,
            0.7343868017196655,
            6.254377841949463,
            2.751188278198242,
            2.8467655181884766,
            -2.1557888984680176,
            -1.3161665201187134,
            -4.018928050994873,
            -0.22936034202575684,
            -1.2131799459457397,
            5.270963191986084,
            5.468167304992676,
            2.9557764530181885,
            2.862562417984009,
            -3.7571656703948975,
            -2.916400909423828,
            -4.224539279937744,
            -1.0998879671096802,
            -1.9635729789733887,
            2.9024147987365723,
            3.0186572074890137,
            2.115063190460205,
            -1.5094746351242065,
            0.28091904520988464,
            -1.3464844226837158,
            -1.1340839862823486,
            -3.777618646621704,
            -2.0539751052856445,
            0.6684072017669678,
            -3.096043825149536,
            -0.15119826793670654,
            -0.5949746966362,
            4.319596290588379,
            -3.1321887969970703,
            -1.9389890432357788,
            -1.2443604469299316,
            0.49651461839675903,
            3.908527374267578,
            -1.4539000988006592,
            -1.7145758867263794,
            0.7235932350158691,
            -1.2123717069625854,
            1.435513973236084,
            1.7129648923873901,
            -2.5509445667266846,
            1.8721762895584106,
            1.9388442039489746,
            -1.604791283607483,
            -4.493368148803711,
            2.242645740509033,
            -5.840878486633301,
            0.4685158133506775,
            3.842747449874878,
            5.622483253479004,
            -3.173016309738159,
            0.6618852615356445,
            1.9226653575897217,
            0.04085839167237282,
            1.0509395599365234,
            -3.4764740467071533,
            1.7251312732696533,
            -0.739143967628479,
            -1.6396790742874146,
            -5.900352954864502,
            -5.393575191497803,
            -3.4014782905578613,
            -2.4690980911254883,
            3.416527271270752,
            2.8145012855529785,
            -0.9042470455169678,
            -1.1985294818878174,
            -0.7982480525970459,
            4.782851696014404,
            0.055107831954956055,
            3.767280101776123,
            0.24981029331684113,
            -4.741186618804932,
            -0.3604079484939575,
            -0.5139654278755188,
            1.3499500751495361,
            -0.5710211992263794,
            1.615338683128357,
            3.927237033843994,
            -1.105710506439209,
            1.2910395860671997,
            0.32581233978271484,
            1.2953410148620605,
            -0.9186751842498779,
            -2.099796772003174,
            -0.7650787830352783,
            -1.6368088722229004,
            3.8240573406219482,
            3.007004976272583,
            3.9418857097625732,
            0.43948009610176086,
            3.2776782512664795,
            2.4865198135375977,
            1.3259809017181396,
            0.8629052042961121,
            3.1171913146972656,
            2.778041362762451,
            0.08598814904689789,
            0.5897399187088013,
            -0.858336865901947,
            0.9729915261268616,
            1.1995854377746582,
            -1.9836570024490356,
            12.06591796875,
            -3.1334080696105957,
            1.5505262613296509,
            -6.312036514282227,
            -0.5899953842163086,
            -2.6509506702423096,
            -5.1688313484191895,
            1.829271912574768,
            -2.744605541229248,
            -1.1947641372680664,
            -4.535674571990967,
            -5.938162803649902,
            0.44209426641464233,
            0.6961848735809326,
            -2.806443691253662,
            2.9504776000976562,
            1.0400450229644775,
            1.1468915939331055,
            1.3987946510314941,
            2.2172598838806152,
            -2.640422821044922,
            1.5273497104644775,
            -0.37423741817474365,
            -0.0781603455543518,
            -3.715888738632202,
            0.5667769312858582,
            0.3009611964225769,
            5.088990211486816,
            -0.378019243478775,
            -2.5526585578918457,
            -1.4822044372558594,
            -3.3738975524902344,
            2.5781991481781006,
            0.17366059124469757,
            -3.6889865398406982,
            1.3197553157806396,
            7.059638977050781,
            2.011296272277832,
            -3.8914852142333984,
            -0.8165416121482849,
            2.455641031265259,
            -1.144191026687622,
            -0.4390943646430969,
            1.1951502561569214,
            0.44650799036026,
            -0.9895370006561279,
            0.785926342010498,
            -5.972840309143066,
            -0.38334232568740845,
            1.6518566608428955,
            4.162610054016113,
            0.12776359915733337,
            2.461611747741699,
            3.1502785682678223,
            -2.135753870010376,
            4.617689609527588,
            5.473211765289307,
            -0.26630935072898865,
            1.1947602033615112,
            -0.6803404688835144,
            2.0300111770629883,
            2.265989065170288,
            -3.418973207473755,
            4.356662273406982,
            2.1040282249450684,
            3.1674885749816895,
            -1.3690264225006104,
            -1.1990889310836792,
            2.938910961151123,
            2.4613232612609863,
            2.9941787719726562,
            3.570040702819824,
            2.353088140487671,
            -3.1576826572418213,
            1.0235759019851685,
            1.6933493614196777,
            -3.236497402191162,
            3.142333507537842,
            1.3036329746246338,
            1.5400437116622925,
            2.62982177734375,
            -0.8858058452606201,
            -2.8930232524871826,
            0.23203116655349731,
            4.963859558105469,
            -5.286340713500977,
            -2.7261099815368652,
            -1.6881767511367798,
            -0.5220547914505005,
            1.4231775999069214,
            -2.38828182220459,
            -0.502722442150116,
            0.5522230863571167,
            1.0206873416900635,
            -3.637665033340454,
            5.1512579917907715,
            -2.0545742511749268,
            0.12711122632026672,
            -1.1938374042510986,
            0.8974477052688599,
            -3.279942035675049,
            -5.501495838165283,
            -2.5708532333374023,
            -0.04030787944793701,
            0.7116245031356812,
            -1.1576106548309326,
            -2.0350394248962402,
            3.8945059776306152,
            1.0144667625427246,
            -0.09290426969528198,
            2.7263247966766357,
            -1.456695556640625,
            2.304663896560669,
            -3.170289993286133,
            -2.1024980545043945,
            -1.0264204740524292,
            2.4277849197387695,
            -2.7398529052734375,
            -2.205904006958008,
            1.7848691940307617,
            1.5964637994766235,
            4.392693042755127,
            3.515763282775879,
            1.2531673908233643,
            1.0661221742630005,
            5.198977470397949,
            4.856203079223633,
            -1.3349641561508179,
            -0.613388180732727,
            -3.262091636657715,
            -6.670660018920898,
            1.5860024690628052,
            -2.662923574447632,
            -1.9573516845703125,
            2.023162364959717,
            -2.4752888679504395,
            0.1420905888080597,
            -1.5440735816955566,
            -4.073674201965332,
            6.554141998291016,
            3.127354145050049,
            2.3040294647216797,
            -1.6801884174346924,
            0.08554297685623169,
            -1.7331573963165283,
            0.6383047103881836,
            -2.369264602661133,
            3.179147720336914,
            -1.0996544361114502,
            0.599328339099884,
            0.7303574085235596,
            -1.6596763134002686,
            1.253179669380188,
            -0.2804577946662903,
            -1.363906979560852,
            0.29833677411079407,
            -2.850515842437744,
            0.5200163722038269,
            0.09156735241413116,
            0.5598170757293701,
            -2.1120948791503906,
            0.5043129324913025,
            5.051673889160156,
            5.866055488586426,
            5.442226886749268,
            4.955405235290527,
            5.26611328125,
            -2.5904407501220703,
            -0.375266969203949,
            -0.9094021916389465,
            1.48459792137146,
            5.36388635635376,
            -2.432835340499878,
            1.32799232006073,
            -0.9143211841583252,
            0.15509504079818726,
            -0.15914951264858246,
            2.3301336765289307,
            0.3093014359474182,
            2.9195597171783447,
            -2.7353429794311523,
            -4.130220413208008,
            -0.9285187721252441,
            0.32954084873199463,
            1.8320956230163574,
            -2.4300715923309326,
            3.175443410873413,
            1.836595892906189,
            -4.259725093841553,
            -2.081542491912842,
            -3.120044708251953,
            0.048967599868774414,
            -1.6385219097137451,
            3.506901264190674,
            1.987374186515808,
            -2.0857367515563965,
            0.8353585004806519,
            2.1589713096618652,
            -1.4565088748931885,
            -2.4704253673553467,
            -0.42520278692245483,
            2.147858142852783,
            2.1764883995056152,
            -2.8369526863098145,
            -0.6567795276641846,
            -4.411628723144531,
            -1.5075106620788574,
            -0.4218476712703705,
            1.4162639379501343,
            0.7766343355178833,
            3.9974358081817627,
            -0.23201453685760498,
            1.2082690000534058,
            -2.561495542526245,
            -1.75043785572052,
            -0.15178552269935608,
            0.39195364713668823,
            -4.04390811920166,
            0.6854099035263062,
            -1.2533777952194214,
            -2.2327678203582764,
            3.5412516593933105,
            -1.9379297494888306,
            1.2007701396942139,
            1.2514503002166748,
            -1.1046416759490967,
            -0.3824053406715393,
            -2.700991630554199,
            0.2790239453315735,
            -2.3144443035125732,
            2.1572022438049316,
            0.17738783359527588,
            0.14411866664886475,
            3.882303237915039,
            -1.8684804439544678,
            3.6050496101379395,
            2.607273578643799,
            1.1879985332489014,
            -4.211408615112305,
            -0.19463056325912476,
            2.8146908283233643,
            -0.7041037082672119,
            -1.0893502235412598,
            -0.8949035406112671,
            0.5290744304656982,
            1.0273189544677734,
            16.523849487304688,
            0.5819903016090393,
            -0.9874379634857178,
            -0.0746917724609375,
            1.0424375534057617,
            -2.0473642349243164,
            -2.2848570346832275,
            2.6750996112823486,
            -3.0572550296783447,
            -1.4116711616516113,
            -5.02472448348999,
            0.03645360469818115,
            -4.44428825378418,
            4.2558488845825195,
            -0.35906121134757996,
            0.8612484931945801,
            -2.753571033477783,
            2.225457191467285,
            -3.1775636672973633,
            -0.7313058376312256,
            1.4306764602661133,
            2.185412883758545,
            -3.7975552082061768,
            -4.024772644042969,
            0.7363061308860779,
            3.4037084579467773,
            2.1465888023376465,
            3.7626428604125977,
            -4.4052839279174805,
            0.3935222923755646,
            0.8388769626617432,
            1.1152974367141724,
            0.41899824142456055,
            0.23220276832580566,
            0.3795914351940155,
            0.3556390106678009,
            2.4181289672851562,
            -2.868408441543579,
            1.0192252397537231,
            1.5055291652679443,
            -0.27327442169189453,
            1.3755027055740356,
            -4.438778877258301,
            2.256809711456299,
            -2.4203996658325195,
            -0.5809934735298157,
            3.9173378944396973,
            -1.7087048292160034,
            -1.7405411005020142,
            4.615850448608398,
            -1.8662059307098389,
            1.9499961137771606,
            2.528754472732544,
            0.39814671874046326,
            2.6596570014953613,
            1.3020236492156982,
            -1.3505511283874512,
            -4.914532661437988,
            0.9110279083251953,
            -1.260247826576233,
            1.5528327226638794,
            2.5289080142974854,
            -1.6719136238098145,
            -3.8875937461853027,
            -2.3326263427734375,
            -2.3346855640411377,
            -2.360772132873535,
            1.1782969236373901,
            4.300073146820068,
            2.042325496673584,
            3.5768909454345703,
            1.8510112762451172,
            -2.687553644180298,
            -0.7098599672317505,
            2.2831263542175293,
            -4.142763137817383,
            0.8189212083816528,
            -4.475828647613525,
            1.4181913137435913,
            3.712070941925049,
            0.0463215708732605,
            0.8020780086517334,
            0.6229348182678223,
            -1.6123839616775513,
            3.9871013164520264,
            -5.699509620666504,
            1.4231889247894287,
            0.1503087282180786,
            0.25975602865219116,
            1.8222379684448242,
            -1.6500217914581299,
            0.2315334975719452,
            3.218486785888672,
            4.8361711502075195,
            0.09551846981048584,
            -4.421156883239746,
            -4.340961456298828,
            -2.0815088748931885,
            -3.811986207962036,
            -2.7346763610839844,
            5.379227638244629,
            3.5527021884918213,
            0.6432908773422241,
            -1.4001260995864868,
            2.1765048503875732,
            -0.4656732678413391,
            -2.7446975708007812,
            -6.383414268493652,
            -1.4742902517318726,
            -0.31466352939605713,
            3.3292996883392334,
            -4.065275192260742,
            -1.3418394327163696,
            2.2796661853790283,
            1.0511059761047363,
            -0.1570470929145813,
            2.0423319339752197,
            0.9472423791885376,
            -0.7576286792755127,
            0.9538199305534363,
            1.0710034370422363,
            -1.6469275951385498,
            -3.0746331214904785,
            -1.727378487586975,
            -2.95530366897583,
            0.9429969787597656,
            -0.7338159084320068,
            -1.61776864528656,
            -0.786518394947052,
            -2.803068161010742,
            2.1520607471466064,
            -2.3551180362701416,
            -0.7976512312889099,
            -0.506100058555603,
            -0.8041706681251526,
            -1.6539816856384277,
            4.013848304748535,
            0.26469680666923523,
            1.2257226705551147,
            2.0063118934631348,
            1.0090422630310059,
            -3.1517248153686523,
            -3.6329879760742188,
            7.6157121658325195,
            -1.3940889835357666,
            -3.9271368980407715,
            -2.8036623001098633,
            -0.8948041200637817,
            0.47917652130126953,
            2.7261605262756348,
            2.1065518856048584,
            -1.179117202758789,
            1.0734138488769531,
            2.011096477508545,
            -2.6254446506500244,
            -1.6371983289718628
        ]
    },
    "authors": [
        {
            "authorId": "2274937078",
            "name": "Tu Vu"
        },
        {
            "authorId": "2311406638",
            "name": "Kalpesh Krishna"
        },
        {
            "authorId": "2186553606",
            "name": "Salaheddin Alzubi"
        },
        {
            "authorId": "7887562",
            "name": "Chris Tar"
        },
        {
            "authorId": "1779225",
            "name": "Manaal Faruqui"
        },
        {
            "authorId": "2254198228",
            "name": "Yun-Hsuan Sung"
        }
    ],
    "references": [
        {
            "paperId": "344fa52471306a25133c9536992be15eecdd1c60",
            "title": "One Thousand and One Pairs: A \"novel\" challenge for long-context language models"
        },
        {
            "paperId": "f590d8926dd12345a3bd22253461850f5ca4b3ed",
            "title": "HelpSteer2: Open-source dataset for training top-performing reward models"
        },
        {
            "paperId": "5d12dfd7278cb8da26f9fd1956cad3c15cea9863",
            "title": "WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild"
        },
        {
            "paperId": "ecdd53eaab7455daea27609b07a418a21aa7ad35",
            "title": "Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models"
        },
        {
            "paperId": "d0489fd7c5ff833e08969341ae6e5fa1d0e6dd2a",
            "title": "MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents"
        },
        {
            "paperId": "5c7f465d162aade4a4c0eefb02fd7aadeebdaf58",
            "title": "LLM Evaluators Recognize and Favor Their Own Generations"
        },
        {
            "paperId": "eb375712bd37250c350ecd3f559e1879e87eb3e5",
            "title": "Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators"
        },
        {
            "paperId": "3f9784cbe6e9be03b07dd4a5cadb0595d16b3974",
            "title": "FABLES: Evaluating faithfulness and content selection in book-length summarization"
        },
        {
            "paperId": "67c0d46f2bf655471cc29a5c1cd2f4ae5f10ab80",
            "title": "Long-form factuality in large language models"
        },
        {
            "paperId": "8e9088c102b3714ae4e5cac7ced93a59804bfc7c",
            "title": "RewardBench: Evaluating Reward Models for Language Modeling"
        },
        {
            "paperId": "0fce243964da0ec358152f226b21432e5a658917",
            "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context"
        },
        {
            "paperId": "53f4fb0e9972989194368faf288ff8e3cba5bd60",
            "title": "Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference"
        },
        {
            "paperId": "411114f989a3d1083d90afd265103132fee94ebe",
            "title": "Mixtral of Experts"
        },
        {
            "paperId": "cfce709a65f90312d2bdc1a6cf0380c19becf694",
            "title": "RAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models"
        },
        {
            "paperId": "37680e5cb6030e01f1a44a5abe2257972196ae26",
            "title": "Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2"
        },
        {
            "paperId": "711ac30df7909fc9de881933580c642e7c3e2b08",
            "title": "HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM"
        },
        {
            "paperId": "71f7bbfb36a0026825e17f3303e73f93876fc3e7",
            "title": "LLMs as Narcissistic Evaluators: When Ego Inflates Evaluation Scores"
        },
        {
            "paperId": "f495d2741f804cb37a6afc3c039f1d3964b964a8",
            "title": "Benchmarking Generation and Evaluation Capabilities of Large Language Models for Instruction Controllable Summarization"
        },
        {
            "paperId": "880ef5392cd4f3bb91469ea0e3f3f8b11124a6aa",
            "title": "Coffee: Boost Your Code LLMs by Fixing Bugs with Feedback"
        },
        {
            "paperId": "9ebf47129c15f61f4b77bbfe305c522480c20347",
            "title": "Prometheus: Inducing Fine-grained Evaluation Capability in Language Models"
        },
        {
            "paperId": "0f0b8f6b9d6f9356f9504c0291ca59db9b20bf53",
            "title": "Towards Better Evaluation of Instruction-Following: A Case-Study in Summarization"
        },
        {
            "paperId": "be177300487b6d0f25e6cade9a31900454b13281",
            "title": "FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation"
        },
        {
            "paperId": "d238a9770d24d0725656ef6cf4789afebf2126e7",
            "title": "TIGERScore: Towards Building Explainable Metric for All Text Generation Tasks"
        },
        {
            "paperId": "d55ed10e6a77e8f0a2359eb92221915f56481843",
            "title": "Benchmarking Cognitive Biases in Large Language Models as Evaluators"
        },
        {
            "paperId": "40e0b9361d88b1879891eb6d16de110b30bf6c62",
            "title": "OctoPack: Instruction Tuning Code Large Language Models"
        },
        {
            "paperId": "fd80f7f3673fc6ca02f192d5d73426f11a4be659",
            "title": "The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation"
        },
        {
            "paperId": "92930ed3560ea6c86d53cf52158bc793b089054d",
            "title": "BeaverTails: Towards Improved Safety Alignment of LLM via a Human-Preference Dataset"
        },
        {
            "paperId": "130d18d1d455336e1a5b06c85784894bb67d87ec",
            "title": "PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations"
        },
        {
            "paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787",
            "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"
        },
        {
            "paperId": "378a545c3a1cf6c4aada8f9ee8820c0d8008220a",
            "title": "Benchmarking Foundation Models with Language-Model-as-an-Examiner"
        },
        {
            "paperId": "e2e52461194bc81351da7caa978ac42e9e9549cc",
            "title": "Fine-Grained Human Feedback Gives Better Rewards for Language Model Training"
        },
        {
            "paperId": "be8db99310602d66bba64bcf41a572c45816fbfc",
            "title": "Let's Verify Step by Step"
        },
        {
            "paperId": "0d1c76d45afa012ded7ab741194baf142117c495",
            "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"
        },
        {
            "paperId": "0899c8fecd47b2843db8dc28e53ee06c3115fb3d",
            "title": "A Critical Evaluation of Evaluations for Long-form Question Answering"
        },
        {
            "paperId": "5d44f16a36ba7ae6b3d9d7c98bbc1b877e598f35",
            "title": "The False Promise of Imitating Proprietary LLMs"
        },
        {
            "paperId": "bd5deadc58ee45b5e004378ba1d54a96bc947b4a",
            "title": "FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation"
        },
        {
            "paperId": "cb6cc7d28d06a0d7c0d3f0d7ee551bbc86dbc3aa",
            "title": "AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback"
        },
        {
            "paperId": "7ad0e4803dcf7232e33ea20842062aba99a5ddfb",
            "title": "SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization Evaluation"
        },
        {
            "paperId": "546d0624adfc6e18fb87d8cc77e7705bb9ea7445",
            "title": "LIMA: Less Is More for Alignment"
        },
        {
            "paperId": "58af2d4fcca54c14334d1efd975554b4eb78cd4d",
            "title": "SLiC-HF: Sequence Likelihood Calibration with Human Feedback"
        },
        {
            "paperId": "b6d6c33298b852cf63edac233deca70530d69a2a",
            "title": "PaLM 2 Technical Report"
        },
        {
            "paperId": "03055978e278960de9fbb5c648b1779ef9f26cd1",
            "title": "Can Large Language Models Be an Alternative to Human Evaluations?"
        },
        {
            "paperId": "1a3763f38e84bf5a43c34df10a381a4449146acc",
            "title": "Large Language Models Effectively Leverage Document-level Context for Literary Translation, but Critical Errors Persist"
        },
        {
            "paperId": "381ab7a640f5b46b62f7e08d1af4a8e0d3eadd55",
            "title": "G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment"
        },
        {
            "paperId": "1c13af186d1e177b85ef1ec3fc7b8d33ec314cfd",
            "title": "Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense"
        },
        {
            "paperId": "574beee702be3856d60aa482ec725168fe64fc99",
            "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4"
        },
        {
            "paperId": "7c1707db9aafd209aa93db3251e7ebd593d55876",
            "title": "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models"
        },
        {
            "paperId": "163b4d6a79a5b19af88b8585456363340d9efd04",
            "title": "GPT-4 Technical Report"
        },
        {
            "paperId": "8221f1597000543432b7021ca79dbc51a7a63f9c",
            "title": "Is ChatGPT a Good NLG Evaluator? A Preliminary Study"
        },
        {
            "paperId": "c5120b546f1bd99df5bd2e2bf44db5c7c46d1545",
            "title": "Pretraining Language Models with Human Preferences"
        },
        {
            "paperId": "40c318400809abf5e50aba5a5a80c8012a7715d5",
            "title": "GPTScore: Evaluate as You Desire"
        },
        {
            "paperId": "f2b0017ddd77fa38760a18145e63553105a1a236",
            "title": "The Flan Collection: Designing Data and Methods for Effective Instruction Tuning"
        },
        {
            "paperId": "f1f6c61ed0b80a785e4e5d0d97a454dbe6126c63",
            "title": "LongEval: Guidelines for Human Evaluation of Faithfulness in Long-form Summarization"
        },
        {
            "paperId": "598d6842a98075be91bfec7a2b569acf9d755d88",
            "title": "LENS: A Learnable Evaluation Metric for Text Simplification"
        },
        {
            "paperId": "3936fd3c6187f606c6e4e2e20b196dbc41cc4654",
            "title": "Constitutional AI: Harmlessness from AI Feedback"
        },
        {
            "paperId": "a63f3785611125257a7feefbb9533ca41af59c13",
            "title": "CREPE: Open-Domain Question Answering with False Presuppositions"
        },
        {
            "paperId": "e40478a91b415eb94a59bf9494389c106a1e471f",
            "title": "An Empirical Study On Contrastive Search And Contrastive Decoding For Open-ended Text Generation"
        },
        {
            "paperId": "77a94f6c91ee1590dd2c6fd80b4a6d8bffdb91ac",
            "title": "Help me write a Poem - Instruction Tuning as a Vehicle for Collaborative Poetry Writing"
        },
        {
            "paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1",
            "title": "Scaling Instruction-Finetuned Language Models"
        },
        {
            "paperId": "dc62b87f2eae1683f5dc667d5035ffbd36bbe011",
            "title": "Improving Large-scale Paraphrase Acquisition and Generation"
        },
        {
            "paperId": "83851f1a32d41975582ca62355858ab5e34738f7",
            "title": "News Summarization and Evaluation in the Era of GPT-3"
        },
        {
            "paperId": "17bcb1edbe068e8fe6a97da552c70a77a15bbce7",
            "title": "Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned"
        },
        {
            "paperId": "876eb375cb7b365475040046df669c039ad54202",
            "title": "CodeT: Code Generation with Generated Tests"
        },
        {
            "paperId": "23447f473cd240494b0a20ea008038aaef7e3391",
            "title": "RankGen: Improving Text Generation with Large Ranking Models"
        },
        {
            "paperId": "1ea7ad7ae45d3d4634b6ffad2a8b0d41ad2fcb25",
            "title": "FaithDial: A Faithful Benchmark for Information-Seeking Dialogue"
        },
        {
            "paperId": "5288b9f3a9f575543f44c39e1d3b78b3ca4c99da",
            "title": "InCoder: A Generative Model for Code Infilling and Synthesis"
        },
        {
            "paperId": "0286b2736a114198b25fb5553c671c33aed5d477",
            "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback"
        },
        {
            "paperId": "7a74fa8620b8dd63a45a5eaece1d0a94ad37646d",
            "title": "Using Interactive Feedback to Improve the Accuracy and Explainability of Question Answering Systems Post-Deployment"
        },
        {
            "paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb",
            "title": "PaLM: Scaling Language Modeling with Pathways"
        },
        {
            "paperId": "1ed66e048bb025e75aa5ea660545285212e5341f",
            "title": "Scaling Up Models and Data with t5x and seqio"
        },
        {
            "paperId": "38115e80d805fb0fb8f090dc88ced4b24be07878",
            "title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis"
        },
        {
            "paperId": "20bbb181d1f515d66827e3e950c7a75c5314ea16",
            "title": "How Do We Answer Complex Questions: Discourse Structure of Long-form Answers"
        },
        {
            "paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
            "title": "Training language models to follow instructions with human feedback"
        },
        {
            "paperId": "5cbe278b65a81602a864184bbca37de91448a5f5",
            "title": "Competition-level code generation with AlphaCode"
        },
        {
            "paperId": "2f3efe44083af91cef562c1a3451eee2f8601d22",
            "title": "WebGPT: Browser-assisted question-answering with human feedback"
        },
        {
            "paperId": "3dc7dc1bea9a4f70c02b6759a0bda7aca0005a9e",
            "title": "A General Language Assistant as a Laboratory for Alignment"
        },
        {
            "paperId": "39d05ffbc06fdca54ea6a90cd6d7fca202809aaa",
            "title": "Understanding Dataset Difficulty with V-Usable Information"
        },
        {
            "paperId": "21478400b07552831a012a1c01ab831e8c2e3fda",
            "title": "DialFact: A Benchmark for Fact-Checking in Dialogue"
        },
        {
            "paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca",
            "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"
        },
        {
            "paperId": "d706645fbbc6edfad5fb642b1dfc3019fcabbd99",
            "title": "The Perils of Using Mechanical Turk to Evaluate Open-Ended Text Generation"
        },
        {
            "paperId": "77d956cdab4508d569ae5741549b78e715fd0749",
            "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods"
        },
        {
            "paperId": "cddf40e579a596d0110b260313adf43470617c4c",
            "title": "Datasets: A Community Library for Natural Language Processing"
        },
        {
            "paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd",
            "title": "Finetuned Language Models Are Zero-Shot Learners"
        },
        {
            "paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269",
            "title": "Evaluating Large Language Models Trained on Code"
        },
        {
            "paperId": "ab847321118de056ff00325d58903b71bdcc76e1",
            "title": "Is GPT-3 Text Indistinguishable from Human Text? Scarecrow: A Framework for Scrutinizing Machine Text"
        },
        {
            "paperId": "a6a7724763d8adba466519489b0b9d209e7f2d15",
            "title": "BARTScore: Evaluating Generated Text as Text Generation"
        },
        {
            "paperId": "3feeb45cb468550bfa12e2ac8a1a4112d2dbfc1a",
            "title": "Evaluating Attribution in Dialogue Systems: The BEGIN Benchmark"
        },
        {
            "paperId": "476d79d1f5650c5361104ed468e75bfc4732622d",
            "title": "Experts, Errors, and Context: A Large-Scale Study of Human Evaluation for Machine Translation"
        },
        {
            "paperId": "667bdd2a8dc997d40c106ff6761babebe4050762",
            "title": "Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics"
        },
        {
            "paperId": "cbdb45fc16b0885905b91d84281c310e6cb49e9c",
            "title": "Cross-Task Generalization via Natural Language Crowdsourcing Instructions"
        },
        {
            "paperId": "f434ca09c7e4acd8dbe2ba54c1a99a930bbfeeba",
            "title": "Annotating and Modeling Fine-grained Factuality in Summarization"
        },
        {
            "paperId": "eebc1811c55c2e5e8b3b78d0b0382ad50f22e32a",
            "title": "Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence"
        },
        {
            "paperId": "3122a2d7799ba585b993e432b3deb47659b3f3c1",
            "title": "Hurdles to Progress in Long-form Question Answering"
        },
        {
            "paperId": "8484fdb56e4690927dc0191ede11c2d24bc5e2ef",
            "title": "MAUVE: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers"
        },
        {
            "paperId": "04052cfab34af874498726209225216bb3b89d3d",
            "title": "GENIE: Toward Reproducible and Standardized Human Evaluation for Text Generation"
        },
        {
            "paperId": "205aab2f5b9b06830e721f398550c72b79790924",
            "title": "MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics"
        },
        {
            "paperId": "53c283cc281deb515c4b4b539dbcd636c5842e62",
            "title": "Towards Question-Answering as an Automatic Metric for Evaluating the Content Quality of a Summary"
        },
        {
            "paperId": "9e67b9758520e49016ab66bafb974d2e1ed762d1",
            "title": "COMET: A Neural Framework for MT Evaluation"
        },
        {
            "paperId": "053b1d7b97eb2c91fc3921d589c160b0923c70b1",
            "title": "Learning to summarize from human feedback"
        },
        {
            "paperId": "781b9a445d1878ee4744546f2b8c7466e3cbbd1a",
            "title": "SummEval: Re-evaluating Summarization Evaluation"
        },
        {
            "paperId": "11b6d1fee0f47a8f9f892ab0d86f370c449097aa",
            "title": "FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization"
        },
        {
            "paperId": "dbeeca8466e0c177ec67c60d529899232415ca87",
            "title": "On Faithfulness and Factuality in Abstractive Summarization"
        },
        {
            "paperId": "3fc0cda3bfad305e9da00f3f564f5205e3833c75",
            "title": "Crisscrossed Captions: Extended Intramodal and Intermodal Semantic Similarity Judgments for MS-COCO"
        },
        {
            "paperId": "4ae52766028e69186052ea8f33a137fbbbdb986a",
            "title": "BLEURT: Learning Robust Metrics for Text Generation"
        },
        {
            "paperId": "d36e39aedd802aea4be1ea303c70dc56e97dbc3c",
            "title": "Asking and Answering Questions to Evaluate the Factual Consistency of Summaries"
        },
        {
            "paperId": "01508f386eb2ca5181fde7bb6da4920e250d7498",
            "title": "Automatic Machine Translation Evaluation in Many Languages via Zero-Shot Paraphrasing"
        },
        {
            "paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
        },
        {
            "paperId": "635cb6fb865e86c108c5d1d895aeac0e759eb199",
            "title": "MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance"
        },
        {
            "paperId": "867db5097ad6aaef098c60b0845785b440eca49a",
            "title": "GLTR: Statistical Detection and Visualization of Generated Text"
        },
        {
            "paperId": "295065d942abca0711300b2b4c39829551060578",
            "title": "BERTScore: Evaluating Text Generation with BERT"
        },
        {
            "paperId": "fc09d6486be1c9bbfbef4165ce3c1ab664e5d084",
            "title": "PAWS: Paraphrase Adversaries from Word Scrambling"
        },
        {
            "paperId": "c242438dac5aa4d9b13766c14240bb8426690d58",
            "title": "e-SNLI: Natural Language Inference with Natural Language Explanations"
        },
        {
            "paperId": "cb0f3ee1e98faf92429d601cdcd76c69c1e484eb",
            "title": "Neural Network Acceptability Judgments"
        },
        {
            "paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e",
            "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"
        },
        {
            "paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008",
            "title": "ROUGE: A Package for Automatic Evaluation of Summaries"
        },
        {
            "paperId": "d7da009f457917aa381619facfa5ffae9329a6e9",
            "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"
        },
        {
            "paperId": "460609e217fd59eaa34f5e11a820661f8ec8d7b6",
            "title": "INSTRUCTSCORE: Towards Explainable Text Generation Evaluation with Automatic Feedback"
        },
        {
            "paperId": null,
            "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality"
        },
        {
            "paperId": null,
            "title": "\ud835\udc5e 2 : Evaluating factual consistency in knowledge-grounded dialogues via question generation and question answering"
        },
        {
            "paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": null,
            "title": "SemEval-2017"
        },
        {
            "paperId": null,
            "title": "A method for stochastic optimization"
        },
        {
            "paperId": null,
            "title": "Gemini: a family of highly capable multimodal models"
        },
        {
            "paperId": null,
            "title": "Data Extraction: We identify and extract specific data fields containing quality assessments conducted by human annotators"
        },
        {
            "paperId": null,
            "title": "Alpacaeval: An automatic evaluator of instruction-following models"
        },
        {
            "paperId": null,
            "title": "Introducing the next generation of claude, 2024"
        },
        {
            "paperId": null,
            "title": "Foundational"
        },
        {
            "paperId": null,
            "title": "Introducing meta llama 3: The most capable openly available llm to date"
        }
    ]
}