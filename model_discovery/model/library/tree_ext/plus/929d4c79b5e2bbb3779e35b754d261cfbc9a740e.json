{
    "paperId": "929d4c79b5e2bbb3779e35b754d261cfbc9a740e",
    "externalIds": {
        "ArXiv": "2409.00088",
        "CorpusId": 272368391
    },
    "title": "On-Device Language Models: A Comprehensive Review",
    "abstract": "The advent of large language models (LLMs) revolutionized natural language processing applications, and running LLMs on edge devices has become increasingly attractive for reasons including reduced latency, data localization, and personalized user experiences. This comprehensive review examines the challenges of deploying computationally expensive LLMs on resource-constrained devices and explores innovative solutions across multiple domains. The paper investigates the development of on-device language models, their efficient architectures, including parameter sharing and modular designs, as well as state-of-the-art compression techniques like quantization, pruning, and knowledge distillation. Hardware acceleration strategies and collaborative edge-cloud deployment approaches are analyzed, highlighting the intricate balance between performance and resource utilization. Case studies of on-device language models from major mobile manufacturers demonstrate real-world applications and potential benefits. The review also addresses critical aspects such as adaptive learning, multi-modal capabilities, and personalization. By identifying key research directions and open challenges, this paper provides a roadmap for future advancements in on-device language models, emphasizing the need for interdisciplinary efforts to realize the full potential of ubiquitous, intelligent computing while ensuring responsible and ethical deployment. For a comprehensive review of research work and educational resources on on-device large language models (LLMs), please visit https://github.com/NexaAI/Awesome-LLMs-on-device. To download and run on-device LLMs, visit https://www.nexaai.com/models.",
    "venue": "",
    "year": 2024,
    "referenceCount": 178,
    "citationCount": 0,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "The development of on-device language models, their efficient architectures, including parameter sharing and modular designs, as well as state-of-the-art compression techniques like quantization, pruning, and knowledge distillation are investigated."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -3.4135775566101074,
            -1.3040059804916382,
            -6.148451805114746,
            6.425320148468018,
            -1.6886005401611328,
            0.6493186354637146,
            3.092355489730835,
            1.8211791515350342,
            -2.7113027572631836,
            0.5870972275733948,
            -3.681384563446045,
            3.2024664878845215,
            -0.5647720098495483,
            -2.2331042289733887,
            -3.980381965637207,
            -1.0470367670059204,
            0.675454318523407,
            0.15645843744277954,
            4.833801746368408,
            2.9798660278320312,
            -1.5753498077392578,
            0.40927308797836304,
            -1.393141746520996,
            0.8023784160614014,
            -1.1158251762390137,
            1.4615085124969482,
            0.014571160078048706,
            1.6483709812164307,
            -0.9836654663085938,
            0.07522082328796387,
            0.25860705971717834,
            -3.8439176082611084,
            6.1169633865356445,
            -3.555741786956787,
            4.735506534576416,
            -2.114497423171997,
            -4.923167705535889,
            6.754037857055664,
            -1.0668020248413086,
            -1.45222806930542,
            2.2261805534362793,
            -2.137760877609253,
            0.61506187915802,
            1.5301473140716553,
            2.4137377738952637,
            0.7952592968940735,
            0.3190917372703552,
            -0.9337896704673767,
            2.783473491668701,
            0.7748298645019531,
            0.7878245115280151,
            1.4125736951828003,
            1.2347280979156494,
            -0.19573938846588135,
            -0.05638095736503601,
            2.5354459285736084,
            2.226762056350708,
            -0.43892383575439453,
            1.4561554193496704,
            -1.5877752304077148,
            4.669655799865723,
            6.826923370361328,
            0.2420814037322998,
            4.137718200683594,
            3.31854510307312,
            -4.578245162963867,
            -2.1775963306427,
            1.6776981353759766,
            3.143070697784424,
            2.9697251319885254,
            -2.83164644241333,
            -2.5628464221954346,
            0.9752504825592041,
            2.819460153579712,
            -5.046229362487793,
            -0.982450544834137,
            0.6999871730804443,
            -2.672028064727783,
            0.9365662336349487,
            -4.067482948303223,
            1.9463229179382324,
            4.772464752197266,
            1.8875467777252197,
            2.663761854171753,
            3.7302069664001465,
            -2.468104839324951,
            -4.329995155334473,
            2.9755091667175293,
            0.6034119129180908,
            -3.4209392070770264,
            0.02760636806488037,
            0.36406904458999634,
            -4.195615768432617,
            0.26961660385131836,
            -0.16707611083984375,
            -0.24020451307296753,
            3.1272904872894287,
            -3.480595111846924,
            -1.3246217966079712,
            -0.15288367867469788,
            1.1878907680511475,
            0.11912140250205994,
            -1.1516516208648682,
            1.0275768041610718,
            2.789181709289551,
            -3.869614362716675,
            -1.317447543144226,
            3.6845226287841797,
            -1.8238197565078735,
            2.7309556007385254,
            -2.027277708053589,
            5.829096794128418,
            -0.0008532404899597168,
            -2.097494602203369,
            -1.7773206233978271,
            -2.885453939437866,
            -1.81429123878479,
            -0.8631777763366699,
            -2.0114192962646484,
            6.166769981384277,
            -0.0339447557926178,
            -0.18656492233276367,
            -3.170158863067627,
            -0.46211254596710205,
            2.877556085586548,
            -0.07864174246788025,
            0.5249584317207336,
            -0.8189628720283508,
            -1.5288323163986206,
            -2.501044750213623,
            -1.193206548690796,
            0.31079646944999695,
            0.015010416507720947,
            -3.078678846359253,
            -0.1416018009185791,
            -0.9798825979232788,
            -5.161231994628906,
            1.3791519403457642,
            -3.615046977996826,
            1.9154239892959595,
            0.30717816948890686,
            4.496735095977783,
            -0.31650468707084656,
            1.4597350358963013,
            0.7340697050094604,
            0.5184921026229858,
            2.9204859733581543,
            0.7324090003967285,
            -0.1405211091041565,
            6.465785503387451,
            6.03814172744751,
            -0.6114830374717712,
            -3.455965757369995,
            1.583919644355774,
            -1.488184928894043,
            3.001627206802368,
            -1.5139349699020386,
            0.998968243598938,
            -1.9736164808273315,
            3.1753203868865967,
            0.3911241292953491,
            0.21812081336975098,
            -8.841035842895508,
            -3.191706895828247,
            2.3175442218780518,
            -2.5646986961364746,
            -3.23184871673584,
            2.154841899871826,
            -0.6751697659492493,
            4.7306928634643555,
            -2.65755033493042,
            3.888856887817383,
            3.7541990280151367,
            3.3074212074279785,
            3.989821195602417,
            1.894207239151001,
            0.48032093048095703,
            -0.8771926760673523,
            -4.092329502105713,
            -1.437398076057434,
            -2.351560592651367,
            3.2601709365844727,
            -4.9659199714660645,
            3.575543165206909,
            -3.418911933898926,
            -2.99241304397583,
            0.3794363737106323,
            -1.0992367267608643,
            -2.079888343811035,
            2.0955421924591064,
            -1.4211833477020264,
            0.03965449333190918,
            4.198681831359863,
            2.9034082889556885,
            3.037365198135376,
            0.10991743206977844,
            4.30905294418335,
            3.6940650939941406,
            -2.791043519973755,
            -1.7120428085327148,
            2.638762950897217,
            1.458773136138916,
            1.0248303413391113,
            -3.649043083190918,
            4.306852340698242,
            1.9587171077728271,
            -5.742688179016113,
            -0.17645779252052307,
            0.8484047651290894,
            1.9134960174560547,
            1.51524019241333,
            1.65287184715271,
            -0.9744837284088135,
            3.693387269973755,
            0.846365749835968,
            -3.18538761138916,
            -4.713399887084961,
            1.541289210319519,
            6.139259338378906,
            1.215251088142395,
            -3.491915464401245,
            0.18164986371994019,
            0.23733556270599365,
            -4.745240211486816,
            3.9964840412139893,
            -0.8427219390869141,
            3.3088202476501465,
            -0.21350336074829102,
            0.27332234382629395,
            -1.420657992362976,
            -0.5763885974884033,
            -4.2397918701171875,
            0.4649103283882141,
            0.02587774395942688,
            -5.171680927276611,
            1.0110764503479004,
            -2.4414124488830566,
            0.3678014278411865,
            2.4755921363830566,
            -4.038426399230957,
            3.9290003776550293,
            2.622076988220215,
            0.30586475133895874,
            2.5092790126800537,
            2.148369312286377,
            -0.9172376394271851,
            -2.5153794288635254,
            -1.3270363807678223,
            2.150738477706909,
            -3.0015909671783447,
            0.7934732437133789,
            -3.615237236022949,
            6.091953754425049,
            -1.5740748643875122,
            -0.06109693646430969,
            4.081864356994629,
            -1.2669177055358887,
            -1.6737024784088135,
            0.7812116146087646,
            1.6081395149230957,
            -1.129865288734436,
            4.0008158683776855,
            4.316330909729004,
            4.694419860839844,
            -0.4522390365600586,
            -2.8143608570098877,
            -2.7141923904418945,
            -0.28335633873939514,
            0.08774733543395996,
            3.6334307193756104,
            3.155238151550293,
            2.525991439819336,
            1.7437673807144165,
            -3.8750436305999756,
            -4.290060997009277,
            -7.475472927093506,
            0.007445588707923889,
            -2.5111138820648193,
            0.5125226378440857,
            3.1241180896759033,
            4.243289470672607,
            -5.1319804191589355,
            0.17781484127044678,
            -0.530320942401886,
            0.4404563903808594,
            -0.5133553743362427,
            0.6783106327056885,
            -2.760842800140381,
            -4.228910446166992,
            -1.3966946601867676,
            -2.7792458534240723,
            -0.6310248374938965,
            -1.6603323221206665,
            -0.590996265411377,
            -2.1653900146484375,
            0.8265913724899292,
            4.581562042236328,
            -1.4697144031524658,
            1.3372383117675781,
            2.1284162998199463,
            -1.0659549236297607,
            1.656539797782898,
            1.9608622789382935,
            -1.2817386388778687,
            0.4765239655971527,
            2.9245262145996094,
            -2.334012746810913,
            -4.550535202026367,
            1.6696293354034424,
            -0.8941535353660583,
            0.30826035141944885,
            -0.11632558703422546,
            4.996161460876465,
            -3.989128589630127,
            -0.462719202041626,
            1.3611104488372803,
            0.7035543918609619,
            -1.4578871726989746,
            -1.4272211790084839,
            3.314070463180542,
            0.7211648225784302,
            -2.710143566131592,
            -3.717775344848633,
            -2.064406394958496,
            -5.358646392822266,
            3.2243993282318115,
            -1.4151463508605957,
            2.8696353435516357,
            -3.329131603240967,
            5.436702728271484,
            0.8510228395462036,
            3.137662172317505,
            3.346940040588379,
            2.1301486492156982,
            -1.385665774345398,
            -1.1714072227478027,
            -1.2442837953567505,
            -0.4225000739097595,
            0.033192962408065796,
            -4.268934726715088,
            3.316876173019409,
            5.873115539550781,
            -2.387054443359375,
            2.7798538208007812,
            -0.963553249835968,
            -0.026458144187927246,
            2.010469913482666,
            -2.8851780891418457,
            -1.3561546802520752,
            -2.9611949920654297,
            2.0538289546966553,
            0.607704758644104,
            2.604307174682617,
            -1.4298572540283203,
            3.2701303958892822,
            2.6800084114074707,
            -1.3558508157730103,
            -1.1992428302764893,
            2.558086395263672,
            1.9108903408050537,
            -3.1673929691314697,
            0.10580107569694519,
            1.1363890171051025,
            -1.0879006385803223,
            0.8850477933883667,
            -2.9711780548095703,
            12.549753189086914,
            -1.2961136102676392,
            1.051344394683838,
            -4.447469711303711,
            -0.5281475186347961,
            -4.8416924476623535,
            -1.519438624382019,
            2.1638970375061035,
            -0.8032880425453186,
            -0.5331375598907471,
            -2.448580741882324,
            -1.8010120391845703,
            -0.9669570922851562,
            -0.26024705171585083,
            -0.2778114080429077,
            5.138832092285156,
            -3.0113699436187744,
            3.6102099418640137,
            0.47364920377731323,
            2.3374814987182617,
            -1.230770468711853,
            0.4160107374191284,
            1.0063471794128418,
            -1.4292035102844238,
            -2.289019823074341,
            0.8022557497024536,
            1.1478902101516724,
            2.943091869354248,
            -1.2649524211883545,
            -5.261569499969482,
            -0.8190361857414246,
            -4.295656204223633,
            1.0307673215866089,
            1.8844130039215088,
            0.23443832993507385,
            -4.858649253845215,
            4.360398292541504,
            5.992443084716797,
            -2.6938509941101074,
            2.322873592376709,
            -0.2955935001373291,
            2.830765724182129,
            -3.243992805480957,
            -0.43189698457717896,
            -1.7219157218933105,
            -1.464205265045166,
            -0.4532960057258606,
            -4.6756134033203125,
            -3.2892651557922363,
            -0.655534565448761,
            1.5135966539382935,
            1.843200445175171,
            1.2851295471191406,
            -2.9216105937957764,
            -2.317288637161255,
            -0.01708056777715683,
            5.727164268493652,
            1.026280403137207,
            -3.3299388885498047,
            2.7875492572784424,
            2.2455356121063232,
            0.3342013955116272,
            0.00015464425086975098,
            4.367164134979248,
            -1.1880016326904297,
            0.4584529995918274,
            -4.559541702270508,
            -0.6158769726753235,
            -0.04937434196472168,
            4.636852264404297,
            0.42046260833740234,
            2.409419059753418,
            1.4506081342697144,
            -1.3875035047531128,
            0.42419707775115967,
            3.6795740127563477,
            -6.2434916496276855,
            2.82515811920166,
            -1.5333364009857178,
            1.2032215595245361,
            -0.09558597207069397,
            -0.42585092782974243,
            -4.442532539367676,
            -1.0129454135894775,
            3.1884403228759766,
            -1.1739369630813599,
            3.464704990386963,
            -1.8497005701065063,
            1.4112595319747925,
            0.6424369215965271,
            -2.809659481048584,
            0.029157742857933044,
            1.814018964767456,
            0.10708308219909668,
            -1.7846381664276123,
            3.8451600074768066,
            -0.6693432927131653,
            0.5338124632835388,
            2.9150123596191406,
            -0.7235550284385681,
            1.1230919361114502,
            -7.55570650100708,
            -0.4583453834056854,
            0.7392170429229736,
            0.5577009320259094,
            1.0458810329437256,
            -3.374660015106201,
            3.5705714225769043,
            -3.3527398109436035,
            -0.5499082803726196,
            2.0311317443847656,
            -0.02649351954460144,
            -0.6354738473892212,
            -4.404358863830566,
            0.2910328209400177,
            0.504418671131134,
            -0.3460957407951355,
            -4.279234409332275,
            0.618948221206665,
            5.53943395614624,
            4.120100021362305,
            2.2652645111083984,
            -1.7271901369094849,
            -0.375139057636261,
            -1.349325180053711,
            -1.1095789670944214,
            3.4678969383239746,
            -2.643528938293457,
            1.6367692947387695,
            0.38133296370506287,
            -5.4019670486450195,
            3.9017837047576904,
            0.18002033233642578,
            1.7450501918792725,
            -0.8732000589370728,
            -5.799249649047852,
            -2.9352455139160156,
            -2.137380361557007,
            -3.089916229248047,
            4.409897327423096,
            5.273645401000977,
            -3.6167194843292236,
            -1.3646349906921387,
            3.4613423347473145,
            -0.5375690460205078,
            -0.8865295648574829,
            -4.211828231811523,
            3.453589916229248,
            -0.5840764045715332,
            1.2852636575698853,
            0.9135566353797913,
            -0.6528277397155762,
            0.7454134225845337,
            0.07453322410583496,
            -3.0762577056884766,
            2.940032720565796,
            -1.237135410308838,
            2.2981929779052734,
            0.7542107105255127,
            1.5812435150146484,
            -2.1419119834899902,
            1.3563413619995117,
            1.7246946096420288,
            6.940863609313965,
            4.188084602355957,
            2.8592140674591064,
            -0.0846555083990097,
            -2.879042863845825,
            0.871379554271698,
            -1.7943683862686157,
            1.3482069969177246,
            4.4495110511779785,
            -2.7377991676330566,
            -0.010378658771514893,
            -3.478365659713745,
            2.1865246295928955,
            3.762547731399536,
            5.95428991317749,
            0.5185747146606445,
            2.4686193466186523,
            -6.442767143249512,
            0.7591893672943115,
            -2.057159900665283,
            -0.01876172423362732,
            1.8731346130371094,
            0.537773847579956,
            2.2013564109802246,
            1.9070472717285156,
            -1.7550053596496582,
            -2.5118422508239746,
            -1.2499035596847534,
            0.6026643514633179,
            -1.6280288696289062,
            2.653595209121704,
            1.6786612272262573,
            1.2740044593811035,
            -0.6308269500732422,
            7.580009937286377,
            -1.3165397644042969,
            -2.9460582733154297,
            -3.486553192138672,
            2.305142402648926,
            -0.22434638440608978,
            -2.292807102203369,
            0.08301430940628052,
            -2.9110093116760254,
            3.8203024864196777,
            -0.4131762981414795,
            -0.5455551743507385,
            2.4123334884643555,
            0.473731130361557,
            -0.22956255078315735,
            -3.3990721702575684,
            -2.961822032928467,
            -0.544304370880127,
            -1.8840453624725342,
            -4.131543159484863,
            -4.734678268432617,
            0.08245939016342163,
            -2.4690256118774414,
            -2.4813413619995117,
            3.727548122406006,
            -3.8190760612487793,
            1.1001402139663696,
            0.5516558885574341,
            -2.07466983795166,
            0.21291716396808624,
            -2.050478458404541,
            -1.2401210069656372,
            -6.2852864265441895,
            0.7383381128311157,
            -0.6544620990753174,
            -0.8633118867874146,
            -1.9135117530822754,
            -0.36621716618537903,
            4.583560943603516,
            2.8726348876953125,
            0.33895736932754517,
            -3.6724348068237305,
            -0.18621869385242462,
            5.981809139251709,
            0.12977057695388794,
            -0.3088453412055969,
            -1.7879438400268555,
            -2.8391361236572266,
            2.4571053981781006,
            17.749881744384766,
            -0.42356228828430176,
            -3.918092966079712,
            -2.6348187923431396,
            0.2717891335487366,
            -3.5266776084899902,
            -2.496591567993164,
            0.8950667977333069,
            -0.5346594452857971,
            2.975309133529663,
            0.33988481760025024,
            0.7669130563735962,
            1.3813027143478394,
            1.8940391540527344,
            -2.651059865951538,
            0.9494671821594238,
            -1.434232234954834,
            0.007279038429260254,
            -2.152177333831787,
            0.43116989731788635,
            1.9410823583602905,
            0.5045688152313232,
            -1.3416334390640259,
            -3.9186973571777344,
            -2.8920395374298096,
            0.5147560238838196,
            5.740486145019531,
            1.935272216796875,
            -0.9776440858840942,
            -0.08467835187911987,
            1.8402456045150757,
            0.8788455724716187,
            0.8998497724533081,
            0.06369879841804504,
            -1.9851269721984863,
            4.89117956161499,
            1.7191762924194336,
            -1.0634217262268066,
            3.434081554412842,
            0.8661101460456848,
            -0.6174331903457642,
            1.3046389818191528,
            -1.288318157196045,
            -0.7002712488174438,
            -2.3553192615509033,
            0.5435310006141663,
            1.8794496059417725,
            -2.7999460697174072,
            -3.5179927349090576,
            3.3710222244262695,
            -2.7050273418426514,
            -3.1771907806396484,
            -2.2243826389312744,
            -2.6799609661102295,
            -0.32845550775527954,
            3.3060145378112793,
            -1.4708449840545654,
            -2.0976500511169434,
            2.821582317352295,
            -0.3728882670402527,
            2.795916795730591,
            -0.7388051152229309,
            -2.3094980716705322,
            -0.37948182225227356,
            -4.316626071929932,
            3.0513737201690674,
            -2.296255350112915,
            -0.355530321598053,
            0.6275812387466431,
            -0.7055919766426086,
            3.4339654445648193,
            0.04079464077949524,
            1.3310668468475342,
            -0.17888586223125458,
            2.1094846725463867,
            -2.875213146209717,
            2.4737305641174316,
            -1.657264232635498,
            -1.6349657773971558,
            8.465887069702148,
            -3.1668221950531006,
            5.2928924560546875,
            2.070465564727783,
            -1.2542533874511719,
            2.7616162300109863,
            -3.497729778289795,
            4.8824357986450195,
            2.1655073165893555,
            -4.119147300720215,
            2.853541851043701,
            -1.969031810760498,
            -1.2680516242980957,
            3.4243502616882324,
            3.051028251647949,
            3.119807243347168,
            -3.613924980163574,
            -3.7504849433898926,
            -5.7178144454956055,
            -3.2782318592071533,
            -1.191078543663025,
            5.223684310913086,
            2.505202293395996,
            2.128511428833008,
            -1.16987943649292,
            0.22628943622112274,
            -1.7686647176742554,
            0.1770743578672409,
            -2.5740413665771484,
            -1.7003180980682373,
            0.27745339274406433,
            2.995408058166504,
            -1.937619686126709,
            -1.0805366039276123,
            0.9457331299781799,
            0.9606956243515015,
            -3.4079463481903076,
            0.5360264182090759,
            0.2338651716709137,
            2.532585620880127,
            1.607280969619751,
            0.38181135058403015,
            -0.006880760192871094,
            -0.12386542558670044,
            -2.5037248134613037,
            -0.8264560699462891,
            0.5129382610321045,
            -3.72285532951355,
            -2.1441564559936523,
            -1.5151774883270264,
            1.5960187911987305,
            0.6872296333312988,
            0.2087102234363556,
            -1.8111286163330078,
            -0.04876723885536194,
            -0.8527682423591614,
            -1.5803864002227783,
            0.6678972244262695,
            2.259885787963867,
            -0.2685850262641907,
            1.6250841617584229,
            6.284292221069336,
            -4.310285568237305,
            2.5749006271362305,
            8.559307098388672,
            0.40113985538482666,
            0.23178213834762573,
            -2.9608917236328125,
            -1.011520266532898,
            0.7831695079803467,
            2.1748688220977783,
            0.5958736538887024,
            -2.56850528717041,
            1.9975790977478027,
            -0.12188541889190674,
            1.4842404127120972,
            -3.0366485118865967
        ]
    },
    "authors": [
        {
            "authorId": "2316519813",
            "name": "Jiajun Xu"
        },
        {
            "authorId": "2294674012",
            "name": "Zhiyuan Li"
        },
        {
            "authorId": "2294845809",
            "name": "Wei Chen"
        },
        {
            "authorId": "2316514278",
            "name": "Qun Wang"
        },
        {
            "authorId": "2319809164",
            "name": "Xin Gao"
        },
        {
            "authorId": "2319333048",
            "name": "Qi Cai"
        },
        {
            "authorId": "2319410023",
            "name": "Ziyuan Ling"
        }
    ],
    "references": [
        {
            "paperId": "4b6a597ca3a722f7875db927946e41aaa5fdfc24",
            "title": "A General-Purpose Device for Interaction with LLMs"
        },
        {
            "paperId": "6520557cc3bfd198f960cc8cb6151c3474321bd8",
            "title": "The Llama 3 Herd of Models"
        },
        {
            "paperId": "7241ca4190676d4a203fabc87dd55f65a44192df",
            "title": "Metron: Holistic Performance Evaluation Framework for LLM Inference Systems"
        },
        {
            "paperId": "bdbaa3c801d8ee0576986a27e5decc73f0ff9b4d",
            "title": "Enabling On-Device LLMs Personalization with Smartphone Sensing"
        },
        {
            "paperId": "312b06cf2eec64b19c44f0e2ab649dde49b06b1e",
            "title": "Offline Energy-Optimal LLM Serving: Workload-Based Energy Models for LLM Inference on Heterogeneous Systems"
        },
        {
            "paperId": "29c67918f2a4dfd167e4d4b878defad093dd3824",
            "title": "VELO: A Vector Database-Assisted Cloud-Edge Collaborative LLM QoS Optimization Framework"
        },
        {
            "paperId": "bf472a22415d5bb6a83660604c2a8e8bb3f92e93",
            "title": "PFID: Privacy First Inference Delegation Framework for LLMs"
        },
        {
            "paperId": "c7f9706898bdfa3241601e075b1305649b174ff1",
            "title": "ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools"
        },
        {
            "paperId": "0a9a9fc600eccdcf13e46044844f2fcc8f22920a",
            "title": "DataComp-LM: In search of the next generation of training sets for language models"
        },
        {
            "paperId": "bd247dfa9697447b08e6fb6700eb6a91ecb13af8",
            "title": "GUI-WORLD: A Dataset for GUI-oriented Multimodal LLM-based Agents"
        },
        {
            "paperId": "236eeca00166bbfc0226c446e54e2189a0b500ae",
            "title": "New Solutions on LLM Acceleration, Optimization, and Application"
        },
        {
            "paperId": "74894e3d6cdaceba75d6c256abc1cf82483e4e21",
            "title": "MobileAIBench: Benchmarking LLMs and LMMs for On-Device Use Cases"
        },
        {
            "paperId": "0afae4fd689b99b76b46daee66f1be9c743518b6",
            "title": "PowerInfer-2: Fast Large Language Model Inference on a Smartphone"
        },
        {
            "paperId": "c80a3847fd13b06e1b0ff4e59c4bb3df06bd088d",
            "title": "Hybrid SLM and LLM for Edge-Cloud Collaborative Inference"
        },
        {
            "paperId": "b5e689a220e01c775ff3159b778e62deed862f4b",
            "title": "WiP: An On-device LLM-based Approach to Query Privacy Protection"
        },
        {
            "paperId": "8a2fdd5d6c93eeb9df5b8d2e21b01cd4a68b037d",
            "title": "No Free Lunch Theorem for Privacy-Preserving LLM Inference"
        },
        {
            "paperId": "58700f3740105e3422eb030305372b6d8bc44986",
            "title": "Hardware-Aware Parallel Prompt Decoding for Memory-Efficient Acceleration of LLM Inference"
        },
        {
            "paperId": "87a108853c92a969fda26d0fd91bbd1d70706a98",
            "title": "The Evolution of Multimodal Model Architectures"
        },
        {
            "paperId": "cceaefd3c86fa34970ef597fbd8c71d668180745",
            "title": "EdgeShard: Efficient LLM Inference via Collaborative Edge Computing"
        },
        {
            "paperId": "3c465f37b0d7b4cc51c22f34c85ff3fe0f7035ca",
            "title": "PerLLM: Personalized Inference Scheduling with Edge-Cloud Collaboration for Diverse LLM Services"
        },
        {
            "paperId": "6839e8ef0205ad4732e9f743977eb5bfc296ec2c",
            "title": "Towards Modular LLMs by Building and Reusing a Library of LoRAs"
        },
        {
            "paperId": "fc5933ced955bb14c8b28a1d401bd00b8e4d08b2",
            "title": "WDMoE: Wireless Distributed Large Language Models with Mixture of Experts"
        },
        {
            "paperId": "481f02fc53a70eb92f6f328323387ab7f91cbbac",
            "title": "The Breakthrough Memory Solutions for Improved Performance on LLM Inference"
        },
        {
            "paperId": "779c031fc347bb278a610673e8dc41406d3f7fa0",
            "title": "Octopus v4: Graph of language models"
        },
        {
            "paperId": "7d09c6c8ef1e1c0c447cb8910c27a7acf1dd96af",
            "title": "Continual Learning of Large Language Models: A Comprehensive Survey"
        },
        {
            "paperId": "f187697a28fdc8d6d44dc3c1ea3a65ed85449c42",
            "title": "Examining the robustness of LLM evaluation to the distributional assumptions of benchmarks"
        },
        {
            "paperId": "db229da82d4821446fb14d084ec58da7d964b7ce",
            "title": "OpenELM: An Efficient Language Model Family with Open Training and Inference Framework"
        },
        {
            "paperId": "b8c0fa6a4af6ecfe1932b374d9f60ca07f17ac0a",
            "title": "Deferred Continuous Batching in Resource-Efficient Large Language Model Serving"
        },
        {
            "paperId": "9a90ab84efe9f85f7f80788ec081b48e621a73ce",
            "title": "Edge Intelligence Optimization for Large Language Model Inference with Batching and Quantization"
        },
        {
            "paperId": "ec93fc7ec82c65a7bf7213488327d391014539ed",
            "title": "An Empirical Analysis and Resource Footprint Study of Deploying Large Language Models on Edge Devices"
        },
        {
            "paperId": "264e25fdda3dc68706d1c6aa684bb2395769faaa",
            "title": "Octopus v3: Technical Report for On-device Sub-billion Multimodal AI Agent"
        },
        {
            "paperId": "a39ed048aa86296b16f9d2d33011f94e3d5ac402",
            "title": "Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models"
        },
        {
            "paperId": "c9ff9fbbe21985b35d6a070b67f22a0e065c4328",
            "title": "JetMoE: Reaching Llama2 Performance with 0.1M Dollars"
        },
        {
            "paperId": "d0a21c79996815953f933286d848f11eca42f097",
            "title": "Scalable Language Model with Generalized Continual Learning"
        },
        {
            "paperId": "49873ee415619efd9e1e4c16f73ee066ff008c1f",
            "title": "MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies"
        },
        {
            "paperId": "5de0279248f2c688b0a6fb09be6d23bb6890e3b2",
            "title": "Octopus: On-device language model for function calling of software APIs"
        },
        {
            "paperId": "3dcc854dbe084f24419ace8a682f100a14aeb09b",
            "title": "Octopus v2: On-device language model for super agent"
        },
        {
            "paperId": "8d63fdce0e72223e8adbf8e73c33d17a1c960f86",
            "title": "Preventing the Immense Increase in the Life-Cycle Energy and Carbon Footprints of LLM-Powered Intelligent Chatbots"
        },
        {
            "paperId": "72c906a9841b8d44c2962c4890d5845a394856bb",
            "title": "Towards Greener LLMs: Bringing Energy-Efficiency to the Forefront of LLM Inference"
        },
        {
            "paperId": "cef6713b723224d4f1dadd3e6dc95baa63d24644",
            "title": "Tiny Machine Learning: Progress and Futures [Feature]"
        },
        {
            "paperId": "75b2ae5ee35611ecfbd3dc2c3d0799cfb4fd98e4",
            "title": "InternLM2 Technical Report"
        },
        {
            "paperId": "93ad719fdad8ef1ced208d7034954009ec4d793e",
            "title": "Exploring Post-training Quantization in LLMs from Comprehensive Study to Low Rank Compensation"
        },
        {
            "paperId": "70bfd279b24583bbbf58804b5d4a1c1367464201",
            "title": "A Multimodal Approach to Device-Directed Speech Detection with Large Language Models"
        },
        {
            "paperId": "8c997fbe1606f544fe5a26c1177f640880b597bf",
            "title": "MELTing point: Mobile Evaluation of Language Transformers"
        },
        {
            "paperId": "1942fd1ee7e584dbd313492588b13449779d7c6e",
            "title": "LLM as a System Service on Mobile Devices"
        },
        {
            "paperId": "1a25e89d3df8574f9f3eed6c314b369289b35855",
            "title": "Using an LLM to Turn Sign Spottings into Spoken Language Sentences"
        },
        {
            "paperId": "6675bcf6dc97c87da7afda223938ec7e51ecc3b2",
            "title": "MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training"
        },
        {
            "paperId": "c0b454e0a6aa51ff3ba56778787d0c43932ef6ba",
            "title": "Yi: Open Foundation Models by 01.AI"
        },
        {
            "paperId": "c1fa6255cc9fc3128f74befc7855e255bc7a2c6e",
            "title": "GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection"
        },
        {
            "paperId": "fc5eb6a11987bcd0bf0460ff65b46f15cee3a911",
            "title": "Interactive Continual Learning: Fast and Slow Thinking"
        },
        {
            "paperId": "1d10aa5e7122d1df6d559999987c76de3a088f62",
            "title": "Training Machine Learning models at the Edge: A Survey"
        },
        {
            "paperId": "20f090e35ad598fba2404e550c2462dc9da03a10",
            "title": "Taming Throughput-Latency Tradeoff in LLM Inference with Sarathi-Serve"
        },
        {
            "paperId": "fdbe9b2fd738a25a4e3cb344d831d3709dec0b7b",
            "title": "LLM-PQ: Serving LLM on Heterogeneous Clusters with Phase-Aware Partition and Adaptive Quantization"
        },
        {
            "paperId": "63167c30b06aa6c3d76e09065ced0412090d6c3b",
            "title": "The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits"
        },
        {
            "paperId": "2cea424c7dce71042c24d43317521abdc4c0ffb4",
            "title": "Large Multimodal Agents: A Survey"
        },
        {
            "paperId": "f7310dac21abc6ba357bcd5e75fb2e6957a97303",
            "title": "MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases"
        },
        {
            "paperId": "758c2dc290c037a6f211ec503beee70abe2d1197",
            "title": "DriveVLM: The Convergence of Autonomous Driving and Large Vision-Language Models"
        },
        {
            "paperId": "ee92723f03475fcfbb37ce8b8c888c497453ceb9",
            "title": "Head-wise Shareable Attention for Large Language Models"
        },
        {
            "paperId": "b3c99575f91c551704d4a31d703d5ceb4b616dd1",
            "title": "Any-Precision LLM: Low-Cost Deployment of Multiple, Different-Sized LLMs"
        },
        {
            "paperId": "13b8934468665ecb586f491d7f9f6c460cb095e5",
            "title": "BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains"
        },
        {
            "paperId": "ce7a2ea8774b996e7022b3bd712c13b75365fc96",
            "title": "Large Language Models for Forecasting and Anomaly Detection: A Systematic Literature Review"
        },
        {
            "paperId": "d3a23b571143a45c5d7406fbc395750ac5cfef95",
            "title": "BiLLM: Pushing the Limit of Post-Training Quantization for LLMs"
        },
        {
            "paperId": "a091bf215c716a146140f81c751712db628c8e20",
            "title": "MobileVLM V2: Faster and Stronger Baseline for Vision Language Model"
        },
        {
            "paperId": "bd0cd89337cc40d39d3a4cbe9c8709e06e877f3e",
            "title": "Continual Learning for Large Language Models: A Survey"
        },
        {
            "paperId": "05ab4b262a2a343aa505ff3640fdf30b2530ac99",
            "title": "LLM-based NLG Evaluation: Current Status and Challenges"
        },
        {
            "paperId": "ac45bbf9940512d9d686cf8cd3a95969bc313570",
            "title": "OLMo: Accelerating the Science of Language Models"
        },
        {
            "paperId": "ad1bb59e3e18a0dd8503c3961d6074f162baf710",
            "title": "Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research"
        },
        {
            "paperId": "74a2ef37466667c843b6322691c49b0475030cb0",
            "title": "Security and Privacy Challenges of Large Language Models: A Survey"
        },
        {
            "paperId": "cd1d7f5c4ce2d31ce9ee72db165a8272624da7d3",
            "title": "MoE-LLaVA: Mixture of Experts for Large Vision-Language Models"
        },
        {
            "paperId": "27d2c0acd2f26f98548ea62c1919cecbc60a8b11",
            "title": "Scaling Sparse Fine-Tuning to Large Language Models"
        },
        {
            "paperId": "a5001fd96ee93464791072904818d90f739a4662",
            "title": "LocMoE: A Low-overhead MoE for Large Language Model Training"
        },
        {
            "paperId": "21e53e51ff77a5f34f43cb8ca029909c3ad9f71e",
            "title": "Inference without Interference: Disaggregate LLM Inference for Mixed Downstream Workloads"
        },
        {
            "paperId": "57e7af0b69325fafb371ef5d502e39ef9c90ef7e",
            "title": "Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads"
        },
        {
            "paperId": "cf278f48c09c2747f415c0b190c09773673ea959",
            "title": "A Survey on Hardware Accelerators for Large Language Models"
        },
        {
            "paperId": "cfabacfc676ea8804b5acbab169f2df5e5866d4d",
            "title": "A Survey of Resource-efficient LLM and Multimodal Foundation Models"
        },
        {
            "paperId": "06d860a5bbb99a4eafdbbb2d5f6aa8dd5fd32cf4",
            "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security"
        },
        {
            "paperId": "411114f989a3d1083d90afd265103132fee94ebe",
            "title": "Mixtral of Experts"
        },
        {
            "paperId": "560c6f24c335c2dd27be0cfa50dbdbb50a9e4bfd",
            "title": "TinyLlama: An Open-Source Small Language Model"
        },
        {
            "paperId": "6348aeb405a496ca1729f3cc6e5eb6f12d0bc151",
            "title": "Beyond Efficiency: A Systematic Survey of Resource-Efficient Large Language Models"
        },
        {
            "paperId": "5acbf917da5be89e4eebd7e98c81d87069450a5d",
            "title": "Cloud-Device Collaborative Learning for Multimodal Large Language Models"
        },
        {
            "paperId": "01944be9dc13f74befe55e39a971e6191d677afa",
            "title": "A Performance Evaluation of a Quantized Large Language Model on Various Smartphones"
        },
        {
            "paperId": "ddacee7382548fd9976e846c92500cfa3b6741db",
            "title": "PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU"
        },
        {
            "paperId": "3784e97b757aa1581cfd3a368ffe1fc053d1cc88",
            "title": "Ensemble Variance Reduction Methods for Stochastic Mixed-Integer Programming and their Application to the Stochastic Facility Location Problem"
        },
        {
            "paperId": "53c3c3984649ca82a2f85629dae01087e9e72991",
            "title": "OneLLM: One Framework to Align All Modalities with Language"
        },
        {
            "paperId": "383c598625110e0a4c60da4db10a838ef822fbcf",
            "title": "A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly"
        },
        {
            "paperId": "eca8a3e6383e3618e0bc984382e08c09be3cca6c",
            "title": "TimeChat: A Time-sensitive Multimodal Large Language Model for Long Video Understanding"
        },
        {
            "paperId": "2c0312c604f9f7638bb4533b39e0ae81e7f6ab12",
            "title": "The Falcon Series of Open Language Models"
        },
        {
            "paperId": "b10d8f2913a18f90561e616881a42ae1f36d74c9",
            "title": "PrivateLoRA For Efficient Privacy Preserving LLM"
        },
        {
            "paperId": "52941cadbd340344f3e0a6f50719fe55b3de5088",
            "title": "Multimodal Large Language Models: A Survey"
        },
        {
            "paperId": "2a86d281bef364e2ea2d4fc61fde46ca25b955f1",
            "title": "HuatuoGPT-II, One-stage Training for Medical Adaption of LLMs"
        },
        {
            "paperId": "d3367dc9a7a1d7ae70a06eadc02b2430f4529f7c",
            "title": "Large Language Models for Robotics: A Survey"
        },
        {
            "paperId": "ac3390c58ef059277466c51a4b642ada8c4b3205",
            "title": "Making LLMs Worth Every Penny: Resource-Limited Text Classification in Banking"
        },
        {
            "paperId": "95240dda409e28acccdc5cf619ad0c036cf4292d",
            "title": "Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time"
        },
        {
            "paperId": "46fe9ce789408b8a50fb4259e6bf0cc5855f4ed5",
            "title": "AgentTuning: Enabling Generalized Agent Abilities for LLMs"
        },
        {
            "paperId": "8ff1dd6e15408581592f91434be870acc5f1bdd4",
            "title": "REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models"
        },
        {
            "paperId": "43017a16dfe593c09533c5fb3c3612c83761a98a",
            "title": "Matrix Compression via Randomized Low Rank and Low Precision Factorization"
        },
        {
            "paperId": "db633c6b1c286c0386f0078d8a2e6224e03a6227",
            "title": "Mistral 7B"
        },
        {
            "paperId": "124d4d374fbef2016fa9880489871a58a7450644",
            "title": "Improved Baselines with Visual Instruction Tuning"
        },
        {
            "paperId": "5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0",
            "title": "Qwen Technical Report"
        },
        {
            "paperId": "07bd95538974fa693d388be113d9122acbf0e19d",
            "title": "LLM-Powered Conversational Voice Assistants: Interaction Patterns, Opportunities, Challenges, and Design Guidelines"
        },
        {
            "paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05",
            "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"
        },
        {
            "paperId": "fa75a55760e6ea49b39b83cb85c99a22e1088254",
            "title": "NExT-GPT: Any-to-Any Multimodal LLM"
        },
        {
            "paperId": "e26888285436bc7998e5c95102a9beb60144be5e",
            "title": "Textbooks Are All You Need II: phi-1.5 technical report"
        },
        {
            "paperId": "00e889fcfaf4396a20f37f681cf8b14f3e878879",
            "title": "LLMCad: Fast and Scalable On-device Large Language Model Inference"
        },
        {
            "paperId": "fc6a2f7478f68adefd69e2071f27e38aa1647f2f",
            "title": "Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond"
        },
        {
            "paperId": "e3763ca5958b20299094ec2d5551d6baf7bdcc6b",
            "title": "Enhancing Trust in LLM-Based AI Automation Agents: New Considerations and Future Challenges"
        },
        {
            "paperId": "304f8b4edea01fdb5a2f7f8b998c83188deeccff",
            "title": "Towards Generalist Biomedical AI"
        },
        {
            "paperId": "e01ab53663e5df5961a021506a9cb09f4efc3788",
            "title": "Challenges and Applications of Large Language Models"
        },
        {
            "paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a",
            "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"
        },
        {
            "paperId": "f5ea85f67fc5ea9cce2c5345ed92740f7377cb2e",
            "title": "Using an LLM to Help with Code Understanding"
        },
        {
            "paperId": "b2c68b708a9f98996b18c8d21b53a815a2c46a8b",
            "title": "ProPILE: Probing Privacy Leakage in Large Language Models"
        },
        {
            "paperId": "2922768fd451ecdb45f48c1a83eb57f54a91221b",
            "title": "Textbooks Are All You Need"
        },
        {
            "paperId": "400cee04737f6a2012a2677acd8c052d233335eb",
            "title": "Understanding Parameter Sharing in Transformers"
        },
        {
            "paperId": "7ca613e577db04bdb90b8c90e125a10a4272a17b",
            "title": "On the Viability of Using LLMs for SW/HW Co-Design: An Example in Designing CiM DNN Accelerators"
        },
        {
            "paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787",
            "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"
        },
        {
            "paperId": "db9507cdd3e2d7d9c90ed185bd831e55c62dcec9",
            "title": "AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration"
        },
        {
            "paperId": "e154dd91de91558f9d671370754eace62a54c911",
            "title": "A study of generative large language model for medical research and healthcare"
        },
        {
            "paperId": "5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200",
            "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints"
        },
        {
            "paperId": "57e90f4fae211f23e2c2d437e344a40ee9da87a0",
            "title": "Response Length Perception and Sequence Scheduling: An LLM-Empowered LLM Inference Pipeline"
        },
        {
            "paperId": "4c4722d3767dae6bc00b7de3e3fa160caaffe483",
            "title": "Privacy-Preserving Prompt Tuning for Large Language Model Services"
        },
        {
            "paperId": "81e7e82245c2f230eeb8aaaa1a2b2604c143754a",
            "title": "MultiModal-GPT: A Vision and Language Model for Dialogue with Humans"
        },
        {
            "paperId": "131c6f328c11706de2c43cd16e0b7c5d5e610b6a",
            "title": "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond"
        },
        {
            "paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8",
            "title": "Visual Instruction Tuning"
        },
        {
            "paperId": "38179848e2d6a3ad373b1793848816111428ac36",
            "title": "OpenAGI: When LLM Meets Domain Experts"
        },
        {
            "paperId": "d4793bcb3fd92b9da9a62b15e0dc93f64e452578",
            "title": "Decoder-Only or Encoder-Decoder? Interpreting Language Model as a Regularized Encoder-Decoder"
        },
        {
            "paperId": "a757999ed260d7bc45484dc6b4456bf33fe6f679",
            "title": "LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention"
        },
        {
            "paperId": "163b4d6a79a5b19af88b8585456363340d9efd04",
            "title": "GPT-4 Technical Report"
        },
        {
            "paperId": "d51f1261148bd2f13006be78d21385abbe58a631",
            "title": "On Model Compression for Neural Networks: Framework, Algorithm, and Convergence Guarantee"
        },
        {
            "paperId": "57e849d0de13ed5f91d086936296721d4ff75a75",
            "title": "LLaMA: Open and Efficient Foundation Language Models"
        },
        {
            "paperId": "6ee2cb42f838323e55042428b7e804426653bb36",
            "title": "Compromise policy for multi-stage stochastic linear programming: Variance and bias reduction"
        },
        {
            "paperId": "7da0f2501034522e3d50af7e9b8fa7ec9d7b65b6",
            "title": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers"
        },
        {
            "paperId": "c2c6bb5c70488897afb0a96dfabe39a607605210",
            "title": "On-Device Training Under 256KB Memory"
        },
        {
            "paperId": "cb5e3f085caefd1f3d5e08637ab55d39e61234fc",
            "title": "Do As I Can, Not As I Say: Grounding Language in Robotic Affordances"
        },
        {
            "paperId": "7a7a4f41f9ca5682b1444140799ca4dde44352f5",
            "title": "Overcoming Oscillations in Quantization-Aware Training"
        },
        {
            "paperId": "80d0116d77beeded0c23cf48946d9d10d4faee14",
            "title": "GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"
        },
        {
            "paperId": "cddf40e579a596d0110b260313adf43470617c4c",
            "title": "Datasets: A Community Library for Natural Language Processing"
        },
        {
            "paperId": "3263cae798e14e58e4302cf924766a05a7e8126f",
            "title": "Aquabolt-XL: Samsung HBM2-PIM with in-memory processing for ML accelerators and beyond"
        },
        {
            "paperId": "1d5617db4c7c05d3dbb5e7e319d9b51572fd6412",
            "title": "Near-Memory Processing in Action: Accelerating Personalized Recommendation With AxDIMM"
        },
        {
            "paperId": "b103e87c7727134927d3ffb06934a95c10c02fc0",
            "title": "GPT-3: Its Nature, Scope, Limits, and Consequences"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "519b7c2a6429ca81c45ae24af502f21cfd17ff39",
            "title": "Computational Operations Research Exchange (Core): A Cyber-Infrastructure for Analytics"
        },
        {
            "paperId": "10eda4521c032adabaa8e70d6569e17370b29dcd",
            "title": "Root Mean Square Layer Normalization"
        },
        {
            "paperId": "c95383f251a62c63217586059c67f63507c3e839",
            "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"
        },
        {
            "paperId": "783a40d65f6b77c7b5135a92c8d962c76a512c66",
            "title": "Market"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586",
            "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"
        },
        {
            "paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e",
            "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
        },
        {
            "paperId": "47990fefbad009186adc7da2f4218815f9d74a02",
            "title": "Mixture of experts: a literature survey"
        },
        {
            "paperId": "0a5339ea02b719101a86c537235d520bbbe2b32d",
            "title": "Overview"
        },
        {
            "paperId": "c8d90974c3f3b40fa05e322df2905fc16204aa56",
            "title": "Adaptive Mixtures of Local Experts"
        },
        {
            "paperId": "c09a17ca78f06c2e5394fec19bdfbea55a216a7b",
            "title": "Towards Efficient and Reliable LLM Serving: A Real-World Workload Study"
        },
        {
            "paperId": "8a9b43946dc10f91ce8c5971a1f247fbacda7a42",
            "title": "Opening the Black Box of Large Language Models: Two Views on Holistic Interpretability"
        },
        {
            "paperId": "2b7c9fd2a94deaee3e7e56dc57bab0bd39d3683c",
            "title": "AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration"
        },
        {
            "paperId": "1a4c6856292b8c64d19a812a77f0aa6fd47cb96c",
            "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework"
        },
        {
            "paperId": "3d473cbb7a377cf960abff31748a1a39bb6c7d7c",
            "title": "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding"
        },
        {
            "paperId": "b8b45b14df9029562b8995c6ab7fd90a8810f312",
            "title": "GPT3.int8(): 8-bit Matrix Multiplication for Transformers at Scale"
        },
        {
            "paperId": "02ded8fd5415556babb817c6a439eb5257047b2c",
            "title": "Towards Understanding the Mixture-of-Experts Layer in Deep Learning"
        },
        {
            "paperId": "d4b95b37bcec7f5b09f02c60e5e12bb13aa86866",
            "title": "Preprint. Under review"
        },
        {
            "paperId": null,
            "title": "On layer normalization in the trans-former architecture"
        },
        {
            "paperId": "9405cc0d6169988371b2755e573cc28650d14dfe",
            "title": "Language Models are Unsupervised Multitask Learners"
        },
        {
            "paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "title": "Improving Language Understanding by Generative Pre-Training"
        },
        {
            "paperId": "6a630ac89d7c0a57eb7bf4cb30dd5946bcf3ccce",
            "title": "google,\u6211,\u8428\u5a1c"
        },
        {
            "paperId": null,
            "title": ": Lightweight library for approximate nearest neighbors and maximum inner product search"
        },
        {
            "paperId": null,
            "title": "Revolutionizing Mobile Interaction: Enabling a 3 Billion Parameter GPT LLM on Mobile"
        },
        {
            "paperId": null,
            "title": "InternLM Team"
        },
        {
            "paperId": null,
            "title": "Openllm: Open-source library for language model lifecycle management"
        },
        {
            "paperId": null,
            "title": ": A lightweight deep neural network inference engine"
        },
        {
            "paperId": null,
            "title": "VLLM Project Team"
        },
        {
            "paperId": null,
            "title": "Modelbest Inc."
        },
        {
            "paperId": null,
            "title": "MLC team"
        },
        {
            "paperId": null,
            "title": "Distill-cli meeting summarizer"
        },
        {
            "paperId": null,
            "title": "MosaicML"
        },
        {
            "paperId": null,
            "title": "Software/hardware co-design for llm and its application for design verification"
        },
        {
            "paperId": null,
            "title": "Gpt4 response time"
        },
        {
            "paperId": null,
            "title": "Ali Cloud Qwen Team. Qwen 2-0.5b"
        },
        {
            "paperId": null,
            "title": "Plaud note summarizer"
        },
        {
            "paperId": null,
            "title": "Gemini: a family of highly capable multimodal models"
        },
        {
            "paperId": null,
            "title": ": Open models based on gemini research and technology"
        }
    ]
}