{
    "paperId": "71c7d4c7b1efe3931552274ec5b27c51844e3ad8",
    "externalIds": {
        "ArXiv": "2407.16198",
        "DBLP": "journals/corr/abs-2407-16198",
        "DOI": "10.48550/arXiv.2407.16198",
        "CorpusId": 271334712
    },
    "title": "INF-LLaVA: Dual-perspective Perception for High-Resolution Multimodal Large Language Model",
    "abstract": "With advancements in data availability and computing resources, Multimodal Large Language Models (MLLMs) have showcased capabilities across various fields. However, the quadratic complexity of the vision encoder in MLLMs constrains the resolution of input images. Most current approaches mitigate this issue by cropping high-resolution images into smaller sub-images, which are then processed independently by the vision encoder. Despite capturing sufficient local details, these sub-images lack global context and fail to interact with one another. To address this limitation, we propose a novel MLLM, INF-LLaVA, designed for effective high-resolution image perception. INF-LLaVA incorporates two innovative components. First, we introduce a Dual-perspective Cropping Module (DCM), which ensures that each sub-image contains continuous details from a local perspective and comprehensive information from a global perspective. Second, we introduce Dual-perspective Enhancement Module (DEM) to enable the mutual enhancement of global and local features, allowing INF-LLaVA to effectively process high-resolution images by simultaneously capturing detailed local information and comprehensive global context. Extensive ablation studies validate the effectiveness of these components, and experiments on a diverse set of benchmarks demonstrate that INF-LLaVA outperforms existing MLLMs. Code and pretrained model are available at https://github.com/WeihuangLin/INF-LLaVA.",
    "venue": "arXiv.org",
    "year": 2024,
    "referenceCount": 112,
    "citationCount": 0,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This work proposes a novel MLLM, INF-LLaVA, designed for effective high-resolution image perception that outperforms existing MLLMs and introduces a Dual-perspective Cropping Module (DCM), which ensures that each sub-image contains continuous details from a local perspective and comprehensive information from a global perspective."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -2.4777746200561523,
            -3.269026041030884,
            0.585517168045044,
            5.864355087280273,
            -2.205228805541992,
            -0.377493679523468,
            3.372903347015381,
            0.2615026831626892,
            -1.968098759651184,
            -2.9177045822143555,
            -1.704418420791626,
            6.817359924316406,
            -2.1990280151367188,
            1.1631346940994263,
            -0.7723224759101868,
            -4.293152332305908,
            -0.8442125916481018,
            0.07506072521209717,
            3.7457103729248047,
            0.977401614189148,
            -2.3357784748077393,
            -0.650902271270752,
            -3.9928812980651855,
            0.7504816055297852,
            -1.0450730323791504,
            -0.7596800327301025,
            1.3976423740386963,
            3.696906328201294,
            -0.6787051558494568,
            -3.2140965461730957,
            0.4057127833366394,
            -2.698883056640625,
            4.884393692016602,
            -2.199491024017334,
            2.708218812942505,
            1.5902280807495117,
            0.7357263565063477,
            4.632187843322754,
            -2.132991313934326,
            -2.4431815147399902,
            1.770986557006836,
            -0.777453601360321,
            -0.2658931314945221,
            -1.539624571800232,
            3.2331607341766357,
            -1.5506584644317627,
            -0.33118700981140137,
            1.5480666160583496,
            -1.3888094425201416,
            2.433225631713867,
            0.9638105034828186,
            1.6853060722351074,
            2.128480911254883,
            1.812582015991211,
            -4.042139530181885,
            -1.3990478515625,
            -0.3158321976661682,
            7.549332141876221,
            5.099770545959473,
            -2.00048828125,
            5.9580488204956055,
            5.727886199951172,
            3.253713369369507,
            4.408627986907959,
            2.885565757751465,
            -2.488222122192383,
            -0.36190319061279297,
            3.7872021198272705,
            0.936397135257721,
            -0.5335025787353516,
            0.45605188608169556,
            -2.420321464538574,
            -0.6173861026763916,
            0.502700924873352,
            -4.740787506103516,
            -1.6997621059417725,
            1.2307660579681396,
            -3.49898624420166,
            -3.5659842491149902,
            -1.156721830368042,
            -0.9066027402877808,
            2.280134677886963,
            1.2239326238632202,
            0.6356340646743774,
            3.163156032562256,
            1.7784767150878906,
            -1.8186079263687134,
            0.8147225379943848,
            -2.1508853435516357,
            -3.204038619995117,
            -2.266693353652954,
            0.3918013572692871,
            0.1658163070678711,
            1.2036997079849243,
            -4.22550630569458,
            1.6996995210647583,
            1.7051818370819092,
            -0.7720169425010681,
            -2.5773065090179443,
            1.231119155883789,
            0.7138674855232239,
            -2.5842278003692627,
            -0.4122127890586853,
            2.3578739166259766,
            0.4972907602787018,
            -3.2081596851348877,
            -1.7932865619659424,
            -1.8787964582443237,
            2.803165912628174,
            -2.701441526412964,
            -2.2996397018432617,
            2.9597463607788086,
            1.7695159912109375,
            0.9304711222648621,
            -4.09830379486084,
            0.665674090385437,
            0.7295607924461365,
            1.7995924949645996,
            -0.8086191415786743,
            5.082250595092773,
            0.8239775896072388,
            -1.397890567779541,
            -2.9213979244232178,
            2.112034797668457,
            2.4373018741607666,
            3.764279365539551,
            -0.03651900589466095,
            -0.1361376792192459,
            0.6622177362442017,
            -2.692739725112915,
            3.176264762878418,
            -3.6899571418762207,
            0.6302604079246521,
            -0.05346211791038513,
            1.0783894062042236,
            3.762650966644287,
            -3.6159849166870117,
            -0.9369539022445679,
            -2.0046215057373047,
            -0.3739985227584839,
            4.0228424072265625,
            4.838562965393066,
            -1.073542594909668,
            2.277073383331299,
            2.064398765563965,
            -3.1876115798950195,
            -1.6322605609893799,
            1.907738208770752,
            1.1502718925476074,
            5.733163833618164,
            1.450890064239502,
            -3.4239773750305176,
            -0.1298072636127472,
            2.814082145690918,
            0.6148649454116821,
            1.373734951019287,
            -5.420771598815918,
            4.28446102142334,
            -2.796339988708496,
            0.866662323474884,
            -2.072489023208618,
            2.485973358154297,
            -11.281608581542969,
            -2.0401039123535156,
            5.026174068450928,
            -2.720552921295166,
            -1.1935272216796875,
            2.408238649368286,
            0.2543428838253021,
            2.7049365043640137,
            2.339517593383789,
            0.4985367953777313,
            3.569406747817993,
            4.8524932861328125,
            2.516688823699951,
            1.9880378246307373,
            1.3491889238357544,
            -2.182210922241211,
            -2.031294584274292,
            1.175724744796753,
            -1.5597413778305054,
            -0.16614055633544922,
            -6.7686567306518555,
            0.866629958152771,
            -3.882519006729126,
            0.49244844913482666,
            -1.2611541748046875,
            -0.4598340690135956,
            0.7410175204277039,
            -0.8560237288475037,
            2.419840097427368,
            0.45104169845581055,
            3.298452854156494,
            4.5814714431762695,
            0.45465967059135437,
            0.5065239667892456,
            0.8148800134658813,
            0.15222066640853882,
            -0.37911340594291687,
            1.0479047298431396,
            4.268748760223389,
            -0.7103196382522583,
            -3.2451515197753906,
            -5.8325347900390625,
            3.1848556995391846,
            0.3651847839355469,
            -3.065152406692505,
            1.24039626121521,
            5.443629264831543,
            -1.3439890146255493,
            0.3496471047401428,
            -0.8975517749786377,
            0.6192499995231628,
            6.638453483581543,
            -1.4732745885849,
            -1.804144024848938,
            -4.845419406890869,
            1.8974902629852295,
            3.116191864013672,
            0.7247534394264221,
            1.8720279932022095,
            3.6067047119140625,
            -0.9591901302337646,
            -1.2421587705612183,
            0.22620007395744324,
            -7.002568244934082,
            -0.8073993921279907,
            2.2130284309387207,
            1.0873315334320068,
            2.0790793895721436,
            -0.3639964461326599,
            -5.622532844543457,
            -0.5531646609306335,
            -0.11537590622901917,
            -5.369085311889648,
            -0.148923859000206,
            -3.7700982093811035,
            1.3637244701385498,
            -3.404881238937378,
            -2.960672378540039,
            7.676058292388916,
            0.6317493915557861,
            1.2288975715637207,
            4.023559093475342,
            0.2924646735191345,
            -2.251481056213379,
            -1.9090874195098877,
            -2.2226338386535645,
            2.8370866775512695,
            0.9626210331916809,
            -0.49539533257484436,
            -1.0669916868209839,
            4.69735860824585,
            -4.026912212371826,
            -1.1591273546218872,
            -2.4024200439453125,
            1.5845913887023926,
            5.3542633056640625,
            1.6238341331481934,
            0.629145622253418,
            2.962526321411133,
            2.9606595039367676,
            1.2025827169418335,
            5.421411514282227,
            -3.7455055713653564,
            -1.393409013748169,
            -0.9308223724365234,
            1.1203036308288574,
            -1.2184643745422363,
            3.1247262954711914,
            4.804224014282227,
            0.9853691458702087,
            0.17639553546905518,
            -4.965696811676025,
            -3.839175224304199,
            -7.354074478149414,
            -4.6921892166137695,
            -0.6784594058990479,
            2.668064594268799,
            1.701655626296997,
            2.5068459510803223,
            -1.2750440835952759,
            -0.6206288933753967,
            -0.5993704199790955,
            -0.05016219615936279,
            -2.5989527702331543,
            -4.13929557800293,
            0.5032976865768433,
            0.11117246747016907,
            -4.279101371765137,
            -2.9357409477233887,
            3.2235875129699707,
            -4.481032848358154,
            -0.062054336071014404,
            -1.7670302391052246,
            5.46370792388916,
            3.9583349227905273,
            -0.5133801698684692,
            -1.1523669958114624,
            0.5840239524841309,
            -1.1488349437713623,
            1.0897064208984375,
            3.862814426422119,
            -2.3973140716552734,
            -1.918903112411499,
            4.271333694458008,
            3.065497398376465,
            -2.286337375640869,
            0.9159079790115356,
            -0.46487802267074585,
            -2.279825210571289,
            1.345978856086731,
            2.8387937545776367,
            -6.9201340675354,
            -2.2659413814544678,
            -0.4821918308734894,
            3.937758684158325,
            -2.7317440509796143,
            -0.4312523901462555,
            1.8465461730957031,
            0.31567248702049255,
            0.8239657282829285,
            -3.8943634033203125,
            -1.4656580686569214,
            -2.935079574584961,
            -3.09431791305542,
            3.0111303329467773,
            2.3616597652435303,
            -3.1091771125793457,
            3.1755733489990234,
            2.5143628120422363,
            4.043452739715576,
            4.384679317474365,
            -0.8136852979660034,
            -1.0282410383224487,
            -2.409396171569824,
            1.233441710472107,
            -2.1324470043182373,
            -0.174627423286438,
            0.18275697529315948,
            1.631226658821106,
            6.8261237144470215,
            -3.407865047454834,
            1.4568511247634888,
            3.875674247741699,
            1.2144560813903809,
            2.9621472358703613,
            0.12825801968574524,
            -0.6381402015686035,
            -2.2458574771881104,
            2.394254207611084,
            -0.4194936156272888,
            1.484309196472168,
            -3.9086952209472656,
            1.4213398694992065,
            1.9288257360458374,
            3.7637953758239746,
            -0.09211021661758423,
            2.780266284942627,
            2.8511252403259277,
            -0.39976465702056885,
            1.3178117275238037,
            1.3604445457458496,
            -0.6647725105285645,
            1.2363910675048828,
            -1.7248680591583252,
            9.754656791687012,
            -1.7709487676620483,
            0.06000521779060364,
            -3.853538990020752,
            -1.800450086593628,
            -1.8773185014724731,
            -3.146470785140991,
            2.671095609664917,
            -2.7660794258117676,
            -0.9014299511909485,
            -1.0658111572265625,
            -2.7748608589172363,
            -1.2307274341583252,
            2.8941140174865723,
            -1.797767996788025,
            3.3417017459869385,
            1.69227135181427,
            2.3169288635253906,
            1.4703283309936523,
            -0.6895239353179932,
            -3.364025592803955,
            3.2658426761627197,
            0.2199667990207672,
            1.2020914554595947,
            -0.6059016585350037,
            1.9281243085861206,
            0.5100640654563904,
            -1.2584730386734009,
            -3.501056671142578,
            -6.786585807800293,
            -3.3477251529693604,
            -3.564405918121338,
            0.9954667091369629,
            -2.132229804992676,
            3.7917275428771973,
            -1.2836555242538452,
            4.059093475341797,
            1.3687044382095337,
            -2.6279757022857666,
            -0.8135197162628174,
            2.2897636890411377,
            1.2044398784637451,
            -1.6084413528442383,
            3.294448137283325,
            -2.7508537769317627,
            -5.722156524658203,
            -2.882581949234009,
            -1.5935720205307007,
            -1.362134337425232,
            -0.3265010714530945,
            0.7858633399009705,
            0.9584338665008545,
            2.5201542377471924,
            1.4033818244934082,
            -2.4735708236694336,
            2.7318668365478516,
            3.0400009155273438,
            2.409717559814453,
            1.656654953956604,
            2.3906362056732178,
            2.176422357559204,
            2.509622573852539,
            -3.73860239982605,
            0.46021899580955505,
            -0.956691563129425,
            3.449328660964966,
            -3.1963956356048584,
            -1.1737291812896729,
            -2.1682491302490234,
            3.011162281036377,
            1.4859508275985718,
            -1.6298775672912598,
            3.4007725715637207,
            -4.13468074798584,
            1.9540200233459473,
            5.900601863861084,
            -4.20335054397583,
            4.613405227661133,
            2.3116302490234375,
            1.3799302577972412,
            -1.6320301294326782,
            -0.8679561614990234,
            -3.396589756011963,
            -3.058093547821045,
            3.8762879371643066,
            -1.8837940692901611,
            -2.993391513824463,
            -2.365431785583496,
            0.45062151551246643,
            2.952141284942627,
            -2.7758238315582275,
            1.3743804693222046,
            3.1478214263916016,
            -3.58614444732666,
            -5.815410614013672,
            1.6264773607254028,
            2.3018553256988525,
            2.3664329051971436,
            0.9466812014579773,
            3.027920722961426,
            0.21137088537216187,
            -4.989619255065918,
            -0.5385533571243286,
            -1.841988205909729,
            2.9398961067199707,
            0.5769898891448975,
            -2.23970890045166,
            0.23875921964645386,
            -1.1004486083984375,
            -1.4925451278686523,
            1.707731008529663,
            -0.8462574481964111,
            0.5107923150062561,
            -3.4412074089050293,
            -1.198137640953064,
            -1.5416545867919922,
            3.22371244430542,
            -2.180912971496582,
            -0.6349728107452393,
            4.568977355957031,
            6.103116035461426,
            1.8981845378875732,
            4.603123664855957,
            4.786893844604492,
            -0.006066054105758667,
            0.9651018977165222,
            3.4079277515411377,
            0.9349349737167358,
            1.16768217086792,
            -1.2197638750076294,
            -5.903528213500977,
            1.696038007736206,
            1.2809040546417236,
            -3.302225112915039,
            0.6681986451148987,
            -4.542235851287842,
            -2.4225761890411377,
            1.8540596961975098,
            -1.2634505033493042,
            3.7217049598693848,
            5.371721267700195,
            -1.9258517026901245,
            -2.0126991271972656,
            -1.5843346118927002,
            2.1146507263183594,
            1.3253365755081177,
            -5.656413555145264,
            -1.4904601573944092,
            -2.2450942993164062,
            -2.069326639175415,
            5.847954273223877,
            -2.0637564659118652,
            -0.6607237458229065,
            1.3895314931869507,
            -1.869382619857788,
            1.3982516527175903,
            1.0572881698608398,
            3.076146125793457,
            3.067685604095459,
            -0.922612190246582,
            -5.55025053024292,
            2.466543197631836,
            2.23923659324646,
            3.7775816917419434,
            3.3417868614196777,
            2.2338671684265137,
            0.4167855381965637,
            -0.1322682946920395,
            -1.7822630405426025,
            -7.633382797241211,
            -0.6906644105911255,
            2.588057041168213,
            1.0557223558425903,
            -1.2714887857437134,
            -0.01683908700942993,
            -0.4312417507171631,
            3.696824312210083,
            6.88139533996582,
            -0.9590690732002258,
            3.363454818725586,
            -5.294949531555176,
            -2.5335965156555176,
            -2.5305066108703613,
            -0.7724383473396301,
            0.8240431547164917,
            -1.5659199953079224,
            1.417181134223938,
            -2.5348846912384033,
            -3.682525634765625,
            3.4333791732788086,
            -2.295039176940918,
            -5.7195963859558105,
            1.2990360260009766,
            3.598808765411377,
            1.8808934688568115,
            -5.363753318786621,
            -0.23000670969486237,
            4.379937171936035,
            -1.8439254760742188,
            0.4510350227355957,
            0.13994652032852173,
            2.2372889518737793,
            0.586227297782898,
            -2.326082706451416,
            -2.396437406539917,
            -4.7210822105407715,
            0.32024097442626953,
            0.18946728110313416,
            0.0550263375043869,
            3.5553712844848633,
            1.461605191230774,
            0.47601479291915894,
            -5.627529621124268,
            -2.4673705101013184,
            -1.6174070835113525,
            -2.362828493118286,
            -2.786017417907715,
            -4.482655048370361,
            1.5835254192352295,
            -2.024838924407959,
            -4.5790276527404785,
            2.8394930362701416,
            -3.2384986877441406,
            4.510092735290527,
            4.8627777099609375,
            -1.5166865587234497,
            0.7991625070571899,
            -4.280773162841797,
            -2.495114803314209,
            -4.1786298751831055,
            6.677382469177246,
            2.375235080718994,
            -0.6975172162055969,
            2.4175124168395996,
            2.6074304580688477,
            4.436020851135254,
            4.5032806396484375,
            3.36159348487854,
            -3.5145652294158936,
            1.6373950242996216,
            1.4199703931808472,
            -0.734992265701294,
            -3.6195359230041504,
            0.8623530864715576,
            -0.9926669597625732,
            4.217261791229248,
            16.70803451538086,
            -4.497831344604492,
            -0.3203594982624054,
            -1.0185835361480713,
            -3.5937857627868652,
            -3.3199596405029297,
            0.7594296932220459,
            -1.519500732421875,
            0.09329065680503845,
            1.8518729209899902,
            0.5806959271430969,
            -1.5740492343902588,
            1.2022852897644043,
            1.2657424211502075,
            -5.204977035522461,
            0.48444655537605286,
            -2.3630948066711426,
            4.321796894073486,
            -0.47316819429397583,
            0.05509817600250244,
            -0.5727432370185852,
            1.0159482955932617,
            -0.7163137197494507,
            -2.3189454078674316,
            -4.973203659057617,
            0.96329665184021,
            2.4200820922851562,
            0.23397649824619293,
            -4.2227582931518555,
            1.7742877006530762,
            -1.7675367593765259,
            -0.6779755353927612,
            2.9886178970336914,
            -2.7186577320098877,
            -2.7134602069854736,
            3.4400954246520996,
            4.802875995635986,
            -1.0754324197769165,
            0.5042427182197571,
            1.1758726835250854,
            -0.889950156211853,
            3.760817527770996,
            -5.511760711669922,
            1.6596887111663818,
            -3.8425989151000977,
            1.715984582901001,
            3.1170167922973633,
            -5.678382873535156,
            -2.8708138465881348,
            6.678414821624756,
            -0.3861691951751709,
            -0.0013494640588760376,
            0.18053095042705536,
            -0.1432325839996338,
            2.6649556159973145,
            2.4140784740448,
            -1.270002841949463,
            -1.8057136535644531,
            5.495911598205566,
            -0.252216637134552,
            -0.2570230960845947,
            0.20084059238433838,
            -4.878718852996826,
            -3.498729705810547,
            -0.20979547500610352,
            0.6733453273773193,
            -2.035020589828491,
            2.56360125541687,
            3.469066619873047,
            -1.135904312133789,
            2.1878714561462402,
            4.527524471282959,
            3.4870429039001465,
            0.6004310250282288,
            -3.013638973236084,
            -2.371306896209717,
            -0.8802799582481384,
            0.4098251461982727,
            2.349992513656616,
            6.711953163146973,
            -1.717617392539978,
            5.710392951965332,
            -2.723426103591919,
            -1.397747278213501,
            7.446239948272705,
            -2.5225987434387207,
            -0.31972092390060425,
            -1.3769145011901855,
            -1.6953926086425781,
            2.625293493270874,
            -0.08930590748786926,
            0.09158772230148315,
            0.8841310739517212,
            0.6592276096343994,
            4.347137928009033,
            -7.316722869873047,
            -1.504683494567871,
            -0.8748339414596558,
            -4.961623191833496,
            -0.4591241478919983,
            5.7438645362854,
            3.686574697494507,
            1.1635830402374268,
            -3.0169386863708496,
            -0.21690711379051208,
            -2.360041856765747,
            -1.3062822818756104,
            -4.796459674835205,
            -2.1424171924591064,
            -1.809793472290039,
            2.302999496459961,
            -2.620499610900879,
            3.411306619644165,
            -0.09301066398620605,
            0.9374970197677612,
            -0.695531964302063,
            0.7786442637443542,
            3.7658252716064453,
            -0.13787783682346344,
            1.836809515953064,
            0.8053457736968994,
            -0.3783515393733978,
            -4.661808013916016,
            -1.1720049381256104,
            1.1912951469421387,
            0.15917116403579712,
            -1.873600721359253,
            1.0991517305374146,
            -1.8736357688903809,
            -3.2123122215270996,
            0.04016425460577011,
            1.069501280784607,
            -1.612229585647583,
            4.670691013336182,
            -0.8486876487731934,
            0.3900037407875061,
            0.39243441820144653,
            1.267400860786438,
            -2.3450334072113037,
            4.98541259765625,
            4.207892894744873,
            -5.0932111740112305,
            0.024784564971923828,
            7.000797748565674,
            -1.5815825462341309,
            -1.7400113344192505,
            -2.2565011978149414,
            -4.154484748840332,
            -3.510636329650879,
            -0.6029114723205566,
            -0.6319503784179688,
            1.9810755252838135,
            5.082637786865234,
            1.0142756700515747,
            -4.372941493988037,
            -3.1488304138183594
        ]
    },
    "authors": [
        {
            "authorId": "2161655780",
            "name": "Yiwei Ma"
        },
        {
            "authorId": "2261358809",
            "name": "Zhibin Wang"
        },
        {
            "authorId": "2227806539",
            "name": "Xiaoshuai Sun"
        },
        {
            "authorId": "2312687039",
            "name": "Weihuang Lin"
        },
        {
            "authorId": "2266512639",
            "name": "Qiang Zhou"
        },
        {
            "authorId": "2258718943",
            "name": "Jiayi Ji"
        },
        {
            "authorId": "2232781359",
            "name": "Rongrong Ji"
        }
    ],
    "references": [
        {
            "paperId": "8cec34a36bf871f6a7a47e8ed0b419872dda7c34",
            "title": "MG-LLaVA: Towards Multi-Granularity Visual Instruction Tuning"
        },
        {
            "paperId": "3fd165604597714a788afbc88d6a8e5a76b742bb",
            "title": "Generative Visual Instruction Tuning"
        },
        {
            "paperId": "8c304d35f16295056a20bc8bf20a3c72f828827f",
            "title": "DeepStack: Deeply Stacking Visual Tokens is Surprisingly Simple and Effective for LMMs"
        },
        {
            "paperId": "14f139d035b818cfd16e1dc7665aef6b2ebc6741",
            "title": "ConvLLaVA: Hierarchical Backbones as Visual Encoder for Large Multimodal Models"
        },
        {
            "paperId": "c2f3d3e847faf3a8448eabb5bd5fdb6bebbc3a05",
            "title": "Hallucination of Multimodal Large Language Models: A Survey"
        },
        {
            "paperId": "01ae1c181dcb5117491affae728065e5e62bf074",
            "title": "InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD"
        },
        {
            "paperId": "b38845e9adbeeeab37519a2fc30e899411b4a36a",
            "title": "Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models"
        },
        {
            "paperId": "15ef0417570a190241caac0615eabdff11abb4de",
            "title": "mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding"
        },
        {
            "paperId": "b6648235f437c5be722db822f1f29a6a05984cd2",
            "title": "LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images"
        },
        {
            "paperId": "b14e5138d4d1f3577b2390541dc7b730a41bb651",
            "title": "DeepSeek-VL: Towards Real-World Vision-Language Understanding"
        },
        {
            "paperId": "c0b454e0a6aa51ff3ba56778787d0c43932ef6ba",
            "title": "Yi: Open Foundation Models by 01.AI"
        },
        {
            "paperId": "a379d387a48b079286bd0bf0264166a6cc254ef5",
            "title": "Feast Your Eyes: Mixture-of-Resolution Adaptation for Multimodal Large Language Models"
        },
        {
            "paperId": "14191e9f12913ad8c7ac6e1188682afac04aad09",
            "title": "AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling"
        },
        {
            "paperId": "f6b9ccd7533b58e14d284191f1a576b0c764b3d5",
            "title": "ALLaVA: Harnessing GPT4V-Synthesized Data for Lite Vision-Language Models"
        },
        {
            "paperId": "7260442ef9c0448f07ce3803efd49cebaffcebe9",
            "title": "DeepSeek LLM: Scaling Open-Source Language Models with Longtermism"
        },
        {
            "paperId": "ece33ee67d74c29cd2a83c505e5bf0b818f9c2a1",
            "title": "LLaVA-Phi: Efficient Multi-Modal Assistant with Small Language Model"
        },
        {
            "paperId": "6c64ddd2190909de2c680dd18abc9b92e80c39f9",
            "title": "Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision, Language, Audio, and Action"
        },
        {
            "paperId": "4b1b5e219fb41a7413599c3b2ca6a7fdf045d1a5",
            "title": "Generative Multimodal Models are In-Context Learners"
        },
        {
            "paperId": "d1f925c65d56ff4de5d317a54d47d6df34b17d4e",
            "title": "Hallucination Augmented Contrastive Learning for Multimodal Large Language Model"
        },
        {
            "paperId": "4f5654ec1dfc04478be42d03eee8e6db6bd9ca14",
            "title": "Honeybee: Locality-enhanced Projector for Multimodal LLM"
        },
        {
            "paperId": "b240a1d8ec2860bdd7370daa3144268ce46ac018",
            "title": "Vary: Scaling up the Vision Vocabulary for Large Vision-Language Models"
        },
        {
            "paperId": "fb064f8376eba221245c551cc028e4dbcb9f043e",
            "title": "Prompt Highlighter: Interactive Control for Multi-Modal LLMs"
        },
        {
            "paperId": "53c3c3984649ca82a2f85629dae01087e9e72991",
            "title": "OneLLM: One Framework to Align All Modalities with Language"
        },
        {
            "paperId": "ed4e20bcd73b1138d3bb2ed4dbbf5e8b224ef5c7",
            "title": "mPLUG-PaperOwl: Scientific Diagram Analysis with the Multimodal Large Language Model"
        },
        {
            "paperId": "b50d19c5c298f6562c3b3c6c3822a351bdc89260",
            "title": "MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI"
        },
        {
            "paperId": "cf193b5b34178a444cb9bd9f51beb4124b753935",
            "title": "HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction Data"
        },
        {
            "paperId": "f68f6f2a057c4e6e5a3c91fc8563533d9bf6e560",
            "title": "ShareGPT4V: Improving Large Multi-Modal Models with Better Captions"
        },
        {
            "paperId": "76a3f4a79ae9a00db2f2b5f6877021d8deb96ada",
            "title": "SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for Multi-modal Large Language Models"
        },
        {
            "paperId": "bf14244669d5505f63343d4365d99d24aa6c5e82",
            "title": "Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models"
        },
        {
            "paperId": "2f566575a246752d59438e2bde22f88680927af9",
            "title": "OtterHD: A High-Resolution Multi-modality Model"
        },
        {
            "paperId": "ad13b213681b6f634bc83a264df246e83dd9a9d9",
            "title": "mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration"
        },
        {
            "paperId": "2313afae52d98e569da2dedbf14daf9efc74e7cf",
            "title": "CogVLM: Visual Expert for Pretrained Language Models"
        },
        {
            "paperId": "6f632fd516d5adb07b85533cb696e2c1045fbaa4",
            "title": "AcFormer: An Aligned and Compact Transformer for Multimodal Sentiment Analysis"
        },
        {
            "paperId": "1ddbd08ad8cf22a5c66c4242194c4286328533bf",
            "title": "MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning"
        },
        {
            "paperId": "124d4d374fbef2016fa9880489871a58a7450644",
            "title": "Improved Baselines with Visual Instruction Tuning"
        },
        {
            "paperId": "696d6b667926a559e63989d45eec53c3a15986be",
            "title": "Pink: Unveiling the Power of Referential Comprehension for Multi-modal LLMs"
        },
        {
            "paperId": "092245d86b77181c36f972b1b7a17a59cd989c4a",
            "title": "Guiding Instruction-based Image Editing via Multimodal Large Language Models"
        },
        {
            "paperId": "f2f9c02a7eb484dd7b7ac46892856e3f278eed77",
            "title": "AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model"
        },
        {
            "paperId": "7b689adb8c156d6158660f90d1c86888ee281f63",
            "title": "DreamLLM: Synergistic Multimodal Comprehension and Creation"
        },
        {
            "paperId": "54c68b8623505dc6bf7a0b08aaa77ca9165f2d7f",
            "title": "ImageBind-LLM: Multi-modality Instruction Tuning"
        },
        {
            "paperId": "1a735015a1f7ef4f2ba2273ce5fcaaacfa9d1ea2",
            "title": "Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning"
        },
        {
            "paperId": "94972e30504017156ef5b5debc419bf6edc67384",
            "title": "MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities"
        },
        {
            "paperId": "7fbc502441d66daf1f53765d5d86a8dfba9ab0ce",
            "title": "OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models"
        },
        {
            "paperId": "4309d572a37d655779f9dce6a2c98c66334132de",
            "title": "SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension"
        },
        {
            "paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a",
            "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"
        },
        {
            "paperId": "b37b1dc72b1882858f5120f2cd6883134089a6ed",
            "title": "MMBench: Is Your Multi-modal Model an All-around Player?"
        },
        {
            "paperId": "e2a58fd18961c3941102989e3a3d0d27c615e015",
            "title": "Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic"
        },
        {
            "paperId": "948e8cfae92c2004f2dd5c9316f5972f8baaea21",
            "title": "OBELISC: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents"
        },
        {
            "paperId": "0d1c76d45afa012ded7ab741194baf142117c495",
            "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"
        },
        {
            "paperId": "6fb5c0eff3696ef252aca9638e10176ecce7cecb",
            "title": "Generating Images with Multimodal Language Models"
        },
        {
            "paperId": "c6ac708b65b24c20f80831d518c1795ce8133ad5",
            "title": "ChatBridge: Bridging Modalities with Large Language Model as a Language Catalyst"
        },
        {
            "paperId": "206400aba5f12f734cdd2e4ab48ef6014ea60773",
            "title": "Evaluating Object Hallucination in Large Vision-Language Models"
        },
        {
            "paperId": "8bd6a2a89503be083176f2cc26fabedb79238cbd",
            "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"
        },
        {
            "paperId": "ca6a2bc279be5a3349a22bfd6866ed633d18734b",
            "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"
        },
        {
            "paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8",
            "title": "Visual Instruction Tuning"
        },
        {
            "paperId": "5a9cb1b3dc4655218b3deeaf4a2417a9a8cd0891",
            "title": "DINOv2: Learning Robust Visual Features without Supervision"
        },
        {
            "paperId": "7470a1702c8c86e6f28d32cfa315381150102f5b",
            "title": "Segment Anything"
        },
        {
            "paperId": "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d",
            "title": "A Survey of Large Language Models"
        },
        {
            "paperId": "163b4d6a79a5b19af88b8585456363340d9efd04",
            "title": "GPT-4 Technical Report"
        },
        {
            "paperId": "57e849d0de13ed5f91d086936296721d4ff75a75",
            "title": "LLaMA: Open and Efficient Foundation Language Models"
        },
        {
            "paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb",
            "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"
        },
        {
            "paperId": "e5c8960eb2ec034ffbd353ef39fd1cb541d3c7c9",
            "title": "LAION-5B: An open large-scale dataset for training next generation image-text models"
        },
        {
            "paperId": "d3135733aa39dec20ce72aa138589dda27c8406d",
            "title": "Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering"
        },
        {
            "paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221",
            "title": "OPT: Open Pre-trained Transformer Language Models"
        },
        {
            "paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3",
            "title": "Flamingo: a Visual Language Model for Few-Shot Learning"
        },
        {
            "paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
            "title": "Training language models to follow instructions with human feedback"
        },
        {
            "paperId": "177e957f5cd93229c9794ea652c646d2557b4a69",
            "title": "A ConvNet for the 2020s"
        },
        {
            "paperId": "b668ce936cff0b0ca8b635cd5f25a62eaf4eb3df",
            "title": "LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs"
        },
        {
            "paperId": "69ff4686b6517a0f9ae59503fedd8ed6e7be9983",
            "title": "3DVG-Transformer: Relation Modeling for Visual Grounding on Point Clouds"
        },
        {
            "paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092",
            "title": "LoRA: Low-Rank Adaptation of Large Language Models"
        },
        {
            "paperId": "ad4a0938c48e61b7827869e4ac3baffd0aefab35",
            "title": "Emerging Properties in Self-Supervised Vision Transformers"
        },
        {
            "paperId": "805584d97f05aeb0b8eeee63c3ba0b1c55de9ed2",
            "title": "Document Collection Visual Question Answering"
        },
        {
            "paperId": "d5611a92619548e7f2af5adb04070574c0dacac1",
            "title": "InfographicVQA"
        },
        {
            "paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4",
            "title": "Learning Transferable Visual Models From Natural Language Supervision"
        },
        {
            "paperId": "ae7e5a4de962ca4face3bb52b36dfd09db5451d8",
            "title": "Dual-Level Collaborative Transformer for Image Captioning"
        },
        {
            "paperId": "d40c77c010c8dbef6142903a02f2a73a85012d5d",
            "title": "A Survey on Vision Transformer"
        },
        {
            "paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a",
            "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
        },
        {
            "paperId": "b40bfcf339de3f0dba08fabb2b58b9368ff4c51a",
            "title": "DocVQA: A Dataset for VQA on Document Images"
        },
        {
            "paperId": "7145cec8802299266fa485dbfa1324397daf8d47",
            "title": "HRDNet: High-Resolution Detection Network for Small Objects"
        },
        {
            "paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
            "title": "Language Models are Few-Shot Learners"
        },
        {
            "paperId": "1de68f12db136526116c6ac7064fd13965f2c966",
            "title": "A Survey of Convolutional Neural Networks: Analysis, Applications, and Prospects"
        },
        {
            "paperId": "33eadd4e666a894306a22ba0839c5e0cef77280e",
            "title": "TextCaps: a Dataset for Image Captioning with Reading Comprehension"
        },
        {
            "paperId": "fc9c52f55ffe0e860b1bb4222fe86cce60c05551",
            "title": "Meshed-Memory Transformer for Image Captioning"
        },
        {
            "paperId": "d08c7e556071e87eea263abe9393405501457ea4",
            "title": "Towards High-Resolution Salient Object Detection"
        },
        {
            "paperId": "28ad018c39d1578bea84e7cedf94459e3dbe1e70",
            "title": "OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge"
        },
        {
            "paperId": "cfc9ef5c7ef8056cff7bf1f1cfdd75e120f28231",
            "title": "MUREL: Multimodal Relational Reasoning for Visual Question Answering"
        },
        {
            "paperId": "a7ac99d7cf3f568ab1a741392144b646b856ae0c",
            "title": "GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering"
        },
        {
            "paperId": "0000fcfd467a19cf0e59169c2f07d730a0f3a8b9",
            "title": "Exploring Visual Relationship for Image Captioning"
        },
        {
            "paperId": "b4df354db88a70183a64dbc9e56cf14e7669a6c0",
            "title": "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"
        },
        {
            "paperId": "d2de5d94461d66e6b97e6825ae0fea3d6d925382",
            "title": "R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering"
        },
        {
            "paperId": "a7aa181fd7cadc7568d4fd87d2a1b12994ea1828",
            "title": "FLIPDIAL: A Generative Model for Two-Way Visual Dialogue"
        },
        {
            "paperId": "7289a240c9425bc7cad87b3b835e5f0cac22f488",
            "title": "DVQA: Understanding Data Visualizations via Question Answering"
        },
        {
            "paperId": "d07284a6811f1b2745d91bdb06b040b57f226882",
            "title": "Decoupled Weight Decay Regularization"
        },
        {
            "paperId": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "title": "Proximal Policy Optimization Algorithms"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "35fe3dd3350c32467030884337dde10d5e20ff99",
            "title": "ICNet for Real-Time Semantic Segmentation on High-Resolution Images"
        },
        {
            "paperId": "1b80416cc2b05954941ac7e7dcbcc358c10e5ace",
            "title": "Visual Dialog"
        },
        {
            "paperId": "de4ee92cfad3734ca820d004bc9ee75fc9dcfbf4",
            "title": "RefineNet: Multi-path Refinement Networks for High-Resolution Semantic Segmentation"
        },
        {
            "paperId": "e18ec2c9f0b4a817b8cf0435822bbc879d7db698",
            "title": "A Diagram is Worth a Dozen Images"
        },
        {
            "paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "title": "Deep Residual Learning for Image Recognition"
        },
        {
            "paperId": "1cf6bc0866226c1f8e282463adc8b75d92fba9bb",
            "title": "Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering"
        },
        {
            "paperId": "97ad70a9fa3f99adf18030e5e38ebe3d90daa2db",
            "title": "VQA: Visual Question Answering"
        },
        {
            "paperId": "5ddb51ae85deca14dc7fc8adc07305c22a1ebe0a",
            "title": "Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities"
        },
        {
            "paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": "9405cc0d6169988371b2755e573cc28650d14dfe",
            "title": "Language Models are Unsupervised Multitask Learners"
        },
        {
            "paperId": null,
            "title": "Stanford alpaca: An instruction-following llama model"
        },
        {
            "paperId": null,
            "title": "Introducing mpt-7b: A new standard for open-source,"
        },
        {
            "paperId": null,
            "title": "Introducing meta llama 3: The most capable openly available llm to date"
        },
        {
            "paperId": null,
            "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023"
        },
        {
            "paperId": null,
            "title": "Low-rank approximation for sparse attention in multi-modal llms"
        },
        {
            "paperId": null,
            "title": "Emu: Generative pretraining in multimodality"
        },
        {
            "paperId": null,
            "title": "Introducing chatgpt"
        }
    ]
}