{
    "paperId": "d048c9ad2fdf0a5155110271358e30cd24f53bda",
    "externalIds": {
        "ArXiv": "2409.03752",
        "CorpusId": 272423770
    },
    "title": "Attention Heads of Large Language Models: A Survey",
    "abstract": "Since the advent of ChatGPT, Large Language Models (LLMs) have excelled in various tasks but remain largely as black-box systems. Consequently, their development relies heavily on data-driven approaches, limiting performance enhancement through changes in internal architecture and reasoning pathways. As a result, many researchers have begun exploring the potential internal mechanisms of LLMs, aiming to identify the essence of their reasoning bottlenecks, with most studies focusing on attention heads. Our survey aims to shed light on the internal reasoning processes of LLMs by concentrating on the interpretability and underlying mechanisms of attention heads. We first distill the human thought process into a four-stage framework: Knowledge Recalling, In-Context Identification, Latent Reasoning, and Expression Preparation. Using this framework, we systematically review existing research to identify and categorize the functions of specific attention heads. Furthermore, we summarize the experimental methodologies used to discover these special heads, dividing them into two categories: Modeling-Free methods and Modeling-Required methods. Also, we outline relevant evaluation methods and benchmarks. Finally, we discuss the limitations of current research and propose several potential future directions. Our reference list is open-sourced at \\url{https://github.com/IAAR-Shanghai/Awesome-Attention-Heads}.",
    "venue": "",
    "year": 2024,
    "referenceCount": 93,
    "citationCount": 0,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This survey aims to shed light on the internal reasoning processes of LLMs by concentrating on the interpretability and underlying mechanisms of attention heads, and systematically review existing research to identify and categorize the functions of specific attention heads."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -3.8106119632720947,
            0.17806434631347656,
            -0.8103363513946533,
            4.001911163330078,
            2.0860118865966797,
            -0.766228973865509,
            2.2697207927703857,
            -0.613831639289856,
            -1.068524956703186,
            0.7536214590072632,
            -1.819361925125122,
            3.0883285999298096,
            0.674898624420166,
            0.45704805850982666,
            -4.547069072723389,
            1.5859304666519165,
            1.724949836730957,
            -1.0694595575332642,
            5.011094093322754,
            -0.9503617882728577,
            0.14995679259300232,
            1.5687435865402222,
            -0.36599159240722656,
            -4.374828338623047,
            -1.4888800382614136,
            -2.3451831340789795,
            4.728342533111572,
            1.4679864645004272,
            -4.071579933166504,
            5.783539295196533,
            -1.913478136062622,
            -4.241288185119629,
            2.30643892288208,
            -5.09920597076416,
            1.4989874362945557,
            -5.050497531890869,
            -3.892712116241455,
            6.964660167694092,
            -0.36298298835754395,
            -1.9428538084030151,
            -0.5463926792144775,
            0.022584974765777588,
            3.5775012969970703,
            1.240504264831543,
            0.07778745889663696,
            1.5672545433044434,
            -0.5903129577636719,
            0.2693939208984375,
            0.8311331272125244,
            2.246457815170288,
            2.945560932159424,
            -1.2761914730072021,
            1.0126826763153076,
            3.877458095550537,
            2.948200225830078,
            -0.7046363949775696,
            3.0007314682006836,
            1.3152519464492798,
            1.8080933094024658,
            -4.408382415771484,
            4.772349834442139,
            6.237597465515137,
            -0.362979531288147,
            1.2701308727264404,
            3.448026418685913,
            -2.7651150226593018,
            -6.0047078132629395,
            2.6751863956451416,
            2.2507100105285645,
            2.4858558177948,
            0.2943539619445801,
            -6.874322891235352,
            1.8191241025924683,
            2.985602855682373,
            -1.5446189641952515,
            0.2789606750011444,
            1.4379898309707642,
            -6.946101188659668,
            -1.7823283672332764,
            -0.9451416730880737,
            -0.03655022382736206,
            1.2164218425750732,
            3.524813652038574,
            4.238724708557129,
            3.246504068374634,
            -0.33301740884780884,
            -4.3435187339782715,
            3.177830696105957,
            2.6166625022888184,
            -4.440871715545654,
            -1.659366250038147,
            0.009873822331428528,
            1.30545973777771,
            0.9171348214149475,
            -1.9951612949371338,
            -0.3359333276748657,
            2.2792510986328125,
            -4.007023334503174,
            -2.618793249130249,
            0.46482911705970764,
            3.021841049194336,
            0.07072779536247253,
            1.9790406227111816,
            1.7147502899169922,
            4.480804443359375,
            -6.014664649963379,
            1.6897854804992676,
            0.30721038579940796,
            0.9316729307174683,
            0.11900007724761963,
            0.4269057512283325,
            3.086073875427246,
            -0.1173022985458374,
            -0.3473334312438965,
            0.9048838019371033,
            -3.4034371376037598,
            -4.21443510055542,
            0.36347496509552,
            -0.6986475586891174,
            6.797382354736328,
            -4.34976863861084,
            -3.106137990951538,
            -2.7264914512634277,
            -1.5504201650619507,
            2.9155092239379883,
            0.6328376531600952,
            -2.6786983013153076,
            0.0299643874168396,
            1.9649739265441895,
            -2.6128437519073486,
            3.992544412612915,
            3.449427843093872,
            4.636125087738037,
            -1.2214081287384033,
            2.484532594680786,
            4.89174222946167,
            -4.592099189758301,
            3.7379374504089355,
            2.5550696849823,
            0.032264381647109985,
            0.8104629516601562,
            5.711233139038086,
            0.37999120354652405,
            0.5625437498092651,
            -0.3042287528514862,
            2.3755712509155273,
            -0.005870997905731201,
            2.8177785873413086,
            0.5971883535385132,
            5.650271415710449,
            0.0831749439239502,
            -4.876964092254639,
            -0.4953917860984802,
            0.2826675772666931,
            -0.9416994452476501,
            3.0728375911712646,
            -3.147341728210449,
            1.5790762901306152,
            -3.553591728210449,
            0.5213191509246826,
            1.157226800918579,
            -1.059887170791626,
            -8.607446670532227,
            -1.4212478399276733,
            1.780065894126892,
            -6.62573766708374,
            -2.0545294284820557,
            2.853092670440674,
            -0.22172510623931885,
            1.9817661046981812,
            0.3012053668498993,
            0.7651894092559814,
            2.245896339416504,
            1.7256650924682617,
            1.9100761413574219,
            2.125582218170166,
            -1.3749995231628418,
            -3.2648284435272217,
            -2.349677324295044,
            0.08609804511070251,
            -3.030759811401367,
            0.6337637901306152,
            -7.754878044128418,
            0.8045097589492798,
            -2.36392879486084,
            -3.38392972946167,
            -1.4129843711853027,
            -4.442795753479004,
            2.008894205093384,
            -1.5783517360687256,
            -1.960770845413208,
            -1.5484647750854492,
            6.868904113769531,
            6.591229438781738,
            2.182906150817871,
            1.177053451538086,
            4.359134674072266,
            2.2257189750671387,
            -1.5891696214675903,
            0.4688286781311035,
            2.2590038776397705,
            0.09998100996017456,
            1.0987048149108887,
            -2.815675735473633,
            5.8673577308654785,
            1.765260934829712,
            -5.588481903076172,
            4.016631126403809,
            2.0907812118530273,
            -0.19067537784576416,
            3.6412909030914307,
            0.11530214548110962,
            -1.4214260578155518,
            3.3099164962768555,
            -3.010160446166992,
            0.05214512348175049,
            -6.1071391105651855,
            1.1471092700958252,
            2.6618738174438477,
            1.5434778928756714,
            -1.2426420450210571,
            -0.29611286520957947,
            3.3012611865997314,
            -3.1326401233673096,
            1.0903918743133545,
            -2.1949496269226074,
            1.016648769378662,
            -3.068277597427368,
            0.20611697435379028,
            -1.4947857856750488,
            -2.459991693496704,
            -1.558125615119934,
            0.2956010699272156,
            -0.4990474581718445,
            -6.563125133514404,
            0.9861850738525391,
            -6.165452003479004,
            2.4844913482666016,
            0.8778517246246338,
            -1.9045273065567017,
            0.2515155076980591,
            5.688108444213867,
            1.9950320720672607,
            2.5656538009643555,
            4.426684856414795,
            0.3834507167339325,
            -2.7617955207824707,
            2.343524694442749,
            0.7520179748535156,
            -1.1946444511413574,
            0.2931324243545532,
            -1.1326342821121216,
            2.2940292358398438,
            -0.9387601613998413,
            -0.7384763956069946,
            1.6715781688690186,
            -0.30693912506103516,
            -0.05689948797225952,
            -0.3248089849948883,
            2.841824531555176,
            1.4586663246154785,
            5.206869125366211,
            -0.7400752305984497,
            2.603574752807617,
            0.040992796421051025,
            -0.24555623531341553,
            -3.4597978591918945,
            0.5195837020874023,
            -3.495802879333496,
            5.401578903198242,
            1.4900624752044678,
            0.4105011224746704,
            1.7817683219909668,
            -3.7257091999053955,
            -2.11452054977417,
            -6.628280162811279,
            -1.4299310445785522,
            -3.5434188842773438,
            1.7698007822036743,
            0.2278589904308319,
            0.6521003246307373,
            -2.0654172897338867,
            0.03531527519226074,
            1.6601943969726562,
            0.5931645035743713,
            -0.8116893768310547,
            -2.764518976211548,
            -0.4449462294578552,
            -0.1288776397705078,
            -1.9953441619873047,
            0.21780672669410706,
            3.8595082759857178,
            0.2653615176677704,
            -2.492511749267578,
            0.13077419996261597,
            2.0312795639038086,
            4.208160400390625,
            -3.2111406326293945,
            1.6773900985717773,
            -2.2092080116271973,
            0.49676287174224854,
            4.353880882263184,
            1.5644679069519043,
            -0.30676281452178955,
            0.8124169111251831,
            3.922550916671753,
            -1.053564429283142,
            -0.10744774341583252,
            -1.2170199155807495,
            -5.4294633865356445,
            -2.3765454292297363,
            -1.8347365856170654,
            4.869241714477539,
            -4.635713577270508,
            -1.9334533214569092,
            0.513336181640625,
            2.6007862091064453,
            -1.5877193212509155,
            -1.7727477550506592,
            -0.2492462694644928,
            -1.5829814672470093,
            -1.8133087158203125,
            -4.95589542388916,
            -2.761711359024048,
            -5.174898147583008,
            1.1073176860809326,
            -1.2229764461517334,
            2.166274070739746,
            -5.06223201751709,
            1.5717060565948486,
            -0.7531302571296692,
            2.9331939220428467,
            2.778207778930664,
            1.537601113319397,
            -1.5474575757980347,
            -3.017904758453369,
            -2.0080525875091553,
            -1.193886399269104,
            1.9236024618148804,
            2.3547630310058594,
            -1.6279891729354858,
            4.467552185058594,
            -0.8095954060554504,
            0.46521687507629395,
            1.1150431632995605,
            2.081984758377075,
            -2.143937826156616,
            -0.9084100127220154,
            -1.7058433294296265,
            -3.2492880821228027,
            0.7309871315956116,
            2.0021867752075195,
            3.6487221717834473,
            -3.260885715484619,
            3.444485664367676,
            1.9373390674591064,
            0.7719411849975586,
            -0.18450748920440674,
            0.24290642142295837,
            0.3816559314727783,
            -2.6582412719726562,
            -1.5972458124160767,
            2.902963399887085,
            3.3210973739624023,
            -0.4135338068008423,
            -2.834427833557129,
            12.268802642822266,
            -1.2134840488433838,
            1.3554984331130981,
            -6.505558967590332,
            -3.713461399078369,
            -1.7771707773208618,
            -4.905815124511719,
            6.119348049163818,
            -3.6570515632629395,
            -1.4869036674499512,
            -2.0262889862060547,
            -4.876715183258057,
            1.7817567586898804,
            2.765756130218506,
            -2.3990159034729004,
            3.9276022911071777,
            -1.3871203660964966,
            1.9678014516830444,
            -1.2625353336334229,
            2.7970657348632812,
            -2.2198925018310547,
            2.790844440460205,
            -0.18014028668403625,
            0.8551733493804932,
            -2.347440481185913,
            -1.4722058773040771,
            1.2797081470489502,
            1.7441450357437134,
            -5.00022029876709,
            -1.502640962600708,
            -0.11602315306663513,
            -2.5810623168945312,
            1.8417015075683594,
            2.183168649673462,
            0.0017204880714416504,
            0.2497122585773468,
            3.0265755653381348,
            4.227530479431152,
            -2.324718713760376,
            0.19395583868026733,
            -0.36201101541519165,
            0.07324165105819702,
            -2.8135204315185547,
            2.326643466949463,
            -0.8466699123382568,
            -2.2886834144592285,
            0.8628517985343933,
            -3.494321346282959,
            -2.2821404933929443,
            0.5470287203788757,
            1.5128445625305176,
            0.9986449480056763,
            1.7147233486175537,
            0.06515219807624817,
            -4.263390064239502,
            1.5537450313568115,
            4.947824478149414,
            1.7714289426803589,
            1.402964472770691,
            0.5848702192306519,
            3.257593870162964,
            1.3493099212646484,
            -0.9645765423774719,
            2.952505350112915,
            -0.05489838123321533,
            2.597928762435913,
            -2.7341830730438232,
            -0.25461602210998535,
            0.4100196361541748,
            1.2797532081604004,
            2.3344130516052246,
            1.0743674039840698,
            0.8187199831008911,
            -5.330589294433594,
            1.8783040046691895,
            2.6075797080993652,
            -3.7533161640167236,
            5.419732093811035,
            -1.1551556587219238,
            0.10505756735801697,
            1.4167174100875854,
            0.9340233206748962,
            -1.4973541498184204,
            -0.6622041463851929,
            4.770454406738281,
            -3.1897084712982178,
            -2.397974967956543,
            -2.4078798294067383,
            0.0021191835403442383,
            0.15603125095367432,
            -3.370241403579712,
            0.6293500065803528,
            1.216123104095459,
            -0.9617258310317993,
            -2.842524528503418,
            3.729795455932617,
            -3.444333076477051,
            0.5030751824378967,
            1.499289631843567,
            -3.2546257972717285,
            -2.656259059906006,
            -4.072857856750488,
            -0.9752398133277893,
            4.352876663208008,
            4.501307487487793,
            0.4488482177257538,
            -4.159736156463623,
            1.7674176692962646,
            -0.12286573648452759,
            1.1038405895233154,
            1.5615227222442627,
            0.5090649724006653,
            0.9649516344070435,
            -0.727066159248352,
            -3.8641085624694824,
            -0.026098906993865967,
            6.1589202880859375,
            -1.3266655206680298,
            -1.5587201118469238,
            3.7932019233703613,
            0.7863393425941467,
            1.8281317949295044,
            0.9783927202224731,
            1.262826681137085,
            1.152363896369934,
            4.292049884796143,
            3.0641894340515137,
            -1.6451239585876465,
            -2.061572551727295,
            -0.7904419898986816,
            -4.059007167816162,
            0.403597354888916,
            2.3793225288391113,
            -0.07412725687026978,
            -1.5119390487670898,
            -5.375339984893799,
            -0.10988375544548035,
            -2.3512003421783447,
            -1.7212624549865723,
            6.547146320343018,
            2.651358127593994,
            1.5612962245941162,
            0.3461472988128662,
            0.38852405548095703,
            -1.657792329788208,
            1.5368342399597168,
            -5.257934093475342,
            2.2014098167419434,
            -1.1314953565597534,
            -1.736609697341919,
            4.816296577453613,
            -1.3113384246826172,
            -0.6778163909912109,
            1.201280951499939,
            -0.9940732717514038,
            -1.9580336809158325,
            -0.8702270984649658,
            3.2071099281311035,
            0.9470005035400391,
            -1.9215682744979858,
            -0.0760926604270935,
            -1.7587238550186157,
            0.8172093629837036,
            6.619407653808594,
            5.792847156524658,
            4.324683666229248,
            3.2600812911987305,
            -1.5061357021331787,
            -0.530484676361084,
            -2.5354807376861572,
            0.6640980243682861,
            2.416491985321045,
            -4.195615768432617,
            -0.22012388706207275,
            0.28658396005630493,
            -0.7545350790023804,
            -0.28164422512054443,
            6.08467435836792,
            3.380845546722412,
            4.485219478607178,
            -3.08349609375,
            -1.2194957733154297,
            -1.7361781597137451,
            -2.075634002685547,
            0.9603761434555054,
            -2.471560478210449,
            2.9665470123291016,
            1.6199122667312622,
            -2.7654380798339844,
            -1.4728641510009766,
            -1.0767154693603516,
            -1.158025860786438,
            -2.548628568649292,
            1.1563498973846436,
            4.945043087005615,
            -1.004157543182373,
            0.29842230677604675,
            4.5233869552612305,
            -2.5107903480529785,
            -2.087376356124878,
            -2.674675464630127,
            4.199027061462402,
            -1.1775981187820435,
            -1.2603890895843506,
            -0.19661211967468262,
            -3.696826934814453,
            1.8613059520721436,
            0.7214276790618896,
            -0.7484901547431946,
            2.7572827339172363,
            2.5071451663970947,
            2.6342859268188477,
            -2.3335745334625244,
            -2.15305757522583,
            0.49678921699523926,
            -0.05452432483434677,
            -0.13254065811634064,
            -3.679734230041504,
            1.1299372911453247,
            -1.6503669023513794,
            0.14595049619674683,
            1.9638584852218628,
            -4.253522872924805,
            1.0725913047790527,
            5.723837852478027,
            1.1825543642044067,
            1.2202363014221191,
            -2.5350301265716553,
            0.9632487893104553,
            -4.164344787597656,
            2.517975091934204,
            2.660667896270752,
            -2.8460240364074707,
            1.2983102798461914,
            -0.898260235786438,
            2.682863473892212,
            1.880814790725708,
            2.5507044792175293,
            -4.072807788848877,
            -2.7662112712860107,
            3.6611075401306152,
            0.44334128499031067,
            -3.4545416831970215,
            -0.3672999143600464,
            -0.1742146611213684,
            2.5635600090026855,
            16.631935119628906,
            -0.789297342300415,
            -1.373389720916748,
            1.4522240161895752,
            -2.167452812194824,
            -3.2280726432800293,
            -1.0253195762634277,
            -0.17618441581726074,
            -1.138129472732544,
            -0.7674321532249451,
            -2.9012527465820312,
            -1.8551363945007324,
            -2.521242618560791,
            1.6817618608474731,
            0.427419513463974,
            -2.4655890464782715,
            -2.141498565673828,
            0.5905062556266785,
            -3.8138186931610107,
            -1.6454548835754395,
            2.2902231216430664,
            3.115144729614258,
            -4.046048164367676,
            -3.49385142326355,
            0.517839789390564,
            0.7145227789878845,
            -0.12116469442844391,
            2.301384449005127,
            -6.338076114654541,
            1.296667218208313,
            2.439903497695923,
            1.663182258605957,
            0.8724043965339661,
            1.1066786050796509,
            0.07481780648231506,
            1.1520607471466064,
            1.2369401454925537,
            -4.334914207458496,
            3.1597464084625244,
            2.6222193241119385,
            -1.5598833560943604,
            3.439542531967163,
            -3.443878173828125,
            4.184632301330566,
            -1.0883150100708008,
            0.416640043258667,
            1.344153881072998,
            -1.925697684288025,
            -0.7137966156005859,
            4.702507019042969,
            -0.1819724440574646,
            -1.6386314630508423,
            -1.7894076108932495,
            0.26020050048828125,
            5.339467525482178,
            -0.7052129507064819,
            -1.4843270778656006,
            -5.037608623504639,
            0.14538359642028809,
            0.8497896194458008,
            3.5398099422454834,
            1.9106249809265137,
            -0.47475969791412354,
            -2.1812288761138916,
            -2.7409915924072266,
            -1.7771241664886475,
            -4.677333831787109,
            3.120021343231201,
            0.5076152682304382,
            -0.28919273614883423,
            5.1292290687561035,
            2.511350631713867,
            -1.6544296741485596,
            -3.1089048385620117,
            -0.7520335912704468,
            -3.0909929275512695,
            2.029409170150757,
            -2.8568058013916016,
            -0.252034455537796,
            6.569541931152344,
            -2.098928213119507,
            4.1962361335754395,
            -0.5681169629096985,
            0.29440391063690186,
            2.300785779953003,
            -1.2880098819732666,
            4.499563217163086,
            -1.6853588819503784,
            -3.486531972885132,
            3.1780529022216797,
            -2.639186382293701,
            1.7350356578826904,
            4.872272968292236,
            4.6054887771606445,
            1.8711702823638916,
            -3.0513291358947754,
            -0.36540845036506653,
            -3.8852338790893555,
            -2.636500120162964,
            -2.1958346366882324,
            3.6428842544555664,
            3.8767640590667725,
            0.8212287425994873,
            -3.910334587097168,
            0.034470684826374054,
            -1.519305944442749,
            -3.192941188812256,
            -7.570976734161377,
            -2.4151740074157715,
            -1.7383652925491333,
            5.220455169677734,
            -0.7415155172348022,
            1.8129948377609253,
            0.6032678484916687,
            1.976195216178894,
            -1.1446223258972168,
            2.677748680114746,
            2.011382579803467,
            -0.13807883858680725,
            3.880154609680176,
            0.2428622841835022,
            0.08520674705505371,
            -1.060577154159546,
            -4.070988655090332,
            -3.4296298027038574,
            -0.15557590126991272,
            -1.0172041654586792,
            -1.7855957746505737,
            -1.8306219577789307,
            -0.7783986330032349,
            1.6348925828933716,
            -2.399507522583008,
            0.558472216129303,
            -1.006656527519226,
            -0.3104664385318756,
            -0.958533525466919,
            3.012199878692627,
            0.5917918682098389,
            1.939394235610962,
            3.203227996826172,
            -0.28852760791778564,
            -1.3190910816192627,
            -2.614522933959961,
            9.936666488647461,
            -1.251784324645996,
            -1.496153473854065,
            -3.7116990089416504,
            1.2319536209106445,
            -2.240419387817383,
            -1.8085287809371948,
            3.077298164367676,
            0.4617030620574951,
            0.013153433799743652,
            0.9019261598587036,
            -3.6406171321868896,
            -2.3271842002868652
        ]
    },
    "authors": [
        {
            "authorId": "2214221817",
            "name": "Zifan Zheng"
        },
        {
            "authorId": "2299332188",
            "name": "Yezhaohui Wang"
        },
        {
            "authorId": "2266815897",
            "name": "Yuxin Huang"
        },
        {
            "authorId": "2268434524",
            "name": "Shichao Song"
        },
        {
            "authorId": "2268400606",
            "name": "Bo Tang"
        },
        {
            "authorId": "2268399953",
            "name": "Feiyu Xiong"
        },
        {
            "authorId": "2268429641",
            "name": "Zhiyu Li"
        }
    ],
    "references": [
        {
            "paperId": "7fbf028793a5252941e358366f57837888fcbf11",
            "title": "Controllable Text Generation for Large Language Models: A Survey"
        },
        {
            "paperId": "a7a63c50547f252d8fdbc9d6d593fc95cad7b5cf",
            "title": "Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment"
        },
        {
            "paperId": "fa0cbfba4e41b9f2487df251fcc3b93c21381167",
            "title": "Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability"
        },
        {
            "paperId": "d5f82199e97d325427dffdc027baca75578561f5",
            "title": "RazorAttention: Efficient KV Cache Compression Through Retrieval Heads"
        },
        {
            "paperId": "31048d9161dad19723b5c0733c7da0ea8b592e8f",
            "title": "Answer, Assemble, Ace: Understanding How Transformers Answer Multiple Choice Questions"
        },
        {
            "paperId": "3a588665fb59801fcbdce825ed7a4cf59984567f",
            "title": "Internal Consistency and Self-Feedback in Large Language Models: A Survey"
        },
        {
            "paperId": "d334a921861284a370d7aa97bd4a177baa294635",
            "title": "Look Within, Why LLMs Hallucinate: A Causal Perspective"
        },
        {
            "paperId": "8aa8f60fd63fc8cea29fe1722fc2bcdf5462d30d",
            "title": "Steering Large Language Models for Cross-lingual Information Retrieval"
        },
        {
            "paperId": "6d84377d5765229d621c4b2a209e44479ef33516",
            "title": "Induction Heads as an Essential Mechanism for Pattern Matching in In-context Learning"
        },
        {
            "paperId": "143a05fb36be8198d7675b594c0656b5652da3cb",
            "title": "Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps"
        },
        {
            "paperId": "952fb6413499bc377faa51bf71e4d558ac6f6387",
            "title": "MoA: Mixture of Sparse Attention for Automatic Large Language Model Compression"
        },
        {
            "paperId": "078e4ff3739a96365482483beca71fc505a7e7eb",
            "title": "Iteration Head: A Mechanistic Study of Chain-of-Thought"
        },
        {
            "paperId": "f1481b4eba72c1e1d355413af37352a0bcfc50e9",
            "title": "Knowledge Circuits in Pretrained Transformers"
        },
        {
            "paperId": "d04a7906161835440daaff90265dacca01ed3ba3",
            "title": "Linking In-context Learning in Transformers to Human Episodic Memory"
        },
        {
            "paperId": "e6c6836da35dcd93639e49095af1c3191a3b4ce0",
            "title": "xFinder: Robust and Pinpoint Answer Extraction for Large Language Models"
        },
        {
            "paperId": "015dd4ca002c14b83e0e53bce83b7eacea9f5a28",
            "title": "How does GPT-2 Predict Acronyms? Extracting and Understanding a Circuit via Mechanistic Interpretability"
        },
        {
            "paperId": "2d7d313c276d64b70f9839732ba5257c9e1a1110",
            "title": "Functional Equivalence with NARS"
        },
        {
            "paperId": "b51dbe60e8ee7cece43f8f8e3a54bfc123d1fb15",
            "title": "Defining intelligence: Bridging the gap between human and artificial perspectives"
        },
        {
            "paperId": "edd705ebe3546272b7fe952e2ed6088200adad76",
            "title": "Retrieval Head Mechanistically Explains Long-Context Factuality"
        },
        {
            "paperId": "a0b775b9ff82ce1fb7dd34d53a7d09f70b171895",
            "title": "How to use and interpret activation patching"
        },
        {
            "paperId": "63a87feede94433b44b2c2b194e5902c3c5158f2",
            "title": "What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation"
        },
        {
            "paperId": "9cf6d8ad63fd43658d4cdae58a78013852a759ff",
            "title": "Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models"
        },
        {
            "paperId": "4c0a545b1eb73084e3d395435af9cf6649c2b1da",
            "title": "Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and Mitigating Knowledge Conflicts in Language Models"
        },
        {
            "paperId": "1784cd42207a12bdc4061bb0f78bc8d5c82f61dd",
            "title": "Information Flow Routes: Automatically Interpreting Language Models at Scale"
        },
        {
            "paperId": "4b84736c87d9d927cc2b68a9fdc769f91dc56d71",
            "title": "Identifying Semantic Induction Heads to Understand In-Context Learning"
        },
        {
            "paperId": "36681edd6a32b1521844f2e3904587c8f5750d09",
            "title": "The Evolution of Statistical Induction Heads: In-Context Learning Markov Chains"
        },
        {
            "paperId": "ebfc54627cdd61a07c44667ab3a8ea77099fe59b",
            "title": "Summing Up the Facts: Additive Mechanisms Behind Factual Recall in LLMs"
        },
        {
            "paperId": "46955794ab197d56b40595fcb8e74b6948097075",
            "title": "How do Large Language Models Learn In-Context? Query and Key Matrices of In-Context Heads are Two Towers for Metric Learning"
        },
        {
            "paperId": "3f877562995d1408b0b3abd5dfbbe8eeecb6061e",
            "title": "From Understanding to Utilization: A Survey on Explainability for Large Language Models"
        },
        {
            "paperId": "07c2c3b4af7e4ff1577f36f47f1c93398a6df648",
            "title": "Successor Heads: Recurring, Interpretable Attention Heads In The Wild"
        },
        {
            "paperId": "b13947c7598aa91992cf04048afa19c7cfe69795",
            "title": "Function Vectors in Large Language Models"
        },
        {
            "paperId": "012dda8aef89ffa57128b15dc3cad2c02eedfa80",
            "title": "Linear Representations of Sentiment in Large Language Models"
        },
        {
            "paperId": "c0d9a48547d728dd320b453b01a0ab1ce2f96098",
            "title": "Circuit Component Reuse Across Tasks in Transformer Language Models"
        },
        {
            "paperId": "0eae83a76b2db97547d8ed42bb048c3eaaf78027",
            "title": "Copy Suppression: Comprehensively Understanding an Attention Head"
        },
        {
            "paperId": "c16c05ca0a3d24519405849fd24604fc1ce47751",
            "title": "Towards Best Practices of Activation Patching in Language Models: Metrics and Methods"
        },
        {
            "paperId": "965d15261b682fd3fd766311b99a11257322ac4c",
            "title": "Activation Addition: Steering Language Models Without Optimization"
        },
        {
            "paperId": "55c562c0de9d011c91965a34ba784c9d4b72fecb",
            "title": "Linearity of Relation Decoding in Transformer Language Models"
        },
        {
            "paperId": "77f02ff24909896856fec410968aef7999c29440",
            "title": "Does Circuit Analysis Interpretability Scale? Evidence from Multiple Choice Capabilities in Chinchilla"
        },
        {
            "paperId": "405f8f5f1c6df1b3343c812832479aad5180b65f",
            "title": "Inference-Time Intervention: Eliciting Truthful Answers from a Language Model"
        },
        {
            "paperId": "11ae58636a5daf0ea1297f1c4ee94042fcebefa8",
            "title": "Birth of a Transformer: A Memory Viewpoint"
        },
        {
            "paperId": "5dc15ac1c92ab7492f121471823fb13a95d273ba",
            "title": "A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis"
        },
        {
            "paperId": "7fa85f9c0fe44f1bf9e58a55f0f009296578c2f0",
            "title": "What In-Context Learning \"Learns\" In-Context: Disentangling Task Recognition and Task Learning"
        },
        {
            "paperId": "133b97e40017a9bbbadd10bcd7f13088a97ca3cc",
            "title": "Dissecting Recall of Factual Associations in Auto-Regressive Language Models"
        },
        {
            "paperId": "6edd112383ad494f5f2eba72b6f4ffae122ce61f",
            "title": "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small"
        },
        {
            "paperId": "c90a99eeb57019732a6cc996bb9eaf13faedf00f",
            "title": "In-context Learning and Induction Heads"
        },
        {
            "paperId": "2c709ef6186bd607494a3344c903552ea500e449",
            "title": "Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks"
        },
        {
            "paperId": "41b6cc4acedea461646ea85426f4f750a753a33b",
            "title": "A Survey on Attention Mechanisms for Medical Applications: are we Moving Toward Better Algorithms?"
        },
        {
            "paperId": "5a71bf38cf409b55b14b2d5159c0b06bef9ad603",
            "title": "A General Survey on Attention Mechanisms in Deep Learning"
        },
        {
            "paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5",
            "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"
        },
        {
            "paperId": "7211f8fca79962cc1d4f440524b0dad6481abdfb",
            "title": "Neural Attention Models in Deep Learning: Survey and Taxonomy"
        },
        {
            "paperId": "42fc019b2668c9d9d984154d4c57f6c6d5a91619",
            "title": "Language Models are Few-shot Multilingual Learners"
        },
        {
            "paperId": "77d956cdab4508d569ae5741549b78e715fd0749",
            "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods"
        },
        {
            "paperId": "76e9e2ec3de437ffb30d8b7b629f7fe3e61de5c2",
            "title": "On the Opportunities and Risks of Foundation Models"
        },
        {
            "paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4",
            "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"
        },
        {
            "paperId": "2c871df72c52b58f05447fcb3afc838168d94505",
            "title": "Knowledge Neurons in Pretrained Transformers"
        },
        {
            "paperId": "fdacf2a732f55befdc410ea927091cad3b791f13",
            "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"
        },
        {
            "paperId": "4a54d58a4b20e4f3af25cea3c188a12082a95e02",
            "title": "Transformer Feed-Forward Layers Are Key-Value Memories"
        },
        {
            "paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678",
            "title": "Measuring Massive Multitask Language Understanding"
        },
        {
            "paperId": "8d908042f139575d6688c745e94156c9df6eae07",
            "title": "Understanding the Difficulty of Training Transformers"
        },
        {
            "paperId": "a0cfd36e6c7abf070f492ae52a35af895a1c5592",
            "title": "Zoom In: An Introduction to Circuits"
        },
        {
            "paperId": "43f2ad297941db230c089ba353efc3f281ab678c",
            "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"
        },
        {
            "paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4",
            "title": "GLU Variants Improve Transformer"
        },
        {
            "paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a",
            "title": "On Layer Normalization in the Transformer Architecture"
        },
        {
            "paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2",
            "title": "Scaling Laws for Neural Language Models"
        },
        {
            "paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583",
            "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"
        },
        {
            "paperId": "a8427ce5aee6d62800c725588e89940ed4910e0d",
            "title": "An Attentive Survey of Attention Models"
        },
        {
            "paperId": "cb15c1c51e8a7da42d5b2ebac955bf1cd9dd4022",
            "title": "Text Generation from Knowledge Graphs with Graph Transformers"
        },
        {
            "paperId": "d7701e78e0bfc92b03a89582e80cfb751ac03f26",
            "title": "Explaining Explanations: An Overview of Interpretability of Machine Learning"
        },
        {
            "paperId": "a002e71561c90767240672f357b7d9e6d4d95186",
            "title": "Methods for interpreting and understanding deep neural networks"
        },
        {
            "paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need"
        },
        {
            "paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c",
            "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"
        },
        {
            "paperId": "51a55df1f023571a7e07e338ee45a3e3d66ef73e",
            "title": "Character-level Convolutional Networks for Text Classification"
        },
        {
            "paperId": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
        },
        {
            "paperId": "39a05307d03a528392be8f3c35c45265910579a5",
            "title": "Mental models"
        },
        {
            "paperId": "6a6fc284e6e83935e2ededb1b8501aa07a28cf2e",
            "title": "Models of word production"
        },
        {
            "paperId": "a3b7e80260891dcd3844b1835df8dee3a1cd67c7",
            "title": "The Number Sense: How the Mind Creates Mathematics."
        },
        {
            "paperId": "37b187e3df04fe7dd31293222407b4b86f3089fb",
            "title": "Attention!"
        },
        {
            "paperId": "69f6963992e7b82f6c58855af35d661e3fea6036",
            "title": "Memory and the hippocampus: a synthesis from findings with rats, monkeys, and humans."
        },
        {
            "paperId": "289d3a9562f57d0182d1aae9376b0e3793d80272",
            "title": "The role of knowledge in discourse comprehension: a construction-integration model."
        },
        {
            "paperId": "8c5448160c2640a9fa3b038ce7973ff9e0e35d91",
            "title": "Operant Conditioning"
        },
        {
            "paperId": "a6c4c667242f0ae280da5057fb2bf46f8f467d09",
            "title": "Enhancing Semantic Consistency of Large Language Models through Model Editing: An Interpretability-Oriented Approach"
        },
        {
            "paperId": "e661de406d8105e52a5351a2cd66db84cc4af115",
            "title": "Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods"
        },
        {
            "paperId": null,
            "title": "nostalgebraist"
        },
        {
            "paperId": null,
            "title": "A mathematical framework for transformer circuits"
        },
        {
            "paperId": "9405cc0d6169988371b2755e573cc28650d14dfe",
            "title": "Language Models are Unsupervised Multitask Learners"
        },
        {
            "paperId": null,
            "title": "The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery"
        },
        {
            "paperId": null,
            "title": "Aspects of the Theory of Syntax . Number 11"
        },
        {
            "paperId": "e73f84a26eec06083b473aa059a8a194ac9f361d",
            "title": "Machine Psychology : Autonomous Behavior , Perceptual Categorization and Conditioning in a Brain-based Device"
        },
        {
            "paperId": null,
            "title": "Semantic structures , volume 18"
        },
        {
            "paperId": "d792562462dbb687015954805d31620240db57a1",
            "title": "Episodic and semantic memory"
        },
        {
            "paperId": null,
            "title": "Nl-iti: Optimizing probing and intervention for improvement of iti method"
        },
        {
            "paperId": null,
            "title": "A comprehensive mechanistic interpretability explainer & glossary"
        },
        {
            "paperId": null,
            "title": "Llm test: Needle-in-a-haystack"
        }
    ]
}