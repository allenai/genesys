{
    "paperId": "b51d1946a6184946c93809d06942aa410c384203",
    "externalIds": {
        "ArXiv": "2409.02795",
        "CorpusId": 272397953
    },
    "title": "Towards a Unified View of Preference Learning for Large Language Models: A Survey",
    "abstract": "Large Language Models (LLMs) exhibit remarkably powerful capabilities. One of the crucial factors to achieve success is aligning the LLM's output with human preferences. This alignment process often requires only a small amount of data to efficiently enhance the LLM's performance. While effective, research in this area spans multiple domains, and the methods involved are relatively complex to understand. The relationships between different methods have been under-explored, limiting the development of the preference alignment. In light of this, we break down the existing popular alignment strategies into different components and provide a unified framework to study the current alignment strategies, thereby establishing connections among them. In this survey, we decompose all the strategies in preference learning into four components: model, data, feedback, and algorithm. This unified view offers an in-depth understanding of existing alignment algorithms and also opens up possibilities to synergize the strengths of different strategies. Furthermore, we present detailed working examples of prevalent existing algorithms to facilitate a comprehensive understanding for the readers. Finally, based on our unified perspective, we explore the challenges and future research directions for aligning large language models with human preferences.",
    "venue": "",
    "year": 2024,
    "referenceCount": 160,
    "citationCount": 0,
    "influentialCitationCount": 0,
    "openAccessPdf": null,
    "tldr": {
        "model": "tldr@v2.0.0",
        "text": "This survey decomposes all the strategies in preference learning into four components: model, data, feedback, and algorithm, which offers an in-depth understanding of existing alignment algorithms and opens up possibilities to synergize the strengths of different strategies."
    },
    "embedding": {
        "model": "specter_v1",
        "vector": [
            -2.9660916328430176,
            -2.7202138900756836,
            -2.8460893630981445,
            4.138896942138672,
            -0.17157505452632904,
            -0.9861184358596802,
            3.4603524208068848,
            -1.146077036857605,
            -2.1364829540252686,
            0.9148253202438354,
            -1.841842770576477,
            2.3335862159729004,
            -2.521005630493164,
            -0.39954566955566406,
            -3.3326735496520996,
            -1.641343355178833,
            2.7877774238586426,
            -4.4510955810546875,
            4.748404502868652,
            1.5246286392211914,
            -3.36655592918396,
            3.156276226043701,
            -3.607147693634033,
            -2.717432737350464,
            0.6200764775276184,
            -2.9313793182373047,
            3.995450973510742,
            1.83879816532135,
            -0.24422003328800201,
            -1.7487351894378662,
            -1.0464493036270142,
            -3.5086169242858887,
            5.744316101074219,
            -0.18483370542526245,
            -0.46019816398620605,
            -5.513988018035889,
            -1.2310991287231445,
            4.544419765472412,
            1.457237720489502,
            -1.767635703086853,
            0.1489659547805786,
            -0.1359635591506958,
            1.5614317655563354,
            0.19491535425186157,
            0.2619156837463379,
            1.6846438646316528,
            1.2102606296539307,
            0.7067574858665466,
            -0.9098557233810425,
            2.4675755500793457,
            2.212841033935547,
            -0.7481297254562378,
            0.8427485823631287,
            3.561704158782959,
            -0.13450299203395844,
            -1.1923633813858032,
            -0.13173642754554749,
            1.6079678535461426,
            3.549177408218384,
            -2.376915454864502,
            4.886744499206543,
            8.474916458129883,
            0.9806559681892395,
            0.8804548978805542,
            3.632990837097168,
            -2.019810676574707,
            -2.2112808227539062,
            3.48020339012146,
            0.8048789501190186,
            2.113346815109253,
            -0.40585973858833313,
            -6.855237007141113,
            0.5171977877616882,
            2.6368536949157715,
            -1.913069248199463,
            -0.16037477552890778,
            1.8564422130584717,
            -6.326511859893799,
            -1.9487866163253784,
            -0.5222345590591431,
            0.2544485330581665,
            -0.743786096572876,
            1.701373815536499,
            -0.3387908935546875,
            3.1984055042266846,
            0.5233715176582336,
            -4.217287063598633,
            3.6590988636016846,
            4.206097602844238,
            -5.731402397155762,
            -0.17195382714271545,
            1.0937716960906982,
            2.2941598892211914,
            2.1830496788024902,
            -3.332982063293457,
            -0.41200533509254456,
            1.4943956136703491,
            1.015977382659912,
            -0.8349569439888,
            -1.2297006845474243,
            3.6660590171813965,
            -2.680483341217041,
            0.9408888220787048,
            2.1334245204925537,
            2.670557975769043,
            -7.612419605255127,
            3.573359489440918,
            -0.3649011254310608,
            1.8398003578186035,
            -0.3640478253364563,
            2.1380367279052734,
            5.077132225036621,
            -1.6336565017700195,
            -3.233238458633423,
            -0.2056466042995453,
            -1.315551519393921,
            -1.5088876485824585,
            1.3486053943634033,
            -0.033531129360198975,
            6.598957061767578,
            -4.302957057952881,
            -4.270307540893555,
            -1.0946907997131348,
            2.6667213439941406,
            0.8214911818504333,
            4.3280439376831055,
            -2.226033926010132,
            -1.4125399589538574,
            -0.6926356554031372,
            -5.473662853240967,
            3.1964645385742188,
            -0.16138675808906555,
            6.361410140991211,
            -1.70931875705719,
            2.872013807296753,
            4.767346382141113,
            -3.8899059295654297,
            0.5811249017715454,
            0.16532903909683228,
            0.27858036756515503,
            0.4033399820327759,
            4.945865154266357,
            1.844074010848999,
            -0.684395968914032,
            -0.737134575843811,
            1.3313398361206055,
            0.769040584564209,
            2.0912437438964844,
            0.42202866077423096,
            4.759413719177246,
            3.5808091163635254,
            -2.388395309448242,
            -1.8277760744094849,
            1.9974287748336792,
            -1.2118680477142334,
            2.6409459114074707,
            -3.50773286819458,
            0.6727385520935059,
            -2.654269218444824,
            -0.15940597653388977,
            -2.2457761764526367,
            1.5173518657684326,
            -8.821556091308594,
            -3.1963086128234863,
            1.727503776550293,
            -5.571242809295654,
            -2.933439254760742,
            2.5494141578674316,
            -1.3186477422714233,
            0.39365261793136597,
            -0.49297118186950684,
            2.031548261642456,
            1.8801958560943604,
            2.145418643951416,
            -2.524954319000244,
            2.005707263946533,
            -2.1224799156188965,
            -3.4679837226867676,
            -0.007175147533416748,
            0.04318106174468994,
            -1.825141191482544,
            0.2153628170490265,
            -7.255161762237549,
            -1.7522276639938354,
            -3.284169912338257,
            -0.06921356916427612,
            -0.8583279848098755,
            -1.1527104377746582,
            -0.28883251547813416,
            -2.727334499359131,
            -3.8244833946228027,
            -0.5765153169631958,
            5.1118340492248535,
            5.295134544372559,
            3.635617256164551,
            2.136953830718994,
            2.4506468772888184,
            -0.547855019569397,
            -0.2163081169128418,
            4.52725887298584,
            2.5928103923797607,
            -0.48438096046447754,
            0.604964017868042,
            -0.5476659536361694,
            5.118097305297852,
            2.1072568893432617,
            -1.3866938352584839,
            2.858121871948242,
            -0.18193696439266205,
            -0.80450439453125,
            0.704979419708252,
            2.160231590270996,
            -0.06494113802909851,
            -0.2065945565700531,
            -4.552371978759766,
            1.686913013458252,
            -6.816266059875488,
            -1.5954606533050537,
            0.40928441286087036,
            2.629880905151367,
            -0.6243053674697876,
            0.5558758974075317,
            0.9234042167663574,
            -5.85654354095459,
            0.5335044860839844,
            -1.7126338481903076,
            1.212181806564331,
            2.1706879138946533,
            -1.3596450090408325,
            -1.6625392436981201,
            -4.035905838012695,
            -4.716779708862305,
            -3.5383894443511963,
            0.23721903562545776,
            -5.284183025360107,
            -1.2632124423980713,
            -7.425327777862549,
            3.468562602996826,
            -0.1726316511631012,
            0.02602449804544449,
            3.1684207916259766,
            3.2738492488861084,
            -0.3075276017189026,
            3.027677059173584,
            1.0487005710601807,
            1.3064857721328735,
            -2.904858112335205,
            0.9993767738342285,
            -3.132587194442749,
            -1.9473985433578491,
            -1.17192804813385,
            -0.640385627746582,
            0.6413164138793945,
            -2.0231637954711914,
            2.849309206008911,
            2.183262825012207,
            0.40057313442230225,
            1.7828614711761475,
            0.016365766525268555,
            -0.6905441880226135,
            1.8832166194915771,
            3.72174334526062,
            -1.3999314308166504,
            1.16892409324646,
            -0.14792442321777344,
            -0.6755498647689819,
            -2.7988829612731934,
            -0.46782809495925903,
            -3.284616470336914,
            3.7047247886657715,
            4.582688331604004,
            0.6003215312957764,
            2.3811445236206055,
            -7.923918724060059,
            -1.4572741985321045,
            -5.405796527862549,
            0.3082859516143799,
            -2.5018632411956787,
            2.294252634048462,
            -0.0769021064043045,
            1.2047343254089355,
            -0.6927892565727234,
            -0.8772087097167969,
            0.7143121957778931,
            1.288703203201294,
            -2.991452693939209,
            -3.2392773628234863,
            0.9260059595108032,
            0.1550617218017578,
            -2.9457507133483887,
            -0.4888308644294739,
            2.865480899810791,
            -0.5670312643051147,
            -1.2591614723205566,
            -0.973616898059845,
            3.728334426879883,
            4.162881851196289,
            -0.10671012103557587,
            -1.5413633584976196,
            -0.19818562269210815,
            0.5882159471511841,
            4.064453125,
            3.6163947582244873,
            -1.5023460388183594,
            2.609919786453247,
            3.878622055053711,
            0.20603016018867493,
            0.039010316133499146,
            1.1274688243865967,
            -0.8966077566146851,
            -0.6714348793029785,
            1.6654468774795532,
            3.814598321914673,
            -7.478320598602295,
            -2.772062301635742,
            1.7382049560546875,
            0.09042653441429138,
            -0.3544135093688965,
            -4.706643104553223,
            2.867868661880493,
            1.1001719236373901,
            -0.7591149210929871,
            -7.937602996826172,
            -1.8872711658477783,
            -2.043886661529541,
            2.899672031402588,
            -2.756709098815918,
            4.403143882751465,
            -6.59089994430542,
            1.2789416313171387,
            1.1782984733581543,
            6.265496253967285,
            2.401366710662842,
            0.8727918267250061,
            -1.7630102634429932,
            -3.987422466278076,
            -1.2213385105133057,
            -1.967895269393921,
            3.773270606994629,
            0.1718308925628662,
            1.484241008758545,
            4.579428195953369,
            -0.6937493681907654,
            -2.0380094051361084,
            -1.2401553392410278,
            0.6093206405639648,
            2.143066167831421,
            1.8701032400131226,
            -1.6309683322906494,
            -1.2058533430099487,
            2.976439952850342,
            2.271103620529175,
            3.955991744995117,
            -1.845479965209961,
            2.063769578933716,
            2.271074056625366,
            2.6337990760803223,
            -1.3750503063201904,
            -1.1537318229675293,
            -0.1089690625667572,
            -1.2345004081726074,
            0.7404977679252625,
            4.94508695602417,
            2.0197296142578125,
            0.5347304940223694,
            -1.6144676208496094,
            12.629560470581055,
            -3.548323631286621,
            4.744838714599609,
            -1.6774396896362305,
            -4.76745080947876,
            -1.408771276473999,
            -4.687007427215576,
            1.8357436656951904,
            -3.1841554641723633,
            -1.4249387979507446,
            -2.505000114440918,
            -2.5110034942626953,
            3.4666123390197754,
            2.455023765563965,
            -2.7458696365356445,
            1.750821590423584,
            -0.8881658911705017,
            0.9830167293548584,
            0.9385143518447876,
            2.2282519340515137,
            -1.8006742000579834,
            0.575039803981781,
            -3.148780345916748,
            3.792969226837158,
            0.0031838715076446533,
            0.8446692228317261,
            -1.6069289445877075,
            0.5158843994140625,
            -3.1024537086486816,
            -1.9981987476348877,
            1.0900077819824219,
            -2.3699069023132324,
            1.7827422618865967,
            0.5448600649833679,
            -1.3335710763931274,
            1.751466989517212,
            4.751551628112793,
            1.8881043195724487,
            -4.502665996551514,
            2.4665346145629883,
            1.5451035499572754,
            -0.6221892833709717,
            -0.34185463190078735,
            2.7354483604431152,
            -2.5792746543884277,
            -1.7022281885147095,
            -0.246541827917099,
            -3.709414482116699,
            1.944216251373291,
            -0.8040905594825745,
            2.111879587173462,
            3.0159354209899902,
            1.1331787109375,
            2.41990327835083,
            -0.2762855291366577,
            2.70064115524292,
            5.201605796813965,
            2.816237449645996,
            1.2251315116882324,
            0.48754024505615234,
            0.06895850598812103,
            -0.10466161370277405,
            -3.8697965145111084,
            4.275315284729004,
            0.5267202854156494,
            2.209947109222412,
            -2.5961365699768066,
            -0.2811790704727173,
            0.005130171775817871,
            2.547264814376831,
            2.446133852005005,
            2.954061985015869,
            2.3921194076538086,
            -2.4499099254608154,
            0.7806742191314697,
            0.3044663667678833,
            -3.551790237426758,
            1.328265905380249,
            3.519904136657715,
            3.6850028038024902,
            0.893762469291687,
            -3.2249698638916016,
            -1.6119515895843506,
            -1.83549964427948,
            4.907978057861328,
            -1.2469770908355713,
            -2.9471073150634766,
            -1.6063727140426636,
            -0.4623042941093445,
            0.18085235357284546,
            -2.3963518142700195,
            0.08880835771560669,
            -0.21954232454299927,
            -1.271608829498291,
            -2.432175874710083,
            0.2156897783279419,
            -0.338420569896698,
            1.7430883646011353,
            1.4613181352615356,
            -2.4151031970977783,
            -0.9098907709121704,
            -2.4813363552093506,
            -3.029106616973877,
            3.1338930130004883,
            2.154094696044922,
            -0.2633979320526123,
            -3.9690558910369873,
            1.2277041673660278,
            -2.1849236488342285,
            -0.9611620903015137,
            -0.0628734827041626,
            0.473254919052124,
            2.212043285369873,
            -5.262287139892578,
            -3.52541446685791,
            0.28516244888305664,
            4.76425313949585,
            -1.4596717357635498,
            -0.5402031540870667,
            5.790737152099609,
            1.3252894878387451,
            2.3985047340393066,
            1.7226390838623047,
            1.5776188373565674,
            1.2866332530975342,
            3.8409197330474854,
            4.270942687988281,
            1.421388864517212,
            -1.9790905714035034,
            -0.8345826268196106,
            -5.544609069824219,
            2.2049546241760254,
            0.8117145299911499,
            -1.53931725025177,
            0.8202333450317383,
            -7.455178260803223,
            0.0275191068649292,
            1.4871299266815186,
            -2.348184585571289,
            7.249171733856201,
            5.896880149841309,
            0.855351448059082,
            1.0733590126037598,
            0.8540681600570679,
            -0.09786668419837952,
            2.7864131927490234,
            -6.895615577697754,
            1.8198790550231934,
            -1.5347709655761719,
            -1.2016059160232544,
            6.546398162841797,
            -3.558295249938965,
            -1.0003283023834229,
            1.2356178760528564,
            -1.1125022172927856,
            -1.080337643623352,
            -1.6723439693450928,
            0.263195663690567,
            1.7176655530929565,
            -0.6607599258422852,
            -3.400099992752075,
            1.3995327949523926,
            2.8545632362365723,
            3.245299816131592,
            5.944094181060791,
            3.1049094200134277,
            3.2210021018981934,
            1.2810332775115967,
            2.4483067989349365,
            -4.0036420822143555,
            0.609021782875061,
            4.70077657699585,
            -1.9233100414276123,
            -3.9340648651123047,
            -0.6326091289520264,
            -2.790940284729004,
            2.668917179107666,
            5.329652786254883,
            0.7446862459182739,
            1.9563690423965454,
            -4.4015655517578125,
            -0.9272353053092957,
            -1.8036391735076904,
            0.0939452052116394,
            1.7309731245040894,
            -4.928152084350586,
            1.3707432746887207,
            3.288029670715332,
            -5.006768226623535,
            0.5327568650245667,
            0.2856399714946747,
            -4.125581741333008,
            -1.7086743116378784,
            0.5661766529083252,
            7.04849910736084,
            -3.8630006313323975,
            -1.927561640739441,
            1.8746953010559082,
            -1.6174890995025635,
            1.6533182859420776,
            -2.9784724712371826,
            3.85689640045166,
            1.799566626548767,
            -1.2788317203521729,
            -0.6016122102737427,
            -2.619321584701538,
            1.8282968997955322,
            -0.9400836229324341,
            -0.37643662095069885,
            3.2044239044189453,
            5.36140775680542,
            4.2743096351623535,
            -0.3203764855861664,
            -0.1616918444633484,
            -4.010580062866211,
            -0.9070665836334229,
            -2.430230140686035,
            -4.1071624755859375,
            0.7540270090103149,
            -0.8644541501998901,
            -1.3582746982574463,
            1.8428698778152466,
            -3.2080435752868652,
            -1.1775298118591309,
            6.349643230438232,
            -1.8151212930679321,
            1.3984965085983276,
            -1.3757822513580322,
            0.5655672550201416,
            -4.420947074890137,
            1.0316689014434814,
            2.319103240966797,
            -2.7798995971679688,
            2.36429762840271,
            2.736268997192383,
            2.736241579055786,
            0.15540677309036255,
            1.799086093902588,
            -2.0493998527526855,
            -1.492143154144287,
            3.27217435836792,
            -1.0123941898345947,
            -1.4314521551132202,
            -0.8759864568710327,
            -3.5078630447387695,
            1.790623426437378,
            17.215843200683594,
            -2.124729633331299,
            -0.9039030075073242,
            1.0889203548431396,
            -0.2915261387825012,
            -3.1556990146636963,
            -3.1761226654052734,
            1.6018359661102295,
            -1.4909064769744873,
            0.9675710797309875,
            -0.7823886275291443,
            -0.8717013001441956,
            -1.0588812828063965,
            1.1578954458236694,
            -2.787034034729004,
            -0.5858871936798096,
            -3.457425117492676,
            2.2742347717285156,
            -3.6971945762634277,
            -0.9964792728424072,
            1.6268301010131836,
            0.16898924112319946,
            0.17652910947799683,
            -3.2968578338623047,
            -1.641409158706665,
            3.044661283493042,
            3.8785228729248047,
            3.2317025661468506,
            -6.235206604003906,
            0.46754664182662964,
            0.6017150282859802,
            4.952807426452637,
            0.3675503730773926,
            0.709357738494873,
            1.9614171981811523,
            3.7326927185058594,
            0.6925901174545288,
            -2.866419553756714,
            2.525679588317871,
            2.130584716796875,
            -1.8641986846923828,
            0.6128332614898682,
            -3.1308560371398926,
            1.7987934350967407,
            -3.9506773948669434,
            -1.1823642253875732,
            1.3774824142456055,
            -2.71547794342041,
            -2.7605648040771484,
            2.4762940406799316,
            -1.5839626789093018,
            -3.572504997253418,
            -2.4302220344543457,
            0.6901648044586182,
            3.386141538619995,
            -3.0504024028778076,
            -0.5168402194976807,
            -3.0299570560455322,
            1.0747534036636353,
            3.2022907733917236,
            2.220280170440674,
            1.4374194145202637,
            1.6378211975097656,
            -4.788865089416504,
            -2.246826648712158,
            -0.6682264804840088,
            -2.0732107162475586,
            0.0919625461101532,
            2.4476895332336426,
            -1.3187774419784546,
            3.6647682189941406,
            1.205976963043213,
            -1.2911088466644287,
            -0.4434411823749542,
            -0.38897812366485596,
            -4.698858737945557,
            2.374631404876709,
            -1.2757837772369385,
            -1.5357868671417236,
            6.372809410095215,
            0.6257209777832031,
            3.8997936248779297,
            -3.4177632331848145,
            -1.7367658615112305,
            2.1011102199554443,
            -1.0346797704696655,
            3.514583110809326,
            -0.18248030543327332,
            -0.38366836309432983,
            1.201328992843628,
            -2.012190818786621,
            -0.462398886680603,
            3.1026477813720703,
            3.463505506515503,
            0.8454091548919678,
            -3.618868350982666,
            -2.434070110321045,
            -2.1510021686553955,
            -3.376046895980835,
            -1.5271966457366943,
            5.036060810089111,
            0.79280686378479,
            0.08344542980194092,
            -0.8743066191673279,
            0.6216477751731873,
            0.9582079648971558,
            -2.3605737686157227,
            -5.824768543243408,
            -2.2665352821350098,
            -1.2193573713302612,
            4.721813201904297,
            -2.2613792419433594,
            -0.2336599975824356,
            -0.5139285922050476,
            1.3215837478637695,
            -3.6510536670684814,
            2.1055445671081543,
            -0.4660290479660034,
            0.487515389919281,
            5.115673065185547,
            1.4790153503417969,
            0.5409722328186035,
            -0.14127680659294128,
            -1.2038871049880981,
            -1.6737570762634277,
            0.7565670013427734,
            -0.7852432131767273,
            -1.8711364269256592,
            -3.019474506378174,
            -0.8255494832992554,
            4.188973903656006,
            0.806523323059082,
            -1.5016560554504395,
            0.9375847578048706,
            3.7244882583618164,
            0.5755417943000793,
            0.9993826150894165,
            0.03153848648071289,
            -0.6927512288093567,
            5.492788791656494,
            0.4380658268928528,
            -3.672685146331787,
            -3.4912209510803223,
            10.457900047302246,
            -1.2656121253967285,
            -2.557215452194214,
            -1.3750174045562744,
            0.8395236730575562,
            -3.3260462284088135,
            1.6536600589752197,
            3.633385181427002,
            0.8663024306297302,
            -0.6874619722366333,
            0.8497871160507202,
            -2.649415969848633,
            -2.9673733711242676
        ]
    },
    "authors": [
        {
            "authorId": "2186406832",
            "name": "Bofei Gao"
        },
        {
            "authorId": "66947198",
            "name": "Feifan Song"
        },
        {
            "authorId": "2319604149",
            "name": "Yibo Miao"
        },
        {
            "authorId": "2117632647",
            "name": "Zefan Cai"
        },
        {
            "authorId": "2257389788",
            "name": "Zhe Yang"
        },
        {
            "authorId": "2319598019",
            "name": "Liang Chen"
        },
        {
            "authorId": "2266695201",
            "name": "Helan Hu"
        },
        {
            "authorId": null,
            "name": "Runxin Xu"
        },
        {
            "authorId": "2047143813",
            "name": "Qingxiu Dong"
        },
        {
            "authorId": "2113919886",
            "name": "Ce Zheng"
        },
        {
            "authorId": "2304627872",
            "name": "Wen Xiao"
        },
        {
            "authorId": "2319593518",
            "name": "Ge Zhang"
        },
        {
            "authorId": "2134434187",
            "name": "Daoguang Zan"
        },
        {
            "authorId": "2304717248",
            "name": "Keming Lu"
        },
        {
            "authorId": "2249451832",
            "name": "Bowen Yu"
        },
        {
            "authorId": "2248487202",
            "name": "Dayiheng Liu"
        },
        {
            "authorId": "2248072386",
            "name": "Zeyu Cui"
        },
        {
            "authorId": "2319616826",
            "name": "Jian Yang"
        },
        {
            "authorId": "39058310",
            "name": "Lei Sha"
        },
        {
            "authorId": "2284129758",
            "name": "Houfeng Wang"
        },
        {
            "authorId": "2287829088",
            "name": "Zhifang Sui"
        },
        {
            "authorId": "2284076735",
            "name": "Peiyi Wang"
        },
        {
            "authorId": "2311842337",
            "name": "Tianyu Liu"
        },
        {
            "authorId": "2261083637",
            "name": "Baobao Chang"
        }
    ],
    "references": [
        {
            "paperId": "ac9adab122210f022fcc64e133bd56f0028040e0",
            "title": "Generative Verifiers: Reward Modeling as Next-Token Prediction"
        },
        {
            "paperId": "e1a642026fb46a8b8a868862bcf0728e8d215d7e",
            "title": "DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search"
        },
        {
            "paperId": "4814f1744ebfbbf0e987ee4242a930dd2d3d09a5",
            "title": "Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers"
        },
        {
            "paperId": "df90ee11ed6378635f22e6d0061cf67dd0bacd13",
            "title": "Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge"
        },
        {
            "paperId": "54fb839f621e3fe787437ab8ca5f37e7e4726bfe",
            "title": "Qwen2 Technical Report"
        },
        {
            "paperId": "8deb5fd40e310dc4feb27f7db7019e734b44631b",
            "title": "LLM Critics Help Catch LLM Bugs"
        },
        {
            "paperId": "0c4bf8ba0a17f6066490664e83d28567dd089a40",
            "title": "LLM Critics Help Catch Bugs in Mathematics: Towards a Better Mathematical Verifier with Natural Language Feedback"
        },
        {
            "paperId": "a5f26555194d50955f6b3fdafb04d4330cb272dc",
            "title": "A Survey on Human Preference Learning for Large Language Models"
        },
        {
            "paperId": "394e14ae60bae4c41162056717d9e30a8168abaa",
            "title": "Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement"
        },
        {
            "paperId": "5387445a58a958422a8cfd297e6a611aade0f0e8",
            "title": "3D-Properties: Identifying Challenges in DPO and Charting a Path Forward"
        },
        {
            "paperId": "2c27967c92fda392cdf0654281df5a902bb62240",
            "title": "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B"
        },
        {
            "paperId": "8c752981471b0a4cf98b6950ae3919631988864b",
            "title": "ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search"
        },
        {
            "paperId": "f32bcc2155997110a7905da050df4c8404867b24",
            "title": "Improve Mathematical Reasoning in Language Models by Automated Process Supervision"
        },
        {
            "paperId": "f0dece803297c0f368142a33aaa3afdc7f3b42a4",
            "title": "Direct Alignment of Language Models via Quality-Aware Self-Refinement"
        },
        {
            "paperId": "49d25bf7d5f16da3f201f607d57411dd50bcf5f6",
            "title": "Group Robust Preference Optimization in Reward-free RLHF"
        },
        {
            "paperId": "200a19739ef76cb91c490be72d409f0fb0468901",
            "title": "TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models"
        },
        {
            "paperId": "097d5045ad87b3992dbdf1f30a964e5952fd474d",
            "title": "Hybrid Preference Optimization: Augmenting Direct Preference Optimization with Auxiliary Objectives"
        },
        {
            "paperId": "c3f1fae241a3c2449e675ab750873d800f95513c",
            "title": "SimPO: Simple Preference Optimization with a Reference-Free Reward"
        },
        {
            "paperId": "b53780b0dc66f11a6d77eb3daf4e3e2fdcfc8db6",
            "title": "Mallows-DPO: Fine-Tune Your LLM with Preference Dispersions"
        },
        {
            "paperId": "3648515cc35b517cdf60331cc4870e24616f9939",
            "title": "DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data"
        },
        {
            "paperId": "58bf4853effe89282eb8d8cd1e0dd1b782eee62f",
            "title": "LIRE: listwise reward enhancement for preference alignment"
        },
        {
            "paperId": "4490d077087df12e47c6f8d77a217179980c7516",
            "title": "Navigating LLM Ethics: Advancements, Challenges, and Future Directions"
        },
        {
            "paperId": "1e53e98e8709748a6385137d8f240787c12fcfd4",
            "title": "RLHF Workflow: From Reward Modeling to Online RLHF"
        },
        {
            "paperId": "df8c3a325419d63366b9b347739fcbf3e2c4d22c",
            "title": "Self-Play Preference Optimization for Language Model Alignment"
        },
        {
            "paperId": "38333f6e8f0388968edc4b2ea7a683ce69677e69",
            "title": "Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning"
        },
        {
            "paperId": "fa018aa098c28bd694b316ddf7e213641e7f86ad",
            "title": "Aligning LLM Agents by Learning Latent Preference from User Edits"
        },
        {
            "paperId": "db407c3a60c6dc768fde8dd1088dab3be951f04e",
            "title": "Insights into Alignment: Evaluating DPO and its Variants Across Multiple Tasks"
        },
        {
            "paperId": "315a5cb5dbbbe2be8468b2bb7c62ea72af8930da",
            "title": "Filtered Direct Preference Optimization"
        },
        {
            "paperId": "370fb62e60f80081015d591f8c10c5a59a56a32d",
            "title": "Learn Your Reference Model for Real Good Alignment"
        },
        {
            "paperId": "eb375712bd37250c350ecd3f559e1879e87eb3e5",
            "title": "Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators"
        },
        {
            "paperId": "39d976e2fb52c72fa43f1b52a3d23810e4f171e2",
            "title": "Towards Analyzing and Understanding the Limitations of DPO: A Theoretical Perspective"
        },
        {
            "paperId": "9216ec4ce85502e2d81beec89f54423af7810403",
            "title": "Prior Constraints-based Reward Model Training for Aligning Large Language Models"
        },
        {
            "paperId": "ed62e3847f45f152cf6d7b9b4bebb782547f1a54",
            "title": "Regularized Best-of-N Sampling to Mitigate Reward Hacking for Language Model Alignment"
        },
        {
            "paperId": "eabd317bf33a636b099a38f4b49aecca97202661",
            "title": "sDPO: Don't Use Your Data All at Once"
        },
        {
            "paperId": "c8c5db6eb1320967acc1dc91816d5ef0f3b5491b",
            "title": "Compiler generated feedback for Large Language Models"
        },
        {
            "paperId": "b3cdde45d87a3a90d86ebe20c1ee8c4ef0150d1c",
            "title": "Scaling Data Diversity for Fine-Tuning Language Models in Human Alignment"
        },
        {
            "paperId": "973814cd535facbf4f27c3de477b05bf19366030",
            "title": "ORPO: Monolithic Preference Optimization without Reference Model"
        },
        {
            "paperId": "0fce243964da0ec358152f226b21432e5a658917",
            "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context"
        },
        {
            "paperId": "66e7edf09589527ebb58418632418758cee668cd",
            "title": "On the Essence and Prospect: An Investigation of Alignment Approaches for Big Models"
        },
        {
            "paperId": "53f4fb0e9972989194368faf288ff8e3cba5bd60",
            "title": "Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference"
        },
        {
            "paperId": "6fe7e6ce3cc0ebd038caa456d73fd7472e7d6c38",
            "title": "Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment"
        },
        {
            "paperId": "8be81d531dfc4a1145474a1bb2f9c0cf15e19f45",
            "title": "Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration"
        },
        {
            "paperId": "07038b2d2da9f1785a1e8e260a75c8215bd36ac7",
            "title": "Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive"
        },
        {
            "paperId": "08436b3ddafd2edc798753ebc87f6ceffed6e8df",
            "title": "KnowTuning: Knowledge-aware Fine-tuning for Large Language Models"
        },
        {
            "paperId": "041ab8f72343db5d50769eeb725398c689b2850c",
            "title": "ICDPO: Effectively Borrowing Alignment Capability of Others via In-context Direct Preference Optimization"
        },
        {
            "paperId": "b46d05bcf42295b872f3cebf875643d2e66496a4",
            "title": "Direct Language Model Alignment from Online AI Feedback"
        },
        {
            "paperId": "35b142ea69598e6241f0011312128031df55895c",
            "title": "DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models"
        },
        {
            "paperId": "b899a28eb553800ce558cf8974a697f65103e591",
            "title": "DeAL: Decoding-time Alignment for Large Language Models"
        },
        {
            "paperId": "44162aa2763c88a384d9c51d60eafcc59277a1c9",
            "title": "Decoding-time Realignment of Language Models"
        },
        {
            "paperId": "c0d8e5ee66c279299012cc3b8d0519011b3f4998",
            "title": "KTO: Model Alignment as Prospect Theoretic Optimization"
        },
        {
            "paperId": "f977dac98cc603bfccae6ea991cf4b1f83bf139c",
            "title": "LiPO: Listwise Preference Optimization through Learning-to-Rank"
        },
        {
            "paperId": "08e84c939b88fc50aaa74ef76e202e61a1ad940b",
            "title": "StepCoder: Improve Code Generation with Reinforcement Learning from Compiler Feedback"
        },
        {
            "paperId": "65fb348291de709a379a3f0d00b48726a1a674d2",
            "title": "Improving Reinforcement Learning from Human Feedback with Efficient Reward Model Ensemble"
        },
        {
            "paperId": "a54dcfb673e1bbf5c709908160ca2fa70f2b4bb2",
            "title": "Recovering Mental Representations from Large Language Models with Markov Chain Monte Carlo"
        },
        {
            "paperId": "57781664a2066ca67df69ab2ae89ed4b54ea6534",
            "title": "West-of-N: Synthetic Preference Generation for Improved Reward Modeling"
        },
        {
            "paperId": "67f03ac399693393116076c0b8ec8ea05b910685",
            "title": "WARM: On the Benefits of Weight Averaged Reward Models"
        },
        {
            "paperId": "04d64be16fb402f28348faffef484bd419c8bd8f",
            "title": "Self-Rewarding Language Models"
        },
        {
            "paperId": "ebd1c04c61f73f46def3305ca11d038c46665b65",
            "title": "Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation"
        },
        {
            "paperId": "e360eb07461f2741793f99ece8b97a6c04fb2b68",
            "title": "MAPO: Advancing Multilingual Reasoning through Multilingual Alignment-as-Preference Optimization"
        },
        {
            "paperId": "7260442ef9c0448f07ce3803efd49cebaffcebe9",
            "title": "DeepSeek LLM: Scaling Open-Source Language Models with Longtermism"
        },
        {
            "paperId": "ef9e058d22d190fdd38ddee367cf6aa8d1a14bd5",
            "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models"
        },
        {
            "paperId": "cdd0e94e51a02bac22ca5e94fa95daa18f36e226",
            "title": "Uncertainty-Penalized Reinforcement Learning from Human Feedback with Diverse Reward LoRA Ensembles"
        },
        {
            "paperId": "66ea57809a718f2634e4f2065569c0ba24659d44",
            "title": "Align on the Fly: Adapting Chatbot Behavior to Established Norms"
        },
        {
            "paperId": "4ba57555bef02f988f2ed3bab2f102733dc55221",
            "title": "Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations"
        },
        {
            "paperId": "6b97aa78bcdb88548c44e7e1671c0ed37ed37976",
            "title": "Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision"
        },
        {
            "paperId": "600d9287efc4703bdb99ce39b5e8b37da0baa6f6",
            "title": "The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning"
        },
        {
            "paperId": "288e64e8adb23d81e291a2cb51e3a56b315023b7",
            "title": "OVM, Outcome-supervised Value Models for Planning in Mathematical Reasoning"
        },
        {
            "paperId": "e327ef8d46ea0413316c80ee1404453834d84f05",
            "title": "Black-Box Prompt Optimization: Aligning Large Language Models without Model Training"
        },
        {
            "paperId": "e5aed8e930b1efa1a5e0aad7ecf3038084cb0a33",
            "title": "Controlled Decoding from Language Models"
        },
        {
            "paperId": "9c0102443a1b5adc0c2235fab23a80bf8122ce72",
            "title": "CycleAlign: Iterative Distillation from Black-box LLM to White-box Models for Better Human Alignment"
        },
        {
            "paperId": "386cebdba39d2d5f2862a9ab43a8d807f3863dae",
            "title": "Contrastive Preference Learning: Learning from Human Feedback without RL"
        },
        {
            "paperId": "f3460dc3ae5cfd41099d576a3bb77411e1fc2e3f",
            "title": "A General Theoretical Paradigm to Understand Learning from Human Preferences"
        },
        {
            "paperId": "864a81b053d480b7db11ee1a1979f86554ccecba",
            "title": "Automated Evaluation of Personalized Text Generation using Large Language Models"
        },
        {
            "paperId": "d3f8d5a9c48ee9f338f25f1be5f3adc7fd5dd855",
            "title": "ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for Aligning Large Language Models"
        },
        {
            "paperId": "e5d0857feca845b474b89565d513ff599629851d",
            "title": "Reward-Augmented Decoding: Efficient Controlled Text Generation With a Unidirectional Reward Model"
        },
        {
            "paperId": "9ebf47129c15f61f4b77bbfe305c522480c20347",
            "title": "Prometheus: Inducing Fine-grained Evaluation Capability in Language Models"
        },
        {
            "paperId": "6f217d984f36499d88ab8a3d89572171552e6f3f",
            "title": "Evaluating Large Language Models at Evaluating Instruction Following"
        },
        {
            "paperId": "94a5f96308729e31c1ffbc0f0618db87795092fe",
            "title": "SWE-bench: Can Language Models Resolve Real-World GitHub Issues?"
        },
        {
            "paperId": "5001630bcc65e8e0e621b19625629a2689724743",
            "title": "Generative Judge for Evaluating Alignment"
        },
        {
            "paperId": "023d462ec6ff84cee0d0716a34d11efc7cde8534",
            "title": "Reward Model Ensembles Help Mitigate Overoptimization"
        },
        {
            "paperId": "e8df1cf6742b50a15500b8dd3dde3942e9c91418",
            "title": "Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training"
        },
        {
            "paperId": "860c8de4fdac38695ff6860dd15312f1079c6117",
            "title": "Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints"
        },
        {
            "paperId": "749d59f887c8ac83fd4f5178465e8b03e463358c",
            "title": "Large Language Model Alignment: A Survey"
        },
        {
            "paperId": "77b1f1c6d1658d120456b9046667cf009ceb39ce",
            "title": "MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models"
        },
        {
            "paperId": "b574245f3db22b5eb7fe64bd8b0a147dab467b60",
            "title": "RAIN: Your Language Models Can Align Themselves without Finetuning"
        },
        {
            "paperId": "22ab4219371366a4e890382bc0ca606130840ca7",
            "title": "Statistical Rejection Sampling Improves Preference Optimization"
        },
        {
            "paperId": "1ab91d6ac7afc1a0121487a9089fa70edc1634d4",
            "title": "Certifying LLM Safety against Adversarial Prompting"
        },
        {
            "paperId": "74b4b993babe99bc5f5c589c27fef0f1baba606b",
            "title": "Making Large Language Models Better Reasoners with Alignment"
        },
        {
            "paperId": "91206346edbe28abb606d7b3425cd455d4019d4f",
            "title": "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models"
        },
        {
            "paperId": "3705919b880f4f8dc37483a704e14dd078cb9ac4",
            "title": "Wider and Deeper LLM Networks are Fairer LLM Evaluators"
        },
        {
            "paperId": "e0ca43a635d35fd0414ee76ca1e7c287715f5b00",
            "title": "PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback"
        },
        {
            "paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a",
            "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"
        },
        {
            "paperId": "a669ea57529f4db630043c8c75d8f840c485d24d",
            "title": "RLTF: Reinforcement Learning from Unit Test Feedback"
        },
        {
            "paperId": "130d18d1d455336e1a5b06c85784894bb67d87ec",
            "title": "PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations"
        },
        {
            "paperId": "929305892d4ddae575a0fc23227a8139f7681632",
            "title": "Jailbroken: How Does LLM Safety Training Fail?"
        },
        {
            "paperId": "19db2d61f20a6c439cc79f28ef4c9e4bf26cd20e",
            "title": "Preference Ranking Optimization for Human Alignment"
        },
        {
            "paperId": "5efec343015f9329c5cd56e2259f68f03c2ef8b5",
            "title": "CMATH: Can Your Language Model Pass Chinese Elementary School Math Test?"
        },
        {
            "paperId": "bb9a44c94a89dbe00f0061d05c70a45064ff6ea6",
            "title": "CMMLU: Measuring massive multitask language understanding in Chinese"
        },
        {
            "paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787",
            "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"
        },
        {
            "paperId": "ccd94602e3acecf999d0c9ba62b1a8bc02e9f696",
            "title": "PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"
        },
        {
            "paperId": "993df7df129f8d18816877d69923d7df7b347d85",
            "title": "LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion"
        },
        {
            "paperId": "e2e52461194bc81351da7caa978ac42e9e9549cc",
            "title": "Fine-Grained Human Feedback Gives Better Rewards for Language Model Training"
        },
        {
            "paperId": "4d74a5048b884e8bb3842240abf98915c619c8f8",
            "title": "Multi-Dimensional Evaluation of Text Summarization with In-Context Learning"
        },
        {
            "paperId": "be8db99310602d66bba64bcf41a572c45816fbfc",
            "title": "Let's Verify Step by Step"
        },
        {
            "paperId": "38d64919ba526868a850a0e5f6239d4c474b7e7e",
            "title": "Large Language Models are not Fair Evaluators"
        },
        {
            "paperId": "0d1c76d45afa012ded7ab741194baf142117c495",
            "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"
        },
        {
            "paperId": "5d44f16a36ba7ae6b3d9d7c98bbc1b877e598f35",
            "title": "The False Promise of Imitating Proprietary LLMs"
        },
        {
            "paperId": "a122863d239643453195424c04067e89406246e1",
            "title": "Enhancing Chat Language Models by Scaling High-quality Instructional Conversations"
        },
        {
            "paperId": "cb6cc7d28d06a0d7c0d3f0d7ee551bbc86dbc3aa",
            "title": "AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback"
        },
        {
            "paperId": "58af2d4fcca54c14334d1efd975554b4eb78cd4d",
            "title": "SLiC-HF: Sequence Likelihood Calibration with Human Feedback"
        },
        {
            "paperId": "236c7dafea3df7ecffb5f18ec780d12f2f27d4b0",
            "title": "C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models"
        },
        {
            "paperId": "03055978e278960de9fbb5c648b1779ef9f26cd1",
            "title": "Can Large Language Models Be an Alternative to Human Evaluations?"
        },
        {
            "paperId": "3ab661db57d924f4ff1706e05ac807873ca00e0a",
            "title": "RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment"
        },
        {
            "paperId": "748698bd4387afd08594e0dc8150c2afa210d9ae",
            "title": "RRHF: Rank Responses to Align Language Models with Human Feedback without tears"
        },
        {
            "paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8",
            "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"
        },
        {
            "paperId": "381ab7a640f5b46b62f7e08d1af4a8e0d3eadd55",
            "title": "G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment"
        },
        {
            "paperId": "163b4d6a79a5b19af88b8585456363340d9efd04",
            "title": "GPT-4 Technical Report"
        },
        {
            "paperId": "4161ad2d2495d8af1d62dc5e71882bde642cd1c1",
            "title": "Large Language Models Are State-of-the-Art Evaluators of Translation Quality"
        },
        {
            "paperId": "57e849d0de13ed5f91d086936296721d4ff75a75",
            "title": "LLaMA: Open and Efficient Foundation Language Models"
        },
        {
            "paperId": "cb3125e4f63f3d058a2a39270ecb585e86c3d1ff",
            "title": "Chain of Hindsight Aligns Language Models with Feedback"
        },
        {
            "paperId": "6d7b8a478801bd9d21df82d5f33ae6eced90da5e",
            "title": "Solving math word problems with process- and outcome-based feedback"
        },
        {
            "paperId": "663a41c866d49ce052801fbc88947d39764cad29",
            "title": "Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them"
        },
        {
            "paperId": "891edceb78a274b0c2494d8176bc4d6f6e3f9cbc",
            "title": "Calibrating Sequence likelihood Improves Conditional Language Generation"
        },
        {
            "paperId": "0286b2736a114198b25fb5553c671c33aed5d477",
            "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback"
        },
        {
            "paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c",
            "title": "Training language models to follow instructions with human feedback"
        },
        {
            "paperId": "2f3efe44083af91cef562c1a3451eee2f8601d22",
            "title": "WebGPT: Browser-assisted question-answering with human feedback"
        },
        {
            "paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea",
            "title": "Training Verifiers to Solve Math Word Problems"
        },
        {
            "paperId": "39d05ffbc06fdca54ea6a90cd6d7fca202809aaa",
            "title": "Understanding Dataset Difficulty with V-Usable Information"
        },
        {
            "paperId": "a38e0f993e4805ba8a9beae4c275c91ffcec01df",
            "title": "Program Synthesis with Large Language Models"
        },
        {
            "paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269",
            "title": "Evaluating Large Language Models Trained on Code"
        },
        {
            "paperId": "b6c4a96e09b9f11e7c70e7f1fbe3f3971b92762d",
            "title": "FUDGE: Controlled Text Generation With Future Discriminators"
        },
        {
            "paperId": "49f905eb03958c7cfae52ac759ea8978b8b2a6ea",
            "title": "Alignment of Language Agents"
        },
        {
            "paperId": "346081161bdc8f18e2a4c4af7f51d35452b5cb01",
            "title": "Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies"
        },
        {
            "paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678",
            "title": "Measuring Massive Multitask Language Understanding"
        },
        {
            "paperId": "053b1d7b97eb2c91fc3921d589c160b0923c70b1",
            "title": "Learning to summarize from human feedback"
        },
        {
            "paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0",
            "title": "Natural Questions: A Benchmark for Question Answering Research"
        },
        {
            "paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1",
            "title": "The Curious Case of Neural Text Degeneration"
        },
        {
            "paperId": "e5a1d41e6212951cb6a831ed61a59d00b7ff6867",
            "title": "Complex Sequential Question Answering: Towards Learning to Converse Over Linked Question Answer Pairs with a Knowledge Graph"
        },
        {
            "paperId": "f5265e346382354887340c7b520d639162e2f598",
            "title": "TL;DR: Mining Reddit to Learn Automatic Summarization"
        },
        {
            "paperId": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "title": "Proximal Policy Optimization Algorithms"
        },
        {
            "paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c",
            "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"
        },
        {
            "paperId": "05dd7254b632376973f3a1b4d39485da17814df5",
            "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"
        },
        {
            "paperId": "7b4f3d0e4e2486a8d5d3f8e00549cf9a117bf88f",
            "title": "Sequence Transduction with Recurrent Neural Networks"
        },
        {
            "paperId": "e635d81a617d1239232a9c9a11a196c53dab8240",
            "title": "Bandit Based Monte-Carlo Planning"
        },
        {
            "paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008",
            "title": "ROUGE: A Package for Automatic Evaluation of Summaries"
        },
        {
            "paperId": "597ecf3cf9ce315f16dfa6fb7e9c456b6597a44c",
            "title": "NON-NULL RANKING MODELS. I"
        },
        {
            "paperId": "7d47ee5f84103529f84297c98c21dadb4742e3ff",
            "title": "RANK ANALYSIS OF INCOMPLETE BLOCK DESIGNS THE METHOD OF PAIRED COMPARISONS"
        },
        {
            "paperId": "5edcbf3ea678a7d9977555ecd59370452667597a",
            "title": "Towards Efficient and Exact Optimization of Language Model Alignment"
        },
        {
            "paperId": "4c8cc2383cec93bd9ea0758692f01b98a035215b",
            "title": "UltraFeedback: Boosting Language Models with High-quality Feedback"
        },
        {
            "paperId": "ac771182d1780c863954243809d1e144433919f9",
            "title": "Aligning Large Language Models with Human: A Survey"
        },
        {
            "paperId": null,
            "title": "AlpacaEval: An Automatic Evaluator of Instruction-following Models"
        },
        {
            "paperId": null,
            "title": "\u201cStar: Self-taught reasoner bootstrapping reasoning with reasoning\u201d"
        },
        {
            "paperId": "c4c0d6ffd70081d143b32be53b06fec1259b3ad8",
            "title": "The Lean 4 Theorem Prover and Programming Language"
        },
        {
            "paperId": "4c915c1eecb217c123a36dc6d3ce52d12c742614",
            "title": "Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning"
        },
        {
            "paperId": null,
            "title": "\u201cAligner: Achieving efficient alignment through weak-to-strong correction\u201d"
        },
        {
            "paperId": "0002c42e8d7bfeafc431c4ed9f6318f223bbf58b",
            "title": "Practices for Governing Agentic AI Systems"
        },
        {
            "paperId": null,
            "title": "\u201cBeyond one-preference-for-all: Multi-objective direct preference optimiza-tion\u201d"
        },
        {
            "paperId": null,
            "title": "\u201cMl-bench: Large language models leverage open-source libraries for machine learning tasks\u201d"
        },
        {
            "paperId": null,
            "title": "Open Hermes Preferences"
        },
        {
            "paperId": null,
            "title": "Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality"
        }
    ]
}