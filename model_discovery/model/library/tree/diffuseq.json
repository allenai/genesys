{
    "acronym": "diffuseq",
    "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models ",
    "seed_ids": [
        "classfreediffu",
        "diffusionlm",
        "d3pms",
        "transformer"
    ],
    "s2id": "69144d537f90f214d5b07a7c79121d16afd7da16",
    "abstract": "Recently, diffusion models have emerged as a new paradigm for generative models. Despite the success in domains using continuous signals such as vision and audio, adapting diffusion models to natural language is under-explored due to the discrete nature of texts, especially for conditional generation. We tackle this challenge by proposing DiffuSeq: a diffusion model designed for sequence-to-sequence (Seq2Seq) text generation tasks. Upon extensive evaluation over a wide range of Seq2Seq tasks, we find DiffuSeq achieving comparable or even better performance than six established baselines, including a state-of-the-art model that is based on pre-trained language models. Apart from quality, an intriguing property of DiffuSeq is its high diversity during generation, which is desired in many Seq2Seq tasks. We further include a theoretical analysis revealing the connection between DiffuSeq and autoregressive/non-autoregressive models. Bringing together theoretical analysis and empirical evidence, we demonstrate the great potential of diffusion models in complex conditional language generation tasks. Code is available at \\url{https://github.com/Shark-NLP/DiffuSeq}",
    "authors": [
        "Shansan Gong",
        "Mukai Li",
        "Jiangtao Feng",
        "Zhiyong Wu",
        "Lingpeng Kong"
    ],
    "venue": "International Conference on Learning Representations",
    "year": 2022,
    "tldr": "Upon extensive evaluation over a wide range of Seq2Seq tasks, DiffuSeq is found achieving comparable or even better performance than six established baselines, including a state-of-the-art model that is based on pre-trained language models.",
    "citationCount": 199,
    "influentialCitationCount": 40,
    "code": "\"\"\"\nThis code started out as a PyTorch port of Ho et al's diffusion models:\nhttps://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py\n\nDocstrings have been added, as well as DDIM sampling and a new collection of beta schedules.\n\"\"\"\n\nimport enum\nimport math\n\nimport numpy as np\nimport torch as th\nimport sys\nsys.path.append('.')\n\nimport torch.nn.functional as F\n\nfrom .utils.nn import mean_flat\nfrom .utils.losses import normal_kl, discretized_gaussian_log_likelihood\n\ndef get_named_beta_schedule(schedule_name, num_diffusion_timesteps):\n    \"\"\"\n    Get a pre-defined beta schedule for the given name.\n\n    The beta schedule library consists of beta schedules which remain similar\n    in the limit of num_diffusion_timesteps.\n    Beta schedules may be added, but should not be removed or changed once\n    they are committed to maintain backwards compatibility.\n    \"\"\"\n    if schedule_name == \"linear\":\n        # Linear schedule from Ho et al, extended to work for any number of\n        # diffusion steps.\n        scale = 1000 / num_diffusion_timesteps\n        beta_start = scale * 0.0001\n        beta_end = scale * 0.02\n        return np.linspace(\n            beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64\n        )\n    elif schedule_name == \"cosine\":\n        return betas_for_alpha_bar(\n            num_diffusion_timesteps,\n            lambda t: math.cos((t + 0.008) / 1.008 * math.pi / 2) ** 2,\n        )\n    elif schedule_name == 'sqrt':\n        return betas_for_alpha_bar(\n            num_diffusion_timesteps,\n            lambda t: 1-np.sqrt(t + 0.0001),\n        )\n    elif schedule_name == \"trunc_cos\":\n        return betas_for_alpha_bar_left(\n            num_diffusion_timesteps,\n            lambda t: np.cos((t + 0.1) / 1.1 * np.pi / 2) ** 2,\n        )\n    elif schedule_name == 'trunc_lin':\n        scale = 1000 / num_diffusion_timesteps\n        beta_start = scale * 0.0001 + 0.01\n        beta_end = scale * 0.02 + 0.01\n        return np.linspace(\n            beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64\n        )\n    elif schedule_name == 'pw_lin':\n        scale = 1000 / num_diffusion_timesteps\n        beta_start = scale * 0.0001 + 0.01\n        beta_mid = scale * 0.0001  #scale * 0.02\n        beta_end = scale * 0.02\n        first_part = np.linspace(\n            beta_start, beta_mid, 10, dtype=np.float64\n        )\n        second_part = np.linspace(\n            beta_mid, beta_end, num_diffusion_timesteps - 10 , dtype=np.float64\n        )\n        return np.concatenate(\n            [first_part, second_part]\n        )\n    else:\n        raise NotImplementedError(f\"unknown beta schedule: {schedule_name}\")\n\ndef betas_for_alpha_bar_left(num_diffusion_timesteps, alpha_bar, max_beta=0.999):\n    \"\"\"\n    Create a beta schedule that discretizes the given alpha_t_bar function, but shifts towards left interval starting from 0\n    which defines the cumulative product of (1-beta) over time from t = [0,1].\n\n    :param num_diffusion_timesteps: the number of betas to produce.\n    :param alpha_bar: a lambda that takes an argument t from 0 to 1 and\n                      produces the cumulative product of (1-beta) up to that\n                      part of the diffusion process.\n    :param max_beta: the maximum beta to use; use values lower than 1 to\n                     prevent singularities.\n    \"\"\"\n    betas = []\n    betas.append(min(1-alpha_bar(0), max_beta))\n    for i in range(num_diffusion_timesteps-1):\n        t1 = i / num_diffusion_timesteps\n        t2 = (i + 1) / num_diffusion_timesteps\n        betas.append(min(1 - alpha_bar(t2) / alpha_bar(t1), max_beta))\n    return np.array(betas)\n\ndef betas_for_alpha_bar(num_diffusion_timesteps, alpha_bar, max_beta=0.999):\n    \"\"\"\n    Create a beta schedule that discretizes the given alpha_t_bar function,\n    which defines the cumulative product of (1-beta) over time from t = [0,1].\n\n    :param num_diffusion_timesteps: the number of betas to produce.\n    :param alpha_bar: a lambda that takes an argument t from 0 to 1 and\n                      produces the cumulative product of (1-beta) up to that\n                      part of the diffusion process.\n    :param max_beta: the maximum beta to use; use values lower than 1 to\n                     prevent singularities.\n    \"\"\"\n    betas = []\n    for i in range(num_diffusion_timesteps):\n        t1 = i / num_diffusion_timesteps\n        t2 = (i + 1) / num_diffusion_timesteps\n        betas.append(min(1 - alpha_bar(t2) / alpha_bar(t1), max_beta))\n    return np.array(betas)\n\nclass GaussianDiffusion:\n    \"\"\"\n    Utilities for training and sampling diffusion models.\n\n    Ported directly from here, and then adapted over time to further experimentation.\n    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42\n\n    :param betas: a 1-D numpy array of betas for each diffusion timestep,\n                  starting at T and going to 1.\n    :param predict_xstart: the model outputs to predict x_0, else to predict eps.\n    :param learn_sigmas: the model outputs to predict sigma or not. Default: False\n    :param rescale_learned_sigmas, sigma_small: details setting of learned sigmas\n    :param rescale_timesteps: if True, pass floating point timesteps into the\n                              model so that they are always scaled like in the\n                              original paper (0 to 1000).\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        betas,\n        predict_xstart,\n        rescale_learned_sigmas,\n        learn_sigmas,\n        sigma_small,\n        use_kl,\n        rescale_timesteps=False,\n    ):\n        self.rescale_timesteps = rescale_timesteps\n        self.predict_xstart = predict_xstart\n        self.rescale_learned_sigmas = rescale_learned_sigmas\n        self.learn_sigmas = learn_sigmas\n        self.sigma_small = sigma_small\n        self.use_kl = use_kl\n\n        # Use float64 for accuracy.\n        betas = np.array(betas, dtype=np.float64)\n        self.betas = betas\n        assert len(betas.shape) == 1, \"betas must be 1-D\"\n        assert (betas > 0).all() and (betas <= 1).all()\n\n        self.num_timesteps = int(betas.shape[0])\n\n        alphas = 1.0 - betas\n        self.alphas_cumprod = np.cumprod(alphas, axis=0)\n        self.alphas_cumprod_prev = np.append(1.0, self.alphas_cumprod[:-1])\n        self.alphas_cumprod_next = np.append(self.alphas_cumprod[1:], 0.0)\n        assert self.alphas_cumprod_prev.shape == (self.num_timesteps,)\n\n        # calculations for diffusion q(x_t | x_{t-1}) and others\n        self.sqrt_alphas_cumprod = np.sqrt(self.alphas_cumprod)\n        self.sqrt_one_minus_alphas_cumprod = np.sqrt(1.0 - self.alphas_cumprod)\n        self.log_one_minus_alphas_cumprod = np.log(1.0 - self.alphas_cumprod)\n        self.sqrt_recip_alphas_cumprod = np.sqrt(1.0 / self.alphas_cumprod)\n        self.sqrt_recipm1_alphas_cumprod = np.sqrt(1.0 / self.alphas_cumprod - 1)\n\n        # calculations for posterior q(x_{t-1} | x_t, x_0)\n        self.posterior_variance = (\n            betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n        )\n        # log calculation clipped because the posterior variance is 0 at the\n        # beginning of the diffusion chain.\n        self.posterior_log_variance_clipped = np.log(\n            np.append(self.posterior_variance[1], self.posterior_variance[1:])\n        )\n        self.posterior_mean_coef1 = (\n            betas * np.sqrt(self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n        )\n        self.posterior_mean_coef2 = (\n            (1.0 - self.alphas_cumprod_prev)\n            * np.sqrt(alphas)\n            / (1.0 - self.alphas_cumprod)\n        )\n\n        self.mapping_func = None # implement in train main()\n        self.add_mask_noise = False # TODO\n\n    def training_losses(self, model, *args, **kwargs):\n        self.model = model\n        return self.training_losses_seq2seq(model, *args, **kwargs)\n\n    def _predict_xstart_from_eps(self, x_t, t, eps):\n        assert x_t.shape == eps.shape\n        return (\n            _extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t\n            - _extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * eps\n        )\n\n    def _predict_eps_from_xstart(self, x_t, t, pred_xstart):\n        return (\n            _extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t\n            - pred_xstart\n        ) / _extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape)\n\n    def _scale_timesteps(self, t):\n        if self.rescale_timesteps:\n            return t.float() * (1000.0 / self.num_timesteps)\n        return t\n\n    def q_mean_variance(self, x_start, t):\n        \"\"\"\n        Get the distribution q(x_t | x_0).\n\n        :param x_start: the [N x C x ...] tensor of noiseless inputs.\n        :param t: the number of diffusion steps (minus 1). Here, 0 means one step.\n        :return: A tuple (mean, variance, log_variance), all of x_start's shape.\n        \"\"\"\n        mean = (\n            _extract_into_tensor(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n        )\n        variance = _extract_into_tensor(1.0 - self.alphas_cumprod, t, x_start.shape)\n        log_variance = _extract_into_tensor(\n            self.log_one_minus_alphas_cumprod, t, x_start.shape\n        )\n        return mean, variance, log_variance\n\n    def q_sample(self, x_start, t, noise=None, mask=None):\n        \"\"\"\n        Diffuse the data for a given number of diffusion steps.\n\n        In other words, sample from q(x_t | x_0).\n\n        :param x_start: the initial data batch.\n        :param t: the number of diffusion steps (minus 1). Here, 0 means one step.\n        :param noise: if specified, the split-out normal noise.\n        :param mask: anchoring masked position\n        :return: A noisy version of x_start.\n        \"\"\"\n        if noise is None:\n            noise = th.randn_like(x_start)\n\n        assert noise.shape == x_start.shape\n        x_t = (\n            _extract_into_tensor(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n            + _extract_into_tensor(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape)\n            * noise\n        )\n\n        if mask == None:\n            return x_t\n        else:\n            mask = th.broadcast_to(mask.unsqueeze(dim=-1), x_start.shape)\n            return th.where(mask==0, x_start, x_t)\n\n    def q_posterior_mean_variance(self, x_start, x_t, t):\n        \"\"\"\n        Compute the mean and variance of the diffusion posterior: \n            q(x_{t-1} | x_t, x_0)\n\n        \"\"\"\n        assert x_start.shape == x_t.shape\n        posterior_mean = (\n            _extract_into_tensor(self.posterior_mean_coef1, t, x_t.shape) * x_start\n            + _extract_into_tensor(self.posterior_mean_coef2, t, x_t.shape) * x_t\n        )\n        posterior_variance = _extract_into_tensor(self.posterior_variance, t, x_t.shape)\n        posterior_log_variance_clipped = _extract_into_tensor(\n            self.posterior_log_variance_clipped, t, x_t.shape\n        )\n        assert (\n            posterior_mean.shape[0]\n            == posterior_variance.shape[0]\n            == posterior_log_variance_clipped.shape[0]\n            == x_start.shape[0]\n        )\n        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n\n    def p_mean_variance(\n        self, model, x, t, clip_denoised=True, denoised_fn=None, model_kwargs=None\n    ):\n        \"\"\"\n        Apply the model to get p(x_{t-1} | x_t), as well as a prediction of\n        the initial x, x_0.\n\n        :param model: the model, which takes a signal and a batch of timesteps\n                      as input.\n        :param x: the [N x C x ...] tensor at time t.\n        :param t: a 1-D Tensor of timesteps.\n        :param clip_denoised: if True, clip the denoised signal into [-1, 1].\n        :param denoised_fn: if not None, a function which applies to the\n            x_start prediction before it is used to sample. Applies before\n            clip_denoised.\n        :param model_kwargs: if not None, a dict of extra keyword arguments to\n            pass to the model. This can be used for conditioning.\n        :return: a dict with the following keys:\n                 - 'mean': the model mean output.\n                 - 'variance': the model variance output.\n                 - 'log_variance': the log of 'variance'.\n                 - 'pred_xstart': the prediction for x_0.\n        \"\"\"\n        if model_kwargs is None:\n            model_kwargs = {}\n\n        B, C = x.size(0), x.size(-1)\n        assert t.shape == (B,)\n        # print(x.shape)\n        model_output = model(x, self._scale_timesteps(t), **model_kwargs)\n        \n        # for fixedlarge, we set the initial (log-)variance like so\n        # to get a better decoder log likelihood.\n        model_variance = np.append(self.posterior_variance[1], self.betas[1:])\n        model_log_variance = np.log(np.append(self.posterior_variance[1], self.betas[1:]))\n        \n        model_variance = _extract_into_tensor(model_variance, t, x.shape)\n        model_log_variance = _extract_into_tensor(model_log_variance, t, x.shape)\n\n        def process_xstart(x):\n            if denoised_fn is not None:\n                # print(denoised_fn)\n                x = denoised_fn(x, t)\n            if clip_denoised:\n                return x.clamp(-1, 1)\n            return x\n\n        if self.predict_xstart:\n            pred_xstart = process_xstart(model_output)\n        else:\n            ### model is used to predict eps\n            pred_xstart = process_xstart(\n                self._predict_xstart_from_eps(x_t=x, t=t, eps=model_output)\n            )\n\n        model_mean, _, _ = self.q_posterior_mean_variance(\n            x_start=pred_xstart, x_t=x, t=t\n        )\n\n        assert (\n            model_mean.shape == model_log_variance.shape == pred_xstart.shape == x.shape\n        )\n        return {\n            \"mean\": model_mean,\n            \"variance\": model_variance,\n            \"log_variance\": model_log_variance,\n            \"pred_xstart\": pred_xstart,\n        }\n\n    def p_sample(\n        self, model, x, t, clip_denoised=True, denoised_fn=None, model_kwargs=None,\n            top_p=None, mask=None, x_start=None,\n    ):\n        \"\"\"\n        Sample x_{t-1} from the model at the given timestep.\n\n        :param model: the model to sample from.\n        :param x: the current tensor at x_{t-1}.\n        :param t: the value of t, starting at 0 for the first diffusion step.\n        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].\n        :param denoised_fn: if not None, a function which applies to the\n            x_start prediction before it is used to sample.\n        :param mask: anchoring masked position to x_start\n        :param model_kwargs: if not None, a dict of extra keyword arguments to\n            pass to the model. This can be used for conditioning.\n        :return: a dict containing the following keys:\n                 - 'sample': a random sample from the model.\n                 - 'pred_xstart': a prediction of x_0.\n        \"\"\"\n        out = self.p_mean_variance(\n            model,\n            x,\n            t,\n            clip_denoised=clip_denoised,\n            denoised_fn=denoised_fn,\n            model_kwargs=model_kwargs,\n        )\n        if top_p is not None and top_p > 0:\n            # print('top_p sampling')\n            noise = th.randn_like(x)\n            replace_mask = th.abs(noise) > top_p\n            while replace_mask.any():\n                noise[replace_mask] = th.randn_like(noise[replace_mask])\n                replace_mask = th.abs(noise) > top_p\n            assert (th.abs(noise) <= top_p).all()\n\n        else:\n            noise = th.randn_like(x)\n\n        nonzero_mask = (\n            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))\n        )  # no noise when t == 0\n        sample = out[\"mean\"] + nonzero_mask * th.exp(0.5 * out[\"log_variance\"]) * noise\n        if mask == None:\n            pass\n        else:\n            sample = th.where(mask==0, x_start, sample)\n\n        return {\n            \"sample\": sample, \n            \"pred_xstart\": out[\"pred_xstart\"],\n            \"greedy_mean\": out[\"mean\"], \n            \"out\": out\n        }\n\n    \n    def p_sample_loop(\n        self,\n        model,\n        shape,\n        noise=None,\n        clip_denoised=True,\n        denoised_fn=None,\n        model_kwargs=None,\n        device=None,\n        progress=False,\n        top_p=None,\n        clamp_step=None,\n        clamp_first=None,\n        mask=None,\n        x_start=None,\n        gap=1,\n    ):\n        \"\"\"\n        Generate samples from the model.\n\n        :param model: the model module.\n        :param shape: the shape of the samples, (N, C, H, W).\n        :param noise: if specified, the noise from the encoder to sample.\n                      Should be of the same shape as `shape`.\n        :param clip_denoised: if True, clip x_start predictions to [-1, 1].\n        :param denoised_fn: if not None, a function which applies to the\n            x_start prediction before it is used to sample.\n        :param mask: anchoring masked position to x_start\n        :param clamp_step: in clamp_first mode, choose end clamp step, otherwise starting clamp step\n        :param clamp_first: bool, clamp_first mode\n        :param model_kwargs: if not None, a dict of extra keyword arguments to\n            pass to the model. This can be used for conditioning.\n        :param device: if specified, the device to create the samples on.\n                       If not specified, use a model parameter's device.\n        :param progress: if True, show a tqdm progress bar.\n        :return: a non-differentiable batch of samples.\n        \"\"\"\n        final = []\n        for sample in self.p_sample_loop_progressive(\n            model,\n            shape,\n            noise=noise,\n            clip_denoised=clip_denoised,\n            denoised_fn=denoised_fn,\n            model_kwargs=model_kwargs,\n            device=device,\n            progress=progress,\n            top_p=top_p,\n            clamp_step=clamp_step,\n            clamp_first=clamp_first,\n            mask=mask,\n            x_start=x_start\n        ):\n            final.append(sample['sample'])\n        return final\n\n    def p_sample_loop_progressive(\n        self,\n        model,\n        shape,\n        noise=None,\n        clip_denoised=True,\n        denoised_fn=None,\n        model_kwargs=None,\n        device=None,\n        progress=False,\n        top_p=None,\n        clamp_step=None,\n        clamp_first=None,\n        mask=None,\n        x_start=None,\n    ):\n        \"\"\"\n        Generate samples from the model and yield intermediate samples from\n        each timestep of diffusion.\n\n        Arguments are the same as p_sample_loop().\n        Returns a generator over dicts, where each dict is the return value of\n        p_sample().\n        \"\"\"\n        if device is None:\n            device = next(model.parameters()).device\n        assert isinstance(shape, (tuple, list))\n        if noise is not None: # custom your the start point of x_0\n            sample_x = noise\n        else:\n            sample_x = th.randn(*shape, device=device)\n        indices = list(range(self.num_timesteps))[::-1]\n\n        if progress:\n            # Lazy import so that we don't depend on tqdm.\n            from tqdm.auto import tqdm\n            indices = tqdm(indices)\n\n        for i in indices: # from T to 0\n            t = th.tensor([i] * shape[0], device=device)\n            if not clamp_first:\n                if i > clamp_step:\n                    denoised_fn_cur = None\n                else:\n                    denoised_fn_cur = denoised_fn\n            else:\n                if i >= clamp_step:\n                    denoised_fn_cur = denoised_fn\n                else:\n                    denoised_fn_cur = None\n            with th.no_grad():\n                out = self.p_sample(\n                    model,\n                    sample_x,\n                    t,\n                    clip_denoised=clip_denoised,\n                    denoised_fn=denoised_fn_cur,\n                    model_kwargs=model_kwargs,\n                    top_p=top_p,\n                    mask=mask,\n                    x_start=x_start\n                )\n                yield out\n                sample_x = out[\"sample\"]\n\n\n    def _get_x_start(self, x_start_mean, std):\n        '''\n        Word embedding projection from {Emb(w)} to {x_0}\n        :param x_start_mean: word embedding\n        :return: x_0\n        '''\n        noise = th.randn_like(x_start_mean)\n        assert noise.shape == x_start_mean.shape\n        # print(x_start_mean.device, noise.device)\n        return (\n             x_start_mean + std * noise\n        )\n\n    def _token_discrete_loss(self, x_t, get_logits, input_ids, mask=None, truncate=False, t=None):\n        '''\n        the loss of -log p(w|z_0)\n        :param x_start_mean: word embedding\n        :return: x_0\n        '''\n        reshaped_x_t = x_t\n        logits = get_logits(reshaped_x_t)  # bsz, seqlen, vocab\n        # print(logits.shape)\n        loss_fct = th.nn.CrossEntropyLoss(reduction='none')\n        decoder_nll = loss_fct(logits.view(-1, logits.size(-1)), input_ids.view(-1)).view(input_ids.shape)\n        if mask != None:\n            decoder_nll *= mask\n        # print(decoder_nll.shape)\n        if mask != None:\n            decoder_nll = decoder_nll.sum(dim=-1)/mask.sum(dim=-1)\n        else:\n            decoder_nll = decoder_nll.mean(dim=-1)\n\n        return decoder_nll\n\n    def _x0_helper(self, model_output, x, t):\n\n        if self.predict_xstart:\n            pred_xstart = model_output\n            pred_prev, _, _ = self.q_posterior_mean_variance(\n                x_start=pred_xstart, x_t=x, t=t\n            )\n\n        else: # predict eps\n            pred_xstart = self._predict_xstart_from_eps(x_t=x, t=t, eps=model_output)\n        \n            pred_prev, _, _ = self.q_posterior_mean_variance(\n                x_start=pred_xstart, x_t=x, t=t\n            )\n\n        return {'pred_xprev':pred_prev, 'pred_xstart':pred_xstart}\n\n    def training_losses_seq2seq(self, model, x_start, t, model_kwargs=None, noise=None):\n        \"\"\"\n        Compute training losses for a single timestep.\n\n        :param model: the model to evaluate loss on.\n        :param x_start: the [N x C x ...] tensor of inputs. # not used unless fixing the input embeddings\n        :param t: a batch of timestep indices.\n        :param model_kwargs: if not None, a dict of extra keyword arguments to\n            pass to the model. This can be used for conditioning.\n        :param noise: if specified, the specific Gaussian noise to try to remove.\n        :return: a dict with the key \"loss\" containing a tensor of shape [N].\n                 Some mean or variance settings may also have other keys.\n        \"\"\"\n        x_start_fix = x_start # save the orignal x_0\n        assert 'input_ids' in model_kwargs\n        input_ids_x = model_kwargs.pop('input_ids').to(t.device)\n        input_ids_mask = model_kwargs.pop('input_mask').to(t.device)\n        x_start_mean = model.model.module.get_embeds(input_ids_x)\n        \n        std = _extract_into_tensor(self.sqrt_one_minus_alphas_cumprod,\n                                   th.tensor([0]).to(x_start_mean.device),\n                                   x_start_mean.shape)\n        # print(std.shape, )\n        # x_start_log_var = 2 * th.log(std)\n        x_start = self._get_x_start(x_start_mean, std)\n        # print(x_start_mean.shape, x_start.shape)\n        if noise is None:\n            noise = th.randn_like(x_start)\n\n        x_t = self.q_sample(x_start, t, noise=noise, mask=input_ids_mask) # reparametrization trick.\n\n        get_logits = model.model.module.get_logits\n\n        terms = {}\n\n        target = x_start\n        model_output = model(x_t, self._scale_timesteps(t), **model_kwargs)\n        assert model_output.shape == target.shape == x_start.shape\n        terms[\"mse\"] = mean_flat((target - model_output) ** 2)\n\n        model_out_x_start = self._x0_helper(model_output, x_t, t)['pred_xstart'] # predicted_xstart = model_output\n        t0_mask = (t == 0)\n        t0_loss = mean_flat((x_start_mean - model_out_x_start) ** 2)\n        terms[\"mse\"] = th.where(t0_mask, t0_loss, terms[\"mse\"])\n\n        # tT_mask = (t == self.num_timesteps - 1)\n        out_mean, _, _ = self.q_mean_variance(x_start, th.LongTensor([self.num_timesteps - 1]).to(x_start.device))\n        tT_loss =  mean_flat(out_mean ** 2)\n\n        decoder_nll = self._token_discrete_loss(x_start, get_logits, input_ids_x) # embedding regularization\n        terms[\"nll\"] = self._token_discrete_loss(model_out_x_start, get_logits, input_ids_x, mask=input_ids_mask, truncate=True, t=t) # x_0->model_out_x_start\n        # assert (model.lm_head.weight == model.word_embedding.weight).all()\n\n        terms[\"loss\"] = terms[\"mse\"] + decoder_nll + tT_loss\n\n        return terms\n\n    def ddim_sample(\n        self,\n        model,\n        x,\n        t,\n        clip_denoised=True,\n        denoised_fn=None,\n        model_kwargs=None,\n        eta=0.0,\n        langevin_fn=None,\n        mask=None,\n        x_start=None\n    ):\n        \"\"\"\n        Sample x_{t-1} from the model using DDIM.\n\n        Same usage as p_sample().\n        \"\"\"\n        out = self.p_mean_variance(\n            model,\n            x,\n            t,\n            clip_denoised=clip_denoised,\n            denoised_fn=denoised_fn,\n            model_kwargs=model_kwargs,\n        )\n        # Usually our model outputs epsilon, but we re-derive it\n        # in case we used x_start or x_prev prediction.\n        eps = self._predict_eps_from_xstart(x, t, out[\"pred_xstart\"])\n        alpha_bar = _extract_into_tensor(self.alphas_cumprod, t, x.shape)\n        alpha_bar_prev = _extract_into_tensor(self.alphas_cumprod_prev, t, x.shape)\n        sigma = (\n            eta\n            * th.sqrt((1 - alpha_bar_prev) / (1 - alpha_bar))\n            * th.sqrt(1 - alpha_bar / alpha_bar_prev)\n        )\n        # Equation 12.\n        noise = th.randn_like(x)\n        mean_pred = (\n            out[\"pred_xstart\"] * th.sqrt(alpha_bar_prev)\n            + th.sqrt(1 - alpha_bar_prev - sigma ** 2) * eps\n        )\n        nonzero_mask = (\n            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))\n        )  # no noise when t == 0\n        # print(sigma.mean())\n        sample = mean_pred + nonzero_mask * sigma * noise\n        if langevin_fn:\n            print(t.shape)\n            sample=langevin_fn(sample, mean_pred, sigma, self.alphas_cumprod_prev[t[0]], t, x)\n        \n        if mask == None:\n            pass\n        else:\n            sample = th.where(mask==0, x_start, sample)\n        \n        return {\"sample\": sample, \"pred_xstart\": out[\"pred_xstart\"]}\n\n    def ddim_reverse_sample(\n        self,\n        model,\n        x,\n        t,\n        clip_denoised=True,\n        denoised_fn=None,\n        model_kwargs=None,\n        eta=0.0,\n    ):\n        \"\"\"\n        Sample x_{t+1} from the model using DDIM reverse ODE.\n        \"\"\"\n        assert eta == 0.0, \"Reverse ODE only for deterministic path\"\n        out = self.p_mean_variance(\n            model,\n            x,\n            t,\n            clip_denoised=clip_denoised,\n            denoised_fn=denoised_fn,\n            model_kwargs=model_kwargs,\n        )\n        # Usually our model outputs epsilon, but we re-derive it\n        # in case we used x_start or x_prev prediction.\n        eps = (\n            _extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x.shape) * x\n            - out[\"pred_xstart\"]\n        ) / _extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x.shape)\n        alpha_bar_next = _extract_into_tensor(self.alphas_cumprod_next, t, x.shape)\n\n        # Equation 12. reversed\n        mean_pred = (\n            out[\"pred_xstart\"] * th.sqrt(alpha_bar_next)\n            + th.sqrt(1 - alpha_bar_next) * eps\n        )\n\n        return {\"sample\": mean_pred, \"pred_xstart\": out[\"pred_xstart\"]}\n\n    def ddim_sample_loop(\n        self,\n        model,\n        shape,\n        noise=None,\n        clip_denoised=True,\n        denoised_fn=None,\n        model_kwargs=None,\n        device=None,\n        progress=False,\n        top_p=None,\n        clamp_step=None,\n        clamp_first=None,\n        mask=None,\n        x_start=None,\n        gap=1,\n    ):\n        \"\"\"\n        Generate samples from the model using DDIM.\n        :param gap: compute ddim sampling for each {gap} step\n\n        Same usage as p_sample_loop().\n        \"\"\"\n        final = []\n        for sample in self.ddim_sample_loop_progressive(\n            model,\n            shape,\n            noise=noise,\n            clip_denoised=clip_denoised,\n            denoised_fn=denoised_fn,\n            model_kwargs=model_kwargs,\n            device=device,\n            progress=progress,\n            mask=mask,\n            x_start=x_start,\n            gap = gap\n        ):\n            final.append(sample['sample'])\n        return final\n\n    def ddim_sample_loop_progressive(\n        self,\n        model,\n        shape,\n        noise=None,\n        clip_denoised=True,\n        denoised_fn=None,\n        model_kwargs=None,\n        device=None,\n        progress=False,\n        eta=0.0,\n        langevin_fn=None,\n        mask=None,\n        x_start=None,\n        gap=1\n    ):\n        \"\"\"\n        Use DDIM to sample from the model and yield intermediate samples from\n        each timestep of DDIM.\n\n        Same usage as p_sample_loop_progressive().\n        \"\"\"\n        if device is None:\n            device = next(model.parameters()).device\n        assert isinstance(shape, (tuple, list))\n        if noise is not None:\n            sample_x = noise\n        else:\n            sample_x = th.randn(*shape, device=device)\n        indices = list(range(self.num_timesteps))[::-1][::gap]\n\n        if progress:\n            # Lazy import so that we don't depend on tqdm.\n            from tqdm.auto import tqdm\n\n            indices = tqdm(indices)\n\n        for i in indices:\n            t = th.tensor([i] * shape[0], device=device)\n            with th.no_grad():\n                out = self.ddim_sample(\n                    model,\n                    sample_x,\n                    t,\n                    clip_denoised=clip_denoised,\n                    denoised_fn=denoised_fn,\n                    model_kwargs=model_kwargs,\n                    mask=mask,\n                    x_start=x_start\n                )\n                yield out\n                sample_x = out[\"sample\"]\n\ndef _extract_into_tensor(arr, timesteps, broadcast_shape):\n    \"\"\"\n    Extract values from a 1-D numpy array for a batch of indices.\n\n    :param arr: the 1-D numpy array.\n    :param timesteps: a tensor of indices into the array to extract.\n    :param broadcast_shape: a larger shape of K dimensions with the batch\n                            dimension equal to the length of timesteps.\n    :return: a tensor of shape [batch_size, 1, ...] where the shape has K dims.\n    \"\"\"\n    res = th.from_numpy(arr).to(device=timesteps.device)[timesteps].float()\n    while len(res.shape) < len(broadcast_shape):\n        res = res[..., None]\n    return res.expand(broadcast_shape)\n\n\ndef space_timesteps(num_timesteps, section_counts):\n    \"\"\"\n    Create a list of timesteps to use from an original diffusion process,\n    given the number of timesteps we want to take from equally-sized portions\n    of the original process.\n\n    For example, if there's 300 timesteps and the section counts are [10,15,20]\n    then the first 100 timesteps are strided to be 10 timesteps, the second 100\n    are strided to be 15 timesteps, and the final 100 are strided to be 20.\n\n    If the stride is a string starting with \"ddim\", then the fixed striding\n    from the DDIM paper is used, and only one section is allowed.\n\n    :param num_timesteps: the number of diffusion steps in the original\n                          process to divide up.\n    :param section_counts: either a list of numbers, or a string containing\n                           comma-separated numbers, indicating the step count\n                           per section. As a special case, use \"ddimN\" where N\n                           is a number of steps to use the striding from the\n                           DDIM paper.\n    :return: a set of diffusion steps from the original process to use.\n    \"\"\"\n    if isinstance(section_counts, str):\n        if section_counts.startswith(\"ddim\"):\n            desired_count = int(section_counts[len(\"ddim\") :])\n            for i in range(1, num_timesteps):\n                if len(range(0, num_timesteps, i)) == desired_count:\n                    return set(range(0, num_timesteps, i))\n            raise ValueError(\n                f\"cannot create exactly {num_timesteps} steps with an integer stride\"\n            )\n        section_counts = [int(x) for x in section_counts.split(\",\")]\n    size_per = num_timesteps // len(section_counts)\n    extra = num_timesteps % len(section_counts)\n    start_idx = 0\n    all_steps = []\n    for i, section_count in enumerate(section_counts):\n        size = size_per + (1 if i < extra else 0)\n        if size < section_count:\n            raise ValueError(\n                f\"cannot divide section of {size} steps into {section_count}\"\n            )\n        if section_count <= 1:\n            frac_stride = 1\n        else:\n            frac_stride = (size - 1) / (section_count - 1)\n        cur_idx = 0.0\n        taken_steps = []\n        for _ in range(section_count):\n            taken_steps.append(start_idx + round(cur_idx))\n            cur_idx += frac_stride\n        all_steps += taken_steps\n        start_idx += size\n    return set(all_steps)\n\n\nclass SpacedDiffusion(GaussianDiffusion):\n    \"\"\"\n    A diffusion process which can skip steps in a base diffusion process.\n\n    :param use_timesteps: a collection (sequence or set) of timesteps from the\n                          original diffusion process to retain.\n    :param kwargs: the kwargs to create the base diffusion process.\n    \"\"\"\n\n    def __init__(self, use_timesteps, **kwargs):\n        self.use_timesteps = set(use_timesteps)\n        self.timestep_map = []\n        self.original_num_steps = len(kwargs[\"betas\"])\n\n        # print(kwargs.keys())\n        base_diffusion = GaussianDiffusion(**kwargs)  # pylint: disable=missing-kwoa\n        last_alpha_cumprod = 1.0\n        new_betas = []\n        for i, alpha_cumprod in enumerate(base_diffusion.alphas_cumprod):\n            if i in self.use_timesteps:\n                new_betas.append(1 - alpha_cumprod / last_alpha_cumprod)\n                last_alpha_cumprod = alpha_cumprod\n                self.timestep_map.append(i)\n        kwargs[\"betas\"] = np.array(new_betas)\n        super().__init__(**kwargs)\n\n    def p_mean_variance(\n        self, model, *args, **kwargs\n    ):  # pylint: disable=signature-differs\n        # print('called p_mean_var')\n        return super().p_mean_variance(self._wrap_model(model), *args, **kwargs)\n\n    def training_losses(\n        self, model, *args, **kwargs\n    ):  # pylint: disable=signature-differs\n        # print('called training_losses')\n        return super().training_losses(self._wrap_model(model), *args, **kwargs)\n\n    def _wrap_model(self, model):\n        if isinstance(model, _WrappedModel):\n            return model\n        return _WrappedModel(\n            model, self.timestep_map, self.rescale_timesteps, self.original_num_steps\n        )\n\n    def _scale_timesteps(self, t):\n        # Scaling is done by the wrapped model.\n        return t\n\n",
    "description": null,
    "url": null
}