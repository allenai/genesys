{
    "acronym": "sgconv",
    "title": "What Makes Convolutional Models Great on Long Sequence Modeling?",
    "seed_ids": [
        "s4d",
        "cosformer",
        "s4",
        "lssl",
        "rfa",
        "hippo",
        "bigbird",
        "linformer",
        "synthesizer",
        "reformer",
        "sparsetransformer",
        "transformer",
        "bert"
    ],
    "s2id": "240300b1da360f22bf0b82c6817eacebba6deed4",
    "abstract": "Convolutional models have been widely used in multiple domains. However, most existing models only use local convolution, making the model unable to handle long-range dependency efficiently. Attention overcomes this problem by aggregating global information but also makes the computational complexity quadratic to the sequence length. Recently, Gu et al. [2021] proposed a model called S4 inspired by the state space model. S4 can be efficiently implemented as a global convolutional model whose kernel size equals the input sequence length. S4 can model much longer sequences than Transformers and achieve significant gains over SoTA on several long-range tasks. Despite its empirical success, S4 is involved. It requires sophisticated parameterization and initialization schemes. As a result, S4 is less intuitive and hard to use. Here we aim to demystify S4 and extract basic principles that contribute to the success of S4 as a global convolutional model. We focus on the structure of the convolution kernel and identify two critical but intuitive principles enjoyed by S4 that are sufficient to make up an effective global convolutional model: 1) The parameterization of the convolutional kernel needs to be efficient in the sense that the number of parameters should scale sub-linearly with sequence length. 2) The kernel needs to satisfy a decaying structure that the weights for convolving with closer neighbors are larger than the more distant ones. Based on the two principles, we propose a simple yet effective convolutional model called Structured Global Convolution (SGConv). SGConv exhibits strong empirical performance over several tasks: 1) With faster speed, SGConv surpasses S4 on Long Range Arena and Speech Command datasets. 2) When plugging SGConv into standard language and vision models, it shows the potential to improve both efficiency and performance.",
    "authors": [
        "Yuhong Li",
        "Tianle Cai",
        "Yi Zhang",
        "De-huai Chen",
        "Debadeepta Dey"
    ],
    "venue": "International Conference on Learning Representations",
    "year": 2022,
    "tldr": "A simple yet effective convolutional model called Structured Global Convolution (SGConv), which exhibits strong empirical performance over several tasks and shows the potential to improve both efficiency and performance when plugging SGConv into standard language and vision models.",
    "citationCount": 69,
    "influentialCitationCount": 14,
    "code": "# Modified from S4: https://github.com/HazyResearch/state-spaces/blob/main/src/models/sequence/ss/s4.py\n# We will release the whole codebase upon acceptance.\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.utils as U\nfrom einops import rearrange, repeat\nfrom omegaconf import DictConfig\nimport opt_einsum as oe\nimport numpy as np\nfrom IPython import embed\n\noptimized = True\n\nif optimized:\n    contract = oe.contract\nelse:\n    contract = torch.einsum\n\nfrom src.models.nn import LinearActivation, Activation, Normalization\n\nclass GConv(nn.Module):\n    requires_length = True\n\n    def __init__(\n            self,\n            d_model,\n            d_state=64,\n            l_max=1, # Maximum length of sequence. Fine if not provided: the kernel will keep doubling in length until longer than sequence. However, this can be marginally slower if the true length is not a power of 2\n            channels=1, # maps 1-dim to C-dim\n            bidirectional=False,\n            # Arguments for FF\n            activation='gelu', # activation in between SS and FF\n            ln=False, # Extra normalization\n            postact=None, # activation after FF\n            initializer=None, # initializer on FF\n            weight_norm=False, # weight normalization on FF\n            hyper_act=None, # Use a \"hypernetwork\" multiplication\n            dropout=0.0,\n            transposed=True, # axis ordering (B, L, D) or (B, D, L)\n            verbose=False,\n            shift=False,\n            linear=False,\n            mode=\"cat_randn\",\n            # SSM Kernel arguments\n            **kernel_args,\n        ):\n        \"\"\"\n        d_state: the dimension of the state, also denoted by N\n        l_max: the maximum sequence length, also denoted by L\n          if this is not known at model creation, set l_max=1\n        channels: can be interpreted as a number of \"heads\"\n        bidirectional: bidirectional\n        dropout: standard dropout argument\n        transposed: choose backbone axis ordering of (B, L, H) or (B, H, L) [B=batch size, L=sequence length, H=hidden dimension]\n\n        Other options are all experimental and should not need to be configured\n        \"\"\"\n\n        super().__init__()\n        if verbose:\n            import src.utils.train\n            log = src.utils.train.get_logger(__name__)\n            log.info(f\"Constructing S4 (H, N, L) = ({d_model}, {d_state}, {l_max})\")\n\n        self.h = d_model\n        self.n = d_state\n        self.bidirectional = bidirectional\n        self.ln = ln\n        self.channels = channels\n        self.transposed = transposed\n        self.shift = shift\n        self.linear = linear\n        self.mode = mode\n        self.l_max = l_max\n\n        # optional multiplicative modulation GLU-style\n        # https://arxiv.org/abs/2002.05202\n        self.hyper = hyper_act is not None\n        if self.hyper:\n            channels *= 2\n            self.hyper_activation = Activation(hyper_act)\n\n        self.D = nn.Parameter(torch.randn(channels, self.h))\n\n        if self.bidirectional:\n            channels *= 2\n\n        # Pointwise\n        if not self.linear:\n            self.activation = Activation(activation)\n            dropout_fn = nn.Dropout2d if self.transposed else nn.Dropout\n            self.dropout = dropout_fn(dropout) if dropout > 0.0 else nn.Identity()\n            if self.ln:\n                self.norm = Normalization(self.h*self.channels, transposed=transposed)\n            else:\n                self.norm = nn.Identity()\n\n        # position-wise output transform to mix features\n        if not self.linear:\n            self.output_linear = LinearActivation(\n                self.h*self.channels,\n                self.h,\n                transposed=self.transposed,\n                initializer=initializer,\n                activation=postact,\n                activate=True,\n                weight_norm=weight_norm,\n            )\n\n        self.init_scale = kernel_args.get('init_scale', 0)\n        self.kernel_dim = kernel_args.get('kernel_dim', 64)\n        self.num_scales = kernel_args.get('n_scales', 1+math.ceil(math.log2(l_max/self.kernel_dim))-self.init_scale)\n        if self.num_scales is None:\n            self.num_scales = 1 + math.ceil(math.log2(l_max/self.kernel_dim)) - self.init_scale\n        self.kernel_list = nn.ParameterList()\n\n        decay_min = kernel_args.get('decay_min', 2)\n        decay_max = kernel_args.get('decay_max', 2)\n        \n        for _ in range(self.num_scales):\n            if 'randn' in mode:\n                kernel = nn.Parameter(torch.randn(channels, self.h, self.kernel_dim))\n            elif 'cos' in mode:\n                kernel = nn.Parameter(torch.cat([torch.cos(torch.linspace(0, 2*i*math.pi, self.kernel_dim)).expand(channels, 1, self.kernel_dim) for i in range(self.h)], dim=1)[:, torch.randperm(self.h), :])\n            else:\n                raise ValueError(f\"Unknown mode {mode}\")\n            kernel._optim = {\n                'lr': kernel_args.get('lr', 0.001),\n            }\n            self.kernel_list.append(kernel)\n            \n        if 'learnable' in mode:\n            self.decay = nn.Parameter(torch.rand(self.h) * (decay_max - decay_min) + decay_min)\n            if 'fixed' in mode:\n                self.decay.requires_grad = False\n            else:   \n                self.decay._optim = {\n                    'lr': kernel_args.get('lr', 0.001),\n                }\n            self.register_buffer('multiplier', torch.tensor(1.0))\n        else:\n            self.register_buffer('multiplier', torch.linspace(decay_min, decay_max, self.h).view(1, -1, 1))\n\n        self.register_buffer('kernel_norm', torch.ones(self.h, 1))\n        self.register_buffer('kernel_norm_initialized', torch.tensor(0, dtype=torch.bool))\n\n\n    def forward(self, u, state=None, **kwargs): # absorbs return_output and transformer src mask\n        \"\"\"\n        u: (B H L) if self.transposed else (B L H)\n        state: (H N) never needed unless you know what you're doing\n\n        Returns: same shape as u\n        \"\"\"\n        if not self.transposed: u = u.transpose(-1, -2)\n        L = u.size(-1)\n\n        kernel_list = []\n        interpolate_mode = 'nearest' if 'nearest' in self.mode else 'linear'\n        multiplier = self.multiplier\n        if 'sum' in self.mode:\n            for i in range(self.num_scales):\n                kernel = F.pad(\n                    F.interpolate(\n                        self.kernel_list[i],\n                        scale_factor = 2**(i+self.init_scale),\n                        mode = interpolate_mode,\n                    ),\n                    (0, self.kernel_dim*2**(self.num_scales-1+self.init_scale) - self.kernel_dim*2**(i+self.init_scale)),\n                ) * multiplier ** (self.num_scales - i - 1)\n                kernel_list.append(kernel)\n            k = sum(kernel_list)\n        elif 'cat' in self.mode:\n            for i in range(self.num_scales):\n                kernel = F.interpolate(\n                    self.kernel_list[i],\n                    scale_factor = 2**(max(0, i-1)+self.init_scale),\n                    mode = interpolate_mode,\n                ) * multiplier ** (self.num_scales - i - 1)\n                kernel_list.append(kernel)\n            k = torch.cat(kernel_list, dim=-1)\n        else:\n            raise ValueError(f\"Unknown mode {self.mode}\")\n\n        if 'learnable' in self.mode:\n            k = k * torch.exp(-self.decay.view(1, -1, 1)*torch.log(torch.arange(k.size(-1), device=k.device)+1).view(1, 1, -1))\n\n        if not self.kernel_norm_initialized:\n            self.kernel_norm = k.norm(dim=-1, keepdim=True).detach()\n            self.kernel_norm_initialized = torch.tensor(1, dtype=torch.bool, device=k.device)\n            print(f\"Kernel norm: {self.kernel_norm.mean()}\")\n            print(f\"Kernel size: {k.size()}\")  \n\n        if k.size(-1) > L:\n            k = k[..., :L]\n        elif k.size(-1) < L:\n            k = F.pad(k, (0, L - k.size(-1)))\n\n        k = k / self.kernel_norm #* (L / self.l_max) ** 0.5\n            \n        # Convolution\n        if self.bidirectional:\n            k0, k1 = rearrange(k, '(s c) h l -> s c h l', s=2)\n            k = F.pad(k0, (0, L)) \\\n                    + F.pad(k1.flip(-1), (L, 0)) \\\n\n        k_f = torch.fft.rfft(k, n=2*L) # (C H L)\n        u_f = torch.fft.rfft(u, n=2*L) # (B H L)\n        y_f = contract('bhl,chl->bchl', u_f, k_f) # k_f.unsqueeze(-4) * u_f.unsqueeze(-3) # (B C H L)\n        y = torch.fft.irfft(y_f, n=2*L)[..., :L] # (B C H L)\n       \n        # Compute D term in state space equation - essentially a skip connection\n        y = y + contract('bhl,ch->bchl', u, self.D)\n\n        # Reshape to flatten channels\n        y = rearrange(y, '... c h l -> ... (c h) l')\n\n        if not self.linear:\n            y = self.dropout(self.activation(y))\n\n        if not self.transposed: y = y.transpose(-1, -2)\n\n        if not self.linear:\n            y = self.norm(y)\n            y = self.output_linear(y)\n\n        return y, None\n\n    @property\n    def d_state(self):\n        return self.h * self.n\n\n    @property\n    def d_output(self):\n        return self.h\n\n    @property\n    def state_to_tensor(self):\n        return lambda state: rearrange('... h n -> ... (h n)', state)",
    "description": null,
    "url": null
}