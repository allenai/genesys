{
    "acronym": "routingtransformer",
    "title": "Efficient Content-Based Sparse Attention with Routing Transformers",
    "seed_ids": [
        "reformer",
        "productkeymem",
        "sparsetransformer"
    ],
    "s2id": "657329c633709dd1ac34a30d57341b186b1a47c2",
    "abstract": "Self-attention has recently been adopted for a wide range of sequence modeling problems. Despite its effectiveness, self-attention suffers from quadratic computation and memory requirements with respect to sequence length. Successful approaches to reduce this complexity focused on attending to local sliding windows or a small set of locations independent of content. Our work proposes to learn dynamic sparse attention patterns that avoid allocating computation and memory to attend to content unrelated to the query of interest. This work builds upon two lines of research: It combines the modeling flexibility of prior work on content-based sparse attention with the efficiency gains from approaches based on local, temporal sparse attention. Our model, the Routing Transformer, endows self-attention with a sparse routing module based on online k-means while reducing the overall complexity of attention to O(n1.5d) from O(n2d) for sequence length n and hidden dimension d. We show that our model outperforms comparable sparse attention models on language modeling on Wikitext-103 (15.8 vs 18.3 perplexity), as well as on image generation on ImageNet-64 (3.43 vs 3.44 bits/dim) while using fewer self-attention layers. Additionally, we set a new state-of-the-art on the newly released PG-19 data-set, obtaining a test perplexity of 33.2 with a 22 layer Routing Transformer model trained on sequences of length 8192. We open-source the code for Routing Transformer in Tensorflow.1",
    "authors": [
        "Aurko Roy",
        "M. Saffar",
        "Ashish Vaswani",
        "David Grangier"
    ],
    "venue": "Transactions of the Association for Computational Linguistics",
    "year": 2020,
    "tldr": "This work proposes to learn dynamic sparse attention patterns that avoid allocating computation and memory to attend to content unrelated to the query of interest, and shows that this model outperforms comparable sparse attention models on language modeling on Wikitext-103, as well as on image generation on ImageNet-64 while using fewer self-attention layers.",
    "citationCount": 478,
    "influentialCitationCount": 45,
    "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nfrom inspect import isfunction\nfrom operator import mul\nfrom functools import partial, reduce, wraps\n\n\n# constants\n\nTOKEN_SELF_ATTN_VALUE = -5e4\nKMEAN_INIT_ITERS = 10\n\n# helper functions\n\ndef exists(val):\n    return val is not None\n\ndef identity(x, *args, **kwargs):\n    return x\n\ndef default(x, d):\n    if not exists(x):\n        return d if not isfunction(d) else d()\n    return x\n\ndef cast_tuple(x):\n    return x if isinstance(x, tuple) else (x,)\n\ndef cache_fn(f):\n    cache = None\n    @wraps(f)\n    def cached_fn(*args, **kwargs):\n        nonlocal cache\n        if exists(cache):\n            return cache\n        cache = f(*args, **kwargs)\n        return cache\n    return cached_fn\n\ndef compose(*fns):\n    def inner(x, *args, **kwargs):\n        for fn in reversed(fns):\n            x = fn(x, *args, **kwargs)\n        return x\n    return inner\n\ndef to(t):\n    return {'device': t.device, 'dtype': t.dtype}\n\ndef find_modules(nn_module, type):\n    return [module for module in nn_module.modules() if isinstance(module, type)]\n\ndef is_empty(t):\n    return t.nelement() == 0\n\ndef max_neg_value(tensor):\n    return -torch.finfo(tensor.dtype).max\n\ndef batched_index_select(values, indices):\n    last_dim = values.shape[-1]\n    return values.gather(2, expand_dim(indices, -1, last_dim))\n\ndef merge_dims(ind_from, ind_to, tensor):\n    shape = list(tensor.shape)\n    arr_slice = slice(ind_from, ind_to + 1)\n    shape[arr_slice] = [reduce(mul, shape[arr_slice])]\n    return tensor.reshape(*shape)\n\ndef expand_dim(t, dim, k):\n    t = t.unsqueeze(dim)\n    expand_shape = [-1] * len(t.shape)\n    expand_shape[dim] = k\n    return t.expand(*expand_shape)\n\ndef scatter_mean(src, t, index, dim, eps = 1e-5):\n    numer = src.scatter_add(dim, index, t)\n    denom = src.scatter_add(dim, index, torch.ones_like(t))\n    return numer / (denom + eps)\n\ndef split_at_index(dim, index, t):\n    pre_slices = (slice(None),) * dim\n    l = (*pre_slices, slice(None, index))\n    r = (*pre_slices, slice(index, None))\n    return t[l], t[r]\n\ndef reshape_dim(t, dim, split_dims):\n    shape = list(t.shape)\n    num_dims = len(shape)\n    dim = (dim + num_dims) % num_dims\n    shape[dim:dim+1] = split_dims\n    return t.reshape(shape)\n\ndef ema(old, new, decay):\n    if not exists(old):\n        return new\n    return old * decay + new * (1 - decay)\n\ndef ema_inplace(moving_avg, new, decay):\n    if is_empty(moving_avg):\n        moving_avg.data.copy_(new)\n        return\n    moving_avg.data.mul_(decay).add_(new, alpha= (1 - decay))\n\n# kmeans related function and class\n\ndef update_kmeans_on_backwards(module):\n    module.kmean_modules = find_modules(module, Kmeans)\n    def hook(_, grad_in, grad_out):\n        for m in module.kmean_modules:\n            m.update()\n\n    return module.register_backward_hook(hook)\n\ndef similarity(x, means):\n    return torch.einsum('bhld,hcd->bhlc', x, means)\n\ndef dists_and_buckets(x, means):\n    dists = similarity(x, means)\n    _, buckets = torch.max(dists, dim=-1)\n    return dists, buckets\n\ndef batched_bincount(index, num_classes, dim=-1):\n    shape = list(index.shape)\n    shape[dim] = num_classes\n    out = index.new_zeros(shape)\n    out.scatter_add_(dim, index, torch.ones_like(index, dtype=index.dtype))\n    return out\n\ndef kmeans_iter(x, means, buckets = None):\n    b, h, l, d, dtype, num_clusters = *x.shape, x.dtype, means.shape[1]\n\n    if not exists(buckets):\n        _, buckets = dists_and_buckets(x, means)\n\n    bins = batched_bincount(buckets, num_clusters).sum(0, keepdim=True)\n    zero_mask = bins.long() == 0\n\n    means_ = buckets.new_zeros(b, h, num_clusters, d, dtype=dtype)\n    means_.scatter_add_(-2, expand_dim(buckets, -1, d), x)\n    means_ = F.normalize(means_.sum(0, keepdim=True), dim=-1).type(dtype)\n\n    means = torch.where(zero_mask.unsqueeze(-1), means, means_)\n    means = means.squeeze(0)\n    return means\n\ndef distribution(dists, window_size):\n    _, topk_indices = dists.topk(k=window_size, dim=-2)\n    indices = topk_indices.transpose(-2, -1)\n    return indices.reshape(*indices.size()[:2], -1)\n\nclass Kmeans(nn.Module):\n    def __init__(self, num_heads, head_dim, num_clusters, ema_decay = 0.999, commitment = 1e-4):\n        super().__init__()\n        self.commitment = commitment\n        self.ema_decay = ema_decay\n\n        self.register_buffer('means', torch.randn(num_heads, num_clusters, head_dim))\n        self.register_buffer('initted', torch.tensor(False))\n        self.num_new_means = 0\n        self.new_means = None\n\n    @torch.no_grad()\n    def init(self, x):\n        if self.initted:\n            return\n        _, h, _, d, device, dtype = *x.shape, x.device, x.dtype\n\n        num_clusters = self.means.shape[1]\n\n        means = x.transpose(0, 1).contiguous().view(h, -1, d)\n        num_samples = means.shape[1]\n\n        if num_samples >= num_clusters:\n            indices = torch.randperm(num_samples, device=device)[:num_clusters]\n        else:\n            indices = torch.randint(0, num_samples, (num_clusters,), device=device)\n\n        means = means[:, indices]\n\n        for _ in range(KMEAN_INIT_ITERS):\n            means = kmeans_iter(x, means)\n\n        self.num_new_means = 0\n        self.means.data.copy_(means)\n        self.initted.data.copy_(torch.tensor(True))\n\n    @torch.no_grad()\n    def update(self, new_means = None):\n        new_means = default(new_means, self.new_means)\n        assert exists(new_means), 'new kmeans has not been supplied'\n        ema_inplace(self.means, new_means, self.ema_decay)\n\n        del self.new_means\n        self.new_means = None\n        self.num_new_means = 0\n\n    def forward(self, x, update_means = False):\n        self.init(x)\n\n        b, dtype = x.shape[0], x.dtype\n        means = self.means.type(dtype)\n        x = F.normalize(x, 2, dim=-1).type(dtype)\n\n        with torch.no_grad():\n            dists, buckets = dists_and_buckets(x, means)\n\n        routed_means = batched_index_select(expand_dim(means, 0, b), buckets)\n        loss = F.mse_loss(x, routed_means) * self.commitment\n\n        if update_means:\n            with torch.no_grad():\n                means = kmeans_iter(x, means, buckets)\n            self.new_means = ema(self.new_means, means, self.num_new_means / (self.num_new_means + 1))\n            self.num_new_means += 1\n\n        return dists, loss\n\n# kmeans attention class\n\nclass KmeansAttention(nn.Module):\n    def __init__(self, num_clusters, window_size, num_heads, head_dim, causal = False, dropout = 0., ema_decay = 0.999, commitment = 1e-4, context_window_size = None, receives_context = False, num_mem_kv = 0, shared_qk = False):\n        super().__init__()\n        self.num_heads = num_heads\n        self.num_clusters = num_clusters\n        self.head_dim = head_dim\n\n        self.window_size = window_size\n        self.context_window_size = default(context_window_size, window_size)\n        self.causal = causal\n\n        self.shared_qk = shared_qk\n        self.receives_context = receives_context\n        self.kmeans = Kmeans(num_heads, head_dim, num_clusters, ema_decay, commitment)\n        self.dropout = nn.Dropout(dropout)\n\n        self.num_mem_kv = max(num_mem_kv, 1 if causal and not shared_qk else 0)\n        self.mem_key = nn.Parameter(torch.randn(num_heads, num_clusters, self.num_mem_kv, head_dim))\n        self.mem_value = nn.Parameter(torch.randn(num_heads, num_clusters, self.num_mem_kv, head_dim))\n\n    def forward(self, q, k, v, query_mask = None, key_mask = None, **kwargs):\n        b, h, t, d, kv_t, wsz, c_wsz, nc, device, dtype = *q.shape, k.shape[2], self.window_size, self.context_window_size, self.num_clusters, q.device, q.dtype\n        is_reverse = kwargs.pop('_reverse', False)\n\n        out = torch.zeros_like(q, dtype=dtype)\n\n        update_kmeans = self.training and not is_reverse\n        \n        key_mask = default(key_mask, query_mask) if not self.receives_context else key_mask\n        kv_wsz = wsz if not self.receives_context else c_wsz\n\n        wsz = min(wsz, t)\n        kv_wsz = min(kv_wsz, kv_t)\n\n        if not self.shared_qk or self.receives_context:\n            dists, aux_loss = self.kmeans(torch.cat((q, k), dim=2), update_kmeans)\n            q_dists, k_dists = split_at_index(2, t, dists)\n            indices = distribution(q_dists, wsz)\n            kv_indices = distribution(k_dists, kv_wsz)\n        else:\n            dists, aux_loss = self.kmeans(q, update_kmeans)\n            k = F.normalize(k, dim=-1).to(q)\n            indices = distribution(dists, wsz)\n            kv_indices = indices\n\n        q = batched_index_select(q, indices)\n        k = batched_index_select(k, kv_indices)\n        v = batched_index_select(v, kv_indices)\n\n        reshape_with_window = lambda x: x.reshape(b, h, nc, -1, d)\n        q, k, v = map(reshape_with_window, (q, k, v))\n\n        m_k, m_v = map(lambda x: expand_dim(x, 0, b).to(q), (self.mem_key, self.mem_value))\n        k, v = map(lambda x: torch.cat(x, dim=3), ((m_k, k), (m_v, v)))\n\n        dots = torch.einsum('bhnid,bhnjd->bhnij', q, k) * (d ** -0.5)\n\n        mask_value = max_neg_value(dots)\n\n        if exists(query_mask) or exists(key_mask):\n            query_mask = default(query_mask, lambda: torch.ones((b, t), device=device).bool())\n            key_mask = default(key_mask, lambda: torch.ones((b, kv_t), device=device).bool())\n\n            q_mask = expand_dim(query_mask, 1, h).gather(2, indices)\n            kv_mask = expand_dim(key_mask, 1, h).gather(2, kv_indices)\n            q_mask, kv_mask = map(lambda t: t.reshape(b, h, nc, -1), (q_mask, kv_mask))\n            mask = q_mask[:, :, :, :, None] * kv_mask[:, :, :, None, :]\n            mask = F.pad(mask, (self.num_mem_kv, 0), value=True)\n            dots.masked_fill_(~mask, mask_value)\n            del mask\n\n        if self.causal:\n            q_mask, kv_mask = map(lambda t: t.reshape(b, h, nc, -1), (indices, kv_indices))\n            mask = q_mask[:, :, :, :, None] >= kv_mask[:, :, :, None, :]\n            mask = F.pad(mask, (self.num_mem_kv, 0), value=True)\n            dots.masked_fill_(~mask, mask_value)\n            del mask            \n\n        if self.shared_qk:\n            q_mask, kv_mask = map(lambda t: t.reshape(b, h, nc, -1), (indices, kv_indices))\n            mask = q_mask[:, :, :, :, None] == kv_mask[:, :, :, None, :]\n            mask = F.pad(mask, (self.num_mem_kv, 0), value=False)\n            dots.masked_fill_(mask, TOKEN_SELF_ATTN_VALUE)\n            del mask\n\n        dots = dots.softmax(dim=-1)\n        dots = self.dropout(dots)\n\n        bo = torch.einsum('bhcij,bhcjd->bhcid', dots, v)\n        so = torch.reshape(bo, (b, h, -1, bo.shape[-1])).type(dtype)\n        out = scatter_mean(out, so, indices.unsqueeze(-1).expand_as(so), -2)\n        return out, aux_loss\n",
    "description": null,
    "url": null
}