{
    "acronym": "scattn",
    "title": "Sparse and continuous attention mechanisms",
    "seed_ids": [],
    "s2id": "09e69bf0926e55cd277a3ef5b1450ba083719cb9",
    "abstract": "Exponential families are widely used in machine learning; they include many distributions in continuous and discrete domains (e.g., Gaussian, Dirichlet, Poisson, and categorical distributions via the softmax transformation). Distributions in each of these families have fixed support. In contrast, for finite domains, there has been recent work on sparse alternatives to softmax (e.g. sparsemax and alpha-entmax), which have varying support, being able to assign zero probability to irrelevant categories. This paper expands that work in two directions: first, we extend alpha-entmax to continuous domains, revealing a link with Tsallis statistics and deformed exponential families. Second, we introduce continuous-domain attention mechanisms, deriving efficient gradient backpropagation algorithms for alpha in {1,2}. Experiments on attention-based text classification, machine translation, and visual question answering illustrate the use of continuous attention in 1D and 2D, showing that it allows attending to time intervals and compact regions.",
    "authors": [
        "Andr\u00e9 F. T. Martins",
        "Marcos Vin\u00edcius Treviso",
        "Ant\u00f3nio Farinhas",
        "Vlad Niculae",
        "M\u00e1rio A. T. Figueiredo",
        "P. Aguiar"
    ],
    "venue": "Neural Information Processing Systems",
    "year": 2020,
    "tldr": "This paper extends alpha-entmax to continuous domains, revealing a link with Tsallis statistics and deformed exponential families, and introduces continuous-domain attention mechanisms, deriving efficient gradient backpropagation algorithms for alpha in {1,2}.",
    "citationCount": 28,
    "influentialCitationCount": 2,
    "code": "from core.model.net_utils import FC, MLP, LayerNorm\nfrom core.model.mca import MCA_ED\n\nimport numpy as np\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch\nfrom entmax import sparsemax\nfrom functools import partial\nfrom torch import Tensor\n\nfrom core.model.basis_functions import GaussianBasisFunctions\nimport math \nfrom core.model.tv2d_numba import prox_tv2d\n\nfrom torch.autograd import Function\n\nfrom numba import jit\n\n@jit(nopython=True)\ndef isin(x, l):\n    for i in l:\n        if x==i:\n            return True\n    return False\n\n@jit(nopython=True)        \ndef back(Y, dX, dY):\n    neigbhours=list([(1,1)])\n    del neigbhours[-1] \n    group=[(0,0)]\n    del group[-1]\n    n=0\n    idx_grouped = [(200,200)for x in range(196)]\n    count=0\n    value=0\n    s=0\n    while True:\n        if len(neigbhours)!=0:\n            while len(neigbhours)!=0:\n                if Y[neigbhours[0][0],neigbhours[0][1]] == value:\n                    a = neigbhours[0][0]\n                    b = neigbhours[0][1]\n                    del neigbhours[0]\n                    count+=1\n                    s+=dY[a,b]\n                    group.append((a,b))\n                    idx_grouped[n]=(a,b)\n                    n+=1\n                    if b<13 and isin((a,b+1), idx_grouped)==False and isin((a,b+1), neigbhours)==False:\n                        neigbhours.append((a,b+1))\n                    if a<13 and isin((a+1,b), idx_grouped)==False and isin((a+1,b), neigbhours)==False:\n                        neigbhours.append((a+1,b)) \n                    if b>0 and isin((a,b-1), idx_grouped)==False and isin((a,b-1), neigbhours)==False:\n                        neigbhours.append((a,b-1)) \n                    if a>0 and isin((a-1,b), idx_grouped)==False and isin((a-1,b), neigbhours)==False:\n                        neigbhours.append((a-1,b)) \n                else:\n                    del neigbhours[0]\n        else:\n            if len(group)>0:\n                o=s/count\n                count=0\n                for x in group:\n                    dX[x[0],x[1]]=o\n                group=[(0,0)]\n                del group[0]\n            \n            if n>=196:\n                break\n            B=False\n            for i in range(14):\n                for j in range(14):\n                    if isin((i,j), idx_grouped)==False:\n                        value = Y[i,j]\n                        s = dY[i,j]\n                        count+=1\n                        group.append((i, j))\n                        idx_grouped[n] = (i, j)\n                        n+=1\n                        if j<13 and isin((i,j+1), idx_grouped)==False and isin((i,j+1), neigbhours)==False:\n                            neigbhours.append((i,j+1))\n                        if i<13 and isin((i+1,j), idx_grouped)==False and isin((i+1,j), neigbhours)==False:\n                            neigbhours.append((i+1,j)) \n                        if j>0 and isin((i,j-1), idx_grouped)==False and isin((i,j-1), neigbhours)==False:\n                            neigbhours.append((i,j-1)) \n                        if i>0 and isin((i-1,j), idx_grouped)==False and isin((i-1,j), neigbhours)==False:\n                            neigbhours.append((i-1,j)) \n                        B=True\n                        break\n                if B:\n                    break\n    return dX\n\nclass TV2DFunction(Function):\n\n    @staticmethod\n    def forward(ctx, X, alpha=0.01, max_iter=35, tol=1e-2):\n        torch.set_num_threads(8)\n        ctx.digits_tol = int(-np.log10(tol)) // 2\n\n        X_np = X.detach().cpu().numpy()\n        n_rows, n_cols = X_np.shape\n        Y_np = prox_tv2d(X_np.ravel(),\n                         step_size=alpha / 2,\n                         n_rows=n_rows,\n                         n_cols=n_cols,\n                         max_iter=max_iter,\n                         tol=tol)\n        \n        \n        Y_np = Y_np.reshape(n_rows, n_cols)\n        Y = torch.from_numpy(Y_np)  # double-precision\n        Y = torch.as_tensor(Y, dtype=X.dtype, device=X.device)\n        ctx.save_for_backward(Y.detach())  # TODO figure out why detach everywhere\n\n        return Y\n\n    @staticmethod\n    def backward(ctx, dY):\n        #with torch.autograd.profiler.profile(use_cuda=True) as prof)\n        torch.set_num_threads(8)\n        Y, = ctx.saved_tensors\n        \"\"\"\n        tic = perf_counter()\n        dY_np = dY.cpu().numpy()\n        dX_np = np.zeros((8,8))\n\n        Y_np_round = Y.cpu().numpy().round(ctx.digits_tol)\n        # TODO speed me up. Maybe with scikit-image label?\n        uniq, inv = np.unique(Y_np_round, return_inverse=True)\n        \n        inv = inv.reshape((8,8))\n        \n        for j in range(len(uniq)):\n            objs, n_objs = label(inv == j)\n            for k in range(1, n_objs + 1):\n                obj = objs == k\n                obj_mean = (obj * dY_np).sum() / obj.sum()\n                dX_np += obj_mean * obj\n        #tac=perf_counter()\n        #print(torch.as_tensor(dX_np, dtype=dY.dtype, device=dY.device))\n        #print('vlad', tac-tic)\n        #tic=perf_counter()\n        \"\"\"\n        Y_np = np.array(Y.cpu()).round(ctx.digits_tol)\n        dY_np = np.array(dY.cpu())\n        dX = np.zeros((14,14))\n        dX = back(Y_np, dX, dY_np)\n        dX = torch.as_tensor(dX, dtype=dY.dtype, device=dY.device)\n        #tac=perf_counter()\n        #print(dX)\n        #print('pedro', tac-tic)\n        \n        return dX, None \n\n\n\nclass ContinuousSoftmaxFunction(torch.autograd.Function):\n\n    @classmethod\n    def _expectation_phi_psi(cls, ctx, Mu, Sigma):\n        \"\"\"Compute expectation of phi(t) * psi(t).T under N(mu, sigma_sq).\"\"\"\n        num_basis = [len(basis_functions) for basis_functions in ctx.psi]\n        total_basis = sum(num_basis)\n        V = torch.zeros((Mu.shape[0], 6, total_basis), dtype=ctx.dtype, device=ctx.device)\n        offsets = torch.cumsum(torch.IntTensor(num_basis).to(ctx.device), dim=0)\n        start = 0\n        for j, basis_functions in enumerate(ctx.psi):\n            V[:, 0, start:offsets[j]]=basis_functions.integrate_t_times_psi_gaussian(Mu,Sigma).squeeze(-1)[:,:,0]\n            V[:, 1, start:offsets[j]]=basis_functions.integrate_t_times_psi_gaussian(Mu,Sigma).squeeze(-1)[:,:,1]\n            V[:, 2, start:offsets[j]]=basis_functions.integrate_t2_times_psi_gaussian(Mu,Sigma)[:,:,0,0]\n            V[:, 3, start:offsets[j]]=basis_functions.integrate_t2_times_psi_gaussian(Mu,Sigma)[:,:,0,1]\n            V[:, 4, start:offsets[j]]=basis_functions.integrate_t2_times_psi_gaussian(Mu,Sigma)[:,:,1,0]\n            V[:, 5, start:offsets[j]]=basis_functions.integrate_t2_times_psi_gaussian(Mu,Sigma)[:,:,1,1]\n            start = offsets[j]\n        return V # [batch,6,N]\n\n\n    @classmethod\n    def _expectation_psi(cls, ctx, Mu, Sigma):\n        \"\"\"Compute expectation of psi under N(mu, sigma_sq).\"\"\"\n        num_basis = [len(basis_functions) for basis_functions in ctx.psi]\n        total_basis = sum(num_basis)\n        r = torch.zeros(Mu.shape[0], total_basis, dtype=ctx.dtype, device=ctx.device)\n        offsets = torch.cumsum(torch.IntTensor(num_basis).to(ctx.device), dim=0)\n        start = 0\n        for j, basis_functions in enumerate(ctx.psi):\n            r[:, start:offsets[j]] = basis_functions.integrate_psi_gaussian(Mu, Sigma).squeeze(-2).squeeze(-1)\n            start = offsets[j]\n        return r # [batch,N]\n\n    @classmethod\n    def _expectation_phi(cls, ctx, Mu, Sigma):\n        v = torch.zeros(Mu.shape[0], 6, dtype=ctx.dtype, device=ctx.device)\n        v[:, 0:2]=Mu.squeeze(1).squeeze(-1)\n        v[:, 2:6]=((Mu @ torch.transpose(Mu,-1,-2)) + Sigma).view(-1,4)\n        return v # [batch,6]\n\n\n    @classmethod\n    def forward(cls, ctx, theta, psi):\n        # We assume a Gaussian\n        # We have:\n        # Mu:[batch,1,2,1] and Sigma:[batch,1,2,2]\n        #theta=[(Sigma)^-1 @ Mu, -0.5*(Sigma)^-1]\n        #theta: batch x 6 \n        #phi(t)=[t,tt^t]\n        #p(t)= Gaussian(t; Mu, Sigma)\n\n        ctx.dtype = theta.dtype\n        ctx.device = theta.device\n        ctx.psi = psi\n\n        Sigma=(-2*theta[:,2:6].view(-1,2,2))\n        Sigma=(1/2. * (Sigma.inverse() + torch.transpose(Sigma.inverse(),-1,-2))).unsqueeze(1) # torch.Size([batch, 1, 2, 2])\n        Mu=(Sigma @ (theta[:,0:2].view(-1,2,1)).unsqueeze(1)) # torch.Size([batch, 1, 2, 1])\n        \n        r=cls._expectation_psi(ctx, Mu, Sigma)\n        ctx.save_for_backward(Mu, Sigma, r)\n        return r # [batch, N]\n\n    @classmethod\n    def backward(cls, ctx, grad_output):\n        Mu, Sigma, r = ctx.saved_tensors\n        J = cls._expectation_phi_psi(ctx, Mu, Sigma) # batch,6,N\n        e_phi = cls._expectation_phi(ctx, Mu, Sigma) # batch,6\n        e_psi = cls._expectation_psi(ctx, Mu, Sigma) # batch,N\n        J -= torch.bmm(e_phi.unsqueeze(2), e_psi.unsqueeze(1))\n        grad_input = torch.matmul(J, grad_output.unsqueeze(2)).squeeze(2)\n        return grad_input, None\n\nclass ContinuousSoftmax(nn.Module):\n    def __init__(self, psi=None):\n        super(ContinuousSoftmax, self).__init__()\n        self.psi = psi\n\n    def forward(self, theta):\n        return ContinuousSoftmaxFunction.apply(theta, self.psi)\n\n\nclass ContinuousSparsemaxFunction(torch.autograd.Function):\n\n    @classmethod\n    def _expectation_phi_psi(cls, ctx, Mu, Sigma):\n        \"\"\"Compute expectation of phi(t) * psi(t).T under N(mu, sigma_sq).\"\"\"\n        num_basis = [len(basis_functions) for basis_functions in ctx.psi]\n        total_basis = sum(num_basis)\n        V = torch.zeros((Mu.shape[0], 6, total_basis), dtype=ctx.dtype, device=ctx.device)\n        offsets = torch.cumsum(torch.IntTensor(num_basis).to(ctx.device), dim=0)\n        start = 0\n        for j, basis_functions in enumerate(ctx.psi):\n            integral_t_times_psi=(basis_functions.integrate_t_times_psi(Mu,Sigma).squeeze(-1)).to(ctx.device)\n            integral_t2_times_psi=basis_functions.integrate_t2_times_psi(Mu,Sigma).to(ctx.device)\n\n            V[:, 0, start:offsets[j]]=integral_t_times_psi[:,:,0]\n            V[:, 1, start:offsets[j]]=integral_t_times_psi[:,:,1]\n            V[:, 2, start:offsets[j]]=integral_t2_times_psi[:,:,0,0]\n            V[:, 3, start:offsets[j]]=integral_t2_times_psi[:,:,0,1]\n            V[:, 4, start:offsets[j]]=integral_t2_times_psi[:,:,1,0]\n            V[:, 5, start:offsets[j]]=integral_t2_times_psi[:,:,1,1]\n            start = offsets[j]\n        return V # [batch,6,N]\n\n\n    @classmethod\n    def _expectation_psi(cls, ctx, Mu, Sigma):\n        \"\"\"Compute expectation of psi under N(mu, sigma_sq).\"\"\"\n        num_basis = [len(basis_functions) for basis_functions in ctx.psi]\n        total_basis = sum(num_basis)\n        r = torch.zeros(Mu.shape[0], total_basis, dtype=ctx.dtype, device=ctx.device)\n        offsets = torch.cumsum(torch.IntTensor(num_basis).to(ctx.device), dim=0)\n        start = 0\n        for j, basis_functions in enumerate(ctx.psi):\n            r[:, start:offsets[j]] = basis_functions.integrate_psi(Mu, Sigma).squeeze(-2).squeeze(-1)\n            start = offsets[j]\n        return r # [batch,N]\n\n\n    @classmethod\n    def _expectation_phi(cls, ctx, Mu, Sigma):\n        \n        num_basis = [len(basis_functions) for basis_functions in ctx.psi]\n        total_basis = sum(num_basis)\n        v = torch.zeros((Mu.shape[0], 6, total_basis), dtype=ctx.dtype, device=ctx.device)\n        offsets = torch.cumsum(torch.IntTensor(num_basis).to(ctx.device), dim=0)\n        start = 0\n        \n        for j, basis_functions in enumerate(ctx.psi):\n            integral_normal=basis_functions.integrate_normal(Mu, Sigma).to(ctx.device) # [batch, N, 1, 1]\n            aux=(basis_functions.aux(Mu, Sigma)).to(ctx.device)\n\n            v[:, 0, start:offsets[j]]=Mu.squeeze(-1)[:,:,0] * integral_normal.squeeze(-1).squeeze(-1)\n            v[:, 1, start:offsets[j]]=Mu.squeeze(-1)[:,:,1] * integral_normal.squeeze(-1).squeeze(-1)\n            v[:, 2, start:offsets[j]]=(aux * integral_normal)[:,:,0,0]\n            v[:, 3, start:offsets[j]]=(aux * integral_normal)[:,:,0,1]\n            v[:, 4, start:offsets[j]]=(aux * integral_normal)[:,:,1,0]\n            v[:, 5, start:offsets[j]]=(aux * integral_normal)[:,:,1,1]\n            start = offsets[j]\n        return v # [batch,6,N]\n\n\n    @classmethod\n    def forward(cls, ctx, theta, psi):\n        # We assume a Gaussian\n        # We have:\n        # Mu:[batch,1,2,1] and Sigma:[batch,1,2,2]\n        #theta=[(Sigma)^-1 @ Mu, -0.5*(Sigma)^-1]\n        #theta: batch x 6 \n        #phi(t)=[t,tt^t]\n        #p(t)= Gaussian(t; Mu, Sigma)\n\n        ctx.dtype = theta.dtype\n        ctx.device = theta.device\n        ctx.psi = psi\n\n        Sigma=(-2*theta[:,2:6].view(-1,2,2))\n        Sigma=(1/2. * (Sigma.inverse() + torch.transpose(Sigma.inverse(),-1,-2))).unsqueeze(1) # torch.Size([batch, 1, 2, 2])\n        Mu=(Sigma @ (theta[:,0:2].view(-1,2,1)).unsqueeze(1)) # torch.Size([batch, 1, 2, 1])\n        \n        r=cls._expectation_psi(ctx, Mu, Sigma)\n        ctx.save_for_backward(Mu, Sigma, r)\n        return r # [batch, N]\n\n    @classmethod\n    def backward(cls, ctx, grad_output):\n        Mu, Sigma, r = ctx.saved_tensors\n        J = cls._expectation_phi_psi(ctx, Mu, Sigma) - cls._expectation_phi(ctx, Mu, Sigma) # batch,6,N\n        grad_input = torch.matmul(J, grad_output.unsqueeze(2)).squeeze(2)\n        return grad_input, None\n\nclass ContinuousSparsemax(nn.Module):\n    def __init__(self, psi=None):\n        super(ContinuousSparsemax, self).__init__()\n        self.psi = psi\n\n    def forward(self, theta):\n        return ContinuousSparsemaxFunction.apply(theta, self.psi)\n\n# --------------------------------------------------------------\n# ---- Flatten the sequence (image in continuous attention) ----\n# --------------------------------------------------------------\n\nclass AttFlat(nn.Module):\n    def __init__(self, __C, gen_func=torch.softmax):\n        super(AttFlat, self).__init__()\n        self.__C = __C\n\n        self.attention=__C.attention\n        self.gen_func=gen_func\n\n        if str(gen_func)=='tvmax':\n            self.sparsemax = partial(sparsemax, k=512)\n            self.tvmax = TV2DFunction.apply\n\n        self.mlp = MLP(\n            in_size=__C.HIDDEN_SIZE,\n            mid_size=__C.FLAT_MLP_SIZE,\n            out_size=__C.FLAT_GLIMPSES,\n            dropout_r=__C.DROPOUT_R,\n            use_relu=True)\n\n        self.linear_merge = nn.Linear(__C.HIDDEN_SIZE * __C.FLAT_GLIMPSES,__C.FLAT_OUT_SIZE)\n\n        if (self.attention=='cont-sparsemax'):\n            self.transform = ContinuousSparsemax(psi=None) # use basis functions in 'psi' to define continuous sparsemax\n        else:\n            self.transform = ContinuousSoftmax(psi=None) # use basis functions in 'psi' to define continuous softmax\n        \n        device='cuda'\n\n        # compute F and G offline for one length = 14*14 = 196\n        self.Gs = [None]\n        self.psi = [None]\n        max_seq_len=14*14 # 196 grid features\n        attn_num_basis=100 # 100 basis functions\n        nb_waves=attn_num_basis\n        self.psi.append([])\n        self.add_gaussian_basis_functions(self.psi[1],nb_waves,device=device)\n\n\n        # stack basis functions\n        padding=True\n        length=max_seq_len\n        if padding:\n            shift=1/float(2*math.sqrt(length))\n            positions_x = torch.linspace(-0.5+shift, 1.5-shift, int(2*math.sqrt(length)))\n            positions_x, positions_y=torch.meshgrid(positions_x,positions_x)\n            positions_x=positions_x.flatten()\n            positions_y=positions_y.flatten()\n        else:\n            shift = 1 / float(2*math.sqrt(length))\n            positions_x = torch.linspace(shift, 1-shift, int(math.sqrt(length)))\n            positions_x, positions_y=torch.meshgrid(positions_x,positions_x)\n            positions_x=positions_x.flatten()\n            positions_y=positions_y.flatten()\n\n        positions=torch.zeros(len(positions_x),2,1).to(device)\n        for position in range(1,len(positions_x)+1):\n            positions[position-1]=torch.tensor([[positions_x[position-1]],[positions_y[position-1]]])\n\n        F = torch.zeros(nb_waves, positions.size(0)).unsqueeze(2).unsqueeze(3).to(device) # torch.Size([N, 196, 1, 1])\n        # print(positions.size()) # torch.Size([196, 2, 1])\n        basis_functions = self.psi[1][0]\n        # print(basis_functions.evaluate(positions[0]).size()) # torch.Size([N, 1, 1])\n\n        for i in range(0,positions.size(0)):\n            F[:,i]=basis_functions.evaluate(positions[i])[:]\n\n        penalty = .01  # Ridge penalty\n        I = torch.eye(nb_waves).to(device)\n        F=F.squeeze(-2).squeeze(-1) # torch.Size([N, 196])\n        G = F.t().matmul((F.matmul(F.t()) + penalty * I).inverse()) # torch.Size([196, N])\n        if padding:\n            G = G[length:-length, :]\n            G=torch.cat([G[7:21,:],G[35:49,:],G[63:77,:],G[91:105,:],G[119:133,:],G[147:161,:],G[175:189,:],G[203:217,:],G[231:245,:],G[259:273,:],G[287:301,:],G[315:329,:],G[343:357,:],G[371:385,:]])\n        \n        self.Gs.append(G.to(device))\n\n    def add_gaussian_basis_functions(self, psi, nb_basis, device):\n        \n        steps=int(math.sqrt(nb_basis))\n\n        mu_x=torch.linspace(0,1,steps)\n        mu_y=torch.linspace(0,1,steps)\n        mux,muy=torch.meshgrid(mu_x,mu_y)\n        mux=mux.flatten()\n        muy=muy.flatten()\n\n        mus=[]\n        for mu in range(1,nb_basis+1):\n            mus.append([[mux[mu-1]],[muy[mu-1]]])\n        mus=torch.tensor(mus).to(device)\n\n        sigmas=[]\n        for sigma in range(1,nb_basis+1):\n            sigmas.append([[0.001,0.],[0.,0.001]]) # it is possible to change this matrix\n        sigmas=torch.tensor(sigmas).to(device) # in continuous softmax we have sigmas=torch.DoubleTensor(sigmas).to(device)\n\n        assert mus.size(0) == nb_basis\n        psi.append(GaussianBasisFunctions(mu=mus, sigma=sigmas))\n\n    def value_function(self, values, mask=None):\n        # Approximate B * F = values via multivariate regression.\n        # Use a ridge penalty. The solution is B = values * G\n        # x:(batch,L,D)\n        G = self.Gs[1]\n        B = torch.transpose(values,-1,-2) @ G\n        return B\n\n    def forward(self, x, x_mask):\n        att = self.mlp(x)\n        att = att.masked_fill(x_mask.squeeze(1).squeeze(1).unsqueeze(2),-1e9)\n\n        if str(self.gen_func)=='tvmax':\n            att = att.squeeze(-1).view(-1,14,14)\n            for i in range(att.size(0)):\n                att[i] = self.tvmax(att[i])\n            att = self.sparsemax(att.view(-1,14*14)).unsqueeze(-1)\n        \n        else:\n            att = self.gen_func(att.squeeze(-1), dim=-1).unsqueeze(-1)\n\n        # compute distribution parameters\n        max_seq_len=196\n        length=max_seq_len\n\n        positions_x = torch.linspace(0., 1., int(math.sqrt(length)))\n        positions_x, positions_y=torch.meshgrid(positions_x,positions_x)\n        positions_x=positions_x.flatten()\n        positions_y=positions_y.flatten()\n        positions=torch.zeros(len(positions_x),2,1).to(x.device)\n        for position in range(1,len(positions_x)+1):\n            positions[position-1]=torch.tensor([[positions_x[position-1]],[positions_y[position-1]]])\n\n        # positions: (196, 2, 1)\n        # positions.unsqueeze(0): (1, 196, 2, 1)\n        # att.unsqueeze(-1): (batch, 196, 1, 1)\n        Mu= torch.sum(positions.unsqueeze(0) @ att.unsqueeze(-1), 1) # (batch, 2, 1)\n        Sigma=torch.sum(((positions @ torch.transpose(positions,-1,-2)).unsqueeze(0) * att.unsqueeze(-1)),1) - (Mu @ torch.transpose(Mu,-1,-2)) # (batch, 2, 2)\n        Sigma=Sigma + (torch.tensor([[1.,0.],[0.,1.]])*1e-6).to(x.device) # to avoid problems with small values\n\n\n        if (self.attention=='cont-sparsemax'):\n            Sigma=9.*math.pi*torch.sqrt(Sigma.det().unsqueeze(-1).unsqueeze(-1))*Sigma\n\n        # get `mu` and `sigma` as the canonical parameters `theta`\n        theta1 = ((1/2. * (Sigma.inverse() + torch.transpose(Sigma.inverse(),-1,-2))) @ Mu).flatten(1)\n        theta2 = (-1. / 2. * (1/2. * (Sigma.inverse() + torch.transpose(Sigma.inverse(),-1,-2)))).flatten(1)\n        theta = torch.zeros(x.size(0), 6, device=x.device ) #torch.Size([batch, 6])\n        theta[:,0:2]=theta1\n        theta[:,2:6]=theta2\n\n        # map to a probability density over basis functions\n        self.transform.psi = self.psi[1]\n        r = self.transform(theta)  # batch x nb_basis\n\n        # compute B using a multivariate regression\n        # batch x D x N\n        B = self.value_function(x, mask=None)\n\n        # (bs, nb_basis) -> (bs, 1, nb_basis)\n        r = r.unsqueeze(1)  # batch x 1 x nb_basis\n\n        # (bs, hdim, nb_basis) * (bs, nb_basis, 1) -> (bs, hdim, 1)\n        # get the context vector\n        # batch x values_size x 1\n        context = torch.matmul(B, r.transpose(-1, -2))\n        context = context.transpose(-1, -2)  # batch x 1 x values_size\n\n        att_list = []\n        for i in range(self.__C.FLAT_GLIMPSES):\n            att_list.append(torch.sum(att[:, :, i: i + 1] * x, dim=1))\n\n        x_atted = torch.cat(att_list, dim=1) # don't need this for continuous attention\n        \n        x_atted=context.squeeze(1) # for continuous softmax/sparsemax\n\n        x_atted = self.linear_merge(x_atted) # linear_merge is used to compute Wx\n        return x_atted\n\n\n\n\n\n# ----------------------------------------------------------------\n# ---- Flatten the sequence (question and discrete attention) ----\n# ----------------------------------------------------------------\n# this is also used to flatten the image features with discrete attention\nclass AttFlatText(nn.Module):\n    def __init__(self, __C, gen_func=torch.softmax):\n        super(AttFlatText, self).__init__()\n        self.__C = __C\n\n        self.gen_func=gen_func\n\n        if str(gen_func)=='tvmax':\n            self.sparsemax = partial(sparsemax, k=512)\n            self.tvmax = TV2DFunction.apply\n\n        self.mlp = MLP(\n            in_size=__C.HIDDEN_SIZE,\n            mid_size=__C.FLAT_MLP_SIZE,\n            out_size=__C.FLAT_GLIMPSES,\n            dropout_r=__C.DROPOUT_R,\n            use_relu=True)\n\n        self.linear_merge = nn.Linear(__C.HIDDEN_SIZE * __C.FLAT_GLIMPSES,__C.FLAT_OUT_SIZE)\n\n    def forward(self, x, x_mask):\n        att = self.mlp(x)\n        att = att.masked_fill(x_mask.squeeze(1).squeeze(1).unsqueeze(2),-1e9)\n\n        if str(self.gen_func)=='tvmax':\n            att = att.squeeze(-1).view(-1,14,14)\n            for i in range(att.size(0)):\n                att[i] = self.tvmax(att[i])\n            att = self.sparsemax(att.view(-1,14*14)).unsqueeze(-1)\n        \n        else:\n            att = self.gen_func(att.squeeze(-1), dim=-1).unsqueeze(-1)\n        att_list = []\n        for i in range(self.__C.FLAT_GLIMPSES):\n            att_list.append(torch.sum(att[:, :, i: i + 1] * x, dim=1))\n\n        x_atted = torch.cat(att_list, dim=1)\n        x_atted = self.linear_merge(x_atted)\n        return x_atted\n\n\n# -------------------------\n# ---- Main MCAN Model ----\n# -------------------------\n\nclass Net(nn.Module):\n    def __init__(self, __C, pretrained_emb, token_size, answer_size, gen_func=torch.softmax):\n        super(Net, self).__init__()\n\n        self.embedding = nn.Embedding(num_embeddings=token_size, embedding_dim=__C.WORD_EMBED_SIZE)\n\n        # Loading the GloVe embedding weights\n        if __C.USE_GLOVE:\n            self.embedding.weight.data.copy_(torch.from_numpy(pretrained_emb))\n\n        self.attention=__C.attention #added this \n\n\n        #if __C.USE_IMG_POS_EMBEDDINGS:\n        #    self.img_pos_x_embeddings = nn.Embedding(num_embeddings=14, embedding_dim=int(__C.HIDDEN_SIZE/2))\n        #    torch.nn.init.xavier_uniform_(self.img_pos_x_embeddings.weight)\n        #    self.img_pos_y_embeddings = nn.Embedding(num_embeddings=14, embedding_dim=int(__C.HIDDEN_SIZE/2))\n        #    torch.nn.init.xavier_uniform_(self.img_pos_y_embeddings.weight)\n        #    self.use_img_pos_embeddings = __C.USE_IMG_POS_EMBEDDINGS\n\n        self.lstm = nn.LSTM(\n            input_size=__C.WORD_EMBED_SIZE,\n            hidden_size=__C.HIDDEN_SIZE,\n            num_layers=1,\n            batch_first=True)\n\n        self.img_feat_linear = nn.Linear(\n            __C.IMG_FEAT_SIZE,\n            __C.HIDDEN_SIZE)\n\n        self.gen_func=gen_func\n        self.backbone = MCA_ED(__C, gen_func)\n\n        if (self.attention=='discrete'):\n            self.attflat_img = AttFlatText(__C, self.gen_func)\n        else: # use continuous attention \n            self.attflat_img = AttFlat(__C, self.gen_func)\n\n        self.attflat_lang = AttFlatText(__C)\n\n        self.proj_norm = LayerNorm(__C.FLAT_OUT_SIZE)\n        self.proj = nn.Linear(__C.FLAT_OUT_SIZE, answer_size)\n\n        \n\n\n    def forward(self, img_feat, ques_ix):\n\n        # Make mask\n        lang_feat_mask = self.make_mask(ques_ix.unsqueeze(2))\n        img_feat_mask = self.make_mask(img_feat)\n\n        # Pre-process Language Feature\n        lang_feat = self.embedding(ques_ix)\n        lang_feat, _ = self.lstm(lang_feat)\n\n        # Pre-process Image Feature\n        img_feat = self.img_feat_linear(img_feat)\n\n        #if self.use_img_pos_embeddings:\n        #    for i in range(img_feat.size(0)):\n        #        pos = torch.LongTensor(np.mgrid[0:14,0:14]).cuda()\n        #        img_feat[i]+=torch.cat([self.img_pos_x_embeddings(pos[0].view(-1)), self.img_pos_y_embeddings(pos[1].view(-1))],1)\n\n        # Backbone Framework\n        lang_feat, img_feat = self.backbone(\n            lang_feat,\n            img_feat,\n            lang_feat_mask,\n            img_feat_mask)\n\n        lang_feat = self.attflat_lang(\n            lang_feat,\n            lang_feat_mask)\n\n        img_feat = self.attflat_img(\n            img_feat,\n            img_feat_mask)\n\n        proj_feat = lang_feat + img_feat\n        proj_feat = self.proj_norm(proj_feat)\n        proj_feat = torch.sigmoid(self.proj(proj_feat))\n\n        return proj_feat\n\n\n    # Masking\n    def make_mask(self, feature):\n        return (torch.sum(torch.abs(feature),dim=-1) == 0).unsqueeze(1).unsqueeze(2)",
    "description": null,
    "url": null
}