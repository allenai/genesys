{
    "acronym": "lssl",
    "title": "Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers",
    "seed_ids": [
        "hippo",
        "transformer"
    ],
    "s2id": "ca9047c78d48b606c4e4f0c456b1dda550de28b2",
    "abstract": "Recurrent neural networks (RNNs), temporal convolutions, and neural differential equations (NDEs) are popular families of deep learning models for time-series data, each with unique strengths and tradeoffs in modeling power and computational efficiency. We introduce a simple sequence model inspired by control systems that generalizes these approaches while addressing their shortcomings. The Linear State-Space Layer (LSSL) maps a sequence $u \\mapsto y$ by simply simulating a linear continuous-time state-space representation $\\dot{x} = Ax + Bu, y = Cx + Du$. Theoretically, we show that LSSL models are closely related to the three aforementioned families of models and inherit their strengths. For example, they generalize convolutions to continuous-time, explain common RNN heuristics, and share features of NDEs such as time-scale adaptation. We then incorporate and generalize recent theory on continuous-time memorization to introduce a trainable subset of structured matrices $A$ that endow LSSLs with long-range memory. Empirically, stacking LSSL layers into a simple deep neural network obtains state-of-the-art results across time series benchmarks for long dependencies in sequential image classification, real-world healthcare regression tasks, and speech. On a difficult speech classification task with length-16000 sequences, LSSL outperforms prior approaches by 24 accuracy points, and even outperforms baselines that use hand-crafted features on 100x shorter sequences.",
    "authors": [
        "Albert Gu",
        "Isys Johnson",
        "Karan Goel",
        "Khaled Kamal Saab",
        "Tri Dao",
        "A. Rudra",
        "Christopher R'e"
    ],
    "venue": "Neural Information Processing Systems",
    "year": 2021,
    "tldr": "A simple sequence model inspired by control systems that generalizes RNN heuristics, temporal convolutions, and neural differential equations while addressing their shortcomings, and introduces a trainable subset of structured matrices that endow LSSLs with long-range memory.",
    "citationCount": 244,
    "influentialCitationCount": 14,
    "code": "\"\"\"Implementation of LSSL module. Succeeded by S4.\"\"\"\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom einops import rearrange, repeat\nfrom omegaconf import DictConfig\n\nfrom src.models.nn import Activation\nfrom src.models.hippo import transition\nfrom src.models.functional.toeplitz import causal_convolution\nfrom src.models.sequence.base import SequenceModule, TransposedModule\nimport src.models.nn.utils as U\n\ncontract = torch.einsum\n\n\n\ndef krylov(L, A, b, c=None, return_power=False):\n    \"\"\"Compute the Krylov matrix (b, Ab, A^2b, ...) using the squaring trick.\n\n    If return_power=True, return A^{L-1} as well\n    \"\"\"\n    # TODO There is an edge case if L=1 where output doesn't get broadcasted, which might be an issue if caller is expecting broadcasting semantics... can deal with it if it arises\n\n    x = b.unsqueeze(-1) # (..., N, 1)\n    A_ = A\n\n    AL = None\n    if return_power:\n        AL = torch.eye(A.shape[-1], dtype=A.dtype, device=A.device)\n        _L = L-1\n\n    done = L == 1\n    # loop invariant: _L represents how many indices left to compute\n    while not done:\n        if return_power:\n            if _L % 2 == 1: AL = A_ @ AL\n            _L //= 2\n\n        # Save memory on last iteration\n        l = x.shape[-1]\n        if L - l <= l:\n            done = True\n            _x = x[..., :L-l]\n        else: _x = x\n\n        _x = A_ @ _x\n        x = torch.cat([x, _x], dim=-1) # there might be a more efficient way of ordering axes\n        if not done: A_ = A_ @ A_\n\n    assert x.shape[-1] == L\n\n    if c is not None:\n        x = torch.einsum('...nl, ...n -> ...l', x, c)\n    x = x.contiguous() # WOW!!\n    if return_power:\n        return x, AL\n    else:\n        return x\n    \ndef linear_system_from_krylov(u, C, D, k):\n    \"\"\"\n    Computes the state-space system y = Cx + Du from Krylov matrix K(A, B)\n\n    u: (L, B, ...) ... = H\n    C: (..., M, N) ... = H\n    D: (..., M)\n    k: (..., N, L) Krylov matrix representing b, Ab, A^2b...\n\n    y: (L, B, ..., M)\n    \"\"\"\n\n\n    # Equivalent ways to perform C @ k, slight speed differences\n    k = C @ k # (..., M, L)\n    # k = torch.einsum('... m n, ... n l -> ... m l', C, k) # C @ k\n    # k = torch.sum(k.unsqueeze(-3) * C.unsqueeze(-1), dim=-2) # (..., M, L) C @ k\n\n    k = rearrange(k, '... m l -> m ... l')\n    k = k.to(u) # if training in half precision, need to go back to float32 for the fft\n    k = k.unsqueeze(1) # (M, 1, ..., L)\n\n    v = u.unsqueeze(-1).transpose(0, -1) # (1, B, ..., L)\n    y = causal_convolution(k, v, fast=True) # (M, B, ..., L)\n    y = y.transpose(0, -1) # (L, B, ..., M)\n    y = y + u.unsqueeze(-1) * D # (L, B, ..., M)\n    return y\n\nclass Platypus(SequenceModule):\n    \"\"\" Implementation of LSSL module.\n    # TODO this expects (length, batch) but this codebase is now (batch, length)\n    \"\"\"\n    requires_length = True\n\n    def __init__(\n            self,\n            d,\n            d_model=-1, # overloading this term, same as memory_order or N\n            measure='legs', # 'legs', 'legt' main ones; can also try 'lagt'\n            measure_args={},\n            learn=0, # 0 means no learn, 1 means same A matrix for each hidden feature H, 2 means different A matrix per feature. 1 does not change parameter count. 2 adds parameters but does not slow down\n            lr=0.0001, # controls learning rate of transition parameters\n            noise=0.0, # injects input noise to the state space system\n            init='normal', # for debugging, but might be useful?\n            dt=None,\n            channels=1, # denoted by M below\n            bias=False,\n            activation='gelu',\n            ff=True,\n            weight_norm=False,\n            dropout=0.0,\n            l_max=-1,\n        ):\n        \"\"\"\n        N: the order of the HiPPO projection\n        dt: discretization step size - should be roughly inverse to the length of the sequence\n        \"\"\"\n        super().__init__()\n        self.d = d\n        self.N = d_model if d_model > 0 else d\n        self.dt = DictConfig({\n            'min' : 0.001,\n            'max' : 0.1,\n            'learn' : False,\n            'lr': 0.001,\n            'init' : 'random',\n        })\n        if dt is not None: self.dt.update(dt)\n        self.ff = ff\n        self.bias = bias\n\n\n        # Construct transition\n        self.learn = learn\n        if self.learn == 0:\n            if measure == 'identity': # for testing\n                A, B = torch.eye(self.N), torch.ones(self.N)\n                self.transition = transition.ManualAdaptiveTransition(self.N, A, B)\n            elif measure == 'random':\n                A = torch.randn(self.N, self.N) / self.N # E[AA^T] = (1/N)I -- empirically I nans out\n                B = torch.ones(self.N) # based on HiPPO matrices; worth trying random, haven't tried\n                self.transition = transition.ManualAdaptiveTransition(self.N, A, B)\n            elif measure == 'legt':\n                # self.transition = transition.LegTAdaptiveTransition(self.N)\n                self.transition = transition.LegTTriDInverseAdaptiveTransition(self.N, **measure_args)\n            elif measure == 'cheb':\n                self.transition = transition.ChebITriDInverseAdaptiveTransition(self.N, **measure_args)\n            elif measure == 'chebii':\n                self.transition = transition.ChebIITriDInverseAdaptiveTransition(self.N, **measure_args)\n            elif measure == 'lagt':\n                self.transition = transition.LagTCumsumAdaptiveTransition(self.N, **measure_args)\n            elif measure == 'glagt':\n                self.transition = transition.GLagTToeplitzAdaptiveTransition(self.N, **measure_args)\n            elif measure == 'legs':\n                self.transition = transition.LegSTriDInverseAdaptiveTransition(self.N, **measure_args)\n            elif measure == 'jac':\n                self.transition = transition.JacTriDInverseAdaptiveTransition(self.N, **measure_args)\n            else:\n                raise NotImplementedError\n        elif self.learn == 1 or self.learn == 2:\n            kwargs = {'trainable': True, 'lr': lr}\n            kwargs.update(measure_args)\n            if self.learn == 2:\n                kwargs['batch'] = (self.d,)\n            if measure == 'random':\n                A = torch.randn(self.N, self.N) / self.N # E[AA^T] = (1/N)I . empirically I doesn't work, dunno why\n                B = torch.ones(self.N) # based on HiPPO matrices; worth trying random, haven't tried\n                self.transition = transition.ManualAdaptiveTransition(self.N, A, B, **kwargs)\n            elif measure == 'legt':\n                self.transition = transition.LegTTriDInverseAdaptiveTransition(self.N, **kwargs)\n            elif measure == 'lagt':\n                self.transition = transition.LagTTriDInverseAdaptiveTransition(self.N, **kwargs)\n            elif measure == 'legs':\n                self.transition = transition.LegSTriDInverseAdaptiveTransition(self.N, **kwargs)\n            elif measure == 'cheb':\n                self.transition = transition.ChebITriDInverseAdaptiveTransition(self.N, **kwargs)\n            elif measure == 'chebii':\n                self.transition = transition.ChebIITriDInverseAdaptiveTransition(self.N, **kwargs)\n            elif measure == 'toep':\n                self.transition = transition.LagTToeplitzAdaptiveTransition(self.N, **kwargs)\n            else: raise NotImplementedError\n        else:\n            raise NotImplementedError\n\n\n        self.m = channels\n\n        if init == 'normal':\n            self.C = nn.Parameter(torch.randn(self.d, self.m, self.N))\n            self.D = nn.Parameter(torch.randn(self.d, self.m))\n        elif init == 'constant':\n            self.C = nn.Parameter(torch.ones(self.d, self.m, self.N))\n            self.D = nn.Parameter(torch.ones(self.d, self.m))\n        elif init == 'uniform':\n            self.C = nn.Parameter(1.732 * torch.rand(self.d, self.m, self.N))\n            self.D = nn.Parameter(torch.randn(self.d, self.m))\n        else: raise NotImplementedError\n        if self.bias:\n            self.E = nn.Parameter(torch.zeros(self.d, self.m))\n\n        if self.dt.init == 'uniform':\n            log_dt = torch.linspace(math.log(self.dt.min), math.log(self.dt.max), self.d)\n        elif self.dt.init == 'random':\n            log_dt = torch.rand(self.d) * (math.log(self.dt.max)-math.log(self.dt.min)) + math.log(self.dt.min)\n        else: raise NotImplementedError\n\n        if self.dt.learn:\n            self.log_dt = nn.Parameter(log_dt) # (H)\n            self.log_dt._lr = self.dt.lr # register the parameter for the optimizer to reduce lr\n        else:\n            self.register_buffer('log_dt', log_dt)\n        self.k = None\n        self.noise = noise\n\n        self.activate = Activation(activation)\n        self.drop = nn.Dropout(dropout)\n\n        if self.ff:\n            self.output_linear = nn.Linear(self.m * self.d, self.d)\n\n            if weight_norm:\n                self.output_linear = nn.utils.weight_norm(self.output_linear)\n\n        # For test time shift\n        self.l_max = l_max\n        self.last_len = -1\n\n    def forward(self, u, *args, state=None, **kwargs):\n        \"\"\"\n        u: (L, B, H) [21-09-29] Our backbone now passes inputs as (B, L, H). This calss originally expected (L, B, H) so we transpose accordingly\n        state: (B, H, N) previous hidden state of the recurrence\n        \"\"\"\n        next_state = None\n\n        u = u.transpose(0, 1)\n\n        # Construct dt (H)\n        dt = torch.exp(self.log_dt) # Note: if dt is not learnable this slightly wastes computation, but it isn't a bottleneck\n\n        ## # Calculate test-time shift\n        # changed sampling rate; uncache Krylov\n        if self.last_len != u.shape[0]:\n            self.k = None\n            self.last_len = u.shape[0]\n        # Calculate change from train sampling rate\n        if self.l_max > 0:\n            rate = self.l_max / u.shape[0]\n            # if rate != 1.0: dt = dt * rate\n            if rate != 1.0: rate = round(rate)\n            else: rate = None\n        else:\n            rate = None\n\n\n        # We need to compute the \"recurrence\" if\n        # (*) there is noise or an initial state\n        # (*) we're learning the system A, B\n        # (*) first pass\n        kb = [] # will store the B vectors for Krylov computation\n        _learn = (self.dt.learn or self.learn) and self.training # need to learn and it's training time # TODO this ignores the last training minibatch if no test time shift (prev batch's K gets cached)... should recalculate A in the last_len check ideally\n        _conv = _learn or self.k is None or u.shape[0] > self.k.shape[-1] # or rate\n        _noise = self.noise > 0.0 and self.training\n        if _conv:\n            B = self.transition.gbt_B(dt) # (..., N) depending if learn=2\n            kb.append(B)\n        if _noise:\n            noise = self.noise * torch.randn(self.d, self.N, dtype=u.dtype, device=u.device) # (H, N)\n            kb.append(noise)\n\n        A = None\n        if len(kb) > 0:\n            if rate is not None:\n                dt = dt * rate\n\n            A = self.transition.gbt_A(dt) # (..., N, N) (..., N)\n\n            # Adjust by rate\n            # if _conv and rate is not None:\n            #     while rate > 1:\n            #         B = B + torch.sum(A * B.unsqueeze(-2), dim=-1) # (I + A) @ B\n            #         A = A @ A\n            #         rate //= 2\n\n            kb = [b.broadcast_to(dt.shape+(self.N,)) for b in kb]\n            kb = torch.stack(torch.broadcast_tensors(*kb), dim=0) # each (..., N)\n            krylovs = krylov(u.shape[0], A, kb) # (H, N, L) each\n            k_noise, k_conv = torch.split(\n                krylovs,\n                split_size_or_sections=[int(_noise), int(_conv)],\n                dim=0\n            )\n            if _conv: # Cache the Krylov matrix K(A, B)\n                self.k = k_conv.squeeze(0) # (H, N, L)\n            if _noise:\n                k_noise = k_noise.squeeze(0) # (H, N, L)\n\n        # Convolution\n        y = linear_system_from_krylov(u, self.C, self.D, self.k[..., :u.shape[0]]) # (L, B, H, M)\n        if _noise:\n            k_noise = torch.cumsum(k_noise, dim=-1) # (H, N, L) w + Aw + A^2w + ...\n            k_noise = contract('h m n, h n l -> l h m', self.C, k_noise) # C @ k\n            y = y + k_noise.unsqueeze(1) # (L, B, H, M)\n            y = y + self.noise * torch.randn(y.shape, dtype=u.dtype, device=u.device)\n\n        # State needs a special case because it has a batch dimension\n        if state is not None: # (B, H, N)\n            if A is None: A = self.transition.gbt_A(dt) # (..., N, N) (..., N)\n\n            ATC, ATL = krylov(u.shape[0], A.transpose(-1,-2), self.C.transpose(0, 1), return_power=True) # (M, H, N, L), (H, N, N) represents A^T C and (A^T)^L\n            y = y + contract('mhnl, bhn -> lbhm', ATC, state)\n\n            # Compute next state\n            with torch.no_grad():\n                next_state = contract('hnp, bhn -> bhp', ATL, state)\n                if _noise:\n                    next_state = next_state + k_noise[..., -1]\n                next_state = next_state + contract('lbh, hnl -> bhn', u.flip(0), self.k[:..., u.shape[0]]) # (B, H, N)\n                next_state = contract('hnp, bhp -> bhn', A, next_state)\n                next_state = next_state.detach() # TODO necessary?\n\n            # Debugging code useful for checking if state computation is correct\n            # from models.functional.unroll import variable_unroll_sequential, variable_unroll\n            # B = self.transition.gbt_B(dt)\n            # inps = B*u.unsqueeze(-1) # (L, B, H, N)\n            # inps[0] = inps[0] + state\n            # xx = variable_unroll(A, inps, variable=False)\n            # yy = torch.sum(self.C * xx.unsqueeze(-2), dim=-1)\n            # yy = yy + u.unsqueeze(-1) * self.D # true output y; should equal y\n            # xx_ = variable_unroll(A, B*u.unsqueeze(-1), variable=False)\n            # yy_ = torch.sum(self.C * xx_.unsqueeze(-2), dim=-1)\n            # yy_ = yy_ + u.unsqueeze(-1) * self.D # output without state; should equal y before the C A^T S term was added\n            # ss = (A @ xx[-1].unsqueeze(-1)).squeeze(-1) # should equal next_state\n            # breakpoint()\n            # y = z\n\n        # bias term\n        if self.bias:\n            y = y + self.E\n\n        y = self.drop(self.activate(y))\n\n        y = rearrange(y, 'l b h m -> l b (h m)') # (L, B, H*M)\n\n        if self.ff:\n            y = self.output_linear(y) # (L, B, H)\n        y = y.transpose(0, 1) # Back to (B, L, H) as expected\n        return y, next_state\n\n    def is_initialized(self):\n        return self.k is not None\n\n    def initialize(self, shared_params):\n        if 'k' in shared_params:\n            self.k = shared_params['k']\n        else:\n            dt = torch.exp(self.log_dt)\n            A = self.transition.gbt_A(dt) # (..., N, N)\n            B = self.transition.gbt_B(dt) # (..., N)\n            self.k = krylov(1024, A, B) # (L, H, N) each\n            shared_params['k'] = self.k\n\n    def default_state(self, *batch_shape, device=None):\n        return torch.zeros(*batch_shape, self.N, device=device)\n\n    def step(self, x, state):\n        raise NotImplementedError(\"Needs to be implemented.\")\n\n    @property\n    def d_state(self):\n        return self.d\n\n    @property\n    def d_output(self):\n        return self.d\n\n    @property\n    def state_to_tensor(self):\n        return lambda state: state\n\nLSSL = TransposedModule(Platypus)",
    "description": null,
    "url": null
}