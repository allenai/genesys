{
    "acronym": "memorizingtrans",
    "title": "Memorizing Transformers",
    "seed_ids": [
        "htransformer1d",
        "performer",
        "bigbird",
        "linformer",
        "longformer",
        "routingtransformer",
        "reformer",
        "transformerxl"
    ],
    "s2id": "0e802c0739771acf70e60d59c2df51cd7e8c50c0",
    "abstract": "Language models typically need to be trained or finetuned in order to acquire new knowledge, which involves updating their weights. We instead envision language models that can simply read and memorize new data at inference time, thus acquiring new knowledge immediately. In this work, we extend language models with the ability to memorize the internal representations of past inputs. We demonstrate that an approximate kNN lookup into a non-differentiable memory of recent (key, value) pairs improves language modeling across various benchmarks and tasks, including generic webtext (C4), math papers (arXiv), books (PG-19), code (Github), as well as formal theorems (Isabelle). We show that the performance steadily improves when we increase the size of memory up to 262K tokens. On benchmarks including code and mathematics, we find that the model is capable of making use of newly defined functions and theorems during test time.",
    "authors": [
        "Yuhuai Wu",
        "M. Rabe",
        "DeLesley S. Hutchins",
        "Christian Szegedy"
    ],
    "venue": "International Conference on Learning Representations",
    "year": 2022,
    "tldr": "It is demonstrated that an approximate kNN lookup into a non-differentiable memory of recent (key, value) pairs improves language modeling across various benchmarks and tasks, including generic webtext, math papers, books, code, as well as formal theorems (Isabelle).",
    "citationCount": 138,
    "influentialCitationCount": 15,
    "code": "import math\nfrom functools import partial\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom filelock import FileLock\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn, einsum\n\nfrom einops import rearrange, repeat\nfrom einops_exts import repeat_many\nfrom einops.layers.torch import Rearrange\n\nimport os\nimport faiss\nimport numpy as np\nfrom pathlib import Path\n\nfrom contextlib import ExitStack, contextmanager\n\nfrom einops import rearrange, pack, unpack\n\nfrom .modules import KNN, FeedForward, Attention, PreNormResidual, T5RelativePositionBias\nfrom .utils import exists, default, cast_list, unique, all_el_unique, check_shape, l2norm, cpu_count, multi_context, cast_tuple\n\n# multiprocessing\n\nfrom joblib import Parallel, delayed, cpu_count\n\n# constants\n\nFAISS_INDEX_GPU_ID = int(os.getenv('FAISS_INDEX_GPU_ID', 0))\n\nDEFAULT_KNN_MEMORY_MEMMAP_DIRECTORY = './.tmp/knn.memories'\n\n# KNN memory layer, where one can store key / value memories\n# can automatically take care of a collection of faiss indices (across batch dimension)\n\nclass KNNMemory():\n    def __init__(\n        self,\n        dim,\n        max_memories = 16000,\n        num_indices = 1,\n        memmap_filename = './knn.memory.memmap',\n        multiprocessing = True\n    ):\n        self.dim = dim\n        self.num_indices = num_indices\n        self.scoped_indices = list(range(num_indices))\n\n        self.max_memories = max_memories\n        self.shape = (num_indices, max_memories, 2, dim)\n        self.db_offsets = np.zeros(num_indices, dtype = np.int32)\n\n        self.db = np.memmap(memmap_filename, mode = 'w+', dtype = np.float32, shape = self.shape)\n        self.knns = [KNN(dim = dim, max_num_entries = max_memories, cap_num_entries = True) for _ in range(num_indices)]\n    \n        self.n_jobs = cpu_count() if multiprocessing else 1\n\n    def set_scoped_indices(self, indices):\n        indices = list(indices)\n        assert all_el_unique(indices), f'all scoped batch indices must be unique, received: {indices}'\n        assert all([0 <= i < self.num_indices for i in indices]), f'each batch index must be between 0 and less than {self.num_indices}: received {indices}'\n        self.scoped_indices = indices\n\n    @contextmanager\n    def at_batch_indices(self, indices):\n        prev_indices = self.scoped_indices\n        self.set_scoped_indices(indices)\n        yield self\n        self.set_scoped_indices(prev_indices)\n\n    def clear(self, batch_indices = None):\n        if not exists(batch_indices):\n            batch_indices = list(range(self.num_indices))\n\n        batch_indices = cast_list(batch_indices)\n\n        for index in batch_indices:\n            knn = self.knns[index]\n            knn.reset()\n\n        self.db_offsets[batch_indices] = 0\n\n    def add(self, memories):\n        check_shape(memories, 'b n kv d', d = self.dim, kv = 2, b = len(self.scoped_indices))\n\n        memories = memories.detach().cpu().numpy()\n        memories = memories[:, -self.max_memories:]\n        num_memories = memories.shape[1]\n\n        knn_insert_ids = np.arange(num_memories)\n\n        keys = np.ascontiguousarray(memories[..., 0, :])\n        knns = [self.knns[i] for i in self.scoped_indices]\n        db_offsets = [self.db_offsets[i] for i in self.scoped_indices]\n\n        # use joblib to insert new key / value memories into faiss index\n\n        @delayed\n        def knn_add(knn, key, db_offset):\n            knn.add(key, ids = knn_insert_ids + db_offset)\n            return knn\n\n        updated_knns = Parallel(n_jobs = self.n_jobs)(knn_add(*args) for args in zip(knns, keys, db_offsets))\n        for knn_idx, scoped_idx in enumerate(self.scoped_indices):\n            self.knns[scoped_idx] = updated_knns[knn_idx]\n\n        # add the new memories to the memmap \"database\"\n\n        add_indices = (rearrange(np.arange(num_memories), 'j -> 1 j') + rearrange(self.db_offsets[list(self.scoped_indices)], 'i -> i 1')) % self.max_memories\n        self.db[rearrange(np.array(self.scoped_indices), 'i -> i 1'), add_indices] = memories\n        self.db.flush()\n\n        self.db_offsets += num_memories\n\n    def search(\n        self,\n        queries,\n        topk,\n        nprobe = 8,\n        increment_hits = True,\n        increment_age = True\n    ):\n        check_shape(queries, 'b ... d', d = self.dim, b = len(self.scoped_indices))\n        queries, ps = pack([queries], 'b * d')\n\n        device = queries.device\n        queries = queries.detach().cpu().numpy()\n\n        all_masks = []\n        all_key_values = []\n\n        knns = [self.knns[i] for i in self.scoped_indices]\n\n        # parallelize faiss search\n\n        @delayed\n        def knn_search(knn, query):\n            return knn.search(query, topk, nprobe, increment_hits = increment_hits, increment_age = increment_age)\n\n        fetched_indices = Parallel(n_jobs = self.n_jobs)(knn_search(*args) for args in zip(knns, queries))\n\n        # get all the memory key / values from memmap 'database'\n        # todo - remove for loop below\n\n        for batch_index, indices in zip(self.scoped_indices, fetched_indices):\n            mask = indices !=  -1\n            db_indices = np.where(mask, indices, 0)\n\n            all_masks.append(torch.from_numpy(mask))\n\n            key_values = self.db[batch_index, db_indices % self.max_memories]\n            all_key_values.append(torch.from_numpy(key_values))\n\n        all_masks = torch.stack(all_masks)\n        all_key_values = torch.stack(all_key_values)\n        all_key_values = all_key_values.masked_fill(~rearrange(all_masks, '... -> ... 1 1'), 0.)\n\n        all_key_values, = unpack(all_key_values, ps, 'b * n kv d')\n        all_masks, = unpack(all_masks, ps, 'b * n')\n\n        return all_key_values.to(device), all_masks.to(device)\n\n    def __del__(self):\n        if hasattr(self, 'knns'):\n            for knn in self.knns:\n                del knn\n        del self.db\n\n# extends list with some extra methods for collections of KNN memories\n\nclass KNNMemoryList(list):\n    def cleanup(self):\n        for memory in self:\n            del memory\n\n    @classmethod\n    def create_memories(\n        self,\n        *,\n        batch_size,\n        num_memory_layers,\n        memories_directory = DEFAULT_KNN_MEMORY_MEMMAP_DIRECTORY\n    ):\n        memories_path = Path(memories_directory)\n        memories_path.mkdir(exist_ok = True, parents = True)\n\n        def inner(*args, **kwargs):\n            return self([KNNMemory(*args, num_indices = batch_size, memmap_filename = str(memories_path / f'knn.memory.layer.{ind + 1}.memmap'), **kwargs) for ind in range(num_memory_layers)])\n        return inner\n\n    @contextmanager\n    def at_batch_indices(\n        self,\n        indices\n    ):\n        knn_batch_indices_contexts = [memory.at_batch_indices(indices) for memory in self]\n        with multi_context(*knn_batch_indices_contexts):\n            yield\n\n    def clear_memory(\n        self,\n        batch_indices = None,\n        memory_indices = None\n    ):\n        memory_indices = default(memory_indices, tuple(range(len(self))))\n\n        for memory_index in memory_indices:\n            memory = self[memory_index]\n            memory.clear(batch_indices)\n\n\n# approximate nearest neighbor attention\n\nclass KNNAttention(nn.Module):\n    def __init__(\n        self,\n        *,\n        dim,\n        heads = 8,\n        dim_head = 64,\n        dropout = 0.,\n        num_retrieved_memories = 32,\n        xl_max_memories = 0.,\n        attn_scale_init = 20,\n        gate_output = False\n    ):\n        super().__init__()\n        self.heads = heads\n        self.scale = nn.Parameter(torch.ones(heads, 1, 1) * math.log(attn_scale_init))\n\n        inner_dim = heads * dim_head\n        self.xl_max_memories = xl_max_memories\n\n        self.num_retrieved_memories = num_retrieved_memories\n\n        self.dropout = nn.Dropout(dropout)\n        self.knn_mem_dropout = nn.Dropout(dropout)\n\n        self.to_q = nn.Linear(dim, inner_dim, bias = False)\n        self.to_kv = nn.Linear(dim, dim_head * 2, bias = False)\n        self.to_out = nn.Linear(inner_dim, dim, bias = False)\n\n        self.output_gate = nn.Parameter(torch.zeros(1)) if gate_output else None\n\n    def forward(\n        self,\n        x,\n        *,\n        knn_memory,\n        xl_memory = None,\n        add_knn_memory = True,\n        rel_pos_bias = None\n    ):\n        b, n, h, device = *x.shape[:2], self.heads, x.device\n        q, k, v = (self.to_q(x), *self.to_kv(x).chunk(2, dim = -1))\n\n        q = rearrange(q, 'b n (h d) -> b h n d', h = h)\n\n        # in paper, they showed normalizing of keys led to more stable training\n        # we'll just go with full cosine sim attention https://arxiv.org/abs/2010.04245\n\n        q, k = map(l2norm, (q, k))\n\n        # handle xl memory\n\n        if exists(xl_memory):\n            k_xl_mem, v_xl_mem = xl_memory.unbind(dim = -2)\n            k = torch.cat((k_xl_mem, k), dim = -2)\n            v = torch.cat((v_xl_mem, v), dim = -2)\n\n        # calculate local attention\n\n        scale = self.scale.exp()\n\n        sim = einsum('b h i d, b j d -> b h i j', q, k) * scale\n        i, j = sim.shape[-2:]\n\n        if exists(rel_pos_bias):\n            sim = rel_pos_bias[..., -i:, -j:] + sim\n\n        mask_value = -torch.finfo(sim.dtype).max\n\n        causal_mask = torch.ones((i, j), dtype = torch.bool, device = device).triu(j - i + 1)\n        sim = sim.masked_fill(causal_mask, mask_value)\n\n        # calculate knn attention over memory, if index is passed in\n\n        mem_kv, mem_mask = knn_memory.search(q, self.num_retrieved_memories)\n        mem_k, mem_v = mem_kv.unbind(dim = -2)\n\n        sim_mem = einsum('b h i d, b h i j d -> b h i j', q, mem_k) * scale\n        sim_mem = sim_mem.masked_fill(~mem_mask, mask_value)\n\n        # calculate new XL memories, as well as memories to be discarded\n\n        new_kv_memories = torch.stack((k, v), dim = -2).detach()\n\n        if self.xl_max_memories > 0:\n            new_kv_memories_discarded, new_xl_kv_memories = new_kv_memories[:, :-self.xl_max_memories], new_kv_memories[:, -self.xl_max_memories:]\n        else:\n            new_kv_memories_discarded, new_xl_kv_memories = new_kv_memories, None\n\n        # add memories to be discarded into KNN memory\n\n        if add_knn_memory and new_kv_memories_discarded.numel() > 0:\n            knn_memory.add(new_kv_memories_discarded)\n\n        # attention (combining local and distant)\n\n        sim = torch.cat((sim_mem, sim), dim = -1)\n        attn = sim.softmax(dim = -1)\n        attn = self.dropout(attn)\n\n        local_attn, mem_attn = attn[..., self.num_retrieved_memories:], attn[..., :self.num_retrieved_memories]\n        local_out = einsum('b h i j, b j d -> b h i d', local_attn, v)\n        mem_out = einsum('b h i j, b h i j d -> b h i d', mem_attn, mem_v)\n\n        out = local_out + mem_out\n\n        # combine heads and project out\n\n        out = rearrange(out, 'b h n d -> b n (h d)')\n        out = self.to_out(out)\n\n        # use flamingo styled gating of output, so that memorizing transformers can be gated into an existing LLM\n        # preparation to add this to block-recurrent-transformer-pytorch, for the pinnacle of long context attention network\n\n        if exists(self.output_gate):\n            out = out * self.output_gate.tanh()\n\n        return out, new_xl_kv_memories\n\n# main class\n\nclass MemorizingTransformer(nn.Module):\n    def __init__(\n        self,\n        *,\n        num_tokens,\n        dim,\n        depth,\n        dim_head = 64,\n        heads = 8,\n        knn_attn_heads = None,\n        attn_dropout = 0.,\n        ff_mult = 4,\n        ff_dropout = 0.,\n        memorizing_layers = None,\n        max_knn_memories = 250000,\n        num_retrieved_memories = 32,\n        clear_memories_on_sos_token_id = None,\n        clear_memories_on_eos_token_id = None,\n        knn_memories_directory = DEFAULT_KNN_MEMORY_MEMMAP_DIRECTORY,\n        shift_knn_memories_down = 0.,\n        pad_id = 0,\n        xl_max_memories = 0,\n        xl_memory_layers = None,\n        shift_xl_memories_down = 0.,\n        knn_memory_multiprocessing = False\n    ):\n        super().__init__()\n        self.token_emb = nn.Embedding(num_tokens, dim)\n        self.pad_id = pad_id\n\n        block_wrapper = partial(PreNormResidual, dim)\n        valid_layers = set(range(1, depth + 1))\n\n        memorizing_layers = default(memorizing_layers, (depth // 2,)) # default KNN attention layer to midpoint of transformer\n        memorizing_layers = cast_tuple(memorizing_layers)\n        memorizing_layers = tuple(filter(lambda i: i in valid_layers, memorizing_layers))\n\n        self.dim_head = dim_head\n\n        knn_attn_heads = default(knn_attn_heads, heads)\n\n        # xl memory hyperparameter\n\n        if xl_max_memories > 0:\n            xl_memory_layers = default(xl_memory_layers, tuple(range(1, depth + 1)))\n            xl_memory_layers = unique(xl_memory_layers)\n            self.xl_memory_layers = tuple(filter(lambda i: i in valid_layers, xl_memory_layers))            \n            self.num_xl_memory_layers = len(self.xl_memory_layers)\n        else:\n            self.xl_memory_layers = tuple()\n            self.num_xl_memory_layers = 0\n\n        # knn memory hyperparameters\n\n        self.max_knn_memories = max_knn_memories\n        self.knn_memories_directory = knn_memories_directory\n        self.memorizing_layers = unique(memorizing_layers)\n        self.num_memory_layers = len(memorizing_layers)\n\n        self.clear_memories_on_sos_token_id = clear_memories_on_sos_token_id\n        self.clear_memories_on_eos_token_id = clear_memories_on_eos_token_id\n\n        # relative positional bias\n\n        self.rel_pos_bias = T5RelativePositionBias(scale = dim_head ** 0.5, heads = heads)\n        self.knn_rel_pos_bias = T5RelativePositionBias(scale = dim_head ** 0.5, heads = heads)\n\n        # layers\n\n        self.layers = nn.ModuleList([])\n        for idx in range(depth):\n            layer_num = idx + 1\n\n            use_xl_memories = layer_num in self.xl_memory_layers\n            use_knn_attention = layer_num in memorizing_layers\n            xl_max_memories_layer = 0 if not use_xl_memories else xl_max_memories\n\n            if use_knn_attention:\n                attn = KNNAttention(dim = dim, dim_head = dim_head, heads = knn_attn_heads, dropout = attn_dropout, num_retrieved_memories = num_retrieved_memories, xl_max_memories = xl_max_memories_layer)\n            else:\n                attn = Attention(dim = dim, dim_head = dim_head, heads = heads, dropout = attn_dropout, xl_max_memories = xl_max_memories_layer)\n\n            self.layers.append(nn.ModuleList([\n                block_wrapper(attn),\n                block_wrapper(FeedForward(dim = dim, mult = ff_mult, dropout = ff_dropout)),\n            ]))\n\n        # memory layer shifting\n        # from a little known paper https://arxiv.org/abs/2012.15688\n\n        self.shift_knn_memories_down = shift_knn_memories_down\n        self.shift_xl_memories_down = shift_xl_memories_down\n\n        # to logits\n\n        self.to_logits = nn.Sequential(\n            nn.LayerNorm(dim),\n            nn.Linear(dim, num_tokens)\n        )\n\n        # knn memories init\n\n        self.knn_mem_kwargs = dict(\n            dim = self.dim_head,\n            max_memories = self.max_knn_memories,\n            multiprocessing = knn_memory_multiprocessing\n        )\n\n    def create_knn_memories(\n        self,\n        *,\n        batch_size\n    ):\n        return KNNMemoryList.create_memories(\n            batch_size = batch_size,\n            num_memory_layers = self.num_memory_layers,\n            memories_directory = self.knn_memories_directory,\n        )(**self.knn_mem_kwargs)\n\n    @contextmanager\n    def knn_memories_context(\n        self,\n        **kwargs\n    ):\n        knn_dir = Path(self.knn_memories_directory)\n        knn_dir.mkdir(exist_ok = True, parents = True)\n        lock = FileLock(str(knn_dir / 'mutex'))\n\n        with lock:\n            knn_memories = self.create_knn_memories(**kwargs)\n            yield knn_memories\n            knn_memories.cleanup()\n\n    def clear_memory(self, x, token_id):\n        \"\"\" clears the KNN memories based on if the batch row contains the specified token id \"\"\"\n        \"\"\" for auto-clearing KNN memories based on start and end of strings \"\"\"\n\n        clear_memory = (x == token_id).any(dim = -1)\n        batch_indices, _ = clear_memory.nonzero(as_tuple = True)\n        batch_indices_to_clear = batch_indices.tolist()\n\n        if len(batch_indices_to_clear) == 0:\n            return\n\n        knn_memories.clear_memory(batch_indices_to_clear)\n\n    def forward(\n        self,\n        x,\n        knn_memories,\n        xl_memories = None,\n        labels = None,\n        add_knn_memory = True\n    ):\n        batch_size, seq_len, *_, device = *x.shape, x.device\n        x = self.token_emb(x)\n\n        # validate KNN memories to have enough indices for batch size\n\n        assert all([memory.num_indices == batch_size for memory in knn_memories]), f'you passed in an input with batch size {batch_size} but your memories were not instantiated with that number of KNN indices'\n\n        # if KNN memories are passed in, and researcher wants memories auto-cleared on <sos> token detection\n        # do the appropriate logic\n\n        if exists(self.clear_memories_on_sos_token_id):\n            self.clear_memory(x, self.clear_memories_on_sos_token_id)\n\n        # handle XL memories\n\n        xl_memories = default(xl_memories, (None,) * self.num_xl_memory_layers)\n        assert len(xl_memories) == self.num_xl_memory_layers\n        has_xl_memories = len(xl_memories) > 0\n\n        # shifting memories a number of layers down, little known technique shown to enhance memories from Ernie-Doc paper\n\n        if len(knn_memories) > 0 and self.shift_knn_memories_down > 0:\n            knn_memories = [*knn_memories[self.shift_knn_memories_down:], *knn_memories[:self.shift_knn_memories_down]]\n\n        if len(xl_memories) > 0 and self.shift_xl_memories_down > 0:\n            xl_memories = [*xl_memories[self.shift_xl_memories_down:], *xl_memories[:self.shift_xl_memories_down]]\n\n        # iterate through the memories in order of the ascending layers that contain KNNAttention\n\n        xl_memories_iter = iter(xl_memories)\n        knn_memories_iter = iter(knn_memories)\n\n        # positional bias\n\n        max_context_len = max([seq_len, *map(lambda t: (t.shape[-3] if exists(t) else 0) + seq_len, xl_memories)])\n\n        rel_pos_bias = self.rel_pos_bias(seq_len, max_context_len, device = device)\n        knn_rel_pos_bias = self.knn_rel_pos_bias(seq_len, max_context_len, device = device)\n\n        # keep track of new xl memories\n\n        new_xl_memories = [] if has_xl_memories else None\n\n        # go through all layers\n\n        for ind, (attn, ff) in enumerate(self.layers):\n            layer_num = ind + 1\n\n            is_memorizing_layer = layer_num in self.memorizing_layers\n            is_xl_memory_layer = layer_num in self.xl_memory_layers\n\n            attn_kwargs = dict(rel_pos_bias = rel_pos_bias if not is_memorizing_layer else knn_rel_pos_bias)\n\n            if is_memorizing_layer:\n                attn_kwargs = {**attn_kwargs, 'knn_memory': next(knn_memories_iter), 'add_knn_memory': add_knn_memory}\n\n            if is_xl_memory_layer:\n                attn_kwargs = {**attn_kwargs, 'xl_memory': next(xl_memories_iter)}\n\n            # attention\n\n            x, xl_mem = attn(x, **attn_kwargs)\n\n            # add new XL memories if needed\n\n            if exists(xl_mem):\n                new_xl_memories.append(xl_mem)\n\n            # feedforward\n\n            x = ff(x)\n\n        # to logits\n\n        logits = self.to_logits(x)\n\n        # auto-clear KNN memories on end of string token\n\n        if exists(self.clear_memories_on_eos_token_id):\n            self.clear_memory(x, self.clear_memories_on_eos_token_id)\n\n        # for training\n\n        if not exists(labels):\n            if exists(new_xl_memories):\n                return logits, new_xl_memories\n\n            return logits\n\n        loss = F.cross_entropy(rearrange(logits, 'b n c -> b c n'), labels, ignore_index = self.pad_id)\n\n        if exists(new_xl_memories):\n            return loss, new_xl_memories\n\n        return loss",
    "description": null,
    "url": null
}