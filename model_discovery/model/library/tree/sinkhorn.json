{
    "acronym": "sinkhorn",
    "title": "Sparse Sinkhorn Attention",
    "seed_ids": [
        "sparsetransformer"
    ],
    "s2id": "34a4e6818d680875ff0bef9a76de0376118446d1",
    "abstract": "We propose Sparse Sinkhorn Attention, a new efficient and sparse method for learning to attend. Our method is based on differentiable sorting of internal representations. Concretely, we introduce a meta sorting network that learns to generate latent permutations over sequences. Given sorted sequences, we are then able to compute quasi-global attention with only local windows, improving the memory efficiency of the attention module. To this end, we propose new algorithmic innovations such as Causal Sinkhorn Balancing and SortCut, a dynamic sequence truncation method for tailoring Sinkhorn Attention for encoding and/or decoding purposes. Via extensive experiments on algorithmic seq2seq sorting, language modeling, pixel-wise image generation, document classification and natural language inference, we demonstrate that our memory efficient Sinkhorn Attention method is competitive with vanilla attention and consistently outperforms recently proposed efficient Transformer models such as Sparse Transformers.",
    "authors": [
        "Yi Tay",
        "Dara Bahri",
        "Liu Yang",
        "Donald Metzler",
        "Da-Cheng Juan"
    ],
    "venue": "International Conference on Machine Learning",
    "year": 2020,
    "tldr": "This work introduces a meta sorting network that learns to generate latent permutations over sequences and is able to compute quasi-global attention with only local windows, improving the memory efficiency of the attention module.",
    "citationCount": 285,
    "influentialCitationCount": 36,
    "code": "import math\nimport torch\nfrom torch import nn\nfrom operator import mul\nfrom math import gcd\nimport torch.nn.functional as F\nfrom inspect import isfunction\nfrom functools import partial, wraps, reduce\n\nfrom local_attention import LocalAttention\n\n# helper functions\n\ndef default(x, d):\n    if x is None:\n        return d if not isfunction(d) else d()\n    return x\n\ndef divisible_by(num, divisor):\n    return num % divisor == 0\n\ndef all_none(*arr):\n    return all(el is None for el in arr)\n\ndef rotate_left(t, n, dim=0):\n    pre_slices = (slice(None),) * dim\n    l = (*pre_slices, slice(n, None))\n    r = (*pre_slices, slice(0, n))\n    return torch.cat((t[l], t[r]), dim=dim)\n\ndef rotate_right(t, n, dim=0):\n    pre_slices = (slice(None),) * dim\n    l = (*pre_slices, slice(-n, None))\n    r = (*pre_slices, slice(None, -n))\n    return torch.cat((t[l], t[r]), dim=dim)\n\ndef merge_dims(ind_from, ind_to, tensor):\n    shape = list(tensor.shape)\n    arr_slice = slice(ind_from, ind_to + 1)\n    shape[arr_slice] = [reduce(mul, shape[arr_slice])]\n    return tensor.reshape(*shape)\n\ndef merge_heads(h, v):\n    b, t, d = v.shape\n    return v.view(b, t, h, -1).transpose(1, 2).reshape(b, h, t, -1)\n\ndef split_heads(h, v):\n    *_, t, d = v.shape\n    return v.view(-1, h, t, d).transpose(1, 2).reshape(-1, t, d * h)\n\ndef split_at_index(dim, index, t):\n    pre_slices = (slice(None),) * dim\n    l = (*pre_slices, slice(None, index))\n    r = (*pre_slices, slice(index, None))\n    return t[l], t[r]\n\ndef bucket(buckets, t, dim=1):\n    shape = list(t.shape)\n    shape[dim:dim+1] = [buckets, -1]\n    return t.reshape(*shape)\n\ndef unbucket(t, dim=1):\n    shape = list(t.shape)\n    shape[dim:dim+2] = [-1]\n    return t.reshape(*shape)\n\ndef sample_gumbel(shape, device, dtype, eps=1e-6):\n    u = torch.empty(shape, device=device, dtype=dtype).uniform_(0, 1)\n    return -log(-log(u, eps), eps)\n\ndef sinkhorn_sorting_operator(r, n_iters=8):\n    n = r.shape[1]\n    for _ in range(n_iters):\n        r = r - torch.logsumexp(r, dim=2, keepdim=True)\n        r = r - torch.logsumexp(r, dim=1, keepdim=True)\n    return torch.exp(r)\n\ndef reorder_buckets(t, r):\n    return torch.einsum('buv,bvtd->butd', r, t)\n\ndef log(t, eps = 1e-6):\n    return torch.log(t + eps)\n\ndef max_neg_value(tensor):\n    return -torch.finfo(tensor.dtype).max\n\ndef cumavg(t, dim):\n    r = torch.arange(1, t.shape[dim] + 1, device=t.device, dtype=t.dtype)\n    expand_slice = [None] * len(t.shape)\n    expand_slice[dim] = slice(None, None)\n    return t.cumsum(dim=dim) / r[tuple(expand_slice)]\n\ndef batched_index_select(values, indices):\n    last_dim = values.shape[-1]\n    return values.gather(1, indices[:, :, None].expand(-1, -1, last_dim))\n\ndef expand_dim(t, dim, k):\n    expand_shape = [-1] * len(t.shape)\n    expand_shape[dim] = k\n    return t.expand(*expand_shape)\n\ndef expand_batch_and_merge_head(b, t):\n    shape = list(t.squeeze(0).shape)\n    t = expand_dim(t, 0, b)\n    shape[0] = shape[0] * b\n    return t.reshape(*shape)\n\ndef differentiable_topk(x, k, temperature=1.):\n    *_, n, dim = x.shape\n    topk_tensors = []\n\n    for i in range(k):\n        is_last = i == (k - 1)\n        values, indices = (x / temperature).softmax(dim=-1).topk(1, dim=-1)\n        topks = torch.zeros_like(x).scatter_(-1, indices, values)\n        topk_tensors.append(topks)\n        if not is_last:\n            x.scatter_(-1, indices, float('-inf'))\n\n    topks = torch.cat(topk_tensors, dim=-1)\n    return topks.reshape(*_, k * n, dim)\n\n\n# causal sort net and reordered bucketing attention\n\ndef mask_reordering_matrix(R, topk, temperature):\n    buckets = R.shape[1]\n\n    mask_value = max_neg_value(R)\n    mask = torch.zeros(R.shape, device=R.device).bool()\n    i, j = torch.triu_indices(buckets, buckets)\n    mask[:, i, j + topk] = True\n\n    R.masked_fill_(mask, mask_value)\n    return differentiable_topk(R, topk, temperature)\n\nclass CausalSimpleSortNet(nn.Module):\n    def __init__(self, heads, bucket_size, max_buckets, n_top_buckets, dim, temperature):\n        super().__init__()\n        self.dim = dim\n        self.heads = heads\n        self.bucket_size = bucket_size\n        self.max_buckets = max_buckets\n        self.n_top_buckets = n_top_buckets\n        self.temperature = temperature\n        self.linear = nn.Parameter(torch.randn(1, heads, dim, max_buckets + n_top_buckets))\n        self.act = nn.LeakyReLU()\n\n    def forward(self, q, k, topk=1):\n        bh, *_, h, max_buckets = *q.shape, self.heads, self.max_buckets\n        b = bh // h\n        buckets = k.shape[1] // self.bucket_size\n\n        k_r = torch.cat((cumavg(k, dim=1), k), dim=-1)\n        k_r = bucket(buckets, k_r)\n\n        # for causal sort net, take the first token of each bucket to prevent leaking of future to past\n        x = k_r[:, :, 0]\n\n        W = expand_batch_and_merge_head(b, self.linear)\n        R = self.act(x @ W)\n        R = R[:, 0:buckets, 0:(buckets + self.n_top_buckets)]\n\n        return mask_reordering_matrix(R, topk, self.temperature)\n\nclass CausalAttentionSortNet(nn.Module):\n    def __init__(self, heads, bucket_size, dim, temperature):\n        super().__init__()\n        self.heads = heads\n        self.bucket_size = bucket_size\n        self.dim = dim\n        self.temperature = temperature\n\n    def forward(self, q, k, topk=1):\n        bh, *_, h, dim = *q.shape, self.heads, self.dim\n\n        b = bh // h\n        buckets = q.shape[1] // self.bucket_size\n        kv_buckets = k.shape[1] // self.bucket_size\n\n        q_r = bucket(buckets, cumavg(q, dim=1))\n        k_r = bucket(kv_buckets, cumavg(k, dim=1))\n\n        sq = q_r[:, :, 0]\n        sk = k_r.sum(dim=2)\n        sk = F.pad(sk, (0, 0, topk, 0))\n\n        R = torch.einsum('bie,bje->bij', sq, sk) * (dim ** -0.5)\n        return mask_reordering_matrix(R, topk, self.temperature)\n\ndef apply_fn_after_split_ind(dim, ind, fn, t):\n    l, r = split_at_index(dim, ind, t)\n    return torch.cat((l, fn(r)), dim=dim)\n\nclass SinkhornCausalAttention(nn.Module):\n    def __init__(self, bucket_size, dim, dim_heads, heads, max_seq_len, dropout = 0., kv_bucket_size = None, use_simple_sort_net = False, n_top_buckets = 2, temperature = 1.):\n        super().__init__()\n        assert kv_bucket_size is None or bucket_size == kv_bucket_size, 'different bucketing for key/values for causal reordering not supported yet'\n\n        self.dim = dim\n        self.heads = heads\n        self.bucket_size = bucket_size\n\n        # a learned null key / value for the first bucket (which has nothing in the past to sort to)\n        self.null_keys = nn.Parameter(torch.randn(heads, 1, dim_heads))\n        self.null_values = nn.Parameter(torch.randn(heads, 1, dim_heads))\n\n        if use_simple_sort_net:\n            self.sort_net = CausalSimpleSortNet(heads, bucket_size, max_seq_len // bucket_size, n_top_buckets, dim_heads * 2, temperature)\n        else:\n            self.sort_net = CausalAttentionSortNet(heads, bucket_size, dim_heads, temperature)\n\n        self.n_top_buckets = n_top_buckets\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, q, k, v, q_mask = None, kv_mask = None):\n        b, h, t, d_h, n_top, d, bsz, device = *q.shape, self.n_top_buckets, self.dim, self.bucket_size, q.device\n\n        bh = b * h\n        hh = h // 2\n        buckets = t // bsz\n        n_top = min(n_top, buckets)\n\n        hh_slice = (slice(None), slice(hh, None))\n\n        rotate_fn = partial(apply_fn_after_split_ind, 1, hh, lambda t: rotate_left(t, bsz-1, dim=2))\n        q, k, v = map(rotate_fn, (q, k, v))\n\n        # merge batch and head\n        merge_batch_head = partial(merge_dims, 0, 1)\n        q, k, v = map(merge_batch_head, (q, k, v))\n\n        # bucket qkv\n        b_q, b_k, b_v = map(partial(bucket, buckets), (q, k, v))\n\n        # calculate R\n        R = self.sort_net(q, k, topk=n_top)\n        R = R.type_as(q).to(q)\n\n        # add null key / values\n        b_null_k = self.null_keys[None, :, None, :, :].expand(b, h, n_top, bsz, -1).reshape(bh, n_top, bsz, -1).to(k)\n        b_null_v = self.null_values[None, :, None, :, :].expand(b, h, n_top, bsz, -1).reshape(bh, n_top, bsz, -1).to(v)\n\n        b_k_r = torch.cat((b_null_k, b_k), dim=1)\n        b_v_r = torch.cat((b_null_v, b_v), dim=1)\n\n        # reorder buckets to buckets of the past\n        b_k_r = reorder_buckets(b_k_r, R)\n        b_v_r = reorder_buckets(b_v_r, R)\n\n        b_k_r = b_k_r.reshape(bh, buckets, bsz * n_top, -1)\n        b_v_r = b_v_r.reshape(bh, buckets, bsz * n_top, -1)\n\n        # and concatenate to original buckets themselves for local attention\n        b_k = torch.cat((b_k_r, b_k), dim=2)\n        b_v = torch.cat((b_v_r, b_v), dim=2)\n\n        dots = torch.einsum('buie,buje->buij', b_q, b_k) * (d_h ** -0.5)\n\n        # mask\n        mask_value = max_neg_value(q)\n\n        if not all_none(q_mask, kv_mask):\n            q_mask = default(q_mask, lambda: torch.ones((b, t), device=device).bool())\n            kv_mask = default(kv_mask, q_mask)\n\n            expand_head = lambda x: x.unsqueeze(1).repeat(1, h, 1)\n            q_mask, kv_mask = map(expand_head, (q_mask, kv_mask))\n\n            q_mask[hh_slice] = rotate_left(q_mask[hh_slice], bsz-1, dim=2)\n            kv_mask[hh_slice] = rotate_left(kv_mask[hh_slice], bsz-1, dim=2)\n\n            q_mask, kv_mask = map(lambda x: merge_dims(0, 1, x), (q_mask, kv_mask))\n            mq, mk = bucket(buckets, q_mask), bucket(buckets, kv_mask)\n\n            mk_with_null = F.pad(mk, (0, 0, 2, 0), value=True)\n            mk_r = batched_index_select(mk_with_null, R.abs().argmax(dim=-1))\n\n            mk_r = mk_r.reshape(bh, buckets, -1)\n            mk = torch.cat((mk_r, mk), dim=2)\n            mask = mq[:, :, :, None] * mk[:, :, None, :]\n            dots.masked_fill_(~mask, mask_value)\n            del mask\n\n        # masking for half head rotations\n        shift = n_top * bsz\n        total_shift = shift + bsz\n\n        mask = torch.ones((b, h, buckets, bsz, total_shift), device=device).bool()\n        i, j = torch.triu_indices(bsz, bsz, 1)\n        mask[:, :, :, i, j + shift] = False\n        mask[:, hh:, -1, 0:shift, 0:shift+1] = False\n        mask[:, hh:, -1, 0, 0:shift+1] = True\n        mask = mask.reshape(b * h, buckets, bsz, total_shift)\n\n        dots.masked_fill_(~mask, mask_value)\n        del mask\n\n        # attention\n        dots = dots.softmax(dim=-1)\n        dots = self.dropout(dots)\n\n        out = torch.einsum('buij,buje->buie', dots, b_v)\n        out = unbucket(out)\n\n        out = out.reshape(b, h, t, d_h)\n        out = apply_fn_after_split_ind(1, hh, lambda t: rotate_right(t, bsz-1, dim=2), out)\n        return out\n\nclass SinkhornSelfAttention(nn.Module):\n    def __init__(self, dim, bucket_size, max_seq_len, heads = 8, dim_head = None, kv_bucket_size = None, causal = False, non_permutative = True, sinkhorn_iter = 5, n_sortcut = 0, temperature = 0.75, attn_dropout = 0., dropout = 0., context_only = False, use_simple_sort_net = False, n_local_attn_heads = 0, n_top_buckets = 1):\n        super().__init__()\n        assert dim_head or divisible_by(dim, heads), f'If dim_head is None, dimension {dim} must be divisible by the number of heads {heads}'\n        assert not (causal and n_sortcut > 0), 'sortcut can only be used for non causal attention'\n        assert not (causal and context_only), 'context only self attention layer cannot be causal'\n        assert n_local_attn_heads <= heads, 'number of local attention heads cannot exceed total heads'\n\n        dim_head = default(dim_head, dim // heads)\n        dim_heads = dim_head * heads\n        self.dim_head = dim_head\n\n        self.heads = heads\n        self.bucket_size = bucket_size\n        self.kv_bucket_size = default(kv_bucket_size, bucket_size)\n\n        self.context_only = context_only\n        self.to_q = nn.Linear(dim, dim_heads, bias=False)\n        self.to_kv = nn.Linear(dim, dim_heads * 2, bias=False) if not context_only else None\n\n        self.to_out = nn.Linear(dim_heads, dim)\n\n        self.n_local_attn_heads = n_local_attn_heads\n        self.local_attention = LocalAttention(bucket_size, causal, dropout = attn_dropout, look_forward=(1 if not causal else 0))\n\n        sink_heads = heads - n_local_attn_heads\n\n        attn = SinkhornCausalAttention(bucket_size, dim, dim_head, sink_heads, max_seq_len, dropout = attn_dropout, kv_bucket_size = kv_bucket_size, use_simple_sort_net = use_simple_sort_net, n_top_buckets = n_top_buckets, temperature = temperature)\n\n        self.sinkhorn_attention = attn\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, input_mask = None, context = None, context_mask = None):\n        b, t, d, h, dh, l_h = *x.shape, self.heads, self.dim_head, self.n_local_attn_heads\n        assert divisible_by(t, self.bucket_size), f'sequence {t} needs to be divisible by bucket size {self.bucket_size}'\n        assert not (self.context_only and context is None), 'context key / values must be supplied if context self attention layer'\n        assert not (context is not None and (context.shape[0], context.shape[2]) !=  (b, d)), 'contextual key / values must have the same batch and dimensions as the decoder'\n\n        q = self.to_q(x)\n\n        kv = self.to_kv(x).chunk(2, dim=-1) if not self.context_only else (context, context)\n        kv_mask = input_mask if not self.context_only else context_mask\n\n        assert divisible_by(kv[0].shape[1], self.kv_bucket_size), 'key/value sequences need to be divisible by key/value bucket size'\n\n        qkv = (q, *kv)\n        merge_heads_fn = partial(merge_heads, h)\n        q, k, v = map(merge_heads_fn, qkv)\n\n        split_index_fn = partial(split_at_index, 1, l_h)\n        (lq, q), (lk, k), (lv, v) = map(split_index_fn, (q, k, v))\n        has_local, has_sinkhorn = map(lambda x: x.shape[1] > 0, (lq, q))\n\n        out = []\n\n        if has_local > 0:\n            out.append(self.local_attention(lq, lk, lv, input_mask = input_mask))\n\n        if has_sinkhorn > 0:\n            out.append(self.sinkhorn_attention(q, k, v, q_mask = input_mask, kv_mask = kv_mask))\n\n        out = torch.cat(out, dim=1)\n        out = split_heads(h, out)\n        out = self.to_out(out)\n        out = self.dropout(out)\n        return out\n",
    "description": null,
    "url": null
}