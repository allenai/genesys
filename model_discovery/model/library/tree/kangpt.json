{
    "acronym": "kangpt",
    "title": "Generative Pre-trained Transformers (GPTs) using Kolmogorov-Arnold Networks (KANs) for language modeling",
    "seed_ids": [
        "gpt3",
        "transformer"
    ],
    "s2id": null,
    "abstract": null,
    "authors": [
        "Aditya N Ganesh"
    ],
    "venue": null,
    "year": 2024,
    "tldr": null,
    "citationCount": null,
    "influentialCitationCount": null,
    "code": "import copy\nimport glob\nimport os\nimport random\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport sympy\nimport torch\nimport torch.nn as nn\nfrom tqdm import tqdm\n\nfrom .KANLayer import KANLayer\nfrom .LBFGS import LBFGS\nfrom .spline import curve2coef\nfrom .Symbolic_KANLayer import SYMBOLIC_LIB, Symbolic_KANLayer\n\n\nclass KAN(nn.Module):\n    \"\"\"\n    KAN class\n\n    Attributes:\n    -----------\n        biases: a list of nn.Linear()\n            biases are added on nodes (in principle, biases can be absorbed\n            into activation functions. However, we still have them for better optimization)\n        act_fun: a list of KANLayer\n            KANLayers\n        depth: int\n            depth of KAN\n        width: list\n            number of neurons in each layer. e.g., [2,5,5,3] means 2D inputs,\n            5D outputs, with 2 layers of 5 hidden neurons.\n        grid: int\n            the number of grid intervals\n        k: int\n            the order of piecewise polynomial\n        base_fun: fun\n            residual function b(x). an activation function\n            phi(x) = sb_scale * b(x) + sp_scale * spline(x)\n        symbolic_fun: a list of Symbolic_KANLayer\n            Symbolic_KANLayers\n        symbolic_enabled: bool\n            If False, the symbolic front is not computed (to save time).\n            Default: True.\n\n    Methods:\n    --------\n        __init__():\n            initialize a KAN\n        initialize_from_another_model():\n            initialize a KAN from another KAN (with the same shape, but\n            potentially different grids)\n        update_grid_from_samples():\n            update spline grids based on samples\n        initialize_grid_from_another_model():\n            initalize KAN grids from another KAN\n        forward():\n            forward\n        set_mode():\n            set the mode of an activation function: 'n' for numeric, 's' for\n            symbolic, 'ns' for combined (note they are visualized differently\n            in plot(). 'n' as black, 's' as red, 'ns' as purple).\n        fix_symbolic():\n            fix an activation function to be symbolic\n        suggest_symbolic():\n            suggest the symbolic candicates of a numeric spline-based\n            activation function\n        lock():\n            lock activation functions to share parameters\n        unlock():\n            unlock locked activations\n        get_range():\n            get the input and output ranges of an activation function\n        plot():\n            plot the diagram of KAN\n        train_kan():\n            train KAN\n        prune():\n            prune KAN\n        remove_edge():\n            remove some edge of KAN\n        remove_node():\n            remove some node of KAN\n        auto_symbolic():\n            automatically fit all splines to be symbolic functions\n        symbolic_formula():\n            obtain the symbolic formula of the KAN network\n    \"\"\"\n\n    def __init__(\n        self,\n        width=None,\n        grid=3,\n        k=3,\n        noise_scale=0.1,\n        noise_scale_base=0.1,\n        base_fun=torch.nn.SiLU(),\n        symbolic_enabled=True,\n        bias_trainable=True,\n        grid_eps=1.0,\n        grid_range=[-1, 1],\n        sp_trainable=True,\n        sb_trainable=True,\n        seed=0,\n    ):\n        \"\"\"\n        initalize a KAN model\n\n        Args:\n        -----\n            width : list of int\n                :math:`[n_0, n_1, .., n_{L-1}]` specify the number of neurons\n                in each layer (including inputs/outputs)\n            grid : int\n                number of grid intervals. Default: 3.\n            k : int\n                order of piecewise polynomial. Default: 3.\n            noise_scale : float\n                initial injected noise to spline. Default: 0.1.\n            base_fun : fun\n                the residual function b(x). Default: torch.nn.SiLU().\n            symbolic_enabled : bool\n                compute or skip symbolic computations (for efficiency).\n                By default: True.\n            bias_trainable : bool\n                bias parameters are updated or not. By default: True\n            grid_eps : float\n                When grid_eps = 0, the grid is uniform; when grid_eps = 1,\n                the grid is partitioned using percentiles of samples.\n                0 < grid_eps < 1 interpolates between the two extremes.\n                Default: 0.02.\n            grid_range : list/np.array of shape (2,))\n                setting the range of grids. Default: [-1,1].\n            sp_trainable : bool\n                If true, scale_sp is trainable. Default: True.\n            sb_trainable : bool\n                If true, scale_base is trainable. Default: True.\n            seed : int\n                random seed\n\n        Returns:\n        --------\n            self\n\n        Example\n        -------\n        >>> model = KAN(width=[2,5,1], grid=5, k=3)\n        >>> (model.act_fun[0].in_dim, model.act_fun[0].out_dim), \\\n            (model.act_fun[1].in_dim, model.act_fun[1].out_dim)\n        ((2, 5), (5, 1))\n        \"\"\"\n        super(KAN, self).__init__()\n\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n        random.seed(seed)\n\n        # initializeing the numerical front ###\n\n        self.biases = []\n        self.act_fun = []\n        self.depth = len(width) - 1\n        self.width = width\n\n        for l in range(self.depth):\n            # splines\n            scale_base = (\n                1 / np.sqrt(width[l])\n                + (\n                    torch.randn(\n                        width[l] * width[l + 1],\n                    )\n                    * 2\n                    - 1\n                )\n                * noise_scale_base\n            )\n            sp_batch = KANLayer(\n                in_dim=width[l],\n                out_dim=width[l + 1],\n                num=grid,\n                k=k,\n                noise_scale=noise_scale,\n                scale_base=scale_base,\n                scale_sp=1.0,\n                base_fun=base_fun,\n                grid_eps=grid_eps,\n                grid_range=grid_range,\n                sp_trainable=sp_trainable,\n                sb_trainable=sb_trainable,\n            )\n            self.act_fun.append(sp_batch)\n\n            # bias\n            bias = nn.Linear(width[l + 1], 1, bias=False).requires_grad_(\n                bias_trainable\n            )\n            bias.weight.data *= 0.0\n            self.biases.append(bias)\n\n        self.biases = nn.ModuleList(self.biases)\n        self.act_fun = nn.ModuleList(self.act_fun)\n\n        self.grid = grid\n        self.k = k\n        self.base_fun = base_fun\n\n        # initializing the symbolic front ###\n        self.symbolic_fun = []\n        for l in range(self.depth):\n            sb_batch = Symbolic_KANLayer(in_dim=width[l], out_dim=width[l + 1])\n            self.symbolic_fun.append(sb_batch)\n\n        self.symbolic_fun = nn.ModuleList(self.symbolic_fun)\n        self.symbolic_enabled = symbolic_enabled\n\n    def forward(self, x):\n        \"\"\"\n        KAN forward\n\n        Args:\n        -----\n            x : 2D torch.float\n                inputs, shape (batch, input dimension)\n\n        Returns:\n        --------\n            y : 2D torch.float\n                outputs, shape (batch, output dimension)\n\n        Example\n        -------\n        >>> model = KAN(width=[2,5,3], grid=5, k=3)\n        >>> x = torch.normal(0,1,size=(100,2))\n        >>> model(x).shape\n        torch.Size([100, 3])\n        \"\"\"\n\n        shape_size = len(x.shape)\n\n        if shape_size == 3:\n            B, C, T = x.shape\n        elif shape_size == 2:\n            B, T = x.shape\n        else:\n            raise NotImplementedError()\n\n        x = x.view(-1, T)\n\n        self.acts = []  # shape ([batch, n0], [batch, n1], ..., [batch, n_L])\n        self.spline_preacts = []\n        self.spline_postsplines = []\n        self.spline_postacts = []\n        self.acts_scale = []\n        self.acts_scale_std = []\n        # self.neurons_scale = []\n\n        self.acts.append(x)  # acts shape: (batch, width[l])\n\n        for l in range(self.depth):\n\n            x_numerical, preacts, postacts_numerical, postspline = (\n                self.act_fun[l](x)\n            )\n\n            if self.symbolic_enabled:\n                x_symbolic, postacts_symbolic = self.symbolic_fun[l](x)\n            else:\n                x_symbolic = 0.0\n                postacts_symbolic = 0.0\n\n            x = x_numerical + x_symbolic\n            postacts = postacts_numerical + postacts_symbolic\n\n            # self.neurons_scale.append(torch.mean(torch.abs(x), dim=0))\n            grid_reshape = self.act_fun[l].grid.reshape(\n                self.width[l + 1], self.width[l], -1\n            )\n            input_range = grid_reshape[:, :, -1] - grid_reshape[:, :, 0] + 1e-4\n            output_range = torch.mean(torch.abs(postacts), dim=0)\n            self.acts_scale.append(output_range / input_range)\n            self.acts_scale_std.append(torch.std(postacts, dim=0))\n            self.spline_preacts.append(preacts.detach())\n            self.spline_postacts.append(postacts.detach())\n            self.spline_postsplines.append(postspline.detach())\n\n            x = x + self.biases[l].weight\n            self.acts.append(x)\n\n        U = x.shape[1]\n\n        if shape_size == 3:\n            x = x.view(B, C, U)\n        elif shape_size == 2:\n            assert x.shape == (B, U)\n\n        return x\n\n    def train_kan(\n        self,\n        dataset,\n        opt=\"LBFGS\",\n        steps=100,\n        log=1,\n        lamb=0.0,\n        lamb_l1=1.0,\n        lamb_entropy=2.0,\n        lamb_coef=0.0,\n        lamb_coefdiff=0.0,\n        update_grid=True,\n        grid_update_num=10,\n        loss_fn=None,\n        lr=1.0,\n        stop_grid_update_step=50,\n        batch=-1,\n        small_mag_threshold=1e-16,\n        small_reg_factor=1.0,\n        metrics=None,\n        sglr_avoid=False,\n        save_fig=False,\n        in_vars=None,\n        out_vars=None,\n        beta=3,\n        save_fig_freq=1,\n        img_folder=\"./video\",\n        device=\"cpu\",\n    ):\n        \"\"\"\n        training\n\n        Args:\n        -----\n            dataset : dic\n                contains dataset['train_input'], dataset['train_label'],\n                dataset['test_input'], dataset['test_label']\n            opt : str\n                \"LBFGS\" or \"Adam\"\n            steps : int\n                training steps\n            log : int\n                logging frequency\n            lamb : float\n                overall penalty strength\n            lamb_l1 : float\n                l1 penalty strength\n            lamb_entropy : float\n                entropy penalty strength\n            lamb_coef : float\n                coefficient magnitude penalty strength\n            lamb_coefdiff : float\n                difference of nearby coefficits (smoothness) penalty strength\n            update_grid : bool\n                If True, update grid regularly before stop_grid_update_step\n            grid_update_num : int\n                the number of grid updates before stop_grid_update_step\n            stop_grid_update_step : int\n                no grid updates after this training step\n            batch : int\n                batch size, if -1 then full.\n            small_mag_threshold : float\n                threshold to determine large or small numbers (may want to\n                apply larger penalty to smaller numbers)\n            small_reg_factor : float\n                penalty strength applied to small factors relative to large\n                factos\n            device : str\n                device\n            save_fig_freq : int\n                save figure every (save_fig_freq) step\n\n        Returns:\n        --------\n            results : dic\n                results['train_loss'], 1D array of training losses (RMSE)\n                results['test_loss'], 1D array of test losses (RMSE)\n                results['reg'], 1D array of regularization\n\n        Example\n        -------\n        >>> # for interactive examples, please see demos\n        >>> from utils import create_dataset\n        >>> model = KAN(width=[2,5,1], grid=5, k=3, noise_scale=0.1, seed=0)\n        >>> f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n        >>> dataset = create_dataset(f, n_var=2)\n        >>> model.train(dataset, opt='LBFGS', steps=50, lamb=0.01);\n        >>> model.plot()\n        \"\"\"\n\n        def reg(acts_scale):\n\n            def nonlinear(x, th=small_mag_threshold, factor=small_reg_factor):\n                return (x < th) * x * factor + (x > th) * (\n                    x + (factor - 1) * th\n                )\n\n            reg_ = 0.0\n            for i in range(len(acts_scale)):\n                vec = acts_scale[i].reshape(\n                    -1,\n                )\n\n                p = vec / torch.sum(vec)\n                l1 = torch.sum(nonlinear(vec))\n                entropy = -torch.sum(p * torch.log2(p + 1e-4))\n                reg_ += (\n                    lamb_l1 * l1 + lamb_entropy * entropy\n                )  # both l1 and entropy\n\n            # regularize coefficient to encourage spline to be zero\n            for i in range(len(self.act_fun)):\n                coeff_l1 = torch.sum(\n                    torch.mean(torch.abs(self.act_fun[i].coef), dim=1)\n                )\n                coeff_diff_l1 = torch.sum(\n                    torch.mean(\n                        torch.abs(torch.diff(self.act_fun[i].coef)), dim=1\n                    )\n                )\n                reg_ += lamb_coef * coeff_l1 + lamb_coefdiff * coeff_diff_l1\n\n            return reg_\n\n        pbar = tqdm(range(steps), desc=\"description\", ncols=100)\n\n        if loss_fn is None:\n            loss_fn = loss_fn_eval = lambda x, y: torch.mean((x - y) ** 2)\n        else:\n            loss_fn = loss_fn_eval = loss_fn\n\n        grid_update_freq = int(stop_grid_update_step / grid_update_num)\n\n        if opt == \"Adam\":\n            optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n        elif opt == \"LBFGS\":\n            optimizer = LBFGS(\n                self.parameters(),\n                lr=lr,\n                history_size=10,\n                line_search_fn=\"strong_wolfe\",\n                tolerance_grad=1e-32,\n                tolerance_change=1e-32,\n                tolerance_ys=1e-32,\n            )\n\n        results = {}\n        results[\"train_loss\"] = []\n        results[\"test_loss\"] = []\n        results[\"reg\"] = []\n        if metrics is not None:\n            for i in range(len(metrics)):\n                results[metrics[i].__name__] = []\n\n        if batch == -1 or batch > dataset[\"train_input\"].shape[0]:\n            batch_size = dataset[\"train_input\"].shape[0]\n            batch_size_test = dataset[\"test_input\"].shape[0]\n        else:\n            batch_size = batch\n            batch_size_test = batch\n\n        global train_loss, reg_\n\n        def closure():\n            global train_loss, reg_\n            optimizer.zero_grad()\n            pred = self.forward(dataset[\"train_input\"][train_id].to(device))\n            if sglr_avoid:\n                id_ = torch.where(~torch.isnan(torch.sum(pred, dim=1)))[0]\n                train_loss = loss_fn(\n                    pred[id_], dataset[\"train_label\"][train_id][id_].to(device)\n                )\n            else:\n                train_loss = loss_fn(\n                    pred, dataset[\"train_label\"][train_id].to(device)\n                )\n            reg_ = reg(self.acts_scale)\n            objective = train_loss + lamb * reg_\n            objective.backward()\n            return objective\n\n        if save_fig:\n            if not os.path.exists(img_folder):\n                os.makedirs(img_folder)\n\n        for _ in pbar:\n\n            train_id = np.random.choice(\n                dataset[\"train_input\"].shape[0], batch_size, replace=False\n            )\n            test_id = np.random.choice(\n                dataset[\"test_input\"].shape[0], batch_size_test, replace=False\n            )\n\n            if (\n                _ % grid_update_freq == 0\n                and _ < stop_grid_update_step\n                and update_grid\n            ):\n                self.update_grid_from_samples(\n                    dataset[\"train_input\"][train_id].to(device)\n                )\n\n            if opt == \"LBFGS\":\n                optimizer.step(closure)\n\n            if opt == \"Adam\":\n                pred = self.forward(\n                    dataset[\"train_input\"][train_id].to(device)\n                )\n                if sglr_avoid:\n                    id_ = torch.where(~torch.isnan(torch.sum(pred, dim=1)))[0]\n                    train_loss = loss_fn(\n                        pred[id_],\n                        dataset[\"train_label\"][train_id][id_].to(device),\n                    )\n                else:\n                    train_loss = loss_fn(\n                        pred, dataset[\"train_label\"][train_id].to(device)\n                    )\n                reg_ = reg(self.acts_scale)\n                loss = train_loss + lamb * reg_\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n            test_loss = loss_fn_eval(\n                self.forward(dataset[\"test_input\"][test_id].to(device)),\n                dataset[\"test_label\"][test_id].to(device),\n            )\n\n            if _ % log == 0:\n                pbar.set_description(\n                    \"train loss: %.2e | test loss: %.2e | reg: %.2e \"\n                    % (\n                        torch.sqrt(train_loss).cpu().detach().numpy(),\n                        torch.sqrt(test_loss).cpu().detach().numpy(),\n                        reg_.cpu().detach().numpy(),\n                    )\n                )\n\n            if metrics is not None:\n                for i in range(len(metrics)):\n                    results[metrics[i].__name__].append(metrics[i]().item())\n\n            results[\"train_loss\"].append(\n                torch.sqrt(train_loss).cpu().detach().numpy()\n            )\n            results[\"test_loss\"].append(\n                torch.sqrt(test_loss).cpu().detach().numpy()\n            )\n            results[\"reg\"].append(reg_.cpu().detach().numpy())\n\n            if save_fig and _ % save_fig_freq == 0:\n                self.plot(\n                    folder=img_folder,\n                    in_vars=in_vars,\n                    out_vars=out_vars,\n                    title=\"Step {}\".format(_),\n                    beta=beta,\n                )\n                plt.savefig(\n                    img_folder + \"/\" + str(_) + \".jpg\",\n                    bbox_inches=\"tight\",\n                    dpi=200,\n                )\n                plt.close()\n\n        return results\n",
    "description": "Kolmogorov-Arnold Networks (KANs) are promising alternatives of Multi-Layer Perceptrons (MLPs). KANs have strong mathematical foundations just like MLPs: MLPs are based on the universal approximation theorem, while KANs are based on Kolmogorov-Arnold representation theorem. KANs and MLPs are dual: KANs have activation functions on edges, while MLPs have activation functions on nodes. This simple change makes KANs better (sometimes much better!) than MLPs in terms of both model accuracy and interpretability. ",
    "url": "https://adityang.github.io/kan-gpt/"
}