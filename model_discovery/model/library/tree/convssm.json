{
    "acronym": "convssm",
    "title": "Convolutional State Space Models for Long-Range Spatiotemporal Modeling",
    "seed_ids": [],
    "s2id": "5ad84fe07a569b6cc339d77cd2c265c1b79d644d",
    "abstract": "Effectively modeling long spatiotemporal sequences is challenging due to the need to model complex spatial correlations and long-range temporal dependencies simultaneously. ConvLSTMs attempt to address this by updating tensor-valued states with recurrent neural networks, but their sequential computation makes them slow to train. In contrast, Transformers can process an entire spatiotemporal sequence, compressed into tokens, in parallel. However, the cost of attention scales quadratically in length, limiting their scalability to longer sequences. Here, we address the challenges of prior methods and introduce convolutional state space models (ConvSSM) that combine the tensor modeling ideas of ConvLSTM with the long sequence modeling approaches of state space methods such as S4 and S5. First, we demonstrate how parallel scans can be applied to convolutional recurrences to achieve subquadratic parallelization and fast autoregressive generation. We then establish an equivalence between the dynamics of ConvSSMs and SSMs, which motivates parameterization and initialization strategies for modeling long-range dependencies. The result is ConvS5, an efficient ConvSSM variant for long-range spatiotemporal modeling. ConvS5 significantly outperforms Transformers and ConvLSTM on a long horizon Moving-MNIST experiment while training 3X faster than ConvLSTM and generating samples 400X faster than Transformers. In addition, ConvS5 matches or exceeds the performance of state-of-the-art methods on challenging DMLab, Minecraft and Habitat prediction benchmarks and enables new directions for modeling long spatiotemporal sequences.",
    "authors": [
        "Jimmy T.H. Smith",
        "Shalini De Mello",
        "Jan Kautz",
        "Scott W. Linderman",
        "Wonmin Byeon"
    ],
    "venue": "Neural Information Processing Systems",
    "year": 2023,
    "tldr": "This work addresses the challenges of prior methods and introduces convolutional state space models (ConvSSM) that combine the tensor modeling ideas of ConvLSTM with the long sequence modeling approaches of state space methods such as S4 and S5 and develops an equivalence between ConvSSMs and SSMs, which motivates parameterization and initialization strategies for modeling long-range dependencies.",
    "citationCount": 9,
    "influentialCitationCount": 0,
    "code": "# ------------------------------------------------------------------------------\n# Copyright (c) 2022-2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n#\n# This work is made available under the Nvidia Source Code License.\n# To view a copy of this license, visit\n# https://github.com/NVlabs/ConvSSM/blob/main/LICENSE\n#\n# Written by Jimmy Smith\n# ------------------------------------------------------------------------------\n\nfrom functools import partial\nimport jax\nimport jax.numpy as np\nfrom flax import linen as nn\nfrom jax.nn.initializers import he_normal, normal\nfrom jax.numpy.linalg import eigh\nfrom jax.scipy.linalg import block_diag\n\nfrom .conv_ops import VmapResnetBlock, VmapDiag_CD_Conv, VmapDiagResnetBlock, Half_GLU\nfrom jax import lax, numpy as np\nfrom .conv_ops import vmap_conv\n\n\n# Scan functions\n@jax.vmap\ndef conv_binary_operator(q_i, q_j):\n    \"\"\"Assumes 1x1 kernels\n       :inputs q_i an q_j are tuples containing (A_i, BU_i) and (A_j, BU_j)\n       :inputs A_i and A_j are (P,)\n       :inputs BU_i and BU_j are bszxH_UxW_UxP\n       :returns tuple where first entry AA is (P,)\n                and second entry is bszxH_UxW_UxP\"\"\"\n\n    A_i, BU_i = q_i\n    A_j, BU_j = q_j\n\n    # AA = convolve_1x1_kernels(A_j, A_i)\n    AA = A_j * A_i\n    A_jBU_i = np.expand_dims(A_j, (0, 1, 2)) * BU_i\n\n    return AA, A_jBU_i + BU_j\n\n\ndef apply_convSSM_parallel(A, B, C, us, x0):\n    \"\"\"Compute the output sequence of the convolutional SSM\n        given the input sequence using a parallel scan.\n        Computes x_k = A * x_{k-1} + B * u_k\n                 y_k = C * x_k     + D * U_k\n        where * is a convolution operator.\n    Args:\n        A (complex64): Conv kernel A                (P,)\n        B (complex64): input-to-state conv kernel   (k_B,k_B,U,P)\n        C (complex64): state-to-output conv kernel  (k_c,k_c, P, U)\n        us (float32): input sequence of features  (L,bsz,H, W, U)\n        x0 (complex64): initial state               (bsz, H, W, P)\n    Returns:\n        x_L (complex64): the last state of the SSM  (bsz, H, W, P)\n        ys (float32): the conv SSM outputs        (L,bsz, H, W, U)\n    \"\"\"\n    L = us.shape[0]\n    As = A * np.ones((L,)+A.shape)\n    Bus = vmap_conv(B, np.complex64(us))\n    Bus = Bus.at[0].add(np.expand_dims(A, (0, 1, 2)) * x0)\n\n    _, xs = lax.associative_scan(conv_binary_operator, (As, Bus))\n\n    ys = 2 * vmap_conv(C, xs).real\n\n    return xs[-1], ys\n\n\ndef apply_convSSM_sequential(A, B, C, us, x0):\n    \"\"\"Compute the output sequence of the convolutional SSM\n        given the input sequence sequentially. For testing purposes.\n    Args:\n        A (complex64): Conv kernel A                (P,)\n        B (complex64): input-to-state conv kernel   (k_B,k_B,U,P)\n        C (complex64): state-to-output conv kernel  (k_c,k_c, P, U)\n        us (float32): input sequence of features  (L,bsz,H, W, U)\n        x0 (complex64): initial state               (bsz, H, W, P)\n    Returns:\n        x_L (complex64): the last state of the SSM  (bsz, H, W, P)\n        ys (float32): the conv SSM outputs        (L,bsz, H, W, U)\n    \"\"\"\n    def step(x_k_1, u_k):\n        Bu = lax.conv_general_dilated(np.complex64(u_k), B, (1, 1),\n                                      'SAME',\n                                      dimension_numbers=('NHWC', 'HWIO', 'NHWC'))\n        x_k = np.expand_dims(A, (0, 1, 2)) * x_k_1 + Bu\n        y_k = 2 * lax.conv_general_dilated(x_k, C, (1, 1),\n                                           'SAME',\n                                           dimension_numbers=('NHWC', 'HWIO', 'NHWC')).real\n        return x_k, y_k\n    return lax.scan(step, np.complex64(x0), us)\n\ndef make_HiPPO(N):\n    P = np.sqrt(1 + 2 * np.arange(N))\n    A = P[:, np.newaxis] * P[np.newaxis, :]\n    A = np.tril(A) - np.diag(np.arange(N))\n    return -A\n\n\ndef make_Normal_HiPPO(N):\n    \"\"\"normal approximation to the HiPPO-LegS matrix\"\"\"\n    # Make -HiPPO\n    hippo = make_HiPPO(N)\n\n    # Add in a rank 1 term. Makes it Normal.\n    P = np.sqrt(np.arange(N) + 0.5)\n    nhippo = hippo + P[:, np.newaxis] * P[np.newaxis, :]\n\n    # HiPPO also specifies the B matrix\n    B = np.sqrt(2 * np.arange(N) + 1.0)\n\n    return nhippo, P, B\n\n\ndef make_NPLR_HiPPO(N):\n    \"\"\"\n    Makes components needed for NPLR representation of HiPPO-LegS\n     From https://github.com/srush/annotated-s4/blob/main/s4/s4.py\n    Args:\n        N (int32): state size\n    Returns:\n        N x N HiPPO LegS matrix, low-rank factor P, HiPPO input matrix B\n    \"\"\"\n    # Make -HiPPO\n    hippo = make_HiPPO(N)\n\n    # Add in a rank 1 term. Makes it Normal.\n    P = np.sqrt(np.arange(N) + 0.5)\n\n    # HiPPO also specifies the B matrix\n    B = np.sqrt(2 * np.arange(N) + 1.0)\n    return hippo, P, B\n\n\ndef make_DPLR_HiPPO(N):\n    \"\"\"\n    Makes components needed for DPLR representation of HiPPO-LegS\n     From https://github.com/srush/annotated-s4/blob/main/s4/s4.py\n    Note, we will only use the diagonal part\n    Args:\n        N:\n    Returns:\n        eigenvalues Lambda, low-rank term P, conjugated HiPPO input matrix B,\n        eigenvectors V, HiPPO B pre-conjugation\n    \"\"\"\n    A, P, B = make_NPLR_HiPPO(N)\n\n    S = A + P[:, np.newaxis] * P[np.newaxis, :]\n\n    S_diag = np.diagonal(S)\n    Lambda_real = np.mean(S_diag) * np.ones_like(S_diag)\n\n    # Diagonalize S to V \\Lambda V^*\n    Lambda_imag, V = eigh(S * -1j)\n\n    P = V.conj().T @ P\n    B_orig = B\n    B = V.conj().T @ B\n    return Lambda_real + 1j * Lambda_imag, P, B, V, B_orig\n\n\ndef discretize_zoh(Lambda, B_tilde, Delta):\n    \"\"\" Discretize a diagonalized, continuous-time linear SSM\n        using zero-order hold method.\n        Args:\n            Lambda (complex64): diagonal state matrix              (P,)\n            B_tilde (complex64): input matrix                      (P, H)\n            Delta (float32): discretization step sizes             (P,)\n        Returns:\n            discretized Lambda_bar (complex64), B_bar (complex64)  (P,), (P,H)\n    \"\"\"\n    Identity = np.ones(Lambda.shape[0])\n    Lambda_bar = np.exp(Lambda * Delta)\n    B_bar = (1/Lambda * (Lambda_bar-Identity))[..., None] * B_tilde\n    return Lambda_bar, B_bar\n\n\ndef log_step_initializer(dt_min=0.001, dt_max=0.1):\n    def init(key, shape):\n        return jax.random.uniform(key, shape) * (\n            np.log(dt_max) - np.log(dt_min)\n        ) + np.log(dt_min)\n\n    return init\n\n\ndef init_log_steps(key, input):\n    U, dt_min, dt_max = input\n    log_steps = []\n    for i in range(U):\n        key, skey = jax.random.split(key)\n        log_step = log_step_initializer(dt_min=dt_min, dt_max=dt_max)(skey, shape=(1,))\n        log_steps.append(log_step)\n\n    return np.array(log_steps)\n\n\ndef initialize_C_kernel(key, shape):\n    \"\"\"For general kernels, e.g. C,D, encoding/decoding\"\"\"\n    out_dim, in_dim, k = shape\n    fan_in = in_dim*(k**2)\n\n    # Note in_axes should be the first by default:\n    # https://jax.readthedocs.io/en/latest/_autosummary/jax.nn.initializers.variance_scaling.html#jax.nn.initializers.variance_scaling\n    return he_normal()(key,\n                       (fan_in, out_dim)).reshape(out_dim,\n                                                  in_dim,\n                                                  k, k).transpose(0, 2, 3, 1).reshape(-1, in_dim)\n\n\ndef initialize_B_kernel(key, shape):\n    \"\"\"We will store the B kernel as a matrix,\n    returns shape: (out_dim, in_dim*k*k)\"\"\"\n    out_dim, in_dim, k = shape\n    fan_in = in_dim*(k**2)\n\n    # Note in_axes should be the first by default:\n    # https://jax.readthedocs.io/en/latest/_autosummary/jax.nn.initializers.variance_scaling.html#jax.nn.initializers.variance_scaling\n    return he_normal()(key,\n                       (fan_in, out_dim)).T\n\n\ndef init_VinvB(key, shape, Vinv):\n    B = initialize_B_kernel(key, shape)\n    VinvB = Vinv @ B\n    VinvB_real = VinvB.real\n    VinvB_imag = VinvB.imag\n    return np.concatenate((VinvB_real[..., None], VinvB_imag[..., None]), axis=-1)\n\n\ndef init_CV(key, shape, V):\n    out_dim, in_dim, k = shape\n    C = initialize_C_kernel(key, shape)\n    CV = C @ V\n    CV = CV.reshape(out_dim, k, k, in_dim//2).transpose(1, 2, 3, 0)\n    CV_real = CV.real\n    CV_imag = CV.imag\n    return np.concatenate((CV_real[..., None], CV_imag[..., None]), axis=-1)\n\n\nclass ConvS5SSM(nn.Module):\n    Lambda_re_init: np.DeviceArray\n    Lambda_im_init: np.DeviceArray\n    V: np.DeviceArray\n    Vinv: np.DeviceArray\n    clip_eigs: bool\n    parallel: bool  # Compute scan in parallel\n    activation: nn.module\n    num_groups: int\n\n    U: int    # Number of SSM input and output features\n    P: int    # Number of state features of SSM\n    k_B: int  # B kernel width/height\n    k_C: int  # C kernel width/height\n    k_D: int  # D kernel width/height\n\n    dt_min: float  # for initializing discretization step\n    dt_max: float\n    C_D_config: str = \"standard\"\n    squeeze_excite: bool = False\n\n    def setup(self):\n        # Initialize diagonal state to state transition kernel Lambda (eigenvalues)\n        self.Lambda_re = self.param(\"Lambda_re\", lambda rng, shape: self.Lambda_re_init, (None,))\n        self.Lambda_im = self.param(\"Lambda_im\", lambda rng, shape: self.Lambda_im_init, (None,))\n        if self.clip_eigs:\n            self.Lambda = np.clip(self.Lambda_re, None, -1e-4) + 1j * self.Lambda_im\n        else:\n            self.Lambda = self.Lambda_re + 1j * self.Lambda_im\n\n        # Initialize input to state (B) and output to state (C) kernels\n        self.B = self.param(\"B\",\n                            lambda rng, shape: init_VinvB(rng,\n                                                          shape,\n                                                          self.Vinv),\n                            (2*self.P, self.U, self.k_B))\n        B_tilde = self.B[..., 0] + 1j * self.B[..., 1]\n\n        self.C = self.param(\"C\",\n                            lambda rng, shape: init_CV(rng, shape, self.V),\n                            (self.U, 2*self.P, self.k_C))\n        self.C_tilde = self.C[..., 0] + 1j * self.C[..., 1]\n\n        if self.C_D_config == \"standard\":\n            self.C_D_conv = VmapDiag_CD_Conv(activation=self.activation,\n                                             k_D=self.k_D,\n                                             out_channels=self.U,\n                                             num_groups=self.num_groups,\n                                             squeeze_excite=self.squeeze_excite)\n        elif self.C_D_config == \"resnet\":\n            self.C_D_conv = VmapResnetBlock(activation=self.activation,\n                                            k_size=self.k_D,\n                                            out_channels=self.U,\n                                            num_groups=self.num_groups,\n                                            squeeze_excite=self.squeeze_excite)\n        elif self.C_D_config == \"diag_resnet\":\n            self.C_D_conv = VmapDiagResnetBlock(activation=self.activation,\n                                                k_size=self.k_D,\n                                                out_channels=self.U,\n                                                num_groups=self.num_groups,\n                                                squeeze_excite=self.squeeze_excite)\n\n        elif self.C_D_config == \"half_glu\":\n            self.C_D_conv = Half_GLU(dim=self.U)\n\n        # Initialize learnable discretization steps\n        self.log_step = self.param(\"log_step\",\n                                   init_log_steps,\n                                   (self.P, self.dt_min, self.dt_max))\n        step = np.exp(self.log_step[:, 0])\n\n        if self.parallel:\n            # Discretize\n            self.A_bar, self.B_bar = discretize_zoh(self.Lambda,\n                                                    B_tilde,\n                                                    step)\n            self.B_bar = self.B_bar.reshape(self.P, self.U, self.k_B, self.k_B).transpose(2, 3, 1, 0)\n        else:\n            # trick to cache the discretization for step-by-step\n            # generation\n            def init_discrete():\n                A_bar, B_bar = discretize_zoh(self.Lambda,\n                                              B_tilde,\n                                              step)\n                B_bar = B_bar.reshape(self.P, self.U, self.k_B, self.k_B).transpose(2, 3, 1, 0)\n                return A_bar, B_bar\n            ssm_var = self.variable(\"prime\", \"ssm\", init_discrete)\n            if self.is_mutable_collection(\"prime\"):\n                ssm_var.value = init_discrete()\n            self.ssm = ssm_var.value\n\n    def __call__(self, input_sequence, x0):\n        \"\"\"\n        input sequence is shape (L, bsz, H, W, U)\n        x0 is (bsz, H, W, U)\n        Returns:\n            x_L (float32): the last state of the SSM  (bsz, H, W, P)\n            ys (float32): the conv SSM outputs       (L,bsz, H, W, U)\n        \"\"\"\n        if self.parallel:\n            # TODO: right now parallel version assumes x_init is zeros\n            x_last, ys = diagonal_scans.apply_convSSM_parallel(self.A_bar,\n                                                               self.B_bar,\n                                                               self.C_tilde,\n                                                               input_sequence,\n                                                               x0)\n\n        else:\n            # For sequential generation (e.g. autoregressive decoding)\n            x_last, ys = diagonal_scans.apply_convSSM_sequential(*self.ssm,\n                                                                 self.C_tilde,\n                                                                 input_sequence,\n                                                                 x0)\n        if self.C_D_config == \"standard\":\n            ys = self.C_D_conv(ys, input_sequence)\n        elif self.C_D_config == \"resnet\":\n            ys = self.C_D_conv(ys)\n        elif self.C_D_config in [\"half_glu\"]:\n            ys = jax.vmap(self.C_D_conv)(ys)\n        return x_last, ys\n\n\ndef hippo_initializer(ssm_size, blocks):\n    block_size = int(ssm_size/blocks)\n    Lambda, _, _, V, _ = make_DPLR_HiPPO(block_size)\n    ssm_size = ssm_size // 2\n    block_size = block_size // 2\n    Lambda = Lambda[:block_size]\n    V = V[:, :block_size]\n    Vc = V.conj().T\n\n    Lambda = (Lambda * np.ones((blocks, block_size))).ravel()\n    V = block_diag(*([V] * blocks))\n    Vinv = block_diag(*([Vc] * blocks))\n\n    return Lambda.real, Lambda.imag, V, Vinv, ssm_size\n\n\ndef init_ConvS5SSM(ssm_size,\n                   blocks,\n                   clip_eigs,\n                   U,\n                   k_B,\n                   k_C,\n                   k_D,\n                   dt_min,\n                   dt_max,\n                   C_D_config):\n    Lambda_re_init, Lambda_im_init,\\\n        V, Vinv, ssm_size = hippo_initializer(ssm_size, blocks)\n\n    return partial(ConvS5SSM,\n                   Lambda_re_init=Lambda_re_init,\n                   Lambda_im_init=Lambda_im_init,\n                   V=V,\n                   Vinv=Vinv,\n                   clip_eigs=clip_eigs,\n                   U=U,\n                   P=ssm_size,\n                   k_B=k_B,\n                   k_C=k_C,\n                   k_D=k_D,\n                   dt_min=dt_min,\n                   dt_max=dt_max,\n                   C_D_config=C_D_config)",
    "description": null,
    "url": null
}