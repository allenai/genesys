{"paperId": "2fc229bfe561f42aae6f3bb84598cfa5737a8b6a", "abstract": "How to reduce compute and memory requirements of neural networks (NNs) without sacrificing performance? Many recent works use sparse Mixtures of Experts (MoEs) to build resource-efficient large language models (LMs). Here we introduce several novel perspectives on MoEs, presenting a general framework that unifies various methods to approximate two-layer NNs (e.g., feedforward blocks of Transformers), including product-key memories (PKMs). Leveraging insights from this framework, we propose methods to improve both MoEs and PKMs. Unlike prior work that compares MoEs with dense baselines under the compute-equal condition, our evaluation condition is parameter-equal, which is crucial to properly evaluate LMs. We show that our MoEs are competitive with the dense Transformer-XL on both the WikiText-103 and enwiki8 datasets at two different scales, while being much more resource efficient. This demonstrates that MoEs are relevant not only to extremely large LMs but also to any-scale resource-efficient LMs. Our code is public.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "citationCount": 9, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces several novel perspectives on MoEs, presenting a general framework that unifies various methods to approximate two-layer NNs, including product-key memories (PKMs), and proposes methods to improve both MoEs and PKMs."}, "embedding": {"model": "specter_v2", "vector": [0.10549069941043854, 0.8206380605697632, -0.4543379247188568, -0.007042150013148785, -0.4770869016647339, -0.028144054114818573, 0.833066999912262, -0.4772181510925293, -0.5947137475013733, -0.26678889989852905, 0.8827231526374817, 0.0262166615575552, 0.3213026523590088, 0.18833597004413605, -0.22262567281723022, 0.15397661924362183, -0.7488970160484314, 0.44073018431663513, -0.14872291684150696, -0.19094721972942352, -0.5259730815887451, -0.7967487573623657, -0.9974430203437805, -0.09374567121267319, 0.21951867640018463, 0.6843181848526001, 0.17597121000289917, 0.6743246912956238, -0.6256821751594543, 0.4945385158061981, 0.8522268533706665, -0.4198947250843048, 0.5491685271263123, 0.18801672756671906, -0.09965585172176361, -0.1134655624628067, 0.26871931552886963, -0.5196260809898376, -0.823010265827179, 0.7104719281196594, -0.1223873421549797, 0.33760973811149597, 0.5332739949226379, -0.529849112033844, -0.37636950612068176, 1.0947328805923462, 0.7683361172676086, 0.5251729488372803, -0.6642496585845947, -0.4303719103336334, 1.3664987087249756, -1.6142878532409668, 0.034863997250795364, 1.652272343635559, 0.6020188927650452, 0.13361746072769165, -0.28221064805984497, -0.8768481016159058, 0.775475025177002, -0.14515429735183716, -0.8029918074607849, -0.9190323948860168, -0.16786013543605804, 0.13437674939632416, 2.0029470920562744, -0.4066023826599121, 0.09828072786331177, 0.6472901105880737, -0.5282419323921204, 1.5065778493881226, -0.24165813624858856, -0.6648317575454712, -0.4749237895011902, 0.1949300915002823, 0.11373239755630493, 0.8854045271873474, -0.4639148414134979, 0.5076484084129333, -0.8769554495811462, -0.2288491129875183, 0.3703487813472748, 0.27669787406921387, -0.13383685052394867, -0.1131950318813324, -0.23812280595302582, 0.9666325449943542, 0.31264927983283997, 1.0839903354644775, -0.4778669774532318, 0.7390525341033936, 0.4909774363040924, 0.3322179317474365, 0.2586154341697693, 0.5503380298614502, -0.25838780403137207, 0.2902217209339142, -1.1767023801803589, 0.2437608242034912, 0.3042862117290497, 0.7034019231796265, -0.37170326709747314, 0.3119749128818512, -0.560081958770752, 0.42478469014167786, 1.5291345119476318, 0.17524453997612, 0.612459659576416, -0.9746648669242859, 0.07018152624368668, -1.0487258434295654, -0.1159415990114212, -0.6019458174705505, 0.015628894791007042, -0.3513212502002716, -1.0187796354293823, -1.6202069520950317, -0.6449853777885437, 0.5159479379653931, -0.7606436610221863, 0.7532824277877808, -0.429394394159317, 0.3765014111995697, 0.012303382158279419, 0.4316941797733307, 0.47702568769454956, 1.0442008972167969, 0.3094758093357086, 0.1440647542476654, 0.9371358156204224, -1.3177061080932617, -0.957651674747467, -1.2564001083374023, 0.6882837414741516, -0.21151039004325867, -0.06555934995412827, 0.10728958249092102, -1.234323263168335, -0.8603366017341614, -0.5272620916366577, -0.04534009471535683, -0.5006638765335083, 0.37452059984207153, 1.1213414669036865, 0.3640652894973755, -1.1572809219360352, 0.6937698125839233, -0.20257660746574402, 0.028736252337694168, 0.39673754572868347, 0.3153904378414154, 0.04319969564676285, -0.5070303082466125, -1.419143795967102, 0.4333952069282532, 0.25314781069755554, -0.5132321715354919, -0.20739533007144928, -0.6381823420524597, -1.1002713441848755, 0.28697434067726135, 0.19056329131126404, -0.6657717227935791, 1.6182386875152588, -0.24168358743190765, -1.3299267292022705, 0.37027281522750854, -0.23525957763195038, -0.06430238485336304, 0.14401067793369293, -0.3724556267261505, -0.5527614951133728, -0.342274934053421, -0.3323003053665161, 0.7678006887435913, 0.46895939111709595, -0.22823454439640045, -0.09306586533784866, 0.38696810603141785, -0.25683191418647766, -0.0007984833209775388, -0.6038025617599487, 0.9284618496894836, -0.5354443788528442, -0.1074826717376709, 0.038338154554367065, 0.80446857213974, -0.3473314940929413, 0.04871750622987747, -0.418488472700119, -0.9863110780715942, 0.5863845944404602, -0.30278247594833374, 1.0216552019119263, -0.935107946395874, -0.747278094291687, -0.010130667127668858, 0.503814160823822, 0.09448948502540588, -1.1325901746749878, 0.5188924074172974, -0.45270949602127075, 0.22684094309806824, -0.010387003421783447, -1.6491485834121704, 0.4834822118282318, -0.1028628721833229, -0.6736094951629639, -0.2657697796821594, -0.08925171196460724, 0.9199733138084412, -1.0340378284454346, 0.005367449019104242, -0.019974885508418083, 0.5567490458488464, -0.82594895362854, 1.3822212219238281, -0.27777090668678284, -0.34050917625427246, 0.23800979554653168, -0.48870980739593506, 0.09464793652296066, -0.30432796478271484, 0.6394769549369812, -0.4610903263092041, 0.05923238396644592, 0.5907682180404663, -0.6212942600250244, 1.1302835941314697, -0.43878164887428284, 0.4819120764732361, 0.18433880805969238, -0.8428709506988525, 0.00025112932780757546, 0.8540319800376892, -0.1323504000902176, -0.5542197227478027, 0.35575225949287415, 0.8797465562820435, -0.6716630458831787, 0.5071431994438171, 0.7481536865234375, 0.3799712359905243, -0.27562808990478516, 0.3144127130508423, 0.7517293095588684, -0.07307692617177963, 0.6715124249458313, 0.5691397190093994, 0.7415130138397217, -0.11483506858348846, 0.36063846945762634, 0.07806800305843353, -0.0253269225358963, -1.3909016847610474, -0.10912203043699265, 0.45613494515419006, 0.7910275459289551, 0.6596221923828125, 0.31019777059555054, -0.761726438999176, -0.36809083819389343, 0.043921228498220444, 0.7816340923309326, 1.3730019330978394, -0.8187766671180725, -0.21396517753601074, -0.4323710501194, -0.21171274781227112, -0.3733195960521698, 0.07042036950588226, -0.2086585909128189, -0.10783330351114273, -0.7429513335227966, -0.8203875422477722, 0.8035565614700317, 0.4415377378463745, 0.6211487650871277, -0.23405860364437103, -0.06782782822847366, -0.404875248670578, 0.12630198895931244, -0.6909331679344177, -0.7623676657676697, 0.4993812143802643, -0.6476860642433167, 0.006798546761274338, -0.24873894453048706, -0.10142102092504501, 0.14912118017673492, -0.6847094297409058, 1.0638655424118042, -0.8082696199417114, 0.21898400783538818, -0.03580889850854874, 0.68119215965271, -0.4646073877811432, -0.6186105608940125, 0.18982842564582825, 0.4759815037250519, -0.2746424078941345, 0.22704821825027466, 0.18024314939975739, 0.0015369273023679852, -0.11399193853139877, -0.2754993140697479, 0.32568687200546265, 0.34669119119644165, -0.007433099672198296, 0.6947409510612488, -0.32553723454475403, -0.19809240102767944, -1.407553791999817, 0.9045512676239014, -0.20911838114261627, -0.40493524074554443, 0.18757914006710052, -0.6077175140380859, -0.15501274168491364, 0.6674526333808899, -0.9333009719848633, -0.15234185755252838, -0.7069177031517029, 0.189994215965271, -0.8153030276298523, 0.0024689261335879564, 0.2548133432865143, 0.2702615261077881, 0.41208919882774353, 0.024097425863146782, 0.4567197859287262, 0.06896866858005524, -0.34270504117012024, 0.906381368637085, -0.7281896471977234, 0.4678165018558502, 0.23003007471561432, 0.317001074552536, -0.3732635974884033, -0.6121333241462708, -0.4338918924331665, -0.15527166426181793, -0.7618590593338013, 0.20623299479484558, 0.011130765080451965, -0.24866566061973572, -0.7664201855659485, -0.42700526118278503, -0.24851806461811066, -1.3367732763290405, -0.00717720203101635, 0.0834193080663681, -0.13525047898292542, -0.13379980623722076, -1.16417396068573, -1.5793358087539673, -0.8862324953079224, -0.9378117918968201, -0.9622254371643066, 0.4117615818977356, -0.13540980219841003, -0.477918416261673, -0.5829073786735535, 0.05602893605828285, -0.46029019355773926, 1.479129672050476, -1.0620710849761963, 0.6762343049049377, -0.3429025709629059, -0.1941174417734146, -0.4153275787830353, -0.00745119946077466, 0.6015251874923706, -0.5660107731819153, 0.19102957844734192, -1.101477861404419, 0.26695170998573303, -0.36816057562828064, -0.19896626472473145, 0.28227534890174866, 0.5386953949928284, 0.5164514183998108, -0.4581846296787262, -0.638766884803772, 0.41247108578681946, 1.1993423700332642, -0.8250641226768494, 0.04707763344049454, -0.385755330324173, 0.9534820318222046, 0.06364864110946655, -0.6323765516281128, 0.5016124248504639, 0.3312225341796875, 0.21871738135814667, 0.0523284487426281, -0.2592043876647949, 0.0507819727063179, -0.5298370122909546, 0.49551981687545776, 2.248622417449951, 0.3865400552749634, -0.19572317600250244, -0.6927142143249512, 0.7524974346160889, -1.4305490255355835, -0.6074738502502441, 0.6667032837867737, 0.49752140045166016, 0.4388964772224426, -0.44379526376724243, -0.13420000672340393, -0.1220390573143959, 0.1917923241853714, 0.7315529584884644, 0.027361365035176277, -0.4957697093486786, 0.04213673993945122, 0.7603785991668701, 0.3722977638244629, 0.4235568046569824, -0.1280834972858429, 0.266633540391922, 14.46586799621582, 0.9945186972618103, 0.09841365367174149, 0.9748954176902771, 0.8630461096763611, -0.17331397533416748, -0.61830073595047, -0.1713535189628601, -0.9762681126594543, -0.12156178802251816, 1.6442497968673706, 0.5503054261207581, 0.8453600406646729, 0.14365136623382568, -0.06739084422588348, 0.4290398359298706, -0.5370599627494812, 0.9824033975601196, 0.33019742369651794, -1.3984352350234985, 0.2406102567911148, 0.05836135149002075, 0.5215442180633545, 0.6087813973426819, 0.6621049046516418, 1.1313929557800293, 0.8318704962730408, -0.6180849671363831, 0.5030838251113892, 0.6209154725074768, 0.9996651411056519, 0.10851260274648666, 0.46684128046035767, 0.44816794991493225, -1.0466198921203613, -0.3266124129295349, -0.518530547618866, -1.1513361930847168, 0.4062163829803467, 0.4446616470813751, -0.1957041174173355, -0.7873045206069946, -0.10852429270744324, 0.6559451222419739, 0.49666762351989746, 0.353206604719162, 0.17940449714660645, 0.6108375787734985, -0.6596571803092957, 0.34095415472984314, 0.45257866382598877, 0.45995041728019714, -0.11583485454320908, 0.0021254157181829214, 0.30953842401504517, -0.1339249312877655, 0.018916137516498566, 0.7057432532310486, -0.7438902258872986, -0.020376700907945633, -0.34602347016334534, -0.7683515548706055, 0.10919743031263351, 0.8880532383918762, 0.61685711145401, 0.09551167488098145, -0.5298725366592407, 0.3342360258102417, 0.7437423467636108, 0.251315176486969, 0.05675790458917618, 0.009781149215996265, 0.3492695689201355, -0.3579443693161011, 0.12671558558940887, 0.9463189244270325, 0.16237153112888336, -0.38332146406173706, -0.7911527752876282, -0.5642486214637756, 0.2667434811592102, -0.7624507546424866, -0.7310839295387268, 0.855141282081604, -0.3720548748970032, -0.14199833571910858, 0.22742418944835663, -0.7562915682792664, -0.27312010526657104, 0.4898756742477417, -1.2520627975463867, -0.5814499855041504, 0.6688656806945801, -0.4849598705768585, -0.5142235159873962, -0.053763799369335175, 1.5329482555389404, 0.6620349287986755, -0.3436734080314636, 0.0803038626909256, 0.3156008720397949, -0.0004363202315289527, -0.22431088984012604, -0.5497123599052429, 0.9715200662612915, 0.21056616306304932, -0.01877238228917122, 0.4121299982070923, 0.03233557939529419, 0.2838747501373291, -0.6068878173828125, 0.12806206941604614, 1.276390790939331, -0.6039207577705383, -0.4396339952945709, -0.8070740103721619, -0.46568334102630615, 0.382737398147583, 0.4283103942871094, -0.06017187610268593, 0.4271749258041382, 0.12252148985862732, -0.8563824892044067, -0.07653860747814178, -0.47868919372558594, -0.1895906925201416, 0.5482409596443176, -0.9490634799003601, -0.06878187507390976, 0.14389094710350037, 0.3096540570259094, -0.8584040403366089, -0.5196790099143982, -0.48655349016189575, 0.1929469257593155, 0.07179403305053711, 1.082880973815918, -0.3162784278392792, 0.6057633757591248, 0.9222257137298584, -0.21428997814655304, -0.9432054162025452, -0.06872250884771347, -0.8786225914955139, -0.5748599767684937, -0.18399935960769653, 0.34552261233329773, -0.2536074221134186, 0.031936705112457275, 0.7257955074310303, 0.23868265748023987, -0.5113415122032166, -0.5020759701728821, -0.27175846695899963, -0.3041130304336548, -0.6600089073181152, 0.4269242286682129, -0.04158962517976761, -0.02682807482779026, 0.25989705324172974, 0.3388998210430145, 0.18328265845775604, -0.2896154224872589, -1.0807570219039917, 0.04553908854722977, -0.14019331336021423, -0.2749019265174866, -0.6861478090286255, -0.10414830595254898, -1.5520381927490234, 0.15935678780078888, -0.9822933673858643, 0.05561370775103569, -0.9650143980979919, -0.3145948052406311, -0.06878024339675903, -0.3299632668495178, 0.059527620673179626, 0.39683499932289124, -0.1490996927022934, -0.44908490777015686, -0.6216217279434204, -0.6859334111213684, 0.9286198616027832, 0.7008695006370544, -0.8626999258995056, 0.42146316170692444, -0.1384255737066269, 0.16860049962997437, 0.38596197962760925, 0.11519980430603027, -0.40559694170951843, -0.834434449672699, -1.4164531230926514, 0.43178674578666687, 0.020625703036785126, -0.24396345019340515, -0.6060926914215088, 0.760514497756958, 0.47908058762550354, -0.4026752710342407, 0.3194440007209778, 0.6116068363189697, -1.244631290435791, -0.07062797993421555, 0.2917975187301636, -0.6771557331085205, 0.25515857338905334, 0.08192815631628036, -0.5195385813713074, -0.5009303092956543, 0.7020197510719299, -0.09916689246892929, -1.2922275066375732, -0.38885053992271423, 0.5850389003753662, -0.5594519972801208, -0.044034186750650406, -0.6346107125282288, -0.10731039941310883, -0.9267087578773499, -0.5064237117767334, 0.2122635841369629, 0.14481230080127716, -0.5840681791305542, 0.6041207313537598, 0.5932025909423828, -1.2495636940002441, 0.1711655855178833, 0.528962254524231, -0.07195600867271423, 0.002448462648317218, 0.5550854802131653, 0.5550838708877563, -0.09684556722640991, 0.8583697080612183, 0.494005024433136, 0.8037547469139099, -0.7219200730323792, -0.0805320218205452, 1.0252137184143066, -0.8948244452476501, -0.10625292360782623, 1.4927126169204712, -0.26207223534584045, -1.4463074207305908, 0.43185970187187195, -1.2610583305358887, -0.265330046415329, -0.4435262978076935, 0.6807546019554138, 0.1037411093711853, -0.13725696504116058, -0.10412579029798508, -0.3328258991241455, -0.03257351368665695, 0.10183153301477432, -0.4169791042804718, 0.8827512264251709, 0.0061444444581866264, -0.48522865772247314, 0.5535494685173035, 1.081339955329895, -0.7851629257202148, -0.507949709892273, -1.0948126316070557, -0.7198915481567383, -0.05217895284295082, 0.6354891061782837, -0.23029963672161102, -0.9073143005371094, 0.9367340207099915, 0.4938920736312866, 0.09676288068294525, 0.16973207890987396, -0.2117685079574585, 0.6729996204376221, 0.5247939229011536, -0.13767404854297638, -0.7247263789176941, -0.7433938980102539, 1.3953930139541626, 0.7274034023284912, -0.6307927966117859, 0.1248493418097496, -0.1610773652791977, -0.3712463080883026, 0.6749727725982666, 0.15529856085777283, 0.11626660078763962, 1.020703673362732, 0.11773073673248291, -0.08737418800592422, -0.07654276490211487, -1.1588796377182007, -0.2641284465789795, 0.8831608891487122, 0.8118137121200562, 0.7264867424964905, 0.3565071225166321, 0.3625350296497345, 1.216481328010559, 0.2720688581466675, 0.08515042811632156, -0.13894042372703552, 0.31297430396080017, -0.08462820202112198, -0.039564866572618484, 0.15035782754421234, 1.0539988279342651, -0.47148963809013367, -1.1384913921356201, 0.3458055257797241, 0.036118920892477036, 0.3820090591907501, 0.37531372904777527, 0.9766696095466614, 0.1199587807059288, 0.4768364727497101, 0.2858872413635254, 0.47192272543907166, -0.3708708584308624, -0.24007244408130646, -0.14323364198207855, -0.3776291310787201, -0.12237575650215149, -0.22669225931167603, 0.03847263380885124, -0.10862457752227783, -0.6126815676689148, 0.24356278777122498, -0.02080642431974411, 0.30138394236564636, 1.2780072689056396, 0.3562914729118347, 0.4717245101928711, -0.49668964743614197, -0.543925404548645, -0.5116056203842163, -1.0580450296401978, -0.3338223397731781, -0.5450223684310913, -0.34641513228416443, -0.006314742378890514, -0.26470625400543213, -0.5282827019691467]}, "authors": [{"authorId": "2258963332", "name": "R'obert Csord'as"}, {"authorId": "2350348", "name": "Kazuki Irie"}, {"authorId": "145341374", "name": "J. Schmidhuber"}], "references": [{"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "52045d4d4ae305aebb9e92fbbcf23104242c4d31", "title": "A Study on ReLU and Softmax in Transformer"}, {"paperId": "e0271cb75087ccfd4a8c3351e0f5189a6de04c03", "title": "The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in Transformers"}, {"paperId": "9d125f45b1d2dea01f05281470bc08e12b6c7cba", "title": "Toy Models of Superposition"}, {"paperId": "4be7d1524edb0137599a5cc95f72844b85a52fe1", "title": "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale"}, {"paperId": "8b3a67c7e5289eed160d2acfd04d71cfb552c67d", "title": "Branch-Train-Merge: Embarrassingly Parallel Training of Expert Language Models"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "c26bb68806a992bf4fc85b5639e1657a445c4781", "title": "On the Representation Collapse of Sparse Mixture of Experts"}, {"paperId": "c2536182c010c41941e8a031071a1880c34cec60", "title": "Unified Scaling Laws for Routed Language Models"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "e528466e2aff981511d4ca6e063211297c0b4175", "title": "The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization"}, {"paperId": "6b95a0c36683025ff38c66128b817d3640a7e03a", "title": "Unbiased Gradient Estimation with Balanced Assignments for Mixtures of Experts"}, {"paperId": "b15ea460c77a4ee8aa159a30ab0331deedfcf392", "title": "BASE Layers: Simplifying Training of Large, Sparse Models"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "4a54d58a4b20e4f3af25cea3c188a12082a95e02", "title": "Transformer Feed-Forward Layers Are Key-Value Memories"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "1882f194cb43828852cc052887671e55a80f945a", "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "ce106590145e89ea4b621c99665862967ccf5dac", "title": "Q8BERT: Quantized 8Bit BERT"}, {"paperId": "f3fbcfbb396f6c0391674c8637a373b729e5e531", "title": "Compositionality Decomposed: How do Neural Networks Generalise?"}, {"paperId": "bf442ab269074665a68e4dbbe19e4efc97862541", "title": "Large Memory Layers with Product Keys"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "3504bc0739501220d07e8e3ecb4ad26a06fc50ad", "title": "RADMM: Recurrent Adaptive Mixture Model with Applications to Domain Robust Language Modeling"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586", "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"}, {"paperId": "2cd8e8f510c89c7c18268e8ad51c061e459ad321", "title": "A Decomposable Attention Model for Natural Language Inference"}, {"paperId": "13fe71da009484f240c46f14d9330e932f8de210", "title": "Long Short-Term Memory-Networks for Machine Reading"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "d6f2f611da110b5b5061731be3fc4c7f45d8ee23", "title": "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649", "title": "Understanding the difficulty of training deep feedforward neural networks"}, {"paperId": "bf10cc938c5f564e2c8038548ec20c5c47355237", "title": "Compositionality I: Definitions and Variants"}, {"paperId": "c8d90974c3f3b40fa05e322df2905fc16204aa56", "title": "Adaptive Mixtures of Local Experts"}, {"paperId": "56cbfcbfffd8c54bd8477d10b6e0e17e097b97c7", "title": "Connectionism and cognitive architecture: A critical analysis"}, {"paperId": "70e0d2487440b519b392503f4fa6b94891238c90", "title": "Concerning nonnegative matrices and doubly stochastic matrices"}, {"paperId": "f7256f6acf51e253a567df57412cf4e21ccdda78", "title": "CYBERNETIC PREDICTING DEVICES"}, {"paperId": "441f33fab0614fa0696be54a046cbc692b7e70a2", "title": "A Relationship Between Arbitrary Positive Matrices and Doubly Stochastic Matrices"}, {"paperId": null, "title": "Vicuna: An opensource chatbot impressing gpt-4 with 90%* chatgpt"}, {"paperId": null, "title": "Stanford alpaca: An instruction-following llama model"}, {"paperId": null, "title": "peS2o (Pretraining Efficiently on S2ORC) Dataset"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Learning to control fastweight memories: An alternative to recurrent nets"}]}