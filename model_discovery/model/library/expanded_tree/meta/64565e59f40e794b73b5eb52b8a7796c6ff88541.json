{"paperId": "64565e59f40e794b73b5eb52b8a7796c6ff88541", "abstract": "This paper presents Z-Code++, a new pre-trained language model optimized for abstractive text summarization. The model extends the state-of-the-art encoder-decoder model using three techniques. First, we use a two-phase pre-training to improve the model\u2019s performance on low-resource summarization tasks. The model is first pre-trained using text corpora for language understanding, then is continually pre-trained on summarization corpora for grounded text generation. Second, we replace self-attention layers in the encoder with disentangled attention layers, where each word is represented using two vectors that encode its content and position, respectively. Third, we use fusion-in-encoder, a simple yet effective method of encoding long sequences in a hierarchical manner. Z-Code++ createsa new state-of-the-art on 9 of 13 text summarization tasks across 5 languages. Our model is parameter-efficient in that it outperforms the 600x larger PaLM540B on XSum, and the finetuned 200x larger GPT3175B on SAMSum. In zero-shot and few-shot settings, our model substantially outperforms the competing models.", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2022, "citationCount": 33, "influentialCitationCount": 3, "openAccessPdf": {"url": "http://arxiv.org/pdf/2208.09770", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "Z-Code++, a new pre-trained language model optimized for abstractive text summarization, is presented, which is parameter-efficient in that it outperforms the 600x larger PaLM540B on XSum, and the finetuned 200x larger GPT3175B on SAMSum."}, "embedding": {"model": "specter_v2", "vector": [0.18610981106758118, 0.39601972699165344, -0.4341103434562683, -0.11074411123991013, -0.6776024699211121, -0.4653938114643097, 0.6613015532493591, 0.45011794567108154, -0.3668701946735382, 0.199849933385849, 1.295980453491211, 0.17256003618240356, 0.21186737716197968, -0.04542138800024986, -0.08880707621574402, 0.18802058696746826, -0.6957514882087708, 0.04715510457754135, -0.28123342990875244, -0.4855960011482239, 0.5373089909553528, -1.1763947010040283, -0.6166413426399231, 0.501890242099762, 0.9816885590553284, -0.04861005023121834, -0.05285806581377983, 1.4217532873153687, -0.4591076076030731, 0.5197676420211792, -0.050022900104522705, -0.2372802048921585, -0.14282305538654327, -0.46657153964042664, -0.6878724098205566, 0.07671967893838882, 0.36851629614830017, -0.6482560038566589, -0.03319132328033447, 0.5458443760871887, 0.010450120083987713, 0.11537252366542816, 0.7217077612876892, -0.08572196960449219, -0.22833281755447388, 1.2836191654205322, 0.47615134716033936, 0.6537142395973206, 0.11362187564373016, -0.4067874848842621, 1.6722491979599, -1.3055864572525024, 0.3043045103549957, 1.270327091217041, 0.22013476490974426, 0.6707311272621155, -0.0964825227856636, -0.3035999834537506, 0.7310746312141418, 0.08874896913766861, -0.6578904986381531, -0.5564565658569336, -0.157514750957489, -0.28136706352233887, 2.019000768661499, -0.18984217941761017, 0.1420464813709259, 0.20923244953155518, -0.042569175362586975, 1.7259985208511353, -0.7989514470100403, -0.5091906189918518, -0.25464919209480286, -0.36019444465637207, 0.8274176120758057, 0.7413208484649658, -0.038026828318834305, -0.239608496427536, -0.9785552024841309, 0.031701989471912384, -0.08178536593914032, -0.03795470669865608, -0.49863892793655396, 0.04879529029130936, -0.4648214280605316, 0.67664635181427, 0.24200595915317535, 0.8420089483261108, -0.3205026090145111, 0.6972775459289551, 0.7305060029029846, 0.2453482747077942, 0.5535136461257935, 0.66875821352005, -0.06337495148181915, 0.3465847969055176, -1.2010242938995361, 0.7703183889389038, -0.06028240546584129, 0.5783591866493225, -0.19864541292190552, 0.37004178762435913, -1.2588465213775635, -0.006474672816693783, 0.8696256279945374, 0.016949938610196114, 0.23440632224082947, -1.0180563926696777, 0.34604504704475403, -0.4162464737892151, 0.2104446291923523, -0.6468388438224792, -0.19769743084907532, -0.14136795699596405, -0.8340311050415039, -1.2886089086532593, -0.6513538360595703, -0.20773173868656158, -0.5662620663642883, 0.7871780395507812, -0.5951364040374756, -0.07630398124456406, 0.5857747197151184, 0.21009282767772675, 1.1224595308303833, 1.100219964981079, -0.0455641970038414, -0.503146767616272, 0.8493323922157288, -1.0020493268966675, -1.1995859146118164, -0.9496961236000061, 1.0100818872451782, -0.16067452728748322, -0.2584971487522125, -0.09425322711467743, -1.4514046907424927, -0.6441691517829895, -1.1717556715011597, -0.14109869301319122, -0.2635815143585205, 0.40762534737586975, 0.5775253176689148, 0.32824596762657166, -0.8867077231407166, 0.8389742970466614, -0.11903558671474457, -0.27460893988609314, 0.2598937451839447, -0.15010425448417664, 0.22032110393047333, -0.349955677986145, -0.9597628116607666, 0.18995942175388336, 0.2749960124492645, -0.8385898470878601, -0.04384353384375572, -0.843661367893219, -1.1849067211151123, -0.05337125062942505, 0.35896801948547363, -0.9254444241523743, 1.566548228263855, 0.13890855014324188, -1.4647109508514404, 0.43482401967048645, -0.6590202450752258, -0.20953239500522614, -0.05478586256504059, -1.0438569784164429, -0.13382798433303833, 0.11011732369661331, 0.036639440804719925, 0.3134794533252716, 0.04790627583861351, 0.020527370274066925, -0.052741363644599915, 0.3150475323200226, -0.41454216837882996, -0.07144676893949509, -0.27206483483314514, 0.848111629486084, -0.43455827236175537, -0.30318546295166016, 0.16899709403514862, 1.0803803205490112, 0.11605171114206314, -0.740601122379303, -0.8595077395439148, -1.1313984394073486, 0.570813775062561, -0.08092314749956131, 1.286151647567749, -0.7273921370506287, -0.4355335533618927, -0.7103947997093201, 0.04724627733230591, 0.3364049196243286, -0.6819390058517456, 0.8589568734169006, -0.29514262080192566, 0.7528833746910095, -0.4062109589576721, -1.1983786821365356, -0.07194434106349945, -0.44694364070892334, -0.8232241272926331, -0.3417147696018219, 0.5288740396499634, 1.1242527961730957, -1.007692813873291, 0.025979788973927498, -0.10238975286483765, -0.07726181298494339, -1.419724464416504, 1.1288797855377197, -0.5328546762466431, 0.31120339035987854, -0.5296854376792908, -0.5506101250648499, -0.024780482053756714, -0.037660375237464905, -0.11615726351737976, -0.170824334025383, -0.6058211922645569, 0.3604412376880646, -0.29854726791381836, 1.6285185813903809, 0.05944366380572319, 0.38296857476234436, -0.22633863985538483, -0.5128219127655029, 0.2397494614124298, 0.6400901079177856, -0.03591049462556839, 0.06519115716218948, 0.32183757424354553, 0.273333340883255, -1.0632482767105103, -0.05787507817149162, 1.0384202003479004, 1.1265443563461304, -0.7995009422302246, 0.3674726188182831, 0.6440097689628601, -0.48418986797332764, 1.0741820335388184, 0.9676390886306763, 0.9390314221382141, 0.22923485934734344, 0.6237579584121704, -0.16020101308822632, 0.47182008624076843, -0.4278346598148346, -0.011238260194659233, 0.5823939442634583, 0.8887498378753662, 1.373267412185669, 0.4460009038448334, -0.7389498949050903, -0.17338477075099945, -0.12705759704113007, 1.2769207954406738, 1.168462872505188, -0.06391166150569916, -0.7235240936279297, -0.9997405409812927, -0.2668474614620209, -0.6086754202842712, 0.6135892868041992, -0.18680313229560852, -0.5585457682609558, -0.4715180993080139, -0.971910834312439, 0.7487146258354187, 0.1497756391763687, 1.2614761590957642, -0.2488168179988861, -0.24472209811210632, -0.338344544172287, -0.2592860162258148, -0.6124098896980286, -0.9769119620323181, 0.05200837552547455, -0.35987964272499084, -0.11558319628238678, -0.27600225806236267, 0.029222939163446426, 0.021189609542489052, -0.33140918612480164, 1.1627748012542725, -0.2180226892232895, -0.1353272646665573, 0.0910920724272728, 0.2376331388950348, -0.8056066632270813, -0.6495475769042969, 0.15223050117492676, 0.07477977871894836, -0.18641482293605804, 0.22756804525852203, 0.7439584732055664, -0.13481710851192474, -0.46920046210289, -0.5257489085197449, 0.188142791390419, -0.07057555764913559, -0.2071395069360733, 0.16009727120399475, -0.3903541564941406, 0.15358208119869232, -0.9712719917297363, 1.272728681564331, 0.26245447993278503, 0.13392047584056854, 0.17606034874916077, -0.07681973278522491, -0.15422752499580383, 0.20604082942008972, -0.3045589029788971, -0.4270135760307312, -1.2192882299423218, 0.41079458594322205, 0.4941798746585846, -0.024360135197639465, 0.4741983711719513, 0.1663392335176468, 0.8291870355606079, 0.20414811372756958, 0.4586182236671448, 0.34868693351745605, -0.11135737597942352, 0.790775716304779, -0.6214696764945984, 0.9261471629142761, 0.5823755860328674, 0.07607394456863403, -0.2686265707015991, -0.5202094912528992, -0.9808930158615112, -0.5890146493911743, -0.4157955050468445, 0.1225147694349289, -0.1916005164384842, 0.8406416773796082, -0.7079272866249084, -0.5332682132720947, 0.07471569627523422, -1.6900317668914795, -0.09959810227155685, -0.1248517856001854, -0.4786418378353119, -0.20679844915866852, -0.6682630181312561, -0.9594075679779053, -0.5981540679931641, -1.1264251470565796, -0.6291947364807129, 0.7162781953811646, 0.1948937624692917, -1.1070297956466675, -0.18972843885421753, 0.3676140606403351, -0.6068260073661804, 0.5308844447135925, -0.014278203248977661, 0.5151401162147522, -0.16959424316883087, -0.09658075124025345, -0.44601333141326904, 0.5319180488586426, 0.7148069143295288, -0.28662601113319397, 0.37489190697669983, -0.11687887459993362, 0.1814689338207245, -0.24694375693798065, -0.2536593973636627, 0.7346345782279968, 0.7263267040252686, 0.2863341271877289, -0.11133429408073425, -0.3865519165992737, 0.18264055252075195, 1.1528807878494263, -0.6488130688667297, -0.016055094078183174, -0.1312200129032135, 0.825249195098877, 0.387370765209198, -0.24915476143360138, 0.6972419619560242, 0.36478057503700256, 0.28526630997657776, 0.02156684175133705, -0.2769415080547333, -0.13382233679294586, -0.19983425736427307, 0.8991738557815552, 1.717363715171814, 0.32073649764060974, -0.6312987208366394, -0.9388655424118042, 0.9819467067718506, -1.376372218132019, -0.7844208478927612, 0.04664647579193115, 0.3049924969673157, 0.42877984046936035, -0.7033299207687378, -0.2967093288898468, 0.09359098225831985, 0.36215710639953613, 0.4140540063381195, -0.12490803748369217, -1.0072941780090332, -0.037262726575136185, 0.2221725583076477, -0.1083824411034584, 1.0121477842330933, -0.24348700046539307, 0.6157330870628357, 14.461130142211914, 0.484846830368042, 0.2640700340270996, 0.12512646615505219, 0.4610622525215149, -0.3492130935192108, -0.44325244426727295, -0.09556256979703903, -0.9552968740463257, -0.3468005359172821, 0.8021823763847351, -0.5413254499435425, -0.01397513784468174, -0.19844037294387817, 0.3803092837333679, -0.07786566019058228, -0.5520036816596985, 0.5432277321815491, 0.646598219871521, -1.509490966796875, 0.7114062309265137, 0.1647726148366928, 0.4670740067958832, 0.17103229463100433, 0.705264687538147, 0.7988969683647156, 0.4764862656593323, -0.2228253036737442, 0.4430907666683197, 0.4476214647293091, 0.4822319447994232, -0.5151070356369019, 0.5600393414497375, 0.9290505647659302, -0.48480063676834106, -0.19955691695213318, -0.46453189849853516, -1.302895188331604, 0.6379978060722351, 0.22107726335525513, -0.36615845561027527, 0.1726558804512024, -0.2744268774986267, 0.9051203727722168, 0.1453125774860382, 0.2698797285556793, -0.19339123368263245, 0.6385835409164429, 0.37090492248535156, -0.35370248556137085, 0.3152593970298767, 0.41086483001708984, 0.6612696051597595, 0.3055659830570221, 0.27237099409103394, 0.42183637619018555, 0.21788112819194794, 0.369611918926239, -0.42735257744789124, -0.056046631187200546, -0.588457465171814, -0.18721425533294678, -0.18521825969219208, 0.31626075506210327, 0.8236523270606995, -0.09664300084114075, -0.3064908981323242, 0.3000505566596985, 0.23378878831863403, 0.03459247201681137, -0.03736502304673195, -0.5992686152458191, 0.1506756693124771, -0.22879160940647125, 0.06649485230445862, 0.3624272346496582, -0.44478145241737366, -0.6296432614326477, -0.9536724090576172, -0.38109108805656433, 0.31638601422309875, -0.7845099568367004, -0.23605012893676758, 0.8455780148506165, -0.06976646184921265, -0.5371497273445129, -0.1741286814212799, -0.2804296612739563, -0.8840073943138123, 0.26746270060539246, -0.9707277417182922, -0.2915607690811157, 0.23834958672523499, -0.7834983468055725, -0.006767566315829754, -0.2298489362001419, 1.2959553003311157, -0.37364375591278076, -0.5371440052986145, -0.3860483765602112, 0.20156316459178925, -0.31890955567359924, -0.08453306555747986, -1.0289357900619507, 0.8692837357521057, 0.6664066314697266, -0.5634168982505798, 0.2983756959438324, 0.3715912997722626, 0.013793526217341423, -0.7512187361717224, -0.2815825939178467, 1.0126616954803467, -1.008049488067627, -0.7201589345932007, -0.7037310600280762, -0.9470388293266296, -0.10607469081878662, 1.1454644203186035, -0.8137474656105042, 0.41731196641921997, -0.0404287651181221, 0.06780537217855453, -0.04821302741765976, -0.7519455552101135, 0.2866293489933014, 0.26289477944374084, -0.13482028245925903, -0.5577471852302551, -0.07357195764780045, 0.9639248251914978, -0.5504845976829529, -0.09015797823667526, -0.2763637900352478, -0.27236151695251465, -0.09561920166015625, 0.8398891091346741, 0.050680894404649734, 1.0930439233779907, 0.7438269853591919, 0.2995818257331848, -1.103142499923706, -0.10027073323726654, -1.2778747081756592, 0.08000069111585617, 0.6448090672492981, 0.5433387756347656, -0.0736892819404602, 0.21997301280498505, 0.5137531757354736, 0.07419896870851517, -0.3368881642818451, -0.4335044026374817, -0.1606621891260147, 0.526530385017395, -0.11656748503446579, 0.2351682335138321, -0.31154435873031616, 0.2965230941772461, 0.4397048056125641, 0.4134800434112549, 0.36325687170028687, -0.15132832527160645, -0.9348204731941223, 0.9860820770263672, -0.11058467626571655, 0.3021533191204071, -0.9060112237930298, -0.23342709243297577, -1.384581208229065, -0.15647859871387482, -0.9331767559051514, 0.1541442573070526, -1.5691016912460327, -0.1455366015434265, 1.3140780925750732, 0.43914586305618286, -0.07911854237318039, -0.14787541329860687, -0.5094541907310486, -0.48697760701179504, -0.9313335418701172, -0.950585663318634, 0.9281128644943237, 0.7814581394195557, -0.9104679226875305, -0.19848516583442688, -0.3414778411388397, -0.6185940504074097, 0.30636662244796753, 0.6401240825653076, -0.24901671707630157, -0.7948890328407288, -1.6113253831863403, 0.22635847330093384, -0.04086535423994064, -0.05408981442451477, -0.8174765110015869, 0.6318264007568359, 0.7826220393180847, -0.2126726508140564, -0.8180923461914062, -0.19152124226093292, -0.05108767747879028, -0.7949717044830322, 0.5677022933959961, -0.8014670014381409, 0.32608887553215027, 0.3599722981452942, -0.5910564064979553, -0.5399022698402405, 0.7384052276611328, -0.4332905411720276, -1.0745866298675537, -0.45794442296028137, 0.33454346656799316, -0.9970819354057312, 0.1658850908279419, -0.3419792056083679, -0.0952138900756836, -1.2067973613739014, -0.6670470237731934, 0.4502892792224884, 0.7566668391227722, -0.34497037529945374, 0.9401366710662842, 0.49327704310417175, -0.8618909120559692, -0.6633040904998779, 0.2114214301109314, -0.07721256464719772, 0.16603100299835205, 0.6684964895248413, 0.1517173796892166, -0.44542235136032104, 0.337426096200943, 0.6424127817153931, 0.2076631635427475, -0.7999973893165588, -0.2429521530866623, 0.40583112835884094, -0.720231294631958, -0.15662382543087006, 1.041878342628479, -0.28872472047805786, -0.8405914306640625, -0.14139072597026825, -1.346065878868103, -0.684277355670929, -0.21821092069149017, 1.2743017673492432, 0.37342798709869385, -0.2350391000509262, 0.0035194207448512316, -0.5347966551780701, 0.46941158175468445, -0.212114155292511, -0.6431340575218201, 0.8712033629417419, -0.13507767021656036, -0.6025057435035706, 0.5900452136993408, 0.8623644709587097, -0.6072471141815186, -0.40958067774772644, -0.6175417900085449, -0.09051749855279922, 0.4007408618927002, 0.47937458753585815, -0.24820993840694427, -0.08433207124471664, 0.8348686099052429, -0.06919831782579422, 0.5510784387588501, 0.3009934425354004, -0.43259352445602417, 0.2774626910686493, 0.5773866772651672, -0.4506646394729614, -0.7132031917572021, -0.16400723159313202, 1.488292932510376, 1.5209904909133911, -0.7317470908164978, 0.7124881744384766, -0.07386785745620728, -0.9024342894554138, 0.8778557181358337, -0.1137458011507988, -0.23136553168296814, 0.34509918093681335, -0.3202095925807953, 0.18531139194965363, 0.06671818345785141, -1.2774133682250977, -0.26039746403694153, 0.8513421416282654, 0.8832685947418213, 1.0447150468826294, 0.06582705676555634, -0.20171181857585907, 1.025376558303833, 0.13067607581615448, 0.032893724739551544, 0.8831980228424072, 0.43649762868881226, -0.49359580874443054, 0.11134617775678635, 0.03689463809132576, 0.21189190447330475, -0.7546505928039551, -0.35840553045272827, -0.3863355219364166, 0.4463820457458496, 0.017514847218990326, 1.1710009574890137, 0.659903347492218, 0.3040703535079956, 0.6972829699516296, 0.10927724838256836, 0.3146982192993164, -0.9005075097084045, -0.5103769302368164, -0.2754204273223877, -0.40927037596702576, -0.0298309288918972, -0.22176341712474823, -0.6904515027999878, -0.43683087825775146, -0.26770156621932983, 0.24185332655906677, 0.3282434940338135, 0.1270652711391449, 1.2930668592453003, 0.7310998439788818, 0.738136887550354, -0.36456117033958435, -0.5852422714233398, -0.3206978440284729, -1.1409286260604858, 0.014929313212633133, -0.5167015194892883, 0.2574756443500519, 0.1023431122303009, -0.10357527434825897, -0.06000848859548569]}, "authors": [{"authorId": "50462546", "name": "Pengcheng He"}, {"authorId": "1780690", "name": "Baolin Peng"}, {"authorId": "2152515481", "name": "Liyang Lu"}, {"authorId": "2117074851", "name": "Song Wang"}, {"authorId": "2052119293", "name": "Jie Mei"}, {"authorId": "39798499", "name": "Yang Liu"}, {"authorId": "8233965", "name": "Ruochen Xu"}, {"authorId": "3032929", "name": "H. Awadalla"}, {"authorId": "1844953096", "name": "Yu Shi"}, {"authorId": "8652308", "name": "Chenguang Zhu"}, {"authorId": "145814376", "name": "Wayne Xiong"}, {"authorId": "48262024", "name": "Michael Zeng"}, {"authorId": "48441311", "name": "Jianfeng Gao"}, {"authorId": "144531812", "name": "Xuedong Huang"}], "references": [{"paperId": "f2d952a183dfb0a1e031b8a3f535d9f8423d7a6e", "title": "Mastering Diverse Domains through World Models"}, {"paperId": "e47da75675b9a3fe02ef1efadca39bc8cdfcdc17", "title": "Designing Effective Sparse Expert Models"}, {"paperId": "b6ec1e8f18185b4b3d46201359a440404575460c", "title": "METRO: Efficient Denoising Pretraining of Large Scale Autoencoding Language Models with Model Generated Signals"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "e96493b4181de6c60b761dc66492db8e66fd784f", "title": "Long Document Summarization with Top-down and Bottom-up Inference"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "e4e9d556e9725a5fdb2e133b61243ff7c1ca8aeb", "title": "Repairing the Cracked Foundation: A Survey of Obstacles in Evaluation Practices for Generated Text"}, {"paperId": "3def68bd0f856886d34272840a7f81588f2bc082", "title": "Survey of Hallucination in Natural Language Generation"}, {"paperId": "b97a33933541c276778c3fe63baad6964f4bdf44", "title": "Neural Approaches to Conversational Information Retrieval"}, {"paperId": "3dfb1f50f2a34a699c339dabaa6f9b3a977973de", "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences"}, {"paperId": "972706306f85b1bfb40c7d35c796ad5174eb0c9c", "title": "DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "dbae4c89a93597c41ec4373f6da03a93eac2927b", "title": "Leveraging Pretrained Models for Automatic Summarization of Doctor-Patient Conversations"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "077108a733f9b505437d404bf44d85a5858a434f", "title": "Learning to Sample Replacements for ELECTRA Pre-Training"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "9623e9e461647a10a8f14419a9abe40482e9eb47", "title": "MediaSum: A Large-scale Media Interview Dataset for Dialogue Summarization"}, {"paperId": "161321ef451d658d66b762cba5c202b12260220e", "title": "Data Augmentation for Abstractive Query-Focused Multi-Document Summarization"}, {"paperId": "824cd8db8a68732db04f4d8b7139eb4475e59ff2", "title": "The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics"}, {"paperId": "789b5441743c2e38cf4c38749ed820c0671d81b1", "title": "Muppet: Massive Multi-task Representations with Pre-Finetuning"}, {"paperId": "74276a37bfa50f90dfae37f767b2b67784bd402a", "title": "mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer"}, {"paperId": "f00f2d4b8ddd55aa2cc202f44053e5f97a254175", "title": "WikiLingua: A New Benchmark Dataset for Multilingual Abstractive Summarization"}, {"paperId": "8d2cb5d898a2299d96ca776f75908956ad6de03e", "title": "Multi-task Learning for Multilingual Neural Machine Translation"}, {"paperId": "053b1d7b97eb2c91fc3921d589c160b0923c70b1", "title": "Learning to summarize from human feedback"}, {"paperId": "ea8c46e193d5121e440daf96edfd15a47151c293", "title": "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering"}, {"paperId": "e23cb51f50f749320b9122fb5f75113b4d192c0a", "title": "Evaluation of Text Generation: A Survey"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "24e4d3370dc366d6b353d1d6818a0df266bb31b9", "title": "MLSUM: The Multilingual Summarization Corpus"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "f9700e31a1d0ae34d4571ab056dfb268c1543349", "title": "SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization"}, {"paperId": "16dbfa7ad452277d2c568913d2550a9a58a43b62", "title": "CCMatrix: Mining Billions of High-Quality Parallel Sentences on the Web"}, {"paperId": "46b8201f1b84950f141cbbb5eeccaa1437159ff4", "title": "A Massive Collection of Cross-Lingual Web-Document Pairs"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "af93e1accba69994cdc36254ef93584af307fd8a", "title": "Neural Text Summarization: A Critical Evaluation"}, {"paperId": "63748e59f4e106cbda6b65939b77589f40e48fcb", "title": "Text Summarization with Pretrained Encoders"}, {"paperId": "81f5810fbbab9b7203b9556f4ce3c741875407bc", "title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans"}, {"paperId": "cc27ec53160d88c25fc5096c0df65536eb780de4", "title": "Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model"}, {"paperId": "7cc730da554003dda77796d2cb4f06da5dfd5592", "title": "Hierarchical Transformers for Multi-Document Summarization"}, {"paperId": "ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc", "title": "Cross-lingual Language Model Pretraining"}, {"paperId": "a01fb557abc65ec5c37c28ca18298f27aa0dba72", "title": "Abstractive Summarization of Reddit Posts with Multi-level Memory Networks"}, {"paperId": "305b2cf37e5dece81e95c92883d5a6e28ac93b22", "title": "Don\u2019t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"}, {"paperId": "4e346eb1628df6a12c1a121f862fb3a16c6fec60", "title": "Newsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "12a50024da4b1ad71ddab2fb68785dc56c2e540f", "title": "Text Summarization Techniques: A Brief Survey"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "668db48c6a79826456341680ee1175dfc4cced71", "title": "Get To The Point: Summarization with Pointer-Generator Networks"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "7a67159fc7bc76d0b37930b55005a69b51241635", "title": "Abstractive Sentence Summarization with Attentive Recurrent Neural Networks"}, {"paperId": "f37076f426023241f19cdc2fb0a0fd733a6fa7fa", "title": "Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond"}, {"paperId": "1ac30af5522c7a50ec4d1ee43fd2bd8652a9bd52", "title": "A Neural Attention Model for Abstractive Sentence Summarization"}, {"paperId": "f40aeae3e522ada1f6a9f326841b01ef5c8657b6", "title": "Unifying Language Learning Paradigms"}, {"paperId": null, "title": "Large-scale pretraining for goal-directed dialogue"}, {"paperId": "775f42ed458b8c5b0f2094ea4ff5b64c557b1a34", "title": "A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27"}, {"paperId": null, "title": "Holistic evaluation of language models. arXiv preprint arXiv:2211.09110"}, {"paperId": "7e4d5dad222877e0b526de63b37e548cd4b2c0ae", "title": "A Thorough Evaluation of Task-Specific Pretraining for Summarization"}, {"paperId": "acf2dd4e2853f90832c01c556a2e716e7c720bc2", "title": "G ENIE A Leaderboard for Human-in-the-Loop Evaluation of Text Generation"}, {"paperId": "2a7023e7d1dbd6ea0d98efd09a1f18d8599fe78f", "title": "PRIMER: Pyramid-based Masked Sentence Pre-training for Multi-document Summarization"}, {"paperId": null, "title": "ELECTRA: Pre-training text encoders as discriminators rather than generators"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic (e.g., country of residence)? Not applicable"}, {"paperId": null, "title": "Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? Not applicable"}, {"paperId": null, "title": "Was the data collection protocol approved (or determined exempt) by an ethics review board? Not applicable"}, {"paperId": null, "title": "error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single run? Section 3, experiments C4"}, {"paperId": null, "title": "screenshots, disclaimers of any risks to participants or annotators, etc.? Not applicable"}, {"paperId": null, "title": "Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values? Section 3, experiments and appendix A 1"}]}