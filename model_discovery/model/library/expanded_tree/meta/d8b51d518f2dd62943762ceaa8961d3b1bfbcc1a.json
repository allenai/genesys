{"paperId": "d8b51d518f2dd62943762ceaa8961d3b1bfbcc1a", "abstract": "The needle-in-a-haystack (NIAH) test, which examines the ability to retrieve a piece of information (the\"needle\") from long distractor texts (the\"haystack\"), has been widely adopted to evaluate long-context language models (LMs). However, this simple retrieval-based test is indicative of only a superficial form of long-context understanding. To provide a more comprehensive evaluation of long-context LMs, we create a new synthetic benchmark RULER with flexible configurations for customized sequence length and task complexity. RULER expands upon the vanilla NIAH test to encompass variations with diverse types and quantities of needles. Moreover, RULER introduces new task categories multi-hop tracing and aggregation to test behaviors beyond searching from context. We evaluate ten long-context LMs with 13 representative tasks in RULER. Despite achieving nearly perfect accuracy in the vanilla NIAH test, all models exhibit large performance drops as the context length increases. While these models all claim context sizes of 32K tokens or greater, only four models (GPT-4, Command-R, Yi-34B, and Mixtral) can maintain satisfactory performance at the length of 32K. Our analysis of Yi-34B, which supports context length of 200K, reveals large room for improvement as we increase input length and task complexity. We open source RULER to spur comprehensive evaluation of long-context LMs.", "venue": "arXiv.org", "year": 2024, "citationCount": 35, "influentialCitationCount": 10, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A new synthetic benchmark RULER is created with flexible configurations for customized sequence length and task complexity to provide a more comprehensive evaluation of long-context language models (LMs)."}, "embedding": {"model": "specter_v2", "vector": [0.08231710642576218, -0.09548377245664597, -0.20355059206485748, -0.1261441558599472, -0.6434370875358582, -0.6797599196434021, 0.6019778847694397, -0.012574169784784317, -0.553817868232727, -0.027432523667812347, 0.5636426210403442, -0.6883746981620789, -0.08579252660274506, 0.33733925223350525, 0.059231821447610855, 0.06320442259311676, -0.9471851587295532, 0.33724674582481384, -0.3824840784072876, -0.5033156275749207, 0.17982372641563416, -0.9398995041847229, -0.45191797614097595, 0.1886761486530304, 0.7955164313316345, -0.03114224597811699, 0.5347044467926025, 1.0646339654922485, -0.49454638361930847, 0.2513682246208191, 0.05793230980634689, -0.33356547355651855, 0.0758037120103836, 0.22984331846237183, -0.3400007486343384, -0.5253103971481323, 0.3355470597743988, -0.37142637372016907, -0.2947145998477936, 0.4879695475101471, 0.0409773588180542, 0.16490128636360168, 0.4216446280479431, -0.12088643014431, -0.5270462036132812, 1.2390762567520142, 0.8068287968635559, 0.5991517305374146, 0.4354422390460968, -0.41289785504341125, 1.5394151210784912, -1.5237582921981812, 0.4599270224571228, 1.2464287281036377, 0.4721466302871704, 0.28296032547950745, -0.3257749378681183, -0.7847752571105957, 0.9745074510574341, -0.16902445256710052, -1.1400277614593506, -0.28215667605400085, -0.45582014322280884, 0.02247394062578678, 1.9891877174377441, -0.310023695230484, -0.12267167866230011, 0.9915933012962341, 0.048823971301317215, 1.5998761653900146, -0.28369900584220886, -0.8646892309188843, -0.3776891529560089, -0.4181082248687744, 0.4711843430995941, 0.26137229800224304, -0.20620177686214447, 0.31928372383117676, -0.5549782514572144, -0.2786189913749695, 0.22102969884872437, -0.1983577013015747, -0.27622169256210327, 0.43744659423828125, -0.7442678809165955, 0.45680689811706543, 0.045648522675037384, 1.169144630432129, -0.10521791875362396, 0.3813803493976593, 0.30293431878089905, 0.707425594329834, -0.07356501370668411, 0.5369410514831543, -0.25548508763313293, 0.08263947814702988, -1.1290593147277832, 0.5463854074478149, 0.3042965531349182, 1.0479985475540161, -0.27412092685699463, 0.2506045401096344, -0.9133559465408325, 0.503424882888794, 1.2017815113067627, 0.2390655279159546, 0.694502055644989, -0.6285333037376404, 0.3389596939086914, -0.6587812304496765, 0.6791824102401733, -0.40973806381225586, -0.28080952167510986, -0.3755318820476532, -0.032024748623371124, -1.3019022941589355, 0.18069854378700256, -0.426845520734787, -0.28093981742858887, 0.6287707090377808, -0.25821277499198914, 0.09181002527475357, 0.45541876554489136, 0.6276609897613525, 0.6717889308929443, 0.6714634895324707, 0.335872083902359, 0.019170202314853668, 0.7110806107521057, -0.5096637010574341, -0.5251831412315369, -1.1924200057983398, 1.2498233318328857, -0.5522035956382751, 0.6778441071510315, -0.09952455759048462, -1.0522478818893433, -0.7145360708236694, -0.9307988286018372, -0.05642765387892723, -0.7688647508621216, 0.37998801469802856, 0.837573230266571, 0.34130337834358215, -0.8071042895317078, 0.7551701068878174, 0.3470648229122162, -0.18375523388385773, -0.3134380578994751, -0.25131022930145264, 0.33488938212394714, -0.9147480726242065, -1.5899513959884644, 0.2625007629394531, 0.3727019429206848, -0.472136527299881, -0.19027525186538696, -0.15924902260303497, -1.1697620153427124, -0.3238758444786072, 0.8493244051933289, -0.3218693137168884, 1.431622862815857, 0.03944316878914833, -0.8594984412193298, 0.24375680088996887, -0.22901424765586853, 0.5621068477630615, 0.13616245985031128, -0.39350759983062744, -1.0261261463165283, -0.5079743266105652, -0.07743480801582336, 0.3500536382198334, 0.20650647580623627, -0.24644441902637482, -0.47948944568634033, 0.0888524055480957, -0.2666381001472473, 0.2751064598560333, 0.47235795855522156, 0.8109644651412964, -0.3562442660331726, -0.6527379751205444, -0.09161056578159332, 0.6477829813957214, 0.15516774356365204, -0.4841608703136444, -0.41399234533309937, -0.9338024854660034, 0.7975139617919922, -0.2590136229991913, 1.6449002027511597, -0.6532101035118103, -0.9297037124633789, -0.17580927908420563, -0.5524393320083618, 0.004584408365190029, -0.9868953227996826, 0.9356614947319031, 0.0003417377301957458, 1.0238474607467651, -0.2322693169116974, -0.7645480036735535, 0.14195242524147034, 0.01728406548500061, -0.5094656348228455, -0.7101263403892517, -0.2037801742553711, 1.0370523929595947, -1.133050560951233, -0.04749564081430435, 0.04594412446022034, 0.33689138293266296, -0.4948333501815796, 0.7395084500312805, -0.8277369737625122, 0.2541690170764923, -0.23185531795024872, -0.057153116911649704, -0.20960263907909393, -0.30619576573371887, 0.46078529953956604, 0.026354994624853134, -0.36280763149261475, 0.4459158778190613, -0.38039448857307434, 1.8695564270019531, -0.586654007434845, 0.31480711698532104, -0.019046537578105927, 0.17347510159015656, -0.3678405284881592, 0.5567607283592224, -0.46531519293785095, -0.4307734966278076, -0.26022014021873474, 0.7145383954048157, -0.41221827268600464, 0.14513945579528809, 0.9156330227851868, 1.1593130826950073, -0.6232873201370239, 0.3129061162471771, 0.047860488295555115, -0.29651781916618347, 0.6938038468360901, 0.4137760102748871, 0.6707882285118103, 0.5495851635932922, 0.47190114855766296, -0.08203796297311783, 0.3630494475364685, -0.564974844455719, -0.33994051814079285, 0.8661289215087891, 0.982136607170105, 0.4487716555595398, 0.1028900071978569, -0.5121751427650452, -0.06499937921762466, 0.06845936924219131, 0.7626318335533142, 1.8670326471328735, -0.049504440277814865, -0.5249490141868591, -0.6801439523696899, -0.4045800268650055, -0.08754190057516098, 0.7942718267440796, -0.19942662119865417, 0.22624169290065765, -0.6528732180595398, -0.49214479327201843, 0.8223283290863037, 0.06569258868694305, 0.7098045945167542, -0.791738748550415, -0.22417008876800537, 0.050219740718603134, -0.06643884629011154, -0.8351688385009766, -0.8905467391014099, -0.0012460198486223817, -0.3875057101249695, -0.3294767737388611, 0.14730864763259888, -0.04796994850039482, -0.4012315273284912, -0.3017471730709076, 1.036686897277832, 0.24885796010494232, -0.24814920127391815, 0.28007742762565613, 0.153891921043396, -0.3539412021636963, -0.5723823308944702, 0.14499203860759735, -0.029266269877552986, -0.6485686898231506, 0.30069032311439514, 0.6436286568641663, -0.14649690687656403, 0.43772566318511963, -0.4208381474018097, 0.1456236094236374, 0.40900322794914246, 0.05673077702522278, 0.6584117412567139, -0.24213260412216187, 0.21702195703983307, -1.0313743352890015, 1.4797486066818237, 0.15602293610572815, -0.3960570693016052, 0.7938069701194763, -0.8299395442008972, -0.4750690162181854, 0.589487612247467, -0.5640923976898193, -0.3513384759426117, -1.393153190612793, 0.3718165457248688, 0.22163446247577667, -0.3320175111293793, 0.5864245891571045, 0.23191098868846893, 0.4188458323478699, 0.30777958035469055, 0.7393947243690491, 0.10035081207752228, -0.29508087038993835, 0.8620420694351196, -0.24642404913902283, 0.17568933963775635, -0.018650969490408897, -0.14389139413833618, -0.44284945726394653, -0.5582454204559326, -1.0181841850280762, -0.3424204885959625, -0.3866111934185028, 0.0013376920251175761, -0.06746066361665726, 0.05808519572019577, -0.2285560816526413, -0.7837286591529846, -0.27686062455177307, -0.9833094477653503, -0.566434919834137, 0.2632755637168884, -0.1643064171075821, -0.02240856923162937, -0.9113280177116394, -1.1250789165496826, -0.5466673374176025, -0.6263779401779175, -0.9472428560256958, 0.46665042638778687, -0.2226330041885376, -0.5789645314216614, -0.8224667906761169, -0.14718055725097656, -0.5709254145622253, 0.9350526928901672, -0.8503814935684204, 1.1075841188430786, -0.2626360356807709, -0.180500328540802, -0.05498873069882393, 0.10761404037475586, 0.08157069981098175, -0.1176690086722374, 0.35037723183631897, -0.5767571926116943, 0.09356125444173813, -0.29856061935424805, -0.13904447853565216, -0.037760909646749496, 0.22680513560771942, 0.41903313994407654, -0.12893392145633698, -0.6884379386901855, 0.008143431507050991, 1.3852213621139526, -0.2764444947242737, -0.060188982635736465, -0.20067283511161804, 0.9130221605300903, 0.44698500633239746, 0.15768617391586304, 0.4129406213760376, 0.278511643409729, 0.11396313458681107, -0.08967161923646927, 0.4397176504135132, 0.09355457127094269, -0.616323709487915, 0.635327935218811, 1.4712203741073608, 0.11460273712873459, -0.16717667877674103, -1.1893514394760132, 0.33940228819847107, -1.2209006547927856, -0.7050519585609436, 0.7654581665992737, 1.1695106029510498, 0.5050223469734192, -0.4786386489868164, -0.5556904673576355, -0.12345590442419052, 0.07760128378868103, 0.29554492235183716, -0.16380488872528076, -0.41723504662513733, 0.10481512546539307, -0.08546764403581619, -0.40760567784309387, 0.8818007707595825, -0.3261924386024475, 0.9203760027885437, 14.764491081237793, 1.0923875570297241, 0.10652539134025574, 0.3301357328891754, 0.4088860750198364, 0.16880910098552704, -0.7250906229019165, -0.2490474432706833, -1.4353210926055908, -0.12805400788784027, 1.222245216369629, -0.11167356371879578, 0.8841838836669922, 0.0389082245528698, 0.2823893427848816, -0.12051784247159958, -0.6264994144439697, 0.5961926579475403, 0.38264933228492737, -0.9205672144889832, 0.7716798782348633, 0.15882360935211182, -0.07613935321569443, 0.46359771490097046, 0.6842014193534851, 1.091991901397705, 0.5955938696861267, -0.6353784203529358, 0.6535674929618835, 0.1257457733154297, 1.017313003540039, -0.20405089855194092, 0.12830530107021332, 0.8127210736274719, -0.8167703747749329, -0.5702458024024963, -0.5321876406669617, -0.9895387291908264, -0.05819401517510414, 0.004672716837376356, -0.6292083263397217, -0.23907482624053955, -0.487566202878952, 0.5495765209197998, -0.3084441125392914, 0.2257576733827591, -0.32850778102874756, 0.7416516542434692, 0.12445646524429321, -0.29641249775886536, 0.4586448669433594, 0.3454846143722534, 0.7442066669464111, 0.1357080191373825, 0.2301376909017563, -0.1163434237241745, 0.2886892855167389, 0.23862749338150024, -0.30307477712631226, 0.46017345786094666, -0.9202839732170105, -0.2802647352218628, 0.3934428095817566, 0.4414896070957184, 0.5069321393966675, 0.2682204246520996, -0.33215200901031494, 0.26305198669433594, 0.6428616642951965, 0.5337129831314087, 0.21942605078220367, -0.05940496549010277, 0.4842348098754883, -0.5385658740997314, -0.3348848819732666, 0.019291367381811142, 0.032698482275009155, -0.44969338178634644, -0.6054220199584961, -0.5096032023429871, 0.46424219012260437, -0.9307106137275696, -0.8528333306312561, 0.825657308101654, -0.11255631595849991, -0.5565513372421265, -0.26331329345703125, -0.841630756855011, -0.1693306565284729, 0.38791564106941223, -1.486091136932373, -1.0171324014663696, 0.37913551926612854, -0.1449468433856964, 0.14071747660636902, 0.2845977246761322, 1.4888250827789307, 0.01823204942047596, -0.44780927896499634, -0.11842118203639984, 0.6344349980354309, 0.20503443479537964, -0.055576737970113754, -0.9294579029083252, 0.7019691467285156, 0.1493944525718689, -0.002607120666652918, 0.8299249410629272, -0.20213627815246582, -0.33856746554374695, -0.739140510559082, -0.13211658596992493, 0.5230594873428345, -1.2359141111373901, -0.4484424293041229, -0.7564602494239807, -1.0372400283813477, 0.19141268730163574, 0.7823927998542786, -0.4717790186405182, 0.6936562061309814, 0.2474265843629837, -0.4984956681728363, -0.11867108196020126, -0.7368062734603882, 0.5711424946784973, 0.832176923751831, -0.6434505581855774, -0.39986249804496765, -0.04406825453042984, 0.6423168778419495, -0.7752126455307007, -0.5148102045059204, -0.4119911193847656, 0.5204237103462219, -0.004267383832484484, 0.6799372434616089, -0.2719824016094208, 0.5172028541564941, 0.8228747248649597, -0.4030005931854248, -1.0520216226577759, 0.1588296890258789, -1.089847207069397, 0.3156644403934479, -0.22166374325752258, 1.4583265781402588, -0.4176017940044403, -0.4754875898361206, 1.0751824378967285, 0.42085620760917664, -0.7224664092063904, -0.5493414402008057, -0.536524772644043, 0.2713793218135834, -0.5947064161300659, 0.5994855761528015, 0.02761024981737137, 0.11779200285673141, 0.2860226631164551, 0.6505781412124634, 0.33927997946739197, -0.2674741744995117, -0.5725470781326294, 0.1298910528421402, -0.026199523359537125, 0.06762037426233292, -0.5607652068138123, 0.13281667232513428, -1.4195369482040405, -0.1979714334011078, -0.9513841867446899, 0.027920793741941452, -0.9233473539352417, -0.9964728951454163, -0.2379189133644104, -0.1296139806509018, -0.1797788292169571, 0.30930206179618835, -0.9050541520118713, -0.44898825883865356, -0.540180504322052, -0.6519938111305237, 0.3048410713672638, 0.993589460849762, -0.45041531324386597, 0.07983656227588654, -0.16068200767040253, -0.03954731673002243, 0.28790712356567383, 0.40340301394462585, -0.27722737193107605, -1.0140639543533325, -1.6085700988769531, 0.4965783655643463, 0.04621901735663414, -0.35866278409957886, -0.5545753836631775, 0.521077573299408, 0.15617330372333527, -0.053994182497262955, 0.024670811370015144, 0.1807331144809723, -0.9027366638183594, -0.6792740225791931, -0.026258686557412148, -0.852472186088562, 0.5653166174888611, -0.0014680740423500538, -0.4736711084842682, -0.04275558888912201, 0.4576129615306854, -0.4950191080570221, -1.266309142112732, -0.6755750179290771, 0.028978634625673294, -0.8459005951881409, 0.22453507781028748, -0.25317198038101196, -0.246048703789711, -1.0879641771316528, -0.4185446798801422, -0.12088111788034439, 0.5981723666191101, -0.1968461126089096, 1.118683099746704, 0.7271695137023926, -0.6824610233306885, 0.12108971178531647, 0.13927702605724335, -0.04632182419300079, 0.06676488369703293, 0.23154516518115997, 0.33869537711143494, -0.21031324565410614, 0.4743448495864868, 0.7946586012840271, 0.17331399023532867, -0.967112123966217, -0.05842472240328789, 0.5953248739242554, -0.5908029079437256, -0.13987690210342407, 0.5752553343772888, -0.5468422174453735, -0.9740490913391113, 0.15825165808200836, -1.4451435804367065, -0.5478980541229248, -0.5437965989112854, 0.86738121509552, 0.20377710461616516, -0.1765320599079132, -0.011214864440262318, -0.28013336658477783, 0.2792496383190155, -0.3440520763397217, -0.7833013534545898, 0.014289461076259613, -0.5681197643280029, 0.026490917429327965, 0.6421009302139282, 0.42729732394218445, -0.1890677809715271, -0.40981391072273254, -0.3998517096042633, -0.03061722405254841, -0.16379104554653168, -0.007086440920829773, -1.102954387664795, 0.25096556544303894, 0.617289125919342, 0.16970553994178772, 0.43478402495384216, -0.317720502614975, -0.5485632419586182, 0.19099418818950653, 1.2136996984481812, 0.42369019985198975, -0.7518978118896484, -0.6484572291374207, 1.578088402748108, 1.4773991107940674, -1.0764358043670654, 0.09420517086982727, 0.08502329885959625, -0.8005669116973877, 0.7621384263038635, 0.5119723081588745, 0.4241471588611603, 0.9111161231994629, -0.23724547028541565, 0.6887460350990295, 0.12477697432041168, -1.0312901735305786, -0.14218087494373322, 0.4876086413860321, 0.9017269015312195, 0.9548761248588562, 0.4252949059009552, -0.0034672280307859182, 0.9456440806388855, 0.07325466722249985, -0.017074260860681534, 0.5843191146850586, 0.7858676314353943, -0.3584133982658386, -0.14086253941059113, 0.22890250384807587, 0.6439331769943237, -0.8136522173881531, -0.9647389650344849, -0.14661741256713867, 0.907325267791748, -0.056409046053886414, 0.8595944046974182, 0.30832546949386597, 0.10339339822530746, 0.432027131319046, 0.7287361025810242, 0.372387170791626, -0.5292113423347473, -0.531554639339447, -0.13051776587963104, -0.3010774254798889, -0.060672834515571594, 0.04612652212381363, -0.2962212860584259, -0.2362116575241089, 0.03877075016498566, 0.04604605212807655, 0.2960372567176819, 0.2606523633003235, 1.1917587518692017, 0.7331961989402771, -0.14348746836185455, -0.6516169905662537, -0.299971342086792, -0.46506956219673157, -1.1670997142791748, 0.11323821544647217, -0.6600876450538635, -0.2314135879278183, 0.012620761059224606, 0.04026813432574272, -0.5768374800682068]}, "authors": [{"authorId": "2295886165", "name": "Cheng-Ping Hsieh"}, {"authorId": "23134878", "name": "Simeng Sun"}, {"authorId": "1380253623", "name": "Samuel Kriman"}, {"authorId": "9528018", "name": "Shantanu Acharya"}, {"authorId": "2239169883", "name": "Dima Rekesh"}, {"authorId": "2187456778", "name": "Fei Jia"}, {"authorId": "2241631811", "name": "Boris Ginsburg"}], "references": [{"paperId": "41b47f33a24feefd6728bdc1339d0d4ff5fec7be", "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context"}, {"paperId": "c0b454e0a6aa51ff3ba56778787d0c43932ef6ba", "title": "Yi: Open Foundation Models by 01.AI"}, {"paperId": "f05e84702562cb693dd68d3d1c88072519a7bd71", "title": "\u221eBench: Extending Long Context Evaluation Beyond 100K Tokens"}, {"paperId": "c9603ec967879c24973b5bd48861df2e5555932e", "title": "LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens"}, {"paperId": "f288e2238ac8725baa7ca9874bbc3fed1e89a632", "title": "Data Engineering for Scaling Language Models to 128K Context"}, {"paperId": "26e13e1da4f47c93c9ad0daf9cc9e2bb4ffd063d", "title": "InfLLM: Training-Free Long-Context Extrapolation for LLMs with an Efficient Context Memory"}, {"paperId": "2b8439f319dfa73df62ca8957ff6d0c1f3c7a73c", "title": "Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon"}, {"paperId": "1be73fa3e856c33d0aed1d9e46693523e7fa3c60", "title": "Zoology: Measuring and Improving Recall in Efficient Language Models"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "0484f05b6b3c11a9344cb623649ae867f172046f", "title": "LooGLE: Can Long-Context Language Models Understand Long Contexts?"}, {"paperId": "4c0428917aeee6aa7bd434f337d039f35996b736", "title": "LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression"}, {"paperId": "2b35b946a8ad64e018c24b283bc1c6c65d36fb67", "title": "Retrieval meets Long Context Large Language Models"}, {"paperId": "02ad9f3fefe33cb9ca546591bec65dbdf7766c80", "title": "Ring Attention with Blockwise Transformers for Near-Infinite Context"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "3a1a9ef603fd245fd9732064e5756efc82c797b1", "title": "A Benchmark for Learning to Translate a New Language from One Grammar Book"}, {"paperId": "5e0cb1c4b91a7486e1c2b15a44a0be56bd74bdc0", "title": "Effective Long-Context Scaling of Foundation Models"}, {"paperId": "a51ac7a5e8f6454268ac16ecdc52ecac98ce54d9", "title": "DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models"}, {"paperId": "42d83576ee920c1b6df318e212047d9ba57fc4fd", "title": "BAMBOO: A Comprehensive Benchmark for Evaluating Long Text Modeling Capacities of Large Language Models"}, {"paperId": "b6346f9fa093b8e85df712485a2b851b9f680dac", "title": "LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"}, {"paperId": "73290ecbec2f38d1d647ddef1ada69cee41725b3", "title": "PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training"}, {"paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05", "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"}, {"paperId": "819bbdc2dac9e13d9ca3e2508a6e063186ce5e40", "title": "YaRN: Efficient Context Window Extension of Large Language Models"}, {"paperId": "b31a5884a8ebe96b6300839b28608b97f8f8ef76", "title": "LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding"}, {"paperId": "b0db25e317cf856f1ec1ca3df0e573d850ed4696", "title": "L-Eval: Instituting Standardized Evaluation for Long Context Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "240103933ffe3dac2179cc160a2bd91299357a53", "title": "Retentive Network: A Successor to Transformer for Large Language Models"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "b069c32fcd77160f944ab3ba71ab6f0cfb782c68", "title": "Focused Transformer: Contrastive Training for Context Scaling"}, {"paperId": "c12db2c60e8989f646a29ad4f4d24475e860ad91", "title": "LongNet: Scaling Transformers to 1, 000, 000, 000 Tokens"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "80980cd10d19f021c14a6b7eee871b6a5d328024", "title": "Augmenting Language Models with Long-Term Memory"}, {"paperId": "60b35c6d68acced19b0c66edcfc0ee0a2c11efed", "title": "Landmark Attention: Random-Access Infinite Context Length for Transformers"}, {"paperId": "eb511ae6b9f04e4936891d26787f274b48b99d57", "title": "ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "594d8e1696619f3cebb7c6bffdad8e0a5592f006", "title": "Scaling Transformer to 1M tokens and beyond with RMT"}, {"paperId": "998ac3e945857cf2676ee7efdbaf443a0c6f820a", "title": "Hyena Hierarchy: Towards Larger Convolutional Language Models"}, {"paperId": "54155c2977a977bf129849455dcae3a2b79b3f41", "title": "Simple Hardware-Efficient Long Convolutions for Sequence Modeling"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "9575afb5702bc33d7df14c48feeee5901ea00369", "title": "A Length-Extrapolatable Transformer"}, {"paperId": "c90a99eeb57019732a6cc996bb9eaf13faedf00f", "title": "In-context Learning and Induction Heads"}, {"paperId": "732e3faec4e5be4d144256f2c379b9dc49f0b227", "title": "Efficient Long-Text Understanding with Short-Text Models"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "b9a701c90f3d3df27366f5b29a97f798eb940ac7", "title": "ChapterBreak: A Challenge Dataset for Long-Range Language Models"}, {"paperId": "da0d38cf2ac7e2a6908e0d9e1fff07058daab2ed", "title": "Sparse is Enough in Scaling Transformers"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "ec307b17f193b14292206b65a1bcc95bfd8f02ed", "title": "\u266b MuSiQue: Multihop Questions via Single-hop Question Composition"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "50796b0f3edf9cb5ff1e447c298b33755378aa4f", "title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "67ee20536c30a225b86902af2f091e28e5e19b40", "title": "Memformer: A Memory-Augmented Transformer for Sequence Modeling"}, {"paperId": "33ec7eb2168e37e3007d1059aa96b9a63254b4da", "title": "Beyond Accuracy: Behavioral Testing of NLP Models with CheckList"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "6398cb8f2af1c988a097ed1e1cefb380195edfb8", "title": "(Preprint)"}, {"paperId": "22655979df781d222eaf812b0d325fa9adf11594", "title": "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering"}, {"paperId": "4d1c856275744c0284312a3a50efb6ca9dc4cd4c", "title": "Know What You Don\u2019t Know: Unanswerable Questions for SQuAD"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "b387a36c3cbf05f5671670471985d3f0985795bd", "title": "Selected Studies of the Principle of Relative Frequency in Language"}, {"paperId": "7b36c5602930abf08efd2867f92cdb48a1be757a", "title": "Together"}, {"paperId": "c96f7099e2e8b6d402440700ca5fd2bf247ca81f", "title": "Supervised Noun Phrase Coreference Research: The First Fifteen Years"}, {"paperId": "0d24df6d9507feeacdce5ff0633f95127fc1a77c", "title": "Strategies of discourse comprehension"}, {"paperId": "98b4d4e24aab57ab4e1124ff8106909050645cfa", "title": "Neural networks and physical systems with emergent collective computational abilities."}, {"paperId": "e3aa232577bb427b1f3a34acbdef84bd85734042", "title": "LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models"}, {"paperId": "0d113a4c25a2220f9f50f680a90b0c719ae9db1a", "title": "Discourse referents"}, {"paperId": null, "title": "Needle In A Haystack - pressure testing LLMs"}, {"paperId": null, "title": "Long context prompting for Claude 2.1"}, {"paperId": null, "title": "OpenAI: Josh Achiam et al. GPT-4 technical report"}, {"paperId": null, "title": "Introducing the next generation of claude"}, {"paperId": null, "title": "How long can open-source LLMs truly promise on context length?"}, {"paperId": null, "title": "\u221e -former: Infinite memory Transformer"}, {"paperId": null, "title": "World model on million-length video and language with Ring Attention"}, {"paperId": null, "title": "Introducing jamba: Ai21\u2019s groundbreaking ssm-transformer model"}]}