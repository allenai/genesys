{"paperId": "2faad1112335ff99d1cb7967a51ac977fc9e6804", "abstract": "Several parameter-efficient fine-tuning methods based on adapters have been proposed as a streamlined approach to incorporate not only a single specialized knowledge into existing Pre-Trained Language Models (PLMs) but also multiple of them at once. Recent works such as AdapterSoup propose to mix not all but only a selective sub-set of domain-specific adapters during inference via model weight averaging to optimize performance on novel, unseen domains with excellent computational efficiency. However, the essential generalizability of this emerging weight-space adapter mixing mechanism on \\textit{unseen, in-domain examples} remains unexplored. Thus, in this study, we conduct a comprehensive analysis to elucidate the generalizability of domain-specific adapter mixtures in in-domain evaluation. We also provide investigations into the inner workings of the mixture of domain-specific adapters by analyzing their weight signs, yielding critical analysis on the negative correlation between their fraction of weight sign difference and their mixtures' generalizability.", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This study conducts a comprehensive analysis to elucidate the generalizability of domain-specific adapter mixtures in in-domain evaluation and provides investigations into the inner workings of the mixture of domain-specific adapters by analyzing their weight signs, yielding critical analysis on the negative correlation between their fraction of weight sign difference and their mixtures' generalizability."}, "embedding": {"model": "specter_v2", "vector": [0.08449479937553406, 0.49128010869026184, -0.7912434339523315, -0.37834280729293823, -0.6182113289833069, -0.2728557586669922, 0.2827221155166626, -0.7751743197441101, -0.34957805275917053, -0.22209590673446655, 0.577189028263092, -0.045933619141578674, -0.367297887802124, 0.3412594199180603, 0.1600586324930191, -0.08816371113061905, -0.7297865748405457, 0.9766645431518555, -0.01904408447444439, -0.46806302666664124, -0.5702588558197021, -0.8046402335166931, -0.6218532919883728, 0.02603250741958618, 0.7060907483100891, 0.47574812173843384, 0.0738307312130928, 0.7409595847129822, -0.541674017906189, -0.01464283186942339, 0.48759207129478455, -0.671051561832428, 0.3270648717880249, -0.1401994228363037, 0.24582482874393463, 0.15682953596115112, 0.29212474822998047, -0.3594161570072174, -0.8148826360702515, 0.836369514465332, -0.11475091427564621, 0.3231356143951416, 0.7616967558860779, -0.6359833478927612, -0.39874550700187683, 0.8466281294822693, 0.7169586420059204, 0.526426374912262, -0.7206993699073792, -0.22901348769664764, 1.5476983785629272, -1.275793194770813, 0.478087842464447, 1.3799686431884766, 0.6162195801734924, 0.3623647689819336, -0.5424284934997559, -1.0398870706558228, 0.6851348280906677, 0.1516571044921875, -0.8636437058448792, -0.2473720908164978, 0.38527047634124756, 0.21075646579265594, 1.8229516744613647, -0.2789453864097595, -0.2566693127155304, 0.4657648503780365, -0.495822012424469, 1.6952922344207764, -0.6447756886482239, -0.4556387960910797, -0.28348642587661743, 0.16858674585819244, 0.25906792283058167, 0.9124600291252136, -0.34578144550323486, 0.4121052324771881, -0.6301093101501465, -0.4997342824935913, 0.1411924660205841, -0.3023706376552582, -0.14977823197841644, -0.2080923467874527, 0.06639724224805832, 0.7946437001228333, 0.18032291531562805, 0.6459054946899414, 0.17760463058948517, 0.3967430889606476, 0.3584984242916107, 0.5331054925918579, 0.43185099959373474, 0.536223828792572, -0.611745297908783, 0.5862395167350769, -0.6782364249229431, 0.6786101460456848, 0.07721380144357681, 0.9978054761886597, -0.2512788474559784, -0.05432884395122528, -0.6646612286567688, 0.8647953271865845, 1.6878077983856201, -0.17402125895023346, 0.7229841947555542, -0.8959833383560181, 0.45409032702445984, -0.03194691985845566, -0.04284769669175148, -0.3796372413635254, -0.30858778953552246, -0.44035646319389343, -0.6438816785812378, -1.4891029596328735, -0.2252107411623001, 0.2430797815322876, -0.597631573677063, 1.1695884466171265, -0.3211809992790222, 0.24559614062309265, -0.1122012808918953, 0.4048607349395752, 0.4710494577884674, 0.49225011467933655, 0.622349202632904, 0.24172620475292206, 0.6938429474830627, -1.009265661239624, -0.2938266396522522, -1.5538394451141357, 1.224929690361023, -0.2492648959159851, 0.4561770558357239, -0.2751365303993225, -1.2555161714553833, -0.8810805082321167, -0.8832666277885437, 0.08941445499658585, -0.5409079790115356, 0.533272385597229, 0.8150907754898071, 0.1236405223608017, -0.4806826114654541, 0.787223756313324, 0.22567860782146454, -0.3349560499191284, 0.2789103090763092, 0.30325689911842346, 0.01182783953845501, -0.8899543881416321, -1.2505749464035034, 0.3888252377510071, 0.5780356526374817, -1.1009842157363892, -0.08980321139097214, -0.8924399018287659, -0.9444066882133484, -0.1946849226951599, 0.48080146312713623, -0.9890440106391907, 1.474343180656433, -0.15195192396640778, -1.1331959962844849, 0.5382110476493835, -0.3546934127807617, 0.18257790803909302, 0.1708853542804718, 0.1277020126581192, -0.7813740968704224, -0.794567883014679, -0.5641357898712158, 0.4441341459751129, 0.20837508141994476, 0.02431735023856163, -0.17906440794467926, 0.07743728160858154, -0.10715553164482117, 0.28218215703964233, -0.4434715807437897, 0.5955175161361694, -0.5592202544212341, -0.5605705380439758, 0.30122432112693787, 0.695462167263031, -0.0767645612359047, 0.11113302409648895, 0.15957537293434143, -1.4118499755859375, 0.8745991587638855, -0.007149166893213987, 1.4606865644454956, -0.9219449758529663, -0.2919301986694336, -0.3117368221282959, -0.05228082835674286, 0.15394607186317444, -1.4040288925170898, 0.6244665384292603, -0.1940947026014328, 0.26689937710762024, -0.40875187516212463, -1.383082628250122, 0.40894386172294617, 0.008822638541460037, -0.5468145608901978, -0.4301757514476776, 0.49939677119255066, 0.8996908664703369, -1.1970709562301636, 0.10880923271179199, -0.3317590355873108, 0.037118177860975266, -1.4393292665481567, 1.2427037954330444, -0.7031449675559998, -0.21222971379756927, 0.07282274961471558, 0.04581562057137489, 0.16582025587558746, -0.05465583875775337, 0.18542735278606415, -0.41891318559646606, 0.27954399585723877, 0.7628102898597717, -0.4884136915206909, 1.3606821298599243, -0.21373073756694794, 0.13333958387374878, -0.0059206015430390835, -0.48627138137817383, 0.056624606251716614, 0.45487597584724426, -0.45805835723876953, -0.27799150347709656, 0.48125582933425903, 0.7346680164337158, -0.4286646842956543, 0.17937792837619781, 0.5994089245796204, 0.24423377215862274, -0.30316397547721863, 0.07292899489402771, 1.0560476779937744, -0.2882724404335022, 0.8525047898292542, 0.14050336182117462, 0.8385177850723267, 0.013927563093602657, 0.4534498155117035, -0.0341976098716259, 0.5575932264328003, -0.8845095634460449, -0.04465896636247635, 0.188862606883049, 0.6304261684417725, 0.7761834859848022, 0.15425115823745728, -0.4854678213596344, -0.24709472060203552, -0.25321680307388306, 0.631020724773407, 1.822962760925293, -0.3254927694797516, -0.32717472314834595, -0.3119112551212311, -0.4953942596912384, -0.11311356723308563, 0.48728737235069275, -0.3101145327091217, -0.6227319836616516, -0.526093602180481, -1.3383997678756714, 0.9465304017066956, 0.3899359107017517, 0.83514803647995, 0.07249842584133148, 0.3550807237625122, -0.020251445472240448, -0.07158935070037842, -0.27918532490730286, -0.944783627986908, 0.4799405038356781, -0.6993931531906128, -0.2973603308200836, 0.1306382268667221, -0.02635287307202816, -0.002330588875338435, -0.4447750747203827, 1.1440969705581665, -0.709194004535675, -0.2611953914165497, 0.05846323072910309, 0.8635845184326172, -0.46498897671699524, -0.7644125819206238, 0.27690303325653076, 0.10119268298149109, -0.15909147262573242, 0.7224364876747131, 0.46246907114982605, 0.052857909351587296, 0.4817187786102295, -0.4896486699581146, -0.06658667325973511, -0.033913079649209976, 0.6948814988136292, 0.6801986694335938, -0.18633143603801727, -0.2064419835805893, -0.9731874465942383, 1.070824146270752, -0.28069940209388733, -0.3310244083404541, 0.36347028613090515, -0.3741690218448639, -0.23572978377342224, 0.4391632676124573, -1.1352288722991943, -0.5751957893371582, -1.1621921062469482, 0.2541789710521698, -0.08321384340524673, 0.06542859226465225, 0.24624241888523102, -0.22117191553115845, 0.32084134221076965, 0.6392690539360046, 0.2162827104330063, 0.34841591119766235, -0.4890967607498169, 0.740692138671875, -0.9317907094955444, 0.1434803605079651, 0.09591840207576752, 0.1623568832874298, -0.2820657789707184, -0.38313403725624084, -0.4624558687210083, -0.27286702394485474, -0.8734023571014404, 0.25398170948028564, 0.053180355578660965, -0.5036125183105469, -0.5665497779846191, -0.06776322424411774, 0.10004990547895432, -0.8629206418991089, -0.06658053398132324, 0.17578501999378204, -0.2390243411064148, -0.13844034075737, -1.3658339977264404, -1.2013882398605347, -0.24188733100891113, -0.3288521468639374, -1.1343241930007935, 0.5148509740829468, -0.1853705197572708, -0.5824700593948364, -0.8522559404373169, 0.12841305136680603, -0.20726901292800903, 1.267058253288269, -0.9714681506156921, 1.1454631090164185, -0.4473921060562134, -0.2808600068092346, -0.5638349056243896, 0.023450003936886787, 0.519819974899292, -0.422048956155777, 0.14299526810646057, -1.0426476001739502, 0.3479713201522827, -0.1574457287788391, 0.010225360281765461, 0.14408324658870697, 0.1405297964811325, 0.7269372344017029, -0.21630728244781494, -0.9932138323783875, 0.7185937762260437, 1.3204115629196167, -0.6059831976890564, -0.16320595145225525, -0.15414898097515106, 0.5278921127319336, 0.3795672357082367, -0.09151236712932587, 0.3975861072540283, 0.34789326786994934, 0.5244863629341125, 0.08407563716173172, -0.16860942542552948, -0.042724478989839554, -0.6263433694839478, 0.5221914052963257, 1.9326636791229248, 0.2664766013622284, -0.22514276206493378, -0.8306801915168762, 0.6462661623954773, -1.3444770574569702, -0.5885823965072632, 0.7136187553405762, 0.5316680669784546, 0.5144394040107727, -0.6551104784011841, -0.21804402768611908, -0.25605452060699463, 0.05844051018357277, 0.22591982781887054, -0.26917243003845215, -0.2307506501674652, -0.13670431077480316, 0.2196611911058426, 0.33971089124679565, 0.5312149524688721, -0.28257375955581665, 0.557067334651947, 14.439586639404297, 1.226475477218628, 0.5376505851745605, 0.8685905933380127, 0.6114726066589355, 0.061372339725494385, -0.605334997177124, -0.17806166410446167, -1.2100484371185303, 0.08307457715272903, 1.1258082389831543, -0.00249043432995677, 0.8934372067451477, 0.32908937335014343, -0.38817116618156433, 0.6242551207542419, -0.5197874307632446, 0.3997686207294464, 0.6386251449584961, -1.0705430507659912, 0.642317533493042, 0.10808560252189636, 0.3395741283893585, 0.7916706204414368, 0.6481924057006836, 1.285757303237915, 0.562606930732727, -0.30155041813850403, 0.17064300179481506, -0.0071739512495696545, 0.6547837257385254, -0.021085329353809357, 0.5533552169799805, 0.5002934336662292, -0.621823251247406, -0.5077101588249207, -0.855769157409668, -1.147485375404358, 0.17816641926765442, 0.10806415230035782, -0.5655835270881653, -0.6394249200820923, -0.39637693762779236, 0.7124611139297485, 0.1518862396478653, 0.4801967740058899, 0.04450860247015953, 0.699202299118042, -0.3030666708946228, 0.372641384601593, 0.3281402289867401, 0.21141153573989868, 0.5510355830192566, 0.06244436278939247, 0.6855255365371704, 0.011130662634968758, -0.09559036046266556, 0.6928882598876953, -0.7139012217521667, -0.2000320553779602, -0.5422501564025879, -0.2398010492324829, 0.0602240264415741, 0.7364274263381958, 0.9092426896095276, -0.09414954483509064, -0.4532306492328644, 0.13612675666809082, 0.802862286567688, 0.32463666796684265, -0.5050297975540161, 0.05485639348626137, 0.8604252338409424, -0.39600443840026855, -0.3217328190803528, 0.795766294002533, -0.2772686779499054, -0.2734741270542145, -0.7926624417304993, -0.5226039886474609, 0.6291199922561646, -0.6521353125572205, -1.2040798664093018, 0.9155606627464294, 0.0811106264591217, -0.6598044633865356, 0.405150830745697, -0.9700216054916382, -0.3782239258289337, 0.16265110671520233, -1.3776922225952148, -0.6637855172157288, 0.3326245844364166, -0.64675372838974, -0.15617164969444275, -0.5432929396629333, 1.4052858352661133, 0.43228769302368164, -0.5922917723655701, 0.5851185917854309, 0.4025241732597351, -0.533383846282959, 0.2609242796897888, -0.6405832767486572, 0.8352250456809998, -0.18368113040924072, -0.2201944887638092, 0.5575681328773499, -0.1229652613401413, 0.5215787291526794, -0.5963919162750244, -0.27205556631088257, 1.0617414712905884, -0.8393094539642334, -0.021354947239160538, -0.38670432567596436, -0.826248049736023, 0.3135370910167694, 0.5789140462875366, -0.48049208521842957, 0.7304461598396301, 0.29285338521003723, -1.112705111503601, -0.25527045130729675, -0.8206174373626709, 0.40415728092193604, 1.20555579662323, -0.39397212862968445, -0.5763930082321167, 0.03505505993962288, 0.11671129614114761, -0.8712971210479736, -0.381780207157135, 0.28547999262809753, -0.1635693907737732, -0.04928797483444214, 1.3747752904891968, -0.6380425691604614, 0.5528100728988647, 0.4850061237812042, -0.37882310152053833, -1.2141057252883911, -0.3396877348423004, -0.532560408115387, -0.1356876790523529, 0.11579477041959763, 0.7651196122169495, -0.5717149376869202, -0.1600983887910843, 0.9031938910484314, 0.08754019439220428, -0.5349659323692322, -0.6574060320854187, -0.3749822974205017, 0.09823790192604065, -0.5108965039253235, 0.6150059103965759, -0.23253333568572998, 0.1535935401916504, 0.05042778328061104, 0.774885892868042, 0.5023133158683777, -0.3681805729866028, -1.1135854721069336, 0.31321388483047485, 0.10630601644515991, -0.3174345791339874, -0.8932139277458191, -0.3074762523174286, -1.493255376815796, 0.13864858448505402, -1.4209874868392944, -0.01740702986717224, -0.49686354398727417, -0.48311641812324524, 0.06291775405406952, -0.7141523361206055, -0.3114853799343109, 0.29619890451431274, -0.11340730637311935, -0.6441125869750977, -0.6081647276878357, -0.4278348982334137, 0.8786098957061768, 0.6564462780952454, -1.297777533531189, 0.3979731798171997, -0.015005184337496758, -0.02878197468817234, 0.6847275495529175, 0.5906710624694824, -0.38458654284477234, -1.0700684785842896, -1.6294788122177124, 0.3666304051876068, -0.39766326546669006, -0.25130003690719604, -0.49516549706459045, 0.6163766384124756, 0.2764803469181061, -0.40203550457954407, 0.1825249344110489, 0.5685216784477234, -1.1812175512313843, -0.2743833065032959, 0.18910983204841614, -0.5079941749572754, 0.20883549749851227, 0.1608743518590927, -0.49328330159187317, -0.556013822555542, 0.4109112024307251, -0.023646406829357147, -1.1065921783447266, -0.479051411151886, 0.27917593717575073, -0.5590908527374268, 0.4354056119918823, -0.397271990776062, -0.02401232346892357, -0.9373701810836792, 0.01719353161752224, 0.4365406036376953, 0.35747000575065613, -0.286621630191803, 0.7411822080612183, 0.4760017991065979, -1.5205446481704712, 0.13012467324733734, 0.6371699571609497, 0.530702531337738, -0.18997825682163239, 0.4610179662704468, 0.3368833363056183, -0.03403407335281372, 0.45850515365600586, 0.5647546052932739, 0.4942685663700104, -0.8753785490989685, -0.2012670487165451, 0.8339900374412537, -0.8146743774414062, 0.1767176389694214, 1.725597858428955, 0.031067395582795143, -1.6745150089263916, 0.26857897639274597, -1.107642412185669, 0.1251177191734314, -0.6433393359184265, 0.756661057472229, 0.6876299977302551, -0.16055497527122498, 0.12821781635284424, -0.42939409613609314, 0.2387770265340805, -0.38974252343177795, -0.25358396768569946, 0.5070874691009521, 0.07637747377157211, -0.3889380395412445, 0.2584264576435089, 0.9006764888763428, -0.8606747984886169, -0.6539446711540222, -0.6142756342887878, -0.2018468677997589, -0.14524035155773163, 0.1605319380760193, -0.5032681822776794, -0.6468128561973572, 0.5072959661483765, 0.20719626545906067, -0.35931333899497986, 0.23481690883636475, -0.250838965177536, 0.23755671083927155, 0.4077916741371155, -0.13165819644927979, -0.912701427936554, -0.834733784198761, 1.107810378074646, 1.2856560945510864, -0.9189450144767761, 0.014327960088849068, -0.04921800643205643, -0.6001394987106323, 0.622565507888794, 0.2723482549190521, -0.17672720551490784, 0.8684031367301941, -0.16894644498825073, 0.05650898069143295, 0.090655617415905, -1.300487756729126, -0.2308107614517212, 1.3787212371826172, 1.0580003261566162, 0.8562651872634888, 0.31230729818344116, -0.32595381140708923, 1.1801316738128662, 0.4342534840106964, -0.05555190145969391, -0.060595739632844925, -0.09854675829410553, -0.07509179413318634, -0.3593289852142334, 0.1431029587984085, 0.6576278805732727, 0.03562714159488678, -0.5145145654678345, -0.3496473729610443, 0.7442740797996521, 0.5898640155792236, 0.443912148475647, 0.46222636103630066, -0.1315004974603653, 0.6389226317405701, 0.7072828412055969, 0.28558892011642456, -0.3988147974014282, -0.14934612810611725, -0.33617815375328064, -0.37631872296333313, 0.055430419743061066, -0.05637173354625702, -0.18635158240795135, 0.15886183083057404, -0.0299098901450634, 0.04178190976381302, -0.3479701280593872, 0.05885254219174385, 1.0457088947296143, 0.6360102891921997, 0.5058931708335876, -0.6755673885345459, -0.24383077025413513, -0.5407645106315613, -1.2237648963928223, 0.13560600578784943, -0.10736542195081711, -0.5521233081817627, -0.36781641840934753, -0.48007693886756897, -0.6697357892990112]}, "authors": [{"authorId": "2279868416", "name": "Tuc Nguyen"}, {"authorId": "2279871130", "name": "Thai Le"}], "references": [{"paperId": "9618aa98729670f74418d2087f5e47ab137856b4", "title": "Mixture-of-Domain-Adapters: Decoupling and Injecting Domain Knowledge to Pre-trained Language Models\u2019 Memories"}, {"paperId": "3ff08b5ca57e786d8af7b204ef94c9972bd9a61e", "title": "Dataless Knowledge Fusion by Merging Weights of Language Models"}, {"paperId": "7bd551537b67a31a733ac12a8de69968bc190f66", "title": "SparseAdapter: An Easy Approach for Improving the Parameter-Efficiency of Adapters"}, {"paperId": "8b3a67c7e5289eed160d2acfd04d71cfb552c67d", "title": "Branch-Train-Merge: Embarrassingly Parallel Training of Expert Language Models"}, {"paperId": "996445d847f06e99b0bd259345408a0cf1bce87e", "title": "Locating and Editing Factual Associations in GPT"}, {"paperId": "06b20a1c6883464fcb2855adc146874fe7937c41", "title": "Merging Models with Fisher-Weighted Averaging"}, {"paperId": "7b5b15279e5a52439614f886b79fa33f4b88bfb2", "title": "Efficient Test Time Adapter Ensembling for Low-resource Language Varieties"}, {"paperId": "07432dd1f73938a2439dfe74c55bcaabf775aa77", "title": "Post-training deep neural network pruning via layer-wise calibration"}, {"paperId": "ab158a20229999d9d437c23fb194e05deb2801c1", "title": "The Topic Confusion Task: A Novel Evaluation Scenario for Authorship Attribution"}, {"paperId": "0932abfd0fb90e8a28f7bd195633c9891bfd7ecb", "title": "Pruning Neural Networks at Initialization: Why are We Missing the Mark?"}, {"paperId": "3b0fb765716ef6861a84abffcbe40643857c613b", "title": "Pruning neural networks without any data by iteratively conserving synaptic flow"}, {"paperId": "66f0f35fc78bdf2af9de46093d49a428970cde2e", "title": "Movement Pruning: Adaptive Sparsity by Fine-Tuning"}, {"paperId": "98ef0db84e62aef969629264c9de1f4d0013f3b9", "title": "AdapterFusion: Non-Destructive Task Composition for Transfer Learning"}, {"paperId": "26299d5fdc5137291dc6a091573b3d18aba1d1c2", "title": "MAD-X: An Adapter-based Framework for Multi-task Cross-lingual Transfer"}, {"paperId": "c114ce10c4a315d92c3815f54bc9893e7e6ef182", "title": "Picking Winning Tickets Before Training by Preserving Gradient Flow"}, {"paperId": "4f03e69963b9649950ba29ae864a0de8c14f1f86", "title": "K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters"}, {"paperId": "ae04f3d011511ad8ed7ffdf9fcfb7f11e6899ca2", "title": "Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "101fc5b569ee9b9e11850f8b5d86a6dd74ee7258", "title": "Universal Sentence Encoder for English"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "937e55826b0fe64e42a43121681e5e4a62ddcc40", "title": "PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "642d0f49b7826adcf986616f4af77e736229990f", "title": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"}, {"paperId": "bee044c8e8903fb67523c1f8c105ab4718600cdb", "title": "Explaining and Harnessing Adversarial Examples"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "4211bff1388da30a3b7dfd35d6aef2032900ca5c", "title": "Good debt or bad debt: Detecting semantic orientations in economic texts"}, {"paperId": "90ef13736a55121f346bb68b590698627c96055f", "title": "Diverse"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "First quora dataset release: Question pairs"}, {"paperId": "db8885a0037fe47d973ade79d696586453710233", "title": "The Sixth PASCAL Recognizing Textual Entailment Challenge"}, {"paperId": "4574d77fff19e093782178595a8988a7f3aa1969", "title": "Latent Dirichlet Allocation"}, {"paperId": "475354f10798f110d34792b6d88f31d6d5cb099e", "title": "Automatically Constructing a Corpus of Sentential Paraphrases"}, {"paperId": null, "title": "2022. Lora: Low-rank adaptation of large language models"}, {"paperId": null, "title": "2023. Adaptersoup: Weight averaging to improve generalization of pre-trained language models"}, {"paperId": null, "title": "by training and test set"}, {"paperId": null, "title": "tweetsimdb"}]}