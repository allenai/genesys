{"paperId": "5eda60d4940d4185df45c5703e103458171d465d", "abstract": "We show that standard Transformers without graph-specific modifications can lead to promising results in graph learning both in theory and practice. Given a graph, we simply treat all nodes and edges as independent tokens, augment them with token embeddings, and feed them to a Transformer. With an appropriate choice of token embeddings, we prove that this approach is theoretically at least as expressive as an invariant graph network (2-IGN) composed of equivariant linear layers, which is already more expressive than all message-passing Graph Neural Networks (GNN). When trained on a large-scale graph dataset (PCQM4Mv2), our method coined Tokenized Graph Transformer (TokenGT) achieves significantly better results compared to GNN baselines and competitive results compared to Transformer variants with sophisticated graph-specific inductive bias. Our implementation is available at https://github.com/jw9730/tokengt.", "venue": "Neural Information Processing Systems", "year": 2022, "citationCount": 129, "influentialCitationCount": 16, "openAccessPdf": {"url": "http://arxiv.org/pdf/2207.02505", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "It is shown that standard Transformers without graph-specific modifications can lead to promising results in graph learning both in theory and practice, and it is proved that this approach is theoretically at least as expressive as an invariant graph network (2-IGN) composed of equivariant linear layers."}, "embedding": {"model": "specter_v2", "vector": [0.44350099563598633, 1.1036580801010132, -0.6887585520744324, 0.4079536497592926, 0.1178322434425354, -0.18861518800258636, 0.880792498588562, 0.000243726433836855, -0.4950075149536133, 0.003401242196559906, 0.18251265585422516, 0.10593049973249435, 0.28299689292907715, -0.5457364320755005, -0.595344066619873, 0.14325793087482452, -1.1835983991622925, 0.013294716365635395, 0.2743819057941437, -0.0776572898030281, 0.04632928594946861, -0.6525020003318787, -0.6831950545310974, -0.3190133273601532, 0.35351720452308655, 0.3423195481300354, -0.1298537403345108, 0.9302002787590027, -0.46116870641708374, 0.8032247424125671, 0.7326856255531311, -0.8421245217323303, 0.3368135094642639, -0.002053147880360484, -0.9287021160125732, -0.0961809754371643, 0.2934877574443817, -0.24511538445949554, -0.8164615035057068, 1.1237590312957764, -0.43357208371162415, 0.36134716868400574, 0.2958958148956299, -1.366249442100525, -0.27510368824005127, 1.5953179597854614, 0.38052910566329956, 0.3147931396961212, -0.513965368270874, -0.8564136624336243, 2.0602686405181885, -1.1760865449905396, 0.5034679770469666, 1.3497953414916992, 0.5980156064033508, 0.3591674566268921, -0.3408340513706207, -0.7538861632347107, 0.9012095928192139, 0.44102221727371216, -0.7783642411231995, 0.10582667589187622, 0.17434161901474, 0.14617802202701569, 1.6764650344848633, -0.4248737692832947, 0.43243035674095154, 0.46594592928886414, -0.10409673303365707, 1.3293806314468384, 0.008106300607323647, -0.7662099003791809, -0.5251421332359314, -0.012254028581082821, 0.36162132024765015, 1.2701036930084229, 0.08112093061208725, 0.4241052269935608, -0.9276260137557983, 0.2963893711566925, 0.4792979955673218, 0.3819316029548645, 0.13423989713191986, -0.18034058809280396, -0.08792802691459656, 0.5967722535133362, 0.9904904365539551, 0.8142197728157043, -0.38463571667671204, 1.311213493347168, 0.42933833599090576, 0.377789705991745, -0.14782820641994476, 0.31493517756462097, 0.5869128108024597, 0.7243216633796692, -0.5104997158050537, 0.22291319072246552, -0.23864977061748505, 0.7283584475517273, 0.3581867516040802, 0.3271574079990387, -0.4005855321884155, -0.17834603786468506, 1.3140852451324463, -0.023725083097815514, -0.012417254969477654, -0.7814608812332153, -0.1170433759689331, -0.17512229084968567, -0.21689407527446747, -1.0639660358428955, -0.24310773611068726, -0.3730144500732422, -0.796234667301178, -0.9567548632621765, -0.2660761773586273, 0.6989815831184387, -0.7450042963027954, 1.0093884468078613, -0.41146120429039, 0.4046950042247772, -0.3367628753185272, 0.23467545211315155, 0.8494880199432373, 0.46723100543022156, 0.4668819308280945, 0.22949057817459106, 0.6594853401184082, -1.091120958328247, -0.6899940371513367, -0.7672944664955139, 0.8659310340881348, 0.3294082283973694, -0.06258530169725418, -0.13577626645565033, -1.1716057062149048, -1.0000842809677124, -0.8841293454170227, 0.2095334827899933, -1.0663524866104126, -0.5263151526451111, 1.0720715522766113, 0.6991987228393555, -1.0658173561096191, 0.8091608285903931, -0.24626287817955017, -0.17127187550067902, 0.3198464810848236, 0.6270162463188171, -0.18951193988323212, -0.69267737865448, -1.3292216062545776, 0.3510849177837372, 0.6686926484107971, -0.5266504287719727, -0.4823276698589325, -0.7744900584220886, -1.3554877042770386, -2.9582190109067596e-05, 0.7942695021629333, -0.5127270817756653, 0.9013485312461853, 0.009158576838672161, -0.764811098575592, 0.9236646294593811, 0.011386935599148273, -0.13737860321998596, 0.51285719871521, 0.07531841844320297, -0.5446286797523499, -0.1741608828306198, 0.0018186565721407533, 0.34667548537254333, 0.28176915645599365, -0.7032461762428284, -0.15202149748802185, 0.0358385406434536, -0.2664870619773865, -0.6174368262290955, -0.4236716330051422, 0.7243101596832275, -0.2812013328075409, 0.05270989611744881, -0.13671138882637024, 0.540087878704071, -0.09531160444021225, -0.2038860321044922, -0.9954656362533569, -1.1135896444320679, 0.714322566986084, 0.23699797689914703, 0.96030193567276, -0.7368594408035278, -0.5388750433921814, 0.354957640171051, 0.8948469161987305, 0.042320188134908676, -0.6970499157905579, 0.9158111810684204, -0.7234748005867004, 0.7434060573577881, 0.057597897946834564, -0.8542115688323975, 0.4934847354888916, 0.06834855675697327, -0.17692247033119202, -0.11420918256044388, 0.07745413482189178, 1.34773588180542, -1.3648513555526733, -0.41498711705207825, 0.5479342937469482, 0.017806585878133774, -0.9553184509277344, 1.0981335639953613, 0.04458979144692421, -0.42619380354881287, -0.07704417407512665, -0.5265786051750183, 0.15518099069595337, -0.435152143239975, 0.6552019715309143, -0.29513606429100037, 0.19468075037002563, 0.40189987421035767, -0.5995675325393677, 1.0778292417526245, -0.2789892554283142, 0.2659074366092682, -0.019948219880461693, -1.13193678855896, 0.10558760911226273, 0.22317391633987427, 0.19378814101219177, -0.4084130525588989, -0.08482662588357925, -0.024342333897948265, -0.5456477403640747, 0.3564651906490326, 0.6538499593734741, 0.6179034113883972, -0.1122535765171051, 0.4065712094306946, 0.7446080446243286, 0.3276849091053009, 0.5708171129226685, 0.8212960362434387, 1.1586458683013916, 0.149989053606987, 0.3637423813343048, 0.03186061605811119, 0.027367446571588516, -0.8209890127182007, -0.11251147836446762, 0.8411297798156738, 0.6054788827896118, 0.25414279103279114, 0.5117864012718201, -0.6348465085029602, -0.16177286207675934, -0.3725486695766449, 0.9287967681884766, 1.5372819900512695, 0.4087938964366913, -0.9191901087760925, -0.4996815025806427, -0.8223491311073303, -0.26661139726638794, 0.08922257274389267, -0.6793821454048157, -0.5709611773490906, -0.40660691261291504, -1.048776388168335, 0.8689151406288147, 0.4397430717945099, 1.3891733884811401, -0.5255858898162842, 0.11669102311134338, -0.3062305748462677, 0.13713723421096802, -0.9640639424324036, -0.48863697052001953, 0.27440446615219116, 0.01738002896308899, -0.574172854423523, 0.20840434730052948, -0.07728604227304459, 0.5910642743110657, -0.5985483527183533, 0.8281902074813843, 0.06734424084424973, -0.3339490592479706, 0.42159906029701233, 0.7101160883903503, -0.32927918434143066, -0.40317681431770325, 0.3081068992614746, -0.0983743742108345, -0.19173364341259003, 0.08712088316679001, 0.25073155760765076, 0.03277380391955376, 0.2792282700538635, -0.7216250896453857, 0.16915488243103027, -0.1257193386554718, 0.22737416625022888, 0.11644241958856583, 0.3001670241355896, -0.01397819072008133, -1.456965446472168, 0.5085167288780212, 0.08677394688129425, -0.3047120273113251, 0.22727563977241516, -1.0797162055969238, -0.3210582733154297, 0.6354673504829407, -0.5662546753883362, 0.1426582783460617, -1.3017758131027222, 0.546933650970459, -0.009871619753539562, -0.07754486799240112, 0.3193543553352356, -0.08064396679401398, -0.21962767839431763, -0.06355895847082138, 0.11529116332530975, 0.15444597601890564, 0.24887505173683167, 0.7030975818634033, -1.3217554092407227, 0.6356126666069031, 0.024586493149399757, 0.8470377922058105, -0.20273078978061676, 0.6151854991912842, -0.7252954244613647, -0.2504790127277374, -0.29470881819725037, -0.019000135362148285, -0.649186909198761, -0.0155549431219697, -0.16988788545131683, -1.3123937845230103, 0.1299564242362976, -0.6811730861663818, -0.5999007821083069, 0.1839693784713745, -0.4275914430618286, 0.16748274862766266, -0.6593008637428284, -1.197041630744934, -0.5048268437385559, 0.07464137673377991, -0.788999080657959, 0.1299436092376709, 0.07099968194961548, -0.3464933931827545, -1.2019346952438354, -0.29297682642936707, -0.3678944408893585, 0.7906067967414856, 0.08512771129608154, 0.9010180234909058, -0.06533996015787125, -0.8319054841995239, -0.33521464467048645, 0.035063549876213074, 0.2840212881565094, -0.2250385582447052, 0.1863115280866623, -0.6090772151947021, 0.24899888038635254, -1.3771450519561768, -0.16048221290111542, 0.08292803913354874, 0.424142986536026, 0.7654035687446594, -0.4170672595500946, -0.8105546236038208, 0.09510047733783722, 1.4889293909072876, -1.034229040145874, 0.27781423926353455, 0.31729161739349365, 1.2426128387451172, 0.3472762405872345, -0.46194666624069214, 0.2156512290239334, 0.4927586019039154, 0.4694259464740753, 0.583512008190155, -0.6632108688354492, -0.2543875575065613, -1.1475392580032349, 0.6036657691001892, 1.1659525632858276, 0.1596672087907791, -0.45553791522979736, -0.9154602885246277, 0.8151365518569946, -1.384592890739441, -1.2109296321868896, 0.5486156940460205, 0.6895861029624939, -0.15936189889907837, -0.13616597652435303, 0.23482246696949005, 0.425983190536499, 1.0213676691055298, 0.3086276948451996, -0.12913371622562408, -0.38643407821655273, 0.09005782008171082, 0.8194289207458496, 0.8407039642333984, 0.9785749912261963, 0.14054061472415924, 0.8260813355445862, 14.466617584228516, 0.7562128305435181, 0.23386946320533752, 0.04225311428308487, 0.08406781405210495, 0.44078969955444336, -0.7200583815574646, 0.2846105098724365, -0.6540773510932922, -0.2171701043844223, 0.8636948466300964, -0.23086516559123993, 0.6188894510269165, 0.06892012059688568, -0.2764226198196411, 0.5129104852676392, -0.4720984101295471, 0.2817671000957489, 0.16899001598358154, -1.270359754562378, 0.4983389377593994, 0.6503198742866516, 0.06533309817314148, 0.309502512216568, 0.8674950003623962, 0.6714181900024414, 0.9503610134124756, -0.8933950662612915, 0.2815747559070587, 0.23939988017082214, 1.0138463973999023, -0.2932981550693512, 0.4711436927318573, 0.25954386591911316, -1.3898377418518066, 0.015784852206707, -0.5119646191596985, -1.0354132652282715, 0.0024567709770053625, 0.1600031554698944, -0.7469613552093506, 0.1634361743927002, -0.09922797977924347, 1.5971803665161133, 0.19835785031318665, 0.21827222406864166, -0.5894956588745117, 0.7248238921165466, -0.09389420598745346, 0.1927250772714615, 0.4042390286922455, 0.38986557722091675, 0.22951637208461761, 0.07615809142589569, -0.05724377930164337, -0.1431138515472412, 0.38342806696891785, 0.5844763517379761, -0.8605312705039978, -0.12897056341171265, -0.8780714273452759, -0.5543718338012695, 0.19209763407707214, 1.1228128671646118, 0.35051804780960083, 0.46024033427238464, -0.33775338530540466, -0.034333404153585434, 0.42313268780708313, 0.24622640013694763, -0.3410903513431549, -0.4250819683074951, 0.17277148365974426, -0.05005252733826637, -0.29739895462989807, 0.7178869843482971, 0.21856850385665894, -0.08940873295068741, -1.098911166191101, -0.10784708708524704, 0.8003838658332825, -0.6606755256652832, -0.6865537762641907, 0.5371682643890381, -0.3923375904560089, -0.03266168758273125, 0.26773756742477417, -1.0268257856369019, -0.572471559047699, 0.007222561631351709, -1.8064494132995605, -1.1544042825698853, -0.07928715646266937, 0.2771148979663849, -1.058700442314148, 0.2344631403684616, 1.185076117515564, 0.15687276422977448, -0.43187233805656433, 0.34166407585144043, -0.5936000943183899, 0.4588874578475952, -0.3407105803489685, -1.453955888748169, 0.6443387866020203, 0.7569440007209778, 0.3580964505672455, 0.4767407476902008, 0.1349002718925476, 0.17322342097759247, -0.7436602115631104, -0.29744014143943787, 0.4620068371295929, -0.8716127872467041, -0.19717489182949066, -0.7955235838890076, -0.8398967385292053, 1.033397912979126, 0.6204690337181091, 0.08486700803041458, 0.4679625928401947, 0.1932123601436615, -0.7431847453117371, -0.34883952140808105, -0.8803479671478271, 0.3946273922920227, 1.1625841856002808, -0.571790337562561, -0.02695474773645401, -0.3395441770553589, -0.034017499536275864, -0.4181092083454132, -0.7676500082015991, -0.34963446855545044, 0.13021190464496613, -0.28598669171333313, 1.1675211191177368, -0.7014366388320923, 0.6322500705718994, 0.7040973901748657, 0.2303771823644638, -0.9796774387359619, -0.4948130249977112, -1.6359282732009888, 0.251905232667923, 0.19204236567020416, 0.5827962756156921, -0.8389718532562256, 0.29295167326927185, 0.4367769956588745, 0.2093319147825241, 0.012268993072211742, -0.46541377902030945, -0.17378923296928406, -0.22330397367477417, -0.30678340792655945, 0.2974855601787567, 0.42578381299972534, 0.14771193265914917, 0.09132928401231766, 0.2615029811859131, 0.6876578330993652, 0.34470802545547485, -0.8267974257469177, 0.5408075451850891, -0.279043585062027, 0.22064784169197083, -1.0038574934005737, -0.995161235332489, -1.029845952987671, 0.5800101161003113, -1.754096269607544, -0.23886093497276306, -1.3883763551712036, -0.230739027261734, 0.41014614701271057, -0.40356704592704773, 0.48879337310791016, 0.07632913440465927, -0.2360873967409134, -0.6285691857337952, -1.2379156351089478, -0.7434151768684387, 0.48490190505981445, 0.824314296245575, -0.8841081261634827, 0.7930629849433899, -0.26979413628578186, -0.21625465154647827, 0.052751325070858, 0.2510051727294922, -0.6437947154045105, -0.8380941152572632, -0.6835983991622925, 0.4772646427154541, -0.46563687920570374, 0.5071654319763184, -0.41557031869888306, 0.6345248818397522, 0.26862576603889465, -0.09310402721166611, 0.44003763794898987, 0.2328394055366516, -0.9382732510566711, -0.06298615038394928, 0.6848200559616089, -1.0049943923950195, 0.40260109305381775, -0.25765419006347656, -0.2729237377643585, -0.07507392764091492, 0.8915936350822449, 0.14515505731105804, -1.0853155851364136, -0.5867754817008972, 0.8936598300933838, -0.5237752199172974, 0.36487260460853577, -0.27397146821022034, -0.6908812522888184, -1.3264822959899902, -0.42621293663978577, 0.13510526716709137, 0.5429360866546631, -0.2115415781736374, 0.6178539395332336, 0.4019041955471039, -1.2272584438323975, -0.07715059816837311, 0.0851908028125763, 0.16185784339904785, -0.24707353115081787, 0.2346259355545044, 0.19528916478157043, -0.005085302982479334, 0.052546482533216476, -0.17404791712760925, 0.5031172037124634, -1.0369211435317993, 0.2611488699913025, 0.6893893480300903, -0.8424580693244934, -0.6788415312767029, 0.6419669389724731, -0.1784592568874359, -0.8403533101081848, 0.13819070160388947, -0.9188880324363708, -0.39278170466423035, -0.770105242729187, 0.29085320234298706, 0.4349307417869568, -0.6247849464416504, 0.1316055804491043, -0.4707562029361725, 0.46631091833114624, -0.016820747405290604, -0.08283675462007523, 0.637877881526947, -0.01247181836515665, -0.633162796497345, 0.2908654510974884, 0.514003336429596, -0.482526957988739, -0.14812426269054413, -0.9795418977737427, -0.25068411231040955, -0.323923796415329, 0.43605464696884155, -0.023886173963546753, -0.793205976486206, 0.7797695398330688, -0.151356041431427, 1.0755258798599243, 0.08861324191093445, -0.36385518312454224, 0.04744800180196762, 0.6118031740188599, -0.015030876733362675, -0.6718267798423767, -0.16334596276283264, 0.5534070730209351, 0.6546051502227783, -0.42989373207092285, 0.1443706750869751, -0.5552908778190613, -0.44239529967308044, 0.8109759092330933, 0.18040554225444794, -0.22851397097110748, 0.6798043847084045, -0.20109622180461884, -0.0927577093243599, -0.028466293588280678, -0.9789690375328064, -0.4067709445953369, 0.5210851430892944, 1.4912309646606445, 0.4768718481063843, 0.2006264328956604, 0.37616562843322754, 0.44257447123527527, 0.011340362951159477, -0.17147761583328247, 0.8173288106918335, 0.23874299228191376, -0.16872823238372803, -0.293227881193161, 0.5193985104560852, 0.18978360295295715, -0.8721259832382202, -0.20459304749965668, -0.4440133571624756, 1.2547913789749146, 0.08843102306127548, 0.7444734573364258, 0.18758076429367065, 0.03340189903974533, 0.3955741822719574, -0.07103440910577774, 0.7657427787780762, -0.3534727096557617, -0.24674052000045776, -0.7908118367195129, -0.4031272530555725, -0.24962571263313293, -0.6573594212532043, -0.078729547560215, -0.5819879770278931, -0.7939232587814331, 0.009738107211887836, 0.42844536900520325, 0.08351261913776398, 1.0716352462768555, 0.04006115347146988, 0.6849708557128906, 0.04474379122257233, 0.12190049886703491, 0.154501274228096, -0.596830427646637, -0.517619252204895, -0.2771126329898834, -0.2829747200012207, -0.6297634840011597, -0.3886595368385315, -0.5867278575897217]}, "authors": [{"authorId": "2144171168", "name": "Jinwoo Kim"}, {"authorId": "2175080400", "name": "Tien Dat Nguyen"}, {"authorId": "3387623", "name": "Seonwoo Min"}, {"authorId": "2149157242", "name": "Sungjun Cho"}, {"authorId": "3056520", "name": "Moontae Lee"}, {"authorId": "2118338545", "name": "Honglak Lee"}, {"authorId": "2241528", "name": "Seunghoon Hong"}], "references": [{"paperId": "5922f437512158970c417f4413bface021df5f78", "title": "A Generalist Agent"}, {"paperId": "407238453abd02a9edf48032eaa19819d6d150ff", "title": "Benchmarking Graphormer on Large-Scale Molecular Modeling Datasets"}, {"paperId": "e0995bad59c8638ea8c319bb7220c0f0b1ed5dca", "title": "DeepNet: Scaling Transformers to 1, 000 Layers"}, {"paperId": "eb984b142db9965b10a3b5ae5813eeb3e0f6e676", "title": "Sign and Basis Invariant Networks for Spectral Graph Representation Learning"}, {"paperId": "9a5ff9a67fd389d26b20697fea01c12d012f8592", "title": "1-WL Expressiveness Is (Almost) All You Need"}, {"paperId": "e58dde4b23f251314e900f56e765b4aad27bc15f", "title": "Transformer for Graphs: An Overview from Architecture Perspective"}, {"paperId": "b92898a28bfad42a053726c2707cc05686cd332a", "title": "GRPE: Relative Positional Encoding for Graph Transformer"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "a585828fab3ec46ad27e14adfd299953df107a47", "title": "Transformers Generalize DeepSets and Can be Extended to Graphs and Hypergraphs"}, {"paperId": "9933a5af7895354087baf6c96b64dc8a8973eaed", "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs"}, {"paperId": "cf5e6e3c50a798d87033e0e108e88b3647738bbe", "title": "How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "47ae807cd511b35e78a2cd4e198283dea6dafd41", "title": "Do Transformers Really Perform Bad for Graph Representation?"}, {"paperId": "5863d7b35ea317c19f707376978ef1cc53e3534c", "title": "Rethinking Graph Transformers with Spectral Attention"}, {"paperId": "148011adfae37b821407aae84fcbbf7fb4619eb6", "title": "On the Expressive Power of Self-Attention Matrices"}, {"paperId": "af679d69fcc1d0fcf0f039aba937853bcb50a8de", "title": "Luna: Linear Unified Nested Attention"}, {"paperId": "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500", "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling"}, {"paperId": "ab30672c8c5e4787f6a5985f26a8f281f0db2fb8", "title": "How Attentive are Graph Attention Networks?"}, {"paperId": "d13a0c8d49cb268d8d245925baee0316c1fe1875", "title": "Which transformer architecture fits my data? A vocabulary bottleneck in self-attention"}, {"paperId": "919ede27c84203ee0522c623f99f2315124cf164", "title": "Mesh Graphormer"}, {"paperId": "2984ab83ade26639c3a82d29628d0d9e4abbebb0", "title": "Incorporating Convolution Designs into Visual Transformers"}, {"paperId": "9389af659f14239319186dff1cef49e8ece742c8", "title": "OGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs"}, {"paperId": "b3bf9fe13195e9aa70e1dac04e01fcff7008e812", "title": "Perceiver: General Perception with Iterative Attention"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "849b88ddc8f8cabc6d4246479b275a1ee65d0647", "title": "A Generalization of Transformer Networks to Graphs"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c6d550c3fcecf27b979be84c4cd444cc1c72bf47", "title": "A Note on Over-Smoothing for Graph Neural Networks"}, {"paperId": "a9a4e8e631890a14257539948e1813b5214c60dd", "title": "Self-Supervised Graph Transformer on Large-Scale Molecular Data"}, {"paperId": "75e17a2dc0a2b2c1cce5ab89d8c703fb8bddbef1", "title": "On the Computational Power of Transformers and Its Implications in Sequence Modeling"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "750fbba3e7545ee8eb73c549a6f4d92ea0521386", "title": "Set2Graph: Learning Graphs From Sets"}, {"paperId": "597712c88550cfa0ebfdba8ee3f0134404d95c56", "title": "On Learning Sets of Symmetric Elements"}, {"paperId": "b1c39d042fdf8f00a407b0df734764beb6c3b062", "title": "Low-Rank Bottleneck in Multi-head Attention Models"}, {"paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a", "title": "On Layer Normalization in the Transformer Architecture"}, {"paperId": "536da0e76290aea9cbe75c29bac096aeb45ef875", "title": "Can graph neural networks count substructures?"}, {"paperId": "509b4661ed74a24c2ffdbf131f9e1c6a1783752d", "title": "Are Transformers universal approximators of sequence-to-sequence functions?"}, {"paperId": "bb713d56a39a040b35e4f9e036fb4422f543e614", "title": "On the Relationship between Self-Attention and Convolutional Layers"}, {"paperId": "5951d1e1a850a333519caaeee68e3b1070e2eb7a", "title": "Universal Graph Transformer Self-Attention Networks"}, {"paperId": "135334ea7fdef8eef0367e862797cac7dcd232a4", "title": "Multi-scale Attributed Node Embedding"}, {"paperId": "4ca4e7ed290617aab8b4d99294d10b0ac8372967", "title": "Self-Attention with Structural Position Representations"}, {"paperId": "4ce9c20642dce5eb7930966053a1e3da4ef617f2", "title": "Graph Neural Networks Exponentially Lose Expressive Power for Node Classification"}, {"paperId": "057b594c9e6ed45fc445a4dc45384117bdd15a3e", "title": "Provably Powerful Graph Networks"}, {"paperId": "d52961a91f03061c6732a69e292bd1e403e7f8b8", "title": "Universal Invariant and Equivariant Graph Neural Networks"}, {"paperId": "09b8c3ca3f625b222dea87c1cf904a4632c71a71", "title": "Convolution, attention and structure embedding."}, {"paperId": "b7a6b7adafd01e939c9266083dfba9edea88846c", "title": "On the Universality of Invariant Networks"}, {"paperId": "5f4a22ee70ca613d9c0630eafc96364fe365fdf8", "title": "Efficient Attention: Attention with Linear Complexities"}, {"paperId": "c2d40522eaa5523d67a0de5e4098e7031fdccb3d", "title": "Pitfalls of Graph Neural Network Evaluation"}, {"paperId": "62ed9bf1d83c8db1f9cbf92ea2f57ea90ef683d9", "title": "How Powerful are Graph Neural Networks?"}, {"paperId": "6541afa4b4061a7d5c8387514bedea9dc249fd80", "title": "Invariant and Equivariant Graph Networks"}, {"paperId": "7a90d95ffc3d2d397fee3133165c0af9501f55c0", "title": "3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data"}, {"paperId": "6f3370fcf266fc10842b6d3e77c6cadd842a3580", "title": "Tensor Field Networks: Rotation- and Translation-Equivariant Neural Networks for 3D Point Clouds"}, {"paperId": "36652428740cd30d245d55889f01a7fb04a91c93", "title": "Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "5cba70a9b08ad6dc1ec06e269cff5e1dca34df14", "title": "Approximating Continuous Functions by ReLU Nets of Minimal Width"}, {"paperId": "33998aff64ce51df8dee45989cdca4b6b1329ec4", "title": "Graph Attention Networks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "e24cdf73b3e7e590c2fe5ecac9ae8aa983801367", "title": "Neural Message Passing for Quantum Chemistry"}, {"paperId": "a456265138c088a894301c0433dae938705a9bec", "title": "Deep Sets"}, {"paperId": "5394da74498e00597295d18cd0557bd47e3fc341", "title": "The Unreasonable Effectiveness of Structured Random Orthogonal Embeddings"}, {"paperId": "459cdfa379bffc07dd963610132f22421b9a0659", "title": "Equivariance Through Parameter-Sharing"}, {"paperId": "db1207440d20104854464d51da4cf5f79c5de240", "title": "Steerable CNNs"}, {"paperId": "0e779fd59353a7f1f5b559b9d65fa4bfe367890c", "title": "Geometric Deep Learning: Going beyond Euclidean data"}, {"paperId": "32e934094c4d17fe4d734b2e169ba5e3cd0ee05e", "title": "Orthogonal Random Features"}, {"paperId": "36eff562f65125511b5dfab68ce7f7a943c27478", "title": "Semi-Supervised Classification with Graph Convolutional Networks"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "fafcaf5ca3fab8dc4fad15c2391c0fdb4a7dc005", "title": "Group Equivariant Convolutional Networks"}, {"paperId": "de7422927aaa1cf84b5ce79f91400b0df4a60d46", "title": "Approximation with random bases: Pro et Contra"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "ebcea2d842d3d4e320500086aff0deb4cb4412ff", "title": "Efficient object localization using Convolutional Networks"}, {"paperId": "f22f6972e66bdd2e769fa64b0df0a13063c0c101", "title": "Multilayer feedforward networks are universal approximators"}, {"paperId": "d08a0eb7024dff5c4fabd58144a38031633d4e1a", "title": "Benchmarking Graph Neural Networks"}, {"paperId": "f9e84f215d0510a9eced6143645b47ddf330a714", "title": "Permutation Equivariant Layers for Higher Order Interactions"}, {"paperId": "716e5970c99aaff68b0be37c3eda0390e2e82199", "title": "Edge-augmented Graph Transformers: Global Self-attention is Enough for Graphs"}, {"paperId": null, "title": "Set transformer: A framework for attention-based permutation-invariant neural networks"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "7cd316505f52aa337ef8a2aff10bc6bf1df561d0", "title": "and s"}, {"paperId": "f3c389929f39c5347c37d2fa1b23259e0ef687a0", "title": "Convolution"}, {"paperId": null, "title": "First place solution of 2019 champs predicting molecular properties challenge"}, {"paperId": "3d2218b17e7898a222e5fc2079a3f1531990708f", "title": "I and J"}, {"paperId": "a828fd17399d0ec9f59801e21230e7f6391757f4", "title": "Emergence of Scaling in Random Networks"}, {"paperId": "12b03af504d0960334c77567dab38791bf0f739a", "title": "AND T"}, {"paperId": null, "title": "Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)?"}, {"paperId": null, "title": "Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content"}, {"paperId": null, "title": "Did you discuss any potential negative societal impacts of your work?"}, {"paperId": null, "title": "Did you discuss whether and how consent was obtained from people whose data you're using/curating?"}, {"paperId": null, "title": "Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?"}, {"paperId": null, "title": "Cited on 2) Checklist The checklist follows the references. Please read the checklist guidelines carefully for information on how to answer these questions. For each question"}, {"paperId": null, "title": "Have you read the ethics review guidelines and ensured that your paper conforms to them"}, {"paperId": null, "title": "code, data, models) or curating/releasing new assets... (a) If your work uses existing assets"}, {"paperId": null, "title": "(a) Did you state the full set of assumptions of all theoretical results?"}, {"paperId": null, "title": "Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)?"}]}