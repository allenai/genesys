{"paperId": "eda08c6f5919f39979acf0b3bc52e903063b5ba4", "abstract": "New Natural Langauge Process~(NLP) benchmarks are urgently needed to align with the rapid development of large language models (LLMs). We present Xiezhi, the most comprehensive evaluation suite designed to assess holistic domain knowledge.Xiezhi comprises multiple-choice questions across 516 diverse disciplines ranging from 13 different subjects with 249,587 questions and accompanied by Xiezhi-Specialty with 14,041 questions and Xiezhi-Interdiscipline with 10,746 questions. We conduct evaluation of the 47 cutting-edge LLMs on Xiezhi. Results indicate that LLMs exceed average performance of humans in science, engineering, agronomy, medicine, and art, but fall short in economics, jurisprudence, pedagogy, literature, history, and management. All the evaluation code and data are open sourced in https://github.com/MikeGu721/XiezhiBenchmark", "venue": "AAAI Conference on Artificial Intelligence", "year": 2023, "citationCount": 30, "influentialCitationCount": 8, "openAccessPdf": {"url": "http://arxiv.org/pdf/2306.05783", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "Evaluation of the 47 cutting-edge LLMs on Xiezhi indicates that LLMs exceed average performance of humans in science, engineering, agronomy, medicine, and art, but fall short in economics, jurisprudence, pedagogy, literature, history, and management."}, "embedding": {"model": "specter_v2", "vector": [-0.10857535153627396, 0.5670597553253174, -0.3288341462612152, -0.04185371845960617, -0.4957738518714905, -0.7923691868782043, 0.5852339267730713, -0.298336386680603, -0.11193407326936722, 0.5681353807449341, 0.40519577264785767, -0.5410487651824951, -0.17975039780139923, -0.03865470737218857, 0.02180998958647251, 0.12375269085168839, -0.21508322656154633, 0.6127581596374512, -0.49339812994003296, -0.29472073912620544, 0.09224022179841995, -0.5310049057006836, -0.43444040417671204, -0.1322719156742096, 0.5633965730667114, 0.10951176285743713, -0.11713552474975586, 0.9525157809257507, -0.33788925409317017, 0.5037144422531128, 0.22535686194896698, -0.5195478200912476, -0.1932908296585083, 0.07060161232948303, -0.875016450881958, -0.073007732629776, 0.29362228512763977, -0.37034401297569275, -0.4137217104434967, 0.7672250866889954, -0.021684452891349792, -0.00495128845795989, 0.8484838604927063, -0.45247122645378113, -0.7781745195388794, 0.7862103581428528, 0.9889046549797058, 0.09580624848604202, 0.31640446186065674, -0.15545286238193512, 1.6020077466964722, -1.2265974283218384, 0.877350926399231, 1.2977582216262817, 0.3962830901145935, 0.4231368899345398, -0.19699887931346893, -0.8606452345848083, 0.027189895510673523, -0.051014333963394165, -0.7766397595405579, 0.19159097969532013, -0.014476370997726917, -0.3227032721042633, 1.1642920970916748, -0.5261434316635132, -0.38756996393203735, 0.34552332758903503, 0.19759412109851837, 1.267926812171936, 0.2517780661582947, -0.6057282090187073, 0.017672374844551086, 0.27350446581840515, 0.4042315185070038, 0.4816223680973053, -0.30175426602363586, 0.18292097747325897, -0.7486656308174133, -0.1443508416414261, 0.5782450437545776, -0.27373766899108887, -0.32044512033462524, 0.34575092792510986, -0.7439607977867126, 0.5468676090240479, -0.056713711470365524, 1.0869789123535156, -0.13916707038879395, 0.3538847863674164, 0.1601426750421524, 0.851910412311554, -0.2847682237625122, 0.8215853571891785, -0.7283479571342468, 0.2034779191017151, -0.5344215035438538, 0.6300168633460999, 0.4748595356941223, 0.9409693479537964, 0.14767403900623322, -0.056571464985609055, -0.8837871551513672, -0.06696070730686188, 1.4249147176742554, 0.009542040526866913, 0.2307094931602478, -1.3408282995224, 0.15210117399692535, 0.04586013779044151, 0.7043706774711609, -0.45349743962287903, -0.24564531445503235, -0.2227385938167572, -0.33002522587776184, -0.9765630960464478, -0.3403248190879822, -0.2717874050140381, -0.4979615807533264, 0.825609028339386, -0.048384130001068115, -0.24053192138671875, 0.50982266664505, 0.4403918981552124, 1.2435989379882812, 0.6437839865684509, 0.5075467824935913, 0.25211700797080994, 1.0479165315628052, -0.06273932754993439, -0.8405240774154663, -0.864608645439148, 0.8705731630325317, 0.10902106761932373, 0.2594938278198242, -0.16191712021827698, -1.2064745426177979, -0.7386215925216675, -0.5444961786270142, -0.28999200463294983, -0.4874001443386078, 0.4231961965560913, 0.7484738826751709, 0.4197118580341339, -1.083531141281128, 0.38303300738334656, 0.5044581294059753, -0.3102208375930786, -0.18528173863887787, 0.06361120939254761, -0.2218468338251114, -0.7901244759559631, -1.7497037649154663, 0.4552795886993408, 0.8220743536949158, -0.7230827808380127, -0.5227380990982056, -0.37360432744026184, -1.2865065336227417, 0.20777270197868347, 0.814026951789856, -0.6148078441619873, 1.432649850845337, 0.4887658953666687, -1.1715352535247803, 0.731431245803833, -0.1726081222295761, 0.5574793815612793, 0.2115810662508011, -0.029871994629502296, -0.896416962146759, -0.09330997616052628, 0.23159140348434448, 0.4003552198410034, -0.12015579640865326, -0.4418206512928009, 0.09057494252920151, 0.20804855227470398, 0.03538976609706879, -0.26622089743614197, -0.23582454025745392, 0.8955700993537903, -0.27882638573646545, -0.08204153925180435, 0.022472448647022247, 0.7723600268363953, 0.15800723433494568, 0.24363812804222107, -0.6476773023605347, -0.9042417407035828, 0.9523038268089294, -0.30396348237991333, 1.1122325658798218, -0.8892789483070374, -0.8048046827316284, -0.5178284049034119, 0.21985092759132385, -0.2968369722366333, -0.7479397058486938, 0.911338210105896, -0.2289951741695404, 0.7747731804847717, -0.6930899620056152, -0.7494919896125793, 0.23489166796207428, -0.06602217257022858, -0.4170391261577606, -0.4046599864959717, 0.2147047370672226, 1.3518627882003784, -0.7865996956825256, -0.26288706064224243, 0.2803792953491211, -0.17666397988796234, -0.5035220980644226, 0.8850504755973816, -0.7986294031143188, 0.44492340087890625, -0.2932916283607483, 0.08281401544809341, -0.10117197036743164, -0.34334149956703186, 0.3088292181491852, -0.06242477148771286, -0.48904600739479065, 0.15517714619636536, -0.6795380115509033, 1.580301284790039, -0.16312965750694275, 0.4613114595413208, 0.35185593366622925, -0.23477697372436523, -0.008618607185781002, 1.020715355873108, -0.4043208062648773, 0.016132283955812454, 0.09921550005674362, 0.2070600539445877, -0.8244249224662781, -0.38496795296669006, 0.03419347107410431, 0.49357888102531433, -0.639213502407074, 0.46300631761550903, 0.675309956073761, -0.6636305451393127, 0.33984702825546265, 0.08935371041297913, 0.6672545671463013, 0.3233930468559265, 0.7909737229347229, -0.48770639300346375, 0.595453143119812, -0.22973164916038513, 0.10127084702253342, 0.47978687286376953, 0.44921648502349854, 0.3591808080673218, 0.5053909420967102, -0.5061968564987183, 0.028304224833846092, -0.2283543348312378, 0.34690195322036743, 1.1816056966781616, 0.16798123717308044, 0.011221768334507942, -0.6361010670661926, -0.45240727066993713, -0.30571335554122925, 0.7838871479034424, -0.6002957820892334, 0.10302768647670746, -0.3654579520225525, -0.5129931569099426, 0.9289267659187317, 0.3368063271045685, 1.2381513118743896, -0.8819159269332886, -0.2564105987548828, -0.19142453372478485, 0.35111698508262634, -0.5239369869232178, -0.1584601104259491, -0.25584641098976135, -0.08229947835206985, -0.40632250905036926, 0.12922915816307068, -0.30721575021743774, -0.16438694298267365, -0.7280005216598511, 0.9887176156044006, -0.6885917782783508, -0.3067033886909485, 0.4707993268966675, 0.8147774934768677, -0.5970945358276367, -0.8317059278488159, -0.107316754758358, -0.3507179319858551, -0.7388596534729004, 0.16981478035449982, 0.5383262634277344, 0.07148297131061554, 0.61615389585495, -1.0399147272109985, -0.08022020012140274, 0.2561606466770172, 0.29482296109199524, 0.283231258392334, 0.22210408747196198, 0.2536821961402893, -1.070320963859558, 1.059575080871582, 0.04040800780057907, -0.4936353862285614, 0.9144545197486877, -0.773788571357727, -0.40266743302345276, 0.3870680630207062, -0.5367657542228699, -0.7236558198928833, -1.3181812763214111, 0.5308894515037537, 0.7548524141311646, -0.9973665475845337, 0.9518263339996338, -0.35461369156837463, 0.04667699709534645, 0.043749384582042694, 0.38339701294898987, 0.13186149299144745, 0.1338370442390442, 0.8299780488014221, -0.5063135027885437, 0.3037472069263458, 0.19415916502475739, 0.24042704701423645, -0.37650805711746216, -0.06128877401351929, -0.8383671045303345, -0.27182745933532715, -0.031782448291778564, 0.32053881883621216, -0.395232617855072, 0.4771938920021057, -0.628278374671936, -1.132067322731018, 0.02867194265127182, -1.0974823236465454, -0.1770935356616974, 0.18014279007911682, -0.1444026082754135, 0.08771765232086182, -0.9460604190826416, -1.0744762420654297, -0.5905852913856506, -0.42863187193870544, -0.7664244771003723, 1.1034096479415894, 0.034379150718450546, -0.6190425753593445, -0.9431827068328857, 0.30920538306236267, -0.16476960480213165, 0.6903074383735657, -0.1779010146856308, 1.2259507179260254, -0.07737826555967331, -0.10264284163713455, -0.43795278668403625, 0.28024229407310486, 0.39148417115211487, 0.05245843529701233, 0.3546072840690613, -0.4023102819919586, 0.6321696043014526, 0.4631425142288208, -0.5503365397453308, -0.35084548592567444, 0.4798453152179718, 0.3654031753540039, 0.2874760627746582, -0.3090667724609375, -0.41865649819374084, 1.4479711055755615, -0.42627736926078796, 0.11307470500469208, 0.036198608577251434, 0.43843722343444824, 0.8325206637382507, -0.12553724646568298, 0.5004473328590393, 0.48092976212501526, -0.0722481980919838, -0.07576119899749756, -0.019336728379130363, 0.42250367999076843, -0.17648634314537048, 0.5751709938049316, 0.6431582570075989, 0.3474535644054413, -0.43363308906555176, -1.4918245077133179, 0.5190190076828003, -0.8734319806098938, -0.677712082862854, 0.4290514588356018, 0.4376208484172821, 0.5041336417198181, -0.6265397667884827, -0.8239856958389282, 0.13822801411151886, 0.5300705432891846, 0.01919298619031906, -0.30512627959251404, 0.03195733204483986, -0.07586020231246948, 0.32017630338668823, -0.2745310664176941, 0.8402750492095947, -0.35558006167411804, 0.7455682754516602, 14.99311637878418, 0.7323334813117981, 0.16525417566299438, 0.358473002910614, 0.7044801712036133, 0.7020674347877502, -0.6857370734214783, -0.12501829862594604, -1.1117706298828125, -0.4043194353580475, 0.9861161112785339, -0.11050217598676682, 0.18311579525470734, 0.37205731868743896, 0.06766195595264435, 0.1609867811203003, -0.4071599245071411, 0.22736497223377228, 0.41345202922821045, -1.2130272388458252, 0.48032164573669434, 0.47632452845573425, 0.6307479739189148, 0.26160135865211487, 0.6566715240478516, 0.9302512407302856, 0.6781366467475891, -0.6721416115760803, 0.5251078009605408, 0.37007713317871094, 1.015989899635315, -0.07274315506219864, 0.819047749042511, 0.9132717251777649, -0.7201451063156128, -0.3637913465499878, -0.36016878485679626, -1.0410568714141846, 0.17967620491981506, 0.06495825201272964, -0.6322479844093323, -0.1763196885585785, -0.5963083505630493, 0.36226537823677063, 0.3960886597633362, 0.06227538734674454, -0.750260591506958, 0.7929268479347229, 0.26552465558052063, -0.08228101581335068, 0.018656330183148384, 0.33556318283081055, 0.22173082828521729, -0.4769866466522217, 0.3511119484901428, 0.414508581161499, 0.11235493421554565, 0.724498987197876, -0.6297725439071655, -0.1273265928030014, -0.7634729743003845, -0.5898016691207886, -0.0720963254570961, 0.36314186453819275, 0.5231558084487915, 0.5002390742301941, -0.48437434434890747, 0.04060707241296768, -0.06272786855697632, 0.3664795756340027, -0.13135850429534912, 0.0005667884834110737, 0.6662436127662659, -0.39521893858909607, -0.5564131140708923, 0.26737865805625916, -0.5948312282562256, -0.2837987542152405, -0.9222736358642578, -0.21500876545906067, 0.2544480562210083, -0.8241578936576843, -0.8583964109420776, 0.6506494283676147, -0.23514164984226227, -0.6724528074264526, 0.08341579139232635, -1.0250900983810425, -0.41351914405822754, 0.3509276509284973, -1.2669486999511719, -1.3030033111572266, 0.12124913185834885, -0.3051057755947113, -0.3160269260406494, 0.3572239577770233, 1.4024629592895508, -0.3726642429828644, -0.34506168961524963, -0.5554343461990356, 0.13263455033302307, 0.02426876500248909, 0.011840890161693096, -1.0549918413162231, 0.7453997135162354, -0.05498656630516052, -0.47606590390205383, 0.4461403489112854, 0.04140594229102135, -0.49866631627082825, -0.9185947775840759, -0.16389822959899902, 0.7378029227256775, -1.344849944114685, -0.3154054880142212, -0.5972461700439453, -0.8430750966072083, 0.17214663326740265, 0.7107310891151428, -0.8026838898658752, 0.8810524344444275, -0.24176040291786194, 0.06807275116443634, 0.3030250072479248, -1.3825688362121582, 0.0008545506279915571, 0.39942991733551025, -0.8964640498161316, -0.7974272966384888, 0.3120425045490265, 0.650949239730835, -0.5444345474243164, -0.8654579520225525, 0.08310430496931076, 0.12166082113981247, 0.14115285873413086, 0.5769936442375183, -0.4840479791164398, 0.8825801610946655, 0.48211365938186646, -0.07228298485279083, -0.34970659017562866, -0.1890830397605896, -0.8023799657821655, 0.3284080922603607, 0.08691763132810593, 1.1298977136611938, -0.6353937983512878, -0.010724429041147232, 1.3634849786758423, 0.20613321661949158, -0.39253517985343933, -0.7769291400909424, -0.14419500529766083, 0.32606539130210876, -0.4984285831451416, 0.5185473561286926, 0.09053009003400803, -0.1306249052286148, -0.05847508832812309, 0.4359753429889679, 0.9755151867866516, -0.2451913207769394, -0.33458539843559265, 0.2500073313713074, -0.6502378582954407, -0.050575483590364456, -0.6894023418426514, -0.33082082867622375, -1.1211837530136108, 0.23813512921333313, -0.5609560012817383, 0.17616704106330872, -1.3467621803283691, -0.7008306384086609, 0.9610602259635925, 0.12917301058769226, -0.06288022547960281, 0.277783066034317, -0.6975821256637573, -1.1969125270843506, -0.5963107347488403, -0.27783510088920593, 0.7713479995727539, 1.1142423152923584, -0.8311145901679993, 0.15784870088100433, -0.4291408360004425, -0.5390187501907349, 0.08591270446777344, 0.38481956720352173, -0.17915546894073486, -0.9358422160148621, -1.251234769821167, 0.3179721534252167, 0.0738038569688797, -0.15792760252952576, -0.7352774143218994, 0.6637044548988342, 0.0558413490653038, -0.13815712928771973, 0.23339912295341492, 0.03473668918013573, -0.8053872585296631, -0.1070004254579544, 0.30888402462005615, -0.9902431964874268, 0.051703814417123795, 0.2574338912963867, -0.6168648600578308, -0.6022868752479553, 0.4658359885215759, -0.25602325797080994, -1.1433629989624023, -0.5685985088348389, 0.333575963973999, -0.8507192730903625, -0.06425698101520538, 0.317204087972641, -0.3514295518398285, -1.0755256414413452, -0.5717109441757202, -0.16746152937412262, 0.8172188997268677, -0.13487491011619568, 0.33137962222099304, 0.38212689757347107, -0.5574147701263428, -0.25056931376457214, 0.15382228791713715, 0.12443685531616211, -0.16759845614433289, 0.7044126391410828, -0.06055735424160957, -0.5818271636962891, 0.6879135966300964, 0.3892081677913666, 0.7480764389038086, -0.4655821621417999, -0.20742982625961304, 0.18513330817222595, -0.314782053232193, 0.08532268553972244, 1.0503084659576416, 0.11031323671340942, -1.1013439893722534, -0.13732150197029114, -1.284719467163086, -0.9166125655174255, -0.7903192043304443, 0.8452317118644714, 0.32446786761283875, -0.6115084886550903, 0.11461314558982849, -0.1271607130765915, 0.3579210638999939, 0.14575672149658203, -0.7613831162452698, 0.4410613179206848, -0.011731673032045364, -0.6189828515052795, 0.6242944598197937, 0.36145684123039246, -0.6758719086647034, -0.2432214319705963, -0.2831575870513916, -0.022618155926465988, 0.23127742111682892, 0.2110660970211029, -0.770285964012146, 0.18878963589668274, 0.4720993638038635, 0.3337476849555969, 0.4896971583366394, 0.23110871016979218, 0.028102096170186996, 0.15485401451587677, 0.92919921875, 0.04567380249500275, -0.5242813229560852, -0.7218936681747437, 1.2027757167816162, 1.7052791118621826, -1.0510557889938354, 0.15514160692691803, -0.3409903645515442, -0.9242873787879944, 0.8628276586532593, 0.5458166003227234, 0.5668965578079224, 1.0817158222198486, -0.33122363686561584, 0.31119272112846375, -0.29995211958885193, -0.740947961807251, 0.009899371303617954, 0.5121727585792542, 0.6973966956138611, 0.6904259324073792, 0.42534223198890686, -0.2317967265844345, 0.952305257320404, 0.2640400230884552, 0.4041760265827179, 0.4715464413166046, 0.6784375309944153, -0.22785116732120514, -0.11157475411891937, 0.04336709901690483, 0.3460458517074585, -0.13829445838928223, -0.42822158336639404, -0.8287177085876465, 0.9018387198448181, 0.40974003076553345, 0.7238757014274597, -0.17516668140888214, 0.09195371717214584, 0.5440654158592224, 0.46191513538360596, -0.18021386861801147, -0.8577582836151123, -0.2422366589307785, -0.407095342874527, -0.3572938144207001, 0.14883224666118622, -0.20786075294017792, -0.43090811371803284, -0.26790446043014526, 0.19970713555812836, 0.07194818556308746, 0.3480692207813263, 0.3473576009273529, 1.2459226846694946, 0.6738279461860657, -0.2168121188879013, -0.6955351829528809, 0.1707441359758377, -0.5481156706809998, -1.0975637435913086, -0.22248828411102295, -0.8532159924507141, -0.4285655915737152, -0.42466530203819275, -0.1490868180990219, -0.6798800230026245]}, "authors": [{"authorId": "2160631240", "name": "Zhouhong Gu"}, {"authorId": "2215265340", "name": "Xiaoxuan Zhu"}, {"authorId": "2215246086", "name": "Haoning Ye"}, {"authorId": "2143838757", "name": "Lin Zhang"}, {"authorId": "2219864610", "name": "Jianchen Wang"}, {"authorId": "1999030240", "name": "Sihang Jiang"}, {"authorId": "2215212876", "name": "Zhuozhi Xiong"}, {"authorId": "2118274188", "name": "Zihan Li"}, {"authorId": "2152880833", "name": "Qi He"}, {"authorId": "2115803996", "name": "Rui Xu"}, {"authorId": "2158103505", "name": "Wenhao Huang"}, {"authorId": "1807168", "name": "Weiguo Zheng"}, {"authorId": "27155736", "name": "Hongwei Feng"}, {"authorId": "2116642640", "name": "Yanghua Xiao"}], "references": [{"paperId": "bb9a44c94a89dbe00f0061d05c70a45064ff6ea6", "title": "CMMLU: Measuring massive multitask language understanding in Chinese"}, {"paperId": "ce913026f693101e54d3ab9152e107034d81fce1", "title": "Holistic Evaluation of Language Models"}, {"paperId": "25f729d7773614846b412db3c6c2a3aab41ec409", "title": "M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models"}, {"paperId": "236c7dafea3df7ecffb5f18ec780d12f2f27d4b0", "title": "C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models"}, {"paperId": "86df06f81428921f8edda574f6a4106ea260e962", "title": "Measuring Massive Multitask Chinese Understanding"}, {"paperId": "a8d740aff768210d21bf30cd83bab156d78a232a", "title": "Towards Better Instruction Following Language Models for Chinese: Investigating the Impact of Training Data and Evaluation"}, {"paperId": "ae736662f64d56f3ab1894fbd9c45f8f37251843", "title": "OpenAssistant Conversations - Democratizing Large Language Model Alignment"}, {"paperId": "302ee27524a717ddc21f332ca634b9211c6ec6aa", "title": "HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge"}, {"paperId": "68c834c19cd126bbd6d25a3572d7205cfed76271", "title": "AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models"}, {"paperId": "bdb68c5e2369633b20e733774ac66eb4600c34d1", "title": "LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models"}, {"paperId": "bce55193d9a887ad00774a9134df08cd521a85ae", "title": "DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task"}, {"paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8", "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"}, {"paperId": "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d", "title": "A Survey of Large Language Models"}, {"paperId": "8fc90497d9043fdf35e71302b7c2e79bb907144f", "title": "Exploring the Impact of Instruction Data Scaling on Large Language Models: An Empirical Study on Real-World Use Cases"}, {"paperId": "574beee702be3856d60aa482ec725168fe64fc99", "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "8221f1597000543432b7021ca79dbc51a7a63f9c", "title": "Is ChatGPT a Good NLG Evaluator? A Preliminary Study"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "3599a236f285af48782fc30b1341d13ec7320735", "title": "A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT"}, {"paperId": "fbd49b25bdab98c171af49962a41139c73dacbde", "title": "Specializing Smaller Language Models towards Multi-Step Reasoning"}, {"paperId": "554d59aa0f61edb9fa896fbf5cd574058dd0500a", "title": "LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain"}, {"paperId": "cef330bacf014d60daabbd489647b2006af130ca", "title": "Discovering Language Model Behaviors with Model-Written Evaluations"}, {"paperId": "3936fd3c6187f606c6e4e2e20b196dbc41cc4654", "title": "Constitutional AI: Harmlessness from AI Feedback"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "663a41c866d49ce052801fbc88947d39764cad29", "title": "Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them"}, {"paperId": "1d26c947406173145a4665dd7ab255e03494ea28", "title": "GLM-130B: An Open Bilingual Pre-trained Model"}, {"paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a", "title": "Emergent Abilities of Large Language Models"}, {"paperId": "bd1331b233e84bab7eba503abc60b31ac08e7881", "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "cbf98ebe967e0f3f3236e7932f37013b98244e94", "title": "ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "1ccd031f28dccfb226f6c0c588c93a97a50bf95f", "title": "Measuring Coding Challenge Competence With APPS"}, {"paperId": "50796b0f3edf9cb5ff1e447c298b33755378aa4f", "title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling"}, {"paperId": "cedd535b3892766eef522d4d44bd67e120113e9f", "title": "Neural Correction Model for Open-Domain Named Entity Recognition."}, {"paperId": "c6d38e105562ae0a5d9b21fb4333212f36a3e041", "title": "A Survey of Evaluation Metrics Used for NLG Systems"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "66117f82def0c69a3b9cc77eb3e2694b0245ca86", "title": "Cosmos QA: Machine Reading Comprehension with Contextual Commonsense Reasoning"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": null, "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality"}, {"paperId": null, "title": "Free dolly: Introducing the world\u2019s first truly open instruction-tuned llm"}, {"paperId": "c9dff8253b2e776abf363d0a4836abcaf64ee327", "title": "ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge"}, {"paperId": "4972b88f8f324a4fa18e921f62a9857af2b5fc7b", "title": "Crosslingual Generalization through Multitask Finetuning"}, {"paperId": null, "title": "Baize: An open-source chat model with parameter-efficient tuning on self-chat data"}, {"paperId": null, "title": "Chatgpt: Optimizing language models for dialogue"}, {"paperId": null, "title": "Luotuo: An instruction-following chinese language model, lora tuning on llama"}, {"paperId": null, "title": "Koala: A dialogue model for academic research"}, {"paperId": null, "title": "Introducing mpt-7b: A new standard for open-source, ly usable llms"}, {"paperId": null, "title": "2023a). Fudannlp moss"}, {"paperId": null, "title": "h2ogpt -the world's best open source gpt"}, {"paperId": null, "title": "Stanford alpaca: An instruction-following llama model"}, {"paperId": null, "title": "Chatglm-med: \u57fa\u4e8e\u4e2d\u6587\u533b\u5b66\u77e5\u8bc6 \u7684chatglm\u6a21\u578b\u5fae\u8c03"}, {"paperId": null, "title": "How does gpt obtain its ability? tracing emergent abilities of language models to their sources"}, {"paperId": "bb0656031cb17adf6bac5fd0fe8d53dd9c291508", "title": "An empirical analysis of compute-optimal large language model training"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "If you are using existing assets (e.g., code, data, models) or curating/releasing new assets."}, {"paperId": null, "title": "Questions with incorrect answers should be removed"}, {"paperId": null, "title": "If deletion of a question leads to imbalance, new questions should be re-selected from Xiezhi-All to be included"}, {"paperId": null, "title": "ControlScienceandEngineering ControlTheoryandControlEngineering TestingTechnologyandAutomation SystemsEngineering PatternRecognitionandIntelligentSystems Navigation,GuidanceandControl"}, {"paperId": null, "title": "Most benchmarks relied on 4-option multiple choice questions. This made it too easy for models to guess correctly. More options were needed to better differentiate model capabilities"}, {"paperId": null, "title": "Did you mention the license of the assets?"}, {"paperId": null, "title": "2023b. MOSS: An open-source tool-augmented conversational language model from Fudan University"}, {"paperId": null, "title": "Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [Yes] Provided in"}, {"paperId": null, "title": "(a) If your work uses existing assets, did you cite the creators? [Yes] We use baseline models from Huggingface\u2019s Transformers, and detail describe and cite them in Appendix Models"}, {"paperId": null, "title": "c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation?"}, {"paperId": null, "title": "c) Did you include any new assets either in the supplemental material or as a URL? [Yes] We provide details in Appendix Models"}, {"paperId": null, "title": "b) Did you include complete proofs of all theoretical re-sults?"}, {"paperId": null, "title": "c) Did you discuss any potential negative societal impacts of your work? [Yes] We describe the limitations in Appendix"}, {"paperId": null, "title": "a) Did you include the full text of instructions given to participants and screenshots, if applicable? [Yes] The instructions are included in"}, {"paperId": null, "title": "Did you discuss whether and how consent was obtained from people whose data you \u2019 re using/curating?"}, {"paperId": null, "title": "Questions involving sensitive content such as military matters and politics should be removed"}, {"paperId": null, "title": "If the subject annotation is incorrect, it should be removed"}, {"paperId": null, "title": "If issue that cannot be modified was introduced during the crawling of questions, it should be removed"}, {"paperId": null, "title": "Many existing benchmarks quickly became outdated as they got incorporated into the training data of the latest LLMs. There was a need for benchmarks with fresher data"}, {"paperId": null, "title": "StabilityAI (2023)"}, {"paperId": null, "title": "Have you read the ethics review guidelines and ensured that your paper conforms to them?"}, {"paperId": null, "title": "If you are including theoretical results"}, {"paperId": null, "title": "Questions that contain China\u2019s ancient texts and contemporary political content should be removed"}, {"paperId": null, "title": "(a) Do the main claims made in the abstract and introduction accurately reflect the paper \u2019 s contributions and scope?"}, {"paperId": null, "title": "If you used crowdsourcing or conducted research with human subjects"}, {"paperId": null, "title": "OpenAI (2023a"}, {"paperId": null, "title": "Did you specify all the training details (e.g., data splits hyperparameters, how they were chosen)? [Yes] We describe the training of proposed annotation in Appendix Auto Annotator"}]}