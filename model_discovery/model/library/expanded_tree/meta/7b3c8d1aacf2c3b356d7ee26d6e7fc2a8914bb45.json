{"paperId": "7b3c8d1aacf2c3b356d7ee26d6e7fc2a8914bb45", "abstract": "In large language model training, input documents are typically concatenated together and then split into sequences of equal length to avoid padding tokens. Despite its efficiency, the concatenation approach compromises data integrity -- it inevitably breaks many documents into incomplete pieces, leading to excessive truncations that hinder the model from learning to compose logically coherent and factually consistent content that is grounded on the complete context. To address the issue, we propose Best-fit Packing, a scalable and efficient method that packs documents into training sequences through length-aware combinatorial optimization. Our method completely eliminates unnecessary truncations while retaining the same training efficiency as concatenation. Empirical results from both text and code pre-training show that our method achieves superior performance (e.g., relatively +4.7% on reading comprehension; +16.8% in context following; and +9.2% on program synthesis), and reduces closed-domain hallucination effectively by up to 58.3%.", "venue": "arXiv.org", "year": 2024, "citationCount": 4, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes Best-fit Packing, a scalable and efficient method that packs documents into training sequences through length-aware combinatorial optimization, and completely eliminates unnecessary truncations while retaining the same training efficiency as concatenation."}, "embedding": {"model": "specter_v2", "vector": [-0.04942915961146355, 0.6235722303390503, -0.2539686858654022, 0.16114488244056702, -0.24827267229557037, -0.27229776978492737, 0.4545595347881317, -0.05571994557976723, -0.09487646818161011, -0.2142203450202942, 0.9322946071624756, -0.5403342247009277, 0.5201379060745239, 0.2627710700035095, -0.324116587638855, 0.229227676987648, -0.9626678228378296, -0.07281459867954254, -0.5466609001159668, -0.07453080266714096, -0.14733316004276276, -0.7094119191169739, -0.8244854211807251, 0.3210758864879608, 0.6895290613174438, 0.00811670534312725, 0.29622113704681396, 0.49597907066345215, -0.34029436111450195, 0.6062726378440857, 0.17791126668453217, -0.034458622336387634, -0.04141101613640785, -0.08519858121871948, -0.02995564043521881, 0.05042010545730591, 0.039071742445230484, -0.30009031295776367, -0.4836123287677765, 0.5223458409309387, -0.20017479360103607, 0.22889456152915955, 0.26915422081947327, -0.3831855356693268, -0.24207623302936554, 1.1569617986679077, 0.6215021014213562, 0.238237202167511, -0.13763873279094696, -0.7006869912147522, 1.1417878866195679, -1.3383992910385132, 0.11340579390525818, 1.2887241840362549, 0.5466771125793457, 0.3750249445438385, -0.20476412773132324, -0.564344584941864, 0.7298337817192078, -0.2365194708108902, -0.9377210736274719, -0.23502594232559204, -0.17901372909545898, -0.1734202653169632, 2.052905321121216, -0.30706241726875305, 0.14899010956287384, 0.5189018845558167, 0.10781647264957428, 1.1756898164749146, -0.3008021116256714, -0.7784028053283691, -0.2995701730251312, 0.025074046105146408, 0.41917604207992554, 0.7136867046356201, -0.2615208029747009, 0.32085561752319336, -0.7146062254905701, -0.23510688543319702, 0.27776819467544556, -0.030396729707717896, -0.14540067315101624, -0.20593664050102234, -0.2135072946548462, 0.29658278822898865, -0.1047871857881546, 0.904914915561676, 0.19264183938503265, 0.5323562026023865, 0.37667837738990784, 0.2568328380584717, -0.018256882205605507, 0.6123676300048828, 0.0009096483699977398, 0.03510679304599762, -0.9548042416572571, 0.41723451018333435, 0.19281388819217682, 1.3718602657318115, -0.17611326277256012, 0.46012547612190247, -0.7054144144058228, 0.33739230036735535, 1.3091402053833008, 0.0545412115752697, 0.5288362503051758, -0.745568573474884, 0.5264840126037598, -0.6454136371612549, 0.3328058123588562, -0.17701876163482666, -0.4719323515892029, -0.6303027868270874, -0.18437066674232483, -1.190938115119934, -0.4941066801548004, -0.1588704138994217, -0.5272610783576965, 0.7226826548576355, -0.7527471780776978, 0.25692442059516907, 0.1709020584821701, 0.1290825754404068, 0.251308411359787, 0.46206891536712646, 0.267438679933548, -0.2301713079214096, 0.7474114894866943, -0.91243976354599, -0.604507327079773, -1.240573763847351, 0.9160996079444885, -0.5548965334892273, 0.285441130399704, -0.02836480364203453, -1.3860405683517456, -0.8601952791213989, -1.113861322402954, -0.129813089966774, -0.39124977588653564, 0.30664190649986267, 0.8482815027236938, 0.610069215297699, -0.8147702813148499, 1.0072879791259766, -0.11415039747953415, 0.25348374247550964, 0.3001348078250885, 0.11450580507516861, 0.4797776937484741, -0.6642805933952332, -0.9793471693992615, 0.22881802916526794, 0.235494926571846, -0.9330519437789917, -0.5386361479759216, -0.7176920771598816, -1.412816047668457, -0.10092475265264511, 0.35301822423934937, -0.37491440773010254, 1.326703429222107, 0.4852585792541504, -1.0001327991485596, 0.09811794012784958, -0.4571990668773651, 0.2993042767047882, 0.02677794173359871, -0.5576469898223877, -0.7008854746818542, -0.717619776725769, -0.45280054211616516, 0.2230001538991928, 0.3319896459579468, -0.5980998277664185, 0.24555730819702148, 0.3820686340332031, -0.4598854184150696, 0.093716561794281, -0.4533645212650299, 0.9564186930656433, -0.38796189427375793, -0.2907755672931671, 0.2886072099208832, 0.7896906137466431, -0.09292340278625488, -0.6064136028289795, -0.3641397953033447, -0.6922014355659485, 0.7826598286628723, -0.2795684337615967, 1.44329035282135, -0.9771251082420349, -0.990170419216156, -0.36479422450065613, -0.09238411486148834, -0.13891887664794922, -0.763301432132721, 1.1133761405944824, -0.4945264160633087, 0.5660093426704407, -0.29825419187545776, -1.5571202039718628, 0.31786826252937317, -0.10425960272550583, -1.011879324913025, -0.2371351718902588, 0.004567259456962347, 1.0218069553375244, -0.8242076635360718, 0.020693831145763397, -0.07323889434337616, 0.2329147756099701, -0.910243570804596, 1.1894333362579346, -0.796424150466919, 0.0811539739370346, 0.16155856847763062, 0.024823030456900597, 0.19397807121276855, -0.03437976911664009, 0.4870678186416626, -0.2341448813676834, -0.24209238588809967, 0.4691867232322693, -0.041838694363832474, 1.486649751663208, -0.4001334309577942, 0.45633789896965027, -0.3946130573749542, -0.35479408502578735, 0.17207971215248108, 0.655444860458374, -0.21128453314304352, -0.19886180758476257, 0.2931203544139862, 0.31240883469581604, -0.542275071144104, -0.15350399911403656, 0.9856346249580383, 0.5117846131324768, -0.40225401520729065, 0.30309391021728516, 0.598684549331665, -0.4570460319519043, 0.5515649914741516, 0.27626755833625793, 0.8373053073883057, 0.3994492292404175, 0.3672630786895752, 0.23709852993488312, -0.010119076818227768, -0.9454813003540039, -0.22340801358222961, 0.5489032864570618, 1.0198382139205933, 1.1870919466018677, 0.44421592354774475, -0.2799128592014313, -0.838337242603302, 0.0964406207203865, 0.8395469188690186, 1.2313741445541382, -0.12641674280166626, -0.6168055534362793, -0.9737359285354614, -0.22426792979240417, -0.415010929107666, 0.5124817490577698, -0.026673033833503723, -0.16495124995708466, -0.7454357147216797, -0.7270565032958984, 0.8155104517936707, 0.46015554666519165, 0.6810858845710754, -0.41427749395370483, 0.07202454656362534, -0.22981755435466766, 0.24497286975383759, -0.9256035685539246, -0.6207914352416992, 0.39293578267097473, -0.5768481492996216, 0.07313072681427002, 0.18146781623363495, -0.30979442596435547, 0.14411000907421112, -0.339802622795105, 1.0911258459091187, -0.05456451699137688, -0.27740478515625, 0.03339702636003494, 0.2296363264322281, -0.5300531983375549, -0.874918520450592, -0.11559450626373291, 0.037705324590206146, -0.6265823841094971, 0.26465263962745667, 0.20789016783237457, 0.42572295665740967, -0.09406157582998276, -0.4012521207332611, 0.270707368850708, 0.3225521445274353, 0.08740285038948059, 0.18337403237819672, -0.058156710118055344, -0.21225284039974213, -0.9620229601860046, 0.9812309741973877, 0.0667351558804512, -0.0556640699505806, 0.48081183433532715, -0.6328936815261841, -0.5389136075973511, 0.9205700159072876, -0.7027904987335205, -0.16702669858932495, -1.2439833879470825, 0.44500479102134705, -0.26780828833580017, -0.3173064887523651, 0.46122562885284424, -0.026925140991806984, 0.2451009303331375, 0.22008273005485535, 0.8177478313446045, 0.34626272320747375, -0.28284913301467896, 0.45557093620300293, -0.647922158241272, 0.4609188139438629, 0.10302037745714188, 0.194668248295784, -0.40054038166999817, -0.41860145330429077, -0.7997021675109863, -0.17046234011650085, -0.22331368923187256, -0.10181132704019547, -0.20833273231983185, 0.08074668049812317, -0.6993218660354614, -0.3970475196838379, -0.14752702414989471, -1.2828712463378906, -0.12944361567497253, 0.060553137212991714, -0.39161768555641174, -0.13718101382255554, -0.6713940501213074, -0.9533835053443909, -0.8530060052871704, -0.0967092514038086, -0.9581689238548279, 0.3931252658367157, -0.11102678626775742, -0.8032378554344177, -0.48643308877944946, -0.10039845108985901, -0.34939879179000854, 0.42712655663490295, -0.5960339307785034, 0.9188491106033325, 0.0382005013525486, -0.2571730613708496, -0.22202004492282867, 0.29295986890792847, 0.6369756460189819, -0.38889843225479126, 0.11802873760461807, -0.8746469616889954, 0.052052028477191925, 0.09552327543497086, -0.15941530466079712, -0.1102340966463089, -0.07113511860370636, 0.6670454144477844, -0.0896681696176529, -0.4933764636516571, 0.2923263907432556, 1.2268669605255127, -0.33423495292663574, 0.3194493353366852, -0.20316720008850098, 1.1604143381118774, 0.3808164596557617, -0.3305361866950989, 0.8294089436531067, -0.1459452211856842, 0.1582852303981781, 0.0664842277765274, 0.07607097923755646, -0.1771622896194458, -0.8539992570877075, 0.7294098734855652, 1.4194914102554321, 0.548272967338562, -0.16481176018714905, -1.1262727975845337, 0.7156152129173279, -1.277194619178772, -0.4409172832965851, 0.6354812383651733, 0.5705186128616333, 0.439290851354599, -0.49684348702430725, -0.46049970388412476, -0.15464623272418976, 0.3626539409160614, 0.14668011665344238, -0.21070538461208344, -0.4453869163990021, 0.07391323149204254, 0.32437434792518616, -0.02684987336397171, 0.6878409385681152, -0.3161599636077881, 0.25470757484436035, 15.206727981567383, 0.9456002712249756, 0.2665228545665741, 0.6915738582611084, 0.41874396800994873, 0.10148980468511581, -0.6490079760551453, -0.03677079826593399, -1.1175442934036255, -0.08342186361551285, 1.2169773578643799, 0.10128701478242874, 0.8078039288520813, 0.08196141570806503, 0.40429794788360596, 0.11546173691749573, -0.4572765827178955, 0.605861485004425, 0.5729607939720154, -1.20522141456604, 0.31396380066871643, 0.31185925006866455, 0.519015908241272, 0.0795084685087204, 0.8573020100593567, 0.8435609340667725, 0.2892996668815613, -0.7853121161460876, 0.851009726524353, 0.01224104780703783, 0.6152161359786987, -0.2775872051715851, 0.268473356962204, 0.8621669411659241, -0.5538060665130615, -0.48132097721099854, -0.48184606432914734, -1.3345776796340942, 0.28576427698135376, 0.11203790456056595, -0.8540210723876953, -0.3125622570514679, -0.7785360813140869, 0.5521436929702759, -0.12423761934041977, 0.43166792392730713, -0.23364514112472534, 0.780255913734436, 0.23682677745819092, -0.06732866168022156, 0.21905440092086792, 0.5259950757026672, 0.10541635006666183, 0.006946377921849489, 0.07193975150585175, -0.020166432484984398, 0.23469436168670654, 0.4474177658557892, -0.36809638142585754, -0.016993632540106773, -0.5598478317260742, -0.5125719308853149, -0.04823608323931694, 0.4075765609741211, 0.4272446930408478, 0.16133160889148712, -0.7978028059005737, -0.1129930168390274, 0.49541085958480835, 0.2720951437950134, -0.33570727705955505, 0.11979085952043533, 0.36423590779304504, -0.37429141998291016, -0.08706770837306976, 0.11387555301189423, -0.8002246618270874, -0.5930382013320923, -0.6180719137191772, -0.4763818383216858, -0.05549291521310806, -0.8744514584541321, -0.41589871048927307, 0.769102931022644, -0.07963550835847855, -0.8597646355628967, 0.2543887197971344, -0.5925086140632629, -0.2016487568616867, 0.48447033762931824, -0.7692914605140686, -0.7077463865280151, 0.24392376840114594, -0.6527367234230042, -0.44844603538513184, -0.11321625858545303, 1.4385100603103638, 0.09984935075044632, -0.35105007886886597, 0.030588150024414062, 0.27624425292015076, -0.021461594849824905, -0.3186742961406708, -0.6754981875419617, 0.7311045527458191, 0.5172476768493652, -0.05697402358055115, 0.766506016254425, 0.46113088726997375, -0.21321704983711243, -0.4695116877555847, -0.14300380647182465, 0.9970752596855164, -0.8382650017738342, -0.342739462852478, -1.0151325464248657, -1.0061465501785278, 0.20074807107448578, 0.617484450340271, -0.5479338765144348, 0.7595963478088379, 0.25027623772621155, -0.7223581075668335, 0.25314807891845703, -0.7188620567321777, 0.4666481614112854, 0.5112563967704773, -0.9706829786300659, -0.4526258409023285, -0.018415218219161034, 0.6544243693351746, -1.187988042831421, -0.471945196390152, -0.34829577803611755, -0.03235415369272232, -0.19287563860416412, 0.738457202911377, -0.23406267166137695, 1.1533046960830688, 0.7079935073852539, -0.14329488575458527, -0.6863159537315369, 0.1759599894285202, -1.110547661781311, -0.13282746076583862, 0.17444445192813873, 0.6137834191322327, -0.13916943967342377, 0.2202979028224945, 1.1577736139297485, -0.32988467812538147, -0.5384719967842102, -0.330832839012146, -0.39475786685943604, 0.39442628622055054, -0.7734927535057068, 0.3665727376937866, -0.17458094656467438, 0.6704469919204712, 0.12490770220756531, 0.23584751784801483, 0.5922175049781799, -0.3320516347885132, -0.7162613868713379, 0.21682856976985931, 0.5041722655296326, -0.25594842433929443, -0.5122637748718262, -0.17238196730613708, -1.4366580247879028, 0.09126930683851242, -0.9068182110786438, 0.16830803453922272, -0.6424095630645752, -0.38276463747024536, 0.44234517216682434, 0.29731595516204834, 0.13039347529411316, 0.48076045513153076, -0.5617339015007019, -0.34568408131599426, -0.59942626953125, -0.5514215230941772, 0.7298703789710999, 0.9505204558372498, -0.6251288652420044, 0.1487954556941986, -0.4127970039844513, -0.1317470520734787, -0.013990167528390884, 0.3681418299674988, -0.23365336656570435, -1.0171173810958862, -1.247239351272583, 0.10010602325201035, 0.061420708894729614, -0.08709795027971268, -0.7629335522651672, 0.4409400522708893, 0.474092960357666, -0.07051876932382584, -0.14978037774562836, 0.21212473511695862, -0.7280439734458923, -0.3284814655780792, 0.10195943713188171, -0.8739586472511292, 0.08874259889125824, 0.35158881545066833, -0.6599886417388916, -0.2033889889717102, 0.08888948708772659, -0.18994005024433136, -1.1939579248428345, -0.41200709342956543, -0.061351895332336426, -0.7628338932991028, 0.011792675592005253, -0.3546212613582611, 0.01670915260910988, -1.2023141384124756, -0.3443954288959503, -0.12359324842691422, 0.30185583233833313, -0.056541457772254944, 0.9696468710899353, 0.5970966815948486, -0.7658042907714844, 0.32385802268981934, 0.36602404713630676, -0.34903284907341003, -0.08530567586421967, 0.4582423269748688, 0.33482539653778076, -0.13875333964824677, 0.567827582359314, 0.6881144046783447, 0.6364045143127441, -1.0043808221817017, 0.13066759705543518, 0.6074036955833435, -0.4666113555431366, -0.1606760174036026, 0.991287887096405, -0.4270189702510834, -0.6394679546356201, 0.28538116812705994, -1.3201277256011963, -0.5222114324569702, -0.5121351480484009, 0.825529158115387, 0.09112272411584854, 0.1258344054222107, 0.12278687208890915, -0.2136046439409256, 0.06947490572929382, -0.2194693386554718, -0.6065900325775146, 0.45193609595298767, -0.2874169647693634, -0.39311107993125916, 0.607366144657135, 1.021809458732605, -0.5667006969451904, -0.6842893362045288, -0.34118175506591797, -0.28327929973602295, -0.16103549301624298, 0.14196151494979858, -0.5699341893196106, 0.09385950863361359, 0.6877683997154236, -0.04848797246813774, 0.27995410561561584, -0.1391213983297348, -0.28281867504119873, 0.30126747488975525, 0.4863642156124115, 0.18566668033599854, -0.6666699051856995, -0.5313885807991028, 1.4834333658218384, 1.461199164390564, -0.5573235750198364, 0.49750378727912903, -0.19648011028766632, -0.7979250550270081, 0.9419335722923279, 0.3669663071632385, 0.0442146360874176, 0.8549256920814514, 0.10931845754384995, 0.14616529643535614, 0.34451615810394287, -0.9715462923049927, 0.06036213040351868, 0.5103148818016052, 1.1130743026733398, 0.8794004917144775, 0.3450487554073334, 0.11419879645109177, 1.293272852897644, -0.08925095200538635, 0.0542394295334816, 0.8061305284500122, 0.7948132157325745, -0.029190585017204285, -0.44829171895980835, -0.3204081654548645, 0.4542425274848938, -0.3249466121196747, -0.8080912232398987, 0.22749458253383636, 0.4889758825302124, 0.5231175422668457, 0.7766507267951965, 0.5944284200668335, -0.2173256129026413, 0.41795042157173157, 0.5934053063392639, 0.5648616552352905, -0.9099156856536865, -0.5237327814102173, 0.312538206577301, -0.277474582195282, 0.09032569080591202, 0.14809894561767578, -0.787197470664978, -0.5394657254219055, -0.18848125636577606, 0.44990792870521545, -0.09397479891777039, 0.02185184508562088, 1.3564674854278564, 0.5125730633735657, 0.5103973150253296, -0.23039044439792633, -0.40852150321006775, -0.46131622791290283, -0.9016820788383484, -0.16365179419517517, -0.6982702612876892, -0.07397256046533585, -0.13711924850940704, 0.10189483314752579, -0.1398821771144867]}, "authors": [{"authorId": "2113455281", "name": "Hantian Ding"}, {"authorId": "2259065741", "name": "Zijian Wang"}, {"authorId": "2296990653", "name": "Giovanni Paolini"}, {"authorId": "40574366", "name": "Varun Kumar"}, {"authorId": "1713801", "name": "Anoop Deoras"}, {"authorId": "2258962983", "name": "Dan Roth"}, {"authorId": "2264070792", "name": "Stefano Soatto"}], "references": [{"paperId": "18e7ab056c16928d8f9539509a4b366889106d97", "title": "StarCoder 2 and The Stack v2: The Next Generation"}, {"paperId": "d395c771f6537259610497ba218cce5b9bfc2c50", "title": "In-Context Pretraining: Language Modeling Beyond Document Boundaries"}, {"paperId": "788477fadc464576ae1b059785245c9581e4e13f", "title": "Data-Juicer: A One-Stop Data Processing System for Large Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "31d65e179b1d00484154b3525d93846dd82f23d8", "title": "Inverse Scaling: When Bigger Isn't Better"}, {"paperId": "8395c95b2b4d0e4fbd345affcba242fe6776f23c", "title": "A Static Evaluation of Code Completion by Large Language Models"}, {"paperId": "7a1e71cb1310c4a873e7a4e54d1a6dab0553adce", "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"}, {"paperId": "154493f69d7db3d49da0e51df0192c6ad5f1724a", "title": "Larger language models do in-context learning differently"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "f3a6115e5fb2237df938976e005468f0b18da797", "title": "The Stack: 3 TB of permissively licensed source code"}, {"paperId": "75f7e9e2b59fb640ef9d1dff94097175daf46c4d", "title": "Large Language Models Struggle to Learn Long-Tail Knowledge"}, {"paperId": "c8d594f09413b1555970f43e68847c211235d60f", "title": "Prompting GPT-3 To Be Reliable"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "38115e80d805fb0fb8f090dc88ced4b24be07878", "title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis"}, {"paperId": "3def68bd0f856886d34272840a7f81588f2bc082", "title": "Survey of Hallucination in Natural Language Generation"}, {"paperId": "73401891d210bb6509f09e845589bca66ac57baa", "title": "QAFactEval: Improved QA-Based Factual Consistency Evaluation for Summarization"}, {"paperId": "fd1b829261ba04bb92e0ab60c4f6e7cea0d99fbf", "title": "Ethical and social risks of harm from Language Models"}, {"paperId": "ee1ef7b70dc34adcc90c42cc28168165ea56501f", "title": "SummaC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization"}, {"paperId": "238deab37e201c57505a4a47bb854e462af79bd7", "title": "Entity-Based Knowledge Conflicts in Question Answering"}, {"paperId": "a38e0f993e4805ba8a9beae4c275c91ffcec01df", "title": "Program Synthesis with Large Language Models"}, {"paperId": "4566c0d22ebf3c31180066ab23b6c445aeec78d5", "title": "Deduplicating Training Data Makes Language Models Better"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "725264948d7b6946259af5b8d966e996b9570f99", "title": "DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "dbeeca8466e0c177ec67c60d529899232415ca87", "title": "On Faithfulness and Factuality in Abstractive Summarization"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0", "title": "Natural Questions: A Benchmark for Question Answering Research"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "d9f6ada77448664b71128bb19df15765336974a6", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"}, {"paperId": "9770fff7379a7ab9006b48939462354dda9a2053", "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "dda6fb309f62e2557a071522354d8c2c897a2805", "title": "DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs"}, {"paperId": "305b2cf37e5dece81e95c92883d5a6e28ac93b22", "title": "Don\u2019t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"}, {"paperId": "39e734da43eb8c72e9549b42e96760545036f8e5", "title": "QuAC: Question Answering in Context"}, {"paperId": "4d1c856275744c0284312a3a50efb6ca9dc4cd4c", "title": "Know What You Don\u2019t Know: Unanswerable Questions for SQuAD"}, {"paperId": "d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a", "title": "The NarrativeQA Reading Comprehension Challenge"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "636a79420d838eabe4af7fb25d6437de45ab64e8", "title": "RACE: Large-scale ReAding Comprehension Dataset From Examinations"}, {"paperId": "668db48c6a79826456341680ee1175dfc4cced71", "title": "Get To The Point: Summarization with Pointer-Generator Networks"}, {"paperId": "d1505c6123c102e53eb19dff312cb25cea840b72", "title": "Teaching Machines to Read and Comprehend"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "318575adfb030622ba709d257b459afa108b8526", "title": "Worst-Case Performance Bounds for Simple One-Dimensional Packing Algorithms"}, {"paperId": "aa7e3b2b88ae3b434e3d5a343c7e3109c9d48ea8", "title": "Towards Mitigating LLM Hallucination via Self Reflection"}, {"paperId": "85cac89ba01a07f3dbf6dbb1e0c56067a3105714", "title": "CROSS-CONTAMINATION: ACCELERATING LARGE LANGUAGE MODELS WITHOUT IMPACTING PERFORMANCE"}, {"paperId": null, "title": "reasoning about physical commonsense in nat-ural language"}, {"paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28", "title": "An Adversarial Winograd Schema Challenge at Scale"}, {"paperId": null, "title": "Social IQa: Commonsense reasoning about social interactions"}, {"paperId": null, "title": "Combinatorial optimization: Theory and algorithms. Springer, Third Edition, 2005"}, {"paperId": "d25e8aa7e3e42708620797d3b2b27d1b4b230b67", "title": "The Loading Problem"}, {"paperId": null, "title": "A 176b-parameter open-access multilingual language"}, {"paperId": null, "title": "Fine-grained hallucinations detections"}, {"paperId": null, "title": "Mitigating hallucination in large language models through real-time"}, {"paperId": null, "title": "When less is more: Investigating data pruning for pretraining llms at scale"}]}