{"paperId": "0a6a6f8f1a76ce48ff52af27d4928eeed5d082a3", "abstract": "Neural networks equipped with self-attention have parallelizable computation, light-weight structure, and the ability to capture both long-range and local dependencies. Further, their expressive power and performance can be boosted by using a vector to measure pairwise dependency, but this requires to expand the alignment matrix to a tensor, which results in memory and computation bottlenecks. In this paper, we propose a novel attention mechanism called \u201cMulti-mask Tensorized Self-Attention\u201d (MTSA), which is as fast and as memory-efficient as a CNN, but significantly outperforms previous CNN-/RNN-/attention-based models. MTSA 1) captures both pairwise (token2token) and global (source2token) dependencies by a novel compatibility function composed of dot-product and additive attentions, 2) uses a tensor to represent the feature-wise alignment scores for better expressive power but only requires parallelizable matrix multiplications, and 3) combines multi-head with multi-dimensional attentions, and applies a distinct positional mask to each head (subspace), so the memory and computation can be distributed to multiple heads, each with sequential information encoded independently. The experiments show that a CNN/RNN-free model based on MTSA achieves state-of-the-art or competitive performance on nine NLP benchmarks with compelling memory- and time-efficiency.", "venue": "North American Chapter of the Association for Computational Linguistics", "year": 2018, "citationCount": 11, "influentialCitationCount": 1, "openAccessPdf": {"url": "https://arxiv.org/pdf/1805.00912", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "A novel attention mechanism called \u201cMulti-mask Tensorized Self-Attention\u201d (MTSA), which is as fast and as memory-efficient as a CNN, but significantly outperforms previous CNN-/RNN-/attention-based models."}, "embedding": {"model": "specter_v2", "vector": [-0.15594840049743652, 0.6114636063575745, -0.3941898047924042, -0.3442752957344055, -0.08352337777614594, -0.06581753492355347, 0.5564568638801575, -0.2264077067375183, -0.4976184368133545, -0.06425510346889496, 0.8808125853538513, 0.5657525658607483, 0.664585530757904, 0.11925552785396576, -0.08678198605775833, -0.049247417598962784, -0.9321059584617615, 0.13399972021579742, 0.0643962174654007, -0.3283345699310303, 0.11905555427074432, -0.7669029235839844, -0.9003295302391052, 0.056327659636735916, 0.4513331353664398, 0.3358798921108246, 0.5477612614631653, 0.8250519633293152, -0.6402618885040283, 0.3236450254917145, 0.22405973076820374, -0.6026692390441895, 0.15387295186519623, 0.012026364915072918, -0.3612833023071289, -0.46848028898239136, 0.5123722553253174, -0.5236724019050598, -0.27533087134361267, 1.1723631620407104, -0.15277829766273499, -0.0945749506354332, 0.3636615574359894, -0.5610117316246033, -0.5484031438827515, 1.161350131034851, 0.597107470035553, 0.8803594708442688, -0.42909345030784607, -0.8167589902877808, 1.7419555187225342, -1.5494858026504517, 0.34337013959884644, 1.3493916988372803, 0.04571657255291939, 0.4545638859272003, -0.06701976805925369, -0.6133391857147217, 0.6882103681564331, 0.4121706783771515, -0.8621633052825928, -0.4372970163822174, 0.11709374189376831, -0.26863810420036316, 1.9986129999160767, -0.29659613966941833, -0.3318079710006714, 0.3537115752696991, 0.19886651635169983, 1.3379096984863281, -0.12954920530319214, -0.7041124105453491, -0.5777854323387146, -0.1892029047012329, 0.5238789319992065, 0.8122504353523254, -0.27339786291122437, 0.20682165026664734, -0.9661792516708374, 0.20332051813602448, 0.6981496810913086, -0.2002832442522049, 0.14742276072502136, 0.1586611121892929, -0.6192185878753662, 0.39149028062820435, 0.5317707061767578, 1.2828298807144165, -0.3204226791858673, 0.8569035530090332, 0.5679678916931152, 0.10615019500255585, -0.04145583510398865, 0.09493998438119888, -0.13286763429641724, 0.46628937125205994, -0.8806139230728149, 0.3186136782169342, 0.14327889680862427, 1.0586415529251099, 0.46890726685523987, 0.23719406127929688, -0.5405759811401367, 0.05556720867753029, 1.3744558095932007, 0.041229650378227234, 0.6939335465431213, -0.34354010224342346, 0.22781655192375183, -0.5947775840759277, -0.05310167744755745, -1.1722673177719116, -0.41741979122161865, -0.411449670791626, -0.9261095523834229, -1.2675840854644775, -0.5779922008514404, 0.22700347006320953, -0.4872692823410034, 0.970914900302887, -0.13117606937885284, -0.24980157613754272, -0.07054895907640457, 0.6107621788978577, 0.8559303879737854, 0.2584233283996582, 0.19278480112552643, 0.21991927921772003, 1.2205824851989746, -1.298337459564209, -1.151726245880127, -0.9057078957557678, 0.6497262120246887, -0.24915504455566406, -0.4107971489429474, -0.829153299331665, -1.1029289960861206, -0.9715994000434875, -0.6751857995986938, -0.2222612351179123, -0.4066230058670044, 0.2640887498855591, 0.6977380514144897, -0.1347218006849289, -1.005128026008606, 1.0959690809249878, -0.24867218732833862, -0.1888880580663681, 0.25147244334220886, 0.2859727740287781, -0.0661945790052414, 0.07499708980321884, -1.427059531211853, 0.4575102627277374, 0.3713267743587494, -0.0730508342385292, 0.06009827181696892, -0.46661344170570374, -1.196952223777771, -0.08539540320634842, 0.2349802851676941, -0.5556999444961548, 1.2348273992538452, -0.20061813294887543, -1.133426547050476, 0.7671459913253784, -0.7050121426582336, 0.3074321746826172, -0.020809277892112732, -0.31104186177253723, -0.7760483622550964, -0.5751070380210876, 0.5914011001586914, 0.6843867897987366, 0.5471894145011902, -0.21693971753120422, -0.2998234033584595, -0.3561246693134308, -0.544748067855835, 0.04421522468328476, -0.3360256850719452, 1.2899188995361328, -0.5660713911056519, -0.4257282316684723, 0.2894352376461029, 0.8396810293197632, 0.2983412742614746, -0.7481092214584351, -0.8390080332756042, -1.3586218357086182, 0.8344211578369141, 0.24074991047382355, 0.7534658312797546, -0.9639790058135986, -0.5390997529029846, -0.5060708522796631, 0.11853156238794327, -0.07480102777481079, -0.7654867172241211, 0.5962036848068237, -0.6585284471511841, 0.5741065144538879, -0.07065100967884064, -0.9892283082008362, -0.1118578091263771, -0.024094242602586746, -0.3898831903934479, -0.4183419942855835, 0.37840980291366577, 1.2735811471939087, -0.9931691884994507, -0.4969976842403412, -0.4548438787460327, 0.026303978636860847, -0.6457387208938599, 1.4521996974945068, -0.21647588908672333, 0.28981813788414, 0.021570490673184395, -0.2905556559562683, 0.1532239019870758, -0.16367217898368835, 0.23595228791236877, -0.8836374878883362, -0.5089228749275208, 0.640826940536499, -0.3874146640300751, 1.1441771984100342, 0.04421432316303253, 0.5460042357444763, 0.17873990535736084, -0.40649086236953735, 0.03650503605604172, 0.3458506166934967, -0.02101934514939785, -0.5357144474983215, 0.2772420048713684, 0.16071301698684692, -0.343341201543808, -0.07570111751556396, 0.8183624744415283, 0.9208254814147949, -0.15206928551197052, 0.16501492261886597, 0.8078820705413818, -0.053107038140296936, 0.5794437527656555, 0.3407995104789734, 0.5921879410743713, 0.47603684663772583, 0.4993422329425812, -0.3668830096721649, 0.2717050611972809, -0.6813215017318726, 0.1411990225315094, 0.07333245128393173, 0.4306473731994629, 0.614568829536438, 0.3863583207130432, -0.5534670948982239, -0.26803985238075256, 0.5704494118690491, 0.5850954055786133, 1.6712044477462769, -0.24769452214241028, -0.10030318796634674, -0.7999721765518188, -0.5483617186546326, -0.21539214253425598, -0.06228954344987869, -0.4339646100997925, 0.1786760836839676, -0.6982840895652771, -0.9840535521507263, 0.7335774898529053, 0.6225718259811401, 1.1457273960113525, -0.6862783432006836, -0.16852182149887085, -0.024187859147787094, 0.13546887040138245, -1.16610848903656, -0.9090747833251953, 0.4293742775917053, -0.18930599093437195, -0.03739862143993378, 0.06678290665149689, -0.2592169940471649, 0.17189505696296692, -0.5886255502700806, 0.90857994556427, -0.781206488609314, -0.24656951427459717, 0.17089736461639404, 0.5337114334106445, -0.8718898892402649, -0.287770539522171, 0.21750237047672272, 0.42168232798576355, 0.05098521336913109, 0.46352508664131165, 0.5196026563644409, -0.23653054237365723, 0.22353574633598328, -0.42529886960983276, -0.004087825305759907, 0.22674520313739777, 0.07653246074914932, 0.6377852559089661, -0.100295789539814, 0.12594889104366302, -1.1946654319763184, 0.5538025498390198, 0.1201525628566742, -0.17827865481376648, -0.27413666248321533, -0.4335203468799591, -0.4124508798122406, 0.1536567211151123, -0.42438873648643494, -0.4898032546043396, -0.8677223920822144, 0.5854616761207581, -0.14607349038124084, -0.4184366464614868, 0.21841605007648468, 0.03442418575286865, -0.018716955557465553, 0.17064498364925385, 0.25147464871406555, 0.4310503304004669, 0.07760594040155411, 0.8495808243751526, -0.9014936089515686, 0.8531254529953003, 0.39646419882774353, 0.35160714387893677, 0.011837555095553398, -0.17727439105510712, -0.8025639057159424, -0.5547384023666382, -0.6819789409637451, -0.5399213433265686, -0.007146099582314491, 0.7082175016403198, -0.530669629573822, -1.0239448547363281, 0.06377764791250229, -1.4886510372161865, 0.03875992074608803, 0.11562696099281311, -0.20106415450572968, 0.17543363571166992, -0.773640513420105, -1.1511592864990234, -0.5749120712280273, -0.8149828910827637, -0.44793373346328735, 0.20344480872154236, 0.19525836408138275, -0.3189559876918793, -0.527483344078064, -0.16513249278068542, -0.5449227094650269, 1.2782474756240845, -0.7637931704521179, 0.49353817105293274, -0.13811072707176208, -0.1363164186477661, -0.24524953961372375, -0.438626229763031, 0.7590194344520569, 0.13670900464057922, 0.20144431293010712, -0.6600073575973511, 0.6760045289993286, -0.09779089689254761, 0.10685544461011887, 0.3808957040309906, 0.2795194685459137, 0.5094954371452332, -0.11449050903320312, -0.6553966999053955, 0.06031319499015808, 1.2502738237380981, -0.8774442076683044, -0.06445183604955673, -0.010127266868948936, 1.3929184675216675, 0.7505520582199097, -0.5542376637458801, 0.21719922125339508, 1.0757966041564941, 0.3743540048599243, 0.6376226544380188, -0.29264676570892334, -0.27632907032966614, -0.20331406593322754, 0.3726426064968109, 1.8571330308914185, -0.1336173415184021, 0.4419698715209961, -0.7726916670799255, 0.978356122970581, -1.394805669784546, -0.805651843547821, 0.29591232538223267, 0.41566622257232666, 0.28600814938545227, -0.7639012336730957, -0.2528727650642395, -0.5736904740333557, 0.7489058375358582, 0.2115536481142044, -0.5922861695289612, -0.40713176131248474, -0.255792498588562, 0.10208102315664291, 0.4089193046092987, 0.34504184126853943, -0.4346340298652649, 0.9799880981445312, 14.70889663696289, 0.20682944357395172, 0.05411284416913986, 0.7132368683815002, 0.5223509073257446, 0.548056960105896, -0.28370532393455505, -0.0174566600471735, -1.5132731199264526, -0.0969836637377739, 0.6973380446434021, 0.16060616075992584, 0.10114555805921555, 0.10273786634206772, -0.026552023366093636, 0.3217404782772064, -0.5202623009681702, 0.5261856317520142, 0.6911320090293884, -0.9443635940551758, 0.11105676740407944, 0.19714537262916565, 0.024402977898716927, 0.9262685775756836, 0.37896716594696045, 0.5253411531448364, 0.5919973254203796, -0.11899401247501373, 0.160216823220253, 0.4190766215324402, 0.9080755114555359, 0.4179154932498932, 0.48147305846214294, 0.21639201045036316, -0.7332744002342224, -0.2420617938041687, -0.5887879133224487, -1.2345908880233765, 0.17964957654476166, 0.5252256989479065, -0.1695898473262787, -0.25043821334838867, 0.19372756779193878, 0.7371527552604675, 0.34653007984161377, 0.04686940833926201, -0.3232649266719818, 0.3954268991947174, 0.224212646484375, -0.1763485074043274, 0.06795062124729156, 0.6233986020088196, 0.3883328139781952, 0.6044545769691467, -0.08759143948554993, 0.1541440784931183, -0.20441342890262604, 0.8896365761756897, -0.4449697434902191, 0.0803101658821106, -0.07014206796884537, -0.3052074909210205, -0.40989962220191956, 1.3512240648269653, 0.9299541711807251, 0.29995983839035034, -0.3939014673233032, 0.5689941644668579, 0.7263370156288147, 0.02960927039384842, -0.11065541952848434, -0.2010756880044937, 0.46057772636413574, -0.34402531385421753, 0.06749246269464493, 0.1095336377620697, -0.07373800128698349, -0.47933775186538696, -0.8311377763748169, 0.21347640454769135, 0.11831623315811157, -0.7619220614433289, -1.1527742147445679, 1.1613036394119263, -0.40116292238235474, -0.29304054379463196, 0.05925029143691063, -1.003239631652832, -0.5153055191040039, 0.5740973353385925, -1.5315097570419312, -0.7176518440246582, 0.14521066844463348, -0.2605569362640381, -0.7711930274963379, 0.1781468540430069, 1.2632477283477783, 0.2161737084388733, -0.5223463177680969, -0.02175804227590561, -0.45162129402160645, 0.4397789537906647, 0.20266637206077576, -0.9534140229225159, 0.7880902290344238, -0.04041186720132828, -0.33473336696624756, 0.13966983556747437, -0.0317981131374836, 0.062214117497205734, -0.7926365733146667, -0.13987697660923004, 1.1375378370285034, -0.7693012952804565, -0.1789150983095169, -0.2533761262893677, -0.8576021194458008, 0.14139918982982635, 0.9469809532165527, 0.21936693787574768, 0.6043503284454346, 0.1827302873134613, -0.8072172403335571, -0.14038987457752228, -0.6042393445968628, 0.14303937554359436, 0.5343729853630066, -0.5565292835235596, -0.3214647173881531, 0.03765812888741493, 0.4989003539085388, -1.1711761951446533, -0.4482065439224243, -0.24513734877109528, -0.08935515582561493, -0.15213926136493683, 0.6865475177764893, -0.3615274429321289, 0.6856419444084167, 0.6861644387245178, -0.16360902786254883, -0.7721489667892456, -0.39597395062446594, -0.9545809626579285, -0.07973609119653702, 0.5897660255432129, 0.6418615579605103, -0.41231223940849304, 0.017119277268648148, 1.1539441347122192, 0.07141294330358505, -0.35003650188446045, -0.6961489915847778, -0.36367690563201904, -0.18146318197250366, -0.3560280203819275, 0.3236011564731598, 0.43556588888168335, 0.2880673408508301, 0.28211021423339844, 0.4984634518623352, 0.56336909532547, 0.2073802500963211, -0.6785203814506531, 0.262099951505661, -0.08103208243846893, 0.2597616910934448, -0.8308707475662231, -0.6988046765327454, -1.1758193969726562, 0.18318498134613037, -1.2378267049789429, -0.06127096712589264, -1.1402534246444702, -0.25332215428352356, 0.3009190559387207, -0.35977473855018616, 0.38764458894729614, 0.02476254478096962, -0.23815494775772095, -0.5706280469894409, -0.17964859306812286, -0.43921178579330444, 0.657406747341156, 1.1256253719329834, -0.6297872066497803, 0.08787279576063156, -0.39701467752456665, -0.4320644736289978, 0.2679627239704132, 0.480819433927536, -0.3414124846458435, 0.22317899763584137, -1.5487148761749268, 0.4232420325279236, -0.16965557634830475, 0.10215795040130615, -0.6063224077224731, 1.0943878889083862, 0.5872569680213928, -0.26110532879829407, -0.22288134694099426, -0.03351703658699989, -0.7570522427558899, -0.9875580072402954, 0.16245870292186737, -0.4685377776622772, 0.31478339433670044, 0.14905518293380737, -0.407830148935318, -0.6306670904159546, 0.843188464641571, -0.40146827697753906, -1.204040765762329, -0.6164138317108154, 0.5304113626480103, -0.431632399559021, 0.021374836564064026, -0.25878703594207764, 0.02509688213467598, -1.1694986820220947, -0.3142588436603546, 0.09450458735227585, 0.5042105913162231, -0.8645127415657043, 0.7931278944015503, 0.12013401836156845, -1.3115277290344238, -0.24367091059684753, 0.4411871135234833, -0.09200316667556763, 0.2634522020816803, 0.8235923647880554, 0.4074735939502716, 0.16708752512931824, 0.6595684289932251, 0.29905009269714355, 0.2550755739212036, -0.7032862305641174, 0.11600552499294281, 0.6535437703132629, -0.23597532510757446, -0.019263645634055138, 1.0701104402542114, -0.25226113200187683, -1.1878976821899414, -0.2268734574317932, -1.0467019081115723, -0.8223093152046204, 0.1146678477525711, 0.547116219997406, 0.22977392375469208, -0.19299963116645813, -0.8537617325782776, -0.6736506819725037, 0.3125187158584595, -0.48790064454078674, -0.6291956901550293, 0.253492146730423, -0.14704309403896332, -1.0649020671844482, 0.24435663223266602, 0.8897485136985779, -0.5578112602233887, -0.39977699518203735, -1.0348964929580688, -0.2955882251262665, 0.27755773067474365, 0.488800972700119, -0.20690208673477173, -0.6459899544715881, 0.7080796957015991, 0.2512148320674896, 0.5704021453857422, -0.13816624879837036, -0.005447234958410263, 0.31299251317977905, 0.4108821153640747, -0.34237349033355713, -0.6073596477508545, -0.5314316153526306, 1.5134611129760742, 1.6166833639144897, -0.8414592146873474, -0.20956318080425262, -0.4948093891143799, -0.8170817494392395, 0.9128584265708923, 0.5774554014205933, -0.049104075878858566, 1.0880967378616333, -0.021297838538885117, 0.2988906800746918, 0.1183711513876915, -0.785396933555603, -0.7014245390892029, 0.7978704571723938, 0.9791658520698547, 0.8910030126571655, 0.3957488238811493, -0.11057266592979431, 0.8073747754096985, 0.118229940533638, -0.17990949749946594, 0.28729701042175293, 0.06467987596988678, -0.05517745018005371, -0.18740679323673248, 0.0788092240691185, 0.4875586926937103, -0.801132082939148, -0.6513060331344604, 0.05097765848040581, 0.2913394868373871, 0.2106199413537979, 0.6716899275779724, 0.9236543774604797, -0.17042507231235504, 0.44164666533470154, 0.07871778309345245, 0.25396448373794556, -0.6831177473068237, -0.09202133119106293, -0.11264008283615112, -0.6829102635383606, -0.293897807598114, -0.6240950226783752, -0.5694627165794373, -0.883321225643158, 0.161362424492836, -0.17285674810409546, -0.2102838009595871, 1.0363004207611084, 1.26619291305542, 0.9119978547096252, 0.7604856491088867, -0.09451891481876373, -0.5730502009391785, -0.29479628801345825, -1.2907800674438477, 0.13181394338607788, -0.5788146257400513, -0.26676416397094727, -0.05012166127562523, -0.2697717845439911, -0.5646814107894897]}, "authors": [{"authorId": "143681703", "name": "Tao Shen"}, {"authorId": "1805655", "name": "Tianyi Zhou"}, {"authorId": "2062835", "name": "Guodong Long"}, {"authorId": "1746594", "name": "Jing Jiang"}, {"authorId": "48934799", "name": "Chengqi Zhang"}], "references": [{"paperId": "3c914230ca499edb9104a9a38fa74a01d37b6926", "title": "Interactive Attention Transfer Network for Cross-Domain Sentiment Classification"}, {"paperId": "5f38a07add820c82a2b13a17d891f08cdcaef500", "title": "Enhancing Sentence Embedding with Generalized Pooling"}, {"paperId": "7442a18a55f257a68f21d0cbb8b1395f8915a452", "title": "Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling"}, {"paperId": "060ff1aad5619a7d6d6cdfaf8be5da29bff3808c", "title": "Linguistically-Informed Self-Attention for Semantic Role Labeling"}, {"paperId": "0ef460c47377c3b9482d8177cbcafad1730a91a5", "title": "Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling"}, {"paperId": "8c1b00128e74f1cd92aede3959690615695d5101", "title": "QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension"}, {"paperId": "5d727286a59d7e2681b6fac5fa269e782849f007", "title": "Reinforced Self-Attention Network: a Hybrid of Hard and Soft Attention for Sequence Modeling"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "d12ae90771d14555a64aa48b8a3f638e7d14426d", "title": "Distance-based Self-Attention Network for Natural Language Inference"}, {"paperId": "6ed376a26045ff0048ec2b216785d396960d6ed1", "title": "Deep Semantic Role Labeling with Self-Attention"}, {"paperId": "33998aff64ce51df8dee45989cdca4b6b1329ec4", "title": "Graph Attention Networks"}, {"paperId": "adc276e6eae7051a027a4c269fb21dae43cadfed", "title": "DiSAN: Directional Self-Attention Network for RNN/CNN-free Language Understanding"}, {"paperId": "ad45b1291067120bf9e55ac7424eb627e0aab149", "title": "Training RNNs as Fast as CNNs"}, {"paperId": "26fe009b958e8728382d9d764bd7153632f0b869", "title": "Shortcut-Stacked Sentence Encoders for Multi-Domain Inference"}, {"paperId": "ceb7dddbd0c51f511c4ba97d328b48fd10d2a7fc", "title": "Recurrent Neural Network-Based Sentence Encoder with Gated Attention for Natural Language Inference"}, {"paperId": "027f9695189355d18ec6be8e48f3d23ea25db35d", "title": "Learning to Compose Task-Specific Tree Structures"}, {"paperId": "a4dd3beea286a20c4e4f66436875932d597190bc", "title": "Deep Semantic Role Labeling: What Works and What\u2019s Next"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "42d2338a8c2e44154e10ff4d68a3c389aeca3913", "title": "Reinforced Mnemonic Reader for Machine Comprehension"}, {"paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0", "title": "Convolutional Sequence to Sequence Learning"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "4550a4c714920ef57d19878e31c9ebae37b049b2", "title": "Massive Exploration of Neural Machine Translation Architectures"}, {"paperId": "204a4a70428f3938d2c538a4d74c7ae0416306d8", "title": "A Structured Self-attentive Sentence Embedding"}, {"paperId": "13d9323a8716131911bfda048a40e2cde1a76a46", "title": "Structured Attention Networks"}, {"paperId": "88caa4a0253a8b0076176745ebc072864eab66e1", "title": "Language Modeling with Gated Convolutional Networks"}, {"paperId": "3a7b63b50c64f4ec3358477790e84cbd6be2a0b4", "title": "Bidirectional Attention Flow for Machine Comprehension"}, {"paperId": "f93a0a3e8a3e6001b4482430254595cf737697fa", "title": "Learning Natural Language Inference using Bidirectional LSTM model and Inner-Attention"}, {"paperId": "36c097a225a95735271960e2b63a2cb9e98bff83", "title": "A Fast Unified Model for Parsing and Sentence Understanding"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "f63e917638553414526a0cc8550de4ad2d83fe7a", "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)"}, {"paperId": "f04df4e20a18358ea2f689b4c129781628ef7fc1", "title": "A large annotated corpus for learning natural language inference"}, {"paperId": "93499a7c7f699b6630a86fad964536f9423bb6d0", "title": "Effective Approaches to Attention-based Neural Machine Translation"}, {"paperId": "c34e41312b47f60986458759d5cc546c2b53f748", "title": "End-to-end learning of semantic role labeling using recurrent neural networks"}, {"paperId": "6e795c6e9916174ae12349f5dc3f516570c17ce8", "title": "Skip-Thought Vectors"}, {"paperId": "af9b9235a68307c782d14d4bf12cb80d662d247f", "title": "Efficient Inference and Structured Learning for Semantic Role Labeling"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "ac3ee98020251797c2b401e1389461df88e52e62", "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling"}, {"paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5", "title": "GloVe: Global Vectors for Word Representation"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba", "title": "Convolutional Neural Networks for Sentence Classification"}, {"paperId": "27725a2d2a8cee9bf9fffc6c2167017103aba0fa", "title": "A Convolutional Neural Network for Modelling Sentences"}, {"paperId": "1149888d75af4ed5dffc25731b875651c3ccdeb2", "title": "Hybrid speech recognition with Deep Bidirectional LSTM"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "f6b51c8753a871dc94ff32152c00c01e94f90f09", "title": "Efficient Estimation of Word Representations in Vector Space"}, {"paperId": "8729441d734782c3ed532a7d2d9611b438c0a09a", "title": "ADADELTA: An Adaptive Learning Rate Method"}, {"paperId": "67107f78a84bdb2411053cb54e94fa226eea6d8e", "title": "Deep Sparse Rectifier Neural Networks"}, {"paperId": "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649", "title": "Understanding the difficulty of training deep feedforward neural networks"}, {"paperId": "cdcf7cb29f37ac0546961ea8a076075b9cc1f992", "title": "Mining and summarizing customer reviews"}, {"paperId": "167e1359943b96b9e92ee73db1df69a1f65d731d", "title": "A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts"}, {"paperId": "2c8ac3e1f0edeed1fbd76813e61efdc384c319c7", "title": "Learning Question Classifiers"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "2018) facilitated the passage summarization problem to a language model problem, and used the decoder from Transformer to solve this problem"}, {"paperId": null, "title": "2017), and similar to softmax with temperature, log(sigmoid(\u00b7)"}, {"paperId": null, "title": "2017) integrated the self aligning layer with general querycontext mutual-attention framework (i.e., BiDAF (Seo et al., 2017)) to model long-term dependency for machine comprehension"}, {"paperId": "8fd61ae673e79de6723f800e06b38b2bda1dc3db", "title": "Convolutional Sequence to Sequence Learning"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": null, "title": "2017), the dropout (Srivastava et al., 2014) with the keep probability of pad can be applied to both the token2token and the source2token attention probabilities in MTSA"}, {"paperId": "1cff7cc15555c38607016aaba24059e76b160adb", "title": "Annotating Expressions of Opinions and Emotions in Language"}]}