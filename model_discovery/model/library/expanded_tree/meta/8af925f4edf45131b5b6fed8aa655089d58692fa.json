{"paperId": "8af925f4edf45131b5b6fed8aa655089d58692fa", "abstract": "Transformer has become ubiquitous in natural language processing (e.g., machine translation, question answering); however, it requires enormous amount of computations to achieve high performance, which makes it not suitable for mobile applications since mobile phones are tightly constrained by the hardware resources and battery. In this paper, we investigate the mobile setting (under 500M Mult-Adds) for NLP tasks to facilitate the deployment on the edge devices. We present Long-Short Range Attention (LSRA), where one group of heads specializes in the local context modeling (by convolution) while another group captures the long-distance relationship (by attention). Based on this primitive, we design Lite Transformer that is tailored for the mobile NLP application. Our Lite Transformer demonstrates consistent improvement over the transformer on three well-established language tasks: machine translation, abstractive summarization, and language modeling. It outperforms the transformer on WMT\u201914 English-French by 1.2 BLEU under 500M Mult-Adds and 1.7 BLEU under 100M Mult-Adds, and reduces the computation of transformer base model by 2.5x. Further, with general techniques, our Lite Transformer achieves 18.2x model size compression. For language modeling, our Lite Transformer also achieves 3.8 lower perplexity than the transformer around 500M Mult-Adds. Without the costly architecture search that requires more than 250 GPU years, our Lite Transformer outperforms the AutoML-based Evolved Transformer by 0.5 higher BLEU under the mobile setting.", "venue": "International Conference on Learning Representations", "year": 2020, "citationCount": 255, "influentialCitationCount": 24, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper investigates the mobile setting for NLP tasks to facilitate the deployment on the edge devices and designs Lite Transformer, which demonstrates consistent improvement over the transformer on three well-established language tasks: machine translation, abstractive summarization, and language modeling."}, "embedding": {"model": "specter_v2", "vector": [0.3783735930919647, 0.2108526974916458, -0.3427058458328247, -0.2444380670785904, -0.8233931660652161, -0.3273516297340393, 0.6016491651535034, -0.1821199506521225, -0.5016531348228455, -0.051660679280757904, 0.9260743260383606, -0.21768496930599213, 0.03478745371103287, 0.0672629252076149, -0.2524743974208832, 0.5128523111343384, -0.3967553377151489, 0.5073946714401245, -0.21490150690078735, -0.4290456175804138, 0.048742324113845825, -0.5099467039108276, -0.5290113091468811, 0.3893035650253296, 0.9160867929458618, 0.3006606101989746, 0.5201606750488281, 1.0185267925262451, -0.6790938377380371, 0.48544296622276306, 0.35879555344581604, -0.24399222433567047, 0.01904699206352234, -0.08566886186599731, -0.1675528883934021, -0.378552109003067, 0.5061057806015015, -0.40237724781036377, -0.13851118087768555, 0.7856163382530212, 0.05572227016091347, 0.0020479406230151653, 0.22701086103916168, -0.4193544089794159, -0.39794692397117615, 0.9588706493377686, 0.46627387404441833, 0.7797170281410217, 0.051721345633268356, -0.6476044058799744, 1.2972431182861328, -1.5208747386932373, 0.058816198259592056, 1.3969557285308838, 0.6388139128684998, 0.24039873480796814, 0.1544930785894394, -0.2625868618488312, 0.5682031512260437, 0.14141102135181427, -0.579975426197052, -0.7737042307853699, -0.22031906247138977, 0.3246597647666931, 1.7919642925262451, -0.05987095087766647, -0.1895185261964798, 0.2093418687582016, 0.0691789984703064, 1.223421335220337, -0.08349591493606567, -0.6486389636993408, -0.1902046948671341, -0.34828391671180725, 0.5312567949295044, 0.8016145825386047, -0.35311776399612427, -0.2629086375236511, -0.6531203389167786, -0.1969147026538849, 0.2588879466056824, 0.11352407187223434, -0.13496075570583344, 0.19968917965888977, -0.5201319456100464, 0.49350839853286743, 0.5134449005126953, 0.7100775241851807, -0.3873903751373291, 0.6374539136886597, 0.5503732562065125, 0.44473299384117126, 0.25809648633003235, 0.40127044916152954, -0.5223203897476196, 0.48984086513519287, -1.1528042554855347, 0.1535586714744568, 0.03187532350420952, 0.9396289587020874, -0.2502579689025879, -0.0726473480463028, -0.9709361791610718, 0.26580679416656494, 1.0184894800186157, 0.4497562050819397, 0.198964923620224, -0.8180360794067383, 0.2647632658481598, -0.6304786205291748, 0.16294041275978088, -0.5491252541542053, -0.24409295618534088, -0.3229758143424988, -0.8316779136657715, -1.2349580526351929, -0.20066452026367188, -0.03264323249459267, -0.5074644088745117, 0.5099747776985168, -0.5603119730949402, 0.3294455111026764, 0.24099940061569214, 0.30372220277786255, 0.6281846761703491, 0.8516765236854553, -0.17210187017917633, -0.4027648866176605, 1.1950987577438354, -1.2381761074066162, -0.897472620010376, -1.3582077026367188, 0.8550194501876831, -0.5402463674545288, 0.6023620367050171, -0.37159961462020874, -1.2895514965057373, -0.5814257264137268, -0.61199551820755, -0.29967933893203735, -0.6013544797897339, 0.3590629994869232, 0.8310388326644897, 0.13169293105602264, -1.2023690938949585, 0.5082522034645081, -0.1494988352060318, -0.5562530755996704, 0.4907686412334442, 0.18558914959430695, 0.2875034511089325, -0.5775850415229797, -1.141666054725647, 0.32070544362068176, -0.26232871413230896, -0.46047648787498474, 0.21157629787921906, -0.6545200347900391, -0.944176197052002, 0.25464943051338196, 0.5496377348899841, -0.816235363483429, 1.2003217935562134, 0.1891368180513382, -1.3468513488769531, 0.1686573326587677, -0.63782799243927, -0.21870693564414978, 0.021649988368153572, -0.6485529541969299, -0.22435465455055237, -0.43795064091682434, 0.08488906174898148, 0.2670515179634094, 0.38574668765068054, 0.35734182596206665, -0.26422786712646484, 0.09858300536870956, -0.22396469116210938, -0.0667266994714737, -0.1538669317960739, 1.304369330406189, -0.467915803194046, -0.12224432080984116, 0.27262941002845764, 0.7538782954216003, -0.013273872435092926, -0.23456746339797974, -0.20620915293693542, -0.8442946076393127, 1.0714462995529175, -0.00019881247135344893, 1.1466152667999268, -0.6921504735946655, -0.7792934775352478, -0.5107073187828064, -0.12660007178783417, 0.038451187312603, -0.9414107799530029, 0.3238903284072876, -0.27956005930900574, 0.22828291356563568, -0.057163335382938385, -0.6716139316558838, 0.03813287615776062, -0.367247074842453, -0.971784234046936, -0.04831695929169655, 0.06707882136106491, 1.4705843925476074, -0.8224416971206665, 0.10307546705007553, -0.02501387521624565, 0.18203607201576233, -1.1059733629226685, 0.9469040632247925, -0.622002124786377, 0.10577187687158585, -0.3205909729003906, -0.03001846931874752, 0.259038507938385, -0.4581244885921478, 0.13054393231868744, -0.5590487122535706, -0.16909413039684296, 0.5949512124061584, -0.16998323798179626, 1.5324143171310425, -0.3316425681114197, 0.6392877101898193, 0.2438942939043045, -0.7023409008979797, 0.13451382517814636, 0.15828919410705566, -0.34012603759765625, -0.43908265233039856, 0.4508613049983978, 0.612005889415741, -0.6609169840812683, 0.31092897057533264, 0.6826770305633545, 1.0999722480773926, -0.5843029022216797, 0.2908397912979126, 0.3937958776950836, -0.11562494933605194, 0.3245967924594879, 0.442147821187973, 0.8810753226280212, 0.40093520283699036, 0.5364809036254883, -0.359260618686676, 0.5222637057304382, -0.6528600454330444, -0.10127182304859161, 0.6500543355941772, 0.590762197971344, 0.8578217625617981, 0.23234246671199799, -0.6678860187530518, -0.17143528163433075, 0.16271814703941345, 0.8725585341453552, 1.6133949756622314, -0.31793785095214844, -0.40396231412887573, -1.0211883783340454, -0.430626779794693, -1.0145338773727417, 0.0960921049118042, 0.1713893562555313, 0.17556068301200867, -0.8535747528076172, -1.0325572490692139, 0.871260404586792, 0.37751778960227966, 1.1320291757583618, -0.32561564445495605, -0.23627160489559174, -0.33909308910369873, -0.2131205052137375, -1.0386475324630737, -1.0000770092010498, 0.05178648233413696, -0.5122359991073608, -0.04638646915555, -0.04685095325112343, -0.16063973307609558, -0.019578060135245323, -0.5322153568267822, 0.9177543520927429, -0.6991723775863647, 0.00412817532196641, 0.20918519794940948, 0.499803751707077, -0.4833480715751648, -0.30732494592666626, 0.3730720579624176, 0.06073829531669617, -0.27172231674194336, 0.5482944846153259, 0.3271991014480591, 0.17821291089057922, 0.15339334309101105, 0.043235138058662415, -0.11438412964344025, 0.13071461021900177, -0.13988317549228668, 0.8233964443206787, -0.48925015330314636, 0.02112978883087635, -1.0149168968200684, 1.0284149646759033, 0.4218828082084656, -0.469098299741745, 0.42951926589012146, -0.39343276619911194, -0.4376699924468994, 0.6291205883026123, -0.6004570722579956, -0.05080138146877289, -1.098707914352417, 0.23494257032871246, -0.1395997703075409, -0.07454506307840347, 0.32225120067596436, -0.19203750789165497, 0.5367465019226074, 0.06994950771331787, 0.41993722319602966, 0.20391467213630676, -0.3164290189743042, 0.8127964735031128, -0.4981536567211151, 0.6697401404380798, 0.5085921883583069, -0.0933263972401619, -0.22989697754383087, -0.10093123465776443, -0.7599810361862183, -0.485173761844635, -0.17292344570159912, -0.10135022550821304, 0.16911576688289642, 0.15316039323806763, -0.5130788087844849, -0.6893985271453857, -0.28006529808044434, -1.3634562492370605, 0.10814042389392853, 0.017950262874364853, -0.16853179037570953, -0.28706490993499756, -1.2848646640777588, -1.2829816341400146, -0.2656845450401306, -0.9284995794296265, -0.9657788872718811, 0.5836400389671326, -0.026013465598225594, -0.3480947017669678, -0.30460959672927856, -0.41022220253944397, -0.4729149043560028, 1.206156849861145, -0.6521318554878235, 0.8807055950164795, -0.24652226269245148, -0.4134967625141144, -0.19261658191680908, -0.12824346125125885, 0.06814649701118469, -0.2503068447113037, -0.05911707505583763, -0.481975793838501, 0.4162929356098175, 0.054597899317741394, 0.15935446321964264, 0.3756334185600281, 0.8807510137557983, 0.2576386630535126, 0.11045820266008377, -0.6244645118713379, 0.39980947971343994, 1.108978509902954, -0.8664069771766663, 0.2894480228424072, 0.0942520722746849, 1.1369980573654175, 0.08884548395872116, -0.03975158929824829, 0.08299079537391663, 0.23867346346378326, 0.12694452702999115, 0.024436401203274727, -0.05012110248208046, -0.23947888612747192, -0.39981895685195923, 0.7608428597450256, 1.7205703258514404, 0.3305317461490631, -0.41726237535476685, -0.7667392492294312, 0.2750205993652344, -1.5332049131393433, -0.612406849861145, 0.43232089281082153, 0.4756582975387573, -0.13775573670864105, -0.5422351360321045, -0.6127967238426208, -0.3540308177471161, 0.7157679200172424, 0.5577647686004639, -0.17641422152519226, -0.776425838470459, -0.2316512167453766, 0.2534237205982208, 0.2303159385919571, 1.0331089496612549, -0.06562260538339615, 1.0125821828842163, 14.92330551147461, 1.1351248025894165, -0.045059334486722946, 0.6399102210998535, 0.4260195195674896, 0.2281968742609024, -0.21826404333114624, -0.0708686038851738, -1.1445109844207764, -0.28535404801368713, 1.2848565578460693, -0.11063914000988007, 0.5867674350738525, -0.15635153651237488, 0.3592400550842285, 0.19799436628818512, -0.5464097857475281, 0.7472662329673767, 0.5451249480247498, -1.4933027029037476, 0.5597111582756042, 0.39983221888542175, 0.11600102484226227, 0.7526676058769226, 0.7630915641784668, 0.5998060703277588, 0.21894003450870514, -0.46656838059425354, 0.15491770207881927, 0.47656139731407166, 1.107531189918518, -0.2402343899011612, 0.5769963264465332, 0.6742739081382751, -0.7764816284179688, -0.37267300486564636, -0.7627341151237488, -1.4735298156738281, 0.29844099283218384, 0.3491935431957245, -0.11431443691253662, -0.46822604537010193, -0.36423739790916443, 0.9844085574150085, 0.18576419353485107, 0.19620859622955322, -0.185844287276268, 0.49702852964401245, -0.4127143919467926, -0.015293840318918228, 0.23625880479812622, 0.20301832258701324, 0.6246863007545471, -0.19088849425315857, 0.42825353145599365, 0.02450464852154255, 0.13851332664489746, 0.40958043932914734, -0.7805364727973938, -0.008256622590124607, -0.37928444147109985, -0.17746849358081818, -0.052829716354608536, 0.5277203917503357, 0.23234079778194427, 0.1215331107378006, -0.42081430554389954, 0.4980836808681488, 0.4202878475189209, 0.06345481425523758, -0.380644291639328, -0.14006733894348145, 0.18414393067359924, -0.06761232763528824, 0.04815298318862915, 0.5928856134414673, -0.3220888674259186, -0.6893215179443359, -0.5897542238235474, -0.3774898052215576, 0.26662471890449524, -0.8802730441093445, -0.4219338297843933, 1.1346431970596313, -0.3089474141597748, -0.25024154782295227, 0.35869988799095154, -0.488694965839386, -0.4461006820201874, 0.26330018043518066, -1.3065102100372314, -0.9050227999687195, 0.5271431803703308, -0.33457157015800476, 0.029176300391554832, -0.05219653248786926, 1.381237506866455, 0.29010656476020813, -0.18548178672790527, -0.16402265429496765, 0.16825152933597565, -0.16220106184482574, -0.20590366423130035, -0.629027247428894, 0.891950249671936, 0.6393031477928162, -0.04643919691443443, 0.17629605531692505, 0.11567215621471405, 0.4080725312232971, -0.9150890707969666, -0.1619221568107605, 1.1673178672790527, -1.0775699615478516, -0.49914953112602234, -0.8773221373558044, -0.7479175925254822, 0.39021939039230347, 0.7205758094787598, -0.012133164331316948, -0.03417095169425011, 0.00683493772521615, -0.18171779811382294, -0.35865041613578796, -0.9719478487968445, 0.11067517101764679, 0.5565516948699951, -0.7499364018440247, -0.28975069522857666, -0.05567139759659767, 0.9648042321205139, -0.9901154041290283, -0.1855388730764389, -0.10054447501897812, 0.0790657177567482, 0.05742426961660385, 1.1042383909225464, -0.1078987792134285, 0.5868761539459229, 0.5805141925811768, -0.42713937163352966, -0.6799572706222534, -0.04767158627510071, -1.1054821014404297, -0.05087975040078163, 0.5025777816772461, 0.7089757323265076, -0.48510923981666565, 0.09331352263689041, 0.6112363338470459, 0.3896329998970032, -0.46851786971092224, -0.5480756759643555, -0.024730220437049866, 0.21295183897018433, -0.49863487482070923, 0.6374475359916687, -0.4198574125766754, -0.19494681060314178, 0.695822536945343, 0.38518378138542175, 0.7348941564559937, -0.2512061297893524, -0.536526083946228, 0.3351742923259735, -0.2756585478782654, 0.28715670108795166, -0.3555779755115509, -0.18444229662418365, -1.8580131530761719, 0.10130389034748077, -0.8601911067962646, -0.1078292727470398, -1.4446061849594116, -0.6168572902679443, 0.4793406128883362, 0.0743555799126625, -0.20777904987335205, 0.28171101212501526, -0.17390435934066772, -0.32532158493995667, -0.7732803821563721, -0.7202029824256897, 0.6962130069732666, 0.7211191058158875, -0.7124515175819397, 0.01683662086725235, 0.06373286247253418, -0.29823917150497437, 0.6413934826850891, 0.3660527169704437, -0.43034660816192627, -0.7097270488739014, -1.5099278688430786, 0.3818672001361847, -0.030474072322249413, -0.13056468963623047, -0.6624767184257507, 1.0138686895370483, 0.5530794858932495, -0.37908732891082764, -0.33185362815856934, 0.13988769054412842, -0.9487356543540955, -0.8202086091041565, 0.1495078057050705, -0.6718886494636536, 0.417887419462204, 0.2754654288291931, -0.7096335291862488, -0.12810645997524261, 0.9435368180274963, -0.1681165248155594, -0.9325997233390808, -0.527049720287323, 0.21623767912387848, -0.5193350315093994, 0.26412636041641235, -0.6557863354682922, 0.08813086897134781, -1.0873215198516846, -0.5639005899429321, 0.09099654108285904, 0.4473966658115387, -0.3989575207233429, 0.66351318359375, 0.28373289108276367, -0.979973554611206, -0.20089872181415558, 0.28113284707069397, -0.37340259552001953, -0.10860719531774521, 0.24125143885612488, 0.6082496643066406, -0.28487730026245117, 0.5378099083900452, 0.5870167016983032, 0.0824570283293724, -1.0289596319198608, 0.25652649998664856, 0.6378817558288574, -0.5897793173789978, -0.4486507177352905, 0.7735601663589478, -0.6229718923568726, -1.2195932865142822, -0.07410970330238342, -1.3774656057357788, -0.5142252445220947, -0.377956748008728, 1.087597370147705, 0.4453309178352356, -0.04160702973604202, -0.04944584146142006, -0.8017990589141846, 0.5490274429321289, -0.006259046029299498, -0.4498448073863983, 0.7116796970367432, -0.5939272046089172, -0.8823350071907043, 0.22190015017986298, 0.6855066418647766, -0.34938469529151917, -0.17320744693279266, -0.8718544840812683, -0.35515186190605164, -0.0030715372413396835, 0.5499836206436157, -0.4785345494747162, -0.22981326282024384, 0.8851441144943237, 0.3442830443382263, 0.2121613621711731, 0.5885968208312988, -0.08133865147829056, 0.34699392318725586, 0.7091214060783386, 0.0408613383769989, -0.33757248520851135, -0.9531307816505432, 1.659037470817566, 1.2438969612121582, -0.6530349254608154, 0.11071858555078506, -0.4001222848892212, -0.3834875524044037, 0.658282995223999, -0.027929777279496193, -0.16257956624031067, 0.7828435301780701, 0.3573300540447235, 0.14511719346046448, 0.26095888018608093, -1.0512521266937256, -0.43526020646095276, 0.5665071606636047, 0.9851860404014587, 0.5096558332443237, 0.08757675439119339, -0.08442477136850357, 1.0435541868209839, 0.21777573227882385, 0.3068174123764038, 0.565903902053833, 0.19847862422466278, -0.36754441261291504, 0.11982690542936325, -0.29584625363349915, 0.6279021501541138, -0.8014606237411499, -0.9053560495376587, 0.11097239702939987, 0.3196810781955719, -0.0026396464090794325, 0.9551740884780884, 0.8657140731811523, 0.2913767099380493, 0.6632623672485352, 0.0327163003385067, 0.5944964289665222, -0.5579484105110168, -0.132700115442276, 0.18102814257144928, -0.9252062439918518, -0.17097590863704681, -0.11931061744689941, -0.28649717569351196, -0.44722312688827515, -0.5813966393470764, 0.18418779969215393, 0.2987445294857025, 0.11499836295843124, 1.2546262741088867, 0.8507959246635437, 0.6798843741416931, -0.5596749186515808, -0.44714584946632385, -0.21309541165828705, -1.1436659097671509, 0.30222147703170776, -1.0207597017288208, 0.05697409436106682, 0.4051966071128845, 0.058765705674886703, -0.44927117228507996]}, "authors": [{"authorId": "1390573666", "name": "Zhanghao Wu"}, {"authorId": "47781592", "name": "Zhijian Liu"}, {"authorId": "2110385919", "name": "Ji Lin"}, {"authorId": "49417466", "name": "Yujun Lin"}, {"authorId": "143840275", "name": "Song Han"}], "references": [{"paperId": "b6207686ecf40f1eb1752425299f265dffbc4abe", "title": "GAN Compression: Efficient Architectures for Interactive Conditional GANs"}, {"paperId": "1148ecf3734486e234869262ae8e8daf309fc0b2", "title": "AutoML for Architecting Efficient and Specialized Neural Networks"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "d78aed1dac6656affa4a04cbf225ced11a83d103", "title": "Revealing the Dark Secrets of BERT"}, {"paperId": "fdde9a63877db44c1b6a7f5cff5d47f01465e793", "title": "Point-Voxel CNN for Efficient 3D Deep Learning"}, {"paperId": "830995ef17cc291c13f42dfd9f462137de1d2179", "title": "Augmenting Self-attention with Persistent Memory"}, {"paperId": "95a251513853c6032bdecebd4b74e15795662986", "title": "What Does BERT Look at? An Analysis of BERT\u2019s Attention"}, {"paperId": "d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "title": "Energy and Policy Considerations for Deep Learning in NLP"}, {"paperId": "f4238bd2385a52413ccbacfd9e409a650235bd13", "title": "Adaptive Attention Span in Transformers"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "bd3df472bc848083068a76e9ce2b2ab49543dc78", "title": "MetaPruning: Meta Learning for Automatic Neural Network Channel Pruning"}, {"paperId": "16c844fd4d97f3c6eb38b0d6527c87d184efedc3", "title": "The Evolved Transformer"}, {"paperId": "fea820b7d953d32069e189af2961c28fd213470b", "title": "Pay Less Attention with Lightweight and Dynamic Convolutions"}, {"paperId": "45532bffbfbb5553da0b2d0844e95a1b37e59147", "title": "FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search"}, {"paperId": "54c4642d017830e1faddbb49f0377228d2b01493", "title": "HAQ: Hardware-Aware Automated Quantization With Mixed Precision"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "f323407464c4cd492d3fc1afd7170eab08f44d9b", "title": "ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware"}, {"paperId": "693c97ecedb0a84539b7162c95e89fa3cd84ca73", "title": "MnasNet: Platform-Aware Neural Architecture Search for Mobile"}, {"paperId": "3d8b62c060f8444907e7c975c6ae590373b51ed4", "title": "Quantizing deep convolutional networks for efficient inference: A whitepaper"}, {"paperId": "bf8fe437f779f2098f9af82b534aa51dc9edb06f", "title": "Scaling Neural Machine Translation"}, {"paperId": "bb669de2fce407df2f5cb2f8c51dedee3f467e04", "title": "The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation"}, {"paperId": "d16b21f3e99171c86365679435f9f03766750639", "title": "NetAdapt: Platform-Aware Neural Network Adaptation for Mobile Applications"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "1717255b6aea01fe956cef998abbc3c399b5d7cf", "title": "AMC: AutoML for Model Compression and Acceleration on Mobile Devices"}, {"paperId": "fe9b8aac9fa3bfd9724db5a881a578e471e612d7", "title": "Efficient Neural Architecture Search via Parameter Sharing"}, {"paperId": "5f79398057bf0bbda9ff50067bc1f2950c2a2266", "title": "Progressive Neural Architecture Search"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "3861ae2a6bdd2a759c2d901a6583e63a216bc2fc", "title": "Weighted Transformer Network for Machine Translation"}, {"paperId": "90a16f34d109b63d95ab4da2d491cbe3a1c8b656", "title": "Learning Efficient Convolutional Networks through Network Slimming"}, {"paperId": "d0611891b9e8a7c5731146097b6f201578f47b2f", "title": "Learning Transferable Architectures for Scalable Image Recognition"}, {"paperId": "ee53c9480132fc0d09b1192226cb2c460462fd6d", "title": "Channel Pruning for Accelerating Very Deep Neural Networks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "07c4fc48ad7b7d1a417b0bb72d0ae2d4efc5aa83", "title": "Depthwise Separable Convolutions for Neural Machine Translation"}, {"paperId": "032274e57f7d8b456bd255fe76b909b2c1d7458e", "title": "A Deep Reinforced Model for Abstractive Summarization"}, {"paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0", "title": "Convolutional Sequence to Sequence Learning"}, {"paperId": "6ce1922802169f757bbafc6e087cc274a867c763", "title": "Regularizing Neural Networks by Penalizing Confident Output Distributions"}, {"paperId": "d418295cd3027c43eccc5592ae5b8303ba8192be", "title": "Trained Ternary Quantization"}, {"paperId": "67d968c7450878190e45ac7886746de867bf673d", "title": "Neural Architecture Search with Reinforcement Learning"}, {"paperId": "98445f4172659ec5e891e031d8202c102135c644", "title": "Neural Machine Translation in Linear Time"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "9ec499af9b85f30bdbdd6cdfbb07d484808c526a", "title": "Efficient softmax approximation for GPUs"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "6eecc808d4c74e7d0d7ef6b8a4112c985ced104d", "title": "Binarized Neural Networks"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "642d0f49b7826adcf986616f4af77e736229990f", "title": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "93499a7c7f699b6630a86fad964536f9423bb6d0", "title": "Effective Approaches to Attention-based Neural Machine Translation"}, {"paperId": "d1505c6123c102e53eb19dff312cb25cea840b72", "title": "Teaching Machines to Read and Comprehend"}, {"paperId": "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff", "title": "Learning both Weights and Connections for Efficient Neural Network"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Ran El-Yaniv, and Yoshua Bengio"}, {"paperId": null, "title": "We propose a specialized multi-branch feature extractor, Long-Short Range Attention (LSRA), as the basic"}]}