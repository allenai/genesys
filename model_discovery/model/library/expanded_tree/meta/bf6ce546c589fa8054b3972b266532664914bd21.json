{"paperId": "bf6ce546c589fa8054b3972b266532664914bd21", "abstract": "Vision Transformers (ViTs) have triggered the most recent and significant breakthroughs in computer vision. Their efficient designs are mostly guided by the indirect metric of computational complexity, i.e., FLOPs, which however has a clear gap with the direct metric such as throughput. Thus, we propose to use the direct speed evaluation on the target platform as the design principle for efficient ViTs. Particularly, we introduce LITv2, a simple and effective ViT which performs favourably against the existing state-of-the-art methods across a spectrum of different model sizes with faster speed. At the core of LITv2 is a novel self-attention mechanism, which we dub HiLo. HiLo is inspired by the insight that high frequencies in an image capture local fine details and low frequencies focus on global structures, whereas a multi-head self-attention layer neglects the characteristic of different frequencies. Therefore, we propose to disentangle the high/low frequency patterns in an attention layer by separating the heads into two groups, where one group encodes high frequencies via self-attention within each local window, and another group encodes low frequencies by performing global attention between the average-pooled low-frequency keys and values from each window and each query position in the input feature map. Benefiting from the efficient design for both groups, we show that HiLo is superior to the existing attention mechanisms by comprehensively benchmarking FLOPs, speed and memory consumption on GPUs and CPUs. For example, HiLo is 1.4x faster than spatial reduction attention and 1.6x faster than local window attention on CPUs. Powered by HiLo, LITv2 serves as a strong backbone for mainstream vision tasks including image classification, dense detection and segmentation. Code is available at https://github.com/ziplab/LITv2.", "venue": "Neural Information Processing Systems", "year": 2022, "citationCount": 84, "influentialCitationCount": 9, "openAccessPdf": {"url": "http://arxiv.org/pdf/2205.13213", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces LITv2, a simple and effective ViT which performs favourably against the existing state-of-the-art methods across a spectrum of different model sizes with faster speed and shows that HiLo is superior to the existing attention mechanisms by comprehensively benchmarking FLOPs, speed and memory consumption on GPUs and CPUs."}, "embedding": {"model": "specter_v2", "vector": [0.706128716468811, 0.6448233723640442, -0.09898147732019424, 0.4765126407146454, -0.19427195191383362, 0.4168250262737274, 0.713175892829895, -0.1848500818014145, -0.3025705814361572, -1.1795110702514648, 0.16456714272499084, 0.7456719875335693, 0.43027642369270325, -0.4053496718406677, -0.18056660890579224, -0.03431921824812889, -0.7692481875419617, -0.038437481969594955, 0.7862987518310547, -0.32865625619888306, 0.2745155394077301, -0.8692688941955566, -1.6413180828094482, 0.15549202263355255, 0.2895672023296356, 1.399057149887085, 0.3183343708515167, 1.1769487857818604, -0.3156435787677765, 0.37848496437072754, 0.4849541187286377, 0.08518136292695999, 0.29958587884902954, 0.020853949710726738, -0.304403692483902, -0.20930449664592743, 1.0288050174713135, -0.09116079658269882, -0.5818467736244202, 1.001697063446045, 0.018984274938702583, -0.011106396093964577, 0.5460708141326904, -0.7000895142555237, -0.3883512616157532, 0.2339555323123932, 0.2266145646572113, 0.8913102149963379, -0.5105953812599182, -0.307317316532135, 1.139266014099121, -1.2939538955688477, 0.2446633130311966, 1.5128087997436523, 0.821176290512085, 0.059611741453409195, -0.1823541522026062, -0.2327781766653061, 0.37621814012527466, 0.44920119643211365, -0.6272315382957458, -0.4339958727359772, -0.00234141550026834, -0.026921093463897705, 1.8424285650253296, -0.5009503960609436, 0.04393591359257698, 0.4697910249233246, 0.41925081610679626, 1.1083500385284424, 0.12263374030590057, -0.8484070897102356, -0.14881746470928192, -0.07960087805986404, 0.4644196033477783, 0.7601494789123535, -0.08458017557859421, 0.2168833166360855, -1.0978479385375977, 0.18364571034908295, 0.4748802185058594, -0.20016612112522125, 0.26856935024261475, -0.3910798728466034, -0.22274698317050934, 0.8473699688911438, 0.9018490314483643, 0.5899089574813843, -0.11099248379468918, 1.1918278932571411, 0.6156413555145264, -0.01586815156042576, -0.028506724163889885, 0.21392250061035156, 0.2545800507068634, 0.9105284810066223, -0.6385385394096375, -0.0456220917403698, -0.4045684039592743, 0.9025049805641174, -0.027679819613695145, 0.33719778060913086, -0.4907647967338562, 0.1905025839805603, 1.0662063360214233, 0.3975014090538025, 0.49624156951904297, -0.4759330749511719, -0.3950820863246918, -0.7931264638900757, -0.2543167471885681, -0.965696394443512, 0.047085363417863846, -0.36812829971313477, -0.8846321105957031, -0.635321855545044, -0.26716211438179016, 0.7024794816970825, -1.204817533493042, 0.23448649048805237, 0.003737267106771469, 0.1291283220052719, -0.3291758894920349, 0.5504761934280396, 0.756476640701294, 0.4146251082420349, 0.18113985657691956, 0.387714147567749, 1.7936341762542725, -0.816602349281311, -0.5833389163017273, -0.8363333344459534, -0.10889916867017746, -0.35823923349380493, 0.32874229550361633, 0.07998592406511307, -1.0479187965393066, -1.5365958213806152, -0.5862314105033875, -0.31541138887405396, -0.5278217792510986, 0.25831320881843567, 1.3464113473892212, 0.24388477206230164, -1.0264406204223633, 0.5707142949104309, -0.4098018407821655, -0.5360506176948547, 0.6879675388336182, -0.0036175535060465336, 0.5201826691627502, -0.11706382781267166, -0.9991376996040344, 0.21012841165065765, 0.04710670933127403, -0.574388861656189, -0.39356547594070435, -0.4982212781906128, -1.2260549068450928, 0.15386778116226196, 0.28204262256622314, -0.6367419958114624, 0.9992286562919617, -0.25223058462142944, -0.7263503670692444, 0.7617641091346741, -0.4395166039466858, -0.37313732504844666, 0.05959850177168846, -0.24905768036842346, -0.24771572649478912, 0.03230245038866997, -0.01696198247373104, 0.7838721871376038, 1.3533657789230347, 0.08730366080999374, -0.5905910134315491, 0.07683175802230835, -0.5492964386940002, -0.2667161524295807, -0.46507322788238525, 0.7301981449127197, -0.8503661155700684, -0.2395074963569641, 0.6580180525779724, 0.48002830147743225, 0.15182149410247803, -0.29547515511512756, -0.07341797649860382, -1.1091192960739136, 1.0459116697311401, 0.43404921889305115, 0.5957316756248474, -0.9791147112846375, -1.1780823469161987, -0.21963313221931458, 0.24755766987800598, -0.3844515383243561, -0.6346487998962402, 0.30382364988327026, -0.3307114839553833, -0.014595062471926212, 0.43317246437072754, -0.6633185148239136, -0.022399328649044037, -0.9061364531517029, -0.7622421383857727, 0.13310138881206512, 0.5027041435241699, 1.1223840713500977, -0.7131540775299072, -0.16155241429805756, 0.09608178585767746, 0.5696665048599243, -0.9277759194374084, 0.7670544385910034, -0.24986541271209717, -0.41292357444763184, 0.08770018070936203, 0.27827736735343933, 0.21386443078517914, -0.3820984661579132, 0.35338684916496277, -0.9613499641418457, -0.06368913501501083, 0.43993428349494934, -0.2948116064071655, 0.9297398328781128, -0.07908095419406891, 0.9107450842857361, -0.34169459342956543, -0.6716696619987488, 0.1880037486553192, 0.014555700123310089, -0.12206540256738663, -0.8807750344276428, 0.47420868277549744, -0.010414629243314266, -0.7844365835189819, 0.3791799247264862, 0.6435809135437012, 1.4461188316345215, -0.2990870475769043, -0.33064574003219604, 0.9950156807899475, -0.4907263517379761, -0.08436259627342224, 0.4543742835521698, 0.6938329339027405, 0.5308927893638611, 0.3121946156024933, -0.43573737144470215, -0.12176778167486191, -0.45175671577453613, -0.164912611246109, 0.9796894192695618, 0.24687941372394562, 1.277600884437561, 0.27829504013061523, -1.0106157064437866, -0.5514194369316101, 0.09077275544404984, 0.19226112961769104, 1.4209345579147339, 0.05563896894454956, -0.004792631138116121, -0.8202494978904724, -0.0713585838675499, -0.38918912410736084, -0.7029924392700195, -0.7782955765724182, -0.1990358978509903, -0.2402859777212143, -1.002193808555603, 0.53910231590271, 0.12033361196517944, 1.332518219947815, -0.6496558785438538, -1.0729025602340698, -0.2813835144042969, 0.3609714210033417, -0.8692051768302917, -0.8888213634490967, 0.46456652879714966, -0.30112653970718384, -0.36352187395095825, 0.0005700992769561708, -0.4085574746131897, -0.021937120705842972, 0.0022166057024151087, 0.6226045489311218, -0.7183587551116943, -1.1863383054733276, 0.27816271781921387, 0.545034646987915, -0.9643529057502747, -0.04153002053499222, 0.01747111603617668, 0.09845735132694244, 0.0850415825843811, 0.453946590423584, 0.19044329226016998, -0.3470597565174103, 0.10028290748596191, -0.2585134506225586, -0.3435112535953522, 0.08983256667852402, 0.02622286044061184, 0.9899199604988098, -0.05701332539319992, -0.1921604722738266, -0.9807528853416443, 0.3873903453350067, 0.33408859372138977, -0.5151563882827759, -0.24281500279903412, -0.6548102498054504, -0.26808780431747437, 0.17679189145565033, -0.9672595858573914, -0.07075333595275879, -0.3500002920627594, 0.7084452509880066, -0.7037686705589294, -0.24018432199954987, -0.5465549826622009, 0.5161451697349548, -0.5799530148506165, 0.9425868391990662, 0.2871331572532654, 0.04712119698524475, 0.45169490575790405, 0.3362298309803009, -1.126705288887024, 1.1995103359222412, 0.5124998092651367, 0.1983509361743927, 0.34497734904289246, -0.04980243742465973, -0.9959874749183655, -0.3587563931941986, -0.6073195934295654, -0.07999375462532043, -0.4788045585155487, 0.5059732794761658, -0.6322372555732727, -1.3035155534744263, 0.20659683644771576, -0.6924121379852295, -0.1463380753993988, 0.08785645663738251, -0.19657352566719055, -0.5722643136978149, -0.8621939420700073, -0.8931000828742981, -0.6858581304550171, -0.8907564878463745, -0.8772774338722229, 0.5376790165901184, 0.4518960416316986, -0.14227858185768127, -0.06287745386362076, -0.3946784734725952, -0.5995596647262573, 1.235020637512207, -0.15947628021240234, 0.14001184701919556, 0.20444989204406738, -0.6271955370903015, -0.023792708292603493, -0.27089372277259827, -0.13637849688529968, -0.2702398896217346, 0.4278355538845062, -1.2627650499343872, 0.39446792006492615, -0.11147481203079224, -0.4229801297187805, 0.9612718224525452, 0.8589047193527222, 0.5010498762130737, 0.3040725886821747, -0.5233861207962036, 0.7900866270065308, 1.7963227033615112, -0.7502455115318298, 0.45756423473358154, 0.3140815794467926, 0.96268630027771, 0.09789752960205078, -0.07684391736984253, 0.47557052969932556, 0.5886173844337463, 0.20113126933574677, 0.6863681077957153, -0.5533443093299866, -0.7663643956184387, -0.33810049295425415, 0.24287284910678864, 0.6624319553375244, 0.24790531396865845, 0.325699120759964, -0.7802512049674988, 0.9858685731887817, -0.9381046295166016, -0.870206892490387, 0.3547227084636688, 0.7948519587516785, 0.03725558519363403, -0.031447019428014755, -0.21128010749816895, -0.4288589060306549, 0.4855746924877167, 0.37188705801963806, -0.5550802946090698, -0.6104203462600708, -0.25736287236213684, 0.7093003392219543, 0.6019864678382874, 0.45036038756370544, -0.7621968984603882, 0.7727632522583008, 14.856476783752441, 0.7494677901268005, -0.28299129009246826, 0.28563979268074036, 0.6399930119514465, 0.4856700003147125, 0.1393936425447464, 0.1816381812095642, -1.1702752113342285, -0.27972516417503357, 0.8514710068702698, 0.4746414124965668, 0.2391997128725052, 0.4922600984573364, -0.3406650722026825, -0.041177306324243546, -0.25740846991539, 0.9839231371879578, 0.5966676473617554, -1.3136156797409058, -0.03589789196848869, 0.2422269731760025, 0.22986814379692078, 0.6196470856666565, 0.8628261685371399, 0.4873308837413788, 0.33585837483406067, -0.21768830716609955, 0.4165453612804413, 0.21263077855110168, 1.2939876317977905, 0.12550611793994904, 0.060618240386247635, -0.05041240155696869, -1.4247535467147827, -0.10255628079175949, -0.7373552918434143, -0.8392823338508606, -0.3534155786037445, 0.20053206384181976, -0.43112966418266296, -0.5694867968559265, 0.6397470831871033, 0.270593523979187, -0.09219008684158325, 0.5299726128578186, 0.3126809298992157, 0.2707522511482239, -0.39867228269577026, 0.029828228056430817, 0.19608958065509796, 0.7984893918037415, -0.035436537116765976, 0.270343154668808, -0.10856740176677704, -0.002624342916533351, -0.008030103519558907, 0.5294913649559021, -0.16204549372196198, -0.5256403684616089, -0.12926726043224335, 0.10132172703742981, -0.18720348179340363, 1.0698691606521606, -0.05146249756217003, 0.13161617517471313, 0.09909442067146301, 0.3186891973018646, 0.22910188138484955, -0.2039240151643753, -0.5106524229049683, -0.5782131552696228, 0.3448654115200043, -0.4763278365135193, 0.4237649738788605, 0.5743998289108276, -0.29543304443359375, -0.5881322026252747, -0.7630632519721985, -0.3582426607608795, 0.4039590358734131, -0.6497558951377869, -0.39080891013145447, 0.9322803616523743, -0.3130454123020172, -0.09483572840690613, 0.6764792203903198, -0.8384256958961487, -0.5975140333175659, 0.2638058662414551, -1.6213669776916504, -0.7966645359992981, -0.35922086238861084, -0.3369869291782379, 0.04707279056310654, 0.1242765411734581, 0.7880658507347107, -0.32993611693382263, 0.00939837098121643, 0.28170573711395264, -0.6948177218437195, -0.2995215356349945, 0.08422324806451797, -0.7950731515884399, 1.2771458625793457, 0.41386112570762634, -0.18879692256450653, -0.030227290466427803, 0.3802942633628845, 0.3933660686016083, -1.0627871751785278, 0.19650119543075562, 0.39635592699050903, -0.4125420153141022, -0.5735201239585876, -0.8480098247528076, -1.0590392351150513, -0.1405344307422638, 0.5593228936195374, 0.31267279386520386, -0.5071497559547424, 0.08139452338218689, -0.794243574142456, -0.0626496896147728, -0.6142697930335999, -0.16392400860786438, 0.34692466259002686, -0.7864073514938354, -0.17858898639678955, 0.0016335260588675737, 0.28795045614242554, -1.0193819999694824, -0.2862206995487213, 0.011866875924170017, 0.46650394797325134, -0.5730388760566711, 1.3422569036483765, 0.13468918204307556, 0.19511191546916962, 0.6315225958824158, 0.0028519306797534227, -0.1558821052312851, -0.29819947481155396, -0.8990150690078735, -0.005079791881144047, 0.25317686796188354, 0.12281487137079239, -0.554681122303009, 0.3651934564113617, 0.32398444414138794, 0.3569487929344177, -0.264053076505661, -0.4499669075012207, -0.08057462424039841, -0.5271989703178406, -0.6554117798805237, -0.07553159445524216, -0.10745001584291458, -0.12898416817188263, 0.01903645321726799, 0.5220193266868591, 0.615617573261261, 0.47256115078926086, -0.42839574813842773, 0.47014039754867554, -0.3062703609466553, -0.17800383269786835, -0.385379821062088, -0.859898030757904, -1.2172937393188477, -0.838438093662262, -0.6516162753105164, -0.13843612372875214, -0.8832589387893677, -0.7048640251159668, 0.19855505228042603, -0.24607223272323608, -0.11267668753862381, 0.16433803737163544, 0.30712834000587463, -0.29523754119873047, -0.4013884663581848, -0.4824713468551636, 0.5637496709823608, 0.5519422888755798, -0.7392538189888, -0.06981469690799713, -0.12184295803308487, -0.08101250231266022, 0.7213624119758606, 0.24068988859653473, -0.35577064752578735, -0.5300636291503906, -0.8546520471572876, 0.19639179110527039, -0.3222561180591583, 0.0540706068277359, -1.4897478818893433, 0.9939028024673462, 0.6382960081100464, 0.1574229896068573, -0.17881254851818085, 0.3716818392276764, -0.5612652897834778, -0.6946678757667542, 0.4485008418560028, -0.35391923785209656, -0.29228031635284424, 0.40841206908226013, -0.40023401379585266, -0.1761881411075592, 1.0980125665664673, 0.3832733929157257, -1.0203453302383423, -1.1820385456085205, 0.39890673756599426, -0.17721393704414368, 0.13335290551185608, -0.3553431034088135, -0.45359259843826294, -1.337973952293396, -0.27727746963500977, -0.07309583574533463, 0.21655286848545074, -0.48386308550834656, 0.912764310836792, 0.6338386535644531, -1.023419737815857, 0.2461887001991272, 0.5709198713302612, -0.016770340502262115, 0.1436251848936081, 0.7563520669937134, 0.4049926996231079, -0.3213718831539154, 0.5482659935951233, -0.044419657438993454, -0.2001711130142212, -0.6312116384506226, 0.5105880498886108, 0.8639130592346191, 0.03556084632873535, -0.3678489625453949, 1.1428998708724976, 0.2915899157524109, -0.4710680842399597, 0.15549398958683014, -1.2786904573440552, -0.5103796124458313, 0.17110493779182434, 0.5615195035934448, 0.06387121975421906, -0.025966918095946312, 0.2726259231567383, -0.6495155096054077, 0.7722340226173401, -0.08474662899971008, -0.459028035402298, 0.1551123410463333, 0.1321888566017151, -0.0688759908080101, 0.17804741859436035, 0.6126567721366882, -0.6926872730255127, -1.1390247344970703, -1.0322210788726807, -0.630401074886322, -0.1256052851676941, 0.41650503873825073, 0.016797520220279694, -0.5879595875740051, 0.8821799755096436, 0.949144184589386, 0.7545854449272156, 0.4848058223724365, 0.02642749436199665, 0.07302097976207733, 0.42371460795402527, -0.12956415116786957, -0.7860303521156311, -0.3185548186302185, 1.1662064790725708, 0.9450511336326599, -0.7889755964279175, 0.01684446819126606, -0.566082775592804, -0.5033857226371765, 0.7798936367034912, 0.5149939656257629, -0.7167066931724548, 0.6748666763305664, -0.34480586647987366, -0.14138329029083252, 0.11973000317811966, -0.9066537022590637, -0.8649669885635376, 1.03574538230896, 1.458052158355713, 0.30974480509757996, -0.21038495004177094, 0.4768064022064209, 0.24721339344978333, 0.19877633452415466, -0.10745610296726227, 0.2818737030029297, 0.14363300800323486, -0.6369415521621704, 0.7218565940856934, -0.4544917047023773, 0.40557003021240234, -0.7109955549240112, -0.459075003862381, 0.22908151149749756, 0.6759397983551025, 0.32957950234413147, 0.5232957005500793, 0.9948578476905823, -0.0076722861267626286, 0.6479038000106812, -0.15018999576568604, 0.6397956013679504, -0.24299389123916626, 0.026539424434304237, 0.3766297698020935, -1.1338626146316528, -0.37201911211013794, -0.02128269523382187, -0.6633578538894653, -0.19713802635669708, 0.1507234126329422, -0.12064289301633835, -0.5095257759094238, 0.43366989493370056, 0.3776359558105469, 0.6637004613876343, 0.9303338527679443, -0.10296781361103058, -1.0188487768173218, -0.16544921696186066, -0.8801695108413696, 0.3943398892879486, -0.6084232330322266, 0.18237340450286865, -0.42083099484443665, -0.2271086424589157, -0.03543361276388168]}, "authors": [{"authorId": "1840579673", "name": "Zizheng Pan"}, {"authorId": "2152629962", "name": "Jianfei Cai"}, {"authorId": "3194022", "name": "Bohan Zhuang"}], "references": [{"paperId": "3e448df5aa191f7a3945d0fd609c8bc5966a2333", "title": "HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions"}, {"paperId": "ba609e5c83ad9b32723e547b9d3c89d97373f755", "title": "VSA: Learning Varied-Size Window Attention in Vision Transformers"}, {"paperId": "1504ab3e1ae7af39bbf3dba62b132ec027611c38", "title": "MixFormer: Mixing Features across Windows and Dimensions"}, {"paperId": "ba637c4f1a170f1e2dadeadb71a63cf2b9a46de2", "title": "Visual attention network"}, {"paperId": "430bab3890e1e52c4c1f74900b0e408e47a1cb8f", "title": "How Do Vision Transformers Work?"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "fbf68eb0cf8237cef59ebdb301569c79b9676ff9", "title": "MAXIM: Multi-Axis MLP for Image Processing"}, {"paperId": "0d9b8ccb1135b8e380dd8015b080158c6aae3ae5", "title": "QuadTree Attention for Vision Transformers"}, {"paperId": "e5cb26148791b57bfd36aa26ce2401e231d01b57", "title": "Vision Transformer with Deformable Attention"}, {"paperId": "da74a10824193be9d3889ce0d6ed4c6f8ee48b9e", "title": "MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer"}, {"paperId": "f454f6b5f2ca9749ddf442eb5134612ef7f758c1", "title": "ResNet strikes back: An improved training procedure in timm"}, {"paperId": "a66686e60a3eda0c606e036403cf0a07a5962595", "title": "Mobile-Former: Bridging MobileNet and Transformer"}, {"paperId": "66775d9f16b3f4ca43dba2b31c7c42ca6dcba72b", "title": "GLiT: Neural Architecture Search for Global and Local Image Transformer"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "48418b285a92376a38daafa664a2dd07d42e3fe3", "title": "Focal Self-attention for Local-Global Interactions in Vision Transformers"}, {"paperId": "d645bd08fc19d52164695f9cd5ae863345459a06", "title": "AutoFormer: Searching Transformers for Visual Recognition"}, {"paperId": "9b6af0e358e76d22f209c75b1702c3e6ea7815b1", "title": "Global Filter Networks for Image Classification"}, {"paperId": "7b664a306b7d2f68dd816ea1d6586cf3472d75c1", "title": "Early Convolutions Help Transformers See Better"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "7fff8018bf625447df837c2fda5c58a705fbc038", "title": "XCiT: Cross-Covariance Image Transformers"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "f43b98fcc2d56c60fc71bce96374c1e6b8e12c66", "title": "Shuffle Transformer: Rethinking Spatial Shuffle for Vision Transformer"}, {"paperId": "58fd841b750163453cfea7d9779fa6997832a3b2", "title": "RDA: Robust Domain Adaptation via Fourier Adversarial Attacking"}, {"paperId": "a0964686d80e173529efca6377f47e6a1b2fe69a", "title": "Less is More: Pay Less Attention in Vision Transformers"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "3cbe314cc5407a6c3249815b5173f22ea15173c2", "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"}, {"paperId": "2984ab83ade26639c3a82d29628d0d9e4abbebb0", "title": "Incorporating Convolution Designs into Visual Transformers"}, {"paperId": "81fcd9309e1168fe0664d8df4213771e4ebfa343", "title": "Scalable Visual Transformers with Hierarchical Pooling"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "310f9ef4f5913261395188fbdfc61d25ccdfb926", "title": "Guided Frequency Separation Network for Real-World Super-Resolution"}, {"paperId": "407f1d16ba4eb3cb4851429cae46c97d723a35a5", "title": "Invertible Image Rescaling"}, {"paperId": "4e6cc92ebe8115247dd42160fc257cd44200f120", "title": "Learning in the Frequency Domain"}, {"paperId": "d14e56568dc5f57ccdae899d84f91e34ad847670", "title": "How Much Position Information Do Convolutional Neural Networks Encode?"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "bb713d56a39a040b35e4f9e036fb4422f543e614", "title": "On the Relationship between Self-Attention and Convolutional Layers"}, {"paperId": "843a1f76a0c82dd0f883fb1bdafae6ad2c8feb5b", "title": "Frequency Separation for Real-World Super-Resolution"}, {"paperId": "c2c083df88e88223e1a411e61040b94c233b1b63", "title": "MMDetection: Open MMLab Detection Toolbox and Benchmark"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "0d9eb72ea89bb7bf5720a7b2c2f3f77c26fc67a6", "title": "Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks With Octave Convolution"}, {"paperId": "a84906dbd4d6640f918d0b6ed2a7313dda0d55f1", "title": "Panoptic Feature Pyramid Networks"}, {"paperId": "c02b909a514af6b9255315e2d50112845ca5ed0e", "title": "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"}, {"paperId": "79cfb51a51fc093f66aac8e858afe2e14d4a1f20", "title": "Focal Loss for Dense Object Detection"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "88512be44744615f4baa8e14f600f036db4c2433", "title": "Semantic Understanding of Scenes Through the ADE20K Dataset"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "c89cd80f38c8c359ea0d1f574934dbe1e727a412", "title": "Compressing Convolutional Neural Networks in the Frequency Domain"}, {"paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd", "title": "ImageNet Large Scale Visual Recognition Challenge"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "bc6dff14a130c57a91d5a21339c23471faf1d46f", "title": "Et al"}, {"paperId": "0ff4a2a5ded5926da632fc9681fe5ecd76dbb0bd", "title": "An adaptive Gaussian filter for noise reduction and edge detection"}, {"paperId": "63b9bf6df5bd3e8cfabe31dfa2d894b8d37a5c9f", "title": "Low\u2010pass filters for signal averaging"}, {"paperId": "239e7a7f8127b25e046e53fd5f1951dd2af473cd", "title": "The Fast Fourier Transform and Its Applications"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": null, "title": "and N"}, {"paperId": null, "title": "Computer Vision Foundation / IEEE"}, {"paperId": null, "title": "Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)?"}, {"paperId": null, "title": "c) Did you include any new assets either in the supplemental material or as a URL? [Yes] Code and pretrained models are included as a URL in the abstract"}, {"paperId": null, "title": "c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation?"}, {"paperId": null, "title": "c) Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)?"}]}