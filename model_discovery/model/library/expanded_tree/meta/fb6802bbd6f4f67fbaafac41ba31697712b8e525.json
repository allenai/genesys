{"paperId": "fb6802bbd6f4f67fbaafac41ba31697712b8e525", "abstract": "\u2014With the growing burden of training deep learning models with large data sets, transfer-learning has been widely adopted in many emerging deep learning algorithms. Trans- former models such as BERT are the main player in natural language processing and use transfer-learning as a de facto standard training method. A few big data companies release pre-trained models that are trained with a few popular datasets with which end users and researchers \ufb01ne-tune the model with their own datasets. Transfer-learning signi\ufb01cantly reduces the time and effort of training models. However, it comes at the cost of security concerns. In this paper, we show a new observation that pre-trained models and \ufb01ne-tuned models have signi\ufb01cantly high similarities in weight values. Also, we demonstrate that there exist vendor-speci\ufb01c computing patterns even for the same models. With these new \ufb01ndings, we propose a new model extraction attack that reveals the model architecture and the pre-trained model used by the black-box victim model with vendor-speci\ufb01c computing patterns and then estimates the entire model weights based on the weight value similarities between the \ufb01ne-tuned model and pre-trained model. We also show that the weight similarity can be leveraged for increasing the model extraction feasibility through a novel weight extraction pruning. ,", "venue": "arXiv.org", "year": 2022, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2207.09539", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "A new observation that pre-trained models and \ufb01ne-tuned models have signi\ufb01cantly high similarities in weight values is shown and the weight similarity can be leveraged for increasing the model extraction feasibility through a novel weight extraction pruning."}, "embedding": {"model": "specter_v2", "vector": [-0.1563352346420288, 0.31758129596710205, -0.6550074815750122, -0.06484220921993256, -0.6399786472320557, -0.4537290632724762, 0.34697675704956055, -0.43942791223526, -0.5015671253204346, -0.31620875000953674, -0.11289819329977036, -0.05876336619257927, 0.7464933395385742, -0.04043113812804222, -0.3867080509662628, 0.03908751904964447, -0.8179146647453308, -0.04525570198893547, -0.09654649347066879, -0.3852936029434204, 0.12756220996379852, -0.3049412965774536, -0.7253401279449463, 0.5768648386001587, -0.009188512340188026, 0.7898969054222107, -0.4400539994239807, 0.8503962159156799, -0.23557496070861816, 0.3457655906677246, 0.4259133040904999, -1.143690824508667, 0.8107298612594604, 0.5917332768440247, -0.46825727820396423, -0.23100456595420837, 0.4134008586406708, -1.069322109222412, -0.6562726497650146, 0.9681682586669922, -0.23993799090385437, -0.16086623072624207, -0.11380483955144882, -1.0999730825424194, -0.036562737077474594, 0.5019791722297668, 0.4351269602775574, 0.8826842308044434, -0.6022071242332458, -0.3109300136566162, 1.0506536960601807, -1.1209300756454468, -0.06866400688886642, 1.2141362428665161, 0.5285849571228027, 0.5008172988891602, -0.03376082330942154, -1.28071129322052, 0.01857049949467182, 0.04975104704499245, -0.8213104605674744, -0.29950544238090515, 0.07850443571805954, -0.23707836866378784, 1.4589533805847168, -0.40532365441322327, -0.282119482755661, 0.6532283425331116, 0.17939428985118866, 1.2267787456512451, 0.25002703070640564, -0.8743749856948853, -0.6291961073875427, 0.46182578802108765, 0.3234809637069702, 1.135433554649353, 0.014453423209488392, 0.6105604767799377, -0.9863158464431763, -0.7794216871261597, 0.2131749838590622, 0.0492517314851284, 0.369278222322464, -0.19999739527702332, 0.19485273957252502, 0.8566446900367737, 0.2509428858757019, 0.5508307218551636, 0.18963037431240082, 0.9444438219070435, 0.7008362412452698, 0.5697088837623596, -0.012384604662656784, 0.3477967381477356, -0.38997355103492737, 0.3476097583770752, -0.8297836780548096, -0.19746841490268707, 0.09699464589357376, 0.8907228112220764, -0.08882337808609009, 0.04703180864453316, -0.3315541446208954, -0.35990092158317566, 1.148323655128479, -0.27403855323791504, 0.4766271710395813, -0.45289525389671326, 0.5997153520584106, -0.6792817115783691, 0.1245657429099083, -0.7011701464653015, 0.159489244222641, -0.1572178155183792, -0.8147402405738831, -1.0578060150146484, -0.44282370805740356, -0.4954549968242645, -0.975024938583374, 0.7491288781166077, -0.8473527431488037, 0.5153318047523499, 0.25130343437194824, 0.3065102994441986, 0.21782076358795166, 0.4542596638202667, 0.28909337520599365, 0.25072264671325684, 0.8419908881187439, -0.6169031858444214, -0.38704049587249756, -0.6293557286262512, 0.8039015531539917, -0.6503227949142456, 0.18288454413414001, -0.271109402179718, -1.1657437086105347, -0.6726312637329102, -1.1617153882980347, 0.38777491450309753, -0.76988685131073, 0.19056706130504608, 1.0156455039978027, 0.6931977868080139, -0.8199670314788818, 1.0520691871643066, -0.2482905238866806, -0.25830236077308655, 0.720111072063446, 0.7804588079452515, 0.07482988387346268, -0.2388828694820404, -1.2237876653671265, 0.5013755559921265, 0.6087642312049866, -0.6704583764076233, -0.16177959740161896, -0.7816663384437561, -0.5464372634887695, 0.36225152015686035, 0.37679752707481384, -0.48726460337638855, 1.2129007577896118, 0.06583116203546524, -0.8694941997528076, 0.9073424339294434, -0.16016630828380585, 0.09511428326368332, 0.48718810081481934, -0.24793803691864014, -0.7803189754486084, -0.6153539419174194, -0.2614278793334961, -0.13720551133155823, 0.8951392769813538, -0.6286901831626892, 0.058253511786460876, 0.4129786193370819, -0.08301703631877899, -0.35904261469841003, -0.6265665888786316, 0.8358771204948425, -0.2871723771095276, -0.19836226105690002, 0.33591434359550476, 0.6812600493431091, 0.13371624052524567, -0.16993607580661774, -0.8917309045791626, -0.3662959337234497, 1.3110840320587158, 0.0006585480296052992, 1.0348215103149414, -0.8666091561317444, -1.0393282175064087, 0.44176527857780457, -0.1496780663728714, 0.32280272245407104, -0.6247142553329468, 0.6584493517875671, -0.4952208995819092, 1.220901608467102, 0.14211873710155487, -0.9190461039543152, -0.018055541440844536, -0.4204988479614258, -1.2385332584381104, -0.32369565963745117, 0.09330952167510986, 1.2664541006088257, -0.40154945850372314, 0.4240134060382843, -0.1430310755968094, -0.08927358686923981, -0.7911311388015747, 1.3959599733352661, -0.07232949882745743, 0.10186828672885895, -0.2401442974805832, 0.036082878708839417, 0.5422310829162598, -0.1950748711824417, 0.007408814039081335, -0.5775429010391235, 0.2254580855369568, 0.39700454473495483, -0.0781852975487709, 1.1724251508712769, -0.24493026733398438, 0.05973216891288757, -0.02474522590637207, -0.6892684698104858, 0.3403981626033783, 0.6761269569396973, -0.11229999363422394, 0.19200463593006134, 0.48753395676612854, 0.519626259803772, -0.39860209822654724, 0.24247723817825317, 0.6800471544265747, 0.4676021933555603, -0.30739256739616394, 0.5431133508682251, 0.6268696784973145, -0.3661346733570099, -0.3323655128479004, 0.2426985502243042, 0.30625206232070923, -0.16778564453125, 0.2731282413005829, 0.13266825675964355, 0.2977117896080017, -0.7308507561683655, -0.10992304235696793, 0.5632612705230713, 0.37323901057243347, 0.6889837980270386, 0.4192529618740082, -0.8803949356079102, -0.2826801836490631, -0.08549020439386368, 0.9436545372009277, 1.2639542818069458, -0.13069851696491241, -0.5947698950767517, -0.3250578045845032, -0.7099195122718811, -0.0031907062511891127, -0.1906147301197052, -0.4398294985294342, -0.8148038983345032, -0.5632084608078003, -1.193273901939392, 1.2961617708206177, 0.006041720509529114, 1.437283992767334, -0.25872743129730225, 0.10117089003324509, -0.3970026671886444, 0.3089900016784668, -0.7960280776023865, -0.5919482707977295, 0.0925469696521759, -0.5981578826904297, 0.16766291856765747, 0.4009188413619995, -0.11623446643352509, 0.179014191031456, -0.6336995363235474, 0.5655844807624817, 0.27234387397766113, -0.06284524500370026, 0.12657670676708221, 0.9163360595703125, -0.9858336448669434, -0.8892034888267517, 0.4212479889392853, 0.1887580305337906, -0.03927413746714592, 0.6695482134819031, 0.4102899730205536, 0.24496717751026154, 0.13983240723609924, -0.4636542797088623, -0.25818100571632385, 0.0771479681134224, 0.19829216599464417, 0.08031003177165985, -0.22315713763237, 0.18623392283916473, -1.2176120281219482, 0.947643518447876, 0.10774011164903641, -0.47996559739112854, 0.502560019493103, -0.6878999471664429, -0.3377428948879242, 0.5829869508743286, -0.8296864628791809, 0.10239828377962112, -1.219760775566101, 0.09431085735559464, -0.8073757290840149, 0.1163770779967308, 0.2574172019958496, 0.1875925213098526, -0.3403543531894684, 0.020515915006399155, 0.35538250207901, 0.4743850529193878, -0.14185655117034912, 0.47622427344322205, -0.9867731928825378, 0.4390203356742859, -0.018819749355316162, 0.9525242447853088, 0.22955717146396637, -0.20510049164295197, -0.039065323770046234, -0.4957023859024048, -0.19625520706176758, -0.5027598142623901, 0.08273587375879288, -0.012600043788552284, -0.38997432589530945, -0.6504701375961304, 0.23436440527439117, -1.1656980514526367, -0.12803637981414795, 0.11341877281665802, 0.011068212799727917, -0.1573944389820099, -1.071204423904419, -1.4042669534683228, -0.4388718903064728, -0.5863598585128784, -0.9915971159934998, -0.1473693549633026, -0.05311259254813194, -0.0868544802069664, -0.5596634745597839, -0.5219805836677551, -0.2627476751804352, 1.1684976816177368, -0.44462889432907104, 1.027770757675171, -0.27463996410369873, -0.36591511964797974, -0.23192954063415527, -0.18956948816776276, 0.6536664962768555, -0.18048684298992157, 0.11270911246538162, -1.2713916301727295, 0.03883886709809303, 0.046928223222494125, -0.31873929500579834, 0.33125144243240356, -0.060138359665870667, 1.0168904066085815, -0.12478461116552353, -0.33696749806404114, 0.6227981448173523, 1.5446995496749878, -0.7067310214042664, 0.12811002135276794, 0.04974550008773804, 1.2882075309753418, 0.33365312218666077, -0.4838748872280121, 0.2731289863586426, -0.31357669830322266, 0.15097326040267944, 0.04546789824962616, -0.15258575975894928, 0.3519827425479889, -0.5172319412231445, 0.3746718466281891, 1.4422365427017212, 0.36131131649017334, 0.3093474209308624, -0.9265835285186768, 0.38542115688323975, -1.1905702352523804, -0.6325269937515259, 0.988625705242157, 1.0001729726791382, 0.1844182163476944, -0.0028483690693974495, -0.4271047115325928, -0.25351276993751526, 0.7835541367530823, 0.21214385330677032, -0.3453790545463562, -1.1715854406356812, 0.5021495223045349, 0.7372734546661377, 0.701030969619751, 0.25186988711357117, -0.21212609112262726, 0.8411322236061096, 14.919742584228516, 0.8821801543235779, -0.43393227458000183, 0.6966328620910645, 0.4219643771648407, 0.28964903950691223, -0.12418017536401749, -0.25741541385650635, -1.0878357887268066, -0.09732700139284134, 0.9605775475502014, -0.3408212959766388, 0.3565558195114136, 0.02139204554259777, -0.4378102123737335, 0.5551170706748962, -0.20032578706741333, 0.9084491729736328, 0.548757791519165, -1.3952713012695312, 0.0758918821811676, 0.49721476435661316, 0.06026165187358856, 0.5916137099266052, 1.0417004823684692, 0.9894818067550659, 0.36354386806488037, -0.4931960999965668, 0.4613008201122284, 0.05063551664352417, 0.9944192171096802, -0.2813078761100769, 0.4668770432472229, 0.4993550777435303, -0.4597929120063782, -0.16442663967609406, -0.9164135456085205, -0.9777165055274963, 0.08921150118112564, 0.19822296500205994, -0.5411929488182068, 0.0016195358475670218, -0.3015706241130829, 0.3023521304130554, 0.2463550865650177, 0.3104654848575592, -0.14944402873516083, 0.8446441292762756, -0.17191818356513977, 0.5198359489440918, 0.055932749062776566, 0.6524708271026611, 0.42910414934158325, -0.3373642861843109, 0.04877711087465286, 0.031140293926000595, 0.12281900644302368, 0.5855350494384766, -1.035403847694397, -0.2976014018058777, -0.5024692416191101, -0.2522841691970825, -0.3464733362197876, 0.9100409746170044, 0.5355609059333801, 0.02436528168618679, -0.3548429012298584, 0.4535515308380127, 0.6815448999404907, 0.09051516652107239, -0.3254750370979309, 0.3645170032978058, 0.26947885751724243, -0.1592698097229004, -0.19017204642295837, 0.1476549506187439, -0.3591580390930176, -0.9856200814247131, -0.6126848459243774, -0.14464277029037476, 0.513846755027771, -0.7745853066444397, -0.9753299355506897, 1.062570333480835, -0.248675137758255, -0.6983134746551514, 0.3841077983379364, -0.5167635083198547, -0.40557023882865906, 0.784405529499054, -1.5453307628631592, -0.73896324634552, 0.5713655352592468, -0.05608373507857323, -0.7407373785972595, -0.4881199300289154, 1.3239531517028809, 0.08113440126180649, -0.2925913631916046, 0.26259997487068176, -0.016072005033493042, 0.5432762503623962, 0.21641205251216888, -0.3828918933868408, 1.0844975709915161, 0.31015917658805847, -0.07777273654937744, 0.2991323173046112, -0.7274728417396545, 0.11592929065227509, -0.2856927812099457, -0.13707587122917175, 0.510962724685669, -0.9739152193069458, -0.3848119080066681, -0.8812689781188965, -0.9508364200592041, 0.3970937430858612, 0.5113762021064758, -0.31662920117378235, 0.48541128635406494, 0.010602504946291447, -0.942940890789032, 0.0006418254342861474, -1.3185276985168457, 0.21423450112342834, 0.17138968408107758, -1.1676183938980103, -0.2603243291378021, -0.007750220131129026, 0.11313816905021667, -0.8851577043533325, -0.6232603192329407, 0.003171973628923297, 0.2054012268781662, -0.41720280051231384, 0.9809698462486267, -0.6226744651794434, 0.5507226586341858, 1.317251205444336, -0.16449123620986938, -0.7172046899795532, 0.1658288687467575, -0.8201410174369812, 0.012213084846735, 0.15227721631526947, 0.4035364091396332, -0.5841262936592102, 0.5305350422859192, 1.3382669687271118, 0.6031370162963867, -0.20034125447273254, -0.3476501703262329, -0.3685026168823242, 0.3842090666294098, -0.5644845366477966, 0.41339901089668274, 0.5482372641563416, -0.27159011363983154, -0.20998558402061462, 0.11351455748081207, 0.800261378288269, 0.06148897111415863, -0.7718260884284973, 0.3258360028266907, -0.25917357206344604, -0.18575532734394073, -0.07846532016992569, -0.4485980272293091, -0.884703516960144, 0.28021079301834106, -1.3134562969207764, -0.3560376763343811, -0.15849578380584717, -0.5538910031318665, 0.06570862978696823, -0.39639827609062195, 0.08814122527837753, 0.7345773577690125, -0.017593249678611755, 0.09968933463096619, 0.2562023997306824, 0.20352984964847565, 0.27572718262672424, 0.836608350276947, -0.5453804731369019, 0.20357343554496765, 0.20279021561145782, -0.20267780125141144, 0.3301786482334137, 0.8654752373695374, -0.8094128370285034, -0.5401524901390076, -1.2839573621749878, -0.06537473946809769, -0.37283316254615784, 0.09678472578525543, -0.5560078620910645, 0.6381244659423828, 0.32942354679107666, -0.08020898699760437, 0.3775283992290497, 0.3186127543449402, -1.2215481996536255, -0.7705969214439392, 0.5969628095626831, -0.5126765370368958, 0.22834379971027374, 0.40986892580986023, -0.7444663643836975, -0.07615984976291656, 0.27511805295944214, -0.02502398006618023, -0.873813271522522, -0.7956618666648865, 0.5410001873970032, -0.44053396582603455, -0.16719788312911987, -0.11387115716934204, 0.00010666797606972978, -1.257836103439331, -0.3528018593788147, -0.4437660574913025, -0.04786977171897888, -0.5306638479232788, 0.8056943416595459, 0.18144585192203522, -1.2142053842544556, 0.17926810681819916, 0.8143457770347595, -0.2593284547328949, -0.2873658835887909, 0.29692426323890686, 0.3781425356864929, -0.32924801111221313, 0.00807750504463911, 0.008230539970099926, 0.5664226412773132, -0.7215161323547363, 0.008497058413922787, 0.6858704090118408, -0.757996141910553, 0.011433349922299385, 0.9427777528762817, -0.46262848377227783, -0.9717633128166199, -0.11646125465631485, -1.0407332181930542, -0.09116493910551071, -0.521709144115448, 0.39353615045547485, -0.08853058516979218, 0.5972137451171875, -0.18029050529003143, -0.3505762815475464, -0.024958999827504158, -0.39886656403541565, -0.6211850047111511, -0.09302202612161636, -0.1047431007027626, -0.2660015821456909, 0.29634466767311096, 1.3132766485214233, -0.4759974181652069, -0.29036545753479004, -0.7942410111427307, -0.10718309879302979, -0.48934218287467957, 0.19842694699764252, -0.4095442295074463, -1.0075645446777344, 0.7008920907974243, 0.6272759437561035, 0.1943710595369339, -0.09790583699941635, -0.6633536219596863, 0.6029565930366516, 0.5589273571968079, 0.35968017578125, -0.22501365840435028, -0.4476410448551178, 1.274623990058899, 0.8656246066093445, -0.8139360547065735, 0.33472856879234314, -0.7020949721336365, -0.5186514258384705, 0.9591953158378601, 0.36749717593193054, -0.47330960631370544, 1.472332239151001, 0.11284924298524857, 0.5417375564575195, 0.2568405568599701, -0.7003214359283447, -0.1935916692018509, 0.780619204044342, 0.6574878692626953, 0.2565399706363678, 0.053217023611068726, 0.3950236737728119, 0.9967102408409119, -0.15571185946464539, 0.18060313165187836, 0.6794823408126831, 0.8293684124946594, -0.067430280148983, -0.5149378180503845, -0.6139163970947266, 0.9932494163513184, -1.2220855951309204, -0.5412142276763916, -0.10869687795639038, 1.0510755777359009, 0.2852596640586853, 0.5828956365585327, 0.5467750430107117, -0.8694725632667542, 0.7159025073051453, 0.608701229095459, 0.15256820619106293, -0.5455060005187988, -0.9373770356178284, -0.30967429280281067, -0.8259432911872864, -0.08111292868852615, -0.2161165177822113, -0.07620130479335785, -0.15658457577228546, -0.7461842894554138, 0.16291846334934235, -0.13830852508544922, -0.17101825773715973, 0.8696932792663574, 0.49360594153404236, 0.04522501304745674, -0.031074607744812965, -0.28372183442115784, -0.4626927375793457, -0.7122594714164734, -0.3266964256763458, -0.48408862948417664, -0.16077210009098053, 0.04069335013628006, -0.3231290578842163, -0.41197431087493896]}, "authors": [{"authorId": "2177342025", "name": "Mujahid Al Rafi"}, {"authorId": "2161638485", "name": "Yuan Feng"}, {"authorId": "33191825", "name": "Hyeran Jeon"}], "references": [{"paperId": "6ecd45137b421b3729c5b28ebb1bd17e71f98b27", "title": "Retrospective: Flipping Bits in Memory Without Accessing Them: An Experimental Study of DRAM Disturbance Errors"}, {"paperId": "cfbe70b779479f450af7c948a7ca327b1b717a00", "title": "BTS: an accelerator for bootstrappable fully homomorphic encryption"}, {"paperId": "74f6e70fd9a945b517e6495920a1267c01842bd4", "title": "DeepSteal: Advanced Model Extractions Leveraging Efficient Weight Stealing in Memories"}, {"paperId": "0a4b92e6600daa7da521b30d750d221ffdaaa58c", "title": "Adversarial Token Attacks on Vision Transformers"}, {"paperId": "66b202ef08099f8bce68a34f879e9729e5331f5f", "title": "F1: A Fast and Programmable Accelerator for Fully Homomorphic Encryption"}, {"paperId": "3c2622daa8a658d5c85ea9869cb460a70b0f878d", "title": "Towards Transferable Adversarial Attacks on Vision Transformers"}, {"paperId": "864cf501b5c04bfcdc836a9cf1909a51ac1d2a99", "title": "Black-Box Attacks on Sequential Recommenders via Data-Free Model Extraction"}, {"paperId": "59c2b4ef91d4ce23cd4f270c8750a00de9054ec2", "title": "Gradient-based Adversarial Attacks against Text Transformers"}, {"paperId": "43e51c1bfd69df518e2907f7a955e485985ba423", "title": "On the Robustness of Vision Transformers to Adversarial Examples"}, {"paperId": "cf592385909a1e3e9a428d8d6d8f427ab70b60a9", "title": "Analyzing the Source and Target Contributions to Predictions in Neural Machine Translation"}, {"paperId": "980451bad2ecb99c5d932e8c05d992a12324dad8", "title": "Hermes Attack: Steal DNN Models with Lossless Inference Accuracy"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "109ad71af2ffce01b60852f8141ea91be6eed9e1", "title": "DeepSniffer: A DNN Model Extraction Framework Based on Learning Architectural Hints"}, {"paperId": "a210fd4656c3fe4a7be8770b3944a672d84c9171", "title": "Model Weight Theft With Just Noise Inputs: The Curious Case of the Petulant Attacker"}, {"paperId": "ac713aebdcc06f15f8ea61e1140bb360341fdf27", "title": "Thieves on Sesame Street! Model Extraction of BERT-based APIs"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "4398448b3af17d1568eb18b0d5395431f1bb1719", "title": "Rendered Insecure: GPU Side Channel Attacks are Practical"}, {"paperId": "527b5265adc87cf59b778c0210dc776830706db8", "title": "Cache Telepathy: Leveraging Shared Resource Attacks to Learn DNN Architectures"}, {"paperId": "50d95d13c02dde5854cd3a5d7bbb8f91711f9730", "title": "Understanding Error Propagation in Deep Learning Neural Network (DNN) Accelerators and Applications"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "8a95423d0059f7c5b1422f0ef1aa60b9e26aab7e", "title": "Stealing Machine Learning Models via Prediction APIs"}, {"paperId": "6dd8d0d2a7ca2c2717e6cd4ee3c8af65f359b796", "title": "Side-channel power analysis of a GPU AES implementation"}, {"paperId": "8929400e4dc217f1706e74285eaea781cb4cff5d", "title": "A Practical Methodology for Measuring the Side-Channel Signal Available to the Attacker for Instruction-Level Events"}, {"paperId": "3813c369accb4b87b5882eec943511fe2e8b4767", "title": "Killing Two Birds with One Stone: Stealing Model and Inferring Attribute from BERT-based APIs"}, {"paperId": "0242acadf4940cf94596b54f7fd6fb75af7bb20d", "title": "Beyond Model Extraction: Imitation Attack for Black-Box NLP APIs"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Repository of Pre-trained models"}, {"paperId": null, "title": "Huggingface General Language Understanding Evaluation (GLUE) Benchmark"}, {"paperId": null, "title": "Huggingface BERT TensorFlow"}, {"paperId": null, "title": "Huggingface Distrilled GPT-2 Pre-trained Model"}, {"paperId": null, "title": "BCoal: Bucketing-Based Memory"}, {"paperId": null, "title": "Huggingface BERT-base Pre-trained Model"}, {"paperId": null, "title": "XLA: Optimizing Compiler for Machine Learning"}, {"paperId": null, "title": "DeepSniffer ResNet Models NVIDIA ResNet v 1 . 5 for PyTorch . [ Online ] TensorFlow ResNet Models"}]}