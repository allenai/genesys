{"paperId": "84d20ad9f42d80dfd5130a6362d5422be8a6bdc3", "abstract": "Rising computational demands of modern natural language processing (NLP) systems have increased the barrier to entry for cutting-edge research while posing serious environmental concerns. Yet, progress on model efficiency has been impeded by practical challenges in model evaluation and comparison. For example, hardware is challenging to control due to disparate levels of accessibility across different institutions. Moreover, improvements in metrics such as FLOPs often fail to translate to progress in real-world applications. In response, we introduce Pentathlon, a benchmark for holistic and realistic evaluation of model efficiency. Pentathlon focuses on inference, which accounts for a majority of the compute in a model's lifecycle. It offers a strictly-controlled hardware platform, and is designed to mirror real-world applications scenarios. It incorporates a suite of metrics that target different aspects of efficiency, including latency, throughput, memory overhead, and energy consumption. Pentathlon also comes with a software library that can be seamlessly integrated into any codebase and enable evaluation. As a standardized and centralized evaluation platform, Pentathlon can drastically reduce the workload to make fair and reproducible efficiency comparisons. While initially focused on natural language processing (NLP) models, Pentathlon is designed to allow flexible extension to other fields. We envision Pentathlon will stimulate algorithmic innovations in building efficient models, and foster an increased awareness of the social and environmental implications in the development of future-generation NLP models.", "venue": "arXiv.org", "year": 2023, "citationCount": 5, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2307.09701", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "Pentathlon is a benchmark for holistic and realistic evaluation of model efficiency, which focuses on inference, which accounts for a majority of the compute in a model's lifecycle, and is designed to mirror real-world applications scenarios."}, "embedding": {"model": "specter_v2", "vector": [0.19579970836639404, -0.12156272679567337, -0.6287699341773987, -0.05340233072638512, -0.6655555963516235, -0.5347796678543091, 0.18159878253936768, 0.16403581202030182, -1.1517789363861084, 0.010229461826384068, 0.17047855257987976, -0.5708474516868591, 0.28341925144195557, 0.031667839735746384, -0.44911709427833557, 0.40324413776397705, -0.43348419666290283, 0.6948301196098328, -0.2881808578968048, 0.21605688333511353, -0.3234574496746063, 0.014373800717294216, -1.1624488830566406, 0.18723434209823608, 0.40082237124443054, 0.3277437090873718, -0.11280784010887146, 1.0682703256607056, -0.10201126337051392, 0.20760776102542877, 0.4643070101737976, -0.06984516233205795, -0.2846071124076843, 0.4044209420681, -0.3601170480251312, -0.8188772797584534, 0.306105375289917, -0.27406832575798035, -0.369579941034317, 0.8757355213165283, -0.1591734141111374, 0.14764009416103363, 0.35212650895118713, -0.8790549635887146, -0.28772443532943726, 0.8990768790245056, 0.6328235268592834, 0.869204044342041, -0.01994250901043415, -0.265838623046875, 1.418056607246399, -1.3300100564956665, 0.6845799088478088, 1.2194130420684814, 0.8178378939628601, 0.07851366698741913, -0.7524715662002563, -0.43008968234062195, -0.32541942596435547, -0.1639428287744522, -1.0621296167373657, -0.8420411348342896, -0.9886952638626099, 0.043385300785303116, 2.1019554138183594, 0.06822334229946136, -0.14957992732524872, 0.1430264115333557, 0.05837240442633629, 1.2355512380599976, 0.044398337602615356, -0.9570826888084412, 0.10581829398870468, -0.06165050342679024, 0.5079818964004517, 0.8358682990074158, 0.0861787497997284, -0.06405408680438995, -0.9798423647880554, -0.5282130241394043, -0.44906893372535706, -0.20595517754554749, 0.17746813595294952, -0.07149539142847061, -0.3932799994945526, 0.5298689603805542, 0.15723228454589844, 0.9328242540359497, -0.4115046262741089, 0.7644689679145813, 0.6791754364967346, 0.37960705161094666, 0.18887317180633545, 0.5439437031745911, -0.35040780901908875, 0.05654996261000633, -1.1822583675384521, 0.40168875455856323, 0.45957887172698975, 0.7538877129554749, -0.328341007232666, 0.06848684698343277, -1.0095523595809937, -0.11680828779935837, 1.1939003467559814, 0.4268783628940582, 0.3682343363761902, -0.6475988030433655, 0.2987958788871765, -0.18810321390628815, 0.6309224963188171, -0.35879597067832947, -0.6338720321655273, 0.2852106988430023, -0.4576769173145294, -1.4073286056518555, -0.1714950054883957, -0.22758786380290985, -0.883409321308136, 0.46010977029800415, -0.3737283945083618, -0.049902044236660004, 0.4393244683742523, 0.39567163586616516, 0.7427021265029907, 0.6605638861656189, 0.20899474620819092, 0.06157020106911659, 1.3674812316894531, -0.6039004921913147, -0.4898657500743866, -1.0195428133010864, 1.0017210245132446, -0.30457741022109985, 0.1312284916639328, -0.7483184933662415, -1.6399757862091064, -0.28208357095718384, -0.11297762393951416, -0.2712439298629761, -0.5675545930862427, 0.5561915636062622, 1.1731795072555542, 0.234441339969635, -0.9388941526412964, 0.1841719001531601, -0.31714123487472534, -0.43855002522468567, 0.2400214821100235, 0.13317425549030304, -0.08653130382299423, -0.5252283215522766, -0.9331737160682678, 0.3577461242675781, 0.5058127641677856, -0.7802962064743042, -0.24402469396591187, -0.689330518245697, -1.1536518335342407, 0.4812659025192261, 0.1459362953901291, -0.5041456818580627, 1.632170557975769, 0.3066920340061188, -0.7063238024711609, 0.5329394340515137, -0.597316563129425, -0.15932320058345795, 0.33392733335494995, -0.0617511086165905, -0.6760608553886414, -0.19372040033340454, 0.09606410562992096, 0.4724159836769104, 0.2685086131095886, -0.006709395907819271, -0.1228582113981247, 0.3987620174884796, -0.23248855769634247, -0.055604301393032074, -0.011206389404833317, 1.2992701530456543, -0.6802586913108826, -0.07137025147676468, 0.3244965672492981, 0.42000219225883484, -0.5093774795532227, 0.30083444714546204, -0.4680803120136261, -0.5347131490707397, 0.45668497681617737, -0.23133540153503418, 1.0188724994659424, -0.8073508143424988, -0.7315651178359985, 0.18085134029388428, -0.1502370685338974, -0.173540860414505, -0.4587135314941406, 0.79585200548172, -0.38983824849128723, 0.8843736052513123, -0.3886426091194153, -0.6303812861442566, 0.18220394849777222, -0.3090748190879822, -0.4479925036430359, -0.06281548738479614, -0.09729928523302078, 0.991531252861023, -0.575968861579895, -0.12489888817071915, -0.019729280844330788, 0.27664944529533386, -1.0996437072753906, 0.6619742512702942, -0.7470674514770508, -0.13987450301647186, -0.010749108158051968, 1.114988208428258e-05, 0.27971595525741577, -0.6676027774810791, 0.5723554491996765, -0.41889867186546326, -0.789735734462738, 0.1893821358680725, -0.395210862159729, 1.3701469898223877, -0.37541553378105164, 0.11623840779066086, 0.4747196137905121, -0.10829775035381317, -0.5223144888877869, 0.6414547562599182, -0.43497395515441895, -0.7226434350013733, 0.2383156567811966, 0.44831493496894836, -0.32564496994018555, 0.0768238753080368, 0.8950856328010559, 1.1333160400390625, -0.32612141966819763, 0.6243934631347656, 0.44083479046821594, -0.17378003895282745, 1.0548609495162964, 0.43607059121131897, 0.8211146593093872, 0.03203963488340378, 0.3973768353462219, -0.30674630403518677, 0.4136809706687927, -0.3263440728187561, -0.09296809881925583, 0.5141136646270752, 0.6230145692825317, 0.038674935698509216, 0.28951936960220337, -0.6491292119026184, -0.4131365418434143, 0.17100045084953308, 0.6096344590187073, 1.6420385837554932, -0.2961944341659546, -0.3135887086391449, -1.0957796573638916, -0.47429192066192627, -0.13586187362670898, 0.3100105822086334, 0.3038104772567749, 0.384520560503006, -0.44287604093551636, -1.1016238927841187, 1.07620370388031, 0.27197563648223877, 0.6072872877120972, -0.713951826095581, -0.5238149166107178, -0.6538494229316711, -0.0544351302087307, -1.1581484079360962, -0.24833159148693085, 0.19131147861480713, -0.503437340259552, -0.4308992326259613, 0.5470582246780396, -0.1305413395166397, 0.42494580149650574, -0.4932311773300171, 1.1228176355361938, -0.12340319156646729, -0.37858542799949646, 0.010843469761312008, 0.7904481291770935, -0.550001859664917, -0.7781676054000854, 0.21018360555171967, 0.16231930255889893, -0.8924627304077148, 0.36180517077445984, 0.7092351913452148, 0.09091482311487198, 0.12135670334100723, -0.6230606436729431, -0.03168632835149765, 0.34949618577957153, 0.05947275459766388, 0.9494500160217285, -0.08767461031675339, -0.3313567340373993, -0.9382423162460327, 1.0707087516784668, -0.023294171318411827, -0.9268369078636169, 0.59306800365448, -0.7774577736854553, -0.04628284275531769, 0.8368203043937683, -0.06703706830739975, -0.18039733171463013, -0.7873550653457642, 0.2931668758392334, 0.1106073334813118, -0.11593350023031235, 0.5670347213745117, 0.5616369247436523, 0.1694902777671814, 0.3013719916343689, 0.6342165470123291, 0.2955697178840637, -0.16415125131607056, 0.6556153297424316, -0.49629902839660645, 0.07439673691987991, 0.3410132825374603, -0.025263730436563492, -0.3094748258590698, -0.3463048040866852, -0.7441864013671875, 0.12112512439489365, -0.09752574563026428, 0.5970765948295593, 0.18184375762939453, -0.13254383206367493, -0.5991969108581543, -1.1680071353912354, -0.4073535203933716, -1.246305227279663, 0.03618477284908295, 0.37135881185531616, 0.06360649317502975, 0.10118459165096283, -1.0608419179916382, -1.3395787477493286, -0.6772385239601135, -1.0633995532989502, -1.115505337715149, 0.806963324546814, -0.239752858877182, -0.3812187612056732, -0.21866685152053833, 0.1826714724302292, -0.2515762746334076, 0.5990776419639587, -0.6193562150001526, 1.0474433898925781, -0.13748382031917572, 0.17593663930892944, -0.3544743061065674, -0.35244083404541016, -0.12752875685691833, -0.9310498237609863, 0.735370397567749, -0.7317215204238892, 0.023706823587417603, -0.7181795239448547, -0.36919650435447693, 0.05180421844124794, 0.5032749176025391, 0.9356366991996765, 0.01847408339381218, -0.8351027965545654, 0.141372412443161, 1.309330701828003, -1.073830246925354, -0.18364284932613373, -0.1020604595541954, 0.5422791242599487, -0.1112029030919075, -0.2938031554222107, 0.40475380420684814, 0.14339447021484375, 0.4633376896381378, -0.14376679062843323, -0.1364438384771347, 0.37787893414497375, -0.322481244802475, 0.3470059931278229, 1.3288393020629883, 0.3650403916835785, -0.6066741943359375, -1.2966458797454834, 0.3190506100654602, -1.1703304052352905, -0.5690085291862488, 0.4892596900463104, 0.5257375240325928, 0.34486523270606995, -0.3381601870059967, -0.3182867467403412, 0.21661651134490967, 0.4257848858833313, 0.2395017147064209, -0.5330532193183899, -0.6636227369308472, 0.10280716419219971, 0.3638746440410614, 0.6891220808029175, 0.3824545741081238, -0.4054129421710968, 0.4941790699958801, 14.892424583435059, 1.2552833557128906, 0.28510963916778564, 0.5758330225944519, 0.43886709213256836, 0.48389819264411926, -0.30542731285095215, -0.2500946521759033, -1.0421044826507568, -0.1075516939163208, 1.5930744409561157, -0.2914184331893921, 0.6652207374572754, 0.3528916537761688, 0.3499149978160858, -0.2896115481853485, -0.3759121596813202, 0.4496571719646454, 0.29099124670028687, -1.4429174661636353, 0.3861689567565918, 0.008944676257669926, 0.03456271439790726, 0.7543157339096069, 0.3343673050403595, 0.618787944316864, 0.7662940621376038, -0.7771978378295898, 0.4839681386947632, 0.24188575148582458, 0.9660707712173462, -0.2029552012681961, 0.6703027486801147, 0.7415488362312317, -0.9951351284980774, -0.07131312042474747, -0.2041492611169815, -1.1074800491333008, -0.01302651409059763, 0.288061261177063, -1.0428595542907715, -0.4139205813407898, 0.02987666241824627, 0.42038390040397644, 0.5158753991127014, 0.17888472974300385, 0.025588588789105415, 0.5883007645606995, -0.4131307303905487, -0.1024007722735405, -0.16609178483486176, 0.6563361883163452, -0.0672982782125473, 0.1803281009197235, -0.04899287596344948, -0.1818922460079193, 0.06036577746272087, 0.35370802879333496, -1.1827127933502197, 0.11199108511209488, -0.6021474003791809, -0.6158879995346069, 0.32588309049606323, 0.9041379690170288, -0.1270013153553009, 0.4790351688861847, -0.35525912046432495, 0.1139468401670456, 0.7174558043479919, -0.017710046842694283, -0.4428097605705261, 0.2307216078042984, 0.26039353013038635, -0.6422943472862244, -0.24380308389663696, 0.5854446887969971, 0.11790797859430313, -0.155517116189003, -0.534908652305603, -0.4242573082447052, 0.27727290987968445, -0.7601411938667297, -0.5713915228843689, 0.587465226650238, -0.25644925236701965, 0.0006692444439977407, 0.43623045086860657, -0.8075347542762756, 0.12208118289709091, 0.3916083574295044, -1.4350786209106445, -0.7729437947273254, 0.6321288347244263, -0.3348656892776489, -0.708999752998352, 0.2716403901576996, 1.7777554988861084, 0.22989046573638916, -0.7463447451591492, -0.0005236928700469434, 0.581344485282898, -0.10162686556577682, -0.43023422360420227, -0.6396338939666748, 1.018385648727417, 0.4268992245197296, -0.1647350937128067, 0.48329395055770874, 0.17051592469215393, 0.08601342141628265, -1.0809869766235352, -0.4964945614337921, 1.0943188667297363, -0.9076835513114929, -0.11747339367866516, -0.7366258502006531, -0.42100006341934204, 0.22686155140399933, -0.019364487379789352, -0.13746774196624756, 0.5904571413993835, -0.1581897735595703, -0.3900909721851349, 0.202189102768898, -1.3578497171401978, 0.36185216903686523, 0.8613119721412659, -0.8765915036201477, 0.014362080954015255, 0.5627079606056213, 0.44843021035194397, -1.1271241903305054, -0.8664460778236389, -0.1337045282125473, 0.26384803652763367, 0.1057145744562149, 0.6566651463508606, -0.5272761583328247, 0.6446709036827087, 0.5166944861412048, -0.19552767276763916, -0.46642768383026123, 0.6037205457687378, -0.6347737312316895, -0.2838932275772095, -0.5426733493804932, 1.4153708219528198, -0.30272310972213745, 0.3207060694694519, 1.0490919351577759, 0.33103373646736145, 0.036340758204460144, -0.6967277526855469, -0.07784315198659897, -0.48243534564971924, -0.19243986904621124, 0.4776596128940582, -0.16092361509799957, -0.09177286177873611, 0.04997454211115837, 0.8243610858917236, 0.7920423746109009, -0.7362002730369568, -0.4033876955509186, 0.2839181125164032, -0.31060418486595154, 0.14111974835395813, -0.17686916887760162, -0.03323595970869064, -0.7713277339935303, 0.26977384090423584, -1.1154491901397705, 0.24583221971988678, -1.0818684101104736, -0.24690333008766174, 0.038961589336395264, 0.23232786357402802, 0.3068504333496094, 0.6063706874847412, -0.31323564052581787, -0.8680559992790222, -0.3677833080291748, -0.6144161224365234, 0.4096902012825012, 0.6436124444007874, -0.5679998993873596, 0.1587621569633484, -0.36784809827804565, 0.3897901177406311, 0.6009255647659302, 0.41018643975257874, -0.7020412087440491, -0.6280941367149353, -1.3593502044677734, 0.5050653219223022, 0.11834703385829926, -0.21191537380218506, -0.5069030523300171, 0.939907431602478, 0.38541579246520996, -0.3457632064819336, 0.17086471617221832, 0.31265124678611755, -1.2182554006576538, -0.006346056237816811, 0.6516434550285339, -0.5099524259567261, 0.6509931683540344, 0.6361172199249268, -0.6674203276634216, -0.12672211229801178, 0.5110538601875305, -0.38454872369766235, -0.7265490293502808, -0.4963432252407074, 0.07122931629419327, -0.6296073198318481, 0.2575969398021698, 0.07254299521446228, -0.21244986355304718, -1.1116774082183838, 0.13458169996738434, -0.05675062537193298, 0.6058104634284973, -0.31453901529312134, 0.29156240820884705, 0.30731457471847534, -0.5350372791290283, 0.118156798183918, 0.3671818673610687, -0.09721377491950989, -0.20029060542583466, 0.24095217883586884, 0.6739779114723206, -0.9634242653846741, 0.7595170140266418, 0.22839179635047913, 0.314340204000473, -1.4303163290023804, -0.3679888844490051, 0.46085742115974426, -0.5680536031723022, 0.021846888586878777, 0.6971491575241089, -0.9611847996711731, -1.3074219226837158, -0.09989053010940552, -1.4090656042099, -0.2357771247625351, -0.4947415590286255, 0.4658590257167816, 0.5053843259811401, 0.4273948073387146, -0.047311607748270035, -0.7653847932815552, -0.18409232795238495, -0.1594732254743576, -0.5076667070388794, 0.5334835052490234, 0.2742461562156677, -0.5679002404212952, -0.027253882959485054, -0.08762554824352264, -0.5061264038085938, 0.11888730525970459, -0.2368275374174118, -0.0033650691621005535, 0.15173879265785217, 0.4614327847957611, -0.5352503061294556, -0.25160038471221924, 0.1757512390613556, 0.2887689769268036, 0.407823771238327, 0.08274102956056595, -0.6330657601356506, 0.08780139684677124, 1.1125057935714722, 0.18109922111034393, -0.6058621406555176, -1.287377953529358, 1.0985897779464722, 0.7541366815567017, -0.8953084349632263, 0.5459092855453491, -0.380995512008667, -0.4708053469657898, 0.6029650568962097, 0.32604262232780457, 0.4964454770088196, 0.8099225163459778, 0.24766309559345245, -0.3218601942062378, 0.0018362049013376236, -0.6743301749229431, -0.026240278035402298, 0.19937372207641602, 0.40565305948257446, 0.7947731018066406, 0.4387257695198059, -0.21644233167171478, 0.7191058397293091, 0.2863372266292572, 0.6984661221504211, 0.20990605652332306, 0.9099261164665222, -0.27317360043525696, -0.021993065252900124, 0.00380029552616179, 0.8822311162948608, -0.7371158599853516, -1.064788579940796, -0.10921238362789154, 0.9280530214309692, 0.11754715442657471, 0.5706310868263245, 0.8007299900054932, 0.25777342915534973, 0.7524296641349792, 0.24392104148864746, 0.2520027458667755, -0.6478893756866455, -0.32328495383262634, -0.627278208732605, -0.021243451163172722, -0.018221529200673103, -0.3092985451221466, -0.10985585302114487, -0.784464955329895, -0.8907415270805359, 0.02789502963423729, 0.6591157913208008, 0.6381101012229919, 0.9891157746315002, 1.0473581552505493, 0.2934013307094574, -0.7860379219055176, -0.2118728905916214, -0.2245616465806961, -0.9530120491981506, 0.25918659567832947, -1.1471542119979858, -0.6454450488090515, 0.09997915476560593, -0.13551518321037292, -0.5233833193778992]}, "authors": [{"authorId": "1818378366", "name": "Hao Peng"}, {"authorId": "31961604", "name": "Qingqing Cao"}, {"authorId": "34176020", "name": "Jesse Dodge"}, {"authorId": "39139825", "name": "Matthew E. Peters"}, {"authorId": "152793333", "name": "Jared Fernandez"}, {"authorId": "20662387", "name": "Tom Sherborne"}, {"authorId": "46258841", "name": "Kyle Lo"}, {"authorId": "46181683", "name": "Sam Skjonsberg"}, {"authorId": "2268272", "name": "Emma Strubell"}, {"authorId": "2223952413", "name": "Darrell Plessas"}, {"authorId": "46181066", "name": "Iz Beltagy"}, {"authorId": "2158819969", "name": "Pete Walsh"}, {"authorId": "144365875", "name": "Noah A. Smith"}, {"authorId": "2548384", "name": "Hannaneh Hajishirzi"}], "references": [{"paperId": "ce913026f693101e54d3ab9152e107034d81fce1", "title": "Holistic Evaluation of Language Models"}, {"paperId": "b777aa86b5a1d49ce8eababc5c2ee56d3562801e", "title": "The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment"}, {"paperId": "fbd49b25bdab98c171af49962a41139c73dacbde", "title": "Specializing Smaller Language Models towards Multi-Step Reasoning"}, {"paperId": "bd8412c233bf3815d8e905911b58e12bd6f279da", "title": "Estimating the Carbon Footprint of BLOOM, a 176B Parameter Language Model"}, {"paperId": "296c4ff39184fb7787954bc4e1a5bde89e16c16e", "title": "Modeling Context With Linear Attention for Scalable Document-Level Translation"}, {"paperId": "fd7e88a2313e176315d99fc299277e752d7703b7", "title": "Efficient Methods for Natural Language Processing: A Survey"}, {"paperId": "00df5cf0d83c48657d453ab8083d8805a67f744f", "title": "Measuring the Carbon Intensity of AI in Cloud Instances"}, {"paperId": "e03609f2587f690867e7ea0bedaf0db25282c548", "title": "ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers"}, {"paperId": "3baf44af201d26337c33b38d291bb4932e2f230b", "title": "Characterizing the Efficiency vs. Accuracy Trade-off for Long-Context NLP Models"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "76cb108e37d9d2a06f5a49df04e993f5fb123c26", "title": "The Carbon Footprint of Machine Learning Training Will Plateau, Then Shrink"}, {"paperId": "b3848d32f7294ec708627897833c4097eb4d8778", "title": "LaMDA: Language Models for Dialog Applications"}, {"paperId": "2c6df83795cd5baf3b8c6e2639b85e2df0cee1d0", "title": "Sustainable AI: Environmental Implications, Challenges and Opportunities"}, {"paperId": "66d735987a31d666a6459566ae026c40ab9a1c3a", "title": "The Efficiency Misnomer"}, {"paperId": "8d911c2be6b68771cc1dae24fd3c5c5dc5261e81", "title": "Towards Efficient NLP: A Standard Evaluation and A Strong Baseline"}, {"paperId": "e1227daa4877599e13de41a5207a222e1b197456", "title": "RAFT: A Real-World Few-Shot Text Classification Benchmark"}, {"paperId": "3631f9a372bfaee6d5448780548fccc9e6e81d87", "title": "Facebook AI\u2019s WMT21 News Translation Task Submission"}, {"paperId": "d1e5ac96faf9165ea60bf593c0da2a1f55e390fd", "title": "IrEne: Interpretable Energy Prediction for Transformers"}, {"paperId": "d25bb256e5b69f769a429750217b0d9ec1cf4d86", "title": "Dynaboard: An Evaluation-As-A-Service Platform for Holistic Next-Generation Benchmarking"}, {"paperId": "77a096d80eb4dd4ccd103d1660c5a5498f7d026b", "title": "Dynabench: Rethinking Benchmarking in NLP"}, {"paperId": "054e307c1edf4b28137ffcbce980fe81f0647d20", "title": "Finetuning Pretrained Transformers into RNNs"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "8d48441fcf5dd900955036761972cecd18110813", "title": "NeurIPS 2020 EfficientQA Competition: Systems, Analyses and Lessons Learned"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "f4af3fe736b616452424d50cbd47d52f0a210582", "title": "OPUS-MT \u2013 Building open translation services for the World"}, {"paperId": "69a974cbdc35c47cc2d23bf68b23c895f6a4ea95", "title": "Overview of the SustaiNLP 2020 Shared Task"}, {"paperId": "687b13c44f849d23c2496996b5da83e706094db9", "title": "Beyond English-Centric Multilingual Machine Translation"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "5f2c083f80073c56c41c4ea66ae48312513c55aa", "title": "Energy and Policy Considerations for Modern Deep Learning Research"}, {"paperId": "0eab758429da5ba86206153a79d0295597a2dd02", "title": "A Systematic Methodology for Analysis of Deep Learning Hardware and Software Platforms"}, {"paperId": "3d5d954aaba0ca66d7f30ab8dbcc7d998e8c200f", "title": "MLPerf: An Industry Standard Benchmark Suite for Machine Learning Performance"}, {"paperId": "c26f90d4cfa33ceff373cf49c2a534e2004685da", "title": "HULK: An Energy Efficiency Benchmark Platform for Responsible Natural Language Processing"}, {"paperId": "74b4f16c5ac91e3e7c88ae81cc8c91416b71d151", "title": "Towards the Systematic Reporting of the Energy and Carbon Footprints of Machine Learning"}, {"paperId": "594a89505eb803280628198920e87cfc2bb82d94", "title": "MLPerf Inference Benchmark"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "df4e3aa275b8f81e22a5332ab550805083094dae", "title": "Findings of the Third Workshop on Neural Generation and Translation"}, {"paperId": "b3ea2d9c8e5ea3b87ace121f0bece71565abc187", "title": "Quantifying the Carbon Emissions of Machine Learning"}, {"paperId": "ea3e18c7b10a137d495054682c055a80b5be768c", "title": "Findings of the 2019 Conference on Machine Translation (WMT19)"}, {"paperId": "3c5f1ab37f70db503636075e15b3173f86eea00b", "title": "Green AI"}, {"paperId": "4754993282f677e1b43407518cc7bfc665a8a37e", "title": "Facebook FAIR\u2019s WMT19 News Translation Task Submission"}, {"paperId": "36b6abfb32ea56208a2858b558acbdd001c965e9", "title": "Findings of the Second Workshop on Neural Machine Translation and Generation"}, {"paperId": "b4bfadfca9742bb3ee98a0cd322d5ce4e59a3ceb", "title": "A Call for Clarity in Reporting BLEU Scores"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "af25e556302014d92499c98d993ee38113d870d6", "title": "Proceedings of the Ninth Workshop on Statistical Machine Translation"}, {"paperId": "25ca4a36df2955b345634b5f8a6b6bb66a774b3c", "title": "Parallel Data, Tools and Interfaces in OPUS"}, {"paperId": "4ba566223e426677d12a9a18418c023a4deec77e", "title": "A decision-theoretic generalization of on-line learning and an application to boosting"}, {"paperId": "8d188daf721fde8de4877718e96f89ae9d7a1925", "title": "Findings of the 2022 Conference on Machine Translation (WMT22)"}, {"paperId": "b88703f68f4abb9e69b86fb42dff85aa4a76fca4", "title": "Multilingual Translation from Denoising Pre-Training"}, {"paperId": "ec4490055de38e9fba38f6ac9ef50d9205df5067", "title": "Findings of the 2021 Conference on Machine Translation (WMT21)"}, {"paperId": "dc20ad0c2161e4d49b880c3d02277ecaf8f10c52", "title": "RAPL in Action: Experiences in Using RAPL for Power Measurements"}, {"paperId": "0c744c55d85654a4181f92e93dd63ec1066a52d6", "title": "Findings of the Fourth Workshop on Neural Generation and Translation"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "b) Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [Yes] We use the standard data splits for evaluation with the WMT14 DE-EN"}, {"paperId": null, "title": "Introducing pytorch fully sharded data parallel (FSDP) api, 2021"}, {"paperId": null, "title": "c) Did you include any new assets either in the supplemental material or as a URL?"}, {"paperId": null, "title": "If you are using existing assets (e.g., code, data, models) or curating/releasing new assets.. (a) If your work uses existing assets, did you cite the creators? [Yes] See Section"}, {"paperId": null, "title": "Did you discuss whether and how consent was obtained from people whose data you\u2019re using/curating? [No] We use WMT14 DE-EN, a popular long-standing corpus of parallel translation data"}, {"paperId": null, "title": "c) Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)?"}, {"paperId": null, "title": "b) Did you mention the license of the assets?"}, {"paperId": null, "title": "a) Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes] The URL to code is provided in"}, {"paperId": null, "title": "Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable?"}, {"paperId": null, "title": "c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation?"}, {"paperId": null, "title": "If you used crowdsourcing or conducted research with human subjects"}]}