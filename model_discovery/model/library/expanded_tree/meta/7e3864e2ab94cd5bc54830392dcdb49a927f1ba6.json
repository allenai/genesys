{"paperId": "7e3864e2ab94cd5bc54830392dcdb49a927f1ba6", "abstract": "In this work, we investigate the potential of a large language model (LLM) to directly comprehend visual signals without the necessity of fine-tuning on multi-modal datasets. The foundational concept of our method views an image as a linguistic entity, and translates it to a set of discrete words derived from the LLM's vocabulary. To achieve this, we present the Vision-to-Language Tokenizer, abbreviated as V2T Tokenizer, which transforms an image into a ``foreign language'' with the combined aid of an encoder-decoder, the LLM vocabulary, and a CLIP model. With this innovative image encoding, the LLM gains the ability not only for visual comprehension but also for image denoising and restoration in an auto-regressive fashion-crucially, without any fine-tuning. We undertake rigorous experiments to validate our method, encompassing understanding tasks like image recognition, image captioning, and visual question answering, as well as image denoising tasks like inpainting, outpainting, deblurring, and shift restoration. Code and models are available at https://github.com/zh460045050/V2L-Tokenizer.", "venue": "arXiv.org", "year": 2024, "citationCount": 4, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The Vision-to-Language Tokenizer is presented, abbreviated as V2T Tokenizer, which transforms an image into a ``foreign language'' with the combined aid of an encoder-decoder, the LLM vocabulary, and a CLIP model."}, "embedding": {"model": "specter_v2", "vector": [0.6691485643386841, 0.4294295012950897, 0.08819617331027985, 0.04009809345006943, -1.0144989490509033, -0.022702917456626892, 0.6512704491615295, -0.2681233584880829, -0.23597010970115662, -0.413156121969223, 0.8620386719703674, 0.6490026712417603, 0.6408185958862305, -0.10832822322845459, -0.4470576345920563, -0.14914344251155853, -0.8952028155326843, -0.5161792039871216, -0.19052407145500183, -0.45694899559020996, -0.14375384151935577, -0.6397951245307922, -1.0332343578338623, 0.6182364821434021, 0.166558638215065, 0.7501876354217529, 0.1299193799495697, 1.2666151523590088, -0.2317536324262619, 0.8258809447288513, 0.2334829866886139, -0.22545011341571808, 0.4365404546260834, -0.07183609902858734, -0.23923657834529877, 0.17218557000160217, 0.5580679774284363, -0.3569808900356293, -0.723752498626709, 0.6217749714851379, 0.052584391087293625, 0.2670961320400238, 0.763305127620697, -0.22894315421581268, -0.6651307344436646, 0.47813481092453003, 0.34316009283065796, 0.4738050699234009, 0.026759741827845573, -0.6037664413452148, 1.5514819622039795, -1.468277096748352, 0.599357008934021, 1.778212308883667, 0.4221750795841217, 0.38034385442733765, -0.09864690154790878, -0.3299100697040558, 0.5254455804824829, 0.3171256482601166, -0.9144466519355774, -0.4202892482280731, -0.08743955194950104, -0.22786062955856323, 1.1850931644439697, -0.3718988001346588, -0.21252717077732086, 0.6518970727920532, 0.25128644704818726, 1.4309035539627075, 0.06302307546138763, -0.8311946392059326, -0.34943193197250366, -0.41478466987609863, -0.17504404485225677, 0.4928840696811676, -0.7736256718635559, 0.16120082139968872, -1.0526504516601562, 0.31264564394950867, 0.3987208902835846, -0.33863139152526855, -0.4411731958389282, 0.15570944547653198, -0.549885630607605, 0.6312995553016663, 0.45369765162467957, 0.5297185778617859, -0.09388954937458038, 1.1014771461486816, 0.8707532286643982, 0.5409335494041443, 0.24399280548095703, 0.03996501863002777, 0.21180933713912964, 0.5510250329971313, -0.8532377481460571, 0.30758029222488403, -0.15223413705825806, 0.8494613170623779, -0.2519661486148834, 0.21777194738388062, -0.8855434060096741, 0.19796264171600342, 0.9950116276741028, 0.22251679003238678, 0.27540406584739685, -0.9903023838996887, -0.015972517430782318, -1.3401981592178345, 0.22724178433418274, -0.8878945112228394, 0.3079947233200073, -0.13234010338783264, -0.9658822417259216, -0.731845498085022, -0.36949270963668823, 0.3216613829135895, -1.0690380334854126, 0.9220796823501587, -0.5408754348754883, -0.014277951791882515, 0.056727077811956406, 0.5259150266647339, 0.5538482666015625, 1.132051944732666, 0.30633363127708435, -0.13716134428977966, 1.2939339876174927, -0.6210229396820068, -0.7977864742279053, -0.6381646394729614, 0.3556811809539795, -0.6080754995346069, 0.31964707374572754, 0.37529823184013367, -1.1605150699615479, -1.4252535104751587, -0.8820739388465881, -0.7610445618629456, -0.422503262758255, 0.39676064252853394, 0.6803341507911682, 0.22575192153453827, -1.1712207794189453, 0.39778217673301697, 0.2113727480173111, -0.44753512740135193, 0.6229137778282166, -0.35672083497047424, 0.14021867513656616, -0.6767042875289917, -1.2766202688217163, 0.5913581848144531, -0.3310701251029968, -0.5916270613670349, -0.4357508718967438, -0.4703899621963501, -1.4711846113204956, -0.18916812539100647, 0.4338066875934601, -0.5720509886741638, 1.04747474193573, -0.31637251377105713, -0.8518653512001038, 0.8941424489021301, -0.9006388187408447, -0.14784781634807587, 0.31994009017944336, -0.6820834279060364, -0.4508301615715027, 0.2111150175333023, 0.043468575924634933, 0.7624261975288391, 0.9469708204269409, -0.5916890501976013, 0.06513799726963043, 0.320605993270874, -0.4689611792564392, -0.16801311075687408, 0.17112167179584503, 0.9304913282394409, -0.5497539639472961, -0.9469543099403381, 0.1352456510066986, 0.7968607544898987, 0.11683749407529831, 0.31080129742622375, -0.19711412489414215, -0.49439507722854614, 0.9017841815948486, -0.29288145899772644, 0.3428895175457001, -1.2222975492477417, -0.6714474558830261, -0.29868465662002563, 0.0437118224799633, -0.5994330048561096, -1.19084632396698, 0.7027289271354675, -0.2160498946905136, 0.4775400459766388, -0.21522778272628784, -1.3014986515045166, 0.056577183306217194, -0.05953279510140419, -1.1544731855392456, 0.01959499903023243, 0.5307498574256897, 1.1479252576828003, -0.5498636364936829, -0.12139230966567993, -0.04087624326348305, 0.41711294651031494, -0.8190472722053528, 0.9095944762229919, -0.6136066317558289, 0.3171408176422119, -0.06946683675050735, -0.15101715922355652, 0.23708169162273407, 0.19338250160217285, -0.23649756610393524, -0.8175041675567627, 0.17210960388183594, -0.16541258990764618, -0.412026971578598, 1.6978645324707031, -0.38731279969215393, 1.24391508102417, 0.10961584746837616, -0.8289427757263184, 0.2941876947879791, 0.7272923588752747, -0.0635753720998764, -0.22457914054393768, 0.4334243834018707, -0.0162199679762125, -1.0417507886886597, -0.295998215675354, 0.6136730313301086, 0.41232985258102417, -0.47047895193099976, 0.1534762978553772, 0.33629119396209717, -0.8463605642318726, 0.4936254620552063, 0.6012819409370422, 0.6766451001167297, 0.4649064242839813, 0.31458866596221924, 0.18869131803512573, 0.3594736158847809, -0.8317953944206238, -0.40176135301589966, 0.9831828474998474, 0.7392053604125977, 1.8480582237243652, 0.3885321319103241, -0.6473439931869507, -0.3813210725784302, -0.4439336657524109, 0.8335973620414734, 1.3900002241134644, -0.025346139445900917, -0.3006203770637512, -0.7143619060516357, 0.2700880467891693, -0.3971656858921051, -0.19109836220741272, -0.6378857493400574, -0.04126325622200966, -0.19395358860492706, -0.6690340638160706, 0.892803966999054, 0.3289543092250824, 1.1011943817138672, -0.7793459296226501, 0.044817063957452774, -0.5302547812461853, 0.027123767882585526, -0.8472521305084229, -1.001198410987854, -0.043085623532533646, 0.10088156163692474, -0.21751898527145386, -0.3935648202896118, -0.4990382790565491, 0.39142605662345886, -0.5439576506614685, 0.7687656879425049, -0.47735607624053955, -1.1074249744415283, 0.653538703918457, 0.15796764194965363, -0.8090375065803528, -0.8471486568450928, -0.4443478584289551, -0.17315346002578735, 0.17083308100700378, -0.08157895505428314, 0.27937349677085876, 0.013234110549092293, -0.15283827483654022, -1.0622731447219849, 0.0672733336687088, 0.3816640377044678, -0.0397401861846447, 0.6774304509162903, 0.028049957007169724, 0.23903752863407135, -0.8443887829780579, 1.065751552581787, 0.26331827044487, 0.11157827079296112, 0.15822842717170715, -0.17752259969711304, -0.5277554988861084, 0.5567212104797363, -0.849582314491272, -0.435107558965683, -0.6082160472869873, 0.39982807636260986, -0.009002123959362507, -0.4859151840209961, 0.5406463146209717, 0.06352744251489639, 0.24108462035655975, 0.3282192051410675, 0.44996193051338196, 0.6268146634101868, -0.008016047067940235, 1.0787121057510376, -0.8260525465011597, 1.1066935062408447, 0.07589776813983917, 0.5528693199157715, 0.6148567795753479, -0.019473973661661148, -1.1431692838668823, -0.561863899230957, -0.375282883644104, -0.4147005081176758, -0.725458025932312, 0.5917040109634399, -0.9178031086921692, -0.58509361743927, 0.2546887695789337, -1.3750481605529785, 0.037411224097013474, -0.25243380665779114, -0.49055299162864685, -0.49590879678726196, -0.6261671781539917, -1.2807022333145142, -0.2904610335826874, -0.3663509488105774, -0.6767798662185669, 0.4810829758644104, -0.019671039655804634, -0.5220319628715515, -0.423086553812027, -0.4054121673107147, -0.13349753618240356, 0.9636803269386292, -0.16140379011631012, 0.9596456289291382, 0.29410722851753235, -0.31145599484443665, -0.5015573501586914, 0.14562879502773285, 0.917747437953949, -0.15940773487091064, 0.020073754712939262, -0.988195538520813, 0.16987855732440948, 0.08970655500888824, -0.4300489127635956, 0.6806772947311401, 0.6307050585746765, 0.4072149693965912, 0.37012234330177307, -0.16428226232528687, 0.22494575381278992, 1.331010341644287, -0.7178680300712585, 0.40041616559028625, -0.14546512067317963, 0.7379682660102844, 0.36081811785697937, -0.35535767674446106, 0.7051719427108765, -0.15497685968875885, -0.20054768025875092, -0.02587110549211502, -0.4186387062072754, -0.7282868027687073, -0.5760959386825562, 0.8344424962997437, 1.165399193763733, 0.38761112093925476, -0.29045790433883667, -0.8083897829055786, 0.7118107080459595, -0.9118746519088745, -0.8788937330245972, 0.5717336535453796, 0.3240639865398407, 0.2217242419719696, -0.3272536098957062, -0.6738436222076416, -0.21833042800426483, 0.5718436241149902, 0.6811284422874451, -0.2972218692302704, -0.47818079590797424, -0.5389074683189392, 0.5358389616012573, 0.05331127345561981, 0.7315068244934082, -0.43099138140678406, 0.35434842109680176, 14.593018531799316, 0.9858623743057251, -0.22135542333126068, 0.2964712679386139, 0.8533128499984741, 0.3192511200904846, -0.299897700548172, 0.02022910863161087, -0.2978125214576721, -0.6538090705871582, 0.46708250045776367, 0.19026081264019012, 0.40538284182548523, -0.12256641685962677, 0.5463083982467651, 0.041245825588703156, -0.5234041810035706, 0.8330094814300537, 0.942160964012146, -1.1669706106185913, 0.7356638312339783, -0.1186426430940628, 0.2726723849773407, 0.08617957681417465, 0.8560622334480286, 0.5950168371200562, -0.29964548349380493, -0.7064071893692017, 0.7948092818260193, 0.3451957404613495, 1.0134128332138062, 0.21809925138950348, 0.10599450021982193, 0.4049832224845886, -1.0500143766403198, -0.17179574072360992, -0.7041829228401184, -1.0208219289779663, 0.5198714733123779, 0.08242399990558624, -0.07285560667514801, -0.2380964159965515, -0.08004231005907059, 0.8349047303199768, 0.06664267927408218, 0.2727625072002411, -0.08403918147087097, 0.6519955992698669, 0.2406166046857834, 0.25722450017929077, -0.13565345108509064, 0.5366336107254028, 0.6957343220710754, 0.029420791193842888, 0.035492897033691406, 0.4092583954334259, 0.011176069267094135, 0.5855547189712524, -0.5708969235420227, 0.06642777472734451, -0.3151533007621765, -0.18205346167087555, -0.6835059523582458, 0.38561901450157166, 0.3742142617702484, 0.4595331847667694, -0.5428583025932312, 0.48450636863708496, -0.17244338989257812, 0.3960425555706024, -0.19182108342647552, -0.29951056838035583, 0.15227378904819489, -0.1424836665391922, 0.4329049587249756, 0.25075921416282654, -0.3155508041381836, -0.4429970681667328, -0.3940684497356415, -0.2143838256597519, 0.11205759644508362, -1.4037202596664429, -1.207565426826477, 0.7948733568191528, -0.245396688580513, -0.6576383709907532, 0.7476168274879456, -0.8981639742851257, -0.6978924870491028, 0.2495604306459427, -1.2767518758773804, -0.9403492212295532, 0.13426610827445984, -0.11240743100643158, 0.19196392595767975, 0.2216920107603073, 0.9566552639007568, -0.050723154097795486, 0.24631012976169586, -0.35723957419395447, 0.2088819444179535, 0.1370142251253128, 0.38562020659446716, -0.5519433617591858, 0.6067785024642944, 0.38250312209129333, -0.1321541666984558, -0.04592229053378105, 0.3582472503185272, 0.056610673666000366, -0.9021224975585938, 0.17603088915348053, 0.5004165768623352, -0.48064228892326355, -0.521440327167511, -0.8524125218391418, -0.8446733951568604, -0.06929190456867218, 0.58713698387146, -0.15871968865394592, 0.07421785593032837, -0.29997822642326355, -0.6534333229064941, -0.2865607440471649, -0.6442365646362305, 0.07237843424081802, 0.019400542601943016, -1.0147706270217896, -0.3100685477256775, 0.10031776130199432, 0.4305153489112854, -0.7333357930183411, -0.2423967570066452, -0.5420539975166321, 0.1142340824007988, -0.1354198455810547, 1.082517147064209, -0.2762739956378937, 1.013811469078064, 0.5793605446815491, -0.36706286668777466, -0.6816573143005371, 0.06841963529586792, -1.2136881351470947, 0.5503242611885071, 0.529834508895874, 0.24942143261432648, 0.02221529185771942, 0.005483267828822136, 0.5257775783538818, 0.4088412821292877, -0.24479849636554718, -0.6397095918655396, 0.028976168483495712, 0.3439387381076813, -1.120836853981018, -0.40805891156196594, -0.6221824884414673, -0.20241577923297882, -0.15852493047714233, -0.06656093895435333, 0.5773024559020996, -0.2847684919834137, -0.6403003334999084, 0.5309564471244812, 0.017990196123719215, 0.2028951197862625, -0.2934199571609497, -0.7202598452568054, -1.5767673254013062, 0.11550866067409515, -0.8986513614654541, 0.34009331464767456, -1.0999202728271484, -0.5823749303817749, 1.0353394746780396, 0.0652129128575325, -0.12289652973413467, 0.428745836019516, 0.043955884873867035, 0.04647437483072281, -0.5501455068588257, -0.5255919694900513, 0.7878445982933044, 1.3005616664886475, -1.1675851345062256, 0.4542243182659149, -0.2626776397228241, -0.14780384302139282, 0.43702787160873413, 0.09552793949842453, -0.3370239734649658, -0.8411506414413452, -1.1684623956680298, 0.16415853798389435, -0.10831518471240997, 0.288730263710022, -1.009305477142334, 0.5691294074058533, 0.6766148805618286, 0.2203778326511383, 0.010200563818216324, 0.7098608016967773, -0.756047248840332, -0.7773481607437134, 0.12070833146572113, -1.3629878759384155, -0.21924978494644165, 0.11939950287342072, 0.009849542751908302, -0.7985005974769592, 0.901594340801239, 0.1245342418551445, -1.216863751411438, -0.7658447027206421, 0.28459206223487854, -0.9038729667663574, 0.32050931453704834, -0.15750612318515778, -0.17397212982177734, -1.0573807954788208, -1.203757405281067, -0.4822843670845032, 0.15790286660194397, -0.42634543776512146, 1.1285830736160278, 0.9580432176589966, -0.8464103937149048, -0.46208885312080383, 0.2947995066642761, -0.14317180216312408, 0.05633024126291275, 1.081114649772644, 0.1583273857831955, -0.3918023109436035, 0.0636603832244873, 0.3796028196811676, 0.42962533235549927, -0.8037258386611938, 0.06508180499076843, 0.505694568157196, 0.025909287855029106, -0.37830454111099243, 1.0742619037628174, 0.05572173744440079, -0.22951368987560272, 0.2681678235530853, -1.1375839710235596, -0.414429247379303, -0.06005813926458359, 0.6798147559165955, -0.13019312918186188, -0.31721392273902893, -0.3833332359790802, -0.08455308526754379, 0.7509705424308777, -0.039361584931612015, -0.7896091938018799, 0.45282337069511414, -0.5907371044158936, -0.49643442034721375, 0.5162535309791565, 1.3674626350402832, -0.3621024191379547, -0.6284751296043396, -0.7101797461509705, -0.6906270384788513, -0.1821220964193344, 0.1298229992389679, -0.2298172265291214, -0.5179014801979065, 0.8192503452301025, 0.6047154664993286, 0.33238181471824646, 0.766351044178009, 0.02701779268682003, 0.5890661478042603, 0.5216408371925354, -0.4196878671646118, -0.7197288870811462, -0.0640096440911293, 1.059645652770996, 1.655766487121582, -0.6697725653648376, 0.4801011085510254, -0.47433650493621826, -0.899549126625061, 1.1326110363006592, -0.11500971019268036, -0.2905506491661072, 1.0346940755844116, -0.23121511936187744, 0.5353231430053711, 0.23022471368312836, -1.0592056512832642, -0.1160232350230217, 0.9522278308868408, 1.420637607574463, 0.5725042819976807, -0.13398073613643646, 0.1591033786535263, 0.9468256235122681, 0.15784834325313568, 0.2621261179447174, 0.9734442234039307, 0.4214304983615875, -0.41716474294662476, 0.06287869065999985, -0.34389302134513855, 0.31549495458602905, -0.7705652117729187, -0.37371519207954407, 0.15185697376728058, 0.5663149952888489, 0.464549720287323, 0.9077318906784058, 0.5759525299072266, 0.3692916929721832, 0.5069379806518555, 0.26970356702804565, 0.5856867432594299, -0.5408016443252563, -0.10312613844871521, -0.054319627583026886, -0.9576589465141296, 0.1025029793381691, -0.5016939640045166, -0.558509111404419, -0.48365482687950134, 0.24008291959762573, 0.7652809023857117, -0.4009077250957489, 0.07196097075939178, 1.1739805936813354, 0.5170227289199829, 0.2071923315525055, -0.43887898325920105, -0.601402997970581, -0.1867944449186325, -0.7057881355285645, -0.384439080953598, 0.09500141441822052, 0.3269926905632019, -0.08919179439544678, -0.45744889974594116, 0.6440169215202332]}, "authors": [{"authorId": "2288067906", "name": "Lei Zhu"}, {"authorId": "2290913195", "name": "Fangyun Wei"}, {"authorId": "2287888645", "name": "Yanye Lu"}], "references": [{"paperId": "985f0c89c5a607742ec43c1fdc2cbfe54541cbad", "title": "Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "376f494126d1ea4f571ea0263c43ac2b6331800a", "title": "SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs"}, {"paperId": "f22d71c7ce9720ba1f717a4f1181488200e78198", "title": "LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day"}, {"paperId": "3a79545719fb193a6b4042ef7d1d87cfd267be06", "title": "Controllable Text-to-Image Generation with GPT-4"}, {"paperId": "0d1c76d45afa012ded7ab741194baf142117c495", "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"}, {"paperId": "9c3a9b4821daa03cb5369041d59d2714329a3811", "title": "Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large Language Models"}, {"paperId": "a03efb04dfb2490f90c1a953c49a577594852320", "title": "Towards Accurate Image Coding: Improved Autoregressive Image Generation with Dynamic Vector Quantization"}, {"paperId": "42a30dc5470f54ec249f25d3c31e05d7c376c8e3", "title": "VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks"}, {"paperId": "f4793adffd6f67ffcb93ccfc5672ab301b8a2b96", "title": "PMC-VQA: Visual Instruction Tuning for Medical Visual Question Answering"}, {"paperId": "b6d6c33298b852cf63edac233deca70530d69a2a", "title": "PaLM 2 Technical Report"}, {"paperId": "3b508a48a4b48d2a16dd790a2a04ffcf51c0b4a6", "title": "SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models"}, {"paperId": "d6d3604f369bb0415cbe814e43ca3131323b03e2", "title": "Otter: A Multi-Modal Model with In-Context Instruction Tuning"}, {"paperId": "570079bbdd8758dfe865097e05719313c9c1301a", "title": "LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model"}, {"paperId": "7e32aac43e9f1df49e116add03327ee6f365dbf3", "title": "mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality"}, {"paperId": "ca6a2bc279be5a3349a22bfd6866ed633d18734b", "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"}, {"paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8", "title": "Visual Instruction Tuning"}, {"paperId": "3ab661db57d924f4ff1706e05ac807873ca00e0a", "title": "RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment"}, {"paperId": "bce55193d9a887ad00774a9134df08cd521a85ae", "title": "DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task"}, {"paperId": "a757999ed260d7bc45484dc6b4456bf33fe6f679", "title": "LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention"}, {"paperId": "bda43eaf9a239a5e03f928b1537309f2e7637fda", "title": "Regularized Vector Quantization for Tokenized Image Synthesis"}, {"paperId": "af997821231898a5f8d0fd78dad4eec526acabe5", "title": "Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "d3bc7ba19e274bb6fb5e055a3f1b62924c731432", "title": "Language Quantized AutoEncoders: Towards Unsupervised Text-Image Alignment"}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "74eae12620bd1c1393e268bddcb6f129a5025166", "title": "Improving alignment of dialogue agents via targeted human judgements"}, {"paperId": "599be9043ef3571f65758cf36e184c9dc1781baf", "title": "BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers"}, {"paperId": "914254fac74a2da051cccf6ca16afcaad416a079", "title": "AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model"}, {"paperId": "9695824d7a01fad57ba9c01d7d76a519d78d65e7", "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "8fbc2d349d3d0945efa5e92fd3713734ce63d19e", "title": "Autoregressive Image Generation using Residual Quantization"}, {"paperId": "f4df78183261538e718066331898ee5cad7cad05", "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"}, {"paperId": "2f3efe44083af91cef562c1a3451eee2f8601d22", "title": "WebGPT: Browser-assisted question-answering with human feedback"}, {"paperId": "47df3fd32d00220c85c2c51a571254fd99b2ecc7", "title": "MetaICL: Learning to Learn In Context"}, {"paperId": "9c7a2cd13b783bb73ad2d1ec2880bdd9b995cbdc", "title": "Vector-quantized Image Modeling with Improved VQGAN"}, {"paperId": "01b5412f3d17e90e09226d7c40ad4d4468a1414d", "title": "Multimodal Few-Shot Learning with Frozen Language Models"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "50796b0f3edf9cb5ff1e447c298b33755378aa4f", "title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling"}, {"paperId": "954121c58819c9348518e241bb4a6a7ce19aaee1", "title": "Generating Diverse Structure for Image Inpainting With Hierarchical VQ-VAE"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "47f7ec3d0a5e6e83b6768ece35206a94dc81919c", "title": "Taming Transformers for High-Resolution Image Synthesis"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "6be216d93421bf19c1659e7721241ae73d483baf", "title": "Generating Diverse High-Fidelity Images with VQ-VAE-2"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "f466157848d1a7772fb6d02cdac9a7a5e7ef982e", "title": "Neural Discrete Representation Learning"}, {"paperId": "5bbb6f9a8204eb13070b6f033e61c84ef8ee68dd", "title": "Deep Reinforcement Learning from Human Preferences"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "62a956d7600b10ca455076cd56e604dfd106072a", "title": "Exploring Models and Data for Image Question Answering"}, {"paperId": "696ca58d93f6404fea0fc75c62d1d7b378f47628", "title": "Microsoft COCO Captions: Data Collection and Evaluation Server"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Stanford alpaca: an instruction-following llama model (2023)"}, {"paperId": null, "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90% chatgpt quality"}, {"paperId": null, "title": "Training data and evaluation for open-sourced chinese instruction-following large language models"}]}