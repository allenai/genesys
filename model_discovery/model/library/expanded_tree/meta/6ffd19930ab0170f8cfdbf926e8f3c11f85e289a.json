{"paperId": "6ffd19930ab0170f8cfdbf926e8f3c11f85e289a", "abstract": "Recent years have seen an increase in the development of large deep learning (DL) models, which makes training ef\ufb01-ciency crucial. Common practice is struggling with the trade-off between usability and performance. On one hand, DL frameworks such as PyTorch use dynamic graphs to facilitate model developers at a price of sub-optimal model training performance. On the other hand, practitioners propose various approaches to improving the training ef\ufb01ciency by sacri\ufb01cing some of the \ufb02exibility, ranging from making the graph static for more thorough optimization (e.g., XLA) to customizing optimization towards large-scale distributed training (e.g., DeepSpeed and Megatron-LM). In this paper, we aim to address the tension between usability and training ef\ufb01ciency through separation of concerns. Inspired by DL compilers that decouple the platform-speci\ufb01c optimizations of a tensor-level operator from its arithmetic de\ufb01nition, this paper proposes a schedule language, Slapo, to decouple model execution from de\ufb01nition. Speci\ufb01cally, Slapo works on a PyTorch model and uses a set of schedule primitives to convert the model for common model training optimizations such as high-performance kernels, effective 3D parallelism, and ef\ufb01cient activation checkpointing. Compared to existing optimization solutions, Slapo progressively optimizes the model \u201cas-needed\u201d through high-level primitives, and thus preserving programmability and debuggability for users to a large extent. Our evaluation results show that by scheduling the existing hand-crafted optimizations in a systematic way using Slapo, we are able", "venue": "arXiv.org", "year": 2023, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2302.08005", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "Inspired by DL compilers that decouple the platform-speci\ufb01c optimizations of a tensor-level operator from its arithmetic de\ufb01nition, this paper proposes a schedule language, Slapo, to decouple model execution from de\ufb01nition, and preserves programmability and debuggability for users to a large extent."}, "embedding": {"model": "specter_v2", "vector": [-0.05166717246174812, 0.17243430018424988, -0.8895046710968018, 0.056238722056150436, -0.014988592825829983, -0.002919756807386875, 0.4757201373577118, -0.1096491664648056, -0.4668610095977783, -0.6344448924064636, 0.16168294847011566, -0.5091880559921265, 0.803402304649353, 0.06876354664564133, -0.06331170350313187, -0.0802212655544281, -0.97388756275177, -0.008803104981780052, 0.23430182039737701, -0.22619226574897766, -0.09983468800783157, 0.3118952214717865, -1.7156994342803955, 0.30373379588127136, 0.2762713134288788, 0.7163010835647583, -0.30554449558258057, 1.1934620141983032, -0.4356980323791504, 0.6968007683753967, 0.21475636959075928, 0.06415053457021713, 0.2921715974807739, 0.44518807530403137, -0.20604802668094635, -0.10536178201436996, 0.46954408288002014, -0.5703094601631165, -0.3865881860256195, 0.7029518485069275, 0.014424366876482964, 0.03616953268647194, -0.30824390053749084, -1.295127272605896, 0.6614084243774414, 0.22587406635284424, 0.015260253101587296, 0.8707476258277893, -1.10899817943573, -0.1695132702589035, 1.0243185758590698, -0.961969256401062, 0.05922197550535202, 0.7876989841461182, 0.4705503582954407, 0.4424148499965668, -0.6617808938026428, -0.16951073706150055, 0.3729144334793091, -0.16143015027046204, -0.7292410135269165, -0.6112747192382812, -0.12620909512043, -0.3083302676677704, 1.8756462335586548, -0.10391037911176682, -0.16615231335163116, 0.08329498767852783, 0.22934158146381378, 1.0635753870010376, -0.059991203248500824, -0.895391583442688, -0.031001627445220947, -0.19372232258319855, 0.42618486285209656, 1.035903811454773, -0.03508463501930237, 0.6267766356468201, -1.0602209568023682, -0.2456260770559311, 0.5320342183113098, 0.05347438156604767, 0.4969726800918579, -0.6199508309364319, -0.16125164926052094, 0.5916745662689209, 0.43380358815193176, 0.3586643636226654, -0.22833658754825592, 1.3566445112228394, 1.0936087369918823, 0.3595353662967682, -0.14948348701000214, 0.18515154719352722, -0.28604817390441895, 0.3608464002609253, -0.7894718050956726, 0.10429318994283676, 0.31684499979019165, 0.4513918161392212, 0.34999802708625793, 0.3099701702594757, -0.6182482838630676, -0.2631371319293976, 0.8143079876899719, -0.12160254269838333, 0.06650304049253464, -0.663314163684845, 0.3310414254665375, -0.539752185344696, -0.2865675091743469, -0.24238543212413788, -0.17632213234901428, -0.34203752875328064, -0.9355984330177307, -0.46512770652770996, -0.7200701832771301, -0.5670371055603027, -0.7159212827682495, 0.4491496980190277, -0.18495692312717438, 0.7492257952690125, 0.2846359610557556, 0.7032998204231262, 0.5561236143112183, 0.4572226405143738, 0.2546756863594055, 0.4717244803905487, 0.7717241048812866, -1.3219592571258545, -0.025573566555976868, -1.0975703001022339, 1.0616734027862549, -0.22429263591766357, 0.16083694994449615, -0.4215536415576935, -1.2141276597976685, -1.0022269487380981, -0.997025191783905, 0.3304196000099182, -0.3051663935184479, 0.3121994733810425, 1.932350993156433, 0.19097480177879333, -1.2769933938980103, 0.9966736435890198, -0.8198019862174988, 0.43746417760849, 0.2250029444694519, 0.5862469673156738, 0.34098705649375916, -0.06811213493347168, -0.7584348320960999, 0.024988729506731033, 0.3853936791419983, -0.6811075210571289, -0.61106276512146, -1.205062985420227, -0.8192787766456604, 0.10661713033914566, 0.2692432403564453, -0.6429677605628967, 1.3904814720153809, 0.008235086686909199, -1.1719768047332764, 0.8014422655105591, -0.13988225162029266, 0.035549554973840714, -0.0820683017373085, 0.058087170124053955, -0.5255581140518188, -0.17586462199687958, -0.3499087393283844, 0.37948814034461975, 0.8048429489135742, -0.2688293159008026, -0.0398157462477684, 0.18262030184268951, 0.06499464064836502, 0.16248750686645508, -0.3491438925266266, 1.0863280296325684, -0.36590665578842163, 0.2619200050830841, 0.18030206859111786, 0.5764907002449036, -0.3244350254535675, -0.13481341302394867, -0.36673954129219055, -0.286578893661499, 0.9662572741508484, 0.43464359641075134, 1.0688493251800537, -1.1937376260757446, -0.42418232560157776, -0.04211580008268356, 0.3526962995529175, 9.041341400006786e-05, -0.25792163610458374, 0.579195499420166, -0.7107869982719421, 0.312714546918869, -0.06474389880895615, -0.9628897309303284, 0.09746374934911728, -0.2039135843515396, -0.6442047357559204, -0.2983398139476776, 0.1971849650144577, 0.6381597518920898, -0.5991609692573547, 0.1723497360944748, -0.3126043379306793, 0.2607477605342865, -1.3756754398345947, 1.3646022081375122, -0.4249694049358368, 0.14851142466068268, 0.22542119026184082, -0.10742615163326263, 0.2652594745159149, -0.696007490158081, 0.7967171669006348, -0.4264644384384155, -0.2553022503852844, 0.40508928894996643, -0.4813924729824066, 1.4101231098175049, -0.6730749011039734, 0.26411667466163635, 0.45726707577705383, -0.5727363228797913, 0.07289581000804901, 0.21884821355342865, 0.03244761750102043, -0.21743357181549072, -0.035820476710796356, 0.5785021185874939, -0.28392142057418823, 0.47907155752182007, 1.1377837657928467, 0.536482572555542, -0.2696760594844818, 0.34048178791999817, 0.42905911803245544, -0.48079314827919006, 0.37388867139816284, 0.4249929189682007, 0.9146969318389893, 0.36115190386772156, -0.17865492403507233, -0.059586040675640106, 0.5266453623771667, -0.5449691414833069, -0.05838519334793091, 0.10960196703672409, 0.5456685423851013, 0.41820648312568665, 1.050550937652588, -0.7699828147888184, -0.39172565937042236, 0.22260630130767822, 0.6616148948669434, 1.8521544933319092, -0.16188085079193115, -0.24051371216773987, -0.4584032893180847, -0.7006102204322815, 0.09011897444725037, -0.13403543829917908, -0.1415332555770874, -0.2895984947681427, -0.9469792246818542, -1.226563811302185, 0.9526875615119934, 0.3654288053512573, 1.0649049282073975, -0.25306180119514465, -0.7765660881996155, -0.8118776082992554, 1.0115289688110352, -0.766609787940979, -0.4561627507209778, 0.7756926417350769, -0.8835186958312988, -0.15540573000907898, 0.5647715926170349, -0.17053531110286713, 0.2946435213088989, -0.14517782628536224, 1.1917896270751953, 0.283450186252594, -0.3402750492095947, -0.2994319200515747, 0.8828721046447754, -0.5165429711341858, -0.4348680377006531, 0.40095075964927673, -0.08150721341371536, -0.3323916792869568, 0.16409523785114288, 0.1697700023651123, 0.2365439236164093, 0.04472237080335617, -0.7160327434539795, 0.3096606135368347, 0.3415329158306122, 0.042418472468853, 0.6735926866531372, -0.08465968817472458, -0.5026645660400391, -1.392698049545288, 1.033415675163269, 0.15318317711353302, -0.8063649535179138, 0.018794028088450432, -0.7080782055854797, 0.3143705725669861, 0.6754211187362671, -0.6799476742744446, -0.09742938727140427, -1.2399243116378784, 0.3126692473888397, -0.8425681591033936, -0.11069624125957489, 0.016495410352945328, 0.5237558484077454, -0.4948611557483673, 0.5737833976745605, 0.10966972261667252, 0.7006217241287231, -0.1546570062637329, 0.44672465324401855, -1.5185009241104126, 0.4094352424144745, -0.5171502232551575, 0.31198638677597046, -0.16505677998065948, 0.17471209168434143, -0.4670777916908264, -0.35911282896995544, -0.4479120969772339, -0.13540993630886078, -0.22940000891685486, 0.08045977354049683, -0.614780843257904, -1.1286834478378296, -0.22468982636928558, -1.2770488262176514, -0.8141933679580688, 0.17742879688739777, -0.4023931324481964, 0.03925330191850662, -1.136029601097107, -1.4345992803573608, 0.10989854484796524, -0.7765423655509949, -1.7283356189727783, 0.6604225635528564, 0.06512977182865143, 0.08980268985033035, -0.618854820728302, 0.06452948600053787, -0.9264806509017944, 1.1802325248718262, -0.13089406490325928, 0.8389344215393066, 0.23197422921657562, -0.3989182412624359, 0.32967841625213623, -0.34472984075546265, 0.6089392900466919, -1.2092835903167725, 0.4126075208187103, -0.9070791006088257, 0.2597532570362091, -0.44422298669815063, -0.585003137588501, 0.07694894075393677, 0.0018561865435913205, 1.0613017082214355, 0.09724857658147812, -0.3260246515274048, 1.0190438032150269, 1.800313949584961, -1.1995911598205566, 0.19101153314113617, 0.11622601002454758, 1.3951976299285889, 0.007675467059016228, -0.4534219801425934, 0.47977349162101746, -0.3042488992214203, 0.4522364139556885, 0.4956721365451813, -0.4984757602214813, -0.2780827581882477, -0.15760891139507294, 0.6435161232948303, 1.469425916671753, 0.44072526693344116, 0.8565404415130615, -1.0629823207855225, 0.08218897134065628, -1.286685824394226, -0.3308001756668091, 0.5131126046180725, 0.827519416809082, 0.1498214602470398, -0.20047082006931305, -0.0802270919084549, -0.13655246794223785, 0.3387705385684967, 0.6591000556945801, -0.472777783870697, -1.2971714735031128, 0.7271917462348938, 0.9022971391677856, 0.9697860479354858, 0.5518035292625427, 0.06143679842352867, 0.502875804901123, 14.36352252960205, 0.9047220945358276, -0.4749254286289215, 0.4841647744178772, 0.4210648238658905, 0.45765992999076843, -0.2951171398162842, 0.35921579599380493, -1.5336229801177979, -0.27824994921684265, 1.6572449207305908, 0.06765572726726532, 0.39812996983528137, 0.5656645894050598, -0.14673833549022675, 0.0866541787981987, -0.3962782323360443, 0.4641874432563782, 0.13761496543884277, -1.6570035219192505, -0.012599585577845573, 0.34711864590644836, 0.307043194770813, 0.6989287734031677, 0.677571177482605, 0.8977296948432922, 0.6629383563995361, -0.32424697279930115, 0.6215626001358032, 0.022259486839175224, 1.4750685691833496, -0.5020663142204285, 0.516432523727417, 0.6579643487930298, -0.7958172559738159, 0.3671068251132965, -0.21997590363025665, -1.4601165056228638, 0.002865184098482132, 0.245389923453331, -0.9156261682510376, -0.2031206339597702, -0.43299543857574463, 0.7495568990707397, 0.2512497305870056, 0.389766663312912, -0.42451637983322144, 0.45320531725883484, 0.07705871015787125, 0.244672954082489, 0.12803669273853302, 0.41726624965667725, -0.22620952129364014, 0.020298833027482033, -0.45854121446609497, -0.5299316048622131, 0.48570019006729126, 0.11832088232040405, -0.708271861076355, -0.5524243116378784, -0.1370624601840973, -0.11296779662370682, -0.1863313764333725, 1.0746763944625854, 0.2795926332473755, 0.1546616554260254, -0.5381377935409546, 0.1944827437400818, 0.8234066963195801, -0.054376374930143356, -0.5620437264442444, -0.1219942718744278, 0.7839910387992859, -0.5615572333335876, -0.2516947388648987, 0.06479315459728241, -0.7510006427764893, -0.8434851169586182, -0.8773508667945862, -0.6927995085716248, 0.26259154081344604, -0.35465356707572937, -0.267094224691391, 0.664251983165741, 0.04313816502690315, -0.23787091672420502, 0.3082466721534729, -1.0505684614181519, -0.4649102985858917, 0.6130968928337097, -1.8374141454696655, -0.1835835874080658, 0.37304359674453735, -0.34893956780433655, -0.8447962999343872, 0.06015833094716072, 1.4972721338272095, 0.3542758822441101, -0.8675253391265869, -0.061787161976099014, -0.24312391877174377, 0.02727634087204933, -0.2616901099681854, -0.943554162979126, 1.2549997568130493, 0.6433908939361572, -0.4796137809753418, 0.2865516245365143, -0.0555977001786232, 0.11967919021844864, -0.9402985572814941, -0.1598069965839386, 0.40661269426345825, -0.668232262134552, 0.3507358729839325, -0.6643271446228027, -0.5973213315010071, 0.426494300365448, 0.25620266795158386, 0.33646467328071594, 0.4075031876564026, 0.364068865776062, -0.6540578007698059, -0.6365864872932434, -0.5737630724906921, 0.18480975925922394, 0.4571512043476105, -0.8679895997047424, 0.11739136278629303, 0.27033624053001404, 0.735019862651825, -1.504642128944397, -0.9244214296340942, -0.3342433273792267, -0.30749234557151794, -0.5416996479034424, 1.2582744359970093, -0.2812853753566742, 1.0496519804000854, 0.803755521774292, 0.01922774687409401, -0.6061978340148926, 0.4598316252231598, -1.1968485116958618, -0.10547798871994019, -0.3337961435317993, 0.4104757010936737, -0.48335564136505127, 0.5972124934196472, 0.6637012362480164, -0.26131853461265564, -0.3210706114768982, -0.007059023715555668, 0.029723534360527992, -0.23939840495586395, -0.6943859457969666, 0.5271234512329102, -0.09196354448795319, -0.16641242802143097, 0.2891206741333008, 0.44652894139289856, 0.9393323063850403, 0.11616593599319458, -0.3830242156982422, 0.6270436644554138, 0.12399018555879593, -0.6101482510566711, -0.5888396501541138, -0.5595970153808594, -1.1611146926879883, 0.05554812029004097, -1.4354174137115479, -0.2133946716785431, -0.3230862319469452, -0.5902276039123535, -0.36705413460731506, -0.05050838366150856, 0.2766190469264984, 0.4906463623046875, -0.3831804096698761, -0.5853433012962341, -0.13032272458076477, -0.7296450138092041, 0.5798158645629883, 0.865648090839386, 0.08029969781637192, 0.05984966456890106, -0.19987674057483673, 0.12601320445537567, 0.3099667727947235, 0.6171260476112366, -0.4574340581893921, -0.6890319585800171, -1.3880902528762817, 0.19403691589832306, 0.3299238383769989, 0.21845978498458862, -1.003792643547058, 0.6441006660461426, 0.16607961058616638, -0.5178021192550659, 0.4136374890804291, -0.12276379019021988, -0.6794781684875488, -0.5400775671005249, 0.5178127288818359, -0.42156481742858887, 0.43686747550964355, 0.9243446588516235, -0.7478170990943909, -0.29172834753990173, 0.8581675887107849, -0.07389285415410995, -0.6934812664985657, -1.3373252153396606, 0.5555822849273682, -0.0029013394378125668, 0.048648446798324585, -0.25477010011672974, 0.33238354325294495, -1.1489551067352295, 0.4619145095348358, 0.1368570178747177, 0.23712806403636932, 0.2057860642671585, 0.37521713972091675, 0.0833577811717987, -1.0335824489593506, 0.4964030385017395, 0.5275320410728455, -0.20362457633018494, 0.28248167037963867, 0.5153584480285645, 0.6949392557144165, -1.2107627391815186, 0.12551352381706238, -0.13590694963932037, 0.2419791966676712, -0.7191880941390991, 0.08616164326667786, 0.7215901017189026, -0.8911687135696411, -0.34330645203590393, 1.0822850465774536, -0.432051420211792, -1.00484299659729, -0.1147039607167244, -1.066148281097412, -0.15623369812965393, -0.815328061580658, 0.5606693625450134, 0.09158892929553986, 0.3584944009780884, 0.27820059657096863, -0.753342866897583, -0.13520434498786926, -0.20068815350532532, -0.40394896268844604, 0.43637800216674805, 0.3625257909297943, -0.9118987917900085, 0.3362661302089691, 0.7488751411437988, -0.5263174772262573, -0.8650215864181519, -0.5829896926879883, -0.25650355219841003, -0.20066870748996735, 0.6177509427070618, -0.11686619371175766, -0.7957364916801453, 0.9677652716636658, -0.1392662227153778, 0.25341546535491943, 0.3090270161628723, -0.7024402618408203, 0.37707096338272095, 0.2084166407585144, 0.19946879148483276, -0.3565969169139862, -0.5345558524131775, 1.0206204652786255, 0.7911829948425293, -0.4875759482383728, 0.7966628074645996, -0.5034365653991699, -0.9590827822685242, 0.9702709317207336, 0.5408827066421509, -0.273529589176178, 0.7136275768280029, 0.3063865303993225, -0.13796892762184143, -0.03686697408556938, -1.0144487619400024, -0.5134634971618652, 0.5730318427085876, 0.7948290705680847, 0.5646902322769165, 0.4702391028404236, 0.2134459763765335, 0.24778471887111664, 0.254769504070282, 0.03099953383207321, 0.5217240452766418, 0.985436737537384, -0.011849012225866318, -0.4606701135635376, -0.27157580852508545, 0.4219598174095154, -0.7262880206108093, -0.5679877996444702, 0.7086668610572815, 1.0550827980041504, 0.18609608709812164, 0.06752444803714752, 0.6717762351036072, -0.3974279463291168, 0.631360650062561, 0.03716364875435829, 0.3958456218242645, -0.9756870269775391, -0.5207948088645935, -0.25579598546028137, -0.38130608201026917, -0.36724305152893066, -0.08563225716352463, -0.31213757395744324, -0.8962352275848389, -0.9753388166427612, 0.8123152256011963, 0.04316854104399681, 0.5887673497200012, 0.732798159122467, 0.9848109483718872, 1.154471755027771, -0.0032536780927330256, -1.1291559934616089, -0.5803426504135132, -0.13886772096157074, -0.08119182288646698, -0.6065475344657898, -0.3893708288669586, -0.15946972370147705, -0.28242653608322144, -0.37847664952278137]}, "authors": [{"authorId": "2108844339", "name": "Hongzheng Chen"}, {"authorId": "2271831246", "name": "Cody Hao Yu"}, {"authorId": "2254011493", "name": "Shuai Zheng"}, {"authorId": "2283747113", "name": "Zhen Zhang"}, {"authorId": "2242087633", "name": "Zhiru Zhang"}, {"authorId": "2253834098", "name": "Yida Wang"}], "references": [{"paperId": "6d5c5e0df5dc4bd0bcd524d2a22d65d672bd0b74", "title": "TensorIR: An Abstraction for Automatic Tensorized Program Optimization"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "bc8b82e8eb0b0714892e4ec7a54ebdf47c4fde96", "title": "Reducing Activation Recomputation in Large Transformer Models"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "cd733ce920e055415e9a9a7d90d3ec89f8750866", "title": "MiCS: Near-linear Scaling for Training Gigantic Model on Public Cloud"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "27e200d3e46a54d2ba16d9173ba6f711eac18adc", "title": "HeteroFlow: An Accelerator Programming Model with Decoupled Data Placement for Software-Defined FPGAs"}, {"paperId": "5a38d67cd2f3881fa3b80f2099460ecf06ba7005", "title": "torch.fx: Practical Program Capture and Transformation for Deep Learning in Python"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "509b16378deec0fb6bbec1d7aeb32a4bdeedddb1", "title": "GSPMD: General and Scalable Parallelization for ML Computation Graphs"}, {"paperId": "774591fdd988eaaff3917e7c5171d044b0843e63", "title": "Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM"}, {"paperId": "148d65a0f0e53a3e824b6dfdbbe9cc8bf623090f", "title": "LazyTensor: combining eager execution with domain-specific compilers"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "725264948d7b6946259af5b8d966e996b9570f99", "title": "DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters"}, {"paperId": "1882f194cb43828852cc052887671e55a80f945a", "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"}, {"paperId": "3c55dd7b8da5c7b47e91b2e749c264f50d007cd4", "title": "Dynamic Tensor Rematerialization"}, {"paperId": "09bda461aa4911d0513e8e46dd39a4113947e450", "title": "Ansor : Generating High-Performance Tensor Programs for Deep Learning"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "3fd7c9ba742dd2b435afa75217847e5087e2f2a8", "title": "PipeDream: generalized pipeline parallelism for DNN training"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "fd431005d26100f5453590080683cbae9dc1189f", "title": "Checkmate: Breaking the Memory Wall with Optimal Tensor Rematerialization"}, {"paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3", "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "33715e08c111625427ddea46f3da52bba090e6da", "title": "HeteroCL: A Multi-Paradigm Programming Infrastructure for Software-Defined Reconfigurable Computing"}, {"paperId": "d79a26226393f687ddbc375e32055b40b8ad8d38", "title": "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism"}, {"paperId": "cb91c2f8d3cac0b655a39be318b603334eb18987", "title": "Learning to Optimize Tensor Programs"}, {"paperId": "8c7310477fd027193cd040288f0aa9824c80b91f", "title": "Tiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "4954fa180728932959997a4768411ff9136aac81", "title": "TensorFlow: A system for large-scale machine learning"}, {"paperId": "1c4e9156ca07705531e45960b7a919dc473abb51", "title": "Wide Residual Networks"}, {"paperId": "942deb7d865b7782c03176d95e3a0d56cb71009e", "title": "Training Deep Nets with Sublinear Memory Cost"}, {"paperId": "4d23db55e6671a82c95dacec33b2967a4b8b677d", "title": "Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines"}, {"paperId": "d668f12be54174141e6197fad737006b7b0c0571", "title": "PyTorch"}, {"paperId": null, "title": "Fully sharded data parallel: faster ai training with fewer gpus"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "ec3071fb918ad69ec80df1ca9cf1fdeb386a9603", "title": "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning"}, {"paperId": null, "title": "JAX: composable transformations of Python+NumPy programs"}, {"paperId": null, "title": "TorchVision maintainers and contributors. Torchvision: Pytorch's computer vision library"}, {"paperId": "6a630ac89d7c0a57eb7bf4cb30dd5946bcf3ccce", "title": "google,\u6211,\u8428\u5a1c"}, {"paperId": "67207a79a346e53d3210960bc5e15a69e7338d43", "title": "This paper is included in the Proceedings of the 16th USENIX Symposium on Operating Systems Design and Implementation."}, {"paperId": null, "title": "Optimizing compiler for machine learning"}, {"paperId": null, "title": "xformers: A modular and hackable transformer modelling library"}, {"paperId": "1d27a56a8133f947a5a0217b00241d26f585f834", "title": "This paper is included in the Proceedings of the 16th USENIX Symposium on Operating Systems Design and Implementation."}, {"paperId": "0a5593b5fc34f976015c0151f75217fc2351b991", "title": "Journal of Graph Algorithms and Applications Subgraph Isomorphism in Planar Graphs and Related Problems"}, {"paperId": null, "title": "Torchdynamo overview"}, {"paperId": null, "title": "Getting started - accelerate your scripts with nvfuser"}]}