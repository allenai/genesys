{"paperId": "be6f989f0104fb8f6b9322073b07c2cfeffbacbf", "abstract": "Recently, large language model (LLM) based artificial intelligence (AI) systems have demonstrated remarkable capabilities in natural language understanding and generation. However, these models face a significant challenge when it comes to sensitive applications, such as reasoning over medical knowledge and answering medical questions in a physician-like manner. Prior studies attempted to overcome this challenge by increasing the model size (>100B) to learn more general medical knowledge, while there is still room for improvement in LLMs with smaller-scale model sizes (<100B). In this work, we start from a pre-trained general LLM model (AntGLM-10B) and fine-tune it from a medical beginner towards a medical expert (called AntGLM-Med-10B), which leverages a 3-stage optimization procedure, i.e., general medical knowledge injection, medical domain instruction tuning, and specific medical task adaptation. Our contributions are threefold: (1) We specifically investigate how to adapt a pre-trained general LLM in medical domain, especially for a specific medical task. (2) We collect and construct large-scale medical datasets for each stage of the optimization process. These datasets encompass various data types and tasks, such as question-answering, medical reasoning, multi-choice questions, and medical conversations. (3) Specifically for multi-choice questions in the medical domain, we propose a novel Verification-of-Choice approach for prompting engineering, which significantly enhances the reasoning ability of LLMs. Remarkably, by combining the above approaches, our AntGLM-Med-10B model can outperform the most of LLMs on PubMedQA, including both general and medical LLMs, even when these LLMs have larger model size.", "venue": "arXiv.org", "year": 2023, "citationCount": 6, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work starts from a pre-trained general LLM model and fine-tune it from a medical beginner towards a medical expert, which leverages a 3-stage optimization procedure, i.e., general medical knowledge injection, medical domain instruction tuning, and specific medical task adaptation."}, "embedding": {"model": "specter_v2", "vector": [-0.07587026059627533, 0.9259381890296936, -0.42612430453300476, -0.1898529827594757, -0.6539164185523987, -0.3794899880886078, 0.1678522825241089, -0.01942950114607811, -0.17582933604717255, -0.04948650300502777, 0.24049881100654602, -0.7379204630851746, -0.06702770292758942, 0.2620100975036621, 0.012634252198040485, 0.22449463605880737, -0.7304349541664124, 0.8836700320243835, -0.24935422837734222, -0.6675655245780945, -0.46093878149986267, -0.46431490778923035, -0.2213577926158905, 0.3757839798927307, 0.7980563640594482, 0.2564018666744232, -0.2369498461484909, 1.0225669145584106, -0.21597570180892944, 0.7711790800094604, 0.49847227334976196, -0.49681180715560913, 0.17506879568099976, -0.12821531295776367, -0.6248395442962646, 0.15167127549648285, 0.012753800489008427, -0.4042407274246216, -0.3970007002353668, 0.23427355289459229, 0.0630611926317215, 0.15733757615089417, 0.5930773019790649, -0.8076719045639038, -0.5508257150650024, 0.6744763851165771, 0.8653377890586853, 0.6318264007568359, 0.23510748147964478, -0.13497216999530792, 1.3488208055496216, -0.9932627081871033, 0.6847746968269348, 1.39724600315094, 0.12235376983880997, 1.0191879272460938, 0.07607544958591461, -0.4136205017566681, 0.2926095426082611, -0.07603388279676437, -0.5661889910697937, -0.2030206024646759, -0.292560338973999, -0.41995978355407715, 1.1244972944259644, -0.38329848647117615, -0.3585282862186432, 0.3070071339607239, 0.2791803777217865, 1.202791452407837, -0.03447926789522171, -0.7186398506164551, 0.01819525845348835, 0.4620620906352997, 0.18572352826595306, 1.3097995519638062, -0.45674338936805725, 0.07733400166034698, -0.5524476170539856, -0.3817860782146454, 0.7202169299125671, -0.3342975080013275, -0.392499178647995, -0.008905226364731789, -0.5947354435920715, 0.5888410210609436, 0.13866057991981506, 1.0148533582687378, -0.38861480355262756, 0.009905057027935982, -0.20278604328632355, 0.5345054864883423, -0.6968281269073486, 0.8714823722839355, -0.5998545289039612, 0.5339351296424866, -0.4902048408985138, 0.39344263076782227, 0.11532352864742279, 0.5984512567520142, -0.4868471324443817, -0.24525901675224304, -1.4821052551269531, 0.1948576420545578, 1.429564118385315, -0.2976149916648865, 0.5139318704605103, -0.9132457375526428, 0.11409587413072586, -0.16958342492580414, 0.7140328288078308, -0.4893653690814972, -0.6043859720230103, -0.12797123193740845, -0.502749502658844, -1.2739710807800293, -0.2105875015258789, -0.41110849380493164, -1.0567947626113892, 1.015071988105774, -0.03772065043449402, -0.2550748586654663, 0.24574993550777435, 0.6708599328994751, 1.2423646450042725, 0.4790700078010559, 0.4037035405635834, 0.0967179462313652, 1.2970397472381592, -0.5533667206764221, -0.7832865118980408, -1.0862054824829102, 0.9428009390830994, 0.2534037232398987, 0.16566796600818634, -0.15323013067245483, -1.202162504196167, -0.7857845425605774, -0.5796947479248047, -0.026125241070985794, -0.2752024829387665, 0.33617785573005676, 0.9223273396492004, 0.140064537525177, -1.025456428527832, 0.21901601552963257, 0.37624111771583557, -0.30073365569114685, -0.16324220597743988, -0.009851212613284588, 0.0884232223033905, -0.8270522952079773, -1.7132081985473633, 0.2778012454509735, 0.09923231601715088, -0.8610502481460571, -0.3454177677631378, -0.6381227970123291, -1.2068796157836914, -0.2576851546764374, 0.6556787490844727, -1.1723299026489258, 1.595450758934021, 0.49009066820144653, -1.018066167831421, 0.9801229238510132, -0.37043434381484985, 0.21943196654319763, 0.0984850600361824, 0.1650109887123108, -0.8661553859710693, 0.019939331337809563, -0.015828633680939674, 0.7548335194587708, 0.011121178977191448, -0.4028404951095581, -0.15443168580532074, 0.6165930032730103, 0.43996626138687134, -0.6170943379402161, 0.3426041305065155, 0.5907359719276428, -0.3888479471206665, -0.22678594291210175, 0.24446223676204681, 0.8101113438606262, -0.5758039355278015, 0.2267763316631317, -0.1860756129026413, -0.988456666469574, -0.15253613889217377, -0.220457524061203, 1.1520349979400635, -0.6347244381904602, -0.7123218774795532, -0.4135989844799042, 0.3136414587497711, -0.24468058347702026, -0.7149268984794617, 0.3572012186050415, -0.7495192289352417, 0.3394429087638855, -0.8143390417098999, -0.47847896814346313, -0.06195998564362526, -0.17637352645397186, -0.36893388628959656, -0.6171154975891113, 0.5234658122062683, 1.3564704656600952, -0.7417324781417847, -0.4490770697593689, -0.1159636527299881, -0.32210108637809753, -1.1191015243530273, 1.4097436666488647, -0.6902703642845154, 0.5858932733535767, -0.357742577791214, 0.18932212889194489, -0.11566493660211563, -0.6482947468757629, -0.18705333769321442, -0.3584393262863159, 0.10617969930171967, 0.09865719079971313, -0.41386768221855164, 1.4671918153762817, -0.05283621326088905, -0.11328618973493576, 0.14439652860164642, -0.8064968585968018, 0.01707572303712368, 0.978428840637207, 0.0918179526925087, -0.19973179697990417, 0.1808800846338272, 0.344514936208725, -0.1493280827999115, -0.7627671957015991, -0.1775159388780594, 0.12937937676906586, -0.34070563316345215, -0.012633341364562511, 0.5176323652267456, -0.2748817205429077, 0.5025103688240051, 0.5666265487670898, 1.0173759460449219, -0.35334518551826477, 0.6544790267944336, 0.08177485316991806, 0.7686569690704346, -0.513922393321991, 0.2644834816455841, 0.7256239056587219, 0.5859794616699219, 0.7586134672164917, 0.22814030945301056, -0.7066993713378906, 0.3630612790584564, 0.07881324738264084, 0.323536217212677, 1.1304136514663696, -0.3318847417831421, -0.269314169883728, -0.5870257019996643, -0.5347629189491272, -0.3855949342250824, 0.5773028135299683, -0.32672080397605896, -0.2772272527217865, -0.3876948356628418, -1.1127853393554688, 0.7883897423744202, 0.16116833686828613, 0.8810054063796997, -0.47153550386428833, -0.049565255641937256, -0.04155978187918663, -0.3912525177001953, -0.9338517189025879, -0.3717041015625, -0.22048810124397278, -0.45313650369644165, -0.34715908765792847, -0.21051335334777832, -0.24094314873218536, 0.23874138295650482, -1.1411423683166504, 0.958743155002594, -0.42730826139450073, -0.7640286684036255, 0.7530733942985535, 0.7650930285453796, -0.38183632493019104, -1.0614832639694214, -0.5785363912582397, -0.39489737153053284, -0.21541868150234222, 0.2432543784379959, 0.9013229608535767, -0.0479300357401371, 0.1410418599843979, -0.731541633605957, -0.08664815127849579, 0.43842828273773193, 0.268220454454422, 0.2629687488079071, -0.220814049243927, 0.11116194725036621, -1.2725014686584473, 1.0181223154067993, -0.012843945063650608, -0.12810461223125458, 0.6300056576728821, -0.7168108820915222, -0.10733940452337265, 0.547607421875, -0.408216655254364, -0.3083527684211731, -1.2630478143692017, -0.09752574563026428, 0.5428974032402039, -0.5775665044784546, 0.6487823128700256, 0.039790086448192596, 0.08956406265497208, 0.49457767605781555, 0.19595837593078613, 0.19459274411201477, 0.025065088644623756, 0.7166789174079895, -0.5726556777954102, 0.2069104015827179, 0.05721944570541382, 0.22701480984687805, -0.19909077882766724, -0.06720764935016632, -0.3028939962387085, -0.5540685653686523, -0.09168176352977753, 0.2130100578069687, 0.03743688389658928, 0.3368307948112488, -0.5068213939666748, -0.6767742037773132, -0.3483428955078125, -0.6948105096817017, -0.14093948900699615, 0.1166979968547821, -0.3422725200653076, -0.08821173757314682, -0.9176518321037292, -1.183090329170227, -0.2722582221031189, -0.03609655797481537, -0.9798846244812012, 0.4507642686367035, -0.006787350866943598, -0.5553436279296875, -0.6010914444923401, -0.11461152881383896, 0.3326718211174011, 0.6053812503814697, -0.28450021147727966, 1.537511944770813, -0.025467051193118095, -0.21499039232730865, -0.3371574580669403, 0.4459128677845001, -0.13114312291145325, 0.2982827425003052, -0.03301026299595833, -0.3644765615463257, 0.40794724225997925, 0.3565140664577484, -0.23341691493988037, -0.27267932891845703, 0.38347160816192627, 0.6807368993759155, 0.14654481410980225, -0.4912939667701721, -0.1610613465309143, 1.0119911432266235, -0.12159764021635056, -0.11888287216424942, -0.01724213734269142, 0.677473247051239, 0.6932697892189026, 0.30684465169906616, 0.5446696281433105, 0.5789046883583069, 0.18562567234039307, -0.33562955260276794, -0.49194765090942383, 0.14864495396614075, -0.20133890211582184, 0.16474312543869019, 0.8357061743736267, 0.4151807725429535, -0.19893595576286316, -1.5255241394042969, 0.5401334762573242, -1.1296623945236206, 0.054443832486867905, 0.762035608291626, 0.41015028953552246, 0.817618727684021, -0.401925265789032, -0.6672046184539795, -0.13700814545154572, 0.25990012288093567, -0.2631913721561432, -0.18244078755378723, -0.16776111721992493, 0.03258794918656349, 0.34246399998664856, -0.27605119347572327, 0.8434433937072754, -0.2139636129140854, 0.3249233663082123, 14.816052436828613, 0.4582279622554779, 0.2074657827615738, 0.5114374160766602, 0.8508020043373108, 0.7579604387283325, -0.5321749448776245, -0.18630605936050415, -0.9605007171630859, -0.526078462600708, 1.1907001733779907, 0.14655888080596924, 0.13420046865940094, 0.02007240802049637, -0.04161384329199791, 0.04260586202144623, -0.7434287667274475, 0.7617149353027344, 0.6666977405548096, -1.0735286474227905, 0.9173843860626221, 0.02286638878285885, 0.1290360689163208, -0.2692028284072876, 0.7815497517585754, 0.807788610458374, 0.37238723039627075, -0.8224586248397827, 0.03679516911506653, 0.595697283744812, 0.6963005661964417, 0.17514744400978088, 0.6975277066230774, 0.741598904132843, -0.6636813282966614, -0.6253705024719238, -0.2299650013446808, -0.537826657295227, 0.16272301971912384, 0.18975050747394562, -0.9883617758750916, -0.1906425505876541, -0.5089598894119263, 0.18424436450004578, 0.1484273076057434, 0.44362974166870117, -0.24010059237480164, 0.5590762495994568, 0.4870005249977112, 0.27371007204055786, 0.10550647974014282, 0.7175665497779846, 0.5134969353675842, -0.28563812375068665, 0.13979960978031158, 0.6307650208473206, 0.2094367891550064, 0.6816480755805969, -0.4126785397529602, -0.010193399153649807, -0.3160841166973114, -0.5133005976676941, -0.36004355549812317, 0.6475715637207031, 0.5246803164482117, 0.27349069714546204, -0.2523178160190582, -0.03828779608011246, 0.2939516305923462, 0.3946526348590851, -0.17416414618492126, -0.23700466752052307, 0.27488699555397034, -0.2840256989002228, -0.335239052772522, 0.705832302570343, -0.190931037068367, -0.4531177282333374, -0.6588003039360046, -0.9655076861381531, 0.7445893287658691, -0.7540077567100525, -0.7984926700592041, 0.8009809851646423, -0.25866517424583435, -0.6911671757698059, 0.13939650356769562, -1.0586460828781128, 0.1278821974992752, 0.33743247389793396, -1.2537446022033691, -0.4372996687889099, 0.1598326712846756, -0.13649897277355194, -0.33712515234947205, -0.04888506978750229, 1.443923830986023, -0.07467561960220337, -0.38300496339797974, 0.0021507192868739367, -0.42080947756767273, -0.017300331965088844, 0.4552339017391205, -0.9310708045959473, 0.5129750370979309, 0.03356363624334335, -0.276820570230484, 0.6395261883735657, 0.02654534950852394, 0.08091700822114944, -0.8209723234176636, -0.12641680240631104, 0.8014696836471558, -1.5178765058517456, -0.5902588963508606, -0.6421250700950623, -0.853582501411438, 0.0932917594909668, 0.35588377714157104, -0.609943687915802, 0.6927623748779297, -0.25644201040267944, -0.037239380180835724, -0.31981992721557617, -1.4355813264846802, 0.4249984920024872, 0.4759458303451538, -0.5671841502189636, -0.9074137210845947, 0.3779793977737427, 0.6553673148155212, -1.0316598415374756, -0.7058252096176147, 0.31310057640075684, -0.285848468542099, 0.32874688506126404, 0.9059112071990967, -0.9372831583023071, 0.7151474952697754, 0.6332993507385254, 0.28137123584747314, -0.6640437245368958, -0.5349066257476807, -0.9408151507377625, 0.23327991366386414, -0.20722876489162445, 1.2553404569625854, -0.6129035949707031, -0.35416585206985474, 1.683267593383789, 0.44112512469291687, -0.7211840748786926, -0.6434007287025452, 0.24009864032268524, 0.23768091201782227, -0.11299155652523041, 0.34460747241973877, 0.0736909881234169, 0.12092624604701996, 0.14497089385986328, 0.6502950191497803, 1.345404863357544, -0.5777373313903809, -0.385612815618515, 0.21372520923614502, -0.2951749563217163, -0.37138763070106506, -0.23650605976581573, -0.1389939785003662, -1.4304618835449219, -0.3895634412765503, -0.8911399245262146, 0.5179290771484375, -1.360243558883667, -0.6032270789146423, 0.3900023102760315, -0.26882311701774597, 0.1703891009092331, -0.21045967936515808, -0.8516181111335754, -1.1390304565429688, -0.9423633217811584, -0.27097252011299133, 0.3010105788707733, 1.0586742162704468, -0.7773553729057312, 0.3168489336967468, -0.21337658166885376, -0.6000922918319702, 0.1588560789823532, 0.17546868324279785, -0.31921055912971497, -0.8213083148002625, -0.9646398425102234, 0.15974919497966766, 0.3652782142162323, -0.03149183467030525, -0.4761292636394501, 0.7479130029678345, 0.28303641080856323, -0.3644787669181824, 0.16426433622837067, 0.1974557787179947, -0.8640622496604919, -0.4474852383136749, 0.6389473080635071, -0.9849963188171387, -0.020233353599905968, 0.3606794774532318, -0.8493661880493164, -0.187715083360672, 0.2711068391799927, -0.0021613400895148516, -1.426620364189148, -0.4174882471561432, 0.4954007565975189, -1.0577770471572876, 0.3538161516189575, -0.39720967411994934, 0.4270927309989929, -0.7790440320968628, -0.475471168756485, -0.1549900323152542, 0.9295120239257812, -0.7107852697372437, 0.6571994423866272, 0.6913093328475952, -0.7666378617286682, -0.2519926130771637, 0.19810178875923157, 0.1585390865802765, -0.07528208196163177, 0.6427392363548279, 0.15408636629581451, -0.30435916781425476, 0.8297260403633118, 0.518817126750946, 0.47595810890197754, -0.6676034927368164, 0.0948532447218895, 0.8726425766944885, -0.5497657656669617, -0.03132955729961395, 1.5175666809082031, 0.0601462796330452, -1.2124943733215332, 0.3014124035835266, -1.2801910638809204, -0.8549037575721741, -0.899852454662323, 0.7211984992027283, -0.25747430324554443, -0.22437222301959991, 0.3206043243408203, -0.5752183198928833, 0.38321053981781006, -0.14059127867221832, -0.7346445918083191, 0.2492455691099167, -0.1140342429280281, -0.543968915939331, 0.6262724995613098, 0.039429936558008194, -0.5796018838882446, 0.2919180989265442, -0.17666736245155334, 0.1828685849905014, 0.3108972907066345, -0.07030429691076279, -0.8987691402435303, -0.21060343086719513, 0.5962727069854736, 0.4819050133228302, -0.027526216581463814, 0.3912152647972107, 0.058097872883081436, 0.1572956144809723, 0.9667671918869019, -0.019740495830774307, -0.2875330150127411, -0.4383070170879364, 0.5568678379058838, 1.4404340982437134, -1.2957996129989624, -0.18831753730773926, -0.4640607535839081, -1.033971905708313, 0.8592413663864136, 0.6649450063705444, 0.4374750554561615, 0.9153252840042114, -0.33185309171676636, 0.5789527893066406, -0.42167559266090393, -1.0771760940551758, 0.010584400966763496, 1.0928468704223633, 1.060177206993103, 0.9710187315940857, 0.19903187453746796, -0.18945318460464478, 1.3005242347717285, 0.18597397208213806, 0.6196653842926025, 0.7434966564178467, 0.44945040345191956, -0.05253208428621292, -0.40786588191986084, -0.08442453294992447, 0.5585741400718689, -0.564890444278717, -0.5416003465652466, -0.3935753107070923, 0.4577390253543854, 0.5327652096748352, 0.9620985388755798, 0.05163385346531868, 0.38925108313560486, 0.8575528264045715, 0.5844499468803406, 0.14706994593143463, -0.9530429840087891, -0.07855416089296341, -0.3123205006122589, -0.4194449186325073, -0.11548274755477905, -0.2516098916530609, -0.014272944070398808, -0.7177783250808716, 0.7287822961807251, 0.5682234764099121, 0.4637005627155304, -0.10196443647146225, 1.2497721910476685, 0.768308699131012, 0.6055760383605957, -0.39095067977905273, 0.8824223875999451, -0.34226664900779724, -0.8683140277862549, 0.20490211248397827, -0.6863448023796082, 0.13731759786605835, -0.3258281648159027, -0.23064589500427246, -0.32181674242019653]}, "authors": [{"authorId": "2171247031", "name": "Qiang Li"}, {"authorId": "2215685191", "name": "Xiaoyan Yang"}, {"authorId": "2268638594", "name": "Haowen Wang"}, {"authorId": "2269511483", "name": "Qin Wang"}, {"authorId": "2267013360", "name": "Lei Liu"}, {"authorId": "2269510514", "name": "Junjie Wang"}, {"authorId": "2269473361", "name": "Yang Zhang"}, {"authorId": "2269473798", "name": "Mingyuan Chu"}, {"authorId": "2260288151", "name": "Sen Hu"}, {"authorId": "2257103276", "name": "Yicheng Chen"}, {"authorId": "2180240771", "name": "Yue Shen"}, {"authorId": "2268644119", "name": "Cong Fan"}, {"authorId": "2260010886", "name": "Wangshu Zhang"}, {"authorId": "2260601133", "name": "Teng Xu"}, {"authorId": "2269769748", "name": "Jinjie Gu"}, {"authorId": "2257349883", "name": "Jing Zheng"}, {"authorId": "2269750295", "name": "Guannan Zhang"}], "references": [{"paperId": "6d67bd189269706c20d1e40d77fa21c379e3e3ca", "title": "Customizable Combination of Parameter-Efficient Modules for Multi-Task Learning"}, {"paperId": "bddb9d818b73de0a06197a6966673c7eb63c9146", "title": "Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory"}, {"paperId": "ce2272a439ba89f1ea0a822c8d19078732d75e5d", "title": "PromptCBLUE: A Chinese Prompt Tuning Benchmark for the Medical Domain"}, {"paperId": "4b0b56be0ae9479d2bd5c2f0943db1906343c10f", "title": "Chain-of-Verification Reduces Hallucination in Large Language Models"}, {"paperId": "916c798b34d55a78c47ae44906fe018a60a30613", "title": "GPTEval: A Survey on Assessments of ChatGPT and GPT-4"}, {"paperId": "0f8d12775a4685575f1489796b5dee9e11fbdfb5", "title": "OphGLM: Training an Ophthalmology Large Language-and-Vision Assistant based on Instructions and Dialogue"}, {"paperId": "5dea206e2a36e672f197252bdd27d156d058f48c", "title": "FinGPT: Open-Source Financial Large Language Models"}, {"paperId": "ce913026f693101e54d3ab9152e107034d81fce1", "title": "Holistic Evaluation of Language Models"}, {"paperId": "5459cab5dcf3c65c6b4f63b3d9f1e376f722bbcb", "title": "HuatuoGPT, towards Taming Language Model to Be a Doctor"}, {"paperId": "e154dd91de91558f9d671370754eace62a54c911", "title": "A study of generative large language model for medical research and healthcare"}, {"paperId": "b6d6c33298b852cf63edac233deca70530d69a2a", "title": "PaLM 2 Technical Report"}, {"paperId": "1c5bc4f10b95a90d0283d0aacc94332aae508169", "title": "Huatuo-26M, a Large-scale Chinese Medical QA Dataset"}, {"paperId": "34d28a5d698d6b93f891d70b5008eb899bc08ee5", "title": "Large language models challenge the future of higher education"}, {"paperId": "2223b92d9c5cb9b2594c1585eac03b32c2f313cb", "title": "The promise of large language models in health care"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "64565e59f40e794b73b5eb52b8a7796c6ff88541", "title": "Z-Code++: A Pre-trained Language Model Optimized for Abstractive Summarization"}, {"paperId": "bc8b82e8eb0b0714892e4ec7a54ebdf47c4fde96", "title": "Reducing Activation Recomputation in Large Transformer Models"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "741776172685b9717159a9fcd21841461bb33b14", "title": "MedMCQA : A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "aa7ed7e04182d0588bb53376e472afb59e236c36", "title": "Rethinking Explainability as a Dialogue: A Practitioner's Perspective"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "50796b0f3edf9cb5ff1e447c298b33755378aa4f", "title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling"}, {"paperId": "fc97c3f375c7228a1df7caa5c0ce5d2a6a171bd7", "title": "What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "e75f77c9daf3e7e1d705ca209d713249be553c6a", "title": "Predicting conversion to wet age-related macular degeneration using deep learning"}, {"paperId": "79ca998550d0810d7b30a2cc63d7da040bf0f594", "title": "Expert Discussions Improve Comprehension of Difficult Cases in Medical Image Assessment"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "0c3c4c88c7b07596221ac640c7b7102686e3eae3", "title": "PubMedQA: A Dataset for Biomedical Research Question Answering"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "23325e2ef18ecb799af81d39c29d5870d2c0dab4", "title": "PubMed: The Bibliographic Database"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Capabilities of gpt-4"}, {"paperId": null, "title": ": Instruction-based fine-tuning of llms"}, {"paperId": "c8ed1d29289ca8d6030e3912ed3242dea0bd6f44", "title": "The technique of report."}, {"paperId": null, "title": "and post-thinking"}]}