{"paperId": "34c2939d3147946b2ac218e7857e1bc4c8902679", "abstract": "The BLOOM model is a large publicly available multilingual language model, but its pretraining was limited to 46 languages. To extend the benefits of BLOOM to other languages without incurring prohibitively large costs, it is desirable to adapt BLOOM to new languages not seen during pretraining. In this work, we apply existing language adaptation strategies to BLOOM and benchmark its zero-shot prompting performance on eight new languages in a resource-constrained setting. We find language adaptation to be effective at improving zero-shot performance in new languages. Surprisingly, we find that adapter-based finetuning is more effective than continued pretraining for large models. In addition, we discover that prompting performance is not significantly affected by language specifics, such as the writing system. It is primarily determined by the size of the language adaptation data. We also add new languages to BLOOMZ, which is a multitask finetuned version of BLOOM capable of following task instructions zero-shot. We find including a new language in the multitask fine-tuning mixture to be the most effective method to teach BLOOMZ a new language. We conclude that with sufficient training data language adaptation can generalize well to diverse languages. Our code is available at https://github.com/bigscience-workshop/multilingual-modeling.", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2022, "citationCount": 57, "influentialCitationCount": 7, "openAccessPdf": {"url": "http://arxiv.org/pdf/2212.09535", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work applies existing language adaptation strategies to BLOOM and finds language adaptation to be effective at improving zero-shot performance in new languages and concludes that with sufficient training data language adaptation can generalize well to diverse languages."}, "embedding": {"model": "specter_v2", "vector": [-0.05398138239979744, 0.6687502861022949, -0.18264487385749817, -0.38974282145500183, 0.043413929641246796, -0.39766955375671387, 0.9246545433998108, -0.19483889639377594, -0.4071221351623535, -0.44347065687179565, 0.5900213718414307, -0.16405344009399414, 0.423597514629364, 0.1520380675792694, -0.211447611451149, 0.2872474193572998, -0.5302491784095764, 0.5558310151100159, -0.11861611902713776, -0.6971925497055054, -0.20823124051094055, -0.8497620820999146, -0.7628496289253235, 0.1505093276500702, 0.1264200657606125, -0.04766537621617317, 0.45405277609825134, 0.8977533578872681, -0.5605659484863281, 0.39429011940956116, 0.2489471137523651, -0.14579245448112488, 0.3487216830253601, 0.07408198714256287, -0.16714194416999817, 0.02933764085173607, 0.555195689201355, -0.8236856460571289, -0.22125916182994843, 0.6036509275436401, -0.23102416098117828, 0.3517935574054718, 0.014424972236156464, -0.43988674879074097, -0.6249487996101379, 0.8811755776405334, 0.74503093957901, 0.7692472338676453, 0.0740908533334732, 0.046400122344493866, 0.8321304321289062, -1.2754696607589722, 0.2846328020095825, 1.5330842733383179, 0.39751848578453064, 0.8528699278831482, 0.03529861569404602, -0.6767703890800476, 1.1359530687332153, -0.43519139289855957, -0.42172476649284363, -0.4804752767086029, -0.04912193864583969, -0.3652243912220001, 1.6149471998214722, -0.604749858379364, -0.17174623906612396, 0.8450316786766052, -0.11007807403802872, 0.9912866950035095, 0.11529945582151413, -0.9658440947532654, -0.5592122673988342, 0.6346137523651123, 0.6322863101959229, 0.677250862121582, -0.8921329379081726, 0.8031976819038391, -0.822501003742218, 0.19845658540725708, 0.939774751663208, -0.30763429403305054, -0.06228351965546608, 0.33067435026168823, -0.6583917737007141, 0.5205968022346497, -0.005788744427263737, 0.9629111289978027, 0.07277403771877289, 0.3200090527534485, 0.653421938419342, 0.6282049417495728, -0.06183011084794998, 0.574720561504364, -0.2998499274253845, 0.3989194929599762, -0.4937017560005188, 0.31886500120162964, -0.06686773896217346, 1.0411854982376099, -0.07494987547397614, 0.10648182779550552, -1.334870457649231, 0.4309617280960083, 1.206256628036499, -0.21671146154403687, 0.6749545335769653, -1.1147042512893677, -0.012425935827195644, -0.857921838760376, 0.3548938035964966, -0.481073796749115, -0.530842125415802, -0.08523178845643997, -0.5022391676902771, -1.3913744688034058, 0.1708739548921585, -0.04318363964557648, -0.5931439995765686, 1.217314600944519, -0.049571432173252106, -0.16858318448066711, -0.11307850480079651, 0.6161105632781982, 1.02817964553833, 0.7134378552436829, 0.39644166827201843, -0.0011711235856637359, 0.6839462518692017, -0.8182875514030457, -0.8725202083587646, -1.0978928804397583, 0.6146710515022278, -0.38287362456321716, 1.1136443614959717, -0.04144594073295593, -0.9403378963470459, -1.0421539545059204, -0.8512024283409119, -0.0448681078851223, -0.2930239737033844, 0.2159767597913742, 1.3198550939559937, 0.558223307132721, -0.9696245789527893, 0.3684939742088318, -0.08617380261421204, -0.5497860312461853, -0.3016517460346222, 0.0029265673365443945, 0.2458234280347824, -0.6267632842063904, -1.4364734888076782, 0.162655770778656, 0.2619361877441406, -0.7754708528518677, -0.215060755610466, -0.6351010799407959, -0.8467968702316284, -0.3732169568538666, 0.5271113514900208, -0.1086401715874672, 1.8195080757141113, -0.5619499087333679, -1.5652557611465454, 0.822571337223053, -0.0011074293870478868, 0.529319703578949, 0.11839774996042252, -0.012145113199949265, -0.9294711947441101, -0.6966848373413086, -0.018418148159980774, 0.899181067943573, 0.261776864528656, -0.020571434870362282, 0.005714972037822008, 0.29191654920578003, 0.06982410699129105, -0.1702209860086441, -0.4728747606277466, 1.1163861751556396, -0.21574103832244873, -0.27152660489082336, 0.12455151975154877, 0.9644904136657715, 0.20859485864639282, -0.2609984576702118, -0.1858074963092804, -1.3920644521713257, 0.77861088514328, 0.017169203609228134, 0.8535696864128113, -1.0203388929367065, -1.085445523262024, -0.5429785251617432, -0.32539603114128113, -0.10183566808700562, -0.9943884015083313, 0.6451089978218079, -0.16744458675384521, 0.12182135134935379, -0.07485422492027283, -0.9628358483314514, -0.06471003592014313, -0.13501933217048645, -0.31573209166526794, -0.5983043313026428, 0.13701200485229492, 0.9326426386833191, -1.0990040302276611, 0.2499321699142456, -0.060630444437265396, 0.0713803619146347, -1.0581978559494019, 1.5929484367370605, -0.6308448910713196, 0.6623325347900391, 0.33914420008659363, -0.1987091600894928, -0.12784147262573242, -0.3184089660644531, 0.07760192453861237, -0.13068829476833344, -0.2718542516231537, 0.35845184326171875, -0.6508157849311829, 1.5561575889587402, -0.29217976331710815, 0.17137771844863892, -0.09651844948530197, -0.27624860405921936, 0.6338093280792236, 0.5308367609977722, -0.3468535244464874, -0.4863470196723938, 0.07573992013931274, 0.5500158071517944, -0.45537829399108887, 0.03659606724977493, 0.686866819858551, 0.4181188941001892, -0.28806254267692566, 0.24228154122829437, 0.8264241218566895, -0.30088990926742554, 0.409803569316864, 0.7162682414054871, 0.42146456241607666, 0.2777465283870697, 0.358385294675827, -0.5048285722732544, 0.20808464288711548, -0.882915198802948, -0.18666169047355652, 0.6094162464141846, 0.4504617750644684, 0.5981851816177368, 0.19115130603313446, -0.9877113699913025, -0.17833243310451508, -0.12800030410289764, 0.6727997064590454, 1.8000810146331787, -0.1791827380657196, -0.04494325816631317, -0.6263095140457153, -0.04551279917359352, -0.6625866293907166, 0.4237155318260193, -0.2326793670654297, -0.2652606964111328, -0.8023724555969238, -0.627466082572937, 0.19092901051044464, 0.1130608543753624, 0.7909256815910339, -0.6820558309555054, -0.16291217505931854, -0.013987459242343903, 0.1552758812904358, -0.6609949469566345, -1.1295961141586304, 0.16491259634494781, -0.2786107063293457, 0.14372190833091736, -0.18684375286102295, -0.3954086899757385, -0.06646748632192612, -0.5707318186759949, 1.1366422176361084, -0.4752889573574066, 0.007450622506439686, 0.5489528775215149, 0.7039650678634644, -0.4009767472743988, -1.1144061088562012, 0.12792131304740906, 0.4752887785434723, -0.141121044754982, 0.383637934923172, 0.7949239015579224, 0.3024553656578064, 0.1332480013370514, -0.42002424597740173, 0.49900156259536743, -0.12716960906982422, -0.061009880155324936, 0.4348521828651428, -0.9469102621078491, 0.47398653626441956, -1.3529458045959473, 1.237237811088562, 0.17755913734436035, -0.5619305968284607, 0.2318209707736969, -0.48409605026245117, -0.5996317267417908, 0.3299781084060669, -1.1218029260635376, -0.5821583271026611, -0.8297773003578186, 0.18447265028953552, 0.1660834699869156, -0.42124563455581665, 0.05373488366603851, 0.04584396630525589, 0.2358250468969345, 0.5308205485343933, -0.006369860842823982, 0.2026124745607376, -0.2040303498506546, 0.7766503691673279, -0.6200258731842041, 0.9374702572822571, -0.06006115302443504, -0.10254005342721939, -0.4112509489059448, -0.6667518615722656, -0.7350987792015076, -0.7274907827377319, -0.19878260791301727, -0.3091546595096588, -0.6096017956733704, 0.09327318519353867, -0.49633508920669556, -0.8488872051239014, 0.22940224409103394, -1.2831041812896729, -0.699944794178009, -0.3247155547142029, -0.5366049408912659, -0.25748303532600403, -1.004981517791748, -1.2308844327926636, -0.32770803570747375, -0.2849341928958893, -0.7190294861793518, 0.17307208478450775, 0.05551576614379883, -0.6833409667015076, -0.36451297998428345, 0.5171626806259155, -0.7070531845092773, 1.0663923025131226, -1.0482861995697021, 0.7877445816993713, 0.05100361257791519, -0.3395756483078003, -0.049812231212854385, 0.4915025234222412, 0.5448896288871765, 0.05199062451720238, 0.25575944781303406, -0.768782913684845, 0.11937680840492249, -0.14896036684513092, -0.5168763399124146, -0.10648678988218307, 0.1502501517534256, 0.47228193283081055, -0.15669658780097961, -0.027020571753382683, 0.35333338379859924, 1.0727143287658691, -0.38125479221343994, -0.1702917218208313, 0.24423299729824066, 0.879263162612915, 0.9158321619033813, -0.32791948318481445, 0.5779755711555481, 0.7195302248001099, 0.5875962376594543, -0.1068030595779419, 0.11642125993967056, -0.22914256155490875, -0.7920421361923218, 0.8043283224105835, 1.516909122467041, 0.6988602876663208, 0.1907840222120285, -1.1743800640106201, 0.573542594909668, -0.9818469285964966, -0.2599772810935974, 0.5056971907615662, 0.9747377038002014, 0.702089786529541, -0.864494264125824, -0.23017209768295288, -0.5792346000671387, 0.37760093808174133, 0.19011807441711426, -0.13805121183395386, -0.9808579087257385, -0.11194215714931488, 0.023508163169026375, -0.42453065514564514, 1.0518653392791748, -0.2597777843475342, 0.8179882168769836, 14.670973777770996, 0.3748917281627655, -0.15582534670829773, 0.895643949508667, 0.7406286001205444, 0.23957622051239014, -0.6682072281837463, -0.2159556895494461, -1.3820772171020508, -0.22264736890792847, 1.1654573678970337, 0.29975613951683044, 0.8269769549369812, -0.28571081161499023, -0.1073286235332489, 0.21948036551475525, -0.4786722958087921, 0.5056136250495911, 0.5865166187286377, -0.9629532098770142, 0.2052489072084427, -0.5486068725585938, 0.5506119132041931, 0.581178605556488, 0.6184672117233276, 0.9054124355316162, 0.4827932119369507, -0.09486182779073715, 0.5379484295845032, 0.46439069509506226, 0.9066078066825867, 0.11105307191610336, 0.020526031032204628, 0.7876754999160767, -0.0632261335849762, -0.11119552701711655, -0.348632276058197, -1.2916967868804932, 0.6405396461486816, -0.11675796657800674, -0.3626519739627838, -1.0925275087356567, 0.024462807923555374, 0.37011414766311646, -0.020870864391326904, 0.20369809865951538, -0.2543632984161377, 0.7514821290969849, -0.10389647632837296, 0.193601593375206, 0.19347922503948212, 0.52315753698349, 0.41800689697265625, 0.006796121597290039, -0.04352055862545967, 0.3138044476509094, 0.40554073452949524, 0.6390824913978577, -0.6099898815155029, 0.15872670710086823, -0.2623172998428345, -0.12442642450332642, -0.056697119027376175, 0.8277826905250549, 0.5883398056030273, 0.014756584540009499, -0.5499189496040344, 0.1712631732225418, 0.6752314567565918, 0.11350402235984802, 0.3468400537967682, 0.2591124176979065, -0.015153816901147366, 0.04297763854265213, -0.7495731711387634, 0.4580555260181427, -0.16793785989284515, -0.4783472716808319, -0.9358757138252258, -0.48654448986053467, 0.1290142685174942, -0.9970452785491943, -1.0284110307693481, 0.7149159908294678, -0.15332162380218506, -0.101495660841465, 0.053117863833904266, -0.5556843280792236, -0.2524496912956238, 0.32868292927742004, -1.0018504858016968, -0.5725677013397217, -0.06533034145832062, -0.24223951995372772, -0.24441257119178772, -0.2282455861568451, 1.298986792564392, 0.1385679990053177, -0.40566909313201904, 0.13796718418598175, -0.04143638536334038, -0.4137893617153168, 0.4324462115764618, -0.6975357532501221, 0.8576480746269226, 0.26460573077201843, -0.18263749778270721, 0.3019934296607971, 0.2291688770055771, -0.0045561036095023155, -0.5069147944450378, 0.15299929678440094, 1.161938190460205, -1.0694024562835693, -0.3128223419189453, -0.8848252892494202, -1.2740191221237183, 0.4157612919807434, 0.9719972014427185, -0.2891401946544647, 0.19062559306621552, 0.3475457429885864, -0.7272635102272034, -0.20716720819473267, -0.743902325630188, 0.059454597532749176, 0.2622842490673065, -0.5247731804847717, -0.35011860728263855, 0.31794655323028564, 1.0171374082565308, -1.0923479795455933, -0.31930065155029297, -0.33850061893463135, -0.012193636037409306, -0.13657325506210327, 0.4714604318141937, -0.4084363281726837, 0.30872565507888794, 1.0294826030731201, 0.048738084733486176, -0.9181793332099915, -0.16018827259540558, -1.221858263015747, 0.3345352113246918, 0.6321700811386108, 0.5859509110450745, -0.5749156475067139, -0.3677009344100952, 1.121978998184204, 0.14052197337150574, -0.16429106891155243, -0.39589640498161316, -0.4212629795074463, 0.5355089902877808, -0.4977124333381653, 0.5297513604164124, 0.19382984936237335, 0.006851167418062687, 0.43385690450668335, 0.2289803922176361, 0.2217041701078415, -0.3906257450580597, -1.1201850175857544, 0.5069156289100647, -0.13824135065078735, -0.42172178626060486, -0.4000242054462433, 0.14623671770095825, -1.675220251083374, -0.22245828807353973, -0.9582269191741943, 0.2658003568649292, -0.5907463431358337, -0.36080342531204224, -0.038661032915115356, -0.295127272605896, 0.058593638241291046, 0.29527732729911804, -0.7067103981971741, -0.23189203441143036, -0.3739054799079895, -0.3339063227176666, 0.7953726649284363, 1.0776970386505127, -0.6067233085632324, -0.10911539196968079, -0.15964961051940918, -0.22084754705429077, 0.14391450583934784, 0.4942614436149597, -0.32413551211357117, -0.4653596878051758, -1.5373622179031372, 0.42196565866470337, 0.000662986421957612, -0.10481159389019012, -0.5441466569900513, 0.5574336051940918, 0.43550416827201843, -0.6422049403190613, 0.1226254478096962, 0.09976521879434586, -0.5785518288612366, -0.6817209124565125, -0.0881657600402832, -0.8602045774459839, 0.41782915592193604, 0.43221673369407654, -0.8461536169052124, -0.004886976908892393, 0.6012589931488037, -0.07402323186397552, -1.1368428468704224, -0.8141725659370422, 0.5813608765602112, -0.8090105652809143, 0.2743881046772003, -0.4703197479248047, 0.23311513662338257, -1.2186450958251953, -0.3976062536239624, 0.1842774897813797, 0.30498865246772766, -0.2979719340801239, 1.3739045858383179, 0.21007642149925232, -1.194797396659851, -0.05041448771953583, 0.5904262661933899, 0.28873518109321594, -0.15366940200328827, 0.6152787208557129, 0.22150611877441406, -0.04655591771006584, 0.35227930545806885, 0.155584916472435, 0.3053305149078369, -0.49156060814857483, 0.08665627986192703, 0.8044981360435486, -0.27608823776245117, -0.07702090591192245, 1.4941589832305908, -0.06178997457027435, -1.660096287727356, 0.2771657109260559, -0.9814111590385437, -0.417967289686203, -0.696032702922821, 0.8626266121864319, -0.025222843512892723, -0.2692427635192871, -0.13845565915107727, -0.2542937099933624, 0.13150882720947266, -0.2740914821624756, -0.727012574672699, 0.1517375409603119, -0.14717188477516174, -0.42443814873695374, 1.1349505186080933, 0.5030379295349121, -0.7193755507469177, -0.8670722246170044, -0.6009031534194946, -0.2974591851234436, 0.11659609526395798, 0.10761983692646027, -0.9963220953941345, -0.343860387802124, 0.8528441190719604, 0.6325110197067261, -0.07623853534460068, 0.1836235225200653, 0.13348928093910217, 0.05035049840807915, 0.6196451783180237, 0.35310935974121094, -0.7518624663352966, -0.3523488938808441, 1.442330241203308, 1.1898294687271118, -1.316245675086975, -0.30852824449539185, -0.002908722497522831, -0.5886845588684082, 0.69066321849823, 0.9493101835250854, 0.18178457021713257, 0.8101948499679565, -0.25609803199768066, 0.6273728609085083, 0.16735534369945526, -1.0836127996444702, 0.14615210890769958, 0.5821481347084045, 1.0262449979782104, 1.0440584421157837, 0.5379661321640015, -0.1211569532752037, 0.9872381687164307, 0.045120131224393845, 0.2647784352302551, 0.7048838138580322, -0.11995980888605118, -0.3494480848312378, -0.33670294284820557, 0.12491323053836823, 0.6043158173561096, -0.17754283547401428, -0.5748897194862366, 0.017123639583587646, 0.40086686611175537, 0.26139891147613525, 0.569342851638794, 0.7010242342948914, 0.3749333620071411, 0.8296543955802917, 0.1183956041932106, 0.5947232246398926, -0.8012611865997314, -0.5923763513565063, -0.17604275047779083, -0.7692287564277649, -0.07445870339870453, 0.08297490328550339, -0.6014944911003113, -0.16343502700328827, -0.019242247566580772, 0.3773679733276367, -0.4372587203979492, -0.08290571719408035, 1.1502349376678467, 0.3386104702949524, 0.017413219437003136, -0.46200916171073914, -0.3483053743839264, -0.5385228991508484, -1.1783583164215088, 0.18736496567726135, -0.6989229321479797, -0.2196912169456482, -0.23650939762592316, 0.03481264039874077, -0.4184802770614624]}, "authors": [{"authorId": "1725420331", "name": "Zheng-Xin Yong"}, {"authorId": "2184031883", "name": "Hailey Schoelkopf"}, {"authorId": "2037383772", "name": "Niklas Muennighoff"}, {"authorId": "8129718", "name": "Alham Fikri Aji"}, {"authorId": "2518906", "name": "David Ifeoluwa Adelani"}, {"authorId": "90615055", "name": "Khalid Almubarak"}, {"authorId": "31773000", "name": "M Saiful Bari"}, {"authorId": "35566806", "name": "Lintang Sutawika"}, {"authorId": "11348687", "name": "Jungo Kasai"}, {"authorId": "114850513", "name": "Ahmed Baruwa"}, {"authorId": "9162688", "name": "Genta Indra Winata"}, {"authorId": "103476203", "name": "Stella Biderman"}, {"authorId": "9215251", "name": "Dragomir R. Radev"}, {"authorId": "2841761", "name": "Vassilina Nikoulina"}], "references": [{"paperId": "ce913026f693101e54d3ab9152e107034d81fce1", "title": "Holistic Evaluation of Language Models"}, {"paperId": "16c64f74ce0e6a59b0709c0d8e66596a5bc08ed6", "title": "The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "aa9cda8e13dc60bde7531245c3d878bec8fdccad", "title": "Prompt-Tuning Can Be Much Better Than Fine-Tuning on Cross-lingual Understanding With Multilingual Language Models"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "62f0db3a5ad5c795ec18fc7a6e7b01836809df57", "title": "Language Models are Multilingual Chain-of-Thought Reasoners"}, {"paperId": "960d40497717ad22a7ebb84db238fa2415fc89cc", "title": "LST: Ladder Side-Tuning for Parameter and Memory Efficient Transfer Learning"}, {"paperId": "9e147db7571494a2a3f9492444aeb8f005379416", "title": "Phylogeny-Inspired Adaptation of Multilingual Models to New Languages"}, {"paperId": "c08c2fd7b269bd9d6c1162adc3b059cdf21d40a6", "title": "Lifting the Curse of Multilinguality by Pre-training Modular Transformers"}, {"paperId": "7cdaa08890895e1ad92afb5fad429690ad7b1dac", "title": "Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "15437760a28d528bb1b76794aa4b1d15e7ba2a16", "title": "Polyglot Prompt: Multilingual Multitask Prompt Training"}, {"paperId": "7a25155364476839b6d1fc0653cd8611327ab9ba", "title": "mGPT: Few-Shot Learners Go Multilingual"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "082eaf09599baab29f7bc4359d72ac67cd26cd9a", "title": "Adapting BigScience Multilingual Model to Unseen Languages"}, {"paperId": "6bf7c93ed5a3aca5ef139308c6797615461daa39", "title": "Match the Script, Adapt if Multilingual: Analyzing the Effect of Multilingual Pretraining on Cross-lingual Transferability"}, {"paperId": "55b9a2ade0a49e9cf10b71528d69dfee4e826025", "title": "Cedille: A large autoregressive French language model"}, {"paperId": "4724ebee34ca2cd0a19c3a1ddb83d6d870dd7904", "title": "Few-shot Learning with Multilingual Generative Language Models"}, {"paperId": "fb01415a0decfa3f3d6339930e95028ae1ff4170", "title": "Efficient Large Scale Language Modeling with Mixtures of Experts"}, {"paperId": "d9cdf21e73519edc593bdf1a00fcd778764b13f6", "title": "Training Neural Networks with Fixed Sparse Masks"}, {"paperId": "99b12d0df2b93e800207a5e4618a353912f3dff8", "title": "Multilingual Unsupervised Neural Machine Translation with Denoising Adapters"}, {"paperId": "13fb4621e463b66914ec04881ce5844fcb554d47", "title": "Continual Learning in Multilingual NMT via Language-Specific Embeddings"}, {"paperId": "fc58779940abb92166b73f47867763a07368c739", "title": "Composable Sparse Fine-Tuning for Cross-Lingual Transfer"}, {"paperId": "ad471be93216ddbf8544721d50ee5aed14f07cae", "title": "UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning"}, {"paperId": "43a87867fe6bf4eb920f97fc753be4b727308923", "title": "Towards a Unified View of Parameter-Efficient Transfer Learning"}, {"paperId": "59c0c6b62e33850cda08663d4c9ecabcf5d21596", "title": "IndoBERTweet: A Pretrained Language Model for Indonesian Twitter with Effective Domain-Specific Vocabulary Initialization"}, {"paperId": "769f8b6d73fcb5b5013ae2c1c48b94c801c88ba3", "title": "Discrete and Soft Prompting for Multilingual Models"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"}, {"paperId": "64902a5077ee68011cd467398dbb66511e8e891a", "title": "It\u2019s All in the Heads: Using Attention Heads as a Baseline for Cross-Lingual Transfer in Commonsense Reasoning"}, {"paperId": "339b2b711fb5b228d097b03ebc3e62a521779235", "title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "c89ff2a0416a6d0870e724953a61a798deee238f", "title": "How to Adapt Your Pretrained Multilingual Model to 1600 Languages"}, {"paperId": "28459083ba624020c8f1c1ed7c3a075f48b4e709", "title": "KLUE: Korean Language Understanding Evaluation"}, {"paperId": "add0dd0ab2a408354fa2d89cc492b4d2ab26845d", "title": "AmericasNLI: Evaluating Zero-shot Natural Language Understanding of Pretrained Multilingual Models in Truly Low-resource Languages"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "6803adc7d8b891be652d18815f830f7a42a0f5b5", "title": "Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets"}, {"paperId": "7e5008713c404445dd8786753526f1a45b93de12", "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow"}, {"paperId": "a9fe5bd8da2d9603cf2cf6c6ea8b0f83c6d3a4f9", "title": "How many data points is a prompt worth?"}, {"paperId": "13bcfb944779165983aaef22cec8a3bbd3e98e62", "title": "UNKs Everywhere: Adapting Multilingual Language Models to New Scripts"}, {"paperId": "d22e4cc3a501c17881b9478621f29760e429e76e", "title": "Parameter-Efficient Transfer Learning with Diff Pruning"}, {"paperId": "8b31fef217004560b8c2517c0f6fdc1c3cf55112", "title": "Language Adapters for Zero Shot Neural Machine Translation"}, {"paperId": "c3a662b864673d8cc7469051419ab8819926d4b0", "title": "Identifying Elements Essential for BERT\u2019s Multilinguality"}, {"paperId": "29599829d26b4acaaf0ad88698ed4362d33b2ae7", "title": "When Being Unseen from mBERT is just the Beginning: Handling New Languages With Multilingual Language Models"}, {"paperId": "bdeec55f95fd6b73e3e4635459b14c7248543efb", "title": "AdapterDrop: On the Efficiency of Adapters in Transformers"}, {"paperId": "e39a4b182c3bae017b08df20b37b9d1d97c9a4bf", "title": "Multi-Stage Pretraining for Low-Resource Domain Adaptation"}, {"paperId": "110c13fbf4ff87b52ee1fd9eb2d3616c839ceb41", "title": "Parsing with Multilingual BERT, a Small Treebank, and a Small Corpus"}, {"paperId": "a1f47c220f68feac3aa041ded35f53776b2885e3", "title": "In Neural Machine Translation, What Does Transfer Learning Transfer?"}, {"paperId": "98ef0db84e62aef969629264c9de1f4d0013f3b9", "title": "AdapterFusion: Non-Destructive Task Composition for Transfer Learning"}, {"paperId": "d97e7561fa7710213ccd4f8128044ea6849be377", "title": "XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning"}, {"paperId": "26299d5fdc5137291dc6a091573b3d18aba1d1c2", "title": "MAD-X: An Adapter-based Framework for Multi-task Cross-lingual Transfer"}, {"paperId": "dbfbfcc2633ef46c53e2343525ee87c700f2cfc3", "title": "Extending Multilingual BERT to Low-Resource Languages"}, {"paperId": "0e141942fa265142f41a2a26eb17b6005d3af29e", "title": "The State and Fate of Linguistic Diversity and Inclusion in the NLP World"}, {"paperId": "6fec3e579c7cd4f13bdabbee2b6ac2e8ff5941c6", "title": "Unsupervised Cross-lingual Representation Learning at Scale"}, {"paperId": "9e9d919c1de684ca42c8b581ec62c7aa685f431e", "title": "On the Cross-lingual Transferability of Monolingual Representations"}, {"paperId": "04a7021fe6be6bddcfae476493fcc7571e7c613c", "title": "PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification"}, {"paperId": "92343cecdc990380de362b969eec60081959f507", "title": "Asynchronous Pipeline for Processing Huge Corpora on Medium to Low Resource Infrastructures"}, {"paperId": "809cc93921e4698bde891475254ad6dfba33d03b", "title": "How Multilingual is Multilingual BERT?"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "160563abbd75265b19afc8b4169bab9e1eb33d97", "title": "Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond"}, {"paperId": "1c3112ef8a346b9817382ed34a8c146c53d5bcf5", "title": "XNLI: Evaluating Cross-lingual Sentence Representations"}, {"paperId": "205ff5dae21ca44c15d3b7d7a9febb7d84b47bc4", "title": "Rapid Adaptation of Neural Machine Translation to New Languages"}, {"paperId": "e12359bfbee8bf069a51c7ce8a0d448b59eadbc3", "title": "Roman"}, {"paperId": "21937ecd9d66567184b83eca3d3e09eb4e6fbd60", "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "1aa9c0045f1fe8c79cce03c7c14ef4b4643a21f8", "title": "A new algorithm for data compression"}, {"paperId": "4972b88f8f324a4fa18e921f62a9857af2b5fc7b", "title": "Crosslingual Generalization through Multitask Finetuning"}, {"paperId": "e2b9464a590ee3a9731c8fd498874ae4f37e92ed", "title": "BAD-X: Bilingual Adapters Improve Zero-Shot Cross-Lingual Transfer"}, {"paperId": "c965f50e790d066afa140d949645c9f100fc18d0", "title": "Jojajovai: A Parallel Guarani-Spanish Corpus for MT Benchmarking"}, {"paperId": "940fc621079ea349109202c7d705461b50d541d8", "title": "Cross-lingual Few-Shot Learning on Unseen Languages"}, {"paperId": "4c0150dd12d52aa3f63c69c5dbfe5e9471e8d428", "title": "Enhancing Cross-lingual Natural Language Inference by Prompt-learning from Cross-lingual Templates"}, {"paperId": "e3764d7bd3548823db271bd4f1adb5b9e0501d5b", "title": "Zero-shot Reading Comprehension and Reasoning for Spanish with BERTIN GPT-J-6B"}, {"paperId": "21abb6f22851e5447cd810dd9e70a4b8691cee51", "title": "You reap what you sow: On the Challenges of Bias Evaluation Under Multilingual Settings"}, {"paperId": null, "title": "Data efficient language transfer with gpt-j"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Ellie Pavlick, Suzana Ili\u0107"}, {"paperId": null, "title": "60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)"}, {"paperId": null, "title": "2022. Data efficient"}]}