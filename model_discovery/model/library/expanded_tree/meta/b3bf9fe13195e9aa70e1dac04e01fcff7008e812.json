{"paperId": "b3bf9fe13195e9aa70e1dac04e01fcff7008e812", "abstract": "Biological systems perceive the world by simultaneously processing high-dimensional inputs from modalities as diverse as vision, audition, touch, proprioception, etc. The perception models used in deep learning on the other hand are designed for individual modalities, often relying on domain-specific assumptions such as the local grid structures exploited by virtually all existing vision models. These priors introduce helpful inductive biases, but also lock models to individual modalities. In this paper we introduce the Perceiver - a model that builds upon Transformers and hence makes few architectural assumptions about the relationship between its inputs, but that also scales to hundreds of thousands of inputs, like ConvNets. The model leverages an asymmetric attention mechanism to iteratively distill inputs into a tight latent bottleneck, allowing it to scale to handle very large inputs. We show that this architecture is competitive with or outperforms strong, specialized models on classification tasks across various modalities: images, point clouds, audio, video, and video+audio. The Perceiver obtains performance comparable to ResNet-50 and ViT on ImageNet without 2D convolutions by directly attending to 50,000 pixels. It is also competitive in all modalities in AudioSet.", "venue": "International Conference on Machine Learning", "year": 2021, "citationCount": 744, "influentialCitationCount": 87, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper introduces the Perceiver - a model that builds upon Transformers and hence makes few architectural assumptions about the relationship between its inputs, but that also scales to hundreds of thousands of inputs, like ConvNets."}, "embedding": {"model": "specter_v2", "vector": [0.5138416290283203, 0.34094229340553284, -0.04132462665438652, 0.1799873411655426, 0.03407071530818939, 0.2665112614631653, 0.5968528985977173, -0.05953407287597656, -0.40203040838241577, -0.8479067087173462, 0.45357546210289, 0.7257217168807983, 0.3575495481491089, -0.15017695724964142, -0.3624255359172821, 0.10045592486858368, -0.7099636197090149, 0.11375420540571213, 0.37378886342048645, -0.25619977712631226, 0.33859938383102417, -0.6531218886375427, -1.4322859048843384, 0.6179245710372925, -0.3826620578765869, 1.1062885522842407, 0.34908631443977356, 1.5056780576705933, 0.15540727972984314, 0.2759782075881958, 0.5168461203575134, 0.24907656013965607, 0.1968599408864975, 0.08324851840734482, -0.3588477373123169, -0.24572151899337769, 0.486964613199234, -0.043257731944322586, -0.5106641054153442, 0.741613507270813, -0.13193146884441376, -0.04122444987297058, 0.7831779718399048, -0.6578438878059387, -0.35060808062553406, 0.09694317728281021, 0.20230594277381897, 0.6150543689727783, -0.010044699534773827, -0.36444491147994995, 1.4999945163726807, -1.108122706413269, 0.2420959174633026, 1.8847017288208008, 0.6051270365715027, 0.21547594666481018, -0.30184975266456604, 0.1534186601638794, 0.8851574063301086, -0.017061205580830574, -0.49559009075164795, 0.26730507612228394, -0.07322849333286285, -0.19756479561328888, 1.563554048538208, -0.6550881266593933, 0.08917224407196045, 0.8199774026870728, 0.35249701142311096, 1.1524146795272827, 0.3290533721446991, -0.9054580926895142, -0.02135862596333027, 0.24062010645866394, 0.09175381064414978, 0.13023531436920166, -0.6339539885520935, 0.22397127747535706, -1.1810269355773926, -0.006544620729982853, 0.9063401818275452, 0.07936011254787445, -0.07301293313503265, -0.12613041698932648, -0.7618619799613953, 0.12253837287425995, 1.091529369354248, 0.37936511635780334, -0.46510234475135803, 1.043235421180725, 0.49365681409835815, 0.29840606451034546, -0.5642275214195251, 0.43960899114608765, 0.18965844810009003, 0.4351281523704529, -0.18780788779258728, -0.2328711301088333, -0.13472315669059753, 0.7750802040100098, -0.15002979338169098, -0.23919114470481873, 0.056419260799884796, 0.13156041502952576, 1.4379348754882812, 0.27912938594818115, 0.2504971921443939, -0.5939164161682129, 0.24791854619979858, -0.5753310322761536, -0.07735162228345871, -1.0829880237579346, 0.1001703292131424, -0.12094767391681671, -0.7650247812271118, -0.3586699068546295, -0.3382386565208435, 0.38159823417663574, -1.0236679315567017, 0.3077368140220642, -0.29940736293792725, -0.14920422434806824, 0.07313228398561478, 0.6861484050750732, 0.39635905623435974, 0.519005537033081, 0.40243247151374817, 1.0086238384246826, 1.1690168380737305, -0.14054040610790253, -0.26454755663871765, -0.7399922609329224, -0.6752405762672424, -0.22000613808631897, 0.585689902305603, 0.30018115043640137, -0.804474413394928, -1.556183934211731, -0.8036280274391174, -0.22613726556301117, -0.7433567047119141, 0.1721743494272232, 1.183898687362671, -0.152334526181221, -0.8146089315414429, 0.9151006937026978, -0.30515214800834656, -0.6024274826049805, 0.5547471046447754, 0.37800341844558716, 0.24452364444732666, 0.16634750366210938, -0.5753344297409058, 0.16323986649513245, 0.2681524157524109, -0.4150342047214508, -0.331595242023468, -0.24554136395454407, -0.9565793871879578, -0.12341810017824173, 0.021364644169807434, -0.9861192107200623, 0.8752797245979309, -0.436053603887558, -0.6992502212524414, 0.5671662092208862, -0.1149040013551712, 0.2260548621416092, -0.07791974395513535, -0.48804205656051636, 0.02692074328660965, 0.030524620786309242, -0.5456677079200745, 0.9875486493110657, 0.4480156898498535, -0.885250449180603, -0.24313879013061523, -0.049421537667512894, -0.37928783893585205, 0.14470818638801575, -0.3340562582015991, 0.7399139404296875, -0.42097020149230957, -0.15317393839359283, 0.537262499332428, 0.598989725112915, 0.08023060858249664, 0.2111826092004776, -0.22393447160720825, -0.7006832361221313, 0.8151484131813049, 0.43837374448776245, -0.04483377933502197, -1.0609819889068604, -0.3313220143318176, -0.08239015191793442, -0.03841264545917511, -0.647702157497406, -0.9089516401290894, 0.6049889922142029, -0.15531125664710999, 0.19652876257896423, -0.09812667965888977, -0.8848171830177307, -0.18887093663215637, -0.0023535878863185644, -0.8395863771438599, -0.007875646464526653, 0.382876455783844, 1.1239722967147827, -1.0741583108901978, -0.16228720545768738, 0.22840282320976257, 0.2931059002876282, -0.8972066044807434, 1.0311522483825684, -0.5308617353439331, -0.013370045460760593, 0.06291532516479492, 0.26475048065185547, 0.09483791887760162, -0.16069398820400238, 0.11858823895454407, -0.6634923815727234, 0.3149307072162628, 0.4312112033367157, -0.3230879008769989, 1.4510263204574585, -0.4513683319091797, 0.7862634658813477, 0.07207513600587845, -0.568030059337616, 0.12426949292421341, 0.2648099958896637, -0.19338026642799377, -0.4670727252960205, 0.46491533517837524, 0.009889965876936913, -0.4745892584323883, -0.04714979976415634, 0.2971084415912628, 0.8292899131774902, -0.31715792417526245, -0.23232917487621307, 0.9077692627906799, -0.8122075796127319, -0.6716104745864868, 0.5215310454368591, 0.5166744589805603, 0.7737777829170227, 0.2565854489803314, 0.13857807219028473, -0.35784026980400085, -1.0213145017623901, -0.196804478764534, 0.6876346468925476, 0.6976367831230164, 1.4669004678726196, 0.3057548999786377, -0.7747395634651184, -0.33862003684043884, -0.6308990716934204, 0.4798545837402344, 1.1628044843673706, 0.38193613290786743, 0.056466877460479736, -0.3297320604324341, -0.0539039708673954, -0.025345241650938988, -0.4793936014175415, -0.7722999453544617, -0.05210460349917412, 0.040766872465610504, -0.8863674402236938, 0.5359099507331848, 0.6905614137649536, 1.1286823749542236, -1.2444497346878052, -0.6248514652252197, -0.42861390113830566, 0.5519136786460876, -0.7667708992958069, -0.24748177826404572, 0.5617124438285828, -0.21749481558799744, -0.16984447836875916, 0.2388111650943756, -0.030926816165447235, 0.3370913565158844, -0.6350528001785278, 0.749267041683197, -0.46603673696517944, -0.612675130367279, 0.7954742312431335, 0.4758544862270355, -1.6317428350448608, -0.022600358352065086, -0.025628086179494858, 0.16535058617591858, 0.05061182752251625, 0.2568446695804596, -0.15674632787704468, -0.31014788150787354, 0.21110856533050537, -0.6699041128158569, -0.1308608055114746, 0.07146458327770233, -0.046906910836696625, 1.0548189878463745, -0.5359383225440979, 0.20887187123298645, -0.6718262434005737, 0.6175448298454285, -0.06764417886734009, -0.050630856305360794, -0.0663771778345108, -0.1254749894142151, -0.6272732615470886, 0.3035520613193512, -0.712508499622345, -0.2517511546611786, -0.4083711802959442, 0.28394612669944763, -0.6619090437889099, -1.0034312009811401, 0.05563294515013695, 0.3611341118812561, -0.28395065665245056, 0.7151546478271484, 0.1542181670665741, 0.09953954815864563, 0.10574453324079514, 0.10168904811143875, -0.5925032496452332, 0.9372708797454834, 0.2009829878807068, 0.2828786373138428, 0.5507704019546509, 0.22334113717079163, -1.0870020389556885, -0.6181625127792358, -0.7068209052085876, -0.8621994853019714, -0.6529512405395508, 0.42021605372428894, -0.34236645698547363, -1.2188091278076172, 0.007726877927780151, -0.9505502581596375, -0.32948654890060425, -0.13222961127758026, -0.0290474034845829, -0.5100913643836975, -0.8246276378631592, -0.8288060426712036, -0.8009852766990662, -0.21439236402511597, -0.36881107091903687, 0.4939407408237457, 0.33869192004203796, -0.661132276058197, -0.3711499571800232, -0.09298507124185562, -0.46684086322784424, 0.6132847666740417, -0.04448385909199715, 0.3350431025028229, 0.3111969828605652, -0.43783077597618103, -0.26557058095932007, 0.08763159066438675, 0.5317312479019165, 0.05021672695875168, 0.42995092272758484, -1.546134352684021, 0.5723634362220764, -0.39283767342567444, -0.7109083533287048, 0.7741531133651733, 0.14265194535255432, 1.182396411895752, 0.5944979190826416, -0.2308373600244522, 0.3795284926891327, 1.3927546739578247, -0.5866206884384155, 0.3035949468612671, 0.050923582166433334, 0.9176256656646729, 0.3591371476650238, -0.10023637861013412, 0.4453704059123993, 0.24042649567127228, 0.06940935552120209, 0.91652512550354, -0.46380284428596497, -0.4252544939517975, -0.9457089304924011, -0.1078089028596878, 0.7277824282646179, -0.5394038558006287, 0.11738725751638412, -0.9407709836959839, 0.9521422386169434, -1.1100785732269287, -0.5695773959159851, 0.9046956896781921, 0.9552748203277588, 0.008082959800958633, 0.033291045576334, -0.4523656666278839, -0.13149568438529968, 0.3183060884475708, -0.11866439878940582, -0.40732064843177795, -0.7505239844322205, 0.009616117924451828, 0.49562305212020874, -0.12834419310092926, 0.4600173532962799, -0.5412163734436035, 0.1883726865053177, 14.973822593688965, 0.14600726962089539, -0.3217063248157501, 0.22004488110542297, 0.34068959951400757, 0.3338961899280548, -0.3411955237388611, -0.21756437420845032, -0.8343052864074707, -0.3207864463329315, 0.7754373550415039, 0.9148982167243958, 0.621455729007721, 0.009797661565244198, -0.2418147176504135, 0.07503554224967957, -0.8887293338775635, 1.0037518739700317, 0.3040861189365387, -0.7873930931091309, 0.1783415973186493, 0.360719233751297, 0.01918313279747963, 0.792850911617279, 1.008194088935852, 0.4063020646572113, 0.06814643740653992, -0.5141993761062622, 0.4896696209907532, 0.5447942018508911, 0.934856116771698, 0.30680587887763977, 0.08002247661352158, 0.3811473548412323, -0.9436272382736206, -0.22858157753944397, -0.7281739115715027, -1.1033010482788086, -0.040163613855838776, -0.28719332814216614, -0.4971996247768402, -0.5256422758102417, 0.34299251437187195, 0.5863927006721497, 0.3717317283153534, 0.61472487449646, -0.059646159410476685, 0.3501226305961609, -0.46562686562538147, -0.3177914321422577, 0.09000054001808167, 0.8022741675376892, 0.19256643950939178, 0.3152605891227722, -0.49117743968963623, 0.38607314229011536, 0.04913514479994774, 0.6485809683799744, -0.5300537347793579, -0.3547227680683136, -0.4765506982803345, 0.0011916124494746327, -0.26216578483581543, 0.7137630581855774, 0.1947336047887802, 0.3992162346839905, -0.2950117886066437, 0.24766145646572113, 0.07698426395654678, 0.28794366121292114, -0.03924211859703064, -0.42836540937423706, 0.35922321677207947, -0.4462837278842926, 0.03905823454260826, 0.3777540624141693, -0.5032562613487244, -0.3162432014942169, -0.6284627914428711, -0.004784917458891869, 0.4080162048339844, -1.087604284286499, -0.9574341773986816, 0.8076760768890381, -0.3194127082824707, -0.41809335350990295, 0.787043035030365, -1.0809308290481567, -0.5513283014297485, 0.6312732100486755, -1.4655535221099854, -0.7955395579338074, -0.4613037705421448, -0.14102119207382202, -0.21423080563545227, 0.3369807004928589, 0.9751046299934387, -0.34313032031059265, 0.3252539038658142, -0.2694091200828552, -0.8411785364151001, -0.19883771240711212, -0.07215407490730286, -1.149863839149475, 0.765606164932251, -0.17048706114292145, 0.1883149892091751, 0.19178564846515656, 0.025084499269723892, 0.21149978041648865, -0.7492178082466125, 0.45968055725097656, 0.027953503653407097, -0.9688719511032104, -0.3964913487434387, -0.699638307094574, -0.9467109441757202, 0.17069435119628906, 0.7703215479850769, -0.06852994859218597, 0.2287900745868683, 0.6116155982017517, -0.8691733479499817, -0.32321372628211975, -0.6605219841003418, -0.2156706601381302, 0.15013256669044495, -1.0434234142303467, -0.8202040195465088, -0.34954628348350525, 0.07709995657205582, -0.9196991324424744, -0.6635146141052246, 0.013594137504696846, 0.5840670466423035, -0.3611062467098236, 1.1976640224456787, -0.40431225299835205, 0.511570394039154, 0.48111140727996826, -0.2998185455799103, -0.781123697757721, -0.04004118964076042, -0.6553745865821838, 0.2612208425998688, -0.12235837429761887, 0.25029176473617554, -0.4575903117656708, -0.11261573433876038, 0.1583852469921112, 0.19790492951869965, -0.5470787882804871, -0.38253170251846313, 0.15745019912719727, -0.2476421445608139, -0.6098594665527344, -0.050167862325906754, -0.2929559648036957, 0.17181459069252014, 0.05815393105149269, 0.7136300802230835, 0.9590365886688232, 0.1257610321044922, -0.38638103008270264, 0.26171934604644775, -0.44570958614349365, -0.49073055386543274, -0.17972035706043243, -0.9109672904014587, -1.548179030418396, -0.8870581984519958, -0.5458520650863647, 0.0818631574511528, -1.0952672958374023, -0.5167943835258484, 0.31362664699554443, -0.8573299050331116, 0.16884753108024597, 0.5353065133094788, -0.04813521355390549, -0.07571882009506226, -0.5347903370857239, -0.5631248950958252, 0.5262649655342102, 1.139704704284668, -0.6156675219535828, -0.06533153355121613, 0.08537071943283081, -0.17301028966903687, 0.9063822627067566, 0.3186958134174347, -0.15980665385723114, -0.6289129257202148, -1.0263358354568481, 0.5610441565513611, -0.274434894323349, 0.49386048316955566, -1.5206031799316406, 0.8812364339828491, 0.3453822135925293, 0.5276162624359131, -0.22368913888931274, 1.209331750869751, -1.0074554681777954, -0.918484628200531, 0.09140931069850922, -0.8548352718353271, -0.23450824618339539, 0.24595263600349426, -0.11579611152410507, -0.3429127335548401, 0.9589887857437134, 0.07516469061374664, -1.1874048709869385, -0.7838314175605774, 0.16271063685417175, -0.3362788259983063, -0.12729105353355408, -0.3358222246170044, -0.2840054929256439, -0.9573565125465393, -0.2772429585456848, -0.4023423194885254, 0.2795768976211548, -0.534770667552948, 0.8668103218078613, 0.9305709600448608, -0.7438879609107971, 0.2694970965385437, 0.29683318734169006, -0.034116990864276886, 0.29631251096725464, 0.29497507214546204, 0.3154158592224121, 0.015572584234178066, 0.25986209511756897, -0.1619928628206253, -0.1653427928686142, -0.8495168089866638, 0.05085385963320732, 0.8755223155021667, 0.7425147891044617, -0.1780557781457901, 1.2718809843063354, 0.25749471783638, -0.9314590692520142, 0.3440566062927246, -1.578324794769287, -0.346426397562027, -0.00033316356712020934, 0.3379609286785126, -0.1778813898563385, -0.18364055454730988, 0.3245439827442169, -0.28328537940979004, 0.8090240955352783, 0.2143147587776184, -0.4670250713825226, 0.31709110736846924, 0.011147499084472656, 0.12839378416538239, 1.0806760787963867, 0.5477177500724792, -0.711486279964447, -0.9544467926025391, -0.7685661911964417, -0.8318926095962524, -0.2254893183708191, -0.028071869164705276, -0.4006429612636566, -0.4066565930843353, 1.351353406906128, 0.4607471823692322, 0.467403769493103, 0.480465829372406, 0.4659814238548279, -0.2319408357143402, 0.8494681715965271, 0.08655078709125519, -0.477671355009079, 0.11940307170152664, 1.1440643072128296, 1.5565561056137085, -0.8302884697914124, 0.3863534927368164, -0.5423187613487244, -0.8471853733062744, 0.6804051399230957, 0.5029036998748779, -0.5231792330741882, 1.042690396308899, -0.22537896037101746, 0.12417490035295486, 0.026301441714167595, -1.0510762929916382, -0.4302801191806793, 1.0632188320159912, 1.4719178676605225, 0.2978852093219757, 0.3296922445297241, 0.5782688856124878, 0.2785375416278839, 0.15426358580589294, 0.016171632334589958, 0.3038516342639923, 0.2824636697769165, -0.16841602325439453, 0.45004400610923767, -0.17775854468345642, 0.3821680247783661, -0.4673576056957245, -0.0877818912267685, -0.19193366169929504, 0.501829981803894, 0.5325300693511963, 0.37503570318222046, 0.9500902891159058, -0.033657852560281754, 0.8157373666763306, -0.39275887608528137, 0.9194924235343933, -0.7225406765937805, -0.24829965829849243, 0.06680610775947571, -0.9281601309776306, -0.015314259566366673, -0.4783734381198883, -0.9631545543670654, -0.4793960452079773, 0.5024164319038391, 0.40229564905166626, -0.3386856019496918, 0.4559483826160431, 0.6176915168762207, 0.44870132207870483, 0.723641574382782, -0.33366116881370544, -0.8958008885383606, -0.166519895195961, -0.9438427686691284, 0.12195821851491928, -0.4611526429653168, 0.24089528620243073, -0.44778352975845337, -0.27760201692581177, -0.0029234078247100115]}, "authors": [{"authorId": "2689633", "name": "Andrew Jaegle"}, {"authorId": "49423009", "name": "Felix Gimeno"}, {"authorId": "2065040247", "name": "Andrew Brock"}, {"authorId": "1688869", "name": "Andrew Zisserman"}, {"authorId": "1689108", "name": "O. Vinyals"}, {"authorId": "35681810", "name": "Jo\u00e3o Carreira"}], "references": [{"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "78ea232dbabc67ca4d6d4a7c1bbf568e9b47cb8a", "title": "Coordination Among Neural Modules Through a Shared Global Workspace"}, {"paperId": "cec7872b194aadf54140578b9be52939eb1112e9", "title": "LambdaNetworks: Modeling Long-Range Interactions Without Attention"}, {"paperId": "c16835c8e535ebd9c10a550ca9455fe384a14449", "title": "High-Performance Large-Scale Image Recognition Without Normalization"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78", "title": "Bottleneck Transformers for Visual Recognition"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "ff50b46b4e1cc0fd9beb832fc3468785b635a824", "title": "PCT: Point cloud transformer"}, {"paperId": "787119e3c3f819244c82b7d97779473773e60696", "title": "MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "502623c4e0b23de2e7030ebaf76da8072bddc97d", "title": "The Critique of Pure Reason"}, {"paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8", "title": "Generative Pretraining From Pixels"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "10d11f0045dc7f217c7f01bc6cbb47929e9b8808", "title": "Self-Supervised MultiModal Versatile Networks"}, {"paperId": "5156381d63bb3e873533b08f203cb56c2d79b6c9", "title": "Object-Centric Learning with Slot Attention"}, {"paperId": "a0dc3135c40e150f0271002a96b7c9680b6cac40", "title": "Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "a0185d4f32dde88aa1749f3a8000ed4721787b65", "title": "Visual Transformers: Token-based Image Representation and Processing for Computer Vision"}, {"paperId": "5bc24361d1f1ec16451d9c9531cfb45b99ea6a1f", "title": "Large Scale Audiovisual Learning of Sounds with Weakly Labeled Data"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "a238109c3969ae681eee0d4f1bf2012f28850593", "title": "Synthesizer: Rethinking Self-Attention in Transformer Models"}, {"paperId": "54c7445f319823c7dcc948c830e75e2fa7460b33", "title": "Exploring Self-Attention for Image Recognition"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "428b663772dba998f5dc6a24488fff1858a0899f", "title": "NeRF"}, {"paperId": "8eba733040b016e9c7ec5c3dc87cc1b28a5c2000", "title": "Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "0172163109a75c0e847dd4b64c566d02afd2d63f", "title": "Audiovisual SlowFast Networks for Video Recognition"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "65d53938a12c77e7920b8eb3a49df249c978ba3f", "title": "PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition"}, {"paperId": "02b1607af35b48f0bd716367caf6a7428b969369", "title": "AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty"}, {"paperId": "f0e287d883755757314fbc628007df2c6709c0bb", "title": "Towards Robust Image Classification Using Sequential Attention Models"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "2e14e84ccec924ed770b58108ad1d9de6f0ca295", "title": "BP-Transformer: Modelling Long-Range Context via Binary Partitioning"}, {"paperId": "bb713d56a39a040b35e4f9e036fb4422f543e614", "title": "On the Relationship between Self-Attention and Convolutional Layers"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "119b1526842c105ef9a5b187c13045eb580220e7", "title": "Context-Gated Convolution"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "54416048772b921720f19869ed11c2a360589d03", "title": "UNITER: Learning UNiversal Image-TExt Representations"}, {"paperId": "4616ea39c9c4fcaec65b1cf4769898b441511fd0", "title": "A Deep Residual Network for Large-Scale Acoustic Scene Analysis"}, {"paperId": "f6390beca54411b06f3bde424fb983a451789733", "title": "Adaptively Sparse Transformers"}, {"paperId": "1be579f4c120a8bf15c4df78d622549913b4d8f7", "title": "Making Sense of Vision and Touch: Learning Multimodal Representations for Contact-Rich Tasks"}, {"paperId": "d6dccb5d71fbb6f5765f89633ba3a8e6809a720d", "title": "Stand-Alone Self-Attention in Vision Models"}, {"paperId": "02f55b398ff8c4d03314e99da7e815d190794471", "title": "What Makes Training Multi-Modal Classification Networks Hard?"}, {"paperId": "f4238bd2385a52413ccbacfd9e409a650235bd13", "title": "Adaptive Attention Span in Transformers"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "27ac832ee83d8b5386917998a171a0257e2151e2", "title": "Attention Augmented Convolutional Networks"}, {"paperId": "b0fae9fbb4e580d92395eabafe73e317ae6510e3", "title": "SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition"}, {"paperId": "bc789aef715498e79a74f857fa090ece9e383bf1", "title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "9bd25f99bfc73af7e6d76f83d92f8270eab7be1d", "title": "Video Action Transformer Network"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "fd4ae71916cf400bfd1490f275e91b154eb69160", "title": "Relational recurrent neural networks"}, {"paperId": "9f5263cda2d58fb3dfaff5ec6db70b0d2ae53c68", "title": "Multi-level attention model for weakly supervised audio classification"}, {"paperId": "aa46c05868d6ccb404f4f6378cc11ae77f702d45", "title": "Convolutional Neural Networks with Alternately Updated Clique"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "dfc504536e8434eb008680343abb77010965169e", "title": "Objects that Sound"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "3afe627b83d4b7b4154f722d361dca9bfcc4adeb", "title": "Learning SO(3) Equivariant Representations with Spherical CNNs"}, {"paperId": "80d635952b283a6886487e51887f2d05ed122738", "title": "Audio Set Classification with Attention Model: A Probabilistic Perspective"}, {"paperId": "9ae0a24f0928cab1554a6ac880f6b350f85be698", "title": "One Model To Learn Them All"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "8674494bd7a076286b905912d26d47f7501c4046", "title": "PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space"}, {"paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0", "title": "Convolutional Sequence to Sequence Learning"}, {"paperId": "5ba2218b708ca64ab556e39d5997202e012717d5", "title": "Audio Set: An ontology and human-labeled dataset for audio events"}, {"paperId": "0e779fd59353a7f1f5b559b9d65fa4bfe367890c", "title": "Geometric Deep Learning: Going beyond Euclidean data"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "fafcaf5ca3fab8dc4fad15c2391c0fdb4a7dc005", "title": "Group Equivariant Convolutional Networks"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "66d4475f0eee4b65983e06b1fbafad533eb81b2a", "title": "Human Pose Estimation with Iterative Error Feedback"}, {"paperId": "dc4fc132b961c165ce5848dde224e92d00ae910a", "title": "Bottom-Up and Top-Down Reasoning with Hierarchical Rectified Gaussians"}, {"paperId": "d25c65d261ea0e6a458be4c50c40ffe5bc508f77", "title": "Learning Spatiotemporal Features with 3D Convolutional Networks"}, {"paperId": "c1126fbffd6b8547a44c58b192b36b08b18299de", "title": "Neural Turing Machines"}, {"paperId": "71ae756c75ac89e2d731c9c79649562b5768ff39", "title": "Memory Networks"}, {"paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327", "title": "Going deeper with convolutions"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "6d4c9c923e9f145d1c01a2de2afc38ec23c44253", "title": "Large-Scale Video Classification with Convolutional Neural Networks"}, {"paperId": "7c8a51d04522496c43db68f2582efd45eaf59fea", "title": "3D ShapeNets: A deep representation for volumetric shapes"}, {"paperId": "4177ec52d1b80ed57f2e72b0f9a42365f1a8598d", "title": "Speech recognition with deep recurrent neural networks"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "82b9099ddf092463f497bd48bb112c46ca52c4d1", "title": "High-Performance Neural Networks for Visual Object Classification"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "7a59fde27461a3ef4a21a249cc403d0d96e4a0d7", "title": "Random Features for Large-Scale Kernel Machines"}, {"paperId": "17832f01dab8145143eb73978ed4946f2722f87d", "title": "Compositional pattern producing networks: A novel abstraction of development"}, {"paperId": "0911b79ff4a7b3c4dc573a1014c0258068002251", "title": "Why don't we see changes? The role of attentional bottlenecks and limited visual memory"}, {"paperId": "72a2c172cf49edb4a33708e05f53938f4d475432", "title": "OBJ CUT"}, {"paperId": "2c3f0fe9478e9785c206b2087ad82849c464bc68", "title": "Combining Top-Down and Bottom-Up Segmentation"}, {"paperId": "2de4eb4a2b74d2b7d7a987dfde3e0b9620012203", "title": "Competition for consciousness among visual events: the psychophysics of reentrant visual processes."}, {"paperId": "4df17f8bbaf8e84f9ebe88c59f88b24babfac9b3", "title": "A model of neuronal responses in visual area MT"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "b94c7ff9532ab26c3aedbee3988ec4c7a237c173", "title": "Normalized cuts and image segmentation"}, {"paperId": "700bbcd3518ca8cb3dac50a89fc69cad3dc1a579", "title": "A neurobiological model of visual attention and invariant pattern recognition based on dynamic routing of information"}, {"paperId": "33ce6c2f2d5128be710fb3ddd8f1117758b9b4a9", "title": "Spatiotemporal energy models for the perception of motion."}, {"paperId": "3d6ae6e9b59a871fd9259836ac9b6b7628f697f2", "title": "Principles of Neural Science"}, {"paperId": "69e68bfaadf2dccff800158749f5a50fe82d173b", "title": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position"}, {"paperId": "c7ecc64af234f2084ca353613463afe9f6fa7060", "title": "Gestalt psychology"}, {"paperId": "db0172576316dc748aea82e8f13fb4719ac933d5", "title": "Certain Topics in Telegraph Transmission Theory"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Set transformer: A framework for attention-based permutation-invariant neural networks"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "JAX: composable transformations of Python+NumPy programs"}, {"paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82", "title": "Deep Learning"}, {"paperId": "8f18b9dde7ff8a49c3807a2dc90c0941a66dc561", "title": "Compositional Pattern Producing Networks : A Novel Abstraction of Development"}, {"paperId": "f42b865e20e61a954239f421b42007236e671f19", "title": "GradientBased Learning Applied to Document Recognition"}, {"paperId": "7bea855e19fd13461590e4f2d44bbf7b807ce3e3", "title": "A bitter lesson."}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}, {"paperId": "c66b40e54fcb1d748aa04d82f497f24ac22d6129", "title": "Distributed hierarchical processing in the primate cerebral cortex."}, {"paperId": null, "title": "The DeepMind JAX Ecosystem , 2020"}, {"paperId": null, "title": "General Perception with Iterative Attention"}]}