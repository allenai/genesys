{"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "abstract": "Transformers are state-of-the-art models for a variety of sequence modeling tasks. At their core is an attention function which models pairwise interactions between the inputs at every timestep. While attention is powerful, it does not scale efficiently to long sequences due to its quadratic time and space complexity in the sequence length. We propose RFA, a linear time and space attention that uses random feature methods to approximate the softmax function, and explore its application in transformers. RFA can be used as a drop-in replacement for conventional softmax attention and offers a straightforward way of learning with recency bias through an optional gating mechanism. Experiments on language modeling and machine translation demonstrate that RFA achieves similar or better performance compared to strong transformer baselines. In the machine translation experiment, RFA decodes twice as fast as a vanilla transformer. Compared to existing efficient transformer variants, RFA is competitive in terms of both accuracy and efficiency on three long text classification datasets. Our analysis shows that RFA's efficiency gains are especially notable on long sequences, suggesting that RFA will be particularly useful in tasks that require working with large inputs, fast decoding speed, or low memory footprints.", "venue": "International Conference on Learning Representations", "year": 2021, "citationCount": 292, "influentialCitationCount": 26, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "RFA, a linear time and space attention that uses random feature methods to approximate the softmax function, is proposed and explored, suggesting that RFA will be particularly useful in tasks that require working with large inputs, fast decoding speed, or low memory footprints."}, "embedding": {"model": "specter_v2", "vector": [0.4070110619068146, 0.6240349411964417, -0.16079220175743103, -0.24075421690940857, -0.33137625455856323, -0.05208183452486992, 0.9341756105422974, -0.3467044532299042, -0.24035866558551788, 0.0966084748506546, 0.6509809494018555, -0.08289588242769241, 0.45797020196914673, 0.22059251368045807, -0.4604807198047638, -0.011218616738915443, -0.5267325639724731, 0.3258630633354187, -0.161467045545578, -0.27774620056152344, 0.02113552950322628, -0.7799219489097595, -0.9930796027183533, -0.18302762508392334, 0.39977478981018066, 0.48295488953590393, 0.6008503437042236, 0.6715271472930908, -0.5469942092895508, 0.6525081992149353, 0.41866153478622437, -0.3744385540485382, 0.024805834516882896, -0.30025193095207214, -0.7299197912216187, -0.25789570808410645, -0.0005502602434717119, 0.021162139251828194, -0.7563684582710266, 0.728234589099884, -0.41781219840049744, 0.4949812889099121, 0.6478978395462036, -0.5744147300720215, -0.4798526167869568, 1.1359542608261108, 0.6270617246627808, 0.7355993986129761, -0.03310013562440872, -0.4313586950302124, 1.3562804460525513, -1.3609923124313354, 0.2240951955318451, 1.5134814977645874, 0.3157326579093933, 0.4338032305240631, -0.1237352266907692, -0.6776614189147949, 1.1251879930496216, 0.31142252683639526, -0.724240243434906, -0.16059818863868713, -0.17529256641864777, -0.226633220911026, 2.340324878692627, -0.24942217767238617, 0.1535082459449768, 0.43307608366012573, 0.4901222288608551, 1.2788381576538086, -0.3095325529575348, -0.7795882821083069, -0.6545610427856445, -0.08484538644552231, 0.48195186257362366, 0.6021522879600525, -0.7958198189735413, 0.327453076839447, -0.698474109172821, -0.12253819406032562, 0.07434044778347015, 0.1800413429737091, -0.012559186667203903, 0.032460812479257584, -0.32535433769226074, 0.6804553270339966, 0.3982124924659729, 0.8563687205314636, -0.39122945070266724, 0.9875975847244263, 0.3648303747177124, 0.20014405250549316, 0.04059116169810295, 0.4500764012336731, -0.31745561957359314, 0.21523137390613556, -0.4890081584453583, 0.04841476306319237, -0.4040690064430237, 0.9783511757850647, -0.17709681391716003, 0.5981967449188232, -0.8107449412345886, 0.17375127971172333, 1.3461809158325195, 0.14208364486694336, 0.5503237843513489, -0.34475022554397583, 0.09889808297157288, -0.6981507539749146, -0.18878716230392456, -0.6200265884399414, -0.026285996660590172, -0.3300202786922455, -0.6489171981811523, -1.226483702659607, -0.6131784319877625, 0.3795701563358307, -0.8964174389839172, 1.035062313079834, -0.5112141966819763, -0.09849972277879715, -0.46515777707099915, 0.11412558704614639, 0.5523577928543091, 0.9528491497039795, 0.4414990544319153, 0.06757400184869766, 0.8155699968338013, -0.7822795510292053, -0.6986026763916016, -1.0105750560760498, 0.5027675032615662, -0.31322383880615234, 0.09320876747369766, -0.13747482001781464, -1.0407893657684326, -0.8877655267715454, -0.5675172805786133, -0.10952618718147278, -0.5593337416648865, -0.013086154125630856, 0.9999083280563354, 0.165318101644516, -0.7400491833686829, 0.8883193731307983, -0.34580641984939575, -0.0027281101793050766, 0.4496432840824127, 0.5033861398696899, 0.26159536838531494, -0.38839593529701233, -1.5571845769882202, 0.6690661907196045, 0.02448812685906887, -0.4239174723625183, -0.31147271394729614, -0.5051851272583008, -1.2643221616744995, 0.10443097352981567, 0.005059277638792992, -0.6451177000999451, 1.3204210996627808, -0.5896065831184387, -1.410285472869873, 0.39429357647895813, -0.742448091506958, 0.09612812101840973, 0.08199598640203476, -0.5062214136123657, -0.2091921716928482, -1.0205209255218506, -0.19957581162452698, 0.32841405272483826, 0.5426777601242065, 0.2927275598049164, -0.11934243142604828, 0.2796652615070343, -0.421109139919281, -0.32455959916114807, -0.10159279406070709, 1.1153169870376587, -0.06119178608059883, -0.20080824196338654, -0.16019856929779053, 0.5937647819519043, -0.05343940481543541, -0.7263728976249695, -0.42840221524238586, -1.4170149564743042, 0.784782350063324, 0.11601641029119492, 0.8839195966720581, -0.7466875314712524, -0.40438276529312134, -0.40803471207618713, -0.00518907280638814, -0.25279486179351807, -0.7088975310325623, 0.6769701242446899, -0.8854606747627258, 0.2894216477870941, -0.04879520833492279, -0.700282871723175, -0.15011532604694366, -0.3331119120121002, -0.5048990845680237, 0.21241524815559387, 0.30225905776023865, 1.1761761903762817, -0.966055691242218, 0.2955269515514374, 0.2008710354566574, 0.36710256338119507, -0.748228132724762, 1.2497540712356567, -0.2652178704738617, 0.04758523032069206, -0.25039467215538025, -0.48680755496025085, 0.12019532173871994, -0.4649662673473358, 0.2786639332771301, -0.30014094710350037, -0.02721727266907692, 0.7374637722969055, 0.2603626847267151, 1.0471285581588745, -0.47322818636894226, 0.877711296081543, -0.6668161153793335, -0.9743314981460571, 0.3132772147655487, 0.35763949155807495, 0.03233576938509941, -0.37265369296073914, 0.48876211047172546, 0.09883329272270203, -0.6383641958236694, 0.24940723180770874, 0.6649073362350464, 0.5762099623680115, -0.44234699010849, 0.18079358339309692, 0.7376869320869446, -0.06256958842277527, -0.02665930613875389, 0.4489809274673462, 0.8438016772270203, 0.7936922311782837, 0.7497641444206238, -0.14891493320465088, 0.05608096346259117, -0.944060742855072, 0.094752237200737, 0.48590219020843506, 0.9935601949691772, 0.8213566541671753, 0.04069448262453079, -0.9700961709022522, -0.3461684584617615, 0.3339701294898987, 0.6855953931808472, 1.5004981756210327, -0.435859352350235, -0.4005078971385956, -0.48338446021080017, -0.45461469888687134, -0.45070070028305054, 0.2614603042602539, -0.7477284669876099, -0.5891348123550415, -0.49529898166656494, -1.107219934463501, 0.3319224715232849, 0.4384896159172058, 0.5023833513259888, -0.5632901787757874, 0.006921727210283279, -0.08522144705057144, 0.03582858666777611, -0.6566309928894043, -0.9178396463394165, 0.7838077545166016, -0.274990975856781, 0.138743594288826, -0.08400488644838333, 0.15048985183238983, 0.18904699385166168, -0.5897019505500793, 1.0087300539016724, -0.7169057130813599, -0.32373958826065063, 0.07813297212123871, 0.4043709933757782, -0.7066166400909424, -0.5042381286621094, 0.5398915410041809, 0.28648605942726135, 0.016713248565793037, 0.43260490894317627, 0.4061053395271301, 0.2861931324005127, 0.30338239669799805, -0.08485681563615799, 0.024485114961862564, -0.12969562411308289, 0.5155681371688843, 0.26906099915504456, -0.4219924807548523, -0.08727391809225082, -1.2929377555847168, 0.38905462622642517, -0.07190964370965958, -0.4684174656867981, 0.24806785583496094, -0.5604694485664368, -0.16012568771839142, 0.7572457194328308, -0.7042227387428284, -0.2961464822292328, -0.5475232005119324, 0.3891468048095703, -0.4407532513141632, 0.06545665115118027, 0.3773138225078583, 0.13298699259757996, 0.5856837630271912, 0.0328974686563015, 0.6542927622795105, 0.21944797039031982, 0.05305454134941101, 0.5339701175689697, -0.6296869516372681, 0.25966671109199524, 0.5060282945632935, 0.25325846672058105, -0.4580899775028229, -0.34103071689605713, -0.67401123046875, -0.49297624826431274, -0.20948106050491333, -0.2577824890613556, -0.286379337310791, 0.3048703074455261, -0.3707920014858246, -0.9400572776794434, 0.17060941457748413, -1.2612433433532715, -0.08105408400297165, 0.11118035763502121, -0.15712319314479828, -0.15875351428985596, -1.279773473739624, -0.8254249095916748, -0.5964062809944153, -0.3560093641281128, -0.9472694993019104, 0.3137703835964203, 0.33217746019363403, -0.42456507682800293, -0.6346486806869507, -0.14017006754875183, -0.2900185286998749, 1.1693596839904785, -0.8039349317550659, 0.8428500294685364, 0.06730648875236511, -0.45436909794807434, -0.24425335228443146, 0.5449321866035461, 0.3706682324409485, 0.04821501672267914, 0.2632473111152649, -0.8793866634368896, 0.1957116574048996, -0.41404616832733154, -0.05641360953450203, 0.223843514919281, 0.5493273735046387, 0.8152989149093628, 0.1197289377450943, -0.7808998227119446, 0.1493239402770996, 1.0215718746185303, -0.37639740109443665, 0.12121107429265976, 0.2479618787765503, 1.051773190498352, -0.06926307082176208, -0.2744629681110382, 0.627382218837738, 0.44938334822654724, 0.7980341911315918, 0.2935386002063751, -0.13507552444934845, 0.15773063898086548, -0.6340386867523193, 0.6821029186248779, 1.2701115608215332, 0.02780487947165966, -0.18690446019172668, -0.9968676567077637, 0.5314776301383972, -1.3386951684951782, -0.9791573286056519, 0.5493556261062622, 0.5790759325027466, 0.2797926962375641, -0.5822927355766296, -0.43596330285072327, -0.3867262899875641, 0.561569333076477, 0.12938131392002106, -0.42939746379852295, -0.5301665663719177, -0.03617337718605995, 0.5490638613700867, 0.2666456997394562, 0.8365132212638855, -0.26706498861312866, 0.7894086241722107, 14.925796508789062, 0.6557672023773193, -0.3136904537677765, 0.6402341723442078, 0.6066780686378479, 0.04017717391252518, -0.23781649768352509, 0.07758801430463791, -1.3336199522018433, 0.013584268279373646, 1.1089093685150146, -0.10516040027141571, 0.49640342593193054, 0.08351505547761917, 0.08960340172052383, 0.5025051236152649, -0.4596036970615387, 0.7392500638961792, 0.4695073664188385, -1.0535991191864014, 0.4364663064479828, 0.20486116409301758, 0.020878586918115616, 0.686415433883667, 0.6804627776145935, 0.7462189197540283, 0.9358371496200562, -0.9111465215682983, 0.5169535875320435, 0.6482080221176147, 0.7812067270278931, 0.019339527934789658, 0.37799274921417236, 0.20799729228019714, -1.038074254989624, -0.3593413233757019, -0.4961981177330017, -1.123081088066101, 0.35568299889564514, 0.22364407777786255, -0.4065457880496979, -0.3525891900062561, -0.2881864905357361, 1.0872553586959839, 0.22191309928894043, 0.17514394223690033, -0.16424378752708435, 0.7382522225379944, 0.07617305219173431, -0.1601870059967041, 0.23940671980381012, 0.6437864899635315, 0.056540556252002716, 0.07505793124437332, -0.10895854234695435, -0.056503910571336746, 0.04687296226620674, 0.17305588722229004, -0.40734684467315674, -0.1577633023262024, -0.4342024624347687, -0.2652507424354553, -0.07579740881919861, 0.6458207964897156, 0.7514150142669678, 0.18987999856472015, -0.4892207384109497, 0.14957715570926666, 0.5037477016448975, 0.052230242639780045, -0.6541271209716797, -0.14741748571395874, 0.3355834484100342, -0.08617543429136276, 0.1106216311454773, 0.6917405724525452, 0.10621153563261032, -0.5679355263710022, -0.8159706592559814, -0.2371520698070526, 0.2418602705001831, -0.9279334545135498, -1.0044856071472168, 1.1406534910202026, -0.26830410957336426, -0.3908179998397827, 0.14654870331287384, -0.534528911113739, -0.13158096373081207, 0.7306602597236633, -1.2097814083099365, -0.604277491569519, 0.24084730446338654, -0.36214888095855713, -0.02397798001766205, -0.1662643998861313, 1.1278738975524902, 0.01060180552303791, -0.15425877273082733, 0.09143567085266113, -0.015455941669642925, 0.12119460105895996, -0.4681659936904907, -0.6361599564552307, 0.8731198906898499, 0.04617873951792717, -0.299482524394989, 0.3282473683357239, 0.21397921442985535, 0.20400835573673248, -0.8420029878616333, -0.13655810058116913, 1.0969690084457397, -1.112760305404663, -0.5022075772285461, -1.0355637073516846, -0.951053261756897, 0.42829498648643494, 0.5655016899108887, -0.17493462562561035, 0.39847373962402344, 0.3320619761943817, -0.552111804485321, -0.08359480649232864, -0.4323333501815796, -0.25268977880477905, 0.4291643500328064, -0.6855364441871643, -0.39276257157325745, -0.0293912161141634, 0.3362402021884918, -0.6661142706871033, -0.22430148720741272, -0.4335855543613434, 0.17536114156246185, 0.5399409532546997, 0.9189964532852173, -0.8501333594322205, 0.6678528785705566, 0.6608477830886841, 0.04406003654003143, -1.0244449377059937, -0.7620596885681152, -1.1678249835968018, 0.3339613080024719, 0.276263564825058, 0.7516521215438843, -0.5686054825782776, -0.1777345836162567, 0.6389548182487488, 0.31340014934539795, -0.39906343817710876, -0.7150238156318665, -0.3017512857913971, 0.1507105678319931, -0.3971346616744995, 0.4687115550041199, 0.07413917779922485, 0.13151657581329346, 0.5340108275413513, 0.0029194066300988197, 0.07470481097698212, -0.5203049182891846, -0.832399308681488, 0.1743127554655075, -0.2964686155319214, -0.1339852511882782, -0.7767981886863708, -0.6246311664581299, -1.5494707822799683, 0.25624847412109375, -1.349351167678833, 0.15105916559696198, -1.056670069694519, -0.12577685713768005, 0.3931770622730255, -0.2726193368434906, 0.4609377980232239, -0.08162913471460342, -0.5832139849662781, -0.39480435848236084, -0.766074538230896, -0.40865829586982727, 1.1250818967819214, 0.7020906209945679, -0.8564611673355103, 0.30505096912384033, 0.1250050663948059, -0.12546469271183014, -0.07026500999927521, 0.2458457201719284, -0.7589422464370728, -0.5674176812171936, -1.3189783096313477, 0.308378130197525, 0.08750994503498077, -0.2660282552242279, -0.2265164852142334, 0.44981008768081665, 0.09173125773668289, 0.09758207947015762, 0.2509285509586334, 0.3414134681224823, -0.7716641426086426, -0.10832089185714722, 0.24045370519161224, -0.864139199256897, 0.5340391397476196, -0.04966537654399872, -0.6029511094093323, -0.13973882794380188, 0.7933053970336914, 0.13324794173240662, -1.3833651542663574, 0.05851861089468002, 0.6659221649169922, -1.1284059286117554, 0.03577699884772301, -0.11369310319423676, -0.2901000678539276, -1.12162184715271, -0.6200624704360962, 0.06764121353626251, 0.35651808977127075, -0.5547512769699097, 1.3302158117294312, 0.3156335651874542, -1.1610515117645264, -0.05238890275359154, 0.2748938202857971, -0.2048662304878235, -0.1385253369808197, 0.35360512137413025, 0.5403612852096558, 0.2505034804344177, 0.658471941947937, 0.5434322953224182, 0.1995803266763687, -1.1370919942855835, 0.08494020998477936, 1.0714083909988403, -0.42545366287231445, -0.326547235250473, 1.1012665033340454, 0.033948641270399094, -1.0927793979644775, 0.07997686415910721, -0.9984875917434692, -0.5893704891204834, -0.2786528170108795, 0.6372771263122559, -0.16322265565395355, -0.057382404804229736, -0.16609704494476318, -0.6689286828041077, 0.294983834028244, -0.25466856360435486, -0.31867891550064087, 1.035420298576355, -0.22814418375492096, -0.3145507276058197, 0.7915245294570923, 0.8322579860687256, -0.8155176043510437, -0.3970954120159149, -0.8507858514785767, -0.33414822816848755, -0.3289526700973511, 0.35955432057380676, -0.4274134933948517, -0.7715190052986145, 0.8903256058692932, 0.4046114385128021, 0.22971057891845703, 0.12617354094982147, 0.08507119864225388, -0.2880842983722687, 0.2446146160364151, 0.05526120588183403, -0.16038461029529572, -0.7718114852905273, 1.889768123626709, 1.3328614234924316, -0.4277082085609436, 0.07448402047157288, -0.24106904864311218, -0.670755922794342, 0.9917991757392883, 0.2131631225347519, -0.016896875575184822, 0.9740814566612244, -0.21382522583007812, -0.001976564060896635, 0.16294483840465546, -1.5580567121505737, -0.08491398394107819, 0.7448462247848511, 1.0779763460159302, 1.1682337522506714, 0.17233815789222717, 0.2801731526851654, 0.6029216647148132, 0.0503167062997818, 0.23039855062961578, 0.63615483045578, 0.4321245551109314, -0.1282816082239151, -0.19146326184272766, 0.20534418523311615, 0.7184267044067383, -0.9442238807678223, -0.6349567770957947, 0.07959263771772385, 0.05589166656136513, 0.028712749481201172, 0.4154829680919647, 0.6842664480209351, -0.011203443631529808, 0.4203225076198578, 0.23178134858608246, 0.6135886907577515, -0.4926322400569916, -0.6536434292793274, -0.3518752455711365, -0.7481695413589478, -0.08376244455575943, -0.06087794527411461, -0.8585826754570007, -0.22530394792556763, -0.024374723434448242, -0.11782735586166382, 0.25456658005714417, 0.2444012612104416, 1.412150263786316, 0.5433371663093567, 0.6765308380126953, 0.054986514151096344, -0.43413734436035156, -0.2210211157798767, -1.287174105644226, 0.2925482392311096, -0.6953253746032715, 0.09396038204431534, -0.6093050241470337, -0.005782634485512972, -0.27085962891578674]}, "authors": [{"authorId": "1818378366", "name": "Hao Peng"}, {"authorId": "143958923", "name": "Nikolaos Pappas"}, {"authorId": "1755465", "name": "Dani Yogatama"}, {"authorId": "4671928", "name": "Roy Schwartz"}, {"authorId": "144365875", "name": "Noah A. Smith"}, {"authorId": "47648549", "name": "Lingpeng Kong"}], "references": [{"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "8c5a394654822a5de53ac2e4a355c1c6ead4750c", "title": "Deep Encoder, Shallow Decoder: Reevaluating the Speed-Quality Tradeoff in Machine Translation"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "d97cd476bef990352ae921e4c7c5ae1222e9b8da", "title": "A Mixture of h - 1 Heads is Better than h Heads"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "07a9f47885cae97efb7b4aa109392128532433da", "title": "Hard-Coded Gaussian Attention for Neural Machine Translation"}, {"paperId": "8af925f4edf45131b5b6fed8aa655089d58692fa", "title": "Lite Transformer with Long-Short Range Attention"}, {"paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d", "title": "ETC: Encoding Long and Structured Inputs in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "114745b95c7029c5163b745a37829d1e85fc3083", "title": "Recurrent Positional Embedding for Neural Machine Translation"}, {"paperId": "68bf7fe0bcc81db4695ef103f071b378ef0dcd31", "title": "Exploring Kernel Functions in the Softmax Layer for Contextual Word Classification"}, {"paperId": "59a916cdc943f0282908e6f3fa0360f4c5fb78d0", "title": "Stabilizing Transformers for Reinforcement Learning"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d", "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"}, {"paperId": "8cef9900c04d7f661c08f4b5b1ed4337ace042a3", "title": "Transformer Dissection: An Unified Understanding for Transformer\u2019s Attention via the Lens of Kernel"}, {"paperId": "2a687609ac1cecb9b20ba52d4f5d72ba14e0eaf2", "title": "Sampled Softmax with Random Fourier Features"}, {"paperId": "36e30516683032634975c53e60f3737b6e35ff80", "title": "Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting"}, {"paperId": "f4238bd2385a52413ccbacfd9e409a650235bd13", "title": "Adaptive Attention Span in Transformers"}, {"paperId": "606c03a5bb36b77bfc99e33fd7cb6731b13b8eab", "title": "Transformers with convolutional context for ASR"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "528b5f5356bc7ad91edc4dc074b0273e1e55fb03", "title": "Modeling Recurrence for Transformer"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "fea820b7d953d32069e189af2961c28fd213470b", "title": "Pay Less Attention with Lightweight and Dynamic Convolutions"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "e20ff55e87e2b3ef02ae0529880bb705f5efbcae", "title": "Document-Level Neural Machine Translation with Hierarchical Attention Networks"}, {"paperId": "a56ebc39b8c527774be705cccdcb5f66c7302e0c", "title": "Rational Recurrences"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "bf8fe437f779f2098f9af82b534aa51dc9edb06f", "title": "Scaling Neural Machine Translation"}, {"paperId": "b4bfadfca9742bb3ee98a0cd322d5ce4e59a3ceb", "title": "A Call for Clarity in Reporting BLEU Scores"}, {"paperId": "249ac07c5b87f44b85500e2d26b68a7edb93e83d", "title": "Differentiable plasticity: training plastic neural networks with backpropagation"}, {"paperId": "8b354d76813bd5375e7e5c8d17f630bec5936a01", "title": "ListOps: A Diagnostic Dataset for Latent Tree Learning"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "3fc5ed18c2294596af072df929c8ee12c71f96a2", "title": "Classical Structured Prediction Losses for Sequence to Sequence Learning"}, {"paperId": "58c6f890a1ae372958b7decf56132fe258152722", "title": "Regularizing and Optimizing LSTM Language Models"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "489f3f36a0606f03155701030081d98cc7090754", "title": "Faster Kernel Ridge Regression Using Sketching and Preconditioning"}, {"paperId": "32e934094c4d17fe4d734b2e169ba5e3cd0ee05e", "title": "Orthogonal Random Features"}, {"paperId": "c91ae35dbcb6d479580ecd235eabf98374acdb55", "title": "Using Fast Weights to Attend to the Recent Past"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "f63e917638553414526a0cc8550de4ad2d83fe7a", "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "ac5213df37aaf92ae4f5fb656224ff30906190b6", "title": "Fast Function to Function Regression"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "2b55f034a3874ad4a4b7f389e6f89e3bf2d1801e", "title": "Quasi-Monte Carlo Feature Maps for Shift-Invariant Kernels"}, {"paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e", "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"}, {"paperId": "5ec85a0d88adcc4344bb5cc81b0d1aef9bcd8dcc", "title": "Findings of the 2014 Workshop on Statistical Machine Translation"}, {"paperId": "5f5dc5b9a2ba710937e2c413b37b053cd673df02", "title": "Auto-Encoding Variational Bayes"}, {"paperId": "bd5fc28c7356915ec71abafbe86b7596c60720aa", "title": "The conference paper"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "77e379fd57ea44638fc628623e383eccada82689", "title": "Kernel Methods for Deep Learning"}, {"paperId": "7a59fde27461a3ef4a21a249cc403d0d96e4a0d7", "title": "Random Features for Large-Scale Kernel Machines"}, {"paperId": "d37fc9e9c4fedc32865b08661e7fb950df1f8fbe", "title": "Kernel methods in machine learning"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "61639af1a89c69094bcc0ed40fad752832b037c3", "title": "Reducing the Ratio Between Learning Complexity and Number of Time Varying Variables in Fully Recurrent Nets"}, {"paperId": "bc22e87a26d020215afe91c751e5bdaddd8e4922", "title": "Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks"}, {"paperId": "ce9a21b93ba29d4145a8ef6bf401e77f261848de", "title": "A Learning Algorithm for Continually Running Fully Recurrent Neural Networks"}, {"paperId": "54c922b956f8d07a81799b8f94d241b3ec0d40fa", "title": "Harmonic Analysis and the Theory of Probability"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "1d8191f8a264be8251a36155bb287c0eafedc9f5", "title": "Random Features Methods in Supervised Learning"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Set transformer: A framework for attention-based permutation-invariant neural networks"}, {"paperId": "406ee84afaf116f52b169494c1d0ede2da4f9f05", "title": "An Empirical Study on The Properties of Random Bases for Kernel Methods"}, {"paperId": "81aace0e90c6a962059b117c24db0d856f340f41", "title": "Report on the 11th IWSLT evaluation campaign"}, {"paperId": null, "title": "The ACL Anthology network"}]}