{"paperId": "d0deaec3e1f74701ac43600d9e64c5c969be7391", "abstract": "With large language models (LLMs) widely deployed in long content generation recently, there has emerged an increasing demand for efficient long-sequence inference support. However, key-value (KV) cache, which is stored to avoid re-computation, has emerged as a critical bottleneck by growing linearly in size with the sequence length. Due to the auto-regressive nature of LLMs, the entire KV cache will be loaded for every generated token, resulting in low utilization of computational cores and high latency. While various compression methods for KV cache have been proposed to alleviate this issue, they suffer from degradation in generation quality. We introduce TriForce, a hierarchical speculative decoding system that is scalable to long sequence generation. This approach leverages the original model weights and dynamic sparse KV cache via retrieval as a draft model, which serves as an intermediate layer in the hierarchy and is further speculated by a smaller model to reduce its drafting latency. TriForce not only facilitates impressive speedups for Llama2-7B-128K, achieving up to 2.31$\\times$ on an A100 GPU but also showcases scalability in handling even longer contexts. For the offloading setting on two RTX 4090 GPUs, TriForce achieves 0.108s/token$\\unicode{x2014}$only half as slow as the auto-regressive baseline on an A100, which attains 7.78$\\times$ on our optimized offloading system. Additionally, TriForce performs 4.86$\\times$ than DeepSpeed-Zero-Inference on a single RTX 4090 GPU. TriForce's robustness is highlighted by its consistently outstanding performance across various temperatures. The code is available at https://github.com/Infini-AI-Lab/TriForce.", "venue": "arXiv.org", "year": 2024, "citationCount": 11, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "TriForce is introduced, a hierarchical speculative decoding system that is scalable to long sequence generation that leverages the original model weights and dynamic sparse KV cache via retrieval as a draft model, which serves as an intermediate layer in the hierarchy and is further speculated by a smaller model to reduce its drafting latency."}, "embedding": {"model": "specter_v2", "vector": [0.4830613136291504, 0.35594332218170166, -0.39162546396255493, 0.1937805712223053, -0.3922199308872223, -0.24961838126182556, 0.6004670858383179, -0.014967459253966808, -0.4924669861793518, -0.18010444939136505, 0.7201268076896667, -0.26782023906707764, 0.6020520925521851, -0.2632717192173004, -0.29862695932388306, -0.016203492879867554, -0.9222071766853333, 0.15570507943630219, 0.05077523738145828, -0.19999916851520538, 0.21006067097187042, -0.687667965888977, -1.5459133386611938, 0.3174518644809723, 0.6047526001930237, 0.6152225732803345, 0.10646245628595352, 1.3496662378311157, -0.4333634674549103, 0.14916697144508362, 0.5635839104652405, -0.3199373781681061, 0.12469329684972763, -0.11735975742340088, -0.3169713318347931, -0.40271827578544617, -0.09389982372522354, -0.7611627578735352, -0.2619723677635193, 0.6321474313735962, -0.15367576479911804, 0.1763591468334198, 0.2510749399662018, -0.7161812782287598, -0.0020809639245271683, 1.1812561750411987, 0.3478604257106781, 0.604877233505249, 0.0846882089972496, -0.5853369235992432, 1.316837191581726, -1.4860085248947144, 0.2737589180469513, 1.110407829284668, 0.5258724689483643, 0.3471889793872833, -0.003943068906664848, -0.3610575199127197, 0.6299540400505066, -0.1080656424164772, -0.983422577381134, -0.32927167415618896, -0.3951956331729889, -0.030239056795835495, 1.6799838542938232, -0.22056515514850616, 0.551047682762146, 0.6485884189605713, -0.030948081985116005, 1.3735487461090088, -0.33480533957481384, -0.8045381903648376, -0.05511278286576271, -0.2309853732585907, 0.3451460599899292, 0.7842831015586853, -0.00867806002497673, 0.53181391954422, -0.9543080925941467, -0.34083840250968933, 0.41876551508903503, -0.2593042850494385, 0.22093382477760315, 0.10298747569322586, -0.2602476477622986, 0.8499479293823242, -0.11162609606981277, 0.6160141229629517, -0.11442971229553223, 0.7944236993789673, 0.8258784413337708, -0.1453913450241089, 0.40103015303611755, 0.010282468050718307, -0.028139149770140648, -0.18296515941619873, -1.4767283201217651, 0.6895447373390198, 0.04338973015546799, 0.9390426874160767, -0.2681654691696167, 0.551452100276947, -0.939661979675293, -0.16881120204925537, 1.1870783567428589, 0.2319841980934143, 0.7366427779197693, -0.49574434757232666, -0.13080665469169617, -1.2411575317382812, -0.02388891577720642, -0.25535282492637634, -0.09137962013483047, -0.21020273864269257, -0.7965510487556458, -1.1557083129882812, -0.5270456671714783, -0.0045434413477778435, -0.804824709892273, 0.5080892443656921, -0.29460999369621277, 0.8471171855926514, 0.28434666991233826, 0.4681705832481384, 0.6991602778434753, 0.8302651047706604, 0.12343384325504303, -0.16034449636936188, 0.8864850997924805, -1.1122395992279053, -0.254915326833725, -0.9121730327606201, 0.672807514667511, -0.2913583815097809, -0.07571738958358765, -0.015892015770077705, -1.724212408065796, -1.134454607963562, -0.866256058216095, -0.06749767065048218, -0.4244317412376404, -0.036440812051296234, 1.237949252128601, 0.5315976738929749, -0.9296833872795105, 0.7250488996505737, -0.30993181467056274, 0.0788007527589798, 0.26652905344963074, -0.24836365878582, 0.6024357080459595, -0.23469635844230652, -1.379625916481018, -0.22014379501342773, 0.2889556884765625, -0.5089868903160095, -0.12784235179424286, -0.8494392037391663, -1.0024045705795288, 0.11692146211862564, 0.21451696753501892, -0.3754385709762573, 1.2885191440582275, 0.15946702659130096, -1.1550809144973755, 0.37566089630126953, -0.5611449480056763, -0.20530803501605988, 0.2986869513988495, -0.3067954182624817, -0.2807542085647583, -0.2634698748588562, -0.08942800760269165, 0.49469390511512756, 0.6530536413192749, -0.11086319386959076, -0.5613700151443481, 0.3752860724925995, -0.4101085662841797, -0.19540230929851532, 0.09572436660528183, 0.5781717896461487, -0.5918020009994507, -0.30847787857055664, 0.1311904340982437, 0.38669759035110474, -0.4378281235694885, -0.394747257232666, -0.386952668428421, -0.9194601774215698, 0.4117374122142792, -0.12249591946601868, 1.0398670434951782, -0.6310098171234131, -0.9129629731178284, 0.00508014066144824, -0.15515142679214478, -0.003001092467457056, -0.5019589066505432, 0.39475491642951965, -0.34077733755111694, 0.5802479386329651, -0.011154563166201115, -0.5465349555015564, -0.055780358612537384, -0.43531525135040283, -1.1067272424697876, -0.42994606494903564, 0.11857755482196808, 1.1123955249786377, -1.0803083181381226, 0.05700691416859627, -0.1975875347852707, 0.2509461045265198, -1.4273722171783447, 1.10484778881073, -0.6788849234580994, 0.2216651439666748, -0.37633785605430603, -0.3829329013824463, 0.25426048040390015, -0.27902135252952576, 0.3854025602340698, -0.28890326619148254, -0.17679479718208313, 0.26513007283210754, -0.09851814806461334, 1.5694280862808228, -0.08572385460138321, 0.12482796609401703, -0.6567931771278381, -0.40439146757125854, 0.28819984197616577, 0.23683448135852814, 0.015510755591094494, -0.4045971930027008, 0.21814386546611786, 0.5072502493858337, -0.4474546015262604, 0.3438774645328522, 1.1983869075775146, 0.8137259483337402, -0.6502404808998108, 0.3412987291812897, 0.28242743015289307, -0.19285106658935547, 1.0137819051742554, 0.7509020566940308, 0.5278632044792175, 0.8924229145050049, 0.2627611756324768, -0.059058450162410736, 0.5569576621055603, -0.7163197994232178, -0.14158429205417633, 0.8610414266586304, 1.0161796808242798, 0.9462993144989014, 0.33317869901657104, -1.0086333751678467, -0.9285907745361328, 0.24199223518371582, 0.7648767232894897, 1.225395679473877, -0.07225335389375687, -0.6318064332008362, -0.8747043013572693, -0.17031022906303406, -0.2803126275539398, 0.39829346537590027, -0.1595516800880432, -0.24227844178676605, -0.5547162294387817, -0.9637207388877869, 0.9968506693840027, 0.20965872704982758, 0.6620457768440247, -0.5804545283317566, -0.4400348961353302, -0.3322199583053589, 0.041398439556360245, -1.0430819988250732, -0.5218816995620728, -0.07250773906707764, -0.1684199571609497, 0.31455346941947937, -0.014136889018118382, 0.2045745849609375, 0.16511599719524384, -0.7374048829078674, 1.06390380859375, -0.027872493490576744, -0.46663591265678406, -0.10585662722587585, 0.2620329260826111, -0.3179381489753723, -1.1666839122772217, 0.21229466795921326, 0.06880584359169006, -0.5326955318450928, 0.25256407260894775, 0.5144283175468445, -0.0728796198964119, -0.51004958152771, -0.23968614637851715, 0.6871320605278015, -0.1860426664352417, 0.024563506245613098, 0.45505237579345703, -0.307858943939209, -0.11900666356086731, -0.8872946500778198, 0.7402523756027222, 0.19772298634052277, -0.6319661140441895, 0.0010775026166811585, -0.7986259460449219, -0.23965007066726685, 0.7544844150543213, -0.46880075335502625, -0.42031005024909973, -1.2368913888931274, -0.1570824831724167, -0.16913524270057678, -0.27511993050575256, -0.017739707604050636, 0.6219850778579712, 0.5940942168235779, -0.1069582924246788, 0.9460573196411133, 0.10778495669364929, -0.14507751166820526, 0.8386077880859375, -0.9857338070869446, 0.5968409180641174, -0.1460360288619995, 0.0636601448059082, -0.14659415185451508, -0.09484060108661652, -0.5305533409118652, -0.2737100124359131, -0.181123286485672, -0.5020204186439514, -0.5456364154815674, 0.30484235286712646, -0.7182796001434326, -0.9473608732223511, 0.03237789869308472, -1.2300182580947876, -0.22646649181842804, 0.1286049783229828, -0.32898709177970886, -0.4278653562068939, -0.5788821578025818, -1.3667665719985962, -0.45237696170806885, -1.192818284034729, -1.09707772731781, 0.6623608469963074, -0.09921984374523163, -0.4206361174583435, -0.32089999318122864, 0.02661101706326008, -0.3343324661254883, 0.5814490914344788, -0.7034278512001038, 0.7619919776916504, -0.0005782669177278876, -0.3331373333930969, -0.048543691635131836, 0.12627650797367096, 0.15239645540714264, -0.8194105625152588, 0.462586373090744, -0.4251329004764557, 0.013339963741600513, -0.9431467056274414, -0.3282807767391205, 0.4215148985385895, 0.25865843892097473, 0.7365247011184692, 0.08564342558383942, -0.7286275625228882, 0.5976144075393677, 1.3515926599502563, -0.5656676888465881, 0.4016536772251129, -0.14798112213611603, 1.0394413471221924, -0.26578614115715027, 0.10826265811920166, 1.1184433698654175, 0.057900309562683105, 0.37090060114860535, -0.12359907478094101, -0.0753699317574501, -0.05750862881541252, -0.6959341168403625, 0.7466121912002563, 1.9077476263046265, 0.24419432878494263, -0.2907499670982361, -0.6626456379890442, 0.5971081852912903, -1.1877496242523193, -0.846685528755188, 0.397601842880249, 0.8476754426956177, 0.216032937169075, -0.3318023681640625, -0.21487784385681152, -0.1938435137271881, 0.3583710193634033, 0.3831155300140381, -0.32057884335517883, -1.229699730873108, 0.21129703521728516, 0.428635835647583, 0.048127681016922, 0.4581851661205292, 0.18252742290496826, 0.9256598949432373, 14.85841178894043, 1.2875761985778809, 0.19287145137786865, 0.26333296298980713, 0.9668177366256714, 0.08643520623445511, -0.8032823801040649, -0.13089746236801147, -1.6005527973175049, -0.008513814769685268, 1.606676459312439, -0.19771304726600647, 0.2215651273727417, 0.2192804366350174, 0.3054458200931549, 0.10967843234539032, -0.14502400159835815, 0.35694819688796997, 0.5702167749404907, -1.6832771301269531, 0.7676869034767151, 0.22661228477954865, 0.16910530626773834, 0.5936384201049805, 0.5943296551704407, 0.8964803218841553, 0.5187921524047852, -0.2705233097076416, 0.7509339451789856, 0.18303167819976807, 1.1802747249603271, -0.3246283531188965, 0.35370177030563354, 0.3794957101345062, -1.1276782751083374, 0.10240782052278519, -0.7687451243400574, -1.2544362545013428, 0.6176066398620605, 0.4863651394844055, -0.798425018787384, -0.2572031617164612, -0.36035189032554626, 0.8188185691833496, 0.3400276005268097, 0.14183957874774933, 0.032625868916511536, 0.8791186213493347, -0.012209160253405571, 0.03592046722769737, 0.44282618165016174, 0.052208662033081055, 0.28283610939979553, -0.06102195382118225, 0.5716597437858582, 0.062006875872612, 0.16555070877075195, 0.6467127799987793, -0.23958592116832733, -0.14146625995635986, -0.2911199927330017, -0.3124144971370697, -0.14223067462444305, 0.6508095860481262, 0.0786561593413353, 0.031876590102910995, -0.48774561285972595, 0.424148827791214, 0.4750922918319702, -0.23041294515132904, -0.6323146820068359, 0.30488327145576477, 0.35959991812705994, -0.42871254682540894, 0.358447790145874, 0.5323455333709717, 0.0503200888633728, -0.8004565238952637, -0.937947154045105, -0.5178552865982056, 0.1632285714149475, -0.7798770666122437, -0.3937641978263855, 0.8812665939331055, -0.1761941760778427, -0.32565927505493164, -0.3468994200229645, -0.40531885623931885, -0.28373607993125916, 0.17059572041034698, -1.316656470298767, -0.7141311168670654, 0.5470864772796631, -0.39457350969314575, 0.028973720967769623, 0.10206124186515808, 1.333416223526001, -0.07279647886753082, -0.1546616554260254, 0.061390653252601624, 0.29756930470466614, -0.2183889001607895, -0.7215440273284912, -0.5254288911819458, 1.523223876953125, 0.6257411241531372, -0.097957082092762, 0.05548955500125885, 0.024199722334742546, -0.14539220929145813, -1.0059294700622559, -0.06220928952097893, 0.5386846661567688, -0.4594152271747589, -0.4192785620689392, -1.2052946090698242, -0.6337716579437256, 0.16700132191181183, 0.5056280493736267, -0.26758185029029846, 0.14045988023281097, -0.1148609146475792, -0.2925991117954254, 0.04253080114722252, -0.4522522985935211, 0.20200477540493011, 0.6246552467346191, -0.2676587402820587, 0.4405543804168701, -0.26296529173851013, 0.7321639060974121, -1.0474586486816406, -0.6016910672187805, -0.14812609553337097, 0.6170393824577332, -0.41291674971580505, 0.9761465787887573, 0.10116323083639145, 0.9673218727111816, 1.0998733043670654, 0.1714327484369278, -0.3410457968711853, -0.048725295811891556, -1.2125951051712036, 0.10215075314044952, 0.22096332907676697, 0.534488320350647, 0.0300909373909235, 0.6338825225830078, 0.6604599952697754, 0.5186865329742432, -0.6535399556159973, -0.5298546552658081, 0.012206700630486012, 0.33380600810050964, -1.0365285873413086, 0.5082087516784668, -0.6629835963249207, 0.10184255242347717, -0.015023184940218925, -0.09180288016796112, 0.5601829290390015, -0.23691201210021973, -0.3812939524650574, 0.6060161590576172, 0.3507944941520691, 0.060180965811014175, -0.3956167697906494, -0.39173614978790283, -1.5169188976287842, -0.018465202301740646, -1.193379282951355, 0.17362381517887115, -0.5587136149406433, -0.3184855580329895, 0.026637690141797066, 0.0869220495223999, -0.26420941948890686, 0.28623753786087036, -0.09594448655843735, -0.36034974455833435, -0.8164913058280945, -0.6396986246109009, 0.8507522940635681, 0.721203625202179, -0.39738762378692627, 0.46971583366394043, -0.2062937170267105, 0.3883821368217468, 0.2423921674489975, 0.2206771969795227, -0.34455859661102295, -0.880149781703949, -0.9718179702758789, 0.6081832647323608, 0.11892813444137573, -0.23032474517822266, -0.7350048422813416, 0.11805008351802826, 0.616422176361084, -0.09055790305137634, -0.3952430188655853, 0.09120907634496689, -0.3753066658973694, -0.48774316906929016, 0.5625225901603699, -0.7428471446037292, 0.27616626024246216, 0.31913140416145325, -0.6586759090423584, 0.10051155835390091, 0.414251446723938, -0.3826921582221985, -1.0750004053115845, -1.0261473655700684, 0.5995897650718689, -0.8413844108581543, 0.16220194101333618, -0.4306888282299042, -0.2008955329656601, -0.837888240814209, -0.3695770502090454, -0.013667606748640537, 0.023270446807146072, -0.22399947047233582, 1.2730969190597534, 0.7288603782653809, -0.8835318088531494, -0.15556150674819946, 0.6723755598068237, -0.32545366883277893, 0.007097919471561909, 0.5643131732940674, 0.08297821879386902, -0.3790924847126007, 0.5610829591751099, 0.5494830012321472, 0.27155765891075134, -0.9375579357147217, 0.29161903262138367, 0.1554071605205536, -0.8437033295631409, -0.4530882239341736, 0.9108194708824158, -0.4960850179195404, -0.7772690653800964, -0.5259143710136414, -1.078859806060791, -0.48625603318214417, -0.6843370795249939, 0.8974872827529907, 0.26343780755996704, -0.2975054979324341, -0.21963323652744293, -0.49297669529914856, 0.16431382298469543, -0.4210001528263092, -0.7407864928245544, 0.3543626070022583, -0.27741682529449463, -0.5716169476509094, 0.2907026410102844, 0.7804665565490723, -0.4204391837120056, -0.3931981325149536, -0.2951284348964691, -0.5694760084152222, -0.057351358234882355, 0.39856380224227905, -0.20917996764183044, -0.3699674904346466, 0.6595110893249512, 0.30063334107398987, 0.2861618995666504, -0.009437857195734978, -0.3933524787425995, 0.866194486618042, 0.1588878631591797, 0.32714688777923584, -0.3030555546283722, -0.5902779698371887, 1.2962024211883545, 0.7943774461746216, -0.47528502345085144, 0.4824013411998749, -0.14197584986686707, -0.6910962462425232, 1.1331546306610107, 0.2354588508605957, -0.06163392961025238, 0.7019674777984619, 0.24214859306812286, -0.07371991127729416, 0.5132068395614624, -1.2892924547195435, -0.35937467217445374, 0.7266245484352112, 0.8262170553207397, 0.7507506608963013, 0.005716394633054733, -0.10573098063468933, 0.8783864378929138, 0.07907925546169281, 0.518761396408081, 0.7448096871376038, 0.2647359371185303, -0.019136425107717514, -0.11694935709238052, 0.04479328542947769, 0.7938265800476074, -0.7977320551872253, -1.243330717086792, 0.8590980768203735, 0.07847215980291367, 0.23775506019592285, 0.5612329840660095, 1.1603330373764038, 0.30212509632110596, -0.17748712003231049, -0.007563923019915819, 0.6414587497711182, -0.2205161154270172, -0.12213724851608276, 0.27178317308425903, -0.49393928050994873, -0.11362973600625992, 0.050710760056972504, -0.5490941405296326, -0.8471741676330566, -0.46458742022514343, 0.1702672690153122, 0.30469805002212524, 0.1411258578300476, 1.2052844762802124, 0.6757462620735168, 0.5120104551315308, -0.4015490412712097, -0.6732768416404724, -0.1785302460193634, -0.5292413830757141, -0.07603919506072998, -0.24080242216587067, -0.32564252614974976, 0.2549644708633423, 0.23565199971199036, -0.02107606828212738]}, "authors": [{"authorId": "2297403194", "name": "Hanshi Sun"}, {"authorId": "2280390208", "name": "Zhuoming Chen"}, {"authorId": "2284120415", "name": "Xinyu Yang"}, {"authorId": "2249538771", "name": "Yuandong Tian"}, {"authorId": "2249538643", "name": "Beidi Chen"}], "references": [{"paperId": "89e0fde2dc60f8520c176a57396c6cad3af5dc40", "title": "No Token Left Behind: Reliable KV Cache Compression via Importance-Aware Mixed Precision Quantization"}, {"paperId": "f608011b0f50a14bb2949c186a7c632a099aa75b", "title": "WKVQuant: Quantizing Weight and Key/Value Cache for Large Language Models Gains More"}, {"paperId": "df6239d0c9acac4d8a700946aa323a998daedbc3", "title": "Sequoia: Scalable, Robust, and Hardware-aware Speculative Decoding"}, {"paperId": "d0b049018c9e21b7b95c179d33e1e2ac9113c85b", "title": "Hydra: Sequentially-Dependent Draft Heads for Medusa Decoding"}, {"paperId": "f1a9e0830bc36c048fa4659beaa62609869895b5", "title": "Break the Sequential Dependency of LLM Inference Using Lookahead Decoding"}, {"paperId": "1165d59f765dcc629b2c4293c05d102527b26f86", "title": "Decoding Speculative Decoding"}, {"paperId": "b085968c4362fb286ad6c5ef71a5db9630da0498", "title": "KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization"}, {"paperId": "1b5db3170c195508ff24fee8eda0d4987e806f0b", "title": "EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty"}, {"paperId": "57e7af0b69325fafb371ef5d502e39ef9c90ef7e", "title": "Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads"}, {"paperId": "0cee098244c9978032702862a43a09f468f691a4", "title": "Unlocking Efficiency in Large Language Model Inference: A Comprehensive Survey of Speculative Decoding"}, {"paperId": "fd2cb81c01d9ab51c78de69b53f8b337775e290c", "title": "DocFinQA: A Long-Context Financial Reasoning Dataset"}, {"paperId": "2b8439f319dfa73df62ca8957ff6d0c1f3c7a73c", "title": "Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon"}, {"paperId": "a9468d8bfa6bd016dfd3128c4e8408e30eb8549b", "title": "LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning"}, {"paperId": "e30666ed82670463aa47686e744f0c6f2a0e083d", "title": "Cascade Speculative Drafting for Even Faster LLM Inference"}, {"paperId": "4d76206515d6b33903937474273885476fc2771e", "title": "FlashDecoding++: Faster Large Language Model Inference on GPUs"}, {"paperId": "95240dda409e28acccdc5cf619ad0c036cf4292d", "title": "Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time"}, {"paperId": "ea1f648988c632a6dbab6d8b88432456aa021cfb", "title": "SpecTr: Fast Speculative Decoding via Optimal Transport"}, {"paperId": "f206d34afed6a5705757f96ea97c7bfb9e1a83cd", "title": "SPEED: Speculative Pipelined Execution for Efficient Decoding"}, {"paperId": "db633c6b1c286c0386f0078d8a2e6224e03a6227", "title": "Mistral 7B"}, {"paperId": "6c323c535365e1c7cbfd9703cbec3b5650a3346b", "title": "Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "8df524e0c50903d0b2c4be338081906d13ea42af", "title": "Draft & Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding"}, {"paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05", "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"}, {"paperId": "819bbdc2dac9e13d9ca3e2508a6e063186ce5e40", "title": "YaRN: Efficient Context Window Extension of Large Language Models"}, {"paperId": "43e624ddeed82df944a6cae0dedec3372438e243", "title": "Accelerating LLM Inference with Staged Speculative Decoding"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "e586a4591ba0303b769f2c07cbddaf1899cb72e4", "title": "H2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models"}, {"paperId": "6bd3ee1ca608bc66a490f63f2fb107d79b44f3e2", "title": "LLM-QAT: Data-Free Quantization Aware Training for Large Language Models"}, {"paperId": "d6eeb2898bd9bd34744194ef543062dda6c4531a", "title": "Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time"}, {"paperId": "3556722b4703a21abafd2f9388743202943f4503", "title": "Accelerating Transformer Inference for Translation via Parallel Decoding"}, {"paperId": "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d", "title": "A Survey of Large Language Models"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "42a14d824caa3348046eb34c37e2ab7985faa7a3", "title": "High-throughput Generative Inference of Large Language Models with a Single GPU"}, {"paperId": "b7d12aec8a0152ec4921dfa43ab525a63b334385", "title": "Speculative Decoding with Big Little Decoder"}, {"paperId": "a1f8082505c7e90b0a033e1b9da0a97d67aad66c", "title": "Accelerating Large Language Model Decoding with Speculative Sampling"}, {"paperId": "d8e9f8c8a37cb4cd26b92ad0d942d641cd512644", "title": "Fast Inference from Transformers via Speculative Decoding"}, {"paperId": "2c994fadbb84fb960d8306ee138dbeef41a5b323", "title": "SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models"}, {"paperId": "379e42895f6d40ab9e9559609f505aba89145a5d", "title": "Efficiently Scaling Transformer Inference"}, {"paperId": "c022f75b00d795c6297d6a9ea948856ea4d365a1", "title": "DeepSpeed- Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "5e04881e91bff952d102d967c4ffb498ec30d4af", "title": "Blockwise Parallel Decoding for Deep Autoregressive Models"}, {"paperId": "d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a", "title": "The NarrativeQA Reading Comprehension Challenge"}, {"paperId": "d1a6b3a5efde3783b53f822dc8dd00aaac934b95", "title": "SpecInfer: Accelerating Generative LLM Serving with Speculative Inference and Token Tree Verification"}, {"paperId": null, "title": "Cuda, release: 10.2. 89"}, {"paperId": "6ff7417332eb1af6d2b3383e1009d37986e32be2", "title": "Modern Information Retrieval : A Brief Overview"}, {"paperId": null, "title": "Gemini: a family of highly capable multimodal models"}, {"paperId": null, "title": "World model on million-length video and language with ringattention"}, {"paperId": null, "title": "Kivi : Plug-and-play 2bit kv cache quantization with streaming asymmetric quantization"}]}