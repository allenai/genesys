{"paperId": "bbd6d6874a8ca1c155bcfb540e8d55199944cdc5", "abstract": "Fine-tuning pre-trained language models (LMs) has become the de facto standard in many NLP tasks. Nevertheless, fine-tuned LMs are still prone to robustness issues, such as adversarial robustness and model calibration. Several perspectives of robustness for LMs have been studied independently, but lacking a unified consideration in multiple perspectives. In this paper, we propose Robustifying LMs via Adversarial perturbation with Selective Training (RoAST), a simple yet effective fine-tuning technique to enhance the multi-perspective robustness of LMs in a unified way. RoAST effectively incorporates two important sources for the model robustness, robustness on the perturbed inputs and generalizable knowledge in pre-trained LMs. To be specific, RoAST introduces adversarial perturbation during fine-tuning while the model parameters are selectively updated upon their relative importance to minimize unnecessary deviation. Under a unified evaluation of fine-tuned LMs by incorporating four representative perspectives of model robustness, we demonstrate the effectiveness of RoAST compared to state-of-the-art fine-tuning methods on six different types of LMs, which indicates its usefulness in practice.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "citationCount": 1, "influentialCitationCount": 1, "openAccessPdf": {"url": "https://aclanthology.org/2023.findings-emnlp.223.pdf", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "Under a unified evaluation of fine-tuned LMs by incorporating four representative perspectives of model robustness, the effectiveness of RoAST is demonstrated compared to state-of-the-art fine- tuning methods on six different types of LMs, which indicates its usefulness in practice."}, "embedding": {"model": "specter_v2", "vector": [0.2254388928413391, 0.7421123385429382, -0.3134731650352478, 0.20803768932819366, -0.4985657334327698, -0.5998149514198303, 0.7170829176902771, -0.3697494864463806, -0.5504999756813049, -0.06754805147647858, 0.4859639108181, 0.14506739377975464, 0.5349502563476562, 0.21972395479679108, -0.6116194128990173, 0.04023690149188042, -0.6179115176200867, 0.28122222423553467, -0.04038199782371521, -0.7428443431854248, -0.6555221676826477, -0.7151474952697754, -0.4877583682537079, 0.24217437207698822, 0.5843119025230408, 0.1836063265800476, 0.014656235463917255, 0.9721240997314453, -0.2566297948360443, 0.02141226828098297, 0.20878538489341736, -0.5334546566009521, 0.5012912154197693, -0.20172682404518127, 0.031437117606401443, -0.04126516729593277, -0.00044525263365358114, -0.3895457088947296, -0.4990387260913849, 1.1514900922775269, 0.1088642105460167, 0.2569176256656647, 0.6785247921943665, -0.33459606766700745, -0.6968364715576172, 1.1884063482284546, 0.6675680875778198, 0.9562079906463623, -0.24690011143684387, -0.5253905653953552, 1.0327982902526855, -1.3555055856704712, 0.1850685179233551, 1.7040369510650635, 0.623760461807251, 0.9265431761741638, -0.15640951693058014, -0.9403667449951172, 0.8153013586997986, -0.23775912821292877, -0.9214669466018677, -0.47444388270378113, 0.0025688991881906986, 0.08704423159360886, 1.5878586769104004, -0.5390452742576599, -0.674331545829773, 0.8583990335464478, 0.05681714415550232, 1.142064094543457, -0.36201876401901245, -0.7923977971076965, -0.626387357711792, 0.39028263092041016, -0.4378832280635834, 0.6093384623527527, -0.7559508085250854, 0.315666526556015, -0.6682334542274475, -0.23935846984386444, -0.01071186363697052, -0.5284491181373596, -0.362175315618515, 0.19139227271080017, -0.16247035562992096, 0.6627957820892334, 0.3442092835903168, 0.9418362379074097, 0.04373776167631149, 0.4312454164028168, 0.5726487040519714, 0.5597729682922363, 0.33343765139579773, 0.6963496208190918, -0.34554168581962585, 0.634270429611206, -0.8882102966308594, 0.3240891695022583, 0.08499021828174591, 0.9686311483383179, -0.3749881088733673, 0.2760910093784332, -1.0341237783432007, 0.5078399777412415, 1.2950282096862793, 0.2692820131778717, 0.7353692650794983, -0.529341459274292, 0.5807221531867981, -0.7598913311958313, 0.30015262961387634, -0.7290167808532715, -0.2894650995731354, -0.22301405668258667, -0.9367278814315796, -1.237635612487793, -0.25363999605178833, -0.12177443504333496, -0.7219913005828857, 1.3545812368392944, -0.0941394492983818, -0.109983429312706, 0.14759555459022522, 0.2579856812953949, 0.6770803332328796, 0.7885285019874573, 0.31278929114341736, -0.29737815260887146, 0.5909362435340881, -0.826911985874176, -0.5814642310142517, -0.9297965168952942, 0.4391050934791565, -0.4587761461734772, 0.5295786261558533, -0.5030919909477234, -1.0247691869735718, -0.7652074694633484, -1.0598217248916626, 0.010482807643711567, -0.3950915038585663, 0.26813995838165283, 0.16881351172924042, 0.23740985989570618, -0.5764811635017395, 0.8839978575706482, 0.07505860924720764, -0.29475340247154236, 0.11535532027482986, 0.18658575415611267, 0.1046857163310051, -0.3671305179595947, -1.774880290031433, 0.38594722747802734, 0.6749582290649414, -0.7234218120574951, -0.3349664509296417, -0.7173106670379639, -0.8958329558372498, -0.14162829518318176, 0.4328456223011017, -0.7250109314918518, 1.405371904373169, -0.4573668837547302, -1.7695499658584595, 0.4779738485813141, -0.24966731667518616, -0.043340545147657394, 0.6683980822563171, 0.013355128467082977, -0.7172212600708008, -0.4115155041217804, -0.25246062874794006, 0.37832337617874146, 0.917717456817627, -0.22221826016902924, 0.13895951211452484, 0.5105469226837158, -0.25124818086624146, -0.1458987593650818, -0.29377517104148865, 0.7618539333343506, -0.7818851470947266, -0.7769713997840881, 0.3508678376674652, 0.6354409456253052, -0.0829816460609436, -0.25531426072120667, -0.5499018430709839, -0.8970392942428589, 0.8429208993911743, -0.2215215116739273, 1.099269986152649, -0.780156135559082, -0.3665255010128021, 0.08353486657142639, -0.42709091305732727, 0.18924356997013092, -0.9707280993461609, 0.8820124864578247, -0.318641722202301, 0.7545077800750732, -0.37861987948417664, -1.4542429447174072, 0.22840334475040436, -0.484453022480011, -0.9273019433021545, -0.17298506200313568, 0.3820543885231018, 1.1664891242980957, -0.9216383099555969, 0.09733603894710541, -0.1861887127161026, 0.32131120562553406, -1.0791515111923218, 0.9668372869491577, -0.7180836200714111, 0.7367519736289978, -0.05486711859703064, -0.082072913646698, -0.0026054184418171644, -0.06743824481964111, 0.08399815857410431, -0.37918514013290405, 0.28623253107070923, 0.19976691901683807, -0.48902761936187744, 1.1482603549957275, -0.3808406889438629, 0.2653873562812805, -0.017246467992663383, -0.49815839529037476, -0.3229368031024933, 0.6097860932350159, -0.29633083939552307, -0.2906606197357178, 0.45933768153190613, 0.3443142771720886, -0.7830649018287659, 0.2488371729850769, 0.567330539226532, 0.4679902195930481, -0.32441917061805725, 0.2731417417526245, 0.5890083312988281, -0.4475017488002777, 0.7011044025421143, 0.47488367557525635, 0.6699361205101013, 0.27799925208091736, 0.7636958956718445, 0.0579439140856266, 0.7810735106468201, -0.9592233896255493, -0.032367266714572906, 0.4994320273399353, 0.577664852142334, 0.8546032905578613, 0.14622153341770172, -0.4040110409259796, -0.3432096838951111, -0.08079396188259125, 0.7564531564712524, 1.8422454595565796, -0.5268869400024414, -0.23701836168766022, -0.8226288557052612, -0.5405645966529846, -0.19579780101776123, 0.3447810411453247, -0.5449386239051819, -0.20996232330799103, -0.4075194299221039, -1.299587368965149, 0.8863286972045898, -0.19439907371997833, 0.8424158692359924, -0.501143753528595, 0.5438736081123352, -0.10791493207216263, 0.08374025672674179, -0.6963090300559998, -1.0413858890533447, 0.04640938341617584, -0.3419550955295563, -0.21728786826133728, 0.025753533467650414, 0.10514869540929794, 0.35779717564582825, -0.8579128980636597, 0.8449676036834717, -0.6138200759887695, 0.33996129035949707, 0.15254627168178558, 0.2449692338705063, -0.8878734111785889, -1.551619529724121, 0.2572764754295349, 0.5964212417602539, -0.1113373339176178, -0.17185360193252563, 0.28374725580215454, 0.4959782063961029, 0.21324755251407623, -0.8988511562347412, -0.5328585505485535, -0.0716003030538559, 0.11941811442375183, 0.9626292586326599, -0.030958615243434906, 0.27924802899360657, -1.7144256830215454, 1.0928642749786377, -0.22179757058620453, -0.5991107225418091, 0.40073856711387634, -0.48241934180259705, -0.2310355007648468, 1.0748027563095093, -0.9549704790115356, -0.6708636283874512, -1.0903221368789673, 0.03383709490299225, -0.11430138349533081, 0.22400444746017456, 0.35287293791770935, 0.023233290761709213, 0.17560169100761414, 0.9474741220474243, 0.3767661154270172, 0.154766246676445, -0.18405988812446594, 0.8411540389060974, -0.8941437602043152, 0.5603428483009338, 0.2397172451019287, 0.766890287399292, -0.19066405296325684, -0.6263924837112427, -0.5896265506744385, -0.41744858026504517, -0.1828003078699112, -0.2041061967611313, -0.029702967032790184, -0.5193929672241211, -0.669890820980072, -0.3863111436367035, -0.042409494519233704, -0.6976975798606873, -0.20094013214111328, 0.0820230022072792, -0.4885534346103668, -0.16007958352565765, -0.8111829161643982, -1.0698487758636475, -0.18492740392684937, -0.8391256332397461, -0.7893158197402954, 0.49580398201942444, -0.02964051626622677, -0.532763659954071, -0.6797346472740173, 0.25508221983909607, -0.42202165722846985, 0.9445573091506958, -0.6474108099937439, 1.0584982633590698, -0.06991887092590332, 0.1532919853925705, -0.5371559858322144, 0.49467700719833374, 0.8520632982254028, -0.04449663311243057, 0.591793954372406, -1.0929112434387207, -0.2385571300983429, -0.11014950275421143, -0.15180158615112305, 0.24379560351371765, 0.19555260241031647, 0.4758872389793396, -0.4010542333126068, -0.5734091997146606, 0.8312386870384216, 1.1523243188858032, -0.8260865211486816, -0.3142133057117462, 0.3279394209384918, 0.5651541948318481, 0.21660639345645905, -0.29678529500961304, 0.5013279914855957, 0.14648646116256714, 0.17590977251529694, 0.08685104548931122, 0.1672203093767166, 0.13538603484630585, -0.8813663721084595, 0.8683716654777527, 1.6558877229690552, 0.6057817339897156, -0.5157420635223389, -0.8974997401237488, 0.42424869537353516, -1.0901813507080078, -0.7869888544082642, 1.1668987274169922, 0.7237016558647156, 0.4962327182292938, -0.4423428773880005, -0.530389130115509, -0.20043359696865082, 0.4219909608364105, 0.44316673278808594, -0.7200887799263, -0.43179571628570557, -0.15245307981967926, -0.08435367047786713, 0.09561339765787125, 0.7021903395652771, -0.7435799837112427, 0.8908499479293823, 14.436562538146973, 0.8696889281272888, -0.001421336317434907, 0.8061988949775696, 0.41051915287971497, -0.06681080907583237, -0.6130257248878479, -0.6298025846481323, -1.1759872436523438, -0.16544832289218903, 0.6749991178512573, 0.09883835911750793, 0.931710422039032, 0.06808769702911377, 0.21654801070690155, 0.40797075629234314, -0.35652288794517517, 0.4348583519458771, 0.7124291062355042, -1.1269862651824951, 0.6952061057090759, -0.32621318101882935, 1.0275336503982544, 0.9402660131454468, 0.8684310913085938, 1.0368787050247192, 0.3973909616470337, -0.32109951972961426, 0.38570815324783325, 0.2952260375022888, 0.5635223984718323, -0.08221396803855896, 0.4369587302207947, 0.8610988855361938, -0.6138219237327576, -0.40297359228134155, -0.664340615272522, -0.7284013628959656, 0.1114211454987526, 0.21129892766475677, -0.6951770782470703, -0.6188766360282898, 0.12334282696247101, 0.7119688987731934, -0.10823669284582138, -0.07236234098672867, -0.32445406913757324, 0.8116695284843445, -0.38932669162750244, 0.3713112473487854, -0.016683293506503105, 0.5152905583381653, 0.8202619552612305, -0.00345475017093122, 0.08519002795219421, 0.04638075456023216, -0.3133608400821686, 0.6008724570274353, -0.875242292881012, 0.1067441999912262, -0.34721264243125916, -0.30864980816841125, 0.14863234758377075, 0.5138761401176453, 0.7989242672920227, 0.45040416717529297, -0.11812889575958252, 0.33719968795776367, 0.6243807077407837, 0.5442756414413452, -0.06724555790424347, 0.18946784734725952, 0.1739194095134735, -0.3710970878601074, -0.20521563291549683, 0.8323579430580139, 0.21536579728126526, -0.5453071594238281, -0.45619457960128784, -0.8208701014518738, 0.11204605549573898, -0.6024961471557617, -1.1418328285217285, 0.8065099716186523, -0.37179726362228394, -0.4470732510089874, 0.06305646896362305, -0.32490864396095276, -0.37349075078964233, 0.57662034034729, -1.3552411794662476, -0.8458199501037598, 1.0109223127365112, -0.22971700131893158, -0.6100108027458191, -0.5478397011756897, 1.2925196886062622, -0.06739426404237747, -0.6580662727355957, 0.6742470860481262, 0.8763284087181091, 0.0001874029403552413, 0.4634014070034027, -0.5699000358581543, 1.131738543510437, 0.652199923992157, -0.3528424799442291, 0.5802016854286194, 0.3452807366847992, 0.03610292822122574, -0.5376707315444946, -0.43533146381378174, 0.6134509444236755, -0.9526392817497253, -0.3391577899456024, -0.385958194732666, -0.9091606140136719, 0.34894177317619324, 0.33984270691871643, -0.42678704857826233, 0.3792884051799774, 0.05491199716925621, -0.6672550439834595, -0.16734591126441956, -1.1592332124710083, 0.0702139362692833, 0.16997531056404114, -0.6660283803939819, -0.28255343437194824, 0.31910473108291626, 0.4584377408027649, -1.3374882936477661, -0.46774229407310486, -0.052580974996089935, -0.1394856572151184, 0.2669745087623596, 0.9711772799491882, -0.5402234196662903, 0.2622772753238678, 0.42063406109809875, -0.2653888761997223, -1.1829726696014404, 0.013008436188101768, -1.101921558380127, 0.12023728340864182, 0.5126020312309265, 0.9315639734268188, -0.44661423563957214, -0.16320838034152985, 0.7644436955451965, 0.4107207953929901, -0.13213318586349487, -0.5334198474884033, -0.07178246229887009, 0.45024964213371277, -0.6284119486808777, 0.42647042870521545, -0.16636209189891815, -0.11562351882457733, -0.15778154134750366, 0.2958086431026459, 1.2681792974472046, -0.449991911649704, -1.042948842048645, 0.6237740516662598, 0.2673373222351074, -0.2956008017063141, -0.5160542726516724, 0.12300900369882584, -1.0318598747253418, 0.22946730256080627, -1.1764756441116333, -0.021743979305028915, -0.793084442615509, -0.7769917249679565, 0.42818742990493774, -0.11335143446922302, -0.13847219944000244, 0.09343946725130081, -0.21259240806102753, -0.04279255494475365, -0.19004856050014496, -0.2337387502193451, 0.8750008344650269, 1.0012173652648926, -1.2303555011749268, -0.22583070397377014, 0.6473119854927063, -0.14067240059375763, 0.5254034996032715, 0.7024984955787659, -0.5049052238464355, -0.6734187602996826, -1.3641647100448608, 0.4159753620624542, -0.5770748853683472, -0.343727171421051, -0.50102299451828, 0.699549674987793, 0.630206823348999, -0.038249846547842026, 0.38005369901657104, 0.2128600925207138, -0.9720649123191833, -0.4964968264102936, 0.13513056933879852, -0.5930464267730713, 0.20096850395202637, 0.36621740460395813, -0.1580340713262558, -0.5496150255203247, 0.5557757019996643, 0.27949783205986023, -1.0833992958068848, -0.49124786257743835, 0.7675579190254211, -0.6153714656829834, 0.5110471844673157, -0.29796701669692993, 0.27439817786216736, -1.0450469255447388, -0.6971482634544373, -0.029920902103185654, 0.5270935893058777, -0.3111127018928528, 0.7836377620697021, 0.13652466237545013, -1.153504729270935, -0.13212718069553375, 0.5388391613960266, 0.13854770362377167, 0.030066760256886482, 0.5325348377227783, 0.10543011873960495, -0.311851441860199, 0.661112368106842, 0.7729417085647583, 0.4486861824989319, -0.853014349937439, 0.017370684072375298, 1.1064761877059937, -0.603459358215332, 0.14394843578338623, 1.5943940877914429, -0.29541513323783875, -1.7195767164230347, 0.22001738846302032, -1.0486819744110107, -0.45247015357017517, -0.12408147752285004, 0.7106382250785828, 0.22600722312927246, -0.1875031441450119, -0.4261305630207062, -0.4055950343608856, 0.4692755937576294, 0.07735182344913483, -0.45678144693374634, 0.32844364643096924, -0.6780791282653809, -0.5807990431785583, 0.4895080626010895, 0.6795307397842407, -0.17885373532772064, -0.7792408466339111, -1.1571953296661377, -0.43986815214157104, 0.30714723467826843, -0.005840201396495104, -0.5448876023292542, -0.3922140598297119, 0.3703850209712982, 0.27721107006073, -0.034601207822561264, 0.4054201543331146, -0.33565038442611694, 0.03754036873579025, 0.967056393623352, -0.16819870471954346, -0.792738139629364, -0.699528157711029, 1.3948842287063599, 1.5054810047149658, -1.4708828926086426, 0.3582141101360321, 0.06206206977367401, -0.8330554366111755, 0.8004155158996582, 0.023695645853877068, 0.1240287572145462, 1.2447983026504517, -0.6650121808052063, 0.48841148614883423, 0.7337682247161865, -0.6957783699035645, 0.0044591608457267284, 1.2337044477462769, 0.8931223750114441, 0.4175036549568176, 0.08615071326494217, 0.271555632352829, 0.7371807098388672, -0.0794738382101059, -0.18636585772037506, 0.3876250386238098, -0.032759033143520355, -0.1498447209596634, -0.3433001935482025, -0.27084288001060486, 0.5008535385131836, -0.9135901927947998, -0.5717719793319702, -0.24957403540611267, 0.6458213329315186, 0.47859230637550354, 0.8187156319618225, 0.024119434878230095, -0.033757954835891724, 0.6235299706459045, 0.3398132622241974, 0.15968608856201172, -0.7952659130096436, -0.19178658723831177, -0.27259767055511475, -0.8942848443984985, -0.07722709327936172, -0.3220882713794708, -0.36926206946372986, -0.15927480161190033, -0.2879646420478821, 0.33473652601242065, -0.09155253320932388, 0.34692198038101196, 1.460818886756897, 0.35026440024375916, 0.25577375292778015, -0.13867469131946564, -0.6125645637512207, -0.6000997424125671, -1.4009974002838135, 0.10801438242197037, -0.4644502103328705, -0.04218941554427147, 0.10642098635435104, -0.3547278642654419, -0.5139109492301941]}, "authors": [{"authorId": "2271337868", "name": "Jaehyung Kim"}, {"authorId": "2272672481", "name": "Yuning Mao"}, {"authorId": "2266467782", "name": "Rui Hou"}, {"authorId": "2273361006", "name": "Hanchao Yu"}, {"authorId": "2257201527", "name": "Davis Liang"}, {"authorId": "2271827637", "name": "Pascale Fung"}, {"authorId": "2266712798", "name": "Qifan Wang"}, {"authorId": "2271382818", "name": "Fuli Feng"}, {"authorId": "2273197501", "name": "Lifu Huang"}, {"authorId": "2072010", "name": "Madian Khabsa"}], "references": [{"paperId": "7d5dfe1a97d7c3b071518d518dd73a8168a4556f", "title": "Is Fine-tuning Needed? Pre-trained Language Models Are Near Perfect for Out-of-Domain Detection"}, {"paperId": "8f944ef5a87276f11b0c8f0e4445698204dc6583", "title": "Spread Spurious Attribute: Improving Worst-group Accuracy with Spurious Attribute Estimation"}, {"paperId": "29b77089a0a40f46372ce2dca9c3bb2dd5d46b1d", "title": "Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution"}, {"paperId": "5e8d3c2dc0fc53949794fc00600e25558c4a2441", "title": "WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation"}, {"paperId": "a4f533f2b7d77b667e1f05b210924ec7c90cc5d1", "title": "How Should Pre-Trained Language Models Be Fine-Tuned Towards Adversarial Robustness?"}, {"paperId": "fe34bca61e451a532f45c680c232cb78bdc558cf", "title": "PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures"}, {"paperId": "8436897e713c2242d6291df9a6a33c1544d4dd39", "title": "Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models"}, {"paperId": "7f2dd0a66a9e6570fc6123f0aab193084c1268fc", "title": "Sharpness-Aware Minimization Improves Language Model Generalization"}, {"paperId": "f45261b7b53043c316f45f613cb735907b93fb5a", "title": "Raise a Child in Large Language Model: Towards Effective and Generalizable Fine-tuning"}, {"paperId": "31e46ed4722a4895a19eda37dbc02da55572783a", "title": "Searching for an Effective Defender: Benchmarking Defense against Adversarial Word Substitution"}, {"paperId": "9cce4c9e69318aef56a274612f8df62ade63622f", "title": "Deep learning for object detection and scene perception in self-driving cars: Survey, challenges, and open issues"}, {"paperId": "520bd2331cca8d5a9c032c186a2a0f7704ead6ff", "title": "R-Drop: Regularized Dropout for Neural Networks"}, {"paperId": "4a9244d0fc9b2b87eca5fa7579835f4a05eb8866", "title": "Can Subnetwork Structure be the Key to Out-of-Distribution Generalization?"}, {"paperId": "291016368158f28829c06c0a037e0ca1a6548cca", "title": "HiddenCut: Simple Data Augmentation for Natural Language Understanding with Better Generalizability"}, {"paperId": "a9b04a3e0cf5766df9b3af8c442f2d85ac5e2c7e", "title": "Contrastive Out-of-Distribution Detection for Pretrained Transformers"}, {"paperId": "e3bba08dc07c5f1372b78450990ba0ef305a834c", "title": "Can NLI Models Verify QA Systems' Predictions?"}, {"paperId": "457e73be2f876e0b838f0f8d7aa921993b7f607d", "title": "Consistency Training with Virtual Adversarial Discrete Perturbation"}, {"paperId": "aac329026fb5f08f54b9f06f35ea2e0c3b664a76", "title": "On the effectiveness of adversarial training against common corruptions"}, {"paperId": "284dfcf7f25ca87b2db235c6cdc848b4143d3923", "title": "DynaSent: A Dynamic Benchmark for Sentiment Analysis"}, {"paperId": "bdfe6051558414589f8b8b2e0fea596833e845bb", "title": "MASKER: Masked Keyword Regularization for Reliable Text Classification"}, {"paperId": "f75a388bd731409b61129ede2a7efc7221e4ff91", "title": "Investigating Societal Biases in a Poetry Composition System"}, {"paperId": "106fb432d2b62f3824a9d6f4a1b30e1f8b6ea9d7", "title": "Sequence-level Mixed Sample Data Augmentation"}, {"paperId": "a79c6fd3da1c3eafc228a0e429846ff048027689", "title": "InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective"}, {"paperId": "a2cd073b57be744533152202989228cb4122270a", "title": "Sharpness-Aware Minimization for Efficiently Improving Generalization"}, {"paperId": "67f343b5212d3a71965d2c217bb567f8af0bbcdb", "title": "SSMBA: Self-Supervised Manifold Based Data Augmentation for Improving Out-of-Domain Robustness"}, {"paperId": "b88c11922cac84e5ea902f82d27ae21c3dda2e04", "title": "Better Fine-Tuning by Reducing Representational Collapse"}, {"paperId": "e1bb329621de73d08c47beae9b5439a1c244eb1a", "title": "CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "f2f3c83db919a2429c4fcad2d0a0ed4e5294354a", "title": "Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting"}, {"paperId": "97f08c1ae8ca5ddf5948c66bfbbc0546ac154807", "title": "Pretrained Transformers Improve Out-of-Distribution Robustness"}, {"paperId": "9739f7030feb8cdc9ab479ffcf742ab1dd24eaa5", "title": "Adversarial Weight Perturbation Helps Robust Generalization"}, {"paperId": "dc0ce66f5ab4c5173cdef951649044e4c4c05076", "title": "BERT-ATTACK: Adversarial Attack against BERT Using BERT"}, {"paperId": "52f47e781852a77abedada48cfa971b24c919dde", "title": "Calibration of Pre-trained Transformers"}, {"paperId": "193092aef465bec868d1089ccfcac0279b914bda", "title": "Distributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-Case Generalization"}, {"paperId": "ab70853cd5912c470f6ff95e95481980f0a2a41b", "title": "SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization"}, {"paperId": "207da6d2c07289bf72a2b5974bb3f011ebb5dd0d", "title": "Adversarial NLI: A New Benchmark for Natural Language Understanding"}, {"paperId": "47f1eb0dc42189ba7cf21b76598c8217eb1b6e05", "title": "Learning the Difference that Makes a Difference with Counterfactually-Augmented Data"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "d01fa0311e8e15b8b874b376123530c815f52852", "title": "FreeLB: Enhanced Adversarial Training for Natural Language Understanding"}, {"paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0", "title": "Natural Questions: A Benchmark for Question Answering Research"}, {"paperId": "ae04f3d011511ad8ed7ffdf9fcfb7f11e6899ca2", "title": "Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "f3b89e9a2b8ce1b6058e6984c3556bc2dded0938", "title": "Probing Neural Network Comprehension of Natural Language Arguments"}, {"paperId": "e26e0e5dc6fe766c4ba1c3c14fc9c971f96d405a", "title": "Natural Language Understanding with the Quora Question Pairs Dataset"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "c42816f497d663c681df20d48a6e66a5632600d8", "title": "MixMatch: A Holistic Approach to Semi-Supervised Learning"}, {"paperId": "726320cdbd04804ffa8f3a78c095bd1b55a2a695", "title": "Similarity of Neural Network Representations Revisited"}, {"paperId": "a4e67bcbf912e13cebbb1241d05d1ca0a1df9df8", "title": "Identifying and Reducing Gender Bias in Word-Level Language Models"}, {"paperId": "4c94ee7df6bc2bfcac76703be4f059a79010f7e5", "title": "Self-Supervised Visual Feature Learning With Deep Neural Networks: A Survey"}, {"paperId": "42ed4a9994e6121a9f325f5b901c5b3d7ce104f5", "title": "Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference"}, {"paperId": "6c405d4b5dc41a86be05acd59c06ed19daf01d14", "title": "Theoretically Principled Trade-off between Robustness and Accuracy"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "b1d24e8e08435b7c52335485a0d635abf9bc604c", "title": "FEVER: a Large-scale Dataset for Fact Extraction and VERification"}, {"paperId": "2997b26ffb8c291ce478bd8a6e47979d5a55c466", "title": "Annotation Artifacts in Natural Language Inference Data"}, {"paperId": "5f1141287c577f2e45f8c35a5fd30cfb91311257", "title": "Explicit Inductive Bias for Transfer Learning with Convolutional Networks"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "0ae5b99f09b7ebacc4aeaed7644aff90534a3aaa", "title": "Deep Learning for Medical Image Analysis"}, {"paperId": "7aa38b85fa8cba64d6a4010543f6695dbf5f1386", "title": "Towards Deep Learning Models Resistant to Adversarial Attacks"}, {"paperId": "d65ce2b8300541414bfe51d03906fca72e93523c", "title": "On Calibration of Modern Neural Networks"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "7493389667058116dbc7e808987f129325ee60d7", "title": "Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results"}, {"paperId": "2e55ba6c97ce5eb55abd959909403fe8da7e9fe9", "title": "Overcoming catastrophic forgetting in neural networks"}, {"paperId": "bc9db6117d0026bc5b11eeba2303d2bddc96c306", "title": "Multi30K: Multilingual English-German Image Descriptions"}, {"paperId": "51a55df1f023571a7e07e338ee45a3e3d66ef73e", "title": "Character-level Convolutional Networks for Text Classification"}, {"paperId": "bee044c8e8903fb67523c1f8c105ab4718600cdb", "title": "Explaining and Harnessing Adversarial Examples"}, {"paperId": "665f89a20b05472d82df0a12f2dd63e8fcc4f3ea", "title": "Hidden factors and hidden topics: understanding rating dimensions with review text"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "128cb6b891aee1b5df099acb48e2efecfcff689f", "title": "The Winograd Schema Challenge"}, {"paperId": "38b3a4447a47a6a6ed1869f3da03352c487f8fe3", "title": "NewsWeeder: Learning to Filter Netnews"}, {"paperId": "e8b90fd68d8ebb398fd8527170724554ae00fe4b", "title": "What Makes Better Augmentation Strategies? Augment Difficult but Not too Different"}, {"paperId": null, "title": "Electra: Pre-training text encoders as discriminators rather than generators"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "conference on machine translation"}, {"paperId": null, "title": "Integral transforms and their applications , volume 41"}, {"paperId": "e101f9cc8ded28cfb85029b0486fa5a1b1336b35", "title": "Findings from the"}]}