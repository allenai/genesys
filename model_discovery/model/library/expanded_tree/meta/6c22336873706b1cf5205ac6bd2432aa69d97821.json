{"paperId": "6c22336873706b1cf5205ac6bd2432aa69d97821", "abstract": null, "venue": "International Journal of Computer Vision", "year": 2022, "citationCount": 166, "influentialCitationCount": 7, "openAccessPdf": {"url": "https://arxiv.org/pdf/2202.10108", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "The ViTAE transformer is proposed, which utilizes a reduction cell for multi-scale feature and a normal cell for locality and demonstrates that the introduced inductive bias still helps when the model size becomes large."}, "embedding": {"model": "specter_v2", "vector": [0.4928443729877472, 0.5232807397842407, -0.2352362871170044, 0.2062084972858429, 0.049902938306331635, -0.026096729561686516, 0.9631478786468506, -0.18787315487861633, -0.4632464051246643, -0.7090473771095276, 0.32853588461875916, 0.40764784812927246, 0.5226094722747803, -0.05223323404788971, -0.37634581327438354, -0.3111620545387268, -0.8028599619865417, 0.07421707361936569, 0.09455431997776031, -0.7108826041221619, 0.20348186790943146, -0.6069301962852478, -1.1275373697280884, 0.09185770153999329, 0.16379517316818237, 1.384102463722229, 0.5705468654632568, 1.1116234064102173, -0.3965173363685608, 0.5288923978805542, 0.4020177721977234, -0.177937850356102, 0.27181023359298706, 0.05386229604482651, -0.5546185374259949, 0.07322626560926437, 0.7741184234619141, -0.3084641695022583, -0.773341715335846, 0.62628573179245, -0.0016299833077937365, 0.15447446703910828, 0.9483402967453003, -0.7923473715782166, -0.5549184679985046, -0.022360514849424362, 0.44548994302749634, 0.8398171067237854, -0.710270345211029, -0.8058283925056458, 1.2451505661010742, -1.1271036863327026, 0.40257567167282104, 1.1672149896621704, 0.3146132230758667, 0.7401149272918701, -0.20745275914669037, -0.28713271021842957, 0.734589159488678, 0.47610047459602356, -0.5826692581176758, -0.22730760276317596, 0.3503503203392029, -0.28480446338653564, 1.6349719762802124, -0.9351992607116699, -0.0345635823905468, 1.0731420516967773, 0.40871742367744446, 1.3797831535339355, 0.24063879251480103, -0.8881498575210571, -0.17762939631938934, -0.19239021837711334, -0.028896398842334747, 0.5848023295402527, -0.46710097789764404, 0.36533674597740173, -0.7246968150138855, 0.5161434412002563, 0.5126787424087524, -0.05782095342874527, 0.37165096402168274, -0.4410722255706787, -0.1841297298669815, 1.0012288093566895, 1.1542433500289917, 0.6331245303153992, -0.14124126732349396, 1.030410647392273, 0.4218101501464844, -0.01163963507860899, -0.3849065899848938, 0.13584327697753906, 0.24088968336582184, 0.9584513306617737, -0.7550022006034851, -0.020998960360884666, -0.5486030578613281, 0.9594497680664062, -0.00582517683506012, 0.3729386627674103, -0.7450976371765137, 0.18824943900108337, 1.2403655052185059, 0.15866586565971375, 0.4151286780834198, -0.3738698959350586, -0.2364680916070938, -0.8902568817138672, -0.18176060914993286, -1.067930817604065, 0.06863414496183395, -0.3524002730846405, -1.1098562479019165, -0.7882020473480225, -0.5576432347297668, 0.7422641515731812, -1.5263268947601318, 0.7349047660827637, -0.20244668424129486, 0.1898084580898285, 0.12942442297935486, 0.42600110173225403, 0.6457557678222656, 0.5823668837547302, 0.3313959836959839, 0.5529959797859192, 1.1171386241912842, -0.9774965643882751, -0.35537847876548767, -1.1433343887329102, -0.09829492121934891, -0.08583574742078781, 0.010032545775175095, -0.185775026679039, -0.8380189538002014, -1.523134708404541, -0.9819983243942261, -0.354440301656723, -0.6809839606285095, 0.14193594455718994, 0.8787847757339478, 0.0017446681158617139, -0.9593251347541809, 0.5025020241737366, 0.04891984164714813, -0.18733415007591248, 0.6523744463920593, 0.03923431411385536, 0.628411591053009, -0.38485652208328247, -1.2838084697723389, 0.21973398327827454, -0.10019560158252716, -0.36013466119766235, -0.740953803062439, -0.4107230305671692, -1.2934092283248901, -0.027494490146636963, 0.16107238829135895, -0.5142183303833008, 0.968389630317688, -0.5949006676673889, -0.5902319550514221, 0.8582314848899841, -0.5033400058746338, 0.041860777884721756, -0.13999168574810028, 0.1426837146282196, -0.11142624914646149, -0.33866533637046814, -0.1255303919315338, 0.9537673592567444, 1.0879921913146973, -0.5056235790252686, -0.06406939774751663, -0.01618877425789833, -0.39777636528015137, -0.10692399740219116, -0.3502644896507263, 0.4237241744995117, -0.7068637609481812, -0.5280059576034546, 0.3391658067703247, 0.3984162509441376, 0.11952020227909088, -0.1775781512260437, 0.21124307811260223, -1.0922787189483643, 0.596906304359436, 0.39039644598960876, 0.23015210032463074, -0.947572648525238, -0.5733309388160706, -0.0610303059220314, 0.08416170626878738, -0.406492680311203, -1.0176734924316406, 0.21320107579231262, -0.28263479471206665, 0.040252506732940674, 0.16754694283008575, -0.8250458836555481, -0.059896424412727356, 0.025062840431928635, -0.8191242814064026, -0.05948525294661522, 0.400010883808136, 1.3695133924484253, -0.9105744957923889, -0.2581488788127899, -0.08886637538671494, 0.398009330034256, -0.7637386918067932, 1.0176565647125244, -0.5197762250900269, -0.16046597063541412, -0.05018874257802963, 0.1999877393245697, -0.01590566895902157, -0.530225396156311, 0.38926270604133606, -0.6049190759658813, 0.2850179970264435, 0.3483017683029175, -0.2847732901573181, 1.434860348701477, -0.30605146288871765, 1.0215513706207275, -0.34297415614128113, -0.9680118560791016, 0.406036913394928, 0.09668392688035965, 0.005399493500590324, -0.8802809715270996, 0.6333413124084473, -0.25584450364112854, -1.0062075853347778, 0.3456314206123352, 0.5279168486595154, 1.0786280632019043, -0.27894431352615356, -0.2778610289096832, 0.7719959616661072, -0.29454973340034485, 0.07467062771320343, 0.6804447770118713, 0.34098944067955017, 0.5050170421600342, 0.1746627241373062, -0.12297748029232025, 0.05226784572005272, -0.6867148280143738, 0.08780694007873535, 0.752824604511261, 0.33113372325897217, 0.9947792887687683, 0.23162071406841278, -0.7826087474822998, -0.7460233569145203, -0.234593003988266, 0.37613144516944885, 1.3713353872299194, 0.2692659795284271, -0.22070184350013733, -0.668704092502594, -0.03534449636936188, -0.5774670243263245, -0.7414699792861938, -0.9438866376876831, -0.16479253768920898, 0.01908775046467781, -0.8121039867401123, 0.6047090888023376, 0.48377829790115356, 1.4425971508026123, -0.709977924823761, -0.18212343752384186, -0.332840234041214, -0.04631272703409195, -0.8027579188346863, -0.8093026876449585, 0.36248743534088135, 0.00019537050684448332, 0.06609585881233215, -0.1322990357875824, -0.4959300756454468, 0.23835884034633636, -0.3804098963737488, 1.0202666521072388, -0.453154981136322, -0.8871663212776184, 0.5880280137062073, 0.35986384749412537, -1.0348402261734009, -0.5288803577423096, 0.005230787675827742, 0.15521906316280365, 0.08124060928821564, 0.4699588418006897, 0.4400275945663452, -0.4765142500400543, 0.19146127998828888, -0.42599427700042725, -0.15026140213012695, 0.2633915841579437, 0.3099808692932129, 1.2019098997116089, -0.5012752413749695, 0.03979041054844856, -0.5018967390060425, 0.3769020438194275, 0.28263232111930847, -0.558928906917572, 0.1379743367433548, -0.914129912853241, -0.24581851065158844, 0.17004695534706116, -0.7999662756919861, -0.032350990921258926, -0.6283355355262756, 0.5789228677749634, -0.6937005519866943, -0.3429197072982788, -0.4206543266773224, 0.5022866725921631, -0.14766746759414673, 0.6730886697769165, 0.3753202557563782, 0.08884105831384659, 0.5525673031806946, 0.42368656396865845, -0.9320248365402222, 0.8854604959487915, 0.22267425060272217, 0.08629646897315979, 0.062319315969944, 0.2042797952890396, -0.7526992559432983, -0.5885629057884216, -0.7529441714286804, -0.37788382172584534, -0.5977979302406311, 0.903649628162384, -0.6859846115112305, -0.9080706834793091, 0.3317415118217468, -0.7332517504692078, -0.18978306651115417, 0.07766140252351761, -0.38427624106407166, -0.542209804058075, -0.9854149222373962, -0.7430100440979004, -0.2061762660741806, -0.5823465585708618, -0.8827393651008606, 0.17273017764091492, 0.6549043655395508, 0.05923478677868843, -0.46492770314216614, -0.04429767280817032, -0.30255889892578125, 1.1315627098083496, -0.23327888548374176, 0.5190379023551941, 0.3131679594516754, -0.448045939207077, 0.07970494031906128, -0.10339433699846268, 0.6378730535507202, -0.2992350161075592, 0.12857447564601898, -1.242760181427002, 0.1682768166065216, -0.40543633699417114, -0.6501979231834412, 0.6356081962585449, 0.5465689301490784, 0.5592151284217834, 0.47344323992729187, -0.350475937128067, 0.7087772488594055, 1.8476285934448242, -0.6386813521385193, 0.4269162118434906, 0.3556337356567383, 0.9803205728530884, 0.07083252817392349, -0.2617049217224121, 0.19433364272117615, 0.5265212059020996, -0.002328332746401429, 0.7534324526786804, -0.5412487983703613, -0.5955410599708557, -0.6306939125061035, 0.052548423409461975, 0.9941216111183167, 0.017907368019223213, -0.04705869406461716, -1.0694278478622437, 1.3701103925704956, -0.7009260654449463, -0.9159685969352722, 0.8135120868682861, 0.570447564125061, 0.11047346889972687, -0.508540689945221, -0.5939300656318665, -0.3462008535861969, 0.45028963685035706, 0.5650164484977722, -0.47342756390571594, -0.6359965801239014, -0.43431800603866577, 0.560416579246521, 0.5017966628074646, 0.36364996433258057, -0.44575074315071106, 0.6873964071273804, 14.676087379455566, 0.6055924892425537, -0.3160567283630371, 0.3234211504459381, 0.7573784589767456, 0.4669974446296692, -0.4268777668476105, -0.02332705818116665, -1.0880392789840698, -0.5461694598197937, 0.6073392033576965, 0.8682286143302917, 0.7198472619056702, 0.42780202627182007, -0.5676423907279968, 0.2798726260662079, -0.3623550832271576, 0.936328113079071, 0.9479702711105347, -1.4743601083755493, 0.337726354598999, 0.29464808106422424, 0.7081648111343384, 0.913594126701355, 1.0832465887069702, 0.6441649198532104, 0.17535048723220825, -0.4355567991733551, 0.3708646893501282, 0.25578343868255615, 0.9572129249572754, 0.09819424897432327, 0.007664191070944071, -0.20782139897346497, -1.150079369544983, -0.2880536615848541, -1.0786993503570557, -0.5192604064941406, -0.3289949595928192, -0.3554994761943817, -0.23938699066638947, -0.3470328450202942, 0.42408517003059387, 0.7155567407608032, -0.040145691484212875, 0.032304540276527405, -0.006482399068772793, 0.34656593203544617, 0.21715402603149414, -0.15966752171516418, 0.6655150651931763, 0.4344303011894226, 0.1143408939242363, -0.24200467765331268, -0.02895883284509182, 0.188411682844162, -0.1989254355430603, 0.5185564160346985, -0.5510420799255371, -0.19131357967853546, -0.38974055647850037, -0.12418024241924286, -0.40591007471084595, 1.0273330211639404, 0.13408470153808594, 0.4202973544597626, -0.0963960513472557, 0.48227232694625854, 0.2633515000343323, 0.26847782731056213, -0.47608107328414917, -0.36413058638572693, 0.34297212958335876, -0.5543847680091858, 0.6769722104072571, 0.5004464983940125, -0.1383005976676941, -0.5199993252754211, -0.821333646774292, -0.15808619558811188, 0.30165520310401917, -1.21343195438385, -0.5440327525138855, 1.1189218759536743, -0.4760006070137024, -0.05990239977836609, 0.2831629514694214, -1.054707407951355, -0.3518999218940735, 0.42253273725509644, -1.7233768701553345, -0.745936393737793, -0.43851250410079956, 0.17914767563343048, -0.2301432341337204, -0.19573667645454407, 0.9519556760787964, -0.08396688103675842, 0.24808409810066223, 0.15112274885177612, 0.004985444247722626, 0.17920628190040588, 0.18170535564422607, -0.923409640789032, 0.798741340637207, 0.20972338318824768, 0.273433655500412, -0.18264324963092804, 0.06839001178741455, 0.5615814328193665, -0.642322838306427, -0.017124099656939507, 0.47017738223075867, -0.9661969542503357, -0.6175484657287598, -0.8995679020881653, -0.7729378938674927, 0.1653958261013031, 0.777414083480835, -0.0366705060005188, -0.03480459377169609, 0.029192999005317688, -0.7846364378929138, -0.5320675373077393, -0.6082321405410767, -0.04293396323919296, 0.297418475151062, -0.7706702351570129, -0.4223979115486145, -0.3431727886199951, -0.027356907725334167, -0.7077600359916687, -0.49297234416007996, -0.20150579512119293, 0.20844990015029907, -0.06756486743688583, 1.3582121133804321, -0.3251550495624542, 0.7121515870094299, 0.7739136219024658, -0.4509386718273163, -0.6706934571266174, -0.49437040090560913, -0.6313633918762207, 0.2962520122528076, 0.33428749442100525, 0.2384118139743805, -0.2916882336139679, 0.042794257402420044, 0.31136277318000793, 0.5687745809555054, -0.5177224278450012, -0.377961128950119, 0.02025081031024456, 0.09387973695993423, -0.4522972106933594, 0.12428335100412369, -0.12761510908603668, -0.5625891089439392, 0.30995893478393555, 0.44646918773651123, 0.5713937282562256, 0.17577143013477325, -0.5337210297584534, 0.4239085614681244, -0.22626550495624542, 0.04863565415143967, -0.30438119173049927, -0.8782433867454529, -1.6812852621078491, -0.43353402614593506, -1.0648399591445923, -0.013704149052500725, -1.149754524230957, -0.4213561415672302, -0.07351110875606537, -0.7228127121925354, 0.06447771936655045, 0.46526074409484863, 0.28415486216545105, -0.13154424726963043, -0.6442998647689819, -0.33064499497413635, 0.7916484475135803, 1.0584489107131958, -1.056524634361267, 0.21565452218055725, -0.5134360790252686, -0.1046433299779892, 0.18992038071155548, 0.39466428756713867, -0.22369004786014557, -1.1218870878219604, -1.0687458515167236, 0.5546852946281433, -0.6362336874008179, 0.08000954240560532, -1.0116769075393677, 0.8905828595161438, 0.3772422969341278, 0.41951945424079895, -0.2224976122379303, 0.6083874702453613, -0.6515642404556274, -0.7451247572898865, 0.16362640261650085, -0.6712019443511963, -0.06360720843076706, 0.1799522340297699, -0.06738927960395813, -0.2858550548553467, 0.7811219692230225, 0.33440354466438293, -0.9458098411560059, -1.2705461978912354, 0.6953585743904114, -0.36536043882369995, 0.3297823667526245, -0.10437063127756119, -0.3395756185054779, -1.2212013006210327, -0.49486199021339417, -0.09467726945877075, 0.5100656747817993, -0.6162647008895874, 1.1505649089813232, 0.7883949279785156, -1.1743923425674438, 0.06451154500246048, 0.6194888353347778, 0.3241439163684845, 0.353468120098114, 0.5859044194221497, 0.2158275991678238, -0.02892206236720085, 0.2859715521335602, -0.2622520327568054, -0.26240235567092896, -0.6323863863945007, 0.6053889989852905, 1.0364428758621216, -0.05798700451850891, 0.0055181109346449375, 1.061602234840393, 0.29626592993736267, -0.6845477223396301, 0.19610145688056946, -0.9481325149536133, -0.8825547695159912, 0.045309606939554214, 0.5020639896392822, -0.35000869631767273, -0.2537734806537628, -0.20694756507873535, -0.5226510763168335, 0.8267028331756592, -0.21105092763900757, -0.4101797640323639, 0.36113229393959045, -0.24327129125595093, -0.1412564069032669, 0.4861161410808563, 0.8674108982086182, -0.940118134021759, -1.0936704874038696, -0.991493821144104, -1.0708223581314087, 0.10601334273815155, 0.4827054738998413, -0.3096679747104645, -0.6300506591796875, 0.8271299004554749, 0.9794940948486328, 0.3363279402256012, 0.5159328579902649, 0.006597510538995266, 0.02189391478896141, 0.6850606203079224, -0.39173921942710876, -0.7616631388664246, 0.051843609660863876, 1.1698577404022217, 1.0707067251205444, -0.9153962731361389, -0.022586893290281296, 0.21012188494205475, -0.7832692861557007, 0.6648372411727905, 0.33321765065193176, -0.4706813395023346, 0.8124586939811707, -0.5917503833770752, 0.4142298102378845, 0.08122176676988602, -1.0405522584915161, -0.6040886640548706, 1.3628298044204712, 1.4613556861877441, 0.2123895138502121, -0.2320479452610016, 0.3738078474998474, 0.4223003685474396, 0.3272533118724823, -0.34050700068473816, 0.5204409956932068, 0.18657711148262024, -0.0701829195022583, 0.2680892050266266, -0.055100467056035995, 0.2469157576560974, -0.6861361861228943, -0.3334256708621979, 0.16524666547775269, 0.5555527210235596, 0.2871953845024109, 0.6711419820785522, 1.3301023244857788, 0.070479616522789, 0.23488019406795502, -0.11586398631334305, 0.9835690259933472, 0.21631164848804474, 0.039420969784259796, -0.1075865849852562, -1.2606738805770874, -0.04778515547513962, -0.7117184996604919, -0.4685150980949402, -0.27485448122024536, 0.004536407068371773, 0.40572628378868103, -0.29156163334846497, 0.7764151096343994, 0.9613388180732727, 0.5070543885231018, 0.8797680139541626, -0.07027485221624374, -0.48742952942848206, -0.05524445325136185, -0.8705975413322449, 0.38632720708847046, -0.29471355676651, 0.20478934049606323, -0.6201175451278687, -0.05564708635210991, 0.12193165719509125]}, "authors": [{"authorId": "151714237", "name": "Qiming Zhang"}, {"authorId": "48615515", "name": "Yufei Xu"}, {"authorId": "1519066969", "name": "Jing Zhang"}, {"authorId": "143719920", "name": "D. Tao"}], "references": [{"paperId": "fdcad86866ca22d8417599deb41b54fe01487ce8", "title": "ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation"}, {"paperId": "ba609e5c83ad9b32723e547b9d3c89d97373f755", "title": "VSA: Learning Varied-Size Window Attention in Vision Transformers"}, {"paperId": "ba637c4f1a170f1e2dadeadb71a63cf2b9a46de2", "title": "Visual attention network"}, {"paperId": "e5cb26148791b57bfd36aa26ce2401e231d01b57", "title": "Vision Transformer with Deformable Attention"}, {"paperId": "15b0e710a9b8069d898ae6a0963d627e0fb86bd8", "title": "MPViT: Multi-Path Vision Transformer for Dense Prediction"}, {"paperId": "008a428e049003fe768068a0f1fa1416af5c4982", "title": "Masked Feature Prediction for Self-Supervised Visual Pre-Training"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "9c4753ef43d2928866dc5bf6cec53d03373ec2fa", "title": "SimMIM: a Simple Framework for Masked Image Modeling"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "fd3bee898ae69bd956af9f4aabd3f7b478de2cbd", "title": "RobustART: Benchmarking Robustness on Architecture Design and Training Techniques"}, {"paperId": "fcdb8904fffd591030fcc102535a0581666c030b", "title": "AP-10K: A Benchmark for Animal Pose Estimation in the Wild"}, {"paperId": "a66686e60a3eda0c606e036403cf0a07a5962595", "title": "Mobile-Former: Bridging MobileNet and Transformer"}, {"paperId": "a5c41f188b0eb0acb444cb4899bf6af378ee9ede", "title": "CrossFormer: A Versatile Vision Transformer Hinging on Cross-scale Attention"}, {"paperId": "48418b285a92376a38daafa664a2dd07d42e3fe3", "title": "Focal Self-attention for Local-Global Interactions in Vision Transformers"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "7fff8018bf625447df837c2fda5c58a705fbc038", "title": "XCiT: Cross-Covariance Image Transformers"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "2a805d0e1b067444a554c5169d189fa1f649f411", "title": "Scaling Vision Transformers"}, {"paperId": "576c462dbc1f3d732b919ef1daac37a817123e52", "title": "ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias"}, {"paperId": "2e8149dafb864ec3675087c99bf5572fcf4eb170", "title": "RegionViT: Regional-to-Local Attention for Vision Transformers"}, {"paperId": "5faf75b5c5a4d83bd6407b4aba8fb0bccd7fa31d", "title": "Conformer: Local Features Coupling Global Representations for Visual Recognition"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "2c9fdba6bf846e0986cbbf30d56b467d9e334333", "title": "ConTNet: Why not use convolution and transformer at the same time?"}, {"paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6", "title": "Multiscale Vision Transformers"}, {"paperId": "14c52ffa7ea9c1971d5d82ea369c946c98d056a9", "title": "LocalViT: Bringing Locality to Vision Transformers"}, {"paperId": "739ceacfafb1c4eaa17509351b647c773270b3ae", "title": "An Empirical Study of Training Self-Supervised Vision Transformers"}, {"paperId": "003326a15fc4a8833785a47a741d7712474fa256", "title": "LeViT: a Vision Transformer in ConvNet\u2019s Clothing for Faster Inference"}, {"paperId": "40f4d7fe800810288a80f84cdb357a8f4c28e880", "title": "Rethinking Spatial Dimensions of Vision Transformers"}, {"paperId": "3cbe314cc5407a6c3249815b5173f22ea15173c2", "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "0eff37167876356da2163b2e396df2719adf7de9", "title": "CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification"}, {"paperId": "d2a3bb6356d439146cd8d8e72dc728a1e3d93e7f", "title": "Understanding Robustness of Transformers for Image Classification"}, {"paperId": "2984ab83ade26639c3a82d29628d0d9e4abbebb0", "title": "Incorporating Convolution Designs into Visual Transformers"}, {"paperId": "610b302950a19acef1c45456111dcd495f638c18", "title": "ConViT: improving vision transformers with soft convolutional inductive biases"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "d29430adccb805ab57b349afa8553954347b3197", "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "b52431a4268bd2f848db4a0c8c614dc1e687eeab", "title": "Grafit: Learning fine-grained image representations with coarse labels"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "f5c8464032a936451b222be1984cabf42d6adfa8", "title": "Are we done with ImageNet?"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "43497fe8aa7c730e075b08facc2aa560a6d4dd85", "title": "Meta Pseudo Labels"}, {"paperId": "bc51622358d8eea83248ef29402fe10640d07ba6", "title": "Big Transfer (BiT): General Visual Representation Learning"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "bc626a52664e948a0ffb2b95d0e1e6377a01171a", "title": "Cascade R-CNN: High Quality Object Detection and Instance Segmentation"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "dc9187434a1c27306c61a3317aa942d3402d97c3", "title": "Simple Baselines for Human Pose Estimation and Tracking"}, {"paperId": "b632e8991c4dd2c3829ec15d0cbb8cdc07033ea9", "title": "Fully Point-wise Convolutional Neural Network for Modeling Statistical Regularities in Natural Images"}, {"paperId": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4", "title": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"}, {"paperId": "04957e40d47ca89d38653e97f728883c0ad26e5d", "title": "Cascade R-CNN: Delving Into High Quality Object Detection"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "c4c06578f4870e4b126e6837907929f3c900b99f", "title": "Dynamic Routing Between Capsules"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "ee4a012a4b12d11d7ab8c0e79c61e807927a163c", "title": "Rethinking Atrous Convolution for Semantic Image Segmentation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "6f34b9a4a0e2ee90e86ed720dc26cc6ba9da8df0", "title": "Dilated Residual Networks"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "88d346374f17189cebef7394ae5d39492443df89", "title": "Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "2a94c84383ee3de5e6211d43d16e7de387f68878", "title": "Feature Pyramid Networks for Object Detection"}, {"paperId": "01a4f33da8ad94ced3cf58548b28dbbb44148571", "title": "Understanding the Effective Receptive Field in Deep Convolutional Neural Networks"}, {"paperId": "1031a69923b80ad01cf3fbb703d10757a80e699b", "title": "Pyramid Scene Parsing Network"}, {"paperId": "5582bebed97947a41e3ddd9bd1f284b73f1648c2", "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"}, {"paperId": "5694e46284460a648fe29117cbc55f6c9be3fa3c", "title": "Densely Connected Convolutional Networks"}, {"paperId": "88512be44744615f4baa8e14f600f036db4c2433", "title": "Semantic Understanding of Scenes Through the ADE20K Dataset"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "b5c26ab8767d046cb6e32d959fdf726aee89bb62", "title": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "7f5fc84819c0cf94b771fe15141f65b123f7b8ec", "title": "Multi-Scale Context Aggregation by Dilated Convolutions"}, {"paperId": "4cef5476f9da50c1a8fefdcb7114863966f61d67", "title": "Efficient Piecewise Training of Deep Structured Models for Semantic Segmentation"}, {"paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327", "title": "Going deeper with convolutions"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "cbb19236820a96038d000dc629225d36e0b6294a", "title": "Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "a83cec6a91701bd8500f8c43ad731d4353c71d55", "title": "3D Object Representations for Fine-Grained Categorization"}, {"paperId": "1a2a770d23b4a171fa81de62a78a3deb0588f238", "title": "Visualizing and Understanding Convolutional Networks"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "84b50ebe85f7a1721800125e7882fce8c45b5c5a", "title": "Cats and dogs"}, {"paperId": "976e29fe6c9baeb39732bca0e35f66f84d5bdd90", "title": "ORB: An efficient alternative to SIFT or SURF"}, {"paperId": "5b101adf8a387ae4bc750fdb8dfae42648186588", "title": "IMAGE Resolution Enhancement by Using Discrete and Stationary Wavelet Decomposition"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "02b28f3b71138a06e40dbd614abf8568420ae183", "title": "Automated Flower Classification over a Large Number of Classes"}, {"paperId": "5a46f093f587eaa29c4d87c755b4b1fa3eabecdb", "title": "PCA-SIFT: a more distinctive representation for local image descriptors"}, {"paperId": "23ca99cc5b24ff959e195879413fdf66f26e8373", "title": "SIFT: predicting amino acid changes that affect protein function"}, {"paperId": "563e821bb5ea825efb56b77484f5287f08cf3753", "title": "Convolutional networks for images, speech, and time series"}, {"paperId": "7424d97bcd51df0d5fa963314f580095ab2f1152", "title": "Gaussian Pyramid Wavelet Transform for Multiresolution Analysis of Images"}, {"paperId": "e49793511ba203e26b99e7e81fd15a7d505b5cea", "title": "PYRAMID METHODS IN IMAGE PROCESSING."}, {"paperId": "83074157d165b6245915508d891b2d0cd066f3ad", "title": "The Laplacian Pyramid as a Compact Image Code"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "7af37e8623d7d68acf1c45c918e597539bcdbb96", "title": "Gauge Equivariant Transformer"}, {"paperId": "03ce51e5e854faa614e79afe4dab8baeb5f73980", "title": "Twins: Revisiting Spatial Attention Design in Vision Transformers"}, {"paperId": null, "title": "A.v.d.: Are we done with imagenet? arXiv preprint arXiv:2006.07159"}, {"paperId": null, "title": "MMSegmentation: Openmmlab semantic segmentation toolbox and benchmark"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Pytorch image models"}, {"paperId": null, "title": "IEEE Transactions on Pattern Analysis and Machine Intelligence Chen CF, Panda R, Fan Q (2021a) Regionvit: Regional-tolocal attention for vision transformers"}, {"paperId": "2913c2bf3f92b5ae369400a42b2d27cc5bc05ecb", "title": "Deep Learning"}, {"paperId": null, "title": "A (2015) Very deep convolutional"}, {"paperId": "6c7cf406a47048730c1a08d46cb0166b16566524", "title": "Notes on the OpenSURF Library"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "59c11e99b5778e995addcad939c626264aeda475", "title": "Dynamic Routing\uc758 \uc774\ub860\uacfc \uc2e4\uc81c"}, {"paperId": null, "title": "Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations"}]}