{"paperId": "06c1a843617621d29208010e5475e4b5a6cc68ca", "abstract": "Recently, linear complexity sequence modeling networks have achieved modeling capabilities similar to Vision Transformers on a variety of computer vision tasks, while using fewer FLOPs and less memory. However, their advantage in terms of actual runtime speed is not significant. To address this issue, we introduce Gated Linear Attention (GLA) for vision, leveraging its superior hardware-awareness and efficiency. We propose direction-wise gating to capture 1D global context through bidirectional modeling and a 2D gating locality injection to adaptively inject 2D local details into 1D global context. Our hardware-aware implementation further merges forward and backward scanning into a single kernel, enhancing parallelism and reducing memory cost and latency. The proposed model, ViG, offers a favorable trade-off in accuracy, parameters, and FLOPs on ImageNet and downstream tasks, outperforming popular Transformer and CNN-based models. Notably, ViG-S matches DeiT-B's accuracy while using only 27% of the parameters and 20% of the FLOPs, running 2$\\times$ faster on $224\\times224$ images. At $1024\\times1024$ resolution, ViG-T uses 5.2$\\times$ fewer FLOPs, saves 90% GPU memory, runs 4.8$\\times$ faster, and achieves 20.7% higher top-1 accuracy than DeiT-T. These results position ViG as an efficient and scalable solution for visual representation learning. Code is available at \\url{https://github.com/hustvl/ViG}.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The proposed model, ViG, offers a favorable trade-off in accuracy, parameters, and FLOPs on ImageNet and downstream tasks, outperforming popular Transformer and CNN-based models and position ViG as an efficient and scalable solution for visual representation learning."}, "embedding": {"model": "specter_v2", "vector": [0.385708749294281, -0.0021549868397414684, -0.23803958296775818, 0.03790014237165451, 0.23995853960514069, 0.25866350531578064, 0.7058572173118591, -0.38332363963127136, -0.6629180312156677, -0.5287022590637207, 0.23440897464752197, 0.2685299515724182, 0.7617459893226624, -0.1639624983072281, -0.07137592136859894, 0.17047888040542603, -0.9980547428131104, -0.036435745656490326, 0.7431851625442505, -0.4292990267276764, 0.364025741815567, 0.10720052570104599, -1.249325156211853, 0.26893937587738037, -0.2386469542980194, 0.9188104271888733, 0.7441056966781616, 1.3391036987304688, -0.18923014402389526, 0.9050787687301636, 0.6855674982070923, -0.01911245472729206, 0.3811648488044739, -0.05828697234392166, -0.24103422462940216, -0.3185059428215027, 0.7596861720085144, -0.4976961016654968, -0.7887786030769348, 0.751975953578949, 0.07875297218561172, 0.29769888520240784, 0.3783078193664551, -0.7283033132553101, 0.010756000876426697, -0.12099188566207886, 0.08071910589933395, 0.9090429544448853, -0.4304230809211731, -0.1438136249780655, 1.3348594903945923, -1.343711018562317, 0.3321625888347626, 1.44143807888031, 0.49219807982444763, 0.4311997592449188, 0.04076874256134033, -0.5871564149856567, 1.2381309270858765, 0.5298154950141907, -0.4878002405166626, -0.1527753323316574, -0.03818715736269951, -0.34715813398361206, 1.9134716987609863, -0.8811188340187073, 0.6556405425071716, 0.641986072063446, 0.32230910658836365, 1.1832672357559204, -0.03772793710231781, -0.8415159583091736, -0.13253360986709595, -0.5780288577079773, 0.3553731441497803, 1.1568683385849, -0.05029924586415291, 0.8108316659927368, -1.0137536525726318, 0.29852789640426636, 1.0329161882400513, -0.013945838436484337, 0.23280377686023712, -0.37591636180877686, -0.2621259391307831, 0.7375807762145996, 1.219605565071106, 0.45948901772499084, -0.35600027441978455, 1.3229455947875977, 0.6050359606742859, -0.12594564259052277, -0.4552689790725708, 0.030692117288708687, 0.2775713801383972, 0.8562360405921936, -0.6865047812461853, -0.07044603675603867, -0.35483428835868835, 1.0659934282302856, -0.09306079149246216, 0.6665030121803284, -0.35793012380599976, -0.2532050907611847, 1.2200102806091309, -0.20308983325958252, 0.17442014813423157, -0.354236900806427, -0.11633334308862686, -0.7928550839424133, -0.10212376713752747, -0.9295782446861267, -0.16676191985607147, -0.5159280300140381, -0.8311843276023865, -0.5387994050979614, -0.4867136478424072, 0.7408353090286255, -1.1432238817214966, 0.5804625153541565, -0.4800918996334076, 0.44796866178512573, -0.5115463733673096, 0.463527649641037, 0.5140448808670044, 0.4734868109226227, 0.6101372838020325, 0.38028478622436523, 1.1420328617095947, -1.3322025537490845, -0.09450649470090866, -1.122288703918457, 0.26281893253326416, 0.06266235560178757, 0.24988766014575958, -0.08539637178182602, -1.1524062156677246, -1.699035406112671, -0.8368546366691589, -0.33807483315467834, -0.6428244709968567, 0.08945531398057938, 1.0551815032958984, 0.06775468587875366, -1.3745784759521484, 0.4095080494880676, -0.4634349048137665, -0.18647748231887817, 0.6389634609222412, -0.11354558914899826, 0.5030946135520935, -0.5281911492347717, -0.8259401917457581, 0.35384270548820496, 0.0699688121676445, -0.31419500708580017, -0.7850538492202759, -0.4996899962425232, -1.3092570304870605, 0.04645290598273277, -0.10315225273370743, -0.8993675112724304, 0.7820237278938293, -0.21850034594535828, -0.5757697224617004, 0.8450570702552795, -0.5534852743148804, -0.23320326209068298, 0.1236007809638977, -0.2036469280719757, -0.022393586114048958, -0.31142300367355347, -0.3527139127254486, 0.9995846152305603, 0.7308066487312317, -0.35127732157707214, -0.5543416142463684, 0.08648739755153656, -0.27143362164497375, -0.16208608448505402, -0.23756617307662964, 0.9996563792228699, -0.6271182298660278, -0.21117906272411346, 0.36908021569252014, 0.4784722924232483, -0.43397068977355957, 0.1498251110315323, 0.2980784773826599, -0.7346155643463135, 0.8514169454574585, 0.12564687430858612, 0.5156826972961426, -0.6039846539497375, -0.8377172946929932, -0.31337404251098633, 0.3654877543449402, -0.22397224605083466, -0.9032382369041443, 0.2905290424823761, -0.4120415151119232, 0.1470203846693039, 0.22587023675441742, -0.8877375721931458, -0.2524186670780182, -0.5776254534721375, -0.6466123461723328, 0.04160697013139725, 0.11822175234556198, 1.5375287532806396, -1.2289894819259644, -0.0964694544672966, 0.21633082628250122, 0.3363927900791168, -0.9414685368537903, 1.2195749282836914, -0.4657665193080902, 0.009984667412936687, 0.1408826857805252, -0.06498002260923386, -0.2452893704175949, -0.6360151767730713, 0.49301794171333313, -0.9984832406044006, -0.16308340430259705, 0.34978991746902466, 0.08977457880973816, 1.2387629747390747, -0.41557642817497253, 0.9953149557113647, -0.5616419315338135, -0.5724641680717468, 0.5238946080207825, -0.22635386884212494, -0.39128032326698303, -0.7371256947517395, 0.324780136346817, -0.1230149045586586, -0.5151808261871338, 0.38433176279067993, 0.4636477530002594, 1.1247419118881226, -0.11980415880680084, -0.14681760966777802, 0.5035977959632874, -0.2739768624305725, 0.17854538559913635, 0.465766042470932, 0.6250160336494446, 0.5766154527664185, 0.7032003402709961, -0.005765445996075869, 0.13357692956924438, -0.9005892872810364, -0.05853036791086197, 0.9102698564529419, 0.19123844802379608, 1.0311359167099, 0.24025598168373108, -1.2171825170516968, -0.7879896759986877, 0.2934422492980957, 0.9742776155471802, 1.4143803119659424, 0.09362850338220596, 0.09322644770145416, -0.2517446279525757, -0.22262658178806305, -0.6386504769325256, -0.34397488832473755, -0.5785644054412842, -0.1501539647579193, -0.6678563356399536, -0.5984062552452087, 0.602765679359436, 0.743829607963562, 1.3639663457870483, -0.8932833075523376, -0.839680552482605, -0.23519210517406464, 0.5691382884979248, -1.1453120708465576, -0.7661074995994568, 0.3601514995098114, -0.37507665157318115, -0.16036777198314667, 0.18141113221645355, -0.3756324052810669, 0.21046234667301178, -0.11390607059001923, 1.1316643953323364, -0.422161340713501, -0.9406281113624573, 0.25054576992988586, 0.6590499877929688, -0.6614378690719604, -0.10699672251939774, 0.10030946880578995, -0.1485612690448761, -0.23835280537605286, 0.301203191280365, 0.4044339060783386, -0.5447785258293152, 0.1397390365600586, -0.19405607879161835, 0.2439131885766983, 0.14005208015441895, 0.019872842356562614, 0.8706561923027039, -0.6229404211044312, 0.2372572124004364, -0.7400687336921692, 0.4173843562602997, 0.6277856826782227, -0.7137997150421143, 0.1910552978515625, -0.36768239736557007, -0.42367976903915405, 0.39246413111686707, -0.5559860467910767, -0.029183709993958473, -0.3506324291229248, 0.3390132188796997, -0.9146945476531982, -0.45474308729171753, -0.28366073966026306, 0.48226362466812134, -0.7187066674232483, 0.5020373463630676, 0.5437189340591431, 0.08377274125814438, 0.54331374168396, 0.445978581905365, -1.6662834882736206, 0.7022516131401062, 0.40287163853645325, 0.06450127810239792, 0.28808748722076416, 0.32207217812538147, -0.7518796920776367, -0.5813219547271729, -0.6422746181488037, -0.6611211895942688, -0.9729808568954468, 0.6628523468971252, -0.6456323862075806, -1.0998681783676147, 0.11026456952095032, -1.1195614337921143, -0.3483242988586426, 0.17616190016269684, -0.12226860970258713, -0.30446043610572815, -0.9513441920280457, -0.8683629631996155, -0.5615761876106262, -0.6095935702323914, -1.0893088579177856, 0.1326756328344345, 0.12380985170602798, -0.09366371482610703, -0.7405903339385986, -0.15616294741630554, -0.672244668006897, 1.110891580581665, -0.0011682499898597598, 0.5981565117835999, 0.26483455300331116, -0.6664873361587524, -0.16704963147640228, -0.24977561831474304, 0.34873339533805847, -0.32822272181510925, 0.3354575037956238, -1.0119248628616333, 0.049496155232191086, -0.37913718819618225, -0.6166386008262634, 0.6144489645957947, 0.6505112648010254, 0.9379453063011169, 0.4458557963371277, -0.3992621600627899, 0.5484156012535095, 1.6494548320770264, -0.33448439836502075, 0.18695232272148132, 0.04402662068605423, 1.2061944007873535, -0.011400905437767506, -0.09200721979141235, 0.6475951075553894, 0.2394765317440033, 0.27765998244285583, 0.600711464881897, -0.639138400554657, -0.8742230534553528, -0.7249203324317932, 0.13228246569633484, 0.9247927069664001, 0.1515987366437912, 0.21018876135349274, -0.9426829218864441, 0.7121530175209045, -0.8461186289787292, -1.1247872114181519, 0.6714697480201721, 0.8095101714134216, -0.1564875692129135, -0.04773242771625519, 0.0039782109670341015, -0.734969437122345, 0.7891619205474854, 0.7332313060760498, -0.5283302664756775, -0.5385451316833496, -0.06610851734876633, 0.33280637860298157, 0.33225223422050476, 0.6895378828048706, -0.1424432098865509, 0.7632544636726379, 14.42808723449707, 0.5660586357116699, -0.5573382377624512, 0.27414897084236145, 1.0218697786331177, 0.4103906750679016, -0.13157954812049866, 0.17195475101470947, -1.4341185092926025, -0.4425618648529053, 0.5513136386871338, 0.2033248245716095, 0.33675694465637207, 0.38696956634521484, 0.09656284004449844, 0.3612801432609558, -0.8107455968856812, 1.148616075515747, 0.7747430801391602, -1.6054006814956665, 0.5347186326980591, 0.20347531139850616, 0.3979620337486267, 0.5591380596160889, 0.8435710072517395, 0.6149687767028809, 0.31670650839805603, -0.7066742777824402, 0.3382343649864197, 0.42331796884536743, 1.1217894554138184, 0.30105021595954895, 0.037314653396606445, 0.25401541590690613, -1.654036283493042, -0.10131000727415085, -0.9164683818817139, -1.1469459533691406, 0.2489943504333496, -0.1763269454240799, -0.6772447228431702, -0.5359835028648376, -0.13327498733997345, 1.150061845779419, -0.03645659610629082, 0.7303522229194641, -0.16266459226608276, 0.2805749773979187, 0.08570510894060135, -0.21845903992652893, 0.6654561161994934, 0.4954722225666046, -0.16278260946273804, 0.22043827176094055, -0.19227692484855652, 0.3914852738380432, 0.390127032995224, 0.31708237528800964, -0.3735056519508362, -0.5382975339889526, -0.557399332523346, 0.16296544671058655, -0.1614566296339035, 0.7802024483680725, 0.004111323039978743, 0.29151397943496704, -0.17017215490341187, 0.012647859752178192, 0.6282058954238892, 0.18353158235549927, -0.6199086308479309, 0.2572997212409973, 0.0490696020424366, -0.5509254932403564, 0.4263071119785309, 0.07477304339408875, -0.4773516058921814, -0.4473045766353607, -0.9915931224822998, -0.2801010310649872, 0.48273196816444397, -0.9368517994880676, -0.5769213438034058, 1.154599905014038, -0.2643894851207733, -0.2949391007423401, 0.4169534146785736, -0.906980574131012, -0.36753788590431213, 0.298061341047287, -1.6435739994049072, -0.7066409587860107, -0.5292862057685852, -0.10108737647533417, 0.03179657831788063, 0.057415422052145004, 0.5884683728218079, -0.017908714711666107, 0.10284578800201416, 0.08105243742465973, -0.7968177199363708, -0.24966321885585785, -0.36344948410987854, -0.31128793954849243, 1.2465070486068726, 0.3532348871231079, 0.05203014612197876, -0.1148453801870346, -0.0938715934753418, 0.13024719059467316, -0.7372387647628784, -0.2933107316493988, 0.3981049358844757, -0.4474712908267975, -0.28265392780303955, -0.9675166606903076, -0.8687755465507507, 0.39099061489105225, 0.40726038813591003, 0.29133662581443787, -0.26405054330825806, -0.1935143768787384, -0.8178021907806396, -0.16576749086380005, -0.5275774598121643, 0.2581603527069092, 0.6870459318161011, -0.6701402068138123, -0.014790037646889687, -0.18303163349628448, 0.23908689618110657, -0.799530029296875, -0.11454974859952927, -0.05843517184257507, 0.42301124334335327, -0.4379577934741974, 1.215144157409668, -0.5085790753364563, 0.5159165263175964, 0.6675412058830261, -0.0936245545744896, -0.22977517545223236, -0.5623071789741516, -0.5602663159370422, 0.2779863178730011, -0.2333706170320511, -0.0011998987756669521, -0.37973958253860474, 0.49012234807014465, 0.27445849776268005, 0.37099647521972656, -0.7307531237602234, -0.39083847403526306, -0.14675848186016083, -0.2916739881038666, -0.6189092993736267, -0.28061938285827637, -0.3064875304698944, -0.6403486728668213, 0.14057300984859467, 0.18662531673908234, 0.5935925841331482, 0.028157977387309074, -0.4710786044597626, 0.3897959887981415, 0.20283183455467224, -0.017557179555296898, -0.7799167633056641, -1.2187285423278809, -1.8152302503585815, -0.19374756515026093, -0.8621532320976257, -0.1826068013906479, -1.0459554195404053, -0.4901445508003235, 0.07126041501760483, -0.20480740070343018, 0.22868184745311737, 0.3880004584789276, 0.021384304389357567, -0.11036469787359238, -0.5569974780082703, -0.6518427729606628, 0.7697740197181702, 1.0360666513442993, -0.4783904552459717, 0.3369535207748413, -0.2310352772474289, 0.4451581537723541, 0.5324326157569885, 0.1817367672920227, -0.14649012684822083, -0.8506114482879639, -0.9883504509925842, 0.25677481293678284, -0.06099768355488777, 0.19707845151424408, -1.333310842514038, 1.1426032781600952, 0.356673926115036, 0.2500300407409668, -0.34715545177459717, 0.42803019285202026, -0.7719648480415344, -0.6711411476135254, 0.9080876708030701, -0.8780755996704102, 0.37787678837776184, 0.4716072380542755, -0.32203176617622375, -0.21416006982326508, 0.8795796632766724, 0.5306335091590881, -1.1291282176971436, -1.5964223146438599, 0.8166040182113647, -0.17151279747486115, 0.05567290261387825, -0.07141875475645065, -0.3753591775894165, -1.275491714477539, -0.5079953670501709, -0.11734113097190857, 0.3854144811630249, -0.41346845030784607, 0.6365997195243835, 1.3623005151748657, -1.0201382637023926, 0.08860072493553162, 0.3521946370601654, -0.12375225126743317, -0.10578048229217529, 0.6762229204177856, 0.23123367130756378, -0.42441216111183167, 0.5638257265090942, -0.23237474262714386, 0.27549049258232117, -0.8793435096740723, 0.5322957038879395, 1.1253066062927246, -0.39857444167137146, -0.12226436287164688, 1.2058587074279785, 0.43602368235588074, -0.49816131591796875, 0.33879104256629944, -0.9961498379707336, -0.5684182047843933, -0.1954260915517807, 0.558458685874939, 0.11518247425556183, 0.02152738720178604, 0.16675256192684174, -0.6271116137504578, 0.6286293864250183, -0.3790547251701355, -0.5689938068389893, 0.07605326175689697, 0.14764563739299774, -0.218658447265625, 0.6018795371055603, 1.0242847204208374, -1.011594533920288, -1.1199129819869995, -0.7661684155464172, -0.7218123078346252, -0.3505314290523529, 0.25542783737182617, -0.1631198674440384, -0.9337936639785767, 0.9638099074363708, 0.7598848938941956, 0.05465034395456314, 0.4343830645084381, -0.2723064124584198, -0.04191106557846069, 0.6008762121200562, 0.2747254967689514, -0.012992676347494125, 0.0848103016614914, 1.47385835647583, 1.4213051795959473, -0.685369074344635, 0.22189699113368988, -0.24160535633563995, -0.6550459861755371, 0.9472205638885498, 0.8832489252090454, -0.8241000175476074, 0.7127288579940796, -0.34486377239227295, -0.16132032871246338, 0.0803995430469513, -1.139988660812378, -0.42012399435043335, 0.9527205228805542, 1.2093238830566406, 0.6103459000587463, -0.3589657247066498, 0.1868809461593628, -0.025897277519106865, 0.40612462162971497, 0.18981307744979858, 0.2466256320476532, 0.4443461298942566, -0.2717912495136261, 0.6385504603385925, 0.16675782203674316, 0.5732296109199524, -0.17650754749774933, -0.7883046865463257, 0.45810264348983765, 0.6838834285736084, -0.07033482939004898, 0.24363817274570465, 0.8549095988273621, 0.07886645197868347, 0.5347622036933899, -0.26246586441993713, 0.7477970719337463, -0.3204289674758911, -0.11910467594861984, -0.14174681901931763, -1.0948811769485474, -0.35293063521385193, -0.3238636255264282, -0.5124014019966125, -0.35398656129837036, 0.047891609370708466, 0.5304134488105774, -0.5680070519447327, 0.2739821672439575, 0.46812769770622253, 0.4923500716686249, 0.8377827405929565, -0.1873546689748764, -0.9322644472122192, -0.007291762623935938, -0.4294629395008087, 0.4971315562725067, -0.6179796457290649, -0.004480444360524416, -0.4015752077102661, 0.027761342003941536, -0.027885781601071358]}, "authors": [{"authorId": "2060439659", "name": "Bencheng Liao"}, {"authorId": "2266175736", "name": "Xinggang Wang"}, {"authorId": "2261901203", "name": "Lianghui Zhu"}, {"authorId": "2261816376", "name": "Qian Zhang"}, {"authorId": "2261759913", "name": "Chang Huang"}], "references": [{"paperId": "e9484cf633985ccef70b0ce46866ce232a81ca4b", "title": "Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length"}, {"paperId": "46732358e98ce6be0c564ae11f71d556a64b4c35", "title": "HGRN2: Gated Linear RNNs with State Expansion"}, {"paperId": "3fd5bc3077d04965eaa3498372c39bbdd09d55e4", "title": "Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention"}, {"paperId": "541bcf94bd09f17c25d8ed7cd10e69c8f91331d0", "title": "ChangeMamba: Remote Sensing Change Detection With Spatiotemporal State Space Model"}, {"paperId": "2833716cabbd7c709f4b266832b8b3fa3e37d2c6", "title": "RS-Mamba for Large Remote Sensing Image Dense Prediction"}, {"paperId": "69fa358ca1680ff2779477bdab2f42851c2499ca", "title": "Gamba: Marry Gaussian Splatting with Mamba for single view 3D reconstruction"}, {"paperId": "62ac3ef81e54e1d1930fb5980b236345ee2e4f32", "title": "PlainMamba: Improving Non-Hierarchical Mamba in Visual Recognition"}, {"paperId": "fea8a3096391a418cb9ef724e0ff9754e5a467fd", "title": "SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series"}, {"paperId": "9f1dc0ebf06841f988d7a1d12d1d2206c0707b53", "title": "EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba"}, {"paperId": "5867382590f9f0ff8caf15804d20bde10845b2d2", "title": "LocalMamba: Visual State Space Model with Windowed Selective Scan"}, {"paperId": "0a32e6ff6eaac83ff325bae4557a8362222979aa", "title": "Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding"}, {"paperId": "b9646f057887825d7471ec01664494b0b7ca5a83", "title": "Motion Mamba: Efficient and Long Sequence Motion Generation with Hierarchical and Bidirectional Selective SSM"}, {"paperId": "3af7273d7ca20c0c63cbaa47e60b058840835052", "title": "VideoMamba: State Space Model for Efficient Video Understanding"}, {"paperId": "51f38bd957fa863022feb5878fa1ba3bea6657cf", "title": "Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like Architectures"}, {"paperId": "d53fe76bd2795a19ddf52d012917782f6f6f2c1e", "title": "Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models"}, {"paperId": "cde66097f4123a62bf3e28d48c764648e8c69f72", "title": "Simple linear attention language models balance the recall-throughput tradeoff"}, {"paperId": "efb7af4ae6943f298449416529c288e9559c991b", "title": "Pan-Mamba: Effective pan-sharpening with State Space Model"}, {"paperId": "21ddc4fc3551619b8a64db6ae124acc72aaae2c2", "title": "PointMamba: A Simple State Space Model for Point Cloud Analysis"}, {"paperId": "7154fc93bdefcd237a0ce3902511c0b154049253", "title": "Scalable Diffusion Models with State Space Backbone"}, {"paperId": "906d0688e1c683d5fec70e88e71ea1291c666b78", "title": "Mamba-ND: Selective State Space Modeling for Multi-Dimensional Data"}, {"paperId": "3719ad19da30771aba5d5c48491a21d6c393832d", "title": "Vivim: a Video Vision Mamba for Medical Video Object Segmentation"}, {"paperId": "5358b0e98934f1bbe8f6123a529bbb91dd36d662", "title": "SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation"}, {"paperId": "b24e899ec0f77eef2fc87a9b8e50516367aa1f97", "title": "VMamba: Visual State Space Model"}, {"paperId": "38c48a1cd296d16dc9c56717495d6e44cc354444", "title": "Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model"}, {"paperId": "c1a04730c83967d0bb904b02263b17893cb50bad", "title": "U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation"}, {"paperId": "62b18cc55dcc7ffe52c28e1086aee893b7bc4334", "title": "Gated Linear Attention Transformers with Hardware-Efficient Training"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "31245344a6eb6cd897a71928dc4b174ab75e4070", "title": "Diffusion Models Without Attention"}, {"paperId": "434d751d355d7a7c20efa570e785c76286245e77", "title": "Hierarchically Gated Recurrent Neural Network for Sequence Modeling"}, {"paperId": "5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0", "title": "Qwen Technical Report"}, {"paperId": "240103933ffe3dac2179cc160a2bd91299357a53", "title": "Retentive Network: A Successor to Transformer for Large Language Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8", "title": "Visual Instruction Tuning"}, {"paperId": "a08b7123a7158f1a7fbbc18e8b5aaebd47980ecf", "title": "EVA-CLIP: Improved Training Techniques for CLIP at Scale"}, {"paperId": "3049c992adbd56e29c4d957ee0c4e9d05fe3c6d1", "title": "EVA-02: A Visual Representation for Neon Genesis"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "a128b1c47e6842605fb95bceae930d2135fc38fc", "title": "Pretraining Without Attention"}, {"paperId": "736973165f98105fec3729b7db414ae4d80fcbeb", "title": "Scalable Diffusion Models with Transformers"}, {"paperId": "3cb3052825d387a2a0eed29c92f07466d2f4a9ed", "title": "Conv2Former: A Simple Transformer-Style ConvNet for Visual Recognition"}, {"paperId": "78281482c1fdad8e167bab39cc9955c73d58ae8f", "title": "EVA: Exploring the Limits of Masked Visual Representation Learning at Scale"}, {"paperId": "26c80bd65baa90f5b18157de4951f4eb0b62ab69", "title": "InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions"}, {"paperId": "e3fc46d5f4aae2c7a8a86b6bd21ca8db5d40fcbd", "title": "The Devil in Linear Transformer"}, {"paperId": "ae67e83980825aa59d5bf67d14213222ca2717cf", "title": "S4ND: Modeling Images and Videos as Multidimensional Signals Using State Spaces"}, {"paperId": "f6d8beb02771791d628f7e0773d8906261ce707c", "title": "Fine-Tuning Pre-trained Transformers into Decaying Fast Weights"}, {"paperId": "6d7d141c75af752ffc0d8a6184cca3f9323d6c74", "title": "Simplified State Space Layers for Sequence Modeling"}, {"paperId": "3e448df5aa191f7a3945d0fd609c8bc5966a2333", "title": "HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions"}, {"paperId": "d1869155960e4b1b882b39171dbecd25a7eda3cd", "title": "More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity"}, {"paperId": "eaef083b9d661f42cc0d89d9d8156218f33a91d9", "title": "Long Range Language Modeling via Gated State Spaces"}, {"paperId": "98e702ef2f64ab2643df9e80b1bd034334142e62", "title": "HiViT: Hierarchical Vision Transformer Meets Masked Image Modeling"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "c431408780586268e8bcf2483b01a80728d10960", "title": "Vision Transformer Adapter for Dense Predictions"}, {"paperId": "f634a09747e4ca11754a9bfdccf7485c884f9f86", "title": "TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation"}, {"paperId": "fb3761d27765536b204191d2a8bca2898055cb95", "title": "Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection"}, {"paperId": "2ad12a7be5eaf339a98c4defd8669e11fe726acc", "title": "MaxViT: Multi-Axis Vision Transformer"}, {"paperId": "a09cbcaac305884f043810afc4fa4053099b5970", "title": "Exploring Plain Vision Transformer Backbones for Object Detection"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "f4b11a696aa5a03fed1bfc47e65fdb7eb0e529c1", "title": "UniFormer: Unifying Convolution and Self-Attention for Visual Recognition"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "0b036cd5dfc49d835d0c759c8ca31d89f2410e65", "title": "CMT: Convolutional Neural Networks Meet Vision Transformers"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "48418b285a92376a38daafa664a2dd07d42e3fe3", "title": "Focal Self-attention for Local-Global Interactions in Vision Transformers"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "9d1934ea1bd69d928d17e05d44495d42edf8601d", "title": "You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection"}, {"paperId": "07e987364bf0be1949e379f976f8dea675977337", "title": "MSG-Transformer: Exchanging Local Spatial Information by Manipulating Messenger Tokens"}, {"paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60", "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"}, {"paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de", "title": "Pay Attention to MLPs"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "8f8f73f0f208302546c825ed474432389ed63be4", "title": "EfficientNetV2: Smaller Models and Faster Training"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "610b302950a19acef1c45456111dcd495f638c18", "title": "ConViT: improving vision transformers with soft convolutional inductive biases"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "10eda4521c032adabaa8e70d6569e17370b29dcd", "title": "Root Mean Square Layer Normalization"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "441555b5cd09703e55c03e70bd2c9f82c0ffcf9b", "title": "Deep High-Resolution Representation Learning for Visual Recognition"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "5132500b23d2da47129b3f4f68dd30947a29e502", "title": "CCNet: Criss-Cross Attention for Semantic Segmentation"}, {"paperId": "c02b909a514af6b9255315e2d50112845ca5ed0e", "title": "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "ebc96892b9bcbf007be9a1d7844e4b09fde9d961", "title": "YOLOv3: An Incremental Improvement"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "5694e46284460a648fe29117cbc55f6c9be3fa3c", "title": "Densely Connected Convolutional Networks"}, {"paperId": "88512be44744615f4baa8e14f600f036db4c2433", "title": "Semantic Understanding of Scenes Through the ADE20K Dataset"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "e23c34414e66118ecd9b08cf0cd4d016f59b0b85", "title": "Bidirectional recurrent neural networks"}, {"paperId": "63f1f2dad0a2e84d37a97258008c5609195487f0", "title": "Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "A method for stochastic optimization"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}, {"paperId": null, "title": "Unire-plknet: A universal perception large-kernel convnet for audio, video, point cloud, time-series and image recognition"}, {"paperId": null, "title": "FLA: A Triton-based library for hardware-efficient implementations of linear attention mechanism"}, {"paperId": null, "title": "Zigma: Zigzag mamba diffusion model"}]}