{"paperId": "c010e76751aaac668bbd5494b2c98a2b7fdd5947", "abstract": "Scaling neural network models has delivered dramatic quality gains across ML problems. However, this scaling also increased the reliance on efficient distributed training techniques. Accordingly, like other distributed computing scenarios, it is important to understand how compute and communication will scale relative to one another as models scale and hardware evolves? A careful study which answers this question can better guide the design of future systems which can efficiently train future large models.Accordingly, we comprehensively analyze compute vs. communication (Comp-vs.-Comm) scaling for future Transformer models on future hardware, across multiple axes (algorithmic, empirical, hardware evolution). First, our algorithmic analysis shows that compute generally enjoys an edge over communication as models scale. However, these trends are being stressed since device memory capacity scales much slower than model size. We quantify this edge by empirically studying how Comp-vs.-Comm scales for future models on future hardware. To avoid profiling numerous Transformer models across many setups, we extract execution regions and project costs using operator models. This allows a spectrum (hundreds) of future model/hardware scenarios to be accurately studied (< 15% error) and reduces profiling costs by 2100\u00d7. Our experiments show that communication will be a significant portion (40-75%) of runtime as models and hardware evolve. Moreover, communication that is often hidden by overlapped computation in today\u2019s models cannot be hidden in future, larger models. Overall, this work highlights communication\u2019s increasingly large role as models scale, discusses promising techniques to potentially tackle communication, and discusses how our analysis influences their potential improvements.", "venue": "IEEE International Symposium on Workload Characterization", "year": 2023, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work comprehensively analyzes compute vs. communication (Comp-vs.-Comm) scaling for future Transformer models on future hardware, across multiple axes, and shows that communication will be a significant portion of runtime as models and hardware evolve."}, "embedding": {"model": "specter_v2", "vector": [0.31024911999702454, 0.1141032949090004, -0.3413064479827881, -0.10924725234508514, -0.7799192070960999, 0.11969800293445587, 0.49297550320625305, 0.20418500900268555, -0.7638062238693237, -0.4086175858974457, 0.09570051729679108, -0.44332924485206604, 0.06682351231575012, -0.0039627449586987495, -0.2814769148826599, 0.19865553081035614, -1.0999211072921753, 0.469316691160202, -0.01915714330971241, 0.0653076246380806, -0.07866053283214569, 0.28266641497612, -1.3488727807998657, 0.19736787676811218, 0.28352198004722595, 0.9389828443527222, -0.2725352346897125, 1.28775954246521, -0.021128345280885696, 0.2443515956401825, 0.20331966876983643, 0.043981440365314484, 0.23443366587162018, 0.22493067383766174, -0.2555195391178131, -0.22081220149993896, 0.43112248182296753, -0.4410213232040405, -0.599187433719635, 0.5298550128936768, 0.3142927289009094, 0.20738209784030914, -0.1463366001844406, -1.1808310747146606, 0.14025291800498962, 0.42567893862724304, 0.27623826265335083, 0.8166899085044861, -0.4477900266647339, -0.4185417592525482, 0.8210151195526123, -1.2114711999893188, 0.013871151022613049, 1.215505838394165, 0.9816890358924866, -0.34283220767974854, -0.5449256896972656, -0.3111516833305359, 0.1016794815659523, -0.17757001519203186, -0.9093332886695862, -0.6528176069259644, -0.3202458918094635, -0.06925013661384583, 1.5010579824447632, -0.40204569697380066, -0.01825730688869953, -0.08812027424573898, 0.006459372118115425, 1.2114754915237427, 0.26791560649871826, -0.9106425642967224, 0.36674582958221436, 0.15585583448410034, 0.5184572339057922, 0.5314576029777527, -0.08066975325345993, 0.22486451268196106, -1.4343360662460327, -0.7837761640548706, 0.12141726911067963, 0.09187797456979752, 0.2816283404827118, -0.5866749882698059, -0.016188986599445343, 0.6223713159561157, -0.03800266981124878, 0.3548838198184967, -0.27066609263420105, 1.3382171392440796, 0.6274434924125671, 0.28905901312828064, 0.5433904528617859, 0.05938713997602463, -0.180573508143425, -0.18461298942565918, -1.4126489162445068, -0.13590840995311737, 0.5962668657302856, 0.8888316750526428, -0.2763304114341736, 0.014721603132784367, -0.3624751567840576, -0.11122660338878632, 0.9986278414726257, 0.23466520011425018, 0.19971667230129242, -0.6185898184776306, 0.2782694101333618, -0.924299955368042, -0.13997597992420197, -0.3962636888027191, -0.18168359994888306, -0.6837087273597717, -0.7753965258598328, -0.9290726780891418, -0.6665534377098083, -0.3770727813243866, -0.7682058811187744, -0.04598117992281914, -0.3224254250526428, 0.923143744468689, 0.16347312927246094, 0.2995149791240692, 0.009356680326163769, 0.5571643710136414, -0.22517040371894836, 0.382607638835907, 0.6615572571754456, -0.8079461455345154, -0.014950389973819256, -1.0492193698883057, 0.7533279061317444, -0.6024969816207886, -0.1432574987411499, -0.08721306174993515, -1.9052287340164185, -0.8109328746795654, -1.0195542573928833, 0.570888102054596, -0.34900370240211487, 0.1291511505842209, 1.5527422428131104, 0.4022371172904968, -1.312597632408142, 1.0830280780792236, -1.0039057731628418, -0.18837518990039825, 0.5456297397613525, 0.47925400733947754, 0.46888551115989685, -0.49984216690063477, -0.4936348795890808, -0.0597851499915123, -0.005060035269707441, -0.7742536664009094, -0.012336320243775845, -0.5646346211433411, -0.5768410563468933, 0.3388032913208008, -0.21456272900104523, -0.5309099555015564, 1.2330986261367798, 0.417322039604187, -0.7541388273239136, 0.54662024974823, -0.17968818545341492, -0.1707066148519516, 0.44493573904037476, 0.243037149310112, -0.653484582901001, -0.29006126523017883, -0.2184029370546341, 0.29717251658439636, 0.4213831126689911, -0.23896941542625427, -0.21774961054325104, -0.20404642820358276, -0.30234596133232117, 0.053646884858608246, -0.2768537700176239, 0.5704326033592224, -0.5870728492736816, 0.09068118035793304, 0.6720669269561768, 0.29074224829673767, -0.6501644849777222, 0.06578157842159271, 0.019130658358335495, -0.5544850826263428, 0.8911890387535095, 0.32026559114456177, 0.5697264671325684, -1.0377373695373535, -0.8087008595466614, 0.3930966556072235, 0.16950958967208862, -0.34649837017059326, -0.47015324234962463, 0.6384487152099609, -0.2969738841056824, 0.12827306985855103, -0.208969384431839, -0.9552653431892395, 0.14654459059238434, -0.32291531562805176, -0.622079610824585, -0.07510477304458618, -0.2523672878742218, 0.7295898199081421, -0.2058429718017578, 0.3542129099369049, -0.41553640365600586, 0.17954273521900177, -1.009338617324829, 1.136704683303833, -0.4731450080871582, -0.011533082462847233, 0.25745710730552673, -0.11576762795448303, 0.814353346824646, -0.8950973153114319, 0.9669241309165955, -0.11500026285648346, 0.14742544293403625, 0.3821823298931122, -0.7271820306777954, 1.4601837396621704, -0.5238982439041138, 0.25130024552345276, 0.636847198009491, -0.7293453812599182, -0.07723738998174667, 0.230031818151474, 0.08138293772935867, -0.39496171474456787, 0.40333664417266846, 0.63117516040802, -0.34139037132263184, 0.5870575308799744, 1.0507001876831055, 0.9529474377632141, -0.19926854968070984, 0.7031781077384949, 0.46409323811531067, -0.4637884795665741, 0.24250443279743195, 0.3810059130191803, 0.5698344707489014, 0.28753966093063354, -0.3257451355457306, -0.11969204992055893, -0.20272411406040192, -0.9660871624946594, -0.4429071247577667, 0.6599962711334229, 0.5222257375717163, 0.08181659877300262, 0.5056938529014587, -0.5655335187911987, -0.7377901077270508, 0.10646148771047592, 0.3297218382358551, 1.5525283813476562, -0.1703869253396988, -0.018938632681965828, -0.5421028733253479, -0.18053820729255676, 0.2019784152507782, -0.18244722485542297, 0.18422015011310577, -0.04342671111226082, -0.5997573137283325, -1.2337490320205688, 0.6546736359596252, 0.5384995341300964, 0.5236136317253113, 0.08280044049024582, -0.5581402778625488, -0.807880163192749, 1.04747474193573, -0.9384181499481201, 0.04910827428102493, 0.6624797582626343, -0.8089116811752319, 0.05597982928156853, -0.008978590369224548, -0.09752126783132553, 0.055843647569417953, -0.31596657633781433, 0.7863495349884033, 0.16165396571159363, -0.40357500314712524, 0.3691881597042084, 0.8728058338165283, -0.8484925031661987, -0.6256686449050903, 0.20742972195148468, 0.1825750768184662, -0.48775774240493774, 0.0558679923415184, -0.045551273971796036, -0.0535338930785656, -0.46271219849586487, -0.29213616251945496, 0.1116810292005539, 0.18224431574344635, -0.2752206325531006, 0.37768176198005676, -0.27421730756759644, -0.40883511304855347, -1.1863458156585693, 1.1114096641540527, -0.25270307064056396, -0.6533909440040588, 0.255191832780838, -0.8203200101852417, -0.09808753430843353, 0.34364715218544006, -0.6556243896484375, 0.28498804569244385, -1.0318140983581543, 0.20508335530757904, -0.6306886672973633, -0.07212145626544952, 0.010242667980492115, 0.9336535930633545, -0.3585608899593353, 0.16255873441696167, 0.4845206141471863, 0.6263391971588135, -0.08942542225122452, 0.5327039361000061, -0.964494526386261, 0.03962390497326851, -0.3057459890842438, 0.1599990725517273, 0.026549207046628, 0.31930485367774963, -0.5415961146354675, 0.009315866976976395, -0.11963226646184921, -0.13026057183742523, 0.01775757223367691, -0.032182469964027405, -0.4846261143684387, -1.0872341394424438, -0.22561310231685638, -1.0734286308288574, -0.3267579674720764, 0.3710324764251709, 0.08832801133394241, -0.12498854845762253, -1.0497550964355469, -1.5354790687561035, -0.4705215394496918, -0.7868886590003967, -1.3990658521652222, 0.604653537273407, -0.060500435531139374, -0.1316748857498169, -0.3930855691432953, -0.32224351167678833, -0.5223979353904724, 1.3788743019104004, -0.8829447031021118, 0.724904477596283, -0.15350504219532013, -0.6384517550468445, -0.1993337720632553, -0.3070802390575409, 0.02568836510181427, -1.1453479528427124, 0.07409660518169403, -1.0519871711730957, -0.2753533124923706, -0.4603523910045624, -0.7194050550460815, 0.19076721370220184, 0.25507551431655884, 1.124911904335022, 0.1699240356683731, -0.8000875115394592, 0.7082954049110413, 1.3660887479782104, -0.5885950922966003, -0.023322787135839462, -0.3098352551460266, 0.8337512612342834, -0.30559268593788147, -0.36789438128471375, 0.8041419982910156, -0.1347014605998993, 0.2922159731388092, -0.09533557295799255, -0.3201459050178528, -0.033060938119888306, 0.0005558650591410697, 0.10372442752122879, 1.7345386743545532, 0.5970878005027771, -0.04511377587914467, -1.000085711479187, 0.132022887468338, -1.2149982452392578, -0.23093320429325104, 0.7470481395721436, 0.9013825058937073, -0.049830880016088486, -0.17223814129829407, -0.45536303520202637, -0.24985714256763458, 0.1391264647245407, 0.5291203260421753, -0.597866952419281, -0.5891442894935608, 0.4294458031654358, 1.082227110862732, 0.7902347445487976, 0.43099719285964966, 0.07637005299329758, 0.3209337592124939, 14.918373107910156, 1.3825063705444336, -0.1193481832742691, 0.7516305446624756, 0.7454085350036621, 0.36433446407318115, -0.2416594922542572, 0.22339056432247162, -1.0481822490692139, 0.08045116066932678, 1.8814915418624878, -0.027967676520347595, 0.60757976770401, 0.5445987582206726, -0.4913405179977417, -0.28221431374549866, -0.4955345392227173, 0.9460130333900452, 0.4901191294193268, -1.7745527029037476, 0.07207870483398438, 0.34555864334106445, 0.4483150839805603, 0.9609679579734802, 0.596106767654419, 0.4837740659713745, 0.7280837297439575, -0.5971887111663818, 0.27048251032829285, 0.3229678273200989, 1.468701720237732, -0.43971148133277893, 0.6390590071678162, 0.5802469849586487, -0.9548900723457336, 0.20287656784057617, -0.25319257378578186, -1.1397610902786255, 0.017313741147518158, 0.14666374027729034, -0.9103164076805115, -0.38067954778671265, -0.37530678510665894, 0.2270401269197464, 0.07154271751642227, 0.4232569932937622, 0.5688751339912415, 0.46914172172546387, -0.5062293410301208, 0.057936277240514755, -0.3873005509376526, 0.522904634475708, -0.5234747529029846, -0.21759340167045593, 0.19233641028404236, -0.49744200706481934, 0.5225229859352112, -0.00765158561989665, -0.910918116569519, -0.3575424551963806, -0.3429873585700989, -0.22414883971214294, 0.24058005213737488, 0.6143816113471985, 0.06815482676029205, -0.029186204075813293, -0.2476971447467804, 0.7283965349197388, 0.6919910311698914, 0.009848800487816334, -0.24948255717754364, 0.20645484328269958, 0.3125811517238617, -0.5523219704627991, -0.29179704189300537, 0.2598174214363098, -0.4935724437236786, -0.5625673532485962, -0.7184566855430603, -0.5947261452674866, 0.28064364194869995, -0.5104451179504395, -0.5029821395874023, 0.5769534707069397, -0.5052087306976318, -0.24083206057548523, 0.5374730229377747, -0.7764121890068054, -0.06978735327720642, 0.5652521252632141, -1.2991524934768677, -0.41577962040901184, 0.3027375042438507, -0.5424253344535828, -0.6953614354133606, 0.16751496493816376, 1.4748643636703491, 0.3353096842765808, -0.013686086982488632, -0.006165655329823494, 0.5429427027702332, -0.25195518136024475, -0.15527985990047455, -0.55539870262146, 1.273621916770935, 0.29687315225601196, 0.09076955914497375, 0.14806067943572998, -0.371814101934433, 0.2509359121322632, -1.16411292552948, 0.12859010696411133, 0.30492743849754333, -0.7108206748962402, 0.0918232873082161, -0.7099788188934326, -0.3049669563770294, 0.6610423922538757, 0.26025325059890747, 0.12689515948295593, 0.4877934157848358, 0.15040521323680878, -0.4601670801639557, -0.11095406860113144, -0.5092188715934753, 0.03050055354833603, 0.5727794766426086, -1.128474473953247, 0.2090560644865036, 0.24813894927501678, 0.4892916679382324, -1.301408290863037, -0.8765560388565063, 0.06568168103694916, 0.02057824656367302, -0.3367438316345215, 0.9181708097457886, -0.07747157663106918, 0.5823603272438049, 1.1386282444000244, -0.35370615124702454, -0.3441527783870697, 0.6060603857040405, -0.8119477033615112, -0.23573872447013855, -0.32748574018478394, 0.5261875987052917, -0.38124945759773254, 0.9701327085494995, 0.8739398717880249, 0.4049047529697418, -0.49196857213974, -0.290977418422699, 0.08293064683675766, -0.2791012227535248, -0.8715741634368896, 0.4851718544960022, 0.25324851274490356, -0.20750896632671356, 0.15645362436771393, 0.36268365383148193, 0.8243253231048584, 0.13369451463222504, -0.3217529058456421, 0.7539957761764526, -0.20651791989803314, -0.7590339183807373, -0.3386904299259186, -0.5235905051231384, -1.372302532196045, -0.2713954746723175, -1.4030171632766724, -0.24757152795791626, -0.4778737723827362, -0.40890949964523315, -0.6311392188072205, 0.01975332759320736, -0.4389117360115051, 0.6652133464813232, -0.12512315809726715, -0.2705109417438507, -0.5975273251533508, -0.7343544363975525, 0.7363232374191284, 0.4695058763027191, -0.02923654392361641, 0.24041399359703064, -0.1641484498977661, 0.46289825439453125, 0.7094077467918396, 0.4361593723297119, -0.38648736476898193, -0.6355602741241455, -1.3255727291107178, 0.3530585467815399, 0.5771536231040955, -0.20987798273563385, -1.2789095640182495, 1.0048236846923828, 0.2845701575279236, -0.005350102670490742, -0.022727400064468384, 0.5840359926223755, -1.1101346015930176, -0.39171987771987915, 0.5920490026473999, -0.5576552152633667, 0.4838598072528839, 0.5002549886703491, -0.4423220455646515, 0.2914629876613617, 0.8189782500267029, -0.011813098564743996, -0.5322487950325012, -0.6072592735290527, 0.46120792627334595, -0.01613595522940159, 0.06881400942802429, -0.05435929447412491, 0.20070800185203552, -1.336018681526184, -0.18110404908657074, -0.29959213733673096, 0.26217520236968994, 0.01699298806488514, 0.365581750869751, 0.1663454920053482, -0.5755817890167236, 0.34041523933410645, 0.568277895450592, -0.3376149535179138, -0.08118846267461777, 0.6999103426933289, 0.5621204376220703, -0.9759198427200317, 0.048239048570394516, 0.22167614102363586, 0.05344687029719353, -1.0289040803909302, -0.184192955493927, 0.3751431405544281, -0.5310186743736267, -0.18622282147407532, 1.3860819339752197, -0.9213457107543945, -1.1528183221817017, 0.28769636154174805, -0.7243746519088745, 0.22309589385986328, -0.3951047360897064, 0.19289925694465637, 0.3943190574645996, 0.1512320190668106, 0.591702401638031, -0.4872199594974518, 0.10542616248130798, 0.07706421613693237, -0.5923751592636108, 0.5288666486740112, 0.13605475425720215, -0.7050196528434753, 0.5663937926292419, 0.7547725439071655, -0.2358671873807907, -0.5973070859909058, -0.9365409016609192, -0.23001904785633087, -0.07109935581684113, 0.32139185070991516, -0.173042893409729, -0.49117743968963623, 1.0177600383758545, 0.7429202198982239, 0.15311311185359955, -0.19283200800418854, -0.06168709322810173, 0.7227048277854919, 0.3175520896911621, 0.7004883289337158, -0.49090877175331116, -0.7137373089790344, 0.9028627872467041, 0.5344491004943848, -0.49060893058776855, 0.8115531206130981, -0.3646814823150635, -0.30749043822288513, 0.7558587789535522, 0.506650984287262, -0.08254272490739822, 1.0606718063354492, 0.5456694960594177, -0.16010470688343048, -0.09624035656452179, -0.8922734260559082, -0.044885553419589996, 0.647030234336853, 0.41429299116134644, 0.4090785086154938, 0.568157434463501, 0.06753432750701904, 0.5093875527381897, -0.007354402914643288, 0.3751216232776642, 0.2408769726753235, 1.0662356615066528, -0.03226267173886299, -0.11200420558452606, -0.29731637239456177, 0.8177050948143005, -0.6424229145050049, -0.8403132557868958, 0.37881001830101013, 0.49247831106185913, 0.13463187217712402, 0.4464012086391449, 1.130772352218628, -0.06595797091722488, 0.18732395768165588, 0.020018422976136208, 0.6429584622383118, -0.33578744530677795, -0.1546839028596878, -0.13552610576152802, -0.40287914872169495, -0.03067682683467865, 0.005408417899161577, 0.1540878266096115, -0.7369875907897949, -1.1934555768966675, 0.4769105911254883, 0.337287962436676, 0.6018062829971313, 0.8538569808006287, 1.1856558322906494, 0.8764093518257141, -0.24844105541706085, -1.1110714673995972, -0.7310214042663574, -0.5765711665153503, -0.23139792680740356, -0.5835728645324707, -0.5178842544555664, 0.5790336728096008, -0.09296928346157074, -0.600949764251709]}, "authors": [{"authorId": "31783708", "name": "Suchita Pati"}, {"authorId": "1898809", "name": "Shaizeen Aga"}, {"authorId": "38862020", "name": "Mahzabeen Islam"}, {"authorId": "2012110", "name": "N. Jayasena"}, {"authorId": "2261954751", "name": "Matthew D. Sinclair"}], "references": [{"paperId": "e11a32f1b939df968ca8741e8ef336eff6efcf31", "title": "AMPeD: An Analytical Model for Performance in Distributed Training of Transformers"}, {"paperId": "74e3ce19755b1d812573d42dac54c08d3f972b9f", "title": "In-Network Aggregation with Transport Transparency for Distributed Training"}, {"paperId": "58d6ec0dec4952e93be7cf72c1cebb0216eac9df", "title": "Mobius: Fine Tuning Large-Scale Models on Commodity GPU Servers"}, {"paperId": "3e9e607210e278d33f5b32b340bb5eb7482dfef5", "title": "MSCCLang: Microsoft Collective Communication Language"}, {"paperId": "3692f4df9d11af68f9b9c9a526667db3f99e552c", "title": "Overlap Communication with Dependent Computation via Decomposition in Large Deep Learning Models"}, {"paperId": "a4d45c1f04822fe24a6ddd3f9018bd701e5a7933", "title": "Demystifying BERT: System Design Implications"}, {"paperId": "b37d57edf4a84da158ab8d77921d4aa39faceb32", "title": "FP8 Formats for Deep Learning"}, {"paperId": "5922f437512158970c417f4413bface021df5f78", "title": "A Generalist Agent"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "7d1e512888a2fa4e838c12a02ae7fce867d322a8", "title": "DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale"}, {"paperId": "d52977458284acce166bb1291a9d79143aa59070", "title": "Scalable and Efficient MoE Training for Multitask Multilingual Models"}, {"paperId": "91b29761840442005da39bc258e2298b528f31aa", "title": "Breaking the computation and communication abstraction barrier in distributed machine learning workloads"}, {"paperId": "72dd63d67588a42fc817bbb8d655b397f67425df", "title": "ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep learning"}, {"paperId": "04e283adccf66742130bde4a4dedcda8f549dd7e", "title": "A Survey of Quantization Methods for Efficient Neural Network Inference"}, {"paperId": "4a9587ad4ed8f755e74524499452ea12bd6c7f3b", "title": "Optimizing Inference Performance of Transformers on CPUs"}, {"paperId": "12b71736392209b4292471b7da0aed71ba2aa545", "title": "ZeRO-Offload: Democratizing Billion-Scale Model Training"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "1aa219b2069de522081980d2d9d764958197e545", "title": "Pushing the Limits of Narrow Precision Inferencing at Cloud Scale with Microsoft Floating Point"}, {"paperId": "e3e846aae8a3f624b5e9caa961cbf9b63e9c1a83", "title": "Demystifying the MLPerf Training Benchmark Suite"}, {"paperId": "7dbf8227b4f1758772975055c707f57f13d445b1", "title": "SeqPoint: Identifying Representative Iterations of Sequence-Based Neural Networks"}, {"paperId": "9818a38ce8cf1cf8787a3364a302474da542d856", "title": "Enabling Compute-Communication Overlap in Distributed Deep Learning Training Platforms"}, {"paperId": "1882f194cb43828852cc052887671e55a80f945a", "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "bc38cabbacca40a4590d7723a7a8f209979c14c1", "title": "An In-Network Architecture for Accelerating Shared-Memory Multiprocessor Collectives"}, {"paperId": "5e4a0a095b1c7e993279afd7e9a7652984c023a9", "title": "SnackNoC: Processing in the Communication Layer"}, {"paperId": "7b7474578b760bebdafa45bb657dc93f6f2f88c8", "title": "DeepRecSys: A System for Optimizing End-To-End At-Scale Neural Recommendation Inference"}, {"paperId": "594a89505eb803280628198920e87cfc2bb82d94", "title": "MLPerf Inference Benchmark"}, {"paperId": "cc8871b27970b9f4e596c9e334abb6d7e38e3010", "title": "Deep Learning Language Modeling Workloads: Where Time Goes on Graphics Processors"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "d8e73f9034e16a380903282353e762d7f9517983", "title": "MLPerf Training Benchmark"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "80f9f109d1564cb8f82aa440a5f6f3fbe220c9ef", "title": "ERNIE 2.0: A Continual Pre-training Framework for Language Understanding"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "611e0bd5d466668989df04d642104428d03eaeb6", "title": "Deep Learning Inference in Facebook Data Centers: Characterization, Performance Optimizations and Hardware Implications"}, {"paperId": "d79a26226393f687ddbc375e32055b40b8ad8d38", "title": "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism"}, {"paperId": "da0a49ca309f1e38f8e40a6baa63a16119be182e", "title": "EcoRNN: Efficient Computing of LSTM RNN Training on GPUs"}, {"paperId": "801aed0fcb0485ce262a99be06c6ef96a161a663", "title": "The Architectural Implications of Autonomous Driving: Constraints and Acceleration"}, {"paperId": "9aa3522c2a01d896f39857b572dd28281635c80a", "title": "TBD: Benchmarking and Analyzing Deep Neural Network Training"}, {"paperId": "fc1d981dd051063ae586a56b05390fe3ea82f040", "title": "Achieving Human Parity on Automatic Chinese to English News Translation"}, {"paperId": "5a7f3f0fdbdc29fddc7a41098ee8bbc3f7cfd1a1", "title": "Toward Human Parity in Conversational Speech Recognition"}, {"paperId": "f416305fa363b99fcc1bb37ce7f5a0f487a65c32", "title": "Data Stream Processing in Networks-on-Chip"}, {"paperId": "ecc156bc51d6f3199f5dc5d3de1daeb0a79f2fef", "title": "Modular array-based GPU computing in a dynamically-typed language"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "c0c352b314e0d972e7eabd35e435789791d407cc", "title": "Scalable Hierarchical Aggregation Protocol (SHArP): A Hardware Architecture for Efficient Data Reduction"}, {"paperId": "5e5da2a57395b0ca6888f1bbd7de5d27e33b5a81", "title": "KLAP: Kernel launch aggregation and promotion for optimizing dynamic parallelism"}, {"paperId": "a4fb215dc03f5a2ff0e394ce9b68e493bd811f0d", "title": "Fathom: reference workloads for modern deep learning methods"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327", "title": "Going deeper with convolutions"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "5e83ab70d0cbc003471e87ec306d27d9c80ecb16", "title": "Network In Network"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "1e1d681092bc4af8cdda05233e2f670d654e3888", "title": "Automatic fusions of CUDA-GPU kernels for parallel map"}, {"paperId": "6757659aeba247db2a35691ee3b4c029e1a2dcf4", "title": "Kernel Fusion: An Effective Method for Better Power Efficiency on Multithreaded GPU"}, {"paperId": null, "title": "Distributed Services Card (DSC)"}, {"paperId": null, "title": "NVIDIA Announces DGX GH200 AI Supercomputer"}, {"paperId": null, "title": "Gddr-pim"}, {"paperId": null, "title": "State of ai report 2022"}, {"paperId": null, "title": "GPU with HBM PIM"}, {"paperId": null, "title": "Context is Everything: Why Maximum Sequence Length Matters"}, {"paperId": null, "title": "Genomics in Unparalleled Resolution: Cerebras Wafer-Scale Cluster Trains Large Language Models on the Full COVID Genome Sequence"}, {"paperId": null, "title": "NVIDIA A100 TENSOR CORE GPU"}, {"paperId": null, "title": "NVIDIA FasterTransformer"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "AMD ROCm Profiler"}, {"paperId": null, "title": "ROCm, a New Era in Open GPU Computing"}, {"paperId": null, "title": "AMD&#x2019;s BLAS Library"}, {"paperId": null, "title": "NVIDIA TESLA V100 GPU ACCELERATOR"}, {"paperId": null, "title": "\u201cAMD INSTINCT\u2122 MI50 ACCELERATOR,\u201d"}, {"paperId": null, "title": "AMD&#x2019;s ROCm Communication Collectives Library"}, {"paperId": null, "title": "Baidu all-reduce"}]}