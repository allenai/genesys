{"paperId": "1ec3a3ff77cb4b424499b3805ecc90182ecd8f8b", "abstract": "Large language models exhibit surprising emergent generalization properties, yet also struggle on many simple reasoning tasks such as arithmetic and parity. This raises the question of if and when Transformer models can learn the true algorithm for solving a task. We study the scope of Transformers' abilities in the specific setting of length generalization on algorithmic tasks. Here, we propose a unifying framework to understand when and how Transformers can exhibit strong length generalization on a given task. Specifically, we leverage RASP (Weiss et al., 2021) -- a programming language designed for the computational model of a Transformer -- and introduce the RASP-Generalization Conjecture: Transformers tend to length generalize on a task if the task can be solved by a short RASP program which works for all input lengths. This simple conjecture remarkably captures most known instances of length generalization on algorithmic tasks. Moreover, we leverage our insights to drastically improve generalization performance on traditionally hard tasks (such as parity and addition). On the theoretical side, we give a simple example where the\"min-degree-interpolator\"model of learning from Abbe et al. (2023) does not correctly predict Transformers' out-of-distribution behavior, but our conjecture does. Overall, our work provides a novel perspective on the mechanisms of compositional generalization and the algorithmic capabilities of Transformers.", "venue": "arXiv.org", "year": 2023, "citationCount": 46, "influentialCitationCount": 8, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes a unifying framework to understand when and how Transformers can exhibit strong length generalization on a given task and provides a novel perspective on the mechanisms of compositional generalization and the algorithmic capabilities of Transformers."}, "embedding": {"model": "specter_v2", "vector": [0.4509476125240326, 0.7531298398971558, -0.3033279478549957, 0.01695316843688488, -0.36588412523269653, -0.6691832542419434, 0.5598098635673523, 0.0362800695002079, 0.00828997790813446, -0.016162337735295296, 0.05538071691989899, -0.31091970205307007, 0.04319266229867935, -0.25727421045303345, -0.3119828999042511, 0.129775270819664, -0.7753403782844543, 0.4101162254810333, 0.028942851349711418, -0.322549432516098, 0.02229336090385914, -0.15375754237174988, -1.2469321489334106, 0.18219426274299622, 0.6497785449028015, 0.7169857025146484, -0.3270467519760132, 0.6069839000701904, -0.581508219242096, 0.5032542943954468, 0.41335830092430115, -0.6387407779693604, 0.534101128578186, 0.09246309846639633, -0.5693469643592834, -0.3578464090824127, 0.5964173078536987, -0.10736957937479019, -0.608259916305542, 0.6977301836013794, -0.5946558117866516, 0.3417545557022095, 0.31210678815841675, -0.9722902774810791, -0.4728916585445404, 1.1968375444412231, 0.6782581210136414, 0.4633036255836487, -0.050873588770627975, -0.21180590987205505, 1.63260817527771, -0.8544880151748657, 0.14332345128059387, 0.9763157963752747, 0.7554353475570679, 0.5747967958450317, -0.30742761492729187, -0.7253164052963257, -0.016043784096837044, -0.08885280787944794, -0.9852192401885986, -0.08256734162569046, -0.38376834988594055, -0.0550529770553112, 1.3937888145446777, -0.5318855047225952, -0.3167180120944977, -0.33665183186531067, -0.1570458710193634, 1.4904059171676636, 0.38775715231895447, -0.3601677119731903, -0.1847447007894516, -0.19439080357551575, 0.322644978761673, 0.7027551531791687, -0.2494535744190216, 0.12671537697315216, -1.1864961385726929, 0.02463090419769287, 0.16564351320266724, 0.0062867444939911366, -0.23432403802871704, -0.3338804543018341, -0.28568825125694275, 0.27715393900871277, 0.47864142060279846, 0.6518079042434692, -0.22026965022087097, 0.9687201976776123, 0.761859118938446, 0.7777989506721497, -0.09316153824329376, 0.7816155552864075, -0.38515347242355347, 0.3753657937049866, -0.9253149032592773, 0.47950392961502075, -0.1939723640680313, 0.9250797033309937, 0.052910346537828445, 0.5569692254066467, -0.2559176981449127, 0.006795019842684269, 0.6656280755996704, -0.018107697367668152, 0.46164774894714355, -0.7907163500785828, 0.0611305832862854, -0.0033408752642571926, 0.022257843986153603, 0.01634308695793152, -0.32980403304100037, -0.4036712348461151, -0.8664655685424805, -0.8518454432487488, -0.1802758127450943, 0.49745386838912964, -0.4786814749240875, 0.9409352540969849, -0.6270020604133606, -0.118517205119133, -0.09298984706401825, 0.3503698408603668, 0.28977397084236145, 0.5997356176376343, 0.2181137502193451, -0.053513482213020325, 0.7873775959014893, -0.2117495834827423, -0.22508984804153442, -0.6444655060768127, 0.9780254364013672, -0.24949230253696442, 0.5066336989402771, 0.37996530532836914, -1.6398483514785767, -1.0192512273788452, -0.8347489237785339, 0.21609507501125336, -0.5383260250091553, -0.04320543631911278, 0.9400015473365784, 0.9033870100975037, -1.0220935344696045, 0.6611959934234619, -0.2522840201854706, -0.28088849782943726, 0.38259586691856384, 0.400002658367157, 0.1789468228816986, -0.45403894782066345, -0.8786584138870239, 0.28293853998184204, 0.7094055414199829, -0.9076887965202332, -0.5652422308921814, -1.070887804031372, -1.0343313217163086, 0.2992936670780182, 0.35554036498069763, -0.6139746904373169, 1.3094390630722046, -0.06821857392787933, -0.6415644288063049, 0.9343217611312866, -0.09699828177690506, -0.14414924383163452, 0.3301483988761902, 0.14018315076828003, -0.17335520684719086, -0.6588898301124573, -0.19461689889431, 0.28823691606521606, 0.0008864380070008337, -0.36917367577552795, -0.4770285487174988, 0.14126189053058624, -0.0036203376948833466, -0.5568093657493591, -0.12368607521057129, 0.598172128200531, 0.5911962389945984, -0.3078365921974182, 0.5234528183937073, 0.4231965243816376, -0.08544663339853287, -0.09975267201662064, -0.0012851194478571415, -1.400856614112854, 0.41103070974349976, 0.09550958126783371, 1.1147570610046387, -0.9193693995475769, -0.35743939876556396, -0.2314010113477707, 0.17617905139923096, -0.39797013998031616, -0.3559710681438446, 0.559671938419342, -0.5608860850334167, 0.9904146790504456, -0.779159665107727, -0.620786190032959, 0.3093017637729645, -0.1036304160952568, -0.8893393874168396, -0.1102466732263565, -0.1783866286277771, 0.9458673000335693, -0.6026580333709717, 0.774504542350769, -0.18412521481513977, -0.32324451208114624, -0.8211724162101746, 1.2776895761489868, -0.8055707216262817, -0.04275405406951904, 0.36112692952156067, -0.13095694780349731, 0.43905749917030334, -0.6037129759788513, 0.05550755560398102, -0.22108010947704315, -0.10308260470628738, 0.6850048303604126, -0.42748263478279114, 1.5555559396743774, -0.2579330503940582, 0.2742856740951538, -0.153252974152565, -1.179578423500061, 0.2979685962200165, 0.35642266273498535, -0.30772650241851807, -0.20432491600513458, 0.044261980801820755, 0.6869331002235413, -0.25173014402389526, 0.02837117575109005, 0.6045209169387817, 0.6062323451042175, -0.7342406511306763, 0.6280279755592346, 0.2746982276439667, -0.706062376499176, 0.4331321120262146, 0.4620029628276825, 0.7128927111625671, 0.06477754563093185, 0.6673071384429932, -0.0036356037016958, 0.49117130041122437, -0.8989925980567932, -0.17106349766254425, 0.7712741494178772, 0.8836783766746521, 0.38103827834129333, 0.36133188009262085, -1.2081855535507202, -0.9968317747116089, -0.40173402428627014, 0.46607568860054016, 1.7957617044448853, -0.07323236763477325, -0.4985494017601013, -0.49103665351867676, -0.18023748695850372, -0.4405660927295685, 0.2527715265750885, -0.34222230315208435, -0.313927561044693, -0.6410672068595886, -0.8804402351379395, 1.1400574445724487, 0.4325925409793854, 1.1205183267593384, -0.6393407583236694, -0.3786003589630127, -0.6256838440895081, 0.5185050368309021, -0.799681544303894, -0.13340958952903748, 0.19827012717723846, -0.5030003786087036, -0.027482524514198303, 0.30252373218536377, -0.3902050852775574, 0.18135182559490204, -0.7806559205055237, 0.6742600798606873, -0.24934592843055725, -0.2323753982782364, 0.25696930289268494, 0.6548224091529846, -0.5231969952583313, -0.8552306294441223, 0.4837491810321808, 0.20054426789283752, -0.3524402976036072, 0.1015750989317894, 0.0915246456861496, 0.1506539285182953, -0.01346506830304861, -0.8424442410469055, -0.1829320192337036, 0.2535373568534851, 0.061422593891620636, 0.2749388813972473, 0.28007936477661133, 0.08146499842405319, -1.2208322286605835, 0.7625073790550232, 0.28172823786735535, -0.6466925740242004, 0.5964226126670837, -1.0691050291061401, 0.0925702229142189, 0.7238052487373352, -0.5912852883338928, 0.35299795866012573, -0.7432378530502319, 0.5210321545600891, -0.27050355076789856, -0.18060094118118286, 0.3107205927371979, 0.22067514061927795, -0.1570311039686203, 0.38050520420074463, 1.0805634260177612, 0.19108396768569946, 0.20687146484851837, 0.5035523176193237, -0.7570230960845947, 0.5070786476135254, -0.02301975153386593, 0.4997974634170532, -0.36680957674980164, 0.23917625844478607, -0.4076616168022156, -0.3895505964756012, 0.37481701374053955, 0.2937031686306, 0.045712780207395554, -0.13016316294670105, -0.48576620221138, -1.2470613718032837, 0.26417267322540283, -0.6979967355728149, -0.7421896457672119, -0.06786619871854782, -0.9336170554161072, -0.37688297033309937, -1.1190749406814575, -1.2856003046035767, -0.7090222239494324, -0.5853667855262756, -1.093664526939392, 0.26269111037254333, 0.2096060812473297, -0.5169799327850342, -0.17443062365055084, -0.5201175808906555, -0.3885151147842407, 0.9037584662437439, -0.6934950947761536, 0.9158029556274414, -0.505159854888916, -0.7254880666732788, 0.16916128993034363, 0.13091062009334564, 0.280425101518631, -0.48453235626220703, 0.13702014088630676, -0.7108854055404663, 0.17203842103481293, -0.6689785122871399, -0.7756125926971436, 0.047099415212869644, 0.2181110978126526, 1.2941124439239502, -0.43556755781173706, -0.16352351009845734, 0.3615995943546295, 1.1562083959579468, -0.5255680680274963, 0.44819119572639465, 0.3094269633293152, 0.9163084030151367, 0.2373354136943817, -0.4442466199398041, 0.5609371662139893, 0.42144641280174255, 0.2979777753353119, -0.036911576986312866, 0.48764240741729736, 0.06327654421329498, -0.42801791429519653, 0.4152492582798004, 0.9380370378494263, 0.19306141138076782, 0.12187886238098145, -1.0766324996948242, 0.4181291162967682, -0.8975493311882019, -0.8943322896957397, 0.6550776362419128, 1.3424692153930664, 0.4307398796081543, -0.011566379107534885, 0.13339358568191528, 0.4692866802215576, -0.025254828855395317, 0.05896587669849396, -0.13097287714481354, -0.745693564414978, -0.04937882348895073, 0.9552749991416931, 0.603839099407196, 0.33477330207824707, -0.05254564806818962, 0.5753458142280579, 15.151872634887695, 1.073261022567749, -0.09496450424194336, 0.5786691308021545, 0.5456511378288269, 0.6599647998809814, -0.7955215573310852, -0.062255121767520905, -0.8100795745849609, -0.09538860619068146, 0.8366365432739258, -0.21594439446926117, 0.8408240079879761, 0.12781403958797455, -0.41074562072753906, 0.48813971877098083, -0.8147411346435547, 0.7475261688232422, 0.24755731225013733, -1.3062673807144165, 0.6334391236305237, -0.02111951634287834, 0.6740817427635193, 0.026203656569123268, 0.96842360496521, 0.5984696745872498, 0.44920918345451355, -0.8035358786582947, 0.6930179595947266, -0.01307788584381342, 1.055616855621338, -0.029919061809778214, 0.13893809914588928, 0.5669230818748474, -1.1258453130722046, -0.44911566376686096, -0.3402446508407593, -1.170570969581604, -0.03554783761501312, 0.03200621157884598, -0.9322999119758606, -0.46410074830055237, -0.45585140585899353, 0.811539888381958, 0.48764169216156006, 0.6895363926887512, -0.6199355721473694, 0.7093371748924255, -0.1182614117860794, 0.2621375322341919, -0.220709428191185, 0.770524799823761, -0.08682466298341751, -0.44957754015922546, 0.4021134674549103, -0.05629143491387367, 0.5967305302619934, 0.43386682868003845, -0.9278209209442139, -0.053556252270936966, -0.13373953104019165, -0.3109475076198578, 0.4473426938056946, 0.44285520911216736, 0.4675435423851013, -0.05450475215911865, 0.17860564589500427, -0.01734074577689171, 0.17935891449451447, 0.12325166165828705, 0.10715547949075699, -0.25728097558021545, 0.38337090611457825, -0.08336461335420609, -0.40605437755584717, 0.6567021608352661, -1.1982630491256714, -0.27884814143180847, -0.6461323499679565, -1.1485897302627563, 0.7213976979255676, -0.8771142959594727, -0.7179727554321289, 0.3311927020549774, -0.5335150361061096, -0.39651429653167725, 0.8144908547401428, -0.5766820311546326, -0.08577511459589005, 0.27546048164367676, -1.0191184282302856, -1.1563423871994019, 0.0358891524374485, -0.2367435246706009, 0.10957103222608566, -0.10168827325105667, 0.9474152326583862, -0.33819296956062317, 0.16608929634094238, 0.5293883681297302, -0.45877137780189514, -0.13308557868003845, -0.11051423847675323, -1.1324785947799683, 0.6188170313835144, 0.2232619822025299, -0.14278386533260345, 0.40747395157814026, 0.21147862076759338, 0.38900306820869446, -0.5715800523757935, 0.14846011996269226, 0.6539097428321838, -1.0442228317260742, 0.017649108543992043, -0.40175914764404297, -1.0798207521438599, 0.8597811460494995, 0.03343391418457031, -0.5193082690238953, 0.11766161024570465, -0.029143700376152992, -1.1036291122436523, -0.3594273328781128, -0.6662262678146362, -0.02676358073949814, 0.8193867802619934, -1.0868923664093018, -0.6399657726287842, -0.2900713384151459, 0.40684613585472107, -1.060935616493225, -0.7918605804443359, 0.285339891910553, 0.468686580657959, -8.486084698233753e-05, 0.9013593196868896, -0.3970049023628235, 0.9785742163658142, 0.47700220346450806, 0.19175586104393005, -0.30741557478904724, 0.0022864011116325855, -1.1125171184539795, 0.316422700881958, -0.0025102910585701466, 0.7287124991416931, -0.7644572854042053, 0.25155407190322876, 0.5999148488044739, -0.2967916429042816, -0.19110755622386932, -0.4350029528141022, -0.05806406959891319, 0.2890244126319885, -0.5440940856933594, 0.6759769320487976, 0.29219794273376465, 0.0594802089035511, -0.2066033035516739, 0.3720420300960541, 1.052497148513794, -0.20635737478733063, -0.4033195972442627, 0.5620672702789307, -0.4066362977027893, -0.10622625052928925, -1.2659269571304321, -0.6807389259338379, -1.4158928394317627, 0.07378697395324707, -1.3160325288772583, 0.0190080925822258, -0.8012227416038513, -0.4937345087528229, -0.2640509009361267, -0.10899487137794495, 0.150551900267601, 0.4908573031425476, -0.5258842706680298, -0.895158588886261, -0.33158352971076965, -0.4899251461029053, 0.47622838616371155, 0.387296199798584, -0.8031121492385864, 0.19308443367481232, 0.025627994909882545, 0.08458441495895386, 0.07514854520559311, 0.5326468348503113, -0.6580681800842285, -0.8338845372200012, -0.9280336499214172, 0.8673986196517944, -0.12550665438175201, -0.44019636511802673, -0.7707982063293457, 0.6863601207733154, 0.20681792497634888, -0.35172349214553833, 0.29489174485206604, 0.07856184244155884, -0.7347592115402222, -0.2514701783657074, 0.6337583065032959, -1.3577618598937988, 0.5649672150611877, 0.12274862080812454, -0.8180776834487915, 0.3660701811313629, 0.46841946244239807, -0.22420792281627655, -0.7714967131614685, -0.29838573932647705, 0.5050005912780762, -0.8592732548713684, 0.3831575810909271, -0.05856300890445709, -0.14375704526901245, -1.3088514804840088, -0.07134577631950378, -0.08599676191806793, 0.3926362991333008, 0.16818615794181824, 0.39171674847602844, -0.0020273071713745594, -0.7412130832672119, 0.06867726147174835, 0.22627955675125122, 0.2660789489746094, 0.2714877128601074, 0.41472601890563965, 0.3624030351638794, -0.4425421357154846, 0.1698722243309021, 0.38573768734931946, 0.4959477186203003, -0.7235493659973145, 0.11509215086698532, 0.5452027916908264, -0.4187227785587311, -0.1274111568927765, 1.154579997062683, -0.05005691200494766, -1.126281499862671, -0.038243405520915985, -1.3727622032165527, -0.06615161150693893, -0.5116625428199768, 0.551957368850708, -0.02588631398975849, -0.4563271403312683, 0.5810520648956299, -0.12047453224658966, 0.21640923619270325, 0.2782478332519531, -0.13371290266513824, 0.5070449113845825, 0.08067885786294937, -0.8180087208747864, 0.7121168375015259, 0.01595679298043251, -0.36522457003593445, 0.08402054756879807, -0.925764262676239, 0.17192548513412476, -0.08126603066921234, -0.3035205900669098, -0.07659459859132767, -0.5582860708236694, 0.8242893815040588, 0.21995383501052856, 0.5832365155220032, 0.48497989773750305, 0.03088713064789772, 0.1895155906677246, 0.5158380270004272, 0.4608915150165558, 0.00472626555711031, -0.22447915375232697, 0.9650383591651917, 1.0145806074142456, -0.6147307753562927, 0.40592896938323975, -0.47073787450790405, -0.291138619184494, 1.1326403617858887, 0.42780452966690063, -0.050502751022577286, 0.41440990567207336, -0.12074315547943115, -0.5761176347732544, 0.2090681791305542, -1.049737572669983, -0.17280633747577667, 0.4448224604129791, 0.83538818359375, 0.7651480436325073, 0.40486806631088257, -0.27269700169563293, 1.0242738723754883, -0.6690803170204163, 0.43065518140792847, 0.7671689987182617, 0.3646453320980072, -0.4771871268749237, -0.129470095038414, 0.16570940613746643, 0.20529663562774658, -0.6636918187141418, -0.4956100285053253, 0.1245594173669815, 0.276397705078125, 0.34543076157569885, 0.19730354845523834, 0.5989749431610107, -0.056099750101566315, 0.36228907108306885, 0.532767653465271, 0.4122796356678009, -0.408314973115921, -0.4941001236438751, -0.8307933807373047, -0.612981915473938, 0.07408646494150162, -0.17763730883598328, -0.24943746626377106, -0.5158161520957947, -0.7639703750610352, 0.44942137598991394, 0.24091677367687225, 0.00321815419010818, 1.1199506521224976, 0.20144596695899963, 0.2879142761230469, -0.23143844306468964, -0.06404000520706177, -0.5110127329826355, -0.4977504312992096, 0.21791934967041016, -0.22184646129608154, -0.1446433812379837, -0.00541680958122015, -0.5008472204208374, -0.2415197789669037]}, "authors": [{"authorId": "2261393101", "name": "Hattie Zhou"}, {"authorId": "2261389630", "name": "Arwen Bradley"}, {"authorId": "1762320", "name": "Etai Littwin"}, {"authorId": "1388726511", "name": "Noam Razin"}, {"authorId": "2438203", "name": "O. Saremi"}, {"authorId": "2243336902", "name": "Josh Susskind"}, {"authorId": "1751569", "name": "Samy Bengio"}, {"authorId": "2181918", "name": "Preetum Nakkiran"}], "references": [{"paperId": "ffd97533ac66b7d02ca58c1d5951d5427da0ffd6", "title": "Improving Length-Generalization in Transformers via Task Hinting"}, {"paperId": "b1fe7bdcfef4e12febe7e8bed8826e66689d60ed", "title": "Auto-Regressive Next-Token Predictors are Universal Learners"}, {"paperId": "f8e99be4f9a01761fab74bade2c3c18de9fc686b", "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks"}, {"paperId": "a72ba8dc49a6a842f69c312ac9a037a0f33b74f5", "title": "The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks"}, {"paperId": "6f6e2e0311589a9af045f6acd00b7dee6d19fce4", "title": "The Impact of Positional Encoding on Length Generalization in Transformers"}, {"paperId": "7d97c17a75beb89f938eaac1d3ca60ac2245fb2e", "title": "Faith and Fate: Limits of Transformers on Compositionality"}, {"paperId": "af385c0fdd0eda2bbf429bea6fedffc327c8a180", "title": "Randomized Positional Encodings Boost Length Generalization of Transformers"}, {"paperId": "c58325547156a70cb27c148e5b57738ca9ce79aa", "title": "Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples"}, {"paperId": "aec826ff336ca442697d5f908ab1668f1ea18987", "title": "How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model"}, {"paperId": "f680d47a51a0e470fcb228bf0110c026535ead1b", "title": "Progress measures for grokking via mechanistic interpretability"}, {"paperId": "a5cc5edcabba4c9c62cfbc3379daa140084a2a24", "title": "Tracr: Compiled Transformers as a Laboratory for Interpretability"}, {"paperId": "7aa801b907b59b8ee4cfb1296d9dac22c5164c5d", "title": "What learning algorithm is in-context learning? Investigations with linear models"}, {"paperId": "fb6d75a4f3b1af2058f59957116c178a47b56f05", "title": "Simplicity Bias in Transformers and their Ability to Learn Sparse Boolean Functions"}, {"paperId": "e070ff286709db28312e08b52b05539debe88146", "title": "Measuring and Narrowing the Compositionality Gap in Language Models"}, {"paperId": "c90a99eeb57019732a6cc996bb9eaf13faedf00f", "title": "In-context Learning and Induction Heads"}, {"paperId": "4988b3d378b79eb8669112620baf1ff4e3e536fd", "title": "Text and Patterns: For Effective Chain of Thought, It Takes Two to Tango"}, {"paperId": "f0a0e8b6e84207f50db4d24cc4016e40601214ef", "title": "Faithful Reasoning Using Large Language Models"}, {"paperId": "de32da8f5c6a50a6c311e9357ba16aa7d05a1bc9", "title": "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes"}, {"paperId": "f843233f76a5dff07bfa93a71a1cf13d8aa6a94a", "title": "Exploring Length Generalization in Large Language Models"}, {"paperId": "ab0e3d3e4d42369de5933a3b4c237780b41c0d77", "title": "Solving Quantitative Reasoning Problems with Language Models"}, {"paperId": "5437e8adab596d7294124c0e798708e050e25321", "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "d3dd80269f2542cc173afb3a1df24b582a1e4af2", "title": "Overcoming a Theoretical Limitation of Self-Attention"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "45ece6f3b0a319dba60c20b3013b5161dd49c58b", "title": "Linear algebra with transformers"}, {"paperId": "92173d081b15824d22a9ef070e118744ceee8052", "title": "Show Your Work: Scratchpads for Intermediate Computation with Language Models"}, {"paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea", "title": "Training Verifiers to Solve Math Word Problems"}, {"paperId": "aead4418733b998792deb9cbf198a834449e00d2", "title": "Symbolic Brittleness in Sequence Models: on Systematic Generalization in Symbolic Mathematics"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "349eb17c5b61924db8ccc5816c863c6674c8b565", "title": "Saturated Transformers are Constant-Depth Threshold Circuits"}, {"paperId": "0735fb79bf34698c1df4461a05ed51c232c412e4", "title": "Thinking Like Transformers"}, {"paperId": "438a91dae6c0c7be7457055258699c0ccc40f43b", "title": "Neural algorithmic reasoning"}, {"paperId": "2cc3ab9fa41ba2804e301f7eae9598636e62422a", "title": "Investigating the Limitations of Transformers with Simple Arithmetic Tasks"}, {"paperId": "52d87b59a1fa6561b90d5ea56f21180a9b1a505c", "title": "How Can Self-Attention Networks Recognize Dyck-n Languages?"}, {"paperId": "10c86505de83647c7b4157595ab10f64e97c94ef", "title": "On the Ability and Limitations of Transformers to Recognize Formal Languages"}, {"paperId": "21f74e2617d8d8f5fc117ff2ad6e58a540541f6d", "title": "Compositional Generalization in Semantic Parsing: Pre-training vs. Specialized Architectures"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "b3564be8b79f25585acb035f3deaf4ae93c26d8f", "title": "Theoretical Limitations of Self-Attention in Neural Sequence Models"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5e4eb58d5b47ac1c73f4cf189497170e75ae6237", "title": "Neural GPUs Learn Algorithms"}, {"paperId": "5b7bd2a9f5c3424f633bd991d1cf2c98ae013e3c", "title": "Computational Complexity: A Modern Approach"}, {"paperId": "f5c541f83d3868a412bda93fd2dd1210741a719a", "title": "Generalization"}, {"paperId": "bef2ae523cd4447af687fae13bfbb606e4a4a5ca", "title": "A Formal Theory of Inductive Inference. Part II"}, {"paperId": "79dd9e62f0e3ba35ce54d98b32750933e91a972a", "title": "Representations and Computations in Transformers that Support Generalization on Structured Tasks"}, {"paperId": "c4cb90a67f45e7cbacb5286e934b309e89843922", "title": "Attention is Turing-Complete"}, {"paperId": "b59947541d2ac4211c4b17554b2e16c260299bed", "title": "Have You Seen That Number? Investigating Extrapolation in Question Answering Models"}, {"paperId": "12d5f626ed81b79d968f27ee6df73dc24090b79e", "title": "Algorithmic reasoning"}, {"paperId": "20f63033e8775cbab0692aed92d38da7e725d64e", "title": "Understanding Machine Learning - From Theory to Algorithms"}, {"paperId": "b9de7b4b1cbc6fe6fd83bd8e0f174735b296630b", "title": "On Tables of Random Numbers"}, {"paperId": null, "title": "trans-formers learn to solve"}, {"paperId": null, "title": "next_tok = func(seq)[-1] seq = np.concatenate((seq, [next_tok])) return seq Listing 11: Simulating autoregressive sampling given a RASP-L next-token function"}, {"paperId": null, "title": "def index_select(x, idx, default=0): # indexes into sequence x, via index sequence idx # i.e. return x[idx] if idx[i] <= i else default return kqv(indices"}, {"paperId": null, "title": "Andrej Karpathy"}]}