{"paperId": "c90fe514cd532f84b1b6a34965a17cd866037716", "abstract": "This paper proposes layer fusion - a model compression technique that discovers which weights to combine and then fuses weights of similar fully-connected, convolutional and attention layers. Layer fusion can signi\ufb01cantly reduce the number of layers of the original network with little additional computation overhead, while maintaining competitive performance. From experiments on CIFAR-10, we \ufb01nd that various deep convolution neural networks can remain within 2% accuracy points of the original networks up to a compression ratio of 3.33 when iteratively retrained with layer fusion. For experiments on the WikiText-2 language modelling dataset, we compress Transformer models to 20% of their original size while being within 5 perplexity points of the original network. We also \ufb01nd that other well-established compression techniques can achieve competitive performance when compared to their original networks given a suf\ufb01cient number of retraining steps. Generally, we observe a clear in\ufb02ection point in performance as the amount of compression increases, suggesting a bound on the amount of compression that can be achieved before an exponential degradation in performance.", "venue": "Asian Conference on Machine Learning", "year": 2021, "citationCount": 5, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A bound on the amount of compression that can be achieved before an exponential degradation in performance is suggested, suggesting a clear in\ufb02ection point in performance as the amount of compression increases."}, "embedding": {"model": "specter_v2", "vector": [0.347795695066452, 0.5456646084785461, -0.12996086478233337, 0.028222061693668365, -0.3526465892791748, 0.33808794617652893, 0.7839674949645996, -0.29768460988998413, -0.46880942583084106, -0.15954798460006714, 0.85221266746521, -0.18176615238189697, 0.2934904098510742, 0.22154366970062256, -0.3147570788860321, 0.20343153178691864, -0.6138516664505005, 0.11738988757133484, 0.17004746198654175, -0.2599916458129883, -0.24739331007003784, -0.5796473622322083, -1.2598390579223633, 0.3342302143573761, 0.5651448965072632, 1.40549635887146, 0.020455973222851753, 0.9389539361000061, -0.5338641405105591, 0.7124608755111694, 0.8411475419998169, -0.6303054094314575, 0.3552649915218353, -0.09324963390827179, -0.05585856735706329, 0.05373375490307808, 0.3071350157260895, -0.25773385167121887, -0.3115363121032715, 1.045832633972168, -0.4859250485897064, 0.10119690001010895, 0.32200172543525696, -0.6403602361679077, 0.16831465065479279, 0.7314766645431519, 0.6182155609130859, 0.6011806726455688, -0.5571076273918152, -0.7838155031204224, 0.6105284094810486, -0.9953515529632568, -0.3878147304058075, 1.5344297885894775, 0.9200041890144348, 0.3040160536766052, -0.2679433226585388, -0.8940680623054504, 0.5339199900627136, -0.13750068843364716, -0.6255944967269897, -0.37211787700653076, 0.22540804743766785, -0.027316369116306305, 1.613907814025879, -0.11810407787561417, -0.12629446387290955, 0.23868149518966675, -0.0520746149122715, 0.9313430786132812, -0.05855101719498634, -0.49547383189201355, -0.3477444648742676, 0.08348909020423889, 0.0189005509018898, 0.6760707497596741, 0.09723182767629623, 0.31534072756767273, -0.6424195170402527, -0.10340496897697449, 0.31036946177482605, 0.4056694209575653, -0.0594833642244339, 0.019804872572422028, -0.036604706197977066, 0.6001282334327698, 0.47702717781066895, 0.6047367453575134, -0.3397952914237976, 1.3661749362945557, 0.6842789053916931, 0.4611179828643799, 0.45856988430023193, 0.4768521189689636, 0.11539427936077118, 0.5644840598106384, -1.0044870376586914, 0.053867537528276443, -0.12879672646522522, 0.8130584359169006, -0.14533843100070953, 0.23926344513893127, -0.14807985723018646, 0.4169387221336365, 1.561883807182312, -0.23997431993484497, 0.4804989993572235, -1.0200709104537964, 0.7087696194648743, -0.7780212759971619, -0.38791441917419434, -0.6378105282783508, -0.010707332752645016, -0.29595911502838135, -1.053841233253479, -0.8552760481834412, -1.0036120414733887, 0.03762742131948471, -1.1575970649719238, 0.518600583076477, -0.9132248759269714, 0.3487340807914734, -0.0072337668389081955, 0.060721930116415024, 0.22218537330627441, 0.44767099618911743, 0.4368502199649811, -0.09700632840394974, 1.0796887874603271, -0.9732648730278015, -0.6903712749481201, -0.8957186937332153, 0.15529568493366241, -0.39829790592193604, -0.23236632347106934, -0.13057821989059448, -1.8600043058395386, -0.9073525071144104, -1.0442906618118286, 0.13533750176429749, -0.23190514743328094, -0.3066540062427521, 1.1775416135787964, 0.201413094997406, -0.852533221244812, 1.3458573818206787, -0.6443332433700562, 0.018907522782683372, 0.8484918475151062, 0.3371492028236389, 0.13599608838558197, -0.034992918372154236, -0.9158737063407898, 0.3109518587589264, 0.5857144594192505, -0.8516272306442261, 0.09161563962697983, -1.083549976348877, -0.6413249373435974, 0.2120116800069809, 0.014056623913347721, -1.036189317703247, 1.1834187507629395, -0.21107125282287598, -0.8278967142105103, 0.10744533687829971, -0.2494545578956604, -0.4780797064304352, 0.19417564570903778, -0.2785758078098297, -0.523796796798706, 0.09988213330507278, -0.5313336849212646, 0.5737507343292236, 0.6335918307304382, -0.35305458307266235, -0.28337326645851135, 0.6105888485908508, -0.42579078674316406, 0.020657915621995926, -0.4677814841270447, 1.0933737754821777, -0.5469111800193787, -0.4819164276123047, 0.42388495802879333, 0.868094265460968, -0.05953839421272278, 0.09067916125059128, -0.2262476086616516, -0.3787434995174408, 1.266737461090088, -0.20831476151943207, 0.7048419713973999, -1.0269315242767334, -0.962291419506073, -0.07616438716650009, 0.3145258128643036, 0.09281989932060242, -0.6983436346054077, 0.31297096610069275, -0.7577559351921082, 0.6260075569152832, -0.4758802056312561, -1.4133095741271973, -0.0951225757598877, -0.25764766335487366, -0.7456718683242798, -0.727615475654602, 0.3509193956851959, 1.2526193857192993, -0.26512831449508667, 0.11073325574398041, 0.06835358589887619, 0.7299342751502991, -1.1253600120544434, 1.1633124351501465, -0.2364441454410553, -0.08391078561544418, 0.3082040846347809, 0.020943399518728256, 0.05037514492869377, -0.29446572065353394, 0.05852529779076576, -0.8442458510398865, 0.28192317485809326, 0.587222695350647, -0.05345376580953598, 1.1428349018096924, -0.1738787740468979, 0.70879065990448, -0.048010606318712234, -0.8874680995941162, 0.3197856843471527, 0.4167025685310364, -0.16893182694911957, -0.32523199915885925, 0.6439933180809021, 0.2531832456588745, -0.6329419016838074, 0.6869673132896423, 0.584276020526886, 0.5013717412948608, -0.31902655959129333, 0.04898446053266525, 1.1146667003631592, -0.48671188950538635, 0.258556604385376, 0.4351343512535095, 0.5446110367774963, -0.39552706480026245, -0.005889838561415672, 0.1283014863729477, 0.08041683584451675, -1.0387921333312988, -0.27031567692756653, 0.203224778175354, 0.5935179591178894, 1.1833752393722534, 0.6331650614738464, -0.5517926812171936, -0.7761340737342834, -0.0446699894964695, 0.87114018201828, 0.955420196056366, -0.44333958625793457, -0.15075433254241943, -0.8141959309577942, -0.25869131088256836, -0.4097630977630615, -0.026047585532069206, -0.4609518349170685, -0.7039502859115601, -0.1843889057636261, -1.006579875946045, 1.0869438648223877, 0.23884467780590057, 1.6623775959014893, 0.1275583803653717, 0.14043234288692474, -0.4121394157409668, 0.13958297669887543, -0.8594880104064941, -0.5093824863433838, 0.6858733296394348, -1.0242750644683838, -0.1633293777704239, -0.04078609496355057, 0.18572187423706055, 0.04540689289569855, -0.3912375271320343, 0.729204535484314, -0.11164265871047974, 0.00983212050050497, 0.0208896454423666, 0.6258230805397034, -0.7675560116767883, -0.8707354664802551, -0.19476549327373505, 0.22567036747932434, -0.06608711183071136, -0.029756460338830948, 0.11036784946918488, 0.07108017057180405, -0.09250373393297195, -0.6610037088394165, 0.4172561466693878, -0.25154221057891846, 0.03788720816373825, 0.7254965305328369, -0.14144174754619598, -0.31404367089271545, -1.179447054862976, 1.3322463035583496, 0.26006150245666504, -0.13799597322940826, 0.3735945522785187, -0.7327257394790649, 0.09532995522022247, 0.2388760894536972, -0.4623895287513733, -0.2922423779964447, -1.3319944143295288, 0.2881269156932831, -1.2269288301467896, -0.14674295485019684, 0.31495201587677, 0.6837266087532043, -0.17673002183437347, 0.045284025371074677, 0.05507013946771622, 0.6210388541221619, -0.460908979177475, 0.3723686635494232, -1.0607621669769287, 1.091227650642395, 0.5657402873039246, 0.2961476743221283, -0.14856097102165222, -0.07109997421503067, -0.2009444385766983, -0.48636189103126526, 0.09719967097043991, 0.001564461039379239, -0.2007082998752594, 0.43929389119148254, -0.6199803352355957, -0.2729771137237549, -0.3087339997291565, -0.7686591148376465, 0.20896779000759125, -0.08865244686603546, 0.028194980695843697, -0.3022417724132538, -1.0759849548339844, -1.199808955192566, -0.5975852012634277, -0.761275589466095, -1.24347984790802, -0.02103390172123909, 0.27201730012893677, -0.12204700708389282, -0.7259644865989685, -0.5135936141014099, -0.5095168352127075, 1.4632940292358398, -0.16553351283073425, 0.5556920170783997, -0.15292541682720184, 0.32926198840141296, -0.18559499084949493, -0.36446279287338257, 1.0808005332946777, -0.5084027051925659, 0.2509879171848297, -0.9488390684127808, 0.31253600120544434, 0.012251107953488827, -0.041457511484622955, 0.8437168002128601, 0.11017337441444397, 0.8367950916290283, -0.005910007283091545, -0.3092747926712036, 0.9211671948432922, 1.3196312189102173, -0.8656965494155884, 0.1458078920841217, -0.122491255402565, 0.8474618792533875, -0.18594859540462494, -1.0335731506347656, 0.27653852105140686, -0.1173858568072319, -0.03722703829407692, 0.6000610589981079, -0.37192538380622864, -0.6445514559745789, -0.7838172316551208, 0.0018515883712098002, 1.8193104267120361, 0.019355464726686478, 0.1946936845779419, -0.7743984460830688, 0.19139063358306885, -1.0212479829788208, -0.6052731275558472, 0.987261950969696, 0.6258522868156433, 0.1968173086643219, -0.12896686792373657, -0.462231308221817, 0.2456992268562317, 0.624814510345459, 0.17463907599449158, -0.19021420180797577, -0.8452516198158264, 0.09016428142786026, 0.49272027611732483, 0.7715703248977661, 0.5972422957420349, -0.34230363368988037, 0.4032512903213501, 14.580349922180176, 0.5895746946334839, -0.29482772946357727, 0.7641181945800781, 0.5452904105186462, 0.07715592533349991, -0.294670432806015, -0.12848784029483795, -0.9065374732017517, 0.01570209488272667, 1.289055347442627, 0.2626833915710449, 0.7994279861450195, -0.2193676233291626, -0.2927286624908447, 0.5467464327812195, 0.10741269588470459, 0.843368411064148, 0.4333166778087616, -1.6200600862503052, 0.2836562395095825, 0.3085225522518158, 0.4557034969329834, 0.8660612106323242, 0.6914042234420776, 0.6882400512695312, 0.3992919325828552, -0.5008293986320496, 0.2901221811771393, 0.7412774562835693, 1.1232081651687622, -0.2101113349199295, 0.39652207493782043, 0.23874573409557343, -0.8514986634254456, -0.2079123854637146, -0.4099580645561218, -1.0731585025787354, 0.5471277236938477, 0.1691681146621704, -0.10083477944135666, -0.5300671458244324, -0.06194150820374489, 0.554411768913269, -0.2291938066482544, 0.4775794744491577, -0.07278648763895035, 0.828339695930481, -0.7079831957817078, 0.5232401490211487, 0.31739166378974915, 0.7554216384887695, 0.008198417723178864, -0.011932977475225925, 0.09601660072803497, -0.143699511885643, -0.17957445979118347, 0.4455973207950592, -0.8233730792999268, -0.8053551316261292, -0.20643676817417145, -0.24806556105613708, 0.009447423741221428, 0.4174760580062866, 0.554818868637085, -0.1744316667318344, -0.4166346788406372, 0.21116600930690765, 0.5317718982696533, 0.31181401014328003, -0.6669994592666626, -0.2326514720916748, 0.5733598470687866, -0.2393883615732193, 0.2116958498954773, 0.5092644691467285, -0.5827059149742126, -0.6686418056488037, -0.8775478005409241, -0.21541349589824677, 0.15737216174602509, -1.128242015838623, -0.5678361654281616, 1.2726389169692993, 0.24955689907073975, -0.17820727825164795, 0.42443597316741943, -0.5413873791694641, -0.477894127368927, 0.3239346444606781, -1.61750328540802, -0.2938128709793091, 0.07802599668502808, -0.05013139173388481, -0.5322606563568115, -0.48454129695892334, 0.9607414603233337, 0.4074040353298187, -0.24667881429195404, 0.3021453022956848, -0.3833734691143036, -0.10759257525205612, -0.5047581791877747, -0.3284026086330414, 0.6615369319915771, 0.35359615087509155, -0.004564772825688124, 0.00904418807476759, -0.23029281198978424, 0.29040446877479553, -0.2107817530632019, -0.2907915711402893, 0.7006038427352905, -0.08844644576311111, -0.27047985792160034, -0.4274556338787079, -0.998990535736084, 0.26733049750328064, 0.7358030676841736, 0.053102023899555206, 0.40356263518333435, -0.11027740687131882, -0.8673834204673767, 0.04056573286652565, -1.1286457777023315, 0.24898086488246918, 0.15174558758735657, -0.9362389445304871, -0.4211902320384979, -0.27455800771713257, 0.9145597815513611, -0.7390332221984863, -0.7345839738845825, 0.17251412570476532, -0.03704942390322685, -0.2891034185886383, 1.0714867115020752, -0.2476760447025299, 0.7506664991378784, 1.0251269340515137, -0.5320227146148682, -0.5926932096481323, -0.11047591269016266, -0.7630980014801025, -0.14128978550434113, 0.09748305380344391, 0.42941415309906006, -0.4422205686569214, -0.07188680768013, 0.9114852547645569, -0.1844313144683838, -0.32065916061401367, -0.7239649891853333, 0.30536311864852905, -0.0748448595404625, -1.036904215812683, 0.5058507323265076, -0.2594718039035797, -0.10607272386550903, -0.24433085322380066, 0.4572391211986542, 0.04685591161251068, 0.07818453758955002, -1.3611540794372559, -0.14450621604919434, -0.24437788128852844, -0.04300973564386368, -1.050108790397644, -0.7428589463233948, -1.0625845193862915, -0.029703469946980476, -1.0726045370101929, -0.5180583000183105, -0.8697763085365295, -0.6054270267486572, 0.37831613421440125, -0.3029131591320038, 0.2111659049987793, 0.530648410320282, 0.32054242491722107, 0.26405617594718933, -0.15302345156669617, -0.5175986886024475, 0.7465230226516724, 0.7199649214744568, -0.5443676710128784, 0.3499438762664795, -0.37592586874961853, -0.434344619512558, 0.8028548359870911, 0.6076202988624573, -0.2605072557926178, -0.7426025867462158, -1.5594042539596558, 0.21164368093013763, -0.12023971229791641, 0.05904558673501015, -1.2914931774139404, 0.9861043095588684, 0.8878111243247986, -0.053779833018779755, 0.07931801676750183, 0.4214019179344177, -1.0791727304458618, -0.4701078534126282, 0.35779958963394165, -0.8901532888412476, 0.29145124554634094, 0.5986416935920715, -0.2613293528556824, -0.4723580777645111, 0.9054754972457886, 0.14225223660469055, -0.8241579532623291, -0.406141459941864, 0.12661252915859222, -0.49306154251098633, -0.24688488245010376, -0.4431719183921814, 0.12317858636379242, -1.183937668800354, -0.2353544533252716, -0.2526116669178009, 0.0321323461830616, -0.6473727822303772, 0.8464561700820923, 0.5613950490951538, -1.4813106060028076, 0.2634104788303375, 0.8175073266029358, -0.2824958860874176, -0.4125351011753082, 0.19888100028038025, 0.6661848425865173, -0.5049225687980652, 0.45240887999534607, 0.31008511781692505, 0.5365330576896667, -0.6670980453491211, -0.08659647405147552, 1.0054916143417358, -0.3296024203300476, -0.16808094084262848, 1.1901229619979858, -0.5349210500717163, -0.605679452419281, 0.37666425108909607, -1.579108715057373, -0.23951515555381775, -0.4017861783504486, 0.6692717671394348, -0.07315898686647415, 0.1905646175146103, 0.12262218445539474, -0.06650620698928833, 0.03298558294773102, -0.02680863067507744, -0.6663312315940857, 0.19116321206092834, -0.19134168326854706, -0.31604623794555664, 0.5787572860717773, 1.2499572038650513, -1.3325797319412231, -0.9282193779945374, -0.9330099821090698, -0.4539574086666107, 0.04696977511048317, 0.769990861415863, -0.49881598353385925, -0.9482781291007996, 0.8855136036872864, 0.49322324991226196, 0.24319487810134888, 0.6165041923522949, -0.25422078371047974, 0.27522048354148865, 0.31059613823890686, -0.30500295758247375, -0.2748108208179474, -0.7529214024543762, 1.3941208124160767, 1.150425910949707, -0.776279091835022, 0.6311368942260742, -0.00034300077822990716, -0.6942564845085144, 0.7073101997375488, -0.2618847191333771, -0.627138614654541, 1.4941824674606323, 0.09084711968898773, -0.3646250367164612, 0.4616621136665344, -1.4992873668670654, -0.38250771164894104, 0.761857807636261, 0.9511455297470093, 0.6941059827804565, 0.04720515385270119, 0.15688414871692657, 1.117815375328064, -0.033564839512109756, 0.11896169930696487, 0.02832532860338688, 0.36338919401168823, -0.4215976297855377, 0.1323007047176361, -0.21640540659427643, 0.9232017397880554, -0.8216822147369385, -0.5507461428642273, 0.16562438011169434, 0.5983268022537231, 0.438098669052124, 0.7435816526412964, 1.1349480152130127, -0.7860933542251587, 0.7542358636856079, 0.11255496740341187, 0.3195459842681885, -0.052392423152923584, -0.6438049674034119, 0.20882079005241394, -0.5345762968063354, -0.019570114091038704, -0.286907821893692, -0.41928210854530334, -0.2711644768714905, -0.7569668292999268, 0.4017704725265503, 0.014102054759860039, 0.6350526213645935, 0.9617137908935547, 0.5354853868484497, 0.8903509378433228, -0.35088443756103516, -0.7324285507202148, -0.1440475434064865, -0.8737647533416748, 0.16725997626781464, -0.47567495703697205, -0.18063035607337952, -0.34758085012435913, -0.2588101029396057, -0.1574721783399582]}, "authors": [{"authorId": "1666206198", "name": "James O'Neill"}, {"authorId": "1719898", "name": "G. V. Steeg"}, {"authorId": "143728483", "name": "A. Galstyan"}], "references": [{"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "ea415809bf87ef4b99966c6c50de6cb996a02a97", "title": "Deep double descent: where bigger models and more data hurt"}, {"paperId": "261004890f902acd810ac4e9b1025ca5981ceedf", "title": "Model Fusion via Optimal Transport"}, {"paperId": "f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1", "title": "Reducing Transformer Depth on Demand with Structured Dropout"}, {"paperId": "a339bd43dc2fa2376f2193dfef87cf8b3d151e9a", "title": "Accelerating Sparse Matrix Operations in Neural Networks on Graphics Processing Units"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "title": "Energy and Policy Considerations for Deep Learning in NLP"}, {"paperId": "726320cdbd04804ffa8f3a78c095bd1b55a2a695", "title": "Similarity of Neural Network Representations Revisited"}, {"paperId": "4ac62731b802c727f916e8deefda1a992991505d", "title": "Are All Layers Created Equal?"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "f86f1748d1b6d22870f4347fd5d65314ba800583", "title": "Reconciling modern machine-learning practice and the classical bias\u2013variance trade-off"}, {"paperId": "21937ecd9d66567184b83eca3d3e09eb4e6fbd60", "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"}, {"paperId": "f6a4bf043af1a9ec7f104a7b7ab56806b241ceda", "title": "Model compression via distillation and quantization"}, {"paperId": "7b8d67593c4ab1b1e3eccc158daee76703b328aa", "title": "Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy"}, {"paperId": "ef9ddbc35676ce8ffc2a8067044473727839dbac", "title": "Breaking the Softmax Bottleneck: A High-Rank RNN Language Model"}, {"paperId": "92d621a603cda8c32214d70953e180fe5a442f3e", "title": "N2N Learning: Network to Network Compression via Policy Gradient Reinforcement Learning"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "90ab469425b772008f7c409972aa520f92dc7a77", "title": "Soft-to-Hard Vector Quantization for End-to-End Learning Compressible Representations"}, {"paperId": "31ea21d2fdf9e243aac746b68ca0111952fc58f4", "title": "Skip Connections Eliminate Singularities"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "5694e46284460a648fe29117cbc55f6c9be3fa3c", "title": "Densely Connected Convolutional Networks"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "1c4e9156ca07705531e45960b7a919dc473abb51", "title": "Wide Residual Networks"}, {"paperId": "2a24b68ef180c0c8742bd494a55fb6f68864efed", "title": "Residual Networks Behave Like Ensembles of Relatively Shallow Networks"}, {"paperId": "d497b87722adc93b98cdb6766d49572a9ed6d096", "title": "Deep Residual Networks with Exponential Linear Unit"}, {"paperId": "d3cb9bad655197b52932978dd8186b36c512bf92", "title": "Quantized Convolutional Neural Networks for Mobile Devices"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "dc49884e1552d21b129eacf3b0a4c72393556158", "title": "Convergent Learning: Do different neural networks learn the same representations?"}, {"paperId": "642d0f49b7826adcf986616f4af77e736229990f", "title": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"}, {"paperId": "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff", "title": "Learning both Weights and Connections for Efficient Neural Network"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "6fc6803df5f9ae505cae5b2f178ade4062c768d0", "title": "Fully convolutional networks for semantic segmentation"}, {"paperId": "bba7ae7d8d5f82acdebcbce6c6e596310c7a66be", "title": "Relating the Bures Measure to the Cauchy Two-Matrix Model"}, {"paperId": "f254cbfe9710de5e41589f8b7898112b06872ed2", "title": "DenseNet: Implementing Efficient ConvNet Descriptor Pyramids"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "df7e1cfa5999c3746a3bbc9817d924677ac8b8f0", "title": "Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions"}, {"paperId": "d4ab89fcc6547b8b77d028abfa34e659eb685ca6", "title": "Elements of large-sample theory"}, {"paperId": "563e821bb5ea825efb56b77484f5287f08cf3753", "title": "Convolutional networks for images, speech, and time series"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "a42954d4b9d0ccdf1036e0af46d87a01b94c3516", "title": "Second Order Derivatives for Network Pruning: Optimal Brain Surgeon"}, {"paperId": "c8e8b54f87f43c4a6f85695712dff55e0edec760", "title": "A simple procedure for pruning back-propagation trained neural networks"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "64ce52ec9f550ddd980e209ca68ff38947cf9061", "title": "CUDA by Example: An Introduction to General-Purpose GPU Programming"}, {"paperId": "400be635de58c0a88d724624b9860b5966112fc3", "title": "Symmetric Positive-Definite Matrices: From Geometry to Applications and Visualization"}]}