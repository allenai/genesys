{"paperId": "04178483ea931ca0bb91bd00542d2d734189886c", "abstract": "Executing machine learning inference tasks on resource-constrained edge devices requires careful hardware-software co-design optimizations. Recent examples have shown how transformer-based deep neural network models such as ALBERT can be used to enable the execution of natural language processing (NLP) inference on mobile systems-on-chip housing custom hardware accelerators. However, while these existing solutions are effective in alleviating the latency, energy, and area costs of running single NLP tasks, achieving multi-task inference requires running computations over multiple variants of the model parameters, which are tailored to each of the targeted tasks. This approach leads to either prohibitive on-chip memory requirements or paying the cost of off-chip memory access. This paper proposes adapter-ALBERT, an efficient model optimization for maximal data reuse across different tasks. The proposed model's performance and robustness to data compression methods are evaluated across several language tasks from the GLUE benchmark. Additionally, we demonstrate the advantage of mapping the model to a heterogeneous on-chip memory architecture by performing simulations on a validated NLP edge accelerator to extrapolate performance, power, and area improvements over the execution of a traditional ALBERT model on the same hardware platform.", "venue": "arXiv.org", "year": 2023, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2303.16100", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes adapter-ALBERT, an efficient model optimization for maximal data reuse across different tasks, and demonstrates the advantage of mapping the model to a heterogeneous on-chip memory architecture by performing simulations on a validated NLP edge accelerator to extrapolate performance, power, and area improvements over the execution of a traditional ALBERT model on the same hardware platform."}, "embedding": {"model": "specter_v2", "vector": [0.3294595181941986, 0.2848685681819916, -0.7871989607810974, 0.172645702958107, -0.5410532355308533, -0.025664834305644035, 0.2678193747997284, -0.003981478977948427, -0.6186414957046509, -0.3595585227012634, 0.7139511704444885, -0.28272947669029236, 0.4077065587043762, -0.06191810220479965, -0.21958577632904053, 0.2860758602619171, -0.6185218691825867, 0.27106931805610657, -0.16334939002990723, 0.0166477058082819, -0.2125881016254425, -0.24129214882850647, -1.1566075086593628, 0.10356651246547699, 0.2927742004394531, 0.9769604802131653, 0.06216621398925781, 1.07064688205719, -0.6855909824371338, -0.14837351441383362, 0.46805712580680847, -0.2588532865047455, 0.0652216300368309, 0.299089640378952, 0.0815761610865593, -0.5547310709953308, 0.25004658102989197, -0.601499080657959, -0.39748087525367737, 1.0226322412490845, -0.11256498843431473, 0.1715209037065506, 0.39891698956489563, -0.6915292143821716, -0.5347573757171631, 0.589998185634613, 0.5327528715133667, 0.6928325295448303, -0.4043375253677368, -0.49221381545066833, 1.179318904876709, -1.4126322269439697, 0.25260379910469055, 1.0441051721572876, 0.693570077419281, 0.33841395378112793, 0.08311673253774643, -0.6451411247253418, -0.15080557763576508, -0.04127711430191994, -0.6390749216079712, -0.7861316204071045, 0.0209795031696558, 0.20362600684165955, 2.069593906402588, -0.13686181604862213, 0.05570812523365021, 0.5154377222061157, 0.4312649369239807, 1.2566454410552979, -0.18331150710582733, -1.0288201570510864, 0.02583000808954239, -0.3433093726634979, 0.1683245152235031, 0.9506235122680664, -0.027971651405096054, 0.3323781192302704, -1.2253203392028809, -0.22728987038135529, -0.05581383779644966, 0.0341930091381073, 0.5904302000999451, 0.18356025218963623, 0.14414894580841064, 0.5427277088165283, 0.38811153173446655, 0.740671694278717, -0.15654133260250092, 0.571463406085968, 1.1183054447174072, 0.12275436520576477, 0.14844080805778503, 0.22783535718917847, -0.15204750001430511, 0.1575915664434433, -1.146175742149353, 0.09522457420825958, 0.45459190011024475, 1.0236310958862305, -0.5102177858352661, 0.4354809820652008, -0.7753577828407288, 0.07969781756401062, 1.0477416515350342, 0.19270125031471252, 0.6256828904151917, -0.3757072985172272, 0.20629523694515228, -0.7428621649742126, 0.09872401505708694, -0.27411171793937683, -0.3249172270298004, -0.20489227771759033, -1.164941668510437, -1.0602340698242188, -0.6145122051239014, 0.040221866220235825, -0.9465420246124268, 0.3687850832939148, -0.6120414733886719, 0.14044858515262604, 0.5377673506736755, 0.009202070534229279, 0.885046124458313, 0.586124062538147, 0.24599191546440125, 0.34281444549560547, 1.449998378753662, -1.4168312549591064, -0.5601882338523865, -1.358288049697876, 0.5199061036109924, -0.3874128758907318, 0.37562379240989685, -0.45285648107528687, -1.5318604707717896, -0.7141501307487488, -0.797909140586853, -0.5064212679862976, -0.720394492149353, 0.2354687601327896, 1.016594648361206, 0.2763211131095886, -0.9552181959152222, 0.505332350730896, -0.21126922965049744, -0.2577986419200897, 0.22408951818943024, 0.4409511089324951, 0.5972498655319214, -0.1650693118572235, -1.2089918851852417, -0.1896337866783142, 0.2874414622783661, -0.8336985111236572, -0.04047290235757828, -0.7092786431312561, -1.0175716876983643, 0.4343603253364563, 0.15809176862239838, -0.9349009990692139, 1.2418708801269531, -0.07486985623836517, -1.4425705671310425, 0.5683850049972534, -0.20931600034236908, -0.040271010249853134, -0.1553984433412552, -0.029998619109392166, -0.760001540184021, -0.20810772478580475, -0.04602667689323425, 0.5629929900169373, 0.6911048293113708, 0.19808556139469147, -0.14576172828674316, 0.2623332440853119, -0.5110689401626587, 0.06673701852560043, -0.4958615005016327, 1.0559266805648804, -0.7994305491447449, -0.453503280878067, 0.17647616565227509, 0.5324520468711853, -0.19309324026107788, -0.023279093205928802, -0.5242148041725159, -0.5428974032402039, 1.0124849081039429, -0.2137661874294281, 1.0571855306625366, -1.3244316577911377, -1.0714200735092163, 0.024112077429890633, -0.07211445271968842, -0.0931549221277237, -0.5767765045166016, 0.22625605762004852, -0.1638532280921936, 0.32346242666244507, -0.10495684295892715, -0.8766780495643616, 0.04492945224046707, -0.2701601982116699, -0.6141247749328613, -0.7613485455513, -0.16707783937454224, 1.3139102458953857, -0.5937997102737427, 0.23669467866420746, -0.5432748198509216, 0.43703439831733704, -1.2884316444396973, 1.1324195861816406, -0.41569676995277405, -0.1474558413028717, 0.11288127303123474, 0.2383335530757904, -0.03168969228863716, -0.3279760181903839, 0.47691836953163147, -0.9906116127967834, 0.1409168541431427, 0.4606098532676697, 0.3039059042930603, 1.6006520986557007, -0.901065468788147, 0.31121596693992615, 0.3910682201385498, -0.4913122057914734, 0.2391466498374939, 0.4860289394855499, -0.48393967747688293, -0.6936088800430298, 0.5228342413902283, 0.8918049335479736, -0.16567778587341309, 0.11966627836227417, 1.3683819770812988, 0.8891603946685791, -0.7983496785163879, 0.21535591781139374, 0.6729332208633423, -0.5488606095314026, 0.6320640444755554, -0.1116214469075203, 1.0252591371536255, 0.0443023145198822, 0.5750583410263062, -0.1861942559480667, 0.36448028683662415, -0.9692047238349915, -0.26787832379341125, 0.4415053129196167, 0.5114238858222961, 0.1942903697490692, 0.24692019820213318, -0.6339406371116638, -0.46510857343673706, -0.2670701742172241, 0.43550628423690796, 1.440744400024414, -0.421789288520813, 0.15622316300868988, -0.9650138020515442, -0.6149144768714905, -0.4605189561843872, 0.14166046679019928, 0.1789015382528305, -0.31982937455177307, -0.4514811933040619, -1.2154194116592407, 1.0395832061767578, 0.4351660907268524, 1.2628777027130127, -0.8313810229301453, -0.5180116891860962, -0.6014683246612549, 0.28232327103614807, -0.8758333325386047, -0.8487935066223145, 0.7753873467445374, -0.5974670648574829, 0.3942626714706421, 0.30633825063705444, -0.13278424739837646, 0.39382025599479675, -0.6842259764671326, 1.22679603099823, -0.46439191699028015, -0.4546854496002197, 0.0267975851893425, 0.6515160799026489, -0.42453664541244507, -1.1162341833114624, 0.490582674741745, -0.15294331312179565, -0.6986362338066101, 0.7141657471656799, 0.09285307675600052, 0.14447516202926636, -0.43129095435142517, -0.5276378393173218, -0.2611052691936493, 0.3727811872959137, 0.21798300743103027, 0.8307161927223206, -0.367642343044281, -0.034406427294015884, -1.0462363958358765, 1.292739987373352, -0.0697595402598381, -0.2632642686367035, 0.1308680772781372, -0.6478354334831238, 0.10515782237052917, 1.1593528985977173, -0.3933444023132324, -0.3992953300476074, -0.7885606288909912, 0.016158603131771088, -0.3167378306388855, -0.22863337397575378, 0.21767151355743408, 0.030246563255786896, 0.00730994762852788, 0.30334004759788513, 0.5956752300262451, 0.07930026948451996, 0.13971824944019318, 0.5252649188041687, -0.397855281829834, 0.7216706871986389, 0.008183062076568604, -0.06871578097343445, -0.0783032774925232, -0.07012989372015, -0.5884578824043274, -0.2684321105480194, -0.05622722581028938, 0.03450794890522957, -0.11842182278633118, 0.33393508195877075, -0.5128575563430786, -0.5481929183006287, -0.49464887380599976, -1.228937029838562, -0.125417560338974, -0.00997157022356987, -0.4321390986442566, -0.33758410811424255, -1.4387811422348022, -1.4204710721969604, -0.25104156136512756, -1.599408745765686, -1.2775822877883911, 0.7974041700363159, 0.28494057059288025, -0.3931746780872345, -0.6259886622428894, -0.37539708614349365, -0.5070305466651917, 1.099181056022644, -0.8275309801101685, 0.9448572993278503, -0.37637487053871155, -0.12400416284799576, -0.029711449518799782, -0.26105907559394836, 0.08682417124509811, -0.5075184106826782, 0.10243140906095505, -0.847802460193634, 0.4650729298591614, -0.2902720272541046, -0.06845413893461227, 0.23725780844688416, 0.3436836898326874, 1.0613839626312256, 0.03103385493159294, -0.6212403178215027, 0.7567487955093384, 1.4076356887817383, -0.5006951689720154, -0.04916612431406975, -0.010512260720133781, 0.6847241520881653, -0.4601556360721588, -0.6640698313713074, 0.315388560295105, -0.0009868709603324533, 0.6267720460891724, -0.0790887176990509, -0.14295320212841034, -0.2550450563430786, -0.3438861072063446, 0.5908796191215515, 1.9920127391815186, 0.7952953577041626, -0.10067901760339737, -0.9014518857002258, 0.49789994955062866, -1.0810117721557617, -0.14948707818984985, 0.8317909240722656, 0.40078556537628174, 0.2953904867172241, 0.14022912085056305, -0.394455224275589, -0.14696823060512543, 0.2369493544101715, 0.4514197111129761, -0.6648475527763367, -1.3542659282684326, 0.4394344985485077, 0.7940529584884644, 0.6587833762168884, 0.43720874190330505, -0.39138731360435486, 0.34495994448661804, 14.571027755737305, 1.142144799232483, 0.19744597375392914, 0.7923305630683899, 0.5545240044593811, 0.3484191596508026, -0.4014119505882263, -0.470913827419281, -1.3246238231658936, -0.07388398051261902, 1.7751539945602417, 0.04417126253247261, 0.5362584590911865, 0.45027127861976624, -0.11098302155733109, 0.4141579866409302, -0.3911437690258026, 0.43935173749923706, 0.6959917545318604, -1.5659923553466797, 0.20846138894557953, -0.1477866917848587, 0.2816704511642456, 0.7574138045310974, 0.6015605330467224, 0.7384822368621826, 0.6085140705108643, -0.19428414106369019, 0.27849990129470825, 0.1539643257856369, 1.131706953048706, -0.20282107591629028, 0.4107975959777832, 0.29065245389938354, -1.0926439762115479, -0.21342605352401733, -0.33294758200645447, -0.7632655501365662, 0.18480609357357025, 0.5963478088378906, -0.44832879304885864, -0.5088746547698975, -0.10168065875768661, 0.5305464267730713, 0.4851090908050537, 0.12513378262519836, -0.1495349258184433, 0.13137111067771912, -0.06508214771747589, 0.1873638778924942, -0.0323740653693676, 0.5043869614601135, 0.17339754104614258, 0.23248201608657837, 0.31570273637771606, -0.5291269421577454, 0.18988847732543945, 0.5279422998428345, -0.923994779586792, -0.2648782730102539, -0.6246903538703918, -0.07281351834535599, -0.0547659769654274, 0.9444637298583984, -0.0053466251119971275, 0.37317559123039246, -0.765515148639679, 0.8430056571960449, 0.6499096155166626, 0.024727437645196915, -0.22504207491874695, -0.2789543867111206, 0.070595882833004, -0.7084099054336548, -0.06710365414619446, 0.4204390347003937, -0.479724645614624, -0.43617352843284607, -0.6742032170295715, -0.42468711733818054, 0.21765586733818054, -0.6749781966209412, -0.683786153793335, 0.9516414403915405, -0.24017862975597382, -0.22086979448795319, 0.26356080174446106, -1.0058033466339111, -0.3041202127933502, 0.2092454880475998, -1.3497494459152222, -0.6355514526367188, 0.4246014356613159, -0.5478740334510803, -0.32913637161254883, -0.18505893647670746, 1.5516018867492676, 0.5726845264434814, -0.3170243203639984, 0.38328295946121216, 0.3143101930618286, 0.026129718869924545, -0.4298713207244873, -0.548917293548584, 1.2168629169464111, 0.33717769384384155, 0.012532387860119343, -0.0802687257528305, -0.018889984115958214, 0.00768943689763546, -0.8088743090629578, -0.3352239429950714, 0.8582478165626526, -0.2250150889158249, -0.14653807878494263, -0.9281930327415466, -0.6341055035591125, 0.11990732699632645, 0.46498000621795654, 0.11576792597770691, 0.6828166842460632, -0.04170563817024231, -0.693529486656189, -0.17574752867221832, -1.0958064794540405, 0.3971933126449585, 0.7372980117797852, -1.1262848377227783, 0.02284378744661808, 0.08365027606487274, 0.5554105043411255, -1.3258395195007324, -0.6247673034667969, -0.1281149536371231, 0.10531438142061234, -0.15781132876873016, 1.0390686988830566, -0.03723850101232529, 1.0556223392486572, 0.9061287045478821, -0.09431400150060654, -0.5927746891975403, 0.4437520503997803, -0.5905109643936157, -0.29931768774986267, -0.1325344443321228, 0.7405203580856323, -0.08944273740053177, 0.5560169816017151, 0.9298830032348633, -0.10064662992954254, -0.4304802119731903, -0.802063524723053, -0.2551004886627197, -0.3479563891887665, -0.5014936923980713, 0.3066503703594208, -0.39335405826568604, 0.015683487057685852, 0.004371688701212406, 0.6824323534965515, 0.3963925838470459, -0.33463677763938904, -0.4239322245121002, 0.021152934059500694, 0.09110616892576218, -0.529345691204071, -0.472680926322937, -0.12168829143047333, -1.2733123302459717, 0.4407767653465271, -1.590667963027954, 0.2533460259437561, -0.15291376411914825, -0.3135962188243866, 0.07297854125499725, 0.03416825458407402, 0.06819237023591995, 0.4116480350494385, -0.036407720297575, -0.36275914311408997, -0.4217984676361084, -0.21601353585720062, 0.7653782367706299, 0.5576618909835815, -0.7066561579704285, -0.07006420940160751, -0.2797333598136902, 0.08680359274148941, 0.5697623491287231, 0.43979328870773315, -0.5648310780525208, -0.5833476781845093, -1.3977794647216797, 0.3196977972984314, 0.015351995825767517, -0.15837617218494415, -0.7972552180290222, 0.8827579021453857, 0.5670605897903442, -0.5385227203369141, 0.4685552716255188, -0.039484038949012756, -1.2874200344085693, -0.6110597848892212, 0.603742241859436, -0.39487338066101074, 0.48948681354522705, 0.8716822266578674, -0.49674007296562195, -0.27552488446235657, 0.2920655608177185, -0.2315475344657898, -0.5603068470954895, -0.7470424771308899, 0.14172270894050598, -0.6117768287658691, 0.17364951968193054, -0.34896591305732727, 0.3234313130378723, -1.1636831760406494, -0.23668038845062256, 0.18968413770198822, -0.2800835371017456, -0.4686034917831421, 0.7239950299263, 0.2192935198545456, -1.0039058923721313, 0.3649533689022064, 0.8154436945915222, -0.42076975107192993, 0.07196147739887238, 0.1646546870470047, 0.5083187818527222, -0.5256478190422058, 0.47909823060035706, 0.12940429151058197, 0.4349013566970825, -0.6958017349243164, -0.1743895411491394, 0.6094298958778381, -0.9758358001708984, -0.17685729265213013, 0.8572121262550354, -0.696575939655304, -1.00535249710083, -0.2707383632659912, -1.364377498626709, 0.014988580718636513, -0.5871707797050476, 0.38780665397644043, -0.14335961639881134, 0.49324506521224976, 0.26098182797431946, -0.40451622009277344, 0.05081390216946602, -0.2305699735879898, -0.3675408661365509, 0.24139438569545746, 0.1990627944469452, -0.3902240991592407, 0.07430221885442734, 0.5685034394264221, -0.2915534973144531, -0.2588348388671875, -0.6307696104049683, -0.1960867941379547, 0.2579481303691864, 0.6449391841888428, -0.1560329794883728, -0.9486737847328186, 0.499048113822937, 0.42517659068107605, 0.11496216058731079, 0.7083843350410461, -0.35128653049468994, 0.7873689532279968, 0.5903127193450928, -0.016761545091867447, -0.560830295085907, -0.6358229517936707, 1.2488287687301636, 0.9697369337081909, -0.5936300158500671, 0.408173531293869, -0.4260264039039612, -0.03692673146724701, 0.9969332814216614, 0.11201199889183044, 0.009075062349438667, 1.1709716320037842, 1.1443802118301392, -0.25722745060920715, 0.3006645143032074, -0.7115321159362793, -0.11141408234834671, 0.6643112897872925, 0.9023262858390808, 0.8103774785995483, 0.3808845579624176, -0.254158079624176, 1.1016724109649658, 0.28906524181365967, 0.5620999336242676, 0.4680783152580261, 0.41890496015548706, -0.010935608297586441, -0.4122128486633301, -0.22361472249031067, 1.0689153671264648, -0.7706535458564758, -1.1821753978729248, 0.30080705881118774, 0.7023840546607971, 0.167585551738739, 0.18765629827976227, 1.1020864248275757, -0.13897764682769775, 0.5439109802246094, 0.15411044657230377, 0.2168143093585968, -0.5271794199943542, -0.5436339378356934, -0.2905724048614502, -0.3477150797843933, -0.10172338783740997, -0.04810858890414238, -0.1531662493944168, -0.8879443407058716, -0.3045107424259186, 0.5830581188201904, -0.23221763968467712, 0.7083724737167358, 0.9590393900871277, 1.111389398574829, 0.8179229497909546, -0.8269671201705933, -0.6729062795639038, 0.025579819455742836, -0.5078650116920471, 0.13942809402942657, -0.578711986541748, -0.4196135401725769, 0.17398987710475922, -0.23663152754306793, -0.3919876217842102]}, "authors": [{"authorId": "46905342", "name": "Zirui Fu"}, {"authorId": "2212937539", "name": "Aleksandre Avaliani"}, {"authorId": "2026851", "name": "M. Donato"}], "references": [{"paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a", "title": "Emergent Abilities of Large Language Models"}, {"paperId": "6c910011a12b5b95bf6a771b54e7253b1f98a8a4", "title": "NVMExplorer: A Framework for Cross-Stack Comparisons of Embedded Non-Volatile Memories"}, {"paperId": "949c0941d4c57482318afa28f2c8eb82569fb401", "title": "Pruning and Quantization for Deep Neural Network Acceleration: A Survey"}, {"paperId": "3af8a493cf756f9fe72623204a11e378a9cd71a5", "title": "EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware Multi-Task NLP Inference"}, {"paperId": "9fd1684e6d163c89bd2b2887ab1b21b89ad10137", "title": "TensorFlow Lite Micro: Embedded Machine Learning on TinyML Systems"}, {"paperId": "6aca11d1adf5b5fa4cf88ceed1554e266456c5a4", "title": "TinyTL: Reduce Activations, Not Trainable Parameters for Efficient On-Device Learning"}, {"paperId": "8acc99c96a9cce2a14e049f756f608dab3491f24", "title": "MCUNet: Tiny Deep Learning on IoT Devices"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "d9b824dbecbe3a1f0b1489f9e4521a532a63818d", "title": "Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning"}, {"paperId": "cecdbafeb178eb6913d071030bd8f717690ed071", "title": "MEMTI: Optimizing On-Chip Nonvolatile Storage for Visual Multitask Inference at the Edge"}, {"paperId": "f394ae69c638d4506e67d5ce44982abe411da53b", "title": "MaxNVM: Maximizing DNN Storage Density and Inference Efficiency with Sparse Encoding and Error Mitigation"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "b177818316922276cb8c67af53dbd7893540d3a6", "title": "Performance-Efficiency Trade-off of Low-Precision Numerical Formats in Deep Neural Networks"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "39f74bcea6b4a3f9491b7823323b8866141fef8b", "title": "Research on NVIDIA Deep Learning Accelerator"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "4081de7e0f94e7e0d7b645c298d7768698d05774", "title": "Efficient Parametrization of Multi-domain Deep Neural Networks"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "e8eb0eb28a66895e4bcc178918c67563ce2654c7", "title": "A Collective Study on Modeling and Simulation of Resistive Random Access Memory"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "90a16f34d109b63d95ab4da2d491cbe3a1c8b656", "title": "Learning Efficient Convolutional Networks through Network Slimming"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "d89ee98810039d2061ed42ee8026da49c503d16b", "title": "Learning multiple visual domains with residual adapters"}, {"paperId": "733a765e1f54eb86dbaabe03d7ba66d72363f665", "title": "TETRIS: Scalable and Efficient Neural Network Acceleration with 3D Memory"}, {"paperId": "d418295cd3027c43eccc5592ae5b8303ba8192be", "title": "Trained Ternary Quantization"}, {"paperId": "c4a0b812421d825121e2b1335ab1edc85aa33843", "title": "A review of emerging non-volatile memory (NVM) technologies and applications"}, {"paperId": "7601b995303f953955004db7b9b8b206c0e02ff8", "title": "Learning Structured Sparsity in Deep Neural Networks"}, {"paperId": "91d03e4bf98a03c827983457e6de43cbd4c6ccd7", "title": "Minerva: Enabling Low-Power, Highly-Accurate Deep Neural Network Accelerators"}, {"paperId": "592d2e65489f23ebd993dbdc0c84eda9ac8aadbe", "title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size"}, {"paperId": "081651b38ff7533550a3adfc1c00da333a8fe86c", "title": "How transferable are features in deep neural networks?"}, {"paperId": "f7085121b404d43b11c3e040c8b6be10ef5462ca", "title": "Design and optimization methodology for 3D RRAM arrays"}, {"paperId": "a224b8378bafb0aa77e921c27b10c965830dbe5e", "title": "RRAM Crossbar Array With Cell Selection Device: A Device and Circuit Interaction Study"}, {"paperId": "dfb71b6ca1d39777250cee12b59f8dcaaf9ba794", "title": "FPGA Based on Integration of CMOS and RRAM"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "220e2ed6968d183af81001e428609fdc859b5ede", "title": "The missing memristor found"}, {"paperId": "08ccf07e211f7bba8c7808a417ee3f9e6738b69f", "title": "Memristor-The missing circuit element"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Bert and pals: Projected attention layers for efficient adaptation in multi-task learning"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "28135fd3e80dda50a673cd556f10b9b972005d27", "title": "Binarized Neural Networks"}, {"paperId": "6132ee6380390a0a78a56240e4256cd203dfabed", "title": "Fast-Write Resistive RAM (RRAM) for Embedded Applications"}]}