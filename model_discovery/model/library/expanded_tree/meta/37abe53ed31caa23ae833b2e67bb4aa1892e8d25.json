{"paperId": "37abe53ed31caa23ae833b2e67bb4aa1892e8d25", "abstract": "We propose FMMformers, a class of efficient and flexible transformers inspired by the celebrated fast multipole method (FMM) for accelerating interacting particle simulation. FMM decomposes particle-particle interaction into near-field and far-field components and then performs direct and coarse-grained computation, respectively. Similarly, FMMformers decompose the attention into near-field and far-field attention, modeling the near-field attention by a banded matrix and the far-field attention by a low-rank matrix. Computing the attention matrix for FMMformers requires linear complexity in computational time and memory footprint with respect to the sequence length. In contrast, standard transformers suffer from quadratic complexity. We analyze and validate the advantage of FMMformers over the standard transformer on the Long Range Arena and language modeling benchmarks. FMMformers can even outperform the standard transformer in terms of accuracy by a significant margin. For instance, FMMformers achieve an average classification accuracy of $60.74\\%$ over the five Long Range Arena tasks, which is significantly better than the standard transformer's average accuracy of $58.70\\%$.", "venue": "Neural Information Processing Systems", "year": 2021, "citationCount": 30, "influentialCitationCount": 2, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "FMMformers is a class of efficient and flexible transformers inspired by the celebrated fast multipole method for accelerating interacting particle simulation that can even outperform the standard transformer in terms of accuracy by a significant margin."}, "embedding": {"model": "specter_v2", "vector": [0.2593403160572052, 0.2288077026605606, -0.06652168184518814, 0.2197997123003006, -0.5716724991798401, -0.05215995013713837, 0.7101988196372986, -0.1183483749628067, -0.5080427527427673, 0.07942995429039001, 0.687263548374176, -0.2146475464105606, 0.005043948069214821, -0.14867348968982697, -0.6493721008300781, -0.42074939608573914, -0.8606083393096924, 0.5068198442459106, -0.30622780323028564, -0.5103012323379517, 0.06931965053081512, -0.22533506155014038, -1.2307676076889038, 0.23085013031959534, 0.8359546065330505, 0.6341282725334167, 0.13356567919254303, 1.016667366027832, -0.24904894828796387, 0.27690282464027405, 0.8286065459251404, -0.08996330946683884, 0.3035131096839905, 0.16336755454540253, -0.7256404161453247, -0.3457529544830322, -0.06820031255483627, -0.19273538887500763, -0.5909084677696228, 0.9716887474060059, -0.3484451472759247, 0.6052860021591187, 0.6833749413490295, -0.5652092695236206, -0.21306785941123962, 0.4097568392753601, 0.4456694722175598, 0.9909035563468933, 0.14272461831569672, -0.34106793999671936, 1.2720907926559448, -1.5919225215911865, 0.2770029902458191, 1.311296820640564, 0.5666418671607971, 0.08019015938043594, -0.31977373361587524, -0.5207844376564026, 0.43299683928489685, 0.15748319029808044, -0.5085991024971008, -0.22418390214443207, -0.23183174431324005, -0.6062375903129578, 1.5095131397247314, -0.12824805080890656, 0.23309318721294403, 0.6113532185554504, 0.6448498368263245, 0.9667088389396667, 0.1399790197610855, -0.7581166625022888, 0.12340965121984482, -0.04393994063138962, 0.5597980618476868, 0.5052098631858826, -0.26366958022117615, 0.531266450881958, -0.9795390367507935, -0.5151812434196472, 0.19581645727157593, 0.202649787068367, 0.21474403142929077, -0.1548323631286621, -0.4927709698677063, 0.6744699478149414, 0.48754099011421204, 0.6655706167221069, -0.3757058084011078, 0.43220293521881104, 0.7293996810913086, -0.18476517498493195, 0.38433223962783813, 0.12714441120624542, 0.46712085604667664, 0.09284844249486923, -0.49599915742874146, 0.6754130721092224, -0.077445849776268, 0.5504099726676941, -0.1423986405134201, -0.08046761155128479, -0.8228293061256409, -0.19916008412837982, 1.4337575435638428, 0.59043949842453, 0.025054359808564186, -0.5988094806671143, -0.06650149822235107, -0.7861222624778748, 0.42560163140296936, -0.6330658197402954, -0.09510387480258942, -0.30669379234313965, -1.1392877101898193, -0.5285005569458008, -0.3715847432613373, 0.44497090578079224, -0.44726431369781494, 0.23065435886383057, 0.09380679577589035, 0.4413618743419647, 0.08803068101406097, 0.6274884343147278, 0.6147365570068359, 0.9028143286705017, 0.011838522739708424, 0.004123887978494167, 1.0792983770370483, -1.1506755352020264, -0.6443624496459961, -1.173774242401123, 0.20428277552127838, -0.725460946559906, 0.26040613651275635, -0.2730415463447571, -1.2697087526321411, -1.020326852798462, -0.6863784790039062, 0.12438566982746124, -0.48609694838523865, -0.27838435769081116, 1.4270962476730347, -0.366555392742157, -0.7468186616897583, 0.6802543997764587, -0.38481247425079346, -0.11606891453266144, 0.28229114413261414, 0.3611757457256317, 0.1489683985710144, -0.2961583137512207, -1.3146724700927734, 0.3508435785770416, -0.25645118951797485, -0.5794468522071838, -0.4002639055252075, -0.7313404083251953, -0.9612049460411072, 0.008341509848833084, 0.0014099309919402003, -0.6513388156890869, 1.3895878791809082, 0.08928411453962326, -1.0968354940414429, -0.08834205567836761, -0.42650389671325684, -0.0635550394654274, 0.25242915749549866, -0.10698705911636353, -0.4938563108444214, -0.3501921594142914, 0.313697874546051, 0.2915896475315094, 0.32396823167800903, -0.3132711350917816, -0.096026211977005, 0.07439426332712173, -0.1323709487915039, 0.11748434603214264, -0.10593153536319733, 0.6864460706710815, -0.03825925290584564, -0.3684791624546051, -0.18915177881717682, 0.371629536151886, -0.36907732486724854, -0.2019871324300766, 0.02440456859767437, -0.5670340061187744, 0.8871952295303345, 0.18114133179187775, 0.5971593856811523, -0.8105053901672363, -0.6021554470062256, -0.03457551449537277, 0.1548868864774704, -0.3091064691543579, -0.4265088737010956, 0.7322950959205627, -0.4740257263183594, -0.3749576807022095, -0.03933022916316986, -0.4093559682369232, -0.21203400194644928, -0.29661837220191956, -1.099403977394104, -0.14978495240211487, -0.14696219563484192, 0.850319504737854, -1.245033621788025, 0.10668181627988815, 0.029510216787457466, 0.7796934843063354, -0.9843698740005493, 0.9156903028488159, -0.18170760571956635, 0.5826358199119568, -0.21255604922771454, -0.6535056233406067, 0.3772018253803253, -0.8660190105438232, 0.12382258474826813, -0.39989012479782104, -0.05841658264398575, 0.2702130377292633, -0.33064308762550354, 1.209800362586975, -0.29353779554367065, 0.4256136119365692, 0.38483908772468567, -0.30888909101486206, -0.14467380940914154, 0.21172866225242615, -0.018115337938070297, -0.5838940739631653, 0.24522802233695984, 0.3093455135822296, -0.4606396555900574, 0.5683558583259583, 0.7462320327758789, 0.68968665599823, -0.11688727885484695, 0.46560510993003845, 0.35576462745666504, 0.21922263503074646, 0.5670955777168274, 0.48053234815597534, 0.6005898714065552, 0.4427981376647949, 0.40189751982688904, -0.6910292506217957, 0.38890478014945984, -0.8747562170028687, -0.6606408953666687, 0.6362572908401489, 0.5739304423332214, 0.2729107737541199, -0.2485545426607132, -1.027006983757019, -0.2684367001056671, -0.02310721017420292, 0.6549265384674072, 1.5567207336425781, 0.14584530889987946, -0.20914915204048157, -0.8951622247695923, -0.41094866394996643, -0.2900054454803467, -0.06746307015419006, -0.39631596207618713, -0.25554901361465454, -0.21326173841953278, -1.2852416038513184, 0.5085434317588806, 0.6299729347229004, 0.8930637836456299, -0.4792810082435608, -0.3032143712043762, -0.5555676221847534, 0.1034480482339859, -0.6029000282287598, -0.6715260744094849, 0.27420833706855774, -0.04002083092927933, 0.02288912795484066, 0.024835458025336266, 0.09932457655668259, 0.22321952879428864, -0.21069522202014923, 0.7263327836990356, -0.34033212065696716, -0.310985267162323, 0.2912580072879791, 0.7505913376808167, -0.5079260468482971, -0.7197901010513306, -0.0005126315518282354, 0.40522757172584534, 0.07714048027992249, 0.15230244398117065, 0.09636197239160538, -0.1329721063375473, 0.031830377876758575, -0.28732728958129883, 0.2205207347869873, -0.013353019021451473, 0.06472481042146683, 0.30158862471580505, -0.6214625835418701, -0.3874203860759735, -0.8343355059623718, 0.8342141509056091, 0.2381373941898346, -0.5310868620872498, -0.26355287432670593, -0.6725289225578308, -0.18384601175785065, 0.6593986749649048, -0.6735833883285522, -0.3855522572994232, -0.9884069561958313, 0.020063025876879692, 0.22216644883155823, -0.16599240899085999, -0.024818774312734604, 0.5133026242256165, -0.3295646905899048, 0.5989152789115906, 0.31873324513435364, 0.4222259819507599, -0.01917431503534317, 0.27691853046417236, -0.8542627096176147, 0.24670805037021637, -0.001127244671806693, 0.35899266600608826, 0.43359097838401794, -0.014578689821064472, -0.5831301808357239, -0.5473921895027161, -0.3091757893562317, -0.04715215414762497, -0.7307435274124146, 0.11920475214719772, -0.3959759473800659, -1.4116904735565186, -0.13133159279823303, -1.332837462425232, -0.021552223712205887, 0.14275914430618286, 0.11404833197593689, -0.21572139859199524, -0.9896939992904663, -1.2547260522842407, -0.6508353352546692, -0.9697917699813843, -1.4225335121154785, 0.6758575439453125, -0.17928990721702576, -0.5020729303359985, -0.5141680836677551, 0.12295710295438766, -0.2582135498523712, 1.1329553127288818, -0.7285611033439636, 0.7320535182952881, -0.12463288009166718, -0.5078151226043701, -0.14908146858215332, -0.024694029241800308, -0.11432607471942902, -0.5318723320960999, 0.05131258815526962, -0.6978921294212341, 0.01586337387561798, -0.24312126636505127, 0.10533290356397629, 0.10655663907527924, 0.3854774236679077, 0.6780358552932739, -0.1408703774213791, -1.0702401399612427, 0.03730481117963791, 1.0749608278274536, -0.34446486830711365, 0.09434998035430908, 0.28815823793411255, 1.0147120952606201, -0.1039796769618988, 0.11068999022245407, 0.7169154286384583, 0.1526942253112793, 0.35262367129325867, -0.033053237944841385, -0.24237269163131714, 0.13251952826976776, -0.17684555053710938, 0.5598114728927612, 1.7866370677947998, -0.007282122038304806, -0.06582552194595337, -1.1493860483169556, 0.2207680195569992, -1.563689112663269, -1.0017077922821045, 0.7588558197021484, 0.6203828454017639, -0.10200495272874832, -0.294551283121109, -0.16920165717601776, 0.013900347985327244, 0.5729939341545105, 0.3996018171310425, -0.3727134168148041, -0.3392612040042877, 0.23896753787994385, 0.312507301568985, -0.01559812854975462, 1.1462870836257935, -0.1647292822599411, 0.31008023023605347, 15.168664932250977, 1.165815830230713, 0.13950590789318085, 0.6185895800590515, 0.9925020337104797, 0.44092825055122375, -0.5315948724746704, 0.013359492644667625, -1.1495051383972168, -0.11083421111106873, 1.1193431615829468, 0.06488148123025894, 0.7627533674240112, 0.212713822722435, -0.024150682613253593, 0.2316741794347763, -0.3414798080921173, 0.4726502299308777, 0.3053552210330963, -1.6583696603775024, 0.7326728701591492, 0.4116358458995819, -0.052080899477005005, 0.4763578176498413, 0.7703725099563599, 0.6671022176742554, 0.45717325806617737, -0.8024076819419861, 0.30930742621421814, 0.4243658781051636, 0.9431541562080383, -0.4127713441848755, 0.4864291548728943, 0.4148775637149811, -1.2134253978729248, -0.08005056530237198, -0.35855183005332947, -1.6906901597976685, 0.018735673278570175, 0.5036874413490295, -0.27171090245246887, -0.5823660492897034, 0.17312414944171906, 0.736723005771637, 0.5616346001625061, 0.13736531138420105, 0.7390334010124207, 0.38595303893089294, 0.0007130534504540265, -0.02920752950012684, 0.26767051219940186, 0.15999262034893036, 0.49682867527008057, -0.18390604853630066, 0.16733650863170624, -0.09985725581645966, 0.40708455443382263, 0.24612288177013397, 0.002551838057115674, -0.1291881650686264, -0.48651188611984253, -0.07036617398262024, -0.2864774167537689, 1.1806823015213013, 0.1742381453514099, 0.5160236358642578, -0.4360581338405609, 0.025028539821505547, 0.5177515149116516, 0.18028755486011505, -0.43403130769729614, -0.1352425515651703, 0.5422431230545044, 0.002674550749361515, -0.13803444802761078, 0.6190482974052429, -0.198795884847641, -0.2177462875843048, -0.9000502228736877, -0.6889838576316833, -0.05565749853849411, -0.8339836001396179, -1.026529312133789, 1.0458015203475952, -0.17474140226840973, -0.27191030979156494, 0.5437465906143188, -0.8360196948051453, -0.467573881149292, 0.15074186027050018, -0.8926079869270325, -0.8911083936691284, 0.48958253860473633, -0.38349929451942444, -0.6588242053985596, 0.09736853837966919, 1.1244186162948608, 0.3443625569343567, 0.23740148544311523, -0.24428147077560425, 0.3155410885810852, 0.03250230476260185, -0.2961333692073822, -0.7144609689712524, 1.0519040822982788, 0.2229498028755188, -0.02466817945241928, 0.516697108745575, 0.5755436420440674, -0.04750317335128784, -0.9845402240753174, -0.0209592804312706, 0.3907720446586609, -0.9741527438163757, -0.13725443184375763, -1.2371835708618164, -0.8792518973350525, -0.00520617188885808, 0.6058666110038757, 0.3407942056655884, 0.3897172808647156, 0.006340254098176956, -0.3394134044647217, -0.36456018686294556, -0.5919237732887268, 0.16143575310707092, 0.5580525994300842, -0.8686873316764832, 0.1470346450805664, 0.35892605781555176, 0.2647515833377838, -1.2244999408721924, -0.1800752729177475, -0.14543528854846954, 0.265424907207489, -0.3311306834220886, 1.416422963142395, -0.11925670504570007, 0.6150290369987488, 0.6230649352073669, -0.12132643908262253, -0.7963676452636719, -0.3851461708545685, -1.079729676246643, -0.07795209437608719, -0.09985627979040146, 0.41161617636680603, -0.4756646156311035, 0.02209337055683136, 0.5597177147865295, 0.5576080679893494, -0.7022368907928467, -0.6934673190116882, 0.14587874710559845, -0.05918547883629799, -0.5961090326309204, 0.55372554063797, -0.44992440938949585, 0.214751735329628, 0.34534773230552673, 0.5498677492141724, 0.663285493850708, -0.07257597893476486, -0.2694054841995239, 0.07080528885126114, -0.27223625779151917, -0.150136798620224, -0.3591441512107849, -0.3186710476875305, -1.2565232515335083, -0.08256097882986069, -1.1893900632858276, 0.041926268488168716, -0.842920184135437, 0.080082006752491, 0.4325917959213257, -0.1625426858663559, -0.29771509766578674, 0.1942729502916336, 0.13031043112277985, -0.6856802701950073, -0.8538261651992798, -1.009899377822876, 0.822647750377655, 1.0808583498001099, -0.7440631985664368, 0.6590884923934937, -0.1701996624469757, -0.11633116006851196, 0.639666736125946, 0.06635931134223938, -0.2957594394683838, -0.5106233358383179, -0.6584462523460388, 0.47694528102874756, -0.04366161674261093, 0.3396053612232208, -0.9289939403533936, 0.7714846730232239, 0.32761627435684204, 0.2146940976381302, 0.11697914451360703, 0.48209550976753235, -0.7743226885795593, -0.34898948669433594, 0.500643789768219, -0.6821770071983337, 0.417917400598526, 0.2725999653339386, -0.3014696538448334, 0.041994545608758926, 0.9965874552726746, 0.02275397814810276, -0.9876071810722351, 0.11734078079462051, 0.6527711153030396, -1.0538673400878906, 0.46125176548957825, -0.15948526561260223, 0.07395508885383606, -0.8773108124732971, -0.5385172963142395, -0.011940053664147854, -0.0959877073764801, -0.33405908942222595, 0.6357653737068176, 0.21168720722198486, -1.433504581451416, 0.3746298849582672, 0.3887995183467865, -0.33574795722961426, -0.2853904068470001, 0.5787779092788696, 0.33518293499946594, 0.17985033988952637, 0.4603176414966583, 0.25677037239074707, 0.23024234175682068, -0.9455804228782654, 0.2387964427471161, 0.4921766221523285, -0.7999974489212036, -0.19404202699661255, 0.8185908198356628, 0.07975993305444717, -1.0968363285064697, -0.13219721615314484, -0.9098525643348694, -0.6952203512191772, -0.583441972732544, 1.117983341217041, 0.716960608959198, 0.049993980675935745, -0.5195878744125366, -0.7493340373039246, 0.40882590413093567, -0.27022647857666016, -0.7584642171859741, 0.4017627239227295, -0.1166001483798027, -0.458590567111969, 0.33964017033576965, 0.19891613721847534, -0.05209475755691528, -0.4716516137123108, -0.4349519610404968, -0.7959100604057312, -0.1823829561471939, 0.26940247416496277, -0.28953468799591064, -0.21018081903457642, 0.6744063496589661, 0.7285370230674744, 0.5987656116485596, -0.19654706120491028, -0.28562307357788086, 0.5455266833305359, 0.721936047077179, 0.34651386737823486, -0.35114383697509766, -0.6692993640899658, 1.4062185287475586, 1.1421751976013184, -0.5375736951828003, 0.29154911637306213, -0.26292893290519714, -0.8082095980644226, 0.6862990856170654, 0.4551561772823334, -0.060673344880342484, 1.0778487920761108, 0.49017783999443054, 0.11415627598762512, 0.1500827968120575, -0.7748329639434814, -0.12478335946798325, 1.1058354377746582, 1.1490439176559448, 0.5511507987976074, -0.018029166385531425, 0.32608315348625183, 0.8385288119316101, 0.46578559279441833, 0.18389827013015747, 0.38884127140045166, 0.42012351751327515, -0.08463377505540848, 0.11878501623868942, -0.3748804032802582, 0.6788316369056702, -0.5557783246040344, -0.6214773058891296, 0.46491968631744385, 0.31922397017478943, 0.12204799801111221, 0.39649391174316406, 0.5984293222427368, 0.2357361614704132, -0.026607073843479156, -0.01946999691426754, 0.4462885558605194, -0.1562948226928711, -0.3682553470134735, -0.23345303535461426, -0.7879035472869873, -0.22523370385169983, -0.27867528796195984, -0.2693536877632141, -0.8100166916847229, -0.5012426376342773, 0.2513481378555298, 0.8228304386138916, -0.2572515308856964, 1.603054404258728, 1.0112818479537964, 0.519629180431366, -0.7224829196929932, -1.4514176845550537, -0.23655648529529572, -0.7580927014350891, 0.19462168216705322, -0.7122765779495239, 0.015634234994649887, -0.5305914878845215, -0.20732051134109497, -0.6662588715553284]}, "authors": [{"authorId": "150322732", "name": "T. Nguyen"}, {"authorId": "2122780198", "name": "Vai Suliafu"}, {"authorId": "1782265", "name": "S. Osher"}, {"authorId": "71063171", "name": "Long Chen"}, {"authorId": "70994653", "name": "Bao Wang"}], "references": [{"paperId": "72f207c777e4a17180cc54ccc6a743d5f43227af", "title": "Choose a Transformer: Fourier or Galerkin"}, {"paperId": "1f133158a8973fb33fea188f20517cd7e69bfe7f", "title": "FNet: Mixing Tokens with Fourier Transforms"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "cec7872b194aadf54140578b9be52939eb1112e9", "title": "LambdaNetworks: Modeling Long-Range Interactions Without Attention"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "35a9749df07a2ab97c51af4d260b095b00da7676", "title": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting"}, {"paperId": "5e11e806d24dd80ecf0f91e7aacedbba8d9fd6fc", "title": "Learning Associative Inference Using Fast Weight Memory"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "cd4ffe5e014601a3d6b64121355d29a730591490", "title": "Fast Transformers with Clustered Attention"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "a32ed7f632e087c92ecd8f7a1080cba23aa6ea99", "title": "Implicit Kernel Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d", "title": "ETC: Encoding Long and Structured Inputs in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "199ff73d2f728e997f860b62a2322823d3e3d9e8", "title": "Designing and Interpreting Probes with Control Tasks"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "2a687609ac1cecb9b20ba52d4f5d72ba14e0eaf2", "title": "Sampled Softmax with Random Fourier Features"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "95a251513853c6032bdecebd4b74e15795662986", "title": "What Does BERT Look at? An Analysis of BERT\u2019s Attention"}, {"paperId": "a039ea239e37f53a2cb60c68e0a1967994353166", "title": "Analyzing the Structure of Attention in a Transformer Language Model"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "97906df07855b029b7aae7c2a1c6c5e8df1d531c", "title": "BERT Rediscovers the Classical NLP Pipeline"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "5f4a22ee70ca613d9c0630eafc96364fe365fdf8", "title": "Efficient Attention: Attention with Linear Complexities"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "fb507ada871d1e8c29e376dbf7b7879689aa89f9", "title": "Music Transformer: Generating Music with Long-Term Structure"}, {"paperId": "b9de9599d7241459db9213b5cdd7059696f5ef8d", "title": "Character-Level Language Modeling with Deeper Self-Attention"}, {"paperId": "0d3c46a3cbfe06cec259fec954b6ff6df6c1a566", "title": "Learning long-range spatial dependencies with horizontal gated-recurrent units"}, {"paperId": "8b354d76813bd5375e7e5c8d17f630bec5936a01", "title": "ListOps: A Diagnostic Dataset for Latent Tree Learning"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "1bf64f0961da08ea0f9941bd899e916a385e9540", "title": "Adaptive Sampled Softmax with Kernel Based Sampling"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "204a4a70428f3938d2c538a4d74c7ae0416306d8", "title": "A Structured Self-attentive Sentence Embedding"}, {"paperId": "13d9323a8716131911bfda048a40e2cde1a76a46", "title": "Structured Attention Networks"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "2cd8e8f510c89c7c18268e8ad51c061e459ad321", "title": "A Decomposable Attention Model for Natural Language Inference"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e", "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"}, {"paperId": "558b807a5c08f95e6337209a7276172dde295920", "title": "A distributed kernel summation framework for general\u2010dimension machine learning"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "7613796ad094e7e17efc789c35a9e3301ed712ce", "title": "Fast algorithms for hierarchically semiseparable matrices"}, {"paperId": "e01eae8dea6fbaa1ae7fc83535053932268df430", "title": "The ACL anthology network corpus"}, {"paperId": "1f09a309f75e2d87f0ea045e07a9373a46c13c4e", "title": "A Fast ULV Decomposition Solver for Hierarchically Semiseparable Representations"}, {"paperId": "7826ff60d2dfb24d2af18c5bc565c357ef9db4c1", "title": "A stochastic version of the delta rule"}, {"paperId": "688384fc5e643445e835435e96b9dfcfb6598d36", "title": "A fast algorithm for particle simulations"}, {"paperId": "b48694cb275eba60b48026f3159373c92c1b286c", "title": "Functions of Positive and Negative Type, and their Connection with the Theory of Integral Equations"}, {"paperId": "2ff74d426e712522030057624510c03713fa77ba", "title": "Linear Transformers Are Secretly Fast Weight Memory Systems"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": "0fca9a022f4910dda7f8bdc92bbbe8a9c6e35303", "title": "Accelerating t-SNE using tree-based algorithms"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": null, "title": "Hierarchical Matrices"}, {"paperId": "d9dc4ac6390ccc88023c37a5b42ea9cf573cc7d7", "title": "A fast direct solver for boundary integral equations in two dimensions"}, {"paperId": "9498bb96328c3e9498772241b55031570e6577d1", "title": "Digital Object Identifier (DOI) 10.1007/s00607-002-1450-4 Data-sparse Approximation by Adaptive H 2-Matrices"}, {"paperId": "93c473358b063cec9bb9ea7cb3036bbce7b76493", "title": "'N-Body' Problems in Statistical Learning"}, {"paperId": "952896a6656080d1a0e021733bfaa237dd53f832", "title": "A Sparse Matrix Arithmetic Based on H-Matrices. Part I: Introduction to H-Matrices"}, {"paperId": "8b6a0a574766d024083bc84e5cfe0192966cdf15", "title": "Philosophical transactions of the Royal Society of London. Series A, Containing papers of a mathematical or physical character"}, {"paperId": null, "title": "The best of the 20th century: Editors name top 10 algorithms"}, {"paperId": null, "title": "On H 2 -matrices"}]}