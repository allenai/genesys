{"paperId": "339ec34efdccdf2bf43bb817ef7cab5058bfa2e7", "abstract": "We propose a method to efficiently equip the Segment Anything Model (SAM) with the ability to generate regional captions. SAM presents strong generalizability to segment anything while is short for semantic understanding. By introducing a lightweight query-based feature mixer, we align the region-specific features with the embedding space of language models for later caption generation. As the number of trainable parameters is small (typically in the order of tens of millions), it costs less computation, less memory usage, and less communication bandwidth, resulting in both fast and scalable training. To address the scarcity problem of regional caption data, we propose to first pre-train our model on objection detection and segmentation tasks. We call this step weak supervision pretraining since the pre-training data only contains category names instead of full-sentence descriptions. The weak supervision pretraining allows us to leverage many publicly available object detection and segmentation datasets. We conduct extensive experiments to demonstrate the superiority of our method and validate each design choice. This work serves as a stepping stone towards scaling up regional captioning data and sheds light on exploring efficient ways to augment SAM with regional semantics. The project page, along with the associated code, can be accessed via https://xk-huang.github.io/segment-caption-anything/.", "venue": "arXiv.org", "year": 2023, "citationCount": 2, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A method to efficiently equip the Segment Anything Model (SAM) with the ability to generate regional captions by introducing a lightweight query-based feature mixer that aligns the region-specific features with the embedding space of language models for later caption generation."}, "embedding": {"model": "specter_v2", "vector": [-0.2697566747665405, 0.8872982859611511, -0.8235352635383606, -0.24973119795322418, -0.4774787724018097, -0.5563072562217712, 0.6952137351036072, 0.06081119179725647, -0.4475589096546173, -0.5898385047912598, 0.7908313870429993, 0.3711402118206024, 0.7258960008621216, 0.23034508526325226, -0.44906914234161377, 0.5173574686050415, -0.5272611975669861, 0.5149357318878174, 0.3918606638908386, -0.30201199650764465, -0.11584138125181198, -0.8159356117248535, -0.895928680896759, 0.32026445865631104, 0.4205816090106964, 0.3540729284286499, 0.2611824870109558, 1.0265462398529053, -0.3642538785934448, 0.18336696922779083, 0.014858501963317394, -0.2267111837863922, 0.04750534147024155, -0.3046926259994507, -0.4711962938308716, 0.0812644511461258, 0.5818557739257812, -0.6339611411094666, -0.3936176300048828, 0.6360018253326416, -0.1573537439107895, 0.28813374042510986, 0.4697425365447998, -0.6890659928321838, -0.5132074952125549, 1.1234619617462158, 0.5512723922729492, 0.4795016050338745, -0.10739002376794815, -0.9887810945510864, 1.4715670347213745, -1.8488726615905762, 0.8219733834266663, 1.7695481777191162, 0.29519379138946533, 0.6309464573860168, 0.2356555461883545, -0.31785207986831665, 1.2088197469711304, 0.18900516629219055, -1.0220227241516113, -0.3181295096874237, -0.17530401051044464, -0.1143341064453125, 1.538650393486023, -0.4273303151130676, -0.0006099658203311265, 0.5931490063667297, -0.6346144080162048, 2.102252721786499, -0.6538144946098328, -0.5801764726638794, -0.4436776340007782, 0.34565111994743347, 0.2907564043998718, 0.4996856451034546, -0.5452457070350647, -0.20562845468521118, -0.48574525117874146, 0.3113403022289276, 0.3217795193195343, -0.23033997416496277, -0.016125008463859558, -0.24293507635593414, -0.4306916892528534, 0.6522040367126465, 0.8273086547851562, 0.6826564073562622, 0.055531080812215805, 0.6168585419654846, 0.49925193190574646, -0.2536298334598541, -0.05052475258708, 0.30436810851097107, -0.3669617772102356, 0.7704237699508667, -1.1102102994918823, 0.34245383739471436, 0.019070595502853394, 1.1236852407455444, -0.5855770707130432, -0.07341401278972626, -0.9594403505325317, 0.200168639421463, 1.334554672241211, 0.01628255844116211, 0.47635945677757263, -0.7065191268920898, 0.47528254985809326, -0.6367829442024231, 0.5918590426445007, -0.6719310283660889, -0.47483548521995544, -0.49073079228401184, 0.04951316863298416, -1.637113332748413, -0.3259470760822296, -0.06553541123867035, -1.1452713012695312, 0.8866979479789734, 0.09302714467048645, 0.08251117169857025, 0.014619292691349983, 0.7312637567520142, 1.242199182510376, 0.9471709728240967, 0.5521994829177856, 0.4697999954223633, 1.1717021465301514, -1.2948075532913208, -0.4111631214618683, -1.0612918138504028, 0.8544053435325623, -0.12548311054706573, 0.14520418643951416, -0.7097674608230591, -0.8467498421669006, -1.4046745300292969, -1.0412139892578125, -0.26668810844421387, -0.9572519659996033, 0.9466433525085449, 0.665186882019043, 0.46156612038612366, -1.08492910861969, 0.3692285120487213, -0.20375290513038635, -0.7183185815811157, 0.32520943880081177, -0.1039312332868576, 0.1469544768333435, -0.2687111496925354, -1.0423078536987305, 0.3204270601272583, 0.14100000262260437, -0.18918615579605103, -0.25508323311805725, -0.18845221400260925, -1.6060607433319092, -0.2781234383583069, 0.28047898411750793, -0.2957178056240082, 1.151873230934143, -0.5730885863304138, -0.5686482191085815, 0.9022353887557983, -0.6246141195297241, -0.09153610467910767, 0.5090879797935486, -0.5420504808425903, -0.502381443977356, -0.0196029394865036, 0.08781906217336655, 1.1463793516159058, 0.5452204942703247, -0.38808420300483704, -0.24854251742362976, 0.1281491219997406, -0.3245401382446289, 0.1705394983291626, -0.12393254041671753, 1.3960365056991577, -0.4418628513813019, -0.2953745126724243, 0.7533796429634094, 0.5069854259490967, 0.25852659344673157, -0.0703120082616806, -0.9464463591575623, -1.2017393112182617, 1.054955005645752, -0.27076104283332825, 0.29713985323905945, -0.8288387656211853, -0.6540880799293518, -0.7876576781272888, -0.3333338499069214, -0.09586390852928162, -1.0924102067947388, 0.5054172277450562, -0.3731900751590729, 0.7798015475273132, 0.04939449578523636, -1.1543190479278564, 0.18448415398597717, -0.5707002878189087, -0.583001434803009, -0.09537329524755478, 0.6716525554656982, 1.487870216369629, -0.4758874475955963, -0.13336730003356934, -0.0359286367893219, 0.18551522493362427, -0.750193178653717, 0.8750027418136597, -0.5981875061988831, 0.14721935987472534, -0.8048994541168213, 0.10565833002328873, 0.14346571266651154, 0.12496979534626007, 0.1796102374792099, -0.3632103502750397, -0.02193664386868477, 0.4179135859012604, -0.512405514717102, 1.0668359994888306, 0.3253271281719208, 0.552026629447937, -0.19431078433990479, -0.9080607891082764, 0.33091625571250916, 0.3593917191028595, -0.18615591526031494, -0.42238062620162964, 0.4312244653701782, 0.44374439120292664, -0.9801468849182129, -0.01813340000808239, 1.0543898344039917, 0.6881293654441833, -0.728981077671051, -0.08052831143140793, 0.5169470906257629, -0.3654369115829468, 0.27541300654411316, 0.7051559090614319, 0.5057696104049683, 0.668973445892334, -0.01970447413623333, -0.004481432028114796, 0.21478943526744843, -0.360571026802063, 0.10441266745328903, 0.3892289400100708, 0.3358043432235718, 1.5934611558914185, 0.5455838441848755, -0.723201334476471, -0.39106568694114685, 0.026422126218676567, 0.6221951246261597, 1.5275421142578125, 0.4975183606147766, -0.1612020581960678, -1.167494773864746, -0.8749220967292786, -0.40523263812065125, 0.0764479711651802, -0.4053506553173065, 0.17961566150188446, -0.6215200424194336, -0.7541738152503967, 0.45480072498321533, 0.5804797410964966, 0.9571565389633179, -0.8527237176895142, 0.03672074154019356, -0.2597164809703827, -0.3341468274593353, -1.1321280002593994, -0.5559068322181702, 0.08324336260557175, -0.1835440993309021, -0.11208853870630264, -0.33870258927345276, -0.7846229076385498, 0.4110035002231598, -0.7605434656143188, 1.1217308044433594, -0.37490972876548767, -0.28362104296684265, 0.20290887355804443, -0.056820277124643326, -0.5806599855422974, -0.6186914443969727, 0.3161439001560211, 0.08102630823850632, -0.19257371127605438, 0.3339242935180664, 1.0494937896728516, -0.05908134952187538, 0.3248867690563202, -0.42250779271125793, 0.24688896536827087, 0.004378299228847027, -0.6117852926254272, 1.0312050580978394, -0.6624809503555298, 0.5640554428100586, -0.974053680896759, 0.322756290435791, -0.2542732059955597, 0.048640716820955276, 0.3175314962863922, 0.27755972743034363, -0.6381072998046875, 0.2288903445005417, -0.4316960871219635, -0.05864613503217697, -0.30822768807411194, 0.4521820843219757, -0.27933269739151, -0.42246440052986145, 0.08549197763204575, -0.032635193318128586, 0.8339438438415527, 0.3502157926559448, 0.3325817584991455, -0.19430387020111084, -0.29910019040107727, 0.8893359899520874, -0.7842310070991516, 0.8054243326187134, 0.3858177661895752, 0.1368340402841568, 0.09129136800765991, -0.607995867729187, -0.6987226009368896, -0.555658757686615, -0.7514421939849854, -0.673534095287323, -0.4275003969669342, 0.5587231516838074, -0.8598477840423584, -0.28586187958717346, -0.2087431699037552, -1.2098325490951538, 0.032945986837148666, -0.10354911535978317, -0.49769285321235657, -0.3325032591819763, -1.0449550151824951, -0.9826333522796631, -0.13480983674526215, -0.04959224909543991, -0.48461514711380005, 0.7469162344932556, 0.41194576025009155, -0.3988971412181854, -0.23580561578273773, 0.006150822155177593, -0.02049543336033821, 0.5784071087837219, -0.003385835560038686, 0.39019477367401123, -0.5794320106506348, -0.5435860753059387, -0.8505001664161682, -0.062281329184770584, 0.7287688255310059, -0.43368232250213623, 0.3054579794406891, -0.3480013310909271, 0.17351166903972626, -0.2661818265914917, -0.41068750619888306, 0.39793962240219116, 0.4809516668319702, 0.45952630043029785, 0.11734121292829514, -0.8371182680130005, 0.06229019537568092, 1.4855846166610718, -1.0660045146942139, -0.020869504660367966, 0.05672420561313629, 0.9625037312507629, 0.822806179523468, 0.02355783060193062, 0.2109781801700592, 0.756640613079071, 0.2694413661956787, 0.3073738217353821, -0.3893415629863739, -0.6819005608558655, -0.914309024810791, 0.6309676766395569, 1.34950852394104, 0.48139122128486633, -0.09434042870998383, -1.0469192266464233, 1.4605062007904053, -1.4295175075531006, -0.5964819192886353, 0.3085551857948303, 0.4202782213687897, -0.1553754210472107, -0.7198496460914612, 0.18204009532928467, -0.9228111505508423, 1.1037665605545044, 0.1389341950416565, -0.6018959879875183, -0.7342934608459473, 0.015756171196699142, -0.11747901141643524, -0.24395830929279327, 0.2462201565504074, -0.9256495833396912, 1.05587637424469, 14.345047950744629, 0.5460299253463745, 0.22346633672714233, 0.21471871435642242, 1.0521936416625977, 0.22166062891483307, -0.42871683835983276, -0.10102511197328568, -1.6272019147872925, -0.18007752299308777, 1.112931251525879, 0.608060896396637, 0.00016071433492470533, 0.5570487380027771, 0.5234530568122864, 0.36624637246131897, -0.4628363251686096, 0.48254603147506714, 0.9806385636329651, -0.7671859264373779, 0.45190179347991943, -0.006715154740959406, 0.39941829442977905, 0.7833334803581238, 0.8129005432128906, 1.019539475440979, 0.00460578128695488, -0.5931146740913391, 1.0913145542144775, -0.012924407608807087, 0.3509275019168854, -0.09914977103471756, 0.6341071128845215, 0.5370241403579712, -0.9674351811408997, -0.36286428570747375, -0.6432549357414246, -0.7651351690292358, 0.5280754566192627, -0.1894516795873642, -0.43566110730171204, -0.29841679334640503, -0.2659054398536682, 0.7260904908180237, -0.38260531425476074, 0.5480920076370239, -0.35622337460517883, 0.4777815341949463, -0.2933720350265503, -0.16947153210639954, 0.5203760862350464, 0.6388769149780273, 0.5571810603141785, 0.07789428532123566, 0.11657027900218964, 0.024253027513623238, 0.4817138612270355, 0.6407499313354492, -0.9064818024635315, 0.14618253707885742, -0.16971291601657867, -0.05424687638878822, 0.047657571732997894, 1.0273633003234863, -0.3597602844238281, -0.015431205742061138, -0.5518885850906372, 0.5230545401573181, 0.17282575368881226, 0.19310612976551056, -0.5537055730819702, -0.06474259495735168, -0.10803842544555664, 0.02220558375120163, 0.5278095006942749, 0.44156837463378906, 0.04602336883544922, -0.8233778476715088, -0.14101026952266693, 0.30691617727279663, 0.2955443859100342, -0.9262213110923767, -0.8299912214279175, 0.7457184195518494, -0.25156912207603455, -1.0066500902175903, -0.12557335197925568, -0.3570132553577423, -0.5116777420043945, -0.050618767738342285, -1.4329556226730347, -1.3698827028274536, 0.01941835507750511, -0.1989431083202362, 0.15032576024532318, 0.5981298685073853, 0.7951115965843201, -0.4635404348373413, -0.3292662799358368, -0.03290305659174919, -0.13032932579517365, 0.6073030233383179, -0.2581276297569275, -0.9887954592704773, 0.7132643461227417, 0.4106043875217438, 0.2105492353439331, -0.022515231743454933, 0.19830872118473053, -0.02061140164732933, -0.23368072509765625, -0.28088751435279846, 0.6893280744552612, -1.0732316970825195, -0.7908657789230347, -0.6225341558456421, -0.7648545503616333, 0.43684348464012146, 0.6291632056236267, 0.37531760334968567, 0.17723985016345978, 0.1967012733221054, -0.5966920256614685, 0.3124408721923828, -1.1379424333572388, -0.24019142985343933, 0.3442915380001068, -0.49918535351753235, -0.6187462210655212, 0.1759626269340515, 0.6459431052207947, -0.5522147417068481, -0.01829265058040619, -0.36762678623199463, 0.043734073638916016, 0.130502849817276, 0.9608394503593445, -0.7527974247932434, 0.741076648235321, 0.3002490699291229, -0.336210161447525, -0.7608312368392944, 0.31373319029808044, -0.5956719517707825, 0.16606278717517853, 0.6171048879623413, 1.1008676290512085, 0.07416167110204697, 0.5028682351112366, 0.9584500193595886, 0.2953542172908783, -0.2785583734512329, -0.4443850815296173, -0.4800173044204712, 0.5948172807693481, -0.2813848555088043, -0.05151135474443436, -0.06076688691973686, -0.2070920616388321, 0.1809493899345398, 0.891494870185852, 0.65741366147995, -0.23240868747234344, -0.5790242552757263, 0.4311831593513489, 0.12923863530158997, 0.17801295220851898, -0.295357346534729, -0.6697789430618286, -1.5332732200622559, -0.029243063181638718, -1.0938054323196411, 0.4178496301174164, -1.4910961389541626, -0.03786347806453705, 0.5133650898933411, -0.2903836965560913, 0.1763138473033905, 0.35145190358161926, -0.16105303168296814, 0.04012477025389671, -0.4902283251285553, -1.0461217164993286, 0.7090703248977661, 1.15887451171875, -0.836871862411499, -0.07037816196680069, 0.05014362186193466, -0.2858155071735382, 0.48279789090156555, 0.30632296204566956, -0.3426792025566101, -0.6561884880065918, -1.236776351928711, 0.3849353492259979, -0.08486991375684738, 0.02180989272892475, -0.7049604654312134, 0.42397990822792053, 0.9645826816558838, 0.16959504783153534, -0.39631062746047974, 0.4232272505760193, -0.5011860728263855, -1.1678625345230103, -0.2985786497592926, -0.7849947810173035, -0.10175949335098267, 0.05465244874358177, -0.46288102865219116, -0.6621346473693848, 0.5515497922897339, 0.03265334665775299, -1.171317458152771, -1.0662392377853394, 0.4321518838405609, -0.2774069011211395, 0.02547057904303074, 0.18632946908473969, -0.43782949447631836, -0.9777531027793884, -0.48227959871292114, -0.5161179900169373, 0.381733775138855, -0.22031265497207642, 1.7097948789596558, 0.457292765378952, -1.234544038772583, -0.5621384978294373, -0.28159087896347046, 0.21040625870227814, 0.2733375132083893, 0.6103578805923462, 0.16025681793689728, -0.37756210565567017, 0.42208245396614075, 0.4627261459827423, 0.09508080780506134, -0.6238256096839905, 0.0509997233748436, 0.7272199392318726, 0.23523902893066406, -0.3188348114490509, 1.3569450378417969, -0.2056383639574051, -1.3686047792434692, -0.15310846269130707, -1.2368687391281128, -0.9767464995384216, 0.2238970696926117, 0.9315987825393677, -0.34510132670402527, -0.15663665533065796, -0.9322084784507751, -0.6237400770187378, 0.608478307723999, -0.11364230513572693, -0.4868946671485901, 0.7568299174308777, -0.4370242953300476, -0.25609126687049866, 0.41604819893836975, 1.0911695957183838, -0.8430129289627075, -0.9046836495399475, -0.11775724589824677, -0.34347590804100037, 0.13769227266311646, 0.00981217436492443, -0.5067391395568848, -0.3524314761161804, 0.5983385443687439, 0.43797338008880615, 0.7712522149085999, -0.10778212547302246, 0.6957143545150757, 0.30754032731056213, 0.4978688359260559, -0.014890704303979874, -1.0520228147506714, -0.23315270245075226, 0.9230833053588867, 1.4325600862503052, -0.7984550595283508, 0.05938613414764404, -0.4525738060474396, -0.7135488390922546, 0.6485329270362854, 0.33610856533050537, -0.2709888517856598, 0.7890770435333252, -0.7586374282836914, 0.08563150465488434, 0.2673596441745758, -0.5034730434417725, -0.35695043206214905, 0.5753471255302429, 1.3759876489639282, 0.4882393181324005, 0.4165196120738983, 0.015291581861674786, 0.8504540324211121, 0.17840608954429626, -0.34248465299606323, 0.7022401094436646, 0.2655860483646393, -0.6992826461791992, 0.08949263393878937, 0.11282257735729218, 0.4222334325313568, -0.5457456707954407, -0.05344707518815994, -0.3854806125164032, 0.629727840423584, 0.24521757662296295, 0.8022598028182983, 0.788377046585083, 0.5760064721107483, 0.630537211894989, 0.17270800471305847, 0.12369608879089355, -0.8154052495956421, -0.09838247299194336, -0.4510401487350464, -0.6869235038757324, -0.2643517255783081, -0.3071308732032776, -0.9505161643028259, -0.9157549738883972, 0.34301528334617615, 0.21796050667762756, -0.3774610459804535, 0.8419176340103149, 1.2975221872329712, 0.8384954333305359, 0.38944298028945923, -0.27366799116134644, -0.5818692445755005, -0.07259789854288101, -1.028409481048584, -0.09364171326160431, -0.12919193506240845, -0.23627527058124542, -0.19777776300907135, -0.13094639778137207, -0.1923409253358841]}, "authors": [{"authorId": "26685143", "name": "Xiaoke Huang"}, {"authorId": "2124948371", "name": "Jianfeng Wang"}, {"authorId": "35299091", "name": "Yansong Tang"}, {"authorId": "2265188183", "name": "Zheng Zhang"}, {"authorId": "2265087734", "name": "Han Hu"}, {"authorId": "2240226596", "name": "Jiwen Lu"}, {"authorId": "29957038", "name": "Lijuan Wang"}, {"authorId": "2251726216", "name": "Zicheng Liu"}], "references": [{"paperId": "28c2a8cd598dbb7651f29402e808e90977696bf6", "title": "Open-Vocabulary Segmentation with Semantic-Assisted Calibration"}, {"paperId": "06773ee8ba36576f1408c20e16c5a5694a84f327", "title": "Universal Segmentation at Arbitrary Granularity with Language Instruction"}, {"paperId": "124d4d374fbef2016fa9880489871a58a7450644", "title": "Improved Baselines with Visual Instruction Tuning"}, {"paperId": "604a8057fd7529eaace00e93836376f484ee3f01", "title": "Strategic Preys Make Acute Predators: Enhancing Camouflaged Object Detectors by Generating Camouflaged Objects"}, {"paperId": "659a12d71d8709c132ccd9ccd235f0024cae0239", "title": "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"}, {"paperId": "1ee8c8dd9d04247515b33775532b72df7b8ec0f3", "title": "RegionBLIP: A Unified Multi-modal Pre-training Framework for Holistic and Regional Comprehension"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "094883e42bb9a41f602c0715c1059bc431e33fb2", "title": "GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest"}, {"paperId": "3b6179c293df29e31d31cea46476f104ab6950f2", "title": "Kosmos-2: Grounding Multimodal Large Language Models to the World"}, {"paperId": "2bf1b63d4222a14f78bfcb481378c3caf9c39528", "title": "Scaling Open-Vocabulary Object Detection"}, {"paperId": "15e61063ddefcbe46d1ad5a1f4ce2e4a55e1a2ec", "title": "A Simple Framework for Text-Supervised Semantic Segmentation"}, {"paperId": "0f60d005fe77f1faee429f4e952ead5d1eebd5ce", "title": "Camouflaged Object Detection with Feature Decomposition and Edge Reconstruction"}, {"paperId": "ed67192cff934d21428fa0e2ae071eaa476dc086", "title": "Weakly-Supervised Concealed Object Segmentation with SAM-based Pseudo Labeling and Multi-scale Feature Grouping"}, {"paperId": "b6d6c33298b852cf63edac233deca70530d69a2a", "title": "PaLM 2 Technical Report"}, {"paperId": "8bd6a2a89503be083176f2cc26fabedb79238cbd", "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"}, {"paperId": "6f8b9192b1f215254ee7625d752710182c05d2f9", "title": "Caption Anything: Interactive Image Description with Diverse Multimodal Controls"}, {"paperId": "ca6a2bc279be5a3349a22bfd6866ed633d18734b", "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"}, {"paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8", "title": "Visual Instruction Tuning"}, {"paperId": "2394feb97b9ec16f6eb61907b40764bd03672971", "title": "DetCLIPv2: Scalable Open-Vocabulary Object Detection Pre-training via Word-Region Alignment"}, {"paperId": "971a8b1eebed7b73cdac896e3872dd8cbee04662", "title": "V3Det: Vast Vocabulary Visual Detection Dataset"}, {"paperId": "9e8cb8c91a0acb6e661b58ad724aa758490f2bea", "title": "Instruction Tuning with GPT-4"}, {"paperId": "7470a1702c8c86e6f28d32cfa315381150102f5b", "title": "Segment Anything"}, {"paperId": "35aba190f28b5c39df333c06ca21f46bd4845eba", "title": "Sigmoid Loss for Language Image Pre-Training"}, {"paperId": "a08b7123a7158f1a7fbbc18e8b5aaebd47980ecf", "title": "EVA-CLIP: Improved Training Techniques for CLIP at Scale"}, {"paperId": "86558ce16e961c5934cadf5e592918873ecafaea", "title": "Three ways to improve feature alignment for open vocabulary detection"}, {"paperId": "0e23c9999c2afe2e494548a77a9ad6ec23897a3b", "title": "Global Knowledge Calibration for Fast Open-Vocabulary Segmentation"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "87a3844241269670721e60401cbc8f008cc686a8", "title": "A Simple Framework for Open-Vocabulary Segmentation and Detection"}, {"paperId": "98be3a878abef9ba0fc624a6ada7b8607da26aae", "title": "CapDet: Unifying Dense Captioning and Open-World Detection Pretraining"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "641d7866db6691e22aa36de5c8ba05804233c016", "title": "Side Adapter Network for Open-Vocabulary Semantic Segmentation"}, {"paperId": "0d53981f3bc7329016ca28c2793cd58b44d38ada", "title": "IC3: Image Captioning by Committee Consensus"}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "967907503b24423b9b74621051811fcf684e3957", "title": "Generalized Decoding for Pixel, Image, and Language"}, {"paperId": "33b1dbf1ad913047b919cd090907ffc4199b4178", "title": "GRiT: A Generative Region-to-text Transformer for Object Understanding"}, {"paperId": "6334322aacd53111ff46a86e274de4c85e7f062a", "title": "Global Spectral Filter Memory Network for Video Object Segmentation"}, {"paperId": "29c2d3d77b6d6f24f4356d5ba20c1a6ab4229c76", "title": "Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP"}, {"paperId": "667bb464a348b2bc85e7a8e8159b948498850ec7", "title": "DetCLIP: Dictionary-Enriched Visual-Concept Paralleled Pre-training for Open-world Detection"}, {"paperId": "1114863be2a713a14771ccacb5c9436fb4a375e2", "title": "MaskCLIP: Masked Self-Distillation Advances Contrastive Language-Image Pretraining"}, {"paperId": "810d8caec7f15ca574e74d41d255189986f6d2cc", "title": "Learning Quality-aware Dynamic Memory for Video Object Segmentation"}, {"paperId": "1243e13254bb4ea1f71b4be8a3e4e54ffd02d2fe", "title": "Scaling Autoregressive Models for Content-Rich Text-to-Image Generation"}, {"paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a", "title": "Emergent Abilities of Large Language Models"}, {"paperId": "49b5ffebdbcbd683010a2558a19eaa9b21cd8c34", "title": "GLIPv2: Unifying Localization and Vision-Language Understanding"}, {"paperId": "60ee030773ba1b68eb222a265b052ca028353362", "title": "GIT: A Generative Image-to-text Transformer for Vision and Language"}, {"paperId": "9695824d7a01fad57ba9c01d7d76a519d78d65e7", "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"}, {"paperId": "a26a7a74f1e5fd562be95c3611a0680759fbdf84", "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "259c681c76335540e13081efad584efdf9101868", "title": "DaViT: Dual Attention Vision Transformers"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "a09cbcaac305884f043810afc4fa4053099b5970", "title": "Exploring Plain Vision Transformer Backbones for Object Detection"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "adb272fbdea3631059cf88ab764bb6c2ce29f965", "title": "Visual Prompt Tuning"}, {"paperId": "b00da02e88a857970d89cd8e69fa77710d03bbfe", "title": "Region-Object Relation-Aware Dense Captioning via Transformer."}, {"paperId": "9dc481ec44178e797466bbad968071917842156b", "title": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "78d02f2909a582c624eca2d0f67c91ee91974180", "title": "DN-DETR: Accelerate DETR Training by Introducing Query DeNoising"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "004f1d2b1b7d7dcecafdd94daee9c1b0aa3e65cf", "title": "DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR"}, {"paperId": "cc9826c222ac1e81b4b374dd9e0df130f298b1e8", "title": "Language-driven Semantic Segmentation"}, {"paperId": "86b42cac364985919987789795be7c3a577ee3de", "title": "Detecting Twenty-thousand Classes using Image-level Supervision"}, {"paperId": "8d737dc6a91a7bfde20aed7bb13d100476de5ae3", "title": "Scaling Open-Vocabulary Image Segmentation with Image-Level Labels"}, {"paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d", "title": "High-Resolution Image Synthesis with Latent Diffusion Models"}, {"paperId": "837173ef1f260adc0d50b76675915776e1cc8ade", "title": "RegionCLIP: Region-based Language-Image Pretraining"}, {"paperId": "5341b412383c43f4a693ad63ec4489e3ec7688c8", "title": "Grounded Language-Image Pre-training"}, {"paperId": "658a017302d29e4acf4ca789cb5d9f27983717ff", "title": "Masked-attention Mask Transformer for Universal Image Segmentation"}, {"paperId": "21ec90872abd986c12afe39bebe807732ffa70c9", "title": "Florence: A New Foundation Model for Computer Vision"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "96ea07447d2f9adefe03852a878517a2a6d45b96", "title": "Learning to Prompt for Vision-Language Models"}, {"paperId": "1c83f3f9789df43bf937ae2618721e2da83dcc06", "title": "From Show to Tell: A Survey on Deep Learning-Based Image Captioning"}, {"paperId": "260ad39a1dac4b451019e2bf17925f4df8e3b69a", "title": "Per-Pixel Classification is Not All You Need for Semantic Segmentation"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "394be105b87e9bfe72c20efe6338de10604e1a11", "title": "Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts"}, {"paperId": "141a5033d9994242b18bb3b217e79582f1ee9306", "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"}, {"paperId": "914a593b7f2e980470075a9955f1407641669a8f", "title": "Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "c5ff974a69fd0c760b4855b819e61e89f31cfffe", "title": "Objects365: A Large-Scale, High-Quality Dataset for Object Detection"}, {"paperId": "e9ea5e8e018fa2d1f508aa0310469ba11a61345a", "title": "Learning Object Context for Dense Captioning"}, {"paperId": "9662b48d9b8a8f2118487a7f3be2d76283848627", "title": "CenterNet: Keypoint Triplets for Object Detection"}, {"paperId": "eba62fe8050e475ffe533b9f70db538074d8d0d1", "title": "Context and Attribute Grounded Dense Captioning"}, {"paperId": "e2751a898867ce6687e08a5cc7bdb562e999b841", "title": "FCOS: Fully Convolutional One-Stage Object Detection"}, {"paperId": "7e27d44e3fac723ccb703e0a83b22711bd42efe8", "title": "A Comprehensive Survey of Deep Learning for Image Captioning"}, {"paperId": "b4df354db88a70183a64dbc9e56cf14e7669a6c0", "title": "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"}, {"paperId": "874b785f3ed82b4e1544975e41ed3c8aedf997ae", "title": "Few-Shot Segmentation Propagation with Guided Networks"}, {"paperId": "79cfb51a51fc093f66aac8e858afe2e14d4a1f20", "title": "Focal Loss for Dense Object Detection"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "21fa67345e49642b8ebb22a59c4b2799a56e996f", "title": "Dense Captioning with Joint Inference and Visual Context"}, {"paperId": "29efbe391950ae438c63d86ad5c82b2942efb0b4", "title": "Modeling Context in Referring Expressions"}, {"paperId": "f90d9c5615f4a0e3f9a1ce2a0075269b9bab6b5f", "title": "SPICE: Semantic Propositional Image Caption Evaluation"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d", "title": "Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations"}, {"paperId": "4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0", "title": "SSD: Single Shot MultiBox Detector"}, {"paperId": "d7ce5665a72c0b607f484c1b448875f02ddfac3b", "title": "DenseCap: Fully Convolutional Localization Networks for Dense Captioning"}, {"paperId": "f8e79ac0ea341056ef20f2616628b3e964764cfd", "title": "You Only Look Once: Unified, Real-Time Object Detection"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "55e022fb7581bb9e1fce678d21fb25ffbb3fbb88", "title": "Deep visual-semantic alignments for generating image descriptions"}, {"paperId": "258986132bf17755fe8263e42429fe73218c1534", "title": "CIDEr: Consensus-based image description evaluation"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "1a81c722727299e45af289d905d7dcf157174248", "title": "BabyTalk: Understanding and Generating Simple Image Descriptions"}, {"paperId": "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation"}, {"paperId": "8e080b98efbe65c02a116439205ca2344b9f7cd4", "title": "Im2Text: Describing Images Using 1 Million Captioned Photographs"}, {"paperId": "59d86a93c4ef54b5489bc375cd02e64205823f42", "title": "Random Walks for Image Segmentation"}, {"paperId": "7533d30329cfdbf04ee8ee82bfef792d08015ee5", "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"}, {"paperId": "f26d35d2e32934150cd27b030d4d769942126184", "title": "\"GrabCut\""}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": null, "title": "Image cap-tioning: a comprehensive survey"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "The Open Images Dataset V4: Unified image classification, object detection, and visual relationship detection at scale"}, {"paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82", "title": "Deep Learning"}, {"paperId": "cfee1826dd4743eab44c6e27a0cc5970effa4d80", "title": "Improving Image Generation with Better Captions"}, {"paperId": null, "title": "Together Computer"}, {"paperId": null, "title": "Stanford alpaca: An instruction-following llama model"}, {"paperId": null, "title": "Semantic-assisted object cluster for referring video object segmentation"}, {"paperId": null, "title": "OpenLLaMA: An Open Re-production of LLaMA, 2023. 5"}]}