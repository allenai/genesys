{"paperId": "f1d39175484e58db627c0dcdbe96ebdfa6d22da1", "abstract": "Monolithic large language models (LLMs) like GPT-4 have paved the way for modern generative AI applications. Training, serving, and maintaining monolithic LLMs at scale, however, remains prohibitively expensive and challenging. The disproportionate increase in compute-to-memory ratio of modern AI accelerators have created a memory wall, necessitating new methods to deploy AI. Composition of Experts (CoE) is an alternative modular approach that lowers the cost and complexity of training and serving. However, this approach presents two key challenges when using conventional hardware: (1) without fused operations, smaller models have lower operational intensity, which makes high utilization more challenging to achieve; and (2) hosting a large number of models can be either prohibitively expensive or slow when dynamically switching between them. In this paper, we describe how combining CoE, streaming dataflow, and a three-tier memory system scales the AI memory wall. We describe Samba-CoE, a CoE system with 150 experts and a trillion total parameters. We deploy Samba-CoE on the SambaNova SN40L Reconfigurable Dataflow Unit (RDU) - a commercial dataflow accelerator architecture that has been co-designed for enterprise inference and training applications. The chip introduces a new three-tier memory system with on-chip distributed SRAM, on-package HBM, and off-package DDR DRAM. A dedicated inter-RDU network enables scaling up and out over multiple sockets. We demonstrate speedups ranging from 2x to 13x on various benchmarks running on eight RDU sockets compared with an unfused baseline. We show that for CoE inference deployments, the 8-socket RDU Node reduces machine footprint by up to 19x, speeds up model switching time by 15x to 31x, and achieves an overall speedup of 3.7x over a DGX H100 and 6.6x over a DGX A100.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Samba-CoE, a CoE system with 150 experts and a trillion total parameters is described and deployed on the SambaNova SN40L Reconfigurable Dataflow Unit (RDU) - a commercial dataflow accelerator architecture that has been co-designed for enterprise inference and training applications."}, "embedding": {"model": "specter_v2", "vector": [0.34334176778793335, 0.18584342300891876, -0.1394071877002716, 0.01313716545701027, -0.018952423706650734, -0.23099829256534576, 0.5339771509170532, -0.36964723467826843, -0.41817301511764526, -0.5289689898490906, 0.2672043442726135, -0.16713856160640717, 0.37179332971572876, 0.08160753548145294, -0.3370540142059326, 0.47581058740615845, -1.0687978267669678, 0.775404155254364, 0.2965550124645233, -0.32962730526924133, -0.17887456715106964, -0.10458794981241226, -1.888765573501587, 0.410451740026474, 0.44828203320503235, 1.0007829666137695, -0.08624793589115143, 1.401619553565979, -0.34091001749038696, 0.6380175948143005, 0.14319489896297455, 0.18526440858840942, 0.1906006932258606, 0.23983854055404663, -0.07089037448167801, -0.27320438623428345, 0.6588411331176758, -0.4952446222305298, -0.4485068619251251, 0.4936447739601135, -0.21915239095687866, 0.07979124784469604, 0.22512485086917877, -1.0298925638198853, 0.21748004853725433, 0.6755263805389404, 0.9012548923492432, 1.0464941263198853, -0.361435204744339, -0.2687578797340393, 1.1179122924804688, -1.1843372583389282, 0.24031174182891846, 1.494433879852295, 0.427868515253067, 0.438445508480072, -0.37606996297836304, -0.6327478885650635, 0.7987909317016602, -0.12317203730344772, -0.4730881452560425, -0.5148195624351501, -0.2217172086238861, -0.305816650390625, 1.9735939502716064, -0.141936793923378, 0.37885424494743347, 0.5515100955963135, 0.05517055094242096, 1.710442304611206, -0.2604196071624756, -0.6170937418937683, 0.194881409406662, 0.1888532191514969, 0.3576933443546295, 0.963523805141449, -0.26830434799194336, 0.19303101301193237, -1.1100050210952759, -0.27214503288269043, 0.6428240537643433, -0.23619575798511505, 0.6246044635772705, -0.12828409671783447, -0.20934522151947021, 0.7144208550453186, 0.29596659541130066, 0.8518266081809998, -0.23009297251701355, 0.8462412357330322, 0.6525217890739441, 0.09720594435930252, -0.0668913722038269, 0.4527761936187744, 0.0670662671327591, 0.34699180722236633, -0.8501868844032288, 0.3594992756843567, 0.2969711124897003, 0.8255294561386108, -0.3381369411945343, 0.5301298499107361, -0.6733816266059875, -0.09996639937162399, 1.4038056135177612, 0.09642750024795532, 0.6764628887176514, -0.8590327501296997, 0.061340320855379105, -0.4794256389141083, 0.08202464133501053, -0.35383138060569763, -0.17138153314590454, -0.5673810243606567, -0.6349261403083801, -0.825945258140564, -0.577359139919281, 0.12423780560493469, -1.2191072702407837, 0.36238983273506165, -0.13682501018047333, 0.3524690866470337, -0.00711692962795496, 0.6302660703659058, 0.6452388763427734, 0.5453495383262634, 0.5483512878417969, 0.6172086596488953, 0.9105247259140015, -0.993751585483551, -0.040054600685834885, -1.8397337198257446, 0.3631078600883484, 0.19376498460769653, -0.06355996429920197, -0.26279905438423157, -1.7613259553909302, -0.9710466861724854, -0.9279497265815735, 0.13030120730400085, -0.3252384066581726, 0.05256571248173714, 1.807859182357788, 0.2176666110754013, -0.9459470510482788, 0.577782154083252, -0.5091767907142639, 0.13956084847450256, 0.6489838361740112, 0.3727051019668579, 0.4876517355442047, -0.21106980741024017, -1.2335299253463745, -0.22977253794670105, 0.3730582594871521, -0.5325983166694641, -0.6151844263076782, -0.7588428258895874, -0.885858952999115, 0.3151881992816925, -0.08372858166694641, -1.0269895792007446, 1.509346604347229, -0.4990594685077667, -1.1847782135009766, 0.6450506448745728, -0.24650922417640686, -0.10466645658016205, 0.22920015454292297, 0.3363296389579773, -0.560154378414154, -0.3114081621170044, -0.35386693477630615, 0.6177929639816284, 0.761890709400177, -0.1873324066400528, -0.4454250633716583, 0.05755685642361641, -0.08452612161636353, -0.17960473895072937, -0.27690401673316956, 1.074897289276123, -0.46972113847732544, 0.3008194863796234, 0.43398743867874146, 0.7020041942596436, -0.4262002408504486, -0.050048261880874634, 0.0861172080039978, -0.7286375761032104, 0.5074246525764465, 0.04018986597657204, 0.9655424952507019, -1.0193439722061157, -0.6137946844100952, -0.034508489072322845, 0.06087670847773552, 0.07183321565389633, -0.3789941370487213, 0.33296656608581543, -0.1645091027021408, 0.1777704805135727, -0.45382970571517944, -0.9000797271728516, 0.07323113083839417, -0.09538713097572327, -0.5794067978858948, -0.7909109592437744, 0.36777985095977783, 1.0977330207824707, -0.8263521194458008, -0.24023926258087158, -0.2255890965461731, 0.2124425768852234, -1.5725247859954834, 1.1301043033599854, -0.8203033804893494, 0.24237455427646637, -0.40617093443870544, -0.15827175974845886, -0.0797639712691307, -0.534481406211853, 0.7042233347892761, -0.21331466734409332, 0.026925571262836456, 0.5388143658638, -0.597771167755127, 1.4461063146591187, -0.572801411151886, 0.10870734602212906, 0.2962470054626465, -0.8458894491195679, 0.17315919697284698, 0.2625865638256073, -0.36980387568473816, -0.5227363109588623, 0.3741307556629181, 0.7130984663963318, -0.14404882490634918, 0.3561861217021942, 0.8776692152023315, 0.7973576188087463, -0.5688498616218567, -0.07096902281045914, 0.8942281603813171, -0.528796374797821, 0.9069364666938782, 0.4575834572315216, 1.0175007581710815, 0.35669392347335815, 0.030597103759646416, -0.14296767115592957, 0.43413543701171875, -0.5629324913024902, 0.10759366303682327, 0.7039861083030701, 0.6396104097366333, 0.5631696581840515, 0.30773410201072693, -0.9690989255905151, -0.26942089200019836, 0.127346009016037, 0.5071085095405579, 1.5789637565612793, -0.44020605087280273, 0.23088371753692627, -0.6829743385314941, -0.49940454959869385, 0.13183097541332245, 0.15908397734165192, -0.08570104092359543, -0.0828549861907959, -0.7259547114372253, -0.9472499489784241, 0.5188180208206177, 0.4742741286754608, 0.8546743392944336, -1.1287667751312256, -0.8546914458274841, -0.1820220947265625, 0.7201073169708252, -0.6991769671440125, -0.1976929008960724, 0.45113852620124817, -0.5816822648048401, 0.4692533016204834, 0.4554983675479889, -0.15967604517936707, 0.39152097702026367, -0.7976559400558472, 1.4083523750305176, -0.3634737730026245, -0.6096044182777405, -0.03986356407403946, 0.8822152614593506, -0.5077718496322632, -1.0024571418762207, 0.24343842267990112, -0.15772682428359985, -0.3165261149406433, -0.0357145331799984, 0.006246894132345915, 0.058685727417469025, 0.055327143520116806, -0.4892396330833435, 0.29041674733161926, 0.1931341290473938, -0.10271506756544113, 0.661098837852478, -0.683040201663971, -0.2652914226055145, -1.4719276428222656, 0.578531801700592, -0.2724282443523407, -0.555500328540802, 0.04269789159297943, -0.25110411643981934, -0.18126820027828217, 1.0149719715118408, -0.6128662824630737, -0.48644208908081055, -1.0386759042739868, 0.2584706246852875, -0.503272294998169, -0.5452878475189209, 0.04099758341908455, 0.4154081642627716, -0.028142161667346954, 0.47824668884277344, 0.27892225980758667, -0.021367395296692848, 0.08072859048843384, 0.4296766221523285, -0.8232819437980652, 0.5646163821220398, -0.12433793395757675, -0.06139097735285759, -0.06924217194318771, -0.235309898853302, -0.4448789060115814, -0.316421240568161, -0.05967390909790993, 0.08097897469997406, -0.43175455927848816, -0.0053342063911259174, -0.41275516152381897, -1.1347167491912842, -0.035278789699077606, -1.0447967052459717, -0.46509385108947754, 0.2743391692638397, -0.46698665618896484, -0.04662523418664932, -1.430923581123352, -1.1816521883010864, -0.593738317489624, -0.8384360671043396, -1.069491982460022, 0.4392123818397522, 0.3865353763103485, -0.3819512724876404, -0.5592711567878723, 0.08718889951705933, -0.2066260129213333, 1.1743767261505127, -0.5096346735954285, 0.5060883164405823, 0.05883578211069107, -0.3791341781616211, -0.40294697880744934, 0.19766919314861298, 0.03713684901595116, -1.0580464601516724, 0.47755908966064453, -1.0121147632598877, 0.3551631271839142, -0.5302001237869263, -0.6873378753662109, 0.39824628829956055, 0.17354492843151093, 0.9750709533691406, 0.21179810166358948, -0.6017275452613831, 0.5092297792434692, 1.3337374925613403, -0.4834684133529663, -0.036578718572854996, -0.11106313019990921, 0.8993940353393555, -0.1001492291688919, -0.45397356152534485, 0.6404342651367188, 0.12781837582588196, 0.42172926664352417, 0.1671896129846573, 0.048369213938713074, -0.20139755308628082, -0.36576715111732483, 0.454499751329422, 1.3704087734222412, 0.5636059045791626, -0.2907175123691559, -1.0996685028076172, 0.4262182116508484, -1.347553014755249, -0.37123796343803406, 0.9189499616622925, 0.5804540514945984, 0.18684740364551544, -0.059050243347883224, -0.3885742723941803, -0.24709929525852203, 0.2802406847476959, 0.03532041981816292, -0.8543821573257446, -1.1429338455200195, 0.3304342031478882, 0.859927237033844, 0.07871583849191666, 0.5940786004066467, -0.09132727980613708, 0.4669906198978424, 14.65626049041748, 0.7984695434570312, 0.07588526606559753, 0.3793337643146515, 0.6968027353286743, 0.4624336063861847, -0.6583967208862305, -0.07038573175668716, -1.4895321130752563, -0.19444677233695984, 1.8503963947296143, 0.17285732924938202, 0.6211579442024231, 0.4295242428779602, -0.6072550415992737, -0.0008183637401089072, -0.47169482707977295, -0.04266202822327614, 0.47544774413108826, -1.2645890712738037, 0.36091452836990356, -0.14626628160476685, 0.11346355825662613, 0.6779595613479614, 0.5976486802101135, 0.9515715837478638, 0.9058916568756104, -0.39607328176498413, 0.7255630493164062, 0.4188242554664612, 0.7299391031265259, -0.045944709330797195, 0.011533777229487896, 0.591535747051239, -0.766793966293335, -0.2808554768562317, -0.24285627901554108, -1.2539294958114624, 0.20706072449684143, -0.13957202434539795, -0.7591816186904907, -0.6118250489234924, -0.0624709390103817, 0.40187525749206543, 0.17101845145225525, 0.2595255672931671, -0.1739019900560379, 0.5095207691192627, -0.4589916467666626, 0.1990325003862381, -0.13473080098628998, 0.60423743724823, -0.040418099611997604, -0.08020114153623581, -0.23438797891139984, -0.3721747100353241, 0.31723642349243164, 0.8284862041473389, -0.4171743392944336, -0.6056054830551147, -0.10365147143602371, -0.595008373260498, -0.16184364259243011, 1.114473581314087, 0.24549813568592072, 0.14918310940265656, -0.4374459683895111, 0.29697084426879883, 0.7914845943450928, -0.12031961232423782, -0.31071266531944275, 0.2512393593788147, 0.3487829864025116, -0.6250585913658142, 0.11882243305444717, 0.6129308342933655, -0.15610414743423462, -0.44745033979415894, -0.9104257225990295, -0.7248263359069824, 0.4865719974040985, -0.43980833888053894, -0.5728892683982849, 0.8048266768455505, -0.07287353277206421, -0.12483511865139008, -0.25679367780685425, -0.8511982560157776, -0.39890486001968384, 0.3489304184913635, -1.178320050239563, -0.7143076658248901, 0.28229451179504395, -0.5942660570144653, -0.5749024152755737, -0.012703407555818558, 1.689361572265625, 0.31918781995773315, -0.5531930923461914, -0.13115592300891876, -0.2071329653263092, -0.2678828835487366, -0.667385995388031, -0.6422374248504639, 1.5479671955108643, 0.3330003619194031, 0.17045347392559052, -0.18101440370082855, 0.0016446291701868176, 0.1673266887664795, -0.965995192527771, 0.21415936946868896, 0.5481774806976318, -0.7807053923606873, -0.010123900137841702, -0.9609617590904236, -0.73075932264328, 0.6628272533416748, 0.02583329938352108, 0.32989996671676636, 0.06359048932790756, -0.00679035997018218, -0.5609626770019531, -0.1923990100622177, -0.8243309855461121, -0.007628244813531637, 0.6769185662269592, -0.46231475472450256, -0.06633878499269485, -0.1273670643568039, 0.3058431148529053, -1.3720723390579224, -0.7757536768913269, -0.243127703666687, 0.367887020111084, -0.3013613820075989, 1.2908800840377808, -0.41388368606567383, 0.898086667060852, 0.7983049750328064, 0.28160595893859863, -0.4999569356441498, 0.006999787408858538, -0.5052398443222046, -0.2915806770324707, -0.1245693638920784, 0.7635828852653503, -0.6005892753601074, 0.44958776235580444, 1.039790391921997, 0.023154366761446, -0.056561533361673355, -0.3060208559036255, 0.1863338053226471, 0.015391000546514988, -0.6068934798240662, 0.4346678853034973, -0.32723501324653625, -0.2518400549888611, 0.1395632028579712, 0.701983630657196, 0.5940105319023132, -0.16819453239440918, -0.13938400149345398, 0.5363364219665527, -0.19384998083114624, -0.6916940212249756, -0.5825774669647217, -0.5005685687065125, -0.9056660532951355, -0.03679794445633888, -1.3079090118408203, 0.2558723986148834, -0.5655403733253479, -0.6194889545440674, -0.1600024402141571, -0.1664200872182846, 0.0021396633237600327, 0.28558024764060974, -0.3559471368789673, -0.5862058401107788, -0.6345669031143188, -0.5073135495185852, 0.3112897574901581, 0.8323323726654053, -0.44840243458747864, 0.06496062129735947, -0.16731658577919006, 0.10326921939849854, 0.30348026752471924, 0.4198746085166931, -0.19826556742191315, -0.6847189664840698, -1.456453561782837, 0.4030511975288391, 0.1378491073846817, -0.2091255933046341, -1.150231122970581, 0.8613470792770386, 0.5010833740234375, -0.06896031647920609, 0.48669371008872986, 0.23464487493038177, -0.7661814093589783, -0.36734941601753235, 0.41767606139183044, -0.48486873507499695, -0.03399165719747543, 1.061914086341858, -0.8849512934684753, -0.09484460949897766, 0.5813618302345276, -0.20196758210659027, -1.1556824445724487, -1.1963741779327393, 0.27207159996032715, -0.6185259222984314, 0.37500473856925964, -0.5850000977516174, 0.21564170718193054, -1.1593624353408813, 0.05562679097056389, 0.17126911878585815, 0.33401012420654297, -0.4917706549167633, 0.7191239595413208, 0.27109962701797485, -0.6279640793800354, -0.007198755629360676, 0.6530377268791199, -0.3384588658809662, 0.3972908854484558, 0.6949465870857239, 0.26083603501319885, -0.48753878474235535, 0.42451170086860657, -0.1798541396856308, 0.255553662776947, -0.41252967715263367, -0.20840929448604584, 0.6927586793899536, -0.7728157043457031, 0.05079757049679756, 1.3287441730499268, -0.20629209280014038, -1.1852816343307495, -0.10191991925239563, -0.9760971665382385, -0.5110113620758057, -0.5919204354286194, 0.6422451138496399, -0.11955902725458145, -0.07126659154891968, 0.2709152400493622, -0.7344305515289307, -0.08735654503107071, -0.24032971262931824, -0.674560546875, 0.38099467754364014, 0.4494154453277588, -0.33877143263816833, 0.7198589444160461, 0.2041371464729309, -0.7245228886604309, -0.719295084476471, -0.4790802597999573, -0.49093180894851685, -0.0330728143453598, 0.6351042985916138, -0.5069482326507568, -0.6163825988769531, 0.8321989178657532, 0.3043918311595917, 0.2563071548938751, -0.02289569564163685, -0.2911243140697479, 0.26129549741744995, 0.24658644199371338, 0.20289793610572815, -0.24221281707286835, -0.6794047951698303, 1.2139726877212524, 1.0941996574401855, -0.7108532190322876, 0.1580464094877243, -0.092816062271595, -0.6734519600868225, 0.7397377490997314, 0.7135562300682068, -0.3737519383430481, 0.5411766171455383, 0.2747626006603241, -0.2374008595943451, 0.114419125020504, -1.1436885595321655, -0.3919250965118408, 0.8039677739143372, 0.6632465720176697, 0.7506812810897827, 0.42585957050323486, 0.3516715168952942, 0.8339954614639282, 0.2066984474658966, 0.5029784440994263, 0.004216895438730717, 0.6750429272651672, -0.05670560896396637, -0.08300326764583588, 0.05360200256109238, 0.8060541152954102, -0.21635088324546814, -0.5605878829956055, 0.3435199558734894, 0.4229496419429779, 0.36251282691955566, 0.3010712265968323, 1.2881324291229248, 0.31301647424697876, 0.4599798321723938, 0.14862675964832306, 0.9322285056114197, -0.5317015647888184, -0.4697326123714447, -0.36378976702690125, -0.4372612237930298, -0.13113102316856384, 0.17942629754543304, -0.31579485535621643, -0.7601960301399231, -0.28940054774284363, 0.7580583691596985, -0.18110382556915283, 0.5200982689857483, 1.0328829288482666, 0.9913628101348877, 0.9793475270271301, -0.4469442665576935, -0.9493201375007629, -0.15157054364681244, -0.8603958487510681, 0.3210289776325226, -0.6493011116981506, -0.5956882834434509, -0.2081000804901123, -0.317041277885437, -0.5787516236305237]}, "authors": [{"authorId": "2688640", "name": "R. Prabhakar"}, {"authorId": "144512130", "name": "R. Sivaramakrishnan"}, {"authorId": "144280544", "name": "Darshan Gandhi"}, {"authorId": "2203922735", "name": "Yun Du"}, {"authorId": "2217860234", "name": "Mingran Wang"}, {"authorId": "2301149803", "name": "Xiangyu Song"}, {"authorId": "2301251444", "name": "Kejie Zhang"}, {"authorId": "2243338432", "name": "Tianren Gao"}, {"authorId": "2301247910", "name": "Angela Wang"}, {"authorId": "2219857708", "name": "Karen Li"}, {"authorId": "2951019", "name": "Yongning Sheng"}, {"authorId": "2301154209", "name": "Joshua Brot"}, {"authorId": "2301154303", "name": "Denis Sokolov"}, {"authorId": "2301154230", "name": "Apurv Vivek"}, {"authorId": "2301155438", "name": "Calvin Leung"}, {"authorId": "2266400032", "name": "Arjun Sabnis"}, {"authorId": "2301569064", "name": "Jiayu Bai"}, {"authorId": "2301270476", "name": "Tuowen Zhao"}, {"authorId": "1790396", "name": "Mark Gottscho"}, {"authorId": "2301157078", "name": "David Jackson"}, {"authorId": "50260984", "name": "Mark Luttrell"}, {"authorId": "49246199", "name": "Manish Shah"}, {"authorId": "2265424969", "name": "Edison Chen"}, {"authorId": "2243335661", "name": "Kaizhao Liang"}, {"authorId": "2301197963", "name": "Swayambhoo Jain"}, {"authorId": "70296695", "name": "Urmish Thakker"}, {"authorId": "2304300017", "name": "Dawei Huang"}, {"authorId": "37522759", "name": "Sumti Jairath"}, {"authorId": "144806284", "name": "Kevin J. Brown"}, {"authorId": "1746638", "name": "K. Olukotun"}], "references": [{"paperId": "a509670659e8b054e2b7d1b6f8a0bc722398fa62", "title": "PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation"}, {"paperId": "4c14b1c41cb0aaa68f5d3f4a432f55e7199657ea", "title": "AI and Memory Wall"}, {"paperId": "5e71d0e85f65a1c0fb2af7bff281209122c58932", "title": "When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method"}, {"paperId": "d6af8cab4ced2d3030e7c07d30c5273eed54014d", "title": "Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM"}, {"paperId": "6fb58d9069bcb119c6a906e458a735b99dd537fc", "title": "A Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Software Engineering Tasks"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "2c0312c604f9f7638bb4533b39e0ae81e7f6ab12", "title": "The Falcon Series of Open Language Models"}, {"paperId": "37680e5cb6030e01f1a44a5abe2257972196ae26", "title": "Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2"}, {"paperId": "215de09ac6e5de81187c85065b5ace8bc01f2862", "title": "Routing to the Expert: Efficient Reward-guided Ensemble of Large Language Models"}, {"paperId": "5c104f905fcacf390270f619f232a2ba4eb873f2", "title": "FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores"}, {"paperId": "db633c6b1c286c0386f0078d8a2e6224e03a6227", "title": "Mistral 7B"}, {"paperId": "0b0debb710366cdff461938c80763eace1651af6", "title": "Code Llama: Open Foundation Models for Code"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "2922768fd451ecdb45f48c1a83eb57f54a91221b", "title": "Textbooks Are All You Need"}, {"paperId": "993df7df129f8d18816877d69923d7df7b347d85", "title": "LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion"}, {"paperId": "0244aeb7c6927e2fb0c2e668687e160a00737dbe", "title": "Orca: Progressive Learning from Complex Explanation Traces of GPT-4"}, {"paperId": "60c646f722d1f206561c716aaabb7a1206499eb6", "title": "A Comprehensive Analysis of Adapter Efficiency"}, {"paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8", "title": "Visual Instruction Tuning"}, {"paperId": "0312e70901f352a6d95f23573788f9f7b737c983", "title": "Training Large Language Models Efficiently with Sparsity and Dataflow"}, {"paperId": "7c25adf2ddb35df05a61c697da97efb8583d77df", "title": "TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings"}, {"paperId": "464770587aece80cc9e3451050058e30c2aa6666", "title": "Scaling Expert Language Models with Unsupervised Domain Discovery"}, {"paperId": "ecd0b23e4828fca585a05eff56563852d35858d9", "title": "ChatGPT"}, {"paperId": "379e42895f6d40ab9e9559609f505aba89145a5d", "title": "Efficiently Scaling Transformer Inference"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "c419c631aa4c271b009d53ef26f94675c87cbf04", "title": "Nvidia Hopper GPU: Scaling Performance"}, {"paperId": "4b10310731ace7f3b905bbb0c368aa154e39644a", "title": "Cerebras Architecture Deep Dive: First Look Inside the HW/SW Co-Design for Deep Learning : Cerebras Systems"}, {"paperId": "8b3a67c7e5289eed160d2acfd04d71cfb552c67d", "title": "Branch-Train-Merge: Embarrassingly Parallel Training of Expert Language Models"}, {"paperId": "4dcf2131cf0bb858d1ce96377800e5ab37013ae6", "title": "A software-defined tensor streaming multiprocessor for large-scale machine learning"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "06d7cb8c8816360feb33c3367073e0ef66d7d0b0", "title": "Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks"}, {"paperId": "b9299077b33b16e90532b12f8931676f891b8ee5", "title": "SambaNova SN10 RDU: A 7nm Dataflow Architecture to Accelerate Software 2.0"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "ddcff7b456ea45987de6eef48166c90086f2d9e5", "title": "SambaNova SN10 RDU:Accelerating Software 2.0 with Dataflow"}, {"paperId": "4ac782a4d5db8ef988d2e6f4a24dda0db027c4d5", "title": "Graphcore"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "309fb5c6ed6d7ec85281ee315760df342e6c4fcc", "title": "Ten Lessons From Three Generations Shaped Google\u2019s TPUv4i : Industrial Product"}, {"paperId": "afa72122ba06b6a694c21cf67d82620662e4917c", "title": "A full-stack search technique for domain optimized deep learning accelerators"}, {"paperId": "21d0613c3e7fe2cb31f34441c1604edc9882fa45", "title": "NVIDIA A100 Tensor Core GPU: Performance and Innovation"}, {"paperId": "3836ccb33191799e748e8e96f85a813eaf650ff8", "title": "Data Movement Is All You Need: A Case Study on Optimizing Transformers"}, {"paperId": "ab5f0004c5f3317689e8457e1c8d8390ccbee522", "title": "A domain-specific supercomputer for training deep neural networks"}, {"paperId": "5dc9b006a741161aef214906b29d1a8c5dafd328", "title": "A Survey on Coarse-Grained Reconfigurable Architectures From a Performance Perspective"}, {"paperId": "336ab02cf16b5c63b8a915c2d59fe0dc0bc4f647", "title": "A Survey of Coarse-Grained Reconfigurable Architecture and Design"}, {"paperId": "2dfeb5a90abc49ab2a80a492a01a4e2c8e92ec22", "title": "In-datacenter performance analysis of a tensor processing unit"}, {"paperId": "092217c2267f6e0673590aa151d811e579ff7760", "title": "Roofline: an insightful visual performance model for multicore architectures"}, {"paperId": "c8d90974c3f3b40fa05e322df2905fc16204aa56", "title": "Adaptive Mixtures of Local Experts"}, {"paperId": "1aa69f7ce1819f5f3a2e4ffa1ad26e8ed193a078", "title": "Multiprotocol Label Switching (MPLS)"}, {"paperId": null, "title": "\u201cTensorrt fusion,\u201d"}, {"paperId": null, "title": "\u201cFine-tuning llms: Lora or full-parameter? an in-depth analysis with llama 2,\u201d"}, {"paperId": null, "title": "\u201cThe shift from models to compound ai systems,\u201d"}, {"paperId": null, "title": "\u201cLlama-2 results,"}, {"paperId": null, "title": "\u201cNavigating the high cost of ai compute.\u201d"}, {"paperId": null, "title": "\u201cMicrosoft\u2019s github copilot loses $20 a month per user.\u201d"}, {"paperId": null, "title": "\u201cDeepseek coder,\u201d"}, {"paperId": null, "title": "\u201cBenchmarking samba-1,\u201d"}, {"paperId": null, "title": "Rigid memory hierarchy and programming model creates data movement bottlenecks: A GPU kernel is launched with a grid of thread blocks"}, {"paperId": null, "title": "\u201cChai research,\u201d"}, {"paperId": null, "title": "\u201cC. raffel, \u201dbuild an ecosystem, not a monolith\u201d.\u201d"}, {"paperId": null, "title": "No pipeline parallelism exploited between operators: Higher order Monarch FFT decompositions"}, {"paperId": null, "title": "\u201cNvidia a100 80gb pcie gpu product brief,\u201d"}, {"paperId": null, "title": "\u201cRetrospective: Plasticine: A reconfigurablearchitecture for parallel patterns,\u201d"}, {"paperId": null, "title": "\u201c\u201cthe ai index 2024 annual report,\u201d ai index steering committee, institute for human-centered"}, {"paperId": null, "title": "\u201cThe inference cost of search disruption.\u201d"}, {"paperId": null, "title": "\u201cAmd instinct mi300x accelerators.\u201d"}, {"paperId": null, "title": "\u201cIntel gaudi ai deep learning processor.\u201d"}, {"paperId": null, "title": "\u201cSamba-coe v0.1 - unlocking the power of routing to build a composition of experts,\u201d"}, {"paperId": null, "title": "Insufficient on-chip SRAM capacity forces materialization of the output of Transpose to HBM, preventing a fusion opportunity"}, {"paperId": null, "title": "\u201cThe batch, issue 246,\u201d"}, {"paperId": null, "title": "\u201cAi server cost analysis - memory is the biggest loser.\u201d"}, {"paperId": null, "title": "\u201cStripedhyena-7b,\u201d"}, {"paperId": null, "title": "\u201cNvidia dgx gh200 datasheet,\u201d"}]}