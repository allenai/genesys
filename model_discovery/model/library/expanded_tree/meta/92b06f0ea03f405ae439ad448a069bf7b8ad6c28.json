{"paperId": "92b06f0ea03f405ae439ad448a069bf7b8ad6c28", "abstract": "Context-aware Machine Translation aims to improve translations of sentences by incorporating surrounding sentences as context. Towards this task, two main architectures have been applied, namely single-encoder (based on concatenation) and multi-encoder models. In this study, we show that a special case of multi-encoder architecture, where the latent representation of the source sentence is cached and reused as the context in the next step, achieves higher accuracy on the contrastive datasets (where the models have to rank the correct translation among the provided sentences) and comparable BLEU and COMET scores as the single- and multi-encoder approaches. Furthermore, we investigate the application of Sequence Shortening to the cached representations. We test three pooling-based shortening techniques and introduce two novel methods - Latent Grouping and Latent Selecting, where the network learns to group tokens or selects the tokens to be cached as context. Our experiments show that the two methods achieve competitive BLEU and COMET scores and accuracies on the contrastive datasets to the other tested methods while potentially allowing for higher interpretability and reducing the growth of memory requirements with increased context size.", "venue": "Findings", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This study shows that a special case of multi-encoder architecture, where the latent representation of the source sentence is cached and reused as the context in the next step, achieves higher accuracy on the contrastive datasets and comparable BLEU and COMET scores as the single- and multi-encoder approaches."}, "embedding": {"model": "specter_v2", "vector": [0.5488207340240479, 0.05353458598256111, -0.5610461235046387, -0.40975192189216614, -0.5039708018302917, -0.40115541219711304, 0.5626774430274963, -0.31959596276283264, -0.6371538043022156, 0.3047756850719452, 1.4206657409667969, 0.07409907877445221, 0.26093435287475586, 0.37120479345321655, -0.07727042585611343, -0.10742896050214767, -1.0116264820098877, -0.2556724548339844, -0.28752782940864563, -0.4243079125881195, -0.0863691046833992, -0.7164216637611389, -0.38245531916618347, 0.6010628938674927, 0.5746535658836365, 0.1828547865152359, 0.604983925819397, 0.9763010144233704, -0.25568974018096924, 0.38019946217536926, 0.20200000703334808, -0.37136319279670715, 0.16252951323986053, -0.48432689905166626, -0.08989088982343674, -0.18881337344646454, 0.3132309913635254, -0.8152065277099609, -0.26873579621315, 0.7459010481834412, -0.28538721799850464, 0.026452433317899704, -0.1644962579011917, -0.5029870271682739, -0.04232075437903404, 1.1099375486373901, 0.5563499927520752, 0.6802733540534973, 0.19705291092395782, -1.0529453754425049, 1.183181881904602, -0.8190061450004578, 0.4593427777290344, 1.0541534423828125, 0.2936699688434601, 0.7584058046340942, 0.1949080526828766, -0.14634880423545837, 0.6164864897727966, -0.1036626547574997, -0.7004407644271851, -0.298579603433609, 0.17421755194664001, 0.1811477690935135, 1.93391752243042, -0.09154243767261505, -0.33078137040138245, 0.4484808146953583, 0.1989588886499405, 1.1981453895568848, -0.03601561859250069, -0.8628901839256287, -0.28397074341773987, -0.15606975555419922, 0.31833192706108093, 0.5245558023452759, -0.3981007933616638, 0.31671062111854553, -0.9148399829864502, -0.08664069324731827, 0.09607648104429245, 0.3102782368659973, -0.10512286424636841, -0.10325400531291962, -0.6326442360877991, 0.5379698872566223, 0.22376792132854462, 0.9794237613677979, -0.12682975828647614, 1.1483463048934937, 1.0322160720825195, 0.4437926709651947, 0.3921779990196228, 0.31470003724098206, -0.1605500876903534, 0.3655570447444916, -0.9671024680137634, 0.0860806480050087, -0.14714325964450836, 1.0534272193908691, -0.3331143856048584, -0.06599270552396774, -0.6840291619300842, 0.03891456872224808, 1.0001713037490845, -0.24563908576965332, 0.34804704785346985, -0.5305679440498352, 0.6274349689483643, -0.8901848793029785, 0.10808556526899338, -0.4479620158672333, -0.34215325117111206, -0.35804006457328796, -0.48092392086982727, -1.3227126598358154, -0.7591116428375244, 0.015525096096098423, -0.3148408532142639, 1.067943811416626, -0.6748809218406677, 0.4745021164417267, 0.5171855688095093, 0.5479259490966797, 0.1382453292608261, 0.5427813529968262, 0.004364612977951765, -0.6920982599258423, 0.5461495518684387, -1.239447832107544, -1.0208063125610352, -0.9507597088813782, 0.7922804355621338, -0.5369098782539368, 0.1521613895893097, -0.5033427476882935, -0.9392217993736267, -0.737448513507843, -1.460752248764038, 0.0403304398059845, -0.3889053463935852, 0.1274583488702774, 1.0239269733428955, 0.3825538754463196, -1.156345248222351, 1.206508755683899, -0.4359741508960724, -0.32709741592407227, 0.27879542112350464, 0.16361822187900543, 0.2187773585319519, -0.47054722905158997, -1.1747609376907349, 0.4724104106426239, 0.17655010521411896, -0.7899718284606934, -0.14427293837070465, -0.5846688747406006, -1.0579124689102173, -0.18152204155921936, 0.4499249756336212, -0.7627065181732178, 1.1138997077941895, 0.010444859974086285, -1.2646816968917847, 0.11498884111642838, -0.31656599044799805, -0.07744228839874268, 0.3571237623691559, -0.7632766962051392, -0.5871543884277344, -0.03598698973655701, -0.034922175109386444, 0.017676545307040215, 0.06331264972686768, -0.14758583903312683, -0.21146602928638458, 0.1136959120631218, -0.1641474813222885, 0.18581591546535492, -0.10352453589439392, 1.3542273044586182, -0.30629032850265503, -0.5670155882835388, 0.36443036794662476, 0.7712079882621765, -0.1310938000679016, -0.5825880765914917, -0.11904630064964294, -0.6117051839828491, 1.0846933126449585, -0.12176695466041565, 1.3995609283447266, -0.6351366639137268, -0.3986717760562897, -0.623076856136322, -0.4847535789012909, -0.004314042162150145, -0.9404120445251465, 0.8508732318878174, -0.058977436274290085, 0.410309374332428, -0.33130326867103577, -1.145583987236023, -0.22869455814361572, -0.16520270705223083, -0.8699272871017456, -0.3378030061721802, -0.17649602890014648, 1.2246683835983276, -1.1293097734451294, 0.268524706363678, -0.08505949378013611, 0.2664123475551605, -0.7827243208885193, 1.0757572650909424, -0.6498399376869202, 0.7192164659500122, -0.24868036806583405, -0.36801084876060486, 0.1633385717868805, -0.15823696553707123, 0.6841413974761963, -0.14747585356235504, -0.006705353502184153, 0.5633218288421631, -0.08769985288381577, 2.02424693107605, -0.5621934533119202, 0.4999667704105377, -0.14640411734580994, -0.40898361802101135, 0.10005256533622742, 0.34993964433670044, -0.13853329420089722, -0.2067820280790329, 0.38778555393218994, 0.31953611969947815, -0.9501867890357971, -0.16315849125385284, 0.9472141861915588, 0.7270816564559937, -0.5475653409957886, 0.33721932768821716, 0.4557005763053894, -0.12179138511419296, 0.7233589291572571, 0.7965819835662842, 0.623527467250824, 0.7473881840705872, 0.33828893303871155, 0.2005966454744339, 0.5750471949577332, -0.7932004928588867, 0.01733565516769886, 0.16407980024814606, 0.6008403301239014, 0.9067316651344299, 0.35913151502609253, -0.5674593448638916, -0.7190526127815247, 0.11911260336637497, 1.2122032642364502, 1.4089372158050537, -0.059389520436525345, -0.4384855628013611, -1.0026737451553345, -0.6960652470588684, -0.5665203332901001, 0.39669069647789, -0.10754735767841339, -0.28856828808784485, -1.0134676694869995, -0.9332152605056763, 0.4305487275123596, 0.4023211598396301, 1.1012202501296997, -0.08704611659049988, -0.2931416928768158, -0.1876528114080429, -0.2919591963291168, -0.9212849140167236, -0.987127959728241, 0.01881593093276024, -0.823785662651062, -0.02742229774594307, 0.02551613748073578, -0.1880161613225937, -0.17869602143764496, -0.3289097547531128, 0.9736566543579102, 0.0627887025475502, 0.12744949758052826, 0.0037404759787023067, 0.1121274009346962, -0.2947537302970886, -1.0517547130584717, 0.017576130107045174, 0.08403004705905914, -0.3832607567310333, 0.4920002222061157, 0.4394022822380066, 0.13038204610347748, -0.04949762672185898, -0.4365679621696472, 0.48757314682006836, -0.10048624128103256, 0.17410972714424133, 0.4780028760433197, -0.5639878511428833, 0.3868386149406433, -1.0972434282302856, 0.8423855900764465, 0.47787484526634216, -0.14948132634162903, 0.4547385275363922, -0.2308090776205063, -0.49724119901657104, 0.5996612906455994, -0.3430241048336029, -0.4346049726009369, -1.0850402116775513, 0.36538589000701904, 0.01835281401872635, -0.1531464010477066, 0.37453657388687134, 0.13925494253635406, 0.32959070801734924, -0.21890732645988464, 0.4382651746273041, 0.5123026967048645, -0.4785512387752533, 0.5952051281929016, -0.2674998641014099, 0.5420612096786499, 0.7942877411842346, -0.2795238792896271, -0.0731070414185524, 0.0713106170296669, -0.35094207525253296, -0.41834092140197754, -0.41768941283226013, -0.716718316078186, -0.18738390505313873, 0.05151848495006561, -0.4423978328704834, -0.22680261731147766, -0.29344502091407776, -1.025044560432434, -0.007537170313298702, 0.39047178626060486, 0.034511689096689224, -0.6569573879241943, -0.5524018406867981, -1.007849097251892, -0.2052433341741562, -0.7474464774131775, -1.0701042413711548, 0.2697405517101288, 0.022013500332832336, -0.3309096693992615, -0.49356314539909363, 0.053692713379859924, -0.34740713238716125, 0.8691906332969666, -0.35892826318740845, 0.7039057612419128, 0.00034600822255015373, -0.27859368920326233, -0.3014996647834778, 0.41320398449897766, 0.6354504823684692, -0.23297226428985596, -0.13172386586666107, -0.5376521944999695, -0.03345735743641853, 0.08281788975000381, 0.15608975291252136, 0.3688786029815674, 0.4164331257343292, 0.3001205623149872, 0.19267192482948303, -0.5358794927597046, 0.3333827555179596, 1.7001068592071533, -0.46336960792541504, 0.067219577729702, -0.06852710247039795, 0.8034330010414124, 0.38467907905578613, 0.10924281924962997, 0.2967001497745514, -0.23031046986579895, 0.5865729451179504, 0.12248202413320541, 0.06216442584991455, -0.6053323149681091, -0.41703468561172485, 0.5658730268478394, 1.8124797344207764, 0.2976199686527252, 0.10566588491201401, -0.542752742767334, 0.5093048214912415, -1.399518370628357, -0.6936062574386597, 0.7280499339103699, 0.451945424079895, 0.329429030418396, -0.6954782009124756, -0.3025200664997101, -0.27597126364707947, 0.7807095646858215, 0.4208909273147583, -0.02644914574921131, -0.6486027240753174, 0.14597190916538239, 0.10167662799358368, 0.14725057780742645, 0.9726309180259705, -0.43825146555900574, 0.6813756823539734, 14.964886665344238, 0.7492464780807495, 0.16187432408332825, 0.6971466541290283, 0.2640487253665924, -0.3589741289615631, -0.09862744808197021, -0.08392423391342163, -1.1654341220855713, 0.245507150888443, 1.2507590055465698, -0.10278499126434326, 0.4420665502548218, -0.20455244183540344, 0.41099977493286133, -0.08632508665323257, -0.48368915915489197, 0.28447747230529785, 0.8504747152328491, -1.6218528747558594, 0.2284562587738037, 0.09487513452768326, 0.5402370691299438, 0.47250139713287354, 0.4815596640110016, 0.3806108832359314, -0.027437100186944008, -0.1111626997590065, 0.11135143786668777, 0.2044079750776291, 0.8449193239212036, -0.41790395975112915, 0.8469011187553406, 0.12330858409404755, -0.4104958474636078, -0.23926660418510437, -0.6010469198226929, -1.2172952890396118, 0.6941432952880859, 0.2018420249223709, -0.3717162311077118, 0.17701321840286255, -0.47150683403015137, 0.8321972489356995, 0.10062500089406967, 0.4858977198600769, -0.4621870815753937, 0.5533715486526489, 0.2940773069858551, -0.4054372012615204, 0.3459356725215912, 0.1908683180809021, 0.6242150068283081, -0.026286054402589798, -0.23711083829402924, 0.023491937667131424, -0.031266942620277405, -0.12623821198940277, -0.48228803277015686, -0.21253602206707, -0.5631238222122192, -0.12105733156204224, -0.106315478682518, 0.40438568592071533, 0.43218839168548584, -0.23552238941192627, -0.5081425309181213, 0.558314859867096, 0.25315937399864197, 0.050301443785429, -0.44234445691108704, -0.25862789154052734, 0.3858043849468231, -0.5434878468513489, -0.11378902941942215, 0.1222437247633934, -0.4607550799846649, -0.6496962308883667, -0.6738964915275574, -0.07663064450025558, 0.39057332277297974, -0.892551839351654, -0.06582893431186676, 1.1666425466537476, 0.14025729894638062, -0.9974168539047241, -0.09901832789182663, -0.5321963429450989, -0.20915961265563965, 0.30407118797302246, -1.2500253915786743, -0.8217945098876953, 0.5045627951622009, -0.7221076488494873, -0.3395285904407501, -0.16967114806175232, 1.3734936714172363, 0.06252941489219666, -0.23503591120243073, -0.00013706623576581478, 0.5019840598106384, -0.12095772475004196, -0.06862328201532364, -0.7032272815704346, 0.46129563450813293, 0.63066565990448, -0.18801136314868927, 0.3939727246761322, 0.2207610011100769, -0.03208867087960243, -0.6896054148674011, -0.09030206501483917, 1.143598198890686, -0.484041303396225, -0.43147921562194824, -0.9067184925079346, -0.5939513444900513, 0.21969717741012573, 0.979261577129364, -0.5625748038291931, 0.47586825489997864, -0.12127557396888733, -0.20705179870128632, -0.1712939292192459, -1.1732052564620972, 0.22244606912136078, 0.7739299535751343, -0.5982505083084106, -0.6269206404685974, 0.01196680124849081, 1.1558881998062134, -0.8220086097717285, -0.4563041031360626, -0.18878822028636932, -0.14647996425628662, 0.02702726051211357, 0.910101056098938, -0.2460651993751526, 0.9750605821609497, 0.6768763065338135, -0.457175076007843, -0.868366003036499, 0.12979651987552643, -1.0634657144546509, 0.19990967214107513, 0.5307148098945618, 0.30758291482925415, -0.1622505784034729, 0.10295794159173965, 0.48759815096855164, 0.04436468333005905, -0.31165727972984314, -0.5185766816139221, -0.3242414891719818, 0.28471705317497253, -0.23963665962219238, 0.5251425504684448, -0.24567145109176636, 0.398895263671875, 0.21640656888484955, 0.2361631542444229, 0.7117272019386292, -0.3329415023326874, -0.5906548500061035, 0.22214646637439728, 0.6924517750740051, 0.0690855011343956, -0.6517540812492371, -0.7703132629394531, -1.5099259614944458, 0.006169385276734829, -1.1147465705871582, -0.18748171627521515, -0.8092491030693054, -0.24955953657627106, 0.684477686882019, -0.08694163709878922, -0.31513309478759766, 0.10629497468471527, -0.07757087051868439, -0.20843861997127533, -0.6702718734741211, -0.8029358386993408, 0.802224338054657, 0.9152629375457764, -0.3979046940803528, 0.15606985986232758, -0.21088646352291107, 0.07906994223594666, 0.19255946576595306, 0.6512472033500671, -0.1289428025484085, -0.7696806788444519, -1.6720397472381592, 0.17792139947414398, -0.10893259197473526, -0.01294739730656147, -0.41304752230644226, 0.4622523784637451, 0.5249524116516113, -0.2330220639705658, -0.6588111519813538, 0.22847969830036163, -0.7075269818305969, -0.4999610185623169, 0.4879787266254425, -0.9216760993003845, 0.339216411113739, 0.1977410614490509, -0.3133697807788849, -0.2166965901851654, 0.49783167243003845, -0.15004821121692657, -0.997901201248169, -1.0792282819747925, -0.08870239555835724, -0.7950502038002014, -0.2038351148366928, -0.14011679589748383, 0.045012813061475754, -1.0655136108398438, -0.43942007422447205, -0.05229947715997696, 0.2940300405025482, -0.20357732474803925, 1.0012811422348022, 0.5141156315803528, -1.0930125713348389, -0.19697140157222748, 0.2993934750556946, -0.28795257210731506, -0.4794446527957916, 0.45700109004974365, 0.4615415632724762, -0.45394694805145264, 0.5649744272232056, 0.4006347060203552, 0.15404917299747467, -1.313723087310791, 0.23137672245502472, 0.5577149987220764, -0.30822041630744934, -0.20849502086639404, 0.8634447455406189, -0.8720608949661255, -0.5759588479995728, 0.13830572366714478, -1.1503514051437378, -0.41742318868637085, -0.48239171504974365, 1.2754650115966797, 0.4687238335609436, 0.0436713844537735, -0.10678087919950485, -0.6263741254806519, 0.3179022967815399, -0.14045469462871552, -0.6457279920578003, 0.845228910446167, -0.9131990671157837, -0.8013759255409241, 0.4357108473777771, 1.0986213684082031, -0.5003852248191833, -0.6921631693840027, -0.7492430210113525, -0.2453152984380722, -0.5789041519165039, 0.3256625235080719, -0.7697108387947083, -0.212355837225914, 0.6606343984603882, 0.5286769866943359, 0.06413744390010834, 0.46260735392570496, -0.11121729761362076, 0.2972887456417084, 0.08779148757457733, 0.33274510502815247, -0.5396429300308228, -0.5309454202651978, 1.101888656616211, 1.6253533363342285, -0.891403079032898, 0.6552041172981262, -0.208532452583313, -0.6449605226516724, 0.7428125143051147, -0.23471297323703766, -0.1572716236114502, 0.7282934784889221, -0.07732953876256943, 0.5285203456878662, 0.7502320408821106, -1.12067711353302, -0.12517383694648743, 0.4164979159832001, 1.0838321447372437, 0.7736063003540039, 0.5303012132644653, -0.5891379714012146, 0.8658802509307861, 0.270719438791275, 0.24431265890598297, 0.956836462020874, 0.6166926026344299, 0.09607617557048798, -0.42334073781967163, 0.030365969985723495, 0.30516135692596436, -0.9287257194519043, -0.6185336709022522, 0.1072656437754631, 0.4596341848373413, -0.08030092716217041, 1.1324818134307861, 0.8558840751647949, -0.1877729892730713, 0.28410306572914124, 0.08765296638011932, 0.5801601409912109, -0.6951929926872253, -0.7017195820808411, 0.20989194512367249, -0.22909651696681976, -0.1845349371433258, -0.5807715654373169, -0.7197180390357971, -0.29285621643066406, -0.3768705725669861, 0.08501141518354416, -0.05173664540052414, 0.5617923736572266, 1.113722801208496, 0.7883362174034119, 0.46176019310951233, -0.11087794601917267, -0.43685126304626465, -0.48727166652679443, -1.1776702404022217, 0.26011940836906433, -0.3975757360458374, -0.029242631047964096, 0.11230067163705826, 0.24618211388587952, -0.21687479317188263]}, "authors": [{"authorId": "2117212250", "name": "Pawe\u0142 M\u0105ka"}, {"authorId": "2045069003", "name": "Yusuf Can Semerci"}, {"authorId": "2282468902", "name": "Jan Scholtes"}, {"authorId": "3266578", "name": "Gerasimos Spanakis"}], "references": [{"paperId": "05bb7f4e44131a1f6a1c3d6b3cefc385a04204cc", "title": "A baseline revisited: Pushing the limits of multi-segment models for context-aware translation"}, {"paperId": "e19b54ad4c1c8af045069e9cac350ffc2ce60e1a", "title": "No Language Left Behind: Scaling Human-Centered Machine Translation"}, {"paperId": "4293121e2bef84aa8db5aab6634cfcd2d06947d4", "title": "Learn To Remember: Transformer with Recurrent Memory for Document-Level Machine Translation"}, {"paperId": "231e768f0cd280faa0f725bb353262cb4fed08d1", "title": "Hierarchical Transformers Are More Efficient Language Models"}, {"paperId": "18dc7f5937d85128447905f5b8e63e9adfb6a310", "title": "When Does Translation Require Context? A Data-driven, Multilingual Exploration"}, {"paperId": "05f53111fff3f811ed559d491eb35fac11778118", "title": "Contrastive Learning for Context-aware Neural Machine Translation Using Coreference Information"}, {"paperId": "e79d1206292bc5e67ba19737d87d4b2ea4a37105", "title": "Charformer: Fast Character Transformers via Gradient-based Subword Tokenization"}, {"paperId": "bc73d53ba859c56ab08c41c475d45a9ae6d021cb", "title": "Is Sparse Attention more Interpretable?"}, {"paperId": "b0de1d5fe394226cec0a59d783ab739eb52da76f", "title": "G-Transformer for Document-Level Machine Translation"}, {"paperId": "72d89aa7cd77c3f22a667f2b0707758eb8d52a7a", "title": "Do Context-Aware Translation Models Pay the Right Attention?"}, {"paperId": "83145b7a391b792e24d8d38f74ed6b6ae7a149dc", "title": "Measuring and Increasing Context Usage in Context-Aware Machine Translation"}, {"paperId": "c24c4f70ae808ebde2b8a0b7799e8696d16289b6", "title": "Divide and Rule: Effective Pre-Training for Context-Aware Multi-Encoder Translation Models"}, {"paperId": "0c1faca71afcd9af4b6277548a40929c94e03f19", "title": "Document-level Neural MT: A Systematic Comparison"}, {"paperId": "29cbc6d14b912bf9fb49cb4b8a3a004ca23618fa", "title": "Diving Deep into Context-Aware Neural Machine Translation"}, {"paperId": "b4193ecd5a4897afb549226693309a37b22e830e", "title": "Long-Short Term Masking Transformer: A Simple but Effective Baseline for Document-level Neural Machine Translation"}, {"paperId": "9e67b9758520e49016ab66bafb974d2e1ed762d1", "title": "COMET: A Neural Framework for MT Evaluation"}, {"paperId": "46b66719849498742908d21b996b09d7eebbee5c", "title": "A Simple and Effective Unified Encoder for Document-Level Machine Translation"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "4ca3b0ea12f02e2dea01a4aa505956bae5500a09", "title": "Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing"}, {"paperId": "1a97f45c2b67053b9e763ba19e86edec2ec33216", "title": "Does Multi-Encoder Help? A Case Study on Context-Aware Neural Machine Translation"}, {"paperId": "f2fc9ef411846dd577c26225ce93f50bb1fa760b", "title": "Multi-scale Transformer Language Models"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "94f94e8892261d0377159379ca5a166ceae19a14", "title": "PoWER-BERT: Accelerating BERT Inference via Progressive Word-vector Elimination"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "9f28386d1c3154616906bd662c839ff762f1ca29", "title": "Context-Aware Monolingual Repair for Neural Machine Translation"}, {"paperId": "7a09101ac03b74db501648597fa54e992a0fc84f", "title": "Towards Making the Most of BERT in Neural Machine Translation"}, {"paperId": "f6390beca54411b06f3bde424fb983a451789733", "title": "Adaptively Sparse Transformers"}, {"paperId": "95a251513853c6032bdecebd4b74e15795662986", "title": "What Does BERT Look at? An Analysis of BERT\u2019s Attention"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "e20ff55e87e2b3ef02ae0529880bb705f5efbcae", "title": "Document-Level Neural Machine Translation with Hierarchical Attention Networks"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "ad796bf779c8617d1e0d8111913ac3f8eaaf6532", "title": "Context-Aware Neural Machine Translation Learns Anaphora Resolution"}, {"paperId": "6a9e5377bbf28b86a1dd8cd5802998c949a34ff3", "title": "OpenSubtitles2018: Statistical Rescoring of Sentence Alignments in Large, Noisy Parallel Corpora"}, {"paperId": "b4bfadfca9742bb3ee98a0cd322d5ce4e59a3ceb", "title": "A Call for Clarity in Reporting BLEU Scores"}, {"paperId": "fc1d981dd051063ae586a56b05390fe3ea82f040", "title": "Achieving Human Parity on Automatic Chinese to English News Translation"}, {"paperId": "ae28c9932e7d16d6b2a25aa14532f9fd0138ba3a", "title": "Learning to Remember Translation History with a Continuous Cache"}, {"paperId": "5503ed99ad2a536e00508432e87553786e1eaa3f", "title": "Evaluating Discourse Phenomena in Neural Machine Translation"}, {"paperId": "2cc765e602458960c3fefadafd75456d6f85f958", "title": "Neural Machine Translation with Extended Context"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "fbe500cb74ea198227debe523e75ecff987153ea", "title": "Does Neural Machine Translation Benefit from Larger Context?"}, {"paperId": "8dde8967c8bf1c97a5614c70beb0eeeaf32d2e7c", "title": "Context Gates for Neural Machine Translation"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "c1e3a26fb88c6720f4e84b7118e6f2df7dc8efa3", "title": "From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "09b8c21374ce3d0a46e715a663c63894c1046a21", "title": "Extending Machine Translation Evaluation Metrics with Lexical Cohesion to Document Level"}, {"paperId": "339ca3fa2d3395b77ce605586b5fb749ded90c39", "title": "What\u2019s magic about magic numbers? Chunking and data compression in short-term memory"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "e248fc190121c5b0f731427bc4eb3baafbc56c22", "title": "Democratizing Machine Translation with OPUS-MT"}, {"paperId": "5f0a1418494c5c8cc669fbf3a3a8395020122a2a", "title": "COMET-22: Unbabel-IST 2022 Submission for the Metrics Shared Task"}, {"paperId": "04b5fe04fffe7fdddaa47cda3f1aa654d7a999fe", "title": "Context-aware Neural Machine Translation with Mini-batch Embedding"}, {"paperId": null, "title": "accuracy presented in Section 5, we also measured COMET (Rei et al.,"}, {"paperId": null, "title": "When a good translation is wrong in context: Context-aware machine translation improves on deixis, ellipsis, and lexical cohesion"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "7ccad715e253b360c646c77876535ad56633d39c", "title": "Neural Machine Translation"}, {"paperId": "6e25bf8558d4a43560ca038c4adc209e5f448ddc", "title": "Contextual Handling in Neural Machine Translation: Look behind, ahead and on both sides"}, {"paperId": "cb0ab255c4079e2082ba6e3a807529527d96687c", "title": "Overview of the IWSLT 2017 Evaluation Campaign"}, {"paperId": null, "title": "Discourse in statistical machine translation: A survey and a case study"}, {"paperId": "a15174ed603bae1b101c4655111bb511787b95b4", "title": "The magical number seven plus or minus two: some limits on our capacity for processing information."}, {"paperId": null, "title": "English-to-German and English-to-French respectively C Detailed Contrastive Results In this section we report the accuracy on the contrastive datasets for the different placements of"}, {"paperId": null, "title": "2022. Efficient transformers: A survey"}, {"paperId": null, "title": "for Computational Linguistics: NAACL 2022"}, {"paperId": null, "title": "2022. Recurrent memory transformer"}, {"paperId": null, "title": "Table 5 shows the number of parameters for each model"}]}