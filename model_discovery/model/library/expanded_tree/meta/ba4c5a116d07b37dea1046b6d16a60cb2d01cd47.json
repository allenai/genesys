{"paperId": "ba4c5a116d07b37dea1046b6d16a60cb2d01cd47", "abstract": "Sequence modeling is a crucial area across various domains, including Natural Language Processing (NLP), speech recognition, time series forecasting, music generation, and bioinformatics. Recurrent Neural Networks (RNNs) and Long Short Term Memory Networks (LSTMs) have historically dominated sequence modeling tasks like Machine Translation, Named Entity Recognition (NER), etc. However, the advancement of transformers has led to a shift in this paradigm, given their superior performance. Yet, transformers suffer from $O(N^2)$ attention complexity and challenges in handling inductive bias. Several variations have been proposed to address these issues which use spectral networks or convolutions and have performed well on a range of tasks. However, they still have difficulty in dealing with long sequences. State Space Models(SSMs) have emerged as promising alternatives for sequence modeling paradigms in this context, especially with the advent of S4 and its variants, such as S4nd, Hippo, Hyena, Diagnol State Spaces (DSS), Gated State Spaces (GSS), Linear Recurrent Unit (LRU), Liquid-S4, Mamba, etc. In this survey, we categorize the foundational SSMs based on three paradigms namely, Gating architectures, Structural architectures, and Recurrent architectures. This survey also highlights diverse applications of SSMs across domains such as vision, video, audio, speech, language (especially long sequence modeling), medical (including genomics), chemical (like drug design), recommendation systems, and time series analysis, including tabular data. Moreover, we consolidate the performance of SSMs on benchmark datasets like Long Range Arena (LRA), WikiText, Glue, Pile, ImageNet, Kinetics-400, sstv2, as well as video datasets such as Breakfast, COIN, LVU, and various time series datasets. The project page for Mamba-360 work is available on this webpage.\\url{https://github.com/badripatro/mamba360}.", "venue": "arXiv.org", "year": 2024, "citationCount": 11, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This survey consolidates the performance of SSMs on benchmark datasets like Long Range Arena, WikiText, Glue, Pile, ImageNet, Kinetics-400, sstv2, as well as video datasets such as Breakfast, COIN, LVU, and various time series datasets and highlights diverse applications of SSMs across domains, including tabular data."}, "embedding": {"model": "specter_v2", "vector": [0.3844101130962372, 0.3851441442966461, -0.22522373497486115, 0.014732662588357925, 0.04797552153468132, -0.35747551918029785, 0.7766278386116028, -0.14405247569084167, -0.32708215713500977, 0.0615004301071167, 0.556200385093689, -0.16374343633651733, 0.5724625587463379, 0.24899446964263916, -0.024891294538974762, -0.22340990602970123, -0.8636453747749329, 0.2864665389060974, 0.003926122561097145, -0.3429211378097534, 0.14982184767723083, -0.19287915527820587, -0.6846759915351868, -0.09037883579730988, -0.2345261573791504, 0.7125728726387024, -0.0008703737985342741, 0.8562154769897461, -0.766636073589325, 0.4849119782447815, 0.5688921213150024, -0.1049739420413971, 0.3356795608997345, -0.560563325881958, -0.5009699463844299, -0.16598659753799438, 0.2975713908672333, -0.2277839481830597, -0.6094565987586975, 0.668222963809967, -0.2814251780509949, 0.48227307200431824, 0.25848591327667236, -0.5757901668548584, 0.3931160569190979, 0.6570562124252319, 0.9003976583480835, 0.7319251298904419, -0.23594875633716583, -0.3638171851634979, 1.4458472728729248, -0.8566156029701233, 0.4429442882537842, 1.029611349105835, 0.4722387492656708, 0.7275493144989014, -0.4799521267414093, -0.9390063285827637, 0.7551096677780151, 0.4936257302761078, -0.45723339915275574, -0.13737165927886963, 0.2218172550201416, -0.30490460991859436, 1.7162601947784424, 0.17690205574035645, 0.6251817345619202, 0.9770594835281372, -0.12465564906597137, 1.0084525346755981, 0.3546743392944336, -0.5214763283729553, 0.29449939727783203, -0.005583271384239197, 0.6545120477676392, 0.8217132687568665, -0.44430476427078247, 0.5404714345932007, -1.1094331741333008, -0.21659338474273682, 0.5105240345001221, 0.3756682276725769, -0.012731047347187996, -0.2284255474805832, -0.40716227889060974, 0.90428626537323, 0.2620125114917755, 0.7532931566238403, -0.2594511806964874, 0.5772351622581482, 0.4816262423992157, 0.1463548094034195, -0.3620656430721283, 0.6634001135826111, -0.16512101888656616, 0.3388892412185669, -0.7015829086303711, 0.21198274195194244, 0.008629725314676762, 0.614601194858551, -0.33044230937957764, 0.6197047829627991, -0.5019793510437012, -0.1211150735616684, 1.3010971546173096, -0.41373199224472046, 0.5528684854507446, -0.6654229164123535, -0.08051132410764694, -0.45305848121643066, 0.41618281602859497, -0.44548943638801575, -0.3424064815044403, -0.11591435223817825, -0.8369433879852295, -1.2000362873077393, -0.4846957325935364, 0.426365464925766, -0.767920732498169, 0.8185528516769409, -0.5849295854568481, 0.9658389091491699, 0.15412461757659912, 0.37292006611824036, 0.490680068731308, 1.0473235845565796, 0.3208640515804291, -0.5511605143547058, 0.5428962707519531, -0.6745861172676086, -0.9872370362281799, -0.9297041893005371, 0.43807339668273926, 0.5747467875480652, -0.3088598847389221, -0.11933385580778122, -1.1922354698181152, -0.8652542233467102, -0.9315046072006226, 0.5825042128562927, -0.5585851669311523, -0.1724403202533722, 0.970474898815155, 0.08928943425416946, -0.6711681485176086, 0.9244091510772705, -0.7848427891731262, -0.644214928150177, 0.03497399389743805, 0.1182478740811348, 0.32845011353492737, 0.2473905235528946, -1.4517066478729248, 0.6492846012115479, 0.5853288769721985, -0.3584243059158325, -0.41189154982566833, -0.333644837141037, -0.8990305662155151, 0.056995660066604614, 0.008962996304035187, -0.22993940114974976, 0.9213834404945374, 0.507056713104248, -1.3770580291748047, 0.37914952635765076, -0.05667239427566528, -0.3148178160190582, 0.2723495364189148, 0.18879789113998413, -0.46184325218200684, -0.6101343631744385, -0.4866885542869568, 0.15004903078079224, -0.0036015717778354883, 0.04868467524647713, -0.10941948741674423, -0.002396232448518276, -0.6379654407501221, -0.492074579000473, -0.216485396027565, 0.8214364647865295, -0.03865278512239456, 0.05838019773364067, 0.4869275391101837, 0.24274125695228577, -0.6107637286186218, -0.20806244015693665, -0.3929969072341919, -0.7330496907234192, 0.4507819414138794, 0.05112552270293236, 1.4494868516921997, -0.5296180248260498, -0.5678126811981201, -0.2684379816055298, -0.42506903409957886, 0.0030897706747055054, -0.6689784526824951, 0.6980859041213989, -0.8196985125541687, 0.11308638006448746, -0.3140389919281006, -0.7816178202629089, -0.3530818521976471, 0.017318660393357277, -0.8795148730278015, 0.0931343138217926, 0.049220990389585495, 1.0073493719100952, -0.9106771349906921, 0.307003378868103, 0.40201884508132935, -0.13648734986782074, -0.7755979299545288, 1.314958095550537, -0.2948525846004486, 0.3134516179561615, 0.0188171174377203, -0.34624576568603516, -0.328879177570343, -0.6421732902526855, 0.8416135907173157, -0.4320835769176483, -0.40546804666519165, 0.6316721439361572, -0.8323856592178345, 1.6770031452178955, 0.17564886808395386, 0.4308087229728699, -0.38028594851493835, -1.0183827877044678, 0.5507764220237732, 0.5394106507301331, 0.1506900042295456, -0.25794118642807007, 0.2393682301044464, 0.1777261197566986, -0.7426905035972595, 0.29098349809646606, 0.17042896151542664, 0.6256778836250305, -0.26716145873069763, 0.021588319912552834, 0.6714968085289001, -0.2678006887435913, 0.4897018074989319, 0.4680856168270111, 0.7604414224624634, 0.29316744208335876, 0.529375433921814, 0.023987341672182083, 0.18674367666244507, -1.0270107984542847, 0.4212566018104553, 0.27162304520606995, 0.19719380140304565, 0.9182361364364624, 0.21409854292869568, -0.9445240497589111, -0.61027991771698, 0.14623737335205078, 0.7721377611160278, 0.7586245536804199, -0.08533505350351334, -0.7014526128768921, -0.4434037506580353, 0.005825743544846773, -0.6585935354232788, 0.2225620001554489, -0.4082716405391693, -0.2909429669380188, -0.6709097027778625, -1.1138523817062378, 0.38883641362190247, 0.5486536026000977, 0.5119160413742065, -0.6867395639419556, -0.41054368019104004, 0.09122614562511444, 0.2288879007101059, -0.5547945499420166, -0.3331694006919861, 0.5430502891540527, -0.796433687210083, -0.3009740710258484, 0.18492203950881958, 0.17743965983390808, -0.4063974618911743, -0.9619812965393066, 0.7659643292427063, -0.9213757514953613, -0.29298290610313416, 0.010581869632005692, 0.7909988164901733, -0.770122230052948, -0.6660692691802979, -0.09114105254411697, 0.1971811056137085, -0.2107166349887848, 0.1669350415468216, 0.28404033184051514, -0.02968548983335495, -0.2486134171485901, -0.188249409198761, 0.3132440745830536, -0.2431013286113739, 0.41389596462249756, 0.6001030206680298, -0.6764808297157288, 0.15479567646980286, -0.8949893712997437, 0.38435864448547363, 0.0971316248178482, -0.7763007879257202, 0.16823267936706543, -1.0167980194091797, -0.17660605907440186, 0.17642515897750854, -0.4871204197406769, 0.11864867806434631, -0.5139240026473999, 0.21008113026618958, -0.7573860287666321, -0.13261328637599945, 0.22164557874202728, 0.5662830471992493, 0.6834414601325989, 0.046913158148527145, 0.6272266507148743, 0.38037973642349243, -0.15303857624530792, 0.3169310688972473, -0.7903561592102051, 0.3944259285926819, 0.8113515377044678, -0.04731263592839241, -0.07280454784631729, 0.27851900458335876, -0.6762349605560303, -0.6793580651283264, -0.4975742995738983, -0.2512594759464264, -0.14292356371879578, 0.33581188321113586, -0.5338726043701172, -0.9826125502586365, 0.09302007406949997, -1.0021270513534546, -0.16557607054710388, 0.10280005633831024, -0.26107919216156006, -0.5073215961456299, -1.0599182844161987, -1.2685761451721191, -0.9305038452148438, -0.4344446659088135, -0.7167642712593079, -0.05187930539250374, 0.16333283483982086, -0.5898296236991882, -0.48393112421035767, 0.37851911783218384, -0.4710592031478882, 0.6364883184432983, -0.18257620930671692, 0.7197579145431519, -0.3891354203224182, -0.20658250153064728, -0.2336423397064209, 0.6982055306434631, 0.3101041913032532, -0.042119525372982025, 0.11539283394813538, -0.6182652711868286, 0.06705231219530106, -0.1446761041879654, -0.09615641832351685, 0.3080541491508484, 0.4736826419830322, 0.6122902631759644, 0.05779695510864258, -0.30264392495155334, 0.27278849482536316, 0.9315458536148071, -0.0023099803365767, 0.06296197324991226, 0.10419921576976776, 0.8389754891395569, 0.004425908904522657, -0.10377347469329834, 0.7440949082374573, -0.15911053121089935, 0.28124678134918213, 0.4412628412246704, 0.06050518527626991, 0.3524480164051056, -0.5634682178497314, 0.5128376483917236, 1.623882532119751, 0.3021152913570404, 0.11971723288297653, -0.6847376227378845, 0.7033942341804504, -1.3151977062225342, -1.0859858989715576, 0.7354134917259216, 0.5104016065597534, 0.5714765787124634, -0.3678811192512512, 0.059005651623010635, 0.28549283742904663, 0.5509017705917358, 0.545628547668457, -0.7062198519706726, -0.5650360584259033, -0.20785899460315704, 0.5032710433006287, 0.15519902110099792, 0.332262247800827, -0.28447413444519043, 0.24017676711082458, 15.338301658630371, 0.5482375025749207, -0.42053043842315674, 0.1496523767709732, 0.5721365809440613, -0.1060863807797432, 0.0874936655163765, 0.17802269756793976, -1.1438685655593872, 0.19105127453804016, 1.6915987730026245, 0.2718801200389862, 0.31700649857521057, 0.06251844018697739, 0.05745355412364006, 0.6596564650535583, -0.7229604125022888, 0.9906225204467773, 0.14918291568756104, -1.8716914653778076, 0.2387745976448059, 0.033578481525182724, 0.23260357975959778, 0.6331068277359009, 0.7540794014930725, 0.5411799550056458, 0.29076099395751953, -0.45379871129989624, 0.5229357481002808, 0.563011109828949, 0.9337154626846313, 0.09403152763843536, 0.3208516538143158, 0.46276500821113586, -1.0255212783813477, -0.4091581702232361, -0.14775227010250092, -1.044937252998352, 0.31679895520210266, -0.40634557604789734, -0.42806118726730347, -0.5093792676925659, -0.2796718180179596, 1.0812920331954956, 0.6129072308540344, 0.18982400000095367, 0.14877533912658691, 0.9227622151374817, 0.08822386711835861, -0.05137045681476593, 0.5516272783279419, -0.32330530881881714, 0.20257307589054108, -0.2921425402164459, 0.10687056183815002, 0.3321216404438019, 0.33456456661224365, 0.3135566711425781, -0.06973599642515182, -0.3600471615791321, -0.30845946073532104, -0.8019060492515564, -0.014891048893332481, 0.6658217906951904, 0.5107451677322388, 0.07770489156246185, -0.40013688802719116, 0.09443043917417526, 0.1627494841814041, 0.21859198808670044, -0.5163674354553223, -0.05225738510489464, 0.6687464714050293, -0.390148788690567, -0.134333536028862, 0.4508659839630127, -0.08230702579021454, -0.5647724866867065, -1.2189851999282837, -0.2699257433414459, 0.5928229093551636, -0.8309144973754883, -0.6460533142089844, 1.0049299001693726, -0.4296988844871521, -0.45737287402153015, 0.11471262574195862, -0.7924080491065979, -0.24084362387657166, 0.41226479411125183, -1.103731632232666, -0.2600088119506836, 0.1499377191066742, -0.25376901030540466, -0.03492806479334831, -0.20892782509326935, 1.432722806930542, -0.15377146005630493, -1.0253592729568481, -0.6411185264587402, 0.19904150068759918, -0.09840579330921173, -0.5298984050750732, -0.927897036075592, 1.0295631885528564, 0.1317128837108612, 0.15684296190738678, 0.3004872500896454, 0.3348350524902344, 0.25723040103912354, -0.7898768186569214, -0.2560858726501465, 0.15055714547634125, -1.0039554834365845, 0.02169048972427845, -0.7695786356925964, -1.0769522190093994, 0.41514697670936584, 0.10111955553293228, -0.21478120982646942, 0.16229179501533508, -0.3514515161514282, -0.26190802454948425, 0.05830497667193413, -0.3896861970424652, -0.035990823060274124, 0.6434856653213501, -0.9958087205886841, -0.48932504653930664, -0.25198307633399963, 0.38414260745048523, -0.5319189429283142, -0.5054382681846619, 0.12459214776754379, -0.03778625652194023, -0.15735311806201935, 0.946198582649231, -1.0228937864303589, 0.22508352994918823, 0.8087939620018005, -0.2657242715358734, -0.5960842370986938, -0.34267881512641907, -1.0399173498153687, -0.46624892950057983, -0.07292263209819794, 0.29259344935417175, -0.43865901231765747, 0.710340142250061, 0.665885865688324, 0.06166575849056244, -0.6806835532188416, -0.7051360011100769, -0.4001619517803192, -0.3544134497642517, -0.11152175813913345, 0.3954694867134094, -0.036515962332487106, -0.07726874202489853, 0.3851863741874695, 0.18396762013435364, 0.34293133020401, -0.37154483795166016, -0.3860873878002167, -0.11781229078769684, -0.4232892096042633, 0.20864318311214447, -0.5587702989578247, -0.6020839214324951, -1.17043936252594, 0.12881702184677124, -1.102128267288208, -0.1395730823278427, -0.9149870872497559, -0.11943237483501434, 0.16318358480930328, -0.9215571284294128, -0.0949305072426796, 0.5757867693901062, -0.5712667107582092, -0.570320188999176, -0.5406869649887085, -0.4979167878627777, 0.8435193300247192, 0.5679711103439331, -0.6996558308601379, -0.09785594791173935, -0.1549701690673828, 0.34699514508247375, 0.1404619663953781, 0.3886251747608185, -0.22103649377822876, -0.6920113563537598, -0.4934403598308563, 0.09428820013999939, 0.46193641424179077, -0.3140909969806671, -0.7706958055496216, 0.3858291804790497, -0.09556541591882706, -0.26740944385528564, -0.3694978654384613, 1.0262941122055054, -0.7039507031440735, 0.4382535219192505, 0.8191699981689453, -0.9726450443267822, 0.026417478919029236, 0.08152319490909576, -0.3579084575176239, -0.27480578422546387, 0.7438169121742249, 0.29710766673088074, -1.017793893814087, -0.5201209783554077, 0.7883431911468506, -0.5699185132980347, -0.47851747274398804, 0.025527672842144966, -0.2735078036785126, -0.6608548760414124, -0.17011871933937073, -0.3857065439224243, 0.2609318196773529, -0.5542327165603638, 0.8201080560684204, 0.4127953052520752, -1.1170299053192139, 0.13533654808998108, 0.3292222321033478, 0.17789341509342194, -0.4929085373878479, 0.12791186571121216, 0.2207430601119995, 0.008816342800855637, 0.9558870196342468, 0.0573585107922554, 0.22595834732055664, -0.9421936273574829, 0.2327314168214798, 0.9171006083488464, -0.21773351728916168, -0.14780180156230927, 1.1300990581512451, -0.3871607184410095, -0.7256389260292053, 0.2463914304971695, -1.051031231880188, -0.8375415205955505, -0.05684787407517433, 0.47871968150138855, 0.465507447719574, -0.242026224732399, -0.02883986197412014, -0.5141786336898804, 0.10010658949613571, 0.16478702425956726, -0.42380136251449585, 0.9826868176460266, -0.08397872745990753, -0.08248703926801682, 1.3820799589157104, 0.8797731399536133, -1.397737979888916, -0.8577370643615723, -0.5354917049407959, 0.012364331632852554, 0.0365181565284729, 0.2264358103275299, -0.2466471791267395, -0.4824022650718689, 0.7853122353553772, 1.1101751327514648, 0.35283324122428894, 0.09630943834781647, -0.17527911067008972, 0.21550922095775604, 0.5457578301429749, 0.04028432443737984, -0.5032681226730347, -0.44057971239089966, 1.1063685417175293, 1.3179574012756348, -0.7067025899887085, 0.19769155979156494, -0.017143050208687782, -0.6281115412712097, 0.6384231448173523, 0.19894209504127502, -0.18420234322547913, 0.7742980718612671, -0.546454131603241, 0.022647064179182053, 0.05317000299692154, -1.4400839805603027, -0.11992300301790237, 0.36678582429885864, 0.6450225710868835, 0.5521170496940613, 0.18494358658790588, 0.26195213198661804, 0.8766965270042419, 0.4264064133167267, 0.056633275002241135, 0.6895605325698853, 0.6839349269866943, 0.03446754813194275, 0.055649589747190475, 0.08924052119255066, 0.7148794531822205, -0.414430171251297, -0.4421509802341461, 0.15151944756507874, 0.05596203729510307, -0.2867826521396637, 0.5140785574913025, 1.1353579759597778, 0.08217263221740723, 0.6809252500534058, 0.4129458963871002, 0.37032246589660645, -0.527873158454895, -0.20116209983825684, -0.1121833324432373, -0.6792436242103577, -0.5346724390983582, -0.2951960861682892, -0.7343048453330994, -0.4450276494026184, 0.12875518202781677, -0.14893776178359985, 0.5659799575805664, 0.5757566690444946, 0.7503250241279602, 0.6050223708152771, 0.33723825216293335, -0.12659431993961334, -0.3916637897491455, -0.695060670375824, -0.887685239315033, -0.1542840301990509, -0.19939181208610535, 0.19883884489536285, -0.31093618273735046, -0.16856907308101654, -0.1987912803888321]}, "authors": [{"authorId": "2064356655", "name": "B. N. Patro"}, {"authorId": "2260868841", "name": "Vijay S. Agneeswaran"}], "references": [{"paperId": "d985e46330dcb76e3e7700e84693d4080061a3e8", "title": "SPMamba: State-space model is all you need in speech separation"}, {"paperId": "8ea1c26d5d6ae19f98381a610b277e5887221f02", "title": "T-Mamba: Frequency-Enhanced Gated Long-Range Dependency for Tooth 3D CBCT Segmentation"}, {"paperId": "bb6afe666ffd07d9059ec94cac551c2b1f33f096", "title": "SpikeMba: Multi-Modal Spiking Saliency Mamba for Temporal Video Grounding"}, {"paperId": "9b8130a2a5d3398f4993f540ddd01d440d99d62e", "title": "Decision Mamba: Reinforcement Learning via Sequence Modeling with Selective State Spaces"}, {"paperId": "3e4ed3b3790980efbb537d381c7bc020eefed53f", "title": "MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection"}, {"paperId": "cbaf689fd9ea9bc939510019d90535d6249b3367", "title": "Jamba: A Hybrid Transformer-Mamba Language Model"}, {"paperId": "5f07ef98b64b2ab47105018cbda158527f903b28", "title": "RSMamba: Remote Sensing Image Classification With State Space Model"}, {"paperId": "69fa358ca1680ff2779477bdab2f42851c2499ca", "title": "Gamba: Marry Gaussian Splatting with Mamba for single view 3D reconstruction"}, {"paperId": "da9178eae82d1ca5492aaecd0151ba49481cb8b1", "title": "Dual-path Mamba: Short and Long-term Bidirectional Selective Structured State Space Models for Speech Separation"}, {"paperId": "62ac3ef81e54e1d1930fb5980b236345ee2e4f32", "title": "PlainMamba: Improving Non-Hierarchical Mamba in Visual Recognition"}, {"paperId": "809bc79e023e69af78b2739fc7e4c60bfbdd1b7b", "title": "Heracles: A Hybrid SSM-Transformer Model for High-Resolution Image and Time-Series Analysis"}, {"paperId": "9bd60a0b1b5e70c9e6ccfde513f8fdea61d8b503", "title": "ReMamber: Referring Image Segmentation with Mamba Twister"}, {"paperId": "278c122ff695a0ded29af43a719a76b97763161c", "title": "CMViM: Contrastive Masked Vim Autoencoder for 3D Multi-modal Representation Learning for AD classification"}, {"paperId": "fea8a3096391a418cb9ef724e0ff9754e5a467fd", "title": "SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series"}, {"paperId": "40e996a7c3e914a67c708704fa9b4c54ea70f36e", "title": "Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference"}, {"paperId": "904563400562d35226618839fd7f3c3de23179bf", "title": "ProMamba: Prompt-Mamba for polyp segmentation"}, {"paperId": "6d49ed0ea24b9c218f5ec6731cd261ce618df2ac", "title": "VL-Mamba: Exploring State Space Models for Multimodal Learning"}, {"paperId": "206974b54e00c1145157d6bc4229b9a2b77ea929", "title": "H-vmunet: High-order Vision Mamba UNet for Medical Image Segmentation"}, {"paperId": "46f33203f6f50bbd38d2e3e3eb1aa4f3eb66715d", "title": "STG-Mamba: Spatial-Temporal Graph Learning via Selective State Space Model"}, {"paperId": "5867382590f9f0ff8caf15804d20bde10845b2d2", "title": "LocalMamba: Visual State Space Model with Windowed Selective Scan"}, {"paperId": "4d3ffd8feca81d750aa30122b49cc1e874e70c1a", "title": "MAMBA: an Effective World Model Approach for Meta-Reinforcement Learning"}, {"paperId": "3a0c5026f7ea965dc4475c8d857fc3b6df27ae05", "title": "TimeMachine: A Time Series is Worth 4 Mambas for Long-term Forecasting"}, {"paperId": "319762c8841f8e1e413642bc551ed748add4777b", "title": "Multichannel Long-Term Streaming Neural Speech Enhancement for Static and Moving Speakers"}, {"paperId": "4e03f7bb27b8ce6a7a0f22bd07dad65f4a45ca3f", "title": "LKM-UNet: Large Kernel Vision Mamba UNet for Medical Image Segmentation"}, {"paperId": "3af7273d7ca20c0c63cbaa47e60b058840835052", "title": "VideoMamba: State Space Model for Efficient Video Understanding"}, {"paperId": "a7b6c089f50aeed1361582338610587b0e76d0a4", "title": "LightM-UNet: Mamba Assists in Lightweight UNet for Medical Image Segmentation"}, {"paperId": "9463ef5f893e4ade0363242894be081f7684350f", "title": "MedMamba: Vision Mamba for Medical Image Classification"}, {"paperId": "d53fe76bd2795a19ddf52d012917782f6f6f2c1e", "title": "Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models"}, {"paperId": "7351898febca53d01453283c9b1a541b662e1ed3", "title": "DenseMamba: State Space Models with Dense Hidden Connection for Efficient Large Language Models"}, {"paperId": "f97440c1eacd628453da4c66030f303ad19f1c80", "title": "Res-VMamba: Fine-Grained Food Category Visual Classification Using Selective State Space Models with Deep Residual Learning"}, {"paperId": "e730beb44042499763d36214c0498434e470dfd5", "title": "MambaIR: A Simple Baseline for Image Restoration with State-Space Model"}, {"paperId": "0682771fd5f611bce2a536bf83587532469a83df", "title": "Weak-Mamba-UNet: Visual Mamba Makes CNN and ViT Work Better for Scribble-based Medical Image Segmentation"}, {"paperId": "bbe0e4cc9b052e960362fdc18b6805043b81ca6b", "title": "On Limitations of the Transformer Architecture"}, {"paperId": "2dda6da7375bf5e8bcf60f87b17ba10757f3bc57", "title": "Graph Mamba: Towards Learning on Graphs with State Space Models"}, {"paperId": "fe54abaf7a3973202158ed73cc8ec1bb5643782a", "title": "P-Mamba: Marrying Perona Malik Diffusion with Mamba for Efficient Pediatric Echocardiographic Left Ventricular Segmentation"}, {"paperId": "1498e54ace1140cdb73aef51b44b7a573101c623", "title": "FD-Vision Mamba for Endoscopic Exposure Correction"}, {"paperId": "906d0688e1c683d5fec70e88e71ea1291c666b78", "title": "Mamba-ND: Selective State Space Modeling for Multi-Dimensional Data"}, {"paperId": "9da427202cc48370fd66359f5d72ff5ff3bc8b57", "title": "Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks"}, {"paperId": "98a7444a221e27f51c89c58fa29a8a1e168c6d69", "title": "Swin-UMamba: Mamba-based UNet with ImageNet-based pretraining"}, {"paperId": "57a6c75ebb987ea29a1f904de23f72451e095032", "title": "Is Mamba Capable of In-Context Learning?"}, {"paperId": "9ed5300327d7a45e408ff418334382fe9ca460a3", "title": "nnMamba: 3D Biomedical Image Segmentation, Classification and Landmark Detection with State Space Model"}, {"paperId": "ffaa66e698655d4b2dee1ab61448d5cc1a743a63", "title": "VM-UNet: Vision Mamba UNet for Medical Image Segmentation"}, {"paperId": "189fde3f4dfa105bb51472a8945618f395919560", "title": "Repeat After Me: Transformers are Better than State Space Models at Copying"}, {"paperId": "1df04f33a8ef313cc2067147dbb79c3ca7c5c99f", "title": "Graph-Mamba: Towards Long-Range Graph Sequence Modeling with Selective State Spaces"}, {"paperId": "3169a2478154e26fd7f63fdf43cf3a24f1007962", "title": "BlackMamba: Mixture of Experts for State-Space Models"}, {"paperId": "3719ad19da30771aba5d5c48491a21d6c393832d", "title": "Vivim: a Video Vision Mamba for Medical Video Object Segmentation"}, {"paperId": "a6e2dca754f3dc625a9da5f10f9b7a57079bfd27", "title": "MambaByte: Token-free Selective State Space Model"}, {"paperId": "5358b0e98934f1bbe8f6123a529bbb91dd36d662", "title": "SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation"}, {"paperId": "b24e899ec0f77eef2fc87a9b8e50516367aa1f97", "title": "VMamba: Visual State Space Model"}, {"paperId": "38c48a1cd296d16dc9c56717495d6e44cc354444", "title": "Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model"}, {"paperId": "95b2cb3f4a765014ce025afe5679660982554e6c", "title": "MambaTab: A Plug-and-Play Model for Learning Tabular Data"}, {"paperId": "c1a04730c83967d0bb904b02263b17893cb50bad", "title": "U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation"}, {"paperId": "745594bd0dc3e9dc86f74e100cd2c98ed36256c0", "title": "MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts"}, {"paperId": "ece33ee67d74c29cd2a83c505e5bf0b818f9c2a1", "title": "LLaVA-Phi: Efficient Multi-Modal Assistant with Small Language Model"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "5c104f905fcacf390270f619f232a2ba4eb873f2", "title": "FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores"}, {"paperId": "434d751d355d7a7c20efa570e785c76286245e77", "title": "Hierarchically Gated Recurrent Neural Network for Sequence Modeling"}, {"paperId": "ab892825da3c560ff72d84d57a4239a6f12fa8b9", "title": "Scattering Vision Transformer: Spectral Mixing Matters"}, {"paperId": "c85268696fe1435605ae66a18653cfdcf8153753", "title": "Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture"}, {"paperId": "0d118f5db08317b019f08b59fb24e87793a163f9", "title": "Rethinking the BERT-like Pretraining for DNA Sequences"}, {"paperId": "b06e1a2c84fb3bff03b10283bc863f007f5483b6", "title": "The Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics"}, {"paperId": "fc6a2f7478f68adefd69e2071f27e38aa1647f2f", "title": "Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond"}, {"paperId": "94972e30504017156ef5b5debc419bf6edc67384", "title": "MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities"}, {"paperId": "b37b1dc72b1882858f5120f2cd6883134089a6ed", "title": "MMBench: Is Your Multi-modal Model an All-around Player?"}, {"paperId": "e2a58fd18961c3941102989e3a3d0d27c615e015", "title": "Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic"}, {"paperId": "bfd2b76998a0521c12903ef5ced517adf70ad2ba", "title": "HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution"}, {"paperId": "ebedc4d7a2356090904baba4104ef0832bc236df", "title": "A Survey on Multimodal Large Language Models"}, {"paperId": "948e8cfae92c2004f2dd5c9316f5972f8baaea21", "title": "OBELISC: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents"}, {"paperId": "d47524cd5c3c4b57af2e5a29f6f91c420310f236", "title": "MIMIC-IT: Multi-Modal In-Context Instruction Tuning"}, {"paperId": "42cf52baff90952944da0409ec52ff7611ed55dc", "title": "Representational Strengths and Limitations of Transformers"}, {"paperId": "4d628e6def9970b62096d564dba0c748fab653aa", "title": "De Novo Design of Nurr1 Agonists via Fragment-Augmented Generative Deep Learning in Low-Data Regime"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "206400aba5f12f734cdd2e4ab48ef6014ea60773", "title": "Evaluating Object Hallucination in Large Vision-Language Models"}, {"paperId": "412e266cddfd87c79087a88ba1e4d11b89a45a13", "title": "MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers"}, {"paperId": "8bd6a2a89503be083176f2cc26fabedb79238cbd", "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"}, {"paperId": "f35f5aedc30e2c5ded210d9c91ba6e84bd029425", "title": "Toeplitz Neural Network for Sequence Modeling"}, {"paperId": "7e32aac43e9f1df49e116add03327ee6f365dbf3", "title": "mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality"}, {"paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8", "title": "Visual Instruction Tuning"}, {"paperId": "c57467e652f3f9131b3e7e40c23059abe395f01d", "title": "SpectFormer: Frequency and Attention is what you need in a Vision Transformer"}, {"paperId": "0810afe92ec3b0b31183648aae2b4dc77dea734f", "title": "Unmasked Teacher: Towards Training-Efficient Video Foundation Models"}, {"paperId": "983d8b87693e909eb8b2f2fe74a6244dd65b61ee", "title": "Selective Structured State-Spaces for Long-Form Video Understanding"}, {"paperId": "f393aff1593c2d370ec0ae004910d18e40524967", "title": "Resurrecting Recurrent Neural Networks for Long Sequences"}, {"paperId": "6ef892cd47300c56a72ff67bc7b87b43b3654e16", "title": "A critical look at the evaluation of GNNs under heterophily: are we really making progress?"}, {"paperId": "998ac3e945857cf2676ee7efdbaf443a0c6f820a", "title": "Hyena Hierarchy: Towards Larger Convolutional Language Models"}, {"paperId": "a9d13e00c30fa82ec201587719efc11a11fceb7e", "title": "Efficiency 360: Efficient Vision Transformers"}, {"paperId": "54155c2977a977bf129849455dcae3a2b79b3f41", "title": "Simple Hardware-Efficient Long Convolutions for Sequence Modeling"}, {"paperId": "9cf9bd2ce5f7caef3c3a6ee2785d24f60a27c90a", "title": "Chemical language models for de novo drug design: Challenges and opportunities."}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "661e8d555c4424b5953f17434f2ba910bfcf3afe", "title": "Efficient Long Sequence Modeling via State Space Augmented Transformer"}, {"paperId": "dad15404d372a23b4b3bf9a63b3124693df3c85e", "title": "A Time Series is Worth 64 Words: Long-term Forecasting with Transformers"}, {"paperId": "240300b1da360f22bf0b82c6817eacebba6deed4", "title": "What Makes Convolutional Models Great on Long Sequence Modeling?"}, {"paperId": "09312f70402847d4c2b5b5348d902ad0b2d4a0d5", "title": "Turbo Training with Token Dropout"}, {"paperId": "b40f0b0465cdf4b487fb2ef85d4e2672c4b623cc", "title": "Liquid Structural State-Space Models"}, {"paperId": "70e91e16eb321067d9402710e14a40cf28311f73", "title": "Mega: Moving Average Equipped Gated Attention"}, {"paperId": "d3135733aa39dec20ce72aa138589dda27c8406d", "title": "Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering"}, {"paperId": "6d7d141c75af752ffc0d8a6184cca3f9323d6c74", "title": "Simplified State Space Layers for Sequence Modeling"}, {"paperId": "de32da8f5c6a50a6c311e9357ba16aa7d05a1bc9", "title": "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes"}, {"paperId": "0b8e8760d7dd64c7439019aeb3b6ac55dd5075d4", "title": "Wave-ViT: Unifying Wavelet and Transformers for Visual Representation Learning"}, {"paperId": "0cd31a2c81f9c14d6f9c0dc810bf98388d8be459", "title": "Branchformer: Parallel MLP-Attention Architectures to Capture Local and Global Context for Speech Recognition and Understanding"}, {"paperId": "eaef083b9d661f42cc0d89d9d8156218f33a91d9", "title": "Long Range Language Modeling via Gated State Spaces"}, {"paperId": "ca444821352a4bd91884413d8070446e2960715a", "title": "On the Parameterization and Initialization of Diagonal State Space Models"}, {"paperId": "238e4958773a5d9d3260f05e2532996b8b7dbaea", "title": "Towards a General Purpose CNN for Long Range Dependencies in ND"}, {"paperId": "dd1139cfc609c2f3263d02e97176d5275caebc0a", "title": "EfficientFormer: Vision Transformers at MobileNet Speed"}, {"paperId": "dbf6e95cb618f207f029276a6df11f4a9a6313d4", "title": "Inception Transformer"}, {"paperId": "004b97aea43f9f62cc49dec20f449abfbae28811", "title": "Masked Autoencoders As Spatiotemporal Learners"}, {"paperId": "2ad12a7be5eaf339a98c4defd8669e11fe726acc", "title": "MaxViT: Multi-Axis Vision Transformer"}, {"paperId": "9226ae23b95b3f6891461e086d910ffeb7ac448a", "title": "Long Movie Clip Classification with State-Space Video Models"}, {"paperId": "71e15a9a52dcafca57bff5f310b95e2c7d0cfc87", "title": "Diagonal State Spaces are as Effective as Structured State Spaces"}, {"paperId": "4990f7542f0600e0501a7e7a931b32eb7cb804d5", "title": "VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training"}, {"paperId": "736eb449526fe7128917954ec5532b59e318ec78", "title": "Block-Recurrent Transformers"}, {"paperId": "dc0102a51a9d33e104a4a3808a18cf17f057228c", "title": "Transformer Quality in Linear Time"}, {"paperId": "b55ee75940d24934a54d7f1acfde06e9cb45ac44", "title": "It's Raw! Audio Generation with State-Space Models"}, {"paperId": "c49ac1f916d6d2edeb187e6619c8d23acd95eb21", "title": "cosFormer: Rethinking Softmax in Attention"}, {"paperId": "563bac1c5cdd5096e9dbf8d4f3d5b3c4f7284e06", "title": "FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting"}, {"paperId": "574acd10c3206fda0492d8364a6ebf21b66fb0e0", "title": "Learning To Recognize Procedural Activities with Distant Supervision"}, {"paperId": "f4b11a696aa5a03fed1bfc47e65fdb7eb0e529c1", "title": "UniFormer: Unifying Convolution and Self-Attention for Visual Recognition"}, {"paperId": "9f951b58fc21926f94fc68d9b565d31cc02e8623", "title": "BEVT: BERT Pretraining of Video Transformers"}, {"paperId": "9137efc758f80dd22bb56f82cca5c94f78a5db3e", "title": "MViTv2: Improved Multiscale Vision Transformers for Classification and Detection"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "a9c352cce882f31e7f28dbe96794e10b089c6623", "title": "Scaled ReLU Matters for Training Vision Transformers"}, {"paperId": "dbf53ece1a6a8860e41ff5f721c72ceb0fb18dd6", "title": "H-Transformer-1D: Fast One-Dimensional Hierarchical Attention for Sequences"}, {"paperId": "0b036cd5dfc49d835d0c759c8ca31d89f2410e65", "title": "CMT: Convolutional Neural Networks Meet Vision Transformers"}, {"paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"}, {"paperId": "1fb10189c500e4902cd1b5afd406f57323d21be8", "title": "VOLO: Vision Outlooker for Visual Recognition"}, {"paperId": "fc46ccb83dc121c33de7ab6bdedab7d970780b2f", "title": "Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting"}, {"paperId": "78a0fb70b79116eb8d42c5951ced4f9efba513f0", "title": "Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers"}, {"paperId": "780bd9eaa032be199ae5e6b7c239e5a4ae8f42ed", "title": "CT-Net: Channel Tensorization Network for Video Classification"}, {"paperId": "af679d69fcc1d0fcf0f039aba937853bcb50a8de", "title": "Luna: Linear Unified Nested Attention"}, {"paperId": "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500", "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling"}, {"paperId": "e34ba5f2eeb8c39ee8369f66df9798648ede3e5a", "title": "Towards Long-Form Video Understanding"}, {"paperId": "40ade43c86d706eaeff72c2daf0661eb306b48f7", "title": "Graph-based High-order Relation Modeling for Long-term Action Recognition"}, {"paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de", "title": "Pay Attention to MLPs"}, {"paperId": "1f133158a8973fb33fea188f20517cd7e69bfe7f", "title": "FNet: Mixing Tokens with Fourier Transforms"}, {"paperId": "b6382a7351c0c595f91472ac71d3b2d87b3c4844", "title": "ViViT: A Video Vision Transformer"}, {"paperId": "63e838bb935f5ebe3498107e753f07f08a8b5689", "title": "An Image is Worth 16x16 Words, What is a Video Worth?"}, {"paperId": "fa08b41ccdfc5d8771adfbc34c176fa237d4646c", "title": "Is Space-Time Attention All You Need for Video Understanding?"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "5c305ea1e3b6c4eb6cbed3f6e040a177414d6b0e", "title": "Combining generative artificial intelligence and on-chip synthesis for de novo drug design"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "2ad2981a53393dc5987419a22cbe1ee3d7fa6e42", "title": "TDN: Temporal Difference Networks for Efficient Action Recognition"}, {"paperId": "35a9749df07a2ab97c51af4d260b095b00da7676", "title": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "0964490205fdc38c2f0980c9d778069089ca92e3", "title": "HiPPO: Recurrent Memory with Optimal Polynomial Projections"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "1b9a07702cd346673b4c5e798d2256157fab1d3f", "title": "Liquid Time-constant Networks"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "0170fc76e934ee643f869df18fb617d5357e8b4e", "title": "Conformer: Convolution-augmented Transformer for Speech Recognition"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "a326d9f2d2d351001fece788165dbcbb524da2e4", "title": "D4RL: Datasets for Deep Data-Driven Reinforcement Learning"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "908cca0abefc35acc38033603714fbb1bcadc49d", "title": "X3D: Expanding Architectures for Efficient Video Recognition"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "6a9d69fb35414b8461573df333dba800f254519f", "title": "Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "dc52b09089704ebd6f471177474bc29741c50023", "title": "Fast Transformer Decoding: One Write-Head is All You Need"}, {"paperId": "4012d4ab621f3f5f04b0f91849a60c6eaabe64b4", "title": "An Optimistic Perspective on Offline Reinforcement Learning"}, {"paperId": "a6aca3527e123849b740d63e064051a1a46ecec6", "title": "WHAM!: Extending Speech Separation to Noisy Environments"}, {"paperId": "3d17bc4c3ffcf9e2ecebcae0f5f24f9ee8cc0dcf", "title": "VideoGraph: Recognizing Minutes-Long Human Activities in Videos"}, {"paperId": "af1f7739283bdbd2b7a94903041f6d6afd991907", "title": "Towards VQA Models That Can Read"}, {"paperId": "c41a11c0e9b8b92b4faaf97749841170b760760a", "title": "VideoBERT: A Joint Model for Video and Language Representation Learning"}, {"paperId": "e27e78c33288728f66f7dab2fe2696ddbc5c1026", "title": "COIN: A Large-Scale Dataset for Comprehensive Instructional Video Analysis"}, {"paperId": "a7ac99d7cf3f568ab1a741392144b646b856ae0c", "title": "GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering"}, {"paperId": "8b47b9c3c35b2b2a78bff7822605b3040f87d699", "title": "SlowFast Networks for Video Recognition"}, {"paperId": "50fec8e60b63e355241f153d6f5c17d4116b2a9e", "title": "Timeception for Complex Action Recognition"}, {"paperId": "ab1d44fe7ee9165974a2487b6d10ddaba6c26549", "title": "De Novo Design of Bioactive Small Molecules by Artificial Intelligence"}, {"paperId": "b68811a9b5cafe4795a11c1048541750068b7ad0", "title": "The \u201cSomething Something\u201d Video Database for Learning and Evaluating Visual Common Sense"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6", "title": "The Kinetics Human Action Video Dataset"}, {"paperId": "a53b094169e04b6461f7ab500c3508040ebcd5a8", "title": "Chemical Space Mimicry for Drug Discovery"}, {"paperId": "7e232313a59d735ef7c8a9f4cc7bc980a29deb5e", "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "df0402517a7338ae28bc54acaac400de6b456a46", "title": "WaveNet: A Generative Model for Raw Audio"}, {"paperId": "e9c771197a6564762754e48c1daafb066f449f2e", "title": "Unitary Evolution Recurrent Neural Networks"}, {"paperId": "3332dc72fbe3907e45e8a500c6a1202ad5092c0f", "title": "Deep clustering: Discriminative embeddings for segmentation and separation"}, {"paperId": "34038d9424ce602d7ac917a4e582d977725d4393", "title": "Librispeech: An ASR corpus based on public domain audio books"}, {"paperId": "185f078accb52be4faa13e4f470a9909cc6fe814", "title": "The Language of Actions: Recovering the Syntax and Semantics of Goal-Directed Human Activities"}, {"paperId": "8b3b8848a311c501e704c45c6d50430ab7068956", "title": "HMDB: A large video database for human motion recognition"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "5fbed98fd9676724f1b42ea27eac81c86819cbbb", "title": "The art and practice of structure\u2010based drug design: A molecular modeling perspective"}, {"paperId": "13c0b6fcf702fcfe0c8dd9c85130477f53430021", "title": "MambaMorph: a Mamba-based Backbone with Contrastive Feature Learning for Deformable MR-CT Registration"}, {"paperId": "cf0f8f585c8822e3c6bcd9527d546eefc8486aea", "title": "S4ND: Modeling Images and Videos as Multidimensional Signals with State Spaces"}, {"paperId": "4a84ce63ac746c255164bb3a10fb296f41d1e52c", "title": "Linear Dynamical Systems as a Core Computational Primitive"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "A benchmark for evaluating object hallucinations, involving a binary classification task determining the presence of objects"}, {"paperId": null, "title": "Mobilevlm: A fast, reproducible and strong vision language assistant for mobile devices"}, {"paperId": null, "title": "Minigpt-4: En-hancing vision-language understanding with advanced large language models"}, {"paperId": null, "title": "Evaluates perceptual and cognitive abilities, including OCR, object recognition, common sense reasoning, numerical calculations, text translation, and code reasoning"}]}