{"paperId": "9bbdcc03d872987eef9165f4a63c3878a5b05189", "abstract": "Pre-trained Transformer language models (LM) have become go-to text representation encoders. Prior research fine-tunes deep LMs to encode text sequences such as sentences and passages into single dense vector representations for efficient text comparison and retrieval. However, dense encoders require a lot of data and sophisticated techniques to effectively train and suffer in low data situations. This paper finds a key reason is that standard LMs\u2019 internal attention structure is not ready-to-use for dense encoders, which needs to aggregate text information into the dense representation. We propose to pre-train towards dense encoder with a novel Transformer architecture, Condenser, where LM prediction CONditions on DENSE Representation. Our experiments show Condenser improves over standard LM by large margins on various text retrieval and similarity tasks.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2021, "citationCount": 208, "influentialCitationCount": 34, "openAccessPdf": {"url": "https://aclanthology.org/2021.emnlp-main.75.pdf", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes to pre-train towards dense encoder with a novel Transformer architecture, Condenser, where LM prediction CONditions on DENSE Representation improves over standard LM by large margins on various text retrieval and similarity tasks."}, "embedding": {"model": "specter_v2", "vector": [-0.2313212752342224, 0.25387513637542725, -0.26504096388816833, 0.16360364854335785, -0.6305742263793945, -0.22094878554344177, 0.9040877223014832, 0.033885497599840164, -0.5270336270332336, -0.0560341440141201, 1.0205568075180054, -0.08573843538761139, 0.15212292969226837, 0.06199747696518898, 0.1460181325674057, -0.09595149010419846, -0.7119056582450867, 0.5224690437316895, -0.2702106535434723, -0.7243748307228088, -0.26638373732566833, -0.7966333031654358, -0.9964709281921387, 0.23310939967632294, 0.505888819694519, 0.5146796703338623, 0.17495562136173248, 0.9381870627403259, -0.8660902380943298, 0.49164676666259766, 0.5164880156517029, -0.36777085065841675, 0.31138861179351807, -0.40485402941703796, -0.7491927146911621, -0.3474445343017578, 0.34347301721572876, -0.6814825534820557, -0.4681965410709381, 0.5928299427032471, 0.01190192624926567, 0.537020206451416, 0.7713261842727661, 0.0358596034348011, -0.4457909166812897, 0.8949659466743469, 1.0460972785949707, 0.5572518706321716, 0.14263583719730377, -0.6790981888771057, 1.2732157707214355, -1.5514618158340454, 0.37994858622550964, 1.396741271018982, 0.40282779932022095, 0.427491694688797, 0.24315747618675232, -0.290310800075531, 0.46368005871772766, 0.014781157486140728, -0.975719690322876, -0.23483850061893463, -0.5034327507019043, 0.05992022529244423, 1.8683030605316162, -0.17058224976062775, 0.1382332295179367, 0.2789855897426605, -0.3411460518836975, 1.285260796546936, -0.5182942748069763, -0.7711337804794312, -0.5216976404190063, 0.017369689419865608, 0.1379658728837967, 0.6837524771690369, -0.5877747535705566, 0.08519342541694641, -0.5678841471672058, 0.1703459918498993, -0.10384229570627213, 0.22675377130508423, -0.2448424994945526, 0.17416800558567047, -0.06838037818670273, 0.5135485529899597, 0.6523188948631287, 1.0922553539276123, -0.11087918281555176, 0.1075969934463501, 0.3945167660713196, 0.5875036716461182, 0.2759721577167511, 0.5442042946815491, 0.5841743350028992, 0.06367256492376328, -0.96442049741745, 0.3121677339076996, -0.04246293753385544, 0.7011715173721313, 0.01807449199259281, -0.081977479159832, -1.2938886880874634, 0.37779971957206726, 0.9885519742965698, 0.17363330721855164, 0.8807533383369446, -0.5561679005622864, 0.3315318822860718, -0.7772531509399414, -0.1051861047744751, -0.820604681968689, 0.2591721713542938, -0.4579537510871887, -1.10886549949646, -1.4781711101531982, -0.7000556588172913, 0.050396326929330826, -0.4928058385848999, 0.482751727104187, -0.4176933169364929, 0.02111246809363365, 0.09122400730848312, 0.8052771687507629, 0.748712956905365, 1.0698738098144531, 0.22237282991409302, 0.13540376722812653, 0.6966066360473633, -0.7573400735855103, -0.8668107390403748, -0.5405181646347046, 1.1354235410690308, -0.516424298286438, 0.4010969400405884, -0.40983515977859497, -1.1773877143859863, -1.0291863679885864, -0.7383325099945068, -0.11302744597196579, -0.6515465378761292, -0.13253025710582733, 0.7109054327011108, 0.06342428922653198, -1.0363600254058838, 1.1199532747268677, -0.033413149416446686, -0.6046459078788757, 0.24938341975212097, 0.09317468851804733, 0.08574524521827698, -0.6585220098495483, -1.3777482509613037, 0.6080688238143921, -0.036520954221487045, -0.6927376389503479, -0.0011103027500212193, -0.36013373732566833, -1.085807204246521, 0.2410469353199005, -0.17357346415519714, -0.7459867000579834, 1.4094732999801636, -0.03010590188205242, -1.358153223991394, 0.5266444087028503, -0.5184075236320496, 0.10674059391021729, -0.04956371709704399, -0.64193195104599, -0.09655599296092987, -0.28967177867889404, -0.2431327998638153, 0.5471991896629333, 0.15736089646816254, 0.28853824734687805, 0.1888381689786911, 0.6537594795227051, -0.6065691113471985, 0.3864229619503021, -0.8894422650337219, 0.7623124718666077, -0.5701677203178406, -4.9473084800411016e-05, -0.0895397812128067, 0.9308454990386963, 0.13700297474861145, -0.5046343803405762, -0.1606418937444687, -1.2302539348602295, 0.9309529662132263, 0.027016008272767067, 1.261795997619629, -0.8735724687576294, -0.2596888840198517, -0.2890612483024597, -0.05057968571782112, 0.2510719895362854, -1.102120041847229, 1.0409091711044312, -0.03230026736855507, 0.20337064564228058, 0.14379344880580902, -1.331709623336792, 0.22735054790973663, -0.23795676231384277, -0.9285879135131836, -0.39538073539733887, -0.01069872546941042, 1.206796646118164, -0.9909417033195496, -0.1610010415315628, -0.056416165083646774, 0.34356287121772766, -0.7608790993690491, 1.5571942329406738, -0.2834368348121643, -0.08902578055858612, -0.43129172921180725, -0.2097114771604538, 0.03164442256093025, -0.4488663375377655, 0.09105806797742844, -0.13838432729244232, 0.004139469470828772, 0.5982528924942017, -0.036166075617074966, 1.4855130910873413, -0.2824549973011017, 0.6475296020507812, -0.21890951693058014, -0.7148425579071045, 0.3551933765411377, 0.5773671269416809, 0.020126253366470337, -0.7635586857795715, 0.3019988536834717, 0.47271203994750977, -0.9946396946907043, 0.257228285074234, 1.0471818447113037, 0.5019981265068054, -0.4111790955066681, 0.23114217817783356, 0.5823521614074707, -0.2230847030878067, 0.7196717858314514, 0.8864122033119202, 0.9897552728652954, 0.08741237223148346, 0.08147256076335907, 0.2412145733833313, 0.23777760565280914, -0.6490299701690674, -0.45184215903282166, 0.778279721736908, 1.1732542514801025, 1.1427382230758667, 0.13303297758102417, -0.4721374809741974, -0.4455302357673645, -0.15681663155555725, 1.023498296737671, 1.1278233528137207, 0.04551209136843681, -0.6829643845558167, -0.4619573652744293, -0.24257634580135345, -0.24670405685901642, -0.13274025917053223, -0.057003818452358246, -0.6238815188407898, -0.3762093782424927, -0.8669366836547852, 0.5152301788330078, -0.07932858169078827, 0.8610326051712036, -0.1784932017326355, 0.2177446484565735, -0.6039525866508484, -0.19936735928058624, -0.5328587889671326, -0.7202872037887573, 0.12380513548851013, -0.7146359086036682, 0.10845601558685303, -0.6410278677940369, 0.005742654204368591, -0.04537944868206978, -0.13893046975135803, 1.2940647602081299, -0.05897914245724678, -0.1179889440536499, 0.25602835416793823, 0.021896500140428543, -0.20884788036346436, -0.39570796489715576, 0.2966041564941406, 0.3051472008228302, -0.38254252076148987, 0.664864718914032, 0.5084835290908813, -0.22507324814796448, 0.03331053629517555, -0.46416929364204407, 0.03117283806204796, 0.13379904627799988, 0.11906705796718597, 0.42575815320014954, -0.3809497356414795, -0.06627873331308365, -0.6472233533859253, 1.279212474822998, -0.2648383677005768, -0.1808595508337021, 0.32912757992744446, -0.7631844282150269, -0.43683749437332153, 0.5029695630073547, -0.5051864981651306, -0.12329857051372528, -1.201700210571289, 0.0938296839594841, -0.45375463366508484, 0.1381531059741974, 0.5420256853103638, 0.4486965835094452, 0.580186665058136, 0.1316341906785965, 0.24990591406822205, 0.5137245059013367, -0.49965518712997437, 0.50975102186203, -0.24912822246551514, 0.425212025642395, 0.43810534477233887, 0.39440903067588806, -0.5373897552490234, -0.33361026644706726, -0.34556806087493896, -0.6238762736320496, -0.6400749683380127, 0.039453085511922836, -0.3182389438152313, 0.08651804178953171, -0.7640622854232788, -0.4290817677974701, -0.5066729784011841, -0.9213352799415588, -0.09173852950334549, -0.33233606815338135, -0.01934678852558136, -0.011609476059675217, -0.7959526181221008, -1.3528317213058472, -0.4199870228767395, -0.917402446269989, -0.7364069819450378, 0.6815568804740906, -0.06258531659841537, -0.7991839051246643, -0.6813822388648987, 0.5371313691139221, -0.7879108190536499, 1.1691128015518188, -0.8732728362083435, 0.6107526421546936, 0.07342939078807831, -0.2568596303462982, -0.7620509266853333, 0.1997622847557068, 0.6813002824783325, -0.08946940302848816, -0.08383409678936005, -0.3932047486305237, -0.0075678457506000996, -0.3734318017959595, -0.46168252825737, 0.28592145442962646, 0.10377215594053268, 0.3510081470012665, -0.09675407409667969, -0.6407872438430786, 0.3962036967277527, 1.3184731006622314, -0.790067195892334, 0.39268022775650024, 0.07255669683218002, 0.708566427230835, 0.2304229736328125, -0.12342085689306259, 0.578644335269928, 0.05819903314113617, 0.5616608262062073, -0.1450524628162384, -0.45849934220314026, -0.6993842720985413, -0.7289621233940125, 0.8077628016471863, 2.2612574100494385, 0.44051167368888855, -0.5315468311309814, -0.8495362401008606, 0.4690721929073334, -1.257972240447998, -0.9388576149940491, 0.69483882188797, 0.5637609958648682, 0.5161315202713013, -1.003047227859497, -0.314791738986969, -0.3757200837135315, 0.2673582434654236, 0.1572059541940689, 0.1814180314540863, -0.4749746024608612, -0.1300513595342636, 0.7397375106811523, 0.024631472304463387, 0.6677235960960388, 0.01759992353618145, 0.4827788472175598, 14.491169929504395, 1.1088567972183228, -0.07338327914476395, 0.4354779124259949, 0.5767775774002075, -0.31765881180763245, -0.3781247138977051, -0.2590627670288086, -1.2733330726623535, -0.12600646913051605, 1.175625205039978, -0.2206740379333496, 0.1239975094795227, -0.026164885610342026, -0.10492408275604248, 0.2830454409122467, -0.5369840860366821, 0.8392696380615234, 0.5453712344169617, -1.4149357080459595, 0.7061738967895508, 0.37270402908325195, 0.226393923163414, 0.48176151514053345, 0.9458971619606018, 1.1799696683883667, 0.41604718565940857, -0.7301203608512878, 0.21462751924991608, 0.5834095478057861, 0.6234221458435059, 0.1485750377178192, 0.8667087554931641, 0.4166187345981598, -0.4818394184112549, -0.11349166929721832, -0.7072933316230774, -1.2650442123413086, 0.4019128382205963, 0.3752189874649048, -0.4937039613723755, -0.22474533319473267, -0.22580274939537048, 1.1810346841812134, 0.12887413799762726, 0.5565062165260315, 0.20800332725048065, 0.541408360004425, -0.22924146056175232, -0.4179576337337494, 0.812293291091919, 0.3336770236492157, 0.24765759706497192, 0.3569079041481018, 0.8287513852119446, -0.05738040804862976, 0.15333913266658783, 0.2928089499473572, -0.6253572702407837, 0.1473177671432495, -0.8856858015060425, -0.2508404552936554, -0.05866573005914688, 0.7492964863777161, 0.8561925292015076, 0.05653148517012596, -0.3303646445274353, 0.4438895285129547, 0.5525358319282532, 0.19402962923049927, 0.383769154548645, -0.4961104393005371, 0.27620062232017517, 0.03697798028588295, -0.23940344154834747, 0.6108517646789551, -0.0077459909953176975, -0.6062923073768616, -0.6890692710876465, -0.30109134316444397, 0.5289373993873596, -0.8169847130775452, -1.005913257598877, 1.1707103252410889, -0.04075552523136139, -1.1906929016113281, -0.5586073994636536, -0.512242317199707, -0.3338812291622162, 0.8576963543891907, -1.4528554677963257, -0.027408750727772713, -0.014967416413128376, -0.34400230646133423, -0.5743752717971802, -0.36662623286247253, 1.399545431137085, 0.28178131580352783, 0.03073984757065773, -0.06547129154205322, 0.42301759123802185, 0.039438072592020035, -0.3001406192779541, -0.5721815824508667, 0.18765507638454437, 0.055793050676584244, -0.003728859592229128, 0.3016819953918457, -0.12835967540740967, 0.2017180323600769, -0.8711640238761902, -0.14342623949050903, 0.9738733172416687, -0.778980016708374, -0.6756775975227356, -0.8352785706520081, -0.9655981063842773, -0.38433730602264404, 0.9488890171051025, -0.5771228671073914, 0.5035504102706909, 0.3792070746421814, -0.2667502164840698, -0.15437179803848267, -0.5721145868301392, 0.2770251929759979, 0.21673788130283356, -0.8712133169174194, -0.4491114020347595, 0.27131563425064087, 0.35199326276779175, -0.6092426180839539, -0.41874611377716064, -0.0628269612789154, -0.15326090157032013, 0.15063321590423584, 1.0242067575454712, -0.19637952744960785, 0.7898141741752625, 0.9725722074508667, -0.049304451793432236, -0.9078120589256287, -0.041198354214429855, -0.8730689287185669, -0.14422206580638885, 0.08871806412935257, 0.42254647612571716, 0.18346010148525238, 0.29952701926231384, 0.7085555791854858, 0.3309182822704315, -0.4387556314468384, -0.3470676839351654, -0.40360620617866516, 0.42692384123802185, 0.03178825229406357, 0.20555651187896729, -0.27287521958351135, 0.586419939994812, 0.3709735870361328, 0.5737919211387634, -0.12220075726509094, -0.5483397245407104, -0.894228994846344, 0.353011816740036, -0.019847113639116287, 0.3022875189781189, -0.7338894009590149, -0.32688000798225403, -1.8022589683532715, 0.026366623118519783, -1.3140771389007568, -0.08754801750183105, -1.3899163007736206, -0.3127177059650421, 0.31467774510383606, -0.13031251728534698, -0.07423838973045349, 0.33305931091308594, -0.21235807240009308, -0.34450867772102356, -0.38317060470581055, -1.050577163696289, 1.2694268226623535, 1.0844004154205322, -0.6997679471969604, 0.0736316591501236, -0.3795291781425476, -0.03584003075957298, -0.11618524044752121, 0.29531288146972656, -0.2809534966945648, -0.849374532699585, -1.5041402578353882, 0.13885679841041565, -0.012060407549142838, -0.15489061176776886, -0.5996385812759399, 0.8377007842063904, 0.6635572910308838, -0.1138671413064003, -0.19263777136802673, 0.5812394022941589, -0.64964759349823, -0.5565683841705322, 0.019434262067079544, -1.037018895149231, 0.48403382301330566, -0.009114744141697884, -0.9893642067909241, -0.8469295501708984, 0.5451501607894897, -0.1511969119310379, -1.0965852737426758, -0.14513133466243744, 0.6795770525932312, -0.7901310324668884, 0.10991320013999939, -0.6123748421669006, -0.1758180409669876, -0.9385471343994141, -0.8907595872879028, 0.35006386041641235, 0.5493976473808289, -0.5028572082519531, 1.0290554761886597, 0.8507564663887024, -1.6363499164581299, -0.07566045224666595, -0.019089391455054283, -0.10557883977890015, -0.2735682427883148, 0.36746910214424133, 0.32959163188934326, -0.15100926160812378, 0.7726605534553528, 0.5719234943389893, 0.2741049528121948, -0.8751223087310791, -0.22978980839252472, 0.7472993731498718, -0.754343569278717, -0.4084620177745819, 1.0776770114898682, -0.6537209153175354, -0.8982076048851013, 0.251077264547348, -0.820344865322113, -0.43005049228668213, -0.22748206555843353, 0.7995116114616394, -0.15860436856746674, -0.13353879749774933, -0.04306301474571228, -0.23382256925106049, 0.3271394968032837, -0.14163553714752197, -0.6240374445915222, 0.6777501702308655, -0.47203513979911804, -0.5757822394371033, 0.48264041543006897, 1.6035131216049194, -1.1464580297470093, -0.07105022668838501, -0.9827312231063843, -0.24654816091060638, -0.3811352550983429, 0.5332990884780884, -0.11514879018068314, -0.3248513638973236, 0.8059907555580139, 0.6027917265892029, 0.3936289846897125, 0.558665931224823, 0.0024193653371185064, 0.7530730962753296, 1.0454158782958984, -0.49965259432792664, -0.6772257089614868, -0.32837986946105957, 1.7945232391357422, 1.1972577571868896, -0.7382761836051941, 0.16195441782474518, 0.2882902920246124, -0.39594894647598267, 0.8699898719787598, 0.04915960878133774, 0.12774434685707092, 0.9555967450141907, -0.11738424748182297, 0.13461637496948242, -0.03516937419772148, -1.4022847414016724, -0.5617792010307312, 1.1492860317230225, 0.9309192299842834, 1.0374431610107422, -0.31685003638267517, 0.12066813558340073, 0.3452467918395996, 0.03894747421145439, 0.3295433521270752, -0.09616588801145554, 0.2588723301887512, -0.4607502818107605, -0.3452082574367523, 0.21114717423915863, 0.4717104732990265, -0.528529167175293, -0.7346630096435547, 0.06584002077579498, 0.29148295521736145, -0.04877648875117302, 0.6032679080963135, 1.0192699432373047, -0.19566534459590912, 0.5978524088859558, 0.211897611618042, 0.35521936416625977, -0.6150793433189392, -0.4685482680797577, -0.23863065242767334, -0.6338350176811218, 0.16549967229366302, -0.22153340280056, -0.6091474890708923, 0.14720189571380615, -0.4575646221637726, 0.6034119725227356, 0.6705107688903809, -0.10143409669399261, 0.9263243079185486, 0.49250009655952454, 0.17965549230575562, -0.07026556134223938, -0.23321345448493958, -0.48907965421676636, -1.1934047937393188, 0.0013686349848285317, 0.01414206437766552, -0.024102266877889633, -0.05830163508653641, -0.08520540595054626, -0.4288553297519684]}, "authors": [{"authorId": "49715441", "name": "Luyu Gao"}, {"authorId": "144987107", "name": "Jamie Callan"}], "references": [{"paperId": "29a3c6968888d8078d21ff5b7d9e6d78c470fdb0", "title": "Unsupervised Corpus Aware Language Model Pre-training for Dense Passage Retrieval"}, {"paperId": "2d7a784a093615d00d4ac0a7b5763a15d86d4996", "title": "COIL: Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List"}, {"paperId": "8d1369a218a39214d82ea77ff964570eca057c15", "title": "Scaling Deep Contrastive Learning Batch Size under Memory Limited Setup"}, {"paperId": "83f915d30720f1aa1c6f6a4342d7f9e52add756e", "title": "Distilling Dense Representations for Ranking using Tightly-Coupled Teachers"}, {"paperId": "f2c1ab4e850ad89bd6b6b9908e12a4151d152070", "title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering"}, {"paperId": "496658ac0483942a8720407f16bb94227f5627fe", "title": "Augmented SBERT: Data Augmentation Method for Improving Bi-Encoders for Pairwise Sentence Scoring Tasks"}, {"paperId": "e1f4dd596cdbff6fd1edc804a851b8783a546fcf", "title": "DiPair: Fast and Accurate Distillation for Trillion-ScaleText Matching and Pair Modeling"}, {"paperId": "a64fbcf815a4f7e4d8b2d97be86451dca0a10d2f", "title": "Generation-Augmented Retrieval for Open-Domain Question Answering"}, {"paperId": "c9b8593db099869fe7254aa1fa53f3c9073b0176", "title": "Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval"}, {"paperId": "4ca3b0ea12f02e2dea01a4aa505956bae5500a09", "title": "Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing"}, {"paperId": "050050e30d0f162c4dd87c1aac8d37df266e4c93", "title": "Sparse, Dense, and Attentional Representations for Text Retrieval"}, {"paperId": "0c3bdbad193ec8a5b1f4005dc1496e341a2025b4", "title": "Efficient Document Re-Ranking for Transformers by Precomputing Term Representations"}, {"paperId": "b49c29327ada7b9a078ee38230ce11ca0245c95e", "title": "Modularized Transfomer-based Ranking Framework"}, {"paperId": "b26f2037f769d5ffc5f7bdcec2de8da28ec14bee", "title": "Dense Passage Retrieval for Open-Domain Question Answering"}, {"paperId": "beb21c9f339bb040e8f360b45eda0f9b10b2c95c", "title": "Pre-training Tasks for Embedding-based Large-scale Retrieval"}, {"paperId": "832fff14d2ed50eb7969c4c4b976c35776548f56", "title": "REALM: Retrieval-Augmented Language Model Pre-Training"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "3de1752cd0854e220fc41f0ccf7db913f846284c", "title": "Context-Aware Sentence/Passage Term Importance Estimation For First Stage Retrieval"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "37ea01066a563c661587b7c3f50fbf64d1bf311a", "title": "Accelerating Large-Scale Inference with Anisotropic Vector Quantization"}, {"paperId": "93d63ec754f29fa22572615320afe0521f7ec66d", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"}, {"paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0", "title": "Natural Questions: A Benchmark for Question Answering Research"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "95a251513853c6032bdecebd4b74e15795662986", "title": "What Does BERT Look at? An Analysis of BERT\u2019s Attention"}, {"paperId": "a81874b4a651a740fffbfc47ef96515e8c7f782f", "title": "Latent Retrieval for Weakly Supervised Open Domain Question Answering"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "dd0529ac76d0e86601e6de922ba35c2321c55b00", "title": "Learning Thematic Similarity Metric from Article Sections Using Triplet Networks"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "a76706d350b8c483a3aff73e61b91d15b5687335", "title": "Universal Sentence Encoder"}, {"paperId": "7113bd87c3e6f727efae24ee52f20c81358da761", "title": "SentEval: An Evaluation Toolkit for Universal Sentence Representations"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "1e077413b25c4d34945cc2707e17e46ed4fe784a", "title": "Universal Language Model Fine-tuning for Text Classification"}, {"paperId": "a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096", "title": "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c", "title": "Supervised Learning of Universal Sentence Representations from Natural Language Inference Data"}, {"paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"}, {"paperId": "2cbb8de53759e75411bc528518947a3094fbce3a", "title": "Billion-Scale Similarity Search with GPUs"}, {"paperId": "dd95f96e3322dcaee9b1e3f7871ecc3ebcd51bfe", "title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset"}, {"paperId": "6e795c6e9916174ae12349f5dc3f516570c17ce8", "title": "Skip-Thought Vectors"}, {"paperId": "6364fdaa0a0eccd823a779fcdd489173f938e91a", "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation"}, {"paperId": "1e4b28465d3166dd4fedeb5f23d4c768c170e859", "title": "Complement Lexical Retrieval Model with Semantic Residual Embeddings"}, {"paperId": null, "title": "2020) also introduces two other pre-training tasks Body First Selection and Wiki Link Prediction"}, {"paperId": null, "title": "Difficulties in reproducing these models come from the large batch requirement and the contrastive loss in ICT"}, {"paperId": null, "title": "2021) find that the judgment in its TREC DL2019 test set biased towards BM25 and other lexical retrieval systems than dense retrievers"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "54fa64b74ec020699fad989f85e74e50c7a34445", "title": "From doc2query to docTTTTTquery"}, {"paperId": null, "title": "2019) based on the BERT implementation in huggingface transformers package (Wolf et al., 2019). As our adjustments go only into the model architecture and the LM objective is kept"}, {"paperId": null, "title": "Adding the head during pre-training, there are roughly 120 M parameters"}, {"paperId": null, "title": "optimizer, a learning rate of 2e-5 with linear schedule and 1 epoch. For low data setup, we search best epoch number in {1,4,8} for BERT and apply those to all other pre-trained models"}, {"paperId": null, "title": "Universal language model \ufb01ne-tuning for text classi\ufb01cation"}, {"paperId": null, "title": "Raquel Urtasun, and Sanja Fidler"}]}