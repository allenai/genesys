{"paperId": "206dd797856fd30c49c53ba5716d9daa44c2351d", "abstract": "Motivated by biological evolution, this paper explains the rationality of Vision Transformer by analogy with the proven practical Evolutionary Algorithm (EA) and derives that both have consistent mathematical formulation. Then inspired by effective EA variants, we propose a novel pyramid EATFormer backbone that only contains the proposed \\emph{EA-based Transformer} (EAT) block, which consists of three residual parts, i.e., \\emph{Multi-Scale Region Aggregation} (MSRA), \\emph{Global and Local Interaction} (GLI), and \\emph{Feed-Forward Network} (FFN) modules, to model multi-scale, interactive, and individual information separately. Moreover, we design a \\emph{Task-Related Head} (TRH) docked with transformer backbone to complete final information fusion more flexibly and \\emph{improve} a \\emph{Modulated Deformable MSA} (MD-MSA) to dynamically model irregular locations. Massive quantitative and quantitative experiments on image classification, downstream tasks, and explanatory experiments demonstrate the effectiveness and superiority of our approach over State-Of-The-Art (SOTA) methods. \\Eg, our Mobile (1.8M), Tiny (6.1M), Small (24.3M), and Base (49.0M) models achieve 69.4, 78.4, 83.1, and 83.9 Top-1 only trained on ImageNet-1K with naive training recipe; EATFormer-Tiny/Small/Base armed Mask-R-CNN obtain 45.4/47.4/49.0 box AP and 41.4/42.9/44.2 mask AP on COCO detection, surpassing contemporary MPViT-T, Swin-T, and Swin-S by 0.6/1.4/0.5 box AP and 0.4/1.3/0.9 mask AP separately with less FLOPs; Our EATFormer-Small/Base achieve 47.3/49.3 mIoU on ADE20K by Upernet that exceeds Swin-T/S by 2.8/1.7. Code is available at \\url{https://github.com/zhangzjn/EATFormer}.", "venue": "International Journal of Computer Vision", "year": 2022, "citationCount": 24, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2206.09325", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "A novel pyramid EATFormer backbone that only contains the proposed EA-based Transformer (EAT) block is proposed, which consists of three residual parts, i.e., multi-Scale Region Aggregation, Global and Local Interaction, and Feed-Forward Network modules, to model multi-scale, interactive, and individual information separately."}, "embedding": {"model": "specter_v2", "vector": [0.32615378499031067, 0.2874242663383484, 0.3326100707054138, 0.2958599925041199, 0.13966810703277588, 0.09753316640853882, 0.3041600286960602, -0.5338971614837646, -0.4643801152706146, -0.4359017014503479, 0.07427138835191727, 0.6278205513954163, 0.07518788427114487, -0.3641110360622406, -0.12066025286912918, -0.6957128643989563, -1.025647521018982, 0.05006318911910057, 0.3406279385089874, -0.6965953707695007, -0.04020976275205612, -0.3823177218437195, -1.061749815940857, -0.007738689426332712, 0.743083119392395, 1.3614097833633423, 0.24179378151893616, 1.140432357788086, 0.19258971512317657, 0.25951087474823, 0.5392051339149475, -0.7145861387252808, 0.7620633244514465, -0.24621859192848206, 0.024254165589809418, 0.5357467532157898, 0.22381161153316498, 0.3669753670692444, -0.4138493835926056, 0.965011715888977, -0.06990665942430496, 0.06456485390663147, 0.5751195549964905, -0.586826741695404, -0.6464572548866272, 0.3756040334701538, 0.2876910865306854, 0.6957560777664185, -0.8996109962463379, -0.5855838656425476, 0.9934239983558655, -1.071412444114685, 0.220279723405838, 0.7830644249916077, 0.8227338790893555, 0.4954359531402588, 0.1253412961959839, -0.37995508313179016, 0.13807998597621918, 0.009356606751680374, -0.6287442445755005, -0.23984412848949432, 0.3492547571659088, -0.13061384856700897, 1.2770404815673828, -0.7207660675048828, 0.7430099844932556, 0.2255958616733551, 0.8041601181030273, 1.1048691272735596, 0.02457565814256668, -0.8145907521247864, -0.006583741866052151, 0.07600245624780655, -0.18516577780246735, 1.3142056465148926, -0.1850193589925766, 0.7410862445831299, -0.9959971308708191, 0.13243316113948822, 0.5931992530822754, -0.0720684677362442, 0.267914354801178, -0.38957691192626953, -0.11627356708049774, 0.6842750310897827, 1.0106565952301025, 0.6741894483566284, -0.5769466161727905, 0.8384590744972229, 0.03266223147511482, 0.13895606994628906, -0.23427066206932068, 0.5141854286193848, 0.07982069253921509, 0.7868036031723022, -0.4582175016403198, 0.10068397223949432, -0.936003565788269, 0.5239042639732361, 0.04701678082346916, 0.5834035873413086, -0.3880155086517334, 0.09623381495475769, 1.4983656406402588, -0.22791634500026703, 0.5880879759788513, -0.7181223630905151, -0.3859536349773407, -0.20049722492694855, -0.2070680409669876, -0.46520256996154785, -0.16891475021839142, -0.4782622456550598, -1.2439218759536743, -0.4776151180267334, -0.573884904384613, 0.3173172175884247, -1.2430378198623657, 0.6233372092247009, -0.2035319060087204, -0.038594141602516174, 0.2930198013782501, 0.5277554988861084, 0.1540253460407257, 0.05736575648188591, 0.026652272790670395, 0.14866602420806885, 1.0767189264297485, -1.329928994178772, -0.3177495300769806, -0.8874989748001099, -0.20466023683547974, 0.027358686551451683, -0.22479556500911713, -0.21867357194423676, -1.3026636838912964, -1.105661153793335, -1.0992376804351807, 0.43526244163513184, -0.36091697216033936, 0.12189559638500214, 1.2888256311416626, 0.36657947301864624, -1.166286587715149, 0.6834301352500916, -0.34387511014938354, -0.499096542596817, 0.397301584482193, -0.19461587071418762, 0.5849185585975647, 0.4090184271335602, -0.9623343348503113, 0.09791740030050278, 0.0230767410248518, -0.3436069190502167, -0.4607953131198883, -0.17662659287452698, -0.6281391978263855, -0.22078870236873627, 0.016426226124167442, -1.3999876976013184, 1.0044481754302979, -0.2176217883825302, -1.0245585441589355, 0.6388090252876282, 0.13551384210586548, -0.1353248655796051, 0.1225695013999939, 0.4880395233631134, -0.3639358878135681, -0.5155694484710693, -0.5049921870231628, 0.47372373938560486, 0.6251490116119385, -0.5442660450935364, -0.35663938522338867, -0.33468976616859436, -0.38265061378479004, -0.3458520174026489, -0.38051047921180725, 0.8364802598953247, -0.13886037468910217, -0.6838221549987793, 0.5148447155952454, 0.48006513714790344, -0.6279832124710083, 0.3133249282836914, 0.4783479869365692, -0.9585151672363281, 0.7508504390716553, 0.030622808262705803, 0.5886396765708923, -0.7394499778747559, -0.3723554015159607, -0.644756555557251, 0.3417770564556122, -0.4465566575527191, -0.6440718770027161, 0.27589645981788635, -0.09803567081689835, -0.11186587065458298, -0.4073048233985901, -0.5749083161354065, -0.06178425997495651, -0.2988623380661011, -0.3884481191635132, -0.0032201141584664583, 0.22948956489562988, 1.19547700881958, -0.6669846773147583, 0.0810563787817955, -0.3494511544704437, 0.08866395801305771, -0.8181656002998352, 0.9996006488800049, -0.28321897983551025, -0.01236524898558855, 0.12008243799209595, 0.4750533103942871, -0.05660272762179375, -0.18481118977069855, -0.23858734965324402, -0.49196699261665344, -0.0657728835940361, -0.11458846926689148, -0.1209118589758873, 1.5503075122833252, 0.18791133165359497, 0.4632173180580139, 0.4590354859828949, -0.7900840044021606, 0.5119552612304688, 0.34775638580322266, -0.1793706864118576, -0.6469162702560425, 0.7479871511459351, 0.10760071873664856, -0.1858985424041748, 0.2288428694009781, 0.7385191917419434, 0.8211469054222107, -0.5160394906997681, -0.32384634017944336, 0.770592212677002, -0.6109026074409485, 0.07260777801275253, -0.05187317356467247, 0.2238049954175949, 0.2510856091976166, 0.3596341013908386, -0.32813820242881775, -0.1365707516670227, -0.7811553478240967, 0.5042350888252258, 0.46098145842552185, -0.2212863266468048, 0.8321877121925354, -0.2705235779285431, -0.9362407326698303, -0.5055440664291382, -0.19582359492778778, 0.44983699917793274, 0.9688401222229004, 0.25872141122817993, -0.09691006690263748, -0.7508411407470703, -0.009789246134459972, -0.39994651079177856, -0.6387544870376587, -0.8391631245613098, -0.6481592655181885, -0.24397379159927368, -1.6897187232971191, 0.8321758508682251, 0.1908111423254013, 1.2993690967559814, -0.5031638145446777, -0.9013247489929199, -0.4254422187805176, 0.6799113750457764, -0.34070929884910583, -0.6884084343910217, 0.4940244257450104, -0.08878275007009506, 0.12218005955219269, -0.2209814339876175, -0.3267855942249298, 0.0814051404595375, -0.606647789478302, 0.6552032828330994, -0.3391802906990051, -0.9935707449913025, 0.38636305928230286, 0.4832754135131836, -1.1955912113189697, -0.6968430280685425, -0.5138218402862549, -0.06584383547306061, -0.029669150710105896, -0.1803196221590042, 0.05749034881591797, 0.0016510292189195752, 0.22825045883655548, -0.4336980879306793, -0.16457970440387726, 0.10895341634750366, 0.7995802760124207, 0.6315041780471802, 0.03690767288208008, -0.22866304218769073, -0.04386477917432785, 1.0719226598739624, 0.7793943881988525, -0.761696457862854, 0.6130269765853882, -0.5985789895057678, -0.3528161942958832, 0.22459262609481812, -0.21860402822494507, -0.3044033646583557, -0.878629744052887, 0.6422736644744873, -0.1604262888431549, 0.13909074664115906, -0.23051950335502625, 0.36750829219818115, -0.750357449054718, 0.5355916023254395, 0.7372571229934692, 0.24802440404891968, 0.5738896131515503, 0.45877331495285034, -0.6010212898254395, 0.6976925730705261, 0.16349391639232635, 0.25210413336753845, -0.004481058567762375, 0.1079547330737114, -0.5032300353050232, -0.3553469181060791, -0.003528216388076544, -0.4657137095928192, -0.9424030780792236, 0.7105876803398132, -0.39298146963119507, -0.5908445715904236, 0.6185705661773682, -0.8086642026901245, 0.05788223072886467, -0.10676133632659912, -0.5728006958961487, -0.3815264105796814, -0.9056546688079834, -0.8291568756103516, -0.5848769545555115, -0.8830915689468384, -1.329637885093689, 0.37158462405204773, 0.5797157883644104, 0.3092691898345947, -0.4178633391857147, 0.3343527913093567, -0.11635506898164749, 1.1608378887176514, -0.2657924294471741, 0.42519611120224, 0.3545108139514923, -0.40914785861968994, 0.14876486361026764, 0.3633158206939697, 0.24180257320404053, 0.0224548801779747, 0.8484050631523132, -0.5236902832984924, 0.3749925196170807, -0.0898442417383194, -0.5217231512069702, 0.7826961278915405, 0.274549275636673, 0.6383122801780701, 0.6142638325691223, -0.47415634989738464, 0.5950005054473877, 1.000600814819336, 0.08695044368505478, 0.1544879972934723, 0.36176106333732605, 0.3165344297885895, 0.33700478076934814, 0.11869572848081589, 0.6165381669998169, 0.2400379776954651, 0.26560792326927185, 0.42879703640937805, -0.44835251569747925, -0.515535831451416, -0.33723515272140503, 0.25258857011795044, 1.5155328512191772, -0.22703365981578827, -0.1278114765882492, -0.7140093445777893, 0.5540632605552673, -1.325053334236145, -0.7856978178024292, 1.0908523797988892, 0.4507996141910553, 0.006581360939890146, -0.5260400176048279, -0.18083322048187256, -0.12762737274169922, 0.6501932144165039, 0.21692875027656555, -0.4250231385231018, -0.27840274572372437, -0.5364460349082947, 0.24690183997154236, 0.24632099270820618, 0.42684802412986755, -0.24315248429775238, 0.5589790344238281, 15.146759033203125, 0.8019683361053467, -0.2862757444381714, 0.3215712904930115, 0.7667313814163208, 0.8026962280273438, -0.4165925681591034, -0.13163188099861145, -0.8169648051261902, -0.09552914649248123, 0.48211470246315, 0.1013362929224968, 0.6798543930053711, 0.3069063723087311, -0.695158064365387, 0.3339398503303528, 0.12203740328550339, 0.605807900428772, 0.6345855593681335, -1.412251591682434, 0.20971369743347168, 0.4057323932647705, 0.5606396198272705, 0.5990250706672668, 0.6775141358375549, 0.2142508625984192, 0.483174592256546, -0.24157442152500153, 0.8536376357078552, 0.21449878811836243, 0.5323520302772522, 0.09432399272918701, 0.2690698206424713, 0.10075490176677704, -1.4168702363967896, -0.37955498695373535, -1.0328845977783203, -0.8710375428199768, 0.07344707101583481, 0.03556203097105026, -0.3610391914844513, -0.31248828768730164, 0.2654673159122467, 0.6538780331611633, -0.22042497992515564, 0.6326223015785217, -0.24823591113090515, -0.0954931303858757, 0.22248737514019012, -0.28017109632492065, -0.03581581637263298, 0.09954956918954849, 0.5651047825813293, -0.40607142448425293, 0.3945256173610687, -0.08169424533843994, 0.07685397565364838, 0.45592397451400757, -0.5517892837524414, -0.8445185422897339, -0.3133520781993866, -0.32005614042282104, 0.013949899934232235, 1.2914671897888184, -0.07373019307851791, 0.38995298743247986, 0.1362183392047882, 0.2889443337917328, 0.5723206400871277, -0.17917972803115845, -0.7507964968681335, -0.46161139011383057, 0.47937726974487305, -0.49851271510124207, 0.2617816627025604, 0.516068160533905, -0.17764811217784882, -0.5559766888618469, -0.778561532497406, -0.29726240038871765, 0.47904425859451294, -0.9337218999862671, -0.7047467827796936, 1.5421748161315918, -0.7795531749725342, -0.14892666041851044, 0.8395580649375916, -1.0187335014343262, -0.7168283462524414, -0.057871900498867035, -1.3325515985488892, -1.0926541090011597, -0.23989100754261017, -0.21372376382350922, -0.26338469982147217, -0.5088978409767151, 0.5626075863838196, -0.2064467966556549, -0.5045477747917175, 0.11796605587005615, -0.18086358904838562, -0.24673515558242798, -0.06507819890975952, -0.6680339574813843, 0.8195905685424805, 0.7007384896278381, 0.17722463607788086, -0.2504248321056366, -0.025295041501522064, 0.3055493235588074, -0.7000604867935181, 0.3873120844364166, 0.019155321642756462, -0.7649722099304199, -0.2629762589931488, -0.7197946906089783, -0.4836926758289337, -0.06288362294435501, 0.989113450050354, -0.09307128190994263, -0.14769615232944489, -0.3014295697212219, -0.32400739192962646, -0.7391304969787598, -0.9366715550422668, -0.03250156715512276, 0.6980063319206238, -0.6539888978004456, -0.8008355498313904, -0.3727549910545349, 0.5661023259162903, -0.5822246074676514, -0.45072993636131287, 0.4201541543006897, 0.5644752383232117, -0.7127701640129089, 1.2117071151733398, -0.1403595507144928, 0.06059814244508743, 0.2615809738636017, -0.17428141832351685, -0.837454080581665, -0.7303921580314636, -0.9371100664138794, 0.5497515797615051, 0.231753870844841, 0.3232291638851166, -0.6844160556793213, 0.2550298571586609, 0.5126475095748901, -0.0003193953016307205, -0.38306114077568054, -0.9174913763999939, 0.3733113706111908, -0.20453476905822754, -0.10168680548667908, 0.4436449408531189, -0.4481106996536255, -0.06387409567832947, -0.27060461044311523, 0.10584744811058044, 0.7430720925331116, 0.2177804857492447, -0.18902119994163513, -0.007924554869532585, -0.13751961290836334, -0.3480580747127533, -0.9290240406990051, -0.8613351583480835, -1.1007262468338013, -0.703326404094696, -0.9250721335411072, 0.3820059895515442, -0.6523959636688232, -0.27643075585365295, 0.2453489899635315, -0.5805643200874329, -0.37009868025779724, 0.3176170587539673, -0.07254203408956528, -0.48148292303085327, -0.7882886528968811, -0.5760906934738159, 1.4071472883224487, 1.1534044742584229, -0.8017896413803101, 0.5539635419845581, -0.4524780809879303, -0.16430285573005676, 0.6292983293533325, 0.19452828168869019, -0.4924960732460022, -0.3760182559490204, -1.2083691358566284, 0.3654792010784149, -0.32876431941986084, -0.19815538823604584, -1.3393093347549438, 1.114622712135315, 0.5721064209938049, 0.2514382600784302, 0.15925627946853638, 0.3424633741378784, -0.7153274416923523, -0.12814459204673767, 0.7445717453956604, -0.39450499415397644, 0.3365819454193115, 0.01718282513320446, -0.659295916557312, -0.4407164752483368, 0.7061262726783752, 0.5251717567443848, -1.1895396709442139, -0.9231017231941223, 0.6256294846534729, -0.8903928995132446, -0.20781829953193665, 0.24995867908000946, -0.48625051975250244, -1.0919252634048462, 0.10318933427333832, 0.08233706653118134, 0.29979953169822693, 0.08957995474338531, 0.8833359479904175, 0.7349950075149536, -0.9286865592002869, 0.16843539476394653, 0.4101985692977905, -0.05017732083797455, -0.16978171467781067, 0.32464614510536194, 0.24463310837745667, -0.20774586498737335, 0.14331063628196716, -0.4490371346473694, 0.27209168672561646, -0.9118844270706177, 0.16553613543510437, 1.2538810968399048, -0.3182467818260193, 0.3596242666244507, 1.6500132083892822, 0.15432347357273102, -1.2821837663650513, 0.02342286705970764, -0.6790047287940979, -0.4340560734272003, -0.43753108382225037, 0.3366962671279907, 0.1594049632549286, -0.4380476772785187, 0.1590299755334854, -0.3996202349662781, 0.917057454586029, 0.04227448254823685, -0.20216546952724457, 0.5883522629737854, -0.26265949010849, -0.8172672986984253, 0.13301454484462738, -0.1581571102142334, -0.5484023094177246, -1.1055576801300049, -0.3953649401664734, -0.39564597606658936, -0.19319669902324677, 0.1500605195760727, -0.1541835516691208, -0.870963990688324, 0.6363264918327332, 0.9392349720001221, 0.25424352288246155, 0.9754648208618164, 0.027162443846464157, 0.24223990738391876, 0.4662591516971588, 0.543099582195282, -0.3806067407131195, 0.0980607122182846, 0.7688942551612854, 1.2672467231750488, -0.6534817814826965, 0.3820614814758301, -0.012182371690869331, -0.6950601935386658, 1.1670844554901123, 0.5388883352279663, -0.1517093926668167, 0.6442160606384277, 0.0032064083497971296, 0.18844245374202728, -0.20511294901371002, -1.1589254140853882, -0.20283034443855286, 0.9376888871192932, 1.3711059093475342, 0.43267256021499634, -0.09737833589315414, 0.2665882408618927, 1.0235408544540405, 0.3526771068572998, 0.04368263855576515, 0.48040851950645447, 0.4466038942337036, -0.4547019898891449, -0.04190480709075928, -0.22855277359485626, 0.13169874250888824, -0.19942666590213776, -0.057095348834991455, -0.08847282081842422, 0.3468705713748932, 0.5675073266029358, 0.16234707832336426, 0.7062188386917114, -0.18922029435634613, 0.2910700738430023, -0.4619419574737549, 0.8221787810325623, 0.3136879503726959, -0.16994251310825348, 0.058512233197689056, -0.8393577337265015, 0.11998554319143295, -0.5765882134437561, -0.5292533040046692, -0.15160351991653442, 0.19709423184394836, 0.023117462173104286, 0.5069572329521179, 0.22769631445407867, 0.28013095259666443, 0.8242353796958923, 0.8293172717094421, -0.14745040237903595, -0.6560889482498169, -0.1235850378870964, -0.5330811738967896, 0.3225953280925751, -0.780228316783905, 0.09704979509115219, -0.3865017294883728, -0.14130887389183044, -0.1536947786808014]}, "authors": [{"authorId": "73329364", "name": "Jiangning Zhang"}, {"authorId": "92385001", "name": "Xiangtai Li"}, {"authorId": "2628601", "name": "Yabiao Wang"}, {"authorId": "1978245", "name": "Chengjie Wang"}, {"authorId": "2130306785", "name": "Yibo Yang"}, {"authorId": "2144385063", "name": "Yong Liu"}, {"authorId": "2075330732", "name": "Dacheng Tao"}], "references": [{"paperId": "493cf3728f49af4e47c2c2f928510ade1e31cf00", "title": "Rethinking Mobile Block for Efficient Attention-based Models"}, {"paperId": "f35016b3180808fa97d59acbdecf47d6e2ed2819", "title": "Rethinking Vision Transformers for MobileNet Size and Speed"}, {"paperId": "5b5908e9d5552123d04f575687587455e19187c0", "title": "Attribution rollout: a new way to interpret visual transformer"}, {"paperId": "5eda60d4940d4185df45c5703e103458171d465d", "title": "Pure Transformers are Powerful Graph Learners"}, {"paperId": "05b7bd47fa5cbe10497c49004b57eb5ab4fdd0b4", "title": "EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for Mobile Vision Applications"}, {"paperId": "6fb05e3483d05f79e59e5ce957708d8ab8932fdc", "title": "Peripheral Vision Transformer"}, {"paperId": "dbf6e95cb618f207f029276a6df11f4a9a6313d4", "title": "Inception Transformer"}, {"paperId": "f6abdedf5927295776d638ac53ad6cb9c507dede", "title": "ConvMAE: Masked Convolution Meets Masked Autoencoders"}, {"paperId": "ad7bcec33f5206d4f28687a6a5a950de67010651", "title": "Neighborhood Attention Transformer"}, {"paperId": "1504ab3e1ae7af39bbf3dba62b132ec027611c38", "title": "MixFormer: Mixing Features across Windows and Dimensions"}, {"paperId": "2ad12a7be5eaf339a98c4defd8669e11fe726acc", "title": "MaxViT: Multi-Axis Vision Transformer"}, {"paperId": "6c22336873706b1cf5205ac6bd2432aa69d97821", "title": "ViTAEv2: Vision Transformer Advanced by Exploring Inductive Bias for Image Recognition and Beyond"}, {"paperId": "ba637c4f1a170f1e2dadeadb71a63cf2b9a46de2", "title": "Visual attention network"}, {"paperId": "3387e9dedb7accc3c248d194b012cab0ab5ab0b8", "title": "Context Autoencoder for Self-Supervised Representation Learning"}, {"paperId": "8f2bca9d684005675e294b33c26481e36f528cdb", "title": "data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language"}, {"paperId": "5fdb05e17fd503b8dbdbadc338e0a00829929dcc", "title": "Rethinking Attention-Model Explainability through Faithfulness Violation Test"}, {"paperId": "f4b11a696aa5a03fed1bfc47e65fdb7eb0e529c1", "title": "UniFormer: Unifying Convolution and Self-Attention for Visual Recognition"}, {"paperId": "c8831d0629f0eaf7f723317d71bbd60b8eb3c39f", "title": "UniFormer: Unified Transformer for Efficient Spatiotemporal Representation Learning"}, {"paperId": "e5cb26148791b57bfd36aa26ce2401e231d01b57", "title": "Vision Transformer with Deformable Attention"}, {"paperId": "15b0e710a9b8069d898ae6a0963d627e0fb86bd8", "title": "MPViT: Multi-Path Vision Transformer for Dense Prediction"}, {"paperId": "72e81bc41ffae1d414836169107910025aaacb75", "title": "Lite Vision Transformer with Enhanced Self-Attention"}, {"paperId": "008a428e049003fe768068a0f1fa1416af5c4982", "title": "Masked Feature Prediction for Self-Supervised Visual Pre-Training"}, {"paperId": "428add0fde6bc3f0440cde2785cd35e148084552", "title": "Spatio-temporal Relation Modeling for Few-shot Action Recognition"}, {"paperId": "9f951b58fc21926f94fc68d9b565d31cc02e8623", "title": "BEVT: BERT Pretraining of Video Transformers"}, {"paperId": "658a017302d29e4acf4ca789cb5d9f27983717ff", "title": "Masked-attention Mask Transformer for Universal Image Segmentation"}, {"paperId": "e0e6ae2ef8ef9f02e0c65ada61eadd82b7ce8a9c", "title": "Shunted Self-Attention via Multi-Scale Token Aggregation"}, {"paperId": "a0023d03985f94dddef12f762bda45948f144460", "title": "On the Integration of Self-Attention and Convolution"}, {"paperId": "e939b55a6f78bffeb00065aed897950c49d21182", "title": "Searching the Search Space of Vision Transformer"}, {"paperId": "3e38f4b4055abecbac2e618df2ecb33554073e08", "title": "PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "1e88d5afe19aea324d33541f60a90b7036894c32", "title": "Restormer: Efficient Transformer for High-Resolution Image Restoration"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "9c4753ef43d2928866dc5bf6cec53d03373ec2fa", "title": "SimMIM: a Simple Framework for Masked Image Modeling"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "da74a10824193be9d3889ce0d6ed4c6f8ee48b9e", "title": "MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer"}, {"paperId": "f454f6b5f2ca9749ddf442eb5134612ef7f758c1", "title": "ResNet strikes back: An improved training procedure in timm"}, {"paperId": "19b3b074d38b250d024920732ae51a8ffa0996dd", "title": "Pix2seq: A Language Modeling Framework for Object Detection"}, {"paperId": "7a9a708ca61c14886aa0dcd6d13dac7879713f5f", "title": "SwinIR: Image Restoration Using Swin Transformer"}, {"paperId": "39b492db00faead70bc3f4fb4b0364d94398ffdb", "title": "Do Vision Transformers See Like Convolutional Neural Networks?"}, {"paperId": "a66686e60a3eda0c606e036403cf0a07a5962595", "title": "Mobile-Former: Bridging MobileNet and Transformer"}, {"paperId": "a5c41f188b0eb0acb444cb4899bf6af378ee9ede", "title": "CrossFormer: A Versatile Vision Transformer Hinging on Cross-scale Attention"}, {"paperId": "57e81d6545dc0279af6d63018bf82a6b9e363fec", "title": "DPT: Deformable Patch-based Transformer for Visual Recognition"}, {"paperId": "0b036cd5dfc49d835d0c759c8ca31d89f2410e65", "title": "CMT: Convolutional Neural Networks Meet Vision Transformers"}, {"paperId": "260ad39a1dac4b451019e2bf17925f4df8e3b69a", "title": "Per-Pixel Classification is Not All You Need for Semantic Segmentation"}, {"paperId": "66775d9f16b3f4ca43dba2b31c7c42ca6dcba72b", "title": "GLiT: Neural Architecture Search for Global and Local Image Transformer"}, {"paperId": "ab7fff96e2cacb5a183ad23fe4ca50df942c17d2", "title": "Long Short-Term Transformer for Online Action Detection"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "d645bd08fc19d52164695f9cd5ae863345459a06", "title": "AutoFormer: Searching Transformers for Visual Recognition"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "1fb10189c500e4902cd1b5afd406f57323d21be8", "title": "VOLO: Vision Outlooker for Visual Recognition"}, {"paperId": "7fff8018bf625447df837c2fda5c58a705fbc038", "title": "XCiT: Cross-Covariance Image Transformers"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "f43b98fcc2d56c60fc71bce96374c1e6b8e12c66", "title": "Shuffle Transformer: Rethinking Spatial Shuffle for Vision Transformer"}, {"paperId": "576c462dbc1f3d732b919ef1daac37a817123e52", "title": "ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias"}, {"paperId": "9d1934ea1bd69d928d17e05d44495d42edf8601d", "title": "You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection"}, {"paperId": "2ac218e12afb4959c00839c5723b175fbcc9e87c", "title": "Analogous to Evolutionary Algorithm: Designing a Unified Sequence Model"}, {"paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60", "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"}, {"paperId": "ad4a0938c48e61b7827869e4ac3baffd0aefab35", "title": "Emerging Properties in Self-Supervised Vision Transformers"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "cc9f3a61ea4eaabf43cbb30cd1dd718074932679", "title": "All Tokens Matter: Token Labeling for Training Better Vision Transformers"}, {"paperId": "5b68522f58b61e7235b852677337ef3725075fd9", "title": "Co-Scale Conv-Attentional Image Transformers"}, {"paperId": "14c52ffa7ea9c1971d5d82ea369c946c98d056a9", "title": "LocalViT: Bringing Locality to Vision Transformers"}, {"paperId": "166e98317ed9c4687e71bef55a6800431e00b8fa", "title": "SiT: Self-supervised vIsion Transformer"}, {"paperId": "f76e9a8c41adb40a9793c82343f1c094450b7f7c", "title": "Facial Attribute Transformers for Precise and Robust Makeup Transfer"}, {"paperId": "739ceacfafb1c4eaa17509351b647c773270b3ae", "title": "An Empirical Study of Training Self-Supervised Vision Transformers"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "b9ce9fea4634d6bfed5af2f4de410822295b3630", "title": "Can Vision Transformers Learn without Natural Images?"}, {"paperId": "421fba3813d04684b42dd667e16ed22a64f50752", "title": "BossNAS: Exploring Hybrid CNN-transformers with Block-wisely Self-supervised Neural Architecture Search"}, {"paperId": "91e8117e7ebc966bc76de2cb52ec717d2acdb1a4", "title": "Scaling Local Self-Attention for Parameter Efficient Visual Backbones"}, {"paperId": "2984ab83ade26639c3a82d29628d0d9e4abbebb0", "title": "Incorporating Convolution Designs into Visual Transformers"}, {"paperId": "96da196d6f8c947db03d13759f030642f8234abf", "title": "DeepViT: Towards Deeper Vision Transformer"}, {"paperId": "610b302950a19acef1c45456111dcd495f638c18", "title": "ConViT: improving vision transformers with soft convolutional inductive biases"}, {"paperId": "dfb37e6216e792bf6bd5a30c0fc7ad55df1cb71e", "title": "Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth"}, {"paperId": "4f5a194ee365b074dcb0434e9c2eb976f6f32298", "title": "Generative Adversarial Transformers"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "63812f583caac3ac32bbfb64f66ba69e57c1e90a", "title": "Conditional Positional Encodings for Vision Transformers"}, {"paperId": "367f7f64ded5d18528c1013db9dfa01b075db484", "title": "Medical Transformer: Gated Axial-Attention for Medical Image Segmentation"}, {"paperId": "0fe8b49369d70a2be473435a82b01544704b3c9f", "title": "Evolving Attention with Residual Convolutions"}, {"paperId": "cec7872b194aadf54140578b9be52939eb1112e9", "title": "LambdaNetworks: Modeling Long-Range Interactions Without Attention"}, {"paperId": "6e8f35c6d54acb14109c9b792a62609eac8a7b5e", "title": "TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up"}, {"paperId": "fa08b41ccdfc5d8771adfbc34c176fa237d4646c", "title": "Is Space-Time Attention All You Need for Video Understanding?"}, {"paperId": "24b8a0b02bcb7934967757fc59d273a71ba67e30", "title": "TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation"}, {"paperId": "94b69cf199fa0b6c842e17fe5d6174a9d161c3df", "title": "Video Transformer Network"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78", "title": "Bottleneck Transformers for Visual Recognition"}, {"paperId": "c000b34633e0b4da9707d37362a1e07f0f2d8fac", "title": "Differential evolution algorithm with multi-population cooperation and multi-strategy integration"}, {"paperId": "d29430adccb805ab57b349afa8553954347b3197", "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "6914a7997ff4be207fa7b3472a9c5879abaec646", "title": "RealFormer: Transformer Likes Residual Attention"}, {"paperId": "6f6f73e69ee0d9d5d7d088bb882db1851d98175a", "title": "Pre-Trained Image Processing Transformer"}, {"paperId": "7e38476342ce1fcc8ef0dcd23686539395961769", "title": "Inductive biases for deep learning of higher-level cognition"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "ef8d788a904ed66bd8e30ffa69bc3ea1fe57dda7", "title": "HAT: Hardware-Aware Transformers for Efficient Natural Language Processing"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "1686203adc5f2dbc18627ce64f66d33eb81432a5", "title": "Self-Attention Attribution: Interpreting Information Interactions Inside Transformer"}, {"paperId": "b146261d0befb47a94c24db4ea4e7eb156a62af3", "title": "Differential Evolution: A review of more than two decades of research"}, {"paperId": "1f6e50be9931b27b744963625a6a80be9faee57b", "title": "Bio-inspired smart vision sensor: toward a reconfigurable hardware modeling of the hierarchical processing in the brain"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "de5ef7fe35262d99e2df54c22b8fe1a49771c13d", "title": "Choosing Mutation and Crossover Ratios for Genetic Algorithms - A Review with a New Dynamic Approach"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "bb713d56a39a040b35e4f9e036fb4422f543e614", "title": "On the Relationship between Self-Attention and Convolutional Layers"}, {"paperId": "c2c083df88e88223e1a411e61040b94c233b1b63", "title": "MMDetection: Open MMLab Detection Toolbox and Benchmark"}, {"paperId": "16c9e6e409d7cdb19e75e6041547ff392dbab642", "title": "2019 Evolutionary Algorithms Review"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "5e19eba1e6644f7c83f607383d256deea71f87ae", "title": "Searching for MobileNetV3"}, {"paperId": "6d99d1deb753822ffaf3dd10efb4cf7125c847eb", "title": "Differential Evolution: A survey of theoretical analyses"}, {"paperId": "987b2db58fbe0bda771f11a046cd23de1ce92b39", "title": "Deformable ConvNets V2: More Deformable, Better Results"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "4a73a1840945e87583d89ca0216a2c449d50a4a3", "title": "Deformable Convolutional Networks"}, {"paperId": "9c4b8f3b53067a34cc13e8b5b3d54071327a1388", "title": "Evolutionary algorithms: A critical review and its future prospects"}, {"paperId": "5582bebed97947a41e3ddd9bd1f284b73f1648c2", "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"}, {"paperId": "88512be44744615f4baa8e14f600f036db4c2433", "title": "Semantic Understanding of Scenes Through the ADE20K Dataset"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "a4fd747f413a18c22b02ebc556c1c4460ac41d1e", "title": "Differential Evolution with adaptive population size"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "1e5efd6cdfd5e3e7b995231d285efb89f1a8ac97", "title": "Evolutionary Algorithms"}, {"paperId": "6c20f808989102a3174ae2b302554c4098247589", "title": "Memetic Search in Differential Evolution Algorithm"}, {"paperId": "a8c0cb5a1596f0f17ad2a425698afd098d695bca", "title": "Differential evolution: Performances and analyses"}, {"paperId": "b630e7344ebd9d7e1386cb08c9e9fc03c910380c", "title": "Differential Evolution: A Survey of the State-of-the-Art"}, {"paperId": "b6b0e3a691e239a8eb5a41554b11c99c117801a2", "title": "Large scale global optimization using self-adaptive differential evolution algorithm"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "e099935324d995b8264716c858575158ae1603b1", "title": "High-dimensional real-parameter optimization using Self-Adaptive Differential Evolution algorithm with population size reduction"}, {"paperId": "5a4c3b779dd63f4c81fc52fd75645113cdcca299", "title": "Self-Adapting Control Parameters in Differential Evolution: A Comparative Study on Numerical Benchmark Problems"}, {"paperId": "a6bafe35fc6ad7c2cac8932cae6e137667677ebe", "title": "Multi-Population Evolutionary Algorithm for Solving Constrained Optimization Problems"}, {"paperId": "a33d0370ac9a3b2834bba80f49519df8a1c05d53", "title": "Genetic Diversity as an Objective in Multi-Objective Evolutionary Algorithms"}, {"paperId": "e941de38bcdaa992badfdea7f3377321a2d907cc", "title": "Performance Scaling of Multi-objective Evolutionary Algorithms"}, {"paperId": "ca7605b6625b973f6ac626147ed2923d7c1ec534", "title": "A Fuzzy Adaptive Differential Evolution Algorithm"}, {"paperId": "aa67babb7362000237e7e4dd0068b0d80b36cdf6", "title": "Differential Evolution \u2013 A Simple and Efficient Heuristic for global Optimization over Continuous Spaces"}, {"paperId": "b6ea4e01a3073689dc4b028807a4e1e2c07abd1e", "title": "Genetic Local Search in Combinatorial Optimization"}, {"paperId": "79fe558ea9e13f4bdbbd1c8ddef8e863c0839d80", "title": "Focal attention produces spatially selective processing in visual cortical areas V1, V2, and V4 in the presence of competing stimuli."}, {"paperId": "4d90f6a0c79f62bf9a607766c9c0e7a8d36215b9", "title": "MCMAE: Masked Convolution Meets Masked Autoencoders"}, {"paperId": "26c89113585741975e932e493c562c3114cc6b96", "title": "AttCAT: Explaining Transformers via Attentive Class Activation Tokens"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "2a23ffef0b4f5f8689ffffb4cd9f515cb28336bd", "title": "HRFormer: High-Resolution Vision Transformer for Dense Predict"}, {"paperId": null, "title": "Container: Context aggregation networks"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Pytorch image models"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "d6bfed0bfc30d8267e6b4dd84d20a6089fdde8be", "title": "Local Search Based on Genetic Algorithms"}, {"paperId": null, "title": "S12 S24 B B S M48 48M Top-1 10"}, {"paperId": "5e5510974359a8f7987358e178e7e51dbb3880bb", "title": "Applications of Multi-Objective Evolutionary Algorithms, Vol. 1, by"}, {"paperId": null, "title": "Base-49. Base 384 Small 384 B B 9"}, {"paperId": "64056e0fc8fe6f11497129efefed3123b3c21847", "title": "Memetic Evolutionary Algorithms"}, {"paperId": null, "title": "Performance scaling of multiobjective evolutionary algorithms. In: International conference on evolutionary multi-criterion optimization"}, {"paperId": "d02a8a0114309238aef12e776b17b861e1ddb7f2", "title": "Evolutionary algorithms with local search for combinatorial optimization"}, {"paperId": "c66b40e54fcb1d748aa04d82f497f24ac22d6129", "title": "Distributed hierarchical processing in the primate cerebral cortex."}, {"paperId": "8b9a748ae77f9235396e04301b82143feb1167fe", "title": "On Evolution, Search, Optimization, Genetic Algorithms and Martial Arts : Towards Memetic Algorithms"}]}