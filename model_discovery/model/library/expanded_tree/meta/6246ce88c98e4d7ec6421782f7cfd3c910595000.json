{"paperId": "6246ce88c98e4d7ec6421782f7cfd3c910595000", "abstract": "Foundation models have emerged as critical components in a variety of artificial intelligence applications, and showcase significant success in natural language processing and several other domains. Meanwhile, the field of graph machine learning is witnessing a paradigm transition from shallow methods to more sophisticated deep learning approaches. The capabilities of foundation models to generalize and adapt motivate graph machine learning researchers to discuss the potential of developing a new graph learning paradigm. This paradigm envisions models that are pre-trained on extensive graph data and can be adapted for various graph tasks. Despite this burgeoning interest, there is a noticeable lack of clear definitions and systematic analyses pertaining to this new domain. To this end, this article introduces the concept of Graph Foundation Models (GFMs), and offers an exhaustive explanation of their key characteristics and underlying technologies. We proceed to classify the existing work related to GFMs into three distinct categories, based on their dependence on graph neural networks and large language models. In addition to providing a thorough review of the current state of GFMs, this article also outlooks potential avenues for future research in this rapidly evolving domain.", "venue": "arXiv.org", "year": 2023, "citationCount": 46, "influentialCitationCount": 3, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This article introduces the concept of Graph Foundation Models (GFMs), and offers an exhaustive explanation of their key characteristics and underlying technologies, and classify the existing work related to GFMs into three distinct categories, based on their dependence on graph neural networks and large language models."}, "embedding": {"model": "specter_v2", "vector": [0.3029189705848694, 0.8878392577171326, -0.8909342288970947, -0.23243708908557892, 0.6978035569190979, -0.16077595949172974, 0.7261293530464172, -0.05949264019727707, -0.2506592869758606, 0.00592047581449151, 0.43961140513420105, -0.08340142667293549, 0.12651482224464417, -0.4245779812335968, -0.5522835850715637, 0.5113834142684937, -0.7821297645568848, 0.2254398614168167, 0.04512934759259224, -0.057133808732032776, 0.09120230376720428, -0.6264849305152893, -0.9900680780410767, -0.15024159848690033, 0.036212705075740814, 0.011269818991422653, -0.03536536917090416, 1.0555905103683472, -0.4980742037296295, 0.3570461571216583, 0.7703428268432617, -0.8875529170036316, 0.15887656807899475, -0.11824332922697067, -0.5678403377532959, -0.03852364048361778, 0.6178762912750244, -0.48903602361679077, -1.1928482055664062, 1.060357928276062, -0.740713894367218, 0.5164220929145813, 0.5639657378196716, -1.252515435218811, -0.5045897364616394, 1.4871776103973389, 0.5346216559410095, 0.48580580949783325, -0.12905053794384003, -0.4757070243358612, 2.1516339778900146, -1.108227014541626, 0.9026460647583008, 1.3100886344909668, 0.5400511622428894, 0.6041330099105835, -0.4879191815853119, -0.665533721446991, 0.3937571346759796, 0.12966269254684448, -0.6305057406425476, -0.0435832254588604, 0.37270933389663696, -0.20127616822719574, 1.720188021659851, -0.6340550780296326, 0.006762105971574783, 0.45487943291664124, -0.29126930236816406, 1.3231942653656006, 0.090673066675663, -1.1801153421401978, -0.42044582962989807, -0.41331157088279724, 0.6278330683708191, 1.5442476272583008, 0.20937415957450867, 0.34005096554756165, -1.0111865997314453, 0.05246562883257866, 0.5508854389190674, -0.14490096271038055, -0.13481858372688293, -0.021663518622517586, 0.0652284324169159, 0.7925498485565186, 0.8744673728942871, 0.5597893595695496, -0.3851413130760193, 0.8910000324249268, 0.21380363404750824, 0.27771511673927307, -0.382072389125824, 0.07385119795799255, 0.42291104793548584, 1.0074093341827393, -0.7321231365203857, 0.4195876717567444, 0.39723363518714905, 0.8387823700904846, 0.3531697690486908, -0.020341230556368828, -0.34728533029556274, -0.1401987373828888, 1.3897475004196167, -0.7126721143722534, 0.057682350277900696, -0.7087937593460083, 0.2085338830947876, -0.059321437031030655, 0.12542308866977692, -1.0109407901763916, -0.40364956855773926, -0.29235246777534485, -0.7752159237861633, -1.1781970262527466, -0.07383666187524796, 0.5493950843811035, -0.6875619292259216, 0.8690899610519409, -0.37961509823799133, 0.2885884940624237, -0.2710244357585907, 0.39208894968032837, 0.8395236730575562, 0.43322426080703735, 0.3642871379852295, 0.3062410056591034, 0.5570839643478394, -1.2367736101150513, -0.6134129762649536, -0.9293169975280762, 1.0610383749008179, 0.20088298618793488, 0.5035309791564941, -0.46651002764701843, -1.0027427673339844, -1.161563754081726, -0.8993639349937439, 0.008735911920666695, -0.6975776553153992, 0.3088013231754303, 1.5326018333435059, 0.5848978757858276, -1.1917839050292969, 0.9168258309364319, -0.012745424173772335, -0.2040412276983261, 0.14291852712631226, 0.4399928152561188, 0.02010846696794033, -0.8683406114578247, -1.2961980104446411, 0.20560145378112793, 0.7565621733665466, -0.48403218388557434, -0.24819296598434448, 0.009029857814311981, -1.3830368518829346, 0.03559424728155136, 0.5815479755401611, -0.9281104207038879, 0.8766282200813293, -0.02701316587626934, -0.5897195339202881, 1.1221493482589722, -0.1519128531217575, -0.12689359486103058, 0.04052264988422394, 0.1343269944190979, -0.7475667595863342, -0.26346394419670105, -0.0033600027672946453, 0.5069262981414795, -0.1098552793264389, -0.457756906747818, 0.15360328555107117, 0.23057492077350616, -0.11872151494026184, -0.6977443695068359, -0.36788251996040344, 0.8218229413032532, -0.6854748725891113, -0.030448919162154198, 0.05882180109620094, 0.434415340423584, -0.137175053358078, 0.00506865419447422, -0.8696030378341675, -1.322408676147461, 0.4180808961391449, -0.08389674127101898, 1.454330563545227, -0.6993807554244995, -0.5247639417648315, 0.15318945050239563, 0.4892151355743408, -0.26509737968444824, -0.804194986820221, 0.9861688613891602, -0.3696645200252533, 0.8234391808509827, -0.055400315672159195, -0.9159873723983765, 0.1480388343334198, 0.05387623608112335, 0.0006017814157530665, -0.1679897904396057, 0.0723421648144722, 1.0638060569763184, -1.0916627645492554, -0.08355546742677689, 0.08274686336517334, -0.3238941729068756, -0.9498153924942017, 0.9544698596000671, -0.46562430262565613, -0.41305914521217346, -0.07399175316095352, -0.3265189826488495, -0.024141937494277954, -0.6390786170959473, 0.6083630323410034, -0.24553638696670532, 0.04730837047100067, 0.5187497735023499, -0.5548767447471619, 1.5274020433425903, 0.20871274173259735, 0.3444172441959381, -0.017407866194844246, -0.6061310172080994, 0.4269310534000397, 0.14877060055732727, -0.4202462136745453, 0.1383102983236313, -0.24811668694019318, 0.2886240780353546, -0.2940354347229004, 0.4458732306957245, 0.6769623160362244, 0.7986648678779602, -0.035928428173065186, 0.30827224254608154, 0.6152942776679993, 0.052496761083602905, 1.2060997486114502, 0.6859534978866577, 0.9437247514724731, 0.3648867607116699, 0.2618855834007263, -0.167250394821167, 0.40862521529197693, -0.49033674597740173, -0.12793606519699097, 0.5796214938163757, 0.6211060881614685, 0.26479747891426086, 0.4433680474758148, -0.8792825937271118, -0.2427133023738861, 0.0629911795258522, 1.0928997993469238, 1.4534238576889038, 0.10213419049978256, -0.8741737604141235, -0.517955482006073, -0.6628483533859253, -0.21210193634033203, 0.2788041830062866, -0.5525434613227844, -0.27441829442977905, -0.43138638138771057, -0.8927809596061707, 0.7744302153587341, 0.408040314912796, 1.0967532396316528, -0.3849770128726959, 0.13846226036548615, -0.4939044117927551, 0.16050425171852112, -0.8617222905158997, -0.5676684379577637, 0.07893186807632446, -0.48164066672325134, -0.6380028128623962, 0.2440873682498932, -0.411250501871109, 0.25964683294296265, -0.4018283188343048, 1.2890962362289429, 0.4825504720211029, -0.2786073088645935, 0.22059737145900726, 0.86469566822052, -0.4503990709781647, -0.6760147213935852, 0.09482870995998383, 0.18548700213432312, -0.43069058656692505, 0.4965549409389496, 0.5066617131233215, 0.08646441251039505, 0.18767617642879486, -0.7047147154808044, 0.2754082679748535, -0.08422616869211197, 0.29285717010498047, 0.5826092958450317, 0.45327460765838623, -0.02932293526828289, -1.329068660736084, 0.8302009701728821, -0.04327789694070816, -0.5017895102500916, 0.5278756618499756, -1.1315712928771973, -0.39033043384552, 0.553348958492279, -0.36322516202926636, -0.03072790801525116, -1.0631103515625, 0.9841805100440979, 0.04203326627612114, -0.23882319033145905, 0.719527542591095, 0.1568441241979599, -0.00966265145689249, 0.35664480924606323, -0.04370500519871712, 0.05170920863747597, 0.015231860801577568, 0.7561122179031372, -1.182515263557434, 0.5771557092666626, 0.05482335388660431, 0.5365601181983948, -0.29968512058258057, 0.6093379855155945, -0.6095077991485596, -0.5350242257118225, -0.511200487613678, -0.28478071093559265, -0.573235809803009, 0.08480285108089447, -0.4602220356464386, -0.5421017408370972, -0.2894529700279236, -0.9320157766342163, -0.3929382562637329, 0.4931034743785858, -0.4407557249069214, 0.1573803722858429, -0.6062774062156677, -1.3241201639175415, -0.3319035768508911, -0.0895431786775589, -0.3444969952106476, 0.2219410389661789, 0.3525838255882263, -0.2848023474216461, -0.9869258403778076, -0.04470247030258179, -0.13911081850528717, 0.2757863402366638, 0.15708990395069122, 1.450085997581482, 0.2983982563018799, -0.4793561100959778, -0.3568636476993561, 0.07854972034692764, 0.3752385377883911, -0.14785049855709076, 0.3356768786907196, -0.43746864795684814, 0.32608070969581604, -0.993151068687439, -0.2635737955570221, 0.21259553730487823, 0.6701796054840088, 0.5097013711929321, -0.11088245362043381, -0.6426514983177185, 0.12065859884023666, 1.5507646799087524, -1.272058129310608, -0.12493126839399338, 0.2835249900817871, 0.8209174275398254, 0.6754266023635864, -0.754150927066803, 0.024327794089913368, 0.6239614486694336, 0.4235757291316986, 0.3839128613471985, -0.38422542810440063, -0.7958709597587585, -1.3794012069702148, 0.4702792465686798, 1.2140271663665771, -0.031119322404265404, -0.5389114022254944, -1.5252337455749512, 0.6647030115127563, -1.3196535110473633, -0.9043482542037964, 0.030998101457953453, 0.5425429940223694, -0.0720476284623146, -0.0950569212436676, 0.2504751682281494, -0.020090393722057343, 1.1509796380996704, 0.33630070090293884, -0.35509130358695984, -0.24341318011283875, -0.3213493525981903, 0.44227394461631775, 0.3799937963485718, 0.6387487053871155, -0.1787753850221634, 0.8547373414039612, 14.398336410522461, 0.49577808380126953, 0.5118025541305542, -0.05734705924987793, 0.3904416263103485, 0.605669379234314, -0.5929237604141235, 0.4736920893192291, -1.024647831916809, -0.3341061472892761, 0.9488794207572937, -0.19878427684307098, 0.8793361186981201, 0.24226196110248566, -0.08709046989679337, 0.3448757827281952, -0.5277943015098572, 0.4162601828575134, 0.1849919855594635, -1.615991473197937, 0.8622691035270691, 0.5467389822006226, 0.5335939526557922, 0.6039972901344299, 0.5504628419876099, 0.7268679141998291, 0.7535240650177002, -0.6819711923599243, 0.2825367748737335, 0.2236902117729187, 0.8254692554473877, 0.21064944565296173, 0.49058467149734497, 0.8363186717033386, -1.2933228015899658, -0.14778947830200195, -1.1782792806625366, -1.3673509359359741, 0.1342017948627472, 0.1428743153810501, -0.7025048136711121, 0.13164232671260834, -0.530952513217926, 1.242351770401001, -0.09290414303541183, 0.15786270797252655, -0.9295928478240967, 0.6772454977035522, -0.20152723789215088, 0.04446471855044365, 0.2719082534313202, 0.17219826579093933, 0.0960964635014534, 0.027044925838708878, 0.1731569766998291, -0.2594953775405884, 0.5572519302368164, 0.5983375906944275, -1.0375267267227173, 0.23722811043262482, -1.0501914024353027, -0.8703648447990417, -0.17167162895202637, 0.7926718592643738, 0.22311176359653473, 0.44365599751472473, -0.6989140510559082, 0.04563167691230774, 0.6910864114761353, 0.45481428503990173, -0.07539324462413788, -0.08156268298625946, -0.2445533722639084, 0.02430710755288601, -0.4615353047847748, 0.2571670114994049, -0.04739438742399216, -0.5910493731498718, -0.8339114189147949, 0.09052364528179169, 0.9035853147506714, -0.8465856909751892, -1.0065827369689941, 0.674007773399353, -0.4912327229976654, 0.1260213553905487, -0.09909683465957642, -1.1660778522491455, -0.6716354489326477, 0.3068138659000397, -1.8674685955047607, -1.1762821674346924, -0.13334983587265015, 0.31336909532546997, -0.612510621547699, -0.19201643764972687, 1.2847305536270142, -0.2283909171819687, -0.43916064500808716, -0.1251605898141861, -0.512900173664093, 0.1923915296792984, -0.6529861092567444, -1.0742813348770142, 0.8179944753646851, 0.7026434540748596, 0.6844719052314758, 0.5861068964004517, 0.18560178577899933, -0.23407506942749023, -0.7404924631118774, -0.11846758425235748, 0.8827231526374817, -0.8643439412117004, -0.16628919541835785, -0.5366244912147522, -0.7143751382827759, 0.5881251692771912, 0.448560506105423, -0.20016023516654968, 0.508192241191864, 0.46727490425109863, -0.7576403617858887, 0.3665149509906769, -0.7515287399291992, 0.31200912594795227, 1.2680667638778687, -0.6626828908920288, -0.4284771680831909, 0.16620522737503052, -0.19722798466682434, -0.17850036919116974, -0.40129679441452026, -0.08953311294317245, -0.04802332818508148, -0.3092484474182129, 0.7035159468650818, -0.9171310663223267, 0.9085023999214172, 0.43744710087776184, -0.05333590880036354, -0.7319675087928772, -0.4039621651172638, -1.501329779624939, -0.16019085049629211, -0.12867587804794312, 0.8183376789093018, -0.30697667598724365, 0.7404041886329651, 0.8714752793312073, 0.13116073608398438, -0.09369388222694397, -0.39676254987716675, -0.5103229880332947, -0.22592073678970337, 0.013280227780342102, 0.28881481289863586, 0.2370137870311737, -0.29951396584510803, 0.3669530153274536, 0.2743836045265198, 0.7374767065048218, 0.24162258207798004, -0.47186824679374695, 0.8207138180732727, -0.5201067924499512, -0.30827149748802185, -0.9134899377822876, -0.3023470640182495, -1.3201133012771606, 0.7491561770439148, -1.8359827995300293, -0.4665170907974243, -1.7047600746154785, -0.3575495183467865, 0.3316367566585541, -0.19437545537948608, -0.0068126521073281765, 0.3875037133693695, -0.5150099992752075, -0.7321478128433228, -0.5244375467300415, -0.3351333439350128, 0.4010568857192993, 1.0912089347839355, -0.44569000601768494, 0.34018105268478394, -0.14395873248577118, 0.06108282506465912, 0.41412752866744995, 0.31546449661254883, -0.5801393985748291, -0.9200303554534912, -1.443239450454712, 0.45180293917655945, -0.21538831293582916, 0.1344466507434845, -0.309616357088089, 0.91665118932724, 0.06869678199291229, -0.2519897520542145, 0.5268715023994446, 0.275047242641449, -0.5842811465263367, -0.23148797452449799, 0.5754551291465759, -0.8264129757881165, 0.5361489653587341, -0.21835429966449738, 0.17195582389831543, -0.43429890275001526, 0.42328891158103943, -0.32688847184181213, -1.0428067445755005, -0.5489811897277832, 0.5754614472389221, -0.04797430709004402, -0.2158980667591095, -0.287670373916626, -0.35059061646461487, -0.9615541100502014, -0.46968674659729004, 0.005084463395178318, 0.4213486313819885, -0.039671190083026886, 0.5773491859436035, 0.37652090191841125, -1.2341556549072266, -0.11261042952537537, 0.1536169946193695, 0.1190047636628151, -0.40799883008003235, 0.20103859901428223, -0.061127837747335434, -0.2184075564146042, 0.6007834672927856, 0.18522877991199493, 0.7697564959526062, -0.7151150703430176, 0.18411779403686523, 0.2889214754104614, -0.8392225503921509, -0.5808078050613403, 0.9204841256141663, -0.38408851623535156, -1.0510029792785645, 0.11558999866247177, -0.9214990735054016, -0.46080297231674194, -0.9361962676048279, 0.15681611001491547, 0.04139394313097, -0.7510204911231995, 0.0077886818908154964, -0.04423859342932701, 0.2693385183811188, 0.2605101764202118, -0.005227436777204275, 0.7528486847877502, 0.13002978265285492, -0.6634060144424438, 0.33913353085517883, 0.2017393559217453, -0.6534619331359863, -0.26474711298942566, -0.58702552318573, 0.46921128034591675, -0.386344850063324, 0.3698323965072632, -0.32931584119796753, -0.2462424784898758, 0.7253815531730652, -0.5188126564025879, 0.5472652912139893, 0.2985105514526367, -0.3259062170982361, 0.14471536874771118, 0.7883562445640564, 0.1618899405002594, -0.7680132389068604, -0.47133246064186096, 0.9546644687652588, 1.0967719554901123, -0.5692433714866638, 0.35586363077163696, -0.698502242565155, -0.248200461268425, 1.3425929546356201, 0.3489808440208435, -0.14791063964366913, 0.8938310742378235, -0.4685359001159668, -0.4723426401615143, -0.27597564458847046, -0.945182204246521, 0.021684635430574417, 0.8549286127090454, 0.9795107841491699, 0.7392351031303406, 0.2306973934173584, -0.16238997876644135, 0.8243817090988159, -0.10885486751794815, 0.2076050341129303, 0.9238072633743286, 0.29373252391815186, -0.2239951342344284, -0.38162490725517273, 0.6716803908348083, 0.33779019117355347, -0.4236451983451843, -0.41692906618118286, -0.7340543866157532, 1.2227623462677002, 0.10282380878925323, 0.7253561019897461, 0.14075134694576263, 0.09159865975379944, 0.42012497782707214, 0.28881195187568665, 0.5318952202796936, -0.7863940000534058, -0.13732485473155975, -0.5410082340240479, -0.08813613653182983, 0.1876005381345749, -0.7690155506134033, -0.0753948912024498, -0.4896470904350281, -0.465591162443161, -0.14857788383960724, -0.0749477967619896, 0.5012272596359253, 0.7957145571708679, 0.3516665995121002, 0.016828889027237892, -0.4890987277030945, 0.4464458227157593, -0.15477235615253448, -0.8356479406356812, -0.24386733770370483, -0.44552427530288696, -0.6418918371200562, -0.5537695288658142, -0.3803008496761322, -0.3203849792480469]}, "authors": [{"authorId": "2260178816", "name": "Jiawei Liu"}, {"authorId": "2257052319", "name": "Cheng Yang"}, {"authorId": "2110327382", "name": "Zhiyuan Lu"}, {"authorId": "2260645232", "name": "Junze Chen"}, {"authorId": "2274190647", "name": "Yibo Li"}, {"authorId": "16003017", "name": "Mengmei Zhang"}, {"authorId": "2300370790", "name": "Ting Bai"}, {"authorId": "2267220071", "name": "Yuan Fang"}, {"authorId": "2257354508", "name": "Lichao Sun"}, {"authorId": "2258679535", "name": "Philip S. Yu"}, {"authorId": "2257131498", "name": "Chuan Shi"}], "references": [{"paperId": "ca9f5b3bf0f54ad97513e6175b30497873670fed", "title": "Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality"}, {"paperId": "4738bbf3a8ff695a05ffc6c1099957ae9039b000", "title": "Distinguished In Uniform: Self Attention Vs. Virtual Nodes"}, {"paperId": "95887f9a63b369e436c570487bce1148285cd290", "title": "Exploring Neural Scaling Law and Data Pruning Methods For Node Classification on Large-scale Graphs"}, {"paperId": "356842f9c2e1c0abd4424d82d933e28a749c9b20", "title": "GraphWiz: An Instruction-Following Language Model for Graph Problems"}, {"paperId": "38f4f27bfdc6cdc4c72d714a097541f1e6ca98f2", "title": "Inductive Graph Alignment Prompt: Bridging the Gap between Graph Pre-training and Inductive Fine-tuning From Spectral Perspective"}, {"paperId": "62081710ffd320cffb9ea9c4b3e03a31e68b120a", "title": "Can GNN be Good Adapter for LLMs?"}, {"paperId": "71d1ac7b09f833d343a966f712c6c64c1120d8e6", "title": "Endowing Pre-trained Graph Models with Provable Fairness"}, {"paperId": "f59089c0b0140eb5254777088b1a4b772af2f207", "title": "Can we Soft Prompt LLMs for Graph Learning Tasks?"}, {"paperId": "d299a6b26e9ee23d0337a1d1a896fc1c847f5a46", "title": "InstructGraph: Boosting Large Language Models via Graph-centric Instruction Tuning and Preference Alignment"}, {"paperId": "b90ea57bf10f7ed1d50dd051604d68fb892c5633", "title": "GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks"}, {"paperId": "13f81979372850d9ab9d386c35bb00b4cc0e35f1", "title": "Position: Graph Foundation Models are Already Here"}, {"paperId": "50047a529e997210353d94ddec5ee12037c6dab5", "title": "Efficient Tuning and Inference for Large Language Models on Textual Graphs"}, {"paperId": "3c001ac268fcb813cdb262c89eb1006f18d778e9", "title": "On the Feasibility of Simple Transformer for Dynamic Graph Modeling"}, {"paperId": "e9273e5c14343c0b34010bbf2e2aada57d5f6bcf", "title": "Zero-shot Causal Graph Extrapolation from Text via LLMs"}, {"paperId": "5714916191ead5a581c6bb0258bb380e005f5d24", "title": "Fine-tuning Graph Neural Networks by Preserving Graph Generative Patterns"}, {"paperId": "0e9063c34165868df384f1d602afc1fea9857a1e", "title": "HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot Prompt Learning"}, {"paperId": "92266bd67b15fe46aebb790a33ea5b1f66aa98d8", "title": "MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs"}, {"paperId": "ba0d462c8094272c0205b8243c11f23b9995a253", "title": "Generalized Graph Prompt: Toward a Unification of Pre-Training and Downstream Tasks on Graphs"}, {"paperId": "7ec393a898521e4e9a3f510be424861f5a518109", "title": "Large Language Models as Topological Structure Enhancers for Text-Attributed Graphs"}, {"paperId": "5aa3b1009955ce2c8f896e0d5e94e06155ef1e43", "title": "LLMRec: Large Language Models with Graph Augmentation for Recommendation"}, {"paperId": "e391d266b0d43475567f59efeaeabc884a48abd0", "title": "ReLM: Leveraging Language Models for Enhanced Chemical Reaction Prediction"}, {"paperId": "45872b94798c3125abfb185b7926689c5e767763", "title": "GraphGPT: Graph Instruction Tuning for Large Language Models"}, {"paperId": "25738c43c0c4788d803981eaf5d397691aba0958", "title": "MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter"}, {"paperId": "c4fa9c1e53e7818ad11c9e656869c3f35b6b2c69", "title": "Pretraining Language Models with Text-Attributed Heterogeneous Graphs"}, {"paperId": "cfa6abd1af69cc6bce3a549a7886c47906dfdf4a", "title": "Federated Heterogeneous Graph Neural Network for Privacy-preserving Recommendation"}, {"paperId": "22cda0fa3849c8cdaca499746c5a3126dc5c1ea5", "title": "GraphControl: Adding Conditional Control to Universal Graph Pre-trained Models for Graph Domain Transfer Learning"}, {"paperId": "6f217d984f36499d88ab8a3d89572171552e6f3f", "title": "Evaluating Large Language Models at Evaluating Instruction Following"}, {"paperId": "d5f4ecbb3fc2220eed7c62ea308e4f6cba2240b5", "title": "Beyond Memorization: Violating Privacy Via Inference with Large Language Models"}, {"paperId": "aae2aaff450edc58abcf522a33f891eff6a52bf0", "title": "Learning Multiplex Representations on Text-Attributed Graphs with One Language Model Encoder"}, {"paperId": "8c9b8ba4a44b9736ea9db94f11c3227d5bb91a09", "title": "Do Large Language Models Know about Facts?"}, {"paperId": "4d1bcfb754dcd14fd312356021d9e332d3d3b18f", "title": "Label-free Node Classification on Graphs with Large Language Models (LLMS)"}, {"paperId": "3784fd84b61d482b52f7ef72aac66bcb886b892b", "title": "Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models"}, {"paperId": "55367fbade73f96181ffcf52169d0471d4c014a2", "title": "GraphText: Graph Reasoning in Text Space"}, {"paperId": "ab22d54dd13876d25c6c8f46c40fb9ac41c61ec5", "title": "One for All: Towards Training One Graph Model for All Classification Tasks"}, {"paperId": "1081b62f3eea92c87eb024ce80cb9e5d16113057", "title": "TouchUp-G: Improving Feature Representation through Graph-Centric Finetuning"}, {"paperId": "d00735241af700d21762d2f3ca00d920241a15a4", "title": "Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models"}, {"paperId": "b4646815d5107489e7660d71e83c6584a926d280", "title": "Graph Meets LLMs: Towards Large Graph Models"}, {"paperId": "229a37db06386459cce7b58c72fac5c97521de5d", "title": "Will More Expressive Graph Neural Networks do Better on Generative Tasks?"}, {"paperId": "927fc7652e033c9eb17296df087e3e6491112bb0", "title": "Evaluating Large Language Models on Graphs: Performance Insights and Comparative Analysis"}, {"paperId": "306d298e2c0606f93cd01cc8cbab0852d8e8fd12", "title": "Voucher Abuse Detection with Prompt-based Fine-tuning on Graph Neural Networks"}, {"paperId": "8d65b5940a4dbed8c18e02ca35e3a9d7a14ea76b", "title": "Language is All a Graph Needs"}, {"paperId": "2e3dcf5a5d58ac210d0d87e9f918540a8373211a", "title": "GIT-Mol: A Multi-modal Large Language Model for Molecular Science with Graph, Image, and Text"}, {"paperId": "d25f8c388677d287d00ca67d44ef02da2b45f2d9", "title": "Large Language Models and Knowledge Graphs: Opportunities and Challenges"}, {"paperId": "da0576c2a92daa9cc5b737647d51377e15f6c527", "title": "A Data-centric Framework to Endow Graph Neural Networks with Out-Of-Distribution Detection Ability"}, {"paperId": "303b7d0a81395562e3a46578a89d6821ce564a8b", "title": "SimTeG: A Frustratingly Simple Approach Improves Textual Graph Learning"}, {"paperId": "83c48aa341850af478247e3b34ba1ee1db9f1236", "title": "Meta-Transformer: A Unified Framework for Multimodal Learning"}, {"paperId": "84b77180228051040286423cec82b62c323a8fda", "title": "Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation"}, {"paperId": "09826f769cef899388909d9f4cfaa335429c41a4", "title": "Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations"}, {"paperId": "105669ec59a58fb2d4dd3021a984af33c227c5ab", "title": "Exploring the Potential of Large Language Models (LLMs)in Learning on Graphs"}, {"paperId": "a35f1315e91513ff0bec0c488fe175214fd9636c", "title": "Recommender Systems in the Era of Large Language Models (LLMs)"}, {"paperId": "80c698688bb4488beaceaab5c64f701a946cb7ae", "title": "All in One: Multi-Task Prompting for Graph Neural Networks"}, {"paperId": "87d3b93d74876383d1a3e603aa6e115ac0e96e37", "title": "Individual and Structural Graph Information Bottlenecks for Out-of-Distribution Generalization"}, {"paperId": "c63de70f5e4a9b36b5ca7f50cc8dac72e4a9254b", "title": "Privacy and Fairness in Federated Learning: On the Perspective of Tradeoff"}, {"paperId": "a6d3794c23626060781da0f1ff2bcdf7457b6c43", "title": "DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models"}, {"paperId": "9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6", "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap"}, {"paperId": "bb17c5fb339e758feeed1bd080bf49ba1f097900", "title": "Comprehensive evaluation of deep and graph learning on drug-drug interactions prediction"}, {"paperId": "3090d5ef973e34e054ed520a118b2df8b16a5702", "title": "Graph-Aware Language Model Pre-Training on a Large Graph Corpus Can Help Multiple Graph Applications"}, {"paperId": "5d321194696f1f75cf9da045e6022b2f20ba5b9c", "title": "Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding"}, {"paperId": "e94804f8df0e5a3eff6f0a278606d60dcb767d56", "title": "White-Box Transformers via Sparse Rate Reduction"}, {"paperId": "fdb361ea83c010ed0011d179567de5a1112651ac", "title": "Red Teaming Language Model Detectors with Language Models"}, {"paperId": "2d2b05f0969568ac3fd3c2cca5df04c4136c5416", "title": "Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning"}, {"paperId": "119a3ed0898499fce0ce6af6958d566d82390ba5", "title": "GIMLET: A Unified Graph-Text Model for Instruction-Based Molecule Zero-Shot Learning"}, {"paperId": "ce913026f693101e54d3ab9152e107034d81fce1", "title": "Holistic Evaluation of Language Models"}, {"paperId": "2b967d82b25088566980aaaf5a7062d90b2fb14f", "title": "GPT4Graph: Can Large Language Models Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking"}, {"paperId": "1cf13ca3244f78c3bbba49bfe19836b671ff3635", "title": "Building Transportation Foundation Model via Generative Graph Transformer"}, {"paperId": "452dac53963afe5599c484136e200498763f750b", "title": "ConGraT: Self-Supervised Contrastive Pretraining for Joint Graph and Text Embeddings"}, {"paperId": "f5c73d9e6641b018b633690102121f5605d34fb0", "title": "Editing Large Language Models: Problems, Methods, and Opportunities"}, {"paperId": "02529b2666a536053a2e2940de5b28de36fd594b", "title": "Lion: Adversarial Distillation of Proprietary Large Language Models"}, {"paperId": "0088c9f4d50706c7ab71efa13bcb4b42cf2058e2", "title": "PRODIGY: Enabling In-context Learning Over Graphs"}, {"paperId": "3a755f8dcc9af9304c2cbd3a00e42e66feec1d5d", "title": "Patton: Language Model Pretraining on Text-Rich Networks"}, {"paperId": "42a30dc5470f54ec249f25d3c31e05d7c376c8e3", "title": "VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks"}, {"paperId": "e0bc91243e4e446f6b8871b4fc40b4a413f93c73", "title": "G-Adapter: Towards Structure-Aware Parameter-Efficient Transfer Learning for Graph Transformer Networks"}, {"paperId": "df2beaae63e4d68ef8e762bcd4704c9f11f856d9", "title": "Can Language Models Solve Graph Problems in Natural Language?"}, {"paperId": "37767c063cfb1620c51f51ae726c7e6efe05dad6", "title": "Augmenting Low-Resource Text Classification with Graph-Grounded Pre-training and Prompting"}, {"paperId": "51484cf02592a3551f944b7c6bf94fe902c0aa66", "title": "Train Your Own GNN Teacher: Graph-Aware Distillation on Textual Graphs"}, {"paperId": "cba6c4fff441a317632c6a92e4e10aba59cb0217", "title": "AdapterGNN: Parameter-Efficient Fine-Tuning Improves Generalization in GNNs"}, {"paperId": "0d502a1e300336ae628f5c8b99ee4d3766c8f60b", "title": "Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT"}, {"paperId": "bb435dcd5fa7c7a7112af9adcb58f23b87ef28ac", "title": "GraphMAE2: A Decoding-Enhanced Masked Self-Supervised Graph Learner"}, {"paperId": "99fc800f20fbdc7bbb70cc5dbd456959338ce7b8", "title": "A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material"}, {"paperId": "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d", "title": "A Survey of Large Language Models"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "30809168fff23c852867ad359baaebfae532f0a7", "title": "Enhancing Activity Prediction Models in Drug Discovery with the Ability to Understand Human Language"}, {"paperId": "6155e94e5174e4c615f890c185acbe4b635dba16", "title": "IGB: Addressing The Gaps In Labeling, Features, Heterogeneity, and Size of Public Graph Datasets for Deep Learning Research"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "8b3c2c1886f4e08f6f916f8fbad8c1a5567b927e", "title": "SGL-PT: A Strong Graph Learner with Graph Prompt Tuning"}, {"paperId": "1b8927a2ef3b83663ce1c32aeb8539f549395a97", "title": "HINormer: Representation Learning On Heterogeneous Information Networks with Graph Transformer"}, {"paperId": "1c3ddc72d39d99da8c73669155e9109c6b4e1ef4", "title": "Edgeformers: Graph-Empowered Transformers for Representation Learning on Textual-Edge Networks"}, {"paperId": "3599a236f285af48782fc30b1341d13ec7320735", "title": "A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT"}, {"paperId": "ae3d869719c15099889c02c03b922516b3b60aa0", "title": "How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation"}, {"paperId": "349a080b4649e6ea8440178cde6e72b448fcc951", "title": "Foundation Models for Natural Language Processing: Pre-trained Language Models Integrating Media"}, {"paperId": "efbe97d20c4ffe356e8826c01dc550bacc405add", "title": "Adding Conditional Control to Text-to-Image Diffusion Models"}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "958bb3831589246fe5b6b58cf99e3b65c58d027f", "title": "Multi-modal Molecule Structure-text Model for Text-based Retrieval and Editing"}, {"paperId": "3fd66f10b978d44e063aa23c64cdfe98722a3812", "title": "MA-GCL: Model Augmentation Tricks for Graph Contrastive Learning"}, {"paperId": "efb6899d2eeb27fbd099220146f511aeb78acfa9", "title": "On the power of foundation models"}, {"paperId": "7d645a3fd276918374fd9483fd675c28e46506d1", "title": "Galactica: A Large Language Model for Science"}, {"paperId": "b35cf53b13065f9860faa4760279e3c164d9762c", "title": "A Systematic Survey of Chemical Pre-trained Models"}, {"paperId": "8bb37e8ae7dd6fa8cab2407f63a61f697152717f", "title": "Learning on Large-scale Text-attributed Graphs via Variational Inference"}, {"paperId": "85f578d2df32bdc3f42fdaa9b65a1904b680a262", "title": "Universal Prompt Tuning for Graph Neural Networks"}, {"paperId": "1c7a4e8d9f4fcf19a5d1caa078c66ca39cb75dd2", "title": "A Molecular Multimodal Foundation Model Associating Molecule Graphs with Natural Language"}, {"paperId": "17bcb1edbe068e8fe6a97da552c70a77a15bbce7", "title": "Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned"}, {"paperId": "51f98ef273a868d2db82727b339f52f19b7883f9", "title": "MentorGNN: Deriving Curriculum for Pre-Training GNNs"}, {"paperId": "e60ad3d4ed3273af6a94745689783b83f59c8b4a", "title": "GPPT: Graph Pre-training and Prompt Tuning to Generalize Graph Neural Networks"}, {"paperId": "eb329330c5cf838343f277e08e1478f142153922", "title": "Effectively Identifying Compound-Protein Interaction Using Graph Neural Representation"}, {"paperId": "5eda60d4940d4185df45c5703e103458171d465d", "title": "Pure Transformers are Powerful Graph Learners"}, {"paperId": "f7a3d9bcf052f2b4ef7d59dcca4013ea11081d0f", "title": "Long Range Graph Benchmark"}, {"paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a", "title": "Emergent Abilities of Large Language Models"}, {"paperId": "277dd73bfeb5c46513ce305136b0e71fcd2a311c", "title": "Recipe for a General, Powerful, Scalable Graph Transformer"}, {"paperId": "b161c4aaddd2983a9d4d5a240bd5ffa84b36c4e7", "title": "GraphMAE: Self-Supervised Masked Graph Autoencoders"}, {"paperId": "5445c21f471938a495ba7459fc8e3662d9a4b1eb", "title": "Heterformer: Transformer-based Deep Node Representation Learning on Heterogeneous Text-Rich Networks"}, {"paperId": "246c97ebe5ebd13603be168515cd5f5a347e7e0a", "title": "Graph Neural Networks Designed for Different Graph Types: A Survey"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "f2b0869b17bace854d73c19b449e3f88b9fed82e", "title": "How Pre-trained Language Models Capture Factual Knowledge? A Causal-Inspired Analysis"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "e58dde4b23f251314e900f56e765b4aad27bc15f", "title": "Transformer for Graphs: An Overview from Architecture Perspective"}, {"paperId": "4f0925684db82985f9c48566065d4ead5e00a16b", "title": "Learning and Evaluating Graph Neural Network Explanations based on Counterfactual and Factual Reasoning"}, {"paperId": "cc73da69eb495a122ed24bc680bf9e2f1a420e0c", "title": "A Survey of Pretraining on Graphs: Taxonomy, Methods, and Applications"}, {"paperId": "ea0e4a9778e33b7f8e7b3246d63071330950995a", "title": "Structure-Aware Transformer for Graph Representation Learning"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "be8e58320203a92bfacc1a1f95f6e65f3ee4fa5c", "title": "A Survey of Controllable Text Generation Using Transformer-based Pre-trained Language Models"}, {"paperId": "002c58077a1f1b296468b117230a1199e91f35c2", "title": "Black-Box Tuning for Language-Model-as-a-Service"}, {"paperId": "b415ecb687941e1e9ef68e04a4a1c68c73483d51", "title": "A Comprehensive Analytical Survey on Unsupervised and Semi-Supervised Graph Representation Learning Methods"}, {"paperId": "4755b49e44a453666022ac47a0706802aed8ec94", "title": "A Review on Graph Neural Network Methods in Financial Applications"}, {"paperId": "09f2b7eaa20c98c7668885ff5276580734100fe5", "title": "Cross-Domain Graph Convolutions for Adversarial Unsupervised Domain Adaptation"}, {"paperId": "8436897e713c2242d6291df9a6a33c1544d4dd39", "title": "Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models"}, {"paperId": "429a6f6a8455634e1bb818811248b25a008c78f4", "title": "Graph neural networks in node classification: survey and evaluation"}, {"paperId": "259cbc1492c51d985bdafb67e48fa170471ee446", "title": "Node Feature Extraction by Self-Supervised Multi-scale Neighborhood Prediction"}, {"paperId": "cb8dcaf8e5fe7256577c6bc83e11dd64d8f3ae31", "title": "Towards artificial general intelligence via a multimodal foundation model"}, {"paperId": "06487c52f923b3123f9fddcc6f611bf39d593bd6", "title": "Contrastive Pre-Training of GNNs on Heterogeneous Graphs"}, {"paperId": "b8f816e23ff40d6afabccca2ee4770087ef0ef57", "title": "Pre-training Molecular Graph Representation with 3D Geometry"}, {"paperId": "3b2f5884e8199544375ddcdb4fa58f44df0b1a7e", "title": "Be Confident! Towards Trustworthy Graph Neural Networks via Confidence Calibration"}, {"paperId": "cddf40e579a596d0110b260313adf43470617c4c", "title": "Datasets: A Community Library for Natural Language Processing"}, {"paperId": "8c24ef76d0a15bae316d1b9e6ab526ea5af93530", "title": "Graph Neural Networks: Methods, Applications, and Opportunities"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "163d9fe4c45d38e31a53464b5af7638d70839a9b", "title": "LINKTELLER: Recovering Private Edges from Graph Neural Networks via Influence Analysis"}, {"paperId": "64a5b04b2dd6c1a80ba1201b323eea10f0674ba6", "title": "Pre-training on Large-Scale Heterogeneous Graph"}, {"paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"}, {"paperId": "5863d7b35ea317c19f707376978ef1cc53e3534c", "title": "Rethinking Graph Transformers with Spectral Attention"}, {"paperId": "a1fd9d031c77b7476c3bcb26ec169977584857f7", "title": "MoCL: Data-driven Molecular Fingerprint via Knowledge-aware Contrastive Learning from Molecular Graph"}, {"paperId": "2d00798b8a7d979c925901e9faa5fe4360030ca2", "title": "Self-Supervised Learning on Graphs: Contrastive, Generative, or Predictive"}, {"paperId": "bf713a9595edc9f8c4d240a08f2b5b01efbf1eb2", "title": "GraphFormers: GNN-nested Transformers for Representation Learning on Textual Graph"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "7b99c51d562e33309a46601c846abbe72a65c6a4", "title": "What to Pre-Train on? Efficient Intermediate Task Selection"}, {"paperId": "38fdd7d958708e124fd2bf65771fe5151b9ff03b", "title": "Extract the Knowledge of Graph Neural Networks and Go Beyond it: An Effective Knowledge Distillation Framework"}, {"paperId": "e259ee075998eedc0b0c91c17769bf9dffeba46f", "title": "Graph Self-Supervised Learning: A Survey"}, {"paperId": "7dee0821e4b0ece2972d4cedfbe31785a05dba37", "title": "Graph-Based Semi-Supervised Learning: A Comprehensive Review"}, {"paperId": "8d68eae4068fca5ae3e9660c2a87857c89d30f73", "title": "Self-Supervised Learning of Graph Neural Networks: A Unified Review"}, {"paperId": "5bf57b615bfce122792295fd7a4e89d230787ccc", "title": "A federated graph neural network framework for privacy-preserving personalization"}, {"paperId": "bad3534cc797606d1fe3cb09713407783e77cac4", "title": "Graph Neural Network for Traffic Forecasting: A Survey"}, {"paperId": "5a2e45ce35fb26ab70a61b424a49f8e5b4532a8e", "title": "WARP: Word-level Adversarial ReProgramming"}, {"paperId": "a50f37cdd0614567ef52ffa63c70285d97630ce4", "title": "A compact review of molecular property prediction with graph neural networks."}, {"paperId": "0a69c8815536a657668e089e3281ff2e963d947a", "title": "Design Space for Graph Neural Networks"}, {"paperId": "9df9810cc43719290f2796aa298f386c74228150", "title": "Biological network analysis with deep learning"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "2a9fbca9dc6badbeedc591ad829c5c6e0f950fd6", "title": "Graph Contrastive Learning with Augmentations"}, {"paperId": "b8b3380efb26854bae6f51ad1d2b5a045129c5a1", "title": "Distance Encoding: Design Provably More Powerful Neural Networks for Graph Representation Learning"}, {"paperId": "1ef493a358cae89e8d5474574b4c7fdddbe00570", "title": "Graph-based Modeling of Online Communities for Fake News Detection"}, {"paperId": "04faf433934486c41d082e8d75ccfe5dc2f69fef", "title": "GPT-GNN: Generative Pre-Training of Graph Neural Networks"}, {"paperId": "a9a4e8e631890a14257539948e1813b5214c60dd", "title": "Self-Supervised Graph Transformer on Large-Scale Molecular Data"}, {"paperId": "91fb815361fdbf80ff15ce4d783a41846bd99232", "title": "GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training"}, {"paperId": "3bfa808ce20b2736708c3fc0b9443635e3f133a7", "title": "On the Bottleneck of Graph Neural Networks and its Practical Implications"}, {"paperId": "4bf76588122827157c43a59e656dccc6b6a22e90", "title": "Deep Graph Contrastive Representation Learning"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "4a253cd63110da07bb17074f6ac14717afd2f3f1", "title": "Foundations and Modeling of Dynamic Networks Using Dynamic Graph Neural Networks: A Survey"}, {"paperId": "597bd2e45427563cdf025e53a3239006aa364cfc", "title": "Open Graph Benchmark: Datasets for Machine Learning on Graphs"}, {"paperId": "4a4f84992b4ee8331f1e3189f6f9b0437214035c", "title": "Traffic Flow Prediction via Spatial Temporal Graph Neural Network"}, {"paperId": "3bcb17559ce96eb20fa79af8194f4af0380d194a", "title": "Pre-trained models for natural language processing: A survey"}, {"paperId": "0ca7d8c3250d43d14fdde46bf6fc299654d861ef", "title": "Heterogeneous Graph Transformer"}, {"paperId": "898861ab4733194be5e6fd43449d36c700f53884", "title": "Estimated Research and Development Investment Needed to Bring a New Medicine to Market, 2009-2018."}, {"paperId": "78542c2be9bb853a4e04642f2d315cfb0c6d94b3", "title": "Graph-Bert: Only Attention is Needed for Learning Graph Representations"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "a75649771901a4881b44c0ceafa469fcc6e6f968", "title": "How Can We Know What Language Models Know?"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "75acc731bdd2b626edc74672a30da3bc51010ae8", "title": "CTRL: A Conditional Transformer Language Model for Controllable Generation"}, {"paperId": "d0086b86103a620a86bc918746df0aa642e2a8a3", "title": "Language Models as Knowledge Bases?"}, {"paperId": "93d63ec754f29fa22572615320afe0521f7ec66d", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"}, {"paperId": "bc8473992cde60fa6618886dfc354f67bc041263", "title": "CensNet: Convolution with Edge-Node Switching in Graph Neural Networks"}, {"paperId": "0a6a9e6d4e3efd7c69357769305b70097281655f", "title": "DropEdge: Towards Deep Graph Convolutional Networks on Node Classification"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "3c4d3ac27a23c144bb3c4f8785bffcdc71addd15", "title": "Attributed Graph Clustering: A Deep Attentional Embedding Approach"}, {"paperId": "789a7069d1a2d02d784e4821685b216cc63e6ec8", "title": "Strategies for Pre-training Graph Neural Networks"}, {"paperId": "4e7dd1e79f0f13650b2612325e6ba8d206dc04fb", "title": "DeepGCNs: Can GCNs Go As Deep As CNNs?"}, {"paperId": "00b7efbf14a54cced4b9f19e663b70ffbd01324b", "title": "Heterogeneous Graph Attention Network"}, {"paperId": "403227333329b36183004f04db72362b604adef3", "title": "A Theoretical Analysis of Contrastive Unsupervised Representation Learning"}, {"paperId": "70f7cd54b5918aed60c3d8c3a8e4aa7e8d634c41", "title": "AliGraph: A Comprehensive Graph Neural Network Platform"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "658721bc13b0fa97366d38c05a96bf0a9f4bb0ac", "title": "Multi-Task Deep Neural Networks for Natural Language Understanding"}, {"paperId": "62ed9bf1d83c8db1f9cbf92ea2f57ea90ef683d9", "title": "How Powerful are Graph Neural Networks?"}, {"paperId": "967a21a111757d6af7f7a25ca7ea2bdf6d505098", "title": "Deep Graph Infomax"}, {"paperId": "510d98681e5e85fb1265513728f16e2543ae1b4b", "title": "Hypergraph Neural Networks"}, {"paperId": "59d502851cd20f28af03eef1d15dc83d3a7bb300", "title": "Graph Classification using Structural Attention"}, {"paperId": "e4715a13f6364b1c81e64f247651c3d9e80b6808", "title": "Link Prediction Based on Graph Neural Networks"}, {"paperId": "36652428740cd30d245d55889f01a7fb04a91c93", "title": "Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning"}, {"paperId": "1e077413b25c4d34945cc2707e17e46ed4fe784a", "title": "Universal Language Model Fine-tuning for Text Classification"}, {"paperId": "33998aff64ce51df8dee45989cdca4b6b1329ec4", "title": "Graph Attention Networks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "6b7d6e6416343b2a122f8416e69059ce919026ef", "title": "Inductive Representation Learning on Large Graphs"}, {"paperId": "e24cdf73b3e7e590c2fe5ecac9ae8aa983801367", "title": "Neural Message Passing for Quantum Chemistry"}, {"paperId": "54906484f42e871f7c47bbfe784a358b1448231f", "title": "Variational Graph Auto-Encoders"}, {"paperId": "36eff562f65125511b5dfab68ce7f7a943c27478", "title": "Semi-Supervised Classification with Graph Convolutional Networks"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "5abf1c0ff7dc9157aedd9dfa021f8d3dcc647d9b", "title": "A Survey of Heterogeneous Information Network Analysis"}, {"paperId": "fff114cbba4f3ba900f33da574283e3de7f26c83", "title": "DeepWalk: online learning of social representations"}, {"paperId": "0d2336389dff3031910bd21dd1c44d1b4cd51725", "title": "Why Does Unsupervised Pre-training Help Deep Learning?"}, {"paperId": "bb0770be24e49d1c11a61ee4c0cec2730a7256cc", "title": "AdapterGNN: Efficient Delta Tuning Improves Generalization Ability in Graph Neural Networks"}, {"paperId": "8aa98fbfb6f1e979dead13ce24075503fe47658e", "title": "A Survey for In-context Learning"}, {"paperId": "f01281b125128435ad134230c6a41cc55808eaac", "title": "Can LLMs Effectively Leverage Graph Structural Information: When and Why"}, {"paperId": "d2ecb191cb037c96d4c2ad0a47a49ba82b701285", "title": "WalkLM: A Uniform Language Model Fine-tuning Framework for Attributed Graph Embedding"}, {"paperId": "ec936b808e0fab9281c050ad4010cddec92c8cbe", "title": "P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks"}, {"paperId": "57651d65078818821234d13544ac1f29858dcd67", "title": "Text2Mol: Cross-Modal Molecule Retrieval with Natural Language Queries"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "acf87283fa8ae426f1a4987b345b401bf2913f61", "title": "Do Transformers Really Perform Badly for Graph Representation?"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "1e66fbcc886788dd54046c7221b69da1c82b6229", "title": ": Exploring"}, {"paperId": null, "title": "AGL: A Scalable System for Industrial-purpose Graph Machine Learning"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "6d1d91a413af1212fea8791e266282019b62c37d", "title": "THE REDUCTION OF A GRAPH TO CANONICAL FORM AND THE ALGEBRA WHICH APPEARS THEREIN"}, {"paperId": "4be8e86de6ecd38d0b5204476d296fcc70004568", "title": "Graph Clustering"}, {"paperId": "0c0a778e6fdf7e36b1750c533dcc916f86608607", "title": "A Survey on Context Learning"}, {"paperId": "d49cb9c050e29a2a073e636a0849626e2b2501b7", "title": "The Development of Social Network Analysis\u2014with an Emphasis on Recent Events"}, {"paperId": "69381b5efd97e7c55f51c2730caccab3d632d4d2", "title": "Graph Embedding and Extensions: A General Framework for Dimensionality Reduction"}, {"paperId": null, "title": "2023. Explanations as Features: LLM-Based Features for Text-Attributed Graphs"}, {"paperId": "156d0bc37cee49f70f361e89b5ca2c6c88b6e128", "title": "Pretrained Language Models to Solve Graph Tasks in Natural Language"}, {"paperId": null, "title": "\u201cLlm4dyg: Can large language models solve problems on dynamic graphs?,\u201d"}, {"paperId": null, "title": "2023. Large Graph Models: A Perspective"}, {"paperId": null, "title": "\u201cLess is more: on the over-globalizing problem in graph transformers"}, {"paperId": null, "title": "2023. Retentive network: A successor to transformer for large language models"}, {"paperId": null, "title": "2023. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality"}, {"paperId": null, "title": "Towards Graph"}, {"paperId": null, "title": "\u201cIts all graph to me: Single-model graph representation learning on multiple domains,\u201d"}, {"paperId": null, "title": "\u201cCan large"}, {"paperId": null, "title": "language models empower molecular property prediction?"}]}