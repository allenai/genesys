{"paperId": "5d032bd2632b6f5847767f39ce247098c6bbc563", "abstract": "Transformers provide a class of expressive architectures that are extremely effective for sequence modeling. However, the key limitation of transformers is their quadratic memory and time complexity $\\mathcal{O}(L^2)$ with respect to the sequence length in attention layers, which restricts application in extremely long sequences. Most existing approaches leverage sparsity or low-rank assumptions in the attention matrix to reduce cost, but sacrifice expressiveness. Instead, we propose Combiner, which provides full attention capability in each attention head while maintaining low computation and memory complexity. The key idea is to treat the self-attention mechanism as a conditional expectation over embeddings at each location, and approximate the conditional distribution with a structured factorization. Each location can attend to all other locations, either via direct attention, or through indirect attention to abstractions, which are again conditional expectations of embeddings from corresponding local regions. We show that most sparse attention patterns used in existing sparse transformers are able to inspire the design of such factorization for full attention, resulting in the same sub-quadratic cost ($\\mathcal{O}(L\\log(L))$ or $\\mathcal{O}(L\\sqrt{L})$). Combiner is a drop-in replacement for attention layers in existing transformers and can be easily implemented in common frameworks. An experimental evaluation on both autoregressive and bidirectional sequence tasks demonstrates the effectiveness of this approach, yielding state-of-the-art results on several image and text modeling tasks.", "venue": "Neural Information Processing Systems", "year": 2021, "citationCount": 62, "influentialCitationCount": 7, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Combiner is a drop-in replacement for attention layers in existing transformers and can be easily implemented in common frameworks, yielding state-of-the-art results on several image and text modeling tasks."}, "embedding": {"model": "specter_v2", "vector": [0.5159388780593872, 0.5640111565589905, -0.17719846963882446, -0.08677938580513, -0.1464346945285797, 0.13180886209011078, 0.7951621413230896, -0.17949426174163818, -0.18931017816066742, -0.547420859336853, 0.8314387798309326, 0.5840103626251221, 0.6057562232017517, 0.2544423043727875, -0.20444506406784058, 0.19400735199451447, -0.6978349685668945, 0.21661467850208282, 0.15113961696624756, -0.5407017469406128, 0.09287911653518677, -0.7186459898948669, -1.1878539323806763, 0.222031831741333, 0.2641837000846863, 0.6715660095214844, 0.6525529623031616, 0.8651536703109741, -0.4203489124774933, 0.6798850297927856, 0.5496852397918701, -0.09483063966035843, 0.11626940220594406, 0.020536458119750023, -0.11261671036481857, -0.12656579911708832, 0.6236730217933655, -0.22080165147781372, -0.7020178437232971, 0.7835233807563782, -0.2982722818851471, 0.22892387211322784, 0.6756759881973267, -0.6754739880561829, -0.2456304430961609, 0.8788398504257202, 0.29051706194877625, 0.8591163158416748, -0.1056557297706604, -0.8582733869552612, 1.6466257572174072, -1.6315836906433105, 0.013128970749676228, 1.5682802200317383, 0.3962724208831787, 0.1837657392024994, -0.18769493699073792, -0.6128029823303223, 1.1691954135894775, 0.4321022033691406, -0.656320333480835, -0.5109676718711853, 0.023604534566402435, -0.2288697212934494, 1.9916292428970337, -0.3247351050376892, 0.2218897044658661, 0.397773802280426, 0.08608376234769821, 1.3705737590789795, -0.18017327785491943, -0.6932798027992249, -0.3949132263660431, -0.15445004403591156, 0.4374869167804718, 1.0574613809585571, -0.746288537979126, 0.16675028204917908, -1.261299729347229, -0.010184932500123978, 0.46166157722473145, 0.2726995646953583, 0.07087092101573944, -0.260492205619812, -0.07856680452823639, 0.3617320656776428, 0.6007472276687622, 0.9373306035995483, -0.36162737011909485, 0.9636852741241455, 0.4103092551231384, 0.10478724539279938, -0.10861998051404953, 0.1752283275127411, 0.17697539925575256, 0.46785545349121094, -0.6869367361068726, 0.09015083312988281, -0.01958649791777134, 1.2040659189224243, -0.11571981012821198, 0.46986404061317444, -0.4574996829032898, 0.07130756974220276, 1.2893105745315552, 0.2542676627635956, 0.47703003883361816, -0.4000478982925415, 0.04185565933585167, -0.687541127204895, -0.12965017557144165, -1.2620251178741455, 0.06446865946054459, -0.29413846135139465, -0.9131253361701965, -1.1240930557250977, -0.6339243054389954, 0.59296053647995, -0.6692153215408325, 0.6828525066375732, -0.4315558671951294, 0.4295892119407654, -0.45920294523239136, 0.11808473616838455, 0.5003535747528076, 0.8022423982620239, 0.48180344700813293, 0.3876018822193146, 1.3125652074813843, -1.1614158153533936, -0.6582112312316895, -1.2018953561782837, 0.4542474150657654, -0.05793842673301697, 0.13309159874916077, -0.23796656727790833, -1.0015794038772583, -1.1146382093429565, -0.5998796224594116, -0.11588213592767715, -0.7237566113471985, 0.29296326637268066, 0.592179000377655, 0.03493710979819298, -1.128880262374878, 0.6898807287216187, -0.32939690351486206, 0.022488977760076523, 0.5186269283294678, 0.14891575276851654, 0.09029281139373779, -0.2328580617904663, -1.2325878143310547, 0.4592932164669037, -0.20924662053585052, -0.34489160776138306, -0.30722928047180176, -0.702053427696228, -1.4041986465454102, 0.38150638341903687, 0.17417344450950623, -0.27728506922721863, 0.8832498788833618, -0.20303624868392944, -1.0716303586959839, 0.6506209373474121, -0.9086401462554932, -0.011201770976185799, -0.22874268889427185, -0.6527786254882812, -0.16277433931827545, -0.358193576335907, -0.02449633926153183, 0.33342793583869934, 0.6709228157997131, -0.10584153234958649, -0.2891579270362854, -0.15739059448242188, -0.5734964609146118, -0.03960457816720009, -0.500393271446228, 1.2617870569229126, -0.44985365867614746, -0.31314343214035034, -0.03783782571554184, 0.6331048011779785, -0.02840438485145569, -0.286467969417572, -0.15852667391300201, -1.0248523950576782, 0.9314476251602173, -0.06997311115264893, 0.9849425554275513, -1.026090145111084, -0.245282843708992, -0.42790132761001587, 0.1382835954427719, -0.2204936146736145, -1.0777872800827026, 0.6556255221366882, -0.8028277158737183, 0.2877006232738495, -0.01227258238941431, -1.4108102321624756, -0.11013536155223846, -0.3992927074432373, -0.8797190189361572, -0.18167227506637573, 0.12002691626548767, 1.1574549674987793, -1.0154640674591064, -0.23526833951473236, -0.04847889393568039, 0.44140350818634033, -0.8709284663200378, 1.3255431652069092, -0.2776026129722595, -0.23123015463352203, -0.27138108015060425, -0.23208202421665192, -0.11325744539499283, -0.5017523169517517, 0.40055590867996216, -0.7778813242912292, 0.055636316537857056, 0.32232338190078735, 0.08138283342123032, 1.0713553428649902, -0.42996945977211, 0.5712124705314636, -0.11986495554447174, -0.8237568736076355, 0.47112640738487244, 0.31077712774276733, -0.07301811128854752, -0.2818775773048401, 0.19323468208312988, 0.11334612220525742, -0.8947077393531799, 0.056489430367946625, 0.7196062207221985, 0.9453667998313904, -0.36351507902145386, -0.08395782113075256, 0.5294843912124634, -0.2730861008167267, 0.07006195932626724, 0.7067161202430725, 0.9007513523101807, 0.6388217806816101, 0.5543116331100464, -0.20845037698745728, 0.2574377954006195, -1.1615098714828491, -0.043296199291944504, 0.36829614639282227, 0.7574059963226318, 0.9250920414924622, 0.4025803804397583, -0.8329373002052307, -0.5452556014060974, 0.45650556683540344, 1.1890134811401367, 1.6314669847488403, -0.24140118062496185, -0.5023751258850098, -0.4954489469528198, -0.22572456300258636, -0.42568984627723694, -0.23542167246341705, -0.6021946668624878, -0.24353554844856262, -0.5708500146865845, -0.5074872970581055, 0.3827456831932068, 0.6533285975456238, 0.8996037244796753, -0.6346116065979004, -0.4399084746837616, -0.1822005808353424, 0.07584647089242935, -1.0866901874542236, -0.7882632613182068, 0.3708878457546234, -0.2534310221672058, 0.048995859920978546, 0.0467691645026207, -0.32736465334892273, 0.1296747624874115, -0.36732086539268494, 1.061500072479248, -0.5418058037757874, -0.4133100211620331, 0.4617592692375183, 0.28637588024139404, -0.8766006827354431, -0.11296622455120087, 0.376827210187912, 0.07249214500188828, 0.11268818378448486, 0.5558932423591614, 0.11529403924942017, 0.11267609894275665, -0.032140281051397324, -0.1060088723897934, -0.009436888620257378, -0.06180211901664734, -0.12537972629070282, 0.49002647399902344, -0.37659838795661926, -0.1392485648393631, -1.0190967321395874, 0.3239840865135193, -0.14418740570545197, -0.250577449798584, 0.05163206532597542, -0.19490675628185272, -0.7638125419616699, 0.5744529962539673, -0.5931848883628845, -0.18102934956550598, -0.23430363833904266, 0.546837329864502, -0.775108814239502, -0.1961289346218109, 0.402799129486084, 0.25258252024650574, 0.348602831363678, 0.09768262505531311, 0.7605087161064148, 0.5421863198280334, 0.02167661488056183, 0.26462993025779724, -1.041815996170044, 0.5607889890670776, 0.3369453549385071, 0.2398727834224701, 0.1076655164361, 0.06338092684745789, -1.0608839988708496, -0.7109551429748535, -0.7220901846885681, -0.38712286949157715, -0.40121376514434814, 0.3786666989326477, -0.7932113409042358, -0.7984341382980347, -0.04384496808052063, -1.218218445777893, -0.1280592381954193, 0.16069908440113068, -0.678273618221283, -0.38378801941871643, -0.9123122096061707, -0.8609398007392883, -0.6672166585922241, -0.5175484418869019, -0.7917211055755615, 0.6586434245109558, 0.13428451120853424, -0.43957147002220154, -0.6262571811676025, -0.11449085175991058, -0.46445122361183167, 0.9351288080215454, -0.30754557251930237, 0.515204131603241, -0.17414624989032745, -0.597114622592926, -0.47397270798683167, 0.1763102412223816, 0.4538883566856384, 0.09961215406656265, 0.10765494406223297, -0.758438766002655, 0.22152751684188843, -0.14006878435611725, -0.16616573929786682, 0.32216188311576843, 0.2991168200969696, 0.8283299207687378, 0.042730942368507385, -0.9089034795761108, -0.03684341907501221, 1.4971665143966675, -0.5204841494560242, 0.1815829873085022, -0.11211536079645157, 1.0950560569763184, 0.33673200011253357, -0.30532923340797424, 0.6575313806533813, 0.6613404154777527, 0.43410709500312805, 0.3477456271648407, -0.20060686767101288, -0.2661621868610382, -0.5951960682868958, 0.6262697577476501, 1.6848310232162476, 0.1417757272720337, 0.11030859500169754, -1.1498903036117554, 1.1425142288208008, -1.4009461402893066, -1.0522489547729492, 0.6808047294616699, 0.26221975684165955, 0.1731502115726471, -0.7197245955467224, -0.19467417895793915, -0.6225390434265137, 0.5851060152053833, 0.5462808012962341, -0.2005094438791275, -0.31578564643859863, 0.05496001988649368, 0.40383416414260864, -0.07931888103485107, 0.7802574634552002, -0.4226831793785095, 0.5048898458480835, 14.794317245483398, 0.48123592138290405, 0.01759505271911621, 0.2748529613018036, 0.8187779188156128, 0.19259750843048096, -0.28135713934898376, 0.06374306231737137, -1.3068612813949585, -0.051100097596645355, 0.9340524077415466, 0.2527724504470825, 0.3405821621417999, 0.1115591824054718, -0.01145560946315527, 0.4468857944011688, -0.7800196409225464, 0.7455494403839111, 1.0083438158035278, -1.0463753938674927, 0.30863049626350403, 0.08619076013565063, -0.011861113831400871, 0.18529440462589264, 0.9174643158912659, 0.6817276477813721, 0.5576485991477966, -0.6228858232498169, 0.31442439556121826, 0.7264291644096375, 0.7943163514137268, 0.2154502123594284, -0.03239886090159416, 0.4632585942745209, -1.3713923692703247, -0.3417626917362213, -0.6022961139678955, -1.2760380506515503, 0.3665488660335541, 0.1231401339173317, -0.27541396021842957, -0.439012736082077, 0.08489006757736206, 1.2154690027236938, 0.018882689997553825, 0.1724228858947754, -0.12055180221796036, 0.4487624764442444, -0.059397660195827484, -0.3430942893028259, 0.2891218662261963, 0.5844554305076599, 0.23553258180618286, 0.2006542980670929, 0.10030768811702728, 0.3681192696094513, 0.11920084059238434, 0.4461853504180908, -0.23101283609867096, -0.09989190101623535, -0.5475236773490906, -0.2409370392560959, -0.046822689473629, 0.8991481065750122, 0.6896911263465881, 0.06963710486888885, -0.5581154227256775, 0.06412838399410248, 0.7409251928329468, 0.11076197028160095, -0.3861989378929138, -0.09783770143985748, 0.11938592046499252, -0.18714742362499237, 0.4692496359348297, 0.5593294501304626, -0.17818501591682434, -0.5117027759552002, -0.9319815635681152, -0.5405522584915161, 0.37227511405944824, -1.0183221101760864, -0.722968578338623, 0.9371054768562317, -0.17014184594154358, -0.19958017766475677, 0.3302752375602722, -0.632628858089447, -0.3904392123222351, 0.4754989743232727, -1.2392542362213135, -0.7694264650344849, -0.1771484762430191, -0.38421347737312317, 0.046522364020347595, -0.22699899971485138, 1.1791112422943115, -0.00878951046615839, -0.16255265474319458, -0.20053084194660187, -0.4304165542125702, -0.13754530251026154, -0.36877214908599854, -0.8812722563743591, 0.774817168712616, 0.11320168524980545, -0.12997576594352722, 0.2530139088630676, 0.2877737581729889, 0.11839032173156738, -0.7548626065254211, -0.11289090663194656, 0.9436120390892029, -0.815281093120575, -0.1940552294254303, -0.8496139049530029, -0.8834477066993713, 0.5529624819755554, 0.8487563729286194, -0.12202570587396622, 0.35246437788009644, 0.13059666752815247, -0.8124117255210876, -0.07724369317293167, -0.34629184007644653, 0.21118173003196716, 0.3841021656990051, -0.9881967306137085, -0.3737804889678955, -0.20469599962234497, 0.34988686442375183, -0.8174889087677002, -0.4332849383354187, -0.2011300027370453, 0.22406820952892303, -0.11814665049314499, 1.058639407157898, -0.4408252239227295, 1.254509687423706, 0.7091882824897766, -0.09596572816371918, -0.7744966149330139, -0.5204877853393555, -0.9424670934677124, -0.22725065052509308, 0.336714506149292, 0.4230341911315918, -0.25760138034820557, 0.25011906027793884, 0.7766150236129761, 0.4394555389881134, -0.5300683975219727, -0.3210996985435486, -0.0422593392431736, -0.17896591126918793, -0.018229417502880096, 0.14814326167106628, -0.11063716560602188, 0.23326165974140167, 0.40320777893066406, 0.16230203211307526, 0.40457969903945923, -0.02373436838388443, -0.6428496837615967, 0.3968918025493622, -0.09475981444120407, -0.002109634457156062, -0.5257254838943481, -0.5082425475120544, -1.5349421501159668, 0.31034964323043823, -0.9717928171157837, 0.08649557083845139, -1.0705673694610596, -0.27194660902023315, 0.34356674551963806, -0.1261061280965805, 0.3198581337928772, 0.08753204345703125, -0.44949018955230713, -0.08624520897865295, -0.6686606407165527, -0.5305073857307434, 0.8702170252799988, 0.7497414946556091, -0.8093848824501038, 0.4950779676437378, -0.3115730285644531, -0.17093807458877563, 0.3054264783859253, 0.2521388828754425, -0.4168631136417389, -0.6344461441040039, -1.0508475303649902, 0.4154883921146393, 0.04591676965355873, -0.00976396631449461, -0.6023274660110474, 0.925631582736969, 0.4990304112434387, -0.18005095422267914, -0.11528144031763077, 0.6772517561912537, -1.2374156713485718, -0.5894544720649719, 0.36612561345100403, -1.0292924642562866, 0.3055497407913208, 0.17839807271957397, -0.3247322142124176, -0.5442010760307312, 0.779208242893219, 0.04411622881889343, -1.3374966382980347, -0.5818107724189758, 0.6796051263809204, -0.6187032461166382, -0.02855481207370758, -0.09327474981546402, -0.19195030629634857, -0.9710685014724731, -0.7557913064956665, -0.10572018474340439, 0.3974275290966034, -0.6229348182678223, 1.0850050449371338, 0.6868067979812622, -1.3479410409927368, -0.07095657289028168, 0.20539610087871552, -0.1100986897945404, 0.11868282407522202, 0.6493740081787109, 0.19178366661071777, 0.08643818646669388, 0.31846702098846436, 0.16175362467765808, 0.2503805458545685, -1.152406096458435, 0.2843395173549652, 0.7592344880104065, -0.5318905711174011, -0.1878548115491867, 1.0177534818649292, 0.15905015170574188, -0.6932940483093262, 0.08140212297439575, -0.8612415790557861, -0.8300520777702332, -0.005421242211014032, 0.8946482539176941, 0.12161615490913391, -0.5331296324729919, -0.3258351683616638, -0.6276119947433472, 0.498654305934906, -0.2723124325275421, -0.30871641635894775, 0.8955986499786377, -0.13612133264541626, -0.534773051738739, 0.66696697473526, 0.9833822846412659, -0.7352970838546753, -0.730069637298584, -1.0123740434646606, -0.6505157351493835, -0.2231321781873703, 0.16206826269626617, 0.05914296954870224, -0.6813909411430359, 0.8546876311302185, 0.15150117874145508, 0.6046284437179565, 0.2411198616027832, -0.19526393711566925, -0.09433687478303909, 0.5335297584533691, -0.21310432255268097, -0.39834463596343994, -0.02273443154990673, 1.6212542057037354, 1.9222642183303833, -0.260151207447052, 0.22088317573070526, -0.6620269417762756, -0.8354125618934631, 0.6737315654754639, 0.5405189394950867, -0.5455065369606018, 1.2614085674285889, 0.16193905472755432, -0.17146332561969757, -0.019533000886440277, -1.302119255065918, -0.2407456636428833, 0.8473632335662842, 1.421990156173706, 0.7325471043586731, -0.14679358899593353, 0.551493227481842, 0.490616112947464, 0.20670220255851746, 0.05805296078324318, 0.4486987888813019, 0.1728358268737793, -0.1104966327548027, 0.29636311531066895, 0.15948887169361115, 0.585304319858551, -0.5124849677085876, -0.5404433608055115, 0.2654256820678711, 0.1118607148528099, -0.3044508099555969, 0.258720338344574, 0.9875088930130005, 0.12414313852787018, 0.5609301924705505, 0.20850008726119995, 0.35494139790534973, -0.663128674030304, -0.20538316667079926, -0.11759486049413681, -0.8875594735145569, -0.1661130040884018, -0.5485027432441711, -0.8211679458618164, -0.08400380611419678, 0.25629836320877075, 0.2872367203235626, -0.4550078809261322, 0.015441945753991604, 1.081990361213684, 0.7223624587059021, 0.8072015643119812, -0.17030256986618042, -0.6617096662521362, -0.3127828538417816, -0.8868148326873779, 0.05692634731531143, -0.4469214081764221, 0.0977000743150711, -0.21861344575881958, -0.03265459090471268, 0.15536244213581085]}, "authors": [{"authorId": "40046694", "name": "Hongyu Ren"}, {"authorId": "2791430", "name": "H. Dai"}, {"authorId": "3422912", "name": "Zihang Dai"}, {"authorId": "2111076891", "name": "Mengjiao Yang"}, {"authorId": "1702139", "name": "J. Leskovec"}, {"authorId": "50319359", "name": "D. Schuurmans"}, {"authorId": "144445933", "name": "Bo Dai"}], "references": [{"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "40ca4fcfffa7ca9aa9b7ff06ecf3cd0436712d78", "title": "$O(n)$ Connections are Expressive Enough: Universal Approximability of Sparse Transformers"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "01203341a8b5b7df21dec5359afe8cc388786ebf", "title": "Wiki-40B: Multilingual Language Model Dataset"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "c5f7074a264356c9a022a8dff24df79d1db8c3d3", "title": "ProGen: Language Modeling for Protein Generation"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "e38a118f18f1b6e1a4e3d3f6fe4838fcdc0af022", "title": "Learning and Evaluating Contextual Embedding of Source Code"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "36e30516683032634975c53e60f3737b6e35ff80", "title": "Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "bed7c155b843fda8a1c994ce71e9176e43b20f77", "title": "Factorized Attention: Self-Attention with Linear Complexities"}, {"paperId": "5132500b23d2da47129b3f4f68dd30947a29e502", "title": "CCNet: Criss-Cross Attention for Semantic Segmentation"}, {"paperId": "36d3a18a1519e27f7c9c8479b19fc00d4d805a00", "title": "Generating High Fidelity Images with Subscale Pixel Networks and Multidimensional Upscaling"}, {"paperId": "fb507ada871d1e8c29e376dbf7b7879689aa89f9", "title": "Music Transformer: Generating Music with Long-Term Structure"}, {"paperId": "21b786b3f870fc7fa247c143aa41de88b1fc6141", "title": "Glow: Generative Flow with Invertible 1x1 Convolutions"}, {"paperId": "bb669de2fce407df2f5cb2f8c51dedee3f467e04", "title": "The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation"}, {"paperId": "41a78e2885b5dc8c719495a33985b5f4880f5b48", "title": "Speech-Transformer: A No-Recurrence Sequence-to-Sequence Model for Speech Recognition"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "d1c424c261c577958917055f72fb9e2ad0348865", "title": "PixelSNAIL: An Improved Autoregressive Generative Model"}, {"paperId": "ef9ddbc35676ce8ffc2a8067044473727839dbac", "title": "Breaking the Softmax Bottleneck: A High-Rank RNN Language Model"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "2d1b8f60f2724efd6c9344870fb60e8525157d70", "title": "Parallel Multiscale Autoregressive Density Estimation"}, {"paperId": "a456265138c088a894301c0433dae938705a9bec", "title": "Deep Sets"}, {"paperId": "2e77b99e8bd10b9e4551a780c0bde9dd10fdbe9b", "title": "PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications"}, {"paperId": "41f1d50c85d3180476c4c7b3eea121278b0d8474", "title": "Pixel Recurrent Neural Networks"}, {"paperId": "58c85498e23c86f526223e661e250007794c8d67", "title": "Memory Efficient Kernel Approximation"}, {"paperId": "7a59fde27461a3ef4a21a249cc403d0d96e4a0d7", "title": "Random Features for Large-Scale Kernel Machines"}, {"paperId": "dd6de9423afcc0f821fee2bd0363a4091c7f8cd3", "title": "Distribution Augmentation for Generative Modeling"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "is typically used for BERT pretraining"}]}