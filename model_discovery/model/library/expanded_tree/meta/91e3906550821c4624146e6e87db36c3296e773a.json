{"paperId": "91e3906550821c4624146e6e87db36c3296e773a", "abstract": "Since DARPA Grand Challenges (rural) in 2004/05 and Urban Challenges in 2007, autonomous driving has been the most active field of AI applications. Recently powered by large language models (LLMs), chat systems, such as chatGPT and PaLM, emerge and rapidly become a promising direction to achieve artificial general intelligence (AGI) in natural language processing (NLP). There comes a natural thinking that we could employ these abilities to reformulate autonomous driving. By combining LLM with foundation models, it is possible to utilize the human knowledge, commonsense and reasoning to rebuild autonomous driving systems from the current long-tailed AI dilemma. In this paper, we investigate the techniques of foundation models and LLMs applied for autonomous driving, categorized as simulation, world model, data annotation and planning or E2E solutions etc.", "venue": "arXiv.org", "year": 2023, "citationCount": 5, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper investigates the techniques of foundation models and LLMs applied for autonomous driving, categorized as simulation, world model, data annotation and planning or E2E solutions etc."}, "embedding": {"model": "specter_v2", "vector": [-0.4968051016330719, 0.657759964466095, -0.29707175493240356, 0.14534907042980194, -0.30818697810173035, -0.08341719210147858, 0.7198891043663025, -0.5129504799842834, -0.36398035287857056, 0.723619282245636, 0.3312879800796509, -0.42276448011398315, 0.27693986892700195, -0.20206356048583984, -0.38671866059303284, 0.16978168487548828, -1.0583951473236084, 0.5668486952781677, 0.3070071339607239, -0.6676194667816162, -0.4655003845691681, -0.10421160608530045, -1.2823948860168457, 0.0017094959039241076, 0.5687164068222046, -0.004765513818711042, 0.050813399255275726, 0.8780940771102905, -0.09493788331747055, 0.6482303738594055, 0.6127366423606873, 0.017917070537805557, 0.3752632439136505, 0.13654103875160217, -0.04025516286492348, -0.3528132140636444, 0.2485380470752716, -0.6822043061256409, -1.0474778413772583, 0.5904580354690552, -0.38975420594215393, 0.21812298893928528, 0.2359549105167389, -1.4860543012619019, -0.06254281848669052, 0.3777531385421753, 1.0061451196670532, 0.8331605195999146, 0.0705081969499588, -0.4582969546318054, 1.2387773990631104, -0.8845676183700562, 0.5000125765800476, 1.3494809865951538, 0.3044346868991852, 0.552300751209259, -0.05655158311128616, -1.0732953548431396, -0.019084468483924866, 0.33036497235298157, -1.004299283027649, -0.251101553440094, -0.1293054223060608, -0.4317154288291931, 1.0074084997177124, -0.5232319235801697, -0.10156979411840439, 0.24223899841308594, 0.24770884215831757, 1.3434561491012573, 0.14581313729286194, -1.0001529455184937, 0.012676934711635113, 0.46182188391685486, 0.17623867094516754, 1.0237547159194946, -0.03794259950518608, 0.5094575881958008, -0.9286791682243347, -0.4196695387363434, 0.4478304982185364, -0.6687559485435486, 0.034667596220970154, -0.5090731382369995, -0.4628892242908478, 1.2631603479385376, -0.13996776938438416, 0.03802337870001793, -0.0025057385209947824, 0.6856898665428162, 0.4936411380767822, 0.3079083561897278, -0.5784923434257507, -0.0568821020424366, 0.11244523525238037, 0.38611048460006714, -0.07783813774585724, 0.7157477736473083, 0.23533043265342712, 0.8683659434318542, 0.09883788228034973, 0.1382991373538971, -0.6778755784034729, 0.027657978236675262, 1.25787353515625, 0.23283925652503967, 0.5706120133399963, -1.1032217741012573, 0.3038308918476105, -0.4606921672821045, 1.1630796194076538, -0.28212082386016846, -0.09914340823888779, 0.26015788316726685, -0.4496060013771057, -0.5808172821998596, -0.012743260711431503, -0.3292180895805359, -0.6890087723731995, 0.44904428720474243, -0.27477070689201355, 0.009512223303318024, 0.36407560110092163, 0.4150964915752411, 0.25050652027130127, 0.6190678477287292, 0.34980708360671997, 0.17960919439792633, 0.7418526411056519, -0.672336757183075, -0.9458577632904053, -0.8792104721069336, 0.7543104290962219, 0.5120687484741211, 0.14555498957633972, -0.3074926733970642, -1.12578284740448, -1.1045602560043335, -0.8993620872497559, 0.1774633377790451, -0.4233340322971344, 0.45754867792129517, 1.5112278461456299, 0.10629577934741974, -1.122694969177246, 0.2896147072315216, -0.10745663940906525, -0.3366316258907318, 0.08353070914745331, 0.29621878266334534, -0.005562214180827141, -0.4250977337360382, -1.9413352012634277, 0.7218847274780273, 0.5573318004608154, -0.49879953265190125, -0.8032868504524231, 0.4549829363822937, -1.0758082866668701, -0.6626302599906921, 0.4092223048210144, -0.3523057997226715, 1.3847510814666748, 0.49471190571784973, -0.7895382642745972, 0.32415536046028137, -0.3075469136238098, -0.7536942362785339, 0.5880778431892395, -0.03770709037780762, -1.0309793949127197, -0.5634630918502808, 0.15081441402435303, 0.7131131291389465, 0.2070368230342865, -0.4926477074623108, -0.7030685544013977, 0.5700410008430481, 0.22178047895431519, -0.33273330330848694, -0.04449019581079483, 0.9875974059104919, -0.20610907673835754, 0.38495275378227234, -0.2939419746398926, 0.48212143778800964, -0.6150547862052917, 0.4654686152935028, 0.0786610096693039, -1.0375940799713135, 1.112689733505249, 0.05856650322675705, 1.1766775846481323, -0.669441282749176, -0.8309705853462219, 0.1397102326154709, -0.19053034484386444, -0.08794356137514114, -0.7429594993591309, 0.5314319729804993, 0.08795885741710663, 0.386965274810791, -0.05803218111395836, -0.17232829332351685, -0.15832263231277466, 0.5016352534294128, -0.8505963683128357, -0.23324668407440186, -0.14278168976306915, 0.9827818870544434, -0.6662161946296692, -0.12539717555046082, 0.017661169171333313, -0.26105764508247375, -0.6400177478790283, 1.225083589553833, -0.5484490990638733, 0.27665749192237854, -0.49016276001930237, -0.5429444313049316, -0.21334156394004822, 0.3884066343307495, 0.17355191707611084, 0.12853342294692993, -0.6269844174385071, 0.2963680028915405, -0.8011735677719116, 1.175363302230835, 0.11171620339155197, 0.8070203065872192, 0.350932776927948, -0.6388830542564392, 0.18303529918193817, 0.7674985527992249, -0.6349437236785889, -0.25371816754341125, -0.020378202199935913, 0.6625059247016907, -0.0542365163564682, -0.30559006333351135, 0.5797643661499023, 0.8004093170166016, -0.5461747050285339, 0.6008954644203186, 0.04665319249033928, -0.5296385288238525, 0.9203852415084839, 0.5416223406791687, 0.33792752027511597, 0.34766465425491333, 0.421154648065567, -0.14696401357650757, 0.7342677712440491, -0.143846333026886, -0.08666880428791046, 0.6804199814796448, 0.05044495686888695, 0.3227534890174866, 0.07914561033248901, -1.2116270065307617, -0.49471625685691833, 0.5309436917304993, 0.7849302291870117, 1.0411311388015747, 0.34047600626945496, -0.3758772611618042, -0.7845610976219177, -0.34464555978775024, -0.3578437566757202, 0.6697207093238831, -0.438749223947525, 0.1549282968044281, -0.9801842570304871, -0.5235044956207275, 0.9414014220237732, 0.7818266153335571, 1.3168312311172485, -0.7315114140510559, -0.4152853786945343, -0.037227824330329895, 0.2351486086845398, -0.6662340760231018, -0.2766278386116028, -0.017334576696157455, -0.3681187331676483, -0.06838524341583252, 0.37092599272727966, -0.04396830499172211, -0.16082008183002472, -0.3501611649990082, 0.41852009296417236, -0.4338904023170471, -0.38569292426109314, 0.018863605335354805, 1.0068681240081787, -1.0603798627853394, -1.2190262079238892, -0.4048176407814026, 0.3375667631626129, -0.4976576864719391, 0.324906587600708, 0.6077834963798523, 0.4988052248954773, 0.5423671007156372, -0.010668174363672733, 0.2956655025482178, 0.1268264502286911, 0.15815292298793793, 0.5872625112533569, 0.050497401505708694, 0.16980032622814178, -0.6650451421737671, 1.3544071912765503, 0.35045522451400757, -0.7520888447761536, 0.07135357707738876, -0.19778645038604736, -0.17002399265766144, 0.458507239818573, -0.6361843347549438, -0.1359522044658661, -0.8449986577033997, 0.5471047163009644, -0.085274338722229, -0.8609880805015564, 0.5267313122749329, 0.27672410011291504, -0.07559574395418167, 0.5444261431694031, 0.751960813999176, 0.8861586451530457, -0.0103460643440485, 0.647499144077301, -0.4367276430130005, 0.5014263391494751, 0.21580132842063904, 0.18678158521652222, 0.05435626208782196, -0.12058687955141068, -0.4242576062679291, -0.2028369903564453, 0.06652632355690002, -0.4409298300743103, -0.25891372561454773, 0.15591241419315338, -0.9633966684341431, -0.28500935435295105, -0.42266565561294556, -1.0034745931625366, -0.49554169178009033, 0.077872633934021, -0.05414058640599251, -0.3820965886116028, -0.928615391254425, -0.7536973357200623, -0.8547875881195068, 0.11894573271274567, -0.6612599492073059, 0.03948421776294708, 0.02492232248187065, -0.31986474990844727, -0.24873635172843933, 0.14248014986515045, 0.04079171642661095, 0.8812934756278992, -0.5602756142616272, 0.9074480533599854, 0.07735900580883026, -0.2575422525405884, -0.5609081983566284, 0.35608595609664917, 0.20110520720481873, -0.42975983023643494, 0.033232204616069794, -0.3608238399028778, 0.38770025968551636, -0.39878523349761963, -0.48497989773750305, -0.21299931406974792, -0.037233758717775345, 0.5758916735649109, 0.3410535156726837, -0.7698430418968201, -0.59333735704422, 0.841882586479187, -0.13187193870544434, 0.4444204866886139, 0.22455264627933502, 0.9475811123847961, 0.5344370007514954, 0.15189647674560547, 0.23711290955543518, 0.5462307929992676, 0.5537896156311035, 0.10826645791530609, -0.22185678780078888, 0.009569797664880753, -0.36153343319892883, 0.7088696360588074, 0.7278979420661926, -0.35820794105529785, 0.16166678071022034, -1.1785255670547485, 0.5484211444854736, -1.7051265239715576, -0.9350816011428833, 0.48192840814590454, 0.5812640190124512, 0.02447189763188362, -0.06329772621393204, 0.0662272721529007, 0.18006883561611176, 0.9970577955245972, -0.40673625469207764, -0.27120330929756165, -0.5358347296714783, 0.2946127653121948, -0.212741881608963, 0.26723507046699524, 0.48305705189704895, -0.5305867791175842, 0.23659801483154297, 14.775389671325684, 1.0840684175491333, 0.20222844183444977, 0.6596940159797668, 0.33843183517456055, 0.9156836271286011, -0.2045951634645462, -0.2802371382713318, -1.362070083618164, -0.3629303276538849, 1.6305177211761475, -0.46891435980796814, 0.6292716264724731, 0.4178680181503296, 0.26176905632019043, 0.03669215738773346, -0.2684372365474701, 0.19264429807662964, 0.42493757605552673, -1.507772445678711, 0.7115063071250916, 0.571786642074585, 0.08582019805908203, 0.729467511177063, -0.10451214760541916, 0.9439229965209961, 0.8291195034980774, -0.2889969050884247, 1.0122735500335693, -0.23291988670825958, 1.034639596939087, -0.30058541893959045, 0.6164279580116272, 1.335605263710022, -0.9434057474136353, -0.6752484440803528, -0.8318915963172913, -1.3616875410079956, 0.39008376002311707, -0.3714478611946106, -0.32148003578186035, -0.6390824317932129, -0.5999857783317566, 0.09268859773874283, 0.48199698328971863, 0.3086065649986267, -0.7119500041007996, 0.4963574707508087, -0.3327861726284027, -0.2072337418794632, 0.04034336283802986, 0.40241867303848267, 0.30310553312301636, -0.49331134557724, 0.0744645819067955, 0.18770362436771393, 0.37636855244636536, 0.5525808930397034, -0.0990784540772438, -0.36413609981536865, -0.9344609379768372, -0.32075080275535583, -0.33607539534568787, 0.6682568788528442, 0.5962206125259399, 0.1470683217048645, -0.35043928027153015, -0.19412781298160553, 0.1906544715166092, -0.010804175399243832, -0.588537335395813, -0.3875737488269806, 0.5385947823524475, 0.062351830303668976, -0.22863899171352386, -0.04132717475295067, 0.012065637856721878, -0.7827084064483643, -0.819129228591919, -0.03894862160086632, 0.09655169397592545, -0.8328987956047058, -0.5624189376831055, 1.4020367860794067, 0.4247521162033081, -0.9184133410453796, 0.044980596750974655, -0.793755829334259, -0.5938917398452759, 0.12336175888776779, -1.451317310333252, -1.0290619134902954, 0.1537361890077591, 0.32914188504219055, -0.1611986607313156, -0.22263024747371674, 1.4499340057373047, -0.24728909134864807, -0.4039701521396637, -0.5591657757759094, -0.03434496372938156, 0.08669660985469818, -0.49324941635131836, -0.3550202548503876, 0.6532859206199646, 0.3572009801864624, -0.0034512600395828485, -0.11931853741407394, -0.05858268961310387, -0.034790001809597015, -0.5885193347930908, -0.07833213359117508, 0.6604820489883423, -1.2028555870056152, -0.011683132499456406, -1.476427435874939, -0.7608327269554138, 0.07510051876306534, 0.21618930995464325, -0.07544875144958496, -0.2572307586669922, -0.5949045419692993, 0.04362139105796814, 0.002915980527177453, -1.1261531114578247, 0.22340336441993713, 0.40408045053482056, -0.7229099869728088, -0.7528631687164307, 0.290975421667099, 0.12080296128988266, -0.7094742059707642, -0.01904907077550888, -0.47671088576316833, 0.0018116268329322338, 0.36847829818725586, 0.7681830525398254, -0.34459418058395386, 0.3449089527130127, 0.2508898675441742, -0.03362882882356644, -0.3526240885257721, -0.156657412648201, -1.026030421257019, 0.10958825051784515, -0.0008184235775843263, 0.841029703617096, -0.5250682234764099, 0.27456510066986084, 1.5718233585357666, 0.25703224539756775, 0.20869489014148712, -0.7105408906936646, -0.27501460909843445, -0.026083361357450485, -0.924476146697998, 0.2375449538230896, -0.7184711694717407, 0.11820252984762192, 0.07730673253536224, 0.14665277302265167, 0.6951757073402405, -0.2529849410057068, -0.4694017469882965, 0.7575041055679321, -0.3454008102416992, 0.4936056137084961, 0.18041351437568665, -0.2994307577610016, -1.057237982749939, 0.3355225920677185, -0.7720568776130676, 0.6865032911300659, -1.5901075601577759, -0.9136996269226074, -0.1010207086801529, 0.03548748418688774, 0.039267465472221375, 1.1300851106643677, -0.15864801406860352, -0.802812933921814, 0.07131429016590118, -0.4342789947986603, 0.4478384256362915, 0.7934549450874329, -0.45559102296829224, 0.05563830956816673, 0.05863961949944496, 0.18716619908809662, 0.818569004535675, 0.45184192061424255, -0.298749715089798, -1.008189082145691, -0.7165039777755737, 0.05996611341834068, -0.033880267292261124, -0.27546578645706177, -0.8348503112792969, 1.0057289600372314, -0.013811955228447914, -0.16469070315361023, 0.1536228209733963, 0.43740957975387573, -1.0860300064086914, -0.4000687301158905, 0.18562538921833038, -0.6374645233154297, -0.1602579951286316, 0.5930620431900024, -0.114524245262146, -0.7319075465202332, 0.6685478091239929, -0.3172209560871124, -1.1854338645935059, -1.0308215618133545, 0.018640344962477684, -1.524875283241272, -0.3082047998905182, 0.36478883028030396, -0.27416282892227173, -0.6727924346923828, -0.561915397644043, -0.06823596358299255, 0.6634790301322937, -0.6272103190422058, 0.7943766713142395, 0.38726818561553955, -0.9783799052238464, -0.05831940099596977, 0.8979010581970215, -0.12648025155067444, -0.2712792158126831, 0.14905788004398346, 0.23288936913013458, -0.2787477672100067, 0.7810240387916565, -0.14083723723888397, 0.7377244830131531, -0.5737061500549316, -0.08569259941577911, 0.22840933501720428, -0.0246382225304842, -0.6160426735877991, 0.6857849955558777, -0.2342110574245453, -0.7638843059539795, 0.33621272444725037, -0.8892158269882202, -1.306023120880127, -0.7894300818443298, 1.149335503578186, 0.012917369604110718, -0.8684630393981934, -0.5320385694503784, -0.28584596514701843, 0.3074886202812195, 0.014151142910122871, -0.7758491039276123, 0.28305572271347046, -0.47756335139274597, -0.3156569004058838, 0.6690499782562256, -0.2906549274921417, -0.43592044711112976, -0.6257862448692322, 0.32627788186073303, -0.3789539635181427, -0.35974910855293274, -0.06039244681596756, -0.38360217213630676, 0.04947062209248543, 0.8935839533805847, 0.6008971333503723, 0.26700979471206665, -0.23515646159648895, -0.13049432635307312, 0.41864752769470215, 0.8660315275192261, 0.8328414559364319, -0.4216449558734894, -1.1498850584030151, 1.168940782546997, 1.585265874862671, -0.8694178462028503, 0.10222528129816055, -0.415670782327652, -0.9086129069328308, 1.1516079902648926, 0.6295753121376038, -0.3148101270198822, 0.497395783662796, 0.08278253674507141, 0.10471166670322418, 0.3884497582912445, -1.2205692529678345, -0.16666269302368164, 0.20941054821014404, 1.127993106842041, 0.3235938847064972, 0.4075041711330414, -0.16715660691261292, 0.783305823802948, 0.23655737936496735, 1.1456619501113892, 1.2962262630462646, 0.5624228715896606, -0.6517048478126526, -0.2102874368429184, -0.003735418664291501, 0.4673011004924774, -0.23461617529392242, 0.16354158520698547, -0.016931721940636635, 1.4085676670074463, 0.4869093894958496, 0.5719776153564453, 0.5950413942337036, -0.1854299157857895, 0.6466110944747925, 0.4539395272731781, 0.03130410611629486, -0.6702202558517456, 0.2589106857776642, -0.09401554614305496, 0.05143857002258301, -0.05674883350729942, -0.3964768648147583, -0.29452767968177795, -0.9057313203811646, 0.01689920574426651, 0.05261373892426491, 0.5252284407615662, 0.3418520987033844, 0.8381311297416687, 0.5701120495796204, -0.3588615953922272, -1.1221994161605835, -0.4194242060184479, -0.31069937348365784, -0.6785734295845032, 0.014600448310375214, -0.9826384782791138, -0.326202929019928, -0.7900858521461487, -0.19010218977928162, -0.27168452739715576]}, "authors": [{"authorId": "2157142843", "name": "Yu Huang"}, {"authorId": "2267495438", "name": "Yue Chen"}, {"authorId": "2267733355", "name": "Zhu Li"}], "references": [{"paperId": "0e4e899e8d4de9bd8d0ea43e32afd0baca7b6bf0", "title": "OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving"}, {"paperId": "3039e5c8bd6147b6ee08f0f50d52047cc3be2372", "title": "ADriver-I: A General World Model for Autonomous Driving"}, {"paperId": "cd1c95ee95fd7026bad1e115f26e4119678fdd83", "title": "MUVO: A Multimodal Generative World Model for Autonomous Driving with Geometric Representations"}, {"paperId": "357e182a38219625dd37cba526befe5f8429aa4b", "title": "A Language Agent for Autonomous Driving"}, {"paperId": "5b7c820dec29f38438b89bc6d483a63de0084402", "title": "Copilot4D: Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion"}, {"paperId": "84d99893ee24fc825e359598d44d602c45c4865e", "title": "LLM4Drive: A Survey of Large Language Models for Autonomous Driving"}, {"paperId": "a9c4efebbeda0c38601eee232a07c5c307582140", "title": "Gen2Sim: Scaling up Robot Learning in Simulation with Generative Models"}, {"paperId": "84a2719338a1f1db73aaa7b5bd61ca507c63da8e", "title": "Drive Anywhere: Generalizable End-to-end Autonomous Driving with Multi-modal Foundation Models"}, {"paperId": "fc0794e537be6dafb0195ff4a583d34180ed1023", "title": "OpenAnnotate3D: Open-Vocabulary Auto-Labeling System for Multi-modal 3D Data"}, {"paperId": "28bfafdf04642a74487970e658506c79c91978b1", "title": "UE4-NeRF: Neural Radiance Field for Real-Time Rendering of Large-Scale Scene"}, {"paperId": "ad4beeecbdfc7dd238eb55e2b19113f62096d95b", "title": "Habitat 3.0: A Co-Habitat for Humans, Avatars and Robots"}, {"paperId": "c96e5681566e34dfbd2a5e379f075d5d3a631230", "title": "BEVGPT: Generative Pre-trained Large Model for Autonomous Driving Prediction, Decision-Making, and Planning"}, {"paperId": "68e0e789b5147b1e7d028c7a825650075f4e26bf", "title": "PaLI-3 Vision Language Models: Smaller, Faster, Stronger"}, {"paperId": "06545fc3aa68622ecdadcf93524f5343c652400a", "title": "EasyGen: Easing Multimodal Generation with BiDiffuser and LLMs"}, {"paperId": "ef7d31137ef06c5be8c2824ecc5af6ce3358cc8f", "title": "Open X-Embodiment: Robotic Learning Datasets and RT-X Models"}, {"paperId": "9930206a9faa5e58bf8e59389c089400fc6eb6e6", "title": "UniPAD: A Universal Pre-training Paradigm for Autonomous Driving"}, {"paperId": "1ce23cfe7053af2e12c437317bf5d91d5f86b7aa", "title": "PonderV2: Pave the Way for 3D Foundation Model with A Universal Pre-training Paradigm"}, {"paperId": "458111ac5a0f73bb35a2acf55298268be25ccfa2", "title": "Ferret: Refer and Ground Anything Anywhere at Any Granularity"}, {"paperId": "7ee9301f239556896403e00404db3cfef3b60903", "title": "Learn From Model Beyond Fine-Tuning: A Survey"}, {"paperId": "c465e2c612c9bb15f3efcb554e35052b6374d012", "title": "DrivingDiffusion: Layout-Guided multi-view driving scene video generation with latent diffusion model"}, {"paperId": "2835b5dba741b4e48c2f578bbf7f8c6eed259832", "title": "Uni3D: Exploring Unified 3D Representation at Scale"}, {"paperId": "985f0c89c5a607742ec43c1fdc2cbfe54541cbad", "title": "Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation"}, {"paperId": "712ac6589e5eefe480e80f16050810a28a4e3f50", "title": "MagicDrive: Street View Generation with Diverse 3D Geometry Control"}, {"paperId": "19933dd9e03058e686ef412262eef7696cce3e8f", "title": "LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving"}, {"paperId": "f01ff5acf9e086030c01beda6f433f99013ebbd4", "title": "Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving"}, {"paperId": "77693ca00a8ef775af96b5c450aa0afdb0e10a51", "title": "Talk2BEV: Language-enhanced Bird's-eye View Maps for Autonomous Driving"}, {"paperId": "958ed4830ae80a189ecb9b93ab75a6ce2e3926fc", "title": "GPT-Driver: Learning to Drive with GPT"}, {"paperId": "ccd6f8b6544f112de632e49bfbe592a0a654537d", "title": "DriveGPT4: Interpretable End-to-end Autonomous Driving via Large Language Model"}, {"paperId": "54814744b42b06c855c97b23de1366e0bcbe775a", "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)"}, {"paperId": "98478ac589e5b40a20630ff54bb4eec4ab4c5f6b", "title": "GAIA-1: A Generative World Model for Autonomous Driving"}, {"paperId": "3cbfe152220de84ecf8059fa50c47587a3134c86", "title": "DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models"}, {"paperId": "861593f632f98aa597802b95056a05b37e8955f8", "title": "MatrixCity: A Large-scale City Dataset for City-scale Neural Rendering and Beyond"}, {"paperId": "f2f9c02a7eb484dd7b7ac46892856e3f278eed77", "title": "AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model"}, {"paperId": "f42f61a547c5996be6aee175145b0d74e6324dff", "title": "Navigate through Enigmatic Labyrinth A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future"}, {"paperId": "baebac51365ef920645a445b192ddf3a1a2246fa", "title": "DriveSceneGen: Generating Diverse and Realistic Driving Scenarios From Scratch"}, {"paperId": "749d59f887c8ac83fd4f5178465e8b03e463358c", "title": "Large Language Model Alignment: A Survey"}, {"paperId": "afdf04289e384e9750cc9a3dc901c5606738804f", "title": "Unsupervised 3D Perception with 2D Vision-Language Distillation for Autonomous Driving"}, {"paperId": "482665786ce1956fb9ea4b694d2d8e8cf92276fa", "title": "Drive as You Speak: Enabling Human-Like Interaction with Large Language Models in Autonomous Vehicles"}, {"paperId": "af3ab5da98e0807784b57e321ed887a3666a8ab6", "title": "Multimodal Foundation Models: From Specialists to General-Purpose Assistants"}, {"paperId": "0ef8bbccbfab7e6d9c8bd09bcadfe9c5bbbff512", "title": "DriveDreamer: Towards Real-world-driven World Models for Autonomous Driving"}, {"paperId": "0c72450890a54b68d63baa99376131fda8f06cf9", "title": "The Rise and Potential of Large Language Model Based Agents: A Survey"}, {"paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05", "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"}, {"paperId": "7679dc8534cb1dd65c63c50b38f56386228d32d1", "title": "Can you text what is happening? Integrating pre-trained language encoders into trajectory prediction models for autonomous driving"}, {"paperId": "16ed5f612b66cb7d91e534dd7126b69756f45c34", "title": "HiLM-D: Towards High-Resolution Understanding in Multimodal Large Language Models for Autonomous Driving"}, {"paperId": "fa75a55760e6ea49b39b83cb85c99a22e1088254", "title": "NExT-GPT: Any-to-Any Multimodal LLM"}, {"paperId": "29d262a66c57a9f819fe0325f184b91d48a4c2a4", "title": "Language Prompt for Autonomous Driving"}, {"paperId": "daa6a6b2c495d002d72075c6203c98061d1e35f9", "title": "Adv3D: Generating 3D Adversarial Examples in Driving Scenarios with NeRF"}, {"paperId": "d00735241af700d21762d2f3ca00d920241a15a4", "title": "Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models"}, {"paperId": "26089bdfdbca1e6eaaceca71e3116b715bec6d47", "title": "Explainability for Large Language Models: A Survey"}, {"paperId": "58c78f1cdf6b52c37f3327cea0a328a6f32b0d17", "title": "AI-Generated Content (AIGC) for Various Data Modalities: A Survey"}, {"paperId": "28c6ac721f54544162865f41c5692e70d61bccab", "title": "A Survey on Large Language Model based Autonomous Agents"}, {"paperId": "f0950a3f27c0fefffba60ae1c9a8ee360d5eb55f", "title": "Instruction Tuning for Large Language Models: A Survey"}, {"paperId": "fca92fe287c44c9ec79ca1f2762b0bf2e5e8df2b", "title": "Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models"}, {"paperId": "aade40af0d85b0b4fe15c97f6222d5c2e4d6d9b3", "title": "Graph of Thoughts: Solving Elaborate Problems with Large Language Models"}, {"paperId": "119ff6dc18dd4c7920f2b90ec0558a0aee0316d3", "title": "MonoNeRD: NeRF-like Representations for Monocular 3D Object Detection"}, {"paperId": "338d8f3b199abcebc85f34016b0162ab3a9d5310", "title": "A Survey on Model Compression for Large Language Models"}, {"paperId": "e2e59f434940d03300ee0fac14d2c65ed0e2ae15", "title": "UniWorld: Autonomous Driving Pre-training via World Models"}, {"paperId": "f05bae259c29474500201cad207fd6a2f7a1fb21", "title": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving"}, {"paperId": "659a12d71d8709c132ccd9ccd235f0024cae0239", "title": "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"}, {"paperId": "0bfc804e31eecfd77f45e4ee7f4d629fffdcd628", "title": "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs"}, {"paperId": "a5cddee937d7d2f005e781e453833cd64d3cf343", "title": "Learning to Model the World with Language"}, {"paperId": "ed1c04bd73d3b3c25d13d67c3d96f6c54ab3f35d", "title": "MTD-GPT: A Multi-Task Decision-Making GPT Model for Autonomous Driving at Unsignalized Intersections"}, {"paperId": "38939304bb760473141c2aca0305e44fbe04e6e8", "title": "RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control"}, {"paperId": "8fff44ec37eba77127a0d88525fba6be17fb3cf6", "title": "MARS: An Instance-aware, Modular and Realistic Simulator for Autonomous Driving"}, {"paperId": "4daaecd6230523ff346cacbea102dfde922bab0d", "title": "NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection"}, {"paperId": "96a69d1026503262d8150bd9d958b5930fa5cdbb", "title": "Points-to-3D: Bridging the Gap between Sparse Points and Shape-Controllable Text-to-3D Generation"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "11bca2cafe89e14dc733504f97e2489de697ceab", "title": "Drive Like a Human: Rethinking Autonomous Driving with Large Language Models"}, {"paperId": "6eddfde78d5f6b10206f00675102fe3ddef8ff89", "title": "Structured World Models from Human Videos"}, {"paperId": "888728745dbb769e29ed475d4f7661eebe1a71cf", "title": "A Survey on Evaluation of Large Language Models"}, {"paperId": "528ca770243af9baacc9e59a6fc6588d8649dfe5", "title": "An Overview about Emerging Technologies of Autonomous Driving"}, {"paperId": "5a5894843bacf3ddfa57794a1ea07bca005c3216", "title": "Edit-DiffNeRF: Editing 3D Neural Radiance Fields using 2D Diffusion Model"}, {"paperId": "c6639aa87101f76c11fcfb4f69193a55363050d3", "title": "Segment Any Point Cloud Sequences by Distilling Vision Foundation Models"}, {"paperId": "9120da58459f3fca99f94ca343467653f5275a40", "title": "Language-Guided Traffic Simulation via Scene-Level Diffusion"}, {"paperId": "d8f504a57740244308c5b8f7ae617563e2ba2093", "title": "StreetSurf: Extending Multi-view Implicit Surface Reconstruction to Street Views"}, {"paperId": "f2d39bbbf30f32325b06a9134af218daf36ad6f1", "title": "GeoDiffusion: Text-Prompted Geometric Control for Object Detection Data Generation"}, {"paperId": "c77ca4e4e73654c270a70931b3e3091ea377ccd1", "title": "BeyondPixels: A Comprehensive Review of the Evolution of Neural Radiance Fields"}, {"paperId": "25c9502575d3c328a9e2f20580c98acb877ea2c5", "title": "AD-PT: Autonomous Driving Pre-Training with Large-scale Point Cloud Dataset"}, {"paperId": "330c2304c1f64843b885a7b8eb698d37c1adc40b", "title": "UniSim: A Neural Closed-Loop Sensor Simulator"}, {"paperId": "3099d6f4965b4d73aa1e2b2880522ec89ed2dc0a", "title": "PaLI-X: On Scaling up a Multilingual Vision and Language Model"}, {"paperId": "52d901c142f7aa949d7acb8ccedbcb500d346256", "title": "Generating Driving Scenes with Diffusion"}, {"paperId": "c5e9fd131cde68c218d0ea69cd617a67c7f35d42", "title": "ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation"}, {"paperId": "2a9f1e923ccd7aa8f9411471275bef251a1466dd", "title": "Language-Guided 3D Object Detection in Point Cloud for Autonomous Driving"}, {"paperId": "00cb69a9f280317d1c59ac5827551ee9b10642b8", "title": "EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought"}, {"paperId": "32ac52069e562d4f900afee70bdca63f53461481", "title": "QLoRA: Efficient Finetuning of Quantized LLMs"}, {"paperId": "5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200", "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints"}, {"paperId": "213a14d426acebf2f04709eea722a887a1f5f051", "title": "Text2NeRF: Text-Driven 3D Scene Generation with Neural Radiance Fields"}, {"paperId": "f6fdac9b5e771394d22bfd5fbaf8147a52b6e792", "title": "UniControl: A Unified Diffusion Model for Controllable Visual Generation In the Wild"}, {"paperId": "432df08dc388bb08ab31847328b62b4632e5b7b7", "title": "OpenShape: Scaling Up 3D Shape Representation Towards Open-World Understanding"}, {"paperId": "2f3822eb380b5e753a6d579f31dfc3ec4c4a0820", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models"}, {"paperId": "4b203ee52e27cbf27d210dd671951150729a8259", "title": "ULIP-2: Towards Scalable Multimodal Pre-training for 3D Understanding"}, {"paperId": "8bd6a2a89503be083176f2cc26fabedb79238cbd", "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"}, {"paperId": "7dc6da87eaa6f830354feb2db14023cab8678c91", "title": "ImageBind One Embedding Space to Bind Them All"}, {"paperId": "906451f8cfc2adb967f2c81e2c000c536016ceb6", "title": "NeRF-LiDAR: Generating Realistic LiDAR Point Clouds with Neural Radiance Fields"}, {"paperId": "f5a0c57f90c6abe31482e9f320ccac5ee789b135", "title": "Align Your Latents: High-Resolution Video Synthesis with Latent Diffusion Models"}, {"paperId": "5a9cb1b3dc4655218b3deeaf4a2417a9a8cd0891", "title": "DINOv2: Learning Robust Visual Features without Supervision"}, {"paperId": "0819c1e60c13b9797f937282d06b54d252d9d6ec", "title": "Segment Everything Everywhere All at Once"}, {"paperId": "13581a46d32822e44cbeb1acdba4a59cef2b2ec1", "title": "On Efficient Training of Large-Scale Deep Learning Models: A Literature Review"}, {"paperId": "410469645334b02da4b8bd206f5ffe76c71a71cb", "title": "Lift3D: Synthesize 3D Training Data by Lifting 2D GAN to 3D Generative Radiance Field"}, {"paperId": "07faa238c8fad8e8213260dae37dc8a9114971c7", "title": "Neural Fields Meet Explicit Geometric Representations for Inverse Rendering of Urban Scenes"}, {"paperId": "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d", "title": "A Survey of Large Language Models"}, {"paperId": "6007263dd3d14373be5f84fb6ccb0be3f7fce903", "title": "Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning"}, {"paperId": "2643f90ed0b3e3ee08e7c30a8775465a5d217a47", "title": "SUDS: Scalable Urban Dynamic Scenes"}, {"paperId": "d84616f108ccbd958735fef7622e58d148b32139", "title": "Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior"}, {"paperId": "0cbb518c364067200476a51e5ce7476a4f582770", "title": "Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation"}, {"paperId": "fc64ff39e853791704f6b72eb824f4e86306fee1", "title": "Compositional 3D Scene Generation using Locally Conditioned Diffusion"}, {"paperId": "1b492746ee3a304a13950cad1a59861b9ee44645", "title": "A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?"}, {"paperId": "5356c3dac654854a0842753bcc2e3433dc4a2afd", "title": "Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation"}, {"paperId": "35ccd924de9e8483bdcf144cbf2edf09be157b7e", "title": "Text-to-image Diffusion Models in Generative AI: A Survey"}, {"paperId": "2144681c6efbee8b3d2025bb14ab3225471cbf80", "title": "ConBaT: Control Barrier Transformer for Safe Policy Learning"}, {"paperId": "2ebd5df74980a37370b0bcdf16deff958289c041", "title": "Foundation Models for Decision Making: Problems, Methods, and Opportunities"}, {"paperId": "564c10232f544ed46d7dd6d324278598662b4c44", "title": "TrafficBots: Towards World Models for Autonomous Driving Simulation and Motion Prediction"}, {"paperId": "38fe8f324d2162e63a967a9ac6648974fc4c66f3", "title": "PaLM-E: An Embodied Multimodal Language Model"}, {"paperId": "380578ed28081a70b877be7e8a3c4d3a9997b041", "title": "S-NeRF: Neural Radiance Fields for Street Views"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "ce89c70c9678b475247cae57b363674d97410fe0", "title": "A Joint Modeling of Vision-Language-Action for Target-oriented Grasping in Clutter"}, {"paperId": "84cce9b8aea35e4fa38eef63da439573f21c0728", "title": "RealFusion 360\u00b0 Reconstruction of Any Object from a Single Image"}, {"paperId": "58842cdca3ea68f7b9e638b288fc247a6f26dafc", "title": "T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models"}, {"paperId": "efbe97d20c4ffe356e8826c01dc550bacc405add", "title": "Adding Conditional Control to Text-to-Image Diffusion Models"}, {"paperId": "61e721334296ebfbbf6443b5ed9eb8c83b708c95", "title": "Scaling Vision Transformers to 22 Billion Parameters"}, {"paperId": "53d128ea815bcc0526856eb5a9c42cc977cb36a7", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools"}, {"paperId": "ccb1ccc4deacc4fb18000f0e1ce24329548963ae", "title": "Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents"}, {"paperId": "6d7534a41fc933f4f6a99e039f585dc57a370a29", "title": "ADAPT: Action-aware Driving Caption Transformer"}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "0c17326565266c40a02b230fac3b405a4d3220b9", "title": "CLIP2Scene: Towards Label-efficient 3D Scene Understanding by CLIP"}, {"paperId": "28fa9d31301e3338c7d39430c29d7feda6f67e12", "title": "Systems for Parallel and Distributed Large-Model Deep Learning Training"}, {"paperId": "aa5645b4896acb72aa4893d174af765d962aa708", "title": "Policy Pre-training for Autonomous Driving via Self-supervised Geometric Modeling"}, {"paperId": "c10e201728cbc639384abf598beeed5b01378740", "title": "Ponder: Point Cloud Pre-training via Neural Rendering"}, {"paperId": "1b8a734dd28a9d766a5d3dbc0871e76b6a452b65", "title": "Point-E: A System for Generating 3D Point Clouds from Complex Prompts"}, {"paperId": "3936fd3c6187f606c6e4e2e20b196dbc41cc4654", "title": "Constitutional AI: Harmlessness from AI Feedback"}, {"paperId": "791afcb97eb31f25d0899c3e6de761168909c8e4", "title": "LidarCLIP or: How I Learned to Talk to Point Clouds"}, {"paperId": "fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d", "title": "RT-1: Robotics Transformer for Real-World Control at Scale"}, {"paperId": "fe34137e5cc07235eae65ce53a54cd226b9f8b23", "title": "MAGVIT: Masked Generative Video Transformer"}, {"paperId": "e3f5a9251529f34bc15b89e3294e576efbc0af4c", "title": "NeRDi: Single-View NeRF Synthesis with Language-Guided Diffusion as General Image Priors"}, {"paperId": "fc011ed5ee986332523a62d2783adee1179dc1ed", "title": "Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation"}, {"paperId": "b4ece600c6dadd41b0b38d8359ce8e5b544305a9", "title": "SparseFusion: Distilling View-Conditioned Diffusion for 3D Reconstruction"}, {"paperId": "774408d8848b129d93fb67548ec6571d99b31a2d", "title": "OpenScene: 3D Scene Understanding with Open Vocabularies"}, {"paperId": "bdf4af8311637c681904e71cf50f96fd0026f578", "title": "Magic3D: High-Resolution Text-to-3D Content Creation"}, {"paperId": "793939b83e10903f58d8edbb7534963df627a1fe", "title": "Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures"}, {"paperId": "f33d33aa070c738d481e3968092bc36d4f07d73b", "title": "RITA: Boost Driving Simulators with Realistic Interactive Traffic Flow"}, {"paperId": "247fbf266e70e196d983f53e7b4990b9548b0fc5", "title": "Guided Conditional Diffusion for Controllable Traffic Simulation"}, {"paperId": "9793e6f3883e5ce5dbb92c0b940df06021ece1ae", "title": "LION: Latent Point Diffusion Models for 3D Shape Generation"}, {"paperId": "99832586d55f540f603637e458a292406a0ed75d", "title": "ReAct: Synergizing Reasoning and Acting in Language Models"}, {"paperId": "1d26c947406173145a4665dd7ab255e03494ea28", "title": "GLM-130B: An Open Bilingual Pre-trained Model"}, {"paperId": "4c94d04afa4309ec2f06bdd0fe3781f91461b362", "title": "DreamFusion: Text-to-3D using 2D Diffusion"}, {"paperId": "28630034bb29760df01ab033b743e30b37f336ae", "title": "PaLI: A Jointly-Scaled Multilingual Language-Image Model"}, {"paperId": "e342165a614588878ad0f4bc9bacf3905df34d08", "title": "Diffusion Models: A Comprehensive Survey of Methods and Applications"}, {"paperId": "cdf54c147434c83a4a380916b6c1279b0ca19fc2", "title": "LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "9695824d7a01fad57ba9c01d7d76a519d78d65e7", "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"}, {"paperId": "982236b056edc17962853c7344e5cf43513b474c", "title": "READ: Large-Scale Neural Scene Rendering for Autonomous Driving"}, {"paperId": "7cdaa08890895e1ad92afb5fad429690ad7b1dac", "title": "Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning"}, {"paperId": "d4a265b6008058506a143177422fe192e4fe2090", "title": "Panoptic Neural Fields: A Semantic Object-Aware Neural Scene Representation"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "c57293882b2561e1ba03017902df9fc2f289dea2", "title": "Hierarchical Text-Conditional Image Generation with CLIP Latents"}, {"paperId": "084f52f037074c4ef58e8c2a0065a1b1d98a851b", "title": "SinNeRF: Training Neural Radiance Fields on Complex Scenes from a Single Image"}, {"paperId": "aa8c61c9f6bb21c57e49611ccb995cfda1b53b10", "title": "Exploring Visual Prompts for Adapting Large-Scale Models"}, {"paperId": "e9b595ec1d0ff14753626601c832c42fc09a3dd9", "title": "Panoptic NeRF: 3D-to-2D Label Transfer for Panoptic Urban Scene Segmentation"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "d7d1bbade9453f0348fac8a5c60d131528b87fcf", "title": "Block-NeRF: Scalable Large Scene Neural View Synthesis"}, {"paperId": "e6770e3f5e74210c6863aaeed527ac4c1da419d7", "title": "A Survey on Retrieval-Augmented Text Generation"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "80d44d92f074683ba8d4c86e1f18f0bc1a29abc4", "title": "Mega-NeRF: Scalable Construction of Large-Scale NeRFs for Virtual Fly- Throughs"}, {"paperId": "7002ae048e4b8c9133a55428441e8066070995cb", "title": "GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models"}, {"paperId": "26b1c7ba30879b54c42eef91ee58fa906d7e26cb", "title": "Dense Depth Priors for Neural Radiance Fields from Sparse Input Views"}, {"paperId": "f3ce9ba3fcec362b70263a7ed63d9404975496a0", "title": "PointCLIP: Point Cloud Understanding by CLIP"}, {"paperId": "03e1c3b5fdad9b21bbed3d13af7e8d6c73cbcfa6", "title": "Zero-Shot Text-Guided Object Generation with Dream Fields"}, {"paperId": "102d29870ba101004afce311823df85a9f304be7", "title": "Urban Radiance Fields"}, {"paperId": "4e1e3efa9218335c1b40573c5c88b41dc49c0da1", "title": "NeSF: Neural Semantic Fields for Generalizable Semantic Segmentation of 3D Scenes"}, {"paperId": "ec90ffa017a2cc6a51342509ce42b81b478aefb3", "title": "Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields"}, {"paperId": "ee8984a6712791d4e0f2c776dad8119a3b893dd9", "title": "Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training"}, {"paperId": "f3a332ff1b73acda482e5d83696b2c701f487819", "title": "P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"}, {"paperId": "19b3b074d38b250d024920732ae51a8ffa0996dd", "title": "Pix2seq: A Language Modeling Framework for Object Detection"}, {"paperId": "8bdfd48579130b50112c03170904d803aafe6ba9", "title": "Learning Object-Compositional Neural Radiance Field for Editable Scene Rendering"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"}, {"paperId": "988952b0e737c8ab9b6c1fbd6d54db86e299d270", "title": "Depth-supervised NeRF: Fewer Views and Faster Training for Free"}, {"paperId": "4aa88c1406414cda3ce9cf76c8af0abaa8391760", "title": "Habitat 2.0: Training Home Assistants to Rearrange their Habitat"}, {"paperId": "cf5647cb2613f5f697729eab567383006dcd4913", "title": "NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction"}, {"paperId": "339b2b711fb5b228d097b03ebc3e62a521779235", "title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "72dd63d67588a42fc817bbb8d655b397f67425df", "title": "ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep learning"}, {"paperId": "be05b97c1a221b12640bac66cf4b322e3a81ca86", "title": "In-Place Scene Labelling and Understanding with Implicit Scene Representation"}, {"paperId": "169971b60749264cbbe2b577dc4d2ad23ca4f46c", "title": "MVSNeRF: Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo"}, {"paperId": "c041aaed581616e122e790dd2769337216df3d8d", "title": "KiloNeRF: Speeding up Neural Radiance Fields with Thousands of Tiny MLPs"}, {"paperId": "21336e57dc2ab9ae2171a0f6c35f7d1aba584796", "title": "Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields"}, {"paperId": "c32fd8ea1b3f2df410410fb18d569dede102c53a", "title": "Diffusion Probabilistic Models for 3D Point Cloud Generation"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "7cbc3dd0280b8c4551ac934af42dc227d43754f7", "title": "IBRNet: Learning Multi-View Image-Based Rendering"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "12b71736392209b4292471b7da0aed71ba2aa545", "title": "ZeRO-Offload: Democratizing Billion-Scale Model Training"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "4365f51fc270c55005adb794002685078a6fca1d", "title": "pixelNeRF: Neural Radiance Fields from One or Few Images"}, {"paperId": "633e2fbfc0b21e959a244100937c5853afca4853", "title": "Score-Based Generative Modeling through Stochastic Differential Equations"}, {"paperId": "82c05a83e56fa6ad089ba7d4aad2bec85b9b4edf", "title": "DeRF: Decomposed Radiance Fields"}, {"paperId": "fb8a1dd5d3bc0395b8ceb7ee73475a10e39b52fe", "title": "Neural Scene Graphs for Dynamic Scenes"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "5b0ea2c92ee16fa2f5a3dbc9315cd5c1e4ec1d88", "title": "NeRF++: Analyzing and Improving Neural Radiance Fields"}, {"paperId": "691eddbfaebbc71f6a12d3c99d5c155042459434", "title": "NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections"}, {"paperId": "5a160c901683fc48844ff343412aeb65da9391f3", "title": "Autonomous Driving with Deep Learning: A Survey of State-of-Art Technologies"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "428b663772dba998f5dc6a24488fff1858a0899f", "title": "NeRF"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "dc52b09089704ebd6f471177474bc29741c50023", "title": "Fast Transformer Decoding: One Write-Head is All You Need"}, {"paperId": "c8b041226ef3231d87297ac546bd1c2fd82b35ca", "title": "Talk to the Vehicle: Language Conditioned Autonomous Navigation of Self Driving Cars"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3", "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "ecf2a5496c765c8a0133c45952e82e3756961a11", "title": "Talk2Car: Taking Control of Your Self-Driving Car"}, {"paperId": "965359b3008ab50dd04e171551220ec0e7f83aba", "title": "Generative Modeling by Estimating Gradients of the Data Distribution"}, {"paperId": "d9f1f536c67e650992ec4afd66166740f860c99b", "title": "A Survey of Autonomous Driving: Common Practices and Emerging Technologies"}, {"paperId": "b4a35e548de27b6924e5f2ee41d37238a5c4a1d5", "title": "Habitat: A Platform for Embodied AI Research"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "bd79a394b3eb055a0c73a34f3428704ca6404cbd", "title": "Autonomous Driving"}, {"paperId": "bc6dff14a130c57a91d5a21339c23471faf1d46f", "title": "Et al"}, {"paperId": "795dcc714d0c53d718ba0e0cce5fe4f930186a3e", "title": "Stability"}, {"paperId": "825298ea1933f01f1cfbff0c5e9bca4c60fdb5cd", "title": "SurrealDriver: Designing Generative Driver Agent Simulation Framework in Urban Contexts based on Large Language Model"}, {"paperId": "5ef82a8c8aa50f99285f2143b57ca4e82da1af80", "title": "Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning"}, {"paperId": "1250676d646a9b48cf3bab66f13dc3c628ff68af", "title": "3D Open-vocabulary Segmentation with Foundation Models"}, {"paperId": "013719cdcc1cbf9861a661210d981a4f8bf24268", "title": "Vision Language Models in Autonomous Driving and Intelligent Transportation Systems"}, {"paperId": "3e02594b765fdc81342589dc524f8290c537f3c7", "title": "D2NeRF: Self-Supervised Decoupling of Dynamic and Static Objects from a Monocular Video"}, {"paperId": "cd23c49803ede0f71354d2ada153e0a9f76fa559", "title": "NeRF: Neural Radiance Field in 3D Vision, A Comprehensive Review"}, {"paperId": "5755f5ed765dd6295f6780dc5b2e3a1d32a1aa1c", "title": "ULIP: Learning Unified Representation of Language, Image and Point Cloud for 3D Understanding"}, {"paperId": "dccd764ec820c13369e91c53890dfc8cd0334355", "title": "PointCLIP V2: Adapting CLIP for Powerful 3D Open-world Learning"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": null, "title": "Stereo Radiance Fields: Learning View Synthesis for Sparse Views of Novel Scenes (SRF)"}, {"paperId": null, "title": "GPT Understands Too (P-tuning)"}, {"paperId": null, "title": "Denoising Diffusion Probabilistic Models (DDPM)"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "0c0a778e6fdf7e36b1750c533dcc916f86608607", "title": "A Survey on Context Learning"}, {"paperId": null, "title": "Attention is All You Need (Transformer)"}, {"paperId": "cfee1826dd4743eab44c6e27a0cc5970effa4d80", "title": "Improving Image Generation with Better Captions"}, {"paperId": null, "title": "Large Language Models and Knowledge Graphs: Opportunities and Challenges (Overview)"}, {"paperId": null, "title": "Training Compute-Optimal Large Language Model (scaling law)"}, {"paperId": null, "title": "A Generalist Agent (GATO)"}, {"paperId": null, "title": "Visual Instruction Tuning(LLaVA)"}, {"paperId": null, "title": "DriveLM: Drive on language"}, {"paperId": null, "title": "2023. GPT-4 Technical report"}, {"paperId": null, "title": "Segment anything (SAM)"}, {"paperId": null, "title": "Generating Conditional 3D Implicit Functions"}, {"paperId": null, "title": "Scaling Language Modeling with Pathways"}, {"paperId": null, "title": "Tool Learning with Foundation Models (review)"}, {"paperId": null, "title": "IEEE) Kansas city"}, {"paperId": null, "title": "---Vision Model, Visual Language Model, Multimodal Model and Embodied AI"}]}