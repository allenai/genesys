{"paperId": "23c265ba884b92ecbd9d18641078d964697e4590", "abstract": "Pretrained language models (PLMs) have demonstrated remarkable performance in various natural language processing tasks: Unidirectional PLMs (e.g., GPT) are well known for their superior text generation capabilities; bidirectional PLMs (e.g., BERT) have been the prominent choice for natural language understanding (NLU) tasks. While both types of models have achieved promising few-shot learning performance, their potential for zero-shot learning has been underexplored. In this paper, we present a simple approach that uses both types of PLMs for fully zero-shot learning of NLU tasks without requiring any task-specific data: A unidirectional PLM generates class-conditioned texts guided by prompts, which are used as the training data for fine-tuning a bidirectional PLM. With quality training data selected based on the generation probability and regularization techniques (label smoothing and temporal ensembling) applied to the fine-tuning stage for better generalization and stability, our approach demonstrates strong performance across seven classification tasks of the GLUE benchmark (e.g., 72.3/73.8 on MNLI-m/mm and 92.8 on SST-2), significantly outperforming zero-shot prompting methods and achieving even comparable results to strong few-shot approaches using 32 training samples per class.", "venue": "Neural Information Processing Systems", "year": 2022, "citationCount": 158, "influentialCitationCount": 13, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper presents a simple approach that uses both types of PLMs for fully zero-shot learning of NLU tasks without requiring any task-specific data: a unidirectional PLM generates class-conditioned texts guided by prompts, which are used as the training data for fine-tuning a bidirectionalPLM."}, "embedding": {"model": "specter_v2", "vector": [0.5510612726211548, 0.9391324520111084, -0.25120699405670166, -0.09913548827171326, -0.20517419278621674, -0.4611055552959442, 0.9352855086326599, 0.014839726500213146, -0.3130958676338196, -0.06353677064180374, 0.5283864140510559, -0.3615957200527191, 0.3509860336780548, -0.10914340615272522, 0.05860493704676628, 0.12713348865509033, -0.3898148238658905, 0.6894667148590088, -0.14092200994491577, -0.7775959372520447, -0.0370120070874691, -1.4433681964874268, -0.6705294251441956, 0.015354317612946033, 0.6745765805244446, 0.10673113912343979, 0.25774726271629333, 0.8155349493026733, -0.5275306105613708, 0.2646527588367462, 0.26759544014930725, -0.4154720604419708, 0.2796628177165985, -0.2552960515022278, -0.38458389043807983, 0.023635277524590492, 0.09968563914299011, -0.466337651014328, -0.25162968039512634, 0.5569384694099426, -0.13620725274085999, 0.28294041752815247, 0.5294246077537537, -0.521842896938324, -0.7685562372207642, 1.0819703340530396, 0.696968138217926, 0.35872966051101685, 0.18490147590637207, -0.16181214153766632, 1.423872709274292, -1.1246014833450317, 0.5998255610466003, 1.388088583946228, 0.19371046125888824, 0.9897324442863464, -0.1967991292476654, -0.5896084308624268, 0.6210240721702576, -0.1755712777376175, -0.36889833211898804, -0.08450747281312943, -0.23866641521453857, -0.056310828775167465, 1.703168511390686, -0.5906669497489929, -0.32012709975242615, 1.0894556045532227, -0.12168645113706589, 1.39557945728302, -0.2453191578388214, -0.9691586494445801, -0.4805268943309784, 0.08709241449832916, 0.6337354183197021, 0.7031098008155823, -0.7352375388145447, 0.6729031205177307, -0.7455847263336182, 0.040218330919742584, 0.3575046956539154, -0.19532808661460876, -0.5318897366523743, 0.1461338847875595, -0.6644352078437805, 0.8067208528518677, 0.16107258200645447, 0.6357018947601318, 0.11861911416053772, 0.08124755322933197, 0.7512214183807373, 0.5132637023925781, 0.21192717552185059, 0.395345538854599, -0.0833454430103302, 0.2972116768360138, -0.6911185383796692, 0.27921953797340393, 0.47265803813934326, 1.0095868110656738, -0.45246416330337524, 0.09772977232933044, -1.4140249490737915, 0.19059424102306366, 1.131399154663086, -0.23491981625556946, 0.5711245536804199, -0.7117244601249695, 0.32856932282447815, -0.7294397950172424, 0.3964393138885498, -0.43192386627197266, -0.20464064180850983, 0.06686127930879593, -0.6611878871917725, -1.3776041269302368, -0.13072709739208221, -0.30172184109687805, -1.03294038772583, 1.217090368270874, -0.24057656526565552, 0.008235234767198563, 0.640807032585144, 0.3540913462638855, 0.9178240895271301, 1.0362310409545898, 0.4302282929420471, -0.3199824392795563, 0.5628758668899536, -0.7771316766738892, -0.7615903615951538, -0.9096465110778809, 1.1829473972320557, -0.3517957925796509, 0.4406696557998657, 0.02851162478327751, -0.8808072805404663, -0.86820387840271, -0.6784992218017578, -0.31085363030433655, -0.3378952443599701, 0.5851560831069946, 0.9062143564224243, 0.7910956740379333, -0.8144418001174927, 0.7061983346939087, -0.005078647751361132, -0.5026283264160156, -0.008490112610161304, -0.3317967653274536, 0.41146573424339294, -0.7352569699287415, -1.4329887628555298, 0.0022031422704458237, 0.4036053419113159, -0.7129860520362854, -0.4301309585571289, -0.8604174256324768, -1.305957555770874, -0.4728159010410309, 0.4588505029678345, -0.3751101493835449, 1.5673426389694214, -0.05634984374046326, -1.287826418876648, 0.7879233360290527, -0.37607628107070923, 0.1248139888048172, 0.4906308948993683, -0.35722965002059937, -0.40716031193733215, -0.5618965029716492, 0.25926005840301514, 0.9359026551246643, -0.03353942185640335, -0.05290677025914192, -0.0798666700720787, 0.4233737289905548, -0.11065308749675751, -0.3450483977794647, -0.33053433895111084, 0.5585495829582214, -0.04267890006303787, -0.2801882028579712, 0.35918083786964417, 0.8552111983299255, 0.03496091440320015, -0.5307953357696533, -0.6933370232582092, -1.6729481220245361, 0.8006938099861145, -0.08110195398330688, 0.7025704383850098, -0.6679961681365967, -0.8507259488105774, -0.7884703278541565, -0.37226828932762146, 0.04287533834576607, -0.9912829399108887, 0.9756656885147095, -0.30406323075294495, 0.5063576698303223, -0.13915269076824188, -1.239888310432434, 0.13181334733963013, -0.03995766490697861, -0.9852102994918823, -0.6949166655540466, 0.15177655220031738, 1.1647981405258179, -1.4135150909423828, 0.34251049160957336, -0.1607593297958374, -0.05772388353943825, -0.8471248149871826, 1.1436238288879395, -0.7791522741317749, 0.33869484066963196, -0.11591515690088272, -0.22848324477672577, 0.020634422078728676, -0.12328718602657318, 0.22242553532123566, -0.32635655999183655, -0.08341236412525177, 0.42131277918815613, -0.231626495718956, 1.5577256679534912, -0.22172828018665314, 0.24509012699127197, -0.43570244312286377, -0.6069499254226685, 0.3848094046115875, 1.0242968797683716, -0.5270933508872986, -0.582251787185669, 0.391071617603302, 0.40804964303970337, -0.5690580606460571, -0.07578465342521667, 0.6726238131523132, 0.3067699670791626, -0.30949127674102783, 0.7797084450721741, 1.0032278299331665, -0.2294480800628662, 1.1121572256088257, 0.7709043025970459, 0.5966524481773376, 0.40418893098831177, 0.28518766164779663, -0.03774828463792801, 0.19580818712711334, -0.45160314440727234, -0.1067156046628952, 0.6821625828742981, 0.7492257952690125, 1.0589627027511597, 0.4654896557331085, -0.8185872435569763, -0.32708805799484253, -0.07498784363269806, 0.8209390640258789, 1.6752378940582275, 0.11319528520107269, -0.20545028150081635, -0.9590896964073181, -0.5725612044334412, -0.6254231929779053, 0.7904807925224304, -0.3912031948566437, -0.2613063454627991, -0.24035939574241638, -0.867336630821228, 0.47899770736694336, 0.2562577724456787, 0.8156739473342896, -0.6167911887168884, -0.029678724706172943, -0.13055871427059174, -0.13629250228405, -0.7127106785774231, -0.7415047883987427, 0.2841135859489441, -0.33847203850746155, -0.3153393566608429, -0.23002904653549194, -0.18565654754638672, 0.26531004905700684, -0.3534717857837677, 1.09773850440979, -0.5321224927902222, -0.44263115525245667, 0.4264706075191498, 0.24049493670463562, -0.5970297455787659, -1.0867183208465576, 0.21462216973304749, 0.08912686258554459, -0.41180211305618286, 0.5707359910011292, 0.7580714225769043, 0.34829431772232056, 0.06604631245136261, -0.5313778519630432, 0.574425995349884, -0.2609850764274597, 0.17666961252689362, 0.39647337794303894, -0.7020835280418396, 0.46333640813827515, -1.4818451404571533, 1.2223632335662842, 0.012197839096188545, -0.2614823579788208, 0.38173314929008484, -0.47091883420944214, -0.6963600516319275, 0.48207366466522217, -0.8739790320396423, -0.8215566873550415, -0.9904013872146606, 0.5442777872085571, 0.17184123396873474, -0.593045711517334, 0.22985929250717163, 0.2071874737739563, 0.6102184057235718, 0.7554686665534973, 0.5767030715942383, 0.2582029104232788, -0.0704629123210907, 0.9648464918136597, -0.754042387008667, 0.5820856690406799, -0.0396902859210968, 0.09126868098974228, -0.3160231113433838, -0.5971318483352661, -0.48961034417152405, -1.0682687759399414, -0.4133491516113281, -0.4272189140319824, -0.38827985525131226, 0.3496937155723572, -0.37125006318092346, -0.7144069075584412, -0.0732990950345993, -1.5550014972686768, -0.33064767718315125, 0.03462424501776695, -0.7205914258956909, -0.4546322524547577, -0.8812436461448669, -1.0869852304458618, -0.3843148350715637, -0.6598989963531494, -0.5460676550865173, 0.4813510775566101, 0.20567578077316284, -0.7463775873184204, -0.7543458342552185, 0.5795482397079468, -0.10740577429533005, 0.5860267281532288, -0.6285362243652344, 0.8339329361915588, -0.30718690156936646, -0.261035293340683, -0.34511011838912964, 0.3687046766281128, 0.5516753792762756, -0.01978377439081669, 0.02316761389374733, -0.7088280320167542, 0.1195826455950737, -0.1697324812412262, -0.8263781070709229, 0.015921566635370255, 0.18356750905513763, 0.1262388974428177, 0.08244666457176208, -0.443253755569458, 0.08733898401260376, 1.3855935335159302, -0.3747941255569458, -0.21577462553977966, -0.09273374080657959, 1.0133394002914429, 0.7973470687866211, -0.020766250789165497, 0.333158940076828, 0.3815811574459076, 0.07289520651102066, -0.027193497866392136, 0.1005217656493187, 0.10265126824378967, -0.6703866720199585, 0.6032683253288269, 1.171764612197876, 0.4219509959220886, -0.33531588315963745, -1.3032305240631104, 0.9869579672813416, -1.2236723899841309, -0.31786343455314636, 0.1450040191411972, 0.31199589371681213, 0.6349560618400574, -0.7723089456558228, -0.6987582445144653, -0.35628148913383484, 0.6133164763450623, 0.2423567771911621, -0.1537942886352539, -0.8695582747459412, 0.17267662286758423, 0.24596090614795685, -0.23880864679813385, 0.4653928875923157, -0.19554854929447174, 0.7651148438453674, 14.478632926940918, 1.0250301361083984, 0.06781498342752457, 0.6745663285255432, 0.6397969722747803, 0.06787239015102386, -0.5987894535064697, -0.14198808372020721, -1.3413562774658203, -0.6003059148788452, 1.033806562423706, -0.30339235067367554, 0.3848966956138611, -0.021356502547860146, 0.26779770851135254, 0.1355239897966385, -0.8060207962989807, 0.2820921540260315, 0.6573694944381714, -1.1130645275115967, 0.838880181312561, 0.027402622625231743, 0.8143537044525146, 0.46317026019096375, 0.7105510830879211, 0.8740799427032471, 0.44169357419013977, -0.3296865224838257, 0.437896728515625, 0.059862785041332245, 0.5458939671516418, -0.08971747010946274, 0.3514738976955414, 1.112485647201538, -0.2679036557674408, -0.2896215319633484, -0.7270330190658569, -1.198386311531067, 0.7456644773483276, 0.09677322953939438, -0.4913877248764038, -0.3167283833026886, -0.6311895251274109, 0.7818113565444946, 0.5608013868331909, 0.07348613440990448, -0.3988488018512726, 0.7381459474563599, 0.18475963175296783, 0.06401213258504868, 0.6655123829841614, 0.22095003724098206, 0.48315274715423584, -0.08499448001384735, 0.29479172825813293, 0.4271320104598999, 0.42915454506874084, 1.0002480745315552, -0.6171874403953552, 0.15913547575473785, -0.6594441533088684, -0.2356908768415451, -0.31252333521842957, 0.7481375932693481, 0.3288004398345947, 0.05816970393061638, -0.3498384356498718, 0.3058822453022003, 0.36206236481666565, 0.13405302166938782, 0.15016169846057892, -0.07462265342473984, -0.12349888682365417, -0.4621889591217041, -0.33021220564842224, 0.7015852928161621, -0.3346197307109833, -0.4576944410800934, -0.9114211201667786, -0.30407705903053284, 0.31312206387519836, -0.7643283605575562, -1.0840404033660889, 0.7876633405685425, -0.5061761140823364, -0.6649701595306396, -0.13766686618328094, -0.5896821022033691, -0.8275865316390991, 0.38858562707901, -1.2786693572998047, -0.7776104211807251, 0.16350388526916504, -0.5951472520828247, -0.02653094381093979, -0.10366281121969223, 1.4623665809631348, -0.2262580543756485, -0.35757628083229065, -0.009255603887140751, 0.13896393775939941, -0.24928611516952515, -0.07543904334306717, -0.8413436412811279, 0.8182569146156311, 0.20712411403656006, -0.033006295561790466, 0.26514527201652527, 0.1291482299566269, -0.07188349217176437, -0.4499207139015198, -0.24444293975830078, 1.0763545036315918, -0.9057199358940125, -0.6028033494949341, -0.7321486473083496, -1.0181041955947876, 0.20393963158130646, 0.9404884576797485, -0.5614253878593445, 0.4297221899032593, 0.34986311197280884, -0.4306165277957916, 0.3647844195365906, -0.7272752523422241, 0.25868889689445496, 0.4349413514137268, -0.4733584523200989, -0.4837000072002411, 0.5038542747497559, 0.77983558177948, -1.0629557371139526, -0.3422960042953491, -0.4042990207672119, -0.3780590295791626, 0.07660628110170364, 0.5051786303520203, -0.3051985204219818, 0.9234126806259155, 1.0146526098251343, 0.3974491059780121, -0.7933342456817627, 0.28015008568763733, -1.3055421113967896, 0.5344836115837097, 0.8440780639648438, 0.744665265083313, -0.3312534987926483, 0.04386241361498833, 1.0425034761428833, 0.198420450091362, -0.2607196569442749, -0.36432701349258423, -0.5111061930656433, 0.44316422939300537, -0.6446759104728699, 0.11533090472221375, 0.13404114544391632, 0.1557128131389618, 0.26757046580314636, 0.535214900970459, 0.4599817395210266, -0.046410419046878815, -0.7520027756690979, 0.43423187732696533, -0.1953090876340866, 0.012874381616711617, -0.2976708710193634, 0.20628343522548676, -1.5676664113998413, 0.11568830907344818, -1.3840564489364624, 0.2974170446395874, -0.9145886301994324, -0.2990037798881531, 0.33085018396377563, 0.13011117279529572, 0.16705845296382904, 0.34358835220336914, -0.34153246879577637, -0.45116347074508667, -0.8323711156845093, -0.6197371482849121, 0.6972580552101135, 1.0524343252182007, -0.7672667503356934, -0.18763421475887299, -0.12815885245800018, -0.2142476737499237, 0.12615078687667847, 0.4363378882408142, -0.3478682339191437, -0.8867343664169312, -1.4169316291809082, 0.2460479736328125, 0.20062404870986938, 0.1494203358888626, -0.46746256947517395, 0.5337203741073608, 0.6111759543418884, -0.6190319061279297, -0.08445319533348083, -0.20740270614624023, -0.2583712637424469, -0.8829187750816345, 0.04119117185473442, -1.133509874343872, -0.22465719282627106, 0.02016129158437252, -0.5453022122383118, -0.36538568139076233, 0.3017566204071045, -0.2142752856016159, -1.3761632442474365, -0.6427561044692993, 0.51930832862854, -0.5460628271102905, 0.2985284626483917, -0.18353210389614105, -0.23209808766841888, -1.1431423425674438, -0.3325619697570801, -0.0381687767803669, 0.6450169682502747, -0.42364978790283203, 1.1319161653518677, 0.2131604254245758, -1.061874270439148, -0.07240130752325058, 0.22620941698551178, 0.13272619247436523, 0.16375230252742767, 0.737621009349823, 0.22308941185474396, 0.0498996265232563, 0.6926050186157227, 0.48083239793777466, 0.2721179127693176, -0.649646520614624, -0.006800906267017126, 0.6285027861595154, -0.5087694525718689, -0.2549235224723816, 1.2114531993865967, -0.14450399577617645, -1.4960427284240723, 0.015551425516605377, -0.8149881362915039, -0.6090061664581299, -0.2608490586280823, 0.9057602882385254, 0.11224021017551422, -0.022632282227277756, 0.06664939224720001, 0.30372390151023865, 0.1308407187461853, -0.24540799856185913, -0.5039184093475342, 0.7423434257507324, -0.1357063502073288, -0.40746480226516724, 0.7510216236114502, 0.6024177074432373, -1.2528105974197388, -0.7003872394561768, -0.5033065676689148, -0.4534636437892914, 0.10952439159154892, 0.1698945313692093, -0.7269165515899658, -0.06352201849222183, 1.0856735706329346, 0.24742776155471802, 0.7073512673377991, -0.14191834628582, -0.07323160022497177, 0.7011321783065796, 0.49968549609184265, 0.13425759971141815, -0.7677880525588989, -0.3147489130496979, 1.4667021036148071, 1.0767130851745605, -1.0875434875488281, -0.5429431796073914, -0.25441208481788635, -0.7286502122879028, 1.0066325664520264, 0.4419924020767212, 0.35317546129226685, 0.4152890741825104, -0.5505561232566833, 0.5522938370704651, 0.194779172539711, -1.2691527605056763, -0.09421936422586441, 0.6257879734039307, 1.4622386693954468, 1.0687192678451538, 0.1945227086544037, -0.28860825300216675, 1.1147186756134033, -0.023879092186689377, 0.3750568926334381, 0.9146634936332703, 0.22823527455329895, -0.3411611020565033, -0.4377388656139374, 0.37820756435394287, 0.5201699137687683, -0.41011178493499756, -0.7667350172996521, 0.007703361567109823, 0.30875566601753235, 0.15865418314933777, 0.839956521987915, 0.5846878290176392, 0.5036166906356812, 0.475398987531662, 0.3710370659828186, 0.17705494165420532, -1.0718700885772705, -0.08319902420043945, -0.3842872083187103, -0.6984218955039978, -0.015233269892632961, -0.008437412790954113, -0.5586660504341125, -0.31845369935035706, 0.041405025869607925, 0.248119056224823, -0.15490660071372986, 0.010366999544203281, 1.529145359992981, 0.3242556154727936, 0.17657239735126495, -0.36573830246925354, -0.26605337858200073, -0.5710394978523254, -1.0181958675384521, 0.01706678420305252, -0.4035169184207916, -0.46184349060058594, -0.007763473782688379, -0.021151050925254822, -0.05528509244322777]}, "authors": [{"authorId": "145391513", "name": "Yu Meng"}, {"authorId": "3488341", "name": "Jiaxin Huang"}, {"authorId": "49891156", "name": "Yu Zhang"}, {"authorId": "2111759643", "name": "Jiawei Han"}], "references": [{"paperId": "02f36289e227595dd2786b32c3975ce7e61dff48", "title": "Pretraining Text Encoders with Adversarial Mixture of Training Signal Generators"}, {"paperId": "2145fcceeb69385e108bf1796d52f974854d4c0b", "title": "ZeroGen: Efficient Zero-shot Learning via Dataset Generation"}, {"paperId": "842104ef0575823498f26cdd57b4b4dba655df9e", "title": "ZeroPrompt: Scaling Prompt-Based Pretraining to 1, 000 Tasks Improves Zero-Shot Generalization"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "ddcd5bed531c13e0da65e30333aaa5c27914f882", "title": "A Plug-and-Play Method for Controlled Text Generation"}, {"paperId": "c2a79e2a65b721d4de5f6d4806323174b9f8f393", "title": "Towards Zero-Label Language Learning"}, {"paperId": "a6d8d04962f84ae6225e72723869a002b9fc8036", "title": "What Changes Can Large-scale Language Models Bring? Intensive Study on HyperCLOVA: Billions-scale Korean Generative Pretrained Transformers"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "9b56086e420ecb216f85d408a25264f640e46705", "title": "Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners"}, {"paperId": "3b02eb62f198449840334da26917e3610b283e25", "title": "Controlled Text Generation as Continuous Optimization with Multiple Constraints"}, {"paperId": "ead441f3e9db042ffdeaf469f70bbe4b127d9060", "title": "Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with Language Models"}, {"paperId": "a6a7724763d8adba466519489b0b9d209e7f2d15", "title": "BARTScore: Evaluating Generated Text as Text Generation"}, {"paperId": "b58d8579ece27a60432e667bfbdb750590fa65d9", "title": "True Few-Shot Learning with Language Models"}, {"paperId": "02f033482b8045c687316ef81ba7aaae9f0a2e1c", "title": "DExperts: Decoding-Time Controlled Text Generation with Experts and Anti-Experts"}, {"paperId": "667bdd2a8dc997d40c106ff6761babebe4050762", "title": "Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics"}, {"paperId": "cbdb45fc16b0885905b91d84281c310e6cb49e9c", "title": "Cross-Task Generalization via Natural Language Crowdsourcing Instructions"}, {"paperId": "7fa273f450251523e6b7fcc2eb3fdbdfd4a30493", "title": "CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in NLP"}, {"paperId": "c26759e6c701201af2f62f7ee4eb68742b5bf085", "title": "SimCSE: Simple Contrastive Learning of Sentence Embeddings"}, {"paperId": "bbfdcbfee1762d48cae9db8637f21ea3c234ba30", "title": "GPT3Mix: Leveraging Large-scale Language Models for Text Augmentation"}, {"paperId": "b769b629c8de35b16735214251d6b4e99cb55762", "title": "Generating Datasets with Pretrained Language Models"}, {"paperId": "b6c4a96e09b9f11e7c70e7f1fbe3f3971b92762d", "title": "FUDGE: Controlled Text Generation With Future Discriminators"}, {"paperId": "4b0ec90dc10e51c1fc983edcd57bb86636d7b3ca", "title": "Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections"}, {"paperId": "e812919d2cd818e7262f01b32dc5e630fc825af1", "title": "Improving and Simplifying Pattern Exploiting Training"}, {"paperId": "bc37c6bdb8f39929a58b30464f72d6aa46cddc17", "title": "GPT Understands, Too"}, {"paperId": "a9fe5bd8da2d9603cf2cf6c6ea8b0f83c6d3a4f9", "title": "How many data points is a prompt worth?"}, {"paperId": "ca2f1088d3e581b2c6c75cf0ebc96506d620f64d", "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? \ud83e\udd9c"}, {"paperId": "56fa0b9cba4d9aee5ccc327365b3b3a721031c69", "title": "Calibrate Before Use: Improving Few-Shot Performance of Language Models"}, {"paperId": "19537be34dbadbcaa4fffcf028a8ada5095b1b5c", "title": "COCO-LM: Correcting and Contrasting Text Sequences for Language Model Pretraining"}, {"paperId": "10b15a695f837fbdc2babe0c38f8702c10af7bfb", "title": "Neural Data Augmentation via Example Extrapolation"}, {"paperId": "85e7d63f75c0916bd350a229e040c5fbb1472e7a", "title": "Making Pre-trained Language Models Better Few-shot Learners"}, {"paperId": "1841cf23c65ff2f27f21ba0d2268c3445f20332f", "title": "Few-Shot Text Generation with Natural Language Instructions"}, {"paperId": "07fd366a8ebdefe54cdb57d87c81dcd22de25a91", "title": "A Distributional Approach to Controlled Text Generation"}, {"paperId": "e02c114d6269f4781b0fa92f4e2c9376e7462906", "title": "PowerTransformer: Unsupervised Controllable Revision for Biased Language Correction"}, {"paperId": "e2d38543bd3cf813c63df336b21b003156ed48a8", "title": "Universal Natural Language Processing with Limited Annotations: Try Few-shot Textual Entailment as a Start"}, {"paperId": "399e7d8129c60818ee208f236c8dda17e876d21f", "title": "RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models"}, {"paperId": "f30444fbb6ad806168e2564db4815cd27faa7fd9", "title": "It\u2019s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners"}, {"paperId": "07bcda1dff9bb696ea9cbc69303eee8bd3d85bd6", "title": "GeDi: Generative Discriminator Guided Sequence Generation"}, {"paperId": "02eaaf87f9cae34cca398fed146079e6eeb1f868", "title": "Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "9b975cd0e9cb330300062916c72df3d63e1db207", "title": "CoCon: A Self-Supervised Approach for Controlled Text Generation"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "ae2c03cbe6162dadf65edd2ff7dfc5333524dca5", "title": "MixText: Linguistically-Informed Interpolation of Hidden Space for Semi-Supervised Text Classification"}, {"paperId": "82c77a88969ac0e3a4e55c9a7dc5ced4afee0225", "title": "Does label smoothing mitigate label noise?"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "8ae9a17c87a4518b513e860683a0ef7824be994d", "title": "Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference"}, {"paperId": "bbf105d2286c5a6b09998f514f685310562973b3", "title": "Zero-shot Text Classification With Generative Language Models"}, {"paperId": "7eba731a7fd8de712b7b79b5af41a6e2d4dbd191", "title": "Do Not Have Enough Data? Deep Learning to the Rescue!"}, {"paperId": "18d026ec5d0eebd17ee2c762da89540c0b3d7bde", "title": "A Comprehensive Survey on Transfer Learning"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c385e811f98260b673d52abcfdb981b60e880695", "title": "SELF: Learning to Filter Noisy Labels with Self-Ensembling"}, {"paperId": "e04a80263d252a3d8a382ba37a249b9345620570", "title": "Plug and Play Language Models: A Simple Approach to Controlled Text Generation"}, {"paperId": "7a15950dc71079285a4eaf195de5aadd87c41b40", "title": "Fine-Tuning Language Models from Human Preferences"}, {"paperId": "75acc731bdd2b626edc74672a30da3bc51010ae8", "title": "CTRL: A Conditional Transformer Language Model for Controllable Generation"}, {"paperId": "093d9253a2fe765ca6577b091d3f99bab3155a7d", "title": "Benchmarking Zero-shot Text Classification: Datasets, Evaluation and Entailment Approach"}, {"paperId": "93d63ec754f29fa22572615320afe0521f7ec66d", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"}, {"paperId": "53a77e8f73f2ca422d6e38fa9ecc490231ac044c", "title": "Neural Text Generation with Unlikelihood Training"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "f8de25118af2abc4c48afb947d6ec298e05ef1e5", "title": "When Does Label Smoothing Help?"}, {"paperId": "d9f6ada77448664b71128bb19df15765336974a6", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"}, {"paperId": "0feea94f89d395436bf41bd10c797447eecbc128", "title": "Unsupervised Data Augmentation for Consistency Training"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "5a814b1b114a8eb0dc60276af467d76e6250ca73", "title": "Weakly-Supervised Hierarchical Text Classification"}, {"paperId": "89644d9869df2df4d26500ccdd46f6326856534d", "title": "Weakly-Supervised Neural Text Classification"}, {"paperId": "cb0f3ee1e98faf92429d601cdcd76c69c1e484eb", "title": "Neural Network Acceptability Judgments"}, {"paperId": "bface38422b7e53287134c4d01a39fa58edd4469", "title": "Style Transfer Through Back-Translation"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "2a215755d7548ffc82079ce734c4ac60b62f6f56", "title": "Toward Controlled Generation of Text"}, {"paperId": "54ddb00fa691728944fd8becea90a373d21597cf", "title": "Understanding deep learning requires rethinking generalization"}, {"paperId": "d2e4587744a89bad95fea69e08842cad6c8ff0dd", "title": "Temporal Ensembling for Semi-Supervised Learning"}, {"paperId": "2cd55ded95d5d13430edfa223ba591b514ebe8a5", "title": "Adversarial Training Methods for Semi-Supervised Text Classification"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "8e12047bb8ed40c3266459ce8370a9f9594397bb", "title": "Transfer of Learning"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "2eddb4bffb5dda2a53a2a05da5914800c3dfa0db", "title": "GraDA: Graph Generative Data Augmentation for Commonsense Reasoning"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": null, "title": "Text classification using label names only: A language model self-training approach"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "2019). x denotes a sequence randomly sampled from the pretraining corpus; x denotes the sequence to be generated by G\u03b8"}, {"paperId": null, "title": "Furthermore, it was announced that a sequel to \u201cThe Last Airbender\u201d will be released in 2019. contradiction There is a rumor that Directed by Daniel"}, {"paperId": null, "title": "OpenWebText corpus"}, {"paperId": null, "title": "First Quora dataset release: Question pairs, 2017"}, {"paperId": "db8885a0037fe47d973ade79d696586453710233", "title": "The Sixth PASCAL Recognizing Textual Entailment Challenge"}, {"paperId": "351ec42df2b60c6042addf96e6b98673bbaf4dfd", "title": "The Fourth PASCAL Recognizing Textual Entailment Challenge"}, {"paperId": "de794d50713ea5f91a7c9da3d72041e2f5ef8452", "title": "The Third PASCAL Recognizing Textual Entailment Challenge"}, {"paperId": "136326377c122560768db674e35f5bcd6de3bc40", "title": "The Second PASCAL Recognising Textual Entailment Challenge"}, {"paperId": "475354f10798f110d34792b6d88f31d6d5cb099e", "title": "Automatically Constructing a Corpus of Sentential Paraphrases"}, {"paperId": "e808f28d411a958c5db81ceb111beb2638698f47", "title": "The PASCAL Recognising Textual Entailment Challenge"}, {"paperId": null, "title": "(a) Did you state the full set of assumptions of all theoretical results"}, {"paperId": null, "title": "Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation"}, {"paperId": null, "title": "Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?"}, {"paperId": null, "title": "Did you report error bars (e.g., with respect to the random seed after running experiments multiple times"}, {"paperId": null, "title": "Have you read the ethics review guidelines and ensured that your paper conforms to them"}, {"paperId": null, "title": "Checklist 1. For all authors"}, {"paperId": null, "title": "code, data, models) or curating/releasing new assets... (a) If your work uses existing assets"}, {"paperId": null, "title": "Did you include the code, data, and instructions needed to reproduce the main experimental results"}, {"paperId": null, "title": "Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable?"}, {"paperId": null, "title": "Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content?"}, {"paperId": null, "title": "Did you discuss any potential negative societal impacts of your work"}, {"paperId": null, "title": "If you used crowdsourcing or conducted research with human subjects"}]}