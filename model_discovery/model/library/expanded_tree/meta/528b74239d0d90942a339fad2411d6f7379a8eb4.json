{"paperId": "528b74239d0d90942a339fad2411d6f7379a8eb4", "abstract": "Visual Transformers (ViTs) have shown impressive performance due to their powerful coding ability to catch spatial and channel information. MetaFormer gives us a general architecture of transformers consisting of a token mixer and a channel mixer through which we can generally understand how transformers work. It is proved that the general architecture of the ViTs is more essential to the models\u2019 performance than self-attention mechanism. Then, Depth-wise Convolution layer (DwConv) is widely accepted to replace local self-attention in transformers. In this work, a pure convolutional \"transformer\" is designed. We rethink the difference between the operation of self-attention and DwConv. It is found that the self-attention layer, with an embedding layer, unavoidably affects channel information, while DwConv only mixes the token information per channel. To address the differences between DwConv and self-attention, we implement DwConv with an embedding layer before as the token mixer to instantiate a MetaFormer block and a model named EmbedFormer is introduced. Meanwhile, SEBlock is applied in the channel mixer part to improve performance. On the ImageNet-1K classification task, EmbedFormer achieves top-1 accuracy of 81.7% without additional training images, surpassing the Swin transformer by +0.4% in similar complexity. In addition, EmbedFormer is evaluated in downstream tasks and the results are entirely above those of PoolFormer, ResNet and DeiT. Compared with PoolFormer-S24, another instance of MetaFormer, our EmbedFormer improves the score by +3.0% box AP/+2.3% mask AP on the COCO dataset and +1.3% mIoU on the ADE20K.", "venue": "Italian National Conference on Sensors", "year": 2022, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://www.mdpi.com/1424-8220/22/24/9854/pdf?version=1671085357", "status": "GOLD"}, "tldr": {"model": "tldr@v2.0.0", "text": "It is proved that the general architecture of the ViTs is more essential to the models\u2019 performance than self-attention mechanism, and Depth-wise Convolution layer (DwConv) is widely accepted to replace local self-Attention in transformers."}, "embedding": {"model": "specter_v2", "vector": [0.008864110335707664, 0.5209904909133911, -0.4997197687625885, 0.4052330553531647, -0.2965150475502014, -0.23007015883922577, 0.789899468421936, -0.1605498492717743, -0.325267493724823, -0.49184146523475647, 1.0207562446594238, 0.36134248971939087, 0.8128330707550049, -0.2169295847415924, -0.04398396611213684, -0.2193576544523239, -0.618493378162384, -0.4438733756542206, 0.04615314304828644, 0.011116662994027138, 0.1825057566165924, -0.6966031193733215, -1.0182676315307617, 0.6725600361824036, 0.17633064091205597, 0.9951656460762024, 0.4807288348674774, 0.8478375673294067, -0.43019434809684753, 0.6129192113876343, 0.3378887176513672, -0.41445520520210266, 0.263997882604599, -0.005481593310832977, -0.21284957230091095, 0.09985261410474777, 0.7416198253631592, -0.2624768614768982, -0.6307054162025452, 0.8863637447357178, 0.24363520741462708, -0.0814032033085823, 0.38882991671562195, -0.73794025182724, -0.04653124511241913, 1.232656717300415, 0.8272110819816589, 0.7353660464286804, -0.9036652445793152, -0.34411659836769104, 1.5210351943969727, -1.5502610206604004, 0.06093485280871391, 1.3691908121109009, 0.2567984461784363, 0.24916411936283112, -0.06449159234762192, -0.7844647169113159, 0.8814484477043152, 0.4657669961452484, -0.39798876643180847, -0.3973238468170166, 0.3151648938655853, -0.07602833211421967, 1.6523385047912598, -0.5295184254646301, 0.20733068883419037, 0.9315731525421143, 0.13412638008594513, 1.4927949905395508, 0.2059219479560852, -0.305292546749115, -0.16029657423496246, 0.14077208936214447, 0.18049800395965576, 0.7271067500114441, -0.5296837091445923, 0.27026623487472534, -1.0846779346466064, 0.44554758071899414, 0.9283577799797058, -0.03185413032770157, 0.3847125768661499, -0.11265464127063751, -0.6779608726501465, 0.4943917393684387, 0.9549227356910706, 0.838232159614563, -0.4979318380355835, 0.9646103978157043, 0.702948272228241, -0.0453786663711071, -0.1984572410583496, 0.5334036946296692, 0.3091428875923157, 0.42052605748176575, -0.7072950601577759, -0.060732416808605194, -0.41518905758857727, 0.9066711664199829, -0.23405775427818298, 0.6479631066322327, -0.6887176036834717, -0.052675362676382065, 1.6111853122711182, 0.13245601952075958, 0.43351849913597107, -0.8387254476547241, 0.09200503677129745, -0.8590704798698425, -0.37896618247032166, -0.8027048110961914, 0.5790620446205139, -0.8141369223594666, -1.0019328594207764, -0.8307650089263916, -0.3949963450431824, 0.48576581478118896, -1.258723258972168, 0.4827876389026642, -0.6653512120246887, 0.3762779235839844, 0.030388247221708298, 0.21889251470565796, 0.711466372013092, 0.48136836290359497, 0.6112653613090515, 0.377339243888855, 1.3706609010696411, -1.5223840475082397, -0.8955914974212646, -0.8692401051521301, -0.24022546410560608, -0.38555076718330383, -0.30535703897476196, -0.04735371470451355, -1.1765773296356201, -1.3778910636901855, -1.0599393844604492, 0.18879534304141998, -0.766228437423706, -0.12884119153022766, 0.9239847660064697, 0.5712084770202637, -1.172729253768921, 0.8420372009277344, -0.401738703250885, -0.2728816568851471, 0.7313385009765625, -0.25600066781044006, 0.2397862672805786, 0.3821697235107422, -0.9693917036056519, 0.1825060099363327, 0.04996919631958008, -0.1407335102558136, -0.9432612657546997, -0.7227447032928467, -0.9587974548339844, 0.12890267372131348, 0.024348832666873932, -0.36312565207481384, 1.1386268138885498, -0.3530227243900299, -0.8246950507164001, 0.5715112090110779, -0.5433354377746582, 0.007081512827426195, 0.3306061625480652, -0.23632590472698212, -0.2937781810760498, -0.2518368363380432, 0.1305401772260666, 0.6657519936561584, 0.8876871466636658, -0.3926636278629303, -0.20397482812404633, 0.2230575829744339, -0.3830486238002777, -0.07464781403541565, -0.27313029766082764, 0.8372584581375122, -0.3542715013027191, -0.6431931853294373, 0.4444577395915985, 1.3895554542541504, 0.05106452479958534, -0.057860925793647766, -0.3311217725276947, -0.7294277548789978, 0.8200100064277649, 0.3322010338306427, 0.47894859313964844, -1.0517299175262451, -0.902855634689331, -0.2640991806983948, 0.3567025661468506, -0.15415386855602264, -1.018979787826538, 0.7123361825942993, -0.4483906924724579, 0.28562310338020325, 0.4374629855155945, -1.0941815376281738, 0.07102562487125397, -0.2936154007911682, -0.6055333614349365, -0.3211231231689453, 0.27214938402175903, 1.1705601215362549, -0.9497350454330444, -0.39303353428840637, -0.0260811448097229, 0.4737893342971802, -1.1374053955078125, 1.2818175554275513, -0.061639800667762756, -0.16554895043373108, -0.16860608756542206, 0.2857937812805176, 0.2954435348510742, -0.27772945165634155, 0.39188113808631897, -0.8781595230102539, -0.34486737847328186, 0.5351283550262451, -0.6921216249465942, 1.2050647735595703, -0.049550533294677734, 0.8941164612770081, 0.056904301047325134, -0.8019118309020996, 0.13783355057239532, 0.6404107213020325, -0.23736298084259033, -0.8078863620758057, 0.4423541724681854, 0.1311962902545929, -0.6470800042152405, 0.32625526189804077, 0.8549140691757202, 0.875843346118927, -0.07339305430650711, -0.30560702085494995, 1.0087274312973022, -0.032492365688085556, -0.16372224688529968, 0.4589015245437622, 0.6584038138389587, 0.03406275808811188, 0.12716130912303925, -0.27222684025764465, -0.18035578727722168, -1.178436040878296, 0.014085552655160427, 0.8584064245223999, 0.27105486392974854, 1.1628966331481934, 0.7091231942176819, -0.4657995104789734, -0.4621829688549042, -0.3814403712749481, 0.6768194437026978, 1.082635760307312, 0.029878534376621246, -0.3282586932182312, -0.7012083530426025, -0.4416188597679138, -0.39101654291152954, -0.5844262838363647, -0.4411909282207489, -0.15832434594631195, -0.04484081268310547, -0.5930933356285095, 0.9411545395851135, 0.7567522525787354, 1.4879776239395142, -0.8000044226646423, -0.5171576142311096, -0.01869949884712696, 0.22547541558742523, -0.9155617356300354, -0.6340050101280212, 0.5532547235488892, -0.4812506139278412, -0.19918230175971985, -0.30682289600372314, -0.3467399775981903, 0.1599297970533371, -0.44130900502204895, 0.5899335741996765, -0.6378621459007263, -0.30410391092300415, 0.21037104725837708, 0.17197974026203156, -0.48044833540916443, -0.24078701436519623, 0.18384699523448944, -0.25843849778175354, 0.18747878074645996, -0.11821632832288742, 0.045885294675827026, -0.4215424656867981, 0.12064739316701889, -0.12101548165082932, 0.11799409985542297, 0.2677907347679138, 0.07840724289417267, 0.45425525307655334, -0.21107088029384613, -0.11029089987277985, -0.9108008742332458, 0.6340351104736328, 0.22400017082691193, 0.004662428982555866, -0.20011134445667267, -0.5827023386955261, -0.40678203105926514, 0.040473293513059616, -0.43473881483078003, -0.2481972873210907, -0.9810240864753723, 0.33645808696746826, -0.4413723647594452, -0.15133526921272278, 0.04607001692056656, -0.10905716568231583, 0.3037566840648651, 0.1689058393239975, 0.47437581419944763, -0.05497549846768379, -0.10249575227499008, 0.6181760430335999, -0.7106370329856873, 0.8307175040245056, 0.23600052297115326, 0.17220228910446167, 0.07250362634658813, -0.5726619362831116, -0.7039822340011597, -0.2946895360946655, -0.7522455453872681, -0.030065424740314484, -0.5477287173271179, 0.6898248791694641, -0.952609658241272, -1.0546760559082031, 0.795807421207428, -1.0815002918243408, -0.29039207100868225, -0.10729403793811798, -0.3879975378513336, -0.09242545068264008, -1.241033911705017, -0.8456918001174927, -0.7424784302711487, -0.2612116038799286, -1.1282265186309814, 0.041696954518556595, 0.4185057282447815, 0.03505273163318634, -0.44261327385902405, -0.3225434422492981, -0.525292694568634, 1.480613350868225, -0.4543531537055969, 0.366481214761734, -0.18798741698265076, -0.6970841884613037, 0.11824221909046173, -0.5096089243888855, 0.8716822862625122, -0.030658099800348282, 0.015030269511044025, -1.4407140016555786, 0.5085644721984863, -0.1968352049589157, -0.10623036324977875, 0.7345744371414185, 0.2945101857185364, 0.761661946773529, 0.02323865331709385, -0.4532341957092285, 0.46652689576148987, 1.6433813571929932, -0.28011637926101685, 0.8097578287124634, 0.10347367823123932, 0.9513529539108276, -0.12677688896656036, -0.6778988242149353, 0.49755704402923584, 0.49496883153915405, 0.05675964057445526, 0.7069571018218994, -0.5353720784187317, -0.5958307385444641, -0.7944324612617493, 0.3301629424095154, 1.1877593994140625, -0.06572425365447998, -0.015996616333723068, -0.8795357346534729, 1.0951119661331177, -1.2576326131820679, -1.0695137977600098, 0.6747105121612549, 0.31789252161979675, 0.056707847863435745, -0.34873685240745544, -0.46369174122810364, 0.1558426022529602, 0.555985689163208, 0.8581953644752502, 0.03678099438548088, -0.5454555153846741, -0.031380731612443924, 0.8658141493797302, 0.44267261028289795, 0.8123573660850525, -0.4942735731601715, 0.5797532796859741, 14.537971496582031, 0.48565101623535156, -0.1234973669052124, 0.46258440613746643, 0.714893102645874, 0.9217877984046936, -0.2795678675174713, 0.20143505930900574, -1.0667089223861694, -0.09159871190786362, 0.6029178500175476, 0.5697504281997681, 0.21819628775119781, 0.17923453450202942, -0.16943037509918213, 0.16737346351146698, -0.43225517868995667, 0.648328423500061, 0.579107940196991, -1.3995565176010132, 0.20214307308197021, 0.26588788628578186, 0.17950816452503204, 0.3565601706504822, 0.908299446105957, 0.46875354647636414, 0.35603442788124084, -0.4068182706832886, 0.7817205786705017, 0.1856761872768402, 0.6600528955459595, 0.32093438506126404, 0.3163686692714691, -0.18746109306812286, -1.3603323698043823, 0.02667798101902008, -0.5185139775276184, -1.0345244407653809, 0.00146448181476444, 0.09449979662895203, -0.08038025349378586, -0.6817660927772522, 0.13162264227867126, 0.9346053004264832, 0.05074869841337204, 0.8387772440910339, -0.44077861309051514, 0.4429410398006439, 0.40725985169410706, -0.06985927373170853, 0.5435264110565186, 1.1470212936401367, 0.3182656764984131, 0.2491527646780014, -0.12188085913658142, -0.007381391245871782, -0.05268105864524841, 0.5742416977882385, -0.6659864187240601, -0.4164288341999054, 0.08971994370222092, -0.4827083945274353, -0.06780765950679779, 1.1373648643493652, 0.08598045259714127, -0.008272048085927963, 0.033333223313093185, 0.5947151184082031, 0.09174197912216187, 0.12111527472734451, -0.7275323271751404, -0.37918633222579956, 0.442938894033432, -0.23304899036884308, 0.33505845069885254, 0.6058450937271118, -0.16726386547088623, -0.4750765562057495, -0.8728492259979248, -0.37870532274246216, 0.264030784368515, -0.962655782699585, -0.5727104544639587, 1.175764799118042, -0.3593772351741791, -0.3838023543357849, 0.7714264988899231, -1.0195859670639038, -0.7741288542747498, 0.26797792315483093, -1.6738499402999878, -0.8798080682754517, -0.5202417969703674, -0.1824977546930313, -0.14278560876846313, -0.16959980130195618, 1.0237677097320557, 0.24977299571037292, -0.041052158921957016, 0.08239906281232834, -0.5174504518508911, 0.4610331952571869, -0.12060897052288055, -1.0970666408538818, 0.7209723591804504, 0.2836414873600006, -0.05702434480190277, -0.09697381407022476, -0.011727070435881615, 0.3996009826660156, -0.38018763065338135, 0.09610376507043839, 0.7858558297157288, -0.3948221206665039, -0.319142609834671, -1.0079110860824585, -0.5569466948509216, 0.11020135134458542, 1.411334753036499, 0.16137120127677917, -0.0253921952098608, 0.025389470160007477, -1.0458345413208008, -0.2549785375595093, -0.4488450586795807, -0.04786526411771774, 0.4102001488208771, -0.6991601586341858, -0.20516248047351837, -0.5011475086212158, 0.12370937317609787, -0.897081732749939, -0.2659011483192444, -0.5010405778884888, 0.36299365758895874, -0.520764172077179, 1.1124850511550903, -0.3391411304473877, 0.856650173664093, 0.9719512462615967, -0.3162137567996979, -0.9648572206497192, -0.03066880628466606, -0.9479140639305115, 0.5171158909797668, 0.7050831317901611, 0.7787249684333801, -0.5424477458000183, 0.5003467798233032, 0.32964855432510376, 0.10734532028436661, -0.29740965366363525, -0.4641684591770172, -3.353845022502355e-05, -0.2831491231918335, -0.6854671239852905, 0.21500994265079498, 0.08881708234548569, 0.20554570853710175, -0.17163588106632233, 0.5552060008049011, 0.33556193113327026, 0.2087109535932541, -0.9244334101676941, 0.19973544776439667, 0.17851831018924713, -0.07986482232809067, -0.47205957770347595, -0.8041677474975586, -1.223252773284912, -0.474811851978302, -1.0579216480255127, 0.12093310058116913, -1.1555917263031006, -0.2519402503967285, 0.2121421992778778, -0.8816210627555847, 0.09725220501422882, 0.3902389705181122, -0.04629773646593094, 0.061648350208997726, -0.7840713858604431, -0.5037493705749512, 0.6035197377204895, 1.1718599796295166, -0.9714556932449341, 0.2218257337808609, -0.3654033839702606, -0.49645596742630005, 0.3569927513599396, 0.25268083810806274, -0.4858275055885315, -0.4552364647388458, -1.1612707376480103, 0.15061457455158234, -0.1605137139558792, 0.19379986822605133, -1.1436823606491089, 1.0850186347961426, 0.7648428678512573, 0.31456735730171204, 0.029167678207159042, 0.2504468560218811, -0.8232330679893494, -0.6591495871543884, 0.36485588550567627, -0.7886046171188354, 0.23281612992286682, 0.054367296397686005, -0.6887842416763306, -0.5631817579269409, 1.0481046438217163, 0.19246958196163177, -1.3495687246322632, -1.1328794956207275, 0.37182676792144775, -0.7277964353561401, 0.09728120267391205, -0.30850639939308167, -0.3232121169567108, -1.3643718957901, -0.3445548713207245, -0.1796654313802719, 0.20284545421600342, -0.9633229374885559, 0.9378014802932739, 0.8035743236541748, -1.233375072479248, 0.09333229064941406, 0.6732669472694397, -0.1519579440355301, -0.2889406383037567, 0.4904734790325165, 0.4324684143066406, -0.31549617648124695, -0.021491067484021187, -0.27013811469078064, 0.18293063342571259, -0.5358070135116577, -0.1981399655342102, 1.0723929405212402, -0.4733433723449707, 0.06638582050800323, 1.1582834720611572, -0.17318964004516602, -0.363350510597229, 0.4705647826194763, -1.0779016017913818, -0.542233407497406, 0.3451244533061981, 0.572519838809967, 0.19438382983207703, -0.36002323031425476, -0.012438993901014328, -0.543298602104187, 0.16271382570266724, -0.296095609664917, -0.7518458366394043, 0.4449274241924286, 0.3028101623058319, -0.10206157714128494, 0.17340579628944397, 0.7507851719856262, -0.641782820224762, -1.052370548248291, -0.7286261320114136, -0.912775993347168, -0.28222694993019104, 0.33597198128700256, -0.18457764387130737, -1.1344777345657349, 1.1890356540679932, 0.843048632144928, 0.5099444389343262, 0.15136949717998505, -0.10211463272571564, -0.03097156621515751, 0.11801328510046005, -0.30094319581985474, -0.6538633704185486, 0.13601014018058777, 1.0828427076339722, 0.9200299382209778, -0.4407157003879547, -0.18133561313152313, -0.14402152597904205, -0.6667490005493164, 0.6055359840393066, 0.45612335205078125, -0.44823718070983887, 0.9514864683151245, -0.021369125694036484, 0.5013760924339294, 0.28930607438087463, -1.019586443901062, -0.7752645611763, 0.44024035334587097, 1.4681458473205566, 0.6884582042694092, 0.035591885447502136, 0.3631094992160797, 0.7406586408615112, 0.3431745171546936, -0.4730322062969208, 0.387413889169693, 0.10489457100629807, -0.15823112428188324, -0.13515044748783112, 0.1344282329082489, 0.27030548453330994, -0.739982008934021, -0.6691778302192688, 0.3327348530292511, 0.5684638023376465, 0.370577871799469, 0.5206589102745056, 1.0425225496292114, -0.09568120539188385, 0.6745131611824036, 0.16262173652648926, 0.45019471645355225, -0.21122699975967407, -0.5473942756652832, 0.26989445090293884, -1.0269017219543457, -0.3097202181816101, -0.6200510263442993, -0.44194698333740234, 0.12088626623153687, 0.12346131354570389, 0.23422692716121674, -0.18092887103557587, 0.47363030910491943, 0.7855929732322693, 0.24301208555698395, 1.235470175743103, 0.014026842080056667, -0.7080940008163452, -0.032946497201919556, -0.8021360635757446, 0.1359250843524933, -0.6561086177825928, 0.148151233792305, -0.11324095726013184, -0.18698807060718536, -0.09410566836595535]}, "authors": [{"authorId": "145660543", "name": "Zeji Wang"}, {"authorId": "1476816524", "name": "Xiaowei He"}, {"authorId": "2196270883", "name": "Yi Li"}, {"authorId": "2197290103", "name": "Qinliang Chuai"}], "references": [{"paperId": "7d7b8d20e4a4c620847663f74b568db4e1919553", "title": "Transformer Based Binocular Disparity Prediction with Occlusion Predict and Novel Full Connection Layers"}, {"paperId": "5ebd33fd6c2355177effe891495a8f622f4459c2", "title": "Single-Shot Object Detection via Feature Enhancement and Channel Attention"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "db74b8415d6442255aa0a368a6392252ef85fcee", "title": "ELSA: Enhanced Local Self-Attention for Vision Transformer"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "f454f6b5f2ca9749ddf442eb5134612ef7f758c1", "title": "ResNet strikes back: An improved training procedure in timm"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "70cf7c785952375e8061c92235aa20e94b02ecd4", "title": "Coordinate Attention for Efficient Mobile Network Design"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "d29430adccb805ab57b349afa8553954347b3197", "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "6d5f423164cd5ef9324281652987c8a65009e98e", "title": "Sparse R-CNN: End-to-End Object Detection with Learnable Proposals"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "f1e8a99a7e17d449559b26ee0db2e8f1f47ce7ad", "title": "SpeechBERT: An Audio-and-Text Jointly Learned Language Model for End-to-End Spoken Question Answering"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "c2c083df88e88223e1a411e61040b94c233b1b63", "title": "MMDetection: Open MMLab Detection Toolbox and Benchmark"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "69455376f5ad52cac5b72d5e8c6cf03fb466b55c", "title": "Cross-Modal Self-Attention Network for Referring Image Segmentation"}, {"paperId": "deb956b70eb93bb08eaabc18fb11aed9bd20d08f", "title": "SRM: A Style-Based Recalibration Module for Convolutional Neural Networks"}, {"paperId": "fb8cf663a71bf31f59557a35d36aaf8c465b50af", "title": "Selective Kernel Networks"}, {"paperId": "a84906dbd4d6640f918d0b6ed2a7313dda0d55f1", "title": "Panoptic Feature Pyramid Networks"}, {"paperId": "987b2db58fbe0bda771f11a046cd23de1ce92b39", "title": "Deformable ConvNets V2: More Deformable, Better Results"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "04957e40d47ca89d38653e97f728883c0ad26e5d", "title": "Cascade R-CNN: Delving Into High Quality Object Detection"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "9da734397acd7ff7c557960c62fb1b400b27bd89", "title": "ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "4a73a1840945e87583d89ca0216a2c449d50a4a3", "title": "Deformable Convolutional Networks"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "5582bebed97947a41e3ddd9bd1f284b73f1648c2", "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"}, {"paperId": "88512be44744615f4baa8e14f600f036db4c2433", "title": "Semantic Understanding of Scenes Through the ADE20K Dataset"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "7f5fc84819c0cf94b771fe15141f65b123f7b8ec", "title": "Multi-Scale Context Aggregation by Dilated Convolutions"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}]}